\subsection{Preliminaries and Notation}
In this section, we introduce essential concepts relevant to HyFi, and present preliminaries concerning hypergraphs and hypergraph neural networks. The notations utilized are concisely summarized in Table \ref{tab:notation}.



\subsubsection{Hypergraphs}
HyFi employs hypergraphs as a foundational structure, denoted by \( G = (V, E) \), where \( G \) represents the hypergraph, \( V \) the set of nodes, and \( E \) the set of hyperedges.  The nodes and hyperedges are denoted as \( V = \{v_1, v_2, \ldots, v_{|V|}\} \) and \( E = \{e_1, e_2, \ldots, e_{|E|}\} \), respectively. The node feature matrix is defined by \( X \in \mathbb{R}^{|V| \times d} \), where each node \( v_i \)'s feature vector \( x_i \) is represented by \( X[i, :]^T \in \mathbb{R}^d \). In general, a hypergraph can be alternatively characterized by its incidence matrix \( H \in \{0, 1\}^{|V| \times |E|} \), where the entries are defined as \( h_{ij} = 1 \) if node \( v_i \) is included in hyperedge \( e_j \), and \( h_{ij} = 0 \) otherwise.


\subsubsection{Hypergraph neural networks}

Prior studies on HGNNs have predominantly adopted a two-phase neighborhood aggregation approach that includes both node-to-hyperedge and hyperedge-to-node aggregations. These networks use an iterative process to update hyperedge representations by accumulating the representations of neighboring nodes, and similarly, to update node representations by accumulating those of neighboring hyperedges. At the k-th layer, the representations of nodes and hyperedges are denoted as \( P^{(k)} \in \mathbb{R}^{|V| \times d^\prime_k} \) and \( Q^{(k)} \in \mathbb{R}^{|E| \times d^{\prime\prime}_k} \), respectively. More precisely, the k-th layer function in a Hypergraph neural network can be expressed as \( q_j^{(k)} = f_{V \rightarrow E}^{(k)}(q_{j}^{(k-1)}, p_{i}^{(k-1)} : v_i \in e_j) \) and \( p_i^{(k)} = f_{E \rightarrow V}^{(k)}(p_{i}^{(k-1)}, q_{j}^{(k)} : v_i \in e_j) \), where \( p_i^{(0)} = x_i \). Therefore, the choice of aggregation functions \( f_{V \rightarrow E}(\cdot) \) and \( f_{E \rightarrow V}(\cdot) \) is critical to the performance of the model. We will use HGNN model\cite{feng2019hypergraph} as the backbone of the HyFi encoder.

\begin{table}[t!]
\centering
\caption{Primary Notations in this paper.}
\label{tab:notation}
\resizebox{\columnwidth}{!}{
\renewcommand{\arraystretch}{1.2}
\begin{tabular}{cl}
\hline
\textbf{Notation} & \textbf{Definition} \\
\hline
$G = (V, E)$ & Hypergraph with nodes $V$ and hyperedges $E$ \\
$H$ & Incidence matrix \\
$X$ & Node feature matrix \\
$V$ & Hypergraph with nodes, where $V = \{v_1, v_2, \ldots, v_{|V|}\}$ \\
$E$ & Hypergraph with hyperedges, where $E = \{e_1, e_2, \ldots, v_{|E|}\}$ \\
$P^{(l)}$ & Node embedding matrix at layer $l$\\
$Q^{(l)}$ & Hyperedge embedding matrix at layer $l$\\
$l$ & Number of layers\\
$D_v$ & Diagonal matrix, Degree of node\\
$D_e$ & Diagonal matrix, Degree of hyperedge\\
$W$ & Diagonal matrix, Weight of hyperedge\\
$\mathcal{N}(0, \sigma^2)$ & noises from Gaussian distribution with 0 mean and variance $\sigma^2$\\
$f_\theta(\cdot)$ & HGNN Encoder\\  
$g_\pi(\cdot)$ & Node embedding projection head\\
$g_\psi(\cdot)$ & Hyperedge embedding projection head\\
$Z$ & Final Node embedding after passing the projection head\\
$Y$ & Final Hyperedge embedding after passing the projection head\\
$sim(u, v)$ & Cosine similarity $\mathbf{u}^\mathsf{T} \mathbf{v} / \|\mathbf{u}\| \|\mathbf{v}\|$\\
$N_{v_i}$ & Set of other nodes in the group to which node $v_i$ belongs\\
$M$ & Number of Noise views\\
\hline
\end{tabular}}
\end{table}
% 최종본 내기 전에 추가할 것 있는지 확인 필요

% \begin{figure*}[th!]
%   \centering
%   \includegraphics[width=1.00\textwidth,
%   % height=6.2cm
%   ]{FIG/framework.pdf}
%   \caption {Illustration of the HyFi framework. \( X^{\prime} \) is first generated by adding a noise value to \( X \). Subsequently, embeddings for both the original view and the noise view are obtained through the same HGNN Encoder, denoted as \( f_{\theta}(\cdot) \). The embeddings for the nodes and hyperedges are then passed through their respective projection heads: \( g_{\phi} \) and \( g_{\psi} \). Contrastive learning is conducted at the node-level and the edge-level.}
%   \label{fig:Framework}
% \end{figure*}
