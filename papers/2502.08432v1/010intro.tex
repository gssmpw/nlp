Hypergraphs surpass simple pairwise connections, capturing complex interactions in the real world\cite{yang2022semi, he2023robust, yang2023group, luo2022dualgraph, xie2022contrastive, zhu2021inhomogeneous, saifuddin2023hygnn, li2023coclep, yin2022dynamic}. Although recent advances in graph-based learning have primarily focused on these simple relationships, they often fail to account for the intricate group dynamics inherent in real-world data. In contrast, hypergraphs can go beyond pairwise connections to capture high-order data correlations. Their application across diverse fields such as social network analysis\cite{yang2019revisiting, sun2022ms, sun2023self}, bioinformatics\cite{saifuddin2023seq, zhang2022multiscale, you2022cross, liu2022generating}, and complex system modeling is increasingly prevalent, as they can effectively represent the depth of relationships within these domains. These applications showcase the advantages of hypergraphs in capturing high-order data correlations from real-world scenarios\cite{li2021hyperbolic, vijaikumar2021hypertenet, xia2021self, gu2020quantum, liu2023self}.


% 하이퍼그래프는 단순한 쌍 간의 연결을 뛰어넘어 실제 세계의 복잡한 상호작용을 포착합니다\cite{yang2022semi, he2023robust, yang2023group, luo2022dualgraph, xie2022contrastive, zhu2021inhomogeneous, saifuddin2023hygnn, li2023coclep, yin2022dynamic}. 최근 그래프 기반 학습의 발전은 주로 이러한 단순한 관계에 초점을 맞추었지만, 실제 데이터에 내재된 복잡한 그룹 역학을 설명하지 못하는 경우가 많습니다. 이와는 대조적으로 하이퍼그래프는 쌍 단위의 연결을 넘어 고차 데이터 상관관계를 포착할 수 있습니다. 하이퍼그래프는 이러한 영역 내 관계의 깊이를 효과적으로 나타낼 수 있기 때문에 소셜 네트워크 분석\cite{yang2019revisiting, sun2022ms, sun2023self}, 생물정보학\cite{saifuddin2023seq, zhang2022multiscale, you2022cross, liu2022generating} 및 복잡한 시스템 모델링 등 다양한 분야에 걸쳐 점점 더 널리 적용되고 있으며, 그 활용 범위가 점점 더 넓어지고 있습니다. 이러한 애플리케이션은 실제 시나리오에서 고차 데이터 상관관계를 포착하는 데 있어 하이퍼그래프의 장점을 보여줍니다\cite{li2021hyperbolic, vijaikumar2021hypertenet, xia2021self, gu2020quantum, liu2023self}.

\begin{figure}[t!]
  \centering
  \begin{subfigure}[b]{0.56\columnwidth}
    \includegraphics[width=\linewidth]{FIG/fig1_1.pdf}
    \caption{Tranditional HGCL}
  \end{subfigure}
  \begin{subfigure}[b]{0.39\columnwidth}
    \includegraphics[width=\linewidth]{FIG/fig1_2.pdf}
    \caption{HyFi}
  \end{subfigure}
  \caption{Example of tranditional hypergraph contrastive learning vs. HyFi. In (a), contrastive learning only learns postive or negative pairs between graphs augmented by randomly dropping hyperedges or nodes. In (b), HyFi preserves the topology of the hypergraph by adding noise to the node features, while adding weak postive pair relationships for fine-grained contrastive learning.}
  \label{fig1}
\end{figure}


\begin{figure}[t!]
  \centering
  \begin{subfigure}[b]{0.47\columnwidth}
    \includegraphics[width=\linewidth]{FIG/fig2.co-citeation.pdf}
    \caption{Co-citation}
  \end{subfigure}
  \hspace{5pt} % Adjust the space as needed
  \begin{subfigure}[b]{0.47\columnwidth}
    \includegraphics[width=\linewidth]{FIG/fig2.co-authorship.pdf}
    \caption{Co-authorship}
  \end{subfigure}
  \begin{subfigure}[b]{0.47\columnwidth}
    \includegraphics[width=\linewidth]{FIG/fig2.Visiongraphics.pdf}
    \caption{Computer Vision and Graphics}
  \end{subfigure}
  \hspace{5pt} % Adjust the space as needed
  \begin{subfigure}[b]{0.47\columnwidth}
    \includegraphics[width=\linewidth]{FIG/fig2.MachineLearning.pdf}
    \caption{Machine Learning Repository}
  \end{subfigure}
  \caption{The average of the cosine similarity of the node features over the number of commonalities between two nodes, where commonality, defined as a common group, means common hyperedges. The higher the number of common hyperedges, the higher the similarity of the two node features.}
  \label{fig2}
\end{figure}

Despite its potential, research on hypergraph-based learning has been relatively sparse, with even fewer studies exploring contrastive learning, although the possibility of using a hypergraph has recently gained momentum. The complex structure of hypergraphs, which includes nodes and hyperedges, differs significantly from traditional homogeneous graphs, requiring new approaches tailored specifically to hypergraphs for effective learning. Traditional hypergraph contrastive learning (HGCL) relies on contrastive learning between graphs augmented with random variations in nodes or hyperedges. Consequently, it depends heavily on the embedding of the augmented opposite view. In contrast, we propose \textbf{Hy}pergraph \textbf{Fi}ne-Grained contrastive learning (HyFi), a novel method that identifies and contrastively learns new positive pairs within the original view without perturbing the topology of the original graph. Furthermore, our model does not rely on the quality of the augmented view, as it generates positive pairs by simply adding some noise to the node features. Fig. \ref{fig1} illustrates the difference between trainditional HGCL and HyFi.

% 하이퍼그래프의 잠재력에도 불구하고 하이퍼그래프 기반 학습에 대한 연구는 상대적으로 드물었으며, 대조 학습을 탐구하는 연구는 더욱 적었지만 최근 들어 하이퍼그래프 사용의 가능성에 탄력이 붙고 있습니다. 노드와 하이퍼엣지를 포함하는 하이퍼그래프의 복잡한 구조는 기존의 동질 그래프와 크게 다르기 때문에 효과적인 학습을 위해서는 하이퍼그래프에 특화된 새로운 접근 방식이 필요합니다. 기존의 하이퍼그래프 대조 학습은 노드 또는 하이퍼엣지의 무작위 변형으로 보강된 그래프 간의 대조 학습에 의존합니다. 따라서 증강된 반대쪽 보기의 임베딩에 크게 의존합니다. 이와는 대조적으로, 저희는 원본 그래프의 토폴로지를 교란하지 않고 원본 보기 내에서 새로운 양의 쌍을 식별하고 대조적으로 학습하는 새로운 방법인 \textbf{Hy}퍼그래프 \textbf{Fi}네-그레인 대조 학습(HyFi)을 제안합니다. 또한 이 모델은 노드 특징에 약간의 노이즈를 추가하여 양수 쌍을 생성하기 때문에 증강 뷰의 품질에 의존하지 않습니다. Figure 1은 trainditional HGCL과 HyFi의 차이를 보여줍니다.

Traditional graph contrast learning (GCL) typically generates two augmented views of an existing graph and then contrasts them using positive and negative pairs\cite{velivckovic2018deep, peng2020graph, hassani2020contrastive, you2020graph, zhu2020deep}. However, these traditional approaches do not adequately capture the nature of hypergraphs, especially their ability to represent complex group interactions and higher-order correlations represented by commonality. The dichotomous relationship represented by the traditional positive pair and negative pair makes sense for homogeneous graphs with one relation, but cannot capture the higher-order correlations present in hypergraphs with many different relations. Furthermore, efficient contrastive learning is sensitive to the augmentation of the graph, which mostly relies on the randomness of the graph, which can lead to loss of important information in the graph.

% 기존의 그래프 대비 학습(GCL)은 일반적으로 기존 그래프의 증강된 두 가지 보기를 생성한 다음 양수 및 음수 쌍을 사용하여 대조합니다. 하지만 이러한 전통적인 접근 방식은 하이퍼그래프의 특성, 특히 복잡한 그룹 상호작용과 공통성으로 대표되는 고차적 상관관계를 표현하는 능력을 적절히 포착하지 못합니다. 기존의 포지티브 쌍과 네거티브 쌍으로 표현되는 이분법적 관계는 하나의 관계를 가진 동질적인 그래프에는 적합하지만, 다양한 관계를 가진 하이퍼그래프에 존재하는 고차 상관관계를 포착할 수 없습니다. 그 뿐만아니라 효율적인 대조학습이 이루어지기 위해서는 graph의 증강 방식에 민감하게 영향을 받을 수 밖에 없지만 대부분 graph의 random성에 의존하기 때문에 그래프의 중요정보가 손실될 수 있습니다.

Therefore, we propose a new relation, called a weak positive pair, which shows how group sharing can be exploited in contrastive learning. We show that a weak positive pair is a relationship between nodes that share the same group relative to an anchor node, and that we see significant performance gains just by introducing weak positive pairs. Moreover, weak positive pairs can be found within the original view, so there is little dependence on augmenting the graph. These new relationships are based on the idea that we can define ourselves by the people around us who are in the same group as us. In reality, we are strongly influenced by the people around us and relate to similar people.

% 따라서 저희는 그룹 공유가 대조 학습에서 어떻게 활용될 수 있는지 보여주는 약한 포지티브 쌍이라는 새로운 관계를 제안합니다. 약한 포지티브 쌍은 앵커 노드를 기준으로 동일한 그룹을 공유하는 노드 간의 관계이며, 약한 포지티브 쌍을 도입하는 것만으로도 상당한 성능 향상을 볼 수 있다는 것을 보여줍니다. 이러한 새로운 관계는 우리와 같은 그룹에 속한 주변 사람들에 의해 우리 자신을 정의할 수 있다는 생각에 기반합니다. 실제로 우리는 주변 사람들의 영향을 많이 받고 비슷한 사람들과 관계를 맺습니다.

Furthermore, our approach to augmenting the graph by adding noise to the node features to generate positive samples differs from typical graph augmentation techniques that corrupt the original topology and increase model complexity through random modifications. However, we show that this approach is still sufficient to generate positive samples and is an efficient graph augmentation technique. Therefore, we propose a new form of HGCL method that emphasizes the importance of shared hyperedges and shared nodes while maintaining the structural integrity of the hypergraph. Properly exploiting this commonality is very important in HGCL because hypergraphs are well suited to represent these different relationships through hyperedges.

% 또한, 노드 특징에 노이즈를 추가하여 긍정적인 샘플을 생성함으로써 그래프를 증강하는 우리의 접근 방식은 무작위 수정을 통해 원래 토폴로지를 손상시키고 모델 복잡성을 증가시키는 일반적인 그래프 증강 기법과는 다릅니다. 그러나 이 접근 방식이 여전히 양성 샘플을 생성하기에 충분하며 효율적인 그래프 증강 기법이라는 것을 보여줍니다. 따라서 우리는 하이퍼그래프의 구조적 무결성을 유지하면서 공유 하이퍼엣지와 공유 노드의 중요성을 강조하는 새로운 형태의 하이퍼그래프 대조 학습 방법을 제안합니다. 하이퍼그래프는 하이퍼엣지를 통해 이러한 다양한 관계를 표현하는 데 적합하기 때문에 이러한 공통점을 적절히 활용하는 것은 하이퍼그래프 대조 학습에서 매우 중요합니다.


Distinguishing these types of relationships allows us to capture complex intricacies more accurately. This approach is based on the assumption that the more two nodes share a common group, the more similar they are. In other words, we define higher-order correlations in a hypergraph as “commonality,” which is the property of sharing a common group between two nodes. Our assumption is confirmed in Figure \ref{fig2}, where we see that the cosine similarity of two node features increases as the number of hyperedges shared by the two nodes increases. For example, two people belonging to the same group could mean that they have the same disposition, or they could belong to the same group and have similar dispositions. Therefore, the assumption of common group membership is important to exploit the high-dimensional correlations in the hypergraph. Also, the model implements group unit contrastive learning to efficiently learn homophily trends within the hypergraph. In previous HGCL, contrastive learning is based on nodes; however, we use group-based contrastive learning. Thus, nodes that belong to the same group are able to contrasted multiple times. 

% 이러한 유형의 관계를 구분하면 복잡한 복잡성을 보다 정확하게 파악할 수 있습니다. 이 접근 방식은 두 노드가 공통 그룹을 더 많이 공유할수록 더 유사하다는 가정을 기반으로 합니다. 즉 우리는 하이퍼그래프에서 고차 상관관계를 두 노드 간에 공통 그룹을 공유하는 속성인 '공통성'으로 정의합니다. 그림 \ref{그림2}에서 두 노드가 공유하는 하이퍼엣지의 수가 증가함에 따라 두 노드 특징의 코사인 유사성이 증가하는 것을 볼 수 있습니다. 예를 들어, 두 사람이 같은 그룹에 속한다는 것은 같은 성향을 가지고 있다는 의미일 수도 있고, 같은 그룹에 속해 있으면서 비슷한 성향을 가지고 있다는 의미일 수도 있습니다. 따라서 하이퍼그래프에서 고차원적 상관관계를 활용하기 위해서는 공통 그룹 소속이라는 가정이 중요합니다. 또한 이 모델은 하이퍼그래프 내에서 동질성 경향을 효율적으로 학습하기 위해 그룹 단위의 대조 학습을 구현합니다. 기존 HGCL에서는 노드를 기반으로 대조 학습을 수행했지만, 우리는 그룹 기반 대조 학습을 사용합니다. 따라서 같은 그룹에 속하는 노드는 여러 번 대조됩니다.


Our proposed HyFi method enhances the classification of weak positive relations in shared group connections between nodes in a hypergraph. This approach generates higher quality embeddings than those produced by traditional hypergraph contrastive learning (HGCL) models. As a result, HyFi outperformed 10 supervised and 6 unsupervised baselines in node classification tasks across 10 datasets. It also outperformed both types of baselines in 10 separate node classification tasks. Furthermore, because HyFi does not modify the topology of the graph, it is widely applicable to a variety of datasets and is more efficient in terms of both time and memory usage compared to traditional HGCL models.
% 저희가 제안한 HyFi 방법은 하이퍼그래프에서 노드 간의 공유 그룹 관계에 대한 약한 포지티브 분류를 개선합니다. 이 접근 방식은 기존의 하이퍼그래프 대조 학습 모델에 비해 더 높은 품질의 임베딩을 생성합니다. 결과적으로 HyFi는 10개의 데이터 세트에서 노드 분류 작업에서 10개의 감독 기준선과 6개의 비감독 기준선보다 우수한 성능을 보였습니다. 또한, 10개의 개별 노드 분류 작업에서 지도 및 비지도 기준선을 모두 능가했습니다. 또한 HyFi는 그래프의 토폴로지를 변경하지 않기 때문에 다양한 데이터 세트에 광범위하게 적용할 수 있으며 기존의 하이퍼그래프 대조 학습 모델보다 시간 및 메모리 사용 측면에서 더 효율적입니다.

The main contributions of this paper are highlighted as follows:
\begin{itemize}
    \item We propose a novel  contrastive learning method, called HyFi. The method exploits the higher-order correlations in hypergraphs represented by commonality to achieve efficient contrast learning that is less dependent on graph augmentation than existing methods.
    \item We introduce a new relation called weak positive pair, which shows that setting the positive sample to be fine-grained is key to contrastive learning.
    \item We propose an augmentation scheme that adds noise to the node features in a way that does not preserve the topology of the hypergraph, and show that it is sufficient to generate positive samples that are comparable to various forms of augmentation.
\end{itemize}

% 저희는 HyFi라는 새로운 대조 학습 방법을 제안합니다. 이 방법은 공통성으로 표현되는 하이퍼그래프의 고차 상관관계를 활용하여 기존 방법에 비해 graph 증강에 덜 의존적이며 효율적인 대조학습이 가능합니다.
% 약한 포지티브 쌍이라는 새로운 관계를 소개하며, 포지티브 샘플을 세밀하게 설정하는 것이 대조 학습의 핵심임을 보여줍니다.
% 하이퍼그래프의 토폴로지를 보존하지 않는 방식으로 노드 특징에 노이즈를 추가하는 증강 방식을 제안하고 다양한 형태의 증강과 비교할 수 있는 포스티브 샘플을 생성하는 데 충분하다는 것을 보여줍니다.






