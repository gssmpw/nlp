% This section describes how we conduct our experiments to evaluate the performance of HyFi. We investigate the following research questions:
In this section, we conduct experiments to evaluate HyFi through answering the following research questions.
\begin{itemize}
    \item \textbf{RQ1 (Generalizability)}: How does HyFi outperform baselines on node classification tasks?
    \item \textbf{RQ2 (Efficiency)}: How efficient is HyFi regarding GPU memory usage and training time?
    \item \textbf{RQ3 (Ablation Study)}: How do the newly introduced modules in HyFi affect its overall performance?
    \item \textbf{RQ4 (Type of Augmentation)}: How do different augmentation methods affect performance?
    \item \textbf{RQ5 (Effect of Positive sample)}: How does the number of positive samples affect hypergraph contrastive learning?
\end{itemize}

\begin{table}[t!]
\centering
\caption{Statistics for datasets.}
\begin{tabular}{lccc}
\hline
Dataset & \# Nodes & \# Hyperedges & \# Classes \\
\hline \hline
Cora-C & 1,434 & 1,579 & 7 \\
Citeseer & 1,458 & 1,079 & 6 \\
Pubmed & 3,840 & 7,963 & 3 \\
Cora-A & 2,388 & 1,072 & 7 \\
DBLP & 41,302 & 22,363 & 6 \\
Zoo & 101 & 43 & 7 \\
20News & 16,242 & 100 & 4 \\
Mushroom & 8,124 & 298 & 2 \\
NTU2012 & 2,012 & 2,012 & 67 \\
ModelNet40 & 12,311 & 12,311 & 40 \\
\hline
\end{tabular}
\label{tab:dataset}
\end{table}

\subsection{Experimental Setup}


\subsubsection{Datasets}

To compare the performance of HyFi, we use a total of 10 datasets that can be categorized into: (1) citation network datasets (Cora-C, Citeseer, and Pubmed \cite{sen2008collective}), (2) co-authorship network datasets (Cora-A and DBLP \cite{rossi2015network}), (3) computer vision and graphics datasets (NTU2012 \cite{chen2003visual} and ModelNet40 \cite{wu20153d}), and (4) datasets from the UCI Categorical Machine Learning Repository (Zoo, 20Newsgroups, and Mushroom \cite{asuncion2007ucireferences}). The statistics of these datasets are provided in Table \ref{tab:dataset}.

\subsubsection{Hyperparameter Setting}
For all datasets, we used AdamW as the optimizer\cite{loshchilov2018decoupled}. To perturb the node features, we use random noise from a Gaussian distribution with mean zero and standard deviation $\sigma^2$ as a hyperparameter. The number of positive samples equals the number of noise views, which is also a hyperparameter.


\begin{table*}[t!]
\centering
\caption{Comparison of node classification accuracy. The highest scores in each dataset are highlighted in bold, indicating the best performance by method, while the second highest scores are underlined. The `A.R.' indicates the average rank across all datasets. `-' indicates that the results are not available in published papers.}
\resizebox{\textwidth}{!}{
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{lcccccccccccc}
\hline
& Method & {Cora-C} & {Citeseer} & {Pubmed} & {Cora-A} & {DBLP} & {Zoo} & {20News} & {Mushroom} & {NTU2012} & {ModelNet40} & {A.R.$\downarrow$}\\
\hline
\hline
\multirow{10}{*}{\rotatebox[origin=c]{90}{Supervised}}
& MLP & 60.32\textpm1.5 & 62.06\textpm2.3 & 76.27\textpm1.1 & 64.05\textpm1.4 & 81.18\textpm0.2 & 75.62\textpm9.5 & 79.19\textpm0.5 & 99.58\textpm0.3 & 65.17\textpm2.3 & 93.75\textpm0.6 & 11.4 \\ 
& GCN & 77.11\textpm1.8 & 66.07\textpm2.4 & 82.63\textpm0.6 & 73.66\textpm1.3 & 87.58\textpm0.2 & 36.79\textpm9.6 & - & 92.47\textpm0.9 & 71.17\textpm2.4 & 91.67\textpm0.2 & 10.7 \\ 
& GAT & 77.75\textpm2.1 & 67.62\textpm2.5 & 81.96\textpm0.7 & 74.52\textpm1.3 & 88.59\textpm0.1 & 36.48\textpm10.0 & - & - & 70.94\textpm2.6 & 91.43\textpm0.3 & 10.0 \\ 
& HGNN & 77.50\textpm1.8 & 66.16\textpm2.3 & 83.52\textpm0.7 & 74.38\textpm1.2 & 88.32\textpm0.3 & 78.58\textpm11.1 & \underline{80.15\textpm0.3} & 98.59\textpm0.5 & 72.03\textpm2.4 & 92.23\textpm0.2 & 7.1 \\
& HyperConv & 76.19\textpm2.1 & 64.12\textpm2.6 & 83.42\textpm0.6 & 73.52\textpm1.0 & 88.83\textpm0.2 & 62.53\textpm14.5 & 79.83\textpm0.4 & 97.56\textpm0.6 & 72.62\textpm2.6 & 91.84\textpm0.1 & 8.7 \\
& HNHN & 76.21\textpm1.7 & 67.28\textpm2.2 & 80.97\textpm0.9 & 74.88\textpm1.6 & 86.71\textpm1.2 & 78.89\textpm10.2 & 79.51\textpm0.4 & \underline{99.78\textpm0.1} & 71.45\textpm3.2 & 92.96\textpm0.2 & 7.9 \\
& HyperGCN & 64.11\textpm7.4 & 59.92\textpm9.6 & 78.40\textpm9.2 & 60.65\textpm9.2 & 76.59\textpm7.6 & 40.86\textpm2.1 & 77.31\textpm6.0 & 48.26\textpm0.3 & 46.05\textpm3.9 & 69.23\textpm2.8 & 14.1 \\
& HyperSAGE & 64.98\textpm5.3 & 52.43\textpm9.4 & 79.49\textpm8.7 & 64.59\textpm4.3 & 79.63\textpm8.6 & 40.86\textpm2.1 & - & - & - & - & 13.7 \\
& UniGCN & 77.91\textpm1.9 & 66.40\textpm1.9 & \textbf{84.08\textpm0.7} & 77.30\textpm1.4 & 90.31\textpm0.2 & 72.10\textpm12.1 & \textbf{80.24\textpm0.4} & 98.84\textpm0.5 & 73.27\textpm2.7 & 94.62\textpm0.2 & 5.0 \\
& AllSet & 76.21\textpm1.7 & 67.83\textpm1.8 & 82.85\textpm0.9 & 76.94\textpm1.3 & 90.07\textpm0.3 & 72.72\textpm11.8 & 79.90\textpm0.4 & \underline{99.78\textpm0.1} & \underline{75.09\textpm2.5} & 96.85\textpm0.2 & 5.0\\
\hline
\multirow{7}{*}{\rotatebox[origin=c]{90}{Unsupervised}}
& Random-Init & 63.62\textpm3.1 & 60.44\textpm2.5 & 67.49\textpm2.2 & 66.27\textpm2.2 & 76.57\textpm0.6 & 78.43\textpm11.0 & 77.14\textpm0.6 & 97.40\textpm0.6 & 74.39\textpm2.6 & 96.29\textpm0.3 & 10.9 \\
& Node2vec & 70.99\textpm1.4 & 53.85\textpm1.9 & 78.75\textpm0.9 & 58.50\textpm2.1 & 72.09\textpm0.3 & 17.02\textpm4.1 & 63.35\textpm1.7 & 88.16\textpm0.8 & 67.72\textpm2.1 & 84.94\textpm0.4 & 14.6 \\
& DGI & 78.17\textpm1.4 & 68.81\textpm1.8 & 80.83\textpm0.6 & 76.94\textpm1.1 & 88.00\textpm0.2 & 36.54\textpm9.7 & - & - & 72.01\textpm2.5 & 92.18\textpm0.2 & 8.2\\
& GRACE & 79.11\textpm1.7 & 68.65\textpm1.7 & 80.08\textpm0.7 & 76.59\textpm1.0 & - & 37.07\textpm9.3 & - & - & 70.51\textpm2.4 & 90.68\textpm0.3 & 9.4 \\
& S\textsuperscript{2}-HHGR & 78.08\textpm1.7 & 68.21\textpm1.8 & 82.13\textpm0.6 & 78.15\textpm1.1 & 88.69\textpm0.2 & \textbf{80.06\textpm11.1} & 79.75\textpm0.3 & 97.15\textpm0.5 & 73.95\textpm2.4 & 93.26\textpm0.2 & 5.7\\
& TriCL & \underline{81.03\textpm1.3} & \underline{71.97\textpm1.3} & 83.80\textpm0.6 & \textbf{82.22\textpm1.1} & \textbf{90.93\textpm0.2} & 79.47\textpm11.0 & 79.93\textpm0.2 & 98.93\textpm0.3 & 74.63\textpm2.5 & \underline{97.33\textpm0.1} & \underline{2.5} \\
& \textbf{HyFi} & \textbf{81.48\textpm1.5} & \textbf{72.57\textpm1.1} & \underline{83.82\textpm0.6} & \underline{79.33\textpm1.2} & \underline{90.41\textpm0.2} & \underline{80.02\textpm10.9} & 79.76\textpm0.3 & \textbf{99.79\textpm0.2} & \textbf{75.10\textpm2.6} & \textbf{97.38\textpm0.1} & \textbf{1.9} \\
\hline
\end{tabular}}
\label{table:node_classification}
\end{table*}


\subsubsection{Compared baselines}

HyFi was compared against 10 (semi-)supervised models and 5 unsupervised models. Given that graph-based methods are not directly applicable to hypergraphs, hypergraphs were transformed into graphs through clique expansion before applying these methods. We focused particularly on comparisons with the state-of-the-art model in HGCL, which is TriCL. To ensure a fair comparison, we assume the use of the same encoder (HGNN) architecture. For the baselines other than TriCL, results from their respective references are cited. 

% TriCL is an HGCL that uses a tri-directional contrast approach and performs contrast learning at the node, group, and membership levels. Although TriCL achieves reasonable performance, it is inefficient in terms of GPU memory usage and training time due to its complex tri-directional contrastive learning approach. Moreover, It uses a combination of random node feature masking \cite{you2020graph, zhu2020deep} and membership masking to augment the hypergraph in terms of attributes and structure, which has the disadvantage of deforming the topology of the hypergraph. In contrast, HyFi focuses on two-way contrastive learning at the node-level and edge-level, without heavily relying on hypergraph augmentation. This approach not only demonstrates good performance but also offers high efficiency. To ensure a fair comparison, we assume the use of the same encoder (HGNN) architecture. For the baselines other than TriCL, results from their respective references are cited.

\subsubsection{Evaluation protocol}
For the node classification task, we follow the standard linear evaluation protocol introduced in \cite{velivckovic2018deep}. First, an encoder is trained in a fully unsupervised manner to generate node representations. A simple linear classifier is then trained on top of these fixed representations without backpropagation the gradient through the encoder. For all datasets, nodes are randomly assigned to the training, validation, and test sets in proportions of 10\%, 10\%, and 80\%, respectively, following the approach in \cite{zhu2020deep} and \cite{thakoorlarge}. In the unsupervised setting, we evaluated the model using 20 dataset splits with 5 random weight initializations and reported the average accuracy for each dataset. In the supervised setting, 20 dataset splits were used, each with a different model initialization, and the average accuracy was reported. The experiment was repeated a total of five times, and the average results are reported here.


\subsection{Generalizability (RQ1)}

To evaluate the overall performance of HyFi, we performed comparative node classification experiments using different baseline models. As shown in the results in Table \ref{table:node_classification}, the HyFi model performed well on the node classification task in both supervised and unsupervised models. HyFi consistently ranked among the top performers on a variety of datasets and had the highest average ranking. Notably, it outperformed TriCL on average ranking, which is encouraging because HyFi outperforms TriCL while still using resources efficiently. These results highlight the importance of considering commonality, which is high-dimensional information in hypergraphs, and suggest that weak positive pair relationships are efficient for contrast learning. HyFi also has the advantage of being applicable to a wide variety of graphs because it relies little on graph augmentation. In fact, it ranks in the top 2 on almost all of the 9 datasets except 20News, and even on 20News, the performance gap to the top is very small.

% HyFi의 전반적인 성능을 평가하기 위해 다양한 기준 모델을 사용해 비교 노드 분류 실험을 수행했습니다. 표 \ref{table:node_classification}의 결과에서 볼 수 있듯이 HyFi 모델은 감독 환경과 비감독 환경 모두에서 노드 분류 작업에서 우수한 성능을 보였습니다. HyFi는 다양한 데이터 세트에서 일관되게 상위권에 랭크되었으며 평균 순위도 가장 높았습니다. 특히 평균 순위에서 TriCL을 앞섰는데, 이는 HyFi가 리소스를 효율적으로 사용하면서도 TriCL보다 성능이 뛰어나다는 점에서 고무적인 결과입니다. 이러한 결과는 하이퍼그래프에서 고차원 정보인 공통성을 고려하는 것이 중요하다는 것을 강조하며, 약한 양의 쌍 관계가 대비 학습에 효율적이라는 것을 시사합니다. HyFi는 그래프 증강에 거의 의존하지 않기 때문에 다양한 그래프에 적용할 수 있다는 장점도 있습니다. 실제로 20News를 제외한 거의 모든 9개 데이터 세트에서 상위 2위에 올랐으며, 20News에서도 상위권과의 성능 격차가 매우 작습니다.


\begin{table}[t!]
\centering
\caption{Comparisons of training time.}
\label{tab:speed}
\begin{tabular}{lcc}
\hline
Dataset & TriCL & HyFi \\
\hline
\hline
Cora-C & 21.79 s ($\times$1.71) & 12.71 s ($\times$1.00)\\
Citeseer & 58.91 s ($\times$3.17) & 18.60 s ($\times$1.00)\\
Pubmed & 350.68 s ($\times$5.07) & 69.22 s ($\times$1.00)\\
Cora-A & 33.82 s ($\times$1.40) & 24.21 s ($\times$1.00)\\
DBLP & 1145.62 s ($\times$2.38) & 481.86 s ($\times$1.00)\\
Zoo & 5.11 s ($\times$2.61) & 1.96 s ($\times$1.00)\\
20News & 286.86 s ($\times$5.68) & 50.47 s ($\times$1.00)\\
Mushroom & 251.69 s ($\times$7.95) & 31.67 s ($\times$1.00)\\
NTU2012 & 44.08 s ($\times$4.98) & 8.86 s ($\times$1.00)\\
ModelNet & 213.52 s ($\times$3.29) & 65.04 s ($\times$1.00)\\
\hline
\end{tabular}
\end{table}

\subsection{Efficiency (RQ2)}

To demonstrate the efficiency of the HyFi model, we conducted an experiment to compare it with another HGCL model, TriCL, in terms of training time and memory cost. To ensure a fair and consistent comparison, we set the hyperparameters between the two models as similar as possible. We experimented on the RTX A6000 (48GB GPU), and only employed batch processing in for the DBLP datasets, as not using batch processing would result in out-of-memory error.

% HyFi 모델의 효율성을 입증하기 위해 다른 HGCL 모델인 TriCL과 훈련 시간과 메모리 비용 측면에서 비교하는 실험을 진행했습니다. 공정하고 일관된 비교를 위해 두 모델 간의 하이퍼파라미터를 가능한 한 유사하게 설정했습니다. 일괄 처리를 사용하지 않으면 메모리 부족 오류가 발생할 수 있으므로 RTX A6000(48GB GPU)에서 실험했으며, DBLP 데이터 세트에 대해서만 일괄 처리 기능을 사용했습니다.

\begin{figure*}[thbp!]
  \centering
  \begin{subfigure}[b]{0.2\textwidth}
    \includegraphics[width=\textwidth]{FIG/legend.pdf}
  \end{subfigure}
  \\
  \begin{subfigure}[b]{0.19\textwidth}
    \includegraphics[width=\textwidth]{FIG/memory_fig/Cora-C_memory.pdf}
    \caption{Cora-C}
  \end{subfigure}
  % \hfill
  \begin{subfigure}[b]{0.19\textwidth}
    \includegraphics[width=\textwidth]{FIG/memory_fig/Citeseer_memory.pdf}
    \caption{Citeseer}
  \end{subfigure}
  % \hfill
  \begin{subfigure}[b]{0.19\textwidth}
    \includegraphics[width=\textwidth]{FIG/memory_fig/Pubmed_memory.pdf}
    \caption{Pubmed}
  \end{subfigure}
  % \hfill
  \begin{subfigure}[b]{0.19\textwidth}
    \includegraphics[width=\textwidth]{FIG/memory_fig/Cora-A_memory.pdf}
    \caption{Cora-A}
  \end{subfigure}
  % \hfill
  \begin{subfigure}[b]{0.19\textwidth}
    \includegraphics[width=\textwidth]{FIG/memory_fig/DBLP_memory.pdf}
    \caption{DBLP}
  \end{subfigure}
  \begin{subfigure}[b]{0.19\textwidth}
    \includegraphics[width=\textwidth]{FIG/memory_fig/Zoo_memory.pdf}
    \caption{Zoo}
  \end{subfigure}
  % \hfill
  \begin{subfigure}[b]{0.19\textwidth}
    \includegraphics[width=\textwidth]{FIG/memory_fig/20News_memory.pdf}
    \caption{20News}
  \end{subfigure}
  % \hfill
  \begin{subfigure}[b]{0.19\textwidth}
    \includegraphics[width=\textwidth]{FIG/memory_fig/Mushroom_memory.pdf}
    \caption{Mushroom}
  \end{subfigure}
  % \hfill
  \begin{subfigure}[b]{0.19\textwidth}
    \includegraphics[width=\textwidth]{FIG/memory_fig/NTU2012_memory.pdf}
    \caption{NTU2012}
  \end{subfigure}
  % \hfill
  \begin{subfigure}[b]{0.19\textwidth}
    \includegraphics[width=\textwidth]{FIG/memory_fig/ModelNet40_memory.pdf}
    \caption{ModelNet40}
  \end{subfigure}
  \caption{Illustration of the GPU memory usage comparison between HyFi and TriCL, focusing on how they differ in memory consumption in various dimensions, where dimension denotes the encoder output dimension and the project head output dimension, a bar with a diagonal pattern means `Out of Memory'.}
  \label{fig:memory}
\end{figure*}

\begin{table*}[t!]
\centering
\caption{Ablation study exploring various configurations of the contrastive learning framework `w/o' stands for `without'.}
\resizebox{\textwidth}{!}{
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{lccccccccccc}
\hline
 & {Cora-C} & {Citeseer} & {Pubmed} & {Cora-A} & {DBLP} & {Zoo} & {20News} & {Mushroom} & {NTU2012} & {ModelNet40} & {A.R.$\downarrow$} \\ \hline\hline
\textbf{HyFi} & \textbf{81.48\textpm1.5} & \underline{72.57\textpm1.1} & \textbf{83.82\textpm0.6} & \textbf{79.33\textpm1.2} & \underline{90.41\textpm0.2} & \textbf{80.02\textpm10.9} & \textbf{79.76\textpm0.3} & \underline{99.79\textpm0.2} & \textbf{75.10\textpm2.6} & \textbf{97.38\textpm0.1} & \textbf{1.4}\\ 
w/o weak positive pair & 70.89\textpm3.6 & 60.12\textpm3.6 & 79.91\textpm0.9 & 75.75\textpm1.1 & 88.46\textpm0.1 & 79.79\textpm10.9 & 79.69\textpm0.3 & \textbf{99.87\textpm0.1} & 74.88\textpm2.6 & 97.31\textpm0.1 & 4.2\\ 
w/o positive pair & 77.96\textpm1.7 & 71.97\textpm1.1 & 83.59\textpm0.6 & 76.65\textpm1.4 & 87.62\textpm0.6 & \underline{79.94\textpm11.0} & \underline{79.74\textpm0.3} & 99.79\textpm0.1 & 74.91\textpm2.6 & \underline{97.35\textpm0.1} & 3.2\\ 
w/o weak weight & 80.44\textpm1.3 & \textbf{72.61\textpm1.1} & \underline{83.79\textpm0.7} & 78.44\textpm1.1 & \textbf{90.54\textpm0.1} & 79.77\textpm10.9 & \textbf{79.76\textpm0.3} & 99.76\textpm0.2 & 74.52\textpm2.5 & 97.32\textpm0.1 & 2.9\\ 
w/o edge loss & \underline{81.25\textpm1.4} & 72.42\textpm1.2 & 83.77\textpm0.7 & \underline{79.04\textpm1.1} & 90.31\textpm0.2 & 79.79\textpm11.0 & \underline{79.74\textpm0.3} & \underline{99.79\textpm0.2} & \underline{74.94\textpm2.6} & 97.26\textpm0.1 & \underline{2.8}\\ 
\hline
\end{tabular}}
\label{tab:ablation}
\end{table*}

\subsubsection{Training time}


Table \ref{tab:speed} shows the results of training speed comparisons between the HyFi model and the TriCL model across 10 experimental datasets, highlighting HyFi's significant efficiency advantage. HyFi consistently exhibits faster training times compared to TriCL on these datasets. The disparity in training speeds is particularly pronounced in larger datasets such as PubMed and DBLP. HyFi completes training in just 69.22 seconds and 481.86 seconds for these datasets, respectively, significantly faster than TriCL, which takes 350.68 seconds and 1145.62 seconds. Such results underscore the efficiency of HyFi, especially in scenarios where rapid model training is essential. The consistent speed advantage across various datasets highlights the optimized nature of the HyFi model.




\subsubsection{Memory cost}

As shown in Figure \ref{fig:memory}, the HyFi model shows significant improvements in GPU memory efficiency compared to the TriCL model across the data sets, without exception. Unlike TriCL, which shows a steep increase in memory consumption at larger dimensions, HyFi maintains a relatively moderate growth in GPU memory consumption. This difference becomes more pronounced at larger dimensions, where TriCL experiences a sensitive increase in memory consumption, leading to out-of-memory problems on datasets such as DBLP, Mushroom, NTU2012 and ModelNet40. HyFi, on the other hand, never runs out of memory on any dataset.

The high efficiency of HyFi is due to two main factors: the strategy of avoiding augmentation in the hypergraph topology and the simplification of the contrastive learning process from three losses in TriCL to only two in HyFi (no need for membership-level loss). As a result, the significant difference in memory consumption between HyFi and TriCL demonstrates the strength of HyFi in handling large datasets or data with high dimensionality of node features.




\begin{table*}[t!]
\centering
\caption{Performance of different augmentation method on various datasets.}
\resizebox{\textwidth}{!}{
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{ccccccccccccc}
\hline
Augmentation Type & Method & {Cora-C} & {Citeseer} & {Pubmed} & {Cora-A} & {DBLP} & {Zoo} & {20News} & {Mushroom} & {NTU2012} & {ModelNet40} & {A.R.$\downarrow$}\\ \hline \hline
\multirow{3}{*}{Add Noise} & Gaussian Noise & \textbf{81.48\textpm1.5} & \textbf{72.57\textpm1.1} & \underline{83.82\textpm0.6} & \textbf{79.33\textpm1.2} & \textbf{90.41\textpm0.2} & \textbf{80.02\textpm10.9} & \textbf{79.76\textpm0.3} & 99.79\textpm0.2 & \textbf{75.10\textpm2.6} & \textbf{97.38\textpm0.1} & \textbf{1.4}\\ 
 & Uniform Noise & \underline{81.40\textpm1.2} & \underline{72.51\textpm1.1} & \textbf{84.03\textpm0.7} & \underline{77.61\textpm1.2} & \underline{90.37\textpm0.2} & 79.65\textpm10.8 & \textbf{79.76\textpm0.3} & 99.79\textpm0.1 & 74.52\textpm2.5 & 97.32\textpm0.1 & \underline{2.9}\\ 
 & Bernoulli Noise & 76.78\textpm1.5 & 71.17\textpm1.3 & 82.54\textpm0.7 & 76.78\textpm1.2 & 90.01\textpm0.2 & 79.60\textpm10.8 & \textbf{79.76\textpm0.3} & 99.78\textpm0.1 & 74.40\textpm2.5 & 97.29\textpm0.1 & 5.2\\ \hline
\multirow{3}{*}{Drop}  & Incidence & 78.81\textpm1.5 & 72.22\textpm1.2 & 83.59\textpm0.6 & 77.54\textpm1.3 & 89.12\textpm0.4 & 79.91\textpm10.9 & 79.73\textpm0.3 & \underline{99.82\textpm0.1} & 75.05\textpm2.6 & \underline{97.37\textpm0.1} & 3.5\\ 
 & Node & 78.89\textpm1.5 & 72.25\textpm1.2 & 83.58\textpm0.6 & 77.57\textpm1.3 & 89.05\textpm0.4 & 79.90\textpm10.9 & 79.73\textpm0.3 & \underline{99.82\textpm0.1} & \underline{75.08\textpm2.6} & \textbf{97.38\textpm0.1} & 3.1\\ 
 & Hyperedge & 78.71\textpm1.5 & 72.25\textpm1.1 & 83.58\textpm0.6 & 77.30\textpm1.4 & 88.86\textpm0.4 & \underline{79.98\textpm11.0} & 79.73\textpm0.3 & \textbf{99.83\textpm0.1} & 75.04\textpm2.6 & \underline{97.37\textpm0.1} & 3.7\\ \hline
\end{tabular}}
\label{tab:augmentation_results}
\end{table*}

\begin{figure*}[thbp!]
  \centering
  \begin{subfigure}[b]{0.19\textwidth}
    \includegraphics[width=\textwidth]{FIG/num_pos_fig/Cora-C_noise_view.pdf}
    \caption{Cora-C}
  \end{subfigure}
  % \hfill
  \begin{subfigure}[b]{0.19\textwidth}
    \includegraphics[width=\textwidth]{FIG/num_pos_fig/Citeseer_noise_view.pdf}
    \caption{Citeseer}
  \end{subfigure}
  % \\ 
  % \vspace{10pt}
  \begin{subfigure}[b]{0.19\textwidth}
    \includegraphics[width=\textwidth]{FIG/num_pos_fig/Pubmed_noise_view.pdf}
    \caption{Pubmed}
  \end{subfigure}
  % \hfill
  \begin{subfigure}[b]{0.19\textwidth}
    \includegraphics[width=\textwidth]{FIG/num_pos_fig/Cora-A_noise_view.pdf}
    \caption{Cora-A}
  \end{subfigure}
  % \\ 
  % \vspace{10pt}
  \begin{subfigure}[b]{0.19\textwidth}
    \includegraphics[width=\textwidth]{FIG/num_pos_fig/DBLP_noise_view.pdf}
    \caption{DBLP}
  \end{subfigure}
  % \hfill
  \begin{subfigure}[b]{0.19\textwidth}
    \includegraphics[width=\textwidth]{FIG/num_pos_fig/Zoo_noise_view.pdf}
    \caption{Zoo}
  \end{subfigure}
  % \\ 
  % \vspace{10pt}
  \begin{subfigure}[b]{0.19\textwidth}
    \includegraphics[width=\textwidth]{FIG/num_pos_fig/20News_noise_view.pdf}
    \caption{20News}
  \end{subfigure}
  % \hfill
  \begin{subfigure}[b]{0.19\textwidth}
    \includegraphics[width=\textwidth]{FIG/num_pos_fig/Mushroom_noise_view.pdf}
    \caption{Mushroom}
  \end{subfigure}
  % \\ 
  % \vspace{10pt}
  \begin{subfigure}[b]{0.19\textwidth}
    \includegraphics[width=\textwidth]{FIG/num_pos_fig/NTU2012_noise_view.pdf}
    \caption{NTU2012}
  \end{subfigure}
  % \hfill
  \begin{subfigure}[b]{0.19\textwidth}
    \includegraphics[width=\textwidth]{FIG/num_pos_fig/ModelNet40_noise_view.pdf}
    \caption{ModelNet40}
  \end{subfigure}
  \caption{Illustration of the performance of node classification as the number of positive samples. The number of noise views is equal to the number of positive samples in the contrastive learning.}
  \label{fig:num_pos}
\end{figure*}


\subsection{Ablation Study (RQ3)} 

The ablation study, detailed in Table \ref{tab:ablation}, evaluates the efficacy of various components on the performance of the HyFi. The study considers four different configurations: a model that does not use weak positive pairs (only positive and negative pairs), a model that does not use positive pairs (only weak positive and negative pairs), a model that does not utilize weights for weak positive pairs, and a model with no edge-level loss.

The results for the model that does not use weak positive pairs show a significant decrease in performance, which is more pronounced than the decrease observed in the model without positive pairs. Except for a few datasets, the performance of the model using only weak positive pairs is almost as good as when using both positive and weak positive pairs. These results demonstrate that the commonality of sharing the same group can be very important in hypergraph contrastive learning. We also observe a slight performance drop when weights for weak positive pairs are not used or when edge-level loss is not utilized. The results indicate that weighted contributions further enhance the model's efficiency. Additionally, we observe that edge-level loss also helps to improve the model's performance.


\subsection{Types of Augmentation (RQ4)}

% We experimented with different augmentation methods to determine the suitability of adding Gaussian noise to node features to generate a positive sample. We experimented various types of noise. Bernoulli noise perturbs the node features at values of 0 and 1, significantly disturbing these values. We also compared our method with common graph augmentation techniques, such as drop augmentation, which involve removing the incidence, node, or hyperedge, thereby modifying the topology of the hypergraph. We  used a drop rate of 20\%.

% Among all graph augmentation methods, adding Gaussian noise achieved the best average ranking. It outperformed both uniform and Bernoulli noise, demonstrating its superiority in adding the right amount of subtle noise compared to Bernoulli noise, which often causes large variations in node features.

% Additionally, methods that modify the topology of the graph performed poorly in terms of average rank. This suggests that graph augmentation methods that change the topology are less effective in generating positive samples. Since the topology of the graph is highly dependent on randomness, there is a risk of losing important information. However, HyFi does not deform the topology of the graph, thus preserving structural integrity. This not only makes HyFi very robust but also highly efficient for graph augmentation.

We experimented with different augmentation methods to determine the suitability of adding Gaussian noise to node features to generate a positive sample. We experimented with various types of noise (Gaussian, Uniform, Bernoulli). Bernoulli noise perturbs the node feature at values of 0 and 1, which perturbs the node feature significantly compared to Gaussian noise and uniform noise. We also compared our method with common graph augmentation techniques, such as drop augmentation, which involve removing the incidence, node, or hyperedge, thereby modifying the topology of the hypergraph. We used a drop rate of 20\%.

Among all graph augmentation methods, adding Gaussian noise achieved the best average ranking. However, since graph augmentation in HyFi is basically aimed at creating positive pairs, adding some noise to the node features is enough to create positive pairs. However, methods that modify the topology of the graph performed poorly in terms of average ranking, suggesting that graph augmentation methods that change the topology are less effective at generating positive samples. Furthermore, the topology of the graph relies heavily on randomness, suggesting the possibility of losing important information. For example, the dropping of a community called family will result in a significant loss of information for some nodes. As such, HyFi's graph augmentation method has the advantage of being able to be used on a variety of graphs without worrying about information loss due to variations in the topology of the graph. Therefore, HyFi, which does not disturb the topology of the graph, can be utilized on a variety of graphs and in a variety of downstream tasks. 


\subsection{Effect of Positive sample (RQ5)}


Figure \ref{fig:num_pos} shows how performance varies with the number of positive samples. In HyFi, we use 2 positive samples: the number of positive samples is equal to the number of noise views, and the number of positive samples is considered a hyperparameter. We found that the number of positive samples has little effect on the overall performance. We observed less than a 1\% difference in performance for most datasets, and it was difficult to find a correlation between the number of positive samples and performance. This indicates that HyFi's performance is not driven by the relationship of weak positive pairs, and that the relationship of positive pairs is not critical to HyFi's performance.
