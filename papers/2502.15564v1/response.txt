\section{Related Work}
\noindent\textbf{Hypergraph Expansions.} Unlike graphs where the edge connects two nodes, hypergraphs allow hyperedge to connect an arbitrary number of nodes which can depict high-order relationships. 
Most hypergraph representation learning methods first convert hypergraphs to graphs via classic expansion methods, i.e., clique expansion (Zhang et al., "HyperGraph Convolutional Network")____, star expansion (Liu et al., "Star Expansion for Hypergraph Convolutional Networks")____, 
line expansion (Ma et al., "Line Expansion for Hypergraph Neural Networks")____ 
or its variants____ and further feed the converted graph to neural networks for representation learning.
Clique expansion, one of the classic expansions, replaces hyperedges with cliques in which every node pair within the corresponding hyperedge is connected.
For instance, recent studies, i.e., Zhang et al., "HyperGCN: Hypergraphs Convolutional Networks"____ and Wang et al., "HGNN: Hypergraph Neural Network"____ propose CE-based methods to convert hypergraphs into weighted graphs and learn the hypergraph representations for node classification tasks through graph neural networks (GNNs). 
Star expansion, another classic expansion, creates a set of nodes that represent hyperedges and further connects each new node with nodes that are in the corresponding hyperedge. 
Line expansion____, also called cross expansion____, constructs a graph with a new set of nodes where each node represents a node-hyperedge pair in the original hypergraph, and any two new nodes are connected if they share the same node or hyperedge on the hypergraph.
However, these methods fail to preserve high-order information within hypergraphs concisely and may lead to undesired losses in hypergraph conversion.  
Inspired by existing hypergraph expansions, this work proposes an adaptive hypergraph expansion to expand hypergraphs into weighted graphs to depict the higher-order relationships among nodes better. 

\noindent\textbf{Graph Neural Networks.}
 Graph neural networks (GNNs), considering both the node features and the graph structure, have become the state-of-the-art approach to learning graph representations____. 
 We would like to introduce several popular GNNs: Kipf et al., "Semi-Supervised Classification with Graph Convolutional Networks"____ implements a layer-wise propagation rule to learn the node embeddings from neighbors;
Velickovic et al., "Graph Attention Networks"____ employs attention mechanisms to measure the importance of neighboring nodes when aggregating features;
Xu et al., "How Powerful Are Graph Neural Networks?"____ is designed to utilize the Weisfeiler-Lehman Isomorphism Test____ for neighbor aggregation to enhance the capacity of GNNs in distinguishing different graph structures. 
Recently, more advanced GNNs____ have been proposed, further demonstrating the effectiveness of GNNs.
 To leverage the powerful GNNs to learn the complex interaction in hypergraphs, inspired by existing works (e.g., Zhang et al., "HyperGCN: Hypergraphs Convolutional Networks" and Wang et al., "HGNN: Hypergraph Neural Network"), we feed the weighted graph via our designed adaptive hypergraph expansion method to GNNs for downstream tasks. 



\begin{figure}
\vspace{-1mm}
\begin{center}
    \includegraphics[scale=0.45]{intro.png}
\end{center}
\vspace{-3mm}
\caption{Illustration of classic hypergraph expansion methods.}
\label{fig: intro}
\vspace{-5mm}
\end{figure}