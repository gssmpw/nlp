\section{Experiments}\label{sec:exp}
We evaluate on two crystal generation tasks: ab initio generation in \cref{sec:exp_abinitio} and stable structure prediction task in \cref{sec:exp_csp}. Ablation studies are detailed in \cref{sec:exp_ablation} to validate design choices. We provide the implementation details in \cref{appd:imple_details}.

%\textbf{Datasets} 
Following \citet{xie2021crystal,jiao2023crystal}, we choose the following datasets for evaluation: $1)$ \textbf{Perov-5}~\citep{castelli2012new, castelli2012computational} is composed of 18,928 perovskite crystals of similar structures, with 5 atoms in a unit cell sharing the chemical formula ABX$_3$. $2)$ \textbf{Carbon-24}~\citep{carbon2020data} contains 10,153 crystals with 6$\sim$24 atoms in a cell, and all atom types are carbon. $3)$ \textbf{MP-20}~\citep{jain2013commentary} selects 45,231 stable inorganic materials from Material Projects~\citep{jain2013commentary}, including the majority of experimentally-verified materials with at most 20 atoms in a unit cell. $4)$ \textbf{MPTS-52} \citep{jiao2023crystal} consists of 40,476 crystals up to 52 atoms per cell, which is a more challenging extension of MP-20. All crystals are reduced as Niggli cells \citep{nigglicell}. The procedure to split the datasets into training, validation, and testing subsets adheres to prior practices~\citep{xie2021crystal,jiao2023crystal}. 

\subsection{Ab Initio Generation}\label{sec:exp_abinitio}
\begin{table}[t!]
  \caption{Results on ab initio generation task. Baseline results are from \citet{xie2021crystal,jiao2023crystal,flowmm}.}
  \vskip -0.1in
  \label{tab:abgen}
  \centering
  \resizebox{0.99\linewidth}{!}{
  \begin{tabular}{ccccccccc}
    \toprule
    \multirow{2}{*}{\bf Data} & \multirow{2}{*}{\bf Method}  & \multicolumn{2}{c}{\bf Validity (\%)  $\uparrow$}  & \multicolumn{2}{c}{\bf Coverage (\%) $\uparrow$}  & \multicolumn{3}{c}{\bf Property $\downarrow$}  \\
    % \cmidrule(r){1-2}
    ~     & ~     & Struc. & Comp. & COV-R & COV-P & $d_\rho$ & $d_E$ & $d_{elem}$ \\
    \midrule
    \multirow[t]{5}{*}{Perov-5} 
    & Cond-DFC-VAE~\citep{court20203} & 73.60 & 82.95 & 73.92 & 10.13 & 2.268 & 4.111 & 0.8373 \\
    & G-SchNet~\citep{NIPS2019_8974}  & 99.92 & 98.79 & 0.18 & 0.23 & 1.625 &	4.746 &	0.0368 \\
    & P-G-SchNet~\citep{NIPS2019_8974} & 79.63 & \textbf{99.13} & 0.37 & 0.25 & 0.2755 & 1.388 & 0.4552 \\
    & CDVAE~\citep{xie2021crystal} & \textbf{100.0} & 98.59 & 99.45 & 98.46 & 0.1258 & 0.0264 & 0.0628 \\
    & DiffCSP\citep{jiao2023crystal}  & \textbf{100.0} & 98.85 & \textbf{99.74} & 98.27 & 0.1110 & 0.0263 & 0.0128 \\
    & \modelname & \textbf{100.0} & 98.86 & 99.52 & \textbf{98.63} & \textbf{0.0728} & \textbf{0.0198} & \textbf{0.0098} \\
    \midrule
    \multirow[t]{5}{*}{Carbon-24} 
    & G-SchNet~\citep{NIPS2019_8974} & 99.94	 & --	  & 0.00 & 0.00 & 0.9427 & 1.320 &	-- \\
    & P-G-SchNet~\citep{NIPS2019_8974} & 48.39 & -- & 0.00 & 0.00 & 1.533 & 134.7 & --  \\
    & CDVAE~\citep{xie2021crystal} & \textbf{100.0} & -- & 99.80 & 83.08 & 0.1407 & 0.2850 & -- \\
    & DiffCSP \citep{jiao2023crystal}     & \textbf{100.0} & -- & \textbf{99.90} & 97.27 & 0.0805 & 0.0820 & --  \\
    & \modelname   & \textbf{100.0} & -- & \textbf{99.90} & \textbf{99.12} & \textbf{0.0612} & \textbf{0.0503} & --  \\
    \midrule
    \multirow[t]{5}{*}{MP-20} 
    & G-SchNet~\citep{NIPS2019_8974} & 99.65 &	75.96 & 38.33 & 99.57 &	3.034 &	42.09 &	0.6411	\\
    & P-G-SchNet~\citep{NIPS2019_8974} & 77.51 & 76.40 & 41.93 & 99.74 & 4.04 & 2.448 & 0.6234 \\
    & CDVAE~\citep{xie2021crystal} & \textbf{100.0} & 86.70 & 99.15 & 99.49 & 0.6875 & 0.2778 & 1.432  \\
    & DiffCSP\citep{jiao2023crystal} &  \textbf{100.0} & 83.25 & \textbf{99.71} & 99.76 & 0.3502 & 0.1247 & 0.3398  \\
    & FlowMM \citep{flowmm} &  96.85 & 83.19 & 99.49 & 99.58 & 0.239 & - & \textbf{0.083}  \\
     & \modelname & \textbf{100.0} & \textbf{87.51} & 99.09 & \textbf{99.79} & \textbf{0.2067} & \textbf{0.0632} & 0.1628\\
    \bottomrule
  \end{tabular}
  }
% \vskip -0.2in
\end{table}

\begin{table*}[t!]
\vskip -0.1in
% \renewcommand\arraystretch{0.85}
 %  
  \centering
  \caption{Results on stable structure prediction task. Baseline results are from \citet{jiao2023crystal,flowmm}.}
  \resizebox{0.90\linewidth}{!}{
  % \small
    \setlength{\tabcolsep}{2.5pt}
  % \setlength{\tabcolsep}{3.2mm}
    \begin{tabular}{lccccccc}
    \toprule
    \multirow{2}[2]{*}{} & \multicolumn{2}{c}{Perov-5 } &  \multicolumn{2}{c}{MP-20} & \multicolumn{2}{c}{MPTS-52} \\
          &  Match rate$\uparrow$ & RMSE$\downarrow$   & Match rate$\uparrow$ & RMSE$\downarrow$ & Match rate$\uparrow$ & RMSE$\downarrow$ \\
    \midrule
    % \multicolumn{7}{c}{\textit{Generative Models}} \\
    % \midrule
     % & 1     & 48.22  & 0.4179  & 15.39 & 0.3762 & 3.67 & 0.4115   \\
     %  P-cG-SchNet~\citep{gebauer2022inverse}    & 20    &   97.94  &  0.3463 & 32.64   & 0.3018 & 12.96 & 0.3942 \\    
    % \midrule
    CDVAE~\citep{xie2021crystal}   & 45.31  & 0.1138  & 33.90  & 0.1045 & 5.34 & 0.2106 \\
          % & 20    & 88.51  & 0.0464 & 66.95  & 0.1026 & 20.79 & 0.2085 \\
    \midrule
    DiffCSP~\citep{jiao2023crystal}      & 52.02  & 0.0760  & 51.49 &	0.0631 & 12.19 & 0.1786 \\
          % & 20    & 98.60 & 0.0128 &  77.93 & 0.0492 & 34.02 & 0.1749 \\
    \midrule
    FlowMM~\citep{flowmm}     & 53.15  & 0.0992  & 61.39 &	 0.0566 & 17.54 &  0.1726 \\
          % & 20    & 98.60 & 0.0128 &  77.93 & 0.0492 & 34.02 & 0.1749 \\
    % \midrule
    % EquiCSP~\citep{equicsp} & 1     & 52.02  & 0.0707  & 57.59 &	 0.0510 & 14.85 &  0.1169 \\
          % & 20    & 98.60 & 0.0128 &  77.93 & 0.0492 & 34.02 & 0.1749 \\
    \midrule
    \modelname    & \textbf{54.69}  & \textbf{0.0636} & \textbf{64.35} &	\textbf{0.0433} & \textbf{20.52} & \textbf{0.1038} \\
     % & 20 & \textbf{98.64} & \textbf{0.0116} &\textbf{80.72} & \textbf{0.0473} & \textbf{36.86} & \textbf{0.1596} \\
    \bottomrule
    \end{tabular}
    }
\vskip -0.25in
 \label{tab:oto}%
\end{table*}%

\textbf{Baselines} For this task, the compared baselines include:  $2)$ two-stage VAE-based methods \textbf{Cond-DFC-VAE} \citep{court20203} and \textbf{CD-VAE} \citep{xie2021crystal}; $2)$ auto-regressive method \textbf{G-SchNet}~\citep{NIPS2019_8974}, and its periodic adaptation \textbf{P-G-SchNet}~\citep{xie2021crystal}; $3)$ diffusion-based joint generation approach \textbf{DiffCSP} \citep{jiao2023crystal}. $4)$ flow-matching-based approach \textbf{FlowMM} (Note that FlowMM only reports results on MP-20 and excludes $d_{E}$). We follow \citep{hoogeboom2022equivariant,jiao2023crystal} to sample atom numbers from a distribution that is pre-computed based on atom numbers in the training dataset. \textbf{Performance Indicators} Following previous work \citep{xie2021crystal}, we evaluate the efficacy of our model from three aspects: $1)$ \textit{Validity}: Structure and compositional validity of randomly generated 10000 materials. $2)$ \textit{Coverage}: Coverage score between generated 10000 materials and test set, defined by average minimum structure distance and average minimum compositional distance. $3)$ \textit{Property Statistics}: the earth mover's distance (EMD) between the property distribution of generated crystals and test dataset crystals. Monitored properties include density ($\rho$, unit g/cm$^3$), energy predicted by an independent GNN ($E$, unit eV/atom), and the number of unique elements (\# elem.).

\textbf{Results} The evaluation metrics for ab initio generation tasks are listed in \cref{tab:abgen}. Our method consistently achieves better or competitive property statistics and generation precision on three datasets compared to baseline generative models. For compositional metrics including $d_{elem}$ and compositional validity, our method demonstrates bigger performance improvement for the more challenging dataset MP-20 ($+4.34$\% compared to DiffCSP with the same level of $d_{elem}$), underscoring the importance of modeling atom types in the simplex space. 

\subsection{Stable Structure Prediction} \label{sec:exp_csp}
In this section, we extend our method to stable structure prediction task, where the modeling target is $p(\vL,\vF|\vA)$. The condition of atom types $\vA$ is incorporated into the network by concatenating node feature and atom type embedding, following \citet{jiao2023crystal}. 

\textbf{Baselines}~Following the practices in \citet{jiao2023crystal}, we select baselines generative approaches including Diffusion-based approaches \textbf{CD-VAE} and \textbf{DiffCSP} and the recent flow-matching-based method, \textbf{FlowMM}, which only reports results on the MP-20 dataset for this task. \textbf{Performance Indicators}~The measured performance indicators for this task are \textbf{Match Rate} and \textbf{RMSD} computed by \verb|StructureMatcher| class with thresholds \verb|stol=0.5, angle_tol=10, ltol=0.3| in pymatgen~\citep{ong2013python}, between the predicted 
 structure candidates and the groundtruth structure given the composition. \textbf{Results} As summarized in \cref{tab:oto},  \modelname achieves consistent performance improvement over baseline methods, especially for more challenging datasets ($\sim$ 13$\%$ higher match rate than DiffCSP for MP-20 and $\sim$ 40$\%$ lower RMSE compared to FlowMM for MPTS-52).




\begin{wraptable}{r}{0.50\textwidth}
% \begin{table}
 \vskip -0.3in
\small
  \centering
  \caption{Ablation studies on MP-20. }
    \begin{tabular}{lcc}
    \toprule
          & Match rate (\%) $\uparrow$ & RMSE $\downarrow$  \\
    \midrule
    \modelname & \textbf{64.35} & \textbf{0.0433} \\
    % \midrule
    % \addlinespace[-0.1pt]
    % \rowcolor{gray!30}\multicolumn{3}{c}{\textit{w/ diffusion schedule}} \\
    % \addlinespace[-2pt]
    \midrule
    % $\vF$ $w/$ diffusion schedule & 51.71 & 0.0656 \\
    $w/o$~entropy cond. & 52.16 & 0.0631 \\
    $w/o $ approx. sch. & 49.76 & 0.0643 \\
    $w/o$ torus BFN & 6.17 & 0.3822\\
    % $w/o$ equivariant network & 0.00 & -\\    
    % $\mF\rightarrow\mL$ & 36.73  & 0.0838 \\
    \midrule
     & \multicolumn{2}{c}{1k Batches Sim. Time (s)} \\
    \midrule
    Iterated Sim.  & \multicolumn{2}{c}{356.1}\\
    Fast Sim. & \multicolumn{2}{c}{92.6}\\
    % \midrule
    \bottomrule
    \end{tabular}%
  \label{tab:exp_abl}%
   % \vskip -0.1in

\end{wraptable}

\subsection{Ablation Study}\label{sec:exp_ablation}

Using MP-20 dataset and stable structure prediction task, we validate the necessity of proposed components of CrysBFN with results summarized in \cref{tab:exp_abl}: 

$1)$ By removing the entropy parameter condition $\bcF$ and using time as condition, match rate drops to $52.16\%$, proving that, different from original BFN, the non-additive accuracy dynamics requires the network to model both mean parameter $m$ and entropy parameter condition $c$. 

$2)$ By altering the approximated linear-entropy sender accuracy schedule to the hand-designed roughly linear-entropy schedule $c(t)=t c^{t}(1)$, we validate the effect of exact searched linear entropy schedule. 

$3)$ By replacing the proposed hyper-torus BFN with the original continuous BFN, we observe poor match rate at $6.17\%$, indicating the importance of redesigning BFN for crystal data. Calculating the computational time for simulating 1000 batches, we observe $\sim4\times$ efficiency, verifying fast sampling rate considering the full training procedure of MP-20 requires $\sim 150$k steps.



\subsection{Sampling Efficiency Experiment}
\begin{wrapfigure}{r}{0.5\textwidth} % 图片靠右，宽度为文本宽度的40%
\vskip -0.4in
    \centering
    \includegraphics[width=0.4\textwidth]{imgs/match_rate.pdf} 
    \caption{Experimental results on MP-20 with different Number of Function Evaluations (NFE) \emph{i.e.} number of network forward passes. } % 图像标题
    \label{fig:eff_compare}
\vskip -0.9in
\end{wrapfigure}
We compare the sampling efficiency of CrysBFN and DiffCSP over the CSP task on the MP-20 dataset, based on the Number of Function Evaluations (NFE), \textit{i.e.}, the number of network forward passes. The experimental results is plotted in \cref{fig:eff_compare}. Notably, CrysBFN achieves a remarkable match rate of 60.02\% with only 10 step network forwards, surpassing DiffCSP's performance of 51.49\% at 2000 step network forwards. This illustrates the exceptional sampling efficiency of CrysBFN.  




