\section{Related Work}
Defining software quality is a fundamental challenge in software engineering. One of the first solutions dates back to 1978 through the means of a software quality model (SQM) ____, which is a set of characteristics and their relationships. It provides the basis for specifying quality requirements and evaluation ____. The first SQMs ____ are called \textit{basic} and they make global assessments of a software product, while the ones developed for specific domains or applications are characterized as \textit{tailored} quality models ____.
The quality assessment models (QAM) concept was developed for the purpose of measuring software quality. On top of quality attributes, QAMs also include \textit{metrics} which enable the measurement of the attributes. Examples of such metrics are design metrics, complexity metrics, duplicated code, quality improvement and software reliability ____. %Systematic reviews of QAMs have indicated that the practicality of such models can be increased by focusing on essential quality characteristics as opposed to comprehensive models including all possible attributes, and on metrics that are amenable to automation as this can quicken the evaluation process and result in faster decision making ____.

The extensive usage of ML systems in production introduced software engineering challenges related to their development and maintenance ____ and accumulating technical debt over their deployment life-cycle ____. This proliferation of challenges has given rise to the paradigm of Machine Learning Operations (MLOps). 
MLOps introduces a set of best practices to operate ML systems in production at scale ____. However, despite the rise of MLOps practices the field of quality management for ML systems has received less attention. While there are studies mapping traditional quality management activities to ML systems ____ as well as frameworks for ML quality assessment ____, none of the existing work provides concrete metrics to be measured.


%\input{includes/example_mat}
%\input{includes/compressed_subchar_table}
%\subsection{Maturity models for Machine Learning}
A concept orthogonal to the quality assessment is the definition of quality standards to determine the maturity of an ML system. The notion of maturity for software applications dates back to 1988 when the first maturity framework was introduced ____, aiming to improve software development processes, leading to later version of the Capability Maturity Model ____.
The usefulness of maturity models is validated by the development of many variants across time ____. Since ML systems are software products, the same concept has been applied to ML system development as well ____. The general structure of these frameworks is composed of increasing levels of maturity. The concept of \textit{maturity} is often defined at \textit{organization} level ____ depending on the level of \textit{automation} ____ of MLOps activities.
They key differences of our framework with existing ones used as baselines are: a) the maturity levels in our framework are defined on a \textit{system} level, since in practice, organizations own several ML systems at different maturity levels ____; b) we take into account more quality aspects than automation, such as discoverability, scalability or ownership which are not covered by existing frameworks ____ as discussed in ____; c) our framework allows for a quick review of ML systems with respect to internal policies and regulations ____; d) we provide different quality criteria for the maturity, based on the systemâ€™s criticality, to avoid unnecessary overhead for low criticality systems, which is a concern for any organization.


%The usefulness of such models in software development is validated through their extensive research and development of many variants ____ aiming at improving the quality of software products. Given that ML systems are software products as well, the concept of maturity models has been introduced into ML system development with the development of various maturity models aiming at the optimization of machine learning operations . 

\begin{table*}[!htbp]
\caption{Full description of quality assessment requirements, and their expected maturity levels. The symbol ``-'' means no requirement, the symbol ``\protect\ckmark'' means the minimal requirement, and ``\protect\doubleckmark'' refers to the full requirement.}
\label{tab:full_qa}
\begin{tblr}{
  colspec = {
    p{0.01\linewidth}
    p{0.05\linewidth}
    p{0.12\linewidth}
    p{0.16\linewidth}
    p{0.32\linewidth}
    p{0.01\linewidth}
    p{0.01\linewidth}
    p{0.01\linewidth}
    p{0.01\linewidth}
    p{0.01\linewidth}}
    , 
    cell{1}{1} = {c=2}{l},
  %colspec = {p{2.4cm}p{2.7cm}XXX}, 
  rowhead = 1,
  cells = {font = \fontsize{7pt}{6pt}\selectfont},
  hlines,
}
 \textbf{Sub-Characteristic} & &\textbf{Minimal req. \ckmark} & \textbf{Full req. \doubleckmark} & \textbf{Reasoning} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5 }\\
 
\SetCell[r=4]{l} \rotatebox{90}{\textbf{Utility}}  & Accuracy & The ML system outperforms a simple baseline & The ML system outperforms a baseline and its input data are validated & Outperforming a baseline is required to justify the effort of building an ML system ____. Input data should be validated to avoid problematic system versions deployed in production ____. & \ckmark & \ckmark & \doubleckmark & \doubleckmark & \doubleckmark \\ 

& Effectiveness & Effectiveness is verified with an A/B experiment & Long-term effectiveness is verified by repeating the AB test in 6 months & A/B testing is a reliable way to assess a system's effectiveness ____.  & - & - & \ckmark & \ckmark & \doubleckmark \\

& Responsiveness & - & Latency and throughput requirements are met & An ML system, will not have business impact if the latency is too high (real time predictions) or the throughput too small ____. & \doubleckmark & \doubleckmark & \doubleckmark & \doubleckmark & \doubleckmark \\

& Usability & - & System is deployed in a serving system & An ML system can only have value if it can be effectively used by its potential users.   & - & - & \doubleckmark & \doubleckmark & \doubleckmark \\
% --------- 
\SetCell[r=2]{l} \rotatebox{90}{\textbf{Economy}} &  Cost \mbox{Effectiveness} & - & Revenue from the system is greater than its training and inference costs & A system which costs more to train, maintain,
and serve than the impact of these predictions should not be deployed. & - & - & - & - & \doubleckmark \\

& Efficiency & Basic operations are automated & Resources for training and inference are optimized  & Efficient systems should reach their desired objective with the minimum number of utilized resources ____.   & - & - & - &  \ckmark & \doubleckmark \\
% ---------
\SetCell[r=4]{l} \rotatebox{90}{\textbf{Robustness}} & Availability & - & The deployed service meets its SLAs ____ & An unavailable system, cannot achieve its business purpose ____. & \doubleckmark & \doubleckmark & \doubleckmark & \doubleckmark & \doubleckmark \\

& Resilience & Up to $30\%$ failed ML pipelines per Q & At most $10\%$ failed ML pipelines per quarter & Automated ML pipelines should not fail frequently to ensure that the most updated model is available for predictions ____.  & - & - & \ckmark & \ckmark & \doubleckmark \\

& Adaptability & The system is partially adaptable  & The system is adaptable (e.g. retrained frequently) & The system operates in a changing environment, hence it should adapt to such changes to avoid losing commercial impact ____. & - & - & \ckmark & \doubleckmark & \doubleckmark \\

& Scalability & - & The system is deployed and can scale the resources depending on the traffic. & Different ML use cases have different needs in terms of traffic. Given that a system can be used in multiple use cases it is essential to handle traffics of different scale. & - & - & - & - & \doubleckmark \\
% -----------
% --------- 
\SetCell[r=2]{l} \rotatebox{90}{\textbf{Productionability}} & Repeatability & The pipeline of the ML life-cycle is partially automated & The pipeline repeating the ML life-cycle is fully automated  & Automation of an ML pipeline decreases the overhead of manual actions and minimizes the chances for human error ____.  & - & - & \ckmark & \doubleckmark & \doubleckmark \\

& Monitoring & ML performance is being monitored & ML performance, feature drift and metrics are monitored  & ML systems can have many points of failure, it is essential to monitor key indicators to identify performance degradation ____. & - & - & \ckmark & \ckmark & \doubleckmark \\

\SetCell[r=4]{l} \rotatebox{90}{\textbf{Modifiability}} & Maintainability & Code is versioned & Code is versioned and Readability full requirement is met  & The ease of maintenance of an ML system affects the downtime, speed of iteration and hence the commercial impact ____. & - & \ckmark & \ckmark & \ckmark & \doubleckmark \\
% -----------
& Modularity & The source code is partially modular  & The code is fully modular, split into components of limited functionality  & Highly modular ML systems allow for changes to be performed in one part of the system without the risk to break another
part of it ____. & - & \ckmark & \ckmark & \ckmark & \doubleckmark \\%This translates to faster development time to maintain or extend the functionality of the system.\\
% ---------
& Testability & Test coverage is at least $20\%$  & Test coverage is at least $80\%$ & System test coverage directly affects its robustness and ease of maintenance ____. & - & \ckmark & \ckmark & \ckmark & \doubleckmark \\
% ---------
& Operability & The system is deployed on a service  & The system can be disabled, updated and reverted & Production systems might need to have their state altered in case of deployment issues or identified bugs.  & \ckmark & \ckmark & \doubleckmark & \doubleckmark & \doubleckmark \\

% ----------
\SetCell[r=4]{l} \rotatebox{90}{\textbf{Comprehensibility}} & Discoverability & - & The system is deployed in an accessible registry  & The ability to discover and audit an ML system is essential for ensuring transparency and allowing new users to exploit its value. & - & - & \doubleckmark & \doubleckmark & \doubleckmark \\
% -----------
& Readability & Meaningful variables names &The code is fully modular, there is a unified code style.  & Easily readable code enhances a system's ability to maintained, modified and extended ____. & - & - & \ckmark & \ckmark & \doubleckmark \\
% ----------
& Traceability & Metadata is \textit{partially} logged & Metadata and artifacts in the ML life-cycle are \textit{fully} logged  & To reproduce production systems it is important to have visibility on the exact conditions they were created and deployed ____. & - & - & \ckmark & \doubleckmark & \doubleckmark \\
% ----------
& Understand- ability & The system has partial documentation & The system has complete documentation  & Systems must be understandable to provide trust to potential users, and allow potential contributors to maintain them ____. & \ckmark & \ckmark & \doubleckmark & \doubleckmark & \doubleckmark \\
\end{tblr}
\end{table*}




\begin{table*}
\begin{tblr}[
  caption = \textbf{Full description of quality assessment requirements},
  entry = {Short Caption},
  label = {tab:full_qa},
]{
  colspec = {
    p{0.01\linewidth}
    p{0.06\linewidth}
    p{0.07\linewidth}
    p{0.18\linewidth}
    p{0.36\linewidth}
    p{0.01\linewidth}
    p{0.01\linewidth}
    p{0.01\linewidth}
    p{0.01\linewidth}
    p{0.01\linewidth}}
    , 
    cell{1}{1} = {c=2}{l},
  %colspec = {p{2.4cm}p{2.7cm}XXX}, 
  rowhead = 1,
  cells = {font = \fontsize{7pt}{7pt}\selectfont},
  hlines,
}
 \textbf{Sub-Characteristic} & &\textbf{Min req. \ckmark} & \textbf{Full req. \doubleckmark} & \textbf{Reasoning} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} \\
 
% ----------
\SetCell[r=5]{l} \rotatebox{90}{\textbf{Responsibility}} & Explainability & - & The system's predictions are explainable  & Explain the mechanism with which the system outputs its predictions is key for gaining stakeholders' trust ____. & - & - & - & \doubleckmark & \doubleckmark \\
% ---------
& Fairness & - & The system has been checked against undesired biases and none were identified & ML systems' predictions can be used to take irreversible decisions on behalf of customers, hence it is important that their performance is not affected by undesired biases ____.& \doubleckmark & \doubleckmark & \doubleckmark & \doubleckmark & \doubleckmark \\
% ---------
& Ownership & - & A team is appointed for maintaining the ML system & Ownership ensures that there is always an appointed individual to maintain the system in case of issues ____. & \doubleckmark & \doubleckmark & \doubleckmark & \doubleckmark & \doubleckmark \\
% % \midrule
& Standards \mbox{Compliance} & - &Compliance standards, such as PII data handling, are met & Adherence to applied regulatory standards is essential for the long-term viability of an ML system ____.  & \doubleckmark & \doubleckmark & \doubleckmark & \doubleckmark & \doubleckmark \\
% % \midrule
& Vulnerability & - & Bots are filtered out from the input data & Existence of bots in data adds noise to the system which harms its performance and pose security risks ____. & \doubleckmark & \doubleckmark & \doubleckmark & \doubleckmark & \doubleckmark \\
\end{tblr}
\end{table*}