% \usepackage{tabularray}
\begin{longtblr}[
  label = none,
  entry = none,
]{
  width = \linewidth,
  colspec = {Q[15]Q[80]Q[696]},
  cell{1}{1} = {c=2}{0.15\linewidth},
  cell{2}{1} = {r=12}{},
  cell{2}{2} = {r=3}{},
  cell{5}{2} = {r=3}{},
  cell{8}{2} = {r=3}{},
  cell{11}{2} = {r=3}{},
  cell{14}{1} = {r=6}{},
  cell{14}{2} = {r=3}{},
  cell{17}{2} = {r=3}{},
  cell{20}{1} = {r=12}{},
  cell{20}{2} = {r=3}{},
  cell{23}{2} = {r=3}{},
  cell{26}{2} = {r=3}{},
  cell{29}{2} = {r=3}{},
  cell{32}{1} = {r=6}{},
  cell{32}{2} = {r=3}{},
  cell{35}{2} = {r=3}{},
  cell{38}{1} = {r=12}{},
  cell{38}{2} = {r=3}{},
  cell{41}{2} = {r=3}{},
  cell{44}{2} = {r=3}{},
  cell{47}{2} = {r=3}{},
  cell{50}{1} = {r=12}{},
  cell{50}{2} = {r=3}{},
  cell{53}{2} = {r=3}{},
  cell{56}{2} = {r=3}{},
  cell{59}{2} = {r=3}{},
  cell{62}{1} = {r=15}{},
  cell{62}{2} = {r=3}{},
  cell{65}{2} = {r=3}{},
  cell{68}{2} = {r=3}{},
  cell{71}{2} = {r=3}{},
  cell{74}{2} = {r=3}{},
  hline{2,14,20,32,38,50,62,77} = {-}{},
  hline{5,8,11,17,23,26,29,35,41,44,47,53,56,59,65,68,71,74} = {2-3}{},
}
\textbf{Sub-characteristic} &  & Requirements\\
\rotatebox{90}{\textbf{Utility}} & Accuracy & The ML system outperforms a simple baseline\\
 &  & The ML system outperforms a baseline and its input data are validated\\
 &  & Outperforming a baseline is the minimum requirement to justify the effort of building a deploying an ML system \cite{huyen2022designing, poran2022one}. Input data should be validated to avoid problematic system versions deployed in production \cite{google-data-validation}.\\
 & Effectiveness & Short-term effectiveness is verified with an A/B experiment\\
 &  & Long-term effectiveness is verified by repeating the AB test after 6 months\\
 &  & A/B testing is a reliable way to assess a system's effectiveness \cite{Kohavi-rules-of-thumb, kohavi2022b, bernardi2019150, booking2021personalization}.\\
 & Responsiveness & -\\
 &  & Latency and throughput requirements are met\\
 &  & An ML system, even of high accuracy, will not have business impact if the latency is too high (real time predictions) or the throughput too small (batch predictions) \cite{google-latency}.\\
 & Usability & -\\
 &  & System is deployed in a serving system or its output is stored for consumption\\
 &  & An ML system can only have value if it can be effectively used by its potential users.\\
\rotatebox{90}{\textbf{Economy}} & {Cost \\\mbox{Effectiveness}} & -\\
 &  & Revenue from the system is greater than its training and inference costs\\
 &  & An ML system which costs more to train, maintain,and serve predictions than the impact of these predictions should not be deployed.\\
 & Efficiency & Basic operations are automated\\
 &  & Technical resources for training and inference are optimized (max 5 hours training time)\\
 &  & Efficient systems should reach their desired objective with the minimum number of utilized resources \cite{efficient-ml-review}.\\
\rotatebox{90}{\textbf{Robustness}} & Availability & -\\
 &  & The deployed serving system meets its Service Level Agreements (SLA) \cite{wieder2011service}\\
 &  & A system that is not available, cannot achieve its business purpose \cite{sre}.\\
 & Resilience & At most~30\%\\
 &  & At most~10\%\\
 &  & ML pipelines should not fail frequently to ensure that the most updated model is available for predictions \cite{resilient-ml}.\\
 & Adaptability & The system is partially adaptable (e.g. retrained infrequently or manually)\\
 &  & The system is adaptable (e.g. retrained frequently)\\
 &  & The environment a system operates in changes over time, hence a production system should adapt to such changes to avoid losing commercial impact \cite{concept-drift-adaptation}.\\
 & Scalability & -\\
 &  & The system is deployed in a deployment system which can scale the resources depending on the traffic.\\
 &  & Different ML use cases have different needs in terms of traffic. Given that a system can be used in multiple use cases it is essential to handle traffics of different scale.\\
\rotatebox{90}{\textbf{Productionizability}} & Repeatability & The pipeline repeating the ML life-cycle is partially automated\\
 &  & The pipeline repeating the ML life-cycle is fully automated\\
 &  & Automation of an ML pipeline decreases the overhead of manual actions and minimizes the chances for human error \cite{MLOps-Overview}.\\
 & Monitoring & ML performance is being monitored\\
 &  & ML performance, feature drift and business metrics are being monitored\\
 &  & Since ML systems can have many points of failure, it is essential to monitor key indicators to identify any performance degradation as soon as possible \cite{MLOps-Overview, monitoring-article}.\\
\rotatebox{90}{\textbf{Modifiability}} & Maintainability & Code is versioned\\
 &  & Code is versioned and Readability full requirement is met\\
 &  & The ease with which the code of an ML system can be maintained, directly affects the downtime, speed of iteration and hence the commercial impact of the system \cite{maintainability}.\\
 & Modularity & The source code is partially modular (each step of the ML pipeline is split into a separate function)\\
 &  & The source code is fully modular, e.g. split into interrelated components of limited functionality\\
 &  & Highly modular ML systems allow for changes to be performed in one part of the system without the risk to break anotherpart of it \cite{modularity}.\\
 & Testability & Test coverage is at least~20\%\\
 &  & Test coverage is at least~80\%\\
 &  & The extent to which the code of a system is tested, directly affects its robustness and ease of maintenance \cite{software-testing}.\\
 & Operability & The system is deployed on a serving system\\
 &  & The system can be disabled, updated and reverted to previous versions\\
 &  & Production systems might need to have their state altered in case of deployment issues or identified bugs.\\
\rotatebox{90}{\textbf{Comprehensibility}} & Discoverability & -\\
 &  & The system is deployed in an accessible registry\\
 &  & The ability to discover and audit an ML system is essential for ensuring transparency and allowing new potential users to exploit its value.\\
 & Readability & Naming of variables/functions/classes is human readable and meaningful\\
 &  & Minimal requirement is met, the code is fully modular, there is a unified code style.\\
 &  & Easily readable code enhances a system's ability to maintained, modified and extended \cite{code-readablity}.\\
 & Traceability & Metadata and artifacts created in the ML life-cycle are~\textit{partially}~logged\\
 &  & Metadata and artifacts created in the ML life-cycle are~\textit{fully}~logged\\
 &  & To be able to debug production systems it is important to have visibility on the exact conditions they were created and deployed \cite{MLOps-Overview}.\\
 & Understandability & The system has partial documentation\\
 &  & The system has complete documentation\\
 &  & Systems must be understandable in order provide trust to potential users, and allow potential contributors to maintain or improve them \cite{ml-documentation}.\\
\rotatebox{90}{\textbf{Responsibility}} & Explainability & -\\
 &  & The system's predictions are explainable (either by the model's architecture or techniques like Shapley values)\\
 &  & Being able to explain the mechanism with which the system outputs its predictions is key for gaining stakeholders' trust \cite{explainable-ml-princinples}.\\
 & Fairness & -\\
 &  & The system has been checked against undesired biases and none were identified\\
 &  & ML systems' predictions can be used to take irreversible decisions on behalf of customers, hence it is important that their performance is not affected by undesired biases \cite{ml-fairness}.\\
 & Ownership & -\\
 &  & There is an appointed team responsible for maintaining the ML system\\
 &  & Ownership ensures that there is always an appointed individual to maintain the system in case of issues \cite{microsoft-ownership}.\\
 & Standards \mbox{Compliance} & -\\
 &  & Necessary compliance standards, such as PII data handling, are met\\
 &  & Adherence to applied regulatory standards is essential for the long-term viability of an ML system \cite{ml-privacy-meter}.\\
 & Vulnerability & -\\
 &  & Bots are filtered out from the input data\\
 &  & Existence of bots in data adds noise to the system which is detrimental to its performance and pose security risks \cite{data-poisoning}.
\end{longtblr}