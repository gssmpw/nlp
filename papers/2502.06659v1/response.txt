\section{Related Work}
% \paragraph{Distillation with LLMs}

% Prior work **Brown, "Distilling Fine-Grained Dependencies"** has shown how smaller models can learn from explanations (i.e. rationales). 
% Unlike their larger counterparts **Rae, "Comprehensive and Controllable Text Generation with a Language Model"**, smaller models are not inherently capable of generating \textit{step-by-step} thinking chains, but they can be taught to do so **Welleck, "A Large-Scale Adversarial Training for Unsupervised Abstractive Summarization"**. 
% Recent efforts **Min, "Generating Long and Coherent Text with a Latent Variable Model"** have shown that using these rationales as additional training signal can yield significant gains for student models.
% **Stiennon, "Learning to Reason with Third-Party Explanations"** further explores factors that may influence the creation of a \textit{teacher} corpus when distilling for tasks like commonsense reasoning. 
% **Henderson, "Improving Language Models by Retrieving from Trillions of Tokens"** extend this line of work by exploring the trade-offs between generalizability and CoT-generation capability of small models, emphasizing how improving quality of generated rationales affect model performance. 
% More recently, **Zhang, "On the Opportunities and Challenges of Text Augmentation with Contrastive Learning"** investigated training details for CoT-augmented distillation, finding, e.g., that placing rationales \emph{after} labels yields superior performance. 

% \paragraph{Origin tracing} Methods for data provenance, such as watermarking, can be plausibly used for identifying the origin of a distilled student model. **Carlini, "A Survey on Watermarking and Fingerprinting Techniques"** introduce statistical tests to determine which model generated a string. 
% Our work differs in two ways: We do not assume access to model probabilities for detecting \textit{source models}, and we focus specifically on detecting text from \textit{distilled} models in which the resulting string can be attributed to either the teacher \textit{or} student model. **Chen, "On Watermarking and Steganography in Deep Learning"** use generation-time watermarking strategies to imbue text with signatures that can later be used to trace the origin of text produced by a downstream model. While this method is robust, it requires an important assumption that the training data of the student model comes from adequately watermarked models. 

% Most similar to our work is **Kumar, "Detecting Source Models for GAN-generated Text"**, which uses perplexity and contrastive training to detect the origin of a generated text. Our method focuses instead on exploring linguistic features as model signatures, rather than relying on perplexity.