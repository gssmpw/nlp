\section{Related Work}
% \paragraph{Distillation with LLMs}

% Prior work \citep{hase-bansal-2022-models} has shown how smaller models can learn from explanations (i.e. rationales). 
% Unlike their larger counterparts \cite{10.5555/3600270.3602070}, smaller models are not inherently capable of generating \textit{step-by-step} thinking chains, but they can be taught to do so \cite{magister-etal-2023-teaching}. 
% Recent efforts \citep{wadhwa-etal-2023-revisiting,ho-etal-2023-large} have shown that using these rationales as additional training signal can yield significant gains for student models.
% \citet{li-etal-2023-symbolic} further explores factors that may influence the creation of a \textit{teacher} corpus when distilling for tasks like commonsense reasoning. 
% \citet{pmlr-v202-fu23d} extend this line of work by exploring the trade-offs between generalizability and CoT-generation capability of small models, emphasizing how improving quality of generated rationales affect model performance. 
% More recently, \citet{wadhwa-etal-2024-investigating} investigated training details for CoT-augmented distillation, finding, e.g., that placing rationales \emph{after} labels yields superior performance. 

% \paragraph{Origin tracing} Methods for data provenance, such as watermarking, can be plausibly used for identifying the origin of a distilled student model. \citet{li2024statistical} introduce statistical tests to determine which model generated a string. 
% Our work differs in two ways: We do not assume access to model probabilities for detecting \textit{source models}, and we focus specifically on detecting text from \textit{distilled} models in which the resulting string can be attributed to either the teacher \textit{or} student model. \citet{li2024identifying} use generation-time watermarking strategies to imbue text with signatures that can later be used to trace the origin of text produced by a downstream model. While this method is robust, it requires an important assumption that the training data of the student model comes from adequately watermarked models. 

% Most similar to our work is \citet{li2023origin}, which uses perplexity and contrastive training to detect the origin of a generated text. Our method focuses instead on exploring linguistic features as model signatures, rather than relying on perplexity.