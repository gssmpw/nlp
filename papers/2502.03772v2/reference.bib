@inproceedings{Settransformer,
	title={Set transformer: A framework for attention-based permutation-invariant neural networks},
	author={Lee, Juho and Lee, Yoonho and Kim, Jungtaek and Kosiorek, Adam and Choi, Seungjin and Teh, Yee Whye},
	booktitle={International conference on machine learning},
	pages={3744--3753},
	year={2019},
	organization={PMLR}
}
@article{PerceiverIO,
	title={Perceiver IO: A general architecture for structured inputs \& outputs. arXiv, 2021},
	author={Jaegle, Andrew and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Doersch, Carl and Ionescu, Catalin and Ding, David and Koppula, Skanda and Zoran, Daniel and Brock, Andrew and Shelhamer, Evan and others},
	journal={arXiv preprint arXiv:2107.14795}
}
@inproceedings{Perceiver,
	title={Perceiver: General perception with iterative attention},
	author={Jaegle, Andrew and Gimeno, Felix and Brock, Andy and Vinyals, Oriol and Zisserman, Andrew and Carreira, Joao},
	booktitle={International conference on machine learning},
	pages={4651--4664},
	year={2021},
	organization={PMLR}
}
@inproceedings{ConvNext,
	title={A convnet for the 2020s},
	author={Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={11976--11986},
	year={2022}
}
@article{goyal2021coordination,
	title={Coordination among neural modules through a shared global workspace},
	author={Goyal, Anirudh and Didolkar, Aniket and Lamb, Alex and Badola, Kartikeya and Ke, Nan Rosemary and Rahaman, Nasim and Binas, Jonathan and Blundell, Charles and Mozer, Michael and Bengio, Yoshua},
	journal={arXiv preprint arXiv:2103.01197},
	year={2021}
}
@inproceedings{Involution,
	title={Involution: Inverting the inherence of convolution for visual recognition},
	author={Li, Duo and Hu, Jie and Wang, Changhu and Li, Xiangtai and She, Qi and Zhu, Lei and Zhang, Tong and Chen, Qifeng},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={12321--12330},
	year={2021}
}
@article{Volo,
	title={Volo: Vision outlooker for visual recognition},
	author={Yuan, Li and Hou, Qibin and Jiang, Zihang and Feng, Jiashi and Yan, Shuicheng},
	journal={IEEE transactions on pattern analysis and machine intelligence},
	volume={45},
	number={5},
	pages={6575--6586},
	year={2022},
	publisher={IEEE}
}
@inproceedings{Learnedqueries,
	title={Learned queries for efficient local attention},
	author={Arar, Moab and Shamir, Ariel and Bermano, Amit H},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={10841--10852},
	year={2022}
}
@article{deepseekv1,
	title={Deepseekmoe: Towards ultimate expert specialization in mixture-of-experts language models},
	author={Dai, Damai and Deng, Chengqi and Zhao, Chenggang and Xu, RX and Gao, Huazuo and Chen, Deli and Li, Jiashi and Zeng, Wangding and Yu, Xingkai and Wu, Y and others},
	journal={arXiv preprint arXiv:2401.06066},
	year={2024}
}
@article{deepseekv2,
	title={Deepseek-v2: A strong, economical, and efficient mixture-of-experts language model},
	author={Liu, Aixin and Feng, Bei and Wang, Bin and Wang, Bingxuan and Liu, Bo and Zhao, Chenggang and Dengr, Chengqi and Ruan, Chong and Dai, Damai and Guo, Daya and others},
	journal={arXiv preprint arXiv:2405.04434},
	year={2024}
}
@article{Qwen2,
	title={Qwen2. 5 Technical Report},
	author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
	journal={arXiv preprint arXiv:2412.15115},
	year={2024}
}
@inproceedings{mmoe,
	title={Modeling task relationships in multi-task learning with multi-gate mixture-of-experts},
	author={Ma, Jiaqi and Zhao, Zhe and Yi, Xinyang and Chen, Jilin and Hong, Lichan and Chi, Ed H},
	booktitle={Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery \& data mining},
	pages={1930--1939},
	year={2018}
}
@inproceedings{LlamamoeV1,
	title={Llama-moe: Building mixture-of-experts from llama with continual pre-training},
	author={Zhu, Tong and Qu, Xiaoye and Dong, Daize and Ruan, Jiacheng and Tong, Jingqi and He, Conghui and Cheng, Yu},
	booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
	pages={15913--15923},
	year={2024}
}
@article{LlamamoeV2,
	title={LLaMA-MoE v2: Exploring Sparsity of LLaMA from Perspective of Mixture-of-Experts with Post-Training},
	author={Qu, Xiaoye and Dong, Daize and Hu, Xuyang and Zhu, Tong and Sun, Weigao and Cheng, Yu},
	journal={arXiv preprint arXiv:2411.15708},
	year={2024}
}
@article{moesurvey,
	title={A survey on mixture of experts},
	author={Cai, Weilin and Jiang, Juyong and Wang, Fan and Tang, Jing and Kim, Sunghun and Huang, Jiayi},
	journal={arXiv preprint arXiv:2407.06204},
	year={2024}
}
@article{globalcancer,
	title={Global cancer statistics 2022: GLOBOCAN estimates of incidence and mortality worldwide for 36 cancers in 185 countries},
	author={Bray, Freddie and Laversanne, Mathieu and Sung, Hyuna and Ferlay, Jacques and Siegel, Rebecca L and Soerjomataram, Isabelle and Jemal, Ahmedin},
	journal={CA: a cancer journal for clinicians},
	volume={74},
	number={3},
	pages={229--263},
	year={2024},
	publisher={Wiley Online Library}
}
@article{metaanalysis1,
	title={Comparative 13-year meta-analysis of the sensitivity and positive predictive value of ultrasound, CT, and MRI for detecting hepatocellular carcinoma},
	author={Hanna, Robert F and Miloushev, Vesselin Z and Tang, An and Finklestone, Lee A and Brejt, Sidney Z and Sandhu, Ranjit S and Santillan, Cynthia S and Wolfson, Tanya and Gamst, Anthony and Sirlin, Claude B},
	journal={Abdominal radiology},
	volume={41},
	pages={71--90},
	year={2016},
	publisher={Springer}
}
@article{metaanalysis2,
	title={Imaging techniques for the diagnosis of hepatocellular carcinoma: a systematic review and meta-analysis},
	author={Chou, Roger and Cuevas, Carlos and Fu, Rongwei and Devine, Beth and Wasson, Ngoc and Ginsburg, Alexander and Zakher, Bernadette and Pappas, Miranda and Graham, Elaine and Sullivan, Sean D},
	journal={Annals of internal medicine},
	volume={162},
	number={10},
	pages={697--711},
	year={2015},
	publisher={American College of Physicians}
}
@article{vit,
	title={An image is worth 16x16 words: Transformers for image recognition at scale},
	author={Dosovitskiy, Alexey},
	journal={arXiv preprint arXiv:2010.11929},
	year={2020}
}
@article{conv,
	title={Convolutional networks for images, speech, and time series},
	author={LeCun, Yann and Bengio, Yoshua and others},
	journal={The handbook of brain theory and neural networks},
	volume={3361},
	number={10},
	pages={1995},
	year={1995},
	publisher={Citeseer}
}
@article{bridging,
	title={Bridging the gap between vision transformers and convolutional neural networks on small datasets},
	author={Lu, Zhiying and Xie, Hongtao and Liu, Chuanbin and Zhang, Yongdong},
	journal={Advances in Neural Information Processing Systems},
	volume={35},
	pages={14663--14677},
	year={2022}
}
@inproceedings{RepLKNet,
	title={Scaling up your kernels to 31x31: Revisiting large kernel design in cnns},
	author={Ding, Xiaohan and Zhang, Xiangyu and Han, Jungong and Ding, Guiguang},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={11963--11975},
	year={2022}
}
@article{slak,
	title={More convnets in the 2020s: Scaling up kernels beyond 51x51 using sparsity},
	author={Liu, Shiwei and Chen, Tianlong and Chen, Xiaohan and Chen, Xuxi and Xiao, Qiao and Wu, Boqian and K{\"a}rkk{\"a}inen, Tommi and Pechenizkiy, Mykola and Mocanu, Decebal and Wang, Zhangyang},
	journal={arXiv preprint arXiv:2207.03620},
	year={2022}
}
@inproceedings{pelk,
	title={PeLK: Parameter-efficient Large Kernel ConvNets with Peripheral Convolution},
	author={Chen, Honghao and Chu, Xiangxiang and Ren, Yongjian and Zhao, Xin and Huang, Kaiqi},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={5557--5567},
	year={2024}
}
@inproceedings{acnet,
	title={Acnet: Strengthening the kernel skeletons for powerful cnn via asymmetric convolution blocks},
	author={Ding, Xiaohan and Guo, Yuchen and Ding, Guiguang and Han, Jungong},
	booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
	pages={1911--1920},
	year={2019}
}
@inproceedings{repvgg,
	title={Repvgg: Making vgg-style convnets great again},
	author={Ding, Xiaohan and Zhang, Xiangyu and Ma, Ningning and Han, Jungong and Ding, Guiguang and Sun, Jian},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={13733--13742},
	year={2021}
}
@inproceedings{repvit,
	title={Repvit: Revisiting mobile cnn from vit perspective},
	author={Wang, Ao and Chen, Hui and Lin, Zijia and Han, Jungong and Ding, Guiguang},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={15909--15920},
	year={2024}
}
@inproceedings{deformablev1,
	title={Deformable convolutional networks},
	author={Dai, Jifeng and Qi, Haozhi and Xiong, Yuwen and Li, Yi and Zhang, Guodong and Hu, Han and Wei, Yichen},
	booktitle={Proceedings of the IEEE international conference on computer vision},
	pages={764--773},
	year={2017}
}
@inproceedings{deformablev2,
	title={Deformable convnets v2: More deformable, better results},
	author={Zhu, Xizhou and Hu, Han and Lin, Stephen and Dai, Jifeng},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={9308--9316},
	year={2019}
}
@inproceedings{internimage,
	title={Internimage: Exploring large-scale vision foundation models with deformable convolutions},
	author={Wang, Wenhai and Dai, Jifeng and Chen, Zhe and Huang, Zhenhang and Li, Zhiqi and Zhu, Xizhou and Hu, Xiaowei and Lu, Tong and Lu, Lewei and Li, Hongsheng and others},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={14408--14419},
	year={2023}
}
@inproceedings{swin,
	title={Swin transformer: Hierarchical vision transformer using shifted windows},
	author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
	booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
	pages={10012--10022},
	year={2021}
}
@inproceedings{slide,
	title={Slide-transformer: Hierarchical vision transformer with local self-attention},
	author={Pan, Xuran and Ye, Tianzhu and Xia, Zhuofan and Song, Shiji and Huang, Gao},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={2082--2091},
	year={2023}
}
@inproceedings{cswin,
	title={Cswin transformer: A general vision transformer backbone with cross-shaped windows},
	author={Dong, Xiaoyi and Bao, Jianmin and Chen, Dongdong and Zhang, Weiming and Yu, Nenghai and Yuan, Lu and Chen, Dong and Guo, Baining},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={12124--12134},
	year={2022}
}
@article{p2t,
	title={P2T: Pyramid pooling transformer for scene understanding},
	author={Wu, Yu-Huan and Liu, Yun and Zhan, Xin and Cheng, Ming-Ming},
	journal={IEEE transactions on pattern analysis and machine intelligence},
	volume={45},
	number={11},
	pages={12760--12771},
	year={2022},
	publisher={IEEE}
}
@article{pvtv2,
	title={Pvt v2: Improved baselines with pyramid vision transformer},
	author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
	journal={Computational Visual Media},
	volume={8},
	number={3},
	pages={415--424},
	year={2022},
	publisher={Springer}
}
@inproceedings{metaformer,
	title={Metaformer is actually what you need for vision},
	author={Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={10819--10829},
	year={2022}
}
@inproceedings{mae,
	title={Masked autoencoders are scalable vision learners},
	author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={16000--16009},
	year={2022}
}
@inproceedings{Hybrid,
	title={Learning CNN on ViT: A Hybrid Model to Explicitly Class-specific Boundaries for Domain Adaptation},
	author={Ngo, Ba Hung and Do-Tran, Nhat-Tuong and Nguyen, Tuan-Ngoc and Jeon, Hae-Gon and Choi, Tae Jong},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={28545--28554},
	year={2024}
}
@article{Hybridsurvey,
	title={Exploring the Synergies of Hybrid CNNs and ViTs Architectures for Computer Vision: A survey},
	author={Yunusa, Haruna and Qin, Shiyin and Chukkol, Abdulrahman Hamman Adama and Yusuf, Abdulganiyu Abdu and Bello, Isah and Lawan, Adamu},
	journal={arXiv preprint arXiv:2402.02941},
	year={2024}
}
@article{kanwal2024equipping,
	title={Equipping computational pathology systems with artifact processing pipelines: a showcase for computation and performance trade-offs},
	author={Kanwal, Neel and Khoraminia, Farbod and Kiraz, Umay and Mosquera-Zamudio, Andr{\'e}s and Monteagudo, Carlos and Janssen, Emiel AM and Zuiverloon, Tahlita CM and Rong, Chunming and Engan, Kjersti},
	journal={BMC Medical Informatics and Decision Making},
	volume={24},
	number={1},
	pages={288},
	year={2024},
	publisher={Springer}
}
@inproceedings{resnet,
	title={Deep residual learning for image recognition},
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={770--778},
	year={2016}
}
@inproceedings{densenet,
	title={Densely connected convolutional networks},
	author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={4700--4708},
	year={2017}
}
@article{dilated,
	title={Multi-scale context aggregation by dilated convolutions},
	author={Yu, F},
	journal={arXiv preprint arXiv:1511.07122},
	year={2015}
}
@inproceedings{senet,
	title={Squeeze-and-excitation networks},
	author={Hu, Jie and Shen, Li and Sun, Gang},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={7132--7141},
	year={2018}
}
@inproceedings{cbam,
	title={Cbam: Convolutional block attention module},
	author={Woo, Sanghyun and Park, Jongchan and Lee, Joon-Young and Kweon, In So},
	booktitle={Proceedings of the European conference on computer vision (ECCV)},
	pages={3--19},
	year={2018}
}
@article{transformer,
	title={Attention is all you need},
	author={Vaswani, A},
	journal={Advances in Neural Information Processing Systems},
	year={2017}
}
@inproceedings{cvt,
	title={Cvt: Introducing convolutions to vision transformers},
	author={Wu, Haiping and Xiao, Bin and Codella, Noel and Liu, Mengchen and Dai, Xiyang and Yuan, Lu and Zhang, Lei},
	booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
	pages={22--31},
	year={2021}
}
@article{cct,
	title={Escaping the big data paradigm with compact transformers},
	author={Hassani, Ali and Walton, Steven and Shah, Nikhil and Abuduweili, Abulikemu and Li, Jiachen and Shi, Humphrey},
	journal={arXiv preprint arXiv:2104.05704},
	year={2021}
}
@article{focal,
	title={Focal self-attention for local-global interactions in vision transformers},
	author={Yang, Jianwei and Li, Chunyuan and Zhang, Pengchuan and Dai, Xiyang and Xiao, Bin and Yuan, Lu and Gao, Jianfeng},
	journal={arXiv preprint arXiv:2107.00641},
	year={2021}
}
@article{focalnet,
	title={Focal modulation networks},
	author={Yang, Jianwei and Li, Chunyuan and Dai, Xiyang and Gao, Jianfeng},
	journal={Advances in Neural Information Processing Systems},
	volume={35},
	pages={4203--4217},
	year={2022}
}
@article{mobilevit,
	title={Mobilevit: light-weight, general-purpose, and mobile-friendly vision transformer},
	author={Mehta, Sachin and Rastegari, Mohammad},
	journal={arXiv preprint arXiv:2110.02178},
	year={2021}
}
@inproceedings{valanarasu2021medical,
	title={Medical transformer: Gated axial-attention for medical image segmentation},
	author={Valanarasu, Jeya Maria Jose and Oza, Poojan and Hacihaliloglu, Ilker and Patel, Vishal M},
	booktitle={Medical image computing and computer assisted intervention--MICCAI 2021: 24th international conference, Strasbourg, France, September 27--October 1, 2021, proceedings, part I 24},
	pages={36--46},
	year={2021},
	organization={Springer}
}
@inproceedings{yolov3,
	title={Yolov3: An incremental improvement},
	author={Farhadi, Ali and Redmon, Joseph},
	booktitle={Computer vision and pattern recognition},
	volume={1804},
	pages={1--6},
	year={2018},
	organization={Springer Berlin/Heidelberg, Germany}
}
@article{ThyNet,
	title={Deep learning-based artificial intelligence model to assist thyroid nodule diagnosis and management: a multicentre diagnostic study},
	author={Peng, Sui and Liu, Yihao and Lv, Weiming and Liu, Longzhong and Zhou, Qian and Yang, Hong and Ren, Jie and Liu, Guangjian and Wang, Xiaodong and Zhang, Xuehua and others},
	journal={The Lancet Digital Health},
	volume={3},
	number={4},
	pages={e250--e259},
	year={2021},
	publisher={Elsevier}
}
@inproceedings{hiera,
	title={Hiera: A hierarchical vision transformer without the bells-and-whistles},
	author={Ryali, Chaitanya and Hu, Yuan-Ting and Bolya, Daniel and Wei, Chen and Fan, Haoqi and Huang, Po-Yao and Aggarwal, Vaibhav and Chowdhury, Arkabandhu and Poursaeed, Omid and Hoffman, Judy and others},
	booktitle={International Conference on Machine Learning},
	pages={29441--29454},
	year={2023},
	organization={PMLR}
}
@inproceedings{resnext,
	title={Aggregated residual transformations for deep neural networks},
	author={Xie, Saining and Girshick, Ross and Doll{\'a}r, Piotr and Tu, Zhuowen and He, Kaiming},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={1492--1500},
	year={2017}
}
@inproceedings{mpvit,
	title={Mpvit: Multi-path vision transformer for dense prediction},
	author={Lee, Youngwan and Kim, Jonghee and Willette, Jeffrey and Hwang, Sung Ju},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={7287--7296},
	year={2022}
}
@inproceedings{davit,
	title={Davit: Dual attention vision transformers},
	author={Ding, Mingyu and Xiao, Bin and Codella, Noel and Luo, Ping and Wang, Jingdong and Yuan, Lu},
	booktitle={European conference on computer vision},
	pages={74--92},
	year={2022},
	organization={Springer}
}