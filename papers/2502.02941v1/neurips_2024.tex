\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2024


% ready for submission
% \usepackage{neurips_2024}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
    % \usepackage[preprint]{neurips_2024}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2024}


% to avoid loading the natbib package, add option nonatbib:
\usepackage[nonatbib,final]{neurips_2024}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors


\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{subcaption}
\usepackage{colortbl}
\usepackage{color}
\usepackage{multirow}
\usepackage{autobreak}
\usepackage{caption}
% \usepackage[ruled,linesnumbered]{algorithm2e}
\usepackage{makecell}
% \SetKwInOut{Parameter}{Parameters}
\usepackage{soul}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{amssymb}
\usepackage{amsmath}
% \usepackage{boondox-cal}
% \usepackage{boondox-calo}
% \usepackage{dutchcal}
\usepackage{amsthm}
\usepackage{diagbox}
\usepackage{bbding}
\usepackage{listings}
% \usepackage{minted}
% \usepackage{pythonhighlight}
% \usepackage{arydshln} 
% \usepackage{fontawesome}
% \usepackage{bm}

\usepackage{algorithm}
% \usepackage{algorithmic}
\usepackage{eqparbox}
\usepackage{array}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\renewcommand{\algorithmicrequire}{ \textbf{Input:}} %Use Input in the format of Algorithm
\renewcommand{\algorithmicensure}{ \textbf{Output:}} %UseOutput in the format of Algorithm

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\usepackage{mathtools}
\newcommand{\defeq}{\vcentcolon=}
\newcommand{\eqdef}{=\vcentcolon}

\newcommand{\mymodel}{Fast T2T}
\newcommand{\x}{\mathbf{x}}
\newcommand{\f}{\mathbf{f}}
\definecolor{white}{HTML}{F0F0F4}

% \title{T2T-CNS: Optimization Consistency for Train-phase Distribution Learning and Test-phase Gradient Search in Combinatorial Optimization}

% \title{Optimization Consistency for Distribution Learning and  Gradient Search in Combinatorial Optimization}

\title{Optimization Consistency Models for Solving Combinatorial Optimization in Lightning Speedup}

\title{Lightening Speedup with Optimization Consistency Models for Solving Combinatorial Optimization}

\title{Optimization Consistency Models for Solving Combinatorial Optimization in a Flash {\color{yellow} \faBolt}}

\title{Fast T2T: The Optimization Consistency Models for Solving Combinatorial Problems in Few Shots}

\title{Fast T2T: The Optimization Consistency Models for Solving Combinatorial Problems in Few Shots}

\title{Fast T2T: Optimization Consistency Speeds Up Diffusion-Based Training-to-Testing Solving for Combinatorial Optimization}

% \title{Fast T2T: Training-Testing  for Solving Combinatorial Problems in Few Shots}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


\author{%
  Yang Li$^{1\dag}$, Jinpei Guo$^{1\dag}$, Runzhong Wang$^{2}$,  Hongyuan Zha$^3$, Junchi Yan$^1$~\thanks{Correspondence author. $\dag$ denotes equal contribution.  This work was partly supported by NSFC (92370201, 62222607) and Shanghai Municipal Science and Technology Major Project under Grant 2021SHZDZX0102.} \\
  $^1$Dept. of CSE \& School of AI \& MOE Key Lab of AI, Shanghai Jiao Tong University\\
  $^2$Massachusetts Institute of Technology\\
  $^3$The Chinese University of Hong Kong, Shenzhen\\
  \texttt{\{yanglily,mike0728,yanjunchi\}@sjtu.edu.cn} \\
  \texttt{runzhong@mit.edu, zhahy@cuhk.edu.cn}\\
  % code: \url{https://github.com/Thinklab-SJTU/Fast-T2T}\\
  % examples of more authors
  % \And
  % Jinpei Guo$^{\dag}$ \\
  % Shanghai Jiao Tong University \\
  % \texttt{mike0728@sjtu.edu.cn} \\
  % \AND
  % Runzhong Wang \\
  % Massachusetts Institute of Technology \\
  % \texttt{runzhong@mit.edu} \\
  % \And
  % Hongyuan Zha \\
  % The Chinese University of Hong Kong, Shenzhen \\
  % \texttt{zhahy@cuhk.edu.cn} \\
  % \And
  % Junchi Yan\thanks{Correspondence author. $\dag$ denotes equal contribution.  This work was partly supported by NSFC (92370201, 62222607) and Shanghai Municipal Science and Technology Major Project under Grant 2021SHZDZX0102.} \\
  % Shanghai Jiao Tong University \\
  % \texttt{yanjunchi@sjtu.edu.cn} \\
}


\begin{document}


\maketitle


\begin{abstract}
Diffusion models have recently advanced Combinatorial Optimization (CO) as a powerful backbone for neural solvers. However, their iterative sampling process requiring denoising across multiple noise levels incurs substantial overhead. We propose to learn direct mappings from different noise levels to the optimal solution for a given instance, facilitating high-quality generation with minimal shots. This is achieved through an optimization consistency training protocol, which, for a given instance, minimizes the difference among samples originating from varying generative trajectories and time steps relative to the optimal solution. The proposed model enables fast single-step solution generation while retaining the option of multi-step sampling to trade for sampling quality, which offers a more effective and efficient alternative backbone for neural solvers. In addition, within the training-to-testing (T2T) framework, to bridge the gap between training on historical instances and solving new instances, we introduce a novel consistency-based gradient search scheme during the test stage, enabling more effective exploration of the solution space learned during training. It is achieved by updating the latent solution probabilities under objective gradient guidance during the alternation of noise injection and denoising steps. We refer to this model as Fast T2T. Extensive experiments on two popular tasks, the Traveling Salesman Problem (TSP) and Maximal Independent Set (MIS), demonstrate the superiority of Fast T2T regarding both solution quality and efficiency, even outperforming LKH given limited time budgets. Notably, Fast T2T with merely one-step generation and one-step gradient search can mostly outperform the SOTA diffusion-based counterparts that require hundreds of steps, while achieving tens of times speedup. The codes are publicly available at \url{https://github.com/Thinklab-SJTU/Fast-T2T}.\looseness=-1
\end{abstract}
% disrupts the local structure of the given solution by the noising process of diffusion and updates latent probabilities using gradient guidance from the optimization objective.

% \vspace{-3pt}
\section{Introduction}\label{sec:intro}
% \vspace{-3pt}
Combinatorial Optimization (CO) problems, which involve optimizing discrete variables under given objectives, are essential in computer science and operational research. Due to the inherent computational difficulty, e.g. NP-hardness,  solving efficiency poses significant challenges and requires exhaustive human efforts to design solving heuristics. Recent progress in this domain has shown promise in automatically learning heuristics with Machine Learning (ML) in a data-driven manner~\cite{BengioEJOR20,kool2018attention,joshi2019efficient,kwon2020pomo,kim2022sym,qiu2022dimes,sun2023difusco,li2023t2t}, bringing practical advantages in both quality and speed, especially when the instances are within a certain domain. In addition, learning can help quickly uncover new heuristics for new problems or new instance distributions where experts are not there.

Learning-based solvers for CO typically employ neural networks to generate neural predictions for solution construction or search guidance, aiming to minimize either the objective score~\cite{kool2018attention,kwon2020pomo,kim2022sym,qiu2022dimes,min2024unsupervised} or the deviation from reference solutions~\cite{vinyals2015pointer,joshi2019efficient,hudson2022graph,fu2021generalize,luo2024neural}. The problem-solving task places significant demands on the testing performance of the model, while optimizing the average performance across training data does not ensure optimal performance for every encountered test instance. Thus, methods~\cite{bello2016neural,hottung2021efficient,qiu2022dimes,li2023t2t} have been proposed to perform tailored optimization on neural predictions for every testing instance. In particular, generative modeling like diffusion has shown promise in learning instance-conditioned quality solution distributions~\cite{sun2023difusco,li2023t2t} with robust expressive power to achieve state-of-the-art performance, which also provides more informative support for further exploitation like gradient search in the solving stage, which was previously proposed as the diffusion-based training-to-testing (T2T) framework~\cite{li2023t2t}. However, a major drawback of the diffusion backbone lies in its costly inference process, which necessitates tens or hundreds of denoising steps to solve one problem instance. This limitation in inference speed is crucial since CO seeks to achieve the highest solution quality within the shortest possible time, where both performance and efficiency are pivotal metrics in this pursuit. Although the diffusion solvers~\cite{sun2023difusco,li2023t2t} can exhibit superiority in inference speed compared to certain traditional methods and prior learning-based solvers, there remains substantial potential for speed enhancement, where bolstering this aspect could provide fundamental support and several-fold speedup for neural solvers based on generative modeling.

% Diffusion models~\cite{sohl2015deep,ho2020denoising,song2020denoising,austin2021structured,hoogeboom2021argmax} have shown robust expressive power and effective problem-solving capabilities for CO~\cite{sun2023difusco,li2023t2t}.

\begin{figure}[!tb]
    \centering
    \includegraphics[width=0.88\linewidth]{figs/overview.pdf}
    % \vspace{-5pt}
    \caption{Optimization consistency models for CO solving where the model learns how to map from varying levels of noise to the solution distribution, conditioned on the problem graph instance.}
    \label{fig:overview}
    % \vspace{-15pt}
\end{figure}

To resolve this issue, drawing inspiration from the successful practice of consistency models~\cite{song2023consistency} for image generation, we propose the optimization consistency models to speed up the diffusion-based T2T framework, dubbed as {\mymodel}, specifically for optimization problem-solving. We follow \cite{li2023t2t} to approach CO problems as conditional generation tasks, with the goal of modeling the distribution of high-quality solutions specific to given problem instances. As illustrated in Fig.~\ref{fig:overview}, {\mymodel} builds upon the methodology foundation of the discrete diffusion models~\cite{sohl2015deep,austin2021structured,hoogeboom2021argmax} where a smooth transition from random uniform noise to the high-quality solution distribution is established. Given a problem instance, {\mymodel} trains the conditional prediction consistency directly from varying noise levels to the solution distribution centered on the optimal solution to enable fast one-step solution distribution estimation. Meanwhile, to bridge the disparity between data-driven training and problem-solving, {\mymodel} incorporates a novel objective gradient search for every instance in the testing phase based on the trained optimization consistency mappings.

Specifically, for the solving task, the model is expected to deliver the optimal solution output to the best extent possible for a given input instance. Thus, we define the optimization consistency property for the optimization scenario by conditional generation: \textit{conditoned on a given instance $G$, points on all trajectories of all noising steps consistently map to the optimal solution of $G$.} Compared to the diffusion prediction of the data distribution from noising step $t$ to step $t-1$, the consistency modeling enables generating solutions ($\mathbf{x}_0$ in Fig.~\ref{fig:overview}) from random noise vectors ($\mathbf{x}_T$ in Fig.~\ref{fig:overview}) by a single step of model inference. This is achieved by an optimization consistency training protocol that minimizes the difference among samples originating from varying trajectories and noising steps relative to the optimal solution.  The model retains the capability for multi-step sampling to trade for sampling quality by alternating noise introduction on $\mathbf{x}_0$ to generate a less noisy point $\mathbf{x}_t$ and solution reconstruction to obtain a new $\mathbf{x}_0$. Additionally, we design a novel objective gradient-based search on top of the learned consistency mapping to further explore the learned solution distribution for every test instance. We introduce instance-specific guidance from the objective to the learned solution prior $p_\theta(\x|G)$ and obtain the posterior $p_\theta(\x|y^*,G)$ where $y^*$  represents the optimal objective score given instance $G$, thereby directing the sampling process to the optimal $\x^*$. It specifically entails minimizing the free energy corresponding to the posterior by updating the probability parameters of intermediate noisy points through exponential gradient updates guided by the objective function during the alternation of noise injection and denoising steps.

We show the efficacy of {\mymodel} on two typical CO problems for edge-decision and node-decision types respectively, i.e., Traveling Salesman Problem (TSP) and Maximum Independent Set (MIS). We show that {\mymodel}, even with a single-step initial solution generation and a single-step gradient search, can mostly outperform the SOTA diffusion-based counterparts with hundreds of inference steps. Meanwhile, due to its reduced step requirement, {\mymodel} naturally demands significantly less inference time to achieve comparable quality, with more steps for further enhancement.

The highlights of this paper include: \textbf{1)} We introduce the optimization consistency condition and establish {\mymodel} based on the proposed optimization consistency models to facilitate fast high-quality CO solving, which offers a highly effective and efficient backbone for learning-based solvers. \textbf{2)} To complement the learned prior and bridge the disparity between data-driven training and the requirement of problem-solving, we introduce a novel gradient search with objective guidance based on consistency mappings to conduct a tailored search for every test instance. \textbf{3)} Extensive experiments show that {\mymodel} exhibits strong performance superiority over existing SOTA neural solvers on benchmark datasets across various scales.\looseness=-1

% the promising performance of the proposed {\mymodel}.

% Empirically, {\mymodel} exhibits strong performance superiority over existing state-of-the-art neural solvers on benchmark datasets across various scales.
% \vspace{-3pt}
\section{Related Work}
% \vspace{-3pt}
\textbf{Machine Learning for Combinatorial Optimization.} Current learning-based CO solvers can be categorized into constructive approaches and improvement-based approaches. Constructive approaches refer to autoregressive methods~\cite{khalil2017learning,kool2018attention,kwon2020pomo,hottung2021learning,kim2022sym} that directly construct solutions by sequentially determining decision variables until a complete solution is constructed, and non-autoregressive methods~\cite{joshi2019efficient,fu2021generalize,geisler2022generalization,qiu2022dimes,sun2023difusco,zheng2024learning} that predict soft-constrained solutions in one shot and then perform post-processing to achieve feasibility. Improvement-based solvers~\cite{d2020learning,wu2021learning,chen2019learning,li2021learning,hougeneralize} learn to iteratively refine a solution through local search operators toward minimizing the optimization objective. 

% Such approaches have been testified in a wide range of graph combinatorial optimization problems including edge-decision problems like routing problems e.g. Traveling Salesman Problem~\cite{joshi2019efficient,sun2023difusco,li2023t2t} and Vehicle Routing Problem~\cite{kool2018attention,kwon2020pomo}, Graph Matching~\cite{wang2019learning,wang2023linsatnet} and node-decision problems like Maximum Independent Set~\cite{boether_dltreesearch_2022,li2023t2t,zhang2023let}, (Maximum) Satisfiability~\cite{selsam2018learning,li2022nsnet} and so on.

% and generating adversarial samples for robustness~\cite{geisler2021generalization,lu2022roco}

Generative modeling for CO has recently shown promise with its potent representational capabilities and informative distribution estimation. It models the problem-solving task as a conditional generation task for learning solution distributions conditioned on given instances~\cite{hottung2021learning,cheng2022policy,sun2023difusco,du2023hubrouter,zhang2023let,li2023t2t}. Drawing from diffusion models, DIFUSCO~\cite{sun2023difusco} has attained SOTA performance in solving TSP and MIS. Nonetheless, it does not incorporate any instance-specific search paradigms to fully capitalize on the estimated solution distribution. Addressing this limitation, the T2T framework~\cite{li2023t2t} further introduces an objective-guided gradient search process during solving to leverage the learned distribution. However, every aspect of this system, including distribution learning and gradient search, hinges on the diffusion model for step-by-step generation. This reliance renders the diffusion-based approaches computationally inefficient and impedes further search computations to trade for solution quality.

% Two lines of work dominate this domain: the first involves modeling the problem-solving task as a conditional generation task for learning solution distributions conditioned on given instances~\cite{hottung2021learning,cheng2022policy,sun2023difusco,du2023hubrouter,zhang2023let,li2023t2t}; the other involves generating valuable problem instances to support problem-solving, e.g., augmenting real-world data to overcome data bottlenecks~\cite{you2019g2sat,li2023hardsatgen,geng2023deep,chen2024mixsatgen}.

\textbf{Diffusion Models and Consistency Models.} Diffusion models entail a dual process comprising noise injection and learnable denoising, wherein neural networks predict the data distribution at each step based on the data from the previous step. For Diffusion in continuous space~\cite{sohl2015deep,song2019generative,ho2020denoising,song2020denoising,song2020improved,nichol2021improved,dhariwal2021diffusion}, the solution trajectories can be modeled by Probability Flow ODE~\cite{song2020score}. Similar paradigms have also been adopted for discrete data using binomial or multinomial/categorial noises~\cite{sohl2015deep,austin2021structured,hoogeboom2021argmax}. On top of the foundation of diffusion models, consistency models~\cite{song2023consistency} define the self-consistency for every generation trajectory and introduce a consistency training paradigm for continuous data to directly learn the mappings from noise to the data. Inspired by this paradigm, we define the optimization consistency condition tailored for the optimization scenario, which requires consistency across multiple trajectories and time steps with the optimal solution as the target in a conditional context, thereby proposing the optimization consistency models as the solver embodiment. The models are employed on the discrete multinomial data for the benefit of CO.

% Methods have been proposed for fast diffusion sampling, including faster numerical ODE solvers~\cite{song2020denoising,zhang2022fast,lu2022dpm} and distillation techniques~\cite{luhman2021knowledge,salimans2022progressive,meng2023distillation,zheng2023fast}. However, these methods still necessitate more than ten inference steps or require a costly data collection process.

% Diffusion models are bottlenecked by their slow sampling speed and 

% \vspace{-3pt}
% \section{Methodology}
% \vspace{-3pt}
\section{Preliminaries and Problem Definition}\label{sec:preliminaries}
% \vspace{-3pt}
Adopting the conventions established in \cite{karalias2020erdos,wang2022unsupervised} we define $\mathcal{G}$ as the collection of CO problem instances represented by graphs $G(V,E)\in \mathcal{G}$, where $V$ and $E$ denote the nodes and edges respectively. CO problems can be broadly classified into two types based on the solution composition: edge-decision problems that involve determining the selection of edges and node-decision problems that determine nodes. Let $\mathbf{x}\in\{0,1\}^{N\times 2}$ denote the optimization variable, where each entry is represented by a one-hot vector, i.e., each entry with $(0,1)$ indicates that it is included in $\mathbf{x}$ and $(1,0)$ indicates the opposite. For edge-decision problems, $N={n^2}$ and $\mathbf{x}_{i,j}$ indicates whether $E_{i,j}$ is included in $\mathbf{x}$. For node-decision problems, $N=n$ and $\mathbf{x}_{i}$ indicates whether $V_{i}$ is included in $\mathbf{x}$. The feasible set $\Omega$ consists of $\mathbf{x}$ satisfying specific constraints as feasible solutions. A CO problem on $G$ aims to find a feasible $\mathbf{x}$ that minimize the given objective function $l(\cdot;G):\{0,1\}^{N\times 2}\to\mathbb{R}_{\geq 0}$:
\begin{equation}
    \min_{\mathbf{x}\in\{0,1\}^{N\times 2}}l(\mathbf{x};G)\quad \mathrm{ s.t. } \quad \mathbf{x}\in\Omega
\end{equation}
TSP is defined on an undirected complete graph $G=(V,E)$, where $V$ represents $n$ cities and each edge $E_{i,j}$ is assigned a non-negative weight $w_{i,j}$ representing the distance between cities $i$ and $j$. The problem revolves around identifying a Hamiltonian cycle of minimum weight in $G$. For MIS, given an undirected graph $G=(V,E)$, an independent set is a subset of vertices $S\subseteq V$ such that no two vertices in $S$ are adjacent in $G$. MIS entails finding an independent set of maximum cardinality in $G$.
% \vspace{-3pt}

\section{Training-Stage Optimization Consistency Modeling}
\label{sec:train}
% \vspace{-3pt}
% notations
\subsection{Solution Encoding and Noising Process}
% \vspace{-3pt}
Using the notations in Sec.~\ref{sec:preliminaries}, we represent the solutions of CO problems as $\mathbf{x}\in\{0,1\}^{N\times 2}$ with $\mathbf{x}\in\Omega$. The distribution of $\mathbf{x}$ is represented by $N$ Bernoulli distributions indicating whether each entry should be selected, i.e., $p(\mathbf{x})\in [0,1]^{N\times 2}$. The objective of utilizing generative modeling for problem-solving is to capture the distribution of high-quality solutions conditioned on a given instance $G$, denoted as $p_\theta(\mathbf{x}|G)$. The neural models try to establish transition trajectories from random uniform noise to high-quality soft-constrained solutions, i.e., $\mathbf{x}\in\{0,1\}^{N\times 2}$. These soft-constrained solutions are directly sampled from the estimated Bernoulli distributions where feasibility constraints can be broadly captured through learning and eventually hard-guaranteed by post-processing.

% can not directly generate solutions that satisfy hard constraints of $\mathbf{x}\in\Omega$, thus we

To establish the transition trajectories of data, we follow the discrete diffusion modeling~\cite{sun2023difusco,li2023t2t} to define the noising process, which takes the initial solution $\mathbf{x}_0$ sampled from the distribution $q(\mathbf{x}_0|G)$ and progressively introduces noise to generate a sequence of latent variables $\mathbf{x}_{1:T}=\mathbf{x}_1,\mathbf{x}_2,\cdots,\mathbf{x}_T$. Specifically, the noising process is formulated as $q(\mathbf{x}_{1:T}|\mathbf{x}_0) = \prod_{t=1}^{T} q(\mathbf{x}_t|\mathbf{x}_{t-1})$, which is achieved by  multiplying $\mathbf{x}_t\in\{0,1\}^{N\times2}$ at step $t$ with a forward transition probability matrix $\mathbf{Q}_t\in[0,1]^{2\times2}$ which indicates the transforming probability of decision state. We set $\mathbf{Q}_t=\left[ \begin{array}{cc}
   \beta_t  & 1-\beta_t \\
   1-\beta_t  & \beta_t
\end{array}\right]$~\cite{austin2021structured}, where $\beta_t\in [0,1]$ such that the transition matrix is doubly stochastic with strictly positive entries, ensuring that the stationary distribution is uniform which is an unbiased prior for sampling. The noising process for each step and the $t$-step marginal are formulated as:
\begin{align}
    q(\mathbf{x}_t|\mathbf{x}_{t-1})=\texttt{Cat}(\mathbf{x}_t;\mathbf{p}=\mathbf{x}_{t-1}\mathbf{Q}_t)\quad \text{and}\quad
    q(\mathbf{x}_t|\mathbf{x}_0)=\texttt{Cat}(\mathbf{x}_t;\mathbf{p}=\mathbf{x}_{0}\overline{\mathbf{Q}}_t)
    % ,\quad \text{with}\ \  \overline{\mathbf{Q}}_t=\mathbf{Q}_1\mathbf{Q}_2\cdots\mathbf{Q}_t
\end{align}
where $\texttt{Cat}(\mathbf{x};\mathbf{p})$ is a categorical distribution over $N$ one-hot variables and  $\overline{\mathbf{Q}}_t=\mathbf{Q}_1\mathbf{Q}_2\cdots\mathbf{Q}_t$.

\begin{figure}[tb!]
% \begin{wrapfigure}{r}{0.50\linewidth}%[!tb]
    \centering
    % \subfigure[Self-Consistency]{\raisebox{10pt}{\includegraphics[width=0.48\linewidth]{figs/self-consistency.pdf}}}
    % \subfigure[Optimization Consistency]
    % \vspace{-40pt}
	% {\includegraphics[width=1\linewidth]{figs/consistency.pdf}}
    {\includegraphics[width=0.97\linewidth]{figs/consistency-both1.pdf}}
    % \vspace{-8pt}
    \caption{Vannila consistency models are trained to map points on any trajectory to its origin. Optimization consistency enforces that all trajectories conditioned on $G$ consistently map to the same initial point, i.e., the optimal solution of $G$.}
    \label{fig:consistency}
    % \vspace{-10pt}
% \end{wrapfigure}
\end{figure}

% \vspace{-3pt}
\subsection{Optimization Consistency Training Scheme} 
% \vspace{-3pt}

Unlike the diffusion models modeling $p_\theta(\x_{t-1}|\x_{t}, G)$, we aim to directly map random noise to data by $p_\theta(\x_{0}|\x_t, G)$ in an optimization context. In continuous-time diffusion models defined on $(\epsilon,T]$~\cite{song2020score}, consistency models~\cite{song2023consistency} defines the self-consistency property as \textit{points on the same trajectory map to the same initial point}, and optimize the learned consistency function $f_\theta(\cdot,\cdot)$ to satisfy the requirement by: 1) boundary condition: $f_\theta(\x_\epsilon,\epsilon)=\x_\epsilon$; 2) self-consistency property: $f_\theta$ outputs consistent estimation for arbitrary pairs of $(\x_t,t)$ that belong to the same trajectory, i.e., $f_\theta(\x_t,t)=f_\theta(\x_{t^\prime},t^\prime),\forall\ t,t^\prime\in[\epsilon,T]$. The joint effect of these two constraints serves as the necessary and sufficient condition to achieve a reliable data prediction from noise step $T$ to data, i.e., $f_\theta(\x_T,T)\to\x_\epsilon$. In the optimization scenario of mapping instance $G$ to approximate its optimal solution $\x^*$, the generation process is conditioned on the problem instance $G$ with a reference optimal solution $\x^*$ serving as the commonly targeted initial point for all the conditional trajectories. Based on the discrete diffusion process with an explicit sampling process~\cite{austin2021structured,sun2023difusco,li2023t2t}, we use the consistency function to estimate the optimal solution distribution as a point estimate $\delta(\x-\x^*)$ where $\delta(\cdot)$ represents Dirac delta. Below defines optimization consistency for the conditional context of problem-solving.\looseness=-1

\begin{definition}[Optimization Consistency]
Given a solution trajectory $\{\x_t\}_{t\in[0,T]}$, we define the consistency function as $f:(\x_t,t,G)\mapsto \delta(\x-\x^*)$, which maintains the optimization consistency property: conditioned on instance $G$, all points along any trajectory map to its optimal solution, i.e., $f_\theta(\mathbf{x}_t^i,t,G)=f_\theta(\mathbf{x}_{t^\prime}^j,t^\prime,G)=\delta(\x-\x^*)$ for distinct trajectories $i$ and $j$ at distinct steps $t$ and $t^\prime$.
\end{definition}

% \vspace{-3pt}
% \subsection{Optimization Consistency Training Scheme}
% \vspace{-3pt}

As illustrated in Fig.~\ref{fig:consistency}, the goal of the consistency model $f_\theta$ in the optimization context, is to estimate the consistency function from data by learning to enforce optimization consistency. To achieve such consistency in the context of optimization to learn $f:G\mapsto \x^*$, given its nature as a conditional generation and the aim for an explicit optimal solution $\mathbf{x}^*$, we can seamlessly integrate $\mathbf{x}^*$ into the objective function for smooth training. Instead of optimizing the expectation of the variation of the consistency mappings over two noise points $\x$ and $\x^\prime$, i.e., $\mathcal{L}_\text{CM}(\theta)=\mathbb{E}\big[d\big(f_\theta\left(\x,t,G\right),f_\theta\left(\x^\prime,t^\prime,G\right)\big)\big]$, we introduce $\x^*$ to optimize the upper bound of $\mathcal{L}_\text{CM}$ through triangle inequality of distance measures as 
\begin{equation}
\mathcal{L}_\text{OptCM}(\theta) = \mathbb{E}\big[d\big(f_\theta(\x,t,G),\delta(\x-\x^*)\big) + d\big(f_\theta(\x^\prime,t^\prime,G),\delta(\x-\x^*)\big)\big] \geq \mathcal{L}_\text{CM}(\theta).
\end{equation}
Here $d(\cdot,\cdot)$ is a distance metric function. In this case, the boundary conditions become less significant, since we have already dispersed the information of $\mathbf{x}^*$ across all noise time steps. Therefore, we can directly utilize the neural network $\theta$ to estimate the consistency function $f_\theta(\cdot,\cdot,\cdot)$. In addition, all learned trajectories are expected to map to the optimal solution $\x^*$ given the instance $G$, and the estimated solution distribution is expected to center on $\x^*$. This calls for the requirement of consistency extending across all trajectories, rather than being confined within a single trajectory.
% that satisfies $\forall \x, \mathbf{y}: d(\x,\mathbf{y})\geq 0$ and $d(\x,\mathbf{y})=0$ if and only if $\x=\mathbf{y}$


\begin{definition}\label{loss}
    % Given instance $G\sim p_G$ and its optimal solution $x^*$, 
The optimization consistency loss for conditional problem-solving is defined as: 
\begin{equation}
\small
\mathcal{L}^{N_t}_\text{OptCM}(\theta) \defeq \mathbb{E}\left[\lambda(t_n)\left(d\left(f_\theta(\x_{t_n}^i,t_n,G),\delta(\x-\x^*)\right) + d\left(f_\theta(\x_{t_{n+1}}^j,t_{n+1},G),\delta(\x-\x^*)\right)\right)\right]
\end{equation}
where the expectation is taken with respect to $G\sim p_G$, $n\sim \mathcal{U}[1,N_t-1]$, $\mathbf{x}_{t_n}^i\sim \texttt{Cat}(\mathbf{x}_{t_n};\mathbf{p}=\mathbf{x}^*\overline{\mathbf{Q}}_{t_n})$, and $\mathbf{x}_{t_{n+1}}^j\sim \texttt{Cat}(\mathbf{x}_{t_{n+1}};\mathbf{p}=\mathbf{x}^*\overline{\mathbf{Q}}_{t_{n+1}})$. Here $\mathcal{U}[1,N_t-1]$ denotes the uniform distribution over $\{1,2,\cdots, N-1\}$, $\lambda(\cdot)\in\mathbb{R}^+$ is a positive weighting function.
\end{definition}
Since the model outputs $N$ Bernoulli distributions as the distribution of $\x_0$, we adopt the binary cross entropy to measure the distance between the estimation $ p_\theta(\x)$ and $\delta(\x-\x^*)$. We set $\lambda(t_n)\equiv 1$ and discover a decent empirical performance. $\mathbf{x}_{t_n}^i$ and $\mathbf{x}_{t_{n+1}}^j$ are identically and independently sampled from different noising trajectories, in comparison to $\mathbf{x}_{t_n}^i\sim \texttt{Cat}(\mathbf{x}_{t_n};\mathbf{p}=\mathbf{x}^*\overline{\mathbf{Q}}_{t_n}),\mathbf{x}_{t_{n+1}}^i\sim \texttt{Cat}(\mathbf{x}_{t_{n+1}};\mathbf{p}=\x_{t_n}\mathbf{Q}_{t_n+1}\cdots\mathbf{Q}_{t_{n+1}})$ where $\mathbf{x}_{t_n}^i$ and $\mathbf{x}_{t_{n+1}}^i$ are from the same trajectory. Since very close $t_n$ and $t_{n+1}$ would make Eq.~\ref{loss} very easy to learn, we reschedule the time horizon into $N_t-1$ sub-intervals $t_1=1<t_2<\cdots<t_{N_t}=T$ through the cosine denoising schedular such that $t_i=\lfloor \cos \left ( \frac{1-\pi \cdot ci}{2}\right)\cdot T\rfloor$ following DDIM~\cite{song2020denoising}. This training procedure enforces the model to learn conditional consistency across different noise steps to consistently map to the optimal solution $\x^*$ of the given condition $G$. Note that although we enforce the noise to map to the Dirac delta on $\x^*$, the generative modeling process with a single sample per instance condition during training still enables the model to estimate a solution distribution (centering around the optimal solution) to enjoy diversity to enhance performance via parallel sampling, as evidenced by the experiments in Table.~\ref{tab:tsp500-1000}.

Specifically for implementation, the network $\theta$ is embodied as an anisotropic graph neural network with edge gating mechanisms~\cite{joshi2019efficient}, and instance $G$ serves as a part of the conditional input as the node or edge features. For TSP, the 2D coordinates of the vertices serve as the instance condition, and the input edge features are from the embeddings of entries in $\mathbf{x}_t$ integrated with the embedding of the input time step $t$. For MIS, the edges $E$ serve as the instance condition and the node embeddings are from $\mathbf{x}_t$ to collectively form the input. After the GNN iterations, the features of the decision variables (edges for TSP and nodes for MIS) are projected to 2-D outputs $ p_\theta(\mathbf{x}_0|\mathbf{x}_t,G)\in[0,1]^{N\times2}$ featuring $N$ Bernoulli distributions for $N$ entries in $\mathbf{x}_0$  via a linear layer followed by a Softmax layer.

% Specifically for implementation, the network $\theta$ is embodied as an anisotropic graph neural network with edge gating mechanisms~\cite{joshi2019efficient}, and instance $G$ serves as a part of the conditional input as the node or edge features. For TSP, the instance condition consists of 2D coordinates of the vertices, which we further use a position embedding layer and a linear layer to extract the initial node feature. The initial edge features are similarly extracted by employing a consistent mechanism for each entry of $\mathbf{x}_t$. We use linear layers to extract the embedding of the input time step $t$, which is then integrated with the edge embedding in each GNN iteration through addition. For MIS, the edges $E$ serve as the instance condition and the node embeddings are from $\mathbf{x}_t$ to collectively form the input. The embeddings are extracted through position embedding layers and linear layers. The features of the decision variables (edges for TSP and nodes for MIS) are projected to 2-D outputs $ p_\theta(\mathbf{x}_0|\mathbf{x}_t,G)\in[0,1]^{N\times2}$ featuring $N$ Bernoulli distributions for $N$ entries in $\mathbf{x}_0$  via a linear layer followed by a Softmax layer.

% \vspace{-3pt}
\section{Testing-Stage Problem Solving via Consistency-Based Gradient Search}\label{sec:test}
% \label{sec:test}
% \vspace{-3pt}

The solving involves obtaining the initial solution from the raw consistency sampling process and a consistency-based gradient search process with objective feedback for iterative solution improvement.

% \vspace{-3pt}
\subsection{Consistency Sampling for Initial Solutions}\label{sec:sampling}
% \vspace{-3pt}

\begin{wrapfigure}{r}{0.45\linewidth}
\begin{minipage}[t]{1\linewidth}
\vspace{-20pt}
\begin{algorithm}[H]
% \setstretch{0.5}
    \caption{Multistep Consistency Sampling}
    \label{algorithm1}
    \begin{algorithmic}
    \State {\bfseries Input:} Consistency model $f_\theta(\cdot,\cdot,\cdot)$, graph problem instance $G$, sequence of time points $\tau_1>\tau_2>\cdots>\tau_{N_\tau-1}$
    \State Sample $\x_T$ from uniform distribution $\mathcal{U}$
    \State $p_\theta(\x_0|G)\leftarrow f_\theta(\x_T,T,G)$
    \State $\x_0\sim  p_\theta(\x_0|G)$
    \For{$n=1$ to $N_\tau-1$}
        \State Sample $\x_{\tau_n}\sim\texttt{Cat}(\x_{\tau_n};\mathbf{p}=\x_0\overline{\mathbf{Q}}_{\tau_n})$
        % \State \textit{\textcolor{blue}{// Bernoulli distribution:} }
        \State $p_\theta(\x_0|G)\leftarrow f_\theta(\x_{\tau_n},\tau_n,G)$
        \State $\x_0\sim p_\theta(\x_0|G)$ %\textit{\small\textcolor{blue}{// Bernoulli distribution sampling} }
    \EndFor
    \State {\bfseries Output:} Solution $\x_0$
    \end{algorithmic}
\end{algorithm}
\end{minipage}
\vspace{-10pt}
\end{wrapfigure}

With a well-trained $f_\theta(\cdot,\cdot,\cdot)$, we generate solutions for a given instance $G$ by sampling $\x_T$ from the  uniform distribution and then evaluate it for $\x_0\sim p_\theta(\x_0)=f_\theta(\x_T,T,G)$. This process requires only one forward pass through the consistency model, resulting in sampling in a single step. Solution sampling with multiple steps of inferences can also be accomplished via alternating denoising and noise injection, allowing trading runtime for improved solving quality. Given a sequence of time points $\tau_1>\tau_2>\cdots>\tau_{N_\tau-1}$, in time step $\tau_n$, the multistep sampling process adds noise to the $\x_0$ obtained from the last step $\tau_{n-1}$ by $\x_{\tau_n}\sim\texttt{Cat}(\x_{\tau_n};\mathbf{p}=\x\overline{\mathbf{Q}}_{\tau_n})$, then denoise to find the new solution by $\x_0\sim f_\theta(\x_{\tau_n},\tau_n,G)$, as shown in Algorithm.~\ref{algorithm1}.

% \vspace{-3pt}
\subsection{Consistency-based Gradient Search with Objective Feedback}
% \vspace{-3pt}

% \begin{equation}
%     y^*=\min_\x l(\x;G) \quad \mathrm{ s.t. } \quad \mathbf{x}\in\Omega.
% \end{equation}
For CO, the integration of objective optimization facilitates direct engagement with the objective and enables efficient exploration of the solution space to minimize the score. \cite{li2023t2t} has established such a procedure for the step-by-step denoising function,  yet it is not transferable to the consistency function, and incorporating objective optimization may prove more challenging as the consistency function maps across longer distance time steps. With the learned conditional solution prior $p_\theta(\x|G)$, this section aims to introduce a constraint $c(\x,y^*|G)$ on $\x$ to this prior for inference, where $y^*$ represents the optimal objective score given the instance $G$. That is, we want to find an approximation to the posterior distribution $p_\theta(\x|y^*,G)\propto p_\theta(\x|G)c(\x,y^*|G)$ to guide the sampling process to the optimal $\x^*$.\looseness=-1

Here we follow ~\cite{li2023t2t} to determine $c(\x,y^*|G)$ by utilizing energy-based modeling~\cite{lecun2006tutorial} with the energy function $E(y,\x,G)=\left|y-l(\x;G)\right|$, which quantifies the compatibility between $y$ and $(\x,G)$, and it reaches zero when $y$ is exactly the objective score of $\x$ with respect to $G$. Such a design enables the best $y$
matching the inputs to maintain the highest probability density and the probability density is positively correlated with the matching degree. Then we employ the \emph{Gibbs distribution} to characterize the probability distribution over a collection of arbitrary energies:
\begin{equation}\label{eq:c}
\vspace{-3pt}
    c(\x,y|G)=\frac{\exp(-E(y,\x,G))}{\int_{y^\prime}\exp(-E(y^\prime,\x,G))}=Z\exp(-\left|y-l(\x;G)\right|)
\end{equation}
Following \cite{graikos2022diffusion}, we introduce an approximate variational posterior $q(\x|G)$ and the free energy
% \begin{equation}
%     F=-\mathbb{E}_{q(\x|G)}\left[\log p_\theta(\x|G)+\log c(\x,y^*|G) - \log q(\x)\right]
% \end{equation}
\begin{equation}\label{eq:F}
\begin{aligned}
% \vspace{-3pt}
    F
    % &=-\mathbb{E}_{q(\x|G)q(\mathbf{h}|\x,G)}\left[\log p_\theta(\x,\mathbf{h}|G)+\log c(\x,y^*|G) - \log q(\x)q(\mathbf{h}|\x,G)\right]\\
    &=\underbrace{-\mathbb{E}_{q(\x|G)q(\mathbf{h}|\x,G)}\left[\log p_\theta(\x,\mathbf{h}|G)- \log q(\x)q(\mathbf{h}|\x,G)\right]}_{F_1} \underbrace{-\mathbb{E}_{q(\x|G)}\left[\log c(\x,y^*|G)\right]}_{F_2}
\end{aligned}
% \vspace{-3pt}
\end{equation}
is minimized when $\text{KL}(q(\x|G)||p_\theta(\x|y^*,G))$ is minimized. Here $\mathbf{h}=\x_1,\cdots,\x_T$ represent the latent variables. Through the diffusion process, we can obtain $q(\mathbf{h}|\x)=\prod_{t=1}^T q(\x_t|\x_{t-1})$. We apply an approximation to the posterior over $\x=\x_0$ as a point estimate $q(\x|G)=\delta(\x-\mathbf{\boldsymbol{\eta}})$. $F_1$ aligns with the objective of the consistency and diffusion models and $F_2$ can be transformed using Eq.~\ref{eq:c}:
\begin{equation}
\vspace{-3pt}
\small
% \begin{aligned}
F_1=\mathbb{E}_{q(\mathbf{h}|\mathbf{\boldsymbol{\eta}},G)}\left[\log\frac{q(\mathbf{h}|\mathbf{\boldsymbol{\eta}},G)}{p_\theta(\mathbf{\boldsymbol{\eta}},\mathbf{h}|G)}\right] \quad \text{and} \quad F_2=-\log c(\mathbf{\boldsymbol{\eta}},y^*|G)=l(\mathbf{\boldsymbol{\eta}};G) -\log Z -y^*.
    % =\sum_t \text{KL}\left(q(\x_0|G)||p_\theta(\x_0|\x_t,G)\right)\\
    % =\sum_t \lambda(t) \texttt{BCE}(p_\theta(\x_0|\x_t,G),)
% \end{aligned}
\end{equation}
% While with Eq.~\ref{eq:c}, the second term $F_2$ can be expressed as
% \begin{equation}
%     F_2=-\log c(\mathbf{\boldsymbol{\eta}},y^*|G)=l(\mathbf{\boldsymbol{\eta}};G) -\log Z -y^*. %\approx l(f_\theta(\x_t,t,G);G)+Z^\prime
% \end{equation}

% \begin{wrapfigure}{r}{0.5\linewidth}
% \begin{minipage}[t]{1\linewidth}
% \vspace{-25pt}
% \begin{algorithm}[H]
% % \setstretch{0.5}
%     \caption{Consistency-based Gradient Search}
%     \label{algorithm1}
%     \begin{algorithmic}
%     \State {\bfseries Input:} Consistency model $f_\theta(\cdot,\cdot,\cdot)$, problem instance $G$, initial solution $\x_0$, noise degree $\alpha$
%     \State $\mathbf{p}\leftarrow \x_0\overline{\mathbf{Q}}_{\alpha T}$
%     \State $p_\theta(\x_0|G)\leftarrow f_\theta(\mathbb{E}_\mathbf{p}\x_{\alpha T},{\alpha T},G)$
%     \State $\mathbf{p}\leftarrow \mathbf{p} \odot \exp(\lambda\nabla_\mathbf{p} d(p_\theta(\x_0|G),\delta(\x))$
    
    
%     \State $p_\theta(\x_0)\leftarrow f_\theta(\x_T,T,G)$
%     \State $\x_0\sim  p_\theta(\x_0)$
%     \For{$n=1$ to $N_\tau-1$}
%         \State Sample $\x_{\tau_n}\sim\texttt{Cat}(\x_{\tau_n};\mathbf{p}=\x_0\overline{\mathbf{Q}}_{\tau_n})$
%         % \State \textit{\textcolor{blue}{// Bernoulli distribution:} }
%         \State $ p_\theta(\x_0)\leftarrow f_\theta(\x_{\tau_n},\tau_n,G)$
%         \State $\x_0\sim  p_\theta(\x_0)$ \textit{\small\textcolor{blue}{// Bernoulli distribution sampling} }
%     \EndFor
%     \State {\bfseries Output:} Solution $\x_0$
%     \end{algorithmic}
% \end{algorithm}
% \end{minipage}
% \end{wrapfigure}

Initializing $\mathbf{\boldsymbol{\eta}}$ from Sec.~\ref{sec:sampling}, we aim to update $\boldsymbol{\eta}$ to reach conditional solution distribution $p_\theta(\x|y^*,G)$ through exponential gradient decent on the latent continuous probability $\mathbf{p}_\x=p(\x_{\alpha T})=\boldsymbol{\eta}\overline{\mathbf{Q}}_{\alpha T}\in[0,1]^{N\times 2}$ at each iteration minimizing $F_1$ and $F_2$. Here $\mathbf{p}_\x$ parameterizes $N$ Bernoulli distributions and  $\alpha$ serves as a hyperparameter to control the noise degree. We view $\mathbf{p}_\x$  as the expectation of $\x_{\alpha T}$ over $\mathbf{p}_\x$, i.e., $\mathbb{E}_{\mathbf{p}_\x}(\x_{\alpha T})=\mathbf{p}_\x$, since $\mathbf{p}_\x$ is a multivariate Bernoulli. To obtain reliable gradients on $\mathbf{p}_\x$, we estimate the expected distribution of $\x_0$ by $f_\theta(\mathbf{p}_\x,\alpha T,G)$. Note $F_1$ is exactly the (implicit) objective of the diffusion and consistency models, i.e., the variational upper bound of the negative log-likelihood with the targeted data $\mathbf{\boldsymbol{\eta}}$, which we optimize by minimizing the consistency over the re-predicted solutions $d\big(f_\theta(\mathbf{p}_\x,\alpha T,G),\delta(\x-\mathbf{\boldsymbol{\eta}})\big)$. While $F_2$ can be optimized by minimizing $l\big(f_\theta(\mathbf{p}_\x,\alpha T,G);G\big)+\text{Const}(\mathbf{p}_\x)$, where the objectives are defined following \cite{li2023t2t} as $l_{\text{MIS}}(\x;G) \triangleq -\sum_{1\leq i\leq N}\x_i+\beta \sum_{(i,j)\in E}\x_i\x_j$ and $l_{\text{TSP}}=\x\odot D$ where $D\in\mathbb{R}_+^{n\times n}$ denotes the distance matrix.\looseness=-1

In each iteration, with current $\boldsymbol{\eta}$, we obtain $\mathbf{p}_\x=\boldsymbol{\eta}\overline{\mathbf{Q}}_{\alpha T}$, $p_\theta(\boldsymbol{\eta})=f_\theta\left(\mathbf{p}_\x,\alpha T,G\right)$ and update $\mathbf{p}_\x$ by
\begin{equation}
\begin{aligned}
% \vspace{-3pt}
\mathbf{p}_\x \leftarrow \mathbf{p}_\x \odot \exp\big\{-\nabla_{\mathbf{p}_\x} \big[\lambda_1 \cdot d\big(\mathbb{E}_{p_\theta(\boldsymbol{\eta})}\boldsymbol{\eta},\delta\left(\x-\mathbf{\boldsymbol{\eta}}\right)\big) + \lambda_2 \cdot l\big(\mathbb{E}_{p_\theta(\boldsymbol{\eta})}\boldsymbol{\eta};G\big)\big]\big\}
\end{aligned}
\end{equation}
where $\lambda_1,\lambda_2$ are weighting hyperparameters. Then we sample $\x_{\alpha T}\sim \mathbf{p}_\x$ and reconstruct a new distribution estimate of $\boldsymbol{\eta}$ by $p_\theta^\prime(\boldsymbol{\eta})=f_\theta(\x_{\alpha T},\alpha T,G)$. To guarantee the feasibility, we utilize the logits of $p_\theta(\boldsymbol{\eta})$ and $p_\theta^\prime(\boldsymbol{\eta})$ to produce the heatmaps where each element denotes each edge/node's confidence to be selected, and then adopt post-processing\footnote{We follow previous works~\cite{qiu2022dimes,sun2023difusco,li2023t2t} to perform greedy decoding by sequentially inserting edges or nodes with the highest confidence if there are no conflicts. For TSP, the 2Opt heuristic~\cite{lin1973effective} is optionally applied.} to obtain two feasible solutions. This iteration concludes by outputting the lower-cost solution as $\boldsymbol{\eta}$. 

% Empirically, we show that even a single step of gradient search can achieve significant performance gain.




% Thus, $F_1$ can be minimized by minimizing the consistency over the re-predicted solutions
% \begin{equation}
%     d\left(f_\theta(\x_t,t,G),\delta(\x-\mathbf{\boldsymbol{\eta}})\right), \x_t\sim \texttt{Cat}(\x_t;\mathbf{p}=\mathbf{\boldsymbol{\eta}}\overline{\mathbf{Q}}_t).
% \end{equation}


% f theta 到底输出啥，距离的定义，eq 3，BCE Loss



% \vspace{-3pt}
\section{Experiments}\label{sec:experiments}
% \vspace{-3pt}


\begin{table}[tb!]	
\centering 
\caption{Results with \textbf{Greedy Decoding} on TSP-50 and TSP-100. RL: Reinforcement Learning, SL: Supervised Learning, G: Greedy Decoding. $^*$~denotes results that are quoted from previous works.}%(best in bold)
% \vspace{-7pt}
\resizebox{0.75\linewidth}{!}{
    \begin{tabular}{lcccccccc}
    \toprule
    \multirow{2}{*}{\textsc{Algorithm}}&\multirow{2}{*}{\textsc{Type}}	& \multicolumn{3}{c}{TSP-50}&&\multicolumn{3}{c}{TSP-100} \\\cmidrule{3-5}\cmidrule{7-9}
    && \textsc{Length}$\downarrow$ & \textsc{Drop}$\downarrow$ & \textsc{Time}$\downarrow$ && \textsc{Length}$\downarrow$ & \textsc{Drop}$\downarrow$ & \textsc{Time}$\downarrow$ 
 \\	\midrule
Concorde~\cite{applegate2006concorde} & Exact & 5.69 & 0.00\% & (3m)  && 7.76 & 0.00\% & (12m) \\
LKH3~\cite{helsgaun2017extension} & Heuristics & 5.69 & 0.00\% & (3m)  && 7.76 & 0.00\% & (33m)\\
2Opt~\cite{croes1958method} & Heuristics & 5.86 & 2.95\% & -- && 8.03 & 3.54\%& -- \\
\midrule


AM$^*$~\cite{kool2018attention} & RL+G & 5.80 & 1.76\%  & (2s) && 8.12 & 4.53\% & (6s) \\
GCN$^*$~\cite{joshi2019efficient} & SL+G & 5.87 & 3.10\% & (55s) && 8.41 & 8.38\% & (6m)\\
Transformer$^*$~\cite{bresson2021transformer} & RL+G & 5.71 & 0.31\% & (14s) && 7.88 & 1.42\% & (5s) \\
POMO$^*$~\cite{kwon2020pomo} & RL+G & 5.73 & 0.64\% & (1s)  && 7.84 & 1.07\% & (2s) \\
Sym-NCO$^*$~\cite{kim2022sym} & RL+G & -- & -- & -- && 7.84 & 0.94\%  & (2s)\\
Image Diffusion$^*$~\cite{graikos2022diffusion} & SL+G & 5.76 & 1.23\% & -- && 7.92 & 2.11\% & -- \\\midrule

DIFUSCO (T$_\text{s}$=1)~\cite{sun2023difusco} & SL+G & 6.42 & 12.84\% & (16s)  && 9.32 & 20.20\% & (20s)  \\

DIFUSCO (T$_\text{s}$=50)~\cite{sun2023difusco} & SL+G & 5.71 & 0.45\% & (9m)  && 7.85 & 1.21\% & (9m)  \\

DIFUSCO (T$_\text{s}$=100)~\cite{sun2023difusco} & SL+G & 5.71 & 0.41\% & (18m)  && 7.84 & 1.16\% & (18m)  \\

\rowcolor{white}{\mymodel} (T$_\text{s}$=1) & SL+G & 5.71 & 0.31\% & \textbf{(11s)} && 7.86 & 1.31\% & \textbf{(16s)} \\

\rowcolor{white}{\mymodel} (T$_\text{s}$=3) & SL+G & 5.69 & 0.05\% & (25s) && 7.77 & 0.17\% & (33s) \\

\rowcolor{white}{\mymodel} (T$_\text{s}$=5) & SL+G & \textbf{5.69} & \textbf{0.02\%}& (1m) && \textbf{7.76} & \textbf{0.07\%} & (1m) \\

\midrule

T2T (T$_\text{s}$=1,T$_\text{g}$=1)~\cite{li2023t2t} & SL+G & 6.15 & 8.15\% &  (55s) && 9.00 & 16.09\% & \textbf{(1m)}   \\

T2T (T$_\text{s}$=50,T$_\text{g}$=15)~\cite{li2023t2t} & SL+G & 5.69 & 0.07\% &  (18m) && 7.77 & 0.20\% & (18m)   \\

T2T (T$_\text{s}$=50,T$_\text{g}$=30)~\cite{li2023t2t} & SL+G & 5.69 & 0.03\% &  (26m) && 7.76 & 0.11\% & (42m)   \\

\rowcolor{white} {\mymodel} (T$_\text{s}$=1,T$_\text{g}$=1) & SL+G & 5.69 & 0.03\% & \textbf{(54s)} && 7.76 & 0.10\% & \textbf{(1m)} \\

\rowcolor{white} {\mymodel} (T$_\text{s}$=2,T$_\text{g}$=2) & SL+G & 5.69 & 0.02\% & (2m) && 7.76 & 0.04\% & (2m) \\

\rowcolor{white} {\mymodel} (T$_\text{s}$=3,T$_\text{g}$=3) & SL+G & \textbf{5.69} & \textbf{0.01\%} & (3m) && \textbf{7.76} & \textbf{0.03\%} & (3m) \\
% \midrule

% AM~\cite{kool2018attention} & RL+G+2Opt & 5.77 & 1.41\% & && 8.02 & 3.32\% & \\
% GCN~\cite{joshi2019efficient} & SL+G+2Opt & 5.70 & 0.12\%  & && 7.81 & 0.62\%  &\\
% Transformer~\cite{bresson2021transformer} & RL+G+2Opt & 5.70 & 0.16\% & && 7.85 & 1.19\% & \\
% POMO~\cite{kwon2020pomo} & RL+G+2Opt & 5.73 & 0.63\% & && 7.82 & 0.82\% &\\
% Sym-NCO~\cite{kim2022sym} & RL+G+2Opt & -- & -- & && 7.82 & 0.76\% & \\\midrule
% DIFUSCO (T$_\text{s}$=50)~\cite{sun2023difusco} & SL+G+2Opt & \\
% T2T (T$_\text{s}$=50,T$_\text{g}$=15)~\cite{li2023t2t} & SL+G+2Opt & \\

% \rowcolor{white}{\mymodel} (T$_\text{s}$=1) & SL+G & 5.69 & 0.07\% & (15s) && 7.77 & 0.23\% & (19s) \\

% \rowcolor{white}{\mymodel} (T$_\text{s}$=1) & SL+G & 5.69 & 0.07\% & (15s) && 7.77 & 0.23\% & (19s) \\

% \rowcolor{white} {\mymodel} (T$_\text{s}$=1,T$_\text{g}$=1) & SL+G & \textbf{5.69} & \textbf{0.02\%} & (1m) && \textbf{7.76} & \textbf{0.05\%} & (1m) \\

% \rowcolor{white} {\mymodel} (T$_\text{s}$=1,T$_\text{g}$=1) & SL+G & \textbf{5.69} & \textbf{0.02\%} & (1m) && \textbf{7.76} & \textbf{0.05\%} & (1m) \\

\bottomrule
\end{tabular}
}
% \vspace{-15pt}
\label{tab:tsp50-100}
\end{table}

We test on two CO problems, TSP and MIS. The comparison includes SOTA learning-based solvers, heuristics, and exact solvers for each problem. To configure the generative-based models, we adopt T$_\text{s}$ and T$_\text{g}$ to represent the number of inference steps in initial solution sampling and the number of gradient search steps, respectively. For diffusion-based baselines including DIFUSCO~\cite{sun2023difusco} and T2T~\cite{li2023t2t}, we adopt T$_\text{s}$=50 and involve 3 iterations with 5 guided denoising steps per iteration for T2T's gradient search, i.e., T$_\text{g}$=15. {\mymodel} can achieve promising results with merely one-step initial solution sampling and one-step gradient search, i.e., T$_\text{s}$=1 and T$_\text{g}$=1. However, the affordability of model inference facilitates a more extensive exploration of the solution distribution through a thorough search.\looseness=-1

% To balance the inference time, for experiments with runtime measurement, {\mymodel} utilizes a reduced number of sampling steps for constructing the initial solutions, specifically 20 steps. While DIFUSCO, as an important baseline, adopts 120 inference steps for TSP and 50 steps for MIS. The models for both TSP and MIS are trained with 1000 denoising steps, i.e., $T=1000$. For gradient search, {\mymodel} generally involves 3 iterations with 10 guided denoising steps for each. See more details in Appendix.

% \vspace{-3pt}
\subsection{Experiments for TSP}\label{sec:exp-tsp}
% \vspace{-3pt}



\textbf{Datasets.} A TSP instance includes $N$ $2$-D coordinates and a reference solution obtained by heuristics. Training and testing instances are generated via uniformly sampling $N$ nodes from the unit square $[0,1]^2$, which is a standard procedure as adopted in~\cite{kool2018attention,hottung2021learning,joshi2019efficient,da2020learning,qiu2022dimes,sun2023difusco,li2023t2t}. We experiment on various problem scales including TSP-50, 100, 500, and 1000. 

% This section also incorporates results on real-world TSPLIB\footnote{\url{http://comopt.ifi.uni-heidelberg.de/software/TSPLIB95/}} dataset.

\textbf{Metrics.} Following~\cite{kool2018attention,joshi2019efficient,qiu2022dimes,sun2023difusco,li2023t2t}, we adopt three evaluation metrics: 1) Length: the average total distance or cost of the solved tours w.r.t. the corresponding instances, as directly corresponds to the objective. 2) Drop: the relative performance drop w.r.t. length compared to the global optimality or the reference solution; 3) Time: the average computational time to solve the problems.

% \textbf{Graph Sparsification.} For large-scale TSP problems, we follow~\cite{sun2023difusco,li2023t2t} to employ sparse graphs, as sparsified by constraining each node to connect to only its $k$ nearest neighbors, determined by Euclidean distances. For TSP-500, we set $k=50$, and for TSP-1000, $k=100$. This strategy prevents the exponential increase in edges typical in dense graphs as node count rises.


\textbf{Results for TSP-50/100.} Given the recent success of learning-based solvers in achieving near-optimal performance on small-scale problems, we follow \cite{li2023t2t} to assess methods within the naive greedy decoding setting, aiming for a more discernable evaluation. The comparison includes state-of-the-art learning-based methods with greedy decoding and traditional solvers. Hyperparameter $\alpha$ is set as $0.2$. The sampling steps and gradient search steps are explicitly marked. Table.~\ref{tab:tsp50-100} shows that {\mymodel} with merely one-step sampling steps approximates diffusion-based solvers with 100 sampling steps with a slight average performance gain of  \textbf{5.7\%}, yet with an average speedup of \textbf{82.8x}. A similar conclusion can be made for methods with gradient search with an average performance gain of \textbf{4.5\%} and speedup of \textbf{35.4x}. {\mymodel} variants with more sampling and gradient search steps achieve \textbf{82.1\%} performance gain with \textbf{14.7x} speedup compared to previous state-of-the-art diffusion-based counterparts.\looseness=-1



\begin{figure*}[tb!]
\centering
 \begin{minipage}[h]{0.65\textwidth}
  \centering

% \begin{table*}[tb!]	
% \centering 
\makeatletter\def\@captype{table}\makeatother\caption{Results on TSP-500 and TSP-1000. AS: Active Search, S: Sampling Decoding, BS: Beam Search. $^*$~denotes results that are quoted from previous works~\cite{li2023t2t,qiu2022dimes}.}%(best in bold)
% Best results are marked in \textbf{bold}.
% \vspace{-7pt}
    \resizebox{1\linewidth}{!}{
    \begin{tabular}{lcccccccc}
    \toprule
    \multirow{2}{*}{\textsc{Algorithm}}&\multirow{2}{*}{\textsc{Type}}	& \multicolumn{3}{c}{TSP-500}&&\multicolumn{3}{c}{TSP-1000} \\\cmidrule{3-5}\cmidrule{7-9}
    && \textsc{Length}$\downarrow$ & \textsc{Drop}$\downarrow$ & T\footnotesize{IME} && \textsc{Length}$\downarrow$ & \textsc{Drop}$\downarrow$ & T\footnotesize{IME}
 \\	\midrule

\multicolumn{9}{c}{\emph{Mathematical Solvers or Heuristics}}\\\midrule

Concorde~\cite{applegate2006concorde} & Exact & 16.55 & 0.00\% & 37.66m && 23.12 & 0.00\% & 6.65h \\
Gurobi~\cite{llc2020gurobi} & Exact & 16.55 & 0.00\% & 45.63h && -- & -- & -- \\
LKH-3~\cite{helsgaun2017extension} & Heuristics & 16.55 & 0.00\% & 46.28m && 23.12 & 0.00\% & 2.57h \\
% LKH-3 (less trails)~\cite{} & Heuristics & 16.55 & 0.00\% & 3.03m && 23.12 & 0.00\% & 7.73m \\
Farthest Insertion & Heuristics & 18.30 & 10.57\% & 0s && 25.72 & 11.25\% & 0s \\\midrule

\multicolumn{9}{c}{\emph{Learning-based Solvers with Greedy Decoding}}\\\midrule

AM$^*$~\cite{kool2018attention} & RL+G & 20.02 & 20.99\% & 1.51m && 31.15 & 34.75\% & 3.18m \\
GCN$^*$~\cite{joshi2019efficient} & SL+G & 29.72 & 79.61\% & 6.67m && 48.62 & 110.29\% & 28.52m \\
POMO+EAS-Emb$^*$~\cite{hottung2021efficient}& RL+AS+G & 19.24 & 16.25\% & 12.80h && -- & -- & -- \\
POMO+EAS-Tab$^*$~\cite{hottung2021efficient}& RL+AS+G & 24.54 & 48.22\% & 11.61h && 49.56 & 114.36\% & 63.45h\\
DIMES$^*$~\cite{qiu2022dimes} & RL+G & 18.93 & 14.38\% & 0.97m && 26.58 & 14.97\% & 2.08m \\
DIMES$^*$~\cite{qiu2022dimes} & RL+AS+G & 17.81 & 7.61\% & 2.10h && 24.91 & 7.74\% & 4.49h \\

DIMES$^*$~\cite{qiu2022dimes} & RL+G+2Opt & 17.65 & 6.62\%  & 1.01m && 24.83 & 7.38\% & 2.29m  \\
DIMES$^*$~\cite{qiu2022dimes} & RL+AS+G+2Opt & 17.31 & 4.57\% & 2.10h && 24.33 & 5.22\% & 4.49h \\

\midrule

DIFUSCO (T$_\text{s}$=100)~\cite{sun2023difusco} & SL+G &  18.17 & 9.82\%  & 4m31s && 25.74 & 11.36\% & 14m20s \\

\rowcolor{white} {\mymodel} (T$_\text{s}$=1) & SL+G & 17.80 & 7.57\% & \textbf{17s} && 25.23 & 9.13\% & \textbf{55s} \\
\rowcolor{white} {\mymodel} (T$_\text{s}$=5) & SL+G & \textbf{17.53} & \textbf{5.94\%} & 22s && \textbf{24.57} & \textbf{6.29\%} & 1m21s \\

\midrule

T2T (T$_\text{s}$=50,T$_\text{g}$=30)~\cite{li2023t2t} & SL+G & 17.48 & 5.61\% & 6m23s && 25.21 & 9.04\% & 19m21s \\

\rowcolor{white} {\mymodel} (T$_\text{s}$=1,T$_\text{g}$=1) & SL+G & 17.26 & 4.28\% & \textbf{36s} && 24.60 & 6.42\% & \textbf{2m30s} \\
\rowcolor{white} {\mymodel} (T$_\text{s}$=5,T$_\text{g}$=5) & SL+G & \textbf{16.93} & \textbf{2.33\%} & 2m12s && \textbf{23.96} & \textbf{3.64\%} & 9m12s \\

\midrule

% DIFUSCO (T$_\text{s}$=1)~\cite{sun2023difusco} & SL+G+2Opt & 17.55 & 6.07\%  & 22s && 24.82 & 7.39\% &  \\
% DIFUSCO (T$_\text{s}$=50)~\cite{sun2023difusco} & SL+G+2Opt & 16.81 & 1.58\%  & 1m44s && 23.56 & 1.92\% &   \\
DIFUSCO (T$_\text{s}$=100)~\cite{sun2023difusco} & SL+G+2Opt & 16.80  & 1.50\%  & 4m40s && 23.55 & 1.89\% & 14m25s \\

\rowcolor{white} {\mymodel} (T$_\text{s}$=1) & SL+G+2Opt & 16.75 & 1.23\% & \textbf{15s} && 23.45 & 1.42\% & \textbf{57s} \\

% \rowcolor{white} {\mymodel} (T$_\text{s}$=3) & SL+G+2Opt & 16.67 & 0.76\% & 41s && 23.36 & 1.05\% &  \\

\rowcolor{white} {\mymodel} (T$_\text{s}$=5) & SL+G+2Opt & \textbf{16.70} & \textbf{0.90\%} & 22s && \textbf{23.38} & \textbf{1.14\%} & 1m20s \\

% \rowcolor{white} {\mymodel} (T$_\text{s}$=10) & SL+G+2Opt &  &  & &&  &  &  \\

\midrule


% T2T (T$_\text{s}$=1,T$_\text{g}$=1)~\cite{li2023t2t} & SL+G+2Opt & 17.45 & 5.47\% & 44s && 24.67 & 6.70\% &  \\

% T2T (T$_\text{s}$=50,T$_\text{g}$=15)~\cite{li2023t2t} & SL+G+2Opt & 16.69 & 0.89\% & 3m25s && -- & -- & --\\

T2T (T$_\text{s}$=50,T$_\text{g}$=30)~\cite{li2023t2t} & SL+G+2Opt & 16.68 & 0.82\% & 6m29s && 23.44 & 1.40\% & 19m39s  \\

\rowcolor{white} {\mymodel} (T$_\text{s}$=1,T$_\text{g}$=1) & SL+G+2Opt & 16.67 & 0.73\%  & \textbf{39s} && 23.35 & 1.00\% & \textbf{2m33s} \\

% \rowcolor{white} {\mymodel} (T$_\text{s}$=3,T$_\text{g}$=1) & SL+G+2Opt & 16.64 & 0.55\%  &  && &  & \\

% \rowcolor{white} {\mymodel} (T$_\text{s}$=3,T$_\text{g}$=3) & SL+G+2Opt & 16.61 & 0.40\%  & 1m46s && 23.27 & 0.65\% & \\

\rowcolor{white} {\mymodel} (T$_\text{s}$=5,T$_\text{g}$=5) & SL+G+2Opt & \textbf{16.61} & \textbf{0.39\%} & 2m10s && \textbf{23.25} & \textbf{0.58\%} & 8m37s \\

\midrule

\multicolumn{9}{c}{\emph{Learning-based Solvers with Sampling Decoding}}\\\midrule

EAN$^*$~\cite{deudon2018learning} & RL+S+2Opt & 23.75 & 43.57\% & 57.76m && 47.73 & 106.46\% & 5.39h \\
AM$^*$~\cite{kool2018attention} & RL+BS & 19.53 & 18.03\% & 21.99m && 29.90 & 29.23\% & 1.64h \\
GCN$^*$~\cite{joshi2019efficient} & SL+BS & 30.37 & 83.55\% & 38.02m && 51.26 & 121.73\% & 51.67m \\
DIMES$^*$~\cite{qiu2022dimes} & RL+S & 18.84 & 13.84\% & 1.06m && 26.36 & 14.01\% & 2.38m \\
DIMES$^*$~\cite{qiu2022dimes} & RL+AS+S & 17.80 & 7.55\% & 2.11h && 24.89 & 7.70\% & 4.53h \\
DIMES$^*$~\cite{qiu2022dimes} & RL+S+2Opt & 17.64 & 6.56\% & 1.10m && 24.81 & 7.29\% & 2.86m \\
DIMES$^*$~\cite{qiu2022dimes} & RL+AS+S+2Opt & 17.29 & 4.48\% & 2.11h && 24.32 & 5.17\% & 4.53h \\

\midrule

DIFUSCO (T$_\text{s}$=100)~\cite{sun2023difusco} & SL+S & 17.55 & 6.05\% & 14m3s && 25.12 & 8.64\% & 51m49s \\

\rowcolor{white} {\mymodel} (T$_\text{s}$=1) & SL+S & 17.63 & 6.56\% & \textbf{53s} && 24.91 & 7.76\% & \textbf{3m2s} \\
\rowcolor{white} {\mymodel} (T$_\text{s}$=5) & SL+S & \textbf{17.02} & \textbf{2.85\%} & 1m7s && \textbf{24.07} & \textbf{4.10\%} & 4m39s \\

\midrule

T2T (T$_\text{s}$=50,T$_\text{g}$=30)~\cite{li2023t2t} & SL+S & 17.04 & 2.99\% & 19m33s && 24.85 & 7.49\% & 49m42s \\

\rowcolor{white} {\mymodel} (T$_\text{s}$=1,T$_\text{g}$=1) & SL+S & 17.08 & 3.21\% & \textbf{2m26s} && 24.43 & 5.67\% & \textbf{6m8s} \\
\rowcolor{white} {\mymodel} (T$_\text{s}$=5,T$_\text{g}$=5) & SL+S & \textbf{16.72} & \textbf{1.02\%} & 7m9s && \textbf{23.68} & \textbf{2.44\%} & 19m1s\\

\midrule

% DIFUSCO (T$_\text{s}$=1)~\cite{sun2023difusco} & SL+S+2Opt &  \\
% DIFUSCO (T$_\text{s}$=50)~\cite{sun2023difusco} & SL+S+2Opt &  \\
DIFUSCO (T$_\text{s}$=100)~\cite{sun2023difusco} & SL+S+2Opt & 16.69 & 0.87\% & 19m8s && 23.42 & 1.31\% & 51m56s \\

\rowcolor{white} {\mymodel} (T$_\text{s}$=1) & SL+S+2Opt & 16.72 & 1.02\% & \textbf{59s} && 23.39 & 1.17\% & \textbf{3m12s} \\

% \rowcolor{white} {\mymodel} (T$_\text{s}$=3) & SL+S+2Opt & \\

\rowcolor{white} {\mymodel} (T$_\text{s}$=5) & SL+S+2Opt & \textbf{16.63} & \textbf{0.49\%} & 1m8s && \textbf{23.30} & \textbf{0.77\%} & 4m50s \\

% \rowcolor{white} {\mymodel} (T$_\text{s}$=10) & SL+S+2Opt &  &  & &&  &  &  \\

\midrule


% T2T (T$_\text{s}$=1,T$_\text{g}$=1)~\cite{li2023t2t} & SL+S+2Opt &   \\

% T2T (T$_\text{s}$=50,T$_\text{g}$=15)~\cite{li2023t2t} & SL+S+2Opt &\\

T2T (T$_\text{s}$=50,T$_\text{g}$=30)~\cite{li2023t2t} & SL+S+2Opt & 16.63 & 0.48\% & 19m42s && 23.37 & 1.07\% & 51m3s\\

\rowcolor{white} {\mymodel} (T$_\text{s}$=1,T$_\text{g}$=1) & SL+S+2Opt & 16.64 & 0.54\% & \textbf{2m33s} && 23.31 & 0.83\% & \textbf{6m14s} \\

% \rowcolor{white} {\mymodel} (T$_\text{s}$=3,T$_\text{g}$=1) & SL+S+2Opt &  \\

\rowcolor{white} {\mymodel} (T$_\text{s}$=5,T$_\text{g}$=5) & SL+S+2Opt & \textbf{16.58} & \textbf{0.21\%} & 6m51s && \textbf{23.22} & \textbf{0.42\%} & 18m17s  \\
% \midrule

% Att-GCN & SL+MCTS & 16.97 & 2.54\% & 2.20m && 23.86 & 3.22\% & 4.10m \\
% DIMES & RL+MCTS & 16.87 & 1.93\% & 2.92m && 23.73 & 2.64\% & 6.87m \\
% DIMES & RL+AS+MCTS & 16.84 & 1.76\% & 2.15h && 23.69 & 2.46\% & 4.62h \\
% DIFUSCO & SL+MCTS &  & \% &  &&  & \% &  \\
% \rowcolor{white} \mymodel & SL+MCTS &  & \% &  &&  & \% &  \\

\bottomrule
\end{tabular}
}
% \vspace{-10pt}
\label{tab:tsp500-1000}
% \end{table*}

    \vspace{-5pt}

  \end{minipage}\quad
  \begin{minipage}[h]{0.29\textwidth}
   \centering


   % {\includegraphics[width=1\linewidth]{figs/step-drop.pdf}}
   % \vspace{-15pt}
   % \caption{Effect of step number to drop for diffusion/consistency based methods. GS stands for gradient search.}

   {\includegraphics[width=1\linewidth]{figs/time-drop-100-new.pdf}}
   \vspace{-15pt}
   \caption{Effect of runtime to optimality drop for {\mymodel} and LKH3 on TSP-100.}
   \label{fig:time-drop-100}
   \vspace{5pt}

   {\includegraphics[width=1\linewidth]{figs/time-drop-1000-new.pdf}}
   \vspace{-15pt}
   \caption{Effect of runtime to optimality drop for {\mymodel} and LKH3 on TSP-1000.}
   \label{fig:time-drop-1000}

    \vspace{5pt}

 {\includegraphics[width=1\linewidth]{figs/alpha-drop.pdf}}
   \vspace{-15pt}
   \caption{Effect of $\alpha$ to the performance drop.}
   \label{fig:alpha-drop}
   

    \vspace{-5pt}
   \end{minipage}
\end{figure*}


\textbf{Results for TSP-500/1000.} Learning-based solvers are compared using greedy decoding and sampling decoding ($\times$ 4), i.e., sampling multiple solutions and reporting the best one. Hyperparameter $\alpha$ is set as $0.2$. The sampling steps and gradient search steps are explicitly marked. Table.~\ref{tab:tsp500-1000} shows that {\mymodel} with merely one-step sampling steps averagely outperforms diffusion-based solvers with 100 sampling steps by a performance gain of  \textbf{10.1\%} and a speedup of \textbf{16.8x}. A similar conclusion can be made for methods with gradient search with an average performance gain of \textbf{14.9\%} and a speedup of \textbf{8.5x}. {\mymodel} variants with more sampling and gradient search steps achieve \textbf{52.1\%} performance gain with \textbf{7.4x} speedup compared to previous SOTA diffusion-based counterparts.



% \begin{table}[tb!]
\begin{wrapfigure}{r}{0.54\linewidth}
  \centering
  \vspace{-14pt}
\makeatletter\def\@captype{table}\makeatother\caption{Generalization results. \textit{Tour length} and \textit{drop} with \textbf{\emph{Greedy Decoding}} are reported.}
\vspace{-8pt}
     \resizebox{1\linewidth}{!}{
\begin{tabular}{crc|cccc}
    \toprule
    
    \multicolumn{2}{c}{\diagbox{Testing}{Training}} && TSP-50 & TSP-100 & TSP-500 & TSP-1000 \\
    \midrule
    
    \multirow{4}{*}{TSP-50} & DIFUSCO (T$_\text{s}$=50)$^*$~\cite{sun2023difusco} && \textit{5.69, 0.09\%} & 5.70, 0.25\% & 5.83, 2.55\% & 5.84, 2.71\% \\
    & T2T (T$_\text{s}$=50,T$_\text{g}$=30)$^*$~\cite{li2023t2t} && \textit{5.69, 0.02\%} & 5.70, 0.11\% & 5.78, 1.60\% & 5.75, 1.10\% \\
    & {\mymodel} (T$_\text{s}$=5,T$_\text{g}$=5) && \textit{5.69, 0.01\%} & 5.69, 0.02\% & 5.71, 0.36\% & 5.75, 1.02\% \\
    & {\mymodel} (T$_\text{s}$=20,T$_\text{g}$=20) && \textbf{\textit{5.69, 0.00\%}} & \textbf{5.69, 0.01\%} & \textbf{5.71, 0.21\%} & \textbf{5.73, 0.80\%} \\
    \midrule
    
    \multirow{4}{*}{TSP-100} & DIFUSCO (T$_\text{s}$=50)$^*$~\cite{sun2023difusco} && 7.87, 1.44\% & \textit{7.78, 0.23\%} & 8.03, 3.44\% & 8.02, 3.31\% \\
    & T2T (T$_\text{s}$=50,T$_\text{g}$=30)$^*$~\cite{li2023t2t} && 7.80, 0.55\% & \textit{7.77, 0.08\%} & 7.95, 2.47\% & 7.91, 1.96\% \\
    & {\mymodel} (T$_\text{s}$=5,T$_\text{g}$=5) && 7.77, 0.12\% & \textit{7.76, 0.02\%} & 7.79, 0.40\% & 7.80, 0.55\% \\
    & {\mymodel} (T$_\text{s}$=20,T$_\text{g}$=20) && \textbf{7.76, 0.08\%} & \textbf{\textit{7.76, 0.01\%}} & \textbf{7.77, 0.23\%} & \textbf{7.78, 0.34\%} \\
    \midrule

    \multirow{4}{*}{TSP-500} & DIFUSCO (T$_\text{s}$=50)$^*$~\cite{sun2023difusco} && 17.31, 4.61\% & 17.05, 3.04\% & \textit{16.78, 1.40\%} & 16.86, 1.85\% \\
    & T2T (T$_\text{s}$=50,T$_\text{g}$=30)$^*$~\cite{li2023t2t} && 17.18, 3.79\% & \textbf{16.92, 2.25\%} & \textit{16.68, 0.81\%} & 16.72, 1.00\% \\
    & {\mymodel} (T$_\text{s}$=5,T$_\text{g}$=5) && 16.99, 2.67\% & 17.02, 2.87\% & \textit{16.61, 0.36\%} & 16.63, 0.51\% \\
    & {\mymodel} (T$_\text{s}$=20,T$_\text{g}$=20) && \textbf{16.94, 2.34\%} & 16.97, 2.54\% & \textbf{\textit{16.58, 0.20\%}} &\textbf{ 16.60, 0.33\%} \\
    
    \midrule

    \multirow{4}{*}{TSP-1000} & DIFUSCO (T$_\text{s}$=50)$^*$~\cite{sun2023difusco} && 24.17, 4.54\% & 24.04, 3.98\% & 23.65, 2.30\% & \textit{23.63, 2.21\%} \\
    & T2T (T$_\text{s}$=50,T$_\text{g}$=30)$^*$~\cite{li2023t2t} && 24.20, 4.66\% & \textbf{23.85, 3.16\%} & 23.47, 1.51\% & \textit{23.41, 1.23\%} \\
    & {\mymodel} (T$_\text{s}$=5,T$_\text{g}$=5) && 23.12, 3.43\% & 24.08, 4.15\% & 23.31, 0.82\% & \textit{23.25, 0.56\%} \\
    & {\mymodel} (T$_\text{s}$=20,T$_\text{g}$=20) && \textbf{23.86, 3.22\%} & 24.01, 3.87\% & \textbf{23.25, 0.58\%} & \textbf{\textit{23.20, 0.36\%}} \\
    \bottomrule
    \end{tabular}
    }
     \label{tab:generalization1}
     \vspace{-15pt}
% \end{table}
\end{wrapfigure}




\textbf{Results for Generalization.} Based on the problem set \{TSP-50, TSP-100, TSP-500, TSP-1000\}, we train the model on a specific problem scale and then evaluate it on all problem scales. Table ~\ref{tab:generalization1} presents the generalization results of {\mymodel} compared with diffusion-based counterparts with greedy decoding. The results show the satisfying cross-domain generalization ability of {\mymodel}, e.g., the model trained on TSP-1000 achieves less than a 0.6\% optimality gap on all other problem scales.

\textbf{Soving Time vs. Optimality Drop on TSP-100/1000.}  Fig.~\ref{fig:time-drop-100} and Fig.~\ref{fig:time-drop-1000} illustrate the solving progress via the runtime-drop curves of {\mymodel} and the prominent mathematical solver LKH3~\cite{helsgaun2017extension}. The comparison is conducted on TSP-100 and TSP-1000. We are excited to discover that {\mymodel} surpasses LKH3 in the early solving stage while also performing comparably in the later stage. This suggests that {\mymodel} can serve as an effective rapid solver for approximate solutions outperforming LKH3, which may find widespread applications requiring prompt responses. Other neural solver baselines fall far outside the comparable range; please refer to Fig.~\ref{fig:step-drop} for an intuitive illustration.

\textbf{Ablation and Hyperparameter Study.} Fig.~\ref{fig:alpha-drop} illustrates the performance variation when altering the noise hyperparameter $\alpha$, and we discover a relatively superior and stable performance at $\alpha=0.2$. Fig.~\ref{fig:step-drop} shows the performance variation when varying the sampling and gradient search steps. We also include DIFUSCO~\cite{sun2023difusco} and T2T~\cite{li2023t2t} for direct comparison, in order to see whether diffusion-based methods can achieve promising results using minimal sampling steps. In this case, we let the gradient search steps equal to the sampling steps for {\mymodel} and T2T. The results show a significant performance overwhelm of {\mymodel} to diffusion-based counterparts.

% \begin{figure}[tb!]
%     \centering 
%     \includegraphics[width=0.5\linewidth]{figs/alpha-Drop.pdf}

%     \vspace{-8pt}
%     \caption{Effect of $\alpha$ and initialization steps to the performance drop. For each subgraph, the left represents the greedy decoding, while the right represents the sampling decoding.}
%     \label{fig:alpha&init}
%     \vspace{-5pt}
% \end{figure}

\begin{figure*}[tb!]
\centering
 \begin{minipage}[h]{0.65\textwidth}
  \centering

% \begin{table*}[tb!]	
% \centering 
\makeatletter\def\@captype{table}\makeatother
\caption{Results on MIS. TS: Tree Search, UL: Unsupervised Learning. $^*$~denotes results quoted from previous works~\cite{li2023t2t,zhang2023let}.}%(best in bold)
\vspace{-5pt}
\resizebox{1\linewidth}{!}{
    \begin{tabular}{lcccccccc}
    \toprule
    \multirow{2}{*}{\textsc{Algorithm}}&\multirow{2}{*}{\textsc{Type}}	& \multicolumn{3}{c}{RB-[200-300]}&&\multicolumn{3}{c}{ER-[700-800]} \\\cmidrule{3-5}\cmidrule{7-9}
    && S\footnotesize{IZE}$\uparrow$ & \textsc{Drop}$\downarrow$ & T\footnotesize{IME} && S\footnotesize{IZE}$\uparrow$ & \textsc{Drop}$\downarrow$ & T\footnotesize{IME}
 \\	\midrule
 

KaMIS~\cite{lamm2016finding} & Heuristics & 20.10$^*$ & -- & 1h24m && 44.87$^*$ & -- & 52.13m \\
Gurobi~\cite{llc2020gurobi} & Exact & 19.98 & 0.01\% & 47m34s && 41.28 & 7.78\% & 50.00m \\
\midrule
\midrule

Intel~\cite{li2018combinatorial} & SL+G & -- & -- & -- && 34.86 & 22.31\% & 6.06m \\
DIMES~\cite{qiu2022dimes} & RL+G & -- & -- & -- && 38.24 & 14.78\% & 6.12m \\

\midrule

DIFUSCO (T$_\text{s}$=100)~\cite{sun2023difusco} & SL+G & 18.52 & 7.81\% & 16m3s && 37.03 & 18.53\% & 5m30s  \\
\rowcolor{white} {\mymodel} (T$_\text{s}$=1) & SL+G & 18.59 & 7.37\% & \textbf{35s} && 36.72 & 18.17\% & \textbf{11s} \\
\rowcolor{white} {\mymodel} (T$_\text{s}$=5) & SL+G & \textbf{18.74} & \textbf{6.65\%} & 1m16s && \textbf{37.80} & \textbf{15.76\%} & 24s \\

\midrule

T2T (T$_\text{s}$=50,T$_\text{g}$=30)~\cite{li2023t2t} & SL+G & 18.98 & 5.49\% & 20m58s && 39.81 & 11.28\% & 7m7s\\
\rowcolor{white} {\mymodel} (T$_\text{s}$=1,T$_\text{g}$=1) & SL+G & 19.37 & 3.51\% & \textbf{1m18s} &&  40.25 & 10.30\% & \textbf{25s}  \\
\rowcolor{white} {\mymodel} (T$_\text{s}$=5,T$_\text{g}$=5) & SL+G & \textbf{19.49} & \textbf{2.89\%} & 4m44s && \textbf{40.68} & \textbf{9.34\%} & 1m32s
\\

\midrule
\midrule


Intel~\cite{li2018combinatorial} & SL+TS & 18.47 & 8.11\% & 13m4s && 38.80 & 13.43\% & 20.00m \\
DGL~\cite{bother2022s} & SL+TS & 17.36 & 13.61\% & 12m47s && 37.26 & 16.96\% & 22.71m \\
LwD~\cite{ahn2020learning}& RL+S & -- & -- & -- && 41.17 & 8.25\% & 6.33m\\
GFlowNets~\cite{zhang2023let} & UL+S & 19.18 & 4.57\% & 32s && 41.14 & 8.53\% & 2.92m\\
% DIMES~\cite{} & RL+S & 423.28 & 0.63\% & 20.26m && 42.06 & 6.26\% & 12.01m \\

\midrule

DIFUSCO (T$_\text{s}$=100)~\cite{sun2023difusco} & SL+S & 19.13 & 4.79\% & 20m28s && 39.12 & 12.81\% & 21m43s \\
\rowcolor{white} {\mymodel} (T$_\text{s}$=1) & SL+S & 18.91 & 5.81\% & \textbf{42s} && 37.91 & 15.52\% & \textbf{24s} \\
\rowcolor{white} {\mymodel} (T$_\text{s}$=5) & SL+S & \textbf{19.38} & \textbf{3.46\%} & 1m50s && \textbf{39.81} & \textbf{11.27\%} & 1m16s \\

\midrule

T2T (T$_\text{s}$=50,T$_\text{g}$=30)~\cite{li2023t2t} & SL+S & 19.38 & 3.53\% & 30m18s && 41.41 & 7.72\% & 27m45s \\
\rowcolor{white} {\mymodel} (T$_\text{s}$=1,T$_\text{g}$=1) & SL+S & 19.53 & 2.74\% & \textbf{1m59s} && 40.98 & 8.66\% & \textbf{1m19s} \\
\rowcolor{white} {\mymodel} (T$_\text{s}$=5,T$_\text{g}$=5) & SL+S & \textbf{19.70} & \textbf{1.90\%} & 6m59s && \textbf{41.73} & \textbf{6.99\%} & 5m51s \\
\bottomrule
\end{tabular}
    }
\label{tab:mis}
% \end{table*}

\vspace{-5pt}

  \end{minipage}\quad
  \begin{minipage}[h]{0.29\textwidth}
   \centering

   % {\includegraphics[width=1\linewidth]{figs/alpha-drop.pdf}}
   % \vspace{-15pt}
   % \caption{Effect of $\alpha$ to the performance drop.}

   % \vspace{5pt}

   {\includegraphics[width=1\linewidth]{figs/step-drop-new.pdf}}
   \vspace{-15pt}
   \caption{Effect of step number to drop for diffusion/consistency based methods. GS stands for gradient search.}
   \label{fig:step-drop}

   % {\includegraphics[width=1\linewidth]{figs/time-drop-100.pdf}}
   % \vspace{-15pt}
   % \caption{Effect of runtime to optimality drop for {\mymodel} and LKH3 on TSP-100.}

   % \vspace{5pt}

   % {\includegraphics[width=1\linewidth]{figs/time-drop-1000.pdf}}
   % \vspace{-15pt}
   % \caption{Effect of runtime to optimality drop for {\mymodel} and LKH3 on TSP-1000.}

   

    \vspace{-5pt}
   \end{minipage}
\end{figure*}

% \vspace{-3pt}
\subsection{Experiments for MIS}
% \vspace{-3pt}

\textbf{Datasets.} Two datasets are tested for the MIS problem following \cite{li2018combinatorial,ahn2020learning,bother2022s,qiu2022dimes,sun2023difusco}, including RB graphs~\cite{zhang2023let} and Erdős–Rényi (ER) graphs~\cite{erdHos1960evolution}. We randomly sample $200$ to $300$ vertices uniformly and generate the graph instances. ER graphs are randomly generated with each edge maintaining a fixed probability of being present or absent, independently of the other edges. We adopt ER graphs of $700$ to $800$ nodes with the pairwise connection probability set as $0.15$.

\textbf{Metrics.} Following previous works~\cite{kool2018attention,joshi2019efficient,qiu2022dimes,sun2023difusco}, we adopt three evaluation metrics to measure model performance: 1) Size: the average size of the solutions w.r.t. the corresponding instances, i.e. the objective. 2) Drop: the relative performance drop w.r.t. size compared to the optimal solution or the reference solution; 3) Time: the average computational time required to solve the problems.

\textbf{Main Results.} The baselines include SOTA neural methods with greedy and sampling decoding ($\times 4$), as well as exact solver Gurobi~\cite{llc2020gurobi} and heuristic solver KaMIS~\cite{lamm2016finding}. The solving time of Gurobi is set as comparable to neural solvers, thus it does not reach optimality. Table.~\ref{tab:mis} shows that {\mymodel} with merely one-step sampling and gradient search steps averagely approximates diffusion-based counterparts with approximately 100 sampling steps by a slight performance gain of  \textbf{2.5\%} and a speedup of \textbf{26.3x}. {\mymodel} variants with more sampling and gradient search steps achieve \textbf{23.7\%} performance gain with \textbf{9.1x} speedup compared to previous SOTA diffusion-based counterparts.



% \vspace{-3pt}
\section{Conclusion}
% \vspace{-3pt}

We introduce optimization consistency on top of the diffusion-based training-to-testing solving framework for efficient and effective combinatorial optimization solving. Our proposed model facilitates rapid single-step solving, demonstrating comparable or superior performance to SOTA diffusion-based counterparts, offering a more effective and efficient alternative backbone for neural solvers. In addition, a novel consistency-based gradient search scheme is introduced to further complement the generalization capability during solving. Experimental results on TSP and MIS datasets showcase the superiority of our methods, exhibiting significant performance gains in both solution quality and speed compared to previous state-of-the-art neural solvers. Furthermore, our approach demonstrates superiority over LKH3 in the early stages of solving.\looseness=-1

% \begin{table*}[tb!]	
% \centering 
% \caption{Results on TSP-500 and TSP-1000. AS: Active Search, S: Sampling Decoding, BS: Beam Search. $^*$~denotes the baseline for computing the performance drop. DIFUSCO and {\mymodel} are compared in the same running settings, while other numbers are quoted from \cite{fu2021generalize,qiu2022dimes}.}%(best in bold)
% % Best results are marked in \textbf{bold}.
% \vspace{-7pt}
%     \resizebox{0.9\linewidth}{!}{
%     \begin{tabular}{lcccccccc}
%     \toprule
%     \multirow{2}{*}{\textsc{Algorithm}}&\multirow{2}{*}{\textsc{Type}}	& \multicolumn{3}{c}{TSP-500}&&\multicolumn{3}{c}{TSP-1000} \\\cmidrule{3-5}\cmidrule{7-9}
%     && \textsc{Length}$\downarrow$ & \textsc{Drop}$\downarrow$ & T\footnotesize{IME} && \textsc{Length}$\downarrow$ & \textsc{Drop}$\downarrow$ & T\footnotesize{IME}
%  \\	\midrule

% % \multicolumn{9}{c}{\emph{Mathematical Solvers or Heuristics}}\\\midrule

% % Concorde~\cite{applegate2006concorde} & Exact & 16.55$^*$ & -- & 37.66m && 23.12$^*$ & -- & 6.65h \\
% % Gurobi~\cite{llc2020gurobi} & Exact & 16.55 & 0.00\% & 45.63h && -- & -- & -- \\
% % LKH-3~\cite{helsgaun2017extension} & Heuristics & 16.55 & 0.00\% & 46.28m && 23.12 & 0.00\% & 2.57h \\
% % % LKH-3 (less trails)~\cite{} & Heuristics & 16.55 & 0.00\% & 3.03m && 23.12 & 0.00\% & 7.73m \\
% % Farthest Insertion & Heuristics & 18.30 & 10.57\% & 0s && 25.72 & 11.25\% & 0s \\\midrule

% \multicolumn{9}{c}{\emph{Learning-based Solvers with Greedy Decoding}}\\\midrule

% % DIFUSCO (T$_\text{s}$=100)~\cite{sun2023difusco} & SL+G &  18.09 & 9.32\%  & 3m14s && 25.79 & 11.57\% & \\

% % \rowcolor{white} {\mymodel} (T$_\text{s}$=1) & SL+G & 17.78 & 7.45\% &  && 25.19 & 8.98\% &  \\
% % \rowcolor{white} {\mymodel} (T$_\text{s}$=5) & SL+G & 17.16 & 3.70\% &  && 24.32 & 5.21\% &  \\

% % T2T (T$_\text{s}$=50,T$_\text{g}$=30)~\cite{li2023t2t} & SL+G & 17.34 & 4.77\% & 16m23s && 25.17 & 8.86\% &  \\

% % \rowcolor{white} {\mymodel} (T$_\text{s}$=1,T$_\text{g}$=1) & SL+G & 17.24 & 4.15\% &  && 24.56 & 5.73\% &  \\
% % \rowcolor{white} {\mymodel} (T$_\text{s}$=5,T$_\text{g}$=5) & SL+G & 16.86 & 1.91\% &  && 23.88 & 3.30\% &  \\

% % \midrule

% DIFUSCO (T$_\text{s}$=1)~\cite{sun2023difusco} & SL+G+2Opt & 17.55 & 6.07\%  & 22s && 24.82 & 7.39\% &  \\
% DIFUSCO (T$_\text{s}$=50)~\cite{sun2023difusco} & SL+G+2Opt & 16.81 & 1.58\%  & 1m44s && 23.56 & 1.92\% &   \\
% DIFUSCO (T$_\text{s}$=100)~\cite{sun2023difusco} & SL+G+2Opt & 16.79  & 1.49\%  & 3m13s && 23.55 & 1.87\% & \\

% \rowcolor{white} {\mymodel} (T$_\text{s}$=1) & SL+G+2Opt & 16.75 & 1.24\% & 15s && 23.46 & 1.46\% &  \\

% \rowcolor{white} {\mymodel} (T$_\text{s}$=3) & SL+G+2Opt & 16.67 & 0.76\% & 41s && 23.36 & 1.05\% &  \\

% \rowcolor{white} {\mymodel} (T$_\text{s}$=5) & SL+G+2Opt & 16.65 & 0.62\% &  && 23.33 & 0.90\% &  \\

% % \rowcolor{white} {\mymodel} (T$_\text{s}$=10) & SL+G+2Opt &  &  & &&  &  &  \\

% \midrule


% T2T (T$_\text{s}$=1,T$_\text{g}$=1)~\cite{li2023t2t} & SL+G+2Opt & 17.45 & 5.47\% & 44s && 24.67 & 6.70\% &  \\

% T2T (T$_\text{s}$=50,T$_\text{g}$=15)~\cite{li2023t2t} & SL+G+2Opt & 16.69 & 0.89\% & 3m25s && -- & -- & --\\

% T2T (T$_\text{s}$=50,T$_\text{g}$=30)~\cite{li2023t2t} & SL+G+2Opt & 16.66 & 0.65\% & 18m5s && 23.45 & 1.45\% &   \\

% \rowcolor{white} {\mymodel} (T$_\text{s}$=1,T$_\text{g}$=1) & SL+G+2Opt & 16.68 & 0.78\%  & 40s && 23.35 & 1.01\% & 2m30s \\

% % \rowcolor{white} {\mymodel} (T$_\text{s}$=3,T$_\text{g}$=1) & SL+G+2Opt & 16.64 & 0.55\%  &  && &  & \\

% \rowcolor{white} {\mymodel} (T$_\text{s}$=3,T$_\text{g}$=3) & SL+G+2Opt & 16.61 & 0.40\%  & 1m46s && 23.27 & 0.65\% & \\

% \rowcolor{white} {\mymodel} (T$_\text{s}$=5,T$_\text{g}$=5) & SL+G+2Opt & 16.61 & 0.36\%  &  && 23.24 & 0.54\% &  \\

% \midrule

% \multicolumn{9}{c}{\emph{Learning-based Solvers with Sampling Decoding}}\\\midrule

% % DIFUSCO (T$_\text{s}$=100)~\cite{sun2023difusco} & SL+S &  \\

% % \rowcolor{white} {\mymodel} (T$_\text{s}$=1) & SL+S & \\
% % \rowcolor{white} {\mymodel} (T$_\text{s}$=5) & SL+S & \\

% % T2T (T$_\text{s}$=50,T$_\text{g}$=30)~\cite{li2023t2t} & SL+S &  \\

% % \rowcolor{white} {\mymodel} (T$_\text{s}$=1,T$_\text{g}$=1) & SL+S & \\
% % \rowcolor{white} {\mymodel} (T$_\text{s}$=3,T$_\text{g}$=3) & SL+S & \\

% % \midrule

% DIFUSCO (T$_\text{s}$=1)~\cite{sun2023difusco} & SL+S+2Opt &  \\
% DIFUSCO (T$_\text{s}$=50)~\cite{sun2023difusco} & SL+S+2Opt &  \\
% DIFUSCO (T$_\text{s}$=100)~\cite{sun2023difusco} & SL+S+2Opt &  \\

% \rowcolor{white} {\mymodel} (T$_\text{s}$=1) & SL+S+2Opt &  \\

% \rowcolor{white} {\mymodel} (T$_\text{s}$=3) & SL+S+2Opt & \\

% \rowcolor{white} {\mymodel} (T$_\text{s}$=5) & SL+S+2Opt &  \\

% % \rowcolor{white} {\mymodel} (T$_\text{s}$=10) & SL+S+2Opt &  &  & &&  &  &  \\

% \midrule


% T2T (T$_\text{s}$=1,T$_\text{g}$=1)~\cite{li2023t2t} & SL+S+2Opt &   \\

% T2T (T$_\text{s}$=50,T$_\text{g}$=15)~\cite{li2023t2t} & SL+S+2Opt &\\

% T2T (T$_\text{s}$=50,T$_\text{g}$=30)~\cite{li2023t2t} & SL+S+2Opt &\\

% \rowcolor{white} {\mymodel} (T$_\text{s}$=1,T$_\text{g}$=1) & SL+S+2Opt &  \\

% \rowcolor{white} {\mymodel} (T$_\text{s}$=3,T$_\text{g}$=1) & SL+S+2Opt &  \\

% \rowcolor{white} {\mymodel} (T$_\text{s}$=3,T$_\text{g}$=3) & SL+S+2Opt &  \\
% % \midrule


% \bottomrule
% \end{tabular}
% }
% \vspace{-5pt}
% \label{tab:tsp500-1000-diffusion}
% \end{table*}


% \begin{table*}[tb!]	
% \centering 
% \caption{Results on MIS. TS: Tree Search, UL: Unsupervised Learning. DIFUSCO and {\mymodel} are compared in the same running settings, while other numbers are quoted from \cite{qiu2022dimes,zhang2023let}.}%(best in bold)
% \vspace{-5pt}
% \resizebox{0.75\linewidth}{!}{
%     \begin{tabular}{lcccccccc}
%     \toprule
%     \multirow{2}{*}{\textsc{Algorithm}}&\multirow{2}{*}{\textsc{Type}}	& \multicolumn{3}{c}{SATLIB}&&\multicolumn{3}{c}{ER-[700-800]} \\\cmidrule{3-5}\cmidrule{7-9}
%     && S\footnotesize{IZE}$\uparrow$ & \textsc{Drop}$\downarrow$ & T\footnotesize{IME} && S\footnotesize{IZE}$\uparrow$ & \textsc{Drop}$\downarrow$ & T\footnotesize{IME}
%  \\	\midrule
 

% KaMIS~\cite{lamm2016finding} & Heuristics & 425.96$^*$ & -- & 37.58m && 44.87$^*$ & -- & 52.13m \\
% Gurobi~\cite{llc2020gurobi} & Exact & 425.95 & 0.00\% & 26.00m && 41.28 & 7.78\% & 50.00m \\
% \midrule

% Intel~\cite{li2018combinatorial} & SL+G & 420.66 & 1.48\% & 23.05m && 34.86 & 22.31\% & 6.06m \\
% DIMES~\cite{qiu2022dimes} & RL+G & 421.24 & 1.11\% & 24.17m && 38.24 & 14.78\% & 6.12m \\
% DIFUSCO (T$_\text{s}$=100)~\cite{sun2023difusco} & SL+G & 424.58 & 0.32\% & 11m1s && 37.03 & 18.53\% & 5m30s  \\
% \rowcolor{white} {\mymodel} (T$_\text{s}$=1) & SL+G & 421.65 & 1.01\% & 40s && 36.72 & 18.17\% & 11s \\
% \rowcolor{white} {\mymodel} (T$_\text{s}$=5) & SL+G & 423.96 & 0.47\% & 1m4s && 37.80 & 15.76\% & 24s \\
% T2T (T$_\text{s}$=50,T$_\text{g}$=30)~\cite{li2023t2t} & SL+G & 425.07 & 0.21\% & 15m39s && 39.81 & 11.28\% & 7m7s\\
% \rowcolor{white} {\mymodel} (T$_\text{s}$=1,T$_\text{g}$=1) & SL+G & 424.25 & 0.40\% & 2m1s &&  40.25 & 10.30\% & 25s  \\
% \rowcolor{white} {\mymodel} (T$_\text{s}$=5,T$_\text{g}$=5) & SL+G & 424.73 & 0.29\% & 7m41s && 40.68 & 9.34\% & 1m32s
% \\\midrule
% Intel~\cite{li2018combinatorial} & SL+TS & -- & -- & -- && 38.80 & 13.43\% & 20.00m \\
% DGL~\cite{bother2022s} & SL+TS & -- & -- & -- && 37.26 & 16.96\% & 22.71m \\
% LwD~\cite{ahn2020learning}& RL+S & 422.22 & 0.88\% & 18.83m && 41.17 & 8.25\% & 6.33m\\
% GFlowNets~\cite{zhang2023let} & UL+S & 423.54 & 0.57\% & 23.22m && 41.14 & 8.53\% & 2.92m\\
% DIMES~\cite{} & RL+S & 423.28 & 0.63\% & 20.26m && 42.06 & 6.26\% & 12.01m \\
% DIFUSCO (T$_\text{s}$=100)~\cite{sun2023difusco} & SL+S & 425.21 & 0.18\% & 53m41s && 39.12 & 12.81\% & 21m43s \\
% \rowcolor{white} {\mymodel} (T$_\text{s}$=1) & SL+S & 422.74 & 0.76\% & 2m12s && 37.91 & 15.52\% & 24s \\
% \rowcolor{white} {\mymodel} (T$_\text{s}$=5) & SL+S & 424.96 & 0.24\% & 3m7s && 39.81 & 11.27\% & 1m16s \\
% T2T (T$_\text{s}$=50,T$_\text{g}$=30)~\cite{li2023t2t} & SL+S & 425.18 & 0.18\% & 38m1s && 41.41 & 7.72\% & 27m45s \\
% \rowcolor{white} {\mymodel} (T$_\text{s}$=1,T$_\text{g}$=1) & SL+S & 424.68 & 0.30\% & 6m44s && 40.98 & 8.66\% & 1m19s \\
% \rowcolor{white} {\mymodel} (T$_\text{s}$=5,T$_\text{g}$=5) & SL+S & 425.23 & 0.17 & 25m35s && 41.73 & 6.99\% & 5m51s \\
% \bottomrule
% \end{tabular}
%     }
% \label{tab:mis}
% \vspace{-5pt}
% \end{table*}



\bibliographystyle{IEEEtran}
\bibliography{acmart}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\newpage
\appendix

\section*{Appendix}

\section{Training Details}

\subsection{Training Algorithm}

\begin{algorithm}
\caption{Optimization Consistency Training}
\begin{algorithmic}[1] % 1 表示每行代码前面有行号
\State \textbf{Input} dataset $\mathcal{D}$, consistency model $f_\theta(\cdot, \cdot)$, initial model parameter $\theta$, learning rate $\eta$, consistency loss function $d(\cdot, \cdot)$, inference steps $T$, scaling factor $\alpha$, Bernoulli noise matrix $\bar{Q}_{1,...,T}$, weighting function $\lambda (\cdot)$
\State \Repeat
    \State Sample $\mathbf{x^*}\sim \mathcal{D}$, $t_1\sim [1, T]$, $t_2\leftarrow \lceil \alpha t_1\rceil$
    \State Sample $\mathbf{z_1}\sim \mathbf{x^*}\bar{Q}_{t_1}$, $\mathbf{z_2}\sim \mathbf{x^*}\bar{Q}_{t_2}$
    \State $\mathcal{L(\theta)}\leftarrow \lambda(t_1) \left(d\left(\mathbf{f_\theta} \left( \mathbf{z_1}, t_1\right), \delta(\mathbf{z_1}-\mathbf{x^*})\right)\right) + d\left(\mathbf{f_\theta} \left( \mathbf{z_2}, t_2\right), \delta(\mathbf{z_1}-\mathbf{x^*})\right)$
    \State $\theta \leftarrow \theta - \eta \nabla_\theta \mathcal{L(\theta)}$
\State \Until convergence

\end{algorithmic}
\end{algorithm}

\subsection{Design Choices for Optimization Consistency}

We supplement the specific design choices of the optimization consistency models, and the listed hyperparameters correspond to those used in the algorithm presented in sections~\ref{sec:train} and \ref{sec:test}.

\begin{table}[h!]
\centering
\begin{tabular}{cc}
\toprule
\textbf{Training}                 & \textbf{Design Choice}                              \\\midrule
Consistency Loss Function         & $d(x,y)=\text{Binary\_Cross\_Entropy}(x,y)$         \\ 
Scaling Factor                    & $\alpha=0.5$                                        \\ 
Weighting Function                & $\lambda (t)=1$                                     \\ 
Discretization Curriculum         & $t \sim \{1, 2,\dots,T\}$, randomly sampling        \\ 
Initial Learning Rate             & $\eta=0.0002$                                       \\ 
Learning Rate Schedule            & Cosine decay, decay rate $\omega=0.0001$            \\ 
\bottomrule
\end{tabular}
\end{table}

\begin{table}[h!]
\centering
\begin{tabular}{cc}
\toprule
\textbf{Test}                     & \textbf{Design Choice}                                                               \\ \midrule
Sampling Step Schedule            & $t_1=T(1-\sin(N\cdot i\pi/2))$, $t_2=T(1-\sin(N\cdot (i+1)\pi/2))$                  \\ 
Guided Weighting Parameters       & $\lambda_1=50$, $\lambda_2=50$ on TSP \quad $\lambda_1=2$, $\lambda_2=2$ on MIS  \\
Rewrite Ratio                     & $\epsilon=0.2$ on TSP and ER-[700-800] \quad $\epsilon=0.3$ on RB-[200-300]      \\ \bottomrule

\end{tabular}
\end{table}


\section{Supplementary Experiments}\label{app:supplementary}

\subsection{Results on TSP Real-World Data}

\textbf{Results on TSPLIB 50-200.} We evaluate our model trained with random 100-node problems on real-world TSPLIB instances with 50-200 nodes. The compared baselines include DIFUSCO~\cite{sun2023difusco}, T2T~\cite{li2023t2t}, and baselines listed in \cite{hudson2021graph}'s Table 3. The hyperparameter settings of the compared baselines are: DIFUSCO: T$_\text{s}$=50; T2T: T$_\text{s}$=50 and T$_\text{g}$=30; {\mymodel} (w/o GS): T$_\text{s}$=10; {\mymodel} (w/ GS): T$_\text{s}$=10 and T$_\text{g}$=10. The diffusion-based methods are compared in the same settings with greedy decoding and Two-Opt post-processing. For each instance, we normalize the coordinates to [0,1].

\textbf{Results on TSPLIB 50-200.} We also supplement the results (optimality drop) of diffusion-based baselines and {\mymodel} on large-scale TSPLIB benchmark instances with 200-1000 nodes. The models are trained on TSP-500 and inference with greedy decoding and Two-Opt post-processing. For each instance, we normalize the coordinates to [0,1].

\begin{table}[ht]	
\centering 
\caption{Solution quality for methods trained on random 100-node problems and evaluated on \textbf{TSPLIB instances} with 50-200 nodes. $^*$~denotes results quoted from previous works~\cite{hudson2021graph}.}%(best in bold)
% \vspace{-5pt}
\resizebox{1\linewidth}{!}{
    \begin{tabular}{rcccccc>{\columncolor{white}}c>{\columncolor{white}}c}
    \toprule
    \textsc{Instances} & AM* & GCN* & Learn2OPT* & GNNGLS* & DIFUSCO  & T2T   & {\mymodel} (w/o GS) & {\mymodel} (w/ GS)
 \\	\midrule
eil51 & 16.767\% & 40.025\% & 1.725\% & 1.529\% & 2.82\% &  0.14\% &  0.00\% &  0.00\% \\
berlin52 & 4.169\% & 33.225\% & 0.449\% & 0.142\% & 0.00\% & 0.00\% & 0.00\% & 0.00\%  \\
st70 & 1.737\% & 24.785\% & 0.040\% & 0.764\% & 0.00\% & 0.00\% & 0.01\% & 0.00\%    \\
eil76 & 1.992\% & 27.411\% & 0.096\% & 0.163\% & 0.34\% & 0.00\% & 0.00\% & 0.00\%    \\
pr76 & 0.816\% & 27.793\% & 1.228\% & 0.039\% & 1.12\% & 0.40\% & 0.00\% & 0.00\%    \\

rat99 & 2.645\% & 17.633\% & 0.123\% & 0.550\% & 0.09\% & 0.09\% & 0.00\% & 0.00\% \\
kroA100 & 4.017\% & 28.828\% & 18.313\% &   0.728\% & 0.10\% & 0.00\% & 0.00\% & 0.00\%  \\
kroB100 & 5.142\% & 34.686\% & 1.119\% & 0.147\% & 2.29\% & 0.74\% & 0.74\% & 0.65\%    \\
kroC100 & 0.972\% & 35.506\% & 0.349\% & 1.571\% & 0.00\% & 0.00\% & 0.00\% & 0.00\%   \\
kroD100 & 2.717\% & 38.018\% & 0.866\% & 0.572\% & 0.07\% & 0.00\% & 0.00\% & 0.00\%    \\

kroE100 & 1.470\% & 26.589\% & 1.832\% & 1.216\% & 3.83\% & 0.27\% & 0.13\% & 0.00\%    \\
rd100 & 3.407\% & 50.432\% & 1.725\% & 0.003\% & 0.08\% & 0.00\% & 0.00\% & 0.00\%   \\
eil101 & 2.994\% & 26.701\% & 0.387\% & 1.529\% & 0.03\% & 0.00\% & 0.00\% & 0.00\%  \\
lin105 & 1.739\% & 34.902\% & 1.867\% & 0.606\% & 0.00\% & 0.00\% & 0.00\% & 0.00\%    \\
pr107 & 3.933\% & 80.564\% & 0.898\% & 0.439\% & 0.91\% & 0.61\% & 1.31\% & 0.62\%    \\

pr124 & 3.677\% & 70.146\% & 10.322\% & 0.755\% & 1.02\% & 0.60\% & 0.08\% & 0.08\%    \\
bier127 & 5.908\% & 45.561\% & 3.044\% & 1.948\% & 0.94\% & 0.54\% & 1.50\% & 1.50\%    \\
ch130 & 3.182\% & 39.090\% & 0.709\% & 3.519\% & 0.29\% & 0.06\% & 0.00\% & 0.00\%    \\
pr136 & 5.064\% & 58.673\% & 0.000\% & 3.387\% & 0.19\% & 0.10\% & 0.01\% & 0.01\%  \\
pr144 & 7.641\% & 55.837\% & 1.526\% & 3.581\% & 0.80\% & 0.50\% & 0.39\% & 0.39\% \\

ch150 & 4.584\% & 49.743\% & 0.312\% & 2.113\% & 0.57\% & 0.49\% & 0.00\% & 0.00\% \\
kroA150 & 3.784\% & 45.411\% & 0.724\% & 2.984\% & 0.34\% & 0.14\% & 0.00\% & 0.00\%  \\
kroB150 & 2.437\% & 56.745\% & 0.886\% & 3.258\% & 0.30\% & 0.00\% & 0.07\% & 0.07\%   \\
pr152 & 7.494\% & 33.925\% & 0.029\% & 3.119\% & 1.69\% & 0.83\% & 1.17\% & 0.19\%   \\
u159 & 7.551\% & 38.338\% & 0.054\% & 1.020\% & 0.82\% & 0.00\% & 0.00\% & 0.00\%  \\

rat195 & 6.893\% & 24.968\% & 0.743\% & 1.666\% & 1.48\% & 1.27\% & 0.79\% & 0.79\%  \\
d198 & 373.020\% & 62.351\% & 0.522\% & 4.772\% & 3.32\% & 1.97\% & 1.35\% & 0.86\%  \\
kroA200 & 7.106\% & 40.885\% & 1.441\% & 2.029\% & 2.28\% & 0.57\% & 1.79\% & 0.49\%  \\
kroB200 & 8.541\% & 43.643\% & 2.064\% & 2.589\% & 2.35\% & 0.92\% & 2.50\% & 2.50\% \\\midrule
\textbf{Mean} & 16.767\% & 40.025\% & 1.725\% & 1.529\% & 0.97\% & 0.35\% & 0.41\% & 0.28\%  \\


\bottomrule
\end{tabular}
}
\label{tab:tsplib1}
\vspace{-5pt}
\end{table}

\begin{table}[ht]	
\centering 
\caption{Solution quality for methods trained on random 500-node problems and evaluated on \textbf{TSPLIB instances} with 200-1000 nodes.}%(best in bold)
% \vspace{-5pt}
\resizebox{0.7\linewidth}{!}{
    \begin{tabular}{rcc>{\columncolor{white}}c>{\columncolor{white}}cc}
    \toprule
    \textsc{Instances} & DIFUSCO & T2T & {\mymodel} (w/o GS) &{\mymodel} (w/ GS)
 \\	\midrule
a280 & 1.39\% & 1.39\% & 4.58\% & 0.10\% \\
d493 & 1.81\% & 1.81\% & 3.48\% & 1.43\% \\
d657 & 4.86\% & 2.40\% & 1.91\% & 0.64\% \\
fl417 & 3.30\% & 3.30\% & 7.45\% & 2.01\% \\
gil262 & 2.18\% & 0.96\% & 0.64\% & 0.18\% \\
lin318 & 2.95\% & 1.73\% & 2.24\% & 1.21\% \\
linhp318 & 2.17\% & 1.11\% & 2.00\% & 0.78\% \\
p654 & 7.49\% & 1.19\% & 4.84\% & 1.67\% \\
pcb442 & 2.59\% & 1.70\% & 1.47\% & 0.61\% \\
pr226 & 4.22\% & 0.84\% & 0.66\% & 0.34\% \\
pr264 & 0.92\% & 0.92\% & 0.77\% & 0.73\% \\
pr299 & 1.46\% & 1.46\% & 2.16\% & 1.40\% \\
pr439 & 2.73\% & 1.63\% & 0.53\% & 0.50\% \\
rat575 & 2.32\% & 1.29\% & 1.74\% & 1.43\% \\
rat783 & 3.04\% & 1.88\% & 1.76\% & 1.03\% \\
rd400 & 1.18\% & 0.44\% & 0.16\% & 0.08\% \\
ts225 & 4.95\% & 2.24\% & 3.31\% & 1.37\% \\
tsp225 & 3.25\% & 1.69\% & 0.84\% & 0.81\% \\
u574 & 2.50\% & 1.85\% & 1.31\% & 0.94\% \\
u724 & 2.05\% & 2.05\% & 2.15\% & 1.41\% \\\midrule
\textbf{Mean} & 2.87\% & 1.59\% & 2.20\% & 0.93\% \\
\bottomrule
\end{tabular}
}
\label{tab:tsplib2}
\vspace{-5pt}
\end{table}

\subsection{Results on MIS Real-World Data}

We supplement the results on the SATLIB real-world dataset~\cite{hoos2000satlib} below. Initially, we did not include the SATLIB results because Fast T2T requires more data to learn the consistency mapping, which, due to its greater power, is more challenging to learn. Unfortunately, SATLIB does not provide sufficient data for this purpose. However, we still discover a positive results of Fast T2T outperforming previous baselines.

\begin{table}[h!]
\centering
\caption{Results on MIS SATLIB dataset.}
\begin{tabular}{cllccc}
\toprule
\textbf{Type} & \textbf{Method} & \textbf{Size} & \textbf{Drop} & \textbf{Time} \\ \midrule
Heuristic & KAMIS & 425.96\* & -- & 37.58m \\ 
Gurobi & Exact & 425.95 & 0.00\% & 26.00m \\ \midrule
RL+Sampling & LwD & 422.22 & 0.88\% & 18.83m \\ 
RL+Sampling & DIMES & 423.28 & 0.63\% & 20.26m \\ 
UL+Sampling & GlowNets & 423.54 & 0.57\% & 23.22m \\ 
SL+Sampling & DIFUSCO ($T_s=100$) & 425.14 & 0.19\% & 53m41s \\ 
SL+Sampling & T2T ($T_s=50,T_g=30$) & 425.18 & 0.18\% & 38m1s \\ 
SL+Sampling & Fast T2T ($T_s=5,T_g=5$) & \textbf{425.23} & \textbf{0.17\%} & 25m35s \\ \bottomrule
\end{tabular}
\end{table}


\subsection{Results for Generalization on TSP Datasets}
Fig.~\ref{fig:cm} visualized the performance of DIFUSCO, T2T, and \mymodel \  on different scales of TSP instances. The experimental settings are the same to Sec.~\ref{sec:exp-tsp}.


\begin{figure*}[ht]
    \begin{center}
    \resizebox{0.8\linewidth}{!}{
        \begin{tabular}{cc}
            \includegraphics[width=0.48\linewidth]{figs/DIFUSCO.pdf}  &
            \includegraphics[width=0.48\linewidth]{figs/T2T.pdf} \\
            \includegraphics[width=0.48\linewidth]{figs/OptCM5.pdf} &
            \includegraphics[width=0.48\linewidth]{figs/OptCM20.pdf}\\
            \end{tabular}
    }
    \end{center}
    \vspace{-2.5pt}
    \caption{Confusion matrix of four scales from TSP datasets. Models are trained on scales on the $y$-axis, and tested with \textbf{\emph{Greedy Decoding}} on scales on the $x$-axis. Values in matrices are the corresponding drop compared to exact solvers.}
    \label{fig:cm}
    \vspace{-7.5pt}
    
\end{figure*}

\subsection{Results for Generalization on MIS}

We provide supplementary results for generalization results on the MIS problem below. We test the model trained on ER 700-800 with $p=0.15$ to different $p$ (the probability that each simple edge exists) and $n$ (graph size). We find that the generalization ability of Fast T2T is significantly better than that of the previous diffusion-based methods DIFUSCO and T2T regarding both solution quality and speed, e.g., in ER 350-400 Sampling setting Fast T2T achieves significant performance gain from (23.28\%, 24m31s) to (11.45\%, 1m1s). Results are presented in Tables~\ref{tab:mis-gen1} and \ref{tab:mis-gen2}.

% \begin{table}[h!]
% \centering
% \caption{Generalization Performance from $p=0.15$  to  $p=0.2$.}
% \begin{tabular}{cllccc}
% \toprule
%  \textbf{Decoding} & \textbf{Method} & \textbf{Size} & \textbf{Drop} & \textbf{Time} \\ \midrule
%  \multirow{4}{*}{Greedy} & DIFUSCO ($T_s=100$) & 26.25 & 25.65\% & 6m31s \\
%   & T2T ($T_s=50,T_g=30$) & 27.84 & 21.13\% & 7m52s \\
%   & Fast T2T ($T_s=1,T_g=1$) & 28.04 & 20.58\% & 32s \\ 
%    & Fast T2T ($T_s=5,T_g=5$) & 29.52 & 16.38\% & 1m57s \\ \midrule
%  \multirow{4}{*}{Sampling} & DIFUSCO ($T_s=100$) & 27.98 & 20.73\% & 27m15s \\ 
%      & T2T ($T_s=50,T_g=30$) & 28.07 & 20.49\% & 33m58s \\ 
%     & Fast T2T ($T_s=1,T_g=1$) & 28.81 & 18.39\% & 1m40s \\ 
%     & Fast T2T ($T_s=5,T_g=5$) & 30.10 & 14.74\% & 6m13s \\ \bottomrule
% \end{tabular}
% \end{table}

\begin{table}[h!]
\centering
\caption{Generalization Performance from $p=0.15$ to $p=0.2$, $p=0.3$, and $p=0.4$.}\label{tab:mis-gen1}
\resizebox{0.7\linewidth}{!}{
\begin{tabular}{cllccc}
\toprule
\textbf{p} & \textbf{Type} & \textbf{Method} & \textbf{Size} & \textbf{Drop} & \textbf{Time} \\ \midrule
\multirow{8}{*}{0.2} & \multirow{4}{*}{Greedy} & DIFUSCO ($T_s=100$) & 26.25 & 25.65\% & 6m31s \\
    &  & T2T ($T_s=50,T_g=30$) & 27.84 & 21.13\% & 7m52s \\
    &  & Fast T2T ($T_s=1,T_g=1$) & 28.04 & 20.58\% & 32s \\
    &  & Fast T2T ($T_s=5,T_g=5$) & 29.52 & 16.38\% & 1m57s \\ \cmidrule(l){2-6}
    & \multirow{4}{*}{Sampling} & DIFUSCO ($T_s=100$) & 27.98 & 20.73\% & 27m15s \\
    &  & T2T ($T_s=50,T_g=30$) & 28.07 & 20.49\% & 33m58s \\
    &  & Fast T2T ($T_s=1,T_g=1$) & 28.81 & 18.39\% & 1m40s \\
    &  & Fast T2T ($T_s=5,T_g=5$) & \textbf{30.10} & \textbf{14.74\%} & 6m13s \\ \midrule
    
\multirow{8}{*}{0.3} & \multirow{4}{*}{Greedy} & DIFUSCO ($T_s=100$) & 15.84 & 34.99\% & 7m58s \\
    &  & T2T ($T_s=50,T_g=30$) & 16.43 & 32.55\% & 8m20s \\
    &  & Fast T2T ($T_s=1,T_g=1$) & 17.43 & 28.45\% & 51s \\
    &  & Fast T2T ($T_s=5,T_g=5$) & 17.69 & 27.39\% & 2m52s \\ \cmidrule(l){2-6}
    & \multirow{4}{*}{Sampling} & DIFUSCO ($T_s=100$) & 17.17 & 29.52\% & 30m3s \\
    &  & T2T ($T_s=50,T_g=30$) & 16.38 & 32.78\% & 37m27s \\
    &  & Fast T2T ($T_s=1,T_g=1$) & 17.79 & 26.97\% & 2m2s \\
    &  & Fast T2T ($T_s=5,T_g=5$) & \textbf{18.38} & \textbf{24.53\%} & 8m36s \\ \midrule

\multirow{8}{*}{0.4} & \multirow{4}{*}{Greedy} & DIFUSCO ($T_s=100$) & 11.75 & 35.40\% & 9m40s \\
    &  & T2T ($T_s=50,T_g=30$) & 12.77 & 29.77\% & 10m28s \\
    &  & Fast T2T ($T_s=1,T_g=1$) & 12.86 & 29.30\% & 1m1s \\
    &  & Fast T2T ($T_s=5,T_g=5$) & 13.27 & 27.06\% & 3m36s \\ \cmidrule(l){2-6}
    & \multirow{4}{*}{Sampling} & DIFUSCO ($T_s=100$) & 12.69 & 30.21\% & 40m22s \\
    &  & T2T ($T_s=50,T_g=30$) & 13.03 & 28.33\% & 45m2s \\
    &  & Fast T2T ($T_s=1,T_g=1$) & 13.31 & 26.80\% & 2m12s \\
    &  & Fast T2T ($T_s=5,T_g=5$) & \textbf{13.56} & \textbf{25.43\%} & 8m58s \\ \bottomrule
\end{tabular}}
\end{table}



\begin{table}[h!]
\centering
\caption{Generalization Performance from ER 700-800  to  ER 350-400 and 1400-1600.}\label{tab:mis-gen2}
\resizebox{0.7\linewidth}{!}{
\begin{tabular}{cllccc}
\toprule
\textbf{n} & \textbf{Decoding} & \textbf{Method} & \textbf{Size} & \textbf{Drop} & \textbf{Time} \\ \midrule
\multirow{6}{*}{350-400}   & \multirow{3}{*}{Greedy} & DIFUSCO ($T_s=100$) & 27.31 & 28.04\% & 5m1s \\ 
           &        & T2T ($T_s=50,T_g=30$) & 28.54 & 24.80\% & 6m59s \\ 
           &        & Fast T2T ($T_s=1,T_g=1$) & 32.56 & 14.20\% & 22s \\ \cmidrule{2-6}
           & \multirow{3}{*}{Sampling} & DIFUSCO ($T_s=100$) & 29.33 & 22.73\% & 20m12s \\ 
           &        & T2T ($T_s=50,T_g=30$) & 29.12 & 23.28\% & 24m31s \\ 
           &        & Fast T2T ($T_s=1,T_g=1$) & 33.61 & 11.45\% & 1m1s \\ \midrule
\multirow{6}{*}{1400-1600}  & \multirow{3}{*}{Greedy} & DIFUSCO ($T_s=100$) & 34.39 & 32.48\% & 22m7s \\ 
           &        & T2T ($T_s=50,T_g=30$) & OOM & OOM & OOM \\ 
           &        & Fast T2T ($T_s=1,T_g=1$) & 36.95 & 27.47\% & 1m39s \\ \cmidrule{2-6}
           & \multirow{3}{*}{Sampling} & DIFUSCO ($T_s=100$) & 35.55 & 30.21\% & 1h27m31s \\ 
           &        & T2T ($T_s=50,T_g=30$) & OOM & OOM & OOM \\ 
           &        & Fast T2T ($T_s=1,T_g=1$) & 38.59 & 24.25\% & 3m56s \\ \bottomrule
\end{tabular}}
\end{table}

We also supplement cross-dataset generalization results between RB graphs and ER graphs in Table~\ref{tab:mis-cross-data}. As seen, Fast T2T outperforms previous diffusion-based counterparts by a clear margin, e.g., in "Train:ER; Test:RB" "Sampling" setting, Fast T2T achieves significant performance gain from the previous (23.24\%, 30m13s) to (9.10\%, 4m20s).

\begin{table}[h!]
\centering
\caption{Performance Comparison Between Greedy and Sampling Methods (Train:ER; Test:RB).}\label{tab:mis-cross-data}
\resizebox{0.8\linewidth}{!}{
\begin{tabular}{cllccc}
\toprule
\textbf{Setting} & \textbf{Type} & \textbf{Method} & \textbf{Size} & \textbf{Drop} & \textbf{Time} \\ \midrule
\multirow{8}{*}{Train:ER; Test:RB} & \multirow{4}{*}{Greedy} & DIFUSCO ($T_s=100$) & 15.87 & 21.00\% & 10m8s \\
    &  & T2T ($T_s=50,T_g=30$) & 16.59 & 17.41\% & 15m5s \\
    &  & Fast T2T ($T_s=1,T_g=1$) & 16.73 & 16.59\% & 40s \\
    &  & Fast T2T ($T_s=5,T_g=5$) & \textbf{17.01} & \textbf{15.21\%} & 2m39s \\ \cmidrule(l){2-6}
    & \multirow{4}{*}{Sampling} & DIFUSCO ($T_s=100$) & 16.75 & 16.62\% & 41m0s \\
    &  & T2T ($T_s=50,T_g=30$) & 16.80 & 16.40\% & 29m48s \\
    &  & Fast T2T ($T_s=1,T_g=1$) & 17.29 & 13.78\% & 57s \\
    &  & Fast T2T ($T_s=5,T_g=5$) & \textbf{17.38} & \textbf{13.38\%} & 4m33s \\ \midrule

\multirow{8}{*}{Train:ER; Test:RB} & \multirow{4}{*}{Greedy} & DIFUSCO ($T_s=100$) & 29.98 & 27.54\% & 10m48s \\
    &  & T2T ($T_s=50,T_g=30$) & 31.47 & 23.96\% & 13m40s \\
    &  & Fast T2T ($T_s=1,T_g=1$) & 36.39 & 11.96\% & 43s \\
    &  & Fast T2T ($T_s=5,T_g=5$) & \textbf{36.94} & \textbf{10.64\%} & 2m37s \\ \cmidrule(l){2-6}
    & \multirow{4}{*}{Sampling} & DIFUSCO ($T_s=100$) & 31.67 & 23.47\% & 44m0s \\
    &  & T2T ($T_s=50,T_g=30$) & 31.77 & 23.24\% & 30m13s \\
    &  & Fast T2T ($T_s=1,T_g=1$) & 36.84 & 10.90\% & 57s \\
    &  & Fast T2T ($T_s=5,T_g=5$) & \textbf{37.58} & \textbf{9.10\%} & 4m20s \\ \bottomrule
\end{tabular}}
\end{table}



\section{Experimental Details}\label{app:exp-detail}


\subsection{Computational Resources.} Test evaluations on TSP-50/100 and MIS are performed on a single GPU of NVIDIA RTX 4090, and evaluations on TSP-500/1000 are performed on a single GPU of NVIDIA Telsla A100.

\subsection{Graph Sparsification.} For large-scale TSP problems, we follow~\cite{sun2023difusco,li2023t2t} to employ sparse graphs, as sparsified by constraining each node to connect to only its $k$ nearest neighbors, determined by Euclidean distances. For TSP-500, we set $k=50$, and for TSP-1000, $k=100$. This strategy prevents the exponential increase in edges typical in dense graphs as node count rises.

\subsection{Datasets.} The reference solutions for TSP-50/100 are labeled by the Concorde exact solver~\cite{applegate2006concorde} and the solutions for TSP-500/1000 are labeled by the LKH-3 heuristic solver~\cite{helsgaun2017extension}. The test set for TSP-50/100 is taken from \cite{kool2018attention,joshi2019efficient} with 1280 instances and the test set for TSP-500/1000 is from \cite{fu2021generalize} with 128 instances for the fair comparison. 

The reference solutions for both RB graphs and ER graphs are labeled with KaMIS~\cite{lamm2016finding}. For RB graphs, we randomly generate 90000 instances for the training set and 500 instances for the test set. For ER graphs, we randomly generate 163840 instaces for the training set and the test is from~\cite{qiu2022dimes}.


\subsection{Training Resource Requirement}
We outline the offline training resource requirements of the {\mymodel} framework in Table~\ref{tab:resource}, with computations conducted on A100 GPUs. For contextual comparison, AM~\cite{kool2018attention} necessitates 128M instances generated on-the-fly to train TSP-100, consuming 45.8 hours on 2 1080Ti GPUs. POMO~\cite{kwon2020pomo} mandates 200M instances generated dynamically for TSP-100 training, entailing approximately one week on a single Titan RTX. Sym-NCO~\cite{kim2022sym}, an extension of POMO, requires approximately two weeks on a single A100 for training. Additionally, Sym-NCO~\cite{kim2022sym} built upon AM~\cite{kool2018attention} necessitates three days on 4 A100 GPUs. Compared with DIFUSCO~\cite{sun2023difusco}, \mymodel~necessitates approximately double training time and GPU memory under the same settings, because our consistency training method requires forward twice for each training instance, leading to more time and memory consumption.

\begin{table}[ht]	
\centering 
\caption{Details about the training resource requirement of {\mymodel} framework. The results are calculated on A100 GPUs.}%(best in bold)
% \vspace{-5pt}

\resizebox{0.8\linewidth}{!}{
    \begin{tabular}{ccccccc}
    \toprule
    Problem Scale & Dataset Size & Batch Size & 1 GPU & 2 GPUs & 4 GPUs & GPU Mem 
 \\	\midrule

TSP-50  &1,502 k & 32 &112h 45m &62h 24m & 41h 16m &16.5 GB\\
TSP-100 &1,502 k & 12 & 488h 12m & 268h 37m & 139h 26m & 23.2 GB \\
TSP-500 &128 k & 6 &142h 17m &78h 58m & 45h 2m & 37.8 GB \\
TSP-1000 & 64 k & 4 &324h 43m & 185h26s & 101h 3m & 20.2 GB\\

\bottomrule
\end{tabular}
}
\label{tab:resource}
\end{table}

\subsection{Hyperparamters}
We conduct experiments on TSP and MIS benchmarks with our methods and compare the performance with prevalent learning-based solvers, heuristics, and exact solvers. The noise degree $\alpha$ associated with each benchmark is listed in Table.~\ref{tab:alpha}.

\begin{table}[ht]
    \centering
    \caption{Noise Degree for each benchmark.}
    \resizebox{0.7\linewidth}{!}{\begin{tabular}{r|cccccc}
    \toprule
    
    Benchmark & TSP-50 & TSP-100 & TSP-500 & TSP-1000 & RB-[200-300] & ER-[700-800] \\
    \midrule
    $\alpha$ & 0.20 & 0.20 & 0.20 & 0.20 & 0.30 & 0.20 \\
    \bottomrule
    \end{tabular}}
    \label{tab:alpha}
\end{table}

\subsection{Baseline Settings}
\subsubsection{TSP Benchmarks}
% \begin{itemize}

\textbf{TSP-50/100:} In the evaluation of TSP-50 and TSP-100, we compare our proposed {\mymodel} against 11 baseline methods. These baselines include one exact solver, Concorde~\cite{applegate2006concorde}, two heuristic solvers - 2OPT~\cite{croes1958method} and Farthest Insertion - and seven learning-based solvers: AM~\cite{kool2018attention}, GCN~\cite{joshi2019efficient}, Transformer~\cite{bresson2021transformer}, POMO~\cite{kwon2020pomo}, Sym-NCO~\cite{kim2022sym}, Image Diffusion~\cite{graikos2022diffusion}, DIFUSCO~\cite{sun2023difusco}, and T2T~\cite{li2023t2t}. Our post-processing involves greedy sampling and 2OPT refinement. To ensure equitable comparisons in terms of computational effort, we limit the number of inference steps for DIFUSCO to 100, and for T2T, we set the number of inference steps and guided search steps to 50 and 30, respectively.

\textbf{TSP-500/1000:} In the evaluation of TSP-500 and TSP-1000, our method is compared with 2 exact solvers, Concorde~\cite{applegate2006concorde} and Gurobi~\cite{llc2020gurobi}, 2 heuristic solvers, LKH-3~\cite{helsgaun2017extension} and Farthest Insertion, and 6 learning-based methods, including EAN~\cite{deudon2018learning}, AM~\cite{kool2018attention}, GCN~\cite{joshi2019efficient}, POMO+EAS~\cite{hottung2021efficient}, DIMES~\cite{qiu2022dimes}, and DIFUSCO~\cite{sun2023difusco}. These learning-based methods can be further categorized into supervised learning (SL) and reinforcement learning (RL). Post-processing techniques employed encompass greedy sampling (Grdy, G), multiple sampling (S), 2OPT refinement (2OPT), beam search (BS), active search (AS), and combinations thereof. To ensure fair comparisons in terms of computational resources, we cap the number of inference steps for DIFUSCO at 100. Additionally, for T2T, we fix the number of inference steps and guided search steps at 50 and 30, respectively.

% \end{itemize}

% For all TSP benchmarks, we set the inference steps of DIFUSCO 120 for fair comparison.

\subsubsection{MIS Benchmarks}

We assess our method on two distinct benchmarks: RB-[200-300] and ER-[700-800]. Across both benchmarks, we compare the performance of {\mymodel} against one exact solver, Gurobi~\cite{llc2020gurobi}, one heuristic solver, KaMIS~\cite{lamm2016finding}, and 5 learning-based frameworks: Intel~\cite{li2018combinatorial}, DGL~\cite{li2018combinatorial}, LwD~\cite{ahn2020learning}, DIMES~\cite{qiu2022dimes}, and DIFUSCO~\cite{sun2023difusco}. Post-processing strategies encompass greedy sampling (Grdy) and tree search (TS). Specifically, on both benchmarks, we set the number of inference steps at 100 for DIFUSCO. For T2T, we set the number of inference steps and guided search steps at 50 and 30, respectively.

\section{Network Architecture Details}
\subsection{Input Embedding Layer}
Given node vector $x\in \mathbb{R}^{N\times 2}$, weighted edge vector $e \in \mathbb{R}^E$, denoising timestep $t\in \{\tau_1,\dots, \tau_M\}$, where $N$ denotes the number of nodes in the graph, and $E$ denotes the number of edges, we compute the sinusoidal features of each input element respectively:

\begin{align}
    \Tilde{x}_i &= \operatorname{concat}(\Tilde{x}_{i,0}, \Tilde{x}_{i,1}) \\
    \Tilde{x}_{i,j}&=\operatorname{concat}\left(\sin \frac{x_{i,j}}{T^\frac{0}{d}}, \cos \frac{x_{i,j}}{T^\frac{0}{d}}, \sin \frac{x_{i,j}}{T^{\frac{2}{d}}}, \cos \frac{x_{i,j}}{T^\frac{2}{d}}, \dots,\sin \frac{x_{i,j}}{T^{\frac{d}{d}}}, \cos \frac{x_{i,j}}{T^\frac{d}{d}}\right) \\
    \Tilde{e}_i&=\operatorname{concat}\left(\sin \frac{e_i}{T^\frac{0}{d}}, \cos \frac{e_i}{T^\frac{0}{d}}, \sin \frac{e_i}{T^{\frac{2}{d}}}, \cos \frac{e_i}{T^\frac{2}{d}}, \dots,\sin \frac{e_i}{T^{\frac{d}{d}}}, \cos \frac{e_i}{T^\frac{d}{d}}\right) \\
    \Tilde{t}&=\operatorname{concat}\left(\sin \frac{t}{T^\frac{0}{d}}, \cos \frac{t}{T^\frac{0}{d}}, \sin \frac{t}{T^{\frac{2}{d}}}, \cos \frac{t}{T^\frac{2}{d}}, \dots,\sin \frac{t}{T^{\frac{d}{d}}}, \cos \frac{t}{T^\frac{d}{d}}\right)
\end{align}

where $d$ is the embedding dimension, $T$ is a large number (usually selected as $10000$), $\operatorname{concat(\cdot)}$ denotes concatenation. 

Next, we compute the input features of the graph convolution layer:
\begin{align}
    x_i^0&=W_1^0\Tilde{x_i} \\
    e_i^0&=W_2^0\Tilde{e_i} \\
    t^0&=W_4^0 (\operatorname{ReLU}(W_3^0 \Tilde{t}))
\end{align}
where $t^0\in \mathbb{R}^{d_t}$, $d_t$ is the time feature embedding dimension. Specifically, for TSP, the embedding input edge vector $e$ is a weighted adjacency matrix, which represents the distance between different nodes, and $e^0$ is computed as above. For MIS, we initialize $e^0$ to a zero matrix $0^{E\times d}$.

\subsection{Graph Convolution Layer} 
Following \cite{joshi2019efficient}, the cross-layer convolution operation is formulated as:
\begin{align}
    x_i^{l+1}&=x_i^l+\operatorname{ReLU}(\operatorname{BN}(W_1^lx_i^l+\sum_{j\sim i}\eta_{ij}^l\odot W_2^lx_j^l))\\
    e_{ij}^{l+1}&=e_i^l+\operatorname{ReLU}(\operatorname{BN}(W_3^le_{ij}^l+W_4^lx_i^l+W_5^lx_j^l))\\
    \eta_{ij}^l&=\frac{\sigma(e_{ij}^l)}{\sum_{j'\sim i}\sigma(e^l_{ij'})+\epsilon}
\end{align}
where $x^l_i$ and $e_{ij}^l$ denote the node feature vector and edge feature vector at layer $l$, $W_1,\cdots,W_5\in\mathbb{R}^{h\times h}$ denote the model weights, $\eta^l_{ij}$ denotes the dense attention map. The convolution operation integrates the edge feature to accommodate the significance of edges in routing problems.

For TSP, we aggregate the timestep feature with the edge convolutional feature and reformulate the update for edge features as follows:
\begin{equation}
    e_{ij}^{l+1}=e_{ij}^l+\operatorname{ReLU}(\operatorname{BN}(W_3^le_{ij}^l+W_4^lx_i^l+W_5^lx_j^l)) + W_6^l(\operatorname{ReLU}(t^0))   
\end{equation}

For MIS, we aggregate the timestep feature with the node convolutional feature and reformulate the update for node features as follows:
\begin{equation}
    x_i^{l+1}=x_i^l+\operatorname{ReLU}(\operatorname{BN}(W_1^lx_i^l+\sum_{j\sim i}\eta_{ij}^l\odot W_2^lx_j^l)) + W_6^l(\operatorname{ReLU}(t^0))   
\end{equation}

\subsection{Output Layer}
The prediction of the edge heatmap in TSP and node heatmap in MIS is as follows:
\begin{align}
    e_{i,j}&=\operatorname{Softmax}(\operatorname{norm}(\operatorname{ReLU}(W_e e_{i,j}^L))) \\
    x_i&=\operatorname{Softmax}(\operatorname{norm}(\operatorname{ReLU}(W_n x_i^L)))
\end{align}

where $L$ is the number of GCN layers and $\operatorname{norm}$ is layer normalization.


\subsection{Hyper-parameters}
For both TSP and MIS tasks, we construct a 12-layer GCN derived above. We set the node, edge, and timestep embedding dimension $d=256, 128$ for TSP and MIS tasks, respectively.




\section{Limitations and Broader Impacts}
\label{app:limit}

As the scale increases, our method's improvement in solving speed compared to diffusion-based methods will experience a certain degree of attenuation. This is because, with the expansion of the scale, the proportion of time required for relevant serial processing becomes larger, while the proportion of time for model inference is squeezed, resulting in a weakening of the speed improvement in the overall pipeline. This limitation can be addressed by combining our model with more efficient traditional solving strategies, which we leave for future work. Since the consistency model requires two inference predictions with different noise levels during training, it requires twice the training cost of the original diffusion model. However, this overhead on training is offline, and the consistency model is much more efficient than diffusion at inference time.

Our work provides a more powerful and efficient backbone for neural combinatorial optimization, enabling significant performance improvement and versatility, making its application feasible across various solving frameworks. This work can be integrated into existing and future research in this field, driving progress in related studies.














%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\section*{NeurIPS Paper Checklist}

%%% BEGIN INSTRUCTIONS %%%
% The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: {\bf The papers not including the checklist will be desk rejected.} The checklist should follow the references and precede the (optional) supplemental material.  The checklist does NOT count towards the page
% limit. 

% Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist:
% \begin{itemize}
%     \item You should answer \answerYes{}, \answerNo{}, or \answerNA{}.
%     \item \answerNA{} means either that the question is Not Applicable for that particular paper or the relevant information is Not Available.
%     \item Please provide a short (1–2 sentence) justification right after your answer (even for NA). 
%    % \item {\bf The papers not including the checklist will be desk rejected.}
% \end{itemize}

% {\bf The checklist answers are an integral part of your paper submission.} They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with the paper.

% The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While "\answerYes{}" is generally preferable to "\answerNo{}", it is perfectly acceptable to answer "\answerNo{}" provided a proper justification is given (e.g., "error bars are not reported because it would be too computationally expensive" or "we were unable to find the license for the dataset we used"). In general, answering "\answerNo{}" or "\answerNA{}" is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer \answerYes{} to a question, in the justification please point to the section(s) where related material for the question can be found.

% IMPORTANT, please:
% \begin{itemize}
%     \item {\bf Delete this instruction block, but keep the section heading ``NeurIPS paper checklist"},
%     \item  {\bf Keep the checklist subsection headings, questions/answers and guidelines below.}
%     \item {\bf Do not modify the questions and only use the provided macros for your answers}.
% \end{itemize} 
 

%%% END INSTRUCTIONS %%%


\begin{enumerate}

\item {\bf Claims}
    \item[] Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope?
    \item[] Answer: \answerYes{} % Replace by \answerYes{}, \answerNo{}, or \answerNA{}.
    \item[] Justification: The abstract and introduction explicitly state the claims made, including the contributions made in the paper (Sec.~\ref{sec:intro}). The claims match the experimental results in Sec.~\ref{sec:experiments}.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the abstract and introduction do not include the claims made in the paper.
        \item The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. 
        \item The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. 
        \item It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. 
    \end{itemize}

\item {\bf Limitations}
    \item[] Question: Does the paper discuss the limitations of the work performed by the authors?
    \item[] Answer: \answerYes{} % Replace by \answerYes{}, \answerNo{}, or \answerNA{}.
    \item[] Justification: We discuss the limitations in Appendix~\ref{app:limit}.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. 
        \item The authors are encouraged to create a separate "Limitations" section in their paper.
        \item The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.
        \item The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.
        \item The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.
        \item The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.
        \item If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.
        \item While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
    \end{itemize}

\item {\bf Theory Assumptions and Proofs}
    \item[] Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?
    \item[] Answer: \answerYes{} % Replace by \answerYes{}, \answerNo{}, or \answerNA{}.
    
    Justification: The theoretical derivation of this paper has been given in Sec.~\ref{sec:test}, and there are no additional theorems needed to be proved.
    % \item[] Justification: We provide a formal problem description for the combinatorial optimization problems in Sec.~\ref{sec:preliminaries}. We thoroughly discuss the training-stage of optimization consistency modeling in Sec.~\ref{sec:train}, including the diffusion-based solution encoding, noising process, and prove the validness of our proposed training scheme. The testing-stage is discussed in Sec.~\ref{sec:test}, we provide a formal description of our gradient search method and analyze the validness.
    
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the paper does not include theoretical results. 
        \item All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
        \item All assumptions should be clearly stated or referenced in the statement of any theorems.
        \item The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. 
        \item Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
        \item Theorems and Lemmas that the proof relies upon should be properly referenced. 
    \end{itemize}

    \item {\bf Experimental Result Reproducibility}
    \item[] Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)?
    \item[] Answer: \answerYes{} % Replace by \answerYes{}, \answerNo{}, or \answerNA{}.
    \item[] Justification: The experimental details are in Sec.~\ref{sec:experiments} and Append.~\ref{app:supplementary},~\ref{app:exp-detail}. We will make our source code publicly available upon acceptance.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the paper does not include experiments.
        \item If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.
        \item If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. 
        \item Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.
        \item While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example
        \begin{enumerate}
            \item If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm.
            \item If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully.
            \item If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).
            \item We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
        \end{enumerate}
    \end{itemize}


\item {\bf Open access to data and code}
    \item[] Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?
    \item[] Answer: \answerNo{} % Replace by \answerYes{}, \answerNo{}, or \answerNA{}.
    \item[] Justification: The source code will be made publicly available upon acceptance.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that paper does not include experiments requiring code.
        \item Please see the NeurIPS code and data submission guidelines (\url{https://nips.cc/public/guides/CodeSubmissionPolicy}) for more details.
        \item While we encourage the release of code and data, we understand that this might not be possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
        \item The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (\url{https://nips.cc/public/guides/CodeSubmissionPolicy}) for more details.
        \item The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
        \item The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
        \item At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
        \item Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
    \end{itemize}


\item {\bf Experimental Setting/Details}
    \item[] Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results?
    \item[] Answer: \answerYes{} % Replace by \answerYes{}, \answerNo{}, or \answerNA{}.
    \item[] Justification: The experimental details are in Sec.~\ref{sec:experiments} and Append.~\ref{app:supplementary},~\ref{app:exp-detail}.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the paper does not include experiments.
        \item The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.
        \item The full details can be provided either with the code, in appendix, or as supplemental material.
    \end{itemize}

\item {\bf Experiment Statistical Significance}
    \item[] Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments?
    \item[] Answer: \answerNo{} % Replace by \answerYes{}, \answerNo{}, or \answerNA{}.
    \item[] Justification: we follow the setting of previous works to report the average solution quality over 128 or 1,280 instances in Sec.~\ref{sec:experiments}.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the paper does not include experiments.
        \item The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.
        \item The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
        \item The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
        \item The assumptions made should be given (e.g., Normally distributed errors).
        \item It should be clear whether the error bar is the standard deviation or the standard error of the mean.
        \item It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96\% CI, if the hypothesis of Normality of errors is not verified.
        \item For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
        \item If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
    \end{itemize}

\item {\bf Experiments Compute Resources}
    \item[] Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments?
    \item[] Answer: \answerYes{} % Replace by \answerYes{}, \answerNo{}, or \answerNA{}.
    \item[] Justification: We provide the testing GPUs and time-consumption of our methods as well as previous works in Sec.~\ref{sec:experiments}. The training resource requirement is in Appendix.~\ref{app:exp-detail}
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the paper does not include experiments.
        \item The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.
        \item The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. 
        \item The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). 
    \end{itemize}
    
\item {\bf Code Of Ethics}
    \item[] Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics \url{https://neurips.cc/public/EthicsGuidelines}?
    \item[] Answer: \answerYes{} % Replace by \answerYes{}, \answerNo{}, or \answerNA{}.
    \item[] Justification: The research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
        \item If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.
        \item The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
    \end{itemize}


\item {\bf Broader Impacts}
    \item[] Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed?
    \item[] Answer: \answerYes{} % Replace by \answerYes{}, \answerNo{}, or \answerNA{}.
    \item[] Justification: We discuss the borader impacts in Appendix.~\ref{app:limit}.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that there is no societal impact of the work performed.
        \item If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.
        \item Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
        \item The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
        \item The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
        \item If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
    \end{itemize}
    
\item {\bf Safeguards}
    \item[] Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)?
    \item[] Answer: \answerNA{} % Replace by \answerYes{}, \answerNo{}, or \answerNA{}.
    \item[] Justification: The paper poses no such risks.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the paper poses no such risks.
        \item Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. 
        \item Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.
        \item We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
    \end{itemize}

\item {\bf Licenses for existing assets}
    \item[] Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected?
    \item[] Answer: \answerYes{} % Replace by \answerYes{}, \answerNo{}, or \answerNA{}.
    \item[] Justification: The original papers that introduce models and datasets used in the paper are cited in Sec.~\ref{sec:experiments}.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the paper does not use existing assets.
        \item The authors should cite the original paper that produced the code package or dataset.
        \item The authors should state which version of the asset is used and, if possible, include a URL.
        \item The name of the license (e.g., CC-BY 4.0) should be included for each asset.
        \item For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
        \item If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, \url{paperswithcode.com/datasets} has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
        \item For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
        \item If this information is not available online, the authors are encouraged to reach out to the asset's creators.
    \end{itemize}

\item {\bf New Assets}
    \item[] Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets?
    \item[] Answer: \answerNA{} % Replace by \answerYes{}, \answerNo{}, or \answerNA{}.
    \item[] Justification: Currently, the paper does not release new assets. Our source code will be released upon the acceptance of the paper with comprehensive documents. As parts of the documents, we formally describe our proposed model and the corresponding details in Sec.~\ref{sec:train} and~\ref{sec:test}. The training details are presented in Appendix.~\ref{app:exp-detail}.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the paper does not release new assets.
        \item Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. 
        \item The paper should discuss whether and how consent was obtained from people whose asset is used.
        \item At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
    \end{itemize}

\item {\bf Crowdsourcing and Research with Human Subjects}
    \item[] Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? 
    \item[] Answer: \answerNA{} % Replace by \answerYes{}, \answerNo{}, or \answerNA{}.
    \item[] Justification: The paper does not involve crowdsourcing nor research with human subjects.
    
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
        \item Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. 
        \item According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. 
    \end{itemize}

\item {\bf Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects}
    \item[] Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained?
    \item[] Answer: \answerNA{} % Replace by \answerYes{}, \answerNo{}, or \answerNA{}.
    \item[] Justification: This paper does not incur such risks.
    \item[] Guidelines:
    \begin{itemize}
        \item The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
        \item Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper. 
        \item We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. 
        \item For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.
    \end{itemize}

\end{enumerate}


\end{document}