\section{Solution Design}~\label{sec:approach}
This section defines our notation and then presents our proposed approaches, \kashif and \RICE, as well as the baseline which we re-implemented as part our multi-solution study.

\subsection{Notation}~\label{subsec:def}
Let $\mathcal{R}=\{r_1, r_2, \ldots, r_n\}$ be a set of requirements and $\mathcal{C}=\{c_1, c_2, \ldots, c_m\}$ be a set of provisions derived from applicable regulations. 
Candidate trace links can be created through the Cartesian product between $\mathcal{R}$ and $\mathcal{C}$. 
LRT is then defined as the task of classifying the candidate links into trace links (denoted as $\rightarrow(r_i, c_j)$) or not trace links (denoted as $\centernot\rightarrow(r_i, c_j)$). 
LRT can be regarded as a multi-label classification problem since one requirement can be traced to one or more provisions. 

%In this work, we solve LRT by utilizing semantic similarity in two main steps. First, we use ST to compute the semantic similarity between each $r_i\in\mathcal{R}$ and $c_j\in \mathcal{C}$. 
%Second, we use the resulting similarity values to predict whether a trace link exists between $r_i$ and $c_j$. 

%\subsection{\kashif }

To predict trace links between requirements and provisions, \kashif utilizes Sentence Transformers (ST) and cosine similarity~\cite{Manning:08}.  
%
%\textcolor{blue}{The intuition behind using the ST model and cosine similarity technique is that requirements and regulations with trace links are expected to have more similar text representations compared to those without trace links. Therefore, \kashif builds on this intuition and strengthens it by utilizing Noise Contrastive Estimation (NCE)~\cite{pmlr-v9-gutmann10a}}.

\subsection{\kashif}
Fig.~\ref{fig:approach} provides a comprehensive overview of the two phases comprising our approach. 
Phase A covers steps~1-3 and offers a developer's perspective, focusing on building a traceability model for solving LRT. 
Step~1 prepares a training dataset of manually identified trace links. 
Step~2 selects a pre-trained model to customize for addressing LRT. Step~3 involves fine-tuning the LRT model.   
%
Phase B covers steps~4-6 and provides the perspective of an end user (e.g., a requirements analyst) assuming the availability of an LRT model.  
Step~4 preprocesses the input requirements document (RD). Step~5 applies the LRT model to compute the semantic similarities between each requirement in the RD and each provisions. Step~6 predicts trace links. 
We explain these steps in detail next.     

\begin{figure}[t]
\includegraphics[width=0.8\textwidth]{Approach.pdf}
  %\centering
 %\vspace*{-1em}
  \caption{Overview of \kashif.}
  %\vspace*{-1.5em}
  \label{fig:approach}
\end{figure}

\subsection*{Step~1: Training set preparation } 
Step~1 assumes the availability of a labeled dataset for LRT. We discuss the dataset used in our work in Section~\ref{subsec:datacol}. 
In this step, we transform the training examples into a format suitable for fine-tuning the pre-trained ST models. Each training example is represented as a triple $\langle r_i,c_j,\ell\rangle$, where $\ell=1$ when $r_i$ and $c_j$ have a trace link (positive sample) and $\ell=0$ (negative sample) otherwise. 

\subsection*{Step~2: Model Selection} 
Defining which pre-trained models to start with has become a challenging task due to the regular release of new models\footnote{As of May 15, 2024, there are 124 ST pre-trained models available on HuggingFace.}. 
Ideally, one should fine-tune all available models to select the best-performing one. However, since fine-tuning is resource-intensive, we narrow down the alternatives for experimentation in this step. 
%
Selecting the best ST model in step~2 is the subject of RQ1,  elaborated in Section~\ref{subsec:rq1}.  

\subsection*{Step~3: Model fine-tuning } \label{sec:fine-tunning}
In step~3, we fine-tune the selected model from step~2. Fine-tuning involves exposing the model to domain-specific knowledge from the provisions and requirements, as well as the particularities of the LRT task. 
During this process, the model learns to assign higher similarity scores when there is a trace link between the requirement and a provision, and lower scores otherwise. 
The resulting \textit{LRT model} is then passed on to step~5.  


\subsection*{Step~4: Preprocessing } 
In  step~4, we preprocess the input requirements using a simple NLP pipeline composed of two modules, namely \textit{Tokenization} and \textit{sentence splitting}. The goal is to decompose the text into separate sentences. In our work, a requirement $r_i$ corresponds to a sentence generated by the NLP pipeline, which may or may not be grammatically correct. 
%
Using \kashif to solve LRT for multi-sentence requirements is straightforward. A provision is traced to the requirement if it is traced to any sentence thereof. The intermediary output of this step is a set of $n$ requirements ($\mathcal{R}=\{r_1, r_2, \ldots, r_n\}$) from the input RD. 

\subsection*{Step~5: Similarity Computation }  
Given a set of $m$ provisions $\mathcal{C}$, step~5 computes the semantic similarity scores between each $r_i\in\mathcal{R}$ and each provision $c_j\in\mathcal{C}$. In this work, we apply cosine similarity, which is a widely-used measure for text similarity~\cite{Jurafsky:20}. 
%
The similarity score is a real value between 0 to 1. A score close to 0 indicates dissimilarity, while a score close to 1 indicates similarity. %Since the LRT model has been fine-tuned on manually identified trace links, it is expected to compute high similarity scores when there are trace links between $r_i$ and $c_j$, and low scores otherwise. 
The output of this step is a matrix of dimension $n \times m$, containing the similarity scores between the $n$ requirements in the RD and the $m$ provisions in $\mathcal{C}$. 

\subsection*{Step~6: Trace links Prediction }  
Step~6 predicts a trace link between $r_i$ and $c_j$ using the similarity matrix from step~5. A trace link is predicted when the similarity between $r_i$ and $c_j$ exceeds a certain threshold $\theta$. 
Below, we discuss alternative methods for setting $\theta$.

\sectopic{(a) Constant Threshold: } 
To predict a trace link, we utilize a pre-defined constant threshold, $\theta = 0.5$. Specifically, a trace link is predicted if the similarity score exceeds $0.5$. 
This threshold is considered a reasonable rule of thumb, as evidenced by its previous application in the literature~\cite{Yao2014,Corley2005}. 

%\input{Files/threshold-method}
\sectopic{(b) Dynamic Threshold: } 
Another practical method to adjust $\theta$ involves curating a set of negative training examples, i.e., requirements that do not have trace links. These requirements can be sourced from publicly available datasets or from different projects. However, for more accurate results, it is ideal to use requirements from the same project under analysis.  
%
Inspired by similarity-based classification proposed in the literature~\cite{Amaral:21}, we select $\theta$ using the following procedure. 
For each provision $c_j \in \mathcal{C}$, we identify a set of negative training examples ($TR_j^-$), i.e., requirements $\{r_1^\prime, \ldots, r_k^\prime\}$ that do not have trace links to $c_j$. We then compute the similarity between $r_i$ and $TR_j^-$ and set $\theta$ to the average cosine similarity between $r_i$ and $TR_j^-$. 
If the similarity between $r_i$ and $c_j$ is higher than the similarity between $r_i$ and $TR_j^-$, then $r_i$ is semantically closer to $c_j$ and should be traced to it.  
Conversely, if the similarity between $r_i$ and $TR_j^-$ is higher, then it should not be traced to $c_j$ as it is semantically  closer to the negative examples.   
This procedure sets a different $\theta$ value for each $r_i$ based on randomly selected negative examples. 

\sectopic{(c) Maximum Delta Cutoff: }
In this method, we apply the following procedure. First, for each $r_i$, we sort the similarity values computed across the different provision $c_j\in\mathcal{C}$. Then, we compute delta values ($\Delta$) corresponding to the differences between each pair of consecutive similarity values and identify the largest $\Delta$ (i.e., the biggest gap in the computed similarities). 
%
To illustrate, consider the following example. Assume $r_i$ has similarity values of 0.98, 0.1, 0.3, and 0.7 with $c_1$, $c_2$, $c_3$, and $c_4$. We sort these values in descending order as follows: $c_1$: 0.98, $c_4$: 0.7, $c_3$: 0.3, $c_2$: 0.1. Next, we compute the $\Delta$ values: $\Delta(c_1, c_4)$=0.28, $\Delta(c_4, c_3)$=0.4, $\Delta(c_3, c_2)$=0.2. Based on these values, the largest $\Delta$ is 0.4 between $c_3$ and $c_4$. 
Finally, we set $\theta$ to the lower similarity value in the pair that yielded the largest $\Delta$. In the above example, we would set $\theta$ to 0.3 (the similarity value between $r_i$  and $c_3$).  
The largest $\Delta$ represents the most significant drop in similarity, indicating a potential boundary between relevant and irrelevant provision for $r_i$.     

The  methods described above result in three variants of \kashif, each determined by how $\theta$ is set. These variants are referred to as \kashif$_{constant}$, \kashif$_{dynamic}$, and \kashif$_\Delta$. We compare these variants in  Section~\ref{sec:evaluation}. 

\subsection{\RICE}~\label{subsec:Prompting_LLMs}
Our second proposed approach, \RICE, is composed of two steps as illustrated in Fig.~\ref{fig:rice}. The first step involves designing a prompt that is effective for addressing LRT. The second step then applies the prompt to instruct an LLM to predict trace links. We elaborate these steps next. 
\begin{figure}[H]
\includegraphics[width=0.7\textwidth]{Rice.pdf}
  %\centering
 %\vspace*{-1em}
  \caption{Overview of \RICE.}
  %\vspace*{-1.5em}
  \label{fig:rice}
\end{figure}

\subsubsection*{Step 1: Prompt Design}
In this step, we designed the prompt following recent best practices reported in the RE literature~\cite{vogelsang2024using,vogelsang2024specifications}. 
\rev{Fig.~\ref{fig:prompt} presents our final prompt, obtained through iterative refinements. 
The prompt was used on each requirement in the input RD, where the input requirement was provided to the LLM at the end of the prompt. To design the prompt, we followed to the \RICE (Role, Instruction, Context, Constraints, Examples) framework to a large extent with some distinctions necessitated by the LRT task, as we discuss below.  
Following this, the prompt is structured in the following five elements: }
\begin{itemize}
    \item \textbf{Context:} This element introduces the LRT task. Since the role is implicitly indicated as a requirements analyst building the trace links, this element subsumes the \textit{Role} element in the original 
    \RICE framework and simply provides  the \textit{Context}. We omitted the explicit mention of the role to obtain a more general applicability of the prompt. 
    For LRT, it is likely that multiple analysts with different backgrounds are involved, e.g., a legal analyst in addition to the requirements analyst. %It can also be considered as the introduction or the role and context component of the RICE template. 
    \rev{Context corresponds to the text shaded in cyan in Fig.~\ref{fig:prompt}. }
    \item \textbf{Examples:} \rev{This element provides a few examples selected from our ground truth. 
    The examples should cover different trace links. } Each example is composed of a requirement and the set of trace links alongside the rationale behind each trace link. We note that the LRT task is complex as we demonstrate throughout the paper. For this reason, we opted for the few-shot prompting technique. This element matches \textit{Examples} in \RICE. \rev{Examples corresponds to the text shaded in pink in Fig.~\ref{fig:prompt}. }
    \item \textbf{Instruction:} This element provides explicit instructions on how to perform the LRT task. This element 
    %have identified four key components that balance flexibility and constraints in the reasoning process. This section is crucial for generating the outputs, as it 
    aims to guide the model through the right reasoning process to generate the desired output. \rev{The \textit{Instruction} element corresponds to the text shaded in olive green in Fig.~\ref{fig:prompt}. }
    Compared to the original \RICE framework, this element contains both the \textit{Instruction} element combined with the \textit{Constraint}. The reason for this is that both elements are intertwined in our context. The  prompt must therefore account for task-specific considerations, explained below. %Therefore, it should be implemented with the goal of aligning with the requirements engineer's objectives. In this paper, we have outlined the following flexibility and constraints:
    \begin{itemize}
        \item[$\bullet$] The prompt should encourage the LLM  to equally consider other provisions, since only a subset of the provisions are explicitly explained via the examples and rationales in the \textit{Examples} element. Ideally, the prompt should present an example on each provision. However, this is infeasible since only relevant provisions should be traced to software requirements in a given project. For instance, if the legal basis for collecting personal data is the \textit{contract}, then unlike explicit consent, only certain \textit{data subject rights} are applicable according to GDPR and must be appropriately implemented in the software.   %regulations and avoid bias toward the regulations shown in the examples.
        %\item[$\bullet$] The prompt should account for  different requirements types (user stories and ``shall'' requirements in our case). %Since we are presenting both "shall" and "use case" requirements to the model (we have highlighted the relevant text in yellow) to draw attention to the roles in the UC requirements, as they may influence the regulation selection.
        \item[$\bullet$] \rev{The prompt should account for indirect trace links. As stated above, the LRT is challenging primarily due to the terminology gap between requirements and provisions. We therefore encourage the LLM to use its reasoning capability to identify indirect links, generalizing beyond the provided examples in the prompt.} %emphasize on   commonsense in the prompt.
        %the GDPR must be  primarily focus on laws related to "personal data" and our test documents contain requirements covering various aspects of data, we have included this section (we have highlighted the relevant text in olive) to guide the model, ensuring it does not become biased toward only "personal data" regulations but also considers other types of data and functionalities.
        %\item Since requirement texts may contain implicit knowledge, we have included guidance (highlighted in green) for the model to pay attention to any form of commonsense or implicit knowledge within the requirements that could be linked to any of the regulations.
        \item[$\bullet$] \rev{The prompt should favor recall by predicting at least one trace link for each requirement. %over precision in our context. Indeed, 
        As we discuss in Section~\ref{sec:evaluation}, filtering out falsely introduced trace links, they are not too numerous, requires less time and effort by the human analyst than identifying missing trace links.} % to some extent more acceptable than missing ones. Though the decision to accept or dismiss proposed trace links must be made by the analyst, this is still more efficient than assigning trace links to each requirement from scratch. 
        % assuming that any additional labels can be filtered out by the analyst. In our context 
        % Finally, we provide the model with the flexibility (highlighted in blue) to select all regulations that may be related to the given requirement text as the final output. In this section, 
    \end{itemize}
    \item \textbf{Output Indicator:} This element clearly describes the output format, \rev{corresponding to the text shaded in violet in Fig.~\ref{fig:prompt}. }%of the expectations for the output format.
\end{itemize}


% \begin{tcolorbox}[breakable=true,arc=1mm,width=\columnwidth,                 top=0mm,left=0mm,  right=0mm, bottom=0mm,
%                   boxrule=1pt,
%                colback=gray!15!white,colframe=white]
% \texttt{I am working on a requirements to GDPR regulatory codes traceability task. Below are the main regulatory codes that I want you to remember at first. \{The 26 regulatory codes with their descriptions + a 27th code capturing the ``ELSE'' value indicating no trace link.\} 
% %
% Below are five example traces. I've also added my rationale for tracing requirements to the regulatory codes for your reference. \{Five example requirements along with their trace links and the rationale behind selecting these links. \}
% %
% Below are a set of untraced requirements. Can you use similar thinking process to mine? Generate the links in format similar to mine (alphabetical order) and your rationale as well. Please consider  regulatory codes which I have not used and make an informed decision. Some other rationale include, we don't have to trace each requirement - some simple functionalities like maintaining buddy lists do not GDPR. I want you to use your critical thinking.}
% \end{tcolorbox}


% \TBD{Where is your input data given in the prompt, Romina? It comes the end of the prompt}
\input{prompt}


\subsubsection*{Step 2: LLM Querying}\label{subsec:LLMQuerying}
This step applies the prompt designed in Step~1 to instruct the LLM to predict trace links in textual requirements. 
%
A prerequisite for using our prompt involves creating few examples that will demonstrate the LRT task to the LLM. To effectively trigger the reasoning of the LLM, we built our few examples by exposing both the labels (i.e., trace links) as well as the rationale behind selecting these labels. The few examples are then integrated into the above RTL prompt template. We applied our prompt by querying the GPT4o model through the web interface. This decision is motivated by simulating a realistic scenario where LLMs act as assistants for requirements engineers. The input data follows after the prompt is provided to the GPT4o model.

Below, we show an example output for a given requirement from  KeePass, a password management   project\footnote{\url{https://keepass.info/extensions/v1/docs/SoftwareRequirementsSpecification\allowbreak-KeePass-1.10.pdf}} using our prompt \rev{(shown in Fig.~\ref{fig:prompt})}. As mentioned above, {we instruct the LLM through our output indicator to generate the rationale for each regulatory code recommended for a given requirement.} The rationale is meant to help the analysts decide whether to accept or disregard a trace link. %The ground truth for this requirement is only \texttt{CON} regulatory code. The predicted set includes two additional regulatory codes (\texttt{ACC} and \texttt{SEC}), along with the rationale for their selection. 
They can examine the reasoning and logic behind these codes generated by the LLM to understand their potential relevance to the requirement and use their knowledge and interpretation of the requirements documents to decide whether \rev{the proposed trace links by the LLM apply in their context.}

\begin{tcolorbox}[arc=1mm,width=\columnwidth,top=0mm,left=0mm,  right=0mm, bottom=0mm,
                  boxrule=1pt,
               colback=gray!15!white,
               colframe=black, breakable, 
               title=GPT4o Example Output, breakable]
% \noindent\textbf{[GPT4o Output]}
\texttt{\textbf{REQ:}  \textit{If a key file is required to unlock the database, the database doesn’t open unless the key file is present.}}
%\newline
\newline
\texttt{\textbf{Trace links:} [ACC, CNF, SEC]}
\newline
\texttt{
\textbf{Rationale:}
\begin{itemize}
    \item ACC\footnote{ACC: Right to access. 
    %Ensure the right to request access to personal data.
    }: The presence of the key file is required to gain access to the database, ensuring proper authentication.
    \item CNF\footnote{CNF: Ensure confidentiality. 
    %Stipulate that the processor ensures that persons authorized to process personal data have committed themselves to confidentiality or are under an appropriate statutory obligation of confidentiality. 
    }: Protecting the database with a key file ensures that sensitive data remains confidential and accessible only to those with the correct authentication file.
    \item SEC\footnote{SEC: Ensuring security. %Take all measures required pursuant to ensure the security of processing. Implement appropriate technical and organizational measures to ensure a level of security appropriate to the risk of varying likelihood and severity for the rights and freedoms of natural persons. 
    }: Requiring a key file adds an additional layer of security, preventing unauthorized access even if the password is compromised.
\end{itemize}
}
\end{tcolorbox}

% We applied each prompt with a batch of 20 requirements to adhere to the token limit size. 

%the web-interface GPT4o model using few-shot learning, summarized as follows: First, we manually add the rationale of selecting the trace links only into the first five requirements.  These requirements along with the selected trace links and the rationale are then used as the ``few-shot'' examples exposed to the GPT model as part of the prompt. Our objective is to investigate whether and to what extent the GPT model can learn the reasoning process behind identifying trace links. }

% \subsubsection*{\rev{Step 1: Prompt Design}}
% \rev{In this step, we developed and designed a specific prompt tailored to the traceability task. This involved carefully crafting a prompt that would guide the model in establishing clear and accurate connections between requirements and relevant regulatory codes.
% % following recent best practices~\cite{vogelsang2024using,vogelsang2024specifications}. 
% % Our prompt follows the \RICE (Role, Instruction, Context, Constraints, Examples) framework. 
% As prompts are task-dependent, they require prompt engineering process which refines a simple prompt based on the task in hand~\cite{vogelsang2024specifications}. Therefore, we have selected a simple template (Instruction, Context, Input Data, Output Indicator) to start with~\cite{vogelsang2024using}.
% % , and 2) a few-shot learning template: Role, Instruction, Context/Constraints, Examples (RICE)\cite{vogelsang2024specifications}. 
% We design our prompt following the procedure of prompt engineering described in recent relevant literature in RE~\cite{vogelsang2024using}. We initially adopted this simple template as a starting point for our traceability task. 
% By identifying the actions and constrains in our problem, we adjusted the template to align with the challenges in the requirement and regulation traceability task. Based on this process, we have designed the following prompt which includes 4 main parts: Problem definition, Few-shot Examples, Actions, and output format. The rationale behind this structure is that we first introduce the task and its context to the model, along with the relevant GDPR regulations to help the model retain the necessary information. Next, we provide five examples to the model, including the ground truth and the reasoning behind their selection, to guide the model in learning how to identify trace links. In the third step, we offer additional instructions to encourage the model to broaden its thinking and avoid becoming biased by the few-shot examples. Finally, we request a structured output from the model for use in subsequent processes.
%  }
% {\color{red}
% \begin{itemize}
%     \item \textbf{Problem definition:} This section briefly describes the main task of regulatory compliance. It provides the regulations and what is expected from the LLM model to do as a requirement analyst. This section can also be considered as the context component.
%     \item \textbf{Few-shot examples:} This section provides examples along with the ground truths and rationales for the model. It can also be viewed as the Example component.
%     \item \textbf{Actions:} This section guides the model on how to perform trace link recovery. To achieve this, we have identified five key components that balance flexibility and constraints in the reasoning process. This section is crucial for generating the outputs, as it influences the model's thinking process. Therefore, it should be implemented with the goal of aligning with the requirements engineer's objectives. This part can be considered as the Instruction and Constraint component. In this paper, we have outlined the following instructions:
%     \begin{itemize}
%         \item Since only a subset of regulations is presented in the few-shot examples, we guide the model to consider all regulations and avoid bias toward the regulations shown in the examples.
%         \item Since we are presenting both "shall" and "use case" requirements to the model to draw attention to the roles in the UC requirements, as they may influence the regulation selection.
%         \item Since the GDPR regulations primarily focus on laws related to "personal data" and our test documents contain requirements covering various aspects of data, we have included this section to guide the model, ensuring it does not become biased toward only "personal data" regulations but also considers other types of data and functionalities.
%         \item Since requirement texts may contain implicit knowledge, we have included guidance for the model to pay attention to any form of commonsense or implicit knowledge within the requirements that could be linked to any of the regulations.
%         \item Finally, we provide the model with the flexibility to select all regulations that may be related to the given requirement text as the final output. In this section, we prioritize recall over precision, assuming that any additional labels can be filtered out by the analyst.
%     \end{itemize}
%     \item \textbf{Output format:} This section outlines clear and direct expectations for the output format. It can be considered the output indicator in the ICIO template.
% \end{itemize}
% }

% \begin{tcolorbox}[breakable=true,arc=1mm,width=\columnwidth,                 top=0mm,left=0mm,  right=0mm, bottom=0mm,
%                   boxrule=1pt,
%                colback=gray!15!white,colframe=white]
% \texttt{I am working on a requirements to GDPR regulatory codes traceability task. Below are the main regulatory codes that I want you to remember at first. \{The 26 regulatory codes with their descriptions + a 27th code capturing the ``ELSE'' value indicating no trace link.\} 
% %
% Below are five example traces. I've also added my rationale for tracing requirements to the regulatory codes for your reference. \{Five example requirements along with their trace links and the rationale behind selecting these links. \}
% %
% Below are a set of untraced requirements. Can you use similar thinking process to mine? Generate the links in format similar to mine (alphabetical order) and your rationale as well. Please consider  regulatory codes which I have not used and make an informed decision. Some other rationale include, we don't have to trace each requirement - some simple functionalities like maintaining buddy lists do not GDPR. I want you to use your critical thinking.}
% \end{tcolorbox}


% \subsubsection*{\rev{Step 2: LLM Querying}}
% \rev{This step applies the prompt desgined in Step~1 to instruct the LLM to predict trace links in textual requirements. 
% %
% A prerequisite for using our prompt involves creating few examples that will be demonstrate the LRT task to the LLM. To effectively trigger the reasoning of the LLM, we built our few examples by exposing both the labels (i.e., trace links) as well as the rationale behind selecting these labels. The few examples are then integrated into the above-illustrated prompt. We applied our prompt by querying the GPT4o model through the web interface. This decision is motivated by simulating a realistic scenario where LLMs act as assistants for requirements engineers. We applied each prompt with a batch of 20 requirements to adhere to the token limit size. 
% }
%the web-interface GPT4o model using few-shot learning, summarized as follows: First, we manually add the rationale of selecting the trace links only into the first five requirements.  These requirements along with the selected trace links and the rationale are then used as the ``few-shot'' examples exposed to the GPT model as part of the prompt. Our objective is to investigate whether and to what extent the GPT model can learn the reasoning process behind identifying trace links. }

\subsection{The Baseline (\texttt{B})}
\rev{To better evaluate our proposed solutions, we re-implement as part of this work a baseline \texttt{B} from the literature~\cite{cleland:2010,Guo:17}. }
\texttt{B} %The baseline 
is a probabilistic approach based on occurrences of words in requirements texts and how likely these words are associated with specific provisions. Specifically, \texttt{B} predicts whether a requirement is traced to a provision by identifying keywords (also known as \textit{indicator terms}) that are present in the requirement. %the goal  have approached the traceability issue as a classification task, wherein the goal is to determine the likelihood of a requirement text being associated with a regulatory code. This is achieved by specific keywords present in the requirement texts tied to the regulatory code, which are determined using the training data. \newline
%The process of classification 
Given an input requirement for which the trace link should be predicted, \texttt{B} requires a training set based on which the likelihood estimates of indicator terms are computed in the input requirement, representing how likely it is relevant to a specific regulation.
The training set is composed of provisions, software requirements, and the trace links between the two. During training, indicator terms are identified and weighted for each provision by parsing the textual requirements traced to these  statements. %, with frequently occurring terms in specific regulation-related requirements designated as \textit{indicator terms}. 
%These indicator terms are weighted based on the likelihood of their occurrence in relation to specific regulations. 
%based on their relevance to regulatory
The weights are computed considering factors such as term frequency in related requirements, the fraction of regulation-related requirements containing the term, and the fraction of projects (specific to the \texttt{HIPAA} dataset) involving regulation-related requirements that also contain the term. 
%The baseline algorithm heavily relies on specific vocabulary and terms, neglecting implicit knowledge within sentences. Additionally, it is computationally inefficient, as it requires a separate classifier for each regulatory code. To address these limitations, our approach incorporates advanced solutions, including sentence embeddings and the GPT model, to enhance both efficiency and understanding.

% These factors aim to identify terms indicative of regulation relevance while mitigating the impact of project-specific terms. \newline
%This technique requires the development of a probabilistic model for each regulatory code contained within the dataset. This is because the weights of indicator terms need to be determined individually for each regulatory code. Moreover, this approach cannot create a classifier for a regulatory code that does not exist in the training set.

\rev{Given the absence of publicly released implementation} for the baseline, we present in this paper a replicated version of \texttt{B} which follows the same procedure described above.  We further adjusted the evaluation to be more realistic and aligned with the one we use for evaluating our proposed approaches.

\subsection{Implementation}
We implement \kashif in Python 3.8. For pre-processing the text, we use the NLTK toolkit (v 3.8.1). 
We access the ST pre-trained models through the
Hugging Face Transformers library (4.44.0). For the fine-tuning, we use the Sentence-Transformers library (2.6.1). We use the same library also for computing the cosine similarity.  
Our experiments were performed on an RTX 6000 GPU with 24 GB of RAM.
%
\rev{We implement \RICE in Python 3.8. using the GPT4o web interface with the default settings enforced by the OpenAI platform, namely a temperature of 0.7, a max-token of 2,000, a frequency penalty of 0.2, and a presence penalty of 0.2. }
%
We also implement \texttt{B} in Python 3.8. We have used the scikit-learn library (1.3.1) to implement the probabilistic functions. 


