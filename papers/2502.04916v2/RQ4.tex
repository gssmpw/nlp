\subsection{Effectiveness of Large Language Model (RQ4) } \label{subsec:rq4}

The baseline performance on the LRT task is extremely poor, highlighting the need for improvement (RQ2). When we attempted a more refined approach using the ST models (\kashif), it performed better than the baseline but fell short of achieving satisfactory results on an unseen dataset (RQ3). This indicates that the ST models can partially address some of the issues inherent in the baseline approach, such as overly simplistic assumptions or the fixed threshold values specific to the HIPAA dataset. However, the ST models lack the robustness needed to generalize effectively across unseen data, as discussed in RQ3. Given their promising results on many tasks~\cite{AroraHH24,abs_2310_18648}, RQ4 aims to assess whether LLMs offer a meaningful alternative for LRT. We posit that LLMs, with their pre-training on different domains, might significantly improve trace link recovery tasks.

\sectopic{Metholodology.} As discussed in Section~\ref{subsec:Prompting_LLMs}, we designed a prompt, based on the RICE structure~\cite{vogelsang2024using}. We prompted the GPT4o model to generate recommendations of trace links between the requirements and the GDPR provisions. We base our analysis on the four documents discussed in RQ3. We compare the recommendations made by the LLM using our prompt for each requirement against our ground truth. 

% However, we understand that even with LLMs, success will depend on careful tuning, prompt engineering, and potentially incorporating domain-specific knowledge to achieve meaningful results. Therefore, we designed a prompt using few-shot learning to help the model learn the rationale behind the selection of regulations. It is important to note that the selection of regulations may vary depending on the rational and reasoning of the requirements engineer.

\sectopic{Evaluation Metrics.} Same as in RQ3. 
% To evaluate the efficacy of LLMs, we report the results at the requirements and trace link levels. At the requirements level, we report (i) the number of requirements where the recommendations made by the LLM were exactly the same as our ground truth (\emph{exact match}); (ii) the number of requirements that were a \emph{partial match} to the ground truth, i.e., the requirements where the LLM recommended the same regulatory codes as in the ground truth along with additional recommendations (FP); 
% %We limit the number of FPs to five, as we deem it a reasonable threshold to balance precision and recall. Beyond this threshold, the recommendations would likely introduce excessive noise, reducing their utility for practical applications; 
% (iii) the number of \emph{incorrect matches}, i.e., all the other requirements that are not exact or partial matches. Following this, we compute the \textit{success rate}  as the ratio of requirements for which the approach predicts correct trace links (considering both partial and exact match) to the total number of requirements. At the trace link level, we report the total number of actual trace links, true positives (TP) and false positives (FP), and recall.

%Driven by the motivation of building a trustworthy recommender system, the predicted trace links for a given requirement are deemed \textit{correct} if they exactly match or contain all of the manually identified links. If the predicted trace links for a requirement miss any manually identified link, then the prediction is considered \textit{incorrect}. For example, if the ground truth identifies for a requirement the trace links \{\texttt{ACC},\texttt{TRN}\}, then the automated recommendations should be exactly  \{\texttt{ACC},\texttt{TRN}\} or fully contain these links (e.g.,  \{\texttt{ACC},\texttt{TRN},\texttt{CON}\}),  assuming that the additional labels can be filtered out by the analyst. However, a recommendation that captures only \{\texttt{ACC}\} would be considered incorrect. The rationale behind this evaluation procedure is that the analyst would not be able to recognize a missing trace link without substantial effort to analyze all regulatory codes, which defeats the purpose of the automated recommendation. In contrast, the analyst would be able to easily spot any falsely predicted trace link. 
%which a \textit{perfect} or \textit{partial} match is obtained against the trace links in the ground truth. We also report on the maximum number of predicted trace links by each approach to assess the manual effort required by the analyst to review and validate the results compared with analyzing the entire set of regulatory codes. 



%consider reporting recall on trace link recovery and the percentage of the trace links that have been retrieved (correct or incorrect) by GPT4o, which is the number of retrieved links divided by the total number of possible links. We aim to demonstrate the number of trace links an engineer needs to review using our technique compared to the total number of possible links. For instance, in Table~\ref{tab:rq4-1}, the Keepass document have 1,664 possible links (calculated as 64 requirements Ã— 26 regulatory codes). The model retrieves 183 (47+136) links with a recall of 82.5\%, it means the engineer only needs to review 183 out of 1,664 links (reduction of 91.4\% or only 9.6\% of the main set).



% \input{Files/tab-RQ4-2}

\sectopic{Results. } Table~\ref{tab:rq4-1} shows the results of the \RICE-based approach, realized by prompting GPT4o. %using an LLM based on our prompt . 
At the trace link level, the results are significantly better than \kashif  (Table~\ref{tab:rq3}), which yielded a 15.0\% average recall across the four documents. In contrast, the LLM-based approach led to a significant improvement with an average recall of 84.0\% at the trace link level.

\input{tab-RQ4}

At the requirements level, there are very low or no exact matches for \RICE. We note that \RICE outputs at least one regulatory code for each requirement (based on our prompt of Section~\ref{subsec:Prompting_LLMs}) even when requirements do not have any trace links in the ground truth. This is one explanation for the sharp decrease in exact matches. Despite this, the number of partial matches has increased to a large extent, thereby improving the overall success rate. While one would ideally like an approach with a high exact match rate, we note that the results are still beneficial, as we discuss next. 
%We posit that it is much easier for an analyst to weed out one or a few false positives rather than matching the requirement to all regulatory codes for false negatives. 



\begin{figure}[!tbh]
\includegraphics[width=\textwidth]{RQ4_FPs_Fig.pdf}
  %\centering
 %\vspace*{-1em}
  \caption{Number of FPs for requirements with partial match (Keepass: RD1, WASP: RD2, Datahub: RD3, and ScrumAlliance: RD4).}
  %\vspace*{-1.5em}
  \label{fig:RQ4_FPsAnalysis}
\end{figure}

Fig.~\ref{fig:RQ4_FPsAnalysis} shows the split of partially matched requirements for the number of FPs. For instance, for RD1, %the KeePass document, 
there were 63 partially matched requirements. Of these, 15 (23.8\%) had only one FP, 34 (54.0\%) had two FPs, and the remaining 14 (22.2\%) had three FPs. As seen in the figure, in all four documents, there were very few requirements with a high number of FPs, i.e., very few had five FPs. 
%
This indicates that most partially matched requirements had a manageable number of FPs, typically between one and three. This result is significant because it suggests that the model's outputs are not overwhelming for analysts to process. Fewer FPs per requirement allow analysts to review and validate the suggested trace links efficiently, reducing their cognitive load. Instead of starting from scratch or sifting through a vast space of 26 possible provisions per requirement, analysts can focus their efforts on validating and refining a much smaller, pre-filtered set of trace links. This aligns with the principle of assisted decision-making~\cite{skitka1999does}, where automated tools augment human judgment by narrowing down options. 

Our results further indicate that the GPTo model successfully demonstrated an understanding of the LRT task despite not being provided with any prior domain-specific information. This indicates that \RICE is effective at identifying the underlying logic and rationale behind provisions, even when provided with only a limited number of few-shot examples. Its ability to navigate complex relationships and extract logical links demonstrates its robustness in understanding the nuances of regulatory requirements. However, the cases it misses highlight areas where the connections may require deeper domain-specific knowledge or additional context to resolve ambiguities.

On investigating the FPs for each requirement, we observed that \rev{several predicted trace links may be relevant depending on the application context, even though they do not exactly match the ground truth. These false positives provide either provisions that are not in the ground truth but are relevant to the input requirements, or some of the provisions in the ground truth (but not all, which is why they are considered partial matches). This underscores the potential of \RICE to identify trace links that correspond to potential associations between requirements and provisions that may not have been contemplated when building the ground truth. Such cases could still be informative to the analysts.}%  understanding of the regulatory landscape. 
For example, the \RICE output presented in Section~\ref{subsec:LLMQuerying} included three predictions with corresponding rationales. Of these, [SEC] is the ground truth, and [ACC] and [CNF] are categorized as FPs. The rationale for [ACC] highlights that requiring a key file ensures proper authentication, which can be interpreted as supporting the right to access. Similarly, the rationale for [CNF] emphasizes that protecting the database with a key file ensures sensitive data remains confidential. While these codes are not explicitly part of the ground truth for this requirement, they surface related regulatory considerations that may enrich the analyst's understanding of the requirement and its broader implications in the context of GDPR. Hence, while FPs may not align perfectly with the ground truth, their contextual relevance based on the generated rationale can offer valuable insights for the LRT task.
This also underscores the inherent subjectivity of the LRT task, especially when dealing with broadly framed regulations like GDPR, which often leave room for interpretation, compared to domain-specific regulations such as \texttt{HIPAA}. 
%
% \TBD{Below we show an example output for a given requirement - ``\textit{As a company, I want to join the Scrum Alliance by paying a corporate membership fee, so that I can show the company's support of Scrum}''. Recall that the prompt requested a rationale for each selection. This helps the analyst decide whether to accept or disregard a trace link. The ground truth for this requirement is only \texttt{CON} regulatory code. The predicted set includes two additional regulatory codes (\texttt{ACC} and \texttt{SEC}), along with the rationale for their selection. This allows the analyst to examine the reasoning and logic behind these codes to understand their potential relevance to the requirement. Based on their own knowledge and interpretation of the requirement documents, the analysis can then decide whether to consider these regulations.}

% \begin{tcolorbox}[arc=1mm,width=\columnwidth,top=0mm,left=0mm,  right=0mm, bottom=0mm,
%                   boxrule=1pt,
%                colback=gray!15!white,
%                colframe=black, breakable, 
%                title=GPT4o Example Output, breakable]
% % \noindent\textbf{[GPT4o Output]}
% \texttt{\textbf{Trace links:} [ACC, CON, SEC]}
% \newline
% \texttt{
% \textbf{Rationale:}
% \begin{itemize}
%     \item ACC\footnote{ACC: Right to access. Ensure the right to request access to personal data.}: The company/person requires access to the platform to complete the membership process and pay the corporate membership fee.
%     \item CON\footnote{CON: Consent. Ensure the data subject gives consent. }: The company must provide consent for their personal and business data to be processed as part of the membership registration and payment.
%     \item SEC\footnote{SEC: Ensuring security. Take all measures required pursuant to ensure the security of processing. Implement appropriate technical and organizational measures to ensure a level of security appropriate to the risk of varying likelihood and severity for the rights and freedoms of natural persons. }: Security measures are essential to protect the company's sensitive financial information and ensure that the payment process is secure and compliant with GDPR.
% \end{itemize}
% }
% \end{tcolorbox}



 


% \textcolor{red}{GPT4o outperforms .....}

\begin{tcolorbox}[arc=1mm,width=\columnwidth,
                  top=0mm,left=0mm,  right=0mm, bottom=0mm,
                  boxrule=1pt, colback=violet!15!white,colframe=white, breakable]
\textbf{The answer to RQ4 is} that our \RICE-based approach which utilizes prompting on GPT4o significantly outperforms \kashif and \texttt{ST29} on the LRT task across the four test documents. Further, \RICE is effective when training data is unavailable, leveraging its internal knowledge and reasoning capabilities alongside a few examples to deliver accurate results. It also generates a rationale for the decisions made and can thus help reduce the manual effort needed to analyze complex LRT scenarios in practice. %Therefore, an approach based on LLMs seems more promising to address the LRT challenge when compared to building classifiers, regardless of the selected modeling approach. 
\end{tcolorbox}