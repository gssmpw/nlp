\section{{Threats to Validity}}~\label{sec:threats}
\sectopic{Internal Validity.} Bias is a well-known internal validity concern. To mitigate bias, in RQ3 and RQ4, the dataset of over four documents was curated by two annotators with more than a decade of experience in RE.  Before the traceability sessions, there was no exposure to technical details related to our approach. The second potential threat to internal validity concerns the few-shot prompting in RQ4. The initial few-shot examples used for GPT4o’s prompt engineering could introduce confirmation bias, potentially influencing the model’s predictions. To mitigate this, we designed the few-shot examples to reflect realistic usage scenarios where LLM is a recommendation tool guided by a human expert’s rationale for the first few requirements. This approach aligns with practical applications while minimizing the risk of confirmation bias. Additionally, the limited number of examples in the few-shot prompt was deliberately chosen to avoid overfitting. By doing so, we allowed the LLM sufficient flexibility to independently apply reasoning across the remaining requirements, maintaining a balance between guidance and adaptability. This approach ensures the LLM's outputs remain broadly applicable while minimizing potential validity threats, as seen by the relatively high success rate in RQ4.

\sectopic{External Validity.} We evaluated \kashif on two datasets, namely \texttt{HIPAA} and four new documents against GDPR. \texttt{HIPAA} is a pre-existing dataset frequently used in the RE literature. The dataset used in RQ3 and RQ4 (with four documents against GDPR), which we created as part of our work, covers two types of textual requirements, including user stories and shall-type requirements. Such diversity helped increase the generalizability of our results. Experiments on more diverse requirements documents and other regulations are nonetheless required to improve the external validity of our study.   


