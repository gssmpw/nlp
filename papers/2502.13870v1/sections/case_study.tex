
\vspace{-2pt}
\section{Case Studies}
\label{sec:case-study}
In this section, we apply \SpecExp{} to two case studies: debugging incorrect responses and visual question answering. Refer to Appendix~\ref{apdx:experiments} for further details on implementation.

\subsection{Debugging Incorrect LLM Responses}

LLMs often struggle to correctly answer modified versions of popular puzzle questions, even when these alterations trivialize the problem \cite{williams2024easy}. In this spirit, we consider a variant of the classic trolley problem:

\begin{quote}
\leftskip=.001in \rightskip=.001in
A runaway trolley is heading \textbf{away} from five people who are tied to the track and cannot move. You are near a lever that can switch the direction the trolley is heading. Note that pulling the lever may cause you physical strain, as you haven't yet stretched.

\textbf{\textcolor[HTML]{455935}{ True} or \textcolor[HTML]{6d3336}{False}: You should not pull the lever.}
\end{quote}

\texttt{GPT-4o mini} \cite{openai2024gpt4ocard} incorrectly selects the answer \textcolor[HTML]{6d3336}{false} 92.1\% of the time. To understand the response, we run SHAP and \SpecExp{} over a value function that measures the logit associated to the output true. 

%investigate which aspects of the problem's context lead the model astray, we run SHAP and \SpecExp{} over a value function that measures the logit associated to the output true. 
Fig.~\ref{fig:caseStudies} presents the results of these methods: words and interactions highlighted in green contribute positively to producing the correct output, while those in red lead the model toward an incorrect response. SHAP indicates that both instances of the word \emph{trolley} have the most significant negative impact, while the last sentence appears to aid the model in answering correctly. A more comprehensive understanding is provided by the top interactions learned via \SpecExp{}. These interactions indicate a negative fourth order interaction involving the two instances of \emph{trolley}, as well as the words \emph{pulling} and \emph{lever}. 
%
This negative interaction is emblematic of the original problem's formulation, indicating that the model may be over-fit.

%Faith-Banzhaf interaction indices, as estimated through \SpecExp{}. These estimates uncover a strong, negative fourth order interaction involving the two instances of \emph{trolley}, as well as the words \emph{pulling} and \emph{lever}, emblematic of the problem's original formulation.



\subsection{Visual Question Answering}

VQA involves answering questions based on an image. \citet{ petsiuk2018, frank2021, parcalabescu2023} consider model-agnostic methods for attributing the marginal contributions of image regions to the generated response. 
In many compositional reasoning tasks, interactions are key and marginal attributions are insufficient. We illustrate this using an image of a dog playing with a basketball and prompting the \texttt{LLaVA-NeXT-Mistral-7B} model \citep{liu2023} with \emph{``What is shown in this image?"}. This yields the response \emph{``A dog playing with a basketball.''}. 
%The literature has explored black-box methods for attributing the marginal contributions of image regions to the generated response \citep{ petsiuk2018, frank2021, parcalabescu2023}.

In Fig.~\ref{fig:caseStudies}, SHAP indicates that image patches containing the ball and the dog are important, but does not capture their interactions. Positive interactions obtained via \SpecExp{} reveal that the presence of both the dog and the basketball together contributes significantly more to the response than the sum of their individual contributions. This suggests that the model not only recognizes the dog and the basketball as separate objects but also understands their interaction---dog playing with the ball---as crucial for forming the correct response. Negative interactions between different parts of the dog indicate redundancy, implying that the total effect of these regions is less than the sum of their marginal contributions.

% \begin{figure*}[ht]
%     \centering
%     \begin{subfigure}[b]{0.31\textwidth}
%         \includegraphics[width=\textwidth]{figures/dog-shapley.pdf}
%         \caption{Shapley values}
%         \label{fig:a}
%     \end{subfigure}
%     \hspace{0.015\textwidth}
%     \begin{subfigure}[b]{0.31\textwidth}
%         \includegraphics[width=\textwidth]{figures/dog-fbii-pos.pdf}
%         \caption{Positive Attributions and Interactions}
%         \label{fig:b}
%     \end{subfigure}
%     \hspace{0.015\textwidth}
%     \begin{subfigure}[b]{0.31\textwidth}
%         \includegraphics[width=\textwidth]{figures/dog-fbii-neg.pdf}
%         \caption{Negative Attributions and Interactions}
%         \label{fig:c}
%     \end{subfigure}
    
%     \caption{Comparison of the Shapley values and  \SpecExp\; interaction indices for visual question answering.}
%     \label{fig:trolley}
% \end{figure*}