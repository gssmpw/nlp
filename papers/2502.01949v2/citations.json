[
  {
    "index": 0,
    "papers": [
      {
        "key": "sanghi2022clip",
        "author": "Sanghi, Aditya and Chu, Hang and Lambourne, Joseph G and Wang, Ye and Cheng, Chin-Yi and Fumero, Marco and Malekshan, Kamal Rahimi",
        "title": "Clip-forge: Towards zero-shot text-to-shape generation"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "jain2022zero",
        "author": "Jain, Ajay and Mildenhall, Ben and Barron, Jonathan T and Abbeel, Pieter and Poole, Ben",
        "title": "Zero-shot text-guided object generation with dream fields"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "michel2022text2mesh",
        "author": "Michel, Oscar and Bar-On, Roi and Liu, Richard and Benaim, Sagie and Hanocka, Rana",
        "title": "Text2mesh: Text-driven neural stylization for meshes"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "wang2022clip",
        "author": "Wang, Can and Chai, Menglei and He, Mingming and Chen, Dongdong and Liao, Jing",
        "title": "Clip-nerf: Text-and-image driven manipulation of neural radiance fields"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "mohammad2022clip",
        "author": "Mohammad Khalid, Nasir and Xie, Tianhao and Belilovsky, Eugene and Popa, Tiberiu",
        "title": "Clip-mesh: Generating textured meshes from text using pretrained image-text models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "poole2022dreamfusion",
        "author": "Poole, Ben and Jain, Ajay and Barron, Jonathan T and Mildenhall, Ben",
        "title": "Dreamfusion: Text-to-3d using 2d diffusion"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "lin2023magic3d",
        "author": "Lin, Chen-Hsuan and Gao, Jun and Tang, Luming and Takikawa, Towaki and Zeng, Xiaohui and Huang, Xun and Kreis, Karsten and Fidler, Sanja and Liu, Ming-Yu and Lin, Tsung-Yi",
        "title": "Magic3d: High-resolution text-to-3d content creation"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "chen2023fantasia3d",
        "author": "Chen, Rui and Chen, Yongwei and Jiao, Ningxin and Jia, Kui",
        "title": "Fantasia3d: Disentangling geometry and appearance for high-quality text-to-3d content creation"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "wang2024prolificdreamer",
        "author": "Wang, Zhengyi and Lu, Cheng and Wang, Yikai and Bao, Fan and Li, Chongxuan and Su, Hang and Zhu, Jun",
        "title": "Prolificdreamer: High-fidelity and diverse text-to-3d generation with variational score distillation"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "wang2023score",
        "author": "Wang, Haochen and Du, Xiaodan and Li, Jiahao and Yeh, Raymond A and Shakhnarovich, Greg",
        "title": "Score jacobian chaining: Lifting pretrained 2d diffusion models for 3d generation"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "tang2023dreamgaussian",
        "author": "Tang, Jiaxiang and Ren, Jiawei and Zhou, Hang and Liu, Ziwei and Zeng, Gang",
        "title": "Dreamgaussian: Generative gaussian splatting for efficient 3d content creation"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "yi2023gaussiandreamer",
        "author": "Yi, Taoran and Fang, Jiemin and Wu, Guanjun and Xie, Lingxi and Zhang, Xiaopeng and Liu, Wenyu and Tian, Qi and Wang, Xinggang",
        "title": "Gaussiandreamer: Fast generation from text to 3d gaussian splatting with point cloud priors"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "chen2024text",
        "author": "Chen, Zilong and Wang, Feng and Wang, Yikai and Liu, Huaping",
        "title": "Text-to-3d using gaussian splatting"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "li2023gaussiandiffusion",
        "author": "Li, Xinhai and Wang, Huaibin and Tseng, Kuo-Kun",
        "title": "Gaussiandiffusion: 3d gaussian splatting for denoising diffusion probabilistic models with structured noise"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "chang2014learning",
        "author": "Chang, Angel and Savva, Manolis and Manning, Christopher D",
        "title": "Learning spatial knowledge for text to 3D scene generation"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "niemeyer2021giraffe",
        "author": "Niemeyer, Michael and Geiger, Andreas",
        "title": "Giraffe: Representing scenes as compositional generative neural feature fields"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "cohen2023set",
        "author": "Cohen-Bar, Dana and Richardson, Elad and Metzer, Gal and Giryes, Raja and Cohen-Or, Daniel",
        "title": "Set-the-scene: Global-local training for generating controllable nerf scenes"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "hollein2023text2room",
        "author": "H{\\\"o}llein, Lukas and Cao, Ang and Owens, Andrew and Johnson, Justin and Nie{\\ss}ner, Matthias",
        "title": "Text2room: Extracting textured 3d meshes from 2d text-to-image models"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "zhang2024text2nerf",
        "author": "Zhang, Jingbo and Li, Xiaoyu and Wan, Ziyu and Wang, Can and Liao, Jing",
        "title": "Text2nerf: Text-driven 3d scene generation with neural radiance fields"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "chen2024vp3d",
        "author": "Chen, Yang and Pan, Yingwei and Yang, Haibo and Yao, Ting and Mei, Tao",
        "title": "Vp3d: Unleashing 2d visual prompt for text-to-3d generation"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "ge2024compgs",
        "author": "Ge, Chongjian and Xu, Chenfeng and Ji, Yuanfeng and Peng, Chensheng and Tomizuka, Masayoshi and Luo, Ping and Ding, Mingyu and Jampani, Varun and Zhan, Wei",
        "title": "CompGS: Unleashing 2D Compositionality for Compositional Text-to-3D via Dynamically Optimizing 3D Gaussians"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "vilesov2023cg3d",
        "author": "Vilesov, Alexander and Chari, Pradyumna and Kadambi, Achuta",
        "title": "Cg3d: Compositional generation for text-to-3d via gaussian splatting"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "kumaran2023scenecraft",
        "author": "Kumaran, Vikram and Rowe, Jonathan and Mott, Bradford and Lester, James",
        "title": "Scenecraft: Automating interactive narrative scene generation in digital games with large language models"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "yang2024holodeck",
        "author": "Yang, Yue and Sun, Fan-Yun and Weihs, Luca and VanderBilt, Eli and Herrasti, Alvaro and Han, Winson and Wu, Jiajun and Haber, Nick and Krishna, Ranjay and Liu, Lingjie and others",
        "title": "Holodeck: Language guided generation of 3d embodied ai environments"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "feng2024layoutgpt",
        "author": "Feng, Weixi and Zhu, Wanrong and Fu, Tsu-jui and Jampani, Varun and Akula, Arjun and He, Xuehai and Basu, Sugato and Wang, Xin Eric and Wang, William Yang",
        "title": "Layoutgpt: Compositional visual planning and generation with large language models"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "zhou2024gala3d",
        "author": "Zhou, Xiaoyu and Ran, Xingjian and Xiong, Yajiao and He, Jinlin and Lin, Zhiwei and Wang, Yongtao and Sun, Deqing and Yang, Ming-Hsuan",
        "title": "Gala3d: Towards text-to-3d complex scene generation via layout-guided generative gaussian splatting"
      }
    ]
  }
]