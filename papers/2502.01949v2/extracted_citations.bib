@inproceedings{chang2014learning,
  title={Learning spatial knowledge for text to 3D scene generation},
  author={Chang, Angel and Savva, Manolis and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={2028--2038},
  year={2014}
}

@inproceedings{chen2023fantasia3d,
  title={Fantasia3d: Disentangling geometry and appearance for high-quality text-to-3d content creation},
  author={Chen, Rui and Chen, Yongwei and Jiao, Ningxin and Jia, Kui},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={22246--22256},
  year={2023}
}

@inproceedings{chen2024text,
  title={Text-to-3d using gaussian splatting},
  author={Chen, Zilong and Wang, Feng and Wang, Yikai and Liu, Huaping},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={21401--21412},
  year={2024}
}

@inproceedings{chen2024vp3d,
  title={Vp3d: Unleashing 2d visual prompt for text-to-3d generation},
  author={Chen, Yang and Pan, Yingwei and Yang, Haibo and Yao, Ting and Mei, Tao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4896--4905},
  year={2024}
}

@inproceedings{cohen2023set,
  title={Set-the-scene: Global-local training for generating controllable nerf scenes},
  author={Cohen-Bar, Dana and Richardson, Elad and Metzer, Gal and Giryes, Raja and Cohen-Or, Daniel},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2920--2929},
  year={2023}
}

@article{feng2024layoutgpt,
  title={Layoutgpt: Compositional visual planning and generation with large language models},
  author={Feng, Weixi and Zhu, Wanrong and Fu, Tsu-jui and Jampani, Varun and Akula, Arjun and He, Xuehai and Basu, Sugato and Wang, Xin Eric and Wang, William Yang},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{ge2024compgs,
  title={CompGS: Unleashing 2D Compositionality for Compositional Text-to-3D via Dynamically Optimizing 3D Gaussians},
  author={Ge, Chongjian and Xu, Chenfeng and Ji, Yuanfeng and Peng, Chensheng and Tomizuka, Masayoshi and Luo, Ping and Ding, Mingyu and Jampani, Varun and Zhan, Wei},
  journal={arXiv preprint arXiv:2410.20723},
  year={2024}
}

@inproceedings{hollein2023text2room,
  title={Text2room: Extracting textured 3d meshes from 2d text-to-image models},
  author={H{\"o}llein, Lukas and Cao, Ang and Owens, Andrew and Johnson, Justin and Nie{\ss}ner, Matthias},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7909--7920},
  year={2023}
}

@inproceedings{jain2022zero,
  title={Zero-shot text-guided object generation with dream fields},
  author={Jain, Ajay and Mildenhall, Ben and Barron, Jonathan T and Abbeel, Pieter and Poole, Ben},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={867--876},
  year={2022}
}

@inproceedings{kumaran2023scenecraft,
  title={Scenecraft: Automating interactive narrative scene generation in digital games with large language models},
  author={Kumaran, Vikram and Rowe, Jonathan and Mott, Bradford and Lester, James},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},
  volume={19},
  number={1},
  pages={86--96},
  year={2023}
}

@article{li2023gaussiandiffusion,
  title={Gaussiandiffusion: 3d gaussian splatting for denoising diffusion probabilistic models with structured noise},
  author={Li, Xinhai and Wang, Huaibin and Tseng, Kuo-Kun},
  journal={arXiv preprint arXiv:2311.11221},
  year={2023}
}

@inproceedings{lin2023magic3d,
  title={Magic3d: High-resolution text-to-3d content creation},
  author={Lin, Chen-Hsuan and Gao, Jun and Tang, Luming and Takikawa, Towaki and Zeng, Xiaohui and Huang, Xun and Kreis, Karsten and Fidler, Sanja and Liu, Ming-Yu and Lin, Tsung-Yi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={300--309},
  year={2023}
}

@inproceedings{michel2022text2mesh,
  title={Text2mesh: Text-driven neural stylization for meshes},
  author={Michel, Oscar and Bar-On, Roi and Liu, Richard and Benaim, Sagie and Hanocka, Rana},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13492--13502},
  year={2022}
}

@inproceedings{mohammad2022clip,
  title={Clip-mesh: Generating textured meshes from text using pretrained image-text models},
  author={Mohammad Khalid, Nasir and Xie, Tianhao and Belilovsky, Eugene and Popa, Tiberiu},
  booktitle={SIGGRAPH Asia 2022 conference papers},
  pages={1--8},
  year={2022}
}

@inproceedings{niemeyer2021giraffe,
  title={Giraffe: Representing scenes as compositional generative neural feature fields},
  author={Niemeyer, Michael and Geiger, Andreas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11453--11464},
  year={2021}
}

@article{poole2022dreamfusion,
  title={Dreamfusion: Text-to-3d using 2d diffusion},
  author={Poole, Ben and Jain, Ajay and Barron, Jonathan T and Mildenhall, Ben},
  journal={arXiv preprint arXiv:2209.14988},
  year={2022}
}

@inproceedings{sanghi2022clip,
  title={Clip-forge: Towards zero-shot text-to-shape generation},
  author={Sanghi, Aditya and Chu, Hang and Lambourne, Joseph G and Wang, Ye and Cheng, Chin-Yi and Fumero, Marco and Malekshan, Kamal Rahimi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18603--18613},
  year={2022}
}

@article{tang2023dreamgaussian,
  title={Dreamgaussian: Generative gaussian splatting for efficient 3d content creation},
  author={Tang, Jiaxiang and Ren, Jiawei and Zhou, Hang and Liu, Ziwei and Zeng, Gang},
  journal={arXiv preprint arXiv:2309.16653},
  year={2023}
}

@article{vilesov2023cg3d,
  title={Cg3d: Compositional generation for text-to-3d via gaussian splatting},
  author={Vilesov, Alexander and Chari, Pradyumna and Kadambi, Achuta},
  journal={arXiv preprint arXiv:2311.17907},
  year={2023}
}

@inproceedings{wang2022clip,
  title={Clip-nerf: Text-and-image driven manipulation of neural radiance fields},
  author={Wang, Can and Chai, Menglei and He, Mingming and Chen, Dongdong and Liao, Jing},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3835--3844},
  year={2022}
}

@inproceedings{wang2023score,
  title={Score jacobian chaining: Lifting pretrained 2d diffusion models for 3d generation},
  author={Wang, Haochen and Du, Xiaodan and Li, Jiahao and Yeh, Raymond A and Shakhnarovich, Greg},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12619--12629},
  year={2023}
}

@article{wang2024prolificdreamer,
  title={Prolificdreamer: High-fidelity and diverse text-to-3d generation with variational score distillation},
  author={Wang, Zhengyi and Lu, Cheng and Wang, Yikai and Bao, Fan and Li, Chongxuan and Su, Hang and Zhu, Jun},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{yang2024holodeck,
  title={Holodeck: Language guided generation of 3d embodied ai environments},
  author={Yang, Yue and Sun, Fan-Yun and Weihs, Luca and VanderBilt, Eli and Herrasti, Alvaro and Han, Winson and Wu, Jiajun and Haber, Nick and Krishna, Ranjay and Liu, Lingjie and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16227--16237},
  year={2024}
}

@article{yi2023gaussiandreamer,
  title={Gaussiandreamer: Fast generation from text to 3d gaussian splatting with point cloud priors},
  author={Yi, Taoran and Fang, Jiemin and Wu, Guanjun and Xie, Lingxi and Zhang, Xiaopeng and Liu, Wenyu and Tian, Qi and Wang, Xinggang},
  journal={arXiv preprint arXiv:2310.08529},
  year={2023}
}

@article{zhang2024text2nerf,
  title={Text2nerf: Text-driven 3d scene generation with neural radiance fields},
  author={Zhang, Jingbo and Li, Xiaoyu and Wan, Ziyu and Wang, Can and Liao, Jing},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  year={2024},
  publisher={IEEE}
}

@article{zhou2024gala3d,
  title={Gala3d: Towards text-to-3d complex scene generation via layout-guided generative gaussian splatting},
  author={Zhou, Xiaoyu and Ran, Xingjian and Xiong, Yajiao and He, Jinlin and Lin, Zhiwei and Wang, Yongtao and Sun, Deqing and Yang, Ming-Hsuan},
  journal={arXiv preprint arXiv:2402.07207},
  year={2024}
}

