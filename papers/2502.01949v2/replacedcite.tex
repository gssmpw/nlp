\section{Related Work}
\subsection{Text-guided 3D Generation}

Early works in text-to-3D generation, such as CLIP-forge ____, Dream Fields ____, Text2Mesh ____, CLIP-NeRF ____, and CLIP-mesh ____ employed CLIP as a guidance mechanism for 3D generation. However, DreamFusion ____ introduced the Score Distillation Sampling (SDS) loss, significantly advancing the quality of 3D models with the aid of 2D diffusion guidance. Magic3D ____ improved the quality of generated models by employing a two-stage optimization process, progressing from coarse to fine. Fantasia3D ____ prioritized the optimization of geometry and texture in 3D models, while ProlificDreamer ____ enhanced the diversity of SDS loss and addressed out-of-distribution issues by introducing Variational Score Distillation. Similarly, Score Jacobian Chaining (SJC) ____ proposed a method for 3D generation using 2D diffusion, leveraging the Perturb-and-Average Scoring (PAAS) technique to iteratively optimize 3D structures. Additionally, other works utilized 3DGS as a 3D representation to achieve rapid and high-fidelity model generation. DreamGaussian ____ initialized 3D Gaussians by randomly assigning positions within a sphere. However, this approach introduced a bias, favoring spherical symmetry in generated structures. In contrast, methods such as GaussianDreamer ____, GSGEN ____, and GaussianDiffusion ____ employed pre-trained 3D generation models to initialize 3D Gaussians, offering a more versatile approach.
% Despite these advancements, these methods face challenges in maintaining consistency in 3D outputs for complex scenes. Our work addresses this limitation by converting text into scene graphs to guide the generation process, facilitating the efficient generation of physically plausible composite 3D scenes.

\subsection{Complex Scene Generation}
Early methods ____ for synthesizing 3D scenes used scene graphs to define objects and organize spatial relationships. Giraffe ____ used compositional NeRF for scene representation, while Set-the-Scene ____ developed a style-consistent, disentangled NeRF-based framework for scene generation. Text2Room ____ and Text2NeRF ____ generated 2D views from text and extrapolated these views to construct 3D scenes but struggled to maintain scene coherence. VP3D ____ and CompGS ____ achieved compositional 3D generation through layout guidance from 2D views. CG3D ____ incorporated gravity and contact constraints during compositional generation to produce physically realistic outcomes. 

With the rise of large language models (LLMs), new inspirations for scene layout have emerged. Methods such as SceneCraft ____, Holodeck ____ and LayoutGPT ____ utilized LLMs or vision-language models (VLMs) to generate complex 3D scenes from the textual descriptions. Nonetheless, due to the hallucination issues inherent in large models, layout confusion can arise in intricate spatial environments. Gala3D ____ utilized coarse layout priors from LLMs and refined the layout through optimization to achieve more structured and coherent scene arrangements. 
% Our work addresses these limitations by constructing initial layouts guided by scene graphs and emphasizing physical layout constraints during training, facilitating the efficient creation of physically plausible composite scenes.