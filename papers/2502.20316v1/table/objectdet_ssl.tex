\begin{table}
\centering
\footnotesize
\caption{Comparison of object detection performance on the nuScenes dataset with state-of-the-art point-based pre-training methods. Following the evaluation protocol of~\citep{yang2023gd-mae,Yang2023UniPADAU}, the methods are finetuned using 20\% labeled frames, without CBGS and copy-paste augmentation.}
\begin{tabular}{p{3.6cm} >{\centering\arraybackslash}p{1.6cm} >{\centering\arraybackslash}p{1.6cm}}
    \toprule
    \textbf{Methods} & \textbf{NDS} & \textbf{mAP} \\
    \midrule
    UVTR-L (Baseline)  & 46.7 & 39.0 \\
    \quad+ALSO\,\citep{boulch2023also} &  48.2 & 41.2 \\
    \quad+GD-MAE\,\citep{yang2023gd-mae} &  48.8 & 42.6 \\
    \quad+Learning from 2D\,\citep{Liu2021LearningF2}& 49.2 & 48.8 \\
    \quad+UniPAD\,\citep{Yang2023UniPADAU}  & 55.8 & 48.1 \\
    \midrule
    \quad+NOMAE (ours) & \textbf{60.9} & \textbf{54.4} \\
\bottomrule
\end{tabular}
\label{tab:objectdet_ssl}
\vspace{-0.5em}
\end{table}