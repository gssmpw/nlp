\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage[rebuttal]{cvpr}

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}

% Import additional packages in the preamble file, before hyperref
\input{preamble}

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,allcolors=cvprblue]{hyperref}

% If you wish to avoid re-using figure, table, and equation numbers from
% the main paper, please uncomment the following and change the numbers
% appropriately.
\setcounter{figure}{9}
\setcounter{table}{13}
\setcounter{equation}{5}

% If you wish to avoid re-using reference numbers from the main paper,
% please uncomment the following and change the counter value to the
% number of references you have in the main paper (here, 100).
\makeatletter
\apptocmd{\thebibliography}{\global\c@NAT@ctr 42\relax}{}{}
\makeatother

%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\paperID{1815} % *** Enter the Paper ID here
\def\confName{CVPR}
\def\confYear{2025}

\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Multi-Scale Neighborhood Occupancy Masked Autoencoder for Self-Supervised Learning in LiDAR Point Clouds}  % **** Enter the paper title here

\maketitle
\thispagestyle{empty}
\appendix

%%%%%%%%% BODY TEXT - ENTER YOUR RESPONSE BELOW
We sincerely thank the reviewers for their valuable comments and feedback. We are happy the reviewers find that NOMAE
"\textit{is well organized and presented}" and achieves "state-of-the-art performance"{\color{red} (TH88)}. "\textit{the motivation is clear}", proposes "\textit{several novel designs to address the problems}" and "\textit{proposes reconstructing occupancy only in the neighborhood of non-masked voxels}", "\textit{clearly explains the technical details}", "\textit{The proposed method is novel with great performance}", and "\textit{the field can learn knowledge from this paper}"{\color{green} (LNUj)}. "\textit{addresses challenges in masked autoencoders for sparse 3D data}","\textit{A good trade-off}", \textit{experiments are extensive and thorough}" and "\textit{scalability with finer voxel resolutions}"{\color{blue} (bhU8)}. 
%Below we respond to the main points raised and will incorporate the suggestions in the final version.
We hope that the clarifications and experiments below further improve the paper. We Will also update the references and correct the typos.  
%We are sure that the additional insights from addressing reviewers main points increase our papers value. 

\noindent\textbf{{\color{red}(TH88)}"\textit{The claimed novelty, i.e., multi-scale and hierarchical masking scheme may not be qualified for CVPR}":}
In addition to the novelties mentioned by the reviewer, we claim Neighborhood Occupancy MAE as a novelty contribution. 
NOMAE is the first \textsl{localized reconstruction} self-supervised learning framework. 
This efficiently solves the positional information leakage problem of standard MAE on point clouds while being better suited for large sparse point clouds compared to full-scene reconstruction in earlier works [23,36].
NOMAE is more effective for representation learning on large scenes,
adding $7.7$~mIoU over existing SSL methods in Tab.~4. 
%We show in Tab. 4 that reconstructing only the neighborhood adds 7.7 mIoU when probing the learned representation for Semseg, compared to full scene reconstruction. 
Single-scale NOMAE needs only a fraction of computational capacity for pretraining compared to earlier works [23,36], enabling supervision at finer scales and at multiple feature levels. %We will change "sparse" to "localized reconstruction" in line 80 to make the contribution clearer.
We will reformulate the parts in the paper to make this contribution clearer. 

\noindent\textbf{{\color{red}(TH88)}"\textit{As said in sec 3.3, muli-scale idea has been used in Geo-MAE, although in a different way}":}
MSP in NOMAE assigns different reconstruction target sets to different layers of different granularity, promoting feature diversity between layers. In contrast, GEO-MAE reconstructs a voxel sub-occupancy at multiple scales, but only from a single feature layer.
This does not promote feature diversity and makes the layer a bottleneck. 
Results in Tab.~3 quantify the performance gain of NOMAE over GEO-MAE. 
Our ablation in the table below adds further evidence by varying only the multi-scale target (GEO-MAE vs our MSP).
The gain from MSP is $\sim3\times$ GeoMAE's MS on nuScenes Semseg val set. 
We will add this experiment to the ablations.
\begin{table}[h]
    \centering
    % \addtolength{\tabcolsep}{-0.5em}
    \footnotesize
    \vspace{-2.2em}
    \begin{tabular}{ccc}
\toprule
        SS $2^s=8$ NOMAE& +GEO-MAE's MS& +our MSP\\
        \midrule
        68.3 & 69.7 & \textbf{72.6}\\
        \bottomrule
    \end{tabular}
    \vspace{-1.6em}
    \label{tab:convergence_semseg}
\end{table}

\noindent\textbf{{\color{red}(TH88)}"\textit{Hierarchical masking seems quite straightforward}":}
We agree with the reviewer, yet the simplicity of HMG adds to its elegance. 
HMG ensures consistent masking ratios across scales, balancing coarse and fine feature learning. 
The effectiveness of HMG is supported by results in Tab.~4 that compare it to existing masking schemes.

\noindent\textbf{{\color{red}(TH88)}"\textit{Tight coupling with PTv3}",{\color{green}(LNUj)}"\textit{demonstrate the generalizability of NOMAE}":}
%We thank them for directing us to test the generalization of NOMAE to other architectures. 
Our work uses PTv3 as it is the strongest baseline model on many benchmark datasets. We agree with the reviewers that a good SSL method should be applicable to a variety of models, including CNNs and transformers. We thank the reviewers for highlighting this issue. Below, we present additional results on nuScenes Semseg val set for SPUnet~[9], OACNNs \href{https://openaccess.thecvf.com/content/CVPR2024/papers/Peng_OA-CNNs_Omni-Adaptive_Sparse_CNNs_for_3D_Semantic_Segmentation_CVPR_2024_paper.pdf}{[43]}, and Octformer \href{https://ojs.aaai.org/index.php/AAAI/article/view/25121/24893}{[44]}.
%We use the same settings as in Sec. 4.3 and Sec. 6 except for the learning rate. 
NOMAE improves the mIoU by 1.8 points on average, even without optimizing the hyperparameters, which we were unable to perform given the limited rebuttal time period. We hypothesize that NOMAE's generalization arises from the feature diversity promoted by MSP. We will add the table to the ablations.
% To the best of our knoweldge, these concepts(i.e. localized reconstruction, MS-SSL at multiple feature levels, Hierarchal Masking) were never introduced in earlier works, and our extensive experiments demonstrate the benefit of each of those contributions. 
\begin{table}[h]
    \centering
    \footnotesize
    \vspace{-0.6em}
    \addtolength{\tabcolsep}{-0.5em}
    \begin{tabular}{lcccccc}
    \toprule
    \textbf{Model} & \multicolumn{2}{c}{Scratch(paper)} & \multicolumn{2}{c}{Scratch(ours)} & \multicolumn{2}{c}{+ NOMAE}\\
    & \textbf{mIoU} & \textbf{mACC} & \textbf{mIoU} & \textbf{mACC}& \textbf{mIoU} & \textbf{mACC} \\
    \midrule
      SPUnet\,[9] &73.3&-&78.6&83.9&80.1&86.2\\ % number of original paper
      OACNNs\,\href{https://openaccess.thecvf.com/content/CVPR2024/papers/Peng_OA-CNNs_Omni-Adaptive_Sparse_CNNs_for_3D_Semantic_Segmentation_CVPR_2024_paper.pdf}{[43]}   &78.9&-&78.8&85.8&80.9&86.4\\ 
      % Octformer\,\href{https://ojs.aaai.org/index.php/AAAI/article/view/25121/24893}{[44]} &-&-&78.4&86.9&80.2&\textbf{88.2}\\
      Octformer\,\href{https://ojs.aaai.org/index.php/AAAI/article/view/25121/24893}{[44]} &-&-&79.4&87.0&81.6&\textbf{88.8}\\ 
      PTv3[31] &80.4&-&80.4&87.3&\textbf{81.8}&87.7\\ 
    \bottomrule
    \end{tabular}
    \vspace{-1.1em}
\end{table}

\noindent\textbf{{\color{blue}(bhU8)}{Results at convergence}:} 
The results of our baselines in Tab.~1 are taken from the original papers, thus after convergence. 
Below, we provide additional results for longer training schedules of $50$, $100$, and $200$ epochs from scratch. 
The results show no significant improvement from longer training, confirming that NOMAE improves sample efficiency. 
We will add the experiment to the paper. 

\begin{table}[h]
    \centering
    \footnotesize
    \vspace{-0.7em}
    \begin{tabular}{cccccc}
    \toprule
        Sup,50 ep~[31]& Sup, 100ep& Sup, 200ep & NOMAE+50ep\\
        \midrule
        80.4 & 80.7 & 80.6& \textbf{81.8}\\
        \bottomrule
    \end{tabular}
    \vspace{-1em}
\end{table}

For object detection, results after convergence show a performance gain through NOMAE, even with only $40$ epochs of training:
\begin{table}[h]
    \centering
    \footnotesize
    % \caption{Objdet mAP and NDS for 20\% labeled data, no CBGS, and no object sample}
    \addtolength{\tabcolsep}{-0.25em}
    \vspace{-0.7em}
    \begin{tabular}{l|ccc|cc}
    \toprule
        &\multicolumn{3}{c}{Scratch}&\multicolumn{2}{c}{NOMAE}\\
        &20ep~[37]&300ep&400ep&20ep&40ep\\
        % \midrule
        %   GEO-MAE\,\citep{tian2023geomae}$^{*}$ &78.6&-&-\\ % number of original paper
        %   GEO-MAE + PTv3$^{*}$ &78.9&84.7&94.4\\
        %   Occupancy-MAE\,\citep{min2022OccupancyMAESP}$^{*}$ &72.9&-&-\\  % number of original paper
        %   Occupancy-MAE + PTv3$^{*}$ &80.0&86.1&94.6\\% number of your re-implementation with PTv3
        %   UniPAD\,~\citep{Yang2023UniPADAU}&79.4&-&-\\
        % %  PTv3 &&&\\ % number of original paper
        \midrule
        NDS/mAP&46.7/39.0& 64.1/56.8& 64.2/56.7 & 60.9/54.5 & \textbf{64.9}/\textbf{58.9}\\
        % NDS&46.7& 58.6& 60.2 & 60.9 & \textbf{64.9}\\
        % mAP&39.0& 51.8& 51.9 & 54.5 & \textbf{58.9}\\
        \bottomrule
    \end{tabular}
    \vspace{-1.0em}
    \label{tab:convergence_objdet}
\end{table}

\noindent\textbf{{\color{blue}(bhU8)}{Object sample augmentation}:} 
We agree with the reviewer that the object sample's database should only use the $20\%$ labeled data.
For this reason, \textsl{we did not use} object sample at all. 
Furthermore, this makes our evaluation consistent with the SSL literature [37]. 
%
%We don't use Object sample augmentation during finetuning or pretraining. 
%We refereed to it as copy paste augmentation in the caption of Tab. 2. 
%We choose to train only for 20 epochs to directly compare with other SSL methods. 
%We didn't use Object sample for the same reason. 
%As reviewer noted, this is not enough for convergence. 
%Results at convergence using for the same setup are as follows,
Below we show results using $100\%$ labeled data, CBGS (1 epoch equals 5 epochs without CBGS), \textsl{with object sample augmentation}:
% \begin{table}[h]
%     \centering
%     \footnotesize
%     % \caption{Objdet mAP and NDS for 100\% labeled data, with CBGS, and object sample}
%     \addtolength{\tabcolsep}{-0.5em}
%     \vspace{-0.5em}
%     \begin{tabular}{lcccc}
%         &backbone&epochs&NDS& mAP\\
%         \midrule
%         UVTR~[20] & SpConv& 20 &67.7 &60.9\\
%         +NOMAE & SpConv& 5& \textbf{\color{red}todo}&\textbf{\color{red}todo}\\

%         UVTR & PTv3& 20& 69.3&64.1 \\
%         +NOMAE & PTv3& 5& \textbf{71.2}&\textbf{67.0} \\
%     \end{tabular}
%     \vspace{-1.0em}
%     \label{tab:convergence_objdet}
% \end{table}

%\begin{table}[h]
%    \centering
%    \footnotesize
    % \caption{Objdet mAP and NDS for 20\% labeled data, no CBGS, and no object sample}
    % \addtolength{\tabcolsep}{-0.25em}
%    \vspace{-1.5em}
%    \begin{tabular}{l|cc|cc}
%        &\multicolumn{2}{c}{Scratch 20ep}&\multicolumn{2}{c}{NOMAE+5ep}\\
%        backbone&SpConv~[37]&PTv3&SpConv&PTv3\\
%        
%        \midrule
%        NDS/mAP&67.7/60.9& 69.3/64.1& {\color{red}todo} & \textbf{71.2}/\textbf{67.0} \\
%    \end{tabular}
%    \vspace{-1.0em}
%\end{table}

\begin{table}[h]
    \centering
    \footnotesize
    % \caption{Objdet mAP and NDS for 20\% labeled data, no CBGS, and no object sample}
    % \addtolength{\tabcolsep}{-0.25em}
    \vspace{-0.7em}
    \begin{tabular}{l|c|c}
    \toprule
        NDS/mAP&{Scratch 20ep}&{NOMAE +5ep}\\
        
        \midrule
        UVTR+PTv3&69.3/64.1& \textbf{71.2}/\textbf{67.0} \\
        UVTR+SPConv~[37]&67.7/60.9& 70.4/65.3 \\
        \bottomrule
    \end{tabular}
    \vspace{-1.0em}
\end{table}

%The results shows that in addition to greatly improving convergence speed, NOMAE improves sample efficiency. We will state it clearly in our results and implementation details.

% After receiving paper reviews, authors may optionally submit a rebuttal to address the reviewers' comments, which will be limited to a {\bf one page} PDF file.
% Please follow the steps and style guidelines outlined below for submitting your author response.

% The author rebuttal is optional and, following similar guidelines to previous conferences, is meant to provide you with an opportunity to rebut factual errors or to supply additional information requested by the reviewers.
% It is NOT intended to add new contributions (theorems, algorithms, experiments) that were absent in the original submission and NOT specifically requested by the reviewers.
% You may optionally add a figure, graph, or proof to your rebuttal to better illustrate your answer to the reviewers' comments.

% Per a passed 2018 PAMI-TC motion, reviewers should refrain from requesting significant additional experiments for the rebuttal or penalize for lack of additional experiments.
% Authors should refrain from including new experimental results in the rebuttal, especially when not specifically requested to do so by the reviewers.
% Authors may include figures with illustrations or comparison tables of results reported in the submission/supplemental material or in other papers.

% Just like the original submission, the rebuttal must maintain anonymity and cannot include external links that reveal the author identity or circumvent the length restriction.
% The rebuttal must comply with this template (the use of sections is not required, though it is recommended to structure the rebuttal for ease of reading).

% %-------------------------------------------------------------------------

% \subsection{Response length}
% Author responses must be no longer than 1 page in length including any references and figures.
% Overlength responses will simply not be reviewed.
% This includes responses where the margins and formatting are deemed to have been significantly altered from those laid down by this style guide.
% Note that this \LaTeX\ guide already sets figure captions and references in a smaller font.

% %------------------------------------------------------------------------
% \section{Formatting your Response}

% {\bf Make sure to update the paper title and paper ID in the appropriate place in the tex file.}

% All text must be in a two-column format.
% The total allowable size of the text area is $6\frac78$ inches (17.46 cm) wide by $8\frac78$ inches (22.54 cm) high.
% Columns are to be $3\frac14$ inches (8.25 cm) wide, with a $\frac{5}{16}$ inch (0.8 cm) space between them.
% The top margin should begin 1 inch (2.54 cm) from the top edge of the page.
% The bottom margin should be $1\frac{1}{8}$ inches (2.86 cm) from the bottom edge of the page for $8.5 \times 11$-inch paper;
% for A4 paper, approximately $1\frac{5}{8}$ inches (4.13 cm) from the bottom edge of the page.

% Please number any displayed equations.
% It is important for readers to be able to refer to any particular equation.

% Wherever Times is specified, Times Roman may also be used.
% Main text should be in 10-point Times, single-spaced.
% Section headings should be in 10 or 12 point Times.
% All paragraphs should be indented 1 pica (approx.~$\frac{1}{6}$ inch or 0.422 cm).
% Figure and table captions should be 9-point Roman type as in \cref{fig:onecol}.


% List and number all bibliographical references in 9-point Times, single-spaced,
% at the end of your response.
% When referenced in the text, enclose the citation number in square brackets, for example~\cite{Alpher05}.
% Where appropriate, include the name(s) of editors of referenced books.

% \begin{figure}[t]
%   \centering
%   \fbox{\rule{0pt}{0.5in} \rule{0.9\linewidth}{0pt}}
%   %\includegraphics[width=0.8\linewidth]{egfigure.eps}
%    \caption{Example of caption.  It is set in Roman so that mathematics
%    (always set in Roman: $B \sin A = A \sin B$) may be included without an
%    ugly clash.}
%    \label{fig:onecol}
% \end{figure}

% To avoid ambiguities, it is best if the numbering for equations, figures, tables, and references in the author response does not overlap with that in the main paper (the reviewer may wonder if you talk about \cref{fig:onecol} in the author response or in the paper).
% See \LaTeX\ template for a workaround.

% %-------------------------------------------------------------------------
% \subsection{Illustrations, graphs, and photographs}

% All graphics should be centered.
% Please ensure that any point you wish to make is resolvable in a printed copy of the response.
% Resize fonts in figures to match the font in the body text, and choose line widths which render effectively in print.
% Readers (and reviewers), even of an electronic copy, may choose to print your response in order to read it.
% You cannot insist that they do otherwise, and therefore must not assume that they can zoom in to see tiny details on a graphic.

% When placing figures in \LaTeX, it is almost always best to use \verb+\includegraphics+, and to specify the  figure width as a multiple of the line width as in the example below
% {\small\begin{verbatim}
%    \usepackage{graphicx} ...
%    \includegraphics[width=0.8\linewidth]
%                    {myfile.pdf}
% \end{verbatim}
% }


%%%%%%%%% REFERENCES
% {
%     \small
%     \bibliographystyle{ieeenat_fullname}
%     \bibliography{main}
% }

\end{document}
