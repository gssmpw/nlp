\section{Related Work}
\vspace{-2mm}
\paragraph{Hallucination Detection Benchmarks.}
 Hallucination in LLMs has been extensively documented in a variety of tasks, including machine translation____, dialogue systems____, text summarization____, and question answering____, as reviewed in recent surveys____. Existing benchmarks for hallucination detection, such as Hades____ and HaluEval____, offer robust methodologies for identifying hallucinated content. However, they predominantly employ generic techniques that fail to account for the nuanced complexities inherent in medical contexts. Similarly, while benchmarks such as HaluBench____ include some medical data samples in their data set, their data generation processes are not specifically tailored for the medical domain. Although Med-HALT____ focuses on medical hallucinations, it mainly serves as a performance evaluation tool rather than providing a structured dataset. In contrast, our work introduces the first comprehensive dataset for medical hallucination detection, employing controlled methods to address these domain-specific challenges.
\vspace{-2mm}
\paragraph{Semantic Analysis of Hallucinated Text.}
Hallucinated sentences often sound over-confident____ and frequently contain tokens that are statistically improbable within a given context, primarily due to suboptimal decoding strategies. Fine-tuned models have sought to mitigate this issue by adjusting decoding parameters to enhance factual accuracy, thereby reducing the occurrence of rare or anomalous terms in hallucinated outputs____. Despite these advancements, previous research has not systematically compared hallucinated sentences with their corresponding ground truth to assess semantic similarities. Our work fills this gap by uncovering deeper semantic relationships between hallucinated texts and their ground truth counterparts.
\vspace{-2mm}

\paragraph{Improvement Methods in Hallucination Detection.}

Recent advancements in hallucination detection have focused on integrating external knowledge to enhance model performance. Retrieval-augmented methods____ have mitigate hallucinations via grounding models in general knowledge. However, few studies have examined the impact of domain-specific knowledge on hallucination detection tasks. While HaluEval____ evaluates knowledge-augmented detection, it lacks fine-grained, domain-relevant knowledge integration. LLMs often overestimate their competence ____, which underscores the need for structured mechanisms to allow models to abstain from answering when uncertain. Prior works have leveraged reinforcement learning____, conformal abstention____, or likelihood score and entropy-based metrics____ to guide refusal decisions. However, these methods rely on complex supervision or predefined thresholds. More straightforward approaches, such as refusing to answer out-of-domain questions____, offer greater practicality but lack adaptability to domain-specific tasks, particularly in complex fields like medicine. Our work addresses these limitations by (1) incorporating task-specific medical knowledge to enhance hallucination detection and (2) introducing a self-supervised “not sure” class, enabling models to autonomously abstain from answering when uncertain, without requiring elaborate supervision. This dual approach remains under-explored in medical NLP, where precision and reliability are paramount.

\vspace{-3mm}