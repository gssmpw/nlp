\begin{table*}[t]
  \centering
  \renewcommand{\arraystretch}{1.2}
  \begin{adjustbox}{width=\linewidth,center}
  \begin{tabular}{lccccc|ccccc|c}
    \toprule
    \textbf{Model} & \multicolumn{5}{c|}{\textbf{Without Knowledge}} & \multicolumn{5}{c|}{\textbf{With Knowledge}} & \textbf{$\Delta$ F1} \\
    \cmidrule(lr){2-6} \cmidrule(lr){7-11}
      & Overall F1 & Overall P & Easy F1 & Med F1 & Hard F1 
      & Overall F1 & Overall P & Easy F1 & Med F1 & Hard F1 & \\
    \midrule
    \multicolumn{12}{l}{\textbf{General LLMs}} \\
    \cmidrule(lr){1-12}
    Qwen/Qwen2.5-14B-Instruct 
         & $0.623\pm0.005$ & $0.721\pm0.043$ & $0.803\pm0.042$ & $0.620\pm0.014$ & $0.495\pm0.018$ 
         & $0.841\pm0.015$ & $0.843\pm0.020$ & $0.924\pm0.016$ & $0.874\pm0.026$ & $0.764\pm0.007$ 
         & $0.218\pm0.021$ \\
    google/gemma-2-2b-it 
         & $0.482\pm0.100$ & $0.596\pm0.033$ & $0.631\pm0.069$ & $0.454\pm0.099$ & $0.398\pm0.083$ 
         & $0.654\pm0.086$ & $0.736\pm0.071$ & $0.777\pm0.050$ & $0.668\pm0.052$ & $0.566\pm0.093$ 
         & $0.172\pm0.014$ \\
    deepseek-ai/DeepSeek-R1-Distill-Llama-8B & $0.641\pm0.010$ & $0.510\pm0.010$ & $0.711\pm0.022$ & $0.687\pm0.011$ & $0.580\pm0.007$ & $0.679\pm0.001$ & $0.522\pm0.003$ & $0.692\pm0.008$ & $0.686\pm0.006$ & $0.670\pm0.000$ & $0.038\pm0.011$ \\

    meta-llama/Llama-3.1-8B-Instruct 
         & $0.501\pm0.029$ & $0.813\pm0.030$ & $0.691\pm0.017$ & $0.536\pm0.030$ & $0.334\pm0.054$ 
         & $0.763\pm0.048$ & $0.815\pm0.057$ & $0.866\pm0.019$ & $0.804\pm0.010$ & $0.670\pm0.073$ 
         & $0.262\pm0.018$ \\
    meta-llama/Llama-3.2-3B-Instruct 
         & $0.455\pm0.061$ & $0.646\pm0.070$ & $0.616\pm0.050$ & $0.445\pm0.031$ & $0.354\pm0.042$ 
         & $0.685\pm0.070$ & $0.670\pm0.148$ & $0.759\pm0.090$ & $0.704\pm0.027$ & $0.622\pm0.058$ 
         & $0.230\pm0.009$ \\
    Qwen/Qwen2.5-3B-Instruct 
         & $0.606\pm0.000$ & $0.495\pm0.000$ & $0.875\pm0.000$ & $0.602\pm0.000$ & $0.556\pm0.000$ 
         & $0.676\pm0.000$ & $0.514\pm0.000$ & $0.693\pm0.000$ & $0.677\pm0.000$ & $0.661\pm0.000$ 
         & $0.070\pm0.000$ \\
    \midrule
    \textbf{Average (General)} & $0.554$ & $0.641$ & $0.724$ & $0.566$ & $0.450$ & $0.728$ & $0.691$ & $0.796$ & $0.748$ & $0.672$ & $0.175$ \\

    \midrule
    \multicolumn{12}{l}{\textbf{Medical Fine-Tuned LLMs}} \\
    \cmidrule(lr){1-12}
    m42-health/Llama3-Med42-8B 
         & $0.354\pm0.088$ & $0.733\pm0.136$ & $0.547\pm0.075$ & $0.311\pm0.096$ & $0.236\pm0.040$ 
         & $0.768\pm0.040$ & $0.831\pm0.036$ & $0.874\pm0.035$ & $0.782\pm0.016$ & $0.688\pm0.028$ 
         & $0.414\pm0.048$ \\
    OpenMeditron/Meditron3-8B 
         & $0.280\pm0.000$ & $0.856\pm0.000$ & $0.476\pm0.000$ & $0.338\pm0.000$ & $0.164\pm0.000$ 
         & $0.651\pm0.000$ & $0.840\pm0.000$ & $0.790\pm0.000$ & $0.690\pm0.000$ & $0.557\pm0.000$ 
         & $0.372\pm0.000$ \\
    aaditya/OpenBioLLM-Llama3-8B 
         & $0.505\pm0.031$ & $0.523\pm0.046$ & $0.519\pm0.035$ & $0.499\pm0.035$ & $0.502\pm0.028$ 
         & $0.489\pm0.093$ & $0.550\pm0.024$ & $0.500\pm0.087$ & $0.483\pm0.101$ & $0.556\pm0.006$ 
         & $-0.016\pm0.062$ \\
    BioMistral/BioMistral-7B 
         & $0.584\pm0.019$ & $0.520\pm0.003$ & $0.615\pm0.018$ & $0.611\pm0.067$ & $0.545\pm0.028$ 
         & $0.652\pm0.006$ & $0.519\pm0.004$ & $0.652\pm0.000$ & $0.676\pm0.024$ & $0.637\pm0.005$ 
         & $0.068\pm0.013$ \\
    TsinghuaC3I/Llama-3.1-8B-UltraMedical 
         & $0.619\pm0.001$ & $0.662\pm0.006$ & $0.775\pm0.040$ & $0.611\pm0.021$ & $0.520\pm0.005$ 
         & $0.725\pm0.068$ & $0.609\pm0.099$ & $0.783\pm0.069$ & $0.875\pm0.025$ & $0.682\pm0.051$ 
         & $0.106\pm0.066$ \\
    \midrule
    \textbf{Average (Medical)} 
         & $0.468$ & $0.659$ & $0.586$ & $0.474$ & $0.393$ 
         & $0.657$ & $0.670$ & $0.720$ & $0.701$ & $0.624$ 
         & $0.189$ \\
    \bottomrule
  \end{tabular}
  \end{adjustbox}
  \caption{Medhallu data generated by Qwen2.5-14B (1,000 samples of pqa\_labeled). Mean $\pm$ standard deviation of performance metrics (Overall F1, Overall Precision, Easy/Medium/Hard F1) for various LLMs under two conditions: without and with external knowledge. The final column ($\Delta$ F1) shows the difference in F1 scores (with knowledge minus without knowledge).}
  \label{tab:llm_performance_qwen}
\end{table*}
