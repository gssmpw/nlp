\begin{table*}[t]
    \centering
    \renewcommand{\arraystretch}{1.2}
    \begin{adjustbox}{width=1\linewidth,center}
    \begin{tabular}{lccccc|ccccc|c}
    \toprule
    \textbf{Model} & \multicolumn{5}{c|}{\textbf{Without Knowledge}} & \multicolumn{5}{c|}{\textbf{With Knowledge}} & \textbf{$\Delta$ F1} \\
    \cmidrule(lr){2-6} \cmidrule(lr){7-11}
     & Overall F1 & Overall P & Easy F1 & Med F1 & Hard F1 
       & Overall F1 & Overall P & Easy F1 & Med F1 & Hard F1 & \\
    \midrule
    \multicolumn{12}{l}{\textbf{General LLMs}} \\
    \cmidrule(lr){1-12}
    deepseek-ai/DeepSeek-R1-Distill-Llama-8B 
         & $0.603\pm0.028$ & $0.479\pm0.027$ & $0.773\pm0.186$ & $0.635\pm0.024$ & $0.564\pm0.037$ 
         & $0.682\pm0.002$ & $0.537\pm0.005$ & $0.831\pm0.178$ & $0.696\pm0.049$ & $0.671\pm0.007$ 
         & $0.078\pm0.025$ \\
    Qwen/Qwen2.5-14B-Instruct 
         & $0.646\pm0.004$ & $0.781\pm0.007$ & $0.820\pm0.031$ & $0.681\pm0.012$ & $0.526\pm0.011$ 
         & $0.835\pm0.017$ & $0.846\pm0.010$ & $0.924\pm0.022$ & $0.879\pm0.017$ & $0.781\pm0.021$ 
         & $0.189\pm0.013$ \\
    Qwen/Qwen2.5-3B-Instruct & $0.609\pm0.014$ & $0.489\pm0.011$ & $0.701\pm0.009$ & $0.627\pm0.016$ & $0.560\pm0.016$ & $0.686\pm0.010$ & $0.526\pm0.013$ & $0.692\pm0.009$ & $0.699\pm0.046$ & $0.676\pm0.007$ & $0.077\pm0.025$ \\
    google/gemma-2-2b-it 
         & $0.408\pm0.004$ & $0.551\pm0.013$ & $0.567\pm0.015$ & $0.347\pm0.086$ & $0.302\pm0.031$ 
         & $0.607\pm0.004$ & $0.684\pm0.011$ & $0.710\pm0.012$ & $0.623\pm0.027$ & $0.545\pm0.016$ 
         & $0.199\pm0.008$ \\
    meta-llama/Llama-3.1-8B-Instruct 
         & $0.484\pm0.005$ & $0.768\pm0.061$ & $0.674\pm0.046$ & $0.579\pm0.027$ & $0.269\pm0.050$ 
         & $0.741\pm0.000$ & $0.873\pm0.000$ & $0.903\pm0.007$ & $0.843\pm0.068$ & $0.712\pm0.120$ 
         & $0.310\pm0.070$ \\
    meta-llama/Llama-3.2-3B-Instruct 
         & $0.410\pm0.050$ & $0.593\pm0.083$ & $0.527\pm0.091$ & $0.394\pm0.143$ & $0.369\pm0.032$ 
         & $0.645\pm0.001$ & $0.584\pm0.007$ & $0.776\pm0.068$ & $0.731\pm0.102$ & $0.636\pm0.053$ 
         & $0.235\pm0.049$ \\
    \midrule
    \textbf{Average (General)} & $0.526$ & $0.610$ & $0.677$ & $0.544$ & $0.432$ & $0.699$ & $0.675$ & $0.806$ & $0.745$ & $0.670$ & $0.181$ \\

    \midrule
    \multicolumn{12}{l}{\textbf{Medical Fine-Tuned LLMs}} \\
    \cmidrule(lr){1-12}
    m42-health/Llama3-Med42-8B 
         & $0.296\pm0.008$ & $0.633\pm0.031$ & $0.500\pm0.026$ & $0.325\pm0.023$ & $0.184\pm0.022$ 
         & $0.722\pm0.008$ & $0.786\pm0.010$ & $0.805\pm0.014$ & $0.788\pm0.004$ & $0.654\pm0.004$ 
         & $0.425\pm0.000$ \\
    OpenMeditron/Meditron3-8B 
         & $0.273\pm0.043$ & $0.835\pm0.026$ & $0.473\pm0.029$ & $0.285\pm0.078$ & $0.160\pm0.039$ 
         & $0.685\pm0.009$ & $0.879\pm0.006$ & $0.827\pm0.004$ & $0.700\pm0.002$ & $0.611\pm0.022$ 
         & $0.412\pm0.052$ \\
    aaditya/OpenBioLLM-Llama3-8B 
         & $0.546\pm0.039$ & $0.571\pm0.057$ & $0.556\pm0.001$ & $0.555\pm0.082$ & $0.536\pm0.037$ 
         & $0.566\pm0.028$ & $0.555\pm0.021$ & $0.578\pm0.042$ & $0.555\pm0.055$ & $0.565\pm0.009$ 
         & $0.019\pm0.011$ \\
    BioMistral/BioMistral-7B 
         & $0.617\pm0.007$ & $0.540\pm0.006$ & $0.760\pm0.000$ & $0.663\pm0.044$ & $0.577\pm0.016$ 
         & $0.651\pm0.013$ & $0.522\pm0.015$ & $0.832\pm0.137$ & $0.683\pm0.009$ & $0.607\pm0.001$ 
         & $0.001\pm0.066$ \\
    TsinghuaC3I/Llama-3.1-8B-UltraMedical 
         & $0.611\pm0.026$ & $0.649\pm0.037$ & $0.776\pm0.037$ & $0.668\pm0.010$ & $0.501\pm0.042$ 
         & $0.704\pm0.013$ & $0.571\pm0.019$ & $0.760\pm0.024$ & $0.714\pm0.033$ & $0.672\pm0.002$ 
         & $0.093\pm0.013$ \\
    \midrule
    \textbf{Average (Medical)} 
         & $0.469$ & $0.646$ & $0.613$ & $0.499$ & $0.392$ 
         & $0.666$ & $0.663$ & $0.760$ & $0.688$ & $0.622$ 
         & $0.190$ \\
    \bottomrule
  \end{tabular}
    \end{adjustbox}
    \caption{Medhallu data generated by Gemma2-9B-it (1,000 samples of pqa\_labeled). Mean $\pm$ standard deviation of performance metrics (Overall F1, Overall Precision, Easy/Medium/Hard F1) for various LLMs under two conditions: without and with external knowledge. The final column ($\Delta$ F1) shows the difference in F1 scores (with knowledge minus without knowledge).}
    \label{tab:llm_performance_gemma}
\end{table*}
