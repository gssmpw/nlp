% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").
% gestures for reference resolution
@String{AP   = {Ann. Phys.}}
@book{Kendon2004,
    author = {Kendon, Adam},
    title = {Gesture: Visible Action as Utterance},
    chapter = {7},
    pages = {108--126},
    publisher = {Cambridge University Press},
    year = {2004},
    doi = {10.1017/CBO9780511807572.007}
}
@inproceedings{haber2019photobook,
  title={The PhotoBook Dataset: Building Common Ground through Visually-Grounded Dialogue},
  author={Haber, Janosch and Baumg{\"a}rtner, Tim and Takmaz, Ece and Gelderloos, Lieke and Bruni, Elia and Fern{\'a}ndez, Raquel},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={1895--1910},
  year={2019}
}

@article{clark1986referring,
  title={Referring as a collaborative process},
  author={Clark, Herbert H and Wilkes-Gibbs, Deanna},
  journal={Cognition},
  volume={22},
  number={1},
  pages={1--39},
  year={1986},
  publisher={Elsevier}
}
@article{McNeill1992,
    author = {McNeill, David},
    title = {Hand and mind},
    journal = {Advances in Visual Semiotics},
    volume = {351},
    year = {1992}
}

@article{HollerLevinson2019,
    author = {Holler, Judith and Levinson, Stephen C},
    title = {Multimodal language processing in human communication},
    journal = {Trends in Cognitive Sciences},
    volume = {23},
    number = {8},
    pages = {639--652},
    year = {2019}
}

@incollection{HollerWilkin2020,
    author = {Holler, Judith and Wilkin, Katie},
    title = {Speech Accompanying-Gesture},
    booktitle = {Communicating common ground: How mutually shared knowledge influences speech and gesture in a narrative task},
    pages = {267--289},
    publisher = {Psychology Press},
    year = {2020}
}

@article{TerBekke2024,
    author = {Ter Bekke, Marlijn and Drijvers, Linda and Holler, Judith},
    title = {Hand Gestures Have Predictive Potential During Conversation: An Investigation of the Timing of Gestures in Relation to Speech},
    journal = {Cognitive Science},
    volume = {48},
    number = {1},
    pages = {e13407},
    year = {2024}
}

@article{Eijk2022,
    author = {Eijk, Lotte and Rasenberg, Marlou and Arnese, Flavia and others},
    title = {The CABB dataset: A multimodal corpus of communicative interactions for behavioural and neural analyses},
    journal = {NeuroImage},
    volume = {264},
    year = {2022},
    pages = {119734}
}

@article{Nyatsanga2023,
    author = {Nyatsanga, S. and Kucherenko, T. and Ahuja, C. and others},
    title = {A Comprehensive Review of Data-Driven Co-Speech Gesture Generation},
    journal = {Computer Graphics Forum},
    volume = {42},
    pages = {569--596},
    year = {2023}
}

@inproceedings{Vaswani2017,
    author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and others},
    title = {Attention is all you need},
    booktitle = {Advances in neural information processing systems},
    volume = {30},
    year = {2017}
}

@inproceedings{Zhu2023,
    author = {Zhu, Wentao and Ma, Xiaoxuan and Liu, Zhaoyang and others},
    title = {Motionbert: A unified perspective on learning human motion representations},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
    year = {2023},
    pages = {15085--15099}
}

@article{Baevski2020,
    author = {Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
    title = {wav2vec 2.0: A framework for self-supervised learning of speech representations},
    journal = {Advances in neural information processing systems},
    volume = {33},
    year = {2020},
    pages = {12449--12460}
}

@inproceedings{Yoon2019,
    author = {Yoon, Youngwoo and Ko, Woo-Ri and Jang, Minsu and others},
    title = {Robots learn social skills: End-to-end learning of co-speech gesture generation for humanoid robots},
    booktitle = {2019 International Conference on Robotics and Automation (ICRA)},
    organization = {IEEE},
    year = {2019},
    pages = {4303--4309}
}

@Book{1979_Adams,
  author =	 {Douglas Adams},
  editor =	 { },
  title =	 {The Hitchhiker's Guide to the Galaxy},
  publisher =	 {},
  year =	 1979,
  address =	 {London, UK},
}

@Article{1905_Einstein,
  author =	 {Albert Einstein},
  title =	 {{\"U}ber die von der molekularkinetischen Theorie
                  der W{\"a}rme geforderte Bewegung von in ruhenden
                  Fl{\"u}ssigkeiten suspendierten Teilchen},
  journal =	 AP,
  year =	 1905,
  volume =	 17,
  pages =	 {549-560}
}
@article{skantze2022collie,
  title={Collie: Continual learning of language grounding from language-image embeddings},
  author={Skantze, Gabriel and Willemsen, Bram},
  journal={Journal of Artificial Intelligence Research},
  volume={74},
  pages={1201--1223},
  year={2022}
}
@inproceedings{takmaz2020refer,
  title={Refer, Reuse, Reduce: Generating Subsequent References in Visual and Conversational Contexts},
  author={Takmaz, Ece and Giulianelli, Mario and Pezzelle, Sandro and Sinclair, Arabella and Fern{\'a}ndez, Raquel},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={4350},
  year={2020},
  organization={Association for Computational Linguistics}
}
@inproceedings{moon2020situated,
  title={Situated and Interactive Multimodal Conversations},
  author={Moon, Seungwhan and Kottur, Satwik and Crook, Paul A and De, Ankita and Poddar, Shivani and Levin, Theodore and Whitney, David and Difranco, Daniel and Beirami, Ahmad and Cho, Eunjoon and others},
  booktitle={Proceedings of the 28th International Conference on Computational Linguistics},
  pages={1103--1121},
  year={2020}
}
@inproceedings{yoon2019robots,
  title={Robots learn social skills: End-to-end learning of co-speech gesture generation for humanoid robots},
  author={Yoon, Youngwoo and Ko, Woo-Ri and Jang, Minsu and Lee, Jaeyeon and Kim, Jaehong and Lee, Geehyuk},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={4303--4309},
  year={2019},
  organization={IEEE}
}
@inproceedings{chen2021yourefit,
  title={Yourefit: Embodied reference understanding with language and gesture},
  author={Chen, Yixin and Li, Qing and Kong, Deqian and Kei, Yik Lun and Zhu, Song-Chun and Gao, Tao and Zhu, Yixin and Huang, Siyuan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1385--1395},
  year={2021}
}
@incollection{matuszek2023grounding,
  title={Grounding Spoken Language},
  author={Matuszek, Cynthia},
  booktitle={Sound and Robotics},
  pages={76--98},
  year={2023},
  publisher={Chapman and Hall/CRC}
}
@inproceedings{kebe2022bridging,
  title={Bridging the gap: Using deep acoustic representations to learn grounded language from percepts and raw speech},
  author={Kebe, Gaoussou Youssouf and Richards, Luke E and Raff, Edward and Ferraro, Francis and Matuszek, Cynthia},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  pages={10884--10893},
  year={2022}
}

@inproceedings{kontogiorgos2018multimodal,
  title={Multimodal reference resolution in collaborative assembly tasks},
  author={Kontogiorgos, Dimosthenis and Sibirtseva, Elena and Pereira, Andre and Skantze, Gabriel and Gustafson, Joakim},
  booktitle={Proceedings of the 4th International Workshop on Multimodal Analyses Enabling Artificial Agents in Human-Machine Interaction},
  pages={38--42},
  year={2018}
}
@article{kennington2017simple,
  title={A simple generative model of incremental reference resolution for situated dialogue},
  author={Kennington, Casey and Schlangen, David},
  journal={Computer Speech \& Language},
  volume={41},
  pages={43--67},
  year={2017},
  publisher={Elsevier}
}

@inproceedings{shore2018using,
  title={Using lexical alignment and referring ability to address data sparsity in situated dialog reference resolution},
  author={Shore, Todd and Skantze, Gabriel},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={2288--2297},
  year={2018}
}

@article{van2019artificial,
  title={Artificial Intelligence Research Agenda for the Netherlands},
  author={van den Bosch, A and van Dijck, J and Helberger, N and Heylen, D and Hindriks, K and Hoos, H and Lagendijk, I and de Rijke, M and Niessen, W and Verheij, B and others},
  year={2019},
  publisher={The HagueNWO}
}


@inproceedings{campana2005real,
  title={Real-time integration of gesture and speech during reference resolution},
  author={Campana, Ellen and Silverman, Laura and Tanenhaus, Michael K and Bennetto, Loisa and Packard, Stephanie},
  booktitle={Proceedings of the 27th annual meeting of the Cognitive Science Society},
  pages={378--383},
  year={2005}
}

% == Reference resolution

@article{KenningtonSchlangen2017,
title = {A simple generative model of incremental reference resolution for situated dialogue},
journal = {Computer Speech \& Language},
volume = {41},
pages = {43-67},
year = {2017},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2016.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S0885230815300127},
author = {Casey Kennington and David Schlangen}
}

@inproceedings{gatt-paggio-2013-empirical,
    title = "What and Where: An Empirical Investigation of Pointing Gestures and Descriptions in Multimodal Referring Actions",
    author = "Gatt, Albert  and
      Paggio, Patrizia",
    editor = "Gatt, Albert  and
      Saggion, Horacio",
    booktitle = "Proceedings of the 14th {E}uropean Workshop on Natural Language Generation",
    month = aug,
    year = "2013",
    address = "Sofia, Bulgaria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W13-2109/",
    pages = "82--91"
}




@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}


@article{conneau2020unsupervised,
  title={Unsupervised cross-lingual representation learning for speech recognition},
  author={Conneau, Alexis and Baevski, Alexei and Collobert, Ronan and Mohamed, Abdelrahman and Auli, Michael},
  journal={arXiv preprint arXiv:2006.13979},
  year={2020}
}

@article{pepino2021emotion,
  title={Emotion Recognition from Speech Using wav2vec 2.0 Embeddings},
  author={Pepino, Leonardo and Riera, Pablo and Ferrer, Luciana},
  journal={Proc. Interspeech 2021},
  pages={3400--3404},
  year={2021}
}

@inproceedings{thoker2021skeleton,
  title={Skeleton-contrastive 3D action representation learning},
  author={Thoker, Fida Mohammad and Doughty, Hazel and Snoek, Cees GM},
  booktitle={Proceedings of the 29th ACM international conference on multimedia},
  pages={1655--1663},
  year={2021}
}

@inproceedings{brinzea2022contrastive,
  title={Contrastive learning with cross-modal knowledge mining for multimodal human activity recognition},
  author={Brinzea, Razvan and Khaertdinov, Bulat and Asteriadis, Stylianos},
  booktitle={2022 International Joint Conference on Neural Networks (IJCNN)},
  pages={01--08},
  year={2022},
  organization={IEEE}
}

@inproceedings{tsai-etal-2022-superb,
    title = "{SUPERB}-{SG}: Enhanced Speech processing Universal {PER}formance Benchmark for Semantic and Generative Capabilities",
    author = "Tsai, Hsiang-Sheng  and
      Chang, Heng-Jui  and
      Huang, Wen-Chin  and
      Huang, Zili  and
      Lakhotia, Kushal  and
      Yang, Shu-wen  and
      Dong, Shuyan  and
      Liu, Andy  and
      Lai, Cheng-I  and
      Shi, Jiatong  and
      Chang, Xuankai  and
      Hall, Phil  and
      Chen, Hsuan-Jui  and
      Li, Shang-Wen  and
      Watanabe, Shinji  and
      Mohamed, Abdelrahman  and
      Lee, Hung-yi",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.580/",
    doi = "10.18653/v1/2022.acl-long.580",
    pages = "8479--8492",
}

@inproceedings{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}

@inproceedings{li2023exploration,
  title={Exploration of a self-supervised speech model: A study on emotional corpora},
  author={Li, Yuanchao and Mohamied, Yumnah and Bell, Peter and Lai, Catherine},
  booktitle={2022 IEEE Spoken Language Technology Workshop (SLT)},
  pages={868--875},
  year={2023},
  organization={IEEE}
}

@inproceedings{ghaleb2024learning,
  title={Learning Co-Speech Gesture Representations in Dialogue through Contrastive Learning: An Intrinsic Evaluation},
  author={Ghaleb, Esam and Khaertdinov, Bulat and Pouw, Wim and Rasenberg, Marlou and Holler, Judith and Ozyurek, Asli and Fern{\'a}ndez, Raquel},
  booktitle={Proceedings of the 26th International Conference on Multimodal Interaction},
  pages={274--283},
  year={2024}
}

@inproceedings{liu2024multi,
  title={Multi-modality co-learning for efficient skeleton-based action recognition},
  author={Liu, Jinfu and Chen, Chen and Liu, Mengyuan},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={4909--4918},
  year={2024}
}

@article{chen2024vision,
  title={Vision-language meets the skeleton: Progressively distillation with cross-modal knowledge for 3d action representation learning},
  author={Chen, Yang and He, Tian and Fu, Junfeng and Wang, Ling and Guo, Jingcai and Hu, Ting and Cheng, Hong},
  journal={IEEE Transactions on Multimedia},
  year={2024},
  publisher={IEEE}
}

@article{zaiem2025speech,
  title={Speech self-supervised representations benchmarking: a case for larger probing heads},
  author={Zaiem, Salah and Kemiche, Youcef and Parcollet, Titouan and Essid, Slim and Ravanelli, Mirco},
  journal={Computer Speech \& Language},
  volume={89},
  pages={101695},
  year={2025},
  publisher={Elsevier}
}


% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries
@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@article{eyben2015opensmile,
  title={openSMILE:) The Munich open-source large-scale multimedia feature extractor},
  author={Eyben, Florian and Schuller, Bj{\"o}rn},
  journal={ACM SIGMultimedia Records},
  volume={6},
  number={4},
  pages={4--13},
  year={2015},
  publisher={ACM New York, NY, USA}
}
%WACV paper on co-speech gestures:
@inproceedings{ghaleb2023co,
  title={Co-Speech Gesture Detection through Multi-phase Sequence Labeling},
  author={Ghaleb, Esam and Burenko, Ilya and Rasenberg, Marlou and Pouw, Wim and Uhrig, Peter and Holler, Judith and Toni, Ivan and {\"O}zy{\"u}rek, Asl{\i} and Fern{\'a}ndez, Raquel},
 booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  year={2024},
address={Hawaai, USA},
publisher={CVF/IEEE}
}
@article{ortega2020types,
  title={Types of iconicity and combinatorial strategies distinguish semantic categories in silent gesture across cultures},
  author={Ortega, Gerardo and {\"O}zy{\"u}rek, Asli},
  journal={Language and Cognition},
  volume={12},
  number={1},
  pages={84--113},
  year={2020},
  publisher={Cambridge University Press}
}
%wav2vec2
@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}
%vggish
@inproceedings{hershey2017cnn,
  title={CNN architectures for large-scale audio classification},
  author={Hershey, Shawn and Chaudhuri, Sourish and Ellis, Daniel PW and Gemmeke, Jort F and Jansen, Aren and Moore, R Channing and Plakal, Manoj and Platt, Devin and Saurous, Rif A and Seybold, Bryan and others},
  booktitle={2017 ieee international conference on acoustics, speech and signal processing (icassp)},
  pages={131--135},
  year={2017},
  publisher={IEEE},
}
@article{abu2016youtube,
  title={Youtube-8m: A large-scale video classification benchmark},
  author={Abu-El-Haija, Sami and Kothari, Nisarg and Lee, Joonseok and Natsev, Paul and Toderici, George and Varadarajan, Balakrishnan and Vijayanarasimhan, Sudheendra},
  journal={arXiv preprint arXiv:1609.08675},
  year={2016}
}
%hubert 
@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={29},
  pages={3451--3460},
  year={2021},
  publisher={IEEE}
}

@inproceedings{Shi2022a,
  title={Learning Audio-Visual Speech Representation by Masked Multimodal Cluster Prediction},
  author={Shi, Bowen and Hsu, Wei-Ning and Lakhotia, Kushal and Mohamed, Abdelrahman},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{Liu2022a,
  author = {Liu, H. and Zhu, Z. and Iwamoto, N. and Peng, Y. and Li, Z. and Zhou, Y. and ... and Zheng, B.},
  title = {Beat: A large-scale semantic and emotional multi-modal dataset for conversational gestures synthesis},
  booktitle = {European Conference on Computer Vision},
  pages = {612--630},
  year = {2022},
  publisher = {Springer Nature Switzerland},
  address = {Cham}
}

@inproceedings{Liu2022b,
  author = {Liu, D. and Zhang, L. and Wu, Y.},
  title = {LD-ConGR: A large RGB-D video dataset for long-distance continuous gesture recognition},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages = {3304--3312},
  year = {2022}
}
@article{liu9beat,
  title={BEAT: A Large-Scale Semantic and Emotional Multi-Modal Dataset for Conversational Gestures Synthesis: Supplementary Materials},
  author={Liu, Haiyang and Zhu, Zihao and Iwamoto, Naoya and Peng, Yichen and Li, Zhengqing and Zhou, You and Bozkurt, Elif and Zheng, Bo},
  journal={Gesture},
  volume={9},
  number={10s},
  pages={11s},
  year={2022}
}

@inproceedings{Abavisani2019,
  author = {Abavisani, M. and Joze, H. R. V. and Patel, V. M.},
  title = {Improving the performance of unimodal dynamic hand-gesture recognition with multimodal training},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages = {1165--1174},
  year = {2019}
}

@inproceedings{Chen2021,
  author = {Chen, Y. and Li, Q. and Kong, D. and Kei, Y. L. and Zhu, S. C. and Gao, T. and ... and Huang, S.},
  title = {Yourefit: Embodied reference understanding with language and gesture},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages = {1385--1395},
  year = {2021}
}

% Gestures in NLP conferences
@inproceedings{abzaliev2022towards,
  title={Towards understanding the relation between gestures and language},
  author={Abzaliev, Artem and Owens, Andrew and Mihalcea, Rada},
  booktitle={Proceedings of the 29th International Conference on Computational Linguistics},
  pages={5507--5520},
  year={2022}
}

@article{lascarides2009formal,
  title={A formal semantic analysis of gesture},
  author={Lascarides, Alex and Stone, Matthew},
  journal={Journal of Semantics},
  volume={26},
  number={4},
  pages={393--449},
  year={2009},
  publisher={Oxford University Press}
}

@inproceedings{lai2024encoding,
  title={Encoding Gesture in Multimodal Dialogue: Creating a Corpus of Multimodal AMR},
  author={Lai, Kenneth and Brutti, Richard and Donatelli, Lucia and Pustejovsky, James},
  booktitle={Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)},
  pages={5806--5818},
  year={2024}
}
@inproceedings{xu-etal-2024-llm,
    title = "{LLM} Knows Body Language, Too: Translating Speech Voices into Human Gestures",
    author = "Xu, Chenghao  and
      Lyu, Guangtao  and
      Yan, Jiexi  and
      Yang, Muli  and
      Deng, Cheng",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.273/",
    doi = "10.18653/v1/2024.acl-long.273",
    pages = "5004--5013"}

@inproceedings{Nyatsanga2023,
  author = {Nyatsanga, S. and Kucherenko, T. and Ahuja, C. and Henter, G. E. and Neff, M.},
  title = {A Comprehensive Review of Data‐Driven Co‐Speech Gesture Generation},
  booktitle = {Computer Graphics Forum},
  volume = {42},
  number = {2},
  pages = {569--596},
  year = {2023}
}

@inproceedings{Chen2023,
  author = {Chen, L. W. and Rudnicky, A.},
  title = {Exploring Wav2vec 2.0 Fine Tuning for Improved Speech Emotion Recognition},
  booktitle = {ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages = {1--5},
  year = {2023},
  publisher = {IEEE}
}

@article{Wu2016,
  author = {Wu, D. and Pigou, L. and Kindermans, P. J. and Le, N. D. H. and Shao, L. and Dambre, J. and Odobez, J. M.},
  title = {Deep dynamic neural networks for multimodal gesture segmentation and recognition},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {38},
  number = {8},
  pages = {1583--1597},
  year = {2016}
}

@inproceedings{Wang2017,
  author = {Wang, H. and Wang, P. and Song, Z. and Li, W.},
  title = {Large-scale multimodal gesture segmentation and recognition based on convolutional neural networks},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision Workshops},
  pages = {3138--3146},
  year = {2017}
}

@article{Neverova2015,
  author = {Neverova, N. and Wolf, C. and Taylor, G. and Nebout, F.},
  title = {Moddrop: adaptive multi-modal gesture recognition},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {38},
  number = {8},
  pages = {1692--1706},
  year = {2015}
}

@inproceedings{Franich2022,
  author = {Franich, K. and Keupdjio, H.},
  title = {The influence of tone on the alignment of speech and co-speech gesture},
  booktitle = {Proceedings of Speech Prosody},
  pages = {2022--63},
  year = {2022}
}

@inproceedings{Escalera2013,
  author = {Escalera, S. and Gonzàlez, J. and Baró, X. and Reyes, M. and Lopes, O. and Guyon, I. and ... and Escalante, H.},
  title = {Multi-modal gesture recognition challenge 2013: Dataset and results},
  booktitle = {Proceedings of the 15th ACM on International Conference on Multimodal Interaction},
  pages = {445--452},
  year = {2013}
}

@inproceedings{bhattacharya2021speech2affectivegestures,
  title={Speech2affectivegestures: Synthesizing co-speech gestures with generative adversarial affective expression learning},
  author={Bhattacharya, Uttaran and Childs, Elizabeth and Rewkowski, Nicholas and Manocha, Dinesh},
  booktitle={Proceedings of the 29th ACM International Conference on Multimedia},
  pages={2027--2036},
  year={2021}
}

% gesture --> theory
@article{mcneill1985so,
  title={So you think gestures are nonverbal?},
  author={McNeill, David},
  journal={Psychological review},
  volume={92},
  number={3},
  pages={350},
  year={1985},
  publisher={American Psychological Association}
}
@article{arbona2023semantically,
  title={Semantically related gestures facilitate language comprehension during simultaneous interpreting},
  author={Arbona, El{\'e}onore and Seeber, Kilian G and Gullberg, Marianne},
  journal={Bilingualism: Language and cognition},
  volume={26},
  number={2},
  pages={425--439},
  year={2023},
  publisher={Cambridge University Press}
}

@article{sanchez2022gesture,
  title={Gesture Phase Segmentation Dataset: An Extension for Development of Gesture Analysis Models},
  author={S{\'a}nchez-Ancajima, Ra{\'u}l A and Peres, Sarajane Marques and L{\'o}pez-C{\'e}spedes, Javier A and Saly-Rosas-solano, Jos{\'e} L and Hern{\'a}ndez, Ronald M and Saavedra-L{\'o}pez, Miguel A},
  journal={Journal of Internet Services and Information Security},
  volume={12},
  number={4},
  pages={139--155},
  year={2022},
  publisher={Innovative Information Science and Technology Research Group}
}
@article{mcneill1992hand,
  title={Hand and mind},
  author={McNeill, David},
  journal={Advances in Visual Semiotics},
  volume={351},
  year={1992}
}
@incollection{kendon2004gesture, 
    place={Cambridge}, 
    title={Gesture units, gesture phrases and speech}, 
    DOI={10.1017/CBO9780511807572.007}, booktitle={Gesture: Visible Action as Utterance}, 
    publisher={Cambridge University Press}, author={Kendon, Adam}, 
    year={2004},
    pages={108–126},
    chapter=7
}
@inproceedings{nijholt2008mutually,
  title={Mutually coordinated anticipatory multimodal interaction},
  author={Nijholt, Anton and Reidsma, Dennis and van Welbergen, Herwin and op den Akker, Rieks and Ruttkay, Zsofia},
  booktitle={Verbal and Nonverbal Features of Human-Human and Human-Machine Interaction: COST Action 2102 International Conference, Patras, Greece, October 29-31, 2007. Revised Papers},
  pages={70--89},
  year={2008},
  publisher={Springer}
}
% Named entity recognition
% It seems that the following paper is only a preprint!?
@article{yan2019tener, 
  title={TENER: adapting transformer encoder for named entity recognition},
  author={Yan, Hang and Deng, Bocao and Li, Xiaonan and Qiu, Xipeng},
  journal={arXiv preprint arXiv:1911.04474}, 
  year={2019}
}
@incollection{jurafsky2020sequence,
  title={Sequence labeling for parts of speech and named entities},
  author={Jurafsky, Daniel and Martin, James H},
  booktitle={Speech and Language Processing},
  year={2023},
  pages = "168-193",
  publisher="Internet: https://web.stanford.edu/~jurafsky/slp3/,(Accessed: Oct 30, 2023)",
  chapter= 8
}
% literature on sensor-based gesture analysis:
@article{guo2021human,
  title={Human-machine interaction sensing technology based on hand gesture recognition: A review},
  author={Guo, Lin and Lu, Zongxing and Yao, Ligang},
  journal={IEEE Transactions on Human-Machine Systems},
  volume={51},
  number={4},
  pages={300--309},
  year={2021},
  publisher={IEEE}
}
% keypoints based models for gesture recognition
@article{liu20203d,
  title={3D skeletal gesture recognition via hidden states exploration},
  author={Liu, Xin and Shi, Henglin and Hong, Xiaopeng and Chen, Haoyu and Tao, Dacheng and Zhao, Guoying},
  journal={IEEE Transactions on Image Processing},
  volume={29},
  pages={4583--4597},
  year={2020},
  publisher={IEEE}
}
%classis gesture segmentation work
@inproceedings{morency2007latent,
  title={Latent-dynamic discriminative models for continuous gesture recognition},
  author={Morency, Louis-Philippe and Quattoni, Ariadna and Darrell, Trevor},
  booktitle={2007 IEEE conference on computer vision and pattern recognition},
  pages={1--8},
  year={2007},
  publisher={IEEE}
}
@article{kong2014towards,
  title={Towards subject independent continuous sign language recognition: A segment and merge approach},
  author={Kong, WW and Ranganath, Surendra},
  journal={Pattern Recognition},
  volume={47},
  number={3},
  pages={1294--1308},
  year={2014},
  publisher={Elsevier}
}

@article{neogi2022factored,
  title={Factored Latent-Dynamic Conditional Random Fields for single and multi-label sequence modeling},
  author={Neogi, Satyajit and Dauwels, Justin},
  journal={Pattern Recognition},
  volume={122},
  pages={108236},
  year={2022},
  publisher={Elsevier}
}
@article{elmezain2009hidden,
  title={A hidden markov model-based isolated and meaningful hand gesture recognition},
  author={Elmezain, Mahmoud and Al-Hamadi, Ayoub and Appenrodt, J{\"o}rg and Michaelis, Bernd},
  journal={International Journal of Electrical, Computer, and Systems Engineering},
  volume={3},
  number={3},
  pages={156--163},
  year={2009}
}
@article{tang2018structured,
  title={Structured dynamic time warping for continuous hand trajectory gesture recognition},
  author={Tang, Jingren and Cheng, Hong and Zhao, Yang and Guo, Hongliang},
  journal={Pattern Recognition},
  volume={80},
  pages={21--31},
  year={2018},
  publisher={Elsevier}
}
@article{wu2016deep,
  title={Deep dynamic neural networks for multimodal gesture segmentation and recognition},
  author={Wu, Di and Pigou, Lionel and Kindermans, Pieter-Jan and Le, Nam Do-Hoang and Shao, Ling and Dambre, Joni and Odobez, Jean-Marc},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={38},
  number={8},
  pages={1583--1597},
  year={2016},
  publisher={IEEE}
}
% classic CRF work on gestures and SLR
@article{song2012continuous,
  title={Continuous body and hand gesture recognition for natural human-computer interaction},
  author={Song, Yale and Demirdjian, David and Davis, Randall},
  journal={ACM Transactions on Interactive Intelligent Systems (TiiS)},
  volume={2},
  number={1},
  pages={1--28},
  year={2012},
  publisher={ACM New York, NY, USA}
}
% recent work on gesture segmentation
@inproceedings{wang2017large,
  title={Large-scale multimodal gesture segmentation and recognition based on convolutional neural networks},
  author={Wang, Huogen and Wang, Pichao and Song, Zhanjie and Li, Wanqing},
  booktitle={Proceedings of the IEEE international conference on computer vision workshops},
  pages={3138--3146},
  year={2017}
}
@inproceedings{molchanov2016online,
  title={Online detection and classification of dynamic hand gestures with recurrent 3d convolutional neural network},
  author={Molchanov, Pavlo and Yang, Xiaodong and Gupta, Shalini and Kim, Kihwan and Tyree, Stephen and Kautz, Jan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4207--4215},
  year={2016}
}
@article{zhu2018continuous,
  title={Continuous gesture segmentation and recognition using 3DCNN and convolutional LSTM},
  author={Zhu, Guangming and Zhang, Liang and Shen, Peiyi and Song, Juan and Shah, Syed Afaq Ali and Bennamoun, Mohammed},
  journal={IEEE Transactions on Multimedia},
  volume={21},
  number={4},
  pages={1011--1021},
  year={2018},
  publisher={IEEE}
}
@article{kopuklu2019real,
  title={Online dynamic hand gesture recognition including efficiency analysis},
  author={K{\"o}p{\"u}kl{\"u}, Okan and Gunduz, Ahmet and Kose, Neslihan and Rigoll, Gerhard},
  journal={IEEE Transactions on Biometrics, Behavior, and Identity Science},
  volume={2},
  number={2},
  pages={85--97},
  year={2020},
  publisher={IEEE}
}
%ipn dataset
@inproceedings{benitez2021ipn,
  title={IPN hand: A video dataset and benchmark for real-time continuous hand gesture recognition},
  author={Benitez-Garcia, Gibran and Olivares-Mercado, Jesus and Sanchez-Perez, Gabriel and Yanai, Keiji},
  booktitle={2020 25th international conference on pattern recognition (ICPR)},
  pages={4340--4347},
  year={2021},
  publisher={IEEE}
}
% CABB dataset
@article{rasenberg2022primacy,
  title={The primacy of multimodal alignment in converging on shared symbols for novel referents},
  author={Rasenberg, Marlou and {\"O}zy{\"u}rek, Asli and B{\"o}gels, Sara and Dingemanse, Mark},
  journal={Discourse Processes},
  volume={59},
  number={3},
  pages={209--236},
  year={2022},
  publisher={Taylor \& Francis}
}


@article{eijk2022cabb,
  title = {The {{CABB}} Dataset: {{A}} Multimodal Corpus of Communicative Interactions for Behavioural and Neural Analyses},
  shorttitle = {The {{CABB}} Dataset},
  author = {Eijk, Lotte and Rasenberg, Marlou and Arnese, Flavia and Blokpoel, Mark and Dingemanse, Mark and Doeller, Christian F. and Ernestus, Mirjam and Holler, Judith and Milivojevic, Branka and {\"O}zy{\"u}rek, Asli and Pouw, Wim and {van Rooij}, Iris and Schriefers, Herbert and Toni, Ivan and Trujillo, James and B{\"o}gels, Sara},
  year = {2022},
  month = dec,
  journal = {NeuroImage},
  volume = {264},
  pages = {119734},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2022.119734},
  urldate = {2022-12-14},
  langid = {english},
  keywords = {Conceptual alignment,Face-to-face interaction,fMRI,Motion tracking,Multimodal data,read\_now,Referential communication},
  file = {/Users/shoakamine/Zotero/storage/9LZAC2RC/cabb_equipment.pdf;/Users/shoakamine/Zotero/storage/AIYTRZNW/Eijk et al_2022_The CABB dataset.pdf}
}

% ST GCNs
@inproceedings{yan2018spatial,
  title={Spatial temporal graph convolutional networks for skeleton-based action recognition},
  author={Yan, Sijie and Xiong, Yuanjun and Lin, Dahua},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  year={2018}
}
@article{wu2020comprehensive,
  title={A comprehensive survey on graph neural networks},
  author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and others},
  journal={IEEE transactions on neural networks and learning systems},
  volume={32},
  number={1},
  pages={4--24},
  year={2020},
  publisher={IEEE}
}
@article{zhou2020graph,
  title={Graph neural networks: A review of methods and applications},
  author={Zhou, Jie and Cui, Ganqu and Hu, Shengding others},
  journal={AI Open},
  volume={1},
  pages={57--81},
  year={2020},
  publisher={Elsevier}
}
@inproceedings{kipf2017semi,
  title={Semi-Supervised Classification with Graph Convolutional Networks},
  author={Kipf, Thomas N. and Welling, Max},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2017}
}
@inproceedings{song2020stronger,
  title={Stronger, Faster and More Explainable: A Graph Convolutional Baseline for Skeleton-based Action Recognition},
  author={Song, Yi-Fan and Zhang, Zhang and Shan, Caifeng and Wang, Liang},
  booktitle={Proceedings of the 28th ACM International Conference on Multimedia},
  pages={1625--1633},
  year={2020}
}
@inproceedings{jiang2021skeleton,
  title={Skeleton aware multi-modal sign language recognition},
  author={Jiang, Songyao and Sun, Bin and Wang, Lichen and Bai, Yue and Li, Kunpeng and Fu, Yun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3413--3423},
  year={2021}
}

% Transformer
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

% tools, tsne
@article{van2008visualizing,
  title={Visualizing data using t-SNE.},
  author={Van der Maaten, Laurens and Hinton, Geoffrey},
  journal={Journal of machine learning research},
  volume={9},
  number={11},
  year={2008}
}
%viterbi
@article{forney1973viterbi,
  title={The viterbi algorithm},
  author={Forney, G David},
  journal={Proceedings of the IEEE},
  volume={61},
  number={3},
  pages={268--278},
  year={1973},
  publisher={Ieee}
}
% tools: mmpose
@article{sengupta2020mm,
  title={mm-Pose: Real-time human skeletal posture estimation using mmWave radars and CNNs},
  author={Sengupta, Arindam and Jin, Feng and Zhang, Renyuan and Cao, Siyang},
  journal={IEEE Sensors Journal},
  volume={20},
  number={17},
  pages={10032--10044},
  year={2020},
  publisher={IEEE}
}

%tools: CRFs
@inproceedings{lafferty2001conditional,
  title={Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data},
  author={Lafferty, John and McCallum, Andrew and Pereira, Fernando CN},
  booktitle={Proceedings of the Eighteenth International Conference on Machine Learning, 2001},
  pages={282--289},
  year={2001}
}
%Staccato algorithm Lücking
@inproceedings{lucking2011assessing,
  title={Assessing agreement on segmentations by means of staccato, the segmentation agreement calculator according to thomann},
  author={L{\"u}cking, Andy and Ptock, Sebastian and Bergmann, Kirsten},
  booktitle={International gesture workshop},
  pages={129--138},
  year={2011},
  publisher={Springer}
}

% explainable gcn
@inproceedings{ghaleb2021skeleton,
  title={Skeleton-based explainable bodily expressed emotion recognition through graph convolutional networks},
  author={Ghaleb, Esam and Mertens, Andr{\'e} and Asteriadis, Stylianos and Weiss, Gerhard},
  booktitle={2021 16th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2021)},
  pages={1--8},
  year={2021},
  publisher={IEEE}
}

% speech and gestures: theoretical papers:
@misc{wagner2014gesture,
  title={Gesture and speech in interaction: An overview},
  author={Wagner, Petra and Malisz, Zofia and Kopp, Stefan},
  journal={Speech Communication},
  volume={57},
  pages={209--232},
  year={2014},
  publisher={Elsevier}
}
@article{holler2019multimodal,
  title={Multimodal language processing in human communication},
  author={Holler, Judith and Levinson, Stephen C},
  journal={Trends in Cognitive Sciences},
  volume={23},
  number={8},
  pages={639--652},
  year={2019},
  publisher={Elsevier}
}
@incollection{holler2020communicating,
  title={Communicating common ground: How mutually shared knowledge influences speech and gesture in a narrative task},
  author={Holler, Judith and Wilkin, Katie},
  booktitle={Speech Accompanying-Gesture},
  pages={267--289},
  year={2020},
  publisher={Psychology Press}
}
@inproceedings{han2017natural,
  title={Natural language informs the interpretation of iconic gestures: A computational approach},
  author={Han, Ting and Hough, Julian and Schlangen, David},
  booktitle={Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
  pages={134--139},
  year={2017}
}

@article{ozyurek2014hearing,
  title={Hearing and seeing meaning in speech and gesture: Insights from brain and behaviour},
  author={{\"O}zy{\"u}rek, Asl{\i}},
  journal={Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume={369},
  number={1651},
  pages={20130296},
  year={2014},
  publisher={The Royal Society}
}

% papers on referring expressions and mapping them to visual content
@inproceedings{kazemzadeh2014referitgame,
  title={Referitgame: Referring to objects in photographs of natural scenes},
  author={Kazemzadeh, Sahar and Ordonez, Vicente and Matten, Mark and Berg, Tamara},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={787--798},
  year={2014}
}
@inproceedings{plummer2015flickr30k,
  title={Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models},
  author={Plummer, Bryan A and Wang, Liwei and Cervantes, Chris M and Caicedo, Juan C and Hockenmaier, Julia and Lazebnik, Svetlana},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2641--2649},
  year={2015}
}
@article{krishna2017visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International journal of computer vision},
  volume={123},
  pages={32--73},
  year={2017},
  publisher={Springer}
}



@article{holler2011co,
  title={Co-speech gesture mimicry in the process of collaborative referring during face-to-face dialogue},
  author={Holler, Judith and Wilkin, Katie},
  journal={Journal of Nonverbal Behavior},
  volume={35},
  pages={133--153},
  year={2011},
  publisher={Springer}
}
@inproceedings{ter2020predictive,
  title={The predictive potential of hand gestures during conversation: An investigation of the timing of gestures in relation to speech},
  author={Ter Bekke, Marlijn and Drijvers, Linda and Holler, Judith},
  booktitle={Gesture and Speech in Interaction Conference},
  year={2020},
  publisher={KTH Royal Institute of Technology}
}

@inproceedings{donnellan2022timing,
  title={Timing relationships between representational gestures and speech: A corpus based investigation},
  author={Donnellan, Ed and {\"O}zder, Levent Emir and Man, Hillarie and Grzyb, Beata and Gu, Yan and Vigliocco, Gabriella},
  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume={44},
  pages={2052--2058},
  year={2022},
  publisher={University of California}
}

@article{ter2024hand,
  title={Hand Gestures Have Predictive Potential During Conversation: An Investigation of the Timing of Gestures in Relation to Speech},
  author={Ter Bekke, Marlijn and Drijvers, Linda and Holler, Judith},
  journal={Cognitive Science},
  volume={48},
  number={1},
  pages={e13407},
  year={2024},
  publisher={Wiley Online Library}
}

@article{pouw2020energy,
  title={Energy flows in gesture-speech physics: The respiratory-vocal system and its coupling with hand gestures},
  author={Pouw, Wim and Harrison, Steven J and Esteve-Gibert, N{\'u}ria and Dixon, James A},
  journal={The Journal of the Acoustical Society of America},
  volume={148},
  number={3},
  pages={1231--1247},
  year={2020},
  publisher={AIP Publishing}
}

@inproceedings{mcfee2015librosa,
  title={librosa: Audio and music signal analysis in python},
  author={McFee, Brian and Raffel, Colin and Liang, Dawen and Ellis, Daniel PW and McVicar, Matt and Battenberg, Eric and Nieto, Oriol},
  booktitle={Proceedings of the 14th python in science conference},
  volume={8},
  year={2015}
}
@inproceedings{mauch2014pyin,
  title={pYIN: A fundamental frequency estimator using probabilistic threshold distributions},
  author={Mauch, Matthias and Dixon, Simon},
  booktitle={2014 ieee international conference on acoustics, speech and signal processing (icassp)},
  pages={659--663},
  year={2014},
  publisher={IEEE}
}

@inproceedings{kucherenko2019analyzing,
  title={Analyzing input and output representations for speech-driven gesture generation},
  author={Kucherenko, Taras and Hasegawa, Dai and Henter, Gustav Eje and Kaneko, Naoshi and Kjellstr{\"o}m, Hedvig},
  booktitle={Proceedings of the 19th ACM International Conference on Intelligent Virtual Agents},
  pages={97--104},
  year={2019}
}

@inproceedings{hasegawa2018evaluation,
  title={Evaluation of speech-to-gesture generation using bi-directional LSTM network},
  author={Hasegawa, Dai and Kaneko, Naoshi and Shirakawa, Shinichi and Sakuta, Hiroshi and Sumi, Kazuhiko},
  booktitle={Proceedings of the 18th International Conference on Intelligent Virtual Agents},
  pages={79--86},
  year={2018}
}
@inproceedings{zhou2016learning,
  title={Learning deep features for discriminative localization},
  author={Zhou, Bolei and Khosla, Aditya and others},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2921--2929},
  year={2016}
}
@article{ghaleb2023joint,
  title={Joint modelling of audio-visual cues using attention mechanisms for emotion recognition},
  author={Ghaleb, Esam and Niehues, Jan and Asteriadis, Stylianos},
  journal={Multimedia Tools and Applications},
  volume={82},
  number={8},
  pages={11239--11264},
  year={2023},
  publisher={Springer}
}
@inproceedings{radford2023robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}
@inproceedings{tan2019lxmert,
  title={LXMERT: Learning Cross-Modality Encoder Representations from Transformers},
  author={Tan, Hao and Bansal, Mohit},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  year={2019},
  organization={Association for Computational Linguistics}
}

@article{hadar2001gesture,
  title={Gesture during speech in first and second language: Implications for lexical retrieval},
  author={Hadar, Uri and Dar, Rivka and Teitelman, Amit},
  journal={Gesture},
  volume={1},
  number={2},
  pages={151--165},
  year={2001},
  publisher={John Benjamins}
} 
@article{krauss1999role,
  title={The role of speech-related arm/hand gestures in word retrieval},
  author={Krauss, Robert M and Hadar, Uri},
  journal={Gesture, speech, and sign},
  volume={93},
  year={1999}
}

@article{khan2022transformers,
  title={Transformers in vision: A survey},
  author={Khan, Salman and Naseer, Muzammal and Hayat, Munawar and Zamir, Syed Waqas and Khan, Fahad Shahbaz and Shah, Mubarak},
  journal={ACM computing surveys (CSUR)},
  volume={54},
  number={10s},
  pages={1--41},
  year={2022},
  publisher={ACM New York, NY}
}
@article{li2019visualbert,
  title={Visualbert: A simple and performant baseline for vision and language},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1908.03557},
  year={2019}
}
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{bardes2022vicreg,
  title={VICReg: Variance-Invariance-Covariance Regularization For Self-Supervised Learning},
  author={Bardes, Adrien and Ponce, Jean and Lecun, Yann},
  booktitle={ICLR 2022-International Conference on Learning Representations},
  year={2022}
}

@inproceedings{kucherenko2022multimodal,
  title={Multimodal analysis of the predictability of hand-gesture properties},
  author={Kucherenko, Taras and Nagy, Rajmund and Neff, Michael and Kjellstr{\"o}m, Hedvig and Henter, Gustav Eje},
  booktitle={21st International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2022, Auckland, New Zealand, May 9-13, 2022},
  pages={770--779},
  year={2022},
  organization={ACM Press}
}

@inproceedings{rajan2022cross,
  title={Is cross-attention preferable to self-attention for multi-modal emotion recognition?},
  author={Rajan, Vandana and Brutti, Alessio and Cavallaro, Andrea},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={4693--4697},
  year={2022},
  organization={IEEE}
}
@article{baltruvsaitis2018multimodal,
  title={Multimodal machine learning: A survey and taxonomy},
  author={Baltru{\v{s}}aitis, Tadas and Ahuja, Chaitanya and Morency, Louis-Philippe},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={2},
  pages={423--443},
  year={2018},
  publisher={IEEE}
}
@article{drijvers2017visual,
  title={Visual context enhanced: The joint contribution of iconic gestures and visible speech to degraded speech comprehension},
  author={Drijvers, Linda and {\"O}zy{\"u}rek, Asli},
  journal={Journal of Speech, Language, and Hearing Research},
  volume={60},
  number={1},
  pages={212--222},
  year={2017},
  publisher={ASHA}
}
@article{trujillo2021speakers,
  title={Speakers exhibit a multimodal Lombard effect in noise},
  author={Trujillo, James and {\"O}zy{\"u}rek, Asli and Holler, Judith and Drijvers, Linda},
  journal={Scientific reports},
  volume={11},
  number={1},
  pages={16721},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@misc{devries2019bertje,
title = {{BERTje}: {A} {Dutch} {BERT} {Model}},
shorttitle = {{BERTje}},
author = {de Vries, Wietse  and  van Cranenburgh, Andreas  and  Bisazza, Arianna  and  Caselli, Tommaso  and  Noord, Gertjan van  and  Nissim, Malvina},
year = {2019},
month = dec,
howpublished = {arXiv:1912.09582},
url = {http://arxiv.org/abs/1912.09582},
}

@inproceedings{zhu2023motionbert,
  title={Motionbert: A unified perspective on learning human motion representations},
  author={Zhu, Wentao and Ma, Xiaoxuan and Liu, Zhaoyang and Liu, Libin and Wu, Wayne and Wang, Yizhou},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={15085--15099},
  year={2023}
}

@article{jaiswal2020survey,
  title={A survey on contrastive self-supervised learning},
  author={Jaiswal, Ashish and Babu, Ashwin Ramesh and Zadeh, Mohammad Zaki and Banerjee, Debapriya and Makedon, Fillia},
  journal={Technologies},
  volume={9},
  number={1},
  pages={2},
  year={2020},
  publisher={MDPI}
}

@inproceedings{he2020momentum,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9729--9738},
  year={2020}
}

@inproceedings{tian2020contrastive,
  title={Contrastive multiview coding},
  author={Tian, Yonglong and Krishnan, Dilip and Isola, Phillip},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XI 16},
  pages={776--794},
  year={2020},
  organization={Springer}
}

@inproceedings{girdhar2023imagebind,
  title={Imagebind: One embedding space to bind them all},
  author={Girdhar, Rohit and El-Nouby, Alaaeldin and Liu, Zhuang and Singh, Mannat and Alwala, Kalyan Vasudev and Joulin, Armand and Misra, Ishan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15180--15190},
  year={2023}
}

@inproceedings{bergmann2012gestural,
  title={Gestural alignment in natural dialogue},
  author={Bergmann, Kirsten and Kopp, Stefan},
  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume={34},
  number={34},
  year={2012}
}

@article{belinkov2022probing,
  title={Probing classifiers: Promises, shortcomings, and advances},
  author={Belinkov, Yonatan},
  journal={Computational Linguistics},
  volume={48},
  number={1},
  pages={207--219},
  year={2022},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@inproceedings{basaj2021visualprobing,
  title     = {Explaining Self-Supervised Image Representations with Visual Probing},
  author    = {Basaj, Dominika and Oleszkiewicz, Witold and Sieradzki, Igor and Górszczak, Michał and Rychalska, Barbara and Trzcinski, Tomasz and Zieliński, Bartosz},
  booktitle = {Proceedings of the Thirtieth International Joint Conference on
               Artificial Intelligence, {IJCAI-21}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Zhi-Hua Zhou},
  pages     = {592--598},
  year      = {2021},
  month     = {8},
  note      = {Main Track},
  doi       = {10.24963/ijcai.2021/82},
  url       = {https://doi.org/10.24963/ijcai.2021/82},
}

@inproceedings{ryb-etal-2022-analog,
    title = "{A}na{L}og: Testing Analytical and Deductive Logic Learnability in Language Models",
    author = "Ryb, Samuel  and
      Giulianelli, Mario  and
      Sinclair, Arabella  and
      Fern{\'a}ndez, Raquel",
    editor = "Nastase, Vivi  and
      Pavlick, Ellie  and
      Pilehvar, Mohammad Taher  and
      Camacho-Collados, Jose  and
      Raganato, Alessandro",
    booktitle = "Proceedings of the 11th Joint Conference on Lexical and Computational Semantics",
    month = jul,
    year = "2022",
    address = "Seattle, Washington",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.starsem-1.5",
    doi = "10.18653/v1/2022.starsem-1.5",
    pages = "55--68",
    abstract = "We investigate the extent to which pre-trained language models acquire analytical and deductive logical reasoning capabilities as a side effect of learning word prediction. We present AnaLog, a natural language inference task designed to probe models for these capabilities, controlling for different invalid heuristics the models may adopt instead of learning the desired generalisations. We test four languagemodels on AnaLog, finding that they have all learned, to a different extent, to encode information that is predictive of entailment beyond shallow heuristics such as lexical overlap and grammaticality. We closely analyse the best performing language model and show that while it performs more consistently than other language models across logical connectives and reasoning domains, it still is sensitive to lexical and syntactic variations in the realisation of logical statements.",
}

@inproceedings{belinkov-etal-2017-neural,
    title = "What do Neural Machine Translation Models Learn about Morphology?",
    author = "Belinkov, Yonatan  and
      Durrani, Nadir  and
      Dalvi, Fahim  and
      Sajjad, Hassan  and
      Glass, James",
    editor = "Barzilay, Regina  and
      Kan, Min-Yen",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1080",
    doi = "10.18653/v1/P17-1080",
    pages = "861--872",
    abstract = "Neural machine translation (MT) models obtain state-of-the-art performance while maintaining a simple, end-to-end architecture. However, little is known about what these models learn about source and target languages during the training process. In this work, we analyze the representations learned by neural MT models at various levels of granularity and empirically evaluate the quality of the representations for learning morphology through extrinsic part-of-speech and morphological tagging tasks. We conduct a thorough investigation along several parameters: word-based vs. character-based representations, depth of the encoding layer, the identity of the target language, and encoder vs. decoder representations. Our data-driven, quantitative evaluation sheds light on important aspects in the neural MT system and its ability to capture word structure.",
}

@inproceedings{de2022probing,
  title={Probing phoneme, language and speaker information in unsupervised speech representations},
  author={de Seyssel, Maureen and Lavechin, Marvin and Adi, Yossi and Dupoux, Emmanuel and Wisniewski, Guillaume},
  booktitle={Interspeech 2022-23rd INTERSPEECH Conference},
  year={2022}
}

@inproceedings{conneau-etal-2018-cram,
    title = "What you can cram into a single {\$}{\&}!{\#}* vector: Probing sentence embeddings for linguistic properties",
    author = {Conneau, Alexis  and
      Kruszewski, German  and
      Lample, Guillaume  and
      Barrault, Lo{\"\i}c  and
      Baroni, Marco},
    editor = "Gurevych, Iryna  and
      Miyao, Yusuke",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1198",
    doi = "10.18653/v1/P18-1198",
    pages = "2126--2136",
    abstract = "Although much effort has recently been devoted to training high-quality sentence embeddings, we still have a poor understanding of what they are capturing. {``}Downstream{''} tasks, often based on sentence classification, are commonly used to evaluate the quality of sentence representations. The complexity of the tasks makes it however difficult to infer what kind of information is present in the representations. We introduce here 10 probing tasks designed to capture simple linguistic features of sentences, and we use them to study embeddings generated by three different encoders trained in eight distinct ways, uncovering intriguing properties of both encoders and training methods.",
}

@inproceedings{guo2022contrastive,
  title={Contrastive learning from extremely augmented skeleton sequences for self-supervised action recognition},
  author={Guo, Tianyu and Liu, Hong and Chen, Zhan and Liu, Mengyuan and Wang, Tao and Ding, Runwei},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={36},
  number={1},
  pages={762--770},
  year={2022}
}

@inproceedings{li20213d,
  title={3d human action representation learning via cross-view consistency pursuit},
  author={Li, Linguo and Wang, Minsi and Ni, Bingbing and Wang, Hang and Yang, Jiancheng and Zhang, Wenjun},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4741--4750},
  year={2021}
}

@inproceedings{hong2022versatile,
  title={Versatile multi-modal pre-training for human-centric perception},
  author={Hong, Fangzhou and Pan, Liang and Cai, Zhongang and Liu, Ziwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16156--16166},
  year={2022}
}

@inproceedings{zhang-etal-2021-need,
    title = "When Do You Need Billions of Words of Pretraining Data?",
    author = "Zhang, Yian  and
      Warstadt, Alex  and
      Li, Xiaocheng  and
      Bowman, Samuel R.",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.90",
    doi = "10.18653/v1/2021.acl-long.90",
    pages = "1112--1125",
    abstract = "NLP is currently dominated by language models like RoBERTa which are pretrained on billions of words. But what exact knowledge or skills do Transformer LMs learn from large-scale pretraining that they cannot learn from less data? To explore this question, we adopt five styles of evaluation: classifier probing, information-theoretic probing, unsupervised relative acceptability judgments, unsupervised language model knowledge probing, and fine-tuning on NLU tasks. We then draw learning curves that track the growth of these different measures of model ability with respect to pretraining data volume using the MiniBERTas, a group of RoBERTa models pretrained on 1M, 10M, 100M and 1B words. We find that these LMs require only about 10M to 100M words to learn to reliably encode most syntactic and semantic features we test. They need a much larger quantity of data in order to acquire enough commonsense knowledge and other skills required to master typical downstream NLU tasks. The results suggest that, while the ability to encode linguistic features is almost certainly necessary for language understanding, it is likely that other, unidentified, forms of knowledge are the major drivers of recent improvements in language understanding among large pretrained models.",
}

@inproceedings{tenney-etal-2019-bert,
    title = "{BERT} Rediscovers the Classical {NLP} Pipeline",
    author = "Tenney, Ian  and
      Das, Dipanjan  and
      Pavlick, Ellie",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'\i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1452",
    doi = "10.18653/v1/P19-1452",
    pages = "4593--4601",
}



@article{shah2021all,
  title={What all do audio transformer models hear? probing acoustic representations for language delivery and its structure},
  author={Shah, Jui and Singla, Yaman Kumar and Chen, Changyou and Shah, Rajiv Ratn},
  journal={arXiv preprint arXiv:2101.00387},
  year={2021}
}

@article{ghaleb2024le,
  title={Leveraging Speech for Gesture Detection in Multimodal Communication},
  author={Ghaleb, Esam and Burenko, Ilya and Rasenberg, Marlou and Pouw, Wim  and Toni, Ivan and  Uhrig, Peter and Wilson, Anna and Holler, Judith and {\"O}zy{\"u}rek, Asl{\i} and Fern{\'a}ndez, Raquel},
  journal={arXiv:2404.14952v1},
  year={2024}
}

@inproceedings{kanakanti2023multifacet,
  title={MultiFacet: A Multi-Tasking Framework for Speech-to-Sign Language Generation},
  author={Kanakanti, Mounika and Singh, Shantanu and Shrivastava, Manish},
  booktitle={Companion Publication of the 25th International Conference on Multimodal Interaction},
  pages={205--213},
  year={2023}
}

@article{yoon2020speech,
  title={Speech gesture generation from the trimodal context of text, audio, and speaker identity},
  author={Yoon, Youngwoo and Cha, Bok and Lee, Joo-Haeng and Jang, Minsu and Lee, Jaeyeon and Kim, Jaehong and Lee, Geehyuk},
  journal={ACM Transactions on Graphics (TOG)},
  volume={39},
  number={6},
  pages={1--16},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{ionescu2013human3,
  title={Human3.6m: Large scale datasets and predictive methods for 3d human sensing in natural environments},
  author={Ionescu, Catalin and Papava, Dragos and Olaru, Vlad and Sminchisescu, Cristian},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={36},
  number={7},
  pages={1325--1339},
  year={2013},
  publisher={IEEE}
}

@inproceedings{xu2024chain,
  title={Chain of generation: Multi-modal gesture synthesis via cascaded conditional control},
  author={Xu, Zunnan and Zhang, Yachao and Yang, Sicheng and Li, Ronghui and Li, Xiu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={6},
  pages={6387--6395},
  year={2024}
}

@inproceedings{lee2021crossmodal,
  title={Crossmodal clustered contrastive learning: Grounding of spoken language to gesture},
  author={Lee, Dong Won and Ahuja, Chaitanya and Morency, Louis-Philippe},
  booktitle={Companion Publication of the 2021 International Conference on Multimodal Interaction},
  pages={202--210},
  year={2021}
}



# intrinsic eval via similarity
@article{navigli2019overview,
  title={An overview of word and sense similarity},
  author={Navigli, Roberto and Martelli, Federico},
  journal={Natural Language Engineering},
  volume={25},
  number={6},
  pages={693--714},
  year={2019},
  publisher={Cambridge University Press}
}

@article{bruni2014multimodal,
  title={Multimodal distributional semantics},
  author={Bruni, Elia and Tran, Nam-Khanh and Baroni, Marco},
  journal={Journal of artificial intelligence research},
  volume={49},
  pages={1--47},
  year={2014}
}
% speech
@article{pasad2024self,
  title={What do self-supervised speech models know about words?},
  author={Pasad, Ankita and Chien, Chung-Ming and Settle, Shane and Livescu, Karen},
  journal={Transactions of the Association for Computational Linguistics},
  volume={12},
  pages={372--391},
  year={2024},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}
@Article{pezzelle-etal-2021-tacl,
  author = 	 "Sandro Pezzelle and Ece Takmaz and Raquel Fern\'andez",
  title = 	 "Word Representation Learning in Multimodal Pre-Trained Transformers: An Intrinsic Evaluation",
  journal = 	 "Transactions of the Association for Computational Linguistics (TACL)",
  year = "2021",
  url = "https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl_a_00443/1979754/tacl_a_00443.pdf"
}

@article{rautaray2015vision,
  title={Vision based hand gesture recognition for human computer interaction: a survey},
  author={Rautaray, Siddharth S and Agrawal, Anupam},
  journal={Artificial intelligence review},
  volume={43},
  pages={1--54},
  year={2015},
  publisher={Springer}
}
@inproceedings{bergmann2010systematicity,
  title={Systematicity and idiosyncrasy in iconic gesture use: Empirical analysis and computational modeling},
  author={Bergmann, Kirsten and Kopp, Stefan},
  booktitle={Gesture in Embodied Communication and Human-Computer Interaction: 8th International Gesture Workshop, GW 2009, Bielefeld, Germany, February 25-27, 2009, Revised Selected Papers 8},
  pages={182--194},
  year={2010},
  organization={Springer}
}
@inproceedings{bergmann2009increasing,
  title={Increasing the expressiveness of virtual agents: autonomous generation of speech and gesture for spatial description tasks.},
  author={Bergmann, Kirsten and Kopp, Stefan},
  booktitle={AAMAS (1)},
  pages={361--368},
  year={2009}
}

@article{pouw2020quantification,
  title={The quantification of gesture--speech synchrony: A tutorial and validation of multimodal data acquisition using device-based and video-based motion tracking},
  author={Pouw, Wim and Trujillo, James P and Dixon, James A},
  journal={Behavior research methods},
  volume={52},
  pages={723--740},
  year={2020},
  publisher={Springer}
}
@article{trettenbrein2021controlling,
  title={Controlling video stimuli in sign language and gesture research: The OpenPoseR package for analyzing OpenPose motion-tracking data in R},
  author={Trettenbrein, Patrick C and Zaccarella, Emiliano},
  journal={Frontiers in Psychology},
  volume={12},
  pages={628728},
  year={2021},
  publisher={Frontiers}
}
@article{trujillo2019toward,
  title={Toward the markerless and automatic analysis of kinematic features: A toolkit for gesture and movement research},
  author={Trujillo, James P and Vaitonyte, Julija and Simanova, Irina and {\"O}zy{\"u}rek, Asli},
  journal={Behavior research methods},
  volume={51},
  pages={769--777},
  year={2019},
  publisher={Springer}
}
@inproceedings{hawkins-etal-2020-continual,
    title = "Continual Adaptation for Efficient Machine Communication",
    author = "Hawkins, Robert  and
      Kwon, Minae  and
      Sadigh, Dorsa  and
      Goodman, Noah",
    editor = "Fern{\'a}ndez, Raquel  and
      Linzen, Tal",
    booktitle = "Proceedings of the 24th Conference on Computational Natural Language Learning",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.conll-1.33/",
    doi = "10.18653/v1/2020.conll-1.33",
    pages = "408--419"
}
@article{sinclair2021linguistic,
  title={Linguistic and Gestural Coordination: Do Learners Converge in Collaborative Dialogue?.},
  author={Sinclair, Arabella J and Schneider, Bertrand},
  journal={International Educational Data Mining Society},
  year={2021},
  publisher={ERIC}
}

@book{clark1991grounding,
  title={Grounding in communication.},
  author={Clark, Herbert H and Brennan, Susan E},
  year={1991},
  publisher={American Psychological Association}
}
@article{brennan1996conceptual,
  title={Conceptual pacts and lexical choice in conversation.},
  author={Brennan, Susan E and Clark, Herbert H},
  journal={Journal of experimental psychology: Learning, memory, and cognition},
  volume={22},
  number={6},
  pages={1482},
  year={1996},
  publisher={American Psychological Association}
}

@inproceedings{Akamine2024sp,
  title={Speakers align both their gestures and words not only to establish but also to maintain reference to create shared labels for novel objects in interaction},
  author={Akamine, Sho and Ghaleb, Esam and Rasenberg, Marlou and Fern{\'a}ndez, Raquel and Meyer, Antje and  {\"O}zy{\"u}rek, Asl{\i} },
  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume={46},
  year={2024}
}
@inproceedings{ghaleb2024an,
  title={Analysing Cross-Speaker Convergence in Face-to-Face Dialogue through the Lens of Automatically Detected Shared Linguistic Constructions},
  author={Ghaleb, Esam and Rasenberg, Marlou and Pouw, Wim and Toni, Ivan and Holler, Judith and {\"O}zy{\"u}rek, Asl{\i} and Fern{\'a}ndez, Raquel},
  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume={46},
  year={2024}
}

@misc{bressem2013linguistic,
  title={A linguistic perspective on the notation of form features in gestures},
  author={Bressem, Jana and others},
  journal={Body--language--communication: An international handbook on multimodality in human interaction},
  volume={1},
  number={1},
  pages={1079--1098},
  year={2013},
  publisher={De Gruyter Mouton Berlin \& Boston}
}

@misc{Falcon_PyTorch_Lightning_2019,
author = {Falcon, William and {The PyTorch Lightning team}},
doi = {10.5281/zenodo.3828935},
license = {Apache-2.0},
month = mar,
title = {{PyTorch Lightning}},
url = {https://github.com/Lightning-AI/lightning},
version = {1.4},
year = {2019}
}

@inproceedings{Ansel_PyTorch_2_Faster_2024,
author = {Ansel, Jason and Yang, Edward and He, Horace and Gimelshein, Natalia and Jain, Animesh and Voznesensky, Michael and Bao, Bin and Bell, Peter and Berard, David and Burovski, Evgeni and Chauhan, Geeta and Chourdia, Anjali and Constable, Will and Desmaison, Alban and DeVito, Zachary and Ellison, Elias and Feng, Will and Gong, Jiong and Gschwind, Michael and Hirsh, Brian and Huang, Sherlock and Kalambarkar, Kshiteej and Kirsch, Laurent and Lazos, Michael and Lezcano, Mario and Liang, Yanbo and Liang, Jason and Lu, Yinghai and Luk, CK and Maher, Bert and Pan, Yunjie and Puhrsch, Christian and Reso, Matthias and Saroufim, Mark and Siraichi, Marcos Yukio and Suk, Helen and Suo, Michael and Tillet, Phil and Wang, Eikan and Wang, Xiaodong and Wen, William and Zhang, Shunting and Zhao, Xu and Zhou, Keren and Zou, Richard and Mathews, Ajit and Chanan, Gregory and Wu, Peng and Chintala, Soumith},
booktitle = {29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2 (ASPLOS '24)},
doi = {10.1145/3620665.3640366},
month = apr,
publisher = {ACM},
title = {{PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation}},
url = {https://pytorch.org/assets/pytorch2-2.pdf},
year = {2024}
}

@inproceedings{pouw2021semantically,
  title={Semantically related gestures move alike: Towards a distributional semantics of gesture kinematics},
  author={Pouw, Wim and de Wit, Jan and B{\"o}gels, Sara and Rasenberg, Marlou and Milivojevic, Branka and Ozyurek, Asli},
  booktitle={International Conference on Human-Computer Interaction},
  pages={269--287},
  year={2021},
  organization={Springer}
}


@article{bain2022whisperx,
  title={WhisperX: Time-Accurate Speech Transcription of Long-Form Audio},
  author={Bain, Max and Huh, Jaesung and Han, Tengda and Zisserman, Andrew},
  journal={INTERSPEECH 2023},
  year={2023}
}

@inproceedings{ahuja-etal-2020-gestures,
    title = "No Gestures Left Behind: Learning Relationships between Spoken Language and Freeform Gestures",
    author = "Ahuja, Chaitanya  and
      Lee, Dong Won  and
      Ishii, Ryo  and
      Morency, Louis-Philippe",
    editor = "Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.170/",
    doi = "10.18653/v1/2020.findings-emnlp.170",
    pages = "1884--1895"
}