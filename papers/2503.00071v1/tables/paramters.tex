\begin{table*}[ht!]
\centering
\caption{Parameters for the three architectures. The skeleton encoders (the adapted DSTFormer) and the projection heads are the trainable parameters. The speech (i.e., wav2vec2) and text-based semantic (i.e., BERTje) encoders are frozen during pre-training).}
\label{tab:parameters}
\begin{tabular}{l|c|cc|cc}
\toprule
 & \textbf{Unimodal} & \multicolumn{2}{c|}{\textbf{Multimodal-X}} & \multicolumn{2}{c}{\textbf{Multimodal}} \\
\cmidrule{2-6}
 &  & \textbf{Semantic} & \textbf{Speech} & \textbf{Semantic} & \textbf{Speech} \\
\midrule
\shortstack[l]{\textbf{Skeleton Encoders params} \\ \textbf{+ Projection heads (M)}} 
                   & 10.3 & 22.0 & 24.2 & 10.5 & 10.5 \\
\textit{Non-trainable params (M)}   & -- & 109 & 315 & 109 & 315 \\
\textit{Total params (M)}           & 10.3 & 131 & 339 & 119 & 325 \\
\textbf{Model size (GB)}            & 0.041 & 0.525 & 1.359 & 0.478 & 1.304 \\
\bottomrule
\end{tabular}
\end{table*}
