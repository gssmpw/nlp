@inproceedings{YaoXLMTMKL24,
  author       = {Dingling Yao and
                  Danru Xu and
                  S{\'{e}}bastien Lachapelle and
                  Sara Magliacane and
                  Perouz Taslakian and
                  Georg Martius and
                  Julius von K{\"{u}}gelgen and
                  Francesco Locatello},
  title        = {Multi-View Causal Representation Learning with Partial Observability},
  booktitle    = {International Conference on Learning Representations,
                  {ICLR}},
  year         = {2024},
}


@article{orthonormal-concepts,
	abstract = {What does a neural network encode about a concept as we traverse through the layers? Interpretability in machine learning is undoubtedly important, but the calculations of neural networks are very challenging to understand. Attempts to see inside their hidden layers can be misleading, unusable or rely on the latent space to possess properties that it may not have. Here, rather than attempting to analyse a neural network post hoc, we introduce a mechanism, called concept whitening (CW), to alter a given layer of the network to allow us to better understand the computation leading up to that layer. When a concept whitening module is added to a convolutional neural network, the latent space is whitened (that is, decorrelated and normalized) and the axes of the latent space are aligned with known concepts of interest. By experiment, we show that CW can provide us with a much clearer understanding of how the network gradually learns concepts over layers. CW is an alternative to a batch normalization layer in that it normalizes, and also decorrelates (whitens), the latent space. CW can be used in any layer of the network without hurting predictive performance.},
	author = {Chen, Zhi and Bei, Yijie and Rudin, Cynthia},
	date = {2020/12/01},
	date-added = {2025-01-30 14:55:28 +0100},
	date-modified = {2025-01-30 14:55:28 +0100},
	doi = {10.1038/s42256-020-00265-z},
	id = {Chen2020},
	isbn = {2522-5839},
	journal = {Nature Machine Intelligence},
	number = {12},
	pages = {772--782},
	title = {Concept whitening for interpretable image recognition},
	url = {https://doi.org/10.1038/s42256-020-00265-z},
	volume = {2},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1038/s42256-020-00265-z}}


@inproceedings{10.5555/3327757.3327875,
author = {Alvarez-Melis, David and Jaakkola, Tommi S.},
title = {Towards robust interpretability with self-explaining neural networks},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Most recent work on interpretability of complex machine learning models has focused on estimating a posteriori explanations for previously trained models around specific predictions. Self-explaining models where interpretability plays a key role already during learning have received much less attention. We propose three desiderata for explanations in general – explicitness, faithfulness, and stability – and show that existing methods do not satisfy them. In response, we design self-explaining models in stages, progressively generalizing linear classifiers to complex yet architecturally explicit models. Faithfulness and stability are enforced via regularization specifically tailored to such models. Experimental results across various benchmark datasets show that our framework offers a promising direction for reconciling model complexity and interpretability.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {7786–7795},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@misc{mahinpei2021promisespitfallsblackboxconcept,
      title={Promises and Pitfalls of Black-Box Concept Learning Models}, 
      author={Anita Mahinpei and Justin Clark and Isaac Lage and Finale Doshi-Velez and Weiwei Pan},
      year={2021},
      eprint={2106.13314},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2106.13314}, 
}

@misc{margeloiu2021conceptbottleneckmodelslearn,
      title={Do Concept Bottleneck Models Learn as Intended?}, 
      author={Andrei Margeloiu and Matthew Ashman and Umang Bhatt and Yanzhi Chen and Mateja Jamnik and Adrian Weller},
      year={2021},
      eprint={2105.04289},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2105.04289}, 
}

@article{KhajenezhadMB21,
  author       = {Ahmad Khajenezhad and
                  Hatef Madani and
                  Hamid Beigy},
  title        = {Masked Autoencoder for Distribution Estimation on Small Structured
                  Data Sets},
  journal      = {{IEEE} Transactions Neural Networks Learning Systems},
  volume       = {32},
  number       = {11},
  year         = {2021},
}

@inproceedings{gallego2021flexible,
  title     ={Flexible learning of sparse neural networks via constrained {$L_0$} regularization},
  author    ={Gallego-Posada, Jose and Ramirez, Juan and Erraqabi, Akram},
  booktitle ={NeurIPS 2021 Workshop LatinX in AI},
  year      ={2021}
}

@inproceedings{MaddisonMT17,
  author       = {Chris J. Maddison and
                  Andriy Mnih and
                  Yee Whye Teh},
  title        = {The Concrete Distribution: {A} Continuous Relaxation of Discrete Random
                  Variables},
  booktitle    = {International Conference on Learning Representations, {ICLR}},
  year         = {2017},
}

@inproceedings{JangGP17,
  author       = {Eric Jang and
                  Shixiang Gu and
                  Ben Poole},
  title        = {Categorical Reparameterization with Gumbel-Softmax},
  booktitle    = {International Conference on Learning Representations, {ICLR}},
  year         = {2017},
}

@inproceedings{KingmaB14,
  author       = {Diederik P. Kingma and
                  Jimmy Ba},
  title        = {Adam: {A} Method for Stochastic Optimization},
  booktitle    = {International Conference on Learning Representations, {ICLR}},
  year         = {2015},
}

@inproceedings{ZimmermannSSBB21,
  author       = {Roland S. Zimmermann and
                  Yash Sharma and
                  Steffen Schneider and
                  Matthias Bethge and
                  Wieland Brendel},
  title        = {Contrastive Learning Inverts the Data Generating Process},
  booktitle    = {International Conference on Machine Learning, 
                  {ICML}},
  series       = {Proceedings of Machine Learning Research},
  publisher    = {{PMLR}},
  year         = {2021},
}

@inproceedings{KugelgenSGBSBL21,
  author       = {Julius von K{\"{u}}gelgen and
                  Yash Sharma and
                  Luigi Gresele and
                  Wieland Brendel and
                  Bernhard Sch{\"{o}}lkopf and
                  Michel Besserve and
                  Francesco Locatello},
  title        = {Self-Supervised Learning with Data Augmentations Provably Isolates
                  Content from Style},
  booktitle    = {Advances in Neural Information Processing Systems, {NeurIPS}},
  year         = {2021},
}

@article{chen2018isolating,
  title     = {Isolating sources of disentanglement in variational autoencoders},
  author    = {Chen, Ricky TQ and 
               Li, Xuechen and 
               Grosse, Roger B and 
               Duvenaud, David K},
  journal   = {Advances in neural information processing systems},
  volume    = {31},
  year      = {2018}
}

@article{baker1973joint,
  title={Joint measures and cross-covariance operators},
  author={Baker, Charles R},
  journal={Transactions of the American Mathematical Society},
  year={1973}
}

@article{bricken2023monosemanticity,
   title    = {Towards Monosemanticity: Decomposing Language Models With Dictionary Learning},
   author   = {Bricken, Trenton and 
               Templeton, Adly and 
               Batson, Joshua and 
               Chen, Brian and 
               Jermyn, Adam and 
               Conerly, Tom and 
               Turner, Nick and 
               Anil, Cem and 
               Denison, Carson and
               Askell, Amanda and 
               Lasenby, Robert and 
               Wu, Yifan and 
               Kravec, Shauna and 
               Schiefer, Nicholas and 
               Maxwell, Tim and 
               Joseph, Nicholas and 
               Hatfield-Dodds, Zac and 
               Tamkin, Alex and 
               Nguyen, Karina and 
               McLean, Brayden and 
               Burke, Josiah E and 
               Hume, Tristan and 
               Carter, Shan and 
               Henighan, Tom and 
               Olah, Christopher},
   year     = {2023},
   journal  = {Transformer Circuits Thread},
   note     = {https://transformer-circuits.pub/2023/monosemantic-features/indexhtml}
}.

@inproceedings{HubenCRES24,
  author       = {Robert Huben and
                  Hoagy Cunningham and
                  Logan Riggs and
                  Aidan Ewart and
                  Lee Sharkey},
  title        = {Sparse Autoencoders Find Highly Interpretable Features in Language
                  Models},
  booktitle    = {International Conference on Learning Representations,
                  {ICLR}},
  year         = {2024},
}i

@inproceedings{LippeMLACG22,
  author       = {Phillip Lippe and
                  Sara Magliacane and
                  Sindy L{\"{o}}we and
                  Yuki M. Asano and
                  Taco Cohen and
                  Stratis Gavves},
  title        = {{CITRIS:} Causal Identifiability from Temporal Intervened Sequences},
  booktitle    = {International Conference on Machine Learning, 
                  {ICML}},
  series       = {Proceedings of Machine Learning Research},
  publisher    = {{PMLR}},
  year         = {2022},
}

@inproceedings{PerdomoZMH20,
  author       = {Juan C. Perdomo and
                  Tijana Zrnic and
                  Celestine Mendler{-}D{\"{u}}nner and
                  Moritz Hardt},
  title        = {Performative Prediction},
  booktitle    = {International Conference on Machine Learning,
                  {ICML}},
  series       = {Proceedings of Machine Learning Research},
  publisher    = {{PMLR}},
  year         = {2020},
}

@inproceedings{lippe23a,
  title     = {{BISCUIT}: Causal Representation Learning from Binary
               Interactions},
  author    = {Lippe, Phillip and 
               Magliacane, Sara and 
               L{\"o}we, Sindy and 
               Asano, Yuki M and 
               Cohen, Taco and 
               Gavves, Efstratios},
  booktitle = {Uncertainty in Artificial Intelligence {UAI}},
  year      = {2023},
  series    = {Proceedings of Machine Learning Research},
  publisher = {PMLR},
}


@article{lachapelle2024nonparametric,
  title     = {Nonparametric partial disentanglement via mechanism sparsity:
               Sparse actions, interventions and sparse temporal dependencies},
  author    = {Lachapelle, S{\'e}bastien and 
               L{\'o}pez, Pau Rodr{\'\i}guez and 
               Sharma, Yash and 
               Everett, Katie and 
               Priol, R{\'e}mi Le and 
               Lacoste, Alexandre and 
               Lacoste-Julien, Simon},
  journal   = {arXiv preprint arXiv:2401.04890},
  year      = {2024}
}

@article{yuan2006model,
  title     = {Model selection and estimation in regression with grouped
               variables},
  author    = {Yuan, Ming and 
               Lin, Yi},
  journal   = {Journal of the Royal Statistical Society Series B: Statistical
               Methodology},
  year      = {2006},
  publisher = {Oxford University Press}
}

@inproceedings{kambhampati2022symbols,
  title     = {Symbols as a lingua franca for bridging human-ai chasm for
               explainable and advisable ai systems},
  author    = {Kambhampati, Subbarao and 
               Sreedharan, Sarath and 
               Verma, Mudit and 
               Zha, Yantian and 
               Guan, Lin},
  booktitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
  year      = {2022}
}

@article{verma2020counterfactual,
  title     = {Counterfactual explanations for machine learning: A review},
  author    = {Verma, Sahil and 
               Dickerson, John and 
               Hines, Keegan},
  journal   = {arXiv preprint arXiv:2010.10596},
  year      = {2020}
}

@inproceedings{smilkov2017smoothgrad,
  title     = {Smoothgrad: removing noise by adding noise},
  author    = {Smilkov, Daniel and 
               Thorat, Nikhil and 
               Kim, Been and 
               Vi{\'e}gas, Fernanda and 
               Wattenberg, Martin},
  booktitle = {Proceedings of the 2017 Workshop on Visualization for Deep
               Learning},
  year      = {2017}, 
  organization={ICML}
}

@book{molnar2022,
  title      = {Interpretable Machine Learning},
  author     = {Christoph Molnar},
  year       = {2022},
  subtitle   = {A Guide for Making Black Box Models Explainable},
  edition    = {2},
}


@inproceedings{beckers2019abstracting,
  title     = {Abstracting causal models},
  author    = {Beckers, Sander and 
               Halpern, Joseph Y},
  booktitle = {Proceedings of the {AAAI} conference on artificial intelligence},
  year      = {2019}
}

@inproceedings{beckers2020approximate,
  title         = {Approximate causal abstractions},
  author        = {Beckers, Sander and 
                   Eberhardt, Frederick and 
                   Halpern, Joseph Y},
  booktitle     = {Uncertainty in Artificial Intelligence {UAI}},
  year          = {2020},
  organization  = {PMLR}
}

@article{schut2023bridging,
  title    = {Bridging the human-ai knowledge gap: Concept discovery and
             transfer in alphazero},
  author   = {Schut, Lisa and 
              Tomasev, Nenad and 
              McGrath, Tom and 
              Hassabis, Demis and 
              Paquet, Ulrich and 
              Kim, Been},
  journal = {arXiv preprint arXiv:2310.16410},
  year    = {2023}
}

@inproceedings{zhang2021invertible,
  title     = {Invertible concept-based explanations for cnn models with
               non-negative concept activation vectors},
  author    = {Zhang, Ruihan and 
               Madumal, Prashan and 
               Miller, Tim and 
               Ehinger, Krista A and 
               Rubinstein, Benjamin IP},
  booktitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
  year      = {2021}
}

@inproceedings{ahujaMWB2023,
  title     = {Interventional causal representation learning},
  author    = {Ahuja, Kartik and 
               Mahajan, Divyat and 
               Wang, Yixin and 
               Bengio, Yoshua},
  booktitle = {International Conference on Machine Learning, {ICML}},
  year      = {2023},
  series    = {Proceedings of Machine Learning Research},
  organization={PMLR}
}

@inproceedings{zarlenga2022concept,
  title     = {Concept embedding models: beyond the accuracy-explainability
               trade-off},
  author    = {Zarlenga, Mateo Espinosa and 
               Barbiero, Pietro and 
               Ciravegna, Gabriele and 
               Marra, Giuseppe and 
               Giannini, Francesco and
               Diligenti, Michelangelo and 
               Shams, Zohreh and 
               Precioso, Frederic and 
               Melacci, Stefano and 
               Weller, Adrian and 
               others},
  booktitle = {Advances in Neural Information Processing Systems, {NeurIPS}},
  year={2022}
}

@inproceedings{xu2024sparsity,
    author       = {Xu, Danru and 
                    Yao, Dingling and 
                    Lachapelle, Sébastien and 
                    Taslakian, Perouz and 
                    von Kügelgen, Julius and 
                    Locatello, Francesco and 
                    Magliacane, Sara},
    booktitle    = {International Conference on Machine Learning, {ICML}},
	publisher    = {{PMLR}},
	series       = {Proceedings of Machine Learning Research},
    title        = {A sparsity principle for partially observable causal
                    representation learning},
    year         = {2024}
}


@inproceedings{WS2000nystrom,
 author    = {Williams, Christopher and 
              Seeger, Matthias},
 booktitle = {Advances in Neural Information Processing Systems, {NeurIPS}},
 publisher = {MIT Press},
 title     = {Using the Nystr\"{o}m Method to Speed Up Kernel Machines},
 volume    = {13},
 year      = {2000}
}


@inproceedings{SHS2001rep,
  title         = {A generalized representer theorem},
  author        = {Sch{\"o}lkopf, Bernhard and 
                   Herbrich, Ralf and 
                   Smola, Alex J},
  booktitle     = {International conference on computational learning theory},
  year          = {2001},
  organization  = {Springer}
}

@book{buhlmannVG11,
  title     = {Statistics for high-dimensional data: 
               methods, theory and applications},
  author    = {B{\"u}hlmann, Peter and Van 
               De Geer, Sara},
  year      = {2011},
  publisher = {Springer Science \& Business Media}
}

@article{BachJMO12,
  author       = {Francis R. Bach and
                  Rodolphe Jenatton and
                  Julien Mairal and
                  Guillaume Obozinski},
  title        = {Optimization with Sparsity-Inducing Penalties},
  journal      = {Foundations and Trends in Machine Learning},
  pages        = {1--106},
  year         = {2012},
}

@book{bach2024first,
  title     = {Learning Theory from First Principles}, 
  publisher = {MIT Press},
  year      = {2024},
  author    = {Bach, Francis R.}
}

@article{cavalier2002oracle,
  title     = {Oracle inequalities for inverse problems},
  author    = {Cavalier, Laurent and 
               Golubev, Georgi K and 
               Picard, Dominique and 
               Tsybakov, Alexandre B},
  journal   = {The Annals of Statistics},
  year      = {2002},
  publisher = {Institute of Mathematical Statistics}
}

@article{bach2008consistency,
  author  = {Francis R. Bach},
  title   = {Consistency of the Group Lasso and Multiple Kernel Learning},
  journal = {Journal of Machine Learning Research},
  year    = {2008},
  volume  = {9},
  number  = {40},
  pages   = {1179--1225},
}

@article{lounici2011oracle,
  title         = {Oracle inequalities and optimal inference under group sparsity},
  author        = {Lounici, Karim and 
                   Pontil, Massimiliano and 
                   Van De Geer, Sara and 
                   Tsybakov, Alexandre B},
  journal       = {The Annals of Statistics},
  year          = {2011}
}

@inproceedings{hyvarinen2019nonlinear,
  author       = {Aapo Hyv{\"{a}}rinen and
                  Hiroaki Sasaki and
                  Richard E. Turner},
  title        = {Nonlinear {ICA} Using Auxiliary Variables and Generalized
                  Contrastive Learning},
  booktitle    = {International Conference on Artificial Intelligence and 
                  Statistics, {AISTATS}},
  series       = {Proceedings of Machine Learning Research},
  publisher    = {{PMLR}},
  year         = {2019}
}

@inproceedings{
lachapelle2022dms,
title={Disentanglement via Mechanism Sparsity Regularization: A New Principle for Nonlinear {ICA}},
author={Sebastien Lachapelle and Pau Rodriguez and Yash Sharma and Katie E Everett and R{\'e}mi LE PRIOL and Alexandre Lacoste and Simon Lacoste-Julien},
booktitle={First Conference on Causal Learning and Reasoning},
year={2022},
url={https://openreview.net/forum?id=dHsFFekd_-o}
}

@inproceedings{agarwal2021towards,
	title        = {Towards the Unification and Robustness of Perturbation and Gradient Based Explanations},
	author       = {Sushant Agarwal and
					Shahin Jabbari and
				    Chirag Agarwal and
				    Sohini Upadhyay and
				    Steven Wu and
				    Himabindu Lakkaraju},
	year         = {2021},
	booktitle    = {International Conference on Machine Learning, {ICML}},
	publisher    = {{PMLR}},
	series       = {Proceedings of Machine Learning Research}
}
@article{garreau2020looking,
	title        = {Looking deeper into LIME},
	author       = {Damien Garreau and
				    Ulrike von Luxburg},
	year         = {2020}
}
@article{sundararajan2017axiomatic,
	title        = {Axiomatic attribution for deep networks},
	author       = {Sundararajan, Mukund and
				    Taly, Ankur an Yan, Qiqi},
	year         = {2017},
	booktitle    = {International Conference on Machine Learning, {ICML}},
	publisher    = {{PMLR}},
	series       = {Proceedings of Machine Learning Research},
}
@article{lundberg2017unified,
	title        = {A unified approach to interpreting model predictions},
	author       = {Lundberg, Scott M and
				    Lee, Su-In},
	year         = {2017},
	booktitle    = {Advances in Neural Information Processing Systems, {NeurIPS}},
}
@article{adebayo2018sanity,
	title        = {Sanity checks for saliency maps},
	author       = {Adebayo, Julius and
				    Gilmer, Justin and
				    Muelly, Michael and
				    Goodfellow, Ian and
				    Hardt, Moritz and
				    Kim, Been},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1810.03292}
}
@article{ancona2019gradient,
	title        = {Gradient-based attribution methods},
	author       = {Ancona, Marco and
				    Ceolini, Enea and
				    {\"O}ztireli, Cengiz and
				    Gross, Markus},
	year         = {2019},
	booktitle    = {Explainable AI: Interpreting, Explaining and Visualizing Deep Learning},
	publisher    = {Springer},
}
@article{guidotti2018survey,
	title        = {A survey of methods for explaining black box models},
	author       = {Guidotti, Riccardo and
				    Monreale, Anna and
				    Ruggieri, Salvatore and
				    Turini, Franco and
				    Giannotti, Fosca and
				    Pedrechi, Dino},
	year         = {2018},
	journal      = {ACM computing surveys (CSUR)},
	publisher    = {ACM New York},
}
@article{kindermans2019reliability,
	title        = {The (un) reliability of saliency methods},
	author       = {Kindermans, Pieter-Jan and
				    Hooker, Sara and
				    Adebayo, Julius and
				    Alber, Maximilian and
				    Sch{\"u}tt, Kristof T and
				    D{\"a}hne, Sven and
				    Erhan, Dumitru and
				    Kim, Been},
	year         = {2019},
	booktitle    = {Explainable AI: Interpreting, Explaining and Visualizing Deep Learning},
	publisher    = {Springer},
}
@article{vaswani2017attention,
	title        = {Attention is all you need},
	author       = {Vaswani, Ashish and
				    Shazeer, Noam and
				    Parmar, Niki and
				    Uszkoreit, Jakob and
				    Jones, Llion and
				    Gomez, Aidan N and
				    Kaiser, {\L}ukasz and
				    Polosukhin, Illia},
	year         = {2017},
	journal      = {Advances in Neural Information Processing Systems, {NeurIPS}},
}
@article{devlin2018bert,
	title        = {Bert: Pre-training of deep bidirectional transformers for language understanding},
	author       = {Devlin, Jacob and
				    Chang, Ming-Wei and
				    Lee, Kenton and
				    Toutanova, Kristina},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1810.04805}
}
@article{radford2019language,
	title        = {Language models are unsupervised multitask learners},
	author       = {Radford, Alec and
				    Wu, Jeffrey and
				    Child, Rewon and
				    Luan, David and
				    Amodei, Dario and
				    Sutskever, Ilya and
				    others},
	year         = {2019},
	journal      = {OpenAI blog},
}
@article{dosovitskiy2020image,
	title        = {An image is worth 16x16 words: Transformers for image recognition at scale},
	author       = {Dosovitskiy, Alexey and Beyer, Lucas and
				    Kolesnikov, Alexander and
				    Weissenborn, Dirk and
				    Zhai, Xiaohua and
				    Unterthiner, Thomas and
				    Dehghani, Mostafa and
				    Minderer, Matthias and
				    Heigold, Georg and
				    Gelly, Sylvain and
				    others},
	year         = {2020},
	journal      = {arXiv preprint arXiv:2010.11929}
}
@inproceedings{bibal2022attention,
	title        = {Is attention explanation? an introduction to the debate},
	author       = {Bibal, Adrien and
				    Cardon, R{\'e}mi and
				    Alfter, David and
				    Wilkens, Rodrigo and
				    Wang, Xiaoou and
				    Fran{\c{c}}ois, Thomas and
				    Watrin, Patrick},
	year         = {2022},
	booktitle    = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	pages        = {3889--3900}
}
@article{bastings2020elephant,
	title        = {The elephant in the interpretability room: Why use attention as explanation when we have saliency methods?},
	author       = {Bastings, Jasmijn and
				    Filippova, Katja},
	year         = {2020},
	journal      = {arXiv preprint arXiv:2010.05607}
}
@article{mcgrath2022acquisition,
	title        = {Acquisition of chess knowledge in alphazero},
	author       = {McGrath, Thomas and
				    Kapishnikov, Andrei and
				    Toma{\v{s}}ev, Nenad and
				    Pearce, Adam and
				    Wattenberg, Martin and
				    Hassabis, Demis and
				    Kim, Been and
				    Paquet, Ulrich and
				    Kramnik, Vladimir},
	year         = {2022},
	journal      = {Proceedings of the National Academy of Sciences},
	publisher    = {National Academy Sciences},
}
@article{bolukbasi2021interpretability,
	title        = {An interpretability illusion for bert},
	author       = {Bolukbasi, Tolga and
				    Pearce, Adam and
				    Yuan, Ann and
				    Coenen, Andy and
				    Reif, Emily and
				    Vi{\'e}gas, Fernanda and
				    Wattenberg, Martin},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2104.07143}
}
@article{nanda2023progress,
	title        = {Progress measures for grokking via mechanistic interpretability},
	author       = {Nanda, Neel and
				    Chan, Lawrence and
				    Liberum, Tom and
				    Smith, Jess and
				    Steinhardt, Jacob},
	year         = {2023},
	journal      = {arXiv preprint arXiv:2301.05217}
}
@inproceedings{koh2020conceptbottleneck,
	title        = {Concept Bottleneck Models},
	author       = {Koh, Pang Wei and
				    Nguyen, Thao and
				    Tang, Yew Siang and
				    Mussmann, Stephen and
				    Pierson, Emma and
				    Kim, Been and
				    Liang, Percy},
	year         = {2020},
	booktitle    = {International Conference on Machine Learning, {ICML}},
	publisher    = {{PMLR}},
	series       = {Proceedings of Machine Learning Research},
}
@article{abnar2020quantifying,
	title        = {Quantifying attention flow in transformers},
	author       = {Abnar, Samira and
				    Zuidema, Willem},
	year         = {2020},
	journal      = {arXiv preprint arXiv:2005.00928}
}
@inproceedings{ethayarajh2021attention,
	title        = {Attention Flows are Shapley Value Explanations},
	author       = {Ethayarajh, Kawin  and
				    Jurafsky, Dan},
	year         = {2021},
	booktitle    = {Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
}
@inproceedings{amini2022faithful,
	title        = {How (Un) Faithful is Attention?},
	author       = {Amini, Hessam and
				    Kosseim, Leila},
	year         = {2022},
	booktitle    = {Proceedings of the {BlackboxNLP} Workshop on Analyzing
                    and Interpreting Neural Networks for {NLP},
                    {BlackboxNLP@EMNLP}},
}
@inproceedings{clark2019does,
	title        = {What Does BERT Look at? An Analysis of BERT‚Äôs Attention},
	author       = {Clark, Kevin and
				    Khandelwal, Urvashi and
				    Levy, Omer and
				    Manning, Christopher D},
	year         = {2019},
	booktitle    = {Proceedings of the {BlackboxNLP} Workshop on Analyzing
                    and Interpreting Neural Networks for {NLP},
                    {BlackboxNLP@EMNLP}},
}
@article{geshkovski2023emergence,
	title        = {The emergence of clusters in self-attention dynamics},
	author       = {Geshkovski, Borjan and
				    Letrouit, Cyril and
				    Polyanskiy, Yury and
				    Rigollet, Philippe},
	year         = {2023},
	journal      = {arXiv preprint arXiv:2305.05465}
}
@inproceedings{kim2018interpretability,
    title        = {Interpretability beyond feature attribution: Quantitative
                    testing with concept activation vectors ({TCAV})},
	author       = {Kim, Been and
				    Wattenberg, Martin and
				    Gilmer, Justin and
				    Cai, Carrie and
				    Wexler, James and
				    Viegas, Fernanda and
				    others},
	year         = {2018},
	booktitle    = {International Conference on Machine Learning, {ICML}},
    series       = {Proceedings of Machine Learning Research},
    publisher    = {{PMLR}},
}
@inproceedings{graziani2018regression,
	title        = {Regression concept vectors for bidirectional explanations in histopathology},
	author       = {Graziani, Mara and
				    Andrearczyk, Vincent and
				    M{\"u}ller, Henning},
	year         = {2018},
    booktitle    = {Understanding and Interpreting Machine Learning in Medical
                    Image Computing Applications: First International
                    Workshops},
}
@inproceedings{graziani2023concept,
	title        = {Concept discovery and dataset exploration with singular value decomposition},
	author       = {Graziani, Mara and
				    Nguyen, An-phi and
				    O'Mahony, Laura and
				    M{\"u}ller, Henning and
				    Andrearczyk, Vincent},
	year         = {2023},
	booktitle    = {ICLR 2023 Workshop on Pitfalls of limited data and computation for Trustworthy ML}
}
@article{graziani2020physicians,
	title        = {Concept attribution: Explaining CNN decisions to physicians},
	author       = {Graziani M. and
				    Andrearczyk V. and
				    Marchand-Maillet S. and
				    M{\"u}ller H.},
	year         = {2020},
	journal      = {Computers in Biology and Medicine},
}
@article{magister2021gcexplainer,
	title        = {Gcexplainer: Human-in-the-loop concept-based explanations for graph neural networks},
	author       = {Magister, Lucie Charlotte and
				    Kazhdan, Dmitry and
				    Singh, Vikash and
				    Li{\`o}, Pietro},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2107.11889}
}
@article{magister2022encoding,
	title        = {Encoding concepts in graph neural networks},
	author       = {Magister, Lucie Charlotte and
				    Barbiero, Pietro and
				    Kazhdan, Dmitry and
				    Siciliano, Federico and
				    Ciravegna, Gabriele and
				    Silvestri, Fabrizio and
				    Jamnik, Mateja and
				    Lio, Pietro},
	year         = {2022},
	journal      = {arXiv preprint arXiv:2207.13586}
}
@article{ghorbani2019towards,
	title        = {Towards automatic concept-based explanations},
	author       = {Ghorbani, Amirata and
				    Wexler, James and
				    Zou, James Y and
				    Kim, Been},
	year         = {2019},
	journal      = {Advances in Neural Information Processing Systems, {NeurIPS}},
}
@article{lyu2022online,
	title        = {Online nonnegative CP-dictionary learning for Markovian data},
	author       = {Lyu, Hanbaek and
				    Strohmeier, Christopher and
				    Needell, Deanna},
	year         = {2022},
	journal      = {Journal of Machine Learning Research},
}
@inproceedings{brunner2020identifiability,
	title        = {On Identifiability in Transformers},
	author       = {Gino Brunner and
				    Yang Liu and
				    Damian Pascual and
				    Oliver Richter and
				    Massimiliano Ciaramita and
				    Roger Wattenhofer},
	year         = {2020},
	booktitle    = {International Conference on Learning Representations, {ICLR}},
}
@inproceedings{pereira2023distillnexplain,
	title        = {Distill n' Explain: explaining graph neural networks using simple surrogates},
	author       = {Pereira, Tamara and
				    Nascimento, Erik and
				    Resck, Lucas E. and
				    Mesquita, Diego and
				    Souza, Amauri},
	year         = {2023},
	booktitle    = {International Conference on Artificial Intelligence and Statistics, {AISTATS}},
	publisher    = {{PMLR}},
	series       = {Proceedings of Machine Learning Research},
}
@article{chughtai2023toy,
	title        = {A toy model of universality: Reverse engineering how networks learn group operations},
	author       = {Chughtai, Bilal and
				    Chan, Lawrence and
				    Nanda, Neel},
	year         = {2023},
	journal      = {arXiv preprint arXiv:2302.03025}
}
@article{conmy2023towards,
	title        = {Towards automated circuit discovery for mechanistic interpretability},
	author       = {Conmy, Arthur and
				    Mavor-Parker, Augustine N and
				    Lynch, Aengus and
				    Heimersheim, Stefan and
				    Garriga-Alonso, Adri{\`a}},
	year         = {2023},
	journal      = {arXiv preprint arXiv:2304.14997}
}
@article{elhage2021mathematical,
	title        = {A mathematical framework for transformer circuits},
	author       = {Elhage, Nelson and
				    Nanda, Neel and
				    Olsson, Catherine and
				    Henighan, Tom and
				    Joseph, Nicholas and
				    Mann, Ben and
				    Askell, Amanda and
				    Bai, Yuntao and
				    Chen, Anna and
				    Conerly, Tom and
				    others},
	year         = {2021},
	journal      = {Transformer Circuits Thread},
}
@inproceedings{wang2023interpretability,
	title        = {Interpretability in the Wild: a Circuit for Indirect Object Identification in {GPT}-2 Small},
	author       = {Kevin Ro Wang and
				    Alexandre Variengien and
				    Arthur Conmy and
				    Buck Shlegeris and
				    Jacob Steinhardt},
	year         = {2023},
	booktitle    = {International Conference on Learning Representations, {ICLR}},
}
@inproceedings{alain2017understanding,
	title        = {Understanding intermediate layers using linear classifier probes},
	author       = {Guillaume Alain and
				    Yoshua Bengio},
	year         = {2017},
	booktitle    = {International Conference on Learning Representations, {ICLR}},
}
@article{belinkov2022probing,
	title        = {Probing classifiers: Promises, shortcomings, and advances},
	author       = {Belinkov, Yonatan},
	year         = {2022},
	journal      = {Computational Linguistics},
}
@article{mahinpei2021promises,
  title         = {Promises and pitfalls of black-box concept learning models},
  author        = {Mahinpei, Anita and 
                   Clark, Justin and 
                   Lage, Isaac and
                   Doshi-Velez, Finale and 
                   Pan, Weiwei},
  journal       = {arXiv preprint arXiv:2106.13314},
  year          = {2021}
}
@article{ravfogel2022linear,
	title        = {Linear Guardedness and its Implications},
	author       = {Ravfogel, Shauli and
				    Goldberg, Yoav and
				    Cotterell, Ryan},
	year         = {2022},
	journal      = {arXiv preprint arXiv:2210.10012}
}
@article{geiger2023causal,
	title        = {Causal abstraction for faithful model interpretation},
	author       = {Geiger, Atticus and
				    Potts, Chris and
				    Icard, Thomas},
	year         = {2023},
	journal      = {arXiv preprint arXiv:2301.04709}
}
@article{pimentel2020information,
	title        = {Information-theoretic probing for linguistic structure},
	author       = {Pimentel, Tiago and
				    Valvoda, Josef and
				    Maudslay, Rowan Hall and
				    Zmigrod, Ran and
				    Williams, Adina and
				    Cotterell, Ryan},
	year         = {2020},
	journal      = {arXiv preprint arXiv:2004.03061}
}
@article{hewitt2021conditional,
	title        = {Conditional probing: measuring usable information beyond a baseline},
	author       = {Hewitt, John and
				    Ethayarajh, Kawin and
				    Liang, Percy and
				    Manning, Christopher D},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2109.09234}
}
@article{espinosa2022concept,
	title        = {Concept embedding models: Beyond the accuracy-explainability trade-off},
	author       = {Espinosa Zarlenga, Mateo and
				    Barbiero, Pietro and
				    Ciravegna, Gabriele and
				    Marra, Giuseppe and
				    Giannini, Francesco and
				    Diligenti, Michelangelo and
				    Shams, Zohreh and
				    Precioso, Frederic and
				    Melacci, Stefano and
				    Weller, Adrian and
				    others},
	year         = {2022},
	journal      = {Advances in Neural Information Processing Systems, {NeurIPS}},
}
@article{geiger2021causal,
	title        = {Causal abstractions of neural networks},
	author       = {Geiger, Atticus and
				    Lu, Hanson and
				    Icard, Thomas and
				    Potts, Christopher},
	year         = {2021},
	journal      = {Advances in Neural Information Processing Systems},
	volume       = {34},
	pages        = {9574--9586}
}
@inproceedings{wu2023causal,
	title        = {Causal Proxy Models for concept-based model explanations},
	author       = {Wu, Zhengxuan and
				    D'Oosterlinck, Karel and
				    Geiger, Atticus and
				    Zur, Amir and
				    Potts, Christopher},
	year         = {2023},
	booktitle    = {International Conference on Machine Learning, {ICML}},
	organization = {{PMLR}},
	series       = {Proceedings of Machine Learning Research},
}
@article{steinmann2023learning,
	title        = {Learning to Intervene on Concept Bottlenecks},
	author       = {Steinmann, David and
				    Stammer, Wolfgang and
				    Friedrich, Felix and
				    Kersting, Kristian},
	year         = {2023},
	journal      = {arXiv preprint arXiv:2308.13453}
}
@inproceedings{adebayo2021post,
	title        = {Post hoc explanations may be ineffective for detecting unknown spurious correlation},
	author       = {Adebayo, Julius and
				    Muelly, Michael and
				    Abelson, Harold and
				    Kim, Been},
	year         = {2021},
	booktitle    = {International Conference on Learning Representations, {ICLR}}
}
@inproceedings{ismail2023concept,
	title        = {Concept Bottleneck Generative Models},
	author       = {Ismail, Aya Abdelsalam and
				    Adebayo, Julius and
				    Bravo, Hector Corrada and
				    Ra, Stephen and
				    Cho, Kyunghyun},
	year         = {2023},
	booktitle    = {International Conference on Learning Representations, {ICLR}}
}
@article{ravichander2020probing,
	title        = {Probing the probing paradigm: Does probing accuracy entail task relevance?},
	author       = {Ravichander, Abhilasha and
				    Belinkov, Yonatan and
				    Hovy, Eduard},
	year         = {2020},
	journal      = {arXiv preprint arXiv:2005.00719}
}
@article{goyal2019explaining,
	title        = {Explaining classifiers with causal concept effect ({CaCE})},
	author       = {Goyal, Yash and
				    Feder, Amir and
				    Shalit, Uri and
				    Kim, Been},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1907.07165}
}
@article{alain2016understanding,
	title        = {Understanding intermediate layers using linear classifier probes},
	author       = {Alain, Guillaume and
				    Bengio, Yoshua},
	year         = {2016},
	journal      = {arXiv preprint arXiv:1610.01644}
}
@inproceedings{peters2011identifiability,
	title        = {Identifiability of causal graphs using functional Models},
	author       = {Peters, Jonas and
				    Mooij, Joris M and
				    Janzing, Dominik and
				    Sch{\"o}lkopf, Bernhard},
	year         = {2011},
	booktitle    = {Uncertainty in Artificial Intelligence {UAI}},
}
@inproceedings{clark2019bert,
	title        = {What Does {BERT} Look at? An Analysis of {BERT}{'}s Attention},
	author       = {Clark, Kevin  and
				    Khandelwal, Urvashi  and
				    Levy, Omer  and
				    Manning, Christopher D.},
	year         = {2019},
    booktitle    = {Proceedings of the {BlackboxNLP} Workshop on Analyzing
                    and Interpreting Neural Networks for {NLP},
                    {BlackboxNLP@EMNLP}},
	publisher    = {Association for Computational Linguistics},
}
@article{lovering2022unit,
	title        = {Unit Testing for Concepts in Neural Networks},
	author       = {Lovering, Charles  and
				    Pavlick, Ellie},
	year         = {2022},
	journal      = {Transactions of the Association for Computational Linguistics},
	publisher    = {MIT Press},
}
@article{fodor2001fodor,
	author       = {Steven Gross},
	year         = {2001},
	journal      = {Mind},
	publisher    = {[Oxford University Press, Mind Association]},
}
@article{mooij2016observational,
	title        = {Distinguishing Cause from Effect Using Observational Data: Methods and Benchmarks},
	author       = {Joris M. Mooij and
				    Jonas Peters and
				    Dominik Janzing and
				    Jakob Zscheischler and
				    Bernhard Sch{{\"o}}lkopf},
	year         = {2016},
	journal      = {Journal of Machine Learning Research},
}
@article{nichols2007observational,
	title        = {Causal Inference with Observational Data},
	author       = {Austin Nichols},
	year         = {2007},
	journal      = {The Stata Journal},
}
@book{peters2017elements,
	title        = {Elements of causal inference: foundations and learning algorithms},
	author       = {Peters, Jonas and
				    Janzing, Dominik and
				    Sch{\"o}lkopf, Bernhard},
	year         = {2017},
	publisher    = {The MIT Press}
}
@inproceedings{zhang2009identifiability,
	title        = {On the Identifiability of the Post-Nonlinear Causal Model},
	author       = {Zhang, K and
				    Hyv{\"a}rinen, A},
	year         = {2009},
	booktitle    = {Uncertainty in Artificial Intelligence {UAI}},
	organization = {AUAI Press}
}
@article{mcgrath2021acquisition,
	title        = {Acquisition of Chess Knowledge in AlphaZero},
	author       = {McGrath, Thomas and
				    Kapishnikov, Andrei and
				    Toma{\v{s}}ev, Nenad and
				    Pearce, Adam and
				    Hassabis, Demis and
				    Kim, Been and
				    Paquet, Ulrich and
				    Kramnik, Vladimir},
	year         = {2022},
	journal      = {Proceedings of the National Academy of Sciences, {PNAS}},
    publisher    = {National Academy of Sciences}
}
@article{scholkopf2021crl,
	title        = {Toward Causal Representation Learning},
	author       = {Sch{\"o}lkopf, Bernhard and
				    Locatello, Francesco and
				    Bauer, Stefan and
				    Ke, Nan Rosemary and
				    Kalchbrenner, Nal and
				    Goyal, Anirudh and
				    Bengio, Yoshua},
	year         = {2021},
	journal      = {Proceedings of the IEEE}
}
@inproceedings{kugelgen2023nonparametric,
	title        = {Nonparametric Identifiability of Causal Representations from Unknown Interventions},
	author       = {Julius von K{\"{u}}gelgen and
				    Michel Besserve and
				    Wendong Liang and
				    Luigi Gresele and
				    Armin Kekic and
				    Elias Bareinboim and
				    David M. Blei and
				    Bernhard Sch{\"{o}}lkopf},
	year         = {2023},
	booktitle    = {Neural Information Processing Systems, {NeurIPS}}
}
@article{marconato2023humanintepretable,
    title        = {Interpretability is in the Mind of the Beholder: {A} Causal
                    Framework for Human-interpretable Representation Learning},
	author       = {Emanuele Marconato and
				    Andrea Passerini and
				    Stefano Teso},
	year         = {2023},
	journal      = {Entropy},
    publisher    = {MDPI}
}
@inproceedings{li2023syntheticinterventions,
	title        = {Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task},
	author       = {Kenneth Li and
				    Aspen K. Hopkins and
				    David Bau and
				    Fernanda B. Vi{\'{e}}gas and
				    Hanspeter Pfister and
				    Martin Wattenberg},
	year         = {2023},
	booktitle    = {International Conference on Learning Representations, {ICLR}}
}
@article{Wu2023scale,
	title        = {Interpretability at Scale: Identifying Causal Mechanisms in Alpaca},
	author       = {Zhengxuan Wu and 
                    Atticus Geiger and 
                    Christopher Potts and 
                    Noah D. Goodman},
	year         = {2023},
	journal      = {arXiv preprint arXiv:2305.08809} 
}
@inproceedings{wang2023concept,
	title        = {Concept Algebra for (Score-Based) Text-Controlled Generative Models},
	author       = {Zihao Wang and 
                    Lin Gui and 
                    Jeffrey Negrea and 
                    Victor Veitch},
	year         = {2023},
    booktitle    = {Advances in Neural Information Processing Systems, {NeurIPS}},
}
@inproceedings{ilse2021augmentation,
	title        = {Selecting Data Augmentation for Simulating Interventions},
	author       = {Maximilian Ilse and 
                    Jakub M. Tomczak and 
                    Patrick Forr{\'{e}}},
	year         = {2021},
	booktitle    = {International Conference on Machine Learning, {ICML}},
	publisher    = {{PMLR}},
	series       = {Proceedings of Machine Learning Research}
}
@inproceedings{suter2019robustdis,
    title        = {Robustly Disentangled Causal Mechanisms: Validating Deep
                    Representations for Interventional Robustness},
	author       = {Raphael Suter and 
                    {\DH}or{\dh}e Miladinovic and 
                    Bernhard Sch{\"{o}}lkopf and 
                    Stefan Bauer},
	year         = {2019},
	booktitle    = {International Conference on Machine Learning, {ICML}},
	publisher    = {{PMLR}},
	series       = {Proceedings of Machine Learning Research},
}
@article{lipton2018mythos,
	title        = {The mythos of model interpretability},
	author       = {Zachary C. Lipton},
	year         = {2018},
	journal      = {Commun. {ACM}}
}
@inproceedings{marconato2022glance,
	title        = {GlanceNets: Interpretable, Leak-proof Concept-based Models},
	author       = {Emanuele Marconato and 
                    Andrea Passerini and 
                    Stefano Teso},
	year         = {2022},
	booktitle    = {Neural Information Processing Systems, {NeurIPS}}
}
@inproceedings{geiger2022inducing,
	title        = {Inducing Causal Structure for Interpretable Neural Networks},
    author       = {Atticus Geiger and 
                    Zhengxuan Wu and 
                    Hanson Lu and 
                    Josh Rozner and 
                    Elisa Kreiss and 
                    Thomas Icard and 
                    Noah D. Goodman and 
                    Christopher Potts},
	year         = {2022},
	booktitle    = {International Conference on Machine Learning, {ICML}},
	publisher    = {{PMLR}},
	series       = {Proceedings of Machine Learning Research}
}
@inproceedings{geiger2020interchange,
	title        = {Neural Natural Language Inference Models Partially Embed Theories of Lexical Entailment and Negation},
	author       = {Atticus Geiger and 
                    Kyle Richardson and 
                    Christopher Potts},
	year         = {2020},
    booktitle    = {Proceedings of the Third BlackboxNLP Workshop on Analyzing
                    and Interpreting Neural Networks for NLP,
                    {BlackboxNLP@EMNLP}},
	publisher    = {Association for Computational Linguistics}
}
@book{pearl2009causality,
	title        = {Causality},
	author       = {Judea Pearl},
	year         = {2009},
	publisher    = {Cambridge university press}
}

@book{forre2023mathematical,
	title        = {A Mathematical Introduction to Causality},
	author       = {Patrick Forr{\'e} and 
                    Joris M Mooij},
	year         = {2023}
}
@article{identifiability2023ica,
    author       = {Aapo Hyv{\"{a}}rinen and
                    Ilyes Khemakhem and
                    Ricardo Pio Monti},
    title        = {Identifiability of latent-variable and structural-equation models:
                    from linear to nonlinear},
    year         = {2023},
	journal      = {arXiv preprint arXiv:2302.02672} 
}
@inproceedings{buchholz2022function,
  author       = {Simon Buchholz and
                  Michel Besserve and
                  Bernhard Sch{\"{o}}lkopf},
  title        = {Function Classes for Identifiable Nonlinear Independent
                  Component Analysis},
  booktitle    = {Advances in Neural Information Processing Systems,
                  {NeurIPS}}, 
  year         = {2022},
}
@inproceedings{khemakhem2020vaeica,
  author       = {Ilyes Khemakhem and
                  Diederik P. Kingma and
                  Ricardo Pio Monti and
                  Aapo Hyv{\"{a}}rinen},
  title        = {Variational Autoencoders and Nonlinear {ICA:} {A}
                  Unifying Framework},
  booktitle    = {International Conference on Artificial Intelligence and
                  Statistics, {AISTATS} },
  series       = {Proceedings of Machine Learning Research},
  publisher    = {{PMLR}},
  year         = {2020},
}
@inproceedings{rubenstein2017abstraction,
  author       = {Paul K. Rubenstein and
                  Sebastian Weichwald and
                  Stephan Bongers and
                  Joris M. Mooij and
                  Dominik Janzing and
                  Moritz Grosse{-}Wentrup and
                  Bernhard Sch{\"{o}}lkopf},
  title        = {Causal Consistency of Structural Equation Models},
  booktitle    = {Conference on Uncertainty in Artificial
                  Intelligence, {UAI}},
  publisher    = {{AUAI} Press},
  year         = {2017},
}

@Article{HofmannScholkopfSmola2008,
  author =    {Thomas Hofmann and Bernhard Sch{\"o}lkopf and Alexander J. Smola},
  title =     {{Kernel methods in machine learning}},
  journal =   {The Annals of Statistics},
  year =      {2008},
  volume =    {36},
  number =    {3},
  pages =     {1171--1220},
  doi =       {10.1214/009053607000000677},
  publisher = {Institute of Mathematical Statistics},
  url =       {https://doi.org/10.1214/009053607000000677}
}

@Article{BengioEtAl2025,
  author = {Bengio, Yoshua and Mindermann, S{\"o}ren and Privitera, Daniel and Besiroglu, Tamay and Bommasani, Rishi and Casper, Stephen and Choi, Yejin and Fox, Philip and Garfinkel, Ben and Goldfarb, Danielle and Heidari, Hoda and Ho, Anson and Kapoor, Sayash and Khalatbari, Leila and others},
  title  = {International AI Safety Report},
  url    = {https://assets.publishing.service.gov.uk/media/679a0c48a77d250007d313ee/International_AI_Safety_Report_2025_accessible_f.pdf},
  year   = {2025},
}
  
