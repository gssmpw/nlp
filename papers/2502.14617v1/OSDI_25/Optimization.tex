% \clearpage
\section{Optimization Problem \pglen{1}}
\label{sec:optz}
We solve the problem of request routing
and capacity allocation to serve fast and slow LLM inferencing workloads within the required SLA while maximizing utilization. 

\noindent \textbf{Definition.}~\textit{
Given a captive set of VMs of specific types in multiple regions, 
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt]
    \item we need to continuously ensure that the right number of model instances of different model types are provisioned as endpoints at the regions, and 
    \item route the incoming workload across these endpoints,
\end{itemize}
such that
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt]
    \item we maximize the utility of the workload requests completed within their SLA, and 
    \item maximize the capacity utilization of the VMs for the internal workloads.
\end{itemize}}
We have two parts to solving this high level problem. 

% One, we need to \textbf{forecast the load} for the different model types over time generated by the different workloads. \apnote{@kunal, we are not making predctions at 2 different granularity, right?} Here, the forecasting has to be at coarse granularity and time horizon (e.g., at 15~mins for 24~hour) to preemptively reprovisioning LLM instances that can take 1--10s of mins, and at finer granularity and horizon (e.g., at 1~min for 1~hour) for routing requests. While the bulk of the workloads that involve product users have a periodicity, NIW  do not have such a discernible pattern and we need to account for the same.

First, we need to \textbf{optimally provision instances} for model endpoints in different regions to handle this workload, within the available VM capacities. Since there is an overhead for (re)provisioning an LLM instance set onto VMs, we need to consider the inefficiency due to this process when the GPU VMs are not serving.
Given this, such reprovisioning decisions are viable at a coarse granularity, e.g., every 15~mins -- while some reprovisioning such as reclaiming spot instances can be fast, e.g., done each 1~min.

Second, we need to \textbf{route the requests} to the model instances in different regions while meeting the SLA. These routing decisions can use real-time information on the load and responsiveness of the region endpoints.
As part of reprovisioning resources and routing, we need to use relevant tools~\cite{splitwise} to estimate the expected latency for serving requests at a certain request rate to ensure we meet the SLA.
%
Any spare capacity of model instances that are not being used for workloads can be released to external spot instances.

Next, we formulate these as an optimization problem. 


\subsection{Problem Formulation} \label{sec:optimization}
\begin{table}[t]
\setlength{\tabcolsep}{2pt} % reduce horizontal spacing
    \centering
   \caption{Variables used in optimization problem}
    \label{tab:ILP_var}
    \begin{tabular}{ccp{5.3cm}}
    \hline
        \bf Symbol & \bf Type  & \bf Description \\
         \hline\hline
$l$ & $\texttt{int}$ &  Model types  \\
$r$ & $\texttt{int}$ & Number of regions\\
$g$ & $\texttt{int}$  & GPU types\\
$n_{i, j, k}$ &$[\texttt{int}]_{l\times r\times g}$ & Instances of model $i$ at region $j$ on GPU type $k$\\ %$C_{i, j, k}$
 $\rho_{i, j, w}$ & $[\texttt{int}]_{l\times r}$ & {TPS requested} for model $i$ from clients at region $j$ for future time window $w$ \\ % R_i,j
$\theta_{i, k}$ & $ [\texttt{float}]_{l\times g}$ &  TPS provided by model $i$ on GPU $k$ \\
 $\alpha_{k}$ & $[\texttt{float}]_{g}$ & Cost of acquiring VM of GPU type $k$ \\ % G
 $\sigma_{i, k}$ & $[\texttt{float}]_{l\times g}$ &  Cost of starting a model $i$ on VM $k$ \\
    \hline
    $\delta_{i, j, k}$ & $[\texttt{int}]_{l\times r\times g}$ & ILP output: optimal number of changes in VM allocation\\
    \hline
    \end{tabular}
\end{table}


\autoref{tab:ILP_var} has the notations used in the problem definition.

\para{Constraints} 
Say, the current number of VMs of GPU type $k$ assigned to a model $i$ at region $j$ at a given time is $n_{i,j, k}$. Let $\delta_{i, j, k}$ be the optimal number of changes to be made to this VM count to service all IW requests in the next hour.

\textit{Servicing Interactive Workload within each Region.} 
Say the forecasted rate of tokens to be served per second for an IW workload for model $i$ at region $j$ during each time window $w$  over the next decision making window of, say, 1~hour, is $\rho_{i,j,w}$.
Each model type in a region should be able to serve at least a fraction $0 < \epsilon \leq 1$ of it's peak future request load received from clients within its region in real-time. Excess load $(1-\epsilon)$ can be rerouted to other regions to reduce the number of model-instance changes needed.
\[ \sum_k (n_{i,j, k} + \delta_{i, j, k}) \times \theta_{i,k} \geq \max_{w}{\ \epsilon \times \rho_{i,j,w}} \ \forall i, j \]

\textit{Servicing Interactive Workloads across all Region.} 
Next, we ensure that all IW requests for each model $i$ received from across all regions $j$ can cumulatively be processed using its model instances present across all region, with rerouting.
\[\sum_{j} \sum_k (n_{i, j, k} + \delta_{i, j, k}) \times \theta_{i, k}\geq\max_{w}\sum_{j}\rho_{i,j,w} \ \forall i\]

\textit{Non-negative number of instances.} We should never deallocate more models than are allocated, $\delta_{i, j} \geq -n_{i, j}$.


\para{Objective} We minimize the wasted resource overheads when provisioning VMs and instances required to support IW workloads while maintaining their SLAs. We incur two overheads when provisioning a new model instance: (i) VM start up cost to instantiate a new VM ($\gamma$), and (ii) the deployment cost ($\mu$) when loading the model and its weights on a VM, when we have acquired and are paying for the VM but are unable to use it yet to serve requests. This makes acquiring new VMs less attractive than spot instances. 
\[ \gamma = \sum_{k}\Big(\alpha_{k} \times \sum_{i, j} \delta_{i, j, k} \Big) \]
\[ \mu = \sum_{k}\sum_{i}\sum_{j}\big(\sigma_{i, k} \times \max(0, \delta_{i, j, k}) \big) \]
\[ \textit{The objective is~~~~} \arg \min (\gamma + \mu)\]

% \ysnote{utility does not enter the picture at all. Is it worth reporting utility in previous bar plots in motivation \ref{fig:motivation-utilization}?}

