
\section{Experimental Details}
% \section{Appendix}
  % \begin{itemize}
  %       \item analyse EDC vs ofcre, for graph
  %       \item Prompts, results
  %       \item Data augmentation with k=1,3,5, 7?
  %   \end{itemize}
    
\subsection{Few-shot Continual Relation Extraction (FCRE)}
\subsubsection{Benchmark datasets}
\label{app:data}
Our experiments for the FCRE scenario utilize two benchmark datasets:

\begin{itemize}
    \item \textbf{FewRel} \citep{han-etal-2018-fewrel}: This dataset comprises 100 relations with 70,000 samples. Following \citet{DBLP:conf/acl/QinJ22}, we employ a configuration of 80 relations, partitioned into 8 tasks, each containing 10 relations (10-way). The initial task, $\mathcal{T}^1$, includes 100 samples per relation, while subsequent tasks are structured as few-shot tasks under 5-shot settings.
\begin{table}[h]
    \centering
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{lcc}
        \toprule
        & \textbf{Train} & \textbf{Test} \\
        \midrule
        Total samples of DR & 1350 & 8000 \\
        Total samples of UR & 7431 & 43175 \\
        Average entities per sample & 4.21 & 4.20 \\
        \bottomrule
    \end{tabular}
    }
    \caption{Fewrel Dataset with UR Statistics}
    \label{tab:first1}
\end{table}

    \item \textbf{TACRED} \citep{zhang-etal-2017-position}: This dataset encompasses 42 relations with 106,264 samples extracted from Newswire and Web documents. Consistent with \citep{DBLP:conf/acl/QinJ22}, we exclude instances labeled as ``no\_relation'' and distribute the remaining 41 relations across 8 tasks. The first task, $\mathcal{T}^1$, comprises 6 relations with 100 samples each, while subsequent tasks involve 5 relations (5-way) in 5-shot configurations.
    % \item Data tacred with UR
\begin{table}[h]
    \centering
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{lcc}
        \toprule
        & \textbf{Train} & \textbf{Test} \\
        \midrule
        Total samples of DR & 775 & 2122 \\
        Total samples of UR & 5173 & 15152 \\
        Average entities per sample & 4.43 & 4.61 \\
        \bottomrule
    \end{tabular}
    }
    \caption{Tacred Dataset with UR Statistics}
    \label{tab:second2}
\end{table}
    
\end{itemize}

In addition to adding samples and their corresponding entities with an undetermined relation, we also incorporate this description into the training data.

Definition of \textbf{Undetermined relation}: This relation is used when the relationship between entities is either not applicable or unknown. It serves as a default category when no other relation type clearly applies or when there is insufficient information to determine the relationship.


\subsubsection{Example Sample in Dataset}
\label{app:example}
\textbf{Example Sample:}  
Spearhafoc was succeeded by William the Norman and was the last Bishop of London of English descent for an extended period, likely until Roger Niger's appointment in 1228.

\textbf{Determined Relation:}  
The entities \textit{Spearhafoc} and \textit{Bishop of London} are determined to have the relation type: \textit{Location of Formation}, as per the dataset. \\
\textbf{Undetermined Relation} is one of two types below:
\begin{itemize}
% \textbf{Uncertain Relation:}  
\item \textbf{None of the Above (NOTA)}: The relation between \textit{Roger Niger} and \textit{Bishop of London} is classified as \textit{"Appointed Location"}.

\item \textbf{No Relation (NA):}  
The entities \textit{Roger Niger} and \textit{Spearhafoc} do not share any directly applicable relation.
\end{itemize}
\subsection{Baselines}
\label{sec:appendix_baseline1}

This study evaluates our approach against state-of-the-art methods in FCRE and FCED. The selected baselines are as follows:

\subsubsection{FCRE Baselines}
\begin{itemize}
    \item \textbf{SCKD} \citep{DBLP:conf/acl/WangWH23} introduces a structured knowledge distillation approach aimed at retaining information from past tasks. This method incorporates contrastive learning along with pseudo samples to improve the differentiation capability of relation representations.
    
    \item \textbf{ConPL} \citep{DBLP:conf/acl/ChenWS23} consists of three key components: a prototype-based classification module, a memory-enhanced mechanism, and a consistency learning module that helps maintain distributional stability while reducing forgetting. Moreover, ConPL leverages prompt learning to refine representation learning and applies focal loss to minimize ambiguity among similar classes.

    \item \textbf{CPL} \citep{DBLP:conf/coling/MaHL024} proposes a framework that employs prompts to enhance generalization across categories and adopts margin-based contrastive learning to manage difficult samples, effectively addressing catastrophic forgetting and overfitting. Additionally, CPL integrates a memory augmentation technique using ChatGPT to generate diverse samples, further alleviating overfitting in low-resource FCRE settings.

    To perform the ablation study presented in Table ...

    \item \textbf{CPL+MI} \citep{tran-etal-2024-preserving} (Mutual Information Maximization) serves as an enhancement to existing baselines by utilizing the often-overlooked language model heads to retain prior knowledge from pre-trained backbones and improve representation learning. This is accomplished by maximizing the mutual information between the latent representations from the language model head branch and the primary classifier branch.
\end{itemize}

\subsubsection{Open Information Extraction baselines}
EDC \citep{zhang-soh-2024-extract}, Extract-Define-Canonicalize, is a novel framework designed for knowledge graph construction (KGC) using large language models (LLMs). KGC is the task of creating knowledge graphs, which are structured representations of knowledge that organize interconnected information through graph structures, with entities and relations represented as nodes and edges. The EDC framework addresses the challenges of using LLMs for KGC, particularly in scenarios with large or unavailable schemas.

The key idea behind EDC is to \textbf{break down KGC into three phases}:

\begin{enumerate}
    \item \textbf{Open Information Extraction (OIE)}: 
    This phase involves extracting entity-relation triplets from the input text without adhering to a pre-defined schema. Large Language Models (LLMs) are used to identify and extract these triplets. For example, given the following text:
        "Alan Shepard was born on Nov 18, 1923 and selected by NASA in 1959. He was a member of the Apollo 14 crew."


    The extracted triplets might be:
    \begin{itemize}
        \item ("Alan Shepard", "bornOn", "Nov 18, 1923")
        \item ("Alan Shepard", "participatedIn", "Apollo 14")
    \end{itemize}
    
    \item \textbf{Schema Definition}: 
    In this phase, LLMs generate natural language definitions for each relation type identified in the extraction phase. For the example above, definitions for ``bornOn'' and ``participatedIn'' would be generated.

    \item \textbf{Schema Canonicalization}: 
    This phase refines the open knowledge graph into a canonical form by eliminating redundancies and ambiguities. This is done either through \textit{target alignment} (with an existing target schema) or \textit{self-canonicalization} (without a target schema). In target alignment, the system identifies the most closely related components within the target schema for each element, and LLMs assess the feasibility of each potential transformation. For instance,  LLMs will replace ``participatedIn'' in the retrieved closest schema (``mission'', ``season'', etc.) to ``mission''. In self-canonicalization, the system consolidates semantically similar schema components, standardizing them to a singular representation.
\end{enumerate}

To further improve performance, the EDC framework can be iteratively refined with a \textbf{Schema Retriever}. The Schema Retriever is a trained model that retrieves schema components relevant to the input text, akin to retrieval-augmented generation. This process involves constructing a ``hint'' for the extraction phase, which includes candidate entities and relations extracted in previous iterations.

The benefits of EDC include its \textbf{flexibility, performance, and ability to handle large schemas or situations where no pre-defined schema is available}. Experiments have demonstrated that EDC can extract higher-quality knowledge graphs compared to state-of-the-art methods. EDC is also more general compared to existing canonicalization methods because it works whether a target schema is provided or not. Instead of using static external sources like WordNet, EDC utilizes contextual and semantically-rich side information generated by LLMs. Furthermore, by allowing the LLMs to verify if a transformation can be performed, EDC alleviates the over-generalization issue faced by previous methods.

There are several limitations that could be addressed in future works. These include incorporating an entity de-duplication mechanism, improving the components of EDC (such as the schema retriever), testing smaller open-source models' performance on the other tasks, and reducing the cost of EDC.



\subsection{Training Configurations}
This section outlines the optimal hyperparameter configurations utilized across our experimental framework. Through comprehensive Grid Search optimization, we identified the optimal values for loss factors $\alpha_{x}$, $\alpha_{xd}$, and $\alpha_{xc}$ by exploring the range $[0.5, 1.0, 2.0, 3.0]$. Table \ref{tab:hyperparameters_cpl1} details the specific parameter settings for each model variant.

% For inference, we found that when testing without the UR label, the formula described in \eqref{eq:alternative} performs better. Conversely, for cases involving UR prediction, \eqref{eq:primary} should be used.

% FOR OUR
\begin{table}[ht]
 \resizebox{\columnwidth}{!}{%
    \begin{tabular}{lc}
        \hline
        \textbf{Hyperparameter} & \textbf{Value} \\
        \hline
        Number of training epochs & 10 \\
        Memory training epochs & 10 \\
        Learning rate & $1 \times 10^{-5}$ \\
        \hline
        Encoder output dimension & 768 \\
        BERT input maximum sequence length & 256 \\
        % Margin ($m$) for Margin Loss & 1.0 \\ 
        \hline
        $\alpha_x$ & 1.0 \\
        $\alpha_{xd}$ & 2.0 \\
        $\alpha_{xc}$ & 2.0 \\
        \hline
    \end{tabular}
    }
    \caption{Hyperparameter configuration for OFCRE}
    \label{tab:hyperparameters_cpl1}
\end{table}
General process of inference in OFCRE using OIE:
\begin{figure}[ht]
    \centering
    \includegraphics[width=\columnwidth]{imgs/nota.pdf}
    \caption{In case the labels of the pair of entities are not learned yet, we can know whether the pair of entities has a meaningful relationship or not.}
    \label{fig:infer}
\end{figure}
% FOR OTHER BASELINES \\
% FOR EDC
\begin{table*}[ht]
\centering
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{lllllllll}
\toprule
\multirow{2}{*}{Method} & \multicolumn{8}{c}{Tasks} \\
\cmidrule{2-9}
& $\mathcal{T}^1$ & $\mathcal{T}^2$ & $\mathcal{T}^3$ & $\mathcal{T}^4$ & $\mathcal{T}^5$ & $\mathcal{T}^6$ & $\mathcal{T}^7$ & $\mathcal{T}^8$  \\ 
\toprule
\multicolumn{9}{c}{\textbf{FewRel} \textit{(10-way--5-shot)}} \\
\midrule
\method & $91.02_{\pm 0.90}$ & $\mathbf{85.36_{\pm 1.91}}$ & $\mathbf{79.83_{\pm 1.68}}$ & $\mathbf{76.46_{\pm 1.60}}$ & $\mathbf{74.69_{\pm 2.73}}$ & $\mathbf{72.08_{\pm 2.01}}$ & $\mathbf{69.60_{\pm 1.44}}$ & $\mathbf{67.62_{\pm 0.95}}$ \\

\quad w/o $\mathcal{L}_{HSMT}$ & ${91.23_{\pm 0.50}}$ & $\underline{84.73_{\pm 2.65}}$ & $\underline{79.30_{\pm 2.15}}$ & $\underline{76.28_{\pm 1.96}}$ & \underline{$73.68_{\pm 2.62}$} & \underline{$71.07_{\pm 2.43}$} & $\underline{68.92_{\pm 1.20}}$ & ${65.16_{\pm 0.41}}$ \\

\quad w/o $\mathcal{L}_{WMI_{SD}}$ & $\mathbf{92.88_{\pm 0.87}}$ & $84.09_{\pm 1.77}$ & $78.4_{\pm 1.83}$ & $74.29_{\pm 1.62}$ & $71.25_{\pm 3.25}$ & $68.3_{\pm 3.07}$ & $66.02_{\pm 1.67}$ & $63.75_{\pm 0.86}$ \\

\quad w/o $\mathcal{L}_{WMI_{SC}}$ & \underline{$91.57_{\pm 0.78}$} & {$84.19_{\pm 1.97}$} & {$79.24_{\pm 2.61}$} & {$75.17_{\pm 2.33}$} & ${73.59_{\pm 3.14}}$ & ${70.65_{\pm 2.39}}$ & {$68.57_{\pm 1.40}$} & \underline{$66.95_{\pm 0.25}$} \\
\toprule
\multicolumn{9}{c}{\textbf{TACRED} \textit{(5-way-5-shot)}} \\
\midrule

\method & $85.23_{\pm 0.39}$ & $\mathbf{82.39_{\pm 2.78}}$ & $\mathbf{77.64_{\pm 3.39}}$ & $\mathbf{74.67_{\pm 3.91}}$ & ${71.08_{\pm 5.83}}$ & $\mathbf{70.79_{\pm 3.94}}$ & $\mathbf{68.91_{\pm 2.87}}$ & $\mathbf{67.8_{\pm 1.32}}$ \\

\quad w/o $\mathcal{L}_{HSMT}$ & $\mathbf{85.8_{\pm 0.64}}$ & ${81.22_{\pm 3.58}}$ & \underline{$77.07_{\pm 4.96}$} & \underline{$74.47_{\pm 3.56}$} & $\mathbf{71.95_{\pm 5.13}}$ & {$69.31_{\pm 3.28}$} & $\underline{68.58_{\pm 1.41}}$ & $67.10_{\pm 2.33}$ \\

\quad w/o $\mathcal{L}_{WMI_{SD}}$ & $85.49_{\pm 1.15}$ & $\underline{82.12_{\pm 2.85}}$ & $76.47_{\pm 3.39}$ & $73.98_{\pm 2.65}$ & $70.86_{\pm 3.04}$ & \underline{$70.51_{\pm 1.54}$} & $67.51_{\pm 2.35}$ & $\underline{67.35_{\pm 2.04}}$ \\

\quad w/o $\mathcal{L}_{WMI_{SC}}$ &$\underline{85.52_{\pm 0.77}}$ & $81.50_{\pm 4.15}$ & $75.32_{\pm 3.66}$ & $73.71_{\pm 3.78}$ & $\underline{71.11_{\pm 5.42}}$ & $69.40_{\pm 4.37}$ & {$67.11_{\pm 3.56}$} & {$66.40_{\pm 1.86}$} \\


\bottomrule

\end{tabular}%}
\end{adjustbox}
\caption{Ablation study (\%) of loss functions for our model tested \textbf{without undetermined relation}. The best results are in \textbf{bold}, while the second highest scores are \underline{underlined}}
\label{table:ablation1}
\end{table*}


\begin{table*}[ht]
\centering
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{lllllllll}
\toprule
\multirow{2}{*}{Method} & \multicolumn{8}{c}{Tasks} \\
\cmidrule{2-9}
& $\mathcal{T}^1$ & $\mathcal{T}^2$ & $\mathcal{T}^3$ & $\mathcal{T}^4$ & $\mathcal{T}^5$ & $\mathcal{T}^6$ & $\mathcal{T}^7$ & $\mathcal{T}^8$  \\ 
\toprule
\multicolumn{9}{c}{\textbf{FewRel} \textit{(10-way--5-shot)}} \\
\midrule
\method & $\underline{64.98_{\pm 1.31}}$ & $\mathbf{51.80_{\pm 3.72}}$ & $\mathbf{46.64_{\pm 2.32}}$ & $\mathbf{45.11_{\pm 2.34}}$ & $\mathbf{43.06_{\pm 2.68}}$ & $\mathbf{40.44_{\pm 1.33}}$ & $\mathbf{38.92_{\pm 0.84}}$ & $\mathbf{37.06_{\pm 0.42}}$ \\

\quad w/o $\mathcal{L}_{HSMT}$ & ${61.75_{\pm 0.62}}$ & ${49.8_{\pm 4.05}}$ & ${44.18_{\pm 2.56}}$ & ${40.52_{\pm 3.07}}$ & {$40.19_{\pm 2.71}$} & {$37.39_{\pm 1.42}$} & ${35.74_{\pm 1.48}}$ & ${33.39_{\pm 0.70}}$ \\

\quad w/o $\mathcal{L}_{WMI_{SD}}$ & $\mathbf{65.52_{\pm 0.60}}$ & $50.2_{\pm 3.62}$ & $\underline{45.46_{\pm 1.67}}$ & $\underline{44.73_{\pm 2.68}}$ & $\underline{42.30_{\pm 2.76}}$ & $39.03_{\pm 1.71}$ & $36.65_{\pm 1.49}$ & $\underline{35.77_{\pm 0.98}}$ \\

\quad w/o $\mathcal{L}_{WMI_{SC}}$ & $63.28_{\pm 0.43}$ & \underline{$50.72_{\pm 3.95}$} & {$44.11_{\pm 2.25}$} & {$43.53_{\pm 2.60}$} & ${41.13_{\pm 2.71}}$ & $\underline{39.88_{\pm 2.17}}$ & \underline{$37.92_{\pm 0.85}$} & {$35.30_{\pm 1.40}$} \\
\toprule
\multicolumn{9}{c}{\textbf{TACRED} \textit{(5-way-5-shot)}} \\
\midrule

\method & $\mathbf{65.99_{\pm 0.99}}$ & $\underline{53.08_{\pm 1.71}}$ & $\mathbf{45.52_{\pm 0.11}}$ & $\mathbf{41.99_{\pm 5.31}}$ & $\mathbf{37.79_{\pm 5.64}}$ & $\mathbf{35.73_{\pm 3.03}}$ & $\mathbf{33.20_{\pm 2.29}}$ & $\mathbf{32.15_{\pm 1.48}}$ \\

\quad w/o $\mathcal{L}_{HSMT}$ & ${61.42_{\pm 2.71}}$ & ${49.29_{\pm 3.31}}$ & {$42.81_{\pm 4.18}$} & {$36.34_{\pm 3.34}$} & {$33.02_{\pm 3.03}$} & {$30.30_{\pm 1.25}$} & $29.11_{\pm 0.85}$ & $27.20_{\pm 1.36}$ \\

\quad w/o $\mathcal{L}_{WMI_{SD}}$ & $62.66_{\pm 0.57}$ & $52.55_{\pm 2.97}$ & $43.41_{\pm 2.07}$ & $\underline{41.26_{\pm 3.31}}$ & $36.79_{\pm 3.53}$ & $\underline{34.85_{\pm 3.07}}$ & $32.46_{\pm 1.12}$ & $31.52_{\pm 1.09}$ \\

\quad w/o $\mathcal{L}_{WMI_{SC}}$ &$\underline{64.34_{\pm 0.60}}$ & $\mathbf{53.92_{\pm 1.69}}$ & $\underline{44.84_{\pm 1.66}}$ & $40.41_{\pm 4.01}$ & $\underline{37.15_{\pm 5.09}}$ & $34.29_{\pm 2.97}$ & \underline{$32.88_{\pm 2.08}$} & \underline{$31.54_{\pm 1.39}$} \\


\bottomrule

\end{tabular}%}
\end{adjustbox}
\caption{Ablation study (\%) of loss functions for our model tested \textbf{with undetermined relation}. The best results are in \textbf{bold}, while the second highest scores are \underline{underlined}}
\label{table:ablation2}
\end{table*}



\begin{table*}[ht]
\centering
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{lllllllll}
\toprule
\multirow{2}{*}{Method} & \multicolumn{8}{c}{Tasks} \\
\cmidrule{2-9}
& $\mathcal{T}^1$ & $\mathcal{T}^2$ & $\mathcal{T}^3$ & $\mathcal{T}^4$ & $\mathcal{T}^5$ & $\mathcal{T}^6$ & $\mathcal{T}^7$ & $\mathcal{T}^8$  \\ 
\toprule
\multicolumn{9}{c}{\textbf{FewRel} \textit{(10-way--5-shot)}} \\
\midrule
\method + OIE & $\underline{69.23_{\pm 0.53}}$ & $\mathbf{58.23_{\pm 3.58}}$ & $\mathbf{52.94_{\pm 2.84}}$ & $\mathbf{51.17_{\pm 2.89}}$ & $\mathbf{49.31_{\pm 2.68}}$ & $\mathbf{46.57_{\pm 1.34}}$ & $\mathbf{45.00_{\pm 0.88}}$ & $\mathbf{43.11_{\pm 0.87}}$ \\

\quad w/o $\mathcal{L}_{HSMT}$ & ${67.33_{\pm 0.69}}$ & ${57.07_{\pm 3.78}}$ & ${51.40_{\pm 2.68}}$ & ${47.97_{\pm 2.85}}$ & {$47.22_{\pm 2.65}$} & {$44.31_{\pm 1.48}$} & ${42.7_{\pm 1.28}}$ & ${40.5_{\pm 0.53}}$ \\

\quad w/o $\mathcal{L}_{WMI_{SD}}$ & {$\mathbf{69.43_{\pm 0.48}}$} & $\underline{57.77_{\pm 3.46}}$ & $\underline{52.90_{\pm 1.71}}$ & $\underline{50.03_{\pm 2.64}}$ & $\underline{48.56_{\pm 2.65}}$ & $\underline{45.42_{\pm 1.82}}$ & $\underline{44.03_{\pm 1.48}}$ & $\underline{42.26_{\pm 0.87}}$ \\

\quad w/o $\mathcal{L}_{WMI_{SC}}$ & $68.07_{\pm 0.18}$ & {$56.94_{\pm 3.64}$} & {$50.45_{\pm 2.39}$} & {$49.94_{\pm 2.54}$} & ${48.52_{\pm 2.79}}$ & ${45.31_{\pm 2.22}}$ & {$43.46_{\pm 0.90}$} & {$41.92_{\pm 1.12}$} \\
\toprule
\multicolumn{9}{c}{\textbf{TACRED} \textit{(5-way-5-shot)}} \\
\midrule

\method + OIE & $\mathbf{67.51_{\pm 0.81}}$ & $\mathbf{59.14_{\pm 1.59}}$ & $\mathbf{52.23_{\pm 0.85}}$ & $\mathbf{48.85_{\pm 5.82}}$ & $\mathbf{43.26_{\pm 5.38}}$ & $\mathbf{41.28_{\pm 3.31}}$ & $\mathbf{38.87_{\pm 2.32}}$ & $\mathbf{37.79_{\pm 1.58}}$ \\

\quad w/o $\mathcal{L}_{HSMT}$ & ${67.26_{\pm 1.17}}$ & ${57.09_{\pm 2.33}}$ & {$50.84_{\pm 3.47}$} & {$45.03_{\pm 4.23}$} & {$41.56_{\pm 4.54}$} & {$39.08_{\pm 1.96}$} & $37.55_{\pm 0.95}$ & $35.80_{\pm 1.77}$ \\

\quad w/o $\mathcal{L}_{WMI_{SD}}$ & $67.05_{\pm 0.69}$ & $57.45_{\pm 2.56}$ & $\underline{51.70_{\pm 1.70}}$ & $\underline{47.89_{\pm 2.96}}$ & $\underline{42.93_{\pm 4.17}}$  & $\underline{42.26_{\pm 2.87}}$ & $\underline{39.24_{\pm 1.70}}$ & $\underline{36.79_{\pm 1.17}}$\\

\quad w/o $\mathcal{L}_{WMI_{SC}}$ &$\underline{67.36_{\pm 0.36}}$ & $\underline{58.07_{\pm 2.00}}$ & $50.85_{\pm 1.68}$ & $46.73_{\pm 4.16}$ & $41.10_{\pm 5.33}$ & $41.03_{\pm 2.92}$ & {$37.54_{\pm 2.62}$} & {$36.35_{\pm 1.61}$} \\


\bottomrule

\end{tabular}%}
\end{adjustbox}
\caption{Ablation study (\%) of loss functions for our model with OIE tested \textbf{with undetermined relation}. The best results are in \textbf{bold}, while the second highest scores are \underline{underlined}}
\label{table:ablation3}
\end{table*}

\section{Ablation study}
The ablation study highlights the critical role of each loss component in \textbf{OFCRE}'s performance. We further analyze the contributions of the \textbf{Hard Soft Margin Triplet Loss ($\mathcal{L}_{HSMT}$)}, \textbf{Weighted Mutual Information Loss for raw descriptions ($\mathcal{L}_{WMI_{SD}}$)}, and \textbf{Weighted Mutual Information Loss for candidate descriptions ($\mathcal{L}_{WMI_{SC}}$)} across tasks and datasets.

% \subsubsection*{Key Observations}
\begin{itemize}
    \item \textbf{Impact of $\mathcal{L}_{HSMT}$}: 
    Removing $\mathcal{L}_{HSMT}$ leads to a $\sim$2--4\% drop in accuracy on both datasets. For instance, on \textbf{TACRED} (Table~\ref{table:ablation1}), Task $\mathcal{T}^8$ performance declines from \SI{67.8}{\%} to \SI{65.16}{\%} without UR. This loss enforces margin-based separation between hardest positive and negative pairs, critical for distinguishing semantically similar relations.
    
    \item \textbf{Role of $\mathcal{L}_{WMI_{SD}}$}: 
    Excluding $\mathcal{L}_{WMI_{SD}}$ results in gradual performance decay, with a $\sim$3--5\% decline by $\mathcal{T}^8$ on \textbf{FewRel} (Table~\ref{table:ablation1} and Table~\ref{table:ablation2}). This loss aligns sample representations with raw relation descriptions (e.g., \textit{"headquarters location: administrative center"}), stabilizing knowledge retention.
    
    \item \textbf{Significance of $\mathcal{L}_{WMI_{SC}}$}: 
    $\mathcal{L}_{WMI_{SC}}$ is critical for handling \textbf{undetermined relations (UR)}. On \textbf{TACRED} with UR (Table~\ref{table:ablation2}), removing it causes a $\sim$5\% drop in $\mathcal{T}^8$ (\SI{32.15}{\%} $\rightarrow$ \SI{31.54}{\%}). This loss leverages OIE-generated candidate descriptions (e.g., \textit{"was born in"} for \textit{"person place of birth"}) to generalize to unseen relations.
\end{itemize}

% \subsubsection*{Dataset-Specific Trends}
\begin{itemize}
    \item \textbf{FewRel}: Dominated by $\mathcal{L}_{HSMT}$ and $\mathcal{L}_{WMI_{SD}}$, as predefined relations are structured. UR detection relies less on OIE candidates here.
    \item \textbf{TACRED}: $\mathcal{L}_{WMI_{SC}}$ plays a stronger role due to noisy, real-world text. UR labels often require contextual OIE descriptions for accurate classification.
\end{itemize}

% \subsubsection*{Variability Analysis}
% The standard deviations in Table~\ref{tab:ablation_no_ur} (e.g., \texttt{TACRED} $\mathcal{T}^2$: $\pm$\SI{7.38}{\%}) indicate that $\mathcal{L}_{\text{WMI-c}}$ stabilizes performance in dynamic scenarios. Without it, predictions become erratic, especially with abundant UR labels.

The joint optimization of $\mathcal{L}_{HSMT}$, $\mathcal{L}_{WMI_{SD}}$, and $\mathcal{L}_{WMI_{SC}}$ ensures a balance between \textit{discriminative power}, \textit{knowledge retention}, and \textit{adaptability to unseen relations}. Future work could explore:
\begin{itemize}
    \item Dynamic loss weighting (e.g., increasing $\mathcal{L}_{WMI_{SC}}$'s weight in later tasks).
    \item Reinforcement learning to prioritize underperforming components during training.
\end{itemize}
\label{sec:appendix_ablation1}
% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.49\textwidth]{imgs/ablation.pdf}
%     \caption{Ablation study on loss function. Accuracy results without (w/o) each loss component across eight tasks. More details are in Table \ref{table:ablation}.}
%     \label{fig:ablation}
% \end{figure}




% \subsection{Additional Experimental Results}



\begin{table*}[ht]
    \centering
    \begin{mdframed}[linewidth=1pt] % Outer frame
        \textbf{Prompt for generating an expanded relation description with examples from original description} \\
        \hrulefill
        You are an experienced data scientist working on a relation extraction task. \\
        Your objective is to take a given relation and its brief description and produce a more detailed explanation. Additionally, you should generate three diverse sentence examples demonstrating the relation in use. \\
        The relation is: headquarters location \\
        The description is: location where an organization's central administration is based. \\
        Please provide 2 distinct (relation description, examples) pairs. \\
        Your response:
    \end{mdframed}

    \vspace{5pt} % Adds space between prompt and output

    \begin{mdframed}[linewidth=1pt] % Outer frame for output
        \textbf{Output:} \\
        \hrulefill
        This relation indicates the primary location where an organization, corporation, or institution's central administrative functions are managed. The headquarters serves as the main hub for decision-making, strategic planning, and coordination of business operations.\\
        Examples: \\
        - The headquarters of Apple Inc. is located in Cupertino, California, where key corporate decisions and product development take place. \\
        - The United Nations Headquarters is based in New York City, serving as the central meeting place for international diplomatic activities. \\
        - Toyota's global headquarters is situated in Toyota City, Japan, overseeing its worldwide automobile manufacturing and business operations. \\

        \vspace{5pt} % Adds spacing before the next sample

        This relation describes the official site of an organization's main offices, which serves as the administrative center and often houses executives and key departments.\\
        Examples: \\
        - Google's headquarters, known as the Googleplex, is in Mountain View, California, hosting thousands of employees working on technology and innovation. \\
        - The European Central Bank has its headquarters in Frankfurt, Germany, where major financial policies for the Eurozone are formulated. \\
        - The headquarters of Amazon is located in Seattle, Washington, guiding the company's global e-commerce and cloud computing strategies.
    \end{mdframed}

    \caption{Example of generating an expanded relation description with examples from original description}
    \label{tab:relation_description_prompt1}
\end{table*}


\section{Prompt and Output Example}
\label{app:prompt}
\begin{table*}[ht]
    \centering
    \begin{mdframed}[linewidth=1pt] % Outer frame
        \textbf{Prompt for Open Information Extraction} \\
        \hrulefill
Given a piece of text, two entities subject, object (not ordered) and corresponding relation type between two entities, extract the relation trigger in the form of [Subject, Relation, Object] from it. If there is not any relation, relation is null.
Here are some examples: \\
\\
Example 1: \\
Text: "he passed away on saturday ."\\
Subject, Object entities(not ordered): "he", "saturday" \\
% Relation type: "person date of death" \\
Complete triplets: ["he", "passed away on", "saturday"] \\
\\
Example 2: \\
Text: "as a substantial shareholder in cnac's subsidiary air china, cathay pacific said late monday it would give serious consideration to joining cnac and form a strategic partnership with china eastern." \\
Subject, Object entities(not ordered): "cnac", "cathay pacific" \\
% Relation type: "organization member of" \\
Complete triplets: ["cathay pacific", "a substantial shareholder", "cnac"] \\
\\
Now it's your turn! Please extract the relation from the following text: \\
Text: "Elon Musk founded SpaceX in 2002." \\
Subject, Object (not ordered): "Elon Musk", "SpaceX" \\
% Relation type: "organization founded" \\
Complete triplets: 
    \end{mdframed}

    \vspace{5pt} % Adds space between prompt and output

    \begin{mdframed}[linewidth=1pt] % Outer frame for output
        \textbf{Output:} \\
        \hrulefill
        % Extracted relation trigger: \\
      ["Elon Musk", "founded", "SpaceX"] \\
        
        % This relation represents the birth location of a person, establishing a connection between an individual and their place of birth.\\
        
        % \textbf{Additional Examples:} \\
        % - "Albert Einstein was born in Germany." → ["Albert Einstein", "was born in", "Germany"] \\
        % - "Marie Curie was born in Poland." → ["Marie Curie", "was born in", "Poland"] \\
        % - "Leonardo da Vinci was born in Vinci, Italy." → ["Leonardo da Vinci", "was born in", "Vinci, Italy"] \\
    \end{mdframed}

\caption{Prompt used for Open Information Extraction. During training, it generates a candidate triplet, whereas in testing, it returns only triplet with identified relationship. If no relationship exists (NA), the relation is set to null, e.g., ["Elon Musk", null, "SpaceX"].}
    \label{tab:prompt_stability2}
\end{table*}



\begin{table*}[ht]
    \centering
    \begin{mdframed}[linewidth=1pt] % Outer frame
        \textbf{Prompt for Relation Definition and Augmentation from Open Information Extraction} \\
        \hrulefill
Define the relationship in a relational triplet extracted from a given text and provide 3 sentence examples of the relationship.
You must generate 2 diverse samples of (relation definition, example) pairs for the relationship. \\

Example 1: \\
Text: "Albert Einstein was born in Germany in 1879." \\
Triplet: ["Albert Einstein", "was born in", "Germany"] \\
Relation type: "person place of birth" \\
Definitions and examples of "was born in": \\

\textbf{Sample 1:}  
\begin{quote}
\{
    "definition": "The relationship between a person and the place where they were born.", \\
    "examples": [ \\
    \quad "Isaac Newton was born in England in 1643.", \\
    \quad "Marie Curie was born in Warsaw, Poland.", \\
    \quad "Leonardo da Vinci was born in Vinci, Italy." \\
    ]
\}
\end{quote}

Now it's your turn! Please define the relationship in the following relational triplet: \\
Text: "Elon Musk founded SpaceX in 2002." \\
Triplet: ["Elon Musk", "founded", "SpaceX"] \\
Relation type: "organization founder" \\
Definitions and examples of "founded":
    \end{mdframed}

    \vspace{5pt} % Adds space between prompt and output

    \begin{mdframed}[linewidth=1pt] % Outer frame for output
        \textbf{Output:} \\
        \hrulefill
        
        \textbf{Sample 1:} \\
        \begin{quote}
        \{
            "definition": "The relationship between a person and an organization they established.", \\
            "examples": [ \\
            \quad "Bill Gates founded Microsoft in 1975.", \\
            \quad "Steve Jobs founded Apple in 1976.", \\
            \quad "Mark Zuckerberg founded Facebook while studying at Harvard." \\
            ]
        \}
        \end{quote}

        \vspace{5pt} % Adds space between samples

        \textbf{Sample 2:} \\
        \begin{quote}
        \{
            "definition": "The connection between an individual and the company or organization they initiated, often as its creator or co-founder.", \\
            "examples": [ \\
            \quad "Larry Page and Sergey Brin founded Google in 1998.", \\
            \quad "Jeff Bezos founded Amazon in 1994.", \\
            \quad "Jack Ma founded Alibaba in 1999." \\
            ]
        \}
        \end{quote}
    \end{mdframed}

    \caption{Candidate Description Definition and Augmentation}
    \label{tab:prompt_stability3}
\end{table*}