\section{Web AI Agent System}\label{sec:webagent_system}


A Web AI agent system, powered by an LLM, operates autonomously by continuously interacting with its environment through an iterative loop of actions and feedback \citep{yao2022react, sumers2023cognitive, yang2023language, fang2024llm, zhang2024cybench}. 
With well-structured abstractions that bridge digital environments and LLMs, these agents can seamlessly translate observations into LLM-readable inputs and convert LLM-generated outputs into executable actions. 
These connection components between the web browser and the LLM allow  the LLM to autonomously generate meaningful actions and produce tangible outcomes within the system. 
Previous work highlights the essential role of Web AI agents in enhancing LLM performance across diverse environments. \citep{yang2024swe, yao2024taubenchbenchmarktoolagentuserinteraction}. 


To assess Web AI agent vulnerabilities, we follow the LLM agent workflow, OpenHands \citep{openhands}, formerly known as OpenDevin \citep{wang2024opendevin}. OpenHands is a flexible AI agent platform widely used in benchmarks \citep{xu2024theagentcompanybenchmarkingllmagents}, prior research \citep{pan2024trainingsoftwareengineeringagents,kumar2024refusal,zhuge2024agentasajudgeevaluateagentsagents}, and the open-source community. 
The insights from our study are applicable to other frameworks as well. Specifically, Web AI agent systems with an observation processing module \citep{shen2024scribeagentspecializedwebagents}, action tools \citep{debenedetti2024agentdojo}, and actions transformation module for a web-executable format \citep{su2025learnbyinteractdatacentricframeworkselfadaptive} shares their core components with this study, indicating generalizability of our conclusions.

\subsection{How A Web AI Agent System Works}
A Web AI agent begins by observing both the user's request and the current environment (e.g., the layout of a webpage). 
It then translates this information into structured inputs that the LLM can interpret. 
The LLM processes these inputs and generates corresponding actions for the agent to execute. 
The system applies these outputs as actionable commands, modifying the environment and generating new observations for the next iteration. 
This cycle repeats until the agent successfully completes its task (i.e., reaches a specified goal) or exceeds a specific predefined iteration limit.

Unlike a standalone LLM, which passively generates text responses, a Web AI agent actively interacts with its environment, bridging abstract reasoning with practical execution. 
For example, when navigating a web interface, the agent can interpret page content, select relevant actions (e.g., clicking buttons or entering text), and adapt its strategy based on real-time feedback from the environment.



\begin{figure}[t]  
    \centering
    \includegraphics[width=1.\textwidth]{\fighome/updated_final_fig_icon.png} 
    \caption{\textbf{An overview of the component differences between the Web Agent framework and standalone LLMs and their impact on Vulnerability rates.} (a) Users interacting with LLMs. (b) Users interacting with the Web Agent, with colors highlighting Factor 1, 2, and 3, illustrating key component differences grouped by categories (More details in Section \ref{sec:System Components}, \ref{sec:Our Hypothesis}) (c) A study analyzing Clear Denial and Vulnerability rate changes through factor ablation and integration. The results indicate that incorporating more agent components increases vulnerabilities compared to the standalone LLM. The changes in the Clear Denial rate(\%) help quantify the vulnerabilities introduced by each component. (See Section \ref{sec:results} for more factors and experimental details.)}\label{llm_framework} 
\end{figure}


\subsection{System Components of the Web AI Agent}
\label{sec:System Components}
To ensure seamless integration with dynamic web environments, a Web AI agent system consists of several key components, broadly categorized into the LLM and its supporting modules, as illustrated in Fig. \ref{llm_framework}. The process begins with the \textit{Goal Preprocessing} module,
which paraphrases user requests before incorporating them into the LLM’s system prompt (\colorbox{Factor1-blue}{blue box}). 
Simultaneously, the agent receives information about its predefined \textit{Action Space} and the execution constraints, which are also included in the system prompt (\colorbox{Factor2-yellow}{yellow box}).


Another critical component is the \textit{Event Stream}, which maintains the history of actions, observations, and metadata, enabling continuous interaction with the environment (\colorbox{Factor3-purple}{red box}). 
This allows the agent to track environmental changes and adapt its behavior accordingly. 
The system processes observations from the environment and integrates them into the user prompt, which also includes structured information about available actions (e.g., Accessibility Tree \citep{openhands, Mozilla}).
Additionally, the user prompt retains records of the agent’s previous actions, providing contextual awareness to guide subsequent decisions. 

Notably, Web AI agents are often evaluated using mock-up websites rather than real-world webpages---a common practice in recent studies and benchmarks \citep{yao2022webshop, zhou2023webarena, kumar2024refusal, yao2024taubenchbenchmarktoolagentuserinteraction}.
This reliance on artificial environments may introduce limitations in assessing real-world robustness and security risks.













