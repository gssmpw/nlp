\section{Related Works}
\subsection{Sheet Music Generation}

Sheet music generation has been widely studied, with a focus on encoding methods and composition modeling. Score Transformer \cite{suzuki2021score} introduces a tokenized representation for sheet music and applies it to piano music generation. Measure by Measure \cite{Yan-2024} models sheet music as grids of part-wise bars and employs hierarchical architectures for generation. Compared to the intricate representations used by the models above, ABC notation, a comprehensive text-based sheet music representation, simplifies encoding and facilitates composition modeling, gaining increasing adoption in recent research. The following models utilize the ABC notation: FolkRNN \cite{sturm2016music} and Tunesformer \cite{wu2023tunesformer}, specializing in folk melody generation; DeepChoir \cite{wu2023chord}, which generates choral music with chord conditioning; and MuPT \cite{qu2024mupt}, a large-scale pre-trained model for sheet music, which explores multitrack symbolic music generation. 

\subsection{Pre-training in Symbolic Music Generation}

The success of pre-training in NLP has inspired the application of this technique in symbolic music generation. LakhNES \cite{donahue2019lakhnes} enhances chiptune music generation by pre-training on the Lakh MIDI Dataset \cite{raffel2016learning}. MuseBERT \cite{wang2021musebert} adopts masked language modeling \cite{kenton2019bert}, while MelodyGLM \cite{wu2023melodyglm} implements auto-regressive blank infilling \cite{du2021glm} for generation. 
% PianoBART \cite{liang2024pianobart} applies the pre-training method of BART \cite{lewis2019bart} with an encoder-decoder architecture for piano music generation and understanding. 
MelodyT5 \cite{wu2024melodyt5} leverages multi-task learning \cite{raffel2020exploring}. These studies highlight the effectiveness of pre-training in enhancing music generation performance.

\subsection{Reinforcement Learning in Music Generation}

Reinforcement learning has long been recognized as a promising approach for enhancing the musicality of music generation models. It has been successfully applied in RL Tuner \cite{jaques2017tuning} for melody generation, RL-Duet \cite{jiang2020rl} for online duet accompaniment, RL-Chord \cite{ji2023rl} for melody harmonization, and \cite{guo2022fine} for multi-track music generation. However, these methods either base their rewards on music theory, which limits flexibility, or tailor them to specific music styles, hindering their generalization to a broader range of music generation tasks. To tackle this problem, MusicRL \cite{cideron2024musicrl} adopts the RLHF method with extensive human feedback to align the generated compositions with human preference.

\begin{figure*}[!ht]
    \centering
    \begin{minipage}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figure-representation.pdf}
        \caption*{(a)}
    \end{minipage}\hfill
    \begin{minipage}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figure-model.pdf}
        \caption*{(b)}
    \end{minipage}\hfill
    \caption{Data representation and model architecture of NotaGen. (a) An example of data representation for an excerpt from \textit{String Quartet in B-flat major, Hob.III:1} by Joseph Haydn using interleaved ABC notation. Bar annotations ``[r:]'' denote current/countdown bar indices, with gray bars representing omitted rests. Colored backgrounds delineate bar-stream patch boundaries. (b) The model architecture of NotaGen. After passing through the linear projection, bar-stream patches are processed by the patch-level decoder to generate features for a character-level decoder, which performs auto-regressive character prediction.}
    \label{fig:Figure 2}
\end{figure*}