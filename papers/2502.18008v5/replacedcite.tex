\section{Related Works}
\subsection{Sheet Music Generation}

Sheet music generation has been widely studied, with a focus on encoding methods and composition modeling. Score Transformer ____ introduces a tokenized representation for sheet music and applies it to piano music generation. Measure by Measure ____ models sheet music as grids of part-wise bars and employs hierarchical architectures for generation. Compared to the intricate representations used by the models above, ABC notation, a comprehensive text-based sheet music representation, simplifies encoding and facilitates composition modeling, gaining increasing adoption in recent research. The following models utilize the ABC notation: FolkRNN ____ and Tunesformer ____, specializing in folk melody generation; DeepChoir ____, which generates choral music with chord conditioning; and MuPT ____, a large-scale pre-trained model for sheet music, which explores multitrack symbolic music generation. 

\subsection{Pre-training in Symbolic Music Generation}

The success of pre-training in NLP has inspired the application of this technique in symbolic music generation. LakhNES ____ enhances chiptune music generation by pre-training on the Lakh MIDI Dataset ____. MuseBERT ____ adopts masked language modeling ____, while MelodyGLM ____ implements auto-regressive blank infilling ____ for generation. 
% PianoBART ____ applies the pre-training method of BART ____ with an encoder-decoder architecture for piano music generation and understanding. 
MelodyT5 ____ leverages multi-task learning ____. These studies highlight the effectiveness of pre-training in enhancing music generation performance.

\subsection{Reinforcement Learning in Music Generation}

Reinforcement learning has long been recognized as a promising approach for enhancing the musicality of music generation models. It has been successfully applied in RL Tuner ____ for melody generation, RL-Duet ____ for online duet accompaniment, RL-Chord ____ for melody harmonization, and ____ for multi-track music generation. However, these methods either base their rewards on music theory, which limits flexibility, or tailor them to specific music styles, hindering their generalization to a broader range of music generation tasks. To tackle this problem, MusicRL ____ adopts the RLHF method with extensive human feedback to align the generated compositions with human preference.

\begin{figure*}[!ht]
    \centering
    \begin{minipage}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figure-representation.pdf}
        \caption*{(a)}
    \end{minipage}\hfill
    \begin{minipage}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figure-model.pdf}
        \caption*{(b)}
    \end{minipage}\hfill
    \caption{Data representation and model architecture of NotaGen. (a) An example of data representation for an excerpt from \textit{String Quartet in B-flat major, Hob.III:1} by Joseph Haydn using interleaved ABC notation. Bar annotations ``[r:]'' denote current/countdown bar indices, with gray bars representing omitted rests. Colored backgrounds delineate bar-stream patch boundaries. (b) The model architecture of NotaGen. After passing through the linear projection, bar-stream patches are processed by the patch-level decoder to generate features for a character-level decoder, which performs auto-regressive character prediction.}
    \label{fig:Figure 2}
\end{figure*}