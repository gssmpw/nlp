\section{Introduction}
\label{sec:introduction}
There is no doubt that the recent rise of Large Code Models (\lcms) has revolutionized the automation of Software Engineering (SE) activities. 
To understand \emph{why}, \emph{when}, and \emph{how} this transformation occurred, we must narrow down our analysis to two key aspects that have contributed significantly to this revolution: (i) the availability of large, text-rich datasets, which provide the foundational knowledge required for training these models, and (ii) the increasing scale of deep learning (DL) architectures, with models now boasting trillions of parameters (\eg GPT-4 \cite{openai2024gpt4}). These two elements together have not only expanded the ability of models to embed and generalize vast amounts of programming knowledge but also facilitated their capacity to capture peculiar elements within the code, including intricate patterns, structures, and relationships. This duality (\ie large corpus and models) laid down the groundwork for achieving new levels of automation in SE, that were once thought to be beyond reach.


In this regard, tools, functioning as ``artificial collaborators'', such as GitHub Copilot \cite{copilot} and ChatGPT \cite{chatgpt}, have been effective in assisting and supporting developers in multiple phases of the software development lifecycle \cite{white2023chatgpt,nashid2023retrieval,watanabe2024use} as well as enhancing their understanding of code \cite{khojah2024beyond,dakhel2023github}.

While recent literature has presented the various and multifaceted possibilities of AI methods for software engineering activities \cite{hou2023large}, the ``no free lunch'' theorem reminds us that these benefits come at a cost. In particular, as models continue to grow in complexity and scale, the computational demands for training and maintaining them have become a significant burden \cite{stojkovic2024greener}. Also, concerns about bias, trustworthiness, and interpretability in large DL models such as \lcms, highlight a significant roadblock, preventing further advancement.
%as progress has stalled with stakeholders increasingly hindered by these challenges, preventing further advancement.

%Companies must now weigh the high expenses of developing and running their own models against the alternative of relying on third-party services, which carry potential risks to data privacy and misuse, as demonstrated in past instances \cite{}. 

%Consequently, organizations that want to benefit from these models but cannot outsource have few viable options. Developing an in-house AI-driven framework is one approach, but due to sustainability concerns, not every organization can afford to undertake such an effort. Additionally, smaller companies and research institutions may find it nearly impossible to compete in this landscape without collaborative or open-source solutions that alleviate these resource-intensive demands \cite{}



In this paper, we challenge the prevailing belief that scaling up models indefinitely is the path forward for every domain where AI-driven methods are deployed, including SE. 
To this end, Villalobos \etal \cite{villalobosposition} recently challenged the assumption that Large Language Models (\llms) can continue to learn effectively from existing data. They noted that society is approaching a point where the amount of relevant information available for \llms to learn from will be nearly exhausted, an event projected to occur between 2026 and 2032. In other words, we are nearing a critical threshold where the size of these models--counted in terms of parameters--could outstrip the volume of meaningful data available for processing.

Given this state of affairs, we ask: \emph{``What if we take a step back now to move two steps forward later?''} In other words, we have hit the limits of improvement through sheer model scaling, making it necessary to reconsider the dominant paradigm that has fueled innovations in the past decade.

With this in mind, our overarching goal is to \textbf{\emph{develop a new framework that harnesses the probabilistic capabilities of \llms while seamlessly integrating traditional symbolic rules}}. This combination enhances interpretability, ensures deterministic reasoning, and overcomes the inherent limitations of purely probabilistic approaches--that as seen--are increasingly plateauing.
%\cite{song2024goodbadgreedyevaluation} inherent in LLMs and, by extension, \lcms, while offering the added advantages of being extremely fast and nearly cost-free compared to DL-based data-driven solutions.}}
%\textbf{\emph{We believe that symbolic, heuristic-based techniques can offer a pivotal path forward, unlocking new potential to advance program comprehension activities}}


%As a first step towards this endeavor, we focus on program comprehension, a fundamental activity in software engineering that involves understanding the structure, functionality, and behavior of code to support various tasks, including, debugging, refactoring, and software maintenance. Hence, we propose the \textbf{N}eurosymbolic \textbf{P}rogram \textbf{C}omprehension (\framework) paradigm, which integrates \lcms with symbolic layers to offer comprehensive support for developers engaged in program comprehension activities.

%As a first step towards this endeavor, we focus on program comprehension, a fundamental activity in software engineering that involves understanding the structure, functionality, and behavior of code. This understanding is critical for various tasks, such as debugging, refactoring, software maintenance, and more specialized objectives as detecting insecure code, which relies on the ability to analyze and reason about code to identify vulnerabilities. To support these activities, we propose the \textbf{N}eurosymbolic \textbf{P}rogram \textbf{C}omprehension (\framework) paradigm, which integrates \lcms with symbolic layers, providing developers with robust tools for tackling program comprehension challenges, specifically in identifying and addressing insecure code.


As a first step towards this endeavor, we focus on \textit{vulnerability detection}, a critical task in software security that heavily depends on program comprehension. Understanding how code is structured and behaves is essential for identifying security weaknesses, as detecting vulnerabilities requires the ability to analyze and reason about code effectively. This understanding also plays a key role in related tasks such as debugging, refactoring, and secure software maintenance. To support these efforts, we propose the \textbf{N}eurosymbolic \textbf{P}rogram \textbf{C}omprehension (\framework) paradigm, which combines \lcms with symbolic reasoning to equip developers with more powerful tools for identifying and addressing insecure code.


%In this research, we present preliminary analyses and results aimed at developing the first \framework approach for insecure code detection \cite{zhou2019devign}. This approach is grounded on SHAP \cite{NIPS2017_Lundberg}, an interpretability method that generates local explanations for individual predictions (\eg determining whether a code component is insecure). By leveraging SHAP values, we identify underlying patterns, which are then translated into symbolic rules and seamlessly integrated into the \lcm. 

%In the proposed \framework approach for detecting insecure code, the symbolic layer is activated in cases where the \lcm exhibits uncertainty in predicting whether a code component is insecure. In such instances, a set of derived symbolic rules serves as a quality control mechanism, validating the prediction and, if necessary, refining or ``correcting'' it to enhance accuracy and reliability.

%To the best of our knowledge, this is the first documented attempt toward embedding a symbolic layer into the probabilistic framework of \lcms for program comprehension. This approach introduces a promising direction for automating software engineering practices, paving the way for future methods in the SE domain that prioritize not only peak performance but also interpretability and transparency.

In this research, we present preliminary analyses and results aimed at developing the first \framework approach for vulnerability detection \cite{zhou2019devign}, leveraging SHAP \cite{NIPS2017_Lundberg}, an interpretability method that generates local explanations for individual predictions (\eg determining whether a code component is affected by a vulnerability). By using SHAP values, we envision to uncover underlying patterns, translate them into symbolic rules, and seamlessly integrate these rules into the \lcm. To the best of our knowledge, this is the first documented attempt to embed a symbolic layer into the probabilistic framework of \lcms for program comprehension, introducing a promising direction for automating software engineering practices. This novel approach prioritizes not only peak performance but also interpretability and transparency, paving the way for future methods in the SE domain.

%Specifically, when an LCM is trained to detect defects in code, it produces a binary output, either 0 or 1, indicating whether the input code is identified as defective. Alongside this prediction, a confidence score ($c$) in the range [0, 1] can be assigned, representing the model’s certainty about its prediction. Building on this concept, our proposed NPC approach for defect detection utilizes this confidence score for each prediction made by the LCM on a given code component. If the confidence score falls below a certain threshold, signaling uncertainty, we verify whether the prediction still indicates defective code. If so, a set of derived symbolic rules is activated as a quality check to validate and eventually ``fix'' the prediction.

%However, the model’s confidence level that is attached to the prediction itself,  can vary significantly. This value that we can indicate with $c$ is defined in the range [0;1] and informs about how certain is the model about the recommendation.
%For example, in \figref{fig:example}, two Python methods are shown. The method in the top portion of the figure contains a bug, which the model detects correctly with high confidence ($>0.9$), indicating near certainty in its prediction. In contrast, in the bottom portion of \figref{fig:}, the model also identifies the code as buggy but with much lower confidence ($<0.4$). \ANTONIO{Alejo, please, find a pic here}

%While the details of the symbolic component and how it was built are presented in \secref{sec:approach}--we anticipate that such module is grounded on the application of the interpretability theory revolving around Shaply values \cite{}. 

%Preliminary results indicate that NPC methods are not only feasible but also open up a promising research direction, providing a more interpretable approach with the symbolic component functioning as a white-box. To the best of our knowledge, no existing research challenges the probabilistic application of LCM by integrating a symbolic component within the context of program comprehension.


%in this direction is to enhance SE classification tasks, particularly defect detection. To this end, we base the NPC approach on CodeBERT, a pre-trained DL model of code widely used in the literature \cite{} that we further fine-tune on a novel bug-fixing dataset \cite{}. Then, we perform a SHAP-value analysis to interpret the model’s predictions, pinpointing the input features that most influence defect code. Finally, we use the output of the SHAP-value analysis to create a map of input patterns that occur in defect/non defect code.

%This mapping forms our Symbolic component, enhancing the defect prediction task. We validate our symbolic map on 100 examples randomly sampled from .................


%\figref{fig:approach} illustrates the first NeuroSymbolic Program Comprehension approach designed to improve the detection of bugs in Python methods. In this paper, we detail the creation and application of this approach, which combines the predictive power of CodeBERT with a symbolic validation layer, aiming to increase accuracy and interpretability in bug detection. The diagram includes the entire process, illustrating our current methodology and the broader vision for how this framework could evolve.

% \begin{figure}[H]
%         \centering
%     	\includegraphics[width=0.5\textwidth]{images/approach.jpg}
%     	\caption{NeuroSymbolic Program Comprehension approach for detecting bug.}
%     	\label{fig:approach}
% \end{figure}



