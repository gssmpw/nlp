\section{Case Study}
\label{sec:case_study}

To demonstrate the practical application of NsPC, we conducted a case study to identify SHAP value patterns in the context of insecure code detection (\ie binary classification task) using Java code snippets. This study aimed to address the following research question:

\begin{enumerate}[label=\textbf{RQ$_{\arabic*}$}, ref=\textbf{RQ$_{\arabic*}$}, wide, labelindent=5pt]\setlength{\itemsep}{0.2em}
      \item \label{rq:neuro_symbolic_rules} {\textbf{[Symbolic rules from SHAP]} To what extent SHAP values enable the definition of symbolic rules?}
\end{enumerate}

%%%%%% SELECTED MODEL
\textbf{Selected \lcm.} For our analysis, we selected CodeBERT \cite{feng_codebert_2020}, fine-tuned for detecting insecure code snippets \footnote{https://huggingface.co/mrm8488/codebert-base-finetuned-detect-insecure-code} as BERT-like architectures are widely adopted in SE for classification tasks \cite{10.1145/3528588.3528660,9492202,ardimento2020using,chochlov2022using}. Specifically, we focus on a binary classification task, where the presence of insecure code in a code snippet is treated as the \textit{"positive"} class prediction, while the absence of insecure code is the \textit{negative}. The selected model, trained on the Devign \cite{zhou_devign_2019} (CodeXGLUE--Defect Detection \cite{lu_codexglue_2021}), features a vocabulary size of $50,265$ and comprises $12$ hidden layers with attention heads. The model was deployed on an Ubuntu 20.04 system with an AMD EPYC 7532 32-Core CPU, an NVIDIA A100 GPU with 40GB VRAM, and 1TB of RAM.

%%%%%% EVALUATION METHODOLOGY
\textbf{Evaluation Dataset.} For evaluation, we used the validation split of the CodeXGLUE dataset for Defect Detection. Specifically, we created two smaller datasets by splitting the datapoints based on the target class (\ie positive and negative). To align with the token limit defined by the selected model, we restricted each data point to a maximum of $500$ tokens. The resulting datasets included a total of $300$ confirmed insecure datapoints for the positive target class and $300$ datapoints free of insecure code for the negative target class.


%%%%%% EVALUATION METHODOLOGY
\textbf{Evaluation Methodology}. To address \ref{rq:neuro_symbolic_rules}, we applied \framework to compute SHAP tensors for each of the two evaluation datasets (refer to \secref{sec:npc_pattern_identification}). We analyzed these tensors by defining six position ranges, considering a maximum token length of $300$ per snippet. Additionally, we trained logistic regression models to compute decision boundaries within these ranges for the two possible classes: \textbf{\textit{secure}} and \textbf{\textit{insecure}}.


\subsection{Results \& Discussion}
\label{sec:case_study_results_discussion} 


%%%%%%%%%%%%%%%%%%% PATTERN EXAMPLES 
\begin{figure*}[ht]
		\centering
  \includegraphics[width=1\textwidth]{images/results.png}
		\caption{Examples of logistic regression models suggesting the presence of a pattern in each position range per type of AST element.}
    \label{fig:rules_examples}
    \vspace{-1em}
\end{figure*}
%%%%%%%%%%%%%%%%%%

\tabref{tab:results} summarizes the results of the trained logistic regression models for each position range and identified AST type. The trained logistic regression model surpassed the $60\%$ accuracy threshold and exhibited a clear decision boundary for the two possible outcomes only for the AST types \textit{punctuation}, \textit{operator}, \textit{literal}, \textit{type}, and \textit{primitive}. For instance, as illustrated in \figref{fig:rules_examples}, if a snippet contains a \textit{literal} token within positions $[0-43]$, there is a high probability that the snippet will be classified as \textbf{\textit{insecure}}. Similarly, if a snippet contains an \textit{operator} within positions $[251-280]$, there is a high probability that the snippet will be classified as \textbf{\textit{secure}}. 


%We can capitalize on these patterns by deriving symbolic rules to improve model interpretability and guide predictions in low-confidence cases. For instance, if the model predicts a snippet as \textit{\textbf{insecure}} with low confidence, we can verify whether the snippet matches the identified rule to support or refine the prediction, thus enhancing both reliability and transparency in decision-making.

These patterns reflect meaningful correlations arising from the underlying dataset and programming conventions. For instance, literal tokens often appear early in code snippets due to the prevalence of hardcoded values, initialization blocks, or function arguments, which are common in insecure patterns. Conversely, \textit{operator} tokens in later positions typically belong to logical constructs or functional operations, often associated with structured and secure code. 
We capitalize on these patterns to present compelling evidence supporting the instantiation of the \emph{NsPC} framework to identify symbolic rules for the selected \lcm (\ie fine-tuned CodeBERT).
%While additional experiments on other datasets are necessary to validate the generalizability of these findings, the practical applications of the extracted patterns are already accessible to practitioners. For instance, if the model classifies a snippet as \textit{\textbf{insecure}} with low confidence, assessing whether the snippet conforms to the identified patterns can help either reinforce or adjust the prediction, thereby enhancing both the model’s reliability and transparency.


%Additional experiments with other datasets are needed to confirm the generalizability of these findings. While not absolute indicators of secure or insecure code, these patterns offer valuable insights that complement model predictions. For example, if the model predicts a snippet as \textit{\textbf{insecure}} with low confidence, verifying whether the snippet aligns with the identified patterns can support or refine the prediction, improving both reliability and transparency.}

%We believe our results provide compelling evidence supporting the instantiation of the \emph{NsPC} framework to identify symbolic rules for the selected model (\ie, fine-tuned CodeBERT). However, as the pattern identification relies on SHAP values computed specifically for this model, the evidence is insufficient to generalize these rules to other models or tasks. While we present empirical evidence, further studies are necessary to expand on this idea and establish a solid mathematical foundation. 

However, as the pattern identification relies on SHAP values computed specifically for this model, the evidence obtained is not sufficient to generalize these rules to other models, tasks, or datasets, highlighting the need for further research. Nevertheless, this study represents a foundational step toward introducing the first \framework in the literature aimed at supporting program comprehension tasks, with a particular focus on vulnerability detection.
%While this study serves as an initial attempt to empirically demonstrate the first \framework in the literature designed to support insecure code detection, further research is required to expand upon this concept and establish a robust mathematical foundation.

%Despite the generalizability of our findings has to be proven with other datasets, we provide compelling evidence supporting the instantiation of the \emph{NsPC} framework to identify symbolic rules for the selected model (\ie fine-tuned CodeBERT).

%%%%%%%%%%%%%%%%% FINDING 
\begin{boxK}
    \textit{\ref{rq:neuro_symbolic_rules}} \textbf{[Neurosymbolic Component]}: Using the proposed \framework framework, we identified meaningful insecure-prone patterns within specific position ranges, which facilitated the definition of symbolic rules for detecting \textbf{secure} and \textbf{insecure} code snippets. The patterns reveal that tokens from certain AST types in particular positions have a significant impact on the model’s predictions.
\end{boxK}
%%%%%%%%%%%%%%%%%%
