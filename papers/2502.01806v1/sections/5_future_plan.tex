\section{Future Plans}
\label{sec:future_plan}

In this paper, we presented our framework designed to enhance the capabilities of \lcms through the definition of a deterministic layer built upon symbolic rules. By leveraging interpretability techniques such as SHAP, our approach identifies patterns in model predictions, which can be formalized into symbolic rules. We believe that interpretability techniques not only provide valuable insights into model behavior but also serve as a foundation for defining rules that improve both the transparency and performance of \lcms, particularly in tasks requiring high reliability and explainability. In other words, we are challenging the canonical paradigm that has dominated software engineering automation over the past decade, where the predictive capabilities of machine learning methods, particularly deep neural networks, have streamlined various SE-related practices

%As next steps, we aim to address several key areas to further refine and expand our framework. First, we plan to validate the generalizability of the identified rules across different models and datasets. Second, we intend to explore the scalability of the \framework framework for larger and more complex datasets. %Additionally, incorporating automated techniques for symbolic rule generation could streamline the process and reduce manual effort. 
%Finally, we aim to establish a more rigorous mathematical foundation for our framework to formalize its theoretical underpinnings and improve its reliability in diverse applications, that extend beyond classification tasks.

As next steps, we aim to address two fundamental key areas to further refine and expand our framework. First, we seek to establish a more rigorous mathematical foundation for our framework to formalize its theoretical underpinnings and improve its reliability and generalizability in diverse applications that extend beyond classification tasks. 
%This includes extending our technique to program comprehension generative tasks,that such as refactoring, code summarization, and documentation generation.
Second,  we aim to incorporate human validation of the derived symbolic rules to ensure their correctness, interpretability, and practical relevance, thereby bridging the gap between automated rule generation and real-world applicability.

%First, we plan to validate the generalizability of the identified rules across different models and datasets. 
%Second, we intend to explore the scalability of the \framework framework for larger and more complex datasets. 

%Third, we aim to incorporate human validation of the derived symbolic rules to ensure their correctness, interpretability, and practical relevance, thereby bridging the gap between automated rule generation and real-world applicability.


