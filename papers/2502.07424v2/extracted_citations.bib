@article{belrose2023eliciting,
  title={Eliciting latent predictions from transformers with the tuned lens},
  author={Belrose, Nora and Furman, Zach and Smith, Logan and Halawi, Danny and Ostrovsky, Igor and McKinney, Lev and Biderman, Stella and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2303.08112},
  year={2023}
}

@inproceedings{chen2024selfie,
  author       = {Haozhe Chen and
                  Carl Vondrick and
                  Chengzhi Mao},
  title        = {SelfIE: Self-Interpretation of Large Language Model Embeddings},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=gjgRKbdYR7},
}

@article{elhage2021mathematical,
  title={A mathematical framework for transformer circuits},
  author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and others},
  journal={Transformer Circuits Thread},
  url = {https://transformer-circuits.pub/2021/framework/index.html},
  volume={1},
  number={1},
  pages={12},
  year={2021}
}

@inproceedings{geiger2022inducing,
  title={Inducing causal structure for interpretable neural networks},
  author={Geiger, Atticus and Wu, Zhengxuan and Lu, Hanson and Rozner, Josh and Kreiss, Elisa and Icard, Thomas and Goodman, Noah and Potts, Christopher},
  booktitle={International Conference on Machine Learning},
  pages={7324--7338},
  year={2022},
  organization={PMLR}
}

@inproceedings{ghandeharioun2024patchscope,
  author       = {Asma Ghandeharioun and
                  Avi Caciularu and
                  Adam Pearce and
                  Lucas Dixon and
                  Mor Geva},
  title        = {Patchscopes: {A} Unifying Framework for Inspecting Hidden Representations
                  of Language Models},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=5uwBzcn885},
}

@inproceedings{husain2024romansetu,
  title={Romansetu: Efficiently unlocking multilingual capabilities of large language models via romanization},
  author={Jaavid, J and Dabre, Raj and Aswanth, M and Gala, Jay and Jayakumar, Thanmay and Puduppully, Ratish and Kunchukuttan, Anoop},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
url = "https://aclanthology.org/2024.acl-long.833/",
  pages={15593--15615},

  year={2024}
}

@article{kramar2024atp,
  title={AtP*: An efficient and scalable method for localizing LLM behaviour to components},
  author={Kram{\'a}r, J{\'a}nos and Lieberum, Tom and Shah, Rohin and Nanda, Neel},
  journal={arXiv preprint arXiv:2403.00745},
  year={2024}
}

@inproceedings{liu-etal-2024-translico,
  author       = {Yihong Liu and
                  Chunlan Ma and
                  Haotian Ye and
                  Hinrich Sch{\"{u}}tze},
  title        = {TransliCo: {A} Contrastive Learning Framework to Address the Script
                  Barrier in Multilingual Pretrained Language Models},
  booktitle    = {Proceedings of the 62nd Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2024, Bangkok, Thailand,
                  August 11-16, 2024},
  pages        = {2476--2499},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://doi.org/10.18653/v1/2024.acl-long.136},
}

@article{logit-lens,
    author = "Nostalgebraist" ,
    title = "{Interpreting GPT: The Logit Lens}",
    journal = "LessWrong",
    year =  "2020",
    url = "https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens"
}

@inproceedings{meng2022locating,
  author       = {Kevin Meng and
                  David Bau and
                  Alex Andonian and
                  Yonatan Belinkov},
  title        = {Locating and Editing Factual Associations in {GPT}},
  booktitle    = {Advances in Neural Information Processing Systems 35: Annual Conference
                  on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans,
                  LA, USA, November 28 - December 9, 2022},
  year         = {2022},
  url          = {http://papers.nips.cc/paper\_files/paper/2022/hash/6f1d43d5a82a37e89b0665b33bf3a182-Abstract-Conference.html},
}

@inproceedings{zhao2024large,
  author       = {Yiran Zhao and
                  Wenxuan Zhang and
                  Guizhen Chen and
                  Kenji Kawaguchi and
                  Lidong Bing},
  title        = {How do Large Language Models Handle Multilingualism?},
  booktitle    = {Advances in Neural Information Processing Systems 38: Annual Conference
                  on Neural Information Processing Systems 2024, NeurIPS 2024, Vancouver,
                  BC, Canada, December 10 - 15, 2024},
  year         = {2024},
  url          = {http://papers.nips.cc/paper\_files/paper/2024/hash/1bd359b32ab8b2a6bbafa1ed2856cf40-Abstract-Conference.html},
}

@article{zhong2024beyond,
  title={Beyond English-Centric LLMs: What Language Do Multilingual Language Models Think in?},
  author={Zhong, Chengzhi and Cheng, Fei and Liu, Qianying and Jiang, Junfeng and Wan, Zhen and Chu, Chenhui and Murawaki, Yugo and Kurohashi, Sadao},
  journal={arXiv preprint arXiv:2408.10811},
  year={2024}
}

