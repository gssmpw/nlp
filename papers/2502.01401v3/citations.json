[
  {
    "index": 0,
    "papers": [
      {
        "key": "chen2020scanrefer",
        "author": "Chen, Dave Zhenyu and Chang, Angel X and Nie{\\ss}ner, Matthias",
        "title": "{ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language}"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "achlioptas2020referit3d",
        "author": "Achlioptas, Panos and Abdelreheem, Ahmed and Xia, Fei and Elhoseiny, Mohamed and Guibas, Leonidas",
        "title": "{ReferIt3D: Neural Listeners for Fine-grained 3D Object Identification in Real-world Scenes}"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "dai2017scannet",
        "author": "Dai, Angela and Chang, Angel X and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Nie{\\ss}ner, Matthias",
        "title": "{ScanNet: Richly-Annotated 3D Reconstructions of Indoor Scenes}"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "jain2022bottom",
        "author": "Jain, Ayush and Gkanatsios, Nikolaos and Mediratta, Ishita and Fragkiadaki, Katerina",
        "title": "{Bottom Up Top Down Detection Transformers for Language Grounding in Images and Point Clouds}"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "chen2022language",
        "author": "Chen, Shizhe and Guhur, Pierre-Louis and Tapaswi, Makarand and Schmid, Cordelia and Laptev, Ivan",
        "title": "Language conditioned spatial relation reasoning for 3d object grounding"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "3dvista",
        "author": "Ziyu, Zhu and Xiaojian, Ma and Yixin, Chen and Zhidong, Deng and Siyuan, Huang and Qing, Li",
        "title": "3D-VisTA: Pre-trained Transformer for 3D Vision and Text Alignment"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "hsu2023ns3d",
        "author": "Hsu, Joy and Mao, Jiayuan and Wu, Jiajun",
        "title": "{NS3D: Neuro-Symbolic Grounding of 3D Objects and Relations}"
      },
      {
        "key": "feng2024naturally",
        "author": "Feng, Chun and Hsu, Joy and Liu, Weiyu and Wu, Jiajun",
        "title": "Naturally supervised 3d visual grounding with language-regularized concept learners"
      },
      {
        "key": "li2024r2g",
        "author": "Li, Yixuan and Wang, Zan and Liang, Wei",
        "title": "R2G: Reasoning to Ground in 3D Scenes"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "yuan2024visual",
        "author": "Yuan, Zhihao and Ren, Jinke and Feng, Chun-Mei and Zhao, Hengshuang and Cui, Shuguang and Li, Zhen",
        "title": "Visual programming for zero-shot open-vocabulary 3d visual grounding"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "yang2024llm",
        "author": "Yang, Jianing and Chen, Xuweiyi and Qian, Shengyi and Madaan, Nikhil and Iyengar, Madhavan and Fouhey, David F and Chai, Joyce",
        "title": "Llm-grounder: Open-vocabulary 3d visual grounding with large language model as an agent"
      },
      {
        "key": "fang2024transcrib3d",
        "author": "Fang, Jiading and Tan, Xiangshan and Lin, Shengjie and Vasiljevic, Igor and Guizilini, Vitor and Mei, Hongyuan and Ambrus, Rares and Shakhnarovich, Gregory and Walter, Matthew R",
        "title": "Transcrib3D: 3D Referring Expression Resolution through Large Language Models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "xuvlm",
        "author": "Xu, Runsen and Huang, Zhiwei and Wang, Tai and Chen, Yilun and Pang, Jiangmiao and Lin, Dahua",
        "title": "VLM-Grounder: A VLM Agent for Zero-Shot 3D Visual Grounding"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "csvg",
        "author": "Yuan, Qihao and Zhang, Jiaming and Li, Kailai and Stiefelhagen, Rainer",
        "title": "Solving Zero-Shot 3D Visual Grounding as Constraint Satisfaction Problems"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "yuan2024visual",
        "author": "Yuan, Zhihao and Ren, Jinke and Feng, Chun-Mei and Zhao, Hengshuang and Cui, Shuguang and Li, Zhen",
        "title": "Visual programming for zero-shot open-vocabulary 3d visual grounding"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "li2024seeground",
        "author": "Rong Li and Shijie Li and Lingdong Kong and Xulei Yang and Junwei Liang",
        "title": "SeeGround: See and Ground for Zero-Shot Open-Vocabulary 3D Visual Grounding"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "yang2024llm",
        "author": "Yang, Jianing and Chen, Xuweiyi and Qian, Shengyi and Madaan, Nikhil and Iyengar, Madhavan and Fouhey, David F and Chai, Joyce",
        "title": "Llm-grounder: Open-vocabulary 3d visual grounding with large language model as an agent"
      },
      {
        "key": "xuvlm",
        "author": "Xu, Runsen and Huang, Zhiwei and Wang, Tai and Chen, Yilun and Pang, Jiangmiao and Lin, Dahua",
        "title": "VLM-Grounder: A VLM Agent for Zero-Shot 3D Visual Grounding"
      },
      {
        "key": "fang2024transcrib3d",
        "author": "Fang, Jiading and Tan, Xiangshan and Lin, Shengjie and Vasiljevic, Igor and Guizilini, Vitor and Mei, Hongyuan and Ambrus, Rares and Shakhnarovich, Gregory and Walter, Matthew R",
        "title": "Transcrib3D: 3D Referring Expression Resolution through Large Language Models"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "yuan2024visual",
        "author": "Yuan, Zhihao and Ren, Jinke and Feng, Chun-Mei and Zhao, Hengshuang and Cui, Shuguang and Li, Zhen",
        "title": "Visual programming for zero-shot open-vocabulary 3d visual grounding"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "roziere2023code",
        "author": "Roziere, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Sauvestre, Romain and Remez, Tal and others",
        "title": "Code llama: Open foundation models for code"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "li2023chain",
        "author": "Li, Chengshu and Liang, Jacky and Zeng, Andy and Chen, Xinyun and Hausman, Karol and Sadigh, Dorsa and Levine, Sergey and Fei-Fei, Li and Xia, Fei and Ichter, Brian",
        "title": "Chain of code: Reasoning with a language model-augmented code emulator"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "liang2023code",
        "author": "Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy",
        "title": "Code as policies: Language model programs for embodied control"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "gupta2023visual",
        "author": "Gupta, Tanmay and Kembhavi, Aniruddha",
        "title": "Visual Programming: Compositional visual reasoning without training"
      },
      {
        "key": "yuan2024visual",
        "author": "Yuan, Zhihao and Ren, Jinke and Feng, Chun-Mei and Zhao, Hengshuang and Cui, Shuguang and Li, Zhen",
        "title": "Visual programming for zero-shot open-vocabulary 3d visual grounding"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "zhou2024programming",
        "author": "Zhou, Fan and Wang, Zengzhi and Liu, Qian and Li, Junlong and Liu, Pengfei",
        "title": "Programming every example: Lifting pre-training data quality like experts at scale"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "ma2023eureka",
        "author": "Ma, Yecheng Jason and Liang, William and Wang, Guanzhi and Huang, De-An and Bastani, Osbert and Jayaraman, Dinesh and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima",
        "title": "Eureka: Human-level reward design via coding large language models"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "le2022coderl",
        "author": "Le, Hung and Wang, Yue and Gotmare, Akhilesh Deepak and Savarese, Silvio and Hoi, Steven Chu Hong",
        "title": "Coderl: Mastering code generation through pretrained models and deep reinforcement learning"
      },
      {
        "key": "chen2023teaching",
        "author": "Chen, Xinyun and Lin, Maxwell and Sch{\\\"a}rli, Nathanael and Zhou, Denny",
        "title": "Teaching large language models to self-debug"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "yuan2024visual",
        "author": "Yuan, Zhihao and Ren, Jinke and Feng, Chun-Mei and Zhao, Hengshuang and Cui, Shuguang and Li, Zhen",
        "title": "Visual programming for zero-shot open-vocabulary 3d visual grounding"
      },
      {
        "key": "fang2024transcrib3d",
        "author": "Fang, Jiading and Tan, Xiangshan and Lin, Shengjie and Vasiljevic, Igor and Guizilini, Vitor and Mei, Hongyuan and Ambrus, Rares and Shakhnarovich, Gregory and Walter, Matthew R",
        "title": "Transcrib3D: 3D Referring Expression Resolution through Large Language Models"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "li2023scallop",
        "author": "Li, Ziyang and Huang, Jiani and Naik, Mayur",
        "title": "Scallop: A language for neurosymbolic programming"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "cheng2022binding",
        "author": "Cheng, Zhoujun and Xie, Tianbao and Shi, Peng and Li, Chengzu and Nadkarni, Rahul and Hu, Yushi and Xiong, Caiming and Radev, Dragomir and Ostendorf, Mari and Zettlemoyer, Luke and others",
        "title": "{Binding Language Models in Symbolic Languages}"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "hsu2023ns3d",
        "author": "Hsu, Joy and Mao, Jiayuan and Wu, Jiajun",
        "title": "{NS3D: Neuro-Symbolic Grounding of 3D Objects and Relations}"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "feng2024naturally",
        "author": "Feng, Chun and Hsu, Joy and Liu, Weiyu and Wu, Jiajun",
        "title": "Naturally supervised 3d visual grounding with language-regularized concept learners"
      }
    ]
  }
]