\section{Discussion, Limitations and Future Work}
\label{sec:discussion}

Our novel HIG representation enables highly controllable and complex conditioning, outperforming the state-of-the-art in image quality while remaining more computationally efficient by foregoing quadratic attention mechanisms. By structuring images and conditioning variables as a single heterogeneous graph, we incorporate all available data—including attributes and relationships—into a unified representation. This allows for unprecedented control over local attribute conditioning and complex spatial ambiguities, paving the way for larger and more diverse datasets in image synthesis. While we attempt to mitigate randomness by using consistent seeds across experiments, our model still exhibits notable failures in adhering to the prescribed relationships and attribute conditioning, which we attribute to factors such as inconsistent spatial labeling, under-training, and other contributing limitations.
Despite relying on basic graph convolutional operators, our model achieves strong results. Future work will explore more advanced architectures, such as attention-based message passing or higher-order graph operators, which could further enhance expressivity. Moreover, we only utilise models trained on ImageNet as our backbone, we believe a more generalised model would significantly improve our results. More broadly, we believe our approach has implications beyond diffusion models, offering new directions for structured representations in generative modeling.

\clearpage
\newpage

\section*{Impact Statement}

Large-scale image generation models present notable societal risks, including the spread of disinformation and the reinforcement of stereotypes \cite{eiras2024risksopportunitiesopensourcegenerative}. While the methods we introduce in this paper significantly improve the controllability of these models, they may also intensify these risks by making it easier to generate tailored, high-fidelity content that aligns precisely with specified scenes, faces, and events, potentially amplifying the spread of misleading or biased information.

The substantial computational demands required for training and sampling diffusion models should also be acknowledged, as they lead to considerable energy consumption and may further contribute to broader environmental challenges, including climate change.

\section*{Acknowledgments} We would like to acknowledge support from the Engineering and Physical Sciences Research Council (EPSRC) Ph.D. Studentship EP/N509620/1 and the UKRI access to high performance computing facilities program.

\section*{Conflicts of Interest} SWP is co-founder of a spin-out company called Matta that develops AI for Factories.

% E. Negative societal impacts Large-scale image generators such as DALL·E 3, Stable Diffusion XL, or MidJourney can have various negative societal effects, including types of disinformation or emphasizing sterotypes and harmful biases [52]. Our advances to the result quality can potentially further amplify some of these issues. Even with our efficiency improvements, the training and sampling of diffusion models continue to require a lot of electricity, potentially contributing to wider issues such as climate change.