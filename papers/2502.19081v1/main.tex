\documentclass[oneside,twocolumn,pdflatex,sn-mathphys-num]{sn-jnl}

\usepackage{graphicx}%
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%
\usepackage{multirow}




\definecolor{darkred}{RGB}{139,0,0} % Dark red color
\definecolor{darkgreen}{RGB}{0,100,0} % Dark green
\definecolor{amber}{RGB}{205,140,0}

\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}%
\newtheorem{proposition}[theorem]{Proposition}% 

\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%

\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}%

\raggedbottom

\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 right=20mm,
 bottom=40mm,
 }

\usepackage[numbers,sort&compress]{natbib}
\bibliographystyle{sn-mathphys-num}  % Or use another style like plainnat


\begin{document}

\title[Article Title]{Efficient and Accurate Spatial Mixing of Machine Learned Interatomic Potentials for Materials Science}

\author*[1]{\fnm{Fraser} \sur{Birks}}\email{fraser.birks@warwick.ac.uk}

\author[2]{\fnm{Thomas} D \sur{Swinburne}}\email{}

\author[1]{\fnm{James} R \sur{Kermode}}

\affil*[1]{\orgdiv{Warwick Center for Predictive Modelling, School of Engineering}, \orgname{University of Warwick}, \orgaddress{\street{Library Road}, \city{Coventry}, \postcode{CV4 7AL}, \country{United Kingdom}}}

\affil[2]{\orgdiv{Aix-Marseille Université}, \orgname{CNRS}, \orgaddress{\street{CINaM UMR 7325, Campus de Luminy}, \city{Marseille}, \postcode{13288}, \country{France}}}

\abstract{Machine-learned interatomic potentials offer near first-principles accuracy but are computationally expensive, limiting their application in large-scale molecular dynamics simulations. Inspired by quantum mechanics/molecular mechanics methods, we present ML-MIX, an efficient and flexible \texttt{LAMMPS} package for accelerating simulations by spatially mixing interatomic potentials of different complexities. Through constrained linear fitting, we show it is possible to generate a `cheap' approximate model which closely matches an `expensive' reference in relevant regions of configuration space. We demonstrate the capability of ML-MIX through case-studies in Si, Fe, and W–He systems, achieving up to an 11× speedup on $\sim$ 8,000 atom systems without sacrificing accuracy on static and dynamic quantities, including calculation of minimum energy paths and dynamical simulations of defect diffusion. For larger domain sizes, we show that the achievable speedup of ML-MIX simulations is limited only by the relative speed of the cheap potential over the expensive potential. The ease of use and flexible nature of this method will extend the practical reach of MLIPs throughout computational materials science, enabling parsimonious application to large spatial and temporal domains.}

\keywords{}

\maketitle

\section{Introduction}\label{sec1}
Atomistic simulations face two central challenges: accuracy in the 
model for atomic energies and forces and capturing 
physical processes at large length- and time-scales.
Addressing each challenge under fixed computational budget leads to cost-accuracy trade-offs which have driven the development of many methods that approximate the underlying quantum-mechanical ground truth. 
The most important (and most successful) approximation for atomic interactions is density functional theory (DFT) --- which pushed the size of simulations from one or two small atoms to hundreds or even thousands on modern machines --- a meteoric development recognised with the 1998 Nobel Prize \cite{Burke_2012,Jones_2015}. \\

A further level of approximation is to do away with electrons completely; instead making predictions about atomic behavior purely from the positions of atomic nuclei and chemical species. For a many years, the most accurate models in this category were fit-by-hand interatomic potentials with simple functional forms designed to match experimental quantities of interest \cite{Daw_1984,Lennard-Jones_1931,Stillinger_1985,Tersoff_1988} or DFT derived properties \cite{Ercolessi_1994,Brommer_2007}. Many such `empirical' potentials still see considerable use today \cite{Muser_2023}. In the last three decades a new class of interatomic potentials has emerged, which have complex functional forms and parameters fit to DFT data, with an aim to reproduce large swathes of the potential energy surface \cite{Behler_2007,Bartok_2010,Shapeev_2016,Drautz_2019,Deringer_2021,Batatia_2022}. These machine learned interatomic potentials (MLIPs) have consistently achieved remarkable accuracy over a range of applications across materials science and chemistry \cite{Bartok_2018,Kovacs_2023,Qamar_2023,Batatia_2024}. Whilst the evaluation costs of empirical potentials and MLIPs both scale linearly with the number of atoms in a system, the flexible functional forms of MLIPs result in much larger scaling pre-factors. Generally, MLIPs are approximately 2-3 orders of magnitude slower in evaluation than their simple empirical counterparts \cite{Lysogorskiy_2021,Xie_2023}. \\

This cost has led to the uptake of MLIPs being slow in fields where simulation domains are prohibitively large and simulation timescales are long, for example investigations requiring molecular dynamics (MD) simulations of millions of atoms for billions of timesteps. These simulations can be split into two categories, those in which the entire domain is chemically complex, with atoms involved in bond-making/breaking processes throughout (e.g, amorphous materials \cite{Qian_2023,Griesser_2023}, liquids \cite{Al-Awad_2023,Tian_2023}, high entropy alloys \cite{Byggmastar_2021,Shiotani_2023}), and those where the domain contains only isolated regions of complexity surrounded by atoms in simple environments (e.g, materials defects \cite{Gleizer_2014}, biochemical simulations \cite{Cui_2021}, catalysis \cite{Bramley_2023}). In the second case, simulation cost can in principle be reduced by using cheap, approximate models away from the chemically `important' regions of high complexity. \\

This idea has been extensively explored in the context of quantum mechanical/ molecular mechanics modeling (QM/MM), a method which couples an expensive first-principles method (typically DFT) with a linear scaling potential for the complex (QM) and simple (MM) regions of a simulation domain respectively \cite{Warshel_1976,Chen_Ortner_2016,Chen_Ortner_2017,Swinburne_and_Kermode_2017,Bernstein_2009,Kermode_2008,Molani_2024,Grigorev_2023,Wagih_2022}. This paper details a method that is conceptually similar to QM/MM, but where the `QM' and `MM' regions are replaced with linear-scaling MLIPs of different complexities (ML/ML). The key difference is that ML/ML simulations aim to run for millions of timesteps, compared to only hundreds or thousands in QM/MM, with each timestep taking 3-6 orders of magnitude less wall time. ML/ML therefore incurs different software challenges: to minimise overhead, operations that take place each timestep must be embedded directly into the MD code. Whilst some studies have explored similar `ML/MM' ideas \cite{Hofstetter_2022,Boselt_2021,Immel_2024}, no generic, computationally parallel, simple to use implementation of ML/ML exists. \\

In this paper we present ML-MIX, a package created to enable the whole workflow of accelerating a simulation within the popular open-source MD software \texttt{LAMMPS} \cite{LAMMPS,type_label_LAMMPS}. We show that if one starts with an `expensive' MLIP, it is possible to generate a `cheap' MLIP that locally approximates the potential energy surface, and this can be spatially mixed with the expensive MLIP to run accurate simulations at a fraction of the cost. The process is schematically depicted in Fig.~\ref{fig:flowchart}. \\

The package is designed to be user-friendly; provided that a user has access to an expensive potential, our aim is that it should be straightforward to generate a cheap potential and attain a reasonable simulation speedup with minimal effort. To ensure the cheap potential locally matches the expensive potential, we generate the cheap potential through constrained linear fitting. The constraints we apply can be divided into two types depending on the strength of regularization they impose on the fit; `soft' and `hard'. Soft constraint data covers the whole region of potential energy space that the cheap potential should approximate. Hard constraint data covers important properties which should match closely between potentials. The fit is constrained to a subspace in which predictions on the hard constraint data match near-exactly between the cheap and expensive potentials. The constrained fitting procedure is described in detail in section \ref{sec:constrained_fit}. \\

We first present results of four ML/ML case-studies, targeting one static and three dynamic quantities of interest in Si, Fe and W, demonstrating that ML-MIX results agree with those from fully expensive simulations at a fraction of the cost. The quantities of interest are selected primarily to demonstrate distinct aspects of ML-MIX package rather than for their intrinsic scientific interest. For each quantity, the total atomistic domain remained small ($\sim$8000 atoms), to ensure validation measurements are viable. However, this limited the attainable speed-up (to $\sim$$10 \times$, depending on the cheap potential). In appendix \ref{secB1} we show that speedups approaching the theoretical limiting value (of $>$30$\times$ in this case) are possible with larger domains (up to $\sim$$10^{6}$ atoms). 

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{slightly_edited_constrained_fit.png}
    \caption{A schematic overview of the simulation acceleration workflow. Left hand side: the constrained potential fitting process, whereby an accurate expensive potential (orange) is approximated in local regions of potential energy space by a simpler cheap potential (blue). Right hand side: schematic showing how simulation is accelerated; cheap potential is used to evaluate force components on atoms in `bulk-like' environments.}
    \label{fig:flowchart}
\end{figure}

\section{Results}\label{sec2}
\subsection{Potential fitting}
The starting point for our study are three `expensive' linear atomic cluster expansion (ACE) potentials, each of which was fit to expansive and publically available DFT datasets (Si \cite{Bartok_2018}, Fe \cite{Zhang_2023}, W--He \cite{Nutter_2024}) using the linear \texttt{ACEpotentials.jl} package \cite{Witt_2023}. The Fe and W--He potentials were of correlation order 3 and maximum total polynomial degree 20, whilst the Si potential had a larger basis set, with correlation order 4 and maximum total polynomial degree 20. The Si potential cutoff was 6.0~{\AA}, the Fe potential cutoff was 5.5~{\AA}, and the W--He potential cutoff was 5.0~{\AA}. For the Si potential, the potential parameters and dataset match those described in \cite{Witt_2023}. For the Fe and W--He potentials, full sets of fitting parameters are given in appendix \ref{secA1}.

These expensive potentials were used to generate `synthetic' training data focused around a suitable local region of potential energy space. In each case, soft constraint data was a bulk-crystal high temperature MD trajectory, and hard constraint data was a set of zero-temperature homogeneous lattice deformations. Energy and force evaluations were performed using the ML-PACE package \cite{Lysogorskiy_2021}. As the energy of weak, homogeneously deformed lattice structures are described fully by the elastic constants \cite{Grigorev_2023}, the selected hard constraint enforced elastic constant matching between potentials. Additional details on the fitting of these potentials is presented in section \ref{sec:potential_fitting}.\\

\begin{table*}[]
\centering
\caption{RMSE table for both expensive and cheap potentials on the full DFT datasets used for the creation of the expensive potentials and the small synthetic MD datasets used for the creation of the cheap potentials. For the W-He potential, only configurations containing W are used (as the cheap UF3 potential cannot describe He interactions). Note that the synthetic data is generated by the expensive potential, hence the lack of RMSE values in the lower left quadrant.}
\begin{tabular}{l|l|ll|ll}
 &  & \multicolumn{2}{c|}{Expensive potentials} & \multicolumn{2}{c}{Cheap potentials} \\
 &  & \begin{tabular}[c]{@{}l@{}}Energy \\ (meV)\end{tabular} & \begin{tabular}[c]{@{}l@{}}Force\\ (eV/{\AA})\end{tabular} & \begin{tabular}[c]{@{}l@{}}Energy\\ (meV)\end{tabular} & \begin{tabular}[c]{@{}l@{}}Force\\ (eV/{\AA})\end{tabular} \\ \hline
\multirow{3}{*}{Full DFT data} & Si & 2.14 & 0.075 & 2022.68 & 0.79 \\
 & Fe & 2.32 & 0.083 & 152.15 & 0.30 \\
 & W  & 2.15 & 0.070 & 11938.00  & 157.54 \\ \hline
\multirow{3}{*}{Synthetic MD data} & Si & - & - & 0.21 & 0.045 \\
 & Fe & - & - & 0.81 & 0.090 \\
 & W  & - & - & 1.02 & 0.053
\end{tabular}
\label{tab:all_rmses}
\end{table*}

\textbf{Cheap potential models}: For Si and Fe, the cheap potentials were small ACE potentials, with correlation orders of 2 and maximum total polynomial degrees of 10, with potential cutoffs matching those of the reference models. For the W-He simulation, the cheap potential was a pure W ultra-fast (UF3) potential \cite{Xie_2023} with a two-body cutoff of 6.0~{\AA} and a 3 body cutoff of 3.5~{\AA}. The energy and force root mean squared error (RMSE) values for all potentials evaluated on both the expensive potential DFT datasets and cheap potential synthetic datasets are displayed in Table.~\ref{tab:all_rmses}. The cheap potentials perform very badly compared to the expensive potential when tested across the whole potential energy surface, but exhibit excellent performance when evaluated in their target domain. \\

A plot for the relative speedups of each cheap potential over the expensive potentials on different numbers of processors are shown in Fig.~\ref{fig:speedups}. Data is shown for a small domain ($\sim$8k atoms) and a large domain ($\sim$250k atoms), with the speedup curves being approximately the same for both. The serial speedup for the Si potential is $\sim$19x, but this increases up to $\sim$30x in parallel. Similar behaviour is seen for the W--He potentials, the relative speedup is $\sim$59x in serial, but in parallel increases up to $\sim$75x. In contrast, the Fe cheap potential remains $\sim$8x faster in both serial and parallel. It is unclear exactly why the W--He and Si cheap potentials show this additional parallel speedup, and is likely due to the implementation of the ML-PACE package \cite{Lysogorskiy_2021}.\\

\begin{figure}
    \centering
    \includegraphics[width=0.95\linewidth]{speeedup_gp_fit_results_section.png}
    \caption{Speedup of simulations using only the expensive potential relative to the same simulations using only the cheap potential on 8k and 250k atoms with an increasing number of MPI parallel domains. Trendlines are given by a Gaussian process fit to all the datapoints in each group. It can be seen that the W--He and Si cheap potentials exhibit a greater speedup over the expensive potentials in parallel than serial. Error bars on each data point represent the standard deviation in the measured speedups over three repeats.}
    \label{fig:speedups}
\end{figure}

Table \ref{tab:elastic_constants} shows the impact of the hard constraint on the elastic constants and lattice parameters predicted by the cheap potentials. The elastic constants were computed using the \texttt{matscipy} package \cite{matscipy}. The unconstrained fit (fitting to MD data only) produced potentials with mismatched elastic constants and lattice parameters relative to the expensive potential reference. In the case of the Si and Fe ACE potentials, adding the hard constraint data led to near perfect matching of the reference elastic constants. For the pure W UF3 potential the fitting was less successful; it was determined the UF3 functional form was insufficiently flexible to match the hard constraint data and simultaneously give a low RMSE on the MD data. Under the constraint, the $\mathrm{C}_{11}$ and $\mathrm{C}_{44}$ elastic constants got closer to the underlying reference, but $\mathrm{C}_{12}$ became worse. In all cases, the equilibrium lattice parameter of the model became more accurate under constrained fitting. The RMSE in the predicted energies and forces on the MD data for both the constrained and unconstrained fits are shown in table \ref{tab:RMSEs}. Forcing the fit to lie in the constraint subspace always increases the RMSE.

\begin{table*}[] 
\centering
\caption{Table of elastic constants and lattice parameters of according to each potential (expensive, cheap unconstrained, cheap constrained) for Si, Fe and W--He. Elastic constants are fit to stress-strain data using Bayesian linear regression, with the error $\sigma$ in each value found from the maximum likelihood estimate. For Si and Fe, the addition of the hard constraints to the cheap potential fitting produces elastic constants which match the expensive within $1 \sigma$. For the W--He potential, the constrained fitting improves $C_{11}$ (matching within $1 \sigma$) and $C_{44}$ (matching within $2 \sigma$), but leads to a significantly worse $C_{12}$ than the unconstrained case. In all cases, the constraint dramatically improves the lattice parameter.}
\label{tab:elastic_constants}
\begin{tabular}{cl|llll}
\multicolumn{1}{l}{} &  & $C_{11}$ (GPa) & $C_{12}$ (GPa) & $C_{44}$ (GPa) & a (\AA) \\ \hline
\multicolumn{1}{c|}{\multirow{3}{*}{Si}} & Expensive (reference) & 150.8 $\pm$ 1.0 & 56 $\pm$ 2 & 70.5 $\pm$ 0.4 & 5.461 \\
\multicolumn{1}{c|}{} & Cheap (unconstrained) & {\textcolor{red}{139 $\pm$ 3}} & {\textcolor{red}{81.29 $\pm$ 0.12}} & {\textcolor{red}{52.2 $\pm$ 1.9}} & {\textcolor{red}{5.661}} \\
\multicolumn{1}{c|}{} & Cheap (constrained) & {\textcolor{darkgreen}{148 $\pm$ 2}} & {\textcolor{darkgreen}{55 $\pm$ 3}} & {\textcolor{darkgreen}{69.8 $\pm$ 0.3}} & {\textcolor{darkgreen}{5.461}} \\ \hline
\multicolumn{1}{c|}{\multirow{3}{*}{Fe}} & Expensive (reference) & 283 $\pm$ 12 & 154 $\pm$ 6 & 105 $\pm$ 6 & 2.834 \\
\multicolumn{1}{c|}{} & Cheap (unconstrained) & {\textcolor{red}{426 $\pm$ 16}} & {\textcolor{red}{364 $\pm$ 2}} & {\textcolor{red}{239.0 $\pm$ 1.9}} & {\textcolor{red}{3.360}} \\ 
\multicolumn{1}{c|}{} & Cheap (constrained) & {\textcolor{darkgreen}{284 $\pm$ 11}} & {\textcolor{darkgreen}{154 $\pm$ 7}} & {\textcolor{darkgreen}{106 $\pm$ 3}} & {\textcolor{darkgreen}{2.834}} \\ \hline
\multicolumn{1}{c|}{\multirow{3}{*}{W---He}} & Expensive (reference) & 520 $\pm$ 14 & 199 $\pm$ 5 & 143 $\pm$ 5 & 3.181 \\
\multicolumn{1}{c|}{} & Cheap (unconstrained) & {\textcolor{red}{604 $\pm$ 12}} & {\textcolor{darkgreen}{209 $\pm$ 12}} & {\textcolor{red}{180 $\pm$ 6}} & {\textcolor{red}{3.136}} \\
\multicolumn{1}{c|}{} & Cheap (constrained) & {\textcolor{darkgreen}{527 $\pm$ 11}} & {\textcolor{red}{157 $\pm$ 4}} & {\textcolor{amber}{157 $\pm$ 3}} & {\textcolor{darkgreen}{3.180}} \\ 
\end{tabular}
\end{table*}


\begin{table}[]
\caption{RMSE table for the constrained and unconstrained cheap potentials on the synthetic MD dataset. The RMSEs get slightly worse when the fit is constrained.}
\begin{tabular}{l|ll|ll}
 & \multicolumn{2}{c|}{Unconstrained fit} & \multicolumn{2}{c}{Constrained fit} \\
 & \begin{tabular}[c]{@{}l@{}}Energy \\ (meV)\end{tabular} & \begin{tabular}[c]{@{}l@{}}Force\\ (eV/{\AA})\end{tabular} & \begin{tabular}[c]{@{}l@{}}Energy\\ (meV)\end{tabular} & \begin{tabular}[c]{@{}l@{}}Force\\ (eV/{\AA})\end{tabular} \\ \hline
Si & 0.15 & 0.038 & 0.21 & 0.045 \\
Fe & 0.14 & 0.083 & 0.81 & 0.090 \\
W--He & 0.12 & 0.053 & 1.02 & 0.053
\end{tabular}
\label{tab:RMSEs}
\end{table}

\subsection{Energy barrier for Si vacancy migration}
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{neb_plot_final.png}
    \caption{The energy barrier associated with vacancy migration in Si, obtained through all-expensive (blue curve) and ML/ML (orange curve) nudged elastic band simulations. For the ML/ML simulation, the final energies were obtained through one-shot energy evaluations of the relaxed structures with the expensive potential. The all-expensive energy barrier (0.0543 eV) agrees with the ML/ML energy barrier (0.0548 eV) within 1 meV. The tangent lines arise from the projected forces.}
    \label{fig:NEB_plot}
\end{figure}
A simple zero temperature (static) quantity of interest for a materials defect is the energy barrier for migration. Here, we aimed to show that it is possible to attain a near identical energy barrier for vacancy migration in a $10\times10\times10$ (8000 atom) block of Si for both a fully-expensive simulation and an ML/ML simulation where the expensive potential is only localised around the vacancy. For both simulations, the minimum energy pathway was found using the nudged elastic band (NEB) method \cite{Henkelman_2000}, as implemented in LAMMPS, with further analysis in ASE \cite{ASE}. For the ML/ML NEB, the combined relaxation was performed using ML-MIX, with the final energies obtained through one-shot energy evaluations of the relaxed structures with the expensive potential. Fig.~\ref{fig:NEB_plot} shows the results from this investigation. The energy barrier obtained through the ML/ML simulation (0.0548 eV) agrees with the all-expensive reference energy barrier (0.0543 eV) to within 1 meV. The NEB relaxation ran $\sim$5$\times$ faster, close to the theoretical `zero-overhead' value of $5.90 \times$ expected from the fraction of expensive atoms in the ML/ML simulation.

\subsection{Stretched bond in silicon} \label{sec:si_stretched_bond}
\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{silicon_stretched_bond_simple.png}
    \caption{Average force on stretched bond in silicon over 100~ps at 300~K for different expensive potential radii $r_{\mathrm{core}}$ and thermostat damping strength. Error bars represent the standard deviation in bond force measured over this time. For $R_{\mathrm{core}} = 0$, which corresponds to using the cheap potential everywhere, the average bond force measured does not match the all-expensive $NVE$ reference. Once the expensive potential is introduced at and around the stretched bond, this difference vanishes and agreement between the mixed simulation and the $NVE$ reference is within statistical error. The weaker the thermostat, the better the agreement with the $NVE$ reference.}
    \label{fig:2_10_si}
\end{figure}
Turning to a dynamical example, we investigated the quantity of interest proposed as a test for the quality of different QM/MM techniques by Bernstein et al \cite{Bernstein_2009} --- the average force on a single stretched and rigidly fixed Si bond in a block of bulk Si at 300~K. 

In a $10\times 10 \times 10$ (8000 atom) supercell of bulk Si, a bond was stretched an additional 0.1~{\AA} along its length and fixed. The average force on this stretched bond recorded over 100~ps was then found, both for all-expensive reference and a number of ML/ML simulations. In the ML/ML simulations, the impact of changing the radius of the expensive potential region around the stretched bond atoms $r_\mathrm{core}$ on the measured average force was investigated. The first simulation, at $r_\mathrm{core} = 0$ corresponded to an all-cheap simulation. Further simulations were conducted for $r_\mathrm{core} = 4$, $r_\mathrm{core} = 6$, $r_\mathrm{core} = 8$ and $r_\mathrm{core} = 10$. \\

The results for these simulations are presented in Fig.~\ref{fig:2_10_si}. It can be seen that as the expensive potential replaces the cheap potential in the core ($r_\mathrm{core} > 0$), the forces jump to closely matching the $NVE$ reference. Images of the simulation domain highlighting the atoms treated expensively around the fixed bond are shown on the insets in Fig.~\ref{fig:2_10_si}. \\

The theoretical and measured speedups are shown in table \ref{tab:si_speedups}. It can be seen that in serial, the measured speedups match the theoretical, whilst in parallel the values are lower due to imperfect load balancing and parallel overheads. As $r_{\mathrm{core}}$ increases, the number of expensive atoms in the simulation increases, and the overall speedup decreases. The load balancing strategy employed in this study, as well the effectiveness of load balancing for ML/ML simulations across different regimes is discussed in appendix \ref{secB1}.

\begin{table}[]
\caption{Speedup table for mixed simulations in Si.}
\label{tab:si_speedups}
\begin{tabular}{l|lll}
Simulation & \begin{tabular}[c]{@{}l@{}}Theoretical\\ Speedup\end{tabular} & \begin{tabular}[c]{@{}l@{}}Serial\\ Speedup\end{tabular} & \begin{tabular}[c]{@{}l@{}}Parallel\\ Speedup\end{tabular} \\ \hline
Si: $r_{\mathrm{core}}=4$ & 12.93 & 12.89 & 8.89\\
Si: $r_{\mathrm{core}}=6$ & 10.79 & 10.73 & 10.10\\
Si: $r_{\mathrm{core}}=8$ & 8.55 & 8.55 & 8.89\\
Si: $r_{\mathrm{core}}=10$ & 6.72 & 6.72 & 6.88
\end{tabular}
\end{table}


\subsection{Diffusion coefficients}
A key property of point defects in materials are diffusion coefficients, and estimating these is a common use-case for MD simulations. Here, we consider the diffusion of a dumbbell self-interstitial in Fe and an interstitial He impurity in W, both of which have been extensively studied \cite{Wang_2012,Hammond_2018,Willaime_2005,Marinica_2011}. \\

For both target defects, reference simulations were carried out using the expensive ACE potentials. These were followed by ML/ML simulations where the expensive potentials were limited to a small region around the diffusing defect, which was tracked as it moved, with the rest of the simulation domain treated using the Fe or W cheap potentials. \\

Fig.~\ref{fig:Diff_coeff_results} presents the results from these investigations side-by-side. For the Fe system, measurements of the diffusion coefficient as a function of temperature were taken with only the cheap potential, only the expensive potential and using the ML/ML approach. For W-He, only the ML/ML and expensive only simulation results are presented as as the UF3 potential was fit only for pure W and could not model W-He interactions. For both quantities of interest, the ML/ML simulations agreed well with the all-expensive reference calculations at multiple temperatures, despite the inaccuracy of the all-cheap simulation in the Fe case. Further details on the simulation setup are given in section \ref{sec:diffusion}. The theoretical and measured speedups of the mixed simulations over the reference for both simulation types are shown in table \ref{tab:diff_speedup}. The measured serial speedups again closely agree with the theoretical values whilst the parallel speedups are lower.

\begin{figure*}
    \centering
    \includegraphics[width=0.95\linewidth]{both_diff_figs.png}
    \caption{Diffusion coefficient as a function of temperature for the diffusion of the iron interstitial dumbbell defect through bulk iron and for helium in bulk tungsten. Left: The diffusion coefficient of the iron dumbbell for three cases: expensive reference potential only (blue), cheap potential only (orange) and mixed simulation (green). The mixed simulation leads to results which are well matched with the reference. Each point is the average of 5 diffusion coefficients measured in independent runs of 1~ns each. The error-bars on each point reflect the standard deviation of these values. Right: The diffusion coefficient for He in W using a helium-tungsten ACE (blue) and a mixed simulation with both a helium-tungsten ACE and a UF3 tungsten potential. Again, agreement is good. Note that there is no 'cheap-only' reference in this case because the UF3 potential cannot be used to model tungsten-helium interactions. Each point is the average of 25 diffusion coefficients measured in independent runs of 60~ps each. The error-bars on each point reflect the standard deviation of these values.}
    \label{fig:Diff_coeff_results}
\end{figure*}

\begin{table}[]
\caption{Speedup table for mixed simulations of diffusion coefficients in Fe and W--He.}
\label{tab:diff_speedup}
\begin{tabular}{l|lll}
Simulation & \begin{tabular}[c]{@{}l@{}}Theoretical\\ Speedup\end{tabular} & \begin{tabular}[c]{@{}l@{}}Serial\\ Speedup\end{tabular} & \begin{tabular}[c]{@{}l@{}}Parallel\\ Speedup\end{tabular} \\ \hline
Fe & 3.79 & 3.80 & 2.23 \\
W--He & 10.55 & 10.46 & 7.39
\end{tabular}
\end{table}

\section{Discussion}
\label{sec:Discussion}
We have presented a hybrid simulation scheme which aims to break existing cost-accuracy tradeoffs in simulations by localizing accuracy requirements, 
enabling a $10\times$ speed-up on small (8000 atom) domains with minimal loss in accuracy on quantities of interest. A central innovation is the use of a constrained fitting procedure to automatically generate cheap models which locally approximate the potential energy surface of a reference expensive model. We show that even for very lightweight ACE potentials, imposing hard constraints can lead to exact matching of elastic constants. For UF3 potentials, we show that under hard constraints, elastic constants will improve up to some limit, beyond which any further improvements are limited by the inflexibility, or misspecification, of the functional form. We stress that whilst we have specifically discussed constrained fitting in the context of generating one MLIP that locally approximates another, it would be easy to apply this methodology to constrain the fitting of a large, flexible MLIP to DFT data directly, extending recent retraining approaches \cite{Grigorev_2023}. \\

Constrained fitting is important for this process; without it, errors are far more pronounced at small strains. This can lead to erroneous Eshelby-inclusion\cite{eshelby1957} like strain fields in the vicinity of the ML/ML potential boundary under small deformations. This is explored in more detail in appendix \ref{secC1}. \\

The first case-study we present in this paper was a nudged elastic band energy barrier calculation for the migration of an Si vacancy. We showed that, using an ML/ML simulation, a value for the migration barrier can be attained which is within 1~meV of the all-expensive reference at a fifth of the computational cost. This speedup, whilst already considerable, is not as great as what is seen for ML/ML MD simulations on the same 8000 atom domain -- this is because a larger fixed set of expensive atoms is necessary for a NEB to converge. It is important to point out that total energies are undefined in ML-MIX ML/ML simulations; the final energies were computed by performing one-shot energy evaluations of the relaxed structures using only the expensive potential. In principle, one could take this a step further and perform a small number of additional relaxation steps using only the expensive potential. If the domain was so large or the expensive potential so expensive that even the final single-point energy calculations became intractable, a further option to approximate energy barriers is to directly integrate the ML/ML forces on the final NEB image states using the virtual work method introduced by Swinburne and Kermode \cite{Swinburne_and_Kermode_2017}, originally devised for QM/MM simulations.\\

Next, we presented an investigation into the average force on a stretched and rigidly fixed bond in an Si bulk structure. This was selected to mirror previous tests performed in QM/MM studies \cite{Bernstein_2009}. It should be noted that for an $r_{\mathrm{core}}$ of 0.0 (cheap potential only) the average force measured on the stretched bond is within 5\% of the correct value, which is a significantly smaller error than one typically sees in QM/MM simulations. Adding even a small amount of expensive potential region around the stretched bond led to an immediate jump in the measured average bond force, leading to a value which was within $1$ standard deviation ($\sigma$) of the $NVE$ reference value. This behavior persisted for larger $r_{\mathrm{core}}$ values.

The measured serial speed-up closely matched theoretical predictions, showing that our implementation incurs minimal overhead due to the mixing process. 

However, in parallel testing (on 48 cores) the measured speedup is below  theoretical predictions, in particular for the $r_{\mathrm{core}}=4$ case. 
We attribute this performance to the limited strong scalability of the 
expensive interatomic potential at low atom count, leading to significant 
load balancing issues in \texttt{LAMMPS} when there are few expensive atoms. The limited speed-up is thus a property of the expensive interatomic potential rather than our load balancing protocol- near-theoretical parallel speed-ups are achievable on larger systems with simple load balancing requirements. For a demonstration of this, please see appendix \ref{secB1}. \\

We also presented case studies on more challenging quantities of interest; defect diffusion coefficients in Fe and W. The measured diffusion coefficients consistently agreed with the all-expensive reference simulations within statistical error, and were attained for a fraction of the cost of the full expensive simulations. The close matching of the measured diffusion coefficients with the reference values suggest that one only requires spatially local accuracy to attain correct defect diffusion dynamics in materials; corroborating findings from earlier QM/MM studies \cite{Csanyi_2004}. \\

Through these studies, we have demonstrated the flexibility and efficiency of the ML-MIX package to reliably and automatically track defects both in simple cases where the same atoms are always involved in the defects (i.e, for He in W) and for more complex cases where different atoms are involved as the defects move (i.e, for Fe dumbbell interstitial in Fe). Whilst the presented results only concern ACE and UF3 potentials, the general method is extendable to many other interatomic potentials implemented as \texttt{LAMMPS} pair styles. A full list of those compatible can be found on the ML-MIX GitHub repository \cite{ML-MIX}. \\

It is crucial however to point out a key limitation in ML/ML (and indeed, QM/MM) simulations --- if a force mixing method is used to combine potentials (as it is here), Newton's third law is broken at the internal ML/ML boundary. This directly results in simulations not conserving energy, meaning thermostats are required to keep simulations from heating up as they progress. The energy drift in well-matched ML/ML simulations is relatively small, meaning thermostats can be weak enough to not impact dynamics --- but this should \textbf{always be checked}. Force mixing is discussed further in section \ref{sec:force_mixing}, and a full investigation into the factors affecting energy conservation in ML/ML simulations is presented in appendix \ref{secD1}. \\

In summary, the ML-MIX approach presented here provides a largely automated 
and robust scheme to reduce the cost of any machine learned potential with 
minimal loss in accuracy. We anticipate the approach will find application in a broad range of atomic simulations of heterogeneous systems, including the calculation of defect free energy barriers \cite{Swinburne_2018}, interface migration \cite{Rogal_2021} or nucleation phenomena \cite{Bonati_2021}. 

\section{Methods}\label{sec2}
\subsection{Constrained potential fitting}
\label{sec:constrained_fit}
The constrained potential fitting process is shown schematically in Fig~\ref{fig:local_fitting}. By fitting a cheap potential to highly localized regions of the potential energy surface of the expensive potential, it is possible to attain high accuracy in local regions whilst maintaining a low complexity (and thus low evaluation cost).

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{Constrained_fit_v2_labelled.png}
    \caption{A schematic representation of the constrained fitting of a cheap potential to an expensive one. Top: A representation of the local potential energy surface of the expensive reference model (orange curve). Data has been sampled from this potential energy surface (crosses). Bottom: The cheap model, fit to this data in order to locally match the expensive model. It approximately matches the `soft' constraint data (pink crosses) and exactly matches the `hard' constraint data (green crosses).}
    \label{fig:local_fitting}
\end{figure}

\subsubsection{Selecting constraints}

The requirements of the cheap potential are split into two types: soft constraints (loose matching), and hard constraints (tight matching). Archetypal hard constraints are the elastic constants, to ensure seamless matching of the long range elastic stress fields between the cheap and expensive potentials in a solid state simulation~\cite{Bernstein_2009}.

Writing the design matrices for the hard and soft constraints as $\mathbf{A}_\mathrm{H} \in \mathbb{R}^{N_{\mathrm{H}} \times N_{\mathrm{D}}}$ and $\mathbf{A}_\mathrm{S} \in \mathbb{R}^{N_{\mathrm{S}} \times N_{\mathrm{D}}}$, and the fitting data as $\mathbf{y}_{\mathrm{H}} \in \mathbb{R}^{N_{\mathrm{H}}}$ and $\mathbf{y}_{\mathrm{S}} \in \mathbb{R}^{N_{\mathrm{S}}}$, we can express the potential parameters $\mathbf{c} \in \mathbb{R}^{N_{\mathrm{D}}}$ as a solution to the constrained optimization problem
%
\begin{equation}
    \min_{\mathbf{c}, ||\mathbf{A}_\mathrm{H} \mathbf{c} - \mathbf{y}_{\mathrm{H}}||^{2} < \alpha} \left(||\mathbf{y}_{\mathrm{S}} - \mathbf{A}_\mathrm{S}\mathbf{c}||^{2} \right)
\end{equation}
%
where regularization terms have been excluded for simplicity. The hard constraint is imposed by constraining the fit to the subspace $||\mathbf{A}_\mathrm{H} \mathbf{c} - \mathbf{y}_{\mathrm{H}}||^{2} < \alpha$, where $\alpha$ is the maximum allowed error for the model on the hard constraint data. Expressing this constraint through a Lagrange multiplier argument gives us the augmented Lagrangian
%
\begin{equation}
    \mathcal{L}(\mathbf{c}, \lambda) = ||\mathbf{y}_{\mathrm{S}} - \mathbf{A}_\mathrm{S}\mathbf{c}||^{2} + \lambda (||\mathbf{y}_{\mathrm{H}} - \mathbf{A}_\mathrm{H} \mathbf{c}||^{2} - \alpha).
\end{equation}
%
By requiring that $\nabla_{\mathbf{c}}\mathcal{L}(\mathbf{c}, \lambda) = 0$, we can express optimal constrained model parameters $\mathbf{c}$ at fixed $\lambda$ as a solution to the unconstrained problem
%
\begin{equation}
    \label{eq:full_loss}
    \min_{\mathbf{c}}(||\mathbf{y}_{\mathrm{S}} - \mathbf{A}_\mathrm{S}\mathbf{c}||^{2} + \lambda ||\mathbf{y}_{\mathrm{H}} - \mathbf{A}_\mathrm{H} \mathbf{c}||^{2}).
\end{equation}
%
From this expression, it is clear that the quadratic constraint is equivalent to adding the hard constraint configurations to the fit with weights scaled by $\lambda$. Obtaining a solution to the full constrained problem therefore requires finding the minimum $\lambda$ such that the solution to (\ref{eq:full_loss}) lies on the surface of the constraint subspace $||\mathbf{A}_\mathrm{H} \mathbf{c} - \mathbf{y}_{\mathrm{H}}||^{2} = \alpha$. \\

Scripts to perform constrained linear fitting for ACE and UF3 potentials are provided in the accompanying code \cite{ML-MIX}. To perform the $\lambda$ hyperparameter search, the linear problem is solved repeatedly. Initially, $\lambda$ is increased logarithmically until $||\mathbf{A}_\mathrm{H} \mathbf{c} - \mathbf{y}_{\mathrm{H}}||^{2} < \alpha$. Interval bisection is then used to find $\lambda$ such that $||\mathbf{A}_\mathrm{H} \mathbf{c} - \mathbf{y}_{\mathrm{H}}||^{2} - \alpha < \mathrm{tol}$, where $\mathrm{tol}$ is set by default as $\alpha/10$. $\mathbf{A}_\mathrm{H}$ and $\mathbf{A}_\mathrm{S}$ only need to be assembled once, and as the cheap potentials are small (often $\lesssim 100$ parameters), the whole constrained fitting process takes approximately 5 minutes on a single CPU core. \\

\subsubsection{Cheap potential data}
\label{sec:potential_fitting}
In each of the three case-studies, regions far from the defect cores in each domain resembled near-bulk high temperature MD. Soft constraint data was generated to match this. For Si a 4096-atom diamond structure bulk cell was simulated at 500~K for 10~ps, with snapshots saved every 0.5~ps. For W and Fe, 2000-atom body centered cubic (BCC) bulk cells were simulated at 1200~K, with snapshots saved every 0.1~ps. The soft constraints consisted of the total energy and forces from each snapshot. \\

For the hard constraints, following \cite{Grigorev_2023}, data was generated by applying multiple shear and expansion deformations to  $5\times5\times5$ bulk supercell of Si, Fe and W lattices and saving the resulting energies. 17 configurations were generated between $\pm 0.5 \% $ strain for all of the following strain states: hydrostatic, uniaxial [100], uniaxial [111], shear ([100], (010)), shear ([110], (001)) and shear ([110], (1$\Bar{1}$2)). \\

For the Si and Fe ACE potentials, an $\alpha$ value was selected that corresponded to an enforced energy error of less than $10^{-7}$~eV/atom on the hard constraint data. For Si, the corresponding $\lambda$ value was $3.25 \times 10^{9}$. For Fe, $\lambda$ was found to be $5.5 \times 10^{9}$. For the W potential the constrained fitting process failed due to the UF3 potential not being capable of simultaneously fitting the hard constraint data and maintain a low RMSE on the soft constraints. By searching the space of $\lambda$ values, it was found that above approximately $\lambda$ = $4.3 \times 10^{5}$, $||\mathbf{A}_\mathrm{H} \mathbf{c} - \mathbf{y}_{\mathrm{H}}||^{2}$ stopped decreasing. $\lambda$ was therefore set to $4.3 \times 10^{5}$.

\subsection{Region tracking}

\begin{figure*}
    \centering
    \includegraphics[width=0.9\linewidth]{region_construction_v2.png}
    \caption{Region construction schematic. From left to right: Starting with a cell containing an initial defect, it is identified either using a user-specified \texttt{LAMMPS} group or by the output vector from a user-defined \texttt{LAMMPS} fix. The defect atoms are then iterated over, with atoms that sit less than one core radius out from any defect atom being added to the core region. This construction process is then repeated for the atoms in the blended region.}
    \label{fig:TrackingFigure}
\end{figure*}

When running an ML/ML simulation, it is crucial that process of tracking defects and building the expensive potential region(s) is: \\
(i) Accurate --- if the cheap potential is erroneously used in a region that requires the expensive potential, it could impact on the accuracy of the simulation. \\
(ii) Flexible --- any defect type should be trackable. \\
(iii) Fast --- region building should not add considerable overhead to a simulation. \\

In order to satisfy all three of these simultaneously, the region building and tracking were implemented directly in \texttt{LAMMPS} through a fix. By re-using the same neighbour lists that are built for the pair style evaluation step, this fix can quickly rebuild regions. Additionally, the fix is MPI local; whilst a limited amount of communication between neighbouring processes is necessary, no expensive global communication is required. \\

The fix builds regions in two distinct stages: (i) Identify the `seed' atoms through user-defined criteria. (ii) Construct the regions around these atoms.

\subsubsection{Seed atom identification}
Seed atoms are identified in one of two ways; through a \texttt{LAMMPS} group or through querying the output vector of a separately defined \texttt{LAMMPS} fix. Tracking through a predefined \texttt{LAMMPS} group is for situations where seed atoms are unchanging, and are known at the start of the simulation, as is the case with He atoms in W. Tracking through the output vector of a user-supplied fix is useful for tracking defects which are not tied to any one particular set of atoms, for example a vacancy, dislocation or the Fe dumbbell interstitial described in the previous section. Seed atom identification is schematically represented in the first two panels of Fig.~\ref{fig:TrackingFigure}.

\subsubsection{Region construction}
Once the seed atoms are identified, regions are constructed around these seed atoms, using a method that is schematically identified in the last two panels of Fig.~\ref{fig:TrackingFigure}. \\

During region construction two arrays are populated, \texttt{i2\_potential} and \texttt{d2\_eval}. Both arrays are of size number of potentials $\times$ number of atoms. The \texttt{i2\_potential} array holds integers and is used to determine which atoms are to be evaluated with each potential; \texttt{i2\_potential[1][10] = 1} indicates that atom 10 should be evaluated with potential 1, whilst \texttt{i2\_potential[1][10] = 0} indicates that it should not be. \texttt{d2\_eval} holds double-precision real numbers and describes how much each potential contributes to forces on atoms. By allowing \texttt{d2\_eval} to hold fractional values, it is possible to introduce a blending region in which atoms move under a mixture of the forces from the two separate potentials; \texttt{d2\_eval[0][10] = 0.4} and \texttt{d2\_eval[1][10] = 0.6} indicates that atom 10 should get 40\% of its' forces from potential 0 and 60\% from potential 1. \\

Three regions are built in the region construction process, the \textbf{core region}, in which the force on all the atoms is given entirely by the expensive potential, the \textbf{blending region}, in which the forces are a mixture between the cheap and expensive potentials and the \textbf{buffer region}, which is crucial for the accuracy force-mixing scheme, and is discussed in the next section. The size of each region is specified by user controlled parameters: \texttt{r\_core}, \texttt{r\_blend} and \texttt{r\_buffer} which are passed to the fix. \\

Algorithms \ref{alg:build_core_region}, \ref{alg:build_blend_region} and \ref{alg:build_buffer_region} describe how these arrays are populated in the region construction process for one of the two potentials (potential 0). Note that in algorithm \ref{alg:build_blend_region}, a linear blending function to mix together potentials in the blending region is used. This is not mandatory and in principle could be replaced by any blending function. So long as there are only two potentials, it is trivial to populate \texttt{i2\_potential} and \texttt{d2\_eval} for the other potential once the regions have been constructed around the seed atoms. Currently, ML-MIX is limited to two potentials only. \\

\begin{algorithm}
\caption{Build core region}
\label{alg:build_core_region}
\begin{algorithmic}[1]
    \State Initialise i2\_potential to 0
    \State Initialise d2\_eval to 0.0
    \For{i $\leftarrow$ seed atoms}
        \State i2\_potential[i][0] = 1
        \State d2\_eval[i][0] = 1.0
        \For{j $\leftarrow$ neighbours of atom i}
            \If{$||\mathrm{pos(i)} - \mathrm{pos(j)}||$ $<$ r\_core}
                \State i2\_potential[j][0] = 1
                \State d2\_eval[j][0] = 1.0
            \EndIf
        \EndFor
    \EndFor
    \State Communicate()
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Build blended region}
\label{alg:build_blend_region}
\begin{algorithmic}[1]
    \For{i $\leftarrow$ core atoms}
        \For{j $\leftarrow$ neighbours of atom i}
            \If{$||\mathrm{pos(i)} - \mathrm{pos(j)}||$ $<$ r\_blend}
                \State i2\_potential[j][0] = 1
                \State r = $||\mathrm{pos(i)} - \mathrm{pos(j)}||$
                \State v = max(d2\_eval[j][0], 1.0-(r/r\_blend))
                \State d2\_eval[j][0] = v
            \EndIf
        \EndFor
    \EndFor
    \State Communicate()
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Build buffer region}
\label{alg:build_buffer_region}
\begin{algorithmic}[1]
\For{i $\leftarrow$ blended atoms}
    \For{j $\leftarrow$ neighbours of atom i}
        \If{$||\mathrm{pos(i)} - \mathrm{pos(j)}||$ $<$ r\_buffer}
            \State i2\_potential[j][0] = 1
        \EndIf
    \EndFor
\EndFor
\State Communicate()
\end{algorithmic} 
\end{algorithm}

\subsection{Spatial potential mixing}
The mixing scheme implemented in ML-MIX is force-mixing, which is a scheme commonly used in QM/MM. For in-depth reviews of force-mixing in the QM/MM context, please see Bernstein et al \cite{Bernstein_2009}. Here we briefly review the force-mixing method, and discuss simplifications that can be made when using two local potentials. \\

\subsubsection{Force mixing}\label{sec:force_mixing}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{force_mixing_figure_v2.png}
    \caption{An illustration of force-mixing with interatomic potentials. A mixed domain is split into two non-interacting subdomains, which are composed of all the atoms in the core and blending regions for each potential (solid line), plus an extra buffer region containing atoms up to the potential cutoff radius out (dotted line). Partial force vectors $\mathbf{F}_{\mathrm{c}}$ and $\mathbf{F}_{\mathrm{e}}$ are obtained by evaluating the cheap and expensive subdomains respectively. These partial vectors are then combined into the full force vector on the system $\mathbf{F}$. In this process, forces on buffer atoms are discarded and forces on blending atoms are mixed between potentials.}
    \label{fig:force_mixing}
\end{figure}

The process of force mixing is schematically shown in Fig.~\ref{fig:force_mixing}. To obtain the forces, the domain is split into separate segments where an additional buffer region is included to stop individual regions seeing an artificial surface. The forces on these regions are then evaluated to create separate parts of the overall force vector. The full force vector is constructed as a combination of these separate vectors. In QM/MM, as DFT is a non-local method, the size of the buffer region around the QM domain is a crucial convergence parameter - one needs to balance the error due to the separation of the region of interest from the artificial surface against additional cost incurred as atoms are added. \\

Local potentials simplify this. Consider a set of atoms $\Lambda_{k}$, which is a subset within a larger domain $\Lambda_{k} \subseteq \Lambda$. We want to attain correct forces on atoms in $\Lambda_{k}$ with a local potential $\Phi_{k}$ that has a defined cutoff radius $r_{\mathrm{cutoff}}$. The force on atom $i \in \Lambda_{k}$ can be written in terms of local energies as
%
\begin{equation}
    F_{i} = \frac{\partial E}{\partial \mathbf{x}_{i}} = \sum_{j}^{j\in \mathrm{neigh}(i)}{\frac{\partial E^{k}_{j}}{\partial \mathbf{x}_{i}}}
\end{equation}
%
where $E^{k}_{j}$ represents the local energy of atom $j$ as evaluated by $\Phi_{k}$. Due to the local nature of the potential, we only need to evaluate $E^{k}_{j}$ for atoms that lie within $r_{\mathrm{cutoff}}$ of atom $i$. For an atom that lies on the edge of $\Lambda_{k}$, it is clear that attaining the correct force requires evaluation of atoms up to $r_{\mathrm{cutoff}}$ outside $\Lambda_{k}$. Defining the distance between two atoms $i, j$ as $d(i, j)$, the buffer region $\Lambda_{k\text{-buffer}}$ is given by

\begin{equation}
\begin{split}
\Lambda_{k\text{-buffer}} = \bigcup \Big\{ i \in \Lambda \setminus \Lambda_k \,\Big|\,  
\exists j \in \Lambda_k, \\
\text{ such that } d(i, j) \leq r_{\mathrm{cutoff}} \Big\}.
\end{split}
\end{equation}

Note that through the dependence of local energies on local atomic positions, there is an implicit dependence on atomic positions up to two cutoff radii out. Hence, \texttt{r\_buffer} need not be any greater than the potential cutoff. \\

Force mixing is implemented in ML-MIX through a wrapper \texttt{pair\_style} which evaluates multiple sub-\texttt{pair\_styles} in turn. Algorithm \ref{alg:force_mixing} demonstrates this process. \\

\begin{algorithm}
\caption{Force mixing}
\label{alg:force_mixing}
\begin{algorithmic}[1]
\State Initialise forces to 0
\For{i $\leftarrow$ potentials}
    \For{j $\leftarrow$ atoms}
        \If{i2\_potential[i][j] == 0}
            \State Remove j from neighbour list
        \EndIf
    \EndFor
    \State temp\_forces = potentials(i) $\rightarrow$ compute()
    \State temp\_forces = temp\_forces * d2\_eval[i][:]
    \State forces = forces + temp\_forces
    \State Restore neighbour list
\EndFor
\end{algorithmic} 
\end{algorithm}

\subsection{Si vacancy migration}
To generate the vacancy structure, a 10$\times$10$\times$10 (8000) atom Si super-cell was generated, and the atom nearest the centre was removed. Initial guesses for the minimum energy pathway were formed by linearly interpolating the migration of a neighbouring atom into this vacancy. Including the start and end states, 9 images were generated along this pathway, which were then relaxed using the LAMMPS NEB package. For the ML/ML simulation, the seed atoms for the expensive potential region were a union of all atoms immediately surrounding the vacancy in the final and end states. These neighbours were identified using coordination analysis with a cutoff of 4.0~{\AA}, with all atoms that have 15 neighbours being selected. An additional 4.0~{\AA} of core region was added around these atoms, as well as 4.0~{\AA} of blending region. 6.0~{\AA} of buffer region was then included, which matches the cutoff of the cheap and expensive potentials. Region rebuilding was switched off, this is because dynamically changing the expensive potential region during a relaxation will often prevent convergence. For both the all-expensive and ML/ML NEB simulations, no energy tolerance was set (as total energies are not present in the ML/ML simulation) and the force tolerance was set such that $\|\mathbf{F}\|_{\infty} < 0.0005$~eV/{\AA}. Tighter tolerances than this would frequently fail to converge for the ML/ML simulation. If tighter tolerances are necessary, then we recommend switching to the all-expensive regime for the last steps of a relaxation.

\subsection{Si stretched bond}
To generate the structure, a $10\times 10 \times 10$ (8000 atom) periodic supercell of bulk Si was constructed and a bond in the centre of the structure was stretched an additional 0.1~{\AA} along its length and fixed using the rigid package in \texttt{LAMMPS} \cite{Kamberaj_2005}. This block was then pre-thermalised to 300 K in a 2 ps simulation with a Langevin thermostat using only the expensive potential. This thermalised initial structure was used as the starting point for all subsequent comparison simulations, in which the average force on this bond was recorded over 100 ps. For the all-expensive simulations, an $NVE$ ensemble was used. For the ML/ML simulations, the seed atoms were selected to be the atoms involved in the stretched bond, no blending region was used (abrupt force mixing), as well as a weak thermostat of time constant 1.0 ps. For all simulations a buffer region size of 6.0~{\AA} was used (which matches the cutoff of both potentials). The size of the core region was varied between simulations, as described in section.~\ref{sec:si_stretched_bond}. The expensive potential region was rebuilt about this seed atom every timestep.\\

\subsection{Diffusion coefficients}
\label{sec:diffusion}
To calculate the diffusion coefficients, individual defects were placed into periodic cells of size 16 $\times$ 16 $\times$ 16 unit cells ($\sim 8000$ atoms). Cells were heated to the target simulation temperature over 2~ps with a Langevin thermostat. For the Fe simulation, diffusion coefficients were measured at 800~K, 900~K, 1000~K and 1100~K. For W--He, diffusion coefficients were measured at 400~K, 600~K and 800~K. The reference simulations were then switched to NVE, whilst the ML/ML cells were switched to 'psuedo NVE' with a weak Langevin thermostat (damping parameter - 2.0 ps) applied only to the cheap potential region. For the Fe simulation, each data point consisted of the average of five diffusion coefficients derived from the mean square displacements from non-overlapping time-lags of $5\times1$~ns simulations. For the W--He simulations, each point was the average of twenty-five diffusion coefficients derived from the mean square displacements from non-overlapping time-lags from $25\times60$~ps simulations. In all cases, the error was estimated from the standard deviation in the averaged diffusion coefficients. For the W--He ML/ML simulation, the seed atom was selected to be the single He present in the simulation, and regions were rebuilt around this seed atom every timestep. For the Fe ML/ML simulation, seed atoms were selected by finding the most highly coordinated atoms (on average) in the simulation every 100 timesteps. For this, measurements of atomic coordination $Z$ (with a cutoff of 2.0~{\AA}) were taken every 10 timesteps, and these were averaged using \texttt{fix ave/atom}. New seed atoms were selected according to the criteria that $\langle Z \rangle >0.4$. Regions were rebuilt around these seed atoms every timestep. For the first 100 timesteps in the Fe ML/ML simulation, only the expensive potential was used. Both simulations used a core potential region of 6.0~{\AA} around the defect atoms, as well as a blending region of 4.0~{\AA}. For the Fe potential, a buffer width of 5.5~{\AA} was used, whilst for the W--He potential, a width of 6.0~{\AA} was used, matching the UF3 potential cutoff.

\section*{Data availability}
All the data generated and analysed in the current study is available in the v0.1 version of the ML-MIX repository released on Zenodo \cite{ml-mix-zenodo}.

\section*{Code availability}
All underlying code for this study is available in the ML-MIX GitHub repository \cite{ML-MIX}. 

\section*{Acknowledgements}
We thank Christoph Ortner for helpful discussions. We also thank Lakshmi Shenoy and Matthew Nutter for providing the Fe and W-He ACE potential fitting scripts. FB is supported by a studentship funded by the UK Engineering and Physical Sciences Research Council supported Centre for Doctoral Training in Modelling of Heterogeneous Systems, Grant No. EP/S022848/1. JRK acknowledges funding from the NOMAD Centre of Excellence funded by the European Commission under grant agreement 951786. We acknowledge the University of Warwick Scientific Computing Research Technology Platform for assisting the research described within this study. Some of the calculations were performed using the Sulis Tier 2 HPC platform hosted by the Scientific Computing Research Technology Platform at the University of Warwick. Sulis is funded by EPSRC Grant EP/T022108/1 and the HPC Midlands+ consortium. TDS gratefully acknowledges support from ANR grants ANR-19-CE46-0006-1, ANR-23-CE46-0006-1, IDRIS allocation A0120913455 and an Emergence@INP grant from the CNRS. 

\section*{Competing interests}
All authors declare no financial or non-financial competing interests. 

\section*{Contribution statement}
FB, TDS and JRK designed the research. FB developed the software, generated the data and performed the analyses. TDS and JRK provided supervision, guidance, and feedback throughout. FB wrote the paper, with input from TDS and JRK at all stages. All authors revised the paper and approved its final version.

\bibliography{sn-bibliography}

\begin{appendices}

\section{Expensive potential fitting parameters}\label{secA1}
Here we present the full set of potential fitting parameters for the Fe and W-He ACE potentials used in the study. The main fitting parameters are presented in table \ref{tab:potential_params}. Weights by config type for the Fe potential are shown in table \ref{tab:Fe_ACE_weights}. For the W--He ACE, we derive energy weights for configurations following the method suggested in \cite{Witt_2023} in which the energy weight on configuration $R$ is generated by 
\begin{equation}
    w_{R{}} = \frac{1000}{\sqrt{N_{R}}}
\end{equation}
where $N_{R}$ is the number of atoms in configuration $R$. For each configuration, the force weights were set to 10.0 and the virial weights were set to 0.0. Virials were not used in the fitting in order to avoid any errors introduced from underconverged (insufficient $K$-point density) DFT, as suggested by the dataset author \cite{Nutter_2024_supp}. The exception to this were the single W atom configurations, which had an energy weight of 4000.0, a force weight of 100.0 and a virial weight of 200.0.

\begin{table}[]
\caption{Fe and W--He ACE potential parameters.}
\begin{tabular}{l|ll}
 & Fe ACE & W--He ACE \\ \hline
Cutoff & 5.5 & 5.0 \\ 
Corr. order & 3 & 3 \\ 
Max. poly. deg. & 20 & 20 \\
Solver & BLR & BLR \\ 
\begin{tabular}[c]{@{}l@{}}Smoothness prior\\ strength\end{tabular} & 4 & -
\end{tabular}
\label{tab:potential_params}
\end{table}


\begin{table}[]
\caption{Fe ACE configuration weighting.}
\begin{tabular}{l|lll}
Config type & \begin{tabular}[c]{@{}l@{}}Energy\\ weight\end{tabular} & \begin{tabular}[c]{@{}l@{}}Force\\ weight\end{tabular} & \begin{tabular}[c]{@{}l@{}}Virial\\ weight\end{tabular} \\ \hline
default & 30.0 & 1.0 & 1.0 \\ 
slice\_sample & 80.0 & 0.1 & 1.0 \\ 
prim\_random & 80.0 & 0.1 & 1.0 \\ 
\end{tabular}
\label{tab:Fe_ACE_weights}
\end{table}


\section{Speedup and load balancing of mixed simulations}\label{secB1}
This section provides an investigation into the speedups for load balanced and non-load balanced ML-MIX simulations in silicon with a fixed expensive potential region size for (a) a fixed number of atoms and an increasing number of processors and (b) a fixed number of processors and an increasing number of atoms. It is shown that load balancing is most important when considering small domains ($<$30,000 atoms) and fewer MPI parallel processors ($<$15). It is shown that for small domains, the speedup variability between different numbers of processors is lessened by load balancing. 

\subsection{Method}
MD simulations were conducted with Si domains at 0 K (frozen atoms). Two sets of simulations were run, set (a) where the number of atoms were fixed and the number of processors were increased between 1 and 48, and set (b) where the number of processors was fixed and the number of atoms were increased between $8 \times 10^{3}$ and $10^{6}$. For each separate simulation domain, timing measurements were carried out with (i) only the 2\_10 ACE Si cheap potential, (ii) only the 4\_20 ACE Si expensive potential, (iii) load-balanced and (iv) non-load balanced ML/ML simulations containing both the expensive and cheap potentials. Within each simulation domain, the same number of timesteps was used for each timing measurement (i-iv), with the number selected such that the wall-time of the longest (the all-expensive) simulation was approximately 45 minutes. To build the expensive domain in each ML/ML simulation, single seed atoms were selected at the center of each cell, around which 6~{\AA} core regions and 6~{\AA} buffer regions were constructed. This meant that the number of expensive potential atoms was fixed across all ML/ML simulations, regardless of overall domain size. \\

For set (a), two atomistic domain sizes were chosen; a `small' domain of 8000 atoms, and a `large' domain of 262,144 atoms. For set (b), the number of processors was set at 27 for all domain sizes used. For each simulation domain investigated, the `upper-limit' speedup $S_{\mathrm{UL}}$ was computed with 
\begin{equation} \label{equation:speedup_theo}
    S_{\mathrm{UL}} = \frac{N S_{\mathrm{C/E}}}{N_{\mathrm{E}} S_{\mathrm{C/E}} + N_{\mathrm{C}}},
\end{equation}
where $N$ is the total number of atoms in a simulation domain, $N_{\mathrm{E}}$ and $N_{\mathrm{C}}$ are the number of expensive and cheap atoms (including those in both buffer regions), and $S_{\mathrm{C/E}}$ is the measured speedup of the all-cheap simulation over the all-expensive simulation in the domain of interest. \\

Simulations were carried out on Dell PowerEdge C6420 compute nodes each with 2 x Intel Xeon Platinum 826 (Cascade Lake) 2.9 GHz 24-core processors; 48 cores per node; 192 GB DDR4-2933 RAM per node; 4 GB RAM per core.

\subsection{Load balancing strategies}
Load-balancing is performed via the \texttt{fix balance} command in \texttt{LAMMPS}. If the \texttt{time} keyword is specified \texttt{LAMMPS} attempts to dynamically decompose the overall domain into subdomains of equal computational cost. \texttt{LAMMPS} has two strategies to decompose domains - `brick' and `tiled'. With the `brick' strategy, each individual sub-domain is cuboidal, and is constrained to be joined at the corners. With the `tiled' strategy, each domain is also cuboidal, but not necessarily constrained to connect at corners. For more details, please refer to the \texttt{comm\_style} page of the \texttt{LAMMPS} documentation \cite{comm_style}. Within the \texttt{fix balance} command, two algorithms are available; the \texttt{shift} algorithm, compatible with both the `brick' and `tiled' decomposition strategies, and the \texttt{rcb} algorithm, compatible with just the `tiled' decomposition strategy. For more detail on these algorithms, please refer to the \texttt{fix balance} page of the \texttt{LAMMPS} documentation \cite{fix_balance}. Each load balancing strategy was investigated, and it was found for a simple domain with one central expensive region, the \texttt{shift} algorithm performed marginally better when domains were small and the \texttt{rcb} algorithm performed marginally better when domains were large. Throughout this paper, the \texttt{shift} algorithm is used with the brick domain decomposition strategy. We recommend users test each load-balancing strategy to determine which works best for their system.

\subsection{Results and discussion}
\subsubsection{Fixed atoms, increasing processors}
\begin{figure*}
    \centering
    \includegraphics[width=0.8\linewidth]{GP_fixed_atom_speedup_plots.png}
    \caption{Speedup of ML/ML simulations over all-expensive reference simulations on an increasing number of processors for two domain sizes. In each case, the upper bound speedup (green line) is determined from equation \ref{equation:speedup_theo}. Left: Speedup on a small (8000 atom) domain. For this domain size, one can only attain near-upper bound speedups for small numbers of processors if a load-balancing strategy is used. The effect of load balancing is very pronounced, as without it all expensive atoms frequently end up on one sub-domain, creating simulation bottle-necks. Right: Speedup on a large (262,144 atom) domain. At this domain size, one attains a near upper-bound speedup for any number of MPI parallel domains, and load balancing has a relatively minor effect. All trend-lines are fitted with Gaussian process regression.}
    \label{fig:fixed_atom_load_balancing}
\end{figure*}
The results for simulation set (a) are displayed in Fig.~\ref{fig:fixed_atom_load_balancing}. For the smaller (8000 atom) domain, it can be seen that with load balancing, a near-upper-bound speedup can be attained for a number of processors below $\sim$15. Above this, the load balanced simulation falls significantly below the upper-bound due to communication overheads taking up a significant fraction of the runtime. Without load balancing, the performance is on average significantly worse, but varies greatly between the number of processors chosen. Particularly poor performances are due to all of the expensive atoms landing on a single parallel domain. For the larger (262,144 atom) domain, it can be seen that near-upper bound speedup is approximately attained for any processor number, regardless of load-balancing. This arises due to every individual subdomain always being far larger than the expensive potential region. 

\subsubsection{Fixed processors, increasing atoms}
\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{speedup_gp_fixed_proc.png}
    \caption{The measured speedup of the mixed simulation over the all expensive simulation on 27 processors, for increasing numbers of atoms. The green line indicates the maximum possible speedup (with no overheads), computed from equation \ref{equation:speedup_theo}. It can be seen that for small numbers of atoms ($<$30,000) load balancing is important, and for large number of atoms ($\sim 10^{6}$) the speedup tends toward the upper bound. Trend lines have been fitted with Gaussian process regression.}
    \label{fig:load_balance_fixed_proc}
\end{figure}
Results for simulation set (b) in which the simulation domain size is increased at a fixed number of processors (27) is shown in Fig.~\ref{fig:load_balance_fixed_proc}. For smaller atomic domains ($<$30,000 atoms), it can be seen that load balancing is important, providing a considerable speedup. As the size of the domain gets larger, load-balancing becomes less important, and the overall speedup tends toward the overhead-free upper limit. 


\section{Impact of constrained fitting}\label{secC1}
In this paper, the cheap potentials have been constrained to enforce elastic constant matching. In this section, we show that matching the elastic constants between our potentials leads to reduced errors in ML-MIX relaxed structures for less than 3\% strain deviations from the bulk. 

\subsection{Methods}
A periodic $10 \times 10 \times 10$ (8000 atom) bulk Si structure was constructed and sheared in the $xy$ to directions to strains between 0 and 7\%. For each structure, a joint ML/ML relaxation was performed using ML-MIX. The central atom and the surrounding 6~{\AA} were modeled expensively, with the remainder of the atoms were with the constrained or unconstrained Si 2\_10 cheap potentials in two separate investigations. For the relaxation, a blending region of 6.0~{\AA} was used, as well as a relatively loose tolerance of $\|\mathbf{F}\|_2 < 10^{-3}$~eV/{\AA}. Smaller tolerances than this would frequently fail to converge. The strain error $Du$ was then found for each structure as
\begin{equation}
    Du = \|\nabla u - \nabla u_{\mathrm{ref}}\|_2
\end{equation}
where $u$ is the displacement field from the ML/ML relaxed structure and $u_{\mathrm{ref}}$ is the displacement field from the relaxed all-expensive reference.

\subsection{Results and discussion}
\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{just_eshelby_error_fig.png}
    \caption{The strain error norm Du measured for sheared and relaxed bulk Si using an ML/ML simulation compared to the all-expensive simulation for different applied shear strain. The ML/ML simulation contains a central 6~{\AA} sphere of the expensive potential surrounded by the cheap potential. $Du$ is far greater for small strains when using the unconstrained cheap potential, as the mismatched elastic constants to the expensive lead to Eshelby-inclusion type strain fields.}
    \label{fig:constrained_potentials}
\end{figure}

Fig.~\ref{fig:constrained_potentials} shows the strain error in the ML/ML relaxed structures. The spatial distribution of the error in the strain fields matches that expected from an Eshelby inclusion, and it can be seen that for very small strains $\epsilon_{xy}<0.005$, the constrained potential exhibits very little error in the strain whilst the constrained potential error increases immediately. The constrained potential continues to have lower strain error up until $\epsilon_{xy}=0.03$.

\section{Energy conservation}\label{secD1}
A fundamental limitation of force mixing is a lack of energy conservation. Whilst this has been noted in previously \cite{Bernstein_2009}, the features in a force-mixed simulation that may worsen or improve energy conservation are unclear. Here we present a brief investigation where we test the impact on energy conservation of (i) having a larger interface region between potentials, (ii) having a more flexible cheap potential and (iii) introducing a larger blending region between potentials. Whilst findings presented here are derived from ML/ML simulations using ML-MIX, the findings are applicable to force-mixing simulations more generally, including QM/MM simulations. \\

\subsection{Methods}
A periodic cube of Si was constructed which matches that described in section \ref{sec:si_stretched_bond}. The spherical central region of the domain (around the fixed stretched bond) was simulated expensively, with the remainder of the domain modeled cheaply. The expensive potential was the same Si ACE used in section \ref{sec:si_stretched_bond}. Three different cheap ACE potentials were used, fit according to the constrained fitting procedure outlined in section \ref{sec:constrained_fit}. The key parameters of these potentials are displayed in table \ref{tab:eng_consv_pot_params}. To investigate energy drift in the simulation set-up, a 50~ps, 300~K ML-MIX \texttt{LAMMPS} MD simulation was performed with a timestep of 1 fs. As the total energy of a force-mixed simulation is not defined, the energy was measured through evaluating snapshots output every ps with just the expensive potential. \\

\begin{table}[]
\caption{Si cheap potential parameters.}
\begin{tabular}{l|lll}
 & 2\_10 & 2\_15 & 3\_15 \\ \hline
Cutoff & 6.0 & 6.0 & 6.0 \\
Corr. order & 2 & 2 & 3 \\
Max. poly. deg. & 10 & 15 & 15 \\ 
\end{tabular}
\label{tab:eng_consv_pot_params}
\end{table}

Two separate investigations were conducted for each cheap potential. (a) For a set-up with no blending region (abrupt force-mixing) the size of the spherical expensive potential region was varied between 4 and 10~\AA, and (b) for a fixed 10~{\AA} core + blending region, the amount of blending region is varied between 4 and 6~{\AA}.

\subsection{Results and discussion}
\subsubsection{Size of potential-potential interface}
\begin{figure*}
    \centering
    \includegraphics[width=0.9\linewidth]{combined_energy_fig.png}
    \caption{Energy drift over time for an abruptly mixed ML/ML simulation of bulk Si, using the 2\_10 cheap potential. The size of the expensive region is varied between 4 and 10~{\AA}. Left - the raw energy change for each simulation, showing that a larger expensive potential region causes a greater rate of energy increase. Right - energy change normalised by spherical interfacial contact area between potentials, showing that for a given two potentials in abrupt contact the rate of energy change per unit of contact area (energy flux) is constant.}
    \label{fig:energy_drift}
\end{figure*}

The energy over time for the abruptly force-mixed ML/ML simulations are shown on the left of Fig.~\ref{fig:energy_drift}. Two facts are discernible from these plots: the energy drifts are approximately linear, and larger expensive potential regions lead to greater energy gain. The right hand side of Fig.~\ref{fig:energy_drift} shows the energy gains normalised by the (approximately spherical) surface interface area between potentials. Under this normalisation, the curves collapse onto a single straight line, giving us the result that for two given potentials and a given blending regime the rate of energy increase per unit surface contact area is approximately constant. The gradient of this line can be thought of as the energy flux from the force mixing contact surface into the material caused by the local violation of Newton's 3rd law.

\subsubsection{Flexibility of cheap potential}
\begin{figure*}
    \centering
    \includegraphics[width=0.9\linewidth]{combined_energy_fig_pot_and_blend.png}
    \caption{Left - energy flux for abruptly mixed ML/ML simulations with different cheap potentials of increasing complexity. More complex cheap potentials lead to orders of magnitude lower energy drift. Right - energy flux for ML/ML simulations with the 2\_10 potential with different blending widths. The blue bar corresponds to abrupt mixing, whilst the other bars correspond to increasing amounts of blending. Increasing the blending width decreases the energy flux from the potential contact surface.}
    \label{fig:energy_pot_and_blending}
\end{figure*}
Energy fluxes from ML/ML simulations of three different cheap potentials are shown on the left-hand side of Fig.~\ref{fig:energy_pot_and_blending}. Note that as the cheap potential complexity increases, the energy flux from the internal potential/potential contact surface decreases by orders of magnitude. The rationale for this is straightforward; more complex cheap potentials with greater numbers of basis functions have the flexibility to better approximate the local potential energy surface of the expensive potential, causing the violations of Newton's 3rd law to be lesser in magnitude.

\subsubsection{Width of blending region}
The right-hand side of Fig \ref{fig:energy_pot_and_blending} shows how adding a blending region in the ML-MIX simulation can decrease the energy flux. The blue bar corresponds to abrupt mixing, and it can be seen that as core region is swapped out for blending region the amount of energy drift in the simulation decreases.


\end{appendices}

\end{document}

\typeout{get arXiv to do 4 passes: Label(s) may have changed. Rerun}
