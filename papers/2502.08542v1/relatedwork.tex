\section{Related Work}
\label{sec:related}
The topics of \textbf{fairness and accountability in automated decision-making (ADM) systems} have garnered significant attention among scholars and practitioners due to their increasingly pervasive deployment in multiple domains \citep{chiusi2020automating} and their potential social impact \citep{araujo2020ai}. Research in this area has extensively explored pre-, in-, and post-processing techniques to mitigate biases in data and modeling pipelines (for comprehensive reviews see, for instance, \cite{mehrabi2021survey, pessach2022review}), contributing to the promotion of fairness in algorithmically supported decision systems. However, studies have demonstrated that fair algorithms alone cannot guarantee fairness in practice~\citep{goel2021importance, jeong2022fairness}, and aspects as interpretability and fairness are inherently interdependent factors adding complexity to their operationalization in real-world AI systems~\citep{dodge2019explaining, schoeffer2022relationship, ramachandranpillai2023fairxai, jain2020biased}.

The multifaceted nature of fairness is further influenced by cultural and social contexts, complicating efforts to develop fairness frameworks that extend beyond pre-defined universal metrics~\citep{selbst2019fairness}. Moreover, some authors argue that, while fairness-aware methods often succeed in reducing biases in model outputs, they frequently fail to address systemic inequities and, for this reason, approaches that more effectively incorporate diverse stakeholder interests and account for broader societal impacts are needed to promote more equitable social outcomes~\citep{gerdes2022participatory}.

Especially in dynamic and interactive decision-making settings, where multiple actorsâ€™ interests come into play, \textbf{multi-agent systems} may offer a promising framework. Contributions to multi-agent reinforcement learning~\citep{zimmer2021learning} and multi-agent multi-armed bandit frameworks~\citep{hossain2021fair} leverage, for instance, welfare functions to foster fairness in multi-agent decision settings. In this context, Wen et al.~\citep{wen2021algorithms} advance these efforts by integrating feedback effects into Markov decision processes, enabling the modeling of dynamic, long-term impacts of decisions on fairness outcomes, as demonstrated through a loan approval scenario. Despite their valuable contribution to the integration of the presence of multiple actors in ADM systems, though, most approaches rely on predefined fairness definitions and require specific problem structures, limiting their adaptability to evolving stakeholder preferences and use-case-specific requirements.

Against this backdrop, \textbf{Participatory AI} has emerged as a significant paradigm for integrating diverse stakeholder perspectives throughout the AI lifecycle, offering opportunities to foster context-dependent fairness and promote accountability \citep{birhane2022power}. This paradigm emphasizes collaboration and co-creation, promoting inclusivity across both technical and non-technical domains~\citep{hossain2021towards, berditchevskaia2021participatory}. Contributions in this area span diverse fields, including healthcare~\citep{donia2021co}, judicial systems~\citep{barabas2020studying}, civic engagement~\citep{arana2021citizen}, philanthropy~\citep{lee2019webuildai}, and urban planning~\citep{quan2019artificial}. More technical applications include collective debiasing~\citep{chan2024group}, collaborative debugging~\citep{nakao2022toward}, ranking with partial preferences~\citep{cachel2024prefair} and web-based tools for democratizing ML workflows~\citep{zhang2023deliberating} . Collectively, these contributions reflect what has been described as a "participatory turn" in AI design~\citep{delgado2023participatory}.

However, current challenges such as the technical complexity of AI systems, structural and social barriers to participation, and power asymmetries hinder broader adoption and expose some applications to the risk of what has been described as "participation washing"~\citep{sloane2022participation}. Consequently, the scalability and generalizability of Participatory AI remain limited~\citep{delgado2023participatory}, compounded by the lack of flexible, generalizable frameworks that can be applied to a wide range of use cases.