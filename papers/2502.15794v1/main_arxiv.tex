%%% Elias: I commented out lines 548 and 549 for arxiv; bring back for ICML camera ready if accepted

% change log feb.16:
% refined key contributions in intro 
% updated related works, adding more citations
% updated section 3.4 to discuss possible extensions
% updated conclusions to talk about training datat sel-improvement

%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables


% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}
\usepackage{multirow}



% remove at submission
\usepackage{tcolorbox}
\usepackage{todonotes}
\makeatletter
\define@key{todonotes}{EK}[]{%
    \setkeys{todonotes}{author=EK,color=green}}%
\definecolor{lightred}{RGB}{255,71,76}
\define@key{todonotes}{WL}[]{%
    \setkeys{todonotes}{author=WL,color=orange}}%
\define@key{todonotes}{WX}[]{%
    \setkeys{todonotes}{author=WX,color=cyan}}%
\define@key{todonotes}{SS}[]{%
    \setkeys{todonotes}{author=SS,color=yellow}}%

\newcommand{\methodname}{ConsFormer}
% CSPFormer

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
% \usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Self-Supervised Transformers as Iterative Solution Improvers for Constraint Satisfaction}

\begin{document}

\twocolumn[

% key words: Learning to Search, Iterative/Local Search, Self-supervised/Distant Supervised,
% Transformer, Constraint Satisfaction

% \icmltitle{Constraint Satisfaction with Single-Step Self-Supervised Transformers}
% \icmltitle{Self-Supervised Transformers for Iterated Refinement Search}

% Constraint Satisfaction with Single-Step Self-Supervised Transformers
% \icmltitle{Constrained Satisfaction with Self-supervised Transformer for Iterative Solution Search}
% \icmltitle{Learning Neural Local Search for Constraint Satisfaction \\ with Self-Supervised Transformers}

% \icmltitle{Learning to Iteratively Search for Constraint Satisfaction \\ with Self-Supervised Transformers}

% \icmltitle{A Transformer for Constraint SatisfactionLearning to Search for Constraint Satisfaction: Single-step Solution Improvement}

% \icmltitle{Self-Supervised Transformers as Solution Improvers for Constraint Satisfaction}
\icmltitle{Self-Supervised Transformers \\ as Iterative Solution Improvers for Constraint Satisfaction}


% possible names of our model:
%  \methodname
%  CPFormer
% S^4 Transformer




% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Yudong W.~Xu}{uoft}
\icmlauthor{Wenhao Li}{uoft}
\icmlauthor{Scott Sanner}{uoft,vector}
\icmlauthor{Elias B.~Khalil}{uoft,vector,scaleai}
%\icmlauthor{}{sch}
% \icmlauthor{Firstname8 Lastname8}{sch}
% \icmlauthor{Firstname8 Lastname8}{yyy,comp}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{uoft}{Department of Mechanical \& Industrial Engineering, University of Toronto}
\icmlaffiliation{vector}{Vector Institute for Artificial Intelligence}
\icmlaffiliation{scaleai}{Scale AI Research Chair in Data-Driven Algorithms for Modern Supply Chains}



\icmlcorrespondingauthor{Yudong Xu}{wil.xu@mail.utoronto.ca}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
We present a Transformer-based framework for Constraint Satisfaction Problems (CSPs). 
CSPs find use in many applications and thus accelerating their solution with machine learning is of wide interest. 
Most existing approaches rely on supervised learning from feasible solutions or reinforcement learning, paradigms that require either feasible solutions to these NP-Complete CSPs or large training budgets and a complex expert-designed reward signal.
To address these challenges, we propose \methodname, a self-supervised framework that leverages a Transformer as a solution refiner. \methodname{} constructs a solution to a CSP iteratively in a process that mimics local search. Instead of using feasible solutions as labeled data, we devise differentiable approximations to the discrete constraints of a CSP to guide model training. Our model is trained to improve random assignments for a single step but is deployed iteratively at test time, circumventing the bottlenecks of supervised and reinforcement learning. Our method can tackle out-of-distribution CSPs simply through additional iterations.
% \vspace{-2mm}
% todo, talk about the set of work that use GNN and how it is difficult to generalize to non-graph based problems.
% should we mention that a) our model mimics large neighbourhood search? b) we represent the CSPs using CP which we think is more suited for Transformer.
\end{abstract}

\section{Introduction}


\begin{figure*}[t]
    \centering
    \includegraphics[width=0.98\linewidth]{figures/solution-showcase.jpg}
    \caption{\methodname{} models construct solutions for Sudoku (Top) and Graph Coloring (Bottom). The models are trained with a single step from randomly initialized assignment. At test time, a~\methodname{} model is invoked iteratively until a feasible solution is found or an iteration limit is met.}
    \label{fig:solution-example}
\end{figure*}


Constraint Satisfaction Problems (CSPs) are fundamental to many real-world applications such as scheduling, planning, and resource management. However, solving CSPs efficiently in practice remains a significant challenge due to their NP-complete nature. Traditional solvers based on constraint propagation and backtracking search can be computationally expensive, especially for large problem instances. This has motivated the exploration of learning-based approaches as fast neural heuristics for CSP solving~\cite{khalil2017learning, neurosat, bengio2021machine}.

Most existing learning-based methods use either supervised or reinforcement learning (RL). Supervised approaches train models on datasets of CSP instances with feasible solutions as labels, a paradigm that is laden with drawbacks. First, generating labels for CSP instances requires solving them, which makes it challenging to generate the large quantities of data often needed to train a model that generalizes well. This is especially true for hard instances that traditional solvers struggle to solve quickly. Second, CSPs often have multiple feasible solutions~\cite{aimodernapproach}, making it difficult to apply supervised learning unambiguously when there are many possible labels for the same input. RL-based methods, on the other hand, search for solution strategies through black-box optimization of a reward function, often requiring extensive computing resources. Designing reward functions that capture solution feasibility across different constraints is difficult yet crucial to success in RL~\cite{arulkumaran2017deep}. These limitations hinder the generalization and scalability of learned heuristics.

To address these challenges, we introduce \methodname{}, a Transformer-based self-supervised framework for solving CSPs. \methodname{} learns to iteratively refine variable assignments through a self-supervised training paradigm that approximates discrete constraints with continuous differentiable penalty functions. Our model is trained to improve an initial random assignment in a single refinement step, but is applied iteratively at test time. While a single refinement step may not yield a feasible solution, a sufficiently large number of improving iterations (on average) does. Examples of \methodname{} solutions are shown in \Cref{fig:solution-example}. 

Transformers provide a natural fit for this approach due to their strong generalization capabilities and their ability to process structured data efficiently~\cite{lewkowycz2022solving, achiam2023gpt}. They are particularly effective at learning with tokenized inputs, making them well-suited for combinatorial problems formulated in the Constraint Programming paradigm~\cite{cp-handbook}. Furthermore, recurrence has been shown to enhance the generalization abilities of Transformers~\cite{abacus-embedding, loopedtransformers}, reinforcing their suitability for our setting.

Our iterative solution improvement strategy enables \methodname{} to generalize beyond its training distribution, effectively solving out-of-distribution (OOD) CSP instances simply by performing more refinement steps. We evaluate \methodname{} on a diverse set of CSP problems, including Sudoku, Graph Coloring, and Nurse Scheduling, demonstrating its ability to generalize across problem domains. 

% We contribute these following highlevel findings
The following high-level findings summarize our contributions:
\begin{itemize}
    \item[--] \textbf{Self-supervised learning can be applied to solve CSPs.} We show that a loss function that combines differentiable penalties for the violation of the discrete constraints of a CSP can guide model training without the need for labels.
    \item[--] \textbf{Decision variable positional information is key for Transformer learning.} We show that by representing variable positional information as absolute and relational positional encodings in the Transformer, we enable solution improvement in variable space. 
    \item[--] \textbf{\methodname{} can generalize when trained to perform solution improvement.} While trained to perform a single improvement step, \methodname{} generalizes to out-of-distribution instances and achieves state-of-the-art results for generalizing to OOD tasks in Sudoku, outperforming all existing neural methods.
\end{itemize}


% Transformers is good at generalization
% Transformers is good at learning with tokens.
% We formulate the CSP problems using the Constraint Programming paradigm.
% Recurrency has been shown to enable generalization in Transformers~\cite{universal-transformer, takase2021lessons}, 


% We show how a CSP can be transformed as inputs to the Transformer.

% We show that our model can learn to solve CSPs without labels.

% Remarkably, our model trained on a single step is able to generalize.



\section{Background}

\subsection{Constraint Satisfaction and Programming}

A {Constraint Satisfaction Problem (CSP)} is a mathematical model used to represent problems that involve finding values for a set of variables subject to (possibly discrete and non-linear) constraints. Formally, a CSP is defined as a tuple \( (X, D, C) \), where \( X = \{x_1, x_2, \dots, x_n\} \) is a finite set of variables, \( D = \{D_1, D_2, \dots, D_n\}, D_i\subset\mathbb{Z}\;\forall i\in[n] \) represents the discrete domains of these variables, and \( C = \{c_1, c_2, \dots, c_m\} \) is the set of constraints, where each constraint \( c_i \) is defined over a subset of variables \( X_i \subseteq X \), restricting the values that can be simultaneously assigned to them. The goal in solving a CSP is to assign to each variable a value from its domain such that all constraints in \( C \) are satisfied.

Constraint Programming (CP)~\cite{cp-handbook} is the study of mathematical models and solution algorithms for CSPs. CP uses highly expressive~\textit{global constraints}~\cite{globalconstraints} that involve multiple variables and are designed to capture common constraint structures that appear in a wide range of real-world applications. One prominent example of a global constraint is the \textsc{AllDifferent} constraint~\cite{alldifferent}, which ensures that a subset of the variables take on distinct values. 



\subsection{Related Work}

\paragraph{Constraint solving with supervised learning.}
Supervised learning has been extensively applied to constraint solving. For example, Pointer Networks~\cite{ptrnet} are used for the sequential generation of combinatorial problems involving permutations such as the traveling salesperson problem. \citet{rrn} propose a graph-based recurrent network to model CSPs, effectively leveraging the graph structure to refine variable assignments iteratively. SATNet~\cite{satnet} differentiates through semidefinite programming relaxations in a supervised setting to handle logical constraints. \citet{ired} introduce a method for iterative reasoning through energy diffusion, focusing on progressive refinement of solutions. More recently, \citet{iclr23Transformercsp} proposed a recurrent Transformer architecture that reuses the same Transformer weights across multiple steps, iteratively refining inputs before projecting them to the final outputs. The common drawback for supervised approaches is the need for labels, which is not easy to generate for many large CSP problems. Additionally, for problems with more than one unique solution, label generation becomes non-trivial. 

% \todo[EK,inline]{Need to say why we are better/different than all these methods.}

% Various works exist that utilizes supervised learned to solve constrained reasoning problems. For example, Pointer Networks utilizes the structure of the problems specifically to solve combinatorial tasks\cite{ptrnet}. \citet{rrn} introduced a graph-based recurrent approach to solving CSPs. SATNet is a differentiable MAXSAT solver that learns the parameters of the SDP relaxation for the MAXSAT in a supervised setting~\cite{satnet}. \citet{ired} proposes to iteratively solve reasoning problems through energy diffusion. \citet{iclr23Transformercsp} introduced a recurrent-transformer architecture that reuses a same set of transformer weights to repeatedly process a set of inputs, before projecting them to produce an output. 



% In ANY-CSP they say: “A fundamentally different approach considers soft relaxations of the underlying problems which can optimized directly with SGD. Examples of this concept are PDP (Amizadeh, Matusevych, and Weimer 2019) for SAT and RUNCSP (Tönshoff et al. 2021) for all binary CSPs with fixed constraint language. These architectures can predict completely new solutions in each iteration but the relaxed differentiable objectives used for training typically do not capture the full hardness of the discrete problem."

\paragraph{Constraint solving without labels.}

% Existing approaches for learning to solve CSPs without labels mostly rely on reinforcement learning (RL). 
A common recipe for Reinforcement Learning (RL) in constraint solving is to express the problem with a graph  which is then processed using Graph Neural Networks (GNN). The GNN's weights are updated using RL based on a reward function expressing an objective function and/or constraint satisfaction~\cite{khalil2017learning, chalumeau2021seapearl, li2024gsatbench, boisvert2024towards}. For example, \citet{anycsp} converts a CSP instance into a tripartite variable-domain-constraint graph which is then solved using a GNN trained by RL. \citet{rltsp} use a Transformer architecture to learn discrete transformation steps with RL for routing problems. However, RL approaches require significant computational resources for training, as well as an expertly designed reward signal for each problem. 


% \citet{khalil2017learning} represents combinatorial optimization problems as graphs and use GNN and RL to learn heuristics solvers. 

% However, RL approaches requires high computational resources for training, as well as an expertly designed reward signal for each problem.

Non-RL based methods require addressing the non-differentiability of discrete constraints. \citet{injectconstraints} use the straight-through estimator~\cite{bengio2013estimating} for logical constraints and \citet{bo-mip} explore a similar approach for mixed-integer non-linear programs. \citet{toenshoff2021graph} devise a continuous relaxation for binary constraints (i.e., constraints involving two variables) which are used to guide a recurrent GNN to generate solutions; this approach is limited in applicability as many CSPs of interest have non-binary constraints. \citet{clrdrnets} design continuous relaxations for some constraint classes in conjunction with a reconstruction loss to tackle a visual Sudoku problem; it is unclear how their architecture can be adapted to CSP solving in general. 
% while this approach can extend to 

% and \citet{bo-mip} explores a similar approach in solving mixed-integer non-linear programs. 
% Our advantage over ANYCSP: much faster to train (they use RL and takes 24-48 hours, while we produce good models within a few hours). We can also compute in batches, making our approach much faster during inference.


% A concurrent work investigated 

\paragraph{Continuous relaxation of discrete functions.}
Continuous relaxations have been used effectively to approximate discrete functions. For example, T-norm has been widely implemented as a continuous approximation for discrete binary logic operations~\cite{ddlg,tnorm, jaxplan}. \citet{petersen2021learning} introduced continuous relaxations for discrete algorithms, such as if-statements and while-loops. Similarly, \citet{drn} proposed entropy-based relaxations to handle discrete constraints.

% T-norm has been effectively implemented as continuous approximation for discrete binary logic operations~\cite{jaxplan, ddlg, tnorm}. \cite{petersen2021learning} introduces continuous relaxation for discrete algorithms such as if statements and while loops. \cite{drn} introduces entropy based relaxations for discrete constraints. 

\paragraph{Recurrency for generalization.}
The incorporation of recurrency has been shown to improve a model's generalization. \citet{recurrent-algo2022} implement recurrent ResNet blocks to solve simple logic puzzles and show that increasing recurrent steps at test-time allows generalization to harder unseen tasks. Recurrency was introduced to the Transformer architecture by sharing weights across Transformer layers~\cite{universal-transformer, takase2021lessons}, yielding improved generalization capabilities on arithmetic and logic-based string manipulation tasks \cite{abacus-embedding, loopedtransformers}. Our method differs from the existing work as recurrency is only introduced during test-time deployment.




\section{\methodname: a Single-Step Self-Supervised Transformer}

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/architecturev3.jpg}
    \caption{\methodname: a Single-Step Self-Supervised Transformer for CSP. A CSP instance is transformed into a set of input embeddings composed of the variable value encoding, index-based Absolute Position Encoding, and a selected update set embedding indicating the variables to be updated. The input is processed by $L$ Transformer layers, incorporating the binary constraint graph as Relative Positional Encodings for attention. The output values are used to compute a differentiable self-supervised loss on constraint violation. Although trained to perform one step of solution improvement, \methodname{} can be deployed iteratively at test time, improving the odds of solving instances never seen during training.}
    \label{fig:architecture}
\end{figure*}


% 4 sections:
% how to represent the input
% how does the model process the input
% how is the loss computed 
% how is the model deplyed at test time.

We introduce \methodname, a single-step Transformer trained with self-supervision. Given an assignment of values to variables (hereafter referred to as~\textit{variable assignment}), \methodname{} attempts to generate a refined variable assignment that is closer to satisfying the constraints of the input CSP. An overview of our model is shown in~\Cref{fig:architecture}.

\Cref{sec:input} presents a Transformer-compatible representation of variable assignments. \Cref{sec:architecture} details the Transformer design and how it generates an updated assignment. \Cref{sec:loss} focuses on the self-supervised training process. Finally,~\Cref{sec:testtime} discusses how the model, trained for single-step solution refinement, can be deployed iteratively at test time to solve CSPs.

\subsection{Input Representation}
\label{sec:input}

The input to the model includes the current variable assignment (which may be infeasible), variable indices, and a binary relational constraint graph indicating the participation of a variable in a constraint. We adapt the Transformer architecture to process a CSP instance by encoding these elements as follows.
\paragraph{Variable assignments as tokens.}  
Let $X = \{x_1, x_2, \dots, x_n\}$ be the set of variables in a CSP, each of which has a finite domain $D_i$. A variable assignment $x_i = v$, $v \in D_i$, is treated as a token. A learnable embedding $\mathbf{e}(v)$ is assigned to each unique value $v \in \bigcup_{i=1}^{n}D_i$. The input variable assignment, represented as $\mathbf{X} = \{x_1 = v_1, x_2 = v_2, \dots, x_n = v_n\}$, forms the input token set to the Transformer. Thus, the input embedding set is given by 
\begin{equation}
\label{eq:token_embed}
    \mathbf{E} = \{\mathbf{e}(v_1), \mathbf{e}(v_2), \dots, \mathbf{e}(v_n)\}.
\end{equation}
In this paper, we focus on problems where all variables share the same domain $D$.


\paragraph{Representing variable indices with Absolute Positional Encoding.}  
Transformers use Absolute Positional Encoding (APE) to represent the position of tokens in a sequence. For CSPs, we use APE to encode the indices of variables. If the indices of a variable $x_i$ are multi-dimensional, we concatenate the positional encodings for each dimension. Specifically, let $x_{i_{1}, i_{2}, \dots, i_{k}}$ denote a variable with $k$-dimensional indices $(i_1, i_2, \dots, i_k)$. The APE for this variable is computed as:  
\begin{equation}
\label{eq:ape}
    \text{APE}(x_{i_{1}, i_{2}, \dots, i_{k}}) = \text{Concat}(\text{PE}(i_1), \text{PE}(i_2), \dots, \text{PE}(i_k)),
\end{equation}
where $\text{PE}(i_k)$ is the positional encoding for dimension $k$. For example, in Sudoku, a variable $x_{12}$ would have an APE formed by concatenating the encodings for row 1 and column 2. This approach is inspired by the APE design in Vision Transformers~\cite{vit, vitarc}.

\paragraph{Constraint relations as Relative Positional Encoding.}  
A Relative Positional Encoding (RPE) is typically used by Transformers to capture the positional relationship between tokens independently of their absolute positions in a sequence. For CSPs, we use RPE to encode the constraint relationships between variables. Specifically, we represent the CSP constraints as a binary constraint graph $\mathbf{G} = (V, E)$, where $V = \{1, 2, \dots, n\}$ corresponds to the variables and $E$ contains edges between pairs of variables that participate together in at least one constraint of the CSP.

The RPE is incorporated into the attention mechanism by modifying the attention logits. Let $\mathbf{A}_{ij}$ denote the attention logit between variables $i$ and $j$. The modified logits are computed as:  
\[
\mathbf{A}_{ij} = \mathbf{A}_{ij} + \text{RPE}(i, j),
\]
where 
\begin{equation}
\text{RPE}(i, j) = c\cdot\mathbb{I}[(i,j)\not\in E],
% \text{RPE}(i, j) =
% \begin{cases} 
%  0 & \text{if } (i, j) \in E, \\
%  c & \text{if } (i, j) \notin E,
% \end{cases}
\label{eq:rpe}
\end{equation}
and $c\leq 0$ is either a constant hyperparameter or a learned parameter. Setting $c$ to $-\infty$ effectively masks the attention between variables that do not have any constraints in common. The inclusion of the constraint graph via the RPE helps the model identify variable pairs that have a strong effect on each other's assignments. 
% Notably, our framework supports alternative implementations of constraint relations in RPE beyond this masking mechanism.


% We adapt the Transformer architecture to process a CSP instance as an input as follows.

% - Variable assignments are treated as tokens and a token embedding is learned for each value in the variable's domain. The current set of variable assignments are used as the input to the Transformer. 

% - Variable-index encoded as Abasolute Positinal Encoding. 
% Abasolute Positinal Encodings are used by Transformers to encode the exact position of a token within a sequence. We utilize APE to encapsulate the indices of the variables. If a variable has higher dimensional indices, we concatanate the APE for each of the dimension inspired by the APE implementation for Vision Transformers\cite{vit, vitarc}. For example, for Sudoku, variable $x_{12}$ will have an APE as the concatenation of 

% - Constraint-relations as Relative Positional Encoding. Relative Positional Encoding is used in Transformers to encode relative positional information between two tokens that is independent of their exact position. We therefore leverage RPE to inform \methodname{} the relative relations between variables. Specifically, we construct a $n \times n$ binary constraint graph as part of the input, and adding RPE based on the graph to the attention logits before applying softmax.  
% We found applying a large negative weight to the pairs of variables not sharing a constraint to be effective, this can effectively be thouht of as applying attention masking, although our framework allows for other implementation of constraint relations as RPE.



\subsection{A Single-Step Transformer Architecture}
\label{sec:architecture}

Our model takes the inputs described in the previous section and outputs a new variable assignment. Below, we outline the key components of the Transformer architecture.

\paragraph{Variable subset selection.}  
Inspired by the~\textit{local search} principle, we posit that small modifications to a variable assignment are preferable as it is easier to assess their impact on constraint satisfaction. Our model essentially performs a~\textit{stochastic} local search by randomly selecting a subset $S\subset X$ of the variables to update. We do this by flipping a biased coin with probability of selection $p$ for each variable, where $p$ is a hyperparameter. A special learned embedding $\mathbf{e}_s$ is added to the variables in $S$. The Transformer's output for the variables in $S$ is used to update the assignment; variables not in $S$ take on the same values as in the input variable assignment.
The input to the first Transformer block for a variable $x_i$ is given by:  
\begin{equation}
\mathbf{h}_i^{(0)} = \alpha \cdot\mathbf{e}(v_i) + \beta \cdot\text{APE}(x_i) + \gamma \cdot\mathbf{e}_s\cdot\mathbb{I}[x_i \in S],
% \mathbf{h}_i^{(0)} = 
% \begin{cases} 
% \mathbf{e}(v_i) + \text{APE}(x_i) + \mathbf{e}_s, & \text{if } x_i \in S, \\
% \mathbf{e}(v_i) + \text{APE}(x_i), & \text{otherwise.}
% \end{cases}
\end{equation}

where $\mathbf{e}(v_i)$ is the token embedding of variable $x_i$'s current value $v_i$ as described in~\Cref{eq:token_embed}, and $\text{APE}(x_i)$ is its positional encoding as computed in~\Cref{eq:ape}. $\alpha, \beta, \gamma$ are learnable scalars that allow the model to balance the contributions of each encoding, inspired by~\citet{vitarc}. The set of embeddings for all variables forms the input set $\mathbf{H}^{(0)} = \{\mathbf{h}_1^{(0)}, \mathbf{h}_2^{(0)}, \dots, \mathbf{h}_n^{(0)}\}$.


% \begin{figure}
%     \centering
%     \includegraphics[width=0.9\linewidth]{temp2.jpg}
%     \caption{change this to use a specific Sudoku example}
%     \label{fig:enter-label}
% \end{figure}

We note that this allows for easy handling of problems where certain variables have fixed values, such as in Sudoku. We simply bypass the variable subset selection step for the fixed variables, ensuring they are never updated by \methodname.

\paragraph{Self-attention.}  

\methodname{} employs a self-attention mechanism to compute updated representations of variables based on other variables. For each variable token $\mathbf{h}_i^{(l)}\in\mathbb{R}^{h\times 1}$ at layer $l$, the self-attention mechanism proceeds as follows:
\begin{enumerate}
    \item Each input token is projected to query, key, and value vectors:  
\[
\mathbf{q}_i = \mathbf{W}^Q \mathbf{h}_i^{(l)}, \quad 
\mathbf{k}_i = \mathbf{W}^K \mathbf{h}_i^{(l)}, \quad 
\mathbf{v}_i = \mathbf{W}^V \mathbf{h}_i^{(l)},
\]
where $\mathbf{W}^Q\in\mathbb{R}^{d\times h}$, $\mathbf{W}^K\in\mathbb{R}^{d\times h}$, and $\mathbf{W}^V\in\mathbb{R}^{d_v\times h}$ are learnable weight matrices.

    \item The relative positional encoding $\text{RPE}(i, j)$ as described in~\Cref{eq:rpe} is added to the attention logits $\mathbf{A}_{ij}$:  
\[
\mathbf{A}_{ij} = \frac{\mathbf{q}_i^\top \mathbf{k}_j}{\sqrt{d}} + \text{RPE}(i, j).
\]
% where $d$ is the size of the query and key vectors. 

    \item The attention weights are computed using a softmax:  
\[
\alpha_{ij} = \frac{\exp(\mathbf{A}_{ij})}{\sum_{k \in \mathcal{S}} \exp(\mathbf{A}_{ik})}.
\]

    \item The output representation for token $i$ is computed as:  
\[
\mathbf{z}_i = \sum_{j \in \mathcal{S}} \alpha_{ij} \mathbf{v}_j.
\]
\end{enumerate}


\paragraph{Feedforward network and layer stacking.}  
The output of the self-attention mechanism $\mathbf{z}_i$ is passed through a position-wise feedforward network (FFN):  
\[
\mathbf{h}_i^{(l+1)} = \text{FFN}(\mathbf{z}_i) = \mathbf{W}_2(\text{GeLU}(\mathbf{W}_1 \mathbf{z}_i + \mathbf{b}_1))  + \mathbf{b}_2,
\]
where $\mathbf{W}_1$, $\mathbf{W}_2$, $\mathbf{b}_1$, and $\mathbf{b}_2$ are learnable parameters. The Transformer consists of multiple such layers.

\paragraph{Output: one-hot variable assignments.}  
At the final layer, the Transformer outputs a one-hot vector over the domain $D_i$ of each variable in the subset $S$, representing its new assignment. Specifically, for variable $x_i$, the output is:  
\[
\hat{\mathbf{y}}_i = \text{GumbelSoftmax}\Big(\mathbf{W}_{\text{out}} \mathbf{h}_i^{(L)} + \mathbf{b}_{\text{out}}\Big),
\]
where $|\hat{\mathbf{y}}_i| = |D_i|$, $\mathbf{W}_{\text{out}}$ and $\mathbf{b}_{\text{out}}$ are learnable, and $L$ is the  number of Transformer layers. The Gumbel-Softmax~\cite{jang2017categorical} operator serves as a differentiable proxy to selecting the highest-output domain value. The predicted assignment for $x_i$ is then:  
\[
v'_i = \arg\max_{} \hat{\mathbf{y}}_i, \quad \forall i \in S.
\]





% - Intuitively our model takes in as input a CSP problem 

% - Inspired by Large Neighbourhood Search, we introduce stochasticity by randomly selecting a subset of variables the Transformer can operate on.

% - Model Architecture: Transformer

% - The model outputs a one-hot vector for each variable representing the new assignment for that variable.

\begin{table*}[]
    \centering
    \caption{Discrete constraints used in our studied problems and their continuous penalty counterparts. In the continuous penalties, the variables $x_i$ are represented by probability distributions approximating their one-hot form such that $x_i^{(j)}\in[0,1] \;\forall j \in \{1, \ldots, m\}$, 
    where $\{1, \ldots, m\}$ represents the domain $D_i$. Numerical examples for each constraint can be found in~\Cref{app:pen-eval}.}
    \renewcommand{\arraystretch}{1.6} 
    \begin{tabular}{@{}p{0.4\textwidth}p{0.5\textwidth}@{}}
    % \begin{tabular}{lp{0.5\textwidth}@{}}

        \toprule
        \textbf{Discrete Constraint ($c$)} & \textbf{Continuous Penalty ($p$)} \\ \midrule

        $\textsc{Cardinality}_j(x_1, \ldots, x_n) = k$ & $\left | k - \sum_{i=1}^n x_i^{(j)} \right |$ \\ 
        \multicolumn{2}{@{}p{\textwidth}@{}}{\textit{Explanation:} The cardinality constraint ensures that there are exactly $k$ variables taking the value $j$. The continuous relaxation penalizes the deviation from the desired count $k$.} \\ \midrule

        $\textsc{AllDifferent}_{m=n}(x_1, \ldots, x_n)$ & $\sum_{j=1}^{m} \left( \left |1 - \sum_{i=1}^n x_i^{(j)} \right | \right)$ \\ 
        \multicolumn{2}{@{}p{\textwidth}@{}}{\textit{Explanation:} The all-different constraint ensures that each variable takes a unique value. When the number of variables equals the domain size $m$, the all-different constraint can be rewritten as $n$ cardinality constraints restricting the cardinality of every value in the domain to be $1$.} \\ \midrule

        $\textsc{AllDifferent}_{m>n}(x_1, \ldots, x_n)$ & $\sum_{j=1}^{m} \left[ \text{ReLU}\left(\sum_{i=1}^n x_i^{(j)} - 1\right) + 
        \sum_{i=1}^n x_i^{(j)} \cdot \left( \left |1 - \sum_{i=1}^n x_i^{(j)}\right| \right) \right]$ \\ 
        \multicolumn{2}{@{}p{\textwidth}@{}}{\textit{Explanation:} When there are more domain values than variables, each value should appear no more than once. This is enforced by ensuring values above 1 are penalized and values remain in the set $\{0, 1\}$.} \\ \midrule

        $x_i \neq x_k$ & $\sum_{j=1}^{m}(x_i^{(j)} \cdot x_k^{(j)})$ \\ 
        \multicolumn{2}{@{}p{\textwidth}@{}}{\textit{Explanation:} This constraint ensures that two variables take different values by penalizing overlapping one-hot encodings. The continuous relaxation takes the dot product of the two variables, penalizing it if it is above $0$.} \\ 

        \bottomrule
    \end{tabular}
    \label{tab:loss_relaxed}
\end{table*}

\subsection{Self-supervised Loss Function}
\label{sec:loss}

How should the Transformer learn to refine an input variable assignment into a better one? In the CSP context, the loss function must reflect the level of constraint satisfaction achieved by the predicted assignment. As argued earlier, one could use a supervised approach in which a feasible solution is first computed for each training CSP and a loss function measuring the variable-wise mismatch between the prediction and the solution is used. However, this approach hinges on solving many NP-Complete CSPs, a substantial overhead for large and complex problems. Additionally, there may be multiple feasible solutions, making supervision by a single solution somewhat arbitrary. Alternatively, our Transformer could be trained by RL, with the reward function reflecting the level of constraint satisfaction. We argue that this is unnecessarily complicated. An input CSP instance is fully observable as is the amount of violation of a constraint for any given variable assignment. Treating this violation signal as part of a  reward function given by a black-box ``environment'' is thus overkill. Should we be able to derive differentiable approximations to the constraints, their violations could be used directly in a loss function, enabling end-to-end differentiable training. 

With these design principles in mind, we train our Transformer using self-supervision. As our loss function, we use a linear combination of approximations to the amount of constraint violations by the predicted variable assignment to guide the model towards a satisficing predicted assignment.

However, many constraints in CSP are discrete and not differentiable. To address this, we introduce simple continuous penalties that approximate discrete constraints, which are then used to compute the loss for guiding the model. Let $P = \{p_1, p_2,\dots,p_m\}$ be the set of continuous penalties approximating constraints $C = \{c_1, c_2,\dots,c_m\}$ such that 
\begin{equation*}
p_i(X_i) = 0 \iff c_i(X_i) = \texttt{True},
\end{equation*}
implying that $X^*$ is a feasible solution for the CSP when
\begin{equation*}
p_i(X_i^*) = 0 \quad \forall p_i \in P.
\end{equation*}
The loss for \methodname{} for a single CSP training instance is therefore
\begin{equation} 
\label{eq:loss}
\mathcal{L} = \sum_{i} \lambda_i f(p_i(X_i)) \quad \forall p_i \in P,
\end{equation}
where hyperparameter $\lambda_i$ is the weight assigned to $p_i$, and $f$ is an optional operation to transform the penalty for better learning. In practice, we implemented the common quadratic penalty, $f(x) = x^2$. The discrete constraints and their relaxed continuous counterparts we implemented for our experiments are shown in~\Cref{tab:loss_relaxed}, and numerical examples of valid and invalid assignments for each constraint can be found in~\Cref{app:pen-eval}.




\subsection{Iterative Test-Time Deployment}
\label{sec:testtime}

Another issue with RL is its multi-step nature which requires exploring an extremely large space of iterative solution refinement sequences. We show that learning a single-step solution refiner with self-supervision suffices as the model can be be deployed iteratively at test time. More specifically, our method refines an initial solution by repeatedly feeding its output variable assignment back as input to the next iteration as visualized in~\Cref{fig:architecture}.

In this sense, \methodname{} can be viewed as performing a single step of neural local search to improve the candidate solution. Our experiments focus on basic iterative solution refinement in one continuous sequence, without additional augmentations. However, this capability can be combined with techniques such as backtracking and random restarts~\cite{cp-handbook} to create a neuro-symbolic solver. Another possible extension is to incorporate \methodname{} as an evolutionary algorithm~\cite{holland1992genetic} utilizing the Transformer's parallel processing ability to update a pool of candidate solutions all at once. We leave these explorations as future work.



\section{Experimental Results}
% Our code is in the supplementary materials and will be made public upon publication.
% \todo[inline]{add a figure here or in appendix showing an example instance being progressively solved}

% \todo[inline]{add OR-Tools for Sudoku}



% \begin{table*}
% \centering
% \renewcommand{\arraystretch}{1.3}
% \setlength{\tabcolsep}{6pt}
% \begin{tabular}{lcccc}
% \toprule
% \textbf{Method} & \textbf{\% Test Instances} & \textbf{\% Constraints} & \textbf{\% Test Instances} & \textbf{\% Constraints} \\
%                 & \textbf{Solved}       & \textbf{Satisfied}      & \textbf{Solved (OOD)} & \textbf{Satisfied (OOD)} \\
% \midrule

% \textbf{Sudoku} &&&& \\
% \citet{satnet}** & 98.3 & - &  3.2 & - \\
% \citet{rrn}** & 99.8 & - &  28.6 & - \\
% \citet{iclr23Transformercsp} (64 Iters) & \textbf{100}            & 100         & 32.90                 & 68.20       \\
% \citet{iclr23Transformercsp} (2k Iters) &             &          &   14.00 &  54.63     \\
% \citet{ired} & 99.4 & - & 62.1 & - \\
% \methodname{} (2k Iters)  & \textbf{100}    & 100       & 65.88 & 82.77       \\
% \methodname{} (10k Iters)  & \textbf{100}    & 100       & \textbf{77.74} & 82.73       \\

% \midrule
% \end{tabular}
% \caption{ Performance comparison for Sudoku OOD refers to Out-of-Distribution evaluation.}
% \label{table:performance-comparison}
% \end{table*}

% \begin{table*}
% \centering
% \renewcommand{\arraystretch}{1.3}
% \setlength{\tabcolsep}{6pt}
% \begin{tabular}{lcccc}
% \toprule
% \textbf{Method} & \textbf{\% Test Instances} & \textbf{\% Constraints} & \textbf{\% Test Instances} & \textbf{\% Constraints} \\
%                 & \textbf{Solved}       & \textbf{Satisfied}      & \textbf{Solved (OOD)} & \textbf{Satisfied (OOD)} \\
% \midrule
% \textbf{Graph-Coloring-5}  &&&& \\
% OR-Tools (10s) & 83.08 & -       &  57.08       & - \\
% \methodname{} (3k) & 79.92 (avg. 0.22s) & 99.75       &  47.75 (avg. 0.49s)       & 99.37       \\
% \methodname{} (10k) & 81.25 (avg. 0.75s) &  99.77  &  51.42 (avg. 1.65s)  &  99.39      \\
% \midrule
% \textbf{Graph-Coloring-10} &   &      &          &        \\
% OR-Tools (10s) & 51.42 & -       &  09.58       & - \\
% \methodname{} (3k)  & 53.58 (avg. 0.62s) & 99.31       & 13.92 (avg.1.52s)       & 97.83       \\
% \methodname{} (10k) & \textbf{53.83} (avg. 2.09s) & 99.30 & \textbf{15.00} (avg. 5.06s) & 97.85 \\
% \bottomrule
% \end{tabular}
% \caption{Performance comparison for Graph-Coloring tasks. OOD refers to Out-of-Distribution evaluation for our learned model. For Graph Coloring 5, in distribution problems have graph size of 50, ood size of 100. For Graph Coloring 10, in ditribution have size 100, OOD 200 }
% \label{table:performance-comparison}

% \end{table*}


% \begin{table*}
% \centering
% \renewcommand{\arraystretch}{1.3}
% \setlength{\tabcolsep}{6pt}
% \begin{tabular}{lcccc}
% \toprule
% \textbf{Method} & \textbf{\% Test Instances} & \textbf{\% Constraints} & \textbf{\% Test Instances} & \textbf{\% Constraints} \\
%                 & \textbf{Solved}       & \textbf{Satisfied}      & \textbf{Solved (OOD)} & \textbf{Satisfied (OOD)} \\
% \midrule

% \textbf{Sudoku} &&&& \\
% \citet{satnet}** & 98.3 & - &  3.2 & - \\
% \citet{rrn}** & 99.8 & - &  28.6 & - \\
% \citet{iclr23Transformercsp} (64 Iters) & \textbf{100}            & 100         & 32.90                 & 68.20       \\
% \citet{iclr23Transformercsp} (2k Iters) &             &          &   14.00 &  54.63     \\
% \citet{ired} & 99.4 & - & 62.1 & - \\
% \methodname{} (2k Iters)  & \textbf{100}    & 100       & 65.88 & 82.77       \\
% \methodname{} (10k Iters)  & \textbf{100}    & 100       & \textbf{77.74} & 82.73       \\

% \midrule
% \end{tabular}
% \caption{ Performance comparison for Sudoku OOD refers to Out-of-Distribution evaluation.}
% \label{table:performance-comparison}
% % \textbf{ **TODO!!!: satnet, rrn results are taken directly from the diffusion paper, which may be dubious as Wenhao and I found. I think we should try to run it ourselves, not sure if we have time to}

% \end{table*}

% \begin{table*}
% \centering
% \renewcommand{\arraystretch}{1.3}
% \setlength{\tabcolsep}{6pt}
% \begin{tabular}{lcccc}
% \toprule
% \textbf{Method} & \textbf{\% Test Instances} & \textbf{\% Constraints} & \textbf{\% Test Instances} & \textbf{\% Constraints} \\
%                 & \textbf{Solved}       & \textbf{Satisfied}      & \textbf{Solved (OOD)} & \textbf{Satisfied (OOD)} \\
% \midrule
% \textbf{Graph-Coloring-5}  &&&& \\
% OR-Tools (10s) & 83.08 & -       &  57.08       & - \\
% \methodname{} (3k) & 79.92 (avg. 0.22s) & 99.75       &  47.75 (avg. 0.49s)       & 99.37       \\
% \methodname{} (10k) & 81.25 (avg. 0.75s) &  99.77  &  51.42 (avg. 1.65s)  &  99.39      \\
% \midrule
% \textbf{Graph-Coloring-10} &   &      &          &        \\
% OR-Tools (10s) & 51.42 & -       &  09.58       & - \\
% \methodname{} (3k)  & 53.58 (avg. 0.62s) & 99.31       & 13.92 (avg.1.52s)       & 97.83       \\
% \methodname{} (10k) & \textbf{53.83} (avg. 2.09s) & 99.30 & \textbf{15.00} (avg. 5.06s) & 97.85 \\
% \bottomrule
% \end{tabular}
% \caption{Performance comparison for Graph-Coloring tasks. OOD refers to Out-of-Distribution evaluation for our learned model. For Graph Coloring 5, in distribution problems have graph size of 50, ood size of 100. For Graph Coloring 10, in ditribution have size 100, OOD 200 }
% \label{table:performance-comparison}

% \end{table*}
\subsection{Problems}
% We apply \methodname{} to the following problems.

\noindent\textbf{Sudoku} is a well-known CSP problem that involves filling a $9 \times 9$ grid with digits from 1 to 9 such that each row, column, and $3 \times 3$ sub-grid  contain each digit exactly once. A single Sudoku instance consists of a partially filled board and a unique assignment to the unfilled cells that satisfies the constraints. A Sudoku instance's difficulty is determined by the initial board: fewer initially filled cells in the board involve a larger space of possible assignments to the unfilled cells, with the hardest Sudoku puzzles having only 17 of the 81 numbers provided~\cite{Sudoku-difficulty}. We use the $\textsc{AllDifferent}_{m=n}(x_1, \ldots, x_n)$ constraint from~\Cref{tab:loss_relaxed} to formulate the problem and its corresponding continuous penalty as the loss function to guide the model learning. The full formulation of Sudoku in CP is detailed in~\Cref{app:cpform}.

We use the dataset from SATNet~\cite{satnet}, which contains instances with $[31, 42]$ missing values, as the training and in-distribution testing dataset. To test our model's ability to generalize to harder out-of-distribution instances, we use the dataset from RRN~\cite{rrn} which contains instances with $[17, 34]$ missing values. 
% Our experiments show that \methodname{} generalizes effectively to these more challenging OOD problems, outperforming all existing neural approaches.

\noindent\textbf{Graph Coloring} is the problem of finding an assignment of colors to vertices in a graph such that no two neighboring nodes share the same color. The problem is defined by the graph's structure and the number of available colors $k$. We generate two sets of graph instances for $k=5$ and $k=10$ following a similar procedure as \cite{anycsp} (See Appendix~\ref{app:datagen} for details). Training graphs have 50 vertices for $k=5$ and 100 vertices for $k=10$ whereas OOD graphs have 100 for $k=5$ and 200 for $k=10$. We use inequality constraints of the form $x_i \neq x_j$ for an edge between nodes $i$ and $j$ and their penalty in~\Cref{tab:loss_relaxed} to represent the coloring constraints.

\noindent\textbf{Nurse Scheduling} is an operations research problem of assigning nurses to shifts. A problem instance has a specified number of days $n$, number of shifts per day $s$, number of nurses per shift $ns$, and a total number of nurses. The variables $x_{d,n,ns}$ are the shift slots indexed by the day, shift, and nurse and their domains are the indices of the nurses. A feasible solution ensures that no nurse is assigned to more than one shift per day and avoids assigning the same nurse to both the last shift of one day and the first shift of the following day. We use both the inequality $x_i \neq x_j$ and the $\textsc{AllDifferent}_{m>n}(x_1, \ldots, x_n)$ constraints for this problem; see~\Cref{app:cpform} for the full formulation.




\begin{table}[]
\centering
\caption{Performance comparison for Sudoku. In-distribution test instances contain 1K instances from the SATNet dataset, OOD refers to Out-of-Distribution evaluation on the RRN test dataset which contains 18K instances. *Values reported in \cite{ired}.}
\begin{tabular}{lcc}
\toprule
\textbf{Method} & \textbf{Test}  & \textbf{Harder OOD}  \\
                & \textbf{Instances}             & \textbf{Instances}  \\
\midrule
% OR-Tools & 100 & 100 \\
% \textbf{Sudoku} & & \\
\citet{satnet} * & 98.3 & 3.2 \\
\citet{rrn}* & 99.8 & 28.6 \\
\citet{iclr23Transformercsp} & \textbf{100} & 32.9 \\
\citet{iclr23Transformercsp} (2k Iters) & 97.7 & 14.0 \\
\citet{ired} * & 99.4 & 62.1 \\
\methodname{} (2k Iters) & \textbf{100} & 65.88 \\
\methodname{} (10k Iters) & \textbf{100} & \textbf{77.74} \\

\midrule
\end{tabular}
\label{table:Sudoku_results}
% \textbf{ **TODO!!!: satnet, rrn results are taken directly from the diffusion paper, which may be dubious as Wenhao and I found. I think we should try to run it ourselves, not sure if we have time to}

\end{table}

\subsection{Training}

For each of the problems, we train the model with randomly initialized variable assignments guided by the loss function defined in~\Cref{eq:loss} and the corresponding $p_i$ associated with the constraints used to define the CSP. The training set contains 9K instances for all problems. The training details and hyperparameters for the best performing model for each problem is detailed in~\Cref{app:hyperparam}.


\subsection{Results}

% Table~\ref{table:Sudoku_results} reports the performance of \methodname{} and various neural methods on the Sudoku task. \methodname{} solves 100\% of the Sudoku tasks from the in-distribution test dataset. On the harder out-of-distribution dataset, \methodname{} significantly outperforms all competing methods, demonstrating superior generalization capabilities. \methodname{} achieves instance solve rates of 65.88\% and 77.74\% with 2k and 10k iterations, respectively. These results highlight \methodname’s ability to generalize effectively to more challenging distributions.


\paragraph{Sudoku.}
\Cref{table:Sudoku_results} reports the performance of \methodname{} and various neural methods on the Sudoku task. \methodname{} solves 100\% of the Sudoku tasks from the in-distribution test dataset. On the harder out-of-distribution dataset, \methodname{} significantly outperforms all learned methods, demonstrating superior generalization capabilities. \methodname{} achieves instance solve rates of 65.88\% and 77.74\% with 2k and 10k iterations, respectively.

This highlights the iterative reasoning nature of our approach. Harder instances can be solved with additional reasoning steps, whereas other solvers with fixed reasoning steps struggle. Notably, \citet{iclr23Transformercsp}'s approach also employs iterative reasoning with Transformers, but their performance degraded with more test-time iterations while \methodname{}'s continued to improve. This could be due to \citet{iclr23Transformercsp}'s approach being trained for 32 iterations, while \methodname{} was trained for a single iteration, allowing it to generalize better when applied iteratively.

% These results underscore \methodname{}'s strong generalization capabilities and its effectiveness in leveraging iterative refinement to tackle more challenging distributions. Furthermore, the ability to progressively improve solutions with additional iterations makes \methodname{} particularly well-suited for complex reasoning tasks where fixed-step models may struggle.

\begin{table}[]
\centering
\caption{Performance comparison for Graph-Coloring tasks. OOD refers to Out-of-Distribution evaluation for ANYCSP and \methodname{} where the number of verticies $n$ in the graph is larger than that of the training instances. All datasets has 1200 instances.}
\renewcommand{\arraystretch}{1.3}
\setlength{\tabcolsep}{6pt}
\begin{tabular}{lcc}
\toprule
\textbf{Method} & \textbf{Test}  & \textbf{Harder OOD}  \\
                & \textbf{Instances}             & \textbf{Instances}  \\
\midrule
        \multicolumn{3}{c}{\textbf{Graph-Coloring-5} ($n=50 \rightarrow n=100$)} \\
        \midrule
        % OR-Tools (2s)     & \textbf{83.08}   & 56.83 \\
        OR-Tools (10s)    & \textbf{83.08}  & \textbf{57.16} \\ 
        ANYCSP (10s)      & 79.17  & 34.83 \\
        % \methodname{} (1s) & 69.42  & 27.17 \\
        % \methodname{} (2s) & 74.58  & 34.41 \\
        % \methodname{} (3s) & 76.17  & 38.66 \\
        % \methodname{} (5s) & 78.58  & 42.66 \\
        \methodname{} (10s) & 81.00  & 47.33 \\
        
        \midrule
        \multicolumn{3}{c}{\textbf{Graph-Coloring-10} ($n=100 \rightarrow n=200$)} \\
        \midrule
        % OR-Tools (1s)   & 44.75  & 8.42
        % OR-Tools (2s)     & 46.75   & 8.83 \\
        OR-Tools (10s)    & 52.41  & 10.25 \\ 
        ANYCSP (10s)      & 0.00   & 0.00 \\
        % \methodname{} (1s) & 38.33  & 7.17 \\
        % \methodname{} (2s) & 45.33  & 8.67 \\
        % \methodname{} (3s) & 48.08  & 9.50 \\
        % \methodname{} (5s) & 50.42  & 10.42 \\
        \methodname{} (10s) & \textbf{52.60}  & \textbf{11.92} \\
        % \bottomrule

        % \midrule
        % \multicolumn{3}{c}{\textbf{Graph-Coloring-10-ER} ($n=100 \rightarrow n=200$)} \\ 
        % ER stands for Erdos-Renyi graphs (appendix b), our model outperforms ORTools on this distribution, but ORTools is better on Random geometric graphs. 
        % \midrule
        % OR-Tools (10s)    & \textbf{97.3}  & 22.6 \\ 
        % ANYCSP (10s)      & 0.00   & 0.00 \\
        % \methodname{} (10s) & 96.4  & \textbf{26.2} \\
        \bottomrule
\end{tabular}
\label{table:col-nurse-results}
\end{table}


% \begin{table}[htbp!]
% \centering
% \caption{Performance comparison for Graph-Coloring tasks. OOD refers to Out-of-Distribution evaluation for ANYCSP and \methodname{}. For Graph Coloring 5, in-distribution problems have a graph size of 50, OOD size of 100. For Graph Coloring 10, in-distribution problems have a size of 100, OOD 200.}
% \renewcommand{\arraystretch}{1.3}
% \setlength{\tabcolsep}{6pt}
% \begin{tabular}{lcc}
% \toprule
% \textbf{Method} & \textbf{Test}  & \textbf{Harder OOD}  \\
%                 & \textbf{Instances}             & \textbf{Instances}  \\
% \midrule
% \textbf{Graph-Coloring-5}  & $n=50$ & $n=100$ \\ 
% % old results
% % OR-Tools (10s) & \textbf{83.08} & \textbf{57.08} \\
% % \methodname{} (3k) & 79.92 (avg. 0.22s) & 47.75 (avg. 0.49s) \\
% % \methodname{} (10k) & 81.25 (avg. 0.75s) & 51.42 (avg. 1.65s) \\
% % \methodname{} (3k) & 79.92 & 47.75 \\
% % \methodname{} (10k) & 81.25 & 51.42 \\
% % Greedy & 32.42 & 0.0 \\
% OR-Tools (10s) & \textbf{83.08} & \textbf{57.16}\\
% ANYCSP (10s) & 79.17 & 34.83\\
% \methodname{} (10s) & 76.75 & 41.92\\

% % OR-Tools (20s) & 83.08 & 57.16\\  % solves all feasible instances
% % \methodname{} (20s) & 78.91 & \\
% \midrule
% \textbf{Graph-Coloring-10} &$n=100$ & $n=200$ \\

% % Greedy & 0.75 & 0.0 \\
% OR-Tools (10s) & 52.41 & 10.25\\
% ANYCSP (10s) & 0.0 & 0.0\\
% \methodname{} (10s) & \textbf{52.6} & \textbf{11.92}\\
% % OR-Tools (20s) & 53.33 & 10.92\\
% % \methodname{} (20s) & 53.75 & \\
% % OR-Tools (30s) & & 11.66\\
% % old results
% % OR-Tools (10s) & 51.42 & 09.58 \\
% % \methodname{} (3k) & 53.58 & 13.92 \\
% % \methodname{} (10k) & 53.83 & 15.00 \\
% \bottomrule
% % \textbf{Nurse-Scheduling-10} & & \\
% % OR-Tools (10s) & \textbf{100} & \textbf{100} \\
% % \methodname{} (3k) & 100 & 100 \\
% % \bottomrule
% \end{tabular}
% \label{table:col-nurse-results}
% \end{table}



\paragraph{Graph Coloring.}
Table~\ref{table:col-nurse-results} summarizes the performance of OR-Tools, ANYCSP~\cite{anycsp}, and \methodname{} on Graph Coloring instances. OR-Tools is a state-of-the-art traditional solver for constraint programming applications and serves as a strong baseline~\cite{cpsat}, achieving 100\% on Sudoku instances. We ran test instances sequentially through all models with a 10-second timeout, though \methodname{} can process instances significantly faster if processed in batches due to the Transformer architecture. We note that the harder dataset is not out of distribution for OR-Tools, since it solves each task individually and is not a learning-based solver. 

% \methodname{} demonstrates competitive performance on in-distribution Graph Coloring with $k=5$, solving 76.75\% of the test instances approaching the 83.08\% achieved by OR-Tools. However, it lags behind on the harder OOD test set, solving 41.92\% compared to the 57.16\% by OR-Tools. This is not a surprising result, since a performance drop-off is expected for harder instances not seen during training.

\methodname{} demonstrates competitive performance on in-distribution Graph Coloring with $k=5$, solving 81\% of the test instances approaching the 83.08\% achieved by OR-Tools. While it lags behind the state-of-the-art solver with 47.33\% on the harder OOD test set, \methodname{} outperforms ANYCSP on both distributions, which again shows our method's high generalization ability.

% This is not a surprising result, since a performance drop-off is expected for harder instances not seen during training.

On the more challenging Graph Coloring with $k=10$ datasets, \methodname{} surpasses OR-Tools in performance, showcasing the advantage of learned heuristic approaches: it may not surpass state-of-the-art solvers on smaller instances, but it excels in complex cases under short time limits—crucial for real-world applications.
% \methodname{} solves 52.6\% of in-distribution and 11.83\% of out-of-distribution test instances, compared to OR-Tools’ 52.41\% and 10.25\%, respectively. 
Surprisingly, ANYCSP failed to solve any instances within 10 seconds for both datasets, underscoring the scalability limitations of its graph-based representation and the difficulty of training with RL.

% This suggests that, while \methodname{} cannot beat stat-of-the-art non-neural solvers in accuracy on smaller instances, it demonstrates strong performance and even surpasses traditional solvers on more complex cases when the time limit is short, which is often needed in real-life applications.
% \methodname{} achieves 52.6\% and 11.83\% on in-distribution and out-of-distribution test instances while OR-Tools solves 52.41\% and 10.25\% respectively. 


% The experimental results on Graph Coloring 

\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/subset_mainv2.jpg}
    \caption{Variable selection probability ablation for Sudoku (Top) and Graph Coloring with $k=5$ (Bottom). The horizontal axis shows the number of iterations at test time and the vertical axis represents the \% solved of in-distribution test instances. }
    \label{fig:bern-ablation}
\end{figure}

\paragraph{Nurse Scheduling.}
For the Nurse Scheduling problem, \methodname{} matches OR-Tools in solving all tasks across both in-distribution and out-of-distribution instances within the 10-second timeout. This high accuracy is expected, given the large number of feasible solutions for each instance, as detailed in~\Cref{app:datagen}. However, solving this problem neurally is non-trivial, as the model must learn to balance multiple constraints within a single step of solution refinement. ANYCSP was not evaluated on this dataset due to their difficulty dealing with the $\textsc{AllDifferent}$ constraint. This result highlights \methodname{}'s potential to generalize to more complex problems with diverse constraint structures. 

% then for Nurse Scheduling say there are no ML baselines as they cannot deal with all-diff!




\subsection{Ablations}





\begin{table}[t]
\centering
\caption{Positional Encoding Ablation on Sudoku.}

\begin{tabular}{lccc}
\toprule
\textbf{Model Variant}     & \textbf{No APE} & \textbf{1D APE} & \textbf{2D APE} \\
\midrule
\textbf{No RPE}            & 0.00\%              & 0.00\%              & 99.90\%             \\
\textbf{Learned RPE}       & 98.70\%             & 97.10\%             & 98.20\%             \\
\textbf{Masked RPE}        & 99.80\%             & 99.50\%             & 99.80\%             \\
\bottomrule
\end{tabular}
\label{table:Sudoku-abl}
\end{table}

\begin{table}[t]
\centering
\caption{Positional Encoding Ablation on Graph Coloring.}
\resizebox{\linewidth}{!}{
\begin{tabular}{lcccc}
\toprule
\textbf{Model Variant}     & \multicolumn{2}{c}{\textbf{No APE}} & \multicolumn{2}{c}{\textbf{1D APE}} \\
                           & \textbf{COL50} & \textbf{COL100}   & \textbf{COL50} & \textbf{COL100}   \\
\midrule
\textbf{No RPE}            & 1.58\%          & 0.00\%               & 1.25\%          & 0.00\%               \\
\textbf{Learned RPE}       & 78.00\%         & 12.50\%              & 77.33\%         & 0.25\%               \\
\textbf{Masked RPE}        & 75.67\%         & 52.25\%              & 77.00\%         & 51.92\%              \\
\bottomrule
\end{tabular}}
\label{table:combined-col-abl}
\end{table}



% \begin{table}[htbp!]
% \centering
% \caption{Comparison of norpe and maskrpe across datasets and pe levels}
% \begin{tabular}{@{}lccc@{}}
% \toprule
% \textbf{Model}          & \textbf{0pe}   & \textbf{1pe}   & \textbf{2pe}   \\ \midrule
% \textbf{COL50 norpe}    & 0.0158         & 0.0125         & -             \\
% \textbf{COL50 maskrpe}  & 0.7567         & 0.77           & -             \\
% \textbf{COL100 norpe}   & 0.0            & 0.0            & -             \\
% \textbf{COL100 maskrpe} & 0.5225         & 0.5192         & -             \\
% \textbf{Sudoku norpe}   & 0.0            & 0.0            & 0.999         \\
% \textbf{Sudoku maskrpe} & 0.998          & 0.995          & 0.998         \\ \bottomrule
% \end{tabular}
% \end{table}


\paragraph{Effect of subset improvement.}




Figure~\ref{fig:bern-ablation} examines the impact of varying probability of selection $p$ on the performance of the model. The horizontal axis refers to the number of iterations at test time while the vertical axis represents the percentage of in-distribution test instances solved. We investigate the behavior of the model under different probabilities $p \in \{1.0, 0.9, 0.7, 0.5, 0.3, 0.1\}$, where $p$ determines the probability of selecting each variable for updates during a single iteration as detailed in~\Cref{sec:architecture}. A larger $p$ results in more variables being selected to be updated.

When \(p=1.0\) (blue line), all variables are selected for updates during every iteration. This approach leads to rapid improvement in the early stages, as the model converges quickly to local optima. This is clearly observed in Graph Coloring, where the $p=1.0$ model rapidly solved 65\% of instances. Performance plateaus after the initial surge whereas the stochastic models surpass it in accuracy after 50 iterations. The difference in model performance is even more drastic for Sudoku, with the $p=1.0$ model reaching 20\% instances solved early and converging, while the $p=0.9$, $p=0.7$, and $p=0.5$ models surpass it and reach near 100\% within 50 iterations.

These findings highlight the importance of incorporating stochasticity into the update process for combinatorial optimization tasks. While deterministic updates provide faster initial convergence, they are prone to premature stagnation. Stochastic updates, by selectively updating a subset of variables, improve generalization and allow the model to achieve higher final performance.








\paragraph{Effect of variable information as positional encodings.}


\Cref{table:Sudoku-abl} and \ref{table:combined-col-abl} show the performance of \methodname{} with different positional encodings. The value displayed indicates the percentage of in-distribution test instances solved by the model running 1k iterations
% Our ablations demonstrates the critical role of positional information of variables in ensuring effective model learning. 

Across both Graph Coloring and Sudoku, we observe that the inclusion of relative variable relations with RPE provides a significant performance boost. This is especially true in the Graph Coloring problem, which heavily relies on the constraint graph, since the vertices have no inherent ordering to them, and therefore the indices have little meaning for the model to learn from. 

In Sudoku however, we see that the Transformer is able to achieve strong performance using only 2D APE, without leveraging explicit constraint graph information. This indicates that in highly structured problems like Sudoku, the positional indices of variables alone contain sufficient information for solving the instances. We also observe that 2D APE outperforms the standard 1D APE typically used in Transformers.  These results suggests the importance of supporting both forms of positional encodings, as different properties of different problems requires distinct spatial or relational information.

We also note that when RPE is implemented as masked RPE, attention scores for each variable are restricted to its connected variables, closely resembling the behavior of a graph neural network with attention.



% Input representation: 2D APE vs Traditional 1D APE.

% RPE: without vs with.

% Our result shows that the positional information of variables play a critical role in ensuring the model's learning.

% We observe that, for both problems, the inclusion of relative information as RPE provides a significant boost to the model's performance, especially in the case of Graph Coloring, a problem highly dependent on the structure of the graph, and therefore the relations between the variables instead of the variable indices is critical for solving. We note that when implemented as masked RPE, each variable's attention scores are only non-zero for its connected variables, which is similar to that of a graph neural network. 

% In Sudoku, we see the importance of 2D ape instead of the standard 1d ape used in Transformers. While using no information from the constraint graph, the Transformer is able to learn from the indices of the variables alone when represented as 2D APE alone, this suggests that in the simple problem of Sudoku where the problem is highly structured, the indices of the variables contains enough information for the instance to be solved.


% \paragraph{Effects of Loss Functions}



\section{Conclusion}
% Conclusion can be short, reiterate contributions briefly, then mention some future work such as extending to more constraints and problems

We introduced \methodname{}, a self-supervised Transformer for iteratively solving Constraint Satisfaction Problems. We showed that our method, trained to perform a single step of solution improvement, is able to generalize to harder out-of-distribution instances at test time, outperforming supervised and reinforcement learning approaches. Future work includes exploring neural-symbolic approaches incorporating \methodname{} such as those discussed in \Cref{sec:testtime}, other performance boosting techniques such as self-improvement techniques to augment the training data~\cite{lee2025self}, as well as extending \methodname{} to more problems and more constraints, with the goal of devising a general continuous approximation for constraints.

% Limitation, currently our model uses a fixed variable dimension for each problem, we could add an additional layer in the end that outputs dynamic length one-hot encodings. Relatedly, the 

\clearpage
\bibliography{example_paper}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\appendix
\onecolumn
% The $\mathtt{\backslash onecolumn}$ command above can be kept in place if you prefer a one-column appendix, or can be removed if you prefer a two-column appendix.  Apart from this possible change, the style (font size, spacing, margins, page numbering, etc.) should be kept the same as the main body.


\section{Example Continuous Penalty Evaluations}
\label{app:pen-eval}



\begin{table*}[h]
\centering
\renewcommand{\arraystretch}{1.2}
\caption{Example assignments illustrating the evaluation of continuous penalties for discrete constraints. The variables $x_i$ are represented by probability distributions approximating their one-hot form. Two assignments are shown: a valid assignment representing a set of variable values that exactly satisfy the constraint, and an invalid assignment representing a set of variable values that violate the constraint. The penalty evaluates to 0 for valid assignments and increases with the degree of constraint violation.}
\label{tab:example-penalties}
\begin{tabular}{@{}p{0.3\textwidth} p{0.65\textwidth}@{}}
\toprule
\textbf{Constraint and Relaxation} 
& \textbf{Example Assignments} \\
\midrule

%-------------------------------------------------------------------------------------------
% \textbf{Cardinality}\\
\[
\textsc{Cardinality}_j(x_1,\dots,x_n)=k
\]
\[
\Longrightarrow\quad
p \;=\;\bigl|\,k \;-\;\sum_{i} x_i^{(j)}\bigr|.
\]
\[
j = 1, k = 2
\]
&
\textbf{Valid Assignment: }
\(\displaystyle x_1=(1,0),\;x_2=(1,0),\;x_3=(0,1)\)\newline
\(\sum_{i} x_i^{(1)} = 1 + 1 + 0 = 2\)\newline
% \(\text{Constraint value} = 2,\quad k=2\)\newline
\(\displaystyle p = |2-2| = 0.\)\newline

\vspace{2pt}

\textbf{Invalid Assignment:}
\(\displaystyle x_1 = (0.7,\,0.3),\quad
x_2 = (0.2,\,0.8),\quad
x_3 = (0,\,1)\)\newline
\(\sum_{i} x_i^{(1)} = 0.7 + 0.2 + 0 = 0.9\)\newline
% \(\text{Constraint value} \approx 1.3\quad(\text{vs. }k=2)\)\newline
\(\displaystyle p = |2 - 0.9|=1.1.\)
\\[10pt]\midrule

%-------------------------------------------------------------------------------------------
% \textbf{(2) All-Different (\(m=n\))}\\
\[
\textsc{AllDifferent}_{m=n}(x_1,\dots,x_n)
\]
\[
\Longrightarrow\;
p \;=\;\sum_{j}\Bigl|\,
1 - \sum_{i} x_i^{(j)}\Bigr|.
\]
&
\textbf{Valid Assignment: }\(x_1=(1,0,0),\;x_2=(0,1,0),\;x_3=(0,0,1)\)\newline
\(\sum_{i} x_i^{(1)}=1,\;\sum_{i} x_i^{(2)}=1,\;\sum_{i} x_i^{(3)}=1\)\newline
\(\displaystyle
p = |1-1| + |1-1| + |1-1| = 0.\)\newline

\vspace{2pt}
\textbf{Invalid Assignment: }
\(\displaystyle x_1=(0.9,0.1,0),\;x_2=(0.9,0.1,0),\;x_3=(0,0,1)\)\newline
\(\sum_i x_i^{(1)}=1.8,\;\sum_i x_i^{(2)}=0.2,\;\sum_i x_i^{(3)}=1\)\newline
\(\displaystyle
p = |1-1.8| + |1-0.2| + |1-1| = 0.8 + 0.8 + 0 = 1.6.\)
\\[10pt]\midrule

%-------------------------------------------------------------------------------------------
% \textbf{(3) All-Different (\(m>n\))}\\
\[
\textsc{AllDifferent}_{m>n}(x_1,\dots,x_n)
\]
\[
\Longrightarrow\;
p \;=\;\sum_{j}\Bigl[\mathrm{ReLU}\bigl(\sum_{i}x_i^{(j)}-1\bigr)
\]
\[
+ \sum_{i} x_i^{(j)}\,\bigl|1-\sum_{i} x_i^{(j)}\bigr|\Bigr].
\]
&
\textbf{Valid Assignment: }
\(x_1=(1,0,0),\;x_2=(0,1,0)\)\newline
\(\sum_i x_i^{(1)}=1,\;\sum_i x_i^{(2)}=1,\;\sum_i x_i^{(3)}=0\)\newline
\(\mathrm{ReLU}(1-1)=0,\;\;1\cdot|1-1|=0\)\newline
\(\mathrm{ReLU}(1-0)=0,\;\;0\cdot|1-0|=0\)\newline
\(\displaystyle p=0 + 0 + 0 + 0 + 0 + 0=0.\)

\vspace{2pt}
\textbf{Invalid Assignment: }
\(\displaystyle x_1=(0.6,\,0.4,\,0),\quad
x_2=(0.7,\,0.3,\,0)\)\newline
\(\sum_i x_i^{(1)}=1.3,\;\sum_i x_i^{(2)}=0.7,\;\sum_i x_i^{(3)}=0\)\newline 
\(\mathrm{ReLU}(1.3-1)=0.3,\;\;1.3\cdot|1-1.3|=0.39\)\newline
% \(\quad\Longrightarrow p_{1}=0.3+0.39=0.69.\)\newline
\(\mathrm{ReLU}(0.7-1)=0,\;\;0.7\cdot|1-0.7|=0.21\)\newline
% \(\quad\Longrightarrow p_{2}=0.21,\;\;p_{3}=0.\)\newline
\(\displaystyle p=0.3+0.39+0 + 0.21+0 + 0=0.9.\)
\\[10pt]\midrule

%-------------------------------------------------------------------------------------------
% \textbf{(4) Inequality \(\;x_i \neq x_k\)}\\
\[
x_i \neq x_k
\]
\[
\Longrightarrow\quad
p \;=\;\sum_{j}\bigl(x_i^{(j)}\,x_k^{(j)}\bigr).
\]
&
\textbf{Valid Assignment: }
\(x_i=(1,0,0),\;x_k=(0,1,0)\)\newline
\(\displaystyle p = (1\cdot0)+(0\cdot1)+(0\cdot0)=0.\)\newline

\vspace{2pt}
\textbf{Invalid Assignment: }
\(\displaystyle x_i=(0.7,0.3,0),\quad x_k=(0.7,0.2,0.1)\)\newline
\(\displaystyle p = (0.7\cdot0.7)+(0.3\cdot0.2)+(0\cdot0.1)
=0.49+0.06+0=0.55.\)
\\[2pt]\bottomrule
\end{tabular}
\end{table*}


% \begin{table*}[h]
% \centering
% \renewcommand{\arraystretch}{1.2}
% \caption{Simple examples illustrating how each discrete constraint is turned into a penalty and evaluated under two different one-hot assignments.}
% \label{tab:penalty-simplified}
% \begin{tabular}{@{}p{0.25\textwidth} p{0.70\textwidth}@{}}
% \toprule
% \textbf{Constraint \& Penalty} 
% & \textbf{Two Example Assignments (One-Hot) \& Computed Penalty} \\
% \midrule

% \textbf{1) Cardinality} 
% \[
% \textstyle
% p \;=\; \bigl|\,k \;-\; \sum_{i} x_i^{(j)}\bigr|
% \]
% &
% \textbf{Satisfying:} 
% \[
% x_1=(1,0),\;x_2=(1,0),\;x_3=(0,1)
% \]
% \[
% \sum_i x_i^{(1)} = 1+1+0=2,\quad p = |2-2|=0.
% \]

% \textbf{Violating:}
% \[
% x_1=(1,0),\;x_2=(1,0),\;x_3=(1,0)
% \]
% \[
% \sum_i x_i^{(1)} = 1+1+1=3,\quad p = |2-3|=1.
% \]
% \\[6pt]\midrule

% \textbf{2) All-Different (equal \#vars, \#values)} 
% \[
% \textstyle
% p \;=\; \sum_{j} \bigl|\,1 \;-\; \sum_{i} x_i^{(j)}\bigr|
% \]
% &
% \textbf{Satisfying:}
% \[
% x_1=(1,0,0),\;x_2=(0,1,0),\;x_3=(0,0,1)
% \]
% \[
% \textstyle
% \sum_i x_i^{(1)}=1,\;\sum_i x_i^{(2)}=1,\;\sum_i x_i^{(3)}=1
% \;\;\Rightarrow\;p=0.
% \]

% \textbf{Violating:}
% \[
% x_1=(1,0,0),\;x_2=(1,0,0),\;x_3=(0,0,1)
% \]
% \[
% \textstyle
% \sum_i x_i^{(1)}=2,\;\sum_i x_i^{(2)}=0,\;\sum_i x_i^{(3)}=1
% \;\;\Rightarrow\;p=|1-2|+|1-0|+|1-1|\;=\;2.
% \]
% \\[6pt]\midrule

% \textbf{3) All-Different (more values than vars)} 
% \[
% \textstyle
% p \;=\; \sum_{j}\Bigl[\mathrm{ReLU}(\sum_i x_i^{(j)} - 1)
% \;+\;\sum_i x_i^{(j)}\,\bigl|\,
% 1-\sum_i x_i^{(j)}\bigr|\Bigr]
% \]
% &
% \textbf{Satisfying:}
% \[
% x_1=(1,0,0),\;x_2=(0,1,0)
% \]
% \[
% \sum_i x_i^{(1)}=1,\;\sum_i x_i^{(2)}=1,\;\sum_i x_i^{(3)}=0,
% \]
% \[
% p=0\quad(\text{each value used at most once}).
% \]

% \textbf{Violating:}
% \[
% x_1=(1,0,0),\;x_2=(1,0,0)
% \]
% \[
% \sum_i x_i^{(1)}=2,\;\sum_i x_i^{(2)}=0,\;\sum_i x_i^{(3)}=0
% \]
% \[
% \mathrm{ReLU}(2-1)=1,\;\bigl|1-2\bigr|=1,\;\sum_i x_i^{(1)}=2
% \;\Rightarrow\;1+2=3.
% \quad p=3.
% \]
% \\[6pt]\midrule

% \textbf{4) Inequality: \(x_i \neq x_k\)}
% \[
% \textstyle
% p \;=\; \sum_{j} \bigl(x_i^{(j)}\,x_k^{(j)}\bigr)
% \]
% &
% \textbf{Satisfying:}
% \[
% x_i=(1,0,0),\quad x_k=(0,1,0)
% \]
% \[
% p = (1\cdot0) + (0\cdot1) + (0\cdot0)=0.
% \]

% \textbf{Violating:}
% \[
% x_i=(1,0,0),\quad x_k=(1,0,0)
% \]
% \[
% p = (1\cdot1) + (0\cdot0) + (0\cdot0)=1.
% \]
% \\

% \bottomrule
% \end{tabular}
% \end{table*}




\newpage
\section{Constraint Programming formulations}
\label{app:cpform}
\subsection{Sudoku}

We define the Sudoku problem as a constraint satisfaction problem (CSP) with the following components:

\paragraph{Variables:} Let $X_{i,j}$ denote the variable representing the value assigned to cell $(i,j)$, where $i, j \in \{1,2,\dots,9\}$.

\paragraph{Domains:} Each variable $X_{i,j}$ takes values from the discrete domain:
\begin{equation*}
X_{i,j} \in \{1,2,\dots,9\}.
\end{equation*}

\paragraph{Constraints:} The solution must satisfy the following $\text{AllDifferent}$ constraints:

\begin{itemize}
    \item Each row must contain unique values:
    \begin{equation*}
    \textsc{AllDifferent}_{m=n}(X_{i,1}, X_{i,2}, \dots, X_{i,9}), \quad \forall i \in \{1, \dots, 9\}. 
    \end{equation*}

    \item Each column must contain unique values:
    \begin{equation*}
    \textsc{AllDifferent}_{m=n}(X_{1,j}, X_{2,j}, \dots, X_{9,j}), \quad \forall j \in \{1, \dots, 9\}.
    \end{equation*}

    \item Each $3 \times 3$ subgrid must contain unique values. Let $(r, c)$ index the subgrid with $r, c \in \{0,1,2\}$, then:
    \begin{equation*}
    \textsc{AllDifferent}_{m=n} \left(
    \begin{array}{c}
    X_{3r+1,3c+1}, X_{3r+1,3c+2}, X_{3r+1,3c+3}, \\
    X_{3r+2,3c+1}, X_{3r+2,3c+2}, X_{3r+2,3c+3}, \\
    X_{3r+3,3c+1}, X_{3r+3,3c+2}, X_{3r+3,3c+3}
    \end{array}
    \right), \quad \forall r, c \in \{0,1,2\}.
    \end{equation*}
\end{itemize}

% The CSP representation of Sudoku includes the following components. 

% The variables correspond to the cells of the grid, denoted \( x_{ij} \), where \( i \) and \( j \) are the row and column indices respectively. Each variable \( x_{ij} \) has a domain \( D_{ij} = \{1, \dots, 9\} \), representing the possible digits that can be assigned to the cell. 

% The constraints are expressed as \textsc{AllDifferent} constraints applied to the rows, columns, and sub-grids of the grid. For instance, the constraints for a single row \( i \), a single column \( j \), and a specific sub-grid \( S \) are written as:
% \begin{align*}
% \textsc{AllDifferent}(x_{i1}, x_{i2}, \dots, x_{i9}), & \quad \forall i \in {1, \dots, 9}\\
% \textsc{AllDifferent}(x_{1j}, x_{2j}, \dots, x_{9j}), & \quad \forall j \in {1, \dots, 9} \\
% \textsc{AllDifferent}(x_{p_1q_1}, x_{p_1q_2}, \dots, x_{p_3q_3})  & 
% \end{align*}
% where \( S = \{(p_k, q_k)\}_{k=1}^9 \) denotes the indices of the cells within the sub-grid.

\subsection{Graph Coloring}

Given a graph $G = (V, E)$, we define the graph coloring problem as a constraint satisfaction problem (CSP) with the following components:

\paragraph{Variables:} Let $X_v$ be a variable representing the color assigned to vertex $v \in V$.

\paragraph{Domains:} Each variable $X_v$ takes values from a set of $k$ available colors:
\begin{equation*}
X_v \in \{1,2,\dots,k\}, \quad \forall v \in V.
\end{equation*}

\paragraph{Constraints:} The solution must satisfy that any two adjacent vertices must be assigned different colors:
    \begin{equation*}
    X_u \neq X_v, \quad \forall (u,v) \in E.
    \end{equation*}

\subsection{Nurse Rostering}

We define the nurse rostering problem as a constraint satisfaction problem (CSP) with the following components:

\paragraph{Variables:} Let $x_{d,s,ns}$ be a variable representing the nurse assigned to the $ns$-th slot of shift $s$ on day $d$, where:
\begin{equation*}
x_{d,s,ns} \in \{1,2,\dots,N\}, \quad \forall d \in \{1,\dots,n\}, \quad \forall s \in \{1,\dots,S\}, \quad \forall ns \in \{1,\dots,NS\}.
\end{equation*}

\paragraph{Constraints:} A feasible schedule must satisfy the following constraints:

\begin{itemize}
    \item No nurse can be assigned to more than one shift per day:
    \begin{multline*}
    \textsc{AllDifferent}_{m>n}(x_{d,1,1}, x_{d,1,2}, \dots, x_{d,1,NS}, x_{d,2,1}, x_{d,2,2}, \dots, x_{d,2,NS}, \dots, x_{d,S,1}, x_{d,S,2}, \dots, x_{d,S,NS}) \\
    \quad \forall d \in \{1,\dots,n\}.
    \end{multline*}

    \item A nurse cannot be assigned both the last shift of a given day and the first shift of the following day:
    \begin{equation*}
    x_{d,S,ns} \neq x_{d+1,1,ns'}, \quad \forall d \in \{1,\dots,n-1\}, \quad \forall ns, ns' \in \{1,\dots,NS\}.
    \end{equation*}

\end{itemize}

\section{Dataset Details}
\label{app:datagen}
\subsection{Graph Coloring}
Following \cite{anycsp}, we generate Graph Coloring instances with the following 3 distributions:
\begin{itemize}
    \item \textbf{Erdős-Rényi graphs} with edge probability $p \sim U[0.1, 0.3]$
    \item \textbf{Barabási-Albert graphs} with parameter $m \sim U[2, 10]$
    \item \textbf{Random geometric graphs} with vertices distributed uniformly at random in a 2-dimensional $1 \times 1$ square and edge threshold radius drawn uniformly from $r \sim U[0.15, 0.3]$.
\end{itemize}

The 5-coloring instances were drawn uniformly for all 3 distributions, with vertices count 50 for training and in-distribution testing data, vertices count 100 for out of distribution testing. The 10-coloring instances were drawn uniforming from Erdős-Rényi graphs and Random geometric graphs, with vertices count 100 for training and in-distribution testing data, and 200 for out of distribution testing.

For each graph $G$ generated a linear time greedy coloring heuristic as implemented by \texttt{NetworkX} \cite{networkx} to color the graph without conflict. If the greedy heuristic required $k'$ colors for $G$, then we pose the problem of coloring $G$ with $k$ colors as the training CSP instance, where $k$ is chosen as:
\[
k = \max \{ 3, \min \{ 10, k' - 1 \} \}
\]
We generate instances until a fixed number of instances for a specific k is reached. 9000 for training sets, 1200 for test sets.

\subsection{Nurse Scheduling}

We generate Nurse Rostering instances with varying difficulties. Each problem instance is defined by the number of days $n$, number of shifts per day $s$, number of nurses required per shift $ns$, and the total number of available nurses $N$.

\begin{itemize}
    \item \textbf{in-distribution instances} were generated with $n = 10$ days, $s = 3$ shifts per day, $ns = 3$ nurses per shift, and a total of $N = 10$ nurses.
    \item \textbf{Out-of-distribution instances} were generated with $n = 10$, $s = 3$, $ns = 3$, and $N = 10$.
\end{itemize}

The in-distribution instances consisted of 9000 training instances and 1000 test instances. Out-of-distribution instances also had 1000 samples.

To initialize different instances, we assign one random shift to every nurse as an initial assignment. This ensures that each instance starts with a minimally constrained but valid configuration.

We note that these instances are relatively easy to solve due to the large number of feasible solutions available. The constraints in the problem formulation do not drastically limit the space ofValid Assignments. The purpose of this dataset is to examine \methodname{}'s ability to solve instances with a combination of different constraints.



\newpage
\section{Model Details}
\label{app:hyperparam}

Our models were trained on various single-core GPU nodes, including P100, V100, and T4. A grid search was conducted to determine the best-performing hyperparameters, evaluating a few hundred configurations per problem.
The final reported models were trained with a batch size of 512 for 5000 epochs. The typical training time for a model ranges from 6 to 10 hours (wall clock). The hyperparameters for the best performing model for each of the problems is shown in~\Cref{tab:hyperparam}. For all models, we used AdamW as the optimizer and applied a dropout of 0.1, with learning rate set to 0.0001.

\begin{table}[ht]
    \centering
    \begin{tabular}{lcccc}
        \toprule
        & Sudoku & Graph-coloring-5 & Graph-coloring-10 & Nurse Scheduling \\
        \midrule
        Layer Count & 7 & 4 & 7 & 7 \\
        Head Count & 3 & 3 & 3 & 3 \\
        Embedding Size & 128 & 128 & 128 & 126 \\
        Selection Probability $p$ & 0.5 & 0.3 & 0.3 & 0.3 \\
        
        
        \bottomrule
    \end{tabular}
    \caption{Hyperparameters for the best performing models.}
    \label{tab:hyperparam}
\end{table}



% \section{Graph-Coloring-10 Performance Breakdown}

% To further analyze the performance of \methodname{} on Graph-Coloring-10 instances, we generated an additional 1000 instances for each of the two graph distributions, and evaluated the same model used to report~\Cref{table:col-nurse-results}. We see that \methodname{} outperforms OR-Tools on the larger Erdős-Rényi dataset while having similar performance for the other distribution and graph size combinations.  

% \begin{table}[th]
% \centering
% \caption{Performance comparison for Graph-Coloring tasks based on graph distributions. OOD refers to Out-of-Distribution evaluation for \methodname{} where the number of verticies $n$ in the graph is larger than that of the training instances.}
% \renewcommand{\arraystretch}{1.3}
% \setlength{\tabcolsep}{6pt}
% \begin{tabular}{lcc}
%     \toprule
%     \textbf{Method} & \textbf{Test}  & \textbf{Harder OOD}  \\
%                    & \textbf{Instances}  & \textbf{Instances}  \\
%     \midrule
%     \multicolumn{3}{c}{\textbf{Graph-Coloring-10-Erdős-Rényi} ($n=100 \rightarrow n=200$)} \\ 
%     % ER stands for Erdos-Renyi graphs (appendix b), our model outperforms ORTools on this distribution, but ORTools is better on Random geometric graphs. 
%     \midrule
%     OR-Tools (10s)    & \textbf{97.3}  & 22.6 \\ 
%     % ANYCSP (10s)      & 0.00   & 0.00 \\
%     \methodname{} (10s) & 96.4  & \textbf{26.2} \\
%     \midrule
%     \multicolumn{3}{c}{\textbf{Graph-Coloring-10-Random-Geometric} ($n=100 \rightarrow n=200$)} \\ 
%     % ER stands for Erdos-Renyi graphs (appendix b), our model outperforms ORTools on this distribution, but ORTools is better on Random geometric graphs. 
%     \midrule
%     OR-Tools (10s)    & \textbf{8.0} & \textbf{0.6} \\ 
%     % ANYCSP (10s)      & 0.00   & 0.00 \\
%     \methodname{} (10s) & 7.7 &  0.2 \\
%     \bottomrule
% \end{tabular}
% \label{table:col-10-app}
% \end{table}




\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
