\section{Background and Related Work}
\label{sec:back_rw}
    

\subsection{Factor Graphs and the Max-Sum Algorithm}
    
Factor Graphs (FGs)~\cite{kschischang2001factor} originate from probabilistic graphical models but are also well integrated within distributed AI as a common tool for DCOP formulation~\cite{maxsumfarinelli,dcopsurvey}.
Given an FG structure as the one in Fig.~\ref{fig:fg_dist}(a), we seek to obtain all control variable configurations $x_i \in \mathbf{x}$ that maximize the sum of the factors, i.e., solve the optimization problem: $\mathbf{x}^*={\arg\max}_{\mathbf{x}}\sum_j F_j(\mathbf{s}_j)$, where $\mathbf{s}_j \subseteq \mathbf{x}$.
Note that factors $F_j$ connect different variables, and may potentially associate more than two (e.g., $F_l$).
The corresponding vector $\mathbf{s}_j$ contains all variables $x_i$ connected to factor $F_j$.
For instance, in Fig.~\ref{fig:fg_dist}(a): $\mathbf{s}_l=[x_k,x_m,x_n]^T$.
In general, the factors can depend on any subset $\mathbf{s}_j \subseteq \mathbf{x}$ of the control variables.


Max-Sum~\cite{maxsumfarinelli} is an iterative, inference-based algorithm that provides an approximate solution for this optimization problem through
a message-passing operation involving two types of messages.
The first type of messages concerns values sent from variable $i$ to factor $j$:
$q_{i \rightarrow j}(x_i) = c_{ij} + \sum_{k \in M_i \setminus j} r_{k \rightarrow i}(x_i)$, where $M_i$ is the set of factor indices that variable $i$ is connected to. 
For instance, $M_k=\{j,l\}$ in Fig.~\ref{fig:fg_dist}(a). 
As such, $q_{i \rightarrow j}(x_i)$ contains an estimate for each value of $x_i$ to be sent to factor $j$.
Essentially, $q_{i \rightarrow j}(x_i)$ performs propagation of evaluations from all the other connected factors $M_i \setminus j$,
and can be viewed as the agent's current ``intents'' regarding their final configuration of variable $x_i$.
Then, $c_{ij}$ is a normalization constant that satisfies $\sum_{x_i}q_{i \rightarrow j}(x_i)=0$.
This normalization is important in cyclic graphs since we need to bound the messages' values. 
While convergence in cyclic FGs is not guaranteed, the use of $c_{ij}$ has proven to be quite effective in many studies~\cite{kok_vlassis,loopy_belief_prop,maxsumfarinelli}.

The second type of messages involves evaluations that a variable $i$ receives from a connected factor $j$:
$r_{j \rightarrow i}(x_i)=\max_{\mathbf{s}_j\setminus x_i}  \lbrack F_j(\mathbf{s}_j) + \sum_{k \in N_j \setminus i} q_{k \rightarrow j}(x_k)  \rbrack$, where $N_j$ is the set containing the variable indices connected to factor $j$, and the maximization process involves all the variables $\mathbf{s}_j$ connected to factor $F_j$ without $x_i$.
For instance, in Fig.~\ref{fig:fg_dist}(a), $N_l=\{k,m,n\}$, meaning that variables $x_k,x_m,x_n$ are connected to factor $F_l$.
These messages calculate for each possible value $x_i$ an estimate for the outcome considering both the associated factor, and all other messages sent to it. 
Since the $q_{k\rightarrow j}$ values provide these connected $N_l$ variables evaluation for their respective decisions, agent $i$ maximizes over all these variables, in order to have an evaluation that incorporates both the immediate factor's value and other agents' influence.
In every new iteration, the previous evaluations of the messages are utilized.
This operation is performed until some stopping criterion (e.g., time,  iterations number), or if all message values converge (within a threshold).
Finally, each agent computes the optimal value as: $x_i^* = \arg \max_{x_i} \sum_{j \in M_i} r_{j \rightarrow i}(x_i)$, i.e., the $x_i$ that maximizes the sum of all the received messages.
Without loss of generality, we consider that each agent controls one variable, 
and refer (same indexing) to agents and variables interchangeably.

\subsection{Related Work}

Dynamic DCOPs (D-DCOPs)~\cite{dcopsurvey} extend conventional DCOPs to dynamic environments. 
Consequently, the notion of time is introduced to the problem. In an FG problem formulation, we consider a dynamic graph structure with the possibility to change in time. 
At a time-step $t$, the FG contains a set of factors $M$, with $F_j(\mathbf{s}_j) \in M$, and $x_i \in N$, where $N$ is the set of variables.
There are two types of changes for every update from $t$ to $t+1$: (a) existing factors $F_j(\mathbf{s}_j)$ can now contain different values; or (b) new variables $x_i$ and factors $F_j(\mathbf{s}_j)$ can be introduced, and existing ones can be removed.
Commonly, D-DCOPs do not model how the factor evolves over time and algorithmic extensions~\cite{dcopsurvey} re-solve every new static instance of the problem at time $t$, effectively incorporating domain knowledge to improve performance~\cite{Ramchurn2010}.
Prior work in lane-free environments~\cite{troullinos_ijcai} (and~\cite{stranders2009}) also solves every new instance of the problem by relying on the previous solution as a starting point, with the assumption that changes in the graph modelling vehicles' interactions will not be substantially different.
In contrast,~\cite{Nguyen_Yeoh_Lau_Zilberstein_Zhang_2014} explicitly model the FG's evolution as Markovian D-DCOPs, thereby they tackle the sequentiality of the problem and incorporate methods from RL.
Moreover,~\cite{scalablemcts} addresses D-DCOPs from the perspective of DecMDPs, which can be viewed as a similar problem, and perform planning based on Monte-Carlo tree search with Max-Sum.\footnote{The Max-Plus algorithm (employed in~\cite{scalablemcts}) is effectively the same method with Max-Sum when the FG follows a structure that contains factors up to $2$ variables.}

Finally, we note that papers applying Max-Sum on Mobile Sensor Teams (MSTs), dealing with exploration issues~\cite{yedidson2018} or collision avoidance~\cite{pertzovsky2024collision}, exhibit conceptual similarities to our domain (which is natural since MSTs involve a dynamic environment of moving agents).
Regardless, they do not deal with asynchrony in the agents' variable updates as we do in this paper.






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%