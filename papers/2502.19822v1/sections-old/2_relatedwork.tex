\section{Related Work}
\label{sec:relatedwork}

\subsection{Current AI Tools for Social Service}
\label{subsec:relatedtools}
% the title I feel is quite broad

Harnessing technology for social good has always been a grand challenge in social service \cite{berzin_practice_2015}. As early as the 90s, artificial neural networks and predictive models have been employed as tools for risk assessments, decision-making, and workload management in sectors like child protective services and mental health treatment \cite{fluke_artificial_1989, patterson_application_1999}. The recent rise of generative AI is poised to further advance social service practice, facilitating the automation of administrative tasks, streamlining of paperwork and documentation, optimisation of resource allocation, data analysis, and enhancing client support and interventions \cite{fernando_integration_2023, perron_generative_2023}.

Today, AI solutions are increasingly being deployed in both policy and practice \cite{goldkind_social_2021, hodgson_problematising_2022}. In clinical social work, AI has been used for risk assessments, crisis management, public health initiatives, and education and training for practitioners \cite{asakura_call_2020, gillingham2019can, jacobi_functions_2023, liedgren_use_2016, molala_social_2023, rice_piloting_2018, tambe_artificial_2018}. AI has also been employed for mental health support and therapeutic interventions, with conversational agents serving as on-demand virtual counsellors to provide clinical care and support \cite{lisetti_i_2013, reamer_artificial_2023}.
% commercial solutions include Woebot, which simulates therapeutic conversation, and Wysa, an “emotionally intelligent” AI coach, powered by evidenced-based clinical techniques \cite{reamer_artificial_2023}. 
% Non-clinical AI agents like Replika and companion robots can also provide social support and reduce loneliness amongst individuals \cite{ahmed_humanrobot_2024, chaturvedi_social_2023, pani_can_2024, ta_user_2020}.

Present research largely focuses on \textit{\textbf{AI-based decision support tools}} in social service \cite{james_algorithmic_2023, kawakami2022improving}, especially predictive risk models (PRMs) used to predict social service risks and outcomes \cite{gillingham2019can, van2017predicting}, like the Allegheny Family Screening Tool (AFST), which assesses child abuse risk using data from US public systems \cite{chouldechova_case_2018, vaithianathan2017developing}. Elsewhere, researchers have also piloted PRMs to predict social service needs for the homeless using Medicaid data\cite{erickson_automatic_2018, pourat_easy_2023}, and AI-powered algorithms to promote health interventions for at-risk populations, such as HIV testing among Californian homeless \cite{rice_piloting_2018, yadav_maximizing_2017}.

\subsection{Generative AI and Human-AI Collaboration}
\label{subsec:relatedworkhaicollaboration}
Beyond decision-making algorithms and PRMs, advancements in generative AI, such as large language models (LLMs), open new possibilities for human-AI (HAI) collaboration in social services. 
LLMs have been called "revolutionary" \cite{fui2023generative} and a "seismic shift" \cite{cooper2023examining}, offering "content support" \cite{memmert2023towards} by generating realistic and coherent responses to user inputs \cite{cascella2023evaluating}. Their vastly improved capabilities and ubiquity \cite{cooper2023examining} makes them poised to revolutionise work patterns \cite{fui2023generative}. Generative AI is already used in fields like design, writing, music, \cite{han2024teams, suh2021ai, verheijden2023collaborative, dhillon2024shaping, gero2023social} healthcare, and clinical settings \cite{zhang2023generative, yu2023leveraging, biswas2024intelligent}, with promising results. However, the social service sector has been slower in adopting AI \cite{diez2023artificial, kawakami2023training}.

% Yet, the social service sector is one that could perhaps stand to gain the most from AI technologies. As Goldkind \cite{goldkind_social_2021} writes, social service, as a "values-centred profession with a robust code of ethics" (p. 372), is uniquely placed to inform the development of thoughtful algorithmic policy and practice. 
Social service, however, stands to benefit immensely from generative AI. SSPs work in time-poor environments \cite{tiah_can_2024}, often overwhelmed with tedious administrative work \cite{meilvang_working_2023} and large amounts of paperwork and data processing \cite{singer_ai_2023, tiah_can_2024}. 
% As such, workers often work in time-poor environments and are burdened with information overload and administrative tasks \cite{tiah_can_2024, meilvang_working_2023}. 
Generative AI is well-placed to streamline and automate tasks like formatting case notes, formulating treatment plans and writing progress reports, which can free up valuable time for more meaningful work like client engagement and enhance service quality \cite{fernando_integration_2023, perron_generative_2023, tiah_can_2024, thesocialworkaimentor_ai_nodate}. 

Given the immense potential, there has been emerging research interest in HAI collaboration and teamwork in the Human-Computer Interaction and Computer Supported Cooperative Work space \cite{wang_human-human_2020}. HAI collaboration and interaction has been postulated by researchers to contribute to new forms of HAI symbiosis and augmented intelligence, where algorithmic and human agents work in tandem with one another to perform tasks better than they could accomplish alone by augmenting each other's strengths and capabilities  \cite{dave_augmented_2023, jarrahi_artificial_2018}.

However, compared to the focus on AI decision-making and PRM tools, there is scant research on generative AI and HAI collaboration in the social service sector \cite{wykman_artificial_2023}. This study therefore seeks to fill this critical gap by exploring how SSPs use and interact with a novel generative AI tool, helping to expand our understanding of the new opportunities that HAI collaboration can bring to the social service sector.

\subsection{Challenges in AI Use in Social Service}
\label{subsec:relatedworkaiuse}

% Despite the immense potential of AI systems to augment social work practice, there are multiple challenges with integrating such systems into real-life practice. 
Despite its evident benefits, multiple challenges plague the integration of AI and its vast potential into real-life social service practice.
% Numerous studies have investigated the use of PRMs to help practitioners decide on a course of action for their clients. 
When employing algorithmic decision-making systems, practitioners often experience tension in weighing AI suggestions against their own judgement \cite{kawakami2022improving, saxena2021framework}, being uncertain of how far they should rely on the machine. 
% Despite often being instructed to use the tool as part of evaluating a client, 
Workers are often reluctant to fully embrace AI assessments due to its inability to adequately account for the full context of a case \cite{kawakami2022improving, gambrill2001need}, and lack of clarity and transparency on AI systems and limitations \cite{kawakami2022improving}. Brown et al. \cite{brown2019toward} conducted workshops using hypothetical algorithmic tools 
% to understand service providers' comfort levels with using such tools in their work,
and found similar issues with mistrust and perceived unreliability. Furthermore, introducing AI tools can  create new problems of its own, causing confusion and distrust amongst workers \cite{kawakami2022improving}. Such factors are critical barriers to the acceptance and effective use of AI in the sector.

\citeauthor{meilvang_working_2023} (2023) cites the concept of \textit{boundary work}, which explores the delineation between "monotonous" administrative labour and "professional", "knowledge based" work drawing on core competencies of SSPs. While computers have long been used for bureaucratic tasks like client registration, the introduction of decision support systems like PRMs stirred debate over AI "threatening professional discretion and, as such, the profession itself" \cite{meilvang_working_2023}. Such latent concerns arguably drive the resistance to technology adoption described above. Generative AI is only set to further push this boundary, 
% these concerns are only set to grow in tandem with the vast capabilities of generative and other modern AI systems. Compared to the relatively primitive AI systems in past years, perceived as statistical algorithms \cite{brown2019toward} turning preset inputs like client age and behavioural symptoms \cite{vaithianathan2017developing} into simple numerical outputs indicating various risk scores, modern AI systems are vastly more capable: LLMs 
with its ability to formulate detailed reports and assessments that encroach upon the "core" work of SSPs.
% accept unrestricted and unstructured inputs and return a range of verbose and detailed evaluations according to the user's instructions. 
Introducing these systems exacerbate previously-raised issues such as understanding the limitations and possibilities of AI systems \cite{kawakami2022improving} and risk of overreliance on AI \cite{van2023chatgpt}, and requires a re-examination of where users fall on the algorithmic aversion-bias scale \cite{brown2019toward} and how they detect and react to algorithmic failings \cite{de2020case}. We address these critical issues through an empirical, on-the-ground study that to our knowledge is the first of its kind since the new wave of generative AI.

% W 

% Yet, to date, we have limited knowledge on the real-world impacts and implications of human-AI collaboration, and few studies have investigated practitioners’ experiences working with and using such AI systems in practice, especially within the social work context \cite{kawakami2022improving}. A small number of studies have explored practitioner perspectives on the use of AI in social work, including Kawakami et al. \cite{kawakami2022improving}, who interviewed social workers on their experiences using the AFST; Stapleton et al. \cite{stapleton_imagining_2022}, who conducted design workshops with caseworkers on the use of PRMs in child welfare; and Wassal et al. \cite{wassal_reimagining_2024}, who interviewed UK social work professionals on the use of AI. A common thread from all these studies was a general disregard for the context and users, with many practitioners criticising the failure of past AI tools arising from the lack of participation and involvement of social workers and actual users of such systems in the design and development of algorithmic systems \cite{wassal_reimagining_2024}. Similarly, in a scoping review done on decision-support algorithms in social work, Jacobi \& Christensen \cite{jacobi_functions_2023} reported that the majority of studies reveal limited bottom-up involvement and interaction between social workers, researchers and developers, and that algorithms were rarely developed with consideration of the perspective of social workers.
% so the \cite{yang_unremarkable_2019} and \cite{holten_moller_shifting_2020} are not real-world impacts? real-world means to hear practitioner's voice? I feel this is quite important but i didnt get this point in intro!

% why mentioning 'which have largely focused on existing ADS tools (e.g., AFST)'? i can see our strength is more localized, but without basic knowledge of social work i didnt get what's the 'departure' here orz
% the paragraph is great! do we need to also add one in line 20 21?

\subsection{Designing AI for Social Service through Participatory Design}
\label{subsec:relatedworkpd}
% i think it's important! but maybe not a whole subsection? but i feel the strong connection with practitioners is indeed one of our novelties and need to highlight it, also in intro maybe
% Participatory design (PD) has long been used extensively in HCI \cite{muller1993participatory}, to both design effective solutions for a specific community and gain a deep understanding of that community. Of particular interest here is the rich body of literature on PD in the field of healthcare \cite{donetto2015experience}, which in this regard shares many similarities and concerns with social work. PD has created effective health improvement apps \cite{ryu2017impact}, 

% PD offers researchers the chance to gather detailed user requirements \cite{ryu2017impact}...

Participatory design (PD) is a staple of HCI research \cite{muller1993participatory}, facilitating the design of effective solutions for a specific community while gaining a deep understanding of its stakeholders. The focus in PD of valuing the opinions and perspectives of users as experts \cite{schuler_participatory_1993} 
% In recent years, the tech and social work sectors have awakened to the importance of involving real users in designing and implementing digital technologies, developing human-centred design processes to iteratively design products or technologies through user feedback 
has gained importance in recent years \cite{storer2023reimagining}. Responding to criticisms and failures of past AI tools that have been implemented without adequate involvement and input from actual users, HCI scholars have adopted PD approaches to design predictive tools to better support human decision-making \cite{lehtiniemi_contextual_2023}.
% ; accordingly, in social service, a line of research has begun studying and designing for human-AI collaboration with real-world users (e.g. \cite{holten_moller_shifting_2020, kawakami2022improving, yang_unremarkable_2019}).
Section \ref{subsec:relatedworkaiuse} shows a clear need to better understand SSP perspectives when designing and implementing AI tools in the social sector. 
Yet, PD research in this area has been limited. \citeauthor{yang2019unremarkable} (2019), through field evaluation with clinicians, investigated reasons behind the failure of previous AI-powered decision support tools, allowing them to design a new-and-improved AI decision-support tool that was better aligned with healthcare workers’ workflows. Similarly, \citeauthor{holten_moller_shifting_2020} (2020) ran PD workshops with caseworkers, data scientists and developers in public service systems to identify the expectations and needs that different stakeholders had in using ADS tools.

% Indeed, it is as Wise \cite{wise_intelligent_1998} noted so many years ago on the rise of intelligent agents: “it is perhaps when technologies are new, when their (and our) movements, habits and attitudes seem most awkward and therefore still at the forefront of our thoughts that they are easiest to analyse” (p. 411). 
Building upon this existing body of work, we thus conduct a study to co-design an AI tool \textit{for} and \textit{with} SSPs through participatory workshops and focus group discussions. In the process, we revisit many of the issues mentioned in Section \ref{subsec:relatedworkaiuse}, but in the context of novel generative AI systems, which are fundamentally different from most historical examples of automation technologies \cite{noy2023experimental}. This valuable empirical inquiry occurs at an opportune time when varied expectations about this nascent technology abound \cite{lehtiniemi_contextual_2023}, allowing us to understand how SSPs incorporate AI into their practice, and what AI can (or cannot) do for them. In doing so, we aim to uncover new theoretical and practical insights on what AI can bring to the social service sector, and formulate design implications for developing AI technologies that SSPs find truly meaningful and useful.
% , and drive future technological innovations to transform the social service sector not just within [our country], but also on a global scale.

 % with an on-the-ground study using a real prototype system that reflects the state of AI in current society. With the presumption that AI will continue to be used in social work given the great benefits it brings, we address the pressing need to investigate these issues to ensure that any potential AI systems are designed and implemented in a responsible and effective manner.

% Building upon these works, this study therefore seeks to adopt a participatory design methodology to investigate social workers’ perspectives and attitudes on AI and human-AI collaboration in their social work practice, thus contributing to the nascent body of practitioner-centred HCI research on the use of AI in social work. Yet, in a departure from prior work, which have largely focused on existing ADS tools (e.g., AFST) and were situated in a Western context, our paper also aims to expand the scope by piloting a novel generative AI tool that was designed and developed by the researchers in partnership with a social service agency based in Singapore, with aims of generating more insights on wider use cases of AI beyond what has been previously studied.

% i may think 'While the current lacunae of research on applications of AI in social work may appear to be a limitation, it simultaneously presents an exciting opportunity for further research and exploration \cite{dey_unleashing_2023},' this point is already convincing enough, not sure if we need to quote here
% I like this end! it's a good transition to our study design, do we need to mention the localization in intro as well? like we target at singapore

% Given the increasing prominence and acceptance of AI in modern society, 

% These increased capabilities vastly exacerbate the issues already present with a simpler tool like the AFST: the boundaries and limitations of an LLM system are significantly more difficult to understand and its possible use cases are exponentially greater in scope. 

% Put this in discussion section instead?
% Kawakami et al's work "highlights the importance of studying how collaborative decision-making... impacts how people rely upon and make sense of AI models," They conclude by recommending designing tools that "support workers in understanding the boundaries of [an AI system's] capabilities", and implementing design procedures that "support open cultures for critical discussion around AI decision making". The authors outline critical challenges of implementing AI systems, elucidating factors that may hinder their effectiveness and even negatively affect operations within the organisation.


% Is this needed?:
% talk about the strengths of PD in eliciting user viewpoints and knowledge, in particular when it is a field that is novel or where a certain system has not been used or developed or tested before