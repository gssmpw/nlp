
\section{Discussion and Conclusion}

% \begin{quote}
% \textit{"We believe it is unethical for social workers not to learn... about technology-mediated social work."} (\citeauthor{singer_ai_2023}, 2023)
% \end{quote}

In this study, we uncovered multiple ways in which GenAI can be used in social service practice. While some concerns did arise, practitioners by and large seemed optimistic about the possibilities of such tools, and that these issues could be overcome. We note that while most participants found the tool useful, it was far from perfect in its outputs. This is not surprising, since it was powered by a generic LLM rather than one fine-tuned for social service case management. However, despite these inadequacies, our participants still found many uses for most of the tool's outputs. Many flaws pointed out by our participants related to highly contextualised, local knowledge. To tune an AI system for this would require large amounts of case files as training data; given the privacy concerns associated with using client data, this seems unlikely to happen in the near future. What our study shows, however, is that GenAI systems need not aim to be perfect to be useful to social service practitioners, and can instead serve as a complement to the critical "human touch" in social service.

We draw both inspiration and comparisons with prior work on AI in other settings. Studies on creative writing tools showed how the "uncertainty" \cite{wan2024felt} and "randomness" \cite{clark2018creative} of AI outputs aid creativity. Given the promise that our tool shows in aiding brainstorming and discussion, future social service studies could consider AI tools explicitly geared towards creativity - for instance, providing side-by-side displays of how a given case would fit into different theoretical frameworks, prompting users to compare, contrast, and adopt the best of each framework; or allowing users to play around with combining different intervention modalities to generate eclectic (i.e. multi-modal) interventions.

At the same time, the concept of supervision creates a different interaction paradigm to other uses of AI in brainstorming. Past work (e.g. \cite{shaer2024ai}) has explored the use of GenAI for ideation during brainstorming sessions, wherein all users present discuss the ideas generated by the system. With supervision in social service practice, however, there is a marked information and role asymmetry: supervisors may not have had the time to fully read up on their supervisee's case beforehand, yet have to provide guidance and help to the latter. We suggest that GenAI can serve a dual purpose of bringing supervisors up to speed quickly by summarising their supervisee's case data, while simultaneously generating a list of discussion and talking points that can improve the quality of supervision. Generalising, this interaction paradigm has promise in many other areas: senior doctors reviewing medical procedures with newer ones \cite{snowdon2017does} could use GenAI to generate questions about critical parts of a procedure to ask the latter, confirming they have been correctly understood or executed; game studio directors could quickly summarise key developmental pipeline concerns to raise at meetings and ensure the team is on track; even in academia, advisors involved in rather too many projects to keep track of could quickly summarise each graduate student's projects and identify potential concerns to address at their next meeting.

In closing, we are optimistic about the potential for GenAI to significantly enhance social service practice and the quality of care to clients. Future studies could focus on 1) longitudinal investigations into the long-term impact of GenAI on practitioner skills, client outcomes, and organisational workflows, and 2) optimising workflows to best integrate GenAI into casework and supervision, understanding where best to harness the speed and creativity of such systems in harmony with the experience and skills of practitioners at all levels.

% GenAI here thus serves as a tool that supervisors can use before rather then using the session, taking just a few minutes of their time to generate a list of discussion points with their supervisees.

% Traditional brainstorming comes up with new things that users discuss. In supervision, supervisors can use AI to more efficiently generate talking points with their supervisees. These are generally not novel ideas, since an experienced worker would be able to come up with these on their own. However, the interesting and novel use of AI here is in its use as a preparation tool, efficiently generating talking and discussion points, saving supervisors' time in preparing for a session, while still serving as a brainstorming tool during the session itself.

% The idea of embracing imperfect AI echoes the findings of \citeauthor{bossen2023batman} (2023) in a clinical decision setting, which examined the successful implementation of an "error-prone but useful AI tool". This study frames human-AI collaboration as "Batman and Robin", where AI is a useful but ultimately less skilled sidekick that plays second fiddle to Batman. This is similar to \citeauthor{yang2019unremarkable}'s (2019) idea of "unremarkable AI", systems designed to be unobtrusive and only visible to the user when they add some value. As compared to \citeauthor{bossen2023batman}, however, we see fewer instances of our AI system producing errors, and more examples of it providing learning and collaborative opportunities and other new use cases. We build on the idea of "complementary performance" \cite{bansal2021does}, which discusses how the unique expertise of AI enhances human decision-making performance beyond what humans can achieve alone. Beyond decision-making, GenAI can now enable "complementary work patterns", where the nature of its outputs enables humans to carry out their work in entirely new ways. Our study suggests that rather being a sidekick - Robin - AI is growing into the role of a "second Batman" or "AI-Batman": an entity with distinct abilities and expertise from humans, and that contributes in its own unique way. There is certainly still a time and place for unremarkable AI, but exploring uses beyond that paradigm uncovers entirely new areas of system design.

% % \cite{gero2022sparks} found AI to be useful for science writers to translate ideas already in their head into words, and to provide new perspectives to spark further inspiration. \textit{But how is ours different from theirs?}

% \subsection{New Avenues of Human-AI Collaboration}
% \label{subsubsec:discussionhaicollaboration}

% Past HCI literature in other areas \cite{nah2023generative} has suggested that GenAI represents a "leap" \cite{singh2023hide} in human-AI collaboration, 
% % Even when an AI system sometimes produces irrelevant outputs, it can still provide users 
% % Such systems have been proposed as ways to 
% helping users discover new viewpoints \cite{singh2023hide}, scour existing literature to suggest new hypotheses 
% \cite{cascella2023evaluating} and answer questions \cite{biswas2023role}, stimulate their cognitive processes \cite{memmert2023towards}, and overcome "writer's block" \cite{singh2023hide, cooper2023examining} (particularly relevant to SSPs and the vast amount of writing required of them). Our study finds promise for AI to help SSPs in all of these areas. By nature of being more verbose and capable of generating large amounts of content, GenAI seems to create a new way in which AI can complement human work and expertise. Our system, as LLMs tend to do, produced a lot of "bullshit" (S6) \cite{frankfurt2005bullshit} - superficially true statements that were often only "tangentially related" and "devoid of meaning" \cite{halloran2023ai}. Yet, many participants cited the page-long analyses and detailed multi-step intervention plans generated by the AI system to be a good starting point for further discussion, both to better conceptualize a particular case and to facilitate general worker growth and development. Almost like throwing mud at a wall to see what sticks, GenAI can quickly produce a long list of ideas or information, before the worker glances through it and quickly identifies the more interesting points to discuss. Playing the proposed role as a "scaffold" for further work \cite{cooper2023examining}, GenAI, literally, generates new opportunities for novel and more effective processes and perspectives that previous systems (e.g., PRMs) could not. This represents an entirely new mode of human-AI collaboration.
% % This represents a new mode of collaboration not possible with the largely quantitative AI models (like PRMs) of the past.

% Our work therefore supports and extends prior research that have postulated the the potential of AI's shifting roles from decision-maker to human-supporter \cite{wang_human-human_2020}. \citeauthor{siemon2022elaborating} (2022) suggests the role of AI as a "creator" or "coordinator", rather than merely providing "process guidance" \cite{memmert2023towards} that does not contribute to brainstorming. Similarly, \citeauthor{memmert2023towards} (2023) propose GenAI as a step forward from providing meta-level process guidance (i.e. facilitating user tasks) to actively contributing content and aiding brainstorming. We suggest that beyond content-support, AI can even create new work processes that were not possible without GenAI. In this sense, AI has come full circle, becoming a "meta-facilitator".

% % --- WIP BELOW ---

% % Our work echoes and extends previous research on HAI collaboration in tasks requiring a human touch. \cite{gero2023social} found AI to be a safe space for creative writers to bounce ideas off of and document their inner thoughts. \cite{dhillon2024shaping} reference the idea of appropriate scaffolding in argumentative writing, where the user is providing with guidance appropriate for their competency level, and also warns of decreased satisfaction and ownership from AI use. 

% Separately, we draw parallels with the field of creative writing, where HAI collaboration has been extensively researched. Writers note the "irreducibly human" aspect of creativity in writing \cite{gero2023social}, similar to the "human touch" core to social service practice (D1); both groups therefore expressed few concerns about AI taking over core aspects of their jobs. Another interesting parallel was how writers often appreciated the "uncertainty" \cite{wan2024felt} and "randomness" \cite{clark2018creative} of AI systems, which served as a source of inspiration. This echoes the idea of "imperfect AI" "expanding [the] perspective[s]" (S4) of our participants when they simply skimmed through what the AI produced. \cite{wan2024felt} cited how the "duality of uncertainty in the creativity process advances the exploration of the imperfection of GenAI models". While social service work is not typically regarded as "creative", practitioners nonetheless go through processes of ideation and iteration while formulating a case. Our study showed hints of how AI can help with various forms of ideation, but, drawing inspiration from creative writing tools, future studies could consider designs more explicitly geared towards creativity - for instance, by attempting to fit a given case into a number of different theories or modalities, and displaying them together for the user to consider. While many of these assessments may be imperfect or even downnright nonsensical, they may contain valuable ideas and new angles on viewing the case that the practitioner can integrate into their own assessment.

% % \cite{foong2024designing}, describing the design of caregiver-facing values elicitation tools, cites the "twin scenarios" that caregivers face - private use, where they might use a tool to discover their patient's values, and collaborative use, where they discuss the resulting values with other parties close to the patient. This closely mirrors how SSPs in our study reference both individual and collaborative uses of our tool. Unlike in \cite{foong2024designing}, however, we do not see a resulting need to design a "staged approach" with distinct interface features for both stages.

% % --- END OF WIP ---

% Having mentioned algorithm aversion previously, we also make a quick point here on the other end of the spectrum - automation bias, or blind trust in an automated system \cite{brown2019toward}. LLMs risk being perceived as an "ultimate epistemic authority" \cite{cooper2023examining} due to their detailed, life-like outputs. While automation bias has been studied in many contexts, including in the social sector or adjacent areas, we suggest that the very nature of GenAI systems fundamentally inhibits automation bias. The tendency of GenAI to produce verbose, lengthy explanations prompts users to read and think through the machine's judgement before accepting it, bringing up opportunities to disagree with the machine's opinion. This guards against blind acceptance of the system's recommendations, particularly in the culture of a social work agency where constant dialogue - including discussing AI-produced work - is the norm.


% % : Perception of AI in Social Service Work ??

% \subsection{Redefining the Boundary}
% \label{subsubsec:discussiontheoretical}

% As \citeauthor{meilvang_working_2023} (2023) describes, the social service profession has sought to distance itself from comprising mostly "administrative work" \cite{abbott2016boundaries}, and workers have long tried to tried to reduce their considerable time \cite{socialraadgiverforening2010notat} spent on such tasks in favour of actual casework with clients \cite{toren1972social}. Our study, however, suggests a blurring of the line between "manual" administrative tasks and "mental" casework that draws on practitioner expertise. Many tasks our participants cited involve elements of both: for instance, documenting a case recording requires selecting only the relevant information to include, and planning an intervention can be an iterative process of drafting a plan and discussing it with colleagues and superiors. This all stems from the fact that GenAI can produce virtually any document required by the user, but this document almost always requires revision under a watchful human eye.

% \citeauthor{meilvang_working_2023} (2023) also describes a more recent shift in the perceived accepted boundary of AI interventions in social service work. From "defending [the] jurisdiction [of social service work] against artificial intelligence" in the early days of PRM and other statistical assessment tools, the community has started to embrace AI as a "decision-support ... element in the assessment process". Our study concurs and frames GenAI as a source of information that can be used to support and qualify the assessments of SSPs \cite{meilvang_working_2023}, but suggests that we can take a step further: AI can be viewed as a \textit{facilitator} rather than just a supporter. GenAI can facilitate a wide range of discussions that promote efficiency, encourage worker learning and growth, and ultimately enhance client outcomes. This entails a much larger scope of AI use, where practitioners use the information provided by AI in a range of new scenarios. 

% Taken together, these suggest a new focus for boundary work and, more broadly, HCI research. GAI can play a role not just in menial documentation or decision-support, but can be deeply ingrained into every facet of the social service workflow to open new opportunities for worker growth, workflow optimisation, and ultimately improved client outcomes. Future research can therefore investigate the deeper, organisational-level effects of these new uses of AI, and their resulting impact on the role of profession discretion in effective social service work.

% % MH: oh i feel this paragraph is quite new to me! Could we elaborate this more, and truncate the first two paragraphs a bit to adjust the word propotion?


% % Our study extensively documents this for the first time in social service practice, and in the process reveals new insights about how AI can play such a role.



% \subsection{Design Implications}

% % Add link from ACE diagram?

% % EJ: it would be interesting to discuss how LLMs could help "hands-on experience" in the discussion section

% Addressing the struggle of integrating AI amidst the tension between machine assessment and expert judgement, we reframe AI as an \textit{facilitator} rather than an algorithm or decision-support tool, alleviating many concerns about trust and explainablity. We now present a high-level framework (Figure \ref{fig:hai-collaboration}) on human-AI collaboration, presenting a new perspective on designing effective AI systems that can be applied to both the social service sector and beyond.

% \begin{figure}
%     \centering
%     \includegraphics[scale=0.15]{images/designframework.png}
%     \caption{Framework for Human-AI Collaboration}
%     \label{fig:hai-collaboration}
%     \Description{An image showing our framework for Human-AI Collaboration. It shows that as stakeholder level increases from junior to senior, the directness of use shifts from co-creation to provision.}
% \end{figure}
% % MH: so this paradigm is proposed by us? I wonder if this could a part of results as well..?

% % \subsubsection{From Creation to Provision}

% In Section \ref{sec:stage2findings}, we uncovered the different ways in which SSPs of varying seniorities use, evaluate, and suggest uses of AI. These are intrinsically tied to the perspectives and levels of expertise that each stakeholder possesses. We therefore position the role of AI along the scale of \textit{creation} to \textit{provision}. 

% With junior workers, we recommend \textbf{designing tools for co-creation}: systems that aid the least experienced workers in creating the required deliverables for their work. Rather than \textit{telling} workers what to do - a difficult task in any case given the complexity of social work solutions - AI systems should instead \textit{co-create} deliverables required of these workers. These encompass the multitude of use cases that junior workers found useful: creating reports, suggesting perspectives from which to formulate a case, and providing a starting template for possible intervention plans. Notably, since AI outputs are not perfect, we emphasise the "co" in "co-creation": AI should only be a part of the workflow that also includes active engagement on the part of the SSPs and proactive discussion with supervisors. 

% For more experienced SSPs, we recommend \textbf{designing tools for provision}. Again, this is not the mere provision of recommendations or courses of action with clients, but rather that of resources which complement the needs of workers with greater responsibilities. This notably includes supplying materials to aid with supervision, a novel use case that to our knowledge has not surfaced in previous literature. In addition, senior workers also benefit greatly from manual tasks such as routine report writing and data processing. Since these workers are more experienced and can better spot inaccuracies in AI output, we suggest that AI can "provide" a more finished product that requires less vetting and corrections, and which can be used more directly as part of required deliverables.

% % MH: can we seperate here? above is about the guidance to paradigm, below is the practical roadmap for implementation
% In terms of concrete design features, given the constant focus on discussing AI outputs between colleagues in our FGDs, we recommend that AI tools, particularly those for junior workers, \textbf{include collaborative features} that facilitate feedback and idea sharing between users. We also suggest that designers work closely with domain experts (i.e. social work practitioners and agencies) to identify areas where the given AI model tends to make more mistakes, and to build in features that \textbf{highlight potential mistakes or inadequacies} in the AI's output to facilitate further discussion and avoid workers adopting suboptimal suggestions. 

% We also point out a fundamental difference between GenAI systems and previous systems: that GenAI can now play an important role in aiding users \textit{regardless of its flaws}. The nature of GenAI means that it promotes discussion and opens up new workflows by nature of its verbose and potentially incomplete outputs. Rather than working towards more accurate or explainable outcomes, which may in any case have minimal improvement on worker outcomes \cite{li2024advanced}, designers can also focus on \textbf{understanding how GenAI outputs can augment existing user flows and create new ones}.

% % for more senior workers...

% % how to differentiate levels of workers?

% % \subsubsection{Provider}

% % The most basic and obvious role of modern AI that we identify leverages the main strength of LLMs. They have the ability to produce high-quality writing from short, point-form, or otherwise messy and disjoint case notes that user often have \textit{[cite participant here]}. 

% Finally, given the limited expertise of many workers at using AI, it is important that systems \textbf{explicitly guide users to the features they need}, rather than simply relying on the ability of GAI to understand complex user instructions. For example, in the case of flexibility in use cases (Section \ref{subsubsec:control}), systems should include user flows that help combine multiple intervention and assessment modalities in order to directly meet the needs of workers.

% \subsection{Limitations and Future Work}

% While we attempt to mimic a contextual inquiry and work environment in our study design, there is no substitute for real data from actual system deployment. The use of an AI system in day-to-day work could reveal a different set of insights. Future studies could in particular study how the longitudinal context of how user attitudes, behaviours, preferences, and work outputs change with extended use of AI. 

% While we tried to include practitioners from different agencies, roles, and seniorities, social service practice may differ culturally or procedurally in other agencies or countries. Future studies could investigate different kinds of social service agencies and in different cultures to see if AI is similarly useful there.

% As the study was conducted in a country with relatively high technology literacy, participants naturally had a higher baseline understanding and acceptance of AI and other computer systems. However, we emphasise that our findings are not contingent on this - rather, we suggest that our proposed lens of viewing AI in the social sector is a means for engaging in relevant stakeholders and ensuring the effective design and implementation of AI in the social sector, regardless of how participants feel about AI to begin with. 



% % \subsection{Notes}

% % 1) safety and risks and 2) privacy - what does the emphasis on this say about a) design recommendations and b) approach to designing/PD of such systems?


% % W9 was presented with "Strengths" and "SFBT" output options. They commented, "solution focus is always building on the person's strengths". W9 therefore requested being able to output strengths and SFBT at the same time. But this would suggest that the SFBT output does not currently emphasise strengths strongly enough. However, W9 did not specifically evaluate that, and only made this comment because they saw the "strengths" option available, and in their head, strengths are key to SFBT.
% % What does this say about system design and UI in relation to user mental models?