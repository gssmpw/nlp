\section{Related Work}
\label{sec:relatedwork}

\subsection{Current AI Tools for Social Service Practitioners}
\label{subsec:relatedtools}
% the title I feel is quite broad

Artificial Intelligence (AI) has long been used for risk assessments, decision-making, and workload management in sectors like child protection services and mental health treatment \cite{fluke_artificial_1989, patterson_application_1999}. 
Recent applications in clinical social work include risk assessments \cite{gillingham2019can, jacobi_functions_2023, liedgren_use_2016, molala_social_2023}, public health initiatives \cite{rice_piloting_2018}, and education and training for practitioners \cite{asakura_call_2020, tambe_artificial_2018}. Present studies on case management focus mainly on decision support tools \cite{james_algorithmic_2023, kawakami2022improving}, especially predictive risk models (PRMs) used to predict social service risks and outcomes \cite{gillingham2019can, van2017predicting}. A prominent example is the Allegheny Family Screening Tool (AFST), which assesses child abuse risk using data from US public systems \cite{chouldechova_case_2018, vaithianathan2017developing}. Elsewhere, researchers have also piloted AI systems to predict social service needs for the homeless using Medicaid data \cite{erickson_automatic_2018, pourat_easy_2023} or promote health interventions like HIV testing among at-risk populations \cite{rice_piloting_2018, yadav_maximizing_2017}.

Beyond such tools, however, the sector also stands to benefit immensely from newer forms of AI, such as GenAI. SSPs work in time-poor environments \cite{tiah_can_2024}, being often overwhelmed with tedious administrative work \cite{meilvang_working_2023} and large amounts of paperwork and data processing \cite{singer_ai_2023, tiah_can_2024}. GenAI is well placed to streamline and automate tasks such as the formatting of case notes, the formulation of treatment plans, and the writing of progress reports, allowing valuable time to be spent on more meaningful work, such as client engagement and the improvement of service quality \cite{fernando_integration_2023, perron_generative_2023, tiah_can_2024, thesocialworkaimentor_ai_nodate}. There is, however, scant research on GenAI in the social service sector \cite{wykman_artificial_2023}.

% This study therefore seeks to fill this critical gap by exploring how SSPs use and interact with a novel GenAI tool, helping to expand our understanding of the new opportunities that HAI collaboration can bring to the social service sector.

% AI has also been employed for mental health support and therapeutic interventions, with conversational agents serving as on-demand virtual counsellors to provide clinical care and support \cite{lisetti_i_2013, reamer_artificial_2023}.

% The recent rise of GenAI is poised to further advance social service practice, facilitating the automation of administrative tasks, streamlining of paperwork and documentation, optimisation of resource allocation, data analysis, and enhancing client support and interventions \cite{fernando_integration_2023, perron_generative_2023}.


% commercial solutions include Woebot, which simulates therapeutic conversation, and Wysa, an “emotionally intelligent” AI coach, powered by evidenced-based clinical techniques \cite{reamer_artificial_2023}. 
% Non-clinical AI agents like Replika and companion robots can also provide social support and reduce loneliness amongst individuals \cite{ahmed_humanrobot_2024, chaturvedi_social_2023, pani_can_2024, ta_user_2020}.


\subsection{Challenges in AI Use in Social Service}
\label{subsec:relatedworkaiuse}

% Despite the immense potential of AI systems to augment social work practice, there are multiple challenges with integrating such systems into real-life practice. 
Despite its evident benefits, multiple challenges plague the integration of AI and its vast potential into real-life social service practice.
% Numerous studies have investigated the use of PRMs to help practitioners decide on a course of action for their clients. 
When employing algorithmic decision-making systems, practitioners often experience tension in weighing AI suggestions against their own judgement \cite{kawakami2022improving, saxena2021framework}, being uncertain of how far they should rely on the machine. 
% Despite often being instructed to use the tool as part of evaluating a client, 
Workers are often reluctant to fully embrace AI assessments due to its inability to adequately account for the full context of a case \cite{kawakami2022improving, gambrill2001need}, and lack of clarity and transparency on AI systems and limitations \cite{kawakami2022improving}. Brown et al. \cite{brown2019toward} conducted workshops using hypothetical algorithmic tools 
% to understand service providers' comfort levels with using such tools in their work,
and found similar issues with mistrust and perceived unreliability. Furthermore, introducing AI tools can create new problems of its own, causing confusion and distrust amongst workers \cite{kawakami2022improving}. Such factors are critical barriers to the acceptance and effective use of AI in the sector.

\citeauthor{meilvang_working_2023} (2023) cites the concept of \textit{boundary work}, which explores the delineation between "monotonous" administrative labour and "professional", "knowledge-based" work drawing on core competencies of SSPs. While computers have long been used for bureaucratic tasks such as client registration, the introduction of decision support systems like PRMs stirred debate over AI "threatening professional discretion and, as such, the profession itself" \cite{meilvang_working_2023}. Such latent concerns arguably drive the resistance to technology adoption described above. GenAI is only set to further push this boundary, 
% these concerns are only set to grow in tandem with the vast capabilities of generative and other modern AI systems. Compared to the relatively primitive AI systems in past years, perceived as statistical algorithms \cite{brown2019toward} turning preset inputs like client age and behavioural symptoms \cite{vaithianathan2017developing} into simple numerical outputs indicating various risk scores, modern AI systems are vastly more capable: LLMs 
with its ability to formulate detailed reports and assessments that encroach upon the "core" work of SSPs.
% accept unrestricted and unstructured inputs and return a range of verbose and detailed evaluations according to the user's instructions. 
Introducing these systems exacerbates previously-raised issues such as understanding the limitations and possibilities of AI systems \cite{kawakami2022improving} and risk of overreliance on AI \cite{van2023chatgpt}, and requires a re-examination of where users fall on the algorithmic aversion-bias scale \cite{brown2019toward} and how they detect and react to algorithmic failings \cite{de2020case}. We address these critical issues through an empirical, on-the-ground study that to our knowledge is the first of its kind since the new wave of GenAI.

% W 

% Yet, to date, we have limited knowledge on the real-world impacts and implications of human-AI collaboration, and few studies have investigated practitioners’ experiences working with and using such AI systems in practice, especially within the social work context \cite{kawakami2022improving}. A small number of studies have explored practitioner perspectives on the use of AI in social work, including Kawakami et al. \cite{kawakami2022improving}, who interviewed social workers on their experiences using the AFST; Stapleton et al. \cite{stapleton_imagining_2022}, who conducted design workshops with caseworkers on the use of PRMs in child welfare; and Wassal et al. \cite{wassal_reimagining_2024}, who interviewed UK social work professionals on the use of AI. A common thread from all these studies was a general disregard for the context and users, with many practitioners criticising the failure of past AI tools arising from the lack of participation and involvement of social workers and actual users of such systems in the design and development of algorithmic systems \cite{wassal_reimagining_2024}. Similarly, in a scoping review done on decision-support algorithms in social work, Jacobi \& Christensen \cite{jacobi_functions_2023} reported that the majority of studies reveal limited bottom-up involvement and interaction between social workers, researchers and developers, and that algorithms were rarely developed with consideration of the perspective of social workers.
% so the \cite{yang_unremarkable_2019} and \cite{holten_moller_shifting_2020} are not real-world impacts? real-world means to hear practitioner's voice? I feel this is quite important but i didnt get this point in intro!

% why mentioning 'which have largely focused on existing ADS tools (e.g., AFST)'? i can see our strength is more localized, but without basic knowledge of social work i didnt get what's the 'departure' here orz
% the paragraph is great! do we need to also add one in line 20 21?

% \subsection{Designing AI for Social Service through Participatory Design}
% \label{subsec:relatedworkpd}
% % i think it's important! but maybe not a whole subsection? but i feel the strong connection with practitioners is indeed one of our novelties and need to highlight it, also in intro maybe
% % Participatory design (PD) has long been used extensively in HCI \cite{muller1993participatory}, to both design effective solutions for a specific community and gain a deep understanding of that community. Of particular interest here is the rich body of literature on PD in the field of healthcare \cite{donetto2015experience}, which in this regard shares many similarities and concerns with social work. PD has created effective health improvement apps \cite{ryu2017impact}, 

% % PD offers researchers the chance to gather detailed user requirements \cite{ryu2017impact}...

% Participatory design (PD) is a staple of HCI research \cite{muller1993participatory}, facilitating the design of effective solutions for a specific community while gaining a deep understanding of its stakeholders. The focus in PD of valuing the opinions and perspectives of users as experts \cite{schuler_participatory_1993} 
% % In recent years, the tech and social work sectors have awakened to the importance of involving real users in designing and implementing digital technologies, developing human-centred design processes to iteratively design products or technologies through user feedback 
% has gained importance in recent years \cite{storer2023reimagining}. Responding to criticisms and failures of past AI tools that have been implemented without adequate involvement and input from actual users, HCI scholars have adopted PD approaches to design predictive tools to better support human decision-making \cite{lehtiniemi_contextual_2023}.
% % ; accordingly, in social service, a line of research has begun studying and designing for human-AI collaboration with real-world users (e.g. \cite{holten_moller_shifting_2020, kawakami2022improving, yang_unremarkable_2019}).
% Section \ref{subsec:relatedworkaiuse} shows a clear need to better understand SSP perspectives when designing and implementing AI tools in the social sector. 
% Yet, PD research in this area has been limited. \citeauthor{yang2019unremarkable} (2019), through field evaluation with clinicians, investigated reasons behind the failure of previous AI-powered decision support tools, allowing them to design a new-and-improved AI decision-support tool that was better aligned with healthcare workers’ workflows. Similarly, \citeauthor{holten_moller_shifting_2020} (2020) ran PD workshops with caseworkers, data scientists and developers in public service systems to identify the expectations and needs that different stakeholders had in using ADS tools.

% % Indeed, it is as Wise \cite{wise_intelligent_1998} noted so many years ago on the rise of intelligent agents: “it is perhaps when technologies are new, when their (and our) movements, habits and attitudes seem most awkward and therefore still at the forefront of our thoughts that they are easiest to analyse” (p. 411). 
% Building upon this existing body of work, we thus conduct a study to co-design an AI tool \textit{for} and \textit{with} SSPs through participatory workshops and focus group discussions. In the process, we revisit many of the issues mentioned in Section \ref{subsec:relatedworkaiuse}, but in the context of novel GenAI systems, which are fundamentally different from most historical examples of automation technologies \cite{noy2023experimental}. This valuable empirical inquiry occurs at an opportune time when varied expectations about this nascent technology abound \cite{lehtiniemi_contextual_2023}, allowing us to understand how SSPs incorporate AI into their practice, and what AI can (or cannot) do for them. In doing so, we aim to uncover new theoretical and practical insights on what AI can bring to the social service sector, and formulate design implications for developing AI technologies that SSPs find truly meaningful and useful.
