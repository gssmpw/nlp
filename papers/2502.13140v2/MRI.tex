\subsection{Biomedical Imaging}\label{sec:td_imaging}
%\subsubsection{Applications}

Tensor decomposition methods have emerged as powerful tools for analyzing high-dimensional data in biomedical imaging~\cite{sedighin2024tensor}.
%By leveraging the ability to disentangle high-dimensional data into lower-dimensional components, these techniques can reduce computational complexity while preserving meaningful structural information, which is often obscured in raw data. 
Applications span a wide range of domains, including medical image denoising, super resolution, reconstruction, and so on, where tensors effectively model spatial, temporal, and spectral relationships in MRI and hyperspectral images. Beyond MRI and conventional imaging modalities, TD techniques have shown promise in analyzing high-dimensional datasets generated by multiphoton microscopy, including fluorescence-based and label-free modalities such as second harmonic generation (SHG) and third harmonic generation (THG) imaging~\cite{jamesdarian2021recent}.  In this section, we will review these applications from a methods perspective by discussing how each tensor decomposition technique is used in biomedical imaging analysis. 

\paragraph{CP decomposition.} CP decomposition is widely used in real-world data due to its simplicity, interpretability, and ability to efficiently represent multi-dimensional data. It decomposes the data tensor into a sum of rank-one components (Equation~\ref{eq:cp}) to uncover latent structures, which is particularly useful in data with spatial, temporal, and spectral dimensions like MRI data and hyperspectral image. CP decomposition has been used to reconstruct images from under-sampled data like brain \cite{li2023learned, hou2020matrix}, cardiac \cite{wu2018multiple} MRI and CT scans \cite{zhang2016tensor}. Using the low-rank nature of medical images it achieves high-quality reconstructions with reduced scan times. In magnetic resonance fingerprinting (MRF) reconstruction, CP decomposition is used as a component in a neural network to learn low-rank tensor priors~\cite{li2023learned}, avoiding computationally expensive SVD on high-dimensional data.  

CP decomposition can help reduce redundancy and has been used for brain MRI denoising~\cite{cao2016tensor, cui2020multidimensional}. By selecting the dominant components in CP decomposition, noise and artifacts in medical images can be effectively removed, preserving only the significant structures or patterns. Variants such as Bayesian CP decomposition have been proposed to recover the de-noised tensor from a noisy tensor by estimating rank-one tensors through a variational Bayesian inference strategy~\cite{cao2016tensor}. CP decomposition has been used in a dental CT super resolution task producing high SNR with robust segmentation quality~\cite{hatvani2018tensor}. It is also used in hyperspectral image unmixing with applications in fluorescence microscopy of retina~\cite{dey2019tensor}. In this work, different excitation wavelengths were assembled as a tensor and a non-negative CP decomposition was performed to obtain low-rank factors. Other applications include cardiac $T_1$ mapping \cite{yaman2019low} and feature extraction for multi-modal data, where a robust coupled CP decomposition was used with an assumption that the tensors shared the first factor marix~\cite{zhao2023robust}. In multiphoton microscopy, CP decomposition has been utilized to extract meaningful components from 3D distribution in disease models such as cancer and fibrosis~\cite{uckermann2020label}.
%In Cao \textit{et al.}'s work \cite{cao2016tensor}, a Bayesian CP decomposition method is proposed to recover the clean tensor from its noisy observation, in which the rank-one tensors are estimated through a variational Bayesian inference strategy. 

% For it providing simple representations for high dimensional tensors, CP decomposition has also been used for various tasks such as dental CT super resolution\cite{hatvani2018tensor}, hyperspectral image unmixing for fluorescence microscopy of retina \cite{dey2019tensor}, cardiac $T_1$ mapping \cite{yaman2019low}, and feature extraction for multimodal data \cite{zhao2023robust}. In Karahan \textit{et al.}'s work \cite{dey2019tensor}, images from different excitation wavelengths are assembled as a tensor, and non-negative CP decomposition is applied to the tensor to perform low-rank decomposition. In Zhao \textit{et al.}'s work \cite{zhao2023robust}, to extract common features from multiple tensors, a robust coupled CP decomposition is proposed with the assumption that these tensors share the first factor matrix of CP decomposition.


\paragraph{Tucker decomposition.}
%\os{(Shehab: In this section, every paragraph starts with the same phrase. Maybe some of them should be rephrased? Jiasen: They has been rephrased)}
Tucker decomposition expresses a tensor as a core tensor multiplied by factor matrices along each mode. Compared with HOSVD and CP decomposition, Tucker decomposition allows for arbitrary forms of factor matrices, providing a more general representation. It has been widely used for predicting missing information in high-dimensional images, with applications in super-resolution \cite{gui2017brain, jia2022nonconvex, hatvaniy2021single} and reconstruction \cite{wu2018multiple, wang2021spectral, li2018efficient}. The general model can be summarized as $\mathcal{T} = \mathcal{A}\mathcal{X} $ where $T$ is the observed tensor, $X$ is the original image to be predicted and $X$ is a linear operator. By representing $X$ with Tucker decomposition, the operation for each mode and their interactions can be separated, providing interpretable insight into the data. For example, in super-resolution of dental CT images, the high-resolution image is represented by a Tucker decomposition~\cite{hatvaniy2021single}. Applications of Tucker decomposition also includes 
%regarding  the high resolution image to be predicted is represented with Tucker decomposition. The blurring operation is modeled with three 2D matrices multiplied with the factor matrices.
%Tucker decomposition has also been used to help improve 
$T_1$ mapping \cite{liu2021accelerating, yaman2019low}. Accelerating the acquisition of 3D $T{1\rho}$ mapping of cartilage, the image tensor is defined as the sum of a sparse component and a low rank tensor. Tucker decomposition is used for tensor low-rank regularization~\cite{liu2021accelerating}. It can also be used for approximating higher quality images and improving $T_1$ mapping performance~\cite{yaman2019low}.  

%In Liu \textit{et al.}'s work \cite{liu2021accelerating} regarding accelerating the acquisition of 3D $T{1\rho}$ mapping of cartilage, the image tensor is defined as the sum of a sparse component and a low-rank tensor, and the Tucker decomposition is used for tensor low-rank regularization. In Yaman \textit{et al.}'s work \cite{yaman2019low}, a CP or Tucker decomposition based method is proposed to approximate the images with higher quality and then improve $T_1$ mapping performance.


Another application of Tucker decomposition is in medical image fusion \cite{yin2018tensor, zhang2023tdfusion, chen2024multi}. In these methods, original or processed medical images from diverse modalities are represented with Tucker decomposition sharing the same core tensor or factor matrices. Sparsity regularization is introduced to the core tensors. For example, Yin \textit{et al.}~\cite{yin2018tensor} tackled image fusion by first learning a dictionary from training images. They represented each image as a tensor split into unique sparse core tensors and shared factor matrices. When fusing images, they used these same factor matrices to compute the new tensor representations, letting the core tensors dictate the fusion weights. Beyond MRI, Tucker decomposition has been leveraged to fuse multiphoton imaging data with complementary modalities, such as Raman or fluorescence lifetime imaging, allowing integrative tissue characterization in tumor microenvironments~\cite{karahan2015tensor}. It enables robust feature extraction and pattern recognition, facilitating automated classification of healthy versus diseased tissue regions. 
% In Yin \textit{et al.}'s work \cite{yin2018tensor} about image fusion through dictionary learning, tensor sparse representations of a set of training images are obtained, with different sparse core tensors and sharing factor matrices for each mode. In the fusion step, the tensor sparse representations of the fused images are computed similarly with the learned factor matrices. Finally the fusion weights are decided by the core tensors of the fused images.
Besides, Tucker decomposition has shown the potential to be used for medical image segmentation \cite{khan2022deep, weber2025posttraining}, usually as a component of a deep neural network. In knee cartilage MRI segmentation, the original input images are reconstructed by Tucker decomposition with low rank~\cite{khan2022deep}. 
%Khan \textit{et al.}'s work \cite{khan2022deep} about  
Both the original and reconstructed inputs are fed into the neural network to learn the inter-dimensional tissue structures. In another work~\cite{weber2025posttraining}, the Tucker-decomposed convolution is proposed to replace the conventional 3D convolution and improve computational efficiency of the neural network. 

The application of Tucker decomposition in MRI and multiphoton brain imaging data extends to optogenetics and imaging studies, where simultaneous stimulation and recording of neuronal populations require advanced computational techniqus to disentangle overlapping signals. It separates the evoked responses from spontaneous activity in high-dimensional optogenetic data, aiding the identification of circuit-level changes in neurodevelopmental and neurodegenerative disorders~\cite{erol2022tensors}. 


\paragraph{HOSVD.} The applications of HOSVD, a generalization of the matrix SVD, are ubiquitous in biomedical image analysis. As a constraint case of Tucker decomposition, the factor matrices and core tensor of HOSVD are orthogonal. Therefore, HOSVD is less flexible than Tucker decomposition but can ensure decorrelation between components along each mode. For its ability to use the redundancy in high-dimensional data, HOSVD has been used for brain MRI denoising \cite{fu20163d, zhang2017denoise, bustin2019high, wang2020modified, kim2021denoising, olesen2023tensor}. Specifically,
%a  In Olesen \textit{et al.}'s work \cite{olesen2023tensor}, 
Marchenko-Pastur principal component analysis (MPPCA), a matrix-based method for denoising, is generalized to tensor MPPCA based on HOSVD so that it can directly process multidimensional MRI data~\cite{olesen2023tensor}. A patch-based HOSVD method for denoising has also been proposed, combined with a global HOSVD method to mitigate stripe artifacts in the outputs~\cite{zhang2017denoise}.  
Like Tucker decomposition, HOSVD has been used for medical image reconstruction~\cite{liu2021calibrationless, yi2021joint, roohi2016dynamic, zhang2022compressed} of MRI data by exploiting sparsity and low rank properties. It has also been applied in low-rank tensor approximation of the multi-slice image tensor in parallel MRI reconstruction~\cite{liu2021calibrationless}. HOSVD, analogous to the Tucker decomposition, enables the computation of a core tensor and the factorization of three-way tensors into three matrices. This capability has proven particularly effective for feature extraction, as demonstrated in a blood cell recognition task and wavelet transform in colored pupil images, where they are naturally represented as three-way tensors~\cite{le2023tensor,giap2023adaptive}. 

HOSVD has found utility in analyzing complex spatiotemporal patterns in brain imaging data acquired through single-photon and multiphoton techniques such as two photon and three-photon calcium imaging~\cite{grewe2010high}. It has been applied to denoise neuronal activity maps while preserving underlying spatiotemporal dynamics by reducing motion artificats in calcium imaging datasets. It improved the detection of neuronal ensembles in awake behaving animals~\cite{cho2023robust}. 


% HOSVD has also been used for feature extraction\cite{le2023tensor, giap2023adaptive}. In Le \textit{et al.}'s work \cite{le2023tensor} about feature extraction for blood cell recognition, the color image is represented as a 3D tensor. Through HOSVD, the core tensor is computed and split into three matrices. While the middle one is kept unchanged, the other two are replaced with all-zero matrices and then the feature is obtained by reconstructing the image with the new core tensor. In Giap \textit{et al.}'s work \cite{giap2023adaptive} for feature extraction of color pupil image, a 3D tensor is constructed from the color pupil image based on wavelet transform. HOSVD is applied to eliminate redundant information in the tensor and estimate the feature information.


\paragraph{t-SVD.}
    Unlike HOSVD, which is based on tensor-matrix product, tensor-SVD (t-SVD) represents a 3-way tensor as the \say{t-product} of three 3-way tensors. The t-SVD, a relatively recent and nuanced tensor decomposition technique, has been effectively employed in a range of medical imaging applications, particularly for enforcing low-rank regularization constraints. It has been used for MRI reconstruction \cite{jiang2020improved, liu2025dynamic, ai2018dynamic, liu2023low}. Specifically, it has been used to approximate the rank minimization problem, which is NP-hard to a tensor nuclear norm minimization, with applications in low-rank tensor regularization in a dynamic MRI reconstruction model~\cite{liu2025dynamic}. Similar to other tensor decomposition methods, t-SVD has been used in denoising MRI images~\cite{khaleel2018denoising, kong2017new, khaleel2018denoising2} as well as in image segmentation tasks~\cite{shi2021multi}. A low-rank approximation of the noisy image is obtained by thresholding the t-SVD coefficients in the Fourier domain to perform denoising~\cite{khaleel2018denoising2}. For image segmentation of pathological liver CT, a low-rank tensor decomposition is performed based on t-SVD~\cite{shi2021multi}. Specifically, it is used to recover the underlying low-rank structure of the 3D images and generate tumor-free liver atlases.  
    t-SVD based low-rank approximations have also been used to model neural network connectivity and extract functional components from large-scale neural activity data~\cite{williams2018unsupervised}. 


As observed in several tensor decomposition methods applied in biomedical imaging, it is often used together with deep learning techniques such as convolutional neural networks (CNNs)~\cite{yaman2019low,oymak2021learning, khan2022deep, li2023learned}. Deep learning techniques have shown empirical success to process and extract features from images, or to reconstruct them. However, their effectiveness is still a mystery with their heavy dependence on several parameters and their sensitivity to noise along with lack of generalization to out-of-distribution data, and overfitting in limited training samples~\cite{chen2023deep}. Tensor decompositions play a crucial role here extracting meaningful features which increase generalizability of neural network models. Tensor decomposition methods have shown to learn kernels from training data and increase performance of CNNs~\cite{oymak2021learning}. They are also used to reduce training parameters of CNNs and reduce model size, leading to effective training~\cite{liu2023tensor}. Hence, TD methods can be used in conjunction with deep learning methods to enhance the overall throughput and performance of downstream tasks such as prediction, segmentation, reconstruction, super-resolution, etc. in analyzing biomedical images. 

    %For example, in Liu \textit{et al.}'s work \cite{liu2025dynamic}, a multi-directional low-rank tensor regularization is applied to the dynamic MRI reconstruction model. The NP-hard rank-minimization problem is then approximated to a tensor nuclear norm minimization, which can be represented with the singular tensors obtained through t-SVD. 

% t-SVD has also been used for brain MRI denoising \cite{khaleel2018denoising, kong2017new, khaleel2018denoising2}. In Khaleel \textit{et al.}'s work \cite{khaleel2018denoising, khaleel2018denoising2}, low rank approximation of the noisy image is obtained by thresholding the t-SVD coefficients in Fourier domain.


% Besides, t-SVD shows potential to be applied in medical image segmentation. In Shi \textit{et al.}'s work \cite{shi2021multi} for pathological liver CT segmentation, low-rank tensor decompisition (LRTD) method based on an improved t-SVD is applied to different steps of the multi-atlas segmentation framework. Specifically, it is used to recover the underlying low-rank structure of the 3D images and generate tumor free liver atlases to benefit liver segmentation.

% \paragraph{Tensor Decomposition in Tissue Imaging with Multiphoton Microscopy}
% Beyond MRI and conventional imaging modalities, TD techniques have shown promise in analyzing high-dimensional datasets generated by multiphoton microscopy, including fluorescence-based and label-free modalities such as second harmonic generation (SHG) and third harmonic generation (THG) imaging~\cite{jamesdarian2021recent}. These imaging techniques offer high spatial resolution and deep tissue penetration, making them ideal for studying tissue architecture, extracellular matrix composition, and cellular interactions in both healthy and pathological conditions~\cite{campagnola2003second}.
% However, the large-scale, multi-channel datasets acquired from multiphoton imaging pose computational challenges, necessitating advanced decomposition strategies for efficient analysis, denoising, and feature extraction~\cite{vinegoni2020fluorescence}.

% In SHG and THG imaging, tensor decomposition methods such as CP decomposition and Tucker decomposition can be employed to separate intrinsic signal components from noise and enhance structural details in fibrous tissues. For example, CP decomposition has been utilized to extract meaningful components from 3D SHG datasets of collagen-rich tissues, improving segmentation and quantitative analysis of collagen density distribution in disease models such as cancer and fibrosis~\cite{uckermann2020label}. Similarly, Tucker decomposition has been leveraged to fuse multiphoton imaging data with complementary modalities, such as Raman or fluorescence lifetime imaging, allowing for integrative tissue characterization in tumor microenvironments~\cite{karahan2015tensor}. These techniques enable robust feature extraction and pattern recognition, facilitating automated classification of healthy versus diseased tissue regions.

% \paragraph{Tensor Decomposition for Single and Multiphoton Brain Imaging}
% Multiphoton microscopy is widely used in neuroscience to investigate brain activity at the cellular and network levels. Tensor decomposition approaches provide powerful means to analyze the complex spatiotemporal patterns present in brain imaging data acquired through single-photon and multiphoton techniques, such as two-photon and three-photon calcium imaging~\cite{grewe2010high}. In these applications, HOSVD and t-SVD have been applied to denoise and reconstruct neuronal activity maps while preserving the underlying spatiotemporal dynamics. For instance, HOSVD has been used to reduce motion artifacts and enhance neural signal extraction from calcium imaging datasets, improving the detection of neuronal ensembles in awake behaving animals~\cite{cho2023robust}. Similarly, t-SVD-based low-rank approximations have been employed to model neural network connectivity and extract functional components from large-scale recordings~\cite{cai2022review}.

% The application of tensor decomposition in multiphoton brain imaging extends to optogenetics and functional imaging studies, where simultaneous stimulation and recording of neuronal populations require advanced computational techniques to disentangle overlapping signals. Tucker decomposition has been used to analyze high-dimensional optogenetic data, allowing for the separation of evoked responses from spontaneous activity and aiding in the identification of circuit-level changes in neurodevelopmental and neurodegenerative disorders~\cite{erol2022tensors}. As multiphoton imaging technology continues to advance, tensor decomposition methods will play a crucial role in handling the increasing data complexity, improving image reconstruction, and extracting biologically relevant information from large-scale neural imaging experiments~\cite{uckermann2020label}.
% \paragraph{Tensor train}

% \paragraph{Tensor ring}

% \paragraph{Reconstruction}
% Image reconstruction in biomedical image analysis refers to the process of recovering under-sampled image to get into high-quality and interpretable images. It is critical for visualizing anatomical structures, assessing physiological functions, and aiding in diagnosis and treatment planning. Tensor decomposition methods have been applied in this task especially for MRI or dynamic MRI reconstruction, because MRI data usually involves data with three or more dimensions. Besides, such methods can be naturally combined with compressive sensing, a technique overwhelmingly used in image reconstruction. Treating the high dimensional MRI data as tensors rather than matrices help reduce redundancy and achieve better reconstruction quality. 

% \paragraph{Brain, knee, blood cell, eye}
% Brain image analysis is an important issue in biomedical imaging. The objectives of brain image analysis include structral and functional analysis, pathology detection and cognitive studies. The workflow involves brain image denoising, segmentation, feature extraction and so on. 


% \subsubsection{Challenges}
% % \AB{Phase transition/computational hardness discussions with plots following from the notebook shared with you}

% % Tensor based modeling starts with the idea of preserving the high dimensional structures (geometries) of biomedical data during the formulation of the problems. The computation of numerical results often converts the tensor based models into  equivalent matrix/vector based ones and it often requires formulation of large matrices coming from Kronecker operators. State of the art traditional computing hardware is not able to handle the vectorization of the entire biomedical data and one often needs to break the computation into small overlapping patches. However, not all biomedical application problems can be split into smaller patches. For instance, for super resolution of MRI images, the available low resolution image is a global Fourier transformation of the entire underlying high resolution image and thus can't be computed using patches which take only part of the Fourier information. 

% Tensor-based modeling in medical imaging seeks to preserve the intrinsic high-dimensional structure of biomedical images. However, computation of numerical results from tensors often requires converting these models into matrix or vector forms. This leads to the construction of large matrices involving Kronecker products, imposing significant computational burdens on current hardware. Consequently, computations are typically divided into small, overlapping patches, an approach that is not universally applicable, especially in medical imaging. For example, in MRI super-resolution, the low-resolution image is derived from a global Fourier transform of the entire high-resolution image, making patch-based processing infeasible. 

% Another general challenge in tensor decomposition is rank selection. For example, in Tucker decomposition, selecting the size of the core tensor, which is also the rank, is hard. It is significant since it determines the level of dimensionality reduction and the trade-off between performance and computational efficiency. If the rank is too low, capturing the latent structures in the data may be weakened, while a high rank increases computational complexity and memory usage significantly. As we discuss in Section~\ref{sec:hardness}, understanding the optimal rank of the tensor leads to a low MMSE, yielding efficient signal recovery. This phenomenon is true for all tensor decomposition techniques and their applications in medical imaging ranging from MRI to neural activity patterns and calcium imaging. This is demonstrated in Figure ~\ref{fig:mri_tensor_decomposition} using multi-slice MRI data with image size $512\times784\times912$ and voxel size $0.2\times0.18\times0.18$~mm, 
% %\os{(Shehab: People from quantum background may have no clue what it means. Are these voxels?)}, 
% where the dimensions represent the number of slices (512), and the in-plane resolution  ($784\times912$) of the imaging sequence. 
% %\os{(Shehab: For uninitiated readers like me, can we explain why the memory usage and execution time are bad? For example memory is cheap and 1.5 GB is nothing. It seems multi-volume MRI data could take 100+ GB when Voxel size: 0.5 $\times$ 0.5 $\times$ 0.5 mm, Matrix size: 512 $\times$ 512 $\times$ 512, Single 3D volume: $\sim$256 MB, Multi-subject dataset (400+ subjects, multiple sequences): 100+ GB. Maybe we can scale up the problem such that the memory requirement looks really bad, in hundreds of GBs? Same is true for execution time. Why 30 second is bad? )}.

% \begin{figure}[ht]
%     \centering
%     \subfloat{\includegraphics[width=0.45\textwidth]{figures/mri_memory_usage.png}}
%     \hspace{0.5cm} % Adds some spacing between images
%     \subfloat{\includegraphics[width=0.45\textwidth]{figures/mri_execution_time.png}}
%     \caption{Memory usage and execution time for tensor decomposition of 4D MRI data of size (384, 384, 28, 7). \os{(Can we increase the font size of the axis labels?)}}
%     \label{fig:mri_tensor_decomposition}
% \end{figure}
% Besides, real-world tensors in medical imaging, often contain noise or artifacts that reduce performance and increase computational requirements for robust solutions. Performance reduction when adding noise has been reported in different methods using CP decomposition \cite{zhao2023robust}, Tucker decomposition \cite{prevost2020hyperspectral}, t-SVD \cite{liu2025dynamic}. 

% Applications of TD methods in tissue and brain imaging also leads to significant challenges, particularly,  in the context of high-speed multiphoton microscopy and large-scale neural recordings. These challenges stem from the high-dimensional and multi-modal nature of the data acquired from multiphoton imaging techniques, such as second and third harmonic generation microscopy, two-photon and three-photon imaging, and functional calcium imaging. These datasets are inherently large, spanning spatial, temporal, and spectral domains, making tensor-based approaches computationally demanding~\cite{kolda2009tensor}. 
% %Existing tensor decomposition methods often struggle with the sheer volume of data, requiring advanced computational strategies to efficiently process and store high-dimensional image stacks without loss of information \os{(Shehab: Does this paragraph need some citations?)}.

% Another critical challenge is motion artifacts and signal contamination in live brain imaging. In awake behaving animals, head movements, heartbeat, and breathing introduce artifacts in calcium imaging and optogenetic recordings, complicating the extraction of meaningful neural signals. While tensor-based motion correction techniques have shown promise, they often require large computational resources and can introduce biases if the decomposition fails to properly separate artifacts from genuine neural activity~\cite{kara2024facilitating}. 
% % Additionally, rank selection and model generalization remain significant issues, particularly for dynamic imaging applications. Selecting the optimal rank for CP, Tucker, or t-SVD decomposition in functional brain imaging is challenging, as an improper choice can either oversimplify neural activity patterns or introduce excessive computational burden. The variability in neural signals across subjects and experimental conditions further complicates the application of a single decomposition model, necessitating adaptive approaches that can generalize across different imaging modalities and experimental paradigms. \os{(Shehab: Does this paragraph need some citations?)}
% Furthermore, biological noise and tissue heterogeneity present difficulties in tensor-based models applied to tissue imaging. In label-free multiphoton microscopy, where contrast arises from intrinsic tissue properties rather than fluorescent markers, non-uniform signal intensities, variations in optical scattering, and background noise can degrade the performance of decomposition techniques~\cite{borile2021label}. Robust pre-processing and artifact rejection methods are essential to improve the reliability of tensor-based segmentation, classification, and feature extraction in histopathological and live-tissue imaging. Finally, hardware limitations pose another barrier. While parallel computing and GPU acceleration have improved computational feasibility, real-time applications, such as closed-loop optogenetics or high-speed volumetric imaging, require further advancements in tensor decomposition algorithms to achieve near-instantaneous data processing and decision-making. Addressing these challenges will be crucial for fully harnessing tensor decomposition in large-scale tissue and brain imaging studies.