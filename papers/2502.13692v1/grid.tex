\section{Meet in the Middle Bound}
\label{sec:meetinmid}
The goal of this section is to prove the following
\begin{customlem}{\ref{lem:supW}}
There is a constant $c>0$ such that with probability at least $1-\delta$ over $\rS \sim \cD^n$ we have
\begin{align*}
    \sup_{w \in \subH(\Gamma_i,L_j)} \left|\E_{\rA,\rt} [\Loss^{\gamma_i/2}_{\rA \cD}(h_{\rA,\rt}(w)) - \Loss^{\gamma_i/2}_{\rA \rS}(h_{\rA,\rt}(w))]\right| &\leq\\ c \left(\sqrt{\frac{(\ell_{j+1}+ \exp(-\gamma_{i+1}^2k/c)) (k + \ln(e/\delta))}{n}} + \frac{(k + \ln(e/\delta))}{n} \right).
\end{align*}
\end{customlem}
Notice here that the two losses $\Loss^{\gamma_i/2}_{\rA \cD}(h_{\rA,\rt}(w))$ and $\Loss^{\gamma_i/2}_{\rA \rS}(h_{\rA,\rt}(w))$ refer to the same margin $\gamma_i/2$ and $h_{\rA,\rt}(w)$ has been discretized to have all coordinates of the form $(1/2)(10 \sqrt{k})^{-1} + z (10 \sqrt{k})^{-1}$ for integer $z$. Intuitively, we will try to exploit this discretization to union bound over a grid of finitely many hypotheses. Unfortunately, the random matrix $\rA$ may increase the norm of $w$ arbitrarily much, and thus a single grid is insufficient. Instead, we need an infinite sequence of grids. For this, let $\Disc_0$ denote the set of all vectors in $4 \Ball_2^k$ whose coordinates are of the form $(1/2)(10 \sqrt{k})^{-1} + z(10 \sqrt{k})^{-1}$ for integer $z$. More generally, let $\Disc_i$ for $i > 0$ denote the set of all vectors in $(2^i \cdot 4 \Ball_2^k)$ whose coordinates are of this form. Since $\|x\|_1 \leq \sqrt{k} \|x\|_2$ for any $x \in \R^k$, we have that $\Disc_i \subset (2^i \cdot 4 \Ball_2^k) \subseteq \sqrt{k}(2^i \cdot 4 \Ball_1^k)$. For a vector $x \in \Disc_i$, let $i(x)=(i_1,\dots,i_k)$ denote the integers so that $x = (10 \sqrt{k})^{-1} i(x) + (1/2)(10 \sqrt{k})^{-1} \AllOne$ with $\AllOne \in \R^k$ the all-1's vector. Then by the triangle inequality, we have $(10 \sqrt{k})^{-1}\|i(x)\|_2 \leq \|x\|_2 + (1/2)(10 \sqrt{k})^{-1}\|\AllOne\|_2 \leq 2^i \cdot 4 + 1/20$. This implies $\|i(x)\|_1 \leq (10 \sqrt{k}) \sqrt{k} (2^i \cdot 4 + 1/20) \leq (5 \cdot 2^{i+3}+1)k$. Since each coordinate of $i(x)$ is an integer, there are thus at most $2^k$ choices for the signs and $\sum_{t=0}^{(5 \cdot 2^{i+3}+1)k} \binom{k + t -1}{t}$ choices for the absolute values of the integers. That is, we have
\begin{align}
|\Disc_i| \leq 2^k \cdot \sum_{t=0}^{(5 \cdot 2^{i+3}+1) k} \binom{k + t -1}{t} \leq 2^{(5 \cdot 2^{i+3}+3)k} \leq 2^{2^{i+7}k}.\label{eq:netsize}
\end{align}
We now start by considering a fixed outcome $A$ of the random matrix $\rA$. For such a fixed $A$, the training set $\rS$ behaves well in the sense that $\Loss^\gamma_{A \cD}(w)$ and $\Loss^\gamma_{A \rS}(w)$ are close with high probability for any $w$. This is formalized in the following remark
\begin{remark}
\label{rmk:concentrationx}
For any distribution $\cD$ over $\finalX \times \{-1,1\}$, fixed $w \in \finalH$, margin $\gamma$ and any $A \in \R^{k \times d}$, it holds with probability at least $1-\delta$ over $\rS \sim \cD^n$ that
\[
|\Loss_{A\cD}^{\gamma}(w) - \Loss_{A\rS}^{\gamma}(w)| \leq \sqrt{\frac{8\Loss_{A \cD}^{\gamma}(w)\ln(1/\delta)}{n}} + \frac{2 \ln(1/\delta)}{n}.
\]
\end{remark}
The proof of Remark~\ref{rmk:concentrationx} is a simple application of Bernstein's and can be found in Appendix~\ref{sec:aux}.

In Lemma~\ref{lem:supW}, the matrix $\rA$ is not fixed but random. Thus we need to find a formal property of the training set $\rS$ under which $\Loss^{\gamma_i/2}_{\rA \cD}(h_{\rA,\rt}(w))$ and $\Loss^{\gamma_i/2}_{\rA \rS}(h_{\rA,\rt}(w))$ are close in expectation over the random choice of $\rA$. With this goal in mind, we now say that a matrix $A$ in the support of $\rA$ and a training set $S$ has \emph{distortion} at least $\beta$, if there is a grid $\Disc_a$ and a vector $w \in \Disc_a$ such that
\[
|\Loss_{A\cD}^{\gamma_i/2}(w) - \Loss_{A\rS}^{\gamma_i/2}(w)| > \beta \cdot \left(\sqrt{\frac{8\Loss_{A \cD}^{\gamma_i/2}(w)(2^{a+7}k + \ln(1/\delta))}{n}} + \frac{2 (2^{a+7}k + \ln(1/\delta))}{n}\right).
\]
For a training set $S$, we use $D_\beta(S)$ to denote the set of matrices $A$ with distortion at least $\beta$ for $S$.

We observe that for a fixed matrix $A$, grid $\Disc_a$ and $\beta>1$, we have by Remark~\ref{rmk:concentrationx} with $\delta'_a = (\delta/2^{2^{a+7}k})^{\beta}$
and a union bound over all $w \in \Disc_a$, that with probability at least $1-|\Disc_a|\delta'_a$, it holds for all $w \in \Disc_a$ that
\begin{align*}
    |\Loss_{A\cD}^{\gamma_i/2}(w) - \Loss_{A\rS}^{\gamma_i/2}(w)| &\leq \sqrt{\frac{8\Loss_{A \cD}^{\gamma_i/2}(w)\ln(1/\delta'_a)}{n}} + \frac{2 \ln(1/\delta'_a)}{n} \\
    &= \sqrt{\frac{8\Loss_{A \cD}^{\gamma_i/2}(w)(\beta 2^{a+7}k + \beta \ln(1/\delta))}{n}} + \frac{2 (\beta 2^{a+7}k + \beta \ln(1/\delta))}{n}  \\
    &\leq \beta \cdot \left(\sqrt{\frac{8\Loss_{A \cD}^{\gamma_i/2}(w)(2^{a+7}k + \ln(1/\delta))}{n}} + \frac{2 (2^{a+7}k + \ln(1/\delta))}{n}\right).
\end{align*}
Thus for $\beta \geq 2$, we have
\begin{align*}
\Pr_{\rS}[A \in D_\beta(\rS)] &\leq \sum_{a=0}^\infty |\Disc_a| \delta'_a \\
&\leq \sum_{a=0}^\infty \delta^\beta \cdot 2^{-(\beta-1)2^{a+7}k} \\
&\leq 2 \cdot \delta^{\beta} \cdot 2^{-(\beta-1)2^{7}k}.
\end{align*}
By Markov's inequality, we have
\begin{align*}
\Pr_{\rS}[\Pr_{\rA}[\rA \in D_\beta(\rS)] > 2 \cdot \delta^{\beta/2} \cdot 2^{-(\beta-1)\cdot 2^{6}k}] &\leq \frac{\E_{\rS}[\Pr_{\rA}[\rA \in D_\beta(\rS)]}{2 \cdot \delta^{\beta/2} \cdot 2^{-(\beta-1)\cdot 2^{6}k}} \\
&= \frac{\E_{\rA}[\Pr_{\rS}[\rA \in D_\beta(\rS)]}{2 \cdot \delta^{\beta/2} \cdot 2^{-(\beta-1)\cdot 2^{6}k}}\\
&\leq \delta^{\beta/2} \cdot 2^{-(\beta-1)2^{6}k}.
\end{align*}
Now call a training set $S$ \emph{representative} if it holds for every $\beta=2^h$ with integer $h \geq 1$ that
\[
\Pr_{\rA}[\rA \in D_\beta(\rS)] \leq 2 \cdot \delta^{\beta/2} \cdot 2^{-(\beta-1)\cdot 2^{6}k}.
\]
A union bound implies that $\rS$ is representative with probability at least
\[
1-\sum_{h=1}^\infty 2 \cdot \delta^{2^{h-1}} \cdot 2^{-(2^h-1)2^{6}k} \geq 1-\frac{\delta}{2^{2^6 k-2}} \geq 1-\delta.
\]
Now define for integer $h \geq 1$ the set
\[
K_h(S) = D_{2^h}(S) \setminus \left(\cup_{b=h+1}^{\infty} D_{2^b}(S) \right).
\]
Let $K_0(S)$ be defined as
\[
K_0(S) = \support(\rA) \setminus \left(\cup_{b=1}^{\infty} D_{2^b}(S) \right).
\]

For any $w \in \finalH$, we may use the triangle inequality to conclude
\begin{align*}
 \left|\E_{\rA,\rt} [\Loss^{\gamma_i/2}_{\rA \cD}(h_{\rA,\rt}(w)) - \Loss^{\gamma_i/2}_{\rA S}(h_{\rA,\rt}(w))]\right| &\leq \\
 \sum_{h=0}^\infty \E_{\rA,\rt}\left[\left|\Loss^{\gamma_i/2}_{\rA \cD}(h_{\rA,\rt}(w)) - \Loss^{\gamma_i/2}_{\rA S}(h_{\rA,\rt}(w))\right| \mid \rA \in K_h(S)\right] \Pr_{\rA}[\rA \in K_h(S)].
\end{align*}
Now consider an $A \in K_h(S)$. Then $A$ has distortion no more than $2^{h+1}$ by definition of $K_h(S)$. This implies that if $h_{A,t}(w)$ is in $\Disc_a$ but not $\Disc_b$ for $b < a$, then $\|h_{A,t}(w)\|_2 \geq 2^{a+1}$ by definition of $\Disc_b$ and we get
\begin{align*}
|\Loss_{A\cD}^{\gamma_i/2}(h_{A,t}(w)) - \Loss_{A\rS}^{\gamma_i/2}(h_{A,t}(w))| &\leq\\
2^{h+1} \cdot \left(\sqrt{\frac{8\Loss_{A \cD}^{\gamma_i/2}(w)(2^{a+7}k + \ln(1/\delta))}{n}} + \frac{2 (2^{a+7}k + \ln(1/\delta))}{n}\right) 
&\leq \\
2^{h+8}  \|h_{A,t}(w)\|_2 \cdot \left(\sqrt{\frac{8\Loss_{A \cD}^{\gamma_i/2}(w)(k + \ln(1/\delta))}{n}} + \frac{2 (k + \ln(1/\delta))}{n}\right).
\end{align*}
Using Cauchy-Schwartz, we thus get for any $w \in \finalH$ that
\begin{align*}
 \left|\E_{\rA,\rt} [\Loss^{\gamma_i/2}_{\rA \cD}(h_{\rA,\rt}(w)) - \Loss^{\gamma_i/2}_{\rA S}(h_{\rA,\rt}(w))]\right| &\leq \\
\sum_{h=0}^\infty 2^{h+8} \E_{\rA,\rt}\bigg[\|h_{\rA,\rt}(w)\|_2  \cdot  \bigg(\sqrt{\frac{8\Loss_{\rA \cD}^{\gamma_i/2}(w)(k + \ln(1/\delta))}{n}} &+\\
\frac{2 (k + \ln(1/\delta))}{n}\bigg)\mid \rA \in K_h(S)\bigg]\Pr_{\rA}[\rA \in K_h(S)]&\leq \\
\sum_{h=0}^\infty 2^{h+8} \sqrt{\E_{\rA,\rt}\left[\|h_{\rA,\rt}(w)\|^2_2  \mid \rA \in K_h(S) \right]} &\ \cdot \\
\sqrt{\E_{\rA,\rt}\left[ \left(\sqrt{\frac{8\Loss_{\rA \cD}^{\gamma_i/2}(w)(k + \ln(1/\delta))}{n}} + \frac{2 (k + \ln(1/\delta))}{n}\right)^2\mid \rA \in K_h(S)\right]}\Pr_{\rA}[\rA \in K_h(S)].
\end{align*}
By Cauchy-Schwartz, this is at most
\begin{align*}
\sqrt{\sum_{h=0}^\infty 2^{2h+16}\E_{\rA,\rt}[\|h_{\rA,\rt}(w)\|_2^2 \mid \rA \in K_h(S) ]  \Pr_{\rA}[\rA \in K_h(S)]} &\ \cdot\\
\sqrt{\sum_{h=0}^\infty \E_{\rA,\rt}\left[ \left(\sqrt{\frac{8\Loss_{\rA \cD}^{\gamma_i/2}(w)(k + \ln(1/\delta))}{n}} + \frac{2 (k + \ln(1/\delta))}{n}\right)^2\mid \rA \in K_h(S)\right]\Pr_{\rA}[\rA \in K_h(S)] }.
\end{align*}
Using Cauchy-Schwartz again and Jensen's inequality, the first sum is bounded by
\begin{align*}
\sum_{h=0}^\infty 2^{2h+16} \E_{\rA,\rt}[\|h_{\rA,\rt}(w)\|^2_2 \mid \rA \in K_h(S) ] \Pr_{\rA}[\rA \in K_h(S)] &\leq \\
\sqrt{ \sum_{h=0}^\infty 2^{4h + 64}\Pr_{\rA}[\rA \in K_h(S)] } \cdot \sqrt{\sum_{h=0}^\infty \E_{\rA,\rt}[\|h_{\rA,\rt}(w)\|^2_2 \mid \rA \in K_h(S) ]^2 \Pr_{\rA}[\rA \in K_h(S)] } &\leq \\
\sqrt{ \sum_{h=0}^\infty 2^{4h + 64}\Pr_{\rA}[\rA \in D_{2^h}(S)] } \cdot \sqrt{\sum_{h=0}^\infty \E_{\rA,\rt}[\|h_{\rA,\rt}(w)\|^4_2 \mid \rA \in K_h(S) ] \Pr_{\rA}[\rA \in K_h(S)] } &\leq \\
\sqrt{ \sum_{h=0}^\infty 2^{4h + 64} 2 (\delta/2^{2^7k+1})^{(2^h-1)/2} } \cdot \sqrt{\E_{\rA,\rt}[\|h_{\rA,\rt}(w)\|^4_2 ] } &\leq \\
2^{33} \cdot \sqrt{\E_{\rA,\rt}[\|h_{\rA,\rt}(w)\|^4_2 ] }.
\end{align*}
Using Jensen's inequality on the second sum, we find that
\begin{align*}
\sum_{h=0}^\infty \E_{\rA,\rt}\left[ \left(\sqrt{\frac{8\Loss_{\rA \cD}^{\gamma_i/2}(w)(k + \ln(1/\delta))}{n}} + \frac{2 (k + \ln(1/\delta))}{n} \right)^2\mid \rA \in K_h(S)\right]\Pr_{\rA}[\rA \in K_h(S)] &=\\
\E_{\rA,\rt}\left[ \left(\sqrt{\frac{8\Loss_{\rA \cD}^{\gamma_i/2}(w)(k + \ln(1/\delta))}{n}} + \frac{2 (k + \ln(1/\delta))}{n} \right)^2\right].
\end{align*}
For positive constants $c_0,c_1,c_2$, we have that the function $f(t)=(\sqrt{c_0 t + c_1} + c_2)^2$ is concave for $t \geq 0$. To see this, we compute its derivative 
\[
f'(t) = 2(\sqrt{c_0 t + c_1} + c_2) \cdot \frac{c_0}{2\sqrt{c_0 t + c_1}} = c_0 + \frac{c_0 c_2}{\sqrt{c_0 t + c_1}},
\]
and its second derivative
\begin{align*}
f''(t) &= \frac{-c_0^2 c_2}{2 (c_0 t + c_1)^{3/2}}.
\end{align*}
This is a negative function for $t \geq 0$. We thus use Jensen's inequality to conclude
\begin{align*}
\E_{\rA,\rt}\left[ \left(\sqrt{\frac{8\Loss_{\rA \cD}^{\gamma_i/2}(w)(k + \ln(1/\delta))}{n}} + \frac{2 (k + \ln(1/\delta))}{n} \right)^2\right] &\leq \\
 \left(\sqrt{\frac{8\E_{\rA,\rt}\left[\Loss_{\rA \cD}^{\gamma_i/2}(w)\right] (k + \ln(1/\delta))}{n}} + \frac{2 (k + \ln(1/\delta))}{n} \right)^2.
\end{align*}
Combining it all, we have thus shown
\begin{align*}
\left|\E_{\rA,\rt} [\Loss^{\gamma_i/2}_{\rA \cD}(h_{\rA,\rt}(w)) - \Loss^{\gamma_i/2}_{\rA S}(h_{\rA,\rt}(w))]\right| &\leq \\
\sqrt{2^{33} \cdot \sqrt{\E_{\rA,\rt}[\|h_{\rA,\rt}(w)\|_2^4]}} \cdot \sqrt{\left(\sqrt{\frac{8\E_{\rA,\rt}\left[\Loss_{\rA \cD}^{\gamma_i/2}(w)\right] (k + \ln(1/\delta))}{n}} + \frac{2 (k + \ln(1/\delta))}{n} \right)^2} &\leq \\
2^{17} \cdot \E_{\rA,\rt}[\|h_{\rA,\rt}(w)\|_2^4]^{1/4} \cdot \left(\sqrt{\frac{8\E_{\rA,\rt}\left[\Loss_{\rA \cD}^{\gamma_i/2}(w)\right] (k + \ln(1/\delta))}{n}} + \frac{2 (k + \ln(1/\delta))}{n} \right).
\end{align*}
We now bound $\E_{\rA,\rt}[\|h_{\rA,\rt}(w)\|_2^4]$ as follows
\begin{align*}
\E_{\rA,\rt}[\|h_{\rA,\rt}(w)\|_2^4] &= \\
\E_{\rA,\rt}[\|\rA w + (h_{\rA,\rt}(w)-\rA w)\|_2^4] &\leq \\
\E_{\rA,\rt}[\left(\|\rA w\|_2 + \|h_{\rA,\rt}(w)-\rA w\|_2\right)^4] &\leq\\
\E_{\rA,\rt}\left[\left(\|\rA w\|_2 + \sqrt{k (10\sqrt{k})^{-2}}\right)^4\right] &=\\
\E_{\rA,\rt}\left[\left(\|\rA w\|_2 + 1/10\right)^4\right] &=\\
\sum_{b=0}^4 \binom{4}{b} \E_{\rA,\rt}[\|\rA w\|_2^b] 10^{-(4-b)}.
\end{align*}
Recalling that $\|\rA w\|_2^2 \sim (1/k)\chi_k^2$, we have from the moments of the chi-square distribution that for even $k \geq 4$:
\[
\E_{\rA,\rt}[\|\rA w\|_2^b] \leq \E_{\rA,\rt}[\|\rA w\|_2^4] =k^{-2}\E_{\rA,\rt}[(k\|\rA w\|_2^2)^2] = k^{-2} 2^2 \frac{(2 + k/2)!}{(k/2)!} \leq 4.
\]
Hence
\begin{align*}
\E_{\rA,\rt}[\|h_{\rA,\rt}(w)\|_2^4] \leq
\sum_{b=0}^4 \binom{4}{b} 4 \cdot 10^{-(4-b)} \leq (4 + 1/10)^4 < 5^4.
\end{align*}
We thus have
\begin{align*}
\left|\E_{\rA,\rt} [\Loss^{\gamma_i/2}_{\rA \cD}(h_{\rA,\rt}(w)) - \Loss^{\gamma_i/2}_{\rA S}(h_{\rA,\rt}(w))]\right| &\leq \\
2^{20} \cdot \left(\sqrt{\frac{8\E_{\rA,\rt}\left[\Loss_{\rA \cD}^{\gamma_i/2}(w)\right] (k + \ln(1/\delta))}{n}} + \frac{2 (k + \ln(1/\delta))}{n} \right).
\end{align*}
Finally, we exploit that for any $w \in \subH(\Gamma_i, L_j)$, we have by definition that $\Loss_\cD^{(3/4)\gamma_{i}}(w)\leq \ell_{j+1}$. Thus for any such $w$, we have
\begin{align*}
\E_{\rA,\rt}[\Loss^{\gamma_i/2}_{\rA \cD}(w)] &=\E_{\rA,\rt}[\Pr_{(\rx,\ry)\sim \cD}[\ry \langle h_{\rA,\rt}(w), \rA\rx \rangle \leq \gamma_i/2]] \\
&=
\E_{(\rx,\ry)\sim \cD}[\Pr_{\rA,\rt}[\ry \langle h_{\rA,\rt}(w), \rA\rx \rangle \leq \gamma_i/2]]
\\&\leq
\Pr_{(\rx,\ry)\sim \cD}[\ry\langle w, \rx \rangle \leq (3/4)\gamma_{i}] \\
&+ \E_{(\rx,\ry)\sim \cD}[\Pr_{\rA,\rt}[\ry \langle h_{\rA,\rt}(w), \rA\rx \rangle \leq \gamma_i/2] \mid \ry\langle w, \rx \rangle > (3/4)\gamma_{i}] \\
&\leq \Loss_{\cD}^{(3/4)\gamma_{i}}(w)  + \sup_{\mu > (3/4)\gamma_i}[\Pr_{\rA,\rt}[\langle h_{\rA,\rt}(w), \rA x \rangle \leq \gamma_i/2 \mid y\ipr{w,x}=\mu].
\end{align*}
Using Lemma~\ref{lem:concdiscretize} and that $\Loss^{(3/4)\gamma_i}_\cD(w) \in L_j$ by definition of $\subH(\Gamma_i,L_j)$, there is a constant $c>0$ such that this is bounded by
\begin{align*}
&\leq \Loss_{\cD}^{(3/4)\gamma_{i}}(w) + c\exp(-k(\gamma_{i}/4)^2/c)\\
&\leq \ell_{j+1} + c \exp(-k \gamma_{i+1}^2/(16 c)).
\end{align*}
We have thus reached the conclusion that there is a constant $c>0$, such that with probability at least $1-\delta$ over $\rS \sim \cD^n$, it holds that
\begin{align*}
    \sup_{w \in \subH(\Gamma_i,L_j)} \left|\E_{\rA,\rt} [\Loss^{\gamma_i/2}_{\rA \cD}(h_{\rA,\rt}(w)) - \Loss^{\gamma_i/2}_{\rA S}(h_{\rA,\rt}(w))]\right| &\leq\\ c \cdot \left(\sqrt{\frac{(\ell_{j+1} + \exp(-k \gamma_{i+1}^2/c)) (k + \ln(1/\delta))}{n}} + \frac{k + \ln(1/\delta)}{n} \right).
\end{align*}
This completes the proof of Lemma~\ref{lem:supW}.