\section{Discussion and Future Work}
Our paper formulates a fair MA-MAB problem where the search is over reward-based social welfare maximizing policy that also ensures fairness to each agent.
Our notion of fairness guarantees a pre-specified fraction of the corresponding maximum possible rewards to each agent. 
We derive the lower bound of $\tilde{O}(\sqrt{T})$ that holds individually for both social welfare and fairness regret. 
Our proposed algorithm \ouralgo \ obtains an optimal (up to logarithmic constants) social welfare regret and a sub-linear fairness regret. We also propose baseline algorithms/heuristics for the problem, present the exploration-exploitation trade-off and empirically validate the efficacy of the proposed \ouralgo \ algorithm on both simulated and real-world data. Our algorithms can be easily made time-horizon unaware with a doubling trick \cite[Theorem 4]{besson2018doubling}.
Improving the fairness regret upper bound of $\tilde{O}(T^{3/4})$ to match the lower bound of $\Omega(\sqrt{T})$ would be an interesting future work which would also include theoretically analysing the proposed dual-based heuristics.
Another future work could be to extend the lower bounds for the regrets derived individually to hold simultaneously. It will also be interesting to extend our theoretical analysis for \textsc{Explore-First} algorithm (Algo~\ref{algOne-EF}) for $m>2$.

\begin{acks}
PM thanks Google for the PhD Fellowship. GG thanks support from SERB through grant CRG/2022/007927.  The authors also thank the anonymous reviewers for their constructive feedback.
\end{acks}