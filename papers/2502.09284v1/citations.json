[
  {
    "index": 0,
    "papers": [
      {
        "key": "llama3modelcard",
        "author": "AI@Meta",
        "title": "Llama 3 Model Card"
      },
      {
        "key": "touvron2023llama",
        "author": "Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\\'e}e and Rozi{\\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others",
        "title": "Llama: Open and efficient foundation language models"
      },
      {
        "key": "jiang2023mistral",
        "author": "Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and L\u00e9lio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timoth\u00e9e Lacroix and William El Sayed",
        "title": "Mistral 7B"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "chen2023salm",
        "author": "Chen, Zhehuai and Huang, He and Andrusenko, Andrei and Hrinchuk, Oleksii and Puvvada, Krishna C and Li, Jason and Ghosh, Subhankar and Balam, Jagadeesh and Ginsburg, Boris",
        "title": "SALM: Speech-augmented Language Model with In-context Learning for Speech Recognition and Translation"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "yu2023connecting",
        "author": "Yu, Wenyi and Tang, Changli and Sun, Guangzhi and Chen, Xianzhao and Tan, Tian and Li, Wei and Lu, Lu and Ma, Zejun and Zhang, Chao",
        "title": "Connecting speech encoder and large language model for asr"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "houlsby2019parameter",
        "author": "Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain",
        "title": "Parameter-efficient transfer learning for NLP"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "vaswani2017attention",
        "author": "Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\\L}ukasz and Polosukhin, Illia",
        "title": "Attention is all you need"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "li2023blip",
        "author": "Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven",
        "title": "Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "radford2023robust",
        "author": "Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya",
        "title": "Robust speech recognition via large-scale weak supervision"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "pmlr-v202-chen23ag",
        "author": "Chen, Sanyuan and Wu, Yu and Wang, Chengyi and Liu, Shujie and Tompkins, Daniel and Chen, Zhuo and Che, Wanxiang and Yu, Xiangzhan and Wei, Furu",
        "title": "{BEAT}s: Audio Pre-Training with Acoustic Tokenizers"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "das2024speechverse",
        "author": "Das, Nilaksh and Dingliwal, Saket and Ronanki, Srikanth and Paturi, Rohit and Huang, David and Mathur, Prashant and Yuan, Jie and Bekal, Dhanush and Niu, Xing and Jayanthi, Sai Muralidhar and others",
        "title": "SpeechVerse: A Large-scale Generalizable Audio Language Model"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "JMLR:v25:23-0870",
        "author": "Hyung Won Chung and Le Hou and Shayne Longpre and Barret Zoph and Yi Tay and William Fedus and Yunxuan Li and Xuezhi Wang and Mostafa Dehghani and Siddhartha Brahma and Albert Webson and Shixiang Shane Gu and Zhuyun Dai and Mirac Suzgun and Xinyun Chen and Aakanksha Chowdhery and Alex Castro-Ros and Marie Pellat and Kevin Robinson and Dasha Valter and Sharan Narang and Gaurav Mishra and Adams Yu and Vincent Zhao and Yanping Huang and Andrew Dai and Hongkun Yu and Slav Petrov and Ed H. Chi and Jeff Dean and Jacob Devlin and Adam Roberts and Denny Zhou and Quoc V. Le and Jason Wei",
        "title": "Scaling Instruction-Finetuned Language Models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "ma2024embarrassingly",
        "author": "Ma, Ziyang and Yang, Guanrou and Yang, Yifan and Gao, Zhifu and Wang, Jiaming and Du, Zhihao and Yu, Fan and Chen, Qian and Zheng, Siqi and Zhang, Shiliang and others",
        "title": "An Embarrassingly Simple Approach for LLM with Strong ASR Capacity"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "zhang2023speechgpt",
        "author": "Zhang, Dong and Li, Shimin and Zhang, Xin and Zhan, Jun and Wang, Pengyu and Zhou, Yaqian and Qiu, Xipeng",
        "title": "SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "Qwen2-Audio",
        "author": "Chu, Yunfei and Xu, Jin and Yang, Qian and Wei, Haojie and Wei, Xipin and Guo,  Zhifang and Leng, Yichong and Lv, Yuanjun and He, Jinzheng and Lin, Junyang and Zhou, Chang and Zhou, Jingren",
        "title": "Qwen2-Audio Technical Report"
      }
    ]
  }
]