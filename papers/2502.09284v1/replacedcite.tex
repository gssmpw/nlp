\section{Related Works}
The availability  of instruction-tuned LLMs____ open a new research direction for speech processing by connecting speech directly to these multi-task models. ____ proposed multitask speech-language modeling with unified LLM framework that shows in-context learning ability. ____ utilized three approaches for adapting speech to text modality: Fully Connected Linear Layers following ____ adapter method, multi-head cross attention mechanism described in ____, and query transformer____. For processing speech input, they utilized two models: Whisper Large-v2____ and BEATS____. The SpeechVerse____ framework used WavLM-based speech encoder interfaced with a Flan-T5-XL____ language model.
In a another study, ____ demonstrated the sufficiency of a single linear layer for speech-LLM integration in ASR, albeit with limited exploration beyond this task.
Speech as language modeling was also studied in SpeechGPT ____ which integrates both speech and text modalities. The model incorporates a speech tokenizer that converts raw audio waveforms into discrete speech tokens, enabling efficient processing within the transformer architecture. Through multi-task fine-tuning on downstream tasks such as ASR, translation, and generation, the model demonstrates remarkable versatility. Qwen2-Audio____, designed as a general-purpose audio understanding model, exhibits broad applicability across various audio-related tasks. The model employs self-supervised learning techniques, such as masked audio modeling and contrastive learning, to capture rich audio representations.

Table \ref{tab:related_works_comparison} summarizes the features of most relevant related works. Note that our proposed model, SparQLe, is the only one that relies exclusively on SSL features (i.e. HuBERT) as input, and a simple adapter between the frozen speech encoder and LLM; previous approaches relied on complex encoder that have already been aligned with text through supervised training, such as Whisper, in addition to complex adaptation mechanism.