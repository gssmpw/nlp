@article{anastassiou2024seed,
  title={Seed-TTS: A Family of High-Quality Versatile Speech Generation Models},
  author={Anastassiou, Philip and Chen, Jiawei and Chen, Jitong and Chen, Yuanzhe and Chen, Zhuo and Chen, Ziyi and Cong, Jian and Deng, Lelai and Ding, Chuang and Gao, Lu and others},
  journal={arXiv preprint arXiv:2406.02430},
  year={2024}
}
@article{du2024cosyvoice,
  title={Cosyvoice: A scalable multilingual zero-shot text-to-speech synthesizer based on supervised semantic tokens},
  author={Du, Zhihao and Chen, Qian and Zhang, Shiliang and Hu, Kai and Lu, Heng and Yang, Yexin and Hu, Hangrui and Zheng, Siqi and Gu, Yue and Ma, Ziyang and others},
  journal={arXiv preprint arXiv:2407.05407},
  year={2024}
}
@article{du2024cosyvoice2,
  title={CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models},
  author={Du, Zhihao and Wang, Yuxuan and Chen, Qian and Shi, Xian and Lv, Xiang and Zhao, Tianyu and Gao, Zhifu and Yang, Yexin and Gao, Changfeng and Wang, Hui and others},
  journal={arXiv preprint arXiv:2412.10117},
  year={2024}
}
@article{chen2024f5,
  title={F5-tts: A fairytaler that fakes fluent and faithful speech with flow matching},
  author={Chen, Yushen and Niu, Zhikang and Ma, Ziyang and Deng, Keqi and Wang, Chunhui and Zhao, Jian and Yu, Kai and Chen, Xie},
  journal={arXiv preprint arXiv:2410.06885},
  year={2024}
}
@article{wang2024maskgct,
  title={Maskgct: Zero-shot text-to-speech with masked generative codec transformer},
  author={Wang, Yuancheng and Zhan, Haoyue and Liu, Liwei and Zeng, Ruihong and Guo, Haotian and Zheng, Jiachen and Zhang, Qiang and Zhang, Xueyao and Zhang, Shunsi and Wu, Zhizheng},
  journal={arXiv preprint arXiv:2409.00750},
  year={2024}
}
@article{meng2024autoregressive,
  title={Autoregressive speech synthesis without vector quantization},
  author={Meng, Lingwei and Zhou, Long and Liu, Shujie and Chen, Sanyuan and Han, Bing and Hu, Shujie and Liu, Yanqing and Li, Jinyu and Zhao, Sheng and Wu, Xixin and others},
  journal={arXiv preprint arXiv:2407.08551},
  year={2024}
}
@inproceedings{eskimez2024e2,
  title={E2 tts: Embarrassingly easy fully non-autoregressive zero-shot tts},
  author={Eskimez, Sefik Emre and Wang, Xiaofei and Thakker, Manthan and Li, Canrun and Tsai, Chung-Hsien and Xiao, Zhen and Yang, Hemin and Zhu, Zirun and Tang, Min and Tan, Xu and others},
  booktitle={2024 IEEE Spoken Language Technology Workshop (SLT)},
  pages={682--689},
  year={2024},
  organization={IEEE}
}
@article{guo2024fireredtts,
  title={Fireredtts: A foundation text-to-speech framework for industry-level generative speech applications},
  author={Guo, Hao-Han and Liu, Kun and Shen, Fei-Yu and Wu, Yi-Chen and Xie, Feng-Long and Xie, Kun and Xu, Kai-Tuo},
  journal={arXiv preprint arXiv:2409.03283},
  year={2024}
}
@article{kumar2024high,
  title={High-fidelity audio compression with improved rvqgan},
  author={Kumar, Rithesh and Seetharaman, Prem and Luebs, Alejandro and Kumar, Ishaan and Kumar, Kundan},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@inproceedings{zhang2024speechtokenizer,
  title={Speechtokenizer: Unified speech tokenizer for speech language models},
  author={Zhang, Xin and Zhang, Dong and Li, Shimin and Zhou, Yaqian and Qiu, Xipeng},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}
@article{xin2024bigcodec,
  title={Bigcodec: Pushing the limits of low-bitrate neural speech codec},
  author={Xin, Detai and Tan, Xu and Takamichi, Shinnosuke and Saruwatari, Hiroshi},
  journal={arXiv preprint arXiv:2409.05377},
  year={2024}
}
@article{ji2024wavtokenizer,
  title={Wavtokenizer: an efficient acoustic discrete codec tokenizer for audio language modeling},
  author={Ji, Shengpeng and Jiang, Ziyue and Wang, Wen and Chen, Yifu and Fang, Minghui and Zuo, Jialong and Yang, Qian and Cheng, Xize and Wang, Zehan and Li, Ruiqi and others},
  journal={arXiv preprint arXiv:2408.16532},
  year={2024}
}
@article{defossez2024moshi,
  title={Moshi: a speech-text foundation model for real-time dialogue},
  author={D{\'e}fossez, Alexandre and Mazar{\'e}, Laurent and Orsini, Manu and Royer, Am{\'e}lie and P{\'e}rez, Patrick and J{\'e}gou, Herv{\'e} and Grave, Edouard and Zeghidour, Neil},
  journal={arXiv preprint arXiv:2410.00037},
  year={2024}
}
@article{parker2024scaling,
  title={Scaling Transformers for Low-Bitrate High-Quality Speech Coding},
  author={Parker, Julian D and Smirnov, Anton and Pons, Jordi and Carr, CJ and Zukowski, Zack and Evans, Zach and Liu, Xubo},
  journal={arXiv preprint arXiv:2411.19842},
  year={2024}
}
@article{ye2024codec,
  title={Codec does matter: Exploring the semantic shortcoming of codec for audio language model},
  author={Ye, Zhen and Sun, Peiwen and Lei, Jiahe and Lin, Hongzhan and Tan, Xu and Dai, Zheqi and Kong, Qiuqiang and Chen, Jianyi and Pan, Jiahao and Liu, Qifeng and others},
  journal={arXiv preprint arXiv:2408.17175},
  year={2024}
}
@article{le2024voicebox,
  title={Voicebox: Text-guided multilingual universal speech generation at scale},
  author={Le, Matthew and Vyas, Apoorv and Shi, Bowen and Karrer, Brian and Sari, Leda and Moritz, Rashel and Williamson, Mary and Manohar, Vimal and Adi, Yossi and Mahadeokar, Jay and others},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}
@article{chen2024vall,
  title={VALL-E 2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers},
  author={Chen, Sanyuan and Liu, Shujie and Zhou, Long and Liu, Yanqing and Tan, Xu and Li, Jinyu and Zhao, Sheng and Qian, Yao and Wei, Furu},
  journal={arXiv preprint arXiv:2406.05370},
  year={2024}
}
@article{wang2023neural,
  title={Neural codec language models are zero-shot text to speech synthesizers},
  author={Wang, Chengyi and Chen, Sanyuan and Wu, Yu and Zhang, Ziqiang and Zhou, Long and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and others},
  journal={arXiv preprint arXiv:2301.02111},
  year={2023}
}
@inproceedings{kimclam,
  title={CLaM-TTS: Improving Neural Codec Language Model for Zero-Shot Text-to-Speech},
  author={Kim, Jaehyeon and Lee, Keon and Chung, Seungjun and Cho, Jaewoong},
  booktitle={The Twelfth International Conference on Learning Representations}
}
@article{song2024ella,
  title={Ella-v: Stable neural codec language modeling with alignment-guided sequence reordering},
  author={Song, Yakun and Chen, Zhuo and Wang, Xiaofei and Ma, Ziyang and Chen, Xie},
  journal={arXiv preprint arXiv:2401.07333},
  year={2024}
}
@article{han2024vall,
  title={VALL-E R: Robust and Efficient Zero-Shot Text-to-Speech Synthesis via Monotonic Alignment},
  author={Han, Bing and Zhou, Long and Liu, Shujie and Chen, Sanyuan and Meng, Lingwei and Qian, Yanming and Liu, Yanqing and Zhao, Sheng and Li, Jinyu and Wei, Furu},
  journal={arXiv preprint arXiv:2406.07855},
  year={2024}
}
@inproceedings{siuzdakvocos,
  title={Vocos: Closing the gap between time-domain and Fourier-based neural vocoders for high-quality audio synthesis},
  author={Siuzdak, Hubert},
  booktitle={The Twelfth International Conference on Learning Representations}
}

@article{liu2024semanticodec,
  title={SemantiCodec: An Ultra Low Bitrate Semantic Audio Codec for General Sound},
  author={Liu, Haohe and Xu, Xuenan and Yuan, Yi and Wu, Mengyue and Wang, Wenwu and Plumbley, Mark D},
  journal={arXiv preprint arXiv:2405.00233},
  year={2024}
}

@article{defossez2022high,
  title={High fidelity neural audio compression},
  author={D{\'e}fossez, Alexandre and Copet, Jade and Synnaeve, Gabriel and Adi, Yossi},
  journal={arXiv preprint arXiv:2210.13438},
  year={2022}
}

@article{saeki2022utmos,
  title={Utmos: Utokyo-sarulab system for voicemos challenge 2022},
  author={Saeki, Takaaki and Xin, Detai and Nakata, Wataru and Koriyama, Tomoki and Takamichi, Shinnosuke and Saruwatari, Hiroshi},
  journal={arXiv preprint arXiv:2204.02152},
  year={2022}
}

@inproceedings{rix2001perceptual,
  title={Perceptual evaluation of speech quality (PESQ)-a new method for speech quality assessment of telephone networks and codecs},
  author={Rix, Antony W and Beerends, John G and Hollier, Michael P and Hekstra, Andries P},
  booktitle={2001 IEEE international conference on acoustics, speech, and signal processing. Proceedings (Cat. No. 01CH37221)},
  volume={2},
  pages={749--752},
  year={2001},
  organization={IEEE}
}

@inproceedings{andersen2017non,
  title={A non-intrusive short-time objective intelligibility measure},
  author={Andersen, Asger Heidemann and de Haan, Jan Mark and Tan, Zheng-Hua and Jensen, Jesper},
  booktitle={2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5085--5089},
  year={2017},
  organization={IEEE}
}

@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM transactions on audio, speech, and language processing},
  volume={29},
  pages={3451--3460},
  year={2021},
  publisher={IEEE}
}

@inproceedings{panayotov2015librispeech,
  title={Librispeech: an asr corpus based on public domain audio books},
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5206--5210},
  year={2015},
  organization={IEEE}
}

 

@article{vallex,
  author       = {Ziqiang Zhang and
                  Long Zhou and
                  Chengyi Wang and
                  Sanyuan Chen and
                  Yu Wu and
                  Shujie Liu and
                  Zhuo Chen and
                  Yanqing Liu and
                  Huaming Wang and
                  Jinyu Li and
                  Lei He and
                  Sheng Zhao and
                  Furu Wei},
  title        = {Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural
                  Codec Language Modeling},
  journal      = {CoRR},
  volume       = {abs/2303.03926},
  year         = {2023},
}

@article{speartts,
  author       = {Eugene Kharitonov and
                  Damien Vincent and
                  Zal{\'{a}}n Borsos and
                  Rapha{\"{e}}l Marinier and
                  Sertan Girgin and
                  Olivier Pietquin and
                  Matt Sharifi and
                  Marco Tagliasacchi and
                  Neil Zeghidour},
  title        = {Speak, Read and Prompt: High-Fidelity Text-to-Speech with Minimal
                  Supervision},
  journal      = {Trans. Assoc. Comput. Linguistics},
  volume       = {11},
  pages        = {1703--1718},
  year         = {2023},
}

@article{melle,
  author       = {Lingwei Meng and
                  Long Zhou and
                  Shujie Liu and
                  Sanyuan Chen and
                  Bing Han and
                  Shujie Hu and
                  Yanqing Liu and
                  Jinyu Li and
                  Sheng Zhao and
                  Xixin Wu and
                  Helen Meng and
                  Furu Wei},
  title        = {Autoregressive Speech Synthesis without Vector Quantization},
  journal      = {CoRR},
  volume       = {abs/2407.08551},
  year         = {2024},
}

@article{kalle,
  title={Autoregressive Speech Synthesis with Next-Distribution Prediction},
  author={Zhu, Xinfa and Tian, Wenjie and Xie, Lei},
  journal={arXiv preprint arXiv:2412.16846},
  year={2024}
}
 
@article{Pratap2020MLSAL,
  title={MLS: A Large-Scale Multilingual Dataset for Speech Research},
  author={Vineel Pratap and Qiantong Xu and Anuroop Sriram and Gabriel Synnaeve and Ronan Collobert},
  journal={ArXiv},
  year={2020},
  volume={abs/2012.03411}
}
@article{lajszczak2024base,
  title={BASE TTS: Lessons from building a billion-parameter text-to-speech model on 100K hours of data},
  author={{\L}ajszczak, Mateusz and C{\'a}mbara, Guillermo and Li, Yang and Beyhan, Fatih and van Korlaar, Arent and Yang, Fan and Joly, Arnaud and Mart{\'\i}n-Cortinas, {\'A}lvaro and Abbas, Ammar and Michalski, Adam and others},
  journal={arXiv preprint arXiv:2402.08093},
  year={2024}
}
@inproceedings{zhou2021seen,
  title={Seen and unseen emotional style transfer for voice conversion with a new emotional speech dataset},
  author={Zhou, Kun and Sisman, Berrak and Liu, Rui and Li, Haizhou},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={920--924},
  year={2021},
  organization={IEEE}
}
@article{zhou2021emotional,
title = {Emotional voice conversion: Theory, databases and ESD},
journal = {Speech Communication},
volume = {137},
pages = {1-18},
year = {2022},
issn = {0167-6393}
}
@article{ma2023emotion2vec,
  title={emotion2vec: Self-Supervised Pre-Training for Speech Emotion Representation},
  author={Ma, Ziyang and Zheng, Zhisheng and Ye, Jiaxin and Li, Jinchao and Gao, Zhifu and Zhang, Shiliang and Chen, Xie},
  journal={arXiv preprint arXiv:2312.15185},
  year={2023}
}
@article{snell2024scaling,
  title={Scaling llm test-time compute optimally can be more effective than scaling model parameters},
  author={Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral},
  journal={arXiv preprint arXiv:2408.03314},
  year={2024}
}
@article{ma2025inference,
  title={Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps},
  author={Ma, Nanye and Tong, Shangyuan and Jia, Haolin and Hu, Hexiang and Su, Yu-Chuan and Zhang, Mingda and Yang, Xuan and Li, Yandong and Jaakkola, Tommi and Jia, Xuhui and others},
  journal={arXiv preprint arXiv:2501.09732},
  year={2025}
}

 
@article{kong2020hifi,
  title={Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis},
  author={Kong, Jungil and Kim, Jaehyeon and Bae, Jaekyoung},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={17022--17033},
  year={2020}
}
@inproceedings{
anonymous2025scaling,
title={Scaling Transformers for Low-Bitrate High-Quality Speech Coding},
author={Anonymous},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=4YpMrGfldX}
}

@article{basetts,
  author       = {Mateusz Lajszczak and
                  Guillermo C{\'{a}}mbara and
                  Yang Li and
                  Fatih Beyhan and
                  Arent van Korlaar and
                  Fan Yang and
                  Arnaud Joly and
                  {\'{A}}lvaro Mart{\'{\i}}n{-}Cortinas and
                  Ammar Abbas and
                  Adam Michalski and
                  Alexis Moinet and
                  Sri Karlapati and
                  Ewa Muszynska and
                  Haohan Guo and
                  Bartosz Putrycz and
                  Soledad L{\'{o}}pez Gambino and
                  Kayeon Yoo and
                  Elena Sokolova and
                  Thomas Drugman},
  title        = {{BASE} {TTS:} Lessons from building a billion-parameter Text-to-Speech
                  model on 100K hours of data},
  journal      = {CoRR},
  volume       = {abs/2402.08093},
  year         = {2024},
}

@article{tortoisetts,
  author       = {James Betker},
  title        = {Better speech synthesis through scaling},
  journal      = {CoRR},
  volume       = {abs/2305.07243},
  year         = {2023},
}

@article{ji2025test,
  title={Test-time Computing: from System-1 Thinking to System-2 Thinking},
  author={Ji, Yixin and Li, Juntao and Ye, Hai and Wu, Kaixin and Xu, Jia and Mo, Linjian and Zhang, Min},
  journal={arXiv preprint arXiv:2501.02497},
  year={2025}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{Ma2025InferenceTimeSF,
  title={Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps},
  author={Nanye Ma and Shangyuan Tong and Haolin Jia and Hexiang Hu and Yu-Chuan Su and Mingda Zhang and Xuan Yang and Yandong Li and T. Jaakkola and Xuhui Jia and Saining Xie},
  year={2025},
  url={https://api.semanticscholar.org/CorpusID:275570556}
}
@article{jaech2024openai,
  title={Openai o1 system card},
  author={Jaech, Aaron and Kalai, Adam and Lerer, Adam and Richardson, Adam and El-Kishky, Ahmed and Low, Aiden and Helyar, Alec and Madry, Aleksander and Beutel, Alex and Carney, Alex and others},
  journal={arXiv preprint arXiv:2412.16720},
  year={2024}
}
@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}
@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}
@article{zhu2024survey,
  title={A survey on model compression for large language models},
  author={Zhu, Xunyu and Li, Jian and Liu, Yong and Ma, Can and Wang, Weiping},
  journal={Transactions of the Association for Computational Linguistics},
  volume={12},
  pages={1556--1577},
  year={2024},
  publisher={MIT Press 255 Main Street, 9th Floor, Cambridge, Massachusetts 02142, USA~…}
}
@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}
@article{borsos2023audiolm,
  title={Audiolm: a language modeling approach to audio generation},
  author={Borsos, Zal{\'a}n and Marinier, Rapha{\"e}l and Vincent, Damien and Kharitonov, Eugene and Pietquin, Olivier and Sharifi, Matt and Roblek, Dominik and Teboul, Olivier and Grangier, David and Tagliasacchi, Marco and others},
  journal={IEEE/ACM transactions on audio, speech, and language processing},
  volume={31},
  pages={2523--2533},
  year={2023},
  publisher={IEEE}
}
@inproceedings{
mentzer2024finite,
title={Finite Scalar Quantization: {VQ}-{VAE} Made Simple},
author={Fabian Mentzer and David Minnen and Eirikur Agustsson and Michael Tschannen},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=8ishA3LxN8}
}
@article{barrault2023seamless,
  title={Seamless: Multilingual Expressive and Streaming Speech Translation},
  author={Barrault, Lo{\"\i}c and Chung, Yu-An and Meglioli, Mariano Coria and Dale, David and Dong, Ning and Duppenthaler, Mark and Duquenne, Paul-Ambroise and Ellis, Brian and Elsahar, Hady and Haaheim, Justin and others},
  journal={arXiv preprint arXiv:2312.05187},
  year={2023}
}
@inproceedings{radford2023robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International conference on machine learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}
@misc{gao2023paraformerfastaccurateparallel,
      title={Paraformer: Fast and Accurate Parallel Transformer for Non-autoregressive End-to-End Speech Recognition}, 
      author={Zhifu Gao and Shiliang Zhang and Ian McLoughlin and Zhijie Yan},
      year={2023},
      eprint={2206.08317},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2206.08317}, 
}
@article{chen2022wavlm,
  title={Wavlm: Large-scale self-supervised pre-training for full stack speech processing},
  author={Chen, Sanyuan and Wang, Chengyi and Chen, Zhengyang and Wu, Yu and Liu, Shujie and Chen, Zhuo and Li, Jinyu and Kanda, Naoyuki and Yoshioka, Takuya and Xiao, Xiong and others},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  volume={16},
  number={6},
  pages={1505--1518},
  year={2022},
  publisher={IEEE}
}
@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}
@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}
@article{li2023diverse,
  title={Diverse and expressive speech prosody prediction with denoising diffusion probabilistic model},
  author={Li, Xiang and Liu, Songxiang and Lam, Max WY and Wu, Zhiyong and Weng, Chao and Meng, Helen},
  journal={arXiv preprint arXiv:2305.16749},
  year={2023}
}
@misc{ren2022fastspeech2fasthighquality,
      title={FastSpeech 2: Fast and High-Quality End-to-End Text to Speech}, 
      author={Yi Ren and Chenxu Hu and Xu Tan and Tao Qin and Sheng Zhao and Zhou Zhao and Tie-Yan Liu},
      year={2022},
      eprint={2006.04558},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2006.04558}, 
}
 
@inproceedings{reddy2021dnsmos,
  title={DNSMOS: A non-intrusive perceptual objective speech quality metric to evaluate noise suppressors},
  author={Reddy, Chandan KA and Gopal, Vishak and Cutler, Ross},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6493--6497},
  year={2021},
  organization={IEEE}
}
@article{gao2023funasr,
  title={Funasr: A fundamental end-to-end speech recognition toolkit},
  author={Gao, Zhifu and Li, Zerui and Wang, Jiaming and Luo, Haoneng and Shi, Xian and Chen, Mengzhe and Li, Yabin and Zuo, Lingyun and Du, Zhihao and Xiao, Zhangyu and others},
  journal={arXiv preprint arXiv:2305.11013},
  year={2023}
}
@article{ma2024wenetspeech4tts,
  title={WenetSpeech4TTS: A 12,800-hour Mandarin TTS Corpus for Large Speech Generation Model Benchmark},
  author={Ma, Linhan and Guo, Dake and Song, Kun and Jiang, Yuepeng and Wang, Shuai and Xue, Liumeng and Xu, Weiming and Zhao, Huan and Zhang, Binbin and Xie, Lei},
  journal={arXiv preprint arXiv:2406.05763},
  year={2024}
}
@inproceedings{he2024emilia,
  title={Emilia: An extensive, multilingual, and diverse speech dataset for large-scale speech generation},
  author={He, Haorui and Shang, Zengqiang and Wang, Chaoren and Li, Xuyuan and Gu, Yicheng and Hua, Hua and Liu, Liwei and Yang, Chen and Li, Jiaqi and Shi, Peiyang and others},
  booktitle={2024 IEEE Spoken Language Technology Workshop (SLT)},
  pages={885--890},
  year={2024},
  organization={IEEE}
}
@inproceedings{kang2024libriheavy,
  title={Libriheavy: a 50,000 hours asr corpus with punctuation casing and context},
  author={Kang, Wei and Yang, Xiaoyu and Yao, Zengwei and Kuang, Fangjun and Yang, Yifan and Guo, Liyong and Lin, Long and Povey, Daniel},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={10991--10995},
  year={2024},
  organization={IEEE}
}
 
@article{pratap2020mls,
  title={Mls: A large-scale multilingual dataset for speech research},
  author={Pratap, Vineel and Xu, Qiantong and Sriram, Anuroop and Synnaeve, Gabriel and Collobert, Ronan},
  journal={arXiv preprint arXiv:2012.03411},
  year={2020}
}
@article{chen2021gigaspeech,
  title={Gigaspeech: An evolving, multi-domain asr corpus with 10,000 hours of transcribed audio},
  author={Chen, Guoguo and Chai, Shuzhou and Wang, Guanbo and Du, Jiayu and Zhang, Wei-Qiang and Weng, Chao and Su, Dan and Povey, Daniel and Trmal, Jan and Zhang, Junbo and others},
  journal={arXiv preprint arXiv:2106.06909},
  year={2021}
}