[
  {
    "index": 0,
    "papers": [
      {
        "key": "ji2025test",
        "author": "Ji, Yixin and Li, Juntao and Ye, Hai and Wu, Kaixin and Xu, Jia and Mo, Linjian and Zhang, Min",
        "title": "Test-time Computing: from System-1 Thinking to System-2 Thinking"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "speartts",
        "author": "Eugene Kharitonov and\nDamien Vincent and\nZal{\\'{a}}n Borsos and\nRapha{\\\"{e}}l Marinier and\nSertan Girgin and\nOlivier Pietquin and\nMatt Sharifi and\nMarco Tagliasacchi and\nNeil Zeghidour",
        "title": "Speak, Read and Prompt: High-Fidelity Text-to-Speech with Minimal\nSupervision"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "wang2023neural",
        "author": "Wang, Chengyi and Chen, Sanyuan and Wu, Yu and Zhang, Ziqiang and Zhou, Long and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and others",
        "title": "Neural codec language models are zero-shot text to speech synthesizers"
      },
      {
        "key": "chen2024vall",
        "author": "Chen, Sanyuan and Liu, Shujie and Zhou, Long and Liu, Yanqing and Tan, Xu and Li, Jinyu and Zhao, Sheng and Qian, Yao and Wei, Furu",
        "title": "VALL-E 2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "wang2023neural",
        "author": "Wang, Chengyi and Chen, Sanyuan and Wu, Yu and Zhang, Ziqiang and Zhou, Long and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and others",
        "title": "Neural codec language models are zero-shot text to speech synthesizers"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "vallex",
        "author": "Ziqiang Zhang and\nLong Zhou and\nChengyi Wang and\nSanyuan Chen and\nYu Wu and\nShujie Liu and\nZhuo Chen and\nYanqing Liu and\nHuaming Wang and\nJinyu Li and\nLei He and\nSheng Zhao and\nFuru Wei",
        "title": "Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural\nCodec Language Modeling"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "speartts",
        "author": "Eugene Kharitonov and\nDamien Vincent and\nZal{\\'{a}}n Borsos and\nRapha{\\\"{e}}l Marinier and\nSertan Girgin and\nOlivier Pietquin and\nMatt Sharifi and\nMarco Tagliasacchi and\nNeil Zeghidour",
        "title": "Speak, Read and Prompt: High-Fidelity Text-to-Speech with Minimal\nSupervision"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "tortoisetts",
        "author": "James Betker",
        "title": "Better speech synthesis through scaling"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "basetts",
        "author": "Mateusz Lajszczak and\nGuillermo C{\\'{a}}mbara and\nYang Li and\nFatih Beyhan and\nArent van Korlaar and\nFan Yang and\nArnaud Joly and\n{\\'{A}}lvaro Mart{\\'{\\i}}n{-}Cortinas and\nAmmar Abbas and\nAdam Michalski and\nAlexis Moinet and\nSri Karlapati and\nEwa Muszynska and\nHaohan Guo and\nBartosz Putrycz and\nSoledad L{\\'{o}}pez Gambino and\nKayeon Yoo and\nElena Sokolova and\nThomas Drugman",
        "title": "{BASE} {TTS:} Lessons from building a billion-parameter Text-to-Speech\nmodel on 100K hours of data"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "anastassiou2024seed",
        "author": "Anastassiou, Philip and Chen, Jiawei and Chen, Jitong and Chen, Yuanzhe and Chen, Zhuo and Chen, Ziyi and Cong, Jian and Deng, Lelai and Ding, Chuang and Gao, Lu and others",
        "title": "Seed-TTS: A Family of High-Quality Versatile Speech Generation Models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "du2024cosyvoice",
        "author": "Du, Zhihao and Chen, Qian and Zhang, Shiliang and Hu, Kai and Lu, Heng and Yang, Yexin and Hu, Hangrui and Zheng, Siqi and Gu, Yue and Ma, Ziyang and others",
        "title": "Cosyvoice: A scalable multilingual zero-shot text-to-speech synthesizer based on supervised semantic tokens"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "guo2024fireredtts",
        "author": "Guo, Hao-Han and Liu, Kun and Shen, Fei-Yu and Wu, Yi-Chen and Xie, Feng-Long and Xie, Kun and Xu, Kai-Tuo",
        "title": "Fireredtts: A foundation text-to-speech framework for industry-level generative speech applications"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "melle",
        "author": "Lingwei Meng and\nLong Zhou and\nShujie Liu and\nSanyuan Chen and\nBing Han and\nShujie Hu and\nYanqing Liu and\nJinyu Li and\nSheng Zhao and\nXixin Wu and\nHelen Meng and\nFuru Wei",
        "title": "Autoregressive Speech Synthesis without Vector Quantization"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "kalle",
        "author": "Zhu, Xinfa and Tian, Wenjie and Xie, Lei",
        "title": "Autoregressive Speech Synthesis with Next-Distribution Prediction"
      }
    ]
  }
]