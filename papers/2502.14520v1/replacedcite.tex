\section{Related Work}
\paragraph{3D Semantic Scene Completion.}
% The SSC task aimed to address the challenges of scene completion and semantic segmentation by predicting the occupancy and semantic categories of individual voxels within a 3D scene. This task received significant attention because of its crucial role in semantic occupancy prediction for autonomous driving.
% Existing methods for outdoor SSC were mainly divided into LiDAR-based and camera-based approaches, depending on their input modality. LiDAR-based methods focused on utilizing LiDAR for accurate 3D semantic occupancy predictions. SSCNet____ was the first to define the semantic scene completion task, wherein both geometry and semantics were jointly inferred from incomplete visual observations.
% Subsequent research recognized the inherently 3D characteristics of semantic scene completion tasks, leading to numerous studies that directly employed 3D inputs____, such as depth information, occupancy meshes, and point clouds, to leverage their rich geometric cues. To incorporate additional texture information, many works____ explored the use of multi-modal inputs, combining RGB images with diverse geometric cues. Additionally, some research____ explored the relationship between semantic segmentation and scene completion.

Semantic Scene Completion (SSC) aims to jointly predict the geometry and semantics of a scene in 3D space, addressing the challenges of both scene completion and semantic segmentation. SSCNet____ was the first to introduce this task, inferring both occupancy and semantic labels from incomplete visual observations. Subsequent studies have leveraged explicit 3D representations, such as depth maps, occupancy grids, and point clouds____, which provide rich geometric cues. Meanwhile, multi-modal approaches____ have integrated RGB imagery with depth information to enhance texture representation. Additionally, several works____ have explored the interdependence between semantic segmentation and scene completion.
% -------------------------------------------------
\begin{figure*}[t]
\centering
  \includegraphics[width=\textwidth]{figure3.pdf}
  \caption{The FlowScene framework is proposed for temproal 3D semantic scene completion.}
  \label{fig:figure3}
\end{figure*}
% \vspace{-3mm}
% -------------------------------------------------

With the advent of cost-effective, vision-based autonomous driving solutions, monocular SSC methods have gained traction. MonoScene____ was the first to infer dense 3D semantics from a single RGB image. TPVFormer____ introduced a tri-perspective view (TPV) representation, extending BEV with two vertical planes. OccFormer____ proposed a dual-path transformer to encode voxel features, while VoxFormer____ introduced a two-stage pipeline for voxelized semantic scene understanding. SurroundOcc____ employed 3D convolutions for progressive voxel upsampling and dense SSC ground truth generation.
OctOcc____ utilized an octree-based representation for semantic occupancy prediction, while NDCScene____ redefined spatial encoding by mapping 2D feature maps to normalized device coordinates (NDC) rather than world space.
MonoOcc____ enhanced 3D volumetric representations using an image-conditioned cross-attention mechanism. H2GFormer____ introduced a progressive feature reconstruction strategy to propagate 2D information across multiple viewpoints. Symphonize____ extracted high-level instance features to serve as key-value pairs for cross-attention. HASSC____ proposed a self-distillation framework to improve the performance of VoxFormer. Stereo-based methods, such as BRGScene____, leveraged stereo depth estimation to resolve geometric ambiguities. MixSSC____ fused forward projection sparsity with the denseness of depth-prior backward projection.
CGFormer____ utilized a context-aware query generator to initialize context-dependent queries tailored to individual input images, effectively capturing their unique characteristics and aggregating information within the region of interest. HTCL____ decomposed temporal context learning into two hierarchical steps: cross-frame affinity measurement and affinity-based dynamic refinement.
\vspace{-4mm}
\paragraph{Optical Flow for Visual Perception.}
Optical flow estimation, a fundamental task in computer vision, aims to establish dense pixel-wise correspondences between consecutive frames. FlowNet____ introduced the first CNN-based end-to-end flow estimation pipeline, leveraging a hierarchical pyramid structure. PWC-Net____ further refined this approach by incorporating multi-stage warping to handle large-displacement motion. RAFT____ introduced an iterative, recurrent architecture that refines residual flow predictions in a fully convolutional manner. GMFlow____ reframed optical flow as a global matching problem, directly computing feature similarities to establish correspondences.

Beyond motion estimation, optical flow has been leveraged to enhance various vision tasks. FlowTrack____ used optical flow to enrich feature representations and improve tracking accuracy. FGFA____ employed flow-guided feature aggregation for end-to-end video object detection. LoSh____ utilized flow-based warping to propagate annotations across temporal neighbors, thereby boosting referring video object segmentation. DATMO____ introduced a moving object detection and tracking framework tailored for autonomous vehicles. DeVOS____ incorporated optical flow into scene motion modeling, using it as a prior for learnable offsets in video segmentation.