@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})


@inproceedings{cao2022monoscene,
    title={MonoScene: Monocular 3D Semantic Scene Completion}, 
    author={Anh-Quan Cao and Raoul de Charette},
    booktitle={CVPR},
    year={2022}
}
@inproceedings{huang2023tri,
  title={Tri-perspective view for vision-based 3d semantic occupancy prediction},
  author={Huang, Yuanhui and Zheng, Wenzhao and Zhang, Yunpeng and Zhou, Jie and Lu, Jiwen},
  booktitle={CVPR},
  pages={9223--9232},
  year={2023}
}
@InProceedings{li2023voxformer,
      title={VoxFormer: Sparse Voxel Transformer for Camera-based 3D Semantic Scene Completion}, 
      author={Li, Yiming and Yu, Zhiding and Choy, Christopher and Xiao, Chaowei and Alvarez, Jose M and Fidler, Sanja and Feng, Chen and Anandkumar, Anima},
      booktitle = {CVPR},
      year={2023}
}
@article{zhang2023occformer,
  title={OccFormer: Dual-path Transformer for Vision-based 3D Semantic Occupancy Prediction},
  author={Zhang, Yunpeng and Zhu, Zheng and Du, Dalong},
  journal={arXiv preprint arXiv:2304.05316},
  year={2023}
}
@inproceedings{song2017semantic,
  title={Semantic scene completion from a single depth image},
  author={Song, Shuran and Yu, Fisher and Zeng, Andy and Chang, Angel X and Savva, Manolis and Funkhouser, Thomas},
  booktitle={CVPR},
  pages={1746--1754},
  year={2017}
}

@article{rist2021semantic,
  title={Semantic scene completion using local deep implicit functions on lidar data},
  author={Rist, Christoph B and Emmerichs, David and Enzweiler, Markus and Gavrila, Dariu M},
  journal={TPAMI},
  volume={44},
  number={10},
  pages={7205--7218},
  year={2021},
  publisher={IEEE}
}
@inproceedings{zhang2018efficient,
  title={Efficient semantic scene completion network with spatial group convolution},
  author={Zhang, Jiahui and Zhao, Hao and Yao, Anbang and Chen, Yurong and Zhang, Li and Liao, Hongen},
  booktitle={ECCV},
  pages={733--749},
  year={2018}
}
@inproceedings{cai2021semantic,
  title={Semantic scene completion via integrating instances and scene in-the-loop},
  author={Cai, Yingjie and Chen, Xuesong and Zhang, Chao and Lin, Kwan-Yee and Wang, Xiaogang and Li, Hongsheng},
  booktitle={CVPR},
  pages={324--333},
  year={2021}
}
@inproceedings{li2019rgbd,
  title={Rgbd based dimensional decomposition residual network for 3d semantic scene completion},
  author={Li, Jie and Liu, Yu and Gong, Dong and Shi, Qinfeng and Yuan, Xia and Zhao, Chunxia and Reid, Ian},
  booktitle={CVPR},
  pages={7693--7702},
  year={2019}
}
@inproceedings{philion2020lift,
  title={Lift, splat, shoot: Encoding images from arbitrary camera rigs by implicitly unprojecting to 3d},
  author={Philion, Jonah and Fidler, Sanja},
  booktitle={ECCV},
  pages={194--210},
  year={2020},
  organization={Springer}
}
@inproceedings{li2022bevformer,
  title={Bevformer: Learning birdâ€™s-eye-view representation from multi-camera images via spatiotemporal transformers},
  author={Li, Zhiqi and Wang, Wenhai and Li, Hongyang and Xie, Enze and Sima, Chonghao and Lu, Tong and Qiao, Yu and Dai, Jifeng},
  booktitle={ECCV},
  pages={1--18},
  year={2022},
  organization={Springer}
}
@article{roddick2018orthographic,
  title={Orthographic feature transform for monocular 3d object detection},
  author={Roddick, Thomas and Kendall, Alex and Cipolla, Roberto},
  journal={arXiv preprint arXiv:1811.08188},
  year={2018}
}
@inproceedings{wang2022detr3d,
  title={Detr3d: 3d object detection from multi-view images via 3d-to-2d queries},
  author={Wang, Yue and Guizilini, Vitor Campagnolo and Zhang, Tianyuan and Wang, Yilun and Zhao, Hang and Solomon, Justin},
  booktitle={Conference on Robot Learning},
  pages={180--191},
  year={2022},
  organization={PMLR}
}
@inproceedings{li2023bevdepth,
  title={Bevdepth: Acquisition of reliable depth for multi-view 3d object detection},
  author={Li, Yinhao and Ge, Zheng and Yu, Guanyi and Yang, Jinrong and Wang, Zengran and Shi, Yukang and Sun, Jianjian and Li, Zeming},
  booktitle={AAAI},
  volume={37},
  number={2},
  pages={1477--1485},
  year={2023}
}
@inproceedings{behley2019semantickitti,
  title={Semantickitti: A dataset for semantic scene understanding of lidar sequences},
  author={Behley, Jens and Garbade, Martin and Milioto, Andres and Quenzel, Jan and Behnke, Sven and Stachniss, Cyrill and Gall, Jurgen},
  booktitle={ICCV},
  pages={9297--9307},
  year={2019}
}
@inproceedings{tan2019efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={ICML},
  pages={6105--6114},
  year={2019},
  organization={PMLR}
}
@inproceedings{hatamizadeh2023global,
  title={Global context vision transformers},
  author={Hatamizadeh, Ali and Yin, Hongxu and Heinrich, Greg and Kautz, Jan and Molchanov, Pavlo},
  booktitle={ICML},
  pages={12633--12646},
  year={2023},
  organization={PMLR}
}
@inproceedings{zhu2020deforDETR,
  title={Deformable DETR: Deformable Transformers for End-to-End Object Detection},
  author={Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
  booktitle={ICLR},
  year={2020}
}
@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}
@inproceedings{li2023fbbev,
  title={{FB-BEV}: {BEV} Representation from Forward-Backward View Transformations},
  author={Li, Zhiqi and Yu, Zhiding and Wang, Wenhai and Anandkumar, Anima and Lu, Tong and Alvarez, Jose M},
  booktitle={ICCV},
  year={2023}
}
@inproceedings{guo2018view,
  title={View-volume network for semantic scene completion from a single depth image},
  author={Guo, Yuxiao and Tong, Xin},
  booktitle={IJCAI},
  pages={726--732},
  year={2018}
}
@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={ICCV},
  pages={10012--10022},
  year={2021}
}
@article{dosovitskiy2020vit,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@inproceedings{li2020aicnet,
  title={Anisotropic convolutional networks for 3d semantic scene completion},
  author={Li, Jie and Han, Kai and Wang, Peng and Liu, Yu and Yuan, Xia},
  booktitle={CVPR},
  pages={3351--3359},
  year={2020}
}
@inproceedings{roldao2020lmscnet,
  title={Lmscnet: Lightweight multiscale 3d semantic completion},
  author={Roldao, Luis and de Charette, Raoul and Verroust-Blondet, Anne},
  booktitle={3DV},
  pages={111--119},
  year={2020},
  organization={IEEE}
}
@inproceedings{yan2021sparse,
  title={Sparse single sweep lidar point cloud segmentation via learning contextual shape priors from scene completion},
  author={Yan, Xu and Gao, Jiantao and Li, Jie and Zhang, Ruimao and Li, Zhen and Huang, Rui and Cui, Shuguang},
  booktitle={AAAI},
  volume={35},
  number={4},
  pages={3101--3109},
  year={2021}
}
@inproceedings{lin2017feature,
  title={Feature pyramid networks for object detection},
  author={Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  booktitle={CVPR},
  pages={2117--2125},
  year={2017}
}
@inproceedings{wei2023surroundocc,
  title={Surroundocc: Multi-camera 3d occupancy prediction for autonomous driving},
  author={Wei, Yi and Zhao, Linqing and Zheng, Wenzhao and Zhu, Zheng and Zhou, Jie and Lu, Jiwen},
  booktitle={ICCV},
  pages={21729--21740},
  year={2023}
}
@inproceedings{yao2023ndc,
  title={Ndc-scene: Boost monocular 3d semantic scene completion in normalized device coordinates space},
  author={Yao, Jiawei and Li, Chuming and Sun, Keqiang and Cai, Yingjie and Li, Hao and Ouyang, Wanli and Li, Hongsheng},
  booktitle={ICCV},
  pages={9455--9465},
  year={2023}
}
@article{li2023sscbench,
      title={SSCBench: Monocular 3D Semantic Scene Completion Benchmark in Street Views}, 
      author={Li, Yiming and Li, Sihang and Liu, Xinhao and Gong, Moonjun and Li, Kenan and Chen, Nuo and Wang, Zijun and Li, Zhiheng and Jiang, Tao and Yu, Fisher and Wang, Yue and Zhao, Hang and Yu, Zhiding and Feng, Chen},
      journal={arXiv preprint arXiv:2306.09001},
      year={2023}
}
@inproceedings{Geiger2012kitti,
  author = {Andreas Geiger and Philip Lenz and Raquel Urtasun},
  title = {Are we ready for Autonomous Driving? The KITTI Vision Benchmark Suite},
  booktitle = {CVPR},
  year = {2012}
}
@article{Liao2022kitti360,
   title =  {{KITTI}-360: A Novel Dataset and Benchmarks for Urban Scene Understanding in 2D and 3D},
   author = {Yiyi Liao and Jun Xie and Andreas Geiger},
   journal = {TPAMI},
   year = {2022},
}
@inproceedings{zou2021udnet,
  title={Up-to-down network: Fusing multi-scale context for 3d semantic scene completion},
  author={Zou, Hao and Yang, Xuemeng and Huang, Tianxin and Zhang, Chujuan and Liu, Yong and Li, Wanlong and Wen, Feng and Zhang, Hongbo},
  booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={16--23},
  year={2021},
  organization={IEEE}
}
@inproceedings{yang2021ssasc,
  title={Semantic segmentation-assisted scene completion for lidar point clouds},
  author={Yang, Xuemeng and Zou, Hao and Kong, Xin and Huang, Tianxin and Liu, Yong and Li, Wanlong and Wen, Feng and Zhang, Hongbo},
  booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={3555--3562},
  year={2021},
  organization={IEEE}
}
@inproceedings{mei2023sscrs,
  title={SSC-RS: Elevate LiDAR Semantic Scene Completion with Representation Separation and BEV Fusion},
  author={Mei, Jianbiao and Yang, Yu and Wang, Mengmeng and Huang, Tianxin and Yang, Xuemeng and Liu, Yong},
  booktitle={2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={1--8},
  year={2023},
  organization={IEEE}
}
@article{li2023stereoscene,
  title={Stereoscene: Bev-assisted stereo matching empowers 3d semantic scene completion},
  author={Li, Bohan and Sun, Yasheng and Jin, Xin and Zeng, Wenjun and Zhu, Zheng and Wang, Xiaoefeng and Zhang, Yunpeng and Okae, James and Xiao, Hang and Du, Dalong},
  journal={arXiv preprint arXiv:2303.13959},
  year={2023}
}
@inproceedings{zbontar2015computing,
  title={Computing the stereo matching cost with a convolutional neural network},
  author={Zbontar, Jure and LeCun, Yann},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1592--1599},
  year={2015}
}
@inproceedings{yao2018mvsnet,
  title={Mvsnet: Depth inference for unstructured multi-view stereo},
  author={Yao, Yao and Luo, Zixin and Li, Shiwei and Fang, Tian and Quan, Long},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={767--783},
  year={2018}
}
@inproceedings{bhat2021adabins,
  title={Adabins: Depth estimation using adaptive bins},
  author={Bhat, Shariq Farooq and Alhashim, Ibraheem and Wonka, Peter},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4009--4018},
  year={2021}
}
@InProceedings{Yu_2020_fastmvsnet,
author = {Yu, Zehao and Gao, Shenghua},
title = {Fast-MVSNet: Sparse-to-Dense Multi-View Stereo With Learned Propagation and Gauss-Newton Refinement},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}
@InProceedings{Bae_2022_magnet,
    author    = {Bae, Gwangbin and Budvytis, Ignas and Cipolla, Roberto},
    title     = {Multi-View Depth Estimation by Fusing Single-View Depth Probability With Multi-View Geometry},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {2842-2851}
}
@inproceedings{li2023bevstereo,
  title={Bevstereo: Enhancing depth estimation in multi-view 3d object detection with temporal stereo},
  author={Li, Yinhao and Bao, Han and Ge, Zheng and Yang, Jinrong and Sun, Jianjian and Li, Zeming},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={2},
  pages={1486--1494},
  year={2023}
}
@inproceedings{guo2019gwcnet,
  title={Group-wise correlation stereo network},
  author={Guo, Xiaoyang and Yang, Kai and Yang, Wukui and Wang, Xiaogang and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={3273--3282},
  year={2019}
}
@inproceedings{gu2020cascade,
  title={Cascade cost volume for high-resolution multi-view stereo and stereo matching},
  author={Gu, Xiaodong and Fan, Zhiwen and Zhu, Siyu and Dai, Zuozhuo and Tan, Feitong and Tan, Ping},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2495--2504},
  year={2020}
}
@article{yin2022towards,
  title={Towards accurate reconstruction of 3d scene shape from a single monocular image},
  author={Yin, Wei and Zhang, Jianming and Wang, Oliver and Niklaus, Simon and Chen, Simon and Liu, Yifan and Shen, Chunhua},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={45},
  number={5},
  pages={6480--6494},
  year={2022},
  publisher={IEEE}
}
@inproceedings{kong2023robodepth,
  title = {RoboDepth: Robust Out-of-Distribution Depth Estimation under Corruptions},
  author = {Kong, Lingdong and Xie, Shaoyuan and Hu, Hanjiang and Ng, Lai Xing and Cottereau, Benoit R. and Ooi, Wei Tsang},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2023},
}
@InProceedings{Li_2023_CVPR,
    author    = {Li, Rui and Gong, Dong and Yin, Wei and Chen, Hao and Zhu, Yu and Wang, Kaixuan and Chen, Xiaozhi and Sun, Jinqiu and Zhang, Yanning},
    title     = {Learning To Fuse Monocular and Multi-View Cues for Multi-Frame Depth Estimation in Dynamic Scenes},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2023},
    pages     = {21539-21548}
}
@article{chen2017aspp,
  title={Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs},
  author={Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={40},
  number={4},
  pages={834--848},
  year={2017},
  publisher={IEEE}
}
@InProceedings{Hassani_2023_Neighborhood,
    author    = {Hassani, Ali and Walton, Steven and Li, Jiachen and Li, Shen and Shi, Humphrey},
    title     = {Neighborhood Attention Transformer},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2023},
    pages     = {6185-6194}
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International conference on machine learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}

@inproceedings{radford2021clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{li2022lseg,
  title={Language-driven semantic segmentation},
  author={Li, Boyi and Weinberger, Kilian Q and Belongie, Serge and Koltun, Vladlen and Ranftl, Ren{\'e}},
  journal={arXiv preprint arXiv:2201.03546},
  year={2022}
}
@inproceedings{ghiasi2022openseg,
  title={Scaling open-vocabulary image segmentation with image-level labels},
  author={Ghiasi, Golnaz and Gu, Xiuye and Cui, Yin and Lin, Tsung-Yi},
  booktitle={European Conference on Computer Vision},
  pages={540--557},
  year={2022},
  organization={Springer}
}
@inproceedings{dong2023maskclip,
  title={Maskclip: Masked self-distillation advances contrastive language-image pretraining},
  author={Dong, Xiaoyi and Bao, Jianmin and Zheng, Yinglin and Zhang, Ting and Chen, Dongdong and Yang, Hao and Zeng, Ming and Zhang, Weiming and Yuan, Lu and Chen, Dong and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10995--11005},
  year={2023}
}

@inproceedings{jain2022bottom,
  title={Bottom up top down detection transformers for language grounding in images and point clouds},
  author={Jain, Ayush and Gkanatsios, Nikolaos and Mediratta, Ishita and Fragkiadaki, Katerina},
  booktitle={European Conference on Computer Vision},
  pages={417--433},
  year={2022},
  organization={Springer}
}
@inproceedings{kerr2023lerf,
  title={Lerf: Language embedded radiance fields},
  author={Kerr, Justin and Kim, Chung Min and Goldberg, Ken and Kanazawa, Angjoo and Tancik, Matthew},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={19729--19739},
  year={2023}
}
@inproceedings{Peng2023OpenScene,
      title     = {OpenScene: 3D Scene Understanding with Open Vocabularies},
      author    = {Peng, Songyou and Genova, Kyle and Jiang, Chiyu "Max" and Tagliasacchi, Andrea and Pollefeys, Marc and Funkhouser, Thomas},
      booktitle = CVPR,
      year      = {2023}
  }
@inproceedings{tschernezki2022neural,
  title={Neural feature fusion fields: 3d distillation of self-supervised 2d image representations},
  author={Tschernezki, Vadim and Laina, Iro and Larlus, Diane and Vedaldi, Andrea},
  booktitle={2022 International Conference on 3D Vision (3DV)},
  pages={443--453},
  year={2022},
  organization={IEEE}
}
@inproceedings{chen2023clip2scene,
  title={Clip2scene: Towards label-efficient 3d scene understanding by clip},
  author={Chen, Runnan and Liu, Youquan and Kong, Lingdong and Zhu, Xinge and Ma, Yuexin and Li, Yikang and Hou, Yuenan and Qiao, Yu and Wang, Wenping},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7020--7030},
  year={2023}
}
@inproceedings{ding2023pla,
  title={Pla: Language-driven open-vocabulary 3d scene understanding},
  author={Ding, Runyu and Yang, Jihan and Xue, Chuhui and Zhang, Wenqing and Bai, Song and Qi, Xiaojuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7010--7019},
  year={2023}
}
@inproceedings{
kuo2023F-VLM,
title={Open-Vocabulary Object Detection upon Frozen Vision and Language Models},
author={Weicheng Kuo and Yin Cui and Xiuye Gu and AJ Piergiovanni and Anelia Angelova},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
}

@article{yang2023regionplc,
  title={Regionplc: Regional point-language contrastive learning for open-world 3d scene understanding},
  author={Yang, Jihan and Ding, Runyu and Deng, Weipeng and Wang, Zhe and Qi, Xiaojuan},
  journal={arXiv preprint arXiv:2304.00962},
  year={2023}
}

@article{gao2024clipadapter,
  title={Clip-adapter: Better vision-language models with feature adapters},
  author={Gao, Peng and Geng, Shijie and Zhang, Renrui and Ma, Teli and Fang, Rongyao and Zhang, Yongfeng and Li, Hongsheng and Qiao, Yu},
  journal={International Journal of Computer Vision},
  volume={132},
  number={2},
  pages={581--595},
  year={2024},
  publisher={Springer}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@inproceedings{wang2022head,
  title={Head: Hetero-assists distillation for heterogeneous object detectors},
  author={Wang, Luting and Li, Xiaojie and Liao, Yue and Jiang, Zeren and Wu, Jianlong and Wang, Fei and Qian, Chen and Liu, Si},
  booktitle={European Conference on Computer Vision},
  pages={314--331},
  year={2022},
  organization={Springer}
}
@inproceedings{mirzadeh2020improved,
  title={Improved knowledge distillation via teacher assistant},
  author={Mirzadeh, Seyed Iman and Farajtabar, Mehrdad and Li, Ang and Levine, Nir and Matsukawa, Akihiro and Ghasemzadeh, Hassan},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={04},
  pages={5191--5198},
  year={2020}
}
@inproceedings{dai2021general,
  title={General instance distillation for object detection},
  author={Dai, Xing and Jiang, Zeren and Wu, Zhao and Bao, Yiping and Wang, Zhicheng and Liu, Si and Zhou, Erjin},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={7842--7851},
  year={2021}
}
@inproceedings{guo2021distilobj,
  title={Distilling object detectors via decoupled features},
  author={Guo, Jianyuan and Han, Kai and Wang, Yunhe and Wu, Han and Chen, Xinghao and Xu, Chunjing and Xu, Chang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2154--2164},
  year={2021}
}
@inproceedings{zhang2020improveod,
  title={Improve object detection with feature-based knowledge distillation: Towards accurate and efficient detectors},
  author={Zhang, Linfeng and Ma, Kaisheng},
  booktitle={International Conference on Learning Representations},
  year={2020}
}
@inproceedings{klingner2023x3kd,
  title={X3kd: Knowledge distillation across modalities, tasks and stages for multi-camera 3d object detection},
  author={Klingner, Marvin and Borse, Shubhankar and Kumar, Varun Ravi and Rezaei, Behnaz and Narayanan, Venkatraman and Yogamani, Senthil and Porikli, Fatih},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13343--13353},
  year={2023}
}
@inproceedings{liu2019structured,
  title={Structured knowledge distillation for semantic segmentation},
  author={Liu, Yifan and Chen, Ke and Liu, Chris and Qin, Zengchang and Luo, Zhenbo and Wang, Jingdong},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2604--2613},
  year={2019}
}

@inproceedings{shang2023incrementer,
  title={Incrementer: Transformer for class-incremental semantic segmentation with knowledge distillation focusing on old class},
  author={Shang, Chao and Li, Hongliang and Meng, Fanman and Wu, Qingbo and Qiu, Heqian and Wang, Lanxiao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7214--7224},
  year={2023}
}
@inproceedings{sautier2022image2lidar,
  title={Image-to-lidar self-supervised distillation for autonomous driving data},
  author={Sautier, Corentin and Puy, Gilles and Gidaris, Spyros and Boulch, Alexandre and Bursuc, Andrei and Marlet, Renaud},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9891--9901},
  year={2022}
}
@article{liu2021PPKT,
  title={Learning from 2d: Contrastive pixel-to-point knowledge transfer for 3d pretraining},
  author={Liu, Yueh-Cheng and Huang, Yu-Kai and Chiang, Hung-Yueh and Su, Hung-Ting and Liu, Zhe-Yu and Chen, Chin-Tang and Tseng, Ching-Yu and Hsu, Winston H},
  journal={arXiv preprint arXiv:2104.04687},
  year={2021}
}
@inproceedings{yan20222dpass,
  title={2dpass: 2d priors assisted semantic segmentation on lidar point clouds},
  author={Yan, Xu and Gao, Jiantao and Zheng, Chaoda and Zheng, Chao and Zhang, Ruimao and Cui, Shuguang and Li, Zhen},
  booktitle={European Conference on Computer Vision},
  pages={677--695},
  year={2022},
  organization={Springer}
}
@article{hui2022ecpnet,
  title={Efficient 3D point cloud feature learning for large-scale place recognition},
  author={Hui, Le and Cheng, Mingmei and Xie, Jin and Yang, Jian and Cheng, Ming-Ming},
  journal={IEEE Transactions on Image Processing},
  volume={31},
  pages={1258--1270},
  year={2022},
  publisher={IEEE}
}
@inproceedings{hong2022cmkd,
  title={Cross-modality knowledge distillation network for monocular 3d object detection},
  author={Hong, Yu and Dai, Hang and Ding, Yong},
  booktitle={European Conference on Computer Vision},
  pages={87--104},
  year={2022},
  organization={Springer}
}
@article{chen2022bevdistill,
  title={Bevdistill: Cross-modal bev distillation for multi-view 3d object detection},
  author={Chen, Zehui and Li, Zhenyu and Zhang, Shiquan and Fang, Liangji and Jiang, Qinhong and Zhao, Feng},
  journal={arXiv preprint arXiv:2211.09386},
  year={2022}
}
@inproceedings{zhou2023unidistill,
  title={UniDistill: A Universal Cross-Modality Knowledge Distillation Framework for 3D Object Detection in Bird's-Eye View},
  author={Zhou, Shengchao and Liu, Weizhou and Hu, Chen and Zhou, Shuchang and Ma, Chao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5116--5125},
  year={2023}
}
@inproceedings{wang2023distillbev,
  title={Distillbev: Boosting multi-camera 3d object detection with cross-modal knowledge distillation},
  author={Wang, Zeyu and Li, Dingwen and Luo, Chenxu and Xie, Cihang and Yang, Xiaodong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={8637--8646},
  year={2023}
}
@inproceedings{wang2024distilvpr,
  title={DistilVPR: Cross-Modal Knowledge Distillation for Visual Place Recognition},
  author={Wang, Sijie and She, Rui and Kang, Qiyu and Jian, Xingchao and Zhao, Kai and Song, Yang and Tay, Wee Peng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={9},
  pages={10377--10385},
  year={2024}
}

@inproceedings{ouyang2024octocc,
  title={OctOcc: High-Resolution 3D Occupancy Prediction with Octree},
  author={Ouyang, Wenzhe and Song, Xiaolin and Feng, Bailan and Xu, Zenglin},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={5},
  pages={4369--4377},
  year={2024}
}
@misc{wang2023repvit,
      title={RepViT: Revisiting Mobile CNN From ViT Perspective}, 
      author={Ao Wang and Hui Chen and Zijia Lin and Jungong Han and Guiguang Ding},
      year={2023},
      eprint={2307.09283},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{zheng2024monoocc,
  title={Monoocc: Digging into monocular semantic occupancy prediction},
  author={Zheng, Yupeng and Li, Xiang and Li, Pengfei and Zheng, Yuhang and Jin, Bu and Zhong, Chengliang and Long, Xiaoxiao and Zhao, Hao and Zhang, Qichao},
  journal={arXiv preprint arXiv:2403.08766},
  year={2024}
}
@inproceedings{wang2024h2gformer,
  title={H2gformer: Horizontal-to-global voxel transformer for 3d semantic scene completion},
  author={Wang, Yu and Tong, Chao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={6},
  pages={5722--5730},
  year={2024}
}
@inproceedings{wang2024HASSC,
  title={Not all voxels are equal: Hardness-aware semantic scene completion with self-distillation},
  author={Wang, Song and Yu, Jiawei and Li, Wentong and Liu, Wenyu and Liu, Xiaolu and Chen, Junbo and Zhu, Jianke},
  booktitle={CVPR},
  pages={14792--14801},
  year={2024}
}
@inproceedings{jiang2024symphonize,
  title={Symphonize 3d semantic scene completion with contextual instance queries},
  author={Jiang, Haoyi and Cheng, Tianheng and Gao, Naiyu and Zhang, Haoyang and Lin, Tianwei and Liu, Wenyu and Wang, Xinggang},
  booktitle={CVPR},
  pages={20258--20267},
  year={2024}
}
@InProceedings{Xia_2023_scpnet,
    author    = {Xia, Zhaoyang and Liu, Youquan and Li, Xin and Zhu, Xinge and Ma, Yuexin and Li, Yikang and Hou, Yuenan and Qiao, Yu},
    title     = {SCPNet: Semantic Scene Completion on Point Cloud},
    booktitle = {CVPR},
    month     = {June},
    year      = {2023},
    pages     = {17642-17651}
}
@inproceedings{liu2022swin3d,
  title={Video swin transformer},
  author={Liu, Ze and Ning, Jia and Cao, Yue and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Hu, Han},
  booktitle={CVPR},
  pages={3202--3211},
  year={2022}
}
@inproceedings{he2016resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  pages={770--778},
  year={2016}
}
@inproceedings{zhu2021cylindrical,
  title={Cylindrical and asymmetrical 3d convolution networks for lidar segmentation},
  author={Zhu, Xinge and Zhou, Hui and Wang, Tai and Hong, Fangzhou and Ma, Yuexin and Li, Wei and Li, Hongsheng and Lin, Dahua},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9939--9948},
  year={2021}
}
@inproceedings{xue2024bi,
  title={Bi-SSC: Geometric-Semantic Bidirectional Fusion for Camera-based 3D Semantic Scene Completion},
  author={Xue, Yujie and Li, Ruihui and Wu, Fan and Tang, Zhuo and Li, Kenli and Duan, Mingxing},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={20124--20134},
  year={2024}
}
@inproceedings{dosovitskiy2015flownet,
  title={Flownet: Learning optical flow with convolutional networks},
  author={Dosovitskiy, Alexey and Fischer, Philipp and Ilg, Eddy and Hausser, Philip and Hazirbas, Caner and Golkov, Vladimir and Van Der Smagt, Patrick and Cremers, Daniel and Brox, Thomas},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2758--2766},
  year={2015}
}
@inproceedings{teed2020raft,
  title={Raft: Recurrent all-pairs field transforms for optical flow},
  author={Teed, Zachary and Deng, Jia},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part II 16},
  pages={402--419},
  year={2020},
  organization={Springer}
}
@inproceedings{sun2018pwc,
  title={Pwc-net: Cnns for optical flow using pyramid, warping, and cost volume},
  author={Sun, Deqing and Yang, Xiaodong and Liu, Ming-Yu and Kautz, Jan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8934--8943},
  year={2018}
}
@inproceedings{xu2022gmflow,
  title={GMFlow: Learning Optical Flow via Global Matching},
  author={Xu, Haofei and Zhang, Jing and Cai, Jianfei and Rezatofighi, Hamid and Tao, Dacheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8121-8130},
  year={2022}
}
@inproceedings{zhu2017fgfa,
  title={Flow-guided feature aggregation for video object detection},
  author={Zhu, Xizhou and Wang, Yujie and Dai, Jifeng and Yuan, Lu and Wei, Yichen},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={408--417},
  year={2017}
}
@inproceedings{zhu2018flowtrack,
  title={End-to-end flow correlation tracking with spatial-temporal attention},
  author={Zhu, Zheng and Wu, Wei and Zou, Wei and Yan, Junjie},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={548--557},
  year={2018}
}
@article{wang2025mixssc,
  title={MixSSC: Forward-Backward Mixture for Vision-based 3D Semantic Scene Completion},
  author={Wang, Meng and Ding, Yan and Liu, Yumeng and Qin, Yunchuan and Li, Ruihui and Tang, Zhuo},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2025},
  publisher={IEEE}
}
@inproceedings{ilg2017flownet2,
  title={Flownet 2.0: Evolution of optical flow estimation with deep networks},
  author={Ilg, Eddy and Mayer, Nikolaus and Saikia, Tonmoy and Keuper, Margret and Dosovitskiy, Alexey and Brox, Thomas},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2462--2470},
  year={2017}
}
@InProceedings{Yuan_2024_LoSh,
    author    = {Yuan, Linfeng and Shi, Miaojing and Yue, Zijie and Chen, Qijun},
    title     = {LoSh: Long-Short Text Joint Prediction Network for Referring Video Object Segmentation},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2024},
    pages     = {14001-14010}
}
@InProceedings{Fedynyak_2024_DeVos,
    author    = {Fedynyak, Volodymyr and Romanus, Yaroslav and Hlovatskyi, Bohdan and Sydor, Bohdan and Dobosevych, Oles and Babin, Igor and Riazantsev, Roman},
    title     = {DeVos: Flow-Guided Deformable Transformer for Video Object Segmentation},
    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    month     = {January},
    year      = {2024},
    pages     = {240-249}
}
@article{sormoli2024optical,
  title={Optical Flow Based Detection and Tracking of Moving Objects for Autonomous Vehicles},
  author={Sormoli, Mohammadreza Alipour and Dianati, Mehrdad and Mozaffari, Sajjad and Woodman, Roger},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  year={2024},
  publisher={IEEE}
}
@inproceedings{meister2018unflow,
  title={Unflow: Unsupervised learning of optical flow with a bidirectional census loss},
  author={Meister, Simon and Hur, Junhwa and Roth, Stefan},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}
@inproceedings{sundaram2010dense,
  title={Dense point trajectories by gpu-accelerated large displacement optical flow},
  author={Sundaram, Narayanan and Brox, Thomas and Keutzer, Kurt},
  booktitle={European conference on computer vision},
  pages={438--451},
  year={2010},
  organization={Springer}
}
@inproceedings{luo2018cosine,
  title={Cosine normalization: Using cosine similarity instead of dot product in neural networks},
  author={Luo, Chunjie and Zhan, Jianfeng and Xue, Xiaohe and Wang, Lei and Ren, Rui and Yang, Qiang},
  booktitle={Artificial Neural Networks and Machine Learning--ICANN 2018: 27th International Conference on Artificial Neural Networks, Rhodes, Greece, October 4-7, 2018, Proceedings, Part I 27},
  pages={382--391},
  year={2018},
  organization={Springer}
}
@inproceedings{CGFormer,
  title={Context and Geometry Aware Voxel Transformer for Semantic Scene Completion},
  author={Yu, Zhu and Zhang, Runmin and Ying, Jiacheng and Yu, Junchen and Hu, Xiaohai and Luo, Lun and Cao, Si-Yuan and Shen, Hui-Liang},
  booktitle = {Advances in Neural Information Processing Systems},
  year={2024}
}
@inproceedings{li2024htcl,
  title={Hierarchical temporal context learning for camera-based semantic scene completion},
  author={Li, Bohan and Deng, Jiajun and Zhang, Wenyao and Liang, Zhujin and Du, Dalong and Jin, Xin and Zeng, Wenjun},
  booktitle={European Conference on Computer Vision},
  pages={131--148},
  year={2024},
  organization={Springer}
}
@article{mei2024sgn,
  title={Camera-based 3d semantic scene completion with sparse guidance network},
  author={Mei, Jianbiao and Yang, Yu and Wang, Mengmeng and Zhu, Junyu and Ra, Jongwon and Ma, Yukai and Li, Laijian and Liu, Yong},
  journal={IEEE Transactions on Image Processing},
  year={2024},
  publisher={IEEE}
}
@inproceedings{huang2022flowformer,
  title={Flowformer: A transformer architecture for optical flow},
  author={Huang, Zhaoyang and Shi, Xiaoyu and Zhang, Chao and Wang, Qiang and Cheung, Ka Chun and Qin, Hongwei and Dai, Jifeng and Li, Hongsheng},
  booktitle={European conference on computer vision},
  pages={668--685},
  year={2022},
  organization={Springer}
}