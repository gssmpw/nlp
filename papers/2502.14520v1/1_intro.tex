\section{Introduction}
 \label{sec:intro}
One of the key challenges in autonomous driving is 3D scene understanding, which involves interpreting the spatial layout and semantic properties of objects within the scene. The ability to perceive and accurately interpret 3D scenes is essential for making safe and informed driving decisions. Recently, the 3D Semantic Scene Completion (SSC) task~\cite{song2017semantic,roldao2020lmscnet} has gained significant attention in autonomous driving, as it enables the joint inference of geometry and semantics from incomplete observations.

Most existing SSC methods~\cite{rist2021semantic,zhang2018efficient,guo2018view,li2020aicnet,roldao2020lmscnet,yan2021sparse} rely on input RGB images along with corresponding 3D data to predict volume occupancy and assign semantic labels. However, the dependence on 3D data often requires specialized and costly depth sensors, which can limit the broader applicability of SSC algorithms. Recently, many researchers~\cite{cao2022monoscene,zhang2023occformer,li2023stereoscene,huang2023tri} have investigated camera-based approaches to reconstruct dense 3D geometric structures and recover semantic information, offering a more accessible alternative.

Previous camera-based SSC methods~\cite{jiang2024symphonize,CGFormer,li2023stereoscene} typically rely on the limited observations available in the current frame to recover 3D geometry and semantics. Later, some researchers~\cite{li2023voxformer,li2024htcl,mei2024sgn,wang2024HASSC} stacked historical temporal features or aligned features with estimated camera poses to enrich contextual information, as shown in Figure~\ref{fig:figure2}(a). However, these direct temporal modeling methods overlook the scene motion context, fail to achieve temporal consistency, and inherently limit the increase of effective contextual cues. Based on these limitations, we asked: \textbf{\textit{How can we accurately identify the correlation between historical frames and the current frame to guide temporal SSC modeling?}}

% -------------------------------------------------

In this paper, we propose a novel temporal SSC method: FlowScene, Learning Temporal 3D Semantic Scene Completion via Optical Flow Guidance. As shown in Figure~\ref{fig:figure2}(b), FlowScene uses optical flow to guide temporal modeling, injecting various types of information into the SSC model, such as motion, different viewpoints, deformation, texture, geometric structure, lighting, and occlusion. As shown in Figure~\ref{fig:figure1}, the corresponding optical flow and occlusion masks are generated from the historical and current frame images, allowing for the further derivation of scene geometry and semantic structure. The positions and semantics of the car, tree trunk, vegetation, and pole within the red box in Figure~\ref{fig:figure1} are more accurate, even when they are mutually occluded.
Specifically, we introduce the \textit{Flow-Guided Temporal Aggregation} module to effectively enhance temporal and motion cues by incorporating motion and contextual information from previous frames. Furthermore, we design the \textit{Occlusion-Guided Voxel Refinement} module, which leverages aggregated features and occlusion masks to refine 3D voxel predictions for explicit geometric modeling.
To evaluate the performance of FlowScene, we conduct thorough experiments on SemanticKITTI~\cite{behley2019semantickitti} and SSCBench-KITTI360~\cite{Liao2022kitti360,li2023sscbench}. Our method achieves state-of-the-art performance. The main contributions of our work are summarized as follows:
\begin{itemize}
    \item We introduce FlowScene, a novel approach to 3D SSC that incorporates optical flow guidance to capture and model temporal and spatial dependencies across frames. 
    \item We propose the flow-guided temporal aggregation module, which effectively enhances temporal and motion cues by incorporating motion and contextual information from previous frames.
    \item We design the occlusion-guided voxel refinement module, which leverages aggregated features and occlusion masks to refine 3D voxel predictions, enabling explicit geometric modeling and improving the accuracy of scene reconstruction in occluded regions.
    \item We evaluate FlowScene on the SemanticKITTI and SSCBench-KITTI-360 benchmarks, achieving state-of-the-art performance. Our method surpasses the latest methods in both semantic and geometric analysis, demonstrating the effectiveness of optical flow-guided temporal modeling in SSC tasks.
\end{itemize}
% -------------------------------------------------
\begin{figure}[t]
\begin{center}
% \fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
   \includegraphics[width=\linewidth]{figure2.pdf}
\end{center}
   \caption{Our method uses optical flow guide temporal SSC versus the previous temporal SSC method.}
\label{fig:figure2}
\end{figure}
% -------------------------------------------------