% -------------------------------------------------
\begin{figure*}[t]
\centering
  \includegraphics[width=0.95\textwidth]{figure6.pdf}
  \caption{Qualitative results on the SemanticKITTI validation set.}
  \label{fig:figure6}
\end{figure*}
% -------------------------------------------------


\section{Experiments}
To assess the effectiveness of our FlowScene, we conducted thorough experiments using the large outdoor datasets SemanticKITTI~\cite{behley2019semantickitti,Geiger2012kitti}, SSCBench-KITTI-360~\cite{li2023sscbench,Liao2022kitti360}.
\subsection{Experimental Setup}
\paragraph{Datasets.} 
The SemanticKITTI\cite{behley2019semantickitti, Geiger2012kitti} dataset includes dense semantic scene completion annotations and labels a voxelized scene with 20 semantic classes. It consists of 10 training sequences, 1 validation sequence, and 11 testing sequences. RGB images are resized to $1280\times384$ for input processing.
The SSCBench-KITTI-360\cite{li2023sscbench, Liao2022kitti360} dataset contains 7 training sequences, 1 validation sequence, and 1 testing sequence, covering 19 semantic classes in total. The RGB images are resized to $1408\times384$ for input processing.
\vspace{-5mm}
\paragraph{Metrics.} We use intersection over union (IoU) to evaluate the scene completion performance. To assess the effectiveness of our 3D Semantic Scene Completion method, we focus on the mean IoU (mIoU). A higher IoU value reflects accurate geometric predictions, while a higher mIoU value indicates more precise semantic segmentation.
\vspace{-5mm}
\paragraph{Implementation Details.} 
We use RepVit~\cite{wang2023repvit} and FPN~\cite{lin2017feature} to extract features for all images (The number of historical temporal frames n is set to 2).
We use and freeze the GMFlow~\cite{xu2022gmflow} optical flow estimation model to obtain optical flow information.
We use the LSS paradigm for 2D-3D projection. The neighborhood cross-attention range is set to 7, and the number of attention heads is set to 8. Finally, the final outputs of SemantiKITTI is 20 classes, and SSCBench-KITTI-360 is 19 classes. All datasets have the scene size of $51.2m \times 51.2m \times 64m$ with the voxel grid size of $256 \times 256 \times 32$. By default, the model is trained for 25 epochs. We optimise the process, utilizing the AdamW optimizer with an initial learning rate of 1e-4 and a weight decay of 0.01. We also employ a multi-step scheduler to reduce the learning rate. All models are trained on two A100 Nvidia GPUs with 80G memory and batch size 4.

\subsection{Main Results}
\vspace{-4mm}
\paragraph{Quantitative Results.}
As shown in Table~\ref{tab:Test Quantitative Comparison}, we compare FlowScene with the latest public methods on the SemanticKITTI dataset, including approaches that use single-image input (S) and temporal image input (T). Temporal methods, such as VoxFormer~\cite{li2023voxformer}, H2GFormer~\cite{wang2024h2gformer}, HASSC~\cite{wang2024HASSC}, and SGN~\cite{mei2024sgn}, utilize additional historical 5-frame input, while HTCL~\cite{li2024htcl} uses a 3-frame historical input. In contrast, FlowScene uses only 2 historical frames as input, achieving the highest mIoU for the overall semantic metric and the highest IoU for the completion metric.
Compared to the best-performing HTCL with temporal input, FlowScene improves the mIoU and IoU by 0.61\% and 0.97\%, respectively. When compared to the best CGFormer, which uses single-frame input, FlowScene achieves improvements of 1.07\% in mIoU and 0.79\% in IoU. Additionally, our method achieves the best or second-best results in most categories, outperforming or closely matching other methods. These results demonstrate the superiority of FlowScene in both geometry and semantics, effectively utilizing optical flow motion information and achieving temporal consistency.
%-----------------------------------------
\begin{table}[t]
  % \renewcommand\arraystretch{1.2}
  \centering
  \small
% \setlength{\tabcolsep}{3pt}
  \begin{tabular}{l|l|ccc}
    \toprule
    \multirow{2}{*}{\textbf{Methods}}  & \multirow{2}{*}{\textbf{Venues}}& & \textbf{mIoU(\%)} &  \\
    & &12.8m &25.6m & 51.2m  \\
    \midrule
    MonoScene  & CVPR'2022&12.25& 12.22& 11.30\\
    VoxFormer-T& CVPR'2023 & 21.55& 18.42 &13.35\\
    OccFormer& ICCV'2023 & 20.91& 17.90& 13.46\\
    HASSC-T& CVPR'2024& 24.10 &20.27 &14.74\\
    H2GFormer-T& AAAI'2024 & 23.43& 20.37& 14.29 \\
    BRGScene& IJCAI'2024 & 23.27& 21.15& 15.24\\
    SGN-T&TIP'2024&25.70 &22.02& 15.32\\
    \rowcolor{gray!20}\textbf{Ours} & &  \textbf{27.63}& \textbf{24.65}& \textbf{18.13}\\
    \bottomrule
  \end{tabular} 
\caption{Comparison of different ranges on SemanticKITTI validation set.}
  \label{tab:diff range}
  \vspace{-5mm}
\end{table}
%--------------------------------
Due to the rich data samples and high-quality annotations in the SSCBench-KITTI-360 dataset, FlowScene outperforms current camera-based methods in both semantic and geometric analysis on the comprehensive SSCBench-KITTI-360 benchmark, as shown in Table~\ref{tab:KITTI360Test Quantitative Comparison}. Our method achieves superior results in terms of both IoU and mIoU, surpassing all existing approaches.

Moreover, Table~\ref{tab:diff range} illustrates the performance of FlowScene across three distance ranges (12.5m, 25.6m, 51.2m) on the SemanticKITTI validation set. It is evident that our approach significantly outperforms state-of-the-art methods at every tested distance.

Furthermore, as shown in Table~\ref{tab:cost}, we compare the inference time and number of parameters of our method with other state-of-the-art methods on the SemanticKITTI validation set. FlowScene achieves state-of-the-art performance with a mIoU of 18.13\%, while utilizing only 52.4M parameters. Additionally, FlowScene processes the extra 2-frame temporal image input with lower inference time, further demonstrating its efficiency and superior mIoU performance.
\vspace{-5mm}
%--------------------------------
\begin{table}[t]
  \centering\small
\setlength{\tabcolsep}{4pt}{
  \begin{tabular}{l|c|ccc}
    \toprule
    {\textbf{Method}}&\textbf{Input}& {\textbf{mIoU}(\%)}&\textbf{Times(s)}&\textbf{Params(M)} \\
    \midrule
    MonoScene& T&12.96&\textbf{0.281}&132.4\\
    OccFormer&T& {13.58}&0.338&203.4 \\
    VoxFormer&T& {13.35}&0.307&57.9 \\
    Symphonize&S& {14.89}&0.319&59.3 \\
    BRGScene&S& {15.43}&0.285&161.4 \\
    HTCL&T& {17.13}&0.297&181.4 \\
    \rowcolor{gray!20}{Ours}&T&{\textbf{18.13}}&0.301&\textbf{52.4} \\
    \bottomrule
  \end{tabular}
  }
      \caption{Comparison of inference time and number of parameters.}
  \label{tab:cost}
  \vspace{-5mm}
\end{table}
%-------------------------------------------------------------
\begin{table*}[t]
\centering\small

% \setlength{\tabcolsep}{3pt}
  \begin{tabular}{c|cc|cc|ccc|ccc}
    \toprule
     \multirow{2}{*}{\textbf{Variants}}& \multicolumn{2}{c|}{\textbf{OFE}} &\multicolumn{2}{c|}{\textbf{FGTA}} &   \multicolumn{3}{c|}{\textbf{OGVR}} & \multirow{2}{*}{\textbf{IoU(\%)}} & \multirow{2}{*}{\textbf{mIoU(\%)}}& \multirow{2}{*}{\textbf{Params(M)}} \\
     &FGW&OD&TA&{OCA}&$\operatorname{V_t}$ &$\operatorname{V_{agg}}$ &$\operatorname{V_{mask}}$&&&\\

    \midrule
      Baseline&{}& {}&{}& {} & {} & {} &{} &  {43.98} & {15.89}&47.4\\
      
     1&{\checkmark}& {}&{}& {} & {} & {} &{} &  {44.13} & {16.21}&52.1 \\
     
     2&{\checkmark}& {\checkmark}&{}& {\checkmark} & {\checkmark} & {} &{} &  {44.38} & {16.43}&52.2 \\
     
     3&{\checkmark}& {\checkmark}&{}& {} & {\checkmark} & {\checkmark} &{\checkmark} &  {44.56} & {16.67}&52.1 \\
     
     4&{\checkmark}& {\checkmark} & {\checkmark}&{}& {\checkmark} & {\checkmark} &{\checkmark} &  {44.63} & {17.23}&52.3 \\
     
     5&{\checkmark}& {\checkmark}&{}& {\checkmark} & {\checkmark} & {\checkmark} &{\checkmark} &  {44.42} & {17.08}&52.3 \\
     
     6&{\checkmark}& {\checkmark} & {\checkmark}&{\checkmark}& {\checkmark} & {} & {} & {44.68} & {17.18}&52.4 \\
     
     7&{\checkmark}&{\checkmark }&{\checkmark}& {\checkmark} & {\checkmark} & {\checkmark} &{}& {{44.72}} &{{17.63}}&{52.4} \\
     
     \rowcolor{gray!20}8&{\checkmark}&{\checkmark }&{\checkmark}& {\checkmark} & {\checkmark} & {\checkmark} &{\checkmark}& {\textbf{45.01}} &{\textbf{18.13}}&{52.4} \\
     
    \bottomrule
\end{tabular}
  
  \caption{Ablation study for Architecture Components on SemanticKITTI validation set. OFE: Optical Flow Estimation; FGTA: Flow-Guided Temporal Aggregation; OGVR: Occlusion-Guided Voxel Refinement; FGW: Flow-Guided Warping; OD: Occlusion Detection; TA: Temporal Aggregation; OCA: Occlusion Cross-Attention; $\operatorname{V_t}$: reference voxel features; $ \operatorname{V_{agg}}$: aggregation voxel features; $ \operatorname{V_{mask}}$: voxel occlusion mask.}
  \label{tab:architecture}
  \vspace{-5mm}
\end{table*}
%------------------------------------------------------------
%--------------------------------
%-----------------------------------------
\begin{table}[t]
  % \renewcommand\arraystretch{1.2}
  \centering
  \small
\setlength{\tabcolsep}{5pt}
  \begin{tabular}{ccccc|ccc}
    \toprule
    \multicolumn{5}{c|}{\textbf{ Temporal Inputs}}&\multirow{2}{*}{\textbf{IoU(\%)}}  & \multirow{2}{*}{\textbf{mIoU(\%)}} &\multirow{2}{*}{\textbf{Times(s)}}\\
    t-1&t-2 &t-3 &t-4 &t-5&&  \\
    \midrule
    {\checkmark}& {} & {}&{}& {} & {44.63} & {17.74}&0.290\\
    \rowcolor{gray!20}{\checkmark}& {\checkmark} & {}&{}& {} & {45.01} & {18.13}& {0.301}\\
    {\checkmark}& {\checkmark} & {\checkmark}&{}& {} & {44.72} & {18.30}& {0.314}\\
    {\checkmark}& {\checkmark} & {\checkmark}&{\checkmark}& {} & {44.66} & {17.68}& {0.328}\\
    {\checkmark}& {\checkmark} & {\checkmark}&{\checkmark}& {\checkmark} & {44.53} & {17.55}& {0.344}\\
    \bottomrule
  \end{tabular} 
\caption{Ablation study of the different number of temporal inputs on the SemanticKITTI validation set.}
  \label{tab:input}
  \vspace{-5mm}
\end{table}
%--------------------------------
% \vspace{-4mm}
\paragraph{Qualitative Visualizations.}
To intuitively demonstrate the performance of FlowScene, Figure~\ref{fig:figure6} presents qualitative results for VoxFormer-T, BRGScene, and our method on the SemanticKITTI validation set.
The first column displays the input reference image and the corresponding optical flow. It is evident that optical flow is particularly sensitive to the perception of moving objects, such as cars and cyclists.
Compared to BRGScene, our method more effectively captures the location and details of mutually occluded objects in the scene (e.g., the arrangement of multiple cars in the second row).
In comparison to VoxFormer-T, FlowScene maintains better temporal consistency, as shown by the car parked on the roadside in the blue box in the third row.
Overall, our method demonstrates superior geometric and semantic visualization.

\subsection{Ablation Studies}
We conduct extensive ablation experiments for FlowScene on the Semantickitti validation set. Specifically, we analyze the impact of different architecture component variations and temporal input in Table~\ref{tab:input} and Table~\ref{tab:architecture}.
% \vspace{-4mm}
\paragraph{Optical Flow Estimation (OFE).}
The baseline model removes all components, using only the current image and two frames of historical images as input. After passing through the image encoder, all features are stacked together. Variant 1 in Table~\ref{tab:architecture} uses Flow-Guided Warping to align the temporal features to the reference moment, achieving a 0.32\% mIoU improvement (Variant 1 vs. Baseline).
Additionally, Variant 2 incorporates Occlusion Detection to obtain an occlusion mask, which guides the interaction of non-occluded areas in the 2D feature space, boosting the mIoU score by 0.22\% (Variant 2 vs. Variant 1).

% \vspace{-4mm}

\paragraph{Flow-Guided Temporal Aggregation (FGTA).}
Variants 3, 4, and 5 represent different configurations of the FGTA module: removing the FGTA module (Variant 3), removing the Occlusion Cross-Attention (Variant 4), and removing the Temporal Aggregation component (Variant 5). Variant 4 adaptively assigns weights to aggregate historical features, resulting in a 0.56\% mIoU improvement (Variant 4 vs. Variant 3). Variant 5 uses Occlusion Cross-Attention to facilitate interaction between the current feature and the non-occluded areas in the historical frame, enhancing the texture and contextual information of the current frame's features, further boosting the mIoU by 0.41\% (Variant 5 vs. Variant 3).

% \vspace{-4mm}

\paragraph{Occlusion-Guided Voxel Refinement (OGVR).}
Variant 6 represents the removal of the OGVR module, while Variant 7 uses convolution fusion to concatenate $V_t$ and $V_{agg}$. Even with this simple fusion strategy, a 0.45\% mIoU improvement is achieved (Variant 7 vs. Variant 6). Variant 8 represents our final full model. Compared to Variant 7, the mask-based refinement strategy further improves the mIoU metric. It is worth noting that the OGVR module incurs no additional parameter overhead. Overall, compared to the baseline, our method achieves significant improvements in both completion and semantic metrics (+2.24\% mIoU, +1.03\% IoU).

% \vspace{-4mm}

\paragraph{Temporal Inputs.}
As shown in Table~\ref{tab:input}, we evaluate the performance of temporal inputs with different numbers of frames. We observe that, as the number of frames increases, the time overhead also increases. However, the mIoU metric does not increase linearly, as the optical flow estimation model is less effective when the time interval between frames is long. As a result, inputs with 4 or 5 frames (t-4 and t-5) lead to reduced effectiveness. Considering both the experimental metrics and the time overhead, we use 2 frames as the input for our FlowScene method.

\section{Conclusion}
In this paper, we propose a novel temporal SSC method FlowScene. Specifically, we introduce a Flow-Guided Temporal Aggregation module that aligns and aggregates temporal features using optical flow, capturing motion-aware context and deformable structures. In addition, we design an Occlusion-Guided Voxel Refinement module that injects occlusion masks and temporally aggregated features into 3D voxel space, adaptively refining voxel representations for explicit geometric modeling.
Experimental results demonstrate that FlowScene achieves SOTA performance on the SemanticKITTI and SSCBench-KITTI-360 benchmarks.