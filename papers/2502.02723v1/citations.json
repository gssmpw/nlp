[
  {
    "index": 0,
    "papers": [
      {
        "key": "sparsegpt",
        "author": "Frantar, Elias and Alistarh, Dan",
        "title": "Sparsegpt: Massive language models can be accurately pruned in one-shot"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "llmpruner",
        "author": "Ma, Xinyin and Fang, Gongfan and Wang, Xinchao",
        "title": "Llm-pruner: On the structural pruning of large language models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "ShearedLlama",
        "author": "Xia, Mengzhou and Gao, Tianyu and Zeng, Zhiyuan and Chen, Danqi",
        "title": "Sheared llama: Accelerating language model pre-training via structured pruning"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "gptq",
        "author": "Frantar, Elias and Ashkboos, Saleh and Hoefler, Torsten and Alistarh, Dan",
        "title": "Gptq: Accurate post-training quantization for generative pre-trained transformers"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "3",
        "author": "Jaderberg, Max and Vedaldi, Andrea and Zisserman, Andrew",
        "title": "Speeding up convolutional neural networks with low rank expansions"
      },
      {
        "key": "4",
        "author": "Zhang, Xiangyu and Zou, Jianhua and He, Kaiming and Sun, Jian",
        "title": "Accelerating very deep convolutional networks for classification and detection"
      },
      {
        "key": "5",
        "author": "Denton, Emily L and Zaremba, Wojciech and Bruna, Joan and LeCun, Yann and Fergus, Rob",
        "title": "Exploiting linear structure within convolutional networks for efficient evaluation"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "1",
        "author": "Chen, Patrick and Si, Si and Li, Yang and Chelba, Ciprian and Hsieh, Cho-Jui",
        "title": "Groupreduce: Block-wise low-rank approximation for neural language model shrinking"
      },
      {
        "key": "2",
        "author": "Acharya, Anish and Goel, Rahul and Metallinou, Angeliki and Dhillon, Inderjit",
        "title": "Online embedding compression for text classification using low rank matrix factorization"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "6",
        "author": "Hsu, Yen-Chang and Hua, Ting and Chang, Sungen and Lou, Qian and Shen, Yilin and Jin, Hongxia",
        "title": "Language model compression with weighted low-rank factorization"
      },
      {
        "key": "7",
        "author": "Wang, Hongyi and Agarwal, Saurabh and Papailiopoulos, Dimitris",
        "title": "Pufferfish: Communication-efficient models at no extra cost"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "truth",
        "author": "Sharma, Pratyusha and Ash, Jordan T and Misra, Dipendra",
        "title": "The truth is in there: Improving reasoning in language models with layer-selective rank reduction"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "lowrank_1",
        "author": "Zhang, Cheng and Cheng, Jianyi and Constantinides, George A and Zhao, Yiren",
        "title": "LQER: Low-Rank Quantization Error Reconstruction for LLMs"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "lowrank_3",
        "author": "Lee, Jung Hyun and Kim, Jeonghoon and Yang, June Yong and Kwon, Se Jung and Yang, Eunho and Yoo, Kang Min and Lee, Dongsoo",
        "title": "Lrq: Optimizing post-training quantization for large language models by learning low-rank weight-scaling matrices"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "lowrank_4",
        "author": "Saha, Rajarshi and Sagan, Naomi and Srivastava, Varun and Goldsmith, Andrea J and Pilanci, Mert",
        "title": "Compressing Large Language Models using Low Rank and Low Precision Decomposition"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "lowrank_2",
        "author": "Saha, Rajarshi and Srivastava, Varun and Pilanci, Mert",
        "title": "Matrix compression via randomized low rank and low precision factorization"
      }
    ]
  }
]