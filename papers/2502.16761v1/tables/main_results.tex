
\begin{table*}[ht]
    \centering
    \scriptsize
    \caption{
    Evaluation on OpinionQA and the \OURDATA evaluation set (\OURDATA-Eval) for 22 subpopulations following ~\cite{santurkar2023whose}.
    We compute the WD by averaging over all questions and subpopulations.
    Lower and upper bounds of performance give guidance on how each method performs.
    For Modular Pluralism, we provide an error rate of one-hot prediction ($\dag$) (\Cref{section_method_evaluation_metric}) which was used in the original paper.
    }
    \label{table:main_results}
    \resizebox{1.0\textwidth}{!}{%
    \begin{tabular}{l|cccc|cccc}
    \toprule
     \multirow{2}{*}{Method} & \multicolumn{4}{c|}{\textbf{OpinionQA}}
     & \multicolumn{4}{c}{\textbf{\OURDATA-Eval}} \\
    & \textbf{Llama-2-7B} & \textbf{Llama-2-13B} & \textbf{Mistral-7B} & \textbf{Llama-3-70B}
    & \textbf{Llama-2-7B} & \textbf{Llama-2-13B} & \textbf{Mistral-7B} & \textbf{Llama-3-70B} \\
    \midrule
    Upper bound (Unif.) & \multicolumn{4}{c|}{0.178} & \multicolumn{4}{c}{0.208} \\
    Lower bound (Human) & \multicolumn{4}{c|}{0.031} & \multicolumn{4}{c}{0.033} \\
    \midrule
    Zero-shot prompt (\texttt{QA}) & 0.173 & 0.170 & 0.153 & 0.138 & 0.206 & 0.196 & 0.187 & 0.160 \\
    Zero-shot prompt (\texttt{BIO}) & 0.193 & 0.183 & 0.162 & 0.143 & 0.221 & 0.212 & 0.202 & 0.175 \\
    Zero-shot prompt (\texttt{PORTRAY})  & 0.195 & 0.207 & 0.158 & 0.209 & 0.212 & 0.242 & 0.194 & 0.247 \\
    Few-shot prompt  & 0.186 & 0.175 & 0.174 & 0.166 & 0.217   & 0.194   & 0.175 & 0.182   \\
    Modular Pluralism & \multicolumn{4}{c|}{0.285 ($^\dag$55.6\%)} & \multicolumn{4}{c}{0.279 ($^\dag$55.2\%)}   \\
    \highlightrow Ours (\OURDATA-FT) &  0.106 &  0.102 &  0.096 &  0.094 &  0.121 & 0.113 &  0.115 &  0.096 \\
    \bottomrule
    \end{tabular}
    }
\vspace{5pt}
\end{table*}
