\section{Baseline Details}
\label{appendix_baseline_detail}

\begin{itemize}[leftmargin=*]
    \item \textbf{Zero-shot prompting}:
    Three prompt styles—\texttt{QA}, \texttt{BIO}, and \texttt{PORTRAY}—are introduced in~\cite{santurkar2023whose} to integrate group information into prompts.
    These prompts are then combined with survey questions to construct inputs for LLM.
    Then, the first-token log-probability from LLM is measured to calculate the model's response distribution over options.
    In our baseline (and also in fine-tuning experiments) we focus on the \texttt{QA} steering format.
    Examples of this prompting method are shown in \Cref{fig:baseline_qa_example}.
    \item \textbf{Few-shot prompting}: 
    We craft a conditioning prompt that contains not only group information
    but also the group's response distribution to \textit{k} train questions,
    following \cite{hwang2023aligning}.
    For a test question $q_{test} \in Q_{test}$,
    we first sort training questions $Q_{train}$ into $\{q_1, q_2, ...\}$
    such that $\texttt{sim}(\texttt{E}(q_1), \texttt{E}(q_{test}))
    > \texttt{sim}(\texttt{E}(q_2), \texttt{E}(q_{test}))$, and so on.
    $\texttt{E}(q)$ denotes the embedding model (OpenAI-text-embedding-3-large) output
    of the input $q$ and
    \texttt{sim} is a cosine similarity between two embedding vectors. 
    Then, response information of the first $k$ questions $\{q_i, p(\mathcal{A}_{q_i}|q_i, g)\}_{i=1}^{k}$ are used as few shot prompts to have the language model verbalize \cite{meister2024benchmarking} expected response distribution for the given $g$ and $q_{test}$.
    An example of the prompt for $k=3$ case is shown in Figure \ref{fig:fewshot_example},
    while we run the baseline experiment in a $k=5$ setting. 
    
    \item \textbf{Modular Pluralism}:
    The intuition behind Modular Pluralism \cite{feng-etal-2024-modular} is that
    a language model trained on a text corpus of a specific subpopulation will faithfully
    represent public opinion of that population.
    Given a survey question with a \texttt{PORTRAY}-style steering prompt,
    each of language model `modules' (fine-tuned Mistral-7B-Instruct-v0.1)
    generates an option choice with explanation.
    A black-box LLM (GPT-3.5-turbo-Instruct) receives all generations and select a generation that best aligns with the given group. Finally, using the chosen generation as a context, a black-box LLM generates probability distribution over options.
    The example pipeline is shown in Figure \ref{fig:modular_pluralism_example}.
    Instead of the sub-sampled OpinionQA dataset the authors of the method used, we use the exactly same evaluation set across all baseline methods and our approach for a fair comparison.

    \item \textbf{Upper bound}:
    We estimate the distribution between human responses and uniform distribution as an upper bound of WD metrics.
    
    \item \textbf{Lower bound}: We compute a lower bound by randomly sampling a group of respondents and calculating the Wasserstein distance (WD) between the distribution of the sampled group and that of the original respondents for each question. We then bootstrap with $R = 1000$ to construct a 95\% confidence interval (CI) for the WDs. Further details on this estimation process are provided below.

    \paragraph{Computing weighted answer distributions:}
    For each group $g$ and question $q$, we have $n_{gq}$ responses from respondents who belong to group $g$ answering question $q$: $x_1, x_2, \cdots, x_{n_{gq}}$, where $x_i \in \mathcal{A}_q$, i.e., the answer set for question $q$ (e.g., $\{1, 2, 3, 4\}$). 
    Furthermore, each respondent (and thus, their response) is associated with a wave-specific weight $w_1, w_2, \cdots, w_{n_{gq}}$, provided by Pew Research.
    We compute the human answer distribution $\pi_{gq}^{(H)}$ as a weighted sum over responses, where the proportion of respondents providing answer $a \in \mathcal{A}_q$ is estimated as
    \begin{align*}
        \pi_{gq}^{(H)}(a) = \frac{\sum_{i=1}^{n_{gq}} w_i \mathbbm{1}[x_i = a]}{\sum_{i=1}^{n_{gq}} w_i}. \label{eqn:human-weighted-dist}
    \end{align*}


    \paragraph{Bootstrapping at the respondent-level:}
    We draw bootstrap samples per group at the respondent-level including questions from all survey waves.
    This allows us to capture correlations in answer distributions across questions and across waves.
    
    Specifically, let $\mathcal{P}_{g}$ represent the set of respondents in group $g$, where $|\mathcal{P}_{g}| = n_{g}$.
    We produce bootstrapped samples by repeatedly sampling $n_{g}$ respondents from $\mathcal{P}_{g}$ with replacement.
    Let $p_1^{(r)}, p_2^{(r)}, \cdots, p_{n_{g}}^{(r)}$ represent the sampled respondents for the $r$-th bootstrap, and let $w_{1}^{(r)}, w_{2}^{(r)}, \cdots, w_{n_{g}}^{(r)}$ represent their corresponding weights.
    
    For each question $q$, let $\mathcal{P}_{gq} \subseteq \mathcal{P}_{g}$ represent the set of respondents from group $g$ who answered question $q$; as before, $|\mathcal{P}_{gq}| = n_{gq}$.
    Let us define $q(p_i)$ as person $p_i$'s response to question $q$ if $p_i$ answered question $q$, i.e., $p_i \in \mathcal{P}_{gq}$, and 0 otherwise.
    Then, we compute the $r$-th answer distribution to question $q$ as:
    \begin{align*}
        \pi_{gq}^{(r)}(a) = \frac{\sum_{i=1}^{n_{g}} \mathbbm{1}[p_i^{(r)} \in \mathcal{P}_{gq}] w_i^{(r)} \mathbbm{1}[q(p_i^{(r)}) = a]}{\sum_{i=1}^{n_{g}} \mathbbm{1}[p_i^{(r)} \in \mathcal{P}_{gq}] w_i^{(r)}}.
    \end{align*}


    \paragraph{Human lower bound of WD.}
    Our statistic of interest is the mean Wasserstein distance over all questions $Q$ across all waves per group. We approximate this as the WD between the observed human distribution $\pi_{gq}^{(H)}$ and the bootstrap sample $\pi_{gq}^{(r)}$ for question $q$ and group $g$.
    Over all $R=1000$ bootstraps, we have

\begin{align*}
    \mathcal{D}_{g}^{(H)} &= \left\{\frac{1}{|Q|}\sum_{q \in Q} WD(\pi_{gq}^{(H)}, \pi_{gq}^{(r)})\right\}_{r=1}^R.
\end{align*}
To quantify agreement between human samples, we report the mean and 95\% CI (i.e., from $2.5^{th}$ to $97.5^{th}$ percentiles) of $\mathcal{D}_{gq}^{(H)}$.
    
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[!t]
    \captionsetup{font=small}
    \includegraphics[width=\linewidth]{figures/appendix_qa_example1.pdf}
    \includegraphics[width=\linewidth]{figures/appendix_qa_example2.pdf}
    \caption{
    Two examples of Zero-shot prompting in the \texttt{QA} format \cite{santurkar2023whose}.
    Subpopulation's information (colored in pink) is concatenated with
    survey question (colored in sky blue).
    The first-token log-probability (probabilities assigned to A, B, C, ...)
    are used to calculate language model's response distribution.
    The same steering prompt format is used in our fine-tuning experiment.
    }
    \label{fig:baseline_qa_example}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[!t]
    \captionsetup{font=small}
    \includegraphics[width=\linewidth]{figures/appendix_fewshot_example.pdf}
    \caption{
        Few-shot prompting example for $k=3$.
        Group information is presented in the beginning of the prompt (colored in pink).
        Following group information, $k$ questions whose text embedding are the most similar to the text embedding of the evaluation question (colored in sky blue)
        are presented along with their opinion distribution.
        $k$ questions are presented in the ascending order of cosine similarity.
        The generation of language model (verbalization of opinion distribution)
        is parsed to obtain the response distribution.
    }
    \label{fig:fewshot_example}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[!t]
    \captionsetup{font=small}
    \includegraphics[width=\linewidth]{figures/appendix_modular_1.pdf}
    \includegraphics[width=\linewidth]{figures/appendix_modular_2.pdf}
    \includegraphics[width=\linewidth]{figures/appendix_modular_3.pdf}
    \caption{
    Pipeline example of Modular Pluralism.
    Given a demographic group and a survey question, the first prompt is asked to
    multiple (6) language models, Mistral-7B-v0.1-Instruct fine-tuned on the community text corpus.
    The generations are sent to a black-box LLM (gpt-3.5-0613-Instruct) in the format of the second prompt.
    The black-box LLM answers which one of generations best reflects the given demographics.
    Finally, the selected generation serves as a context to answer the given survey question
    and the black-box LLM is prompted (the third prompt) to generate response distribution
    over the answer token A, B, C, etc.
    }
    \label{fig:modular_pluralism_example}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%