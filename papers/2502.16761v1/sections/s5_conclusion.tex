\section{Conclusion}
\vspace{-10pt}
In this work, we demonstrated that fine-tuning large language models on structured public opinion survey data markedly improves their ability to predict human response distributions. 
We curate \OURDATA—a dataset 6.5× larger than previous collections to fine-tune and evaluate LLMs on survey response distribution prediction task.
By fine-tuning on \OURDATA, we showed that LLMs can capture the nuanced, group-specific variability in public opinions, while also generalizing to unseen subpopulations, survey waves and question topics, and different survey families. 
Fine-tuning achieves consistent improvements across subpopulations of varying sizes, and our experiments demonstrate that fine-tuned LLMs are indeed \textit{adapting} their responses to the subpopulation specified in the prompt, even for subpopulations unseen during fine-tuning. 
Finally, our experiments also reveal that as the fine-tuning dataset grows, model performance continues to scale favorably, underscoring the value of our larger dataset. 

Generalization is a critical capability for LLMs, if they are to be used to assist public opinion research, as researchers are most in need of accurate opinion predictions for questions or subpopulations whom they have not surveyed before.
Our work, by greatly improving LLMs' ability to accurately predict opinions with fine-tuning and demonstrating strong generalization to out-of-distribution data, moves us closer towards the goal of leveraging LLMs for opinion prediction.
However, many open questions remain: 
why is the model able to generalize well to unseen subpopulations and questions, and under what conditions might it fail to do so?
How do we ensure that LLMs faithfully capture opinions along other dimensions that are not explored in this work, such as intersections of demographic identities or changing opinions over time? 
How should LLMs be integrated into survey designs, to serve as tools that can complement large-scale surveys with human participants? 
Answering these questions will require interdisciplinary collaborations with domain experts and critical assessments of LLMs' and traditional survey methods' strengths and weaknesses, so that we can most effectively and responsibly combine them to better estimate public opinions and inform public policies.