
\NewDocumentCommand\emojiplus{}{
    \scalerel*{
        \includegraphics{emojis/plus.png}
    }{X}
}

\NewDocumentCommand\emojiinfo{}{
    \scalerel*{
        \includegraphics{emojis/info.png}
    }{X}
}

\NewDocumentCommand\emojipeople{}{
    \scalerel*{
        \includegraphics{emojis/people.png}
    }{X}
}

\NewDocumentCommand\emojitool{}{
    \scalerel*{
        \includegraphics{emojis/tool.png}
    }{X}
}

\newcommand{\positiveOpp}[1]{\emojiplus #1}
\newcommand{\challengeOpp}[1]{\emojiinfo #1}
\newcommand{\technicalOpp}[1]{\emojitool #1}
\newcommand{\recommendationOpp}[1]{\emojipeople #1}

To complement the categorization of standards by criticality levels in Section~\ref{sec:framework}, we provide an extensive discussion of the technical aspects that make the process of aligning GenAI models with standards both challenging and promising, and highlight the advantages that standards can introduce to existing GenAI-based systems
%, which will be crucial for even wider adoption in the future.
%Likewise, the discussions in this section can also serve as potential directions for researchers interested in aligning and benchmarking GenAI models for standards compliance tasks.

\subsection{Complexities of Standards}
\textbf{\challengeOpp{Standards Are Living Documents}} Standards can be considered as \textit{living documents} where their contents can be revised, changed, or updated at any point in time by their developers. SDOs typically perform periodic reviews of their standards (5 in the case of ISO), which are driven by factors such as industry changes, the introduction of new methods or products, and significant technological advances in the field \cite{eetimes_when_standards_change, bsigroup_standards_terminology}. Other forms of standards we consider in this work, such as organizational policies and guidelines, can be updated as needed. As such, architectures for standard-aligned GenAI model pipelines should be designed to adapt dynamically, accommodating both minor and major changes in a standard's specifications for compliance-based tasks. A good example of this is ISO/IEC 22989:2022, where new AI-related terminologies and concepts (e.g., \textit{AI agent}) are added to the list, including their recognized definitions as research in the field progresses \cite{iso_22989_2022}.

\textbf{\challengeOpp{Standards Are Specifications-Driven}} The core DNA of standards is its technical specifications, which detail precise descriptions of the inputs and outputs of products being measured and the expected behaviors of processes. This approach parallels established engineering disciplines, where clear, non-ambiguous specifications enable the development of modular and robust systems 
\cite{weber1986specification,stoica2024specifications}. The quantity of specifications that make up a complete standard depends on the standard's complexity. The challenge for GenAI models is to learn these specifications and apply them dynamically or on an as-needed basis. Moreover, showing which specifications have been used by the GenAI model to generate content or check for compliance can fulfill regulatory demands for transparency and improve user trust 
\cite{ehsan2019automated,wei2022chain,liu2023increasing}. 

\textbf{\challengeOpp{Standards Have Limited Reference Data}} The clarity and level of information needed by domain experts in interpreting input and output requirements and learning from a few standard-compliant examples may not be equivalent to what GenAI models require. This limitation may pose challenges when automating compliance or conformity assessment using GenAI models. Some standards, especially those focusing on prescribed semantic and syntactic information, such as MLCommons' AILuminate Standard for assessing safety responses of LLMs \cite{mlcommons_ailuminate} or the NHS Standard for creating health-related content \cite{nhs_health_content_standard}, may have specifications where only a few conforming examples (typically 2-3) are provided. For cases like these, researchers often need to conduct their own data collection from external resources or perform synthetic data generation to increase the gold-standard reference data for compliance-based tasks, which may entail additional costs. These practices have been explored in previous works on using GenAI for compliance assessment concerning the HIPAA Privacy Rule and GDPR Documentation Standard \cite{colombo2024saullm,zoubi-etal-2024-privat5,fan-etal-2024-goldcoin}. 

\textbf{\challengeOpp{Standards Depend on Domain Knowledge Expertise}} Standards developed by experts in fields such as healthcare, science, and engineering require domain knowledge to interpret how their specifications and constraints can be applied to domain-specific processes or activities that require compliance. Baseline GenAI models are often trained with massive collections of web-scraped internet data combined with scaling techniques from which it can learn generic, jack-of-all-trades knowledge required for most tasks \cite{chung2024scaling,chowdhery2023palm}. LLMs, in particular, often demonstrate better performance than their baseline counterparts in domain-specific tasks when further finetuned or optimized with additional curated datasets that provide deeper domain knowledge. \cite{chen2023meditron}. This can be evidenced by previous works such as the Meditron-70B model, where they finetuned a Llama-70B with 40K clinical medical standards and guidelines from online healthcare websites and over 16M medical abstracts and papers from PubMed and PubCentral, which obtained higher performance across medical QA tasks than other closed and open-weight LLMs \cite{chen2023meditron}. This static finetuning of large models may be effective only for well-established standards that will not be updated for a substantial amount of time but may not be suited for standards, policies, or guidelines that are inherently dynamic and flexible. 

\textbf{\challengeOpp{Standards Require Strong Expert-Level Evaluation}} Perhaps one of the most important aspects of aligning GenAI with standards for compliance tasks is how we evaluate such alignment in terms of accuracy and practical usability. As discussed in Section~\ref{sec:paradigm_shift}, conformity assessments with standards can be a variable process depending on the level of compliance required for inputs and on how protocols work across different domains and sectors. Thus, the process of evaluation for standard compliance tasks should anchor to an agile, use-case basis that targets specific output requirements rather than adopting a one-size-fits-all approach \cite{khanzada2024conformity}. Ultimately, domain experts in standards should already be involved even at the conceptualization stage of GenAI-based workflows related to standard compliance to help identify plausible evaluation metrics to improve reliability and usability in real-world settings.


\subsection{Advantages and Benefits of Aligning GenAI with Standards}

\textbf{\positiveOpp{Standard Alignment Can Enhance Quality and Interoperability}} GenAI models are often controlled through various experimental means, such as different forms of structured prompting \cite{brown2020language,shin-etal-2020-autoprompt,wei2022chain}, finetuning \cite{weifinetuned2022,zhang2023adding,chowdhery2023palm}, and preference optimization \cite{ziegler2019fine,ouyang2022training,rafailov2024direct}, which have shown effectiveness across various tasks and domains. In line with this, standards can serve as a \textit{reference of control} for these models to generate and refine their outputs based on the standard's specifications, as done in recent works on education and language proficiency assessment \cite{imperial-etal-2024-standardize} and safe response generation using company policies \cite{guan2024deliberative}. Likewise, in relation to the emerging body of work with GenAI-based agents, aligning them with standards to produce an interconnected ecosystem can enable enhanced interoperability between inputs and outputs, thus improving efficiency, transparency, and the production of quality-controlled content.

\textbf{\positiveOpp{Standard Alignment Can Improve Oversight, Transparency, and Auditing}} In high-stakes domains, human oversight of any AI-based system or interface is crucial for transparency and auditing 
\cite{bowman2022measuring,kentonscalable}. As such, controlling how GenAI models produce outputs by updating the specifications of standards and being able to trace back deviations through these changes will be extremely valuable in areas such as bias mitigation \cite{gallegos2024bias}, fairness evaluations 
\cite{teo2024measuring}, and domain-specific tasks related to healthcare, finance, and legal decision-making 
\cite{bowman2022measuring,mesko2023imperative,mokander2023auditing}. Likewise, this form of oversight achieved by controlling with standards can also be scaled through \textit{superalignment}\footnote{First coined by OpenAI: \url{https://openai.com/index/introducing-superalignment/}} where a smaller GenAI teacher model specializing in a particular standard can regulate larger student models while exploiting its enhanced instruction-following capabilities \cite{burns2024weak,guo2024vision}. 

\textbf{\positiveOpp{Standard Alignment Can Strengthen User Trust}} Building user trust is considered one of the most elusive challenges in the design of AI-based systems, as it can dictate the lifeline of how these systems will be adopted and used \cite{riegelsberger2005mechanics,kizilcec2016much,schmidt2020transparency}. Bridging the same rules and regulations that domain experts follow, in the form of standards to control GenAI models, can potentially enhance process-based user trust. For example, a medical expert may feel much more confident in using a specialized open model like Meditron \cite{chen2023meditron} to complete or assist with their tasks than in using a black-box general-purpose model, simply from knowing that the former has undergone further training using massive collections of clinical guidelines and medical papers with which the expert is familiar. This level of transparency given to domain experts can be highly beneficial for earning and strengthening user trust, as it assures them of certainties in the performance expectations and design of standard-aligned GenAI models \cite{kizilcec2016much}.

%\textbf{\positiveOpp{Standard Alignment Can Improve Decision Transparency and Auditing}}

\textbf{\positiveOpp{Standard Alignment Can Reduce Risk of Inaccuracies}}  
The results of the State of AI in 2024 survey conducted by McKinsey revealed that \textit{inaccuracy}---the tendency of GenAI models to produce factually incorrect and unexpected results---as one of the highest risk factors hindering adoption across major organizations and industries. Such risks can cause a domino effect, including losing user trust, potential physical or mental harm, and financial losses for both consumers and businesses if not properly mitigated and controlled \cite{mckinsey2024stateofai}. In line with this, the standard alignment of GenAI models can contribute to reducing inaccuracies by pairing it with architectural enhancements such as scaling and finetuning with massive collections of domain-specific data to improve domain knowledge, as evidenced in previous works on education \cite{imperial-tayyar-madabushi-2023-flesch,imperial-etal-2024-standardize}, legal \cite{zhu2024legilm,fan-etal-2024-goldcoin}, and medicine \cite{chen2023meditron}. Additionally, businesses can also use standard alignment as proof that their services conform to domain-specific regulations, thereby providing quality assurance to clients and consumers.