
A \textbf{paradigm shift} occurs when a dominant standard practice becomes incompatible due to some emerging technological phenomena, facilitating the adoption of new forms of conceptualization, practices, or paradigms \cite{kuhn1970nature, tapscott1994paradigm}. The current state-of-the-art GenAI models are known to exhibit remarkable capabilities across a wide range of generative tasks. In particular, one of the most useful and powerful skills a model can learn is the ability to \textit{follow complex human instructions} from prompts \cite{weifinetuned2022,ouyang2022training,chung2024scaling}. Standards are composed of technical specifications which, at their core, can also be considered a set of instructions. As such, it was not long until users and practitioners knowledgeable of standards in their specific domains and sectors started exploring and reframing these specifications as instructional prompts for GenAI models (e.g., GPT-4) to assist with compliance-based tasks. We consider this phenomenon as an \textit{{emerging paradigm shift}} in standards and regulatory compliance, as shown in Figure~\ref{fig:paradigm-shift}. This paradigm shift is introduced by the rise of instruction and preference-optimized GenAI models that can follow specifications derived from standards through well-structured prompting techniques and domain-specific fine-tuning.

% Current state-of-the-art GenAI models are known to exhibit remarkable capabilities across a wide range of generative tasks. In particular, one of the most useful and powerful skills a model can learn is the ability to follow complex instructions and constraints from prompts. This capability can be attributed to several factors that researchers have prioritized, including larger model scaling, using massive datasets for pretraining and finetuning, and applying complex post-training optimization techniques to capture human preferences \cite{weifinetuned2022,ouyang2022training,chung2024scaling}.

In this section, we further discuss specific cases from the literature in relation to the paradigm shift observed in two major aspects: 1) \textbf{conformity assessment} practices with standards and 2) \textbf{generating standard-aligned content} across various domains and sectors.

\subsection{Shift in Standard Conformity Assessment}
Conformity assessment, in relation to standards, pertains to how implementing organizations and users measure the level to which their products or services meet the requirements of the standard itself. This process is often formally known as \textit{certification} and is extremely variable and dependent on several factors, including the level of conformity required by the standard and common assessment norms in specific domains or sectors  \cite{iso_conformity_assessment}. For some standards-driven sectors such as pharmaceuticals, automotive, and energy industries, certifications are a legal or contractual requirement. For non-regulatory and operational standards, certifications are less common, and conformity can often be assessed through various means, including using third-party evaluator software, hiring trained expert evaluators, or self-assessment by learning the standards from publications or documentation releases. We highlight notable works across various domains in automating conformity assessment with GenAI below:

\noindent \textbf{Data Privacy Laws}. Well-known data privacy laws such as the General Data Protection Regulation (GDPR)\footnote{\url{https://gdpr-info.eu/}} \cite{regulation2016regulation} for the EU and the Health Insurance Portability and Accountability Act (HIPAA)\footnote{\url{https://www.hhs.gov/hipaa/index.html}} \cite{act1996health} for the US have served as common ground for optimizing GenAI models in terms of compliance checking due to the availability of data. \citet{fan-etal-2024-goldcoin} proposed the GoldCoin framework, which leverages contextual integrity theory to build synthetic case scenarios showing compliance and violations of the HIPAA Privacy Rule. The works of \citet{zoubi-etal-2024-privat5} and \citet{zhu2024legilm} introduced PrivT5 and LegiLM, new specialized finetuned models trained from compilations of GDPR-related legal content such as case laws and data-sharing contracts and reported state-of-the-art performance in legal compliance tasks in NLP. 

\noindent \textbf{Financial and Accounting Report Standards}. 
The International Financial Reporting Standards (IFRS) provides a standardized method of evaluating a company's financial performance for compliance across national and international regulations \cite{posner2010sequence}. Auditing financial documents for compliance is considered labor-intensive, and the exploration of AI-driven solutions has been evident in recent years \cite{albuquerque2024exploring}. The work of \citet{berger2023towards} in collaboration with PwC Germany reported the effectiveness of GPT-4 for compliance validation of text sections from financial reports concerning IFRS and Germany's Handelsgesetzbuch or Commercial Code (HGB) through template-based prompting while noting the need for a major improvement in robustness before deploying to real-world scenarios.

\noindent \textbf{Operational Design Standards for Driving Autonomous Systems}. Beyond text-based applications, GenAI models have also been explored and have shown promising results for compliance assessment in multimodal settings. The work of \citet{hildebrandt2024odd} examined the use of OpenAI's ChatGPT-4V \cite{openai_gpt4v_system_card} and Vicuna \cite{chiang2023vicuna} integrated in a pipeline called ODD-diLLMma to check the compliance of compiled sensor image data from self-driving cars with respect to Operational Design Domains (ODDs). ODDs are documented standards provided by manufacturers (e.g., Tesla or GMC) describing specific conditions under which a self-driving car may operate safely and within its designed function (e.g., \textit{vehicle must not be driven at night}). The proposed \textsc{ODD-diLLMma} pipeline is considered the first to automate the compliance checking of ODDs using multimodal LLMs with high accuracy between \~85\%-94\% across 11 weather, environment, and roadway characteristic dimensions.

\subsection{Shift in Standard-Aligned Content Generation}
Automatically generating text- or image-based content that adheres to a specific set of detailed specifications is considered a challenging task, even for AI-based models. State-of-the-art language models like GPT-4 can be prompted to create content using seed topics in which specific syntactic and semantic characteristics can be directed 
\cite{pu-demberg-2023-chatgpt,zhou2023controlled}. Vision-based and multimodal models have also demonstrated the same level of controllability through prompting, particularly in models like DALL-E \cite{betker2023improving} and Stable Diffusion \cite{rombach2022high}. This degree of controllability via simple interactions through a chat interface, which can easily be utilized by users, has been pivotal to the applications of these models across various domains and sectors. We emphasize previous studies that focused on improving GenAI models' capabilities to automatically generate content that conforms to the standards below:


\noindent \textbf{Education and Language Proficiency Frameworks}.
Content-based standards serve as a meter to ensure that classroom resources, such as reading and activity books, meet certain research-based quality criteria \cite{la2000state,sadler2017academic}. An example of a content standard is the Common European Framework of Reference for Languages (CEFR), which is one of the most used resources for automatic educational content generation tasks using LLMs. The combined recent works of \citet{imperial-etal-2024-standardize}, \citet{malik-etal-2024-tarzan}, and  \citet{glandorf-meurers-2024-towards} have all explored a wide range of LLMs, including Llama, GPT-4, and Mistral, using specifications from CEFR in prompts to steer for desired granularities, including target complexity, grammar rules and structure, and levels of meaning. Experts in language testing using CEFR in \citet{imperial-etal-2024-standardize} have also given positive feedback on how GPT-4 can achieve a certain level of completeness, fluency, and coherence in generated texts.

\noindent \textbf{Medical Reporting and Appraisal Standards}.
High-quality documentation and appraisal in the medical literature are driven by checklists and reporting standards. \citet{sanmarchi2024step} explored ChatGPT's capabilities to reformulate the STROBE checklist \cite{von2007strengthening} to analyze epidemiology studies related to COVID-19 vaccinations in 68 countries. The results of the study support ChatGPT's potential as an assistant in setting up epidemiological observational research but caution against its tendency to produce inconsistent responses when analyzing methods. In the same vein, \citet{muluk2024enhancing} also used ChatGPT for customizing checklists related to managing patient-specific musculoskeletal injections that also conform to the METRICS standard \cite{sallam2024preliminary}. The study echoed the considerable potential of GenAI models like ChatGPT for streamlining easily verifiable aspects in clinical practices, such as preparing medical checklists, but emphasized the importance of expert oversight.

\noindent \textbf{Industry Safety Policies}.
Recent works have explored integrating industry safety policies into GenAI models to improve their capability to generate content that adheres to these specifications. An example of this is the Deliberative Alignment training paradigm used in OpenAI's \textsc{o}-series model \cite{guan2024deliberative}. In this method, LLMs are optimized to interpret the company's safety specifications and reason over them when responding to potentially harmful prompts. Another advantage of this method is that the models have been optimized to identify which policy specifications might be relevant to produce a compliant response, rather than going through the full copy of the policy at every iteration. Likewise, the work of \citet{zhang2024controllable} also observes a similar approach to safety policy alignment but focuses on controlling the levels of safety by retraining models across different providers (e.g., \textit{safety policies for generating realistic dialogues for video games can be relaxed to allow cursing}).

%Businesses, firms, and other industry entities often have in-house standards and policies that serve as resources for ensuring the quality delivery of products and services. Technology-based companies like OpenAI and Google, which offer access to content-generating tools, use advanced filtering techniques and safety policies to ensure access to their models is not used beyond terms of service, such as following malicious instructions and generating toxic content \cite{vidgen2023simplesafetytests,rottger-etal-2024-xstest,vidgen2024introducing}. 

