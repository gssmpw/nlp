
\begin{figure}[!t]
    \centering
    \includegraphics[width=0.99\linewidth]{fig/framework.pdf}
    %\vspace{-0.8em}
    \caption{\textbf{The \textsc{Criticality and Compliance Capabilities Framework (C3F)}.} We introduce a joint framework for assessing the current state-of-the-art foundational and specialized text and image-based GenAI models based on their (\textbf{Top}) documented \textit{compliance capabilities} for generating content that aligns with standards, as well as (\textbf{Bottom}) the estimated \textit{criticality} of standards from various domains and sectors based on the permissible error level a GenAI model can commit and the potential consequences in the case of non-compliance.}
    \label{fig:framework}
    %\vspace{-0.60cm}
\end{figure}

The level of sensitivity and compliance requirements vary by standard and depend on its purpose and scope (see discussion on compliance in Section~\ref{sec:paradigm_shift}). For example, coding standards such as Python Enhancement Proposals (PEP) are less sensitive and critical than healthcare standards like the HIPAA Privacy Rule. Thus, for researchers exploring areas using GenAI as an assistant with compliance-based tasks, it is important to know \textit{both} the documented capabilities of the GenAI models they plan to use for experiments \textit{and} the target level of standard compliance they use as a benchmark for success or failure. To bridge this gap, we propose \textsc{C3F}, a joint \textsc{Criticality and Compliance Capabilities Framework} in Figure~\ref{fig:framework} to classify the current capabilities of modern GenAI models to follow compliance with standards as well as assess the different levels of criticality of standards across domains and sectors. We provide a more in-depth discussion of the two components of \textsc{C3F} in the succeeding sections.

\subsection{Classification of GenAI by Documented Compliance Capabilities}

We define {\textbf{compliance capabilities}} as an aggregation of a GenAI model's documented capabilities for compliance-based tasks across various publications and recognition from the interdisciplinary community. For \textsc{C3F}, we propose a four-level assessment scheme to measure a GenAI model's compliance capabilities in an increasing linear fashion as seen in Figure~\ref{fig:framework}. 
%We find a similar and closely comparable pattern in skill assessment of GenAI models from works such as \citet{morrisposition} for levels of AGI and \citet{pmlr-v235-eiras24b} for risks and openness. 

\noindent \textbf{Compliance Capabilities Grading Scheme}. For the \baseline level, we consider GenAI models that have been instruction-tuned as a \textit{minimum qualification skill} for assessing compliance capabilities since the core nature of standards is to conform to their specifications. Instruction-tuned GenAI models (particularly LLMs) can pick up generic domain knowledge from the massive datasets often used for pretraining and additional output optimizations through instruction tuning and preference optimization. This is particularly evident from tasks such as code generation \cite{siddiq2023lightweight,beer2024examination} and health-related checklists \cite{sanmarchi2024step,muluk2024enhancing}. Succeeding levels, including Specialized and Advanced, require further evidence of domain knowledge expertise that outperforms Baseline-level models. GenAI models classified as \specialized are typically those that have been additionally fine-tuned with domain-specific gold-standard datasets such as clinical guidelines \cite{chen2023meditron} and examples of regulatory compliant documents \cite{fan-etal-2024-goldcoin}. On the other hand, \advanced GenAI models are those that can be considered equal to domain experts for the task of standard compliance while also being capable of justifying or reasoning over decisions with constraints from standards. Lastly, we consider \adaptive as the final level a GenAI model can obtain, which should exhibit the highest form of capability via generalization of multiple expert-level knowledge across domains. No existing GenAI model is currently classified under this level.

\noindent \textbf{Assessment}. We used the compliance capabilities component of \textsc{C3F} to assess 15 foundational and specialized GenAI models both for text and image as shown in Table~\ref{tab:model_classification} in Appendix~\ref{app:framework_tables} which includes information on their respective domains (in the case of Specialized models) and accessibility. We note that only the o-series models (o1 and o3) from OpenAI have been documented to exhibit the required capabilities to be classified under the Advanced category, as evidenced by their Deliberative Alignment study, which shows how LLMs can be trained to reason and select which applicable specifications from safety policies should be used to generate a safe response \cite{guan2024deliberative}. Recently released models, such as DeepSeek-R1 \cite{deepseek2025}, are currently classified as Baseline and can be updated upon publication of literature documenting if their compliance capabilities can quality for the Advanced level.

\noindent \textbf{Observation}. We highlight two complementing observational points---(1) domain knowledge dependency and (2) model development complexity---in the compliance capabilities of the framework (reflected as two green gradient arrows in Figure~\ref{fig:framework}). The first point, \textit{domain knowledge dependency}, describes a direct relationship between the documented compliance capabilities of GenAI models and their evidenced domain knowledge. This is a straightforward observation as Specialized (and higher level) models will typically outperform their Baseline versions for domain-specific compliance tasks. The second point, \textit{model development complexity}, reflects a similar direct relationship where higher compliance capabilities of GenAI models demands increasing complexity and costly data curation and training procedures. As a consequence, AI-based companies with higher financial resources such as Google, Meta, and OpenAI typically lead the development of more compute-heavy models.


\subsection{Classification of Standards by Criticality Levels}

We define the \textbf{criticality levels} of standards as a measure of their sensitivity, which can be determined by the allowable margin of error for a hypothetical GenAI model assisting with standard compliance tasks. For \textsc{C3F}, in parallel with compliance capabilities, we also propose a similar four-level assessment scheme illustrating the reduction of allowable errors as the criticality of standards increases as shown in Figure~\ref{fig:framework}. 

\noindent \textbf{Criticality Level Grading Scheme}. We consider \minimal criticality level as the least sensitive and can be used for GenAI-based experiments without requiring in-depth domain knowledge or expert oversight. Non-compliance can also be easily detected with existing rule-based software. This includes standards such as coding conventions (e.g., Python Enhancement Proposals) or writing and formatting guidelines (e.g., Plain Language, SMILES in Chemistry). For \moderate, there are potential risks associated with non-compliance but they can easily be managed and corrected by human experts. Examples in this category include most non-regulatory standards, standards with variations across domains, and standards developed by independent, private-sector organizations primarily used for interoperability, such as PRISMA for reporting systematic review papers and IFRS Accounting Standards in finance. Standards classified under  \high are those that require high levels of accuracy and may pose significant consequences in case of non-compliance. Most patient-facing healthcare standards classified in this category include the SPIRIT Checklist, which is used for transparency of clinical trial protocols; GDPR and HIPAA for data protection and privacy; and the USDA Food Safety Documentation. Lastly, the highest criticality level a standard can be classified as is \extreme, which is reserved for situations with zero margin of error allowed, and non-compliance may result in catastrophic and potentially irreversible consequences. This includes standards under the chemical, biological, radiological, and nuclear (CBRN) umbrella, such as the Safety Standards developed by the International Atomic Energy Agency and the Joint Operating Principles for Emergency Services, which pertain to documenting CBRN-related emergency responses. Such a high degree of sensitivity and criticality is necessary to include, as works on GenAI, particularly LLMs, are already gaining research attention and preliminary works \cite{de2024classification,hirata2024generative}.

\noindent \textbf{Assessment}. We used the standard criticality level component of \textsc{C3F} to assess 34 globally recognized standards (including guidelines, checklists, and policies) from a wide range of domains and sectors. While the level of compliance with a certain standard can be deduced by reading its respective documentation and release reports, collecting the opinions of domain experts can justify its classification based on criticality from \textsc{C3F}, which is a normal practice in the conventional standards development process shown in Figure~\ref{fig:standard-hierarchy} in Appendix~\ref{app:framework_tables}. In assessing the standards, we consider two things: the \textit{consequences of harm} and the \textit{scale of harm}. The former describes the level of potential damage that non-compliance with standards can trigger, while the latter considers the number of people who might be harmed by an error caused by non-compliance. For example, an error in a patient-facing scenario in healthcare might endanger one person, but an error in a nuclear energy scenario might endanger or kill thousands. Both can lead potentially to death, but the scale varies between the two. For standards classified under the domains of healthcare and engineering in Table~\ref{tab:standards_classification}, we conversed with two practitioners from our university network who have experience using the standard and obtained their assessments based on \textsc{C3F}.

\noindent \textbf{Observation}. We also highlight two observational points---(1) ideal margin of error and (2) dependence on human expert oversight---in terms of criticality levels proposed in the framework (reflected as two red gradient lines). In this case, however, the two points are opposites. The \textit{ideal margin of error} should decrease from low to zero as criticality levels increase, particularly for standards rated High and Extreme, to avoid the potential consequences of non-compliance. The \textit{dependence on human expert oversight}, on the other hand, is directly proportional and should increase from occasional (for Minimal criticality) to required (for High and Extreme) as criticality levels also increase.

