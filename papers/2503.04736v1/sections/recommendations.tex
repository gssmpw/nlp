

At this stage, we outline the potential risks and key responsibilities of each stakeholder group involved in the development of standards and advancement of GenAI and provide recommendations to align with the evolving practices in standard compliance.

\textbf{\recommendationOpp{For Government and Regulatory Bodies}} Regulations established by governing bodies can be considered one of the major drivers of standard development (see Section~\ref{sec:background}). However, two of the main concerns with regulations are the \textit{risk of rigid standardization} which may compromise innovation efforts and hinder or slow down the beneficial applications of AI \cite{aghion2023impact}, and the \textit{risk of regulatory gaps} due to vague stipulations and the unrealistic technical feasibility of legislations \cite{pouget2023}. To address these, we recommend periodic \textit{regulatory and policy adaptation} to revisit existing regulations and critically discuss how GenAI's evolving role impacts compliance practices with these regulations. Likewise, legislation aimed at developing a unified \textit{meta-standard} can also be enacted to assist professional regulatory bodies in effectively updating their professional guidelines for specific workforces that will experience major job augmentations with the use of GenAI (e.g., physicians now using GenAI to support clinical decision-making for patients in the UK), in order to uphold ethical principles and ensure human oversight \cite{Hashem2024}. Lastly, since the challenge of regulatory compliance through standards is closely tied to advanced research on GenAI, we propose ongoing research funding for academic and industry partners to promote scientific advancements in accountability, responsibility, and transparency of GenAI.


\textbf{\recommendationOpp{For SDOs, Industry, and Academic Expert Groups}} Rethinking the conventional standard development process (see Figure~\ref{fig:standard-hierarchy}) due to the shift in compliance practices with GenAI might be a major but necessary step for SDOs, industry associations, and academic expert groups. This is important to prevent the regulatory authority of technical standards from the \textit{risk of being uninformative} for users wanting clear guidelines for standard compliance amid the progress of GenAI. We recommend establishing a dedicated committee responsible for updating and initiating maintenance revisions of existing published standards. These domain-specific committees can conduct their own studies and collaborate with other stakeholders to \textit{closely monitor current practices, available tools, and limitations} in using GenAI for standard compliance \cite{manheim2024necessity}.  Similarly, to boost advancements in GenAI research with standard compliance, we recommend open-sourcing machine-readable format of standards along with producing gold-standard compliant data for the research community.

\textbf{\recommendationOpp{For GenAI Researchers and Model Developers}} When an AI model is deployed in critical high-risk domains such as healthcare, legal, or engineering safety, it is the responsibility of researchers and developers to propose explainability techniques to interpret model outcomes. This aspect of GenAI research is important to avoid the \textit{risk of eroding trust} among domain users who will use this technology. Thus, we recommend using standard compliance as an impactful case study of \textit{explaining} the black-box nature of GenAI models. Since standards can be considered as co-regulation tools, developing novel approaches such as automatic audit trail generation for decisions made by standard-aligned GenAI and providing human-readable explanations is vital for its wider interdisciplinary adoption \cite{mokander2023auditing, song2019auditing}. In addition, we also recommend that researchers collaborate with domain experts and explore using standards and regulatory documents as \textit{references for control} for content generation tasks. This research direction will contribute to realistic applications of the capabilities of GenAI where the task of standard compliance with documents can be added to LLM benchmark evaluation suites such as HELM \cite{liang2023holistic}, ChatBot Arena \cite{chiang2023chatbot}, and BIG-Bench \cite{srivastava2023beyond}. 

\textbf{\recommendationOpp{For Regulated Entities, Practitioners, and Users}} The final stakeholder group that will experience the greatest impact from GenAI are the regulated entities, practitioners, and users. Our most important recommendation is to practice and uphold the highest form of responsibility and accountability in using GenAI to comply with regulatory and operational requirements \cite{coeckelbergh2020artificial}. Professionals in regulated fields do not need to understand the full technical inner workings of GenAI. However, to reduce the \textit{risk of misuse and over-reliance}, they should remain knowledgeable about the limitations of any GenAI model, including its tendency to produce inaccurate responses and exhibit limited domain expertise. Thus, we strongly recommend establishing a \textit{solid, domain-specific foundation of AI literacy}, which is expected of an ideal professional who knows how to work with and maximize the potential of these intelligent tools. Finally, we recommend close collaboration with all stakeholders in the standard development process while providing feedback to enhance the overall usability and experience of standard compliance with GenAI models.