
While we emphasized and supported our position in the previous sections, we present two main alternative views that we consider equally valid and necessary to ensure a healthy discussion in this emerging new research direction. 

\textbf{Aligning GenAI for Compliance May Be Superficial} GenAI can produce non-factual, hallucinated responses if it lacks sufficient domain knowledge for various tasks. Deploying GenAI-based assistants, particularly those classified below the Adaptive level in compliance capabilities in \textsc{C3F}, is not realistic since AI often struggles with \textit{very specific edge cases and context-dependent ambiguities} that only experienced domain experts can realistically resolve. In response to this, we believe GenAI is \textit{not} intended to take a significant portion of work from domain experts, but rather, to act as \textit{first-line assistants} in managing automatic, repetitive preliminary tasks, thereby allowing domain experts to focus other parts of their work. We emphasize that maintaining \textit{human oversight} is crucial for any AI-based workflow, as indicated in the critical levels assessment of standards in \textsc{C3F}. Using GenAI as first-line assistants is also viable for standard-compliance tasks requiring generating content that conforms to specific writing conventions (e.g., ASD-STE Simplified Technical English \cite{asd-ste100-issue9,imperial-tayyar-madabushi-2024-specialex}) and can be easily verified with rule-based software. 

\textbf{Aligning GenAI for Compliance Creates False Sense of Security} Optimizing GenAI to follow rigid standards might result in users and practitioners being too \textit{overreliant} on these systems. Even if users are domain experts themselves, they can subjected to a \textit{false notion of security} from an over-confident model, which might lead to reduced human vigilance and possibly cause major to catastrophic errors from non-compliance. In response to this, we acknowledge that \textit{trust is a multifaceted concept}, particularly for AI systems \cite{papenmeier2022s}. As discussed in Section~\ref{sec:recommendations}, our position on aligning GenAI with standards entails the need for strong collaborative efforts across all stakeholders in designing \textit{user-centric approaches}. This recommendation is crucial as it enables regulated entities, practitioners, and users to actively engage in the \textit{process of standard alignment} for GenAI models, where they will understand the importance of human oversight and accountability in using these systems and the potential risks of overreliance.

