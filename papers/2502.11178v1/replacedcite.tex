\section{Related Work}
% \textbf{Unsupervised Domain Adaptation.} Unsupervised domain adaptation (UDA) aims to train a model for a target domain that lacks labeled data by leveraging labeled data from a source domain. UDA has shown significant success, especially when integrated with deep neural networks. There are two primary strategies in this field. The first focuses on reducing the domain gap through discrepancy-based methods, often employing metrics such as maximum mean discrepancy (MMD) to minimize domain discrepancies ____. The second approach, adversarial domain adaptation, treats the task as a min-max optimization problem where a domain classifier helps align the source and target domain distributions ____. In addition, generative models such as CycleGAN ____ have been applied to image-level domain adaptation. However, domain adaptation for object detection is more complex because the model needs to predict both bounding boxes and object classes, making it more challenging than general vision tasks. To overcome these challenges, several methods ____ have been introduced to learn features that bridge the domain gap. Recently, consensus regularization ____, a technique borrowed from semi-supervised learning, has gained traction in domain adaptation. This approach involves using multiple classifiers with varied initializations, where the disagreement between their output measures domain divergence. For example, ____ reduces the classifier disagreement while diversifying the feature embeddings, and ____ iteratively adjusts this disagreement to improve adaptation. Building on this, ____ employs the Wasserstein metric to analyze prediction dissimilarities, while ____ expands these ideas to multiclass settings. These methods have been successfully applied in tasks such as semantic segmentation ____ and keypoint detection ____.

\textbf{Domain Adaptive Object Detection.} Domain adaptive object detection (DAOD) bridges the gap between training and testing domains using techniques like style transfer, self-labeling, and domain alignment. Many methods, such as Chen et al. ____ and Saito et al. ____, employ adversarial learning to align feature distributions at different levels. While effective, these approaches rely on both source and target data, limiting their applicability to single-domain generalizable object detection (Single-DGOD). Recent works refine feature alignment strategies, as seen in SWDA ____ and HTCN ____, but often compromise detector discriminability by entangling adaptation with training. Unlike prior methods, we enhance transfer learning through adversarial hard example mining and domain-level metric regularization, improving robustness without adding complexity or extra parameters.

\textbf{Mamba.} Mamba has significantly influenced vision applications, inspiring various adaptations. Vim ____ employed a bidirectional state-space model (SSM) to enhance spatial understanding but suffered from high computational costs and global context loss. In contrast, MambaVision introduces a streamlined forward pass and redesigned Mamba block, improving efficiency and surpassing Vim in accuracy and throughput. EfficientVMamba ____ combined atrous-based selective scanning with CNN-SSM hierarchies for global dependencies, while MambaVision optimizes this by using CNNs for high-resolution features and self-attention for fine-grained details, achieving superior performance. VMamba ____ proposed a Cross-Scan Module (CSM) for directional sensitivity but had a limited receptive field, whereas MambaVision simplifies this with a Mamba mixer for efficient dependency capture. The evolution of SSMs ____ has enhanced long-range modeling, with approaches like S4 ____ and Mamba ____ improving efficiency and scalability. Mamba-based models continue to demonstrate versatility across vision, medical imaging, and graph representation tasks.


\begin{figure*}[!t]
\centering
\includegraphics[width=1 \linewidth]{mamba.pdf}
\caption{Overview of the Hybrid Domain-Adaptive Mamba-Transformer architecture, showing the flow of source, source-dominant, target-dominant, and target features across the stages. The framework includes gating attention mechanisms and Mamba-Transformer blocks, which integrate self-attention, cross-attention and DAMamba block for domain-adaptive feature extraction and alignment.}
\label{fig:mamba}
\end{figure*}