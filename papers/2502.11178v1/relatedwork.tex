\section{Related Work}
% \textbf{Unsupervised Domain Adaptation.} Unsupervised domain adaptation (UDA) aims to train a model for a target domain that lacks labeled data by leveraging labeled data from a source domain. UDA has shown significant success, especially when integrated with deep neural networks. There are two primary strategies in this field. The first focuses on reducing the domain gap through discrepancy-based methods, often employing metrics such as maximum mean discrepancy (MMD) to minimize domain discrepancies \cite{long2015learning, long2016unsupervised, long2017deep}. The second approach, adversarial domain adaptation, treats the task as a min-max optimization problem where a domain classifier helps align the source and target domain distributions \cite{tzeng2017adversarial, sankaranarayanan2018generate, ganin2016domain, ganin2015unsupervised}. In addition, generative models such as CycleGAN \cite{zhu2017unpaired} have been applied to image-level domain adaptation. However, domain adaptation for object detection is more complex because the model needs to predict both bounding boxes and object classes, making it more challenging than general vision tasks. To overcome these challenges, several methods \cite{zhang2020unsupervised, tzeng2017adversarial, saito2018maximum, lee2019sliced, kumar2018co, ganin2016domain} have been introduced to learn features that bridge the domain gap. Recently, consensus regularization \cite{luo2008transfer}, a technique borrowed from semi-supervised learning, has gained traction in domain adaptation. This approach involves using multiple classifiers with varied initializations, where the disagreement between their output measures domain divergence. For example, \cite{kumar2018co} reduces the classifier disagreement while diversifying the feature embeddings, and \cite{saito2018maximum} iteratively adjusts this disagreement to improve adaptation. Building on this, \cite{lee2019sliced} employs the Wasserstein metric to analyze prediction dissimilarities, while \cite{zhang2020unsupervised, zhang2019domain} expands these ideas to multiclass settings. These methods have been successfully applied in tasks such as semantic segmentation \cite{luo2019taking, zheng2021rectifying} and keypoint detection \cite{jiang2021regressive, zhou2018unsupervised}.

\textbf{Domain Adaptive Object Detection.} Domain adaptive object detection (DAOD) bridges the gap between training and testing domains using techniques like style transfer, self-labeling, and domain alignment. Many methods, such as Chen et al. \cite{chen2018domain} and Saito et al. \cite{saito2019strong}, employ adversarial learning to align feature distributions at different levels. While effective, these approaches rely on both source and target data, limiting their applicability to single-domain generalizable object detection (Single-DGOD). Recent works refine feature alignment strategies, as seen in SWDA \cite{saito2019strong} and HTCN \cite{chen2020harmonizing}, but often compromise detector discriminability by entangling adaptation with training. Unlike prior methods, we enhance transfer learning through adversarial hard example mining and domain-level metric regularization, improving robustness without adding complexity or extra parameters.

\textbf{Mamba.} Mamba has significantly influenced vision applications, inspiring various adaptations. Vim \cite{zhu2024vision} employed a bidirectional state-space model (SSM) to enhance spatial understanding but suffered from high computational costs and global context loss. In contrast, MambaVision introduces a streamlined forward pass and redesigned Mamba block, improving efficiency and surpassing Vim in accuracy and throughput. EfficientVMamba \cite{pei2024efficientvmamba} combined atrous-based selective scanning with CNN-SSM hierarchies for global dependencies, while MambaVision optimizes this by using CNNs for high-resolution features and self-attention for fine-grained details, achieving superior performance. VMamba \cite{zhu2024vision} proposed a Cross-Scan Module (CSM) for directional sensitivity but had a limited receptive field, whereas MambaVision simplifies this with a Mamba mixer for efficient dependency capture. The evolution of SSMs \cite{gu2021efficiently, gu2023mamba} has enhanced long-range modeling, with approaches like S4 \cite{gu2021efficiently} and Mamba \cite{gu2023mamba} improving efficiency and scalability. Mamba-based models continue to demonstrate versatility across vision, medical imaging, and graph representation tasks.


\begin{figure*}[!t]
\centering
\includegraphics[width=1 \linewidth]{mamba.pdf}
\caption{Overview of the Hybrid Domain-Adaptive Mamba-Transformer architecture, showing the flow of source, source-dominant, target-dominant, and target features across the stages. The framework includes gating attention mechanisms and Mamba-Transformer blocks, which integrate self-attention, cross-attention and DAMamba block for domain-adaptive feature extraction and alignment.}
\label{fig:mamba}
\end{figure*}