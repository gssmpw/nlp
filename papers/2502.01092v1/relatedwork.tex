\section{Related Work}
\subsection{Planning and Control for Reliable Visual Navigation}


The importance of acquiring rich keypoints in visual navigation has been well recognized since the early days of visual SLAM research \cite{davison2002simultaneous}. With advancements in path planning and control, there has been a growing focus on integrating visual navigation capabilities into these algorithms.


Belief Space Planning (BSP) addresses state uncertainty by modeling it as a probability distribution, allowing objectives like collision avoidance to be treated as chance constraints. For instance, estimators with explicit uncertainty representation, such as the Extended Kalman Filter (EKF), have been combined with Rapidly-exploring Random Trees (RRT) to manage uncertainty in path planning \cite{bry2011rapidly}. 
% Similarly, Linear-Quadratic Gaussian (LQG) control can be employed to handle collision constraints \cite{van2011lqg}. 
In vision-based systems, computationally intensive techniques such as bundle adjustment are used to estimate future states. Integrating these methods into the core of planning and control algorithms is often impractical for real-time control due to their high computational cost \cite{achtelik2014motion} \cite{indelman2015planning}. To mitigate this computational burden, metrics like the Fisher Information Matrix \cite{zhang2019beyond} or the observability Gramian \cite{hausman2017observability} are employed as proxies for explicit uncertainty computation and are used as objective functions in optimal control algorithms.
% , though they still can't be directly applied to image inputs.


In contrast, vision-based heuristics are designed to assess visual navigation quality efficiently, often derived directly from pixel measurements. For instance, point visibility can be constrained in controller design \cite{falanga2018pampc} \cite{kim2023visibility}, effective for fixed landmarks but unsuitable for dynamic  feature tracking. Metrics like the number of visible features \cite{kim2021topology} and co-visible features \cite{chen2024apace} approximate visual estimation quality and integrate into trajectory optimization. Our work aligns closely with this, operating directly in image space. However, instead of balancing multiple objectives in trajectory optimization, we use a safety-critical control method that formulates reliable feature tracking as a constrained control problem.
The resulting QP-based safety filter provides safe control with feasibility guarantees under mild assumptions, offering a more interpretable and numerically efficient real-time control method compared to multi-objective non-convex trajectory optimization approaches.


% Additionally, Indelman et al.  investigated the use of model predictive control in planning under uncertainty, highlighting the computational challenges these methods entail. However, BSP's reliance on probabilistic models to represent state uncertainty tends to limit its application to specific types of estimators and it often requires heavy computation.
% The importance of acquiring richful salient keypoints on visual navigation is understood from the early development of visual SLAM \cite{davison2002simultaneous}.  With development of efficient path planning and control methods, the studies have focused on integrating the visual navigation components into the developed planning and control algorithms. And this topic is stuided as subset of active SLAM \cite{placed2023survey}, but in this case we only consider uncertain state estimation, not building map. Belief space planning (BSP) handles uncertain state in probability distribution, met the planning objective such as collision avoidance as chance constraints. The aspect of BSP is it requires probability distrubition to model the state uncertainty, which narrows the domain of BSP in specific types of estimators such as EKF \cite{van2011lqg} or require heavy computation. For global planning \cite{bry2011rapidly} used EKF with RRT, \cite{achtelik2014motion} run bundle adjustment to acquire future state estimation which requires large computation thus only used for offline planning. \cite{indelman2015planning} model predictive control. 

% Our work proposes the method to 

% \cite{bonzanini2024perception} perception-aware mpc
% \cite{wu2022perception}
% \cite{chen2024apace} apace, co-visibility of features maximization with smoothness. 

\subsection{Safety-Critical Control with Perception Objective}


The growing focus on autonomous navigation has increased the need for safety with formal guarantees like collision avoidance. Safety-critical control techniques including Hamilton-Jacobi reachability and control barrier functions (CBFs) have been developed to address these needs. These techniques now increasingly integrate perception systems for broader applications.

To handle state uncertainty, measurement-robust CBFs \cite{cosner2021measurement} and observer-controller co-designs \cite{agrawal2022safe} address safety under estimation errors. In vision-based systems, the challenge of high-dimensional image inputs is tackled by learning-based CBFs trained on RGB-D images to avoid collisions with arbitrarily shaped objects \cite{abdi2023safe}, and BarrierNet \cite{xiao2023barriernet}, which uses differentiable CBFs for tasks like end-to-end driving. CBFs have also been designed for environmental representations such as point clouds from depth cameras \cite{de2024point} and neural radiance fields \cite{tong2023enforcing} for collision avoidance.

Beyond collision avoidance, safety-critical control can also be used to maintain the visibility of points of interest, which is essential in applications like visual servoing \cite{zheng2019toward} \cite{wei2024diffocclusion} and teleoperation \cite{kim2023visibility}, ensuring that targets remain within the camera's field of view. We extend this concept by developing a safety filter for reliable visual navigation, enforcing a sufficient number of visible image features.
% As a new application for a safety-critical control, we develop a safety filter tailored for reliable visual navigation, with safety requirements based designed to ensure a sufficient number of visible image features.


% Consider uncertainty of state-estimate 
% \cite{dean2020robust} robust guarnatee on perception-based control
% \cite{agrawal2022safe} observer and controller synthesis.

% \cite{de2024point} pointcloud-based cbf 
% \cite{xiao2023barriernet} barrier net, learnable differential cbf, high-dimensional image input applied to such as end-to-end driving scenario. 
% \cite{tong2023enforcing} nerf with cbf, collision avoidance in nerf representation of scene. 


%