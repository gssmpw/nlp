In this section, we introduce the proof of the lower bound in Theorem \ref{theorem-lower-bound}. Let $\bar{\sigma}^2:=\bbE[\xi^2]+\sum_{i=M+1}^{\infty}\lambda_i(\upv_i^*)^4$. Recall the analysis in Phase I, $\upv^{T_1}$ satisfies the inequality $\overline{\upb} \leq \upv^{T_1} \leq \widehat{\upb}$ with high probability. Here, $\widehat{\upb}$ is defined as $\widehat{\upb}^{\top}=(\frac{3}{2}(\upv_{1:D}^*)^{\top},3(\upv_{D+1:M}^*)^{\top})$, while $\overline{\upb}$ is defined as $\overline{\upb}^{\top}=(\frac{1}{2}(\upv_{1:D}^*)^{\top},\mathbf{0}^{\top})$. We begin with the required concepts as below. A Markov chain $\{\breve{\upv}^t\}_{t=0}^{T_2}$ is constructed with initialization $\breve{\upv}^0$ satisfying $\overline{\upb} \leq \breve{\upv}^0 \leq \widehat{\upb}$. The update rule is defined by
\begin{align}\label{eq-bv}
     \breve{\upv}^{t+1}=\breve{\upv}^t-\eta_t\upH_{\breve{\upv}}^t\left(\breve{\upv}^t-\upv_{1:M}^*\right)+\eta_t\upR_{\breve{\upv}}^t\Pi_M\upx^t, \quad \forall t\in[0:T_2-1],\notag
\end{align}
% if $\overline{\upb}\leq\breve{\upv}^t\leq\widehat{\upb}$, let
% \begin{align}
%     \breve{\upv}^{t+1}=\breve{\upv}^t-\eta_t\upH_{\breve{\upv}}^t\left(\breve{\upv}^t-\upv_{1:M}^*\right)+\eta_t\upR_{\breve{\upv}}^t\Pi_M\upx^t,\notag
% \end{align}
% otherwise, let 
% \begin{align}
%     \breve{\upv}^{\tau+1}=\breve{\upv}^{\tau}-\eta_{\tau}\breve{\upH}^{\tau}(\breve{\upv}^{\tau}-\upv_{1:M}^*)+\eta_{\tau}\breve{\upR}^{\tau}\Pi_M\upx^{\tau},\quad\forall \tau\in[t:T_2-1],\notag
% \end{align}
where $\upH_{\breve{\upv}}^{t}$ and $\upR_{\breve{\upv}}^t$ satisfy: 
\begin{enumerate}
    \item If $\overline{\upb}\leq\breve{\upv}^t\leq\widehat{\upb}$, $\upH_{\breve{\upv}}^{t}=(\breve{\upv}^t\odot\Pi_M\upx^t)\otimes((\breve{\upv}^t+\upv_{1:M}^*)\odot\Pi_M\upx^t)$ and $\upR_{\breve{\upv}}^t=(\xi^t+\sum_{i=M+1}^{\infty}\upx_i^t(\upv_i^*)^2)\diag\{\breve{\upv}^t\}$,
    \item Otherwise, for any $\tau\in[t:T_2-1]$,  $\upH_{\breve{\upv}}^{\tau}=\frac{25}{4}(\upv_{1:M}^*\odot\Pi_{M}\upx^{\tau})\otimes(\upv_{1:M}^*\odot\Pi_{M}\upx^{\tau})$ and $\upR_{\breve{\upv}}^{\tau}=(\xi^{\tau}+\sum_{i=M+1}^{\infty}\upx_i^{\tau}(\upv_i^*)^2)$ $\diag\{\overline{\upb}\}$.
\end{enumerate}
Let $\breve{\upw}^t:=\breve{\upv}^t-\upv_{1:M}^*$ be the error vector, and let $t_s:=\inf\{t\mid \breve{\upv}^t\nleqslant\widehat{\upb}\bigvee\breve{\upv}^t\ngeqslant\overline{\upb}\}$ be the stopping time. According to Eq.~\eqref{eq-bv}, $\{\breve{\upw}^t\}_{t=1}^{T_2}$ is recursively defined by
\begin{align}
		\breve{\upw}^{t+1}=\left(\upI-\eta_t\upH_{\breve{\upv}}^t\right)\breve{\upw}^t+\eta_t\upR_{\breve{\upv}}^t\Pi_M\upx^t. \notag
\end{align}
% Analogous to Phase II analysis, the dynamics of $\breve{\upw}^t$ can be decomposed into two random processes,
% \begin{align}
%     \breve{\upw}^t=\breve{\upw}_{\bi}^t+\breve{\upw}_{\var}^t,
% \end{align}
% for any $t\in[0:T_2]$, where $\{\breve{\upw}_{\var}^t\}_{t=1}^{T_2}$ is recursively defined by
% \begin{align}
% 		\breve{\upw}_{\var}^{t+1}=\left(\upI-\eta_t\upH_{\breve{\upv}}^t\right)\breve{\upw}_{\var}^t+\eta_t\upR_{\breve{\upv}}^t\Pi_M\upx^t, \notag
% \end{align}
% for any $t\in[0:T_2-1]$ with $\breve{\upw}_{\var}^0=0$ and $\{\breve{\upw}_{\bi}^t\}_{t=1}^{T_2}$ is recursively defined by
% \begin{align}
% 		\breve{\upw}_{\bi}^{t+1}=\left(\upI-\eta_t\upH_{\breve{\upv}}^t\right)\breve{\upw}_{\bi}^t, \notag
% \end{align}
% for any $t\in[0:T_2-1]$ with  $\breve{\upw}_{\bi}^0=\breve{\upv}^0-\upv_{1:M}^*$. 
We define $\breve{\upV}^t=\bbE\left[\breve{\upw}^t\otimes\breve{\upw}^t\right]$. By the definitions of $\calH_{\cdot}^t$, $\widetilde{\calH}_{\cdot}^t$, $\calG_{\cdot}^t$, and $\widetilde{\calG}_{\cdot}^t$ in Phase II, we derive the iterative relationship governing the sequence $\{\breve{\upV}^t\}_{t=0}^{T_2}$:
\begin{align}
	% \begin{cases}
 %        \breve{\upB}^{t+1}&=\left(\calI-\eta_t\calG_{\breve{\upv}}^t\right)\circ\breve{\upB}^t,
	% 	\\
		\breve{\upV}^{t+1}&=\bbE\left[\left(\calI-\eta_t\calG_{\breve{\upv}}^t\right)\circ\left(\breve{\upw}^t\otimes\breve{\upw}^t\right)\right]+\eta_t^2\upSigma_{\breve{\upv}}^t,
	% \end{cases}
\end{align}
for $t\in[0:T_2-1]$ with $\upV^0=\left(\upw^0-\upv_{1:M}^*\right)\otimes\left(\upw^0-\upv_{1:M}^*\right)$. If $t<t_s$, $\upSigma_{\breve{\upv}}^t=\bar{\sigma}^2\upLambda\bbE[\diag\{\breve{\upv}^{t\odot2}\}]$; otherwise, $\upSigma_{\breve{\upv}}^{\tau}=\bar{\sigma}^2\upLambda\diag\{\overline{\upb}^{\odot2}\}$ for any $\tau\geq t$. According to the definitions above, we obtain following estimation of the last-iteration function value:
\begin{align}\label{lower-bound-I}
    \bbE\left[\calR_M(\breve{\upw}^{T_2})-\calR_M(\upv_{1:M}^*)\right]\geq\frac{1}{24}\llangle\breve{\upH},\bbE\left[\breve{\upw}^{T_2}\otimes\breve{\upw}^{T_2}\right]\rrangle\geq\frac{1}{24}\llangle\breve{\upH},\breve{\upV}^{T_2}\rrangle,
\end{align}
where $\breve{\upH}:=12\upLambda\diag\{\upv_{1:M}^*\odot\upv_{1:M}^*\}$. We define $\breve{\calG}^i:=\breve{\upH}\otimes\upI+\upI\otimes\breve{\upH}-\eta_i\breve{\upH}\otimes\breve{\upH}$. We formally propose the lower bound of the estimate in Theorem \ref{theorem-lower-bound} as below.

\begin{theorem}\label{theorem-lower-bound}
%     Under Assumptions \ref{ass-d} and \ref{ass-ss}, we consider a predictor trained by Algorithm \ref{SGD} with iteration number $T$. Suppose there exists $D\leq M$ such that $T_1\in[\widetilde{\calO}(\frac{\bar{\sigma}^2+\mathcal{M}^2(\upb)}{\eta\sigmin(D)}),\widetilde{\Theta}(\frac{\Tildesigmax^{-1}(D)}{\eta^2(\bar{\sigma}^2+\mathcal{M}^2(\upb))})]$, where $\eta\leq\widetilde{\Theta}(\frac{\Barsigmin(D)}{(\bar{\sigma}^2+\mathcal{M}^2(\upb))^2})$ and $T_1:=\lceil(T-h)/\log(T-h)\rceil$ with $h\geq T_1$. Then we have
%     \begin{align}
%     \bbE\left[\calR_M(\upv^{T})-\calR_M(\upv_{1:M}^*)\right]\gtrsim\bar{\sigma}^2\left(\frac{H_1}{T_1}+\eta\sum_{i=H_1+1}^{H_2}\lambda_i(\upv_i^*)^2+\eta^2h\sum_{i=H_2+1}^{D}\lambda_i^2(\upv_i^*)^4\right),\notag
% \end{align}
% where $H_1:=\min\{D,\max\{i\mid\lambda_i(\upv_i^*)^2\geq\frac{1}{12\eta T_1}\}\}$ and $H_2:=\min\{D,\max\{i\mid\lambda_i(\upv_i^*)^2\geq\frac{1}{12\eta h}\}\}$. Otherwise, let $T_1\in[\widetilde{\calO}(\frac{\bar{\sigma}^2+\mathcal{M}^2(\upb)}{\eta\sigmin(M)}),+\infty)$, where $\eta\leq\widetilde{\Theta}(\frac{\Barsigmin(M)}{(\bar{\sigma}^2+\mathcal{M}^2(\upb))^2})$ and $T_1:=\lceil(T-h)/\log(T-h)\rceil$ with $h\geq T_1$. Then we have
%     \begin{align}
%     \bbE\left[\calR_M(\upv^{T})-\calR_M(\upv_{1:M}^*)\right]\gtrsim\bar{\sigma}^2\left(\frac{H_1'}{T_1}+\eta\sum_{i=H_1'+1}^{H_2'}\lambda_i(\upv_i^*)^2+\eta^2h\sum_{i=H_2'+1}^{D}\lambda_i^2(\upv_i^*)^4\right),\notag
% \end{align}
% where $H_1':=\min\{M,\max\{i\mid\lambda_i(\upv_i^*)^2\geq\frac{1}{12\eta T_1}\}\}$ and $H_2':=\min\{M,\max\{i\mid\lambda_i(\upv_i^*)^2\geq\frac{1}{12\eta h}\}\}$.
Under Assumption \ref{ass-d} and \ref{ass-ss}, we consider a predictor trained by Algorithm \ref{SGD} with iteration number $T$ and middle phase length $h>\lceil(T-h)/\log(T-h)\rceil$. Let $D\asymp\min\{T^{1/\max\{\beta,(\alpha+\beta)/2\}},$ $M\}$ and $\eta\asymp D^{\min\{0,(\alpha-\beta)/4\}}$. Then we have
    \begin{align}\label{last-iterate-lower-1}
    \bbE\left[\mathcal{R}_M(\upv^{T})\right]-\bbE[\xi^2]\gtrsim\frac{1}{M^{\beta-1}}+\frac{\bar{\sigma}^2D}{T}+\frac{1}{D^{\beta-1}}\mathds{1}_{M>D},
    \end{align}
where $\bar{\sigma}^2:=\bbE[\xi^2]+\sum_{i=M+1}^{\infty}\lambda_i(\upv_i^*)^4$.
\end{theorem}
\begin{proof}
    The proof of Theorem \ref{theorem-lower-bound} is divided into two steps. \textbf{Step I} reveals that for coordinates $j\geq\widetilde{\calO}(D)$, the slow ascent rate inherently prevents $\upv_j^t$ from attaining close proximity to the optimal solution $\upv_j^*$ upon algorithmic termination.
    
    \noindent \textbf{Step I:} Let $M\gtrsim T^{1/\max\{\beta,(\alpha+\beta)/2\}}$, and define $T_1:=\lceil(T-h)/\log(T-h)\rceil$ and $D^{\dagger}:=\calO((\eta T)^{2/(\alpha+\beta)})$. Considering the $\upb$-capped coupling process $\{\bar{\upv}^t\}_{t=0}^{T}$ mentioned in Phase I, we denote $\hat{\tau}_j$ as the stopping time when $\bar{\upv}_j^{\hat{\tau}_j}\geq\frac{1}{4}\upv_j^*$ for each coordinate $D^{\dagger}\leq j\leq M$, i.e., 
    \begin{align}
        \hat{\tau}_j=\inf\left\{t:\bar{\upv}_j^{t}\geq\frac{1}{4}\upv_j^*\right\}.\notag
    \end{align}
    We aim to estimate the following probability for coordinates $j\in[D^{\dagger}:M]$ and times $t_1\in[1:T_1]$:
    \begin{align}
        \bbP\left(\mathcal{J}^{\hat{\tau}_j=t_1}(j)=\left\{\bar{\upv}_j^0\leq\frac{1}{8}\upv_j^*\bigwedge\bar{\upv}_j^{0:t_1-1}\in\left[0:\frac{1}{4}\upv_j^*\right]\bigwedge\bar{\upv}_j^{t_1}\geq\frac{1}{4}\upv_j^*\right\}\right).\notag
    \end{align}
    For fixed $j\in[D^{\dagger}:M]$ and any $t\in[0:t_1-1]$, we have
    \begin{equation}\label{lower-concen-1}
    \begin{aligned}
        \bbE\left[\bar{\mathbf{v}}_j^{t+1}\mid\mathcal{F}^t\right]=&\bbE_{{\mathbf{x}}_{1:M}^{t+1},{\xi}^{t+1},{\zeta}_{M+1:\infty}^{t+1}}\left[\bar{\mathbf{v}}_j^{t}-\eta\left(\left((\bar{\upv}_j^t)^2-(\upv_j^*)^2\right)\hat{\upx}_j^{t+1}+\hat{\upz}_j^{t+1}(\bar{\upv}^t)\right.\right.
        \\
        &\, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \left.\left.-\hat{\zeta}_{M+1:\infty}^{t+1}-\hat{\xi}^{t+1}\right)\hat{\mathbf{x}}_j^{t+1}\bar{\mathbf{v}}_j^{t+1}\right]
        \\
		\leq&\left(1+\eta\lambda_{j}(\mathbf{v}_{j}^*)^2\right)\bar{\mathbf{v}}_j^{t}.
    \end{aligned}
    \end{equation}
    Similarly, based on Lemma \ref{aux-1}, we have
    \begin{equation}
    \small
    \begin{split}
        \bbE\left[\exp\left\{\lambda(\bar{\upv}_j^{t+1}-\bbE[\bar{\upv}_j^{t+1}\mid\calF^t])\right\}\mid\calF^t\right]\leq\exp\left\{\frac{\lambda^2\eta^2\lambda_j(\upv_j^*)^2\calO\left(\left[\bar{\sigma}^2+\mathcal{M}^2(\upv_{1:M}^*)\right]\log^4(MT_1/\delta)\right)}{2}\right\},\notag
    \end{split}
    \end{equation}
    for any $\lambda\in\bbR$. According to the setting of stepsize $\eta$, we have $(1+\eta\lambda_i(\upv_i^*)^2)^{T_1}\leq 2$ for any $i\in[D^{\dagger}:M]$. Utilizing Corollary \ref{aux-coro-3} and Eq.~\eqref{lower-concen-1}, we can establish the probability bound for event $\mathcal{J}^{\hat{\tau}_j=t_1}(j)$ for any time $t_1\in[1:T_1]$ as
    \begin{align}\label{probability-lower-1}
		\Pro\left (\mathcal{J}^{\hat{\tau}_j=t_1}(j)\right )\leq\exp\left\{-\frac{1}{T\eta^2\lambda_j\calO\left([\bar{\sigma}^2+\calM^2(\upv_{1:M}^*)]\log^2(MT_1/\delta)\right)}\right\}.
    \end{align}

    Finally, combining the probability bounds Eq.\eqref{probability-lower-1} with the setting of $\eta$, we obtain the following probability bound for complement event $\bigcup_{j=D^{\dagger}}^M\{\max_{t\in[1:T_1]}\bar{\upv}_j^t\geq\frac{1}{4}\upv_j^*\}$:
    \begin{align}
        \bbP\left(\bigcup_{j=D^{\dagger}}^M\left\{\max_{t\in[1:T_1]}\bar{\upv}_j^t\geq\frac{1}{4}\upv_j^*\right\}\right)\leq&\sum_{j=D^{\dagger}}^M\sum_{t_1=1}^{T_1}\Pro\left (\mathcal{J}^{\hat{\tau}_j=t_1}(j)\right)\notag
        \\
        \leq&MT_1\exp\left\{-\frac{\min_{D^{\dagger}\le j\le M}\lambda_j^{-1}}{T_1\eta^2\calO\left([\bar{\sigma}^2+\calM^2(\upv_{1:M}^*)]\log^4(MT_1/\delta)\right)}\right\}\notag
        \\
        \leq&\frac{\delta}{2}.
    \end{align}
    Therefore, we have $\bigcap_{j=D^{\dagger}}^M\{\max_{t\in[1:T_1]}{\upv}_j^t<\frac{1}{4}\upv_j^*\}$ with high probability.

    Similar to \textbf{Phase II}'s analysis, \textbf{Step II} derives the lower bound estimate of the risk by constructing a recursive expression for $\{\breve{\upV}_{\diag}^{t}\}_{t=0}^{T_2}$ where $T_2=T-T_1$. We continue to use use $\upv^{T_1}$, which satisfies Eq.~\eqref{thm-1-eq}, as the initial point for the SGD iterations in \textbf{Step II}. If $M\gtrsim T^{1/\max\{\beta,(\alpha+\beta)/2\}}$, we further require that $\upv^{T_1}$ satisfies
    \begin{align}
        \upv_j^{T_1}<\frac{1}{4}\upv_j^*,\quad\forall j\in\left[\widetilde{\calO}(T^{1/\max\{\beta,(\alpha+\beta)/2\}}), M\right].\notag
    \end{align}
    According to Theorem \ref{theorem_1} and the result of \textbf{Step I}, the assumption on $\upv^{T_1}$ can be satisfied with high probability.

    \noindent \textbf{Step II:} If $M\gtrsim T^{1/\max\{\beta,(\alpha+\beta)/2\}}$, assume that $\breve{\upv}^0$ further satisfies $\breve{\upv}_{D^{\dagger}:M}^0\leq\frac{1}{4}\upv_{D^{\dagger}:M}^*$. Setting $\eta_0 = \eta$ and $K=T_1$, we have 
    \begin{align}
        \breve{\upV}_{\diag}^{t+1}=&\left(\bbE\left[\left(\calI-\eta_t\widetilde{\calG}_{\breve{\upv}}^t\right)\circ\left(\breve{\upw}^t\otimes\breve{\upw}^t\right)\right]\right)_{\diag}+\eta_t^2\left(\bbE\left[\left(\calH_{\breve{\upv}}^t-\widetilde{\calH}_{\breve{\upv}}^t\right)\circ\left(\breve{\upw}^t\otimes\breve{\upw}^t\right)\right]\right)_{\diag}+\eta_t^2\Sigma_{\breve{\upv}}^t\notag
        \\
        \succeq&\left(\calI-\eta_t\breve{\calG}^t\right)\circ\breve{\upV}_{\diag}^t+\eta_t^2\bar{\sigma}^2\upLambda\diag\left\{\overline{\upb}^{\odot2}\right\},\notag
    \end{align}
    for any $t\in[0:T_2-1]$. According to the recursive step above, we obtain
    \begin{align}\label{lower-bound-proof-I}
        \breve{\upV}^{T_2}
        % \succeq&\bar{\sigma}^2\sum_{t=1}^{T_2}\eta_t^2\prod_{i=t+1}^{T_2}\left(\calI-\eta_i\widetilde{\calG}_{\breve{\upv}}^i\right)\circ\upLambda\diag\left\{\overline{\upb}^{\odot2}\right\}\notag
        % \\
        \succeq&\bar{\sigma}^2\sum_{t=1}^{T_2}\eta_t^2\prod_{i=t+1}^{T_2}\left(\upI-\eta_i\breve{\upH}\right)^2\upLambda\diag\left\{\overline{\upb}^{\odot2}\right\}+\underbrace{\left(\upI-\eta_0\breve{\upH}\right)^{2T_2}\left(\breve{\upw}^0\otimes\breve{\upw}^0\right)}_{\calcolII}\notag
        \\
        \succeq&\bar{\sigma}^2\underbrace{\sum_{t=1}^{T_2}\eta_t^2\prod_{i=t+1}^{T_2}\left(\upI-2\eta_i\breve{\upH}\right)\upLambda\diag\left\{\overline{\upb}^{\odot2}\right\}}_{\calcolI}+\calcolII.
    \end{align}
    Recalling the step size decay rule in Algorithm \ref{SGD}, we have
    \begin{align}\label{lower-bound-proof-2}
        \calcolI=&\eta_0^2\sum_{i=1}^h\left(\upI-2\eta_0\breve{\upH}\right)^{h-i}\prod_{j=1}^{L-1}\left(\upI-\frac{\eta_0}{2^{j-1}}\breve{\upH}\right)^K\upLambda\diag\left\{\overline{\upb}^{\odot2}\right\}\notag
	\\
	&+\sum_{l=1}^{L-1}\left(\frac{\eta_0}{2^l}\right)^2\sum_{i=1}^K\left(\upI-\frac{\eta_0}{2^{l-1}}\breve{\upH}\right)^{K-i}\prod_{j=l+1}^{L-1}\left(\upI-\frac{\eta_0}{2^{j-1}}\breve{\upH}\right)^K\upLambda\diag\left\{\overline{\upb}^{\odot2}\right\}\notag
	\\
	=&\frac{\eta_0^2}{12}\sum_{i=1}^h\left(\upI_{1:D}-2\eta_0\breve{\upH}_{1:D}\right)^{h-i}\prod_{j=1}^{L-1}\left(\upI_{1:D}-\frac{\eta_0}{2^{j-1}}\breve{\upH}_{1:D}\right)^K\breve{\upH}_{1:D}\notag
	\\
	&+\frac{1}{12}\sum_{l=1}^{L-1}\left(\frac{\eta_0}{2^l}\right)^2\sum_{i=1}^K\left(\upI_{1:D}-\frac{\eta_0}{2^{l-1}}\breve{\upH}_{1:D}\right)^{K-i}\prod_{j=l+1}^{L-1}\left(\upI_{1:D}-\frac{\eta_0}{2^{j-1}}\breve{\upH}_{1:D}\right)^K\breve{\upH}_{1:D}\notag
	\\
	=&\frac{\eta_0}{24}\left(\upI_{1:D}-\left(\upI_{1:D}-2\eta_0\breve{\upH}_{1:D}\right)^h\right)\left(\prod_{j=1}^{L-1}\left(\upI_{1:D}-\frac{\eta_0}{2^{j-1}}\breve{\upH}_{1:D}\right)\right)^K\notag
	\\
	&+\sum_{l=1}^{L-1}\frac{\eta_0}{12\cdot 2^{l+1}}\left(\upI_{1:D}-\left(\upI_{1:D}-\frac{\eta_0}{2^{l-1}}\breve{\upH}_{1:D}\right)^K\right)\left(\prod_{j=l+1}^{L-1}\left(\upI_{1:D}-\frac{\eta_0}{2^{j-1}}\breve{\upH}_{1:D}\right)\right)^K\notag
	\\
	\overset{\text{(a)}}{\geq}&\frac{\eta_0}{24}\left(\upI_{1:D}-\left(\upI_{1:D}-2\eta_0\breve{\upH}_{1:D}\right)^h\right)\left(\upI_{1:D}-2\eta_0\breve{\upH}_{1:D}\right)^K\notag
	\\
	&+\sum_{l=1}^{L-1}\frac{\eta_0}{12\cdot 2^{l+1}}\left(\upI_{1:D}-\left(\upI_{1:D}-\frac{\eta_0}{2^{l-1}}\breve{\upH}_{1:D}\right)^K\right)\left(\upI_{1:D}-\frac{\eta_0}{2^{l-1}}\breve{\upH}_{1:D}\right)^K,
    \end{align}
    where (a) is derived from following inequality
\begin{align}
	\prod_{i=l+1}^{L-1}\left(\upI_{1:D}-\frac{\eta_0}{2^{i-1}}\breve{\upH}_{1:D}\right)\geq\upI_{1:D}-\sum_{i=l+1}^{L-1}\frac{\eta_0}{2^{i-1}}\breve{\upH}\geq\upI_{1:D}-\frac{\eta_0}{2^{l-1}}\breve{\upH}_{1:D}.\notag
\end{align}
When $h > K$, we apply an auxiliary function analogous to [Lemma D.1, \citet{wu2022last}]'s:
\begin{align}
    f(x):=\frac{x}{2}\left(1-\left(1-2x\right)^h\right)(1-2x)^K+\sum_{l=1}^{L-1}\frac{x}{2^{l+1}}\left(1-\left(1-\frac{x}{2^{l-1}}\right)^K\right)\left(1-\frac{x}{2^{l-1}}\right)^K.\notag
\end{align}
Then, we obtain
\begin{align}\label{lower-bound-proof-III}
    f(\eta_0\breve{\upH})\succeq\frac{1}{4800K}\upI_{1:H_1}+\frac{\eta_0}{480}\breve{\upH}_{H_1+1:H_2}+\frac{\eta_0^2h}{480}\breve{\upH}_{H_2+1:D}^2,
\end{align}
where $H_1:=\min\{D,\max\{i\mid\lambda_i(\upv_i^*)^2\geq\frac{1}{12\eta_0K}\}\}$ and $H_2:=\min\{D,\max\{i\mid\lambda_i(\upv_i^*)^2\geq\frac{1}{12\eta_0h}\}\}$. 

% According to the result of \text{Step I}, we can obtain $\bigcap_{j=D^{\dagger}}^M\left\{\max_{t\in[1:T_1]}\bar{\upv}_j^t<\frac{1}{3}\upv_j^*\right\}$ with high probability. This
% Notice $\breve{\upv}_{D^{}}^t<\frac{1}{3}\upv_j^*$ implicates that
For term $\calcolII$, we have
\begin{align}\label{lower-bias}
    \llangle\breve{\upH},\calcolII\rrangle\gtrsim\begin{cases}
        \sum_{i=D^{\dagger}}^M\lambda_i(\upv_i^*)^4, & \text{ if }M\gtrsim T^{1/\max\{\beta,(\alpha+\beta)/2\}},
        \\
        0, & \text{ otherwise},
    \end{cases}
\end{align}
where the estimation for $\langle\breve{\upH},\calcolII\rangle$ under case $M\gtrsim T^{1/\max\{\beta,(\alpha+\beta)/2\}}$ is derived from the initialization $\breve{\upv}_{D^{\dagger}:M}^0<\frac{1}{4}\upv_{D^{\dagger}:M}^*$ and $(1+\eta\lambda_i(\upv_i^*)^2)^{2T_2}\leq 2$ for any $i\in[D^{\dagger}:M]$.

Therefore, using Eq.~\eqref{lower-bound-I}-Eq.~\eqref{lower-bias}, we derive 
\begin{align}
    \bbE\left[\calR_M(\breve{\upv}^{T_2})-\calR_M(\upv_{1:M}^*)\right]\gtrsim&\bar{\sigma}^2\llangle\breve{\upH},\frac{1}{K}\breve{\upH}_{1:H_1}^{-1}+\eta_0\upI_{H_1+1:H_2}+\eta_0^2h\breve{\upH}_{H_2+1:D}\rrangle+\llangle\breve{\upH},\calcolII\rrangle\notag
    \\
    =&\bar{\sigma}^2\left(\frac{H_1}{K}+\eta_0\sum_{i=H_1+1}^{H_2}\lambda_i(\upv_i^*)^2+\eta_0^2h\sum_{i=H_2+1}^{D}\lambda_i^2(\upv_i^*)^4\right)+\llangle\breve{\upH},\calcolII\rrangle.\notag
\end{align}
According to Lemma \ref{high-probability-phase-II}, we have $\mathbb{P}(t_s\leq T_2)\leq\delta$, which implies that 
\begin{align}\label{lower-bound-proof-IV}
    &\bbE\left[\calR_M(\breve{\upv}^{T_2})-\calR_M(\upv_{1:M}^*)\mid t_s>T_2\right]\notag
    \\
    \geq&\bbE\left[\calR_M(\breve{\upv}^{T_2})-\calR_M(\upv_{1:M}^*)\right]-\sum_{i=1}^{T_2}\bbP(t_s=i)\bbE\left[\calR_M(\breve{\upv}^{T_2})-\calR_M(\upv_{1:M}^*)\mid t_s=i\right]\notag
    \\
    \overset{\text{(b)}}{\gtrsim}&\bar{\sigma}^2\left(\frac{H_1}{K}+\eta_0\sum_{i=H_1+1}^{H_2}\lambda_i(\upv_i^*)^2+\eta_0^2h\sum_{i=H_2+1}^{D}\lambda_i^2(\upv_i^*)^4\right)+\llangle\breve{\upH},\calcolII\rrangle.
\end{align}
Since $\delta$ is sufficiently small, (b) is drawn from two facts: 1) $\breve{\upv}^{t_s}$ resides in a bounded neighborhood of $\widehat{\upb}$ or $\overline{\upb}$; 2) the risk upper bound for SGD established in [Theorem 4.1, \citet{wu2022last}]. The lower bound established in Eq.~\eqref{lower-bound-proof-IV} is uniformly valid for all $\breve{\upv}^0\in[\overline{\upb},\widehat{\upb}]$. Denote event 
$$
\mathcal{K}\left(\upv^{T_1}\right):=\left\{\overline{\upb}\leq\upv^{T_1}\leq\widehat{\upb}\bigwedge \left\{\upv_{D^{\dagger}:M}^{T_1}\leq\frac{1}{4}\upv_{D^{\dagger}:M}^*, \text{ if }M\gtrsim T^{1/\max\{\beta,(\alpha+\beta)/2\}}\right\}\right\}.
$$
For $t_s > T_2$, the trajectory $\{\breve{\upv}^t\}_{t=0}^{T_2}$ aligns with Algorithm \ref{SGD}'s iterations over $[T_1:T]$, given the initialization $\breve{\upv}^0 = \upv^{T_1}$ with $\mathcal{K}(\upv^{T_1})$ occurs. Then, we have
\begin{align}\label{lower-bound-proof-V}
    &\min_{\upv^{T_1}}\bbE\left[\calR_M(\upv^{T})-\calR_M(\upv_{1:M}^*)\mid \mathcal{K}(\upv^{T_1})\right]\notag
    \\
    \geq&(1-\delta)\min_{\upv^{T_1}}\bbE\left[\calR_M(\breve{\upv}^{T_2})-\calR_M(\upv_{1:M}^*)\mid t_s>T_2\bigwedge\breve{\upv}^0 = \upv^{T_1}\bigwedge\mathcal{K}(\upv^{T_1})\right]\notag
    \\
    \gtrsim&\bar{\sigma}^2\left(\frac{H_1}{K}+\eta_0\sum_{i=H_1+1}^{H_2}\lambda_i(\upv_i^*)^2+\eta_0^2h\sum_{i=H_2+1}^{D}\lambda_i^2(\upv_i^*)^4\right)+\mathds{1}_{M\gtrsim T^{1/\max\{\beta,(\alpha+\beta)/2\}}}\sum_{i=D^{\dagger}}^M\lambda_i(\upv_i^*)^4.
    % \notag
    % \\
    % \geq&\frac{\bar{\sigma}^2}{46080}\left(\frac{T_1}{10K}+12\eta_0\sum_{i=T_1+1}^{T_2}\lambda_i(\upv_i^*)^2+144\eta_0^2h\sum_{i=T_2+1}^{D}\lambda_i^2(\upv_i^*)^4\right).
\end{align}
Noticing that $\mathcal{K}(\upv^{T_1})$ occurs with probability at least $1-\delta$, and combining Eq.~\eqref{lower-bound-proof-IV} with Eq.~\eqref{lower-bound-proof-V}, we obtain
\begin{align}
    \bbE\left[\calR_M(\upv^{T})-\calR_M(\upv_{1:M}^*)\right]\geq&(1-\delta)\min_{\upv^{T_1}}\bbE\left[\calR_M(\upv^{T})-\calR_M(\upv_{1:M}^*)\mid\mathcal{K}(\upv^{T_1})\right]\notag
    \\
    \gtrsim&\bar{\sigma}^2\left(\frac{H_1}{K}+\eta_0\sum_{i=H_1+1}^{H_2}\lambda_i(\upv_i^*)^2+\eta_0^2h\sum_{i=H_2+1}^{D}\lambda_i^2(\upv_i^*)^4\right)\notag
    \\
    &+\mathds{1}_{M\gtrsim T^{1/\max\{\beta,(\alpha+\beta)/2\}}}\sum_{i=D^{\dagger}}^M\lambda_i(\upv_i^*)^4,\notag
\end{align}
where $H_1:=\min\{D,\max\{i\mid\lambda_i(\upv_i^*)^2\geq\frac{1}{12\eta_0K}\}\}$ and $H_2:=\min\{D,\max\{i\mid\lambda_i(\upv_i^*)^2\geq\frac{1}{12\eta_0h}\}\}$. We complete the proof of lower bound.
\end{proof}
