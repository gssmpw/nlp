
In this section, we introduce our proof techniques to prove our main result Theorem \ref{theorem-main-convergence} on the upper bound of the last-iteration instantaneous risk of Algorithm \ref{SGD}. As shown in Section \ref{sec:proof sketch}, the dynamic of SGD and our analysis can be basically divided into two phases. In the \textbf{Phase I} named ``adaption" phase, we demonstrate that SGD can adaptively identify the first $D$ coordinates as the optimal set $\mathcal{S}$ without explicit selection of $D$, and bound such $D$ coordinates near the corresponding optimal solutions by $T_1$ iterations with high probability (refer to Theorem \ref{theorem_1}). The analysis of \textbf{Phase I} can be further separated into two parts:

\begin{itemize}
    \item [1.] We construct a high-probability upper bound of $\upv^{T_1}$. That is for any $i \in \mathcal{S}$, $\upv^{T_1}_i \leq (1+c_1)\upv_i^*$ and for any $i \in \mathcal{S}^c$, $\upv^{T_1}_i \leq \frac{3}{2}\upv_i^*$ (refer to Lemma \ref{lemma_1}).
    \item [2.] We delve into the lower bound of $\max_{t\leq T_1} \upv_i^t$ during $T_1$ iterations. With high probability, for any $i\in\mathcal{S}$, $\max_{t\leq T_1} \upv_i^t$ converges to a neighborhood of $\upv_i^*$ (refer to Lemma \ref{lemma-2}). When $\max_{t\leq T_1}\upv_i^t$ resides within the $\upv_i^*$-neighborhood, the lower bound satisfies $\upv_i^{T_1} \geq (1 - c_1)\upv_i^*$ with high probability (refer to Lemma \ref{lemma-3}).
\end{itemize}

Then we turn to the following \textbf{Phase II} with $T_2$ iterations named ``estimation" phase where we establish the global convergence of Algorithm \ref{SGD} for risk minimization (refer to Theorem \ref{phase-II-main}). The analysis of Algorithm \ref{SGD}'s iterations can be approximated to SGD with geometrically decaying step sizes on a linear regression problem with reparameterized features $\Pi_M\upx\odot\upv_{1:M}^*$. It can also be separated into two parts:

\begin{itemize}
    \item [1.] We demonstrate that $\{\upv^t\}_{t=T_1+1}^{T_1+T_2}$ remain confined within the neighborhood $\prod_{i=1}^D[\frac{1}{2}\upv_i^*,\frac{3}{2}\upv_i^*]\times\prod_{i=D+1}^M[0,2\upv_i^*]$ with high probability (refer to Lemma \ref{high-probability-phase-II}).
    \item [2.] We construct an auxiliary sequence $\{\upw^t\}_{t=1}^{T_2}$ aligned to $\{\upv^{T_1+t}\}_{t=1}^{T_2}$ with high probability. We approximate the update process of $\{\upw^t\}_{t=1}^{T_2}$ to SGD in traditional linear regression, with separated bounds of variance term (refer to Lemma \ref{variance-upper-bound}) and bias term (refer to Lemma \ref{bias-upper-bound}).
\end{itemize}

We propose our proof process step by step according to the above sketch. First, for clarity, we formally define some of the notations to use. We let bold lowercase letters, for example, $\bold{x} \in \mathbb{R}^d$, denote vectors, and bold uppercase letters, for example, $\mathbf{A} \in \mathbb{R}^{m \times n}$, denote matrices. We apply scalar operators to vectors as the coordinate-wise operators of vectors. For vector $\mathbf{x}\in \mathbb{R}^d$, denote  $\mathbf{\left | x  \right | } \in \mathbb{R}^d$ with $\mathbf{\left | x  \right | }_j = \left | \mathbf{x} _j \right | $. For two vectors $\mathbf{x}, \mathbf{y}\in \mathbb{R}^d$, denote $\mathbf{x}\le \mathbf{y}$, if for all $j\in \left [ d \right ]$, $\mathbf{x}_j\le \mathbf{y}_j$. Additionally, we use $\langle\mathbf{x},\mathbf{y}\rangle_{-i}$ to denote $\sum_{j=1\atop j\neq i}^d\mathbf{x}_j\mathbf{y}_j$. For a sequence of real numbers $\{v^t\}_{t=t_1}^{t_2}$ and $a, b \in \mathbb{R}$ with $a \leq b$, denote $v^{t_1:t_2} \in [a, b]$ to represent that $v^t \in [a, b]$ for all $t \in [t_1, t_2]$. 
% A random variable $x$ is called \emph{symmetric} if there exists $a \in \mathbb{R}$ such that its cumulative distribution function $F_x$ satisfies:
% \begin{equation}
%     F_x(a - c) = 1 - F_x(a + c), \quad \forall c \in \mathbb{R}.
% \end{equation}

% We propose a relaxed variant of Assumption \ref{ass-d}, termed distributional assumptions.
% \begin{assumption}[Distributional Assumptions]\label{ass-d}
%     \item[\textbf{[A$_\text{5}$]}] For any $i \geq 1$, assume $\mathbb{E}[\mathbf{x}_i] = 0$ and $\mathbb{E}[|\mathbf{x}_i|^4] \leq C \mathbb{E}[|\mathbf{x}_i|^2]$ with constant $C > 0$. Furthermore, each $\mathbf{x}_i$ is symmetric and sub-Gaussian with parameter $\sqrt{\lambda_i}$ (where $\lambda_i \in \mathbb{R}_+$), satisfying $\mathbb{E}[e^{\lambda \mathbf{x}_i}] \leq e^{\lambda_i \lambda^2/2}$ for all $\lambda \in \mathbb{R}$. Additionally, covariates $\mathbf{x}_i$ and $\mathbf{x}_j$ are mutually independent for all $i \neq j$.   
%     \item[\textbf{[A$_\text{6}$]}] The noise $\xi$ is zero-mean and sub-Gaussian with parameter $\sigma_\xi > 0$, satisfying $\mathbb{E}[e^{\lambda \xi}] \leq e^{\sigma_\xi^2 \lambda^2/2}$ for all $\lambda \in \mathbb{R}$.
% \end{assumption}

Considering Assumption \ref{ass-d}, the random variable $\Pi_M \upx \in \mathbb{R}^M$ satisfies the sub-Gaussian condition with parameter $\lambda_i^{1/2}$ for all $i \in [1:M]$, and the noise $\xi$ is zero-mean sub-Gaussian with parameter $\sigma_{\xi}$. Moreover, define the random variable $\zeta_{M+1:\infty}=\sum_{i=M+1}^{\infty}\upx_i(\upv_i^*)^2$. For any $D\in\bbN_+$, for simplification, we define
\begin{align}
    &\sigmin(D):=\min_{j\in[1:D]}\lambda_{j}(\upv_j^*)^2,\quad \Barsigmin(D):=\min_{j\in[1:D]}(\upv_j^*)^2,\notag
    \\
    &\Hatsigmax(D):=\max_{j\in[1:D]}\log^{-1}(\upv_j^0),\quad \Tildesigmax(D):=\max_{j\in[D+1:M]}\lambda_j.\notag
\end{align}
We also denote the matrix $\diag\{\lambda_1, \dots, \lambda_M\}$ as $\Lambda_{1:M}$. For $\mathbf{b} \in \mathbb{R}_+^M$, we define $\mathcal{M}(\mathbf{b}) = (\sum_{j=1}^M$ $ \lambda_j \mathbf{b}_j^4)^{1/2}$ and $\sigma^2 = \sigma_{\xi}^2 + \sigma_{\zeta_{M+1:\infty}}^2$, where $\sigma_{\zeta_{M+1:\infty}} = (\sum_{j=M+1}^\infty \lambda_j (\upv_j^*)^4)^{1/2}$. We denote $$\calF^t=\sigma\{\mathbf{v}^0,(\Pi_M\upx^1,\zeta_{M+1:\infty}^1,\xi^1),\cdots,(\Pi_M\upx^t,\zeta_{M+1:\infty}^t,\xi^t)\}$$ as the filtration involving the full information of all the previous $t$ iterations with  $\sigma\{\cdot\}$. 

%\begin{definition}[$\calN$-truncation]
%	Considering finite set $\calN\subset\bbN$ is the truncate set and $\mathbf{v}\in\bbR^{\bbN}$, we notate $\mathbf{v}_{\calN}$ a $\#(\calN)$-dimensional vector composed with those dimensions in $\calN$ of $\mathbf{v}$.
%\end{definition}
% \iffalse
% \begin{definition}[$\mathbf{b}$-bounded coupling]
% Let $\{\mathbf{v}^t\}_{t=0}^T$ be a trajectory of  $M$-dimensional positive vectors depend on time $t$. For $\mathbf{b}\in\bbR_+^{M}$, we call sequence $\{\bar{\mathbf{v}}^t\}_{t=0}^T$ a $\mathbf{b}$-bounded coupling based on $\{\mathbf{v}^t\}_{t=0}^T$ if $\{\bar{\mathbf{v}}^t\}_{t=0}^T$ starts from $\bar{\mathbf{v}}^0=\mathbf{v}^0$ where $\mathbf{v}^0\leq\mathbf{b}$, for each time $t<T$, if $\bar{\mathbf{v}}^t\leq\mathbf{b}$, we let $\bar{\mathbf{v}}^{t+1}=\mathbf{v}^{t+1}$; otherwise $\bar{\mathbf{v}}^{t+1}=\bar{\mathbf{v}}^t$.
% %$\calB_{\mathbf{b},\gamma}(\mathbf{v}^*)$
% \end{definition}
%\begin{definition}[$(\mathbf{b},\gamma)$-bounded potential function of $\calN$-truncation]
%	For a vector $\mathbf{v}\in\bbR_+^n$ ($n\in\bbN$ can be infinite), $\mathbf{b}\in\bbR_+^{\#(\calN)}$ and $\gamma>0$, we call function $\phi:\bbR_+^n\rightarrow\bbR_+$ a $(\mathbf{b},\gamma)$-bounded potential function of $\calN$-truncation if
%	\begin{align}
%		\phi(\mathbf{v})=\begin{cases}
%			\sum_{i\in\bar{\calN}}\sqrt{\mathbf{v}_i}, & \text{ if }|\mathbf{v}_{\calN}|\leq\mathbf{b}\text{ and }\|\mathbf{v}_{\bar{\calN}}\|_1\leq\gamma,
%			\\
%			0, & \text{ otherwise }.
%		\end{cases}
%	\end{align}
%\end{definition}
\subsection{High-Probability Results Guarantee}
Before the analyses of the two phases, we first introduce the guarantee of our high-probability results. We formally define a series of events for each iteration of Algorithm \ref{SGD}. We demonstrate that these events occur with high probability throughout the whole $T$ iterations, which indicates that the control sequence $\{\upq^t\}_{t=0}^{T}$ we define is aligned with the original sequence $\{\upv^t\}_{t=0}^{T}$ with high probability. This fact is the basis of our high-probability results

We begin with $\upx$, the covariate vector in $\bbH$, and its projection $\Pi_M\upx$. Let $\{\upu_i\}_{i=1}^{\infty}$ be an orthonormal basis of $\bbH$ and $\upx_i=\langle\upx,\upu_i\rangle$ for any $i\in[1:\infty)$. The projection operator $\Pi_M:\upH\rightarrow\bbR^M$ is defined as $\Pi_M=\sum_{i=1}^M\upe_i\otimes\upu_i$. Thus the projection $\Pi_M\upx$ satisfies $\Pi_M\upx=(\upx_1,\cdots,\upx_M)^{\top}$. At the $t$-th iteration, Algorithm \ref{SGD} requires sampling $(\Pi_M\upx^{t+1},y^{t+1})$, where $y^{t+1}=\langle\Pi_M\upx^{t+1},\upv_{1:M}^*\rangle+\zeta_{M+1:\infty}^{t+1}+\xi^{t+1}$.
% which is equivalent with sampling the triplet $(\Pi_M\upx^t,\zeta_{M+1:\infty}^t,\xi^t)$. 
In order to simply rule out some low-probabilistic unbounded cases, for each iteration $t$, we define the following four events as:
\begin{equation}
\left\{
\begin{aligned}
 \calE_1^{j,t}&:=\left\{\left|\upx_j^t\right|\leq\lambda_j^{1/2}R\right\}, \quad \forall j\in[1:M],\notag \\
 \calE_2^{j,t}(\upv)&:=\left\{\left|\langle\upv^{\odot2}-\upv_{1:M}^{*\odot2},\Pi_M\upx^{t}\rangle_{-j}\right|\leq r_j(\upv)R\right\}, \quad \forall j\in[1:M],\notag \\
 \calE_3^t&:=\left\{\left|\zeta_{M+1:\infty}^t\right|\leq\sigma_{\zeta_{M+1:\infty}}R\right\}, \\
 \calE_4^t&:=\left\{\left|\xi^t\right|\leq\sigma_{\xi}R\right\},\notag 
\end{aligned}
\right\}
\end{equation}
where $R:=\calO(\log(MT/\delta))$ and $r_j(\upv):=\calO(\sum_{i\neq j}\lambda_i[(\upv_i)^4+(\upv_i^*)^4])^{1/2}$ for any $\upv\in\bbR^M$. 

In Algorithm \ref{SGD}, the original sequence $\{\upv^t\}_{t=0}^T$ follows the coordinate-wise update rule as
\begin{equation}
    \begin{split}
    \upv_j^{t+1}=&\upv_j^t-\eta_t\left(\langle\upv^{t\odot2},\Pi_M\upx^{t+1}\rangle-y^{t+1}\right)\upx_j^{t+1}\upv_j^t\\
    \notag
    =&\upv_j^t-\eta_t\llangle\upv^{t\odot2}-\upv_{1:M}^{*\odot2},\Pi_M\upx^{t+1}\rrangle\upx_j^{t+1}\upv_j^t+\eta_t\left(\zeta_{M+1:\infty}^{t+1}+\xi^{t+1}\right)\upx_j^{t+1}\upv_j^{t},
    \end{split}\notag
\end{equation}
for any $j\in[1:M]$. Based on Assumption \ref{ass-d} and Proposition \ref{prop-A5}, we have
\begin{align}
    \min\left\{\bbP\left(\calE_1^{j,t}\right),\bbP\left(\calE_2^{j,t}(\upv^t)\right),\bbP\left(\calE_3^{t}\right),\bbP\left(\calE_4^{t}\right)\right\}\geq 1-\calO\left(\frac{\delta}{MT^2}\right),\notag
\end{align}
for any $j\in[1:M]$ and $t\in[0:T-1]$. Then we define the compound event as 
$$
\calE:=\left\{\bigcap_{t=0}^{T-1}\left(\left(\bigcap_{j=1}^M\calE_1^{j,t}\right)\bigwedge\left(\bigcap_{j=1}^M\calE_2^{j,t}(\upv^t)\right)\bigwedge\calE_3^t\bigwedge\calE_4^t\right)\right\}.
$$
We can directly obtain the probability union bound as follows:
\begin{align}
    \bbP(\calE)=1-\bbP(\calE^c)\geq&1-\sum_{t=1}^T\left(2-\bbP(\calE_3^t)-\bbP(\calE_4^t)+\sum_{j=1}^M\left(2-\bbP\left(\calE_1^{j,t}\right)-\bbP\left(\calE_2^{j,t}(\upv^t)\right)\right)\right)\notag
    \\
    \geq&1-\calO\left(\frac{\delta}{T}\right).
\end{align} 
The high-probability occurrence of event $\calE$ guarantees our analysis of the coordinate-wise update dynamics for the control sequence $\{\upq^t\}_{t=0}^{T}$ defined in $\bbR^M$ as
\begin{align}\label{update-q-primal}
    \upq_j^{t+1}=\upq_j^t&-\eta_t\left(\left(\upq_j^t\right)^2-\left(\upv_j^*\right)^2\right)\left(\upx_j^{t+1}\right)^2\mathds{1}_{|\upx_j^{t+1}|\leq\lambda_j^{1/2}R}\upq_j^t\notag
    \\
    &-\eta_t\llangle\upq^{t\odot2}-\upv_{1:M}^{*\odot2},\Pi_M\upx^{t+1}\rrangle_{-j}\mathds{1}_{|\langle\upq^{t\odot2}-\upv_{1:M}^{*\odot2},\Pi_M\upx^{t+1}\rangle_{-j}|\leq r_j(\upq^t)R}\upx_j^{t+1}\mathds{1}_{|\upx_j^{t+1}|\leq\lambda_j^{1/2}R}\upq_j^t\notag
    \\
    &+\eta_t\left(\zeta_{M+1:\infty}^{t+1}\mathds{1}_{\left|\zeta_{M+1:\infty}^t\right|\leq\sigma_{\zeta_{M+1:\infty}}R}+\xi^{t+1}\mathds{1}_{\left|\xi^t\right|\leq\sigma_{\xi}R}\right)\upx_j^{t+1}\mathds{1}_{|\upx_j^{t+1}|\leq\lambda_j^{1/2}R}\upq_j^t,
\end{align}
for any $j\in[1:M]$ with initialization $\upq^0=\upv^0$ is consistent with the analysis of $\{\upv^t\}_{t=0}^{T}$ with high probability as Proposition \ref{p1}.
\begin{proposition}\label{p1}
    For any $t\in[1:T]$, we have $\upv^{t}=\upq^{t}$ with probability at least $1-\delta/T$.
\end{proposition}

To simplify the representation of $\{\upq^t\}_{t=0}^{T}$, we introduce four truncated random variables as:
\begin{enumerate}
    \item $\widehat{\upx}\in\bbR^M$ with entries $\widehat{\upx}_j=\upx_j\mathds{1}_{|\upx_j|\leq\lambda_j^{1/2}R}$ for any $j\in[1:M]$,
    \item $\widehat{\upz}(\upq)\in\bbR^M$ with entries $\widehat{\upz}_j(\upq)=\llangle\upq^{\odot2}-\upv_{1:M}^{*\odot2},\Pi_M\upx\rrangle_{-j}\mathds{1}_{|\langle\upq^{\odot2}-\upv_{1:M}^{*\odot2},\Pi_M\upx\rangle_{-j}|\leq r_j(\upq)R}$
    \item $\widehat{\zeta}_{M+1:\infty}=\zeta_{M+1:\infty}\mathds{1}_{\zeta_{M+1:\infty}\leq \sigma_{\zeta_{M+1:\infty}}R}$,
    \item $\widehat{\xi}=\xi\mathds{1}_{\xi\leq \sigma_{\xi}R}$. 
\end{enumerate}
Thus, the coordinate-wise update dynamics for $\{\upq^{t}\}_{t=0}^T$ in Eq.~\eqref{update-q-primal} can be represented as:
\begin{align}\label{update-q}
    \upq_j^{t+1}=&\upq_j^t-\eta_t\left(\left(\upq_j^t\right)^2-\left(\upv_j^*\right)^2\right)\left(\widehat{\upx}_j^{t+1}\right)^2\upq_j^t-\eta_t\widehat{\upz}_j^{t+1}(\upq^t)\widehat{\upx}_j^{t+1}\upq_j^t\notag\notag
    \\
    &+\eta_t\left(\widehat{\zeta}_{M+1:\infty}^{t+1}+\widehat{\xi}^{t+1}\right)\widehat{\upx}_j^{t+1}\upq_j^t,
\end{align}
for any $j\in[1:M]$.
% The control sequence $\{\upq^t\}_{t=0}^{T}$ follows the coordinate-wise update rule:
% \begin{align}
%      \upq_j^{t+1}=\upq_j^t-\eta_t\llangle\upq^{t\odot2}-\upq_{1:M}^{*\odot2},\widehat{\upx}_{1:M}^{t+1}\rrangle\widehat{\upx}_j^{t+1}\upq_j^t+\eta_t\left(\widehat{\zeta}_{M+1:\infty}^{t+1}+\widehat{\xi}^{t+1}\right)\widehat{\upx}_j^{t+1}\upq_j^{t},\quad \forall j\in[1:M],\notag
% \end{align}
% with initialization $\upq^0=\upv^0$. When $\mathcal{E}$ holds, the trajectories $\{\upv^t\}_{t=1}^{T}$ and $\{\upq^t\}_{t=1}^T$ coincide, yielding $\upv^{t'}=\upq^{t'}$ for any fixed $t'\in[1:T]$ with probability at least $1-\delta$. Therefore, throughout Phase I and the initial segment of Phase II, our analysis focuses on deriving high-probability bounds through the dynamics of $\upq^t$.



\subsection{Proof of Phase I}\label{phase 1}
% [denote the corresponding theorem in main body as "informal version of xx"]

In this section, we formally propose the proof techniques of \textbf{Phase I} in Theorem \ref{theorem_1}. Theorem \ref{theorem_1} establishes that Algorithm \ref{SGD} adaptively selects a effective dimension $D \in \mathbb{N}_+$ with the following convergence properties: (1) for $j \leq D$, $\upv_j^{T_1}$ converges to an adaptive neighborhood of $\upv_j^*$; (2) for $j > D$, $\upv_j^{T_1}$ is bounded by $\frac{3}{2}\max\{\upv_j^*,2\upv_j^0\}$. Theorem \ref{theorem_1} specifies the intrinsic relationship between Algorithm \ref{SGD}'s key parameters: the recommended step size $\eta$, effective dimension $D$, and total sample size $T$. Furthermore, under Assumption \ref{ass-ss}, Phase II analysis demonstrates the optimality of the effective dimension $D$ selected in Theorem \ref{theorem_1}.
 

% Theorem \ref{theorem_1} states that the $T_1$-iteration output of Algorithm \ref{SGD}, initialized at $\mathbf{v}_0$ with a constant step size $\eta$, satisfies the following conditions with high probability:
% 1) For $1 \leq j \leq D$, $\mathbf{v}_j^{T_1}$ converges to $\mathbf{v}_j^{*}$ with an accuracy of $c_1\mathbf{v}_j^{*}$, i.e., $|\mathbf{v}_j^{T_1} - \mathbf{v}_j^{*}| \leq c_1\mathbf{v}_j^{*}$, where $c_1 \in (0, 1/2)$;
% 2) For $D+1 \leq j \leq M$, $\mathbf{v}_j^{T_1}$ remains close to either its initial value $\mathbf{v}_j^{0}$ or $\upv_j^*$. Define $\hat{\mathbf{v}}^* \in \mathbb{R}^M$ as $\hat{\mathbf{v}}_j^* = \max\left\{\frac{3}{2}\mathbf{v}_j^*, 3\mathbf{v}_j^0\right\}$ for any $j \in [M]$. Set $\mathbf{b} = ((1 + c_1)(\mathbf{v}_{1:D}^*)^{\top}, (\hat{\mathbf{v}}_{D+1:M}^*)^{\top})^{\top}$, where $c_1 \in (0, 1/2)$.

\begin{theorem}\label{theorem_1}[Formal version of Theorem \ref{phase-I-informal} ]
	Under Assumption \ref{ass-d}, consider the dynamic generated via Algorithm \ref{SGD} with initialization $\mathbf{v}_0$. Denote (1) the threshold vector $\hat{\mathbf{v}}^* \in \mathbb{R}^M$ with coordinate $\hat{\mathbf{v}}_j^* = \max\left\{\frac{3}{2}\mathbf{v}_j^*, 3\mathbf{v}_j^0\right\}$ for any $j \in [1:M]$; (2) the composite vector $\mathbf{b} = ((1 + c_1)(\mathbf{v}_{1:D}^*)^{\top}, (\hat{\mathbf{v}}_{D+1:M}^*)^{\top})^{\top}$, where the scaling constant $c_1 \in (0, 1/2)$. Let the step size $\eta$ satisfy $\eta \leq \widetilde{\Omega}\left(\frac{c_1^2 \Barsigmin(\max\{D,M\})}{[\sigma^2 + \mathcal{M}^2(\upb)]^2}\right)$ for the given effective dimension $D \in \mathbb{N}_+$. If the iteration number $T_1$ requires:
    \begin{align}
        T_1\in\begin{cases}
        \left[\widetilde{\mathcal{O}}\left(\frac{\sigma^2 + \mathcal{M}^2(\upb)}{c_1^2 \eta \sigmin(D)}\right): \widetilde{\Omega}\left(\frac{\Tildesigmax^{-1}(D)}{\eta^2[\sigma^2 + \mathcal{M}^2(\upb)]}\right)\right], \quad &\text{ if }D < M,\notag
        \\
\left[\widetilde{\mathcal{O}}\left(\frac{\sigma^2 + \mathcal{M}^2(\upb)}{c_1^2 \eta \sigmin(M)}\right):\infty\right), \quad &\text{ otherwise},
    \end{cases}
    \end{align}
    % When $D < M$, set the iteration number $T_1 \in \left[\widetilde{\mathcal{O}}\left(\frac{\sigma^2 + \mathcal{M}^2(\upb)}{c_1^2 \eta \sigmin(D)}\right), \widetilde{\Omega}\left(\frac{\Tildesigmax^{-1}(D)}{\eta^2[\sigma^2 + \mathcal{M}^2(\upb)]}\right)\right]$. Otherwise, let $T_1 \geq \widetilde{\mathcal{O}}\left(\frac{\sigma^2 + \mathcal{M}^2(\upb)}{c_1^2 \eta \sigmin(M)}\right)$. 
    then the dynamic satisfies the following convergence property:
    \begin{align}\label{thm-1-eq}
        \upv_j^{T_1} \in \begin{cases}
            \left[\upv_j^{*}-c_1\upv_j^*, \upv_j^{*}+c_1\upv_j^*\right], &\text{ if }j\in[1:D],
            \\
            \left[0, \frac
            {3}{2}\max\{\upv_j^*,2\upv_j^0\}\right], &\text{ otherwise },
        \end{cases}
    \end{align}
    with probability at least $1-\delta$.
\end{theorem}

Before the beginning of our proof, we define the $\mathbf{b}$-capped coupling processes used in the following lemmas as below. 
\begin{definition}[$\mathbf{b}$-capped coupling] \label{def:b-capped}
  Let $\{\mathbf{q}^t\}_{t=0}^T$ be a Markov chain in $\mathbb{R}_+^M$ adapted to filtration $\{\mathcal{F} ^{t}\}_{t=0}^T$. Given threshold vector $\mathbf{b}\in\bbR_+^{M}$, the $\mathbf{b}$-capped coupling process $\{\bar{\mathbf{v}}^t\}_{t=0}^T$ with initialization $\bar{\mathbf{v}}^0=\mathbf{q}^0\le \mathbf{b}$ evolves as:
  \begin{enumerate}
      \item Updating state: If $\bar{\mathbf{v}}^t\le \mathbf{b}$, let $\bar{\mathbf{v}}^{t+1}=\mathbf{q}^{t+1}$,
      \item Absorbing state: Otherwise, maintain $\bar{\mathbf{v}}^{t+1}=\bar{\mathbf{v}}^{t}$. 
  \end{enumerate} 
\end{definition}



\subsubsection{Part I: the coordinate-wise upper bounds of $\upv^{T_1}$.}
In this part, we establish coordinate-wise upper bounds for $\upv^{T_1}$ in Lemma \ref{lemma_1}. For each coordinate $i \in [1:M]$, we develop a geometrically compensated supermartingale $\{u_i^t:=(1-\eta\Theta(\lambda_i(\upv_i^*)^2))^{-t}(\Bar{\upv}_i^t-\upv_i^*)\}_{t=1}^{T_1}$ using the $\mathbf{b}$-capped coupling sequence $\{\Bar{\upv}^t\}_{t=0}^{T_1}$ derived from the control sequence $\{\upq^t\}_{t=0}^{T_1}$. We precisely calculate the sub-Gussian parameters of the supermartingale increments through geometric series summation over $\mathcal{S}$ and linear summation over $\mathcal{S}^c$. The analysis enables the application of Bernstein-type inequalities to establish the claimed concentration results in Lemma \ref{lemma_1}.

\begin{lemma}\label{lemma_1}[Formal version of Lemma \ref{phase-1-step-1}]
Under the setting of Theorem \ref{theorem_1}, let $\{\mathbf{q}^t\}_{t=0}^{T_1}$ be a Markov chain with its $\mathbf{b}$-capped coupling process $\{\bar{\mathbf{v}}^t\}_{t=0}^{T_1}$. When $\eta\leq\widetilde{\Omega}\left(\frac{1}{\sigma^2+\calM^2(\upb)}\right)$, the inequality $\bar{\upv}^t\geq\textbf{0}$ holds for any $t\in[1:T_1]$. For any $\mathbf{v}\in \mathbb{R}^M$, define the truncation event $\calA(\mathbf{v}):=\{\mathbf{v}\leq\mathbf{b}\}$. For $\delta\in(0,1)$, the following conditions guarantee that $\calA(\Bar{\mathbf{v}}^{T_1})$ holds with probability at least $1-\frac{\delta}{6}$:
\begin{enumerate}
    \item Dominant coordinates condition: $\Barsigmin(D)\geq\frac{\eta}{c_1^2}\calO([\sigma^2+\calM^2(\upb)]\log^5(MT_1/\delta))$,
    \item Residual spectrum condition: $\Tildesigmax(D)\geq T_1\eta^2\calO([\sigma^2+\calM^2(\upb)]\log(\max\{M-D,0\}T_1/\delta)$ $\log^4(MT_1/\delta))$.
\end{enumerate}
\end{lemma}

\begin{proof}
Define the random variable 
$$
p_j^{t+1}:=\left(\left((\bar{\mathbf{v}}_j^{t})^2-(\mathbf{v}_{j}^{*})^2\right)\hat{\mathbf{x}}_{j}^{t+1}+\hat{\upz}_j^{t+1}(\bar{\upv}^t)-\hat{\zeta}_{M+1:\infty}^{t+1}-\hat{\xi}^{t+1}\right)\hat{\mathbf{x}}_j^{t+1}
$$
for any $j\in[1:M]$ and $t\in[0:T_1-1]$. Then in the updating state of $\{\bar{\upv}^t\}_{t=0}^{T_1}$, we have
\begin{align}
    \bar{\upv}_j^{t+1}=(1-\eta p_j^{t+1})\bar{\upv}_j^{t},\quad \forall j\in[1:M].
\end{align}
Based on the boundedness of $p_j^{t+1}$ and the appropriately chosen step size $\eta\leq\widetilde{\Omega}\left(\frac{1}{\sigma^2+\calM^2(\upb)}\right)$, if $\bar{\upv}^t>\textbf{0}$, then we have $\bar{\upv}^{t+1}\geq\frac{1}{2}\bar{\upv}^t$. Since $\bar{\upv}^0>0$,  we have $\bar{\upv}^t>0$ for any $t\in[1:T_1]$ by induction.
Let $\bar{\tau}_{\mathbf{b} }$ be the stopping time when $\bar{\mathbf{v}}_j^{\bar{\tau}_{\mathbf{b} }} > \mathbf{b}_j$ for a certain coordinate $j\in[1:M]$, i.e.,
\begin{equation}\nonumber
      \bar{\tau}_{\mathbf{b} }=\inf_{t}\left \{ t:\exists j\in[1:M], \text{ s.t. }\bar{\mathbf{v}}_j^t > \mathbf{b}_j \right\}.
\end{equation}
For each coordinate $1\le j\le M$, let $\bar{\tau}_{\mathbf{b},j }$ be the stopping time when $\bar{\mathbf{v}}^{\bar{\tau}_{\mathbf{b},j }}_j > \mathbf{b}_j$, i.e.,
\begin{equation}\nonumber
\bar{\tau}_{\mathbf{b},j }=\inf_{t}\left \{ t:\bar{\mathbf{v}}_j^t > \mathbf{b}_j \right \}.
\end{equation}
Based on Definition \ref{def:b-capped}, when the stopping time $\bar{\tau}_{\mathbf{b}}=t_2$ occurs for some $t_2\in[1:T_1]$, the coupling process satisfies $\bar{\mathbf{v}}^t=\bar{\mathbf{v}}^{t_2}$ for all $t>t_2$. We categorize the following two cases and analyze the probability bound respectively. 

\noindent \textbf{Case I:} Suppose there exists $j\in[1:D]$ such that $\bar{\tau}_{\mathbf{b},j }=t_2$. 
% Since $\bar{\mathbf{v}}^{t}$ is $\mathcal{F}^t$-measurable, 
That is, the event 
$\mathcal{A} \left ( \bar{\mathbf{v}} ^t \right ) $ holds for all $t\in[0:t_2-1]$. 
% According to Lemma \ref{aux-1}, we establish the sub-Gaussian property for for any $t\in[0:T_1-1]$. Consequently, $\mathcal{Z}_j^{t+1}$ admits high-probability concentration bounds. Given $\bar{\upv}^t$, the iterates admit the recursive bound: $|\bar{\upv}^{t+1}|\leq(1+\widetilde{\calO}(\eta))|\bar{\upv}^t|$ with probability at least $1-\frac{\delta}{12MT_1}$. 
The boundedness of $p_j^{t+1}$ and the dominant coordinates condition of $\eta$ in Lemma \ref{lemma_1} indicate that $\bar{\upv}_j^t$ must traverse in and out of the threshold interval $\left[\frac{1}{1+c_1}\mathbf{b}_j,\mathbf{b}_j\right]$ before exceeding $\upb_j$.
We aim to estimate the following probability for coordinates $j\in[1:D]$ and time pairs $t_1<t_2\in[1:T_1]$:
\begin{equation}\nonumber
\bbP\left(\mathcal{B}_{t_1}^{\bar{\tau}_{\mathbf{b},j }=t_2}(j)=\left \{ \bar{\mathbf{v}}_j^{t_1}\leq\frac{1+c_1/2}{1+c_1}\mathbf{
b} _j\bigwedge \bar{\mathbf{v}}_j^{t_1:t_2-1}\in\left[\frac{1}{1+c_1}\mathbf{b}_j,\mathbf{b}_j\right]\bigwedge\bar{\mathbf{v}}_j^{t_2}>\mathbf{b}_j  \right \}\right). 
\end{equation}
For any $t\in[t_1:t_2-1]$, we have 
\begin{equation}\label{mar-concen-1}
    \begin{aligned}
        \bbE\left[\bar{\mathbf{v}}_j^{t+1}-\mathbf{v}_j^*\mid\calF^{t}\right]=&\bbE_{\mathbf{x}_{1:M}^{t+1},\xi^{t+1},\zeta_{M+1:\infty}^{t+1}}\left[\bar{\mathbf{v}}_j^{t}-\mathbf{v}_j^*-\eta p_j^{t+1}\bar{\mathbf{v}}_j^{t}\right]
		\\
		\overset{\text{(a)}}{\leq}&\left(1-\frac{1}{2}\eta\lambda_j\bar{\mathbf{v}}_j^{t}(\bar{\mathbf{v}}_j^{t}+\mathbf{v}_j^*)\right)(\bar{\mathbf{v}}_j^{t}-\mathbf{v}_j^*)
		\\
		\leq&\left(1-\frac{1+c_1/2}{\left(1+c_1\right)^2}\eta\lambda_j(\mathbf{v}_j^*)^2\right)(\bar{\mathbf{v}}_j^{t}-\mathbf{v}_j^*),
    \end{aligned}
\end{equation}
where (a) is due to Assumption \ref{ass-d} and Lemma \ref{aux-1.1}. By applying Lemma \ref{aux-1} to $p_j^t$, we demonstrate that $p_j^t$ satisfies the sub-Gaussian property for all $t\in[0:T_1-1]$. Thus we have
\begin{equation}
\small
\begin{split}
    \bbE\left[\exp\left\{\lambda\left(\bar{\mathbf{v}}_j^{t+1}-\bbE[\bar{\mathbf{v}}_j^{t+1}\mid\calF^t]\right)\right\}\mid\calF^t\right]\leq \exp\left\{\frac{\lambda^2\eta^2\lambda_j(\upv_j^*)^2\calO\left(\left[\sigma^2+\mathcal{M}^2(\upb)\right]\log^4(MT_1/\delta)\right)}{2}\right\},\notag
\end{split}
\end{equation}
for any $\lambda\in\bbR$.
% Next, the absolute value of $\bar{\mathbf{v}}_j^{t+1}-\bar{\mathbf{v}}_j^{t}$ over $[t_1:t_2-1]$, can be bounded as follows,
% \begin{equation}\label{bounded-finite-difference}
%     \begin{aligned}
%         \left|\bar{\mathbf{v}}_j^{t+1}-\bar{\mathbf{v}}_j^{t}\right|\leq&\eta\left[\left|\langle\bar{\mathbf{v}}^{t\odot 2}-\mathbf{v}_{1:M}^{*\odot 2},\mathbf{x}_{1:M}^{t}\rangle\right|+\left|\zeta_{M+1:\infty}^t\right|+\left|\xi^{t}\right|\right]\mathbf{x}_j\bar{\mathbf{v}}_j^{t}
% 		\\
%             \leq&\eta\calO\left(\lambda_j^{1/2}\upv_j^*\left(\sigma_{\xi}+\sigma_{\zeta_{M+1:\infty}}+\mathcal{M}^2(\upb)\right)\log(MT_1/\delta)\right)
% 		% \leq&(1+c_1)^2\eta^2\lambda_j(\mathbf{v}_j^*)^2\left[\sigma_{\xi}^2+M(\mathbf{b})\right],
%     \end{aligned}
% \end{equation}
% where the last inequality follows from combining Lemma \ref{aux-1} and the definitions of $\upx_{1:M}$, $\zeta_{M+1:\infty}$ and $\xi$. Notice Eq.~\eqref{bounded-finite-difference} implies that 
% \begin{align}
%     &\left|\bar{\mathbf{v}}_j^{t+1}-\mathbf{v}_j^*-\left(1-\frac{1+c_1/2}{\left(1+c_1\right)^2}\eta\lambda_j(\mathbf{v}_j^*)^2\right)(\bar{\mathbf{v}}_j^{t}-\mathbf{v}_j^*)\right|^2\leq\eta^2\calO\left(\lambda_j(\upv_j^*)^2\left(\sigma^2+\mathcal{M}^2(\upb)\right)\log^2(MT_1/\delta)\right).\notag
% \end{align}
%is derived from the independence between $\mathbf{x}_i$ and $\mathbf{x}_j$ for any $i\neq j$. 
Combining Lemma \ref{aux-2} with Eq.~\eqref{mar-concen-1}, we can establish the probability bound for event $\mathcal{B}_{t_1}^{\bar{\tau}_{\mathbf{b},j }=t_2}(j)$ for any time pair $t_1<t_2\in[1:T_1]$ as
\begin{align}\label{probability-1}
\Pro\left(\mathcal{B}_{t_1}^{\bar{\tau}_{\mathbf{b},j }=t_2}(j)\right )\leq&\exp\left\{-\frac{c_1^2(\mathbf{v}_j^*)^2}{\eta\calO\left([\sigma^2+\mathcal{M}^2(\upb)]\log^4(MT_1/\delta)\right)}\right\}.
\end{align}
	
\noindent \textbf{Case II:} Suppose there exists $j\in[D+1:M]$ such that $\bar{\tau}_{\mathbf{b},j }=t_2$.  Similarly, $\bar{\upv}_j^t$ must traverse in and out of the threshold interval $[\frac{2}{3}\upb_j,\upb_j]$ before exceeding $\upb_j$. Therefore, we aim to estimate the following probability for coordinates $j\in[D+1:M]$ and time pairs $t_1<t_2\in[1:T_1]$:
\begin{equation}\nonumber
    \bbP\left(\calC_{t_1}^{\bar{\tau}_{\mathbf{b},j }=t_2}(j)=\left\{\bar{\mathbf{v}}_j^{t_1}\leq\frac{3}{4}\mathbf{b}_j\bigwedge\bar{\mathbf{v}}_j^{t_1:t_2-1}\in\left[\frac{2}{3}\upb_j,\mathbf{b}_j\right]\bigwedge \bar{\mathbf{v}}_j^{t_2}>\mathbf{b}_j \right\}\right).
\end{equation}
For any $t\in[t_1:t_2-1]$, we have 
\begin{equation}\label{mar-concen-2}
    \begin{aligned}
         \bbE\left[\bar{\mathbf{v}}_j^{t+1}-\mathbf{v}_j^*\mid\calF^{t}\right]=&\bbE_{\mathbf{x}_{1:M}^{t+1},\xi^{t+1},\zeta_{M+1:\infty}^{t+1}}\left[\bar{\mathbf{v}}_j^{t}-\mathbf{v}_j^*-\eta p_j^{t+1}\bar{\mathbf{v}}_j^{t}\right]
		\\
		\leq&\left(1-\frac{1}{2}\eta\lambda_j\bar{\mathbf{v}}_j^{t}(\bar{\mathbf{v}}_j^{t}+\mathbf{v}_j^*)\right)(\bar{\mathbf{v}}_j^{t}-\mathbf{v}_j^*)
		\\
		\leq &\bar{\mathbf{v}}_j^{t}-\mathbf{v}_j^*.
    \end{aligned}
\end{equation}
Similarly, based on Lemma \ref{aux-1}, we have
\begin{equation}
    \small
    \begin{split}
        \bbE\left[\exp\left\{\lambda(\bar{\upv}_j^{t+1}-\bbE[\bar{\upv}_j^{t+1}\mid\calF^t])\right\}\mid\calF^t\right]\leq\exp\left\{\frac{\lambda^2\eta^2\lambda_j(\upb_j^*)^2\calO\left(\left[\sigma^2+\mathcal{M}^2(\upb)\right]\log^4(MT_1/\delta)\right)}{2}\right\},\notag
    \end{split}
\end{equation}
for any $\lambda\in\bbR$. Combining Lemma \ref{aux-2} with Eq.~\eqref{mar-concen-2}, we can establish the  probability bound for event $\mathcal{C}_{t_1}^{\bar{\tau}_{\mathbf{b},j }=t_2}(j)$ for any time pair $t_1<t_2\in[1:T_1]$ as
	\begin{align}\label{probability-2}
		\Pro\left (\calC_{t_1}^{\bar{\tau}_{\mathbf{b},j }=t_2}(j)\right )\leq\exp\left\{-\frac{1}{T\eta^2\lambda_j\calO\left([\sigma^2+\calM^2(\upb)]\log^2(MT_1/\delta)\right)}\right\}.
	\end{align}
% Finally, we can obtain the following probability bound of event $(\calA(\bar{\mathbf{v}}^{T_1}))^c$ with above probability bounds Eq.~\eqref{probability-1} and Eq.\eqref{probability-2}, and dominant coordinates condition and residual spectrum condition:

Finally, combining the probability bounds Eq.~\eqref{probability-1} and Eq.\eqref{probability-2} with the dominant coordinates condition and residual spectrum condition in Lemma \ref{lemma_1}, we obtain the following probability bound for complement event $\calA^c(\bar{\mathbf{v}}^{T_1})$:
	\begin{align}\label{union-1}
		\Pro\left(\calA^c(\bar{\mathbf{v}}^{T_1})\right ) \leq&\sum_{j=1}^D\sum_{1\leq t_1<t_2\leq T_1}\Pro\left(\mathcal{B}_{t_1}^{\bar{\tau}_{\mathbf{b},j }=t_2}(j)\right)\notag+\sum_{j=D+1}^M\sum_{1\leq t_1<t_2\leq T_1}\Pro\left(\calC_{t_1}^{\bar{\tau}_{\mathbf{b},j }=t_2}(j)\right) \notag
		\\
		\leq&\frac{NT_1^2}{2}\exp\left\{-\frac{c_1^2\min_{1\le j\le D}(\mathbf{v}_j^*)^2}{\eta\calO\left(\left[\sigma^2+\calM^2(\upb)\right]\log^4(MT_1/\delta)\right)}\right\}\notag
		\\
		&+\max\{M-D,0\}T_1\exp\left\{-\frac{\min_{D+1\le j\le M}\lambda_j^{-1}}{T_1\eta^2\calO\left([\sigma^2+\calM^2(\upb)]\log^4(MT_1/\delta)\right)}\right\}\notag
		\\
		\leq&\frac{\delta}{12}.
	\end{align}
\end{proof}

%\begin{lemma}\label{lemma_2}
%	Under the setting of Lemma \ref{lemma_1}, we have $\|\bar{\mathbf{v}}_{\bar{\calN}}^T\|_1\leq\gamma$ with probability $1-\frac{\delta}{6}$.
%\end{lemma}
%\begin{proof}
%	We begin with the discrete dynamic of $|\bar{\mathbf{v}}_j^t|$ in expectation for any $j\in\bar{\calN}$. When $|\bar{\mathbf{v}}_{\calN}^t|\leq\mathbf{b}$ and $\|\bar{\mathbf{v}}_{\bar{\calN}}^t\|\leq\gamma$, we obtain
%	\begin{align}\label{out-truncation}
%		\bbE\left[|\bar{\mathbf{v}}_j^{t+1}|\mid\bar{\mathbf{v}}^t\right]\overset{\text{(a)}}{=}&|\bar{\mathbf{v}}_j^{t}|\bbE_{\mathbf{x}^{t},\xi^{t}}\left[1-\eta(\bar{\mathbf{v}}^{t\odot 2}-\mathbf{v}^{*\odot 2})^{\top}\mathbf{x}^{t}\cdot\mathbf{x}_j^{t}+\eta\xi^{t}\mathbf{x}_j^{t}\right]\notag
%		\\
%		=&|\bar{\mathbf{v}}_j^{t}|[1-\eta\lambda_j((\mathbf{v}_j^t)^2-(\mathbf{v}_j^*)^2)]\notag
%		\\
%		\leq&|\bar{\mathbf{v}}_j^{t}|+\eta\lambda_j(\mathbf{v}_j^*)^2|\bar{\mathbf{v}}_j^{t}|,
%	\end{align}
%	where (a) is derived from the setting of Theorem \ref{theorem_1} that \dnote{size of $\eta$}. Therefore, we have
%	\begin{align}\label{bound-remain}
%		\bbE[\|\bar{\mathbf{v}}_{\bar{\calN}}^{t+1}\|_1\mid\bar{\mathbf{v}}^t]\leq(1+\eta\lambda_{\hat{i}(\calN)}(\mathbf{v}_{\hat{i}(\calN)}^*)^2)\|\bar{\mathbf{v}}_{\bar{\calN}}^{t}\|_1,
%	\end{align}
%	by summing over all dimensions in $\bar{\calN}$. In addition, its obvious that Eq.~\eqref{bound-remain} still holds when $|\bar{\mathbf{v}}_{\calN}^{t}|>\mathbf{b}$ or $\|\bar{\mathbf{v}}_{\bar{\calN}}^{t}\|_1>\gamma$. Finally, we estimate the probability of event  $\{\|\bar{\mathbf{v}}_{\bar{\calN}}^{t}\|>\gamma\}$ as following:
%	\begin{align}
%		\Pro\left\{\|\bar{\mathbf{v}}_{\bar{\calN}}^{t}\|>\gamma\right\}\overset{\text{(b)}}{\leq}&\frac{(1+\eta\lambda_{\hat{i}(\calN)}(\mathbf{v}_{\hat{i}(\calN)}^*)^2)^T\|\mathbf{v}_{\bar{\calN}}^{0}\|_1}{\gamma}\notag
%		\\
%		\overset{\text{(c)}}{\leq}&\frac{\exp\left\{T\eta\lambda_{\hat{i}(\calN)}(\mathbf{v}_{\hat{i}(\calN)}^*)^2\right\}\|\mathbf{v}_{\bar{\calN}}^{0}\|_1}{\gamma}\notag
%		\\
%		\leq&\frac{\delta}{6},
%	\end{align}
%	where (b) and (c) follow from Markov's inequality and setting $T\eta\leq\frac{1}{\lambda_{\hat{i}(\calN)}(\mathbf{v}_{\hat{i}(\calN)}^*)^2}\log\frac{\delta\gamma}{6\|\mathbf{v}_{\bar{\calN}}^{0}\|}$, respectively.
%\end{proof}

% It is worth noting that Lemma \ref{lemma_1} provides an upper bound for $\mathbf{v}^{T_1}$ with high probability. For each $1\le j \le D$, the following lemma shows that there exists at least an iteration $1\le t \le T_1$ such that $\mathbf{v}_j^t$ will be no less than $(1-c_1/2)\mathbf{v}_j^*$ with high probability.
Lemma \ref{lemma_1} establishes the adaptive high-probability upper bounds for each coordinate of $\bar{\upv}^{T_1}$. According to the construction methodology of the coupling process $\{\bar{\upv}^t\}_{t=0}^{T_1}$, these bounds can be naturally extended to $\upq^{T_1}$. Moreover, the high-probability consistency between control sequence $\{\upq^t\}_{t=0}^{T}$ and original sequence $\{\upv^t\}_{t=0}^{T}$ (refer to Proposition \ref{p1}) allows the direct application of Lemma \ref{lemma_1} to $\upv^{T_1}$. It similarly holds for  Lemmas \ref{lemma-2} and \ref{lemma-3}, respectively.

\subsubsection{Part II: The coordinate-wise lower bounds of $\bar{\upv}^{T_1}$}
Deriving a direct high-probability lower bound for $\bar{\upv}^{T_1}$ proves to be a challenge. We turn to the lower bound of $\max_{t\leq T_1} \bar{\upv}_i^t$ during $T_1$ iterations. First  we propose Lemma \ref{lemma-2} to construct such bounds for $\max_{t\leq T_1}\bar{\upv}_j^t$ adaptively over $j\in[1:D]$. We derive a subcoupling sequence $\{\Breve{\upv}^{i,t}\}_{t=0}^{T_1}$ from the original coupling sequence $\{\Bar{\upv}^t\}_{t=0}^{T_1}$ for any $i\in\mathcal{S}$. Each subcoupling sequence undergoes logarithmic transformation to generate a linearly compensated submartingale $\{-t\log(1+\eta\calO(\lambda_i(\upv_i^*)^2))+\log(\breve{\upv}_i^{i,t})\}_{t=1}^{T_1}$. These $|\mathcal{S}|$ submartingales exhibit monotonic growth with sub-Gaussian increments. Applying Bernstein-type concentration inequalities, we obtain $\max_{t\leq T_1}\upv_i^t\geq(1-c_1/2)\upv_i^*$ with high probability for any $i\in\mathcal{S}$ in Lemma \ref{lemma-2}.  
 
\begin{lemma}\label{lemma-2}[Formal version of Lemma \ref{phase-1-step-2}]
	Under the setting of Lemma \ref{lemma_1}, let  $$\eta\leq\frac{c_1\log^{-4}(MT_1/\delta)\min_{j\in[1:D]}(\upv_j^*)^2}{\calO(\sigma^2+(1+C)\mathcal{M}^2(\upb))}$$ and 
    $$
    T_1\geq\max\left\{\frac{\calO\left(\max_{j\in[1:D]}-\log(\upv_j^0)\right)}{c_1\eta\sigmin(D)},\frac{\calO\left([\sigma^2+\mathcal{M}^2(\upb)]\log^8(MT_1/\delta)\right)}{c_1^2\min_{j\in[1:D]}(\lambda_j(\upv_j^*)^4)}\right\}
    $$
    The combined event set satisfies $\mathbb{P}\left(\left(\bigcap_{j=1}^D\calE_{1,j}\right)\bigcup\calE_2\right) \geq 1 - \frac{\delta}{6}$. where $$\calE_{1,j} := \left\{\max_{t\leq T_1}\bar{\upv}_j^t\geq\frac{1-c_1/2}{1+c_1}\upb_j \right\},\quad \forall j\in[1:D],$$ and $\calE_2 := \left\{ \calA^c(\bar{\upv}^{T_1})\right\}$.
    % one of the following cases holds with probability at least $1-\frac{\delta}{6N}$:
\end{lemma}
\begin{proof}
    For a fixed $j\in[1:D]$, we define 
    % $Y_j^t:=\llangle\bar{\upv}^{t\odot 2}-\upv_{1:M}^{*\odot 2},\upx_{1:M}^{t}\rrangle-\left((\bar{\upv}_j^t)^2-(\upv_j^*)^2\right)\upx_j^t-\zeta_{M+1:\infty}^t-\xi^{t}$ for any $t\in[0:T_1-1]$ and 
    the subcoupling $\{\breve{\upv}^t\}_{t=0}^{T_1}$ with initialization $\breve{\upv}^0=\bar{\upv}^0$ as follows: 
    \begin{enumerate}
        \item Updating state: If 
        % $|Y_j^t|\leq R_j:=\calO\left([\sigma^2+\mathcal{M}^2(\upb)]^{1/2}\log^2(MT_1/\delta)R\right)$ and the 
        event $\calB_t(j)=\left\{\calA(\breve{\upv}^t)\bigwedge\breve{\upv}_j^t<\frac{1-c_1/2}{1+c_1}\upb_j\right\}$ holds, let $\breve{\upv}^{t+1}=\bar{\upv}^{t+1}$,
        \item Multiplicative scaling state: Otherwise, let $\breve{\upv}^{t+1}=\left(1+\frac{c_1(1-c_1)\eta}{2}\lambda_{j}(\upv_{j}^*)^2\right)\breve{\upv}^{t}$.
    \end{enumerate}
    We aim to demonstrate that $-t\log(1+\frac{c_1(1-c_1)\eta}{2}\lambda_{j}(\upv_{j}^*)^2)+\log(\breve{\upv}_j^t)$ is a submartingale. 
    If event $\calB_t^c(j)$ holds, we directly obtain $\bbE[\log(\breve{\upv}_j^{t+1}) \mid \calF^t] \geq \log(1+\frac{c_1(1-c_1)\eta}{2}\lambda_j(\upv_j^*)^2) + \log(\breve{\upv}_j^t)$. Otherwise, letting 
    $$
    w_j^t:=\hat{z}_j^t(\bar{\upv}^{t-1})-\hat{\zeta}_{M+1:\infty}^t-\hat{\xi}^t,\quad \forall t\in[1:T_1],
    $$ 
    we have
    % If event $\calB_t^c(j)$ occurs or $Y_j^t$ escapes from $\calB_{R_j}(0)$, it is straightforward to obtain $\bbE\left[\log(\breve{\upv}_j^{t+1})\mid\calF^t\right]\geq\log\left(1+\frac{c_1(1-c_1)\eta}{2}\lambda_{j}(\upv_{j}^*)^2\right)+\log(\breve{\upv}_j^t)$. Otherwise, we have
	\begin{align}
		\bbE\left[\log(\breve{\upv}_j^{t+1})\mid\calF^t\right]=&\bbE\left[\log(\bar{\upv}_j^{t+1})\mid\calF^t\right]\notag
		\\
		=&\bbE_{\upx_{1:M}^{t+1},\xi^{t+1},\zeta_{M+1:\infty}^{t+1}}\left[\log\left(1-\eta\left((\bar{\upv}_j^t)^2-(\upv_j^*)^2\right)(\hat{\upx}_j^{t+1})^2-\eta w_j^{t+1}\hat{\upx}_j^{t+1}\right)\right]\notag
        \\
        &+\log(\bar{\upv}_j^t)\notag
	\\
	\overset{\text{(a)}}       {\geq}&\log\left(1+\frac{3c_1(1-c_1)\eta}{4}\lambda_j(\upv_j^*)^2\right)\notag
        \\
        &-\eta^2\lambda_j\calO\left(\left[\sigma^2+(1+C)\mathcal{M}^2(\upb)\right]\log^4(MT_1/\delta)\right)+\log(\bar{\upv}_j^t)\notag
        \\
        \overset{\text{(b)}}{\geq}&\log\left(1+\frac{c_1(1-c_1)\eta}{2}\lambda_j(\upv_j^*)^2\right)+\log(\bar{\upv}_j^t)\notag
		\\
		\overset{\text{(c)}}{=}&\log\left(1+\frac{c_1(1-c_1)\eta}{2}\lambda_j(\upv_j^*)^2\right)+\log(\breve{\upv}_j^t),\notag
	\end{align} 
    where (a) is based on the following three facts: 1) the Taylor expansion of $\log(a+\cdot)$ with $a=1+\eta((\upv_j^*)^2-(\bar{\upv}_j^t)^2)\bbE[(\hat{\upx}_j^{t+1})^2]$; 2) the property that $Y_j^{t+1}$ is zero-mean and independent of $\hat{\upx}_j^{t+1}$; and 3) the step size $\eta\leq\frac{c_1(\upv_j^*)^2\log^{-4}(MT_1/\delta)}{\calO(\sigma^2+(1+C)\mathcal{M}^2(\upb))}$ ensures that $1-\tau\eta((\bar{\upv}_j^t)^2-(\upv_j^*)^2)[(\hat{\upx}_j^{t+1})^2-\bbE[(\hat{\upx}_j^{t+1})^2]]-\tau\eta w_j^{t+1}\hat{\upx}_j^{t+1}\geq1/2$ for any $\tau\in[0,1]$, 
    (b) is due to the inequality $\log(1+\frac{c_1(1-c_1)\eta}{16}\lambda_j(\upv_j^*)^2)\geq\eta^2\lambda_j\calO([\sigma^2+(1+C)\mathcal{M}^2(\upb)]$ $\log^4(MT_1/\delta))$, and (c) relies on the temporal exclusivity property that if event $\calB_t^c(j)$ occurs at time $t$, then $\calB_{t}(j)$ is permanently excluded for all subsequent times $t' > t$. Therefore, based on the submartingale, we obtain
    \begin{align}\label{lower-2}
        &\Pro\left\{\breve{\upv}_j^{T_1}<\frac{1-c_1/2}{1+c_1}\upb_j\right\}\notag
        \\
        \overset{\text{(d)}}{\leq}&\exp\left\{-\frac{2\left({T_1}\log\left(1+\frac{c_1(1-c_1)\eta}{2}\lambda_j(\upv_j^*)^2\right)+\log(v_j^0)-\log\left(\frac{1-c_1/2}{1+c_1}\upb_j\right)\right)^2}{{T_1}\eta^2\lambda_j\calO\left([\sigma^2+\mathcal{M}^2(\upb)]\log^6(MT_1/\delta)\right)}\right\}\notag
        \\
        \overset{\text{(e)}}{\leq}&\exp\left\{-\frac{{T_1}\log^2\left(1+\frac{c_1(1-c_1)\eta}{2}\lambda_j(\upv_j^*)^2\right)}{\eta^2\lambda_j\calO\left([\sigma^2+\mathcal{M}^2(\upb)]\log^6(MT_1/\delta)\right)}\right\}\notag
        \\
        \overset{\text{(f)}}{\leq}&\frac{\delta}{12N}
    \end{align}
    where (d) is derived from Azuma's inequality and the estimation of $\left|\log(\breve{\upv}_j^{t+1})-\log(\breve{\upv}_j^{t})\right|$ below:
    \begin{align}
        \left|\log(\breve{\upv}_j^{t+1})-\log(\breve{\upv}_j^{t})\right|\leq\eta\lambda_j^{1/2}\calO\left(\left[\sigma^2+\mathcal{M}^2(\upb)\right]^{1/2}\log^4(MT_1/\delta)\right),
    \end{align}
    which implies that
    \begin{align}
        \left|\log(\breve{\upv}_j^{t+1})-\log\left(1+\frac{c_1(1-c_1)\eta}{2}\lambda_{j}(\upv_{j}^*)^2\right)-\log(\breve{\upv}_j^{t})\right|^2\leq\eta^2\lambda_j\calO\left([\sigma^2+\mathcal{M}^2(\upb)]\log^8(MT_1/\delta)\right).\notag
    \end{align}
    Moreover, since ${T_1}\log(1+\frac{c_1(1-c_1)\eta}{2}\lambda_j(\upv_j^*)^2)/4\geq-\log(v_j^0)$ and $c_1^2{T_1}\lambda_j(\upv_j^*)^4\geq\calO([\sigma^2+\mathcal{M}^2(\upb)]$ $\log^8(MT_1/\delta))$, we obtain inequalities (e) and (f). 
    % By combining Lemma \ref{aux-1} and the properties of sub-Gaussian variables, we have $|Y_j^t|>R_j$ with a probability of at most $\frac{\delta}{12MT_1}$ for any $t\in[0:T_1-1]$. 
    If $\calA(\bar{\upv}^{T_1})$ holds, Eq.~\eqref{lower-2} illustrates that $\bbP(\calE_{1,j}^c)\leq\frac{\delta}{12N}$. Thus, we have $\bbP(\calE_{1,j}^c\bigcap\calE_2^c)\leq\frac{\delta}{6N}$.
\end{proof}

Second, we construct the high-probability lower bound for $\bar{\mathbf{v}}_j^{T_1}$ for any $j\in[1:D]$ in Lemma \ref{lemma-3}. The proof technique of Lemma \ref{lemma-3} mirrors that of Lemma \ref{lemma_1}.
By contrast, we construct geometrically compensated supermartingale $\{-u_i^t\}_{t=1}^{T_1}$ for each $i\in\mathcal{S}$.
% For any $i\in\mathcal{S}$, the lower bound analysis necessitates inverted $\{\mathcal{Y}_i^t\}_{t=1}^{T_1}$ to obtain another geometrically compensated supermartingale $\{-\mathcal{Y}_i^t\}_{t=1}^{T_1}$. 
The proof is finished by applying Bernstein-type concentration inequalities to these constructed supermartingales, yielding the required probabilistic bounds.

\begin{lemma}\label{lemma-3}[Formal version of Lemma \ref{phase-1-step-3}]
    Under the setting of Lemma \ref{lemma_1}, let 
    $$
    \eta\leq\frac{c_1^2\Barsigmin(D)}{\calO([\sigma^2+\calM^2(\upb)]\log^4(MT_1/\delta))}.
    $$ 
    The combined event set satisfies $\mathbb{P}\left(\bigcap_{j=1}^D\left(\bigcup_{k={3,4}}\calE_{k,j}\right)\right) \geq 1 - \frac{\delta}{6}$, where 
    $$
    \calE_{3,j} := \left\{\max_{t\leq T_1}\bar{\mathbf{v}}_j^t<\frac{1-c_1/2}{1+c_1}\mathbf{b}_j \right\},\quad\calE_{4,j}:= \left\{\bar{\mathbf{v}}_j^{T_1}\geq\frac{1-c_1}{1+c_1}\mathbf{b}_j\right\},\quad \forall j\in[1:D].
    $$
\end{lemma}
\begin{proof}
For any $j \in [1:D]$, if $\mathcal{E}_{3,j}^c$ occurs, there exists $t \in [1:T_1]$ such that $\bar{\mathbf{v}}_j^t \geq \frac{1 - c_1/2}{1 + c_1}\mathbf{b}_j$. 
Define $\tau_{0,j}$ as the stopping time satisfying $\bar{\mathbf{v}}_j^{\tau_{0,j}} \geq \frac{1 - c_1/2}{1 + c_1}\mathbf{b}_j$ as:
\begin{equation}\nonumber
   \tau_{0,j}=\inf_{t}\left \{ t:\bar{\mathbf{v}}_j^{t}\ge \frac{1-c_1/2}{1+c_1}\mathbf{b}_j\right \}.
\end{equation}
We also define $\tau_{1,j}$ as the stopping time satisfying $\bar{\mathbf{v}}_j^{\tau_{1,j}}<\frac{1-c_1}{1+c_1}\mathbf{b}_j$ after $\tau_{0,j}$ as:
\begin{equation}\nonumber
     \tau_{1,j} =\inf_{t>\tau_{0,j}}\left \{ t:\bar{\mathbf{v}}_j^{t}<\frac{1-c_1}{1+c_1}\mathbf{b}_j\right \}.
\end{equation}
Based on the definition of $\{\bar{\mathbf{v}}^t\}_{t=0}^{T_1}$, once the event $\calA^c(\bar{\mathbf{v}}^t)$ occurs, the coupling process satisfies $\bar{\mathbf{v}}^{t'}=\bar{\mathbf{v}}^{t}$ for any $t'>t$. Therefore, $\mathcal{A}(\bar{\mathbf{v}}^t)$ holds for all $t \leq \tau_{1,j}$. Moreover, $\bar{\upv}_j^t$ must traverse in and out of the threshold interval $\left[\frac{1-c_1}{1+c_1}\upb_j,\frac{1}{1+c_1}\upb_j\right]$ before subceeding $\frac{1-c_1}{1+c_1}\upb_j$. We aim to estimate the following probability for coordinates $j\in[1:D]$ and time pairs $t_0<t_1\in[1:T_1]$:
% For any $1\le t_0<t_1\le T_1$,  we next bound the probability of the event
\begin{equation}\nonumber
    \bbP\left(\bar{\mathcal{D} }_{\tau_0=t_0}^{\tau_1=t_1}\left ( j \right )=\left\{\bar{\mathbf{v}}_j^{t_0}\geq\frac{1-c_1/2}{1+c_1}\mathbf{b}_j\bigwedge\bar{\mathbf{v}}_j^{t_0:t_1-1}\in\left[\frac{1-c_1}{1+c_1}\mathbf{b}_j,\frac{1}{1+c_1}\mathbf{b}_j\right]\bigwedge\bar{\mathbf{v}}_j^{t_1}<\frac{1-c_1}{1+c_1}\mathbf{b}_j\right\}\right).
\end{equation}
% For any $t_0\le t<t_1$, let $\mathcal{F}^t$ denote the $\sigma$-algebra generated by $\{\bar{\mathbf{v}}^i\}_{i=0}^t$. 
For any $t\in[t_0:t_1-1]$, we have 
\begin{equation}\label{mar-concen-3}
    \begin{aligned}
        \bbE\left[\mathbf{v}_j^*-\bar{\mathbf{v}}_j^{t+1}\mid\mathcal{F}^t\right]=&\bbE_{{\mathbf{x}}_{1:M}^{t+1},{\xi}^{t+1},{\zeta}_{M+1:\infty}^{t+1}}\left[\mathbf{v}_j^*-\bar{\mathbf{v}}_j^{t}+\eta\left(\left((\bar{\upv}_j^t)^2-(\upv_j^*)^2\right)\hat{\upx}_j^{t+1}+\hat{\upz}_j^{t+1}(\bar{\upv}^t)\right.\right.
        \\
        &\, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \left.\left.-\hat{\zeta}_{M+1:\infty}^{t+1}-\hat{\xi}^{t+1}\right)\hat{\mathbf{x}}_j^{t+1}\bar{\mathbf{v}}_j^{t+1}\right]
		% \\
		% =&(1-\eta\lambda_j\bar{\mathbf{v}}_j^{t}(\bar{\mathbf{v}}_j^{t}+\mathbf{v}_j^*))(\mathbf{v}_j^*-\bar{\mathbf{v}}_j^{t})\notag
		\\
		\leq&\left(1-\frac{1-c_1}{(1+c_1)^2}\eta\lambda_{j}(\mathbf{v}_{j}^*)^2\right)(\mathbf{v}_j^*-\bar{\mathbf{v}}_j^{t}).
    \end{aligned}
\end{equation}
Applying Lemma \ref{aux-1} to $(((\bar{\upv}_j^t)^2-(\upv_j^*)^2)\hat{\upx}_j^{t+1}+\hat{\upz}_j^{t+1}(\bar{\upv}^t)-\hat{\zeta}_{M+1:\infty}^{t+1}-\hat{\xi}^{t+1})\hat{\mathbf{x}}_j^{t+1}$, we have
\begin{equation}
\small
    \begin{split}
        \bbE\left[\exp\left\{\lambda\left(\bbE[\bar{\mathbf{v}}_j^{t+1}\mid\calF^t]-\bar{\mathbf{v}}_j^{t+1}\right)\right\}\mid\calF^t\right]\leq \exp\left\{\frac{\lambda^2\eta^2\lambda_j(\upv_j^*)^2\calO\left(\left[\sigma^2+\mathcal{M}^2(\upb)\right]\log^4(MT_1/\delta)\right)}{2}\right\},\notag
    \end{split}
\end{equation}
for any $\lambda\in\bbR$. Therefore, combining Lemma \ref{aux-2} with Eq.~\eqref{mar-concen-3}, we establish the probability bound for event $\bar{\mathcal{D} }_{\tau_0=t_0}^{\tau_1=t_1}\left(j\right)$ with any time pair $t_0<t_1\in[1:T_1]$ as 
	\begin{align}\nonumber
		\Pro\left(\bar{\mathcal{D} }_{\tau_0=t_0}^{\tau_1=t_1}\left ( j \right )\right)\leq\exp\left\{\frac{-c_1^2(\mathbf{v}_j^*)^2}{\eta\calO\left(\left[\sigma^2+\calM^2(\upb)\right]\log^4(MT_1/\delta)\right)}\right\}.
	\end{align}
 Notice that the occurrence of  $\calE_{3,j}^c\bigwedge\calE_{4,j}^c$ implies $\bar{\mathcal{D} }_{\tau_0=t_0}^{\tau_1=t_1}\left ( j \right )$  must hold for certain $t_0<t_1\in[1:T_1]$. Therefore, we have
	\begin{align}
		\Pro\left(\calE_{3,j}^c\bigwedge\calE_{4,j}^c\right)\leq&\sum_{1\leq t_1<t_2\leq T_1}	\Pro\left(\bar{\mathcal{D} }_{\tau_0=t_0}^{\tau_1=t_1}\left ( j \right )\right)\notag
		\\
		\leq&\frac{T_1^2}{2}\exp\left\{\frac{-c_1^2(\mathbf{v}_j^*)^2}{\eta\calO\left(\left[\sigma^2+\calM^2(\upb)\right]\log^4(MT_1/\delta)\right)}\right\}\notag
		\\
		\leq&\frac{T_1^2}{2}\exp\left\{\frac{-c_1^2\min_{j\in[1:D]}(\mathbf{v}_{j}^*)^2}{\eta\calO\left(\left[\sigma^2+\calM^2(\upb)\right]\log^4(MT_1/\delta)\right)}\right\}\notag
		\\
		\leq&\frac{\delta}{6N}.
	\end{align}






\iffalse
	For each $j\in\calN$ and $t_0\in[0:T-1]$, we define $t_l=\inf\{t\geq t_0\mid \bar{\mathbf{v}}_j^{t_0}<\frac{1-c_1}{1+c_1}\mathbf{b}_j\}$. We consider the event $\calB_{t_0}^{t_l}=\{\bar{\mathbf{v}}_j^{t_0}\geq\frac{1-c_1/2}{1+c_1}\mathbf{b}_j\bigwedge\bar{\mathbf{v}}_j^{t_0:t_l-1}\in[\frac{1-c_1}{1+c_1}\mathbf{b}_j,\frac{1}{1+c_1}\mathbf{b}_j]\}$. We have
	\begin{align}
		\bbE\left[\mathbf{v}_j^*-\bar{\mathbf{v}}_j^{t+1}\mid\calF^{t}\right]=&\bbE_{\mathbf{x}^{t},\xi^{t}}\left[\mathbf{v}_j^*-\bar{\mathbf{v}}_j^{t}+\eta(\bar{\mathbf{v}}^{t\odot 2}-\mathbf{v}^{*\odot 2})^{\top}\mathbf{x}^{t}\cdot\mathbf{x}_j^{t}\bar{\mathbf{v}}_j^{t}-\eta\xi^{t}\mathbf{x}_j^{t}\bar{\mathbf{v}}_j^{t}\right]\notag
		\\
		=&(1-\eta\lambda_j\bar{\mathbf{v}}_j^{t}(\bar{\mathbf{v}}_j^{t}+\mathbf{v}_j^*))(\mathbf{v}_j^*-\bar{\mathbf{v}}_j^{t})\notag
		\\
		\leq&\left(1-\frac{2(1-c_1)}{(1+c_1)^2}\eta\lambda_{j}(\mathbf{v}_{j}^*)^2\right)(\mathbf{v}_j^*-\bar{\mathbf{v}}_j^{t}),\notag
	\end{align}
	when $t\in[t_0:t_l-1]$ and $\calA(\bar{\mathbf{v}}^t)$ happens. Similarly, we can estimate the variance of $\mathbf{v}_j^*-\bar{\mathbf{v}}_j^{t+1}$ under known $\bar{\mathbf{v}}^{t}$ as:
	\begin{align}
		\Var\left[\mathbf{v}_j^*-\bar{\mathbf{v}}_j^{t+1}\mid\calF^{t}\right]\leq(1+c_1)^2\eta^2\lambda_j(\mathbf{v}_j^*)^2\left[\sigma_{\xi}^2+M(\mathbf{b})\right].\notag
	\end{align}
	According to Lemma \dnote{lemma 27 in Shape matters}, we have
	\begin{align}
		\Pro\left\{\calB_{t_0=t_1}^{t_l=t_2}\right\}=\Pro\left\{\mathbf{v}_j^*-\bar{\mathbf{v}}_j^{t_2}>c_1\mathbf{v}_j^*\right\}\leq\exp\left\{\frac{-(1-c_1)c_1^2(\mathbf{v}_j^*)^2}{(1+c_1)^4\eta\left[\sigma_{\xi}^2+M(\mathbf{b})\right]}\right\},
	\end{align}
	for any $1\leq t_1<t_2\leq T$. As similar as Eq.~\eqref{union-1}, we finish the proof with a union bound. Notice that event $\textit{\textbf{[E$_\text{3}$]}}^c\bigwedge\textit{\textbf{[E$_\text{4}$]}}^c$ implies that event $\calB_{t_0=t_1}^{t_l=t_2}$ has to happen for some $1\leq t_1<t_2\leq T$. Therefore, we have
	\begin{align}
		\Pro\left\{\textit{\textbf{[E$_\text{3}$]}}^c\bigwedge\textit{\textbf{[E$_\text{4}$]}}^c\right\}\leq&\sum_{1\leq t_1<t_2\leq T}\Pro\left\{\calB_{t_0=t_1}^{t_l=t_2}\right\}\notag
		\\
		\leq&\frac{T^2}{2}\exp\left\{\frac{-(1-c_1)c_1^2(\mathbf{v}_j^*)^2}{(1+c_1)^4\eta\left[\sigma_{\xi}^2+M(\mathbf{b})\right]}\right\}\notag
		\\
		\leq&\frac{T^2}{2}\exp\left\{\frac{-(1-c_1)c_1^2\min_{j\in\calN}(\mathbf{v}_{j}^*)^2}{(1+c_1)^4\eta\left[\sigma_{\xi}^2+M(\mathbf{b})\right]}\right\}\notag
		\\
		\leq&\frac{\delta}{6N}.
	\end{align}
 \fi 
\end{proof}


Combining Lemma \ref{lemma_1} in \textbf{Part I} and Lemma \ref{lemma-2}, Lemma \ref{lemma-3} in \textbf{Part II}, we have now completed the proof of Theorem \ref{theorem_1}.

\begin{proof}[Proof of Theorem \ref{theorem_1}]
	% Given the step size $\eta$ and sampling number $T_1$, it is necessary to ensure that the conditions in Lemma \ref{lemma_1}--Lemma \ref{lemma-3} are all satisfied. 
    First, we notice that in the setting of Theorem \ref{theorem_1}, 
	\begin{align}\label{eta-choice}
		\eta\leq\frac{c_1^2\Barsigmin(D)}{\calO\left(\left[\sigma^2+\mathcal{M}^2(\upb)\right]\log^4(MT_1/\delta)\right)},
	\end{align} 
	and  
	\begin{align}\label{T-choice}
		\begin{cases}
			\frac{\calO\left([\sigma^2+\mathcal{M}^2(\upb)]\log^8(MT_1/\delta)-\min_{j\in[1:D]}\log(\upv_j^0)\right)}{c_1^2\eta\sigmin(D)}\leq T_1\leq\frac{\log^{-4}(MT_1/\delta)\log((M-D)T_1/\delta)}{\eta^2\Tildesigmax(D)\calO\left([\sigma^2+\mathcal{M}^2(\upb)]\right)}, & \text{ if }M>D,
			\\
			\frac{\calO\left([\sigma^2+\mathcal{M}^2(\upb)]\log^8(MT_1/\delta)-\min_{j\in[1:D]}\log(\upv_j^0)\right)}{c_1^2\eta\sigmin(D)}\leq T_1, & \text{ otherwise }.
		\end{cases}
	\end{align}
	 satisfy all assumptions in Lemmas \ref{lemma_1}-\ref{lemma-3}. Thus we can use all results in Lemma \ref{lemma_1}-\ref{lemma-3}. \ref{lemma_1} yields $\Pro\{\bar{\upv}^{T_1}>\upb\}\leq\frac{\delta}{6}$. Lemma \ref{lemma-2} implies that $\Pro\{\min_{j\in[1:D]}\max_{t\leq {T_1}}(\bar{\upv}_j^t-\frac{1-c_1/2}{1+c_1}\upb_j)<0\bigwedge\bar{\upv}^{T_1}\leq\upb\}\leq\frac{\delta}{6}$. Combining Lemma \ref{lemma_1} and \ref{lemma-2}, we have $\Pro\{\min_{j\in[1:D]}$ $\max_{t\leq {T_1}}(\bar{\upv}_j^t-\frac{1-c_1/2}{1+c_1}\upb_j)<0\}\leq\frac{\delta}{3}$. Moreover, Lemma \ref{lemma-3} indicates that $\Pro\{\min_{j\in[1:D]}$ $\max_{t\leq {T_1}}(\bar{\upv}_j^t-\frac{1-c_1/2}{1+c_1}\upb_j)\geq0\bigwedge\min_{j\in[1:D]}(\bar{\upv}_j^{T_1}-\frac{1-c_1}{1+c_1}\upb_j)<0\}\leq\frac{\delta}{6}$. Combining these results, we establish the final probability bound: $\Pro\{|\bar{\upv}_{1:D}^{T_1}-\upv_{1:D}^*|\leq\frac{c_1}{1+c_1}\upb_{1:D}\bigwedge\bar{\upv}_{D+1:M}^{T_1}\leq\upb_{D+1:M}\}\geq1-\frac{2}{3}\delta$, and this bound can be extended to $\upq^{T_1}$ by the definition of capped coupling process in Definition \ref{def:b-capped}. By Proposition \ref{p1}, we complete the proof.
\end{proof}


\subsection{Proof of Phase II}\label{phase-2}

In this section, we introduce the proof techniques of \textbf{Phase II} in Theorem \ref{phase-II-main}, where we construct the global convergence analysis of Algorithm \ref{SGD} for risk minimization. We demonstrate that after Phase I (i.e., $t>T_1$), the iterations of $\upv^t$ are confined within a neighborhood of $\upv_{1:M}^*$ with high probability. Therefore, the SGD dynamics for the quadratic model can be well approximated by the dynamics for the linear model with high probability. Therefore, we can extend the analytical techniques for SGD in the linear model to obtain the conclusion of Theorem \ref{phase-II-main}. 

Theorem \ref{theorem_1} illustrates that the output of Algorithm \ref{SGD} after $T_1$ iterations lies in the neighborhood of the ground truth within a constant factor, namely, $|\upv_{1:D}-\upv_{1:D}^*|\leq c_1\upv_{1:D}^*$. Thus, we use $\upv^{T_1}$, which satisfies Eq.~\eqref{thm-1-eq}, as the initial point for the SGD iterations in \textbf{Phase II}, and set the annealing learning rate to guarantee the output of Algorithm \ref{SGD} fully converges to $\calR_M(\upv_{1:M}^*)$. Before we formal propose Theorem \ref{phase-II-main}, we preliminarily introduce some of the coupling process, auxiliary function, and notations used for our statement of Theorem \ref{phase-II-main} and analysis in Phase II. We introduce the truncated coupling $\{\widehat{\upv}^t\}_{t=0}^{T_2}$ as follows:
\begin{align}
	\begin{cases}
		% \frac{1}{4}\upv_{1:M}^*, & \text{ if }\exists j\in[1:D],\, \widehat{\upv}_j^t<\frac{1}{2}\upv_j^*,
  %       \\
		\widehat{\upv}^{t+1}=\upv^{T_1+t+1}, & \text{ if }\calG(\widehat{\upv}^t)\text{ occurs },
		\\
		\widehat{\upv}^{\tau+1}=\frac{13}{4}\upv_{1:M}^*, \quad\forall \tau\geq t, & \text{ otherwise },\notag
        % \text{ if }\exists j\in[1:D],\, \widehat{\upv}_j^t>\frac{3}{2}\upv_j^*\text{ or }\exists j\in[D+1:M],\, \widehat{\upv}_j^t>2\upv_j^*,\notag
	\end{cases}
\end{align}
with initialization $\widehat{\upv}^0=\upv^{T_1}$ which satisfies Eq.~\eqref{thm-1-eq}, where event 
\begin{align}\label{event-G}
\calG(\upv):=\left\{\widehat{\upv}_j^t\in\left[\frac{1}{2}\upv_j^*,\frac{3}{2}\upv_j^*\right],\, \, \forall j\in[1:D]\bigwedge\widehat{\upv}_j^t\in\left[0,2\upv_j^*\right],\, \, \forall j\in[D+1:M]\right\},
\end{align}
for any $\upv\in\bbR^M$ and $T_2=T-T_1$. Moreover, we define the auxiliary function $\psi:\bbR^M\rightarrow\bbR^M$ as:
\begin{align}
	\psi(\upv)=\begin{cases}
		\upv, & \text{ if }\calG(\upv)\text{ occurs },
		\\
		\upv_{1:M}^*, & \text{ otherwise}.
	\end{cases}\notag
\end{align}
Thus we construct the truncated sequence  $\{\upw^t=\psi(\widehat{\upv}^{t})\}_{t=0}^{T_2}$.
% , which will be used to approximate the iterative sequence generated by SGD running over the linear models. 
In this phase, our analysis primarily focuses on the trajectory of $\upw^t$. Based on the generation mechanism of the sequence $\{\upw^t\}_{t=0}^{T_2}$, the update from $\upw^{t}$ to $\upw^{t+1}$ can be categorized into two cases:
Case I) $\upw^{t+1}$ remains updated, with its iteration closely approximating SGD updates in linear models \citep{wu2022last};
Case II) For any $\tau\geq t$, $\upw^{\tau+1}$ does not update and remains constant at $\upv_{1:M}^*$.

We also define some notations for simplifying the representation. For any $\upv,\upu\in\bbR^d$, we define $\upv\odot\upu=(\upv_1\upu_1,\cdots,\upv_d\upu_d)^{\top}$ and $\diag\{\upv\}=\diag\{\upv_1,\cdots,\upv_d\}\in\bbR^{d\times d}$. Let $\upH=\frac{25}{4}\upLambda\diag\{\widehat{\upb}\odot\widehat{\upb}\}$ with $\widehat{\upb}^{\top}=\left((\upv_{1:D}^*)^{\top},(\widehat{\upv}_{D+1:M}^*)^{\top}\right)$ and $\hat{\upv}^*$ satisfies $\hat{\upv}_j^*=\max\left\{\frac{3}{2}\upv_j^*,3\upv_j^0\right\}$. We also denote $\upH_{\upw}^t=(\upw^t\odot\Pi_M\upx^{t+1})\otimes((\upw^t+\upv_{1:M}^*)\odot\Pi_M\upx^{t+1})$ and $\upR_{\upw}^t=(\xi^{t+1}+\zeta_{M+1:\infty}^{t+1})\diag\{\upw^t\}$ for simplicity.
We denote the following linear operators that will be used in the proof:
\begin{align}
	\calI:=\upI\otimes\upI,\quad &\calH_{\upw}^t:=\bbE_t\left[\upH_{\upw}^t\otimes(\upH_{\upw}^t)^{\top}\right],\quad \widetilde{\calH}_{\upw}^t:=\bbE_t\left[\upH_{\upw}^t\right]\otimes\bbE_t\left[\upH_{\upw}^t\right],\notag
	\\
	\calG_{\upw}^t:=\bbE_t\left[\upH_{\upw}^t\right]\otimes\upI+\upI\otimes&\bbE_t\left[\upH_{\upw}^t\right]-\eta_t\calH_{\upw}^t,\quad \widetilde{\calG}_{\upw}^t:=\bbE_t\left[\upH_{\upw}^t\right]\otimes\upI+\upI\otimes\bbE_t\left[\upH_{\upw}^t\right]-\eta_t\widetilde{\calH}_{\upw}^t,\notag
\end{align}
where $\bbE_t[\cdot]=\bbE[\cdot\mid\calF^t]$. For any operator $\calA$, we use $\calA\circ\upA$ to denote $\calA$ acting on a symmetric matrix $\upA$. It's easy to directly verify the following rules for above operators acting on a symmetric matrix $\upA$:
\begin{align}
	\calI\circ\upA=\upA,\quad \calH_{\upw}^t\circ\upA=&\bbE_t\left[\upH_{\upw}^t\upA(\upH_{\upw}^t)^{\top}\right],\quad\widetilde{\calH}_{\upw}^t\circ\upA=\bbE_t\left[\upH_{\upw}^t\right]\upA\bbE_t\left[\upH_{\upw}^t\right],\notag
	\\
	\left(\calI-\eta_t\calG_{\upw}^t\right)\circ\upA=&\bbE_t\left[\left(\upI-\eta_t\upH_{\upw}^t\right)\upA\left(\upI-\eta_t\upH_{\upw}^t\right)\right],\notag
	\\
	\left(\calI-\eta_t\widetilde{\calG}_{\upw}^t\right)\circ\upA=&\left(\upI-\eta_t\bbE_t\left[\upH_{\upw}^t\right]\right)\upA\left(\upI-\eta_t\bbE_t\left[\upH_{\upw}^t\right]\right).\notag
\end{align}
% Consider the auxiliary function $\psi$, 
The following is the formalized expression of the iteration process for $\upw^t$. For all $t\in[0:T_2-1]$, if $\upw^{t+1}=\upv^{T_1+t+1}$ (i.e., event $\calG(\upv^{T_1+t+1})$ occurs), $\upw^{t+1}$ follows the update rule as:
\begin{align}\label{iteration}
	\upw^{t+1}-\upv_{1:M}^*=\upw^t-\upv_{1:M}^*-\eta_t\upH_{\upw}^t\left(\upw^t-\upv_{1:M}^*\right)+\eta_t\upR_{\upw}^t\Pi_M\upx^t.
\end{align}
Otherwise, we have 
$$
\upw^{\tau+1}=\upv_{1:M}^*,\quad \forall \tau\geq t.
$$  
Since $\upw^{t+1}$ = $\upv^{T_1+t+1}$ implies $\upw^t = \upv^{T_1+t}$, but the converse does not necessarily hold, we derive the recurrence process as:
% \begin{align}
% \bbE\left[\left\|\upw^{t+1}-\upv_{1:M}^*\right\|^2\right]\leq\bbE\left[\left\|\upw^t-\upv_{1:M}^*-\eta_t\upH_{\upw}^t\left(\upw^t-\upv_{1:M}^*\right)+\eta_t\upR_{\upw}^t\Pi_M\upx^t\right\|^2\mathds{1}_{\upw^t=\upv^{T_1+t}}\right]\notag.
% \end{align}
% Moreover, we can obtain
\begin{align}
	&\bbE\left[\left(\upw^{t+1}-\upv_{1:M}^*\right)^{\otimes2}\right]\preceq\bbE\left[\left(\upw^t-\upv_{1:M}^*-\eta_t\upH_{\upw}^t\left(\upw^t-\upv_{1:M}^*\right)+\eta_t\upR_{\upw}^t\Pi_M\upx^t\right)^{\otimes2}\mathds{1}_{\upw^t=\upv^{T_1+t}}\right].\notag
\end{align}
Define $\widehat{\upw}^t:=\upw^t-\upv_{1:M}^*$. The iterative update of $\widehat{\upw}^t$ can be decomposed into two random processes,
\begin{align}
	\widehat{\upw}^{t}=\mathds{1}_{\upw^t=\upv^{T_1+t}}\cdot\widehat{\upw}_{\bi}^t+\mathds{1}_{\upw^t=\upv^{T_1+t}}\cdot\widehat{\upw}_{\var}^t,\quad \forall t\in[0:T_2],
\end{align}
where $\{\widehat{\upw}_{\var}^t\}_{t=1}^{T_2}$ is recursively defined by
\begin{align}
	\begin{cases}
		\widehat{\upw}_{\var}^{t+1}=\left(\upI-\eta_t\upH_{\upw}^t\right)\widehat{\upw}_{\var}^t+\eta_t\upR_{\upw}^t\Pi_M\upx^t,  & \text{ if }\upw^t=\upv^{T_1+t},
		\\\widehat{\upw}_{\var}^{t+1}=\mathbf{0}, & \text{ otherwise },
	\end{cases}\notag
\end{align}
for any $t\in[0:T_2-1]$ with $\widehat{\upw}_{\var}^0=\textbf{0}$ and $\{\widehat{\upw}_{\bi}^t\}_{t=1}^{T_2}$ is recursively defined by
\begin{align}
	\begin{cases}
		\widehat{\upw}_{\bi}^{t+1}=\left(\upI-\eta_t\upH_{\upw}^t\right)\widehat{\upw}_{\bi}^t, & \text{ if }\upw^t=\upv^{T_1+t},
		\\
		\widehat{\upw}_{\bi}^{t+1}=\mathbf{0}, & \text{ otherwise },\notag
	\end{cases}
\end{align}
for any $t\in[0:T_2-1]$ with  $\widehat{\upw}_{\bi}^0=\upw^0-\upv_{1:M}^*$. We define the $t$-th step bias iteration as $\upB^t=\bbE\left[\widehat{\upw}_{\bi}^t\otimes\widehat{\upw}_{\bi}^t\right]$ and $t$-th step variance iteration as $\upV^t=\bbE\left[\widehat{\upw}_{\var}^t\otimes\widehat{\upw}_{\var}^t\right]$.
Therefore, we can derive the following relations for 
$\{\upB^t\}_{t=0}^{T_2}$ and $\{\upV^t\}_{t=0}^{T_2}$:
\begin{align}
	\begin{cases}\label{bias-and-variance}
        \upB^{t+1}&\preceq\bbE\left[\left(\calI-\eta_t\calG_{\upw}^t\right)\circ\left(\widehat{\upw}_{\bi}^t\otimes\widehat{\upw}_{\bi}^t\right)\right],
		\\
		\upV^{t+1}&\preceq\bbE\left[\left(\calI-\eta_t\calG_{\upw}^t\right)\circ\left(\widehat{\upw}_{\var}^t\otimes\widehat{\upw}_{\var}^t\right)\right]+\eta_t^2\upSigma_{\upw}^t,
	\end{cases}\quad \forall t\in[0:T_2-1],
\end{align}
with $\upB^0=\left(\upw^0-\upv_{1:M}^*\right)\left(\upw^0-\upv_{1:M}^*\right)^{\top}$ and $\upV^0=\mathbf{0}$, where $\upSigma_{\upw}^t=\sigma^2\upLambda\bbE\left[\diag\{\upw^t\odot\upw^t\}\right]$. 

We formally propose Theorem \ref{phase-II-main} as below.
\begin{theorem}\label{phase-II-main}[Formal version of Theorem \ref{phase-II-informal}]
    Suppose Assumption \ref{ass-d} and \ref{ass-ss} hold, and let $T_1=\lceil(T-h)/\log(T-h)\rceil$ and $h=\lceil T/\log(T)\rceil$.
    Under the following setting
    \begin{enumerate}
        \item There exists $D<M$ such that $\eta_0\leq\widetilde{\Omega}(\min\{\tr^{-1}(\upH),\Barsigmin(D)\})$ and $T_1=\widetilde{\calO}(\frac{\sigma^2+\calM^2(\widehat{\upb})}{\eta_0\sigmin(D)})$,
        \item Let $D=M$, $\eta_0\leq\widetilde{\Omega}(\min\{\tr^{-1}(\upH),\Barsigmin(M)\})$, and $T_1\geq\widetilde{\calO}(\frac{\sigma^2+\calM^2(\widehat{\upb})}{\eta_0\sigmin(M)})$,
    \end{enumerate}
    we have
    \begin{align}\label{phaseII-p1}
        \bbE\left[\calR_M(\upw^{T_2})-\calR_M(\upv_{1:M}^*)\right]\lesssim&\sigma^2\left(\frac{N_0'}{K}+\eta_0\sum_{i=N_0'+1}^{N_0}\lambda_i(\upv_i^*)^2\right)\notag
        \\
        &+\sigma^2\eta_0^2(h+T_1)\sum_{i=N_0+1}^M\lambda_i^2(\widehat{\upb}_i^*)^4\notag
        \\
        &+\llangle\frac{1}{\eta_0 T_1}\upI_{1:N_1}+\upH_{N_1+1:M},\left(\upI-\eta_0\widehat{\upH}\right)^{2h}\upB^0\rrangle\notag
        \\
        &+\Gamma(\upH)\llangle\frac{1}{\eta_0h}\upI_{1:N_1'}+\upH_{N_1'+1:M},\upB^0\rrangle,
    \end{align}
    for arbitrary $D\geq N_0\geq N_0'\geq 0$ and $D\geq N_1\geq N_1'\geq 0$, where $\Gamma(\upH):=(\frac{625N_1'}{T_1}+\frac{25\eta_0h}{T_1}\tr(\upH_{N_1'+1:N_1})+\eta_0^2h\tr(\upH_{N_1+1:M}^2))$ and $T_2=T-T_1$. Specially, we have 
    \begin{equation}\label{phaseII-p2}
        \begin{split}
        \calR_M(\upv^{T})-\calR_M(\upv_{1:M}^*)\lesssim&\frac{\sigma^2N}{T_1}+\sigma^2\eta_0^2(h+T_1)\sum_{i=D+1}^M\lambda_i^2(\widehat{\upb}_i^*)^4
        \\
        &+\llangle\frac{1}{\eta_0 T_1}\upI_{1:D}+\upH_{D+1:M},\left(\upI-\eta_0\widehat{\upH}\right)^{2h}\upB^0\rrangle
        \\
        &+\left(\frac{D}{T_1}+\eta_0^2h\tr(\upH_{D+1:M}^2)\right)\llangle\frac{1}{\eta_0h}\upI_{1:D}+\upH_{D+1:M},\upB^0\rrangle,
        \end{split}
    \end{equation}
    with probability at least 0.95.
\end{theorem}

Before the beginning of our proof, we define the $(c\mathbf{v}^*_{1:D},\mathbf{b})$-neighbor coupling process which will be used in the following lemma as below.

\begin{definition}\label{def-neighbor-couple}[$(c\mathbf{v}^*_{1:D},\mathbf{b})$-neighbor coupling]
Let $\{\mathbf{q}^t\}_{t=0}^T$ be a Markov chain in $\mathbb{R}_+^M$ adapted to filtration $\{\mathcal{F} ^{t}\}_{t=0}^T$.  Given parameters: 1) Dimension index $D\in \mathbb{Z}_{+}$; 2) Tolerance $c>0$; 3) Threshold vector $\mathbf{b}\in\bbR_+^{M-D}$. With initial condition $\bar{\mathbf{v}}^0=\upq^0$, $\left | \bar{\mathbf{v}}_{1:D}^0-\mathbf{v}^*_{1:D} \right | \le c\mathbf{v}^*_{1:D}$ and  $\mathbf{0}\le\bar{\mathbf{v}}_{D+1:M}^0\le \mathbf{b}$, the $(c\mathbf{v}^*_{1:D},\mathbf{b})$-neighbor coupling
process $\{\bar{\mathbf{v}}^t\}_{t=0}^T$ evolves as:
\begin{enumerate}
    \item Updating state: If $\left | \bar{\mathbf{v}}^t_{1:D}-\mathbf{v}^*_{1:D} \right | \le c\mathbf{v}^*_{1:D}$ and $\mathbf{0}\le \bar{\mathbf{v}}^t_{D+1:M}\le \mathbf{b}$, let $\bar{\mathbf{v}}^{t+1}=\mathbf{v}^{t+1}$,
    \item Absorbing state: Otherwise, maintain $\bar{\mathbf{v}}^{t+1}=\bar{\mathbf{v}}^{t}$.
\end{enumerate}
% The process $\bar{\mathbf{v}}^{t}$ is measurable on $\mathcal{F} ^{t\bigwedge \tau_{c,\mathbf{b} }}$ where $\tau_{c,\mathbf{b} }=\inf_{t}\left \{ t:\left | \mathbf{v}^t_{1:D}-\mathbf{v}^*_{1:D} \right | >c\mathbf{v}^*_{1:D}\ \vee  \ \mathbf{v}^t_{D+1:M} > \mathbf{b}  \right \} $.
\end{definition}

\subsubsection{Part I: Bound the Output of Phase I}
In this part, we demonstrate that the output of \textbf{Phase I} remains confirmed within the neighborhood of the ground truth with high probability in Lemma \ref{high-probability-phase-II}. Specifically, by constructing similar supermartingales to that in the proofs of Lemma \ref{lemma_1} and Lemma \ref{lemma-3}, we obtain a set of compressed supermartingales dependent on the coordinate $i\in[1:M]$. Combining the compression properties of these supermartingales with the sub-Gaussian property of their difference sequences, through concentration inequality, we obtain Lemma \ref{high-probability-phase-II} as below.

\begin{theorem}\label{high-probability-phase-II}[Formal version of Theorem \ref{phase-2-step-1}]
Under Assumption \ref{ass-d}, we consider the $T_1$-th step of Algorithm \ref{SGD} and its subsequent iterative process. Let $D \in \mathbb{N}+$ represent the effective dimension. Define $\eta_0 \leq \widetilde{\Omega}\left(\frac{\Barsigmin(\max\{D,M\})}{\sigma^2 + \calM^2(\upb)}\right)$, and let $\{\widetilde{\upv}^t\}_{t=0}^{T_2}$ be an $(1/2,2)$-$\upv^*$ neighbor coupling process based on the control sequence $\{\upq^{T_1+t}\}_{t=0}^{T_2}$. Recall the definition \eqref{event-G} of event $\calG(\upv)$ for any $\upv\in\bbR^M$. If $D < M$, set the iteration number $T_2 \in \left[1: \widetilde{\Omega}\left(\frac{\Tildesigmax^{-1}(D)}{\eta_0^2 [\sigma^2 + \calM^2(\upb)]}\right)\right]$. Otherwise, set $T_2$ be an arbitrary positive integer. Then,   $\bigcap_{t=0}^{T_2}\calG(\upv^{T_1+t})$ holds with probability at least $1 - \delta$.
\end{theorem}
\begin{proof}
	Setting $c_1=\frac{1}{4}$ in Theorem \ref{theorem_1}, we have  $|\upq_{1:D}^{T_1}-\upv_{1:D}^*|\leq\frac{1}{4}\upv_{1:D}^*$ and $\boldsymbol{0}_{D+1:M}\leq\upq_{D+1:M}^{T_1}\leq\frac{3}{2}\upv_{D+1:M}^*$ with probability at least $1-\delta/6$. Without loss of generality, we assume $\upq^{T_1}$ satisfies $|\upq_{1:D}^{T_1}-\upv_{1:D}^*|\leq\frac{1}{4}\upv_{1:D}^*$ and $\boldsymbol{0}_{D+1:M}\leq\upq_{D+1:M}^{T_1}\leq\frac{3}{2}\upv_{D+1:M}^*$. Let $\hat{\tau}$ be the stopping time satisfying $\calG^c(\widetilde{\upv}^{\hat{\tau}})$, i.e.,
    \begin{align}
        \hat{\tau}=\inf\left\{t:\exists j\in[1:D], \text{ s.t. }\left|\widetilde{\upv}_j^t-\upv_j^*\right|>\frac{1}{2}\upv_j^*\text{ or }\exists j\in[D+1:M], \text{ s.t. }\widetilde{\upv}_j^t>2\upv_j^*\right\},\notag
    \end{align}
    For each coordinate $j\in[1:D]$, let $\hat{\tau}_{[1:D],j}^u$ and $\hat{\tau}_{[1:D],j}^l$ be the stopping time satisfying $\widetilde{\upv}_j^{\hat{\tau}_{[1:D],j}^u}>\frac{3}{2}\upv_j^*$ and $\widetilde{\upv}_j^{\hat{\tau}_{[D+1:M],j}^l}<\frac{1}{2}\upv_j^*$, respectively, i.e.,
    $$
    \hat{\tau}_{[1:D],j}^u=\inf\left\{t: \widetilde{\upv}_j^t>\frac{3}{2}\upv_j^*\right\},\quad \hat{\tau}_{[1:D],j}^l=\inf\left\{t: \widetilde{\upv}_j^t<\frac{1}{2}\upv_j^*\right\}.
    $$
    For each coordinate $j\in[D+1:M]$, let $\hat{\tau}_{[D+1:M],j}$ be the stopping time satisfying $\widetilde{\upv}_j^{\hat{\tau}_{[D+1:M],j}}>2\upv_j^*$, i.e.,
    $$
        \hat{\tau}_{[D+1:M],j}=\inf\left\{t: \widetilde{\upv}_j^t>2\upv_j^*\right\}.
    $$
    Based on Defnition \ref{def-neighbor-couple}, once the stopping time $\hat{\tau}=t_2$ occurs for certain $t_2\in[1:T_2]$, the coupling process satisfies $\widetilde{\upv}^t=\widetilde{\upv}^{t_2}$ for all $t>t_2$. Suppose there exists a certain $j\in[1:D]$ such that $\hat{\tau}_{[1:D],j}^u=t_2$. Thus, the event $\calG(\widetilde{\upv}^t)$ holds for all $t\in[0:t_2-1]$. Similar to the proof of Lemma \ref{lemma_1} and \ref{lemma-3}, $\widetilde{\upv}_j^t$ must traverse in and out of the threshold interval $[\upv_j^*,\frac{3}{2}\upv_j^*]$ before exceeding $\frac{3}{2}\upv_j^*$. We aim to estimate the following probability for coordinates $j\in[1:D]$ and time pairs $t_1<t_2\in[0:T_2]$ as:
    % Moreover, for any fixed $t_0\in[0:\tau_u-1]$, we consider the event $\calB_{t_0}^{\tau_u}(j)=\{\widetilde{\upv}_j^{t_0}\leq\frac{5}{4}\upv_j^*\bigwedge\widetilde{\upv}_j^{t_0:\tau_u-1}\in[\frac{1}{2}\upv_j^*,\frac{3}{2}\upv_j^*]\}$. If $t\in[t_0:\tau_u-1]$ and $\calA(\widetilde{\upv}^t)$ holds, we obtain
    \begin{align}
        \bbP\left(\calB_{t_1}^{\hat{\tau}_{[1:D],j}^u=t_2}(j)=\left\{\widetilde{\upv}_j^{t_1}\leq\frac{5}{4}\upv_j^*\bigwedge\widetilde{\upv}_j^{t_1:t_2-1}\in\left[\upv_j^*,\frac{3}{2}\upv_j^*\right]\right\}\right).\notag
    \end{align}
    For any $t\in[t_1:t_2-1]$, we have
    \begin{equation}\label{mar-concen-4}
        \begin{split}
		\bbE\left[\widetilde{\upv}_j^{t+1}-\upv_j^*\mid\calF^t\right]=&\bbE_{\upx_{1:M}^{t+1},\xi^{t+1},\zeta_{M+1:\infty}^{t+1}}\left[\widetilde{\upv}_j^t-\upv_j^*-\eta\left(\left((\widetilde{\upv}_j^t)^2-(\upv_j^*)^2\right)\hat{\upx}_j^{t+1}+\hat{\upz}_j^{t+1}(\widetilde{\upv}^t)\right.\right.
        \\
        &\, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \left.\left.-\hat{\zeta}_{M+1:\infty}^{t+1}-\hat{\xi}^{t+1}\right)\hat{\mathbf{x}}_j^{t+1}\widetilde{\mathbf{v}}_j^{t+1}\right]
		\\
		\leq&\left(1-\frac{3\eta_t}{8}\lambda_j(\upv_j^*)^2\right)(\widetilde{\upv}_j^t-\upv_j^*).
        \end{split}
	\end{equation}
	Applying Lemma \ref{aux-1} to $(((\widetilde{\upv}_j^t)^2-(\upv_j^*)^2)\hat{\upx}_j^{t+1}+\hat{\upz}_j^{t+1}(\widetilde{\upv}^t)-\hat{\zeta}_{M+1:\infty}^{t+1}-\hat{\xi}^{t+1})\hat{\mathbf{x}}_j^{t+1}\widetilde{\mathbf{v}}_j^{t+1}$, we obtain
	\begin{equation}
        \small
        \begin{split}
            \bbE\left[\exp\left\{\lambda\left(\widetilde{\upv}_j^{t+1}-\bbE\left[\widetilde{\upv}_j^{t+1}\mid\calF^t\right]\right)\right\}\mid\calF^t\right]\leq\exp\left\{\frac{\lambda^2\eta_t^2\lambda_j(\upv_j^*)^2\calO\left(\left[\sigma^2+\mathcal{M}^2(\upb)\right]\log^4(MT_2/\delta)\right)}{2}\right\},\notag
        \end{split}
	\end{equation}
	for any $\lambda\in\bbR$. Therefore, based on Lemma \ref{aux-2} and Eq.~\eqref{mar-concen-4}, we establish the probability bound for event $\calB_{t_1}^{\hat{\tau}_{[1:D],j}^u=t_2}(j)$ for any time pair $t_1<t_2\in[0:T_2]$ as:
	\begin{align}\label{phase_II_in_truncation}
		\Pro\left\{\calB_{t_1}^{\hat{\tau}_{[1:D],j}^u=t_2}(j)\right\}\leq\exp\left\{-\frac{(\upv_{j}^*)^2}{V_j}\right\},
	\end{align}
	where $V_j$ is denoted as
	\begin{align}
		V_j=\lambda_j(\upv_j^*)^2\calO\left([\sigma^2+\mathcal{M}^2(\upb)]\log^4(MT_2/\delta)\right)\sum_{t=0}^{T_2-1}\left(\prod_{i=t+1}^{T_2-1}(1-\frac{3\eta_{i}}{4}\lambda_j(\upv_j^*)^2)^{2}\right)(\eta_t)^2.\notag
	\end{align}
	By Lemma \ref{aux-3}, we have $V_j\leq\calO(\eta_0[\sigma^2+\mathcal{M}^2(\upb)]\log^4(MT_2/\delta))$. Therefore, using Eq.~\eqref{phase_II_in_truncation}, we can derive 
    \begin{align}\label{prob-1}
    \Pro\left\{\calB_{t_1}^{\hat{\tau}_{[1:D],j}^u=t_2}(j)\right\}\leq\exp\left\{-\frac{(\upv_j^*)^2}{\eta_0\calO\left([\sigma^2+\mathcal{M}^2(\upb)]\log^4(MT_2/\delta)\right)}\right\}.
    \end{align}
    
    Similarly, suppose there exists a certain $j\in[1:D]$ such that $\hat{\tau}_{[1:D],j}^l=t_2$. Thus, the event $\calG(\widetilde{\upv}^t)$ holds for all $t\in[0:t_2-1]$. $\widetilde{\upv}_j^t$ must traverse in and out of the threshold interval $[\frac{1}{2}\upv_j^*,\upv_j^*]$ before subceeding $\frac{1}{2}\upv_j^*$. We aim to estimate the following probability for coordinates $j\in[1:D]$ and time pairs $t_1<t_2\in[1:T_2]$: 
    \begin{align}
        \bbP\left(\calC_{t_1}^{\hat{\tau}_{[1:D],j}^l=t_2}(j)=\left\{\widetilde{\upv}_j^{t_1}\geq\frac{3}{4}\upv_j^*\bigwedge\widetilde{\upv}_j^{t_1:t_2-1}\in\left[\frac{1}{2}\upv_j^*,\upv_j^*\right]\right\}\right).\notag
    \end{align}
    For any $t\in[t_1:t_2-1]$, we have
    \begin{align}
        \bbE\left[\upv_j^*-\widetilde{\upv}_j^{t+1}\mid\calF^t\right]\leq\left(1-\frac{3\eta_t}{8}\lambda_j(\upv_j^*)^2\right)(\upv_j^*-\widetilde{\upv}_j^t).\notag
    \end{align}
    Based on Lemmas \ref{aux-1}, \ref{aux-2}, and \ref{aux-3} sequentially,  we obtain the probability bound for event $\calC_{t_1}^{\hat{\tau}_{[1:D],j}^l=t_2}(j)$ for any time pair $t_1<t_2\in[0:T_2]$ as:
    \begin{align}\label{prob-2}
		\Pro\left\{\calC_{t_1}^{\hat{\tau}_{[1:D],j}^l=t_2}(j)\right\}\leq\exp\left\{-\frac{(\upv_j^*)^2}{V_j}\right\}\leq\exp\left\{-\frac{(\upv_j^*)^2}{\eta_0\calO\left([\sigma^2+\mathcal{M}^2(\upb)]\log^4(MT_2/\delta)\right)}\right\}.
	\end{align}
	
	% In addition, we consider the component of $\widetilde{\upv}^{T_2}$ on $\bar{\calN}$ and define $\widehat{\tau}_u=\inf\{t\mid\widetilde{\upv}_j^t> 2\upv_{j}^*\}$ for any fixed index $j\in\bar{\calN}$. 
    For the third stopping time, we also suppose there exists a certain $j\in[D+1:M]$ such that $\hat{\tau}_{[D+1:M],j}=t_2$. Thus, the event $\calG(\widetilde{\upv}^t)$ holds for all $t\in[0:t_2-1]$. Similarly, $\widetilde{\upv}_j^t$ must traverse in and out of the threshold interval $[\upv_j^*,2\upv_j^*]$ before exceeding $2\upv_j^*$. We aim to estimate the following probability for coordinates $j\in[D+1:M]$ and time pairs $t_1<t_2\in[0:T_2]$ as:
    \begin{align}
        \bbP\left(\calD_{t_1}^{\hat{\tau}_{[D+1:M],j}=t_2}(j)=\left\{\widetilde{\upv}_j^{t_1}\leq\frac{3}{2}\upv_j^*\bigwedge\widetilde{\upv}_j^{t_1:t_2-1}\in[\upv_j^*,2\upv_j^*]\right\}\right).\notag
    \end{align}
    For any $t\in[t_1:t_2-1]$, we have
	\begin{align}\label{mar-concen-5}
		\bbE\left[\widetilde{\upv}_j^{t+1}-\upv_j^*\mid\calF^t\right]\leq\widetilde{\upv}_j^{t}-\upv_j^*.
	\end{align}
	Applying Lemma \ref{aux-1} to $(((\widetilde{\upv}_j^t)^2-(\upv_j^*)^2)\hat{\upx}_j^{t+1}+\hat{\upz}_j^{t+1}(\widetilde{\upv}^t)-\hat{\zeta}_{M+1:\infty}^{t+1}-\hat{\xi}^{t+1})\hat{\mathbf{x}}_j^{t+1}\widetilde{\mathbf{v}}_j^{t+1}$, we obtain 
    \begin{equation}
    \small
    \begin{split}
        \bbE\left[\exp\left\{\lambda\left(\widetilde{\upv}_j^{t+1}-\bbE\left[\widetilde{\upv}_j^{t+1}\mid\calF^t\right]\right)\right\}\mid\calF^t\right]\leq\exp\left\{\frac{\lambda^2\eta_t^2\lambda_j(\upv_j^*)^2\calO\left(\left[\sigma^2+\mathcal{M}^2(\upb)\right]\log^4(MT_2/\delta)\right)}{2}\right\},\notag
    \end{split}
    \end{equation}
    for any $\lambda\in\bbR$.
    % $\Var(j,t+1\mid t)\leq\frac{9(\eta_t)^2}{4}\lambda_j(\upv_j^*)^2\left[\sigma_{\xi}^2+\mathcal{M}^2(\upb)\right]$ 
    Based on Lemma \ref{aux-2} and Eq.~\eqref{mar-concen-5}, we establish the probability bound for the event $\calD_{t_1}^{\hat{\tau}_{[D+1:M],j}=t_2}(j)$ for any time pair $t_1<t_2\in[0:T_2]$ as:
	\begin{align}\label{prob-3}
		\Pro\left\{\calD_{t_1}^{\hat{\tau}_{[D+1:M],j}=t_2}(j)\right\}\leq\exp\left\{-\frac{(\upv_j^*)^2}{V_j}\right\}\overset{\text{(a)}}{\leq}\exp\left\{-\frac{\log^{-4}(MT_2/\delta)}{T_2\eta_0^2\lambda_j\calO\left(\left[\sigma^2+\mathcal{M}^2(\upb)\right]\right)}\right\},
	\end{align}
	where (a) is derived from $V_j\leq T_2\eta_0^2\lambda_j\calO\left(\left[\sigma^2+\mathcal{M}^2(\upb)\right]\log^4(MT_2/\delta)\right)$.
	
	Then, it is easy to notice that $\calG^c(\widetilde{\upv}^{T_2})$ indicates that one of the following situation happens: 
    \begin{enumerate}
        \item For a certain coordinate $j\in[1:D]$ and time pairs $t_1<t_2\in[0:T_2]$, either $\calB_{t_1}^{\hat{\tau}_{[1:D],j}^u=t_2}(j)$ or $\calC_{t_1}^{\hat{\tau}_{[1:D],j}^l=t_2}(j)$ occurs,
        \item For a certain coordinate $j\in[1:D]$ and time pairs $t_1<t_2\in[0:T_2]$, $\calD_{t_1}^{\hat{\tau}_{[D+1:M],j}=t_2}(j)$ occurs.
    \end{enumerate}
    Therefore, by the setting of $\eta_0$ in Lemma \ref{high-probability-phase-II}, we derive the following probability bound of event $\calG^c(\widetilde{\upv}^{T_2})$:
	\begin{align}
		\Pro\{\calG^c(\widetilde{\upv}^{T_2})\}\leq&\sum_{t_1<t_2}\left[\sum_{j\in[1:D]}\left(\Pro\left\{\calB_{t_1}^{\hat{\tau}_{[1:D],j}^u=t_2}(j)\right\}+\Pro\left\{\calC_{t_1}^{\hat{\tau}_{[1:D],j}^l=t_2}(j)\right\}\right)\right.\notag
		\\
		&\, \, \, \, \, \, \, \, \, \, \, \, \, \, \left.+\sum_{j\in[D+1:M]}\Pro\left\{\calD_{t_1}^{\hat{\tau}_{[D+1:M],j}=t_2}(j)\right\}\right]
		\notag
		\\
		\leq&2T_2^2N\exp\left\{-\frac{\min_{j\in\calN}(\upv_j^*)^2}{\eta_0\calO\left([\sigma^2+\mathcal{M}^2(\upb)]\log^4(MT_2)\right)}\right\}
		\notag
		\\	
		&+T_2^2(\max\{M,D\}-D)\exp\left\{-\frac{\log^{-4}(MT_2/\delta)}{T_2\eta_0^2\max_{j\in\bar{\calN}}\lambda_j\calO\left(\left[\sigma^2+\mathcal{M}^2(\upb)\right]\right)}\right\}\notag
		\\
		\leq&\delta/2.\notag
	\end{align}
	 According to the construction of the coupling process $\{\widetilde{\upv}^t\}_{t=0}^{T_2}$ in Definition \ref{def-neighbor-couple}, we have $\bigcap_{t=T_1}^{T_1+T_2}\calG(\upq^t)$ holds with probability at least $1-\delta/2$. By Proposition \ref{p1}, the proof is completed. 
\end{proof}

\subsubsection{Part II: Linear Approximation of the dynamic}
In part I, we have proved that $\bigcap_{t=0}^{T_2}\calG(\upv^{T_1+t})$ occurs with high probability, which implies the truncated sequence $\{\upw^t\}_{t=1}^{T_2}$ aligned to $\{\upv^{T_1+t}\}_{t=1}^{T_2}$ with high probability. Then we approximate the update process of $\{\upw^t\}_{t=1}^{T_2}$ to SGD in traditional linear regression, with respective bounds of variance term and bias term. 

We estimate the risk between the last-step function value and the ground truth as:
\begin{align}
	\bbE\left[\calR_M(\upw^{T_2})-\calR_M(\upv_{1:M}^*)\right]\overset{\text{(a)}}{\leq}\llangle\upH,\bbE\left[\widehat{\upw}^{T_2}\otimes\widehat{\upw}^{T_2}\right]\rrangle\leq2\llangle\upH,\upB^{T_2}\rrangle+2\llangle\upH,\upV^{T_2}\rrangle,
\end{align}
where $\upH=\frac{25}{4}\upLambda\diag\{\widehat{\upb}\odot\widehat{\upb}\}$ and $\widehat{\upb}^{\top}=\left((\upv_{1:D}^*)^{\top},(\widehat{\upv}_{D+1:M}^*)^{\top}\right)$. Here, (a) is derived from combining
\begin{align}
    \bbE\left[\calR_M(\upw^{T_2})-\calR_M(\upv_{1:M}^*)\right]=\bbE\left[\sum_{i=1}^M\lambda_i(\upw_i^{T_2}+\upv_i^*)^2(\upw_i^{T_2}-\upv_i^*)^2\right]\notag,
\end{align}
with the uniform boundedness of $\upw^t$ over $t\in[0:T_2]$. According to the definitions of $\upw^t$ and $\upH_{\upw}^t$, we have $\bbE[\upH_{\upw}^t]\preceq\upH$. Use $\widehat{\upH}$ to denote $\frac{1}{4}\upLambda\diag\{\overline{\upb}\odot\overline{\upb}\}$ where $\overline{\upb}^{\top}=\left((\upv_{1:D}^*)^{\top},\mathbf{0}^{\top}\right)$, and define $\widehat{\calG}:=\widehat{\upH}\otimes\upI+\upI\otimes\widehat{\upH}-\eta\widehat{\upH}\otimes\widehat{\upH}$. For simplicity, we let $K=T_1$. Moreover, we use $C$ to denote the constant such that $\mathbb{E}[|\mathbf{x}_i|^4] \leq C \mathbb{E}[|\mathbf{x}_i|^2]$ for any $i\geq1$. Then we respectively bound the variance and bias to obtain the estimation of $\calR_M(\upv^{T_2})-\calR_M(\upv_{1:M}^*)$.

\vspace{0.3cm}
\noindent\textbf{Bound of Variance}:
Lemma \ref{primal-var-estimation} provides a uniform upper bound for $\upV^t$ over $t\in[0:T_2]$. 
% The proof of Lemma \ref{primal-var-estimation} draws on the relevant proof techniques from \citet{Belkin2019TwoMO,ge2019step,wu2022last}.
\begin{lemma}\label{primal-var-estimation}
    Suppose Assumption \ref{ass-d} holds. Under the setting of Theorem \ref{phase-II-main}, for any $t\in[0:T_2]$, we obtain
    \begin{align}
        \upV_{\diag}^{t}\precsim\eta_0\sigma^2\upI.
    \end{align}
\end{lemma}
\begin{proof}
    The definition of $\upSigma_{\upw}^t$ and the boundedness of $\upw^t$ implicate that $\upSigma_{\upw}^t\preceq\sigma^2\bbE[\upH_{\upw}^t]\preceq\upH$ given $\upv_{1:M}^*\geq\mathbf{0}$. The proof relies on induction. At $t=0$, it follows that $\upV_{\diag}^0=\mathbf{0}\precsim\eta_0\sigma^2\upI$. Assuming $\upV_{\diag}^{\tau}\precsim\eta_0\sigma^2\upI$ for any $\tau\leq t$, we proceed to estimate $\upV^{t+1}$ by combining Eq.~\eqref{bias-and-variance} as,
    \begin{align}
        \upV_{\diag}^{t+1}\preceq&\left(\bbE\left[\left(\calI-\eta_t\calG_{\upw}^t\right)\circ\left(\widehat{\upw}_{\var}^t\otimes\widehat{\upw}_{\var}^t\right)\right]\right)_{\diag}+\eta_t^2\upSigma_{\upw}^t\notag\\
        \preceq&\left(\calI-\eta_t\widehat{\upH}\otimes\upI-\eta_t\upI\otimes\widehat{\upH}\right)\circ\upV_{\diag}^{t}\notag
        \\
        &+\eta_t^2\left(\bbE\left[\calH_{\upw}^t\circ\left(\widehat{\upw}_{\var}^t\otimes\widehat{\upw}_{\var}^t\right)\right]\right)_{\diag}+\eta_t^2\sigma^2\upH\notag
        \\
        \overset{\text{(a)}}{\preceq}&\left(\upI-2\eta_t\widehat{\upH}\right)\upV_{\diag}^{t}+\calO\left(\eta_t^2 (C+2)\langle\upH,\upV_{\diag}^{t}\rangle\upH+\eta_t^2\sigma^2\upH\right)\notag
        \\
        \preceq&\left(\upI-2\eta_t\widehat{\upH}\right)\upV_{\diag}^{t}+\widetilde{\calO}\left(\eta_t^2\eta_0\sigma^2 (C+2)\tr(\upH)\upH+\eta_t^2\sigma^2\upH\right),\notag
    \end{align}
    where (a) is derived from Lemma \ref{aux-6} with $\upA=\diag\{\upv_{1:M}^*+\upw^t\}$ and $\upB=\widehat{\upw}_{\var}^t\otimes\widehat{\upw}_{\var}^t$. For $i\in[1:D]$, we have
    \begin{align}\label{eq-var-1}
        \left(\upV_{\diag}^{t+1}\right)_{i,i}\leq\left(1-2\eta_t\widehat{\upH}_{i,i}\right)\left(\upV_{\diag}^{t}\right)_{i,i}+\widetilde{\calO}\left(\eta_t^2\sigma^2\widehat{\upH}_{i,i}\right).
    \end{align}
    The recursion given by Eq.~\eqref{eq-var-1} implies that $(\upV_{\diag}^{t+1})_{i,i}\lesssim\eta_0\sigma^2$ for any $i\in[1:D]$, using Lemma \ref{aux-3}. For $i\in[D+1:M]$, we obtain
    \begin{align}
        \left(\upV_{\diag}^{t+1}\right)_{i,i}\lesssim\sigma^2\widehat{\upH}_{i,i}\sum_{k=0}^t\eta_k^2\lesssim\eta_0\sigma^2.
    \end{align}
    % Since $\eta_0>\eta_t$ and $\bbE[\upH_{\upw}^t]\succeq\mathbf{0}$, we have $\upV^{t+1}\preceq\frac{\eta_0\sigma^2}{1-\eta_0R^2}\upI$. 
    Therefore, we complete the induction.
\end{proof}
\begin{lemma}\label{variance-upper-bound}
    Suppose Assumption \ref{ass-d} holds. Under the setting of Theorem \ref{phase-II-main}, we have
    \begin{align}
        \llangle\upH,\upV^{T_2}\rrangle\lesssim&\sigma^2\left(\frac{N_0'}{K}+\eta_0\sum_{i=N_0'+1}^{N_0}\lambda_i(\upv_i^*)^2\right)+\sigma^2\eta_0^2(h+K)\sum_{i=N_0+1}^M\lambda_i^2(\widehat{\upb}_i^*)^4,
    \end{align}
    for arbitrary $D\geq N_0\geq N_0'\geq0$.
\end{lemma}
\begin{proof}
    % By selecting $\upA=\diag\{\upw^t\}$ and $\upB=\diag^2\{\upw^t+\upv_{1:M}^*\}\diag^{-2}\{\upw^t\}$ in Lemma \ref{aux-6}, we derive the inequality $\bbE[\upH^t(\upH^t)^{\top}]\preceq (C+2)\tr(\upH)\bbE[\upH^t]$. 
    Applying Eq.~\eqref{bias-and-variance}, we obtain
    \begin{align}\label{express-V}
        \upV_{\diag}^{t+1}\preceq&\left(\calI-\eta_t\widehat{\calG}\right)\circ\upV_{\diag}^t+\eta_t^2\left(\calH_{\upw}^t\circ\left(\widehat{\upw}_{\var}^t\otimes\widehat{\upw}_{\var}^t\right)\right)_{\diag}+\eta_t^2\sigma^2\bbE[\upH_{\upw}^t]\notag
        \\
        \overset{\text{(a)}}{\preceq}&\left(\calI-\eta_t\widehat{\calG}\right)\circ\upV_{\diag}^t+\widetilde{\calO}\left(\eta_t^2\sigma^2\eta_0(C+2)\tr(\upH)\upH+\eta_t^2\sigma^2\upH\right)\notag
        \\
        =&\left(\calI-\eta_t\widehat{\calG}\right)\circ\upV_{\diag}^t+\widetilde{\calO}\left(\eta_t^2\sigma^2\upH\right),
    \end{align}
    where (a) is derived from Lemma \ref{primal-var-estimation}. Therefore, the recursion for $\upV_{\diag}^{T_2}$ can be directly derived by incorporating Eq.~\eqref{express-V} as
    \begin{align}\label{recur-variance}
        \upV_{\diag}^{T_2}\precsim\sigma^2\sum_{t=0}^{T_2}\eta_t^2\prod_{i=t+1}^{T_2}\left(\calI-\eta_i\widehat{\calG}\right)\circ\upH
        % \overset{\text(b)}{\preceq}&\frac{\sigma^2}{1-\eta_0 (C+2)\tr(\upH)}\sum_{t=0}^{T_2}\eta_t^2\prod_{i=t+1}^{T_2}\left(\upI-\eta_i\bbE[\upH_{\upw}^i]\right)\bbE[\upH_{\upw}^t]\notag
        % \\
        \overset{\text(b)}{\precsim}\sigma^2\underbrace{\sum_{t=0}^{T_2}\eta_t^2\prod_{i=t+1}^{T_2}\left(\upI-\eta_i\widehat{\upH}\right)\upH}_{\lai},
    \end{align}
    where (b) is based on the inequality $(1-\eta c_2)^2c_3\leq(1-\eta c_2)c_3$, which holds for any $\eta\leq c_2^{-1}$ given fixed constants $c_2,c_3>0$. 
    % Additionally, (c) is derived from the estimation $\widehat{\upH}\preceq\bbE[\upH^i]$, which holds for all $i\in[1:T_2]$. 
    According to the update rule for $\eta_t$ defined in Algorithm \ref{SGD}, we obtain
    \begin{align}\label{eq-variance-I}
        \lai=&\eta_0^2\sum_{i=1}^h\left(\upI-\eta_0\widehat{\upH}\right)^{h-i}\prod_{j=1}^{L}\left(\upI-\frac{\eta_0}{2^j}\widehat{\upH}\right)^K\upH\notag
        \\
        &+\sum_{l=1}^{L}\left(\frac{\eta_0}{2^l}\right)^2\sum_{i=1}^K\left(\upI-\frac{\eta_0}{2^l}\widehat{\upH}\right)^{K-i}\prod_{j=l+1}^{L}\left(\upI-\frac{\eta_0}{2^j}\widehat{\upH}\right)^K\upH\notag
        \\
        \preceq&4\left(\left(\frac{\eta_0}{2}\right)^2\sum_{i=1}^{h+K}\left(\upI-\frac{\eta_0}{2}\widehat{\upH}\right)^{h+K-i}\prod_{j=1}^{L-1}\left(\upI-\frac{\eta_0}{2^{1+j}}\widehat{\upH}\right)^K\upH\right.\notag
        \\
        &\, \, \, \, \, \, \, \, +\left.\sum_{l=1}^{L-1}\left(\frac{\eta_0}{2^{1+l}}\right)^2\sum_{i=1}^K\left(\upI-\frac{\eta_0}{2^{1+l}}\widehat{\upH}\right)^{K-i}\prod_{j=l+1}^{L-1}\left(\upI-\frac{\eta_0}{2^{1+j}}\widehat{\upH}\right)^K\upH\right)\notag
        \\
        \preceq&100\left(\frac{\eta_0}{2}\left(\upI-\left(\upI-\frac{\eta_0}{2}\widehat{\upH}_{1:D}\right)^{s+K}\right)\prod_{j=1}^{L-1}\left(\upI-\frac{\eta_0}{2^{1+j}}\widehat{\upH}_{1:D}\right)^K\right.\notag
        \\
        &\, \, \, \, \, \, \, \, \, \, \, \, \, \, +\left.\sum_{l=1}^{L-1}\frac{\eta_0}{2^{1+l}}\left(\upI-\left(\upI-\frac{\eta_0}{2^{1+l}}\widehat{\upH}_{1:D}\right)^K\right)\prod_{j=l+1}^{L-1}\left(\upI-\frac{\eta_0}{2^{1+j}}\widehat{\upH}_{1:D}\right)^K\right)\notag
        \\
        &+2\eta_0^2(h+K)\upH_{D+1:M}.
    \end{align}
    Then, we define the following scalar function
    \begin{align}
        f(x):=x\left(1-(1-x)^{h+K}\right)\prod_{j=1}^{L-1}\left(1-\frac{x}{2^j}\right)^K+\sum_{l=1}^{L-1}\frac{x}{2^l}\left(1-\left(1-\frac{x}{2^l}\right)^K\right)\prod_{j=l+1}^{L-1}\left(1-\frac{x}{2^j}\right)^K,\notag
    \end{align}
    as similar as that in [Lemma C.2, \citet{wu2022last}]. Moreover, the following inequality can be directly derived
    \begin{align}\label{aux-scalar-func}
        f\left(\frac{\eta_0}{2}\widehat{\upH}_{1:D}\right)\preceq\frac{8}{K}\upI_{1:N_0'}+\eta_0\widehat{\upH}_{N_0'+1:N_0}+\frac{\eta_0^2}{2}(h+K)\widehat{\upH}_{N_0+1:D}^2,
    \end{align}
    for arbitrary $D\geq N_0\geq N_0'\geq0$ by [Lemma C.3, \citet{wu2022last}]. Applying Eq.~\eqref{aux-scalar-func} to Eq.~\eqref{eq-variance-I} and combining Eq.~\eqref{recur-variance}, we obtain
    \begin{align}
        \upV_{\diag}^{T_2}\precsim&\sigma^2\left(\frac{1}{K}\widehat{\upH}_{1:N_0'}^{-1}+\eta_0\upI_{N_0'+1:N_0}+\eta_0^2(h+K)\widehat{\upH}_{N_0+1:D}+\eta_0^2(h+K)\upH_{D+1:M}\right).
    \end{align}
    Consequently, we have
    \begin{align}
        \llangle\upH,\upV^{T_2}\rrangle\lesssim&\sigma^2\left(\frac{N_0'}{K}+\eta_0\tr\left(\widehat{\upH}_{N_0'+1:N_0}\right)+\eta_0^2(h+K)\tr\left(\widehat{\upH}_{N_0+1:D}^2\right)\right)\notag
        \\
        &+\sigma^2\eta_0^2(h+K)\tr\left(\upH_{D+1:M}^2\right)\notag
        \\
        \lesssim&\sigma^2\left(\frac{N_0'}{K}+\eta_0\sum_{i=N_0'+1}^{N_0}\lambda_i(\upv_i^*)^2\right)+\sigma^2\eta_0^2(h+K)\sum_{i=N_0+1}^M\lambda_i^2(\widehat{\upb}_i^*)^4.
    \end{align}
\end{proof}

\noindent\textbf{Bound of Bias}:
We begin with an analysis of the bias error during a single period of Algorithm \ref{SGD}, where the bias iterations are updated using a constant step size $\eta_t\equiv\eta$ over $\hat{T}$ steps. Based on Eq.~\eqref{bias-and-variance}, the bias iterations are updated according to the following rule:
\begin{align}\label{recur-bias}
    \upB^{t+1}\preceq\bbE\left[\left(\calI-\eta\calG_{\upw}^t\right)\circ\left(\widehat{\upw}_{\bi}^t\otimes\widehat{\upw}_{\bi}^t\right)\right],\quad \forall t\in[0:\hat{T}-1].
\end{align}
Combining Eq.~\eqref{recur-bias}, we have
\begin{align}\label{period-bias}
    \upB_{\diag}^{t+1}\preceq&\left(\calI-\eta\widehat{\calG}\right)\circ\upB_{\diag}^t+\eta^2\bbE\left(\left[\calH_{\upw}^t\circ\upB^t\right]\right)_{\diag}\notag
    \\
    \preceq&\prod_{i=0}^t\left(\calI-\eta\widehat{\calG}\right)\circ\upB_{\diag}^0+\eta^2\sum_{i=0}^{t}\prod_{j=i+1}^{t}\left(\calI-\eta\widehat{\calG}\right)\circ\bbE\left(\left[\calH_{\upw}^t\circ\upB^t\right]\right)_{\diag}\notag
    \\
    \overset{\text{(a)}}{\preceq}&\prod_{i=0}^t\left(\calI-\eta\widehat{\calG}\right)\circ\upB_{\diag}^0+(C+2)\eta^2\sum_{i=0}^{t}\prod_{j=i+1}^{t}\left(\calI-\eta\widehat{\calG}\right)\circ\upH\llangle\upH,\upB^i\rrangle.
\end{align}
where (a) is derived from Lemma \ref{aux-6} by selecting $\upA=\frac{5}{2}\diag\{\widehat{\upb}\}$ and $\upB=\upB^i$. According to Eq.~\eqref{period-bias}, we have
\begin{align}\label{diag-bias}
    \upB_{\diag}^{t+1}\preceq\left(\calI-\eta\widehat{\calG}\right)^{t+1}\circ\upB_{\diag}^0+(C+2)\eta^2\sum_{i=0}^{t}\left(\upI-\eta\widehat{\upH}\right)^{2(t-i)}\upH\llangle\upH,\upB^i\rrangle.
\end{align}
We utilize the following lemma to estimate $\llangle\upH,\upB^{\hat{T}}\rrangle$ under bias iteration defined in Eq.~\eqref{recur-bias}.
\begin{lemma}\label{period-bias-lemma}
    Suppose Assumption \ref{ass-d} and Assumption \ref{ass-ss} hold, and $\upB^t$ is recursively defined by Eq.~\eqref{recur-bias}. Under the setting of Theorem \ref{phase-II-main}, letting $1\leq\hat{T}\leq T$ and $\eta\leq\eta_0$, we have
    \begin{align}
        \llangle\upH,\upB^{\hat{T}}\rrangle\leq\frac{2}{1-\widetilde{\calO}(C+2)\eta\tr(\upH)}\llangle\frac{25}{\eta \hat{T}}\upI_{1:N_0}+\upH_{N_0+1:M},\upB^0\rrangle,
    \end{align}
    where $N_0\in[0:D]$ is an arbitrary integer.
\end{lemma}
\begin{proof}
    By Lemma \ref{aux-5}, we can derive $\eta(\upI-\eta\widehat{\upH})^{2t}\upH\preceq\frac{25}{t+1}\upI$. Applying this to Eq.~\eqref{diag-bias}, we obtain
    \begin{align}\label{bias-eq-1}
        \upB_{\diag}^{t+1}\preceq\left(\calI-\eta\widehat{\calG}\right)^{t+1}\circ\upB_{\diag}^0+25(C+2)\eta\sum_{i=0}^t\frac{\llangle\upH,\upB^i\rrangle}{t+1-i}\cdot\upI,
    \end{align}
    for any $t\in[0:\hat{T}-1]$. Therefore, based on Lemma \ref{aux-7}, we have
    \begin{align}\label{equation-sum}
        \sum_{i=0}^{t}\frac{\llangle\upH,\upB^i\rrangle}{t+1-i}\leq\llangle\sum_{i=0}^t\frac{(\upI-\eta\widehat{\upH})^{2i}\upH}{t+1-i},\upB^0\rrangle+\widetilde{\calO}(C+2)\eta\tr(\upH)\sum_{i=0}^t\frac{\llangle\upH,\upB^i\rrangle}{t+1-i},
    \end{align}
    for any $t\in[1:\hat{T}]$. Eq.~\eqref{equation-sum} implicates that 
    \begin{align}\label{bias-eq-2}
        \sum_{t=0}^{\hat{T}-1}\frac{\llangle\upH,\upB^t\rrangle}{\hat{T}-t}\leq\frac{1}{1-\widetilde{\calO}(C+2)\eta\tr(\upH)}\llangle\sum_{t=0}^{\hat{T}-1}\frac{(\upI-\eta\widehat{\upH})^{2t}\upH}{\hat{T}-t},\upB^0\rrangle,
        %1-2\calO(C+2)\log(T)^3\log(\delta^{-1})\eta\tr(\upH)
    \end{align}
    since $\widetilde{\calO}\eta(C+2)\tr(\upH)<1$. Combining Eq.~\eqref{bias-eq-1} with Eq.~\eqref{bias-eq-2}, we obtain
    \begin{align}\label{bias-eq-3}
        \llangle\upH,\upB^{\hat{T}}\rrangle\leq&\llangle(\upI-\eta\widehat{\upH})^{2\hat{T}}\upH,\upB^0\rrangle+\frac{{\calO}(C+2)\eta\tr(\upH)}{1-\widetilde{\calO}(C+2)\eta\tr(\upH)}\llangle\sum_{t=0}^{\hat{T}-1}\frac{(\upI-\eta\widehat{\upH})^{2t}\upH}{\hat{T}-t},\upB^0\rrangle\notag
        \\
        \overset{\text{(a)}}{\leq}&\llangle(\upI-\eta\widehat{\upH})^{2\hat{T}}\upH,\upB^0\rrangle\notag
        \\
        &+\frac{{\calO}(C+2)\eta\tr(\upH)}{1-\widetilde{\calO}(C+2)\eta\tr(\upH)}\llangle\frac{\upI_{1:D}-(\upI_{1:D}-\eta\widehat{\upH}_{1:D})^{\hat{T}}}{\eta \hat{T}}+(\upI_{1:D}-\eta\widehat{\upH}_{1:D})^{\hat{T}}\widehat{\upH}_{1:D},\upB^0\rrangle\notag
        \\
        &+\frac{{\calO}(C+2)\eta\tr(\upH)}{1-\widetilde{\calO}(C+2)\eta\tr(\upH)}\llangle\upH_{D+1:M},\upB^0\rrangle\notag
        \\
        \overset{\text(b)}{\leq}&\frac{2}{1-\widetilde{\calO}(C+2)\eta\tr(\upH)}\llangle\frac{25}{\eta T}\upI_{1:N_0}+\upH_{N_0+1:M},\upB^0\rrangle,
    \end{align}
    where $N_0\in[0:D]$ is an arbitrary integer,  (a) follows the technique in [Lemma C.4, \citet{wu2022last}], and (b) is derived from the invariant scaling relationship between $\widehat{\upH}_{1:D}$ and $\upH_{1:D}$. 
\end{proof}

\begin{lemma}\label{bias-diag}
    Suppose Assumption \ref{ass-d} and Assumption \ref{ass-ss} hold. Under the setting of Theorem \ref{phase-II-main}, letting $2\leq\hat{T}\leq T$ and $\eta\leq\eta_0$, we have
    \begin{align}
        \upB_{\diag}^{\hat{T}}\preceq\left(\upI-\eta\widehat{\upH}\right)^{\hat{T}}\upB_{\diag}^0\left(\upI-\eta\widehat{\upH}\right)^{\hat{T}}+\frac{\widetilde{\calO}(C+2)\eta^2\hat{T}}{1-\widetilde{\calO}(C+2)\eta\tr(\upH)}\llangle\widetilde{\upH}^{\hat{T}},\upB^0\rrangle\overline{\upH}^{\hat{T}},
    \end{align}
    where $\widetilde{\upH}^{t}:=\frac{25}{\eta t}\upI_{1:N_0}+\upH_{N_0+1:M}$, and $\overline{\upH}^{t}:=\frac{25}{\eta t}\upI_{1:N_0'}+\upH_{N_0'+1:M}$ for any $t\geq1$, and $N_0,N_0'\in[0:D]$ could be arbitrary integer.
\end{lemma}
\begin{proof}
    Applying Lemma \ref{period-bias-lemma} into Eq.~\eqref{diag-bias}, we obtain
    \begin{align}\label{bias-lemma-1-main}
        \upB_{\diag}^{\hat{T}}\preceq&\left(\calI-\eta\widehat{\calG}\right)^{\hat{T}}\circ\upB_{\diag}^0+(C+2)\eta^2\left(\upI-\eta\widehat{\upH}\right)^{2(\hat{T}-1)}\upH\llangle\upH,\upB^0\rrangle\notag
        \\
        &+(C+2)\eta^2\sum_{t=1}^{\hat{T}-1}\left(\upI-\eta\widehat{\upH}\right)^{2(\hat{T}-1-t)}\upH\llangle\upH,\upB^t\rrangle\notag
        \\
        \preceq&\left(\calI-\eta\widehat{\calG}\right)^{\hat{T}}\circ\upB_{\diag}^0+(C+2)\eta^2\underbrace{\left(\upI-\eta\widehat{\upH}\right)^{2(\hat{T}-1)}\upH\llangle\upH,\upB^0\rrangle}_{\calcolI}\notag
        \\
        &+\frac{2(C+2)\eta^2}{1-2\widetilde{O}(C+2)\eta\tr(\upH)}\underbrace{\sum_{t=1}^{\hat{T}-1}\left(\upI-\eta\widehat{\upH}\right)^{2(\hat{T}-1-t)}\upH\llangle\widetilde{\upH}^t,\upB^0\rrangle}_{\calcolII},
    \end{align}
    We then provide a bound of term $\calcolII$ as follows:
    \begin{align}
        \calcolII=&\left(\sum_{t=1}^{\hat{T}-1}\llangle\widetilde{\upH}^t,\upB^0\rrangle\right)\upH_{D+1:M}+25\sum_{t=1}^{\hat{T}-1}\left(\upI_{1:D}-\eta\widehat{\upH}_{1:D}\right)^{2(\hat{T}-1-t)}\widehat{\upH}_{1:D}\llangle\widetilde{\upH}^t,\upB^0\rrangle\notag
        \\
        \preceq&\hat{T}\log(\hat{T})\llangle\widetilde{\upH}^{\hat{T}},\upB^0\rrangle\upH_{D+1:M}+25\left(\sum_{t=1}^{\hat{T}/2-1}\left(\upI_{1:D}-\eta\widehat{\upH}_{1:D}\right)^{\hat{T}}\widehat{\upH}_{1:D}\llangle\widetilde{\upH}^t,\upB^0\rrangle\right.\notag
        \\
        &+\left.\sum_{t=\hat{T}/2}^{\hat{T}-1}\left(\upI_{1:D}-\eta\widehat{\upH}_{1:D}\right)^{\hat{T}-1-t}\widehat{\upH}_{1:D}\llangle\widetilde{\upH}^{\hat{T}/2},\upB^0\rrangle\right)\notag
        \\
        =&\hat{T}\log(\hat{T})\llangle\widetilde{\upH}^{\hat{T}},\upB^0\rrangle\upH_{D+1:M}+25\left(\left(\upI_{1:D}-\eta\widehat{\upH}_{1:D}\right)^{\hat{T}}\widehat{\upH}_{1:D}\llangle\sum_{t=1}^{\hat{T}/2-1}\widetilde{\upH}^t,\upB^0\rrangle\right.\notag
        \\
        &+\left.\frac{\upI_{1:D}-\left(\upI_{1:D}-\eta\widehat{\upH}_{1:D}\right)^{\hat{T}/2}}{\eta}\llangle\widetilde{\upH}^{\hat{T}/2},\upB^0\rrangle\right)\notag
        \\
        \preceq&\hat{T}\log(\hat{T})\llangle\widetilde{\upH}^{\hat{T}},\upB^0\rrangle\upH_{D+1:M}+25\left(\hat{T}\log(\hat{T})\left(\upI_{1:D}-\eta\widehat{\upH}_{1:D}\right)^{\hat{T}}\widehat{\upH}_{1:D}\llangle\widetilde{\upH}^{\hat{T}},\upB^0\rrangle\right.\notag
        \\
        &+2\left.\frac{\upI_{1:D}-\left(\upI_{1:D}-\eta\widehat{\upH}_{1:D}\right)^{\hat{T}/2}}{\eta}\llangle\widetilde{\upH}^{\hat{T}},\upB^0\rrangle\right)\notag
        \\
        \overset{\text{(a)}}{\preceq}& \hat{T}\log(\hat{T})\llangle\widetilde{\upH}^{\hat{T}},\upB^0\rrangle\overline{\upH}^{\hat{T}},
    \end{align}
    where (a) follows the similar technique used in Eq.~\eqref{bias-eq-3}. We then proceed to establish bounds on $\calcolI$. It's worth to notice that
    \begin{align}\label{sub-1}
        \left(\upI-\eta\widehat{\upH}\right)^{2(\hat{T}-1)}\upH\preceq\frac{25}{2\eta(\hat{T}-1)}\upI_{1:N_0'}+25\widehat{\upH}_{N_0'+1:D}+\upH_{D+1:M}\preceq\overline{\upH}^{\hat{T}}.
    \end{align}
    Applying Eq.~\eqref{sub-1} to $\calcolI$, we obtain
    \begin{align}
        \calcolI\preceq\overline{\upH}^{\hat{T}}\llangle\upH,\upB^0\rrangle\preceq \hat{T}\overline{\upH}^{\hat{T}}\llangle\widetilde{\upH}^{\hat{T}},\upB^0\rrangle,
    \end{align}
    where the last inequality is derived from the condition $\eta<1/(25\tr(\upH))$, which ensures $\lambda_i(\upH)<1/\eta$ holds for all $i\in[1:N_0]$. Combining the estimation of $\calcolI$ and $\calcolII$ with Eq.~\eqref{bias-lemma-1-main}, we have
    \begin{align}
        \upB_{\diag}^{\hat{T}}\preceq&\left(\calI-\eta\widehat{\calG}\right)^{\hat{T}}\circ\upB_{\diag}^0+(C+2)\eta^2\hat{T}\widetilde{\upH}^{\hat{T}}\llangle\widetilde{\upH}^{\hat{T}},\upB^0\rrangle\notag
        \\
        &+\frac{2(C+2)\eta^2}{1-\widetilde{\calO}(C+2)\eta\tr(\upH)}\hat{T}\log(\hat{T})\llangle\widetilde{\upH}^{\hat{T}},\upB^0\rrangle\overline{\upH}^{\hat{T}}\notag
        \\
        \preceq&\left(\calI-\eta\widehat{\calG}\right)^{\hat{T}}\circ\upB_{\diag}^0+\frac{\widetilde{\calO}(C+2)\eta^2\hat{T}}{1-\widetilde{\calO}(C+2)\eta\tr(\upH)}\llangle\widetilde{\upH}^{\hat{T}},\upB^0\rrangle\overline{\upH}^{T}.
    \end{align}
    By the definition of $\widehat{\calG}$, we complete the proof.
\end{proof}

Notice that in \textbf{Phase II}, the step size 
$\eta_t$ decays geometrically. Thus, we define the bias iteration at the end of the step-size-decaying phase as:
\begin{align}
    \widetilde{\upB}^l:=\begin{cases}
        \upB^h, & l=0,\\
        \upB^{h+Kl}, & l\in[1:L].
    \end{cases}
\end{align}
Based on the step-size iteration in Algorithm \ref{SGD} and preceding definition, we formalize the iterative process of Algorithm \ref{SGD} in Phase II as: 1) Phase when $l=0$: Initialized from $\upB^0$, Algorithm \ref{SGD} runs $h$ iterations with step size $\eta_0$, yielding $\widetilde{\upB}^0$;
2) Phase when $l\geq1$: Initialized from $\widetilde{\upB}^{l-1}$, Algorithm \ref{SGD} runs $K$ iterations with step size $\eta_0/2^{l}$, yielding $\widetilde{\upB}^l$. This multi-phase process terminates at $l=L$, with $\widetilde{\upB}^L = \upB^{T_2}$ as the final output.
% in state $l\geq1$, SGD is initialized from $\widetilde{\upB}^{l-1}$ and runs for $K$ steps with step-size $\eta_0/2^{l}$ and output $\widetilde{\upB}^l$; the final output is $\widetilde{\upB}^L=\upB^{T_2}$.
\begin{lemma}\label{lemma-Bias-tr-1}
    Suppose Assumption \ref{ass-d} and Assumption \ref{ass-ss} hold. Under the setting of Theorem \ref{phase-II-main}, we have
    \begin{align}
        \llangle\upH,\widetilde{\upB}^l\rrangle\leq K_l:=
        \begin{cases}
            4\llangle\frac{25}{\eta_0 h}\upI_{1:N_0}+\upH_{N_0+1:M},\upB^0\rrangle, & \text{ for }\, l=0,
            \\
            4\llangle\frac{25\cdot2^l}{\eta_0 K}\upI_{1:N_0}+\upH_{N_0+1:M},\widetilde{\upB}^{l-1}\rrangle, & \text{ for }\, l\in[1:L],
        \end{cases}
    \end{align}
    for arbitrary $N_0\in[0:D]$.
\end{lemma}
\begin{proof}
    For $\llangle\upH,\widetilde{\upB}^0\rrangle$, we apply Lemma \ref{period-bias-lemma} with $\eta=\eta_0$ and $\hat{T}=h$, and use the condition that $\widetilde{\calO}(C+2)\eta\tr(\upH)\leq1/4$; For $\llangle\upH,\widetilde{\upB}^l\rrangle$ with $l\geq 2$, we apply Lemma \ref{period-bias-lemma} with $\eta=\eta_0/2^l$, $\hat{T}=K$ and $\upB^0=\widetilde{\upB}^{l-1}$, and use the condition that $\widetilde{\calO}(C+2)\eta\tr(\upH)\leq1/4$.
\end{proof}

\begin{lemma}\label{lemma-Bias-diag-2}
    Suppose Assumption \ref{ass-d} and Assumption \ref{ass-ss} hold. Under the setting of Theorem \ref{phase-II-main}, we have
    \begin{align}
        \widetilde{\upB}_{\diag}^l\preceq\upR^l:=\begin{cases}
            \left(\upI-\eta_0\widehat{\upH}\right)^{h}\upB_{\diag}^0\left(\upI-\eta_0\widehat{\upH}\right)^{h}+P_0\overline{\upH}_0^h, & \text{ for }\, l=0,
            \\
            \left(\upI-\frac{\eta_0}{2^l}\widehat{\upH}\right)^{h}\widetilde{\upB}_{\diag}^{l-1}\left(\upI-\frac{\eta_0}{2^l}\widehat{\upH}\right)^{h}+P_l\overline{\upH}_l^K, & \text{ for }\, l\in[1:L],
        \end{cases}
    \end{align}
    where $\overline{\upH}_0^t:=\frac{25}{\eta_0 t}\upI_{1:N_0'}+\upH_{N_0'+1:M}$ and $\overline{\upH}_l^t:=\frac{25\cdot2^l}{\eta_0 t}\upI_{1:N_0'}+\upH_{N_0'+1:M}$ for any $t\geq1$ and arbitrary $N_0'\in[0:D]$, and $P_0:=\widetilde{\calO}(C+2)\eta_0^2h\langle\widetilde{\upH}_0^h,\upB^0\rangle$ with $\widetilde{\upH}_0^h:=\frac{25}{\eta_0 h}\upI_{1:N_0}+\upH_{N_0+1:M}$ and $P_l:=\widetilde{\calO}(C+2)(\frac{\eta_0}{2^l})^2K\langle\widetilde{\upH}_l^K,\widetilde{\upB}^{l-1}\rangle$ for $l\in[1:L]$ with $\widetilde{\upH}_l^K:=\frac{25\cdot2^l}{\eta_0 K}\upI_{1:N_0}+\upH_{N_0+1:M}$ for arbitrary $N_0\in[0:D]$.
\end{lemma}
\begin{proof}
    For $\widetilde{\upB}^0$, we apply Lemma \ref{bias-diag} with $\eta=\eta_0$ and $\hat{T}=h$, and use the condition that $\widetilde{\calO}(C+2)\eta\tr(\upH)\leq1/4$. For $\widetilde{\upB}^l$ with $l\geq 2$, we apply Lemma \ref{bias-diag} with $\eta=\eta_0/2^l$, $\hat{T}=K$ and $\upB^0=\widetilde{\upB}^{l-1}$, and use the condition that $\widetilde{\calO}(C+2)\eta\tr(H)\leq1/8$.
\end{proof}
\begin{lemma}\label{phase-II-thm-p1}
    Suppose Assumption \ref{ass-d} and Assumption \ref{ass-ss} hold. Under the setting of Theorem \ref{phase-II-main}, we have
    \begin{align}
        \llangle\upH,\upB^{T_2}\rrangle=\llangle\upH,\widetilde{\upB}^L\rrangle\leq e\llangle\upH,\widetilde{\upB}^1\rrangle
    \end{align}
\end{lemma}
\begin{proof}
    Consider $l\geq 1$. According to Lemma \ref{lemma-Bias-diag-2}, we obtain
    \begin{align}\label{exp-dynamic-Bias}
        \widetilde{\upB}_{\diag}^l\preceq&\left(\upI-\frac{\eta_0}{2^l}\widehat{\upH}\right)^{h}\widetilde{\upB}_{\diag}^{l-1}\left(\upI-\frac{\eta_0}{2^l}\widehat{\upH}\right)^{h}+P_l\widetilde{\upH}_l^K\notag
        \\
        \overset{\text{(a)}}{\preceq}&\widetilde{\upB}_{\diag}^{l-1}+\widetilde{\calO}(C+2)\log(K)\cdot\frac{\eta_0}{2^l}\cdot\llangle\upH,\widetilde{\upB}^{l-1}\rrangle\upI.
    \end{align}
    where (a) is derived from choosing $N_0'=D$ and $N_0=0$ in $\overline{\upH}_l^K$ and $\widetilde{\upH}_l^K$ for any $l\in[1:L]$, respectively, and $\upH_{D+1:M}\preceq\frac{\widetilde{\calO}(2^l)}{\eta_0K}\upI_{D+1:M}$. Eq.~\eqref{exp-dynamic-Bias} implies that
    \begin{align}\label{linear-relation-bias}
        \llangle\upH,\widetilde{\upB}^l\rrangle\leq\left(1+\widetilde{\calO}(C+2)\tr(\upH)\log(K)\cdot\frac{\eta_0}{2^l}\right)\llangle\upH,\widetilde{\upB}^{l-1}\rrangle.
    \end{align}
    Therefore, we have following estimation of bias iterations using Eq.~\eqref{linear-relation-bias}:
    \begin{align}
        \llangle\upH,\widetilde{\upB}^L\rrangle\leq&\prod_{l=1}^L\left(1+\widetilde{\calO}(C+2)\tr(\upH)\log(K)\cdot\frac{\eta_0}{2^l}\right)\llangle\upH,\widetilde{\upB}^1\rrangle\notag
        \\
        \leq&\exp\left\{\widetilde{\calO}(C+2)\eta_0\tr(\upH)\log(K)\sum_{l=1}^L2^{-l}\right\}\llangle\upH,\widetilde{\upB}^1\rrangle\notag
        \\
        \leq&e\llangle\upH,\widetilde{\upB}^1\rrangle.
    \end{align}
\end{proof}
\begin{lemma}\label{phase-II-thm-p2}
    Suppose Assumption \ref{ass-d} and Assumption \ref{ass-ss} hold. Under the setting of Theorem \ref{phase-II-main}, we have
    \begin{align}
        \llangle\upH,\widetilde{\upB}^{1}\rrangle\leq&8\llangle\frac{25}{\eta_0 K}\upI_{1:N_0}+\upH_{N_0+1:M},\left(\upI-\eta_0\widehat{\upH}\right)^{2h}\upB^0\rrangle\notag
        \\
        &+\widetilde{\calO}(C+2)\Gamma_K(\upH)\llangle\frac{25}{\eta_0h}\upI_{1:N_0'}+\upH_{N_0'+1:M},\upB^0\rrangle,
    \end{align}
    where $\Gamma_K(\upH):=\left(\frac{625N_0'}{K}+\frac{25\eta_0h}{K}\tr(\upH_{N_0'+1:N_0})+\eta_0^2h\tr(\upH_{N_0+1:M}^2)\right)$ for arbitrary $D\geq N_0\geq N_0'\geq 0$.
\end{lemma}
\begin{proof}
    According to Lemma \ref{lemma-Bias-tr-1}, we have
    \begin{align}
        \llangle\upH,\widetilde{\upB}^1\rrangle\leq8\llangle\frac{25}{\eta_0 K}\upI_{1:N_0}+\upH_{N_0+1:M},\widetilde{\upB}^0\rrangle,\notag
    \end{align}
    for arbitrary $N_0\in[0:D]$. Then, choosing $N_0=N_0'$ in Lemma \ref{lemma-Bias-diag-2}, we obtain
    \begin{align}
        \widetilde{\upB}_{\diag}^0\preceq&\left(\upI-\eta_0\widehat{\upH}\right)^h\upB_{\diag}^0\left(\upI-\eta_0\widehat{\upH}\right)^h\notag
        \\
        &+\widetilde{\calO}(C+2)\eta_0^2h\llangle\frac{25}{\eta_0h}\upI_{1:N_0'}+\upH_{N_0'+1:M},\upB^0\rrangle\left(\frac{25}{\eta_0h}\upI_{1:N_0'}+\upH_{N_0'+1:M}\right).\notag
    \end{align}
    Combining above two inequalities, we have
    \begin{align}
        \llangle\upH,\widetilde{\upB}^1\rrangle\leq&8\llangle\frac{25}{\eta_0 K}\upI_{1:N_0}+\upH_{N_0+1:M},\left(\upI-\eta_0\widehat{\upH}\right)^{2h}\upB^0\rrangle\notag
        \\
        &+\widetilde{\calO}(C+2)\eta_0^2h\llangle\frac{25}{\eta_0h}\upI_{1:N_0'}+\upH_{N_0'+1:M},\upB^0\rrangle\notag
        \\
        &\, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, 
        \, \, \, \, \, \, \, \, \, \, \times\llangle\frac{25}{\eta_0 K}\upI_{1:N_0}+\upH_{N_0+1:M},\frac{25}{\eta_0h}\upI_{1:N_0'}+\upH_{N_0'+1:M}\rrangle,\notag
    \end{align}
    where
    \begin{align}
        &\llangle\frac{25}{\eta_0 K}\upI_{1:N_0}+\upH_{N_0+1:M},\frac{25}{\eta_0h}\upI_{1:N_0'}+\upH_{N_0'+1:M}\rrangle\notag
        \\
        \leq&\frac{625N_0'}{\eta_0^2hK}+\frac{25}{\eta_0K}\tr(\upH_{N_0'+1:N_0})+\tr(\upH_{N_0+1:M}^2),
    \end{align}
    when $N_0>N_0'$.
\end{proof}
\begin{lemma}\label{bias-upper-bound}
    Suppose Assumptions \ref{ass-d} and \ref{ass-ss} hold. Under the setting of Theorem \ref{phase-II-main}, we have
    \begin{align}
        \llangle\upH,\upB^{T_2}\rrangle\lesssim&\llangle\frac{1}{\eta_0 K}\upI_{1:N_0}+\upH_{N_0+1:M},\left(\upI-\eta_0\widehat{\upH}\right)^{2h}\upB^0\rrangle\notag
        \\
        &+(C+2)\Gamma_K(\upH)\llangle\frac{1}{\eta_0h}\upI_{1:N_0'}+\upH_{N_0'+1:M},\upB^0\rrangle,
    \end{align}
    where $\Gamma_K(\upH):=\left(\frac{625N_0'}{K}+\frac{25\eta_0h}{K}\tr(\upH_{N_0'+1:N_0})+\eta_0^2h\tr(\upH_{N_0+1:M}^2)\right)$ for arbitrary $D\geq N_0\geq N_0'\geq 0$.
\end{lemma}
\begin{proof}
    Using Lemma \ref{phase-II-thm-p1} and Lemma \ref{phase-II-thm-p2} we directly obtain the results.
\end{proof}

Finally we finish the proof of Theorem \ref{phase-II-main}.
\begin{proof}[Proof of Theorem \ref{phase-II-main}]
    Combining Lemma \ref{variance-upper-bound} with Lemma \ref{bias-upper-bound}, we derive Eq.~\eqref{phaseII-p1}. Based on Theorem \ref{high-probability-phase-II}, the equality $\upw^{T_2}=\upv^{T_1+T_2}$ holds with probability at least $1-\delta$. By setting $N_0'=N_0=N_1'=N_1=D$ in Eq.~\eqref{phaseII-p1} and applying Markov's inequality, we obtain Eq.~\eqref{phaseII-p2}.
\end{proof}

\subsection{Proof of Main Results}

In this section, we finally complete the proof of main results o the global convergence of Algorithm \ref{SGD} in Theorem \ref{theorem-main-convergence}, based on the analysis of \textbf{Phase I} and \textbf{Phase II}. Before we propose the main Theorem \ref{theorem-main-convergence}, we set the parameter as follows:
\begin{equation}\label{para-setting-spec}
\small
    \begin{split}
&L_1=\widetilde{\calO}\left((\sigma^2+\calM^2(\upb))^2+\Hatsigmax(D)\right),\, \, \, L_2=\widetilde{\calO}(\sigma^2+\calM^2(\upb)),\, \, \, 
        L_3=1+\frac{L_1\Tildesigmax(D)\Barsigmin(D)}{\sigmin(D)},
    \end{split}
\end{equation}
\begin{theorem}\label{theorem-main-convergence}[General Version of Theorem \ref{theorem-3}]
	Under Assumption \ref{ass-d} and \ref{ass-ss}, we consider a predictor trained by Algorithm \ref{SGD} with total sample size $T$. Let $h<T$ and $T_1:=\lceil(T-h)/\log(T-h)\rceil$. Suppose there exists $D\leq M$ such that $T_1\in[\frac{L_1L_3}{\sigmin(D)\Barsigmin(D)}, \frac{L_2L_3^2}{\Tildesigmax(D)\Barsigmin^2(D)}]$ with parameter setting Eq.~\eqref{para-setting-spec} and let $\eta=\widetilde{\Omega}(\frac{\Barsigmin(D)}{\sigma^2+\calM^2(\upb)})$. Then we have
    \begin{equation}
        \begin{split}
        \calR_M(\upv^{T})-\calR_M(\upv^*)\lesssim&\frac{\sigma^2D}{T_1}+\sigma^2\eta^2(h+T_1)\sum_{i=D+1}^M\lambda_i^2(\upv_i^*)^4\notag
        \\
        &+\frac{1}{\eta T_1}\tr\left(\left(\upI_{1:D}-\frac{\eta}{4}\upH_{1:D}^*\right)^{2h}\diag\left\{(\upv_{1:D}^*)^{\odot2}\right\}\right)\notag
        \\
        &+\llangle\upH_{D+1:M}^*,\diag\left\{(\upv_{D+1:M}^*)^{\odot2}\right\}\rrangle\notag
        \\
        &+\left(\frac{D}{T_1}+\eta^2h\tr\left((\upH_{D+1:M}^*)^2\right)\right)\llangle\frac{1}{\eta h}\upI_{1:D}+\upH_{D+1:M}^*,\diag\left\{(\upv^*)^{\odot2}\right\}\rrangle,\notag
        \end{split}
    \end{equation}
    with probability at least 0.95. Otherwise, let $T_1\in[\frac{L_1L_3}{\sigmin(M)\Barsigmin(M)},+\infty)$ with parameter setting Eq.~\eqref{para-setting-spec} and $\eta=\widetilde{\Omega}(\frac{\Barsigmin(M)}{\sigma^2+\calM^2(\upb)})$. Then we have
    \begin{equation}
        \begin{split}
        \calR_M(\upv^{T})-\calR_M(\upv^*)\lesssim&\frac{\sigma^2M}{T_1}+\frac{1}{\eta T_1}\tr\left(\left(\upI-\frac{\eta}{4}\upH^*\right)^{2h}\diag\left\{(\upv_{1:M}^*)^{\odot2}\right\}\right)\notag
        \\
        &+\frac{M}{\eta hT_1}\tr\left(\diag\left\{(\upv_{1:M}^*)^{\odot2}\right\}\right),\notag
        \end{split}
    \end{equation}
    with probability at least 0.95.
\end{theorem}
\begin{proof}
    Combining Theorem \ref{theorem_1} and Theorem \ref{phase-II-main}, we complete the proof.
\end{proof}