In this section, we introduce the proof techniques of the lower bound in Theorem \ref{theorem-lower-bound}. Recall the analysis in Phase I, $\upv^{T_1}$ satisfies the inequality $\overline{\upb} \leq \upv^{T_1} \leq \widehat{\upb}$ with high probability. Here, $\widehat{\upb}$ is defined as $\widehat{\upb}^{\top}=(\frac{3}{2}(\upv_{1:N}^*)^{\top},3(\upv_{N+1:M}^*)^{\top})$, while $\overline{\upb}$ is defined as $\overline{\upb}^{\top}=(\frac{1}{2}(\upv_{1:N}^*)^{\top},\mathbf{0}^{\top})$. We begin with the required concepts as below. A Markov chain $\{\breve{\upv}^t\}_{t=0}^{T_2}$ is constructed with initialization $\breve{\upv}^0$ satisfying $\overline{\upb} \leq \breve{\upv}^0 \leq \widehat{\upb}$. The update rule is defined by
\begin{align}\label{eq-bv}
     \breve{\upv}^{t+1}=\breve{\upv}^t-\eta_t\upH_{\breve{\upv}}^t\left(\breve{\upv}^t-\upv_{1:M}^*\right)+\eta_t\upR_{\breve{\upv}}^t\Pi_M\upx^t, \quad \forall t\in[0:T_2-1],\notag
\end{align}
% if $\overline{\upb}\leq\breve{\upv}^t\leq\widehat{\upb}$, let
% \begin{align}
%     \breve{\upv}^{t+1}=\breve{\upv}^t-\eta_t\upH_{\breve{\upv}}^t\left(\breve{\upv}^t-\upv_{1:M}^*\right)+\eta_t\upR_{\breve{\upv}}^t\Pi_M\upx^t,\notag
% \end{align}
% otherwise, let 
% \begin{align}
%     \breve{\upv}^{\tau+1}=\breve{\upv}^{\tau}-\eta_{\tau}\breve{\upH}^{\tau}(\breve{\upv}^{\tau}-\upv_{1:M}^*)+\eta_{\tau}\breve{\upR}^{\tau}\Pi_M\upx^{\tau},\quad\forall \tau\in[t:T_2-1],\notag
% \end{align}
where $\upH_{\breve{\upv}}^{t}$ and $\upR_{\breve{\upv}}^t$ satisfy: 
\begin{enumerate}
    \item If $\overline{\upb}\leq\breve{\upv}^t\leq\widehat{\upb}$, $\upH_{\breve{\upv}}^{t}=(\breve{\upv}^t\odot\Pi_M\upx^t)\otimes((\breve{\upv}^t+\upv_{1:M}^*)\odot\Pi_M\upx^t)$ and $\upR_{\breve{\upv}}^t=(\xi^t+\sum_{i=M+1}^{\infty}\upx_i^t(\upv_i^*)^2)\diag\{\breve{\upv}^t\}$,
    \item Otherwise, for any $\tau\in[t:T_2-1]$,  $\upH_{\breve{\upv}}^{\tau}=\frac{25}{4}(\upv_{1:M}^*\odot\Pi_{M}\upx^{\tau})\otimes(\upv_{1:M}^*\odot\Pi_{M}\upx^{\tau})$ and $\upR_{\breve{\upv}}^{\tau}=(\xi^{\tau}+\sum_{i=M+1}^{\infty}\upx_i^{\tau}(\upv_i^*)^2)$ $\diag\{\overline{\upb}\}$.
\end{enumerate}
Let $\breve{\upw}^t:=\breve{\upv}^t-\upv_{1:M}^*$ be the error vector, and let $t_s:=\inf\{t\mid \breve{\upv}^t\nleqslant\widehat{\upb}\bigvee\breve{\upv}^t\ngeqslant\overline{\upb}\}$ be the stopping time. According to Eq.~\eqref{eq-bv}, $\{\breve{\upw}^t\}_{t=1}^{T_2}$ is recursively defined by
\begin{align}
		\breve{\upw}^{t+1}=\left(\upI-\eta_t\upH_{\breve{\upv}}^t\right)\breve{\upw}^t+\eta_t\upR_{\breve{\upv}}^t\Pi_M\upx^t. \notag
\end{align}
% Analogous to Phase II analysis, the dynamics of $\breve{\upw}^t$ can be decomposed into two random processes,
% \begin{align}
%     \breve{\upw}^t=\breve{\upw}_{\bi}^t+\breve{\upw}_{\var}^t,
% \end{align}
% for any $t\in[0:T_2]$, where $\{\breve{\upw}_{\var}^t\}_{t=1}^{T_2}$ is recursively defined by
% \begin{align}
% 		\breve{\upw}_{\var}^{t+1}=\left(\upI-\eta_t\upH_{\breve{\upv}}^t\right)\breve{\upw}_{\var}^t+\eta_t\upR_{\breve{\upv}}^t\Pi_M\upx^t, \notag
% \end{align}
% for any $t\in[0:T_2-1]$ with $\breve{\upw}_{\var}^0=0$ and $\{\breve{\upw}_{\bi}^t\}_{t=1}^{T_2}$ is recursively defined by
% \begin{align}
% 		\breve{\upw}_{\bi}^{t+1}=\left(\upI-\eta_t\upH_{\breve{\upv}}^t\right)\breve{\upw}_{\bi}^t, \notag
% \end{align}
% for any $t\in[0:T_2-1]$ with  $\breve{\upw}_{\bi}^0=\breve{\upv}^0-\upv_{1:M}^*$. 
We define $\breve{\upV}^t=\bbE\left[\breve{\upw}^t\otimes\breve{\upw}^t\right]$. By the definitions of $\calH_{\cdot}^t$, $\widetilde{\calH}_{\cdot}^t$, $\calG_{\cdot}^t$, and $\widetilde{\calG}_{\cdot}^t$ in Phase II, we derive the iterative relationship governing the sequence $\{\breve{\upV}^t\}_{t=0}^{T_2}$:
\begin{align}
	% \begin{cases}
 %        \breve{\upB}^{t+1}&=\left(\calI-\eta_t\calG_{\breve{\upv}}^t\right)\circ\breve{\upB}^t,
	% 	\\
		\breve{\upV}^{t+1}&=\bbE\left[\left(\calI-\eta_t\calG_{\breve{\upv}}^t\right)\circ\left(\breve{\upw}^t\otimes\breve{\upw}^t\right)\right]+\eta_t^2\upSigma_{\breve{\upv}}^t,
	% \end{cases}
\end{align}
for $t\in[0:T_2-1]$ with $\upV^0=\left(\upw^0-\upv_{1:M}^*\right)\otimes\left(\upw^0-\upv_{1:M}^*\right)$. If $t<t_s$, $\upSigma_{\breve{\upv}}^t=\sigma^2\upLambda\diag\{\breve{\upv}^{t\odot2}\}$; otherwise, $\upSigma_{\breve{\upv}}^{\tau}=\sigma^2\upLambda\diag\{\overline{\upb}^{\odot2}\}$ for any $\tau\geq t$. According to the definitions above, we obtain following estimation of the last-iteration function value:
\begin{align}\label{lower-bound-I}
    \bbE\left[\calR_M(\breve{\upw}^{T_2})-\calR_M(\upv_{1:M}^*)\right]\geq\frac{1}{24}\llangle\breve{\upH},\bbE\left[\breve{\upw}^{T_2}\otimes\breve{\upw}^{T_2}\right]\rrangle\geq\frac{1}{24}\llangle\breve{\upH},\breve{\upV}^{T_2}\rrangle,
\end{align}
where $\breve{\upH}:=12\upLambda\diag\{\upv_{1:M}^*\odot\upv_{1:M}^*\}$. We define $\breve{\calG}^i:=\breve{\upH}\otimes\upI+\upI\otimes\breve{\upH}-\eta_i\breve{\upH}\otimes\breve{\upH}$. We formally propose the lower bound of the estimate in Theorem \ref{theorem-lower-bound} as below.

\begin{theorem}[General Version of Theorem \ref{lower-bound}] \label{theorem-lower-bound}
    Under Assumptions \ref{ass-dd} and \ref{ass-s}, we consider a predictor trained by Algorithm \ref{SGD} with iteration number $T$. Suppose there exists $N\leq M$ such that $T_1\in[\widetilde{\calO}(\frac{\sigma^2+\mathcal{M}^2(\upb)}{\eta\sigmin(N)}),\widetilde{\Theta}(\frac{\Tildesigmax^{-1}(N)}{\eta^2(\sigma^2+\mathcal{M}^2(\upb))})]$, where $\eta\leq\widetilde{\Theta}(\frac{\Barsigmin(N)}{(\sigma^2+\mathcal{M}^2(\upb))^2})$ and $T_1:=\lceil(T-h)/\log(T-h)\rceil$ with $h\geq T_1$. Then we have
    \begin{align}
    \bbE\left[\calR_M(\upv^{T})-\calR_M(\upv_{1:M}^*)\right]\gtrsim\sigma^2\left(\frac{H_1}{T_1}+\eta\sum_{i=H_1+1}^{H_2}\lambda_i(\upv_i^*)^2+\eta^2h\sum_{i=H_2+1}^{N}\lambda_i^2(\upv_i^*)^4\right),\notag
\end{align}
where $H_1:=\min\{N,\max\{i\mid\lambda_i(\upv_i^*)^2\geq\frac{1}{12\eta T_1}\}\}$ and $H_2:=\min\{N,\max\{i\mid\lambda_i(\upv_i^*)^2\geq\frac{1}{12\eta h}\}\}$. Otherwise, let $T_1\in[\widetilde{\calO}(\frac{\sigma^2+\mathcal{M}^2(\upb)}{\eta\sigmin(M)}),+\infty)$, where $\eta\leq\widetilde{\Theta}(\frac{\Barsigmin(M)}{(\sigma^2+\mathcal{M}^2(\upb))^2})$ and $T_1:=\lceil(T-h)/\log(T-h)\rceil$ with $h\geq T_1$. Then we have
    \begin{align}
    \bbE\left[\calR_M(\upv^{T})-\calR_M(\upv_{1:M}^*)\right]\gtrsim\sigma^2\left(\frac{H_1'}{T_1}+\eta\sum_{i=H_1'+1}^{H_2'}\lambda_i(\upv_i^*)^2+\eta^2h\sum_{i=H_2'+1}^{N}\lambda_i^2(\upv_i^*)^4\right),\notag
\end{align}
where $H_1':=\min\{M,\max\{i\mid\lambda_i(\upv_i^*)^2\geq\frac{1}{12\eta T_1}\}\}$ and $H_2':=\min\{M,\max\{i\mid\lambda_i(\upv_i^*)^2\geq\frac{1}{12\eta h}\}\}$.
\end{theorem}
\begin{proof}
    Setting $\eta_0 = \eta$, we have 
    \begin{align}
        \breve{\upV}_{\diag}^{t+1}=&\left(\bbE\left[\left(\calI-\eta_t\widetilde{\calG}_{\breve{\upv}}^t\right)\circ\left(\breve{\upw}^t\otimes\breve{\upw}^t\right)\right]\right)_{\diag}+\eta_t^2\left(\bbE\left[\left(\calH_{\breve{\upv}}^t-\widetilde{\calH}_{\breve{\upv}}^t\right)\circ\left(\breve{\upw}^t\otimes\breve{\upw}^t\right)\right]\right)_{\diag}+\eta_t^2\Sigma_{\breve{\upv}}^t\notag
        \\
        \succeq&\left(\calI-\eta_t\breve{\calG}^t\right)\circ\breve{\upV}_{\diag}^t+\eta_t^2\sigma^2\upLambda\diag\left\{\overline{\upb}^{\odot2}\right\}.\notag
    \end{align}
    According to the recursive step above, we obtain
    \begin{align}\label{lower-bound-proof-I}
        \breve{\upV}^{T_2}
        % \succeq&\sigma^2\sum_{t=1}^{T_2}\eta_t^2\prod_{i=t+1}^{T_2}\left(\calI-\eta_i\widetilde{\calG}_{\breve{\upv}}^i\right)\circ\upLambda\diag\left\{\overline{\upb}^{\odot2}\right\}\notag
        % \\
        \succeq&\sigma^2\sum_{t=1}^{T_2}\eta_t^2\prod_{i=t+1}^{T_2}\left(\upI-\eta_i\breve{\upH}\right)^2\upLambda\diag\left\{\overline{\upb}^{\odot2}\right\}\notag
        \\
        \succeq&\sigma^2\underbrace{\sum_{t=1}^{T_2}\eta_t^2\prod_{i=t+1}^{T_2}\left(\upI-2\eta_i\breve{\upH}\right)\upLambda\diag\left\{\overline{\upb}^{\odot2}\right\}}_{\calcolI}.
    \end{align}
    Recalling the step size decay rule in Algorithm \ref{SGD}, we have
    \begin{align}\label{lower-bound-proof-2}
        \calcolI=&\eta_0^2\sum_{i=1}^h\left(\upI-2\eta_0\breve{\upH}\right)^{h-i}\prod_{j=1}^{L-1}\left(\upI-\frac{\eta_0}{2^{j-1}}\breve{\upH}\right)^K\upLambda\diag\left\{\overline{\upb}^{\odot2}\right\}\notag
	\\
	&+\sum_{l=1}^{L-1}\left(\frac{\eta_0}{2^l}\right)^2\sum_{i=1}^K\left(\upI-\frac{\eta_0}{2^{l-1}}\breve{\upH}\right)^{K-i}\prod_{j=l+1}^{L-1}\left(\upI-\frac{\eta_0}{2^{j-1}}\breve{\upH}\right)^K\upLambda\diag\left\{\overline{\upb}^{\odot2}\right\}\notag
	\\
	=&\frac{\eta_0^2}{12}\sum_{i=1}^h\left(\upI_{1:N}-2\eta_0\breve{\upH}_{1:N}\right)^{h-i}\prod_{j=1}^{L-1}\left(\upI_{1:N}-\frac{\eta_0}{2^{j-1}}\breve{\upH}_{1:N}\right)^K\breve{\upH}_{1:N}\notag
	\\
	&+\frac{1}{12}\sum_{l=1}^{L-1}\left(\frac{\eta_0}{2^l}\right)^2\sum_{i=1}^K\left(\upI_{1:N}-\frac{\eta_0}{2^{l-1}}\breve{\upH}_{1:N}\right)^{K-i}\prod_{j=l+1}^{L-1}\left(\upI_{1:N}-\frac{\eta_0}{2^{j-1}}\breve{\upH}_{1:N}\right)^K\breve{\upH}_{1:N}\notag
	\\
	=&\frac{\eta_0}{24}\left(\upI_{1:N}-\left(\upI_{1:N}-2\eta_0\breve{\upH}_{1:N}\right)^h\right)\left(\prod_{j=1}^{L-1}\left(\upI_{1:N}-\frac{\eta_0}{2^{j-1}}\breve{\upH}_{1:N}\right)\right)^K\notag
	\\
	&+\sum_{l=1}^{L-1}\frac{\eta_0}{12\cdot 2^{l+1}}\left(\upI_{1:N}-\left(\upI_{1:N}-\frac{\eta_0}{2^{l-1}}\breve{\upH}_{1:N}\right)^K\right)\left(\prod_{j=l+1}^{L-1}\left(\upI_{1:N}-\frac{\eta_0}{2^{j-1}}\breve{\upH}_{1:N}\right)\right)^K\notag
	\\
	\overset{\text{(a)}}{\geq}&\frac{\eta_0}{24}\left(\upI_{1:N}-\left(\upI_{1:N}-2\eta_0\breve{\upH}_{1:N}\right)^h\right)\left(\upI_{1:N}-2\eta_0\breve{\upH}_{1:N}\right)^K\notag
	\\
	&+\sum_{l=1}^{L-1}\frac{\eta_0}{12\cdot 2^{l+1}}\left(\upI_{1:N}-\left(\upI_{1:N}-\frac{\eta_0}{2^{l-1}}\breve{\upH}_{1:N}\right)^K\right)\left(\upI_{1:N}-\frac{\eta_0}{2^{l-1}}\breve{\upH}_{1:N}\right)^K,
    \end{align}
    where (a) is derived from following inequality
\begin{align}
	\prod_{i=l+1}^{L-1}\left(\upI_{1:N}-\frac{\eta_0}{2^{i-1}}\breve{\upH}_{1:N}\right)\geq\upI_{1:N}-\sum_{i=l+1}^{L-1}\frac{\eta_0}{2^{i-1}}\breve{\upH}\geq\upI_{1:N}-\frac{\eta_0}{2^{l-1}}\breve{\upH}_{1:N}.\notag
\end{align}
When $h > K$, we apply an auxiliary function analogous to [Lemma D.1, \citet{wu2022last}] s:
\begin{align}
    f(x):=\frac{x}{2}\left(1-\left(1-2x\right)^h\right)(1-2x)^K+\sum_{l=1}^{L-1}\frac{x}{2^{l+1}}\left(1-\left(1-\frac{x}{2^{l-1}}\right)^K\right)\left(1-\frac{x}{2^{l-1}}\right)^K.\notag
\end{align}
Then, we obtain
\begin{align}\label{lower-bound-proof-III}
    f(\eta_0\breve{\upH})\succeq\frac{1}{4800K}\upI_{1:H_1}+\frac{\eta_0}{480}\breve{\upH}_{H_1+1:H_2}+\frac{\eta_0^2h}{480}\breve{\upH}_{H_2+1:N}^2,
\end{align}
where $H_1:=\min\{N,\max\{i\mid\lambda_i(\upv_i^*)^2\geq\frac{1}{12\eta_0K}\}\}$ and $H_2:=\min\{N,\max\{i\mid\lambda_i(\upv_i^*)^2\geq\frac{1}{12\eta_0h}\}\}$. Therefore, using Eq.~\eqref{lower-bound-I}-Eq.~\eqref{lower-bound-proof-III}, we derive 
\begin{align}
    \bbE\left[\calR_M(\breve{\upv}^{T_2})-\calR_M(\upv_{1:M}^*)\right]\geq&\frac{\sigma^2}{11520}\llangle\breve{\upH},\frac{1}{10K}\breve{\upH}_{1:H_1}^{-1}+\eta_0\upI_{H_1+1:H_2}+\eta_0^2h\breve{\upH}_{H_2+1:N}\rrangle\notag
    \\
    =&\frac{\sigma^2}{11520}\left(\frac{H_1}{10K}+12\eta_0\sum_{i=H_1+1}^{H_2}\lambda_i(\upv_i^*)^2+144\eta_0^2h\sum_{i=H_2+1}^{N}\lambda_i^2(\upv_i^*)^4\right).\notag
\end{align}
According to Lemma \ref{high-probability-phase-II}, we have $\mathbb{P}(t_s\leq T_2)\leq\delta$, which implies that 
\begin{align}\label{lower-bound-proof-IV}
    &\bbE\left[\calR_M(\breve{\upv}^{T_2})-\calR_M(\upv_{1:M}^*)\mid t_s>T_2\right]\notag
    \\
    \geq&\bbE\left[\calR_M(\breve{\upv}^{T_2})-\calR_M(\upv_{1:M}^*)\right]-\sum_{i=1}^{T_2}\bbP(t_s=i)\bbE\left[\calR_M(\breve{\upw}^{T_2})-\calR_M(\upv_{1:M}^*)\mid t_s=i\right]\notag
    \\
    \overset{\text{(b)}}{\geq}&\frac{\sigma^2}{23040}\left(\frac{H_1}{10K}+12\eta_0\sum_{i=H_1+1}^{H_2}\lambda_i(\upv_i^*)^2+144\eta_0^2h\sum_{i=H_2+1}^{N}\lambda_i^2(\upv_i^*)^4\right).
\end{align}
Since $\delta$ is sufficiently small, (b) is drawn from two facts: 1) $\breve{\upv}^{t_s}$ resides in a bounded neighborhood of $\widehat{\upb}$ or $\overline{\upb}$; 2) the risk upper bound for SGD established in [Theorem 4.1, \citet{wu2022last}]. The lower bound established in Eq.~\eqref{lower-bound-proof-IV} is uniformly valid for all $\breve{\upv}^0\in[\overline{\upb},\widehat{\upb}]$, as it remains independent of the initial condition $\breve{\upv}^0$. In particular, for $t_s > T_2$, the trajectory $\{\breve{\upv}^t\}_{t=0}^{T_2}$ aligns with Algorithm \ref{SGD}'s iterations over $[T_1, T]$, given the initialization $\breve{\upv}^0 = \upv^{T_1} \in [\overline{\upb}, \widehat{\upb}]$. Then, we have
\begin{align}\label{lower-bound-proof-V}
    &\min_{\overline{\upb}\leq\upv^{T_1}\leq\widehat{\upb}}\bbE\left[\calR_M(\upv^{T})-\calR_M(\upv_{1:M}^*)\mid \upv^{T_1}\right]\notag
    \\
    \geq&(1-\delta)\min_{\overline{\upb}\leq\upv^{T_1}\leq\widehat{\upb}}\bbE\left[\calR_M(\breve{\upv}^{T_2})-\calR_M(\upv_{1:M}^*)\mid t_s>T_2,\breve{\upv}^0 = \upv^{T_1}\right]\notag
    \\
    \gtrsim&\sigma^2\left(\frac{H_1}{K}+\eta_0\sum_{i=H_1+1}^{H_2}\lambda_i(\upv_i^*)^2+\eta_0^2h\sum_{i=H_2+1}^{N}\lambda_i^2(\upv_i^*)^4\right).
    % \notag
    % \\
    % \geq&\frac{\sigma^2}{46080}\left(\frac{T_1}{10K}+12\eta_0\sum_{i=T_1+1}^{T_2}\lambda_i(\upv_i^*)^2+144\eta_0^2h\sum_{i=T_2+1}^{N}\lambda_i^2(\upv_i^*)^4\right).
\end{align}
Noticing that $\upv^{T_1}\in[\overline{\upb}:\widehat{\upb}]$ occurs with probability at least $1-\delta$, and combining Eq.~\eqref{lower-bound-proof-IV} with Eq.~\eqref{lower-bound-proof-V}, we obtain
\begin{align}
    \bbE\left[\calR_M(\upv^{T})-\calR_M(\upv_{1:M}^*)\right]\geq&(1-\delta)\min_{\overline{\upb}\leq\upv^{T_1}\leq\widehat{\upb}}\bbE\left[\calR_M(\upv^{T})-\calR_M(\upv_{1:M}^*)\mid\upv^{T_1}\right]\notag
    \\
    \gtrsim&\sigma^2\left(\frac{H_1}{K}+\eta_0\sum_{i=H_1+1}^{H_2}\lambda_i(\upv_i^*)^2+\eta_0^2h\sum_{i=H_2+1}^{N}\lambda_i^2(\upv_i^*)^4\right),\notag
\end{align}
where $H_1:=\min\{N,\max\{i\mid\lambda_i(\upv_i^*)^2\geq\frac{1}{12\eta_0K}\}\}$ and $H_2:=\min\{N,\max\{i\mid\lambda_i(\upv_i^*)^2\geq\frac{1}{12\eta_0h}\}\}$. We complete the proof of lower bound.
\end{proof}
