\section{Related Work}
\noindent\textbf{Vision Language Models for VQA.} In the field of autonomous driving, the application of Vision-Language Models (VLMs) is rapidly expanding____, enhancing the system's understanding of and decision-making capabilities in complex driving environments. VLMs, through extensive image-text pre-training, have already provided the ability for zero-shot learning in autonomous driving____. For example, the DriveVLM____ system explores the integration of VLMs within traditional autonomous driving technologies, enhancing the vehicle's spatial reasoning and planning capabilities. Additionally, the DriVLMe____ and Co-driver____ projects explore how LLMs mimic human understanding and behavior in handling complex road conditions from the perspectives of experiential learning and social interaction, respectively. In recent years, Vision-Question-Answering (VQA) datasets for autonomous driving, such as the Nuscenes-QA____dataset, DriveLM dataset____, have further facilitated advancements in the multimodal understanding of driving scenarios. In our model, we delve deeper into the field of continual learning for autonomous driving, building upon the EM-VLM4AD____ framework.  

\noindent\textbf{Continual Learning.} Continual learning (CL) techniques like memory replay____, regularization____, and optimization____ mitigate catastrophic forgetting by balancing new and old tasks. Memory replay stores key data or features in a buffer, using methods such as random selection____ or feature averaging____. Regularization approaches add terms that selectively preserve crucial parameters based on their importance, assessed using tools like the Fisher Information Matrix (FIM)____. Optimization methods, such as OGD____, maintain previous gradient directions while adjusting current gradients for orthogonality. However, in our approach, we employ some techniques for text vectorization and clustering of different tasks in the dataset to optimize data selection in the memory replay mechanism. In addition to this, we naturally combine memory replay with knowledge distillation (KD), which additionally integrates the past information of the old model. Due to the relatively large number of parameters in the VLM, regularization with gradient projection via parametric aspects is not very practical. Therefore, we emulated the idea of regularization and projection. We did this by comparing the projection layer gaps between different tasks after the model's feature embedding was introduced. Additionally, we added extra terms to the loss function to further enhance the continual learning effect at the model's feature level.