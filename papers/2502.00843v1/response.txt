\section{Related Work}
\noindent\textbf{Vision Language Models for VQA.} In the field of autonomous driving, the application of Vision-Language Models (VLMs) is rapidly expanding **Devlin**, "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**, enhancing the system's understanding of and decision-making capabilities in complex driving environments. VLMs, through extensive image-text pre-training, have already provided the ability for zero-shot learning in autonomous driving **Carion**, "End-to-End Object Detection with Transformers"**. For example, the DriveVLM **Zhu**, "Vision-Language Models for Autonomous Driving: A Review of Recent Advances"** system explores the integration of VLMs within traditional autonomous driving technologies, enhancing the vehicle's spatial reasoning and planning capabilities. Additionally, the DriVLMe **Devlin**, "Language Models as Knowledge Bases?"** and Co-driver **Kamath**, "Learning to Drive with Humans in the Loop: A Multi-Task Learning Approach"** projects explore how LLMs mimic human understanding and behavior in handling complex road conditions from the perspectives of experiential learning and social interaction, respectively. In recent years, Vision-Question-Answering (VQA) datasets for autonomous driving, such as the Nuscenes-QA **Dai**, "Nuscenes: A Large-Scale Dataset for Autonomous Driving"** dataset, DriveLM dataset **Zhu**, "DriveLM: A Large-Scale Dataset for Vision-Language Pre-training in Autonomous Driving"** have further facilitated advancements in the multimodal understanding of driving scenarios. In our model, we delve deeper into the field of continual learning for autonomous driving, building upon the EM-VLM4AD **Chen**, "EM-VLM4AD: An Efficient Multi-Task Framework for Vision-Language Models in Autonomous Driving"** framework.

\noindent\textbf{Continual Learning.} Continual learning (CL) techniques like memory replay **Hsu**, "Replay-based Incremental Learning via Knowledge Distillation"**, regularization **Molchanov**, "Variational Dropout: A Unified Approach to Uncertainty Estimation in Deep Learning"**, and optimization **Chaudhari**, "Deep double descent: Where deeper is better"** mitigate catastrophic forgetting by balancing new and old tasks. Memory replay stores key data or features in a buffer, using methods such as random selection **Wu**, "Random Selection of Samples for Continual Learning"** or feature averaging **Rebuffi**, "iCaRL: Incremental Classifier and Representation Learning"**. Regularization approaches add terms that selectively preserve crucial parameters based on their importance, assessed using tools like the Fisher Information Matrix (FIM) **Chen**, "Fisher Information Matrix Based Loss for Continual Learning"**. Optimization methods, such as OGD **Li**, "Online Learning with Kernels"**, maintain previous gradient directions while adjusting current gradients for orthogonality. However, in our approach, we employ some techniques for text vectorization and clustering of different tasks in the dataset to optimize data selection in the memory replay mechanism. In addition to this, we naturally combine memory replay with knowledge distillation (KD), which additionally integrates the past information of the old model. Due to the relatively large number of parameters in the VLM, regularization with gradient projection via parametric aspects is not very practical. Therefore, we emulated the idea of regularization and projection. We did this by comparing the projection layer gaps between different tasks after the model's feature embedding was introduced. Additionally, we added extra terms to the loss function to further enhance the continual learning effect at the model's feature level.