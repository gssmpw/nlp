
\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage[pagenumbers]{cvpr}
\input{preamble}

\input{math_commands.tex}

\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,allcolors=cvprblue]{hyperref}


\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{booktabs} 
\usepackage{multirow}
\usepackage{pifont}%
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
% \usepackage{minted}
\usepackage{sidecap}

\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{xcolor}

\def\paperID{2239} %
\def\confName{CVPR}
\def\confYear{2025}

\definecolor{mydarkblue}{RGB}{0,0,160} %
\newcommand\mycommfont[1]{\footnotesize\ttfamily\textcolor{mydarkblue}{#1}}
\SetCommentSty{mycommfont}
\SetKwInOut{Parameter}{Hyperparams}

\title{DiSciPLE: Learning Interpretable Programs for Scientific Visual Discovery}


\author{
Utkarsh Mall$^{1}$ \hspace{0.05cm} Cheng Perng Phoo$^{2}$  \hspace{0.05cm} Mia Chiquier$^{1}$ \hspace{0.05cm}
Bharath Hariharan$^{2}$ \hspace{0.05cm}  Kavita Bala$^{2}$ \hspace{0.05cm} Carl Vondrick$^{1}$\\
         $^{1}$Columbia University \qquad
        $^{2}$ Cornell University\\
        \small{\enspace Correspondence: \tt{um2171@columbia.edu}
}\\
\href{https://disciple.cs.columbia.edu/}{disciple.cs.columbia.edu}
}


\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\newcommand{\best}[1]{\textbf{\textcolor{red}{#1}}}
\newcommand{\sota}[1]{\emph{\textcolor{blue}{#1}}}
\newcommand{\second}[1]{\emph{\textcolor{blue}{#1}}}

\def\disciple{DiSciPLE}

\begin{document}

\maketitle
\begin{abstract}


Visual data is used in numerous different scientific workflows ranging from remote sensing to ecology. As the amount of observation data increases, the challenge is not just to make accurate predictions but also to understand the underlying mechanisms for those predictions. 
Good interpretation is important in scientific workflows, as it allows for better decision-making by providing insights into the data. 
This paper introduces an automatic way of obtaining such interpretable-by-design models, by learning programs that interleave neural networks. We propose \disciple~(Discovering Scientific Programs using LLMs and Evolution) an evolutionary algorithm that leverages common sense and prior knowledge of large language models (LLMs) to create Python programs explaining visual data. Additionally, we propose two improvements: a program critic and a program simplifier to improve our method further to synthesize good programs. On three different real-world problems, \disciple~learns state-of-the-art programs on novel tasks with no prior literature. For example, we can learn programs with 35\% lower error than the closest non-interpretable baseline for population density estimation. The supplementary material can be found at: \href{https://disciple.cs.columbia.edu/pdf/supplementary.pdf}{https://disciple.cs.columbia.edu/pdf/supplementary.pdf}




\end{abstract}


\input{sections/new_introduction}
\input{sections/related_works}
\input{sections/method}
\input{sections/results_arxiv}
\input{sections/conclusion}
\input{sections/acknowledgements}
% \clearpage
{
\small
\bibliographystyle{ieeenat_fullname}
\bibliography{indest}
}
\clearpage
\appendix


\end{document}
