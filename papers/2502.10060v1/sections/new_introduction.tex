\section{Introduction}
\label{sec:intro}

Many modern scientific workflows are built on top of visual data. 
Researchers in remote sensing, climate science, ecology, and other sciences use images as a window into our world to estimate population density, the amount of biomass, poverty indicators, and so on. There is a massively increasing volume of visual data, be it from an ever-expanding set of satellites, widespread camera traps, or images uploaded on the web, that is available to domain experts, and computer vision has the potential to meaningfully assist scientists in using it for scientific insight.

Scientific applications of computer vision, however, are demanding tasks because we want models that not only predict outcomes but also reveal underlying mechanisms. For example, a researcher who studies demography may be able to train excellent predictive models that learn the relationships between a satellite image and the population.
However, understanding why certain regions are densely populated is crucial for urban planning and policy decisions --- black-box predictions offer no interpretation of what makes a region have a high population. 
Scientists themselves want to derive insight from the models, not just predict.

\begin{figure}[t!]
    \centering
\includegraphics[width=\linewidth]{figures/teaser.png} %
\caption{We introduce a framework to discover interpretable, predictive programs for scientific computer vision tasks.}
\label{fig:teaser}
\end{figure}


While there have been many works that train interpretable vision models (for example concept-bottlenecks~\citep{koh20concept,menon2022visual}), these models are often limited to simple functions of primitive concepts, such as bag of words.
These simple functions do not scale to the realistic complexity of our visual world and the complex relationships between its many rich scientific indicators, resulting in poor accuracy. 
A promising direction to model rich relationships without foregoing interpretability is to learn \emph{programs} on top of conceptual primitives.
Recently, code generation methods such as ViperGPT and VisProg \cite{suris-23,gupta2023visual} have demonstrated that large language models are able to synthesize programs with competitive performance on many vision tasks, and the representations are interpretable by construction because programs are human-readable. However, while these methods work well for established vision tasks, they often fail to generalize to scientific applications of computer vision because the tasks are new and outside the scope of the training data on the internet. LLMs lack the requisite knowledge to answer novel or domain-specific questions, and as we will show, directly applying such zero-shot code generation methods on scientific domains is not effective.


How can we automatically discover accurate and interpretable programs from the volumes of visual data in scientific applications? This paper introduces DiSciPLE, a framework for \textbf{Di}scovering \textbf{Sci}entific \textbf{P}rograms  using \textbf{L}LMs
and \textbf{E}volution. Given a large dataset of images, our approach learns to synthesize a program for solving the task. As the name suggests,~\disciple~introduces an evolutionary search algorithm that starts with zero-shot programs from LLMs and iteratively improves them over the dataset. The discovered programs are able to interleave neural networks, in particular open-world segmentation foundation models, for segmentation with logical and mathematical operations, enabling powerful predictions while also being interpretable. Our framework makes several improvements to integrate evolutionary search with LLMs, using program simplification and critics to provide fine-grained guidance that accelerates program search.

In three different scientific applications of computer vision, ~\disciple~is able to learn state-of-the-art programs for novel tasks that have no prior documented solutions in existing literature. Our approach significantly outperforms neural networks at estimating population density from satellite imagery. Our method also obtains strong out-of-distribution performance at estimating a regionâ€™s biomass,  generalizing to geographical regions outside of the training set significantly better than all other baselines. 

Our contributions are:
\begin{itemize}
    \item We introduce a novel framework \textbf{\disciple}, that can produce interpretable, reliable, and sample-efficient programs for scientific discovery.
    \item We present two key components: a critic and a program simplification method to \disciple~that can further improve the search resulting in better programs.
    \item We propose benchmarks for the task of scientific visual discovery containing real-world high-dimensional visual data for three problems in two different domains. We also apply \disciple~on these benchmarks and show that our learned programs are more interpretable, reliable, and data-efficient compared to baselines.    
\end{itemize}





















