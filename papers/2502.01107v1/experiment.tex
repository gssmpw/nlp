\section{Experiments}
\begin{table*}[t]
\small
\centering
\fontsize{7}{8}\selectfont
\setlength{\tabcolsep}{8pt}
\begin{tabular}{c|c|cccccccccc|cc}
\toprule
Target & Metric & RW & DE & SE & TG & SG & SV & MS & TT & DT & VO & GTG$^{1}$ & GTG$^{2}$ \\
\midrule
\multirow{7}{*}{BJ} & Distance & 0.0434 & 0.1509 & 0.1662 & 0.2980 & 0.2320 & 0.0080 & 0.1826 & 0.0107 & 0.0173 & 0.1893 & \textbf{0.0006} & \underline{0.0006} \\ 
    & Radius & 0.1191 & 0.1332 & 0.1543 & 0.2180 & 0.2070 & 0.0098 & 0.1450 & 0.0071 & 0.0019 & 0.0518 & \textbf{0.0001} & \underline{0.0002} \\ 
    & LocFreq & 0.198 & 0.076 & 0.196 & 0.187 & 0.038 & 0.044 & 0.410 & 0.095 & 0.216 & 0.145 & \textbf{0.041} & \underline{0.043} \\ 
    & Hausdorff & 2.682 & 3.833 & 3.807 & 7.228 & 10.469 & 3.294 & 7.523 & 1.092 & 3.305 & 5.680 & \textbf{0.292} & \underline{0.315} \\ 
    & DTW & 51.54 & 58.88 & 58.49 & 185.17 & 149.49 & 61.99 & 145.38 & 24.27 & 74.26 & 89.82 & \textbf{4.89} & \underline{5.27} \\ 
    & EDT & 28.17 & 29.85 & 29.90 & 42.93 & 27.31 & 26.20 & 31.07 & 18.13 & 31.42 & 29.17 & \textbf{8.73} & \underline{9.17} \\ 
    & EDR & 0.813 & 0.904 & 0.906 & 0.820 & 0.903 & 0.751 & 0.942 & 0.423 & 0.889 & 0.850 & \textbf{0.190} & \underline{0.205} \\
\midrule
\multirow{7}{*}{XA} & Distance & 0.0524 & 0.2122 & 0.2233 & 0.4271 & 0.1369 & 0.0584 & 0.3018 & 0.0085 & 0.0386 & 0.1450 & \underline{0.0044} & \textbf{0.0040} \\ 
    & Radius & 0.0708 & 0.1422 & 0.1612 & 0.4199 & 0.0655 & 0.0268 & 0.1795 & 0.0011 & 0.0030 & 0.0588 & \textbf{0.0002} & \underline{0.0002} \\ 
    & LocFreq & 0.263 & 0.104 & 0.264 & 0.403 & 0.126 & 0.099 & 0.290 & 0.097 & 0.180 & 0.207 & \underline{0.042} & \textbf{0.040} \\ 
    & Hausdorff & 2.300 & 2.406 & 2.627 & 2.852 & 2.319 & 1.597 & 3.161 & 0.349 & 1.006 & 2.178 & \underline{0.188} & \textbf{0.187} \\ 
    & DTW & 34.02 & 36.35 & 38.04 & 56.34 & 26.20 & 17.66 & 30.69 & 5.28 & 12.09 & 23.52 & \textbf{2.32} & \underline{2.34} \\ 
    & EDT & 24.21 & 30.28 & 30.36 & 34.11 & 17.67 & 13.42 & 17.95 & 7.10 & 14.88 & 15.85 & \textbf{4.29} & \underline{4.23} \\ 
    & EDR & 0.818 & 0.888 & 0.893 & 0.711 & 0.808 & 0.595 & 0.871 & 0.243 & 0.668 & 0.680 & \underline{0.142} & \textbf{0.135} \\ 
\midrule
\multirow{7}{*}{CD} & Distance & 0.0646 & 0.2083 & 0.2069 & 0.3596 & 0.1420 & 0.0405 & 0.2560 & 0.0136 & 0.0440 & 0.1380 & \underline{0.0051} & \textbf{0.0049} \\ 
    & Radius & 0.0958 & 0.1127 & 0.0980 & 0.1259 & 0.0619 & 0.0221 & 0.1598 & 0.0017 & 0.0053 & 0.0162 & \textbf{0.0002} & \underline{0.0002} \\ 
    & LocFreq & 0.280 & 0.110 & 0.267 & 0.210 & 0.103 & 0.051 & 0.374 & 0.069 & 0.159 & 0.098 & \underline{0.027} & \textbf{0.026} \\ 
    & Hausdorff & 1.434 & 1.981 & 1.980 & 2.104 & 2.433 & 1.273 & 3.126 & 0.220 & 1.033 & 1.530 & \textbf{0.117} & \underline{0.125} \\ 
    & DTW & 18.87 & 24.82 & 24.32 & 28.75 & 28.65 & 13.94 & 35.44 & 2.54 & 13.52 & 15.62 & \textbf{1.19} & \underline{1.34} \\ 
    & EDT & 19.42 & 25.64 & 25.83 & 20.16 & 18.27 & 14.02 & 18.42 & 6.69 & 17.48 & 15.01 & \textbf{3.59} & \underline{3.63} \\ 
    & EDR & 0.778 & 0.865 & 0.869 & 0.720 & 0.801 & 0.620 & 0.900 & 0.213 & 0.679 & 0.657 & \textbf{0.109} & \underline{0.117} \\ 
\bottomrule
% \end{tabularx}
\end{tabular}
\caption{New City Trajectory Generation Results 
% (GTG$^1$ refers to the GTG model trained on XA for BJ, BJ for CD, and CD for XA. GTG$^2$ refers to the model trained on BJ for XA, XA for CD and CD for BJ)
}
\label{tab:main_table}
\begin{tablenotes}
\footnotesize
\item [1] GTG$^1$ refers to the GTG model trained on XA for BJ, BJ for CD, and CD for XA. GTG$^2$ refers to the model trained on BJ for XA, XA for CD and CD for BJ.
\end{tablenotes}
\end{table*}

\subsection{Experimental Settings}
Experiments are conducted on three real trajectory datasets. The experiments consists of four parts: New City Trajectory Generation, Downstream Task Support, Target City Fine-tune and Ablation Study.

\subsubsection{Datasets and Preprocessing}
Three real-world trajectory datasets are used to evaluate the performance of our proposed method. These datasets were collected in the three cities, namely Beijing(BJ), Xi'an(XA) and Chengdu(CD).

Road network of the three cities are collected from the OpenStreetMap ~\cite{OpenStreetMap}, and road segment trajectories are obtained by performing map-matching algorithm ~\cite{fmm}.

\subsubsection{Comparative Baselines} 
Baseline models can be categorized into two types, knowledge-driven and data-driven.
\begin{itemize}
    \item Knowledge-Driven Methods:
    The knowledge-driven methods are manually proposed by researchers based on the analysis of trajectory data. Subsequently, they integrate proposed rules with a random walk algorithm to generate trajectory data. This type of baseline includes Random Walk~\cite{node2vec}(RW), Density-EPR~\cite{epr_1}(DE) and Spatial-EPR~\cite{epr_2}(SE).

    \item Data-Driven Methods: TrajGen~\cite{trajgen}(TG), SeqGAN~\cite{SeqGAN}(SG), SVAE~\cite{SVAE}(SV), MoveSim~\cite{MoveSim}(MS), TS-TrajGen~\cite{ts_trajgen}(TT), DiffTraj ~\cite{difftraj}(DT) and VOLUNTEER ~\cite{volunteer}(VO).
\end{itemize}

\subsubsection{Evaluation Metrics}
Evaluation metrics are divided into two categories, macroscopic and microscopic.
\begin{itemize}
    \item Macro metrics: we use the Jensen-Shannon divergence(JSD) to evaluate the similarity between the generated trajectory dataset and the real dataset across three statistical features: travel distance(Distance), radius of gyration(Radius), and road segment visit frequency(LocFreq). 
    \item Micro metrics: we calculate the sequence distance between the each generated trajectory and its corresponding real trajectory to evaluate similarity. We use four types of sequence distance: Hausdorff, DTW, EDT and EDR.
\end{itemize}

\subsection{New City Trajectory Generation Experiment}
\begin{figure}[t]
    \centering
    \subfloat[Real]{\includegraphics[width=0.15\textwidth]{figure/loc_freq/real_xianshi_freq.pdf}}
    \subfloat[GTG]{\includegraphics[width=0.15\textwidth]{figure/loc_freq/our_xianshi_freq.pdf}}  
    \subfloat[SV]{\includegraphics[width=0.15\textwidth]{figure/loc_freq/svae_xianshi_freq.pdf}}


    \subfloat[DE]{\includegraphics[width=0.15\textwidth]{figure/loc_freq/depr_xianshi_freq.pdf}}
    \subfloat[DT]{\includegraphics[width=0.15\textwidth]{figure/loc_freq/difftraj_xianshi_freq.pdf}}
    \subfloat[VO]{\includegraphics[width=0.15\textwidth]{figure/loc_freq/volunteer_xianshi_freq.pdf}}
    
    
    \caption{The visualization of road segment visit frequency on the XA dataset, brighter color means higher frequency.}
    \label{fig:loc_freq_visualize}
\end{figure}
The overall performance result is shown in Table~\ref{tab:main_table}. In our experiments across each dataset, the best results are highlighted in bold, while the second-best results are underlined. 

The proposed method demonstrates superior performance compared to all baseline models on the three real-world trajectory datasets, evaluated from both macro and micro perspectives. Significant improvements are observed across all metrics with the proposed approach. Unlike other deep learning baseline methods that require training on the target city’s data to produce accurate trajectories, \name can operate effectively without training in target city. This demonstrates the model’s generalization capability.

Additionally, all evaluation metrics exhibit smaller values, suggesting that the generated trajectory data closely resembles the real trajectory data. Figure~\ref{fig:loc_freq_visualize} shows the generated datasets and real datasets for some baselines. \name achieves the highest similarity to the real dataset.

\subsection{Downstream Task Support}
\begin{table}[t]
  \centering
  \fontsize{7}{8}\selectfont
    \begin{tabularx}{\linewidth}{C|C|CCC|CCC|CCC}
      \toprule
      & \multicolumn{1}{c|}{\multirow{2}[4]{*}{Data}}  & \multicolumn{3}{c|}{BJ} & \multicolumn{3}{c|}{XA} & \multicolumn{3}{c}{CD} \\
       \cmidrule(lr){3-5} \cmidrule(lr){6-8} \cmidrule(lr){9-11}
      & & ACC & NDCG & MRR & ACC & NDCG & MRR & ACC & NDCG & MRR \\
      \midrule
    \multirow{12}{*}{\rotatebox{90}{DeepMove}} & Real & 0.81 & 0.88 & 0.86 & 0.88 & 0.94 & 0.93 & 0.89 & 0.95 & 0.93\\ 
    \cmidrule{2-11}
        & RW & 0.60 & 0.75 & 0.71 & 0.62 & 0.83 & 0.78 & 0.62 & 0.85 & 0.80\\ 
        & DE & 0.01 & 0.04 & 0.03 & 0.01 & 0.11 & 0.08 & 0.02 & 0.11 & 0.08\\ 
        & SE & 0.01 & 0.02 & 0.02 & 0.01 & 0.03 & 0.03 & 0.01 & 0.05 & 0.03\\ 
        & TG & 0.56 & 0.61 & 0.60 & 0.46 & 0.47 & 0.46 & 0.69 & 0.74 & 0.73\\ 
        & SG & 0.67 & 0.73 & 0.71 & 0.64 & 0.70 & 0.68 & 0.82 & 0.89 & 0.87\\ 
        & SV & 0.64 & 0.68 & 0.67 & 0.78 & 0.81 & 0.80 & 0.82 & 0.88 & 0.87\\ 
        & MS & 0.01 & 0.02 & 0.02 & 0.11 & 0.13 & 0.13 & 0.11 & 0.13 & 0.18\\ 
        & TT & 0.65 & 0.73 & 0.71 & 0.71 & 0.78 & 0.76 & 0.75 & 0.83 & 0.81\\ 
        & DT & 0.14 & 0.20 & 0.18 & 0.39 & 0.52 & 0.49 & 0.41 & 0.51 & 0.49\\ 
        & VO & 0.22 & 0.31 & 0.29 & 0.42 & 0.49 & 0.47 & 0.60 & 0.69 & 0.67\\ 
        \cmidrule{2-11}
        & \name$^1$ & \underline{0.72} & \underline{0.80} & \underline{0.78} & \textbf{0.82} & \underline{0.87} & \textbf{0.85} & \textbf{0.84} & \textbf{0.90} & \textbf{0.89}\\ 
        & \name$^2$ & \textbf{0.73} & \textbf{0.80} & \textbf{0.79} & \underline{0.80} & \textbf{0.85} & 0.84 & \underline{0.83} & \underline{0.89} & \underline{0.88}\\ 

      \midrule
      \multirow{12}{*}{\rotatebox{90}{LSTPM}} & Real & 0.85 & 0.93 & 0.91 & 0.90 & 0.96 & 0.95 & 0.89 & 0.96 & 0.94\\ 
        \cmidrule{2-11}
        & RW & 0.68 & 0.86 & 0.82 & 0.64 & 0.85 & 0.80 & 0.61 & 0.84 & 0.79\\ 
        & DE & 0.01 & 0.05 & 0.04 & 0.01 & 0.10 & 0.08 & 0.00 & 0.11 & 0.08\\ 
        & SE & 0.00 & 0.03 & 0.02 & 0.00 & 0.03 & 0.02 & 0.00 & 0.05 & 0.04\\ 
        & TG & 0.66 & 0.70 & 0.69 & 0.62 & 0.66 & 0.65 & 0.78 & 0.84 & 0.83\\ 
        & SG & \underline{0.80} & 0.87 & 0.85 & 0.75 & 0.82 & 0.81 & 0.85 & 0.93 & 0.91\\ 
        & SV & 0.79 & 0.86 & 0.84 & 0.83 & 0.88 & 0.87 & \underline{0.87} & \underline{0.93} & \underline{0.92}\\ 
        & MS & 0.04 & 0.05 & 0.05 & 0.13 & 0.16 & 0.15 & 0.15 & 0.17 & 0.17\\ 
        & TT & 0.74 & 0.85 & 0.83 & 0.77  & 0.85  & 0.84 & 0.80 & 0.89 & 0.87\\ 
        & DT & 0.17 & 0.26 & 0.23 & 0.43  & 0.56 & 0.53 & 0.45 & 0.58 & 0.55\\ 
        & VO & 0.30 & 0.38 & 0.36  & 0.49 & 0.56  & 0.54 & 0.64 & 0.73 & 0.71\\ 
        \cmidrule{2-11}
        & \name$^1$ & \textbf{0.80} & \textbf{0.88} & \textbf{0.87} & \textbf{0.86} & \textbf{0.91} & \textbf{0.90} & \textbf{0.87} & \textbf{0.94} & \textbf{0.92}\\ 
        & \name$^2$ & 0.78 & \underline{0.87} & \underline{0.60} & \underline{0.85} & \underline{0.90} & \underline{0.89} & 0.87 & 0.93 & 0.92\\ 
      \bottomrule
    \end{tabularx}%
  \caption{Downstream Task Support Experiment Result}
  \label{tab:downstream}%
\end{table}%

\begin{table}[t]
    \centering
    % \small
    \fontsize{7}{8}\selectfont
    \setlength{\tabcolsep}{3pt}
    % \resizebox{0.48\textwidth}{!}{
    \begin{tabular}{c|c|ccc|cccc}
      \toprule
       City & \makecell{ \#Traj \\ ($10^3$)} & \makecell{ Distance \\ ($10^{-3}$)} & \makecell{ Radius \\ ($10^{-3}$)} &  LocFreq & Hausdorff &  DTW  &  EDT &  EDR \\
      \midrule
      \multirow{6}{*}{\rotatebox{90}{BJ $\to$ XA}} & 0.0 & 4.039 & 0.228 & 0.040 & 0.187 & 2.34 & 4.23 & 0.135 \\ 
        & 0.1 & 4.679 & 0.825 & 0.040 & 0.194 & 2.52 & 4.36 & 0.143 \\ 
        & 0.4 & 4.875 & 0.306 & 0.044 & 0.188 & 2.30 & 4.38 & 0.147 \\ 
        & 1.6 & 4.233 & 0.334 & 0.036 & 0.184 & 2.21 & 4.17 & 0.139 \\ 
        & 6.4 & 3.976 & 0.139 & 0.029 & 0.174 & 2.07 & 4.00 & 0.129 \\ 
        & 12.8 & 4.034 & 0.104 & 0.027 & 0.170 & 1.95 & 3.96 & 0.125 \\ 
      \midrule
      \multirow{6}{*}{\rotatebox{90}{CD $\to$ XA}} & 0.0 & 4.375 & 0.206 & 0.042 & 0.188 & 2.32 & 4.29 & 0.142 \\ 
        & 0.1 & 4.468 & 0.345 & 0.050 & 0.192 & 2.45 & 4.67 & 0.148 \\ 
        & 0.4 & 5.951 & 0.464 & 0.067 & 0.207 & 2.72 & 5.05 & 0.159 \\ 
        & 1.6 & 4.285 & 0.175 & 0.043 & 0.181 & 2.13 & 4.38 & 0.139 \\ 
        & 6.4 & 4.103 & 0.219 & 0.033 & 0.171 & 1.95 & 4.09 & 0.130 \\ 
        & 12.8 & 4.128 & 0.253 & 0.029 & 0.170 & 1.93 & 4.01 & 0.128 \\ 
      \bottomrule
    \end{tabular}%
    % }
    \caption{Target City Fine-tune Experiment Results in XA}
    \label{tab:finetune}%
\end{table}%
\begin{table}[t]
    \centering
    \fontsize{7}{8}\selectfont
    \setlength{\tabcolsep}{2.5pt}
    \begin{tabular}{c|c|ccc|cccc}
      \toprule
        City & \makecell{Method} & \makecell{Distance \\ ($10^{-3}$)} & \makecell{Radius \\ ($10^{-3}$)} & LocFreq & Hausdorff & DTW  & EDT & EDR \\
      \midrule
      \multirow{4}{*}{\rotatebox{90}{BJ $\to$ XA}} & w/o Cost & 19.171 & 5.066 & 0.119 & 0.264 & 3.78 & 8.51 & 0.260 \\ 
        & w/o Pref & 4.356 & 0.293 & 0.047 & 0.198 & 2.54 & 4.61 & 0.146 \\ 
        & w/o SS & 3.685 & 0.673 & 0.041 & 0.199 & 2.57 & 4.49 & 0.144 \\ 
        & \name & 4.039 & 0.228 & 0.040 & 0.187 & 2.34 & 4.23 & 0.135 \\ 
      \midrule
      \multirow{4}{*}{\rotatebox{90}{CD $\to$ XA}} & w/o Cost & 17.745 & 3.763 & 0.118 & 0.274 & 3.52 & 6.98 & 0.227 \\ 
        & w/o Pref & 4.641 & 1.052 & 0.062 & 0.219 & 3.00 & 5.03 & 0.164 \\ 
        & w/o SS & 5.261 & 2.817 & 0.059 & 0.228 & 3.15 & 4.95 & 0.163 \\ 
        & \name & 4.375 & 0.206 & 0.042 & 0.188 & 2.32 & 4.29 & 0.142 \\  
      \bottomrule
    \end{tabular}%
    \caption{Ablation Study Results in XA}
    \label{tab:ablation}%    
\end{table}%
Trajectory data is frequently used in many downstream tasks, such as next-hop prediction ~\cite{DeepMove, LSTPM}, trajectory classification~\cite{traj_clf_wang2018cd, traj_chen2019real}, and trajectory recovery~\cite{traj_recover_wang2019deep}.
The downstream task experiment serves as a supplementary verification of the model’s generalization ability and underscores the practical significance of the trajectory generation task. In this experiment, the trajectory generation model is employed to produce pre-training data for the downstream task, thereby enhancing the performance.

Specifically, the trajectory next-location prediction task is selected as the downstream application. This task, which aims to predict the next location in a trajectory given several observed locations, is widely applicable in POI recommendation systems. The models DeepMove~\cite{DeepMove} and LSTPM~\cite{LSTPM}, implemented via LibCity~\cite{libcity}, are utilized for this purpose. These downstream models are trained using the trajectory data generated by the proposed model, and their performance is subsequently tested on real trajectory data.

The results, as presented in Table~\ref{tab:downstream}, are evaluated using three metrics: Accuracy (ACC), Normalized Discounted Cumulative Gain at 3 (NDCG@3), and Mean Reciprocal Rank at 3 (MRR@3). The performance of the data generated by \name in training downstream tasks is found to be second only to that of real data. The baseline model demonstrates inferior performance, indicating that the trajectory data generated by our approach is more effective in supporting downstream tasks.

\subsection{Target City Fine-tune}

Considering that the gradual collection of trajectory data is a more realistic application scenario, it would be helpful if the trajectory generation capability of the model could further adjust in the target city. We fine-tune the model using the trajectory of the target city to test its improved generation ability. Fine-tuning phase training include travel cost prediction and preference learning. The experimental results of fine-tuning in XA are shown in the Table~\ref{tab:finetune}.  The results in other cities can be found in our code repository.

From Table~\ref{tab:finetune}, we can see that using target city data for fine-tuning improves the model's performance. Before applying the model to a new city, collecting a small amount of trajectory data for fine-tuning can achieve good generation results without incurring excessive costs.

\subsection{Ablation Study}

To validate the effectiveness of submodules, we conduct the following ablation studies.

(a) w/o Cost: we removed the cost prediction module, which means that instead of using combined costs shown in formula ~\ref{equ:combined_cost}, we only use hidden costs as road weights to generate trajectories.

(b) w/o Pref: we removed the preference learning module, meaning that we now only use supervise learning to predict observable costs and use their sum as weights for trajectory generation. 

(c) w/o SS: we removed the \textit{Space Syntax} feature extraction module to test the impact of \textit{Space Syntax} features., which means that only the basic features of road segments are input into the model.

The ablation study results in target city XA are shown in Table~\ref{tab:ablation}. 
Upon the removal of the aforementioned submodules, a notable decline in the model's performance was observed, with the cost prediction module having the most pronounced impact. Ablation experiments that excluded the cost prediction and preference learning modules demonstrated that the integration of travel cost components more accurately captures the invariant travel patterns of humans. Additionally, experiments that removed the \textit{Space Syntax} feature extraction module revealed that \textit{Space Syntax} significantly contributes to the cross-city trajectory generation.


