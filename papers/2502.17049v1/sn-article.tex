%Version 3 December 2023
% See section 11 of the User Manual for version history
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%\documentclass[referee,sn-basic]{sn-jnl}% referee option is meant for double line spacing

%%=======================================================%%
%% to print line numbers in the margin use lineno option %%
%%=======================================================%%

%%\documentclass[lineno,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%======================================================%%
%% to compile with pdflatex/xelatex use pdflatex option %%
%%======================================================%%

%%\documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style


%%Note: the following reference styles support Namedate and Numbered referencing. By default the style follows the most common style. To switch between the options you can add or remove Numbered in the optional parenthesis. 
%%The option is available for: sn-basic.bst, sn-vancouver.bst, sn-chicago.bst%  
%%\documentclass[pdflatex,sn-nature]{sn-jnl}% Style for submissions to Nature Portfolio journals
%%\documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style
\documentclass[pdflatex,sn-mathphys-num]{sn-jnl}% Math and Physical Sciences Numbered Reference Style 
%%\documentclass[pdflatex,sn-mathphys-ay]{sn-jnl}% Math and Physical Sciences Author Year Reference Style
%%\documentclass[pdflatex,sn-aps]{sn-jnl}% American Physical Society (APS) Reference Style
%%\documentclass[pdflatex,sn-vancouver,Numbered]{sn-jnl}% Vancouver Reference Style
%%\documentclass[pdflatex,sn-apa]{sn-jnl}% APA Reference Style 
%%\documentclass[pdflatex,sn-chicago]{sn-jnl}% Chicago-based Humanities Reference Style

%%%% Standard Packages
%%<additional latex packages if required can be included here>
% \DeclareUnicodeCharacter
\usepackage{graphicx}%
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%
\usepackage{adjustbox}
\usepackage{enumitem}
\usepackage{amsfonts}
\usepackage[utf8]{inputenc}
% \usepackage[utf8]{inputenc}
% \usepackage[utf8]{inputenc}
%%%%

%%%%%=============================================================================%%%%
%%%%  Remarks: This template is provided to aid authors with the preparation
%%%%  of original research articles intended for submission to journals published 
%%%%  by Springer Nature. The guidance has been prepared in partnership with 
%%%%  production teams to conform to Springer Nature technical requirements. 
%%%%  Editorial and presentation requirements differ among journal portfolios and 
%%%%  research disciplines. You may find sections in this template are irrelevant 
%%%%  to your work and are empowered to omit any such section if allowed by the 
%%%%  journal you intend to submit to. The submission guidelines and policies 
%%%%  of the journal take precedence. A detailed User Manual is available in the 
%%%%  template package for technical guidance.
%%%%%=============================================================================%%%%

%% as per the requirement new theorem styles can be included as shown below
\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}%  meant for continuous numbers
%%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
\newtheorem{proposition}[theorem]{Proposition}% 
%%\newtheorem{proposition}{Proposition}% to get separate numbers for theorem and proposition etc.

\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%

\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}%

\raggedbottom
%%\unnumbered% uncomment this for unnumbered level heads

\begin{document}

\title[Article Title]{TabulaTime: A Novel Multimodal Deep Learning Framework for
Advancing Acute Coronary Syndrome Prediction through Environmental and
Clinical Data Integration}

%%=============================================================%%
%% GivenName	-> \fnm{Joergen W.}
%% Particle	-> \spfx{van der} -> surname prefix
%% FamilyName	-> \sur{Ploeg}
%% Suffix	-> \sfx{IV}
%% \author*[1,2]{\fnm{Joergen W.} \spfx{van der} \sur{Ploeg} 
%%  \sfx{IV}}\email{iauthor@gmail.com}
%%=============================================================%%

\author[1]{\fnm{Xin} \sur{Zhang}}\email{x.zhang@mmu.ac.uk}

\author*[1]{\fnm{Liangxiu} \sur{Han}}\email{l.han@mmu.ac.uk}
% \equalcont{These authors contributed equally to this work.}

\author*[2]{\fnm{Stephen} \sur{White}}\email{steve.white3@newcastle.ac.uk}

\author[3]{\fnm{Saad} \sur{Hassan}}\email{saad.hassan@doctors.org.uk}
\author[4]{\fnm{Philip} \sur{A Kalra}}\email{philip.kalra@nca.nhs.uk}
\author[4]{\fnm{James} \sur{Ritchie}}\email{james.ritchie@nca.nhs.uk}

\author[5]{\fnm{Carl} \sur{Diver}}\email{C.Diver@mmu.ac.uk}

\author[6]{\fnm{Jennie} \sur{Shorley}}\email{j.shorley@mmu.ac.uk}

% \equalcont{These authors contributed equally to this work.}

\affil*[1]{Department of Computing, and Mathematics, Manchester Metropolitan
University, Manchester, M15 6BH, UK}

\affil*[2]{Faculty of Medical Sciences, Newcastle University, Newcastle upon
Tyne, NE1 3BZ, UK}

\affil[3]{Blackpool Teaching Hospitals NHS Foundation Trust, Blackpool Victoria Hospital, Whinney Heys Road Blackpool, FY3 8NR}

\affil[4]{Northern Care Alliance, NHS Foundation Trust, Salford, M6 8HD, UK}
\affil[5]{Department of Engineering, Manchester Metropolitan University,Manchester, M15 6BH, UK}
\affil[6]{Faculty of Business and Law, Manchester Metropolitan University,Manchester, M15 6BH, UK}
%%==================================%%
%% Sample for unstructured abstract %%
%%==================================%%

\abstract{

Acute Coronary Syndromes (ACS), encompassing conditions such as ST-segment elevation myocardial infarction (STEMI) and non-ST-segment elevation myocardial infarction (NSTEMI), remain a leading cause of global mortality. While traditional Cardiovascular Risk Scores (CVRS) provide valuable insights, they primarily rely on clinical data, often overlooking environmental factors like air pollution, which significantly impact cardiovascular health. Additionally, integrating complex time-series environmental data with clinical datasets poses significant challenges due to issues in alignment and fusion.

To address these gaps, we propose TabulaTime, a novel multimodal deep learning framework that integrates clinical risk factors with air pollution data to enhance ACS risk prediction. TabulaTime introduces three major innovations: (1) Multimodal feature integration to combine time-series air pollution data with clinical tabular data for improved predictive accuracy; (2) PatchRWKV, a new module for automatic extraction of complex temporal patterns, overcoming limitations of traditional feature engineering and maintaining linear computational complexity; and (3) Enhanced interpretability using attention mechanisms to reveal interactions between clinical and environmental factors.

Our experimental evaluation demonstrated that TabulaTime achieves a 20.5\% improvement in accuracy compared to the best-performing traditional machine learning model (CatBoost) and surpasses other models, including Random Forest and LightGBM, by 20.5\% to 32.2\%. The integration of air pollution data improves accuracy by 10.1\%, emphasising the importance of environmental factors. The PatchRWKV module showed advanced performance in time-series analysis, outperforming the state-of-the-art methods such as Multi-Layer Perceptrons (MLPs) based methods (LightTS and Dlinera), Convolutional Neural Networks (CNNs) based methods (TimesNet), Recurrent Neural Networks (RNNs) based methods (LSTM, GRU), and Transformers based methods (Autoformer, PatchTST) across various tasks while maintaining efficiency. Additionally, feature importance analysis identified key predictors of ACS, such as previous angina, systolic blood pressure, and pollutants like PM$_{10}$ and NO$_{2}$, highlighting the critical role of environmental-clinical interactions in ACS risk.

This framework bridges the gap between traditional clinical models and environmental health insights, supporting personalised prevention strategies and informing public health policies to mitigate the cardiovascular impact of air pollution.
}


\keywords{Acute Coronary Syndrome (ACS), Deep Learning, Multimodal Deep Learning, Time-Series Analysis, Environmental Data Integration, Clinical Risk Prediction, Air Pollution}

%%\pacs[JEL Classification]{D8, H51}

%%\pacs[MSC Classification]{35A01, 65L10, 65L12, 65L20, 65L70}

\maketitle

\section{Introduction}

Acute Coronary Syndromes (ACS), a spectrum of conditions encompassing unstable angina, ST-segment elevation myocardial infarction (STEMI), and non-ST-segment elevation myocardial infarction (NSTEMI), is the leading cause of death globally, with nearly half of these deaths due to ischaemic heart disease \cite{Reed2017Acute,Bergmark2022Acute}.  Understanding environmental factors is crucial for developing strategies to mitigate ACS risk. Cardiovascular Risk Scores (CVRS) serve as statistical tools used to estimate a person’s risk of having a cardiovascular event, such as a heart attack or stroke, usually over the next 10 years. Various risk scores have been developed, each targeting different populations, incorporating distinct risk factors, and possessing unique predictive strengths. Notable examples include the QRISK family of algorithms \cite{Hippisley2017Development,Hippisley2007Derivation,Hippisley2010Derivation}, Framingham Risk Score (FRS)\cite{Hemann2007Framingham}, Reynolds Risk Score \cite{Ridker2007Development} and European SCORE System \cite{Nashef1999European}. These tools help clinicians assess and manage patients’ cardiovascular risk and target prophylactic therapy more effectively.

However, there is a growing recognition that existing models may not fully capture the comprehensive range of risk factors contributing to ACS. For example, QRISK3 explains 59.6\% of the variation in time to diagnosis of CVD among women and 54.8\% among men, leaving over 40\% of the variation unexplained by the QRISK3 score \cite{Hippisley2017Development}. Numerous epidemiological studies have convincingly linked air pollution exposure to a heightened risk of ACS \cite{Rus2022Impact,Chen2022Hourly}. Air pollutants, particularly particulate matter (PM$_{2.5}$ and PM$_{10}$), nitrogen oxides (NO$_x$), sulphur dioxide (SO$_{2}$), and ozone (O$_3$), trigger inflammation, oxidative stress, and change in blood vessel function, contributing to cardiovascular issues. For instance,  \citeauthor{Rus2022Impact} \cite{Rus2022Impact}provides a broader look at the connection between environmental factors and ACS, highlighting the increased risk associated with PM$_{2.5}$ exposure. Additionally, in \cite{Chen2022Hourly}, the researchers presented a large-scale study analysing the link between hourly air pollutant levels and ACS in over 1 million patients, emphasising the roles of PM$_{2.5}$, NO$_{2}$, SO$_{2}$, and CO in triggering ACS. This gap necessitates novel approaches that leverage the power of environmental data to enhance risk prediction accuracy. 

Traditional medical data used for acute coronary syndrome (ACS) prediction typically include patient demographics and clinical data. These data points, structured in a tabular manner, allow for relatively simple analysis and prediction models. In contrast, the environmental data exists as a time series with more complex features, capturing continuous changes over time. Most current studies often utilise manual time series features, such as statistical features (e.g., maximum and minimum values, standard deviation) and temporal features (e.g., trends, event counts, anomalies). However, these methods do not fully leverage the extensive information embedded within time series data. Identifying and extracting the right features that represent the temporal dependencies within time-series data can be time-consuming and requires domain expertise \cite{Torres2021Deep}.

Deep learning models, such as recurrent neural networks (RNNs) \cite{Connor1994Recurrent}, multi-layer perceptrons (MLPs) \cite{Mayer1999Evolutionary}, convolutional neural networks (CNNs) \cite{Zhao2017Convolutional} and transformers \cite{Vaswani2017Attention}, can automatically learn complex temporal features from raw time series data, reducing the need for extensive manual engineering. Several studies have leveraged deep learning to analyse the relationship between air pollution exposure and health outcomes \cite{Gugnani2022Analysis,Zhou2020Deep,Ghufran2021Forecast,Subramaniam2022Artificial}. For instance, \cite{Bekkar2021Air} implemented a hybrid CNN-LSTM (Long Short-Term Memory) model to analyse hourly PM$_{2.5}$ concentrations in Beijing, China, and predict air quality levels for health risk assessment. Similarly, (Tsai, Zeng, and Chang 2018) used RNNs with LSTM to forecast PM$_{2.5}$ concentrations, while\cite{Miranda2021Application} employed radial basis function (RBF) and MLP neural networks to model the temporal dynamics of air pollution and its impact on respiratory hospital admissions.
Despite the success of advanced deep learning models in various fields, they can demonstrate limitations when processing multimodal data \cite{Jabeen2023Review} . Integrating heterogeneous data types requires sophisticated architectures capable of learning and representing the intricate relationships between different modalities. Furthermore, the alignment, synchronisation, and fusion of multimodal data necessitates advanced techniques to ensure that the combined information enhances, rather than detracts from, the model’s performance \cite{Gandhi2023Multimodal,Liang2024Foundations}.

Existing research on ACS risk prediction primarily emphasises traditional clinical datasets, often neglecting the significant influence of environmental factors. Integrating air pollution data into deep learning models offers a promising opportunity to enhance ACS risk assessment and inform preventive cardiology strategies. This research aims to address these challenges by developing and validating a novel multimodal deep learning based ACS prediction model, TabulaTime, specifically designed to improve CVD risk prediction through the integration of time-series air pollution features and clinical tabular data. Our proposed method offers several key contributions:


% \renewcommand{\labelenumi}{}
\begin{enumerate}
\item [1)]
\textbf{Multimodal feature integration and ACS prediction}: We propose a novel TabulaTime deep learning framework for multimodal feature integration and ACS prediction, combining extracted time-series features from air pollution datasets with ACS risk factors obtained from clinical tabular data. This integration enables the model to conditionally learn attention maps based on the multimodal features, thereby enhancing both predictive performance and interpretability.

\item [2)]
\textbf{Automatic time-series feature extraction}: We introduce PatchRWKV, an advanced feature extraction module designed for automatic extraction of features from time-series data. The PatchRWKV module divides data into patches. It uses the Receptance Weighted Key Value (RWKV) technique, which combines RNN capabilities with attention mechanisms. This approach efficiently processes long sequences while maintaining linear computational complexity, making it more efficient than traditional RNNs and transformers, which have quadratic complexity. By capturing both short-term and long-term patterns, PatchRWKV provides a comprehensive representation of temporal dependencies. This capability is crucial for accurately detecting significant associations between pollution exposure patterns and ACS risk, which are often missed by traditional manual feature extraction methods.  

\item [3)]
\textbf{Enhanced interpretability}: We employ attention mechanisms and feature importance analysis to uncover potential interactions between air pollution, clinical risk factors, and the onset of ACS. This approach ensures that the model’s predictions are both accurate and interpretable, providing deeper insights into how environmental and clinical factors contribute to ACS risk. 

\end{enumerate}

This paper is structured as follows: Section 2 reviews related work, Section 3 details the proposed TabulaTime framework, and Sections 4 and 5 present experimental evaluations and discussions. The conclusion summarises findings and implications for future research.


\section{Related Work}

\subsection{Traditional ACS Prediction Methods}

Acute Coronary Syndrome (ACS) risk prediction methods are essential tools for estimating an individual's likelihood of experiencing cardiovascular events. Traditional methods for predicting ACS risk such as Framingham Risk Score (FRS)\cite{Hemann2007Framingham}, QRISK\cite{Hippisley2017Development}, Reynolds Risk Score \cite{Ridker2007Development} and European SCORE System \cite{Nashef1999European} utilise a combination of demographic, clinical, lifestyle and medical history data to provide an overall risk assessment, but frequently cannot be utilised once a diagnosis of underlying cardiovascular disease has been made. The data used can be categorised as follows: 1) Demographic Information: Age, gender, and family history of cardiovascular diseases\cite{Steen2022Event}. 2) Clinical History: Previous incidences of myocardial infarction, angina, hypertension, diabetes, and hypercholesterolemia. 3) Laboratory and and Clinical Tests: Blood pressure readings, cholesterol levels, and creatinine levels. 4) Electrocardiogram (ECG) Readings: Used to diagnose the type and severity of myocardial infarctions (e.g., Discrimination between STEMI and NSTEMI) \cite{Bhatt2022Diagnosis}.

These traditional methods systematically assess cardiovascular event risk. The FRS, Reynolds Risk Score, National Early Warning Score (NEWS) \cite{Smith2013ability}  and Global Registry of Acute Coronary Events (GRACE) (‘Rationale and Design of the GRACE (Global Registry of Acute Coronary Events) Project: A Multinational Registry of Patients Hospitalized with Acute Coronary Syndromes’ 2001) primarily relied on point-based systems incorporating traditional clinical and lifestyle factors. Each risk factor was assigned a specific number of points based on predefined scales. The QRISK algorithm employed a comprehensive multivariate approach using a wide array of data points to reflect a diverse population. The European SCORE system utilised regional risk charts to account for geographic variability in cardiovascular disease prevalence. 

\subsection{Machine Learning in ACS Prediction}

While these traditional models have been instrumental in guiding clinical practice, they have notable limitations in adaptability, data integration, and predictive accuracy.  Machine learning/deep learning methods offer significant advantages in these areas, providing more dynamic, accurate, and comprehensive risk assessments by leveraging advanced data analytics and continuous learning capabilities \cite{Ke2022Machine}.  Wu et al. \cite{Wu2021Machine} utilised machine learning to predict in-hospital cardiac arrest in ACS patients, finding that the XGBoost model outperformed traditional risk scores such as GRACE and NEWS , achieving high accuracy and AUC. A total of 45 risk features were selected in this work from the electronic health record including age, gender, history of smoking and laboratory features, Killip classification, vital signs, mental status, etc.  Similarly, Hadanny et al. \cite{Hadanny2022Machine} used Random Survival Forest (RSF) and deep neural network (DeepSurv) models to predict 1-year mortality in ACS patients, highlighting the improved performance of RSF over traditional methods. Acute Coronary Syndrome Israeli Survey (ACSIS) and the Myocardial Ischemia National Audit Project (MINAP) data were used in this work. 69 risk factors including demographics, prior medical history, prior medication, clinical presentation, basic laboratory data with admission were selected and evaluated.

D’Ascenzo et al. \cite{D2021Machine} developed the PRAISE risk scores, a machine learning tool validated with external cohorts, which showed high accuracy in predicting post-discharge outcomes for ACS patients. The 25 risk factors included 16 clinical variables, 5 therapeutic variables, and 2 angiographic variables. Research by Emakhu et al. \cite{Emakhu2022Acute} compared various machine learning techniques for predicting ACS outcomes based on 58 variables, including demographic and clinical factors ( e.g. brain natriuretic peptide (BNP), creatinine, glucose, heart rate, red cell distribution width, systolic blood pressure, and troponin), with models like XGBoost and RSF significantly improving prediction accuracy over traditional methods. Ke et al. \cite{Ke2022Machine} focused on early ACS onset prediction using ensemble methods such as gradient boosting, demonstrating the benefits of integrating machine learning into clinical practice for enhanced early detection and management of ACS using demographic characteristics, comorbidities, thrombolytic therapy, laboratory test data, and physical examination data. The study in \cite{Lee2021Machine} concluded that the ML-based approach improved the prediction of mortality, particularly in patients with non-ST-segment elevation myocardial infarction (NSTEMI) based on demographic characteristics, medical history, symptom, initial presentation, laboratory findings, clinical manifestation, echocardiographic finding, coronary angiographic finding, and medication at discharge. 

In recent years, deep learning techniques have shown significant advancements in various healthcare applications, including cardiovascular disease prediction. In \cite{duan2019utilizing}, a deep learning-based approach is introduced to analyse a massive volume of heterogeneous electronic health records in order to predict MACEs following ACS. In \cite{liu2023deep}and \cite{liu2021deep}, the authors introduce deep learning model for classifying ACS abnormalities using electrocardiogram (ECG) data. However, due to the structured and tabular nature of clinical data, the application of deep learning models in ACS prediction remains relatively limited compared to traditional machine learning approaches.




\subsection{Environmental Factors and ACS}


The effects of environmental factors on ACS have also been increasingly studied. Ku\'{z}ma et al. \cite{Kuzma2021Impact} investigated the short-term impact of air pollution on ACS incidence in industrial versus non-industrial areas, finding significant associations between air pollution and ACS admissions. Chen et al. \cite{Chen2022Hourly} examined hourly air pollutant concentrations and their association with ACS onset, employing a case-crossover design that revealed a strong link between short-term exposure to pollutants and increased ACS risk. Gestro et al. \cite{Gestro2020Short} developed models to analyse the delayed effects of air pollutants on emergency department admissions for ACS, underscoring the need for continuous air quality monitoring.

However, environmental time series data have more complex temporal properties than clinic data.  Current approaches often rely on manually selected features from time series datasets, including basic statistical measures such as mean, variance, and autocorrelation. These methods may not capture all relevant information, particularly complex, non-linear patterns. Recently, deep learning has emerged as a powerful tool for time series analysis, especially in examining the impact of air pollution on health outcomes. Various deep learning algorithms have been employed to analyse time series environmental data, such as Recurrent Neural Networks (RNNs) \cite{Husken2003Recurrent,Hewamalage2021Recurrent}, Multi-Layer Perceptrons (MLPs)\cite{Mayer1999Evolutionary}, Convolutional Neural Networks (CNNs)\cite{Zhao2017Convolutional}, and Transformers \cite{Zeng2023Are}.


\textbf{RNNs} are specifically designed for sequence data, making them a natural fit for time series analysis. Their internal state allows them to retain information from previous inputs, which is crucial for understanding temporal dependencies. For instance, Villegas et al. \cite{Villegas2023Predicting} proposed a predictive model for COVID-19 mortality risk using RNNs with attention mechanisms to enhance interpretability. Results indicate that the RNN model outperforms traditional baselines like Support Vector Classifier and Random Forest in sensitivity and overall stability.  

\textbf{MLPs}, though simpler than other models, can effectively model temporal dependencies when applied along the temporal dimension. MLP methods encode these temporal dependencies into the fixed parameters of MLP layers, adopting the MLP framework along the temporal axis. This approach allows MLPs to model sequential patterns in time-series data, providing a straightforward yet powerful means to analyse complex temporal relationships. Suttaket and Kok \cite{Suttaket2024Interpretable} introduced Rational Multi-Layer Perceptrons (RMLP) as a novel interpretable predictive model for healthcare, addressing the limitations of deep learning’s black-box nature. The model combined the strengths of weighted finite state automata and multi-layer perceptrons to process sequential data from electronic health records (EHRs). The study demonstrated that RMLP achieved strong predictive accuracy and enhanced interpretability across six clinical tasks. 

\textbf{CNNs} are traditionally used for image processing but have been adapted for time series analysis\cite{Muller2024IMU}. The key advantage of CNNs is their ability to capture local patterns and hierarchical features through convolutional operations.

\textbf{Transformers}, introduced by Vaswani et al. \cite{Vaswani2017Attention}, have revolutionised sequence modelling by relying on self-attention mechanisms rather than recurrent structures. This allows for parallel processing of data and better handling of long-range dependencies. Ni et al. \cite{Ni2024Time} compared traditional time series models such as ARIMA and Prophet with advanced transformers based models for predicting heart rate dynamics. The study demonstrated that deep learning approaches, particularly transformer-based models like PatchTST \cite{Nie2023Time}, significantly outperformed traditional methods in capturing complex temporal dependencies and non-linear relationships. 

Despite their success, each of these models has specific strengths and limitations that make them suitable for different aspects of time series analysis. RNNs and LSTMs are excellent for handling temporal dependencies but are computationally intensive and complex. MLPs are simpler but less effective for complex time series compared to RNNs or LSTMs and less flexible for variable-length sequences due to requiring fixed input sizes. CNNs excel at capturing local patterns but often miss long-term dependencies. Transformers are powerful but have quadratic complexity relative to sequence length, making them computationally expensive for very long sequences.

Moreover, to the best of our knowledge, there are a few studies \cite{Sayed2024Novel} combining time series air pollution analysis and clinical data using deep learning algorithms for ACS prediction. Integrating heterogeneous data types remains challenging.  Multimodal deep learning frameworks are required to effectively combine clinical and environmental data, addressing issues related to alignment, synchronization, and fusion of multimodal information.  

Our proposed TabulaTime model represents a significant advancement in this field by leveraging deep learning to integrate time-series air pollution data with traditional clinical data. It efficiently processes long sequences while maintaining linear computational complexity, making it more efficient than traditional RNNs and transformers, which have quadratic complexity. This approach addresses the limitations of previous models, providing a more comprehensive and accurate assessment of ACS risk. 


\section{The Proposed Method}

\subsection{Overview of the Framework}

In this study, we propose a multimodal deep learning framework for modelling the effect of air pollution on ACS presentation by integrating time-series data with tabular data, named TabulaTime. {Figure~\ref{fig:1}} illustrates the flowchart of the TabulaTime framework, which comprises three main components: 

\begin{enumerate}
\item[1)]

Input embedding. This component converts raw input data, such as words, images, or time series data, into dense, continuous vectors that a deep learning model can process. This transformation enables the model to interpret and utilise the data more effectively. For instance, clinical tabular data are embedded into vectors, allowing the model to learn simultaneously from both clinical and other data types. This enhances the model’s ability to capture complex patterns and relationships, thereby improving its overall predictive performance.   
\item[2)]

Patched RWKV module (PatchRWKV) for automatic time-series sequential data feature extraction, which includes patching and RWKV (Receptance Weighted Key Value). The patching process divides time-series data into fixed-size segments, enabling the model to focus on short-term patterns within each segment. The RWKV module serves as the backbone for feature extraction, combining the strengths of recurrent neural networks (RNNs) and attention mechanisms to efficiently process time series sequences. PatchRWKV excels at identifying both short-term spikes and long-term trends in the data, providing a comprehensive representation of temporal dependencies. This approach efficiently processes long sequences while maintaining linear computational complexity, making it more efficient than traditional RNNs and transformers, which have quadratic complexity. By capturing both short-term and long-term patterns, PatchRWKV offers a thorough representation of temporal dependencies, crucial for accurately detecting significant associations between pollution exposure patterns and ACS risk, often missed by traditional manual feature extraction methods.

\item[3)]

The multimodal feature integration and ACS prediction. In this part, we leverage attention mechanisms to integrate embedded tabular data features with extracted time-series features from the Patched RWKV module. By generating an attention map, the model assigns weights to different features, aligning data from various types and providing explanations for the model’s decisions. This integration enhances the model's predictive accuracy and interpretability, ensuring that the combined information from different data sources contributes effectively to the ACS risk prediction. 

\end{enumerate}

\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{./img/img1.png}
\caption{The flowchart of the proposed TabulaTime framework.}
\label{fig:1}
\end{figure}



\subsection{Input Embedding}

In this work, the input embedding consists of two parts: embedding clinical tabular data and embedding air pollution time series data.

Embedding clinical tabular data involves several crucial steps as follows: First, handling missing values is essential; we fill missing data with the mean value of the respective attribute to minimise the impact on model prediction. Next, we encode categorical variables using One-Hot encoding to convert them into binary vectors, allowing the model to process categorical information effectively. Following this, data normalisation and standardisation are applied, transforming features to have a mean of 0 and a standard deviation of 1, which improves model performance by ensuring consistency in data scale.  Finally, all features are concatenated into a single feature vector, serving as the input for model integration, enabling the deep learning framework to utilise the comprehensive dataset efficiently.  

Embedding air pollution time series data includes patching and patch embedding, which will be described in detail in a later section.

\subsection{PatchRWKV for Time-Series Feature Extraction}

The PatchRWKV module is a core component of the TabulaTime model, designed to handle and extract features from multivariate time-series data, such as air pollution data. This module allows the model to manage both short-term spikes and long-term trends, providing a comprehensive representation of temporal dependencies crucial for accurate analysis. It integrates Recurrent Neural Networks (RNNs) and attention mechanisms to efficiently process long sequence data while maintaining linear computational complexity. The PatchRWKV consists of three key components: Patching, Patch Embedding, and the RWKV encoder. The rationale behind the model design is as follows:

\begin{enumerate}
\item [1)]
Patching: Patching segments time-series data into fixed-size patches, allowing the model to focus on local temporal patterns within each patch and effectively capture short-term dependencies and variations. This enhances locality and semantic understanding, helping the model efficiently learn from short-term dependencies.

\item [2)]
Patch Embedding: The patch embedding component converts the patched data into a format that the model can process. This step ensures that the data is prepared for deeper analysis by the subsequent components.

\item [3)]

RWKV Encoder: Multivariate time series data consists of multiple channels, each representing different types of measurements taken over time. To extract effective feature representations, it is crucial to understand the relationships between different time periods (Time-Mixing) and between different features (Channel-Mixing). The RWKV encoder serves as the backbone architecture of the model, incorporating Time-Mixing and Channel-Mixing to enhance the model’s ability to detect significant patterns and improve predictive performance. Time-Mixing involves using a linear combination of current and previous time steps along with a multi-head Receptance Weighted Key Value (RWKV) operator to capture temporal dependencies across different time patches. This ensures that the model effectively learns the relationships between data points over various time steps, which is crucial for understanding how past events influence future outcomes in a time series. Channel-Mixing is the process of using a vector of all the features from the time series and projecting it into the embedding space. This approach combines information across different channels using robust non-linear operations. Channel-Mixing helps the model learn the relationships between different types of data collected at the same time step, enhancing its ability to interpret multivariate time series data effectively.
\end{enumerate}

The following sections detail these components.

\subsubsection{Patching}

The patching process consists of two stages: normalisation and patching. Instance normalisation has recently been shown to mitigate the distribution shift effect between training and testing data. Therefore, we first normalise each univariate time-series pollution dataset to have a zero mean and unit standard deviation before applying patching. Each input univariate time series is then tokenised through patching, with patches being either overlapping or non-overlapping, depending on the patch length (P) and stride (S). These patches are projected into a lower-dimensional space using a learnable projection matrix, reducing the number of input tokens and computational complexity. In this study, we use hourly air pollution data and aim to capture localised features of pollution for each day. Consequently, we set the patch size to 24 and do not use overlapping patches.

\subsubsection{Patch Embedding}

In patch embedding, each patch is embedded into a higher-dimensional vector by applying a linear transformation to flatten it. Then each patch is represented as a vector, which captures the essential information of that patch that can be processed by the RWKV model.


\subsubsection{RWKV (Receptance Weighted Key Value) Encoder}



\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{./img/img2.png}
\caption{Architecture of the RWKV Encoder.}
\label{fig:2}
\end{figure}


The RWKV architecture is designed to learn feature representations of time-series data. It consists of stacked residual blocks, each containing a Time-Mixing and a Channel-Mixing sub-block ({Figure~\ref{fig:2}} and {Figure~\ref{fig:3}}). These sub-blocks use recurrent structures to incorporate past information effectively.

\paragraph{Time Mixing Module}


\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{./img/img3.png}
\caption{Architecture of the time and channel mixing.}
\label{fig:3}
\end{figure}



To achieve time mixing in RWKV, the model interpolates between the inputs of the current and previous time-steps. Given an input feature of \(x_{t}\) and previous step \(x_{t - 1}\), a linear projection of the combination of the shifted previous step and the current step is performed using the projection matrix within the block. This process involves creating a weighted blend of~\(x_{t}\)\hspace{0pt}~and~\(x_{t - 1}\)\hspace{0pt}~to capture temporal dependencies effectively.


\begin{equation}
\begin{aligned}
& R_t=W_r \cdot\left(\mu_r \odot x_t+\left(1-\mu_r\right) \odot x_{t-1}\right) \\
& K_t=W_k \cdot\left(\mu_k \odot x_t+\left(1-\mu_k\right) \odot x_{t-1}\right) \\
& V_t=W_v \cdot\left(\mu_v \odot x_t+\left(1-\mu_v\right) \odot x_{t-1}\right)
\end{aligned}
\end{equation}


Where \emph{W} means the weight signifying the positional weight decay vector, a trainable parameter within the model. \emph{\textbf{R}} is the receptance vector acts as the receiver of past information. \emph{\textbf{K}} is the Key vector performs a role analogous to K in traditional attention mechanisms. \emph{\textbf{V:}} The Value vector functions similarly to V in conventional attention processes.

Then a Multi-head WKV Operator is used to operate the attention mechanism but with a linear time and space complexity. This recurrent behaviour in RWKV is articulated through the time-dependent update of the WKV vectors. The formula of single head WKV operator is given by.

\begin{equation}
w k v_t=\operatorname{diag}(u) \cdot k_t^T \cdot v_t+\sum_{i=1}^{t-1} \operatorname{diag}(w)^{(t-1-i)} \cdot k_i^T \cdot v_i
\end{equation}

where \emph{\textbf{w}} and \emph{\textbf{u}} are two trainable parameters. The parameter \emph{u} is a bonus that rewards the model for encountering a token for the first time, specifically the current token. This ensures the model pays more attention to the current token, preventing any potential degradation of \emph{\textbf{w}}. Another important parameter is \emph{\textbf{w}}, which is a channel-wise time decay vector per head. Furthermore, we transform parameter \emph{w} within the range (0,1), ensuring that \(diag(w)\) represents a contraction matrix.

Like the transformer structure, we use the multi-head WKV to enhance the model's capacity which is formally described by the following equation:

\begin{equation}
M H_{w k v_t}=\operatorname{Concat}\left(w k v_t^1, \ldots, w k v_t^h\right)
\end{equation}

Where h is the number of heads. Finally, an output gating mechanism controls the flow of information from the recurrent unit to the next layer or the final output. This gating is implemented using the SiLU activation function and receptance. The output vector \(o_{t}\) per head is given by:

\begin{equation}
o_t=\left(\operatorname{SiL} \mathrm{U}\left(g_t\right) \odot \text { LayerNorm }\left(r_t \cdot w k v_t\right)\right) W_o
\end{equation}

Where LayerNorm operates on each of h heads separately. This gating ensures that only relevant information is passed forward, improving the model's ability to make accurate predictions by filtering out noise and focusing on significant data.

\paragraph{Channel Mixing Module}

In the channel-mixing block, channels are mixed by strong non-linear operations as follow:

\begin{equation}
\begin{gathered}
k_t^{\prime}=W_g^{\prime} \cdot\left(\mu_k^{\prime} \odot x_t+\left(1-\mu_k^{\prime}\right) \odot x_{t-1}\right) \\
r_t^{\prime}=W_r^{\prime} \cdot\left(\mu_r^{\prime} \odot x_t+\left(1-\mu_r^{\prime}\right) \odot x_{t-1}\right) \\
v_t^{\prime}=\operatorname{ReLU}^2\left(k_t^{\prime}\right) \cdot W_v^{\prime} \\
o_t^{\prime}=\operatorname{Sigmoid}\left(r_t^{\prime}\right) \odot v_t^{\prime}
\end{gathered}
\end{equation}

where we adopt the squared ReLU activation function to enhance the non-linearity.

\subsection{Multimodal Feature Integration and Prediction}

\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{./img/img4.png}
\caption{An illustrative example of using attention mechanisms for
multimodal feature integration.}
\label{fig:4}
\end{figure}


Feature integration and prediction in the TabulaTime model combine extracted features from time-series air pollution data with tabular clinical data for ACS risk prediction({Figure~\ref{fig:4}}). This model integrates tabular data embedding feature representations of time-series data into an attention module, enabling the network to learn attention maps conditionally based on the tabular data. This integration enhances the network's ability to pinpoint what, where, and when to focus on in the data, leading to improved performance in tasks involving both time series and tabular data.
Specifically, the tabular data is embedded into the same dimension as the feature representations of the time-series data and passed through shared layers. This allows the attention maps to be computed conditionally on the tabular data, facilitating a more nuanced and effective feature integration process. 


Give the input \(X \in \mathbb{R}^{C}\), the feature integration can be formulated as:

\begin{equation}
\hat{X}_c=\sigma\left(W_2 \cdot \delta\left(W_1 \cdot X_c\right)\right)_c \cdot X_c
\end{equation}

Where $W_1 \in \mathbb{R}^{\frac{c}{r} \times c}$ and $W_2 \in \mathbb{R}^{C \times \frac{c}{r}}$  are the weight matrices of the two fully connected layers. $\sigma$ denotes the ReLU activation function. $\sigma\left(W_2 \cdot \delta\left(W_1 \cdot X_c\right)\right)_c$ refers to the generated attention map. As a final step, a MLP is added at the end of the model to predict the ACS risk.

This process ensures that the model effectively integrates and leverages both the tabular and time-series data, leading to more accurate and reliable ACS risk predictions.

\section{Experimental Evaluation}

\subsection{Experimental Design}

To evaluate the efficacy of the TabulaTime model, we conduct three comprehensive experiments, each designed to assess distinct aspects of its performance:

\begin{enumerate}

\item [1)] Model Performance Analysis

This experiment evaluates the predictive accuracy of TabulaTime for Acute Coronary Syndrome (ACS) risk. We test the model using varying air pollution data durations (3, 7, 10, and 14 days) to identify the optimal time window. Subsequently, we compare its performance against traditional machine learning models, including Random Forest, LightGBM \cite{ke2017lightgbm}, and CatBoost\cite{prokhorenkova2018catboost}, under two scenarios: (a) incorporating air pollution data, and (b) excluding air pollution data. These comparisons quantify the significance of environmental factors in enhancing predictive accuracy. Additionally, the generalizability of TabulaTime are assessed across varying time periods and air conditions.

\item[2)]  PatchRWKV Module Evaluation
    

This experiment focus on the PatchRWKV module's capability in feature extraction from time-series data. Using three publicly available datasets, we benchmark its performance in both classification and forecasting tasks, highlighting its ability to efficiently capture complex temporal patterns. We select several State-of-the-art models and referenced their results, which includes most recent and extensive empirical studies on time-series. The selected models include:

\textbf{Multi-Layer Perceptrons (MLPs) -based models}: LightTS \cite{Zhang2022Less}, LightTS is a MLPs model which is straightforward and computationally efficient, suitable for real-time and large-scale applications. 

\textbf{Convolutional Neural Networks (CNNs)-based models}: TimesNet \cite{Wu2023TimesNet}, TimesNet is a CNN model which is efficient in capturing local patterns and hierarchical features in time-series data, providing a solid comparison for the feature extraction capabilities of the PatchRWKV module .

\textbf{Transformers-based models}: Autoformer\cite{Wu2022Autoformer},  PatchTST \cite{Nie2023Time}. Transformer have revolutionised sequence modelling with their self-attention mechanisms, excelling in capturing long-range dependencies. Both Autoformer and PatchTST represent state-of-the-art approaches in time-series analysis with their decomposition mechanism and patching mechanism.

\textbf{Recurrent Neural Networks (RNNs) -based models}: Gated Recurrent Unit (GRU) \cite{Cho2014Learning} and Long Short-Term Memory (LSTM) \cite{Hochreiter1997Long} are designed for sequence data and known for modelling temporal dependencies effectively. These models provide a comparison for the recurrent structures within the PatchRWKV module.

    \item[3)]  Feature Importance and Model Interpretability
    
This study aim to understand the interplay between clinical and environmental factors in ACS STEMI VS NSTEMI prediction. By analyzing feature importance scores, we identified the key predictors and their relative contributions, enhancing the model’s interpretability and offering valuable insights for targeted interventions. The feature importance is calculated using permutation feature importance\cite{Fisher2019All}. This method assesses the increase in the model’s prediction error when a feature’s values are shuffled. If shuffling a feature increases the model error, the feature is considered important, as the model relies on it for predictions. Conversely, if shuffling does not affect the model error, the feature is deemed unimportant, as the model ignores it for predictions. We first calculate feature importance as the drop in the model’s validation metric when a feature value is randomly shuffled. Then, we calculate step importance to show the significance of each time period. 
    
\end{enumerate}





\subsection{Dataset Description}

The study utilises two primary datasets to evaluate the performance of the TabulaTime model: 
1) Salford MINAP dataset which contains clinical data from the Myocardial Ischaemia National Audit Project (MINAP) collected in Salford, UK. 
2) Air Pollution Dataset which contains hourly measurements of various air pollutants collected from the Salford Eccles monitoring station in Salford, Greater Manchester, United Kingdom. 
3) Additionally, to evaluate  the performance of PatchRWKV, we have also  used three public available time series datasets including Weather \cite{Bahdanau2016Neural}, Heartbeat Monitoring Dataset and Self-Regulation of Slow Cortical Potentials (SCP) Dataset.


\subsubsection{Salford MINAP Dataset}

The Myocardial Ischaemia National Audit Project (MINAP) is a domain within the National Cardiac Audit Programme (NCAP) that contains information about the care provided to patients who are admitted to hospital with acute coronary syndromes (heart attack). It is collected and analysed to illustrate the ‘patient journey’ from a call to the emergency services or their self-presentation at an Emergency Department, through diagnosis and treatment at the hospital, to the prescription of preventive medications on discharge. A pseudonymised dataset was obtained under ethical approval (REC reference: 22/YH/0250) after confidentiality advisory group review (CAG reference: 22/CAG/0155) for use in this study.

In this work, 21 risk factors including patient demographics, clinical history, medications, vital signs and diagnostic indicators are selected to predict the ACS risk and differentiate between STEMI and NSTEMI based on their relevance and significance in clinical and environmental contexts. 

Factors such as previous Acute Myocardial Infarction (AMI), angina, hypertension, hypercholesterolemia, peripheral vascular disease, cerebrovascular disease, asthma/COPD, chronic renal failure, heart failure, smoking status, diabetes, previous PCI (Percutaneous Coronary Intervention), and previous CABG (Coronary Artery Bypass Graft) are included. These factors are crucial as they provide a comprehensive view of a patient's medical history and risk factors associated with cardiovascular diseases\cite{Rhyou2018Clinical,Yunyun2014Analysis}. Use of ACEI or ARB (Angiotensin-Converting Enzyme Inhibitors or Angiotensin II Receptor Blockers), systolic blood pressure (BP), height, weight, BMI (Body Mass Index), family history of coronary heart disease (CHD), creatinine levels, and statin use are considered. These factors help in assessing the ongoing treatment, physiological conditions, and genetic predisposition of patients. The detailed risk factors are shown in Table~\ref{tab:1}.

Based upon electrical heart tracings – electrocardiograms or ECGs recorded during a heart attack, patients are diagnosed as having suffered either ST-elevation myocardial infarction (STEMI) or non-ST elevation myocardial infarction (NSTEMI).  In the annual NCAP report, the terms ‘higher-risk’ and ‘lower-risk’ have been used to differentiate STEMI from NSTEMI. 



\begin{table*}[!htbp]
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{ll}
\hline
Medical Conditions and Measurements                                                        & Counting and calculation formulae   \\ \hline
Previous AMI (Acute Myocardial Infarction)                                                 & Yes 381/No 597                      \\
Previous Angina                                                                            & Yes 470/No 511                      \\
Hypertension                                                                               & Yes 591/No 389                      \\
Hypercholesterolaemia                                                                      & Yes 623/No 358                      \\
Peripheral Vascular Disease                                                                & Yes 103/No 877                      \\
Cerebrovascular Disease                                                                    & Yes 125/No 855                      \\
Asthma/COPD                                                                                & Yes 274/No 704                      \\
Chronic Renal Failure                                                                      & Yes 143/No 837                      \\
Heart Failure                                                                              & Yes 187/No 792                      \\
Smoking Status                                                                             & Ex 384/Current smoker 251/Never 343 \\
Diabetes                                                                                   & Yes 298/No 683                      \\
Previous PCI (Percutaneous Coronary Intervention)                                          & Yes 184/No 797                      \\
Previous CABG (Coronary Artery Bypass Graft)                                               & Yes 99/No 880                       \\
ACEI or ARB (Angiotensin-Converting Enzyme Inhibitors or Angiotensin II Receptor Blockers) & Yes 471/No 507                      \\
Systolic BP (Blood Pressure)                                                               & 137.5 ± 27.1                        \\
Height                                                                                     & 166.6 ± 10.3                        \\
Weight                                                                                     & 78.1 ± 20.57                        \\
BMI                                                                                        & $\mathrm{BMI}=\frac{\text { Weight }}{(\text { Height })^2}$                                    \\
Family History of CHD (coronary heart disease)                                             & Yes 176 /No 785                     \\
Creatinine                                                                                 & 112.4 ± 90.3                        \\
Statin                                                                                     & Yes 592/No 386                      \\
Age                                                                                        & 71.1 ± 13.7                         \\
STEMI                                                                                      & 123/587                             \\ \hline
\end{tabular}
\end{adjustbox}
\caption{Feature used in MINAP dataset.}
\label{tab:1}
\end{table*}



\subsubsection{Air Pollution Dataset}

This air pollution dataset contains hourly measurements of various air pollutants collected from the Salford Eccles monitoring station (UKA00339) in the United Kingdom. The time range covered by the data is from January 1, 2016, to December 31, 2019. The primary indicators monitored include levels of Nitrogen Oxides (NO$_x$), Nitric Oxide (NO), Particulate Matter (PM$_{10}$), and Nitrogen Dioxide (NO$_{2}$), all measured in micrograms per cubic meter (µg/m³).


\subsubsection{Public Datasets}

Weather\cite{Bahdanau2016Neural}, which is recorded every 10 minutes through the whole of the year 2020,  contains 21 meteorological indicators, such as air temperature, humidity, etc. This dataset is used for time series forecasting.
Heartbeat Monitoring Dataset\cite{Kanani2020ECG} is used to classify and monitor heartbeats. The dataset consists of sequences of heartbeat signals, often represented as electrocardiogram (ECG) readings, which need to be classified into different categories such as normal or abnormal heartbeats.
Self-Regulation of Slow Cortical Potentials (SCP) Dataset \cite{Birbaumer1999spelling} is used for studying self-regulation of brain activity, specifically the ability to control slow cortical potentials (SCPs), which are slow voltage changes in the brain's electrical activity. The dataset includes sequences of brain activity measurements, which need to be classified to understand patterns related to self-regulation capabilities.



\subsection{Performance Metrics}

In this study, we evaluate the performance of our proposed TabulaTime
model using several key metrics that are standard in the fields of
classification and forecasting. These metrics provide a comprehensive
view of the model\textquotesingle s predictive capabilities and its
effectiveness in handling both classification tasks (e.g., predicting
STEMI or NSTEMI) and forecasting tasks (e.g., forecasting air pollution
levels).

\subsubsection{Classification Metrics}

For classification tasks such as distinguishing between STEMI and NSTEMI cases, the following metrics were used:

\textbf{Accuracy}: Accuracy is a widely used metric that represents the proportion of correctly predicted instances among the total instances.


\begin{equation}
\text { Accuracy }=\frac{\mathrm{TP}+\mathrm{TN}}{\mathrm{TP}+\mathrm{FP}+\mathrm{FN}+\mathrm{TN}}
\end{equation}


\textbf{Precision:} Proportion of true positive predictions out of all positive predictions made by the model, highlighting prediction reliability.





\textbf{Recall:} Proportion of true positive predictions out of all actual positive cases, indicating the model's ability to detect positive instances.

\begin{equation}
\text { Precision }=\frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FP}}
\end{equation}


\textbf{F1-Score:} Harmonic mean of Precision and Recall, balancing both metrics for a comprehensive assessment of classification performance.

\begin{equation}
\text { Recall }=\frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FN}}
\end{equation}

\textbf{ROC Curve and AUC (Area Under the Curve):} The ROC curve is a graphical representation of a classification model's performance across all classification thresholds. It plots the True Positive Rate (TPR) against the False Positive Rate (FPR). The AUC provides a single scalar value to summarize the model's performance; a higher AUC indicates better model performance.


\subsubsection{Forecasting Metrics}


\textbf{Mean Squared Error (MSE) and Mean Absolute Error (MAE)}: MSE measures the average squared difference between the actual and predicted values. It is particularly sensitive to large errors, making it a suitable metric for assessing the accuracy of continuous predictions. MAE is another metric used to measure the average magnitude of errors in a set of predictions, without considering their direction (positive or negative). It provides a clear interpretation of the average error in the same units as the data. MSE and MAE are calculated as:


\begin{equation}
\mathrm{MSE}=\frac{1}{n} \sum_{i=1}^n\left(\hat{y}_i-y_i\right)^2
\end{equation}

\begin{equation}
\mathrm{MAE}=\frac{1}{n} \sum_{i=1}^n\left|\hat{y}_i-y_i\right|
\end{equation}

Where $\hat{y}_i$ is the predicted value and $y_i$ is the actual value.


\section{Results}

\subsection{The Performance Evaluation of TabulaTime in ACS Prediction}

The evaluation of the TabulaTime model was conducted through a series of experiments to assess its predictive performance for description of Acute Coronary Syndrome (ACS) risk. The experiments were designed to evaluate the influence of time-series air pollution data, compare TabulaTime with existing machine learning models, and analyse its generalization capabilities under varying conditions.

\subsubsection{Impact of Time-Series Length for ACS Prediction}

The model was tested with time-series air pollution data of varying lengths (3, 7, 10, and 14 days) to identify the optimal time window for ACS prediction. As shown in Table~\ref{tab:2}, the 10-day time series achieved the best results, with an accuracy of 82.3\% and an AUC of 0.91, outperforming other time lengths across all metrics. This suggests that a 10-day window strikes a balance between capturing essential trends and avoiding noise introduced by excessive data. Shorter windows (3 and 7 days) lacked critical information, while longer windows (14 days) diluted key patterns.



\begin{table*}[!htbp]
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{llllll}
\hline
\multicolumn{1}{c}{\textbf{Time   Series Length (Days)}} & \multicolumn{1}{c}{\textbf{Accuracy}} & \multicolumn{1}{c}{\textbf{Precision}} & \multicolumn{1}{c}{\textbf{Recall}} & \multicolumn{1}{c}{\textbf{F1-Score}} & \multicolumn{1}{c}{\textbf{AUC}} \\ \hline
3 Days                                                   & 0.815                                 & 0.809                                  & 0.822                               & 0.815                                 & 0.882                            \\
7 Days                                                   & 0.820                                 & 0.817                                  & 0.825                               & 0.821                                 & 0.894                            \\
10 Days                                                  & \textbf{0.823}                        & \textbf{0.820}                         & \textbf{0.830}                      & \textbf{0.825}                        & \textbf{0.914}                   \\
14 Days                                                  & 0.819                                 & 0.813                                  & 0.820                               & 0.816                                 & 0.894                            \\ \hline
\end{tabular}
\end{adjustbox}
\caption{Model prediction performance with time-series air pollution data of varying lengths.}
\label{tab:2}
\end{table*}
 


\subsubsection{Comparison With Existing Machine Learning Models for ACS Risk Prediction}

In this section, we evaluated the performance of the proposed method for ACS risk prediction, compared it with several state-of-the-art machine learning models, including Random Forests (RF), Light Gradient Boosting Machines(LightGBM), and CatBoost. The aim of this task was to predict whether a patient had STEMI or NSTEMI under different scenarios with and without air pollution data included. The accuracies of the proposed method and the existing models were reported in Table~\ref{tab:3}.

Random Forests (RF) is an ensemble learning technique that constructs multiple decision trees and outputs from either the mode of the classes (for classification) or the mean prediction (for regression) from the individual trees. This method is robust against overfitting and handles a large number of input features effectively. Both LightGBM and CatBoost are gradient boosting algorithms that are particularly well-suited for structured/tabular data, offering high performance and efficiency.


\begin{table*}[!htbp]
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{lllll}
\hline
Methods              & Random Forest (RF) & LightGBM & Catboost & The proposed TabulaTime \\ \hline
W/O air pollution    & 0.6                & 0.645    & 0.665    & 0.753                   \\
With air   pollution & 0.627              & 0.655    & 0.688    & 0.829                   \\ \hline
\end{tabular}
\end{adjustbox}
\caption{Model performance between traditional machine learning method and proposed method.}
\label{tab:3}
\end{table*}
 

The performance metrics are provided for two scenarios: without considering air pollution and with considering air pollution. In both scenarios, TabulaTime consistently outperforms RF, LightGBM and Catboost. When air pollution data was included, TabulaTime significantly outperformed the other models. It performed 32.2\% better than Random Forest, 27.5\% better than LightGBM, and 20.5\% better than CatBoost. Without the inclusion of air pollution data, TabulaTime performs 25.5\% better than Random Forest, 16.7\% better than LightGBM, and 13.2\% better than CatBoost.

Both models showed an improvement when air pollution is included as a factor. The performance of RF improves by 4.5\% (from 0.6 to 0.627), LightGBM improved by 1.6\% (from 0.645 to 0.655) and Catboost improves by 3.5\% \% (from 0.665 to 0.688). TabulaTime\textquotesingle s performance improved by 10.1\% (from 0.753 to 0.829). This indicated that incorporating air pollution data enhanced the predictive capabilities of both models, but the improvement was more pronounced for TabulaTime. {Figure~\ref{fig:5}} and {Figure~\ref{fig:6}} reported the Area Under the Receiver Operating Characteristic Curve (AUC-ROC) for the best-performing machine learning model (Catboost) and the proposed TabulaTime. The results confirm that the model performance improved with the inclusion of air pollution indicators. The ROC of the Catboost increased from 0.67 to 0.72, while the proposed TabulaTime improved the prediction accuracy from 0.83 to 0.91.


\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{./img/img5.png}
\caption{ROC curve of Catboost with and without air pollution.}
\label{fig:5}
\end{figure}



\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{./img/img6.png}
\caption{ROC curve of TabulaTime with and without air pollution.}
\label{fig:6}
\end{figure}




\subsubsection{Generalisation Performance Under Varying Conditions}

The generalisability of a model is a crucial indicator of its performance. Notably, during the COVID-19 lockdown in the UK (March 2020 to December 2021), there was a significant decline in air pollution levels. However, the incidence of heart attacks, particularly NSTEMI, increased, a trend confirmed by various studies \cite{Little2020COVID,Topol2020COVID}.

We have evaluated the model performance across three distinct periods: pre-COVID (January 2016 to December 2019), during the COVID lockdown (March 2020 to December 2021), and post-COVID lockdown (January 2022 to December 2023). {Figure~\ref{fig:7}} illustrates the PM$_{10}$ levels and the daily incidence of heart attacks during these periods. The model's accuracy for these periods was 0.829, 0.788, and 0.802, respectively, despite significant fluctuations in air pollution levels. This consistency in model accuracy across different conditions indicates that our model remains effective under various scenarios.

\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{./img/img7.png}
\caption{Changes in air pollution indicator PM$_{10}$ and heart attack daily
incidence over different periods.}
\label{fig:7}
\end{figure}



\subsection{The Performance of PatchRWKV}

In the second experiment, we evaluated the performance of the proposed time series feature extraction module (PatchRWKV). Two types of tasks were used to evaluate the model's performance: \textbf{Classification and Forecasting}.

\subsubsection{Classification}


The aim of this experiment was to assess the model's ability to learn high-level representations through sequence-level classification in time series data. We selected three multivariate datasets from medical diagnosis including heartbeat monitoring and Self-regulation of Slow Cortical Potentials and ACS prediction.

\begin{table*}[!htbp]
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{lrrrrrllr}
\hline
Methods            & \multicolumn{1}{l}{LightTS} & \multicolumn{1}{l}{DLinear} & \multicolumn{1}{l}{TimesNet} & \multicolumn{1}{l}{Autoformer} & \multicolumn{1}{l}{PatchTST} & GRU                       & LSTM  & \multicolumn{1}{l}{PatchRWKV} \\ \hline
Heartbeat          & 0.751                       & 0.751                       & 0.756                        & 0.737                          & 0.771                        & 0.722                     & 0.751 & 0.780                         \\
SelfRegulationSCP1 & 0.898                       & 0.873                       & 0.846                        & 0.887                          & 0.904                        & \multicolumn{1}{r}{0.549} & 0.744 & 0.918                         \\
SelfRegulationSCP2 & 0.511                       & 0.505                       & 0.556                        & 0.544                          & 0.567                        & 0.533                     & 0.517 & 0.572                         \\
ACS                & 0.681                       & 0.667                       & 0.676                        & 0.686                          & 0.678                        & 0.676                     & 0.686 & 0.703                         \\ \hline
\end{tabular}
\end{adjustbox}
\caption{Model performance on classification tasks.}
\label{tab:4}
\end{table*}
 


Table~\ref{tab:4} presents the classification accuracy of eight time series processing models across four classification tasks (Heartbeat, SelfRegulationSCP1, SelfRegulationSCP2, ACS). In Heartbeat task, PatchRWKV improved by 0.9\% over PatchTST and showed a significant improvement of 5.8\% over GRU. In SelfRegulationSCP1 and SelfRegulationSCP2 tasks, PatchRWKV (91.80 and 57.20) outperformed the next best method, PatchTST (90.40 and 56.70), by 1.40\% and 0.50 \%. In the ACS classification task, PatchRWKV (70.28) outperformed the LSTM and Autoformer (both 68.58), by 1.7\%.

PatchRWKV consistently outperformed the other models, achieving the highest accuracy across all tasks: Heartbeat: 78\%, SelfRegulationSCP1: 91.8\%, SelfRegulationSCP2: 57.2\% and ACS: 70.28\%. The improvements range from 0.50\% to 36.85\%, indicating that PatchRWKV is a robust and effective method for these classification tasks, especially with a substantial advantage in more complex tasks like SelfRegulationSCP1. Traditional models like GRU and LSTM lag significantly behind newer architectures, indicating a shift in effectiveness towards more advanced methods like PatchTST and TimesNet.

\subsubsection{Forecasting}

The aim of this experiment was to evaluate the performance of the proposed and compared models in time series forecasting tasks for weather and air pollution prediction. Two real-world datasets were used: the Weather Dataset and the Salford Air Pollution Dataset. 

For the Weather Dataset, 144 historical time steps (24 hours) were used to forecast the next 48 time steps (8 hours), for two indicators: pressure and temperature. In the Salford Air Pollution Dataset, 240 historical time steps (10 days) were used to predict the next 48 time steps (2 days) for four indicators:  Particulate Matter (PM$_{10}$), Nitrogen Dioxide (NO$_{2}$), Nitrogen Oxides (NO$_x$) and Nitric Oxide (NO).


% Time series forecasting is a critical task in various domains. To evaluate the performance of the proposed model in weather forecasting, two real-world datasets are utilized: the Weather dataset and the Salford Air Pollution dataset. 

% For the Weather Dataset, 144 historical time steps (equivalent to 24 hours) are used to forecast the next 48 time steps (8 hours). Two indicators, pressure and temperature, are used for the forecasting task. In the case of the Salford Air Pollution Dataset, 240 historical time steps (representing 10 days) are employed to predict the subsequent 48 time steps (2 days). Four indicators are used for forecasting: Particulate Matter (PM$_{10}$), Nitrogen Dioxide (NO$_{2}$), Nitrogen Oxides (NO$_x$) and Nitric Oxide (NO).


\begin{table*}[!htbp]
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{cccccc}
\hline
\multicolumn{2}{c}{\multirow{2}{*}{\textbf{Methods}}}    & \multicolumn{2}{c}{\textbf{Weather}} & \multicolumn{2}{c}{\textbf{Salford   Air Pollution}} \\ 
\multicolumn{2}{c}{}                                     & MSE               & MAE              & MSE                       & MAE                      \\ \hline
\multirow{2}{*}{\textbf{MLP-based}}        & LightTS    & 0.261             & 0.312            & 0.693                     & 0.511                    \\
                                            & DLinear    & 0.249             & 0.3              & 0.695                     & 0.508                    \\ \hline
\textbf{CNN-based}                          & TimesNet   & 0.259             & 0.287            & 0.78                      & 0.504                    \\ \hline
\multirow{2}{*}{\textbf{Transformer-based}} & Autoformer & 0.338             & 0.382            & 0.707                     & 0.49                     \\
                                            & PatchTST   & 0.231             & 0.266            & 0.685                     & 0.481                    \\ \hline
\multirow{3}{*}{\textbf{RNN-based}}         & GRU        & 0.225             & 0.286            & 0.718                     & 0.524                    \\
                                            & LSTM       & 0.199             & 0.262            & 0.722                     & 0.52                     \\
                                            & PatchRWKV  & 0.177             & 0.264            & 0.674                     & 0.473                    \\ \hline
\end{tabular}
\end{adjustbox}
\caption{Model performance on forecasting tasks.}
\label{tab:5}
\end{table*}
 


    

\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{./img/img8.png}
\caption{The forecasting result of PatchRWKV on Weather (a and b) and Salford Air Pollution dataset (c,d,e and f)}
\label{fig:8}
\end{figure}



Table~\ref{tab:5} presents the performance of various time series processing model on two forecasting tasks. The models are categorized into four types: MLP-based, CNN-based, Transformer-based, and RNN-based. Performance was evaluated using two metrics: Mean Squared Error (MSE) and Mean Absolute Error (MAE). The PatchRWKV approach demonstrates superior performance on both datasets, achieving the lowest MSE and highly competitive MAE values. {Figure~\ref{fig:8}} showed the forecasting results of PatchRWKV on the two real datasets forecasting tasks. The model results were successful in predicting the trends of the pollution indicators. This indicates that PatchRWKV is highly effective in terms of both accuracy and robustness compared to other methods evaluated. Meanwhile, the RNN-based models generally outperformed other types in weather forecasting, with PatchRWKV and LSTM showing particularly strong results.

\subsubsection{Computing Efficiency Analysis}


\begin{table*}[!htbp]
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{cccccc}
\hline
Method     & Time   Complexity        & Test Step & Parameter  \\ \hline
GRU        & O(L)                     & L         & 38,709,216 \\
LSTM       & O(L)                     & L         & 9,216,192  \\
LightTS    & O(L)                     & 1         & 11,128     \\
DLinear    & O(L)                     & 1         & 18,624     \\
TimesNet   & O(k\textasciicircum{}2L) & 1         & 1,193,781  \\
PatchTST   & O(L\textasciicircum{}2)  & 1         & 677,984    \\
Autoformer & O(LlogL)                 & 1         & 882,709    \\
PatchRWKV  & O(L)                     & 1         & 468,144    \\ \hline
\end{tabular}
\end{adjustbox}
\caption{Computational complexity comparison. L is the sequence length; k is the kernel size of convolutions. The GRU and LSTM are sequential processing that have L test step to capture long-term dependencies. For the rest models, only 1 test step needed for processing the entire sequence in parallel, enabling faster inference.}
\label{tab:6}
\end{table*}
 



We have conducted a complexity analysis of the PatchRWKV, and its competing models as shown in Table~\ref{tab:6}. GRU, LSTM, LightTS, DLinear, PatchRWKV have a linear time complexity relative to the sequence length L. This is efficient for longer sequences as the complexity grows at a controlled rate. TimesNet is a CNN based model that introduces a quadratic factor based on the kernel size k. PatchTST and Autoformer which are two transformer-based model that have quadratic and logarithmic complexity concerning the sequence length L. For the Test Step, GRU and LSTM are traditional RNN models with L number of test steps, which means they require multiple steps proportional to the length of the sequence, which may increase the computational load during testing or inference. In contrast, models like LightTS, DLinear, TimesNet, PatchTST, Autoformer, and PatchRWKV need only 1 test step as they process the entire sequence in parallel, enabling faster inference. For the count of parameters, GRU (38,709,216) and LSTM (9,216,192) have significantly higher parameter counts compared to others due~to the RNN\textquotesingle s computational mechanism. The proposed PatchRWKV (468,144) have relatively low parameter counts, which generally translates to more lightweight models that are faster and require less memory, making them suitable for scenarios where computational resources are limited.

\subsection{Feature Importance and Model Interpretability}


\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{./img/img9.png}
\caption{Feature importance on ACS STEMI VS NSTEMI prediction.}
\label{fig:9}
\end{figure}


In this work, we reported feature importance to explain how models make decisions to predict STEMI VS. NSTEMI.The analysis highlights the contributions of 25 risk factors ({Figure~\ref{fig:9}}), encompassing patient demographics, clinical history, vital signs, medications, diagnostic indicators, and air pollution metrics. The analysis revealed that Systolic Blood Pressure (SBP) was the most influential predictor of STEMI and NSTEMI, with the highest importance score (0.084), emphasizing its critical role in cardiovascular function. Body Mass Index (BMI) followed as the second most important feature (0.073), highlighting the metabolic influence on cardiovascular health, particularly in chronic conditions. Air quality metrics, such as PM$_{10}$sum, PM$_{10}$max, and NO$_{2}$sum, were also significant contributors, underscoring the acute and cumulative impact of air pollution on cardiovascular risk. Moderately important features included creatinine levels (0.055), indicative of renal function, and age at admission (0.064), a well-established cardiovascular risk factor. Additionally, historical factors like angina and smoking status provided valuable insights into patient-specific risks. While metabolic factors like diabetes and hypertension were relevant, their lower importance scores suggests a more indirect role in the model. Lesser but notable contributors included peripheral vascular disease and prior CABG/PCI, reflecting the background conditions associated with ACS risk.




\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{./img/img10.png}
\caption{Day-wise Importance for ACS Prediction.}
\label{fig:10}
\end{figure}



{Figure~\ref{fig:10}} showed the average importance of air qiality each day for predicting ACS risk.  The daily step importance analysis revealed that pollution levels on the day prior to a clinical presentation of ACS (Day 1) held the highest predictive significance, followed by a gradual decline in relevance for preceding days. This finding emphasizes the acute impact of short-term pollution exposure on presentation of ACS.


\begin{table*}[!htbp]
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{lrrrrrrl}
\hline
                          & \multicolumn{3}{c}{\textbf{STEMI}} & \multicolumn{3}{c}{\textbf{NSTEMI}} & \textbf{T-test p-value}    \\ \hline
                          & 25\%       & 50\%      & 75\%      & 25\%       & 50\%       & 75\%      &                            \\ \hline
\textbf{Systolic BP}      & 114        & 128       & 146       & 121        & 138        & 156       & 0.0019 (\textless 0.05)    \\
\textbf{Creatinine}       & 70.75      & 86        & 99        & 72         & 88         & 108       & 0.0049 (\textless 0.05)    \\
\textbf{Age At Admission} & 59         & 71        & 80.25     & 60         & 72         & 81        & 0.4911 (\textgreater 0.05) \\
\textbf{BMI}              & 23.36      & 26.02     & 29.5      & 24.53      & 28.03      & 32.23     & 0.0021 (\textless 0.05)    \\
\textbf{PM10sum}          & 748.94     & 910.2     & 1226.46   & 769.85     & 978.45     & 1379.95   & 0.0487 (\textless 0.05)    \\
\textbf{NOsum}            & 160.45     & 345.22    & 751.63    & 157.07     & 296.12     & 681.47    & 0.4883 (\textgreater 0.05) \\
\textbf{NO2sum}           & 1092.68    & 1502.32   & 2045.5    & 1112.78    & 1462.57    & 2049.09   & 0.628 (\textgreater 0.05)  \\
\textbf{NOXsum}           & 1318.5     & 2060.17   & 3244.01   & 1388.16    & 1916.61    & 3054.62   & 0.5147 (\textgreater 0.05) \\
\textbf{PM10max}          & 22.4       & 27.55     & 40.89     & 22         & 29.73      & 43.5      & 0.4147 (\textgreater 0.05) \\
\textbf{NOmax}            & 11.07      & 35.66     & 82.02     & 11.1       & 28.43      & 77.36     & 0.9342 (\textgreater 0.05) \\
\textbf{NO2max}           & 40.21      & 54.79     & 67.28     & 40.12      & 53.04      & 68.63     & 0.8793 (\textgreater 0.05) \\
\textbf{NOXmax}           & 55.79      & 103.91    & 175.8     & 55.86      & 91.64      & 181.47    & 0.8761 (\textgreater 0.05) \\ \hline
\end{tabular}
\end{adjustbox}
\caption{Comparison of key clinical and environmental predictors for STEMI and NSTEMI cases. The Quartile Cutoff values represent the 25th, 50th (median), and 75th percentiles of each predictor's distribution. The statistical significance of these variables (p $<$ 0.05) supports their clinical relevance in distinguishing STEMI from NSTEMI.}
\label{tab:7}
\end{table*}

Table~\ref{tab:7} presented the quartile cutoff values of key clinical and environmental factors along with t-test p-values, significant differences between STEMI and NSTEMI cases emerge, highlighting distinct chronic and acute influences. Systolic BP is significantly higher in NSTEMI (75th percentile = 156) compared to STEMI (75th percentile = 146, p = 0.00187), suggesting that chronic hypertension is more prevalent in NSTEMI, whereas lower BP in STEMI reflects acute cardiovascular dysfunction. BMI follows a similar trend, with higher values in NSTEMI (75th percentile = 32.23 vs. 29.5 in STEMI, p = 0.00207), reinforcing the role of chronic obesity. Creatinine levels are also significantly elevated in STEMI (p = 0.00490), indicating potential acute kidney injury or pre-existing renal impairment as contributors. Notably, PM$_{10}$ exposure is significantly higher in STEMI cases (p = 0.04867), suggesting that short-term environmental triggers may precipitate acute coronary events, while NO, NO$_{X}$, and NO$_{2}$ levels showed no significant difference (p $>$ 0.05), implying a lesser role in STEMI/NSTEMI differentiation. However, the lack of statistical significance in several AQIs may be due to the fact that STEMI and NSTEMI cases occurred on the same day, reducing the distinction between pollution-related effects. Age at admission trends slightly higher in NSTEMI (75th percentile = 81 vs. 80.25 in STEMI), but the difference is not statistically significant (p = 0.49108). These findings emphasize the chronic nature of NSTEMI, driven by hypertension and obesity, versus the acute nature of STEMI, potentially triggered by air pollution exposure, highlighting the need for targeted prevention strategies such as improved hypertension and obesity management and air quality interventions to mitigate ACS risk.
 
% Based on the Table~\ref{tab:7} which shows the quartile cutoffs values of Systolic BP, Creatinine, BMI,Age at Admission, PM$_{10}$, NO, NO$_{X}$ and NO$_{2}$. These cutoffs help illustrate the spread and central tendency of the data across both types of myocardial infarction cases. Higher systolic BP values (e.g., 75th percentile = 156) are associated with NSTEMI, indicating chronic hypertension's role, while lower BP values in STEMI (75th percentile = 146) suggest acute dysfunction. BMI trends, similarly, with higher values (75th percentile = 32.23) linked to NSTEMI, reflecting the chronic effects of obesity. PM$_{10}$sum and Creatinine exhibit higher medians in STEMI, indicating acute environmental or renal triggers contribute to presentation as a STEMI, while age distribution slightly favors NSTEMI outcomes (e.g., 75th percentile = 81). These variations emphasize chronic versus acute influences, highlighting the need for tailored prevention and intervention strategies.


\section{Discussion}


This study presents TabulaTime, a novel deep learning-based method designed to integrate air pollution data with clinical risk factors for predicting Acute Coronary Syndrome (ACS). The results from our experiments suggest that combining environmental and clinical data significantly improves prediction accuracy, reinforcing the need to include environmental factors in cardiovascular risk models.


Traditional cardiovascular risk scores, such as QRISK3, FRS, and GRACE, primarily rely on clinical data and do not include dynamic environmental influences. By incorporating air pollution data, the TabulaTime model addresses this gap, providing a more comprehensive risk assessment tool. This integration is particularly relevant given the growing body of evidence linking air pollution to adverse cardiovascular outcomes. For instance, pollutants such as PM$_{10}$, NO$_{2}$, NO, and NO$_{x}$ have been shown to exacerbate cardiovascular conditions through mechanisms like inflammation and oxidative stress \cite{Chen2022Hourly,Braunwald2023Air}.  In this work, the presence of environmental factors like PM$_{10}$ and NO$_{2}$ among the more important features indicates that air quality and pollution may be significant predictors in the context of the model, possibly relating to respiratory or cardiovascular conditions. Our experimental results demonstrate that including air pollution data improves the accuracy of ACS risk prediction by 10.1\%, a substantial gain over traditional clinical-only models. This finding aligns with prior epidemiological studies linking air pollutants (PM$_{10}$, NO$_{2}$, NO$_{x}$) with increased cardiovascular stress, inflammation, and thrombotic events. By incorporating real-time exposure data, TabulaTime provides a more holistic assessment of ACS risk, highlighting the immediate effects of environmental exposure in triggering cardiovascular events.

One of the major innovations in TabulaTime is the PatchRWKV module, an efficient time-series feature extraction module that combines Recurrent Neural Networks (RNNs) and Transformer-based self-attention mechanisms. Our experiments across multiple classification and forecasting tasks confirmed that PatchRWKV surpassed state-of-the-art models such as PatchTST, Autoformer, and TimesNet, while maintaining linear computational complexity. The patching strategy, which isolates local temporal patterns (e.g., daily pollution cycles), allows the model to discern subtle exposure-response relationships that manual feature engineering might miss. This capability is critical for public health applications, where identifying high-risk periods (e.g., days with PM$_{10}$ >40 µg/m³) can inform real-time interventions.

When compared to Random Forest (RF), LightGBM, and CatBoost, TabulaTime significantly outperformed these traditional machine learning models, achieving a 32.2\% improvement over RF and a 20.5\% improvement over CatBoost. Notably, even without environmental data, TabulaTime still maintains a superior performance, suggesting that its novel multimodal feature integration and advanced temporal feature extraction contribute significantly to its predictive strength.

The robustness of TabulaTime was tested under different environmental and temporal conditions. Notably, during the COVID-19 lockdown (2020–2021)—when air pollution levels were drastically reduced, our model maintains high predictive accuracy (78.8\%), despite the altered exposure conditions. This result underscores TabulaTime’s adaptability to fluctuating environmental factors, making it potentially valuable for real-time health monitoring systems.

Clinically, TabulaTime’s interpretability offers actionable insights. The use of attention mechanisms and feature importance analysis enhances the interpretability of the model. Our analysis identified Systolic Blood Pressure (SBP), Body Mass Index (BMI), PM$_{10}$, and NO$_{2}$ as the most influential features for ACS risk prediction ({Figure~\ref{fig:9}}) . The high importance of PM$_{10}$ and NO$_{2}$ suggests a strong link between air pollution and acute cardiovascular events, reinforcing the need for air quality monitoring as a preventive healthcare measure. Additionally, the day-wise analysis of air pollution exposure ({Figure~\ref{fig:10}}) revealed that pollution levels one day prior to ACS onset were the most predictive, suggesting that short-term exposure triggers acute cardiovascular events. This result is clinically significant, as it supports policies advocating for real-time air quality alerts and public health interventions in high-pollution areas.


Despite its strengths, the TabulaTime model has several limitations. The model was tested using data from Salford, UK, so it may not work exactly the same way in other regions where air pollution levels and healthcare conditions are different. Future studies should test the model in other or larger locations to see if it can be applied more widely. Also, while PM$_{10}$, and NO$_{2}$ were identified as important pollutants, other environmental factors like temperature, humidity, and noise levels were not included in this study. Adding these in the future could make the predictions even more accurate. 

In conclusion, TabulaTime is a powerful tool for ACS prediction that integrates environmental and clinical data. It is more accurate, efficient, and adaptable than traditional models, offering valuable insights for both clinical decision-making and public health policies. With further validation and refinement, it could play a significant role in personalized healthcare, air pollution monitoring, and real-time risk assessment.




\section{Conclusion and Future work}

This study introduces TabulaTime, a novel multimodal model that integrates time-series air pollution data with traditional clinical data to investigate their influence on Acute Coronary Syndrome (ACS) presentation. The results demonstrated that TabulaTime effectively incorporated these elements, achieving outstanding performance. Notably, the PatchRWKV module significantly enhanced the model's accuracy by capturing both short-term and long-term pollution exposure trends, a major advancement in temporal feature extraction.

The experimental results underscored TabulaTime's effectiveness in improving predictive accuracy across various tasks. Our TabulaTime outperformed other state-of-the-art machine learning models, such as Random Forests, LightGBM, and CatBoost, by margins ranging from 16.7\% to 32.2\%, showcasing its robustness and efficacy.  Specifically, our findings highlighted the critical role of environmental factors in cardiovascular risk assessment. The inclusion of air quality data led to a 10.1\% improvement in accuracy compared to scenarios where such data was omitted, emphasizing the importance of integrating environmental factors in ACS risk prediction—an aspect often overlooked in traditional models. 

Furthermore, the PatchRWKV module demonstrated superior performance in time-series classification and forecasting tasks. In classification tasks, it outperformed state-of-the-art models such as LightTS, DLinear, TimesNet, Autoformer and PatchTST. In forecasting tasks, PatchRWKV consistently delivered lower Mean Squared Error (MSE) and Mean Absolute Error (MAE) compared to other models, demonstrating robust predictive capabilities for both weather and air pollution indicators. 

% This study introduces TabulaTime, a novel multimodal model that integrates time-series air pollution data with traditional clinical data to investigate their influence on ACS presentation. The results demonstrated that TabulaTime effectively incorporates these elements, indicating outstanding performance. The PatchRWKV module’s ability to capture both short-term and long-term pollution exposure trends significantly improved the model's accuracy. 
% Specifically, our findings emphasise the critical role of environmental factors in cardiovascular risk assessment. When air quality data was included, the model achieved a 10.1\% improvement in accuracy compared to scenarios where such data was omitted. This highlights the importance of considering environmental factors in ACS risk prediction, often not used in traditional models. 


% The experimental results underscore the effectiveness of the TabulaTime model in enhancing predictive accuracy across various tasks. 


The model maintained high accuracy despite significant fluctuations in air pollution levels, with accuracy rates of 82.9\%, 78.8\%, and 80.2\% for pre-COVID, during COVID lockdown, and post-COVID periods, respectively. This adaptability suggested that TabulaTime was applicable across diverse geographical and temporal contexts. The feature importance analysis revealed that clinical factors such as previous angina and systolic blood pressure, alongside environmental pollutants like PM$_{10}$ and NO$_{2}$, are significant predictors of ACS risk. Interestingly, metabolic factors such as BMI and hypertension, while still relevant, were less influential in this model. This finding suggested that while metabolic factors contributed to cardiovascular risk, the interaction between clinical history and environmental exposure played a more pivotal role in the context of ACS prediction. 

Overall, TabulaTime represents a significant advancement in ACS risk modelling by integrating environmental and clinical data, offering a comprehensive approach to preventive cardiology. The findings suggest that future predictive models should include environmental data to enhance accuracy and provide more holistic insights into patient health, thereby aiding in more effective clinical decision-making and targeted interventions.


Our future work will includes continuously validating TabulaTime across diverse geographic settings to enhance its generalizability, accounting for variations in air pollution levels, socio-demographics, and healthcare access. Additionally, incorporating personalized risk assessments—factoring in genetic predisposition, lifestyle, and comorbidities—could improve individualized ACS prediction. Beyond air pollution, integrating broader environmental and socioeconomic factors, such as healthcare accessibility, would further refine the model into a comprehensive health risk assessment tool. These advancements will enhance TabulaTime’s impact on clinical decision-making and public health strategies.



\section*{Acknowledgement}

Funding support: British Heart Foundation Doug Gurr Cardiovascular Catalyst Award (BHF-CC/22/250021). Liangxiu Han is supported by EPSRC (EP/X013707/1).


%%===========================================================================================%%
%% If you are submitting to one of the Nature Portfolio journals, using the eJP submission   %%
%% system, please include the references within the manuscript file itself. You may do this  %%
%% by copying the reference list from your .bbl file, paste it into the main manuscript .tex %%
%% file, and delete the associated \verb+\bibliography+ commands.                            %%
%%===========================================================================================%%

\bibliography{sn-bibliography}% common bib file
%% if required, the content of .bbl file can be included here once bbl is generated
%%\input sn-article.bbl


\end{document}
