%The area of 
%Large Language Models (LLMs) have rapidly advanced in recent years, accelerating the development of intelligent agents across various domains. In particular, LLM-driven agents are transforming Autonomous Software Engineering (ASE) \cite{devinwebpage}, enabling capabilities such as automatic code generation, program repair, and feature enhancement. 
Large Language Models (LLMs) have advanced rapidly, driving intelligent agents across diverse domains. In Autonomous Software Engineering (ASE) \cite{devinwebpage}, LLM-driven agents enable automatic code generation, program repair, and feature enhancement.
%The possibility of 
Incorporating LLMs into software development processes has been demonstrated promising by tools such as GitHub Copilot~\cite{copilot} and LLM-based agents like AutoCodeRover~\cite{zhang2024autocoderover} and SWE-agent~\cite{yang2024swe}. To navigate repositories, create patches, and fix problems, these agents leverage 
%make use of 
capabilities such as fault localization, action planning, and program-building unit tests.
%, etc. 
Among these abilities, localization -- the ability to precisely identify
%locate 
and navigate to relevant code 
%areas 
for resolving software engineering problems
%issues 
-- remains a crucial yet underexplored challenge in ASE.
%little-studied ASE difficulty.

\begin{figure}[t]
    % \vspace{-5pt}
    \centering
    \centerline{\includegraphics[width=\columnwidth]{fig/motivation.pdf}}
    % \vspace{-10pt}
    \caption{Distribution and average of file / function match rate and resolved rate on SWE-Bench Lite LeaderBoard.}
    \label{fig:motivation}
    % \vspace{-18pt}
    % \vskip -18pt
\end{figure}


Localization is well-recognized as a critical yet challenging step~\cite{yang2024swe, xia2024agentless} in ASE. As shown in Figure~\ref{fig:motivation}, on average, only 53.5\% of issues achieve a correct function match across all submitted agents solutions~\cite{swebenchleaderboard}. Localization is challenging due to an inherent complexity of software repositories. 
For instance, the average codebase of SWE-bench~\cite{swebench} 
%(a popular repository issue resolution benchmark), the average codebase 
consists of $~$3,010 files
%, covering 
with around 438K lines of code.%What's more, localization to the relevant code is hindered by the fact that 
Worse yet, user requirements are often expressed in imprecise natural language, making it even more challenging to extract relevant code from a large repository based on the user's issue input.
%user requirements are typically conveyed in an imprecise natural language, exacerbating the difficulty of extracting relevant code from a large repository containing user's issue input. 
%Thus, it can be very tough to extract relevant code from a large repository containing with user's issue input. 
In particular, we identify 
%there are 
three key challenges of LLM agent-based localization: 

%The first challenge is 
%First, 
1) \textit{How to explore the codebase with strategic action planning and precise navigation?}  
Prior works 
%have investigated
on agent-based software localization 
%but 
%face 
encounter two key limitations: 
(i) action planning inefficiencies arise as %some
certain methods rely solely on LLMs for guidance~\cite{autocoderover}, resulting in unstable and redundant search behaviors; 
%Meanwhile, 
(ii) graph-based scheduling~\cite{repounderstander} 
%will 
limits flexibility by enforcing preprocessed traversal routes that confine searches to neighboring nodes. 


%The second key challenge lies in balancing 
%Second, 
2) \textit{How to achieve both context conciseness and search space completeness?} 
Concise context, such as code skeletons, reduces noise and keeps the context manageable but risks omitting critical details for precise localization.
Conversely, a fully detailed search space ensures completeness but introduces overwhelming noise, redundancy, and irrelevant exploration paths.
Achieving both conciseness and completeness simultaneously is challenging, as existing methods often optimize for one at the expense of the other, leaving an open gap in effective localization.

%Finally, 
3) \textit{How to effectively manage context during exploration?} %is another critical challenge. 
Large repositories often introduce noise due to ambiguities, such as function overrides and inherited classes.
%contain ambiguities such as function overrides and inherited classes, which contribute to noise. 
As the exploration process progresses, 
%grows, 
irrelevant information can accumulate, 
%which will 
misleading the LLM and resulting in 
%cause it to determine 
incorrect identification of bug locations. 
Existing frameworks~\cite{autocoderover, wang2024openhands}, merely concatenate all search results into the context, which is insufficient to manage the expanding complexity of large-scale exploration.


% In addition, code ambiguities within themselves further worsen the problem. Large repositories often feature scenarios, including function overrides, inherited classes, and ambiguous references, causing noise that could misguide LLM-based agents. The navigation task is made more difficult by LLMs' tendency to have hallucinations or generate repetitive search actions.

To address these challenges, we propose an agent system consisting of three key components:

%\begin{itemize}
\squishlist
\item \textbf{Priority-Based Scheduling for LLM-Guided Actions:} 
To address challenge 1), we design a dynamic action scheduling system that incorporates priority queues and LLM-guided action generation for codebase exploration. The priority queue dynamically reorders actions based on their contextual relevance and urgency, solving the shortcomings of previous systems that lacked effective action management.
\item \textbf{Action Decomposition with Relevance Scoring:} To resolve challenge 2), we introduce a method that decomposes high-level actions, such as class skeletons or file skeletons, into finer-grained sub-actions. These sub-actions are evaluated and ranked 
%based on 
according to their relevance to the issue using a multi-agent workflow, ensuring comprehensive exploration while avoiding noise and redundancy.
\item \textbf{Distance-Aware Searched Context Pruning:} To address challenge 3), we design a context manager that 
%will 
dynamically prunes the searched context. The pruning algorithm leverages
%is based on 
%the 
a node distance heuristic within the graph-oriented codebase. By filtering out irrelevant data, the context manager ensures that exploration 
%remains 
stays focused and aligned with the bug localization.
\squishend
% \end{list}

% As for program repair, we are able to integrate our localizer agent into other cutting-edge editor frameworks~\cite{wang2024openhands, xia2024agentless}. Our experiments show that \nickname outperforms other modern localizer frameworks by the function-matched accuracy of the 6.67\% function and the final resolved rate of 6.33\% in SWE-Bench Lite. What's more, we performed several ablation experiments during the localization step to demonstrate the efficacy of our three contributions.


\begin{figure*}[t]
    % \vspace{-5pt}
    \centering
    \centerline{\includegraphics[width=\linewidth]{fig/overview.pdf}}
    % \vspace{-5pt}
    \caption{An overview of \nickname using a demonstrating example from issue \texttt{django\_14580}. (a) shows an abbreviated version of the issue's problem statement, where the user emphasizes \texttt{CreateModel} and \texttt{MigrationWriter}. (b) presents the exploration sequence of our agent over a part of the whole CodeGraph. (c) provides details of the Action Scheduler Queue (ASQ). Specifically, action decomposition is applied from \circlednumber{1} to \circlednumber{2} and from \circlednumber{8} to \circlednumber{9}, as discussed in Section~\ref{score ranking}. Additionally, techniques described in Section~\ref{scheduler queue} are used to handle steps from \circlednumber{6} to \circlednumber{7} and \circlednumber{7} to \circlednumber{8}. (d) illustrates the distance-aware context pruning process, elaborated in Section~\ref{context manager}. Finally, (e) shows the agent's final output. Please note this is a demonstration, experiments may use different configuration. } 
    \label{fig:overview}
    % \vskip -0.2in
    \vspace{-15pt}
\end{figure*}

