One limitation of our search agent design is its lack of awareness of execution stack traces. While static analysis provides substantial information, integrating trace data could further enhance agent performance. To address this, we designed an \textbf{trace analysis  agent} to reproduce issues and extract trace data.
As illustrated in \cref{fig:tracer_appendix}, the trace analysis agent follows three main steps:

\begin{itemize} 
\item Identifies suspicious functions and files from plain text sources, including tracebacks, code snippets, logs, and natural language descriptions; 
\item Attempts to reproduce the issue by generating and executing a snippet, then judging its output; 
\item Extracts key information from the trace through filtering and re-ranking. 
\end{itemize}

\begin{figure}[ht]
    % \vspace{-10pt}
    \centering
    \centerline{\includegraphics[width=\columnwidth]{fig/appendix/tracer_appendix.pdf}}
    % \vspace{-5pt}
    \caption{Internal structure of tracer agent. \cref{tracer_0} contents are labeled in blue, \ref{tracer_1} in red and \ref{tracer_2} in purple.}
    \label{fig:tracer_appendix}
    \vspace{-15pt}
\end{figure}

\subsection{Plain Text Parser} \label{tracer_0}

Extracting relevant data from execution traces is challenging due to their tremendous size. To narrow the search space, we identify initial \textbf{suspicious keywords} from the problem description.

We first segment the description into multiple patterns—tracebacks, code snippets, and natural language. Each segment is then processed using tailored prompts to extract relevant keywords with higher accuracy.

\subsection{Reproduction Snippet Generator} \label{tracer_1}

To reproduce the issue, we set up a conda environment inside a Docker container following the methodology in SWE-Agent \cite{yang2024swe}. We then generate and execute a reproduction snippet using an LLM and record its execution trace with VizTracer \cite{viztracer}.

The snippet’s output is sent to an \textbf{LLM judge}, which determines whether the issue was successfully reproduced. If successful, the reproduction log and code are forwarded to the plain text parser for further analysis.

\subsection{Stack Trace Selector} \label{tracer_2}

Once trace data is collected, we apply filtering strategies based on empirical observations. Our case study indicates that the root cause of a bug is often:

\begin{itemize} 
\item Located in the same file as a suspicious keyword; 
\item A close descendant of a suspicious keyword in the trace; 
\item Near the root of the trace tree. 
\end{itemize}

Using these heuristics, we assign priorities to trace entries and filter the top K = 25 candidates.

For finer-grained ranking, we compute a relevance score for each candidate by feeding its code context into an LLM. The final ranking is determined using a weighted sum of the LLM-generated score and the initial keyword-based priority. We retain candidates that exceed a predefined absolute score threshold and rank within the top 5.