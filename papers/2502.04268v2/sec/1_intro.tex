\vspace{-6pt}
\section{Introduction}
\label{sec:intro}

Emerged as an essential task in computer vision, oriented object detection (OOD) has become a prominent demand in autonomous driving \cite{feng2021deep}, aerial images \cite{xia2018dota, liu2017hrsc, yang2018automatic, yang2022arbitrary, fu2020rotation}, scene text \cite{liao2018rotation, liu2018fots, zhou2017east}, retail scenes \cite{goldman2019precise, pan2020dynamic}, industrial inspection \cite{liu2020data, wu2022pcbnet}, and more.

\begin{figure}[t!]
\setlength{\abovecaptionskip}{1.2mm}
\centering
\includegraphics[width=\linewidth]{figs/intro.pdf}
\caption{Related methods, their principles for knowledge mining, whether using additional priors, and performance on DOTA-v1.0.}
\label{fig:intro}
\vspace{-6pt}
\end{figure}

Manual annotations are essential to teach the detector new concepts of visual objects. Early research is often supervised by rotated bounding boxes (RBoxes), where annotations align with the desired output. While this approach has demonstrated promising results, RBox labels are considerably expensive. The cost of annotating each RBox is approximately 36.5\% higher than a horizontal bounding box (HBox) and 104.8\% higher than a point \cite{yu2024point2rbox}. This highlights the importance of utilizing coarser labels for weakly-supervised oriented detection. Recent advancements in HBox-supervised OOD, particularly with H2RBox \cite{yang2023h2rbox} and H2RBox-v2 \cite{yu2023h2rboxv2}, have shown promise in bridging the gap between HBox- and RBox-supervised methods, thereby lessening the dependence on labor-intensive RBox labeling. 

\begin{figure*}[t!]
\setlength{\abovecaptionskip}{1.2mm}
\centering
\includegraphics[width=0.96\linewidth]{figs/vis.pdf}
\caption{Visual comparisons with state-of-the-art methods including: Point2Mask (2023) \cite{li2023point2mask}, PointOBB (2024) \cite{luo2024pointobb}, PointOBB-v2 (2025) \cite{ren2024pointobbv2}, PointOBB-v3 (2025) \cite{zhang2025pointobbv3}, and Point2RBox (2024) \cite{yu2024point2rbox}. The boxes detected by our method (last row) wrap the objects more tightly.}
\label{fig:vis}
\vspace{-6pt}
\end{figure*}

Following HBox-supervised methods, the more challenging point-supervised OOD opens up a new avenue. Several innovative approaches have emerged in the past year (see Fig. \ref{fig:intro}):
\textbf{1) Point-prompt OOD.} P2RBox \citep{cao2023p2rbox}, PMHO \citep{zhang2024pmho}, and PointSAM \citep{liu2024pointsam} employ the zero-shot ability of SAM \citep{kirillov2023segment}.
\textbf{2) Pseudo generation.} PointOBB \cite{luo2024pointobb} and its v2/v3 version \cite{ren2024pointobbv2, zhang2025pointobbv3} use multiple instance learning and class probability map for RBox generation. 
\textbf{3) Knowledge combination.} Point2RBox \cite{yu2024point2rbox} learns from one-shot examples.
However, existing methods overlook the spatial relationships between objects. This brings us to the motivation of this paper.

\textbf{Motivation.} While point-supervised OOD has gained attention, the utilization of relationships among instances remains absent in the literature. For example, the arrangement of vehicles in a parking lot can serve as effective constraints for learning their size and orientation. This approach may yield valuable insights into point-supervised OOD, particularly in densely packed scenes where current methods face significant challenges. Can we leverage the spatial layout of objects to enhance point-supervised OOD? In this paper, we dive into this idea and seek to answer this question.

\textbf{Highlights.} \textbf{1)} Point2RBox-v2 is proposed for point-supervised OOD, advancing the state of the art as displayed in Fig.~\ref{fig:vis} and Tables \ref{tab:exp_dota}-\ref{tab:exp_other}. 
\textbf{2)} We propose novel and elegant losses to enforce constraints from the spatial layout among instances based on Gaussian overlap and Voronoi tessellation \cite{aurenhammer1991voronoi}. 
\textbf{3)} Other modules are devised (i.e. edge loss, consistency loss, copy-paste) to further enhance the method.

\textbf{Contributions.} \textbf{1)} To our best knowledge, this work is the first attempt to learn point-supervised OOD from the layout among objects, where we propose novel principles based on Gaussian overlap and Voronoi tessellation.
\textbf{2)} The training pipeline and detailed implementation are elucidated, with necessary modules (i.e. edge loss, consistency loss, copy-paste) incorporated. The source code will be made publicly available.
\textbf{3)} Extensive experiments demonstrate that leveraging the spatial layout of instances can significantly advance the state of the art, surpassing other alternatives in accuracy.
