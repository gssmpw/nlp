@inproceedings{abbasi2024deciphering,
  title={Deciphering the Role of Representation Disentanglement: Investigating Compositional Generalization in CLIP Models},
  author={Abbasi, Reza and Rohban, Mohammad Hossein and Baghshah, Mahdieh Soleymani},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2024}
}

@article{berlot2023attribute,
  title={Attribute Diversity Determines the Systematicity Gap in VQA},
  author={Berlot-Attwell, Ian and Carrell, A Michael and Agrawal, Kumar Krishna and Sharma, Yash and Saphra, Naomi},
  journal={arXiv preprint arXiv:2311.08695},
  year={2023}
}

@article{fodor1988connectionism,
  title={Connectionism and cognitive architecture: A critical analysis},
  author={Fodor, Jerry A and Pylyshyn, Zenon W},
  journal={Cognition},
  volume={28},
  number={1-2},
  pages={3--71},
  year={1988},
  publisher={Elsevier}
}

@article{hsieh2023sugarcrepe,
  title={SugarCrepe: Fixing Hackable Benchmarks for Vision-Language Compositionality},
  author={Hsieh, Cheng-Yu and Zhang, Jieyu and Ma, Zixian and Kembhavi, Aniruddha and Krishna, Ranjay},
  journal={arXiv preprint arXiv:2306.14610},
  year={2023}
}

@article{hupkes2020compositionality,
  title={Compositionality decomposed: How do neural networks generalise?},
  author={Hupkes, Dieuwke and Dankers, Verna and Mul, Mathijs and Bruni, Elia},
  journal={Journal of Artificial Intelligence Research},
  volume={67},
  pages={757--795},
  year={2020}
}

@article{jung2024learning,
  title={Learning to Compose: Improving Object Centric Learning by Injecting Compositionality},
  author={Jung, Whie and Yoo, Jaehoon and Ahn, Sungjin and Hong, Seunghoon},
  journal={arXiv preprint arXiv:2405.00646},
  year={2024}
}

@inproceedings{kim2020cogs,
  title={COGS: A compositional generalization challenge based on semantic interpretation},
  author={Kim, Najoung and Linzen, Tal},
  booktitle={Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={9087--9105},
  year={2020}
}

@inproceedings{lake2018generalization,
  title={Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks},
  author={Lake, Brenden and Baroni, Marco},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2018}
}

@article{lake2023human,
  title={Human-like systematic generalization through a meta-learning neural network},
  author={Lake, Brenden M and Baroni, Marco},
  journal={Nature},
  volume={623},
  number={7985},
  pages={115--121},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{lewis2022does,
  title={Does clip bind concepts? probing compositionality in large image models},
  author={Lewis, Martha and Nayak, Nihal V and Yu, Peilin and Yu, Qinan and Merullo, Jack and Bach, Stephen H and Pavlick, Ellie},
  journal={European Chapter of the Association for Computational Linguistics (EACL)},
  year={2024}
}

@inproceedings{ma2023crepe,
  title={Crepe: Can vision-language foundation models reason compositionally?},
  author={Ma, Zixian and Hong, Jerry and Gul, Mustafa Omer and Gandhi, Mona and Gao, Irena and Krishna, Ranjay},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10910--10921},
  year={2023}
}

@inproceedings{mayilvahanan2024search,
  title={In Search of Forgotten Domain Generalization},
  author={Mayilvahanan, Prasanna and Zimmermann, Roland S and Wiedemer, Thadd{\"a}us and Rusak, Evgenia and Juhos, Attila and Bethge, Matthias and Brendel, Wieland},
  booktitle={ICML 2024 Workshop on Foundation Models in the Wild},
  year={2024}
}

@inproceedings{montero2021role,
  title={The role of disentanglement in generalisation},
  author={Montero, Milton Llera and Ludwig, Casimir JH and Costa, Rui Ponte and Malhotra, Gaurav and Bowers, Jeffrey},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@inproceedings{monteroLostLatentSpace2022,
  title = {Lost in {{Latent Space}}: {{Examining}} Failures of Disentangled Models at Combinatorial Generalisation},
  shorttitle = {Lost in {{Latent Space}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Montero, Milton L. and Bowers, Jeffrey and Costa, Rui Ponte and Ludwig, Casimir JH and Malhotra, Gaurav},
  year = {2022},
  month = oct,
  urldate = {2022-12-19},
  abstract = {Recent research has shown that generative models with highly disentangled representations fail to generalise to unseen combination of generative factor values. These findings contradict earlier research which showed improved performance in out-of-training distribution settings when compared to entangled representations. Additionally, it is not clear if the reported failures are due to (a) encoders failing to map novel combinations to the proper regions of the latent space, or (b) novel combinations being mapped correctly but the decoder is unable to render the correct output for the unseen combinations. We investigate these alternatives by testing several models on a range of datasets and training settings. We find that (i) when models fail, their encoders also fail to map unseen combinations to correct regions of the latent space and (ii) when models succeed, it is either because the test conditions do not exclude enough examples, or because excluded cases involve combinations of object properties with it's shape. We argue that to generalise properly, models not only need to capture factors of variation, but also understand how to invert the process that causes the visual stimulus.},
  langid = {english},
}

@article{okawaCompositionalAbilitiesEmerge2023,
  title = {Compositional {{Abilities Emerge Multiplicatively}}: {{Exploring Diffusion Models}} on a {{Synthetic Task}}},
  shorttitle = {Compositional {{Abilities Emerge Multiplicatively}}},
  author = {Okawa, Maya and Lubana, Ekdeep Singh and Dick, Robert P. and Tanaka, Hidenori},
  year = {2023},
  month = jun,
  urldate = {2024-01-11},
  abstract = {Modern generative models exhibit unprecedented capabilities to generate extremely realistic data. However, given the inherent compositionality of real world, reliable use of these models in practical applications mandates they exhibit the ability to compose their capabilities, generating and reasoning over entirely novel samples never seen in the training distribution. Prior work demonstrates recent vision diffusion models exhibit intriguing compositional generalization abilities, but also fail rather unpredictably. What are the reasons underlying this behavior? Which concepts does the model generally find difficult to compose to form novel data? To address these questions, we perform a controlled study of compositional generalization in conditional diffusion models in a synthetic setting, varying different attributes of the training data and measuring the model's ability to generate samples out-of-distribution. Our results show that: (i) the compositional structure of the data-generating process governs the order in which capabilities and an ability to compose them emerges; (ii) learning individual concepts impacts performance on compositional tasks, multiplicatively explaining sudden emergence; and (iii) learning and composing capabilities is difficult under correlations. We hope our study inspires further grounded research on understanding capabilities and compositionality in generative models from a data-centric perspective.},
  langid = {english},
}

@article{ray2024cola,
  title={Cola: A benchmark for compositional text-to-image retrieval},
  author={Ray, Arijit and Radenovic, Filip and Dubey, Abhimanyu and Plummer, Bryan and Krishna, Ranjay and Saenko, Kate},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{schott2022visual,
  title={Visual Representation Learning Does Not Generalize Strongly Within the Same Domain},
  author={Schott, Lukas and Von K{\"u}gelgen, Julius and Tr{\"a}uble, Frederik and Gehler, Peter Vincent and Russell, Chris and Bethge, Matthias and Sch{\"o}lkopf, Bernhard and Locatello, Francesco and Brendel, Wieland},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@inproceedings{sun-etal-2023-validity,
    title = "The Validity of Evaluation Results: Assessing Concurrence Across Compositionality Benchmarks",
    author = "Sun, Kaiser  and
      Williams, Adina  and
      Hupkes, Dieuwke",
    editor = "Jiang, Jing  and
      Reitter, David  and
      Deng, Shumin",
    booktitle = "Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL)",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.conll-1.19",
    doi = "10.18653/v1/2023.conll-1.19",
    pages = "274--293",
    abstract = "NLP models have progressed drastically in recent years, according to numerous datasets proposed to evaluate performance. Questions remain, however, about how particular dataset design choices may impact the conclusions we draw about model capabilities. In this work, we investigate this question in the domain of compositional generalization. We examine the performance of six modeling approaches across 4 datasets, split according to 8 compositional splitting strategies, ranking models by 18 compositional generalization splits in total. Our results show that: i) the datasets, although all designed to evaluate compositional generalization, rank modeling approaches differently; ii) datasets generated by humans align better with each other than with synthetic datasets, or than the latter among themselves; iii) generally, whether datasets are sampled from the same source is more predictive of the resulting model ranking than whether they maintain the same interpretation of compositionality; and iv) specific lexical items in dataset impacts the measurement consistency. Overall, our results demonstrate that much work remains to be done when it comes to assessing whether popular evaluation datasets measure what they intend to measure, and suggests that elucidating more rigorous standards for establishing the validity of evaluation sets could benefit the field.",
}

@inproceedings{thrush2022winoground,
  title={Winoground: Probing vision and language models for visio-linguistic compositionality},
  author={Thrush, Tristan and Jiang, Ryan and Bartolo, Max and Singh, Amanpreet and Williams, Adina and Kiela, Douwe and Ross, Candace},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@misc{wangEnhancingCompositionalGeneralization2024,
  title = {Enhancing {{Compositional Generalization}} via {{Compositional Feature Alignment}}},
  author = {Wang, Haoxiang and Si, Haozhe and Shao, Huajie and Zhao, Han},
  year = {2024},
  month = feb,
  number = {arXiv:2402.02851},
  eprint = {2402.02851},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.02851},
  urldate = {2024-02-12},
  abstract = {Real-world applications of machine learning models often confront data distribution shifts, wherein discrepancies exist between the training and test data distributions. In the common multi-domain multi-class setup, as the number of classes and domains scales up, it becomes infeasible to gather training data for every domain-class combination. This challenge naturally leads the quest for models with Compositional Generalization (CG) ability, where models can generalize to unseen domain-class combinations. To delve into the CG challenge, we develop CG-Bench, a suite of CG benchmarks derived from existing real-world image datasets, and observe that the prevalent pretraining-finetuning paradigm on foundational models, such as CLIP and DINOv2, struggles with the challenge. To address this challenge, we propose Compositional Feature Alignment (CFA), a simple two-stage finetuning technique that i) learns two orthogonal linear heads on a pretrained encoder with respect to class and domain labels, and ii) fine-tunes the encoder with the newly learned head frozen. We theoretically and empirically justify that CFA encourages compositional feature learning of pretrained models. We further conduct extensive experiments on CG-Bench for CLIP and DINOv2, two powerful pretrained vision foundation models. Experiment results show that CFA outperforms common finetuning techniques in compositional generalization, corroborating CFA's efficacy in compositional feature learning.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
}

@inproceedings{wiedemer2023compositional,
 author = {Wiedemer, Thadd\"{a}us and Mayilvahanan, Prasanna and Bethge, Matthias and Brendel, Wieland},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {6941--6960},
 publisher = {Curran Associates, Inc.},
 title = {Compositional Generalization from First Principles},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/15f6a10899f557ce53fe39939af6f930-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}

@article{zhao2022vl,
  title={Vl-checklist: Evaluating pre-trained vision-language models with objects, attributes and relations},
  author={Zhao, Tiancheng and Zhang, Tianqi and Zhu, Mingwei and Shen, Haozhan and Lee, Kyusong and Lu, Xiaopeng and Yin, Jianwei},
  journal={arXiv preprint arXiv:2207.00221},
  year={2022}
}

