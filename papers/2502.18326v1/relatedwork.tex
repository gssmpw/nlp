\section{Related Work}
\label{sec:related}

\paragraph{Theoretical Works \& Synthetic Data}
A growing body of works~\citep{montero2021role,monteroLostLatentSpace2022,schott2022visual,lewis2022does,wiedemer2023compositional,wiedemer2024provable,okawaCompositionalAbilitiesEmerge2023, jung2024learning} provides significant theoretical understanding of compositional generalization results in the vision domain.
Similar works exist for compositionally in language~\citep{fodor1988connectionism,hupkes2020compositionality,berlot2023attribute}, often under the more specific term \emph{systematicity}~\citep{fodor1988connectionism,hupkes2020compositionality,berlot2023attribute}.
In the language domain, promising progress has been made~\citep{lake2023human}, but results in both domains nonetheless remain confined to synthetic datasets~\citep{lake2018generalization,kim2020cogs}l; \citet{sun-etal-2023-validity} actively questions the transferability of insights to real-world data. In contrast, our work analyzes compositional generalization using real-world retrieval datasets.

\paragraph{VLM Benchmarks \& Contamination}
Several compositionality benchmarks have been proposed for VLMs~\citep{thrush2022winoground, lewis2022does, zhao2022vl, yuksekgonul2023when, ma2023crepe, hsieh2023sugarcrepe, ray2024cola, wangEnhancingCompositionalGeneralization2024, abbasi2024deciphering}. However, these studies do not consider the overlap of concept combinations with web-scale pretraining data.
Data contamination of this kind has been shown to significantly impact CLIP's zero-shot performance~\cite{mayilvahanan2024search}, making it difficult to distinguish between genuine generalization and mere memorization.
A notable exception is \citet{abbasi2024deciphering}, who generate test images of novel attribute-object pairs, but as a result, their benchmark resorts to synthetic data. Our work controls for data contamination by only considering combinations that do not occur in the pretraining data but do occur in real-world benchmarks.