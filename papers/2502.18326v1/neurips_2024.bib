@article{antoniades2024generalization,
  title={Generalization vs Memorization: Tracing Language Models' Capabilities Back to Pretraining Data},
  author={Antoniades, Antonis and Wang, Xinyi and Elazar, Yanai and Amayuelas, Alfonso and Albalak, Alon and Zhang, Kexun and Wang, William Yang},
  journal={arXiv preprint arXiv:2407.14985},
  year={2024}
}

@article{sauer2023adversarial,
  title={Adversarial diffusion distillation},
  author={Sauer, Axel and Lorenz, Dominik and Blattmann, Andreas and Rombach, Robin},
  journal={arXiv preprint arXiv:2311.17042},
  year={2023}
}

@article{lake2023human,
  title={Human-like systematic generalization through a meta-learning neural network},
  author={Lake, Brenden M and Baroni, Marco},
  journal={Nature},
  volume={623},
  number={7985},
  pages={115--121},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{kim2020cogs,
  title={COGS: A compositional generalization challenge based on semantic interpretation},
  author={Kim, Najoung and Linzen, Tal},
  booktitle={Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={9087--9105},
  year={2020}
}

@inproceedings{thrushWinogroundProbingVision2022,
  title = {Winoground: {{Probing Vision}} and {{Language Models}} for {{Visio-Linguistic Compositionality}}},
  shorttitle = {Winoground},
  booktitle = {2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Thrush, Tristan and Jiang, Ryan and Bartolo, Max and Singh, Amanpreet and Williams, Adina and Kiela, Douwe and Ross, Candace},
  year = {2022},
  month = jun,
  pages = {5228--5238},
  publisher = {IEEE},
  address = {New Orleans, LA, USA},
  doi = {10.1109/CVPR52688.2022.00517},
  urldate = {2024-01-12},
  abstract = {We present a novel task and dataset for evaluating the ability of vision and language models to conduct visio-linguistic compositional reasoning, which we call Winoground. Given two images and two captions, the goal is to match them correctly---but crucially, both captions contain a completely identical set of words, only in a different order. The dataset was carefully hand-curated by expert annotators and is labeled with a rich set of fine-grained tags to assist in analyzing model performance. We probe a diverse range of state-of-the-art vision and language models and find that, surprisingly, none of them do much better than chance. Evidently, these models are not as skilled at visio-linguistic compositional reasoning as we might have hoped. We perform an extensive analysis to obtain insights into how future work might try to mitigate these models' shortcomings. We aim for Winoground to serve as a useful evaluation set for advancing the state of the art and driving further progress in the field. The dataset is available at https://huggingface.co/datasets/facebook/winoground.},
  isbn = {978-1-66546-946-3},
  langid = {english},
}

@article{lewis2022does,
  title={Does clip bind concepts? probing compositionality in large image models},
  author={Lewis, Martha and Nayak, Nihal V and Yu, Peilin and Yu, Qinan and Merullo, Jack and Bach, Stephen H and Pavlick, Ellie},
  journal={European Chapter of the Association for Computational Linguistics (EACL)},
  year={2024}
}

@book{young1975technique,
  title={A technique for producing ideas},
  author={Young, James Webb and Reinhard, Keith},
  year={1975},
  publisher={NTC Business Books}
}

@article{hammoud2024synthclip,
  title={SynthCLIP: Are We Ready for a Fully Synthetic CLIP Training?},
  author={Hammoud, Hasan Abed Al Kader and Itani, Hani and Pizzati, Fabio and Torr, Philip and Bibi, Adel and Ghanem, Bernard},
  journal={arXiv preprint arXiv:2402.01832},
  year={2024}
}

@inproceedings{montero2021role,
  title={The role of disentanglement in generalisation},
  author={Montero, Milton Llera and Ludwig, Casimir JH and Costa, Rui Ponte and Malhotra, Gaurav and Bowers, Jeffrey},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@inproceedings{schott2022visual,
  title={Visual Representation Learning Does Not Generalize Strongly Within the Same Domain},
  author={Schott, Lukas and Von K{\"u}gelgen, Julius and Tr{\"a}uble, Frederik and Gehler, Peter Vincent and Russell, Chris and Bethge, Matthias and Sch{\"o}lkopf, Bernhard and Locatello, Francesco and Brendel, Wieland},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@inproceedings{sauer2021counterfactual,
  title={Counterfactual Generative Networks},
  author={Sauer, Axel and Geiger, Andreas},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{ray2024cola,
  title={Cola: A benchmark for compositional text-to-image retrieval},
  author={Ray, Arijit and Radenovic, Filip and Dubey, Abhimanyu and Plummer, Bryan and Krishna, Ranjay and Saenko, Kate},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{zhao2022vl,
  title={Vl-checklist: Evaluating pre-trained vision-language models with objects, attributes and relations},
  author={Zhao, Tiancheng and Zhang, Tianqi and Zhu, Mingwei and Shen, Haozhan and Lee, Kyusong and Lu, Xiaopeng and Yin, Jianwei},
  journal={arXiv preprint arXiv:2207.00221},
  year={2022}
}

@article{doveh2023dense,
  title={Dense and aligned captions (dac) promote compositional reasoning in vl models},
  author={Doveh, Sivan and Arbelle, Assaf and Harary, Sivan and Herzig, Roei and Kim, Donghyun and Cascante-Bonilla, Paola and Alfassy, Amit and Panda, Rameswar and Giryes, Raja and Feris, Rogerio and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@article{nulli2024context,
  title={In-Context Learning Improves Compositional Understanding of Vision-Language Models},
  author={Nulli, Matteo and Ibrahimi, Anesa and Pal, Avik and Lee, Hoshe and Najdenkoska, Ivona},
  journal={arXiv preprint arXiv:2407.15487},
  year={2024}
}

@inproceedings{ma2023crepe,
  title={Crepe: Can vision-language foundation models reason compositionally?},
  author={Ma, Zixian and Hong, Jerry and Gul, Mustafa Omer and Gandhi, Mona and Gao, Irena and Krishna, Ranjay},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10910--10921},
  year={2023}
}

@misc{hsiehSugarCrepeFixingHackable2023,
  title = {{{SugarCrepe}}: {{Fixing Hackable Benchmarks}} for {{Vision-Language Compositionality}}},
  shorttitle = {{{SugarCrepe}}},
  author = {Hsieh, Cheng-Yu and Zhang, Jieyu and Ma, Zixian and Kembhavi, Aniruddha and Krishna, Ranjay},
  year = {2023},
  month = jun,
  number = {arXiv:2306.14610},
  eprint = {2306.14610},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2306.14610},
  urldate = {2024-01-11},
  abstract = {In the last year alone, a surge of new benchmarks to measure compositional understanding of vision-language models have permeated the machine learning ecosystem. Given an image, these benchmarks probe a model's ability to identify its associated caption amongst a set of compositional distractors. Surprisingly, we find significant biases in all these benchmarks rendering them hackable. This hackability is so dire that blind models with no access to the image outperform state-of-the-art vision-language models. To remedy this rampant vulnerability, we introduce SugarCrepe, a new benchmark for vision-language compositionality evaluation. We employ large language models, instead of rule-based templates used in previous benchmarks, to generate fluent and sensical hard negatives, and utilize an adversarial refinement mechanism to maximally reduce biases. We re-evaluate state-of-the-art models and recently proposed compositionality inducing strategies, and find that their improvements were hugely overestimated, suggesting that more innovation is needed in this important direction. We release SugarCrepe and the code for evaluation at: https://github.com/RAIVNLab/sugar-crepe.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
}

@misc{wangEnhancingCompositionalGeneralization2024,
  title = {Enhancing {{Compositional Generalization}} via {{Compositional Feature Alignment}}},
  author = {Wang, Haoxiang and Si, Haozhe and Shao, Huajie and Zhao, Han},
  year = {2024},
  month = feb,
  number = {arXiv:2402.02851},
  eprint = {2402.02851},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.02851},
  urldate = {2024-02-12},
  abstract = {Real-world applications of machine learning models often confront data distribution shifts, wherein discrepancies exist between the training and test data distributions. In the common multi-domain multi-class setup, as the number of classes and domains scales up, it becomes infeasible to gather training data for every domain-class combination. This challenge naturally leads the quest for models with Compositional Generalization (CG) ability, where models can generalize to unseen domain-class combinations. To delve into the CG challenge, we develop CG-Bench, a suite of CG benchmarks derived from existing real-world image datasets, and observe that the prevalent pretraining-finetuning paradigm on foundational models, such as CLIP and DINOv2, struggles with the challenge. To address this challenge, we propose Compositional Feature Alignment (CFA), a simple two-stage finetuning technique that i) learns two orthogonal linear heads on a pretrained encoder with respect to class and domain labels, and ii) fine-tunes the encoder with the newly learned head frozen. We theoretically and empirically justify that CFA encourages compositional feature learning of pretrained models. We further conduct extensive experiments on CG-Bench for CLIP and DINOv2, two powerful pretrained vision foundation models. Experiment results show that CFA outperforms common finetuning techniques in compositional generalization, corroborating CFA's efficacy in compositional feature learning.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
}

@inproceedings{abbasi2024deciphering,
  title={Deciphering the Role of Representation Disentanglement: Investigating Compositional Generalization in CLIP Models},
  author={Abbasi, Reza and Rohban, Mohammad Hossein and Baghshah, Mahdieh Soleymani},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2024}
}

@misc{bordes2023pug,
      title={PUG: Photorealistic and Semantically Controllable Synthetic Data for Representation Learning}, 
      author={Florian Bordes and Shashank Shekhar and Mark Ibrahim and Diane Bouchacourt and Pascal Vincent and Ari S. Morcos},
      year={2023},
      eprint={2308.03977},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{sun-etal-2023-validity,
    title = "The Validity of Evaluation Results: Assessing Concurrence Across Compositionality Benchmarks",
    author = "Sun, Kaiser  and
      Williams, Adina  and
      Hupkes, Dieuwke",
    editor = "Jiang, Jing  and
      Reitter, David  and
      Deng, Shumin",
    booktitle = "Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL)",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.conll-1.19",
    doi = "10.18653/v1/2023.conll-1.19",
    pages = "274--293",
    abstract = "NLP models have progressed drastically in recent years, according to numerous datasets proposed to evaluate performance. Questions remain, however, about how particular dataset design choices may impact the conclusions we draw about model capabilities. In this work, we investigate this question in the domain of compositional generalization. We examine the performance of six modeling approaches across 4 datasets, split according to 8 compositional splitting strategies, ranking models by 18 compositional generalization splits in total. Our results show that: i) the datasets, although all designed to evaluate compositional generalization, rank modeling approaches differently; ii) datasets generated by humans align better with each other than with synthetic datasets, or than the latter among themselves; iii) generally, whether datasets are sampled from the same source is more predictive of the resulting model ranking than whether they maintain the same interpretation of compositionality; and iv) specific lexical items in dataset impacts the measurement consistency. Overall, our results demonstrate that much work remains to be done when it comes to assessing whether popular evaluation datasets measure what they intend to measure, and suggests that elucidating more rigorous standards for establishing the validity of evaluation sets could benefit the field.",
}

@inproceedings{wiedemer2023compositional,
 author = {Wiedemer, Thadd\"{a}us and Mayilvahanan, Prasanna and Bethge, Matthias and Brendel, Wieland},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {6941--6960},
 publisher = {Curran Associates, Inc.},
 title = {Compositional Generalization from First Principles},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/15f6a10899f557ce53fe39939af6f930-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2021}
}

@inproceedings{
wiedemer2024provable,
title={Provable Compositional Generalization for Object-Centric Learning},
author={Thadd{\"a}us Wiedemer and Jack Brady and Alexander Panfilov and Attila Juhos and Matthias Bethge and Wieland Brendel},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=7VPTUWkiDQ}
}

@inproceedings{mayilvahanan2024search,
  title={In Search of Forgotten Domain Generalization},
  author={Mayilvahanan, Prasanna and Zimmermann, Roland S and Wiedemer, Thadd{\"a}us and Rusak, Evgenia and Juhos, Attila and Bethge, Matthias and Brendel, Wieland},
  booktitle={ICML 2024 Workshop on Foundation Models in the Wild},
  year={2024}
}

@inproceedings{zhen2019deep,
  title={Deep supervised cross-modal retrieval},
  author={Zhen, Liangli and Hu, Peng and Wang, Xu and Peng, Dezhong},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019}
}

@article{wang2016comprehensive,
  title={A comprehensive survey on cross-modal retrieval},
  author={Wang, Kaiye and Yin, Qiyue and Wang, Wei and Wu, Shu and Wang, Liang},
  journal={arXiv preprint arXiv:1607.06215},
  year={2016}
}

@article{udandarao2020cobra,
  title={Cobra: Contrastive bi-modal representation algorithm},
  author={Udandarao, Vishaal and Maiti, Abhishek and Srivatsav, Deepak and Vyalla, Suryatej Reddy and Yin, Yifang and Shah, Rajiv Ratn},
  journal={arXiv preprint arXiv:2005.03687},
  year={2020}
}

@inproceedings{zhai2022lit,
  title={Lit: Zero-shot transfer with locked-image text tuning},
  author={Zhai, Xiaohua and Wang, Xiao and Mustafa, Basil and Steiner, Andreas and Keysers, Daniel and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2021}
}

@article{pham2023combined,
  title={Combined scaling for zero-shot transfer learning},
  author={Pham, Hieu and Dai, Zihang and Ghiasi, Golnaz and Kawaguchi, Kenji and Liu, Hanxiao and Yu, Adams Wei and Yu, Jiahui and Chen, Yi-Ting and Luong, Minh-Thang and Wu, Yonghui and others},
  journal={Neurocomputing},
  volume={555},
  pages={126658},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{zhai2023sigmoid,
  title={Sigmoid loss for language image pre-training},
  author={Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={11975--11986},
  year={2023}
}

@article{hossain2019comprehensive,
  title={A comprehensive survey of deep learning for image captioning},
  author={Hossain, MD Zakir and Sohel, Ferdous and Shiratuddin, Mohd Fairuz and Laga, Hamid},
  journal={ACM Computing Surveys (CsUR)},
  volume={51},
  number={6},
  pages={1--36},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@article{vinyals2016show,
  title={Show and tell: Lessons learned from the 2015 mscoco image captioning challenge},
  author={Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={39},
  number={4},
  pages={652--663},
  year={2016},
  publisher={IEEE}
}

@inproceedings{you2016image,
  title={Image captioning with semantic attention},
  author={You, Quanzeng and Jin, Hailin and Wang, Zhaowen and Fang, Chen and Luo, Jiebo},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016}
}

@article{herdade2019image,
  title={Image captioning: Transforming objects into words},
  author={Herdade, Simao and Kappeler, Armin and Boakye, Kofi and Soares, Joao},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{stefanini2022show,
  title={From show to tell: A survey on deep learning-based image captioning},
  author={Stefanini, Matteo and Cornia, Marcella and Baraldi, Lorenzo and Cascianelli, Silvia and Fiameni, Giuseppe and Cucchiara, Rita},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={45},
  number={1},
  pages={539--559},
  year={2022},
  publisher={IEEE}
}

@article{yu2022coca,
  title={Coca: Contrastive captioners are image-text foundation models},
  author={Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  journal={arXiv preprint arXiv:2205.01917},
  year={2022}
}

@article{dai2017contrastive,
  title={Contrastive learning for image captioning},
  author={Dai, Bo and Lin, Dahua},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{antol2015vqa,
  title={Vqa: Visual question answering},
  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2015}
}

@article{wu2017visual,
  title={Visual question answering: A survey of methods and datasets},
  author={Wu, Qi and Teney, Damien and Wang, Peng and Shen, Chunhua and Dick, Anthony and Van Den Hengel, Anton},
  journal={Computer Vision and Image Understanding},
  year={2017}
}

@article{kafle2017visual,
  title={Visual question answering: Datasets, algorithms, and future challenges},
  author={Kafle, Kushal and Kanan, Christopher},
  journal={Computer Vision and Image Understanding},
  year={2017}
}

@article{zhou2015simple,
  title={Simple baseline for visual question answering},
  author={Zhou, Bolei and Tian, Yuandong and Sukhbaatar, Sainbayar and Szlam, Arthur and Fergus, Rob},
  journal={arXiv preprint arXiv:1512.02167},
  year={2015}
}

@article{li2019controllable,
  title={Controllable text-to-image generation},
  author={Li, Bowen and Qi, Xiaojuan and Lukasiewicz, Thomas and Torr, Philip},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2021}
}

@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  volume={1},
  number={2},
  pages={3},
  year={2022}
}

@inproceedings{zhang2021cross,
  title={Cross-modal contrastive learning for text-to-image generation},
  author={Zhang, Han and Koh, Jing Yu and Baldridge, Jason and Lee, Honglak and Yang, Yinfei},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}

@inproceedings{reed2016generative,
  title={Generative adversarial text to image synthesis},
  author={Reed, Scott and Akata, Zeynep and Yan, Xinchen and Logeswaran, Lajanugen and Schiele, Bernt and Lee, Honglak},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={1060--1069},
  year={2016},
  organization={PMLR}
}

@article{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  journal={arXiv preprint arXiv:2301.12597},
  year={2023}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@article{awadalla2023openflamingo,
  title={Openflamingo: An open-source framework for training large autoregressive vision-language models},
  author={Awadalla, Anas and Gao, Irena and Gardner, Josh and Hessel, Jack and Hanafy, Yusuf and Zhu, Wanrong and Marathe, Kalyani and Bitton, Yonatan and Gadre, Samir and Sagawa, Shiori and others},
  journal={arXiv preprint arXiv:2308.01390},
  year={2023}
}

@inproceedings{abbas2024effective,
  title={Effective pruning of web-scale datasets based on complexity of concept clusters},
  author={Abbas, Amro and Rusak, Evgenia and Tirumala, Kushal and Brendel, Wieland and Chaudhuri, Kamalika and Morcos, Ari S},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2024}
}

@article{lampert2013attribute,
  title={Attribute-based classification for zero-shot visual object categorization},
  author={Lampert, Christoph H and Nickisch, Hannes and Harmeling, Stefan},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={36},
  number={3},
  pages={453--465},
  year={2013},
  publisher={IEEE}
}

@article{longpre2023pretrainer,
  title={A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, \& Toxicity},
  author={Longpre, Shayne and Yauney, Gregory and Reif, Emily and Lee, Katherine and Roberts, Adam and Zoph, Barret and Zhou, Denny and Wei, Jason and Robinson, Kevin and Mimno, David and others},
  journal={arXiv preprint arXiv:2305.13169},
  year={2023}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={770--778},
  year={2016}
}

@inproceedings{betker2023improving,
  title={Improving image generation with better captions},
  author={Betker, James and Goh, Gabriel and Jing, Li and Brooks, Tim and Wang, Jianfeng and Li, Linjie and Ouyang, Long and Zhuang, Juntang and Lee, Joyce and Guo, Yufei and others},
  booktitle={Computer Science},
  year={2023}
}

@inproceedings{karras2019style,
  title={A style-based generator architecture for generative adversarial networks},
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@article{saharia2022photorealistic,
  title={Photorealistic text-to-image diffusion models with deep language understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={36479--36494},
  year={2022}
}

@article{
yu2022scaling,
title={Scaling Autoregressive Models for Content-Rich Text-to-Image Generation},
author={Jiahui Yu and Yuanzhong Xu and Jing Yu Koh and Thang Luong and Gunjan Baid and Zirui Wang and Vijay Vasudevan and Alexander Ku and Yinfei Yang and Burcu Karagol Ayan and Ben Hutchinson and Wei Han and Zarana Parekh and Xin Li and Han Zhang and Jason Baldridge and Yonghui Wu},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2022},
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2014}
}

@article{young2014image,
  title={From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions},
  author={Young, Peter and Lai, Alice and Hodosh, Micah and Hockenmaier, Julia},
  journal={Transactions of the Association for Computational Linguistics},
  volume={2},
  pages={67--78},
  year={2014},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}



@article{jaiswal2020survey,
  title={A survey on contrastive self-supervised learning},
  author={Jaiswal, Ashish and Babu, Ashwin Ramesh and Zadeh, Mohammad Zaki and Banerjee, Debapriya and Makedon, Fillia},
  journal={Technologies},
  volume={9},
  number={1},
  pages={2},
  year={2020},
  publisher={MDPI}
}

@inproceedings{assran2023self,
  title={Self-supervised learning from images with a joint-embedding predictive architecture},
  author={Assran, Mahmoud and Duval, Quentin and Misra, Ishan and Bojanowski, Piotr and Vincent, Pascal and Rabbat, Michael and LeCun, Yann and Ballas, Nicolas},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}

@inproceedings{goyal2019scaling,
  title={Scaling and benchmarking self-supervised visual representation learning},
  author={Goyal, Priya and Mahajan, Dhruv and Gupta, Abhinav and Misra, Ishan},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2019}
}

@article{oquab2023dinov2,
  title={DINOv2: Learning Robust Visual Features without Supervision},
  author={Oquab, Maxime and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and Vo, Huy V and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and others},
  journal={Transactions on Machine Learning Research},
  year={2023}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

@inproceedings{tay2022ul2,
  title={Ul2: Unifying language learning paradigms},
  author={Tay, Yi and Dehghani, Mostafa and Tran, Vinh Q and Garcia, Xavier and Wei, Jason and Wang, Xuezhi and Chung, Hyung Won and Bahri, Dara and Schuster, Tal and Zheng, Steven and others},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@misc{liu2023hallusionbench,
      title={HallusionBench: You See What You Think? Or You Think What You See? An Image-Context Reasoning Benchmark Challenging for GPT-4V(ision), LLaVA-1.5, and Other Multi-modality Models}, 
      author={Fuxiao Liu and Tianrui Guan and Zongxia Li and Lichang Chen and Yaser Yacoob and Dinesh Manocha and Tianyi Zhou},
      year={2023},
      eprint={2310.14566},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{schottVisualRepresentationLearning2022,
  title = {Visual {{Representation Learning Does Not Generalize Strongly Within}} the {{Same Domain}}},
  author = {Schott, Lukas and {von K{\"u}gelgen}, Julius and Tr{\"a}uble, Frederik and Gehler, Peter and Russell, Chris and Bethge, Matthias and Sch{\"o}lkopf, Bernhard and Locatello, Francesco and Brendel, Wieland},
  year = {2022},
  month = feb,
  journal = {arXiv:2107.08221 [cs]},
  eprint = {2107.08221},
  primaryclass = {cs},
  urldate = {2022-04-11},
  abstract = {An important component for generalization in machine learning is to uncover underlying latent factors of variation as well as the mechanism through which each factor acts in the world. In this paper, we test whether 17 unsupervised, weakly supervised, and fully supervised representation learning approaches correctly infer the generative factors of variation in simple datasets (dSprites, Shapes3D, MPI3D) from controlled environments, and on our contributed CelebGlow dataset. In contrast to prior robustness work that introduces novel factors of variation during test time, such as blur or other (un)structured noise, we here recompose, interpolate, or extrapolate only existing factors of variation from the training data set (e.g., small and medium-sized objects during training and large objects during testing). Models that learn the correct mechanism should be able to generalize to this benchmark. In total, we train and test 2000+ models and observe that all of them struggle to learn the underlying mechanism regardless of supervision signal and architectural bias. Moreover, the generalization capabilities of all tested models drop significantly as we move from artificial datasets towards more realistic real-world datasets. Despite their inability to identify the correct mechanism, the models are quite modular as their ability to infer other in-distribution factors remains fairly stable, providing only a single factor is out-of-distribution. These results point to an important yet understudied problem of learning mechanistic models of observations that can facilitate generalization.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
}

@inproceedings{monteroLostLatentSpace2022,
  title = {Lost in {{Latent Space}}: {{Examining}} Failures of Disentangled Models at Combinatorial Generalisation},
  shorttitle = {Lost in {{Latent Space}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Montero, Milton L. and Bowers, Jeffrey and Costa, Rui Ponte and Ludwig, Casimir JH and Malhotra, Gaurav},
  year = {2022},
  month = oct,
  urldate = {2022-12-19},
  abstract = {Recent research has shown that generative models with highly disentangled representations fail to generalise to unseen combination of generative factor values. These findings contradict earlier research which showed improved performance in out-of-training distribution settings when compared to entangled representations. Additionally, it is not clear if the reported failures are due to (a) encoders failing to map novel combinations to the proper regions of the latent space, or (b) novel combinations being mapped correctly but the decoder is unable to render the correct output for the unseen combinations. We investigate these alternatives by testing several models on a range of datasets and training settings. We find that (i) when models fail, their encoders also fail to map unseen combinations to correct regions of the latent space and (ii) when models succeed, it is either because the test conditions do not exclude enough examples, or because excluded cases involve combinations of object properties with it's shape. We argue that to generalise properly, models not only need to capture factors of variation, but also understand how to invert the process that causes the visual stimulus.},
  langid = {english},
}

@article{okawaCompositionalAbilitiesEmerge2023,
  title = {Compositional {{Abilities Emerge Multiplicatively}}: {{Exploring Diffusion Models}} on a {{Synthetic Task}}},
  shorttitle = {Compositional {{Abilities Emerge Multiplicatively}}},
  author = {Okawa, Maya and Lubana, Ekdeep Singh and Dick, Robert P. and Tanaka, Hidenori},
  year = {2023},
  month = jun,
  urldate = {2024-01-11},
  abstract = {Modern generative models exhibit unprecedented capabilities to generate extremely realistic data. However, given the inherent compositionality of real world, reliable use of these models in practical applications mandates they exhibit the ability to compose their capabilities, generating and reasoning over entirely novel samples never seen in the training distribution. Prior work demonstrates recent vision diffusion models exhibit intriguing compositional generalization abilities, but also fail rather unpredictably. What are the reasons underlying this behavior? Which concepts does the model generally find difficult to compose to form novel data? To address these questions, we perform a controlled study of compositional generalization in conditional diffusion models in a synthetic setting, varying different attributes of the training data and measuring the model's ability to generate samples out-of-distribution. Our results show that: (i) the compositional structure of the data-generating process governs the order in which capabilities and an ability to compose them emerges; (ii) learning individual concepts impacts performance on compositional tasks, multiplicatively explaining sudden emergence; and (iii) learning and composing capabilities is difficult under correlations. We hope our study inspires further grounded research on understanding capabilities and compositionality in generative models from a data-centric perspective.},
  langid = {english},
}

@misc{fradyLearningGeneralizationCompositional2023,
  title = {Learning and Generalization of Compositional Representations of Visual Scenes},
  author = {Frady, E. Paxon and Kent, Spencer and Tran, Quinn and Kanerva, Pentti and Olshausen, Bruno A. and Sommer, Friedrich T.},
  year = {2023},
  month = mar,
  number = {arXiv:2303.13691},
  eprint = {2303.13691},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2303.13691},
  urldate = {2023-03-28},
  abstract = {Complex visual scenes that are composed of multiple objects, each with attributes, such as object name, location, pose, color, etc., are challenging to describe in order to train neural networks. Usually,deep learning networks are trained supervised by categorical scene descriptions. The common categorical description of a scene contains the names of individual objects but lacks information about other attributes. Here, we use distributed representations of object attributes and vector operations in a vector symbolic architecture to create a full compositional description of a scene in a high-dimensional vector. To control the scene composition, we use artificial images composed of multiple, translated and colored MNIST digits. In contrast to learning category labels, here we train deep neural networks to output the full compositional vector description of an input image. The output of the deep network can then be interpreted by a VSA resonator network, to extract object identity or other properties of indiviual objects. We evaluate the performance and generalization properties of the system on randomly generated scenes. Specifically, we show that the network is able to learn the task and generalize to unseen seen digit shapes and scene configurations. Further, the generalisation ability of the trained model is limited. For example, with a gap in the training data, like an object not shown in a particular image location during training, the learning does not automatically fill this gap.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Neural and Evolutionary Computing},
}

@article{jung2024learning,
  title={Learning to Compose: Improving Object Centric Learning by Injecting Compositionality},
  author={Jung, Whie and Yoo, Jaehoon and Ahn, Sungjin and Hong, Seunghoon},
  journal={arXiv preprint arXiv:2405.00646},
  year={2024}
}

@inproceedings{
udandarao2024visual,
title={Visual Data-Type Understanding does not emerge from scaling Vision-Language Models},
author={Vishaal Udandarao and Max F Burg and Samuel Albanie and Matthias Bethge},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024}
}

@article{zhou2023analyzing,
  title={Analyzing and Mitigating Object Hallucination in Large Vision-Language Models},
  author={Zhou, Yiyang and Cui, Chenhang and Yoon, Jaehong and Zhang, Linjun and Deng, Zhun and Finn, Chelsea and Bansal, Mohit and Yao, Huaxiu},
  journal={arXiv preprint arXiv:2310.00754},
  year={2023}
}

@article{tejankar2021fistful,
  title={A fistful of words: Learning transferable visual models from bag-of-words supervision},
  author={Tejankar, Ajinkya and Sanjabi, Maziar and Wu, Bichen and Xie, Saining and Khabsa, Madian and Pirsiavash, Hamed and Firooz, Hamed},
  journal={arXiv preprint arXiv:2112.13884},
  year={2021}
}

@misc{kamath2023text,
      title={Text encoders are performance bottlenecks in contrastive vision-language models}, 
      author={Amita Kamath and Jack Hessel and Kai-Wei Chang},
      year={2023},
      eprint={2305.14897},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{li2023seed,
  title={SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension},
  author={Li, Bohao and Wang, Rui and Wang, Guangzhi and Ge, Yuying and Ge, Yixiao and Shan, Ying},
  journal={arXiv preprint arXiv:2307.16125},
  year={2023}
}

@misc{banerjee2023animalimages,
    author = {Sourav Banerjee},
    title = {Animal Image Dataset: 90 Different Animals},
    year = {2023},
    url = {https://www.kaggle.com/datasets/iamsouravbanerjee/animal-image-dataset-90-different-animals},
    note = {Accessed: 2023-07-10}
}

@article{hendrycks2019benchmarking,
  title={Benchmarking neural network robustness to common corruptions and perturbations},
  author={Hendrycks, Dan and Dietterich, Thomas},
  journal={arXiv preprint arXiv:1903.12261},
  year={2019}
}

@article{wang2019learning,
  title={Learning robust global representations by penalizing local predictive power},
  author={Wang, Haohan and Ge, Songwei and Lipton, Zachary and Xing, Eric P},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{barbu2019objectnet,
  title={Objectnet: A large-scale bias-controlled dataset for pushing the limits of object recognition models},
  author={Barbu, Andrei and Mayo, David and Alverio, Julian and Luo, William and Wang, Christopher and Gutfreund, Dan and Tenenbaum, Josh and Katz, Boris},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{bitton2023breaking,
  title={Breaking common sense: Whoops! a vision-and-language benchmark of synthetic and compositional images},
  author={Bitton-Guetta, Nitzan and Bitton, Yonatan and Hessel, Jack and Schmidt, Ludwig and Elovici, Yuval and Stanovsky, Gabriel and Schwartz, Roy},
  journal={arXiv preprint arXiv:2303.07274},
  year={2023}
}

@article{yarom2023you,
  title={What You See is What You Read? Improving Text-Image Alignment Evaluation},
  author={Yarom, Michal and Bitton, Yonatan and Changpinyo, Soravit and Aharoni, Roee and Herzig, Jonathan and Lang, Oran and Ofek, Eran and Szpektor, Idan},
  journal={arXiv preprint arXiv:2305.10400},
  year={2023}
}

@inproceedings{marathe2023wedge,
  title={WEDGE: A multi-weather autonomous driving dataset built from generative vision-language models},
  author={Marathe, Aboli and Ramanan, Deva and Walambe, Rahee and Kotecha, Ketan},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}


@inproceedings{peng2019moment,
  title={Moment matching for multi-source domain adaptation},
  author={Peng, Xingchao and Bai, Qinxun and Xia, Xide and Huang, Zijun and Saenko, Kate and Wang, Bo},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2019}
}

@inproceedings{li2017deeper,
  title={Deeper, broader and artier domain generalization},
  author={Li, Da and Yang, Yongxin and Song, Yi-Zhe and Hospedales, Timothy M},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2017}
}

@inproceedings{radenovic2023filtering,
  title={Filtering, distillation, and hard negatives for vision-language pre-training},
  author={Radenovic, Filip and Dubey, Abhimanyu and Kadian, Abhishek and Mihaylov, Todor and Vandenhende, Simon and Patel, Yash and Wen, Yi and Ramanathan, Vignesh and Mahajan, Dhruv},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}

@article{yang2023alip,
  title={ALIP: Adaptive Language-Image Pre-training with Synthetic Caption},
  author={Yang, Kaicheng and Deng, Jiankang and An, Xiang and Li, Jiawei and Feng, Ziyong and Guo, Jia and Yang, Jing and Liu, Tongliang},
  journal={arXiv preprint arXiv:2308.08428},
  year={2023}
}

@article{cao2023less,
  title={Less is More: Removing Text-regions Improves CLIP Training Efficiency and Robustness},
  author={Cao, Liangliang and Zhang, Bowen and Chen, Chen and Yang, Yinfei and Du, Xianzhi and Zhang, Wencong and Lu, Zhiyun and Zheng, Yantao},
  journal={arXiv preprint arXiv:2305.05095},
  year={2023}
}

@article{zhu2023multimodal,
  title={Multimodal c4: An open, billion-scale corpus of images interleaved with text},
  author={Zhu, Wanrong and Hessel, Jack and Awadalla, Anas and Gadre, Samir Yitzhak and Dodge, Jesse and Fang, Alex and Yu, Youngjae and Schmidt, Ludwig and Wang, William Yang and Choi, Yejin},
  journal={arXiv preprint arXiv:2304.06939},
  year={2023}
}

@article{laurenccon2023obelisc,
  title={OBELISC: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents},
  author={Lauren{\c{c}}on, Hugo and Saulnier, Lucile and Tronchon, L{\'e}o and Bekman, Stas and Singh, Amanpreet and Lozhkov, Anton and Wang, Thomas and Karamcheti, Siddharth and Rush, Alexander M and Kiela, Douwe and others},
  journal={arXiv preprint arXiv:2306.16527},
  year={2023}
}

@article{wang2023too,
  title={Too Large; Data Reduction for Vision-Language Pre-Training},
  author={Wang, Alex Jinpeng and Lin, Kevin Qinghong and Zhang, David Junhao and Lei, Stan Weixian and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2305.20087},
  year={2023}
}

@article{abbas2023semdedup,
  title={SemDeDup: Data-efficient learning at web-scale through semantic deduplication},
  author={Abbas, Amro and Tirumala, Kushal and Simig, D{\'a}niel and Ganguli, Surya and Morcos, Ari S},
  journal={Advances in Neural Information Processing Systems},
  year={2023}
}

@article{sorscher2022beyond,
  title={Beyond neural scaling laws: beating power law scaling via data pruning},
  author={Sorscher, Ben and Geirhos, Robert and Shekhar, Shashank and Ganguli, Surya and Morcos, Ari},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={19523--19536},
  year={2022}
}
@article{gadre2024datacomp,
  title={Datacomp: In search of the next generation of multimodal datasets},
  author={Gadre, Samir Yitzhak and Ilharco, Gabriel and Fang, Alex and Hayase, Jonathan and Smyrnis, Georgios and Nguyen, Thao and Marten, Ryan and Wortsman, Mitchell and Ghosh, Dhruba and Zhang, Jieyu and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{gadre2023datacomp,
  title={DataComp: In search of the next generation of multimodal datasets},
  author={Gadre, Samir Yitzhak and Ilharco, Gabriel and Fang, Alex and Hayase, Jonathan and Smyrnis, Georgios and Nguyen, Thao and Marten, Ryan and Wortsman, Mitchell and Ghosh, Dhruba and Zhang, Jieyu and others},
  journal={arXiv preprint arXiv:2304.14108},
  year={2023}
}

@article{nguyen2023improving,
  title={Improving Multimodal Datasets with Image Captioning},
  author={Nguyen, Thao and Gadre, Samir Yitzhak and Ilharco, Gabriel and Oh, Sewoong and Schmidt, Ludwig},
  journal={arXiv preprint arXiv:2307.10350},
  year={2023}
}

@article{maini2023t,
  title={T-MARS: Improving Visual Representations by Circumventing Text Feature Learning},
  author={Maini, Pratyush and Goyal, Sachin and Lipton, Zachary C and Kolter, J Zico and Raghunathan, Aditi},
  journal={arXiv preprint arXiv:2307.03132},
  year={2023}
}

@inproceedings{
maini2024tmars,
title={T-{MARS}: Improving Visual Representations by Circumventing Text Feature Learning},
author={Pratyush Maini and Sachin Goyal and Zachary Chase Lipton and J Zico Kolter and Aditi Raghunathan},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024}
}

@article{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={25278--25294},
  year={2022}
}

@inproceedings{cherti2023reproducible,
  title={Reproducible scaling laws for contrastive language-image learning},
  author={Cherti, Mehdi and Beaumont, Romain and Wightman, Ross and Wortsman, Mitchell and Ilharco, Gabriel and Gordon, Cade and Schuhmann, Christoph and Schmidt, Ludwig and Jitsev, Jenia},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}

@article{wang2024variance,
  title={Variance Alignment Score: A Simple But Tough-to-Beat Data Selection Method for Multimodal Contrastive Learning},
  author={Wang, Yiping and Chen, Yifang and Yan, Wendan and Jamieson, Kevin and Du, Simon Shaolei},
  journal={arXiv preprint arXiv:2402.02055},
  year={2024}
}

@inproceedings{birhane2021large,
  title={Large image datasets: A pyrrhic win for computer vision?},
  author={Birhane, Abeba and Prabhu, Vinay Uday},
  booktitle={2021 IEEE Winter Conference on Applications of Computer Vision (WACV)},
  year={2021}
}

@article{yu2023capsfusion,
  title={Capsfusion: Rethinking image-text data at scale},
  author={Yu, Qiying and Sun, Quan and Zhang, Xiaosong and Cui, Yufeng and Zhang, Fan and Wang, Xinlong and Liu, Jingjing},
  journal={arXiv preprint arXiv:2310.20550},
  year={2023}
}

@article{vasu2023mobileclip,
  title={MobileCLIP: Fast Image-Text Models through Multi-Modal Reinforced Training},
  author={Vasu, Pavan Kumar Anasosalu and Pouransari, Hadi and Faghri, Fartash and Vemulapalli, Raviteja and Tuzel, Oncel},
  journal={arXiv preprint arXiv:2311.17049},
  year={2023}
}

@article{chen2023sharegpt4v,
  title={Sharegpt4v: Improving large multi-modal models with better captions},
  author={Chen, Lin and Li, Jisong and Dong, Xiaoyi and Zhang, Pan and He, Conghui and Wang, Jiaqi and Zhao, Feng and Lin, Dahua},
  journal={arXiv preprint arXiv:2311.12793},
  year={2023}
}



@article{lai2023scarcity,
  title={From scarcity to efficiency: Improving clip training via visual-enriched captions},
  author={Lai, Zhengfeng and Zhang, Haotian and Wu, Wentao and Bai, Haoping and Timofeev, Aleksei and Du, Xianzhi and Gan, Zhe and Shan, Jiulong and Chuah, Chen-Nee and Yang, Yinfei and others},
  journal={arXiv preprint arXiv:2310.07699},
  year={2023}
}

@article{nguyen2024improving,
  title={Improving multimodal datasets with image captioning},
  author={Nguyen, Thao and Gadre, Samir Yitzhak and Ilharco, Gabriel and Oh, Sewoong and Schmidt, Ludwig},
  journal={Advances in Neural Information Processing Systems},
  year={2023}
}

@article{ramanujan2024connection,
  title={On the connection between pre-training data diversity and fine-tuning robustness},
  author={Ramanujan, Vivek and Nguyen, Thao and Oh, Sewoong and Farhadi, Ali and Schmidt, Ludwig},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{massiceti2023explaining,
  title={Explaining CLIP's performance disparities on data from blind/low vision users},
  author={Massiceti, Daniela and Longden, Camilla and Slowik, Agnieszka and Wills, Samuel and Grayson, Martin and Morrison, Cecily},
  journal={arXiv preprint arXiv:2311.17315},
  year={2023}
}


@article{zhang2024low,
  title={Low-Resource Vision Challenges for Foundation Models},
  author={Zhang, Yunhua and Doughty, Hazel and Snoek, Cees GM},
  journal={arXiv preprint arXiv:2401.04716},
  year={2024}
}

@article{shao2023quantifying,
  title={Quantifying association capabilities of large language models and its implications on privacy leakage},
  author={Shao, Hanyin and Huang, Jie and Zheng, Shen and Chang, Kevin Chen-Chuan},
  journal={arXiv preprint arXiv:2305.12707},
  year={2023}
}

@inproceedings{razeghi2022snoopy,
  title={Snoopy: An online interface for exploring the effect of pretraining term frequencies on few-shot lm performance},
  author={Razeghi, Yasaman and Mekala, Raja Sekhar Reddy and Logan Iv, Robert L and Gardner, Matt and Singh, Sameer},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  pages={389--395},
  year={2022}
}

@inproceedings{chang2023speak,
  title={Speak, Memory: An Archaeology of Books Known to ChatGPT/GPT-4},
  author={Chang, Kent and Cramer, Mackenzie and Soni, Sandeep and Bamman, David},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={7312--7327},
  year={2023}
}

@article{park2023trak,
  title={Trak: Attributing model behavior at scale},
  author={Park, Sung Min and Georgiev, Kristian and Ilyas, Andrew and Leclerc, Guillaume and Madry, Aleksander},
  journal={arXiv preprint arXiv:2303.14186},
  year={2023}
}

@article{akyurek2022tracing,
  title={Tracing knowledge in language models back to the training data},
  author={Aky{\"u}rek, Ekin and Bolukbasi, Tolga and Liu, Frederick and Xiong, Binbin and Tenney, Ian and Andreas, Jacob and Guu, Kelvin},
  journal={In Findings of the Association for Computational Linguistics: EMNLP },
  year={2022}
}

@article{elazar2022measuring,
  title={Measuring Causal Effects of Data Statistics on Language Model'sFactual'Predictions},
  author={Elazar, Yanai and Kassner, Nora and Ravfogel, Shauli and Feder, Amir and Ravichander, Abhilasha and Mosbach, Marius and Belinkov, Yonatan and Sch{\"u}tze, Hinrich and Goldberg, Yoav},
  journal={arXiv preprint arXiv:2207.14251},
  year={2022}
}

@inproceedings{yauney2023data,
  title={Data Similarity is Not Enough to Explain Language Model Performance},
  author={Yauney, Gregory and Reif, Emily and Mimno, David},
  booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
  year={2023}
}

@article{elazar2023s,
  title={What's In My Big Data?},
  author={Elazar, Yanai and Bhagia, Akshita and Magnusson, Ian and Ravichander, Abhilasha and Schwenk, Dustin and Suhr, Alane and Walsh, Pete and Groeneveld, Dirk and Soldaini, Luca and Singh, Sameer and others},
  journal={arXiv preprint arXiv:2310.20707},
  year={2023}
}

@inproceedings{
elazar2024whats,
title={What's In My Big Data?},
author={Yanai Elazar and Akshita Bhagia and Ian Helgi Magnusson and Abhilasha Ravichander and Dustin Schwenk and Alane Suhr and Evan Pete Walsh and Dirk Groeneveld and Luca Soldaini and Sameer Singh and Hannaneh Hajishirzi and Noah A. Smith and Jesse Dodge},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024}
}


@article{mahmoud2023sieve,
  title={Sieve: Multimodal dataset pruning using image captioning models},
  author={Mahmoud, Anas and Elhoushi, Mostafa and Abbas, Amro and Yang, Yu and Ardalani, Newsha and Leather, Hugh and Morcos, Ari},
  journal={arXiv preprint arXiv:2310.02110},
  year={2023}
}

@article{tirumala2024d4,
  title={D4: Improving llm pretraining via document de-duplication and diversification},
  author={Tirumala, Kushal and Simig, Daniel and Aghajanyan, Armen and Morcos, Ari},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{entezari2023role,
  title={The Role of Pre-training Data in Transfer Learning},
  author={Entezari, Rahim and Wortsman, Mitchell and Saukh, Olga and Shariatnia, M Moein and Sedghi, Hanie and Schmidt, Ludwig},
  journal={arXiv preprint arXiv:2302.13602},
  year={2023}
}

@article{chen2024catastrophic,
  title={On Catastrophic Inheritance of Large Foundation Models},
  author={Chen, Hao and Raj, Bhiksha and Xie, Xing and Wang, Jindong},
  journal={arXiv preprint arXiv:2402.01909},
  year={2024}
}


@article{awadalla2023openflamingo,
  title={Openflamingo: An open-source framework for training large autoregressive vision-language models},
  author={Awadalla, Anas and Gao, Irena and Gardner, Josh and Hessel, Jack and Hanafy, Yusuf and Zhu, Wanrong and Marathe, Kalyani and Bitton, Yonatan and Gadre, Samir and Sagawa, Shiori and others},
  journal={arXiv preprint arXiv:2308.01390},
  year={2023}
}

@article{seshadri2023bias,
  title={The bias amplification paradox in text-to-image generation},
  author={Seshadri, Preethi and Singh, Sameer and Elazar, Yanai},
  journal={arXiv preprint arXiv:2308.00755},
  year={2023}
}

@misc{dailydalle2023,
  author={dailydalle2023},
  title={Instagram account of Daily DALL-E},
  howpublished={\url{https://www.instagram.com/dailydall.e/}},
  note={Accessed: 2024-04-03},
  year={2024}
}

@inproceedings{cho2023dall,
  title={Dall-eval: Probing the reasoning skills and social biases of text-to-image generation models},
  author={Cho, Jaemin and Zala, Abhay and Bansal, Mohit},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3043--3054},
  year={2023}
}

@article{conwell2022testing,
  title={Testing relational understanding in text-guided image generation},
  author={Conwell, Colin and Ullman, Tomer},
  journal={arXiv preprint arXiv:2208.00005},
  year={2022}
}

@misc{byeon2022coyo700m,
  title={Coyo-700m: Image-text pair dataset},
  author={Byeon, M. and Park, B. and Kim, H. and Lee, S. and Baek, W. and Kim, S. C.},
  year={2022},
  howpublished={\url{https://github.com/kakaobrain/coyo-dataset}}
}

@misc{xu2023cit,
      title={CiT: Curation in Training for Effective Vision-Language Data}, 
      author={Hu Xu and Saining Xie and Po-Yao Huang and Licheng Yu and Russell Howes and Gargi Ghosh and Luke Zettlemoyer and Christoph Feichtenhofer},
      year={2023},
      eprint={2301.02241},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{xu2023demystifying,
      title={Demystifying CLIP Data}, 
      author={Hu Xu and Saining Xie and Xiaoqing Ellen Tan and Po-Yao Huang and Russell Howes and Vasu Sharma and Shang-Wen Li and Gargi Ghosh and Luke Zettlemoyer and Christoph Feichtenhofer},
      year={2023},
      eprint={2309.16671},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{gokhale2022benchmarking,
  title={Benchmarking spatial relationships in text-to-image generation},
  author={Gokhale, Tejas and Palangi, Hamid and Nushi, Besmira and Vineet, Vibhav and Horvitz, Eric and Kamar, Ece and Baral, Chitta and Yang, Yezhou},
  journal={arXiv preprint arXiv:2212.10015},
  year={2022}
}

@article{kamath2023s,
  title={What's" up" with vision-language models? Investigating their struggle with spatial reasoning},
  author={Kamath, Amita and Hessel, Jack and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:2310.19785},
  year={2023}
}

@article{ghosh2023geneval,
  title={GenEval: An Object-Focused Framework for Evaluating Text-to-Image Alignment},
  author={Ghosh, Dhruba and Hajishirzi, Hanna and Schmidt, Ludwig},
  journal={arXiv preprint arXiv:2310.11513},
  year={2023}
}

@misc{fang2023data,
      title={Data Filtering Networks}, 
      author={Alex Fang and Albin Madappally Jose and Amit Jain and Ludwig Schmidt and Alexander Toshev and Vaishaal Shankar},
      year={2023},
      eprint={2309.17425},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@inproceedings{hessel2021clipscore,
  title={CLIPScore: A Reference-free Evaluation Metric for Image Captioning},
  author={Hessel, Jack and Holtzman, Ari and Forbes, Maxwell and Le Bras, Ronan and Choi, Yejin},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={7514--7528},
  year={2021}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada}
}

@inproceedings{thrush2022winoground,
  title={Winoground: Probing vision and language models for visio-linguistic compositionality},
  author={Thrush, Tristan and Jiang, Ryan and Bartolo, Max and Singh, Amanpreet and Williams, Adina and Kiela, Douwe and Ross, Candace},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@article{hsieh2023sugarcrepe,
  title={SugarCrepe: Fixing Hackable Benchmarks for Vision-Language Compositionality},
  author={Hsieh, Cheng-Yu and Zhang, Jieyu and Ma, Zixian and Kembhavi, Aniruddha and Krishna, Ranjay},
  journal={arXiv preprint arXiv:2306.14610},
  year={2023}
}

@article{hu2023tifa,
title={TIFA: Accurate and Interpretable Text-to-Image Faithfulness Evaluation with Question Answering},
author={Hu, Yushi and Liu, Benlin and Kasai, Jungo and Wang, Yizhong and Ostendorf, Mari and Krishna, Ranjay and Smith,
Noah A},
journal={arXiv preprint arXiv:2303.11897},
year={2023}
}

@inproceedings{
chen2023pali,
title={Pa{LI}: A Jointly-Scaled Multilingual Language-Image Model},
  author={Chen, Xi and Wang, Xiao and Changpinyo, Soravit and Piergiovanni, AJ and Padlewski, Piotr and Salz, Daniel and Goodman, Sebastian and Grycner, Adam and Mustafa, Basil and Beyer, Lucas and others},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023}
}

@article{chen2022pali,
  title={Pali: A jointly-scaled multilingual language-image model},
  author={Chen, Xi and Wang, Xiao and Changpinyo, Soravit and Piergiovanni, AJ and Padlewski, Piotr and Salz, Daniel and Goodman, Sebastian and Grycner, Adam and Mustafa, Basil and Beyer, Lucas and others},
  journal={arXiv preprint arXiv:2209.06794},
  year={2022}
}

@article{huang2023open,
  title={Open-Set Image Tagging with Multi-Grained Text Supervision},
  author={Huang, Xinyu and Huang, Yi-Jie and Zhang, Youcai and Tian, Weiwei and Feng, Rui and Zhang, Yuejie and Xie, Yanchun and Li, Yaqian and Zhang, Lei},
  journal={arXiv e-prints},
  pages={arXiv--2310},
  year={2023}
}

@article{walfish2006review,
  title={A review of statistical outlier methods},
  author={Walfish, Steven},
  journal={Pharmaceutical technology},
  volume={30},
  number={11},
  pages={82},
  year={2006},
  publisher={ASTER PUBLISHING CORPORATION}
}

@inproceedings{samuel2024generating,
  title={Generating images of rare concepts using pre-trained diffusion models},
  author={Samuel, Dvir and Ben-Ari, Rami and Raviv, Simon and Darshan, Nir and Chechik, Gal},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={5},
  pages={4695--4703},
  year={2024}
}

@article{berlot2023attribute,
  title={Attribute Diversity Determines the Systematicity Gap in VQA},
  author={Berlot-Attwell, Ian and Carrell, A Michael and Agrawal, Kumar Krishna and Sharma, Yash and Saphra, Naomi},
  journal={arXiv preprint arXiv:2311.08695},
  year={2023}
}

@article{fodor1988connectionism,
  title={Connectionism and cognitive architecture: A critical analysis},
  author={Fodor, Jerry A and Pylyshyn, Zenon W},
  journal={Cognition},
  volume={28},
  number={1-2},
  pages={3--71},
  year={1988},
  publisher={Elsevier}
}

% ------------------------------------------------------------------------
% SAMPLE BIBLIOGRAPHY FILE
% ------------------------------------------------------------------------


@inproceedings{kotar2021contrasting,
  title={Contrasting contrastive self-supervised representation learning pipelines},
  author={Kotar, Klemen and Ilharco, Gabriel and Schmidt, Ludwig and Ehsani, Kiana and Mottaghi, Roozbeh},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2021}
}
@article{wortsman2021robust,
  title={Robust fine-tuning of zero-shot models},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Li, Mike and Kim, Jong Wook and Hajishirzi, Hannaneh and Farhadi, Ali and Namkoong, Hongseok and Schmidt, Ludwig},
  journal={arXiv preprint arXiv:2109.01903},
  year={2021}
}

@article{ding2022prompt,
  title={Prompt Tuning with Soft Context Sharing for Vision-Language Models},
  author={Ding, Kun and Wang, Ying and Liu, Pengzhang and Yu, Qiang and Zhang, Haojian and Xiang, Shiming and Pan, Chunhong},
  journal={arXiv preprint arXiv:2208.13474},
  year={2022}
}

@article{bulat2022language,
  title={Language-Aware Soft Prompting for Vision \& Language Foundation Models},
  author={Bulat, Adrian and Tzimiropoulos, Georgios},
  journal={arXiv preprint arXiv:2210.01115},
  year={2022}
}

@article{zhou2022learningcoop,
  title={Learning to prompt for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  journal={International Journal of Computer Vision},
  volume={130},
  number={9},
  pages={2337--2348},
  year={2022},
  publisher={Springer}
}

@inproceedings{shu2022tpt,
  author    = {Manli, Shu and Weili, Nie and De-An, Huang and Zhiding, Yu and Tom, Goldstein and Anima, Anandkumar and Chaowei, Xiao},
  title     = {Test-Time Prompt Tuning for Zero-shot Generalization in Vision-Language Models},
  booktitle = {NeurIPS},
  year      = {2022},
}

@article{pratt2022does,
  title={What does a platypus look like? Generating customized prompts for zero-shot image classification},
  author={Pratt, Sarah and Liu, Rosanne and Farhadi, Ali},
  journal={arXiv preprint arXiv:2209.03320},
  year={2022}
}

@inproceedings{yang2022visiontcl,
  title={Vision-Language Pre-Training with Triple Contrastive Learning},
  author={Yang, Jinyu and Duan, Jiali and Tran, Son and Xu, Yi and Chanda, Sampath and Chen, Liqun and Zeng, Belinda and Chilimbi, Trishul and Huang, Junzhou},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@article{hendricks2021decoupling,
  title={Decoupling the role of data, attention, and losses in multimodal transformers},
  author={Hendricks, Lisa Anne and Mellor, John and Schneider, Rosalia and Alayrac, Jean-Baptiste and Nematzadeh, Aida},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={570--585},
  year={2021},
  publisher={MIT Press}
}

@article{student1908probable,
  title={Probable error of a correlation coefficient},
  author={Student},
  journal={Biometrika},
  pages={302--310},
  year={1908},
  publisher={JSTOR}
}

@article{piantadosi2014zipf,
  title={Zipf’s word frequency law in natural language: A critical review and future directions},
  author={Piantadosi, Steven T},
  journal={Psychonomic bulletin \& review},
  volume={21},
  pages={1112--1130},
  year={2014},
  publisher={Springer}
}

@book{zipf2016human,
  title={Human behavior and the principle of least effort: An introduction to human ecology},
  author={Zipf, George Kingsley},
  year={2016},
  publisher={Ravenio books}
}


@article{burg2023image,
  title={Image retrieval outperforms diffusion models on data augmentation},
  author={Burg, Max F and Wenzel, Florian and Zietlow, Dominik and Horn, Max and Makansi, Osama and Locatello, Francesco and Russell, Chris},
  journal={Transactions on Machine Learning Research (TMLR)},
  year={2023}
}

@inproceedings{zhang2023cafoprompt,
  title={Prompt, generate, then cache: Cascade of foundation models makes strong few-shot learners},
  author={Zhang, Renrui and Hu, Xiangfei and Li, Bohao and Huang, Siyuan and Deng, Hanqiu and Qiao, Yu and Gao, Peng and Li, Hongsheng},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}

@article{tian2024stablerep,
  title={Stablerep: Synthetic images from text-to-image models make strong visual representation learners},
  author={Tian, Yonglong and Fan, Lijie and Isola, Phillip and Chang, Huiwen and Krishnan, Dilip},
  journal={Conference on Neural Information Processing Systems (NeurIPS)},
  year={2023}
}

@inproceedings{sariyildiz2023fake,
  title={Fake it till you make it: Learning transferable representations from synthetic imagenet clones},
  author={Sar{\i}y{\i}ld{\i}z, Mert B{\"u}lent and Alahari, Karteek and Larlus, Diane and Kalantidis, Yannis},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}

@article{he2022synthetic,
  title={Is synthetic data from generative models ready for image recognition?},
  author={He, Ruifei and Sun, Shuyang and Yu, Xin and Xue, Chuhui and Zhang, Wenqing and Torr, Philip and Bai, Song and Qi, Xiaojuan},
  journal={arXiv preprint arXiv:2210.07574},
  year={2022}
}

@inproceedings{szegedy2015going,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2015}
}

@article{du2020perceptual,
  title={Perceptual hashing for image authentication: A survey},
  author={Du, Ling and Ho, Anthony TS and Cong, Runmin},
  journal={Signal Processing: Image Communication},
  year={2020}
}

@article{chan2022data,
  title={Data distributional properties drive emergent in-context learning in transformers},
  author={Chan, Stephanie and Santoro, Adam and Lampinen, Andrew and Wang, Jane and Singh, Aaditya and Richemond, Pierre and McClelland, James and Hill, Felix},
  journal={Conference on Neural Information Processing Systems (NeurIPS)},
  year={2022}
}

@article{ren2022rethinking,
  title={Rethinking the Openness of CLIP},
  author={Ren, Shuhuai and Li, Lei and Ren, Xuancheng and Zhao, Guangxiang and Sun, Xu},
  journal={arXiv preprint arXiv:2206.01986},
  year={2022}
}

@article{huang2022unsupervised,
  title={Unsupervised Prompt Learning for Vision-Language Models},
  author={Huang, Tony and Chu, Jack and Wei, Fangyun},
  journal={arXiv preprint arXiv:2204.03649},
  year={2022}
}

@article{bai2022lat,
  title={LaT: Latent Translation with Cycle-Consistency for Video-Text Retrieval},
  author={Bai, Jinbin and Liu, Chunhui and Ni, Feiyue and Wang, Haofan and Hu, Mengying and Guo, Xiaofeng and Cheng, Lele},
  journal={arXiv preprint arXiv:2207.04858},
  year={2022}
}

@inproceedings{kim2021vilt,
  title={Vilt: Vision-and-language transformer without convolution or region supervision},
  author={Kim, Wonjae and Son, Bokyung and Kim, Ildoo},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2021}
}

@inproceedings{barraco2022unreasonable,
  title={The Unreasonable Effectiveness of CLIP Features for Image Captioning: An Experimental Analysis},
  author={Barraco, Manuele and Cornia, Marcella and Cascianelli, Silvia and Baraldi, Lorenzo and Cucchiara, Rita},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@article{cho2022fine,
  title={Fine-grained image captioning with clip reward},
  author={Cho, Jaemin and Yoon, Seunghyun and Kale, Ajinkya and Dernoncourt, Franck and Bui, Trung and Bansal, Mohit},
  journal={arXiv preprint arXiv:2205.13115},
  year={2022}
}

@article{castro2022fitclip,
  title={Fitclip: Refining large-scale pretrained image-text models for zero-shot video understanding tasks},
  author={Castro, Santiago and Heilbron, Fabian Caba},
  journal={British Machine Vision Conference (BMVC)},
  year={2022}
}

@article{bain2022clip,
  title={A CLIP-Hitchhiker's Guide to Long Video Retrieval},
  author={Bain, Max and Nagrani, Arsha and Varol, G{\"u}l and Zisserman, Andrew},
  journal={arXiv preprint arXiv:2205.08508},
  year={2022}
}

@article{shen2021much,
  title={How Much Can CLIP Benefit Vision-and-Language Tasks?},
  author={Shen, Sheng and Li, Liunian Harold and Tan, Hao and Bansal, Mohit and Rohrbach, Anna and Chang, Kai-Wei and Yao, Zhewei and Keutzer, Kurt},
  journal={arXiv preprint arXiv:2107.06383},
  year={2021}
}

@article{li2021align,
  title={Align before fuse: Vision and language representation learning with momentum distillation},
  author={Li, Junnan and Selvaraju, Ramprasaath and Gotmare, Akhilesh and Joty, Shafiq and Xiong, Caiming and Hoi, Steven Chu Hong},
  journal={Conference on Neural Information Processing Systems (NeurIPS)},
  year={2021}
}

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@article{
yu2022coca,
title={CoCa: Contrastive Captioners are Image-Text Foundation Models},
author={Jiahui Yu and Zirui Wang and Vijay Vasudevan and Legg Yeung and Mojtaba Seyedhosseini and Yonghui Wu},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2022}
}

@inproceedings{dou2022empirical,
  title={An empirical study of training end-to-end vision-and-language transformers},
  author={Dou, Zi-Yi and Xu, Yichong and Gan, Zhe and Wang, Jianfeng and Wang, Shuohang and Wang, Lijuan and Zhu, Chenguang and Zhang, Pengchuan and Yuan, Lu and Peng, Nanyun and others},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@inproceedings{kamath2021mdetr,
  title={MDETR-modulated detection for end-to-end multi-modal understanding},
  author={Kamath, Aishwarya and Singh, Mannat and LeCun, Yann and Synnaeve, Gabriel and Misra, Ishan and Carion, Nicolas},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2021}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katie and Reynolds, Malcolm and others},
  journal={arXiv preprint arXiv:2204.14198},
  year={2022}
}

@article{aghajanyan2022cm3,
  title={Cm3: A causal masked multimodal model of the internet},
  author={Aghajanyan, Armen and Huang, Bernie and Ross, Candace and Karpukhin, Vladimir and Xu, Hu and Goyal, Naman and Okhonko, Dmytro and Joshi, Mandar and Ghosh, Gargi and Lewis, Mike and others},
  journal={arXiv preprint arXiv:2201.07520},
  year={2022}
}

@article{chen2022prototypical,
  title={Prototypical Contrastive Language Image Pretraining},
  author={Chen, Delong and Wu, Zhao and Liu, Fan and Yang, Zaiquan and Huang, Yixiang and Bao, Yiping and Zhou, Erjin},
  journal={arXiv preprint arXiv:2206.10996},
  year={2022}
}

@article{zhang2022can,
  title={Can Language Understand Depth?},
  author={Zhang, Renrui and Zeng, Ziyao and Guo, Ziyu},
  journal={arXiv preprint arXiv:2207.01077},
  year={2022}
}

@inproceedings{
mayilvahanan2024does,
title={Does {CLIP}{\textquoteright}s generalization performance mainly stem from high train-test similarity?},
author={Prasanna Mayilvahanan and Thadd{\"a}us Wiedemer and Evgenia Rusak and Matthias Bethge and Wieland Brendel},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024}
}

@article{nguyen2022quality,
  title={Quality not quantity: On the interaction between dataset design and robustness of clip},
  author={Nguyen, Thao and Ilharco, Gabriel and Wortsman, Mitchell and Oh, Sewoong and Schmidt, Ludwig},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21455--21469},
  year={2022}
}

@article{li2021supervision,
  title={Supervision exists everywhere: A data efficient contrastive language-image pre-training paradigm},
  author={Li, Yangguang and Liang, Feng and Zhao, Lichen and Cui, Yufeng and Ouyang, Wanli and Shao, Jing and Yu, Fengwei and Yan, Junjie},
  journal={arXiv preprint arXiv:2110.05208},
  year={2021}
}

@article{yao2021filip,
  title={Filip: Fine-grained interactive language-image pre-training},
  author={Yao, Lewei and Huang, Runhui and Hou, Lu and Lu, Guansong and Niu, Minzhe and Xu, Hang and Liang, Xiaodan and Li, Zhenguo and Jiang, Xin and Xu, Chunjing},
  journal={arXiv preprint arXiv:2111.07783},
  year={2021}
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2021}
}

@article{calvert2001crossmodal,
  title={Crossmodal processing in the human brain: insights from functional neuroimaging studies},
  author={Calvert, Gemma A},
  journal={Cerebral cortex},
  volume={11},
  number={12},
  pages={1110--1123},
  year={2001},
  publisher={Oxford University Press}
}

@article{song2022clip,
  title={Clip models are few-shot learners: Empirical studies on vqa and visual entailment},
  author={Song, Haoyu and Dong, Li and Zhang, Wei-Nan and Liu, Ting and Wei, Furu},
  journal={arXiv preprint arXiv:2203.07190},
  year={2022}
}

@inproceedings{wang2020understanding,
  title={Understanding contrastive representation learning through alignment and uniformity on the hypersphere},
  author={Wang, Tongzhou and Isola, Phillip},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020}
}

@article{wang2021simvlm,
  title={Simvlm: Simple visual language model pretraining with weak supervision},
  author={Wang, Zirui and Yu, Jiahui and Yu, Adams Wei and Dai, Zihang and Tsvetkov, Yulia and Cao, Yuan},
  journal={arXiv preprint arXiv:2108.10904},
  year={2021}
}

@article{nguyen2018loss,
  title={On the loss landscape of a class of deep neural networks with no bad local valleys},
  author={Nguyen, Quynh and Mukkamala, Mahesh Chandra and Hein, Matthias},
  journal={arXiv preprint arXiv:1809.10749},
  year={2018}
}

@article{tian2020makes,
  title={What makes for good views for contrastive learning?},
  author={Tian, Yonglong and Sun, Chen and Poole, Ben and Krishnan, Dilip and Schmid, Cordelia and Isola, Phillip},
  journal={Conference on Neural Information Processing Systems (NeurIPS)},
  volume={33},
  pages={6827--6839},
  year={2020}
}

@article{ni2022expanding,
  title={Expanding Language-Image Pretrained Models for General Video Recognition},
  author={Ni, Bolin and Peng, Houwen and Chen, Minghao and Zhang, Songyang and Meng, Gaofeng and Fu, Jianlong and Xiang, Shiming and Ling, Haibin},
  journal={arXiv preprint arXiv:2208.02816},
  year={2022}
}

@inproceedings{zhang2022pointclip,
  title={Pointclip: Point cloud understanding by clip},
  author={Zhang, Renrui and Guo, Ziyu and Zhang, Wei and Li, Kunchang and Miao, Xupeng and Cui, Bin and Qiao, Yu and Gao, Peng and Li, Hongsheng},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@article{cui2022you,
  title={You Only Need 90K Parameters to Adapt Light: A Light Weight Transformer for Image Enhancement and Exposure Correction},
  author={Cui, Ziteng and Li, Kunchang and Gu, Lin and Su, Shenghan and Gao, Peng and Jiang, Zhengkai and Qiao, Yu and Harada, Tatsuya},
  journal={arXiv preprint arXiv:2205.14871v3},
  year={2022}  
}

@inproceedings{zhang2022contrastive,
  title={Contrastive Adapters for Foundation Model Group Robustness},
  author={Zhang, Michael and R{\'e}, Christopher},
  booktitle={ICML 2022: Workshop on Spurious Correlations, Invariance and Stability},
  year={2022}
}

@article{virtanen2020scipy,
  title={SciPy 1.0: fundamental algorithms for scientific computing in Python},
  author={Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and others},
  journal={Nature methods},
  volume={17},
  number={3},
  pages={261--272},
  year={2020},
  publisher={Nature Publishing Group}
}

@book{hocking1988topology,
  title={Topology},
  author={Hocking, John Gilbert and Young, Gail S},
  year={1988},
  publisher={Courier Corporation}
}

@book{maunder1996algebraic,
  title={Algebraic topology},
  author={Maunder, Charles Richard Francis},
  year={1996},
  publisher={Courier Corporation}
}

@inproceedings{duan2022multi,
  title={Multi-modal alignment using representation codebook},
  author={Duan, Jiali and Chen, Liqun and Tran, Son and Yang, Jinyu and Xu, Yi and Zeng, Belinda and Chilimbi, Trishul},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@article{liang2022mind,
  title={Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive Representation Learning},
  author={Liang, Weixin and Zhang, Yuhui and Kwon, Yongchan and Yeung, Serena and Zou, James},
  journal={arXiv preprint arXiv:2203.02053},
  year={2022}
}

@article{van2008visualizing,
  title={Visualizing data using t-SNE.},
  author={Van der Maaten, Laurens and Hinton, Geoffrey},
  journal={Journal of machine learning research},
  volume={9},
  number={11},
  year={2008}
}

@article{smith2005development,
  title={The development of embodied cognition: Six lessons from babies},
  author={Smith, Linda and Gasser, Michael},
  journal={Artificial life},
  volume={11},
  number={1-2},
  pages={13--29},
  year={2005},
  publisher={MIT Press}
}

@book{stein1993merging,
  title={The merging of the senses.},
  author={Stein, Barry E and Meredith, M Alex},
  year={1993},
  publisher={The MIT press}
}

@inproceedings{krause20133d,
  title={3d object representations for fine-grained categorization},
  author={Krause, Jonathan and Stark, Michael and Deng, Jia and Fei-Fei, Li},
  booktitle={International Conference on Computer Vision Workshop (ICCV-W) },
  year={2013}
}

@article{lachs2017multi,
  title={Multi-modal perception},
  author={Lachs, Lorin},
  journal={Noba textbook series: Psychology. Champaign: DEF Publishers},
  year={2017}
}

@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  volume={115},
  number={3},
  pages={211--252},
  year={2015},
  publisher={Springer}
}

@article{hao2022mixgen,
  title={MixGen: A New Multi-Modal Data Augmentation},
  author={Hao, Xiaoshuai and Zhu, Yi and Appalaraju, Srikar and Zhang, Aston and Zhang, Wanqian and Li, Bo and Li, Mu},
  journal={arXiv preprint arXiv:2206.08358},
  year={2022}
}

@article{collier2022reality,
  title={On reality and the limits of language data},
  author={Collier, Nigel H and Liu, Fangyu and Shareghi, Ehsan},
  journal={arXiv preprint arXiv:2208.11981},
  year={2022}
}

@misc{browning2022ai,
    title={AI And The Limits Of Language},
    author={Jacob Browning and Yann Lecun},
    url={https://www.noemamag.com/ai-and-the-limits-of-language/},
    year={2022}
}

@article{li2020federated,
  title={Federated learning: Challenges, methods, and future directions},
  author={Li, Tian and Sahu, Anit Kumar and Talwalkar, Ameet and Smith, Virginia},
  journal={IEEE signal processing magazine},
  volume={37},
  number={3},
  pages={50--60},
  year={2020},
  publisher={IEEE}
}

@inproceedings{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@inproceedings{yang2022vision,
  title={Vision-Language Pre-Training with Triple Contrastive Learning},
  author={Yang, Jinyu and Duan, Jiali and Tran, Son and Xu, Yi and Chanda, Sampath and Chen, Liqun and Zeng, Belinda and Chilimbi, Trishul and Huang, Junzhou},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@article{mikolov2013efficient,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  journal={arXiv preprint arXiv:1301.3781},
  year={2013}
}

@article{ethayarajh2018towards,
  title={Towards understanding linear word analogies},
  author={Ethayarajh, Kawin and Duvenaud, David and Hirst, Graeme},
  journal={arXiv preprint arXiv:1810.04882},
  year={2018}
}

@article{fournier2020analogies,
  title={Analogies minus analogy test: measuring regularities in word embeddings},
  author={Fournier, Louis and Dupoux, Emmanuel and Dunbar, Ewan},
  journal={arXiv preprint arXiv:2010.03446},
  year={2020}
}

@inproceedings{mikolov2013linguistic,
  title={Linguistic regularities in continuous space word representations},
  author={Mikolov, Tom{\'a}{\v{s}} and Yih, Wen-tau and Zweig, Geoffrey},
  booktitle={Proceedings of the 2013 conference of the north american chapter of the association for computational linguistics: Human language technologies},
  pages={746--751},
  year={2013}
}

@inproceedings{levy2014linguistic,
  title={Linguistic regularities in sparse and explicit word representations},
  author={Levy, Omer and Goldberg, Yoav},
  booktitle={Proceedings of the eighteenth conference on computational natural language learning},
  pages={171--180},
  year={2014}
}

@inproceedings{razeghi2022impact,
  title={Impact of pretraining term frequencies on few-shot numerical reasoning},
  author={Razeghi, Yasaman and Logan IV, Robert L and Gardner, Matt and Singh, Sameer},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2022},
  pages={840--854},
  year={2022}
}

@inproceedings{li2020oscar,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2020}
}

@inproceedings{couairon2022embedding,
  title={Embedding Arithmetic of Multimodal Queries for Image Retrieval},
  author={Couairon, Guillaume and Douze, Matthijs and Cord, Matthieu and Schwenk, Holger},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@article{schonemann1966generalized,
  title={A generalized solution of the orthogonal procrustes problem},
  author={Sch{\"o}nemann, Peter H},
  journal={Psychometrika},
  volume={31},
  number={1},
  pages={1--10},
  year={1966},
  publisher={Springer}
}

@inproceedings{grave2019unsupervised,
  title={Unsupervised alignment of embeddings with wasserstein procrustes},
  author={Grave, Edouard and Joulin, Armand and Berthet, Quentin},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={1880--1890},
  year={2019},
  organization={PMLR}
}

@article{conneau2017word,
  title={Word translation without parallel data},
  author={Conneau, Alexis and Lample, Guillaume and Ranzato, Marc'Aurelio and Denoyer, Ludovic and J{\'e}gou, Herv{\'e}},
  journal={arXiv preprint arXiv:1710.04087},
  year={2017}
}

@inproceedings{kanazawa2016warpnet,
  title={Warpnet: Weakly supervised matching for single-view reconstruction},
  author={Kanazawa, Angjoo and Jacobs, David W and Chandraker, Manmohan},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016}
}

@inproceedings{novotny2018self,
  title={Self-supervised learning of geometrically stable features through probabilistic introspection},
  author={Novotny, David and Albanie, Samuel and Larlus, Diane and Vedaldi, Andrea},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018}
}

@inproceedings{rocco2017convolutional,
  title={Convolutional neural network architecture for geometric matching},
  author={Rocco, Ignacio and Arandjelovic, Relja and Sivic, Josef},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017}
}

@inproceedings{zhang2019aet,
  title={Aet vs. aed: Unsupervised representation learning by auto-encoding transformations rather than data},
  author={Zhang, Liheng and Qi, Guo-Jun and Wang, Liqiang and Luo, Jiebo},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019}
}

@inproceedings{chen2021jigsaw,
  title={Jigsaw clustering for unsupervised visual representation learning},
  author={Chen, Pengguang and Liu, Shu and Jia, Jiaya},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}

@inproceedings{doersch2015unsupervised,
  title={Unsupervised visual representation learning by context prediction},
  author={Doersch, Carl and Gupta, Abhinav and Efros, Alexei A},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2015}
}

@inproceedings{noroozi2016unsupervised,
  title={Unsupervised learning of visual representations by solving jigsaw puzzles},
  author={Noroozi, Mehdi and Favaro, Paolo},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2016}
}

@article{gidaris2018unsupervised,
  title={Unsupervised representation learning by predicting image rotations},
  author={Gidaris, Spyros and Singh, Praveer and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1803.07728},
  year={2018}
}

@article{zang2022open,
  title={Open-Vocabulary DETR with Conditional Matching},
  author={Zang, Yuhang and Li, Wei and Zhou, Kaiyang and Huang, Chen and Loy, Chen Change},
  journal={arXiv preprint arXiv:2203.11876},
  year={2022}
}

@article{gu2021open,
  title={Open-vocabulary object detection via vision and language knowledge distillation},
  author={Gu, Xiuye and Lin, Tsung-Yi and Kuo, Weicheng and Cui, Yin},
  journal={arXiv preprint arXiv:2104.13921},
  year={2021}
}

@inproceedings{artetxe2018generalizing,
  title={Generalizing and improving bilingual word embedding mappings with a multi-step framework of linear transformations},
  author={Artetxe, Mikel and Labaka, Gorka and Agirre, Eneko},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  year={2018}
}

@phdthesis{nagrani2020video,
  title={Video understanding using multimodal deep learning},
  author={Nagrani, Arsha},
  year={2020},
  school={University of Oxford}
}

@book{edelman1987neural,
  title={Neural Darwinism: The theory of neuronal group selection.},
  author={Edelman, Gerald M},
  year={1987},
  publisher={Basic books}
}

@article{kamachi2003putting,
  title={Putting the face to the voice': Matching identity across modality},
  author={Kamachi, Miyuki and Hill, Harold and Lander, Karen and Vatikiotis-Bateson, Eric},
  journal={Current Biology},
  volume={13},
  number={19},
  pages={1709--1714},
  year={2003},
  publisher={Elsevier}
}

@inproceedings{nagrani2020speech2action,
  title={Speech2action: Cross-modal supervision for action recognition},
  author={Nagrani, Arsha and Sun, Chen and Ross, David and Sukthankar, Rahul and Schmid, Cordelia and Zisserman, Andrew},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2020}
}

@inproceedings{albanie2018emotion,
  title={Emotion recognition in speech using cross-modal transfer in the wild},
  author={Albanie, Samuel and Nagrani, Arsha and Vedaldi, Andrea and Zisserman, Andrew},
  booktitle={Proceedings of the 26th ACM international conference on Multimedia},
  pages={292--301},
  year={2018}
}

@inproceedings{nagrani2018seeing,
  title={Seeing voices and hearing faces: Cross-modal biometric matching},
  author={Nagrani, Arsha and Albanie, Samuel and Zisserman, Andrew},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018}
}

@inproceedings{nagrani2018learnable,
  title={Learnable pins: Cross-modal embeddings for person identity},
  author={Nagrani, Arsha and Albanie, Samuel and Zisserman, Andrew},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2018}
}

@inproceedings{nagrani2020disentangled,
  title={Disentangled speech embeddings using cross-modal self-supervision},
  author={Nagrani, Arsha and Chung, Joon Son and Albanie, Samuel and Zisserman, Andrew},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6829--6833},
  year={2020},
  organization={IEEE}
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@inproceedings{caron2021emerging,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2021}
}

@article{joulin2016bag,
  title={Bag of tricks for efficient text classification},
  author={Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1607.01759},
  year={2016}
}

@article{conneau2019unsupervised,
  title={Unsupervised cross-lingual representation learning at scale},
  author={Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and Guzm{\'a}n, Francisco and Grave, Edouard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1911.02116},
  year={2019}
}

@article{radford2017learning,
  title={Learning to generate reviews and discovering sentiment},
  author={Radford, Alec and Jozefowicz, Rafal and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1704.01444},
  year={2017}
}

@article{kiros2015skip,
  title={Skip-thought vectors},
  author={Kiros, Ryan and Zhu, Yukun and Salakhutdinov, Russ R and Zemel, Richard and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},
  journal={Conference on Neural Information Processing Systems (NeurIPS)},
  year={2015}
}

@article{lecun2021self,
  title={Self-supervised learning: The dark matter of intelligence},
  year={2021},
  author={LeCun, Yann and Misra, Ishan},
  journal={URL https://ai. facebook. com/blog/self-supervised-learning-the-dark-matter-of-intelligence}
}

@inproceedings{tian2020contrastive,
  title={Contrastive multiview coding},
  author={Tian, Yonglong and Krishnan, Dilip and Isola, Phillip},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2020}
}

@inproceedings{poole2019variational,
  title={On variational bounds of mutual information},
  author={Poole, Ben and Ozair, Sherjil and Van Den Oord, Aaron and Alemi, Alex and Tucker, George},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2019}
}

@article{hjelm2018learning,
  title={Learning deep representations by mutual information estimation and maximization},
  author={Hjelm, R Devon and Fedorov, Alex and Lavoie-Marchildon, Samuel and Grewal, Karan and Bachman, Phil and Trischler, Adam and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1808.06670},
  year={2018}
}

@article{jing2020self,
  title={Self-supervised visual feature learning with deep neural networks: A survey},
  author={Jing, Longlong and Tian, Yingli},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={43},
  number={11},
  pages={4037--4058},
  year={2020},
  publisher={IEEE}
}

@article{albelwi2022survey,
  title={Survey on Self-Supervised Learning: Auxiliary Pretext Tasks and Contrastive Learning Methods in Imaging},
  author={Albelwi, Saleh},
  journal={Entropy},
  volume={24},
  number={4},
  pages={551},
  year={2022},
  publisher={MDPI}
}

@inproceedings{misra2020self,
  title={Self-supervised learning of pretext-invariant representations},
  author={Misra, Ishan and Maaten, Laurens van der},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2020}
}

@inproceedings{
yuksekgonul2023when,
title={When and Why Vision-Language Models Behave like Bags-Of-Words, and What to Do About It?},
author={Mert Yuksekgonul and Federico Bianchi and Pratyusha Kalluri and Dan Jurafsky and James Zou},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=KRLUvxh8uaX}
}

@article{chen2020big,
  title={Big self-supervised models are strong semi-supervised learners},
  author={Chen, Ting and Kornblith, Simon and Swersky, Kevin and Norouzi, Mohammad and Hinton, Geoffrey E},
  journal={Conference on Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{goyal2022vision,
  title={Vision models are more robust and fair when pretrained on uncurated images without supervision},
  author={Goyal, Priya and Duval, Quentin and Seessel, Isaac and Caron, Mathilde and Singh, Mannat and Misra, Ishan and Sagun, Levent and Joulin, Armand and Bojanowski, Piotr},
  journal={arXiv preprint arXiv:2202.08360},
  year={2022}
}

@inproceedings{chen2021empirical,
  title={An empirical study of training self-supervised vision transformers},
  author={Chen, Xinlei and Xie, Saining and He, Kaiming},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2021}
}

@article{caron2020unsupervised,
  title={Unsupervised learning of visual features by contrasting cluster assignments},
  author={Caron, Mathilde and Misra, Ishan and Mairal, Julien and Goyal, Priya and Bojanowski, Piotr and Joulin, Armand},
  journal={Conference on Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{kumar2022contrastive,
  title={Contrastive self-supervised learning: review, progress, challenges and future research directions},
  author={Kumar, Pranjal and Rawat, Piyush and Chauhan, Siddhartha},
  journal={International Journal of Multimedia Information Retrieval},
  pages={1--28},
  year={2022},
  publisher={Springer}
}

@article{jaiswal2020survey,
  title={A survey on contrastive self-supervised learning},
  author={Jaiswal, Ashish and Babu, Ashwin Ramesh and Zadeh, Mohammad Zaki and Banerjee, Debapriya and Makedon, Fillia},
  journal={Technologies},
  volume={9},
  number={1},
  pages={2},
  year={2020},
  publisher={MDPI}
}

@article{schiappa2022self,
  title={Self-Supervised Learning for Videos: A Survey},
  author={Schiappa, Madeline C and Rawat, Yogesh S and Shah, Mubarak},
  journal={arXiv preprint arXiv:2207.00419},
  year={2022}
}

@inproceedings{zhang2016colorful,
  title={Colorful image colorization},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2016}
}

@article{bachman2019learning,
  title={Learning representations by maximizing mutual information across views},
  author={Bachman, Philip and Hjelm, R Devon and Buchwalter, William},
  journal={Conference on Neural Information Processing Systems (NeurIPS)},
  year={2019}
}

@article{tschannen2019mutual,
  title={On mutual information maximization for representation learning},
  author={Tschannen, Michael and Djolonga, Josip and Rubenstein, Paul K and Gelly, Sylvain and Lucic, Mario},
  journal={arXiv preprint arXiv:1907.13625},
  year={2019}
}

@inproceedings{gutmann2010noise,
  title={Noise-contrastive estimation: A new estimation principle for unnormalized statistical models},
  author={Gutmann, Michael and Hyv{\"a}rinen, Aapo},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={297--304},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@book{mitchell1997machine,
  title={Machine learning},
  author={Mitchell, Tom M and Mitchell, Tom M},
  volume={1},
  year={1997},
  publisher={McGraw-hill New York}
}

@inproceedings{jin2016describing,
  title={Describing videos using multi-modal fusion},
  author={Jin, Qin and Chen, Jia and Chen, Shizhe and Xiong, Yifan and Hauptmann, Alexander},
  booktitle={Proceedings of the 24th ACM international conference on Multimedia},
  pages={1087--1091},
  year={2016}
}

@article{xiang2018deep,
  title={Deep-learning-based multi-modal fusion for fast MR reconstruction},
  author={Xiang, Lei and Chen, Yong and Chang, Weitang and Zhan, Yiqiang and Lin, Weili and Wang, Qian and Shen, Dinggang},
  journal={IEEE Transactions on Biomedical Engineering},
  volume={66},
  number={7},
  pages={2105--2114},
  year={2018},
  publisher={IEEE}
}



@inproceedings{shvetsova2022everything,
  title={Everything at Once-Multi-Modal Fusion Transformer for Video Retrieval},
  author={Shvetsova, Nina and Chen, Brian and Rouditchenko, Andrew and Thomas, Samuel and Kingsbury, Brian and Feris, Rogerio S and Harwath, David and Glass, James and Kuehne, Hilde},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@inproceedings{kazakos2019epic,
  title={Epic-fusion: Audio-visual temporal binding for egocentric action recognition},
  author={Kazakos, Evangelos and Nagrani, Arsha and Zisserman, Andrew and Damen, Dima},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2019}
}

@article{liu2019use,
  title={Use what you have: Video retrieval using representations from collaborative experts},
  author={Liu, Yang and Albanie, Samuel and Nagrani, Arsha and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1907.13487},
  year={2019}
}

@article{smith2016matching,
  title={Matching novel face and voice identity using static and dynamic facial images},
  author={Smith, Harriet MJ and Dunn, Andrew K and Baguley, Thom and Stacey, Paula C},
  journal={Attention, Perception, \& Psychophysics},
  volume={78},
  number={3},
  pages={868--879},
  year={2016},
  publisher={Springer}
}

@article{ellis2000micro,
  title={Micro-affordance: The potentiation of components of action by seen objects},
  author={Ellis, Rob and Tucker, Mike},
  journal={British journal of psychology},
  volume={91},
  number={4},
  pages={451--471},
  year={2000},
  publisher={Wiley Online Library}
}

@article{borjon2018view,
  title={A view of their own: Capturing the egocentric view of infants and toddlers with head-mounted cameras},
  author={Borjon, Jeremy I and Schroer, Sara E and Bambach, Sven and Slone, Lauren K and Abney, Drew H and Crandall, David J and Smith, Linda B},
  journal={JoVE (Journal of Visualized Experiments)},
  number={140},
  volume={1},
  pages={e58445},
  year={2018}
}

@article{zaadnoordijk2022lessons,
  title={Lessons from infant learning for unsupervised machine learning},
  author={Zaadnoordijk, Lorijn and Besold, Tarek R and Cusack, Rhodri},
  journal={Nature Machine Intelligence},
  pages={1--11},
  year={2022},
  publisher={Nature Publishing Group}
}

@incollection{hunnius2022early,
  title={Early cognitive development: five lessons from infant learning},
  author={Hunnius, Sabine},
  booktitle={Oxford Research Encyclopedia of Psychology},
  year={2022}
}

@article{bushnell1994dual,
  title={A dual-processing approach to cross-modal matching: Implications for development},
  author={Bushnell, Emily W},
  journal={The development of intersensory perception: Comparative perspectives},
  pages={19--38},
  year={1994},
  publisher={Lawrence Erlbaum Hillsdale, NJ}
}

@article{piaget1952origins,
  title={The origins of intelligence in children.},
  author={Piaget, Jean and Cook, Margaret Trans},
  year={1952},
  publisher={WW Norton \& Co}
}

@book{landau2009language,
  title={Language and experience: Evidence from the blind child},
  author={Landau, Barbara and Gleitman, Lila R and Landau, Barbara},
  volume={8},
  year={2009},
  publisher={Harvard University Press}
}

@article{barlow1989unsupervised,
  title={Unsupervised learning},
  author={Barlow, Horace B},
  journal={Neural computation},
  volume={1},
  number={3},
  pages={295--311},
  year={1989},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{grill2020bootstrap,
  title={Bootstrap your own latent-a new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others},
  journal={Conference on Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@inproceedings{zbontar2021barlow,
  title={Barlow twins: Self-supervised learning via redundancy reduction},
  author={Zbontar, Jure and Jing, Li and Misra, Ishan and LeCun, Yann and Deny, St{\'e}phane},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2021}
}

@article{bardes2021vicreg,
  title={Vicreg: Variance-invariance-covariance regularization for self-supervised learning},
  author={Bardes, Adrien and Ponce, Jean and LeCun, Yann},
  journal={arXiv preprint arXiv:2105.04906},
  year={2021}
}

@inproceedings{chen2021exploring,
  title={Exploring simple siamese representation learning},
  author={Chen, Xinlei and He, Kaiming},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}

@article{li2021efficient,
  title={Efficient self-supervised vision transformers for representation learning},
  author={Li, Chunyuan and Yang, Jianwei and Zhang, Pengchuan and Gao, Mei and Xiao, Bin and Dai, Xiyang and Yuan, Lu and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2106.09785},
  year={2021}
}

@article{lan2019albert,
  title={Albert: A lite bert for self-supervised learning of language representations},
  author={Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
  journal={arXiv preprint arXiv:1909.11942},
  year={2019}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Conference on Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@inproceedings{sariyildiz2020learning,
  title={Learning visual representations with caption annotations},
  author={Sariyildiz, Mert Bulent and Perez, Julien and Larlus, Diane},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2020}
}

@inproceedings{sharma2018conceptual,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={2556--2565},
  year={2018}
}

@article{xu2018spherical,
  title={Spherical latent spaces for stable variational autoencoders},
  author={Xu, Jiacheng and Durrett, Greg},
  journal={arXiv preprint arXiv:1808.10805},
  year={2018}
}

@article{sennrich2015neural,
  title={Neural machine translation of rare words with subword units},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  journal={arXiv preprint arXiv:1508.07909},
  year={2015}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{parkhi2015deep,
  title={Deep face recognition},
  author={Parkhi, Omkar M and Vedaldi, Andrea and Zisserman, Andrew},
  year={2015},
  publisher={British Machine Vision Association}
}

@inproceedings{wang2017normface,
  title={Normface: L2 hypersphere embedding for face verification},
  author={Wang, Feng and Xiang, Xiang and Cheng, Jian and Yuille, Alan Loddon},
  booktitle={Proceedings of the 25th ACM international conference on Multimedia},
  pages={1041--1049},
  year={2017}
}

@article{thomee2016yfcc100m,
  title={YFCC100M: The new data in multimedia research},
  author={Thomee, Bart and Shamma, David A and Friedland, Gerald and Elizalde, Benjamin and Ni, Karl and Poland, Douglas and Borth, Damian and Li, Li-Jia},
  journal={Communications of the ACM},
  volume={59},
  number={2},
  pages={64--73},
  year={2016},
  publisher={ACM New York, NY, USA}
}

@article{krishna2017visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International journal of computer vision},
  volume={123},
  number={1},
  pages={32--73},
  year={2017},
  publisher={Springer}
}

@article{zhang2020contrastive,
  title={Contrastive learning of medical visual representations from paired images and text},
  author={Zhang, Yuhao and Jiang, Hang and Miura, Yasuhide and Manning, Christopher D and Langlotz, Curtis P},
  journal={arXiv preprint arXiv:2010.00747},
  year={2020}
}

@article{kiela2019supervised,
  title={Supervised multimodal bitransformers for classifying images and text},
  author={Kiela, Douwe and Bhooshan, Suvrat and Firooz, Hamed and Perez, Ethan and Testuggine, Davide},
  journal={arXiv preprint arXiv:1909.02950},
  year={2019}
}

@inproceedings{wang2016learning,
  title={Learning deep structure-preserving image-text embeddings},
  author={Wang, Liwei and Li, Yin and Lazebnik, Svetlana},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016}
}

@inproceedings{desai2021virtex,
  title={Virtex: Learning visual representations from textual annotations},
  author={Desai, Karan and Johnson, Justin},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}

@inproceedings{hu2019scalable,
  title={Scalable deep multimodal learning for cross-modal retrieval},
  author={Hu, Peng and Zhen, Liangli and Peng, Dezhong and Liu, Pei},
  booktitle={Proceedings of the 42nd international ACM SIGIR conference on research and development in information retrieval},
  pages={635--644},
  year={2019}
}

@article{prabhu2023categories,
  title={From Categories to Classifier: Name-Only Continual Learning by Exploring the Web},
  author={Prabhu, Ameya and Hammoud, Hasan Abed Al Kader and Lim, Ser-Nam and Ghanem, Bernard and Torr, Philip HS and Bibi, Adel},
  journal={arXiv preprint arXiv:2311.11293},
  year={2023}
}

@article{guo2019deep,
  title={Deep multimodal representation learning: A survey},
  author={Guo, Wenzhong and Wang, Jianwen and Wang, Shiping},
  journal={IEEE Access},
  volume={7},
  pages={63373--63394},
  year={2019},
  publisher={IEEE}
}

@inproceedings{andrew2013deep,
  title={Deep canonical correlation analysis},
  author={Andrew, Galen and Arora, Raman and Bilmes, Jeff and Livescu, Karen},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2013}
}

@article{gong2014multi,
  title={A multi-view embedding space for modeling internet images, tags, and their semantics},
  author={Gong, Yunchao and Ke, Qifa and Isard, Michael and Lazebnik, Svetlana},
  journal={International journal of computer vision},
  volume={106},
  number={2},
  pages={210--233},
  year={2014},
  publisher={Springer}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{bahrick2000intersensory,
  title={Intersensory redundancy guides attentional selectivity and perceptual learning in infancy.},
  author={Bahrick, Lorraine E and Lickliter, Robert},
  journal={Developmental psychology},
  volume={36},
  number={2},
  pages={190},
  year={2000},
  publisher={American Psychological Association}
}

@article{shen2022k,
  title={K-lite: Learning transferable visual models with external knowledge},
  author={Shen, Sheng and Li, Chunyuan and Hu, Xiaowei and Xie, Yujia and Yang, Jianwei and Zhang, Pengchuan and Rohrbach, Anna and Gan, Zhe and Wang, Lijuan and Yuan, Lu and others},
  journal={arXiv preprint arXiv:2204.09222},
  year={2022}
}

@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020}
}

@inproceedings{henaff2020data,
  title={Data-efficient image recognition with contrastive predictive coding},
  author={Henaff, Olivier},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020}
}

@article{chen2020improved,
  title={Improved baselines with momentum contrastive learning},
  author={Chen, Xinlei and Fan, Haoqi and Girshick, Ross and He, Kaiming},
  journal={arXiv preprint arXiv:2003.04297},
  year={2020}
}

@inproceedings{he2020momentum,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2020}
}


@book{krzanowski2000principles,
  title={Principles of multivariate analysis},
  author={Krzanowski, Wojtek},
  volume={23},
  year={2000},
  publisher={OUP Oxford}
}

@article{gower1975generalized,
  title={Generalized procrustes analysis},
  author={Gower, John C},
  journal={Psychometrika},
  volume={40},
  number={1},
  pages={33--51},
  year={1975},
  publisher={Springer}
}

@inproceedings{wang2021understanding,
  title={Understanding the behaviour of contrastive loss},
  author={Wang, Feng and Liu, Huaping},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}

@article{so2022multi,
  title={Multi-Modal Mixup for Robust Fine-tuning},
  author={So, Junhyuk and Oh, Changdae and Shin, Minchul and Song, Kyungwoo},
  journal={arXiv preprint arXiv:2203.03897},
  year={2022}
}

@article{gao2022pyramidclip,
  title={PyramidCLIP: Hierarchical Feature Alignment for Vision-language Model Pretraining},
  author={Gao, Yuting and Liu, Jinfeng and Xu, Zihan and Zhang, Jun and Li, Ke and Shen, Chunhua},
  journal={arXiv preprint arXiv:2204.14095},
  year={2022}
}

@article{saito2022prefix,
  title={Prefix Conditioning Unifies Language and Label Supervision},
  author={Saito, Kuniaki and Sohn, Kihyuk and Zhang, Xiang and Li, Chun-Liang and Lee, Chen-Yu and Saenko, Kate and Pfister, Tomas},
  journal={arXiv preprint arXiv:2206.01125},
  year={2022}
}

@inproceedings{mu2022slip,
  title={Slip: Self-supervision meets language-image pre-training},
  author={Mu, Norman and Kirillov, Alexander and Wagner, David and Xie, Saining},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2022}
}

@article{wang2022visually,
  title={Visually-Augmented Language Modeling},
  author={Wang, Weizhi and Dong, Li and Cheng, Hao and Song, Haoyu and Liu, Xiaodong and Yan, Xifeng and Gao, Jianfeng and Wei, Furu},
  journal={arXiv preprint arXiv:2205.10178},
  year={2022}
}

@misc{straub2017bayesian,
  title={Bayesian inference with the von-Mises-Fisher distribution in 3d},
  author={Straub, Julian},
  year={2017}
}

@article{watson1982distributions,
  title={Distributions on the circle and sphere},
  author={Watson, Geoffrey S},
  journal={Journal of Applied Probability},
  volume={19},
  number={A},
  pages={265--280},
  year={1982},
  publisher={Cambridge University Press}
}

@book{mardia2000directional,
  title={Directional statistics},
  author={Mardia, Kanti V and Jupp, Peter E and Mardia, KV},
  volume={2},
  year={2000},
  publisher={Wiley Online Library}
}

@article{de2020power,
  title={The power spherical distribution},
  author={De Cao, Nicola and Aziz, Wilker},
  journal={arXiv preprint arXiv:2006.04437},
  year={2020}
}

@inproceedings{wu2018unsupervised,
  title={Unsupervised feature learning via non-parametric instance discrimination},
  author={Wu, Zhirong and Xiong, Yuanjun and Yu, Stella X and Lin, Dahua},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018}
}

@article{couairon2021embedding,
  title={Embedding Arithmetic for Text-driven Image Transformation},
  author={Couairon, Guillaume and Cord, Matthieu and Douze, Matthijs and Schwenk, Holger},
  journal={arXiv preprint arXiv:2112.03162},
  year={2021}
}

@inproceedings{ulyanov2018deep,
  title={Deep image prior},
  author={Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018}
}

@inproceedings{mahendran2015understanding,
  title={Understanding deep image representations by inverting them},
  author={Mahendran, Aravindh and Vedaldi, Andrea},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2015}
}

@article{goel2022cyclip,
  title={Cyclip: Cyclic contrastive language-image pretraining},
  author={Goel, Shashank and Bansal, Hritik and Bhatia, Sumit and Rossi, Ryan and Vinay, Vishwa and Grover, Aditya},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={6704--6719},
  year={2022}
}

@article{rao2021denseclip,
  title={DenseCLIP: Language-Guided Dense Prediction with Context-Aware Prompting},
  author={Rao, Yongming and Zhao, Wenliang and Chen, Guangyi and Tang, Yansong and Zhu, Zheng and Huang, Guan and Zhou, Jie and Lu, Jiwen},
  journal={arXiv preprint arXiv:2112.01518},
  year={2021}
}

@article{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  journal={arXiv preprint arXiv:2201.12086},
  year={2022}
}

@article{li2019visualbert,
  title={Visualbert: A simple and performant baseline for vision and language},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1908.03557},
  year={2019}
}

@inproceedings{chen2020uniter,
  title={Uniter: Universal image-text representation learning},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2020}
}

@article{faghri2017vse++,
  title={Vse++: Improving visual-semantic embeddings with hard negatives},
  author={Faghri, Fartash and Fleet, David J and Kiros, Jamie Ryan and Fidler, Sanja},
  journal={arXiv preprint arXiv:1707.05612},
  year={2017}
}

@article{wang2022unifying,
  title={Unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning framework},
  author={Wang, Peng and Yang, An and Men, Rui and Lin, Junyang and Bai, Shuai and Li, Zhikang and Ma, Jianxin and Zhou, Chang and Zhou, Jingren and Yang, Hongxia},
  journal={arXiv preprint arXiv:2202.03052},
  year={2022}
}



@inproceedings{lee2018stacked,
  title={Stacked cross attention for image-text matching},
  author={Lee, Kuang-Huei and Chen, Xi and Hua, Gang and Hu, Houdong and He, Xiaodong},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2018}
}

@article{xu2022bridge,
  title={Bridge-Tower: Building Bridges Between Encoders in Vision-Language Representation Learning},
  author={Xu, Xiao and Wu, Chenfei and Rosenman, Shachar and Lal, Vasudev and Duan, Nan},
  journal={arXiv preprint arXiv:2206.08657},
  year={2022}
}

@article{huo2021wenlan,
  title={WenLan: Bridging vision and language by large-scale multi-modal pre-training},
  author={Huo, Yuqi and Zhang, Manli and Liu, Guangzhen and Lu, Haoyu and Gao, Yizhao and Yang, Guoxing and Wen, Jingyuan and Zhang, Heng and Xu, Baogui and Zheng, Weihao and others},
  journal={arXiv preprint arXiv:2103.06561},
  year={2021}
}

@article{yu2022multimodal,
  title={Multimodal Knowledge Alignment with Reinforcement Learning},
  author={Yu, Youngjae and Chung, Jiwan and Yun, Heeseung and Hessel, Jack and Park, JaeSung and Lu, Ximing and Ammanabrolu, Prithviraj and Zellers, Rowan and Bras, Ronan Le and Kim, Gunhee and others},
  journal={arXiv preprint arXiv:2205.12630},
  year={2022}
}

@article{zhang2022tip,
  title={Tip-Adapter: Training-free Adaption of CLIP for Few-shot Classification},
  author={Zhang, Renrui and Zhang, Wei and Fang, Rongyao and Gao, Peng and Li, Kunchang and Dai, Jifeng and Qiao, Yu and Li, Hongsheng},
  journal={arXiv preprint arXiv:2207.09519},
  year={2022}
}

@article{wang2020k,
  title={K-adapter: Infusing knowledge into pre-trained models with adapters},
  author={Wang, Ruize and Tang, Duyu and Duan, Nan and Wei, Zhongyu and Huang, Xuanjing and Cao, Guihong and Jiang, Daxin and Zhou, Ming and others},
  journal={arXiv preprint arXiv:2002.01808},
  year={2020}
}

@article{colon2021combining,
  title={Combining pre-trained language models and structured knowledge},
  author={Colon-Hernandez, Pedro and Havasi, Catherine and Alonso, Jason and Huggins, Matthew and Breazeal, Cynthia},
  journal={arXiv preprint arXiv:2101.12294},
  year={2021}
}

@article{xu2020syntax,
  title={Syntax-enhanced pre-trained model},
  author={Xu, Zenan and Guo, Daya and Tang, Duyu and Su, Qinliang and Shou, Linjun and Gong, Ming and Zhong, Wanjun and Quan, Xiaojun and Duan, Nan and Jiang, Daxin},
  journal={arXiv preprint arXiv:2012.14116},
  year={2020}
}

@article{kwon2022masked,
  title={Masked Vision and Language Modeling for Multi-modal Representation Learning},
  author={Kwon, Gukyeong and Cai, Zhaowei and Ravichandran, Avinash and Bas, Erhan and Bhotika, Rahul and Soatto, Stefano},
  journal={arXiv preprint arXiv:2208.02131},
  year={2022}
}

@article{patch,
  title={Patching open-vocabulary models by interpolating weights},
  author={Ilharco, Gabriel and Wortsman, Mitchell and Yitzhak Gadre, Samir and Song, Shuran and Hajishirzi, Hannaneh and Kornblith, Simon and Farhadi, Ali and Schmidt, Ludwig},
  journal={arXiv preprint arXiv:2208.05592},
  year={2022}
}

@article{ma2022x,
  title={X-CLIP: End-to-End Multi-grained Contrastive Learning for Video-Text Retrieval},
  author={Ma, Yiwei and Xu, Guohai and Sun, Xiaoshuai and Yan, Ming and Zhang, Ji and Ji, Rongrong},
  journal={arXiv preprint arXiv:2207.07285},
  year={2022}
}

@article{pfeiffer2020adapterhub,
  title={Adapterhub: A framework for adapting transformers},
  author={Pfeiffer, Jonas and R{\"u}ckl{\'e}, Andreas and Poth, Clifton and Kamath, Aishwarya and Vuli{\'c}, Ivan and Ruder, Sebastian and Cho, Kyunghyun and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2007.07779},
  year={2020}
}

@article{zhang2023prompt,
title={Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong Few-shot Learners},
author={Zhang, Renrui and Hu, Xiangfei and Li, Bohao and Huang, Siyuan and Deng, Hanqiu and Li, Hongsheng and Qiao, Yu and Gao, Peng},
journal={arXiv preprint arXiv:2303.02151},
year={2023}
}

@inproceedings{lu2021parameter,
  title={Parameter-Efficient Domain Knowledge Integration from Multiple Sources for Biomedical Pre-trained Language Models},
  author={Lu, Qiuhao and Dou, Dejing and Nguyen, Thien Huu},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2021},
  pages={3855--3865},
  year={2021}
}

@article{stickland2020recipes,
  title={Recipes for adapting pre-trained monolingual and multilingual models to machine translation},
  author={Stickland, Asa Cooper and Li, Xian and Ghazvininejad, Marjan},
  journal={arXiv preprint arXiv:2004.14911},
  year={2020}
}

@article{le2021lightweight,
  title={Lightweight adapter tuning for multilingual speech translation},
  author={Le, Hang and Pino, Juan and Wang, Changhan and Gu, Jiatao and Schwab, Didier and Besacier, Laurent},
  journal={arXiv preprint arXiv:2106.01463},
  year={2021}
}

@inproceedings{sung2022vl,
  title={Vl-adapter: Parameter-efficient transfer learning for vision-and-language tasks},
  author={Sung, Yi-Lin and Cho, Jaemin and Bansal, Mohit},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@article{yang2021survey,
  title={A survey of knowledge enhanced pre-trained models},
  author={Yang, Jian and Xiao, Gang and Shen, Yulong and Jiang, Wei and Hu, Xinyu and Zhang, Ying and Peng, Jinghui},
  journal={arXiv preprint arXiv:2110.00269},
  year={2021}
}

@article{zhang2021vtclip,
  title={VT-CLIP: Enhancing Vision-Language Models with Visual-guided Texts},
  author={Zhang, Renrui and Qiu, Longtian and Zhang, Wei and Zeng, Ziyao},
  journal={arXiv preprint arXiv:2112.02399},
  year={2021}
}

@article{ghiasi2021open,
  title={Open-vocabulary image segmentation},
  author={Ghiasi, Golnaz and Gu, Xiuye and Cui, Yin and Lin, Tsung-Yi},
  journal={arXiv preprint arXiv:2112.12143},
  year={2021}
}

@article{santurkar2022caption,
  title={Is a caption worth a thousand images? a controlled study for representation learning},
  author={Santurkar, Shibani and Dubois, Yann and Taori, Rohan and Liang, Percy and Hashimoto, Tatsunori},
  journal={arXiv preprint arXiv:2207.07635},
  year={2022}
}

@article{feuer2022caption,
  title={Caption supervision enables robust learners},
  author={Feuer, Benjamin and Joshi, Ameya and Hegde, Chinmay},
  journal={arXiv preprint arXiv:2210.07396},
  year={2022}
}

@article{shin2022reco,
  title={Reco: Retrieve and co-segment for zero-shot transfer},
  author={Shin, Gyungin and Xie, Weidi and Albanie, Samuel},
  journal={arXiv preprint arXiv:2206.07045},
  year={2022}
}

@inproceedings{du2022learning,
  title={Learning to Prompt for Open-Vocabulary Object Detection with Vision-Language Model},
  author={Du, Yu and Wei, Fangyun and Zhang, Zihe and Shi, Miaojing and Gao, Yue and Li, Guoqi},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}

@inproceedings{stablediffusion,
title = {High-Resolution Image Synthesis with Latent Diffusion Models},
author = {Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Bjarn Ommer},
year  = {2022},
booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
}

@article{chen2022promptplot,
  title={Prompt Learning with Optimal Transport for Vision-Language Models},
  author={Chen, Guangyi and Yao, Weiran and Song, Xiangchen and Li, Xinyue and Rao, Yongming and Zhang, Kun},
  journal={arXiv preprint arXiv:2210.01253},
  year={2022}
}

@article{pfeiffer2020mad,
  title={Mad-x: An adapter-based framework for multi-task cross-lingual transfer},
  author={Pfeiffer, Jonas and Vuli{\'c}, Ivan and Gurevych, Iryna and Ruder, Sebastian},
  journal={arXiv preprint arXiv:2005.00052},
  year={2020}
}

@inproceedings{thomas2022efficient,
  title={Efficient Adapter Transfer of Self-Supervised Speech Models for Automatic Speech Recognition},
  author={Thomas, Bethan and Kessler, Samuel and Karout, Salah},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7102--7106},
  year={2022},
  organization={IEEE}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2019}
}

@article{yang2022prompt,
  title={Prompt Tuning for Generative Multimodal Pretrained Models},
  author={Yang, Hao and Lin, Junyang and Yang, An and Wang, Peng and Zhou, Chang and Yang, Hongxia},
  journal={arXiv preprint arXiv:2208.02532},
  year={2022}
}

@article{derakhshani2022variational,
  title={Variational prompt tuning improves generalization of vision-language models},
  author={Derakhshani, Mohammad Mahdi and Sanchez, Enrique and Bulat, Adrian and da Costa, Victor Guilherme Turrisi and Snoek, Cees GM and Tzimiropoulos, Georgios and Martinez, Brais},
  journal={arXiv preprint arXiv:2210.02390},
  year={2022}
}

@article{proda,
title={Prompt Distribution Learning},
author={Lu, Yuning and Liu, Jianzhuang and Zhang, Yonggang and Liu, Yajing and Tian, Xinmei},
journal={arXiv preprint arXiv:2205.03340},
year={2022}
}

@article{zeng2022socratic,
  title={Socratic models: Composing zero-shot multimodal reasoning with language},
  author={Zeng, Andy and Wong, Adrian and Welker, Stefan and Choromanski, Krzysztof and Tombari, Federico and Purohit, Aveek and Ryoo, Michael and Sindhwani, Vikas and Lee, Johnny and Vanhoucke, Vincent and others},
  journal={arXiv preprint arXiv:2204.00598},
  year={2022}
}

@article{mokady2021clipcap,
  title={Clipcap: Clip prefix for image captioning},
  author={Mokady, Ron and Hertz, Amir and Bermano, Amit H},
  journal={arXiv preprint arXiv:2111.09734},
  year={2021}
}

@article{coca,
  title={CoCa: Contrastive Captioners are Image-Text
Foundation Models},
  author={Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  journal={arXiv preprint arXiv:2205.01917},
  year={2022}
}

@article{ge2022domain,
  title={Domain Adaptation via Prompt Learning},
  author={Ge, Chunjiang and Huang, Rui and Xie, Mixue and Lai, Zihang and Song, Shiji and Li, Shuang and Huang, Gao},
  journal={arXiv preprint arXiv:2202.06687},
  year={2022}
}

@article{hernandez2021scaling,
  title={Scaling laws for transfer},
  author={Hernandez, Danny and Kaplan, Jared and Henighan, Tom and McCandlish, Sam},
  journal={arXiv preprint arXiv:2102.01293},
  year={2021}
}

@article{li2022supporting,
  title={Supporting Vision-Language Model Inference with Causality-pruning Knowledge Prompt},
  author={Li, Jiangmeng and Mo, Wenyi and Qiang, Wenwen and Su, Bing and Zheng, Changwen},
  journal={arXiv preprint arXiv:2205.11100},
  year={2022}
}

@article{maji2013fine,
  title={Fine-grained visual classification of aircraft},
  author={Maji, Subhransu and Rahtu, Esa and Kannala, Juho and Blaschko, Matthew and Vedaldi, Andrea},
  journal={arXiv preprint arXiv:1306.5151},
  year={2013}
}

@article{helber2019eurosat,
  title={Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification},
  author={Helber, Patrick and Bischke, Benjamin and Dengel, Andreas and Borth, Damian},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  volume={12},
  number={7},
  pages={2217--2226},
  year={2019},
  publisher={IEEE}
}

@inproceedings{cimpoi2014describing,
  title={Describing textures in the wild},
  author={Cimpoi, Mircea and Maji, Subhransu and Kokkinos, Iasonas and Mohamed, Sammy and Vedaldi, Andrea},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2014}
}

@inproceedings{xiao2010sun,
  title={Sun database: Large-scale scene recognition from abbey to zoo},
  author={Xiao, Jianxiong and Hays, James and Ehinger, Krista A and Oliva, Aude and Torralba, Antonio},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2010}
}

@inproceedings{bossard2014food,
  title={Food-101--mining discriminative components with random forests},
  author={Bossard, Lukas and Guillaumin, Matthieu and Gool, Luc Van},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2014}
}

@inproceedings{parkhi2012cats,
  title={Cats and dogs},
  author={Parkhi, Omkar M and Vedaldi, Andrea and Zisserman, Andrew and Jawahar, CV},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2012}
}

@inproceedings{nilsback2008automated,
  title={Automated flower classification over a large number of classes},
  author={Nilsback, Maria-Elena and Zisserman, Andrew},
  booktitle={2008 Sixth Indian Conference on Computer Vision, Graphics \& Image Processing},
  pages={722--729},
  year={2008},
  organization={IEEE}
}

@inproceedings{fei2004learning,
  title={Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories},
  author={Fei-Fei, Li and Fergus, Rob and Perona, Pietro},
  booktitle={Conference on Computer Vision and Pattern Recognition Workshop (CVPR-W)},
  year={2004}
}

@article{soomro2012ucf101,
  title={UCF101: A dataset of 101 human actions classes from videos in the wild},
  author={Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
  journal={arXiv preprint arXiv:1212.0402},
  year={2012}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{loshchilov2016sgdr,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1608.03983},
  year={2016}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@article{schuhmann2021laion,
  title={Laion-400m: Open dataset of clip-filtered 400 million image-text pairs},
  author={Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
  journal={arXiv preprint arXiv:2111.02114},
  year={2021}
}

@inproceedings{lampert2009learning,
  title={Learning to detect unseen object classes by between-class attribute transfer},
  author={Lampert, Christoph H and Nickisch, Hannes and Harmeling, Stefan},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2009}
}

@inproceedings{mensink2014costa,
  title={Costa: Co-occurrence statistics for zero-shot classification},
  author={Mensink, Thomas and Gavves, Efstratios and Snoek, Cees GM},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2014}
}

@article{micikevicius2017mixed,
  title={Mixed precision training},
  author={Micikevicius, Paulius and Narang, Sharan and Alben, Jonah and Diamos, Gregory and Elsen, Erich and Garcia, David and Ginsburg, Boris and Houston, Michael and Kuchaiev, Oleksii and Venkatesh, Ganesh and others},
  journal={arXiv preprint arXiv:1710.03740},
  year={2017}
}

@article{zhang2021vt,
  title={VT-CLIP: Enhancing Vision-Language Models with Visual-guided Texts},
  author={Zhang, Renrui and Qiu, Longtian and Zhang, Wei and Zeng, Ziyao},
  journal={arXiv preprint arXiv:2112.02399},
  year={2021}
}

@inproceedings{wang2019learning,
        title={Learning Robust Global Representations by Penalizing Local Predictive Power},
        author={Wang, Haohan and Ge, Songwei and Lipton, Zachary and Xing, Eric P},
        booktitle={Advances in Neural Information Processing Systems},
        pages={10506--10518},
        year={2019}
}

@article{honnibal2017spacy,
  title={spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing},
  author={Honnibal, Matthew and Montani, Ines},
  journal={To appear},
  volume={7},
  number={1},
  pages={411--420},
  year={2017}
}

@inproceedings{koskenniemi1984general,
  title={A general computational model for word-form recognition and production},
  author={Koskenniemi, Kimmo},
  booktitle={10th International Conference on Computational Linguistics and 22nd Annual Meeting of the Association for Computational Linguistics},
  year={1984},
  organization={The Association for Computational Linguistics}
}

@article{lee2023holistic,
  title={Holistic evaluation of text-to-image models},
  author={Lee, Tony and Yasunaga, Michihiro and Meng, Chenlin and Mai, Yifan and Park, Joon Sung and Gupta, Agrim and Zhang, Yunzhi and Narayanan, Deepak and Teufel, Hannah and Bellagente, Marco and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@inproceedings{carlini2023extracting,
  title={Extracting training data from diffusion models},
  author={Carlini, Nicolas and Hayes, Jamie and Nasr, Milad and Jagielski, Matthew and Sehwag, Vikash and Tramer, Florian and Balle, Borja and Ippolito, Daphne and Wallace, Eric},
  booktitle={32nd USENIX Security Symposium (USENIX Security 23)},
  pages={5253--5270},
  year={2023}
}

@article{ho2022classifier,
  title={Classifier-free diffusion guidance},
  author={Ho, Jonathan and Salimans, Tim},
  journal={arXiv preprint arXiv:2207.12598},
  year={2022}
}

@inproceedings{cvae,
 author = {Sohn, Kihyuk and Lee, Honglak and Yan, Xinchen},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Learning Structured Output Representation using Deep Conditional Generative Models},
 url = {https://proceedings.neurips.cc/paper/2015/file/8d55a249e6baa5c06772297520da2051-Paper.pdf},
 volume = {28},
 year = {2015}
}

@article{van2016conditional,
  title={Conditional image generation with pixelcnn decoders},
  author={Van den Oord, Aaron and Kalchbrenner, Nal and Espeholt, Lasse and Vinyals, Oriol and Graves, Alex and others},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{hendrycks2021many,
  title={The many faces of robustness: A critical analysis of out-of-distribution generalization},
  author={Hendrycks, Dan and Basart, Steven and Mu, Norman and Kadavath, Saurav and Wang, Frank and Dorundo, Evan and Desai, Rahul and Zhu, Tyler and Parajuli, Samyak and Guo, Mike and others},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2021}
}

@article{wah2011caltech,
  title={The caltech-ucsd birds-200-2011 dataset},
  author={Wah, Catherine and Branson, Steve and Welinder, Peter and Perona, Pietro and Belongie, Serge},
  year={2011},
  publisher={California Institute of Technology}
}

@inproceedings{berg2014birdsnap,
  title={Birdsnap: Large-scale fine-grained visual categorization of birds},
  author={Berg, Thomas and Liu, Jiongxin and Woo Lee, Seung and Alexander, Michelle L and Jacobs, David W and Belhumeur, Peter N},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2014}
}

@article{griffin2007caltech,
  title={Caltech-256 object category dataset},
  author={Griffin, Gregory and Holub, Alex and Perona, Pietro},
  year={2007},
  publisher={California Institute of Technology}
}

@article{cifar,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada}
}

@article{gao2021clip,
  title={Clip-adapter: Better vision-language models with feature adapters},
  author={Gao, Peng and Geng, Shijie and Zhang, Renrui and Ma, Teli and Fang, Rongyao and Zhang, Yongfeng and Li, Hongsheng and Qiao, Yu},
  journal={arXiv preprint arXiv:2110.04544},
  year={2021}
}

@article{li2021value,
  title={Value: A multi-task benchmark for video-and-language understanding evaluation},
  author={Li, Linjie and Lei, Jie and Gan, Zhe and Yu, Licheng and Chen, Yen-Chun and Pillai, Rohit and Cheng, Yu and Zhou, Luowei and Wang, Xin Eric and Wang, William Yang and others},
  journal={arXiv preprint arXiv:2106.04632},
  year={2021}
}

@inproceedings{cao2020behind,
  title={Behind the scene: Revealing the secrets of pre-trained vision-and-language models},
  author={Cao, Jize and Gan, Zhe and Cheng, Yu and Yu, Licheng and Chen, Yen-Chun and Liu, Jingjing},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2020}
}

@masterthesis{udandarao2022understanding,
    author={Udandarao, Vishaal},
    title={Understanding and Fixing the Modality Gap in Vision-Language Models},
    school={University of Cambridge},
    year={2022}
}

@article{bulat2022languagelasp,
  title={Language-Aware Soft Prompting for Vision \& Language Foundation Models},
  author={Bulat, Adrian and Tzimiropoulos, Georgios},
  journal={arXiv preprint arXiv:2210.01115},
  year={2022}
}


@inproceedings{
he2023is,
title={Is synthetic data from generative models ready for image recognition?},
author={He, Ruifei and Sun, Shuyang and Yu, Xin and Xue, Chuhui and Zhang, Wenqing and Torr, Philip and Bai, Song and Qi, Xiaojuan},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023}
}
@article{ding2022promptsoftcpt,
  title={Prompt Tuning with Soft Context Sharing for Vision-Language Models},
  author={Ding, Kun and Wang, Ying and Liu, Pengzhang and Yu, Qiang and Zhang, Haojian and Xiang, Shiming and Pan, Chunhong},
  journal={arXiv preprint arXiv:2208.13474},
  year={2022}
}

@article{yao2021cpt,
  title={Cpt: Colorful prompt tuning for pre-trained vision-language models},
  author={Yao, Yuan and Zhang, Ao and Zhang, Zhengyan and Liu, Zhiyuan and Chua, Tat-Seng and Sun, Maosong},
  journal={arXiv preprint arXiv:2109.11797},
  year={2021}
}

@article{singh2021flava,
  title={FLAVA: A Foundational Language And Vision Alignment Model},
  author={Singh, Amanpreet and Hu, Ronghang and Goswami, Vedanuj and Couairon, Guillaume and Galuba, Wojciech and Rohrbach, Marcus and Kiela, Douwe},
  journal={arXiv preprint arXiv:2112.04482},
  year={2021}
}

@inproceedings{howard2019searching,
  title={Searching for mobilenetv3},
  author={Howard, Andrew and Sandler, Mark and Chu, Grace and Chen, Liang-Chieh and Chen, Bo and Tan, Mingxing and Wang, Weijun and Zhu, Yukun and Pang, Ruoming and Vasudevan, Vijay and others},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2019}
}

@article{zhou2021learning,
  title={Learning to prompt for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  journal={arXiv preprint arXiv:2109.01134},
  year={2021}
}

@inproceedings{khattab2020colbert,
  title={Colbert: Efficient and effective passage search via contextualized late interaction over bert},
  author={Khattab, Omar and Zaharia, Matei},
  booktitle={Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval},
  pages={39--48},
  year={2020}
}

@article{wang2020generalizing,
  title={Generalizing from a few examples: A survey on few-shot learning},
  author={Wang, Yaqing and Yao, Quanming and Kwok, James T and Ni, Lionel M},
  journal={ACM computing surveys (csur)},
  volume={53},
  number={3},
  pages={1--34},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{rebuffi2017learning,
  title={Learning multiple visual domains with residual adapters},
  author={Rebuffi, Sylvestre-Alvise and Bilen, Hakan and Vedaldi, Andrea},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{sun2022dualcoop,
  title={DualCoOp: Fast Adaptation to Multi-Label Recognition with Limited Annotations},
  author={Sun, Ximeng and Hu, Ping and Saenko, Kate},
  journal={arXiv preprint arXiv:2206.09541},
  year={2022}
}

@article{zhang2021tip,
  title={Tip-Adapter: Training-free CLIP-Adapter for Better Vision-Language Modeling},
  author={Zhang, Renrui and Fang, Rongyao and Gao, Peng and Zhang, Wei and Li, Kunchang and Dai, Jifeng and Qiao, Yu and Li, Hongsheng},
  journal={arXiv preprint arXiv:2111.03930},
  year={2021}
}

@misc{cambridgephoto,
  title = {{Cambridge University Alternative Prospectus}},
  howpublished = "\url{https://www.applytocambridge.com/assets/images/hero/engineering.jpg}",
  note = "[Online; accessed March-2022]"
}

@article{zeng2021multi,
  title={Multi-Grained Vision Language Pre-Training: Aligning Texts with Visual Concepts},
  author={Zeng, Yan and Zhang, Xinsong and Li, Hang},
  journal={arXiv preprint arXiv:2111.08276},
  year={2021}
}

@article{lu2021pretrained,
  title={Pretrained transformers as universal computation engines},
  author={Lu, Kevin and Grover, Aditya and Abbeel, Pieter and Mordatch, Igor},
  journal={ICLR},
  year={2021}
}

@article{derpanis2008bhattacharyya,
  title={The bhattacharyya measure},
  author={Derpanis, Konstantinos G},
  journal={Mendeley Computer},
  volume={1},
  number={4},
  pages={1990--1992},
  year={2008}
}

@article{menendez1997jensen,
  title={The jensen-shannon divergence},
  author={Men{\'e}ndez, ML and Pardo, JA and Pardo, L and Pardo, MC},
  journal={Journal of the Franklin Institute},
  volume={334},
  number={2},
  pages={307--318},
  year={1997},
  publisher={Elsevier}
}

@article{peyre2019computational,
  title={Computational optimal transport: With applications to data science},
  author={Peyr{\'e}, Gabriel and Cuturi, Marco and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={11},
  number={5-6},
  pages={355--607},
  year={2019},
  publisher={Now Publishers, Inc.}
}

@book{villani2009optimal,
  title={Optimal transport: old and new},
  author={Villani, C{\'e}dric},
  volume={338},
  year={2009},
  publisher={Springer}
}

@article{bao2019few,
  title={Few-shot text classification with distributional signatures},
  author={Bao, Yujia and Wu, Menghua and Chang, Shiyu and Barzilay, Regina},
  journal={arXiv preprint arXiv:1908.06039},
  year={2019}
}

@book{miller1998wordnet,
  title={WordNet: An electronic lexical database},
  author={Miller, George A},
  year={1998},
  publisher={MIT press}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2009}
}

@inproceedings{chao2016empirical,
  title={An empirical study and analysis of generalized zero-shot learning for object recognition in the wild},
  author={Chao, Wei-Lun and Changpinyo, Soravit and Gong, Boqing and Sha, Fei},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2016}
}

@article{adadi2018peeking,
  title={Peeking inside the black-box: a survey on explainable artificial intelligence (XAI)},
  author={Adadi, Amina and Berrada, Mohammed},
  journal={IEEE access},
  volume={6},
  pages={52138--52160},
  year={2018},
  publisher={IEEE}
}

@article{linardatos2020explainable,
  title={Explainable ai: A review of machine learning interpretability methods},
  author={Linardatos, Pantelis and Papastefanopoulos, Vasilis and Kotsiantis, Sotiris},
  journal={Entropy},
  volume={23},
  number={1},
  pages={18},
  year={2020},
  publisher={MDPI}
}

@article{vellido2020importance,
  title={The importance of interpretability and visualization in machine learning for applications in medicine and health care},
  author={Vellido, Alfredo},
  journal={Neural computing and applications},
  volume={32},
  number={24},
  pages={18069--18083},
  year={2020},
  publisher={Springer}
}

@article{vinyals2016matching,
  title={Matching networks for one shot learning},
  author={Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Wierstra, Daan and others},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{zhu2022prompt,
  title={Prompt-aligned Gradient for Prompt Tuning},
  author={Zhu, Beier and Niu, Yulei and Han, Yucheng and Wu, Yue and Zhang, Hanwang},
  journal={arXiv preprint arXiv:2205.14865},
  year={2022}
}

@article{jia2022visual,
  title={Visual prompt tuning},
  author={Jia, Menglin and Tang, Luming and Chen, Bor-Chun and Cardie, Claire and Belongie, Serge and Hariharan, Bharath and Lim, Ser-Nam},
  journal={arXiv preprint arXiv:2203.12119},
  year={2022}
}

@article{snell2017prototypical,
  title={Prototypical networks for few-shot learning},
  author={Snell, Jake and Swersky, Kevin and Zemel, Richard},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{you2022learning,
  title={Learning Visual Representation from Modality-Shared Contrastive Language-Image Pre-training},
  author={You, Haoxuan and Zhou, Luowei and Xiao, Bin and Codella, Noel and Cheng, Yu and Xu, Ruochen and Chang, Shih-Fu and Yuan, Lu},
  journal={arXiv preprint arXiv:2207.12661},
  year={2022}
}

@inproceedings{koppen2000curse,
  title={The curse of dimensionality},
  author={K{\"o}ppen, Mario},
  booktitle={5th online world conference on soft computing in industrial applications (WSC5)},
  volume={1},
  pages={4--8},
  year={2000}
}

@article{dou2022coarse,
  title={Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone},
  author={Dou, Zi-Yi and Kamath, Aishwarya and Gan, Zhe and Zhang, Pengchuan and Wang, Jianfeng and Li, Linjie and Liu, Zicheng and Liu, Ce and LeCun, Yann and Peng, Nanyun and others},
  journal={arXiv preprint arXiv:2206.07643},
  year={2022}
}

@article{minderer2022simple,
  title={Simple Open-Vocabulary Object Detection with Vision Transformers},
  author={Minderer, Matthias and Gritsenko, Alexey and Stone, Austin and Neumann, Maxim and Weissenborn, Dirk and Dosovitskiy, Alexey and Mahendran, Aravindh and Arnab, Anurag and Dehghani, Mostafa and Shen, Zhuoran and others},
  journal={arXiv preprint arXiv:2205.06230},
  year={2022}
}

@article{li2022fine,
  title={Fine-Grained Semantically Aligned Vision-Language Pre-Training},
  author={Li, Juncheng and He, Xin and Wei, Longhui and Qian, Long and Zhu, Linchao and Xie, Lingxi and Zhuang, Yueting and Tian, Qi and Tang, Siliang},
  journal={arXiv preprint arXiv:2208.02515},
  year={2022}
}

@inproceedings{li2022grounded,
  title={Grounded language-image pre-training},
  author={Li, Liunian Harold and Zhang, Pengchuan and Zhang, Haotian and Yang, Jianwei and Li, Chunyuan and Zhong, Yiwu and Wang, Lijuan and Yuan, Lu and Zhang, Lei and Hwang, Jenq-Neng and others},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@inproceedings{beery2018recognition,
  title={Recognition in terra incognita},
  author={Beery, Sara and Van Horn, Grant and Perona, Pietro},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2018}
}

@article{cossu2022continual,
  title={Continual Pre-Training Mitigates Forgetting in Language and Vision},
  author={Cossu, Andrea and Tuytelaars, Tinne and Carta, Antonio and Passaro, Lucia and Lomonaco, Vincenzo and Bacciu, Davide},
  journal={arXiv preprint arXiv:2205.09357},
  year={2022}
}

@article{srinivasan2022climb,
  title={CLiMB: A Continual Learning Benchmark for Vision-and-Language Tasks},
  author={Srinivasan, Tejas and Chang, Ting-Yun and Alva, Leticia Leonor Pinto and Chochlakis, Georgios and Rostami, Mohammad and Thomason, Jesse},
  journal={arXiv preprint arXiv:2206.09059},
  year={2022}
}

@inproceedings{christie2018functional,
  title={Functional map of the world},
  author={Christie, Gordon and Fendley, Neil and Wilson, James and Mukherjee, Ryan},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018}
}

@article{kermany2018identifying,
  title={Identifying medical diagnoses and treatable diseases by image-based deep learning},
  author={Kermany, Daniel S and Goldbaum, Michael and Cai, Wenjia and Valentim, Carolina CS and Liang, Huiying and Baxter, Sally L and McKeown, Alex and Yang, Ge and Wu, Xiaokang and Yan, Fangbing and others},
  journal={Cell},
  volume={172},
  number={5},
  pages={1122--1131},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{pedersen2004wordnet,
  title={WordNet:: Similarity-Measuring the Relatedness of Concepts.},
  author={Pedersen, Ted and Patwardhan, Siddharth and Michelizzi, Jason and others},
  booktitle={AAAI},
  volume={4},
  pages={25--29},
  year={2004}
}

@inproceedings{fang2022data,
  title={Data determines distributional robustness in contrastive language image pre-training (clip)},
  author={Fang, Alex and Ilharco, Gabriel and Wortsman, Mitchell and Wan, Yuhao and Shankar, Vaishaal and Dave, Achal and Schmidt, Ludwig},
  booktitle={International Conference on Machine Learning},
  pages={6216--6234},
  year={2022},
  organization={PMLR}
}

@inproceedings{wortsman2022robust,
  title={Robust fine-tuning of zero-shot models},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Kim, Jong Wook and Li, Mike and Kornblith, Simon and Roelofs, Rebecca and Lopes, Raphael Gontijo and Hajishirzi, Hannaneh and Farhadi, Ali and Namkoong, Hongseok and others},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@article{pantazis2022svladapter,
  title={SVL-Adapter: Self-Supervised Adapter for Vision-Language Pretrained Models},
  author={Pantazis, Omiros and Brostow, Gabriel and Jones, Kate and Mac Aodha, Oisin},
  journal={arXiv preprint arXiv:2210.03794},
  year={2022}
}

@article{pratt2022doescupl,
  title={What does a platypus look like? Generating customized prompts for zero-shot image classification},
  author={Pratt, Sarah and Liu, Rosanne and Farhadi, Ali},
  journal={arXiv preprint arXiv:2209.03320},
  year={2022}
}

@article{huang2022unsupervisedupl,
  title={Unsupervised Prompt Learning for Vision-Language Models},
  author={Huang, Tony and Chu, Jack and Wei, Fangyun},
  journal={arXiv preprint arXiv:2204.03649},
  year={2022}
}

@article{guo2022calip,
  title={CALIP: Zero-Shot Enhancement of CLIP with Parameter-free Attention},
  author={Guo, Ziyu and Zhang, Renrui and Qiu, Longtian and Ma, Xianzheng and Miao, Xupeng and He, Xuming and Cui, Bin},
  journal={arXiv preprint arXiv:2209.14169},
  year={2022}
}

@article{pham2021combined,
  title={Combined scaling for zero-shot transfer learning},
  author={Pham, Hieu and Dai, Zihang and Ghiasi, Golnaz and Liu, Hanxiao and Yu, Adams Wei and Luong, Minh-Thang and Tan, Mingxing and Le, Quoc V},
  journal={arXiv preprint arXiv:2111.10050},
  year={2021}
}

@article{cosentino2022toward,
  title={Toward a Geometrical Understanding of Self-supervised Contrastive Learning},
  author={Cosentino, Romain and Sengupta, Anirvan and Avestimehr, Salman and Soltanolkotabi, Mahdi and Ortega, Antonio and Willke, Ted and Tepper, Mariano},
  journal={arXiv preprint arXiv:2205.06926},
  year={2022}
}

@inproceedings{graf2021dissecting,
  title={Dissecting supervised constrastive learning},
  author={Graf, Florian and Hofer, Christoph and Niethammer, Marc and Kwitt, Roland},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2021}
}

@article{qiao2012explicit,
  title={An explicit nonlinear mapping for manifold learning},
  author={Qiao, Hong and Zhang, Peng and Wang, Di and Zhang, Bo},
  journal={IEEE transactions on cybernetics},
  volume={43},
  number={1},
  pages={51--63},
  year={2012},
  publisher={IEEE}
}

@inproceedings{sun2014information,
  title={An information geometry of statistical manifold learning},
  author={Sun, Ke and Marchand-Maillet, St{\'e}phane},
  booktitle={International Conference on Machine Learning},
  pages={1--9},
  year={2014},
  organization={PMLR}
}

@article{arvanitidis2020geometrically,
  title={Geometrically enriched latent spaces},
  author={Arvanitidis, Georgios and Hauberg, S{\o}ren and Sch{\"o}lkopf, Bernhard},
  journal={arXiv preprint arXiv:2008.00565},
  year={2020}
}

@inproceedings{shao2018riemannian,
  title={The riemannian geometry of deep generative models},
  author={Shao, Hang and Kumar, Abhishek and Thomas Fletcher, P},
  booktitle={Conference on Computer Vision and Pattern Recognition Workshops (CVPR-W)},
  year={2018}
}
@inproceedings{shukla2018geometry,
  title={Geometry of deep generative models for disentangled representations},
  author={Shukla, Ankita and Uppal, Shagun and Bhagat, Sarthak and Anand, Saket and Turaga, Pavan},
  booktitle={Proceedings of the 11th Indian Conference on Computer Vision, Graphics and Image Processing},
  pages={1--8},
  year={2018}
}

@article{zhou2022conditional,
  title={Conditional Prompt Learning for Vision-Language Models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  journal={arXiv preprint arXiv:2203.05557},
  year={2022}
}

@article{novack2023chils,
  title={Chils: Zero-shot image classification with hierarchical label sets},
  author={Novack, Zachary and Garg, Saurabh and McAuley, Julian and Lipton, Zachary C},
  journal={arXiv preprint arXiv:2302.02551},
  year={2023}
}

@article{zhou2023distribution,
  title={Distribution Normalization: An ``Effortless'' Test-Time Augmentation for Contrastively Learned Visual-language Models},
  author={Zhou, Yifei and Ren, Juntao and Li, Fengyu and Zabih, Ramin and Lim, Ser-Nam},
  journal={arXiv preprint arXiv:2302.11084},
  year={2023}
}

@inproceedings{fergus2005learning,
  title={Learning object categories from google's image search},
  author={Fergus, Robert and Fei-Fei, Li and Perona, Pietro and Zisserman, Andrew},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2005}
}

@article{menon2022visual,
  title={Visual Classification via Description from Large Language Models},
  author={Menon, Sachit and Vondrick, Carl},
  journal={arXiv preprint arXiv:2210.07183},
  year={2022}
}

% ------------------------------------------------------------------------

@article{shin2022namedmask,
  title={NamedMask: Distilling Segmenters from Complementary Foundation Models},
  author={Shin, Gyungin and Xie, Weidi and Albanie, Samuel},
  journal={arXiv preprint arXiv:2209.11228},
  year={2022}
}

@inproceedings{changpinyo2021conceptual,
  title={Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts},
  author={Changpinyo, Soravit and Sharma, Piyush and Ding, Nan and Soricut, Radu},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}

@inproceedings{kandpal2023large,
  title={Large language models struggle to learn long-tail knowledge},
  author={Kandpal, Nikhil and Deng, Haikang and Roberts, Adam and Wallace, Eric and Raffel, Colin},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={15696--15707},
  year={2023},
  organization={PMLR}
}

@inproceedings{kolesnikov2020big,
  title={Big transfer (bit): General visual representation learning},
  author={Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Puigcerver, Joan and Yung, Jessica and Gelly, Sylvain and Houlsby, Neil},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2020}
}

@inproceedings{udandarao2023sus,
  title={Sus-x: Training-free name-only transfer of vision-language models},
  author={Udandarao, Vishaal and Gupta, Ankush and Albanie, Samuel},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2023}
}

@inproceedings{bao2021beit,
  title={Beit: Bert pre-training of image transformers},
  author={Bao, Hangbo and Dong, Li and Piao, Songhao and Wei, Furu},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2022}
}

@article{kang2023impact,
  title={Impact of co-occurrence on factual knowledge of large language models},
  author={Kang, Cheongwoong and Choi, Jaesik},
  journal={arXiv preprint arXiv:2310.08256},
  year={2023}
}


@article{parashar2024neglected,
  title={The Neglected Tails of Vision-Language Models},
  author={Parashar, Shubham and Lin, Zhiqiu and Liu, Tian and Dong, Xiangjue and Li, Yanan and Ramanan, Deva and Caverlee, James and Kong, Shu},
  journal={CVPR},
  year={2024}
}

@inproceedings{bellagente2024multifusion,
  title={Multifusion: Fusing pre-trained models for multi-lingual, multi-modal image generation},
  author={Bellagente, Marco and Brack, Manuel and Teufel, Hannah and Friedrich, Felix and Deiseroth, Bj{\"o}rn and Eichenberg, Constantin and Dai, Andrew M and Baldock, Robert and Nanda, Souradeep and Oostermeijer, Koen and others},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2023}
}

@inproceedings{kang2023scaling,
  title={Scaling up gans for text-to-image synthesis},
  author={Kang, Minguk and Zhu, Jun-Yan and Zhang, Richard and Park, Jaesik and Shechtman, Eli and Paris, Sylvain and Park, Taesung},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}

@article{birhane2024into,
  title={Into the LAION’s Den: Investigating hate in multimodal datasets},
  author={Birhane, Abeba and Han, Sanghyun and Boddeti, Vishnu and Luccioni, Sasha and others},
  journal={Advances in Neural Information Processing Systems},
  year={2023}
}

@misc{Dayma_DALL·E_Mini_2021,
      author = {Dayma, Boris and Patil, Suraj and Cuenca, Pedro and Saifullah, Khalid and Abraham, Tanishq and Le Khac, Phuc and Melas, Luke and Ghosh, Ritobrata},
      doi = {10.5281/zenodo.5146400},
      month = {7},
      title = {DALL·E Mini},
      url = {https://github.com/borisdayma/dalle-mini},
      year = {2021}
}

@misc{kakaobrain2021minDALL-E,
  title={minDALL-E on Conceptual Captions},
  author = {Saehoon, Kim and Sanghun, Cho and Chiheon, Kim and Lee, Doyup and Baek, Woonhyuk},
  year = {2021},
  howpublished  = {\url{https://github.com/kakaobrain/minDALL-E}},
}

@software{ilharco2021openclip,
  author       = {Ilharco, Gabriel and
                  Wortsman, Mitchell and
                  Wightman, Ross and
                  Gordon, Cade and
                  Carlini, Nicholas and
                  Taori, Rohan and
                  Dave, Achal and
                  Shankar, Vaishaal and
                  Namkoong, Hongseok and
                  Miller, John and
                  Hajishirzi, Hannaneh and
                  Farhadi, Ali and
                  Schmidt, Ludwig},
  title        = {OpenCLIP},
  month        = jul,
  year         = 2021,
  publisher    = {Zenodo},
  version      = {0.1},
  doi          = {10.5281/zenodo.5143773},
  url          = {https://doi.org/10.5281/zenodo.5143773}
}

@misc{Lexica_2024,
    title = {Lexica Search with Stable Diffusion v1.5 (1B)},
    howpublished = {\url{https://lexica.art/?q=stable+diffusion+1.5}}
}

@misc{wikidata_human,
    title = {Human (Q5)},
    howpublished = {\url{https://www.wikidata.org/wiki/Q5}}
}

@inproceedings{lee2022deduplicating,
  title={Deduplicating Training Data Makes Language Models Better},
  author={Lee, Katherine and Ippolito, Daphne and Nystrom, Andrew and Zhang, Chiyuan and Eck, Douglas and Callison-Burch, Chris and Carlini, Nicholas},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={8424--8445},
  year={2022}
}

@inproceedings{carlini2023quantifying,
  title={Quantifying Memorization Across Neural Language Models},
  author={Carlini, Nicholas and Ippolito, Daphne and Jagielski, Matthew and Lee, Katherine and Tramer, Florian and Zhang, Chiyuan},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}

@book{hadfield2021principal,
  title={The Principal--Agent Alignment Problem in Artificial Intelligence},
  author={Hadfield-Menell, Dylan Jasper},
  year={2021},
  publisher={University of California, Berkeley}
}

@misc{deepfloyd2023,
    title = {DeepFloyd IF},
    year = {2023},
    howpublished = {\url{https://github.com/deep-floyd/IF}}
}

@misc{dreamlike_photoreal,
    title = {Dreamlike Photoreal v2.0},
    howpublished = {\url{https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0}}
}

@misc{dreamlike_diffusion,
    title = {Dreamlike Diffusion v1.0},
    howpublished = {\url{https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0}}
}


@misc{openjourney1,
    title = {Openjourney v1 },
    howpublished = {\url{https://huggingface.co/prompthero/openjourney}}
}

@misc{openjourney2,
    title = {Openjourney v2 },
    howpublished = {\url{https://huggingface.co/prompthero/openjourney-v4}}
}

@misc{redshift,
    title = {Redshift Diffusion },
    howpublished = {\url{https://huggingface.co/nitrosocke/redshift-diffusion}}
}

@article{esser2024scaling,
  title={Scaling Rectified Flow Transformers for High-Resolution Image Synthesis},
  author={Esser, Patrick and Kulal, Sumith and Blattmann, Andreas and Entezari, Rahim and M{\"u}ller, Jonas and Saini, Harry and Levi, Yam and Lorenz, Dominik and Sauer, Axel and Boesel, Frederic and others},
  journal={arXiv preprint arXiv:2403.03206},
  year={2024}
}

@software{ilharco_gabriel_2021_5143773,
  author       = {Ilharco, Gabriel and
                  Wortsman, Mitchell and
                  Wightman, Ross and
                  Gordon, Cade and
                  Carlini, Nicholas and
                  Taori, Rohan and
                  Dave, Achal and
                  Shankar, Vaishaal and
                  Namkoong, Hongseok and
                  Miller, John and
                  Hajishirzi, Hannaneh and
                  Farhadi, Ali and
                  Schmidt, Ludwig},
  title        = {OpenCLIP},
  month        = jul,
  year         = 2021,
  note         = {If you use this software, please cite it as below.},
  publisher    = {Zenodo},
  version      = {0.1},
  doi          = {10.5281/zenodo.5143773},
  url          = {https://doi.org/10.5281/zenodo.5143773}
}

@misc{vintedois,
    title = {Vintedois (22h) Diffusion model v0.1},
    howpublished = {\url{https://huggingface.co/22h/vintedois-diffusion-v0-1}}
}


@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{dehouche2023s,
  title={What’s in a text-to-image prompt? The potential of stable diffusion in visual arts education},
  author={Dehouche, Nassim and Dehouche, Kullathida},
  journal={Heliyon},
  year={2023},
  publisher={Elsevier}
}

@article{baack2024training,
  title={Training Data for the Price of a Sandwich1},
  author={Baack, Stefan and Insights, Mozilla},
  year={2024}
}

@inproceedings{
podell2024sdxl,
title={{SDXL}: Improving Latent Diffusion Models for High-Resolution Image Synthesis},
author={Dustin Podell and Zion English and Kyle Lacey and Andreas Blattmann and Tim Dockhorn and Jonas M{\"u}ller and Joe Penna and Robin Rombach},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024}
}

@article{mccoy2023embers,
  title={Embers of autoregression: Understanding large language models through the problem they are trained to solve},
  author={McCoy, R Thomas and Yao, Shunyu and Friedman, Dan and Hardy, Matthew and Griffiths, Thomas L},
  journal={arXiv preprint arXiv:2309.13638},
  year={2023}
}

@inproceedings{garcia2023uncurated,
  title={Uncurated image-text datasets: Shedding light on demographic bias},
  author={Garcia, Noa and Hirota, Yusuke and Wu, Yankun and Nakashima, Yuta},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6957--6966},
  year={2023}
}

@article{fu2024dreamsim,
  title={DreamSim: Learning New Dimensions of Human Visual Similarity using Synthetic Data},
  author={Fu, Stephanie and Tamir, Netanel and Sundaram, Shobhita and Chai, Lucy and Zhang, Richard and Dekel, Tali and Isola, Phillip},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@article{minderer2024scaling,
  title={Scaling open-vocabulary object detection},
  author={Minderer, Matthias and Gritsenko, Alexey and Houlsby, Neil},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@inproceedings{shahmohammadi2023vipe,
  title={ViPE: Visualise Pretty-much Everything},
  author={Shahmohammadi, Hassan and Ghosh, Adhiraj and Lensch, Hendrik},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={5477--5494},
  year={2023}
}

@article{hao2024optimizing,
  title={Optimizing prompts for text-to-image generation},
  author={Hao, Yaru and Chi, Zewen and Dong, Li and Wei, Furu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{hupkes2020compositionality,
  title={Compositionality decomposed: How do neural networks generalise?},
  author={Hupkes, Dieuwke and Dankers, Verna and Mul, Mathijs and Bruni, Elia},
  journal={Journal of Artificial Intelligence Research},
  volume={67},
  pages={757--795},
  year={2020}
}

@inproceedings{lake2018generalization,
  title={Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks},
  author={Lake, Brenden and Baroni, Marco},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2018}
}

@inproceedings{zelle1996learning,
  title={Learning to parse database queries using inductive logic programming},
  author={Zelle, John M and Mooney, Raymond J},
  booktitle={Proceedings of the national conference on artificial intelligence},
  pages={1050--1055},
  year={1996}
}

@inproceedings{
yu2024skillmix,
title={Skill-Mix: a Flexible and Expandable Family of Evaluations for {AI} Models},
author={Dingli Yu and Simran Kaur and Arushi Gupta and Jonah Brown-Cohen and Anirudh Goyal and Sanjeev Arora},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=Jf5gplvglq}
}

@article{gpt4,
  title={Gpt-4 technical report},
  author={OpenAI},
  year={2023}
}

@article{gadre2024language,
  title={Language models scale reliably with over-training and on downstream tasks},
  author={Gadre, Samir Yitzhak and Smyrnis, Georgios and Shankar, Vaishaal and Gururangan, Suchin and Wortsman, Mitchell and Shao, Rulin and Mercat, Jean and Fang, Alex and Li, Jeffrey and Keh, Sedrick and others},
  journal={arXiv preprint arXiv:2403.08540},
  year={2024}
}

@article{penedo2023refinedweb,
  title={The RefinedWeb dataset for Falcon LLM: outperforming curated corpora with web data, and web data only},
  author={Penedo, Guilherme and Malartic, Quentin and Hesslow, Daniel and Cojocaru, Ruxandra and Cappelli, Alessandro and Alobeidli, Hamza and Pannier, Baptiste and Almazrouei, Ebtesam and Launay, Julien},
  journal={arXiv preprint arXiv:2306.01116},
  year={2023}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@misc{Gokaslan2019OpenWeb,  
	title={OpenWebText Corpus},
	author={Aaron Gokaslan and Vanya Cohen},
	year={2019}
}

@software{together2023redpajama,
  author = {Together Computer},
  title = {RedPajama: an Open Dataset for Training Large Language Models},
  month = October,
  year = 2023,
  url = {https://github.com/togethercomputer/RedPajama-Data}
}

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

@misc{yauney2023datasimilarityexplainlanguage,
      title={Data Similarity is Not Enough to Explain Language Model Performance}, 
      author={Gregory Yauney and Emily Reif and David Mimno},
      year={2023},
      eprint={2311.09006},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.09006}, 
}

@misc{kandpal2023largelanguagemodelsstruggle,
      title={Large Language Models Struggle to Learn Long-Tail Knowledge}, 
      author={Nikhil Kandpal and Haikang Deng and Adam Roberts and Eric Wallace and Colin Raffel},
      year={2023},
      eprint={2211.08411},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2211.08411}, 
}

@misc{udandarao2024zeroshotexponentialdatapretraining,
      title={No "Zero-Shot" Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance}, 
      author={Vishaal Udandarao and Ameya Prabhu and Adhiraj Ghosh and Yash Sharma and Philip H. S. Torr and Adel Bibi and Samuel Albanie and Matthias Bethge},
      year={2024},
      eprint={2404.04125},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2404.04125}, 
}