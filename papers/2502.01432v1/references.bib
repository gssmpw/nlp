% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

@inproceedings{Bhattamishra2020OnTA,
  title={On the Ability and Limitations of Transformers to Recognize Formal Languages},
  author={S. Bhattamishra and Kabir Ahuja and Navin Goyal},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2020},
  url={https://api.semanticscholar.org/CorpusID:222225236}
}

@misc{ackerman2020surveyneuralnetworksformal,
      title={A Survey of Neural Networks and Formal Languages}, 
      author={Joshua Ackerman and George Cybenko},
      year={2020},
      eprint={2006.01338},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2006.01338}, 
}

@article{strobl-etal-2024-formal,
    title = "What Formal Languages Can Transformers Express? A Survey",
    author = "Strobl, Lena  and
      Merrill, William  and
      Weiss, Gail  and
      Chiang, David  and
      Angluin, Dana",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "12",
    year = "2024",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2024.tacl-1.30/",
    doi = "10.1162/tacl_a_00663",
    pages = "543--561",
    abstract = "As transformers have gained prominence in natural language processing, some researchers have investigated theoretically what problems they can and cannot solve, by treating problems as formal languages. Exploring such questions can help clarify the power of transformers relative to other models of computation, their fundamental capabilities and limits, and the impact of architectural choices. Work in this subarea has made considerable progress in recent years. Here, we undertake a comprehensive survey of this work, documenting the diverse assumptions that underlie different results and providing a unified framework for harmonizing seemingly contradictory findings."
}

@inproceedings{hahn-rofin-2024-sensitive,
    title = "Why are Sensitive Functions Hard for Transformers?",
    author = "Hahn, Michael  and
      Rofin, Mark",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.800/",
    doi = "10.18653/v1/2024.acl-long.800",
    pages = "14973--15008",
    abstract = "Empirical studies have identified a range of learnability biases and limitations of transformers, such as a persistent difficulty in learning to compute simple formal languages such as PARITY, and a bias towards low-degree functions. However, theoretical understanding remains limited, with existing expressiveness theory either overpredicting or underpredicting realistic learning abilities. We prove that, under the transformer architecture, the loss landscape is constrained by the input-space sensitivity: Transformers whose output is sensitive to many parts of the input string inhabit isolated points in parameter space, leading to a low-sensitivity bias in generalization. We show theoretically and empirically that this theory unifies a broad array of empirical observations about the learning abilities and biases of transformers, such as their generalization bias towards low sensitivity and low degree, and difficulty in length generalization for PARITY. This shows that understanding transformers' inductive biases requires studying not just their in-principle expressivity, but also their loss landscape."
}

@misc{pérez2019turingcompletenessmodernneural,
      title={On the Turing Completeness of Modern Neural Network Architectures}, 
      author={Jorge Pérez and Javier Marinković and Pablo Barceló},
      year={2019},
      eprint={1901.03429},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1901.03429}, 
}

@misc{zhou2023algorithmstransformerslearnstudy,
      title={What Algorithms can Transformers Learn? A Study in Length Generalization}, 
      author={Hattie Zhou and Arwen Bradley and Etai Littwin and Noam Razin and Omid Saremi and Josh Susskind and Samy Bengio and Preetum Nakkiran},
      year={2023},
      eprint={2310.16028},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.16028}, 
}


@misc{zhang2024transformerbasedmodelsperfectlearning,
      title={Transformer-Based Models Are Not Yet Perfect At Learning to Emulate Structural Recursion}, 
      author={Dylan Zhang and Curt Tigges and Zory Zhang and Stella Biderman and Maxim Raginsky and Talia Ringer},
      year={2024},
      eprint={2401.12947},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.12947}, 
}

@inproceedings{kornai-1985-natural,
    title = "Natural Languages and the {C}homsky Hierarchy",
    author = "Kornai, Andr{\'a}s",
    editor = "King, Maghi",
    booktitle = "Second Conference of the {E}uropean Chapter of the Association for Computational Linguistics",
    month = mar,
    year = "1985",
    address = "Geneva, Switzerland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/E85-1001/"
}

@misc{rai2024practicalreviewmechanisticinterpretability,
      title={A Practical Review of Mechanistic Interpretability for Transformer-Based Language Models}, 
      author={Daking Rai and Yilun Zhou and Shi Feng and Abulhair Saparov and Ziyu Yao},
      year={2024},
      eprint={2407.02646},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.02646}, 
}

@inproceedings{
park2023the,
title={The Linear Representation Hypothesis and the Geometry of Large Language Models},
author={Kiho Park and Yo Joong Choe and Victor Veitch},
booktitle={Causal Representation Learning Workshop at NeurIPS 2023},
year={2023},
url={https://openreview.net/forum?id=T0PoOJg8cK}
}

@article{belinkov-2022-probing,
    title = "Probing Classifiers: Promises, Shortcomings, and Advances",
    author = "Belinkov, Yonatan",
    journal = "Computational Linguistics",
    volume = "48",
    number = "1",
    month = mar,
    year = "2022",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2022.cl-1.7/",
    doi = "10.1162/coli_a_00422",
    pages = "207--219",
    abstract = "Probing classifiers have emerged as one of the prominent methodologies for interpreting and analyzing deep neural network models of natural language processing. The basic idea is simple{---}a classifier is trained to predict some linguistic property from a model`s representations{---}and has been used to examine a wide variety of models and properties. However, recent studies have demonstrated various methodological limitations of this approach. This squib critically reviews the probing classifiers framework, highlighting their promises, shortcomings, and advances."
}

@inproceedings{li-etal-2021-implicit,
    title = "Implicit Representations of Meaning in Neural Language Models",
    author = "Li, Belinda Z.  and
      Nye, Maxwell  and
      Andreas, Jacob",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.143/",
    doi = "10.18653/v1/2021.acl-long.143",
    pages = "1813--1827",
    abstract = "Does the effectiveness of neural language models derive entirely from accurate modeling of surface word co-occurrence statistics, or do these models represent and reason about the world they describe? In BART and T5 transformer language models, we identify contextual word representations that function as *models of entities and situations* as they evolve throughout a discourse. These neural representations have functional similarities to linguistic models of dynamic semantics: they support a linear readout of each entity`s current properties and relations, and can be manipulated with predictable effects on language generation. Our results indicate that prediction in pretrained neural language models is supported, at least in part, by dynamic representations of meaning and implicit simulation of entity state, and that this behavior can be learned with only text as training data."
}

@inproceedings{abdou-etal-2021-language,
    title = "Can Language Models Encode Perceptual Structure Without Grounding? A Case Study in Color",
    author = "Abdou, Mostafa  and
      Kulmizev, Artur  and
      Hershcovich, Daniel  and
      Frank, Stella  and
      Pavlick, Ellie  and
      S{\o}gaard, Anders",
    editor = "Bisazza, Arianna  and
      Abend, Omri",
    booktitle = "Proceedings of the 25th Conference on Computational Natural Language Learning",
    month = nov,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.conll-1.9/",
    doi = "10.18653/v1/2021.conll-1.9",
    pages = "109--132",
    abstract = "Pretrained language models have been shown to encode relational information, such as the relations between entities or concepts in knowledge-bases {---} (Paris, Capital, France). However, simple relations of this type can often be recovered heuristically and the extent to which models implicitly reflect topological structure that is grounded in world, such as perceptual structure, is unknown. To explore this question, we conduct a thorough case study on color. Namely, we employ a dataset of monolexemic color terms and color chips represented in CIELAB, a color space with a perceptually meaningful distance metric. Using two methods of evaluating the structural alignment of colors in this space with text-derived color term representations, we find significant correspondence. Analyzing the differences in alignment across the color spectrum, we find that warmer colors are, on average, better aligned to the perceptual color space than cooler ones, suggesting an intriguing connection to findings from recent work on efficient communication in color naming. Further analysis suggests that differences in alignment are, in part, mediated by collocationality and differences in syntactic usage, posing questions as to the relationship between color perception and usage and context."
}

@misc{li2024emergentworldrepresentationsexploring,
      title={Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task}, 
      author={Kenneth Li and Aspen K. Hopkins and David Bau and Fernanda Viégas and Hanspeter Pfister and Martin Wattenberg},
      year={2024},
      eprint={2210.13382},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2210.13382}, 
}

@misc{vafa2024evaluatingworldmodelimplicit,
      title={Evaluating the World Model Implicit in a Generative Model}, 
      author={Keyon Vafa and Justin Y. Chen and Ashesh Rambachan and Jon Kleinberg and Sendhil Mullainathan},
      year={2024},
      eprint={2406.03689},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.03689}, 
}

@misc{elhage2022toymodelssuperposition,
      title={Toy Models of Superposition}, 
      author={Nelson Elhage and Tristan Hume and Catherine Olsson and Nicholas Schiefer and Tom Henighan and Shauna Kravec and Zac Hatfield-Dodds and Robert Lasenby and Dawn Drain and Carol Chen and Roger Grosse and Sam McCandlish and Jared Kaplan and Dario Amodei and Martin Wattenberg and Christopher Olah},
      year={2022},
      eprint={2209.10652},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2209.10652}, 
}

@misc{hewitt2019designinginterpretingprobescontrol,
      title={Designing and Interpreting Probes with Control Tasks}, 
      author={John Hewitt and Percy Liang},
      year={2019},
      eprint={1909.03368},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1909.03368}, 
}

@article{hahn-2020-theoretical,
    title = "Theoretical Limitations of Self-Attention in Neural Sequence Models",
    author = "Hahn, Michael",
    editor = "Johnson, Mark  and
      Roark, Brian  and
      Nenkova, Ani",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "8",
    year = "2020",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2020.tacl-1.11/",
    doi = "10.1162/tacl_a_00306",
    pages = "156--171",
    abstract = "Transformers are emerging as the new workhorse of NLP, showing great success across tasks. Unlike LSTMs, transformers process input sequences entirely through self-attention. Previous work has suggested that the computational capabilities of self-attention to process hierarchical structures are limited. In this work, we mathematically investigate the computational power of self-attention to model formal languages. Across both soft and hard attention, we show strong theoretical limitations of the computational abilities of self-attention, finding that it cannot model periodic finite-state languages, nor hierarchical structure, unless the number of layers or heads increases with input length. These limitations seem surprising given the practical success of self-attention and the prominent role assigned to hierarchical structure in linguistics, suggesting that natural language can be approximated well with models that are too weak for the formal languages typically assumed in theoretical linguistics."
}

@inproceedings{nandaprogress,
  title={Progress measures for grokking via mechanistic interpretability},
  author={Nanda, Neel and Chan, Lawrence and Lieberum, Tom and Smith, Jess and Steinhardt, Jacob},
  booktitle={The Eleventh International Conference on Learning Representations}
}

@article{Jger2012FormalLT,
  title={Formal language theory: refining the Chomsky hierarchy},
  author={Gerhard J{\"a}ger and James Rogers},
  journal={Philosophical Transactions of the Royal Society B: Biological Sciences},
  year={2012},
  volume={367},
  pages={1956 - 1970},
  url={https://api.semanticscholar.org/CorpusID:8765815}
}

@misc{yun2020transformersuniversalapproximatorssequencetosequence,
      title={Are Transformers universal approximators of sequence-to-sequence functions?}, 
      author={Chulhee Yun and Srinadh Bhojanapalli and Ankit Singh Rawat and Sashank J. Reddi and Sanjiv Kumar},
      year={2020},
      eprint={1912.10077},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1912.10077}, 
}

@inproceedings{NEURIPS2023_771155ab,
 author = {Lindner, David and Kramar, Janos and Farquhar, Sebastian and Rahtz, Matthew and McGrath, Tom and Mikulik, Vladimir},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {37876--37899},
 publisher = {Curran Associates, Inc.},
 title = {Tracr: Compiled Transformers as a Laboratory for Interpretability},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/771155abaae744e08576f1f3b4b7ac0d-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}

@misc{1912.10077,
Author = {Chulhee Yun and Srinadh Bhojanapalli and Ankit Singh Rawat and Sashank J. Reddi and Sanjiv Kumar},
Title = {Are Transformers universal approximators of sequence-to-sequence functions?},
Year = {2019},
Eprint = {arXiv:1912.10077},
}

@inproceedings{voita2019analyzingattention,
    title = "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned",
    author = "Voita, Elena  and
      Talbot, David  and
      Moiseev, Fedor  and
      Sennrich, Rico  and
      Titov, Ivan",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1580/",
    doi = "10.18653/v1/P19-1580",
    pages = "5797--5808",
    abstract = "Multi-head self-attention is a key component of the Transformer, a state-of-the-art architecture for neural machine translation. In this work we evaluate the contribution made by individual attention heads to the overall performance of the model and analyze the roles played by them in the encoder. We find that the most important and confident heads play consistent and often linguistically-interpretable roles. When pruning heads using a method based on stochastic gates and a differentiable relaxation of the L0 penalty, we observe that specialized heads are last to be pruned. Our novel pruning method removes the vast majority of heads without seriously affecting performance. For example, on the English-Russian WMT dataset, pruning 38 out of 48 encoder heads results in a drop of only 0.15 BLEU."
}

@article{rogers2020primer,
    title = "A Primer in {BERT}ology: What We Know About How {BERT} Works",
    author = "Rogers, Anna  and
      Kovaleva, Olga  and
      Rumshisky, Anna",
    editor = "Johnson, Mark  and
      Roark, Brian  and
      Nenkova, Ani",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "8",
    year = "2020",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2020.tacl-1.54/",
    doi = "10.1162/tacl_a_00349",
    pages = "842--866",
    abstract = "Transformer-based models have pushed state of the art in many areas of NLP, but our understanding of what is behind their success is still limited. This paper is the first survey of over 150 studies of the popular BERT model. We review the current state of knowledge about how BERT works, what kind of information it learns and how it is represented, common modifications to its training objectives and architecture, the overparameterization issue, and approaches to compression. We then outline directions for future research."
}

@misc{coenen2019visualizingmeasuringgeometrybert,
      title={Visualizing and Measuring the Geometry of BERT}, 
      author={Andy Coenen and Emily Reif and Ann Yuan and Been Kim and Adam Pearce and Fernanda Viégas and Martin Wattenberg},
      year={2019},
      eprint={1906.02715},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1906.02715}, 
}

@misc{stackrnn,
      title={Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets}, 
      author={Armand Joulin and Tomas Mikolov},
      year={2015},
      eprint={1503.01007},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/1503.01007}, 
}

@misc{suzgun2019memoryaugmentedrecurrentneuralnetworks,
      title={Memory-Augmented Recurrent Neural Networks Can Learn Generalized Dyck Languages}, 
      author={Mirac Suzgun and Sebastian Gehrmann and Yonatan Belinkov and Stuart M. Shieber},
      year={2019},
      eprint={1911.03329},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1911.03329}, 
}

@inproceedings{transformerstack,
    title = "Transition-based Parsing with Stack-Transformers",
    author = "Fernandez Astudillo, Ram{\'o}n  and
      Ballesteros, Miguel  and
      Naseem, Tahira  and
      Blodgett, Austin  and
      Florian, Radu",
    editor = "Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.89/",
    doi = "10.18653/v1/2020.findings-emnlp.89",
    pages = "1001--1007",
    abstract = "Modeling the parser state is key to good performance in transition-based parsing. Recurrent Neural Networks considerably improved the performance of transition-based systems by modelling the global state, e.g. stack-LSTM parsers, or local state modeling of contextualized features, e.g. Bi-LSTM parsers. Given the success of Transformer architectures in recent parsing systems, this work explores modifications of the sequence-to-sequence Transformer architecture to model either global or local parser states in transition-based parsing. We show that modifications of the cross attention mechanism of the Transformer considerably strengthen performance both on dependency and Abstract Meaning Representation (AMR) parsing tasks, particularly for smaller models or limited training data."
}

@misc{stackattention,
      title={Stack Attention: Improving the Ability of Transformers to Model Hierarchical Patterns}, 
      author={Brian DuSell and David Chiang},
      year={2024},
      eprint={2310.01749},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.01749}, 
}

@article{Strobl_2024,
   title={What Formal Languages Can Transformers Express? A Survey},
   volume={12},
   ISSN={2307-387X},
   url={http://dx.doi.org/10.1162/tacl_a_00663},
   DOI={10.1162/tacl_a_00663},
   journal={Transactions of the Association for Computational Linguistics},
   publisher={MIT Press},
   author={Strobl, Lena and Merrill, William and Weiss, Gail and Chiang, David and Angluin, Dana},
   year={2024},
   pages={543–561} }

@inproceedings{weiss2021thinking,
  title={Thinking like transformers},
  author={Weiss, Gail and Goldberg, Yoav and Yahav, Eran},
  booktitle={International Conference on Machine Learning},
  pages={11080--11090},
  year={2021},
  organization={PMLR}
}

@misc{merrill2021linguisticcapacityrealtimecounter,
      title={On the Linguistic Capacity of Real-Time Counter Automata}, 
      author={William Merrill},
      year={2021},
      eprint={2004.06866},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2004.06866}, 
}