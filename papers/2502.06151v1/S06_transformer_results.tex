\subsection{Transformer Results}
\label{sm:experiments_transformer_results}

Here, we present the full results from evaluating Transformer with WCMHA.
The architecture is described in Appendix~\ref{sm:transformer_architecture} and the experimental details are provided in Appendices~\ref{sm:exp_details} and \ref{sm:experiments_transformer}.

Table~\ref{tab:transformer_powerLaw_full} provides the aggregate Transformer performance without WCMHA and with WCMHA for varying decay times ($\alpha$).
WCMHA decisively outperforms MHA on 4 or the 7 datasets and ties with the number of best results on ETTh2.
Looking further into ETTh2 we see that when WCMHA outperforms MHA it does so by much larger margins (16\%) than when it underperforms (2\%).
Moreover, we observe the same larger margins of overperformance across all of the datasets.
This indicates that when the natural pairwise distribution is found we can see significant improvements in MSE and MAE, but the effects of imposing the wrong pairwise distribution are much less significant.

In Figs.~\ref{fig:transformer_etth1_96_attn_full}-\ref{fig:transformer_traffic_720_attn_full} we present the attention score and weight distributions with and without applying the local-causal mask.
The distributions can have significant deviations between datasets.
In general, the WCMHA decoder self-attention shows the smallest deviation from the MHA base case.
We note that the MHA base case already has a causal mask.
The last WCMHA encoder self-attention layer often shows the largest difference between WCMHA and MHA distributions.
This makes sense since the MHA encoder attention is not causal.
We do not alter the decoder cross-attention, but we still observe shifts in the distribution, which differ between datasets.
Interestingly we do not observe the same bimodal distribution in attention weights as we do for \emph{Powerformer}.
This may be due to the Transformer's encoder-decoder structure, whereas \emph{Powerformer} only has an encoder.


%\setlength{\tabcolsep}{3.65pt}
\begin{table*}[!ht]
	\centering
    \caption{We provide the forecasting MSE and MAE on the test sets for Transformer with MHA (base case) and for Transformer with WCMHA and the weight power-law mask \fpl. The top row indicates the model or decay constant $(\alpha)$, the bold numbers are the best (lowest) performance, and the underlined numbers are the second best.}
    \label{tab:transformer_powerLaw_full}
    \vskip 0.1in
    \resizebox{0.97\textwidth}{!}{
	\begin{tabular}{c|c|cc|cc|cc|cc|cc|cc}
	\toprule
	\multicolumn{2}{c|}{}  & \multicolumn{2}{c|}{Base Case} & \multicolumn{2}{c|}{0.1} & \multicolumn{2}{c|}{0.25} & \multicolumn{2}{c|}{0.5} & \multicolumn{2}{c|}{0.75} & \multicolumn{2}{c}{1} \\
	\midrule
	\multicolumn{2}{c|}{Metric} & MSE & MAE & MSE & MAE & MSE & MAE & MSE & MAE & MSE & MAE & MSE & MAE \\
	\midrule
	\multirow{4}{*}{\rotatebox[origin=c]{90}{\text{ETTh1}}}
		& 96 &  0.936 & 0.741 &  0.955 & 0.752 &  0.944 & 0.745 &  0.921 & 0.729 &  \underline{0.896} & \underline{0.711} &  \textbf{0.874} & \textbf{0.693}  \\
		& 192 &  0.988 & 0.769 &  0.916 & 0.759 &  0.951 & 0.789 &  \underline{0.887} & \underline{0.749} &  0.895 & \textbf{0.745} &  \textbf{0.876} & \underline{0.749}  \\
		& 336 &  1.061 & 0.815 &  1.067 & 0.835 &  1.063 & 0.814 &  1.054 & \underline{0.809} &  \textbf{1.038} & 0.836 &  \underline{1.044} & \textbf{0.802}  \\
		& 720 &  1.113 & 0.881 &  \textbf{1.047} & \textbf{0.842} &  \underline{1.061} & \underline{0.855} &  1.180 & 0.893 &  1.185 & 0.895 &  1.259 & 0.899  \\
	\midrule
	\multirow{4}{*}{\rotatebox[origin=c]{90}{\text{ETTh2}}}
		& 96 &  1.585 & 1.038 &  \textbf{1.344} & \textbf{0.918} &  \underline{1.349} & \underline{0.920} &  1.392 & 0.936 &  1.496 & 1.000 &  1.511 & 1.005  \\
		& 192 &  \textbf{1.889} & \textbf{1.131} &  \underline{1.899} & \underline{1.133} &  3.025 & 1.459 &  2.916 & 1.423 &  2.800 & 1.384 &  2.761 & 1.365  \\
		& 336 &  \textbf{2.668} & \textbf{1.384} &  2.875 & 1.393 &  2.872 & \underline{1.386} &  2.879 & 1.412 &  \underline{2.860} & 1.409 &  2.951 & 1.442  \\
		& 720 &  3.143 & 1.528 &  3.389 & 1.570 &  3.455 & 1.582 &  3.533 & 1.621 &  \underline{2.635} & \underline{1.331} &  \textbf{2.488} & \textbf{1.272}  \\
	\midrule
	\multirow{4}{*}{\rotatebox[origin=c]{90}{\text{ETTm1}}}
		& 96 &  0.560 & 0.545 &  0.566 & 0.533 &  0.592 & 0.545 &  0.563 & 0.541 &  \underline{0.535} & \underline{0.522} &  \textbf{0.487} & \textbf{0.492}  \\
		& 192 &  0.874 & 0.729 &  0.907 & 0.724 &  0.838 & 0.711 &  0.830 & 0.698 &  \underline{0.774} & \underline{0.686} &  \textbf{0.718} & \textbf{0.645}  \\
		& 336 &  0.960 & 0.786 &  0.948 & 0.786 &  \underline{0.938} & \underline{0.779} &  0.956 & 0.786 &  1.029 & 0.800 &  \textbf{0.888} & \textbf{0.752}  \\
		& 720 &  0.900 & 0.746 &  \textbf{0.864} & \textbf{0.710} &  \underline{0.886} & \underline{0.729} &  0.902 & 0.749 &  0.892 & \underline{0.729} &  1.005 & 0.788  \\
	\midrule
	\multirow{4}{*}{\rotatebox[origin=c]{90}{\text{ETTm2}}}
		& 96 &  \textbf{0.597} & \textbf{0.614} &  \underline{0.619} & \underline{0.628} &  0.632 & 0.636 &  0.660 & 0.653 &  0.697 & 0.674 &  0.700 & 0.638  \\
		& 192 &  \textbf{0.849} & \textbf{0.749} &  \underline{0.876} & \underline{0.761} &  0.893 & 0.769 &  0.927 & 0.787 &  0.970 & 0.808 &  1.011 & 0.827  \\
		& 336 &  \textbf{1.227} & \textbf{0.909} &  \underline{1.259} & \underline{0.920} &  1.271 & 0.925 &  1.295 & 0.936 &  1.320 & 0.947 &  1.333 & 0.955  \\
		& 720 &  \textbf{2.176} & \textbf{1.237} &  2.214 & \underline{1.241} &  2.213 & \underline{1.241} &  2.216 & 1.252 &  2.209 & 1.252 &  \underline{2.195} & 1.250  \\
	\midrule
	\multirow{4}{*}{\rotatebox[origin=c]{90}{\text{Weather}}}
		& 96 &  0.250 & 0.333 &  0.211 & \underline{0.297} &  \underline{0.209} & 0.302 &  \textbf{0.207} & \textbf{0.291} &  0.216 & 0.305 &  0.228 & 0.316  \\
		& 192 &  0.344 & 0.414 &  \underline{0.295} & \underline{0.373} &  \textbf{0.287} & \textbf{0.367} &  0.297 & 0.375 &  0.307 & 0.383 &  0.313 & 0.390  \\
		& 336 &  0.435 & 0.467 &  \underline{0.403} & \underline{0.446} &  0.416 & 0.455 &  0.420 & 0.458 &  0.410 & 0.452 &  \textbf{0.384} & \textbf{0.436}  \\
		& 720 &  0.463 & 0.489 &  \underline{0.420} & \underline{0.460} &  0.435 & 0.471 &  0.424 & 0.464 &  0.426 & 0.468 &  \textbf{0.403} & \textbf{0.454}  \\
	\midrule
	\multirow{4}{*}{\rotatebox[origin=c]{90}{\text{Electricity}}}
		& 96 &  \underline{0.265} & 0.360 &  0.271 & 0.364 &  \textbf{0.264} & \textbf{0.355} &  0.266 & \underline{0.359} &  0.272 & 0.367 &  0.280 & 0.370  \\
		& 192 &  0.284 & 0.378 &  0.278 & 0.372 &  0.286 & 0.378 &  \textbf{0.270} & \textbf{0.366} &  \underline{0.276} & \underline{0.369} &  0.291 & 0.386  \\
		& 336 &  \underline{0.280} & 0.371 &  0.289 & 0.381 &  0.290 & 0.381 &  0.288 & 0.381 &  0.281 & \underline{0.369} &  \textbf{0.277} & \textbf{0.366}  \\
		& 720 &  0.300 & 0.382 &  0.318 & 0.395 &  0.308 & 0.389 &  \underline{0.296} & \underline{0.378} &  0.302 & 0.383 &  \textbf{0.289} & \textbf{0.373}  \\
	\midrule
	\multirow{4}{*}{\rotatebox[origin=c]{90}{\text{Traffic}}}
		& 96 &  0.662 & 0.365 &  0.656 & 0.359 &  0.653 & \underline{0.357} &  \underline{0.652} & \textbf{0.355} &  0.669 & 0.364 &  \textbf{0.649} & 0.358  \\
		& 192 &  \textbf{0.655} & \textbf{0.350} &  0.675 & 0.368 &  0.669 & 0.361 &  0.669 & 0.365 &  \underline{0.660} & 0.356 &  \textbf{0.655} & \underline{0.355}  \\
		& 336 &  \textbf{0.651} & \textbf{0.350} &  \underline{0.652} & \underline{0.353} &  0.657 & 0.357 &  0.670 & 0.364 &  0.667 & 0.361 &  0.658 & 0.358  \\
		& 720 &  \textbf{0.660} & \textbf{0.354} &  0.669 & 0.363 &  0.676 & 0.360 &  \underline{0.667} & \underline{0.355} &  0.668 & 0.361 &  0.689 & 0.370  \\
	\bottomrule
	\end{tabular}}
\end{table*}
%\setlength{\tabcolsep}{6pt}

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.98\textwidth]{figures/Transformer_ETTh1_powerLaw/Transformer_scores_sq256_pl96.pdf}
    \caption{We present the Transformer attention score (inset) and weight distributions on the ETTh1 dataset with a forecasting length of 96. The dotted line represents the reference MHA Transformer results, the dashed-dotted line represents WCMHA with \fpl{} results before applying \maskCL, and the solid lines represent WCMHA with \fpl{} results after applying \maskCL.}
        \label{fig:transformer_etth1_96_attn_full}

\end{figure*}

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.98\textwidth]{figures/Transformer_ETTh1_powerLaw/Transformer_scores_sq256_pl720.pdf}
    \caption{We present the Transformer attention score (inset) and weight distributions on the ETTh1 dataset with a forecasting length of 720. The dotted line represents the reference MHA Transformer results, the dashed-dotted line represents WCMHA with \fpl{} results before applying \maskCL, and the solid lines represent WCMHA with \fpl{} results after applying \maskCL.}
    \label{fig:transformer_etth1_720_attn_full}
\end{figure*}

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.98\textwidth]{figures/Transformer_ETTh2_powerLaw/Transformer_scores_sq256_pl96.pdf}
    \caption{We present the Transformer attention score (inset) and weight distributions on the ETTh2 dataset with a forecasting length of 96. The dotted line represents the reference MHA Transformer results, the dashed-dotted line represents WCMHA with \fpl{} results before applying \maskCL, and the solid lines represent WCMHA with \fpl{} results after applying \maskCL.}
    \label{fig:transformer_etth2_96_attn_full}
\end{figure*}

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.98\textwidth]{figures/Transformer_ETTh2_powerLaw/Transformer_scores_sq256_pl720.pdf}
    \caption{We present the Transformer attention score (inset) and weight distributions on the ETTh2 dataset with a forecasting length of 720. The dotted line represents the reference MHA Transformer results, the dashed-dotted line represents WCMHA with \fpl{} results before applying \maskCL, and the solid lines represent WCMHA with \fpl{} results after applying \maskCL.}
    \label{fig:transformer_etth2_720_attn_full}
\end{figure*}


\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.98\textwidth]{figures/Transformer_ETTm1_powerLaw/Transformer_scores_sq256_pl96.pdf}
    \caption{We present the Transformer attention score (inset) and weight distributions on the ETTm1 dataset with a forecasting length of 96. The dotted line represents the reference MHA Transformer results, the dashed-dotted line represents WCMHA with \fpl{} results before applying \maskCL, and the solid lines represent WCMHA with \fpl{} results after applying \maskCL.}
    \label{fig:transformer_ettm1_96_attn_full}
\end{figure*}

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.98\textwidth]{figures/Transformer_ETTm1_powerLaw/Transformer_scores_sq256_pl720.pdf}
    \caption{We present the Transformer attention score (inset) and weight distributions on the ETTm1 dataset with a forecasting length of 720. The dotted line represents the reference MHA Transformer results, the dashed-dotted line represents WCMHA with \fpl{} results before applying \maskCL, and the solid lines represent WCMHA with \fpl{} results after applying \maskCL.}
    \label{fig:transformer_ettm1_720_attn_full}
\end{figure*}

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.98\textwidth]{figures/Transformer_ETTm2_powerLaw/Transformer_scores_sq256_pl96.pdf}
    \caption{We present the Transformer attention score (inset) and weight distributions on the ETTm2 dataset with a forecasting length of 96. The dotted line represents the reference MHA Transformer results, the dashed-dotted line represents WCMHA with \fpl{} results before applying \maskCL, and the solid lines represent WCMHA with \fpl{} results after applying \maskCL.}
    \label{fig:transformer_ettm2_96_attn_full}
\end{figure*}

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.98\textwidth]{figures/Transformer_ETTm2_powerLaw/Transformer_scores_sq256_pl720.pdf}
    \caption{We present the Transformer attention score (inset) and weight distributions on the ETTm2 dataset with a forecasting length of 720. The dotted line represents the reference MHA Transformer results, the dashed-dotted line represents WCMHA with \fpl{} results before applying \maskCL, and the solid lines represent WCMHA with \fpl{} results after applying \maskCL.}
    \label{fig:transformer_ettm2_720_attn_full}
\end{figure*}

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.98\textwidth]{figures/Transformer_Weather_powerLaw/Transformer_scores_sq256_pl96.pdf}
    \caption{We present the Transformer attention score (inset) and weight distributions on the Weather dataset with a forecasting length of 96. The dotted line represents the reference MHA Transformer results, the dashed-dotted line represents WCMHA with \fpl{} results before applying \maskCL, and the solid lines represent WCMHA with \fpl{} results after applying \maskCL.}
    \label{fig:transformer_weather_96_attn_full}
\end{figure*}

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.98\textwidth]{figures/Transformer_Weather_powerLaw/Transformer_scores_sq256_pl720.pdf}
    \caption{We present the Transformer attention score (inset) and weight distributions on the Weather dataset with a forecasting length of 720. The dotted line represents the reference MHA Transformer results, the dashed-dotted line represents WCMHA with \fpl{} results before applying \maskCL, and the solid lines represent WCMHA with \fpl{} results after applying \maskCL.}
    \label{fig:transformer_weather_720_attn_full}
\end{figure*}

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.98\textwidth]{figures/Transformer_Electricity_powerLaw/Transformer_scores_sq256_pl96.pdf}
    \caption{We present the Transformer attention score (inset) and weight distributions on the Electricity dataset with a forecasting length of 96. The dotted line represents the reference MHA Transformer results, the dashed-dotted line represents WCMHA with \fpl{} results before applying \maskCL, and the solid lines represent WCMHA with \fpl{} results after applying \maskCL.}
    \label{fig:transformer_electricity_96_attn_full}
\end{figure*}

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.98\textwidth]{figures/Transformer_Electricity_powerLaw/Transformer_scores_sq256_pl720.pdf}
    \caption{We present the Transformer attention score (inset) and weight distributions on the Electricity dataset with a forecasting length of 720. The dotted line represents the reference MHA Transformer results, the dashed-dotted line represents WCMHA with \fpl{} results before applying \maskCL, and the solid lines represent WCMHA with \fpl{} results after applying \maskCL.}
    \label{fig:transformer_electricity_720_attn_full}
\end{figure*}

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.98\textwidth]{figures/Transformer_Traffic_powerLaw/Transformer_scores_sq256_pl96.pdf}
    \caption{We present the Transformer attention score (inset) and weight distributions on the Traffic dataset with a forecasting length of 96. The dotted line represents the reference MHA Transformer results, the dashed-dotted line represents WCMHA with \fpl{} results before applying \maskCL, and the solid lines represent WCMHA with \fpl{} results after applying \maskCL.}
    \label{fig:transformer_traffic_96_attn_full}
\end{figure*}

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.98\textwidth]{figures/Transformer_Traffic_powerLaw/Transformer_scores_sq256_pl720.pdf}
    \caption{We present the Transformer attention score (inset) and weight distributions on the Traffic dataset with a forecasting length of 720. The dotted line represents the reference MHA Transformer results, the dashed-dotted line represents WCMHA with \fpl{} results before applying \maskCL, and the solid lines represent WCMHA with \fpl{} results after applying \maskCL.}
    \label{fig:transformer_traffic_720_attn_full}
\end{figure*}
