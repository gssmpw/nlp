

\begin{table}[h]
    \centering
    \caption{Hyper-parameters.}
    \label{tab:hyper}
    \resizebox{\columnwidth}{!}{
    \begin{tabular}{lcc}
        \toprule 
        \textbf{hyper-parameter} & \textbf{nnUNet} & \textbf{U-Net (Baseline)}  \\ 
        \midrule
        architecture & auto & auto \\
        base features & 32 & 24 \\
        normalization & instance (IN) & batch (BN) \\
        batch size & 2 & 2 \\
        patch size & (160, 192, 64) & (160, 160, 64) \\
        epochs & 600 & 600 \\
        batches per epoch & 250 & 250 \\
        loss & Dice Loss + CE & Dice Loss + CE \\
        % loss masking based on intensity & \cmark & \xmark \\
        oversampling rate & 0.66 & 0.75 \\
        optimizer & SGD & SGD \\
        momentum & 0.99 & 0.99 \\
        weight decay & $3 \times 10^{-5}$  & $3 \times 10^{-5}$ \\
        initial learning rate & $10^{-2}$ & $10^{-2}$ \\
        learning rate schedule & poly decay & poly decay \\
        learning rate decay power & 0.9 & 0.9 \\
        test-time augmentation & \cmark & \xmark \\
        \bottomrule

    \end{tabular}}
\end{table}
