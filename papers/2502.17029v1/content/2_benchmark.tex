

\section{M3DA Benchmark}
\label{sec:bench}


We consider a semantic segmentation problem of 3D medical images, which we call a downstream task. Any downstream model works with input samples $x \in X$ and the corresponding segmentation masks $y \in Y$, where $X$ and $Y$ are some input image and label spaces. If $x \in \R^{H \times W \times D}$, segmentation mask is of the same spatial size $y \in \R^{H \times W \times D}$, where every element belongs to a predefined set of labels $y^{(h,w,d)} \in \{ 0, 1, \dots, C \}$, $0$ is background and $C$ is the number of foreground classes.


\input{tables/1_benchmarks}


We follow the standard unsupervised domain adaptation (UDA) problem setting, as in \cite{dann}. We assume that two distributions $\mathcal{S}(x, y)$ and $\mathcal{T}(x, y)$ exist on $X \otimes Y$, called \textit{source} and \textit{target} distributions. At the training time, we have a set of source training samples $X^s = \{ x_i^s \}_{i=1}^n$ with the corresponding masks $Y^s = \{ y_i^s \}_{i=1}^n$ and a set of target training samples $X^t_{tr}$ without annotations; source images and masks are considered to be sampled from $\mathcal{S}$, $(x_i^s, y_i^s) \sim \mathcal{S}(x, y)$. Our goal is to predict segmentations $y$ given the input from the marginal distribution of target images, $x \sim \mathcal{T}(x)$. To evaluate algorithms, we have target testing samples $X^t_{ts}$ with masks $Y^t_{ts}$ \textit{available only for evaluation purposes}.


Thus, given domains A and B, one trains a supervised model on domain A while having access to unannotated samples from domain B for adaptation. The goal of UDA is to develop a model that makes accurate predictions on domain B. Importantly, this setup prohibits incorporating annotations from the target domain into the training routine.


\subsection{UDA problems motivation}
\label{ssec:constructing}


\input{tables/2_datasets}

\paragraph{CT \textbf{$\leftrightarrow$} MRI}
First, we include domain shift from MRI to CT and vice versa. Although the use of CT scans is often clinically justified, it is associated with additional risks, such as potentially increasing the risk of cancer \cite{cao2022ct,brenner2007computed}. In contrast, MRI is a safer imaging modality that does not involve radiation exposure \cite{nie2016estimating}. While CT is critical for various clinical applications like radiotherapy treatment planning, there is a recent transition to MRI for these applications \cite{paczona2023magnetic}. Thus, developing algorithms that use decades of collected CT data and adapt them for newly acquired MRI scans is an important avenue of research.


The inverse problem of estimating MRI from CT is also an important application. CT is a much faster imaging modality compared to MRI, making it a better solution in emergency scenarios such as stroke. However, MRI provides more sensitive brain visualization \cite{vymazal2012comparison}. Therefore, having universal algorithms that can adapt to the needed modality at hand is highly beneficial.


While these examples highlight the clinical relevance of domain adaptation between CT and MRI, for the purpose of this benchmark, we utilize a different dataset focusing on thoracic organ segmentation. This choice is motivated by the availability of a dataset that provides both MR and CT images with corresponding segmentation maps for thoracic organs, which is essential for evaluating the performance of UDA algorithms. Despite the difference in the target application, the underlying principles of domain adaptation remain the same, and the insights gained from this benchmark can be applied to various clinical scenarios.


\paragraph{CT $\rightarrow$ low-dose CT}Second, we include a CT to low-dose CT (LDCT) shift, motivated by the increasing popularity of LDCT. LDCT produces images with a lower signal-to-noise ratio but are still diagnostically effective, resulting in several-fold lower radiation dosage exposure compared to regular CT (allowing for screening purposes \cite{lidc,kubo2016standard}), faster scanning time, mobility to scan underserved populations \cite{raghavan2020initial}, and cost-effectiveness \cite{mohammadshahi2019cost}. Similar to the CT $\leftrightarrow$ MRI domain shift, utilizing publicly available annotated regular CT scans can accelerate the development of automated segmentation models for LDCT. As demonstrated in Table \ref{tab:metrics_pure}, methods trained on regular CT perform poorly on LDCT. This shift is the only one obtained via simulation, where we algorithmically simulate low-dose CT from regular ones.

 % \reconsider{no contrast enhancement}} Why?
\paragraph{Contrast enhancement $\rightarrow$ no contrast enhancement} Third, we include two tasks, MRI and CT, involving domain transfer from a contrast-enhanced (CE) image to an image without contrast enhancement (native). CE injection is a labor-intensive step, requiring additional training for personnel and carrying a small but additional risk for patients \cite{andreucci2014side,costelloe2020risks}. Again, we suggest benchmarking DA methods against the scenario where models that utilized richer imaging modalities (CE) during supervised training are adapted for safer modalities (non-contrast-enhanced).


\paragraph{MRI settings} Finally, we include three setups that address the domain shifts caused by variable MRI scanner settings, which are among the most common sources of domain shift encountered in practice \cite{yan2020mri,medim_da_survey_2023}. These setups cover different field strengths (1.5T vs. 3T), different scanner manufacturers, and a combination of both. Domain shifts arising from variations in scanner settings are ubiquitous in multi-source MRI datasets, as differences in field strength and manufacturer-specific acquisition parameters can significantly impact the appearance and quality of the resulting images. Addressing these shifts is crucial for developing robust and generalizable segmentation models that can handle the heterogeneity of MRI data encountered in real-world clinical scenarios.


\subsection{Datasets selection}
\label{ssec:data}
% \reconsider{Intro sentence, may be add link to some medim datasets summary paper/github, comment on what is necessary to use dataset for DA setup (annotation, metadata)}
We base the inclusion of datasets into the benchmark on two criteria. \textbf{Relevance}, we aim to cover as many relevant domain shifts as possible; see Section~\ref{ssec:limitations} for a list of domain shifts not included in our benchmark. \textbf{Scale}, we prefer a dataset with a larger number of samples, when deciding between two datasets that are both relevant and include similar domain shifts. 
% \textbf{Economy}, we aim to cover selected shifts with a preferably smaller number of datasets.
All reviewed and selected datasets are summarized in Table~\ref{tab:datasets}, and all technical details (e.g., links, download instructions, and licenses) are provided in Supplementary materials.
\input{tables/3_setups}

We start by selecting a dataset for MRI to CT conversion. This allows for several alternatives. Many authors use datasets such as BTCV and CHAOS for these tasks, both of which include images of the thoracic region. BTCV consists of 30 CT scans with 13 organ annotations, and CHAOS of 40 MRI and 40 CT scans with 4 organ annotations. Another option is MM-WHS, which consists of 20 MRI and 20 CT scans of the heart with 8 annotated classes. Finally, there is the newer AMOS dataset, which consists of 500 CT and 100 MRI scans with 15 annotated thoracic organs. Following our criteria, we include AMOS as it is the largest option. We also use AMOS to simulate LDCT data.

To cover CE CT to native CT task, we add Lung Image Database Consortium image collection (LIDC) \cite{lidc}. LIDC contains chest CT images with and without contrast enhancement with segmentation annotation of lung nodules. LIDC dataset covers lung nodules - an oncology pathology, one of the most common reasons for using contrast enhancement \cite{purysko2016does}. Then, we cover the similar CE-based data shift in multi-sequence MRI data, from T1 CE to T1 modality. BraTS 2021, being one of the largest and most widely used datasets in the medical imaging community, emerges as the natural choice, satisfying our criteria of relevance, and scale.

Finally, we cover variability in the single-sequence MRI acquisition. As evident from Tables \ref{tab:benchmarks} and \ref{tab:datasets}, common choices are the ACDC and M\&Ms datasets. Both include segmentation classes of the heart and are relatively large, consisting of 150 and 375 annotated samples, respectively. Both have several concretely defined MRI domains (e.g., different scanners, parameters, field strengths). Another option is CC359, which has the same rich variability in MRI parameters and is similarly sized, including 359 annotated samples. Both ACDC and M\&Ms images have $1\times 1\times 9~ \text{mm}^3$ spacing, for which a 2D algorithm would often be a more viable choice. In contrast, a significant advantage of CC359 is the fine-grade and consistent voxel spacing, approximately $1\times 1\times 1~ \text{mm}^3$, which concludes our selection. UDA setups from the selected datasets are summarized in Table~\ref{tab:setup}.
