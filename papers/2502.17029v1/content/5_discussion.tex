\section{Discussion}
\label{sec:discussion}

While we focused our computational experiments on unsupervised DA, M3DA also supports other DA frameworks.

\paragraph{Supervised DA} involves having annotated data from source and target domains. It can potentially close the performance gap more effectively, leveraging the explicit knowledge of target domain characteristics. All datasets and samples in M3DA come with segmentation annotations, allowing supervised DA setup.

\paragraph{Source-free DA} In this setting, the model is trained on the source domain and later adapted to the target domain without accessing source data. This approach is particularly relevant in scenarios with privacy concerns. M3DA allows source-free DA by removing the source data during finetuning.

\paragraph{Test-time DA} focuses on adapting the model during inference. This method adjusts to the target domain using only the data available at the inference time. Similar to source-free DA, one can limit access to the source domain and use online sampling of the target data.

\paragraph{Domain Generalization (DG)} aims to learn domain-invariant features from multiple source domains without accessing any target domain data during training. This approach is particularly valuable in medical imaging where encountering completely new domains is common, such as images from different hospitals or scanner manufacturers. M3DA's diverse collection of datasets from various medical centers and imaging protocols\footnote{LIDC is sourced from seven academic centers and eight medical imaging companies, BraTS is sourced from at least nine different clinical centers, AMOS was collected in two medical centers, from eight different scanners} makes it well-suited for developing and evaluating DG methods.

These alternative DA frameworks showcase the versatility of our benchmark and its potential to support a wide range of research questions and methodologies in the field of domain adaptation for medical image segmentation.


\subsection{Limitations and future directions}
\label{ssec:limitations}

While we incorporate a diverse set of domain shifts, our benchmark is not exhaustive. We exclude several candidate domain shifts due to their simplicity, low relevance, or lack of available public data. First, the CT reconstruction kernel (from sinogram space to voxel space) is an important parameter. As shown in \cite{fbpaug}, this problem can be largely mitigated via simple augmentations or an auxiliary loss function \cite{shimovolos2022adaptation}. We include our results on this shift in Supplementary materials, but as it is almost fully addressed by simple augmentations, we exclude it from the main benchmark. Also, public datasets containing both reconstruction kernel information and segmentation annotations are scarce.

Second, the CC359 dataset consists of data from six distinct domains, allowing for 30 different domain shift scenarios. We selected the three least ``solved'' shifts based on our preliminary analysis. A complete table with results on all 30 domain pairs is provided in Supplementary materials.

Third, a common critique of the BraTS dataset is that it is heavily preprocessed. Incorporating raw datasets like Burdenko-GP \cite{Zolotova2023Burdenko} could provide an evaluation of DA methods in a more realistic setting. However, this comes with an inevitable trade-off of added complexity in data preparation. We also exclude the MRI T1 to T2 domain shift from the main paper. Although we provide the results for this setup in Supplementary materials, we did not find sufficient evidence to support its clinical relevance, leading to its exclusion from our benchmark.

Finally, while the LIDC dataset allows for the CE CT to CT shift, it is primarily designed for object detection tasks, with multiple nodules per image. Despite this limitation, LIDC remains the only publicly available dataset of sufficient size that enables this clinically relevant domain shift.

Future work should focus on expanding M3DA to include more clinically relevant domain shifts, incorporating datasets with unprocessed scans, and exploring novel approaches to domain adaptation.


\subsection{Conclusion}
\label{sec:conclusion}


In this paper, we introduced the M3DA benchmark for unsupervised domain adaptation in 3D medical image segmentation. Addressing the widely indicated need for developing DA methods in the medical imaging domain \cite{gulrajani2020search,uda_survey_2020,zhuang2020comprehensive,peng2018visda,zhang2021empirical}, we created a large-scale benchmark to facilitate the development of robust segmentation methods in such a crucial application area. Contrary to previously used setups, we covered a diverse set of domain shift sources while using large, publicly available datasets.


We benchmarked the core adaptation methods, covering all key categories of UDA approaches \cite{medim_da_survey_2021,medim_da_survey_2023}, and medical foundational models. Our results revealed that adapted segmentation models struggle to generalize beyond their training distribution when tested at scale. Although some DA methods showed promise in particular settings, we revealed they might completely fail in a number of other setups. This highlights a pressing need for creating robust methods for medical image segmentation, and we hope to foster research efforts in improving adaptation methodsâ€™ performance in diverse situations.

Finally, we described several alternative problem settings within M3DA, e.g., supervised and test-time DA, enabling the evaluation of more complex hypotheses across a wider spectrum of DA methods.
