\section{Evaluation Details of Embedding Models}\label{appendix:embedding}
\begin{table}[H]
    \centering
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{l|ccccc}
        \toprule
        \textbf{Benchmarks} & \textbf{Kanana-Nano-2.1B} & \textbf{Llama3.2 3B} & \textbf{Qwen2.5 3B} & \textbf{Llama3.2 1B} & \textbf{Qwen2.5 1.5B} \\
        \midrule
        \midrule
        \textbf{English (Avg)} & 51.56 & 53.28 & 54.00 & 48.77 & 50.60 \\
        \midrule
        ArguAna & 54.59 & 54.36 & 56.26 & 51.80 & 53.49 \\
        CQADupstackGamingRetrieval & 58.37 & 60.31 & 59.65 & 56.13 & 57.20 \\
        CQADupstackUnixRetrieval & 43.34 & 45.27 & 45.41 & 39.18 & 41.14 \\
        ClimateFEVERHardNegatives & 29.64 & 30.64 & 31.08 & 26.93 & 27.66 \\
        FEVERHardNegatives & 73.18 & 79.09 & 80.26 & 73.27 & 72.09 \\
        FiQA2018 & 40.22 & 46.47 & 47.12 & 38.54 & 41.08 \\
        HotpotQAHardNegatives & 61.35 & 66.10 & 66.33 & 61.21 & 64.18 \\
        SCIDOCS & 21.41 & 21.44 & 22.14 & 18.96 & 19.81 \\
        TRECCOVID & 79.85 & 81.84 & 80.87 & 72.67 & 75.88 \\
        Touche2020Retrieval.v3 & 53.63 & 47.26 & 50.91 & 49.00 & 53.50 \\
        \midrule
        \midrule
        \textbf{Korean (Avg)} & 65.00 & 59.43 & 62.10 & 54.68 & 54.60 \\
        \midrule
        AutoRAGRetrieval & 79.71 & 70.87 & 75.64 & 71.47 & 72.32 \\
        BelebeleRetrieval & 92.35 & 87.58 & 90.16 & 84.44 & 83.53 \\
        Ko-StrategyQA & 79.98 & 73.92 & 76.38 & 63.46 & 64.97 \\
        MIRACLRetrieval & 60.04 & 52.25 & 56.83 & 48.28 & 48.68 \\
        MrTidyRetrieval & 49.82 & 45.83 & 48.48 & 35.32 & 37.94 \\
        MultiLongDocRetrieval & 30.17 & 25.54 & 25.75 & 20.98 & 17.13 \\
        PublicHealthQA & 88.08 & 84.12 & 86.68 & 80.26 & 79.71 \\
        XPQARetrieval & 39.88 & 35.33 & 36.89 & 33.24 & 32.55 \\
        \bottomrule
    \end{tabular}%
    }
    \caption{Evaluation details of embedding models on English and Korean retrieval benchmarks.}
    \label{tab:embedding-details}
\end{table}