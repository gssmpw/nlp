\subsection{Embedding Models}



Text embeddings, or dense vector representations, are essential for capturing the semantic essence of text \citep{karpukhin2020dense, khattab2020colbert}.
Following the success of LLMs, decoder-only language models have taken their place as a popular backbone of sentence embedding models \citep{muennighoff2022sgpt, wang2023improving, springer2024repetition, ma2024fine, behnamghader2024llm2vec, xu2024bmretriever}.
In this section, we examine the capabilities of the Kanana model, specifically the Kanana Nano 2.1B, as a robust backbone for embedding by employing LLM2Vec \citep{behnamghader2024llm2vec}.
For comparative analysis, we also apply LLM2Vec on models of Llama 3 and Qwen2.5 series with similar model sizes.

\begin{table}[ht]
    \centering
    \resizebox{0.5\columnwidth}{!}{%
    \begin{tabular}{l|ccc}
    \toprule
    \textbf{Embedding Backbone} & {\textbf{English}} & {\textbf{Korean}} & \textbf{Avg} \\
    \midrule
    Kanana Nano 2.1B & 51.56 & \textbf{65.00} & \textbf{58.28} \\
    \midrule
    Llama 3.2 3B & 53.28 & 59.43 & 56.35 \\
    Qwen2.5 3B & \textbf{54.00} & 62.10 & 58.05 \\
    Llama 3.2 1B & 48.77 & 54.68 & 51.73 \\
    Qwen2.5 1.5B & 50.60 & 54.60 & 52.60 \\
    \bottomrule
    \end{tabular}
    }
    \caption{Performance comparison of embedding models on English and Korean retrieval benchmarks. All embedding models are fine-tuned from instruct models. See \autoref{appendix:embedding} for detailed evaluations.}
    \label{tab:embedding-performance}
\end{table}

The embedding models are evaluated on subsets of Massive Text Embedding Benchmark (MTEB) \citep{muennighoff2022mteb} retrieval tasks, including 10 English tasks sourced from the MTEB v2 leaderboard \citep{enevoldsen2025mmtebmassivemultilingualtext} and 8 Korean tasks curated by \citet{KURE}.
\autoref{tab:embedding-performance} presents average nDCG@10 scores for English and Korean, summarizing the performance results on retrieval tasks.

Kanana Nano 2.1B consistently demonstrates competitive performance and serves as an effective backbone for embedding tasks.
As shown in \autoref{tab:embedding-performance}, our 2.1B model not only significantly surpasses Llama 3.2 1B and Qwen2.5 1.5B across both English and Korean benchmarks, but also outperforms Llama 3.2 3B and Qwen2.5 3B on Korean evaluations, despite its smaller size.
Additionally, it achieves a solid English score and the highest average score among the models, highlighting the strong capacity of Kanana Nano 2.1B when fine-tuned for retrieval tasks.

