%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass[]{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage[table]{xcolor}
\usepackage{lmodern}  % Use Latin Modern fonts
\usepackage[T1]{fontenc}  % Use T1 font encoding
\usepackage{microtype}
\usepackage{subcaption}  % Add this to your preamble
\usepackage{graphicx}
%\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{dsfont}
\usepackage{amsmath} % for math environments and symbols
\usepackage{graphicx}
\usepackage{adjustbox}
\usepackage{multirow}
\usepackage{arydshln}
\usepackage{rotating}
\usepackage{authblk}  % Package for better author formatting

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
%\usepackage{hyperref}
\usepackage[normalem]{ulem}

%% Color Comments %%
\newcommand{\RFc}[1]{\textcolor{violet}{#1}}
\newcommand{\RNew}[1]{\textcolor{cyan}{#1}}
\newcommand{\Old}[1]{\sout{\textcolor{gray}{#1}}}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
%\usepackage{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage[authoryear]{natbib}  % or [authoryear] depending on the style you want

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\indicator}[1]{\mathds{1}_{#1}}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\title{Compact Rule-Based Classifier Learning via Gradient Descent}

\begin{document}

%\twocolumn[
%\icmltitle{Compact Rule-Based Classifier Learning via Gradient Descent}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
%\icmlsetsymbol{equal}{*}

%\begin{icmlauthorlist}
%\icmlauthor{Javier Fumanal-Idocin}{essex}
%\icmlauthor{Raquel Fernandez-Peralta}{slovakia}
%\icmlauthor{Javier Andreu-Perez}{essex}
%\icmlauthor{Firstname4 Lastname4}{sch}
%\icmlauthor{Firstname5 Lastname5}{yyy}
%\icmlauthor{Firstname6 Lastname6}{sch,yyy,comp}
%\icmlauthor{Firstname7 Lastname7}{comp}
%\icmlauthor{}{sch}
%\icmlauthor{Firstname8 Lastname8}{sch}
%\icmlauthor{Firstname8 Lastname8}{yyy,comp}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
%\end{icmlauthorlist}

%\icmlaffiliation{essex}{School of Computer Science and Electronic Engineering, University of Essex, Essex, United Kingdom}
%\icmlaffiliation{slovakia}{Company Name, Location, Country}

\author[1]{Javier Fumanal-Idocin\thanks{Corresponding author: \texttt{j.fumanal-idocin@essex.ac.uk}}}
\author[2]{Raquel Fernandez-Peralta}
\author[1]{Javier Andreu-Perez}

\affil[1]{\small School of Computer Science and Electronic Engineering, University of Essex, Essex, United Kingdom}
\affil[2]{\small Slovak Academy of Sciences, Bratislava, Slovakia}

\date{}  % Removes default date

%\icmlcorrespondingauthor{Javier Fumanal-Idocin}{j.fumanal-idocin@essex.ac.uk}
%\icmlcorrespondingauthor{Firstname2 Lastname2}{first2.last2@www.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
%\icmlkeywords{Machine Learning, ICML}

%\vskip 0.3in
%]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.
\maketitle
\begin{abstract}
	Rule-based models play a crucial role in scenarios that require transparency and accountable decision-making. However, they primarily consist of discrete parameters and structures, which presents challenges for scalability and optimization. In this work, we introduce a new rule-based classifier trained using gradient descent, in which the user can control the maximum number and length of the rules. For numerical partitions, the user can also control the partitions used with fuzzy sets, which also helps keep the number of partitions small. We perform a series of exhaustive experiments on $40$ datasets to show how this classifier performs in terms of accuracy and rule base size. Then, we compare our results with a genetic search that fits an equivalent classifier and with other explainable and non-explainable state-of-the-art classifiers. Our results show how our method can obtain compact rule bases that use significantly fewer patterns than other rule-based methods and perform better than other explainable classifiers.
	%Our code is available online in the following repository: Redacted for anonymity.
\end{abstract}

\section{Introduction}

Deep neural networks (DNNs) have been used to solve complex problems in machine learning where non-structured data is available in large volumes, such as image and video \citep{lecun2015deep}. However, the use of these models is not always possible in cases where human liability is still relevant in the decision-making process, like medicine and finance \citep{arrieta2020explainable}.
Rule-based algorithms are considered one of the most trustworthy for the users, as they explicitly tell the users the patterns found and their relevance in each decision. They are also considered more faithful than other post hoc explainable artificial intelligence (XAI) methods, which are not always reliable \citep{molnar2020interpretable, tomsett2020sanity}. 

By studying the rules themselves, practitioners can find additional clues about a problem, and they can also disregard the patterns found by the classifier that are contrary to existing knowledge \citep{li2024interpreting}. It is also a popular use case for rule-based inference to use the rule base as a proxy for a more complicated model, such as a deep learning model, to perform post hoc explanations \citep{Zhang2018InterpretingCV,li2024interpreting}.
One of the main research topics in rule-based classification is the trade-off between interpretability and accuracy, as the larger the number of rules, the less interpretable the model becomes. For example, ensembles of tree-based models usually perform very well, at the cost of losing the interpretation capabilities that a single tree has \citep{breiman2001random, friedman2002stochastic}. Bayesian reasoning has also been used, but it usually requires Markov chain models to train them, which is very time-consuming \citep{wang2017bayesian}. Fuzzy rules have been trained mainly using genetic optimization, which balances accuracy and complexity well but causes significant scaling problems \citep{alcala2011fuzzy}. Pure gradient-based approaches have also been used to train rules \citep{wang2023learning, zhang2023learning}. However, they can result in an arbitrarily high number of additive rules, and the only way to handle the model complexity is to perform a dense search of hyperparameters. In addition, how these models partition the state can also be hard to understand for a possible user, especially when the number of rules is high, as the cut points can be arbitrary and very numerous. 
%One solution for this is the use of fuzzy sets for numerical variables, but they suffer from vanishing gradients and explainability issues when they are used alongside gradient descent \citep{mendel2023explainable}.


In this work, we develop a rule-based system, named Fuzzy Rule-based Reasoner (FRR), that can be trained exclusively using gradient descent and where we can manually set the number of rules and antecedents. The space partitions that the FRR uses as logic antecedents can also be set so that they are intuitive to the user. To obtain this, our contributions are the following:
\begin{itemize}
    \item  To maximize the \textbf{interpretability of the system}: we introduce our method for replicating the discrete operations of rule-based systems with matrix operations where the maximum number of rules, antecedents, and partitions can be set a priori. 
    \item To ensure \textbf{training effectiveness and scalability}: we discuss the differentiability issues of the FRR and how to solve them. For that, we propose a relaxation of the indicator function that we call restricted addition, which also boosts the performance of the training process and residual connections for training.
    \item We show the \textbf{superiority of the gradient-based training} with respect to an equivalent rule-based classifier using genetic optimization and against other explainable classifiers in $40$ different classification datasets.
\end{itemize}
 
%We propose a novel rule-based model named Fuzzy Rule-based Reasoner (FRR). The intended contributions to the following:
%\begin{itemize}
%	\item We construct a form sufficient rule inference that can be trained using a gradient-based approach. This model maintains all the desirable properties of rule-based classification, that is, shows rule importance and displays all the patterns found while keeping the same scalability that the gradient-based model has.
%	\item We show how this model can be trained using indicator functions that do not stop the gradient flow. We also show how we can improve the flow of gradient in training time while keeping the same desirable properties in inference time.
%	\item We allow the user to set the maximum number of rules and antecedents for the FRR, which helps to interpretability for human users. These are sufficient rules, which means that the decision process is also easier for a human being to understand than one using additive rules. All rules also share the same partitions of the input state based, so that there are no rules forming arbitrarily complex hyper-rectangles.
%\end{itemize}

\section{Related Work}
\subsection{Rule-based models}
Rule-based models and decision trees have been mostly trained using heuristic procedures due to their discrete and non-differentiable nature \citep{wei2019generalized}. However, these algorithms may not find the best solution and are not guaranteed to find a close one \citep{rudolph1994convergence}. Search algorithms can also be used, but they are expensive to compute, making them unfeasible in large datasets. Most existing rule-based methods mine a series of frequent patterns, which may not be ideal in all situations and do not achieve the same performance as other complex methods such as gradient boosting or random forest \citep{yuan2017improved}. However, such complex models are harder to interpret, and it is necessary to use tools such as Shapley values to do so \citep{lundberg2020local}. Fuzzy rules offer good interpretability, but they are computationally intensive to train \citep{mendel2023explainable} and might require hundreds of rules to achieve good performance. 

Rule-based methods have been used as well for explainable symbolic reasoning when the antecedents are known concepts, and their relationships can be exploited to solve tasks such as classification. Logic structures can be fixed, and then the right concepts are to be found \citep{petersen2022, barbiero2023interpretable}. Finding the optimal connections among the concepts studied \citep{vemuri2024enhancing} is also possible. However, the interpretability of the system is compromised by the quality of the concept detection, which is hard to assess. It is also possible to distil black-box models into rule-based ones with good results \cite{li2024interpreting}, at the expense of having to train both models.

\subsection{Gradient-based training for rule-based and discrete models} 
Due to the good scalability of gradient-based optimization, gradient-based methodologies have been developed for many systems that are not directly differentiable. The most popular is the Straight-Through Estimator (STE) \citep{bengio2013estimating}. Gumbel-Softmax estimator is also very used in architectures that need to sample a categorical distribution in a differentiable model \citep{jang2016categorical}, such as variational autoencoders. Gradient-based optimization for discrete models is also closely related to the quantization of a DNN. For example, one of the pioneering works in using binary weights was aimed at reducing the computing expenses of a DNN model \citep{courbariaux2015binaryconnect}.

The most common approaches to gradient-based rule learning involve the joint use of discrete and continuous models so that continuous models generate a good gradient flow \citep{wang2023learning, zhang2023learning}. The problem in that case is to make sure that the discrete and continuous models behave similarly, which is particularly complex for large models. These models also tend to create large numbers of additive rules, so the reasoning mechanism is very difficult for a human being to understand properly. For the case of fuzzy rule-based inference, it is possible to optimize fuzzy sets using gradient descent \citep{mendel2023explainable}. However, antecedent search using fuzzy sets is not explored in the literature using gradient-descent methods.

Our method, Fuzzy Rule-based Reasoner (FRR), differs from the previous methods in that it proposes an architecture that performs discrete inference while also being able to specify the maximum number of rules, antecedents, and partitions. In addition, the FRR is trained using only gradient-descent techniques and is able to use both sufficient and additive rules, which also enhances its interpretability. 



\section{Gradient-based Rule Inference}

%\subsection{Notation}
%Let $\mathcal{D} = \{(X_1,Y_1),\dots, (X_N,Y_N)\}$ denote a data set with $N$ instances and $M$ features, where $X_i$ is the observed feature vector of the $i$-instance  with $j$-th entry $X_{i,j}$ and $Y_i$ being its discrete associated target. Each feature can be either discrete or continuous, and the target is a categorical variable with $C$ classes. All categorical variables are represented using one hot encoding, and all numeric features are represented as fuzzy linguistic variables with up to $L$ linguistic labels. Thus, if we consider the $j$-th feature, then $\mu_{j,l}(X_{i,j})$ denotes the degree of truth of instance $i$ evaluated in the fuzzy set corresponding to the $l$-th linguistic label.

\subsection{General scheme} \label{sec:general_scheme}

\begin{figure*}
	\centering
	\includegraphics[width=.8\linewidth]{RBF_final}
	\caption{Visual scheme of the Fuzzy Rule-based Reasoner, for example using an input $X_i$ with three features, four rules and two target classes.  The inference process is as follows: \textbf{(1)} We fuzzify the input for each real-valued variable, obtaining the degree of truth for each linguistic label. For categorical variables, we simply identify the specific value it holds. \textbf{(2)} We forward the truth values for each linguistic label and the activated categories in categorical variables to the logic inference layer. This layer selects the linguistic label or category for each antecedent based on the weight magnitudes. We repeat this process for the desired number of antecedents. \textbf{(3)} We reduce the size of the rule by determining which antecedents are needed. If an antecedent is not needed, we substitute its truth degree with one, which is the identity element of multiplication. \textbf{(4)} We compute the truth value for each rule by multiplying the truth degree of its antecedents. \textbf{(5)} We select the output class indicated by the rule with the maximum truth degree. If using additive rules, each rule has a set of weights assigned, which are pondered and then summed based on their truth degrees.}
	\label{fig:scheme}
\end{figure*}

Let $\mathcal{D} = \{(X_1,Y_1),\dots, (X_N,Y_N)\}$ denote a data set with $N$ instances and $M$ features, where $X_i$ is the observed feature vector of the $i$-th instance  with $j$-th entry $X_{i,j}$ and $Y_i$ being its discrete associated target. Each feature can be either discrete or continuous, and the target is a categorical variable with $C$ classes.


The FRR is a rule-based model with $L$ layers of matrix operations.
We will denote by $\mathcal{U}^{(l)}$ the $l$-th layer and by $u_j^{(l)}$ and $n_l$ the $j$-th node and the total number of nodes in that layer, respectively. The output of the $l$-th layer is denoted by a vector $\mathbf{u}^{(l)}$ that contains, as instances, the value of each node and $\mathbf{W}^{(l)}$ represents the connectivity matrix of layer $l$, whose structure and size are specified separately for each layer. We set a $\mathbf{W}$ matrix vector with the connectivity matrices of the different layers for each rule, but we omit this index for the sake of notational simplicity. The components of the FRR are described below and are shown in Figure \ref{fig:scheme}.


	
\subsection{Fuzzification layer} 
Existing rule-based gradient methods rely on dense binarization of real-valued variables to generate partitions, which are then used as potential antecedents for rule construction. In contrast, the FRR model uses fuzzy logic and fuzzy sets to define partitions that are both significantly simpler and more interpretable for end users.

Fuzzy logic extends classical binary logic by allowing truth values to take any real number within the range $[0,1]$ \cite{hajek2013metamathematics}. Traditional Boolean operators are then replaced with their real-valued counterparts. For example, conjunction (the logical ``and") is modelled using T-norms, such as the product or minimum operator, whereas disjunction (the logical ``or") is modelled using T-conorms, such as the maximum operator.

The process of fuzzification involves mapping values from the original domain to degrees of membership in fuzzy sets, which collectively form a fuzzy partition. This partitioning divides the universe of discourse into overlapping fuzzy sets, enabling a more nuanced representation of information. Fuzzy partitions are designed to align with linguistic terms such as "low," "medium," or "high" \cite{zadeh1975concept}. This linguistic representation allows for a more compact set of partitions in real-valued features. Additionally, linguistic concepts provide greater interpretability for end users, as they correspond more naturally to human reasoning than arbitrary numerical thresholds.

The first layer of the FRR model is a fuzzification block that transforms input observations into degrees of truth according to predefined fuzzy partitions. All numerical features are represented as fuzzy linguistic variables with at most $V$ linguistic labels. Formally, the $i$-th instance, feature $j$, and linguistic label $v$, the degree of truth is denoted by $\mu_{j,v}(X_{i,j})$. So, the output of the fuzzification layer is given by $u_{j+v}^{(1)} = \mu_{j,v}(X_{i,j})$.

Categorical variables are represented using one-hot encoding, which can be interpreted as a degenerate form of fuzzy partitioning, where truth values are restricted to $0$ or $1$. Consequently, categorical variables can be seamlessly incorporated into the model without additional considerations, as each category is modelled using a degenerated fuzzy set.

\subsection{Logic inference layers}\label{subsection:logic_inf_layer}

We first consider the Mamdani inference expression to compute the truth value of a fuzzy rule $r$ in an inference system
	\begin{equation}\label{eq:fuzzy_inference}
		r(X) = w_r \prod_{a \in A_r} \mu_{a}(X),
	\end{equation}
	being $w_r$ the rule weight, $A_r$ the set of antecedents of the rule and $\mu_a(X)$ the truth degree of the corresponding fuzzy set.

In order to replicate this, we propose to separate the logic inference into two steps, which correspond to two different layers in the hierarchical model. The first step is to choose which space partitions are forwarded into the rule for each feature. With that aim, layer 2 uses a weight matrix $\mathbf{W}^{(2)}$ of size $M \times V$, i.e., the number of features per number of linguistic labels, which measures the significance of each linguistic label in the logic inference. Then, we only forward the linguistic label with the highest weight value per each feature. In accordance, the output of the second layer is
\begin{eqnarray}\label{eq:u2}
u_j^{(2)} &=&  \sum_{v=1}^V f(W^{(2)}_{j,v}) W^{(2)}_{j,v}u_{j+v}^{(1)} \nonumber \\
&=& \sum_{v=1}^V f(W^{(2)}_{j,v}) W^{(2)}_{j,v}\mu_{j,v}(X_{i,j}),
\end{eqnarray}
where $f$ is an indicator function that, given an instance $M_{i,j}$ of the $i$-row of a certain matrix $\mathbf{M}$, returns 1 if that instance has the highest value in the row, i.e.,
\begin{equation}\label{eq:f}
    f(M_{i,j})=\left\{
    \begin{array}{ll}
        1 & \text{if } j = \argmax_{k} M_{i,k},\\
        0 & \text{otherwise.} 
    \end{array}
    \right.
\end{equation}

The second step for performing the logic inference is to choose which features are selected as part of the antecedents of the rule. In order to set the number of antecedents per rule to a fixed size $A$, in the third layer, we use a weight matrix $\mathbf{W}^{(3)}$ of size $A \times M$, 
 which quantifies the relevance of each feature per antecedent in the rule. The contribution of the $k$-th antecedent is given by the following equation:
\begin{equation}\label{eq:slot_ant}
    A_k=\sum_{j=1}^M f(W^{(3)}_{k,j}) W^{(3)}_{k,j}u_{j}^{(2)},
\end{equation}
where $f$ is the function defined in Eq. (\ref{eq:f}). Consecutively, the degree of truth of each rule is computed as the product of all antecedent's contributions and is the output of the third layer
\begin{equation}\label{eq:u3}
    u^{(3)} = \prod_{k=1}^A A_k =
    \prod_{k=1}^A \sum_{j=1}^M f(W^{(3)}_{k,j}) W^{(3)}_{k,j}u_{j}^{(2)}.
\end{equation}

In this step, it can happen that the same antecedent is propagated more than once. In that case, the same membership is powered as many times as it was chosen, which is equivalent to using linguistic hedges in the original partition space \citep{mendel2023explainable}.

In order to have a valid fuzzy logic inference process, we need to keep the domain of Eq. (\ref{eq:u3}) inside $[0,1]$. Since the input values are already in that range and only the multiplication operation is used, it is sufficient to make sure that the weights are also in that range to keep everything in $[0,1]$. To do so, each weight in Eq. (\ref{eq:u3}) is transformed using the softmax function
\begin{equation}\label{eq:softmax}
\tilde{W}^{(l)}_{i,j}={\frac {e^{ W^{(l)}_{i,j}/\alpha}}{\displaystyle \sum _{m}e^{W^{(l)}_{i,m}/\alpha}}},
\end{equation}
where $\alpha$ is a positive real number called the temperature parameter and controls the sharpness of the distribution. If $\alpha=1$ we retrieve the standard form of the softmax function. We set in our experiments $\alpha=0.1$, so that Eq. (\ref{eq:softmax}) becomes a better approximation of Eq. (\ref{eq:f}), which will be relevant when computing the gradients of the model.

To sum up, if we apply the softmax in Eq. (\ref{eq:softmax}), resolve the argmax functions in Eqs. (\ref{eq:u2}) and (\ref{eq:u3}) and denote by $v_j$ the space partition of the $j$-th feature with the highest weight and $j_k$ the feature with the highest weight for the $k$-th antecedent of the rule we obtain the following expression:
\begin{equation}\label{eq:model_inference}
r(X_i) = \prod_{k=1}^A \tilde{W}^{(3)}_{k,j_k}\tilde{W}^{(2)}_{j_k,v_{j_k}}\mu_{j_k,v_{j_k}}(X_{i,j_k}).
\end{equation}
Notice that since all weights lie within $[0,1]$ the term $\prod_{k=1}^A \tilde{W}^{(3)}_{k,j_k}\tilde{W}^{(2)}_{j_k,v_{j_k}}$ works as $w_r$ in Eq. (\ref{eq:fuzzy_inference}), so the weight of the rule corresponds to the accumulated weight of the relevance of each feature and label selected to be in the antecedent. The other term is the original truth value, i.e., the product of all the membership degrees involved in the rule evaluated to the particular instance. 

%Summarizing, the logic inference is done as follows

%\begin{equation}\label{eq:model_inference_2}
%r(X_i) = \prod_{k=1}^A  \tilde{W}^{(3)}_{k,j_k}\tilde{W}^{(2)}_{j_k,l_{j_k}}\mu_{j_k,l_{j_k}}(X_{i,j_k}) .
%\end{equation}

\subsection{Making the model parsimonious} \label{sec:silencer}

%This layer uses a weight matrix, $\mathbf{W}$, of size = (Number of rules, Number of Variables, Number of space partitions). This weight matrix shall work similarly to a connection matrix that relates the rules with their respective antecedents. Existing continuous approaches to rule-based inference perform thresholding in the weights as a way to determine rule antecedents, which causes problem in gradient flow. However, if we use fuzzy operators, we can replicate fuzzy logical inference without any compromises.

%Consider the Mamdani inference expression to compute the truth value of a fuzzy rule in an inference system:

%\begin{equation} \label{eq:fuzzy_inference}
%    r(X) = w_r \prod_{i=1}^{|m_r|} \mu_{r_i}(x_i) ,   
%\end{equation}

%\noindent being $w_r$ the rule weight and m$_r$ is the subset of features relevant to rule $r$. In order to replicate this, the first step is to choose for each antecedent which space partitions are forwarded into the rule. To do that, we only forward the space partitions that hold the biggest weight value in each antecedent. Then, we compute the truth value of the relevant partitions for each antecedent, multiplied by the weight matrix (for the sake of clarity, we show the expression for only one rule):

%\begin{equation} \label{eq:indicator_weights_forward}
%    r(X) = \prod_{i=1}^{m} \sum_{j=1}^{l} \indicator{w_{i,j}=\max W_i} w_{i,j} \mu_{r_i}(x_i).    
%\end{equation}

%If we take into account the indicator function in Eq. (\ref{eq:indicator_weights_forward}) and take the weights out of the product, we obtain the following expression:

%\begin{equation} \label{eq:fuzzy_inference_equivalent}
%    r(X) = \prod_{i=1}^{m} w_{r_i} \prod_{i=1}^{m} \mu_{r_i}(x_i).    
%\end{equation}

%As long as all $w_i \in [0,1] $ The term $\prod_{i=1}^{n} w_i$ works as $w_r$ in Eq. (\ref{eq:fuzzy_inference}), and the other term is the original truth value. If we do not want to use rule weights, we can then divide the result by the same $\prod_{i=1}^{n} w_i$ term, which would result in the same output as Eq. (\ref{eq:fuzzy_inference}). However, for the gradient to still operate correctly in this expression, we apply the division term as a constant.

The procedure in Section \ref{subsection:logic_inf_layer} sets the number of antecedents per rule to a fixed value. This number represents the highest possible count of antecedents, but ideally, we aim to keep the number of antecedents limited to ensure rule interpretability and reduce the risk of overfitting. In many cases, concise rules not only enhance performance but also ensure that the model remains easily understandable for human users.

To reduce the number of antecedents in each rule, we make them ``compete'' with a null element that will make the system ignore the antecedent value if it is not useful. To do so, we can consider the convex combination between $1$ and the contribution of each antecedent of the rule
\begin{equation}
	\tilde{A}_k = \alpha_k A_k +  (1-\alpha_k),
\end{equation}
where $\alpha_k \in [0,1]$. When $\alpha_k=1$, the value $A_k$ is unmodified, and when $\alpha_k=0$, $\tilde{A}_k =1$, which makes this irrelevant for the computation of Eq. (\ref{eq:u3}). Nonetheless, to avoid having only partially cancelled antecedents, we use again the indicator function in Eq. (\ref{eq:f}) and slightly modify the expression using two weights instead of one
\begin{equation}\label{eq:antecedent_silencer}
\tilde{A}_k = \prod_{k=1}^A (f(\alpha_{k,1})A_k + f(\alpha_{k,2})),
\end{equation}
where $\alpha_{k,1}, \alpha_{k,2} \in \mathbb{R}$. We can do this after the antecedent has been selected in Eq. (\ref{eq:u3}) by replacing $A_k$ for $\tilde{A}_k$.


%\RFc{Este $\alpha$ no es el mismo para todos? O cada slot del antecedente tiene su propio parmametro $\alpha_k$? Lo digo porque aqui la notacion cambia un poco, y ya no se usa la funcion $f$ en Eq. (\ref{eq:f}). Pero en verdad este paso podria corresponder a otra matriz de pesos con cada $\alpha_k$ y un $1-\alpha_k$ por fila, y con la $f$ seleccionar la columna de mayor valor. La capa se podria llamar silenciador o algo asi. La expresion queda:

%\noindent where $\alpha\in [0,1]$. When $\alpha=1$, the antecedent value $A_k$ is completely taken into account, and when $\alpha=0$, $A_k=1$, which makes this irrelevant for the computation of Eq. (\ref{eq:model_inference}). \RNew{However,} in most scenarios $\alpha$ will take a real value between 0 and 1, which makes the condition only partially ignored. To avoid having only partially cancelled antecedents, we use again an indicator function that returns one for the highest value in the convex combination:
%\begin{equation} \label{eq:indicator_weights_forward}
%	\tilde{A_k} = \alpha \indicator{\alpha = \max \{\alpha, 1-\alpha\}} A_k +  (1-\alpha) \indicator{\alpha = \min \{\alpha, 1-\alpha\}}.  
%\end{equation}



\subsection{Final decision layer}

This module computes the predictions of the FRR given the truth degrees of the rules. In this layer, we consider the matrix $\mathbf{W}^{(4)}$ of size $R \times C$ where $R$ is the number of rules and $C$ the number of classes of the target variable. Then, each weight $W_{s,c}^{(4)}$ corresponds to the score that rule $r_s$ gives to class $c$. Taking into account the truth degrees of each rule provided by the previous layer,  we can compute the final outcome, denoted in general by $u^{(4)}_c$,  using sufficient or additive rules.
\begin{itemize}
	\item \textit{Sufficient rules}: 
    for a fixed class $c$ we consider the set of rules whose maximum score is assigned to $c$ and then we consider the value of the highest score per truth degree as output
    \begin{equation}\label{eq:sufficient}
		FRR(X_i)_c^{suf} = \max_{s \in \{1,\dots,R\}} f(W_{s,c}^{(4)})W_{s,c}^{(4)} r_s(X_i).
    \end{equation} 
	To select which rules have $c$ as the class with maximum score we use again the function in Eq. (\ref{eq:f}).
	\item \textit{Additive rules}: in this case we just perform the standard matrix multiplication between the rules truth degrees and the score matrix
	\begin{equation}\label{eq:additive}
		FRR(X_i)_c^{ad} = \sum_{s=1}^R W_{s,c}^{(4)} r_s(X_i).
	\end{equation}
\end{itemize}

Again, we need to apply the softmax function in Eq. (\ref{eq:softmax}) to maintain the weights between $[0,1]$. In this manner, since fuzzy truth degrees are already numbers in $[0,1]$, we can directly apply the cross-entropy loss $\mathcal{L}$ without further modifications.
%$$
%L= - \sum_{i=1}^{N}\sum_{c=1}^{C}Y_{i,c}\cdot \log(FRR(X_i))_c,
%$$
%where $Y_{i,c}$ is the one-hot encoding of $Y_i$.

Notice that Eqs. (\ref{eq:u2}), (\ref{eq:u3}), (\ref{eq:antecedent_silencer}) and (\ref{eq:sufficient}) are not differentiable with respect to the weights because of the presence of the argmax function in the definition of $f$ in Eq. (\ref{eq:f}). We show how to overcome this problem and others related to gradient-based optimization of the FRR in Section \ref{sec:derivations}.
%in order to optimize the cross-entropy loss using gradient descent, we propose the use of Straight-Through Estimators (STEs) and a relaxation of the indicator function. We provide all the training details of the model in Section \ref{sec:derivations}.


% Las secciones cambiadas se han puesto en el documento raquel_comments.tex



\subsection{Extracting the rules from the model}
Once trained, we can recover the rules obtained by the system by following ``the paths'' in the FRR.  For each rule, we select the features that have the biggest weights according to $\mathbf{W}^{(3)}$ that were not cancelled in Eq. (\ref{eq:antecedent_silencer}). Then, for each feature we select the linguistic label according to $\mathbf{W}^{(2)}$ and finally, in the decision layer, we choose the consequent according to $\mathbf{W}^{(4)}$ and depending on if we are working with sufficient or additive rules, considering Eq. (\ref{eq:sufficient}) or (\ref{eq:additive}), respectively.


%For each rule and each antecedent, we select the linguistic label that had the biggest weight for every $z$ in $W^{(3)}$. Then, we discard those antecedents that were cancelled according to Eq. (\ref{eq:indicator_weights_forward}). Finally, in the decision layer, we choose the consequent for each rule based on the biggest weight they assign to each class.

%\section{Gradient-descent and the FRR}
\section{Gradient-based optimization of the FRR}
\label{sec:derivations}

\subsection{Component derivation in the FRR}
To optimize the cross-entropy loss we consider gradient-based optimization, so the parameters are going to be updated according to
\begin{equation}
\mathbf{W}^{(l)}\mid_{t+1} = \mathbf{W}^{(l)}\mid_{t} -\eta_t \frac{\partial \mathcal{L}}{\partial \mathbf{u}^{(4)}} \cdot \frac{\partial 
\mathbf{u}^{(4)}}{\partial \mathbf{W}^{(l)}},
\end{equation}

where $\eta_t$ is the learning rate. Then, to ensure an effective update of the model's parameters, let us analyse the derivative of each node with respect to its directly connected weights and nodes.

First of all, since all the weights are normalized using the softmax function (see Eq. (\ref{eq:softmax})), the derivative of each node according to the weights is multiplied by the derivative of the softmax, i.e, 
$$\frac{\partial u^{(l)}}{ \partial W_{i,j}^{(l)}} = \frac{\partial u^{(l)}}{ \partial \tilde{W}_{i,j}^{(l)}} \cdot \frac{\partial \tilde{W}_{i,j}^{(l)}}{\partial W_{i,j}^{(l)}},
$$
where 
\begin{equation}\label{eq:d1}
\frac{\partial \tilde{W}_{i,j}^{(l)}}{\partial W_{i,m}^{(l)}}
=
\frac{1}{\alpha}\tilde{W}_{i,j}^{(l)}\cdot(\delta_{j,m}-\tilde{W}_{i,m}^{(l)}),
\end{equation}
and $\delta_{j,m}$ is the Kronecker delta. Then, we can compute the derivative of Eqs. (\ref{eq:u2}) and (\ref{eq:u3}) with respect to the normalized weights directly.

\begin{equation}\label{eq:d2}
\frac{\partial u_j^{(2)}}{\partial \tilde{W}_{j,v}^{(2)}} =  \left(\frac{\partial f}{\partial \tilde{W}_{j,v}^{(2)}}\tilde{W}_{j,v}^{(2)}+f(\tilde{W}_{j,v}^{(2)}) \right) u_{j+v}^{(1)}.
\end{equation}
\begin{equation}\label{eq:d3}
\frac{\partial u_j^{(2)}}{\partial u_{j+v}^{(1)}} = f(\tilde{W}_{j,v}^{(2)})\tilde{W}_{j,v}^{(2)}.
\end{equation}
\begin{eqnarray}\label{eq:d4}
\frac{\partial u^{(3)}}{\partial \tilde{W}_{k,j}^{(3)}}
&=& \left(\frac{\partial f}{\partial \tilde{W}_{k,j}^{(3)}}\tilde{W}_{k,j}^{(3)}+f(\tilde{W}_{k,j}^{(3)}) \right) u_{j}^{(2)} \cdot \nonumber \\
&& \prod_{\substack{1 \leq m \leq A \\ m \not = k}} \sum_{n=1}^M f(\tilde{W}^{(3)}_{m,n}) \tilde{W}^{(3)}_{m,n}u_{n}^{(2)}.
\end{eqnarray}
\begin{equation}\label{eq:d5}
\frac{\partial u^{(3)}}{\partial u_j^{(2)}} = \sum_{k=1}^A f(\tilde{W}_{k,j}^{(3)})\tilde{W}_{k,j}^{(3)} \prod_{\substack{1 \leq m \leq A \\ m \not = k}} \sum_{n=1}^M f(\tilde{W}^{(3)}_{m,n}) \tilde{W}^{(3)}_{m,n}u_{n}^{(2)}.
\end{equation}

%We omit the derivatives of Eqs. (\ref{eq:sufficient}) and (\ref{eq:additive}) since the last layer is a standard classification layer.

By the visual inspection of the derivatives, it is clear that there are several issues to overcome for an efficient training:

\begin{itemize}
    \item The derivatives in Eqs. (\ref{eq:d3}) and (\ref{eq:d5}) are 0 whenever the corresponding weight is not chosen by the indicator function $f$, i.e., when the weight is not the biggest one, then it is not updated. This gradient sparsity may severely affect the speed's training.
    %Thus, in all those cases the gradient flow is blocked which may severly affect the speed's training.
    \item The derivative of $f$ appears in Eqs. (\ref{eq:d2}) and (\ref{eq:d4}) but $f$ is not differentiable since it is defined using the argmax.
    \item The derivative of the nodes in which the logic inference is performed, i.e., Eq. (\ref{eq:d5}), involves the product of several terms between $[0,1]$ which may result in the vanishing gradient problem. Notice that this issue escalates with the maximum number of antecedents $A$.
\end{itemize}
The derivatives of the remaining components have a similar behaviour and they are included in Appendix \ref{apx:derivatives}.

In the following sections we introduce several techniques which overcome the above issues and can ensure and efficient training of the FRR.

%Apart from the use of techniques that are related to the optimization of ``discrete models'', in this paper we introduce a new technique called restricted additive contributions that uses a relaxation of the indicator function to enable a decreasing contribution of all the features of the model during training but ensuring a valid logic inference after training.


%\RFc{En algun sitio citar las BNNs}

%\subsection{Straight-through estimators}

\subsection{Gradient estimation}

%Similarly to the FRR, in other machine learning models like Binarized Neural Networks (BNNs) or Reinforcement learning models with discrete actions it is required to use non-differentiable functions to include hard-nonlinearities. In these cases, there exist different methods that can be used to estimate the gradients and backpropragate through the corrresponding neurons. 

To compute the derivative of function $f$, present in numerous equations in the FRR, we have considered gradient estimators, which substitute the derivative of the non-differentiable function by an approximation. This approximation is typically the derivative of the identity function (STE) or another smooth function which behaves similarly to the original \cite{yin2018}. In the case of the FRR, we replace the derivative of $f$ in Eqs. (\ref{eq:d2}) and (\ref{eq:d4}) by $0$ or the identity.
%, or the derivative of the softmax as an approximator of the argmax function, i.e., 
%$$
%\frac{\partial f}{ \partial \tilde{W}_{i,j}^{(k)}} \hookleftarrow 1.
%$$
%$$
%\frac{\partial f}{ \partial \tilde{W}_{i,j}^{(k)}} \hookleftarrow \tilde{W}_{i,j}\cdot(\delta_{j,m}-\tilde{W}_{i,m}).
%$$
Although other approximators could be considered as gradient estimators, there is no guarantee of better results with respect to the use of the identity function \cite{schoenbauer2024}.

Apart from STE, we have also considered ``gradient grafting'' \cite{wang2023learning}, which consists of training simultaneously a discrete model in the forward pass and a continuous one in the backward pass. 
%The FRR easily adapts to this training method, because if the function $f$ in (\ref{eq:f}) is replaced by the identity function we obtain a continuous model that can be trained to use gradient grafting. 


\subsection{Restricted additive contributions}

The FRR mimics the behaviour of fuzzy logic inference because of the different indicator functions used during the inference process. However, these functions present some problems. First, they are not differentiable, and we need to use a STE. Secondly, even with the STE, the indicator functions reduce the flow of information to only one of the possible paths. In order to speed up training, we propose a relaxed version of the indicator function during training time that will also keep the standard behaviour of the model in inference mode. Let $\mathbf{M}$ be a matrix of size $n \times m$, we define:
%Secondly, even with the STE, indicator functions reduce the flow of information to only one rule per class and only to the antecedents used. In order to speed up training, we propose a soft version of the indicator function during training time, that will also keep the standard behaviour of the model in inference mode. Let $\mathbf{M}$ be a matrix of size $n \times m$, we define
\begin{equation}\label{eq:fbeta}
    f_\beta(M_{i,j})=\left\{
    \begin{array}{ll}
        \frac{1}{1+\beta(m-1)} & \text{if } j = \argmax_{k} M_{i,k},\\[0.2cm]
        \frac{\beta}{1+\beta(m-1)} & \text{otherwise,} 
    \end{array}
    \right.
\end{equation}
where $\beta \in [0,1]$ is a hyperparameter of the model. In this way, when $\beta>0$, the additive nature of the summations is restricted but not completely ignored. When $\beta=0$, Eq. (\ref{eq:fbeta}) is equivalent to a hard indicator function. Since $\sum_{j=1}^m f_{\beta}(M_{i,j})=1$ always holds regardless of the value of $\beta$, the output will not change the scale of the input values. 
%However, notice that in this case $f_{\beta}$ is again non-differentiable so we need to maintain the use of the STE.

To set the value $\beta$ during training, we start with a maximum value (usually $1$) and gradually decrease it to a minimum value (usually $0$). This allows the model to explore freely with larger gradient flows initially and resemble final inference behavior in later epochs. 
%We also add a cyclical component to ensure $\beta$ growth is not monotonous during training, like in training schedulers \citep{loshchilov2016sgdr}. Given $T$ the total number of epochs and $t$ the number of the actual epoch:
%\begin{equation}\label{eq:beta_t}
%     \beta_t = a \cdot \left(1 - \frac{t}{T}\right) + c \cdot \sin\left(2\pi d \cdot \frac{t}{T}\right).
%\end{equation}

%\RFc{Under construction $\downarrow$}


\subsection{Projection functions}

The FRR might find problems of vanishing gradient because the truth degree of a rule is computed using the product of values in the $[0,1]$ range, which might result in values very close to $0$ in Eq. (\ref{eq:d5}). A feasible solution is to use custom functions to slow down the speed of approaching to zero. In \cite{wang2023learning} the authors came across a very similar problem, and they propose to use the following function:
$$
    P(x) = \frac{1}{1-\log(x)}.
$$
However, there are many other functions, like $P(x) = \sqrt[n]{x}$, that would serve the same purpose.

In the case of the FRR, this function can be applied when computing the rule truth degree in Eq. (\ref{eq:u3})
\begin{equation}\label{eq:P}
\tilde{u}^{(3)} = \prod_{k=1}^A P(A_k+\varepsilon),
\end{equation}
with $\varepsilon$ a positive small constant. 

%\RFc{Comentario: Esto son funciones de activacion?? Si no se aplican al output de la capa. No serian funciones de activacion si se aplicasen al producto final mas bien?}

%\RFc{Otras opciones:
%\begin{itemize}
%    \item Incorporar un parametro a esta $P$
%    $$
%    P(x) = \frac{1}{1-\alpha\log(x)},
%    $$
%    $\alpha \in (0,+\infty)$. Contra mas cercano a 0, mas se elevan los valores cercanos a 0.
%    \item Usar la siguiente funcion
%        $$
%    P(x) = \sqrt[{\alpha}]{x},
%    $$
%    $\alpha \in (1,+\infty)$. Contra mas cercano a $+\infty$, mas se elevan los valores cercanos a 0. Esto deberia ser completamente igual a usar la $P$ de antes y no tienes problemas con el logaritmo.
%    \item Usar otra t-norma que eleve los valores cercanos a 0:
%    $$
%    \tilde{u}^{(3)} = 
%    \underset{k=1}{\overset{A}{\mathbf{\LARGE T}}} A_k
%    $$
%    Esto se puede combiar con las funciones de activacion.
%        \item Usar la media geometrica
%    $$
%    \tilde{u}^{(3)} = \sqrt[A]{\prod_{k=1}^A A_k},
%%    $$
%    Esto se puede combinar con las funciones de activacion, pero cambia como se hace la inferencia obviamente.
%\end{itemize}
%}
%Transformation of the space to slow the speed of approaching to zero.

%Following \cite{wang2023learning}, in which the authors came across a very similar problem, we propose to use the following projection for the rule truth degrees in Eq. (\ref{eq:model_inference}):

%$$
%\frac{dP}{dx} = \frac{1}{x(1-\log(x))^{2}}.
%$$

%Notice that classical activation functions like ReLU do not overcome this issue, since the input is between 0 and 1, so it will remain invariant.

\subsection{Residual connections}
We also incorporate a residual connection to tackle the problem with the vanishing gradient in Eq. (\ref{eq:u3}). We consider another connection between the rules output and their antecedent values, similar to residual connections \citep{he2016deep}:
\begin{equation}
    %\tilde{u}^{(3)} = u^{(3)} + \gamma \sum_{j=1}^M u_j^{(2)}.
    \tilde{u}^{(3)} = u^{(3)} + \gamma \sum_{k=1}^AA_k.
\end{equation}
\noindent The multiplying constant $\gamma$ of this expression starts at $0.1$ and decreases linearly with the number of epochs passed in the training process, reaching $0$ at the end and in the inference process.






%\RFc{Estas derivadas estan afectadas tambien por la softmax y la funcion $P$. A parte de la ``capa'' que silencia los pesos:}




%\subsection{Using gradient flow using restricted additive contributions}

%The FRR mimics the behaviour of the classical fuzzy logic inference because of the different argmax functions used during the inference process. If those functions were not present, all the terms in those expressions would contribute to the output.

%However, indicator functions present some problems gradient-wise. First, as we mentioned before, is that these functions are not differentiable and we need to use a STE. Secondly, even with the STE, indicator reduce the flow of information to only one rule per class and only to the antecedents used. In order to speed up training, we propose a soft version of the indicator function during training time, that will also keep the standard behaviour of the model in inference mode:

%\begin{equation} \label{eq:new_indicator}
%	f(w)_{W,k} =
%	\begin{cases}
%		\frac{1}{1 + k(|W|-1)} , w=\max W, \\
%		\frac{k}{1 + k(|W|-1)}, \text{otherwise}.
%	\end{cases}
%\end{equation}

%\noindent being $k\in[0,1]$ a hyperparameter of the model. In this way, when $k>0$ the additive nature of the summations is restricted, but not completely ignored. When $k=0$, Eq. (\ref{eq:new_indicator}) is equivalent to a hard indicator function. Since $\sum f(w)_{W,k}=1$ always holds regardless of the value of $k$, the output will not change the scale of the input values.

%Setting the $k$ value during training is not straightforward and can have a significant impact in the final performance of the system. We will discuss different strategies to set this value in Section \ref{sec:exps}.

%\RFc{Yo aqui tambien explicaria como esto rompe que todo este entre [0,1], per al final y en inferencia se mantiene la coherencia.}

%\subsection{Improving gradient flow}

%The FRR might find problems with vanishing gradient because the truth degree of a rule is computing using the product of values in the $[0,1]$ range. Following \cite{wang2023learning}, in which the authors came across a very similar problem, we propose to use the following projection for the rule truth degrees in Eq. (\ref{eq:model_inference}):

%\begin{equation}
%    P(x) = \frac{-1}{-1+\log(x)}.
%\end{equation}

%\RFc{Falta explicar lo de las funciones de activacion logicas.}

%\RFc{Falta explicar la constante $\varepsilon$ para que no haya problemas con el 0.}

%\RNew{
%$$
%\tilde{r}(X_i) = \prod_{k=1}^A P(A_k+\varepsilon)
%$$
%with $\varepsilon$ a positive small constant.
%}

%We also found that using activation functions in the training process also made training more efficient. During training, we changed the $\sigma$ function in Eq. (\ref{eq:1}) and Eq. (\ref{eq:indicator_weights_forward}) by the SELU activation function \citep{klambauer2017self}. 

%To set the $k$ value during training, we use a function that starts with a maximum value, usually $1$, and then gradually decreases it during training until it reaches the minimum value, which is usually $0$. In this way, at the beginning of the training process the model can explore more freely with bigger gradient flows, and then it resembles more the final inference behaviour during the last epochs. Similarly to what is sometimes done in training schedulers, we also add a cyclical component \citep{loshchilov2016sgdr}, so that the $k$ growth is not monotonous during training. Given $T$ the total number of epochs and $t$ the number of the actual epoch:
%\begin{equation}
%     k_t = a \cdot \left(1 - \frac{t}{T}\right) + c \cdot \sin\left(2\pi d \cdot \frac{t}{T}\right).
%\end{equation}
%We also incorporate a residual connection to tackle the problem with the vanishing gradient in Eq. (\ref{eq:model_inference}). We incorporate another connection between the rule outputs and its antecedent values, similar to residual connections \citep{he2016deep}:
%\begin{equation}
%    r(X_i) = \prod_{k=1}^{A} A_k + \gamma \sum_{j=1}^M u_j^{(2)}.
%\end{equation}

%\noindent The multiplying constant $\gamma$ of this expressions starts at $0.1$ and decreases linearly with the number of epochs passed in the training process, reaching $0$ at the end and in the inference process.


%\begin{equation}
%    r(x) = \prod_{k=1}^{A} r_z(X) + 0.1 \sum A_r(X)
%\end{equation}

\section{Experiments} \label{sec:exps}



\subsection{Experimental settings}

We took $40$ datasets of different sizes, all of which are very common in studying classification performance. They range from $80$ to $19020$ samples and from $2$ to $85$ for different numbers of features. Please take a look at Appendix \ref{sec:datasets} to see their specific details and citations. As a performance metric, we use the standard accuracy metric. We use a 5-fold evaluation to obtain more reliable results than a traditional $80/20$ split. When evaluating tree and rule-based models, we also measure the number of rules and antecedents they use to solve the problems. 

For the fuzzification of real-valued variables, we use $3$ linguistic labels, which are translated to the concepts of ``low'', ``medium'' and ``high''. The parameters for each of them are computed based on the quantile distribution. See more details about this in the Appendix \ref{sec:fuzzyfication_details}.

\subsection{Comparison with an equivalent classifier optimized with genetic fine-tuning}

We fitted different fuzzy rule-based classifiers using genetic optimization, which is the current state-of-the-art for such systems. We fit classifiers with different number of rules and antecedents, and we found that the best classifiers with this technique were obtained using smaller models (detailed results are shown in Appendix \ref{sec:detailed_res}).

Then, we trained an FRR using the equivalent maximum number of rules, antecedents, and the same linguistic variables to find the best genetic one. The results for both are in Table \ref{tab:cmp_results} under the ``FRR'' and the ``FGA'' columns. We can see there that the FRR obtained a significant improvement in terms of accuracy over the FGA, backed by a t-test with $p < 0.01$. The number of rules was also bigger, but if we consider both the number of rules and antecedents, we see that the FRR resulted in less complex classifiers (Figure \ref{fig:complexity_accuracy}).

\subsection{Scaling the size of the FRR}

Although the ideal FRR should be as compact as possible, we also believe that it is good to be able to scale the model to more complexity if the trade-off of performance is considered worth it by the user. 

Just as with genetic optimization, we found problems in scaling the FRR to larger numbers of rules. However, we also found that using additive rules instead of sufficient rules allowed the system to scale better in terms of performance, as can be seen in Figure \ref{fig:complexity_accuracy} and Table \ref{tab:cmp_results} under the label of AdFRR.

%For other strategies applied to reduce the size of both the FRR and the AddFRR we refer the reader to the Appendix \ref{sec:reduce_complexity}.

\subsection{Classification performance and comparison with other explainable and standard classifiers}

\begin{table*}[ht]
	\centering
	
	\caption{5-fold accuracy results for all the datasets considered. We also show the average number of rules used for rule-based models. Models before the vertical bar are those considered interpretable.}
	\begin{adjustbox}{width=\textwidth}
		
		\begin{tabular}{c|ccccccc|cccc}
			\toprule
			Method               & AdFRR &  FRR& FGA   & RRL &   CART & C4.5 & LR  & SVM& MLP& RF & GB \\
			\midrule
			Accuracy             & $78.00$& $76.90$ & $70.46$ & $82.33$ &$80.67$ & $76.87$ & $82.22$ & $83.51$ &$82.84$ & $85.87$ & $83.94$ \\
			Number of Rules & $32.32$& $13.77$ & $7.12$  & $99.85$ &$39.75$ & $131.92$ &- & - & - & - & - \\
            Antecedents per Rule &$1.32$ & $1.94$ &  $2.23$ & $8.43$  & $5.75$ & $8.10$ & - & - & - & - & - \\
			\bottomrule
		\end{tabular}
	\end{adjustbox}
	\label{tab:cmp_results}
\end{table*}

Table \ref{tab:cmp_results} shows the results for all the datasets and all the classifiers tested. The interpretable methods chosen were: an equivalent Fuzzy Rule Based classifier using genetic fine tuning \cite{fumanalex2024} (FGA),  Rule-based Representation Learning (RRL), which is another method to obtain gradient optimized rules \citep{wang2021scalable}, classification trees constructed using Classification and Regression Trees (CART) methodology \citep{timofeev2004classification}, C4.5 \cite{quinlan1993c4} and a Linear Regression (LR). We also show results for four models considered ``complex'': a Support Vector Machine (SVM), a Multilayer Perceptron (MLP) \citep{hackeling2017mastering}, Random Forest (RF) \citep{ho1995random} and Gradient Boosting (GB) \citep{friedman2001greedy}, being the latter two ensemble models.

In terms of accuracy, the best explainable classifier obtained was the RRL, with an average accuracy of $82.33$. It did so, however, but using the largest number of additive rules and antecedents per rule, which makes it hardly interpretable in practice.

In terms of the number of rules, the FRR was only surpassed by the Genetic fine-tuning of the fuzzy rule inference, which performed significantly worse than the FRR in terms of accuracy. The most direct competitor of the FFR, the RRL, obtained more accuracy at the expense of using more than 7 times the number of rules, which are also additive and less interpretable than the FRR sufficient rules. The AdFRR obtained better results than the FRR and the C4.5. An example of a rule base obtained with the FRR is shown in Figure \ref{fig:diabetes_rules}.

We believe that all the classifiers that used fuzzy sets were limited in performance by the fuzzification method used, which prioritized explainability over performance. It is also worth pointing out that the performance of any of the explainable classifiers did not surpass the performance of complex classifiers, which shows that there is still a lot of room to improve for explainable classifiers.

\begin{figure}[ht]
    \centering
    \includegraphics[width=.7\linewidth]{ComplexityAcc.pdf}
    \caption{Relation between classifier complexity in terms of antecedents and rules and classifier performance for those classifier where it applies.}
    \label{fig:complexity_accuracy}
\end{figure}

\subsubsection{Ablation study}

To show the effect of the gradient estimation methods in the training process, we also run the FRR with different configurations:
\begin{itemize}
    \item For the indicator in training: we use the standard indicator, the restricted additions and no indicator.
    \item With and without residual connections.
    \item For gradient estimation: STE$_0$, approximating the gradient of the indicator with $0$, STE$_1$ likewise with the identity function, and using gradient grafting in substitution of the STE method \citep{wang2021scalable}. 
\end{itemize}

The results are shown in Table \ref{tab:ablation_results}, which shows that the residual connections were instrumental in achieving good results. Restricted additions were particularly effective when combined with gradient grafting. For results of more combinations of parameters, we refer the reader to Appendix \ref{sec:complete_ablation}.

\begin{table}[ht]
	\centering
	\caption{Results for the ablation study of the compact FRR using different gradient strategies.}
	\adjustbox{max width=\linewidth}{%
		\begin{tabular}{ccc|c} % adjust column alignment as needed
			\toprule
			Indicator & Res. connections & Grad. Strategy & Accuracy \\
            \midrule
                Continuous & No & STE$_0$ & $55.52$\\
                Standard & No & STE$_0$ & $73.52$\\
                Standard & Yes & STE$_0$ & $\mathbf{76.90}$\\
                Standard & No & STE$_1$ & $73.80$\\
                Continuous & No & STE$_1$ & $73.89$\\
                Standard & Yes & STE$_1$ & $76.62$\\
                Continuous &Yes & STE$_1$ & $76.71$\\
                \midrule
                Restricted & No & Graft & $74.08$\\
                Continuous &No & Graft & $72.81$\\
                Restricted & Yes & Graft & $76.78$\\
                Continuous &Yes & Graft & $75.97$\\
			\bottomrule
	\end{tabular}}
	\label{tab:ablation_results}
\end{table}

 

%\begin{figure}
%    \centering
%    \begin{tabular}{l}
%    \toprule
%         Rules for Non-Diabetic \\
%    \midrule
%     \cellcolor{gray!25}IF Diabetes Pedigree IS Low AND Age IS Low \\
%    IF Skin Thickness IS Low AND Insulin IS Medium  \\
%    \cellcolor{gray!25} IF BMI IS Low \\
%    IF Blood Pressure IS High AND Insulin IS Low \\
%    \cellcolor{gray!25} IF Times Pregnant IS Medium AND \\
%     \cellcolor{gray!25} AND Blood Pres. IS High AND Age IS Medium \\
%    \midrule
%    Rules for Diabetic \\
%    \midrule
%    \cellcolor{gray!25} IF Glucose level is IS High \\
%         \bottomrule
%    \end{tabular}
%    \caption{Rules for the \textit{pima} dataset.}
%    \label{fig:table_rules}
%\end{figure}

\begin{figure}[htbp]
    \centering
    \begin{tabular}{l}
    \toprule
    \multicolumn{1}{c}{\textbf{Rules for Non-Diabetic Patients}} \\
    \midrule
    \rowcolor{gray!25} IF Diabetes Pedigree IS Low \textbf{AND} Age IS Low \\
    IF Skin Thickness IS Low \textbf{AND} Insulin IS Medium \\
    \rowcolor{gray!25} IF Body Mass Index (BMI) IS Low \\
    IF Blood Pressure IS High \textbf{AND} Insulin IS Low \\
    \rowcolor{gray!25} IF Times Pregnant IS Medium \textbf{AND} \\
    \rowcolor{gray!25} Blood Pressure IS High \textbf{AND} Age IS Medium \\
    \midrule
    \multicolumn{1}{c}{\textbf{Rules for Diabetic Patients}} \\
    \midrule
    \rowcolor{gray!25} IF Glucose Level IS High \\
    \bottomrule
    \end{tabular}
    \caption{Classification Rules for the \textit{Pima Indians Diabetes} Dataset \cite{smith1988using}.}
    \label{fig:diabetes_rules}
\end{figure}
\section{Conclusions and future work}

We introduced a new explainable classifier, named Rule-based Fuzzy Reasoner (FRR), that can
automatically learn rules for data representation and classification using gradient-based optimization. The FRR comes with a big advantage over other rule-based methods: the user can set the number maximum number of rules and their length, which avoids common problems in real-life applications like having an excessive number of rules and antecedents and overly complex partitions of the space. The FRR presented a series of problems in non-differentiable functions and vanishing gradients, which we studied and mitigated. As tested in the experimentation, the FRR can obtain good performance results both for sufficient and additive rules. Going forward, we aim to study novel fuzzification methods that can retain interpretability while offering better performance. Also, we aim to use the FRR inside bigger deep learning frameworks so that it can offer rule-based explanations of these model's predictions within the same gradient flow.


\section{Acknowledgements}

Javier Fumanal-Idocin research has been supported by the European Union and the University of Essex under a Marie Sklodowska-Curie YUFE4 postdoc action.
Raquel Fernandez-Peralta is funded by the EU NextGenerationEU through the Recovery and Resilience Plan for Slovakia under the project No. 09I03-03-V04- 00557.

%

The authors acknowledge the use of the High Performance Computing Facility (Ceres) and its associated support services at the University of Essex in the completion of this work.

%\section{Impact Statement}
% Nota: esto es lo que piden poner en el ICML si no haces nada que tengas consecuencias directas en la sociedad/presente dilemas eticos.

%This paper presents work that focuses on Explainable AI. Since patterns are explicitly presented to the user, it is possible for him/her to recognize and even delete those that are believed to be harmful to specific groups, which we believe can help AI achieve a positive impact on society.


\bibliographystyle{plainnat}
\bibliography{neurips_2023}
\newpage
\appendix
\onecolumn

\section{Computing the fuzzy partitions} \label{sec:fuzzyfication_details}

For our fuzzy partitions, we use trapezoidal memberships. We chose them instead of Gaussian or other shapes because they are linear functions that are easier to understand for humans. Gaussian shapes are never strictly 0, which can cause unintuitive results sometimes.

The expression for the fuzzy membership takes four parameters:
\begin{equation} \label{eq:trapezoid}
	\mu_A(x) = \begin{cases} 
		0 & \text{if } x \leq a, \\
		\frac{x-a}{b-a} & \text{if } a < x \leq b, \\
		1 & \text{if } b < x \leq c, \\
		\frac{d-x}{d-c} & \text{if } c < x \leq d, \\
		0 & \text{if } x > d.
	\end{cases}
\end{equation}

The parameters $a,b,c,d$ can be easily optimised through gradient as well, but we are not warranted to obtain a reasonable result in that case i.e. lower values in the input space should always have a lower membership value to ``high'' and ``medium'' than to ``low''. Similarly to ReLU, trapezoidal functions are differentiable everywhere except by four points, which does not cause issues during training.

Our preferred setup is to use $3$ linguistic labels, which are translated to the concepts of ``low'', ``medium'' and ``high''. The parameters for each of them are computed based on the quantile distribution:

\noindent Let $\mathbf{X}$ be a matrix of shape $(n, m)$ where $n$ is the number of samples and $m$ is the number of variables.
\begin{enumerate}
	\item Compute quantiles:
	Define quantile percentages: $q_i = \{0, 20, 40, 60, 80, 100\}$
	Compute quantiles: $Q_i = P_{q_i}(\mathbf{X}), \quad i = \{0, 1, 2, 3, 4, 5\}$ where $P_{q}(\mathbf{X})$ is the q-th percentile of each column in $\mathbf{X}$.
	\item  Compute partition parameters:
	Define a tensor $\mathbf{P}$ of shape $(m, 3, 4)$ to store partition parameters.
	
	For the first partition $(i = 0)$:
	\[\begin{cases}
		P_{:,0,0} = Q_0 \\
		P_{:,0,1} = Q_0 \\
		P_{:,0,2} = Q_1 \\
		P_{:,0,3} = Q_2 \\
		
	\end{cases}\]
	
	For the second partition $(i = 1)$:
	\[\begin{cases}
		P_{:,1,0} = Q_1 \\
		P_{:,1,1} = (Q_1 + Q_2) / 2 \\
		P_{:,1,2} = (Q_2 + Q_3) / 2 \\
		P_{:,1,3} = Q_3 \\
	\end{cases}\]
	
	\text{For the third partition $(i = 2)$:}
	\[\begin{cases}
		
		P_{:,2,0} = Q_2 \\
		P_{:,2,1} = Q_3 \\
		P_{:,2,2} = Q_4 \\
            P_{:,2,3} = Q_4 \\
	\end{cases}\]
\end{enumerate}

The resulting tensor $\mathbf{P}$ contains the trapezoidal parameters for each variable and partition. As a visual example, Figure \ref{fig:temperature_fuzzy} shows a fuzzy partition computed this way for the classical Iris dataset.

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{Figure_fuzzy_example.pdf}
	\caption{Visualization of fuzzy partitions using the method proposed for the petal width variable in the Iris dataset.}
	\label{fig:temperature_fuzzy}
\end{figure}

The fuzzy partition itself can be a limiting factor in the performance of the FRR. In order to measure this, we have trained a Multi-Layer Perceptron that takes the membership values to each of the fuzzy partitions as input instead of the original real values, which we can use as an upper estimate of the maximum performance achievable with these partitions. This MLP obtained a $83.32$ average accuracy across al datasets, in line with what we obtained with other classifiers. We can take this as an upper threshold of the possible performance possible with the FRR. The MLP is a more flexible model than the FRR and should be able to overperform if properly trained. 

Detailed results of the fuzzified-input MLP are in Table \ref{tab:classical_results}.

\section{Remaining gradients of interest}\label{apx:derivatives}

In Section \ref{sec:derivations}, we have included and discussed the derivatives of the second and third layers. For completeness, in this appendix, we compute the rest of the derivatives involved in the gradient-based optimization of the FRR. Here we already consider the normalized weights.

To compute the derivatives of the fourth and last layer in which the classification step is performed we have to distinguish between the cases of sufficient and additive rules:
\begin{itemize}
    \item \textit{Sufficient rules}: in this case, for simplifying the notation we consider $h_s(W_{s,c}^{(4)},r_s) = f(W_{s,c}^{(4)})W_{s,c}^{(4)}r_s(X_i)$, then $u^{(4)}_c = \max_{s \in \{1,\dots,R\}} h_s(W_{s,c}^{(4)},r_s)$ and we have
    \begin{equation}\label{eq:du4:r}
    \frac{\partial u^{(4)}_c}{\partial r_s} =    \left\{
    \begin{array}{ll}
        f(W_{s,c}^{(4)})W_{s,c}^{(4)} & \text{if } s = \argmax_k h_k,\\[0.2cm]
        0 & \text{otherwise.} 
    \end{array}
    \right.
    \end{equation}
    \begin{equation}\label{eq:du4:w}
    \frac{\partial u^{(4)}_c}{\partial W_{s,c}^{(4)}} = \left\{
    \begin{array}{ll}
        \left(\frac{\partial f}{\partial W_{s,c}^{(4)}}W_{s,c}^{(4)} + f(W_{s,c}^{(4)})\right) r_s(X_i) & \text{if } s = \argmax_k h_k,\\[0.2cm]
        0 & \text{otherwise.} 
    \end{array}
    \right.
\end{equation}
Similarly than the discussion in Section \ref{sec:derivations}, Eq. (\ref{eq:du4:r}) is 0 whenever $W_{s,c}^{(4)}$ is not the biggest score, which blocks the gradient of the corresponding rule, and in Eq. (\ref{eq:du4:w})  we have to use a gradient estimator since $f$ is not differentiable. 
    \item \textit{Additive rules}:
    \begin{equation}
    \frac{\partial u^{(4)}_c}{\partial r_s} = W_{s,c}^{(4)}, \quad \frac{\partial u^{(4)}_c}{\partial W_{s,c}^{(4)}} = r_s(X_i).
\end{equation}
In this case the derivatives correspond to the score and the truth degree, respectively.
\end{itemize}

Next, we study how the different complementary components of the FRR affect the gradient-based optimization. First, we compute the derivatives involved in the update of the parameters in charge of reducing the number of conditions in each rule (see Eq. (\ref{eq:antecedent_silencer})):
\begin{equation}\label{eq:d6}
\frac{\partial \tilde{A}_k}{\partial A_k} = f(\alpha_{k,1}) \prod_{\substack{1 \leq m \leq A \\ m \not = k}} f(\alpha_{m,1})A_m + f(\alpha_{m,2}).
\end{equation}
\begin{equation}\label{eq:d7}
\frac{\partial \tilde{A}_k}{\partial \alpha_{k,1}} = \frac{\partial f}{\partial \alpha_{k,1}} A_k \prod_{\substack{1 \leq m \leq A \\ m \not = k}} f(\alpha_{m,1})A_m + f(\alpha_{m,2}).
\end{equation}
\begin{equation}\label{eq:d8}
\frac{\partial \tilde{A}_k}{\partial \alpha_{k,2}} = \frac{\partial f}{\partial \alpha_{k,2}}\prod_{\substack{1 \leq m \leq A \\ m \not = k}} f(\alpha_{m,1})A_m + f(\alpha_{m,2}).
\end{equation}
These derivatives have a similar behaviour that the ones already discuss because of the presence of function $f$. Next, the derivative of the projection function is taken into account when the third layer is modified as in Eq. (\ref{eq:P}):
\begin{equation}
\frac{dP}{dx} = \frac{1}{x(1-\log(x))^{2}}.    
\end{equation}
Finally, the derivative of the third layer after including the residual connection is modified additively by the sum of derivatives of the antecedents weighted by $\gamma$:
\begin{equation}
    \frac{\partial \tilde{u}^{(3)}}{\partial u^{(3)}} = \frac{\partial u_j^{(3)}}{\partial u_j^{(2)}} + \gamma \sum_{k=1}^A \frac{\partial A_k}{\partial u_j^{(2)}} = \frac{\partial u_j^{(3)}}{\partial u_j^{(2)}} + \gamma \sum_{k=1}^A f(W_{k,j}^{(3)})W_{k,j}^{(3)}.
\end{equation}
\begin{equation}
    \frac{\partial \tilde{u}^{(3)}}{\partial W^{(3)}_{k,j}} = \frac{\partial u_j^{(3)}}{\partial W^{(3)}_{k,j}} + \gamma \sum_{k=1}^A \frac{\partial A_k}{\partial W^{(3)}_{k,j}} = \frac{\partial u_j^{(3)}}{\partial W_{k,j}^{(3)}} + \gamma \sum_{k=1}^A \left(\frac{\partial f}{\partial W_{k,j}^{(3)}}W_{k,j}^{(3)}+f(W_{k,j}^{(3)})\right)u_{j}^{(2)}.
\end{equation}

\section{Using the FRR with other conjunctions}\label{apx:tnorms}
In fuzzy logic, T-norms are considered to be the extension of the boolean conjunction and are defined as binary functions $T:[0,1]^2 \to [0,1]$ which are commutative, associative, increasing in both variables, and 1 is its neutral element (i.e., $T(x,1)=x$ for all $x \in [0,1]$). Since the properties imposed in this definition are not very restrictive, there exists a lot of functions that can be used to model fuzzy conjunctions. However, in practice, the minimum $T_M(x,y)=\min\{x,y\}$ and the product $T_P(x,y)=x \cdot y$ are the preferred choice because they are easy to implement and have a simple $n$-ary form:
$$T_M(x_1,\dots,x_n) = \min \{x_1,\dots,x_n\}, \quad T_P(x_1,\dots,x_n) = \prod_{i=1}^nx_i.$$
  In general, since all T-norms are associative, the order of the inputs does not change the output, and any t-norm defines an $n$-ary function which is equivalent to the iterative evaluation of each instance.
$$
T(x_1,T(x_2,\dots T(x_{n-1},x_n)))=T(x_1,\dots,x_n) = \underset{i=1}{\overset{n}{\mathbf{\text{\large T}}}}x_i.
$$
However, no T-norm has an easy closed expression of its $n$-ary form, and that is one of the reasons why the minimum and the product are mostly used. Nonetheless, continuous Archimedean T-norms are a special type that can be constructed via a unary continuous, strictly decreasing function $t:[0,1] \to [0,+\infty)$ with $t(1)=0$ called generator and they have a closed $n$-ary expression that allows a more efficient implementation \cite{Giannini2023}:
$$
T(x_1,\dots,x_n) = t^{-1}\left(\min\left\lbrace t(0^+),\sum_{i=1}^nt(x_i)\right\rbrace\right).
$$
Any of these T-norms can be used in the FRR instead of the product to combine weights with inputs and to perform the logic inference during the second and third layers in the following manner
$$
u_j^{(2)}= \sum_{v=1}^V T(f(\tilde{W}^{(2)}_{j,v}) \tilde{W}^{(2)}_{j,v},\mu_{j,v}(X_{i,j})),
$$
$$u^{(3)} = 
\underset{k=1}{\overset{A}{\mathbf{\text{\large T}}}} \sum_{j=1}^M T(f(\tilde{W}^{(3)}_{k,j}) \tilde{W}^{(3)}_{k,j},u_{j}^{(2)}) = \underset{k=1}{\overset{A}{\mathbf{\text{\large T}}}} \sum_{j=1}^M T(f(\tilde{W}^{(3)}_{k,j}) \tilde{W}^{(3)}_{k,j},\sum_{v=1}^V T(f(\tilde{W}^{(2)}_{j,v}) \tilde{W}^{(2)}_{j,v},\mu_{j,v}(X_{i,j}))).$$
Similarly than we did in Eq. (\ref{eq:model_inference}), if we resolve the argmax function and we take into account that $T(x,0)=0$ for all $x \in [0,1]$ the truth degree of a rule $r$ is given by
$$
r(X_i) = \underset{k=1}{\overset{A}{\mathbf{\text{\large T}}}} T(\tilde{W}^{(3)}_{k,j_k},T(\tilde{W}^{(2)}_{j_k,v_{j_k}}\mu_{j_k,v_{j_k}}(X_{i,j_k}))) = \underset{k=1}{\overset{A}{\mathbf{\text{\large T}}}} T(T(\tilde{W}^{(3)}_{k,j_k},\tilde{W}^{(2)}_{j_k,v_{j_k}}),\mu_{j_k,v_{j_k}}(X_{i,j_k})).
$$

By definition, any T-norm is below the minimum $T(x,y) \leq \min \{x,y\}$, so $T_M$ is the greatest T-norm. Then, using the minimum t-norm is the best choice to not accelerate the approach to 0 when doing the logical inference. However, the minimum only takes into account the least value of all the inputs, which may not be desirable in some cases because it may happen that the truth degrees of the fuzzy sets are neglected. Even so, there exist other families of continuously differentiable t-norms that are above the product that may help in the vanishing gradient problem, like, for instance, the family of Aczél-Alsina T-norms:
$$t_{\lambda}(x) = (-\log x)^{\lambda}, \quad T_{\lambda}(x_1,\dots,x_n)= e^{-\sqrt[\lambda]{\sum_{i=1}^n(-\log x_i)^{\lambda}}},$$
with $\lambda \in [1,+\infty)$. As $\lambda \to +\infty$, the T-norm converges to the minimum and if $\lambda=1$ is equal to the product (see Figure \ref{fig:aa_tnorms}). Also, the derivatives of different logic operators can be interpreted in terms of their contribution to the gradient \cite{Vankrieken2022}. However, the use of an arbitrary T-norm may affect the explainability of the system.

\begin{figure}[ht!]
    \centering
    % First Subfigure
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{aa1.png} % Replace with your image file
        \caption{$T_{1}$}
    \end{subfigure}
    \hfill
    % Second Subfigure
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{aa2.png} % Replace with your image file
        \caption{$T_{5}$}
    \end{subfigure}
    \hfill
    % Third Subfigure
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{aa3.png} % Replace with your image file
        \caption{$T_{100}$}
    \end{subfigure}
    
    \caption{Contour plots of the Aczél-Alsina t-norm for different values of the parameter $\lambda$.}
    \label{fig:aa_tnorms}
\end{figure}

\section{Datasets used and Code availability} \label{sec:datasets}


\begin{table}[ht]
\centering
\caption{Datasets with their samples, features, and classes.}
\begin{tabular}{l|rrr}
\hline
\textbf{Dataset} & \textbf{Samples} & \textbf{Features} & \textbf{Classes} \\ 
\midrule
appendicitis     & 106               & 7                 & 2                \\ 
australian       & 690              & 14                & 2                \\ 
balance          & 625              & 4                 & 3                \\ 
banana           & 5300             & 2                 & 2                \\ 
bands            & 512              & 39                & 2                \\ 
bupa             & 345              & 6                 & 2                \\ 
cleveland        & 297              & 13                & 5                \\ 
coil2000         & 9822             & 85                & 2                \\ 
dermatology      & 358              & 34                & 6                \\ 
glass            & 214              & 9                 & 6                \\ 
haberman         & 306              & 3                 & 2                \\ 
heart            & 270              & 13                & 2                \\ 
hepatitis        & 80               & 19                & 2                \\ 
housevotes       & 232              & 16                & 2                \\ 
ionosphere       & 351              & 33                & 2                \\ 
iris             & 150               & 4                 & 3                \\ 
magic            & 19020            & 10                & 2                \\ 
mammographic     & 830              & 5                 & 2                \\ 
monk-2           & 432              & 6                 & 2                \\ 
newthyroid       & 215              & 5                 & 3                \\ 
page-blocks      & 5472             & 10                & 5                \\ 
phoneme          & 5404             & 5                 & 2                \\ 
pima             & 768              & 8                 & 2                \\ 
ring             & 7400             & 20                & 2                \\ 
saheart          & 462              & 9                 & 2                \\ 
satimage         & 6435             & 36                & 6                \\ 
sonar            & 208              & 60                & 2                \\ 
spambase         & 4597             & 57                & 2                \\ 
spectfheart      & 267              & 44                & 2                \\ 
thyroid          & 7200             & 21                & 3                \\ 
titanic          & 2201             & 3                 & 2                \\ 
twonorm          & 7400             & 20                & 2                \\ 
vehicle          & 846              & 18                & 4                \\ 
wdbc             & 569              & 30                & 2                \\ 
wine             & 178              & 13                & 3                \\ 
winequality-red  & 1599             & 11                & 6                \\ 
winequality-white & 4898            & 11                & 7                \\ 
wisconsin        & 683              & 9                 & 2                \\ 
zoo              & 101               & 16                & 7                \\ 
\bottomrule
\end{tabular}
\label{tab:uci_datasets}
\end{table}


The list of datasets used, alongside the number of features, samples, and classes, is in Table \ref{tab:uci_datasets}. They were collected from the UCI datasets \cite{kelly2025uci} and the Keel website \citep{triguero2017keel}. The code will be publicly available on Github. 

Fuzzy rule experiments using genetic optimization were carried out using the exFuzzy library \citep{fumanalex2024}, available at \url{https://github.com/Fuminides/ex-fuzzy}. RRL implementation is provided by the authors at \url{https://github.com/12wang3/rrl}. C4.5 classifier has been implemented by ourselves in Python. For the rest of the classifiers, we used the implementation available in Scikit-learn library \cite{scikit-learn}.


\section{Hyperparameter choosing and detailed performance for each method} \label{sec:detailed_res}

We tried different configurations of hyperparameters for all the classifiers tested. The ones reported in the main text are the ones that achieved the best accuracy results for each of them.

\begin{itemize}
    \item Random forest: we tried $100$ and $200$ trees with maximum depth of $3$ and $5$ in both cases. 
    \item Gradient boosting: same as for random forest.
    \item SVM: we used two kernels, a radial basis function and a linear kernel. We also used a regularization parameter set up as $1.0$ or $0.1$.
    \item CART: we tried trees with three different cost complexity pruning parameters. The higher this parameter, the smaller the final tree shall be. We tried: $0.0$, $0.001$ and $0.003$.
    \item RRL: for the RRL, we used the configurations that the authors recommend in \cite{wang2021scalable}. However, we obtained very similar results in all cases.
    \item MLP: we used three different MLPs with one, two and three hidden layers in each case. The size of the hidden layer was $100$ neurons in all cases. Same for the Fuzzy MLP.
    \item C4.5: we tried a maximum depth of $5$ and $10$.
    
\end{itemize}

\begin{table}[ht]
    \centering
    \caption{Results per each dataset obtained with the best configuration per each classifier.}
 \begin{tabular}{lrrrrrrrrrrr}
\toprule
          Dataset & AdFRR&  FRR &  LR &  RF &  Fuzzy MLP &  GA &  RLL &  CART &  C4.5 &  SVM &    MLP \\
          \midrule
     appendicitis &86.36& 77.27 &   86.36 &   84.55 &          82.73 &   90.91 &           84.03 &      79.09 & 94.02 & 76.36 &  86.36 \\
       australian &78.84& 81.59 &   86.23 &   86.81 &          84.78 &   85.51 &           86.67 &      85.07 & 95.46 &  83.42 &   81.50 \\
          balance &79.20& 72.80 &   88.16 &   84.16 &          78.40 &   61.60 &           84.48 &      78.56 & 73.00 & 88.48 &  96.96 \\
           banana &73.33& 74.60 &   55.70 &   89.51 &          81.53 &   74.06 &           77.36 &      89.04 & 55.42 & 54.77 &  89.45 \\
            bands &56.43& 59.45 &   67.12 &   72.88 &          66.58 &   64.38 &           61.64 &      63.56 & 87.55 & 69.32 &  66.85 \\
             bupa &70.14& 64.64 &   68.12 &   75.36 &          72.75 &   55.07 &           65.80 &      65.51 & 66.81 & 55.07 &  64.93 \\
        cleveland &55.00& 56.33 &   58.00 &   56.00 &          53.00 &   46.67 &           54.22 &      50.00 & 96.82 & 55.33 &  51.33 \\
         coil2000 &85.05& 94.05 &   93.98 &   92.81 &          91.30 &   80.81 &           93.33 &      94.05 & 98.90 & 94.02 &  91.68 \\
      dermatology &78.05& 74.17 &   95.56 &   97.22 &          96.11 &   50.00 &           95.53 &      94.72 & 56.05 & 97.78 &  97.78 \\
            glass &63.23& 52.09 &   62.33 &   73.49 &          73.02 &   39.53 &           65.87 &      66.98 & 100.00 & 48.84 &  60.47 \\
         haberman &62.90& 66.13 &   76.45 &   70.65 &          70.00 &   50.00 &           72.23 &      67.42 & 56.54 & 76.13 &  76.77 \\
            heart &86.29& 81.85 &   83.70 &   82.96 &          82.96 &   70.37 &           84.81 &      73.70 & 66.17 & 77.78 &  77.41 \\
        hepatitis &90.00& 85.00 &   85.00 &   88.75 &          91.25 &   81.25 &           80.00 &      82.50 & 75.89 & 86.25 &  81.25 \\
       housevotes &71.91& 91.49 &   96.17 &   97.02 &          95.74 &   97.87 &           95.70 &      97.87 & 100.00 &  96.20 &   96.30 \\
       ionosphere &85.07& 85.07 &   87.61 &   92.39 &          87.04 &   78.87 &           92.01 &      85.63 & 100.00 & 84.23 &  89.01 \\
             iris &96.66& 94.67 &   95.33 &   96.00 &          96.67 &   76.67 &           95.33 &      96.67 & 62.50 & 96.67 &  98.67 \\
            magic &77.81& 76.40 &   79.02 &   88.23 &          82.77 &   76.37 &           71.39 &      83.17 & 65.08 & 78.87 &  86.86 \\
     mammographic &82.77& 82.77 &   81.33 &   80.12 &          80.96 &   77.71 &           79.88 &      82.65 & 86.04 & 77.95 &  80.24 \\
           monk-2 &95.17& 82.53 &   78.62 &   98.85 &          99.54 &   63.22 &          100.00 &     100.00 & 97.10 & 82.30 & 100.00 \\
       newthyroid &93.48& 86.51 &   94.88 &   96.28 &          93.02 &   88.37 &           94.88 &      93.49 & 79.56 & 88.37 &  97.21 \\
      page-blocks &91.01& 91.56 &   95.95 &   97.37 &          95.95 &   92.60 &           94.63 &      96.44 & 94.74 & 92.51 &  96.73 \\
          phoneme &78.33& 75.13 &   75.00 &   90.36 &          85.86 &   67.90 &           83.25 &      82.35 & 71.31& 76.73 &  83.29 \\
             pima &72.59& 73.25 &   77.66 &   77.14 &          71.43 &   74.68 &           74.08 &      71.95 & 69.24 & 76.88 &  78.18 \\
             ring &84.41& 86.51 &   75.64 &   95.00 &          81.70 &   68.58 &           91.96 &      85.88 & 51.98 & 76.64 &  96.23 \\
          saheart &69.67& 69.89 &   76.13 &   68.17 &          63.01 &   66.67 &           67.30 &      60.86 & 84.74 &  82.14 &   86.80 \\
         satimage &80.32& 70.35 &   85.58 &   91.02 &          88.59 &   61.07 &           89.29 &      83.98 & 76.12 & 86.28 &  88.80 \\
            sonar &80.00& 74.76 &   77.14 &   83.81 &          84.29 &   61.90 &           58.65 &      71.43 & 100.00 & 70.95 &  77.62 \\
         spambase &78.78& 84.61 &   91.91 &   95.20 &          94.39 &   88.48 &           91.45 &      91.02 & 99.35 & 89.67 &  94.30 \\
      spectfheart &77.40& 77.78 &   81.11 &   81.85 &          81.48 &   64.81 &           79.01 &      74.44 & 100.00 & 80.74 &  79.26 \\
          thyroid &91.52& 92.57 &   95.65 &   99.64 &          92.86 &   88.54 &           94.51 &      99.39 & 94.01 & 93.22 &  98.14 \\
          titanic &75.96& 75.42 &   77.64 &   78.91 &          78.55 &   78.91 &           77.96 &      78.37 & 78.26  & 77.55 &  77.37 \\
          twonorm &94.47& 95.46 &   97.50 &   96.96 &          95.45 &   79.73 &           95.22 &      79.76 & 51.18 & 97.95 &  97.96 \\
          vehicle &62.27& 53.88 &   78.82 &   74.82 &          71.18 &   52.94 &           71.52 &      68.12 & 79.62 & 69.53 &  81.29 \\
             wdbc &94.91& 92.11 &   97.54 &   96.49 &          96.67 &   89.47 &           95.26 &      94.04 & 84.61 & 97.19 &  97.19 \\
  winequality-red &54.62& 49.38 &   59.56 &   67.62 &          59.38 &   23.12 &           59.66 &      59.31 & 52.39& 58.75 &  60.94 \\
winequality-white &49.91& 40.06 &   53.73 &   66.47 &          59.59 &   20.61 &           54.10 &      52.47 & 50.12 & 51.06 &  53.96 \\
             wine &97.22& 95.00 &   98.89 &   97.78 &          97.78 &   91.67 &           96.60 &      92.22 & 70.79 & 98.33 &  97.22 \\
        wisconsin &97.51& 93.72 &   96.50 &   96.93 &          96.20 &   95.62 &           95.32 &      94.74 & 98.62 & 97.37 &  96.93 \\
              zoo &42.85& 60.95 &   91.43 &   96.19 &          95.24 &   71.43 &           93.00 &      95.24 & 100.00&  94.98 &   95.10 \\
\bottomrule
\end{tabular}
    \label{tab:classical_results}
\end{table}
For the fuzzy classifiers trained with a genetic algorithm, we tried a different number of antecedents, rules per class and linguistic variables.  The results are shown in Table \ref{tab:noweights_mods}. Figure  \ref{fig:GA_complexity} shows the same results plotted according to the complexity of each classifier according to the number of antecedents, rules and linguistic variables used. This showcases another problem of genetic fine-tuning; it cannot find good solutions when the number of rules is high. The performance obtained in those cases is worse than the one obtained using small models.

\begin{figure}[ht]
	\centering
	\includegraphics[width=.7\linewidth]{Complexity_vs_performance_ga.pdf}
	\caption{Relationship between complexity of the classifier and the F1 score obtained. The complexity is computed as: the number of linguistic variables $*$ number of antecedents per rule $*$  number of rules.} 
	\label{fig:GA_complexity}
\end{figure}


\begin{table}[ht]
	\caption{Results for genetic fine tuning of rules with linguistic hedges.}
	\centering
	\begin{tabular}{lllrr}
		\toprule
		Rules per class & Antecedents & Linguistic variables &    Acc. &  F1 score \\
		\midrule
		3 &           3 &   3 &  70.14 &  68.00 \\
		3 &           3 &   5 &  69.18 &  67.02 \\
		3 &           5 &   3 &  68.89 &  65.97 \\
		3 &           5 &   5 &  65.78 &  61.59 \\
		5 &           3 &   3 &  70.67 &  69.29 \\
		5 &           3 &   5 &  69.31 &  67.19 \\
		5 &           5 &   3 &  67.27 &  65.19 \\
		5 &           5 &   5 &  65.00 &  61.80 \\
		10 &           3 &   3 &  67.89 &  65.35 \\
		10 &           3 &   5 &  69.24 &  66.87 \\
		10 &           5 &   3 &  69.68 &  67.78 \\
		10 &           5 &   5 &  67.17 &  65.04 \\
		30 &           3 &   3 &  62.14 &  58.28 \\
		30 &           3 &   5 &  63.95 &  60.53 \\
		30 &           5 &   3 &  68.30 &  65.55 \\
		30 &           5 &   5 &  65.99 &  63.32 \\
		\bottomrule
	\end{tabular}
	
	\label{tab:noweights_mods}
\end{table}

For the number of epochs, we went with $400$, which was probably more than needed in most cases but did not require a significant time investment in most cases. Two examples of the evolution of loss and accuracy in training and validation, respectively, are shown in Figure \ref{fig:training_loss}. We can see there how the loss in training remains stable until the last epochs, where the $k$ and $\gamma$ values approach 0.

Detailed results for every classifier tested are available in Table \ref{tab:classical_results}.
\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Example_loss_evolution_australian.pdf}
        \caption{Australian dataset}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Example_loss_evolution_magic.pdf}
        \caption{Magic dataset}
    \end{subfigure}
    \caption{Performance evolution for the FRR during two different training sessions for two datasets.}
    \label{fig:training_loss}
\end{figure}

\section{Reducing the size of the FRR} \label{sec:reduce_complexity}
Even though we can set up a maximum number of rules and antecedents, there are sometimes cases where the FRR can find good solutions that are considerably smaller than these specifications. In our experimentation, we found some modifications in the loss function that helped reduce the size of the rules and their number.

The strategy to shorten the rules is to add a Laplacian term in the loss function that penalizes the weights in the cancellation process that affect the antecedent truth value:
\begin{equation}
    L_1 =  \sum_{r=1}^{R} \sum_{k=1}^{A} \alpha_{k,1}^{(r)},
\end{equation}

which is then added to the cross-entropy loss with a multiplier, which in our experimentation was set to $0.01$.

To reduce the number of rules, we use an expression taken from the Gradient boosting algorithm. The reasoning why it reduces the number of rules is not direct, but it had a clear impact on the results obtained nevertheless.

For each rule, except for the first one, we compute the residuals of the system prediction up to that rule. Then, we multiply those losses by a small factor and add it to the final loss. This works differently for sufficient and additive rules, as the final prediction is computed differently in both cases. 
\begin{itemize}
    \item For the case of sufficient rules, the loss for each rule is computed as: \begin{equation}
        L_r = \frac{1}{N} \sum_{i=1}^{N}y_i - \max_{s \in \{1,\dots,r-1\}} f(W_{s,c}^{(4)})W_{s,c}^{(4)} r_s(X_i).
    \end{equation}
    \item For additive rules, we do the following:
    \begin{equation}
        L_r = \frac{1}{N} \sum_{i=1}^{N}y_i - \sum_{s=1}^{r-1} W_{s,c}^{(4)} r_s(X_i).
    \end{equation}
\end{itemize}

Then, we can obtain the final expression as:

\begin{equation}
    L_2 = \sum_{r=2}^{R} L_r,
\end{equation}
which can be added to the global loss as a Laplacian term. Results for the addition of this loss can be seen in Table \ref{tab:addfr_gradient_ablation_full}. We can see there that the reduction in the number of rules is especially appreciable when the number of rules is high, even though accuracy remains mostly unaffected. For example, when using this loss, the $100$ additive rules configuration reduced in $45\%$ its number of rules.


\section{Additional configurations tested} \label{sec:complete_ablation}

For the sake of brevity, some of the results regarding the different gradient techniques have been cut from the main part of the manuscript, as they were not needed to draw the relevant conclusions from the experiments. However, we have included here the rest of the configurations tested in case the reader is interested in the result of a particular configuration. We show Table \ref{tab:results_frr_ablation_appendix} for the ablation study in the FRR and Table \ref{tab:addfr_gradient_ablation_full} those for the AdFRR. Those configurations where the ``K upper'' and ``K lower'' numbers are equal to 0.0 refers to a strict indicator ($k$ was always $0$ during training in Eq. (\ref{eq:fbeta})). When they are both $1.0$, it corresponds to the continuous indicator: $k=1$ in Eq. (\ref{eq:fbeta}) during the whole training. 


\begin{table}[ht]
\centering
\caption{Summary of results for different configurations of gradient strategies for the FRR.}
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{cccccccccccccccc}
\toprule
Rules & Antecedents & LV & Sufficient & Grad mode & K upper train & K lower train & Temp & Residual & Boosted loss & Acc - GA Acc & Acc - LR Acc & N rules & N ants & Acc \\
\midrule
15 & 3 & 3 & True & STE$_0$ & 0.0 & 0.0 & 0.1 & True & False & 6.45 & -5.22 & 13.81 & 1.86 & 76.91 \\
15 & 3 & 3 & True & GRAFT & 1.0 & 0.0 & 0.1 & True & False & 6.33 & -5.34 & 12.57 & 1.91 & 76.79 \\
15 & 3 & 3 & True & STE$_1$ & 1.0 & 1.0 & 0.1 & True & False & 6.25 & -5.42 & 13.78 & 1.84 & 76.71 \\
15 & 3 & 3 & True & GRAFT & 0.0 & 0.0 & 0.1 & True & False & 6.22 & -5.45 & 13.80 & 1.89 & 76.68 \\
15 & 3 & 3 & True & STE$_1$ & 0.0 & 0.0 & 0.1 & True & False & 6.17 & -5.50 & 13.74 & 1.88 & 76.63 \\
15 & 3 & 3 & True & STE$_1$ & 1.0 & 0.0 & 0.1 & True & False & 5.95 & -5.72 & 13.56 & 1.84 & 76.41 \\
15 & 3 & 3 & True & GRAFT & 1.0 & 1.0 & 0.1 & True & False & 5.51 & -6.16 & 12.66 & 1.93 & 75.97 \\
15 & 3 & 3 & True & STE$_0$ & 1.0 & 0.0 & 0.1 & True & False & 4.70 & -6.97 & 13.78 & 1.85 & 75.16 \\
15 & 3 & 3 & True & GRAFT & 1.0 & 0.0 & 0.1 & False & False & 3.62 & -8.05 & 12.92 & 1.90 & 74.08 \\
15 & 3 & 3 & True & STE$_0$ & 1.0 & 1.0 & 0.1 & False & False & 3.43 & -8.24 & 13.89 & 1.83 & 73.89 \\
15 & 3 & 3 & True & STE$_0$ & 0.0 & 0.0 & 0.1 & False & False & 3.34 & -8.33 & 13.87 & 1.78 & 73.80 \\
15 & 3 & 3 & True & STE$_0$ & 0.0 & 0.0 & 0.1 & False & False & 3.00 & -8.67 & 13.94 & 1.78 & 73.47 \\
15 & 3 & 3 & True & STE$_0$ & 1.0 & 0.0 & 0.1 & False & False & 2.49 & -9.17 & 13.98 & 1.81 & 72.96 \\
15 & 3 & 3 & True & GRAFT & 1.0 & 1.0 & 0.1 & False & False & 2.35 & -9.31 & 12.82 & 1.95 & 72.82 \\
15 & 3 & 3 & True & STE$_0$ & 1.0 & 1.0 & 0.1 & False & False & -14.94 & -26.61 & 12.77 & 1.87 & 55.52 \\
\bottomrule
\end{tabular}
\end{adjustbox}
\label{tab:results_frr_ablation_appendix}
\end{table}

\begin{table}[htb]
    \centering
     \caption{Comparison of different AdFRR configurations and their accuracies.}
    \begin{adjustbox}{width=\textwidth}

    \begin{tabular}{ccccccccccccccc}
       \toprule
  Rules & Antecedents &  LV & Sufficient & Grad mode &  K upper train & K lower train &   Temp & Residual & Boosted loss &   Acc - GA Acc &  Acc - LR Acc&     N rules&     N ants &         Acc \\
  \midrule
   70   &         3   &  3   &    False   & STE$_0$   &          1.0   &         0.0   &  0.1   &   True   &      False   &     75.40   &   04.12  & 50.04  & 1.88   &  78.00  \\
   70   &         3   &  3   &    False   & STE$_0$   &          1.0   &         0.0   &  0.1   &   True   &       True   &     69.01   &   04.76  & 32.32  & 1.32   &  77.36 \\
  100   &         3   &  3   &    False   & STE$_0$   &          1.0   &         0.0   &  0.1   &   True   &      False   &     67.22   &   04.94  & 66.21  & 1.94   &  77.18 \\
  100   &         3   &  3   &    False   & STE$_0$   &          1.0   &         0.0   &  0.1   &   True   &       True   &     59.26   &   05.74  & 36.14  & 1.30   &  76.38 \\
   50   &         3   &  3   &    False   & STE$_0$   &          1.0   &         0.0   &  0.1   &   True   &      False   &     58.94   &   05.77  & 37.76  & 1.82   &  76.35 \\
   50   &         3   &  3   &    False   & STE$_0$   &          1.0   &         0.0   &  0.1   &   True   &       True   &     58.77   &   05.79  & 27.54  & 1.34   &  76.33 \\
   30   &         3   &  3   &    False   & STE$_0$   &          1.0   &         0.0   &  0.1   &   True   &       True   &     50.07   &   06.66  & 21.22  & 1.39   &  75.46 \\
   30   &         3   &  3   &    False   & STE$_0$   &          1.0   &         0.0   &  0.1   &   True   &      False   &     48.33   &   06.83  & 24.43  & 1.75   &  75.29 \\
   15   &         3   &  3   &    False   & STE$_0$   &          1.0   &         0.0   &  0.1   &   True   &      False   &     26.80   &   08.98  & 13.62  & 1.74   &  73.14 \\
   15   &         3   &  3   &    False   & STE$_0$   &          1.0   &         0.0   &  0.1   &   True   &       True   &     15.15   &   10.15  & 13.01  & 1.44   &  71.97 \\
   \bottomrule
    \end{tabular}
    \end{adjustbox}
    \label{tab:addfr_gradient_ablation_full}
\end{table}






\section{Computational resources employed} \label{sec:exp_setting}

For the experiments using gradient-based optimization, we used the CERES cluster from the University of Essex. CERES has 1096 processing cores (2192 with hyperthreading) provided by servers with a mix of Intel E5-2698, Intel Gold 5115, 6152 and 6238L processors, and between 500Gb and 6Tb RAM each. There are also 24 NVidia GTX and RTX Series GPU cards (16 x GTX1080Ti and 8 x RTX2080). Figure \ref{fig:time_hist} shows the execution time for all datasets for $400$ epochs with the FRR. The average time was 218 seconds.


For the rest of the experiments, we used the Oracle Cloud Infrastructure. We set up two machines with 128GB of RAM and 32 cores. 
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{Time_histogram.pdf}
    \caption{Histogram with execution times for all datasets using the compact FRR}
    \label{fig:time_hist}
\end{figure}



\newpage


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
