[
  {
    "index": 0,
    "papers": [
      {
        "key": "brown2020language",
        "author": "Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others",
        "title": "Language models are few-shot learners"
      },
      {
        "key": "ouyang2022training",
        "author": "Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others",
        "title": "Training language models to follow instructions with human feedback"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "maynez2020faithfulness",
        "author": "Maynez, Joshua and Narayan, Shashi and Bohnet, Bernd and McDonald, Ryan",
        "title": "On Faithfulness and Factuality in Abstractive Summarization"
      },
      {
        "key": "huang2023survey",
        "author": "Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and others",
        "title": "A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions"
      },
      {
        "key": "hong2024hallucinations",
        "author": "Hong, Giwon and Gema, Aryo Pradipta and Saxena, Rohit and Du, Xiaotang and Nie, Ping and Zhao, Yu and Perez-Beltrachini, Laura and Ryabinin, Max and He, Xuanli and Fourrier, Cl{\\'e}mentine and others",
        "title": "The Hallucinations Leaderboard--An Open Effort to Measure Hallucinations in Large Language Models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "min-etal-2023-factscore",
        "author": "Min, Sewon  and\nKrishna, Kalpesh  and\nLyu, Xinxi  and\nLewis, Mike  and\nYih, Wen-tau  and\nKoh, Pang  and\nIyyer, Mohit  and\nZettlemoyer, Luke  and\nHajishirzi, Hannaneh",
        "title": "{FA}ct{S}core: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation"
      },
      {
        "key": "wang-etal-2024-factcheck",
        "author": "Wang, Yuxia  and\nGangi Reddy, Revanth  and\nMujahid, Zain Muhammad  and\nArora, Arnav  and\nRubashevskii, Aleksandr  and\nGeng, Jiahui  and\nMohammed Afzal, Osama  and\nPan, Liangming  and\nBorenstein, Nadav  and\nPillai, Aditya  and\nAugenstein, Isabelle  and\nGurevych, Iryna  and\nNakov, Preslav",
        "title": "Factcheck-Bench: Fine-Grained Evaluation Benchmark for Automatic Fact-checkers"
      },
      {
        "key": "wanner-etal-2024-closer",
        "author": "Wanner, Miriam  and\nEbner, Seth  and\nJiang, Zhengping  and\nDredze, Mark  and\nVan Durme, Benjamin",
        "title": "A Closer Look at Claim Decomposition"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "wanner2024dndscore",
        "author": "Wanner, Miriam and Van Durme, Benjamin and Dredze, Mark",
        "title": "DnDScore: Decontextualization and Decomposition for Factuality Verification in Long-Form Text Generation"
      },
      {
        "key": "gunjal-durrett-2024-molecular",
        "author": "Gunjal, Anisha  and\nDurrett, Greg",
        "title": "Molecular Facts: Desiderata for Decontextualization in {LLM} Fact Verification"
      },
      {
        "key": "jiang2024core",
        "author": "Jiang, Zhengping and Zhang, Jingyu and Weir, Nathaniel and Ebner, Seth and Wanner, Miriam and Sanders, Kate and Khashabi, Daniel and Liu, Anqi and Van Durme, Benjamin",
        "title": "Core: Robust Factual Precision with Informative Sub-Claim Identification"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "lee2024llm",
        "author": "Lee, Dongryeol and Hwang, Yerin and Kim, Yongil and Park, Joonsuk and Jung, Kyomin",
        "title": "Are LLM-Judges Robust to Expressions of Uncertainty? Investigating the effect of Epistemic Markers on LLM-based Evaluation"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "quachconformal",
        "author": "Quach, Victor and Fisch, Adam and Schuster, Tal and Yala, Adam and Sohn, Jae Ho and Jaakkola, Tommi S and Barzilay, Regina",
        "title": "Conformal Language Modeling"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "kamath2020selective",
        "author": "Kamath, Amita and Jia, Robin and Liang, Percy",
        "title": "Selective Question Answering under Domain Shift"
      },
      {
        "key": "yadkori2024mitigating",
        "author": "Yadkori, Yasin Abbasi and Kuzborskij, Ilja and Stutz, David and Gy{\\\"o}rgy, Andr{\\'a}s and Fisch, Adam and Doucet, Arnaud and Beloshapka, Iuliya and Weng, Wei-Hung and Yang, Yao-Yuan and Szepesv{\\'a}ri, Csaba and others",
        "title": "Mitigating llm hallucinations via conformal abstention"
      },
      {
        "key": "gui2024conformal",
        "author": "Gui, Yu and Jin, Ying and Ren, Zhimei",
        "title": "Conformal Alignment: Knowing When to Trust Foundation Models with Guarantees"
      },
      {
        "key": "piche2024llms",
        "author": "Pich{\\'e}, Alexandre and Milios, Aristides and Bahdanau, Dzmitry and Pal, Chris",
        "title": "LLMs can learn self-restraint through iterative self-reflection"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "fang2024learning",
        "author": "Fang, Yizirui and Nalisnick, Eric",
        "title": "Learning to Defer with an Uncertain Rejector via Conformal Prediction"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "renrobots",
        "author": "Ren, Allen Z and Dixit, Anushri and Bodrova, Alexandra and Singh, Sumeet and Tu, Stephen and Brown, Noah and Xu, Peng and Takayama, Leila and Xia, Fei and Varley, Jake and others",
        "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "mohri2024language",
        "author": "Mohri, Christopher and Hashimoto, Tatsunori",
        "title": "Language Models with Conformal Factuality Guarantees"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "cherian2024large",
        "author": "Cherian, John J and Gibbs, Isaac and Cand{\\`e}s, Emmanuel J",
        "title": "Large language model validity via enhanced conformal prediction methods"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "mielek2022reducing",
        "author": "Mielke, Sabrina J. and Szlam, Arthur and Dinan, Emily and Boureau, Y-Lan",
        "title": "{Reducing Conversational Agents\u2019 Overconfidence Through Linguistic Calibration}"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "wang2024calibrating",
        "author": "Wang, Peiqi and Lam, Barbara D and Liu, Yingcheng and Asgari-Targhi, Ameneh and Panda, Rameswar and Wells, William M and Kapur, Tina and Golland, Polina",
        "title": "Calibrating Expressions of Certainty"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "band2024linguistic",
        "author": "Neil Band and Xuechen Li and Tengyu Ma and Tatsunori Hashimoto",
        "title": "Linguistic Calibration of Long-Form Generations"
      },
      {
        "key": "zhao2021calibrating",
        "author": "Zhao, Shengjia and Kim, Michael and Sahoo, Roshni and Ma, Tengyu and Ermon, Stefano",
        "title": "Calibrating predictions to decisions: A novel approach to multi-class calibration"
      }
    ]
  }
]