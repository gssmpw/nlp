\section{Related Work}
\paragraph{LLM Factuality Evaluation} With the rise of large language models (LLMs) **Voss, "Evaluating Factuality in Neural Text Generation"**__, long-form text generation has become widespread, but LLMs frequently hallucinate, generating content misaligned with real-world facts or user inputs ____.

To improve factuality evaluation, pipelines have been developed to decompose text into smaller claims and verify them against external sources ____. These methods focus on factual precision—the proportion of verifiably true claims—while refinements enhance claim extraction ____. However, they often overlook factors like hedging ____ and the role of controlled imprecision in overall factuality.
In this work, we propose a pipeline that makes this trade-off explicit, advocating for a more detailed study of the interplay between factuality and other key quality dimensions in open-ended generation evaluation.


\paragraph{Conformal Prediction for Language Generation} Applying conformal prediction to free-form generation is challenging due to the absence of a finite answer set, making classic split conformal methods inapplicable. Instead, prior work has focused on structured decision-making tasks such as overgeneration ____*, abstention *****, delegation *****and clarification *****to mitigate the risk of incorrect outputs. The most relevant approach, *****enhances factuality by decomposing text and omitting uncertain claims, a form of abstention. This method was later refined with adaptive conformal prediction by *****which improves the calibration of uncertainty while maintaining informative responses. Unlike these methods, we perform post-hoc calibration while preserving the original generation space, maintaining interpretability and coherence for downstream applications.

\paragraph{Linguistic Calibration} An alternative approach to mitigating large language model (LLM) overconfidence is linguistic calibration, where the model explicitly expresses uncertainty to better align its outputs with factual accuracy ____. This concept has been further extended to estimating the probabilities associated with uncertainty quantifiers ____*, allowing models to more precisely convey their confidence levels. Additionally, recent research has explored integrating verbalized uncertainty with other quantitative calibration techniques ____*, demonstrating that a hybrid approach can enhance decision-making by providing a more nuanced representation of uncertainty. These advancements highlight the growing potential of linguistic calibration as a key tool in improving the reliability and interpretability of LLM-generated responses.

While prior work primarily adds uncertainty markers while preserving the original text, our approach modifies generation itself to introduce imprecision, offering a distinct way to convey uncertainty. This not only enhances interpretability but also provides a structured mechanism to balance specificity and reliability in language generation.