\clearpage
\setcounter{page}{1}
\maketitlesupplementary

% In the supplementary material, we provide additional information about the MVTrack dataset in Section \ref{sec: dataset details}. Further implementation details and experimental results of MITracker are available in Section \ref{sec: experiment details}.
Section \ref{sec: dataset details} provides additional information on the MVTrack dataset, while Section \ref{sec: experiment details} includes further implementation details and experimental results of MITracker.

\section{Dataset Details}
\label{sec: dataset details}
\textbf{Data Annotation.}
In the BEV annotations, the MVTrack dataset covers an $8m \times 8m$ area. Ground truth labels are projected onto a $400 \times 400$ grid, where each cell is $2 cm \times 2 cm$ in size.
 
% 目标属性
\textbf{Attributes Definition.} MVTrack dataset contains nine attributes to assess tracking robustness, as shown in Table \ref{tab: attributes description}. We provide frame-level binary labels for five attributes: Background Clutter (BC), Motion Blur (MB), Partial Occlusion (POC), Full Occlusion (FOC), and Out of View (OV). These are manually annotated for each frame. Deformation (DEF) is labeled according to whether the tracked target deforms. Low Resolution (LR), Aspect Ratio Change (ARC), and Scale Variation (SV) are automatically computed from changes in the BBox size.

\input{tables/dataset/attributes_table}

\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{0.62\columnwidth}
        \centering
        \includegraphics[width=\columnwidth]{images/dataset/frame_1.pdf}
        \caption{Frames distribution.}
        \label{fig: frames distribution}
    \end{subfigure}
    
    \begin{subfigure}[b]{0.62\columnwidth}
        \centering
        \includegraphics[width=\columnwidth]{images/dataset/attr_2.pdf}
        \caption{Attributes distribution.}
        \label{fig: attributes distribution}
    \end{subfigure}
    \caption{Distribution of sequences in each attribute and length in our MVTrack dataset.}
    \label{fig:distribution}
\end{figure}


\textbf{Statistical Details.}
The MVTrack dataset contains 260 videos averaging around 900 frames each, as shown in Figure \ref{fig: frames distribution}. As illustrated in Figure \ref{fig: attributes distribution}, a key challenge is occlusion, which often results from subject-object interactions that cause partial or complete occlusion. Consequently, tracking models need to manage occlusion to perform robustly and adeptly on this dataset.



\section{Experiment Details}
\label{sec: experiment details}

\subsection{Training and Resource Analysis}
\textbf{Training Details.} 
We process the visual inputs by cropping the reference frame to 2 times the target's BBox size and resizing it to $182 \times 182$ pixels. The search frame is cropped at 4.5 times the target box area and resized to $364 \times 364$ pixels to expand the search region. During projection, we transform the camera intrinsic matrix $C_K$ accordingly and add noise to the translation vector $C_t$ to prevent overfitting in multi-view fusion.

Training consists of two stages. In the first stage, we optimize the view-specific encoder using AdamW with a learning rate of $1 \times 10^{-5}$ and the rest of the model at $1 \times 10^{-4}$. We train for 50 epochs, sampling 10,000 image pairs per epoch with a batch size of 32. In the second stage, we fine-tune the encoder at $1 \times 10^{-6}$ while keeping other components at $1 \times 10^{-4}$. We use the MVTrack dataset, sampling 2,500 multi-view image pairs per epoch for 40 epochs with a batch size of 4. AdamW is used throughout.

\textbf{Computational Resource.}
We evaluate MITracker and the single-view model ODTrack under the same input (4 views) on an NVIDIA A100, as summarized in Table \ref{tab:time}. Although multi-view fusion introduces additional computational overhead, it remains within an acceptable range.
\begin{table}[h]
\centering
\begin{tabular}{lccc}
\toprule
Method & Parameters~(M) & GRAM~(MB) & FPS \\ \midrule
ODTrack & 92.12 & 365.82& 18.78 \\
MITracker &101.65& 407.78& 14.08\\ \bottomrule
\end{tabular}
\caption{Comparison of computational complexity and resource.}
\label{tab:time}
\end{table}



\begin{figure*}[th]
	\centering
	\begin{subfigure}{0.8\columnwidth}
		\centering
		\includegraphics[width=\columnwidth]{images/experiments/precision_plot.pdf}
		\caption{Precision plot on MVTrack dataset.}
		\label{fig: Precision plot mvtrack}
	\end{subfigure}
        \hspace{5mm}
        \begin{subfigure}{0.8\columnwidth}
		\centering
		\includegraphics[width=\columnwidth]{images/experiments/norm_precision_plot.pdf}
		\caption{Normalized precision plot on MVTrack dataset.}
		\label{fig: normalized Precision plot mvtrack}
        \end{subfigure}

        \vspace{5mm}
        \centering
        \begin{subfigure}{0.8\columnwidth}
		\centering
		\includegraphics[width=\columnwidth]{images/experiments/precision_plot_gmtd.pdf}
		\caption{Precision plot on GMTD.}
		\label{fig: precision plot gmtd}
        \end{subfigure}
        \hspace{5mm}
        \centering
        \begin{subfigure}{0.8\columnwidth}
		\centering
		\includegraphics[width=\columnwidth]{images/experiments/norm_precision_plot_gmtd.pdf}
		\caption{Normalized precision plot on GMTD.}
		\label{fig: normalized precision plot gmtd}
        \end{subfigure}

        \vspace{5mm}
        \centering
        \begin{subfigure}{0.8\columnwidth}
		\centering
		\includegraphics[width=\columnwidth]{images/experiments/success_plot_gmtd.pdf}
		\caption{Success plot on GMTD.}
		\label{fig: Success plot gmtd}
        \end{subfigure}
        \hspace{5mm}
        \centering
        \begin{subfigure}{0.785\columnwidth}
		\centering
		\includegraphics[width=\columnwidth]{images/experiments/Robust_tracking_plot_gmtd.pdf}
		\caption{Robust tracking plot on GMTD.}
		\label{fig:  Robust tracking plot gmtd}
        \end{subfigure}
        
	\caption{Comparative results across MVTrack and GMTD datasets, with rankings noted in the legends. Parts (a) and (c) sort methods by P with a 20-pixel threshold, parts (b) and (d) by P$_{norm}$ with a 0.2 threshold, and part (e) by AUC.}
	\label{OPEmore}
\end{figure*}


\begin{figure*}[t]
\centering
\includegraphics[width=0.9\textwidth]{images/appendix/bag2-1.pdf} 
\caption{Qualitative comparison results on the impact of different numbers of input views. For a specific view, we compare the effects of using only that view versus including two additional overlapping views.}
\label{fig: input view}
\end{figure*}


\subsection{Comparison on Benchmark Details}
In Figure \ref{OPEmore}, we provide further quantitative evaluations of the AUC, P, and P$_{norm}$ across various threshold settings for both the MVTrack and GMTD datasets. In most settings, MITracker consistently outperforms other methods. 

During zero-shot testing on the GMTD, SAM2 and SAM2Long perform better under lenient threshold conditions but lacks the ability to localize objects precisely.
Furthermore, as shown in Figure \ref{fig: Robust tracking plot gmtd}, MITracker sustains longer tracking durations with fewer reinitializations on this unseen dataset.

\subsection{More Ablation Study}
\textbf{Impact of Input Views.} To assess the importance of the number of views for tracking, we select a fixed camera from each scenario in the testing set. We then examine how model performance changes as we increase the number of additional cameras. The results in Table \ref{tab: input view} highlight the benefits of adding more cameras.

Figure \ref{fig: input view} illustrates the challenges faced by the single-view model: after a prolonged target disappearance, it mistracks a white bottle. In contrast, the multi-view model initially mistakes a white trash can for the target but quickly recovers and maintains stable tracking with the aid of additional views.


\begin{table}[h]
\centering
\resizebox{0.8\linewidth}{!}{
\begin{tabular}{Xcccc}
\toprule
Input views & AUC(\%) & P$_{Norm}$(\%) & P(\%) \\  \hline
1 & 62.27 & 84.71& 73.92 \\
2 & 63.97& 87.07 & 76.30 \\
3 & 67.97& 91.50 & 80.73\\
3/4 &68.65& 92.37&81.55\\ \bottomrule
\end{tabular}
}
\caption{Ablation study for the impact of different numbers of input views on MVTrack dataset.}
\label{tab: input view}
\end{table}

\textbf{Impact of Multi-View Training.} 
Our experiment shows that multi-view training improves single-view performance by exposing the model to richer spatial information, which enhances its ability to handle occlusion and reappearance. Table \ref{tab:single-view} compares results with MITracker SV trained under single-view settings, highlighting the advantages of multi-view training even for single-view scenarios.

\begin{table}[h]
\centering
\begin{tabular}{l ccc}
\toprule
Method &  AUC (\%) & P$_{Norm}$ (\%)  & P (\%) \\ \hline
MITracker SV& 63.42& 82.97 & 79.67\\  % 
MITracker & 65.96& 87.05 & 82.07\\
\bottomrule
\end{tabular}
\caption{Zero-shot performance of single-view results on GMTD.}
\label{tab:single-view}
\end{table}

\textbf{Impact of Temporal Token.}
The temporal token incorporates tracking information from previous frames, Table \ref{tab:temporaltoken} highlights the improvements achieved through the temporal token.

\begin{table}[h]
\centering
\begin{tabular}{cccc}
\toprule
Temporal Token & AUC (\%) & P$_{Norm}$ (\%) & P (\%) \\ \midrule
 & 69.30 & 89.62 & 81.60 \\
\cmark &71.13& 91.87& 83.95\\ \bottomrule
\end{tabular}
\caption{Ablation study for temporal token.}
\label{tab:temporaltoken}
\end{table}

\subsection{More Visualization Results}We provide additional visual comparison results as illustrated in Figure \ref{fig: pingpong5 and umbrella2} and Figure \ref{fig: bottle3 and book4} from the MVTrack dataset, and Figure \ref{fig: QGMTD} from the GMTD. MITracker exhibits enhanced re-tracking capabilities both in multi-view and single-view scenarios. Furthermore, multi-view information assists in correcting instances of mistracking. 
To facilitate better visualization, each frame is cropped to a fixed area. The IoU curves above further illustrate the tracking accuracy by comparing each method’s predictions to the ground truth.

\begin{figure*}[th]
	\centering
	\begin{subfigure}{0.9\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/appendix/pingpong5.pdf}
		\caption{Two views: \textit{pingpong5-1} and \textit{pingpong5-4}. ODTrack tends to lose track after extended periods of target disappearance, whereas MITracker demonstrates robust recovery capabilities.}
		\label{fig: pingpong5}
	\end{subfigure}

        \vspace{3mm}
        \begin{subfigure}{0.9\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/appendix/umbrella2.pdf}
		\caption{Two views: \textit{umbrella2-1} and \textit{umbrella2-2}. Under the interference of a similar object, ODTrack fails to re-track the correct target. In contrast, with the aid of multi-view assistance, MITracker can correct tracking errors from frame V1\#415 to \#521.}
		\label{fig: umbrella2}
        \end{subfigure}

        \vspace{3mm}
        \centering
        \begin{subfigure}{0.8\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/appendix/method_odtrack.pdf}
        \end{subfigure}
        
	\caption{Qualitative comparison results on the MVTrack dataset using ODTrack.}
	\label{fig: pingpong5 and umbrella2}
\end{figure*}



\begin{figure*}[th]
	\centering
	\begin{subfigure}{0.9\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/appendix/bottle3.pdf}
	\end{subfigure}

        \centering
        \begin{subfigure}{0.9\textwidth}
		\centering
		\includegraphics[width=0.89\textwidth]{images/appendix/method_odtrack.pdf}
        \caption{Three views: \textit{bottle3-1},  \textit{bottle3-2} and \textit{bottle3-4}. In V2 \#493, MITracker momentarily mistracks a similar object as the target but successfully re-tracks the target by \#562. In contrast, ODTrack struggles to recover once it mistracks.}
		\label{fig: bottle3}
        \end{subfigure}

        \vspace{3mm}
        \begin{subfigure}{0.9\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/appendix/book4.pdf}
        \end{subfigure}
        
        \centering
        \begin{subfigure}{0.9\textwidth}
		\centering
		\includegraphics[width=0.89\textwidth]{images/appendix/method_sam2.pdf}
        \caption{Sequence: \textit{book4-4}. SAM2Long completely loses the target following disappearances at frames \#242 and \#295. Upon re-tracking, it fails to adapt to target deformation, resulting in diminished IoU by frame \#559.}
		\label{fig: book4}
        \end{subfigure}

        
        
	\caption{Qualitative comparison results on the MVTrack dataset using ODTrack and SAM2Long.}
	\label{fig: bottle3 and book4}
\end{figure*}


\begin{figure*}[th]
	\centering
	\begin{subfigure}{0.9\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/appendix/cola.pdf}
		\caption{Sequence: \textit{cola-2}. MITracker demonstrates faster re-tracking capabilities than EVPTrack upon target reappearance.}
		\label{fig: cola-2}
	\end{subfigure}

        \vspace{3mm}
        \begin{subfigure}{0.9\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/appendix/manInOffice.pdf}
		\caption{Sequence: \textit{manInOffice-2}. EVPTrack fails to correct after mistracking. In contrast, MITracker exhibits superior recovery capabilities, as demonstrated between frames \#500 and \#550.}
		\label{fig: manInOffice-2}
        \end{subfigure}

        \vspace{3mm}
        \centering
        \begin{subfigure}{0.8\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/appendix/method_evptrack.pdf}
        \end{subfigure}
        
	\caption{Qualitative comparison results on the GMTD using EVPTrack.}
	\label{fig: QGMTD}
\end{figure*}