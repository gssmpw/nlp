\section{RELATED WORK}
\label{sec:related_work}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ALGORITHMIC PRIMITIVE FITTING
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Algorithmic Primitive Fitting}
Primitive fitting and shape abstraction techniques have a long tradition in 3D shape analysis ____.
They allow extracting structural information of only a single shape to obtain e.g. a label-agnostic segmentation of the shape, but correspondences between abstracted primitives within collections of shapes are not given ____.
They miss on the extraction of global knowledge from a dataset and need to be re-run on unseen samples.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUPERVISED STRUCTURAL LEARNING
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Supervised Structural Learning}
Some research has been performed on supervised learning for structured representation of collections of 3D shapes ____.
These works use the underlying structure to either interpolate between different shapes using the learned latent space or to generate novel 3D shapes following the learned structure of the data.
Conditioning a generative model on an abstract representation leads to more precise and structure-preserving results.
Furthermore, it allows to prescribe the final shape in an intuitively controllable manner.
Unfortunately, this data cannot be easily obtained and all approaches rely on annotated datasets.
These methods can benefit greatly from an automatic cuboid abstraction of 3D shapes.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% UNSUPERVISED SHAPE ABSTRACTION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Unsupervised Shape Abstraction}
To extract the structure of geometric objects one cannot always depend on annotated data.
Unsupervised techniques focus on geometric features of a shape, learn a latent representation, and finally extract an approximate reconstruction of the input using a limited number of primitives.
One defining part of each method is the selection of the representative primitive.

\subsubsection{Cuboids} 
The most simple choice of a volumetric primitive is a cuboid ____. 
They allow intuitive interpretability of their parameters and straight-forward processing, but sacrifice reconstruction quality per primitive due to the limited expressiveness of the shape.
____ showed that they are still a valid choice for shape abstraction.
____ continued the line of work and extended it to hierarchical compositions of cuboids. 
They fit cuboids at multiple levels and use a cuboid selection module to obtain the optimal abstraction.
It is a coarse-to-fine approach that considers first cuboids at the coarsest level and subdivides them if necessary.
Contrary, we propose a fine-to-coarse approach where we start with a large number of primitives and discard or merge redundant ones. 
____ propose to couple shape abstraction together with segmentation.
They introduce two decoders, where the first one learns the abstraction and the second one learns to associate cuboids with the nearest points and couple them by their loss formulation.
Furthermore, they observe that shape abstraction methods suffer often from degenerate primitives reconstructing only the surface of the shape and not its volume.
To resolve this problem ____ introduce a loss formulation incorporating surface normals of the input shape as well as the normals of the cuboid surface.
We propose to use a simpler approach to resolve this issue and do not consider only the surface of the shape but also enforce volume preservation of the shape with our loss directly.

\subsubsection{Superquadrics} 
An extension to cuboids provides the class of superquadrics. 
By only incorporating two more parameters they are able to extend the primitive types by ellipsoids, spheres, cylinders, octahedra and interpolations in between. 
They offer the advantage of a continuous, differentiable parametrized representation, but are rather challenging to edit intuitively or sample uniformly ____.
Nevertheless multiple methods ____ used them to abstract 3D shapes improving the reconstruction quality while using a similar or lower number of primitives than previous work.

\subsubsection{Deformable part templates} 
The most general class of primitives can be characterized by deformable part templates.
They learn to deform a simple sphere mesh ____, cuboids and cylinders ____ or a learned implicit function ____.
The methods mostly rely on a branched autoencoder architecture ____ where the decoder consists of multiple sub-networks which learn a representation of one commonly occurring part each.
Thus the number of learned parts is determined a-priori by the selected number of decoders.
Even though they have the most representative power per primitive and thus the best reconstruction quality, the final reconstructed parts cannot be easily processed or modified by the user as each vertex position of the template mesh is deformed separately by the neural network.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% METHODOLOGY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%