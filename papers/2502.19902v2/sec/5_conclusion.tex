\section{Conclusion}
In this paper, we propose a novel agent, Optimus-2, which can excel in various tasks in the open-world environment of Minecraft. Optimus-2 integrates an MLLM for high-level planning and a Goal-Observation-Action conditioned Policy (GOAP) for low-level control. As a core contribution of this paper, GOAP includes an Action-guided Behavior Encoder to model the observation-action sequence and an MLLM to align the goal with the observation-action sequence for predicting subsequent actions. Extensive experimental results demonstrate that GOAP has mastered various atomic tasks and can comprehend open-ended language instructions. This enables Optimus-2 to achieve superior performance on long-horizon tasks, surpassing existing SOTA. Moreover, we introduce a Minecraft Goal-Observation-Action dataset to provide the community with large-scale, high-quality data for training Minecraft agents.

