@article{ai-grid,
  title={{AI} safety gridworlds},
  author={Leike, Jan and Martic, Miljan and Krakovna, Victoria and Ortega, Pedro A and Everitt, Tom and Lefrancq, Andrew and Orseau, Laurent and Legg, Shane},
  journal={arXiv preprint arXiv:1711.09883},
  year={2017}
}

@phdthesis{thesis_berkenkamp,
  title={Safe exploration in reinforcement learning: {T}heory and applications in robotics},
  author={Berkenkamp, Felix},
  year={2019},
  school={ETH Zurich}
}

@inproceedings{active_exp,
  title={Active exploration for robotic manipulation},
  author={Schneider, Tim and Belousov, Boris and Chalvatzaki, Georgia and Romeres, Diego and Jha, Devesh K and Peters, Jan},
  booktitle={2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={9355--9362},
  year={2022},
  organization={IEEE}
}

@inproceedings{ldm,
  title={Lyapunov density models: {C}onstraining distribution shift in learning-based control},
  author={Kang, Katie and Gradu, Paula and Choi, Jason J and Janner, Michael and Tomlin, Claire and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={10708--10733},
  year={2022},
  organization={PMLR}
}

@inproceedings{cvpo,
  title={Constrained variational policy optimization for safe reinforcement learning},
  author={Liu, Zuxin and Cen, Zhepeng and Isenbaev, Vladislav and Liu, Wei and Wu, Steven and Li, Bo and Zhao, Ding},
  booktitle={International Conference on Machine Learning},
  pages={13644--13668},
  year={2022},
  organization={PMLR}
}

@article{learning_to_be_safe,
  title={Learning to be safe: {D}eep {RL} with a safety critic},
  author={Srinivasan, Krishnan and Eysenbach, Benjamin and Ha, Sehoon and Tan, Jie and Finn, Chelsea},
  journal={arXiv preprint arXiv:2010.14603},
  year={2020}
}

@inproceedings{advantage_based_intervention,
  title={Safe reinforcement learning using advantage-based intervention},
  author={Wagener, Nolan C and Boots, Byron and Cheng, Ching-An},
  booktitle={International Conference on Machine Learning},
  pages={10630--10640},
  year={2021},
  organization={PMLR}
}

@inproceedings{unsupervised_action_planning,
  title={Improving safety in deep reinforcement learning using unsupervised action planning},
  author={Hsu, Hao-Lun and Huang, Qiuhua and Ha, Sehoon},
  booktitle={2022 International Conference on Robotics and Automation (ICRA)},
  pages={5567--5573},
  year={2022},
  organization={IEEE}
}

@article{VIME,
  title={{VIME: V}ariational information maximizing exploration},
  author={Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{meta_learned_instincts,
  title={Safe reinforcement learning through meta-learned instincts},
  author={Grbic, Djordje and Risi, Sebastian},
  journal={arXiv preprint arXiv:2005.03233},
  year={2020}
}

@inproceedings{sauteRL,
  title={{Saut{\'e} RL: A}lmost surely safe reinforcement learning using state augmentation},
  author={Sootla, Aivar and Cowen-Rivers, Alexander I and Jafferjee, Taher and Wang, Ziyan and Mguni, David H and Wang, Jun and Ammar, Haitham},
  booktitle={International Conference on Machine Learning},
  pages={20423--20443},
  year={2022},
  organization={PMLR}
}

@article{risk-averse-offline-rl,
  title={Risk-averse offline reinforcement learning},
  author={Urp{\'\i}, N{\'u}ria Armengol and Curi, Sebastian and Krause, Andreas},
  journal={arXiv preprint arXiv:2102.05371},
  year={2021}
}

@inproceedings{cpo,
  title={Constrained policy optimization},
  author={Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={22--31},
  year={2017},
  organization={PMLR}
}

@article{intrinsic_fear,
  title={Combating reinforcement learning's {S}isyphean curse with intrinsic fear},
  author={Lipton, Zachary C and Azizzadenesheli, Kamyar and Kumar, Abhishek and Li, Lihong and Gao, Jianfeng and Deng, Li},
  journal={arXiv preprint arXiv:1611.01211},
  year={2016}
}

@article{safe_exp_int_ml,
  title={Safe exploration for interactive machine learning},
  author={Turchetta, Matteo and Berkenkamp, Felix and Krause, Andreas},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}


@article{bootDQN,
  title={Deep exploration via bootstrapped {DQN}},
  author={Osband, Ian and Blundell, Charles and Pritzel, Alexander and Van Roy, Benjamin},
  journal={Advances in Neural Information Processing Systems},
  volume={29},
  year={2016}
}

@article{top,
  title={Tactical optimism and pessimism for deep reinforcement learning},
  author={Moskovitz, Ted and Parker-Holder, Jack and Pacchiano, Aldo and Arbel, Michael and Jordan, Michael},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={12849--12863},
  year={2021}
}

@article{rpf,
  title={Randomized prior functions for deep reinforcement learning},
  author={Osband, Ian and Aslanides, John and Cassirer, Albin},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}


@inproceedings{curiosity_org,
  title={Curiosity-driven exploration by self-supervised prediction},
  author={Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},
  booktitle={International conference on machine learning},
  pages={2778--2787},
  year={2017},
  organization={PMLR}
}

@article{rnd,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  journal={arXiv preprint arXiv:1810.12894},
  year={2018}
}

@book{drl,
    title={Distributional Reinforcement Learning},
    author={Marc G. Bellemare and Will Dabney and Mark Rowland},
    publisher={MIT Press},
    note={\url{http://www.distributional-rl.org}},
    year={2023}
}

@article{csc,
  title={Conservative safety critics for exploration},
  author={Bharadhwaj, Homanga and Kumar, Aviral and Rhinehart, Nicholas and Levine, Sergey and Shkurti, Florian and Garg, Animesh},
  journal={arXiv preprint arXiv:2010.14497},
  year={2020}
}

@inproceedings{dist_rl,
  title={A distributional perspective on reinforcement learning},
  author={Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  pages={449--458},
  year={2017},
  organization={PMLR}
}

@article{slrl,
  title={You Only Live Once: {S}ingle-Life Reinforcement Learning},
  author={Chen, Annie S and Sharma, Archit and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2210.08863},
  year={2022}
}

@article{gpt_3,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{ioca,
  title={Interesting object, curious agent: {L}earning task-agnostic exploration},
  author={Parisi, Simone and Dean, Victoria and Pathak, Deepak and Gupta, Abhinav},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={20516--20530},
  year={2021}
}

@article{singh2022reinforcement,
  title={Reinforcement learning in robotic applications: {A} comprehensive survey},
  author={Singh, Bharat and Kumar, Rajesh and Singh, Vinay Pratap},
  journal={Artificial Intelligence Review},
  pages={1--46},
  year={2022}
}

@article{zhang2021reinforcement,
  title={Reinforcement learning for robot research: {A} comprehensive review and open issues},
  author={Zhang, Tengteng and Mo, Hongwei},
  journal={International Journal of Advanced Robotic Systems},
  volume={18},
  year={2021}
}

@article{zhou2019environment,
  title={Environment probing interaction policies},
  author={Zhou, Wenxuan and Pinto, Lerrel and Gupta, Abhinav},
  journal={Internation Conference on Learning Representations},
  year={2019}
}

@inproceedings{kim2019curiosity,
  title={Curiosity-bottleneck: {E}xploration by distilling task-specific novelty},
  author={Kim, Youngjin and Nam, Wontae and Kim, Hyunwoo and Kim, Ji-Hoon and Kim, Gunhee},
  booktitle={International Conference on Machine Learning},
  pages={3379--3388},
  year={2019}
}

@inproceedings{mao2018universal,
  title={Universal agent for disentangling environments and tasks},
  author={Mao, Jiayuan and Dong, Honghua and Lim, Joseph J},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{simpson1996neither,
  title={Neither clear nor present: {T}he social construction of safety and danger},
  author={Simpson, Ruth},
  booktitle={Sociological Forum},
  volume={11},
  pages={549--562},
  year={1996}
}

@article{crawford2002learning,
  title={Learning where to look for danger: {I}ntegrating affective and spatial information},
  author={Crawford, L Elizabeth and Cacioppo, John T},
  journal={Psychological science},
  volume={13},
  pages={449--453},
  year={2002}
}

@article{bhatia2023rl,
  title={{RL}$^{3}$: {B}oosting Meta Reinforcement Learning via {RL} inside {RL}$^{2}$},
  author={Bhatia, Abhinav and Nashed, Samer B and Zilberstein, Shlomo},
  journal={arXiv preprint arXiv:2306.15909},
  year={2023}
}

@inproceedings{ma2019state,
  title={State-augmentation transformations for risk-sensitive reinforcement learning},
  author={Ma, Shuai and Yu, Jia Yuan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={4512--4519},
  year={2019}
}

@article{calvo2023state,
  title={State augmented constrained reinforcement learning: {O}vercoming the limitations of learning with rewards},
  author={Calvo-Fullana, Miguel and Paternain, Santiago and Chamon, Luiz FO and Ribeiro, Alejandro},
  journal={IEEE Transactions on Automatic Control},
  year={2023}
}

@inproceedings{nath2021revisiting,
  title={Revisiting state augmentation methods for reinforcement learning with stochastic delays},
  author={Nath, Somjit and Baranwal, Mayank and Khadilkar, Harshad},
  booktitle={Proceedings of the 30th ACM International Conference on Information \& Knowledge Management},
  pages={1346--1355},
  year={2021}
}

@article{liu2022goal,
  title={Goal-conditioned reinforcement learning: {P}roblems and solutions},
  author={Liu, Minghuan and Zhu, Menghui and Zhang, Weinan},
  journal={arXiv preprint arXiv:2201.08299},
  year={2022}
}

@article{keating2008adolescent,
  title={Adolescent drivers: {A} developmental perspective on risk, proficiency, and safety},
  author={Keating, Daniel P and Halpern-Felsher, Bonnie L},
  journal={American Journal of Preventive Medicine},
  volume={35},
  number={3},
  pages={S272--S277},
  year={2008}
}
@article{safety-gym,
    author = {Ray, Alex and Achiam, Joshua and Amodei, Dario},
    title = {{Benchmarking Safe Exploration in Deep Reinforcement Learning}},
    year = {2019}
}
@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}
@article{cql,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}
@article{dqn,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}
@inproceedings{iqn,
  title={Implicit quantile networks for distributional reinforcement learning},
  author={Dabney, Will and Ostrovski, Georg and Silver, David and Munos, R{\'e}mi},
  booktitle={International conference on machine learning},
  pages={1096--1105},
  year={2018},
  organization={PMLR}
}
@incollection{huber,
  title={Robust estimation of a location parameter},
  author={Huber, Peter J},
  booktitle={Breakthroughs in statistics: Methodology and distribution},
  pages={492--518},
  year={1992},
  publisher={Springer}
}
@article{d4rl,
  title={D4rl: Datasets for deep data-driven reinforcement learning},
  author={Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.07219},
  year={2020}
}
@article{dsrl,
  title={Datasets and benchmarks for offline safe reinforcement learning},
  author={Liu, Zuxin and Guo, Zijian and Lin, Haohong and Yao, Yihang and Zhu, Jiacheng and Cen, Zhepeng and Hu, Hanjiang and Yu, Wenhao and Zhang, Tingnan and Tan, Jie and others},
  journal={arXiv preprint arXiv:2306.09303},
  year={2023}
}
@article{e3b,
  title={Exploration via elliptical episodic bonuses},
  author={Henaff, Mikael and Raileanu, Roberta and Jiang, Minqi and Rockt{\"a}schel, Tim},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={37631--37646},
  year={2022}
}
@inproceedings{impala,
  title={Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Vlad and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  booktitle={International conference on machine learning},
  pages={1407--1416},
  year={2018},
  organization={PMLR}
}
@article{ioca,
  title={Interesting object, curious agent: Learning task-agnostic exploration},
  author={Parisi, Simone and Dean, Victoria and Pathak, Deepak and Gupta, Abhinav},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={20516--20530},
  year={2021}
}
@article{mode_switch,
  title={When should agents explore?},
  author={Pislar, Miruna and Szepesvari, David and Ostrovski, Georg and Borsa, Diana and Schaul, Tom},
  journal={arXiv preprint arXiv:2108.11811},
  year={2021}
}
@inproceedings{pid_lag,
  title={Responsive safety in reinforcement learning by pid lagrangian methods},
  author={Stooke, Adam and Achiam, Joshua and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={9133--9143},
  year={2020},
  organization={PMLR}
}
@article{ride,
  title={Ride: Rewarding impact-driven exploration for procedurally-generated environments},
  author={Raileanu, Roberta and Rockt{\"a}schel, Tim},
  journal={arXiv preprint arXiv:2002.12292},
  year={2020}
}
@article{extended_epsilon,
  title={Temporally-extended $\{$$\backslash$epsilon$\}$-greedy exploration},
  author={Dabney, Will and Ostrovski, Georg and Barreto, Andr{\'e}},
  journal={arXiv preprint arXiv:2006.01782},
  year={2020}
}
@article{gpt_4,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}
@inproceedings{dalle,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International conference on machine learning},
  pages={8821--8831},
  year={2021},
  organization={Pmlr}
}
@article{rtx,
  title={Open x-embodiment: Robotic learning datasets and rt-x models},
  author={Padalkar, Abhishek and Pooley, Acorn and Jain, Ajinkya and Bewley, Alex and Herzog, Alex and Irpan, Alex and Khazatsky, Alexander and Rai, Anant and Singh, Anikait and Brohan, Anthony and others},
  journal={arXiv preprint arXiv:2310.08864},
  year={2023}
}
@article{ts,
  author       = {Daniel Russo and
                  Benjamin Van Roy and
                  Abbas Kazerouni and
                  Ian Osband},
  title        = {A Tutorial on Thompson Sampling},
  journal      = {CoRR},
  volume       = {abs/1707.02038},
  year         = {2017},
  url          = {http://arxiv.org/abs/1707.02038},
  eprinttype    = {arXiv},
  eprint       = {1707.02038},
  timestamp    = {Mon, 13 Aug 2018 16:46:49 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/0001RKO17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{sac,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}
@article{coherent,
  title={Coherent measures of risk},
  author={Artzner, Philippe and Delbaen, Freddy and Eber, Jean-Marc and Heath, David},
  journal={Mathematical finance},
  volume={9},
  number={3},
  pages={203--228},
  year={1999},
  publisher={Wiley Online Library}
}
@article{chow2015risk,
  title={Risk-sensitive and robust decision-making: a cvar optimization approach},
  author={Chow, Yinlam and Tamar, Aviv and Mannor, Shie and Pavone, Marco},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}
@article{boda2006time,
  title={Time consistent dynamic risk measures},
  author={Boda, Kang and Filar, Jerzy A},
  journal={Mathematical Methods of Operations Research},
  volume={63},
  pages={169--186},
  year={2006},
  publisher={Springer}
}
@article{gagne2021two,
  title={Two steps to risk sensitivity},
  author={Gagne, Christopher and Dayan, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={22209--22220},
  year={2021}
}
@article{ruszczynski2010risk,
  title={Risk-averse dynamic programming for Markov decision processes},
  author={Ruszczy{\'n}ski, Andrzej},
  journal={Mathematical programming},
  volume={125},
  pages={235--261},
  year={2010},
  publisher={Springer}
}
@article{tamar2015policy,
  title={Policy gradient for coherent risk measures},
  author={Tamar, Aviv and Chow, Yinlam and Ghavamzadeh, Mohammad and Mannor, Shie},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}
@inproceedings{prashanth2014policy,
  title={Policy gradients for CVaR-constrained MDPs},
  author={Prashanth, LA},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={155--169},
  year={2014},
  organization={Springer}
}
@article{chow2018risk,
  title={Risk-constrained reinforcement learning with percentile risk criteria},
  author={Chow, Yinlam and Ghavamzadeh, Mohammad and Janson, Lucas and Pavone, Marco},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={167},
  pages={1--51},
  year={2018}
}
@article{wcpg,
  title={Worst cases policy gradients},
  author={Tang, Yichuan Charlie and Zhang, Jian and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1911.03618},
  year={2019}
}
@article{tamar2016sequential,
  title={Sequential decision making with coherent risk},
  author={Tamar, Aviv and Chow, Yinlam and Ghavamzadeh, Mohammad and Mannor, Shie},
  journal={IEEE transactions on automatic control},
  volume={62},
  number={7},
  pages={3323--3338},
  year={2016},
  publisher={IEEE}
}
@inproceedings{keramati2020being,
  title={Being optimistic to be conservative: Quickly learning a CVaR policy},
  author={Keramati, Ramtin and Dann, Christoph and Tamkin, Alex and Brunskill, Emma},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={04},
  pages={4436--4443},
  year={2020}
}
@inproceedings{morimura2010nonparametric,
  title={Nonparametric return distribution approximation for reinforcement learning},
  author={Morimura, Tetsuro and Sugiyama, Masashi and Kashima, Hisashi and Hachiya, Hirotaka and Tanaka, Toshiyuki},
  booktitle={Proceedings of the 27th International Conference on Machine Learning (ICML-10)},
  pages={799--806},
  year={2010}
}
@article{ma2020dsac,
  title={Dsac: Distributional soft actor critic for risk-sensitive reinforcement learning},
  author={Ma, Xiaoteng and Xia, Li and Zhou, Zhengyuan and Yang, Jun and Zhao, Qianchuan},
  journal={arXiv preprint arXiv:2004.14547},
  year={2020}
}
@article{urpi2021risk,
  title={Risk-averse offline reinforcement learning},
  author={Urp{\'\i}, N{\'u}ria Armengol and Curi, Sebastian and Krause, Andreas},
  journal={arXiv preprint arXiv:2102.05371},
  year={2021}
}
@article{ben2000robust,
  title={Robust solutions of linear programming problems contaminated with uncertain data},
  author={Ben-Tal, Aharon and Nemirovski, Arkadi},
  journal={Mathematical programming},
  volume={88},
  pages={411--424},
  year={2000},
  publisher={Springer}
}
@inproceedings{wolff2012robust,
  title={Robust control of uncertain Markov decision processes with temporal logic specifications},
  author={Wolff, Eric M and Topcu, Ufuk and Murray, Richard M},
  booktitle={2012 IEEE 51st IEEE Conference on decision and control (CDC)},
  pages={3372--3379},
  year={2012},
  organization={IEEE}
}
@article{iyengar2005robust,
  title={Robust dynamic programming},
  author={Iyengar, Garud N},
  journal={Mathematics of Operations Research},
  volume={30},
  number={2},
  pages={257--280},
  year={2005},
  publisher={INFORMS}
}
@article{nilim2005robust,
  title={Robust control of Markov decision processes with uncertain transition matrices},
  author={Nilim, Arnab and El Ghaoui, Laurent},
  journal={Operations Research},
  volume={53},
  number={5},
  pages={780--798},
  year={2005},
  publisher={INFORMS}
}
@article{ppo,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}
@article{adroit,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1709.10087},
  year={2017}
}
@article{vint,
  title={Vint: A foundation model for visual navigation},
  author={Shah, Dhruv and Sridhar, Ajay and Dashora, Nitish and Stachowicz, Kyle and Black, Kevin and Hirose, Noriaki and Levine, Sergey},
  journal={arXiv preprint arXiv:2306.14846},
  year={2023}
}
@article{rt2,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}

@article{afsar2022reinforcement,
  title={Reinforcement learning based recommender systems: A survey},
  author={Afsar, M Mehdi and Crump, Trafford and Far, Behrouz},
  journal={ACM Computing Surveys},
  volume={55},
  number={7},
  pages={1--38},
  year={2022},
  publisher={ACM New York, NY}
}

@article{shao2019survey,
  title={A survey of deep reinforcement learning in video games},
  author={Shao, Kun and Tang, Zhentao and Zhu, Yuanheng and Li, Nannan and Zhao, Dongbin},
  journal={arXiv preprint arXiv:1912.10944},
  year={2019}
}

@article{degrave2022magnetic,
  title={Magnetic control of tokamak plasmas through deep reinforcement learning},
  author={Degrave, Jonas and Felici, Federico and Buchli, Jonas and Neunert, Michael and Tracey, Brendan and Carpanese, Francesco and Ewalds, Timo and Hafner, Roland and Abdolmaleki, Abbas and de Las Casas, Diego and others},
  journal={Nature},
  volume={602},
  number={7897},
  pages={414--419},
  year={2022},
  publisher={Nature Publishing Group}
}

@article{arwa2020reinforcement,
  title={Reinforcement learning techniques for optimal power control in grid-connected microgrids: A comprehensive review},
  author={Arwa, Erick O and Folly, Komla A},
  journal={Ieee Access},
  volume={8},
  pages={208992--209007},
  year={2020},
  publisher={IEEE}
}

@article{chen2022reinforcement,
  title={Reinforcement learning for selective key applications in power systems: Recent advances and future challenges},
  author={Chen, Xin and Qu, Guannan and Tang, Yujie and Low, Steven and Li, Na},
  journal={IEEE Transactions on Smart Grid},
  volume={13},
  number={4},
  pages={2935--2958},
  year={2022},
  publisher={IEEE}
}

@article{neu2017unified,
  title={A unified view of entropy-regularized markov decision processes},
  author={Neu, Gergely and Jonsson, Anders and G{\'o}mez, Vicen{\c{c}}},
  journal={arXiv preprint arXiv:1705.07798},
  year={2017}
}

@article{hao2023exploration,
  title={Exploration in deep reinforcement learning: From single-agent to multiagent domain},
  author={Hao, Jianye and Yang, Tianpei and Tang, Hongyao and Bai, Chenjia and Liu, Jinyi and Meng, Zhaopeng and Liu, Peng and Wang, Zhen},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2023},
  publisher={IEEE}
}

@inproceedings{doctor2022learning,
  title={Learning Intrinsically Motivated Transition Models for Autonomous Systems},
  author={Doctor, Khoshrav and Ghosh, Hia and Grupen, Roderic},
  booktitle={2022 IEEE International Conference on Development and Learning (ICDL)},
  pages={9--14},
  year={2022},
  organization={IEEE}
}

@article{howard1972risk,
  title={Risk-sensitive Markov decision processes},
  author={Howard, Ronald A and Matheson, James E},
  journal={Management science},
  volume={18},
  number={7},
  pages={356--369},
  year={1972},
  publisher={INFORMS}
}

@article{garcia2015comprehensive,
  title={A comprehensive survey on safe reinforcement learning},
  author={Garc{\i}a, Javier and Fern{\'a}ndez, Fernando},
  journal={Journal of Machine Learning Research},
  volume={16},
  number={1},
  pages={1437--1480},
  year={2015}
}

@article{salvato2021crossing,
  title={Crossing the reality gap: A survey on sim-to-real transferability of robot controllers in reinforcement learning},
  author={Salvato, Erica and Fenu, Gianfranco and Medvet, Eric and Pellegrino, Felice Andrea},
  journal={IEEE Access},
  volume={9},
  pages={153171--153187},
  year={2021},
  publisher={IEEE}
}

@article{ding2021grounding,
  title={Grounding representation similarity through statistical testing},
  author={Ding, Frances and Denain, Jean-Stanislas and Steinhardt, Jacob},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={1556--1568},
  year={2021}
}

@article{nashed2023fairness,
  title={Fairness and sequential decision making: Limits, lessons, and opportunities},
  author={Nashed, Samer B and Svegliato, Justin and Blodgett, Su Lin},
  journal={arXiv preprint arXiv:2301.05753},
  year={2023}
}
@inproceedings{sutton2011horde,
  title={Horde: A scalable real-time architecture for learning knowledge from unsupervised sensorimotor interaction},
  author={Sutton, Richard S and Modayil, Joseph and Delp, Michael and Degris, Thomas and Pilarski, Patrick M and White, Adam and Precup, Doina},
  booktitle={The 10th International Conference on Autonomous Agents and Multiagent Systems-Volume 2},
  pages={761--768},
  year={2011}
}
@article{jaderberg2016reinforcement,
  title={Reinforcement learning with unsupervised auxiliary tasks},
  author={Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1611.05397},
  year={2016}
}
@inproceedings{riedmiller2018learning,
  title={Learning by playing solving sparse reward tasks from scratch},
  author={Riedmiller, Martin and Hafner, Roland and Lampe, Thomas and Neunert, Michael and Degrave, Jonas and Wiele, Tom and Mnih, Vlad and Heess, Nicolas and Springenberg, Jost Tobias},
  booktitle={International conference on machine learning},
  pages={4344--4353},
  year={2018},
  organization={PMLR}
}
@article{lin2019adaptive,
  title={Adaptive auxiliary task weighting for reinforcement learning},
  author={Lin, Xingyu and Baweja, Harjatin and Kantor, George and Held, David},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}
@article{fujimoto2024sale,
  title={For sale: State-action representation learning for deep reinforcement learning},
  author={Fujimoto, Scott and Chang, Wei-Di and Smith, Edward and Gu, Shixiang Shane and Precup, Doina and Meger, David},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{schwarzer2020data,
  title={Data-efficient reinforcement learning with self-predictive representations},
  author={Schwarzer, Max and Anand, Ankesh and Goel, Rishab and Hjelm, R Devon and Courville, Aaron and Bachman, Philip},
  journal={arXiv preprint arXiv:2007.05929},
  year={2020}
}
@inproceedings{ota2020can,
  title={Can increasing input dimensionality improve deep reinforcement learning?},
  author={Ota, Kei and Oiki, Tomoaki and Jha, Devesh and Mariyama, Toshisada and Nikovski, Daniel},
  booktitle={International conference on machine learning},
  pages={7424--7433},
  year={2020},
  organization={PMLR}
}
@inproceedings{munk2016learning,
  title={Learning state representation for deep actor-critic control},
  author={Munk, Jelle and Kober, Jens and Babu{\v{s}}ka, Robert},
  booktitle={2016 IEEE 55th Conference on Decision and Control (CDC)},
  pages={4667--4673},
  year={2016},
  organization={IEEE}
}
@article{watter2015embed,
  title={Embed to control: A locally linear latent dynamics model for control from raw images},
  author={Watter, Manuel and Springenberg, Jost and Boedecker, Joschka and Riedmiller, Martin},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}
@article{ha2018world,
  title={World models},
  author={Ha, David and Schmidhuber, J{\"u}rgen},
  journal={arXiv preprint arXiv:1803.10122},
  year={2018}
}
@article{liu2021return,
  title={Return-based contrastive representation learning for reinforcement learning},
  author={Liu, Guoqing and Zhang, Chuheng and Zhao, Li and Qin, Tao and Zhu, Jinhua and Li, Jian and Yu, Nenghai and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:2102.10960},
  year={2021}
}
@inproceedings{primacy,
  title={The primacy bias in deep reinforcement learning},
  author={Nikishin, Evgenii and Schwarzer, Max and Dâ€™Oro, Pierluca and Bacon, Pierre-Luc and Courville, Aaron},
  booktitle={International conference on machine learning},
  pages={16828--16847},
  year={2022},
  organization={PMLR}
}
@article{overfitting_regularization,
  title={Efficient deep reinforcement learning requires regulating overfitting},
  author={Li, Qiyang and Kumar, Aviral and Kostrikov, Ilya and Levine, Sergey},
  journal={arXiv preprint arXiv:2304.10466},
  year={2023}
}
@article{overfitting_pomdp,
  title={On overfitting and asymptotic bias in batch reinforcement learning with partial observability},
  author={Fran{\c{c}}ois-Lavet, Vincent and Rabusseau, Guillaume and Pineau, Joelle and Ernst, Damien and Fonteneau, Raphael},
  journal={Journal of Artificial Intelligence Research},
  volume={65},
  pages={1--30},
  year={2019}
}
@article{arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}
@article{overfitting_robust_bengio,
  title={Revisiting the arcade learning environment: Evaluation protocols and open problems for general agents},
  author={Machado, Marlos C and Bellemare, Marc G and Talvitie, Erik and Veness, Joel and Hausknecht, Matthew and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={61},
  pages={523--562},
  year={2018}
}
@article{overfitting_observational,
  title={Observational overfitting in reinforcement learning},
  author={Song, Xingyou and Jiang, Yiding and Tu, Stephen and Du, Yilun and Neyshabur, Behnam},
  journal={arXiv preprint arXiv:1912.02975},
  year={2019}
}
@inproceedings{overfitting_action,
  title={Frame skip is a powerful parameter for learning to play atari},
  author={Braylan, Alex and Hollenbeck, Mark and Meyerson, Elliot and Miikkulainen, Risto},
  booktitle={Workshops at the twenty-ninth AAAI conference on artificial intelligence},
  year={2015}
}
@article{when_to_ask_for_help,
  title={When to ask for help: Proactive interventions in autonomous reinforcement learning},
  author={Xie, Annie and Tajwar, Fahim and Sharma, Archit and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={16918--16930},
  year={2022}
}
@article{risk_constrained,
  title={Risk-constrained reinforcement learning with percentile risk criteria},
  author={Chow, Yinlam and Ghavamzadeh, Mohammad and Janson, Lucas and Pavone, Marco},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={167},
  pages={1--51},
  year={2018}
}
@article{efficient_risk_averse,
  title={Efficient risk-averse reinforcement learning},
  author={Greenberg, Ido and Chow, Yinlam and Ghavamzadeh, Mohammad and Mannor, Shie},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={32639--32652},
  year={2022}
}
@article{le2020contrastive,
  title={Contrastive representation learning: A framework and review},
  author={Le-Khac, Phuc H and Healy, Graham and Smeaton, Alan F},
  journal={Ieee Access},
  volume={8},
  pages={193907--193934},
  year={2020},
  publisher={IEEE}
}
@inproceedings{crpo,
  title={Crpo: A new approach for safe reinforcement learning with convergence guarantee},
  author={Xu, Tengyu and Liang, Yingbin and Lan, Guanghui},
  booktitle={International Conference on Machine Learning},
  pages={11480--11491},
  year={2021},
  organization={PMLR}
}

@inproceedings{mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ international conference on intelligent robots and systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}
@article{sauteadj,
  title={Solving Richly Constrained Reinforcement Learning through State Augmentation and Reward Penalties},
  author={Jiang, Hao and Mai, Tien and Varakantham, Pradeep and Hoang, Minh Huy},
  journal={arXiv preprint arXiv:2301.11592},
  year={2023}
}
@inproceedings{cscadj,
  title={Bridging hamilton-jacobi safety analysis and reinforcement learning},
  author={Fisac, Jaime F and Lugovoy, Neil F and Rubies-Royo, Vicen{\c{c}} and Ghosh, Shromona and Tomlin, Claire J},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={8550--8556},
  year={2019},
  organization={IEEE}
}
@article{metadrive,
  title={Metadrive: Composing diverse driving scenarios for generalizable reinforcement learning},
  author={Li, Quanyi and Peng, Zhenghao and Feng, Lan and Zhang, Qihang and Xue, Zhenghai and Zhou, Bolei},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={45},
  number={3},
  pages={3461--3475},
  year={2022},
  publisher={IEEE}
}
@article{
  fsrl,
  title={Datasets and Benchmarks for Offline Safe Reinforcement Learning},
  author={Zuxin Liu and Zijian Guo and Haohong Lin and Yihang Yao and Jiacheng Zhu and Zhepeng Cen and Hanjiang Hu and Wenhao Yu and Tingnan Zhang and Jie Tan and Ding Zhao},
  journal={Journal of Data-centric Machine Learning Research},
  year={2024}
}
@article{omnisafe,
  author  = {Jiaming Ji and Jiayi Zhou and Borong Zhang and Juntao Dai and Xuehai Pan and Ruiyang Sun and Weidong Huang and Yiran Geng and Mickel Liu and Yaodong Yang},
  title   = {OmniSafe: An Infrastructure for Accelerating Safe Reinforcement Learning Research},
  journal = {Journal of Machine Learning Research},
  year    = {2024},
  volume  = {25},
  number  = {285},
  pages   = {1--6},
  url     = {http://jmlr.org/papers/v25/23-0681.html}
}
@inproceedings{grad,
  title={Balance reward and safety optimization for safe reinforcement learning: A perspective of gradient manipulation},
  author={Gu, Shangding and Sel, Bilgehan and Ding, Yuhao and Wang, Lu and Lin, Qingwei and Jin, Ming and Knoll, Alois},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={19},
  pages={21099--21106},
  year={2024}
}
@article{gu2024review,
  title={A Review of Safe Reinforcement Learning: Methods, Theories and Applications},
  author={Gu, Shangding and Yang, Long and Du, Yali and Chen, Guang and Walter, Florian and Wang, Jun and Knoll, Alois},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  publisher={IEEE}
}
@article{huang2023safe,
  title={Safe dreamerv3: Safe reinforcement learning with world models},
  author={Huang, Weidong and Ji, Jiaming and Zhang, Borong and Xia, Chunhe and Yang, Yaodong},
  journal={arXiv preprint arXiv:2307.07176},
  year={2023}
}