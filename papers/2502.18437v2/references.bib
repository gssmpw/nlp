@article{bardenhagen1970GeneralizedInterpolation,
  title = {The {{Generalized Interpolation Material Point Method}}},
  author = {Bardenhagen, S. G. and Kober, E. M.},
  year = {2004},
  journal = {Computer Modeling in Engineering \& Sciences},
  volume = {5},
  number = {6},
  pages = {477--496},
  publisher = {Tech Science Press},
  issn = {1526-1492, 1526-1506},
  doi = {10.3970/cmes.2004.005.477},
  abstract = {The Material Point Method (MPM) discrete solution procedure for computational solid mechanics is generalized using a variational form and a Petrov--Galerkin discretization scheme, resulting in a family of methods named the G... {\textbar} Find, read and cite all the research you need on Tech Science Press},
  langid = {english}
}

@article{brackbill1986FLIPMethod,
  title = {{{FLIP}}: {{A}} Method for Adaptively Zoned, Particle-in-Cell Calculations of Fluid Flows in Two Dimensions},
  shorttitle = {{{FLIP}}},
  author = {Brackbill, J.U. and Ruppel, H.M.},
  year = {1986},
  month = aug,
  journal = {Journal of Computational Physics},
  volume = {65},
  number = {2},
  pages = {314--343},
  issn = {00219991},
  doi = {10.1016/0021-9991(86)90211-1},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english}
}

@article{brown2004RealtimeKnottying,
  title = {Real-Time Knot-Tying Simulation},
  author = {Brown, Joel and Latombe, Jean-Claude and Montgomery, Kevin},
  year = {2004},
  month = may,
  journal = {The Visual Computer},
  volume = {20},
  number = {2-3},
  pages = {165--179},
  issn = {0178-2789, 1432-8726},
  doi = {10.1007/s00371-003-0226-y},
  abstract = {While rope is arguably a simpler system to simulate than cloth, the real-time simulation of rope, and knot tying in particular, raise unique and difficult issues in contact detection and management. Some practical knots can only be achieved by complicated crossings of the rope, yielding multiple simultaneous contacts, especially when the rope is pulled tight. This paper describes a simulator allowing a user to grasp and smoothly manipulate a virtual rope and to tie arbitrary knots, including knots around other objects, in real-time. One component of the simulator precisely detects selfcollisions in the rope, as well as collisions with other objects. Another component manages collisions to prevent penetration, while making the rope slide with some friction along itself and other objects, so that knots can be pulled tight in believable manner. An additional module uses recent results from knot theory to identify which topological knots have been tied, also in real-time. This work was motivated by surgical suturing, but simulation in other domains, such as sailing and rock climbing, could benefit from it.},
  copyright = {http://www.springer.com/tdm},
  langid = {english}
}

@incollection{comas2008EfficientNonlinearFEM,
  title = {Efficient {{Nonlinear FEM}} for {{Soft Tissue Modelling}} and {{Its GPU Implementation}} within the {{Open Source Framework SOFA}}},
  booktitle = {Biomedical {{Simulation}}},
  author = {Comas, Olivier and Taylor, Zeike A. and Allard, J{\'e}r{\'e}mie and Ourselin, S{\'e}bastien and Cotin, St{\'e}phane and Passenger, Josh},
  editor = {Bello, Fernando and Edwards, P. J. Eddie},
  year = {2008},
  volume = {5104},
  pages = {28--39},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  issn = {0302-9743, 1611-3349},
  doi = {10.1007/978-3-540-70521-5_4},
  abstract = {Accurate biomechanical modelling of soft tissue is a key aspect for achieving realistic surgical simulations. However, because medical simulation is a multi-disciplinary area, researchers do not always have sufficient resources to develop an efficient and physically rigorous model for organ deformation. We address this issue by implementing a CUDA-based nonlinear finite element model into the SOFA open source framework. The proposed model is an anisotropic visco-hyperelastic constitutive formulation implemented on a graphical processor unit (GPU). After presenting results on the model's performance we illustrate the benefits of its integration within the SOFA framework on a simulation of cataract surgery.},
  isbn = {978-3-540-70520-8 978-3-540-70521-5},
  langid = {english}
}

@inproceedings{dallalba2024FFSRLHigh,
  title = {{{FF-SRL}}: {{High Performance GPU-Based Surgical Simulation For Robot Learning}}},
  shorttitle = {{{FF-SRL}}},
  booktitle = {2024 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Dall'Alba, Diego and Naskr{\k e}t, Micha{\l} and Kami{\'n}ska, Sabina and Korzeniowski, Przemys{\l}aw},
  year = {2024},
  month = oct,
  pages = {8378--8384},
  issn = {2153-0866},
  doi = {10.1109/IROS58592.2024.10801658},
  abstract = {Robotic surgery is a rapidly developing field that can greatly benefit from the automation of surgical tasks. However, training techniques such as Reinforcement Learning (RL) require a high number of task repetitions, which are generally unsafe and impractical to perform on real surgical systems. This stresses the need for simulated surgical environments, which are not only realistic, but also computationally efficient and scalable. We introduce FF-SRL (Fast and Flexible Surgical Reinforcement Learning), a high-performance learning environment for robotic surgery. In FF-SRL both physics simulation and RL policy training reside entirely on a single GPU. This avoids typical bottlenecks associated with data transfer between the CPU and GPU, leading to accelerated learning rates. Our results show that FF-SRL reduces the training time of a complex tissue manipulation task by an order of magnitude, down to a couple of minutes, compared to a common CPU/GPU simulator. Such speed-up may facilitate the experimentation with RL techniques and contribute to the development of new generation of surgical systems. To this end, we make our code publicly available to the community.},
  keywords = {Codes,Graphics processing units,Intelligent robots,Physics,Reinforcement learning,Robot learning,Scalability,Stress,Surgery,Training}
}

@incollection{devaucorbeil2020MaterialPoint,
  title = {Material Point Method after 25 Years: {{Theory}}, Implementation, and Applications},
  shorttitle = {Material Point Method after 25 Years},
  booktitle = {Advances in {{Applied Mechanics}}},
  author = {De Vaucorbeil, Alban and Nguyen, Vinh Phu and Sinaie, Sina and Wu, Jian Ying},
  year = {2020},
  volume = {53},
  pages = {185--398},
  publisher = {Elsevier},
  doi = {10.1016/bs.aams.2019.11.001},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  isbn = {978-0-12-820989-9},
  langid = {english}
}

@inproceedings{enayati2018RoboticAssistanceasNeeded,
  title = {Robotic {{Assistance-as-Needed}} for {{Enhanced Visuomotor Learning}} in {{Surgical Robotics Training}}: {{An Experimental Study}}},
  shorttitle = {Robotic {{Assistance-as-Needed}} for {{Enhanced Visuomotor Learning}} in {{Surgical Robotics Training}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Enayati, Nima and Okamura, Allison M. and Mariani, Andrea and Pellegrini, Edoardo and Coad, Margaret M. and Ferrigno, Giancarlo and De Momi, Elena},
  year = {2018},
  month = may,
  pages = {6631--6636},
  issn = {2577-087X},
  doi = {10.1109/ICRA.2018.8463168},
  abstract = {Hands-on training is an indispensable part of surgical practice. As the tools used in the operating room become more intricate, the demand for efficient training methods increases. This work proposes a robotic assistance-as-needed method for training with surgical teleoperated robots. The method adapts the intensity of the assistance according to the trainee's current and past performance while gradually increasing the level of control of the trainee as the training progresses. The work includes an experiment comprising 160 acquisition sessions from 16 novice subjects performing a bimanual teleoperated exercise with a da Vinci Research Kit surgical console. Results capture the subtleties in the task's learning curve with and without robotic assistance and hint at the potential of robotic assistance for complex visuomotor training. Although robotic assistance for motor learning has received mixed results that range from beneficial to detrimental effects, this study shows such assistance may increase the rate of learning of certain skills in complex motor tasks.},
  keywords = {Robot kinematics,Surgery,Task analysis,Tools,Training,Wires}
}

@incollection{faure2012SOFAMultiModel,
  title = {{{SOFA}}: {{A Multi-Model Framework}} for {{Interactive Physical Simulation}}},
  shorttitle = {{{SOFA}}},
  booktitle = {Soft {{Tissue Biomechanical Modeling}} for {{Computer Assisted Surgery}}},
  author = {Faure, Fran{\c c}ois and Duriez, Christian and Delingette, Herv{\'e} and Allard, J{\'e}r{\'e}mie and Gilles, Benjamin and Marchesseau, St{\'e}phanie and Talbot, Hugo and Courtecuisse, Hadrien and Bousquet, Guillaume and Peterlik, Igor and Cotin, St{\'e}phane},
  editor = {Payan, Yohan},
  year = {2012},
  volume = {11},
  pages = {283--321},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/8415_2012_125},
  isbn = {978-3-642-29013-8 978-3-642-29014-5},
  langid = {english}
}

@inproceedings{fontanelli2018VREPSimulator,
  title = {A {{V-REP Simulator}} for the Da {{Vinci Research Kit Robotic Platform}}},
  booktitle = {2018 7th {{IEEE International Conference}} on {{Biomedical Robotics}} and {{Biomechatronics}} ({{Biorob}})},
  author = {Fontanelli, G. A. and Selvaggio, M. and Ferro, M. and Ficuciello, F. and Vendittelli, M. and Siciliano, B.},
  year = {2018},
  month = aug,
  pages = {1056--1061},
  issn = {2155-1782},
  doi = {10.1109/BIOROB.2018.8487187},
  abstract = {In this work we present a V-REP simulator for the da Vinci Research Kit (dVRK). The simulator contains a full robot kinematic model and integrated sensors. A robot operating system (ROS) interface has been created for easy use and development of common software components. Moreover, several scenes have been implemented to illustrate the performance and potentiality of the developed simulator. Both the simulator and the example scenes are available to the community as an open source software.},
  keywords = {Electronic countermeasures,Kinematics,Manipulators,Robot sensing systems,Solid modeling,Surgery}
}

@article{francish1964ParticleincellComputing,
  title = {The Particle-in-Cell Computing Method for Fluid Dynamics},
  author = {Francis H, Harlow},
  year = {1964},
  journal = {Methods Comput. Phys.},
  volume = {3},
  pages = {319--343}
}

@article{hu2018MovingLeast,
  title = {A Moving Least Squares Material Point Method with Displacement Discontinuity and Two-Way Rigid Body Coupling},
  author = {Hu, Yuanming and Fang, Yu and Ge, Ziheng and Qu, Ziyin and Zhu, Yixin and Pradhana, Andre and Jiang, Chenfanfu},
  year = {2018},
  month = aug,
  journal = {ACM Transactions on Graphics},
  volume = {37},
  number = {4},
  pages = {1--14},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3197517.3201293},
  abstract = {In this paper, we introduce the Moving Least Squares Material Point Method (MLS-MPM). MLS-MPM naturally leads to the formulation of Affine Particle-In-Cell (APIC) [Jiang et al. 2015] and Polynomial Particle-In-Cell [Fu et al. 2017] in a way that is consistent with a Galerkin-style weak form discretization of the governing equations. Additionally, it enables a new stress divergence discretization that effortlessly allows all MPM simulations to run two times faster than before. We also develop a Compatible Particle-In-Cell (CPIC) algorithm on top of MLS-MPM. Utilizing a colored distance field representation and a novel compatibility condition for particles and grid nodes, our framework enables the simulation of various new phenomena that are not previously supported by MPM, including material cutting, dynamic open boundaries, and two-way coupling with rigid bodies. MLS-MPM with CPIC is easy to implement and friendly to performance optimization.},
  langid = {english}
}

@article{jiang2015AffineParticleincell,
  title = {The Affine Particle-in-Cell Method},
  author = {Jiang, Chenfanfu and Schroeder, Craig and Selle, Andrew and Teran, Joseph and Stomakhin, Alexey},
  year = {2015},
  month = jul,
  journal = {ACM Transactions on Graphics},
  volume = {34},
  number = {4},
  pages = {1--10},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/2766996},
  abstract = {Hybrid Lagrangian/Eulerian simulation is commonplace in computer graphics for fluids and other materials undergoing large deformation. In these methods, particles are used to resolve transport and topological change, while a background Eulerian grid is used for computing mechanical forces and collision responses. Particle-in-Cell (PIC) techniques, particularly the Fluid Implicit Particle (FLIP) variants have become the norm in computer graphics calculations. While these approaches have proven very powerful, they do suffer from some well known limitations. The original PIC is stable, but highly dissipative, while FLIP, designed to remove this dissipation, is more noisy and at times, unstable. We present a novel technique designed to retain the stability of the original PIC, without suffering from the noise and instability of FLIP. Our primary observation is that the dissipation in the original PIC results from a loss of information when transferring between grid and particle representations. We prevent this loss of information by augmenting each particle with a locally affine, rather than locally constant, description of the velocity. We show that this not only stably removes the dissipation of PIC, but that it also allows for exact conservation of angular momentum across the transfers between particles and grid.},
  langid = {english}
}

@inproceedings{kazanzides2014OpensourceResearch,
  title = {An Open-Source Research Kit for the Da {{Vinci}}{\textregistered} {{Surgical System}}},
  booktitle = {2014 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Kazanzides, Peter and Chen, Zihan and Deguet, Anton and Fischer, Gregory S. and Taylor, Russell H. and DiMaio, Simon P.},
  year = {2014},
  month = may,
  pages = {6434--6439},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2014.6907809},
  abstract = {We present a telerobotics research platform that provides complete access to all levels of control via open-source electronics and software. The electronics employs an FPGA to enable a centralized computation and distributed I/O architecture in which all control computations are implemented in a familiar development environment (Linux PC) and low-latency I/O is performed over an IEEE-1394a (FireWire) bus at speeds up to 400 Mbits/sec. The mechanical components are obtained from retired first-generation da Vinci {\textregistered} Surgical Systems. This system is currently installed at 11 research institutions, with additional installations underway, thereby creating a research community around a common open-source hardware and software platform.},
  keywords = {Field programmable gate arrays,Hardware,Manipulators,Open source software,Real-time systems}
}

@article{leduc2003ModelingSuturing,
  title = {Toward {{Modeling}} of a {{Suturing Task}}},
  author = {LeDuc, Matt and Payandeh, Shahram and Dill, John},
  year = {2003},
  journal = {Graphics Interface},
  volume = {3},
  pages = {273--279},
  abstract = {In this paper we present our initial work on simulating suturing using mass-spring models. Various models for simulating a suture were studied, and a simple linear mass-spring model was determined to give good performance. A novel model for pulling a suture through a deformable tissue model is presented. By connecting two separate tissues together by way of the suture, our model can simulate a suturing task. The results are shown using software we developed that runs on a standard PC and models the action of two suturing devices commonly used in minimally invasive Laparoscopic surgery.},
  langid = {english}
}

@inproceedings{lewin2024PositionBased,
  title = {A {{Position Based Material Point Method}}},
  booktitle = {{{ACM SIGGRAPH}} 2024 {{Talks}}},
  author = {Lewin, Christopher},
  year = {2024},
  month = jul,
  pages = {1--2},
  publisher = {ACM},
  address = {Denver CO USA},
  doi = {10.1145/3641233.3664323},
  abstract = {The explicit Material Point Method (MPM) is an easily implemented scheme for the simulation of a wide variety of different physical materials. However, explicit integration has well known stability issues. We have implemented a novel semi-implicit compliant constraint formulation of MPM that is stable at any time-step while remaining as easy to implement as an explicit integrator. We call this method Position Based MPM (PB-MPM). This work significantly improves the utility of MPM for real-time applications.},
  isbn = {979-8-4007-0515-1},
  langid = {english}
}

@inproceedings{liu2021RealtoSimRegistration,
  title = {Real-to-{{Sim Registration}} of {{Deformable Soft Tissue}} with {{Position-Based Dynamics}} for {{Surgical Robot Autonomy}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Liu, Fei and Li, Zihan and Han, Yunhai and Lu, Jingpei and Richter, Florian and Yip, Michael C.},
  year = {2021},
  month = may,
  pages = {12328--12334},
  publisher = {IEEE},
  address = {Xi'an, China},
  doi = {10.1109/ICRA48506.2021.9561177},
  abstract = {Autonomy in robotic surgery is very challenging in unstructured environments, especially when interacting with deformable soft tissues. The main difficulty is to generate model-based control methods that account for deformation dynamics during tissue manipulation. Previous works in visionbased perception can capture the geometric changes within the scene, however, model-based controllers integrated with dynamic properties, a more accurate and safe approach, has not been studied before. Considering the mechanic coupling between the robot and the environment, it is crucial to develop a registered, simulated dynamical model. In this work, we propose an online, continuous, real-to-sim registration method to bridge 3D visual perception with position-based dynamics (PBD) modeling of tissues. The PBD method is employed to simulate soft tissue dynamics as well as rigid tool interactions for model-based control. Meanwhile, a vision-based strategy is used to generate 3D reconstructed point cloud surfaces based on real-world manipulation, so as to register and update the simulation. To verify this real-to-sim approach, tissue experiments have been conducted on the da Vinci Research Kit. Our real-to-sim approach successfully reduces registration error online, which is especially important for safety during autonomous control. Moreover, it achieves higher accuracy in occluded areas than fusion-based reconstruction.},
  isbn = {978-1-7281-9077-8},
  langid = {english}
}

@inproceedings{macklin2016XPBDPositionbased,
  title = {{{XPBD}}: Position-Based Simulation of Compliant Constrained Dynamics},
  shorttitle = {{{XPBD}}},
  booktitle = {Proceedings of the 9th {{International Conference}} on {{Motion}} in {{Games}}},
  author = {Macklin, Miles and M{\"u}ller, Matthias and Chentanez, Nuttapong},
  year = {2016},
  month = oct,
  pages = {49--54},
  publisher = {ACM},
  address = {Burlingame California},
  doi = {10.1145/2994258.2994272},
  isbn = {978-1-4503-4592-7},
  langid = {english}
}

@article{muller2007PositionBaseda,
  title = {Position Based Dynamics},
  author = {M{\"u}ller, Matthias and Heidelberger, Bruno and Hennix, Marcus and Ratcliff, John},
  year = {2007},
  month = apr,
  journal = {Journal of Visual Communication and Image Representation},
  volume = {18},
  number = {2},
  pages = {109--118},
  issn = {10473203},
  doi = {10.1016/j.jvcir.2007.01.005},
  abstract = {The most popular approaches for the simulation of dynamic systems in computer graphics are force based. Internal and external forces are accumulated from which accelerations are computed based on Newton's second law of motion. A time integration method is then used to update the velocities and finally the positions of the object. A few simulation methods (most rigid body simulators) use impulse based dynamics and directly manipulate velocities. In this paper we present an approach which omits the velocity layer as well and immediately works on the positions. The main advantage of a position based approach is its controllability. Overshooting problems of explicit integration schemes in force based systems can be avoided. In addition, collision constraints can be handled easily and penetrations can be resolved completely by projecting points to valid locations. We have used the approach to build a real time cloth simulator which is part of a physics software library for games. This application demonstrates the strengths and benefits of the method. {\'O} 2007 Elsevier Inc. All rights reserved.},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english}
}

@inproceedings{munawar2019RealTimeDynamic,
  title = {A {{Real-Time Dynamic Simulator}} and an {{Associated Front-End Representation Format}} for {{Simulating Complex Robots}} and {{Environments}}},
  booktitle = {2019 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Munawar, Adnan and Wang, Yan and Gondokaryono, Radian and Fischer, Gregory S.},
  year = {2019},
  month = nov,
  pages = {1875--1882},
  issn = {2153-0866},
  doi = {10.1109/IROS40897.2019.8968568},
  abstract = {Robot Dynamic Simulators offer convenient implementation and testing of physical robots, thus accelerating research and development. While existing simulators support most real-world robots with serially linked kinematic and dynamic chains, they offer limited or conditional support for complex closed-loop robots. On the other hand, many of the underlying physics computation libraries that these simulators employ support closed-loop kinematic chains and redundant mechanisms. Such mechanisms are often utilized in surgical robots to achieve constrained motions (e.g., the remote center of motion (RCM)). To deal with such robots, we propose a new simulation framework based on a front-end description format and a robust real-time dynamic simulator. Although this study focuses on surgical robots, the proposed format and simulator are applicable to any type of robot. In this manuscript, we describe the philosophy and implementation of the front-end description format and demonstrate its performance and the simulator's capabilities using simulated models of real-world surgical robots.}
}

@article{munawar2022OpenSimulationa,
  title = {Open {{Simulation Environment}} for {{Learning}} and {{Practice}} of {{Robot-Assisted Surgical Suturing}}},
  author = {Munawar, Adnan and Wu, Jie Ying and Fischer, Gregory S. and Taylor, Russell H. and Kazanzides, Peter},
  year = {2022},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {2},
  pages = {3843--3850},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3146900},
  abstract = {Automation has the potential to improve the standard of care but is difficult to realize due to perceptual challenges, especially in soft-tissue surgery. Machine learning can provide solutions, but typically requires large amounts of training data, which is time-consuming to collect. Even with shared platforms, hardware differences can prevent effective sharing of data between institutions. This letter proposes a standardized simulation platform for training and testing algorithms to control surgical robotic systems, which is built upon an open-source simulator, the Asynchronous Multi-Body Framework (AMBF), to enable quick prototyping of different scenes. An illustrative example of a suturing task on a phantom is presented and has formed the basis of a challenge, released to the community. The top-level contribution is the open-source release of a dynamic simulation environment that enables realistic suturing on a phantom, but supporting contributions include its extendable architectural design and a series of algorithmic optimizations to achieve real-time control and collision detection, realistic behavior of the needle and suture, and generation of multi-modal ground-truth data, including labeled depth data. These capabilities enable simulation-based surgical training and support research in machine learning for surgical scene perception and autonomous action.},
  keywords = {Data models,Load modeling,Medical robots and systems,Open source software,Phantoms,Robots,simulation and animation,Surgery,Task analysis,telerobotics and teleoperation}
}

@inproceedings{ou2024RealisticSurgical,
  title = {A {{Realistic Surgical Simulator}} for {{Non-Rigid}} and {{Contact-Rich Manipulation}} in {{Surgeries}} with the Da {{Vinci Research Kit}}},
  booktitle = {2024 21st {{International Conference}} on {{Ubiquitous Robots}} ({{UR}})},
  author = {Ou, Yafei and Zargarzadeh, Sadra and Sedighi, Paniz and Tavakoli, Mahdi},
  year = {2024},
  month = jun,
  eprint = {2404.05888},
  primaryclass = {cs},
  pages = {64--70},
  doi = {10.1109/UR61395.2024.10597513},
  abstract = {Realistic real-time surgical simulators play an increasingly important role in surgical robotics research, such as surgical robot learning and automation, and surgical skills assessment. Although there are a number of existing surgical simulators for research, they generally lack the ability to simulate the diverse types of objects and contact-rich manipulation tasks typically present in surgeries, such as tissue cutting and blood suction. In this work, we introduce CRESSim, a realistic surgical simulator based on PhysX 5 for the da Vinci Research Kit (dVRK) that enables simulating various contact-rich surgical tasks involving different surgical instruments, soft tissue, and body fluids. The real-world dVRK console and the master tool manipulator (MTM) robots are incorporated into the system to allow for teleoperation through virtual reality (VR). To showcase the advantages and potentials of the simulator, we present three examples of surgical tasks, including tissue grasping and deformation, blood suction, and tissue cutting. These tasks are performed using the simulated surgical instruments, including the large needle driver, suction irrigator, and curved scissor, through VR-based teleoperation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics}
}

@article{phellan2021RealtimeBiomechanics,
  title = {Real-Time Biomechanics Using the Finite Element Method and Machine Learning: {{Review}} and Perspective},
  shorttitle = {Real-Time Biomechanics Using the Finite Element Method and Machine Learning},
  author = {Phellan, Renzo and Hachem, Bahe and Clin, Julien and {Mac-Thiong}, Jean-Marc and Duong, Luc},
  year = {2021},
  month = jan,
  journal = {Medical Physics},
  volume = {48},
  number = {1},
  pages = {7--18},
  issn = {0094-2405, 2473-4209},
  doi = {10.1002/mp.14602},
  abstract = {Purpose: The finite element method (FEM) is the preferred method to simulate phenomena in anatomical structures. However, purely FEM-based mechanical simulations require considerable time, limiting their use in clinical applications that require real-time responses, such as haptics simulators. Machine learning (ML) approaches have been proposed to help with the reduction of the required time. The present paper reviews cases where ML could help to generate faster simulations, without considerably affecting the performance results. Methods: This review details the ML approaches used, considering the anatomical structures involved, the data collection strategies, the selected ML algorithms, with corresponding features, the metrics used for validation, and the resulting time gains. Results: A total of 41 references were found. ML algorithms are mainly trained with FEM-based simulations, in 32 publications. The preferred ML approach is neural networks, including deep learning, in 35 publications. Tissue deformation is simulated in 18 applications, but other features are also considered. The average distance error and mean squared error are the most frequently used performance metrics, in 14 and 17 publications, respectively. The time gains were considerable, going from hours or minutes for purely FEM-based simulations to milliseconds, when using ML. Conclusions: ML algorithms can be used to accelerate FEM-based biomechanical simulations of anatomical structures, possibly reaching real-time responses. Fast and real-time simulations of anatomical structures, generated with ML algorithms, can help to reduce the time required by FEM-based simulations and accelerate their adoption in the clinical practice.},
  langid = {english}
}

@misc{richter2020OpenSourcedReinforcement,
  title = {Open-{{Sourced Reinforcement Learning Environments}} for {{Surgical Robotics}}},
  author = {Richter, Florian and Orosco, Ryan K. and Yip, Michael C.},
  year = {2020},
  month = jan,
  number = {arXiv:1903.02090},
  eprint = {1903.02090},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1903.02090},
  abstract = {Reinforcement Learning (RL) is a machine learning framework for artificially intelligent systems to solve a variety of complex problems. Recent years has seen a surge of successes solving challenging games and smaller domain problems, including simple though non-specific robotic manipulation and grasping tasks. Rapid successes in RL have come in part due to the strong collaborative effort by the RL community to work on common, open-sourced environment simulators such as OpenAI's Gym that allow for expedited development and valid comparisons between different, state-of-art strategies. In this paper, we aim to start the bridge between the RL and the surgical robotics communities by presenting the first open-sourced reinforcement learning environments for surgical robots, called dVRL[3]\{dVRL available at https://github.com/ucsdarclab/dVRL\}. Through the proposed RL environments, which are functionally equivalent to Gym, we show that it is easy to prototype and implement state-of-art RL algorithms on surgical robotics problems that aim to introduce autonomous robotic precision and accuracy to assisting, collaborative, or repetitive tasks during surgery. Learned policies are furthermore successfully transferable to a real robot. Finally, combining dVRL with the over 40+ international network of da Vinci Surgical Research Kits in active use at academic institutions, we see dVRL as enabling the broad surgical robotics community to fully leverage the newest strategies in reinforcement learning, and for reinforcement learning scientists with no knowledge of surgical robotics to test and develop new algorithms that can solve the real-world, high-impact challenges in autonomous surgery.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics}
}

@article{sadeghirad2011ConvectedParticle,
  title = {A Convected Particle Domain Interpolation Technique to Extend Applicability of the Material Point Method for Problems Involving Massive Deformations},
  author = {Sadeghirad, A. and Brannon, R. M. and Burghardt, J.},
  year = {2011},
  journal = {International Journal for Numerical Methods in Engineering},
  volume = {86},
  number = {12},
  pages = {1435--1456},
  issn = {1097-0207},
  doi = {10.1002/nme.3110},
  abstract = {A new algorithm is developed to improve the accuracy and efficiency of the material point method for problems involving extremely large tensile deformations and rotations. In the proposed procedure, particle domains are convected with the material motion more accurately than in the generalized interpolation material point method. This feature is crucial to eliminate instability in extension, which is a common shortcoming of most particle methods. Also, a novel alternative set of grid basis functions is proposed for efficiently calculating nodal force and consistent mass integrals on the grid. Specifically, by taking advantage of initially parallelogram-shaped particle domains, and treating the deformation gradient as constant over the particle domain, the convected particle domain is a reshaped parallelogram in the deformed configuration. Accordingly, an alternative grid basis function over the particle domain is constructed by a standard 4-node finite element interpolation on the parallelogram. Effectiveness of the proposed modifications is demonstrated using several large deformation solid mechanics problems. Copyright {\copyright} 2011 John Wiley \& Sons, Ltd.},
  copyright = {Copyright {\copyright} 2011 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {extension instability,large deformations,material point method,nodal integration,particle methods,verification}
}

@article{scheikl2023LapGymOpen,
  title = {{{LapGym}} - {{An Open Source Framework}} for {{Reinforcement Learning}} in {{Robot-Assisted Laparoscopic Surgery}}},
  author = {Scheikl, Paul Maria and Gyenes, Bal{\'a}zs and Younis, Rayan and Haas, Christoph and Neumann, Gerhard and Wagner, Martin and {Mathis-Ullrich}, Franziska},
  year = {2023},
  journal = {Journal of Machine Learning Research},
  volume = {24},
  number = {368},
  pages = {1--42},
  issn = {1533-7928},
  abstract = {Recent advances in reinforcement learning (RL) have increased the promise of introducing cognitive assistance and automation to robot-assisted laparoscopic surgery (RALS). However, progress in algorithms and methods depends on the availability of standardized learning environments that represent skills relevant to RALS. We present LapGym, a framework for building RL environments for RALS that models the challenges posed by surgical tasks, and sofaenv, a diverse suite of 12 environments. Motivated by surgical training, these environments are organized into 4 tracks: Spatial Reasoning, Deformable Object Manipulation \& Grasping, Dissection, and Thread Manipulation. Each environment is highly parametrizable for increasing difficulty, resulting in a high performance ceiling for new algorithms. We use Proximal Policy Optimization (PPO) to establish a baseline for model-free RL algorithms, investigating the effect of several environment parameters on task difficulty. Finally, we show that many environments and parameter configurations reflect well-known, open problems in RL research, allowing researchers to continue exploring these fundamental problems in a surgical context. We aim to provide a challenging, standard environment suite for further development of RL for RALS, ultimately helping to realize the full potential of cognitive surgical robotics. LapGym is publicly accessible through GitHub (https://github.com/ScheiklP/lap\_gym).}
}

@inproceedings{schmidgall2024SurgicalGym,
  title = {Surgical {{Gym}}: {{A}} High-Performance {{GPU-based}} Platform for Reinforcement Learning with Surgical Robots},
  shorttitle = {Surgical {{Gym}}},
  booktitle = {2024 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Schmidgall, Samuel and Krieger, Axel and Eshraghian, Jason},
  year = {2024},
  month = may,
  pages = {13354--13361},
  doi = {10.1109/ICRA57147.2024.10610448},
  abstract = {Recent advances in robot-assisted surgery have resulted in progressively more precise, efficient, and minimally invasive procedures, sparking a new era of robotic surgical intervention. This enables doctors, in collaborative interaction with robots, to perform traditional or minimally invasive surgeries with improved outcomes through smaller incisions. Recent efforts are working toward making robotic surgery more autonomous which has the potential to reduce variability of surgical outcomes and reduce complication rates. Deep reinforcement learning methodologies offer scalable solutions for surgical automation, but their effectiveness relies on extensive data acquisition due to the absence of prior knowledge in successfully accomplishing tasks. Due to the intensive nature of simulated data collection, previous works have focused on making existing algorithms more efficient. In this work, we focus on making the simulator more efficient, making training data much more accessible than previously possible. We introduce Surgical Gym, an open-source high performance platform for surgical robot learning where both the physics simulation and reinforcement learning occur directly on the GPU. We demonstrate between 100-5000{\texttimes} faster training times compared with previous surgical learning platforms. The code is available at: https://github.com/SamuelSchmidgall/SurgicalGym.},
  keywords = {Hardware,Medical robotics,Minimally invasive surgery,PD control,Torque,Training,Training data}
}

@article{stomakhin2013MaterialPoint,
  title = {A Material Point Method for Snow Simulation},
  author = {Stomakhin, Alexey and Schroeder, Craig and Chai, Lawrence and Teran, Joseph and Selle, Andrew},
  year = {2013},
  month = jul,
  journal = {ACM Transactions on Graphics},
  volume = {32},
  number = {4},
  pages = {1--10},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/2461912.2461948},
  abstract = {Snow is a challenging natural phenomenon to visually simulate. While the graphics community has previously considered accumulation and rendering of snow, animation of snow dynamics has not been fully addressed. Additionally, existing techniques for solids and fluids have difficulty producing convincing snow results. Specifically, wet or dense snow that has both solid- and fluid-like properties is difficult to handle. Consequently, this paper presents a novel snow simulation method utilizing a usercontrollable elasto-plastic constitutive model integrated with a hybrid Eulerian/Lagrangian Material Point Method. The method is continuum based and its hybrid nature allows us to use a regular Cartesian grid to automate treatment of self-collision and fracture. It also naturally allows us to derive a grid-based semi-implicit integration scheme that has conditioning independent of the number of Lagrangian particles. We demonstrate the power of our method with a variety of snow phenomena including complex character interactions.},
  langid = {english}
}

@article{sulsky1995Applicationa,
  title = {Application of a Particle-in-Cell Method to Solid Mechanics},
  author = {Sulsky, Deborah and Zhou, Shi-Jian and Schreyer, Howard L.},
  year = {1995},
  month = may,
  journal = {Computer Physics Communications},
  volume = {87},
  number = {1-2},
  pages = {236--252},
  issn = {00104655},
  doi = {10.1016/0010-4655(94)00170-7},
  abstract = {An extension to solid mechanics of the FLIP particle-in-cell method is presented. The particle-in-cell method uses two representations of the continuum, one based on a collection of material points and the other based on a computational grid. The material points are followed throughout the deformation of a sofid and provide a Lagrangian description that is not subject to mesh tangling. This feature permits constitutive equations with history-dependent variables to be applied at these material points with no requirement for mapping the history parameters from one point to another. A grid, which can be held fixed or adapted as the need arises, is used to determine spatial gradients. Since the grid is used as an updated Lagrangian frame, the nonlinear convection term associated with Eulerian formulations does not appear. With the use of maps between material points and the grid, the advantages of both Eulerian and Lagrangian schemes are utilized. No-slip impact between bodies, inelastic, elastic, or rigid, is handled automatically by the method without resorting to a special contact algorithm.},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english}
}

@inproceedings{tagliabue2020SoftTissue,
  title = {Soft {{Tissue Simulation Environment}} to {{Learn Manipulation Tasks}} in {{Autonomous Robotic Surgery}}},
  booktitle = {2020 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Tagliabue, Eleonora and Pore, Ameya and Dall'Alba, Diego and Magnabosco, Enrico and Piccinelli, Marco and Fiorini, Paolo},
  year = {2020},
  month = oct,
  pages = {3261--3266},
  issn = {2153-0866},
  doi = {10.1109/IROS45743.2020.9341710},
  abstract = {Reinforcement Learning (RL) methods have demonstrated promising results for the automation of subtasks in surgical robotic systems. Since many trial and error attempts are required to learn the optimal control policy, RL agent training can be performed in simulation and the learned behavior can be then deployed in real environments. In this work, we introduce an open-source simulation environment providing support for position based dynamics soft bodies simulation and state-of-the-art RL methods. We demonstrate the capabilities of the proposed framework by training an RL agent based on Proximal Policy Optimization in fat tissue manipulation for tumor exposure during a nephrectomy procedure. Leveraging on a preliminary optimization of the simulation parameters, we show that our agent is able to learn the task on a virtual replica of the anatomical environment. The learned behavior is robust to changes in the initial end-effector position. Furthermore, we show that the learned policy can be directly deployed on the da Vinci Research Kit, which is able to execute the trajectories generated by the RL agent. The proposed simulation environment represents an essential component for the development of next-generation robotic systems, where the interaction with the deformable anatomical environment is involved.},
  keywords = {Biological tissues,Fats,Optimization,RL,Task analysis,Tissue,Training,Tumors,Visualization}
}

@inproceedings{varier2022AMBFRLRealtime,
  title = {{{AMBF-RL}}: {{A}} Real-Time Simulation Based {{Reinforcement Learning}} Toolkit for {{Medical Robotics}}},
  shorttitle = {{{AMBF-RL}}},
  booktitle = {2022 {{International Symposium}} on {{Medical Robotics}} ({{ISMR}})},
  author = {Varier, Vignesh Manoj and Rajamani, Dhruv Kool and Tavakkolmoghaddam, Farid and Munawar, Adnan and Fischer, Gregory S},
  year = {2022},
  month = apr,
  pages = {1--8},
  issn = {2771-9049},
  doi = {10.1109/ISMR48347.2022.9807609},
  abstract = {Recently, Reinforcement Learning (RL) techniques have seen significant progress in the robotics domain. This can be attributed to robust simulation frameworks that offer realistic environments to train. However, there is a lack of platforms which offer environments that are conducive to medical robotic tasks. Having earlier designed the Asynchronous Multibody Framework (AMBF) - a real-time dynamics simulator well-suited for medical robotics tasks, we propose an open source AMBF-RL (ARL) toolkit to assist in designing control algorithms for these robots, as well as a module to collect and parse expert demonstration data. We validate ARL by attempting to partially automate the task of debris removal on the da Vinci Research Kit (dVRK) Patient Side Manipulator (PSM) in simulation by calculating the optimal policy using both Deep Deterministic Policy Gradient (DDPG) and Hindsight Experience Replay (HER) with DDPG. The trained policies are successfully transferred onto the physical dVRK PSM and tested. Finally, we draw a conclusion from the results and discuss our observations of the experiments conducted.},
  keywords = {Heuristic algorithms,Manipulators,Medical robotics,Real-time systems,Reinforcement learning,Task analysis}
}

@inproceedings{xu2021SurRoLOpensource,
  title = {{{SurRoL}}: {{An Open-source Reinforcement Learning Centered}} and {{dVRK Compatible Platform}} for {{Surgical Robot Learning}}},
  shorttitle = {{{SurRoL}}},
  booktitle = {2021 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Xu, Jiaqi and Li, Bin and Lu, Bo and Liu, Yun-Hui and Dou, Qi and Heng, Pheng-Ann},
  year = {2021},
  month = sep,
  pages = {1821--1828},
  publisher = {IEEE},
  address = {Prague, Czech Republic},
  doi = {10.1109/IROS51168.2021.9635867},
  abstract = {Autonomous surgical execution relieves tedious routines and surgeon's fatigue. Recent learning-based methods, especially reinforcement learning (RL) based methods, achieve promising performance for dexterous manipulation, which usually requires the simulation to collect data efficiently and reduce the hardware cost. The existing learning-based simulation platforms for medical robots suffer from limited scenarios and simplified physical interactions, which degrades the real-world performance of learned policies. In this work, we designed SurRoL, an RL-centered simulation platform for surgical robot learning compatible with the da Vinci Research Kit (dVRK). The designed SurRoL integrates a user-friendly RL library for algorithm development and a real-time physics engine, which is able to support more PSM/ECM scenarios and more realistic physical interactions. Ten learning-based surgical tasks are built in the platform, which are common in the real autonomous surgical execution. We evaluate SurRoL using RL algorithms in simulation, provide in-depth analysis, deploy the trained policies on the real dVRK, and show that our SurRoL achieves better transferability in the real world.},
  isbn = {978-1-6654-1714-3},
  langid = {english}
}

@inproceedings{yu2024OrbitSurgicalOpenSimulationa,
  title = {Orbit-{{Surgical}}: {{An Open-Simulation Framework}} for {{Learning Surgical Augmented Dexterity}}},
  shorttitle = {Orbit-{{Surgical}}},
  booktitle = {2024 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Yu, Qinxi and Moghani, Masoud and Dharmarajan, Karthik and Schorp, Vincent and Panitch, William Chung-Ho and Liu, Jingzhou and Hari, Kush and Huang, Huang and Mittal, Mayank and Goldberg, Ken and Garg, Animesh},
  year = {2024},
  month = may,
  pages = {15509--15516},
  doi = {10.1109/ICRA57147.2024.10611637},
  abstract = {Physics-based simulations have accelerated progress in robot learning for driving, manipulation, and locomotion. Yet, a fast, accurate, and robust surgical simulation environment remains a challenge. In this paper, we present Orbit-Surgical, a physics-based surgical robot simulation framework with photorealistic rendering in NVIDIA Omniverse. We provide 14 benchmark surgical tasks for the da Vinci Research Kit (dVRK) and Smart Tissue Autonomous Robot (STAR) which represent common subtasks in surgical training. Orbit-Surgical leverages GPU parallelization to train reinforcement learning and imitation learning algorithms to facilitate study of robot learning to augment human surgical skills. Orbit-Surgical also facilitates realistic synthetic data generation for active perception tasks. We demonstrate Orbit-Surgical sim-to-real transfer of learned policies onto a physical dVRK robot.Project website: orbit-surgical.github.io},
  keywords = {Imitation learning,Medical robotics,Orbits,Reinforcement learning,Rendering (computer graphics),Stars,Training}
}

@article{ou2024LearningAutonomous,
  title={Learning autonomous surgical irrigation and suction with the Da Vinci Research Kit using reinforcement learning},
  author={Ou, Yafei and Tavakoli, Mahdi},
  journal={arXiv preprint arXiv:2411.14622},
  year={2024}
}

@article{zargarzadeh2025FromDecision,
  title={From Decision to Action in Surgical Autonomy: Multi-Modal Large Language Models for Robot-Assisted Blood Suction}, 
  author={Zargarzadeh, Sadra and Mirzaei, Maryam and Ou, Yafei and Tavakoli, Mahdi},
  journal={IEEE Robotics and Automation Letters}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  doi={10.1109/LRA.2025.3535184}
}

@article{kim2024surgical,
  title={Surgical robot transformer (srt): Imitation learning for surgical tasks},
  author={Kim, Ji Woong and Zhao, Tony Z and Schmidgall, Samuel and Deguet, Anton and Kobilarov, Marin and Finn, Chelsea and Krieger, Axel},
  journal={arXiv preprint arXiv:2407.12998},
  year={2024}
}

@article{bendikas2023learning,
  title={Learning Needle Pick-And-Place without expert demonstrations},
  author={Bendikas, Rokas and Modugno, Valerio and Kanoulas, Dimitrios and Vasconcelos, Francisco and Stoyanov, Danail},
  journal={IEEE Robotics and Automation Letters},
  year={2023},
  publisher={IEEE}
}

@inproceedings{chiu2021bimanual,
  title={Bimanual regrasping for suture needles using reinforcement learning for rapid motion planning},
  author={Chiu, Zih-Yun and Richter, Florian and Funk, Emily K and Orosco, Ryan K and Yip, Michael C},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7737--7743},
  year={2021},
  organization={IEEE}
}

@article{yang2024efficient,
  title={Efficient Physically-based Simulation of Soft Bodies in Embodied Environment for Surgical Robot},
  author={Yang, Zhenya and Long, Yonghao and Chen, Kai and Wei, Wang and Dou, Qi},
  journal={arXiv preprint arXiv:2402.01181},
  year={2024}
}