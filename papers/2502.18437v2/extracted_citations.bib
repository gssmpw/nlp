@article{bardenhagen1970GeneralizedInterpolation,
  title = {The {{Generalized Interpolation Material Point Method}}},
  author = {Bardenhagen, S. G. and Kober, E. M.},
  year = {2004},
  journal = {Computer Modeling in Engineering \& Sciences},
  volume = {5},
  number = {6},
  pages = {477--496},
  publisher = {Tech Science Press},
  issn = {1526-1492, 1526-1506},
  doi = {10.3970/cmes.2004.005.477},
  abstract = {The Material Point Method (MPM) discrete solution procedure for computational solid mechanics is generalized using a variational form and a Petrov--Galerkin discretization scheme, resulting in a family of methods named the G... {\textbar} Find, read and cite all the research you need on Tech Science Press},
  langid = {english}
}

@article{brackbill1986FLIPMethod,
  title = {{{FLIP}}: {{A}} Method for Adaptively Zoned, Particle-in-Cell Calculations of Fluid Flows in Two Dimensions},
  shorttitle = {{{FLIP}}},
  author = {Brackbill, J.U. and Ruppel, H.M.},
  year = {1986},
  month = aug,
  journal = {Journal of Computational Physics},
  volume = {65},
  number = {2},
  pages = {314--343},
  issn = {00219991},
  doi = {10.1016/0021-9991(86)90211-1},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english}
}

@inproceedings{dallalba2024FFSRLHigh,
  title = {{{FF-SRL}}: {{High Performance GPU-Based Surgical Simulation For Robot Learning}}},
  shorttitle = {{{FF-SRL}}},
  booktitle = {2024 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Dall'Alba, Diego and Naskr{\k e}t, Micha{\l} and Kami{\'n}ska, Sabina and Korzeniowski, Przemys{\l}aw},
  year = {2024},
  month = oct,
  pages = {8378--8384},
  issn = {2153-0866},
  doi = {10.1109/IROS58592.2024.10801658},
  abstract = {Robotic surgery is a rapidly developing field that can greatly benefit from the automation of surgical tasks. However, training techniques such as Reinforcement Learning (RL) require a high number of task repetitions, which are generally unsafe and impractical to perform on real surgical systems. This stresses the need for simulated surgical environments, which are not only realistic, but also computationally efficient and scalable. We introduce FF-SRL (Fast and Flexible Surgical Reinforcement Learning), a high-performance learning environment for robotic surgery. In FF-SRL both physics simulation and RL policy training reside entirely on a single GPU. This avoids typical bottlenecks associated with data transfer between the CPU and GPU, leading to accelerated learning rates. Our results show that FF-SRL reduces the training time of a complex tissue manipulation task by an order of magnitude, down to a couple of minutes, compared to a common CPU/GPU simulator. Such speed-up may facilitate the experimentation with RL techniques and contribute to the development of new generation of surgical systems. To this end, we make our code publicly available to the community.},
  keywords = {Codes,Graphics processing units,Intelligent robots,Physics,Reinforcement learning,Robot learning,Scalability,Stress,Surgery,Training}
}

@inproceedings{enayati2018RoboticAssistanceasNeeded,
  title = {Robotic {{Assistance-as-Needed}} for {{Enhanced Visuomotor Learning}} in {{Surgical Robotics Training}}: {{An Experimental Study}}},
  shorttitle = {Robotic {{Assistance-as-Needed}} for {{Enhanced Visuomotor Learning}} in {{Surgical Robotics Training}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Enayati, Nima and Okamura, Allison M. and Mariani, Andrea and Pellegrini, Edoardo and Coad, Margaret M. and Ferrigno, Giancarlo and De Momi, Elena},
  year = {2018},
  month = may,
  pages = {6631--6636},
  issn = {2577-087X},
  doi = {10.1109/ICRA.2018.8463168},
  abstract = {Hands-on training is an indispensable part of surgical practice. As the tools used in the operating room become more intricate, the demand for efficient training methods increases. This work proposes a robotic assistance-as-needed method for training with surgical teleoperated robots. The method adapts the intensity of the assistance according to the trainee's current and past performance while gradually increasing the level of control of the trainee as the training progresses. The work includes an experiment comprising 160 acquisition sessions from 16 novice subjects performing a bimanual teleoperated exercise with a da Vinci Research Kit surgical console. Results capture the subtleties in the task's learning curve with and without robotic assistance and hint at the potential of robotic assistance for complex visuomotor training. Although robotic assistance for motor learning has received mixed results that range from beneficial to detrimental effects, this study shows such assistance may increase the rate of learning of certain skills in complex motor tasks.},
  keywords = {Robot kinematics,Surgery,Task analysis,Tools,Training,Wires}
}

@inproceedings{fontanelli2018VREPSimulator,
  title = {A {{V-REP Simulator}} for the Da {{Vinci Research Kit Robotic Platform}}},
  booktitle = {2018 7th {{IEEE International Conference}} on {{Biomedical Robotics}} and {{Biomechatronics}} ({{Biorob}})},
  author = {Fontanelli, G. A. and Selvaggio, M. and Ferro, M. and Ficuciello, F. and Vendittelli, M. and Siciliano, B.},
  year = {2018},
  month = aug,
  pages = {1056--1061},
  issn = {2155-1782},
  doi = {10.1109/BIOROB.2018.8487187},
  abstract = {In this work we present a V-REP simulator for the da Vinci Research Kit (dVRK). The simulator contains a full robot kinematic model and integrated sensors. A robot operating system (ROS) interface has been created for easy use and development of common software components. Moreover, several scenes have been implemented to illustrate the performance and potentiality of the developed simulator. Both the simulator and the example scenes are available to the community as an open source software.},
  keywords = {Electronic countermeasures,Kinematics,Manipulators,Robot sensing systems,Solid modeling,Surgery}
}

@article{francish1964ParticleincellComputing,
  title = {The Particle-in-Cell Computing Method for Fluid Dynamics},
  author = {Francis H, Harlow},
  year = {1964},
  journal = {Methods Comput. Phys.},
  volume = {3},
  pages = {319--343}
}

@article{hu2018MovingLeast,
  title = {A Moving Least Squares Material Point Method with Displacement Discontinuity and Two-Way Rigid Body Coupling},
  author = {Hu, Yuanming and Fang, Yu and Ge, Ziheng and Qu, Ziyin and Zhu, Yixin and Pradhana, Andre and Jiang, Chenfanfu},
  year = {2018},
  month = aug,
  journal = {ACM Transactions on Graphics},
  volume = {37},
  number = {4},
  pages = {1--14},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3197517.3201293},
  abstract = {In this paper, we introduce the Moving Least Squares Material Point Method (MLS-MPM). MLS-MPM naturally leads to the formulation of Affine Particle-In-Cell (APIC) [Jiang et al. 2015] and Polynomial Particle-In-Cell [Fu et al. 2017] in a way that is consistent with a Galerkin-style weak form discretization of the governing equations. Additionally, it enables a new stress divergence discretization that effortlessly allows all MPM simulations to run two times faster than before. We also develop a Compatible Particle-In-Cell (CPIC) algorithm on top of MLS-MPM. Utilizing a colored distance field representation and a novel compatibility condition for particles and grid nodes, our framework enables the simulation of various new phenomena that are not previously supported by MPM, including material cutting, dynamic open boundaries, and two-way coupling with rigid bodies. MLS-MPM with CPIC is easy to implement and friendly to performance optimization.},
  langid = {english}
}

@article{jiang2015AffineParticleincell,
  title = {The Affine Particle-in-Cell Method},
  author = {Jiang, Chenfanfu and Schroeder, Craig and Selle, Andrew and Teran, Joseph and Stomakhin, Alexey},
  year = {2015},
  month = jul,
  journal = {ACM Transactions on Graphics},
  volume = {34},
  number = {4},
  pages = {1--10},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/2766996},
  abstract = {Hybrid Lagrangian/Eulerian simulation is commonplace in computer graphics for fluids and other materials undergoing large deformation. In these methods, particles are used to resolve transport and topological change, while a background Eulerian grid is used for computing mechanical forces and collision responses. Particle-in-Cell (PIC) techniques, particularly the Fluid Implicit Particle (FLIP) variants have become the norm in computer graphics calculations. While these approaches have proven very powerful, they do suffer from some well known limitations. The original PIC is stable, but highly dissipative, while FLIP, designed to remove this dissipation, is more noisy and at times, unstable. We present a novel technique designed to retain the stability of the original PIC, without suffering from the noise and instability of FLIP. Our primary observation is that the dissipation in the original PIC results from a loss of information when transferring between grid and particle representations. We prevent this loss of information by augmenting each particle with a locally affine, rather than locally constant, description of the velocity. We show that this not only stably removes the dissipation of PIC, but that it also allows for exact conservation of angular momentum across the transfers between particles and grid.},
  langid = {english}
}

@inproceedings{lewin2024PositionBased,
  title = {A {{Position Based Material Point Method}}},
  booktitle = {{{ACM SIGGRAPH}} 2024 {{Talks}}},
  author = {Lewin, Christopher},
  year = {2024},
  month = jul,
  pages = {1--2},
  publisher = {ACM},
  address = {Denver CO USA},
  doi = {10.1145/3641233.3664323},
  abstract = {The explicit Material Point Method (MPM) is an easily implemented scheme for the simulation of a wide variety of different physical materials. However, explicit integration has well known stability issues. We have implemented a novel semi-implicit compliant constraint formulation of MPM that is stable at any time-step while remaining as easy to implement as an explicit integrator. We call this method Position Based MPM (PB-MPM). This work significantly improves the utility of MPM for real-time applications.},
  isbn = {979-8-4007-0515-1},
  langid = {english}
}

@inproceedings{liu2021RealtoSimRegistration,
  title = {Real-to-{{Sim Registration}} of {{Deformable Soft Tissue}} with {{Position-Based Dynamics}} for {{Surgical Robot Autonomy}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Liu, Fei and Li, Zihan and Han, Yunhai and Lu, Jingpei and Richter, Florian and Yip, Michael C.},
  year = {2021},
  month = may,
  pages = {12328--12334},
  publisher = {IEEE},
  address = {Xi'an, China},
  doi = {10.1109/ICRA48506.2021.9561177},
  abstract = {Autonomy in robotic surgery is very challenging in unstructured environments, especially when interacting with deformable soft tissues. The main difficulty is to generate model-based control methods that account for deformation dynamics during tissue manipulation. Previous works in visionbased perception can capture the geometric changes within the scene, however, model-based controllers integrated with dynamic properties, a more accurate and safe approach, has not been studied before. Considering the mechanic coupling between the robot and the environment, it is crucial to develop a registered, simulated dynamical model. In this work, we propose an online, continuous, real-to-sim registration method to bridge 3D visual perception with position-based dynamics (PBD) modeling of tissues. The PBD method is employed to simulate soft tissue dynamics as well as rigid tool interactions for model-based control. Meanwhile, a vision-based strategy is used to generate 3D reconstructed point cloud surfaces based on real-world manipulation, so as to register and update the simulation. To verify this real-to-sim approach, tissue experiments have been conducted on the da Vinci Research Kit. Our real-to-sim approach successfully reduces registration error online, which is especially important for safety during autonomous control. Moreover, it achieves higher accuracy in occluded areas than fusion-based reconstruction.},
  isbn = {978-1-7281-9077-8},
  langid = {english}
}

@inproceedings{macklin2016XPBDPositionbased,
  title = {{{XPBD}}: Position-Based Simulation of Compliant Constrained Dynamics},
  shorttitle = {{{XPBD}}},
  booktitle = {Proceedings of the 9th {{International Conference}} on {{Motion}} in {{Games}}},
  author = {Macklin, Miles and M{\"u}ller, Matthias and Chentanez, Nuttapong},
  year = {2016},
  month = oct,
  pages = {49--54},
  publisher = {ACM},
  address = {Burlingame California},
  doi = {10.1145/2994258.2994272},
  isbn = {978-1-4503-4592-7},
  langid = {english}
}

@article{muller2007PositionBaseda,
  title = {Position Based Dynamics},
  author = {M{\"u}ller, Matthias and Heidelberger, Bruno and Hennix, Marcus and Ratcliff, John},
  year = {2007},
  month = apr,
  journal = {Journal of Visual Communication and Image Representation},
  volume = {18},
  number = {2},
  pages = {109--118},
  issn = {10473203},
  doi = {10.1016/j.jvcir.2007.01.005},
  abstract = {The most popular approaches for the simulation of dynamic systems in computer graphics are force based. Internal and external forces are accumulated from which accelerations are computed based on Newton's second law of motion. A time integration method is then used to update the velocities and finally the positions of the object. A few simulation methods (most rigid body simulators) use impulse based dynamics and directly manipulate velocities. In this paper we present an approach which omits the velocity layer as well and immediately works on the positions. The main advantage of a position based approach is its controllability. Overshooting problems of explicit integration schemes in force based systems can be avoided. In addition, collision constraints can be handled easily and penetrations can be resolved completely by projecting points to valid locations. We have used the approach to build a real time cloth simulator which is part of a physics software library for games. This application demonstrates the strengths and benefits of the method. {\'O} 2007 Elsevier Inc. All rights reserved.},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english}
}

@inproceedings{munawar2019RealTimeDynamic,
  title = {A {{Real-Time Dynamic Simulator}} and an {{Associated Front-End Representation Format}} for {{Simulating Complex Robots}} and {{Environments}}},
  booktitle = {2019 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Munawar, Adnan and Wang, Yan and Gondokaryono, Radian and Fischer, Gregory S.},
  year = {2019},
  month = nov,
  pages = {1875--1882},
  issn = {2153-0866},
  doi = {10.1109/IROS40897.2019.8968568},
  abstract = {Robot Dynamic Simulators offer convenient implementation and testing of physical robots, thus accelerating research and development. While existing simulators support most real-world robots with serially linked kinematic and dynamic chains, they offer limited or conditional support for complex closed-loop robots. On the other hand, many of the underlying physics computation libraries that these simulators employ support closed-loop kinematic chains and redundant mechanisms. Such mechanisms are often utilized in surgical robots to achieve constrained motions (e.g., the remote center of motion (RCM)). To deal with such robots, we propose a new simulation framework based on a front-end description format and a robust real-time dynamic simulator. Although this study focuses on surgical robots, the proposed format and simulator are applicable to any type of robot. In this manuscript, we describe the philosophy and implementation of the front-end description format and demonstrate its performance and the simulator's capabilities using simulated models of real-world surgical robots.}
}

@misc{richter2020OpenSourcedReinforcement,
  title = {Open-{{Sourced Reinforcement Learning Environments}} for {{Surgical Robotics}}},
  author = {Richter, Florian and Orosco, Ryan K. and Yip, Michael C.},
  year = {2020},
  month = jan,
  number = {arXiv:1903.02090},
  eprint = {1903.02090},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1903.02090},
  abstract = {Reinforcement Learning (RL) is a machine learning framework for artificially intelligent systems to solve a variety of complex problems. Recent years has seen a surge of successes solving challenging games and smaller domain problems, including simple though non-specific robotic manipulation and grasping tasks. Rapid successes in RL have come in part due to the strong collaborative effort by the RL community to work on common, open-sourced environment simulators such as OpenAI's Gym that allow for expedited development and valid comparisons between different, state-of-art strategies. In this paper, we aim to start the bridge between the RL and the surgical robotics communities by presenting the first open-sourced reinforcement learning environments for surgical robots, called dVRL[3]\{dVRL available at https://github.com/ucsdarclab/dVRL\}. Through the proposed RL environments, which are functionally equivalent to Gym, we show that it is easy to prototype and implement state-of-art RL algorithms on surgical robotics problems that aim to introduce autonomous robotic precision and accuracy to assisting, collaborative, or repetitive tasks during surgery. Learned policies are furthermore successfully transferable to a real robot. Finally, combining dVRL with the over 40+ international network of da Vinci Surgical Research Kits in active use at academic institutions, we see dVRL as enabling the broad surgical robotics community to fully leverage the newest strategies in reinforcement learning, and for reinforcement learning scientists with no knowledge of surgical robotics to test and develop new algorithms that can solve the real-world, high-impact challenges in autonomous surgery.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics}
}

@article{sadeghirad2011ConvectedParticle,
  title = {A Convected Particle Domain Interpolation Technique to Extend Applicability of the Material Point Method for Problems Involving Massive Deformations},
  author = {Sadeghirad, A. and Brannon, R. M. and Burghardt, J.},
  year = {2011},
  journal = {International Journal for Numerical Methods in Engineering},
  volume = {86},
  number = {12},
  pages = {1435--1456},
  issn = {1097-0207},
  doi = {10.1002/nme.3110},
  abstract = {A new algorithm is developed to improve the accuracy and efficiency of the material point method for problems involving extremely large tensile deformations and rotations. In the proposed procedure, particle domains are convected with the material motion more accurately than in the generalized interpolation material point method. This feature is crucial to eliminate instability in extension, which is a common shortcoming of most particle methods. Also, a novel alternative set of grid basis functions is proposed for efficiently calculating nodal force and consistent mass integrals on the grid. Specifically, by taking advantage of initially parallelogram-shaped particle domains, and treating the deformation gradient as constant over the particle domain, the convected particle domain is a reshaped parallelogram in the deformed configuration. Accordingly, an alternative grid basis function over the particle domain is constructed by a standard 4-node finite element interpolation on the parallelogram. Effectiveness of the proposed modifications is demonstrated using several large deformation solid mechanics problems. Copyright {\copyright} 2011 John Wiley \& Sons, Ltd.},
  copyright = {Copyright {\copyright} 2011 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {extension instability,large deformations,material point method,nodal integration,particle methods,verification}
}

@article{scheikl2023LapGymOpen,
  title = {{{LapGym}} - {{An Open Source Framework}} for {{Reinforcement Learning}} in {{Robot-Assisted Laparoscopic Surgery}}},
  author = {Scheikl, Paul Maria and Gyenes, Bal{\'a}zs and Younis, Rayan and Haas, Christoph and Neumann, Gerhard and Wagner, Martin and {Mathis-Ullrich}, Franziska},
  year = {2023},
  journal = {Journal of Machine Learning Research},
  volume = {24},
  number = {368},
  pages = {1--42},
  issn = {1533-7928},
  abstract = {Recent advances in reinforcement learning (RL) have increased the promise of introducing cognitive assistance and automation to robot-assisted laparoscopic surgery (RALS). However, progress in algorithms and methods depends on the availability of standardized learning environments that represent skills relevant to RALS. We present LapGym, a framework for building RL environments for RALS that models the challenges posed by surgical tasks, and sofaenv, a diverse suite of 12 environments. Motivated by surgical training, these environments are organized into 4 tracks: Spatial Reasoning, Deformable Object Manipulation \& Grasping, Dissection, and Thread Manipulation. Each environment is highly parametrizable for increasing difficulty, resulting in a high performance ceiling for new algorithms. We use Proximal Policy Optimization (PPO) to establish a baseline for model-free RL algorithms, investigating the effect of several environment parameters on task difficulty. Finally, we show that many environments and parameter configurations reflect well-known, open problems in RL research, allowing researchers to continue exploring these fundamental problems in a surgical context. We aim to provide a challenging, standard environment suite for further development of RL for RALS, ultimately helping to realize the full potential of cognitive surgical robotics. LapGym is publicly accessible through GitHub (https://github.com/ScheiklP/lap\_gym).}
}

@inproceedings{schmidgall2024SurgicalGym,
  title = {Surgical {{Gym}}: {{A}} High-Performance {{GPU-based}} Platform for Reinforcement Learning with Surgical Robots},
  shorttitle = {Surgical {{Gym}}},
  booktitle = {2024 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Schmidgall, Samuel and Krieger, Axel and Eshraghian, Jason},
  year = {2024},
  month = may,
  pages = {13354--13361},
  doi = {10.1109/ICRA57147.2024.10610448},
  abstract = {Recent advances in robot-assisted surgery have resulted in progressively more precise, efficient, and minimally invasive procedures, sparking a new era of robotic surgical intervention. This enables doctors, in collaborative interaction with robots, to perform traditional or minimally invasive surgeries with improved outcomes through smaller incisions. Recent efforts are working toward making robotic surgery more autonomous which has the potential to reduce variability of surgical outcomes and reduce complication rates. Deep reinforcement learning methodologies offer scalable solutions for surgical automation, but their effectiveness relies on extensive data acquisition due to the absence of prior knowledge in successfully accomplishing tasks. Due to the intensive nature of simulated data collection, previous works have focused on making existing algorithms more efficient. In this work, we focus on making the simulator more efficient, making training data much more accessible than previously possible. We introduce Surgical Gym, an open-source high performance platform for surgical robot learning where both the physics simulation and reinforcement learning occur directly on the GPU. We demonstrate between 100-5000{\texttimes} faster training times compared with previous surgical learning platforms. The code is available at: https://github.com/SamuelSchmidgall/SurgicalGym.},
  keywords = {Hardware,Medical robotics,Minimally invasive surgery,PD control,Torque,Training,Training data}
}

@article{stomakhin2013MaterialPoint,
  title = {A Material Point Method for Snow Simulation},
  author = {Stomakhin, Alexey and Schroeder, Craig and Chai, Lawrence and Teran, Joseph and Selle, Andrew},
  year = {2013},
  month = jul,
  journal = {ACM Transactions on Graphics},
  volume = {32},
  number = {4},
  pages = {1--10},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/2461912.2461948},
  abstract = {Snow is a challenging natural phenomenon to visually simulate. While the graphics community has previously considered accumulation and rendering of snow, animation of snow dynamics has not been fully addressed. Additionally, existing techniques for solids and fluids have difficulty producing convincing snow results. Specifically, wet or dense snow that has both solid- and fluid-like properties is difficult to handle. Consequently, this paper presents a novel snow simulation method utilizing a usercontrollable elasto-plastic constitutive model integrated with a hybrid Eulerian/Lagrangian Material Point Method. The method is continuum based and its hybrid nature allows us to use a regular Cartesian grid to automate treatment of self-collision and fracture. It also naturally allows us to derive a grid-based semi-implicit integration scheme that has conditioning independent of the number of Lagrangian particles. We demonstrate the power of our method with a variety of snow phenomena including complex character interactions.},
  langid = {english}
}

@inproceedings{tagliabue2020SoftTissue,
  title = {Soft {{Tissue Simulation Environment}} to {{Learn Manipulation Tasks}} in {{Autonomous Robotic Surgery}}},
  booktitle = {2020 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Tagliabue, Eleonora and Pore, Ameya and Dall'Alba, Diego and Magnabosco, Enrico and Piccinelli, Marco and Fiorini, Paolo},
  year = {2020},
  month = oct,
  pages = {3261--3266},
  issn = {2153-0866},
  doi = {10.1109/IROS45743.2020.9341710},
  abstract = {Reinforcement Learning (RL) methods have demonstrated promising results for the automation of subtasks in surgical robotic systems. Since many trial and error attempts are required to learn the optimal control policy, RL agent training can be performed in simulation and the learned behavior can be then deployed in real environments. In this work, we introduce an open-source simulation environment providing support for position based dynamics soft bodies simulation and state-of-the-art RL methods. We demonstrate the capabilities of the proposed framework by training an RL agent based on Proximal Policy Optimization in fat tissue manipulation for tumor exposure during a nephrectomy procedure. Leveraging on a preliminary optimization of the simulation parameters, we show that our agent is able to learn the task on a virtual replica of the anatomical environment. The learned behavior is robust to changes in the initial end-effector position. Furthermore, we show that the learned policy can be directly deployed on the da Vinci Research Kit, which is able to execute the trajectories generated by the RL agent. The proposed simulation environment represents an essential component for the development of next-generation robotic systems, where the interaction with the deformable anatomical environment is involved.},
  keywords = {Biological tissues,Fats,Optimization,RL,Task analysis,Tissue,Training,Tumors,Visualization}
}

@inproceedings{varier2022AMBFRLRealtime,
  title = {{{AMBF-RL}}: {{A}} Real-Time Simulation Based {{Reinforcement Learning}} Toolkit for {{Medical Robotics}}},
  shorttitle = {{{AMBF-RL}}},
  booktitle = {2022 {{International Symposium}} on {{Medical Robotics}} ({{ISMR}})},
  author = {Varier, Vignesh Manoj and Rajamani, Dhruv Kool and Tavakkolmoghaddam, Farid and Munawar, Adnan and Fischer, Gregory S},
  year = {2022},
  month = apr,
  pages = {1--8},
  issn = {2771-9049},
  doi = {10.1109/ISMR48347.2022.9807609},
  abstract = {Recently, Reinforcement Learning (RL) techniques have seen significant progress in the robotics domain. This can be attributed to robust simulation frameworks that offer realistic environments to train. However, there is a lack of platforms which offer environments that are conducive to medical robotic tasks. Having earlier designed the Asynchronous Multibody Framework (AMBF) - a real-time dynamics simulator well-suited for medical robotics tasks, we propose an open source AMBF-RL (ARL) toolkit to assist in designing control algorithms for these robots, as well as a module to collect and parse expert demonstration data. We validate ARL by attempting to partially automate the task of debris removal on the da Vinci Research Kit (dVRK) Patient Side Manipulator (PSM) in simulation by calculating the optimal policy using both Deep Deterministic Policy Gradient (DDPG) and Hindsight Experience Replay (HER) with DDPG. The trained policies are successfully transferred onto the physical dVRK PSM and tested. Finally, we draw a conclusion from the results and discuss our observations of the experiments conducted.},
  keywords = {Heuristic algorithms,Manipulators,Medical robotics,Real-time systems,Reinforcement learning,Task analysis}
}

@inproceedings{xu2021SurRoLOpensource,
  title = {{{SurRoL}}: {{An Open-source Reinforcement Learning Centered}} and {{dVRK Compatible Platform}} for {{Surgical Robot Learning}}},
  shorttitle = {{{SurRoL}}},
  booktitle = {2021 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Xu, Jiaqi and Li, Bin and Lu, Bo and Liu, Yun-Hui and Dou, Qi and Heng, Pheng-Ann},
  year = {2021},
  month = sep,
  pages = {1821--1828},
  publisher = {IEEE},
  address = {Prague, Czech Republic},
  doi = {10.1109/IROS51168.2021.9635867},
  abstract = {Autonomous surgical execution relieves tedious routines and surgeon's fatigue. Recent learning-based methods, especially reinforcement learning (RL) based methods, achieve promising performance for dexterous manipulation, which usually requires the simulation to collect data efficiently and reduce the hardware cost. The existing learning-based simulation platforms for medical robots suffer from limited scenarios and simplified physical interactions, which degrades the real-world performance of learned policies. In this work, we designed SurRoL, an RL-centered simulation platform for surgical robot learning compatible with the da Vinci Research Kit (dVRK). The designed SurRoL integrates a user-friendly RL library for algorithm development and a real-time physics engine, which is able to support more PSM/ECM scenarios and more realistic physical interactions. Ten learning-based surgical tasks are built in the platform, which are common in the real autonomous surgical execution. We evaluate SurRoL using RL algorithms in simulation, provide in-depth analysis, deploy the trained policies on the real dVRK, and show that our SurRoL achieves better transferability in the real world.},
  isbn = {978-1-6654-1714-3},
  langid = {english}
}

@article{yang2024efficient,
  title={Efficient Physically-based Simulation of Soft Bodies in Embodied Environment for Surgical Robot},
  author={Yang, Zhenya and Long, Yonghao and Chen, Kai and Wei, Wang and Dou, Qi},
  journal={arXiv preprint arXiv:2402.01181},
  year={2024}
}

@inproceedings{yu2024OrbitSurgicalOpenSimulationa,
  title = {Orbit-{{Surgical}}: {{An Open-Simulation Framework}} for {{Learning Surgical Augmented Dexterity}}},
  shorttitle = {Orbit-{{Surgical}}},
  booktitle = {2024 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Yu, Qinxi and Moghani, Masoud and Dharmarajan, Karthik and Schorp, Vincent and Panitch, William Chung-Ho and Liu, Jingzhou and Hari, Kush and Huang, Huang and Mittal, Mayank and Goldberg, Ken and Garg, Animesh},
  year = {2024},
  month = may,
  pages = {15509--15516},
  doi = {10.1109/ICRA57147.2024.10611637},
  abstract = {Physics-based simulations have accelerated progress in robot learning for driving, manipulation, and locomotion. Yet, a fast, accurate, and robust surgical simulation environment remains a challenge. In this paper, we present Orbit-Surgical, a physics-based surgical robot simulation framework with photorealistic rendering in NVIDIA Omniverse. We provide 14 benchmark surgical tasks for the da Vinci Research Kit (dVRK) and Smart Tissue Autonomous Robot (STAR) which represent common subtasks in surgical training. Orbit-Surgical leverages GPU parallelization to train reinforcement learning and imitation learning algorithms to facilitate study of robot learning to augment human surgical skills. Orbit-Surgical also facilitates realistic synthetic data generation for active perception tasks. We demonstrate Orbit-Surgical sim-to-real transfer of learned policies onto a physical dVRK robot.Project website: orbit-surgical.github.io},
  keywords = {Imitation learning,Medical robotics,Orbits,Reinforcement learning,Rendering (computer graphics),Stars,Training}
}

