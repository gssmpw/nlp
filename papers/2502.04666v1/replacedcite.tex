\section{Related Work}
\label{sec:relatedwork}

This work falls within the field of Information Retrieval, specifically \textit{Health Information Retrieval}, with the aim of \textcolor{black}{providing} users \textcolor{black}{with} relevant and factually accurate health information. 

In the literature, there are various strategies that attempt to combat (health) misinformation, often addressing the problem as a \textit{binary classification task} (i.e., information versus misinformation).
The most popular methods %for identifying misinformation 
fall \textcolor{black}{mainly} into two categories: $(i)$ \textit{feature-based misinformation detection}, which involves training machine learning models on \textcolor{black}{distinct features extracted from the content (and related metadata) to be classified in terms of information/misinformation} ____, and $(ii)$ \textit{knowledge-based misinformation detection}, which involves gathering external knowledge to serve as corroborative evidence to validate the considered content ____. This can include processing knowledge graphs or specific document fragments to support or dispute \textit{claims}. \textcolor{black}{In this context, the task of \textit{claim detection} is fundamental to ensuring the success of the content verification process against available knowledge bases ____. Recently, there has also been an increasing focus on developing effective methods to place humans at the center of the misinformation identification process, \textcolor{black}{given the fact that automatic systems performing this task can still be subject to various forms of automation bias at different levels ____.}}

%\subsection{Consumer Health Search}

\textcolor{black}{Several of these approaches have been employed and tested within \textit{Information Retrieval Systems} (IRSs)\textcolor{black}{—a.k.a. search engines—}in recent years, also in relation to health to perform the task of \textit{Consumer Health Search} (CHS). CHS refers to the process of seeking health-related information by general consumers, typically through online search engines ____. This encompasses a wide range of queries, from symptoms and treatments of illnesses to general health advice, diet, and wellness information. Unlike professional health search, which is conducted by healthcare providers using specialized databases and resources, CHS is performed by non-experts who may have varying levels of health literacy. The CLEF eHealth Lab Series,\footnote{\url{https://clefehealth.imag.fr/}} part of the \textit{Conference and Labs of the Evaluation Forum} (CLEF),\footnote{\url{http://clef-initiative.eu/}} has played a pivotal role in advancing research CHS. The goal of the initiative is to provide the research community with sophisticated datasets of clinical narratives, enriched with links to evidence-based care guidelines, systematic reviews, and other further information, to design ranking models considering multiple relevance dimensions such as \textit{topicality}, \textit{readability}, and \textit{credibility}, when retrieving documents w.r.t. user queries ____.} \textcolor{black}{The TREC \textit{Heath Misinformation Track} \textcolor{black}{is an another initiative that specifically addresses the challenges of misinformation in health search.\footnote{\url{https://trec-health-misinfo.github.io/}} In particular, the goal of its \textit{ad-hoc retrieval} sub-task is to allow researchers working in the field} ``to design a ranking model that promotes \textit{credible} and \textit{correct} information over incorrect information'' ____.}

\textcolor{black}{%Over the last years, s}everal research works have been submitted to both of these evaluation initiatives that seek to consider the veracity of information (or strictly-related concepts) in the retrieval process.  The CLEF models showcased diverse approaches: The team from the University of Padua
Among the recent research works submitted at CLEF,} in \textcolor{black}{____ the authors evaluate \textit{Reciprocal Ranking Fusion} (RRF) ____ over different query variants, different retrieval functions, w/out
pseudo-relevance feedback, for both \textit{ad-hoc} and \textit{spoken queries retrieval} tasks, aiming to refine the relevance and readability of the retrieved information. The work proposed in ____ focuses on query expansion for \textit{ad-hoc retrieval} using the \textit{Unified Medical Language System} (UMLS)\footnote{\url{https://www.nlm.nih.gov/research/umls/index.html}} and the \textit{FastText} embedding model,\footnote{\url{https://fasttext.cc/}} putting a strong emphasis on enhancing terminological comprehensiveness. In ____, the proposed solution utilizes TF-IDF scoring complemented by medical skip-gram word embeddings to experiment with different vector representations for textual data, aiming to optimize document-query similarity calculations. Concerning TREC submissions, %showcase a diverse array of innovative IR strategies, each aimed at enhancing the accuracy and credibility of retrieved data in response to complex health-related queries. M
models proposed by the CiTIUS Lab ____ and DigiLab ____ utilize BM25 as the basic IR model for ranking, complemented by sophisticated \textit{re-ranking} techniques employing RoBERTa and a combination of Transformer-based models to account for information credibility. Additionally, the works described in ____ and ____ leverage advanced \textit{Natural Language Processing} (NLP) tools including Bio-SBERT ____ and T5 ____ models to refine search results, focusing on semantic similarity and the stance of documents.} Although these solutions have included formal semantic representations of texts that are often based on the use of Transformers, none of these have so far considered the use of generative LLMs to support the process of identifying and considering misinformation in the context of search engines.

%\subsection{Retrieval-Augmented Generation for Misinformation/Fact-checking}
\textcolor{black}{Instead, some work is increasingly appearing that uses generative LLMs to try to identify misinformation as a binary classification task ____, or to answer users' questions directly, including health-related questions ____.}
\textcolor{black}{However, we are aware of the fact that} the knowledge \textcolor{black}{based on which such} LLMs \textcolor{black}{are trained is} commonly out-of-date____, and they also \textcolor{black}{risk to} generate factual inconsistent or hallucinated content, as previously introduced ____. To address these issues, current methodologies increasingly rely on \textit{Retrieval-Augmented Generation} (RAG) approaches ____. These approaches enhance LLM responses by integrating retrieved external data, thus conditioning the generation process to be more factual and contextually relevant. RAG models have achieved remarkable results in various tasks such as open-domain QA____, dialogue____, domain-specific question answering____, and code generation____. 
%
The LLM-Augmenter system presented in ____ incorporates external knowledge and automated feedback mechanisms through plug-and-play modules to refine LLM output. \textcolor{black}{The authors in} ____ introduce a factuality detection framework that evaluates the authenticity of LLM-generated content across various tasks and domains. \textcolor{black}{The work described in} ____ leverages in-context learning capabilities of LLMs, employing \textit{Chain-of-Thought} (CoT) reasoning to guide models through complex problem-solving sequences. \textcolor{black}{In} ____, a \textit{Hierarchical Step-by-Step} (HiSS) prompting methodology \textcolor{black}{is proposed}, which systematically breaks down a claim into manageable sub-claims. This method sequentially verifies each sub-claim using question-answering techniques, relying on Web-retrieved evidence to ensure the factual integrity of responses. Concurrently, ____ emphasizes the necessity for generating sophisticated justifications for fact-checking claims, proposing a novel approach that focuses on the retrieval of evidence to support or refute claims rather than mere summarization.

Recently, \textcolor{black}{despite} a series of retrieval-enhanced tools and products have gained widespread attention, such as the ChatGPT retrieval plugin,\footnote{\url{https://github.com/openai/chatgpt-retrieval-plugin}} %Langchain,\footnote{\url{https://www.langchain.com/}} 
New Bing,\footnote{\url{https://www.bing.com/}} etc., \textcolor{black}{the technical details of these approaches are proprietary, nor is it publicly available how they effectively address the issue of hallucinations and other disadvantages related to the lack of factual accuracy. This is particularly concerning in the context of health misinformation, which is our primary focus of investigation. Therefore, we propose the solution illustrated in the following section.}