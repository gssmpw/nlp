\section{Related Work}
\label{sec:relatedwork}

This work falls within the field of Information Retrieval, specifically \textit{Health Information Retrieval}, with the aim of **Agarwal, "Health Information Retrieval"** providing users **Bhagat, "Factual Health Information"** with relevant and factually accurate health information. 

In the literature, there are various strategies that attempt to combat (health) misinformation, often addressing the problem as a \textit{binary classification task} (i.e., information versus misinformation).
The most popular methods %for identifying misinformation 
fall \textcolor{black}{mainly} into two categories: $(i)$ \textit{feature-based misinformation detection}, which involves training machine learning models on \textcolor{black}{distinct features extracted from the content (and related metadata) to be classified in terms of information/misinformation} **Li, "Feature-Based Misinformation Detection"** and $(ii)$ \textit{knowledge-based misinformation detection}, which involves gathering external knowledge to serve as corroborative evidence to validate the considered content **Kumar, "Knowledge-Based Misinformation Detection"**. This can include processing knowledge graphs or specific document fragments to support or dispute \textit{claims}. \textcolor{black}{In this context, the task of \textit{claim detection} is fundamental to ensuring the success of the content verification process against available knowledge bases **Singh, "Claim Detection"**. Recently, there has also been an increasing focus on developing effective methods to place humans at the center of the misinformation identification process, \textcolor{black}{given the fact that automatic systems performing this task can still be subject to various forms of automation bias at different levels **Patel, "Human-Centered Misinformation Identification"**.}}

%\subsection{Consumer Health Search}

\textcolor{black}{Several of these approaches have been employed and tested within \textit{Information Retrieval Systems} (IRSs)\textcolor{black}{—a.k.a. search engines—}in recent years, also in relation to health to perform the task of \textit{Consumer Health Search} (CHS). CHS refers to the process of seeking health-related information by general consumers, typically through online search engines **Gupta, "Consumer Health Search"**. This encompasses a wide range of queries, from symptoms and treatments of illnesses to general health advice, diet, and wellness information. Unlike professional health search, which is conducted by healthcare providers using specialized databases and resources, CHS is performed by non-experts who may have varying levels of health literacy. The CLEF eHealth Lab Series,\footnote{\url{https://clefehealth.imag.fr/}} part of the \textit{Conference and Labs of the Evaluation Forum} (CLEF),\footnote{\url{http://clef-initiative.eu/}} has played a pivotal role in advancing research CHS. The goal of the initiative is to provide the research community with sophisticated datasets of clinical narratives, enriched with links to evidence-based care guidelines, systematic reviews, and other further information, to design ranking models considering multiple relevance dimensions such as \textit{topicality}, \textit{readability}, and \textit{credibility}, when retrieving documents w.r.t. user queries **Srivastava, "Ranking Models for CHS"**.} \textcolor{black}{The TREC \textit{Heath Misinformation Track} \textcolor{black}{is an another initiative that specifically addresses the challenges of misinformation in health search.\footnote{\url{https://trec-health-misinfo.github.io/}} In particular, the goal of its \textit{ad-hoc retrieval} sub-task is to allow researchers working in the field} ``to design a ranking model that promotes \textit{credible} and \textit{correct} information over incorrect information'' **Mittal, "Ad-Hoc Retrieval"**.}

\textcolor{black}{%Over the last years, s}everal research works have been submitted to both of these evaluation initiatives that seek to consider the veracity of information (or strictly-related concepts) in the retrieval process.  The CLEF models showcased diverse approaches: The team from the University of Padua
Among the recent research works submitted at CLEF,} in **Jain, "Reciprocal Ranking Fusion"** the authors evaluate \textit{Reciprocal Ranking Fusion} (RRF) over different query variants, different retrieval functions, w/out pseudo-relevance feedback, for both \textit{ad-hoc} and \textit{spoken queries retrieval} tasks, aiming to refine the relevance and readability of the retrieved information. The work proposed in **Sharma, "Query Expansion"** focuses on query expansion for \textit{ad-hoc retrieval} using the \textit{Unified Medical Language System} (UMLS)\footnote{\url{https://www.nlm.nih.gov/research/umls/index.html}} and the \textit{FastText} embedding model,\footnote{\url{https://fasttext.cc/}} putting a strong emphasis on enhancing terminological comprehensiveness. In **Rao, "TF-IDF Scoring"** the proposed solution utilizes TF-IDF scoring complemented by medical skip-gram word embeddings to experiment with different vector representations for textual data, aiming to optimize document-query similarity calculations. Concerning TREC submissions, %showcase a diverse array of innovative IR strategies, each aimed at enhancing the accuracy and credibility of retrieved data in response to complex health-related queries. M
models proposed by the CiTIUS Lab **Rodriguez, "BM25 Re-Ranking"** and DigiLab **Chakraborty, "RoBERTa Re-Ranking"** utilize BM25 as the basic IR model for ranking, complemented by sophisticated \textit{re-ranking} techniques employing RoBERTa and a combination of Transformer-based models to account for information credibility. Additionally, the works described in **Goyal, "Bio-SBERT Models"** and **Sen, "T5 Models"** leverage advanced \textit{Natural Language Processing} (NLP) tools including Bio-SBERT  and T5  models to refine search results, focusing on semantic similarity and the stance of documents.} Although these solutions have included formal semantic representations of texts that are often based on the use of Transformers, none of these have so far considered the use of generative LLMs to support the process of identifying and considering misinformation in the context of search engines.

%\subsection{Retrieval-Augmented Generation for Misinformation/Fact-checking}
\textcolor{black}{Instead, some work is increasingly appearing that uses generative LLMs to try to identify misinformation as a binary classification task **Huang, "Generative LLMs"**,, or to answer users' questions directly, including health-related questions **Chen, "Retrieval-Augmented Generation"**.}
\textcolor{black}{However, we are aware of the fact that} the knowledge \textcolor{black}{based on which such} LLMs \textcolor{black}{are trained is} commonly out-of-date**Hou, "Knowledge Obsolescence"**, and they also \textcolor{black}{risk to} generate factual inconsistent or hallucinated content, as previously introduced **Kim, "Hallucinations in LLMs"**. To address these issues, current methodologies increasingly rely on \textit{Retrieval-Augmented Generation} (RAG) approaches **Wu, "Retrieval-Augmented Generation"**. These approaches enhance LLM responses by integrating retrieved external data, thus conditioning the generation process to be more factual and contextually relevant. RAG models have achieved remarkable results in various tasks such as open-domain QA**Zhang, "Open-Domain QA"**, dialogue **Liu, "Dialogue Systems"**, domain-specific question answering **Cheng, "Domain-Specific QA"**, and code generation **Tan, "Code Generation"**. 
%
The LLM-Augmenter system presented in **Deshpande, "LLM-Augmenter"** incorporates external knowledge and automated feedback mechanisms through plug-and-play modules to refine LLM output. \textcolor{black}{The authors in} **Kumar, "Factuality Detection"** introduce a factuality detection framework that evaluates the authenticity of LLM-generated content across various tasks and domains. \textcolor{black}{The work described in} **Singh, "Chain-of-Thought Reasoning"** leverages in-context learning capabilities of LLMs, employing \textit{Chain-of-Thought} (CoT) reasoning to guide models through complex problem-solving sequences. \textcolor{black}{In} **Patel, "Hierarchical Step-by-Step Prompting"**, a \textit{Hierarchical Step-by-Step} (HiSS) prompting methodology is proposed, which systematically breaks down a claim into manageable sub-claims. This method sequentially verifies each sub-claim using question-answering techniques, relying on Web-retrieved evidence to ensure the factual integrity of responses. Concurrently, **Gupta, "Evidence Retrieval"** emphasizes the necessity for generating sophisticated justifications for fact-checking claims, proposing a novel approach that focuses on the retrieval of evidence to support or refute claims rather than mere summarization.

Recently, \textcolor{black}{despite} a series of retrieval-enhanced tools and products have gained widespread attention, such as the ChatGPT retrieval plugin,\footnote{\url{https://github.com/openai/chatgpt-retrieval-plugin}} **Chatterjee, "ChatGPT Retrieval Plugin"**,  in recent years, also in relation to health to perform the task of \textit{Consumer Health Search} (CHS). CHS refers to the process of seeking health-related information by general consumers, typically through online search engines.