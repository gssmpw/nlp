\section{Related Work}
% \subsection{Toxicity Dataset} 
% Toxicity detection has been extensively studied in various contexts, particularly in social media and speech content, often interchangeably referred to as hate speech detection. Toxicity encompasses a range of harmful behaviors including being ``hateful," ``abusive," and ``cyberbullying"~\cite{cheng2022bias}. Two notable datasets include the Jigsaw and Instagram datasets. The Perspective APIâ€™s Jigsaw dataset~\footnote{\url{https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification}} comprises comments extracted from the Civil Comments platform, annotated for toxicity and identity-related biases. This dataset includes various subsets, addressing issues such as unintentional bias and multilingual annotations, making it a valuable resource for studying toxic behavior across different languages and contexts. 
% The Instagram dataset~\cite{hosseinmardi2015detection}, on the other hand, is derived from one of the most popular social networking sites where users frequently report experiences of cyberbullying. Each sample in this dataset represents a social media session composed of a sequence of comments in temporal order, providing insights into the dynamics of toxic interactions over time.
% In addition to these, the DeToxy dataset~\cite{ghosh2021detoxy} presents a large-scale multimodal collection specifically for toxicity classification in spoken utterances. This dataset expands the scope of toxicity detection beyond text-based content to include audio, highlighting the multimodal nature of online abuse. 
% \citet{bensalem2024toxic} integrates 54 Arabic datasets into a unified format, facilitating easier access and comprehensive analysis for toxic comment classification.
% Toxicity detection has also been explored within the gaming sector~\footnote{\url{https://www.databricks.com/blog/2021/06/16/solution-accelerator-toxicity-detection-in-gaming.html}}, where toxic behavior can significantly impact player experiences and community health. The multilingual context of toxicity detection has gained attention as well, with systematic reviews such as the one focusing on Arabic datasets, underscoring the need for culturally and linguistically diverse resources in this domain.
% These existing studies and datasets provide a robust foundation for the development of advanced toxicity detection models. However, the application of toxicity detection in the context of scientific paper reviews remains underexplored, indicating a clear gap that our research aims to address.
% \textcolor{red}{Devide the previous long paragraph into the following three topics and add more related works}

% \paragraph{Toxic Dataset.}

Toxicity detection has been mostly studied  in social media and speech content, often interchangeably referred to as hate speech detection. 
Toxicity encompasses a range of harmful behaviors including being ``hateful'', ``abusive'', and ``cyberbullying''~\cite{cheng2022bias}. 
Two notable datasets include the Jigsaw and Instagram datasets. 
Jigsaw dataset\footnote{\url{https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification}} comprises comments extracted from the Civil Comments platform, annotated for toxicity and identity-related biases. This dataset includes various subsets, addressing issues such as unintentional bias and multilingual annotations, making it a valuable resource for studying toxic behavior across different languages and contexts. 
The Instagram dataset~\cite{hosseinmardi2015detection}, on the other hand, is derived from one of the most popular social networking sites where users frequently report experiences of cyberbullying. Each sample in this dataset represents a social media session composed of a sequence of comments in temporal order, providing insights into the dynamics of toxic interactions over time. In addition to these, the DeToxy dataset~\cite{ghosh2021detoxy} presents a large-scale multimodal collection specifically for toxicity classification in spoken utterances. This dataset expands the scope of toxicity detection beyond text-based content to include audio, highlighting the multimodal nature of online abuse. \citet{bensalem2024toxic} integrates 54 Arabic datasets into a unified format, facilitating easier access and comprehensive analysis for toxic comment classification. 
Additionally, toxicity detection in the gaming sector~\footnote{\url{https://www.databricks.com/blog/2021/06/16/solution-accelerator-toxicity-detection-in-gaming.html}} has garnered attention due to the impact of toxic behavior on player experiences and community health. Despite these advances, the application of toxicity  in the context of scientific paper reviews remains underexplored, indicating a clear gap that our research aims to address.

% \paragraph{Toxic Detection.} 
% \textcolor{red}{Here, we do a recent survey on detecting toxic sentence.}

% \paragraph{Language Revision} 
% \textcolor{red}{Here, we do the recent survey on  rewriting a sentences (detoxified methods and if there is not many such works then style transfer method also belongs to rewriting.} 
% Understanding Iterative Revision from Human-Written Text~\citep{du2022understanding}. 

In contrast to the extensive work done on toxicity detection, toxicity revision, especially in the realm of scientific writing, is somewhat less-studied. Automated revision involving technical concepts is a particularly complex task, beyond the already-challenging task of re-writing for clarity or grammar alone. Jiang, Xu, and Stevens (2022) introduced the arXivEdits dataset, which documents human revisions in scientific papers, categorizing changes like content alterations, grammar corrections, and stylistic improvements. While this work sheds light on general revision practices, it does not specifically address toxic language in peer reviews. Our work aims to fill some of these gaps by investigating how LLMs can both detect and revise toxic language in scientific peer reviews.

% arXivEdits: Understanding the Human Revision Process in Scientific Writing~\citep{jiang2022arxivedits}.