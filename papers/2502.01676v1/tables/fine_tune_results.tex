\begin{table*}[t]
\centering
 \resizebox{0.98\linewidth}{!}{
\begin{tabular}{c|c|c|c|c|c|c|c|c}
    \toprule
    \multirow{2}{*}{\textbf{Models}}& \multicolumn{4}{c}{\textbf{LoRA Fine-tuning Performance}} & \multicolumn{4}{|c}{\textbf{Full Fine-tuning Performance}}\\
     \cmidrule(lr){2-5}
     & {\textbf{Precision}} &  {\textbf{Recall}}  & {\textbf{F1}} &  \textbf{Accuracy} \\ 
     \toprule
    % Zephyr-3B & 0.863& 0.861& 0.862& 0.894 \\
    Mistral-7B  &
    Llama3-8B  &  \\
    % DeBerta-v3+Random Forest & 0.831& 0.835& 0.831& 0.830 \\
    \bottomrule
    \end{tabular}
    }
    \vspace{3mm}
\caption{Fine-tune Performance of Different Models on Toxic Review Detection Task.}
\label{tab:detector_ft_result}
\end{table*}