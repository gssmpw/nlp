@article{busso2008iemocap,
  title={IEMOCAP: Interactive emotional dyadic motion capture database},
  author={Busso, Carlos and Bulut, Murtaza and Lee, Chi-Chun and Kazemzadeh, Abe and Mower, Emily and Kim, Samuel and Chang, Jeannette N and Lee, Sungbok and Narayanan, Shrikanth S},
  journal={Language resources and evaluation},
  volume={42},
  pages={335--359},
  year={2008},
  publisher={Springer}
}

@article{busso2016msp,
  title={MSP-IMPROV: An acted corpus of dyadic interactions to study emotion perception},
  author={Busso, Carlos and Parthasarathy, Srinivas and Burmania, Alec and AbdelWahab, Mohammed and Sadoughi, Najmeh and Provost, Emily Mower},
  journal={IEEE Transactions on Affective Computing},
  volume={8},
  number={1},
  pages={67--80},
  year={2016},
  publisher={IEEE}
}

@article{chen1802emotionlines,
  title={Emotionlines: An emotion corpus of multi-party conversations. arXiv 2018},
  author={Chen, SY and Hsu, CC and Kuo, CC and Ku, LW},
  journal={arXiv preprint arXiv:1802.08379},
  year={2018}
}

@inproceedings{chudasama2022m2fnet,
  title={M2fnet: Multi-modal fusion network for emotion recognition in conversation},
  author={Chudasama, Vishal and Kar, Purbayan and Gudmalwar, Ashish and Shah, Nirmesh and Wasnik, Pankaj and Onoe, Naoyuki},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4652--4661},
  year={2022}
}

@article{delbrouck2020transformer,
  title={A transformer-based joint-encoding for emotion recognition and sentiment analysis},
  author={Delbrouck, Jean-Benoit and Tits, No{\'e} and Brousmiche, Mathilde and Dupont, St{\'e}phane},
  journal={arXiv preprint arXiv:2006.15955},
  year={2020}
}

@article{fromcollecting,
  title={Collecting Large, Richly Annotated Facial-Expression Databases from Movies},
  author={Dhall, Abhinav and Goecke, Roland and Lucey, Simon and Gedoen, Tom},
  publisher={Citeseer},
  journal={IEEE Multimedia},
  pages={34--41},
  year={2012}
}

@article{fu2024ckerc,
  title={CKERC: Joint Large Language Models with Commonsense Knowledge for Emotion Recognition in Conversation},
  author={Fu, Yumeng},
  journal={arXiv preprint arXiv:2403.07260},
  year={2024}
}

@article{ghosal2019dialoguegcn,
  title={Dialoguegcn: A graph convolutional neural network for emotion recognition in conversation},
  author={Ghosal, Deepanway and Majumder, Navonil and Poria, Soujanya and Chhaya, Niyati and Gelbukh, Alexander},
  journal={arXiv preprint arXiv:1908.11540},
  year={2019}
}

@inproceedings{hazarika2018conversational,
  title={Conversational memory network for emotion recognition in dyadic dialogue videos},
  author={Hazarika, Devamanyu and Poria, Soujanya and Zadeh, Amir and Cambria, Erik and Morency, Louis-Philippe and Zimmermann, Roger},
  booktitle={Proceedings of the conference. Association for Computational Linguistics. North American Chapter. Meeting},
  volume={2018},
  pages={2122},
  year={2018},
  organization={NIH Public Access}
}

@article{hu2021mmgcn,
  title={MMGCN: Multimodal fusion via deep graph convolution network for emotion recognition in conversation},
  author={Hu, Jingwen and Liu, Yuchen and Zhao, Jinming and Jin, Qin},
  journal={arXiv preprint arXiv:2107.06779},
  year={2021}
}

@article{jiao2019higru,
  title={Higru: Hierarchical gated recurrent units for utterance-level emotion recognition},
  author={Jiao, Wenxiang and Yang, Haiqin and King, Irwin and Lyu, Michael R},
  journal={arXiv preprint arXiv:1904.04446},
  year={2019}
}

@article{kim2021emoberta,
  title={Emoberta: Speaker-aware emotion recognition in conversation with roberta},
  author={Kim, Taewoon and Vossen, Piek},
  journal={arXiv preprint arXiv:2108.12009},
  year={2021}
}

@article{lei2023instructerc,
  title={Instructerc: Reforming emotion recognition in conversation with a retrieval multi-task llms framework},
  author={Lei, Shanglin and Dong, Guanting and Wang, Xiaoping and Wang, Keheng and Wang, Sirui},
  journal={arXiv preprint arXiv:2309.11911},
  year={2023}
}

@article{li2017dailydialog,
  title={Dailydialog: A manually labelled multi-turn dialogue dataset},
  author={Li, Yanran and Su, Hui and Shen, Xiaoyu and Li, Wenjie and Cao, Ziqiang and Niu, Shuzi},
  journal={arXiv preprint arXiv:1710.03957},
  year={2017}
}

@inproceedings{li2018mec,
  title={Mec 2017: Multimodal emotion recognition challenge},
  author={Li, Ya and Tao, Jianhua and Schuller, Bj{\"o}rn and Shan, Shiguang and Jiang, Dongmei and Jia, Jia},
  booktitle={2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia)},
  pages={1--5},
  year={2018},
  organization={IEEE}
}

@article{majumder2019attentive,
  title={An attentive RNN for emotion detection in conversations},
  author={Majumder, N and Poria, S and Hazarika, D and Mihalcea, R and Gelbukh, A and DialogueRNN, E Cambria},
  journal={Association for the Advancement of Artificial Intelligence},
  pages={6818--6825},
  year={2019}
}

@inproceedings{poria2017context,
  title={Context-dependent sentiment analysis in user-generated videos},
  author={Poria, Soujanya and Cambria, Erik and Hazarika, Devamanyu and Majumder, Navonil and Zadeh, Amir and Morency, Louis-Philippe},
  booktitle={Proceedings of the 55th annual meeting of the association for computational linguistics (volume 1: Long papers)},
  pages={873--883},
  year={2017}
}

@article{poria2018meld,
  title={Meld: A multimodal multi-party dataset for emotion recognition in conversations},
  author={Poria, Soujanya and Hazarika, Devamanyu and Majumder, Navonil and Naik, Gautam and Cambria, Erik and Mihalcea, Rada},
  journal={arXiv preprint arXiv:1810.02508},
  year={2018}
}

@inproceedings{shen2021dialogxl,
  title={Dialogxl: All-in-one xlnet for multi-party conversation emotion recognition},
  author={Shen, Weizhou and Chen, Junqing and Quan, Xiaojun and Xie, Zhixian},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={15},
  pages={13789--13797},
  year={2021}
}

@inproceedings{tsai2019multimodal,
  title={Multimodal transformer for unaligned multimodal language sequences},
  author={Tsai, Yao-Hung Hubert and Bai, Shaojie and Liang, Paul Pu and Kolter, J Zico and Morency, Louis-Philippe and Salakhutdinov, Ruslan},
  booktitle={Proceedings of the conference. Association for computational linguistics. Meeting},
  volume={2019},
  pages={6558},
  year={2019},
  organization={NIH Public Access}
}

@inproceedings{wang2020contextualized,
  title={Contextualized emotion recognition in conversation as sequence tagging},
  author={Wang, Yan and Zhang, Jiayu and Ma, Jun and Wang, Shaojun and Xiao, Jing},
  booktitle={Proceedings of the 21th annual meeting of the special interest group on discourse and dialogue},
  pages={186--195},
  year={2020}
}

@article{wu2024beyond,
  title={Beyond silent letters: Amplifying llms in emotion recognition with vocal nuances},
  author={Wu, Zehui and Gong, Ziwei and Ai, Lin and Shi, Pengyuan and Donbekci, Kaan and Hirschberg, Julia},
  journal={arXiv preprint arXiv:2407.21315},
  year={2024}
}

@inproceedings{xue2024bioserc,
  title={BiosERC: Integrating Biography Speakers Supported by LLMs for ERC Tasks},
  author={Xue, Jieying and Nguyen, Minh-Phuong and Matheny, Blake and Nguyen, Le-Minh},
  booktitle={International Conference on Artificial Neural Networks},
  pages={277--292},
  year={2024}
}

@inproceedings{yu2020ch,
  title={Ch-sims: A chinese multimodal sentiment analysis dataset with fine-grained annotation of modality},
  author={Yu, Wenmeng and Xu, Hua and Meng, Fanyang and Zhu, Yilin and Ma, Yixiao and Wu, Jiele and Zou, Jiyun and Yang, Kaicheng},
  booktitle={Proceedings of the 58th annual meeting of the association for computational linguistics},
  pages={3718--3727},
  year={2020}
}

@inproceedings{zadeh2018multimodal,
  title={Multimodal language analysis in the wild: Cmu-mosei dataset and interpretable dynamic fusion graph},
  author={Zadeh, AmirAli Bagher and Liang, Paul Pu and Poria, Soujanya and Cambria, Erik and Morency, Louis-Philippe},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={2236--2246},
  year={2018}
}

@inproceedings{zahiri2018emotion,
  title={Emotion detection on tv show transcripts with sequence-based convolutional neural networks},
  author={Zahiri, Sayyed M and Choi, Jinho D},
  booktitle={Workshops at the thirty-second aaai conference on artificial intelligence},
  year={2018}
}

@inproceedings{zhang2019modeling,
  title={Modeling both Context-and Speaker-Sensitive Dependence for Emotion Detection in Multi-speaker Conversations.},
  author={Zhang, Dong and Wu, Liangqing and Sun, Changlong and Li, Shoushan and Zhu, Qiaoming and Zhou, Guodong},
  booktitle={IJCAI},
  pages={5415--5421},
  year={2019},
  organization={Macao}
}

@article{zhang2023dialoguellm,
  title={Dialoguellm: Context and emotion knowledge-tuned llama models for emotion recognition in conversations},
  author={Zhang, Yazhou and Wang, Mengyao and Tiwari, Prayag and Li, Qiuchi and Wang, Benyou and Qin, Jing},
  journal={arXiv preprint arXiv:2310.11374},
  year={2023}
}

@article{zhao2022m3ed,
  title={M3ED: Multi-modal multi-scene multi-label emotional dialogue database},
  author={Zhao, Jinming and Zhang, Tenggan and Hu, Jingwen and Liu, Yuchen and Jin, Qin and Wang, Xinchao and Li, Haizhou},
  journal={arXiv preprint arXiv:2205.10237},
  year={2022}
}

@article{zhong2019knowledge,
  title={Knowledge-enriched transformer for emotion detection in textual conversations},
  author={Zhong, Peixiang and Wang, Di and Miao, Chunyan},
  journal={arXiv preprint arXiv:1909.10681},
  year={2019}
}

