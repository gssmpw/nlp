\section{Related work}
\label{section2}
In this section, we describe existing research directions relevant to our research based on traditional spectral-spatial feature extraction, as well as those based on deep learning, along with mainstream generative tasks and development context of DDPMs. Through a comprehensive review of related research, our aim is to establish a strong foundation for our proposed method, solidify our contribution, and apply it effectively in complex HSIC research.

\subsection{HSI classification based on supervised learning}

Traditional feature extraction approaches developed on statistical computations and linear algebra methods along with the canonical machine learning methods \cite{Prasad2008_TGRS, science2000_LLE, DU2003_PR}, which ignore the spatial relationships between each spectral pixels. Although researchers have proposed various methods which take spatial structure and texture information into consideration, e.g., the morphological profiles (MPs) \cite{Benediktsson2005_TGRS}, extended morphological profiles (EMPs) \cite{Plaza2005_TGRS_EMPS}, gray-level co-occurrence matrix (GLCM) \cite{Tsai2013_TGRS}, markov random field (MRF) \cite{Sun2015_TGRS}, invariant attribute profiles (IAPs) \cite{Hong2020_TGRS}. However, the above methods are criticized due to that the extracted shallow features lack representativeness, and the design of the hyperparameters are konwledge-driven.

During the last decade, the deep learning (DL) based methods have flourished in HSIC, many progressive DL-based data-driven networks have been widely utilized for supervised HSIC methods in an end-to-end manner, providing automatic feature learning from data \cite{chen_DBN2015_JSTARS, Li2019_TGRS, Audebert2019_TGRSM, Rasti2020_MGRS}, e.g., deep belief networks (DBNs) \cite{chen_DBN2015_JSTARS}. Particularly, HSIC benifits from CNNs-based models due to the ability to extract locally spatial contextual information and spectral variability information \cite{2DCNN, Zhong2017_IGRSS, Roy2020_LGRS}. Specifically, since the 3D convolution (3DCONV) can simultaneously investigate spectral-spatial relationships \cite{Hamida3dCNN, HybridSN}. For instance, Zhong et al. presented a spectral-spatial residual network (SSRN) \cite{SSRN}, which investigates the 3D spatial-spectral features by skip-connections to ensure the generalization ability. Furthermore, Tang et al. \cite{Tang2021_TGRS} factorized the mixed feature maps by their low and high-frequency information using a 3D Octave convolution model to realize the interaction of spectral-spatial information. However, these 3DCONV methods contain huge model parameters which require a large number of training samples \cite{Fu2023_TGRS}. Additionally, many researches from a sequential perspective with transformers \cite{Hongdf2022_TGRS, Ibañez2022_TGRS, SSTN} to design network for alleviating the deficiency of CNNs on mining and representing the sequence attributes of spectral signatures. For instance, Sun et al. \cite{SSFTT} constructed a spatial–spectral feature tokenization transformer (SSFTT) to capture spatial–spectral features and high-level semantic features. However, these works lack consideration of significant differences, such as the size and the number of basic elements between NLP and HSI. They still face quadratic computation complexities \cite{Liu2021_ICCV_Swin}, hence limited to modeling complex relations. According to \cite{park2022how}, their capture of long-range dependencies even hinders network optimization. 

\subsection{HSI classification based on unsupervised learning}

\subsubsection{\textbf{AE-based model}}
Unsupervised Feature extraction methods do not need labeled data and are not restricted to specific prerequisites. Typically, autoencoder (AE) is a common unsupervised framework. Kemker et al. \cite{Kemker2017_TGRS} proposed stacked convolutional autoencoder (SCAE) to identify deeper features and yielded the superior performance. \cite{Masci2011, Du2017_TCYB} used several autoencoders to learn a hierarchical feature representation, resulting in more discriminative features. The fully connected operators in AE were replaced by convolutional operators, so that the network can directly extract spectral–spatial joint features from cubes. Even so, they often involve complex training processes, which also needs numerous labeled samples in the classification stage.

\subsubsection{\textbf{GAN-based model}}
As a novel unsupervised classification scheme, the GANs have also been employed for HSIC. For instance, Zhan et al. \cite{Zhan2018_LGRS} developed a framework for HSIC using a 1-D GAN for HSIC (HSGAN) using discriminator features. Zhang et al. \cite{Zhangmy2019_TGRS} designed a deconvolutional generator and a 2-D CNN discriminator to learn spectral-spatial relationships of data sets and extract spatial-spectral features, respectively. Hang et al. \cite{Hangrl2020_TGRS} proposed a multitask generative adversarial network (MTGAN) which was consist of a generator network for hyperspectral imagery reconstruction and classification, and a discriminator network to discriminate between the real and fake (generated) data. Although GANs are powerful to energize unsupervised HSI classifiers, they always encounter the failures of model collapse and non-convergence. 

\subsection{Development of Denoising Diffusion Probabilistic Models}
DDPMs \cite{ho2020DDPM} have emerged as the new state-of-the-art family of deep generative models and have broken the long-time dominance of GANs, which has achieved great success in the field of natural image generation, natural language processing, temporal data modeling, multi-modal modeling. DDPMs are a family of probabilistic generative models that progressively destruct data by injecting noise, then reverse the former by learning transition kernels parameterized by deep neural networks. DDPMs are trained by optimizing the variational lower bound of the negative log-likelihood of the data, and it avoids mode collapse often encountered by GANs. Because of slow sample generation speed of DDPM, \cite{DDIM} presented denoising diffusion implicit models (DDIM), a class of non-Markovian diffusion processes, whose reverse process can be 10$\times$ to 50$\times$ faster than DDPMs. Dmitry et al. \cite{baranchuk2022labelefficient} demonstrated that the pretrained conditional DDPM can be served as a feature extractor for discriminative computer vision problems. To train a Neural Radiance Fields (NeRFs) with only a samll views, \cite{yang2023learning} found that unconditional diffusion prior can be treated as guidance for 3D generation and rendering. Furthermore, DDPMs have been successful on high-level semantic understanding tasks, i.e., image super resolution, natural and medical segmentation, classification. Although DDPMs have been widely applied to the community of natural image generation, and a small quantity on remote sensing fake sample generation \cite{Yuanzq2023_TGRS}, synthetic aperture radar despeckling \cite{Perera2023SARDDPM}, remote sensing change detection \cite{bandara2022ddpmcd}, seldom on the field of HSIC. Hence, the critical research question is how to adpat the latent feature representations of DDPMs for discriminative HSIC tasks, under the help of construction of raw HSI data distribution. Considering the theoretical advantages of DDPMs, some researchers have used DDPMs for HSIC \cite{bandara2022ddpmcd, chen2023spectraldiff, zhou2023hyperspectral}. However, there are still a lack of research on spatial-spectral DDPMs that are tailor designed to HSI characteristics and challenges. For example, efficient selection of time steps in DDPM in an adaptive learnable manner for HSIC has not been addressed, given the critical importance of time step selection \cite{baranchuk2022labelefficient, bandara2022ddpmcd, chen2023spectraldiff, zhou2023hyperspectral}. In \cite{bandara2022ddpmcd, chen2023spectraldiff}, the time steps are manually selected to characterize spectral-spatial features, and \cite{zhou2023hyperspectral} uses all of time steps, which might lead to redundancy.