% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{acl}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{changes}
\usepackage{longtable}
\usepackage{tabularx}
% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsfonts}
\usepackage{listings}
% Standard package includes

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.
\newcommand{\xb}[1]{\textcolor{red}{[XBX: #1]}}
\newcommand{\bv}[1]{\textit{\textbf{#1}}}
\newcommand{\TT}{\textsf{T}}
\newcommand{\din}{d_\text{in}}
\newcommand{\dout}{d_\text{out}}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}

\newcommand{\method}{{TATA}}
\newcommand{\danchor}{{$\mathcal{D}_{\text{anchor}}$}}
\newcommand{\dsft}{{$\mathcal{D}_{\text{SFT}}$}}
%\newcommand{\dsfte}{$\mathcal{D}_{\text{SFT}} = {\{(x_i, l_i^k) \}_{i=1}^{N}}_{k=1}^{K_i}$}
\newcommand{\dorig}{{$\mathcal{D}_{\text{orig}}$}}
\newcommand{\dorige}{{$\mathcal{D}_{\text{orig}} = \{(x_i, y_i) \}_{i=1}^N$}}
\newcommand{\danchore}{{$\mathcal{D}_{\text{anchor}} = \{(q_i, a_i) \}_{i=1}^A$}}
\newcommand{\dauge}{{$\mathcal{D}_{\text{aug}} = {\{(x_i, y_i^j)\}_{i=1}^N}_{j=1}^{M_i}$}}
\newcommand{\dde}{{$\mathcal{D} = {\{(x_i, y_i^j, z_i^j)\}_{i=1}^N}_{j=1}^{M_i}$}}
\newcommand{\dd}{{$\mathcal{D}$}}
\newcommand{\daug}{{$\mathcal{D}_{\text{aug}}$}}
\newcommand{\dcandidate}{{$\mathcal{D}^*$}}
\newcommand{\dcandidatee}{{$\mathcal{D}^* = {\{(x_i, y_i^*, z_i^*)\}_{i=1}^N}$}}
\newcommand{\scot}{$S_{\text{CoT}}$}
\newcommand{\scote}{${S_{\text{CoT}}^k}$}
\newcommand{\stir}{$S_{\text{TIR}}$}
\newcommand{\stire}{$S_{\text{TIR}}^k$}
%\newcommand{\dataset}[2]{(#1 from #2)}
\newcommand{\change}[1]{\textcolor{blue}{#1}}
\NewDocumentCommand{\mytodo}
{ mO{} }{\textcolor{blue}{\textsuperscript{\textit{todo}}\textsf{\textbf{\small[#1]}}}}
% Define colors for differences
\definecolor{positive}{rgb}{0,0.5,0} % Green for positive differences
\definecolor{negative}{rgb}{1,0,0}   % Red for negative differences
\title{Teaching LLMs According to Their Aptitude: Adaptive Reasoning for Mathematical Problem Solving}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

%\author{Xin Xu, Yan Xu\textsuperscript{\dag}, Tianhao Chen, Yuchen Yan, Chengwu Liu, Zaoyu Chen, \\ \textbf{Yufei Wang, Yichun Yin, Yasheng Wang, Lifeng Shang, Qun Liu}\\
%Hong Kong University of Science and Technology \\
% \texttt{xxuca@connect.ust.hk} \\
% \texttt{\{sdiaoaa, macyang, yangwang\}@ust.hk}
%}


%\author{First Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  \texttt{email@domain} \\\And
%  Second Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  \texttt{email@domain} \\}

\author{
  \textbf{Xin Xu\textsuperscript{1,2}$^*$},
  \textbf{Yan Xu\textsuperscript{1,2}},
  \textbf{Tianhao Chen\textsuperscript{1}},
\\
  \textbf{Yuchen Yan\textsuperscript{3}},
  \textbf{Chengwu Liu\textsuperscript{2,4}},
  \textbf{Zaoyu Chen\textsuperscript{2,5}},
  \textbf{Yufei Wang\textsuperscript{2}},
  \\
  \textbf{Yichun Yin\textsuperscript{2}},
  \textbf{Yasheng Wang\textsuperscript{2}},
  \textbf{Lifeng Shang\textsuperscript{2}},
  \textbf{Qun Liu\textsuperscript{2}},
 % \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
 % \textbf{Twelfth Author\textsuperscript{1}},
\\
  %\textbf{Thirteenth Author\textsuperscript{3}},
  %\textbf{Fourteenth F. Author\textsuperscript{2,4}},
  %\textbf{Fifteenth Author\textsuperscript{1}},
  %\textbf{Sixteenth Author\textsuperscript{1}},
%\\
  %\textbf{Seventeenth S. Author\textsuperscript{4,5}},
  %\textbf{Eighteenth Author\textsuperscript{3,4}},
  %\textbf{Nineteenth N. Author\textsuperscript{2,5}},
  %\textbf{Twentieth Author\textsuperscript{1}}
\\
\\
  \textsuperscript{1}The Hong Kong University of Science and Technology,
  \textsuperscript{2}Huawei Noah’s Ark Lab,
\\
  \textsuperscript{3}Zhejiang University,
  \textsuperscript{4}Peking University, 
  \textsuperscript{5}The Hong Kong Polytechnic University
\\
  \small{
    \textbf{Correspondence:} \{xxuca, yxucb\}@connect.ust.hk
  }
}

\begin{document}
\maketitle
\renewcommand*{\thefootnote}{\fnsymbol{footnote}}
%\footnotetext{* Equal contribution.}
%\footnotetext{$\dagger$ Corresponding author.}
\renewcommand*{\thefootnote}{\arabic{footnote}}
\def\thefootnote{*}\footnotetext{Work done during the internship at Huawei Noah’s Ark Lab. Codes and data are available at \href{https://github.com/XinXU-USTC/TATA}{https://github.com/XinXU-USTC/TATA}.}
\begin{abstract}
    Existing approaches to mathematical reasoning with large language models (LLMs) rely on Chain-of-Thought (CoT) for generalizability or Tool-Integrated Reasoning (TIR) for precise computation. 
    While efforts have been made to combine these methods, they primarily rely on post-selection or predefined strategies, leaving an open question: 
    whether LLMs can autonomously adapt their reasoning strategies based on their inherent capabilities.
    % whether LLMs can autonomously select the most suitable reasoning paradigm based on their inherent capabilities.
    In this work, we propose \textbf{{\method}} (\textbf{T}eaching LLMs \textbf{A}ccording to \textbf{T}heir \textbf{A}ptitude), an adaptive framework that enables LLMs to personalize their reasoning strategy spontaneously, aligning it with their intrinsic aptitude. 
    {\method} incorporates base-LLM-aware data selection during supervised fine-tuning (SFT) to tailor training data to the model’s unique abilities. 
    This approach equips LLMs to autonomously determine and apply the appropriate reasoning strategy at test time.
    We evaluate {\method} through extensive experiments on six mathematical reasoning benchmarks, using both general-purpose and math-specialized LLMs. 
    Empirical results demonstrate that {\method} effectively combines the complementary strengths of CoT and TIR, achieving superior or comparable performance with improved inference efficiency compared to TIR alone. 
    Further analysis underscores the critical role of aptitude-aware data selection in enabling LLMs to make effective and adaptive reasoning decisions and align reasoning strategies with model capabilities.

\end{abstract}


\input{chapters/intro}
\input{chapters/preliminary}
\input{chapters/method}
\input{chapters/results}
\input{chapters/analysis}
\input{chapters/related_work}
\input{chapters/conclusion}

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom}
\clearpage
\appendix

\input{appendix/background}
\input{appendix/setup}
\input{appendix/more_results}

\end{document}
