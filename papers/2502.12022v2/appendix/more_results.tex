\section{More Fine-grained Results}\label{app:results}

\subsection{Main Results}\label{app:main_results}

The complete results of the main experiments are provided in Table~\ref{tab:full-results}. Besides the effectiveness of our proposed framework, the results also reveal distinct behaviors of CoT and TIR across different datasets, highlighting their complementary strengths. CoT excels on in-domain tasks like GSM8K, where step-by-step reasoning is crucial, achieving higher accuracy (e.g., 55.6\% for Qwen2.5-0.5B) compared to TIR. However, TIR demonstrates superior performance on symbolic and computation-heavy tasks like MATH, leveraging tool integration to achieve higher accuracy (e.g., 67.5\% for Qwen2.5-7B). On out-of-domain datasets, CoT shows strong generalization on structured problems like MAWPS and SVAMP, while TIR performs better on complex tasks like OlympiadBench, where precise computations are essential. This divergence underscores the importance of combining both approaches, as \method~balances CoT's reasoning strength with TIR's computational precision, achieving robust performance across diverse datasets.

\begin{table*}[htbp!]
  \resizebox{\textwidth}{!}{
  \footnotesize
  \centering
    \begin{tabular}{@{}lllccccccccc@{}}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{Model}} & \multirow{2}{*}{Method} & \multirow{2}{*}{Metric} & \multicolumn{3}{c}{In-Domain} & \multicolumn{5}{c}{Out-of-Domain} & \multirow{2}{*}{AVG} \\ \cmidrule(lr){4-11}
\multicolumn{1}{c}{} &  &  & GSM8K & MATH & \multicolumn{1}{c|}{ID AVG} & MAWPS & SVAMP & College & Olympiad & \multicolumn{1}{c|}{OOD AVG} &  \\ \midrule
\multirow{9}{*}{Qwen2.5-0.5B} & \multirow{3}{*}{CoT} & Acc & \textbf{55.6} & 32.5 & \multicolumn{1}{c|}{44.0} & \textbf{86.2} & 58.9 & 26.3 & 6.7 & \multicolumn{1}{c|}{44.5} & 44.4 \\
 &  & Token & 305.4 & 526.8 & \multicolumn{1}{c|}{416.1} & 195.7 & 286.2 & 544.3 & 768.9 & \multicolumn{1}{c|}{448.8} & 437.9 \\
 &  & \# Code & 0.0 & 0.0 & \multicolumn{1}{c|}{0.0} & 0.0 & 0.0 & 0.0 & 0.0 & \multicolumn{1}{c|}{0.0} & 0.0 \\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{TIR} & Acc & 46.9 & 36.4 & \multicolumn{1}{c|}{41.6} & 83.5 & 53.5 & 26.3 & 7.7 & \multicolumn{1}{c|}{42.8} & 42.4 \\
 &  & Token & 326.2 & 502.5 & \multicolumn{1}{c|}{414.4} & 268.6 & 292.3 & 492.9 & 745.8 & \multicolumn{1}{c|}{449.9} & 438.0 \\
 &  & \# Code & 3.16 & 2.72 & \multicolumn{1}{c|}{2.94} & 2.76 & 2.93 & 2.91 & 3.03 & \multicolumn{1}{c|}{2.91} & 2.92 \\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{\method} & Acc & 52.8 & \textbf{36.6} & \multicolumn{1}{c|}{\textbf{44.7}} & 85.9 & \textbf{59.4} & \textbf{26.9} & \textbf{8.6} & \multicolumn{1}{c|}{\textbf{45.2}} & \textbf{45.0} \\
 &  & Token & 309.7 & 508.7 & \multicolumn{1}{c|}{409.2} & 217.3 & 292.9 & 500.9 & 743.0 & \multicolumn{1}{c|}{438.5} & 428.8 \\
 &  & \# Code & 0.19 & 2.63 & \multicolumn{1}{c|}{1.41} & 0.52 & 0.33 & 2.82 & 3.06 & \multicolumn{1}{c|}{1.68} & 1.59 \\ \midrule
\multirow{9}{*}{Qwen2.5-1.5B} & \multirow{3}{*}{CoT} & Acc & \textbf{78.3} & 48.2 & \multicolumn{1}{c|}{63.2} & 93.5 & \textbf{82.5} & \textbf{37.9} & 13.2 & \multicolumn{1}{c|}{56.8} & 58.9 \\
 &  & Token & 273.1 & 488.5 & \multicolumn{1}{c|}{380.8} & 185.9 & 233.9 & 498.9 & 684.0 & \multicolumn{1}{c|}{400.7} & 394.0 \\
 &  & \# Code & 0.0 & 0.0 & \multicolumn{1}{c|}{0.0} & 0.0 & 0.0 & 0.0 & 0.0 & \multicolumn{1}{c|}{0.0} & 0.0 \\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{TIR} & Acc & 70.8 & \textbf{54.3} & \multicolumn{1}{c|}{62.6} & 91.7 & 79.8 & 36.0 & \textbf{19.4} & \multicolumn{1}{c|}{56.7} & 58.7 \\
 &  & Token & 324.0 & 474.5 & \multicolumn{1}{c|}{399.2} & 275.0 & 295.4 & 454.1 & 689.9 & \multicolumn{1}{c|}{428.6} & 418.8 \\
 &  & \# Code & 3.1 & 2.55 & \multicolumn{1}{c|}{2.82} & 2.83 & 2.94 & 2.66 & 2.96 & \multicolumn{1}{c|}{2.85} & 2.84 \\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{\method} & Acc & 77.6 & 53.8 & \multicolumn{1}{c|}{\textbf{65.7}} & \textbf{94.2} & 80.7 & 37.0 & 18.8 & \multicolumn{1}{c|}{\textbf{57.7}} & \textbf{60.4} \\
 &  & Token & 273.1 & 480.5 & \multicolumn{1}{c|}{376.8} & 181.8 & 235.0 & 453.3 & 692.7 & \multicolumn{1}{c|}{390.7} & 386.1 \\
 &  & \# Code & 0.11 & 2.37 & \multicolumn{1}{c|}{1.24} & 0.14 & 0.21 & 2.38 & 2.84 & \multicolumn{1}{c|}{1.39} & 1.34 \\ \midrule
\multirow{9}{*}{Qwen2.5-3B} & \multirow{3}{*}{CoT} & Acc & \textbf{85.3} & 53.8 & \multicolumn{1}{c|}{69.6} & \textbf{94.8} & \textbf{85.8} & 41.5 & 16.3 & \multicolumn{1}{c|}{59.6} & 62.9 \\
 &  & Token & 259.8 & 469.2 & \multicolumn{1}{c|}{364.5} & 180.8 & 230.3 & 491.3 & 679.7 & \multicolumn{1}{c|}{395.5} & 385.2 \\
 &  & \# Code & 0.0 & 0.0 & \multicolumn{1}{c|}{0.0} & 0.0 & 0.0 & 0.0 & 0.0 & \multicolumn{1}{c|}{0.0} & 0.0 \\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{TIR} & Acc & 80.4 & \textbf{61.4} & \multicolumn{1}{c|}{70.9} & 89.9 & 79.8 & 41.1 & 25.0 & \multicolumn{1}{c|}{59.0} & 62.9 \\
 &  & Token & 312.7 & 467.0 & \multicolumn{1}{c|}{389.8} & 283.3 & 293.8 & 434.4 & 676.5 & \multicolumn{1}{c|}{422.0} & 411.3 \\
 &  & \# Code & 3.04 & 2.57 & \multicolumn{1}{c|}{2.8} & 2.94 & 2.89 & 2.56 & 2.81 & \multicolumn{1}{c|}{2.8} & 2.8 \\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{\method} & Acc & 84.0 & 61.3 & \multicolumn{1}{c|}{\textbf{72.6}} & 94.7 & 85.3 & \textbf{41.6} & \textbf{24.9} & \multicolumn{1}{c|}{\textbf{61.6}} & \textbf{65.3} \\
 &  & Token & 265.1 & 468.4 & \multicolumn{1}{c|}{366.8} & 209.3 & 237.7 & 436.4 & 683.5 & \multicolumn{1}{c|}{391.7} & 383.4 \\
 &  & \# Code & 0.07 & 2.44 & \multicolumn{1}{c|}{1.25} & 0.55 & 0.26 & 2.49 & 2.8 & \multicolumn{1}{c|}{1.52} & 1.43 \\ \midrule
\multirow{9}{*}{Qwen2.5-7B} & \multirow{3}{*}{CoT} & Acc & 88.7 & 58.6 & \multicolumn{1}{c|}{73.6} & \textbf{96.1} & \textbf{88.1} & 42.7 & 23.0 & \multicolumn{1}{c|}{62.5} & 66.2 \\
 &  & Token & 255.8 & 464.5 & \multicolumn{1}{c|}{360.2} & 177.7 & 217.9 & 480.0 & 673.5 & \multicolumn{1}{c|}{387.3} & 378.2 \\
 &  & \# Code & 0.0 & 0.0 & \multicolumn{1}{c|}{0.0} & 0.0 & 0.0 & 0.0 & 0.0 & \multicolumn{1}{c|}{0.0} & 0.0 \\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{TIR} & Acc & 86.8 & \textbf{67.5} & \multicolumn{1}{c|}{77.2} & 92.1 & 84.3 & 44.2 & \textbf{31.9} & \multicolumn{1}{c|}{63.1} & 67.8 \\
 &  & Token & 306.4 & 452.3 & \multicolumn{1}{c|}{379.4} & 261.6 & 272.0 & 430.6 & 636.3 & \multicolumn{1}{c|}{400.1} & 393.2 \\
 &  & \# Code & 3.01 & 2.43 & \multicolumn{1}{c|}{2.72} & 2.58 & 2.54 & 2.52 & 2.68 & \multicolumn{1}{c|}{2.58} & 2.63 \\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{\method} & Acc & \textbf{89.5} & 66.8 & \multicolumn{1}{c|}{\textbf{78.2}} & 94.2 & 86.2 & \textbf{43.4} & 31.1 & \multicolumn{1}{c|}{\textbf{63.7}} & \textbf{68.5} \\
 &  & Token & 258.1 & 452.8 & \multicolumn{1}{c|}{355.5} & 195.3 & 222.0 & 433.9 & 652.4 & \multicolumn{1}{c|}{375.9} & 369.1 \\
 &  & \# Code & 0.18 & 2.27 & \multicolumn{1}{c|}{1.23} & 0.5 & 0.29 & 2.49 & 2.66 & \multicolumn{1}{c|}{1.48} & 1.4 \\ \midrule
\multirow{9}{*}{LLaMA-3-8B} & \multirow{3}{*}{CoT} & Acc & \textbf{84.7} & 46.5 & \multicolumn{1}{c|}{65.6} & 91.6 & 81.6 & 30.2 & 13.3 & \multicolumn{1}{c|}{54.2} & 58.0 \\
 &  & Token & 246.4 & 471.0 & \multicolumn{1}{c|}{358.7} & 173.3 & 236.8 & 511.7 & 676.7 & \multicolumn{1}{c|}{399.6} & 386.0 \\
 &  & \# Code & 0.0 & 0.0 & \multicolumn{1}{c|}{0.0} & 0.0 & 0.0 & 0.0 & 0.0 & \multicolumn{1}{c|}{0.0} & 0.0 \\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{TIR} & Acc & 81.7 & \textbf{56.2} & \multicolumn{1}{c|}{69.0} & 87.8 & 77.8 & 30.5 & \textbf{21.9} & \multicolumn{1}{c|}{54.5} & 59.3 \\
 &  & Token & 299.0 & 457.5 & \multicolumn{1}{c|}{378.2} & 240.9 & 269.1 & 437.9 & 650.8 & \multicolumn{1}{c|}{399.7} & 392.5 \\
 &  & \# Code & 2.96 & 2.51 & \multicolumn{1}{c|}{2.74} & 2.42 & 2.64 & 2.69 & 2.76 & \multicolumn{1}{c|}{2.63} & 2.66 \\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{\method} & Acc & 84.0 & 55.1 & \multicolumn{1}{c|}{\textbf{69.6}} & \textbf{91.8} & \textbf{82.7} & \textbf{34.2} & 21.5 & \multicolumn{1}{c|}{\textbf{57.6}} & \textbf{61.5} \\
 &  & Token & 248.2 & 461.1 & \multicolumn{1}{c|}{354.6} & 191.1 & 222.5 & 449.5 & 657.7 & \multicolumn{1}{c|}{380.2} & 371.7 \\
 &  & \# Code & 0.12 & 2.33 & \multicolumn{1}{c|}{1.23} & 0.27 & 0.21 & 2.39 & 2.6 & \multicolumn{1}{c|}{1.37} & 1.32 \\ \midrule
\multirow{9}{*}{Qwen2.5Math-1.5B} & \multirow{3}{*}{CoT} & Acc & 83.1 & 56.6 & \multicolumn{1}{c|}{69.8} & 92.9 & 84.1 & \textbf{44.3} & 19.3 & \multicolumn{1}{c|}{60.2} & 63.4 \\
 &  & Token & 267.1 & 476.5 & \multicolumn{1}{c|}{371.8} & 181.7 & 238.3 & 485.7 & 681.7 & \multicolumn{1}{c|}{396.8} & 388.5 \\
 &  & \# Code & 0.0 & 0.0 & \multicolumn{1}{c|}{0.0} & 0.0 & 0.0 & 0.0 & 0.0 & \multicolumn{1}{c|}{0.0} & 0.0 \\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{TIR} & Acc & 78.8 & 64.8 & \multicolumn{1}{c|}{71.8} & 92.3 & 83.3 & 42.4 & \textbf{27.4} & \multicolumn{1}{c|}{61.4} & 64.8 \\
 &  & Token & 332.2 & 516.6 & \multicolumn{1}{c|}{424.4} & 324.5 & 335.6 & 479.0 & 772.5 & \multicolumn{1}{c|}{477.9} & 460.1 \\
 &  & \# Code & 3.28 & 2.8 & \multicolumn{1}{c|}{3.04} & 3.62 & 3.55 & 2.99 & 3.14 & \multicolumn{1}{c|}{3.32} & 3.23 \\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{\method} & Acc & 83.2 & 62.8 & \multicolumn{1}{c|}{\textbf{73.0}} & \textbf{94.0} & \textbf{85.6} & 43.9 & 26.8 & \multicolumn{1}{c|}{\textbf{62.6}} & \textbf{66.0} \\
 &  & Token & 266.2 & 508.9 & \multicolumn{1}{c|}{387.5} & 199.4 & 247.1 & 467.1 & 743.6 & \multicolumn{1}{c|}{414.3} & 405.4 \\
 &  & \# Code & 0.26 & 1.68 & \multicolumn{1}{c|}{0.97} & 0.32 & 0.42 & 1.44 & 2.38 & \multicolumn{1}{c|}{1.14} & 1.08 \\ \midrule
\multirow{9}{*}{Qwen2.5Math-7B} & \multirow{3}{*}{CoT} & Acc & \textbf{91.0} & 61.5 & \multicolumn{1}{c|}{76.2} & 94.8 & 87.9 & 45.7 & 23.9 & \multicolumn{1}{c|}{63.1} & 67.5 \\
 &  & Token & 254.7 & 470.6 & \multicolumn{1}{c|}{362.6} & 177.0 & 223.5 & 484.1 & 669.2 & \multicolumn{1}{c|}{388.5} & 379.9 \\
 &  & \# Code & 0.0 & 0.0 & \multicolumn{1}{c|}{0.0} & 0.0 & 0.0 & 0.0 & 0.01 & \multicolumn{1}{c|}{0.0} & 0.0 \\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{TIR} & Acc & 88.9 & \textbf{73.6} & \multicolumn{1}{c|}{81.2} & \textbf{95.4} & \textbf{89.4} & 47.1 & 35.3 & \multicolumn{1}{c|}{66.8} & 71.6 \\
 &  & Token & 311.8 & 490.9 & \multicolumn{1}{c|}{401.4} & 261.2 & 272.2 & 456.8 & 713.7 & \multicolumn{1}{c|}{426.0} & 417.8 \\
 &  & \# Code & 3.04 & 2.56 & \multicolumn{1}{c|}{2.8} & 2.58 & 2.51 & 2.65 & 2.75 & \multicolumn{1}{c|}{2.62} & 2.68 \\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{\method} & Acc & 89.8 & 73.0 & \multicolumn{1}{c|}{\textbf{81.4}} & 95.2 & 88.1 & \textbf{48.3} & \textbf{35.9} & \multicolumn{1}{c|}{\textbf{66.9}} & \textbf{71.7} \\
 &  & Token & 264.7 & 487.2 & \multicolumn{1}{c|}{376.0} & 193.7 & 229.7 & 476.9 & 710.6 & \multicolumn{1}{c|}{402.7} & 393.8 \\
 &  & \# Code & 0.25 & 2.14 & 1.2 & 0.33 & 0.24 & 2.02 & 2.59 & 1.3 & 1.26 \\ \bottomrule
\end{tabular}
  }
  \caption{Detailed results of our {\method} framework. The best accuracies within each group are shown in \textbf{bold}.
  % , while the second-best results are \underline{underlined}. 
  The three metrics, ``Acc'', ``Token'', and ``\# Code'' represent the average accuracy (\%), total tokens per generation, and number of code executions. 
  ``ID AVG'', ``OOD AVG'', and ``AVG'' denote the averages of these metrics across in-domain, out-of-domain, and all six benchmarks. 
  ``CoT'', ``TIR'', and ``{\method}'' indicate fine-tuning exclusively on CoT data, TIR data, and using our {\method} framework, respectively, with the corresponding base LLM.}
  \label{tab:full-results}
  %\vspace{-15pt}
\end{table*}


\subsection{Ablation Study}\label{app:ablation}

As detailed in Appendix~\ref{app:exp_setup}, we use different decision function $\mathcal{H}$ for GSM8K and MATH.
Specifically, for GSM8K, the dataset for supervised fine-tuning ($D_{\text{SFT}}$) is defined as:  
$$
D_{\text{SFT}} = \bigcup_{k=1}^N \{(x_k, y_k^j)\}_{j=1}^{M_k} \cup \bigcup_{k \in A} \{(x_k, z_k^j)\}_{j=1}^{M_k},
$$  
where the index set $A = \{k: S_{\text{CoT}}^k - S_{\text{TIR}}^k < \text{quantile}_1\}$.  

For MATH, $D_{\text{SFT}}$ is defined as:  
$$
D_{\text{SFT}} = \bigcup_{k=1}^N \{(x_k, z_k^j)\}_{j=1}^{M_k} \cup \bigcup_{k \in B} \{(x_k, y_k^j)\}_{j=1}^{M_k},
$$  
where the index set $B = \{k: S_{\text{CoT}}^k - S_{\text{TIR}}^k > \text{quantile}_2\}$.  
We consider this as the default choice of our {\method} (i.e., {\method} in Table~\ref{tabapp:ablation}).

We present the results of the $\mathcal{H}$ ablation study in Table~\ref{tabapp:ablation}. The variants of $\mathcal{H}$ evaluated are described as follows:

\paragraph{Random} 
The key difference between ``Random'' and ``{\method}'' lies in the selection of the index sets $A$ and $B$. 
In the ``Random'' variant, we randomly select the index sets $A$ and $B$ while ensuring that $|A|$ and $|B|$ match those in the default {\method} configuration. 
It is important to note that this is not purely a random selection, the number of queries using TIR or CoT is still determined by the default settings of {\method}, making ``Random'' a strong baseline.


\paragraph{CoT + TIR}
 In this variant, we include all CoT and TIR solutions in $D_{\text{SFT}}$, doubling the number of training examples compared to using only CoT or TIR individually. 
 Formally, the dataset is defined as:  
$$
D_{\text{SFT}} = \bigcup_{k=1}^N \{(x_k, y_k^j)\}_{j=1}^{M_k} \cup \bigcup_{k=1}^N \{(x_k, z_k^j)\}_{j=1}^{M_k}.
$$  


\paragraph{\method$^-$}
The {\method}$^-$ variant differs from the original {\method} in that it uses a single quantile for selection. 
The dataset is formally defined as:  
$$
D_{\text{SFT}} = \bigcup_{k \in A} \{(x_k, y_k^j)\}_{j=1}^{M_k} \cup \bigcup_{k \in B} \{(x_k, z_k^j)\}_{j=1}^{M_k},
$$  
where the index set $A = \{k: S_{\text{CoT}}^k - S_{\text{TIR}}^k > \text{quantile}\}$, and $B = A^c$.  
In this setup, each query in the candidate set {\dcandidatee} includes either CoT or TIR solutions but not both.


From Table~\ref{tabapp:ablation}, the selection function $\mathcal{H}$ in our {\method} gains the best results.


\begin{table*}[htbp!]
  \resizebox{\textwidth}{!}{
  \footnotesize
  \centering
    \begin{tabular}{@{}lllccccccccc@{}}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{Model}} & \multirow{2}{*}{Method} & \multirow{2}{*}{Metric} & \multicolumn{3}{c}{In-Domain} & \multicolumn{5}{c}{Out-of-Domain} & \multirow{2}{*}{AVG} \\ \cmidrule(lr){4-11}
\multicolumn{1}{c}{} &  &  & GSM8K & MATH & \multicolumn{1}{c|}{ID AVG} & MAWPS & SVAMP & College & Olympiad & \multicolumn{1}{c|}{OOD AVG} &  \\ \midrule
\multirow{15}{*}{LLaMA-3-8B} & \multirow{3}{*}{CoT} & Acc & \textbf{84.7} & 46.5 & \multicolumn{1}{c|}{65.6} & 91.6 & 81.6 & 30.2 & 13.3 & \multicolumn{1}{c|}{54.2} & 58.0 \\
 &  & Token & 246.4 & 471.0 & \multicolumn{1}{c|}{358.7} & 173.3 & 236.8 & 511.7 & 676.7 & \multicolumn{1}{c|}{399.6} & 386.0 \\
 &  & \# Code & 0.0 & 0.0 & \multicolumn{1}{c|}{0.0} & 0.0 & 0.0 & 0.0 & 0.0 & \multicolumn{1}{c|}{0.0} & 0.0 \\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{TIR} & Acc & 81.7 & 56.2 & \multicolumn{1}{c|}{69.0} & 87.8 & 77.8 & 30.5 & \textbf{21.9} & \multicolumn{1}{c|}{54.5} & 59.3 \\
 &  & Token & 299.0 & 457.5 & \multicolumn{1}{c|}{378.2} & 240.9 & 269.1 & 437.9 & 650.8 & \multicolumn{1}{c|}{399.7} & 392.5 \\
 &  & \# Code & 2.96 & 2.51 & \multicolumn{1}{c|}{2.74} & 2.42 & 2.64 & 2.69 & 2.76 & \multicolumn{1}{c|}{2.63} & 2.66 \\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{Random} & Acc & 83.1 & \textbf{56.4} & \multicolumn{1}{c|}{\textbf{69.8}} & 91.8 & 81.3 & 31.3 & 21.8 & \multicolumn{1}{c|}{56.6} & 61.0\\
 & & Token & 271.6 & 472.0 & \multicolumn{1}{c|}{371.8} & 203.7 & 251.0 & 453.4 & 695.5 & \multicolumn{1}{c|}{400.9} & 391.2\\
 & & \# Code & 0.21 & 2.35 & \multicolumn{1}{c|}{1.28} & 0.36 & 0.33 & 2.44 & 2.83 & \multicolumn{1}{c|}{1.49} & 1.42\\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{CoT + TIR} & Acc & 83.1 & 48.4 & \multicolumn{1}{c|}{65.8} & 91.2 & 78.7 & 30.8 & 16.7 & \multicolumn{1}{c|}{54.4} & 58.2 \\
 &  & Token & 278.0 & 497.4 & \multicolumn{1}{c|}{387.7} & 208.6 & 281.2 & 507.3 & 707.3 & \multicolumn{1}{c|}{421.1} & 410.0 \\
 &  & \# Code & 0.83 & 0.51 & \multicolumn{1}{c|}{0.67} & 0.68 & 0.95 & 0.51 & 1.09 & \multicolumn{1}{c|}{0.81} & 0.76 \\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{{\method}$^-$} & Acc & 83.1 & 54.7 & \multicolumn{1}{c|}{68.9} & 91.2 & 80.6 & 31.9 & 19.6 & \multicolumn{1}{c|}{55.8} & 60.2\\
 & & Token & 285.4 & 472.1 & \multicolumn{1}{c|}{378.8} & 226.7 & 253.9 & 474.3 & 692.2 & \multicolumn{1}{c|}{411.8} & 400.8\\
 & & \# Code & 1.4 & 2.31 & \multicolumn{1}{c|}{1.86} & 1.23 & 1.2 & 2.34 & 2.49 & \multicolumn{1}{c|}{1.81} & 1.83 \\ \cmidrule(l){2-12} 

 & \multirow{3}{*}{\method} & Acc & 84.0 & 55.1 & \multicolumn{1}{c|}{69.6} & \textbf{91.8} & \textbf{82.7} & \textbf{34.2} & 21.5 & \multicolumn{1}{c|}{\textbf{57.6}} & \textbf{61.5} \\
 &  & Token & 248.2 & 461.1 & \multicolumn{1}{c|}{354.6} & 191.1 & 222.5 & 449.5 & 657.7 & \multicolumn{1}{c|}{380.2} & 371.7 \\
 &  & \# Code & 0.12 & 2.33 & \multicolumn{1}{c|}{1.23} & 0.27 & 0.21 & 2.39 & 2.6 & \multicolumn{1}{c|}{1.37} & 1.32 \\ 
\bottomrule
\end{tabular}
  }
  \caption{Ablation Study using LLaMA-3-8B. The best accuracies within each group are shown in \textbf{bold}.
  The three metrics, ``Acc'', ``Token'', and ``\# Code'' represent the average accuracy, total tokens per generation, and number of code executions. 
  ``Acc'' is reported in \%. ``ID AVG'', ``OOD AVG'', and ``AVG'' denote the averages of these metrics across in-domain, out-of-domain, and all six benchmarks.}
  \label{tabapp:ablation}
\end{table*}




\subsection{Analysis of CoT scores and TIR scores}\label{app:scores}

% different base LLMs -> different tendency
% Math LLM has high scores -> 
% qwenmath7b math scores

In Section~\ref{sec:ana_scores}, we presented representative results analyzing CoT and TIR scores. 
Here, we further provide the distributions of {\scote}, {\stire}, and ($S_{\text{CoT}}^k - S_{\text{TIR}}^k$) for various base LLMs in Figures~\ref{fig:llama3-scores}, \ref{fig:qwen05-scores}, \ref{fig:qwen15-scores}, \ref{fig:qwen3-scores}, \ref{fig:qwen7-scores}, \ref{fig:qwenmath15-scores}, and \ref{fig:qwenmath7-scores}.
From these figures, we have the following observations:  
1. Different base LLMs exhibit varying tendencies towards CoT or TIR responding to the same candidate set queries.  
2. Math-specialized LLMs (e.g., Qwen2.5Math) demonstrate higher CoT and TIR scores compared to their general-purpose counterparts (e.g., Qwen2.5). 
This may be attributed to the inclusion of similar CoT and TIR data in their pretraining process.  
3. Notably, Qwen2.5Math-7B achieves TIR scores approaching 0.8 accuracy on the MATH anchor set using only a 1-shot prompt from the candidate set, as shown in Figure~\ref{fig:qwenmath7-scores} (middle). 
This suggests the potential for anchor set contamination~\citep{benbench2024xu}.  


\begin{figure*}
    \centering
    \includegraphics[width=0.32\linewidth]{figures/llama3-gsm8k.pdf}
    \includegraphics[width=0.32\linewidth]{figures/llama3-math.pdf}
    \includegraphics[width=0.32\linewidth]{figures/llama3-cot-tir.pdf}
    \caption{The distribution of {\scote} (left), {\stire} (middle), and ($S_{\text{CoT}}^k - S_{\text{TIR}}^k$) (right) for LLaMA-3-8B.}
    \label{fig:llama3-scores}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=0.32\linewidth]{figures/qwen0_5b-gsm8k.pdf}
    \includegraphics[width=0.32\linewidth]{figures/qwen0_5b-math.pdf}
    \includegraphics[width=0.32\linewidth]{figures/qwen0_5b-cot-tir.pdf}
    \caption{The distribution of {\scote} (left), {\stire} (middle), and ($S_{\text{CoT}}^k - S_{\text{TIR}}^k$) (right) for Qwen2.5-0.5B.}
    \label{fig:qwen05-scores}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=0.32\linewidth]{figures/qwen1_5b-gsm8k.pdf}
    \includegraphics[width=0.32\linewidth]{figures/qwen1_5b-math.pdf}
    \includegraphics[width=0.32\linewidth]{figures/qwen1_5b-cot-tir.pdf}
    \caption{The distribution of {\scote} (left), {\stire} (middle), and ($S_{\text{CoT}}^k - S_{\text{TIR}}^k$) (right) for Qwen2.5-1.5B.}
    \label{fig:qwen15-scores}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=0.32\linewidth]{figures/qwen3b-gsm8k.pdf}
    \includegraphics[width=0.32\linewidth]{figures/qwen3b-math.pdf}
    \includegraphics[width=0.32\linewidth]{figures/qwen3b-cot-tir.pdf}
    \caption{The distribution of {\scote} (left), {\stire} (middle), and ($S_{\text{CoT}}^k - S_{\text{TIR}}^k$) (right) for Qwen2.5-3B.}
    \label{fig:qwen3-scores}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=0.32\linewidth]{figures/qwen7b-gsm8k.pdf}
    \includegraphics[width=0.32\linewidth]{figures/qwen7b-math.pdf}
    \includegraphics[width=0.32\linewidth]{figures/qwen7b-cot-tir.pdf}
    \caption{The distribution of {\scote} (left), {\stire} (middle), and ($S_{\text{CoT}}^k - S_{\text{TIR}}^k$) (right) for Qwen2.5-7B.}
    \label{fig:qwen7-scores}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=0.32\linewidth]{figures/qwenmath1_5b-gsm8k.pdf}
    \includegraphics[width=0.32\linewidth]{figures/qwenmath1_5b-math.pdf}
    \includegraphics[width=0.32\linewidth]{figures/qwenmath1_5b-cot-tir.pdf}
    \caption{The distribution of {\scote} (left), {\stire} (middle), and ($S_{\text{CoT}}^k - S_{\text{TIR}}^k$) (right) for Qwen2.5Math-1.5B.}
    \label{fig:qwenmath15-scores}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=0.32\linewidth]{figures/qwenmath7b-gsm8k.pdf}
    \includegraphics[width=0.32\linewidth]{figures/qwenmath7b-math.pdf}
    \includegraphics[width=0.32\linewidth]{figures/qwenmath7b-cot-tir.pdf}
    \caption{The distribution of {\scote} (left), {\stire} (middle), and ($S_{\text{CoT}}^k - S_{\text{TIR}}^k$) (right) for Qwen2.5Math-7B.}
    \label{fig:qwenmath7-scores}
\end{figure*}




\subsection{Transferability Results}\label{app:transfer}

The complete results of transferability results are given in Table~\ref{tabapp:transfer_results}.

\begin{table*}[htbp!]
  \resizebox{\textwidth}{!}{
  \footnotesize
  \centering
    \begin{tabular}{@{}lllccccccccc@{}}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{Model}} & \multirow{2}{*}{Select By} & \multirow{2}{*}{Metric} & \multicolumn{3}{c}{In-Domain} & \multicolumn{5}{c}{Out-of-Domain} & \multirow{2}{*}{AVG} \\ \cmidrule(lr){4-11}
\multicolumn{1}{c}{} &  &  & GSM8K & MATH & \multicolumn{1}{c|}{ID AVG} & MAWPS & SVAMP & College & Olympiad & \multicolumn{1}{c|}{OOD AVG} &  \\ \midrule
\multirow{9}{*}{Qwen2.5-0.5B}
 & \multirow{3}{*}{Qwen2.5-0.5B} & Acc & \textbf{52.8} & 36.6 & \multicolumn{1}{c|}{\textbf{44.7}} & 85.9 & \textbf{59.4} & \textbf{26.9} & \textbf{8.6} & \multicolumn{1}{c|}{\textbf{45.2}} & \textbf{45.0} \\
 &  & Token & 309.7 & 508.7 & \multicolumn{1}{c|}{409.2} & 217.3 & 292.9 & 500.9 & 743.0 & \multicolumn{1}{c|}{438.5} & 428.8 \\
 &  & \# Code & 0.19 & 2.63 & \multicolumn{1}{c|}{1.41} & 0.52 & 0.33 & 2.82 & 3.06 & \multicolumn{1}{c|}{1.68} & 1.59 \\ \cmidrule(l){2-12}
 & \multirow{3}{*}{LLaMA-3-8B} & Acc & 51.3 & 36.3 & \multicolumn{1}{c|}{43.8} & 86.2 & 55.9 & 26.5 & 8.1 & \multicolumn{1}{c|}{44.2} & 44.1 \\
 &  & Token & 318.2 & 507.7 & \multicolumn{1}{c|}{413.0} & 216.9 & 298.9 & 485.4 & 732.8 & \multicolumn{1}{c|}{433.5} & 426.6 \\
 &  & \# Code & 0.28 & 2.49 & \multicolumn{1}{c|}{1.39} & 0.52 & 0.52 & 2.45 & 2.73 & \multicolumn{1}{c|}{1.56} & 1.5 \\ \cmidrule(l){2-12}
 & \multirow{3}{*}{Qwen2.5-7B} & Acc & 52.2 & 36.8 & \multicolumn{1}{c|}{44.5} & \textbf{86.7} & 57.6 & 26.7 & 7.4 & \multicolumn{1}{c|}{44.6} & \textbf{44.6} \\
 &  & Token & 312.5 & 499.4 & \multicolumn{1}{c|}{406.0} & 228.6 & 308.2 & 489.3 & 744.5 & \multicolumn{1}{c|}{442.6} & 430.4 \\
 &  & \# Code & 0.4 & 2.53 & \multicolumn{1}{c|}{1.46} & 0.85 & 0.68 & 2.75 & 2.94 & \multicolumn{1}{c|}{1.81} & 1.69 \\ 
\bottomrule
\end{tabular}
  }
  \caption{Detailed results of transferability experiments using Qwen2.5-0.5B. The best accuracies within each group are shown in \textbf{bold}.
  The three metrics, ``Acc'', ``Token'', and ``\# Code'' represent the average accuracy, total tokens per generation, and number of code executions. 
  ``Acc'' is reported in \%. ``ID AVG'', ``OOD AVG'', and ``AVG'' denote the averages of these metrics across in-domain, out-of-domain, and all six benchmarks.}
  \label{tabapp:transfer_results}
\end{table*}




\subsection{DPO Results}\label{app:rl}

The detailed settings of DPO are as follows:

\paragraph{Preference Data Construction}
The construction of the preference dataset used in DPO is guided by CoT and TIR scores, following a similar approach to the construction of {\dsft}. 
Specifically, two separate quantiles are used to select preference pairs for the GSM8K and MATH datasets.
The preference dataset, $\mathcal{D}_{\text{pre}}$, is selected from the newly defined candidate set, {\dcandidatee}, and is formally defined as:  
$$
\mathcal{D}_{\text{pre}} = \{(x_k, c_k, r_k)\}_{k \in A},
$$  
where $c_k$ is the \textbf{c}hosen (preferred) response for the query $x_k$, and $r_k$ is the \textbf{r}ejected response.  

The index set $A$ is defined as:  
\begin{align*}
    A = \{k: S_{\text{TIR}}^k - S_{\text{CoT}}^k &< \text{quantile}^{'}_1 \quad \text{or} \\ 
    &S_{\text{CoT}}^k - S_{\text{TIR}}^k > \text{quantile}^{'}_2\}, 
\end{align*}  
where $\text{quantile}^{'}_1$ and $\text{quantile}^{'}_2$ are two quantiles optimized via grid search.

The rules for determining $c_k$ (chosen response) and $r_k$ (rejected response) are as follows:  
$$
c_k = 
\begin{cases} 
y_k & \text{if } S_{\text{CoT}}^k - S_{\text{TIR}}^k > \text{quantile}^{'}_2, \\
z_k & \text{if } S_{\text{TIR}}^k - S_{\text{CoT}}^k < \text{quantile}^{'}_1,
\end{cases}
$$
and  
$$
r_k = 
\begin{cases} 
y_k & \text{if } S_{\text{TIR}}^k - S_{\text{CoT}}^k < \text{quantile}^{'}_1, \\
z_k & \text{if } S_{\text{CoT}}^k - S_{\text{TIR}}^k > \text{quantile}^{'}_2.
\end{cases}
$$  
This preference selection process ensures that the dataset $\mathcal{D}_{\text{pre}}$ contains meaningful comparisons between CoT and TIR responses based on their relative scores.



\paragraph{DPO Hyperparameters}
We utilize \href{https://github.com/OpenRLHF/OpenRLHF}{OpenRLHF} \citep{hu2024openrlhf} to implement DPO. 
The maximum token length is set to 4,096, consistent with the SFT stage. 
The training process adopts a learning rate of $5 \times 10^{-7}$, a batch size of 256, and runs for one epoch.
We use LLaMA-3-8B and Qwen2.5Math-7B, fine-tuned with {\method}, as the starting point for DPO.


The complete results are presented in Table~\ref{tabapp:dpo_results}. 
As shown, DPO achieves comparable results with LLMs fine-tuned with {\method}.

\begin{table*}[htbp!]
  \resizebox{\textwidth}{!}{
  \footnotesize
  \centering
    \begin{tabular}{@{}lllccccccccc@{}}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{Model}} & \multirow{2}{*}{Method} & \multirow{2}{*}{Metric} & \multicolumn{3}{c}{In-Domain} & \multicolumn{5}{c}{Out-of-Domain} & \multirow{2}{*}{AVG} \\ \cmidrule(lr){4-11}
\multicolumn{1}{c}{} &  &  & GSM8K & MATH & \multicolumn{1}{c|}{ID AVG} & MAWPS & SVAMP & College & Olympiad & \multicolumn{1}{c|}{OOD AVG} &  \\ \midrule
\multirow{12}{*}{LLaMA-3-8B} & \multirow{3}{*}{CoT} & Acc & \textbf{84.7} & 46.5 & \multicolumn{1}{c|}{65.6} & 91.6 & 81.6 & 30.2 & 13.3 & \multicolumn{1}{c|}{54.2} & 58.0 \\
 &  & Token & 246.4 & 471.0 & \multicolumn{1}{c|}{358.7} & 173.3 & 236.8 & 511.7 & 676.7 & \multicolumn{1}{c|}{399.6} & 386.0 \\
 &  & \# Code & 0.0 & 0.0 & \multicolumn{1}{c|}{0.0} & 0.0 & 0.0 & 0.0 & 0.0 & \multicolumn{1}{c|}{0.0} & 0.0 \\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{TIR} & Acc & 81.7 & \textbf{56.2} & \multicolumn{1}{c|}{69.0} & 87.8 & 77.8 & 30.5 & \textbf{21.9} & \multicolumn{1}{c|}{54.5} & 59.3 \\
 &  & Token & 299.0 & 457.5 & \multicolumn{1}{c|}{378.2} & 240.9 & 269.1 & 437.9 & 650.8 & \multicolumn{1}{c|}{399.7} & 392.5 \\
 &  & \# Code & 2.96 & 2.51 & \multicolumn{1}{c|}{2.74} & 2.42 & 2.64 & 2.69 & 2.76 & \multicolumn{1}{c|}{2.63} & 2.66 \\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{\method} & Acc & 84.0 & 55.1 & \multicolumn{1}{c|}{\textbf{69.6}} & \textbf{91.8} & \textbf{82.7} & \textbf{34.2} & 21.5 & \multicolumn{1}{c|}{\textbf{57.6}} & 61.5 \\
 &  & Token & 248.2 & 461.1 & \multicolumn{1}{c|}{354.6} & 191.1 & 222.5 & 449.5 & 657.7 & \multicolumn{1}{c|}{380.2} & 371.7 \\
 &  & \# Code & 0.12 & 2.33 & \multicolumn{1}{c|}{1.23} & 0.27 & 0.21 & 2.39 & 2.6 & \multicolumn{1}{c|}{1.37} & 1.32 \\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{+DPO} & Acc & 84.0 & 55.2 & \multicolumn{1}{c|}{\textbf{69.6}} & \textbf{91.8} & \textbf{82.7} & 34.0 & 21.8 & \multicolumn{1}{c|}{\textbf{57.6}} & \textbf{61.6} \\
 &  & Token & 250.8 & \textbf{453.6} & \multicolumn{1}{c|}{\textbf{352.2}} & \textbf{185.0} & \textbf{219.1} & \textbf{435.9} & \textbf{647.9} & \multicolumn{1}{c|}{372.0} & \textbf{365.4} \\
 &  & \# Code & 0.14 & 2.38 & \multicolumn{1}{c|}{1.26} & 0.25 & 0.17 & 2.42 & 2.7 & \multicolumn{1}{c|}{1.38} & 1.34 \\
 \midrule
\multirow{12}{*}{Qwen2.5Math-7B} & \multirow{3}{*}{CoT} & Acc & \textbf{91.0} & 61.5 & \multicolumn{1}{c|}{76.2} & 94.8 & 87.9 & 45.7 & 23.9 & \multicolumn{1}{c|}{63.1} & 67.5 \\
 &  & Token & \textbf{254.7} & 470.6 & \multicolumn{1}{c|}{362.6} & \textbf{177.0} & \textbf{223.5} & 484.1 & 669.2 & \multicolumn{1}{c|}{388.5} & 379.9 \\
 &  & \# Code & 0.0 & 0.0 & \multicolumn{1}{c|}{0.0} & 0.0 & 0.0 & 0.0 & 0.01 & \multicolumn{1}{c|}{0.0} & 0.0 \\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{TIR} & Acc & 88.9 & \textbf{73.6} & \multicolumn{1}{c|}{81.2} & \textbf{95.4} & \textbf{89.4} & 47.1 & 35.3 & \multicolumn{1}{c|}{66.8} & 71.6 \\
 &  & Token & 311.8 & 490.9 & \multicolumn{1}{c|}{401.4} & 261.2 & 272.2 & \textbf{456.8} & 713.7 & \multicolumn{1}{c|}{426.0} & 417.8 \\
 &  & \# Code & 3.04 & 2.56 & \multicolumn{1}{c|}{2.8} & 2.58 & 2.51 & 2.65 & 2.75 & \multicolumn{1}{c|}{2.62} & 2.68 \\ \cmidrule(l){2-12} 
 & \multirow{3}{*}{\method} & Acc & 89.8 & 73.0 & \multicolumn{1}{c|}{\textbf{81.4}} & 95.2 & 88.1 & \textbf{48.3} & \textbf{35.9} & \multicolumn{1}{c|}{\textbf{66.9}} & \textbf{71.7} \\
 &  & Token & 264.7 & 487.2 & \multicolumn{1}{c|}{376.0} & 193.7 & 229.7 & 476.9 & 710.6 & \multicolumn{1}{c|}{402.7} & 393.8 \\
 &  & \# Code & 0.25 & 2.14 & 1.2 & 0.33 & 0.24 & 2.02 & 2.59 & 1.3 & 1.26 \\  \cmidrule(l){2-12} 
 & \multirow{3}{*}{+DPO} & Acc & 89.8 & 73.1 & \multicolumn{1}{c|}{\textbf{81.4}} & 95.2 & 88.1 & \textbf{48.4} & 35.4 & \multicolumn{1}{c|}{66.8} & \textbf{71.7} \\
 &  & Token & 267.0 & \textbf{487.2} & \multicolumn{1}{c|}{377.1} & 193.8 & 229.4 & 474.8 & 718.9 & \multicolumn{1}{c|}{404.2} & 395.2 \\
 &  & \# Code & 0.3 & 2.18 & \multicolumn{1}{c|}{1.24} & 0.39 & 0.27 & 2.08 & 2.67 & \multicolumn{1}{c|}{1.35} & 1.32 \\
\bottomrule
\end{tabular}
  }
  \caption{Detailed DPO results. The best accuracies within each group are shown in \textbf{bold}.
  The three metrics, ``Acc'', ``Token'', and ``\# Code'' represent the average accuracy, total tokens per generation, and number of code executions. 
  ``Acc'' is reported in \%. ``ID AVG'', ``OOD AVG'', and ``AVG'' denote the averages of these metrics across in-domain, out-of-domain, and all six benchmarks.}
  \label{tabapp:dpo_results}
\end{table*}