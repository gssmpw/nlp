\section{Conclusion}\label{sec:conclusion}
We propose {\method}, a novel and effective framework for mathematical reasoning with LLMs that enables models to dynamically align their reasoning strategies, CoT or TIR, with their intrinsic strengths. 
By incorporating base-LLM-aware data selection during SFT, {\method} tailors reasoning strategies to each model, empowering them to select an appropriate paradigm for during inference autonomously. 
Extensive experiments demonstrate that {\method} achieves superior or comparable performance across both in-domain and OOD benchmarks while significantly improving inference efficiency compared to static TIR-based methods. 
Moreover, our analysis underscores the importance of aptitude-aware data selection in unlocking the potential of LLMs to make autonomous and effective reasoning decisions, paving the way for further advancements in reasoning capabilities of LLMs.


\section*{Limitation}
This study primarily focuses on the domain of mathematical reasoning. 
Extending the concept of adaptive tool use to more generalized reasoning scenarios represents a promising avenue for future research.
The proposed approach concentrates on instance-level spontaneous selection between CoT and TIR.
Investigating a more fine-grained, step-level selection strategy could be an interesting direction for future work.
Our method mainly relies on the SFT stage, with the training data sourced from the GSM8K and MATH datasets. 
Further research incorporating reinforcement learning (e.g., \citep{deepseekr12025deepseekai}) or leveraging a more diverse set of training data (e.g., \citep{s12025muennighoff, limo2025ye}) could be interesting directions to explore.

