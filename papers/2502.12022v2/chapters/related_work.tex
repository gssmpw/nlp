\section{Related Work}\label{sec:related_work}

\paragraph{Math Reasoning with CoT and TIR}
%Chain-of-Thought (CoT) \citep{CoT2022Wei} and Tool-Integrated Reasoning (TIR) \citep{PoT2022Chen} are two widely recognized approaches for reasoning with LLMs. 
CoT and TIR are two widely recognized approaches for reasoning with LLMs. 
%CoT breaks reasoning into natural language steps, offering flexibility, and interpretability, but it lacks computational precision. 
%In contrast, TIR ensures rigorous, executable solutions through code but is computationally expensive due to its reliance on interactive execution. 
CoT offers interpretability and generalizability, while TIR can provide precise calculation results.
Previous work on mathematical SFT has primarily focused on either CoT \citep{metamath2023yu, dartmath2024tong, deepseekmath2024shao, yan2024s} or TIR \citep{mammoth2023yue, tora2023Gou, mathcoder2023wang, mumathcode2024yin}, with a few efforts to integrate both \citep{mammoth2023yue, numinamath7b, Qwen25Math2024Yang}. 
For instance, MAmmoTH \citep{mammoth2023yue} mainly adopts TIR but switches to CoT when code execution fails due to errors or timeouts. 
However, it relies on separate prompts and manual inference controls to switch between them.  
Recent work has explored automatic selection between CoT and TIR \citep{automatictoolselect2023zhao, dots2024yue, toolteaching2024yu}, such as using an auxiliary LLM to determine CoT/TIR \citep{automatictoolselect2023zhao}. 
However, these methods rely on external planners to select CoT/TIR, not by LLMs themselves. 
In contrast, our work seeks to enable LLMs to spontaneously select the appropriate reasoning strategy without relying on external planners or manual interventions.
%By doing so, we strike a better balance between inference efficiency and computational accuracy, paving the way for more effective and practical reasoning approaches.


\paragraph{Data Selection}
Data selection plays a crucial role in training LLMs \citep{dataselectionsurvey2024albalak}. Various methods have been developed to optimize data usage at different stages of model training, ranging from pretraining \citep{GPT32020Brown, qurating2024wettig, rho12025lin} to supervised fine-tuning (SFT) \citep{1-shot2023li, gdig2024pan, less2024xia, lima2024zhou}.
Our work focuses specifically on data selection between CoT and TIR given a math problem and a base LLM.

\paragraph{Test-Time Scaling}
Recent efforts in scaling test-time computation have explored refinement strategies \citep{snell2024refine1, pds2024xu, hou2025refine2, lee2025refine3}, which iteratively build on previous outputs, and MCTS-based approaches \citep{zhou2023mcts1, liu2024mcts2, rebase2024wu}. 
The roles of SFT and RL have also been actively discussed \citep{chu2025sftrl}. 
For example, \citet{o1, deepseekr12025deepseekai} use RL to train LLMs for generating longer CoT reasoning, while \citet{s12025muennighoff, limo2025ye} leverage SFT for scaling test-time computation.
This work focuses on enabling adaptive mathematical reasoning in LLMs primarily through data selection during the SFT stage, with discussions on the potential use of RL in Section~\ref{sec:rl}. 
While existing test-time scaling methods mainly target CoT, exploring adaptive selection between CoT and TIR could be an orthogonal direction.


 