\begin{table*}[htbp!]
  \resizebox{\textwidth}{!}{
  \footnotesize
  \centering
    \begin{tabular}{@{}llccccccccc@{}}
\toprule
\multicolumn{1}{l}{\multirow{2}{*}{Model}} & \multirow{2}{*}{Method} & \multicolumn{3}{c}{In-Domain} & \multicolumn{5}{c}{Out-of-Domain} & \multirow{2}{*}{AVG} \\ \cmidrule(lr){3-10}
\multicolumn{1}{c}{} &  &  GSM8K & MATH & \multicolumn{1}{c|}{ID AVG} & MAWPS & SVAMP & College & Olympiad & \multicolumn{1}{c|}{OOD AVG} &  \\ \midrule
\multirow{3}{*}{Qwen2.5-0.5B} & \multirow{1}{*}{CoT}  & \textbf{55.6} & 32.5 & \multicolumn{1}{c|}{44.0} & \textbf{86.2} & 58.9 & 26.3 & 6.7 & \multicolumn{1}{c|}{44.5} & 44.4 \\
 & \multirow{1}{*}{TIR}  & 46.9 & 36.4 & \multicolumn{1}{c|}{41.6} & 83.5 & 53.5 & 26.3 & 7.7 & \multicolumn{1}{c|}{42.8} & 42.4 \\
 & \multirow{1}{*}{\method}  & 52.8 & \textbf{36.6} & \multicolumn{1}{c|}{\textbf{44.7}} & 85.9 & \textbf{59.4} & \textbf{26.9} & \textbf{8.6} & \multicolumn{1}{c|}{\textbf{45.2}} & \textbf{45.0} \\ 
 \midrule
\multirow{3}{*}{Qwen2.5-1.5B} & \multirow{1}{*}{CoT}  & \textbf{78.3} & 48.2 & \multicolumn{1}{c|}{63.2} & 93.5 & \textbf{82.5} & \textbf{37.9} & 13.2 & \multicolumn{1}{c|}{56.8} & 58.9 \\
 & \multirow{1}{*}{TIR}  & 70.8 & \textbf{54.3} & \multicolumn{1}{c|}{62.6} & 91.7 & 79.8 & 36.0 & \textbf{19.4} & \multicolumn{1}{c|}{56.7} & 58.7 \\
 & \multirow{1}{*}{\method}  & 77.6 & 53.8 & \multicolumn{1}{c|}{\textbf{65.7}} & \textbf{94.2} & 80.7 & 37.0 & 18.8 & \multicolumn{1}{c|}{\textbf{57.7}} & \textbf{60.4} \\ 
 \midrule
\multirow{3}{*}{Qwen2.5-3B} & \multirow{1}{*}{CoT}  & \textbf{85.3} & 53.8 & \multicolumn{1}{c|}{69.6} & \textbf{94.8} & \textbf{85.8} & 41.5 & 16.3 & \multicolumn{1}{c|}{59.6} & 62.9 \\
 & \multirow{1}{*}{TIR}  & 80.4 & \textbf{61.4} & \multicolumn{1}{c|}{70.9} & 89.9 & 79.8 & 41.1 & 25.0 & \multicolumn{1}{c|}{59.0} & 62.9 \\
 & \multirow{1}{*}{\method}  & 84.0 & 61.3 & \multicolumn{1}{c|}{\textbf{72.6}} & 94.7 & 85.3 & \textbf{41.6} & \textbf{24.9} & \multicolumn{1}{c|}{\textbf{61.6}} & \textbf{65.3} \\ 
 \midrule
\multirow{3}{*}{Qwen2.5-7B} & \multirow{1}{*}{CoT}  & 88.7 & 58.6 & \multicolumn{1}{c|}{73.6} & \textbf{96.1} & \textbf{88.1} & 42.7 & 23.0 & \multicolumn{1}{c|}{62.5} & 66.2 \\
 & \multirow{1}{*}{TIR}  & 86.8 & \textbf{67.5} & \multicolumn{1}{c|}{77.2} & 92.1 & 84.3 & 44.2 & \textbf{31.9} & \multicolumn{1}{c|}{63.1} & 67.8 \\
 & \multirow{1}{*}{\method}  & \textbf{89.5} & 66.8 & \multicolumn{1}{c|}{\textbf{78.2}} & 94.2 & 86.2 & \textbf{43.4} & 31.1 & \multicolumn{1}{c|}{\textbf{63.7}} & \textbf{68.5} \\
 \midrule
\multirow{3}{*}{LLaMA-3-8B} & \multirow{1}{*}{CoT}  & \textbf{84.7} & 46.5 & \multicolumn{1}{c|}{65.6} & 91.6 & 81.6 & 30.2 & 13.3 & \multicolumn{1}{c|}{54.2} & 58.0 \\
 & \multirow{1}{*}{TIR}  & 81.7 & \textbf{56.2} & \multicolumn{1}{c|}{69.0} & 87.8 & 77.8 & 30.5 & \textbf{21.9} & \multicolumn{1}{c|}{54.5} & 59.3 \\
 & \multirow{1}{*}{\method}  & 84.0 & 55.1 & \multicolumn{1}{c|}{\textbf{69.6}} & \textbf{91.8} & \textbf{82.7} & \textbf{34.2} & 21.5 & \multicolumn{1}{c|}{\textbf{57.6}} & \textbf{61.5} \\
 \midrule
\multirow{3}{*}{Qwen2.5Math-1.5B} & \multirow{1}{*}{CoT}  & 83.1 & 56.6 & \multicolumn{1}{c|}{69.8} & 92.9 & 84.1 & \textbf{44.3} & 19.3 & \multicolumn{1}{c|}{60.2} & 63.4 \\
 & \multirow{1}{*}{TIR}  & 78.8 & \textbf{64.8} & \multicolumn{1}{c|}{71.8} & 92.3 & 83.3 & 42.4 & \textbf{27.4} & \multicolumn{1}{c|}{61.4} & 64.8 \\
 & \multirow{1}{*}{\method}  & \textbf{83.2} & 62.8 & \multicolumn{1}{c|}{\textbf{73.0}} & \textbf{94.0} & \textbf{85.6} & 43.9 & 26.8 & \multicolumn{1}{c|}{\textbf{62.6}} & \textbf{66.0} \\
 \midrule
\multirow{3}{*}{Qwen2.5Math-7B} & \multirow{1}{*}{CoT}  & \textbf{91.0} & 61.5 & \multicolumn{1}{c|}{76.2} & 94.8 & 87.9 & 45.7 & 23.9 & \multicolumn{1}{c|}{63.1} & 67.5 \\
 & \multirow{1}{*}{TIR}  & 88.9 & \textbf{73.6} & \multicolumn{1}{c|}{81.2} & \textbf{95.4} & \textbf{89.4} & 47.1 & 35.3 & \multicolumn{1}{c|}{66.8} & 71.6 \\
 & \multirow{1}{*}{\method}  & 89.8 & 73.0 & \multicolumn{1}{c|}{\textbf{81.4}} & 95.2 & 88.1 & \textbf{48.3} & \textbf{35.9} & \multicolumn{1}{c|}{\textbf{66.9}} & \textbf{71.7} \\
 \bottomrule
\end{tabular}
  }
  \caption{The accuracies (\%) of our {\method} framework, comparing with CoT and TIR methods. The best accuracies within each group are shown in \textbf{bold}.
  % , while the second-best results are \underline{underlined}. 
  % The three metrics, ``Acc'', ``Token'', and ``\# Code'' represent the average accuracy, total tokens per generation, and number of code executions. 
  % ``Acc'' is reported in \%. 
  ``ID AVG'', ``OOD AVG'', and ``AVG'' denote the averages of these metrics across in-domain, out-of-domain, and all six benchmarks. 
  ``CoT'', ``TIR'', and ``{\method}'' indicate fine-tuning exclusively on CoT data, TIR data, and using our {\method} framework, respectively, with the corresponding base LLM.}
  \label{tab:main-results}
  %\vspace{-15pt}
\end{table*}

\begin{table}[ht!]
\resizebox{\linewidth}{!}{
  \footnotesize
  \centering
\begin{tabular}{@{}lllll@{}}
\toprule
Model & Method & Acc$\uparrow$ & Token$\downarrow$ & \# Code$\downarrow$ \\ \midrule
% \multirow{3}{*}{Qwen2.5-0.5B} & \method & 45.0 & 428.8 & 1.59 \\
%  & CoT & 44.4\textcolor{negative}{$_{-0.6}$} & 437.9\textcolor{negative}{$_{+9.1}$} & 0\textcolor{positive}{$_{-1.59}$} \\
%  & TIR & 42.4\textcolor{negative}{$_{-2.6}$} & 438\textcolor{negative}{$_{+9.2}$} & 2.92\textcolor{negative}{$_{+1.33}$} \\ \midrule
% \multirow{3}{*}{Qwen2.5-1.5B} & \method & 60.4 & 386.1 & 1.34 \\
%  & CoT & 58.9\textcolor{negative}{$_{-1.5}$} & 394\textcolor{negative}{$_{+7.9}$} & 0\textcolor{positive}{$_{-1.34}$} \\
%  & TIR & 58.7\textcolor{negative}{$_{-1.7}$} & 418.8\textcolor{negative}{$_{+32.7}$} & 2.84\textcolor{negative}{$_{+1.50}$} \\ \midrule
\multirow{3}{*}{Qwen2.5-3B} & \method & 65.3 & 383.4 & 1.43 \\
 & CoT & 62.9\textcolor{negative}{$_{-2.4}$} & 385.2\textcolor{negative}{$_{+1.8}$} & 0\textcolor{positive}{$_{-1.43}$} \\
 & TIR & 62.9\textcolor{negative}{$_{-2.4}$} & 411.3\textcolor{negative}{$_{+27.9}$} & 2.8\textcolor{negative}{$_{+1.37}$} \\ \midrule
\multirow{3}{*}{Qwen2.5-7B} & \method & 68.5 & 369.1 & 1.4 \\
 & CoT & 66.2\textcolor{negative}{$_{-2.3}$} & 378.2\textcolor{negative}{$_{+9.1}$} & 0\textcolor{positive}{$_{-1.40}$} \\
 & TIR & 67.8\textcolor{negative}{$_{-0.7}$} & 393.2\textcolor{negative}{$_{+24.1}$} & 2.63\textcolor{negative}{$_{+1.23}$} \\ \midrule
\multirow{3}{*}{LLaMA-3-8B} & \method & 61.5 & 371.7 & 1.32 \\
 & CoT & 58\textcolor{negative}{$_{-3.5}$} & 386\textcolor{negative}{$_{+14.3}$} & 0\textcolor{positive}{$_{-1.32}$} \\
 & TIR & 59.3\textcolor{negative}{$_{-2.2}$} & 392.5\textcolor{negative}{$_{+20.8}$} & 2.66\textcolor{negative}{$_{+1.34}$} \\ \midrule
\multirow{3}{*}{Qwen2.5Math-1.5B} & \method & 66.0 & 405.4 & 1.08 \\
 & CoT & 63.4\textcolor{negative}{$_{-2.6}$} & 388.5\textcolor{negative}{$_{+16.9}$} & 0\textcolor{positive}{$_{-1.08}$} \\
 & TIR & 64.8\textcolor{negative}{$_{-1.2}$} & 460.1\textcolor{negative}{$_{+54.7}$} & 3.23\textcolor{negative}{$_{+2.15}$} \\ \midrule
\multirow{3}{*}{Qwen2.5Math-7B} & \method & 71.7 & 393.8 & 1.26 \\
 & CoT & 67.5\textcolor{negative}{$_{-4.2}$} & 379.9\textcolor{negative}{$_{+13.9}$} & 0\textcolor{positive}{$_{-1.26}$} \\
 & TIR & 71.6\textcolor{negative}{$_{-0.1}$} & 417.8\textcolor{negative}{$_{+24.0}$} & 2.68\textcolor{negative}{$_{+1.42}$} \\ \bottomrule
\end{tabular}
}
\caption{Results of inference costs. The three metrics, ``Acc'', ``Token'', and ``\# Code'' represent the average accuracy (\%), total tokens per generation, and number of code executions.}
  \label{tab:efficiency}
\end{table}

\section{Experimental Results}\label{sec:exp}

\subsection{Experimental Setup}\label{sec:exp_setup}

\paragraph{{\method} Implementation}

We select the training sets from GSM8K \citep{gsm8k2021cobbe} and Math \citep{MATH2021hendrycks} as {\dorig}. 
For {\daug}, we use the DART-Math-Hard dataset \citep{dartmath2024tong}.
%, which comprises approximately 0.5 million training examples formatted in chain-of-thought (CoT) style.  
We employ \texttt{GPT-4o} to rewrite CoT solutions into TIR format using carefully curated prompts and filter out triplets with anomalous TIR responses (e.g., those that lack a definitive conclusion regarding the final answer).  
For embedding, we use \texttt{text-embedding-ada-002} to encode all queries in {\dd} into 1,536-dimensional vectors. 
We set the size of {\danchor} to 100 for both the GSM8K and Math. 
To save computational cost, we randomly sample one pair of CoT and TIR solutions per candidate query, leading to a new candidate set, {\dcandidatee}.  
For the decision function $\mathcal{H}$, we determine selection criteria based on two quantiles of the distribution of $(S_{\text{CoT}} - S_{\text{TIR}})$. 
More details are provided in Appendix~\ref{app:method_details}.    




\paragraph{Evaluation Benchmarks}
We evaluate our approach using six benchmarks for both in-domain and out-of-domain (OOD) assessment. 
Specifically, we use the GSM8K and MATH test sets for in-domain evaluation.
For OOD evaluation, we include the SVAMP \citep{SVAMP2021patel}, MAWPS \citep{mawps2016koncel}, CollegeMath \citep{CollegeMath2024Tang}, and OlympiadBench-Math \citep{OlympiadBench2024He} (details in Appendix~\ref{app:benchmarks})
%A brief introduction to these benchmarks is provided in Appendix~\ref{app:benchmarks}.



% ACC, number of code execution, average tokens generated
\paragraph{Evaluation Metrics}
In addition to measuring accuracy on various benchmarks, we evaluate the generation time cost using the average number of total tokens per generation and quantify the cost of invoking Python interpreters by the average number of code executions (see Appendix~\ref{app:metric}). 
%Detailed explanations can be found in Appendix~\ref{app:metric}.

\paragraph{Baselines}
We include two widely used SFT approaches as our baselines: SFT exclusively on CoT data and SFT exclusively on TIR data. 
We also investigate several selection methods in Section~\ref{sec:ablation}.

Additional details, including the SFT setup and evaluation setup, are provided in Appendix~\ref{app:sft_setup}.
%\paragraph{SFT Setup}


%\paragraph{Evaluation Setup}


\subsection{Main Results}\label{sec:results}


% 1. cot tir different behavior on different data sets

% 2. How our method behaves
Results presented in Table~\ref{tab:main-results} demonstrate the effectiveness of our proposed {\method} framework, which combines the strengths of CoT and TIR methods for mathematical reasoning tasks. 
Across various base models, model sizes, and benchmarks, {\method} consistently achieves competitive or superior performance compared to standalone CoT and TIR approaches, highlighting its ability to leverage the complementary advantages of both methods.

\paragraph{In-Domain Performance}
For in-domain tasks (GSM8K and MATH), {\method} achieves the highest average accuracy (ID AVG) in most cases, outperforming both CoT and TIR individually. This suggests that the integration of CoT's step-by-step reasoning with TIR's tool-assisted computations enhances the model's ability to solve problems within its training domain. Notably, for larger models such as Qwen2.5-7B and Qwen2.5Math-7B, {\method} achieves ID AVG scores of 78.2\% and 81.4\%, respectively, demonstrating its scalability and effectiveness as model capacity increases.

\paragraph{Out-of-Domain (OOD) Performance}
The OOD results further underscore the robustness of {\method}. Across diverse benchmarks such as MAWPS, SVAMP, CollegeMath, and OlympiadBench, {\method} consistently achieves the highest OOD average scores, indicating its generalizability. 
% For instance, on the challenging OlympiadBench dataset, \method outperforms both CoT and TIR in most cases, achieving up to 35.9\% accuracy with Qwen2.5Math-7B. This suggests that the combination of symbolic reasoning and tool integration helps the model adapt to unfamiliar problem types and domains.


\paragraph{Inference efficiency}
The results in Table~\ref{tab:efficiency} demonstrate that our {\method} not only improves accuracy but also enhances inference efficiency compared to standalone CoT and TIR methods. More detailed results are presented in Table~\ref{tab:full-results}. Across all model sizes, {\method} achieves higher accuracy while maintaining lower token usage and fewer code executions than TIR, and it significantly reduces computational overhead compared to TIR without sacrificing the benefits of tool integration. For instance, with Qwen2.5-7B, {\method} achieves a 2.3\% accuracy improvement over CoT while using 9.1 fewer tokens per generation and only 1.4 code executions, compared to TIR's 2.63 code executions. This balance between accuracy and efficiency highlights {\method}'s ability to streamline reasoning processes, making it a computationally effective solution for mathematical reasoning tasks.

\subsection{Ablation}\label{sec:ablation}
\begin{table}[htbp!]
  
  \footnotesize
  \centering
    \begin{tabular}{@{}l|cccccc@{}}
\toprule
Quantiles & 50, 60 & 40, 60 & 30, 60 & 30, 65$^*$ & 30, 70 \\
\midrule
AVG & 44.8 & 44.8 & 44.9 & \textbf{45.0} & 44.8 \\
\bottomrule
\end{tabular}
  \caption{{\method} is not sensitive to quantiles. * denotes the quantiles we choose for Qwen2.5Math-0.5B.}
  \label{tab:threshold}
\end{table}
% About threshold selection
\paragraph{Quantile selection}
As mentioned in Section~\ref{sec:exp_setup}, the data selection function $\mathcal{H}$ is determined using two quantiles of the distribution ($S_{\text{CoT}}^k - S_{\text{TIR}}^k$) (see Appendix~\ref{app:exp_setup}). 
These quantiles are selected through the grid search. 
As shown in Table~\ref{tab:threshold}, the performance of {\method} is not very sensitive to the choice of these quantiles (see Appendix~\ref{app:exp_setup}). 
%The complete results is provided in Table~\ref{tabapp:threshold} in Appendix~\ref{app:exp_setup}.


% Method ablation: random, cot+pot, gpt-select
% 1. random 2. gpt-select

\paragraph{Ablation with $\mathcal{H}$}
%We conduct an ablation study on the data selection function $\mathcal{H}$, evaluating the following variants:
We evaluate the following variants of $\mathcal{H}$:
1. ``Random'': This variant uses the same ratio of CoT and TIR as {\method}, but the queries are selected randomly. It serves as a strong baseline because it leverages knowledge about the ratio from {\method}.
2. ``CoT + TIR'': This method includes all CoT and TIR solutions for each query without any data selection.
3. ``{\method}$^-$'': This variant uses only a single threshold for selection, employing the same strategy for both GSM8K and MATH datasets.
More details on these variants can be found in Appendix~\ref{app:ablation}. 
From Table~\ref{tab:ablation}, we observe that {\method} achieves the highest overall accuracy. 
Although ``Random'' uses the same ratio of queries relying on either CoT or TIR as {\method}, it lags behind by 0.5\%, underscoring the importance of the base LLM's ability to differentiate between when to use CoT or TIR for different queries. 
Moreover, naively including all CoT and TIR solutions, (i.e. ``CoT + TIR''), results in a noticeable decline in performance, despite the larger size of the {\dsft} dataset. 
This highlights the critical role of effective data selection for CoT and TIR.


\begin{table}[htbp!]

  \footnotesize
  \centering
    \begin{tabular}{@{}l|cccccc@{}}
\toprule
Method & Random & CoT + TIR & {\method}$^-$ & \method \\
\midrule
AVG & 61.0 & 58.2 & 60.2 & \textbf{61.5} \\
\bottomrule
\end{tabular}
  \caption{Ablation Results (in \%).}
  \label{tab:ablation}
\end{table}


% About anchor set ablation
