\section{Related Work}
\textbf{Gaze-based Object Manipulation.} 
Some works have previously proposed imitation learning methods using gaze data collected from a remote human operator during teleoperated demonstrations for action prediction ____. These gaze-based methods have previously exhibited advantages such as enhanced robustness by disregarding task-irrelevant objects ____ and improved dexterity by focusing on task-relevant regions of visual inputs ____. 
However, because these methods rely on image cropping for gaze-centered images, they are susceptible to visual variations caused by changes in object position.
In this study, we employ a gaze-centered point cloud that is robust to positional changes, and our method further improves the reusability of acquired skills for unseen object positions and end-effector poses, in addition to the conventional benefits of gaze.

\textbf{Data-driven Action Segmentation.} 
Segmenting actions into reaching motions and dexterous actions has been proposed to improve dexterity ____, increase success rates for long-horizon tasks ____, and enable high generalization capabilities ____. 
Kim et al. proposed data-driven segmentation methods based on end-effector velocity ____ or the visibility of the end-effector within a gaze-centered image ____. However, these approaches often fail in tasks where high dexterity is not required or when the end-effector is not visible during dexterous actions, such as manipulating with a long stick.
In contrast, our approach segments motions at bottlenecks, which are determined based on action predictivity in the gaze-centered point cloud. 
This action predictivity-based approach offers a more general and data-driven segmentation scheme compared with these previous methods.

\textbf{Generalization to Out-of-Distribution.} 
Generalization to out-of-distribution scenarios is required across diverse levels and factors ____, including adaptation to a variety of object poses and unseen objects in the same category ____, to changes in the environment such as varying backgrounds, camera positions, or distractor objects ____, and to entirely novel objects and tasks ____. 
However, to the best of our knowledge, there have been no studies examining enhanced generalization to out-of-distribution object positions or end-effector poses, which is the main focus of this study.
In other words, our proposed GazeBot is the first method in the general deep imitation learning framework to demonstrate the high reusability of imitated skills even under unseen object positions and end-effector poses.
Although several methods exhibit similarities with GazeBot, they have not successfully demonstrated such high reusability, primarily owing to issues in the design of the action policy. 
Hydra ____ and SPHINX ____, for instance, segment actions into a reaching phase and a dexterous action phase, using sparse action representations similar to a bottleneck pose for the reaching motion. 
However, in contrast to GazeBot, these sparse representations are directly estimated by a neural network from entire images and the end-effector poses, and dexterous action prediction also relies on absolute information such as the end-effector poses or entire images. As we will see in Section \ref{sec:experiments}, these design changes hinder the accurate extrapolation of the reaching motions and reduce the reusability of the learned dexterous actions when faced with unseen object positions or end-effector poses.