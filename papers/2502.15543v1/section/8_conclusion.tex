\section{Conclusion}
In this paper, we propose \method{}, a novel paradigm for mitigating knowledge conflicts in LLM-based KAG systems. Our approach employs a neuron activation-based pruning method to selectively remove parametric knowledge, followed by the integration of a plug-and-play module that adjusts the modelâ€™s preference toward external information. 

%Extensive experiments on \dataset{} and ConFiQA demonstrate the effectiveness, generalization capability, and parameter efficiency of \method{}. %Further analysis shows that \method{} successfully uninstalls outdated parametric knowledge while enhancing the model's ability to leverage external knowledge. We hope that \method{} will inspire future advancements in KAG systems, particularly in further improving their parameter efficiency.