\section{Introduction}
Large Language Models (LLMs), such as GPT-4~\cite{openai2023gpt} and LLaMA~\cite{touvron2023llama}, have demonstrated remarkable performance across numerous NLP tasks by leveraging their parametric knowledge~\cite{wei2022emergent,zhao2023survey}. However, the parametric knowledge within LLMs is inherently static, making it susceptible to becoming outdated over time. This limitation often leads to hallucinations~\cite{huang2023survey,elazar2021measuring} and inaccurate responses~\cite{ji2023survey,shuster2021retrieval}, significantly hindering their applicability in real-world scenarios.


\begin{figure}[!t]
    \centering
    % \input{tmp}
    \includegraphics[width=0.48\textwidth]{figs/introduction.pdf}
  \caption{Illustration of \method{}. \method{} first uninstalls internal knowledge within LLMs through parameter pruning. Next, an adaptation module is introduced to enhance the ability of LLMs to utilize external knowledge, resulting in more reliable responses.}
  \label{fig:intro}
% \vspace{-1.5em}
\end{figure}


To address this issue, Knowledge-Augmented Generation (KAG) has been introduced, which integrates external knowledge from tools, such as retrievers and search engines, allowing LLMs to access up-to-date information during generation. Nevertheless, this approach gives rise to the knowledge conflict problem~\cite{longpre2021entity,xu2024knowledge}, where external knowledge may contradict the internal memory of LLMs. These conflicts degrade the reliability and effectiveness of KAG systems~\cite{yu2022generate,chen2023benchmarking}. 

To mitigate these conflicts, various strategies have been proposed, such as encouraging models to rely more on external information through prompt engineering~\cite{yu2023chain, zhou2023context}, incorporating context during training~\cite{lin2023ra, li2022large}, or employing context-aware decoding techniques~\cite{huang2025dynamic, yuan2024discerning, wang2024adacad, bi2024context}. While these methods can partially steer models toward better utilization of external knowledge~\cite{li2022large}, their overall impact remains limited~\cite{goyal2024context,bi2024context}. LLMs' strong reliance on parametric knowledge~\cite{tan2024blinded,longpre2021entity} continues to influence the generation process~\cite{tao2024context}, suggesting that simply guiding models to use external knowledge is insufficient.


Motivated by the intuition that ``forgetting'' parametric knowledge can reduce conflicts with external information, enabling the model to better utilize the provided knowledge. As shown in Figure~\ref{fig:intro}, we propose \textbf{P}arametr\textbf{I}c \textbf{P}runing-based \textbf{K}nowledge-\textbf{A}ugmented \textbf{G}eneration (\method{}), a novel framework for resolving knowledge conflicts. Specifically, \method{} first identifies and locates parametric knowledge through neuron inhibition after incorporating the knowledge into the input context for LLMs. Then we conduct a knowledge uninstallation process, which removes these identified parameters via pruning. A plug-and-play knowledge preference calibration module is then applied to the pruned LLM, strengthening the model's reliance on external knowledge and ultimately yielding more accurate and trustworthy responses.


To thoroughly evaluate \method{}, we construct \dataset{}, a benchmark built based on the hallucination and knowledge conflict of LLMs. Additionally, we validate the generalization ability of \method{} by estimating its effectiveness on the ConFiQA benchmark. Experimental results demonstrate that \method{} outperforms all baseline models across both datasets, achieving significant improvements in context faithfulness and knowledge conflict resolution. Additional analyses confirm that \method{} effectively uninstalls parametric knowledge and recalibrates the model's preference towards external knowledge. By combining both knowledge uninstallation and the knowledge preference adaptation module, \method{} enables KAG systems to manage knowledge updates externally, aligning with the growing demand for modular and scalable LLMs. Consequently, \method{} also provides some valuable insights for building parameter-efficient LLMs~\cite{asai2024reliable} within the KAG framework.
