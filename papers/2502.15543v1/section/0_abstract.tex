\begin{abstract}

Knowledge-Augmented Generation (KAG) has shown great promise in updating the internal memory of Large Language Models (LLMs) by integrating external knowledge. However, KAG inevitably faces knowledge conflicts when the internal memory contradicts external information. Current approaches to mitigating these conflicts mainly focus on improving external knowledge utilization. However, these methods have shown only limited effectiveness in mitigating the knowledge conflict problem, as internal knowledge continues to influence the generation process of LLMs. In this paper, we propose a \textbf{P}arametr\textbf{I}c \textbf{P}runing-based \textbf{K}nowledge-\textbf{A}ugmented \textbf{G}eneration (\method{}) approach, which prunes internal knowledge of LLMs and incorporates a plug-and-play adaptation module to help LLMs better leverage external sources. Additionally, we construct the \dataset{} benchmark based on the hallucination of LLMs to better evaluate contextual faithfulness during answering questions. Experimental results on \dataset{} demonstrate that \method{} significantly reduces knowledge conflicts and improves context fidelity. Notably, \method{} reduces LLM's parameters by 13\%, enhancing parameter efficiency in LLMs within the KAG framework. All codes are available at \url{https://github.com/OpenBMB/PIP-KAG}.


\end{abstract}