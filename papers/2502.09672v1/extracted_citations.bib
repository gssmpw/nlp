@article{240313443FastPolyFast,
  title={Fast-Poly: A Fast Polyhedral Algorithm For 3D Multi-Object Tracking},
  author={Li, Xiaoyu and Liu, Dedong and Wu, Yitao and Wu, Xian and Zhao, Lijun and Gao, Jinghan},
  journal={IEEE Robotics and Automation Letters},
  year={2024},
  publisher={IEEE}
}

@inproceedings{benbarkaScoreRefinementConfidencebased2021,
  title = {Score Refinement for Confidence-Based {{3D}} Multi-Object Tracking},
  booktitle = {2021 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Benbarka, Nuri and Schr{\"o}der, Jona and Zell, Andreas},
  year = {2021},
  month = sep,
  pages = {8083--8090},
  issn = {2153-0866},
  doi = {10.1109/IROS51168.2021.9636032},
  urldate = {2024-08-29},
  abstract = {Multi-object tracking is a critical component in autonomous navigation, as it provides valuable information for decision-making. Many researchers tackled the 3D multi-object tracking task by filtering out the frame-by-frame 3D detections; however, their focus was mainly on finding useful features or proper matching metrics. Our work focuses on a neglected part of the tracking system: score refinement and tracklet termination. We show that manipulating the scores depending on time consistency while terminating the tracklets depending on the tracklet score improves tracking results. We do this by increasing the matched tracklets' score with score update functions and decreasing the unmatched tracklets' score. Compared to count-based methods, our method consistently produces better AMOTA and MOTA scores when utilizing various detectors and filtering algorithms on different datasets. The improvements in AMOTA score went up to 1.83 and 2.96 in MOTA. We also used our method as a late-fusion ensembling method, and it performed better than voting-based ensemble methods by a solid margin. It achieved an AMOTA score of 67.6 on nuScenes test evaluation, which is comparable to other state-of-the-art trackers. Code is publicly available at: https://github.com/cogsys-tuebingen/CBMOT.},
  langid = {american},
  keywords = {Detectors,Filtering,Filtering algorithms,Measurement,Pipelines,Solids,Three-dimensional displays},
  file = {C\:\\Users\\Administrator\\Zotero\\storage\\F7539STX\\Benbarka 等 - 2021 - Score refinement for confidence-based 3D multi-obj.pdf;C\:\\Users\\Administrator\\Zotero\\storage\\WIVI5UTV\\9636032.html}
}

@inproceedings{bodlaSoftNMSImprovingObject2017,
  title = {Soft-{{NMS}} -- {{Improving Object Detection With One Line}} of {{Code}}},
  booktitle = {Proceedings of the {{IEEE International Conference}} on {{Computer Vision}}},
  author = {Bodla, Navaneeth and Singh, Bharat and Chellappa, Rama and Davis, Larry S.},
  year = {2017},
  pages = {5561--5569},
  urldate = {2024-10-19},
  langid = {american},
  keywords = {NMS},
  file = {C:\Users\Administrator\Zotero\storage\625Y8EQY\Bodla 等 - 2017 - Soft-NMS -- Improving Object Detection With One Li.pdf}
}

@InProceedings{chenLargeKernel3DScalingKernels2023,
    author    = {Chen, Yukang and Liu, Jianhui and Zhang, Xiangyu and Qi, Xiaojuan and Jia, Jiaya},
    title     = {LargeKernel3D: Scaling Up Kernels in 3D Sparse CNNs},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2023},
    pages     = {13488-13498}
}

@inproceedings{liPolyMOTPolyhedralFramework2023,
  title={Poly-mot: A polyhedral framework for 3d multi-object tracking},
  author={Li, Xiaoyu and Xie, Tao and Liu, Dedong and Gao, Jinghan and Dai, Kun and Jiang, Zhiqiang and Zhao, Lijun and Wang, Ke},
  booktitle={2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={9391--9398},
  year={2023},
  organization={IEEE}
}

@inproceedings{liuAdaptiveNMSRefining2019,
  title = {Adaptive {{NMS}}: {{Refining Pedestrian Detection}} in a {{Crowd}}},
  shorttitle = {Adaptive {{NMS}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Liu, Songtao and Huang, Di and Wang, Yunhong},
  year = {2019},
  pages = {6459--6468},
  urldate = {2024-10-19},
  keywords = {NMS},
  file = {C:\Users\Administrator\Zotero\storage\MLNNCSRN\Liu 等 - 2019 - Adaptive NMS Refining Pedestrian Detection in a C.pdf}
}

@inproceedings{pangSimpleTrackUnderstandingRethinking2021,
  title={Simpletrack: Understanding and rethinking 3d multi-object tracking},
  author={Pang, Ziqi and Li, Zhichao and Wang, Naiyan},
  booktitle={European Conference on Computer Vision},
  pages={680--696},
  year={2022},
  organization={Springer}
}

@INPROCEEDINGS{weng3DMultiObjectTracking2020,
  author={Weng, Xinshuo and Wang, Jianren and Held, David and Kitani, Kris},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={3D Multi-Object Tracking: A Baseline and New Evaluation Metrics}, 
  year={2020},
  volume={},
  number={},
  pages={10359-10366},
  keywords={Measurement;Three-dimensional displays;Two dimensional displays;Tools;Solids;Real-time systems;State estimation},
  doi={10.1109/IROS45743.2020.9341164}}

@INPROCEEDINGS{wojkeSimpleOnlineRealtime2017,
  author={Wojke, Nicolai and Bewley, Alex and Paulus, Dietrich},
  booktitle={2017 IEEE International Conference on Image Processing (ICIP)}, 
  title={Simple online and realtime tracking with a deep association metric}, 
  year={2017},
  volume={},
  number={},
  pages={3645-3649},
  keywords={Kalman filters;Tracking;Extraterrestrial measurements;Standards;Uncertainty;Cameras;Computer Vision;Multiple Object Tracking;Data Association},
  doi={10.1109/ICIP.2017.8296962}}

@InProceedings{xiePolyPCPolyhedralNetwork2023,
    author    = {Xie, Tao and Wang, Shiguang and Wang, Ke and Yang, Linqi and Jiang, Zhiqiang and Zhang, Xingcheng and Dai, Kun and Li, Ruifeng and Cheng, Jian},
    title     = {Poly-PC: A Polyhedral Network for Multiple Point Cloud Tasks at Once},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2023},
    pages     = {1233-1243}
}

@InProceedings{yinCenterbased3DObject2021,
    author    = {Yin, Tianwei and Zhou, Xingyi and Krahenbuhl, Philipp},
    title     = {Center-Based 3D Object Detection and Tracking},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {11784-11793}
}

@InProceedings{zhang2022bytetrack,
author="Zhang, Yifu
and Sun, Peize
and Jiang, Yi
and Yu, Dongdong
and Weng, Fucheng
and Yuan, Zehuan
and Luo, Ping
and Liu, Wenyu
and Wang, Xinggang",
editor="Avidan, Shai
and Brostow, Gabriel
and Ciss{\'e}, Moustapha
and Farinella, Giovanni Maria
and Hassner, Tal",
title="ByteTrack: Multi-object Tracking by Associating Every Detection Box",
booktitle="Computer Vision -- ECCV 2022",
year="2022",
publisher="Springer Nature Switzerland",
address="Cham",
pages="1--21",
abstract="Multi-object tracking (MOT) aims at estimating bounding boxes and identities of objects in videos. Most methods obtain identities by associating detection boxes whose scores are higher than a threshold. The objects with low detection scores, e.g. occluded objects, are simply thrown away, which brings non-negligible true object missing and fragmented trajectories. To solve this problem, we present a simple, effective and generic association method, tracking by associating almost every detection box instead of only the high score ones. For the low score detection boxes, we utilize their similarities with tracklets to recover true objects and filter out the background detections. When applied to 9 different state-of-the-art trackers, our method achieves consistent improvement on IDF1 score ranging from 1 to 10 points. To put forwards the state-of-the-art performance of MOT, we design a simple and strong tracker, named ByteTrack. For the first time, we achieve 80.3 MOTA, 77.3 IDF1 and 63.1 HOTA on the test set of MOT17 with 30 FPS running speed on a single V100 GPU. ByteTrack also achieves state-of-the-art performance on MOT20, HiEve and BDD100K tracking benchmarks. The source code, pre-trained models with deploy versions and tutorials of applying to other trackers are released at https://github.com/ifzhang/ByteTrack.",
isbn="978-3-031-20047-2"
}

