

\section{Scalability-Fidelity Tradeoff}\label{sec_nerf2_tradeoff}

This section presents a theoretical analysis of the inefficiencies of \nerft, followed by an empirical evaluation.


\subsection{Theoretical Analysis}\label{sec_theoretical_ana}
Two main factors cause the its low efficiency:

\subsubsection{Vast Number of Voxels}  
The large number of voxels in a scene requires learning their attributes. 
For example, in a conference room \(26.2\,\textit{ft} \times 16.4\,\textit{ft} \times 9.8\,\textit{ft}\)~\cite{matlab_conference_room}, with the voxel size set to \(1/8\) of the wavelength~(the default setting in \nerft â€” \(0.016\,\text{m}\) for \(2.4\,\text{GHz}\) WiFi), there are approximately 31,257,628 voxels.  
Consequently, a large number of received signals from diverse transmitter locations is required to cover as many of these voxels as possible.


\subsubsection{Intensive Querying of Large MLPs}
In \nerft, all voxels share a single MLP with a large number of parameters~(\eg 690,564) to capture variations among them. 
This large MLP introduces significant computational overhead. 
During ray tracing, each ray intersects multiple voxels, and the attributes of each voxel are computed by querying the MLP with input~\(\{x, y, z, \alpha, \beta, x_{\text{tx}}, y_{\text{tx}}, z_{\text{tx}}\}\).
Repeatedly querying the MLP for numerous voxels introduces high computational costs, slowing down both training and inference.



\subsection{Empirical Evaluation}
We conduct experiments to evaluate the efficiency of \nerft\ using the RFID spatial spectrum dataset described in Section~\ref{sec_overall_rfid}.  
The dataset consists of 6,123 transmitter positions and their corresponding received spatial spectrum at a fixed receiver equipped with an antenna array.



\subsubsection{Data Efficiency}
Efficient models require less training data while maintaining accuracy~\cite{han2015learning, hsieh2023distilling, karras2020training}.  
Reducing training data simplifies data collection and accelerates deployment, enhancing scalability across various applications~\cite{menghani2023efficient}.  
For example, in network planning, fewer training samples reduce the effort required to map the signal environment, enabling faster network setup and optimization~\cite{yin2022practical}.


Data density is defined as the total amount of training data divided by the volume of the 3D scene, measured in \(\text{measurements}/\text{ft}^3\).
We set seven densities~(0.8, 1.6, 3.1, 4.7, 7.8, 12.4, and 15.5) to train \nerft separately and evaluate each trained model on the same testing dataset.
The fidelity of the synthesized spectrum is assessed using the Peak Signal-to-Noise Ratio~(PSNR) metric, as the spectrum can be viewed as an image~(Figure~\ref{fig_vis_d1}).
Figure~\ref{fig_motivation_data} demonstrates that increasing measurement density improves the fidelity of the synthesized spectrum.  
When the measurement density reaches 12.4 or 15.5, the PSNR converges, indicating that a minimum density of 12.4 is required.  
This high data requirement is burdensome, making the data collection process resource-intensive.




\subsubsection{Training GPU-hours}
Efficient models would exhibit short training GPU-hours~\cite{neil2016learning, liu2020training, goyal2017accurate}. 
For example, in fingerprint-based localization tasks, rapid training of RF signal propagation models enables quick data synthesis for updating the fingerprint database.
This allows the database to adapt swiftly to changes in layouts, furniture arrangements, or interference sources, thereby maintaining localization accuracy with minimal delays.
Moreover, shorter training GPU-hours help conserve computational resources.


Figure~\ref{fig_motivation_train_inference} illustrates the training time required for \nerft to converge using NVIDIA GeForce RTX 3080 Ti or 4090 GPUs.  
The average training time is 5.01\,hours with a standard deviation of 0.38\,hours, which is considerably long.  
These prolonged training times delay fingerprint database updates and demand substantial computational resources.




\subsubsection{Inference Latency}
Efficient models are characterized by low inference latency~\cite{fu2024serverlessllm, wang2024minimizing, zhang2021deepslicing}.
In real-time applications, such as channel prediction in 5G, inference latency must be shorter than the coherence time~\cite{liu2021fire},  
which represents the interval over which the channel remains relatively constant~\cite{liu2021fire}.  
The average inference latency of \nerft, depicted in Figure~\ref{fig_motivation_train_inference}, is 352.73\,ms.
This far exceeds the coherence time of 50\,ms for a moving transmitter~\cite{marzetta2016fundamentals}.


\begin{figure}[t]
	\begin{minipage}[t]{0.48\linewidth} 
    	\includegraphics[width=\textwidth]{figs/psnr_ratio.pdf}
\caption{Training data efficiency of \nerft~\cite{zhao2023nerf}.}
        \label{fig_motivation_data}
	\end{minipage}
 \hspace{0.04in}
 	\begin{minipage}[t]{0.48\linewidth} 
    	\includegraphics[width=\textwidth]{figs/training_inference.pdf}
\caption{Training~(hours) and inference times~(ms).}
        \label{fig_motivation_train_inference}
	\end{minipage}
 \Description[]{}
\end{figure}



