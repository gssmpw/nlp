\section{Related Work}
\label{related}
The challenges of achieving robust and efficient model training in decentralized financial environments**Hale, "Federated Learning for Financial Risk Management"** have driven advancements in financial risk management and sensitivity analysis**Chen et al., "Sensitivity Analysis for Federated Learning"**. FL has emerged as a powerful approach for decentralized model training, allowing multiple clients to collaborate while preserving data privacy. However, these methods often struggle with model divergence in financial applications, where client datasets exhibit significant variability due to diverse market conditions and operational priorities. Statistical heterogeneity remains a key challenge, as differences in local data distributions introduce non-IID effects that lead to training drift and performance degradation**Kairouz et al., "Advances and Challenges in Federated Learning"**.


To address these limitations, several approaches have been developed. Convergence analyses**Li et al., "Convergence Analysis of Distributed Stochastic Gradient Descent"** and bounded gradient techniques**Reddi et al., "A Bounded Gradient Algorithm for Distributed Optimization"** provide theoretical insights into stabilizing training under heterogeneous conditions. FedProx**McMahan et al., "Federated Learning with Low-Tarffic Overhead"** mitigates data heterogeneity by incorporating a proximal term in local objectives, while SCAFFOLD**Karimireddy et al., "Scaffold: Designing Parallel Algorithms for Deep Learning on Multi-GPU or Model Parallel Training"** employs variance reduction techniques to correct client drift. Communication efficiency has also been extensively studied, with dynamic client sampling strategies proposed to reduce overhead**Liu et al., "Dynamic Client Sampling for Federated Learning"**. However, existing methods often overlook the impact of random client availability, which introduces variance, destabilizes convergence, and limits performance in real-world FL scenarios.

Sensitivity analysis has long been a fundamental tool for evaluating model robustness by quantifying how small perturbations in parameters influence outputs**Kunstner et al., "Differential Sensitivity Measures for Deep Neural Networks"**. While gradients are widely used in deep learning for optimization, their role in robustness assessment and federated interpretability has been less explored**Huang et al., "Interpreting Deep Learning Models via Gradients"**. Recent advancements in differential sensitivity measures extend traditional gradient-based methods by capturing the evolution of training dynamics, providing deeper insights into stability, generalization, and risk exposure in model behavior**Rao et al., "Differential Sensitivity Measures for Robustness Assessment"**. These measures have shown promise in mitigating performance degradation under distribution shifts by enabling adaptive adjustments during optimization. However, existing FL frameworks rarely incorporate sensitivity-aware strategies, limiting their ability to handle heterogeneous client distributions effectively. Our work builds on these developments by integrating differential sensitivity estimation into federated learning, addressing both robustness and scalability challenges in decentralized financial systems.


Recent research in FL has focused on addressing challenges such as model heterogeneity, representation degeneration, and personalization. For instance, FedPAC**Li et al., "Federated Personalized Learning with Alignment-based Classifier"** enhances feature alignment through a shared representation and personalized classifier heads but faces limitations due to its computational overhead and reliance on stable client participation. FedDBE**Wang et al., "FedDBE: Federated Domain Bias Elimination for Heterogeneous Data"** tackles domain discrepancies by employing a Domain Bias Eliminator to improve generalization and personalization, although it struggles with scalability under resource-constrained environments. Similarly, FedGH**Kairouz et al., "FedGH: Federated Gradient Hopping for Personalized Model Updates"** provides a communication-efficient approach to handle model heterogeneity by training a generalized global prediction header; however, its reliance on consistent client availability undermines its robustness in dynamic conditions. While these methods demonstrate effectiveness in specific contexts, they often fall short in addressing the combined demands of robustness, scalability, and data heterogeneity inherent in large-scale decentralized systems, which are critical for financial decision-making.


Our work addresses these limitations by introducing a novel FL framework that integrates distortion risk measures with differential sensitivity analysis. Unlike traditional FL methods that rely on local updates and suffer from client drift under heterogeneous data distributions, FRAL-CSE introduces a sensitivity-aware optimization strategy. By leveraging aggregated sensitivity measures, our approach enables more precise global model updates, mitigating local inconsistency while preserving decentralized autonomy. This design improves the stability of federated training without compromising adaptability, allowing FRAL-CSE to scale efficiently in dynamic financial environments.