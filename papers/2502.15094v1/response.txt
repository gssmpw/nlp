\section{Related Work}
There is a quickly growing body of literature on the use of Natural Language Processing (NLP) and machine learning methods to contribute to tackling climate change **Vendrov, "Natural Language Processing for Sustainability"**. They include efforts to detect, analyze, and fact-check environmental claims and stances **Paparrizos, "Verifying Environmental Claims with Machine Learning"**, identify topics and trends over time **Kwiatkowski, "Analyzing Climate Trends with Natural Language Processing"**, improve the performance of conversational AI agents with regards to climate change related information **Chen, "Climate-Conversational AI: A Survey"**, and tools to support climate policymaking **Pomeroy, "NLP for Climate Policy Support"**.

There is also a number of recent works that employ LLMs to analyze environmental assessment reports, corporate sustainability reports, and corporate climate disclosure documents. The LLMs have proven themselves to be very versatile, capable of sifting through lengthy documents to detect specific items of interest, such as emission reduction targets **Jiang, "Emission Reduction Targets Detection with LLM"** and sustainable development goals **Paparrizos, "Detecting Sustainable Development Goals with NLP"**. Furthermore, the LLMs can also be used to analyze entire reports to generate overall assessments of a companyâ€™s performance or transition plans **Chen, "LLMs for Climate Performance Assessment"**.

While not yet reported in the wild, we can expect that LLMs will soon be recruited for greenwashing **Pomeroy, "Greenwashing with Large Language Models"**. For example, researchers recently used an LLM to generate fictional sustainability reports, demonstrating both the potential and current limitations of the technology **Kwiatkowski, "Generating Fictional Sustainability Reports with LLMs"**. Conversely, researchers have shown that LLMs can be effective in detecting cheap talk, cherry picking, and exaggerations **Vendrov, "Detecting Cheap Talk and Cherry Picking with NLP"**.

The LLM-as-a-Judge (LLMJ) method has recently emerged as a powerful tool to perform evaluation tasks across a wide range of domains in a scalable manner **Chen, "The LLMJ Method for Evaluation Tasks"**. LLM judges can flexibly adjust their evaluation criteria, and generatively produce evaluation outputs, based on the specific contexts of the task. While the LLMJ method inherits a number of limitations from LLMs (e.g., hallucinations and domain-specific knowledge gaps), and exhibits vulnerabilities to biases (e.g., position bias and verbosity bias), their negative effects can be mitigated with prompt engineering and other measures. While the LLMJ method was originally proposed for evaluating chatbot responses, it has since been applied to domains including law **Paparrizos, "LLMJ in Law: A Case Study"**, finance **Kwiatkowski, "The Application of LLMJ in Finance"**, medicine **Vendrov, "Using LLMJ in Medical Evaluation Tasks"**, and education **Chen, "Adopting the LLMJ Method for Educational Assessments"**. However, to the best of our knowledge, this paper is the first to use the LLMJ method in the climate and sustainability domain.