\section{Related Work}
There is a quickly growing body of literature on the use of Natural Language Processing (NLP) and machine learning methods to contribute to tackling climate change \cite{stede2021climate,rolnick2022tackling}. They include efforts to detect, analyze, and fact-check environmental claims and stances \cite{leippold2023environmental,luo2020detecting,coan2021computer,piskorski2022exploring,gehring2023analyzing,diggelmann2020climate}, identify topics and trends over time \cite{yim2023meticulously,brie2024mandatory}, improve the performance of conversational AI agents with regards to climate change related information \cite{webersinke2021climatebert,vaghefi2023chatclimate,bulian2023assessing}, and tools to support climate policymaking \cite{callaghan2021machine,planas2022beyond}.

There is also a number of recent works that employ LLMs to analyze environmental assessment reports, corporate sustainability reports, and corporate climate disclosure documents. The LLMs have proven themselves to be very versatile, capable of sifting through lengthy documents to detect specific items of interest, such as emission reduction targets \cite{schimanski2023climatebert} and sustainable development goals \cite{garigliotti2024sdg}. Furthermore, the LLMs can also be used to analyze entire reports to generate overall assessments of a companyâ€™s performance or transition plans \cite{ni2023chatreport,colesanti2024combining}.

While not yet reported in the wild, we can expect that LLMs will soon be recruited for greenwashing \cite{moodaley2023greenwashing}. For example, researchers recently used an LLM to generate fictional sustainability reports, demonstrating both the potential and current limitations of the technology \cite{de2024will}. Conversely, researchers have shown that LLMs can be effective in detecting cheap talk, cherry picking, and exaggerations \cite{bingler2022cheap,luo2024unmasking}. 

The LLM-as-a-Judge (LLMJ) method has recently emerged as a powerful tool to perform evaluation tasks across a wide range of domains in a scalable manner \cite{zheng2023judging}. LLM judges can flexibly adjust their evaluation criteria, and generatively produce evaluation outputs, based on the specific contexts of the task. While the LLMJ method inherits a number of limitations from LLMs (e.g., hallucinations and domain-specific knowledge gaps), and exhibits vulnerabilities to biases (e.g., position bias and verbosity bias), their negative effects can be mitigated with prompt engineering and other measures. While the LLMJ method was originally proposed for evaluating chatbot responses, it has since been applied to domains including law \cite{yue2023disc}, finance \cite{son2024krx}, medicine \cite{xie2024doclens}, and education \cite{chiang2024large,wang2024automated}. However, to the best of our knowledge, this paper is the first to use the LLMJ method in the climate and sustainability domain.