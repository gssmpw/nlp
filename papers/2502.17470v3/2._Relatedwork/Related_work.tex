%In this section, we’ll explore the contrast between state-of-the-art models and self-supervised learning techniques. Our pre-train methods improve the efficiency and advancements of both epoch and sequence domains.

%%%%
\subsection{Spectrogram}
\label{Preliminary}

\begin{figure}
\centerline{\includegraphics[width = 230pt]{Figure/how_to_make_spectrogram_v3_1.png}} 
\caption{A process for generating a spectrogram from a raw signal.}
% Conversion of a time-domain signal into a spectrogram through windowing and FFT
% An spectrogram and a procedure for obtaining it from a raw signal.

\label{how_to_make_spectrogram}
\vspace{-15pt}
\end{figure}

A spectrogram is a two-dimensional representation that describes how the frequency spectrum of a signal changes over time.
Recently, spectrograms have been widely adopted across numerous application fields, including sleep stage classification.
%
%Specifically, the process of transforming raw PSG signals into spectrograms has often been underemphasized in existing literature. Our study aims to fill this gap by providing a detailed and systematic approach to preprocessing spectrogram data.
%
Fig. \ref{how_to_make_spectrogram} shows how we obtain a sample of spectrogram data from an epoch of raw EEG signal data. We use single-channel EEG signals, ``Fpz-Cz" in a SleepEDF-78 dataset and ``C4-A1" in a SHHS dataset.
In this work, the employed signal is denoted by $\text{Sg}_{i,j} \in \mathbb{R}^{C \times 3000}$, where $C=1$. The signals are sampled at 100Hz and segmented into standard epoch samples of 30 seconds (100 data points $\times$ 30 sec = 3000 data points).
This approach aligns with datasets like SHHS, where signals originally sampled at 125Hz are resampled to 100Hz.

Then, we apply Fast Fourier Transforms (FFT) to the signals while adopting a window size of 200 data points (double the frequency) and an overlap of the equal size (100 data points), as recommended in studies like \cite{phan2021xsleepnet,kontras2023coresleep} as shown in Fig. \ref{how_to_make_spectrogram}. So, we have \text{29} time segments for an epoch, and each segment is transformed into a frequency spectrum, which is then normalized between 0 and 128. This setup efficiently captures the spectral characteristics of the EEG data. 

As a post-FFT processing, we implement log-magnitude transformations to normalize variance. Then we have a spectrogram data sample, $\text{Sp}_{i,j} \in \mathbb{R}^{C \times T \times \text{Freq}}$ where $T$ is the number of time segments (it is set to 29) and $\text{Freq}$ is set to 129.

%%%%%%%%%%%%%%%%%%%
\subsection{Sleep stage classification} %%%%%% Section 2-1 Sleep stage classification

Sleep stage classification can be leveraged for diagnosing sleep deficiency or disorders. In this classification, 30-second epochs are classified into several classes. According to the AASM guidelines \cite{berry2012aasm}, there are five classes for the sleep stages: Wake, NREM1, NREM2, NREM3, and REM. The datasets used in this work, SleepEDF-78 and SHHS datasets are labeled following the AASM guidelines.
% original follow -> are labeld following

  
%%
%Automating sleep scoring has begun with various machine learning techniques~\cite{mikkelsen2019accurate}.
%
%Because of the rapid advancement of deep learning techniques, various Deep Neural Network models (DNNs) have been employed for automatic sleep scoring.

%Even though these machine learning techniques work to measure faster than deep learning-based models, the advancement of the deep learning era can optimize network performance by both reducing the model size and enhancing accuracy. Thus, deep learning-based labeling has become popular in sleep. 


As an initial deep learning model for sleep stage classification, CNN-based works are used to recognize patterns in biological signals \cite{sors2018convolutional,phan2018joint} which effectively capture features of each epoch data.
%
On the other hand, Recurrent Neural Networks (RNN) are used to extract sequential features from continuous sleep cycles and predict transitions between stages \cite{michielli2019cascaded,mousavi2019sleepeegnet}. To better exploit the sequential features within a consecutive sequence of epochs, variants such as Long-Short-Term Memory (LSTM) \cite{hochreiter1997long} and Gated Recurrent Units (GRU) \cite{chung2014empirical} are particularly prevalent in sleep stage classification.
%
Those methods, which employ a one-to-one approach \cite{Phan2018_DNNwith1MaxPooling}, suffer from primary drawbacks such as increased training time.

To enhance the efficiency of training steps, a many-to-many framework, such as SleepNet \cite{biswal2017sleepnet}, has been leveraged to predict the loss of multiple sequences.
%
DeepSleepNet \cite{supratak2017deepsleepnet} combines the feature extraction capability of CNN with the sequential data interpretation power of BiLSTMs. While it excels in deciphering complex datasets, it has trade-offs such as a large footprint and extended training duration.
%
However, the model demands intricate hyperparameter adjustments and incurs high computational expenses.

In \cite{oropesa1999sleep}, spectrogram was first adopted into various methods. Among them, SeqSleepNet \cite{phan2019seqsleepnet} effectively navigated long-term dependencies within spectrograms and attention mechanisms.
%
SleepTransformer \cite{phan2022sleeptransformer} used self-attention to understand the temporal complexities of spectrograms. Its ability to process in parallel speeded up training, but the necessity for large datasets and challenges in model interpretability were its notable drawbacks. 

For example, SleepTransformer had shown prominent results in large-size datasets such as SHHS, but relatively poor performance in small-size datasets such as SleepEDF. 
%
Consequently, numerous researchers have opted for RNN-based networks for spectrograms instead of Transformer-based models, as seen in works such as L-SeqSleepNet \cite{phan2023seqsleepnet}, XSleepNet, MVFSleepNet \cite{li2022mvf}. Although attempts have been made to utilize Transformer-based architectures, such as in CoReSleepNet \cite{kontras2023coresleep}, they have primarily been applied to large-scale datasets.

% 여기 문장 수정? -> ㅇㅇ 했었을거야. To date, 이부분만 약간 다르게 표현해도 되고.
To date, no research has surpassed the XSleepNet architecture in multi-modal learning in sleep stage classification.
%view training. 
%
We expect that incorporating multi-modal data, including spectrograms, into a model combined with a Transformer and self-supervised learning will robustly enhance performance. This approach could potentially address difficult optimization problems more effectively.
%Original: are used in the model. , mitigate difficult optimization problems.

%%%%%%%%%%%%%%%%%%

\subsection{Self-supervised learning in sleep stage classification} %%%%%% Section 2-4 Epoch level 

Self-supervised learning was introduced with a specific focus on defining positive and negative samples \cite{9533305} and contrastive loss \cite{DBLP:journals/corr/abs-1807-03748} is used for a single-channel EEG. Particularly, CoSleep utilized InfoNCE loss in the multi-view learning era \cite{CoSleep_IEEE2021_multiview_with_CL}. Both models demonstrated enhanced performance and also showed their competitiveness on smaller datasets.
%
On the other hand, MAEEG \cite{chien2022maeeg} and MaskSleepNet \cite{MaskSleepNet2023_IEEE} adopted a masking strategy to extract information in the frequency domain while being trained to effectively reconstruct the original raw signal.
%
These whole networks were trained in a pre-training step to maximize their performance.
% phase -> step


In addition to the epoch-level training, exploiting sequential features embedded within epoch sequences is crucial for achieving even higher classification accuracy. 
%
To train the sequential features from a sequence of multiple epoch samples, BENDR \cite{kostas2021bendr} uses a Transformer and contrastive self-supervised learning. 

From the work proving that a masking strategy can enhance the performances \cite{NIPS2013_bengio}, we expect that the use of the masking strategy for sequence-level training can lead to performance improvement.
%
However, BENDR demonstrates that performance improvement in self-supervised learning can only be achieved when there is a large amount of data samples available to capture their relationships. 


