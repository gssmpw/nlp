In this paper, we introduced an MC$^2$SleepNet for sleep stage classification which aimed to achieve effective collaborative learning of the features extracted from multi-modal data through CNN and Transformer architectures.
% 
By utilizing multi-modal data samples, and putting the data of each modal into different networks, our model overcame the limited inspection and exploration on the feature representation space that could be caused by limited views.
%
A contrastive learning technique is employed to leverage the features extracted through CNN and Transformer backbones from these multi-modal data sources.
% 
Additionally, we have developed a 'Cross-Masking' scheme based on a cross-attention mechanism for sequence-level training, which enhances performance in classifying both minor and major classes.
%We are confident that our method could overcome the challenges associated with predicting minor classes while maintaining high F1 scores.
%
Our MC$^2$SleepNet has achieved the \textit{state-of-the-art} performance with an accuracy of both 84.6\% on the SleepEDF-78 and 88.6\% accuracy on the SHHS dataset. This demonstrates that our proposed network is generalized effectively across small and large datasets.



% 이전 문장들 중에서 그나마 건질만한 문장
%In addition, it's one of the ways we've proposed it by employing a straightforward drop-in random and highly masked prediction strategy, we can accurately predict the labels.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%