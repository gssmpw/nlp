\begin{table}[h]
\setlength{\tabcolsep}{10pt}
\caption{Performance comparison among various model architectures and training schemes. TF: Transformer Backbone, CNN: CNN Backbone, CL: Contrastive Learning in epoch-level, M: Masking prediction in sequence-level with 50\% masking ratio, PT: Pre-training with 50\% masking ratio with `CL' and `M' , FT: Fine-tuning (only sequence-level model part is retrained without masking)}
\label{table5}
\begin{tabular}{l|c|c}
\hline
\textbf{Method} & \textbf{SleepEDF-78} &  \textbf{SHHS 5463} \\
\hline
TF only (single) & 73.8 & 78.8  \\
\hline
CNN only (single) & 79.6 & 84.5  \\
\hline
TF+CNN (multi) & 83.5 & 87.8  \\
\hline
TF+CNN+CL+FT & 83.7 & 88.4  \\
\hline
TF+CNN+M+FT & 84.2 & 88.4  \\
\hline
TF+CNN+PT(CL+M) & 84.4 & 88.3 \\
\hline
TF+CNN+PT+FT & - & 88.6 \\
\hline
\end{tabular}
\end{table}