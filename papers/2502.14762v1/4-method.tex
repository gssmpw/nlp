
\section{Methodology}  
\label{sec:method}

\begin{wrapfigure}[17]{l}{0.2\textwidth}
\centering
  \vspace{-17pt}
  \includegraphics[width=0.18\textwidth]{figs/luca1.pdf}
  \caption{LuCA.}
  \label{fig:luca}
\end{wrapfigure}

%\vspace{5pt}
%In this section, we first present the details of LuCA, our proposed PEFT module. Next, we introduce TOSCA, a specialized instantiation of LuCA designed for class-incremental learning, and highlight its architectural benefits. We then describe the training and inference protocols that leverage a frozen PTM alongside task-specific lightweight modules, ensuring computational efficiency and task-wise orthogonality. Finally, we provide theoretical insights into the stability-plasticity of feature manifolds by maintaining bounded deviations.


\paragraph{LuCA Module.} It decouples feature transformation from discriminative feature enhancement with the dual adapter-calibrator architecture, allowing precise control over parameter updates. LuCA can process any intermediate representation $\mathbf{z} \in \mathbb{R}^d$ through two sequential operations:

\begin{equation}
    L(\mathbf{z}) = C(A(\mathbf{z})),
    \label{eq:general-bender}
\end{equation}


where $A(\cdot)$ is a residual adapter that applies bottlenecked feature modulation with \cref{eq:adapter} to preserve original semantics via skip connections while learning task-specific offsets. 
The calibrator $C(\cdot)$ then enhances adapted features through an attention-like gating, similar to the squeeze-and-excitation blocks~\cite{se_block}, and refines more discriminative features with \cref{eq:calibrator} where $\odot$ denotes the Hadamard product. Compared to full fine-tuning which scales with $\mathcal{O}(d^2)$, LuCA provides an efficient and flexible mechanism for task adaptation with only $4 \times d \times r$ trainable parameters, leading to a significantly reduced $\mathcal{O}(dr)$ complexity, where $r \ll d$.

\begin{equation}
    C(\mathbf{z}) = \mathbf{z} \odot \sigma(\mathbf{z}V_{down})V_{up}, \quad V_{down} \in \mathbb{R}^{d \times r}, \ V_{up} \in \mathbb{R}^{r \times d}
    \label{eq:calibrator}
\end{equation}

\paragraph{TOSCA: Specialization for CIL.} We instantiate the LuCA module as TOSCA which is a strategic implementation for CIL that operates exclusively on the final \texttt{[CLS]} token of ViTs. Given an input $\mathbf{x}$, the frozen pre-trained backbone $\phi(\cdot)$ generates $\phi(\mathbf{x})$ which TOSCA refines through \cref{eq:tokenbender}. The design of placing it at the last \texttt{[CLS]} token is a deliberate architectural choice with three advantages:

\begin{equation}
    \phi(\mathbf{x})' = L(\phi(\mathbf{x})) = C(A(\mathbf{\phi(\mathbf{x})}))
    \label{eq:tokenbender}
\end{equation}

%\newpage
First, by localizing adaptations to the final semantic aggregation point (the \texttt{[CLS]} token), TOSCA preserves the model's feature hierarchy where low/mid-level features remain stable while the final high-level abstractions adapt to new tasks. This way, the intact PTM maintains its generalization and out-of-distribution robustness--a critical advantage over adapter-based methods that indirectly perturb intermediate representations through input and intermediate layer modifications. 

Second, the \texttt{[CLS]} token inherently aggregates global semantic information, making it an optimal locus for task-specific refinement, in contrast to input-layer modifications of prompt-based approaches which indirectly influence later representations through the transformer’s self-attention mechanism.

Third, the total parameter count remains architecture-agnostic with $4dr$ regardless of model depth, contrasting sharply with layer-wise adapters that scale linearly as $N \times 2dr$ for $N$ number of layers. This significant reduction in parameters leads to decreased training and inference complexity.


\paragraph{Training Protocol.}  
We completely freeze the PTM $\phi(\cdot)$ and only train the TOSCA's parameters $\Theta_{B} = \{W_{down}, W_{up}, V_{down}, V_{up}\}$ together with the prototypical classifier $W^\top$.
We utilize a new TOSCA module for each incremental stage $b$ which lets the model encode task-specific information in these lightweight modules by optimizing a composite objective function that combines cross-entropy loss with $\ell_1$-regularization as in \cref{eq:training-loss} where $\lambda$ controls the regularization strength.

\begin{equation}
\min_{\Theta_{_b} \cup W} \sum_{(\mathbf{x},y) \in \mathcal{D}^b} \ell_{CE}\left(W^\top \phi(\mathbf{x})', y\right) + \lambda \|\Theta_b\|_1, \quad \phi(\mathbf{x})' = L(\phi(\mathbf{x})) 
\label{eq:training-loss}
\end{equation}

The $\ell_1$ term induces sparsity in the parameters, encouraging orthogonal configurations across different tasks. This orthogonal specialization enables each module to focus on distinct feature dimensions, preventing interference between successive tasks \cite{sparse_orthogonal, o_lora}. After training, we store $B$ while keeping the pre-trained backbone $\phi(\cdot)$ immutable.

\paragraph{Inference Protocol.}  
During inference, we first extract the frozen backbone's representation $\phi(\mathbf{x})$ through a single forward pass to ensure computational efficiency. This shared feature vector is then easily processed by all TOSCA modules and each transformed feature $\phi(\mathbf{x})'_b$ then generates task-specific probability distributions. The final prediction is selected through entropy minimization over the union of all class probabilities as in \cref{eq:entropy-fusion} where $H(\cdot)$ computes the Shannon entropy and $\pi_b$ represents task priors (uniform by default). This entropy-based selection criterion leverages the observation that the correct task-specific module produces predictions with lower uncertainty due to its specialized feature calibration.

\begin{equation}
\hat{y} = \arg\min_{y \in \mathcal{Y}_b} H\left(\sum_{b=1}^B \pi_b p_b(y|\mathbf{x})\right), \quad p_b(y|\mathbf{x}) = softmax(W^\top \phi(\mathbf{x})'_b)
\label{eq:entropy-fusion}
\end{equation}

\paragraph{Theoretical Underpinnings.}
In this approach, we focus adaptation solely on the final \texttt{[CLS]} token before classification, while ensuring that the feature manifolds of all preceding layers remain unchanged. Specifically, the design of TOSCA guarantees that, for all layers $n < N$, the feature manifolds $ \mathcal{H}_n$ of the PTM are preserved as in \cref{eq:manifold}, meaning the feature distributions remain identical to the PTM's distributions up to the penultimate layer. This stability ensures that the model retains the learned features from prior tasks, avoiding catastrophic forgetting.

\begin{equation}
\forall n < N: \mathcal{H}_n^{TOSCA} = \mathcal{H}_n^{PTM}
\label{eq:manifold}
\end{equation}

By adapting exclusively through \texttt{[CLS]} of the final layer $N$, we achieve a controlled adjustment by allowing a small, bounded deviation in the feature manifold at this layer while maintaining backward compatibility with previously learned classes. The bounded deviation is formally expressed as in \cref{eq:manifold2} where $\epsilon$ is a small value controlled by the residual connection, that limits the change in the feature space and does not disrupt the learned knowledge.

\begin{equation}
\gamma(\mathcal{H}_N^{PTM}, \mathcal{H}_N^{TOSCA}) \leq \epsilon
\label{eq:manifold2}
\end{equation}

\paragraph{Neuroscientific Inspirations.}
The brain's continual learning ability arises from encoding invariant representations in the ventral visual stream \cite{ventral,ventral1} and flexibly adapting them via task-specific circuits in the prefrontal cortex \cite{cortex,cortex1, cortex2}. In other words, the prefrontal cortex receives invariant visual information from the ventral stream and refines these representations through selective synaptic plasticity to adapt to current behavioral demands. This enables the cortex to manipulate and utilize these representations to guide final behavior effectively. Inspired by this, our method leverages a pre-trained ViT to emulate the ventral visual stream’s stable and invariant feature extraction and employs lightweight modules just before the decision-making, analogous to flexible cortical circuits that tailor general representations for specific tasks. This approach not only minimizes the need to relearn basic features for each new task but also mirrors the brain’s learning principles.

\paragraph{Summary.} 
Prompts effectively modulate the self-attention mechanism without explicitly adding new representations, thereby enhancing stability. Conversely, adapters facilitate adaptation to new classes by subtly modifying the PTM’s feature representations via residual additions, which enhances plasticity. To combine these complementary advantages, we introduce a new PEFT module LuCA that integrates an adapter with a calibrator to produce refined feature representations. Unlike many PTM-based CIL methods that place modules at every layer, we strategically position a sparse LuCA module to operate solely on the final \texttt{[CLS]} token just before the classifier, which we refer to as TOSCA. This design enables the orthogonal specialization of modules to focus on distinct feature dimensions, prevents interference between tasks during inference, and efficiently strikes the balance between stability and plasticity in continual learning without compromising the PTM’s generalization.