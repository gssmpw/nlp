%survey
@article{deepcil_survey,
  title={Class-incremental learning: A survey},
  author={Zhou, Da-Wei and Wang, Qi-Wei and Qi, Zhi-Hong and Ye, Han-Jia and Zhan, De-Chuan and Liu, Ziwei},
  journal={TPAMI},
  year={2024},
  publisher={IEEE}
}

@article{defyingforget_survey,
  title={A continual learning survey: Defying forgetting in classification tasks},
  author={De Lange, Matthias and Aljundi, Rahaf and Masana, Marc and Parisot, Sarah and Jia, Xu and Leonardis, Ale{\v{s}} and Slabaugh, Gregory and Tuytelaars, Tinne},
  journal={TPAMI},
  year={2021},
  publisher={IEEE}
}

@article{masana_survey,
  title={Class-incremental learning: survey and performance evaluation on image classification},
  author={Masana, Marc and Liu, Xialei and Twardowski, Bart{\l}omiej and Menta, Mikel and Bagdanov, Andrew D and Van De Weijer, Joost},
  journal={TPAMI},
  year={2022},
  publisher={IEEE}
}

%regularization
@article{ewc,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and others},
  journal={PNAS},
  year={2017}
}

@InProceedings{r_walk,
author = {Chaudhry, Arslan and Dokania, Puneet K. and Ajanthan, Thalaiyasingam and Torr, Philip H. S.},
title = {Riemannian Walk for Incremental Learning: Understanding Forgetting and Intransigence},
booktitle = {ECCV},
year = {2018}
}

@inproceedings{mas,
  title={Memory aware synapses: Learning what (not) to forget},
  author={Aljundi, Rahaf and Babiloni, Francesca and Elhoseiny, Mohamed and Rohrbach, Marcus and Tuytelaars, Tinne},
  booktitle={ECCV},
  year={2018}
}

@inproceedings{si,
  title={Continual learning through synaptic intelligence},
  author={Zenke, Friedemann and Poole, Ben and Ganguli, Surya},
  booktitle={ICML},
  year={2017}
}

@inproceedings{lee2020continual,
  title={Continual learning with extended kronecker-factored approximate curvature},
  author={Lee, Janghyeon and Hong, Hyeong Gwon and Joo, Donggyu and Kim, Junmo},
  booktitle={CVPR},
  year={2020}
}

@article{lwf,
  title={Learning without forgetting},
  author={Li, Zhizhong and Hoiem, Derek},
  journal={TPAMI},
  year={2017}
}

@inproceedings{hou2018kd,
  title={Lifelong learning via progressive distillation and retrospection},
  author={Hou, Saihui and Pan, Xinyu and Loy, Chen Change and Wang, Zilei and Lin, Dahua},
  booktitle={ECCV},
  year={2018}
}

@inproceedings{kang2022kd,
  title={Class-Incremental Learning by Knowledge Distillation With Adaptive Feature Consolidation},
  author={Kang, Minsoo and Park, Jaeyoo and Han, Bohyung},
  booktitle={CVPR},
  year={2022}
}

%replay
@inproceedings{icarl,
  title={icarl: Incremental classifier and representation learning},
  author={Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander and Sperl, Georg and Lampert, Christoph H},
  booktitle={CVPR},
  year={2017}
}

@inproceedings{gem,
  title={Gradient episodic memory for continual learning},
  author={Lopez-Paz, David and Ranzato, Marc'Aurelio},
  booktitle={NeurIPS},
  year={2017}
}

@inproceedings{agem,
  title={Efficient lifelong learning with a-gem},
  author={Chaudhry, Arslan and Ranzato, Marc'Aurelio and Rohrbach, Marcus and Elhoseiny, Mohamed},
  booktitle={ICLR},
  year={2019}
}

@inproceedings{rainbow,
    author    = {Bang, Jihwan and Kim, Heesu and Yoo, YoungJoon and Ha, Jung-Woo and Choi, Jonghyun},
    title     = {Rainbow Memory: Continual Learning With a Memory of Diverse Samples},
    booktitle = {CVPR},
    year      = {2021}
}

@inproceedings{esmer,
  title={Error Sensitivity Modulation based Experience Replay: Mitigating Abrupt Representation Drift in Continual Learning},
  author={Sarfraz, Fahad and Arani, Elahe and Zonooz, Bahram},
  booktitle={ICLR},
  year={2023}
}

@inproceedings{cls-er,
  title={Learning fast, learning slow: A general continual learning method based on complementary learning system},
  author={Arani, Elahe and Sarfraz, Fahad and Zonooz, Bahram},
  booktitle={ICLR},
  year={2022}
}

@inproceedings{rmm,
  title={RMM: Reinforced memory management for class-incremental learning},
  author={Liu, Yaoyao and Sun, Qianru and Sun, Qianru},
  booktitle={NeurIPS},
  year={2021}
}

@inproceedings{wa,
  title={Maintaining discrimination and fairness in class incremental learning},
  author={Zhao, Bowen and Xiao, Xi and Gan, Guojun and Zhang, Bin and Xia, Shu-Tao},
  booktitle={CVPR},
  year={2020}
}

@inproceedings{bic,
  title={Large scale incremental learning},
  author={Wu, Yue and Chen, Yinpeng and Wang, Lijuan and Ye, Yuancheng and Liu, Zicheng and Guo, Yandong and Fu, Yun},
  booktitle={CVPR},
  year={2019}
}

-------------------------------------------------
@inproceedings{fetril,
    title     = {FeTrIL: Feature Translation for Exemplar-Free Class-Incremental Learning},
    author    = {Petit, Gr\'egoire and Popescu, Adrian and Schindler, Hugo and Picard, David and Delezoide, Bertrand},
    booktitle = {WACV},
    year      = {2023}
}

@article{decebal2016gen,
  title={Online contrastive divergence with generative replay: Experience replay without storing data},
  author={Mocanu, Decebal Constantin and Vega, Maria Torres and others},
  journal={arXiv:1610.05555},
  year={2016}
}

@inproceedings{he2018exemplar,
  title={Exemplar-Supported Generative Reproduction for Class Incremental Learning.},
  author={He, Chen and Wang, Ruiping and Shan, Shiguang and Chen, Xilin},
  booktitle={BMVC},
  year={2018}
}

@inproceedings{hu2019overcoming,
  title={Overcoming catastrophic forgetting for continual learning via model adaptation},
  author={Hu, Wenpeng and Lin, Zhou and Liu, Bing and Tao, Chongyang and Tao, Zhengwei Tao and Zhao, Dongyan and Ma, Jinwen and Yan, Rui},
  booktitle={ICLR},
  year={2019}
}

@inproceedings{shin2017continual,
  title={Continual learning with deep generative replay},
  author={Shin, Hanul and Lee, Jung Kwon and Kim, Jaehong and Kim, Jiwon},
  booktitle={NeurIPS},
  year={2017}
}

%architecture expansion
@inproceedings{der,
  title={DER: Dynamically expandable representation for class incremental learning},
  author={Yan, Shipeng and Xie, Jiangwei and He, Xuming},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{par,
    author    = {Wang, Wenjin and Hu, Yunqing and Chen, Qianglong and Zhang, Yin},
    title     = {Task Difficulty Aware Parameter Allocation \& Regularization for Lifelong Learning},
    booktitle = {CVPR},
    year      = {2023},
}

@inproceedings{dytox,
    author    = {Douillard, Arthur and Ram\'e, Alexandre and Couairon, Guillaume and Cord, Matthieu},
    title     = {DyTox: Transformers for Continual Learning With DYnamic TOken eXpansion},
    booktitle = {CVPR},
    year      = {2022}
}

@inproceedings{aanets,
    author    = {Liu, Yaoyao and Schiele, Bernt and Sun, Qianru},
    title     = {Adaptive Aggregation Networks for Class-Incremental Learning},
    booktitle = {CVPR},
    year      = {2021}
}

@inproceedings{foster,
  title={Foster: Feature boosting and compression for class-incremental learning},
  author={Wang, Fu-Yun and Zhou, Da-Wei and Ye, Han-Jia and Zhan, De-Chuan},
  booktitle={ECCV},
  year={2022}
}

@inproceedings{memo,
  title={A model or 603 exemplars: Towards memory-efficient class-incremental learning},
  author={Zhou, Da-Wei and Wang, Qi-Wei and Ye, Han-Jia and Zhan, De-Chuan},
  booktitle={ICLR},
  year={2023}
}

@inproceedings{expertgate,
  title={Expert gate: Lifelong learning with a network of experts},
  author={Aljundi, Rahaf and Chakravarty, Punarjay and Tuytelaars, Tinne},
  booktitle={CVPR},
  year={2017}
}

@inproceedings{dualnet,
  title={Dualnet: Continual learning, fast and slow},
  author={Pham, Quang and Liu, Chenghao and Hoi, Steven},
  booktitle={NeurIPS},
  year={2021}
}

%parameter isolation
@inproceedings{supsup,
  title={Supermasks in superposition},
  author={Wortsman, Mitchell and Ramanujan, Vivek and Liu, Rosanne and Kembhavi, Aniruddha and Rastegari, Mohammad and Yosinski, Jason and Farhadi, Ali},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{piggyback,
  title={Piggyback: Adapting a single network to multiple tasks by learning to mask weights},
  author={Mallya, Arun and Davis, Dillon and Lazebnik, Svetlana},
  booktitle={ECCV},
  year={2018}
}

@inproceedings{clnp,
  title={Continual learning via neural pruning},
  author={Golkar, Siavash and Kagan, Michael and Cho, Kyunghyun},
  booktitle={NeurIPS},
  year={2019}
}

@article{cps,
  title={Continual prune-and-select: class-incremental learning with specialized subnetworks},
  author={Dekhovich, Aleksandr and Tax, David MJ and Sluiter, Marcel HF and Bessa, Miguel A},
  journal={Applied Intelligence},
  year={2023}
}

@inproceedings{packnet,
  title={Packnet: Adding multiple tasks to a single network by iterative pruning},
  author={Mallya, Arun and Lazebnik, Svetlana},
  booktitle={CVPR},
  year={2018}
}

@article{spacenet,
  title={Spacenet: Make free space for continual learning},
  author={Sokar, Ghada and Mocanu, Decebal Constantin and Pechenizkiy, Mykola},
  journal={Neurocomputing},
  year={2021}
}

@inproceedings{afaf,
  title={Avoiding Forgetting and Allowing Forward Transfer in Continual Learning via Sparse Networks},
  author={Sokar, Ghada and Mocanu, Decebal Constantin and Pechenizkiy, Mykola},
  booktitle={ECML PKDD},
  year={2023}
}

@inproceedings{nispa,
  title={Nispa: Neuro-inspired stability-plasticity adaptation for continual learning in sparse networks},
  author={Gurbuz, Mustafa Burak and Dovrolis, Constantine},
  booktitle={ICML},
  year={2022}
}

@inproceedings{wsn,
  title={Forget-free continual learning with winning subnetworks},
  author={Kang, Haeyong and Mina, Rusty John Lloyd and others},
  booktitle={ICML},
  year={2022}
}

@inproceedings{ll-lth,
title={Long Live the Lottery: The Existence of Winning Tickets in Lifelong Learning},
author={Tianlong Chen and Zhenyu Zhang and Sijia Liu and Shiyu Chang and Zhangyang Wang},
booktitle={ICLR},
year={2021}
}

@inproceedings{sparcl,
 author = {Wang, Zifeng and Zhan, Zheng and Gong, Yifan and Yuan, Geng and Niu, Wei and Jian, Tong and Ren, Bin and Ioannidis, Stratis and Wang, Yanzhi and Dy, Jennifer},
 booktitle = {NeurIPS},
 title = {SparCL: Sparse Continual Learning on the Edge},
 year = {2022}
}

@inproceedings{softsubnet,
title={On the Soft-Subnetwork for Few-Shot Class Incremental Learning},
author={Haeyong Kang and Jaehong Yoon and Sultan Rizky Hikmawan Madjid and Sung Ju Hwang and Chang D. Yoo},
booktitle={ICLR},
year={2023}
}

@inproceedings{cl_with_dst,
title={Continual Learning with Dynamic Sparse Training: Exploring Algorithms for Effective Model Updates},
author={Murat Onur Yildirim and Elif Ceren Gok Yildirim and Ghada Sokar and Decebal Constantin Mocanu and Joaquin Vanschoren},
booktitle={CPAL},
year={2023},
}

%metrics
@article{clmetrics,
  title={Don't forget, there is more than forgetting: new metrics for Continual Learning},
  author={D{\'\i}az-Rodr{\'\i}guez, Natalia and Lomonaco, Vincenzo and Filliat, David and Maltoni, Davide},
  journal={arXiv:1810.13166},
  year={2018}
}

%dst

@inproceedings{obd,
  title={Optimal brain damage},
  author={LeCun, Yann and Denker, John and Solla, Sara},
  booktitle={NeurIPS},
  year={1989}
}

@article{set,
  title={Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science},
  author={Mocanu, Decebal Constantin and others},
  journal={Nature communications},
  year={2018}
}

@inproceedings{rigl,
  title={Rigging the lottery: Making all tickets winners},
  author={Evci, Utku and Gale, Trevor and Menick, Jacob and Castro, Pablo Samuel and Elsen, Erich},
  booktitle={ICML},
  year={2020}
}

@inproceedings{itop,
  title={Do we actually need dense over-parameterization? in-time over-parameterization in sparse training},
  author={Liu, Shiwei and Yin, Lu and Mocanu, Decebal Constantin and Pechenizkiy, Mykola},
  booktitle={ICML},
  year={2021}
}

@inproceedings{liu_topological,
  title={Topological insights into sparse neural networks},
  author={Liu, Shiwei and Van der Lee, Tim and others},
  booktitle={ECML PKDD},
  year={2021}
}

@article{liu_tenlessons,
  title={Ten Lessons We Have Learned in the New "Sparseland": A Short Handbook for Sparse Neural Network Researchers},
  author={Liu, Shiwei and Wang, Zhangyang},
  journal={arXiv:2302.02596},
  year={2023}
}

@article{sparsemomentum,
  title={Sparse networks from scratch: Faster training without losing performance},
  author={Dettmers, Tim and Zettlemoyer, Luke},
  journal={arXiv:1907.04840},
  year={2019}
}

@inproceedings{topk,
  title={Top-kast: Top-k always sparse training},
  author={Jayakumar, Siddhant and Pascanu, Razvan and Rae, Jack and Osindero, Simon and Elsen, Erich},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{mostafa2019sparse,
  title={Parameter efficient training of deep convolutional neural networks by dynamic sparse reparameterization},
  author={Mostafa, Hesham and Wang, Xin},
  booktitle={ICML},
  year={2019},
  organization={PMLR}
}

@article{hoefler2021sparsity,
  title={Sparsity in deep learning: Pruning and growth for efficient inference and training in neural networks},
  author={Hoefler, Torsten and Alistarh, Dan and Ben-Nun, Tal and Dryden, Nikoli and Peste, Alexandra},
  journal={JMLR},
  year={2021}
}

@inproceedings{raihan2020sparse,
  title={Sparse weight activation training},
  author={Raihan, Md Aamir and Aamodt, Tor},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{mest,
  title={Mest: Accurate and fast memory-economic sparse training framework on the edge},
  author={Yuan, Geng and Ma, Xiaolong and Niu, Wei and Li, Zhengang and Kong, Zhenglun and Liu, Ning and Gong, Yifan and Zhan, Zheng and He, Chaoyang and Jin, Qing and others},
  booktitle={NeurIPS},
  year={2021}
}

%datasets

@article{mnist,
  title={MNIST handwritten digit database},
  author={LeCun, Yann and Cortes, Corinna and Burges, CJ},
  journal={ATT Labs},
  volume={2},
  year={2010}
}

@online{fashion-mnist,
  author       = {Han Xiao and Kashif Rasul and Roland Vollgraf},
  title        = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},
  date         = {2017-08-28},
  year         = {2017},
  eprintclass  = {cs.LG},
  eprinttype   = {arXiv},
  eprint       = {cs.LG/1708.07747},
}

@article{cifar,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada}
}

@article{cub,
  title={The caltech-ucsd birds-200-2011 dataset},
  author={Wah, Catherine and Branson, Steve and Welinder, Peter and Perona, Pietro and Belongie, Serge},
  year={2011},
  publisher={California Institute of Technology}
}

@inproceedings{imagenet-r,
  title={The many faces of robustness: A critical analysis of out-of-distribution generalization},
  author={Hendrycks, Dan and Basart, Steven and Mu, Norman and Kadavath, Saurav and Wang, Frank and Dorundo, Evan and Desai, Rahul and Zhu, Tyler and Parajuli, Samyak and Guo, Mike and others},
  booktitle={ICCV}},
  year={2021}
}

@inproceedings{imagenet-a,
  title={Natural adversarial examples},
  author={Hendrycks, Dan and Zhao, Kevin and Basart, Steven and Steinhardt, Jacob and Song, Dawn},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{omnibenchmark,
  title={Benchmarking omni-vision representation through the lens of visual realms},
  author={Zhang, Yuanhan and Yin, Zhenfei and Shao, Jing and Liu, Ziwei},
  booktitle={ECCV},
  year={2022}
}

@article{vtab,
  title={A large-scale study of representation learning with the visual task adaptation benchmark},
  author={Zhai, Xiaohua and Puigcerver, Joan and Kolesnikov, Alexander and others},
  journal={arXiv:1910.04867},
  year={2019}
}

@inproceedings{miniimagenet,
author = {Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Kavukcuoglu, Koray and Wierstra, Daan},
title = {Matching Networks for One Shot Learning},
year = {2016},
booktitle = {NeurIPS}
}

@article{tinyimagenet,
  title={Tiny imagenet visual recognition challenge},
  author={Le, Ya and Yang, Xuan},
  year={2015}
}

@inproceedings{imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={CVPR},
  year={2009},
}

%pytorch
@incollection{pytorch,
  title     = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  author    = {Paszke, Adam and Gross, Sam and Massa, Francisco and others},
  booktitle = {NeurIPS},
  year      = {2019}
}

@article{pilot,
  title={Pilot: A pre-trained model-based continual learning toolbox},
  author={Sun, Hai-Long and Zhou, Da-Wei and Ye, Han-Jia and Zhan, De-Chuan},
  journal={arXiv:2309.07117},
  year={2023}
}

%backbones
@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  year={2016}
}

@inproceedings{mobilenetv2,
  title={Mobilenetv2: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={CVPR},
  year={2018}
}

@article{vgg,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={ICLR},
  year={2015}
}

@inproceedings{convit,
  title={Convit: Improving vision transformers with soft convolutional inductive biases},
  author={d’Ascoli, St{\'e}phane and Touvron, Hugo and Leavitt, Matthew L and Morcos, Ari S and Biroli, Giulio and Sagun, Levent},
  booktitle={ICML},
  year={2021}
}

@inproceedings{vit,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and others},
booktitle={ICLR},
year={2021}
}

@inproceedings{swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  year={2021}
}

%online CL
@inproceedings{gss,
  title={Gradient based sample selection for online continual learning},
  author={Aljundi, Rahaf and Lin, Min and Goujaud, Baptiste and Bengio, Yoshua},
  booktitle={NeurIPS},
  year={2019}
}

@inproceedings{aop,
  title={Adaptive orthogonal projection for batch and online continual learning},
  author={Guo, Yiduo and Hu, Wenpeng and Zhao, Dongyan and Liu, Bing},
  booktitle={AAAI},
  year={2022}
}

@inproceedings{mir,
 author = {Aljundi, Rahaf and Belilovsky, Eugene and Tuytelaars, Tinne and others},
 booktitle = {NeurIPS},
 title = {Online Continual Learning with Maximal Interfered Retrieval},
 year = {2019}
}

@inproceedings{gdumb,
  title={Gdumb: A simple approach that questions our progress in continual learning},
  author={Prabhu, Ameya and Torr, Philip HS and Dokania, Puneet K},
  booktitle={ECCV},
  year={2020}
}

@article{er,
  title={On tiny episodic memories in continual learning},
  author={Chaudhry, Arslan and Rohrbach, Marcus and Elhoseiny, Mohamed and Ajanthan, Thalaiyasingam and Dokania, Puneet K and Torr, Philip HS and Ranzato, Marc'Aurelio},
  journal={arXiv:1902.10486},
  year={2019}
}

@inproceedings{aser,
  title={Online class-incremental continual learning with adversarial shapley value},
  author={Shim, Dongsub and Mai, Zheda and Jeong, Jihwan and Sanner, Scott and Kim, Hyunwoo and Jang, Jongseong},
  booktitle={AAAI},
  year={2021}
}

@inproceedings{scr,
  title={Supervised contrastive replay: Revisiting the nearest class mean classifier in online class-incremental continual learning},
  author={Mai, Zheda and Li, Ruiwen and Kim, Hyunwoo and Sanner, Scott},
  booktitle={CVPR Workshops},
  year={2021}
}

@inproceedings{ocm,
  title={Online continual learning through mutual information maximization},
  author={Guo, Yiduo and Liu, Bing and Zhao, Dongyan},
  booktitle={ICML},
  year={2022}
}

@inproceedings{onpro,
  title={Online prototype learning for online continual learning},
  author={Wei, Yujie and Ye, Jiaxin and Huang, Zhizhong and Zhang, Junping and Shan, Hongming},
  booktitle={ICCV},
  year={2023}
}

@inproceedings{cope,
  title={Continual prototype evolution: Learning online from non-stationary data streams},
  author={De Lange, Matthias and Tuytelaars, Tinne},
  booktitle={ICCV},
  year={2021}
}

@InProceedings{dvc,
    author    = {Gu, Yanan and Yang, Xu and Wei, Kun and Deng, Cheng},
    title     = {Not Just Selection, but Exploration: Online Class-Incremental Continual Learning via Dual View Consistency},
    booktitle = {CVPR},
    year      = {2022}
}

@incollection{catastrophic,
  title={Catastrophic interference in connectionist networks: The sequential learning problem},
  author={McCloskey, Michael and Cohen, Neal J},
  booktitle={Psychology of learning and motivation},
  year={1989},
  publisher={Elsevier}
}

@inproceedings{snip,
  title={Snip: Single-shot network pruning based on connection sensitivity},
  author={Namhoon Lee and Thalaiyasingam Ajanthan and Philip Torr},
  booktitle={ICLR},
  year={2019}
}

@inproceedings{grasp,
title={Picking Winning Tickets Before Training by Preserving Gradient Flow},
author={Chaoqi Wang and Guodong Zhang and Roger Grosse},
booktitle={ICLR},
year={2020}
}

@inproceedings{synflow,
  title={Pruning neural networks without any data by iteratively conserving synaptic flow},
  author={Tanaka, Hidenori and Kunin, Daniel and Yamins, Daniel L and Ganguli, Surya},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{randompruning,
title={The Unreasonable Effectiveness of Random Pruning: Return of the Most Naive Baseline for Sparse Training},
author={Shiwei Liu and Tianlong Chen and Xiaohan Chen and Li Shen and Decebal Constantin Mocanu and Zhangyang Wang and Mykola Pechenizkiy},
booktitle={ICLR},
year={2022}
}

@inproceedings{wideforgetless,
  title={Wide neural networks forget less catastrophically},
  author={Mirzadeh, Seyed Iman and Chaudhry, Arslan and Yin, Dong and Hu, Huiyi and Pascanu, Razvan and Gorur, Dilan and Farajtabar, Mehrdad},
  booktitle={ICML},
  year={2022}
}

@article{architecture_matters,
  title={Architecture matters in continual learning},
  author={Mirzadeh, Seyed Iman and Chaudhry, Arslan and Yin, Dong and Nguyen, Timothy and Pascanu, Razvan and Gorur, Dilan and Farajtabar, Mehrdad},
  journal={arXiv:2202.00275},
  year={2022}
}

@inproceedings{ltr,
title={The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks},
author={Jonathan Frankle and Michael Carbin},
booktitle={ICLR},
year={2019}
}

@InProceedings{topology,
author="Liu, Shiwei and Van der Lee, Tim and Yaman, Anil and Atashgahi, Zahra and Ferraro, Davide and Sokar, Ghada and Pechenizkiy, Mykola and Mocanu, Decebal Constantin",
title="Topological Insights into Sparse Neural Networks",
booktitle="ECML PKDD",
year="2020"
}

@article{brain,
  title={Sparseness and expansion in sensory representations},
  author={Babadi, Baktash and Sompolinsky, Haim},
  journal={Neuron},
  volume={83},
  number={5},
  year={2014},
  publisher={Elsevier}
}

@book{automl,
  title={Automated machine learning: methods, systems, challenges},
  author={Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
  year={2019},
  publisher={Springer Nature}
}

@InProceedings{tpe,
  title={Algorithms for hyper-parameter optimization},
  author={Bergstra, James and Bardenet, R{\'e}mi and Bengio, Yoshua and K{\'e}gl, Bal{\'a}zs},
  booktitle={NeurIPS},
  year={2011}
}

@article{rs,
  title={Random search for hyper-parameter optimization.},
  author={Bergstra, James and Bengio, Yoshua},
  journal={Journal of machine learning research},
  volume={13},
  number={2},
  year={2012}
}

@article{asha,
  title={Massively parallel hyperparameter tuning},
  author={Li, Liam and Jamieson, Kevin and Rostamizadeh, Afshin and Gonina, Ekaterina and Hardt, Moritz and Recht, Benjamin and Talwalkar, Ameet},
  journal={arXiv:1810.05934},
  year={2018}
}

@article{mocanu_topological,
  title={A topological insight into restricted boltzmann machines},
  author={Mocanu, Decebal Constantin and Mocanu, Elena and Nguyen, Phuong H and Gibescu, Madeleine and Liotta, Antonio},
  journal={Machine Learning},
  volume={104},
  pages={243--270},
  year={2016},
  publisher={Springer}
}

@inproceedings{why_random_all_need,
  title={Why random pruning is all we need to start sparse},
  author={Gadhikar, Advait Harshal and Mukherjee, Sohom and Burkholz, Rebekka},
  booktitle={ICML},
  year={2023}
}

@article{uniform_init1,
  title={Diversity networks: Neural network compression using determinantal point processes},
  author={Mariet, Zelda and Sra, Suvrit},
  journal={arXiv:1511.05077},
  year={2015}
}

@inproceedings{uniform_init2,
  title={Channel pruning for accelerating very deep neural networks},
  author={He, Yihui and Zhang, Xiangyu and Sun, Jian},
  booktitle={ICCV},
  year={2017}
}

@article{uniform_init3,
  title={The state of sparsity in deep neural networks},
  author={Gale, Trevor and Elsen, Erich and Hooker, Sara},
  journal={arXiv:1902.09574},
  year={2019}
}

@inproceedings{itaml,
  title={itaml: An incremental task-agnostic meta-learning approach},
  author={Rajasegaran, Jathushan and Khan, Salman and Hayat, Munawar and Khan, Fahad Shahbaz and Shah, Mubarak},
  booktitle={CVPR},
  year={2020}
}


@article{three_cl_scenarios,
  title={Three scenarios for continual learning},
  author={Van de Ven, Gido M and Tolias, Andreas S},
  journal={arXiv:1904.07734},
  year={2019}
}

@article{task_agnostic,
title={Task Agnostic Continual Learning Using Online Variational Bayes}, 
author={Chen Zeno and Itay Golan and Elad Hoffer and Daniel Soudry},
journal={arXiv:1902.09574},
year={2019},
}

@inproceedings{task_free,
  title={Task-free continual learning},
  author={Aljundi, Rahaf and Kelchtermans, Klaas and Tuytelaars, Tinne},
  booktitle={CVPR},
  year={2019}
}

@InProceedings{sedem,
    author    = {Ye, Fei and Bors, Adrian G.},
    title     = {Self-Evolved Dynamic Expansion Model for Task-Free Continual Learning},
    booktitle = {ICCV},
    year      = {2023}
}

@inproceedings{cndpm,
title={A Neural Dirichlet Process Mixture Model for Task-Free Continual Learning},
author={Soochan Lee and Junsoo Ha and Dongsu Zhang and Gunhee Kim},
booktitle={ICLR},
year={2020},
}

@article{reservoir,
  title={Random sampling with a reservoir},
  author={Vitter, Jeffrey S},
  journal={ACM Transactions on Mathematical Software (TOMS)},
  volume={11},
  number={1},
  pages={37--57},
  year={1985}
}

@inproceedings{reservoir_good_cl_baseline,
  title={Continual learning with tiny episodic memories},
  author={Chaudhry, Arslan and Rohrbach, Marcus and Elhoseiny, Mohamed and Ajanthan, Thalaiyasingam and Dokania, P and Torr, P and Ranzato, M},
  booktitle={Workshop on Multi-Task and Lifelong Reinforcement Learning},
  year={2019}
}

@article{focil,
      title={FOCIL: Finetune-and-Freeze for Online Class Incremental Learning by Training Randomly Pruned Sparse Experts}, 
      author={Murat Onur Yildirim and Elif Ceren Gok Yildirim and Decebal Constantin Mocanu and Joaquin Vanschoren},
      journal={arXiv:2403.14684},
      year={2024}
}

@inproceedings{dynamic_ocm,
  title={Continual variational autoencoder learning via online cooperative memorization},
  author={Ye, Fei and Bors, Adrian G},
  booktitle={ECCV},
  year={2022}
}

@inproceedings{herding,
  title={Herding dynamical weights to learn},
  author={Welling, Max},
  booktitle={ICML},
  year={2009}
}

@inproceedings{kgreedy,
title={Active Learning for Convolutional Neural Networks: A Core-Set Approach},
author={Ozan Sener and Silvio Savarese},
booktitle={ICLR},
year={2018}
}

@inproceedings{
uncertainty,
title={Selection via Proxy: Efficient Data Selection for Deep Learning},
author={Cody Coleman and Christopher Yeh and Stephen Mussmann and Baharan Mirzasoleiman and Peter Bailis and Percy Liang and Jure Leskovec and Matei Zaharia},
booktitle={International Conference on Learning Representations},
year={2020}
}

@inproceedings{
forgetting,
title={An Empirical Study of Example Forgetting during Deep Neural Network Learning},
author={Mariya Toneva and Alessandro Sordoni and Remi Tachet des Combes and Adam Trischler and Yoshua Bengio and Geoffrey J. Gordon},
booktitle={ICLR},
year={2019}
}

@inproceedings{
grand,
title={Deep Learning on a Data Diet: Finding Important Examples Early in Training},
author={Mansheej Paul and Surya Ganguli and Gintare Karolina Dziugaite},
booktitle={NeurIPS},
year={2021}
}

@article{cal,
  title={Active learning by acquiring contrastive examples},
  author={Margatina, Katerina and Vernikos, Giorgos and Barrault, Lo{\"\i}c and Aletras, Nikolaos},
  journal={arXiv:2109.03764},
  year={2021}
}

@article{deepfool,
  title={Adversarial active learning for deep networks: a margin based approach},
  author={Ducoffe, Melanie and Precioso, Frederic},
  journal={arXiv:1802.09841},
  year={2018}
}

@inproceedings{deepcore,
  title={Deepcore: A comprehensive library for coreset selection in deep learning},
  author={Guo, Chengcheng and Zhao, Bo and Bai, Yanbing},
  booktitle={International Conference on Database and Expert Systems Applications},
  year={2022}
}

@article{brain_attention,
  title={The attention system of the human brain},
  author={Posner, Michael I and Petersen, Steven E},
  journal={Annual review of neuroscience},
  volume={13},
  number={1},
  pages={25--42},
  year={1990},
}

@article{brain_drift_detection,
  title={Interactions between attention and visual short-term memory (VSTM): What can be learnt from individual and developmental differences?},
  author={Astle, Duncan E and Scerif, Gaia},
  journal={Neuropsychologia},
  volume={49},
  number={6},
  pages={1435--1445},
  year={2011},
  publisher={Elsevier}
}

@article{brain_adjusting,
  title={Adjusting behavior to changing environmental demands with development},
  author={Lourenco, Frederico and Casey, BJ},
  journal={Neuroscience \& Biobehavioral Reviews},
  volume={37},
  number={9},
  pages={2233--2242},
  year={2013},
  publisher={Elsevier}
}


@article{neuro_cl0,
  title={Biological underpinnings for lifelong learning machines},
  author={Kudithipudi, Dhireesha and Aguilar-Simon, Mario and Babb, Jonathan and Bazhenov, Maxim and Blackiston, Douglas and Bongard, Josh and Brna, Andrew P and Chakravarthi Raja, Suraj and Cheney, Nick and Clune, Jeff and others},
  journal={Nature Machine Intelligence},
  volume={4},
  number={3},
  year={2022}
}

@article{neuro_cl1,
  title={Continual lifelong learning with neural networks: A review},
  author={Parisi, German I and Kemker, Ronald and Part, Jose L and Kanan, Christopher and Wermter, Stefan},
  journal={Neural networks},
  volume={113},
  pages={54--71},
  year={2019},
}

@article{neuro_cl2,
  title={Inductive biases for deep learning of higher-level cognition},
  author={Goyal, Anirudh and Bengio, Yoshua},
  journal={Proceedings of the Royal Society A},
  volume={478},
  number={2266},
  year={2022},
  publisher={The Royal Society}
}

@article{neuro_drift0,
  title={Neuromodulated attention and goal-driven perception in uncertain domains},
  author={Zou, Xinyun and Kolouri, Soheil and Pilly, Praveen K and Krichmar, Jeffrey L},
  journal={Neural Networks},
  volume={125},
  year={2020}
}

@article{neuro_drift1,
  title={A modeling framework for adaptive lifelong learning with transfer and savings through gating in the prefrontal cortex},
  author={Tsuda, Ben and Tye, Kay M and Siegelmann, Hava T and Sejnowski, Terrence J},
  journal={Proceedings of the National Academy of Sciences},
  volume={117},
  number={47},
  year={2020}
}

@article{neurogenesis,
  title={Experience-induced neurogenesis in the senescent dentate gyrus},
  author={Kempermann, Gerd and Kuhn, H Georg and Gage, Fred H},
  journal={Journal of Neuroscience},
  volume={18},
  number={9},
  year={1998},
}

@article{neurogenesis1,
  title={Glial inhibition of CNS axon regeneration},
  author={Yiu, Glenn and He, Zhigang},
  journal={Nature Reviews Neuroscience},
  volume={7},
  number={8},
  year={2006}
}

@inproceedings{ddm,
  title={Learning with drift detection},
  author={Gama, Joao and Medas, Pedro and Castillo, Gladys and Rodrigues, Pedro},
  booktitle={"Advances in Artificial Intelligence - SBIA"},
  year={2004},
}

@inproceedings{adwin,
  title={Learning from time-changing data with adaptive windowing},
  author={Bifet, Albert and Gavalda, Ricard},
  booktitle={International Conference on Data Mining - SIAM},
  year={2007},
  organization={SIAM}
}

@article{conceptcell,
  title={Concept cells: the building blocks of declarative memory functions},
  author={Quiroga, Rodrigo Quian},
  journal={Nature Reviews Neuroscience},
  volume={13},
  number={8},
  year={2012},
}

%PTM-based CIL
@inproceedings{ranpac,
  title={Ranpac: Random projections and pre-trained models for continual learning},
  author={McDonnell, Mark D and Gong, Dong and Parvaneh, Amin and Abbasnejad, Ehsan and van den Hengel, Anton},
  booktitle={NeurIPS},
  year={2024}
}

@article{nmc,
  title={A simple baseline that questions the use of pretrained-models in continual learning},
  author={Janson, Paul and Zhang, Wenxuan and Aljundi, Rahaf and Elhoseiny, Mohamed},
  journal={NeurIPS Workshop on Distribution Shifts},
  year={2022}
}


@inproceedings{film,
  title={First session adaptation: A strong replay-free baseline for class-incremental learning},
  author={Panos, Aristeidis and Kobe, Yuriko and Reino, Daniel Olmeda and Aljundi, Rahaf and Turner, Richard E},
  booktitle={ICCV},
  year={2023}
}

@inproceedings{slca,
  title={Slca: Slow learner with classifier alignment for continual learning on a pre-trained model},
  author={Zhang, Gengwei and Wang, Liyuan and Kang, Guoliang and Chen, Ling and Wei, Yunchao},
  booktitle={ICCV},
  year={2023}
}

@inproceedings{pivot,
  title={Pivot: Prompting for video continual learning},
  author={Villa, Andr{\'e}s and Alc{\'a}zar, Juan Le{\'o}n and Alfarra, Motasem and Alhamoud, Kumail and Hurtado, Julio and Heilbron, Fabian Caba and Soto, Alvaro and Ghanem, Bernard},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{sprompt,
  title={S-prompts learning with pre-trained transformers: An occam’s razor for domain incremental learning},
  author={Wang, Yabin and Huang, Zhiwu and Hong, Xiaopeng},
  journal={NeurIPS},
  year={2022}
}

@inproceedings{l2p,
  title={Learning to prompt for continual learning},
  author={Wang, Zifeng and Zhang, Zizhao and Lee, Chen-Yu and Zhang, Han and Sun, Ruoxi and Ren, Xiaoqi and Su, Guolong and Perot, Vincent and Dy, Jennifer and Pfister, Tomas},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{dualprompt,
  title={Dualprompt: Complementary prompting for rehearsal-free continual learning},
  author={Wang, Zifeng and Zhang, Zizhao and Ebrahimi, Sayna and others},
  booktitle={ECCV},
  year={2022}
}

@inproceedings{codaprompt,
  title={Coda-prompt: Continual decomposed attention-based prompting for rehearsal-free continual learning},
  author={Smith, James Seale and Karlinsky, Leonid and Gutta, Vyshnavi and others},
  booktitle={CVPR},
  year={2023}
}

@article{simplecil_aper,
  title={Revisiting class-incremental learning with pre-trained models: Generalizability and adaptivity are all you need},
  author={Zhou, Da-Wei and Cai, Zi-Wen and Ye, Han-Jia and Zhan, De-Chuan and Liu, Ziwei},
  journal={IJCV},
  year={2024},
  publisher={Springer}
}

@inproceedings{ease,
  title={Expandable subspace ensemble for pre-trained model-based class-incremental learning},
  author={Zhou, Da-Wei and Sun, Hai-Long and Ye, Han-Jia and Zhan, De-Chuan},
  booktitle={CVPR},
  year={2024}
}

@inproceedings{mos,
  title={MOS: Model Surgery for Pre-Trained Model-Based Class-Incremental Learning},
  author={Sun, Hai-Long and Zhou, Da-Wei and Zhao, Hanbin and Gan, Le and Zhan, De-Chuan and Ye, Han-Jia},
  booktitle={AAAI},
  year={2024}
}

@inproceedings{ptm_effect1,
title={Effect of scale on catastrophic forgetting in neural networks},
author={Vinay Venkatesh Ramasesh and Aitor Lewkowycz and Ethan Dyer},
booktitle={ICLR},
year={2022}
}

@article{ptm_effect2,
  title={An empirical investigation of the role of pre-training in lifelong learning},
  author={Mehta, Sanket Vaibhav and Patil, Darshan and Chandar, Sarath and Strubell, Emma},
  journal={JMLR},
  volume={24},
  number={214},
  year={2023}
}

@inproceedings{ptm_effect3,
  title={Class-incremental learning with strong pre-trained models},
  author={Wu, Tz-Ying and Swaminathan, Gurumurthy and Li, Zhizhong and Ravichandran, Avinash and Vasconcelos, Nuno and Bhotika, Rahul and Soatto, Stefano},
  booktitle={CVPR},
  year={2022}
}

%neuroscience

@book{stability_plasticity,
  title={Studies of mind and brain: Neural principles of learning, perception, development, cognition, and motor control},
  author={Grossberg, Stephen T},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@inproceedings{se_block,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={CVPR},
  year={2018}
}

@article{sparse_orthogonal,
  title={Sparse Orthogonal Parameters Tuning for Continual Learning},
  author={Ning, Kun-Peng and Ke, Hai-Jian and Liu, Yu-Yang and Yao, Jia-Yu and Tian, Yong-Hong and Yuan, Li},
  journal={arXiv:2411.02813},
  year={2024}
}

@article{o_lora,
  title={Orthogonal subspace learning for language model continual learning},
  author={Wang, Xiao and Chen, Tianze and Ge, Qiming and Xia, Han and Bao, Rong and Zheng, Rui and Zhang, Qi and Gui, Tao and Huang, Xuanjing},
  journal={arXiv:2310.14152},
  year={2023}
}

@article{ventral,
  title={Recognizing depth-rotated objects: evidence and conditions for three-dimensional viewpoint invariance.},
  author={Biederman, Irving and Gerhardstein, Peter C},
  journal={Journal of Experimental Psychology: Human perception and performance},
  volume={19},
  number={6},
  pages={1162},
  year={1993},
  publisher={American Psychological Association}
}

@article{ventral1,
  title={Recognition-by-components: a theory of human image understanding.},
  author={Biederman, Irving},
  journal={Psychological review},
  volume={94},
  number={2},
  pages={115},
  year={1987},
  publisher={American Psychological Association}
}

@article{cortex,
  title={Reshaping sensory representations by task-specific brain states: Toward cortical circuit mechanisms},
  author={Zhang, Ningyu and Xu, Ning-long},
  journal={Current Opinion in Neurobiology},
  volume={77},
  pages={102628},
  year={2022},
  publisher={Elsevier}
}

@article{cortex1,
  title={Cortical circuits for perceptual inference},
  author={Friston, Karl and Kiebel, Stefan},
  journal={Neural Networks},
  volume={22},
  number={8},
  pages={1093--1104},
  year={2009},
  publisher={Elsevier}
}

@article{cortex2,
  title={Task structure tailors the geometry of neural representations in human lateral prefrontal cortex},
  author={Bhandari, Apoorva and Keglovits, Haley and Badre, David},
  journal={bioRxiv},
  year={2024}
}