\documentclass{article}

% if you need to pass options to natbib, use, e.g.:

\PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2024

% ready for submission
%\usepackage{neurips_2024}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
\usepackage[preprint]{neurips_2024}

% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2024}

% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2024}

\usepackage[table]{xcolor}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors

%MOY PACKAGE
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{enumitem}
\usepackage{mathrsfs} % Add this in the preamble
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsmath}
\usepackage{pgfplots}
\usepackage{subcaption}
\pgfplotsset{compat=1.18}
\usepgfplotslibrary{groupplots}
\usepgfplotslibrary{colormaps}
\usepackage[capitalize]{cleveref}
\crefname{figure}{Figure}{Figures}


\title{Sculpting \texttt{[CLS]} Features for Pre-Trained Model-Based Class-Incremental Learning}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  Murat Onur Yildirim \\
  TU Eindhoven\\
  \texttt{m.o.yildirim@tue.nl} \\
  \And
  Elif Ceren Gok Yildirim \\
  TU Eindhoven\\
  \texttt{e.c.gok@tue.nl} \\
  \And
  Joaquin Vanschoren \\
  TU Eindhoven\\
  \texttt{j.vancshoren@tue.nl} \\
}

\begin{document}

\maketitle

\vspace{-10pt}
\begin{abstract}
Class-incremental learning requires models to continually acquire knowledge of new classes without forgetting old ones. Although pre-trained models have demonstrated strong performance in class-incremental learning, they remain susceptible to catastrophic forgetting when learning new concepts.
Excessive plasticity in the models breaks generalizability and causes forgetting, while strong stability results in insufficient adaptation to new classes. This necessitates effective adaptation with minimal modifications to preserve the general knowledge of pre-trained models.
To address this challenge, we first introduce a new parameter-efficient fine-tuning module ‘Learn and Calibrate’, or LuCA, designed to acquire knowledge through an adapter-calibrator couple, enabling effective adaptation with well-refined feature representations.
Second, for each learning session, we deploy a sparse LuCA module on top of the last \texttt{[CLS]} token just before the classifier, which we refer to as ‘Token-level Sparse Calibration and Adaptation’, or TOSCA.
This strategic design improves the orthogonality between the modules and significantly reduces both training and inference complexity. By leaving the generalization capabilities of the pre-trained models intact and adapting exclusively via the last token, our approach achieves a harmonious balance between stability and plasticity. Extensive experiments demonstrate TOSCA’s state-of-the-art performance while introducing \textasciitilde{8} times fewer parameters compared to prior methods.
\vspace{-3pt}
%The code is publicly available [linklinlinklink].
\end{abstract}

\input{1-intro}
\input{2-related_work}
\input{3-background}
\input{4-method}
\input{5-experiments}
\input{6-conclusion}

{\small
\bibliographystyle{unsrt}
\bibliography{biblo}
}

\input{7-appendix}

%\input{8-checklist}

\end{document}