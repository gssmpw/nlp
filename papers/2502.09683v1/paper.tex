%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[sigconf]{acmart}

\settopmatter{printacmref=false} % Removes ACM Reference Format
\renewcommand\footnotetextcopyrightpermission[1]{} % Removes copyright notice

\acmConference{}{}{} % Clears conference information
\acmBooktitle{} % Clears book title
\acmPrice{} % Clears price
\acmISBN{} % Clears ISBN
\setcopyright{none}

\AtBeginDocument{\fancyhead{}}


%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
%\setcopyright{acmlicensed}
%\copyrightyear{2018}
%\acmYear{2018}
%\acmDOI{XXXXXXX.XXXXXXX}
%%% These commands are for a PROCEEDINGS abstract or paper.
%\acmConference[Conference acronym 'XX]{Make sure to enter the correct
%  conference title from your rights confirmation email}{June 03--05,
%  2018}{Woodstock, NY}
%%%
%%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%%  from ``Proceedings of ...''!
%%%
%%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%%  June 03--05, 2018, Woodstock, NY}
%\acmISBN{978-1-4503-XXXX-X/2018/06}






%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

\usepackage{hyperref}

\usepackage[normalem]{ulem}
\useunder{\uline}{\ul}{}

% For theorems and such
% \usepackage{amsmath}
% \usepackage{amssymb}
\usepackage{mathtools}
% \usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}
\usepackage[textsize=small]{todonotes}
\setuptodonotes{inline}


\usepackage{amsmath}
%\usepackage[T1]{fontenc}
%\usepackage{lmodern}

\usepackage{xcolor}
\usepackage{multirow}

\DeclareMathOperator{\train}{train}
\DeclareMathOperator{\fix}{fix}
%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
%\title[Towards Understanding the Current State of Time-Series Forecasting]{Towards Understanding the Current State of Time-Series Forecasting: Evaluating Time-Series Forecasting with Challenging Datasets and Tuned Lookback-Windows}

%\title{FaCT: Channel Dependence is Essential for Time Series! \\ Looking Deeper into Forecasting Evaluation using ODE Datasets}

\title[How Biased is Time-Series Forecasting?]{Channel Dependence, Limited Lookback Windows, and the Simplicity of Datasets: How Biased is Time Series Forecasting?}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.


\author{Ibram Abdelmalak}
\authornote{Authors contributed equally to this research.}
\email{abdelmalak@ismll.de}

\affiliation{%
  \institution{Information Science and Machine Learning Lab \& VWFS Data Analytics Research Center\\ University of Hildesheim}
  \city{Hildesheim}
  \state{Niedersachsen}
  \country{Germany}
}


\author{Kiran Madhusudhanan}
\authornotemark[1]
\email{kiranmadhusud@ismll.de}
\affiliation{%
	\institution{Information Science and Machine Learning Lab \& VWFS Data Analytics Research Center\\ University of Hildesheim}
	\city{Hildesheim}
	\state{Niedersachsen}
	\country{Germany}
}
\author{Jungmin Choi}
\authornotemark[1]
\email{choi@ismll.de}
\affiliation{%
	\institution{Information Science and Machine Learning Lab \& VWFS Data Analytics Research Center\\ University of Hildesheim}
	\city{Hildesheim}
	\state{Niedersachsen}
	\country{Germany}
}

\author{Maximilian Stubbemann}

\email{stubbemann@ismll.de}
\affiliation{%
	\institution{Information Science and Machine Learning Lab \& VWFS Data Analytics Research Center\\ University of Hildesheim}
	\city{Hildesheim}
	\state{Niedersachsen}
	\country{Germany}
}

\author{Lars Schmidt-Thieme}

\email{schmidt-thieme@ismll.de}
\affiliation{%
	\institution{Information Science and Machine Learning Lab \& VWFS Data Analytics Research Center\\ University of Hildesheim}
	\city{Hildesheim}
	\state{Niedersachsen}
	\country{Germany}
}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Abdelmalak et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
	Time-series forecasting research has converged to a small set of datasets and a
	standardized collection of evaluation scenarios. Such a standardization is to a
	specific extent needed for comparable research. However, the underlying
	assumption is, that the considered setting is a representative for the problem
	as a whole. In this paper, we challenge this assumption and show that the
	current scenario gives a strongly biased perspective on the state of
	time-series forecasting research. To be more detailed, we show that the current
	evaluation scenario is heavily biased by the simplicity of the current datasets.
	We furthermore emphasize, that when the lookback-window is properly tuned,
	current models usually do not need any information flow across channels. However,
	when using more complex
	benchmark data, the situation changes: Here, modeling channel-interactions in a
	sophisticated manner indeed enhances performances. Furthermore, in this complex
	evaluation scenario, Crossformer, a method regularly neglected as an important
	baseline, is the SOTA method for time series forecasting. Based on this, we
	present the Fast Channel-dependent Transformer (FaCT), a simplified version of
	Crossformer which closes the runtime gap between Crossformer and TimeMixer,
	leading to an efficient model for complex forecasting datasets.

%Time-series forecasting research has converged to a small set of datasets and a
%standardized collection of evaluation scenarios. Such a standardization is to a
%specific extent needed for comparable research. However, the underlying
%assumption is, that the considered setting is a representative for the problem
%as a whole. In this paper, we challenge this assumption and show that the
%current scenario gives a strongly biased perspective on the current state of
%time-series forecasting research. To be more detailed, we show that the current
%evaluation scenario with a fixed lookback window heavily influences the
%performance across different methods. When the Lookback-Window is properly
%tuned, the picture strongly differs. Furthermore, we show, that the simplicity
%of the currently considered datasets gives a bias towards shallow linear models
%and models neglecting channel-dependencies. When using more
%complex benchmark data, Crossformer, a method regularly neglected as an
%important baseline, is the SOTA method for time-series forecasting. Based on
%this, we present LightFormer, a simplified version of Crossformer which closes
%the runtime gap between Crossformer and PatchTST, leading to an efficient model
%for complex forecasting datasets.  

\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>00000000.0000000.0000000</concept_id>
  <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>00000000.00000000.00000000</concept_id>
  <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>00000000.00000000.00000000</concept_id>
  <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>00000000.00000000.00000000</concept_id>
  <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>
\end{CCSXML}

%\ccsdesc[500]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
%\ccsdesc[300]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
%\ccsdesc{Do Not Use This Code~Generate the Correct Terms for Your Paper}
%\ccsdesc[100]{Do Not Use This Code~Generate the Correct Terms for Your Paper}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Time Series Forecasting, Channel Dependency, ODE Datasets, Transformer, Lookback Window Tuning}
%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
% \begin{teaserfigure}
%   \includegraphics[width=\textwidth]{sampleteaser}
%   \caption{Seattle Mariners at Spring Training, 2010.}
%   \Description{Enjoying the baseball game from the third-base
%   seats. Ichiro Suzuki preparing to bat.}
%   \label{fig:teaser}
% \end{teaserfigure}

%\received{20 February 2007}
%\received[revised]{12 March 2009}
%\received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
Time-Series Forecasting (TSF) is one of the most common tasks tackled in modern
machine-learning research. However, experimental evaluation of
forecasting methods has arrived at a state, where it is standardized to a high
extent. Most of the papers focus 
\begin{itemize}
\item on the same small set of data to evaluate
on~\cite{nie23,liu24,zeng23,zhang23,chen23} and
\item an experimental setting, where the lookback-window to predict in the
future is fixed~\cite{nie23,liu24,zhang23,chen23}.
\end{itemize}

While such a standardized evaluation is generally preferable for fair and accurate
comparisons of different forecasting methods,
it has its pitfalls: By using a small set of datasets in all papers, it is
assumed that they are \emph{representative} for TSF as a whole and that the best
forecasting method \emph{on these particular datasets} should be seen as the best
forecasting method \emph{in general}. The same holds for the lookback-window:
The assumption, that all methods should be tested on the same lookback-window
and that this leads to a representative result for finding the state-of-the art
in TSF is questionable.

One of the main questions in TSF research is whether channel correlations are useful for
forecasting. There exist indeed real-world applications where information flow
across channels is highly plausible, as for example in weather forecasting,
where the current high humidity (one feature) can lead to a very plausible high amount of rain (another feature) in the future. Another real world example modeled by chaotic ODEs is the Cell Cycle ODE which models cell growth and DNA replication activities in the human body. For instance, the effect of cdk1 and cdk2 on the degradation of cyclin through the cyclin and enzyme control~\cite{romond1999}. In such cases, information from different channels is essential to monitor the future degradation of cyclin.



However, in practice, it is often
observed, that with enough historical data, forecasting can be done successfully
from the considered channel alone. Here, a major breakthrough has been the
publication of PatchTST~\cite{nie23}, a model which patches time-series channels
into subsequent chunks which are processed by a BERT~\cite{devlin19}-inspired
architecture and pre-training scheme. One of the crucial findings here was, that
TSF can indeed be done effectively in a \emph{channel-independent manner} where
the forecast of a channel only depends on the historical data of this channel. Furthermore,
it has been shown that DLinear, a linear channel-independent
model~\cite{zeng23}, can compete with sophisticated Transformer architectures.
One of the most promising architectures for forecasting in a
\emph{channel-dependent manner}, namely Crossformer, seems to be not competitive
anymore according to a recent survey~\cite{wang24} and has been either dropped
completely as a baseline or is not belonging to the best-performing baselines in
recent papers~\cite{wu24,gao24,han24}. Nevertheless, a variety of recent approaches explicitly
incorporate layers which model information flow across channels, challenging the
findings of PatchTST~\citep{liu24,chen23TSMixer,wang24TM}. One of these papers,
the \emph{Inverted Transformer}~\citep{liu24} even claims that only
inter-channel attention per time-point is needed and the mixing of different
time-points per channel can be done solely with MLPs. 
However, in their paper, they evaluate all methods with a short lookback-window of
96 timesteps, while the results for PatchTST on longer lookback-windows
outperform the reported results of iTransformer~\cite{nie23}.

In this paper, we will contribute towards a
better assessment of the current state of TSF. To be more detailed, we will show
that for forecasting on the current datasets, modeling channel-dependence is
overall \textbf{not} beneficial. Our experimental findings indicate, that removing the layers
being responsible for information flow across channels does not often hurt the
performance. This raises the question, whether the methods we have for modeling
channel-dependence are not sophisticated or whether the datasets we use are
too simple and do not need that. In this paper, we make a case for the latter. To
be more detailed, we show that, when
using a more complex benchmark suit, namely the chaotic ODE
benchmark~\cite{gilpin21}, channel-dependence becomes a strong factor leading
to a consistent performance enhancement for models with sophisticated channel
mixing. Furthermore, in this harder evaluation scenario, Crossformer
is
the best performing model and simple linear models are not competitive
anymore. All of this together strongly indicates that our assessment of the
current state of time-series forecasting is biased by the simplicity of the
currently used datasets.  

Building up on the success of Crossformer on the chaotic ODE benchmark, we propose a lightweight modification of it, which
drops the decoder for making use of the most important features while lowering the runtime and memory costs significantly. The resulted model,
the \underline{Fa}st \underline{C}hannel-dependent \underline{T}ransformer (FaCT) has a runtime complexity reduction of 51.17\% compared
to Crossformer while maintaining 97\% performance of its performance on average in the ODE Benchmark dataset experiments. 
This, places the FaCT model as the second best model on the ODE Benchmark, only second to Crossformer and is the best model
considering performance-runtime trade off.

To sum up, our contributions are as follows.
\begin{itemize}
\item  We show that channel-dependence is not crucial for time-series forecasting
on the usually considered datasets. When the lookback-window is properly hyperparameter-tuned,
the channel independent PatchTST model is still the overall SOTA and in 15 out
of 21 comparisons, dropping the layers which are responsible for information
flow across channels in channel-dependent models (TimeMixer, TSMixer,
Crossformer) does not decrease the performance. See \Cref{sec:tune_lw} and~\Cref{sec:cd}.
\item We show that currently known results are heavily impacted by the
simplicity of the commonly considered datasets.  When
using the challenging chaotic ODE benchmark suite, Crossformer suddenly becomes
the SOTA TSF model and the relative gap of the simple DLinear model to the SOTA
explodes. See~\Cref{sec:complex_sota}. 
\item We propose the \emph{Fast Channel-dependent Transformer}
(FaCT), a novel modification of Crossformer, which still outperforms all
competitors but with a reduction in complexity by approximately 51.17\% on 
the Chaotic-ODE dataset in comparison to the best performing Crossformer model. See \Cref{sec:cf25}.
\end{itemize}

\section{Foundations}

\paragraph{\textbf{Time-Series Forecasting}}
A \emph{multivariate time-series} is a sequence $(x_l)_{l=1}^L \in
(\mathbb{R}^{C})^{L}$, which we can interpret as a matrix $x \in \mathbb{R}^{C \times
L}$. A time-series dataset consists of tuples of time-series $(x,y) \in
\mathbb{R}^{C \times L} \times \mathbb{R}^{C \times H}$, where we call $x$ the
\emph{forecasting query} to the \emph{forecasting answer} $y$. In the
\emph{time-series forecasting problem} we have a dataset
$\mathcal{D}_{\train}\subseteq \mathbb{R}^{C \times L} \times \mathbb{R}^{C
\times H}$ drawn from a distribution $p \sim \mathbb{R}^{C \times L} \times \mathbb{R}^{C
\times H}$. The goal is to train from $\mathcal{D}_{\train}$ a model $\hat{y}:
\mathbb{R}^{C \times L} \to \mathbb{R}^{C \times H}$ such that 
\begin{align}
  \mathbb{E}_{(x,y) \sim p} \ell (y,\hat{y}(x)).
\end{align}
is minimized. Here, $\ell: \mathbb{R}^{C \times H} \times \mathbb{R}^{C \times
H} \to \mathbb{R}$ is the \emph{loss-function}, for which the \emph{Mean Squared
Error} (MSE) is the most common choice.

To sum up, we learn from the training data $\mathcal{D}_{\train}$ a model
$\hat{y}$ which can predict from having the last $L$ observations for all
\emph{channels} $1,\dots,C$ the next $H$ observations. Here, $L$ denotes the
\emph{lookback window} and $H$ the \emph{forecasting horizon}.

\paragraph{\textbf{Channel Dependence.}}
One of the main findings of PatchTST~\cite{nie23} was, that on the usually
considered datasets, channel-independent models are sufficient to forecast and
no interactions between channels are needed. This finding was contradicted by
multiple follow-up papers such as iTranformer~\cite{liu24} and
TimeMixer~\cite{wang24TM}. Formally, we call a model $\hat{y}: \mathbb{R}^{C
\times L} \to \mathbb{R}^{C \times H}$ \emph{channel-independent} when for each
$x,\tilde{x} \in \mathbb{R}^{C \times L}$:
\begin{equation}
  x_{c} = \tilde{x}_{c} \Rightarrow \hat{y}(x)_{c} = \hat{y}(\tilde{x})_{c},
\end{equation}
i.e., the prediction for a specific channel only depends on the input of this
channel.

\paragraph{\textbf{Fixing Lookback Windows.}}
Regarding the lookback-window, time-series forecasting nowadays works with
limited lookback windows, i.e., the queries $x \in \mathbb{R}^{L \times C}$ are
shrunk to shape $\mathbb{R}^{L_{\fix} \times C}$ (mostly $L_{\fix}=96$) by
considering only the last $L_{\fix}$ observations for each lookback window instead of treating it as a hyperparameter of the model.


\section{Related Works}
\label{sec:Related_Works}

\paragraph{\textbf{Deep Neural Models}}
TSF models are based on various methods: MLPs, Transformers, CNNs, and RNNs.
The simplicity of MLP-based models shows both high efficiency and competitive performance in TSF. DLinear~\cite{zeng22Dlinear} focues on only temporal information by processing each channel independently. 
TSMixer~\cite{chen23TSMixer} extends this by introducing cross-channel MLPs emphasizing the importance of learning channel correlations.
TimeMixer~\cite{wang24TM} learns both channel correlation and temporal information by decomposing data into seasaonality and trend in multi-resolution by downsampling.
Furthermore, Transformer-based models have become dominant in TSF. Informer~\cite{informer} improves efficiency with ProbSparse attention across all channels. 
In contrast, Autoformer~\cite{autoformer} and FEDformer~\cite{fedformer} captures channel dependencies through trend-seasonality decomposition and frequency-domain representations respectively.
PatchTST~\cite{nie23} focuses solely on local temporal patterns in each channel independently with patching mechanism. 
On the contrary, Crossformer~\cite{zhang23} captures multi-resolution temporal and cross-channel dependencies with multiple attention mechanisms.
iTransformer~\cite{liu24} reinterprets the Transformer architecture by applying feature-based attention across channels to capture channel dependencies.
CNN- and RNN-based models remain competitive in TSF.
MICN~\cite{MICN} employs isometric convolution for capturing both local and global channel correlation.
TimesNet~\cite{timesnet} reshapes time series into 2D representations, capturing periodic patterns and inter-channel dependencies via convolution.
Although many models consider channel dependence, most recent SOTA models in the TSF domain are based on channel independence.
This is because commonly used datasets, can be easily forecasted without accounting for channel correlation.

\paragraph{\textbf{Channel Dependence and Independence}}
\label{sec:CDI}
TSF models can be categorized based on whether they leverage channel dependencies. Channel dependence refers to considering the dependencies between different features~\cite{chen23TSMixer}, whereas channel independence treats multivariate data as separate univariate series, focusing on intra-channel temporal relationships~\cite{nie23}.
For example, PatchTST~\cite{nie23} captures temporal information for each channel individually.
In contrast, iTransformer~\cite{liu24} focuses solely on capturing channel dependencies. Additionally, some models leverage both temporal and cross-channel information.
For instance, models such as TSMixer~\cite{chen23}, Crossformer~\cite{zhang23}, and TimesNet~\cite{timesnet} emphasize learning both inter-/intra-channel dependencies.
\cite{ci_distri} argues that channel independence is more effective and robust, particularly due to distribution drift in datasets. When datasets are split into training and testing sets, their distributions often differ significantly, making it difficult for a model to capture dependencies between channels.
In contrast, ~\cite{cd_rethinking} suggests that channel dependence remains relevant, especially when accounting for time lags between different variables.
However, recent studies primarily focus on standard datasets, where channel dependence is often easy to overlook. As a result, there has been little in-depth exploration of the importance of channel dependence in the TSF domain.
\section{General Experimental Setup}
\label{sec:experimental setup}

For all experiments considered in the following sections, there is a core set of
experimental design choices which are as follows.

\paragraph{\textbf{Models Considered.}}
We picked a diverse set of established
well performing models with the main variation happening on complexity of the
model and whether these models originally account for channel dependency or not.
These different categories include MLP-based models (TSMixer \cite{chen23} and
TimeMixer \cite{wang24}), Attention-based models (PatchTST \cite{nie23},
iTransformers \cite{liu24}, and Crossformer \cite{zhang23}), and Dlinear
\cite{zeng23} as the simplest but one of the strong baselines. Afterwards, we include in the comparison our proposed FaCT model which is a significantly faster adaptation of the crossformer model.

\paragraph{\textbf{The Standard Datasets.}}
As clarified earlier in the introduction, we study two different
categories of datasets for understanding the effect of having more complex
datasets that includes channel correlation on different models performance.
First, we consider the common TSF benchmark datatsets used on most recent SoTA
papers and surveys~\cite{nie23,liu24,wang24,chen23,zhang23,zeng23}.
These datasets include \emph{weather} dataset, the
\emph{electricity} dataset, the \emph{traffic} dataset, and the \emph{electricity transformer
temperature (ETT)} datasets collected on two different transformers for two different
resolutions each. The establishment of these datasets as the standard datasets
for time-series forecasting is commonly credited to the Informer
paper~\citep{informer}. For more details on granularities, train/validation/test
split
and number of features used for all datasets, please refer to \Cref{sec:dataset-description}. We will refer to these datasets as \emph{the
standard datasets}.

\paragraph{\textbf{The Chaotic ODE Benchmark.}}
As a second collection of datasets, we consider the benchmark proposed by~\citet{gilpin21}.
This benchmark has been introduced as a time-series collection without simple, regular and
recurring patterns, proposing a challenging setting for time-series forecasting.
However, the benchmark paper itself does not contain an evaluation of modern forecasting methods, moreover none of the related works experimented on it for TSF. We select a subset of datasets from the benchmark which fulfills two
distinctive criteria: \textit{(i)} They are generated based on chaotic
systems which makes also the generated trajectories unpredictable and has non
repeating patterns that can be challenging for most time series models.
\textit{(ii)} They are based on the ODE itself in which there is a clear
mathematical correlation between the different variables such as the rate of
change of a specific feature depending on the rate of change of some other
features. For getting datasets that are more complex with respect to criterion (i), we
calculated the \textit{Largest Lyapunov exponent} \cite{gilpin21}, which is a
common measure of how chaotic a system is. Then we choose the datasets with a
multivariate setting (for achieving criterion (ii)) and with high \textit{Largest Lyapunov exponent} value. Through this, we acquired a set of six
datasets that have complex temporal patterns as well as channel dependency. We
will refer to these datasets as \emph{the chaotic ODE datasets} or simply
\emph{the complex datasets}.


\paragraph{\textbf{Channel Dependence and Channel Independence.}}
For some of the models used, two versions exist or can be derived: A channel
dependent (CD) and a channel independent (CI) versions. For CD, the model tries to
capture cross channel correlation either through attention mechanism or MLPs
based on the original model structure. On the contrary, CI versions do not
capture cross channel correlations, but rather is applied to each channel
separately. Important note here though is that for DLinear, we use CI version
only, as the main essence of DLinear is to be the simplest possible baseline.
For iTransformer, we provide only CD version as the main strength of the model
is capturing cross-channel correlation through attention mechanism and if this
part is removed, the model will be simplified to a MLP-based
model. In ~\Cref{sec:CI-CD-Derivation}, we show in detail how different versions of different models are derived if not already existent in the respective paper.

\paragraph{\textbf{Hyperparameter Tuning.}}
We ensure a fair evaluation through the following procedure: For hyperparameters
which affect multiple of the considered models, we ensure that the same search
space is used across models. For hyperparameters specific to some models (such
as the patch length for PatchTST), we stick to the search spaces of the original paper. 
For each hyperparameter, we define either a set of
values (for categorical hyperparameters) or a range values (for continuous
ones). We validate the performance of each set of hyperparameters on the
previously mentioned validation set. The hyperparameter space is searched
through a Bayesian-based approach from the optuna library \cite{akiba19}. This
approach encourages hyperparameter setups that have high probability of
producing good performance. This
procedure is run for 20 trials per experimental setup. We define here one
experimental setup as a set of a specific model, specific dataset, and a
specific forecasting horizon. We emphasize here the usage of the lookback window as a hyperparameter which ensures
producing the best possible results for each given model (yielding what we think
the fairest comparison possible). For a detailed look on the hyperparameter
search space, refer to Appendix~\ref{sec:hyperparameter-tuning}.


\section{PatchTST is the SOTA Time-Series Forecasting Model When the Lookback Window is Properly Tuned}
\label{sec:tune_lw}
The standard scenario  is still to consider a fixed
lookback-window of $L_{\fix}=96$ for forecasting~\citep{liu24,zeng23,wang24TM,lin24}. This is
especially outstanding since the importance of the Lookback-Window has been
emphasized in the past: The DLinear paper~\citep{zeng23} argues that their
linear model profits more from longer lookback-windows than transformer models
around at that time, while PatchTST~\citep{nie23} (a transformer model proposed
after DLinear) clearly profits from
increasing the Lookback-Window. While some papers start to include results for
tuned lookback-window in their appendix~\citep{lin24,wang24TM}, the main
experiments still are often conducted with fixed lookback-windows. One exception
here is given by~\citet{wang24}, where both setups are considered in the main
text. To this end, we reproduce the current time-series forecasting models in
our above mentioned evaluation settings where we do fair and extensive
hyperparameter-tuning, including tuning the lookback-window. If not reported
otherwise, we report results over 5 different seeds. In \Cref{tab:Standard
Datasets Average Results}, one can find the results averaged over the
forecasting horizons 96, 192, 336 and 720 for the standard datasets. The values for the individual
lookback-windows can be found in
~\Cref{sec:detailed-results}. Our main findings are as follows.
\begin{enumerate}
\item \textbf{PatchTST is still the SOTA for Time-Series Forecasting.} In 3 out
of 7 datasets the standard channel-independent version of PatchTST leads to the
best performance. For three other datasets, this version of PatchTST is the
second best model or the third best. Only on the Weather data, its performance
is not in the top 3. Its average rank across the datasets is 2.14, which is by
far the best rank with a gap of 0.57 to the second best model, the channel
independent version of TSMixer.
\item \textbf{Linear Models are still competitive with todays forecasting models.} The performance of Dlinear on
the usual datasets is still close to the considered models. Over all 6 datasets,
it has an average rank of 5.43 out of 10 models. For ETTh1, it is the
second best model, being only beaten by PatchTST by a vanishing marging.
\item \textbf{Crossformer is not competitive to the current SOTA.} The
Crossformer model and PatchTST model have been published in parallel at ICLR
2023 and thus did not compare against each other. In the usual evaluation
scenario, the channel-dependent default version of Crossformer is always outperformed by
PatchTST and DLinear. For the channel-independent variant, this still holds for
all datasets but Weather.
\end{enumerate}



\begin{table*}[ht]
	\begin{tabular}{l|cc|cc|cc|c|c|cc}
	\toprule
	\textbf{Dataset / Model} & \multicolumn{2}{c}{\textbf{PatchTST}}                                                         & \multicolumn{2}{c}{\textbf{TSMixer}}                                                         & \multicolumn{2}{c}{\textbf{Crossformer}}                                                     & \multicolumn{1}{c}{\textbf{DLinear}}                 & \multicolumn{1}{c}{\textbf{iTrans.}} & \multicolumn{2}{c}{\textbf{TimeMixer}}                                                             \\
							 & \multicolumn{1}{c}{\textbf{CI}}                            & \multicolumn{1}{c}{\textbf{CD}} & \multicolumn{1}{c}{\textbf{CI}}                           & \multicolumn{1}{c}{\textbf{CD}} & \multicolumn{1}{c}{\textbf{CI}}                           & \multicolumn{1}{c}{\textbf{CD}} & \multicolumn{1}{c}{\textbf{CI}} & \multicolumn{1}{c}{\textbf{CD}}            & \multicolumn{1}{c}{\textbf{CI}}                           & \multicolumn{1}{c}{\textbf{CD}}       \\ 
							 \midrule 
	\textbf{ETTh1}           & \multicolumn{1}{c|}{{\color[HTML]{0000FF} \textbf{0.422}}}  & 0.437                            & \multicolumn{1}{c|}{\textbf{0.438}}                        & 0.453                            & \multicolumn{1}{c|}{0.477}                                 & \textbf{0.456}                   & 0.423                            & 0.511                                       & \multicolumn{1}{c|}{\textbf{0.434}}                        & 0.489                                  \\ 
	\textbf{Weather}         & \multicolumn{1}{c|}{0.245}                                  & \textbf{0.233}                   & \multicolumn{1}{c|}{\textbf{0.230}}                        & 0.241                            & \multicolumn{1}{c|}{{\color[HTML]{0000FF} \textbf{0.236}}} & 0.296                            & 0.289                            & 0.253                                       & \multicolumn{1}{c|}{0.247}                                 & {\color[HTML]{333333} \textbf{0.246}}  \\ 
	\textbf{Electricity}     & \multicolumn{1}{c|}{{\color[HTML]{0000FF} \textbf{0.159*}}} & 0.170                              & \multicolumn{1}{c|}{\textbf{0.162}}                        & 0.170                            & \multicolumn{1}{c|}{\textbf{0.166}}                        & \textbf{0.188}                   & 0.162                            & 0.220                                       & \multicolumn{1}{c|}{\textbf{0.173}}                                   & 0.260                                  \\ 
	\textbf{ETTh2}           & \multicolumn{1}{c|}{\textbf{0.365}}                         & 0.382                            & \multicolumn{1}{c|}{\textbf{0.378}}                        & 0.390                            & \multicolumn{1}{c|}{0.741}                                 & \textbf{0.691}                   & 0.507                            & {\color[HTML]{0000FF} \textbf{0.363}}       & \multicolumn{1}{c|}{\textbf{0.371}}                        & 0.378                                  \\ 
	\textbf{ETTm1}           & \multicolumn{1}{c|}{\textbf{0.356}}                         & 0.371                            & \multicolumn{1}{c|}{\textbf{0.356}}                        & 0.370                            & \multicolumn{1}{c|}{\textbf{0.393}}                        & 0.426                            & 0.359                            & 0.374                                       & \multicolumn{1}{c|}{{\color[HTML]{0000FF} \textbf{0.355}}} & 0.408                                  \\ 
	\textbf{ETTm2}           & \multicolumn{1}{c|}{\textbf{0.258}}                         & 0.259                            & \multicolumn{1}{c|}{{\color[HTML]{0000FF} \textbf{0.257}}} & 0.273                            & \multicolumn{1}{c|}{\textbf{0.433}}                        & 0.485                            & 0.289                            & {\color[HTML]{0000FF} \textbf{0.257}}       & \multicolumn{1}{c|}{\textbf{0.275}}                        & 0.342                                  \\ 
	\textbf{Traffic}         & \multicolumn{1}{c|}{{\color[HTML]{0000FF} \textbf{0.388*}}} & OOM                              & \multicolumn{1}{c|}{\textbf{0.407}}                        & 0.417                            & \multicolumn{1}{c|}{OOM}                                   & {\color[HTML]{333333} 0.542*}    & 0.426                            & OOM                                         & \multicolumn{1}{c|}{OOM}                                   & {\color[HTML]{0000FF} \textbf{0.388*}} \\
    \midrule
	
	\textbf{Wins}         & \multicolumn{1}{c|}{{\color[HTML]{0000FF} \textbf{3}}} & 0                              & \multicolumn{1}{c|}{1}                        & 0                           & \multicolumn{1}{c|}{1}                                   & 0    & 0                            & 2                                         & \multicolumn{1}{c|}{1}                                   & 0 \\ 
	
	\textbf{Average Rank}         & \multicolumn{1}{c|}{{\color[HTML]{0000FF} \textbf{2.14}}} & 5.43                              & \multicolumn{1}{c|}{2.71}                        & 5.00                            & \multicolumn{1}{c|}{7.29}                                   & 8.14    & 5.43                            & 5.86                                         & \multicolumn{1}{c|}{5.29}                                   & 6.57 \\
	\bottomrule

	\end{tabular}
	\caption{This table shows the average results over the 4 forecasting horizons for each variant of the baseline evaluated on MSE for \textbf{the standard datasets}. The best variant for each model is in \textbf{bold} and the best overall model is in \textcolor{blue}{blue}. Note here due to running out of memory for some experiments related to electricity and traffic, we reported the results with "*" from TimeMixer paper from the experiment where they tune the lookback window as well as the hyperparameters (please refer to appendix E in \cite{wang24TM}).}
	\label{tab:Standard Datasets Average Results}
\end{table*}



\section{Crossformer is the SOTA on the Chaotic-ODE Benchmark}
\label{sec:complex_sota}
\begin{table*}[t]
	\begin{tabular}{l|cc|cc|cc|c|c|cc}
	\toprule
	\textbf{Dataset / Model} & \multicolumn{2}{c}{\textbf{PatchTST}}                                                         & \multicolumn{2}{c}{\textbf{TSMixer}}                                                         & \multicolumn{2}{c}{\textbf{Crossformer}}                                                     & \multicolumn{1}{c}{\textbf{DLinear}}                 & \multicolumn{1}{c}{\textbf{iTrans.}} & \multicolumn{2}{c}{\textbf{TimeMixer}}                                                             \\
	& \multicolumn{1}{c}{\textbf{CI}}                            & \multicolumn{1}{c}{\textbf{CD}} & \multicolumn{1}{c}{\textbf{CI}}                           & \multicolumn{1}{c}{\textbf{CD}} & \multicolumn{1}{c}{\textbf{CI}}                           & \multicolumn{1}{c}{\textbf{CD}} & \multicolumn{1}{c}{\textbf{CI}} & \multicolumn{1}{c}{\textbf{CD}}            & \multicolumn{1}{c}{\textbf{CI}}                           & \multicolumn{1}{c}{\textbf{CD}}       \\ 
	\midrule 
	\textbf{Lorenz}          & \multicolumn{1}{c|}{\textbf{0.839}} & 0.841          & \multicolumn{1}{c|}{0.880}       & \textbf{0.868} & \multicolumn{1}{c|}{0.667}       & {\color[HTML]{0000FF} \textbf{0.643}} & 0.9335           & 0.675                                       & \multicolumn{1}{c|}{0.764}          & \textbf{0.673}                        \\ 
	\textbf{BlinkingRotlet}  & \multicolumn{1}{c|}{\textbf{0.424}} & 0.426          & \multicolumn{1}{c|}{0.580}       & \textbf{0.487} & \multicolumn{1}{c|}{0.340}       & {\color[HTML]{0000FF} \textbf{0.311}} & 0.5224           & 0.426                                       & \multicolumn{1}{c|}{\textbf{0.433}} & 0.520                                 \\ 
	\textbf{CellCycle}       & \multicolumn{1}{c|}{\textbf{0.635}} & 0.667          & \multicolumn{1}{c|}{0.792}       & \textbf{0.771} & \multicolumn{1}{c|}{0.429}       & {\color[HTML]{0000FF} \textbf{0.428}} & 0.9349           & 0.808                                       & \multicolumn{1}{c|}{0.679}          & \textbf{0.556}                        \\ 
	\textbf{DoublePendulum}  & \multicolumn{1}{c|}{\textbf{0.653}} & 0.668          & \multicolumn{1}{c|}{0.768}       & \textbf{0.737} & \multicolumn{1}{c|}{0.553}       & \textbf{0.541}                        & 0.8047           & 0.656                                       & \multicolumn{1}{c|}{0.595}          & {\color[HTML]{0000FF} \textbf{0.529}} \\ 
	\textbf{Hopfield}        & \multicolumn{1}{c|}{0.420}          & \textbf{0.346} & \multicolumn{1}{c|}{0.507}       & \textbf{0.435} & \multicolumn{1}{c|}{0.335}       & \textbf{0.316}                        & 0.6895           & 0.300                                       & \multicolumn{1}{c|}{0.622}          & {\color[HTML]{0000FF} \textbf{0.245}} \\ 
	\textbf{LorenzCoupled}   & \multicolumn{1}{c|}{0.881}          & \textbf{0.866} & \multicolumn{1}{c|}{0.950}       & \textbf{0.900} & \multicolumn{1}{c|}{0.700}       & {\color[HTML]{0000FF} \textbf{0.666}} & 0.9630           & 0.857                                       & \multicolumn{1}{c|}{\textbf{0.788}} & 0.832                                 \\
	\midrule
	\textbf{Wins}         & \multicolumn{1}{c|}{0} & 0                              & \multicolumn{1}{c|}{0}                        & 0                           & \multicolumn{1}{c|}{0}                                   & {\color[HTML]{0000FF} \textbf{4} }  & 0                            & 0                                        & \multicolumn{1}{c|}{0}                                   & 2 \\ 
	
	\textbf{Average Rank}         & \multicolumn{1}{c|}{5.17} & 5.67                              & \multicolumn{1}{c|}{8.83}                        & 7.50                            & \multicolumn{1}{c|}{2.50}                                   & {\color[HTML]{0000FF} \textbf{1.50} }   & 9.83                            & 5.17                                         & \multicolumn{1}{c|}{5.50}                                   & 3.30 \\
	\bottomrule
\end{tabular}
	\caption{This table shows the average results over the 4 forecasting horizons for each variant of the baseline evaluated on MSE for the \textbf{chaotic ODE Benchmark}. The best variant for each model is in \textbf{bold} and the best overall model is in \textcolor{blue}{blue}.}
	\label{tab:Chaotic ODE Datasets Average Results}
\end{table*}

The results discussed in~\Cref{sec:tune_lw} clearly indicate that Crossformer is
not a competitive model. This finding is already acknowledged in the literature: In
most of the recent papers, Crossformer does not belong to the
best-performing baselines~\citep{wang24TM,lin24,liu24,wang24} or is not even considered~\cite{chen23TSMixer}.
Furthermore, our results reproduce the community acknowledged fact that
linear models come close to SOTA models.

In this chapter, we investigate whether these findings are
representative for time-series forecasting or whether this is an artifact of the
considered datasets. For this, we will in this chapter follow the same
experiment setting, but evaluate on the Chaotic-ODE datasets discussed in~\Cref{sec:experimental
setup}. The results can be found in~\Cref{tab:Chaotic ODE Datasets Average
Results}.

The results show a completely different picture with respect to the performance
rankings of the different methods. The most important findings are as follows.

\begin{enumerate}
\item \textbf{Crossformer is the SOTA model on the complex Chaotic-ODE Dataset.}
The default channel-dependent version of Crossformer is the best performing
model on 4/6 datasets and the second best out of the ten models on the remaining 2. It has an average rank of 1.5 which is a
gap of 1.0 to the channel-independent variation and a gap of 1.8 to TimeMixer,
the best model which is not a Crossformer variant. 
\item \textbf{Linear models are not competitive on the Chaotic-ODE Dataset.}
Averaged over all horizons, DLinear is the worst performing model on 5 out of 6
datasets and has an average rank of 9.83. Compared to Crossformer, it has a
performance decrease of 45\% to 118\%, a
median performance decrease of 58.3\% and a mean performance decrease of 74\%.
\end{enumerate}

Summing up, we conclude that the regularly observed competitiveness of linear
models and the disappointing performance of Crossformer may be attributed to the
simplicity of the standard datasets. \textbf{When tested on the complex
Chaotic-ODE dataset, Crossformer is the SOTA forecasting models and the shallow
DLinear model is not proving forecast accuracies comparable to sophisticated
deep learning models. }



\section{Modeling Channel-Dependence is not Important for the Usually Considered Datasets}
\label{sec:cd}
\begin{table}[h]
	\centering
	\begin{tabular}{l|cc|cc}
		\toprule
\multirow{2}{*}{\textbf{Model}} & \multicolumn{2}{c|}{\textbf{Chaotic-ODE-6}} & \multicolumn{2}{c}{\textbf{Standard-7}} \\
		& \textbf{CI} & \textbf{CD} & \textbf{CI} & \textbf{CD} \\
		\midrule
		\textbf{PatchTST} &\textbf{4} & 2  & \textbf{6}  & 1  \\
		\textbf{TSMixer} & 0  & \textbf{6}  & \textbf{7}  & 0  \\
		\textbf{Crossformer} & 0  & \textbf{6}  & \textbf{4}  & 3  \\
		\textbf{TimeMixer}& \textbf{2} &\textbf{4}& \textbf{4}  & 3   \\
		\midrule
		\textbf{Totals} & 6  & \textbf{18}  & \textbf{21}  & 7  \\
		\bottomrule
	\end{tabular}
	\caption{For each model and dataset, we count how often the CI version and how often the CD version performs better.}
	\label{tab:cd_vs_ci}
\end{table}



The question whether channel dependence is useful for time-series forecasting is
widely discussed. It was one of the main findings from \citet{nie23}, that
PatchTST does not profit from channel dependence and works the best when the forecasting to the future for a specific channel is just based on historical data of
this particular
channel. However, TSMixer, TimeMixer and Crossformer are by default channel dependent,
challenging the channel-independence assumption.

In the following, we evaluate whether channel-dependence is indeed needed for
these models and whether this need also depends on the datasets used. For this,
we count both for the standard datasets and the chaotic ODE datasets for each
method that has a channel-dependent and channel-independent variant how often
the channel-dependent and how often the channel-independent variant performs better. The
results can be found in~\Cref{tab:cd_vs_ci}. The main findings are as follows.
\begin{enumerate}
\item \textbf{Modelling channel-dependence is not important for the standard datasets.} For all
methods which have a channel-independent variant, this variant outperforms the
channel-dependent variant, with overall 21 to 7 on the usual dataset. This is
particularly outstanding since TSMixer, Crossformer and TimeMixer are by default
channel-dependent. Our results show, that their ability of mixing
information between channels is NOT the driving factor of their performance and
regularly even increases the error.
\item \textbf{Modelling Channel-Dependence is crucial on the\\ Chaotic-ODE datasets.} Here, for
TSMixer and Crossformer, the performance is better when there is an information
flow between the different channels. This indicates that these models are indeed
able to incorporate channel-dependencies in a reasonable manner. However, this
information is only needed in such more complex forecasting scenarios as given by
the Chaotic-ODE data.
\item \textbf{PatchTST works always the best in its channel independent variant.} The results for PatchTST stand out as PatchTST performs better in its
channel-independent variant in 4
out of 6 datasets of the Chaotic-ODE datasets. This shows, that the findings of
the authors that PatchTST performs best when no information flows across
channels is not an artifact of the usual datasets. This can be explained also by the fact that PatchTST applies both the channel mixing as well as the mixing over patches using one layer, on the contrary all other CD models applies the mixing processes separately. Moreover, as Crossformer in
the channel dependent version outperforms PatchTST, the finding of the
non-relevance of channel-dependency for Chaotic-ODE datasets is limited to
PatchTST. We conclude that for the complex Chaotic-ODE data channel-dependencies
are indeed helpful, that however PatchTST can not incorporate them in a helpful manner. 
\end{enumerate}

\begin{figure*}[!ht]
	\centering
	\includegraphics[width=0.8\textwidth]{./fig/FaCT_architecture.png}
	\caption{\textbf{Comparison of Crossformer model with the proposed FaCT Model Architecture}: The Multivariate input time series sequence is converted into segments and then passed on to the 
		Transformer architecture that utilizes 2-stage attention over both the time dimension and the channel dimension. Each stage compresses the information into multiple resolutions. Unlike Crossformer, 
		that uses an additional decoder for final forecast, FaCT uses linear projection over each resolution to generate the final forecast.}
	\label{fig:fact}
\end{figure*}
\section{From Crossformer to FaCT}
\label{sec:cf25}
As highlighted in the previous sections, channel dependence is innate to time
series forecasting, and by design, a time series forecasting model should be
able to exploit any channel correlations present in the time series datasets.
Our experiments on the Chaotic ODE benchmark clearly show that the default
Crossformer model is the best-performing model when channel correlation is
mathematically modeled within the dataset. The second-best model, TimeMixer, as
well as the currently accepted SOTA methods like PatchTST and TSMixer, are
considerably behind Crossformer in the Chaotic ODE benchmark ranking.
Interestingly, the DLinear model, which is competitive on the standard datasets, struggles
extensively while modeling complex ODE datasets.


We attribute the superiority of the Crossformer 
model to the following reasons.
\begin{itemize}
	\item \textbf{Attention-based Channel Dependence Modeling}: Both Crossformer and iTransformer use attention mechanisms to learn better channel correlation compared to TimeMixer and TSMixer models, which use fully connected layers to model channel correlation. TimeMixer achieves the second-best result on the ODE benchmark datasets, possibly due to the multi-resolution feature maps it utilizes.
	\item \textbf{Multi-Resolution Feature Maps}: Crossformer and TimeMixer are the only models in the list of baselines designed to learn feature maps at multiple resolutions, allowing them to learn aggregated features that improve performance.
	\item \textbf{Patching/Segments}: PatchTST introduced the idea of using time series patches as tokens instead of individual time steps. Segments in Crossformer perform a similar function, enabling Crossformer to achieve strong performance in channel-independent and channel-dependent scenarios, by aggregating information from nearby time steps.
\end{itemize}
To summarize, Crossformer is a robust, well-designed baseline that already incorporates the best features from other SOTA models introduced later. However, the absence of a proper channel-dependent time series forecasting benchmark may have redirected research towards fine-tuning on the standard datasets. Here, we provide a brief overview of the Crossformer architecture, as this is vital for understanding the proposed FaCT model. For an in-depth review, we refer the reader to the original Crossformer paper \cite{zhang23}.

\subsection{High-level Overview of Crossformer}
As shown in ~\Cref{fig:fact}, Crossformer follows an encoder-decoder architecture
similar to the original Transformer \cite{transformer} architecture. The input time series window 
$x \in \mathbb{R}^{C \times L}$ is split into multiple segments each of length $L_{seg}$ such that 
near-by points from the same dimension form a single token for the following attention mechanism. 
The segmented input window is then passed on to the encoder consisting of $N$ many encoder blocks.
Each encoder block consists of \texttt{Cross-Time Stage} and \texttt{Cross-Dimension Stage} attention (figure \ref{fig:enc_block}). Concretely, if $Z \in \mathbb{R}^{K \times C\times d_{model}}$ is the input 
to each stage in the encoder block,
where $K$ is the number of segments, $d_{model}$ is the embedding dimension and $C$ denotes
the number of channels, then, \texttt{Cross-Time Stage} applies Multi-head Self-Attention 
(MSA) to each dimension and across the time segments as,
\begin{equation}
	Z_{:,c} = \texttt{LayerNorm}\big(Z_{:,c} + \texttt{MSA}(Z_{:,c},Z_{:,c},Z_{:,c})\big)
\end{equation}
where $Z_{:,c}$ denotes all time steps from dimension $c$. The output from the \texttt{Cross-Time Stage} 
is embedded using a Feed-Forward layer and passed to the \texttt{Cross-Dimension stage} where the model
learns across the different channels in the input time series. 
\begin{equation}
	Z_{t,:} = \texttt{LayerNorm}\big(Z_{t,:} + \texttt{MSA}(Z_{t,:},Z_{t,:},Z_{t,:})\big)
\end{equation}
where $Z_{:,t}$ denotes all the dimensions with respect to time segment $t$.
Additionally, the Crossformer model utilizes the induced attention \cite{lee2019set} 
as a router mechanism to reduce computational overhead for datasets with a large number of channels.
At the end of each two-stage attention block, time series segments adjacent to each other
are merged to generate multi-resolution feature maps at each encoder block. Figure \ref{fig:enc_block}
represents the components of the two-stage attention block. We use \texttt{CrossformerEncoderLayer} to indicate
all the components of the encoder in the following order: (1) \texttt{Cross-Time Attention} 
(2) \texttt{Routing Mechanism} (3) \texttt{Cross-Dimension Attention} and (4) \texttt{Segment Merging} for 
simplicity.

\begin{figure}[!ht]
	\includegraphics[width=0.25\textwidth]{fig/FaCT_encoder_block.png}
	
	\caption{\textbf{Crossformer/FaCT Encoder Block}: A single decoder layer consists of (1)\textit{Cross-Time Attention}
		that performs attention over the time segments, (2)\textit{Cross-Dimension Attention} that performs 
		attention over the time series channels, (3)\textit{Routing Mechanism} to reduce the Cross-Dimension 
		attention complexity and (4)\textit{Segment Merging} to generate multi-resolution feature maps.}
	\label{fig:enc_block}
\end{figure}

The decoder part of the Crossformer is inspired from U-Net architecture \cite{ronneberger2015u} where
the $n^{\text{th}}$ layer of the decoder extracts information from the $n^{\text{th}}$ layer of the
encoder using the cross-attention mechanism. Linear projection is used in each layer to generate
prediction from each layer and these are summed to make the final forecast.


\subsection{FaCT: A Lightweight Alternative for Crossformer}
\begin{figure}[!ht]
	\includegraphics[width=0.45\textwidth]{fig/CompexityComparison_DoublePendulum_192.png}
	\caption{\textbf{Complexity Comparison of Crossformer with TimeMixer and FaCT model}: Y-axis is the
	total (CPU+GPU) time in milli-seconds (ms) required for a single forward and backward pass and the X-axis denotes the different number of layers of the model. The proposed FaCT reduces run-time by 51.17\% in comparison to Crossformer, is lighter than TimeMixer while providing similar results as the 
	best performing Crossformer.}
	\label{fig:complex_192}
\end{figure}

One clear direction for improving the Crossformer model is addressing its complexity. While Crossformer produces the best results on complex ODE benchmark datasets, its two-stage attention mechanism and encoder-decoder architecture significantly increase the required memory and run-time. Figure \ref{fig:complex_192} compares Crossformer with the second-ranked model, TimeMixer, on the ODE dataset. Crossformer requires double the run-time of TimeMixer, which is itself a heavy model. The authors of the Crossformer paper also identify this as a potential problem and propose the use of a router mechanism and input time series segmentation. However, in our experiments, even with additional optimizations, the model remains the largest and slowest to run among the baselines.

We introduce the Fast Channel-dependent Transformer (FaCT) model, which alleviates this problem by 
proposing an encoder-only architecture inspired by Crossformer. The Crossformer
model was inspired from the original Transformer architecture
proposed in ~\cite{transformer}. Further research on the Transformer architecture led to the development of encoder-only models like BERT~\cite{devlin19}. These models gained popularity due to their reduced complexity 
and computational resource requirements, while still maintaining performance gains. Moreover, recent SOTA 
models in time series forecasting have benefited from switching from an encoder-decoder architecture \cite{informer} to encoder-only models, for example PatchTST \cite{nie23}. 
Considering the success of recent encoder-only models and their reduced complexity, we distill the essence 
of the Crossformer architecture into an encoder-only architecture while retaining all the core components 
that enable the model to perform well on ODE benchmark datasets.



~\Cref{fig:fact} shows the high-level architecture of the FaCT model. The FaCT model retains all the 
core components of the Crossformer architecture, such as multi-resolution feature maps, attention-based 
channel encoding, attention-based time encoding, and the segmentation process introduced in Crossformer. 
Our intuition and experimental results indicate that the Crossformer encoder, coupled with 
multi-resolution linear decoders, encompasses the important components leading to the superior performance 
of the Crossformer model. The learned positional embedding input for the decoder, along with 
cross-attention between the encoder and decoder, provides marginal lifts while increasing 
the model's complexity by almost a factor of two. If $Z \in \mathbb{R}^{K\times C\times d_{model}}$ is the input to each stage in the encoder block after input segmentation, a FaCT encoder layer can be described as,
\begin{align}
	Z_{n} &= \texttt{CrossformerEncoderLayer}(Z_{n-1})\\
	Y_{n} &= \texttt{LinearProjection}(Z_{n})
\end{align}
Here $Z_{n-1}$ denotes the input features to an encoder layer and $Z_{n}$ the output from
the \texttt{CrossformerEncoderLayer}. The learned features $Z_{n}$
continues into the next encoder block to generate $Z_{n+1}$. Additionally, the output
$Z_{n}$ from the $n^{th}$ layer ($n \in \{1, \dots, N\}$) is passed through a \texttt{LinearProjection} layer to condense feature maps from multiple resolutions to a unified resolution $Y_{n}$. The final forecast $Y$ from the 
FaCT architecture is then,
\begin{align}
	\tilde{Y} &= \texttt{Sum}(Y_1, \dots, Y_N)\\
	\hat{Y} &= \texttt{LinearProjection}(\tilde{Y})
\end{align}

\paragraph{\textbf{Results}} As indicated by the results in ~\Cref{tab:FaCT-ODE-Results} and ~\Cref{fig:complex_192}, the 
FaCT model achieves similar performance to the Crossformer model at half the computational cost. In fact, the proposed FaCT model is lighter than the second-ranked TimeMixer model on the ODE datasets. Even with a significant reduction in complexity, FaCT manages to achieve better performance than the TimeMixer model. This is due to the careful distillation of the Crossformer model into an encoder-only model while retaining the core components that allow the model to learn cross-channel dependencies effectively.
 


\begin{table}[h]
	\begin{tabular}{l|c|c|c}
		\toprule
		\textbf{Dataset / Model}         & \textbf{FaCT}                         & \textbf{Crossformer}                  & \textbf{TimeMixer}                    \\
				\midrule 
				Horizon-96 \\
				\midrule
		\textbf{Lorenz}         & {\ul 0.306}                           & {\color[HTML]{0000FF} \textbf{0.266}} & 0.338                                 \\
		\textbf{BlinkingRotlet} & {\ul 0.054}                           & {\color[HTML]{0000FF} \textbf{0.045}} & 0.076                                 \\
		\textbf{CellCycle}      & {\ul 0.045}                           & {\color[HTML]{0000FF} \textbf{0.035}} & 0.071                                 \\
		\textbf{DoublePendulum} & 0.117                                 & {\color[HTML]{0000FF} \textbf{0.083}} & {\ul 0.110}                            \\
		\textbf{Hopfield}       & 0.052                                 & {\ul 0.049}                           & {\color[HTML]{0000FF} \textbf{0.036}} \\
		\textbf{LorenzCoupled}  & {\ul 0.295}                           & {\color[HTML]{0000FF} \textbf{0.276}} & 0.818                                 \\
				\midrule
				Horizon-192 \\
				\midrule
		\textbf{Lorenz}         & {\ul 0.635}                           & {\color[HTML]{0000FF} \textbf{0.631}} & 0.884                                 \\

		\textbf{BlinkingRotlet} & {\ul 0.239}                           & {\color[HTML]{0000FF} \textbf{0.210}} & 0.315                                 \\
		\textbf{CellCycle}      & {\color[HTML]{0000FF} \textbf{0.250}} & {\ul 0.275}                           & 0.370                                  \\
		\textbf{DoublePendulum} & {\color[HTML]{0000FF} \textbf{0.373}} & 0.466                                 & {\ul 0.380}                            \\
		\textbf{Hopfield}       & {\ul 0.125}                           & 0.155                                 & {\color[HTML]{0000FF} \textbf{0.102}} \\
		\textbf{LorenzCoupled}  & {\ul 0.681}   
		                        & {\color[HTML]{0000FF} \textbf{0.635}} & 0.947                                 \\
		                        
		                        \midrule
		                        Horizon-336 \\
		                        \midrule
		                        
		\textbf{Lorenz}         & {\ul 0.799}                           & {\color[HTML]{0000FF} \textbf{0.762}} & 0.895                                 \\
		\textbf{BlinkingRotlet} & {\color[HTML]{0000FF} \textbf{0.439}} & {\ul 0.466}                           & 0.500                                   \\
		\textbf{CellCycle}      & 0.833                                 & {\color[HTML]{0000FF} \textbf{0.556}} & {\ul 0.719}                           \\
		\textbf{DoublePendulum} & {\ul 0.695}                           & 0.712                                 & {\color[HTML]{0000FF} \textbf{0.650}}  \\
		\textbf{Hopfield}       & 0.415                                 & {\ul 0.404}                           & {\color[HTML]{0000FF} \textbf{0.199}} \\
		\textbf{LorenzCoupled}  & 0.836                                 & {\color[HTML]{0000FF} \textbf{0.810}} & 0.984                                 \\
		\midrule
		Horizon-720 \\
		\midrule
		\textbf{Lorenz}         & 0.942                                 & {\color[HTML]{0000FF} \textbf{0.914}} & {\ul 0.929}                           \\
		\textbf{BlinkingRotlet} & {\ul 0.525}                           & {\color[HTML]{0000FF} \textbf{0.524}} & 0.622                                 \\
		\textbf{CellCycle}      & {\ul 0.863}                           & {\color[HTML]{0000FF} \textbf{0.844}} & 0.892                                 \\
		\textbf{DoublePendulum} & {\color[HTML]{0000FF} \textbf{0.893}} & {\ul 0.904}                           & 1.018                                 \\
		\textbf{Hopfield}       & {\ul 0.659}                           & {\color[HTML]{0000FF} \textbf{0.655}} & 0.717                                 \\
		\textbf{LorenzCoupled}  & {\ul 0.946}                           & {\color[HTML]{0000FF} \textbf{0.942}} & 1.003 \\
		\bottomrule                               
	\end{tabular}
	\caption{Comparison of the proposed FaCT against the top 2 performing models on the chaotic ODE Datasets (Crossformer and TimeMixer). The best performing model for each dataset is highlighted in \textcolor{blue}{blue} and the second best performing model is \underline{underlined}.}
	\label{tab:FaCT-ODE-Results}
\end{table}

\section{Recommendations for Time-Series Forecasting}
Based on our findings, we give the following recommendations for proper
evaluations in the domain of time-series forecasting:
\begin{itemize}
\item Do not use the established lookback window of $L=96$, it heavily influence
the performance of established forecasting methods. Treat the lookback window as
a proper hyperparameter to tune instead.
\item Do not rely on the small set of usually considered datasets. Due to their
simplicity, these dataset are biased towards channel-independent architectures
and shallow models which underperform on more complex data, such as the chaotic
ODE benchmark.
\item Consider the Crossformer Model as a strong baseline approach to build on
or to compare against. Even though a lot of papers do not consider it as a SOTA
baseline anymore, our findings indicate that it is the SOTA on the chaotic ODE benchmark.
\item We recommend the use of proposed FaCT model attaining the best trade-off between performance and run time complexity on ODE benchmark. 
\end{itemize}



\bibliographystyle{ACM-Reference-Format}
\bibliography{literature}

\appendix
\section{Description of All Datasets}
\label{sec:dataset-description}

In this section, we would like to show in detail the different datasets used in our experiments. Starting with the standard datasets which were explained a lot in literature, so we will just give a brief description of them. First ETT- datasets which representing indication of long term power deployment which are recorded for 2 different granalurities (15 mins for 'm' and 1 hour for 'h') for 2 different counties (hence the post-fix '1' and '2'). Electricity dataset follows the consumption of electricity over an extended amount of time (3 years) recorded hourly for 321 different households. Traffic dataset is representing the flow of traffic recorded through multiple sensors in an hourly frequency spanning over a period of approximately 2 years. All of this information as well as the train/validation/test split is shown in table \ref{tab:standard-datasets}

\begin{table*}[]
	\begin{tabular}{ccccc}
	    \toprule
		Dataset/Feature               & Channels             & Granularity                   & Train/val/test                & Total Timesteps      \\
		\midrule
		ETTh (1/2)           & 7           & 1 hour                        & 12/4/4 (months)               & 17420                \\
		ETTm (1/2)           & 7                    & 15 mins                       & 12/4/4 (months)               & 69680                \\
		electricity          & 321                  & 1 hour                        & 7:1:2                       & 26304                \\
		traffic              & 862                  & 1 hour                        & 7:1:2                       & 17544                \\
		weather              & 21                   & 10 mins                       & 7:1:2                       & 52696                \\
		\bottomrule

	\end{tabular}
	\caption{Basic statistics about the standard datasets widely used in the time series forecasting literature. This table shows the number of features, frequency of recording the data, train/validation/test split as well as the total timesteps recorded in a given dataset.}
	\label{tab:standard-datasets}
\end{table*}

Second type of datasets used in our experiments is based on the chaotic ODE Benchmark as mentioned in section \ref{sec:experimental setup}. Here, we elaborate more on the general common features of the used ODE datasets and we give further description of the underlying processes for generating them. For the generation process, we use a common protocol for the chosen 6 attractors which is generating 20 points per time unit, splitting the data into 7:1:2 train:validation:test split which is the common practice for the standard datasets as well. Finally, we generate a very long time series 60000 timesteps which is divided into time series forecasting samples though a rolling window (same approach that is adopted on TSF papers for the standard datasets). For reproducibility, we provide the code stating the random seed that should be used to produce the same datasets and subsequently the same results we got. For understanding more the chosen processes as well as the dimensionality of each dataset, please refer to the chaotic ODE Benchmark paper \cite{gilpin21}

\section{Hyperparameter Tuning}
\label{sec:hyperparameter-tuning}
We evaluate various Transformer-based and MLP-based time series forecasting models (e.g., DLinear, TSMixer, PatchTST, Crossformer, and our proposed FaCT) under a unified set of hyperparameter search ranges as shown in Table~\ref{tab:common-hyperparameters}.
\begin{table}[ht]
	\centering
	\begin{tabular}{ll}
		\toprule
		\textbf{Hyperparameter} & \textbf{Search Range} \\ 
		\midrule
		Learning Rate           & $[10^{-7},\,10^{-2}]$ \\ 
		Hidden Dimension ($d\_model$)      & $\{128, 256, 512, 1024\}$ \\
		Feedforward Dimension ($d\_ff$)    & $\{128, 256, 512, 1024\}$ \\
		\#~Encoder/Mixer Layers & $[1,\,10]$ \\
		Dropout                 & $[0,\,0.9]$ \\
		Sequence Length ($seq\_len$)       & $\{96, 192, 336, 512, 720\}$ \\
		\bottomrule
	\end{tabular}
	\caption{Common Hyperparameter Search Ranges with all parameters being integer datatypes except for \textbf{learning rate} and \textbf{dropout} which span the whole range of floats on the respective range of values}
	\label{tab:common-hyperparameters}
\end{table}

For specific architectures, additional parameters that are model specific were tuned on the same range of parameters specified on the respective papers. For all the range $[]$ or set of values $\{\}$, refer to table \ref{tab:model-specific-hyperparameters}.

\begin{table}[ht]
	\centering
	\begin{tabular}{lll}
		\toprule
		\textbf{Model}                & \textbf{Hyperparameter}  & \textbf{Range}                   \\
		\midrule
		PatchTST             & Patch Size      & $\{8, 16\}$             \\
		\multicolumn{1}{l}{} & Stride          & $\{4, 8\}$              \\
		TSMixer              & Hidden Size     & $\{32, 64, 256, 1024\}$ \\
		Crossformer/FaCT     & Segement Length & $[3,12]$                   \\
		\multicolumn{1}{l}{} & Baseline        & $\{0,1\}$               \\
		\multicolumn{1}{l}{} & Cross Factor    & $[3,20]$ \\     
		\bottomrule       
	\end{tabular}
	\caption{Model Specific Hyperparameter Search Ranges/set of possible values with all of them having a datatype of integer in this case.}
	\label{tab:model-specific-hyperparameters}
\end{table}

\section{Implementation Details}
\label{sec:implementation}

\subsection{Libraries and Hardware}
All models were implemented using the PyTorch library (version \texttt{2.4}) in Python (version \texttt{3.12.1}). For hyperparameter optimization, we employed Optuna (version \texttt{3.6.1}). 
Experiments were conducted on machines equipped with NVIDIA RTX\,4090 and RTX\,3090 GPUs.

\subsection{Training Procedure}
All models are trained using the Adam optimizer.
We use MSE as the default loss function, and each epoch iterates over mini-batches of size 32 by default. Training proceeds for a maximum of 100 epochs, or until early stopping is triggered if the validation loss fails to improve for 10 consecutive epochs. We use Optuna to conduct 20 trials per model, selecting configurations from the defined set of hyperparameters \ref{sec:hyperparameter-tuning} that yield the best validation performance.

\subsection{Efficiency Analysis}
To compare computational performance, we record:
\begin{itemize}
    \item \textbf{GPU Memory Usage (GB)}
    \item \textbf{Number of Parameters}
    \item \textbf{Runtime per Training Iteration (s)}
\end{itemize}
across Crossformer~\cite{zhang23} and our proposed FaCT, demonstrating FaCT's efficiency in both memory consumption and training speed while retaining competitive predictive performance.

\section{Derivation of CI/CD version of Models}
\label{sec:CI-CD-Derivation}

In our paper, 6 strong recent baselines are used which as mentioned in section \ref{sec:experimental setup}, they vary in complexity and structure. The aim of this appendix section is to ease the understanding of making CI and CD versions of the different baselines.


\paragraph{\textbf{Simpler Linear/MLP-based Models}}
	We start with the simpler models used in our experiments which are DLinear and TSMixer. DLinear as mentioned earlier is based on being the simplest model that applies a trend seasonality deceomposition followed by simpler linear layers applied on both the trend and the seasonal components \cite{zeng23}. For \textbf{TSMixer}, the authors had implemented a CD version which is the original version of the model and removed the channel mixing component which is called in their paper \textbf{TMix-Only}. We reimplemnted the model using pytorch and made sure of reproducing the paper results before using both versions in our experiments. Throughout our paper, we call both versions as TSMixer (CD) and TSMixer (CI) for the CD and CI versions respectively.


\paragraph{\textbf{PatchTST}}
	Now we move into transformer-based models, starting with PatchTST as one of the first transformer models to re-establish a boost of performance over the DLinear model. In their paper, the original version of the model is CI where the transformer encoder backbone is applied independently on different channels before the application of a linear projection layer. For the CD version, they briefly discuss it in the appendix of applying the same backbone but on a flattened dimension of both number of patches and channels which means the attention is now applied jointly over patches and channels. We use the original implementation of the paper but we had to add the part related to CD implementation ourselves as it was not readily available on the paper at the time of writing our paper.

\paragraph{\textbf{iTransformer/Crossformer}}
Next, transformer model that proved to be a strong baseline is Crossformer which applies a Depth-Segment-Wise embedding before application of a Two Stage Attention (TSA). Finally a decoder layer is applied through cross attention between the positional embedding of output time info and encoder output. The TSA is applied on the segments dimension (temporal) as well as followed by the channel dimension which constitutes the original CD version of the model \cite{zhang23}. For a CI version, we just removed the second stage of the TSA to make the attention only applied on the segments dimension. We used authors implementation of the CD version and made the mentioned edits on the implementation to produce the CI version used in our experiments. For iTransformer \cite{liu24} as mentioned in section \ref{sec:experimental setup}, we don't introduce additional CI version to the existing CD version as otherwise the model will be simplified to a linear model which is already covered in this paper.

\paragraph{\textbf{TimeMixer}}
One more prominent model proposed recently which proves be competitive on the standard datasets is TimeMixer \cite{wang24TM}. In this model, the authors provide an MLP-based approach which is applied over multiple resolutions of the time series. This model original setting is CD where the MLP-mixing is done over both temporal and channel dimensions. For a CI version, the channel mixing component can be removed yielding a  temporal mixing based model. We use the authors implementation for both the CI and CD versions of the model.

\section{Detailed Results}
\label{sec:detailed-results}

In this appendix, we add the full results over all forecasting horizons for both types of introduced datasets. In table ~\Cref{tab:Full-results-ODE-datasets}, we can see in detail the results for the chaotic ODE datasets, confirming the results from table ~\Cref{tab:Chaotic ODE Datasets Average Results} that Crossformer is clearly the SoTA on this benchmark with it being the best model in 15 out of possible 24 settings(for the CD version). For the standard datasets, the results are detailed in table ~\Cref{tab:Full-results-standard-datasets} which also confirms the state of the current datasets where no model is clearly the best even emphasized with DLinear being the best model on \textbf{5 occurrences}. This also fits the picture that was formulated on the main table of the paper ~\Cref{tab:Standard Datasets Average Results} that when propoer tuning is carried out for lookback window as well as all related hyperparameters, PatchTST remains competitive being the best overall \textbf{6 times}. To conclude how comprehensive and reproducible our experiments are, these results represents the mean of 5 random seeds \{3001, 3002, 3003, 3004, 3005\} MSE error on the test split of each dataset.


\begin{table*}[ht]
	\begin{tabular}{lr|c|c|c|c|c|c|c|c|c|c}
		\toprule
		\textbf{Dataset / Model} & \textbf{Horizon} & \multicolumn{2}{c}{\textbf{PatchTST}}                             & \multicolumn{2}{c}{\textbf{TSMixer}}          & \multicolumn{2}{c}{\textbf{Crossformer}}                          & \multicolumn{1}{c}{\textbf{DLinear}}                & \multicolumn{1}{c}{\textbf{iTransformer}} & \multicolumn{2}{c}{\textbf{TimeMixer}}                            \\
		&         & \multicolumn{1}{c}{\textbf{CI}} & \multicolumn{1}{l}{\textbf{CD}} & \multicolumn{1}{c}{\textbf{CI}} & \multicolumn{1}{c}{\textbf{CD}} & \multicolumn{1}{c}{\textbf{CI}} & \multicolumn{1}{c}{\textbf{CD}} & \multicolumn{1}{c}{\textbf{CI}} & \multicolumn{1}{c}{\textbf{CD}}            & \multicolumn{1}{c}{\textbf{CI}} & \multicolumn{1}{c}{\textbf{CD}} \\
		\midrule
		ETTh1                    & 96                          & \textbf{0.375}                 & 0.381                           & \textbf{0.374}                  & 0.404                           & 0.396                           & \textbf{0.400}                  & \textcolor{blue}{\textbf{0.372}}                  & 0.413                                      & \textbf{0.391}                  & 0.426                           \\
		& 192                         & 0.419                           & \textbf{0.407}                  & \textbf{0.432}                  & 0.438                           & \textbf{0.452}                  & 0.446                           & \textcolor{blue}{\textbf{0.406}}                 & 0.457                                      & \textbf{0.434}                  & 0.580                           \\
		& 336                         & \textbf{0.459}                  & 0.460                           & \textbf{0.447}                  & 0.471                           & \textbf{0.459}                  & 0.480                           & \textcolor{blue}{\textbf{0.435}}                  & 0.500                                      & \textbf{0.444}                  & 0.500                           \\
		& 720                         & \textcolor{blue}{\textbf{0.437}}                  & 0.499                           & 0.500                           & \textbf{0.499}                  & \textbf{0.601}                  & 0.497                           & 0.481                           & 0.541                                      & \textbf{0.498}                  & 0.473                           \\
		\midrule
		Weather                  & 96                          & 0.151                           & \textcolor{blue}{\textbf{0.150}}                  & \textbf{0.152}                  & 0.155                           & \textcolor{blue}{\textbf{0.150}}                  & 0.153                           & 0.374                           & 0.156                                      & \textbf{0.158}                  & 0.199                           \\
		& 192                         & \textcolor{blue}{\textbf{0.193}}                  & 0.197                           & \textbf{0.196}                  & 0.202                           & 0.199                           & \textcolor{blue}{\textbf{0.193}}                  & 0.210                           & 0.201                                      & \textbf{0.198}                  & 0.289                           \\
		& 336                         & 0.278                           & \textcolor{blue}{\textbf{0.247}}                  & \textcolor{blue}{\textbf{0.247}}                  & 0.255                           & 0.261                           & 0.495*                          & 0.255                           & 0.263                                      & \textbf{0.266}                  & 0.343                           \\
		& 720                         & 0.359                           & \textbf{0.336}                  & \textbf{0.330}                  & 0.354                           & 0.335                           & 0.342                           & \textcolor{blue}{\textbf{0.316}}                  & 0.319                                      & \textbf{0.342}                  & 0.442                           \\
		\midrule
		Electricity              & 96                          & \textcolor{blue}{\textbf{0.129*}}                 & 0.141                           & \textbf{0.131}                  & 0.137                           & 0.139                           & 0.150                           & 0.135                           & 0.135                                      & \textbf{0.130}                             & 0.143                           \\
		& 192                         & \textcolor{blue}{\textbf{0.147*}}                 & 0.156                           & \textbf{0.149}                  & 0.156                           & 0.177                           & 0.168                           & 0.149                           & 0.151                                      & \textbf{0.149}                             & 0.191                           \\
		& 336                         & \textcolor{blue}{\textbf{0.163*}}                 & 0.173                           & \textbf{0.165}                  & 0.176                           & 0.194                           & 0.182*                          & \textbf{0.164}                  & 0.175                                      & \textbf{0.171}                             & 0.174                  \\
		& 720                         & \textbf{0.197*}                 & 0.210                           & \textbf{0.203}                  & 0.210                           & 0.261                           & 0.251*                          & 0.199                           & \textcolor{blue}{\textbf{0.196}}                             & 0.212                             & \textbf{0.197}                           \\
		\midrule
		ETTh2                    & 96                          & 0.286                           & \textcolor{blue}{\textbf{0.285}}                  & \textbf{0.291}                  & 0.304                           & 0.397                           & 0.537                           & 0.303                           & 0.324                                      & \textcolor{blue}{\textbf{0.285}}                  & 0.377                           \\
		& 192                         & \textcolor{blue}{\textbf{0.352}}                  & 0.381                           & \textbf{0.376}                  & 0.392                           & \textbf{0.713}                  & 0.794                           & 0.397                           & 0.396                                      & \textbf{0.360}                  & 0.459                           \\
		& 336                         & \textcolor{blue}{\textbf{0.392}}                  & 0.422                           & \textbf{0.402}                  & 0.421                           & 0.727                           & 0.553                           & 0.518                           & 0.447                                      & \textbf{0.410}                  & 0.476                           \\
		& 720                         & \textcolor{blue}{\textbf{0.431}}                  & 0.438                           & 0.444                           & \textbf{0.441}                  & 1.126                           & 0.880                           & 0.811                           & 0.441                                      & \textcolor{blue}{\textbf{0.431}}                  & 0.603                           \\
		\midrule
		ETTm1                    & 96                          & \textbf{0.293}                  & 0.306                           & \textcolor{blue}{\textbf{0.292}}                  & 0.294                           & 0.309                           & 0.364                           & 0.299                           & 0.314                                      & \textbf{0.299}                  & 0.366                           \\
		& 192                         & \textbf{0.334}                  & 0.339                           & \textbf{0.333}                  & 0.344                           & \textbf{0.398}                  & 0.411                           & 0.334                           & 0.359                                      & \textcolor{blue}{\textbf{0.330}}                  & 0.340                           \\
		& 336                         & \textbf{0.373}                  & 0.400                           & \textbf{0.374}                  & 0.389                           & 0.399                           & 0.463                           & 0.368                           & 0.405                                      & \textcolor{blue}{\textbf{0.363}}                  & 0.468                           \\
		& 720                         & \textbf{0.425}                  & 0.441                           & \textbf{0.426}                  & 0.452                           & 0.466                           & 0.465                           & 0.434                           & 0.437                                      & \textcolor{blue}{\textbf{0.418}}                  & 0.607                           \\
		\midrule
		ETTm2                    & 96                          & \textcolor{blue}{\textbf{0.161}}                  & 0.166                           & \textbf{0.163}                  & 0.176                           & 0.199                           & 0.188                           & 0.166                           & 0.180                                      & \textbf{0.166}                  & 0.167                           \\
		& 192                         & 0.221                           & \textcolor{blue}{\textbf{0.220}}                  & \textbf{0.234}                  & 0.235                           & \textbf{0.270}                  & 0.305                           & 0.236                           & 0.230                                      & \textcolor{blue}{\textbf{0.220}}                  & 0.242                           \\
		& 336                         & 0.287                           & \textbf{0.273}                  & \textcolor{blue}{\textbf{0.271}}                  & 0.275                           & 0.820                           & 0.660                           & 0.296                           & 0.287                                      & \textbf{0.272}                  & 0.292                           \\
		& 720                         & \textbf{0.363}                  & 0.375                           & \textcolor{blue}{\textbf{0.360}}                  & 0.414                           & 0.442                           & 0.787                           & 0.458                           & 0.369                                      & \textbf{0.361}                  & 0.384                           \\
		\midrule
		Traffic                  & 96                          & 0.360*                          & OOM                             & 0.386                           & \textcolor{blue}{\textbf{0.384}}                  & OOM                             & 0.514*                          & 0.395                           & OOM                                        & OOM                             & 0.360*                          \\
		& 192                         & 0.375*                          & OOM                             & \textcolor{blue}{\textbf{0.392}}                  & 0.405                           & OOM                             & 0.549*                          & 0.406                           & OOM                                        & OOM                             & 0.375*                          \\
		& 336                         & 0.385*                          & OOM                             & \textcolor{blue}{\textbf{0.407}}                  & 0.423                           & OOM                             & 0.530*                          & 0.436                           & OOM                                        & OOM                             & 0.385*                          \\
		& 720                         & 0.43*                           & OOM                             & \textcolor{blue}{\textbf{0.443}}                  & 0.457                           & OOM                             & 0.573*                          & 0.466                           & OOM                                        & OOM                             & 0.43* \\                         
		\bottomrule
	\end{tabular}
	\caption{In this table, the full results over different horizons are shown over all the 7 standard datasets. These results were average of 5 different random seeds \{3001,3002,3003,3004,3005\}. The best result for each variant per model is in \textbf{bold}, while the best results overall for each horizon per dataset is highlighted in \textcolor{blue}{blue}. we reported the results with "*" from TimeMixer paper from the experiment where they tune the lookback window as well as the hyperparameters (please refer to appendix E in \cite{wang24TM}).}
	\label{tab:Full-results-standard-datasets}
\end{table*}


\begin{table*}[ht]
	\begin{tabular}{lr|c|c|c|c|c|c|c|c|c|c}
		\toprule
		\textbf{Dataset / Model} & \textbf{Horizon} & \multicolumn{2}{c}{\textbf{PatchTST}}                             & \multicolumn{2}{c}{\textbf{TSMixer}}          & \multicolumn{2}{c}{\textbf{Crossformer}}                          & \multicolumn{1}{c}{\textbf{DLinear}}                & \multicolumn{1}{c}{\textbf{iTransformer}} & \multicolumn{2}{c}{\textbf{TimeMixer}}                            \\
		&         & \multicolumn{1}{c}{\textbf{CI}} & \multicolumn{1}{l}{\textbf{CD}} & \multicolumn{1}{c}{\textbf{CI}} & \multicolumn{1}{c}{\textbf{CD}} & \multicolumn{1}{c}{\textbf{CI}} & \multicolumn{1}{c}{\textbf{CD}} & \multicolumn{1}{c}{\textbf{CI}} & \multicolumn{1}{c}{\textbf{CD}}            & \multicolumn{1}{c}{\textbf{CI}} & \multicolumn{1}{c}{\textbf{CD}} \\
		\midrule
		Lorenz                   & 96                          & 0.658                           & \textbf{0.658}                  & 0.747                           & \textbf{0.729}                  & 0.331                           & \textcolor{blue}{\textbf{0.266}}                  & 0.884                           & 0.433                                      & 0.398                           & \textbf{0.338}                  \\
		& 192                         & \textbf{0.825}                  & 0.832                           & 0.862                           & \textbf{0.847}                  & \textcolor{blue}{\textbf{0.623}}                  & 0.631                           & 0.922                           & 0.712                                      & \textbf{0.662}                  & 0.884                           \\
		& 336                         & \textbf{0.906}                  & \textbf{0.906}                  & 0.927                           & \textbf{0.926}                  & 0.792                           & \textcolor{blue}{\textbf{0.762}}                  & 0.950                           & 0.852                                      & \textbf{0.878}                  & 0.895                           \\
		& 720                         & \textbf{0.965}                  & 0.970                           & 0.983                           & \textbf{0.971}                  & 0.920                           & \textcolor{blue}{\textbf{0.914}}                  & 0.978                           & 0.954                                      & 0.962                           & \textbf{0.929}                  \\
		\midrule
		BlinkingRotlet           & 96                          & 0.162                           & \textbf{0.156}                  & 0.322                           & \textbf{0.228}                  & 0.064                           & \textcolor{blue}{\textbf{0.045}}                  & 0.374                           & 0.112                                      & 0.116                           & \textbf{0.076}                  \\
		& 192                         & 0.322                           & \textbf{0.321}                  & 0.510                           & \textbf{0.429}                  & 0.230                           & \textcolor{blue}{\textbf{0.210}}                  & 0.504                           & 0.299                                      & \textbf{0.272}                  & 0.315                           \\
		& 336                         & \textbf{0.511}                  & 0.540                           & 0.727                           & \textbf{0.587}                  & 0.491                           & \textcolor{blue}{\textbf{0.466}}                  & 0.576                           & 0.481                                      & 0.599                           & \textbf{0.500}                  \\
		& 720                         & 0.703                           & \textbf{0.688}                  & 0.759                           & \textbf{0.703}                  & 0.576                           & \textcolor{blue}{\textbf{0.524}}                  & 0.635                           & 0.623                                      & 0.710                           & \textbf{0.622}                  \\
		\midrule
		CellCycle                & 96                          & \textbf{0.263}                  & 0.311                           & 0.513                           & \textbf{0.505}                  & 0.036                           & \textcolor{blue}{\textbf{0.035}}                  & 0.866                           & 0.227                                      & 0.110                           & \textbf{0.071}                  \\
		& 192                         & \textbf{0.580}                  & 0.624                           & 0.791                           & \textbf{0.740}                  & \textcolor{blue}{\textbf{0.244}}                  & 0.275                           & 0.932                           & 0.515                                      & 0.475                           & \textbf{0.370}                  \\
		& 336                         & \textbf{0.768}                  & 0.795                           & 0.894                           & \textbf{0.876}                  & 0.612                           & \textcolor{blue}{\textbf{0.556}}                  & 0.957                           & 0.688                                      & 0.742                           & \textbf{0.719}                  \\
		& 720                         & \textbf{0.931}                  & 0.939                           & 0.970                           & \textbf{0.963}                  & \textcolor{blue}{\textbf{0.825}}                  & 0.844                           & 0.984                           & 0.894                                      & \textbf{0.867}                  & 0.892                           \\
		\midrule
		DoublePendulum           & 96                          & 0.322                           & \textbf{0.278}                  & 0.541                           & \textbf{0.461}                  & 0.090                           & \textcolor{blue}{\textbf{0.083}}                  & 0.667                           & 0.314                                      & 0.250                           & \textbf{0.110}                  \\
		& 192                         & \textbf{0.551}                  & 0.594                           & \textbf{0.713}                  & 0.753                           & \textbf{0.418}                  & 0.466                           & 0.762                           & 0.534                                      & 0.440                           & \textcolor{blue}{\textbf{0.380}}                  \\
		& 336                         & \textbf{0.806}                  & 0.825                           & 0.847                           & \textbf{0.808}                  & 0.802                           & \textbf{0.712}                  & 0.856                           & 0.807                                      & 0.702                           & \textcolor{blue}{\textbf{0.650}}                  \\
		& 720                         & \textbf{0.933}                  & 0.975                           & 0.973                           & \textbf{0.926}                  & 0.902                           & \textbf{0.904}                  & 0.933                           & 0.952                                      & \textcolor{blue}{\textbf{0.901}}                  & 1.018                           \\
		\midrule
		Hopfield                 & 96                          & 0.156                           & \textbf{0.073}                  & 0.268                           & \textbf{0.185}                  & 0.059                           & \textbf{0.049}                  & 0.472                           & 0.046                                      & 0.054                           & \textcolor{blue}{\textbf{0.036}}                  \\
		& 192                         & 0.311                           & \textbf{0.216}                  & 0.410                           & \textbf{0.321}                  & 0.162                           & \textbf{0.155}                  & 0.641                           & 0.128                                      & 0.118                           & \textcolor{blue}{\textbf{0.102}}                  \\
		& 336                         & 0.486                           & \textbf{0.439}                  & 0.571                           & \textbf{0.494}                  & \textbf{0.399}                  & 0.404                           & 0.759                           & 0.280                                      & 0.567                           & \textcolor{blue}{\textbf{0.199}}                  \\
		& 720                         & 0.727                           & \textcolor{blue}{\textbf{0.654}}                  & 0.778                           & \textbf{0.742}                  & 0.721                           & \textbf{0.655}                  & 0.886                           & 0.663                                      & \textbf{0.699}                  & 0.717                           \\
		\midrule
		LorenzCoupled            & 96                          & 0.696                           & \textbf{0.587}                  & 0.840                           & \textbf{0.745}                  & 0.372                           & \textcolor{blue}{\textbf{0.276}}                  & 0.919                           & 0.610                                      & \textbf{0.458}                  & 0.818                           \\
		& 192                         & \textbf{0.883}                  & 0.901                           & 0.949                           & \textbf{0.895}                  & 0.687                           & \textcolor{blue}{\textbf{0.635}}                  & 0.959                           & 0.840                                      & \textbf{0.795}                  & 0.947                           \\
		& 336                         & \textbf{0.957}                  & 0.971                           & 0.997                           & \textbf{0.966}                  & 0.813                           & \textcolor{blue}{\textbf{0.810}}                           & 0.978                           & 0.924                                      & \textbf{0.893}                  & 0.984                           \\
		& 720                         & \textbf{0.990}                  & 1.007                           & 1.013                           & \textbf{0.994}                  & \textcolor{blue}{\textbf{0.926}}                  & 0.942                           & 0.996                           & 0.984                                      & \textbf{0.969}                  & 1.003  
		\\                         
		\bottomrule                        
	\end{tabular}
	\caption{In this table, the full results over different horizons are shown over all the 6 chaotic ODE datasets. These results were average of 5 different random seeds \{3001,3002,3003,3004,3005\}. The best result for each variant per model is in \textbf{bold}, while the best results overall for each horizon per dataset is highlighted in \textcolor{blue}{blue}. we reported the results with "*" from TimeMixer paper from the experiment where they tune the lookback window as well as the hyperparameters (please refer to appendix E in \cite{wang24TM}).}
	\label{tab:Full-results-ODE-datasets}
\end{table*}



\begin{table*}[ht]
	\begin{tabular}{l|c|c|c|c|c|c|c|c|c|c}
		\toprule
		\textbf{Dataset / Model} & \multicolumn{2}{c}{\textbf{PatchTST}}                             & \multicolumn{2}{c}{\textbf{TSMixer}}                              & \multicolumn{2}{c}{\textbf{Crossformer}}                          & \multicolumn{1}{l}{\textbf{DLinear}}                & \multicolumn{1}{l}{\textbf{iTransformer}} & \multicolumn{2}{c}{\textbf{TimeMixer}}                            \\
		\midrule
		& \multicolumn{1}{c}{\textbf{CI}} & \multicolumn{1}{c}{\textbf{CD}} & \multicolumn{1}{c}{\textbf{CI}} & \multicolumn{1}{c}{\textbf{CD}} & \multicolumn{1}{c}{\textbf{CI}} & \multicolumn{1}{c}{\textbf{CD}} & \multicolumn{1}{c}{\textbf{CI}} & \multicolumn{1}{c}{\textbf{CD}} & \multicolumn{1}{c}{\textbf{CI}} & \multicolumn{1}{c}{\textbf{CD}} \\
		\midrule
		Lorenz                   & 0.0033                          & 0.0025                          & 0.0020                          & 0.0115                          & 0.0002                          & 0.0095                          & 0.0065                          & 0.0303                                     & 0.0267                          & 0.0066                          \\
		BlinkingRotlet           & 0.0063                          & 0.0072                          & 0.0063                          & 0.0083                          & 0.0023                          & 0.0171                          & 0.0085                          & 0.0580                                     & 0.0146                          & 0.0294                          \\
		CellCycle                & 0.0030                          & 0.0040                          & 0.0030                          & 0.0047                          & 0.0000                          & 0.0093                          & 0.0163                          & 0.1127                                     & 0.0126                          & 0.0818                          \\
		DoublePendulum           & 0.0070                          & 0.0067                          & 0.0070                          & 0.0305                          & 0.0005                          & 0.0110                          & 0.0088                          & 0.0136                                     & 0.0026                          & 0.0052                          \\
		Hopfield                 & 0.0057                          & 0.0070                          & 0.0057                          & 0.0075                          & 0.0007                          & 0.0049                          & 0.0129                          & 0.0262                                     & 0.3732                          & 0.0076                          \\
		LorenzCoupled            & 0.0030                          & 0.0045                          & 0.0030                          & 0.0075                          & 0.0000                          & 0.0127                          & 0.0056                          & 0.0565                                     & 0.0088                          & 0.0088                          \\
		ETTh1                    & 0.0030                          & 0.0092                          & 0.0030                          & 0.0015                          & 0.0002                          & 0.0425                          & 0.0222                          & 0.0156                                     & 0.0012                          & 0.0175                          \\
		Weather                  & 0.0058                          & 0.0010                          & 0.0033                          & 0.0053                          & 0.0004                          & 0.0061                          & 0.0049                          & 0.0172                                     & 0.0037                          & 0.0039                          \\
		Electricity              & OOM                             & OOM                             & 0.0003                          & 0.0020                          & 0.0000                          & 0.0041                          & 0.0124                          & 0.0053                                     & 0.0017                             & 0.0037                          \\
		ETTh2                    & 0.0040                          & 0.0047                          & 0.0040                          & 0.0088                          & 0.0011                          & 0.1265                          & 0.1307                          & 0.0153                                     & 0.0036                          & 0.0389                          \\
		ETTm1                    & 0.0023                          & 0.0047                          & 0.0023                          & 0.0033                          & 0.0000                          & 0.0131                          & 0.0367                          & 0.0059                                     & 0.0023                          & 0.0161                          \\
		ETTm2                    & 0.0010                          & 0.0020                          & 0.0010                          & 0.0040                          & 0.0004                          & 0.0928                          & 0.0364                          & 0.0007                                     & 0.0022                          & 0.1017                          \\
		Traffic                  & OOM                             & OOM                             & 0.0007                          & 0.0025                          & 0.0000                          & OOM                             & OOM                             & OOM                                        & OOM                             & OOM \\
		\bottomrule                           
	\end{tabular}
	\caption{In this table, all standard deviation values are averaged over the 4 used horizons for all datasets. For each horizon, the standard deviation results were acquired by running the model for 5 different seeds with the following values \{3001,3002,3003,3004,3005\}}. Note for some heavier models and datasets, we got Out of Memory error, specifically speaking some of the runs for electricity and traffic datasets.
    \label{tab:std-values}
\end{table*}



\section{Ablation Study on RevIN}
\label{sec:revin-ablation}

In this section, we include an important ablation study where we test the importance of using Reversible Instance Normalization (RevIN) ~\cite{kim21} on 2 standard datasets and 2 datasets from the chaotic benchmark. Crossformer was originally proposed without RevIN, so we added the RevIN component to both the CI and CD versions to measure how much of an effect this can have on different types of datasets. Moreover we included one more strong baseline in PatchTST in the study measuring the effect of RevIN on its main CI version.

We got 2 interesting patterns that can be seen also from table ~\Cref{tab:revin-ablation} which are the following:
\begin{itemize}
	\item Introducing revin helps to improve the performance on the both variants of Crossformer on the standard datasets.
	\item On the contrary on the chaotic ODEs the model without revin is performing better than its counterpart with revin.
\end{itemize}

These findings shows that in general as confirmed in the literature RevIN can help in the performance of different model on standard datasets. While this being not totally true for PatchTST, it has been true for most models in the literature ~\cite{chen23}. Important as emphasized throughout this paper, that is not easy task to generalize to different types of datasets, and that is no different for RevIN as it deteriorates performance if introduced on Crossformer on the chaotic ODE datasets. This shows that the different nature of Chaotic ODEs with the complex patterns can not benefit from the normalization+denormalization technique introduced in RevIN. 


\begin{table*}[ht]
	\begin{tabular}{l|c|c|c|c|c|c}
		\toprule
		\textbf{Dataset / Model} & \multicolumn{2}{c}{\textbf{PatchTST\_CI}}    & \multicolumn{2}{c}{\textbf{Crossformer\_CD}}                & \multicolumn{2}{c}{\textbf{Crossformer\_CI}} \\
		\midrule
		& \multicolumn{1}{c}{\textbf{with RevIN}} & \multicolumn{1}{c}{\textbf{w/o RevIN}} & \multicolumn{1}{c}{\textbf{with RevIN}} & \multicolumn{1}{c}{\textbf{w/o RevIN}}                    & \multicolumn{1}{c}{\textbf{with RevIN}}   & \multicolumn{1}{c}{\textbf{w/o RevIN}}   \\
		\midrule
		\textbf{Hopfield}        & \textbf{0.151}      & 0.156              & 0.058               & {\color[HTML]{0000FF} \textbf{0.049}} & 0.073                 & \textbf{0.059}       \\
		\textbf{LorenzCoupled}   & \textbf{0.689}      & 0.696              & 0.453               & {\color[HTML]{0000FF} \textbf{0.276}} & 0.515                 & \textbf{0.372}       \\
		\textbf{ETTh2}           & 0.298               & \textbf{0.287}     & \textbf{0.322}      & 0.537                                 & \textbf{0.318}        & 0.397                \\
		\textbf{ETTm1}           & 0.314               & \textbf{0.313}     & \textbf{0.339}      & 0.364                                 & \textbf{0.297}        & 0.309 \\
		\bottomrule               
	\end{tabular}
	\caption{This table shows an ablation study on the reversible instance normalization technique ~\cite{kim21} which showed to improve performance for most model on the standard datasets. The best variant of model is in \textbf{bold} and best overall for each dataset is highlighted in \textcolor{blue}{blue}. These results are based on the forecasting horizon 96.}
	\label{tab:revin-ablation}
\end{table*}

\section{Overview of the Crossformer Model}
\label{sec:Crossformer}

In this section, we would like to shed light into some of the important components of the crossformer model which we believe help it to achieve such good forecasting performance on complex datasets. The crossformer is based on a Segmentation module called Depth-Segment-Wise (DSW) embedding followed by a Two Stage Attention (TSA) encoder, finally a decoder block is used to process the layer by layer encoding from the encoder block.

\paragraph{DSW} which we also use in our proposed FaCT adaptation of Crossformer is a segmentation (on other words patching) technique that works on splitting the time series over the temporal dimension into equal-size non overlapping segments. More importantly though is to focus how every segment is formulated as in this case \textbf{each time series segment} from\textbf{ each seperate channel} represents a token that is embedded through a linear layer with the dimensionality $\mathbb{R}^{L_{seg} \times d\_model}$  to embed segments with length $L_{seg}$ into the $d\_model$ dimension.

\paragraph{TSA Encoder} is a fundamental component of the crossformer as it processes the embedded token capturing relations between tokens across segments on the same channel as well as between different channels. First stage is processing \textbf{across-segments} through a Multi-head Self Attention blocks, this can be seen more clearly on equation ~\Cref{eq:cross-segment-attention} where the transformer encoder block is applied on the first dimension (the number of segments dimension) on each channel $c$ separately. Note always for this section $transformer/_encoder$ refers to the original transformer architecture proposed in ~\cite{transformer} which is a MSA layer followed by a layer normalization and finally a Feed-forward layer is applied. $Z^{segments}$ represents the output of the cross-segment mixing process which happens through 1st of the two stages of the encoding phase.

\begin{equation}
	Z^{segments} = transformer\_encoder_{1}\left(Z_{:,c}, Z_{:,c}, Z_{:,c}\right)
	\label{eq:cross-segment-attention}
\end{equation}

Second stage is the cross-channel attention which focuses on capturing interactions between different channels. This is done with the help of a routing mechanism to help make the model more efficient. To explain, we go quickly through what a regular cross-channel attention would like then explain how the routing mechanism work. For a regular MSA block across channel the attention block would need to attend between each two channels which means quadritically scaling with the number of channel $\mathcal{O}(C^{2})$ where $C$ here is the number of channels represented in the dataset. This is why in crossformer's second stage of TSA, a routing mechanism where intermediate smaller attention block is introduced to lower the number of dimensions here to scale with $2rC$ where $r$ here is the number of router that should be way smaller than the number of channels which would make the complexity decrease to $\mathcal{O}(C)$ instead. This can be seen in more detail in equation ~\Cref{eq:attention-with-routing}. Here $MSA_{R}$ represented initial attention block between the routers as the query and the output from previous stage as the key and value. This is followed by the second transformer encoder block which takes as an input the output of 1st transformer encoder block (as query) and the output of $MSA_{R}$ as the key and value. Then the $Z^{channels}$ represents the final output of the encoder layer.

\begin{equation}
	\begin{split}
		Z^{router}_{i,:} &= MSA_{R} \left( R_{i,:}, Z^{segments}_{i,:}, Z^{segments}_{i,:} \right), \\
		Z^{channels} &= transformer\_encoder_{2} \bigl( Z^{segments}_{i,:}, Z^{router}_{i,:}, \\
		&\quad Z^{router}_{i,:} \bigr)
	\end{split}
	\label{eq:attention-with-routing}
\end{equation}




\paragraph{Multiresolution} is important aspect where different encoder layers are applied on different resolution (sampling rates) of the time series to capture both global and local temporal patterns. To wrap up the crossformer model, we present briefly the decoder block where it has a cross attention based blocks that uses the output from the previous decoder layer as the query and the output from the corresponding encoder layer as the both the key and the value (which means number of encoder blocks is always equal to the number of decoder blocks). This can be seen in more detail in equation \Cref{eq:decoder-cross-attention}. Here $E(^{dec})$ represents a learnable positional embedding as initial input to the decoder.

\begin{equation}
	\begin{split}
		Z^{dec, l}_{:,c} &= transformer\_decoder\left(\tilde{Z}^{dec,l}_{:,c}, Z^{channels, l}_{:,c}, Z^{channels, l}_{:,c}\right) \\
		\tilde{Z}^{dec,l} &=
		\begin{cases}
			TSA\left(E^{\text{dec}}\right), & \text{if } l=0 \\
			TSA\left(Z^{dec, l-1}\right), & \text{if } l > 0
		\end{cases}
	\end{split}
	\label{eq:decoder-cross-attention}
\end{equation}

Every output of the decoder layers is linearly projected to the forecasting horizon seperately which are then added together to produce the final forecasting. By this a complete explanation is presented of crossformer with all acknowledgment going to \cite{zhang23} for the methodology as well as the equations presented in this part of the appendix. To wrap up, each component of the method helps on capturing different aspect of the time series. This starts with capturing information across time in patches for getting the local context, then going through cross-segments, cross-channel attention to capture the information on the temporal and spatial (across-channel) dimension. Finally applying all of this across different resolutions helps detect different repeating patterns if existent on different time resolutions.



\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
