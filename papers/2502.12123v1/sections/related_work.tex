\section{Related work}
\label{sec:related_works}


\paragraph{Inference-time scaling for language models}
Practical language generation tasks typically impose various task-specific constraints in addition to the general grammatical rules of language.
One effective way to improve the chance of satisfying such constraints
is to increase the inference-time compute 
through search and/or rejection sampling.
There has been a long history of prior works that employ inference-time scaling in the language generation context, 
dating as far back as beam search \citep{lowerre1976harpy,hayes1976speech,ow1988filtered,jurafsky2000speech,graves2012sequence}.
Much more recently, as researchers develop the techniques for language models to follow instructions 
(see the survey by \citet{zhang2023instruction} and references therein),
more creative designs for inference-time scaling algorithms have become viable 
\citep{wang2022self,yao2023tree,zhang2023planning,zhou2023language,choi2023kcts,liu2024don,xie2024self,snell2024scaling,zhao2024probabilistic},
and see \citet{wu2024inference} for a recent survey on cost-performance tradeoffs of these approaches.
Compared to these approaches in the literature, 
our \algoName (\Cref{alg:sampling_with_backtracking}) shares some features with lookahead search \citep{snell2024scaling}
(specifically, the rejection decision at the current position is based on the verifier decision at some future position).
However, two main differences are:
(1) \algoName (\Cref{alg:sampling_with_backtracking})
does not use a beam (i.e. does not need to generate multiple candidates, thus reducing query complexity),
and (2) \Cref{alg:sampling_with_backtracking} uses a different sampling approach (namely argmax) for the backtracked positions (we verify in \Cref{sec:appendix:experiments:algo} that in some settings this significantly improves the accuracy).
It is a natural future research direction to design inference algorithms that combine the advantages of the two.



\paragraph{Incorporating a process reward model to assist language generation}
Among the vast design space for inference-time scaling,
process reward modeling has been proven to be an important component common to many LLM systems
\citep{polu2020generative,uesato2022solving,ma2023let,lightman2023let,wang2024math}.
The process verifier which we study (\Cref{def:verifier}) is a special case of such process reward model if we restrict the output to be binary.
However, there are still challenging open problems around process reward modeling,
such as how to properly define the ``blocks"
\citep{guo2025deepseek}
(see also our definitions in the ``Block verifier" part of \Cref{sec:experiments:codellama:verifier}).
Towards bringing more clarity to these open questions,
our work develops a theoretical framework for reasoning about the query complexity of process verifiers.
Moreover, our experiments suggest the potentials of a lightweight process verifier in improving the query complexity, accuracy, and diversity of constrained generation.
In particular, our theory and experiments suggest
(1) the ``blocks" do not necessarily have to be carefully designed --- setting each token as a block might potentially suffice, at least in some more structured domains such as codes;
(2) \emph{backtracking} (\Cref{alg:sampling_with_backtracking}, \Cref{sec:experiments}) is a robustly effective strategy that should be applied in combination with process verifiers.
% We discuss additional related works in Appendix~\ref{sec:appendix:related_works}.




\paragraph{Controlled synthetic data distribution as a sandbox for studying language models}
Our Dyck grammar distribution most closely follows \citet{wen2023uninterpretability} 
(though we switched to a fixed-sequence-length setting, and used unbalanced bracket type probability, instead of length extrapolation, to define the criteria for a prompt to be \emph{out-of-distribution}).
Dyck grammar was also used in other prior works \citep{hewitt2020rnns, ebrahimi2020self, yao2021self, liu2023same, liu2023Transformers} to study language models.
Other synthetic data distributions have been used to study various aspects of language models in prior works, including
representational capability \citep{bhattamishra2020ability, li2021limitations, zhang2022unveiling, zhao2023Transformers}, 
statistical sample complexity \citep{edelman2022inductive},
optimization process \citep{lu2021on, jelassi2022vision,li2023Transformers,bietti2023birth},
sampling \citep{li2024promises},
and architectural limitations \citep{liu2023exposing},
and see references cited therein.
