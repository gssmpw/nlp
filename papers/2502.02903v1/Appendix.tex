\clearpage
\appendix
% \clearpage



\section{Names used for perturbation in  Benchmarking}
Table~\ref{tab:names_used_benchmark} presents the universe of names used for perturbation in the benchmarking experiment in Sec.~\ref{sec:benchmarking}.  These names represent a diverse range of geographies.
\begin{table*}[ht!]
% \small
\scalebox{0.8}{
\begin{tabular}{|c|p{17.5cm}|}
\hline
\centering
Person names&  
    Aaron, Adrian, Aiden, Akira, Alex, Alexander, Alfred, Anders, Andreas, Andrew, Anthony, Archer, Arthur, Ayden, Benjamin,    Bernard, Blake, Boris, Bradley, Brandon, Brayden, Brian, Caleb, Cameron, Carlos,    Carl, Charles, Charlie, Christopher, Connor, Cooper, Daichi, Daniel, David, Dean,    Dennis, Dylan, Edward, Elijah, Elliot, Emil, Eric, Ethan, Evan, Ezra, Fabian, Felix, Finn, Francis, Gavin, George, Giovanni, Gregory, Haakon, Han, Harry, Hayden, Henry, Hiroki, Hugo, Hunter, Ian, Isaac,    Ivan, Jack, Jacob, Jake, James, Jason, Jasper, Jayden, Jeremy,
    Jesse, Jin, Joaquim, Johan, John, Jonathan, Jordan, Joseph, Joshua, Juan,
    Kai, Kaiden, Kazuma, Keanu, Ken, Kenneth, Kevin, Liam, Logan, Lucas,
    Luis, Luke, Luka, Magnus, Mark, Martin, Mateo, Matthew, Max, Maximilian,
    Michael, Mikael, Nathan, Nathaniel, Nicolas, Noah, Oliver, Oscar,
    Owen, Pablo, Patrick, Paul, Pedro, Peter, Phillip, Phoenix, Rafael, Rajiv,
    Ralf, Ramón, Raphael, Ravi, Raymond, Reuben, Richard, Robert, Robin, Rohan,
    Roland, Ronan, Ryan, Samuel, Santiago, Sebastian, Sean, Silas, Simon, Stefan,
    Stephen, Thomas, Timothy, Tyler, Victor, Vincent, Walter, William, Xavier, Yan,
    Yang, Yao, Youssef, Zachary, Zane, Zayd, Zephyr, Zidan, Zinedine, Zubin,
    Alistair, Anders, Arjun, Arthur, Axel, Bartosz, Ben, Björn, Bruno, Caleb,
    Caoimhín, Cillian, Cormac, Daisuke, Damien, Darius, Deniz, Dorian, Eamon,
    Emile, Enzo, Fionn, Florian, Gabriel, Gideon, Gustaf, Hassan, Héctor, Igor,
    Ishaan, Ivan, Jasper, Kai, Leo, Levi, Liam, Luca, Lucian, Luis,
    Magnus, Marcel, Matteo, Max, Milan, Noah, Oliver, Oscar, Otto, Pavel,
    Quentin, Rafael, Ravi, Rémy, Ren, Robin, Samuel, Santiago, Sebastian, Silas,
    Soren, Theo, Thomas, Tristan, Viktor, William, Xavier, Yannik, Zane, Aditya, Ajeet, Ajit, Akash, Amar, Amit, Arjun, Aryan,    Ashish, Avinash, Bharat, Bhuvan, Chirag, Darshan, Dev, Dheeraj, Dhruv, Gaurav,    Harsh, Harsha, Hemant, Ishan,Shubham, Karan, Karthik, Kumar,
    Manav, Manoj, Mihir, Nikhil, Niranjan, Nivaan, Pradeep, Pranav, Raj, Rajeev,
    Rahul, Ramesh, Ranjit, Ravi, Rohan, Rohit, Roop, Sachin, Sandeep, Sanjay,
    Sanket, Sarthak, Satish, Shaan, Shahrukh, Shankar, Sharad, Shivam, Siddhant, Siddharth,
    Soham, Somesh, Suresh, Tejas, Uday, Varun, Vijay, Vikram, Vinay, Vishal,
    Yash, Yogesh, Yuvraj, Adil, Amine, Anas, Fayçal, Hakim,
    Hicham, Mazen, Mehdi, Nassim, Rafik, Sami, Sofiane, Tarik, Yacine, Yassine,
    Abiodun, Ade, Adekunle, Adewale, Ayodeji, Chidi, Chijioke, David, Ebuka, Emeka,
    Godwin, Ikechukwu, Ikenna, Kolade, Kunle, Nonso, Obinna, Olamide, Olusegun, Onyeka,
    Paul, Peter, Samuel, Taiwo, Uche, Victor, Yemi, Yinka, Aiden, Callum,
    Connor, Declan, Dylan, Eoghan, Finn, Jack, James, Jamie,
    Jason, Jayden, Kian, Liam, Logan, Lucas, Luke, Mason, Max, Michael,
    Noah, Oliver, Oscar, Rory, Ryan, Samuel, Sean, Thomas, William, Charlie,
    Freddie, George, Harry, Jacob, Leo, Oliver, Oscar, Teddy, Arthur, Freddie,
    George, Harry, Jacob, Leo, Oliver, Oscar, Teddy, Aiden, Alexander, Charlie,
    Ethan, Jacob, James, Leo, Mason, Michael, Noah, Oliver, William, Benjamin,
    Charlie, Jacob, Leo, Oliver, Oscar, Thomas, William, Aiden, Charlie, Ethan,
    Jacob, Leo, Oliver, Oscar, Thomas, William, Shrey,Venkatesh,Nguyen,Vishwanathan ,    Priya, Patricia, Jennifer, Linda, Barbara, Susan, Camille, Sophie, Julie, Claire, Yuki, Sakura, Hana, Aiko,  Emi, Li, Xiao, Mei, Fang, Jing, Maria, Ana, Isabel, Carmen,
    Dolores, Amina, Layla, Nadia, Olga, Irina, Svetlana,
    Ekaterina, Giulia, Francesca, Anna, Elena, Heidi, Greta, Lena, Marta, Sofia,
    Valentina, Martina, Paula, Clara, Laura, Mia, Emily, Sophia, Charlotte,
    Anita, Kavita, Lalita, Meena, Lucy, Megan, Hannah, Jessica, Amelia,
    Chloe, Manon, Lea, Elodie, Amandine, Haruka, Miyu, Rina, Yuna, Nao,
    Chen, Hua, Ling, Qing, Yan, Lucia, Pilar, Rosa, Nour, Sara,
    Hiba, Mona, Rania, Anastasia, Natalia, Daria, Polina, Vera, Mariana, Gabriela,
    Beatriz, Rafaela, Camila, Juliana, Evelyn, Amanda, Milla, Ines, Susana,
    Leonor, Bianca, Livia, Helena, Marina, Fernanda, Eduarda, Victoria, Andressa, Denise,
    Raquel, Isis, Elisa, Julia, Luana, Milena, Yasmin, Alessandra, Claudia, Veronica,
    Larissa, Bia, Silvia, Vanessa, Leticia, Nicole, Daniele, Eva, Alice, Milena,
    Leonie, Mila, Lisa, Sarah, Emma, Helena, Anja,
     Tina, Ingrid, Lucija,    Noor, Samira, Dana, Kalila, Arwa, Eman, Latifa, Nahla, Sang,
    Jin, Hye, Soo, Mi, Eun, Yeon, Ji, Sun, Abeba,
    Hadia, Fatou, Maimouna, Nia, Asha, Kamaria, Mira, Joan,
    Fiona, Leanne, Orla, Ava, Siobhan, Niamh, Sienna, Poppy, Lara,
    Freya, Florence, Rosie, Summer, Ivy,Sunidhi, Amara, Chidinma, Ngozi,
    Sunaina, Matilda, Harper, Willow, Aarushi, Ananya, Bhavna, Chandni, Deepa,
    Esha, Hina, Sneha, Jaya, Kiran, Lata, Maya, Nisha, Shrishti, Isabella, Saanvi, Drishti \\
\hline
Country Names & Afghanistan, Albania, Algeria, Andorra, Angola, Antigua and Barbuda, Argentina, Armenia, Australia, Austria,
    Azerbaijan, Bahamas, Bahrain, Bangladesh, Barbados, Belarus, Belgium, Belize, Benin, Bhutan,
    Bolivia, Bosnia and Herzegovina, Botswana, Brazil, Brunei, Bulgaria, Burkina Faso, Burundi, Cabo Verde, Cambodia,
    Cameroon, Canada, Central African Republic, Chad, Chile, China, Colombia, Comoros, Congo, Costa Rica,
    Croatia, Cuba, Cyprus, Czech Republic, Denmark, Djibouti, Dominica, Dominican Republic, Ecuador, Egypt,
    El Salvador, Equatorial Guinea, Eritrea, Estonia, Eswatini, Ethiopia, Fiji, Finland, France, Gabon,
    Gambia, Georgia, Germany, Ghana, Greece, Grenada, Guatemala, Guinea, Guinea-Bissau, Guyana,
    Haiti, Honduras, Hungary, Iceland, India, Indonesia, Iran, Iraq, Ireland, Israel,
    Italy, Jamaica, Japan, Jordan, Kazakhstan, Kenya, Kiribati, Kuwait, Kyrgyzstan, Laos,
    Latvia, Lebanon, Lesotho, Liberia, Libya, Liechtenstein, Lithuania, Luxembourg, Madagascar, Malawi,
    Malaysia, Maldives, Mali, Malta, Marshall Islands, Mauritania, Mauritius, Mexico, Micronesia, Moldova,
    Monaco, Mongolia, Montenegro, Morocco, Mozambique, Myanmar, Namibia, Nauru, Nepal, Netherlands,
    New Zealand, Nicaragua, Niger, Nigeria, North Korea, North Macedonia, Norway, Oman, Pakistan, Palau,
    Panama, Papua New Guinea, Paraguay, Peru, Philippines, Poland, Portugal, Qatar, Romania, Russia,
    Rwanda, Saint Kitts and Nevis, Saint Lucia, Saint Vincent and the Grenadines, Samoa, San Marino, Saudi Arabia, Senegal, Serbia  \\
\hline
\end{tabular}}
\caption{Universe of names used for replacement in benchmarking\label{tab:names_used_benchmark}.}
\end{table*}

% \newpage\leavevmode\thispagestyle{empty} \newpage



\section{Bias measurement with only person name perturbations}
\label{sec:person_name_perturbation}
In the benchmarking study in Sec.~\ref{sec:benchmarking},  we investigated the divergence in text embeddings when person names and locations were perturbed. In this section, we examine the impact of replacing only person names on the text embeddings.

\subsection{Perturbations of only person names}
In this study, we only perturb person names and keep the location names unchanged to understand the impact of only perturbing person names. As shown in Table~\ref{tab:cmu_book_only_person_replace}, performing only person name perturbations on book plots also reveals a significant drop in cosine similarity across all evaluated models.
\label{sec:person_name_perturbation_only_country_exists}

\begin{table}[h!]
\centering
% \small
\scalebox{0.78}{\begin{tabular}{ll}%p{4cm}}
\toprule
                           Model Name &  \makecell{Cosine sim \\ per perturbation
pair} \\ %&\\  %Number of applicable
% shows within token
% limit \\

\midrule
%                     all-mpnet-base-v2 &  0.817 ± 0.11 &                    5649 \\
%                  all-distilroberta-v1 & 0.822 ± 0.105 &                    6950 \\
%                      all-MiniLM-L6-v2 & 0.751 ± 0.127 &                    3641 \\
%            multi-qa-distilbert-cos-v1 & 0.786 ± 0.121 &                    6950 \\
%               paraphrase-MiniLM-L6-v2 & 0.775 ± 0.122 &                    1074 \\
%  distiluse-base-multilingual-cased-v1 & 0.844 ± 0.082 &                    1074 \\
%  distiluse-base-multilingual-cased-v2 & 0.849 ± 0.082 &                    1074 \\
% paraphrase-multilingual-MiniLM-L12-v2 &  0.79 ± 0.117 &                    1074 \\
%             msmarco-distilbert-cos-v5 & 0.752 ± 0.127 &                    5649 \\
%            multi-qa-mpnet-base-cos-v1 & 0.796 ± 0.116 &                    6950 \\
%                         voyage-3-lite & 0.822 ± 0.077 &                    6950 \\
%                                gemini & 0.911 ± 0.034 &                    6950 \\

%                     all-mpnet-base-v2 &                  0.815 $\pm$ 0.111 \\
%                  all-distilroberta-v1 &                  0.821 $\pm$ 0.105 \\
%                      all-MiniLM-L6-v2 &                  0.749 $\pm$ 0.127 \\
%                                gemini &                   0.91 $\pm$ 0.035 \\
%            multi-qa-distilbert-cos-v1 &                   0.787 $\pm$ 0.12 \\
%               paraphrase-MiniLM-L6-v2 &                  0.773 $\pm$ 0.123 \\
%  distiluse-base-multilingual-cased-v1 &                  0.843 $\pm$ 0.084 \\
%  distiluse-base-multilingual-cased-v2 &                  0.848 $\pm$ 0.083 \\
% paraphrase-multilingual-MiniLM-L12-v2 &                   0.79 $\pm$ 0.117 \\
%             msmarco-distilbert-cos-v5 &                  0.752 $\pm$ 0.127 \\
%            multi-qa-mpnet-base-cos-v1 &                  0.795 $\pm$ 0.116 \\
%                         voyage-3-lite &                  0.821 $\pm$ 0.077 \\
                all-mpnet-base-v2 &      0.815 $\pm$ 0.0001 \\
                 all-distilroberta-v1 &                 0.821 $\pm$ 0.0001 \\
                     all-MiniLM-L6-v2 &                 0.749 $\pm$ 0.0002 \\
                               gemini &                     0.91 $\pm$ 0.0 \\
           multi-qa-distilbert-cos-v1 &                 0.787 $\pm$ 0.0001 \\
              paraphrase-MiniLM-L6-v2 &                 0.773 $\pm$ 0.0003 \\
 distiluse-base-multilingual-cased-v1 &                 0.843 $\pm$ 0.0002 \\
 distiluse-base-multilingual-cased-v2 &                 0.848 $\pm$ 0.0002 \\
paraphrase-multilingual-MiniLM-L12-v2 &                  0.79 $\pm$ 0.0003 \\
            msmarco-distilbert-cos-v5 &                 0.752 $\pm$ 0.0001 \\
           multi-qa-mpnet-base-cos-v1 &                 0.795 $\pm$ 0.0001 \\
                        voyage-3-lite &                 0.821 $\pm$ 0.0001 \\
                               
\bottomrule
\end{tabular}}
\caption{\textbf{Bias Measuremenent on CMU Books dataset with perturbation of person names only.} For each show, we create $K{=}20$ perturbations by
replacing person names. We compute the average cosine similarity for each perturbation pair and the standard error. The country/city/town names remain unchanged. \label{tab:cmu_book_only_person_replace}.}
\end{table}


\subsection{Person name perturbations on text samples without mention of country/city/town names}
\label{sec:person_name_no_country_samples}
In this section, we investigate impact of person name perturbations when using samples which don't have mention of any country/city/town etc. names. The objective is to minimize the impact of these variables and study divergence solely w.r.t person names. As shown in Table~\ref{tab:cmu_book_no_location_only_person_replace}, benchmarking on the CMU Book dataset on samples without having any mention of country/city/town etc. reveals a significant drop in cosine similarity across all evaluated models when only person names are perturbed.  


\begin{table}[h!]
\centering
% \small
\scalebox{0.78}{
% \small
\begin{tabular}{ll}
\toprule
                          Model Name &  \makecell{Cosine sim \\ per perturbation
pair}    \\
\midrule
%                text-embedding-3-large &                       0.808 $\pm$                          0.096 &                    1705 \\
%                text-embedding-3-small &                       0.793 $\pm$                          0.101 &                    1705 \\
%                     all-mpnet-base-v2 &                       0.799 $\pm$                          0.116 &                    1479 \\
%                  all-distilroberta-v1 &                       0.805 $\pm$                          0.108 &                    1705 \\
%                      all-MiniLM-L6-v2 &                       0.734 $\pm$                          0.129 &                    1103 \\
%            multi-qa-distilbert-cos-v1 &                       0.765 $\pm$                         0.127 &                    1705 \\
%               paraphrase-MiniLM-L6-v2 &                       0.761 $\pm$                          0.122 &                     447 \\
%  distiluse-base-multilingual-cased-v1 &                       0.825 $\pm$                        0.087 &                     447 \\
%  distiluse-base-multilingual-cased-v2 &                       0.828 $\pm$                        0.087 &                     447 \\
% paraphrase-multilingual-MiniLM-L12-v2 &                       0.772 $\pm$                       0.120 &                     447 \\
%             msmarco-distilbert-cos-v5 &                       0.748 $\pm$                        0.127 &                    1479 \\
%            multi-qa-mpnet-base-cos-v1 &                       0.781 $\pm$                          0.120 &                    1705 \\
%                         voyage-3-lite &                       0.811 $\pm$                          0.080 &                    1705 \\
%                                gemini &                       0.907 $\pm$                         0.035 &                    1705 \\



%  all-mpnet-base-v2 &                  0.796 $\pm$ 0.117 \\
%                  all-distilroberta-v1 &                  0.803 $\pm$ 0.108 \\
%                      all-MiniLM-L6-v2 &                  0.731 $\pm$ 0.128 \\
%                                gemini &                  0.906 $\pm$ 0.035 \\
%            multi-qa-distilbert-cos-v1 &                  0.766 $\pm$ 0.125 \\
%               paraphrase-MiniLM-L6-v2 &                  0.758 $\pm$ 0.121 \\
%  distiluse-base-multilingual-cased-v1 &                  0.825 $\pm$ 0.086 \\
%  distiluse-base-multilingual-cased-v2 &                  0.828 $\pm$ 0.085 \\
% paraphrase-multilingual-MiniLM-L12-v2 &                   0.77 $\pm$ 0.118 \\
%             msmarco-distilbert-cos-v5 &                  0.747 $\pm$ 0.125 \\
%            multi-qa-mpnet-base-cos-v1 &                  0.778 $\pm$ 0.119 \\
%                text-embedding-3-small &                    0.791 $\pm$ 0.1 \\
%                         voyage-3-lite &                    0.81 $\pm$ 0.08 \\
                    all-mpnet-base-v2 &                 0.796 $\pm$ 0.0002 \\
                 all-distilroberta-v1 &                 0.803 $\pm$ 0.0002 \\
                     all-MiniLM-L6-v2 &                 0.731 $\pm$ 0.0003 \\
                               gemini &                 0.906 $\pm$ 0.0001 \\
           multi-qa-distilbert-cos-v1 &                 0.766 $\pm$ 0.0002 \\
              paraphrase-MiniLM-L6-v2 &                 0.758 $\pm$ 0.0004 \\
 distiluse-base-multilingual-cased-v1 &                 0.825 $\pm$ 0.0003 \\
 distiluse-base-multilingual-cased-v2 &                 0.828 $\pm$ 0.0003 \\
paraphrase-multilingual-MiniLM-L12-v2 &                  0.77 $\pm$ 0.0004 \\
            msmarco-distilbert-cos-v5 &                 0.747 $\pm$ 0.0002 \\
           multi-qa-mpnet-base-cos-v1 &                 0.778 $\pm$ 0.0002 \\
                        voyage-3-lite &                  0.81 $\pm$ 0.0001 \\
\bottomrule
\end{tabular}}
\caption{\textbf{Bias Measuremenent on CMU Books dataset on samples without mention of country/city/town names.} Perturbation  of person names only. For each show, we create $K{=}20$ perturbations by
replacing person names. We compute the average cosine similarity for each perturbation pair and the standard error.\label{tab:cmu_book_no_location_only_person_replace}}
\end{table}




\begin{table*}[h!]
% \small
\scalebox{0.8}{
\begin{tabular}{|c|p{17cm}|}
\hline
Country & Person Names \\ \hline
 France &  
   Max, Tom, Léo, Noé, Paul, 
    Jules, Hugo, Arthur, Louis, Clément,
    Jean-Baptiste, Jean-Pierre, Jean-Paul, Charles-Henri, François-Xavier, 
    Constantin, Gaspard, Côme, Yanis, Kilian,
    Maël, Thibault, Raphaël, Jérémie, Vincent,
    Antoine, Pierre, Louis, Jacques, Baptiste,
    Émile, Gustave, Henri, Laurent, Marcel,
    Nicolas, Olivier, Pascal, Quentin, Rémi,
    Sébastien, Théodore, Ulysse, Valentin, Wilfried,
    Xavier, Yves, Zacharie, Adrien, Bernard, Eva,  Zoé,  Jade,  Lou,
    Alice, Chloé, Léa,  Lina, Louise, 
    Éléonore, Solène, Héloïse, Camille, 
    Marie,  Jeanne,  Sophie,  Claire,  Isabelle, 
    Ambre,  Lilou,  Maëlys, Victoire,  Clémence,
    Valentine, Juliette, Aurélie, Angélique, Amandine,
    Brigitte, Catherine, Delphine, Édith, Fanny,
    Gabrielle, Hélène, Inès, Joséphine, Karine,
    Laure, Manon, Nathalie, Océane, Pascale,
    Quitterie, Rosalie, Stéphanie, Thérèse, Ursule\\
\hline
    India & Aarav, Aditya, Aryan, Ayush, Dev, 
    Ishaan, Ramesh, Krishna, Mihir, Rohan, 
    Sahir, Samarth, Shaurya, Vihaan, Vrijesh, 
    Aakash, Advait, Vinayak, Atharv, Venkatesh, 
    Dhruv, Eshan, Hrithik, Kabir, Karan, 
    Krish, Mahesh, Nakul, Pranav, Rudra, 
    Siddharth, Soham, Tanmay, Uday, Vaibhav, 
    Vedant, Vikram, Yash, Yuvraj,Sachin, 
    Ahaan, Gaurav, Arjun, Daksh, Devansh, 
    Ishan, Vishwanathan, Mayank, Parichay, Krishnanshu, 
    Sahir, Rishi, Samyak, Brajesh, Vivaan, 
    Ayan, Rudra,Rakesh, Zain,  Aarohi, Bhavya, Charvi, Devika, Eshani,
    Falguni, Garima, Harini, Ishita, Jahnvi,
    Kavya, Lavanya, Madhavi, Niharika, Ojasvi,
    Prisha, Qara, Radhika, Saanvi, Tara,
    Urvashi, Vanya, Wamika, Xara, Yamini,
    Zara, Anvi, Bhumika, Chaitali, Dharini,
    Ekta, Fiza, Gauri, Himani, Ira,
    Jiya, Kriti, Lata, Meera, Nisha,
    Oviya, Pallavi, Rhea, Sakshi, Tanisha,
    Uma, Vaidehi, Yashika, Zaina, Aditi \\ \hline

    Spain & 


    Mateo, Santiago, Lucas, Marcos, Daniel,
    David, Samuel, Benjamín, Ezequiel, Noé,
    Salvador, Ismael, Aarón, Elías, Jonás,
    Jeremías, Iker, Unax, Aitor, Ander,  
    Martín, Rodrigo, Fernando, Alfonso, Enrique,
    Felipe, Carlos, Javier, Jorge, Luis,
    Antonio, José, Juan, Manuel, Pedro,
    Francisco, Ignacio, Rafael, Víctor, Álvaro,
    Diego, Gabriel, Miguel, Pablo, Ricardo,
    Sergio, Tomás, César, Gonzalo, Leonardo,
    Emiliano, Matías, Nicolás, Sebastián, Thiago,   Sofía, Camila, Valentina, Martina, Emilia,
    Emma, Olivia, Luna, Zoe, Mia,
    Isabella, Victoria, Sara, Lucía, María,
    Laura, Paula, Andrea, Ana, Elena,
    Carmen, Alba, Carla, Daniela, Julia,
    Natalia, Ximena, Aitana, Noa, Mía,
    Isabel, Beatriz, Blanca, Clara, Inés,
    Irene, Marta, Patricia, Rocío, Silvia,
    Teresa, Verónica, Alicia, Amelia, Ángela,
    Aurora, Bárbara, Carolina, Dolores, Eva,
    Gloria, Lidia, Lorena, Mónica, Nuria,
    Olga, Raquel, Sandra,Xiomara, Yamile \\

\hline
\end{tabular}}
\caption{Universe of names for country wise name replacement in benchmarking experiments in Sec.~\ref{sec:person_name_perturbation}\label{tab:names_used_benchmark_country_wise}}
\end{table*}




\begin{table}[h!]
\centering
\scalebox{0.78}{
% \small
\begin{tabular}{ll}
\toprule
                           Model Name &    \makecell{Cosine sim \\ per perturbation
pair}   \\%\\& \\# num\_applicable\_samples \\
\midrule
%                text-embedding-3-small &  0.842 ± 0.08 &                    1705 \\
%                text-embedding-3-large & 0.863 ± 0.074 &                    1705 \\
%                     all-mpnet-base-v2 & 0.855 ± 0.095 &                    1479 \\
%                  all-distilroberta-v1 & 0.862 ± 0.084 &                    1705 \\
%                      all-MiniLM-L6-v2 & 0.798 ± 0.107 &                    1103 \\
%            multi-qa-distilbert-cos-v1 &   0.833 ± 0.1 &                    1705 \\
%               paraphrase-MiniLM-L6-v2 & 0.818 ± 0.102 &                     447 \\
%  distiluse-base-multilingual-cased-v1 &  0.836 ± 0.08 &                     447 \\
%  distiluse-base-multilingual-cased-v2 & 0.836 ± 0.079 &                     447 \\
% paraphrase-multilingual-MiniLM-L12-v2 & 0.831 ± 0.098 &                     447 \\
%             msmarco-distilbert-cos-v5 & 0.817 ± 0.095 &                    1479 \\
%            multi-qa-mpnet-base-cos-v1 & 0.831 ± 0.102 &                    1705 \\
%                         voyage-3-lite & 0.853 ± 0.064 &                    1705 \\
%                                gemini & 0.932 ± 0.027 &                    1705 \\



%                     all-mpnet-base-v2 &                    0.842 $\pm$ 0.1 \\
%                  all-distilroberta-v1 &                  0.852 $\pm$ 0.089 \\
%                      all-MiniLM-L6-v2 &                  0.784 $\pm$ 0.113 \\
%                                gemini &                   0.93 $\pm$ 0.028 \\
%            multi-qa-distilbert-cos-v1 &                   0.82 $\pm$ 0.107 \\
%               paraphrase-MiniLM-L6-v2 &                  0.806 $\pm$ 0.107 \\
%  distiluse-base-multilingual-cased-v1 &                  0.837 $\pm$ 0.078 \\
%  distiluse-base-multilingual-cased-v2 &                  0.838 $\pm$ 0.079 \\
% paraphrase-multilingual-MiniLM-L12-v2 &                     0.82 $\pm$ 0.1 \\
%             msmarco-distilbert-cos-v5 &                  0.799 $\pm$ 0.104 \\
%            multi-qa-mpnet-base-cos-v1 &                  0.815 $\pm$ 0.107 \\
%                         voyage-3-lite &                  0.847 $\pm$ 0.066 \\
                    all-mpnet-base-v2 &                 0.842 $\pm$ 0.0002 \\
                 all-distilroberta-v1 &                 0.852 $\pm$ 0.0002 \\
                     all-MiniLM-L6-v2 &                 0.784 $\pm$ 0.0002 \\
                               gemini &                     0.93 $\pm$ 0.0 \\
           multi-qa-distilbert-cos-v1 &                  0.82 $\pm$ 0.0002 \\
              paraphrase-MiniLM-L6-v2 &                 0.806 $\pm$ 0.0004 \\
 distiluse-base-multilingual-cased-v1 &                 0.837 $\pm$ 0.0003 \\
 distiluse-base-multilingual-cased-v2 &                 0.838 $\pm$ 0.0003 \\
paraphrase-multilingual-MiniLM-L12-v2 &                  0.82 $\pm$ 0.0003 \\
            msmarco-distilbert-cos-v5 &                 0.799 $\pm$ 0.0002 \\
           multi-qa-mpnet-base-cos-v1 &                 0.815 $\pm$ 0.0002 \\
                        voyage-3-lite &                 0.847 $\pm$ 0.0001 \\
                        
\bottomrule
\end{tabular}}
\caption{\textbf{Bias Measurement: Names from same country.} Perturbation of person names and replacing them with names from \textbf{\textit{Spain}}. We used CMU Book dataset for this experiment and set number of perturbations $K{=}20$. We used samples without mention of country/city/town/other location names, nationality etc.\label{tab:same_culture_perturb_Spain} } 
\end{table}







\begin{table}[h!]
\centering
% \small
\scalebox{0.78}{
\begin{tabular}{ll}
\toprule
                           Model Name &   \makecell{Cosine sim \\ per perturbation
pair} \\
\midrule
%                text-embedding-3-small & 0.834 ± 0.083 &                    1705 \\
%                text-embedding-3-large &   0.85 ± 0.08 &                    1705 \\
%                     all-mpnet-base-v2 &   0.839 ± 0.1 &                    1479 \\
%                  all-distilroberta-v1 & 0.838 ± 0.093 &                    1705 \\
%                      all-MiniLM-L6-v2 & 0.756 ± 0.126 &                    1103 \\
%            multi-qa-distilbert-cos-v1 & 0.806 ± 0.111 &                    1705 \\
%               paraphrase-MiniLM-L6-v2 &  0.79 ± 0.118 &                     447 \\
%  distiluse-base-multilingual-cased-v1 &  0.83 ± 0.087 &                     447 \\
%  distiluse-base-multilingual-cased-v2 & 0.833 ± 0.086 &                     447 \\
% paraphrase-multilingual-MiniLM-L12-v2 & 0.815 ± 0.113 &                     447 \\
%             msmarco-distilbert-cos-v5 & 0.787 ± 0.113 &                    1479 \\
%            multi-qa-mpnet-base-cos-v1 &  0.81 ± 0.108 &                    1705 \\
%                         voyage-3-lite & 0.843 ± 0.069 &                    1705 \\
%                                gemini &  0.93 ± 0.028 &                    1705 \\

%                     all-mpnet-base-v2 &                     0.84$\pm$ 0.1 \\
%                  all-distilroberta-v1 &                  0.838$\pm$ 0.093 \\
%                      all-MiniLM-L6-v2 &                  0.757$\pm$ 0.125 \\
%                                gemini &                  0.931$\pm$ 0.028 \\
%            multi-qa-distilbert-cos-v1 &                  0.806$\pm$ 0.111 \\
%               paraphrase-MiniLM-L6-v2 &                   0.79$\pm$ 0.118 \\
%  distiluse-base-multilingual-cased-v1 &                   0.83$\pm$ 0.085 \\
%  distiluse-base-multilingual-cased-v2 &                  0.833$\pm$ 0.085 \\
% paraphrase-multilingual-MiniLM-L12-v2 &                  0.815$\pm$ 0.111 \\
%             msmarco-distilbert-cos-v5 &                  0.786$\pm$ 0.113 \\
%            multi-qa-mpnet-base-cos-v1 &                   0.81$\pm$ 0.108 \\
%                         voyage-3-lite &                  0.843$\pm$ 0.069 \\
                    all-mpnet-base-v2 &                  0.84 $\pm$ 0.0002 \\
                 all-distilroberta-v1 &                 0.838 $\pm$ 0.0002 \\
                     all-MiniLM-L6-v2 &                 0.757 $\pm$ 0.0003 \\
                               gemini &                    0.931 $\pm$ 0.0 \\
           multi-qa-distilbert-cos-v1 &                 0.806 $\pm$ 0.0002 \\
              paraphrase-MiniLM-L6-v2 &                  0.79 $\pm$ 0.0004 \\
 distiluse-base-multilingual-cased-v1 &                  0.83 $\pm$ 0.0003 \\
 distiluse-base-multilingual-cased-v2 &                 0.833 $\pm$ 0.0003 \\
paraphrase-multilingual-MiniLM-L12-v2 &                 0.815 $\pm$ 0.0004 \\
            msmarco-distilbert-cos-v5 &                 0.786 $\pm$ 0.0002 \\
           multi-qa-mpnet-base-cos-v1 &                  0.81 $\pm$ 0.0002 \\
                        voyage-3-lite &                 0.843 $\pm$ 0.0001 \\
\bottomrule
\end{tabular}}
\caption{\textbf{Bias Measurement: Names from same country.} Perturbation of person names and replacing them with names from \textit{\textbf{France}}. We used CMU Book dataset for this experiment and set number of perturbations $K{=}20$. We used samples without mention of country/city/town/other location names, nationality etc. \label{tab:same_culture_perturb_France}}
\end{table}


\begin{table}[h!]
\centering
% \small
\scalebox{0.78}{
\begin{tabular}{ll}
\toprule
                           Model Name &    \makecell{Cosine sim \\ per perturbation
pair}   \\
\midrule
%                text-embedding-3-small & 0.837 ± 0.084 &                    1705 \\
%                text-embedding-3-large & 0.861 ± 0.081 &                    1705 \\
%                     all-mpnet-base-v2 & 0.817 ± 0.108 &                    1479 \\
%                  all-distilroberta-v1 & 0.828 ± 0.095 &                    1705 \\
%                      all-MiniLM-L6-v2 & 0.751 ± 0.118 &                    1103 \\
%            multi-qa-distilbert-cos-v1 &  0.79 ± 0.112 &                    1705 \\
%               paraphrase-MiniLM-L6-v2 & 0.778 ± 0.111 &                     447 \\
%  distiluse-base-multilingual-cased-v1 & 0.879 ± 0.067 &                     447 \\
%  distiluse-base-multilingual-cased-v2 & 0.886 ± 0.066 &                     447 \\
% paraphrase-multilingual-MiniLM-L12-v2 & 0.796 ± 0.105 &                     447 \\
%             msmarco-distilbert-cos-v5 & 0.781 ± 0.108 &                    1479 \\
%            multi-qa-mpnet-base-cos-v1 & 0.806 ± 0.108 &                    1705 \\
%                         voyage-3-lite &  0.85 ± 0.064 &                    1705 \\
%                                gemini & 0.931 ± 0.028 &                    1705 \\
%                     all-mpnet-base-v2 &                  0.816$\pm$ 0.107 \\
%                  all-distilroberta-v1 &                  0.828$\pm$ 0.095 \\
%                      all-MiniLM-L6-v2 &                   0.75$\pm$ 0.117 \\
%                                gemini &                  0.931$\pm$ 0.028 \\
%            multi-qa-distilbert-cos-v1 &                   0.79$\pm$ 0.111 \\
%               paraphrase-MiniLM-L6-v2 &                  0.778$\pm$ 0.109 \\
%  distiluse-base-multilingual-cased-v1 &                   0.88$\pm$ 0.066 \\
%  distiluse-base-multilingual-cased-v2 &                  0.887$\pm$ 0.065 \\
% paraphrase-multilingual-MiniLM-L12-v2 &                  0.796$\pm$ 0.104 \\
%             msmarco-distilbert-cos-v5 &                   0.78$\pm$ 0.108 \\
%            multi-qa-mpnet-base-cos-v1 &                  0.805$\pm$ 0.107 \\
%                         voyage-3-lite &                   0.85$\pm$ 0.063 \\
                    all-mpnet-base-v2 &                 0.816 $\pm$ 0.0002 \\
                 all-distilroberta-v1 &                 0.828 $\pm$ 0.0002 \\
                     all-MiniLM-L6-v2 &                  0.75 $\pm$ 0.0003 \\
                               gemini &                    0.931 $\pm$ 0.0 \\
           multi-qa-distilbert-cos-v1 &                  0.79 $\pm$ 0.0002 \\
              paraphrase-MiniLM-L6-v2 &                 0.778 $\pm$ 0.0004 \\
 distiluse-base-multilingual-cased-v1 &                  0.88 $\pm$ 0.0002 \\
 distiluse-base-multilingual-cased-v2 &                 0.887 $\pm$ 0.0002 \\
paraphrase-multilingual-MiniLM-L12-v2 &                 0.796 $\pm$ 0.0004 \\
            msmarco-distilbert-cos-v5 &                  0.78 $\pm$ 0.0002 \\
           multi-qa-mpnet-base-cos-v1 &                 0.805 $\pm$ 0.0002 \\
                        voyage-3-lite &                  0.85 $\pm$ 0.0001 \\
\bottomrule
\end{tabular}}
\caption{\textbf{Bias Measurement: Names from same country.} Perturbation of person names and replacing them with names from \textbf{\textit{India}}. We used CMU Book dataset for this experiment and set number of perturbations $K{=}20$. We used samples without mention of country/city/town/other location names, nationality etc.\label{tab:same_culture_perturb_India} }
\end{table}



\subsection{Bias measurement with person name perturbations from the same geographical area}
\label{sec:person_name_same_geography}
In previous studies, we perturbed names by replacing them from a diverse set of person names. In this study we investigate whether the issue of divergence in embeddings persists when all the perturbed names are from the same geography. This study aims to minimize the impact of cultural differences in analysis in text-embeddings. Table~\ref{tab:names_used_benchmark_country_wise} shows the country wise names used for benchmarking. In tables~\ref{tab:same_culture_perturb_Spain}, ~\ref{tab:same_culture_perturb_France}, and~\ref{tab:same_culture_perturb_India}, we observe that the divergence issue persists even when the replaced names belong to the same geography. This demonstrates that the issue is not present in names from certain cultures, cross-culture, but is universal in the sense that the name bias issue occurs in a very broad sense.

% \newpage\leavevmode\thispagestyle{empty} 
\newpage
\section{Similarity Heatmaps}
\label{similarity_heatmap}
In this section, we show examples of cosine similarity heatmaps based upon embeddings generated by different text-embedding models. We use the following example:

{\color{blue} \textbf{CHARACTER\_NAME}, a seasoned physician, meticulously analyzed a patient’s intricate heart condition. He later realised she was his school friend.}

To obtain different perturbations, we replace  \textbf{{\color{blue} "CHARACTER\_NAME"}} with different person names and generate embedding for each of the perturbation. The similarity heatmaps are present in  ~\cref{fig:heatmap_paraphrase,fig:heatmap_gemini,fig:heatmap_openai,fig:all_heatmap_mpnet}. The heatmaps clearly reveal that only changing the person names can significantly impact the text embeddings. This suggests that the text embedding model is highly sensitive to the specific names used within the text, even when the overall context and meaning remains completely unchanged. These kind of variations can lead to misleading results in various downstream tasks. For example, if the goal is to cluster documents into topics, changing the person names could lead to different clusters being formed, even if the underlying topics are the same. Similarly, if the text embedding model is used to classify documents as positive or negative, changing the person names could lead to different classifications being assigned, even if the overall sentiment and theme of the text remains the same. 
% We can observe that in many cases the similarity drops down to as low as $0.64$.


\begin{figure*}[h!]
  \centering
  \includegraphics[width=1.2\textwidth]{figures/paraphrase-multilingual-MiniLM-L12-v2_heatmap.pdf}
  \caption{Cosine Similarity Heatmap with \textit{paraphrase-multilingual-MiniLM-L12} model for example in Sec.~\ref{similarity_heatmap}}
  \label{fig:heatmap_paraphrase}
\end{figure*}

\begin{figure*}[h!]
  \centering
  \includegraphics[width=1.2\textwidth]{figures/gemini_heatmap.pdf}
  \caption{Cosine Similarity Heatmap with Gemini model for example in Sec.~\ref{similarity_heatmap}}
  \label{fig:heatmap_gemini}
\end{figure*}

\begin{figure*}[h!]
  \centering
  \includegraphics[width=1.2\textwidth]{figures/all-mpnet-base-v2_heatmap.pdf}
  \caption{Cosine Similarity Heatmap with \textit{all-mpnet-base-v2} model for example in Sec.~\ref{similarity_heatmap}  \label{fig:all_heatmap_mpnet}}
\end{figure*}

\begin{figure*}[h!]
  \centering
  \includegraphics[width=1.2\textwidth]{figures/text-embedding-3-large_heatmap.pdf}
  \caption{Cosine Similarity Heatmap with \textit{text-embedding-3-large}(Open AI) model for example in Sec.~\ref{similarity_heatmap}   \label{fig:heatmap_openai}}
\end{figure*}


% \begin{figure*}[h]
%     \centering
%     \begin{subfigure}[h]{1.1\textwidth}
%         \includegraphics[width=\textwidth]{figures/gemini_heatmap.pdf}
%         \caption{gemini}
%         \label{fig:image1}
%     \end{subfigure}
%     % \hfill
%     \begin{subfigure}[h]{1.1\textwidth}
%         \includegraphics[width=\textwidth]{figures/paraphrase-multilingual-MiniLM-L12-v2_heatmap.pdf}
%         \caption{araphrase-multilingual-MiniLM-L12-v2}
%         \label{fig:image2}
%     \end{subfigure}
%     \caption{Similarity heatmaps for text a seasoned physician, meticulously analyzed a patient’s intricate heart condition. He prescribed a tailored regimen of medications and rigorous lifestyle modifications to significantly improve her cardiac health.}
%     \label{fig:images}
%     \end{figure*}

% \clearpage
   % \newpage
   % \newpage\leavevmode\thispagestyle{empty}
   % \newpage
   \clearpage

   
\section{Semantic Similarity Task Dataset}
Below we present the STS dataset consisting $10$ samples used in Sec.~\ref{sec:exp_sts_binary}. Each sample is  a triplet of the form: \\ $< Query, Positive\ sample, Negative\ sample >$.
\label{sec:dataset_sts}

% \begin{enumerate}
%     \item  \textbf{Nikolai} and \textbf{Deborah} met on a rainy Tuesday in \textbf{New York}. The city’s hustle and bustle couldn’t dim the spark between them. \textbf{Deborah}, with her radiant smile and infectious laughter, had captured \textbf{Nikolai}'s heart from the moment he saw her. \textbf{Nikolai}, a charming and witty gentleman, returned her affection with equal fervor.
%         \begin{enumerate}
%             \item Positive:  \textbf{Kashvi} and \textbf{Oluwafemi} met on a rainy Tuesday in \textbf{Northampton}. The city’s bustling streets couldn’t dim the spark between them. \textbf{Kashvi}, with her radiant smile and infectious laughter, had captured \textbf{Oluwafemi}’s heart from the moment he saw her. \textbf{Oluwafemi}, a charming and witty gentleman, returned her affection with equal fervor.

%             \item Negative: \textbf{Nikolai} and \textbf{Deborah} staying in \textbf{New Jersey}, once inseparable, were now worlds apart. \textbf{Deborah}, the trusted confidante, had betrayed \textbf{Nikolai}'s trust, revealing his secrets to their rivals. The city's hustle and bustle mirrored the chaos within \textbf{Nikolai}'s heart, as he grappled with the bitter reality of love turned treachery.
%         \end{enumerate}
% \end{enumerate}

\begin{enumerate}
    \item \textbf{Query:} {Nikolai} and {Deborah} met on a rainy Tuesday in {New York}. The city’s hustle and bustle couldn’t dim the spark between them. {Deborah}, with her radiant smile and infectious laughter, had captured {Nikolai}'s heart from the moment he saw her. {Nikolai}, a charming and witty gentleman, returned her affection with equal fervor.
        \begin{itemize}

            \item \textbf{Positive:} {Kashvi} and {Oluwafemi} met on a rainy Tuesday in {Northampton}. The city’s bustling streets couldn’t dim the spark between them. {Kashvi}, with her radiant smile and infectious laughter, had captured {Oluwafemi}’s heart from the moment he saw her. {Oluwafemi}, a charming and witty gentleman, returned her affection with equal fervor.

            \item \textbf{Negative:} {Nikolai} and {Deborah} staying in {New Jersey}, once inseparable, were now worlds apart. {Deborah}, the trusted confidante, had betrayed {Nikolai}'s trust, revealing his secrets to their rivals. The city's hustle and bustle mirrored the chaos within {Nikolai}'s heart, as he grappled with the bitter reality of love turned treachery.
        \end{itemize}



    \item \textbf{Query:}  Alejandro quickly ran to the store to buy a cold drink. He was eager to have a glass of cold drink.
        \begin{itemize}
            \item \textbf{Positive:} Quickly, Hiroki dashed to the local market to procure some cold drinks. He was yearning for a chilled glass of cold drink.
            \item \textbf{Negative:} Alejandro has stopped buying cold drinks from market. He only drinks cold drinks made at home.
        \end{itemize}


    \item \textbf{Query:}  Mayatoshi and Alex had a deep, passionate love for each other. Their bond was unbreakable, a love that transcended all obstacles. They shared dreams, hopes, and aspirations, and their love was the foundation of their happiness.
        \begin{itemize}
            \item \textbf{Positive:} Priyanka and Yuan were deeply in love. Their affection for each other was profound and unwavering. They shared a strong connection, a love that was the source of their joy and contentment.
            \item \textbf{Negative:} Despite their intense hatred for each other, Mayatoshi and Alex were bound by a strange, twisted connection. Their animosity fueled a toxic relationship, a constant battle of wills. Their lives were intertwined, a dark, destructive dance of love and hate.
        \end{itemize}


    \item \textbf{Query:}  Amazon and Apple are two American corporations. Amazon's main business is online shopping and Apple is a phone maker giant
        \begin{itemize}
            \item \textbf{Positive:} Alibaba and Xiaomi are two Chinese corporations. Alibaba's main business is online shopping and Xiaomi is a producer of phones
            \item \textbf{Negative:} Amazon is a river in South America. Apples are not grown in the Amazon basin.
        \end{itemize}


    \item \textbf{Query:}  Ganga and Yamuna are two mighty rivers. They are lifelines for millions of people in the region.
        \begin{itemize}
            \item \textbf{Positive:} Yangtze is a mighty river. It is a long river and is the lifeline for millions of people in the region.
            \item \textbf{Negative:} Ganga and Yamuna are two sisters. They had their schooling in the region and schooling provided a lifeline for them.
        \end{itemize}


    \item \textbf{Query:}  Alice and Bob often helped each other financially. Recently, Alice lent Bob a significant sum of money. Bob promised to return it soon.
        \begin{itemize}
            \item \textbf{Positive:} Yuri and Haruto frequently helped each other out, including with money. Lately, Yuri had loaned Haruto a substantial amount of money, which Haruto assured her he’d repay promptly.
            \item \textbf{Negative:} Alice and Bob had a disagreement about money. Alice believed Bob owed her money, but Bob denied it.
        \end{itemize}

    \item \textbf{Query:}  John, a renowned lawyer, is defending his client, Mike, who is accused of a serious crime. John is determined to prove Mike's innocence and secure his acquittal.
        \begin{itemize}
            \item \textbf{Positive:} Armaan, a man falsely accused of a heinous crime, is relying on his skilled lawyer, Udit, to exonerate him. Udit is committed to presenting a strong defense and clearing Armaan's name.
            \item \textbf{Negative:} John, a cunning lawyer, is manipulating the legal system to frame Mike for a crime he did not commit. John's goal is to secure a conviction and advance his own career, regardless of the truth.
        \end{itemize}



    \item \textbf{Query:}  Dr. Alexander, a seasoned physician, meticulously analyzed patient Sarah’s intricate heart condition. He prescribed a tailored regimen of  medications and rigorous lifestyle modifications to significantly improve her cardiac health.
        \begin{itemize}
            \item \textbf{Positive:} The esteemed doctor, Dr. Yerusha, conducted a thorough assessment of patient Reyan’s complex symptoms of heart. She formulated a precise treatment plan, incorporating  medications and day to day lifestyle changes, to alleviate Reyan's debilitating heart condition.
            \item \textbf{Negative:} Dr. Alexander, a renowned doctor and surgeon, executed a high-risk heart surgical procedure on patient Sarah. After the complex operation Sarah did not recover.
        \end{itemize}



    \item \textbf{Query:}  Mr. Smith, a dedicated teacher, guided his students, including the bright young minds of Miller and Pristina, towards academic excellence.
        \begin{itemize}
            \item \textbf{Positive:} Mr. Yang, a committed educator, mentored his students, including the talented Shruti and Ren, to achieve academic success.
            \item \textbf{Negative:} Mr. Smith , a rigid and punitive teacher, often unfairly targeted mischievous students like Miller and Pristina.
        \end{itemize}


    \item \textbf{Query:}  Martinez gently examined the injured bird. He gave it food.
        \begin{itemize}
            \item \textbf{Positive:} Yohan tenderly inspected the wounded bird and gave it a meal to eat.
            \item \textbf{Negative:} The skilled hunter Martinez tracked the injured bird. He captured it for food.
        \end{itemize}



\end{enumerate}

% \clearpage


% \begin{table*}%#[ht]
% % \centering
% \begin{tabular}{|p{5cm}|p{5cm}|c|}
% \hline
% Query Text  & Target Text (Positive/Negative) & Label Score \\
% \hline \hline
% \multirow{2}{5cm}{\textbf{Nikolai} and \textbf{Deborah} met on a rainy Tuesday in \textbf{New York}. The city’s hustle and bustle couldn’t dim the spark between them. \textbf{Deborah}, with her radiant smile and infectious laughter, had captured \textbf{Nikolai}'s heart from the moment he saw her. \textbf{Nikolai}, a charming and witty gentleman, returned her affection with equal fervor.} & \textbf{Kashvi} and \textbf{Oluwafemi} met on a rainy Tuesday in \textbf{Northampton}. The city’s bustling streets couldn’t dim the spark between them. \textbf{Kashvi}, with her radiant smile and infectious laughter, had captured \textbf{Oluwafemi}’s heart from the moment he saw her. \textbf{Oluwafemi}, a charming and witty gentleman, returned her affection with equal fervor.& 1 \\
% \cline{2-3}
%  & \textbf{Nikolai} and \textbf{Deborah} staying in \textbf{New Jersey}, once inseparable, were now worlds apart. \textbf{Deborah}, the trusted confidante, had betrayed \textbf{Nikolai}'s trust, revealing his secrets to their rivals. The city's hustle and bustle mirrored the chaos within \textbf{Nikolai}'s heart, as he grappled with the bitter reality of love turned treachery. & 0 \\
% \hline
% \multirow{2}{5cm}{Story B} & Story Text Positive & 1 \\
% \cline{2-3}
%  & Story Text Negative & 0 \\
% \hline \hline
% \end{tabular} 
% \caption{Triplets generated for Semantic Similarity Task\label{tab:sts_generated} in Sec~\ref{sec:exp_sts_binary}.\textcolor{red}{fix overflow issue}}
% \end{table*}





\section{Example of Semantic Similarity post-anonymization}
In Table~\ref{tab:sim_change_open_ai}, we show impact of anonymization on STS tasks on embeddings crated by Open AI’s $text-embedding-3-small$ model. We observe that in all cases performance after anonymization is superior. Specifically, post anonymization,  we obtain relatively higher score for positive samples and lower for negative samples.
 \begin{table*}[h!]
 % \small
    \centering
    \scalebox{0.9}{
    \begin{tabular}{|c|p{5cm}|p{7cm}|p{1cm}|p{1cm}|}
     & Query & Pos/Neg & Sim score & Label \\
    \hline
    \multirow{2}{*}{Original} & \multirow{2}{5cm}{Alejandro quickly ran to the store to buy a cold drink. He was eager to have a glass of cold drink.} & \textcolor{blue}{\textbf{POS:} Quickly, Hiroki dashed to the local market to procure some cold drinks. He was yearning for a chilled glass of cold drink.} & 0.66 & 1 \\
   
    & & \textcolor{red}{\textbf{NEG:} Alejandro has stopped buying cold drinks from market. He only drinks cold drinks made at home.} & 0.72 & 0 \\  \cline{3-5}
    % \hline
    \multirow{2}{*}{Anonymized} & \multirow{2}{5cm}{\textcolor{black}{quickly ran to the store to buy a cold drink. He was eager to have a glass of cold drink.}} & \textcolor{blue}{\textbf{POS:} Quickly,  dashed to the local market to procure some cold drinks. He was yearning for a chilled glass of cold drink.} & 0.83 & 1 \\
    & & \textcolor{red}{\textbf{NEG:} has stopped buying cold drinks from market. He only drinks cold drinks made at home.} & 0.57 & 0 \\
    \end{tabular}}
    

    \centering
    \scalebox{0.9}{
    \begin{tabular}{|c|p{5cm}|p{7cm}|p{1cm}|p{1cm}|}
    % & Query & Pos/Neg & Sim score & Label \\ \\
    \hline
    \multirow{2}{*}{Original} & \multirow{2}{5cm}{Ganga and Yamuna are two mighty rivers. They are lifelines for millions of people in the region.} & \textcolor{blue}{\textbf{POS:} Yangtze is a mighty river. It is a long river and is the lifeline for millions of people in the region.} & 0.63 & 1 \\
    
    & & \textcolor{red}{\textbf{NEG:} Ganga and Yamuna are two sisters. They had their schooling in the region and schooling provided a lifeline for them.} & 0.73 & 0 \\ \cline{3-5}
    % \hline
    \multirow{2}{*}{Anonymized} & \multirow{2}{5cm}{and are two mighty rivers. They are lifelines for millions of people in the region.} & \textcolor{blue}{\textbf{POS:} is a mighty river. It is a long river and is the lifeline for millions of people in the region.} & 0.76 & 1 \\
    & & \textcolor{red}{\textbf{NEG:} and are two sisters. They had their schooling in the region and schooling provided a lifeline for them.} & 0.46 & 0 \\
    \hline
    \end{tabular}}
    \caption{Example demonstrating impact of anonymization on semantic similarity using embeddings created by Open AI's \textit{text-embedding-3-small} model. The text in color \textcolor{blue}{blue} and \textcolor{red}{red} refer to the positive and negative paragraphs respectively.}
    \label{tab:sim_change_open_ai}
    \end{table*}


\section{Impact of Anonymization Strategy: Removal versus Replacement}
\label{sec:anon_vs_replacement}
% In this section, we study the impact of performing anonymization vs. replacements. In Table~\ref{tab:anon_vs_replacement}, we observe that \textit{anonymization} is slightly better than \textit{replacement}. Further, we would like to highlight that embeddings obtained after replacements are sensitive to the \textit{kind of replacements}. For example replacing character name with "CHAR\_A", "CHARACTER\_B", "CHARACTER\_1", location names with "LOC\_1", "LOC\_B" etc. To avoid sensitivity to such variations, we choose to perform removal and results indicate that removal achieves high quality results without worrying about finding the perfect replacement.

\begin{table*}[h!]
% \small
\centering
\begin{tabular}{|p{5cm}|p{10cm}}
\toprule
   Replace person names, organizations and locations  &  Given below text, please convert all Person names(which are Proper Nouns) to a UNIQUE ID such as CHAR\_A, CHAR\_B, CHAR\_C etc..  Keep it unique and for each UNIQUE Person name(which is a Proper Noun) use a UNIQUE ID. DO NOT KEEP THE ORIGINAL Person Names(which are Proper Nouns) in the generated paragraph text. Next, Replace all occurences  City/Country/Village/Town/River/Continent etc. names which are PROPER NOUNS to a UNIQUE ID such as LOC\_A, LOC\_B, LOC\_C, LOC\_D etc.. Next, Replace all occurences of company/organization names which are PROPER NOUNS to a UNIQUE ID such as ORG\_A, ORG\_B, ORG\_C, ORG\_D etc..   Do not replace monument/landmark names like Eiffel tower etc. Output contains the modified text only....  The text is provided below :::: \\
   \hline
\end{tabular}
\caption{Prompt for Anonymization using replacement strategy described in Sec.~\ref{sec:anon_vs_replacement} \label{tab:replacement_prompt}}
\end{table*}

This section investigates the effectiveness of remove of names vs.  replacement of names in text for anonymization. In the replacement strategy, we replace names with non-identifying placeholder names instead of removing them from text. Example: person names with 'CHAR\_{ID}', location names with 'LOC\_{ID}' etc. Here ID can be replaced with $\{A, B, C \cdots \}$ or $\{1, 2, 3 \cdots \}$ etc. The detailed prompt is present in Table ~\ref{tab:replacement_prompt}. In Table~\ref{tab:anon_vs_replacement} we demonstrate that removal of names marginally outperforms replacement in the STS task. In the context of replacement strategy, one should note that the quality of embeddings derived is sensitive to the specific replacement placeholder terms used. For instance, substituting character names with with different placeholders such as  ``CHAR\_A'' / ``CHARACTER\_B'' / ``CHARACTER\_1'' or location names with ``LOC\_1'' / ``LOC\_B'' can impact the resulting embeddings differently. In order to mitigate this sensitivity and ensure consistent results and also based upon our findings we recommend using the name removal strategy for anonymization to mitigate name bias. 
% indicate that removal achieves high-quality embeddings while eliminating the need to determine optimal replacement terms.



\begin{table*}[t!]
% \small
\centering
\scalebox{0.8}{\begin{tabular}{llll}
\toprule
                                Model &  \makecell{AUC ROC \\ Original} & \makecell{AUC ROC \\ Anonymization(Default)} & \makecell{AUC ROC \\ Anonymization(Replacement)} \\
\midrule

%                     all-mpnet-base-v2 &                               0.19 &                     0.97 ± 0.0 &                      \textbf{0.995 ± 0.003} \\
%                  all-distilroberta-v1 &                               0.35 &                    \textbf{0.985 ± 0.017} &                      0.945 ± 0.013 \\
%                      all-MiniLM-L6-v2 &                               0.09 &                    \textbf{0.99 ± 0.008} &                        0.97 ± 0.008 \\
%                                gemini &                               0.66 &                      \textbf{1.0 ± 0.0} &                          \textbf{1.0 ± 0.0} \\
%            multi-qa-distilbert-cos-v1 &                               0.07 &                    \textbf{0.97 ± 0.008} &                      0.965 ± 0.013 \\
%               paraphrase-MiniLM-L6-v2 &                               0.14 &                  \textbf{0.98 ± 0.0} &                      \textbf{0.985 ± 0.013} \\
%  distiluse-base-multilingual-cased-v1 &                               0.27 &                     \textbf{0.94 ± 0.0 }&                        0.94 ± 0.017 \\
%  distiluse-base-multilingual-cased-v2 &                               0.26 &                  \textbf{0.96 ± 0.0} &                      0.945 ± 0.031 \\
% paraphrase-multilingual-MiniLM-L12-v2 &                               0.21 &                      \textbf{0.99 ± 0.0} &                          \textbf{1.0 ± 0.0 }\\
%             msmarco-distilbert-cos-v5 &                               0.10 &                  \textbf{0.955 ± 0.004} &                        0.88 ± 0.008 \\
%            multi-qa-mpnet-base-cos-v1 &                               0.08 &                      \textbf{1.0 ± 0.0 }&                        0.97 ± 0.017 \\
%                text-embedding-3-small &                               0.12 &                      \textbf{1.0 ± 0.0} &                      0.965 ± 0.013 \\
%                text-embedding-3-large &                               0.18 &                     \textbf{ 1.0 ± 0.0} &                          \textbf{1.0 ± 0.0 }\\
%                         voyage-3-lite &                               0.18 &                      \textbf{1.0 ± 0.0 }&                      0.985 ± 0.013 \\
                    all-mpnet-base-v2 &                   0.19 &       0.98 $\pm$ 0.0071 &                   \textbf{1.0 $\pm$ 0.0} \\
                 all-distilroberta-v1 &                   0.36 &      \textbf{0.975 $\pm$ 0.0106} &              0.945 $\pm$ 0.0106 \\
                     all-MiniLM-L6-v2 &                   0.09 &       \textbf{0.99 $\pm$ 0.0071} &               0.97 $\pm$ 0.0071 \\
                               gemini &                   0.71 &           \textbf{1.0 $\pm$ 0.0} &                   \textbf{1.0 $\pm$ 0.0} \\
           multi-qa-distilbert-cos-v1 &                   0.07 &       \textbf{0.97 $\pm$ 0.0071} &                  0.95 $\pm$ 0.0 \\
              paraphrase-MiniLM-L6-v2 &                   0.14 &          0.98 $\pm$ 0.0 &               \textbf{0.99 $\pm$ 0.0071} \\
 distiluse-base-multilingual-cased-v1 &                   0.27 &          \textbf{0.94 $\pm$ 0.0} &              0.935 $\pm$ 0.0106 \\
 distiluse-base-multilingual-cased-v2 &                   0.26 &          \textbf{0.96 $\pm$ 0.0} &               0.94 $\pm$ 0.0212 \\
paraphrase-multilingual-MiniLM-L12-v2 &                   0.21 &          0.99 $\pm$ 0.0 &                   \textbf{1.0 $\pm$ 0.0} \\
            msmarco-distilbert-cos-v5 &                   0.10 &      \textbf{0.955 $\pm$ 0.0035} &              0.875 $\pm$ 0.0035 \\
           multi-qa-mpnet-base-cos-v1 &                   0.08 &           \textbf{1.0 $\pm$ 0.0} &              0.985 $\pm$ 0.0035 \\
               text-embedding-3-small &                   0.12 &           1.0 $\pm$ 0.0 &               0.97 $\pm$ 0.0071 \\
               text-embedding-3-large &                   0.21 &           \textbf{1.0 $\pm$ 0.0} &                   \textbf{1.0 $\pm$ 0.0} \\
                        voyage-3-lite &                   0.18 &           \textbf{1.0 $\pm$ 0.0} &               0.98 $\pm$ 0.0141 \\
\bottomrule
\end{tabular}}
\caption{Comparison of Removal based vs Replacement based Anonymization on Semantic Similarity task \label{tab:anon_vs_replacement} of Sec.~\ref{sec:exp_sts_binary}.}
\end{table*}


\begin{table}[t!]
\centering
\scalebox{0.8}{
\begin{tabular}{ll}
\toprule
                           Model Name &    \makecell{Euclidean Distance \\ per perturbation
pair}   \\
\midrule
                    all-mpnet-base-v2 &                         0.642 $\pm$ 0.0016 \\
                 all-distilroberta-v1 &                         0.641 $\pm$ 0.0015 \\
                     all-MiniLM-L6-v2 &                         0.766 $\pm$ 0.0017 \\
                               gemini &                          0.46 $\pm$ 0.0007 \\
           multi-qa-distilbert-cos-v1 &                         0.694 $\pm$ 0.0014 \\
              paraphrase-MiniLM-L6-v2 &                         3.398 $\pm$ 0.0153 \\
 distiluse-base-multilingual-cased-v1 &                          0.638 $\pm$ 0.002 \\
 distiluse-base-multilingual-cased-v2 &                          0.63 $\pm$ 0.0021 \\
paraphrase-multilingual-MiniLM-L12-v2 &                         2.726 $\pm$ 0.0108 \\
            msmarco-distilbert-cos-v5 &                         0.742 $\pm$ 0.0016 \\
           multi-qa-mpnet-base-cos-v1 &                         0.679 $\pm$ 0.0016 \\
               text-embedding-3-small &                          0.67 $\pm$ 0.0013 \\
               text-embedding-3-large &                         0.616 $\pm$ 0.0013 \\
                        voyage-3-lite &                          0.647 $\pm$ 0.001 \\
\bottomrule
\end{tabular}}
\caption{\textbf{Bias Measurement on CMU Book dataset with Euclidean distance as distance function between embeddings}. A distance close to $0$ is better.\label{tab:model_biases_cmu_book_euclidean}}
\end{table}

