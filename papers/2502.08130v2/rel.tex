Continual learning for language models faces challenges like overfitting and loss of generalization  \cite{yogatama2019learning,zhang2021revisiting}. Rehearsal-based methods, such as experience replay \cite{rolnick2019experience} and representation consolidation \cite{bhat2022representation}, show promise but often depend on real data, which may be scarce. To address this, model-generated responses are used through techniques like self-training \cite{he2020revisiting,xie2020self} and self-supervised learning \cite{lewis2020bart}. However, their effectiveness in continual learning remains underexplored. Current methods focus on real data rehearsal \cite{scialom2022continual,mok2023large,zhang2023continual}, but these can be resource-intensive. In contrast, S3FT avoids storing past data or training extra generative models, making it more data-efficient and practical for real-world use.
SDFT \cite{yang2024self}, the closest contemporary work to ours, is thoroughly compared in experiments, where we achieve significantly higher accuracy.