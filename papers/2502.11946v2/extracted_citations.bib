@article{2024moshispeechtextfoundationmodel,
  title={Moshi: a speech-text foundation model for real-time dialogue},
  author={D{\'e}fossez, Alexandre and Mazar{\'e}, Laurent and Orsini, Manu and Royer, Am{\'e}lie and P{\'e}rez, Patrick and J{\'e}gou, Herv{\'e} and Grave, Edouard and Zeghidour, Neil},
  journal={arXiv preprint arXiv:2410.00037},
  year={2024}
}

@article{chen2025minmomultimodallargelanguage,
  title={Minmo: A multimodal large language model for seamless voice interaction},
  author={Chen, Qian and Chen, Yafeng and Chen, Yanni and Chen, Mengzhe and Chen, Yingda and Deng, Chong and Du, Zhihao and Gao, Ruize and Gao, Changfeng and Gao, Zhifu and others},
  journal={arXiv preprint arXiv:2501.06282},
  year={2025}
}

@article{chu2024qwen2audiotechnicalreport,
  title={Qwen2-audio technical report},
  author={Chu, Yunfei and Xu, Jin and Yang, Qian and Wei, Haojie and Wei, Xipin and Guo, Zhifang and Leng, Yichong and Lv, Yuanjun and He, Jinzheng and Lin, Junyang and others},
  journal={arXiv preprint arXiv:2407.10759},
  year={2024}
}

@article{das2024speechverselargescalegeneralizableaudio,
  title={Speechverse: A large-scale generalizable audio language model},
  author={Das, Nilaksh and Dingliwal, Saket and Ronanki, Srikanth and Paturi, Rohit and Huang, Zhaocheng and Mathur, Prashant and Yuan, Jie and Bekal, Dhanush and Niu, Xing and Jayanthi, Sai Muralidhar and others},
  journal={arXiv preprint arXiv:2405.08295},
  year={2024}
}

@article{du2024cosyvoice2scalablestreaming,
  title={Cosyvoice 2: Scalable streaming speech synthesis with large language models},
  author={Du, Zhihao and Wang, Yuxuan and Chen, Qian and Shi, Xian and Lv, Xiang and Zhao, Tianyu and Gao, Zhifu and Yang, Yexin and Gao, Changfeng and Wang, Hui and others},
  journal={arXiv preprint arXiv:2412.10117},
  year={2024}
}

@article{fang2024llamaomniseamlessspeechinteraction,
  title={Llama-omni: Seamless speech interaction with large language models},
  author={Fang, Qingkai and Guo, Shoutao and Zhou, Yan and Ma, Zhengrui and Zhang, Shaolei and Feng, Yang},
  journal={arXiv preprint arXiv:2409.06666},
  year={2024}
}

@article{gao2025lucylinguisticunderstandingcontrol,
  title={LUCY: Linguistic Understanding and Control Yielding Early Stage of Her},
  author={Gao, Heting and Shao, Hang and Wang, Xiong and Qiu, Chaofan and Shen, Yunhang and Cai, Siqi and Shi, Yuchen and Xu, Zihan and Long, Zuwei and Zhang, Yike and others},
  journal={arXiv preprint arXiv:2501.16327},
  year={2025}
}

@inproceedings{huang2023audiogptunderstandinggeneratingspeech,
  title={Audiogpt: Understanding and generating speech, music, sound, and talking head},
  author={Huang, Rongjie and Li, Mingze and Yang, Dongchao and Shi, Jiatong and Chang, Xuankai and Ye, Zhenhui and Wu, Yuning and Hong, Zhiqing and Huang, Jiawei and Liu, Jinglin and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={21},
  pages={23802--23804},
  year={2024}
}

@article{kong2020pannslargescalepretrainedaudio,
  title={Panns: Large-scale pretrained audio neural networks for audio pattern recognition},
  author={Kong, Qiuqiang and Cao, Yin and Iqbal, Turab and Wang, Yuxuan and Wang, Wenwu and Plumbley, Mark D},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={28},
  pages={2880--2894},
  year={2020},
  publisher={IEEE}
}

@article{nguyen2024spiritlminterleavedspoken,
  title={Spirit-lm: Interleaved spoken and written language model},
  author={Nguyen, Tu Anh and Muller, Benjamin and Yu, Bokai and Costa-Jussa, Marta R and Elbayad, Maha and Popuri, Sravya and Duquenne, Paul-Ambroise and Algayres, Robin and Mavlyutov, Ruslan and Gat, Itai and others},
  journal={arXiv preprint arXiv:2402.05755},
  year={2024}
}

@article{wang2024freezeomnismartlowlatency,
  title={Freeze-omni: A smart and low latency speech-to-speech dialogue model with frozen llm},
  author={Wang, Xiong and Li, Yangze and Fu, Chaoyou and Shen, Yunhang and Xie, Lei and Li, Ke and Sun, Xing and Ma, Long},
  journal={arXiv preprint arXiv:2411.00774},
  year={2024}
}

@article{xie2024miniomnilanguagemodelshear,
  title={Mini-omni: Language models can hear, talk while thinking in streaming},
  author={Xie, Zhifei and Wu, Changqiao},
  journal={arXiv preprint arXiv:2408.16725},
  year={2024}
}

@article{zeng2024glm4voiceintelligenthumanlikeendtoend,
  title={Glm-4-voice: Towards intelligent and human-like end-to-end spoken chatbot},
  author={Zeng, Aohan and Du, Zhengxiao and Liu, Mingdao and Wang, Kedong and Jiang, Shengmin and Zhao, Lei and Dong, Yuxiao and Tang, Jie},
  journal={arXiv preprint arXiv:2412.02612},
  year={2024}
}

