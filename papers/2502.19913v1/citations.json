[
  {
    "index": 0,
    "papers": [
      {
        "key": "diloco",
        "author": "Arthur Douillard and\nQixuang Feng and\nAndrei A. Rusu and\nRachita Chhaparia and\nYani Donchev and\nAdhiguna Kuncoro and\nMarc'Aurelio Ranzato and\nArthur Szlam and\nJiajun Shen",
        "title": "DiLoCo: Distributed Low-Communication Training of Language Models"
      },
      {
        "key": "demo",
        "author": "Peng, Bowen and Quesnelle, Jeffrey and Kingma, Diederik P",
        "title": "Decoupled Momentum Optimization"
      },
      {
        "key": "opendiloco",
        "author": "Sami Jaghouar and\nJack Min Ong and\nJohannes Hagemann",
        "title": "OpenDiLoCo: An Open-Source Framework for Globally Distributed Low-Communication\nTraining"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "dtfm",
        "author": "Binhang Yuan and\nYongjun He and\nJared Davis and\nTianyi Zhang and\nTri Dao and\nBeidi Chen and\nPercy Liang and\nChristopher R{\\'{e}} and\nCe Zhang",
        "title": "Decentralized Training of Foundation Models in Heterogeneous Environments"
      },
      {
        "key": "swarm",
        "author": "Max Ryabinin and\nTim Dettmers and\nMichael Diskin and\nAlexander Borzunov",
        "title": "{SWARM} Parallelism: Training Large Models Can Be Surprisingly Communication-Efficient"
      },
      {
        "key": "hetpipe",
        "author": "Jay H. Park and\nGyeongchan Yun and\nChang M. Yi and\nNguyen T. Nguyen and\nSeungmin Lee and\nJaesik Choi and\nSam H. Noh and\nYoung{-}ri Choi",
        "title": "HetPipe: Enabling Large {DNN} Training on (Whimpy) Heterogeneous {GPU}\nClusters through Integration of Pipelined Model Parallelism and Data\nParallelism"
      },
      {
        "key": "metis",
        "author": "Taegeon Um and\nByungsoo Oh and\nMinyoung Kang and\nWoo{-}Yeon Lee and\nGoeun Kim and\nDongseob Kim and\nYoungtaek Kim and\nMohd Muzzammil and\nMyeongjae Jeon",
        "title": "Metis: Fast Automatic Distributed Training on Heterogeneous GPUs"
      },
      {
        "key": "flashflex",
        "author": "Ran Yan and\nYouhe Jiang and\nWangcheng Tao and\nXiaonan Nie and\nBin Cui and\nBinhang Yuan",
        "title": "FlashFlex: Accommodating Large Language Model Training over Heterogeneous\nEnvironment"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "gpipe",
        "author": "Yanping Huang and\nYoulong Cheng and\nAnkur Bapna and\nOrhan Firat and\nDehao Chen and\nMia Xu Chen and\nHyoukJoong Lee and\nJiquan Ngiam and\nQuoc V. Le and\nYonghui Wu and\nZhifeng Chen",
        "title": "GPipe: Efficient Training of Giant Neural Networks using Pipeline\nParallelism"
      },
      {
        "key": "zb",
        "author": "Penghui Qi and\nXinyi Wan and\nGuangxing Huang and\nMin Lin",
        "title": "Zero Bubble (Almost) Pipeline Parallelism"
      },
      {
        "key": "pipedream",
        "author": "Aaron Harlap and\nDeepak Narayanan and\nAmar Phanishayee and\nVivek Seshadri and\nNikhil R. Devanur and\nGregory R. Ganger and\nPhillip B. Gibbons",
        "title": "PipeDream: Fast and Efficient Pipeline Parallel {DNN} Training"
      },
      {
        "key": "hetpipe",
        "author": "Jay H. Park and\nGyeongchan Yun and\nChang M. Yi and\nNguyen T. Nguyen and\nSeungmin Lee and\nJaesik Choi and\nSam H. Noh and\nYoung{-}ri Choi",
        "title": "HetPipe: Enabling Large {DNN} Training on (Whimpy) Heterogeneous {GPU}\nClusters through Integration of Pipelined Model Parallelism and Data\nParallelism"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "skipconnresnet",
        "author": "Andreas Veit and\nMichael J. Wilber and\nSerge J. Belongie",
        "title": "Residual Networks Behave Like Ensembles of Relatively Shallow Networks"
      },
      {
        "key": "vitrob",
        "author": "Srinadh Bhojanapalli and\nAyan Chakrabarti and\nDaniel Glasner and\nDaliang Li and\nThomas Unterthiner and\nAndreas Veit",
        "title": "Understanding Robustness of Transformers for Image Classification"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "stochasticdepth",
        "author": "Gao Huang and\nYu Sun and\nZhuang Liu and\nDaniel Sedra and\nKilian Q. Weinberger",
        "title": "Deep Networks with Stochastic Depth"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "LayerDrop",
        "author": "Angela Fan and\nEdouard Grave and\nArmand Joulin",
        "title": "Reducing Transformer Depth on Demand with Structured Dropout"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "LayerSkip",
        "author": "Mostafa Elhoushi and\nAkshat Shrivastava and\nDiana Liskovich and\nBasil Hosmer and\nBram Wasti and\nLiangzhen Lai and\nAnas Mahmoud and\nBilge Acun and\nSaurabh Agarwal and\nAhmed Roman and\nAhmed A Aly and\nBeidi Chen and\nCarole{-}Jean Wu",
        "title": "LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding"
      }
    ]
  }
]