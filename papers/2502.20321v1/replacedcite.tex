\section{Related Work}
\label{sec:related_work}

\textbf{Image Tokenization for Generation.}
In the domain of visual generation, image tokenization plays an important role in encoding raw pixels into compact latent features for generative modeling ____. Particularly, among a variety of tokenizers, the vector-quantized tokenizer ____ is favored for its discrete latent space and compatibility with autoregressive or masked generative models ____. The pioneering work VQVAE ____ initially introduced the concept of discretizing continuous tokens by mapping them to the nearest neighbors in a learnable codebook. Built on this, VQGAN ____ incorporated perceptual loss ____ and discriminator loss ____ to significantly improve the reconstruction quality. Subsequently, ViT-VQGAN ____ advanced the framework with the transformer architecture. In recent literature, considerable efforts have been devoted to developing better quantization methods such as residual quantization ____ and lookup-free quantization ____, which also constitute a focal point of this paper.

% \vspace{-2mm}
\textbf{Image Tokenization for Understanding.}
The unprecedented success of large language models (LLMs) ____ has catalyzed the development of multimodal large language models (MLLMs) ____. As a critical component of MLLMs, the selection of an effective vision tokenizer has been the subject of extensive study ____. A common choice of the vision tokenizer is the pretrained CLIP model ____, which undergoes alignment with language during its pretraining phase. While self-supervised learning models, such as DINOv2 ____, are shown to be advantageous at region-level tasks ____. Cambrian-1 ____ further demonstrates that MLLMs can benefit from hybrid representations from a mixture of vision encoders. Nonetheless, these tokenizers predominantly encode images into continuous tokens, presenting a challenge for uniformly modeling both vision and text tokens. To address this disparity, several works have explored discretizing CLIP tokens ____ or employing VQVAE encoders ____. However, these approaches have been observed to substantially impair understanding performance of MLLM.

% \vspace{-2mm}
\textbf{Unified Vision-Language Models.}
The rise of MLLMs is not limited to the realm of visual understanding. Recent advancements have witnessed an increasing focus on unifying visual generation and understanding within one MLLM ____. Specifically, a line of works employs continuous visual tokenizers for image encoding, and leverages pretrained diffusion models for image synthesis ____. This approach inevitably disconnects visual token sampling from the MLLM. In contrast, another stream of research adopts VQVAE models to encode images into discrete tokens ____. These tokens are subsequently modeled using the same next token prediction loss that is applied to text tokens, facilitating a unified approach to multimodal learning. However, as reconstruction-oriented VQVAE does not naturally align with the LLM token space, these models typically suffer from degraded visual comprehension capabilities. Our research aligns with the second approach, with a particular focus on the tokenizer design that is suitable for both generation and understanding tasks.