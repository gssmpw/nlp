\section{Related Work}
\label{sec:related_work}

In this section, we review the recent progress in analyzing systematic weaknesses using slice discovery methods (SDMs)~\citep{eyuboglu2022domino} for structured and unstructured data and highlight their connection to interpretability and feature attribution methods.  

For structured data, methods such as SliceFinder~\citep{chung2019slice} and SliceLine~\citep{sagadeeva2021sliceline} leverage the rich metadata available in the form of features to slice the data and exhaustively search for top-k low-performing slices. The differences between these two approaches lie in the scoring of errors, the pruning strategy, and how they handle slice sizes. 
Although these two approaches were explicitly developed to identify systematic weaknesses, subgroup-discovery techniques~\citep{atzmueller2015subgroup}, a subset of data mining, have a similar problem formulation and could also potentially be used for slice discovery of structured data. 

For unstructured data such as images, where metadata is not directly available, SOTA approaches have taken two lines of research. In the first line of prior work, for a given test dataset, DNN embeddings are used as proxies for coherency. Weak-performing slices of the data are obtained by clustering these embeddings along with model errors. 
Here, approaches such as Spotlight~\citep{d2022spotlight} perform clustering on the embeddings of the final layers of the \textbf{DuT} itself. In contrast, recent approaches leverage the joint embedding space of foundational models such as CLIP~\citep{radford2021learning} and apply mixture models like in DOMINO~\citep{eyuboglu2022domino} or SVMs like in SVM-FD~\citep{jain2023distilling} to identify coherent clusters. In Spotlight, an additional step involving humans is required to inspect and understand what uniquely constitutes a weak slice. 
DOMINO and SVM-FD automate the slice description process to reduce human effort and bias using an additional DNN. 
In all these approaches, as coherence is only loosely enforced based on DNN embeddings, it is not always clear what specific human-understandable concept uniquely constitutes a slice. Without this knowledge, it would be unclear to the ML developers what new data samples would need to be collected to retrain the model and fix the systematic weakness. 
To mitigate this problem, some approaches~\citep{gao2023adaptive, slyman2023vlslice} propose iterative human-in-the-loop testing to ensure that the identified slices are human-understandable. 
 
In the second line of prior work, inspired by counterfactuals and leveraging CLIP, several approaches~\citep{wiles2022discovering, Metzen_2023_ICCV} propose synthetically generating new (counterfactual) images that would lead to erroneous predictions by controlling the content and data shift in the image.
Among these, PromptAttack~\citep{Metzen_2023_ICCV} also proposes to identify weaknesses that are aligned with the ODDs. However, while PromptAttack generates new samples using image-generation DNNs, which could potentially introduce biases due to domain shift, our approach is more closely aligned with earlier methods that evaluate a DNN on a given test dataset.
In this direction, HiBug~\citep{NEURIPS2023_0f53ecc0} utilizes a GPT-based model to assign attributes to a given dataset. Building on this and appearing concurrently with our work, DebugAgent~\citep{chen2025debugagent} extends HiBug with a search algorithm to identify weak slices. While we also apply attributes to the data to perform a subsequent weak slice search, we, instead, opt for the less compute-intensive CLIP~\cite{radford2021learning} model to generate attributes. Additionally, we develop a Bayesian framework to compensate for the label noise that occurs from the attribution.



In contrast to SDMs, local interpretability and feature attribution methods~\citep{ribeiro2016should, lundberg2017unified}, while linking achieved understandability to actionability~\citep{guidotti2022stable}, identify local explanations and not the global systematic weaknesses. In addition, the feature attribution methods themselves might not always be robust or consistent~\citep{krishna2022disagreement}. 

 