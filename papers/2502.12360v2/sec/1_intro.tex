\section{Introduction}
\label{sec:intro}







With recent advances in machine learning (ML), there has been a significant improvement in the modeling of unstructured data, such as images. 
However, for safety-critical applications, ML models need to be developed with a focus on trustworthiness by investigating and correcting potential failure modes.
To that end, systematic errors of DNNs need to be studied and rectified. Hidden stratification~\citep{oakden2020hidden} and fairness-related bias~\citep{buolamwini2018gender, wang2020towards, li2023dark} due to spurious correlations~\citep{xiao2020noise, geirhos2020shortcut,mahmood2021detecting} and underrepresented subpopulations~\citep{santurkar2020breeds,sagawa2019distributionally} are some examples of potential failure modes where the error or weakness is systematic in nature. The existence of these modes implies that there are slices~\footnote{In the literature, slices are often also called subgroups or subsets of data. All three terms are used interchangeably in relation to systematic weakness analysis.} of data where the performance of the DNN-under-test (\textbf{DuT}) is worse than the average performance on the entire test dataset. Although identifying slices with weak performance would be trivial by simply grouping samples on which models have high error, identifying slices that are both semantically coherent and have high error is challenging. This is due to the lack of semantic metadata that describes the slices for many data domains (e.g., images, text). Despite this challenge, identifying such slices provides a human-understandable global explanation of the model behavior. Moreover, semantically coherent weak slices offer actionable insights for debugging and auditing models. 

% \begin{figure}[!ht]
%   \centering
%   \includegraphics[width=0.3\textwidth]{images/e4_s0.pdf}
%   % \input{images/pipeline}
%   \caption{A weak slice identified by our approach for a DNN-under-test (SETR~\cite{zheng2021rethinking}) evaluated on the Cityscapes~\cite{cordts2016cityscapes} dataset. The slices are aligned to human-understandable semantic concepts that are defined in ODDs by safety experts from the domain.}
%   \label{fig:intro_img}
% \end{figure}

From a safety and certification perspective, upcoming standards (e.g., ISO/PAS 8800~\citep{ISO8800:2024}), and works with a focus on AI in automotive~\citep{Koopman2019HowMO, burton2022safety}, aerospace~\citep{EASA_concept_paper} and railway~\citep{zeller2023safety} domains have highlighted the importance of data completeness and quality using, in most cases, Operational Design Domains (ODDs). 
In automotive,~\citet{herrmann2022using} have proposed ontologies for different traffic participants that can be used to build ODDs for automated driving.  
The goal of using such ODDs is to describe the scope of AI applications in terms of human-understandable, safety-relevant dimensions where comprehensible safety argumentations can be built w.r.t.\ robustness, explainability, and interpretability.  
To facilitate building such safety augmentations, testing approaches for ML developers and safety experts that evaluate DNN performance and identify systematic weaknesses are essential.



Although in recent years, several works~\citep{chung2019slice, sagadeeva2021sliceline, d2022spotlight, eyuboglu2022domino, Metzen_2023_ICCV, plumb2023towards, jain2023distilling, gao2023adaptive, NEURIPS2023_0f53ecc0} have proposed methods for analyzing systematic weaknesses, there is a lack of focus on identifying weaknesses of models evaluated on real-world datasets, where the weaknesses align with human-understandable semantic concepts defined, for example, by safety experts in ODDs.
We argue that it is more beneficial from a safety perspective if the approaches to identify systematic weaknesses are ODD-compliant for two main reasons: (i) the slices are \textbf{useful} as the identified vulnerabilities are aligned with human-understandable safety-relevant dimensions, and (ii) the slices are \textbf{actionable} as ML developers can gather more data to retrain or reweight existing samples to improve performance along the safety-relevant dimensions. We address the challenge of analyzing unstructured image data by designing an algorithm that leverages recent advances in foundational models and systematic weakness analysis methods for structured data. Our contributions can be summarized as follows:
\begin{itemize}
    \item We introduce an algorithm that takes in an image dataset, ODD description and performance values of a \textbf{DuT} as inputs and outputs systematic weaknesses of the \textbf{DuT} (see~\cref{sec:method}).    
    \item Concretely, as part of the metadata generation module, we make use of CLIP~\citep{radford2021learning} to leverage its rich joint image, text embedding space. As part of the slice discovery module, we propose using SliceLine~\citep{sagadeeva2021sliceline} with modifications to identify weak slices that align with the ODD (see~\cref{sec:method}).
    % \item We evaluate empirically to which extent noise in the metadata generation with CLIP influences the slice discovery process and show that the CLIP performance is sufficient to detect the relevant semantically coherent weak slices (see~\cref{sec:results:celebA,sec:results:ad_results}). \sg{this needs to be adapted}
    \item In addition, we address the noisy nature of metadata generation and propose a way to recover relevant weak slices even if CLIP labeling is suboptimal. We empirically evaluate the behavior of our algorithm at various levels of label quality using synthetic data (see~\cref{sec:synthetic_data}). 
    \item Furthermore, we evaluate multiple pre-trained and publicly available DNNs-under-test using our algorithm on real-world datasets and provide insights into their systematic weaknesses (see~\cref{sec:results}). 
\end{itemize}






%-------------------------------------------------------------------------
