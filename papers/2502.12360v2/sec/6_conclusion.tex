\section{Conclusion}
\label{sec:conclusion}


In this work, we present an algorithm for our Systematic Weakness Detector (SWD) to analyze the systematic weaknesses of DNNs that perform classification, object detection, and semantic segmentation tasks on image data. In the first step, we overcome the problem of missing metadata by generating metadata with a foundation model. Subsequently, in the second step, we perform slice discovery on the structured metadata, which comprises of DNN-under-test's per-object performance and previously acquired per-object metadata. Using our algorithm, we transform the slice discovery of unstructured image data into an (approximate) slice discovery problem on structured data.
In addition, we study the impact of noisy labeling in a Bayesian framework and operationalize it by integrating error correction and slice validity based on quality indicators into our approach.
In the ablation experiments, we show that our SWD detects the same weak slices as would be identified in hypothetical cases where we have access to perfect metadata.
The primary advantage of our algorithm, in comparison to SOTA methods, is that the identified weak slices are aligned with human-understandable semantic concepts that can be derived from a description of the ODD.
As upcoming safety and trustworthy AI specifications require evidences for building safety argumentations w.r.t.\ such ODDs, the results from our approach can directly contribute.
% and requirements\maa{to what do the requirements relate, ODD or argumentation?}, the results from our approach can contribute as evidences to building safety argumentations. 
In addition, the identification of human-understandable weak slices enables ML developers to take mitigation actions, such as a targeted acquisition or generation of data, addressing the weaker slices and, thus, facilitating effective re-training with a limited acquisition budget.
Furthermore, we show that our approach has clear advantages over several metadata-free SOTA methods by giving more actionable results, and we demonstrate the applicability of our approach by identifying systematic weaknesses in multiple AD datasets.
For this, we also provide a quantitative evaluation of the quality of the generated metadata. 

Our algorithm does have certain limitations. Primarily, a minimum metadata labeling quality is required for the discovered slices to be meaningful. In addition to our proposed metadata quality estimation, future works could therefore focus on improving metadata quality by human correction of a subset of generated metadata, fine-tuning~\citep{eyuboglu2022domino} of CLIP, metadata acquisition from other sources (e.g., depth sensor).
Secondly, all approaches based on ODD definitions, like ours or PromptAttack~\citep{Metzen_2023_ICCV}, would suffer from the lack of completeness of the semantic concepts in ODD. 
A potential solution could be in the direction of~\citet{gannamaneni2024assessing} by performing a root-cause analysis of found weaknesses.
Such approaches could address potential issues between correlation and causation for found small slices.
In addition, SDMs based on the evaluation of the test dataset can suffer from insufficient coverage of the application domain by the test dataset.
Both aspects become more relevant with the increasing broadness of the assumed ODD scope. For instance, if one intends to investigate false positives in object detection, the description would effectively contain most other objects (and parts thereof) that could appear in the scene. 
While we, therefore, limit our scope to the more narrowly defined false negatives, our approach still provides valuable insights into, often more critical, missed detections in terms of human-understandable and, thereby, actionable weak slices. 
We believe that such results can contribute to the development of trustworthy AI models and their safety.

