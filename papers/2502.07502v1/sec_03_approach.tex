\section{Enabling Value-Complemented Human Monitoring}
\label{sec:approach}
% value lead that confirms the values and approves them through signatures from stakeholders
In our proposed approach, the goal is to actively incorporate human values as first-class citizens in the early stages of the requirements engineering process, guiding subsequent elicitation of requirements, and ultimately system design. 

\bullitem{Framework Overview:}
We achieve this by first identifying relevant values and corresponding stakeholders, followed by mapping them to relevant monitoring properties (i.e., what data we want to collect at runtime) within the context of a specific \emph{Monitoring Use Case (\muc)}.
\citefig{value-based-framework} provides a high-level overview of our framework, guiding the value complemented monitoring RE process.
% Commonly in requirements engineering, we directly derive both functional and non-functional requirements based on a system usecase. However, this results in human-values being ignored in the process.
In a first step \Circled{1},  we identify the stakeholders \textit{who} will engage with the feature described in the System Use Case, and would be impacted by monitoring functionality, and create respective personas~\cite{schneidewind2012How}. 
Based on these, we then derive a specific \emph{Monitoring Use Case} \Circled{2}, a  subset of a traditional system use case~\cite{yue2013facilitating}, specifically focusing on monitoring-related elements, components, and stakeholders. %These parts are then further augmented with information concerning the potentially relevant information (properties) that should be collected at runtime.


\begin{figure*}[t!]
    \centering
    \includegraphics[width=.95\textwidth]{figures/value-complemented-framework.drawio.pdf}
    \vspace{-10pt}
    \caption{Conceptual value-complemented Framework.}
    \label{fig:value-based-framework}
\end{figure*}


The \muc is then annotated with information regarding \textit{which} properties should be monitored and from \textit{which} component or human actor the data is collected. 
Following Whittle~\etal's~\cite{whittle2021Case} work on human values,  we then identify relevant values \Circled{3} for each of the identified personas and thus their respective stakeholders.
We hereby leverage the taxonomy of Schwartz~\cite{schwartz1992Universals} that categorizes values into Self-Enhancement, Conservation, Openness to Change, and Self-Transcendence. Depending on the stakeholders and monitoring properties involved in a \muc, the defined values can vary significantly~\cite{Spiekermann2023Value}. %p100
These identified values add the dimension of \textit{why} stakeholders want to see a feature implemented, and more crucially, why it should be implemented in a certain way (e.g., by obfuscating user information).
Based on these persona-value pairs, we then define \textit{value tactics}~\cite{wohlrab2024Supporting} in step \Circled{4}, which serve as a link between human-values and functional and non-functional requirements addressing specific quality attributes or suggesting mechanisms to consider in later requirement elicitation.

In step \Circled{4}, we also identify which value tactics oppose or complement each other, serving as value-related input for value prioritization.
Once the initial set of value tactics and their conflicts have been resolved \Circled{5}, the process continues, focusing on eliciting detailed monitoring requirements \Circled{6}, i.e., requirements that are related to the monitoring of actors.
The results of the value tactic and conflict resolution steps serve as input for the monitoring requirements elicitation phase of the overall system. 
The ``traditional'' RE process~\cite{pohl2010requirements}, is thereby  enriched by the notion of the previously identified monitoring properties, personas, their values, and resulting value tactics.
As shown in Figure~\ref{fig:value-based-framework}, each of the described steps are repeated until finally, all affected stakeholders agree upon a set of requirements for the monitoring UC \Circled{7}.
Based on these artifacts, system engineers are then able to design and implement the monitoring infrastructure.

%%% pointer to (5) is still missing


%\subsection{Applying the Process}
\bullitem{Applying the Framework:}
As a first proof-of-concept illustrating our approach and demonstrating it for a concrete scenario, we created an example \muc, personas, values, value tactics, and monitoring requirements, for the aforementioned Use Case (cf. Table~\ref{tab:motivating-example}).
More specifically, the UC revolves around detecting when a shop-floor worker enters a potentially dangerous and restricted area, e.g., where autonomous manufacturing robots are operating, and notifying them to leave said area\footnote{Due to space limitations, we only present a subset of values and tactics in this paper. All created artifacts are available in the supplemental material (\url{https://github.com/Ethical-Human-Machine-Interaction/vcmf}.}.
First, we identified the key stakeholders of the system use case and developed their personas. In our example, we found three key stakeholders: (a) Shop-Floor Workers, (b) Factory Managers / Supervisors, and (c) stakeholders that fall in the ``Others'' category (e.g., personnel without access to dangerous areas).
Based on the System Use Case, we then derived a concrete \muc that further details how monitoring is involved in the process, and particularly, how monitoring involves/affects the human stakeholders.
Next, we augment our \muc with additional information cornering \textit{which} properties should be monitored from \textit{which} components or human actors.
In our shop-floor scenario, this, for example, includes monitoring the position of workers, potentially with an IoT device that is integrated in protective work clothing, or a LiDAR scanner installed at relevant locations inside the factory. Additionally, this requires the collection of non-human-related information, such as the position of robots workers may collide with.

%For each of these stakeholder groups, we then created dedicated personas to gain a better understanding of \textit{who} embodies which values.
We then defined the potential values of each stakeholder group and organized them according to  Schwartz'~\cite{schwartz1992Universals} four value categories. % important to use a taxonomy to gain a better understanding of what needs to be thought of.
An example \textit{Self-Enhancement} value definition of a shop-floor worker for our \muc is ``I want to be able to withdraw my consent of monitoring, even after agreeing to data collection''.
On the other hand, a factory manager's \textit{Self-Enhancement} values may include ``I am able to hold employees accountable for their actions when human-caused accidents occur.''. After defining a set of values for each persona, we defined value tactics (VTs). 
Revisiting the examples from above, one VT is related to \enquote{\textit{allow opt-out of tracking}} and another to \enquote{\textit{track which shop-floor workers enter dangerous areas}}.
Afterward, we consolidated all VTs and identified potential conflicts. 
The two example VTs also exemplify conflicting values which need to be resolved before the final requirements elicitation phase. We argue that, to resolve conflicts, the individual values defined by the stakeholders must be prioritized. The IEEE 7000\textsuperscript{\texttrademark} standard~\cite{noauthor2021ieee} provides criteria to prioritize the core values of a System of Interest, which serves as a basis in this process. 
%Ultimately, the executive leaders assume accountability through their signature and publication of the final value prioritization~\cite{Spiekermann2023Value}.
We realize that value prioritization is an important issue, which is why we aim to develop processes that help stakeholders prioritize values in future work.
% \zp{value negotiation is an open issue and not solved yet}
% TODO: VALUE PRIORIZATION, value based WIN WIN

When eliciting the final requirements, it is crucial to specify values that are related, providing clear traces throughout the entire process.
For example, shop-floor workers not being allowed to opt out of tracking because of safety concerns is related to the   monitoring requirement  \enquote{\textit{When a user enters the bounds of a dangerous area, the system shall always notify the user by audiovisual notifications.}} % \zp{add monitoring specific usecase}
Notice that the wording of the requirement specifies that a user will \textit{always} be notified, meaning it is not possible to opt out of position tracking or disabling notifications by a shop-floor worker. 
Naturally, this would also lead to a discussion about tracking constraints, such as the frequency of measurements.
Such constraints can trigger additional iteration cycles to reassess and potentially revise the \muc, value statements, or value tactics. 
% \zp{add what exactely is the moniotring requirement - did in 3.1}
% \mv{maybe some concluding/discussion remarks...  Following this initial version of the process we were able to... \zp{see comment}}
% \zp{we require constraints}
% \zp{process steps. WHAT WHY HOW}

% schwartz value framework
% Actors / stakeholders / personas of CPS (i.e., shop floor)
% Privacy tactics: \url{https://doi.org/10.1109/SPW.2016.23}
% tactics (value based engineering, value tactics, constraints to these tactics)
% -> monitoring needs
% -> conflicts (i.e., privacy, ethics, .... based on schwartz and related to actors) -> use tactics to fit specific needs -> make a matrix of that
% -> IEEE 7000-2001 (annex G) lists some ``typical ethical values for system design''


% “Human behavior is complex and may not always conform to the model’s theoretical framework. Actors may exhibit contradictory or unexpected behaviors, necessitating flexibility in applying the model and interpreting its results.” ([Alrimawi and Nuseibeh, 2024, p. 6])

% what requirements can we inherit from the motivating example, how can we extend it then?