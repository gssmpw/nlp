\section{Related Work}
\subsection*{Speech Act Theory and Indirect Speech Acts}

It is originally considered by positivist philosophers that every sentence we utter in our everyday life describes or constates something, and thus can always be discerned as true or false. \cite{austin} argued against this concept and categorized our language usage into two types. The first type is the ‘constative utterance’, which can be understood as the same as the traditional idea of a statement. On the other hand, in the case of the second type of language usage called the ‘performative utterance’, sentences have no truth-value. Instead, they become performative acts themselves. For example, uttering “I bet 10 dollars on that” can be considered as an act of ‘betting’, and it cannot be determined whether the sentence itself is true or false. In other words, with performative utterances, we don’t describe the acts we do, but perform the very act itself. We can understand this concept of language usage as ‘Speech Acts’.

\cite{searle79} delved further into Speech Act Theory and categorized speech acts into five classes: representatives, directives, commissives, expressives, and declaratives. The main intention of representative speech acts is to convey or describe something that the speaker believes to be true. For directive speech acts, the intention is to make the listener perform(or not perform) a certain action. Commissive speech acts involve the speaker committing to a future action. Expressive speech acts express the speaker’s emotions about a particular situation. Declarative speech acts create a new state or situation.

Based on the context in which an utterance is made, we can interpret a sentence and the intention of the speaker differently. Take a look at the following utterance: “The ice is thin”. Without a context, it can simply be understood as a description of thin ice, hence as an assertive speech act. However, imagine a situation in which several children are attempting to step on a frozen pond. The same utterance could be interpreted as an act of warning, preventing the children from stepping on the thin ice and falling into the cold water, thus as a directive speech act. We can differentiate between (direct) speech acts and indirect speech acts, which are defined by Searle as utterances in which a certain speech act is performed by performing a different class of speech act. In the example, a directive speech act of ‘advisory warning’ (do not step on the ice) is performed indirectly through an assertive speech act of ‘fact presentation’ (the ice is thin).

As we can see, to understand a speaker’s intention from an utterance, it is crucial to interpret a sentence based on the surrounding context. Considering the existing trend of LLM evaluations through the leaderboards \citep{guo}, which focus primarily on performance in tasks assessing knowledge and understanding explicit literal meanings, evaluating the pragmatic competence of LLMs using the framework of Speech Act Theory can be a meaningful in-depth evaluation of the linguistic performance of LLMs.


\subsection*{Evaluation of human understanding ability of indirect speech acts}
%2-4 문단을 통합 줄여서 2 문단 만들기
%oh 2018(children/learner 화용평가) 설명으로 3 문단 만들기
The evaluation tests of human pragmatic abilities are primarily developed and employed to determine how close the pragmatic competence of the test subjects is to that of general individuals. Most of the assessments focus on individuals with communicative challenges \citep{arcara, kim17, seo, jang}, L1 speaking children and L2 learners \citep{oh}.

\cite{arcara} developed a test for the Assessment of Pragmatic Abilities and Cognitive Substrates(APACS), targeting individuals who have acquired communicative deficiencies. The test comprises the following six tasks in Italian language: Interview, Description, Narratives, Figurative Language 1/2, and Humor. The first task includes autobiographical questions. The Description task involves describing elements of ten everyday pictures. The Narratives task includes comprehension questions about the global topic, specific elements and figurative expressions of a certain story. Figurative Language 1 consists of multiple-choice questions about five idioms, metaphors, and proverbs each. Figurative Language 2 involves open-ended questions. The Humor task includes multiple-choice questions where participants select the appropriate ending(funny, straightforward, unrelated ending) for seven brief stories. The consistency and retest reliability of the test were secured and proved by conducting sample tests with 119 healthy participants representing the general population.

\cite{kim17} developed and conducted a test to evaluate the ability of the students with mild intellectual disability to understand speech acts and indirect speech acts. It is composed of multiple-choice questions, in which certain speech acts are presented in a context that includes two or three sentences. There are three answer options: ‘correct interpretation’, ‘wrong, literal interpretation’ and ‘wrong, context-based interpretation’. Eighteen questions are about indirect speech acts, with half being interrogative sentences and the other half declarative sentences. Another nine questions are about general speech acts, five of which are interrogative sentences and four are declarative sentences. The test was shown to be reliable by producing significantly different results between subjects with varying levels of intellectual challenges.

Other cases of evaluating human understanding of speech act include the tests targeted at children with Asperger syndrome \citep{seo}, right-brain impaired patients \citep{jang} and school-aged children \citep{oh}.

In a similar vein, we developed and employed a speech act comprehension test specifically targeted at LLMs. The main purpose of this test is to determine how well the individual LLMs understand speech acts, with the potential to compare their competence to that of typical human individuals in further research involving human test participants.

\subsection*{Evaluation of LLMs’ understanding ability of indirect speech acts}

Recently, many services are being developed using generative artificial intelligence models in various fields. To assess whether these services can successfully communicate with users and provide requested services, studies on LLM’s ability to understand intention of an utterance are increasing in each field \citep{han, wang, loukas, bouzaki} . In particular, there are many studies using generative artificial intelligence models in language education. Among them, \cite{han} analyzed whether ChatGPT can understand the EFL(English as foreign language) learners’ intention of utterances, which learners enter into ChatGPT while writing English essays. They evaluated whether ChatGPT classifies user input well into 13 predefined intent types such as ‘Request for Translation’, ‘Request for Information’, ‘Statement’, and ‘Acknowledgement’. \cite{wang} examined whether ChatGPT understands which of the talk moves, such as ‘asking for more information’ and ‘making a claim’, correspond to utterances that occur during class, and compared the performance with BERT based models.

% 한문단 추가하기 (교육 외 다른 분야의 LLM 모델 대상으로 화행 이해 평가한 연구) 여행, 금융, 의료(영은), 법률(연구찾아보기, 지우)
% Loukas et al.(2023), Making LLMs Worth Every Penny: Resource-Limited Text Classification in Banking   금융

Moreover, whether LLMs generate appropriate sentences based on a correct understanding of speech acts is dealt with great interest nowadays. Many studies focus on instructing LLMs to generate adequate responses for certain objectives, such as data augmentation and automatic annotation, and evaluating their performance \citep{bouzaki, ostyakova, yu}.

\subsection*{Pragmatic Evaluation of LLMs for Korean}

% 도입부 문단 짧게 추가(한국어 특수성 language specificness \cite{eo} \cite{parka} 강조하기)

\cite{eo} GPT-family models are evaluated on their ability to solve riddles in Korean, a task that demands high creativity and an understanding of language-specific nuances. The results demonstrate that while GPT-4 achieves the highest scores, generally, the models struggle with this task, scoring below 10\% in both EM and F1 scores. This highlights their challenges in tasks that require a deep understanding of the subtleties of human language.

% 같은 대화 기제(그라이스의 협력원리)를 기반으로 LLM 평가하고자 한 프레임웍 연구 -> 한 문장...
\cite{nam} tests Kakao Mini, an AI speaker, for its communicative performance in Korean based on real AI-human conversations in a multi-turn dialogue setup. They leverage the framework of Gricean conversational theory for the evaluation. The results show that the maxim of relation was the most frequently flouted by the tested model, indicating significant room for improvement in achieving natural communication capacity. \cite{park1} evaluates various LLMs, including Korean-specific ones, for their pragmatic competence in Korean, based on Gricean conversational theory. The study assesses whether the models can accurately infer meanings implied by the context, similar to human inference. The findings reveal that while GPT-4 is notable, HyperClovaX, a model tailored for Korean, exhibits superior performance on Korean-specific questions. Building on this, \cite{park2} expand the test suite in size and scope to include other flagship models and additional languages, such as English, Chinese, and German.