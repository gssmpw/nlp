\section{Related Work}
We outline three areas relevant to our study of AI attribution in co-creative writing scenarios. First, we provide a brief overview of the emerging field of human-AI co-creation, in which generative AI models and human users both manipulate artifacts-under-creation. We then discuss prior studies that examined people's feelings of ownership over works co-created with AI. Finally, we examine the landscape of existing attribution frameworks to motivate the need for frameworks specific to AI co-creative partners.

\subsection{Co-creation with generative AI}

Generative AI is often used for co-creation across many content modalities, including text~\cite{wan2024felt, yang2022ai, ding2023mapping, lee2024design}, images~\cite{turchi2023human, fan2024contextcam}, audio~\cite{cao2023comprehensive, ning2024mimosa, louie2020novice}, and video~\cite{wang2024podreels, wang2024reelframer} due to its ability to produce high-fidelity works from natural language descriptions. One common co-creative task is writing~\cite{lee2024design}. Advancements in the ability for LLMs to produce fluent text has led to a rapid proliferation of AI-powered writing assistants, such as Copilot for Microsoft 365\footnote{Copilot for Microsoft 365: \url{https://www.microsoft.com/en-us/microsoft-365/enterprise/copilot-for-microsoft-365}} and Grammarly's AI Writing Assistant\footnote{Grammarly AI Writing Assistant: \url{https://www.grammarly.com/ai-writing-assistant}}. Researchers have explored the use of LLMs to support writing in many domains, including fiction~\cite{calderwood2020novelists, yang2022ai, zhao2023more}, blog posts~\cite{radensky2024let}, social media posts~\cite{lu2024corporate}, song lyrics~\cite{huang2020ai}, comedy~\cite{mirowski2024robot}, and more. \citet{lee2024design} mapped out dimensions within the design space for intelligent writing assistants and identified a wide range of writing contexts, purposes, and stages that they can support. Their work highlights several writing tasks in which AI can contribute, including idea generation, planning, drafting, and revision~\cite{lee2024design}. As such, co-writing with AI assistants can occur through a variety of workflows: a user might use AI-generated ideas as inspiration, write their own draft and ask AI to revise it, ask AI to write a full draft then review it, or anywhere in between. 

Studies of AI-assisted writing have indicated that LLMs can improve various facets of writing, including the creativity, confidence, and efficiency of writers~\cite{cardon2023challenges, doshi2024generative, li2024value}. Studies with students have similarly found that AI assistance can improve their writing skills~\cite{amyatun2023can, song2023enhancing}. In one study on using LLMs to write social media posts, \citet{long2023tweetorial} found that LLMs reduced the mental demand and effort required of writers by supporting brainstorming, information gathering, and revision, hence improving their confidence and satisfaction with their work. In the workforce, knowledge workers have begun using LLMs for writing tasks such as ideation, improving text, and creating a first draft~\cite{brachman2024knowledge}.

The incorporation of AI assistance into writing workflows raises new questions regarding the need for transparency and explainability~\cite{sun2022investigating}. The variable nature of generated outputs -- what \citet{weisz2024design} call ``generative variability'' -- along with the propensity for LLMs to produce factually incorrect yet plausible-sounding text ~\cite{hicks2024chatgpt}, has led researchers to explore techniques for mitigating overreliance on generated texts: attributing sources of information~\cite{do2024facilitating}, identifying and drawing attention to model uncertainties~\cite{kim2024m, weisz2021perfection}, and predicting the likelihood of requiring human edits~\cite{vasconcelos2023generation}. Tools such as iA Writer\footnote{iA Writer for Mac: \url{https://ia.net/writer/support/editor/authorship}} distinguish AI-generated text via different text styles. Technologies such as GLTR\footnote{GLTR: \url{http://gltr.io}} and Radar~\cite{hu2023radar} detect AI-generated text in writings of unknown origins~\cite{gehrmann2019gltr}. Although these studies and tools make important strides in improving transparency in LLM use, there remains a gap in understanding people's transparency needs surrounding the authorship of co-created content -- in essence, much research has focused on understanding \emph{how} an LLM produced a text, but less emphasis has been placed on communicating \emph{what was produced} and \emph{how it was used}. Given the prevalence of AI-assisted writing tools and the growing complexity of human-AI co-writing workflows, there is a need to better understand people's perceptions of attribution and desires for transparency in this rapidly-evolving space.

\subsection{User perceptions of ownership in co-created work}
\label{sec:related-work-perceptions}

\citet{lee2024design} identified ownership as an important dimension of AI-assisted writing, defining it as a ``userâ€™s sense of ownership or authenticity over the written artifact when using the writing assistant.'' As co-writing workflows become more complex and pervasive, the line between AI and human ownership over co-created work becomes blurrier: who is an author and how should each party be credited? \citet{yeh2024ghostwriter} found mixed perceptions of ownership over works co-written with an AI writing tool. \citet{he2024ai} found that, ``Participants mostly felt that ownership was shared between the human and the AI'' in an AI-assisted brainstorming scenario. \citet{draxler2024ai} explored the relationship between sense of ownership and declaration of authorship in the context of co-writing postcards for a friend. They found an ``AI ghostwriter effect'' in which people were less likely to declare an AI's involvement compared to the involvement of another person, even though they did not consider themselves to be the owners or authors of AI-generated writing. Even so, 43.3\% of participants in one of their studies felt that disclosing AI contributions should be mandatory for ethical, transparency, and self-protection reasons, and 61.5\% of participants in their second study felt that denoting AI involvement should be mandatory~\cite{draxler2024ai}.

Work in the HCI literature has also begun to identify factors that affect people's sense of ownership over work produced with AI assistance. Some of these factors regard characteristics of the contributions themselves, such as the types of contributions made~\cite{rezwana2023user, he2024ai, wan2024coco, xu2024makes} and the amount of material contributed~\cite{lee2022coauthor}. Other factors focus on the process by which contributions were made. For example, people's feelings of ownership increase when performing the work of ``critical integration'''~\cite{sarkar2023exploring} or with a greater sense of control over the work~\cite{draxler2024ai, louie2020novice, xu2024makes}. The role of AI in the writing process can also influence ownership perceptions~\cite{draxler2024ai, rezwana2023user, gero2019metaphoria, xu2024makes}. \citet{rezwana2023user} reported the role of AI as a tool vs. an independent entity as a salient consideration, and \citet{gero2019metaphoria} found that a cognitive offloading tool that was used ``like a calculator for words'' raised fewer concerns over ownership compared to a co-creative partner who made more substantial contributions. In the same vein, several works have explored interventions to prevent the loss of human ownership over co-created work. Techniques such as writing longer prompts~\cite{joshi2024writing}, using AI for ideation or a starting point~\cite{biermann2022tool}, and viewing AI contributions in a sidebar rather than within the text~\cite{kim2024towards} have all been found to increase people's sense of ownership, as well as designing AI assistants to be more interactive, transparent, and personalized~\cite{gero2019metaphoria, neate2019empowering}.

One key process factor that impacts feelings of ownership is initiative: whether a contribution was initiated by the human or AI partner~\cite{rezwana2023user}, and whether that contribution was made via ``direct generation'' or ``indirect suggestions''~\cite{wan2024coco}. In our study, we sampled three primary contribution dimensions -- contribution type, contribution amount, and initiative -- because they cover characteristics of the contributions themselves and the process by which they were generated. We summarize these dimensions in Table~\ref{tab:contribution-dimensions}.

\begin{table}[htp]
    \centering
    \small
    \begin{tabularx}{\linewidth}{p{1.5cm}XX}
        \toprule
        \textbf{Dimension} & \textbf{Definition} & \textbf{Literature} \\
        \midrule
        Type of\newline contribution & The kind of content contributed by the writing partner. & \citet{he2024ai, rezwana2023user, wan2024coco, xu2024makes} \\
        \midrule
        Amount of contribution & The quantity of content contributed by the writing partner. & \citet{lee2022coauthor}  \\
        \midrule
        Initiative & Whether the writing partner made a proactive or reactive contribution and whether they contributed actual content or recommendations. & \citet{lee2024design, rezwana2023user, wan2024coco}  \\
        \bottomrule
    \end{tabularx}
    \caption{Summary of dimensions affecting perceptions of ownership in co-creation that we used to structure our study, identified from prior HCI and co-creative literature.}
    \Description{Summary of dimensions affecting perceptions of ownership in co-creation that we used to structure our study, identified from prior HCI and co-creative literature. Each row contains a dimension (type of contribution, amount of contribution, and initiative), its definition, and a list of prior literature that identified it.}
    \label{tab:contribution-dimensions}
\end{table}

These studies provide valuable insights into people's feelings of ownership over co-created works, which inform the focus of our paper: \emph{attribution}. Attribution is the visible recognition provided to the author of a work. Attribution differs from ownership in two key ways. From a legal perspective, ownership provides certain rights and accountability, such as being able to revive work that is no longer being disseminated~\cite{van2016authors}. From a psychological perspective, ownership refers to a ``sense of possession over the target''~\cite{xu2024makes}. In both cases, ownership does not entail a requirement for attribution. The relationship between attribution and authorship is more complex. In many cases, authors are attributed as contributors to their work. However, it is not always required for an author to be attributed (e.g., ghostwriting), or to be attributed under their own name (e.g., pen names).

In this work, we focus on understanding how people believe authorship should be attributed across the many potential types of co-creative workflows. What type of credit should AI receive for different levels of involvement in the co-creative process? While \citet{draxler2024ai} studied similar questions, we sought to conduct a more granular analysis across different natures of contribution, writing contexts, and types of authorship credit.

\subsection{Attribution practices}
\label{sec:attribution-practices}

When writing collaboratively with other people, there are well-established standards for crediting contributions. For example, the ACM's criteria state that authors must ``make substantial intellectual contributions to some components of the original Work'' and ``take full responsibility for all content in the published Works''~\cite{acm2023policy}. The CRediT taxonomy, used by over 120 journals as of 2019, identifies contribution types that can be specified in authorship statements~\cite{brand2015beyond}. Researchers have also explored interactive crediting~\cite{bd2016solving} and creative representations of author order~\cite{demaine2023every}. In the editing domain, different roles capture different contribution responsibilities. For example, developmental editors review the big picture and ensure conceptual alignment, whereas copy editors revise mechanical aspects such as grammar, spelling, and wording~\cite{reeder2016three}. Editors are often acknowledged but not typically listed as authors in published work.

The extent to which these standards translate to human-AI co-creation is an open question. Model providers have begun defining guidelines for attribution of works created with their systems. For example, OpenAI states that when co-authoring with their API, ``published content is attributed to your name or company,'' and requires that ``the role of AI in formulating the content is clearly disclosed''~\cite{openai2022sharing}. Generative AI applications are taking a similar approach. One example is ``Draft One,''~\footnote{Draft One. \url{https://www.axon.com/products/draft-one}} which uses an LLM to assist police officers in writing reports and requires officers to check a box indicating AI usage~\cite{murphy2024police}. Similarly, many journals and publishing companies require the use of AI to be acknowledged, such as in a Methods or Acknowledgments section. However, they maintain that AI cannot credited as an author~\cite{acm2023policy, arxiv, elsevier, icmje, wiley2023generative}. For example, Nature's guidelines state, ``Large Language Models...do not currently satisfy our authorship criteria. Notably an attribution of authorship carries with it accountability for the work, which cannot be effectively applied to LLMs'' \cite{nature}. The language of ``currently satisfy'' indicates that their requirements may evolve as generative technology advances. 

Legal guidelines have also begun to emerge around AI authorship. In the United States, the Copyright Office has declared that AI cannot be recognized as an owner of creative work -- only human portions of co-created work are protected by US copyright~\cite{zirpoli2023generative}. The Copyright Office has stated that they may issue additional guidance as the technology evolves~\cite{zirpoli2023generative}. In contrast, two court decisions in China have indicated that AI-generated content is eligible for copyright protection by a user or platform developer if it is an ``original intellectual achievement''~\cite{cooley2024}. Similarly, in the United Kingdom, copyright law provides protection for ``computer-generated works'' because whoever made the ``arrangements necessary for the creation of the work'' is designated the owner~\cite{cooley2024}. In the EU AI Act, legal guidance on AI authorship is notably missing~\cite{cooley2024}. Transparency requirements are also emerging; the EU AI Act~\cite{eu2023ai} and the California AI Transparency Act~\cite{california2024ai} both require disclosure of AI-generated content, but neither specifies how to do so. The variability in authorship guidelines across different geographies, along with the lack of concrete guidance on how to provide transparency, reflect the uncertain and evolving nature of human-AI authorship.

Although emerging policies have begun to define requirements for AI authorship and attribution, they often take a one-size-fits-all approach that does not account for different kinds of contributions in co-creative workflows, nor do they account for the attribution preferences of those creating the content. As \citet{sarkar2023exploring} contends, ``creativity is ultimately defined by communities of creators and receivers.'' 
A creator-centric \emph{how} of AI attribution remains an open question -- while algorithms for identifying and watermarking AI-generated content offer useful technological approaches~\cite{dathathri2024scalable, fernandez2023stable, hu2023radar}, they may not encompass the extent and nuance of creators' attribution needs. We aim to understand a more granular set of requirements for AI attribution in co-creativity from the perspective of creators: how much authorship credit should be given to AI for different kinds of contributions, and how should their perceptions translate into guidelines for crediting AI?


%%
%% STUDY OF ATTRIBUTION PERCEPTIONS
%%