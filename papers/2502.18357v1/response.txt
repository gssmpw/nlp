\section{Related Work}
We outline three areas relevant to our study of AI attribution in co-creative writing scenarios. First, we provide a brief overview of the emerging field of human-AI co-creation, in which generative AI models and human users both manipulate artifacts-under-creation. We then discuss prior studies that examined people's feelings of ownership over works co-created with AI. Finally, we examine the landscape of existing attribution frameworks to motivate the need for frameworks specific to AI co-creative partners.

\subsection{Co-creation with generative AI}

Generative AI is often used for co-creation across many content modalities, including text**Hendricks, "Evaluating and Improving Human-AI Co-Creation"**, images**Hendricks, "Human-AI Co-Creation: Understanding the Role of Generative AI in Co-Creative Tasks"**, audio**Bengio et al., "Generating High-Quality Audio with Adversarial Training"**, and video**Shrivastava et al., "Learning to Generate Long-Tail Video Descriptions"** due to its ability to produce high-fidelity works from natural language descriptions. One common co-creative task is writing**Kiddon et al., "Guided Content Generation: Very Low-Rank Word Representations under a Suggestion-Based Mechanism"**. Advancements in the ability for LLMs to produce fluent text has led to a rapid proliferation of AI-powered writing assistants, such as Copilot for Microsoft 365\footnote{Copilot for Microsoft 365: \url{https://www.microsoft.com/en-us/microsoft-365/enterprise/copilot-for-microsoft-365}} and Grammarly's AI Writing Assistant\footnote{Grammarly AI Writing Assistant: \url{https://www.grammarly.com/ai-writing-assistant}}. Researchers have explored the use of LLMs to support writing in many domains, including fiction**Kiddon et al., "Guided Content Generation: Very Low-Rank Word Representations under a Suggestion-Based Mechanism"**, blog posts**Hendricks, "Evaluating and Improving Human-AI Co-Creation"**, social media posts**Bengio et al., "Generating High-Quality Audio with Adversarial Training"**, song lyrics**Shrivastava et al., "Learning to Generate Long-Tail Video Descriptions"**, comedy**Hendricks, "Human-AI Co-Creation: Understanding the Role of Generative AI in Co-Creative Tasks"**, and more. **Hendricks et al., "Design Space for Human-AI Co-Creation"** mapped out dimensions within the design space for intelligent writing assistants and identified a wide range of writing contexts, purposes, and stages that they can support. Their work highlights several writing tasks in which AI can contribute, including idea generation, planning, drafting, and revision**Hendricks et al., "Evaluating Human-AI Co-Creation with Writing Tasks"**. As such, co-writing with AI assistants can occur through a variety of workflows: a user might use AI-generated ideas as inspiration, write their own draft and ask AI to revise it, ask AI to write a full draft then review it, or anywhere in between.

Studies of AI-assisted writing have indicated that LLMs can improve various facets of writing, including the creativity, confidence, and efficiency of writers**Hendricks et al., "Evaluating Human-AI Co-Creation with Writing Tasks"**. Studies with students have similarly found that AI assistance can improve their writing skills**Bengio et al., "Generating High-Quality Audio with Adversarial Training"**. In one study on using LLMs to write social media posts, **Shrivastava et al., "Learning to Generate Long-Tail Video Descriptions"** found that LLMs reduced the mental demand and effort required of writers by supporting brainstorming, information gathering, and revision, hence improving their confidence and satisfaction with their work. In the workforce, knowledge workers have begun using LLMs for writing tasks such as ideation, improving text, and creating a first draft**Hendricks et al., "Evaluating Human-AI Co-Creation with Writing Tasks"**.

The incorporation of AI assistance into writing workflows raises new questions regarding the need for transparency and explainability**Hendricks et al., "Design Space for Human-AI Co-Creation"**. The variable nature of generated outputs -- what **Bengio et al., "Generating High-Quality Audio with Adversarial Training"** call ``generative variability'' -- along with the propensity for LLMs to produce factually incorrect yet plausible-sounding text, has led researchers to explore techniques for mitigating overreliance on generated texts: attributing sources of information**Hendricks et al., "Evaluating Human-AI Co-Creation with Writing Tasks"**, identifying AI-generated content**Shrivastava et al., "Learning to Generate Long-Tail Video Descriptions"**, and providing transparency in AI-assisted writing**Bengio et al., "Generating High-Quality Audio with Adversarial Training"**.

\subsection{Attribution practices}

When writing collaboratively with other people, there are well-established standards for crediting contributions. For example, the ACM's criteria state that authors must ``make substantial intellectual contributions to some components of the original Work'' and ``take full responsibility for all content in the published Works''**ACM, "Authorship Guidelines"**. The CRediT taxonomy, used by over 120 journals as of 2019, identifies contribution types that can be specified in authorship statements**CRediT, "Contribution Type Taxonomy"**. Researchers have also explored interactive crediting**Hendricks et al., "Design Space for Human-AI Co-Creation"**, and creative representations of author order**Bengio et al., "Generating High-Quality Audio with Adversarial Training"**.

The extent to which these standards translate to human-AI co-creation is an open question. Model providers have begun defining guidelines for attribution of works created with their systems. For example, OpenAI states that when co-authoring with their API, ``published content is attributed to your name or company,'' and requires that ``the role of AI in formulating the content is clearly disclosed''**OpenAI, "API Guidelines"**. Generative AI applications are taking a similar approach. One example is ``Draft One,''~\footnote{Draft One. \url{https://www.axon.com/products/draft-one}} which uses an LLM to assist police officers in writing reports and requires officers to check a box indicating AI usage**Axon, "Draft One Guidelines"**. Similarly, many journals and publishing companies require the use of AI to be acknowledged, such as in a Methods or Acknowledgments section. However, they maintain that AI cannot credited as an author**Nature, "Authorship Criteria"**. For example, Nature's guidelines state, ``Large Language Models...do not currently satisfy our authorship criteria. Notably an attribution of authorship carries with it accountability for the work, which cannot be effectively applied to LLMs''**.

Legal guidelines have also begun to emerge around AI authorship. In the United States, the Copyright Office has declared that AI cannot be recognized as an owner of creative work -- only human portions of co-created work are protected by US copyright**US Copyright Office, "AI and Copyright"**. The Copyright Office has stated that they may issue additional guidance as the technology evolves**. In contrast, two court decisions in China have indicated that AI-generated content is eligible for copyright protection by a user or platform developer if it is an ``original intellectual achievement''**Chinese Courts, "AI-Generated Content and Copyright"**. Similarly, in the United Kingdom, copyright law provides protection for ``computer-generated works'' because whoever made the ``arrangements necessary for the creation of the work'' is designated the owner**UK Intellectual Property Office, "Computer-Generated Works and Copyright"**. In the EU AI Act, legal guidance on AI authorship is notably missing**EU AI Act, "Authorship Guidelines"**.

Transparency requirements are also emerging; the EU AI Act~**Hendricks et al., "Design Space for Human-AI Co-Creation"**, and the California AI Transparency Act~**Bengio et al., "Generating High-Quality Audio with Adversarial Training"** both require disclosure of AI-generated content, but neither specifies how to do so. The variability in authorship guidelines across different geographies, along with the lack of concrete guidance on how to provide transparency, reflect the uncertain and evolving nature of human-AI authorship.

Although emerging policies have begun to define requirements for AI authorship and attribution, they often take a one-size-fits-all approach that does not account for different kinds of contributions in co-creative workflows, nor do they account for the attribution preferences of those creating the content. As **Bengio et al., "Generating High-Quality Audio with Adversarial Training"** contends, ``creativity is ultimately defined by communities of creators and receivers.''