\clearpage
\setcounter{page}{1}
\maketitlesupplementary


\section{The SIMCO and ComCO Datasets}
\label{app:dataset}
\subsection{The SIMCO Dataset}
The SIMCO dataset comprises 17 objects. These 17 objects are:

\begin{center}
\begin{tabular}{lll}
Cube & Sphere & Cylinder \\
Mug & Pentagon & Heart \\
Cone & Pyramid & Diamond \\
Moon & Cross & Snowflake \\
Leaf & Arrow & Star \\
Torus & Pot &
\end{tabular}
\end{center}

Using Blender software, a collection of images containing 2 to 5 objects has been created from these 17 objects. The total number of images in this dataset is approximately 85,000. Examples of these images can be seen in Figure \ref{fig:simco}.

\begin{figure*}[htbp]
    \centering
    \includegraphics[width=0.9\linewidth]{sec/images/simco.pdf}
    \caption{Examples of SimCO dataset}
    \label{fig:simco}
\end{figure*}

\subsection{The ComCO Dataset}

The ComCO dataset contains 72 objects, as listed below:
\begin{center}
\scriptsize % or \small for slightly larger text
\begin{tabular}{@{} l @{\hspace{2em}} l @{\hspace{2em}} l @{\hspace{2em}} l @{}}
person & bicycle & car & motorcycle \\
airplane & bus & train & truck \\
boat & traffic light & fire hydrant & street sign \\
stop sign & parking meter & bench & bird \\
cat & dog & horse & sheep \\
cow & dining table & cell phone & elephant \\
bear & zebra & giraffe & hat \\
backpack & umbrella & shoe & eye glasses \\
handbag & tie & suitcase & frisbee \\
skis & snowboard & kite & baseball bat \\
baseball glove & tennis racket & wine glass & hot dog \\
potted plant & teddy bear & hair drier & hair brush \\
skateboard & surfboard & bottle & plate \\
cup & fork & knife & spoon \\
bowl & banana & apple & sandwich \\
orange & broccoli & carrot & pizza \\
donut & cake & chair & couch \\
bed & mirror & window & desk \\
toilet & door & tv & laptop \\
mouse & remote & keyboard & microwave \\
oven & toaster & sink & refrigerator \\
blender & book & clock & vase \\
scissors & toothbrush & & \\
\end{tabular}
\end{center}


In this dataset, a collection of images containing 2 to 5 different objects has also been generated. The total number of images in this dataset is approximately 190,000. Various examples from this dataset can be seen in Figure \ref{fig:comco}.


\begin{figure*}[htbp]
    \centering
    \includegraphics[width=0.9\linewidth]{sec/images/comco.pdf}
    \caption{Examples of ComCO dataset}
    \label{fig:comco}
\end{figure*}


\section{Text-based Object Classification}
\label{app:toc}
We conducted the TOC experiment on various models under different scenarios, and the results are presented in Table \ref{tab:toc_total}. This experiment was repeated on both the SIMCO and ComCO datasets.

\input{sec/tables/TOC}


\section{Text-based Object Retrieval}
\label{app:tor}
We repeated the TOR experiment on various models across scenarios with captions containing 2 to 5 objects. This was done to confirm the presence of the discovered bias. The complete results of this experiment, which was conducted on both the SIMCO and ComCO datasets, can be observed in Table \ref{tab:tor_total}.


\input{sec/tables/TOR}

\section{Image-based Object Classification}
\label{app:ioc}
\input{sec/tables/IOC}

We conducted the IOC experiment on images from both generated datasets, focusing on scenarios where one object was significantly larger than the others. This experiment was repeated across various models. In our trials, we ensured that the larger object was not consistently placed in a fixed location, instead testing multiple positions. The average results of these experiments are presented in Table \ref{tab:ioc_total}.


\section{Image-based Object Retrieval}
\label{app:ior}
We extended our investigation by conducting the IOR experiment on images from both the SimCO and ComCO datasets. This experiment encompassed all scenarios ranging from 2 to 5 objects. Similar to our previous experiment, we deliberately varied the position of the larger object to avoid location-based biases. By considering different locations for the larger object, we aimed to better understand the impact of object size on the models' performance.
The results of these experiments are presented in Table \ref{tab:ior_total}.
\input{sec/tables/IOR}



\section{Text-based Object Classification for Long Caption}
\label{app:toc-long}

In this section, we revisited the IOC experiment with a significant modification to the caption structure. Our objective was to investigate whether the previously observed bias persists in longer, more elaborate captions. We achieved this by expanding the caption template, incorporating additional descriptive phrases between object mentions.

The extended caption template used in this experiment was as follows:

\begin{quote}
This vibrant display features a stunning OBJ1 with its radiant glow, a mesmerizing OBJ2 with bold contours, an enchanting OBJ3 that fits perfectly with its graceful form, a dazzling OBJ4 with brilliant tones and intricate patterns, and an alluring OBJ5 that completes the ensemble with its seamless fusion and distinct shape.
\end{quote}

This template allowed us to maintain a consistent structure while significantly increasing the caption length and complexity.

The results of this modified IOC experiment are presented in Table \ref{tab:toc_long_total}. Notably, the observed pattern closely resembles that of the standard IOC experiment. This similarity suggests that the bias identified in shorter captions persists even in more elaborate textual descriptions.



\input{sec/tables/TOC-Long}




\section{Text-based Object Retrieval for Long Caption}
\label{app:tor-long}
\input{sec/tables/TOR-Long}

In this section, we aimed to examine the performance of various models in the IOR experiment when presented with longer caption formats. This approach mirrors our previous investigation, allowing us to draw comparisons between standard and extended caption scenarios.

We utilized the same extended caption template as in the previous section.
The results of this experiment are presented in Table \ref{tab:tor_long_total}. Notably, the observed pattern closely aligns with that of the standard IOR experiment, suggesting a consistency in model behavior across different caption lengths.

\section{Image-text matching}
\label{app:imtexmatch}
In this section, we extended the experiment previously conducted in Section 5.1, broadening its scope to encompass both the SimCO and ComCO datasets. Our investigation covered scenarios involving 2 to 5 objects and was replicated across various models.
The results of this comprehensive experiment are presented in Table \ref{tab:imgtxtmatch_long_total}.
\input{sec/tables/I-Tmatch}


\section{COCO Dataset Analysis}
\label{app:coco-anlysis}
In this section, we repeated the experiment conducted in Section 4.3 for different scenarios involving 2 to 5 objects. We divided the captions in the COCO dataset into four subsets: those mentioning 2 objects, 3 objects, 4 objects, and 5 objects. We then analyzed each subset to determine in what percentage of cases the largest object appeared in which position.

The results of this evaluation are presented in Figure \ref{fig:coco_analysis_total}. As can be observed, this trend is repeated across all scenarios: in most cases, the larger object appears earlier in the caption.
\begin{figure*} [h!]
    \centering
    \includegraphics[width=\linewidth]{sec/images/dis_objects_all.pdf}
    \caption{Distribution of larger object positions in captions for objects in COCO dataset}
    \label{fig:coco_analysis_total}
\end{figure*}
% \setcounter{page}{1}
% \section{Text-based Object Classification2}