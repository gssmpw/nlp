%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[sigconf,nonacm]{acmart}

% \documentclass[sigconf]{acmart}
% \usepackage[UTF8]{ctex}
\usepackage{mdframed}    % 用于创建框架
\usepackage{appendix}    % 用于附录
\usepackage{threeparttable}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{array}
\usepackage{pifont}
\newcommand{\cmark}{\ding{51}} % 勾
\newcommand{\xmark}{\ding{55}} % 叉
\usepackage{listings}
\usepackage{amsmath}
\usepackage{color}
\usepackage{xcolor}
\usepackage{colortbl}
\newcommand{\lm}[1]{{\color{red} [llm: #1]}}

% \usepackage{caption} % Include this in the preamble
% \captionsetup{skip=20pt} % Set the desired distance, for example, 10pt

% \usepackage{titlesec}
% % 调整 subsubsection 的间距
% \titlespacing{\subsubsection}{0pt}{1ex}{1.5ex}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}


%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation emai}{June 03--05,
  2018}{Woodstock, NY}
%%
%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%  from ``Proceedings of ...''!
%%
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
\acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{ChineseEcomQA: A Scalable E-commerce Concept Evaluation Benchmark for Large Language Models}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.

% \author{Ben Trovato}
% \authornote{Both authors contributed equally to this research.}
% \email{trovato@corporation.com}
% \orcid{1234-5678-9012}
% \author{G.K.M. Tobin}
% \authornotemark[1]
% \email{webmaster@marysville-ohio.com}
% \affiliation{%
%   \institution{Institute for Clarity in Documentation}
%   \city{Dublin}
%   \state{Ohio}
%   \country{USA}
% }

\author{Haibin Chen$^{\dagger}$}
\thanks{$^{\dagger}$Both authors contributed equally to this research.}
\affiliation{%
  \institution{Taobao \& Tmall Group of Alibaba}
  \city{Hangzhou}
  \country{China}}

\author{Kangtao Lv$^{\dagger}$}
\affiliation{%
  \institution{Taobao \& Tmall Group of Alibaba}
  \city{Hangzhou}
  \country{China}}

\author{Chengwei Hu}
\affiliation{%
  \institution{Taobao \& Tmall Group of Alibaba}
  \city{Hangzhou}
  \country{China}}

\author{Yanshi Li}
\affiliation{%
  \institution{Taobao \& Tmall Group of Alibaba}
  \city{Beijing}
  \country{China}}

\author{Yujin Yuan}
\affiliation{%
  \institution{Taobao \& Tmall Group of Alibaba}
  \city{Hangzhou}
  \country{China}}
  
\author{Yancheng He}
\affiliation{%
  \institution{Taobao \& Tmall Group of Alibaba}
  \city{Beijing}
  \country{China}}

\author{Xingyao Zhang}
\affiliation{%
  \institution{Taobao \& Tmall Group of Alibaba}
  \city{Hangzhou}
  \country{China}}
  
\author{Langming Liu}
\affiliation{%
  \institution{Taobao \& Tmall Group of Alibaba}
  \city{Hangzhou}
  \country{China}}
  
\author{Shilei Liu}
\affiliation{%
  \institution{Taobao \& Tmall Group of Alibaba}
  \city{Hangzhou}
  \country{China}}
  
\author{Wenbo Su}
\affiliation{%
  \institution{Taobao \& Tmall Group of Alibaba}
  \city{Beijing}
  \country{China}}

\author{Bo Zheng}
\affiliation{%
  \institution{Taobao \& Tmall Group of Alibaba}
  \city{Beijing}
  \country{China}}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Trovato et al.}


%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
With the increasing use of Large Language Models (LLMs) in fields such as e-commerce, domain-specific concept evaluation benchmarks are crucial for assessing their domain capabilities. Existing LLMs may generate factually incorrect information within the complex e-commerce applications. Therefore, it is necessary to build an e-commerce concept benchmark. Existing benchmarks encounter two primary challenges: (1) handle the heterogeneous and diverse nature of tasks, (2) distinguish between generality and specificity within the e-commerce field.
To address these problems, we propose \textbf{ChineseEcomQA}, a scalable question-answering benchmark focused on fundamental e-commerce concepts. ChineseEcomQA is built on three core characteristics: \textbf{Focus on Fundamental Concept}, \textbf{E-commerce Generality} and \textbf{E-commerce Expertise}. Fundamental concepts are designed to be applicable across a diverse array of e-commerce tasks, thus addressing the challenge of heterogeneity and diversity. Additionally, by carefully balancing generality and specificity, ChineseEcomQA effectively differentiates between broad e-commerce concepts, allowing for precise validation of domain capabilities.
We achieve this through a scalable benchmark construction process that combines LLM validation, Retrieval-Augmented Generation (RAG) validation, and rigorous manual annotation. Based on ChineseEcomQA, we conduct extensive evaluations on mainstream LLMs and provide some valuable insights. We hope that ChineseEcomQA could guide future domain-specific evaluations, and facilitate broader LLM adoption in e-commerce applications.

%Large language models (LLMs) have achieved remarkable success in natural language processing (NLP). In practical scenarios like recommendation systems and searching, as users increasingly seek personalized experiences, it becomes crucial to incorporate user interaction history into the context of LLMs to enhance personalization. However, from a utility perspective, the extensive length and noise of these interactions present challenges when used directly as text prompts. A promising solution is to compress and distill user interactions into embeddings, which can serve as soft prompts to assist LLMs in generating personalized responses. Although this approach is efficient, a critical concern remains: Can user embeddings adequately capture valuable information and convey user interests to LLMs?
%To address this concern, we introduce UQABench, a comprehensive benchmark designed to evaluate the effectiveness of user embeddings in prompting LLMs for personalization. We establish a fair and standardized evaluation process for user embeddings, encompassing pre-training, fine-tuning, and assessment stages. To thoroughly evaluate user embeddings, we design three dimensions of evaluation tasks: sequence understanding, action prediction, and interest perception. These evaluation tasks reflect the industry's demands in traditional recommendation systems and its aspirations for LLM-based recommendations, such as accurately understanding user interests and enhancing the user experience.
%We conduct extensive experiments to compare various state-of-the-art methods for modeling user embeddings. Additionally, we reveal the scaling laws in modeling user interests using Transformers, the most widely adopted sequential model.
\end{abstract}

% Large language models (LLMs) have achieved significant success in natural language processing (NLP). In practical scenarios, e.g., recommendation and advertising, as users increasingly demand personalized experiences, it becomes essential to integrate user interaction history into LLMs' context to enhance personalization. However, from a utility standpoint, extensive length and noise pose challenges when leveraging them directly as text prompts. A promising solution is to compress and distill user interactions into embeddings, which can serve as soft prompts to assist LLMs in generating personalized responses. Although this approach is efficient, one critical concern remains: Can user embeddings sufficiently extract valuable information and inform LLMs of user interest? To address this concern, we propose UQABench, a comprehensive benchmark that evaluates the quality of user embeddings in prompting LLMs for personalization. We develop a fair and standardized evaluation process of user embeddings, including pre-training, fine-tuning, and evaluating. To comprehensively assess the user embeddings, we design three dimensions of evaluation tasks: sequence understanding, action prediction, and interest perception. 
% The evaluation tasks embody the industry's requirements in traditional recommendations and the industry's hope for LLM-based recommendations, such as understanding user interest and improving user experience. 
% Extensive experiments are conducted to compare various state-of-the-art methods for modeling user embeddings.
% We also reveal the scaling law in modeling user interest with Transformers, the most widely used sequential model.

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10010147.10010178.10010179.10010186</concept_id>
       <concept_desc>Computing methodologies~Language resources</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Language resources}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Large Language Models, E-commerce, Benchmark}
%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.

\maketitle

\input{files/1introduction.tex}
%\input{files/2preliminary.tex}
\input{files/3methodology.tex}
\input{files/4experiment.tex}
\input{files/5relatedwork.tex}
\input{files/6conclusion}

% \newpage
\bibliographystyle{ACM-Reference-Format}
\bibliography{custom}

\clearpage
\newpage
\appendix
\input{files/appendix.tex}

\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
