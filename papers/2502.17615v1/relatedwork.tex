\section{Related Works}
\vspace{-0.2cm}
\noindent \textbf{Eigenvector-based approaches.} PCA has been fundamental to statistical data analysis since its introduction by Pearson in 1901 [cite]. The method was later formalized within a multivariate analysis framework by Hotelling \cite{hotelling1933analysis}, establishing its theoretical foundations. In its classical form, PCA involves computing an empirical covariance matrix from the data, followed by its eigendecomposition. This formulation allows the application of numerous efficient numerical methods, including QR decomposition \cite{golub1996matrix}, xLAHQR \cite{dhillon2000xlahqr}, the Lanczos method \cite{lanczos1950iteration}, and ARPACK \cite{lehoucq1998arpack}, some of which are implemented in numerical linear algebra packages such as ScaLAPACK \cite{scalapack1997}. 
These methods are effective but often require complete knowledge of the covariance matrix prior to computation.

\noindent\textbf{Centralized stochastic approaches.} With large datasets, iterative and gradient-based methods for PCA have gained prominence.
Krasulina and Oja \& Karhunen proposed two of the earliest stochastic gradient descent methods for online PCA \cite{krasulina1969method, oja1985stochastic}. 
The application of the
least square minimization to the PCA has also received attention \cite{miao1998fast, yang1995projection, bannour1995principal, kung1994adaptive}.
More recently, \cite{arora2012stochastic} and \cite{shamir2015stochastic} have proposed efficient stochastic optimization methods that adapt to the streaming model of data (stochastic) and focus on the theoretical guarantees of gradient-based methods in such non-convex scenarios; see also \cite{boutsidis2014online, garber2015online, shamir2016fast, kim2020stochastic}.
Other approaches include manifold methods \cite{demidovich2024streamlining, chen2024sequential, wang2023incremental, absil2008optimization}, Frank-Wolfe methods \cite{beznosikov2023sarah}, Gauss-Newton methods \cite{zhou2023stochastic}, coordinate descent methods \cite{lei2016coordinate}, accelerated methods \cite{xu2018accelerated}, as well as variants of the PCA problem itself \cite{journee2010generalized, yuan2013truncated, han2014scale, kim2019simple, kim2019scale}.
Nevertheless, these methods are primarily designed as centralized algorithms.

\noindent \textbf{Data-parallel distributed approaches.}
Prior distributed PCA approaches span several key directions. One line of work utilizes randomized linear algebra and SVD projections in distributed settings, yielding strong theoretical guarantees \cite{kannan2014principal, liang2014improved, boutsidis2016optimal, fan2019distributed}. For distributed subspace computation, recent methods combine FedAvg with Orthogonal Procrustes Transformations \cite{li2021communication,mcmahan2017communication,schonemann1966generalized, cape2020orthogonal}. Approaches for computing leading principal components leverage both convex \cite{garber2017communication} and Riemannian optimization for improved efficiency \cite{huang2020communication,alimisis2021distributed}. Notable recent advances include an asynchronous Riemannian gradient method that achieves low computational and communication costs \cite{wang2023incremental}. The field has also expanded to address specialized scenarios, including Byzantine-robust computation \cite{charisopoulos2022communication, zari2022membership}, streaming data analysis \cite{allen2017first, yu2017single}, shift-and-invert preconditioning \cite{garber2016faster}, and coreset-based approaches \cite{feldman2020turning}.

\textbf{Model-parallel distributed approaches.} While most prior work focuses on data-parallel approaches, where each machine computes all principal components using local data, DeepMind's EigenGame \cite{gemp_2020_eigengame} introduced a novel model-parallel framework. Their approach reformulates PCA as a collaborative game, where each principal component computation acts as a player maximizing its utility through Riemannian gradient ascent. Though initially presented as a sequential process with proved convergence guarantees, EigenGame extends to a distributed setting where components are optimized simultaneously across machines. While this parallel extension offers practical benefits, its theoretical convergence properties remain unanalyzed, a limitation that persists in subsequent improvements \cite{gemp2022eigengame}.

Our work complements existing literature mostly theoretically, but also practically. By eliminating the requirement for sequential completion of principal components, our algorithmic framework achieves comparable empirical performance to EigenGame \cite{gemp_2020_eigengame} on large-scale datasets. Crucially, we establish rigorous convergence guarantees for parallel computation, providing the theoretical foundation that has been missing in existing model-parallel approaches.

\vspace{-0.1cm}