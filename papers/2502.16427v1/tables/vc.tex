% !TEX root = ../main.tex

\begin{table*}[!t]
	\centering
	\renewcommand{\arraystretch}{1.1}
	\setlength{\tabcolsep}{9pt}
	\caption{Zero-shot video captioning results on the test set of the MSR-VTT~\cite{xu2016msr-vtt} dataset. 
	\checkmark~indicates whether the method uses the reference captions from the target dataset, MSR-VTT.
	Bold numbers indicate the highest scores among methods that do not utilize reference captions.
%	* denotes that the numbers are from~\cite{lidecap}, ** indicates methods were adapted to zero-shot video captioning by Tewel~\etal~\cite{Tewel_2023_BMVC}, and $\dagger$ indicates our reproduced results.}
	* indicates methods were adapted to zero-shot video captioning by Tewel~\etal~\cite{Tewel_2023_BMVC}, and $\dagger$ indicates our reproduced results.}

	\vspace{2mm}
	\label{table:vc}
	\scalebox{0.8}{
	\begin{tabular}{@{}c|c|c|ccc|ccc@{}}
        \toprule
        Method & Type & Using ref. & B@4 & METEOR & CIDEr & $P_{\text{BERT}}$ & $R_{\text{BERT}}$ & $F_{\text{BERT}}$ \\
        \midrule
        ZeroCap*~\cite{tewel2021zero} & \multirow{2}{*}{\makecell{Test-time \\ optimization}} & & 2.3 & 12.9 & 5.8 & - & - & - \\
        Tewel et al.~\cite{Tewel_2023_BMVC} & &  & 3.0 & 14.6 & 11.3 & 0.280 & 0.391 & 0.319 \\
        \midrule
        MAGIC*~\cite{su2022language} & Inference optimization & & 5.5 & 13.3 & 7.4 & - & - & - \\
        \midrule
        %Mistral-7B~\cite{jiang2023mistral} & \multirow{3}{*}{\makecell{LLM-based \\ video understanding}} & & 15.3 & \textbf{23.8}  & 19.5  &  0.338 & 0.535  & 0.416 \\
        Video ChatCaptioner~\cite{chen2023video} & \multirow{2}{*}{\makecell{LLM-based \\ video understanding}} & & 13.2 & 22.0 & 16.5 & 0.396 & 0.510 & 0.436 \\
        VidIL\textsuperscript{$\dagger$}~\cite{wang2022language} & & \checkmark  & 13.3 & 20.3 & 19.4 & 0.452 & 0.553 & 0.486 \\
        \midrule
        LLM summarization & Text summarization & & 15.3 & \textbf{23.8}  & 19.5  &  0.338 & 0.535  & 0.416 \\
        \midrule
        \vspace{-0.5cm} \\
        Decap-BookCorpus~\cite{lidecap} & \multirow{6}{*}{\makecell{Text-only \\ training}} & & 6.0 & 12.7 & 12.3 & - & - & - \\
        Decap-CC3M~\cite{lidecap} & & & 6.2 & 14.9 & 15.0 & - & - & - \\
        Decap-COCO~\cite{lidecap} & & & 14.7 & 20.4 & 18.6 & 0.429 & 0.537 & 0.465 \\
        Decap-MSRVTT~\cite{lidecap} & & \checkmark & 23.1 & 23.6 & 34.8 & - & - & - \\
        C\textsuperscript{3}\textsuperscript{$\dagger$}~\cite{zhang2024connect} & & \checkmark & 25.3 & 23.4 & 27.8 & 0.518 & 0.550 & 0.519\\
        \textbf{SGVC (Ours)} & & & \textbf{17.1} & 23.0 & \textbf{24.0} & \textbf{0.455} & \textbf{0.547} & \textbf{0.484} \\
        \bottomrule
    \end{tabular}
	}
	\vspace{-2mm}
\end{table*}


\iffalse
\begin{table*}[!t]
	\centering
	\renewcommand{\arraystretch}{1.1}
	\setlength{\tabcolsep}{9pt}
	\caption{Video captioning results on the test set of the MSR-VTT~\cite{xu2016msr-vtt} dataset. 
	\checkmark~indicates whether the method uses the reference captions from the target dataset, MSR-VTT.
	Bold numbers indicate the highest scores among methods that do not utilize reference captions.
	* denotes that the numbers are from~\cite{lidecap}, ** indicates methods were adapted to zero-shot video captioning by Tewel~\etal~\cite{Tewel_2023_BMVC}, and $\dagger$ indicates our reproduced results.}
	\vspace{2mm}
	\label{table:vc}
	\scalebox{0.8}{
	\begin{tabular}{@{}c|c|c|ccc|ccc@{}}
        \toprule
        Method & Type & Using ref. & B@4 & METEOR & CIDEr & $P_{\text{BERT}}$ & $R_{\text{BERT}}$ & $F_{\text{BERT}}$ \\
        \midrule
        \vspace{-0.4cm} \\
        Decap-BookCorpus~\cite{lidecap} & \multirow{6}{*}{\makecell{Text-only \\ training}} & & 6.0 & 12.7 & 12.3 & - & - & - \\
        Decap-CC3M~\cite{lidecap} & & & 6.2 & 14.9 & 15.0 & - & - & - \\
        Decap-COCO~\cite{lidecap} & & & 14.7 & 20.4 & 18.6 & 0.429 & 0.537 & 0.465 \\
        \textbf{SGVC (Ours)} & & & \textbf{17.1} & 23.0 & \textbf{24.0} & \textbf{0.455} & \textbf{0.547} & \textbf{0.484} \\
        %\cdashline{1-1}[3pt/1pt]
        %\cdashline{3-9}[3pt/1pt]        
        Decap-MSRVTT~\cite{lidecap} & & \checkmark & 23.1 & 23.6 & 34.8 & - & - & - \\
        C\textsuperscript{3}\textsuperscript{$\dagger$}~\cite{zhang2024connect} & & \checkmark & 25.3 & 23.4 & 27.8 & 0.518 & 0.550 & 0.519\\
        \midrule
        Mistral-7B~\cite{jiang2023mistral} & \multirow{3}{*}{\makecell{LLM-based \\ video understanding}} & & 15.3 & \textbf{23.8}  & 19.5  &  0.338 & 0.535  & 0.416 \\
        Video ChatCaptioner~\cite{chen2023video} &  & & 13.2 & 22.0 & 16.5 & 0.396 & 0.510 & 0.436 \\
        %\cdashline{1-1}[3pt/1pt]
        %\cdashline{3-9}[3pt/1pt]
        VidIL\textsuperscript{$\dagger$}~\cite{wang2022language} & & \checkmark  & 13.3 & 20.3 & 19.4 & 0.452 & 0.553 & 0.486 \\
        \midrule
%        \midrule

%        CLIPRe-MSRVTT* & Text retrieval & \checkmark & 10.2 & 18.8 & 19.9 & - & - & - \\
%        \midrule
        MAGIC**~\cite{su2022language} & Inference optimization & & 5.5 & 13.3 & 7.4 & - & - & - \\
        \midrule
        ZeroCap**~\cite{tewel2021zero} & \multirow{2}{*}{\makecell{Test-time \\ optimization}} & & 2.3 & 12.9 & 5.8 & - & - & - \\
        Tewel et al.~\cite{Tewel_2023_BMVC} & &  & 3.0 & 14.6 & 11.3 & 0.280 & 0.391 & 0.319 \\
        
        \bottomrule
    \end{tabular}
	}
\end{table*}
\fi

\iffalse
\begin{table*}[!t]
	\centering
	\small
	\renewcommand{\arraystretch}{1.1}
	\setlength{\tabcolsep}{10pt}
	\caption{Video captioning results on the test set of the MSR-VTT~\cite{xu2016msr-vtt} dataset. 
	\checkmark~indicates whether the method uses the reference captions from the target dataset, MSR-VTT.
	Bold numbers indicate the highest scores among methods that do not utilize reference captions.
	* denotes that the numbers are from~\cite{lidecap}, ** indicates methods were adapted to zero-shot video captioning by Tewel~\etal~\cite{Tewel_2023_BMVC}, and $\dagger$ indicates our reproduced results.}
	\label{table:vc}
	\scalebox{0.85}{
	\begin{tabular}{@{}c|c|c|ccc|ccc@{}}
        \toprule
        Method & Type & Using target data & B@4 & METEOR & CIDEr & $P_{\text{BERT}}$ & $R_{\text{BERT}}$ & $F_{\text{BERT}}$ \\
        \midrule
        \vspace{-0.4cm}
  \\
        %Mistral-7B~\cite{jiang2023mistral} & LLM summarization & & 15.3 & \textbf{23.8}  & 19.5  &  0.338 & 0.535  & 0.416 \\
        Decap-BookCorpus~\cite{lidecap} &  \multirow{6}{*}{\makecell{Text-only \\ training}} & & 6.0 & 12.7 & 12.3 & - & - & - \\
        Decap-CC3M~\cite{lidecap} & & & 6.2 & 14.9 & 15.0 & - & - & - \\
        Decap-COCO~\cite{lidecap} & & & 14.7 & 20.4 & 18.6 & 0.429 & 0.537 & 0.465 \\
        \textbf{SGVC (Ours)} & & & \textbf{17.1} & 23.0 & \textbf{24.0} & \textbf{0.455} & \textbf{0.547} & \textbf{0.484} \\
        \cdashline{1-1}[3pt/1pt]
        \cdashline{3-9}[3pt/1pt]
        Decap-MSRVTT~\cite{lidecap} & \rule{0pt}{10pt} & \checkmark & 23.1 & 23.6 & 34.8 & - & - & - \\
        C\textsuperscript{3}\textsuperscript{$\dagger$}~\cite{zhang2024connect} & &  \checkmark  & 25.3* & 23.4* & 27.8* & 0.518 & 0.550 & 0.519\\
        \midrule
        Mistral-7B~\cite{jiang2023mistral} & \multirow{4}{*}{\makecell{LLM-based \\ video understanding}} & & 15.3 & \textbf{23.8}  & 19.5  &  0.338 & 0.535  & 0.416 \\
        Video ChatCaptioner~\cite{} &  & & 13.2 & 22.0 & 16.5 & 0.396 & 0.510 & 0.436 \\
        \multirow{2}{*}{\makecell{VidIL~\cite{}}} &  & & 3.2 & 14.9 & 2.7 & 0.119 & 0.349 & 0.215 \\
         &  & \checkmark & 13.3 & 20.3 & 19.4 & 0.452 & 0.553 & 0.486 \\
        %VidIL~\cite{} &  & \checkmark & 13.3 & 20.3 & 19.4 & 0.452 & 0.553 & 0.486 \\
        %\midrule
        
        \midrule
        \midrule
        CLIPRe-MSRVTT* & Text retrieval & \checkmark & 10.2 & 18.8 & 19.9 & - & - & - \\
        \midrule
        %ZeroCap** &  \multirow{3}{*}{\makecell{Test-time \\optimization}} & \multirow{3}{*}{} & 2.3 & 12.9 & 5.8 &  &  &   \\
        MAGIC** & Inference optimization &  & 5.5 & 13.3 & 7.4 & - & - & - \\
        \midrule
        ZeroCap**~\cite{tewel2021zero} & \multirow{2}{*}{\makecell{Test-time \\ optimization}}  & & 2.3 & 12.9 & 5.8 & - & - & - \\
        Tewel et al.~\cite{Tewel_2023_BMVC} & &  & 3.0 & 14.6 & 11.3 & 0.280 & 0.391 & 0.319 \\
        \bottomrule
    \end{tabular}
	}
\end{table*}
\fi

\iffalse
\begin{table*}[!t]
	\centering
	\small
	\renewcommand{\arraystretch}{1.1}
	\setlength{\tabcolsep}{10pt}
	\caption{Video captioning results on the test set of the MSR-VTT~\cite{xu2016msr-vtt} dataset. 
	\checkmark indicates whether the method uses MSR-VTT reference captions.
	Bold numbers indicate the highest scores among methods that do not utilize reference captions.
	* denotes that the numbers are from~\cite{lidecap}, ** indicates methods were adapted to zero-shot video captioning by Tewel~\etal~\cite{Tewel_2023_BMVC}, and $\dagger$ indicates our reproduced results.}
	\label{table:vc}
	\scalebox{0.85}{
	\begin{tabular}{@{}c|c|c|ccc|ccc@{}}
        \toprule
        Method & Type & Target dataset & B@4 & METEOR & CIDEr & $P_{\text{BERT}}$ & $R_{\text{BERT}}$ & $F_{\text{BERT}}$ \\
        \midrule
        CLIPRe-MSRVTT* & Text retrieval & \checkmark & 10.2 & 18.8 & 19.9 & - & - & - \\
        \midrule
        %ZeroCap** &  \multirow{3}{*}{\makecell{Test-time \\optimization}} & \multirow{3}{*}{} & 2.3 & 12.9 & 5.8 &  &  &   \\
        MAGIC** & Inference optimization &  & 5.5 & 13.3 & 7.4 & - & - & - \\
        \midrule
        ZeroCap**~\cite{tewel2021zero} & \multirow{2}{*}{\makecell{Test-time \\ optimization}}  & & 2.3 & 12.9 & 5.8 & - & - & - \\
        Tewel et al.~\cite{Tewel_2023_BMVC} & &  & 3.0 & 14.6 & 11.3 & 0.280 & 0.391 & 0.319 \\
        \midrule
        Decap-BookCorpus~\cite{lidecap} &  \multirow{6}{*}{\makecell{Text-only \\ training}} & \multirow{4}{*}{}  & 6.0 & 12.7 & 12.3 & - & - & - \\
        Decap-CC3M~\cite{lidecap} & & & 6.2 & 14.9 & 15.0 & - & - & - \\
        Decap-COCO~\cite{lidecap} & & & 14.7 & 20.4 & 18.6 & 0.429 & 0.537 & 0.465 \\
        \textbf{SGVC (Ours)} & & & \textbf{17.1} & 23.0 & \textbf{24.0} & \textbf{0.455} & \textbf{0.547} & \textbf{0.484} \\
        \cdashline{1-1}[3pt/1pt]
        \cdashline{3-9}[3pt/1pt]
        Decap-MSRVTT~\cite{lidecap} & \rule{0pt}{10pt} & \checkmark & 23.1 & 23.6 & 34.8 & - & - & - \\
        C\textsuperscript{3}\textsuperscript{$\dagger$}~\cite{zhang2024connect} & &  \checkmark  & 25.3* & 23.4* & 27.8* & 0.518 & 0.550 & 0.519\\
        \midrule
        Mistral-7B~\cite{jiang2023mistral} & LLM summarization &  & 15.3 & \textbf{23.8}  & 19.5  &  0.338 & 0.535  & 0.416 \\
        \bottomrule
    \end{tabular}
	}
\end{table*}
\fi
\iffalse
\begin{table*}[!t]
	\centering
	\small
	\renewcommand{\arraystretch}{1.1}
	\setlength{\tabcolsep}{6pt}
	\caption{Video captioning results on the test set of the MSR-VTT~\cite{xu2016msr-vtt} dataset.
	Bold numbers indicate the highest scores among methods that do not utilize reference captions.
	* Numbers are from ~\cite{lidecap}, ** numbers are from ~\cite{Tewel_2023_BMVC}, and $\dagger$ indicates our reproduced results. \sh{do not same numbers are from; mention those methods are originally developed for zeroshot image captioning, but was applied to zeroshot video captioning in~\cite{Tewel_2023_BMVC}. split test-time optimization row, annotation as checkbox, not percentage, llm summarization as method}}
	\label{table:vc}
	\scalebox{0.9}{
	\begin{tabular}{@{}c|c|c|ccc|ccc@{}}
        \toprule
        Method & Type & Target dataset & B@4 & METEOR & CIDEr & $P_{\text{BERT}}$ & $R_{\text{BERT}}$ & $F_{\text{BERT}}$ \\
        \midrule
        CLIPRe-MSRVTT* & Text retrieval & \checkmark & 10.2 & 18.8 & 19.9 &  &  & \\
        \midrule
        ZeroCap** &  \multirow{3}{*}{\makecell{Test-time \\optimization}} & \multirow{3}{*}{} & 2.3 & 12.9 & 5.8 &  &  &   \\
        MAGIC** & &  & 5.5 & 13.3 & 7.4 &  &  &  \\
        Tewel et al.~\cite{Tewel_2023_BMVC} & &  & 3.0 & 14.6 & 11.3 & 0.28 & 0.391 & 0.319 \\
        \midrule
        Decap-BookCorpus~\cite{lidecap} &  \multirow{6}{*}{\makecell{Text-only \\ training}} & \multirow{4}{*}{}  & 6.0 & 12.7 & 12.3 &  &  & \\
        Decap-CC3M~\cite{lidecap} & & & 6.2 & 14.9 & 15.0 &  &  &   \\
        Decap-COCO~\cite{lidecap} & & & 14.7 & 20.4 & 18.6 & 0.429 & 0.537 & 0.465 \\
        \textbf{SGVC (Ours)} & & & \textbf{17.1} & 23.0 & \textbf{24.0} & \textbf{0.455} & \textbf{0.547} & \textbf{0.484} \\
        \cdashline{1-1}[3pt/1pt]
        \cdashline{3-9}[3pt/1pt]
        Decap-MSRVTT~\cite{lidecap} & \rule{0pt}{10pt} & \checkmark & 23.1 & 23.6 & 34.8 &  &  & \\
        C\textsuperscript{3}\textsuperscript{$\dagger$}~\cite{zhang2024connect} & &  \checkmark  & 25.3* & 23.4* & 27.8* & 0.518 & 0.550 & 0.519\\
        \midrule
        Mistral-7B~\cite{jiang2023mistral} & LLM summarization &  & 15.3 & \textbf{23.8}  & 19.5  &  0.338 & 0.535  & 0.416 \\
        \bottomrule
    \end{tabular}
	}
\end{table*}
\fi

\iffalse
\begin{table*}[!t]
	\centering
	\small
	\renewcommand{\arraystretch}{1.1}
	\setlength{\tabcolsep}{6pt}
	\caption{Video captioning results on the test set of the MSR-VTT~\cite{xu2016msr-vtt} dataset.
	Bold numbers indicate the highest scores among methods that do not utilize reference captions.
	* Numbers are from ~\cite{lidecap}, ** numbers are from ~\cite{Tewel_2023_BMVC}, and $\dagger$ indicates our reproduced results. \sh{do not same numbers are from; mention those methods are originally developed for zeroshot image captioning, but was applied to zeroshot video captioning in~\cite{Tewel_2023_BMVC}. split test-time optimization row, annotation as checkbox, not percentage, llm summarization as method}}
	\label{table:vc}
	\scalebox{0.9}{
	\begin{tabular}{@{}c|c|c|ccc|ccc@{}}
        \toprule
        Method & Type & Annotation (\%) & B@4 & METEOR & CIDEr & $P_{\text{BERT}}$ & $R_{\text{BERT}}$ & $F_{\text{BERT}}$ \\
        \midrule
        CLIPRe-MSRVTT* & Text retrieval & 100\% & 10.2 & 18.8 & 19.9 &  &  & \\
        \midrule
        ZeroCap** &  \multirow{3}{*}{\makecell{Test-time \\optimization}} & \multirow{3}{*}{0\%} & 2.3 & 12.9 & 5.8 &  &  &   \\
        MAGIC** & &  & 5.5 & 13.3 & 7.4 &  &  &  \\
        Tewel et al.~\cite{Tewel_2023_BMVC} & &  & 3.0 & 14.6 & 11.3 & 0.28 & 0.391 & 0.319 \\
        \midrule
        Decap-BookCorpus~\cite{lidecap} &  \multirow{6}{*}{\makecell{Text-only \\ training}} & \multirow{4}{*}{0\%}  & 6.0 & 12.7 & 12.3 &  &  & \\
        Decap-CC3M~\cite{lidecap} & & & 6.2 & 14.9 & 15.0 &  &  &   \\
        Decap-COCO~\cite{lidecap} & & & 14.7 & 20.4 & 18.6 & 0.429 & 0.537 & 0.465 \\
        \textbf{SGVC (Ours)} & & & \textbf{17.1} & 23.0 & \textbf{24.0} & \textbf{0.455} & \textbf{0.547} & \textbf{0.484} \\
        \cdashline{1-1}[3pt/1pt]
        \cdashline{3-9}[3pt/1pt]
        Decap-MSRVTT~\cite{lidecap} & \rule{0pt}{10pt} & \multirow{2}{*}{100\%} & 23.1 & 23.6 & 34.8 &  &  & \\
        C\textsuperscript{3}\textsuperscript{$\dagger$}~\cite{zhang2024connect} & & & 25.3* & 23.4* & 27.8* & 0.518 & 0.550 & 0.519\\
        \midrule
        Mistral-7B~\cite{jiang2023mistral} & LLM summarization & 0\% & 15.3 & \textbf{23.8}  & 19.5  &  0.338 & 0.535  & 0.416 \\
        \bottomrule
    \end{tabular}
	}
\end{table*}
\fi

\iffalse
\begin{table*}[!t]
	\centering
	\small
	\renewcommand{\arraystretch}{1.1}
	\setlength{\tabcolsep}{6pt}
	\caption{Video captioning results on the test set of the MSR-VTT~\cite{xu2016msr-vtt} dataset. Bold numbers indicate the highest scores among test-time optimization and text-only training methods that do not use reference captions. * Numbers are from ~\cite{lidecap}, ** numbers are from ~\cite{Tewel_2023_BMVC}, and $\dagger$ indicates our reproduced results. \sh{todos}}
	\label{table:vc}
	\scalebox{0.8}{
	\begin{tabular}{@{}c|c|c|ccc|ccc|cccc@{}}
        \toprule
        %\multirow{2}{*}{Method} & \multirow{2}{*}{Type} & \multirow{2}{*}{\makecell{Annotation \\ Used (\%)}} & \multirow{2}{*}{B4} & \multirow{2}{*}{METEOR} & \multirow{2}{*}{CIDEr} & \multirow{2}{*}{P\textsubscript{BERT}} & \multirow{2}{*}{R\textsubscript{BERT}} & \multirow{2}{*}{F\textsubscript{BERT}} & \multirow{2}{*}{VCLIP-S\textsuperscript{ref}} & \multirow{2}{*}{VCLIP-S} \\
        %& & & & & & & & & & \\ 
	%Method & Type & Annotation (\%) & B@4 & METEOR & CIDEr & P\textsubscript{BERT} & R\textsubscript{BERT} & F\textsubscript{BERT} & VCLIP-S\textsuperscript{ref} & VCLIP-S \\
        Method & Type & Annotation (\%) & B@4 & METEOR & CIDEr & $P_{\text{BERT}}$ & $R_{\text{BERT}}$ & $F_{\text{BERT}}$ & VCLIP-S & TCLIP-S & RefVCLIP-S\\
        %\cdashline{1-11}[.4pt/1pt]
        \midrule
        ZeroCap** &  \multirow{3}{*}{\makecell{Test-time \\optimization}} & \multirow{3}{*}{0\%} & 2.3 & 12.9 & 5.8 &  &  &  &  & &  \\
        MAGIC** & &  & 5.5 & 13.3 & 7.4 &  &  &  &  &  \\
        Tewel et al.~\cite{Tewel_2023_BMVC} & &  & 3.0 & 14.6 & 11.3 & 0.28 & 0.391 & 0.319 & \textbf{0.784} & 0.918 & 0.831 \\
        %\cdashline{1-11}[.4pt/1pt]
        \midrule
        Decap-BookCorpus~\cite{lidecap} &  \multirow{6}{*}{\makecell{Text-only \\ training}} & \multirow{4}{*}{0\%}  & 6.0 & 12.7 & 12.3 &  &  &  &  &  & \\
        Decap-CC3M~\cite{lidecap} & & & 6.2 & 14.9 & 15.0 &  &  &  &  &  \\
        Decap-COCO~\cite{lidecap} & & & 14.7 & 20.4 & 18.6 & 0.429 & 0.537 & 0.465 & 0.719 & \textbf{0.997} & 0.835 \\
        \textbf{SGVC (Ours)} & & & \textbf{17.1} & \textbf{23.0} & \textbf{24.0} & \textbf{0.455} & \textbf{0.547} & \textbf{0.484} & 0.75 & 0.971 & \textbf{0.841} \\
        \cdashline{1-1}[3pt/1pt]
        \cdashline{3-12}[3pt/1pt]
        Decap-MSRVTT~\cite{lidecap} & \rule{0pt}{10pt} & \multirow{2}{*}{100\%} & 23.1 & 23.6 & 34.8 &  &  &  &  & &  \\
        C\textsuperscript{3}\textsuperscript{$\dagger$}~\cite{zhang2024connect} & & & 25.3* & 23.4* & 27.8* & 0.518 & 0.550 & 0.519 & 0.732 & 0.995 & 0.842 \\
        \midrule
        CLIPRe-MSRVTT* & Text retrieval & 100\% & 10.2 & 18.8 & 19.9 &  &  &  &  &  & \\
        \midrule
        Mistral-7B~\cite{jiang2023mistral} & LLM summarization & 0\% & 15.3 & 23.8  & 19.5  &  0.338 & 0.535  & 0.416 & 0.748 & 0.982 & \sh{0.844} \\
        \bottomrule
    \end{tabular}
	}
\end{table*}

\begin{table*}[!t]
	\centering
	\small
	\renewcommand{\arraystretch}{1.1}
	\setlength{\tabcolsep}{6pt}
	\caption{Video captioning results on the test set of the MSR-VTT~\cite{xu2016msr-vtt} dataset. * Numbers are from ~\cite{Tewel_2023_BMVC}, ** numbers are from ~\cite{lidecap}, and $\dagger$ indicates our reproduced results. \sh{todos}}
	\label{table:vc}
	\scalebox{0.8}{
	\begin{tabular}{@{}c|c|c|ccc|ccc|cccc@{}}
        \toprule
        %\multirow{2}{*}{Method} & \multirow{2}{*}{Type} & \multirow{2}{*}{\makecell{Annotation \\ Used (\%)}} & \multirow{2}{*}{B4} & \multirow{2}{*}{METEOR} & \multirow{2}{*}{CIDEr} & \multirow{2}{*}{P\textsubscript{BERT}} & \multirow{2}{*}{R\textsubscript{BERT}} & \multirow{2}{*}{F\textsubscript{BERT}} & \multirow{2}{*}{VCLIP-S\textsuperscript{ref}} & \multirow{2}{*}{VCLIP-S} \\
        %& & & & & & & & & & \\ 
	%Method & Type & Annotation (\%) & B@4 & METEOR & CIDEr & P\textsubscript{BERT} & R\textsubscript{BERT} & F\textsubscript{BERT} & VCLIP-S\textsuperscript{ref} & VCLIP-S \\
        Method & Type & Annotation (\%) & B@4 & METEOR & CIDEr & $P_{\text{BERT}}$ & $R_{\text{BERT}}$ & $F_{\text{BERT}}$ & VCLIP-S & TCLIP-S & RefVCLIP-S\\
        \midrule
        Decap-BookCorpus~\cite{lidecap} &  \multirow{6}{*}{\makecell{Text-only \\ training}} & \multirow{4}{*}{0\%}  & 6.0 & 12.7 & 12.3 & - & - & - & - & - & - \\
        Decap-CC3M~\cite{lidecap} &  &  & 6.2 & 14.9 & 15.0 & - & - & - & - & - & - \\
        Decap-COCO~\cite{lidecap} & &  & 14.7 & 20.4 & 18.6 & 0.429 & 0.537 & 0.465 & 0.719 & \textbf{0.997} & 0.835 \\
        \textbf{SGVC (Ours)} &  &  & \textbf{17.1} & \textbf{23.0} & \textbf{24.0} & \textbf{0.455} & \textbf{0.547} & \textbf{0.484} & 0.75 & 0.971 & \textbf{0.841} \\
        \cdashline{1-1}[.4pt/1pt]
        \cdashline{3-12}[.4pt/1pt]
        Decap-MSRVTT~\cite{lidecap} & \rule{0pt}{10pt} & \multirow{2}{*}{100\%} & 23.1 & 23.6 & 34.8 & - & - & - & - & - & - \\
        C\textsuperscript{3}\textsuperscript{$\dagger$}~\cite{zhang2024connect} & & & 25.3* & 23.4* & 27.8* & 0.518 & 0.550 & 0.519 & 0.732 & 0.995 & 0.842 \\
        \midrule
        \midrule
        ZeroCap* &  \multirow{3}{*}{\makecell{Test-time \\optimization}} & \multirow{3}{*}{0\%} & 2.3 & 12.9 & 5.8 & - & - & - & - & - & - \\
        MAGIC* & &  & 5.5 & 13.3 & 7.4 & - & - & - & - & - & - \\
        Tewel et al.~\cite{Tewel_2023_BMVC} & &  & 3.0 & 14.6 & 11.3 & 0.28 & 0.391 & 0.319 & \textbf{0.784} & 0.918 & 0.831 \\
        \midrule
        \midrule
        CLIPRe-MSRVTT** & Text retrieval & 100\% & 10.2 & 18.8 & 19.9 & - & - & - & - & - & - \\
        \midrule
        Mistral-7B~\cite{jiang2023mistral} & LLM summarization & 0\% & 15.3 & 23.8  & 19.5  &  0.338 & 0.535  & 0.416 & 0.748 & 0.982 & 0.844 \\
        %\cdashline{1-11}[.4pt/1pt]
        %\cdashline{1-11}[.4pt/1pt]
        \bottomrule
    \end{tabular}
	}
\end{table*}
%

\begin{table*}[!t]
	\centering
	\small
	\renewcommand{\arraystretch}{1.0}
	\setlength{\tabcolsep}{8pt}
	\caption{Video captioning results on the test set of the MSR-VTT~\cite{xu2016msr-vtt} dataset. * Numbers are from ~\cite{lidecap}, ** numbers are from ~\cite{Tewel_2023_BMVC}, and $\dagger$ indicates our reproduced results. \sh{todos}}
	\label{table:vc}
	\resizebox{1.0\textwidth}{!}{
	\begin{tabular}{@{}c|c|c|ccc|ccc|cccc@{}}
        \toprule
        %\multirow{2}{*}{Method} & \multirow{2}{*}{Type} & \multirow{2}{*}{\makecell{Annotation \\ Used (\%)}} & \multirow{2}{*}{B4} & \multirow{2}{*}{METEOR} & \multirow{2}{*}{CIDEr} & \multirow{2}{*}{P\textsubscript{BERT}} & \multirow{2}{*}{R\textsubscript{BERT}} & \multirow{2}{*}{F\textsubscript{BERT}} & \multirow{2}{*}{VCLIP-S\textsuperscript{ref}} & \multirow{2}{*}{VCLIP-S} \\
        %& & & & & & & & & & \\ 
	%Method & Type & Annotation (\%) & B@4 & METEOR & CIDEr & P\textsubscript{BERT} & R\textsubscript{BERT} & F\textsubscript{BERT} & VCLIP-S\textsuperscript{ref} & VCLIP-S \\
        Method & Type & Annotation (\%) & B@4 & METEOR & CIDEr & $P_{\text{BERT}}$ & $R_{\text{BERT}}$ & $F_{\text{BERT}}$ & VCLIP-S & TCLIP-S & RefVCLIP-S\\
        \midrule
        CLIPRe-MSRVTT* & Text retrieval & 100\% & 10.2 & 18.8 & 19.9 &  &  &  &  &  & \\
        %\cdashline{1-11}[.4pt/1pt]
        \midrule
        ZeroCap** &  \multirow{3}{*}{\makecell{Test-time \\optimization}} & \multirow{3}{*}{0\%} & 2.3 & 12.9 & 5.8 &  &  &  &  & &  \\
        MAGIC** & &  & 5.5 & 13.3 & 7.4 &  &  &  &  &  \\
        Tewel et al.~\cite{Tewel_2023_BMVC} & &  & 3.0 & 14.6 & 11.3 & 0.28 & 0.391 & 0.319 & \textbf{0.784} & 0.918 & 0.831 \\
        %\cdashline{1-11}[.4pt/1pt]
        \midrule
        Decap-BookCorpus~\cite{lidecap} &  \multirow{6}{*}{\makecell{Text-only \\ training}} & \multirow{4}{*}{0\%}  & 6.0 & 12.7 & 12.3 &  &  &  &  &  & \\
        Decap-CC3M~\cite{lidecap} & & & 6.2 & 14.9 & 15.0 &  &  &  &  &  \\
        Decap-COCO~\cite{lidecap} & & & 14.7 & 20.4 & 18.6 & 0.429 & 0.537 & 0.465 & 0.719 & \textbf{0.997} & 0.835 \\
        \textbf{SGVC (Ours)} & & & \textbf{17.1} & \textbf{23.0} & \textbf{24.0} & \textbf{0.455} & \textbf{0.547} & \textbf{0.484} & 0.75 & 0.971 & \textbf{0.841} \\
        \cdashline{1-1}[.4pt/1pt]
        \cdashline{3-12}[.4pt/1pt]
        Decap-MSRVTT~\cite{lidecap} & \rule{0pt}{10pt} & \multirow{2}{*}{100\%} & 23.1 & 23.6 & 34.8 &  &  &  &  & &  \\
        C\textsuperscript{3}\textsuperscript{$\dagger$}~\cite{zhang2024connect} & & & 25.3* & 23.4* & 27.8* & 0.518 & 0.550 & 0.519 & 0.732 & 0.995 & 0.842 \\
        \midrule
        Mistral-7B~\cite{jiang2023mistral} & LLM summarization & 0\% & 15.3 & 23.8  & 19.5  &  0.338 & 0.535  & 0.416 & 0.748 & 0.982 & 0.844 \\
        \bottomrule
    \end{tabular}
	}
\end{table*}
\fi