% !TEX root = ../main.tex

\clearpage
\section{Prompt Instructions} 
\label{appendix_sec:prompt}
\paragraph{Frame caption generation} 
Table~\ref{appendix_tab:imageVLM_fc_prompt} lists the instructional prompts, generated using ChatGPT-4, which guide the image VLM to generate the frame captions.
These prompts are designed to keep captions grounded in the visible content of the image, avoiding factual inaccuracies, unsupported details, or fabricated information.
A prompt was randomly selected for each frame, allowing captions to reflect diverse aspects of a video.
For all experiments, we employed LLAVA-NEXT-7B~\cite{liu2024llavanext} as a backbone model for caption generation.
%
\begin{table*}[h]
	\centering
	\small
	\caption{The list of instructional prompts for frame caption generation using an imageVLM.}
	\vspace{3mm}
	\label{appendix_tab:imageVLM_fc_prompt}
	\scalebox{0.95}{
		\fbox{
		    \begin{minipage}{0.8\linewidth}
		    {\linespread{1.2}\selectfont
		    \textbullet\ “Please describe what is happening in the image using one simple sentence. Focus only on what is visible.'' \par
   		    \textbullet\ “Now, provide a single sentence caption that describes only what is explicitly shown in the image” \par
   		    \textbullet\ “In one sentence, describe what you see in the image without adding any extra details.” \par
		    \textbullet\ “Provide a concise one-sentence description of the image, focusing on only the visible elements.” \par
  		    \textbullet\ “Please give a one-sentence caption that includes only what is clearly shown in the image.” \par
   		    \textbullet\ “Describe what is happening in the image in one simple sentence, without any added information.” \par
  		    \textbullet\ “Please generate a single sentence caption that describes only what can be seen in the image.” \par
  		    \textbullet\ “Provide a one-sentence description of the image, focusing solely on what is shown.” \par
		    \textbullet\ “Now, give a brief, one-sentence caption based strictly on the visible content in the image.” \par
  		    \textbullet\ “In a single sentence, describe what the image shows, without including anything extra.” \par
		    }
		    \end{minipage}
		}
	}
\end{table*}
%
\paragraph{LLM summarization} 
To construct the LLM summarization baseline in our experiments, we designed the prompts by combining the instructional prompt and example frame captions as illustrated in Table~\ref{appendix_tab:llm_summ_prompt}.
This inputs guide the LLM to generate a concise and coherent video-level summary. 
We used Mistral-7B-Instruct-v0.3 for this summarization task.
%
\begin{table*}[h]
	\centering
	\small
	\caption{Illustration of the input construction for LLM summarization, consisting of the instructional prompt and frame captions. We show an example for the frame captions.}
	\vspace{3mm}
	\label{appendix_tab:llm_summ_prompt}
	\scalebox{0.95}{
		\fbox{
			\begin{minipage}{0.9\linewidth}
			{\linespread{1.2}\selectfont
			\textbf{Instructional prompt:} \par
			Below are captions generated from individual frames of a video, each describing specific moments. Please review these frame-by-frame captions and summarize them into a single, compact caption. \par
			\par
			\textbf{Frame captions:} \par
			[1 / 6] A woman in a blue jacket is sitting in front of a sports logo. \par
			[2 / 6] Woman in blue jacket standing outdoors. \par
			[3 / 6] A man in a military uniform is standing in front of a navy sign. \par
			[4 / 6] Man in military uniform standing in front of navy sign. \par
			[5 / 6] The image shows three women wearing sports uniforms and holding medals, smiling and posing for the camera.\par
			[6 / 6] Three women wearing blue and white uniforms, smiling and holding medals. \par
			}
			\end{minipage}
		}
	}
\end{table*}
%