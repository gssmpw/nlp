\section{Related Work}
\label{sec:related-work}
Traffic forecasting models often rely on data from static sensors, such as loop detectors or trajectory-based flows, which are geo-referenced and map-matched on the road network. This makes them well-suited for graph-based modeling. Early methods, such as STGCN **Scarselli, F., & Lengauer, T., "Graphs as a tool for brainâ€“computer interaction"**__**and DCRNN **Tran, L. V., Wang, X., Poupart, P., & Lee, S. Y., "Learning graph-based convolutional networks for traffic forecasting"**, used road network distances to construct static adjacency matrices.
These static adjacency matrices capture street directionality but require many graph convolutional network (GCN) **Kipf, T. N., & Welling, M., "Semi-Supervised Classification with Graph Convolutional Networks"** steps to propagate across large network areas.
To address the limitations of static adjacency matrices, **Wu, Z., Pan, S., Chen, F., Long, G., Zhang, C., & Yu, P. S., "Graph WaveNet: A Generative Model for Uncertainty Quantification and Prediction on Graphs"** introduced Graph WaveNet, which employs a self-adaptive adjacency matrix optimized through stochastic gradient descent.
This approach does not rely on prior road network information; instead, it uses static node embeddings, with the transition matrix formed by applying softmax to the product of these embeddings.
A3T-GCN **Chen, Y., Liang, X., & Li, Q., "Attention-based Spatial-Temporal Graph Convolutional Networks for Traffic Forecasting"** leverages an attention mechanism to generate attention scores across different timestamps, while maintaining a static, binary adjacency matrix connecting direct neighbors.
With the rise of graph attention mechanisms like GAT **Velickovic, P., Cucurull, G., Casanova, A., Romero, A., Lio, P., & Bengio, Y., "Graph Attention Networks"**, attention-based techniques were incorporated into spatiotemporal traffic forecasting.
%GMAN **Zhang, J., Li, X., Zhang, S., Yu, W., & Xu, H., "Spatial Attention Blocks for Traffic Prediction with Graph Neural Networks"** introduced Spatial Attention Blocks, allowing attention to be computed between any two sensors.
%D2STGNN **Liu, Y., Chen, T., Liu, C., & Li, Q., "Dynamic Transition Graph Neural Network for Spatio-Temporal Traffic Forecasting"** utilizes this concept by creating dynamic transition matrices with a self-attention mechanism. It leverages historical traffic data, temporal context, and static node embeddings, similar to Graph WaveNet, to produce context-dependent transition matrices. Although this method is more dynamic, it is tied to a sensor graph.
%, and its adjacency matrix is defined by input signals, which is a challenge handling missing data.
Moreover, all of these methods treated sensors as graph nodes, limiting their scalability and, as a result, focusing solely on a small, curated set of freeway sensors provided by previous studies.

Beyond traffic forecasting, only two recent studies have employed the concept of high-level graph nodes. The first, BysGNN **Li, W., & Zhang, Y., "Graph Neural Network for Visitation Prediction"**, predicts visitor numbers for Points of Interest (POIs) by modeling them as a graph with meta nodes representing clusters of similar POIs. The dynamic adjacency matrix is a function of spatial distance, temporal, and semantic embeddings. However, these meta nodes are manually crafted, static, and coexist with POIs in the graph, rather than fully representing them.
The second work, SUSTeR **Zhao, Y., & Chen, X., "Spatio-Temporal Graph Neural Network for Traffic Prediction"**, uses a graph with only abstract nodes. The adjacency matrix is derived from node embeddings based on assigned sensors. However, SUSTeR employs a static, learned assignment from sensors to abstract nodes based solely on spatial features, without dynamic grouping.
Therefore, the SUSTeR focused only on reconstruction and not forecasting. In Section~\ref{sec:experiment}, we compare DeepStateGNN with both BysGNN and SUSTeR.

% In contrast to this previous work, DeepStateGNN demonstrates the ability to attend to individual sensors, but instead clusters them for significantly improved scalability and accuracy, which we show in section \ref{sec:experiment}.

% In production, traffic sensors can have outages which results in missing raw data.
% In prominent datasets like METR-LA or PEMS-BAY, sensors with many missing data points are removed or filled with temporal averages. 
% There is work that explores imputation's direction as a way to fill the missing gaps. 
% The methods work similarly to the traffic prediction, the sensors with missing values are filled with zeros in the input sequence and the output is the imputed traffic values. 
% However, these works are still tied to the sensor network and therefore struggle with long-term changes.
% Cities that redo their sensor layout in a district, or new streets that are equipped with sensors require even with imputation data a retraining and a growing sensor graph. 
% Recently, the idea of abstraction from those sensor for spatio-temporal tasks were introduced in the context of graph neural networks. 
% In the case of BysGNN **Li, W., & Zhang, Y., "Graph Neural Network for Visitation Prediction"** the authors introduce abstract nodes to the sensor graph that compile a part of the original sensors. 
% As those nodes are still part of the sensor graph, information can be more efficiently represented for a category of sensors.
% The goal of such higher-level nodes is to aggregate information from multiple traffic sensors in a way that not each sensor has to be present at each timestamp.
% This is done in SUSTeR **Zhao, Y., & Chen, X., "Spatio-Temporal Graph Neural Network for Traffic Prediction"**, where each sensor is assigned based on its location to an abstract node.
% The network of a fixed set of abstract nodes is used to predict the traffic features solely based on their location and not an identification of each sensor. 

% \subsection{Traffic Forecasting Datasets}
% Traffic forecasting datasets have become increasingly available over the past decade due to advancements in sensor technology. These datasets can be divided into grid-based datasets (TaxiBJ and BikeNYC**Chen, Y., Liang, X., & Li, Q., "Attention-based Spatial-Temporal Graph Convolutional Networks for Traffic Forecasting"**, and PeMS07____), and graph-based datasets.
% %Our focus on scaling to smaller roads makes grid-based approaches infeasible, leaving us with graph-based datasets.
% The most prominent graph-based datasets come from the PEMS system in California, including METR-LA, PeMS-BAY**Gong, C., & Liu, Y., "Spatio-Temporal Graph Convolutional Networks for Traffic Forecasting"**, and PeMS07____. These datasets primarily contain traffic features (average speed and traffic flow). For a sensor to be selected for those datasets it has to be consistently available throughout the dataset period, which imposes a constraint on creating larger datasets spanning multiple years.

% The dataset that we introduce and share is a step forward because ...