\section{Theoretical Analysis}
\label{sec:theoretical_analysis}
We outline the benefits of grouping tasks with positive inter-task affinity and updating them in multi-task optimization in \Cref{theorem1} and \Cref{theorem2}. We validate the feasibility of tracking proximal inter-task affinity and forming task groups based on this in our grouping updates strategy in \Cref{theorem3}. In this section, we clarify why, from the viewpoint of standard convergence analysis in \Cref{theorem4}, it's difficult to demonstrate that updating task groups sequentially leads to better performance than joint learning. We then explore how sequentially updating grouped task sets can improve multi-task performance, as discussed in \Cref{theorem5}.

\subsection{Convergence Analysis}
We perform conventional convergence analysis to determine the convergence points of the sequential updates of task groups, as outlined in \Cref{theorem4}. Conventional analyses treat the learning of shared and task-specific parameters separately, which fails to explain why sequential updates result in better multi-task performance while maintaining comparable stability.

%-------------------------------------------------------------------------
\begin{restatable}[Convergence Analysis]{theorem}{theomfour}
\label{theorem4}
Given a set of differentiable losses $\{\mathcal{L}_i\}_{i=1}^{\mathcal{K}}$ and Lipschitz continuous gradients with a constant $H>0$, $||\nabla \mathcal{L}_i (x) - \nabla \mathcal{L}_i (y)|| \leq H||x-y||$ for all $i=1,2,...,\mathcal{K}$. If we sequentially update task groups $\{G_i\}_{i=1}^{\mathcal{M}}$ based on inter-task affinity, employing a sufficiently small step size $\eta \leq \min(\frac{2}{H\mathcal{K}}, \frac{1}{H|G_m|})$ where $|G_m|$ is the number of tasks in $G_m$, then the following inequalities are satisfied for any task group $G_m$.
\begin{align}
    \sum_{k=1}^{\mathcal{M}} \mathcal{L}_{G_k}(z^t, &\Theta_{s|G_m}^{t+m/\mathcal{M}}, \Theta_{G_k}^{t+1}) 
    \leq \sum_{k=1}^{\mathcal{M}} \mathcal{L}_{G_k}(z^t, \Theta_{s|G_m}^{t+(m-1)/\mathcal{M}}, \Theta_{G_k}^t)\\
    &-\eta g_{s, G_m}^{t+(m-1)/\mathcal{M}} \cdot (\sum_{k=1}^{\mathcal{M}} g_{s, G_k}^{t+(m-1)/\mathcal{M}} - g_{s, G_m}^{t+(m-1)/\mathcal{M}}) - \frac{\eta}{2}||g_{ts, G_m}^t||^2
\end{align}
\end{restatable}
where $g_{s,G_m}$ and $g_{ts,G_m}$ represent the gradients of the shared parameters and task-specific parameters, respectively, for group $G_m$. Previous approaches, which handle updates of shared and task-specific parameters independently, failing to capture their interdependence during optimization.
The term, $g_{s, G_m}^{t+(m-1)/\mathcal{M}} \cdot (\sum_{k=1}^{\mathcal{M}} g_{s, G_k}^{t+(m-1)/\mathcal{M}})$, fluctuates during optimization. When the gradients of group $G_m$ align well with the gradients of the other groups $\{G_k\}_{i=1, i\neq m}^{\mathcal{M}}$, their dot product yields a positive value, leading to a decrease in multi-task losses. In practice, the sequential update strategy demonstrates a similar level of stability in optimization, which appears to contradict the conventional results. Thus, we assume a correlation between the learning of shared parameters and task-specific parameters, where the learning of task-specific parameters reduces gradient conflicts in shared parameters. Under this assumption, the sequential update strategy can guarantee convergence to Pareto-stationary points. This assumption is reasonable, as task-specific parameters capture task-specific information, thereby reducing conflicts in the shared parameters across tasks.

\subsection{Advantages of Selective Task Group Updates}
Nonetheless, sequentially updating task groups facilitates the learning of task-specific parameters, a concept not covered by conventional analysis. We directly compare the loss of joint learning with the loss of the sequential group updates strategy. To do this, we introduce two-step proximal inter-task affinity, an expanded concept of proximal inter-task affinity over multiple steps, as defined in \Cref{Append:two_step_proximal_inter_task_affinity}. We analyze the benefits of sequential updates using this two-step proximal inter-task affinity based on the plausible assumptions delineated in \Cref{theorem5}.
\begin{restatable}[]{theorem}{theomfive}
\label{theorem5}
Consider three tasks $\{i, j, k\}$, where task groups are formed with positive inter-task affinity as $\{i, k\}$ and $\{j\}$. Assume all losses are convex and differentiable, and the change in affinity during a single step from $t+(m-1)/\mathcal{M}$ to $t+m/\mathcal{M}$ is negligible. The affinity, which learns all tasks jointly, is denoted as $\mathcal{B}_{i,j,k \rightarrow k}^{t+(m-1)/\mathcal{M}}$. The affinity for the updating sequence $(\{i, k\}$, $\{j\})$ is represented as $\mathcal{B}_{i,k; j \rightarrow k}^{t+(m-1)/\mathcal{M}}$, while for the sequence $(\{j\}$, $\{i, k\})$, it is represented as $\mathcal{B}_{j; i,k \rightarrow k}^{t+(m-1)/\mathcal{M}}$. Then, for a sufficiently small learning rate $\eta \ll 1$, the following holds:
\begin{align}
    \mathcal{B}_{i,j,k \rightarrow k}^{t+(m-1)/\mathcal{M}} &\simeq \mathcal{B}_{i,k; j \rightarrow k}^{t+(m-1)/\mathcal{M}} & \mathcal{B}_{i,j,k \rightarrow k}^{t+(m-1)/\mathcal{M}} &\leq \mathcal{B}_{j; i,k \rightarrow k}^{t+(m-1)/\mathcal{M}}
\end{align}
\end{restatable}

This suggests that grouping tasks with proximal inter-task affinity and subsequently updating these groups sequentially result in lower multi-task loss compared to jointly backpropagating all tasks. This disparity arises because the network can discern superior task-specific parameters to accommodate task-specific information during sequential learning. Notably, the order in which tasks are updated impacts multi-task outcomes within a single batch. However, as the optimization progresses, this influence diminishes, as demonstrated in the following experimental results.