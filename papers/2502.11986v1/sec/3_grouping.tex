\section{Selective Task Group Updates for Multi-Task Optimization}
\subsection{The Goal of Multi-Task Learning and Inter-Task Affinity}
\label{sec:problem_def}
In the context of MTL, we deal with multiple tasks with its own objective function denoted as $\{\mathcal{L}_i\}_{i=1}^{\mathcal{K}}$, where $\mathcal{K}$ represents the number of tasks. The network parameters $\Theta$ are partitioned into $\{\Theta_s, \Theta_1, \Theta_2, \ldots, \Theta_\mathcal{K}\}$, where $\Theta_s$ refers to the shared parameters while $\Theta_i$ represents the task-specific parameters for the task $i$. To simplify the discussion, we assumed that $\Theta_s$ is shared across all tasks. However, the following discussion can still apply even when it is only partially shared for specific task sets. The goal of MTL is to find Pareto-optimal parameters \citep{RN36}, denoted as $\Theta^*$, that minimize the weighted sum of task-specific losses. This can be expressed as $\Theta^* = \argmin_{\Theta}\sum_{i=1}^{\mathcal{K}} w_i\mathcal{L}_i(\Theta_s, \Theta_i)$, where $w_i$ represents the weight for the loss of task $i$.

The concept of inter-task affinity \citep{fifty2021efficiently} aims to identify tasks that enhance each other's performance when learned together on shared networks. It measures the extent to which the gradient of a specific task with respect to the shared parameters $\Theta_s$, affects the loss of other tasks.

% -------------------------------------------------------------------------
\begin{definition}[Inter-Task Affinity] Consider a multi-task network shared by tasks $i$ and $k$. For a data sample $z^t$ and a learning rate $\eta$, the task-specific gradients from $\mathcal{L}_i$ are applied to update the shared parameters of the network as follows: $\Theta_{s|i}^{t+1} = \Theta_s^t -\eta \nabla_{\Theta_s^t} \mathcal{L}_i (z^t, \Theta_s^t, \Theta_i^t)$. The inter-task affinity from task $i$ to task $k$ at time step $t$ is then defined as:
\begin{align}
    \mathcal{A}^t_{i\rightarrow k} = 1- \frac{\mathcal{L}_k(z^t, \Theta_{s|i}^{t+1}, \Theta_k^t)}{\mathcal{L}_k(z^t, \Theta_{s}^{t}, \Theta_k^t)}
    \label{definition:inter_task_affinity}
\end{align}
\end{definition}

In the context of task grouping \citep{fifty2021efficiently}, task affinity is computed and utilized in two stages. Initially, task affinity within a shared network is assessed by monitoring how the loss for each task changes when updating the loss of the other task at each step. Subsequently, using the averaged task affinity, task groups are organized, and each group is trained in separate networks. However, directly incorporating inter-task affinity for multi-task optimization presents several challenges. First, it only tracks the learning of shared parameters, $\Theta_s$, and their influence on task losses, without considering task-specific parameters, $\{\Theta_i\}_{i=1}^{\mathcal{K}}$. In practice, both shared and task-specific parameters need to be optimized simultaneously. Second, since inter-task affinity fluctuates significantly during optimization, it must be tracked continuously to capture evolving task relations. This process is computationally expensive, requiring recursive gradient updates, monitoring loss changes, and reverting to previous parameter states.

\subsection{Proximal Inter-Task Affinity for Multi-Task Optimization}
\label{sec:track_prox}
To address the issues mentioned above, we propose practical methods based on the concept of proximal inter-task affinity to track task relations and use this information for concurrent multi-task optimization. Firstly, we integrate the learning of task-specific parameters into the estimation of inter-task affinity to incorporate this affinity into ongoing optimization. Secondly, we extend the concept of inter-task affinity to elucidate relations between task groups rather than individual pairs of tasks. This allows us to monitor these affinities when a set of tasks is collectively backpropagated. Practically, proximal inter-task affinity serves as an approximation of inter-task affinity; however, it also plays a crucial role in theoretical analysis, as discussed in \Cref{sec:theoretical_analysis}, explaining why updating task groups sequentially yields distinct multi-task performance. To be specific, we lay out guidelines for updating proximal inter-task affinity by distinguishing between inter-group relations and intra-group relations. We then incorporate the concept of proximal inter-task affinity to explore the task update strategy, grouping tasks based on their affinity, which has a significant impact on multi-task performance.

Before delving into the algorithm, let's establish some notations building upon those introduced in \Cref{sec:problem_def}. Our objective is to partition tasks into several groups, denoted as $\{G_1,G_2,...,G_{\mathcal{M}}\}$, where $\mathcal{M}$ is the number of task groups. Each group set contains tasks' indices as their components, for example, $G_k=\{i,j\}$. When selecting tasks to form these groups, we require the task groups to be mutually exclusive, meaning that $G_i \cap G_j = \emptyset$ for any $i$ and $j$ ($i \neq j$).

Tracking inter-task affinity during optimization, as defined in \cref{definition:inter_task_affinity}, is impractical. This is because it is difficult to assess the influence of individual tasks on shared network parameters when multiple tasks are updated simultaneously. Additionally, task-specific parameters $\{\Theta_i\}_{i=1}^{\mathcal{K}}$ must also be updated concurrently, which is essential for MTL settings. Therefore, we practically approximate inter-task affinity by utilizing proximal inter-task affinity, taking into account updates of multiple tasks with task-specific parameters. The difference between inter-task affinity and proximal inter-task affinity is difficult to detect, so we provide a more detailed discussion in \Cref{Append:differeence_affinity}.

%-------------------------------------------------------------------------
\begin{definition}[\textbf{Proximal Inter-Task Affinity}] Consider a multi-task network shared by the task set $G$, with their respective losses defined as $\mathcal{L}_G$. For a data sample $z^t$ and a learning rate $\eta$, the gradients of task set $G$ are updated to the parameters of the network as follows: $\Theta_{s|G}^{t+1} = \Theta_s^t -\eta \nabla_{\Theta_s^t} \mathcal{L}_G (z^t, \Theta_s^t, \Theta_G^t)$ and $\Theta_k^{t+1} = \Theta_k^t -\eta \nabla_{\Theta_k^t} \mathcal{L}_k (z^t, \Theta_s^t, \Theta_k^t)$ for $k \in G$. Then, the proximal inter-task affinity from the task set $G$ to $\tau_k$ at time step $t$ is defined as:
\begin{align}
    \mathcal{B}^t_{G\rightarrow k} = 1- \frac{\mathcal{L}_k(z^t, \Theta_{s|G}^{t+1}, \Theta_k^{t+1})}{\mathcal{L}_k(z^t, \Theta_{s}^{t}, \Theta_k^t)}
\end{align}
\end{definition}
%-------------------------------------------------------------------------

As it's not feasible to simultaneously track inter-task affinity and optimize networks, we instead track the proximal inter-task affinity and utilize it for multi-task optimization. We explain the benefits of integrating inter-task affinity into optimization in the view of conventional multi-task optimization. \Cref{theorem1} suggests that grouping tasks with high inter-task affinity leads to better alignment of their gradients compared to grouping tasks with lower affinity. In analysis, we use the extended version of $\mathcal{A}$ for multiple tasks (e.g., $\mathcal{A}_{G\rightarrow k}$) for ease of notation.

\begin{restatable}[]{theorem}{theomone}
\label{theorem1}
Let $g_k$ denote the task-specific gradients backpropagated from the loss function $\mathcal{L}_k$ with respect to the parameters $\Theta_s^t$. At a given time step $t$, if the inter-task affinity from task group $\{i, k\}$ to task $k$ is greater than or equal to the inter-task affinity from group $\{j, k\}$ to task $k$, denoted as $A_{i,k \rightarrow k}^t \geq A_{j,k \rightarrow k}^t$. Then for a sufficiently small learning rate $\eta \ll 1$, it follows that $g_i \cdot g_k \geq g_j \cdot g_k$.
\end{restatable}
The results also apply to proximal inter-task affinity $\mathcal{B}$ instead of $\mathcal{A}$, as the only difference is the inclusion of task-specific parameters for task $k$.


We analyze how this alignment in task-specific gradients reduces the loss of task $k$ in \Cref{theorem2}.
%-------------------------------------------------------------------------
\begin{restatable}[]{theorem}{theomtwo}
\label{theorem2}
Let $g_k$ denote the task-specific gradients backpropagated from the loss function $\mathcal{L}_k$ with respect to the parameters $\Theta_s^t$. Let $\Theta_{s|k}^{t+1}$ represent the updated parameters after applying the gradients. Assume that for tasks $i$, $j$, and $k$, the inequality $g_i \cdot g_k \geq g_j \cdot g_k$ holds. Then, for a sufficiently small learning rate $\eta \ll 1$, the inequality  $\mathcal{L}_k (z^t, \Theta_{s|i,k}^{t+1}, \Theta_k^t) \leq \mathcal{L}_k (z^t, \Theta_{s|j,k}^{t+1}, \Theta_k^t)$ holds.
\end{restatable}
The result indicates that when the gradients $g_i$ align better with $g_k$ than with $g_j$, the loss on the reference task $k$ using the updated gradients $g_i + g_k$ is lower than that using the updated gradients $g_j + g_k$. \Cref{theorem1,theorem2} suggest that updating tasks jointly with high proximal inter-task affinity at each optimization step is a reasonable approach.


\subsection{Tracking Proximal Inter-Task Affinity in Selective Group Updates}
From now on, we'll explain how we track proximal inter-task affinity in the sequential updates of task groups. For ease of explanation, we start with an already clustered (or initialized) task set $\{G_i\}_{i=1}^{\mathcal{M}}$ obtained from the tracked proximal inter-task affinity in the previous time step. $\mathcal{M}$ is the number of task groups. We'll provide more explanation at the end of this section on how the tracked proximal inter-task affinity is utilized in clustering the task set.

\textbf{Inter-Group Relations.} We begin by forwarding the sample $z^t$ to the shared multi-task network, from which we obtain the multi-task loss $\{\mathcal{L}_i (z^t, \Theta_s^t, \Theta_i^t)\}_{i=1}^{\mathcal{K}}$. Based on the task grouping $\{G_i\}_{i=1}^{\mathcal{M}}$, we divide each time step into $\mathcal{M}$ steps to update each task set. For simplicity of discussion, we update the first group $G_1$ in steps from $t$ to $t+1/\mathcal{M}$, but the following discussion can be extended to all sequential updates between $t$ and $t+1$.
\begin{align}
    \Theta_{s|G_1}^{t+1/\mathcal{M}} = \Theta_s^t-\eta \sum_{i \in G_1} w_i \nabla_{\Theta_s^t} \mathcal{L}_i(z^t, \Theta_s^t, \Theta_i^t)
\end{align}
$\Theta_{s|G_1}^{t+1/\mathcal{M}}$ represents the resulting parameter after updating the gradient from task group $G_1$ to the parameter $\Theta_s^t$. Upon forwarding $z^t$ once more, we can access $\{\mathcal{L}_i (z^t, \Theta_{s|G_1}^{t+1/\mathcal{M}}, \Theta_i^{t+1/\mathcal{M}})\}_{i=1}^{\mathcal{K}}$. For tasks that do not belong to $G_1$, their task-specific parameters remain unchanged, satisfying $\Theta_i^{t+1/\mathcal{M}} = \Theta_i^t$. Consequently, we can assess the proximal inter-task affinity from group $G_1$ to other tasks. In case where target task $\tau_j$ does not belong to $G_1$, we refer to this as inter-group relations as follows:
\begin{align}
    \mathcal{B}^t_{G_1\rightarrow j} \simeq \mathcal{B}^t_{i\rightarrow j} = \mathcal{A}^t_{i\rightarrow j} = 1- \frac{\mathcal{L}_j(z^t, \Theta_{s|G_1}^{t+1/\mathcal{M}}, \Theta_j^t)}{\mathcal{L}_j(z^t, \Theta_{s}^{t}, \Theta_j^t)} \hspace{20pt}\text{where}\hspace{5pt} \tau_i\in G_1 \hspace{5pt}\text{and}\hspace{5pt} \tau_j \notin G_1
\label{eq:inter_group}
\end{align}
To be precise, \cref{eq:inter_group} represents the proximal inter-task affinity from $G_1$ to $\tau_j$. However, since $\tau_i$ belongs to $G_1$, which is a group of tasks similar to $\tau_i$, we approximate the relations between $\tau_i$ and $\tau_j$ using $G_1$ and $\tau_j$. We explain how approximation $\mathcal{B}^t_{G_1\rightarrow j} \simeq \mathcal{B}^t_{i\rightarrow j}$ can be justified in task group updates from the results of \Cref{theorem3}. We can repeat this process iteratively $\mathcal{M}$ times, with each step updating each task group in $\{G_i\}_{i=1}^{\mathcal{M}}$.

\textbf{Intra-Group Relations.} Inter-group relation addresses inter-task relations where the source task $\tau_i$ and the target task $\tau_j$ do not belong to the same group. Conversely, intra-group relation refers to the influence between tasks within the same task group, and it follows a slightly different process. Since both the source and target tasks are updated simultaneously, we must infer inter-task relations based on how the tasks' losses change. Let's suppose we're updating the task set $G_1$. The proximal inter-task affinity between tasks within the same group can be calculated as follows: 
\begin{align}
    \mathcal{B}^t_{G_1\rightarrow j} \simeq \mathcal{B}^t_{i\rightarrow j} = 1- \frac{\mathcal{L}_j(z^t, \Theta_{s|G_1}^{t+1/\mathcal{M}}, \Theta_j^{t+1/\mathcal{M}})}{\mathcal{L}_j(z^t, \Theta_{s}^{t}, \Theta_j^t)} \hspace{20pt}\text{where}\hspace{5pt} \tau_i\in G_1 \hspace{5pt}\text{and}\hspace{5pt} \tau_j \in G_1
\end{align}
Similarly to the inter-group case, we approximate the relations from $\tau_i$ to $\tau_j$ using the relations from $G_1$ to $\tau_j$ and this also can be justified by \Cref{theorem3} when we use it to cluster task sets. Since the target task $\tau_j$ is included in $G_1$, we infer the inter-task relations by dividing cases into two. If both $\mathcal{B}^t_{i\rightarrow j}$ and $\mathcal{B}^t_{j\rightarrow i}$ have positive signs, we infer that the inter-task affinity between $\tau_i$ and $\tau_j$ is positive. Otherwise, if at least one of $\mathcal{B}^t_{i\rightarrow j}$ or $\mathcal{B}^t_{j\rightarrow i}$ has a negative sign, the inter-task affinity between $\tau_i$ and $\tau_j$ is negative. This inference is intuitive, as an increase in one task's loss during the decrease of the other task's loss implies that they transfer negative influences. However, it results in faster convergence compared to previous gradient-based optimization methods, which require a number of backpropagations equal to the number of tasks, along with gradient manipulation. This is further analyzed in \Cref{sec:exp}. In the initial phase of learning, we initialize task groups by assigning each task to a different group to facilitate the learning of proximal inter-task affinity. For stable tracking, we employ a decay rate $\beta$. Using the tracked proximal inter-task affinity, the next task groups $\{G_i\}_{i=1}^{\mathcal{M}'}$ are formed by grouping tasks with positive affinity, where $\mathcal{M}'$ is the number of task sets for the next step. During optimization, the number of clustered task sets $\mathcal{M}'$ continuously fluctuates along with their composition. The entire process is outlined in Algorithm \ref{alg:group}.


%-------------------------------------------------------------------------
\begin{figure}[t]
\vspace{-10pt}
\begin{algorithm}[H]
\DontPrintSemicolon
\caption{Tracking Proximal Inter-Task Affinity for Task Group Updates}\label{alg:group}
\SetKwInput{KwRequire}{Require}
\SetKwInput{KwReturn}{return}
\SetKwInput{KwInitialize}{Initialize}


\KwRequire{Loss function $\{\mathcal{L}_i\}^\mathcal{K}_{i=1}$, Dataset $\{z_i\}_{i=1}^n$, Total iteration $T$, \\
Proximal inter-task affinity (w/ decay) $\mathcal{B}^t$ ($\tilde{\mathcal{B}}^t$), Task group set $\{G_i\}_{i=1}^{\mathcal{M}}$, Decay rate $\beta \in (0,1)$}

\KwInitialize{
Proximal inter-task affinity $\tilde{\mathcal{B}}^0 = 0_{\mathcal{K}\times \mathcal{K}}$, \\ 
Task group $G_i = \{\tau_i\}$ for $i=1,...,\mathcal{M}$ ($\mathcal{M}=\mathcal{K}$ for initialization)}

\For{$t=1,\ldots,T$}{
    Randomly mix the sequence of task group $\{G_i\}_{i=1}^{\mathcal{M}}$ and calculate $\{\mathcal{L}_i(z^t, 
        \Theta_s^t, \Theta_i^t)\}_{i=1}^{\mathcal{K}}$ \\
    \For{$k=1,\ldots,\mathcal{M}$}{
        Update gradients $\sum_{\tau_i \in G_k} w_i \nabla \mathcal{L}_i$ backpropagated from losses in $G_k$ \\
        Forward $z^t$ and calculate $\mathcal{L}_i(z^t, \Theta_{s|G_k}^{t+k/\mathcal{M}}, \Theta_i^{t+k/\mathcal{M}})$ for all $i=1,...,\mathcal{K}$ \\
        Calculate $\mathcal{B}^{t+(k-1)/\mathcal{M}}_{i \rightarrow j}$ and $\mathcal{B}^{t+(k-1)/\mathcal{M}}_{j \rightarrow i}$ where $\tau_i \in G_k$ for all $j=1,...,\mathcal{K}$\\
        % \uIf(\tcp*[f]{Inter-Group Affinity})
        \uIf{$\tau_j \notin G_k$ \textbf{or} $\mathcal{B}^{t+(k-1)/\mathcal{M}}_{i\rightarrow j} \cdot \mathcal{B}^{t+(k-1)/\mathcal{M}}_{j\rightarrow i} \geq 0$}
            {$\tilde{\mathcal{B}}^{t+(k-1)/\mathcal{M}}_{i\rightarrow j} = (1-\beta) \tilde{\mathcal{B}}^{t+(k-2)/\mathcal{M}}_{i\rightarrow j} + \beta \mathcal{B}^{t+(k-1)/\mathcal{M}}_{i\rightarrow j}$}
        % \uElse(\tcp*[f]{Intra-Group Affinity})
        \uElse{$\tilde{\mathcal{B}}^{t+(k-1)/\mathcal{M}}_{i\rightarrow j} = (1-\beta) \tilde{\mathcal{B}}^{t+(k-2)/\mathcal{M}}_{i\rightarrow j} - \beta \max(|\mathcal{B}^{t+(k-1)/\mathcal{M}}_{i\rightarrow j}|, |\mathcal{B}^{t+(k-1)/\mathcal{M}}_{j\rightarrow i}|)$}
    }
    Divide task groups $\{G_i\}_{i=1}^{\mathcal{M}'}$ based on proximal inter-task affinity $\tilde{\mathcal{B}}^{(t+\mathcal{M}-1)/\mathcal{M}}$
}
\end{algorithm}
\vspace{-10pt}
\end{figure}
%-------------------------------------------------------------------------

We explain how it effectively approximates inter-task affinity in selective task group updates in \Cref{theorem3}. To be specific, we compare the inter-task affinity when the target task is included in the source task group versus when it is not.
%-------------------------------------------------------------------------
\begin{restatable}[]{theorem}{theomthree}
\label{theorem3}
The affinity between $\{i, k\}\rightarrow k$ and $i \rightarrow k$ satisfies $\mathcal{A}_{i,k \rightarrow k}^t \geq \mathcal{A}_{i \rightarrow k}^t$.
\end{restatable}

When task $i$ and $k$ are within the same task group, we can only access $\mathcal{B}_{i,k \rightarrow k}^t$ rather than $\mathcal{B}_{i \rightarrow k}^t$ during the optimization process. If $\mathcal{B}_{i,k \rightarrow k}^t \leq 0$, the inter-task affinity also satisfies $\mathcal{A}_{i,k \rightarrow k}^t \leq 0$ as $\mathcal{A}_{i,k \rightarrow k}^t \leq \mathcal{B}_{i,k \rightarrow k}^t$ (see the end of \cref{Append:differeence_affinity}). According to \Cref{theorem3}, this condition implies $\mathcal{A}_{i\rightarrow k}^t\leq 0$. The proposed algorithm separates these tasks into different groups when $\mathcal{B}_{i,k \rightarrow k}^t \leq 0$ which justifies our grouping rules.

Conversely, when tasks $\tau_i$ and $\tau_j$ belong to separate task groups, we only have access to $\mathcal{B}_{i \rightarrow k}^t$ instead of $\mathcal{B}_{i,k \rightarrow k}^t$. In this scenario, the proposed algorithm merges these tasks into the same group if $\mathcal{B}_{i \rightarrow k}^t \geq 0$. This inequality also implies $\mathcal{A}_{i\rightarrow k}^t\geq 0$ as $\mathcal{B}_{i \rightarrow k}^t = \mathcal{A}_{i \rightarrow k}^t$ (see the end of \cref{Append:differeence_affinity}), justifying the merging of tasks $\tau_i$ and $\tau_k$ based on $\mathcal{B}_{i \rightarrow k}^t$ during optimization. 