\section{Introduction}
Multi-task learning (MTL) stands out as a key approach for crafting efficient and robust deep learning models that can adeptly manage numerous tasks within a unified architecture \citep{caruana1997multitask}. By training related tasks within a single network, MTL facilitates the acquisition of universal knowledge spanning multiple tasks, thereby enhancing generalization and accelerating convergence. Additionally, MTL reduces the need for expensive computing and storage resources by employing a shared network across tasks, making it a favorable choice for future generalized networks across many applications.

The goal of MTL is to mitigate negative transfer \citep{crawshaw2020multi} between tasks. Since each task possesses its own distinct objective function, improving performance in one task can potentially impede the performance of others. This phenomenon, characterized by a trade-off among tasks' performances, is referred to as negative transfer. To mitigate negative transfer during optimization, task-specific gradients are manipulated \citep{RN19, RN36, RN20, RN18, liu2021towards, navon2022multi, senushkin2023independent}, tasks' losses are adaptively weighted \citep{RN23, RN25, RN26, liu2024famo}, or a combination of both approaches is used \citep{liu2021towards}. Previous research focused on balancing the influence of different tasks by considering unbalance in gradients of shared parameters. However, these analyses overlooked the role of task-specific parameters. Since the learning of shared space and task-specific information influence each other during optimization, a balanced shared space across tasks cannot be achieved without learning task-specific information in the task-specific parameters.

Therefore, we take a fundamentally different approach to mitigate negative transfer in MTL (see \Cref{fig:overview}). Our experiments reveal a notable difference in multi-task performance depending on whether task losses are updated collectively or sequentially. By grouping tasks and updating them sequentially, the network can focus on specific task groups in turn, facilitating the learning of task-specific parameters. Thus, our main objective is to identify optimal strategies for grouping and updating tasks during optimization. Inter-task affinity \citep{fifty2021efficiently}, which evaluates the loss change of one task when updating another task's gradients in the shared parameters, is a useful metric for understanding task relations. However, directly incorporating inter-task affinity into optimization presents several challenges: (i) It only considers updates to shared parameters, ignoring the influence of task-specific parameter updates. (ii) Inter-task affinity varies significantly throughout optimization, so relying on the average across time steps may not fully capture task relations. (iii) Measuring inter-task affinity is computationally intensive because it involves recursive gradient updates, tracking changes in loss, and reverting to previous parameter states. To address these issues, we introduce proximal inter-task affinity (\Cref{sec:problem_def}), which concurrently explains the updates of shared and task-specific parameters. This metric can be tracked over time to approximate inter-task relations during optimization without significant computational overhead.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[t]
    \centering
    \includegraphics[width=0.99\textwidth]{figure/overview_re.png}
    \caption{Comparison of multi-task optimization methods. $\Theta$ represents the network parameters, and $\{\mathcal{L}\}_{i=1}^{\mathcal{K}}$ denotes the task-specific losses for $\mathcal{K}$ tasks. (a) Loss-based approaches balance the loss by adjusting the weights $\{w_i\}_{i=1}^{\mathcal{K}}$ during optimization. (b) Gradient-based approaches modify the task-specific gradients $\{g_i\}_{i=1}^{\mathcal{K}}$ with respect to $\Theta$. (c) Our method divides the tasks into $\mathcal{M}$ groups (in this case, $\mathcal{M}=2$) and updates them sequentially for each batch during optimization.}
    \vspace{-5pt}
    \label{fig:overview}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

By capturing task relations, we introduce an algorithm that dynamically updates task groups using proximal inter-task affinity to effectively mitigate negative transfer between tasks (\Cref{sec:track_prox}). Additionally, we present practical methods for inferring proximal inter-task affinity during task group updates. In the theoretical analysis (\Cref{sec:theoretical_analysis}), we explain how this sequential update strategy can improve multi-task performance from an optimization standpoint. Previous approaches have demonstrated convergence to Pareto-stationary points, where the sum of all task-specific gradients equals zero \citep{RN19, RN36, RN20, RN18, liu2021towards, navon2022multi, senushkin2023independent}. However, conventional convergence analysis cannot explain why sequential updates yield better multi-task performance with comparable stability, as they handle the learning of shared and task-specific parameters separately. Instead, we provide a theoretical explanation of the relations between the updates of shared and task-specific parameters and how the update sequence affects this. This perspective is not addressed in traditional multi-task optimization, which typically deals with the learning of shared and task-specific parameters independently. As a result, our approach facilitates the learning of task-specific parameters with stability similar to other optimization methods, while achieving faster convergence compared to previous gradient-based approaches. Experimental results demonstrate that adaptively partitioning the task set and sequentially updating them during the optimization process significantly enhances multi-task performance compared to previous works. Our main contributions are threefold:
\begin{itemize}[leftmargin=*]
\item We propose an algorithm that dynamically groups tasks for updating each batch during multi-task optimization. To do this, we introduce proximal inter-task affinity, which we can track throughout the optimization process to group tasks accordingly. 
\item  We provide a theoretical explanation of the advantages of sequentially updating task groups based on proximal inter-task affinity. We discuss how sequential updates can enhance the learning of task-specific parameters and improve multi-task performance, a result that traditional multi-task optimization analyses do not explain.
\item Our methods demonstrate superior performance across various benchmarks when compared to previous multi-task optimization techniques, including both loss-based and gradient-based approaches.
\end{itemize}
