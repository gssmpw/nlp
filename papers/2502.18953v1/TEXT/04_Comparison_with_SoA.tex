\section{Comparison with State-of-the-Art}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.98\columnwidth]{FIGURES/SoA_safety_comparison.pdf}
    \caption{Comparison against \gls{soa} heterogeneous SoC for \gls{mcs}.}
    \label{fig:soa-safety}
\end{figure}

\subsection{Comparison with Mixed-Criticality SoCs}
\label{sec:mcs-soa}

Fig.~\ref{fig:soa-safety} compares the proposed SoC against \gls{cots} and \gls{soa} heterogeneous SoC prototypes presented in the literature in the same power class. 
%
\gls{cots} solutions like the \textit{I.MXRT1170} crossover MCUs by NXP~\cite{nxp_industrial_control} mainly address heterogeneous workloads for the average case, relying on ARM Cortex-M cores and \gls{gp} acceleration units. However, they lack hardware mechanisms for reliability, virtualization, and time predictability, limiting their use as a \glspl{mcs}. Renesas' prototype~\cite{otani2728nm600MHz2019} focuses on reliable and virtualized RISC cores, reducing \glspl{vg} context-switch overheads, but it does not enable resource partitioning among concurrent \glspl{vg} in hardware, nor does it provide \gls{ai}/\gls{dsp} hardware acceleration. Another example is the \textit{Stellar} processor by ST~\cite{grossierASILDAutomotivegradeMicrocontroller2023}. Despite integrating reliable and real-time ARM Cortex-R52 cores operating in split-lock and an interconnect with Quality of Service mechanisms, it lacks hardware IPs to observe and partition shared memory endpoints. Moreover, it relies solely on \gls{gp} cores for compute-intensive tasks. 
%
In academia,~\cite{valenteHeterogeneousRISCVBased2024} targets \gls{ai}-enhanced nano-drone applications with a SoC featuring a single-core 64b \gls{rv} processor and an acceleration cluster similar to ours. However, it lacks features for reliability and time-predictability, limiting the~SoC usability in mission-critical scenarios. 

At a comparable power envelope, the proposed SoC is the only one that integrates comprehensive hardware mechanisms for time predictability, enabling software-controlled (e.g., via hypervisors) dynamic partitioning of shared resources like interconnects, caches, and \gls{spm}. It achieves the fastest interrupt latency response, 2$\times$, 3.3$\times$, and 8.3$\times$ lower than~\cite{nxp_industrial_control}, \cite{grossierASILDAutomotivegradeMicrocontroller2023}, and~\cite{valenteHeterogeneousRISCVBased2024}, respectively. Additionally, it supports concurrent execution of GPOS and RTOS, integrates a HW RoT secure domain with extensive security primitives, and a comprehensive set of programmable accelerators for compute-intensive mixed-criticality workloads, achieving \gls{soa} performance and energy \looseness=-1  efficiency.
%The I.MXRT1170 crossover MCUs by NXP~\cite{nxp_industrial_control} target ML-enhanced and motor control applications in industrial, robotics, and automotive domains. Operating below 1W, they integrate 32-b ARM Cortex-M cores and a 2D graphics accelerator but lack support for rich OSs, virtualization, and hardware mechanisms for reliability and time predictability.

%Similarly, despite the \textit{Stellar} processor by ST~\cite{grossierASILDAutomotivegradeMicrocontroller2023} integrates reliable, real-time ARM Cortex-R52 virtualized cores, and interconnect with Quality of Service mechanisms, it still misses comprehensive hardware mechanisms for time-predictability. Morever, it lacks domain-specific accelerators and relies solely on \gls{gp} cores for compute-intensive tasks.

%Renesas' \textbf{prototype}~\cite{otani2728nm600MHz2019} integrates four 32-b, 8-stage out-of-order RISC cores in dual-lockstep mode for high safety integrity, minimizing VM context-switch overheads. Despite its low-power design, it lacks specialized accelerators for AI and floating-point workloads in mixed-criticality edge applications.

%The academic \textbf{SoC in}~\cite{valenteHeterogeneousRISCVBased2024} targets nano-drones and ML-enhanced edge applications in 22nm technology, featuring a 64-b RISC-V host processor and an eight-core 32-b RISC-V programmable cluster with low-bitwidth AI capabilities. While efficient for compute-intensive AI workloads, it lacks hardware mechanisms for reliability and time-predictable execution, limiting its applicability in mission-critical scenarios.



% % NXP processor
% The I.MXRT1170 family of crossover MCUs by NXP~\cite{nxp_industrial_control} targets ML-enhanced and motor control applications in industrial, robotics, and automotive domains. With a power envelope under 1W, these MCUs integrate 32-b ARM Cortex-M based cores and a generic 2D graphics unit acceleration system. However, they lack support for rich OSs like Linux and virtualization. While designed for mixed-criticality application domains, they lack features for reliability and time-predictability in hardware.

% stellar processor
%The Stellar processors by ST~\cite{grossierASILDAutomotivegradeMicrocontroller2023} are tailored for automotive applications. Albeit showing a higher power consumption than~\cite{nxp_industrial_control}, they integrate a homogeneous cluster of six 32-b ARM Cortex-R52 processors, which can operate in split-lock mode for enhanced reliability. 
%These processors are designed for real-time execution of tasks, support virtualization, time-predictable interconnects through Quality of Service mechanisms (not further specified), and a firewall for task isolation. However, they rely on the Cortex-R cores for compute-intensive tasks and do not include domain-specific accelerators.

% Renesas
%Renesas' prototype~\cite{otani2728nm600MHz2019} features a low-power virtual-assisted processor designed to minimize context-switch overheads among different VMs. It consists of four 32-b  8-stage out-of-order RISC cores operating in dual-lockstep mode for high safety integrity levels. Despite the low-power envelope, this prototype works fine for control applications, but it does not provide any specialized accelerators to boost compute-intensive AI and FP workloads typical of modern mixed-criticality edge application pipelines. 

% shaheen
%In academia, the SoC in~\cite{valenteHeterogeneousRISCVBased2024} targets nano-drones and ML-enhanced edge applications in 22nm technology. It includes a single-core 64-b RISC-V host processor accelerated by a programmable cluster of eight 32-b RISC-V cores with floating-point and integer low-bitwidth AI capabilities. Despite this processor being suitable for compute-intensive AI workloads, it lacks hardware features for reliable and time-predictable task execution, limiting its real use in mission-critical scenarios.

% carfield
%At comparable power envelope, the proposed heterogeneous SoC is the only one that integrates, in the same die, comprehensive hardware mechanisms for time-predictability, enabling software-controlled (e.g. by Hypervisors) dynamic partitioning of shared resources like interconnects, caches, and SPM, and showing the fastest interrupt latency response, which is 2x, 3.3x and 8.3x lower than~\cite{nxp_industrial_control}, \cite{grossierASILDAutomotivegradeMicrocontroller2023}, \cite{valenteHeterogeneousRISCVBased2024}, respectively. Moreover, it supports concurrent execution of GPOS and RTOS while offering extensive security primitives within a HW RoT secure domain and an exhaustive set of programmable accelerators for executing AI and FP workloads at state-of-the-art performance and energy efficiency. 


\subsection{Comparison with edge \gls{ai} and Vector Processors}
\label{sec:soa-acc}
\begin{figure}[t]
    \centering
    \includegraphics[width=0.98\columnwidth]{FIGURES/SoA_Accelerators_table_v2.pdf}
    \caption{Comparison against \gls{soa} accelerators for \gls{fp} and edge \gls{ai}.}
    \label{fig:soa-accelerators}
\end{figure}

Fig.~\ref{fig:soa-accelerators} compares the proposed \gls{amr} and vector clusters against \gls{soa} vector and edge \gls{ai} processors. The \gls{amr} cluster compares favorably to a similar parallel cluster that supports low-bit-width integer arithmetic but lacks reliability features~\cite{valenteHeterogeneousRISCVBased2024}, limiting its use in mission-critical applications. In \gls{dlm}, it achieves up to 1.8$\times$ better performance (3.4$\times$ in \gls{indip}) on uniform 8b/4b/2b \glspl{matmul}, with  6.4$\times$ better area efficiency and comparable energy efficiency. In \gls{dlm}, it provides 2.6$\times$ higher performance than the most efficient 8b integer processor~\cite{juSystolicNeuralCPU2023}, which however lacks support for reliable execution modes. 
%
On \gls{fp} workloads, our vector cluster is the only one that operates over the full range of \gls{fp} formats, from 64b down to 8b, achieving the highest computing efficiency due to near-ideal resource utilization. Compared to~\cite{schmidtEightCore144GHzRISCV2022}, implemented in the same technology node, our cluster demonstrates 2.2$\times$ and 3$\times$ higher energy and area efficiency, respectively, on FP16 workloads. 
Additionally, it shows 2.43$\times$ better performance, 2$\times$, and 1.6$\times$ higher energy and area efficiency than~\cite{wang306Vecim28913GOPS2024}, despite the latter leveraging compute-in-memory in the VRF.


%Compare against vector processors: \cite{perottiYunOpenSource64Bit2023}


