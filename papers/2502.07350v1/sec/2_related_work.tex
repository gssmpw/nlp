\section{Related Work}
\subsection{Large Language Model Ensemble}

The ensemble of large language models (LLMs) has emerged as an effective strategy to leverage the complementary strengths of different models and improve performance across diverse tasks. Early approaches primarily focused on combining outputs from multiple models through techniques like reranking or probability distribution averaging. For instance, \citet{jiang2023llm} proposed PAIRRANKER for pairwise output comparisons and GENFUSER for generating improved responses by synthesizing multiple candidates. Similarly, \citet{DBLP:journals/corr/abs-2404-12715} explored output fusion by averaging probability distributions, while FrugalGPT \cite{chen2023frugalgpt} introduced a cost-efficient cascading mechanism that allocates tasks dynamically across LLMs to reduce computational overhead. These methods highlight the potential of ensembling to amplify individual model capabilities while addressing computational constraints.

Beyond simple output aggregation, recent research has shifted toward more dynamic and adaptive frameworks for LLM collaboration. Mixture-of-Agents (MoA) \citet{wang2024mixture} exemplifies this trend by introducing iterative refinement processes where multiple LLMs serve distinct roles, such as generating and refining responses through multi-layered agent interactions. This approach emphasizes the importance of both diversity and performance in model selection, demonstrating that combining heterogeneous models often yields superior results compared to homogeneous ensembles. Additionally, routing-based methods, such as those proposed by \citet{wang2023fusing} and \citet{shnitzer2023large}, optimize efficiency by dynamically selecting the most suitable model for a given input, while ZOOTER \cite{lu2023routing} further refines this concept by distilling model expertise without requiring full inference for all candidates. These advancements highlight the progress in LLM ensemble techniques, focusing on efficiency and quality. Building on this, we propose a framework that integrates knowledge-aware mechanisms to improve adaptability and semantic coherence in multi-agent systems.

% These advancements underline the growing sophistication of LLM ensemble techniques, which increasingly prioritize both computational efficiency and response quality. Our work builds upon these prior studies by proposing a novel framework that integrates knowledge-aware mechanisms into the ensemble process, aiming to further enhance dynamic adaptability and semantic coherence in multi-agent systems.

\subsection{Multi-Armed Bandit for Decision Optimization}
% The Multi-Armed Bandit (MAB) framework is widely used to address the exploration-exploitation trade-off in sequential decision-making under uncertainty. Classical algorithms, such as Upper Confidence Bound (UCB) and Thompson Sampling, have demonstrated success in applications like online recommendation and resource allocation. Other extensions, such as Contextual Bandits and algorithms for non-stationary environments, have introduced mechanisms to incorporate contextual information or adapt to changing reward distributions, enabling more nuanced decision-making in dynamic settings.

The Multi-Armed Bandit (MAB) framework balances exploration and exploitation in sequential decision-making under uncertainty. Classical algorithms like UCB and Thompson Sampling excel in recommendation and resource allocation, while Contextual Bandits and adaptive methods refine decision-making in dynamic settings \cite{li2010contextual}. Recent advances integrate Large Language Models (LLMs) to reduce learning regret and enhance decision-making by leveraging pre-trained knowledge \cite{alamdari2024jump}. Bandit-based reinforcement learning frameworks further aid retrieval in knowledge-intensive tasks \cite{tang2024mba}. Innovations in clustering and transfer learning have improved MAB efficiency across applications like clinical trials and recommendation systems \cite{qi2025graphfeedbackbanditssimilar,sharma2025offlinetoonlinehyperparametertransferstochastic}. These developments highlight the importance of semantic understanding and adaptation, aligning with the Knowledge-Aware Bayesian Bandits (KABB) framework introduced in this paper.

% \subsection{Knowledge Graphs and Knowledge-Aware Systems}

% Multi-agent systems (MAS) have gained attention as an alternative to large-scale language models, yet face coordination and static knowledge challenges. Knowledge graphs (KGs) provide structured semantic representations that improve inference and transparency \cite{ji2021survey,lin2019kagnet}. Graph-based models have enhanced recommendation systems by refining noisy and sparse knowledge \cite{tu2021conditional,yang2022knowledge}, yet lack adaptability to dynamic environments. 

% Knowledge graphs (KGs) have emerged as powerful tools for representing and reasoning with structured knowledge in AI systems. Traditional KG applications focus on enhancing natural language understanding through relationship extraction and knowledge embedding techniques (Zhang et al., 2022). Recent work has explored integrating KGs with large language models to improve reasoning capabilities and reduce hallucinations. For instance, Liu et al. (2023) proposed knowledge graph-augmented prompting strategies, while Wang et al. (2023) developed mechanisms for dynamic knowledge retrieval and updating during inference.

% Knowledge-aware systems extend beyond static knowledge representation to enable dynamic knowledge acquisition and utilization in complex tasks. While existing approaches demonstrate the value of knowledge integration in improving model performance, they typically treat knowledge structures as static references rather than dynamic components that evolve with task requirements. Our work advances this direction by proposing a framework that actively updates and leverages knowledge representations to guide the dynamic allocation of tasks across language models, enabling more efficient and semantically-aware ensemble learning.

% \subsection{Discussion}
% This section reviewed two primary research areas: large language model ensemble and multi-armed bandit optimization. In model ensemble, research has evolved from simple output aggregation to dynamic collaboration frameworks, highlighting the value of model heterogeneity and adaptability. The multi-armed bandit field demonstrates progression from traditional algorithms to deep learning integration, achieving significant advances in handling dynamic environments and knowledge-intensive tasks. These studies lay the foundation for our proposed Knowledge-Aware Bayesian Bandits framework, while also emphasizing our work's innovation in integrating semantic understanding and dynamic adaptation.