\section{Method}
\label{sec:method}
%This chapter introduces the Knowledge-Aware Bayesian Multi-Armed Bandits (KABB) framework, designed to address the expert dynamic selection problem in multi-agent collaborative systems. We first formally define the problem space and analyze the theoretical limitations of traditional methods in knowledge representation and dynamic adaptability. Building upon this, we construct a dynamic Bayesian optimization framework with theoretical guarantees by introducing knowledge-driven decision mechanisms and rigorous distance metrics. Theoretical analysis demonstrates that this framework outperforms existing methods in both exploration efficiency and convergence, providing a new theoretical paradigm for multi-agent collaboration.
This chapter presents the Knowledge-Aware Bayesian Multi-Armed Bandits (KABB) framework for solving the expert selection problem in multi-agent collaborative systems. We begin by defining the problem space and identifying key gaps in classical approaches with respect to knowledge representation and dynamic adaptability. Building upon this foundation, we propose a dynamic Bayesian optimization strategy that incorporates knowledge-driven decision mechanisms, synergy-based distance metrics, and robust theoretical guarantees. Through detailed analysis and illustrative examples, we demonstrate that the KABB framework achieves both improved exploration efficiency and stronger convergence properties, thereby providing a new paradigm for multi-agent collaboration and expert team formation.



\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{Frame_95__1_.pdf}
    \caption{The KABB framework combines knowledge graph embeddings, team synergy metrics, and dynamic Bayesian MAB algorithms to enable efficient expert team selection and adaptation. In this example, the user prompt is mapped to the top-2 concepts from the set $\mathcal{C}$, and the top-4 relevant experts are selected to respond. An aggregator then synthesizes their outputs to generate the final response.}
    \label{fig:kabb-framework}
\end{figure*}

\subsection{System Architecture}
The overall decision-making process of the KABB system (see \cref{fig:kabb-framework}) consists of several key steps:
\label{sec:system_arch}
\begin{enumerate}
    \item \textbf{Task Reception and Concept Extraction}: the system receives a user-input task $T^t$ and employs natural language processing techniques to parse the task into a concept requirement \cite{1,11,111}vector $\mathbf{d}^t \in \mathbb{R}_+^{|\mathcal{C}|}$, where $\mathcal{C}$ is a predefined set of concepts.
    \item \textbf{Expert Capability Mapping}: each expert\cite{GPT2} (i.e., different LLMs\cite{yuxunl}) is represented by an ability vector $\mathbf{v}_e \in \mathbb{R}_+^{|\mathcal{C}|}$, reflecting its expertise across various concepts. Multiple LLMs are thus mapped into an expert set $\mathcal{E} = \{e_1, e_2, \ldots, e_n\}$.
    % \item \textbf{Expert Subset Selection} is performed based on the task requirement vector $\mathbf{d}^t$ and the expert capability vector $\mathbf{v}_e$. The system utilizes a dynamic Bayesian Multi-Armed Bandit (MAB) algorithm combined with the knowledge distance $\text{Dist}(\mathcal{S}, t)$ to select the optimal subset of experts $\mathcal{S}_t \subseteq \mathcal{E}$, aiming to maximize the task success rate. The selected experts in $\mathcal{S}_t$ independently process the task $T^t$, generating individual responses or solutions. An aggregator then integrates these responses through conflict detection, information complementarity analysis, and weighted synthesis to produce a unified and optimized final answer for the user.
    \item \textbf{Expert Subset Selection}: The optimal expert subset $\mathcal{S}_t \subseteq \mathcal{E}$ is identified through a knowledge-aware Thompson sampling process that leverages both the task requirement vector $\mathbf{d}^t$ and expert capability vectors $\mathbf{v}_e$. This process integrates a dynamic Bayesian MAB algorithm with the knowledge distance metric $\text{Dist}(\mathcal{S}, t)$ to maximize task success probability. Selected experts in $\mathcal{S}_t$ independently process task $T^t$, after which an aggregator synthesizes their responses through semantic conflict detection and weighted information fusion to generate the final output.
    \item \textbf{Performance Feedback and Model Update}: The system collects performance metrics (e.g., success rates and user ratings) for each task completion. These feedback signals are used to update the Bayesian model parameters $\alpha$ and $\beta$, enhancing the accuracy and adaptability of future decisions.
\end{enumerate}
% First, \textbf{Task Reception and Concept Extraction}: the system receives a user-input task $T^t$ and employs natural language processing techniques to parse the task into a concept requirement vector $\mathbf{d}^t \in \mathbb{R}_+^{|\mathcal{C}|}$, where $\mathcal{C}$ is a predefined set of concepts. Next, \textbf{Expert Capability Mapping}: each expert (i.e., different LLMs) is represented by an ability vector $\mathbf{v}_e \in \mathbb{R}_+^{|\mathcal{C}|}$, reflecting its expertise across various concepts. Multiple LLMs are thus mapped into an expert set $\mathcal{E} = \{e_1, e_2, \ldots, e_n\}$. 

% Following this, \textbf{Expert Subset Selection} is performed based on the task requirement vector $\mathbf{d}^t$ and the expert capability vector $\mathbf{v}_e$. The system utilizes a dynamic Bayesian multi-armed bandit algorithm combined with the knowledge distance $\text{Dist}(\mathcal{S}, t)$ to select the optimal subset of experts $\mathcal{S}_t \subseteq \mathcal{E}$, aiming to maximize the task success rate. The selected experts in $\mathcal{S}_t$ independently process the task $T^t$, generating individual responses or solutions. An aggregator then integrates these responses through conflict detection, information complementarity analysis, and weighted synthesis to produce a unified and optimized final answer for the user. Finally, feedback on the system's output (such as success rate and ratings) is used to update the parameters $\alpha$ and $\beta$ in the dynamic Bayesian model, enhancing the accuracy and adaptability of future decisions. 
Through this pipeline, the KABB system achieves a closed-loop process from task parsing to expert selection and answer aggregation, ensuring precise alignment between task requirements and expert capabilities while continuously improving decision-making efficiency and effectiveness.

\subsection{Knowledge Distance and Complementarity in Multi-Agent Teams}
\label{sec:knowledge_distance}

To better characterize the collaborative properties of multi-agent\cite{duoagent} (expert \cite{moe}subset) teams, we extend the knowledge distance metric from individual experts to expert subsets, introducing the concepts of team synergy and conflict\cite{biaozhen}. The knowledge distance \cite{qi2025graphfeedbackbanditssimilar}metric $\text{Dist}(\mathcal{S}, t)$ serves as a core component of the KABB model, integrating five key dimensions of information: task difficulty, semantic matching, dependency relations, team complementarity, and historical effectiveness. These dimensions are balanced through learnable weights. The formal definition is given as follows:\begin{definition}[Knowledge Distance Function]
The knowledge distance metric $\text{Dist}(\mathcal{S}, t)$ integrating five dimensions is formally defined as:

\begin{equation}
\scriptsize
\begin{aligned}
\text{Dist}(\mathcal{S}, t) &= \underbrace{\log(1 + d_t)}_{\text{difficulty scaling}} \cdot \Bigg[ 
\omega_1\underbrace{\left(1 - \rho_{\text{overlap}}(\mathcal{S}, t)\right)}_{\text{semantic mismatch}} 
+ \omega_2\underbrace{\frac{|\mathcal{R}_{\text{dep}}(\mathcal{S}, t)|}{K}}_{\text{dependency complexity}} \\
&\quad + \omega_3\underbrace{\left(1 - \bar{H}_{\mathcal{S}}(t)\right)}_{\text{historical effectiveness}} 
+ \omega_4\underbrace{\left(1 - \mathrm{Synergy}(\mathcal{S})\right)}_{\text{team complementarity}} \Bigg] 
\end{aligned}
\tag{4}
\label{eq:emc4}
\end{equation}
where $d_t$ is the task difficulty coefficient based on knowledge graph topology depth, $\omega = [\omega_1, \omega_2, \omega_3, \omega_4]$ are learnable weight parameters satisfying $\sum_{i=1}^4 \omega_i = 1$, $\rho_{\text{overlap}}(\mathcal{S}, t) = \frac{|\mathcal{C}_{\mathcal{S}} \cap \mathcal{C}_t|}{|\mathcal{C}_{\mathcal{S}} \cup \mathcal{C}_t|}$ is the Jaccard similarity between the expert subset $\mathcal{S}$ and task $t$, $|\mathcal{R}_{\text{dep}}(\mathcal{S}, t)|$ is the number of dependency edges between expert subset and task in knowledge graph, $K = |\mathcal{E}|$ is total expert count, $\bar{H}_{\mathcal{S}}(t)$ is average historical success rate of expert subset, and $\mathrm{Synergy}(\mathcal{S}) \in [0,1]$ quantifies team complementarity, where higher values indicate stronger collaboration and less conflict within the team.
\end{definition}

The following theorem ensures the consistency and rationality of knowledge distance when measuring multi-agent team collaboration, thereby enhancing the reliability and effectiveness of the model in expert selection and task allocation.

\begin{theorem}[Pseudo-Metric Properties of Knowledge Distance]
\label{the:Pseudo-Metric}
The knowledge distance function $\text{Dist}(\mathcal{S}, t)$ satisfies the following pseudo-metric properties:

\begin{itemize}
\setlength{\itemsep}{0pt}
\setlength{\parsep}{0pt}
\setlength{\parskip}{0pt}
\item \textbf{Non-negativity}: For any expert subset $\mathcal{S}$ and task $t$, $\text{Dist}(\mathcal{S}, t) \geq 0$.  

% \textit{Proof}: This follows directly from the non-negativity of $\log(1 + d_t)$ and all other terms in the definition.

\item \textbf{Conditional Symmetry}: If the dependency graph $G$ is undirected and $\rho_{\text{overlap}}(\mathcal{S}_1, t) = \rho_{\text{overlap}}(\mathcal{S}_2, t)$, and if $\mathcal{S}_1$ and $\mathcal{S}_2$ are symmetric in terms of knowledge and dependencies, then $\text{Dist}(\mathcal{S}_1, t) = \text{Dist}(\mathcal{S}_2, t)$.  

% \textit{Proof}: Under the given symmetry conditions, $|\mathcal{R}_{\text{dep}}|$, $\bar{H}_{\mathcal{S}}$, and other terms in the distance function are equal for $\mathcal{S}_1$ and $\mathcal{S}_2$, and the weights also preserve symmetry.

\item \textbf{Approximate Triangle Inequality}: There exists a constant $c \geq 1$ such that  
\[
\text{Dist}(\mathcal{S}_1, t) \leq c\left[\text{Dist}(\mathcal{S}_1, \mathcal{S}_2) + \text{Dist}(\mathcal{S}_2, t)\right].
\]  

% \textit{Proof}: This follows from the subadditivity of the graph metric in the knowledge graph and the approximate subadditivity of the Jaccard similarity (see Lemma 3 in the appendix). The relaxation factor $c$ is determined by the extrema of the learnable weights.

%------------
% \item \textbf{Non-negativity}: $\forall \mathcal{S}, t,\ \text{Dist}(\mathcal{S}, t) \geq 0$ \textit{Proof}: Follows directly from $\log(1+d_t) \geq 0$ and non-negativity of all terms. 
% \item \textbf{Conditional Symmetry}: When dependency graph $G$ is undirected and $\rho_{\text{overlap}}(\mathcal{S}_1, t) = \rho_{\text{overlap}}(\mathcal{S}_2, t)$, if $\mathcal{S}_1, \mathcal{S}_2$ are symmetric in knowledge and dependencies, then $\text{Dist}(\mathcal{S}_1, t) = \text{Dist}(\mathcal{S}_2, t)$ \textit{Proof}: Under symmetry, $|\mathcal{R}_{\text{dep}}|$ and $\bar{H}_{\mathcal{S}}$ are equal, with weights sharing symmetry. 
% \item \textbf{Approximate Triangle Inequality}: There exists constant $c \geq 1$ such that $\text{Dist}(\mathcal{S}_1, t) \leq c\left[\text{Dist}(\mathcal{S}_1, \mathcal{S}_2) + \text{Dist}(\mathcal{S}_2, t)\right]$ \textit{Proof}: Using graph metric subadditivity of knowledge graph and approximate subadditivity of Jaccard similarity (Lemma 3 in appendix), relaxation factor $c$ determined by weight extrema.
%----------
\end{itemize}
\end{theorem}

% [Pseudo-Metric Properties of Knowledge Distance]的证明
% \begin{proof}
% \textbf{Proof of Non-negativity}:  
% This follows directly from the non-negativity of $\log(1 + d_t)$ and all other terms in the definition of $\text{Dist}(\mathcal{S}, t)$. Each term (e.g., $1 - \rho_{\text{overlap}}$, dependency complexity, etc.) is non-negative by construction.

% \textbf{Proof of Conditional Symmetry}:  
% If the dependency graph $G$ is undirected and $\rho_{\text{overlap}}(\mathcal{S}_1, t) = \rho_{\text{overlap}}(\mathcal{S}_2, t)$, and if $\mathcal{S}_1$ and $\mathcal{S}_2$ are symmetric in terms of knowledge and dependencies, then all terms in the distance function (e.g., $|\mathcal{R}_{\text{dep}}|$, $\bar{H}_{\mathcal{S}}$, and weights) are equal for $\mathcal{S}_1$ and $\mathcal{S}_2$. Thus, $\text{Dist}(\mathcal{S}_1, t) = \text{Dist}(\mathcal{S}_2, t)$.

% \textbf{Proof of Approximate Triangle Inequality}:  
% Using the properties of the knowledge graph as a metric space, the subadditivity of the graph metric ensures that the dependency-based terms satisfy a triangle inequality. Similarly, the Jaccard similarity used in $\rho_{\text{overlap}}$ is approximately subadditive (as shown in Lemma 3 of the appendix). Combining these with the weight terms, the inequality holds with a relaxation factor $c \geq 1$ determined by the extrema of the weights.
% \end{proof}

By incorporating team complementarity, the knowledge distance measures not only external team-task matching but also internal team synergy, enabling multi-dimensional adaptability assessment.


\subsection{Dynamic Bayesian Multi-Armed Bandit (MAB) Algorithm Derivation for Multi-Agent Systems}
\label{sec:dynamic_bayesian}

To effectively select the most suitable expert subset for specific tasks in expert systems remains a key challenge. Traditional MAB algorithms (e.g., UCB\cite{duobi1,duobi2}, Thompson Sampling) rely solely on historical feedback for decision-making. However, these methods face two significant limitations in practice: (1) they fail to account for the dynamic nature of expert performance over time, and (2) they overlook the critical alignment between task requirements and the knowledge structure of expert teams. To address these issues, we propose a Dynamic Bayesian MAB framework that integrates knowledge distance metrics, team complementarity, and temporal decay mechanisms into Bayesian inference. This framework establishes a joint optimization objective, enabling dynamic adjustment of expert subset selection strategies. As a result, the system can rapidly adapt to changes in expert performance while identifying the best-matched expert teams for incoming tasks.
% only make selections based on historical feedback, but face two main limitations in practice: ignoring the dynamic nature of expert performance over time, and overlooking the matching between task requirements and expert team knowledge structure. Therefore, we propose a Dynamic Bayesian MAB framework that incorporates knowledge distance metrics, team complementarity and temporal decay mechanisms into Bayesian inference, establishing a joint optimization objective to enable dynamic adjustment of expert subset selection strategies, ensuring the system can quickly adapt to changes in expert performance and select the best-matched expert teams for tasks.

\textbf{Dynamic Beta Distribution Modeling and Parameter Evolution.} We model the success probability of an expert subset $\mathcal{S}$ at time step $t$ using a time-varying Beta distribution: 
\[
\theta_{\mathcal{S}}^{(t)} \sim \text{Beta}\left( \alpha_{\mathcal{S}}^{(t)}, \beta_{\mathcal{S}}^{(t)} \right),
\]
where the parameters are updated dynamically according to the following equations:

% Define the success probability of expert subset $\mathcal{S}$ at time step $t$ following a time-varying Beta distribution: $\theta_{\mathcal{S}}^{(t)} \sim \text{Beta}\left( \alpha_{\mathcal{S}}^{(t)}, \beta_{\mathcal{S}}^{(t)} \right)$ where distribution parameters follow dynamic update equations:
\begin{equation}
\scriptsize
\begin{cases}
\alpha_{\mathcal{S}}^{(t+1)} = \underbrace{\gamma^{\Delta t} \alpha_{\mathcal{S}}^{(t)}}_{\text{historical decay}} 
+ \underbrace{r_{\mathcal{S}}^{(t)}}_{\text{immediate feedback}} 
+ \underbrace{\delta \cdot \mathrm{KM}(\mathcal{S}, t)}_{\text{knowledge matching reward}} \\[8pt]
\beta_{\mathcal{S}}^{(t+1)} = \gamma^{\Delta t} \beta_{\mathcal{S}}^{(t)} 
+ \left(1 - r_{\mathcal{S}}^{(t)}\right) 
+ \delta \cdot \left(1 - \mathrm{KM}(\mathcal{S}, t)\right)
\end{cases} 
\tag{5} 
\label{eq:emc5}
\end{equation}

Here $\mathrm{KM}(\mathcal{S}, t) = \overbrace{\rho_{\text{overlap}}}^{\text{semantic matching}} \cdot \underbrace{\mathrm{Synergy}(\mathcal{S})}_{\text{synergy gain}}$ is composite knowledge matching index, $\gamma^{\Delta t} = e^{-\kappa \Delta t}$ ($\kappa > 0$) is exponential time decay factor, and $\delta$ represents prior distribution correction strength per unit knowledge matching.


\textbf{Joint Knowledge-Time-Team Sampling Strategy.} To guide the expert subset selection, we define a comprehensive confidence function $\tilde{\theta}_{\mathcal{S}}^{(t)}$, which incorporates historical performance, knowledge distance, time decay, and team synergy:
% The comprehensive confidence function $\tilde{\theta}_{\mathcal{S}}^{(t)}$ generation process:

\begin{equation}
\resizebox{\linewidth}{!}{$%
\begin{aligned}
\tilde{\theta}_{\mathcal{S}}^{(t)} &= \underbrace{\mathbb{E}\left[\theta_{\mathcal{S}}^{(t)}\right]}_{\text{historical expectation}} 
\cdot \exp\biggl( -\lambda \cdot \overbrace{\text{Dist}(\mathcal{S}, t)}^{\text{knowledge distance}} \biggr) 
\cdot \underbrace{\gamma^{\Delta t}}_{\text{time decay}} 
\cdot \overbrace{\mathrm{Synergy}(\mathcal{S})^\eta}^{\text{synergy effect}} \\[8pt]
&= \left( \frac{\alpha_{\mathcal{S}}^{(t)}}{\alpha_{\mathcal{S}}^{(t)} + \beta_{\mathcal{S}}^{(t)}} \right) 
\cdot \exp\left( -\lambda \cdot \left[ \log(1 + d_t) \cdot \sum_{i=1}^4 \omega_i \Psi_i \right] \right) 
\cdot e^{-\kappa \Delta t} 
\cdot \left( \frac{\sum_{e_i,e_j \in \mathcal{S}} \mathcal{C}_{\text{syn}}(e_i,e_j)}{|\mathcal{S}|(|\mathcal{S}|-1)} \right)^\eta 
\end{aligned}
$}
\tag{6} 
\label{eq:emc6}
\end{equation}

where $\mathbb{E}[\theta_{\mathcal{S}}^{(t)}]$ is the Beta distribution expectation, reflecting the team's historical performance, $\exp\left(-\lambda \cdot \log(1 + d_t) \cdot \sum_{i=1}^4 \omega_i \Psi_i \right)$ is the knowledge distance penalty, $\Psi_i$ are the four sub-indicators defined in Equation~\eqref{eq:emc4}, and $\mathrm{Synergy}(\mathcal{S}) = \frac{1}{|\mathcal{S}|(|\mathcal{S}|-1)} \sum_{e_i,e_j \in \mathcal{S}} \mathcal{C}_{\text{syn}}(e_i,e_j)$ is the synergy effect quantifying team collaboration via the synergy gain coefficient $\mathcal{C}_{\text{syn}}$.

% Key components include: 
% \begin{enumerate}
% \setlength{\itemsep}{0pt}
% \setlength{\parsep}{0pt}
% \setlength{\parskip}{0pt}
% \item \textbf{Historical expectation}: $\mathbb{E}[\theta_{\mathcal{S}}^{(t)}]$, the Beta distribution expectation, reflecting the team's historical performance.  
% \item \textbf{Knowledge distance penalty}: $\exp\left(-\lambda \cdot \log(1 + d_t) \cdot \sum_{i=1}^4 \omega_i \Psi_i \right)$, where $\Psi_i$ are the four sub-indicators defined in Equation~\eqref{eq:emc4}.  
% \item \textbf{Synergy effect}: $\mathrm{Synergy}(\mathcal{S}) = \frac{1}{|\mathcal{S}|(|\mathcal{S}|-1)} \sum_{e_i,e_j \in \mathcal{S}} \mathcal{C}_{\text{syn}}(e_i,e_j)$, quantifying team collaboration via the synergy gain coefficient $\mathcal{C}_{\text{syn}}$.
% \end{enumerate}

% Key components include: 1. \textbf{Historical expectation}: Beta distribution expectation $\mathbb{E}[\theta_{\mathcal{S}}^{(t)}]$ reflecting team historical performance 2. \textbf{Knowledge distance penalty}: $\exp\left(-\lambda \cdot \log(1 + d_t) \cdot \sum_{i=1}^4 \omega_i \Psi_i \right)$ where $\Psi_i$ correspond to four sub-indicators in equation (4) 3. \textbf{Synergy effect}: $\mathrm{Synergy}(\mathcal{S}) = \frac{1}{|\mathcal{S}|(|\mathcal{S}|-1)} \sum_{e_i,e_j \in \mathcal{S}} \mathcal{C}_{\text{syn}}(e_i,e_j)$ with $\mathcal{C}_{\text{syn}}$ as expert synergy gain coefficient.

\textbf{Convergence Analysis of Dynamic Selection Strategy}

\begin{theorem}[$\epsilon$-Approximate Optimal Convergence]
For any $\epsilon > 0$, there exists parameter configuration $(\lambda^*, \eta^*, \gamma^*)$ such that algorithm's cumulative regret within $T$ steps satisfies:

\begin{equation}
\mathcal{R}(T) = \sum_{t=1}^T \left[ \theta_{\mathcal{S}^*}^{(t)} - \theta_{\mathcal{S}_t}^{(t)} \right] \leq \epsilon T + \mathcal{O}\left( \sqrt{T \log T} \right)
\tag{7}
\label{eq:emc7}
\end{equation}

\end{theorem}

% \subsection{Summary}
% \label{sec:summary}
% The KABB framework provides a novel solution approach for expert selection in dynamic multi-agent systems. By introducing knowledge-driven optimization mechanisms, the framework achieves significant improvements in exploration efficiency, decision accuracy, and dynamic adaptability. This research not only provides theoretical support for multi-agent collaborative systems but also explores new possibilities for combining knowledge graphs with dynamic decision-making, demonstrating important academic and practical value.