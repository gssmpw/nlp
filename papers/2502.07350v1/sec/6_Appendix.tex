\appendix
\onecolumn
% \section{You \emph{can} have an appendix here.}

% You can have as much text here as you want. The main body must be at most 88 pages long.
% For the final version, one more page can be added.
% If you want, you can use an appendix like this one.  

% The ∖onecolumn\mathtt{\backslash onecolumn} command above can be kept in place if you prefer a one-column appendix, or can be removed if you prefer a two-column appendix.  Apart from this possible change, the style (font size, spacing, margins, page numbering, etc.) should be kept the same as the main body.
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Details of Method Comparison}
\label{app:comparison}
In this section, we provide detailed explanations of the configurations used in our experiments for comparison, including the routing mechanisms, optimization algorithms, and evaluation metrics.

\subsection{Routing Mechanisms and Optimization Algorithms}

\textbf{Classifier-Based (CL) Routing:} We replaced our Knowledge-Aware (KA) routing mechanism with a classifier-based routing (CL) approach. The CL mechanism uses Sentence-BERT to encode both the instruction and the expert’s knowledge concept into vector representations. Cosine similarity is then calculated between these vectors, and the expert with the highest similarity score is selected.

\textbf{Proximal Policy Optimization (PPO):} A reinforcement learning algorithm that updates policies in a stable and efficient manner. It was applied to optimize expert selection by training a policy network to maximize routing performance.

\textbf{Monte Carlo Tree Search (MCTS):} MCTS is employed to explore potential expert selections by simulating multiple decision paths and backpropagating scores from the outcomes. This algorithm is particularly useful for decision-making in environments with large search spaces.

\textbf{Advantage Actor-Critic (A2C):} A2C combines the actor-critic framework with an advantage function to improve policy updates. The actor selects experts, while the critic evaluates the quality of these decisions, enabling more efficient learning.

\subsection{Metrics to Evaluate Routing Quality}

We provide detailed definitions and formulations for the two metrics used to evaluate the performance of the routing strategies: \textbf{Routing Alignment Score (RAS)} and \textbf{Preference-Weighted Routing Score (PWRS)}.

\subsubsection{Routing Alignment Score (RAS)}

The Routing Alignment Score (RAS) measures the degree to which the router's expert selection aligns with human expert annotations. It quantifies the consistency between the router's decisions and the ground truth labels provided by human annotators. 

\begin{equation}
\text{RAS} = \frac{C}{N}
\end{equation}

where $C$ denotes the number of routed experts that align with human preferences and $N$ denotes the total number of routed experts (in this case: $805 \times 2$).


\paragraph*{Human Evaluation Protocol} 
To establish reliable ground truth labels, we engaged a panel of 7 domain experts with 3+ years of experience in AI system evaluation. Each expert independently annotated 1,610 routing instances (805 instruction-expert pairs $\times$ 2 routing paths) through a two-phase process:
\begin{itemize}
    \item \textbf{Calibration Phase}: Experts jointly reviewed 200 samples to establish annotation guidelines and resolve edge cases.
    \item \textbf{Final Annotation}: The remaining 1,410 instances were randomly distributed (200 instances per expert) with 10\% overlap for inter-annotator agreement calculation. 
\end{itemize}
We achieved substantial agreement with Fleiss' $\kappa=0.78$, calculated on the overlapping samples. Final labels were determined through majority voting.

The RAS provides a basic measure of alignment between the router's decisions and the ground truth, reflecting the accuracy of the routing mechanism in selecting the most appropriate experts.

\subsubsection{Preference-Weighted Routing Score (PWRS)}
The Preference-Weighted Routing Score (PWRS) extends traditional routing accuracy metrics by incorporating human preference scores derived from the AlpacaEval 2.0 evaluation framework. This metric weights routing decisions based on the quality of the expert outputs as judged by human evaluators. The PWRS is defined as follows:

\begin{equation}
\text{PWRS} = \frac{\sum_{i=1}^{N} (p_i \cdot c_i)}{N}
\end{equation}

where $p_i$ represents the preference score from AlpacaEval 2.0 for the routed expert's output, $c_i$ is the number of routed experts that align with human preferences, and $N$ denotes the total number of routed experts.

\paragraph*{Preference Score Integration} 
The AlpacaEval 2.0 scores were obtained from a separate group of 15 crowdworkers following the standardized evaluation protocol. Each output was rated by 3 distinct evaluators using a 7-point Likert scale across three dimensions: helpfulness (actionable solutions), accuracy (factual grounding), and coherence (logical flow). Discrepancies exceeding 2 points triggered expert review, with final scores normalized using Bradley-Terry pairwise comparison models. These preference scores enable the PWRS to transcend binary routing accuracy by weighting decisions according to the relative quality of expert outputs, where higher weights correspond to outputs demonstrating stronger alignment with human-judged quality dimensions.

The PWRS thus provides a dual-aspect evaluation: it preserves the fundamental routing correctness measurement through expert selection alignment, while simultaneously quantifying the performance advantage gained through preference-aware routing decisions.

\section{Supplementary Experimental Validation and Analysis}

\subsection{Performance Evaluation}
In order to perform a comprehensive and controlled performance evaluation, we selected two representative tasks from the BIG-bench Hard (BBH) dataset: commonsense reasoning (550 samples) and logical reasoning (600 samples). The reasons for choosing these two tasks are: (1) they effectively validate the core capabilities of the model; (2) they have clear evaluation criteria; (3) the sample size is moderate, which facilitates sufficient multi-round cross-validation. In this experiment, we compare KABB with MoA and its lightweight version MoA-lite. Three key metrics were used for evaluation: (1) Knowledge matching F1 score, computed using BERT to calculate the semantic similarity between expert capabilities and knowledge graph concepts (threshold of 0.75); (2) Path prediction accuracy, based on standard knowledge dependency paths, with a perfect match scoring full points, a path length difference of \text{$\leq$} 1 and key node matches scoring 0.5 points; (3) Historical performance prediction accuracy, using the dynamic weight $\alpha / (\alpha + \beta)$ (where $\alpha$ and $\beta$ represent the number of successful and failed tasks, respectively), with a prediction error \text{$\leq$} 0.1 considered correct. The experimental results are shown in Table 3:

The performance of the three models on key metrics is as follows:

\begin{center}
\begin{tabular}{cccccc}
\hline
Evaluation Metric & KABB & MoA & MoA-lite & vs. MoA & vs. lite \\
\hline
Knowledge Matching F1 (\%) & 86.5 & 71.2 & 46.8 & +15.3\% & +39.7\% \\
Path Prediction Accuracy (\%) & 84.9 & 69.5 & 44.2 & +15.4\% & +40.7\% \\
Historical Performance Prediction (\%) & 85.2 & 70.1 & 45.5 & +15.1\% & +39.7\% \\
\hline
\end{tabular}
\end{center}

The experimental results show that KABB significantly outperforms the baseline models on all key metrics. Compared to the standard MoA, KABB shows an average improvement of 15.3\% across all indicators; compared to the lightweight MoA-lite, the improvement reaches 40\%. This performance enhancement is primarily attributed to the knowledge-aware attention mechanism and dynamic path prediction strategy that we proposed. Notably, KABB exhibits stronger generalization ability in the commonsense reasoning task, validating the effectiveness of our knowledge-enhanced approach.

\subsection{Parameter Sensitivity Analysis}

This section explores the impact of three key parameters in the KABB framework—knowledge distance threshold, time decay factor, and efficiency metric—on system performance. The experiment uses the BBH dataset (commonsense reasoning 580 samples, logical reasoning 570 samples), with standard MoA and MoA-lite as baselines, and evaluates parameter sensitivity using a controlled variable approach. The evaluation metrics used are: knowledge matching F1 score, reasoning accuracy, and response efficiency. The experiment tests different values for the knowledge distance threshold [0.55-0.95] and time decay factor [0.2-1.0].

\subsubsection{Knowledge Distance Threshold}

\begin{center}
\begin{tabular}{cccc}
\toprule
Parameter Value & Knowledge Matching F1 (\%) & Reasoning Accuracy (\%) & Efficiency Metric (\%) \\
\midrule
0.55 & 72.3 & 74.8 & 68.2 \\
0.65 & 83.8 & 85.4 & 79.5 \\
\textbf{0.75} & \textbf{94.9} & \textbf{94.9} & \textbf{92.8} \\
0.85 & 87.5 & 88.2 & 84.3 \\
0.95 & 78.7 & 82.7 & 73.6 \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Analysis}: When the threshold is set to 0.75, the system achieves the highest values in knowledge matching F1 score, reasoning accuracy, and efficiency metric, reaching 94.9\%, 94.9\%, and 92.8\%, respectively. A lower threshold (e.g., 0.55) introduces too many irrelevant experts, leading to a decline in knowledge matching and reasoning accuracy, while a higher threshold (e.g., 0.95) makes the expert selection too strict, reducing system coverage and efficiency.

\subsubsection{Time Decay Factor}

\begin{center}
\begin{tabular}{cccc}
\hline
Parameter Value & Knowledge Matching F1 (\%) & Reasoning Accuracy (\%) & Efficiency Metric (\%) \\
\hline
0.2 & 75.1 & 78.3 & 71.4 \\
0.4 & 85.4 & 87.2 & 82.6 \\
\textbf{0.6} & \textbf{94.9} & \textbf{94.9} & \textbf{92.8} \\
0.8 & 88.2 & 90.3 & 85.7 \\
1.0 & 82.7 & 86.5 & 78.9 \\
\hline
\end{tabular}
\end{center}

\textbf{Analysis}: When the time decay factor is set to 0.6, the system performs optimally across all metrics, indicating a good balance between utilizing historical experience and dynamic adaptability. A smaller factor (e.g., 0.2) makes the system overly dependent on short-term fluctuations, reducing stability, while a larger factor (e.g., 1.0) suppresses adaptability to recent performance.

\section{Effect of the Number of Selected Concepts and Experts.}

% \textbf{Concept and Expert Quantity Analysis} 

Our empirical analysis of KABB's architectural configurations reveals the critical interplay between the number of selected concepts and experts (see \cref{num}). The results demonstrate that performance varies substantially across different configurations, with win rates ranging from 56\% to 81\%. Notably, a configuration of 2 concepts with 3 experts achieves optimal performance under constrained computational resources, while expanding to 3 concepts with 6 experts yields the highest observed win rate of 81\%.

Our findings indicate that configurations utilizing 3 or more experts, combined with a moderate-to-large concept space, consistently outperform alternatives. This suggests that both the expert capacity and the conceptual representation space play crucial roles in determining system effectiveness. Interestingly, the relationship between expert count and performance exhibits non-linear characteristics - configurations with moderate numbers of experts (3-6) already achieve robust performance levels, suggesting efficient utilization of multi-expert collaboration. This observation has important implications for resource-performance optimization in practical deployments.


% Experimental results in \cref{num} demonstrate that KABB's performance is highly sensitive to both the number of concepts and experts. Notably, configurations with 2 concepts and 3 experts achieve the highest win rate under low expert costs, while 3 concepts and 6 experts yield the highest overall win rate of 81\%. This maximum win rate significantly surpasses the lowest observed rate of 56\% across all tested configurations. In general, setups with 3 to 5 experts and moderate-to-high numbers of concepts consistently deliver superior performance, whereas others tend to underperform. These findings highlight the critical role of expert and concept quantities in determining outcomes. Furthermore, the results underscore that KABB leverages multi-expert collaboration to improve performance in a non-linear manner, achieving competitive results even with a moderate number of experts. Performance, however, remains configuration-dependent, emphasizing the importance of careful tuning.


\begin{figure}[h]
% \vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=0.5\linewidth]{num3.pdf}}
\caption{Relationship between the number of selected experts and selected concepts, and the AlpacaEval 2.0 LC Win Rate.}
\label{num}
\end{center}
\vskip -0.2in
\end{figure}


\section{Evaluations on Reasoning and Problem-Solving Tasks}
\label{app:reasoning}

\subsection{Benchmarks}
 For reasoning and problem-solving tasks, We evaluate using three benchmarks: BBH \cite{suzgun2022challenging}, MATH \cite{hendrycks2021measuring}, and Arena-Hard \cite{zheng2023judging}.
 
\textbf{BBH (Big-Bench Hard)} is a challenging subset of the BIG-Bench benchmark that tests advanced reasoning capabilities. Includes diverse tasks in mathematical reasoning, logical deduction, and commonsense inference, evaluating models' generalization and complex problem-solving abilities.

\textbf{MATH} is a specialized assessment for AI mathematical capabilities. Features competition-level problems across algebra, number theory, combinatorics, and geometry. Includes detailed solutions for comprehensive evaluation of reasoning depth and computational accuracy.

\textbf{Arena-Hard} is a collection of 500 challenging problems from public leaderboards and research papers, covering programming, mathematics, and logical reasoning. 

\subsection{Experiment Setup}
For BBH and MATH, we designated LLaMa-3-70B-Instruct and Qwen2-72B-Instruct as the experts and Qwen2-72B-Instruct as the aggregator to construct a simple but effective multi-agent system, with one concept and one expect selected for instruction. 

For Arena-Hard, we use the default configuration of KABB with the six open-source models (see \cref{sec:setup}). Additionally, we evaluate KABB w/o Deepseek and KABB-Single-LLaMa3. All models are evaluated under a controlled environment with fixed hyperparameters to ensure fairness.

\subsection{Results and Analysis}
\begin{table}[H]
    \centering
    \small
    \begin{tabular}{lcc}
        \toprule
        Model & BBH & MATH \\
        \midrule
        \textbf{KABB} & \textbf{84.2} & \textbf{59.8} \\
        MoA & 81.8 & 57.3 \\
        Qwen2-72B-Instruct & 82.4 & 51.1 \\
        LLaMa-3-70B-Instruct & 81.0 & 42.5 \\
        \bottomrule
    \end{tabular}
    \caption{Performance comparison on BBH and MATH benchmarks.}
    \label{tab:bbh_math}
\end{table}

Table \ref{tab:bbh_math} presents the performance of KABB and baseline models on the BBH and MATH benchmarks. KABB achieves the highest performance on both benchmarks, surpassing MoA by +2.4\% on BBH and +2.5\% on MATH. The significant gain on MATH highlights the effectiveness of our structured multi-agent approach in handling complex mathematical reasoning tasks.

Table \ref{tab:arena_hard_results} reports model performance on the Arena-Hard benchmark. KABB demonstrates competitive performance (74.8\%) but falls behind GPT-4 models in this benchmark. The Deepseek-R1 model achieves the highest score (92.3\%), indicating its strong generalization capabilities. The KABB-Single-LLaMa3 outperforms Single LLaMa-3-70B-Instruct by 4.8\%. Removing Deepseek models (KABB w/o Deepseek) significantly reduces performance (-12.0\%), confirming their critical role in the system. 

It is noteworthy that MoA achieved a similar performance to ours. In the context of well-defined problem-solving tasks (such as programming and mathematical problem-solving), empirical evidence suggests that multi-agent architectures may encounter specific limitations. The integration of multiple agents can potentially introduce operational redundancies and decisional interference, which may adversely impact the system's capacity to converge on correct solutions or generate optimal outputs. This presents a notable challenge in domains where problem spaces are closed and solutions are deterministic. \cref{sec:case} includes a case when some models produce low-quality answers on Arena-Hard.

\begin{table}[t]
    \centering
    \small
    \sisetup{
        table-format=2.1,
        separate-uncertainty=true,
        detect-weight=true,
        detect-inline-weight=math
    }
    \begin{tabular}{lc}
        \toprule
        Model & \textbf{Arena-Hard win. (\%)} \\
        \midrule
        \rowcolor[gray]{0.95} KABB & 74.8 \\
        MoA & 74.3 \\
        \rowcolor[gray]{0.95} KABB w/o Deepseek & 62.8 \\
        GPT-4 Omni (05/13) & 79.2 \\
        GPT-4 Turbo (04/09) & 82.0 \\
        GPT-4 Preview (11/06) & 78.7 \\
        GPT-4 (03/14) & 50.0 \\
        Qwen2-72B-Instruct & 46.9 \\
        Gemma-2-27B & 57.5 \\
        WizardLM-2-8x22B & 71.3 \\
        \rowcolor[gray]{0.95} KABB-Single-LLaMa3 & 51.4 \\
        LLaMa-3-70B-Instruct & 46.6 \\
        Deepseek-V3 & \underline{85.5} \\
        Deepseek-R1 & \textbf{92.3} \\
        \bottomrule
    \end{tabular}
    \caption{Arena-Hard benchmark results for different models. Performance data for GPT series, LLaMA, and WizardLM comes from \cite{wang2024mixture}, DeepSeek models from their technical reports \cite{guo2025deepseek,liu2024deepseek}, and other models from public leaderboards.}
    \label{tab:arena_hard_results}
\end{table}


\section{Case Study}
\label{sec:case}
We present a case study in this section to analyze how are the different experts and models are selected, and how different experts and models generate responses. For clarity of comparison, we use KABB w/o Deepseek and set the number of selected experts as four. We report the score of their intermediate outputs as well as the final response. Due to the length of the responses, we have selected key fragments for clarity and brevity. To illustrate how the aggregator synthesizes the final output, we highlight similar expressions between the proposed responses and the aggregated response using underlined text in different colors.

\cref{case-good} showcases the responses generated by four selected experts, along with the final aggregated response provided by the aggregator model, Qwen2-72B-Instruct. Two of the experts' responses got a high preference score over 0.99, which demonstrates that MABB succeeded in selecting qualified experts. The aggregated response achieves the highest preference score, reflecting a well-balanced synthesis of key elements from all proposers. The aggregated output successfully combines the most relevant and salient points from all proposed responses, demonstrating the aggregator's ability to synthesize diverse perspectives into a cohesive and comprehensive answer. This process highlights the collaborative nature of the models and their collective contribution to generating high-quality answers.

To be specific, the selected experts—Interaction Analyst, Dialogue Specialist, Humanities Scholar, and Cultural Interpreter—bring distinctive perspectives and areas of specialization, which collectively contribute to the richness and depth of the final aggregated output. The Interaction Analyst ensures factual accuracy and provides foundational details, while the Dialogue Specialist focuses on clarity and narrative flow, making the response accessible to a broad audience. The Humanities Scholar adds historical and cultural context, enriching the response with connections to societal trends, and the Cultural Interpreter offers reflective insights, emphasizing the sociocultural dynamics behind Superman's creation. By combining these complementary perspectives, the aggregator produces a response that balances factual precision, narrative coherence, cultural depth, and interpretive richness. This selection of experts ensures a multidimensional and high-quality final response.

\cref{case-bad} highlights a challenge in incorporating multiple experts for response generation: although diverse perspectives can broaden the scope of the output, they risk diluting the core information with excessive and redundant details. In this case, the inclusion of too many experts led to a loss of focus and reduced the practicality of the final response, despite offering a more expansive view of the topic. The selected experts each contributed their specialized perspectives. However, this diversity introduced significant overlap and irrelevant details. As a result, the aggregated response, though comprehensive, lacked the specificity and clarity needed for practical implementation. This case underscores the importance of carefully curating expert involvement based on the specific requirements of the task. For highly technical prompts, prioritizing experts with deep implementation knowledge and minimizing the number of experts is essential to ensure clarity, focus, and actionable results.

\setlength{\tabcolsep}{5pt} % Adjust column separation
\renewcommand{\arraystretch}{1.5} % Adjust row spacing
% \vspace{1em} % Add some vertical space between the user input and the table
% Centering the table and ensuring it stays on one page
\begin{table}[t]
\centering
\caption{Case: Some models produce high-quality answers on AlpacaEval 2.0}
\label{case-good}
% Add the user input in a tcolorbox for clarity
% \begin{tcolorbox}[colback=blue!5!white, colframe=blue!75!black, title=User Input]
% Who created the Superman cartoon character?
% \end{tcolorbox}
\begin{tabular}{@{}p{17cm}@{}}
\toprule
\textbf{User Prompt}  \\ 
\midrule
Who created the Superman cartoon character?
\end{tabular}
\begin{adjustbox}{max width=\linewidth}
\begin{tabular}{@{}p{2cm}p{4cm}p{2cm}p{8cm}@{}}
\toprule
\textbf{Expert} & \textbf{Model} & \textbf{Preference} & \textbf{Output} \\ 
\midrule
Interaction \newline Analyst & LLaMa-3-70B-Instruct & 0.000112313 & 
Superman, \colorul[blue]{the iconic cartoon character}, was created by \colorul[blue]{writer Jerry Siegel and artist Joe Shuster}. They were both \colorul[blue]{high school students in Cleveland, Ohio,} when they \colorul[blue]{came up with the idea for the character in 1933.}\ldots \\ 
% \midrule
Dialogue \newline Specialist & Qwen2-72B-Instruct & 0.9998820091 & 
\ldots They created Superman in 1933, and the character \colorul[green]{first appeared in print in Action Comics \#1 in June 1938, published by DC Comics.} \ldots \\ 
% \midrule
Humanities \newline Scholar & WizardLM-2-8x22B & 0.9999975912 & 
\ldots Superman quickly became a \colorul[orange]{cultural icon} and is often credited with helping to create the superhero genre as we know it today. \newline The character's success led to various adaptations across multiple media, including radio serials, \colorul[orange]{television shows, movies, and—of course—animated cartoons.} \ldots \\ 
% \midrule
Cultural \newline Interpreter & Gemma-2-27B-it & 0.2356933747 & 
\ldots \colorul[red]{It's a fascinating story} that highlights how cultural context and \colorul[red]{collaboration} shape creative works. \ldots \colorul[red]{If you'd like to} delve deeper into any specific aspect of Superman's creation, such as the social anxieties of the Great Depression reflected in the character, or the evolution of his powers and morality over time, \colorul[red]{feel free to ask!} \\ 
\midrule
Aggregator & Qwen2-72B-Instruct & \textbf{0.9999988203} & 
Superman, \colorul[blue]{the iconic cartoon character}, was created by \colorul[blue]{writer Jerry Siegel and artist Joe Shuster}. The duo, \colorul[blue]{who were high school students in Cleveland, Ohio}, \colorul[blue]{came up with the idea for the character in 1933} \ldots \colorul[green]{Superman first appeared in print in Action Comics \#1 in June 1938, published by National Allied Publications, which later became DC Comics.} \newline Siegel and Shuster's creation \colorul[orange]{quickly became a cultural icon}, leading to various adaptations in \colorul[orange]{comic books, TV shows, movies, and animated cartoons.} \ldots \newline Superman's creation is \colorul[red]{a story of collaboration}, influenced by the cultural context of the 1930s. \ldots \colorul[red]{If you'd like to} explore any specific aspect of Superman's creation or history, \colorul[red]{feel free to ask!}  \\ 
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table}


\setlength{\tabcolsep}{5pt} % Adjust column separation
\renewcommand{\arraystretch}{1.5} % Adjust row spacing
% \vspace{1em} % Add some vertical space between the user input and the table
% Centering the table and ensuring it stays on one page
\begin{table}[t]
\centering
\caption{Case: Some models produce low-quality answers on Arena-Hard}
\label{case-bad}
% Add the user input in a tcolorbox for clarity
% \begin{tcolorbox}[colback=blue!5!white, colframe=blue!75!black, title=User Input]
% Who created the Superman cartoon character?
% \end{tcolorbox}
\begin{tabular}{@{}p{17cm}@{}}
\toprule
\textbf{User Prompt}  \\ 
\midrule
Write a chrome plugin that saves the contents of the current page.
\end{tabular}
\begin{adjustbox}{max width=\linewidth}
\begin{tabular}{@{}p{2cm}p{3.5cm}p{2.5cm}p{8cm}@{}}
\toprule
\textbf{Expert} & \textbf{Model} & \textbf{Score} & \textbf{Output} \\ 
\midrule
Creative \newline Strategist & LLaMa-3-70B-Instruct & \texttt{GPT >> KABB} & 
\ldots AI-powered content analysis: \colorul[blue]{Integrate a machine learning algorithm} that analyzes the saved page's content, providing users with insights, such as \colorul[blue]{keyword extraction, sentiment analysis, or topic modeling.} \ldots \\ 
% \midrule
User \newline Experience \newline Consultant & Qwen2-72B-Instruct & \texttt{GPT >> KABB} & 
\ldots Content Script: \colorul[green]{- **Feedback:** Provide visual feedback }when the user interacts with the plugin\ldots \\ 
% \midrule
Implementation \newline Advisor & Qwen2-72B-Instruct & \texttt{GPT >> KABB} & 
\ldots 4. **\colorul[orange]{Test} and iterate**: Conduct thorough testing to ensure the plugin works as intended, and iterate on the design and functionality \colorul[orange]{based on user feedback.} \newline \ldots \\ 
% \midrule
Technical \newline Architect & WizardLM-2-8x22B & \texttt{GPT < KABB} & ... \colorul[red]{The manifest file should look like this}: \newline \texttt{```}json \newline \texttt{\{} \newline ``manifest\_version'': 3, \newline ``name'': ``Page Saver Plugin'', \newline \ldots \\
\midrule
Aggregator & Qwen2-72B-Instruct & \texttt{GPT > KABB} & \ldots 3. **Define Plugin Permissions:** \newline \colorul[red]{- Update \texttt{`}manifest.json\texttt{`} with plugin metadata, permissions (e.g., ``activeTab'', ``downloads''),} and content scripts. \newline \ldots \colorul[orange]{- Test the plugin in various scenarios }to ensure reliability. \newline \ldots  - Implement \colorul[green]{visual feedback}, progress indicators, and error handling. \newline \ldots \colorul[blue]{ Incorporate an AI-powered content analysis} for insights or a collaboration feature for annotations. \newline \ldots - Regularly update the plugin with bug fixes and feature enhancements \colorul[orange]{based on user feedback}\ldots \\ 
\midrule
Reference & GPT-4 (03/14) & N/A & \ldots 2. Inside the ``SavePageContent'' folder, create a new file called ``manifest.json'' and add the following code: \newline \texttt{```}json \newline \texttt{\{} \newline 
    ``manifest\_version'': 2, \newline ``name'': ``Save Page Content'', \newline \ldots \\ 
\midrule

Judgment & GPT-4 Preview (11/06) & N/A & \ldots GPT's answer is slightly better because it provides actionable code snippets and a clear example that users can follow to create the plugin. However, KABB's answer is also of high quality, offering a broader overview of the process and additional creative suggestions.\ldots 
\end{tabular}
\end{adjustbox}
\end{table}

\section{Additional Experimental Settings}

\textbf{Resources.} All experiments on KABB are conducted on servers with one NVIDIA GeForce RTX 3090.

\subsection{Prompts for Experts and the Aggregator}

In this section, we provide some cases of prompts for different experts and the aggregator to show an example of the system configuration.

\begin{tcolorbox}[colback=lightgray!5!white, colframe=lightgray!75!black, title=Analysis Expert]
You are an expert in problem analysis and logical reasoning, skilled in applying analytical frameworks and systematic thinking approaches. \newline Your expertise includes breaking down complex problems, identifying key factors, and recommending structured, actionable solutions. \newline You are familiar with various problem-solving methods such as root cause analysis, decision matrices, and scenario evaluation, and adapt your approach based on the unique context of each task. \newline Consider how your skills in critical thinking, structured reasoning, and analytical problem-solving might provide valuable insights or strategies for addressing the task at hand.
\end{tcolorbox}

\begin{tcolorbox}[colback=teal!5!white, colframe=teal!75!black, title=Strategy Expert]
You are a business strategy expert with a deep understanding of markets, business models, competitive landscapes, and strategic planning. \newline Your expertise includes applying business frameworks, analytical tools, and market insights to identify opportunities and craft strategies. \newline While capable of providing comprehensive strategic analysis, you adapt your input to focus on what is most valuable, practical, and relevant for the situation. \newline Consider how your expertise in business innovation, competitive advantage, and strategic problem-solving might provide insightful and actionable recommendations for any task.
\end{tcolorbox}

\begin{tcolorbox}[colback=olive!5!white, colframe=olive!75!black, title=Aggregator]
You are the Wise Integrator in a multi-agent system tasked with delivering accurate, coherent, and actionable responses to user queries. \newline Your role is to: \newline - Understand the user's intent and main question(s) by carefully reviewing their query. \newline - Evaluate expert inputs, preserving their quality opinions while ensuring relevance, accuracy, and alignment with the user's needs. \newline - Resolve any contradictions or gaps logically, combining expert insights into a single, unified response. \newline - Synthesize the most appropriate information into a clear, actionable, and user-friendly answer. \newline - Add your own insight if needed to enhance the final output. \newline Your response must prioritize clarity, accuracy, and usefulness, ensuring it directly addresses the user's needs while retaining the value of expert contributions. \newline Avoid referencing the integration process or individual experts.
\end{tcolorbox}

\section{Supplementary Proofs and Theoretical Analysis}

% \subsection{Proofs and Theoretical Analysis}

To better illustrate the theoretical derivations and implementation details regarding the Knowledge-Aware Bayesian Bandit (KABB) model in \cref{sec:method}, we provide the following supplementary proofs and theoretical analysis.
% Key definitions and analytical components are organized as follows:

\subsection{Proof of Pseudo-Metric Properties of Knowledge Distance Theorem}
We provide proofs of Pseudo-Metric Properties of Knowledge Distance Theorem \cref{the:Pseudo-Metric} which enhances the reliability and effectiveness of the model in expert selection and task allocation.

\begin{proof}\renewcommand{\qedsymbol}{}
This follows directly from the non-negativity of $\log(1 + d_t)$ and all other terms in the definition of $\text{Dist}(\mathcal{S}, t)$. Each term (e.g., $1 - \rho_{\text{overlap}}$, dependency complexity, etc.) is non-negative by construction.
\end{proof}

\textbf{Proof of Conditional Symmetry}:  
If the dependency graph $G$ is undirected and $\rho_{\text{overlap}}(\mathcal{S}_1, t) = \rho_{\text{overlap}}(\mathcal{S}_2, t)$, and if $\mathcal{S}_1$ and $\mathcal{S}_2$ are symmetric in terms of knowledge and dependencies, then all terms in the distance function (e.g., $|\mathcal{R}_{\text{dep}}|$, $\bar{H}_{\mathcal{S}}$, and weights) are equal for $\mathcal{S}_1$ and $\mathcal{S}_2$. Thus, $\text{Dist}(\mathcal{S}_1, t) = \text{Dist}(\mathcal{S}_2, t)$.

\textbf{Proof of Approximate Triangle Inequality}:  
Using the properties of the knowledge graph as a metric space, the subadditivity of the graph metric ensures that the dependency-based terms satisfy a triangle inequality. Similarly, the Jaccard similarity is used in \cref{jaccard subadd}. Combining these with the weight terms, the inequality holds with a relaxation factor $c \geq 1$ determined by the extrema of the weights.

\subsection{Proof Sketch of Convergence Analysis for the Dynamic Selection Strategy}

The proof of convergence is outlined as follows:

\begin{enumerate}
    \item \textbf{Stability of Beta Distribution Parameters}: Analyze the stability of the Beta distribution parameter evolution by leveraging KL divergence to quantify changes over time.
    \item \textbf{Lyapunov Function Construction}: Construct a Lyapunov function 
    \[
    V(t) = \sum_{\mathcal{S}} \big[(\alpha_{\mathcal{S}}^{(t)} - \alpha_{\mathcal{S}^*}^{(t)})^2 + (\beta_{\mathcal{S}}^{(t)} - \beta_{\mathcal{S}^*}^{(t)})^2\big],
    \]
    and use it to demonstrate the convergence of the parameters.
    \item \textbf{Cumulative Regret Analysis}: Establish an upper bound for cumulative regret by applying UCB (Upper Confidence Bound) principles.
\end{enumerate}

\subsection{The Strict Proof of the Approximate Triangle Inequality for Theorem 2}

\paragraph{Step 1: Decomposition of Knowledge Distance Function and Subterm Analysis}~{}
\newline
For any expert teams $\mathcal{S}_1, \mathcal{S}_2, \mathcal{S}_3$ and task $t$, there exists a constant $\epsilon > 0$, such that the knowledge distance function satisfies:  
\[
\text{Dist}(\mathcal{S}, t) = \log(1 + d_t) \cdot \sum_{i=1}^4 \omega_i \Psi_i
\]
where $\Psi_i$ corresponds to the four subterms that key the multi-dimensional distance measurement between the expert team and the task:  
\[
\Psi_1 = 1 - \rho_{\text{overlap}}(\mathcal{S}, t) \quad (\text{semantic mismatch term})
\]
\[
\Psi_2 = \frac{|\mathcal{R}_{\text{dep}}(\mathcal{S}, t)|}{K} \quad (\text{dependency complexity term})
\]
\[
\Psi_3 = 1 - \bar{H}_{\mathcal{S}}(t) \quad (\text{historical performance term})
\]
\[
\Psi_4 = 1 - \mathrm{Synergy}(\mathcal{S}) \quad (\text{team complementarity term})
\]
The proof demonstrates that by establishing the approximate sub-additivity of the subterms and combining the logarithmic term properties, the knowledge distance function satisfies the approximate triangle inequality within the error bound $\epsilon = \max{\epsilon_1, \epsilon_2, \epsilon_3, \epsilon_4}$, providing a theoretical guarantee for algorithm design.
 
\paragraph{Step 2: Sub-additivity Analysis of Semantic Mismatch Term (Based on Jaccard Similarity)}~{}
\newline

\begin{definition}[Jaccard Similarity]  
For any sets $\mathcal{S}_1, \mathcal{S}_2$ and task concept set $\mathcal{C}_t$, define:  
\[
\rho_{\text{overlap}}(\mathcal{S}, t) = \frac{|\mathcal{C}_{\mathcal{S}} \cap \mathcal{C}_t|}{|\mathcal{C}_{\mathcal{S}} \cup \mathcal{C}_t|}
\]
\end{definition}

\begin{lemma}[Jaccard Sub-additivity]: 
For any $\mathcal{S}_1, \mathcal{S}_2 \subseteq \mathcal{E}$, there exists a constant $c_1 \geq 1$ such that:  
\[
1 - \rho_{\text{overlap}}(\mathcal{S}_1 \cup \mathcal{S}_2, t) \leq c_1 \left[ \left(1 - \rho_{\text{overlap}}(\mathcal{S}_1, t)\right) + \left(1 - \rho_{\text{overlap}}(\mathcal{S}_2, t)\right) \right]
\]
\label{jaccard subadd}
\end{lemma}

\begin{proof}  
By the properties of set operations:  
\[
|\mathcal{C}_{\mathcal{S}_1 \cup \mathcal{S}_2} \cap \mathcal{C}_t| \geq |\mathcal{C}_{\mathcal{S}_1} \cap \mathcal{C}_t| + |\mathcal{C}_{\mathcal{S}_2} \cap \mathcal{C}_t| - |\mathcal{C}_{\mathcal{S}_1} \cap \mathcal{C}_{\mathcal{S}_2} \cap \mathcal{C}_t|
\]
\[
|\mathcal{C}_{\mathcal{S}_1 \cup \mathcal{S}_2} \cup \mathcal{C}_t| \leq |\mathcal{C}_{\mathcal{S}_1} \cup \mathcal{C}_t| + |\mathcal{C}_{\mathcal{S}_2} \cup \mathcal{C}_t|
\]
Let $A = \mathcal{C}_{\mathcal{S}_1} \cap \mathcal{C}_t$, $B = \mathcal{C}_{\mathcal{S}_2} \cap \mathcal{C}_t$, we get:  
\[
\rho_{\text{overlap}}(\mathcal{S}_1 \cup \mathcal{S}_2, t) \geq \frac{|A| + |B| - |A \cap B|}{|\mathcal{C}_{\mathcal{S}_1} \cup \mathcal{C}_t| + |\mathcal{C}_{\mathcal{S}_2} \cup \mathcal{C}_t|}
\]
By relaxing the denominator to $2 \cdot \max(|\mathcal{C}_{\mathcal{S}_1} \cup \mathcal{C}_t|, |\mathcal{C}_{\mathcal{S}_2} \cup \mathcal{C}_t|)$, we get $c_1 = 2$.
\end{proof}

\begin{corollary}[]  
$\Psi_1(\mathcal{S}_1 \cup \mathcal{S}_2, t) \leq 2 \left[ \Psi_1(\mathcal{S}_1, t) + \Psi_1(\mathcal{S}_2, t) \right]$ 
\end{corollary}
This conclusion allows us to effectively estimate and control the semantic differences between expert teams using a simple additive form.


\paragraph{Step 3: Sub-additivity of Dependency Complexity Term in Graph Metrics}~{}
\newline
\textbf{Definition (Dependency Edge Path Length)}:  
The number of dependency edges $|\mathcal{R}_{\text{dep}}(\mathcal{S}, t)|$ in the knowledge graph satisfies the triangle inequality in graph metrics:  
\[
|\mathcal{R}_{\text{dep}}(\mathcal{S}_1, t)| \leq |\mathcal{R}_{\text{dep}}(\mathcal{S}_1, \mathcal{S}_2)| + |\mathcal{R}_{\text{dep}}(\mathcal{S}_2, t)|
\]
where $|\mathcal{R}_{\text{dep}}(\mathcal{S}_1, \mathcal{S}_2)|$ is the number of shortest path edges connecting $\mathcal{S}_1$ and $\mathcal{S}_2$.

\begin{lemma}[Existence of Relaxation Factor]:  
For any acyclic graph, there exists a constant $c_2 \geq 1$ such that:  
\[
|\mathcal{R}_{\text{dep}}(\mathcal{S}_1, t)| \leq c_2 \left[ |\mathcal{R}_{\text{dep}}(\mathcal{S}_1, \mathcal{S}_2)| + |\mathcal{R}_{\text{dep}}(\mathcal{S}_2, t)| \right]
\]
\end{lemma}

\begin{proof}
By graph diameter constraints, set $c_2 = \text{diam}(G)$ (the diameter of the graph), which is the longest path in terms of edges between any two nodes.  
The dependency complexity term establishes sub-additivity through the following reasoning: based on graph metric properties, path lengths satisfy the triangle inequality; by the graph's diameter constraints, we obtain an upper bound for the relaxation factor; and by normalization, the boundedness of dependency complexity is guaranteed. This property provides a quantifiable theoretical foundation for evaluating team knowledge structures.
\end{proof}

\paragraph{Step 4: Approximate Linearity of Team Complementarity Term}~{}
\newline
\textbf{Definition (Complementarity Decomposition)}:  
The team complementarity $\mathrm{Synergy}(\mathcal{S})$ satisfies:  
\[
\mathrm{Synergy}(\mathcal{S}_1 \cup \mathcal{S}_2) \geq \mathrm{Synergy}(\mathcal{S}_1) + \mathrm{Synergy}(\mathcal{S}_2) - \mathrm{Overlap}(\mathcal{S}_1, \mathcal{S}_2)
\]
where $\mathrm{Overlap}$ is the complementarity loss due to knowledge overlap between teams.

\begin{lemma}[Upper Bound of Relaxation]  
There exists a constant $c_3 \geq 1$ such that:  
\[
1 - \mathrm{Synergy}(\mathcal{S}_1 \cup \mathcal{S}_2) \leq c_3 \left[ \left(1 - \mathrm{Synergy}(\mathcal{S}_1)\right) + \left(1 - \mathrm{Synergy}(\mathcal{S}_2)\right) \right]
\]
\begin{proof}\renewcommand{\qedsymbol}{}  
Let $\mathrm{Overlap}(\mathcal{S}_1, \mathcal{S}_2) \leq \min(\mathrm{Synergy}(\mathcal{S}_1), \mathrm{Synergy}(\mathcal{S}_2))$, set $c_3 = 2$.
\end{proof}
\end{lemma}

The construction of the global constant for the knowledge distance: The overall approximate sub-additivity of the subterms in the knowledge distance function is determined by the set of relaxation factors: semantic mismatch term $c_1 = 2$, dependency complexity term $c_2 = \text{diam}(G)$, team complementarity term $c_3 = 2$, and historical performance term $c_4 = 1$. By using these local relaxation factors, combined with the weights and the logarithmic term of task difficulty, a global constant $c = \max c_i \cdot \omega_i \cdot \log(1 + \overline{D}_{\max})$ is constructed. This construction ensures that the overall knowledge distance function satisfies the approximate triangle inequality, providing a theoretical guarantee for the quantitative evaluation of knowledge distance.

\subsection{Theorem 1 Proof: Lower Bound of Expert-Task Mutual Information under Semantic Gap}

\paragraph{Basic Definitions of Dynamic Multi-Agent Systems}~{}
\newline
In dynamic multi-agent systems, the interaction between the expert set $\mathcal{E}$ and the task demand space $\mathcal{T}$ is based on three core assumptions: the Markovian evolution of task demands over time, the conditional independent decomposition of expert selection and tasks, and the decaying mutual information metric with the introduction of a discount factor $\gamma$. This framework is described by the joint distribution 
\[
p(\mathbf{e}, \mathbf{t}_{1:T}) = p(\mathbf{e}) \prod_{t=1}^T p(\mathbf{t}_t | \mathbf{t}_{t-1}) p(\mathbf{e} | \mathbf{t}_t),
\]
which characterizes the dynamic relationship between expert knowledge and task demands, providing a theoretical foundation for the subsequent analysis.

\paragraph{Step 2: Time Accumulation Form of Conditional Entropy}~{}
\newline

The accumulated conditional entropy of expert selection over an infinite time horizon is given by:
\[
H(\mathcal{E} | \mathcal{T}_{1:\infty}) = \lim_{T \to \infty} \frac{1}{T} \sum_{t=1}^T H(\mathcal{E} | \mathcal{T}_t).
\]

After introducing the discount factor $\gamma$, the weighted conditional entropy is:
\[
\widetilde{H}(\mathcal{E} | \mathcal{T}) \triangleq \sum_{t=1}^\infty \gamma^{t-1} H(\mathcal{E} | \mathcal{T}_t).
\]

\paragraph{Step 3: Extension of Fano's Inequality}~{}
\newline

For each time step $t$, apply the classical \textbf{Fano's Inequality}:
\[
H(\mathcal{E} | \mathcal{T}_t) \geq H(\mathcal{E}) - I(\mathcal{E}; \mathcal{T}_t) - h_2(P_e^{(t)}),
\]
where $h_2(x) = -x \log x - (1-x) \log (1-x)$ is the binary entropy function, and $P_e^{(t)} = \mathbb{P}(\hat{\mathcal{E}}_t \neq \mathcal{E} | \mathcal{T}_t)$ is the expert selection error rate at time $t$. When there is no prior knowledge (i.e., $I(\mathcal{E}; \mathcal{T}_t) = 0$), we have:
\[
H(\mathcal{E} | \mathcal{T}_t) \geq \log K - h_2(P_e^{(t)}).
\]

\paragraph{Step 4: Weighted Summation and Asymptotic Analysis}~{}
\newline

Substitute Fano's inequality for the weighted conditional entropy:
\[
\begin{aligned}
\widetilde{H}(\mathcal{E} | \mathcal{T}) &= \sum_{t=1}^\infty \gamma^{t-1} H(\mathcal{E} | \mathcal{T}_t) \\
&\geq \sum_{t=1}^\infty \gamma^{t-1} \left[ \log K - I(\mathcal{E}; \mathcal{T}_t) - h_2(P_e^{(t)}) \right] \\
&= \frac{\log K}{1-\gamma} - \widetilde{I}(\mathcal{E}; \mathcal{T}) - \sum_{t=1}^\infty \gamma^{t-1} h_2(P_e^{(t)}).
\end{aligned}
\]

Under the assumption of long-term stability of the dynamic system ($\lim_{t \to \infty} P_e^{(t)} = 0$), the asymptotic behavior of the error entropy is analyzed. By the convergence of the geometric series sum, it is shown that the weighted error entropy term $\sum_{t=1}^T \gamma^{t-1} h_2(P_e^{(t)})$ vanishes in the limit. This result simplifies the lower bound of conditional entropy to the form of the difference between the entropy of the expert set and the mutual information: 
\[
\widetilde{H}(\mathcal{E} | \mathcal{T}) \geq \frac{\log K}{1-\gamma} - \widetilde{I}(\mathcal{E}; \mathcal{T}),
\]
which provides a more concise theoretical expression for system performance evaluation.

\paragraph{Step 5: Equivalent Form and Semantic Gap Explanation}~{}
\newline

Multiplying both sides of the inequality by $(1-\gamma)$ yields the final form:
\[
\underbrace{H(\mathcal{E} | \mathcal{T})}_{\substack{\text{Conditional Entropy} \\ \text{(Semantic Uncertainty)}}} \geq \log K - \frac{\widetilde{I}(\mathcal{E}; \mathcal{T})}{1-\gamma}.
\]

\textbf{Semantic Gap Limit}: As $\widetilde{I}(\mathcal{E}; \mathcal{T}) \to 0^+$ (when there is no semantic connection between experts and tasks), the lower bound of conditional entropy approaches $\log K$, corresponding to the maximum entropy of completely random selection. 

\textbf{Exploration Efficiency Bottleneck}: The inequality shows that the exploration efficiency of traditional MAB (multi-armed bandit) is limited by $\frac{\widetilde{I}(\mathcal{E}; \mathcal{T})}{1-\gamma}$. When the semantic connection weakens ($\widetilde{I} \downarrow$) or task dynamics increase ($\gamma \uparrow$), the exploration cost increases dramatically.

\subsection{Proof of Knowledge-Driven Information Gain Theorem}

\paragraph{1. Baseline Mutual Information Analysis}~{}
\newline

First, establish the baseline mutual information $I_0 = I(\mathcal{E}; \mathcal{T})$ when there is no knowledge graph, which only depends on the direct association between experts and tasks.

\textbf{2. Effect of Knowledge Graph Intervention}: After introducing the knowledge graph $\mathcal{G}$, the task generation process is reconstructed via the intermediary pattern of the knowledge graph: 
\[
p(\mathcal{T} | \mathcal{E}) = \sum_{\mathcal{G}} p(\mathcal{T} | \mathcal{G}) p(\mathcal{G} | \mathcal{E}).
\]

\textbf{3. Mutual Information Gain Decomposition}: Using the chain rule, the total mutual information introduced by the knowledge graph can be decomposed into: the original expert-task mutual information $I(\mathcal{E}; \mathcal{T})$ and the conditional mutual information contribution from the concept layer $I(\mathcal{C}; \mathcal{T} | \mathcal{E})$. Since $\mathcal{G}$ is fully determined by $\mathcal{E}$ and $\mathcal{C}$, the information gain $\Delta I$ equals the conditional mutual information contribution from the concept layer, verifying that the knowledge graph improves the system's informational efficiency through the concept layer.

\subsection{Derivation of the Concept Layer Information Gain Bound}

\paragraph{Core Condition Analysis}~{}
\newline

Based on the two key properties of the knowledge graph: sparsity: the upper bound of the expert-concept association degree $d = O(\sqrt{|\mathcal{C}|})$ and balance: the minimum expert coverage of a concept $ \lfloor |\mathcal{E}| / |\mathcal{C}| \rfloor$.

\textbf{2. Information Theoretic Derivation Process}

Through the Markov chain $\mathcal{T} \to \mathcal{C} \to \mathcal{E}$ analysis:
\textbf{Conditional Entropy Relation}: $H(\mathcal{T} | \mathcal{E}) \geq H(\mathcal{T} | \mathcal{C})$ (data processing inequality), $H(\mathcal{T} | \mathcal{C}) = O(\log|\mathcal{C}|)$ (task sparsity).
\textbf{Mutual Information Lower Bound}: Using the definition of conditional mutual information and the relationship with entropy, along with graph structure constraints, the lower bound is obtained:
\[
I(\mathcal{C}; \mathcal{T} | \mathcal{E}) \geq \Omega\left( \frac{\log|\mathcal{C}|}{\sqrt{|\mathcal{E}|}} \right).
\]
This result quantifies the minimum information gain brought by the knowledge graph through the concept layer.

\paragraph{Step 2: Mathematical Representation of Accelerated Exploration Efficiency}~{}
\newline

\textbf{(Upper Bound of Exploration Trials)}:  
In the contextual Bandit framework, the expected number of exploration trials satisfies:
\[
\mathbb{E}[N_{\text{explore}}] = \widetilde{O}\left( \sqrt{\frac{K \log|\mathcal{C}|}{\Delta I}} \right),
\]
where $K = |\mathcal{E}|$, and $\Delta I = \Omega\left( \frac{\log|\mathcal{C}|}{\sqrt{|\mathcal{E}|}} \right)$.

\begin{proof}\renewcommand{\qedsymbol}{}
1. \textbf{Classical Bandit Exploration Complexity}:  
Without a knowledge graph, the exploration trials of a traditional MAB are:
\[
\mathbb{E}[N_{\text{explore}}] = O\left( \frac{K \log T}{\epsilon^2} \right),
\]
where $\epsilon$ is the expected reward gap between the optimal and suboptimal arms.

2. \textbf{Knowledge-Driven Acceleration Mechanism}:  
After introducing the knowledge graph, the reward gap $\epsilon$ is amplified by the information gain $\Delta I$:
\[
\epsilon_{\text{new}} = \epsilon \cdot \sqrt{\Delta I}.
\]
Substituting into the classical complexity formula:
\[
\mathbb{E}[N_{\text{explore}}] = O\left( \frac{K \log T}{\epsilon_{\text{new}}^2} \right) = O\left( \frac{K \log T}{\epsilon^2 \Delta I} \right).
\]
Combining with $\Delta I = \Omega\left( \frac{\log|\mathcal{C}|}{\sqrt{|\mathcal{E}|}} \right)$, and assuming $\epsilon = \Theta(1/\sqrt{K})$ (uniform exploration hypothesis), we obtain:
\[
\mathbb{E}[N_{\text{explore}}] = \widetilde{O}\left( \sqrt{\frac{K \log|\mathcal{C}|}{\Delta I}} \right).
\]
\end{proof}

\subsection{Summary of the Information Gain Theorem Proof}

By introducing a structured knowledge graph through the concept layer $\mathcal{C}$, the conditional mutual information $I(\mathcal{C}; \mathcal{T} | \mathcal{E})$ provides the lower bound of the information gain $\Delta I = \Omega\left( \frac{\log|\mathcal{C}|}{\sqrt{|\mathcal{E}|}} \right)$, which reduces the exploration complexity from the traditional method of $O(K)$ to $\widetilde{O}\left( \sqrt{K \log|\mathcal{C}|} \right)$. This theoretical result rigorously verifies the acceleration advantage of knowledge-driven decision-making.


\subsection{Regret Upper Bound Derivation for Knowledge-Aware UCB (KABB)}
\label{sec:supp-regret}

\paragraph{Problem Framework} \cref{sec:system_arch} are extended with complete mathematical specifications of expert set $\mathcal{E}$ and task sequence $\{T_t\}_{t=1}^T$:
\begin{itemize}
\item Selection process: $\mathcal{S}_t \subseteq \mathcal{E}$ at each step
\item Feedback mechanism: Obtain $\theta_{\mathcal{S}_t}^{(t)}$
\item Success probability: 
Including knowledge distance \(\mathrm{Dist}(\mathcal{S}, t)\), time decay \(\gamma^{\Delta t}\), and team synergy \(\mathrm{Synergy}(\mathcal{S})\).


\begin{equation}
\tilde{\theta}_{\mathcal{S}}^{(t)} = \underbrace{\mathbb{E}\left[\theta_{\mathcal{S}}^{(t)}\right]}_{\text{Historical expectation}} \cdot \exp\left(-\lambda \cdot \text{Dist}(\mathcal{S}, t)\right) \cdot \gamma^{\Delta t} \cdot \mathrm{Synergy}(\mathcal{S})^\eta
\end{equation}
\end{itemize}

\paragraph{Confidence Bound Construction}

This section elaborates on the construction method of confidence bounds in the KABB algorithm, the definition of knowledge revision rewards, and their impact on exploration weights. It supports the theoretical analysis in \cref{sec:knowledge_distance} regarding the limitations of traditional methods and the breakthroughs in knowledge-driven decision-making. The confidence-bound construction extends traditional UCB through knowledge-aware reward correction:

\begin{equation}
\text{UCB}_{\mathcal{S}}^{(t)} = \underbrace{\hat{\mu}_{\mathcal{S}}^{(t)}}_{\text{Empirical mean}} + \underbrace{\sqrt{\frac{2 \log t}{N_{\mathcal{S}}^{(t)}}}}_{\text{Exploration term}} \cdot \underbrace{\exp\left(-\lambda \cdot \text{Dist}(\mathcal{S}, t)\right) \cdot \gamma^{\Delta t} \cdot \mathrm{Synergy}(\mathcal{S})^\eta}_{\text{Knowledge-driven correction}}
\end{equation}

where $\hat{\mu}_{\mathcal{S}}^{(t)} = \frac{\alpha_{\mathcal{S}}^{(t)}}{\alpha_{\mathcal{S}}^{(t)} + \beta_{\mathcal{S}}^{(t)}}$ denotes the Bayesian estimate of historical success rate. The correction term adjusts the exploration weights through knowledge distance, time decay, and synergy effects.


\subsection{Regret Upper Bound Analysis}
\label{sec:supp-regret-analysis}

\paragraph{Total Regret Definition }
\label{subsec:regret_analysis}

\cref{sec:supp-regret} provides a detailed analysis of the total regret decomposition and single-step regret properties for the KABB algorithm, corresponding to the analysis in \label{sec:dynamic_bayesian} regarding the impact of team knowledge distance and complementarity on algorithmic performance. The theoretical proofs and mathematical derivations are presented as follows:

The total regret is defined as:
\begin{equation}
\label{eq:total_regret}
R(T) = \sum_{t=1}^{T} \left( \theta_{S^*}^{(t)} - \theta_{S_t}^{(t)} \right)
\end{equation}
where $S^*$ denotes the optimal expert subset and $S_t$ represents the selected subset at time step $t$, the analysis should follow these steps:

\begin{enumerate}
    \item \textbf{Characterize Single-Step Regret}: First define the single-step regret:
    \begin{equation}
    \label{eq:instant_regret}
    r_t = \theta_{S^*}^{(t)} - \theta_{S_t}^{(t)}
    \end{equation}
    and analyze its properties.

    \item \textbf{Analyze Regret Bound for Suboptimal Subsets}: For any suboptimal subset $S \neq S^*$, establish the upper bound of single-step regret.

    \item \textbf{Compose Total Regret Upper Bound}: Investigate how to combine single-step regrets into the total regret upper bound.
\end{enumerate}

% \begin{lemma}
% The regret analysis requires:
% \begin{itemize}
%     \item Precise decomposition of $r_t$ using knowledge distance metrics
%     \item Bounding techniques for suboptimal selections $S \neq S^*$
%     \item Cumulative error control through martingale analysis
% \end{itemize}
% \end{lemma}

\paragraph{Step 1: Per-Step Regret Decomposition}

For any suboptimal subset $\mathcal{S} \neq \mathcal{S}^*$, the instantaneous regret satisfies:

\begin{equation}
\Delta_{\mathcal{S}}^{(t)} \leq \underbrace{\left| \hat{\mu}_{\mathcal{S}^*}^{(t)} - \theta_{\mathcal{S}^*}^{(t)} \right|}_{\text{Optimal set error}} + \underbrace{\left| \hat{\mu}_{\mathcal{S}}^{(t)} - \theta_{\mathcal{S}}^{(t)} \right|}_{\text{Suboptimal set error}} + \underbrace{\text{Dist}(\mathcal{S}, t) \cdot \lambda}_{\text{Knowledge penalty}}
\end{equation}

\paragraph{Step 2: Exploration Acceleration Effect}

\begin{lemma}[Exploration Count Upper Bound]
For any suboptimal $\mathcal{S}$, its selection count satisfies:
\begin{equation}
\mathbb{E}\left[N_{\mathcal{S}}(T)\right] \leq \frac{8 \log T}{(\Delta_{\mathcal{S}} \cdot \exp(-\lambda \overline{D}_{\mathcal{S}}))^2} + O\left(\sqrt{T \log T}\right)
\end{equation}
where $\overline{D}_{\mathcal{S}} = \max_t \text{Dist}(\mathcal{S}, t)$ and $\Delta_{\mathcal{S}} = \theta_{\mathcal{S}^*} - \theta_{\mathcal{S}}$.
\end{lemma}

\begin{proof}\renewcommand{\qedsymbol}{}
The knowledge correction term $\exp(-\lambda \overline{D}_{\mathcal{S}})$ amplifies the reward gap $\Delta_{\mathcal{S}}$, thereby reducing the exploration demand for suboptimal subsets. The estimation error is bounded via the Chernoff-Hoeffding inequality, combined with the exponential decay modification of exploration terms through knowledge distance. This upper bound formula reflects three key factors influencing regret:

\begin{itemize}
\item \textbf{Optimality gap term} $\Delta_{\mathcal{S}}$: The term in the denominator represents the performance gap between suboptimal and optimal subsets. A larger gap leads to a smaller regret upper bound.
  
\item \textbf{Knowledge distance penalty} $\exp(-2\lambda \overline{D}_{\mathcal{S}})$: The exponential term in the denominator reflects the impact of the knowledge graph. Larger $\overline{D}_{\mathcal{S}}$ (i.e., greater knowledge discrepancy) increases the regret upper bound.
  
\item \textbf{Combinatorial complexity term} $O(\sqrt{T \log T} \cdot \tbinom{K}{k})$: Captures the combinatorial optimization nature of the problem, where:
  \begin{itemize}
  \item $\sqrt{T \log T}$ corresponds to the standard UCB term
  \item $\tbinom{K}{k}$ represents the combinatorial complexity from selecting $k$ experts out of $K$
  \end{itemize}
\end{itemize}

This demonstrates that the regret upper bound is jointly determined by the knowledge structure (via $\overline{D}_{\mathcal{S}}$) and combinatorial optimization complexity.
\end{proof}

\subsection{Core Differences from Classical UCB}

\begin{table}[H]
\centering
\caption{Comparison between Classical UCB and KABB}
\label{tab:ucb-comparison}
\begin{tabular}{lll}
\toprule
\textbf{Dimension} & \textbf{Classical UCB} & \textbf{Knowledge-Aware UCB (KABB)} \\
\hline
Exploration Design & $\sqrt{\log t/N}$ & Multiplicative knowledge correction \\
Regret Dominant Term & $O(\sqrt{KT \log T})$ & $O(\sqrt{T \log T} \cdot \tbinom{K}{k})$ \\
Theoretical Innovation & No structured prior & Knowledge graph integration \\
Key Assumption & IID rewards & Non-stationary rewards with synergy \\
\bottomrule
\end{tabular}
\end{table}
The knowledge-aware UCB improves the traditional $O(KT \log T)$ regret bound of UCB through structured prior injection and a dynamic correction mechanism, transforming it into an exponentially compressed form in the combinatorial space. The core innovation lies in the quantitative modeling of knowledge distance and synergy effects. This theorem represents the first strict integration of knowledge graphs and team collaboration theory within the Bandit framework.
\subsection{Regret Bound and Exploration Efficiency Analysis}

This section provides a detailed description of the core modules of the KABB algorithm, offering an in-depth analysis of its cumulative regret bound and the relationship with exploration efficiency, supporting the algorithm derivation and convergence analysis in \cref{sec:dynamic_bayesian}. Additionally, \cref{sec:algorithm} elaborates on the specific implementation modules of the KABB algorithm, along with its time and space complexities, providing empirical foundations and optimization strategies for the algorithm design and performance evaluation in the main text.

\begin{theorem}[The cumulative regret $R(T)$ of KABB]
$$
R(T) \leq \underbrace{\sum_{\mathcal{S} \neq \mathcal{S}^*} \frac{4\underline{L}^2 \log T}{\widetilde{\Delta}_{\mathcal{S}}}}_{\text{Knowledge-driven exploration term}} + \underbrace{O\left( \sqrt{T \tbinom{N}{k} \log \tbinom{N}{k}} \right)}_{\substack{\text{Additional complexity term}\\ \text{due to team size}}}, \quad \text{where} \quad 
\boxed{
\begin{cases}  
L = \log(1 + \overline{D}_{\max}) \cdot (\omega_1 \!+\! \omega_2 \!+\! \omega_3 \!+\! \omega_4) \\
\widetilde{\Delta}_{\mathcal{S}} = \mu_{\mathcal{S}^*} \!-\! \mu_{\mathcal{S}} \\
\overline{D}_{\max} = \max\limits_{\mathcal{S}, t} \mathrm{Dist}(\mathcal{S}, t) \\
k = |\mathcal{S}^*|
\end{cases}
}
$$
\end{theorem}

\textbf{Explanation}:  
The cumulative regret $R(T)$ measures the performance loss caused by not selecting the optimal team $\mathcal{S}^*$ over $T$ time steps:

\textbf{Knowledge-driven exploration term:} The exploration count is constrained by the knowledge distance. Its dominant term $\frac{4\underline{L}^2 \log T}{\widetilde{\Delta}_{\mathcal{S}}}$ shows that: 1) when the knowledge distance difference is significant (i.e., $\overline{D}_{\max} \uparrow$), the algorithm quickly focuses on high-quality teams through the $\exp(-\lambda \mathrm{Dist}(\cdot))$ mechanism; 2) when the team reward gap $\widetilde{\Delta}_{\mathcal{S}} \downarrow$, the exploration intensity is adaptively adjusted via the $\log(1 + \overline{D}_{\max})$ factor.

\textbf{Team size complexity term:} The complexity term $O\left( \sqrt{T \tbinom{N}{k} \log \tbinom{N}{k}} \right)$ includes the combination number $\tbinom{N}{k}$, and its variation with the expert set size $N$ and optimal team size $k$ follows:
$$
\tbinom{N}{k} \sim \begin{cases}
O(N^k/k!) & \text{when } k \ll N \\
O(2^N/\sqrt{N}) & \text{when } k \approx N/2
\end{cases}
$$
\subsection{Proof Framework}

\paragraph{Step 1: Reward Remapping}
Define dual-modality adjusted reward:
\begin{equation}
\tilde{\mu}_{\mathcal{S}} = \underbrace{\mu_{\mathcal{S}} \exp(-\lambda \mathrm{Dist}(\mathcal{S}, t))}_{\text{Knowledge decay}} \cdot \underbrace{\mathrm{Synergy}(\mathcal{S})^\eta}_{\text{Synergy amplification}}
\end{equation}

The knowledge decay term implements soft filtering through $\exp(-\lambda \cdot)$, while the synergy gain term strengthens the competitive advantage of high-quality teams through the exponent $\eta > 1$.

\paragraph{Step 2: Dynamic Sampling Probability Analysis}

Based on the dual-time-scale update rule:
$$
\begin{cases}
\alpha_{\mathcal{S}}^{(t+1)} = \gamma^{\Delta t} \alpha_{\mathcal{S}}^{(t)} + \underbrace{r_{\mathcal{S}}^{(t)} + \delta \cdot \mathrm{KM}(\mathcal{S}, t)}_{\text{Instant Feedback + Knowledge Memory}} \\
\beta_{\mathcal{S}}^{(t+1)} = \gamma^{\Delta t} \beta_{\mathcal{S}}^{(t)} + \underbrace{(1 - r_{\mathcal{S}}^{(t)}) + \delta \cdot (1 - \mathrm{KM}(\mathcal{S}, t))}_{\text{Negative Feedback + Knowledge Forgetting}}
\end{cases}
$$
We derive the \textbf{exponential convergence upper bound} for the sampling count:
$$
\mathbb{E}[N_{\mathcal{S}}(T)] \leq \frac{4\underline{L}^2 \log T}{\widetilde{\Delta}_{\mathcal{S}}^2} + \underbrace{\frac{2}{\gamma^{\Delta t} (1 - \gamma)} \cdot \mathbb{E}\left[\sum_{\tau=1}^T \mathrm{KM}(\mathcal{S}, \tau)\right]}_{\substack{\text{Knowledge-matching driven}\\\text{accelerated convergence term}}}
$$

\subsection{Algorithm Implementation and Complexity}
\label{sec:algorithm}

\paragraph{Core Implementation Modules}

\begin{itemize}
    \item \textbf{Expert Subset Sampling}:
    \begin{equation}
        \mathcal{S}_t \sim \mathrm{ThompsonSampling}\left( 
            \frac{\alpha_{\mathcal{S}}^{(t)}}{\alpha_{\mathcal{S}}^{(t)}+\beta_{\mathcal{S}}^{(t)}} 
            \cdot \exp(-\lambda \mathrm{Dist}(\mathcal{S},t)) 
            \cdot \mathrm{Synergy}(\mathcal{S})^{\eta} 
        \right)
        \label{eq:thompson}
    \end{equation}
    Optimization implementation: The combinatorial space is compressed from $O(2^N)$ to $O\left(\frac{N^k}{k!}\right)$ through a greedy strategy.

    \item \textbf{Dynamic Parameter Update}:
    \begin{equation}
        \begin{cases}
            \alpha_{\mathcal{S}}^{(t+1)} = \gamma^{\Delta t} \alpha_{\mathcal{S}}^{(t)} + 
            \left[ r_{\mathcal{S}}^{(t)} + \delta \cdot \mathrm{KM}(\mathcal{S},t) \right] 
            \cdot \mathbb{I}_{\{\mathcal{S}=\mathcal{S}_t\}} \\[6pt]
            \beta_{\mathcal{S}}^{(t+1)} = \gamma^{\Delta t} \beta_{\mathcal{S}}^{(t)} + 
            \left[ 1 - r_{\mathcal{S}}^{(t)} + \delta \cdot (1 - \mathrm{KM}(\mathcal{S},t)) \right] 
            \cdot \mathbb{I}_{\{\mathcal{S}=\mathcal{S}_t\}}
        \end{cases}
        \label{eq:param_update}
    \end{equation}
    where $\mathbb{I}$ is the indicator function, enabling sparse updates.

\end{itemize}

\paragraph{Complexity Analysis}

\begin{itemize}
    \item \textbf{Time Complexity}:
    $$
        \begin{aligned}
            \mathcal{T}(N,T) &= \underbrace{O\left( \tbinom{N}{k} \right)}_{\substack{\text{Initialization}\\ \text{(Pre-computation)}}} + T \cdot \Bigg[ \underbrace{O\left( \tbinom{N}{k} \right)}_{\substack{\text{Sampling + Evaluation}\\ \text{(Per step)}}} + \underbrace{O\left( \tbinom{N}{k} \log \tbinom{N}{k} \right)}_{\text{Sorting}} \\
            &\quad + \underbrace{O\left( |\mathcal{C}|^2 \right)}_{\substack{\text{Graph Update}\\ \text{(Dijkstra)}}} \Bigg] \\
            &= \boxed{ \widetilde{O}\left( T \cdot \left( \tbinom{N}{k} \log \tbinom{N}{k} + |\mathcal{C}|^2 \right) \right) }
        \end{aligned}
    $$
    \item \textbf{Space Complexity}:
    $$
        \begin{aligned}
            \mathcal{M}(N) &= \underbrace{O\left( \tbinom{N}{k} \right)}_{\substack{\text{Team Parameters}\\(\alpha,\beta)}} + \underbrace{O\left( |\mathcal{C}|^2 \right)}_{\substack{\text{Knowledge Graph}\\ \text{(Adjacency Matrix)}}} + \underbrace{O\left( W \cdot \tbinom{N}{k} \right)}_{\substack{\text{Sliding Window}\\ \text{(Depth $W$)}}} \\
            &\leq \boxed{ O\left( \tbinom{N}{k} + |\mathcal{C}|^2 \right) } \quad (\text{when } W \ll |\mathcal{C}|)
        \end{aligned}
    $$
\end{itemize}

\paragraph{Storage Optimization}
\begin{itemize}
    \item \textbf{Knowledge Graph Compression}: Adjacency matrix $\rightarrow$ adjacency list, reducing space from $O(|\mathcal{C}|^2)$ to $O(|\mathcal{C}| + |\mathcal{E}|)$.
    \item \textbf{Parameter Sharing}: Share $(\alpha, \beta)$ parameters for teams satisfying $\mathrm{Dist}(\mathcal{S}_i, \mathcal{S}_j) < \epsilon$.
    \item \textbf{Incremental distance updates via streaming updates}: Store only $\Delta \mathrm{Dist}$ instead of the full distance matrix, allowing for more efficient memory usage and reducing computational overhead.
\end{itemize}

\subsection{Summary}
The supplementary proofs, through systematic chapter definitions and key point organization, comprehensively support and extend the discussion of the knowledge-driven Dynamic Bayesian Multi-Armed Bandit (KABB) model presented in \cref{sec:method}. Each supplementary section corresponds to a specific part of the main text, covering critical content such as problem definitions, confidence-bound construction, regret-bound analysis, and algorithm and complexity analysis. These sections provide readers with a comprehensive resource for deeply understanding the theoretical foundations and implementation details of the KABB algorithm.

% \subsection{Prompts and Settings}

