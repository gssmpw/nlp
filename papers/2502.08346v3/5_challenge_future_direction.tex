\section{Challenges and Future Directions}

GFMs have demonstrated great potential in recommender systems by incorporating graph structural information  with external world knowledge of LLM. However, several challenges hinder their widespread adoption and effectiveness.

\paragraph{High Computational Cost and Scalability Issues.}
Existing GFM-based RS require substantial computational resources, posing challenges for large-scale deployment \cite{zhai2024actions}. The integration of graph-based reasoning and LLM inference results in high memory consumption and slow inference speed, particularly when processing dense user-item graphs or generating personalized recommendations in real-time \cite{10.1145/3640457.3688161}. Unlike traditional recommendation models, which can be efficiently pruned or quantized, GFMs face unique scalability constraints due to their reliance on long-range graph dependencies and LLM-generated representations. Addressing these limitations requires advancements in efficient model compression strategies tailored for graph-enhanced LLMs, and adaptive graph sparsification techniques to maintain performance while reducing overhead.

\paragraph{Robustness Against Noisy and Adversarial Data.}
Real-world user interactions are inherently noisy, exhibiting short-term fluctuations, incomplete preferences, and adversarial perturbations \cite{zhang2023robust}. Traditional recommendation models rely on explicit feedback signals, making them susceptible to biased or manipulated data. In contrast, GFMs integrate graph-based user-item relationships and LLM-generated contextual representations, which introduces additional sources of noise from both structured and unstructured data. Ensuring robustness requires advancements in self-supervised denoising techniques, adversarial training tailored for multimodal representations, and uncertainty-aware modeling to mitigate the impact of unreliable signals while preserving recommendation accuracy.

\paragraph{Multi-Modal Information Fusion.}
Modern recommendation scenarios involve a diverse range of data modalities, including text, structured graphs, images, audio, and video \cite{tao2020mgat}. While existing GFMs primarily focus on textual and structural embeddings, effectively incorporating rich multi-modal signals remains an open challenge. Different modalities exhibit varying levels of granularity, semantic gaps, and computational costs, making seamless integration nontrivial. Future research should explore adaptive fusion frameworks, cross-modal alignment mechanisms, and lightweight multi-modal representation learning to balance efficiency and accuracy in large-scale recommender systems.

\paragraph{Lack of End-to-End Optimization.}  
% Many existing methods rely on a multi-stage optimization pipeline, where different components—such as graph-based prompt construction, LLM inference, and downstream task adaptation—are optimized separately. For example, in graph-enhanced prompting strategies, the first stage typically focuses on designing optimal prompt generation rules, which are then fixed when fine-tuning the LLM for response generation. Such staged optimization does not necessarily lead to a globally optimal solution, as errors or biases introduced in earlier stages may propagate through the system. Future research should explore unified training frameworks that allow joint optimization across all components, ensuring a more synergistic integration of graph structures and LLM reasoning.
The concept of end-to-end recommender system is not unfamiliar. When deep learning was introduced into the field of recommendation, a process encapsulation was essentially performed~\cite{covington2016deep}. However, the early neural model RS have gradually fallen behind the times. The process of such RS can be roughly divided into three stages: matching, ranking, and re-ranking~\cite{gao2023survey}. In reality, this process is often more refined in industrial applications. Such a meticulous process naturally results in better recommendation performance. However, multi-stage model optimization requires a significant investment of time and manpower. Contrarily, an end-to-end generative RS, different from the one mentioned above, encapsulates multiple stages together for optimization. This significantly reduces complexity and can potentially lead to better performance. Gradually, similar endeavors are being pursued in the industrial field. HSTU~\cite{zhai2024actions} simplifies the internal structure of the LLM and fully implements it through serial modeling. Moreover, \cite{wang2024llm} takes into account both structural and textual information. Such an integrated generative recommendation that combines matching and ranking may likely be a hotspot in the future.

\paragraph{Knowledge-Preference Gap.}
While GFMs leverage external knowledge to alleviate data sparsity, a fundamental misalignment persists between globally pre-trained world knowledge and personalized user preferences \cite{10.1145/3640457.3688161}. Unlike embedding alignment, which focuses on bridging modality gaps (e.g., between graph structures and textual representations), this discrepancy stems from differences in how LLMs interpret knowledge and how users express preferences. For instance, LLM-based recommendation models may naturally generate factually coherent but overly neutral item descriptions, whereas users often respond more favorably to engaging or sensationalized content (e.g., ``Shocking! You won’t believe this..."). Addressing this challenge requires advancing preference-aware knowledge adaptation, dynamic refinement techniques, and contrastive learning strategies tailored to user-specific interests.
