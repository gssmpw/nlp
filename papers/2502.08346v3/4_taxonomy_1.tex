% \section{Graph-Augmented Large Language Models}
% \label{sec:graph-llm}

% Large Language Models (LLMs) excel at understanding and generating text but struggle with the complex relational structures inherent in recommender systems. While pre-training corpora and in-context learning provide some information, they lack an explicit mechanism to model the intricate relationships between users, items, and their attributes that are naturally represented as graphs. Recent research bridges this gap by integrating Graph Neural Networks (GNNs) with LLMs, focusing on the core challenge: \textbf{How to design cross-modal interfaces that effectively bridge graph structures to language models?} Current methods can be broadly categorized into token-level and context-level infusion. Our work will concentrate on these two primary categories, leaving aside for now the investigation of more complex architectures like Wang et al.'s~\cite{wang2024llm} LLM4REC, which integrates graph information by modifying the LLM's attention mechanism with GNN-learned edge representations. These advanced approaches, while promising, are still in early stages of development and fall outside the current scope.

% \subsection{Token-Level Infusion}
% \label{subsec:token-injection}

% This strategy integrates graph information directly into the LLM's input at the token level. Nodes or subgraphs are represented as special tokens, allowing the LLM to process graph information alongside text.

% \begin{equation}
% \mathbf{e}_{v} = f(\mathbf{h}_v)
% \end{equation}
% where $G = (\mathcal{V}, \mathcal{E})$ is a graph, a GNN learns node representations $\mathbf{h}_v \in \mathbb{R}^d$ for each $v \in \mathcal{V}$, and these are projected into the LLM's embedding space via a mapping $f: \mathbb{R}^d \rightarrow \mathbb{R}^{d_{\text{LLM}}}$, creating special token embeddings $\mathbf{e}_{v}$.

% \textbf{Syntax-Integrated Injection}
% This approach embeds special tokens as syntactic components within the LLM's input sequence. For instance, Ma~\cite{ma2024triple} introduce \texttt{[ACTION]} tokens like \texttt{[view]} or \texttt{[purchase]} to represent user actions within an interaction sequence. The embeddings for these actions are learned from a multi-behavior graph, enabling the LLM to process complex semantics like ``user \texttt{[views]} item". Building on this, Wang~\cite{wang2024enhancing} generate a GCN-based embedding $\mathbf{h}_i$ for each item $i$ and add it as a correction term to the item's original text embedding $\mathbf{e}_i$, resulting in a refined embedding $\mathbf{e'}_i = \mathbf{e}_i + \mathbf{h}_i$. This blends textual and structural information, improving item representation.

% A natural progression from here is to consider whether the LLM can directly output these special tokens. Guo~\cite{guo2024integrating} explore this by not only including special tokens in the input but also modifying the LLM's output layer. They introduce a special token for each item, allowing the model to directly generate item tokens as recommendations, effectively creating a tighter link between graph-based recommendations and the LLM's output. Further advancing this line of thought, Mei~\cite{mei2023lightlm} propose a hierarchical indexing scheme. Instead of treating user/item IDs as atomic units, they decompose them into multiple special tokens based on a user-item graph-derived index. Each component token encodes a different attribute or function, moving away from opaque numerical IDs towards more semantically meaningful representations.

% \textbf{Syntax-Decoupled Injection}
% This method appends graph embeddings as prefixes or suffixes, separating graph information from the main textual prompt. Ma~\cite{ma2024xrec} prepend GNN-learned embeddings that represent user-item relationships to the prompt. These embeddings are trained to capture high-level semantic concepts, such as preference similarity between users. Qiu~\cite{qiu2024unveiling} combine user queries with knowledge graph embeddings. A GNN generates embeddings that encapsulate both the user's query and relevant knowledge graph entities, which are then used as a prefix to guide the LLM towards more informed recommendation rationales.

% Token-level infusion offers a fine-grained way to integrate graph information, allowing for nuanced interactions between textual and structural data. However, it often requires modifications to the LLM's architecture or careful prompt engineering.

% \subsection{Context-Level Infusion}
% \label{subsec:prompt-injection}

% This strategy provides graph information as context to the LLM, either through text descriptions or implicit retrieval, avoiding modifications to the LLM's architecture.

% \begin{align}
%     \texttt{user A} &\rightarrow \texttt{purchase} \rightarrow \texttt{item B} \notag \\
%     &\Rightarrow \texttt{user A purchased item B.} \notag \\
%     C(v_q) &= \text{TopK}\left(\{\text{sim}(\mathbf{h}_{v_q}, \mathbf{h}_v) | v \in \mathcal{V}\}\right)
% \end{align}
    
% Where the first example illustrate explicit graph-to-text mapping. The second equation represents implicit graph retrieval, where $C(v_q)$ represents content for a query or subgraph $v_q$, $\text{sim}$ is a similarity function (e.g., cosine similarity) and $\mathcal{V}$ is the set of all nodes in the graph.

% \textbf{Explicit Graph-to-Text Mapping}
% This method involves converting localized graph structures into natural language descriptions, essentially translating graph relationships into text. The simplest form of this is exemplified by Jia~\cite{jia2025hetgcot}. They extract multi-hop neighbor nodes of a target node from a heterogeneous graph and concatenate their attributes to create a natural language description. This description becomes the context for the LLM, informing its recommendations. Similarly, Abu-Salih~\cite{abu2024knowledge} extract one-hop and two-hop related nodes from a knowledge graph and insert them into predefined prompt templates. These templates, now populated with graph information, guide the LLM in generating explainable recommendation rationales.

% Further refinements involve pre-processing the graph information before mapping it to text. Guan~\cite{guan2024enhancing} maintain a dynamic queue of negative samples, items the user is known to dislike, based on knowledge graph insights and LLM feedback. Providing both positive and negative samples as context for the LLM allows for more nuanced recommendations. The processing of graph information can also occur after its initial conversion to text. Wu~\cite{wu2024exploring} construct natural language descriptions of node paths in a job information graph. Each path represents a sequence of related job attributes or skills. During prompt construction, these paths are assigned different weights based on relevance and dependency strength, offering a more refined, contextually rich input to the LLM.

% \textbf{Implicit Graph Retrieval}
% When explicit mapping is difficult, this approach uses GNN embeddings to retrieve relevant information from the graph semantically. Chen~\cite{chen2024leverage} apply this in the legal domain. They encode a legal knowledge graph using a GNN, and retrieve relevant legal provisions based on the similarity between a user's case description embedding and the provision embeddings. These provisions are then concatenated into the prompt context. Shen~\cite{shen2024exploring} retrieve a user's historical interactions from an item-attribute graph, focusing on neighbor interactions. These records are added to the prompt, providing the LLM with cross-domain preference information.

% Context-level infusion provides a flexible way to incorporate graph knowledge without altering the LLM's architecture. It leverages the LLM's ability to understand and reason over natural language, making it suitable for scenarios where graph structures can be effectively verbalized.

% % \subsection{Graph-Integrated Architectures}
% % \label{subsec:advanced-architectures}

% % Beyond basic infusion techniques, new methods are emerging that fundamentally alter how LLMs process graph data.

% % \textbf{Hierarchical Graph-Indexed Tokenization} Mei~\cite{mei2023lightlm} propose LightLM, which uses spectral and graph index learned from GNN to create hierarchical IDs for users and items. These IDs, based on graph structure, are used to build a Trie structure that optimizes the beam search process for generating recommendations. LightLM also features a "deep and narrow" FFN to improve efficiency for recommendation tasks.

% % \textbf{Graph-Enhanced Attention Mechanism} Wang et al.~\cite{wang2024llm} introduce LLM4REC, which modifies the attention mechanism in LLMs (specifically GPT-2) by incorporating GNN-learned representations of edge relationships. This allows the model to directly consider graph proximity when processing tokens, leading to more informed recommendations. Specifically, they introduce adjacency and path relation correction term derived from the graph into the attention's query-key product, guiding the attention mechanism based on the graph structure.

% \subsection{Discussion}
% \label{subsec:discussion}

% The ``Graph $\rightarrow$ GNN $\rightarrow$ LLM" paradigm presents a promising avenue for enhancing recommender systems by bridging the gap between the static world knowledge encapsulated within LLMs and the dynamic nature of user-item interactions captured in graphs. This approach not only allows for a more nuanced understanding of user preferences and item relationships but also potentially mitigates the limitations of LLMs in handling evolving data patterns inherent in recommendation scenarios. By encoding rich structural and relational information from graphs, GNNs empower LLMs with a deeper, more context-aware understanding that can significantly improve recommendation accuracy, diversity, and explainability. Moreover, this graph-augmented approach naturally facilitates the incorporation of heterogeneous data sources, such as user interaction histories, item knowledge graphs, and textual content, paving the way for more holistic and sophisticated recommender systems. Recent innovations like hierarchical graph-indexed tokenization and graph-enhanced attention further demonstrate the potential of this approach by fundamentally altering how LLMs interact with graph data, paving the way for even more sophisticated and effective recommendation models.



\section{Graph-Augmented LLM}
\label{sec:graph-llm}

LLMs excel at understanding and generating text but struggle with the complex relational structures inherent in recommender systems. While pre-training corpora and in-context learning provide some information, they lack an explicit mechanism to model the intricate relationships between users and items that are naturally represented as graphs.
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/Graph-Augmented_LLM-jiawei.pdf}
    \caption{The illustration of graph-augmented LLM methods: 
    a) \textbf{Token-Level Infusion}, where nodes or subgraphs are represented as special tokens, integrating into LLM's input.
    b) \textbf{Context-Level Infusion}, where graph information is converted into context by translating graph into text or retrieving relevant text.}
    \label{fig:graph-augmented LLM}
\end{figure}
Recent research bridges this gap by integrating graphs with LLMs, focusing on the core challenge: \textbf{How to design cross-modal interfaces that effectively bridge graph structures to language models?} We categorize current methods into \textbf{token-level infusion} and \textbf{context-level infusion} (as illustrated in Figure~\ref{fig:graph-augmented LLM}), based on where the cross-modal interface is implemented.

% Our work will concentrate on these two primary categories, leaving aside for now the investigation of more complex architectures like \cite{wang2024llm}'s LLM4REC, which integrates graph information by modifying the LLM's attention mechanism with GNN-learned edge representations. These advanced approaches, while promising, are still in early stages of development and fall outside the current scope.



\subsection{Token-Level Infusion}
\label{subsec:token-injection}

This strategy integrates structural information directly into the LLM's input at the token level. Nodes or subgraphs are represented as special tokens, allowing the LLM to process structural information alongside text.
% Formally, we have:

% \begin{equation}
% \mathbf{e}_{v} = f(\mathbf{h}_v)
% \end{equation}
% where GNN learns node representations $\mathbf{h}_v \in \mathbb{R}^d$ for each vertex $v$, and these are projected into the LLM's embedding space via a mapping $f: \mathbb{R}^d \rightarrow \mathbb{R}^{d_{\text{LLM}}}$, creating special token embeddings $\mathbf{e}_{v}$.
\paragraph{Syntax-Integrated Injection.} This approach embeds special tokens as syntactic components within the LLM's input sequence. For example, TMF~\cite{ma2024triple} introduces \texttt{[ACTION]} tokens like \texttt{[view]} or \texttt{[purchase]} to represent user actions within an interaction sequence. The embeddings for these actions are learned from a multi-behavior graph, enabling the LLM to process complex semantics like ``user \texttt{[views]} item". Building on this, ELMRec~\cite{wang2024enhancing} generates a GCN-based embedding $\mathbf{h}_i$ for each item $i$ and adds it as a correction term to the item's original text embedding $\mathbf{e}_i$, resulting in a refined embedding $\mathbf{e'}_i = \mathbf{e}_i + \mathbf{h}_i$. This operation blends textual and structural information, improving item representation.

A natural progression from here is to consider whether the LLM can directly output these special tokens. LLMGR~\cite{guo2024integrating} explores this by not only including special tokens in the input but also modifying the LLM's output layer. They introduce a special token for each item, allowing the model to directly generate item tokens as recommendations, effectively creating a tighter link between graph-based recommendations and the LLM's output. Further advancing this line of thought, LightLM~\cite{mei2023lightlm} proposes a hierarchical indexing scheme, which decomposes user/item IDs into multiple special tokens based on a user-item graph-derived index. Each component token encodes a different attribute or function, moving away from opaque numerical IDs towards more semantically meaningful representations.

\paragraph{Syntax-Decoupled Injection.}
This method appends graph embeddings as prefixes or suffixes, separating structural information from the main textual prompt. XRec~\cite{ma2024xrec} prepends GNN-learned embeddings that represent user-item relationships to the prompt. These embeddings are trained to capture high-level semantic concepts, such as preference similarity between users. COMPASS~\cite{qiu2024unveiling} combines user queries with knowledge graph embeddings. A GNN generates embeddings that encapsulate both the user's query and relevant knowledge graph entities, which are then used as a prefix to guide the LLM for recommendation.

Token-level infusion offers a fine-grained way to integrate structural information, allowing for natural interactions between textual and structural data. However, it often requires modifications to the LLM's architecture or careful prompt engineering.

\subsection{Context-Level Infusion}

This strategy provides structural information as context to the LLM, either through text descriptions or implicit retrieval, avoiding modifications to the LLM's architecture.

\paragraph{Explicit Graph-to-Text Mapping.} 
This method involves converting localized graph structures into natural language descriptions, essentially translating graph relationships into text. The following example illustrates explicit graph-to-text mapping: \texttt{user A} $\rightarrow$ \texttt{purchase} $\rightarrow$ \texttt{item B} $\rightarrow$ \texttt{payment} $\rightarrow$ \texttt{credit card} $\Rightarrow$ \texttt{A purchased B with a credit card.} The simplest form of this is exemplified by HetGCoT-Rec~\cite{jia2025hetgcot}. They extract multihop neighbors of a target node from a heterogeneous graph and concatenate their attributes to create a natural language description, which becomes the context for the LLM and informs its recommendations. Similarly, KGRec~\cite{abu2024knowledge} extracts one-hop and two-hop related nodes from a knowledge graph and inserts them into predefined prompt templates, which guides the LLM in generating explainable recommendations.

Further refinements involve pre-processing the structural information before mapping it to text. GAL-Rec~\cite{guan2024enhancing} maintains a dynamic queue of negative samples, items the user is known to dislike, based on knowledge graph insights and LLM feedback. Providing both positive and negative samples as context for the LLM allows for more nuanced recommendations. The processing of structural information can also occur after its initial conversion to text. GLRec~\cite{wu2024exploring} constructs natural language descriptions of node paths in a job information graph. Each path represents a sequence of related job attributes or skills. During prompt construction, these paths are assigned different weights based on relevance and dependency strength, offering a more refined, contextually rich input to the LLM.

\paragraph{Implicit Graph Retrieval.} 
When explicit mapping is difficult, this approach uses GNN embeddings to retrieve relevant information from the graph semantically. For example, CLAKG~\cite{chen2024leverage} encodes a legal knowledge graph using a GNN, and retrieve relevant legal provisions based on the similarity between a user's case description embedding and the provision embeddings. These provisions are then concatenated into the prompt context. URLLM~\cite{shen2024exploring} retrieves a user's historical interactions from an item-attribute graph, focusing on neighbor interactions. These records are added to the prompt, providing the LLM with cross-domain preference information.

Context-level infusion provides a flexible way to incorporate graph knowledge without altering the LLM's architecture. It leverages the LLM's ability to understand and reason over natural language, making it suitable for scenarios where graph structures can be effectively verbalized.

\subsection{Discussion}
\label{subsec:discussion}

Graph-augmented LLM methods enhance recommendations by encoding rich relational information from graphs, typically through token-level or context-level infusion. This couples the benefits of graph-structured data with the power of LLMs: the graph provides valuable relational context, while the LLM leverages its pre-trained knowledge to interpret it. Furthermore, since the LLM is the central component, this approach augments the recommender system's ability to extrapolate and make inferences in scenarios where interaction data is limited. However, this heavy reliance on the LLM also introduces inherent biases unsuitable for recommendation, such as a lack of diversity and distributional mismatch with user preferences, potentially limiting its scalability and generalizability. The alternative methods, by shifting the focus to enriching or harmonizing the graph itself, effectively mitigate these issues and offer different trade-offs.