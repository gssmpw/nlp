\section{LLM-Graph Harmonization}

Graph-augmented LLM methods leverage external graph structures to enhance LLMs but often suffer from inefficiencies in real-time adaptability and increased computational overhead. Conversely, LLM-augmented graph methods attempt to incorporate LLMs into graph-based learning but struggle with scalability and effective knowledge utilization. To address these limitations, this section introduces a novel framework that optimally balances computational efficiency, adaptability, and reasoning capabilities.
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/LLM-Graph_Harmonization.pdf}
    \caption{The illustration of LLM-graph harmonization methods:  
    a) \textbf{Embedding Fusion}, where LLM-derived semantic embeddings and GNN-learned structural embeddings are combined into a unified representation space through fusion mechanisms such as concatenation or attention-based integration;  
    b) \textbf{Embedding Alignment}, where embeddings from both modalities are mapped into a shared space using techniques like contrastive learning or MLP-based transformation to enhance consistency and coherence.  }
    \label{fig:LLM-graph harmonization}
\end{figure}

LLMs excel in capturing rich semantic information from unstructured textual data (e.g., item descriptions and user attributes), while GNNs are adept at modeling the topological structure of graphs (e.g., user-item interactions, social connections). As shown in Figure~\ref{fig:LLM-graph harmonization}, harmonizing these two paradigms effectively can significantly enhance recommendation performance. Existing methods can be broadly categorized into two mainstream strategies: \textbf{embedding fusion} and \textbf{embedding alignment}, based on transformations of embeddings.
% Below, we discuss these approaches in detail, highlighting their methodologies and contributions.

\subsection{Embedding Fusion}

The embedding fusion approach aims to combine LLM-derived textual representations with graph-learned structural embeddings, creating a unified feature space that leverages complementary information. This strategy emphasizes the synergy between textual semantics and graph-based connectivity.


% \begin{equation}
% \mathbf{z} = g_{\text{fusion}}(\mathbf{e}_{\text{LLM}}, \mathbf{e}_{\text{GL}})
% \end{equation}
% where $\mathbf{e}_{\text{LLM}} \in \mathbb{R}^{d_{\text{LLM}}}$ represents the semantic embeddings generated by the LLM (e.g., item captions, user-generated content), $\mathbf{e}_{\text{GL}} \in \mathbb{R}^{d_{\text{GL}}}$ denotes the structural embeddings produced by the graph learning method (e.g., user-item interaction embeddings), and $g_{\text{fusion}}$ is a fusion function (e.g., concatenation, attention-based fusion) that combines these embeddings into a shared latent space $\mathbf{z} \in \mathbb{R}^{d_{\text{fusion}}}$.

A notable framework in this domain is DynLLM~\cite{zhao2024dynllm}, which incorporates graph structures into LLMs through dynamic memory-enhanced fusion. DynLLM addresses the limitation of static embeddings by using a dual-flow interaction mechanism: one flow learns from GNN-updated dynamic embeddings reflecting user-item interactions, while the other adapts LLM-generated embeddings based on real-time textual content. These embeddings are fused in a shared latent space, enhancing both semantic and structural understanding. Such a dynamic fusion approach not only captures the temporal evolution of recommendation data but also integrates high-quality textual semantics, leading to more accurate and adaptive recommendations. Another example is LKPNR~\cite{runfeng2023lkpnr}, which combines LLMs with knowledge graphs to enhance personalized news recommendation. LKPNR leverages the semantic richness of LLMs to generate high-quality news representations and uses knowledge graphs to capture the relational structure of news entities. By integrating these modalities, LKPNR effectively addresses the long-tail problem in news recommendation.

The embedding fusion paradigm is particularly effective because it exploits the contextual richness of LLMs alongside the relational structures captured by GNNs. By fusing these modalities, models like DynLLM and LKPNR enable direct, dynamic, and efficient utilization of both textual and graph data, significantly improving representation learning in recommendation scenarios.

\subsection{Embedding Alignment}

Embedding alignment takes a different route by focusing on reconciling the heterogeneity between LLM-generated textual embeddings and GNN-learned structural representations. This strategy ensures that embeddings from both modalities can operate coherently within a unified representational space, reducing information loss and noise. The refined embeddings can provide more valuable information for recommendations.

% \begin{equation}
% \mathcal{L}_{\text{align}} = \sum_{i=1}^N \mathcal{L}\left(f(\mathbf{e}_{\text{LLM}}^{(i)}, \mathbf{e}_{\text{GNN}}^{(i)})\right)
% \end{equation}
% where $\mathbf{e}_{\text{LLM}}^{(i)}$ and $\mathbf{e}_{\text{GNN}}^{(i)}$ denote the LLM and GNN embeddings for instance $i$, respectively. The function $f$ represents a general alignment function, which can be any measure or network (such as contrastive loss, MLP-based mapping, or others) that compares the embeddings from both modalities. The function $\mathcal{L}$ is a loss function applied to the output of $f$, aiming to promote alignment between the two embeddings in the shared space.

The DALR framework~\cite{peng2024denoising} serves as a representative example, where structural embeddings from GNNs (e.g., user-item graph representations) and semantic embeddings from LLMs (e.g., product descriptions, user reviews) are aligned through contrastive learning paradigms. This alignment mitigates the semantic gaps and noise introduced by the inherently different data sources. Similarly, methods such as LLMRec~\cite{wei2024llmrec} and RLMRec~\cite{ren2024representation} also adopt multimodal alignment techniques, such as contrastive learning and MLP-based alignment, to unify embeddings from diverse modalities. For instance, LLMRec employs a denoised data robustification mechanism to enhance the reliability of augmented recommendation data, while RLMRec leverages contrastive alignment strategies to bridge the semantic space of LLMs with the collaborative relational signals from GNNs, thereby improving the overall quality of the learned representations.

Embedding alignment excels in its ability to unify heterogeneous modalities, ensuring consistent representation learning that facilitates better downstream recommendation tasks, such as personalized ranking or user preference clustering.

\subsection{Discussion}

The two approaches offer distinct advantages in integrating LLMs with graph learning for recommender systems. Embedding fusion directly combines textual semantics and structural relationships, leveraging their complementarity to enhance representation learning and personalization. Dynamic fusion methods, such as DynLLM, further enable real-time adaptation to evolving user preferences. Embedding alignment, in contrast, ensures coherence between textual and structural embeddings by mapping them into a shared space, mitigating inconsistencies. Methods like DALR leverages various contrastive learning approaches to enhance alignment robustness. However, embedding fusion may introduce redundant or conflicting information, and increase computational costs, while embedding alignment which is sensitive to noise depends on high-quality training data.
In these methods, the LLM primarily serves as an encoder, and due to the constraints of the scenario, it cannot fully utilize its contextual understanding and language generation capabilities.
% Moreover, in these methods, the involvement of the LLM occurs at a relatively later stage, making it difficult to ensure whether noise from the original data has been introduced into the graph learning process.
% Future work could explore hybrid strategies to balance fusion and alignment, maximizing their strengths.
