%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Submission and Formatting Instructions for ICML 2025}

\begin{document}

\twocolumn[
\icmltitle{A Fokker-Planck-Based Loss Function that Bridges Dynamics with Density Estimation}


% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
%\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Zhixin Lu}{yyy}%{equal,yyy}
\icmlauthor{Łukasz Kuśmierz}{yyy}%{equal,yyy,comp}
\icmlauthor{Stefan Mihalas}{yyy}
\end{icmlauthorlist}

\icmlaffiliation{yyy}{Allen Institute, Seattle}

\icmlcorrespondingauthor{Zhixin Lu}{zhixin.lu@alleninstitute.org}
%\icmlcorrespondingauthor{Stefan Mihalas}{stefanmihalas@alleninstitute.org}


\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
We have derived a novel loss function from the Fokker-Planck equation that links dynamical system models with their probability density functions, demonstrating its utility in model identification and density estimation. In the first application, we show that this loss function can enable the extraction of dynamical parameters from non-temporal datasets, including timestamp-free measurements from steady non-equilibrium systems such as noisy Lorenz systems and gene regulatory networks. In the second application, when coupled with a density estimator, this loss facilitates density estimation when the dynamic equations are known. For density estimation, we propose a density estimator that integrates a Gaussian Mixture Model with a normalizing flow model. It simultaneously estimates normalized density, energy, and score functions from both empirical data and dynamics. It is compatible with a variety of data-based training methodologies, including maximum likelihood and score matching. It features a latent space akin to a modern Hopfield network, where the inherent Hopfield energy effectively assigns low densities to sparsely populated data regions, addressing common challenges in neural density estimators. Additionally, this Hopfield-like energy enables direct and rapid data manipulation through the Concave-Convex Procedure (CCCP) rule, facilitating tasks such as denoising and clustering. Our work demonstrates a principled framework for leveraging the complex interdependencies between dynamics and density estimation, as illustrated through synthetic examples that clarify the underlying theoretical intuitions.
\end{abstract}

\section{Introduction}
\label{intro}
Machine learning (ML) excels in manipulating and interpreting various forms of information: raw data, probabilistic density functions, and dynamical processes. ML tasks often require manipulating these forms separately or exploring their interactions. For example, classification tasks can utilize Support Vector Machines (SVMs) \cite{cortes1995support} to delineate boundaries in raw data spaces, while more complex tasks may engage with multiple information types, such as density estimation that converts empirical data into probabilistic distribution functions; system identification that derives dynamical models from time series data; and data generation using dynamical processes like 
state space models (SSMs) \cite{gu2023mamba}, 
Recurrent Neural Networks (RNNs) 
\cite{sutskever2011generating,ranzato2015sequence,sherstinsky2020fundamentals},
or diffusion models \cite{sohl2015deep} 
to generate both time series and non-time series data. Moreover, methods like Variational Autoencoders (VAE) 
\cite{kingma2022autoencodingvariationalbayes} 
showcase back-and-forth transitions between data (ground truth or reconstructed) and the probabilistic distributions of latent variables.

Compared to the extensively studied interplay between data and density or data and dynamics, the interaction between density and dynamics remains relatively underexplored. This gap is particularly evident in efforts to extract dynamical parameters from non-temporal data points within complex dynamical systems—a task significantly more challenging than learning dynamics from time-series data. Traditional methods often attempt to construct pseudo-time-series from cross-sectional data by linking data points measured at different times \cite{huang2013exploiting}. More recent approaches \cite{tong2020trajectorynet,bunne2024optimal} have tackled this problem from a dynamical optimal transport perspective using the Wasserstein distance. Notably, 
recent works \cite{maddu2024inferring,chardes2023stochastic} propose methods derived from the Fokker-Planck equation and probability flow ordinary differential equations (ODEs) \cite{chen2018neural} to infer dynamics from non-time-series data. However, these methods focus on cases where dynamics are inferred from available cross-sectional data that still contain temporal information. Despite these advancements, significant challenges persist, particularly in handling nonlinear and chaotic dynamics, and in scenarios devoid of cross-sectional data. To our knowledge, no existing method has successfully determined the dynamical parameters of a chaotic system, such as the Lorenz system \cite{lorenz1963deterministic}, from purely non-temporal data. This underscores the need for a first-principles method and a robust theoretical framework capable of establishing the conditions under which the existence and uniqueness of dynamical parameters can be inferred from density functions.

To this end, this paper introduces a novel theoretical framework anchored by a first-principles loss function derived from the Fokker-Planck equation 
\cite{risken1996fokker}, bridging dynamical models with probabilistic density functions. This loss function is uniquely designed to operate bi-directionally: it not only extracts dynamical parameters from density distributions but also uses dynamical models to compute and refine density estimates, thereby enhancing understanding in both directions. This dual functionality allows for a comprehensive integration of dynamics and density that is absent in current methodologies. We demonstrate two primary applications of this approach:
\begin{enumerate}
    \item Extracting dynamical parameters from density functions.
    
    \item Estimating density from the knowledge of dynamical models.
\end{enumerate}
\begin{figure*}[ht]
\vskip 0.in
\begin{center}
\centerline{\includegraphics[width=1.5\columnwidth]{fig1.pdf}}
\caption{Conceptual framework illustrating the intersection of machine learning methods with data, distribution, and dynamics. The central theme of this paper is to bridge probabilistic density functions with dynamical models through a novel Fokker-Planck-based loss function. We demonstrate the application of this loss function in two primary areas: 1) inferring dynamics from probability densities without relying on temporal data, and 2) estimating density functions directly from known dynamical models.}
\label{fig:fig1}
\end{center}
\vskip -0.2in
\end{figure*}

In our first application, we conduct detailed case studies on the Lorenz system and a gene-gene interaction network, both influenced by dynamical noise, to showcase our method’s capability to infer dynamical parameters from density functions without temporal data. For the first time, we successfully infer the three parameters of the Lorenz system from a set of non-temporal data points. This achievement underscores our method’s unique ability to elucidate the dynamics of complex systems directly from their density distributions, without relying on temporal information. Additionally, we establish a mathematical foundation with a theorem that delineates the necessary and sufficient conditions for the unique determination of these parameters (see Appendix~\ref{apn:3} due to space constraints). We also explore the convexity of our loss function and discuss how parameters can be directly solved through linear equations when the dynamical model is affine with respect to its unknown parameters (refer to Appendix~\ref{apn:3} for details due to space limitations).

In our second application, we explore density estimation using both empirical data and known dynamical models. We introduce a density estimator that integrates a Gaussian Mixture Model (GMM) \cite{mclachlan200001} with a normalizing flow model \cite{dinh2017density}, enabling it to simultaneously estimate normalized density, energy, and score functions. This estimator is compatible with our Fokker-Planck based loss function, as well as a variety of data-based training methodologies, such as maximum likelihood and score matching, facilitating a comprehensive approach to density estimation that leverages both data-driven insights and dynamical system knowledge. Moreover, the GMM component of our estimator resembles an energy function similar to that in the modern Hopfield networks 
\cite{krotov2016dense,ramsauer2020hopfield}, enhancing its capability for rapid data manipulation through the Concave-Convex Procedure (CCCP) 
\cite{yuille2001concave,yuille2003concave}. We demonstrate its effectiveness in denoising and clustering through a synthetic 9-cluster dataset. 

The remainder of this paper is organized as follows: Section~\ref{sec:2} introduces the loss function derived from first principles, based on the Fokker-Planck equation, and discusses its dual applications. Section 3 elaborates in detail on the first application, which involves extracting dynamical parameters from non-sequential data, with supporting theory provided in Appendix~\ref{apn:3}. Section~\ref{sec:4} details the use of the loss function for density estimation from dynamics, introducing a novel density estimator that integrates Gaussian Mixture Models with normalizing flow techniques. We also demonstrate the downstream applications of the proposed density estimator, including one-step denoising and one-step clustering, highlighting its potential for broad applications in data manipulations.

\section{The Fokker-Planck-Equation Based Loss Function}
\label{sec:2}
For stochastic dynamical systems, the evolution of the density function is governed by the Fokker-Planck equation. Building upon this foundational theory, we have developed a first-principles loss function that rigorously evaluates the fidelity of system dynamics and the evolution of the density function relative to the Fokker-Planck equation. We employ the L-1 norm to quantify deviations, providing a robust measure of how closely the modeled dynamics and density evolution conform to the theoretical predictions of the Fokker-Planck equation.

\subsection{Deriving the Loss Function}
To enhance the clarity of our presentation, we start by considering a specific case where the stochastic dynamical system is described by:
\begin{equation}
    d\mathbf{x} = \mathbf{f}(\mathbf{x}) dt + \sqrt{2D} d \mathbf{w},\label{eqn:dyn}
\end{equation}
where $D$ represents the diffusion coefficient. We assume that the system has achieved a steady non-equilibrium distribution state. (For more complex scenarios where the SDE is time-dependent, the diffusion coefficient is matrix-valued, the density function fluctuates, and birth-death process is present, we derive the most general loss function in the Appendix~\ref{apn:1} and Appendix~\ref{apn:2}.)

The corresponding Fokker-Planck equation for such a system is:
\begin{equation}
\frac{\partial p(\mathbf{x},t)}{\partial t} + \nabla \cdot [\mathbf{f}(\mathbf{x}) p(\mathbf{x},t) - D \nabla p(\mathbf{x},t)] = 0. \label{eqn:fp_eq}
\end{equation}
Given our assumption that the system has settled into a steady state, the time derivative term ($\frac{\partial p(\mathbf{x},t)}{\partial t}$) drops out, allowing us to focus solely on the divergence term. We utilize the L-1 norm to assess the congruence between the dynamics and the probability distribution by evaluating this divergence term.

Considering the challenges in directly calculating the density function, notably the difficulty in obtaining the normalization constant, we opt to estimate the score function, which does not require normalization. Therefore, we reformulate the divergence term in the Fokker-Planck equation into a score-based representation by dividing it by the probability density function $p(\mathbf{x})$, leading to the following expression for our loss function:
\begin{equation}
\boldsymbol{L} = \sum_{\mathbf{x} \in \boldsymbol{\Omega}} |\mathbf{s}^T(\mathbf{x}) [f(\mathbf{x}) - D\mathbf{s}(\mathbf{x})] + [\nabla \cdot f(\mathbf{x}) - D \nabla \cdot \mathbf{s}(\mathbf{x})]|, \label{eqn:loss}
\end{equation}
where $\mathbf{s}=\nabla \log(p(\mathbf{x}))$ is the steady score function, and $\boldsymbol{\Omega}$ denotes the set of probing points where we evaluate the consistency of the Fokker-Planck equation. Importantly, this formulation does not require global information about the density function, as the evaluation of the score function and its gradient is confined to a specified set of probing points $\boldsymbol{\Omega}$. This attribute is especially favored in scenarios where measurements are restricted to specific regions of the full phase space.

\subsection{Dual Applications of the Loss Function}
Derived from the foundational principles of the Fokker-Planck equation, this loss function forges a direct link between the observed evolution of distributions and the underlying dynamics. It facilitates two primary applications: first, the inference of dynamical parameters from distributions or datasets devoid of temporal information; and second, the training of density estimators directly from dynamical models, extending beyond traditional reliance on empirical data. In the subsequent sections, we explore these applications in depth. We discuss theoretical considerations, including the conditions necessary for the optimization process to yield a unique solution in the first application, and introduce a novel density estimator designed to enhance the second application. Through carefully crafted examples, we elucidate the underlying intuition and demonstrate the effectiveness of our approach.

\section{Application I: From Density to Dynamics}
\label{sec:3}
Traditional system identification typically depends on time-series data. However, scenarios often arise where temporal measurements are impractical or impossible. Such scenarios include destructive measurements, where observing the system disrupts its state; random sampling, where measurements occur at unpredictable times; and ensemble measurements of indistinguishable systems that have not yet stabilized. In cases of destructive and random sampling, dynamical parameters can be deduced from the observed steady distribution of non-temporal data. For ensemble measurements, although it is impossible to trace individual trajectories, the evolution of the density function remains observable. These scenarios involving non-steady states can be addressed using the generalized loss function, elaborated in the Appendix~\ref{apn:1} and \ref{apn:2}. In the main text, we showcase the application of our proposed loss function to extract dynamical parameters from non-temporal data collected at unknown and random times from two complex systems in their steady non-equilibrium states: a stochastic Lorenz system and a set of Stochastic Differential Equations (SDEs) representing a multi-gene transcriptomic model featuring a high-order gene-regulatory network.

\subsection{Example 1: Lorenz System Parameter Inference from Non-temporal Data}
\begin{figure*}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=1.98\columnwidth]{fig2.pdf}}
\caption{Inferring three dynamical parameters (highlighted in yellow) of a stochastic Lorenz system from an unordered cloud of data points (lower left subplot) without timestamps. The central subplot displays the loss and learned parameters across eight trials, with dashed lines indicating the true values. The right subplots compare the simulated noise-free Lorenz dynamics using both true and learned parameters.}
\label{fig:fig2}
\end{center}
\vskip -0.2in
\end{figure*}
We examine the Lorenz system as a novel test case for extracting dynamical parameters from non-temporal data. In its natural state without stochastic noise, the Lorenz system presents a steady-state distribution. However, the fractal nature of its global attractor renders this distribution non-differentiable, complicating the definition of a score function. Typically, such fractal characteristics would not be as problematic in real-world scenarios where dynamical noise inherently exists, smoothing out these complexities. Therefore, we introduce dynamical noise and analyze a dataset of randomly sampled points from a stochastic Lorenz system, taken at arbitrary times after the transient phase.

To implement our loss function, we estimate the underlying score function, $\mathbf{s}(\mathbf{x})$, using a naive GMM. In this model, all data points function as centroids with equal weights and share an isotropic covariance matrix. We evaluate the loss function on a selected subset of 5000 data points, designated as the probing set $\boldsymbol{\Omega}$, which is then segmented into batches of size 2. This granular batching strategy enhances the frequency of updates, potentially expediting the convergence process.

In the Appendix~\ref{apn:3}, we show that the optimization process, due to the L-1 norm in the loss function, is convex but not strictly convex when the dynamical model is affine in terms of the unknown parameters. This ensures reliable convergence to the optimal parameters. We initiate the optimization of the three parameters of the Lorenz system from eight randomly selected initial points, planning for a duration of 2 epochs. However, as Figure \ref{fig:fig2} demonstrates, convergence typically occurs much earlier than anticipated, often well before completing the two epochs. This rapid convergence underscores the efficiency of our approach and the stability of the parameter estimation process, consistently leading to the true values of the system parameters.

Additionally, in the Appendix~\ref{apn:3}, we provide a method for directly solving for the dynamical parameters using a linear equation, as well as the sufficient and necessary conditions for the existence of a unique set of parameters that perfectly solves the problem. These theoretical considerations guarantee the potential of using this loss for much larger systems with minimal computational resources.

\subsection{Example 2: Gene Regulatory Networks Inference from Non-temporal Data}
\begin{figure}[h]
\vskip -0.2in
\begin{center}
\centerline{\includegraphics[width=0.98\columnwidth]{fig3.png}}
\caption{Inferring a gene regulatory network from an unordered cloud of data points (upper left subplot) without timestamps. The right subplots depict the learning dynamics of $7$ out of $21$ parameters, from five random trials. Dashed lines indicate true parameter values. The full parameter plot is available in the Appendix. The lower left subplot visualizes data points generated from a reconstructed system using one of the inferred gene regulatory networks.}
\label{fig:fig3}
\end{center}
\vskip -0.2in
\end{figure}
In this second example of our first application, we utilize our novel loss function to decode a complex high-order gene regulatory network as described in \cite{martinez2012quantitative}. This dynamical transcriptomic model encompasses three non-driver genes, which interact up to the third order, influenced by two extra driver genes. To enhance system dynamics, we have integrated oscillatory controls for the driver genes, establishing an autonomous system with a non-equilibrium steady state. The system incorporates seven variables: three for the non-driver genes and four for the oscillatory dynamics of the drivers, forming a high-order gene regulatory network shaped as $3\times 7$. (See Appendix~\ref{apn:4} for details)

To decode this intricate gene regulatory network, we initially estimate the score function, $\mathbf{s}(\mathbf{x})$, using a naive GMM, where each data point serves as a centroid with equal weight and shares an isotropic covariance matrix. This setup facilitates a decent estimation of the distribution function for the gene expressions. Subsequently, we apply our loss function to directly link the estimated score function to the dynamic parameters of the gene model. Through optimization of the loss function, we successfully learn the 21 parameters of the model. Figure~\ref{fig:fig3} illustrates the learning dynamics for the initial seven parameters. Additionally, this figure shows both the original and the reconstructed data points for the three non-driver genes, demonstrating the capability of our loss function to extract detailed dynamical information from non-temporal data.

The complete learning dynamics for all $21$ parameters are detailed in the Appendix~\ref{apn:4}, where our loss function proves highly effective in recovering most of the network parameters, with only minor deviations in two parameters. In the following subsection, we explore the theoretical considerations related to potential sources of error in this type of dynamical parameter inference and discuss the conditions necessary to achieve a unique solution.

\subsection{Theoretical Considerations}
This subsection delves deeper into the theoretical underpinnings and challenges associated with learning dynamics from non-temporal data, focusing on sources of error and the inherent complexities of the inference problem.

\textbf{Accuracy of Parameter Estimation:} The relationship between the density function and the dynamics is sensitive, thus making the precision of the score function estimation crucial for accurately determining dynamical parameters. However, accurately estimating the global score function may be impractical due to data scarcity or computational constraints. Our loss function addresses this by enabling local score estimation at probing points that are densely populated with data, which can lead to more precise parameter inference with fewer computational resources. This approach prompts a critical question: How many probing points are needed to ensure reliable learning of dynamical parameters? Theorem~\ref{theorem1} in the Appendix~\ref{apn:3} addresses this, outlining the necessary conditions for maintaining a unique solution for the dynamical parameter inference problem, ensuring both theoretical robustness and practical efficacy.

\textbf{Addressing the Ill-Posed Nature of Inference:} Inferring dynamical systems from steady non-equilibrium distributions is fundamentally ill-posed. Theoretically, a single steady distribution could result from various dynamical systems with different flow characteristics or potentially exhibiting no flow. To tackle this challenge, we model the dynamics in an affine form relative to unknown parameters $\boldsymbol{\Theta} \in \mathbb{R}^{d \times m}$:
\begin{equation}
\mathbf{f}_{\boldsymbol{\Theta}}(\mathbf{x}) = \mathbf{v}(\mathbf{x}) + \boldsymbol{\Theta}\mathbf{u}(\mathbf{x}),
\label{eqn:dynamics}
\end{equation}
where $\mathbf{v}:\mathbb{R}^d \rightarrow \mathbb{R}^d$ and $\mathbf{u}:\mathbb{R}^d \rightarrow \mathbb{R}^m$ are functions differentiable at all probing points in $\boldsymbol{\Omega}$. Detailed in the Appendix~\ref{apn:3} are the sufficient and necessary conditions under which $\boldsymbol{\Theta}$ can be uniquely determined, as well as a formula for directly solving for the optimized parameters using the pseudo-inverse. Moreover, the proof of the theorem affirms that the optimization of $\boldsymbol{\Theta}$ through our loss function is a convex process. Despite the challenges posed by the ill-posed nature of this inference task, our methodological framework guarantees robust convergence to an optimal set of parameters, reinforcing the practical applicability of our theoretical model.

These theoretical insights not only support the empirical findings presented but also extend the model’s utility to broader applications, emphasizing its adaptability, computational efficiency, and robustness in handling complex inference scenarios.

\begin{figure*}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=1.8\columnwidth]{fig4.pdf}}
\caption{Schematic of our density estimator, comprising a GMM for the latent space $\boldsymbol{\xi}$, also functioning as a Hopfield-like energy, with adjustable centroids $\boldsymbol{\Xi}$, and a normalizing flow model using real NVP. The GMM approximates the density function flexibly, minimizing artifacts in sparse areas, while the normalizing flow, kept close to an identity map, refines this approximation to align more accurately with the actual data distribution.}
\label{fig:fig4}
\end{center}
\vskip -0.2in
\end{figure*}

\begin{figure*}[ht]
\vskip 0.0in
\begin{center}
\centerline{\includegraphics[width=1.98\columnwidth]{fig5.pdf}}
\caption{Training a density estimator with our loss function to align with a stochastic dynamical system featuring a limit cycle. Top row: initial setup with centroids, prior density, energy, and score functions. The dynamics create a donut-shaped steady-state distribution (upper left). Bottom row: post-training outcomes including transformed centroids, density, energy, and score functions, with training loss shown in the lower-left subplot.}
\label{fig:fig5}
\end{center}
\vskip -0.2in
\end{figure*}

\section{Application II: From Dynamics to Density}
\label{sec:4}
In this section, we explore the second major application of our proposed loss function: inferring density functions from dynamical equations. Typically, such density functions are derived by directly solving the Fokker-Planck equation associated with the dynamical system. However, obtaining an analytical solution is often non-feasible or impractical for application in downstream tasks. To overcome these challenges, we introduce a novel density estimator that effectively complements our loss function for learning density from dynamics, demonstrating its versatile downstream applications.

\subsection{A Novel Density Estimator}
We propose a density estimator that integrates a latent GMM with a normalizing flow model implemented via the real NVP method \cite{dinh2017density}, as illustrated in Fig.~\ref{fig:fig4}. This setup characterizes the latent distribution of $\boldsymbol{\xi}$ by a GMM with $n$ centroids, represented by a $d$-by-$n$ matrix $\boldsymbol{\Xi}$, sharing a common covariance matrix $\boldsymbol{\Sigma}$. The logarithm of the centroid weights is denoted by $\boldsymbol{\lambda}$. We define the energy function for the latent variable as follows:
\begin{align}
    E(\boldsymbol{\xi})  = &-\frac{d}{2} \log(2\pi) - \frac{1}{2} \log(\det(\boldsymbol{\Sigma}))
 +\\
 &\frac{1}{2}\boldsymbol{\xi}^T\boldsymbol{\Sigma}^{-1}\boldsymbol{\xi} -\text{lse}(\boldsymbol{\Xi}^T\boldsymbol{\Sigma}^{-1}\boldsymbol{\xi} + \boldsymbol{\lambda} + \mathbf{l}),\label{eqn:hopfield_energy}
\end{align}
where
\begin{equation}
[\mathbf{l}]_i = -\frac{1}{2}[\boldsymbol{\Xi}]_{:,i}^T\boldsymbol{\Sigma}^{-1}[\boldsymbol{\Xi}]_{:,i},
\label{eqn:the_l}
\end{equation}
and $\text{lse}(\cdot)$ represents the log-sum-exp function as in the Hopfield energy function described in \cite{ramsauer2020hopfield}. In the Appendix~\ref{apn:5}, we discuss how the energy function defined in \cite{ramsauer2020hopfield} corresponds to a special case of this GMM. Recognizing the connection of this latent GMM to modern Hopfield networks, we also propose a CCCP-based update rule in the latent space,
\begin{equation}
\text{CCCP}(\boldsymbol{\xi}) = \boldsymbol{\Xi}\text{softmax}(\boldsymbol{\Xi}^T\boldsymbol{\Sigma}^{-1}\boldsymbol{\xi} + \boldsymbol{\lambda} + \mathbf{l}),
\label{eqn:general_hopfield_update}
\end{equation}
for data manipulation tasks, as discussed later in this section.

Building on the latent GMM distribution, the density estimator approximates the data distribution of $\mathbf{x}$ by applying an invertible nonlinear transformation to the latent variable $\boldsymbol{\xi}$, expressed as $\mathbf{x} = \boldsymbol{\Phi}(\boldsymbol{\xi})$. In our implementation, we utilize the real NVP model for this purpose. This choice facilitates fast and accurate computation of the transformation between the density functions of $\mathbf{x}$ and $\boldsymbol{\xi}$,
\begin{equation}
p_x(\mathbf{x}) = p_{\xi}(\boldsymbol{\Phi}^{-1}(\mathbf{x})) \cdot \left| \operatorname{det}\left(\frac{\partial \boldsymbol{\Phi}^{-1}(\mathbf{x})}{\partial \mathbf{x}}\right)\right|.
\label{eqn:realNVP_transformation_prop}
\end{equation}
We also regulate the  real NVP transformation to maintain proximity to an identity function, ensuring only the necessary deviations needed to accurately approximate the true density.

This estimator is notable for its ability to simultaneously estimate the normalized density function, the energy function, and the score function. It supports various training approaches, including score-matching (SM), maximum likelihood estimation (MLE), and their combination. Additionally, its latent Hopfield-like energy function offers two significant benefits: first, it allows the approximated density functions to be centered around adaptively modifiable centroids, effectively preventing the artificial peaks commonly seen in neural density estimators and minimizing heavy distortions typically observed in models relying solely on normalizing flows. Second, the Hopfield-like energy allows us to use the Concave-Convex Procedure (CCCP) to achieve rapid data manipulation for tasks such as denoising and clustering, as elaborated further in this section.

\subsection{Density Estimator Trained from Dynamical Equations}
Now, we apply our loss function to our density estimator to learn the density function directly from the known dynamical equations of a synthesized model. We consider a two-dimensional Stochastic Differential Equation (SDE) where its deterministic component introduces a global attractor that is a limit cycle. With dynamical noise, this system retains a unique steady yet non-equilibrium distribution resembling a doughnut shape.

As depicted in Fig.~\ref{fig:fig5}, we begin from an initial density estimator with randomly placed centroids, with initial $\boldsymbol{\Phi}$ being an identity function. We then train all the parameters in the density estimator via our loss function given the known dynamical equations. The progression of the loss during training is displayed in the lower-left subplot. The bottom row visualizes the post-learning transformed centroids, normalized density function, energy function, and score function, showing the effectiveness of the density estimator and the loss function.
\begin{figure}[ht]
\vskip 0.in
\begin{center}
\centerline{\includegraphics[width=1.0\columnwidth]{fig6.pdf}}
\caption{Comparative analysis of training methods for the density estimator: (a) Training data points. (b) MLE results, showing less smooth density. (c) Score-matching results, smoother but less effective in sparse regions. (d) Combined MLE and score-matching, achieving optimal smoothness and accuracy throughout the distribution.}
\label{fig:fig6}
\end{center}
\vskip -0.5in
\end{figure}

\begin{figure*}[ht]
\vskip -0.1in
\begin{center}
\centerline{\includegraphics[width=2.1\columnwidth]{fig7.pdf}}
\caption{Application of the proposed density estimator on multi-cluster synthesized data. Panel (a) shows the data colored by cluster. Panel (b) presents 450 randomly selected initial centroids and the initial state of density, energy, and score functions. Panel (c) details the training dynamics, including changes in the loss function and transformations of centroids, density, energy, and score functions.}
\label{fig:fig7}
\end{center}
\vskip -0.2in
\end{figure*}

\begin{figure}[ht]
\vskip -0.2in
\begin{center}
\centerline{\includegraphics[width=0.66\columnwidth]{fig8.pdf}}
\caption{Data manipulation results using the density estimator on a 9-cluster synthetic dataset. Top panel: Original data colored by cluster. Bottom left: Denoising from a single CCCP update, showing data collapsing onto a denoised manifold. Bottom right: Clustering from a single CCCP update with increased temperature, rapidly condensing data points into single points.}
\label{fig:fig8}
\end{center}
\vskip -0.5in
\end{figure}

\subsection{Density Estimator Trained from Data}
To better examine the versatility of the proposed density estimator, we also illustrate in Fig.~\ref{fig:fig6} the same density estimator being trained using a provided dataset rather than the dynamics. We test various data-based training methods: 1) MLE, as shown in Fig.~\ref{fig:fig6}(b); 2) score-matching, as depicted in Fig.~\ref{fig:fig6}(c); and 3) a combination of MLE and score-matching, showcased in Fig.~\ref{fig:fig6}(d). This example distinctly highlights the differences between these three data-driven methods. With MLE, training relies solely on likelihood, leading to a non-smooth distribution that can distort the real NVP due to over-fitting. In contrast, the score-matching method, focusing on aligning the score function with the data, results in a smoother distribution but occasionally positions centroids in regions sparsely populated by data. This happens because score-matching primarily evaluates the score in well-sampled areas, overlooking less populated regions. Combining MLE and score-matching yields a smooth and accurate distribution, akin to that achieved using the dynamics-based loss function.

\subsection{Data Manipulation by the Density Estimator}
While the primary focus of this paper is to link dynamical systems with density functions, we also explore how a well-trained density estimator can facilitate effective data manipulation. This bridges the distribution with the data component in our conceptual framework (Fig.~\ref{fig:fig1}), highlighting the theoretical significance of our approach and its potential.

To demonstrate the capability of a trained density estimator for downstream tasks such as denoisin9 and clustering, we employ a synthetic 2D dataset with nine clusters, as shown in Fig.~\ref{fig:fig7}(a). This setup provides a controlled environment to assess the model’s effectiveness in estimating multi-modal densities and facilitating rapid denoising and clustering.

We train the density estimator using a combined MLE and SM loss, as depicted in Fig.~\ref{fig:fig7}. Notably, after training, the transformed centroids of the density estimator align with a low-dimensional denoised manifold.

Subsequently, we apply the CCCP update rule in the latent space to manipulate the data. This rule rapidly moves the latent data to their corresponding local minima in the latent energy function. Depending on the temperature setting of the energy function, this update can either lead data points to collapse onto a low-dimensional denoised manifold (original temperature) or condense into more discrete clustering centers (higher temperature to eliminate local minima), effectively performing rapid clustering. Specifically, given a data point, $\mathbf{X}$, the one-step update is achieved by $\mathbf{x}_{\text{update}} = \boldsymbol{\Phi}(\text{CCCP}(\boldsymbol{\Phi}^{-1}(\mathbf{x}))$. The temperature of the latent energy function is tuned by simply rescaling the covariance matrix $\boldsymbol{\Sigma}$, leading to either one-step denoising or clustering. 

\section{Conclusion}
This work introduces a novel loss function, derived from first principles. It bridges the gap between dynamical systems and density estimation. This versatile tool enables the extraction of density functions from dynamic models and supports the reconstruction of dynamics from observed densities, showcasing both practical utility and theoretical innovation. For the first time, we show the success of learning parameters of the Lorenz system from a dataset without any temporal information. We also establish the necessary and sufficient conditions for the dynamical parameters to be uniquely determinable. Additionally, we employ our loss function alongside a density estimator, which combines a latent Gaussian Mixture Model (GMM) and real NVP, to demonstrate density estimation directly from dynamical equations as well as from data. We also illustrate rapid data manipulation capabilities, such as one-step denoising and one-step clustering, by implementing the CCCP rule in the density estimator. Through this theoretical work, we aim to inspire the development of more innovative machine learning methods, fostering further research and collaborations.


\section*{Software and Data}

We will include the URL for the GitHub repository upon the acceptance of the paper. 

% Acknowledgements should only appear in the accepted version.
%\section*{Acknowledgements}

%\textbf{Do not} include acknowledgements in the initial version of
%the paper submitted for blind review.

\section*{Impact Statement}

This paper presents work whose goal is to advance the field of 
Machine Learning. There are many potential societal consequences 
of our work, none of which we feel must be specifically highlighted here.


% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
\nocite{langley00}

\bibliography{example_paper}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\section{Rigorous Derivation of the Loss Function in the General Non-Steady Case}
\label{apn:1}
In this section, we, from the Fokker-Planck equation, rigorously derive the loss function in the most general case where the dynamics are time-dependent SDEs, and when the distributions are not steady. 

Consider the general time-varying SDE,
\begin{equation}
    d\mathbf{x} = \mathbf{f}(\mathbf{x},t) dt + \mathbf{G}(\mathbf{x},t)d\mathbf{w},
\end{equation}
where the stochastic term $\mathbf{G}(\mathbf{x},t)d\mathbf{w}$ is following Ito's interpretation. Then, from arbitrary initial distribution, the density function evolves following the Fokker-Planck equation,
\begin{align}
    \frac{\partial p(\mathbf{x},t)}{\partial t} &= 
    - \sum_{i=1}^d \frac{\partial}{\partial x_i} \left[ f_i(\mathbf{x}, t) p(\mathbf{x},t) \right]
    + \frac{1}{2} \sum_{i=1}^d \sum_{j=1}^d \frac{\partial^2}{\partial x_i \partial x_j} 
    \left[ \sum_{k=1}^d G_{ik}(\mathbf{x}, t) G_{jk}(\mathbf{x}, t) p(\mathbf{x},t) \right] \\
    &= 
    \sum_{i=1}^d \frac{\partial}{\partial x_i} \left[ - f_i(\mathbf{x}, t) p(\mathbf{x},t) 
    + \frac{1}{2} \sum_{j=1}^d \frac{\partial}{\partial x_j} 
    \left[ \sum_{k=1}^d G_{ik}(\mathbf{x}, t) G_{jk}(\mathbf{x}, t) p(\mathbf{x},t) \right] \right] \label{Eq:derive_fk}
\end{align}
Note that
\begin{align}
    \sum_{j=1}^d \frac{\partial}{\partial x_j} \left[ \sum_{k=1}^d G_{ik}(\mathbf{x}, t) G_{jk}(\mathbf{x}, t) p(\mathbf{x},t) \right] 
    &= \sum_{j=1}^d \frac{\partial}{\partial x_j} \left[ \sum_{k=1}^d G_{ik}(\mathbf{x}, t) G_{jk}(\mathbf{x}, t) \right] p(\mathbf{x},t) \notag \\ 
    &\quad + \sum_{j=1}^d \sum_{k=1}^d G_{ik}(\mathbf{x}, t) G_{jk}(\mathbf{x}, t) p(\mathbf{x},t) \frac{\partial}{\partial x_j} \log p(\mathbf{x},t) \notag \\
    &= p(\mathbf{x},t) \nabla_{\mathbf{x}} \cdot \left[ \mathbf{G}(\mathbf{x}, t) \mathbf{G}(\mathbf{x}, t)^\top \right] \notag \\
    &\quad + p(\mathbf{x},t) \mathbf{G}(\mathbf{x}, t) \mathbf{G}(\mathbf{x}, t)^\top \nabla_{\mathbf{x}} \log p(\mathbf{x},t),
\end{align}
we can thus rewrite Eq.~\ref{Eq:derive_fk} and obtain a simplified Fokker-Planck equation,
\begin{equation}
    \frac{\partial p(\mathbf{x},t)}{\partial t} = - \nabla_{\mathbf{x}} \cdot [\mathbf{F}(\mathbf{x},t)p(\mathbf{x},t)],\label{eq:simple_fk}
\end{equation}
where 
\begin{equation}
    \mathbf{F}(\mathbf{x},t) \equiv \mathbf{f}(\mathbf{x},t) - \frac{1}{2}\nabla_{\mathbf{x}} \cdot[\mathbf{G}(\mathbf{x},t)\mathbf{G}(\mathbf{x},t)^T] - \frac{1}{2} \mathbf{G}(\mathbf{x},t)\mathbf{G}(\mathbf{x},t)^T\mathbf{s}(\mathbf{x},t),
\end{equation}
where the time-varying score function is defined as 
\begin{equation}
    \mathbf{s}(\mathbf{x},t) \equiv \nabla_{\mathbf{x}}\log p(\mathbf{x},t).
\end{equation}
By dividing both sides of Eq.~\ref{eq:simple_fk} by $p(\mathbf{x},t)$, we obtain
\begin{equation}
    \frac{\partial}{\partial t} \log p(\mathbf{x},t) + \mathbf{s}(\mathbf{x},t)\cdot \mathbf{F}(\mathbf{x},t) + \nabla_{\mathbf{x}}\cdot \mathbf{F}(\mathbf{x},t) = 0
\end{equation}
Then, we define the loss function on a set of paired data $\boldsymbol{\Omega}_{t} = \{(\mathbf{x},t)|\mathbf{x}\in\mathbb{R}^d,\ t\in\mathbb{R}\}$ as
\begin{equation}
    L = \sum_{(\mathbf{x},t)\in\boldsymbol{\Omega}_t} |\partial_t \log p(\mathbf{x},t) + \mathbf{s}(\mathbf{x},t)\cdot \mathbf{F}(\mathbf{x},t) + \nabla_{\mathbf{x}}\cdot \mathbf{F}(\mathbf{x},t)|\label{eq:general_loss}
\end{equation}


\section{Loss Function in the Non-Steady Case with Birth-Death Rate Term}
\label{apn:2}
The Fokker-Planck based loss function can also be extended easily to incorporate the case when an additional birth-death process creates and destroys  data points on top of the time-varying SDE.

Consider the Fokker-Planck equation similar to Eq.~\ref{eq:simple_fk},
\begin{equation}
    \frac{\partial p(\mathbf{x},t)}{\partial t} = - \nabla_{\mathbf{x}} \cdot [\mathbf{F}(\mathbf{x},t)p(\mathbf{x},t)] + g(\mathbf{x})p(\mathbf{x},t),\label{eq:simple_fk_with_bd}
\end{equation}
where $g(\cdot):\mathbb{R}^d\rightarrow \mathbb{R}$ is a bounded and smooth function, describing the state-dependent birth-death rate. 

To derive the loss function, we divide the Eq.~\ref{eq:simple_fk_with_bd} from both sides of the $p(\mathbf{x},t)$, and obtain
\begin{equation}
    \frac{\partial}{\partial t} \log p(\mathbf{x},t) + \mathbf{s}(\mathbf{x},t)\cdot \mathbf{F}(\mathbf{x},t) + \nabla_{\mathbf{x}}\cdot \mathbf{F}(\mathbf{x},t) + g(\mathbf{x})= 0,
\end{equation}
which leads to our loss function 
\begin{equation}
    L = \sum_{(\mathbf{x},t)\in\boldsymbol{\Omega}_t} |\partial_t \log p(\mathbf{x},t) + \mathbf{s}(\mathbf{x},t)\cdot \mathbf{F}(\mathbf{x},t) + \nabla_{\mathbf{x}}\cdot \mathbf{F}(\mathbf{x},t) + g(\mathbf{x})|.\label{eq:general_loss_with_bd}
\end{equation}


\section{Existence and Uniqueness of Dynamical Parameter Solution}\label{apn:3}
Inferring a dynamical system from information without any time information is challenging. Especially when the only information is the steady distribution that the system has reached, one can find an infinite number of distinctive dynamical models, each with a different time scale and different flux, that perfectly evolve into such a distribution. However, when more restrictions on the dynamical system can be provided, it is possible that a unique dynamical system can be found. Here, we consider a partially known dynamical model with a set of to-be-determined parameters. In this case, we provide a theorem for the necessary and sufficient condition that such a unique solution exists, as well as the method to directly solve for the optimal set of the dynamical parameters. We show the proof and also show that in particular cases where the dynamics are written in forms that are affine in terms of the unknown parameters, the optimization of this loss function is convex. Along with the proof, we also note that the use of the proposed loss function in inferring dynamical parameters does not need the global knowledge of the density function, but local assessments, allowing this method to be applied to cases where the score function as well as its divergence can only be assessed locally in several locations. 


\begin{theorem}\label{theorem1}
Given a set of $n$ probing points, $\boldsymbol{\Omega}=\{\mathbf{x}_i|\mathbf{x}_i\in\mathbb{R}^d \text{ for } i=1,2,...,n\}$, where the score function $\mathbf{s}(\mathbf{x})$, and their divergence $\nabla \cdot\mathbf{s}(\mathbf{x})$ are locally known. Consider the case where one uses the proposed loss function to infer the dynamical parameters $\boldsymbol{\Theta}\in\mathbb{R}^{d\times m}$ of a given dynamical model 
\begin{equation}
    d\mathbf{x} = \mathbf{f}_{\boldsymbol{\Theta}}(\mathbf{x})dt + \sqrt{2D}d\mathbf{w},
\end{equation}
with $\mathbf{f}_{\boldsymbol{\Theta}}(\mathbf{x})=\mathbf{v}(\mathbf{x}) + \boldsymbol{\Theta}\mathbf{u}(\mathbf{x})$, $\mathbf{v}:\mathbb{R}^d \rightarrow \mathbb{R}^d$ the known part of the dynamics that is differential at $\mathbf{x}\in\boldsymbol{\Omega}$, and the unknown part of the dynamics being described as a weighted sum of $m$ basis functions $\mathbf{u}:\mathbb{R}^d\rightarrow\mathbb{R}^m$ that are also differentiable at $\mathbf{x}\in\boldsymbol{\Omega}$. The proposed loss function is convex in $\boldsymbol{\Theta}$. There exists a unique solution $\boldsymbol{\Theta}$ if and only if the matrix $A$ has full column rank ($\mathrm{rank}(A) = md$) and the vector $\mathbf{b}$ is in the column space of $A$,
where $A$ is a matrix of shape $n$-by-$md$ such that its $i$-th row is defined as
\begin{equation}
    A_{i,:}^T = \mathrm{Vec}[\mathbf{s}(\mathbf{x}_i) \mathbf{u}^T(\mathbf{x}_i) + \mathbf{J}^T_{\mathbf{u}}(\mathbf{x}_i)], 
\end{equation}
with $\mathbf{J}_{\mathbf{u}}(\mathbf{x})\in\mathbb{R}^{m\times d}$ being the Jacobian matrix of $\mathbf{u}(\cdot)$ evaluated at $\mathbf{x}$, and $\mathbf{b} = [b_1,...,b_n]^T$ is a vector of shape $n$-by-$1$ defined as 
\begin{equation}
    b_i = \mathbf{s}^T(\mathbf{x}_i)\mathbf{v}(\mathbf{x}_i) + \nabla\cdot\mathbf{v}(\mathbf{x}_i) - D(\mathbf{s}^T(\mathbf{x}_i)\mathbf{s}(\mathbf{x}_i) + \nabla\cdot\mathbf{s}(\mathbf{x}_i)).
\end{equation}.

In general, a solution of the dynamical parameter, being denoted as a vector as  $\boldsymbol{\theta}\equiv\mathrm{Vec}[\boldsymbol{\Theta}]\in\mathbb{R}^{md\times 1}$, can be solved directly using 
\begin{equation}
    \boldsymbol{\theta} = A^{\dagger} \mathbf{b}.
\end{equation}
\end{theorem}

\begin{proof}
To prove the theorem, we first show that the loss function can be written as a convex function of an affine function of the parameters. We then show the necessary and sufficient condition for the existence of a unique solution, with its global minimum value being $0$. Then, we show how the dynamical parameters can be solved by simply using the pseudo-inverse.  

By substituting the stochastic dynamical model into the proposed loss function, it is easy to show that 
\begin{equation}   
    L = \sum_{i=1}^{n}|\mathbf{s}^T(\mathbf{x}_i)\mathbf{v}(\mathbf{x}_i) + \mathbf{s}^T(\mathbf{x}_i)\boldsymbol{\Theta}\mathbf{u}(\mathbf{x}_i) - D\mathbf{s}^T(\mathbf{x}_i)\mathbf{s}(\mathbf{x}_i) + \nabla\cdot \mathbf{v}(\mathbf{x}_i) + \langle \boldsymbol{\Theta},J^T_{\mathbf{u}}(\mathbf{x}_i)\rangle_F - D\nabla\cdot \mathbf{s}(\mathbf{x}_i) |,
\end{equation}
where $\langle\cdot,\cdot\rangle_F$ is the Frobenius inner product. By flattening the parameter matrix from $\boldsymbol{\Theta}$ to a vector $\boldsymbol{\theta}\equiv\mathrm{Vec(\boldsymbol{\Theta})}\in\mathbb{R}^{md\times 1}$, it is easy to show that the loss function can be further written as 
\begin{equation}
    L = |A\boldsymbol{\theta}-\mathbf{b}|,
\end{equation}
where $\mathbf{b}$ is given in the theorem. Note that $|\cdot|$ is convex and $A\boldsymbol{\theta}-\mathbf{b}$ is an affine operation on $\boldsymbol{\theta}$. Thus, the loss function is convex. By setting the loss equal to zero, it becomes obvious that the necessary and sufficient condition for a unique solution is when $A$ is of full rank and $\mathbf{b}$ being in the column space of $A$. And generally, no matter if the solution is unique or not, one can solve for the parameter using the pseudo-inverse.

\end{proof}



\section{The Gene Regulatory Network Model}
\label{apn:4}
\begin{figure}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=0.4\columnwidth]{figA1.pdf}}
\caption{The full parameter training behavior of the gene-regulatory network system. The result is from five random trails. The true parameter values are shown as dashed lines.}
\label{fig:figA1}
\end{center}
\vskip -0.2in
\end{figure}

In this section, we detail the gene regulatory network model adapted from \cite{martinez2012quantitative}. We construct a stochastic model involving five interacting genes, where $p$, $b$, and $r$ represent the expression levels of the three non-driver genes, with $\text{BCR}$ and $\text{CD40}$ as the driver genes. To facilitate autonomous oscillatory dynamics for the two driver genes, we introduce a 4-dimensional dynamical system,
\begin{align}
dx_1 &= \left(\frac{\pi}{100} y_1 + x_1 (1 - x_1^2 - y_1^2)\right) dt + \sqrt{0.0002} dw_1, \\
dy_1 &= \left(-\frac{\pi}{100} x_1 + y_1 (1 - x_1^2 - y_1^2)\right) dt + \sqrt{0.0002} dw_2, \\
dx_2 &= \left(\frac{\sqrt{2}\pi}{100} y_2 + x_2 (1 - x_2^2 - y_2^2)\right) dt + \sqrt{0.0002} dw_3, \\
dy_2 &= \left(-\frac{\sqrt{2}\pi}{100} x_2 + y_2 (1 - x_2^2 - y_2^2)\right) dt + \sqrt{0.0002} dw_4.
\end{align}

We define the nonlinear transformations for the transcription levels of the three non-driver genes as follows:
\begin{align}
\pi &= \frac{1}{1 + p^2}, \\
\beta &= \frac{1}{1 + b^2}, \\
\rho &= \frac{1}{1 + r^2}.
\end{align}

The expression levels of the two driver genes are defined by:
\begin{align}
\text{BCR} &= 10 \left(\sin\left(\arctan(\frac{y_1}{x_1})\right)^{30}\right) \beta, \\
\text{CD40} &= 5 \left(\sin\left(\arctan(\frac{y_2}{x_2})\right)^{30}\right) \beta.
\end{align}

The dynamics of the remaining three genes are then given by:
\begin{align}
dp &= \left(1 \times 10^{-6} - p + 9 i_1 \right) dt + \sqrt{0.0002} dw_5, \\
db &= \left(2 - (1 + \text{BCR})  b + 100 i_2 \right) dt + \sqrt{0.0002} dw_6, \\
dr &= \left(0.1 - r + \text{CD40} + 2.6 i_3 \right) dt + \sqrt{0.0002} dw_7,
\end{align}
where
\begin{equation}
\begin{bmatrix}
i_1 \\
i_2 \\
i_3
\end{bmatrix}
=
\begin{bmatrix}
0 & 1 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 \\
0 & 0 & 1 & 0 & 0 & 0 & 0
\end{bmatrix}
\begin{bmatrix}
\pi \\
\beta \\
\rho \\
\pi\beta \\
\pi\rho \\
\beta\rho \\
\pi\beta\rho
\end{bmatrix}.
\end{equation}

In this example, our goal is to infer this $3\times 7$ matrix from a set of 7-dimensional non-temporal data. The learning behavior of the full gene regulatory network is shown in Fig.~\ref{fig:figA1}. Most of the parameters are learned correctly, except for the 12th and 14th parameters. This error can be attributed to symmetries in the data that our loss function does not accurately distill, given the high correlation between the terms $\pi\rho$ and $\pi\beta\rho$.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=.5\textwidth,keepaspectratio]{figA2.pdf}
    \caption{\textbf{Comparing the Modern Hopfield Network's density function and that of the latent space in our density estimator.} The left schematic illustrates the underlying density function of the modern Hopfield network, characterized by a covariance matrix that is a scaled identity matrix. In this model, the weights of the centroids are fixed and disproportionately favor centroids with larger norms. Conversely, the right schematic depicts the latent density function in our proposed density estimator. This model features a shared and trainable covariance matrix, along with evenly distributed and trainable weights for each centroid.}
    \label{fig:figA2}
\end{figure}

\section{Modern Hopfield Network as a Special Case of Gaussian Mixture Model}
\label{apn:5}
Let's consider a $d$-by-$n$ data matrix, $\boldsymbol{\Xi}$, where $n$ is the number of stored patterns and $d$ the dimension. Each column in $\boldsymbol{\Xi}$, denoted by $[\boldsymbol{\Xi}]_{:,i} \in \mathbb{R}^d$, represents the $i$-th pattern stored in the Hopfield network. The energy function of such a Hopfield network is then defined as,
\begin{equation}
    E_{\text{hop}}(\boldsymbol{\xi}) = \frac{1}{2}\boldsymbol{\xi}^T\boldsymbol{\xi} - \text{lse}(\beta, \boldsymbol{\Xi}^T\boldsymbol{\xi}) + \text{const.},
\end{equation}
where the log-sum-exponential function for a vector $\mathbf{z} \in \mathbb{R}^n$ is defined as
\begin{equation}
    \text{lse}(\beta, \mathbf{z}) = \beta^{-1}\log\left(\sum_{i=1}^N \exp(\beta z_i)\right).
    \label{eqn:lse}
\end{equation}
Based on such an energy function, they applied the CCCP and obtained the following update rule that guarantees convergence to the close-by stationary points in the energy landscape,
\begin{equation}
    \boldsymbol{\xi}^{t+1} = \boldsymbol{\Xi}\text{softmax}(\beta \boldsymbol{\Xi}^T\boldsymbol{\xi}^{t}).
    \label{eqn:hopfield_update}
\end{equation}
Note that the softmax function is independently applied onto each column if its input variable is a matrix. In \cite{ramsauer2020hopfield}, they proved that their Hopfield network can retrieve stored patterns in one-step update with exponentially small error, and with storage capacity that is exponential on the network dimension $d$. 

To show the connection between the modern Hopfield network and a GMM, we begin by deriving the Hopfield energy function (Eq.~\ref{eqn:hopfield_energy}) from a particular case of the GMM. 

In general, a GMM estimates the density function from a given dataset $\boldsymbol{X}$ by
\begin{equation}
    p_{\text{gmm}}(\boldsymbol{\xi}) = \sum_{i=1}^N c_i \frac{1}{\sqrt{(2\pi)^d \det(\boldsymbol{\Sigma}_i)}} \exp\left(-\frac{1}{2} (\boldsymbol{\xi}-[\boldsymbol{\Xi}]_{:,i})^T \boldsymbol{\Sigma}_i^{-1}(\boldsymbol{\xi}-[\boldsymbol{\Xi}]_{:,i})\right).
    \label{eqn:gmm_p}
\end{equation}
As a particular case of the general GMM, we assume that all the covariance matrices in the GMM are identically set to be $\boldsymbol{\Sigma}_i = \beta^{-1}\boldsymbol{I}$, where $\beta > 0$ is the inverse temperature, and $i=1,2,...,N$. To derive the modern Hopfield energy function, we require that the GMM model emphasizes data points with higher norm by setting $c_i \sim \exp\left(\frac{1}{2} [\boldsymbol{\Xi}]_{:,i}^T [\boldsymbol{\Xi}]_{:,i}\right)$. At last, we assume that the distribution is at equilibrium under the given temperature by following the Boltzmann distribution,
\begin{equation}
    p(\boldsymbol{\xi}) \sim e^{-\beta E(\boldsymbol{\xi})}.
    \label{eqn:boltz_dis}
\end{equation}
Then, it is evident that the energy function is identical to the previous Hopfield energy, except for a constant difference.

Building upon the connection between the Hopfield energy and the GMM-estimated distribution, we can generalize the modern Hopfield network for much more versatile applications related to density estimation.

Specifically, we consider the case where the GMM constructed from a set of centroids incorporates a shared covariance matrix. In this case, the density function reads,
\begin{equation}
    p(\boldsymbol{\xi}) \sim \sum_{i=1}^N e^{\lambda_i - \frac{1}{2} ([\boldsymbol{\Xi}]_{:,i} - \boldsymbol{\xi})^T \boldsymbol{\Sigma}^{-1} ([\boldsymbol{\Xi}]_{:,i} - \boldsymbol{\xi})},
    \label{eqn:general_hopfield_distribution}
\end{equation}
where $[\boldsymbol{\lambda}]_i \in \mathbb{R}$ for $i=1,2,...,n$, $\boldsymbol{\Sigma}$ is the covariance matrix shared by all centroids that is positive semi-definite. This density function no longer assumes that the density function is a sum of many isotropic normal distributions as the Hopfield network does. Instead, the density is flexibly determined by a shared trainable covariance matrix and trainable weights $\boldsymbol{\lambda}$.

With such a density function, we can define the flexible Hopfield model's energy function as
\begin{equation}
    E(\boldsymbol{\xi}) = -\log(p(\boldsymbol{\xi})) + \text{const.} = \frac{1}{2}\boldsymbol{\xi}^T \boldsymbol{\Sigma}^{-1} \boldsymbol{\xi} - \text{lse}(\boldsymbol{\Xi}^T \boldsymbol{\Sigma}^{-1}\boldsymbol{\xi} + \boldsymbol{\lambda} + \boldsymbol{l}) + \text{const.},
    \label{apeqn:general_hopfield_energy}
\end{equation}
where $[\boldsymbol{l}]_i = -\frac{1}{2} [\boldsymbol{\Xi}]_{:,i}^T \boldsymbol{\Sigma}^{-1} [\boldsymbol{\Xi}]_{:,i}$. We note that the first term is convex and the second is concave. Thus, we can utilize the CCCP rule and obtain the following update rule,
\begin{equation}
    \boldsymbol{\xi}_{\text{update}} = \boldsymbol{\Xi}\text{softmax}(\boldsymbol{\Xi}^T \boldsymbol{\Sigma}^{-1} \boldsymbol{\xi} + \boldsymbol{\lambda} + \boldsymbol{l}).
    \label{apeqn:general_hopfield_update}
\end{equation}

In figure~\ref{fig:figA2}, we use a schematic to show the difference of the density function in a Modern Hopfield network and the latent density function in our density estimator. 


\section{Real NVP Implementation}
\label{apn:6}

In the examples provided in the main text, we employ real NVP modules with two to six stacks, where each stack uses feedforward neural networks with two hidden layers, each layer containing 200 units, as its scaling and translating functions in the affine coupling component.

We recognize that the primary role of the real NVP is not to significantly distort the latent distribution. Rather, we want the real NVP to subtly conform the latent GMM to the true distribution. Therefore, we initialize the coefficients in front of  both the scaling and the translating networks in the real NVP to zero. This allows the real NVP to be initialized at an identity function without impairing its affine coupling network's initial parameter distributions. To further prevent large distortions, which could lead to non-smooth distributions or training instability, we opt for the $\tanh()$ activation function rather than the more common $\text{ReLU}()$ activation function in the affine coupling layers.

During the training of the Real NVP module, we also consider including an optional L-1 regularization on the coefficients in front of the affine coupling layers, minimizing the distance between the latent variable $\boldsymbol{\xi}$ and its corresponding  real NVP transformation $\mathbf{x}$. We anticipate that for more complex datasets, incorporating such a regularization could be beneficial in enhancing model stability and performance.

\end{document}

