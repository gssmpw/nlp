[
  {
    "index": 0,
    "papers": [
      {
        "key": "liu2023llm",
        "author": "Liu, Zechun and Oguz, Barlas and Zhao, Changsheng and Chang, Ernie and Stock, Pierre and Mehdad, Yashar and Shi, Yangyang and Krishnamoorthi, Raghuraman and Chandra, Vikas",
        "title": "Llm-qat: Data-free quantization aware training for large language models"
      },
      {
        "key": "chen2024db",
        "author": "Chen, Hong and Lv, Chengtao and Ding, Liang and Qin, Haotong and Zhou, Xiabin and Ding, Yifu and Liu, Xuebo and Zhang, Min and Guo, Jinyang and Liu, Xianglong and others",
        "title": "DB-LLM: Accurate dual-binarization for efficient LLMs"
      },
      {
        "key": "du2024bitdistiller",
        "author": "Du, Dayou and Zhang, Yijia and Cao, Shijie and Guo, Jiaqi and Cao, Ting and Chu, Xiaowen and Xu, Ningyi",
        "title": "Bitdistiller: Unleashing the potential of sub-4-bit llms via self-distillation"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "yao2022zeroquant",
        "author": "Yao, Zhewei and Yazdani Aminabadi, Reza and Zhang, Minjia and Wu, Xiaoxia and Li, Conglong and He, Yuxiong",
        "title": "Zeroquant: Efficient and affordable post-training quantization for large-scale transformers"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "li2021brecq",
        "author": "Li, Yuhang and Gong, Ruihao and Tan, Xu and Yang, Yang and Hu, Peng and Zhang, Qi and Yu, Fengwei and Wang, Wei and Gu, Shi",
        "title": "Brecq: Pushing the limit of post-training quantization by block reconstruction"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "frantar2022gptq",
        "author": "Frantar, Elias and Ashkboos, Saleh and Hoefler, Torsten and Alistarh, Dan",
        "title": "Gptq: Accurate post-training quantization for generative pre-trained transformers"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "chee2024quip",
        "author": "Chee, Jerry and Cai, Yaohui and Kuleshov, Volodymyr and De Sa, Christopher M",
        "title": "Quip: 2-bit quantization of large language models with guarantees"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "rastegari2016xnor",
        "author": "Rastegari, Mohammad and Ordonez, Vicente and Redmon, Joseph and Farhadi, Ali",
        "title": "Xnor-net: Imagenet classification using binary convolutional neural networks"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "rastegari2016xnor",
        "author": "Rastegari, Mohammad and Ordonez, Vicente and Redmon, Joseph and Farhadi, Ali",
        "title": "Xnor-net: Imagenet classification using binary convolutional neural networks"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "rastegari2016xnor",
        "author": "Rastegari, Mohammad and Ordonez, Vicente and Redmon, Joseph and Farhadi, Ali",
        "title": "Xnor-net: Imagenet classification using binary convolutional neural networks"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "wang2023bitnet",
        "author": "Wang, Hongyu and Ma, Shuming and Dong, Li and Huang, Shaohan and Wang, Huaijie and Ma, Lingxiao and Yang, Fan and Wang, Ruiping and Wu, Yi and Wei, Furu",
        "title": "Bitnet: Scaling 1-bit transformers for large language models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "xu2024onebit",
        "author": "Xu, Yuzhuang and Han, Xu and Yang, Zonghan and Wang, Shuo and Zhu, Qingfu and Liu, Zhiyuan and Liu, Weidong and Che, Wanxiang",
        "title": "OneBit: Towards Extremely Low-bit Large Language Models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "jo2024mixture",
        "author": "Jo, Dongwon and Kim, Taesu and Kim, Yulhwa and Kim, Jae-Joon",
        "title": "Mixture of Scales: Memory-Efficient Token-Adaptive Binarization for Large Language Models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "huang2024billm",
        "author": "Huang, Wei and Liu, Yangdong and Qin, Haotong and Li, Ying and Zhang, Shiming and Liu, Xianglong and Magno, Michele and Qi, Xiaojuan",
        "title": "Billm: Pushing the limit of post-training quantization for llms"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "li2024arb",
        "author": "Li, Zhiteng and Yan, Xianglong and Zhang, Tianao and Qin, Haotong and Xie, Dong and Tian, Jiang and Kong, Linghe and Zhang, Yulun and Yang, Xiaokang and others",
        "title": "ARB-LLM: Alternating Refined Binarizations for Large Language Models"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "dong2024stbllm",
        "author": "Dong, Peijie and Li, Lujun and Zhong, Yuedong and Du, Dayou and Fan, Ruibo and Chen, Yuhan and Tang, Zhenheng and Wang, Qiang and Xue, Wei and Guo, Yike and others",
        "title": "STBLLM: Breaking the 1-Bit Barrier with Structured Binary LLMs"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "ma2023llm",
        "author": "Ma, Xinyin and Fang, Gongfan and Wang, Xinchao",
        "title": "Llm-pruner: On the structural pruning of large language models"
      },
      {
        "key": "ashkboos2024slicegpt",
        "author": "Ashkboos, Saleh and Croci, Maximilian L and Nascimento, Marcelo Gennari do and Hoefler, Torsten and Hensman, James",
        "title": "Slicegpt: Compress large language models by deleting rows and columns"
      },
      {
        "key": "xia2023sheared",
        "author": "Xia, Mengzhou and Gao, Tianyu and Zeng, Zhiyuan and Chen, Danqi",
        "title": "Sheared llama: Accelerating language model pre-training via structured pruning"
      },
      {
        "key": "an2024fluctuation",
        "author": "An, Yongqi and Zhao, Xu and Yu, Tao and Tang, Ming and Wang, Jinqiao",
        "title": "Fluctuation-based adaptive structured pruning for large language models"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "dong2024pruner",
        "author": "Dong, Peijie and Li, Lujun and Tang, Zhenheng and Liu, Xiang and Pan, Xinglin and Wang, Qiang and Chu, Xiaowen",
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "frantar2023sparsegpt",
        "author": "Frantar, Elias and Alistarh, Dan",
        "title": "Sparsegpt: Massive language models can be accurately pruned in one-shot"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "sun2023simple",
        "author": "Sun, Mingjie and Liu, Zhuang and Bair, Anna and Kolter, J Zico",
        "title": "A simple and effective pruning approach for large language models"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "dong2024stbllm",
        "author": "Dong, Peijie and Li, Lujun and Zhong, Yuedong and Du, Dayou and Fan, Ruibo and Chen, Yuhan and Tang, Zhenheng and Wang, Qiang and Xue, Wei and Guo, Yike and others",
        "title": "STBLLM: Breaking the 1-Bit Barrier with Structured Binary LLMs"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "han2015deep",
        "author": "Han, Song and Mao, Huizi and Dally, William J",
        "title": "Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "tung2018clip",
        "author": "Tung, Frederick and Mori, Greg",
        "title": "Clip-q: Deep network compression learning by in-parallel pruning-quantization"
      },
      {
        "key": "yang2020automatic",
        "author": "Yang, Haichuan and Gui, Shupeng and Zhu, Yuhao and Liu, Ji",
        "title": "Automatic neural network compression by sparsity-quantization joint learning: A constrained optimization-based approach"
      },
      {
        "key": "hu2021opq",
        "author": "Hu, Peng and Peng, Xi and Zhu, Hongyuan and Aly, Mohamed M Sabry and Lin, Jie",
        "title": "Opq: Compressing deep neural networks with one-shot pruning-quantization"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "munagala2020stq",
        "author": "Munagala, Sri Aurobindo and Prabhu, Ameya and Namboodiri, Anoop M",
        "title": "STQ-Nets: Unifying Network Binarization and Structured Pruning."
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "li2020bnn",
        "author": "Li, Yixing and Ren, Fengbo",
        "title": "Bnn pruning: Pruning binary neural network guided by weight flipping frequency"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "wang2021extremely",
        "author": "Wang, Peisong and Li, Fanrong and Li, Gang and Cheng, Jian",
        "title": "Extremely sparse networks via binary augmented pruning for fast image classification"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "dong2024stbllm",
        "author": "Dong, Peijie and Li, Lujun and Zhong, Yuedong and Du, Dayou and Fan, Ruibo and Chen, Yuhan and Tang, Zhenheng and Wang, Qiang and Xue, Wei and Guo, Yike and others",
        "title": "STBLLM: Breaking the 1-Bit Barrier with Structured Binary LLMs"
      }
    ]
  }
]