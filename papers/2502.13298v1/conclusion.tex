\vspace{-5pt}
\section{Conclusion} 
\vspace{-5pt}
We introduce {\ours}, a novel framework that enhances LLM-based TOD systems through prompt chaining and fine-grained feedback. {\ours} enables zero-shot domain adaptation by automatically generating in-domain demonstrations, while its fine-grained feedback mechanism systematically verifies API calls and provides precise corrective actions. Our approach significantly improves multi-turn task completion without domain-specific fine-tuning.
Our experiments on SGD and BiTOD datasets demonstrate that {\ours} achieves substantial gains in Full API Call Accuracy, surpassing state-of-the-art TOD systems. Human evaluations further confirm that LLMs integrated with {\ours} generate more fluent, informative, and effective task completions than baseline models. Ablation studies highlight the complementary contributions of prompt chaining and fine-grained feedback.
{\ours} paves the way for more scalable and adaptable TOD systems by eliminating the need for domain-specific fine-tuning.





% We introduced {\ours}, a novel framework that enhances LLM-based TOD systems through prompt chaining and fine-grained feedback. Unlike traditional TOD systems that require extensive fine-tuning and domain-specific annotations, {\ours} enables zero-shot domain adaptation while improving task consistency and response accuracy. By leveraging structured feedback to refine API calls, {\ours} effectively mitigates execution failures and enhances task completion rates. Experimental results on the SGD and BiTOD datasets demonstrate that {\ours} outperforms SOTA TOD systems, achieving significant gains in full API accuracy. Our ablation study further highlights the importance of prompt chaining and fine-grained feedback in improving TOD performance.


%This paper introduces {\ours}, an interactive framework that enhances task-oriented dialog (TOD) systems through prompt chaining and fine-grained feedback. Unlike traditional methods requiring extensive fine-tuning, {\ours} enables zero-shot domain adaptation while improving task consistency and API response accuracy. By providing corrective feedback, it mitigates errors and enhances generalization across diverse TOD scenarios. Our experiments demonstrate that {\ours} outperforms state-of-the-art fine-tuned TOD systems, achieving significant gains in API accuracy. Future work could extend {\ours} to broader conversational AI applications and refine its feedback mechanisms for greater usability and scalability.



%This paper proposes {\ours}, a novel interactive framework that enhances task-oriented dialog (TOD) systems by leveraging prompt chaining and fine-grained feedback mechanisms. Unlike traditional TOD systems that rely on extensive fine-tuning and domain-specific annotations, {\ours} enables zero-shot domain adaptation while maintaining task consistency and improving response accuracy. {\ours} mitigates errors by providing helpful feedback to the LLM, significantly improving the ability to generalize across diverse real-world task-oriented dialog scenarios. Additionally, the fine-grained feedback mechanism ensures robust task completion by detecting and correcting API errors, further enhancing the reliability of multi-domain dialog settings.  Our experiments show that with {\ours}, we can outperform existing state-of-the-art fine-tuned TOD systems, achieving substantial gains in full API accuracy. These findings highlight the effectiveness of our approach in improving the reliability of instruction-tuned LLMs in real-world TOD applications. Future work could explore extending {\ours} to broader conversational AI scenarios and refining its feedback mechanisms to enhance usability and scalability.