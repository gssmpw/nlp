
\section{Related Works} %% TODO Writing :Sajid

\stitle{Fine-Tuned Task-Oriented Dialog Systems.} % Needs work
TOD systems are typically classified into pipeline-based and end-to-end approaches. Pipeline-based methods \cite{WILLIAMS2007393, lee-2013-structured, LEE2009466, peng-etal-2020-shot, chen-etal-2019-semantically} decompose the system into modular components—natural language understanding, dialog state tracking, policy learning, and natural language generation—allowing independent optimization of each module. In contrast, end-to-end approaches \cite{hosseini2020simple, madotto-etal-2018-mem2seq, su-etal-2022-multi, mosharrof2023zero, SiddiqueTOD, lei-etal-2018-sequicity, lin-etal-2020-mintl, imrattanatrai-fukuda-2023-end} generate responses directly, bypassing these modules. A major drawback of these fine-tuned methods is their reliance on high-quality labeled data, which can be a significant limitation.

%In recent years, task-oriented dialog (TOD) systems have been an active area of research in natural language processing (NLP), evolving significantly over the past few decades. These systems can be divided into two approaches, pipeline-based methods eng et al., 2021; Eric et al., 2020 Feng et al., 2022b; Ye et al., 2022; Su et al., 2022; Heck et al., and end-to-end methods \cite{feng-etal-2023-schema, chung-etal-2023-instructtods, hudecek-dusek-2023-large, hosseini2020simple, gupta-etal-2022-show}. 
 
%The pipeline approach has significant drawbacks, such as error propagation. Mistakes made in the earlier phases can transfer over and negatively impact the later modules in the pipeline, making the entire system less reliable. 

%In recent times, \emph{end-to-end} TOD systems emerged and have been popular among researchers, offering a unified model that integrates all modules and is trained on fully annotated dialog datasets \cite{wen2017, wang2020}). These methods have also been trained from scratch or fine-tuned with fully annotated dialog datasets. While this approach simplifies the architecture more than the previous pipeline architectures, it relies heavily on large-scale, annotated dialog data. 

%In an effort to reduce the dependence on large-scale training datasets, researchers have begun to explore zero-shot approaches for TOD systems. For instance, AnyTOD \cite{zhao-etal-2023-anytod,} leverages a neuro-symbolic approach to unseen tasks without the need for additional training or fine-tuning. Similarly, ZS-ToD \cite{mosharrof2023zero} employs domain schemas in a zero-shot end-to-end model to achieve better performance across unseen domains.

%Despite these explorations, these approaches still operate within the classical modular or end-to-end paradigms. They are not entirely free from the need for training data or fine-tuning with domain-specific training, and their overall performance remains significantly is heavily influenced by the quality of the data collected. 

\stitle{LLM-Powered Systems.} The rise of LLMs has led to the development of various intelligent systems, which can be broadly categorized into three classes. The first class includes Web Agents, which facilitate online interactions for information retrieval and task execution \cite{yao2023react, kim-etal-2024-prospector, ma2023laser, fereidouni-etal-2024-grounded, NEURIPS2022_82ad13ec, sridhar2023hierarchical, furuta2024multimodal}. The second class consists of Mobile Agents, which focus on optimizing LLM-based decision-making for performing diverse tasks on mobile applications \cite{bai2024digirl, lee2023explore, AutoDroid, wen2023droidbot, wang2024mobile, wang2024mobilev2}. The third and most relevant class to our work is LLM-powered TOD Systems \cite{chung-etal-2023-instructtods, Mi_Wang_Li_2022, gao-etal-2023-adaptive, hudecek-dusek-2023-large, UnravelingChatGPT}. Specifically, AutoTOD \cite{xu-etal-2024-rethinking} shares similarities with our approach; however, AutoTOD does not account for the possibility of LLMs making errors in generating API calls and lacks proper evaluation of API accuracy.


\stitle{User Simulators.}
One of the earliest data-driven user simulators is \cite{EckertUser}, where user actions are generated probabilistically based on system actions. In addition to this, there have been many advancements in data-driven user simulation. For instance, recent advancements leverage transformer-based architectures for domain-independent simulation \cite{lin-etal-2021-domain, lin-etal-2022-gentus} and GPT-based models integrating goal state tracking \cite{liu-etal-2022-generative}. Reinforcement learning has also been applied to fine-tune generative simulators \cite{tseng-etal-2021-transferable, cheng-etal-2022-multiwoz}.
More recently, in-context learning (ICL) with LLMs has enabled user simulation without fine-tuning, \cite{terragni2023context, davidson2023user}. Similar to \cite{lin-etal-2021-domain, lin-etal-2022-gentus, liu-etal-2022-generative}, our user simulator employs transformer-based architectures.

% as seen in few-shot prompting \cite{terragni2023context} and ICL-based evaluation \cite{davidson2023user}. Similar to \cite{lin-etal-2021-domain, lin-etal-2022-gentus, liu-etal-2022-generative}, our user simulator employs transformer-based architectures.


%One of the earliest data-driven user simulators is \cite{EckertUser}, where user actions are generated probabilistically based on system actions. In addition to this, there have been many advancements in data-driven user simulation. For instance, transformer-based user simulators such as \cite{lin-etal-2021-domain} and \cite{lin-etal-2022-gentus} aim to achieve domain independence. Other approaches, like \cite{liu-etal-2022-generative}, leverage GPT-based architectures to generate both user actions and utterances, integrating goal state tracking to improve interaction quality. Additionally, reinforcement learning has been used to fine-tune generative user simulators, such as in \cite{tseng-etal-2021-transferable} and \cite{cheng-etal-2022-multiwoz}.
%Recent work explores in-context learning (ICL) for user simulation with large language models (LLMs), eliminating the need for fine-tuning. \cite{terragni2023context} generates user utterances via few-shot prompting, while \cite{davidson2023user} uses ICL-based simulators to evaluate task-oriented dialogue systems. Similar to \cite{lin-etal-2021-domain, lin-etal-2022-gentus, liu-etal-2022-generative}, our user simulator utilizes transformer-based architectures and a mechanism similar to goal state tracking. \textcolor{red}{not quite sure that our approach is similar to  goal state tracking}

% Early data-driven user simulators, such as \cite{EckertUser}, generate user actions probabilistically based on system actions. Transformer-based approaches \cite{lin-etal-2021-domain, lin-etal-2022-gentus} focus on domain independence, while GPT-based models \cite{liu-etal-2022-generative} generate both user actions and utterances with goal state tracking. Reinforcement learning has also been used to fine-tune generative simulators \cite{tseng-etal-2021-transferable, cheng-etal-2022-multiwoz}. More recently, in-context learning (ICL) with large language models (LLMs) \cite{terragni2023context, davidson2023user} enables and evaluates user simulation without fine-tuning.


%% TODO Writing 
% \stitle{Prompt-based Approaches.} In recent times in TOD systems, there has been an emergence of prompt-based language models, such as ChatGPT (OpenAI, 2022), Gemini, Claude, DeepSeek, Llama 3.3 (Touvron et al., 2023), has opened a new era of intelligent assistants. These new models have the potential to understand a user's intent on any domain and can create human-like responses from various topics (OpenAI, 2023a). This approach eliminates the need for fine-tuning. Researchers such as Labruna et al. (2023), Hudevcek and Dusek (2023), Dingliwal et al. (2021), Madotto and Liu (2020), Li et al. (2022), and Madotto et al. (2021) have explored this innovative approach.

%Recently AutoTOD \cite{xu2024rethinking}  

%Most of the recent studies in this field depend on turn-level annotated data for training task-oriented dialog (TOD) models and if the model was trained for general tasks, for TOD systems we need to fine-tune them with our tasks and datasets to get better results. This is one of the major limitations of previous task-oriented dialog systems. Our work here focuses on in-context learning with instruction and example-oriented dialog generation. Instead of training/file-tuning LLMs, we leverage the intelligence of recent LLMs for Task-oriented dialog systems. 