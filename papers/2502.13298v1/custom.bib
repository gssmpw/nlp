@misc{anthropic2023claude,
  author = {Anthropic},
  title = {Claude},
  year = {2023},
  howpublished = {\url{https://www.anthropic.com/claude}},
  note = {Accessed: 2024-03-01}
}

@misc{qwen2024max,
  author = {Qwen Team},
  title = {Qwen 2.5 MAX: A Large Language Model for Advanced Natural Language Processing},
  year = {2024},
  howpublished = {\url{https://www.example.com/qwen-max}},
  note = {Accessed: 2024-03-01}
}

@article{touvron2023llama,
  title={LLaMA: Open and Efficient Foundation Language Models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timothée and Rozière, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@misc{deepseek2024deepseek,
  author = {DeepSeek AI},
  title = {DeepSeek},
  year = {2024},
  howpublished = {\url{https://www.deepseek.com}},
  note = {Accessed: 2024-03-01}
}

@misc{ChatGPT, 

    author = "OpenAI", 

    title = "ChatGPT", 

    year = 2023, 

    note = "[Large Language Model]", 

    url = "https://chat.openai.com/chat", 

    accessdate = {2023-08-01} 

} 

@misc{o3, 

    author = "OpenAI", 

    title = "o3", 

    note = "[Large Language Model]", 

    url = "https://openai.com/index/openai-o3-mini/", 

} 


@inproceedings{kazi2024large,
  title={Large Language Models as User-Agents For Evaluating Task-Oriented-Dialogue Systems},
  author={Kazi, Taaha and Lyu, Ruiliang and Zhou, Sizhe and Hakkani-T{\"u}r, Dilek and Tur, Gokhan},
  booktitle={2024 IEEE Spoken Language Technology Workshop (SLT)},
  pages={913--920},
  year={2024},
  organization={IEEE}
}

@inproceedings{xu2024rethinking,
  title={Rethinking Task-Oriented Dialogue Systems: From Complex Modularity to Zero-Shot Autonomous Agent},
  author={Xu, Heng-Da and Mao, Xian-Ling and Yang, Puhai and Sun, Fanshu and Huang, He-Yan},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={2748--2763},
  year={2024}
}

@article{elizabeth2024large,
  title={Do Large Language Models with Reasoning and Acting Meet the Needs of Task-Oriented Dialogue?},
  author={Elizabeth, Michelle and Veyret, Morgan and Couceiro, Miguel and Dusek, Ondrej and Rojas-Barahona, Lina M},
  journal={arXiv preprint arXiv:2412.01262},
  year={2024}
}


@article{peng2021soloist,
  title={Soloist: Building task bots at scale with transfer learning and machine teaching},
  author={Peng, Baolin and Li, Chunyuan and Li, Jinchao and Shayandeh, Shahin and Liden, Lars and Gao, Jianfeng},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={807--824},
  year={2021},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{xu-etal-2024-rethinking,
    title = "Rethinking Task-Oriented Dialogue Systems: From Complex Modularity to Zero-Shot Autonomous Agent",
    author = "Xu, Heng-Da  and
      Mao, Xian-Ling  and
      Yang, Puhai  and
      Sun, Fanshu  and
      Huang, Heyan",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.152/",
    doi = "10.18653/v1/2024.acl-long.152",
    pages = "2748--2763",
    abstract = "Task-oriented dialogue (TOD) systems are predominantly designed to be composed of several functional modules (e.g. dialogue state tracker, dialogue policy, natural language generation) whether they are pipeline or end-to-end architectures. However, this modular design not only heavily relies on massive fully-annotated data, but also suffers from many intrinsic drawbacks, such as serious error accumulation, poor generalization ability, high customization cost, and low fault tolerance rate. In this paper, we rethink the architecture of the task-oriented dialogue systems and propose a novel fully zero-shot autonomous TOD agent, named AutoTOD, where all the delicate modules in traditional TOD systems are deprecated and all it needs is a general-purpose instruction-following language model (e.g. GPT-4). AutoTOD only leverages a simple instruction schema consisting of the description of tasks and external APIs, and can autonomously decide what to do at each dialogue turn, including asking for information, calling APIs, summarizing API results, and correcting previous mistakes. Moreover, we propose a simulation-based evaluation framework to better validate the abilities of TOD models in real-life scenarios. Extensive experiments conducted on the MultiWOZ and SGD datasets show the superior task completion ability and flexible language skills of AutoTOD."
}


@inproceedings{lin2021zero,
  title={Zero-Shot Dialogue State Tracking via Cross-Task Transfer},
  author={Lin, Zhaojiang and Liu, Bing and Madotto, Andrea and Moon, Seungwhan and Zhou, Zhenpeng and Crook, Paul A and Wang, Zhiguang and Yu, Zhou and Cho, Eunjoon and Subba, Rajen},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={7890--7900},
  year={2021}
}

@inproceedings{bang2023survey,
  title={A Survey on Task-Oriented Dialogue Systems through the Lens of Natural Language Generation},
  author={Bang, Yejin and Cahyawijaya, Samuel and Lee, Hwaran and Lee, Jamin and Su, Dan and Fung, Pascale},
  booktitle={arXiv preprint arXiv:2301.00363},
  year={2023}
}

@inproceedings{zhang2023multilingual,
  title={Multilingual Large Language Models are not (yet) Code-Switchers},
  author={Zhang, Ruochen and Cahyawijaya, Samuel and Cruz, Jan Christian Blaise and Aji, Alham Fikri},
  booktitle={arXiv preprint arXiv:2305.14330},
  year={2023}
}

@inproceedings{ham2020end,
  title={End-to-End Neural Pipeline for Goal-Oriented Dialogue Systems using GPT-2},
  author={Ham, Dahee and Lee, Sang-Woo and Kim, Donghyeon and Kim, Jihie},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={583--592},
  year={2020}
}

@inproceedings{chung2023instructtods,
  title={InstructTODS: Large Language Models for End-to-End Task-Oriented Dialogue Systems},
  author={Chung, Willy and Cahyawijaya, Samuel and Wilie, Bryan and Lovenia, Holy and Fung, Pascale},
  booktitle={Proceedings of the 13th International Joint Conference on Natural Language Processing},
  pages={1--21},
  year={2023}
}

@inproceedings{yang2020ubar,
  title={UBAR: Towards Fully End-to-End Task-Oriented Dialog Systems with GPT-2},
  author={Yang, Lize and Li, Xize and Quan, Jinchao and Xie, Lei},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  pages={969--976},
  year={2020}
}

@inproceedings{sun2022b,
  title={Beyond the API: Generalizing Task-Oriented Dialogue Systems with Customization},
  author={Sun, Weizhe and Moon, Seungwhan and Crook, Paul A and Wang, Zhiguang and Yu, Zhou and Subba, Rajen},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={1--16},
  year={2022}
}

@inproceedings{imrattanatrai2023schema,
  title={Schema-Guided Task-Oriented Dialogue Systems with BERT-based Natural Language Understanding and Generation},
  author={Imrattanatrai, Nattapong and Fukuda, Kei},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={1--10},
  year={2023}
}

@inproceedings{sun2022a,
  title={A Comprehensive Study on Dialogue State Tracking: Past, Present, and Future},
  author={Sun, Weizhe and Moon, Seungwhan and Crook, Paul A and Wang, Zhiguang and Yu, Zhou and Subba, Rajen},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={1--16},
  year={2022}
}

@inproceedings{zhao2022effective,
  title={Effective Sequence-to-Sequence Dialogue State Tracking},
  author={Zhao, Tiancheng and Feng, Wei-Nan and Feng, Yang and Zhao, Rui},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics},
  pages={1--11},
  year={2022}
}

@inproceedings{mosharrof2023b,
  title={A Survey on Recent Advances in Task-Oriented Dialogue Systems},
  author={Mosharrof, Md and Siddique, Nahian and Rahman, Md and others},
  booktitle={arXiv preprint arXiv:2301.00363},
  year={2023}
}

@inproceedings{siddique2022task,
  title={Task-Oriented Dialogue Systems: A Survey},
  author={Siddique, Nahian and Mosharrof, Md and Rahman, Md and others},
  booktitle={arXiv preprint arXiv:2201.00067},
  year={2022}
}
@article{zhang2023dynamics,
  title={Dynamics of the Tongue of Ionizations During the Geomagnetic Storm on 7 September 2015: The Altitudinal Dependences},
  author={Zhang, K. and Song, H. and Wang, H. and Liu, J. and Wang, W. and Wan, X. and Wang, D. and Jin, Y.},
  journal={Journal of Geophysical Research: Space Physics},
  volume={128},
  number={11},
  pages={e2023JA031735},
  year={2023},
  publisher={Wiley Online Library},
  doi={10.1029/2023JA031735}
}

@article{Chung2022,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={70},
  pages={1--53},
  year={2024}
}

@article{lin2021bitod,
  title={BiToD: A Bilingual Multi-Domain Dataset For Task-Oriented Dialogue Modeling},
  author={Lin, Zhaojiang and Madotto, Andrea and Winata, Genta Indra and Xu, Peng and Jiang, Feijun and Hu, Yuxiang and Shi, Chen and Fung, Pascale},
  journal={arXiv preprint arXiv:2106.02787},
  year={2021}
}


@article{liu2024deepseek,
  title={Deepseek-v3 technical report},
  author={Liu, Aixin and Feng, Bei and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and others},
  journal={arXiv preprint arXiv:2412.19437},
  year={2024}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{zhang2019bertscore,
  title={Bertscore: Evaluating text generation with bert},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  journal={arXiv preprint arXiv:1904.09675},
  year={2019}
}

@inproceedings{
    yao2023react,
    title={ReAct: Synergizing Reasoning and Acting in Language Models},
    author={Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik R Narasimhan and Yuan Cao},
    booktitle={The Eleventh International Conference on Learning Representations },
    year={2023},
    url={https://openreview.net/forum?id=WE_vluYUL-X}
}

@inproceedings{kim-etal-2024-prospector,
    title = "Prospector: Improving {LLM} Agents with Self-Asking and Trajectory Ranking",
    author = "Kim, Byoungjip  and
      Jang, Youngsoo  and
      Logeswaran, Lajanugen  and
      Kim, Geon-Hyeong  and
      Kim, Yu Jin  and
      Lee, Honglak  and
      Lee, Moontae",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.879/",
    doi = "10.18653/v1/2024.findings-emnlp.879",
    pages = "14958--14976",
    abstract = "Large language models (LLMs) have shown the ability to solve complex decision-making tasks beyond natural language processing tasks. LLM agents based on few-shot in-context learning (ICL) achieve surprisingly high performance without training. Despite their simplicity and generalizability, ICL-based agents are limited in their ability to incorporate feedback from an environment. In this paper, we introduce Prospector, an LLM agent that consists of two complementary LLMs, an Actor and a Critic. To elicit better instruction-aligned actions from the LLM agent, we propose AskAct prompting that performs an additional self-asking step such as goal and progress checking before generating an action. Furthermore, to implicitly incorporate the environment feedback, we propose Trajectory Ranking that orders generated trajectories by predicting the expected total reward. Prospector encourages the LLM Actor to generate diverse (creative) trajectories, and harnesses the LLM Critic to select the most rewarding trajectory. On representative decision-making benchmark environments such as ALFWorld and WebShop, we empirically demonstrate that Prospector can considerably increase the success rate of given tasks, while outperforming recent advancements such as ReAct and Reflexion."
}

@inproceedings{
    ma2023laser,
    title={{LASER}: {LLM} Agent with State-Space Exploration for Web Navigation},
    author={Kaixin Ma and Hongming Zhang and Hongwei Wang and Xiaoman Pan and Dong Yu},
    booktitle={NeurIPS 2023 Foundation Models for Decision Making Workshop},
    year={2023},
    url={https://openreview.net/forum?id=sYFFyAILy7}
}

@article{bai2024digirl,
    title={DigiRL: Training In-The-Wild Device-Control Agents with Autonomous Reinforcement Learning},
    author={Bai, Hao and Zhou, Yifei and Cemri, Mert and Pan, Jiayi and Suhr, Alane and Levine, Sergey and Kumar, Aviral},
    journal={arXiv preprint arXiv:2406.11896},
    year={2024}
}

@inproceedings{fereidouni-etal-2024-grounded,
    title = "Grounded Language Agent for Product Search via Intelligent Web Interactions",
    author = "Fereidouni, Moghis  and
      Mosharrof, Adib  and
      Siddique, A.b.",
    editor = "Kumar, Sachin  and
      Balachandran, Vidhisha  and
      Park, Chan Young  and
      Shi, Weijia  and
      Hayati, Shirley Anugrah  and
      Tsvetkov, Yulia  and
      Smith, Noah  and
      Hajishirzi, Hannaneh  and
      Kang, Dongyeop  and
      Jurgens, David",
    booktitle = "Proceedings of the 1st Workshop on Customizable NLP: Progress and Challenges in Customizing NLP for a Domain, Application, Group, or Individual (CustomNLP4U)",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.customnlp4u-1.7/",
    doi = "10.18653/v1/2024.customnlp4u-1.7",
    pages = "63--75",
    abstract = "Recent research has focused on developing agents powered by large language models (LLMs) to accomplish complex high-level user intents. However, employing LLMs with billions of parameters (e.g., GPT-4) may incur substantial costs on top of handcrafting extensive prompts. To address this, we introduce a Grounded Language Agent for Intelligent Web Interactions, named GLAINTEL. GLAINTEL employs Flan-T5 as its backbone and is flexible in training in various settings: unsupervised learning, supervised learning, and unsupervised domain adaptation. Specifically, we tackle both the challenge of learning without human demonstrations and the opportunity to leverage human demonstrations effectively when those are available. Additionally, we explore unsupervised domain adaptation for cases where demonstrations are limited to a specific domain. Experimental evaluations across diverse setups demonstrate the effectiveness of GLAINTEL in unsupervised settings, outperforming in-context learning-based approaches that employ larger models with up to 540 billion parameters. Surprisingly, behavioral cloning-based methods that straightforwardly use human demonstrations do not outperform unsupervised variants of GLAINTEL. Additionally, we show that combining human demonstrations with reinforcement learning-based training yields results comparable to methods utilizing GPT-4. The code is available at: https://github.com/MultifacetedNLP/Web-Agents-Unsupervised"
}

@article{lee2023explore,
  title={Explore, select, derive, and recall: Augmenting llm with human-like memory for mobile task automation},
  author={Lee, Sunjae and Choi, Junyoung and Lee, Jungjae and Wasi, Munim Hasan and Choi, Hojun and Ko, Steven Y and Oh, Sangeun and Shin, Insik},
  journal={arXiv preprint arXiv:2312.03003},
  year={2023}
}

@inproceedings{NEURIPS2022_82ad13ec,
    author = {Yao, Shunyu and Chen, Howard and Yang, John and Narasimhan, Karthik},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
    pages = {20744--20757},
    publisher = {Curran Associates, Inc.},
    title = {WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents},
    url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/82ad13ec01f9fe44c01cb91814fd7b8c-Paper-Conference.pdf},
    volume = {35},
    year = {2022}
}

@inproceedings{sridhar2023hierarchical,
  title={Hierarchical Prompting Assists Large Language Model on Web Navigation},
  author={Abishek Sridhar and Robert Lo and Frank F. Xu and Hao Zhu and Shuyan Zhou},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:258841249}
}

@inproceedings{
    furuta2024multimodal,
    title={Multimodal Web Navigation with Instruction-Finetuned Foundation Models},
    author={Hiroki Furuta and Kuang-Huei Lee and Ofir Nachum and Yutaka Matsuo and Aleksandra Faust and Shixiang Shane Gu and Izzeddin Gur},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=efFmBWioSc}
}

@inproceedings{AutoDroid,
author = {Wen, Hao and Li, Yuanchun and Liu, Guohong and Zhao, Shanhui and Yu, Tao and Li, Toby Jia-Jun and Jiang, Shiqi and Liu, Yunhao and Zhang, Yaqin and Liu, Yunxin},
title = {AutoDroid: LLM-powered Task Automation in Android},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649379},
doi = {10.1145/3636534.3649379},
abstract = {Mobile task automation is an attractive technique that aims to enable voice-based hands-free user interaction with smartphones. However, existing approaches suffer from poor scalability due to the limited language understanding ability and the non-trivial manual efforts required from developers or endusers. The recent advance of large language models (LLMs) in language understanding and reasoning inspires us to rethink the problem from a model-centric perspective, where task preparation, comprehension, and execution are handled by a unified language model. In this work, we introduce AutoDroid, a mobile task automation system capable of handling arbitrary tasks on any Android application without manual efforts. The key insight is to combine the commonsense knowledge of LLMs and domain-specific knowledge of apps through automated dynamic analysis. The main components include a functionality-aware UI representation method that bridges the UI with the LLM, exploration-based memory injection techniques that augment the app-specific domain knowledge of LLM, and a multi-granularity query optimization module that reduces the cost of model inference. We integrate AutoDroid with off-the-shelf LLMs including online GPT-4/GPT-3.5 and on-device Vicuna, and evaluate its performance on a new benchmark for memory-augmented Android task automation with 158 common tasks. The results demonstrated that AutoDroid is able to precisely generate actions with an accuracy of 90.9\%, and complete tasks with a success rate of 71.3\%, outperforming the GPT-4-powered baselines by 36.4\% and 39.7\%.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {543–557},
numpages = {15},
keywords = {task automation, large language models, app analysis},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}

@article{wen2023droidbot,
  title={Droidbot-gpt: Gpt-powered ui automation for android},
  author={Wen, Hao and Wang, Hongming and Liu, Jiaxuan and Li, Yuanchun},
  journal={arXiv preprint arXiv:2304.07061},
  year={2023}
}


@inproceedings{UnravelingChatGPT,
  author={Tiziano Labruna and Sofia Brenna and Andrea Zaninello and Bernardo Magnini},
  title={Unraveling ChatGPT: A Critical Analysis of AI-Generated Goal-Oriented Dialogues and Annotations},
  year={2023},
  cdate={1672531200000},
  pages={151-171},
  url={https://doi.org/10.1007/978-3-031-47546-7_11},
  booktitle={AI*IA}
}


@article{wang2024mobile,
  title={Mobile-agent: Autonomous multi-modal mobile device agent with visual perception},
  author={Wang, Junyang and Xu, Haiyang and Ye, Jiabo and Yan, Ming and Shen, Weizhou and Zhang, Ji and Huang, Fei and Sang, Jitao},
  journal={arXiv preprint arXiv:2401.16158},
  year={2024}
}

@article{wang2024mobileV2,
  title={Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration},
  author={Wang, Junyang and Xu, Haiyang and Jia, Haitao and Zhang, Xi and Yan, Ming and Shen, Weizhou and Zhang, Ji and Huang, Fei and Sang, Jitao},
  journal={arXiv preprint arXiv:2406.01014},
  year={2024}
}
@article{terragni2023context,
  title={In-context learning user simulators for task-oriented dialog systems},
  author={Terragni, Silvia and Filipavicius, Modestas and Khau, Nghia and Guedes, Bruna and Manso, Andr{\'e} and Mathis, Roland},
  journal={arXiv preprint arXiv:2306.00774},
  year={2023}
}

@inproceedings{lin-etal-2022-gentus,
    title = "{G}en{TUS}: Simulating User Behaviour and Language in Task-oriented Dialogues with Generative Transformers",
    author = "Lin, Hsien-chin  and
      Geishauser, Christian  and
      Feng, Shutong  and
      Lubis, Nurul  and
      van Niekerk, Carel  and
      Heck, Michael  and
      Gasic, Milica",
    editor = "Lemon, Oliver  and
      Hakkani-Tur, Dilek  and
      Li, Junyi Jessy  and
      Ashrafzadeh, Arash  and
      Garcia, Daniel Hern{\'a}ndez  and
      Alikhani, Malihe  and
      Vandyke, David  and
      Du{\v{s}}ek, Ond{\v{r}}ej",
    booktitle = "Proceedings of the 23rd Annual Meeting of the Special Interest Group on Discourse and Dialogue",
    month = sep,
    year = "2022",
    address = "Edinburgh, UK",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.sigdial-1.28/",
    doi = "10.18653/v1/2022.sigdial-1.28",
    pages = "270--282",
    abstract = "User simulators (USs) are commonly used to train task-oriented dialogue systems via reinforcement learning. The interactions often take place on semantic level for efficiency, but there is still a gap from semantic actions to natural language, which causes a mismatch between training and deployment environment. Incorporating a natural language generation (NLG) module with USs during training can partly deal with this problem. However, since the policy and NLG of USs are optimised separately, these simulated user utterances may not be natural enough in a given context. In this work, we propose a generative transformer-based user simulator (GenTUS). GenTUS consists of an encoder-decoder structure, which means it can optimise both the user policy and natural language generation jointly. GenTUS generates both semantic actions and natural language utterances, preserving interpretability and enhancing language variation. In addition, by representing the inputs and outputs as word sequences and by using a large pre-trained language model we can achieve generalisability in feature representation. We evaluate GenTUS with automatic metrics and human evaluation. Our results show that GenTUS generates more natural language and is able to transfer to an unseen ontology in a zero-shot fashion. In addition, its behaviour can be further shaped with reinforcement learning opening the door to training specialised user simulators."
}

@inproceedings{liu-etal-2022-generative,
    title = "A Generative User Simulator with {GPT}-based Architecture and Goal State Tracking for Reinforced Multi-Domain Dialog Systems",
    author = "Liu, Hong  and
      Cai, Yucheng  and
      Ou, Zhijian  and
      Huang, Yi  and
      Feng, Junlan",
    editor = "Ou, Zhijian  and
      Feng, Junlan  and
      Li, Juanzi",
    booktitle = "Proceedings of the Towards Semi-Supervised and Reinforced Task-Oriented Dialog Systems (SereTOD)",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, Beijing (Hybrid)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.seretod-1.10/",
    doi = "10.18653/v1/2022.seretod-1.10",
    pages = "85--97",
    abstract = "Building user simulators (USs) for reinforcement learning (RL) of task-oriented dialog systems (DSs) has gained more and more attention, which, however, still faces several fundamental challenges. First, it is unclear whether we can leverage pretrained language models to design, for example, GPT-2 based USs, to catch up and interact with the recently advanced GPT- 2 based DSs. Second, an important ingredient in a US is that the user goal can be effectively incorporated and tracked; but how to flexibly integrate goal state tracking and develop an end-to-end trainable US for multi-domains has remained to be a challenge. In this work, we propose a generative user simulator (GUS) with GPT-2 based architecture and goal state tracking towards addressing the above two challenges. Extensive experiments are conducted on MultiWOZ2.1. Different DSs are trained via RL with GUS, the classic agenda-based user simulator (ABUS) and other ablation simulators respectively, and are compared for crossmodel evaluation, corpus-based evaluation and human evaluation. The GUS achieves superior results in all three evaluation tasks."
}

@inproceedings{cheng-etal-2022-multiwoz,
    title = "Is {M}ulti{WOZ} a Solved Task? An Interactive {TOD} Evaluation Framework with User Simulator",
    author = "Cheng, Qinyuan  and
      Li, Linyang  and
      Quan, Guofeng  and
      Gao, Feng  and
      Mou, Xiaofeng  and
      Qiu, Xipeng",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.90/",
    doi = "10.18653/v1/2022.findings-emnlp.90",
    pages = "1248--1259",
    abstract = "Task-Oriented Dialogue (TOD) systems are drawing more and more attention in recent studies.Current methods focus on constructing pre-trained models or fine-tuning strategies while the evaluation of TOD is limited by a policy mismatch problem.That is, during evaluation, the user utterances are from the annotated dataset while these utterances should interact with previous responses which can have many alternatives besides annotated texts.Therefore, in this work, we propose an interactive evaluation framework for TOD. We first build a goal-oriented user simulator based on pre-trained models and then use the user simulator to interact with the dialogue system to generate dialogues.Besides, we introduce a sentence-level and a session-level score to measure the sentence fluency and session coherence in the interactive evaluation. Experimental results show that RL-based TOD systems trained by our proposed user simulator can achieve nearly 98{\%} inform and success rates in the interactive evaluation of MultiWOZ dataset and the proposed scores measure the response quality besides the inform and success rates.We are hoping that our work will encourage simulator-based interactive evaluations in the TOD task."
}

@inproceedings{lin-etal-2021-domain,
    title = "Domain-independent User Simulation with Transformers for Task-oriented Dialogue Systems",
    author = "Lin, Hsien-chin  and
      Lubis, Nurul  and
      Hu, Songbo  and
      van Niekerk, Carel  and
      Geishauser, Christian  and
      Heck, Michael  and
      Feng, Shutong  and
      Gasic, Milica",
    editor = "Li, Haizhou  and
      Levow, Gina-Anne  and
      Yu, Zhou  and
      Gupta, Chitralekha  and
      Sisman, Berrak  and
      Cai, Siqi  and
      Vandyke, David  and
      Dethlefs, Nina  and
      Wu, Yan  and
      Li, Junyi Jessy",
    booktitle = "Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue",
    month = jul,
    year = "2021",
    address = "Singapore and Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.sigdial-1.47/",
    doi = "10.18653/v1/2021.sigdial-1.47",
    pages = "445--456",
    abstract = "Dialogue policy optimisation via reinforcement learning requires a large number of training interactions, which makes learning with real users time consuming and expensive. Many set-ups therefore rely on a user simulator instead of humans. These user simulators have their own problems. While hand-coded, rule-based user simulators have been shown to be sufficient in small, simple domains, for complex domains the number of rules quickly becomes intractable. State-of-the-art data-driven user simulators, on the other hand, are still domain-dependent. This means that adaptation to each new domain requires redesigning and retraining. In this work, we propose a domain-independent transformer-based user simulator (TUS). The structure of TUS is not tied to a specific domain, enabling domain generalization and the learning of cross-domain user behaviour from data. We compare TUS with the state-of-the-art using automatic as well as human evaluations. TUS can compete with rule-based user simulators on pre-defined domains and is able to generalize to unseen domains in a zero-shot fashion."
}

@INPROCEEDINGS{EckertUser,
  author={Eckert, W. and Levin, E. and Pieraccini, R.},
  booktitle={1997 IEEE Workshop on Automatic Speech Recognition and Understanding Proceedings}, 
  title={User modeling for spoken dialogue system evaluation}, 
  year={1997},
  volume={},
  number={},
  pages={80-87},
  keywords={Speech analysis;Speech recognition;Performance evaluation;Manuals;Stochastic systems;System testing;Engineering management;Art;Signal generators;Optimal control},
  doi={10.1109/ASRU.1997.658991}}

@inproceedings{tseng-etal-2021-transferable,
    title = "Transferable Dialogue Systems and User Simulators",
    author = "Tseng, Bo-Hsiang  and
      Dai, Yinpei  and
      Kreyssig, Florian  and
      Byrne, Bill",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.13/",
    doi = "10.18653/v1/2021.acl-long.13",
    pages = "152--166",
    abstract = "One of the difficulties in training dialogue systems is the lack of training data. We explore the possibility of creating dialogue data through the interaction between a dialogue system and a user simulator. Our goal is to develop a modelling framework that can incorporate new dialogue scenarios through self-play between the two agents. In this framework, we first pre-train the two agents on a collection of source domain dialogues, which equips the agents to converse with each other via natural language. With further fine-tuning on a small amount of target domain data, the agents continue to interact with the aim of improving their behaviors using reinforcement learning with structured reward functions. In experiments on the MultiWOZ dataset, two practical transfer learning problems are investigated: 1) domain adaptation and 2) single-to-multiple domain transfer. We demonstrate that the proposed framework is highly effective in bootstrapping the performance of the two agents in transfer learning. We also show that our method leads to improvements in dialogue system performance on complete datasets."
}


@article{davidson2023user,
  title={User simulation with large language models for evaluating task-oriented dialogue},
  author={Davidson, Sam and Romeo, Salvatore and Shu, Raphael and Gung, James and Gupta, Arshit and Mansour, Saab and Zhang, Yi},
  journal={arXiv preprint arXiv:2309.13233},
  year={2023}
}

@article{sekulic2024reliable,
  title={Reliable LLM-based user simulator for task-oriented dialogue systems},
  author={Sekuli{\'c}, Ivan and Terragni, Silvia and Guimar{\~a}es, Victor and Khau, Nghia and Guedes, Bruna and Filipavicius, Modestas and Manso, Andr{\'e} Ferreira and Mathis, Roland},
  journal={arXiv preprint arXiv:2402.13374},
  year={2024}
}



@inproceedings{chung-etal-2023-instructtods,
    title = "{I}nstruct{TODS}: Large Language Models for End-to-End Task-Oriented Dialogue Systems",
    author = "Chung, Willy  and
      Cahyawijaya, Samuel  and
      Wilie, Bryan  and
      Lovenia, Holy  and
      Fung, Pascale",
    editor = "Chen, Kehai  and
      Ku, Lun-Wei",
    booktitle = "Proceedings of the Second Workshop on Natural Language Interfaces",
    month = nov,
    year = "2023",
    address = "Bali, Indonesia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.nlint-1.1/",
    doi = "10.18653/v1/2023.nlint-1.1",
    pages = "1--21"
}

@inproceedings{hudecek-dusek-2023-large,
    title = "Are Large Language Models All You Need for Task-Oriented Dialogue?",
    author = "Hude{\v{c}}ek, Vojt{\v{e}}ch  and
      Dusek, Ondrej",
    editor = "Stoyanchev, Svetlana  and
      Joty, Shafiq  and
      Schlangen, David  and
      Dusek, Ondrej  and
      Kennington, Casey  and
      Alikhani, Malihe",
    booktitle = "Proceedings of the 24th Annual Meeting of the Special Interest Group on Discourse and Dialogue",
    month = sep,
    year = "2023",
    address = "Prague, Czechia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.sigdial-1.21/",
    doi = "10.18653/v1/2023.sigdial-1.21",
    pages = "216--228",
    abstract = "Instruction-finetuned large language models (LLMs) gained a huge popularity recently, thanks to their ability to interact with users through conversation. In this work, we aim to evaluate their ability to complete multi-turn tasks and interact with external databases in the context of established task-oriented dialogue benchmarks. We show that in explicit belief state tracking, LLMs underperform compared to specialized task-specific models. Nevertheless, they show some ability to guide the dialogue to a successful ending through their generated responses if they are provided with correct slot values. Furthermore, this ability improves with few-shot in-domain examples."
}

@article{hosseini2020simple,
  title={A simple language model for task-oriented dialogue},
  author={Hosseini-Asl, Ehsan and McCann, Bryan and Wu, Chien-Sheng and Yavuz, Semih and Socher, Richard},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={20179--20191},
  year={2020}
}

@inproceedings{feng-etal-2023-schema,
    title = "Schema-Guided User Satisfaction Modeling for Task-Oriented Dialogues",
    author = "Feng, Yue  and
      Jiao, Yunlong  and
      Prasad, Animesh  and
      Aletras, Nikolaos  and
      Yilmaz, Emine  and
      Kazai, Gabriella",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.116/",
    doi = "10.18653/v1/2023.acl-long.116",
    pages = "2079--2091",
    abstract = "User Satisfaction Modeling (USM) is one of the popular choices for task-oriented dialogue systems evaluation, where user satisfaction typically depends on whether the user`s task goals were fulfilled by the system. Task-oriented dialogue systems use task schema, which is a set of task attributes, to encode the user`s task goals. Existing studies on USM neglect explicitly modeling the user`s task goals fulfillment using the task schema. In this paper, we propose SG-USM, a novel schema-guided user satisfaction modeling framework. It explicitly models the degree to which the user`s preferences regarding the task attributes are fulfilled by the system for predicting the user`s satisfaction level. SG-USM employs a pre-trained language model for encoding dialogue context and task attributes. Further, it employs a fulfillment representation layer for learning how many task attributes have been fulfilled in the dialogue, an importance predictor component for calculating the importance of task attributes. Finally, it predicts the user satisfaction based on task attribute fulfillment and task attribute importance. Experimental results on benchmark datasets (i.e. MWOZ, SGD, ReDial, and JDDC) show that SG-USM consistently outperforms competitive existing methods. Our extensive analysis demonstrates that SG-USM can improve the interpretability of user satisfaction modeling, has good scalability as it can effectively deal with unseen tasks and can also effectively work in low-resource settings by leveraging unlabeled data. Code is available at \url{https://github.com/amzn/user-satisfaction-modeling}."
}

@inproceedings{gupta-etal-2022-show,
    title = "Show, Don`t Tell: Demonstrations Outperform Descriptions for Schema-Guided Task-Oriented Dialogue",
    author = "Gupta, Raghav  and
      Lee, Harrison  and
      Zhao, Jeffrey  and
      Cao, Yuan  and
      Rastogi, Abhinav  and
      Wu, Yonghui",
    editor = "Carpuat, Marine  and
      de Marneffe, Marie-Catherine  and
      Meza Ruiz, Ivan Vladimir",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.336/",
    doi = "10.18653/v1/2022.naacl-main.336",
    pages = "4541--4549",
    abstract = "Building universal dialogue systems that operate across multiple domains/APIs and generalize to new ones with minimal overhead is a critical challenge. Recent works have leveraged natural language descriptions of schema elements to enable such systems; however, descriptions only indirectly convey schema semantics. In this work, we propose Show, Don`t Tell, which prompts seq2seq models with a labeled example dialogue to show the semantics of schema elements rather than tell the model through descriptions. While requiring similar effort from service developers as generating descriptions, we show that using short examples as schema representations with large language models results in state-of-the-art performance on two popular dialogue state tracking benchmarks designed to measure zero-shot generalization - the Schema-Guided Dialogue dataset and the MultiWOZ leave-one-out benchmark."
}

@inproceedings{zhao-etal-2023-anytod,
    title = "{A}ny{TOD}: A Programmable Task-Oriented Dialog System",
    author = "Zhao, Jeffrey  and
      Cao, Yuan  and
      Gupta, Raghav  and
      Lee, Harrison  and
      Rastogi, Abhinav  and
      Wang, Mingqiu  and
      Soltau, Hagen  and
      Shafran, Izhak  and
      Wu, Yonghui",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.1006/",
    doi = "10.18653/v1/2023.emnlp-main.1006",
    pages = "16189--16204",
    abstract = "We propose AnyTOD, an end-to-end, zero-shot task-oriented dialog (TOD) system capable of zero-shot adaptation onto unseen tasks or domains. We view TOD as a program executed by a language model (LM), where program logic and ontology is provided by a designer as a schema. To enable generalization to unseen schemas and programs without prior training, AnyTOD adopts a neuro-symbolic approach. A neural LM keeps track of events that occur during a conversation, and a symbolic program implementing dialog policy is executed to recommend actions AnyTOD should take. This approach drastically reduces data annotation and model training requirements, addressing the enduring challenge of rapidly adapting a TOD system to unseen tasks and domains. We demonstrate state-of-the-art results on STAR, ABCD and SGD benchmarks. We also demonstrate strong zero-shot transfer ability in low-resource settings, such as zero-shot transfer onto MultiWOZ. In addition, we release STARv2, an updated version of the STAR dataset with richer annotations, for benchmarking zero-shot task transfer for end-to-end TOD models."
}


@inproceedings{lee-2013-structured,
    title = "Structured Discriminative Model For Dialog State Tracking",
    author = "Lee, Sungjin",
    editor = "Eskenazi, Maxine  and
      Strube, Michael  and
      Di Eugenio, Barbara  and
      Williams, Jason D.",
    booktitle = "Proceedings of the {SIGDIAL} 2013 Conference",
    month = aug,
    year = "2013",
    address = "Metz, France",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W13-4069/",
    pages = "442--451"
}

@article{WILLIAMS2007393,
title = {Partially observable Markov decision processes for spoken dialog systems},
journal = {Computer Speech \& Language},
volume = {21},
number = {2},
pages = {393-422},
year = {2007},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2006.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S0885230806000283},
author = {Jason D. Williams and Steve Young},
keywords = {Spoken dialog system, Dialog management, Planning under uncertainty, User modelling, Markov decision processes, Decision theory},
abstract = {In a spoken dialog system, determining which action a machine should take in a given situation is a difficult problem because automatic speech recognition is unreliable and hence the state of the conversation can never be known with certainty. Much of the research in spoken dialog systems centres on mitigating this uncertainty and recent work has focussed on three largely disparate techniques: parallel dialog state hypotheses, local use of confidence scores, and automated planning. While in isolation each of these approaches can improve action selection, taken together they currently lack a unified statistical framework that admits global optimization. In this paper we cast a spoken dialog system as a partially observable Markov decision process (POMDP). We show how this formulation unifies and extends existing techniques to form a single principled framework. A number of illustrations are used to show qualitatively the potential benefits of POMDPs compared to existing techniques, and empirical results from dialog simulations are presented which demonstrate significant quantitative gains. Finally, some of the key challenges to advancing this method – in particular scalability – are briefly outlined.}
}

@article{LEE2009466,
title = {Example-based dialog modeling for practical multi-domain dialog system},
journal = {Speech Communication},
volume = {51},
number = {5},
pages = {466-484},
year = {2009},
issn = {0167-6393},
doi = {https://doi.org/10.1016/j.specom.2009.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S0167639309000107},
author = {Cheongjae Lee and Sangkeun Jung and Seokhwan Kim and Gary Geunbae Lee},
keywords = {Example-based dialog modeling, Generic dialog modeling, Multi-domain dialog system, Domain identification},
abstract = {This paper proposes a generic dialog modeling framework for a multi-domain dialog system to simultaneously manage goal-oriented and chat dialogs for both information access and entertainment. We developed a dialog modeling technique using an example-based approach to implement multiple applications such as car navigation, weather information, TV program guidance, and chatbot. Example-based dialog modeling (EBDM) is a simple and effective method for prototyping and deploying of various dialog systems. This paper also introduces the system architecture of multi-domain dialog systems using the EBDM framework and the domain spotting technique. In our experiments, we evaluate our system using both simulated and real users. We expect that our approach can support flexible management of multi-domain dialogs on the same framework.}
}

@inproceedings{peng-etal-2020-shot,
    title = "Few-shot Natural Language Generation for Task-Oriented Dialog",
    author = "Peng, Baolin  and
      Zhu, Chenguang  and
      Li, Chunyuan  and
      Li, Xiujun  and
      Li, Jinchao  and
      Zeng, Michael  and
      Gao, Jianfeng",
    editor = "Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.17/",
    doi = "10.18653/v1/2020.findings-emnlp.17",
    pages = "172--182",
    abstract = "As a crucial component in task-oriented dialog systems, the Natural Language Generation (NLG) module converts a dialog act represented in a semantic form into a response in natural language. The success of traditional template-based or statistical models typically relies on heavily annotated data, which is infeasible for new domains. Therefore, it is pivotal for an NLG system to generalize well with limited labelled data in real applications. To this end, we present FewshotWOZ, the first NLG benchmark to simulate the few-shot learning setting in task-oriented dialog systems. Further, we develop the SC-GPT model. It is pre-trained on a large set of annotated NLG corpus to acquire the controllable generation ability, and fine-tuned with only a few domain-specific labels to adapt to new domains. Experiments on FewshotWOZ and the large Multi-Domain-WOZ datasets show that the proposed SC-GPT significantly outperforms existing methods, measured by various automatic metrics and human evaluations."
}

@inproceedings{chen-etal-2019-semantically,
    title = "Semantically Conditioned Dialog Response Generation via Hierarchical Disentangled Self-Attention",
    author = "Chen, Wenhu  and
      Chen, Jianshu  and
      Qin, Pengda  and
      Yan, Xifeng  and
      Wang, William Yang",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1360/",
    doi = "10.18653/v1/P19-1360",
    pages = "3696--3709",
    abstract = "Semantically controlled neural response generation on limited-domain has achieved great performance. However, moving towards multi-domain large-scale scenarios are shown to be difficult because the possible combinations of semantic inputs grow exponentially with the number of domains. To alleviate such scalability issue, we exploit the structure of dialog acts to build a multi-layer hierarchical graph, where each act is represented as a root-to-leaf route on the graph. Then, we incorporate such graph structure prior as an inductive bias to build a hierarchical disentangled self-attention network, where we disentangle attention heads to model designated nodes on the dialog act graph. By activating different (disentangled) heads at each layer, combinatorially many dialog act semantics can be modeled to control the neural response generation. On the large-scale Multi-Domain-WOZ dataset, our model can yield a significant improvement over the baselines on various automatic and human evaluation metrics."
}

@inproceedings{madotto-etal-2018-mem2seq,
    title = "{M}em2{S}eq: Effectively Incorporating Knowledge Bases into End-to-End Task-Oriented Dialog Systems",
    author = "Madotto, Andrea  and
      Wu, Chien-Sheng  and
      Fung, Pascale",
    editor = "Gurevych, Iryna  and
      Miyao, Yusuke",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1136/",
    doi = "10.18653/v1/P18-1136",
    pages = "1468--1478",
    abstract = "End-to-end task-oriented dialog systems usually suffer from the challenge of incorporating knowledge bases. In this paper, we propose a novel yet simple end-to-end differentiable model called memory-to-sequence (Mem2Seq) to address this issue. Mem2Seq is the first neural generative model that combines the multi-hop attention over memories with the idea of pointer network. We empirically show how Mem2Seq controls each generation step, and how its multi-hop attention mechanism helps in learning correlations between memories. In addition, our model is quite general without complicated task-specific designs. As a result, we show that Mem2Seq can be trained faster and attain the state-of-the-art performance on three different task-oriented dialog datasets."
}

@inproceedings{su-etal-2022-multi,
    title = "Multi-Task Pre-Training for Plug-and-Play Task-Oriented Dialogue System",
    author = "Su, Yixuan  and
      Shu, Lei  and
      Mansimov, Elman  and
      Gupta, Arshit  and
      Cai, Deng  and
      Lai, Yi-An  and
      Zhang, Yi",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.319/",
    doi = "10.18653/v1/2022.acl-long.319",
    pages = "4661--4676",
    abstract = "Pre-trained language models have been recently shown to benefit task-oriented dialogue (TOD) systems. Despite their success, existing methods often formulate this task as a cascaded generation problem which can lead to error accumulation across different sub-tasks and greater data annotation overhead. In this study, we present PPTOD, a unified plug-and-play model for task-oriented dialogue. In addition, we introduce a new dialogue multi-task pre-training strategy that allows the model to learn the primary TOD task completion skills from heterogeneous dialog corpora. We extensively test our model on three benchmark TOD tasks, including end-to-end dialogue modelling, dialogue state tracking, and intent classification. Experimental results show that PPTOD achieves new state of the art on all evaluated tasks in both high-resource and low-resource scenarios. Furthermore, comparisons against previous SOTA methods show that the responses generated by PPTOD are more factually correct and semantically coherent as judged by human annotators."
}

@article{mosharrof2023zero,
  title={Zero-Shot Generalizable End-to-End Task-Oriented Dialog System using Context Summarization and Domain Schema},
  author={Mosharrof, Adib and Maqbool, Muhammad Hasan and Siddique, AB},
  journal={arXiv preprint arXiv:2303.16252},
  year={2023}
}

@inproceedings{SiddiqueTOD,
author = {Siddique, A.B. and Maqbool, M.H. and Taywade, Kshitija and Foroosh, Hassan},
title = {Personalizing Task-oriented Dialog Systems via Zero-shot Generalizable Reward Function},
year = {2022},
isbn = {9781450392365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511808.3557417},
doi = {10.1145/3511808.3557417},
abstract = {Task-oriented dialog systems enable users to accomplish tasks using natural language. State-of-the-art systems respond to users in the same way regardless of their personalities, although personalizing dialogues can lead to higher levels of adoption and better user experiences. Building personalized dialog systems is an important, yet challenging endeavor, and only a handful of works took on the challenge. Most existing works rely on supervised learning approaches and require laborious and expensive labeled training data for each user profile. Additionally, collecting and labeling data for each user profile is virtually impossible. In this work, we propose a novel framework, P-ToD, to personalize task-oriented dialog systems capable of adapting to a wide range of user profiles in an unsupervised fashion using a zero-shot generalizable reward function. P-ToD uses a pre-trained GPT-2 as a backbone model and works in three phases. Phase one performs task-specific training. Phase two kicks off unsupervised personalization by leveraging the proximal policy optimization algorithm that performs policy gradients guided by the zero-shot generalizable reward function. Our novel reward function can quantify the quality of the generated responses even for unseen profiles. The optional final phase fine-tunes the personalized model using a few labeled training examples. We conduct extensive experimental analysis using the personalized bAbI dialogue benchmark for five tasks and up to 180 diverse user profiles. The experimental results demonstrate that P-ToD, even when it had access to zero labeled examples, outperforms state-of-the-art supervised personalization models and achieves competitive performance on BLEU and ROUGE metrics when compared to a strong fully-supervised GPT-2 baseline.},
booktitle = {Proceedings of the 31st ACM International Conference on Information \& Knowledge Management},
pages = {1787–1797},
numpages = {11},
keywords = {dialog systems, personalization, reinforcement learning, zero-shot learning},
location = {Atlanta, GA, USA},
series = {CIKM '22}
}

@inproceedings{lei-etal-2018-sequicity,
    title = "{S}equicity: Simplifying Task-oriented Dialogue Systems with Single Sequence-to-Sequence Architectures",
    author = "Lei, Wenqiang  and
      Jin, Xisen  and
      Kan, Min-Yen  and
      Ren, Zhaochun  and
      He, Xiangnan  and
      Yin, Dawei",
    editor = "Gurevych, Iryna  and
      Miyao, Yusuke",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1133/",
    doi = "10.18653/v1/P18-1133",
    pages = "1437--1447",
    abstract = "Existing solutions to task-oriented dialogue systems follow pipeline designs which introduces architectural complexity and fragility. We propose a novel, holistic, extendable framework based on a single sequence-to-sequence (seq2seq) model which can be optimized with supervised or reinforcement learning. A key contribution is that we design text spans named belief spans to track dialogue believes, allowing task-oriented dialogue systems to be modeled in a seq2seq way. Based on this, we propose a simplistic Two Stage CopyNet instantiation which emonstrates good scalability: significantly reducing model complexity in terms of number of parameters and training time by a magnitude. It significantly outperforms state-of-the-art pipeline-based methods on large datasets and retains a satisfactory entity match rate on out-of-vocabulary (OOV) cases where pipeline-designed competitors totally fail."
}

@inproceedings{lin-etal-2020-mintl,
    title = "{M}in{TL}: Minimalist Transfer Learning for Task-Oriented Dialogue Systems",
    author = "Lin, Zhaojiang  and
      Madotto, Andrea  and
      Winata, Genta Indra  and
      Fung, Pascale",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.273/",
    doi = "10.18653/v1/2020.emnlp-main.273",
    pages = "3391--3405",
    abstract = "In this paper, we propose Minimalist Transfer Learning (MinTL) to simplify the system design process of task-oriented dialogue systems and alleviate the over-dependency on annotated data. MinTL is a simple yet effective transfer learning framework, which allows us to plug-and-play pre-trained seq2seq models, and jointly learn dialogue state tracking and dialogue response generation. Unlike previous approaches, which use a copy mechanism to {\textquotedblleft}carryover{\textquotedblright} the old dialogue states to the new one, we introduce Levenshtein belief spans (Lev), that allows efficient dialogue state tracking with a minimal generation length. We instantiate our learning framework with two pre-trained backbones: T5 and BART, and evaluate them on MultiWOZ. Extensive experiments demonstrate that: 1) our systems establish new state-of-the-art results on end-to-end response generation, 2) MinTL-based systems are more robust than baseline methods in the low resource setting, and they achieve competitive results with only 20{\%} training data, and 3) Lev greatly improves the inference efficiency."
}

@inproceedings{imrattanatrai-fukuda-2023-end,
    title = "End-to-End Task-Oriented Dialogue Systems Based on Schema",
    author = "Imrattanatrai, Wiradee  and
      Fukuda, Ken",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.645/",
    doi = "10.18653/v1/2023.findings-acl.645",
    pages = "10148--10161",
    abstract = "This paper presents a schema-aware end-to-end neural network model for handling task-oriented dialogues based on a dynamic set of slots within a schema. Contrary to existing studies that proposed end-to-end approaches for task-oriented dialogue systems by relying on a unified schema across domains, we design our approach to support a domain covering multiple services where diverse schemas are available. To enable better generalizability among services and domains with different schemas, we supply the schema`s context information including slot descriptions and value constraints to the model. The experimental results on a well-known Schema-Guided Dialogue (SGD) dataset demonstrated the performance improvement by the proposed model compared to state-of-the-art baselines in terms of end-to-end modeling, dialogue state tracking task, and generalization on new services and domains using a limited number of dialogues."
}

@inproceedings{gao-etal-2023-adaptive,
    title = "An Adaptive Prompt Generation Framework for Task-oriented Dialogue System",
    author = "Gao, Jun  and
      Xiang, Liuyu  and
      Wu, Huijia  and
      Zhao, Han  and
      Tong, Yiqi  and
      He, Zhaofeng",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.76/",
    doi = "10.18653/v1/2023.findings-emnlp.76",
    pages = "1078--1089",
    abstract = "The de facto way of utilizing black-box large language models (LLMs) to perform various downstream tasks is prompting. However, obtaining suitable prompts for specific tasks is still a challenging problem. While existing LLM-based methods demonstrate promising performance in task-oriented dialogue (TOD) task, they often require manual adjustment in prompt selection, or focus solely on dialogue understanding or generation. To address these issues, we propose an adaptive prompt generation framework to fully unleash the potential of LLMs for the comprehensive TOD system. Firstly, we design a trainable slot generator (TSG) that can generate domain and slot information in the belief state, which serves as prior knowledge for subsequent prompt generation. Next, we propose an adaptive prompt generator (APG) that utilizes the prior knowledge to generate prompts for the LLM, deriving the belief state and system response of the dialogue for evaluation. Finally, we evaluate our framework on the MultiWOZ 2.0 dataset. Extensive experiments demonstrate that our method outperforms existing methods. Our code and data will be released."
}


@article{naveed2023comprehensive,
  title={A comprehensive overview of large language models},
  author={Naveed, Humza and Khan, Asad Ullah and Qiu, Shi and Saqib, Muhammad and Anwar, Saeed and Usman, Muhammad and Akhtar, Naveed and Barnes, Nick and Mian, Ajmal},
  journal={arXiv preprint arXiv:2307.06435},
  year={2023}
}

@inproceedings{10.5555/3666122.3666499,
author = {Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
title = {Reflexion: language agents with verbal reinforcement learning},
year = {2023},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Large language models (LLMs) have been increasingly used to interact with external environments (e.g., games, compilers, APIs) as goal-driven agents. However, it remains challenging for these language agents to quickly and efficiently learn from trial-and-error as traditional reinforcement learning methods require extensive training samples and expensive model fine-tuning. We propose Reflexion, a novel framework to reinforce language agents not by updating weights, but instead through linguistic feedback. Concretely, Reflexion agents verbally reflect on task feedback signals, then maintain their own reflective text in an episodic memory buffer to induce better decision-making in subsequent trials. Reflexion is flexible enough to incorporate various types (scalar values or free-form language) and sources (external or internally simulated) of feedback signals, and obtains significant improvements over a baseline agent across diverse tasks (sequential decision-making, coding, language reasoning). For example, Reflexion achieves a 91\% pass@1 accuracy on the HumanEval coding benchmark, surpassing the previous state-of-the-art GPT-4 that achieves 80\%. We also conduct ablation and analysis studies using different feedback signals, feedback incorporation methods, and agent types, and provide insights into how they affect performance. We release all code, demos, and datasets at https://github.com/noahshinn024/reflexion.},
booktitle = {Proceedings of the 37th International Conference on Neural Information Processing Systems},
articleno = {377},
numpages = {19},
location = {New Orleans, LA, USA},
series = {NIPS '23}
}

@article{jain2024mitigating,
  title={On Mitigating Code LLM Hallucinations with API Documentation},
  author={Jain, Nihal and Kwiatkowski, Robert and Ray, Baishakhi and Ramanathan, Murali Krishna and Kumar, Varun},
  journal={arXiv preprint arXiv:2407.09726},
  year={2024}
}

@article{song2025callnavi,
  title={CallNavi: A Study and Challenge on Function Calling Routing and Invocation in Large Language Models},
  author={Song, Yewei and Lothritz, Cedric and Tang, Xunzhu and Ezzini, Saad and Klein, Jacques and Bissyand{\'e}, Tegawend{\'e} F and Boytsov, Andrey and Ble, Ulrick and Goujon, Anne},
  journal={arXiv preprint arXiv:2501.05255},
  year={2025}
}

@article{guo2025deepseek,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}

@inproceedings{he-etal-2022-space,
    title = "{SPACE}-2: Tree-Structured Semi-Supervised Contrastive Pre-training for Task-Oriented Dialog Understanding",
    author = "He, Wanwei  and
      Dai, Yinpei  and
      Hui, Binyuan  and
      Yang, Min  and
      Cao, Zheng  and
      Dong, Jianbo  and
      Huang, Fei  and
      Si, Luo  and
      Li, Yongbin",
    editor = "Calzolari, Nicoletta  and
      Huang, Chu-Ren  and
      Kim, Hansaem  and
      Pustejovsky, James  and
      Wanner, Leo  and
      Choi, Key-Sun  and
      Ryu, Pum-Mo  and
      Chen, Hsin-Hsi  and
      Donatelli, Lucia  and
      Ji, Heng  and
      Kurohashi, Sadao  and
      Paggio, Patrizia  and
      Xue, Nianwen  and
      Kim, Seokhwan  and
      Hahm, Younggyun  and
      He, Zhong  and
      Lee, Tony Kyungil  and
      Santus, Enrico  and
      Bond, Francis  and
      Na, Seung-Hoon",
    booktitle = "Proceedings of the 29th International Conference on Computational Linguistics",
    month = oct,
    year = "2022",
    address = "Gyeongju, Republic of Korea",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2022.coling-1.46/",
    pages = "553--569",
    abstract = "Pre-training methods with contrastive learning objectives have shown remarkable success in dialog understanding tasks. However, current contrastive learning solely considers the self-augmented dialog samples as positive samples and treats all other dialog samples as negative ones, which enforces dissimilar representations even for dialogs that are semantically related. In this paper, we propose SPACE-2, a tree-structured pre-trained conversation model, which learns dialog representations from limited labeled dialogs and large-scale unlabeled dialog corpora via semi-supervised contrastive pre-training. Concretely, we first define a general semantic tree structure (STS) to unify the inconsistent annotation schema across different dialog datasets, so that the rich structural information stored in all labeled data can be exploited. Then we propose a novel multi-view score function to increase the relevance of all possible dialogs that share similar STSs and only push away other completely different dialogs during supervised contrastive pre-training. To fully exploit unlabeled dialogs, a basic self-supervised contrastive loss is also added to refine the learned representations. Experiments show that our method can achieve new state-of-the-art results on the DialoGLUE benchmark consisting of seven datasets and four popular dialog understanding tasks."
}

@inproceedings{zhu-etal-2022-continual,
    title = "Continual Prompt Tuning for Dialog State Tracking",
    author = "Zhu, Qi  and
      Li, Bing  and
      Mi, Fei  and
      Zhu, Xiaoyan  and
      Huang, Minlie",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.80/",
    doi = "10.18653/v1/2022.acl-long.80",
    pages = "1124--1137",
    abstract = "A desirable dialog system should be able to continually learn new skills without forgetting old ones, and thereby adapt to new domains or tasks in its life cycle. However, continually training a model often leads to a well-known catastrophic forgetting issue. In this paper, we present Continual Prompt Tuning, a parameter-efficient framework that not only avoids forgetting but also enables knowledge transfer between tasks. To avoid forgetting, we only learn and store a few prompt tokens' embeddings for each task while freezing the backbone pre-trained model. To achieve bi-directional knowledge transfer among tasks, we propose several techniques (continual prompt initialization, query fusion, and memory replay) to transfer knowledge from preceding tasks and a memory-guided technique to transfer knowledge from subsequent tasks. Extensive experiments demonstrate the effectiveness and efficiency of our proposed method on continual learning for dialog state tracking, compared with state-of-the-art baselines."
}

@inproceedings{zhao-etal-2022-prompt,
    title = "Prompt Conditioned {VAE}: Enhancing Generative Replay for Lifelong Learning in Task-Oriented Dialogue",
    author = "Zhao, Yingxiu  and
      Zheng, Yinhe  and
      Tian, Zhiliang  and
      Gao, Chang  and
      Sun, Jian  and
      Zhang, Nevin L.",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.766/",
    doi = "10.18653/v1/2022.emnlp-main.766",
    pages = "11153--11169",
    abstract = "Lifelong learning (LL) is vital for advanced task-oriented dialogue (ToD) systems. To address the catastrophic forgetting issue of LL, generative replay methods are widely employed to consolidate past knowledge with generated pseudo samples. However, most existing generative replay methods use only a single task-specific token to control their models. This scheme is usually not strong enough to constrain the generative model due to insufficient information involved. In this paper, we propose a novel method, prompt conditioned VAE for lifelong learning (PCLL), to enhance generative replay by incorporating tasks' statistics. PCLL captures task-specific distributions with a conditional variational autoencoder, conditioned on natural language prompts to guide the pseudo-sample generation. Moreover, it leverages a distillation process to further consolidate past knowledge by alleviating the noise in pseudo samples. Experiments on natural language understanding tasks of ToD systems demonstrate that PCLL significantly outperforms competitive baselines in building lifelong learning models."
}

@article{zhang2023instruction,
  title={Instruction tuning for large language models: A survey},
  author={Zhang, Shengyu and Dong, Linfeng and Li, Xiaoya and Zhang, Sen and Sun, Xiaofei and Wang, Shuhe and Li, Jiwei and Hu, Runyi and Zhang, Tianwei and Wu, Fei and others},
  journal={arXiv preprint arXiv:2308.10792},
  year={2023}
}

@inproceedings{moradshahi-etal-2023-zero,
    title = "Zero and Few-Shot Localization of Task-Oriented Dialogue Agents with a Distilled Representation",
    author = "Moradshahi, Mehrad  and
      Semnani, Sina  and
      Lam, Monica",
    editor = "Vlachos, Andreas  and
      Augenstein, Isabelle",
    booktitle = "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.eacl-main.62/",
    doi = "10.18653/v1/2023.eacl-main.62",
    pages = "886--901",
    abstract = "Task-oriented Dialogue (ToD) agents are mostly limited to a few widely-spoken languages, mainly due to the high cost of acquiring training data for each language. Existing low-cost approaches that rely on cross-lingual embeddings or naive machine translation sacrifice a lot of accuracy for data efficiency, and largely fail in creating a usable dialogue agent. We propose automatic methods that use ToD training data in a source language to build a high-quality functioning dialogue agent in another target language that has no training data (i.e. zero-shot) or a small training set (i.e. few-shot). Unlike most prior work in cross-lingual ToD that only focuses on Dialogue State Tracking (DST), we build an end-to-end agent. We show that our approach closes the accuracy gap between few-shot and existing full-shot methods for ToD agents. We achieve this by (1) improving the dialogue data representation, (2) improving entity-aware machine translation, and (3) automatic filtering of noisy translations. We evaluate our approach on the recent bilingual dialogue dataset BiToD.In Chinese to English transfer, in the zero-shot setting, our method achieves 46.7{\%} and 22.0{\%} in Task Success Rate (TSR) and Dialogue Success Rate (DSR) respectively. In the few-shot setting where 10{\%} of the data in the target language is used, we improve the state-of-the-art by 15.2{\%} and 14.0{\%}, coming within 5{\%} of full-shot training."
}

@inproceedings{NEURIPS2020_1457c0d6,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
 volume = {33},
 year = {2020}
}


@inproceedings{rastogi2020towards,
  title={Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset},
  author={Rastogi, Abhinav and Zang, Xiaoxue and Sunkara, Srinivas and Gupta, Raghav and Khaitan, Pranav},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={05},
  pages={8689--8696},
  year={2020}
}

@article{patterson2022carbon,
  title={The carbon footprint of machine learning training will plateau, then shrink},
  author={Patterson, David and Gonzalez, Joseph and H{\"o}lzle, Urs and Le, Quoc and Liang, Chen and Munguia, Lluis-Miquel and Rothchild, Daniel and So, David R and Texier, Maud and Dean, Jeff},
  journal={Computer},
  volume={55},
  number={7},
  pages={18--28},
  year={2022},
  publisher={IEEE}
}

@article{Mi_Wang_Li_2022, title={CINS: Comprehensive Instruction for Few-Shot Learning in Task-Oriented Dialog Systems}, volume={36}, url={https://ojs.aaai.org/index.php/AAAI/article/view/21356}, DOI={10.1609/aaai.v36i10.21356}, abstractNote={As the labeling cost for different modules in task-oriented dialog (ToD) systems is high, a major challenge is to learn different tasks with the least amount of labeled data. Recently, pre-trained language models (PLMs) have shown promising results for few-shot learning in ToD. To better utilize the power of PLMs, this paper proposes Comprehensive Instruction (CINS) that exploits PLMs with extra task-specific instructions. We design a schema (definition, constraint, prompt) of instructions and their customized realizations for three important downstream tasks in ToD, ie. intent classification, dialog state tracking, and natural language generation. A sequence-to-sequence model (T5) is adopted to solve these three tasks in a unified framework. Extensive experiments are conducted on these ToD tasks in realistic few-shot learning scenarios with small validation data. Empirical results demonstrate that the proposed CINS approach consistently improves techniques that finetune PLMs with raw input or short prompt.}, number={10}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Mi, Fei and Wang, Yasheng and Li, Yitong}, year={2022}, month={Jun.}, pages={11076-11084} }

@inproceedings{AttentionisAllYouNeed,
author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, \L{}ukasz and Polosukhin, Illia},
title = {Attention is all you need},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {6000–6010},
numpages = {11},
location = {Long Beach, California, USA},
series = {NIPS'17}
}

@inproceedings{shu2024rewritelm,
  title={Rewritelm: An instruction-tuned large language model for text rewriting},
  author={Shu, Lei and Luo, Liangchen and Hoskere, Jayakumar and Zhu, Yun and Liu, Yinxiao and Tong, Simon and Chen, Jindong and Meng, Lei},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={17},
  pages={18970--18980},
  year={2024}
}n Artificial Intelligence, 38(17), 18970-18980}}

@inproceedings{sun-etal-2023-text,
    title = "Text Classification via Large Language Models",
    author = "Sun, Xiaofei  and
      Li, Xiaoya  and
      Li, Jiwei  and
      Wu, Fei  and
      Guo, Shangwei  and
      Zhang, Tianwei  and
      Wang, Guoyin",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.603/",
    doi = "10.18653/v1/2023.findings-emnlp.603",
    pages = "8990--9005",
    abstract = "Despite the remarkable success of large-scale Language Models (LLMs) such as GPT-3, their performances still significantly underperform fine-tuned models in the task of text classification.This is due to (1) the lack of reasoning ability in addressing complex linguistic phenomena (e.g., intensification, contrast, irony etc); (2) limited number of tokens allowed in in-context learning. In this paper, we introduce \textbf{C}lue \textbf{A}nd \textbf{R}easoning \textbf{P}rompting (CARP). CARP adopts a progressive reasoning strategy tailored to addressing the complex linguistic phenomena involved in text classification: CARP first prompts LLMs to find superficial clues (e.g., keywords, tones, semantic relations, references, etc), based on which a diagnostic reasoning process is induced for final decisions. To further address the limited-token issue, CARP uses a fine-tuned model on the supervised dataset for $k$NN demonstration search in the in-context learning, allowing the model to take the advantage of both LLM`s generalization ability and the task-specific evidence provided by the full labeled dataset. Remarkably, CARP yields new SOTA performances on 4 out of 5 widely-used text-classification benchmarks, 97.39 (+1.24) on SST-2, 96.40 (+0.72) on AGNews, 98.78 (+0.25) on R8 and 96.95 (+0.6) on R52, and a performance comparable to SOTA on MR (92.39 v.s. 93.3). More importantly, we find that CARP delivers impressive abilities on low-resource and domain-adaptation setups. Specifically, using 16 examples per class, CARP achieves comparable performances to supervised models with 1,024 examples per class."
}

@article{wang2023large,
  title={Large language models are zero-shot text classifiers},
  author={Wang, Zhiqiang and Pang, Yiran and Lin, Yanbin},
  journal={arXiv preprint arXiv:2312.01044},
  year={2023}
}

@article{zhang2024pushing,
  title={Pushing The Limit of LLM Capacity for Text Classification},
  author={Zhang, Yazhou and Wang, Mengyao and Ren, Chenyu and Li, Qiuchi and Tiwari, Prayag and Wang, Benyou and Qin, Jing},
  journal={arXiv preprint arXiv:2402.07470},
  year={2024}
}

@article{Pu2023SummarizationI,
  title={Summarization is (Almost) Dead},
  author={Xiao Pu and Mingqi Gao and Xiaojun Wan},
  journal={ArXiv},
  year={2023},
  volume={abs/2309.09558},
  url={https://api.semanticscholar.org/CorpusID:262044218}
}

@article{zhang-etal-2024-benchmarking,
    title = "Benchmarking Large Language Models for News Summarization",
    author = "Zhang, Tianyi  and
      Ladhak, Faisal  and
      Durmus, Esin  and
      Liang, Percy  and
      McKeown, Kathleen  and
      Hashimoto, Tatsunori B.",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "12",
    year = "2024",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2024.tacl-1.3/",
    doi = "10.1162/tacl_a_00632",
    pages = "39--57",
    abstract = "Large language models (LLMs) have shown promise for automatic summarization but the reasons behind their successes are poorly understood. By conducting a human evaluation on ten LLMs across different pretraining methods, prompts, and model scales, we make two important observations. First, we find instruction tuning, not model size, is the key to the LLM`s zero-shot summarization capability. Second, existing studies have been limited by low-quality references, leading to underestimates of human performance and lower few-shot and finetuning performance. To better evaluate LLMs, we perform human evaluation over high-quality summaries we collect from freelance writers. Despite major stylistic differences such as the amount of paraphrasing, we find that LLM summaries are judged to be on par with human written summaries."
}


@article{van2023clinical,
  title={Clinical text summarization: adapting large language models can outperform human experts},
  author={Van Veen, Dave and Van Uden, Cara and Blankemeier, Louis and Delbrouck, Jean-Benoit and Aali, Asad and Bluethgen, Christian and Pareek, Anuj and Polacin, Malgorzata and Reis, Eduardo Pontes and Seehofnerova, Anna and others},
  journal={Research Square},
  year={2023},
  publisher={American Journal Experts}
}


@inproceedings{Radford2019LanguageMA,
  title={Language Models are Unsupervised Multitask Learners},
  author={Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:160025533}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{Thoppilan2022LaMDALM,
  title={LaMDA: Language Models for Dialog Applications},
  author={Romal Thoppilan and Daniel De Freitas and Jamie Hall and Noam M. Shazeer and Apoorv Kulshreshtha and Heng-Tze Cheng and Alicia Jin and Taylor Bos and Leslie Baker and Yu Du and Yaguang Li and Hongrae Lee and Huaixiu Steven Zheng and Amin Ghafouri and Marcelo Menegali and Yanping Huang and Maxim Krikun and Dmitry Lepikhin and James Qin and Dehao Chen and Yuanzhong Xu and Zhifeng Chen and Adam Roberts and Maarten Bosma and Yanqi Zhou and Chung-Ching Chang and I. A. Krivokon and Willard James Rusch and Marc Pickett and Kathleen S. Meier-Hellstern and Meredith Ringel Morris and Tulsee Doshi and Renelito Delos Santos and Toju Duke and Johnny Hartz S{\o}raker and Ben Zevenbergen and Vinodkumar Prabhakaran and Mark D{\'i}az and Ben Hutchinson and Kristen Olson and Alejandra Molina and Erin Hoffman-John and Josh Lee and Lora Aroyo and Ravi Rajakumar and Alena Butryna and Matthew Lamm and V. O. Kuzmina and Joseph Fenton and Aaron Cohen and Rachel Bernstein and Ray Kurzweil and Blaise Aguera-Arcas and Claire Cui and Marian Rogers Croak and Ed H. Chi and Quoc Le},
  journal={ArXiv},
  year={2022},
  volume={abs/2201.08239},
  url={https://api.semanticscholar.org/CorpusID:246063428}
}

@ARTICLE{Raiaan10433480,
  author={Raiaan, Mohaimenul Azam Khan and Mukta, Md. Saddam Hossain and Fatema, Kaniz and Fahad, Nur Mohammad and Sakib, Sadman and Mim, Most Marufatul Jannat and Ahmad, Jubaer and Ali, Mohammed Eunus and Azam, Sami},
  journal={IEEE Access}, 
  title={A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges}, 
  year={2024},
  volume={12},
  number={},
  pages={26839-26874},
  keywords={Cognition;Artificial intelligence;Transformers;Training;Taxonomy;Task analysis;Surveys;Natural language processing;Question answering (information retrieval);Information analysis;Linguistics;Large language models (LLM);natural language processing (NLP);artificial intelligence;transformer;pre-trained models;taxonomy;application},
  doi={10.1109/ACCESS.2024.3365742}}


@article{qin2024large,
  title={Large language models meet nlp: A survey},
  author={Qin, Libo and Chen, Qiguang and Feng, Xiachong and Wu, Yang and Zhang, Yongheng and Li, Yinghui and Li, Min and Che, Wanxiang and Yu, Philip S},
  journal={arXiv preprint arXiv:2405.12819},
  year={2024}
}

@article{Bonan/10.1145/3605943,
author = {Min, Bonan and Ross, Hayley and Sulem, Elior and Veyseh, Amir Pouran Ben and Nguyen, Thien Huu and Sainz, Oscar and Agirre, Eneko and Heintz, Ilana and Roth, Dan},
title = {Recent Advances in Natural Language Processing via Large Pre-trained Language Models: A Survey},
year = {2023},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3605943},
doi = {10.1145/3605943},
abstract = {Large, pre-trained language models (PLMs) such as BERT and GPT have drastically changed the Natural Language Processing (NLP) field. For numerous NLP tasks, approaches leveraging PLMs have achieved state-of-the-art performance. The key idea is to learn a generic, latent representation of language from a generic task once, then share it across disparate NLP tasks. Language modeling serves as the generic task, one with abundant self-supervised text available for extensive training. This article presents the key fundamental concepts of PLM architectures and a comprehensive view of the shift to PLM-driven NLP techniques. It surveys work applying the pre-training then fine-tuning, prompting, and text generation approaches. In addition, it discusses PLM limitations and suggested directions for future research.},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {30},
numpages = {40},
keywords = {Large language models, foundational models, generative AI, neural networks}
}

@inproceedings{NEURIPS2023_9cb2a749,
 author = {Zhuang, Yuchen and Yu, Yue and Wang, Kuan and Sun, Haotian and Zhang, Chao},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {50117--50143},
 publisher = {Curran Associates, Inc.},
 title = {ToolQA: A Dataset for LLM Question Answering with External Tools},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/9cb2a7495900f8b602cb10159246a016-Paper-Datasets_and_Benchmarks.pdf},
 volume = {36},
 year = {2023}
}

@article{Yang/10.1145/3649506,
author = {Yang, Jingfeng and Jin, Hongye and Tang, Ruixiang and Han, Xiaotian and Feng, Qizhang and Jiang, Haoming and Zhong, Shaochen and Yin, Bing and Hu, Xia},
title = {Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {6},
issn = {1556-4681},
url = {https://doi.org/10.1145/3649506},
doi = {10.1145/3649506},
abstract = {This article presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs) in their downstream Natural Language Processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from the perspectives of models, data, and downstream tasks. First, we offer an introduction and brief summary of current language models. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a detailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as knowledge-intensive tasks, traditional natural language understanding tasks, generation tasks, emergent abilities, and considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and limitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated with each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such as efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide aims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the successful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly updated, can be found at . An LLMs evolutionary tree, editable yet regularly updated, can be found at  .},
journal = {ACM Trans. Knowl. Discov. Data},
month = apr,
articleno = {160},
numpages = {32},
keywords = {Large language models, neural language processing, practical guide, ChatGPT}
}