\section{Experiment}
We now present the experimental results that comprehensively demonstrate the performance of \texttt{DINN} on real-world benchmark datasets. To facilitate transparency and reproducibility, the code and configuration details are available at \href{https://anonymous.4open.science/r/Decision-informed-Neural-Networks-with-Large-Language-Model-Integration-for-Portfolio-Optimization-A441/README.md}{Anonymous Github}.

\subsection{Implementation details}
In this section, we describe the datasets, evaluation metrics, baseline models, and hyperparameter settings used in our empirical study. 

\subsubsection{Dataset description}
This study analyzes a comprehensive dataset spanning January 2010 to December 2023, encompassing both the post-financial crisis recovery and the COVID-19 pandemic period. Our primary data consists of equity returns from two major indices: the DOW 30 and a market-cap-weighted subset of 50 constituents from the S\&P 100. To address potential survivorship bias, we include only companies that maintained consistent index membership throughout the study period. The financial data, obtained from WRDS, is complemented by five macroeconomic indicators from FRED, selected based on their documented predictive power in asset pricing: weekly initial jobless claims (ICSA), consumer sentiment (UMCSENT), new home sales (HSN1F), unemployment rate (UNRATE), and high-yield bond spread (HYBS). These variables may capture different aspects of economic conditions that influence asset returns through both systematic risk channels and behavioral mechanisms.

\subsubsection{Evaluation Metrics}
We evaluate each model using eight key metrics designed to capture both return characteristics and various dimensions of risk. These include:

\begin{enumerate}
    \item \textbf{Annualized Return (Ret)}: Reflects the average annual growth of the portfolio without subtracting any risk-free component.
    \item \textbf{Annualized Standard Deviation (Std)}: Gauges the volatility of returns, serving as a basic measure of risk.
    \item \textbf{Sharpe Ratio (SR)}: Examines excess returns (portfolio return minus the risk-free rate) per unit of total volatility.
    \item \textbf{Sortino Ratio (SOR)}: Focuses on downside volatility, isolating harmful fluctuations from benign ones.
    \item \textbf{Maximum Drawdown (MDD)}: Captures the largest observed loss from a prior portfolio high, providing a measure of potential capital erosion.
    \item \textbf{Value at Risk (VaR) at 95\% (monthly)}: Indicates the worst likely loss over a specific time horizon under normal market conditions.
    \item \textbf{Return Over VaR (RoV)}: Scales the portfolio’s excess monthly returns relative to VaR, highlighting returns per tail-risk unit.
    \item \textbf{Terminal Wealth (Wealth)}: Reflects the final cumulative portfolio value, integrating the impact of both returns and compounding.
\end{enumerate}



\subsubsection{Baseline Models and Hyperparameter Selection}
We compare \texttt{DINN} against several state-of-the-art deep learning architectures tailored to financial time series, including both Transformer-based and large language model (LLM)-based methods:

\begin{itemize}
    \item \textbf{Transformer-based methods}: iTransformer \citep{liu2023itransformer}, PatchTST \citep{Yuqietal_PatchTST}, TimesNet \citep{wu2023timesnet}, and Crossformer \citep{zhang2023crossformer}.
    \item \textbf{LLM-based methods}: PAttn \citep{tan2024language}, Chronos \citep{ansari2024chronos}, and GPT4TS \citep{zhou2023one}.
\end{itemize}

All baseline models are implemented using their original architectures and recommended hyperparameters, with minor refinements to accommodate the specifics of our financial data. We provide the detailed hyperparameter settings for \texttt{DINN} in Appendix A.3., ensuring reproducibility and clarity.

\subsection{Can \texttt{DINN} exceed standard deep learning models for portfolio optimization?}
Standard deep learning approaches often focus on minimizing forecasting error without directly addressing the inherent fragility of portfolio selection when faced with small parameter estimation errors. Accordingly, even substantial gains in predictive accuracy may not translate into robust improvements in actual investment outcomes. By contrast, \texttt{DINN} integrates portfolio optimization as a learnable module, aligning model parameters not merely to predict returns accurately but also to optimize the final portfolio decision.

\Cref{tab1:main_result} report the eight core performance metrics—annualized return, standard deviation, Sharpe ratio, Sortino ratio, maximum drawdown, Value-at-Risk, Return over VaR, and terminal wealth—across two datasets (S\&P 100 and DOW 30). These indicators each offer a unique perspective on risk and reward.

The empirical evidence demonstrates that \texttt{DINN} consistently outperforms standard deep learning models across multiple dimensions of portfolio performance, particularly in metrics that capture the quality of investment decisions. This superiority manifests in both return generation and risk management, with notably smaller performance variability across experimental trials. In terms of return generation, \texttt{DINN} achieves markedly higher annualized returns of 43.53\% ($\pm$ 1.45\%) for the S\&P 100 and 63.25\% ($\pm$ 0.43\%) for the DOW 30, substantially exceeding the next best performers (TimesNet at 33.28\% $\pm$ 22.54\% and 36.72\% $\pm$ 21.64\%, respectively). More importantly, \texttt{DINN} exhibits relatively low variability in these returns, indicating consistently superior performance rather than sporadic success. This consistency extends to risk-adjusted performance measures, where \texttt{DINN} achieves the highest Sharpe ratios (1.04 $\pm$ 0.04 and 1.29 $\pm$ 0.01) and Sortino ratios (1.50 $\pm$ 0.05 and 1.94 $\pm$ 0.01) across both datasets, again with minimal variability among all models.

The risk management capabilities of \texttt{DINN} reveal a nuanced picture. While GPT4TS achieves marginally lower maximum drawdowns (33.91\% versus \texttt{DINN}'s 39.51\% for S\&P 100), \texttt{DINN} demonstrates remarkably stable risk characteristics, showing the lowest standard deviation in drawdown measures ($\pm$ 0.64\% for S\&P 100, compared to GPT4TS's $\pm$ 3.68\%). This stability is particularly evident in the Value-at-Risk (VaR) metrics, where \texttt{DINN} maintains competitive levels (12.33\% for S\&P 100 and 13.91\% for DOW 30) while exhibiting very small variability ($\pm$ 0.04\% and $\pm$ 0.15\%, respectively).

Most notably, \texttt{DINN} excels in translating its advantages into tangible investment outcomes. The model achieves the highest Return over VaR (19.87\% for S\&P 100 and 27.72\% for DOW 30) and terminal wealth (3.0213 and 4.4715, respectively) for both datasets, with substantially lower variability than competing approaches. This superior wealth accumulation, combined with consistent risk-adjusted performance metrics, suggests that \texttt{DINN}’s decision-informed architecture more effectively bridges the gap between predictive accuracy and portfolio optimization. These empirical results collectively imply that \texttt{DINN} more effectively reconciles predictive accuracy with the practical objectives of portfolio management, yielding robust and reliable performance gains.

\begin{table}[!htbp]
\centering
\input{Tables/1_main_result_snp_dow}
\captionsetup{font=footnotesize}
\caption{Comparative performance metrics for various time series models applied to the S\&P100 and DOW 30 dataset. Each entry represents the mean metric value along with the standard deviation. Metrics include Annualised Return (Ret), Annualised Standard Deviation (Std), Sharpe Ratio (SR), Sortino Ratio (SOR), Maximum Drawdown (MDD), Monthly 95\% Value-at-Risk (VaR), Return Over VaR (RoV), and accumulated terminal wealth (Wealth). Higher values are desirable for Ret, SR, SOR, RoV, and Wealth; while lower values are preferred for Std, MDD, and VaR. All values are presented as mean $\pm$ standard deviation across experimental trials. \textbf{Bold} values indicate the best performance for each metric, with upward ($\uparrow$) and downward ($\downarrow$) arrows indicating the desired direction of each measure. Values highlighted in \textcolor{blue}{blue} represent the lowest standard deviation for that metric.}
\label{tab1:main_result}
\vspace{-0.5cm}
\end{table}



%\subsection{Why does MSE minimization misalign with investment objectives?} 
%\subsection{Why does prediction-driven learning create portfolio inefficiencies?} % optional title

\subsection{Why does prediction based loss function misalign with investment objectives?} 

A purely prediction-based loss function (e.g., minimizing mean-squared error) presumes that accurate forecasts of expected returns alone suffice for optimal investment decisions. In reality, portfolio optimization is highly sensitive to small forecast errors. Minor deviations in the predicted mean vector can lead to substantial misallocations of capital, especially when risk preferences and constraints amplify these inaccuracies.

Figure 1 illustrates this disconnect by comparing standard deviation outcomes for models trained only to minimize forecast error ("DFL w/o") versus those trained with an integrated decision module ("DFL w/"). Notably, the decision-informed approach exhibits a significantly lower standard deviation across experimental trials, signifying not only enhanced alignment with risk-return objectives but also greater robustness in performance. By aligning learned representations directly with portfolio-level goals, decision-informed approach may mitigates the volatility that often arises when small forecast errors are amplified within traditional MSE-based frameworks. Hence, reducing MSE does not always correlate with mitigating drawdowns, enhancing risk-adjusted returns, or boosting terminal wealth. The tighter variability achieved by the decision-focused model underscores that better forecasts do not necessarily translate into better investment outcomes. Instead, models must explicitly account for how forecast errors influence downstream allocation decisions in order to optimize both mean returns and risk exposure effectively.

\begin{figure}[h!] %!htbp
% \small{
  \centering
  \includegraphics[width=\linewidth]{Figures/output_bold_reorder.pdf}%}
   \captionsetup{font=footnotesize}
   \caption{Comparison of portfolio standard deviation across experimental trials for models trained with prediction-based loss only (DFL w/o) versus models incorporating a decision module (DFL w/). The decision-focused approach demonstrates notably lower variability in standard deviation outcomes, representing how integrating portfolio-level objectives during training leads to more consistent and robust investment performance compared to purely prediction-based optimization.}
  \label{fig:dfl}
\end{figure}

Proposition 1 provides a concrete theoretical example of this phenomenon. In a two-asset mean-variance problem ($\Sigma = I_2$ and $\lambda > 0$), we construct a sequence of predicted return vectors $\tilde{{\mu}}^{(k)}$ that converges to the true mean ${\mu}$ in $\ell_2$-norm (i.e., the MSE sense). Nonetheless, the induced optimal weights $\hat{{w}}$ do not converge to the true optimum ${w}^\star$. This result arises because mean-variance optimization can magnify small errors in the mean vector, thereby distorting the final portfolio solution. The implication is that standard predictive metrics—such as MSE—can overlook significant deviations in the resulting portfolio weights and performance.

\textbf{Proposition 1}: Let ${\mu}\in \mathbb{R}^n$ be the true expected return vector, and let $\hat{{\mu}} = \mathrm{arg\,min}_{{x} \in \mathcal{X}} \|{x} - {\mu}\|_{2}^{2}$.

Consider the mean-variance optimization problem
\begin{equation}
  {w}^{\star} = \mathrm{arg\,max}_{{w} \in \mathcal{W}}
  \{
    {w}^{\top}{\mu} - \lambda\,{w}^{\top}\Sigma\,{w}
  \},
\end{equation}
where $\lambda > 0$, $\Sigma \succ 0$, and $\mathcal{W} \subseteq \mathbb{R}^n$. Define similarly the portfolio
\begin{equation}
\hat{{w}} = \mathrm{arg\,max}_{{w} \in \mathcal{W}}
  \{
    {w}^{\top} \hat{{\mu}} -  \lambda\,{w}^{\top}\Sigma\,{w}
  \}.
\end{equation}
We show that there exist cases in which  
\begin{equation}
    \lim_{\|\hat{{\mu}} - {\mu}\|_2 \to 0} \hat{{w}}  \neq {w}^{\star}.
\end{equation}
In other words, even though $\hat{{\mu}}$ converges to ${\mu}$ in mean-squared error, the corresponding optimal portfolios need not converge to the true optimal portfolio ${w}^{\star}$. Consequently, a small MSE can lead to a large discrepancy in portfolio selection.

\textbf{Proof: } Consider the two-asset setting $(n = 2)$ with $\Sigma = I_2$ and $\lambda > 0$. Let the feasible set be
\begin{equation}
    \mathcal{W} = \{(w_1, w_2) : w_1 + w_2 = 1,  w_1, w_2 \ge 0 \}.
\end{equation}
Suppose the true return vector is ${\mu} = (\mu_1, \mu_2)^\top$ with $\mu_1 > \mu_2$.  Then the mean-variance optimization problem reduces to
\begin{equation}
    {w}^{\star} =\mathrm{arg\,max}_{\,w_1 + w_2 = 1,\;w_1,w_2 \ge 0}
\Bigl[
    w_1\,\mu_1+ w_2\,\mu_2 -\lambda\,\bigl(w_1^2 + w_2^2\bigr)
\Bigr].
\end{equation}

Since $w_2 = 1 - w_1$, define $   L(w_1) =  w_1\mu_1 + (1 - w_1)\mu_2 -\lambda \Bigl[w_1^2 + (1 - w_1)^2 \Bigr]$. Then, differentiating $L(w_1)$ and setting it to zero gives 
\begin{equation}
      \frac{dL}{dw_1} = \mu_1 -\mu_2 - \lambda\,\bigl[\,4\,w_1 - 2\bigr] = 0
\end{equation}

Solving for $w_1$ yields
\begin{equation}
    \mu_1 -\mu_2 =  \lambda\,[4w_1^\star - 2] \quad\Longrightarrow\quad w_1^\star =  \frac{1}{2} + \frac{\mu_1 - \mu_2}{4 \lambda}.
\end{equation}
Consequently, $w_2^\star = 1- w^{\star}_1$.

We then construct a specific sequence $\tilde{{\mu}}^{(k)}$ that converges to ${\mu}$ but whose induced portfolio weights fail to converge to ${w}^\star$. Set $\tilde{{\mu}}^{(k)} = \begin{pmatrix}  \mu_1 - \delta + \tfrac{1}{k}\\  \mu_2 \end{pmatrix}$ Where $\delta = \frac{\mu_1 - \mu_2}{2} > 0$. Clearly, as $k \to \infty$, $\tilde{{\mu}}^{(k)} \to {\mu}$ in $\ell_2$-norm because $\|\tilde{{\mu}}^{(k)} - {\mu}\|_2$ can be made arbitrarily small.

To show that the induced weights do not converge to ${w^{\star}}$, substitute $\tilde{{\mu}}^{(k)}$ into the same mean-variance formula. the optimal weight $w_{1}^{(k)}$ solves 
\begin{equation}
     (\mu_1 - \delta + \tfrac{1}{k}) - \mu_2 =    \lambda\ [ 4w_1^{(k)}- 2]
\end{equation}

Hence, $   w_1^{(k)} = \frac{1}{2} + \frac{(\mu_1 - \mu_2) - \delta +  \tfrac{1}{k}}{4\lambda}$.  By definition $\delta = \tfrac{\mu_1 - \mu_2}{2}$, we get
\begin{equation}
\begin{aligned}
w_1^{(k)} &= \frac{1}{2} + \frac{\tfrac{\mu_1 - \mu_2}{2} + \tfrac{1}{k}}{4\lambda},\\
          &= \frac{1}{2} + \frac{\mu_1 - \mu_2}{8\lambda} + \frac{1}{4\lambda k}.
\end{aligned}
\end{equation}
Meanwhile, the true optimum $w_1^\star$ is $w_1^\star = \frac{1}{2} + \frac{\mu_1 - \mu_2}{4\lambda}$. Observe that $\frac{\mu_1 - \mu_2}{8\lambda} + \frac{1}{4\lambda k} \neq \frac{\mu_1 - \mu_2}{4\lambda}$ So, $\lim_{k\to\infty} w_1^{(k)} \neq w_1^\star$. $\blacksquare$
