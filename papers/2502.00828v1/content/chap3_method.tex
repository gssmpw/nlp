\begin{figure}[h!] %!htbp
% \small{
  \centering
  \includegraphics[width=\linewidth]{Figures/DINN.pdf}%}
   \captionsetup{font=footnotesize}
   \caption{Schematic of the proposed Decision-Informed Neural Network (DINN) architecture for unified return forecasting and portfolio selection. The entire system is trained end-to-end to align predictive accuracy with decision quality.}
  \label{fig:model}
\end{figure}

\section{Decision-informed neural networks with large language model integration for portfolio optimization (DINN)}
We introduce a Decision-Informed Neural Network (DINN) that unifies forecasting and portfolio selection within a single learning framework. Unlike traditional methods that treat return prediction and portfolio optimization as separate tasks, DINN merges them via three key components. First, an \emph{input embedding process} captures market dynamics and semantic relationships using LLM-based representations, ensuring that both numeric time series and textual context inform the model. Second, a \emph{cross-attention mechanism} fuses these diverse inputs into coherent return forecasts, allowing interactions between multiple data modalities. Finally, a \emph{differentiable optimization layer} uses these forecasts to produce optimal portfolio weights, enabling the model to refine both predictive accuracy and decision quality simultaneously.  An overview of the DINN architecture is illustrated in \Cref{fig:model}. By jointly training all components, DINN directly aligns return predictions with end-to-end portfolio performance.

\subsection{Preliminaries}
Throughout this paper, let $N \in \mathbb{N}$ denote the number of risky assets in the portfolio. We consider a discrete-time financial market with a finite horizon $ T \in \mathbb{N} $. Let $\{r_{t}\}_{t=1}^{T}$ be a sequence of asset excess returns, where $r_{t} \in \mathbb{R}^{N}$ and $r_{t,i}$ is the excess return of asset $i$ at time $t$. Let $r_{t,i} = \frac{P_{t,i} - P_{t-1,i}}{P_{t-1,i}} - r_{f}$, where $P_{t,i}$ denotes the price of asset $i$ at time $t$ and $r_{f}$ is the risk-free rate. We assume $r_f$ is a known, time-invariant constant. Define $w_{t} \in \mathbb{R}^{N}$ as the portfolio weight vector at time $t$. Let $\mathcal{W} \subseteq \mathbb{R}^{N}$ be the feasible set of portfolio weights, for example $\mathcal{W} = \{ w \in \mathbb{R}^{N}: w_i \geq 0,\ \sum_{i=1}^{N} w_i = 1 \}$. For a given lookback length $ L \in \mathbb{N} $, consider historical returns and macroeconomic variables over the period $\{t-L, \ldots, t-1\}$: 

\begin{equation} r_{t-L: t-1}=\left(r_{t-L}, \ldots, r_{t-1}\right) \in \mathbb{R}^{L \times N},
            \quad x_{t-L: t-1}=\left(x_{t-L}, \ldots, x_{t-1}\right) \in \mathbb{R}^{L \times M}
\end{equation} where $x_{t} \in \mathbb{R}^{M}$ encapsulates $M$ macroeconomic features observed at time $t$.

We consider a forecasting model $ f_{\theta} $ parameterized by $\theta$. This model, given historical data and macroeconomic features, produces predicted returns $\hat{r}_{t+1:t+H} = (\hat{r}_{t+1}, \hat{r}_{t+2}, \ldots, \hat{r}_{t+H})$ but also of the corresponding predicted portfolio weights ${\hat{w}}_{t+1:t+H} = ({\hat{w}}_{t+1}, {\hat{w}}_{t+2}, \ldots, {w}_{t+H})$ over a forecast horizon $ H \in \mathbb{N} $. Formally, we have: 
\begin{equation} 
{\hat{r}}_{t+1: t+H}=f_{\theta}\left(r_{t-L: t-1}, x_{t-L: t-1}\right) 
\end{equation}
where $\widehat{r}_{t+1:t+H} = \bigl(\widehat{r}_{t+1},\,\ldots,\,\widehat{r}_{t+H}\bigr)\in \mathbb{R}^{H\times N}$. The vector $\widehat{r}_{t+h}\in\mathbb{R}^{N}$ thus represents the \emph{predicted} excess returns for the $N$ assets at time $t+h$. 


Once $\hat{r}_{t+1 : t+H}$ is obtained, the corresponding portfolio weights $\hat{w}_{t+1 : t+H} 
= \bigl(\hat{w}_{t+1}, \ldots, \hat{w}_{t+H}\bigr)$ are determined by solving a suitable optimization problem that incorporates risk-return trade-offs over the forecast horizon $H$. We defer the precise formulation to Section~3.3.3. The predicted returns $\hat{r}_{t+h}$ act as inputs to a differentiable optimization layer that selects an \emph{optimal} allocation $\hat{w}_{t+h}$ to balance risk and reward under model predictions.

If we hypothetically had complete knowledge of the future, i.e.\ the ``true'' future returns $r_{t+H}^{\star}$, true expected returns $\mu_{t+H}^{\star}$, and covariance $\Sigma_{t+H}^{\star}$, we could compute the \emph{ex-post} optimal portfolio weights $w_{t+H}^{\star}$ by substituting the actual (rather than predicted) parameters into the same portfolio optimization problem. Formally:
\begin{equation}
    w_{t+H}^{\star} 
    = \arg\min_{w \in \mathcal{W}}
    \Bigl[\lambda\,\bigl\|L_{t+H}^{\star}\,w \bigr\|_2 
    \;-\; (\mu_{t+H}^{\star})^{\top} w 
    \Bigr] 
    \quad \text{where} \quad
    \Sigma_{t+H}^{\star} 
    = L_{t+H}^{\star}\,\bigl(L_{t+H}^{\star}\bigr)^{\top}.
\end{equation}

The difference between the performance of $\hat{w}_{t+H}$ (obtained via predicted returns) and $w_{t+H}^{\star}$ (with full foresight) will later be used to evaluate the ``decision quality'' of the forecasting pipeline. Although we distinguish between predicted returns $\hat{r}_{t+1:t+H}$ and the corresponding weights $\hat{w}_{t+1:t+H}$ for notational clarity, the DINN framework integrates these components into a unified, end-to-end pipeline. That is, the forecast of $\hat{r}_{t+1:t+H}$ directly informs the subsequent portfolio choice, and the model is trained with awareness that its predictions will drive the ultimate decision.


\subsection{Input embeddings}
Our input embedding process is designed to systematically incorporate temporal patterns, asset interactions, and textual context before generating forecasts. First, we \emph{normalize time series data} to stabilize training and ensure comparability across assets. Next, \emph{kernel-based trend-residual decompositions} separate persistent market trends from shorter-term fluctuations, highlighting both low-frequency and high-frequency signals. Finally, \emph{LLM-enhanced semantic embeddings} integrate sector-level yields and pairwise asset relationships into the model, thereby capturing broader economic and inter-asset context. These structured embeddings may provide a strong foundation for subsequent attention-based modeling and decision-focused optimization.


\subsubsection{Time-series normalization and decomposition} We begin by transforming the raw input data into a structured representation well-suited for accurate forecasting and decision-focused optimization. Let $\{r_{t}\}_{t=1}^{T}$ be a sequence of excess returns for $N$ assets, where $r_{t} \in \mathbb{R}^{N}$. To ensure numerical stability and promote effective learning, we first normalize the historical returns. For each asset $i \in \{1, \ldots, N \}$ over a lookback window of length $L$, define the sample mean $\mu_i$, and standard deviation $\sigma_i$ as $\mu_{t, i} = \frac{1}{L}\sum_{k=t-L}^{t-1}r_{k,i}$, $\sigma_{t, i} = \sqrt{\frac{1}{L}\sum_{k=t-L}^{t-1}(r_{k,i}-\mu_{t,i})^{2}+\epsilon}$, respectively. Here $\epsilon>0$ is a small constant to avoid division by zero. And then, we can get the normalized returns (i.e., $r_{t,i}^{\prime} = \frac{r_{t,i}-\mu_{t,i}}{\sigma_{t,i}}$). This normalization step\citep{kim2021reversible} ensures that differences among assets are measured relative to their historical scales, improving training stability and preventing certain assets from dominating the optimization process solely due to larger raw magnitudes.

Next, we apply a multi-scale decomposition \citep{wu2021autoformer, zhou2022fedformer} to the normalized returns to capture both persistent trends and transient fluctuations. Let $\{k_{j}\}_{j=1}^{J}$ be a collection of kernel sizes. For each $j$, we can define as $\tau_{t,i}^{(j)} = \frac{1}{k_j}\sum_{\ell=t-k_j}^{t-1}r_{\ell, i}^{\prime}$, $\rho_{t,i }^{(j)} = r_{t,i}^{\prime}-\tau_{t,i}^{(j)}$. By aggregating across all scales, we can obtain 
\begin{equation}
    \tau_{t,i} := \frac{1}{J}\sum_{j=1}^{J}\tau_{t,i}^{(j)}, \quad \rho_{t,i} := \frac{1}{J}\sum_{j=1}^{J}\rho_{t,i}^{(j)}
\end{equation}
This approach allows the model to focus separately on the long-term market trend (captured by $\tau_t$) and short-term dynamics (captured by $\rho_t$), where $\rho_t$ represents the remaining variations after extracting the trend component, potentially enhancing forecasting accuracy and stability.


\subsubsection{LLM-enhanced semantic embeddings} While normalized and decomposed returns offer valuable insights into market structures, their representational capacity can be significantly enriched by incorporating Large Language Model (LLM)-based embeddings \citep{zhou2023onefitsall, jin2023time, cao2024tempo}. To achieve this, we integrate two distinct types of LLM-based embeddings: one capturing inter-asset relationships, and another encoding macroeconomic information.


\textbf{Inter-asset embeddings:}  Consider a set of assets indexed by $ i \in \{1,\ldots,N\} $, each mapped to a sector $ S(i) $ drawn from a finite set $\mathcal{S}$. Using large language model (LLM)-based textual descriptions, we establish a mapping from each asset to its corresponding sector. Once this mapping is determined, we construct sector-level returns over a historical lookback period to complement asset-level historical returns.

More specifically, let $ L \in \mathbb{N} $ be the lookback length, and consider the historical returns $\{r_{t,i}\}_{t=t-L}^{t-1}$ for each asset $ i $. The sector-level yield at time $ u \in \{t-L,\ldots,t-1\} $ for a sector $ s \in \mathcal{S} $ is defined as:
\begin{equation}
    r_{u,s}^{\text{sector}} = \frac{1}{|\mathcal{A}(s)|} \sum_{i \in \mathcal{A}(s)} r_{u,i}    
\end{equation}

where $\mathcal{A}(s) = \{ i \in \{1,\ldots,N\} : S(i)=s \}$. This produces, for each sector, a time series $\{r_{u,s}^{\text{sector}}\}_{u=t-L}^{t-1}$ that may reveal common patterns, systemic shifts, or sectoral performance trends during the lookback window. 

Next, to capture direct relationships among individual assets, for each pair $(i,j)$ with $i \neq j$, we measure relative historical performance by counting how frequently one asset outperforms the other:  
\begin{equation}
    \text{Count}_{\text{stock}}(i,j) 
    = \Bigl|\bigl\{\, u \in [t-L,t-1] \colon r_{u,i} > r_{u,j}\bigr\}\Bigr|.
    \end{equation}

Similarly, we define a sector-level outperformance count to capture how often the sector of asset $i$ outperforms the sector of asset $j$:  
\begin{equation}
    \text{Count}_{\text{sector}}(i,j)
    = \Bigl|\bigl\{\, u \in [t-L,t-1] \colon r_{u,S(i)}^{\text{sector}} > r_{u,S(j)}^{\text{sector}}\bigr\}\Bigr|.    
\end{equation}

To encode these pairwise relationships into a form suitable for LLM-based embeddings, we generate textual prompts that synthesize the computed statistics. Let $p_{i,j}$ be a prompt-generating function that takes as input the historical returns $\{r_{t-L:t-1,i}, r_{t-L:t-1,j}\}$, sector assignments $(S(i), S(j))$, sector-level yields $\{r_{u,S(i)}^{\text{sector}}\}_{u=t-L}^{t-1}$, $\{r_{u,S(j)}^{\text{sector}}\}_{u=t-L}^{t-1}$, and the pairwise performance statistics $\text{Count}_{\text{stock}}(i,j)$ and $\text{Count}_{\text{sector}}(i,j)$. This function produces a textual prompt describing the relative performance and sectoral context of the two assets.

Collecting such prompts for all pairs $(i,j)$ with $i \neq j$ yields:
\begin{equation}
        \mathcal{P}_{\text{Stocks}} 
    = \bigl\{\, p_{i,j}\bigl([\text{Count}_{\text{stock}}(i,j),\, \text{Count}_{\text{sector}}(i,j)]\bigr) 
      : i \neq j \bigr\},
\end{equation}
where $[\text{a},\text{b}]$ denotes the concatenation of inputs into a single composite prompt for $p_{i,j}$. The prompt-generation function $p_{i,j}$ is a function that maps $\mathcal{T}$ to the space of text descriptions.

Each prompt in $\mathcal{P}_{\text{Stocks}}$ is mapped to a token-level representation via the LLM embedding function $g_{\phi}(\cdot)$. We then stack or concatenate these token embeddings across all prompts, yielding
\begin{equation}
 E_{\text{stocks}} = \bigl\{g_{\phi}(p)\bigr\}_{p \in \mathcal{P}_{\text{Stocks}}} 
     \in \mathbb{R}^{M_{\text{stocks}} \times d_{\text{LLM}}},
\end{equation}
where $M_{\text{stocks}}$ represents the total token count across all stock-related prompts. This embedding $E_{\text{stocks}}$ encodes both asset-level relationships, drawn from pairwise performance statistics, and sector-level relationships, informed by aggregated sector yields and asset-to-sector mappings.

\textbf{Macroeconomic embeddings:} While the above embeddings capture asset-level interactions and sectoral dynamics, they do not fully account for the broader macroeconomic environment. Macroeconomic factors often shape market conditions, influencing correlations among assets and risk-return profiles. However, macroeconomic indicators are frequently observed at irregular intervals and may not align with the regular sampling of financial returns. Directly integrating these irregular observations can pose significant technical and modeling challenges.
To address this, we map macroeconomic data into textual descriptions that summarize their key characteristics. Let $x_{t} \in \mathbb{R}^{M}$ denote a vector of $M$ macroeconomic variables observed at time $t$. Since not all indicators are observed at every time point, let $\mathcal{T}_{m}=\{t_{1}^{(m)}, t_{2}^{(m)},\ldots,t_{|\mathcal{T}_{m}|}^{(m)}\}$ be the set of observation times for the $m$-th variable.

Following \citep{jin2023time}, we extend this approach to handle irregularly sampled variables explicitly. Define a set of transformations $\Xi=\{\xi_{\text{mean}},\xi_{\text{var}},\xi_{\text{autocorr}},\xi_{\text{pattern}}\}$, each capable of extracting salient features from the irregularly sampled observations $\{x_{t,m} : t \in \mathcal{T}_{m}\}$: 
\begin{equation}
    \Xi(m)=\{\xi_{\text{mean}}(x_{\cdot,m}),\,\xi_{\text{var}}(x_{\cdot,m}),\,\xi_{\text{autocorr}}(x_{\cdot,m}),\,\xi_{\text{pattern}}(x_{\cdot,m})\}
\end{equation}
where $x_{\cdot,m}$ denotes all observed values of the $m$-th macroeconomic variable. Each $\xi_{\cdot}$ operator is defined to accommodate irregular time intervals, ensuring accurate representation of the underlying statistical properties. An illustration of this prompt-generation and embedding process for macroeconomic features is shown in \Cref{fig:prompt}.

\begin{figure}[h!] %!htbp
% \small{
  \centering
  \includegraphics[width=\linewidth]{Figures/prompt_example_update.pdf}%}
   \captionsetup{font=footnotesize}
   \caption{Illustration of LLM-based prompt generation from pairwise outperformance statistics and macroeconomic summaries. For each asset pair, relative performance and sector-level yields are synthesized into textual prompts that capture inter-asset relationships, while similarly constructed macro-level prompts summarize irregularly observed economic indicators. These textual prompts are embedded by the LLM and subsequently integrated, via the cross-attention mechanism, into the DINN architecture.}
  \label{fig:prompt}
\end{figure}


Now, for each variable $m$, let $q_{m}$ be a prompt-generating function $q_{m}: \left(\{x_{t,m}\}_{t \in \mathcal{T}_{m}},\mathcal{V}(m)\right) \to \mathcal{T}$ where $\mathcal{V}(m)$ denotes any auxiliary metadata for variable $m$, and $\mathcal{T}$ is the space of textual descriptions. The function $q_{m}$ synthesizes the extracted statistics $\Xi(m)$ and metadata $\mathcal{V}(m)$ into a coherent textual summary. This textual prompt could, for example, note that a given macroeconomic variable has been trending upward, showing seasonal patterns or strong autocorrelation. The function $q_{m}$ synthesizes the extracted statistics $\Xi(m)$ and metadata $\mathcal{V}(m)$ into a coherent textual summary. This textual prompt could, for example, note that a given macroeconomic variable has been trending upward, showing seasonal patterns or strong autocorrelation. Collecting these prompts across all $M$ macroeconomic variables:
\begin{equation} 
    \mathcal{P}_{\text{Macro}} = \{q_{m}(\{x_{t,m}\}_{t\in \mathcal{T}_{m}}, \mathcal{V}(m)) : m=1,\ldots,M \}
\end{equation}

Let $g_{\phi}(\cdot)$ be the same pretrained LLM embedding function used for the inter-asset relationship embeddings. Applying it to each prompt in $\mathcal{P}_{\text{Macro}}$ yields a sequence of token-level representations, which we then stack to form

\begin{equation}
    \mathbf{E}_{\text{macro}} 
    = \bigl\{\,g_{\phi}(p)\bigr\}_{p \in \mathcal{P}_{\text{Macro}}}
    \;\in\;\mathbb{R}^{M_{\text{macro}} \times d_{\text{LLM}}},    
\end{equation}

where $M_{\text{macro}}$ denotes the total token count across all macro prompts. The resulting embedding, $\mathbf{E}_{\text{macro}}$, captures broader economic context complementary to the asset-level embeddings. By reflecting trends, volatility, and structural patterns of macroeconomic variables through natural-language prompts, it enriches the overall representational scope of the model. Unlike previous methods relying solely on return-based factor structures extracted from asset movements \citep{zhang2021universal, giglio2022factor, chen2024deep}, our approach integrates macroeconomic context through semantic embeddings grounded in LLMs.

\subsection{Decision-informed neural network} In this section, we present our neural network that integrates multi-modal information for portfolio optimization. The architecture consists of four key components: (1) a cross-attention mechanism that fuses temporal patterns with LLM-derived semantic embeddings, (2) a pretrained large language model for return forecasts, (3) a differentiable optimization layer that converts predictions into portfolio weights, and (4) a hybrid training objective combining forecasting and decision-focused losses. 

\subsubsection{Efficient Dual-Modality Integration via Prob-Sparse Cross-Attention} Given the decomposed normalized returns and LLM-based embeddings, we employ a prob-sparse cross-attention mechanism \citep{informer_2021} to integrate temporal and semantic information efficiently. In a naive full attention framework \citep{waswani2017attention}, the computational cost scales proportionally to the product of query and key lengths in the simplest case), which becomes prohibitively large for long sequences of textual embeddings or when $N$ and $M$ grow significantly. By contrast, prob‐sparse attention uses a sampling‐based approximation that retains only the most relevant keys for each query. Specifically, for each query, it selects a subset of key positions whose dot‐products are likely to dominate the attention distribution, thereby reducing the effective number of terms in the softmax normalization. This approach substantially lowers the computational complexity under common parameter choices), while preserving the representational capacity and accuracy of attention‐based models.

We employ prob‐sparse attention for two main reasons. First, it alleviates computational and memory burdens that arise from large collections of textual or macroeconomic embeddings, ensuring scalability for real‐world financial datasets with many assets and extended textual descriptions. Second, this approximation focuses model capacity on salient interactions, often leading to improved efficiency during training without sacrificing forecast fidelity. 

Let $\mathbf{T}_{t} \in \mathbb{R}^{L \times N}$ and $\mathbf{R}_{t} \in \mathbb{R}^{L \times N}$ denote the trend and residual components respectively, where $ \mathbf{T}_{t} = [\tau_{t-L+1},\tau_{t-L+2},\ldots,\tau_{t-1}]^\top$ and $ \mathbf{R}_{t} = [\rho_{t-L+1},\rho_{t-L+2},\ldots,\rho_{t-1}]^\top$. The LLM-based semantic embeddings are represented as $\mathbf{E}_{\text{stocks}} \in \mathbb{R}^{M_{\text{stocks}} \times d_{\text{LLM}}}$ and $\mathbf{E}_{\text{macro}} \in \mathbb{R}^{M_{\text{macro}} \times d_{\text{LLM}}}$, where $d_{\text{LLM}}$ denotes the embedding dimension, and $M_{\text{stocks}}, M_{\text{macro}}$ represent the respective sequence lengths of the textual embeddings. We define a cross-attention operation $\text{CrossAttn}(\mathbf{X}, \mathbf{Y})$ that maps temporal patterns $\mathbf{X} \in \mathbb{R}^{L \times N}$ and textual embeddings $\mathbf{Y} \in \mathbb{R}^{M \times d_{\text{LLM}}}$ into an integrated representation in $\mathbb{R}^{N \times d_{\text{LLM}}}$. First, we transpose the temporal input to $\mathbf{X}^\prime = \mathbf{X}^\top \in \mathbb{R}^{N \times L}$ to align the asset dimension with the attention mechanism. Next, we compute query, key, and value representations through learnable linear transformations:

\begin{equation}
    \mathbf{Q} = \mathbf{X}^\prime \mathbf{W}^Q, \quad \mathbf{K} = \mathbf{Y} \mathbf{W}^K, \quad \mathbf{V} = \mathbf{Y} \mathbf{W}^V,
\end{equation}

where $\mathbf{W}^Q, \mathbf{W}^K, \mathbf{W}^V \in \mathbb{R}^{d_{\text{LLM}} \times d_{\text{LLM}}}$ are learnable parameters. To enhance representational capacity, we employ multi-head attention with $B$ heads, each of dimension $d_b$ such that $B \times d_b = d_{\text{LLM}}$. The matrices $\mathbf{Q}, \mathbf{K}, \mathbf{V}$ are split across heads:

\begin{equation}
    \mathbf{Q} \to [\mathbf{Q}_1,\ldots,\mathbf{Q}_B], \quad \mathbf{K} \to [\mathbf{K}_1,\ldots,\mathbf{K}_B], \quad \mathbf{V} \to [\mathbf{V}_1,\ldots,\mathbf{V}_B],
\end{equation}

where $\mathbf{Q}_b \in \mathbb{R}^{N \times d_b}$ and $\mathbf{K}_b, \mathbf{V}_b \in \mathbb{R}^{M \times d_b}$ for each head $b \in \{1,\ldots,B\}$.

Following the prob-sparse attention mechanism \citep{informer_2021}, we compute a sparse approximation of the attention weights. Let $c>0$ be a constant and define $U_b = c\lceil \log M \rceil$ as the number of sampled key positions. For each query position $i \in \{1,\ldots,N\}$, we sample a subset $\mathcal{S}_b(i) \subseteq \{1,\ldots,M\}$ of size $U_b$. The attention weights for head $b$ are:
\begin{equation}
    \alpha_{b,i,j} = 
    \begin{cases}
        \frac{\exp\left(\frac{(\mathbf{Q}_b)_{i,:}(\mathbf{K}_b)_{j,:}^\top}{\sqrt{d_b}}\right)}{\sum_{j' \in \mathcal{S}_b(i)} \exp\left(\frac{(\mathbf{Q}_b)_{i,:}(\mathbf{K}_b)_{j',:}^\top}{\sqrt{d_b}}\right)} & \text{if } j \in \mathcal{S}_b(i), \\
        0 & \text{otherwise}.
    \end{cases}
\end{equation}

So, the output for each head is computed as:
\begin{equation}
    (\mathbf{Z}_b)_{i,:} = \sum_{j \in \mathcal{S}_b(i)} \alpha_{b,i,j} (\mathbf{V}_b)_{j,:},
\end{equation}

and the final output is obtained by concatenating across heads and applying a linear projection:

\begin{equation}
    \mathbf{Z} = [\mathbf{Z}_1;\ldots;\mathbf{Z}_B]\mathbf{W}^O \in \mathbb{R}^{N \times d_{\text{LLM}}},
\end{equation}

where $\mathbf{W}^O \in \mathbb{R}^{(B d_b) \times d_{\text{LLM}}}$ is a learnable parameter matrix. Then, we apply this cross-attention mechanism separately to integrate market-level and stock-specific information: 
\begin{equation}
\begin{aligned}
    \mathbf{C}_{\text{market}} &= \text{CrossAttn}(\mathbf{T}_t, \mathbf{E}_{\text{macro}}) \in \mathbb{R}^{N \times d_{\text{LLM}}}, \\
    \mathbf{C}_{\text{stock}} &= \text{CrossAttn}(\mathbf{R}_t, \mathbf{E}_{\text{stocks}}) \in \mathbb{R}^{N \times d_{\text{LLM}}}.
\end{aligned}
\end{equation}

The resulting representations $\mathbf{C}_{\text{market}}$ and $\mathbf{C}_{\text{stock}}$ capture the alignment between temporal patterns and semantic embeddings at both market and individual stock levels. This dual representation in a common $d_{\text{LLM}}$-dimensional space can facilitates the subsequent joint modeling of returns and portfolio optimization.

\subsubsection{Pretrained large language model for prediction} With the integrated representations from the cross-attention mechanism, we leverage a pretrained large language model to generate return forecasts. Let $g_{\phi}: \mathbb{R}^{N \times d_{\text{LLM}}} \to \mathbb{R}^{N \times d_{\text{LLM}}}$ be the pretrained LLM with frozen parameters $\phi$. It serves as a fixed contextual encoder that maps integrated embeddings into a more semantically enriched space.
Given $\mathbf{C}_{\text{market}}, \mathbf{C}_{\text{stock}} \in \mathbb{R}^{N \times d_{\text{LLM}}}$, we process them through the LLM:
\begin{equation}
\mathbf{Z}_{\text{market}} = g_{\phi}(\mathbf{C}_{\text{market}}), \quad
\mathbf{Z}_{\text{stock}} = g_{\phi}(\mathbf{C}_{\text{stock}})
\end{equation}
where $\mathbf{Z}_{\text{market}}, \mathbf{Z}_{\text{stock}} \in \mathbb{R}^{N \times d_{\text{LLM}}}$. The LLM refines these embeddings by capturing higher-order dependencies among assets through its attention mechanisms while preserving the semantic information encoded in the original representations.

To combine the market-level and stock-specific information, we employ an additive fusion $\mathbf{Z} = \mathbf{Z}_{\text{market}} + \mathbf{Z}_{\text{stock}} \in \mathbb{R}^{N \times d_{\text{LLM}}}$, where the addition is performed element-wise. This operation assumes both embeddings reside in a common semantic space and that their contributions to the final representation are complementary.

To generate normalized return forecasts over the horizon $H$, we project the fused embeddings through a learned linear transformation $\hat{r}^{\prime}_{t+1:t+H} = (\mathbf{Z} \mathbf{W}^{F})^{\top}$, where $\mathbf{W}^{F} \in \mathbb{R}^{d_{\text{LLM}} \times H}$ is a trainable weight matrix and $\hat{r}^{\prime}_{t+1:t+H} \in \mathbb{R}^{H \times N}$. To recover the returns in their original scale, we apply the inverse of the normalization transformation introduced in Section 3.2.1. For each asset $i$ and horizon $h$, we denormalize the predictions using the historical statistics:
\begin{equation}
\hat{r}_{t+h,i} = \hat{r}^{\prime}_{t+h,i} \sigma_{t,i} + \mu_{t,i}
\end{equation}
where $\mu_{t,i}$ and $\sigma_{t,i}$ are the sample mean and standard deviation computed over the lookback window $[t-L, t-1]$ as defined previously.

The final return predictions can be organized into a matrix $\hat{r}_{t+1:t+H} = [\hat{r}_{t+1}, \hat{r}_{t+2}, \ldots, \hat{r}_{t+H}] \in \mathbb{R}^{H \times N}$, where each $\hat{r}_{t+h} \in \mathbb{R}^{N}$ represents the predicted returns across all assets at time $t+h$. 

While employing the latest pretrained LLMs can significantly boost predictive performance, it also raises a critical concern of \emph{data leakage} in empirical evaluations. Because some LLMs (e.g., GPT-4o \citep{achiam2023gpt}, LLAMA \citep{dubey2024llama}) were trained on vast text corpora---potentially including financial data, news reports, or research materials overlapping with one’s test set---there is a nontrivial risk that information from the true “future” may already reside within the LLM’s parameters. Consequently, evaluating forecasts on a test period that the LLM might have indirectly “seen” during pretraining can yield overly optimistic results. Therefore, we used the GPT-2, which is a relatively old model with sufficient representation power, as the default LLM model to avoid the issue of data leakage. 


\subsubsection{Optimization layer} \label{optim_layer} The optimization layer converts predicted returns into optimal portfolio weights by solving a convex optimization problem that balances expected returns and portfolio risk. Given predicted returns $\hat{r}_{t+1:t+H} \in \mathbb{R}^{H \times N}$ and historical returns $r_{t-K:t-1}^{\star} \in \mathbb{R}^{K \times N}$, we estimate covariance matrices $\hat{\Sigma}_{t+h}$ by combining historical and predicted return as $\hat{\Sigma}_{t+h} = \text{Cov}\left( r_{t-K:t-1}^{\star} \cup \hat{r}_{t+1:t+h} \right)$. In this study, we use the past three months of historical returns for stable covariance estimation. Assuming $\hat{\Sigma}_{t+h}$ is positive definite, we perform a Cholesky decomposition $\hat{\Sigma}_{t+h} = \hat{L}_{t+h}\hat{L}_{t+h}^{\top}$. Let $\lambda>0$ be the risk-aversion parameter. For each time step $t+h$, we solve:

\begin{equation}
\begin{aligned}
\min_{w_{t+h}} \quad & \lambda s_{t+h}^2 - \hat{\mu}_{t+h}^{\top} w_{t+h} \\
\text{s.t.} \quad & \|\hat{L}_{t+h} w_{t+h}\|_2 \leq s_{t+h}, \\
                      & s_{t+h} \geq 0, \\
                      & \sum_{i=1}^{N} w_{t+h,i} = 1, \\
                      & 0 \leq w_{t+h,i} \leq 1 \quad \forall i \in \{1, \ldots, N\}.
\end{aligned}
\end{equation}

Here, $s_{t+h}$ represents the portfolio volatility, and the full-investment, long-only constraints ensure that $\sum_i w_{t+h,i} = 1$ with $w_{t+h,i} \ge 0$. This second-order cone formulation is equivalent to solving a mean–variance trade-off problem, where $\lambda$ modulates the level of risk-aversion, and $\hat{\mu}_{t+h}$ encodes the expected return estimates.  Solving this second-order cone optimization problem for each $h$ yields:
\begin{equation}
    \hat{w}_{t+1:t+H} = \bigl(\hat{w}_{t+1}, \hat{w}_{t+2}, \ldots, \hat{w}_{t+H}\bigr)
\end{equation}


\subsubsection{Training} Training aims to align the model’s parameters so that the predicted returns and the resulting decision-making process closely approximate their true counterparts. To achieve this, we combine a forecasting loss and a decision-focused loss into a single objective function. Let $\hat{r}_{t:t+H}$ be the predicted returns over the horizon $H$, and $r_{t:t+H}$ be the corresponding actual returns. The first loss term, which we denote as the forecasting loss, is the mean squared error (MSE) computed over the forecast horizon:
\begin{equation}
 \mathcal{L}_{\mathrm{MSE}}=\frac{1}{NH} \sum_{h=1}^H\left\|\hat{r}_{t+h}-r_{t+h}\right\|_2^2   
\end{equation}
The decision-focused loss measures how prediction errors degrade portfolio quality. Consider optimal weights $w_{t+1:t+h}^{\star}$ obtained from actual returns and $\hat{w}_{t+1:t+h}$ from predicted returns. With $L_{t+h}^{\star}$ the Cholesky factor of the actual covariance $\Sigma_{t+h}^{\star}$, define:
\begin{equation}
    \begin{gathered}
J_{t+h}^{\star}=\lambda\left\|L_{t+h}^{\star} w_{t+h}^{\star}\right\|_2-\mu_{t+h}^{\star \top} w_{t+h}^{\star}, \\
\hat{J}_{t+h}=\lambda\left\|L_{t+h}^{\star} \hat{w}_{t+h}\right\|_2-\mu_{t+h}^{\star \top} \hat{w}_{t+h} 
\end{gathered}
\label{eq:13}
\end{equation}

Intuitively, these performance measures quantify how inaccuracies in predicted returns translate into suboptimal portfolio decisions. Unlike approaches such as those in \citep{costa2023distributionally}, which optimize for metrics like the Sharpe ratio, the proposed decision-focused loss directly measures the regret incurred by substituting predicted returns for actual ones. Consequently, $\Delta J_{t+h} = \hat{J}_{t+h}-J_{t+h}^{\star}$ reflects the additional cost induced by prediction errors on the portfolio’s true risk-return profile. Then the decision-focused loss is the average absolute regret as here:
\begin{equation}
     \mathcal{L}_{\mathrm{Decision}}=\frac{1}{NH} \sum_{h=1}^H|\Delta J_{t+h}|.
\end{equation}
where $\Delta J_{t+h}$ is the discrepancy between the performance of the predicted and true portfolios. 

Finally, we combine the two losses into a single training objective using a weighting parameter $\beta \in [0,1]$, which balances between predictive accuracy and decision robustness:
\begin{equation}
    \mathcal{L}_{\mathrm{loss}}=\beta \mathcal{L}_{\mathrm{MSE}}+(1-\beta) \mathcal{L}_{\mathrm{Decision}}
\end{equation}
By adjusting $\beta$, we can control the relative importance of minimizing forecast errors versus minimizing decision regret. We set $\beta$ = 0.4 as the default value in this study. 

\subsection{Gradient for optimization problem} Consider the decision-focused loss $\mathcal{L}_{\mathrm{Decision}}$, which measures how predictive inaccuracies translate into suboptimal portfolio choices. This loss depends on the model parameters $\theta$ through the predicted returns. Since the predicted returns determine $\hat{\mu}_{t+h}$ and $\hat{L}_{t+h}$, the optimal weights $\hat{w}_{t+h}$ obtained from the optimization layer also depend implicitly on $\theta$.

Define $\Delta J_{t+h} = \hat{J}_{t+h} - J_{t+h}^{\star}$, where $J_{t+h}^{\star} = \lambda \|L_{t+h}^{\star} w_{t+h}^{\star}\|_2 - \mu_{t+h}^{\star \top} w_{t+h}^{\star}$ is the benchmark performance using true returns and true covariance, and $\hat{J}_{t+h} = \lambda \|L_{t+h}^{\star} \hat{w}_{t+h}\|_2 - \mu_{t+h}^{\star \top} \hat{w}_{t+h}$ is the performance under predicted quantities and weights. Since $J_{t+h}^{\star}$ does not depend on $\theta$, its gradient is zero. Thus, the gradient of $\mathcal{L}_{\mathrm{Decision}}$ with respect to $\theta$ reduces to the gradient of $\hat{J}_{t+h}$.

Ignoring non-differentiability at zero for the absolute value and assuming a differentiable approximation if needed, the derivative of $\hat{J}_{t+h}$ with respect to $\hat{w}_{t+h}$ is

\begin{equation}
\begin{aligned}
\nabla_{\hat{w}_{t+h}}\hat{J}_{t+h} &= \nabla_{\hat{w}_{t+h}}\left(\lambda \|L_{t+h}^{\star}\hat{w}_{t+h}\|_2 - \mu_{t+h}^{\star \top}\hat{w}_{t+h}\right) \\
&= \nabla_{\hat{w}_{t+h}}\left(\lambda \|L_{t+h}^{\star}\hat{w}_{t+h}\|_2\right) 
- \nabla_{\hat{w}_{t+h}}\left(\mu_{t+h}^{\star \top}\hat{w}_{t+h}\right) \\
&= \lambda \nabla_{\hat{w}_{t+h}}\sqrt{(L_{t+h}^{\star}\hat{w}_{t+h})^{\top}(L_{t+h}^{\star}\hat{w}_{t+h})} 
- \mu_{t+h}^{\star} \\
&= \lambda \frac{L_{t+h}^{\star \top}(L_{t+h}^{\star}\hat{w}_{t+h})}{\sqrt{(L_{t+h}^{\star}\hat{w}_{t+h})^{\top}(L_{t+h}^{\star}\hat{w}_{t+h})}} 
- \mu_{t+h}^{\star} \\
&= \lambda \frac{L_{t+h}^{\star \top}(L_{t+h}^{\star}\hat{w}_{t+h})}{\|L_{t+h}^{\star}\hat{w}_{t+h}\|_2} - \mu_{t+h}^{\star}.
\end{aligned}
\end{equation}



This gradient provides the directional sensitivity of the performance measure $\hat{J}_{t+h}$ to changes in the predicted weights.

Because $\hat{w}_{t+h}$ solves a parametric optimization problem whose parameters $\hat{\mu}_{t+h}$ and $\hat{L}_{t+h}$ depend on $\theta$, the chain rule must be applied to propagate gradients through the optimization layer. Formally, let $\mathcal{L}_{\mathrm{Decision}}$ be defined as an average over the forecast horizon:

\begin{equation}
    \nabla_{\theta}\mathcal{L}_{\mathrm{Decision}} = \frac{1}{NH}\sum_{h=1}^{H} \left( \frac{\partial \mathcal{L}_{\mathrm{Decision}}}{\partial \hat{w}_{t+h}}\frac{\partial \hat{w}_{t+h}}{\partial \hat{\mu}_{t+h}}\frac{\partial \hat{\mu}_{t+h}}{\partial \theta} + \frac{\partial \mathcal{L}_{\mathrm{Decision}}}{\partial \hat{w}_{t+h}}\frac{\partial \hat{w}_{t+h}}{\partial \hat{L}_{t+h}}\frac{\partial \hat{L}_{t+h}}{\partial \theta}\right)
\end{equation}

Here, $\partial \hat{w}_{t+h}/\partial \hat{\mu}_{t+h}$ and $\partial \hat{w}_{t+h}/\partial \hat{L}_{t+h}$ quantify the sensitivities of the optimal weights to perturbations in predicted means and covariance factors, respectively. These can be derived via the implicit function theorem or through established results in parametric optimization. The terms $\partial \hat{\mu}_{t+h}/\partial \theta$ and $\partial \hat{L}_{t+h}/\partial \theta$ capture how the predictive model’s parameters $\theta$ affect the predicted inputs to the optimization layer.However, While computing the sensitivity terms $\partial \hat{w}_{t+h}/\partial \hat{\mu}_{t+h}$ and $\partial \hat{w}_{t+h}/\partial \hat{L}_{t+h}$ is computationally challenging due to the implicit nature of the optimization problem's solution, these derivatives provide valuable information about how estimation errors in predicted moments affect optimal portfolio weights. As demonstrated in Theorems 1 and Theorems 2, under appropriate regularity conditions, these sensitivities can be characterized using the implicit function theorem applied to the KKT conditions, enabling efficient gradient-based learning through the optimization layer.

\textbf{Theorem 1 (Sensitivity of optimal portfolio weights w.r.t. predicted returns)} Consider the following portfolio optimization problem at each time step $ t+h $ for $\{h = {1, \cdots, H}\}$:
\begin{equation}
\begin{aligned}
\min_{\hat{w}_{t+h}} \quad & \lambda s_{t+h}^{2} - \hat{\mu}_{t+h}^{\top} \hat{w}_{t+h} \\
\text{subject to} \quad & \|\hat{L}_{t+h} \hat{w}_{t+h}\|_2 = s_{t+h}, \\
& \sum_{i=1}^{N} \hat{w}_{t+h,i} = 1,
\end{aligned}
\label{eq:modified_problem}
\end{equation}

where $\lambda > 0$, $\hat{w}_{t+h} \in \mathbb{R}^N$ denotes the portfolio weights, $\hat{\mu}_{t+h} \in \mathbb{R}^N$ are the predicted returns, and $\hat{L}_{t+h} \in \mathbb{R}^{N \times N}$ is a lower-triangular Cholesky factor such that $\hat{\Sigma}_{t+h} = \hat{L}_{t+h}\hat{L}_{t+h}^{\top}$ is the covariance matrix of returns. Assume $\hat{\Sigma}_{t+h}$ is invertible.

Then the derivative of the optimal solution $\hat{w}_{t+h}$ with respect to the predicted returns $\hat{\mu}_{t+h}$ is given by:
\begin{equation}
    \frac{\partial \hat{w}_{t+h}}{\partial \hat{\mu}_{t+h}} = \hat{\Sigma}_{t+h}^{-1} \;-\; \frac{\hat{\Sigma}_{t+h}^{-1}\mathbf{1}\mathbf{1}^{\top}\hat{\Sigma}_{t+h}^{-1}}{\mathbf{1}^{\top}\hat{\Sigma}_{t+h}^{-1}\mathbf{1}},
\end{equation}
where $\mathbf{1}$ is an $N$-dimensional vector of ones.

\textbf{Proof: } Refer to Appendix A.1 for a detailed derivation, which follows from applying Lagrangian duality and differentiating the resulting Karush-Kuhn-Tucker (KKT) conditions with respect to $\hat{\mu}_{t+h}$.

%Consider the problem \Cref{eq:modified_problem}. Introducing Lagrange multipliers $\eta$ and $\gamma$ for the risk and budget constraints, respectively, the Lagrangian is here: 
%\begin{equation}
%    \mathcal{L}(w,s_{t+h},\eta,\gamma)=\lambda s_{t+h}^2 - \hat{\mu}_{t+h}^{\top} \hat{w}_{t+h} + \eta(\hat{w}_{t+h}^{\top}\hat{\Sigma}_{t+h} \hat{w}_{t+h} - s_{t+h}) + \gamma(\mathbf{1}^{\top} \hat{w}_{t+h} -1)
%\end{equation}
%Differentiating with respect to $s_{t+h}$ gives $2\lambda s_{t+h}-\eta =0 \implies \eta=2\lambda s_{t+h}.$ Differentiation with respect to $w$ then yields $-\hat{\mu}_{t+h} + 2\lambda \hat{\Sigma}_{t+h} \hat{w}_{t+h} + \gamma \mathbf{1}=0.$ Hence $\hat{\mu}_{t+h} = 2\lambda \hat{\Sigma}_{t+h} \hat{w}_{t+h} + \gamma \mathbf{1}$. Since $\mathbf{1}^{\top}w=1,$ we have $w = \tfrac{1}{2\lambda}\hat{\Sigma}_{t+h}^{-1}(\hat{\mu}_{t+h}-\gamma\mathbf{1}).$ Multiplying by $\mathbf{1}^{\top}$ and solving for $\gamma$ gives $\gamma = \tfrac{\mathbf{1}^{\top}\hat{\Sigma}_{t+h}^{-1}\hat{\mu}_{t+h}-2\lambda}{\mathbf{1}^{\top}\hat{\Sigma}_{t+h}^{-1}\mathbf{1}}.$  Substituting back into the expression for $w$ and setting $2\lambda=1$ (which does not affect the structure of the solution) yields
%\begin{equation}
%    w = \hat{\Sigma}_{t+h}^{-1}\hat{\mu}_{t+h}-\hat{\Sigma}_{t+h}^{-1}\frac{\mathbf{1}^{\top}\hat{\Sigma}_{t+h}^{-1}\hat{\mu}_{t+h}-1}{\mathbf{1}^{\top}\hat{\Sigma}_{t+h}^{-1}\mathbf{1}}\mathbf{1}
%\end{equation}
%Differentiating this with respect to $\hat{\mu}_{t+h}$ and simplifying leads to
%\begin{equation}
%    \frac{\partial \hat{w}_{t+h}}{\partial \hat{\mu}_{t+h}} = \hat{\Sigma}_{t+h}^{-1}-\frac{\hat{\Sigma}_{t+h}^{-1}\mathbf{1}\mathbf{1}^{\top}\hat{\Sigma}_{t+h}^{-1}}{\mathbf{1}^{\top}\hat{\Sigma}_{t+h}^{-1}\mathbf{1}},
%\end{equation}
%as claimed.


\textbf{Theorem 2 (Sensitivity of optimal portfolio weights w.r.t. cholesky factor)}
Under the same setting and assumptions as in Theorem 1, let
\begin{equation}
    p := \frac{\mathbf{1}^{\top}\hat{\Sigma}_{t+h}^{-1}\hat{\mu}_{t+h} - 1}{\mathbf{1}^{\top}\hat{\Sigma}_{t+h}^{-1}\mathbf{1}}
\end{equation}

Then the derivative of the optimal solution $\hat{w}_{t+h}$ with respect to the cholesky factor $\hat{L}_{t+h}$ is given by:
\begin{equation}
    \frac{\partial \hat{w}_{t+h}}{\partial \hat{L}_{t+h}} = -2\, \hat{\Sigma}_{t+h}^{-1}(\hat{\mu}_{t+h} - p\mathbf{1})\hat{\Sigma}_{t+h}^{-1}\hat{L}_{t+h} \;-\; 2\, \hat{\Sigma}_{t+h}^{-1}\left( \frac{\partial p}{\partial \hat{\Sigma}_{t+h}}\mathbf{1} \right)\hat{L}_{t+h},
\end{equation}

where $\frac{\partial p}{\partial \hat{\Sigma}_{t+h}} = \frac{- \hat{\Sigma}_{t+h}^{-1}\mathbf{1}\hat{\mu}_{t+h}^{\top}\hat{\Sigma}_{t+h}^{-1} z \;+\; (\mathbf{1}^{\top}\hat{\Sigma}_{t+h}^{-1}\hat{\mu}_{t+h} - 1)\hat{\Sigma}_{t+h}^{-1}\mathbf{1}\mathbf{1}^{\top}\hat{\Sigma}_{t+h}^{-1}}{z^{2}}
$ and $z = \mathbf{1}^{\top}\hat{\Sigma}_{t+h}^{-1}\mathbf{1}.$


\textbf{Proof: } Refer to Appendix A.1 for a detailed proof, which follows by applying the chain rule to the Markowitz optimization problem and carefully differentiating with respect to the Cholesky factor $\hat{L}_{t+h}$. These expressions provide explicit formulas for the sensitivities needed to efficiently implement gradient-based learning through the optimization layer, enabling a deeper understanding of how inaccuracies in predicted inputs influence optimal decision-making.

%Starting from the expression derived in Theorem 1 under the normalization $2\lambda=1$, the optimal portfolio weights can be written as  $\hat{w}_{t+h} = \hat{\Sigma}_{t+h}^{-1}\hat{\mu}_{t+h} - p\,\hat{\Sigma}_{t+h}^{-1}\mathbf{1}$, where  $p = \frac{\mathbf{1}^{\top}\hat{\Sigma}_{t+h}^{-1}\hat{\mu}_{t+h} - 1}{\mathbf{1}^{\top}\hat{\Sigma}_{t+h}^{-1}\mathbf{1}}$.  
%In this formulation, $\hat{\Sigma}_{t+h}^{-1}$ depends on $\hat{L}_{t+h}$ through the relation $\hat{\Sigma}_{t+h} = \hat{L}_{t+h}\hat{L}_{t+h}^{\top}$. Thus, the chain rule of differentiation implies that understanding $\partial \hat{w}_{t+h}/\partial \hat{\Sigma}_{t+h}$ allows recovery of $\partial \hat{w}_{t+h}/\partial \hat{L}_{t+h}$.

%Differentiating $\hat{w}_{t+h}$ with respect to $\hat{\Sigma}_{t+h}$ first requires considering the terms $\hat{\Sigma}_{t+h}^{-1}\hat{\mu}_{t+h}$ and $\hat{\Sigma}_{t+h}^{-1}\mathbf{1}$. From standard matrix calculus \citep{petersen2008matrix}, one has $\partial \hat{\Sigma}^{-1}/\partial \hat{\Sigma} = -\hat{\Sigma}^{-1}(\cdot)\hat{\Sigma}^{-1}$. Applying this to $\hat{\Sigma}_{t+h}^{-1}\hat{\mu}_{t+h}$ yields $\frac{\partial (\hat{\Sigma}_{t+h}^{-1}\hat{\mu}_{t+h})}{\partial \hat{\Sigma}_{t+h}} = -\hat{\Sigma}_{t+h}^{-1}\hat{\mu}_{t+h}\hat{\Sigma}_{t+h}^{-1}$.

%Similarly, the term involving $p$ is more involved since $p$ itself depends on $\hat{\Sigma}_{t+h}^{-1}$. Letting $g=\mathbf{1}^{\top}\hat{\Sigma}_{t+h}^{-1}\hat{\mu}_{t+h}$ and $z=\mathbf{1}^{\top}\hat{\Sigma}_{t+h}^{-1}\mathbf{1}$, one has $p=(g-1)/z$. Differentiating $g$ and $z$ with respect to $\hat{\Sigma}_{t+h}$ gives  
%\begin{equation}
%    \frac{\partial g}{\partial \hat{\Sigma}_{t+h}} = -\hat{\Sigma}_{t+h}^{-1}\mathbf{1}\hat{\mu}_{t+h}^{\top}\hat{\Sigma}_{t+h}^{-1}, \quad
%\frac{\partial z}{\partial \hat{\Sigma}_{t+h}} = -\hat{\Sigma}_{t+h}^{-1}\mathbf{1}\mathbf{1}^{\top}\hat{\Sigma}_{t+h}^{-1}.
%\end{equation}

%Applying the quotient rule to differentiate $p=(g-1)/z$ yields  
%\begin{equation}
%    \frac{\partial p}{\partial \hat{\Sigma}_{t+h}}
%= \frac{-\hat{\Sigma}_{t+h}^{-1}\mathbf{1}\hat{\mu}_{t+h}^{\top}\hat{\Sigma}_{t+h}^{-1}z + (g-%1)\hat{\Sigma}_{t+h}^{-1}\mathbf{1}\mathbf{1}^{\top}\hat{\Sigma}_{t+h}^{-1}}{z^2}
%\end{equation}

%Combining these results, the derivative of $p\,\hat{\Sigma}_{t+h}^{-1}\mathbf{1}$ with respect to $\hat{\Sigma}_{t+h}$ is  
%\begin{equation}
%    \frac{\partial (p\,\hat{\Sigma}_{t+h}^{-1}\mathbf{1})}{\partial \hat{\Sigma}_{t+h}}
%= \frac{\partial p}{\partial \hat{\Sigma}_{t+h}}\hat{\Sigma}_{t+h}^{-1}\mathbf{1} - p\,\hat{\Sigma}_{t+h}^{-1}\mathbf{1}\hat{\Sigma}_{t+h}^{-1}
%\end{equation}

%Subtracting this from $-\hat{\Sigma}_{t+h}^{-1}\hat{\mu}_{t+h}\hat{\Sigma}_{t+h}^{-1}$ and rearranging terms leads to  
%\begin{equation}
%    \frac{\partial \hat{w}_{t+h}}{\partial \hat{\Sigma}_{t+h}}
%= -\hat{\Sigma}_{t+h}^{-1}(\hat{\mu}_{t+h}-p\mathbf{1})\hat{\Sigma}_{t+h}^{-1} - \frac{\partial p}{\partial %\hat{\Sigma}_{t+h}}\hat{\Sigma}_{t+h}^{-1}\mathbf{1}
%\end{equation}

%ince $\hat{\Sigma}_{t+h} = \hat{L}_{t+h}\hat{L}_{t+h}^{\top}$, differentiating with respect to $\hat{L}_{t+h}$ involves applying the chain rule. Under appropriate vectorization, symmetry assumptions, the lower-triangular structure of $\hat{L}_{t+h}$, and considering only independent parameters, the derivative $\partial \hat{\Sigma}_{t+h}/\partial \hat{L}_{t+h}$ can be simplified to contribute a factor of $2\hat{L}_{t+h}$. Substituting back, the final result is  
%\begin{equation}
%\begin{aligned}
%\frac{\partial \hat{w}_{t+h}}{\partial \hat{L}_{t+h}} 
%&= \frac{\partial \hat{w}_{t+h}}{\partial \hat{\Sigma}_{t+h}}\frac{\partial \hat{\Sigma}_{t+h}}{\partial \hat{L}_{t+h}}, \\
%&= -2\,\hat{\Sigma}_{t+h}^{-1}(\hat{\mu}_{t+h}-p\mathbf{1})\hat{\Sigma}_{t+h}^{-1}\hat{L}_{t+h} 
%- 2\,\hat{\Sigma}_{t+h}^{-1}\left(\frac{\partial p}{\partial \hat{\Sigma}_{t+h}}\mathbf{1}\right)\hat{L}_{t+h}.
%\end{aligned}
%\end{equation}

