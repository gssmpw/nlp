This work adapts the \ac{MP} approach for the filtering problem to preserve the conditional distribution of interest $\pi'_{\boldsymbol{y}}$ \eqref{eq:filtering_problem_margin} after projection. Conditioning on the observed trajectory to the projected propensities results in another surrogate \ac{SRN} with the desired marginal conditional distributions. The result is summarized in the following theorem, which can be considered a natural extension of Theorem~\ref{th:MP} for the filtering problem.
 
\begin{theorem}[\acf{FMP} for \acp{SRN}]
    \label{th:FMP}
    Let 
    $\boldsymbol{Z} = \begin{bmatrix} \boldsymbol{X}' \\ \boldsymbol{X}'' \\ \boldsymbol{Y} \end{bmatrix}$ 
    be a non-explosive $d$-dimensional \ac{SRN} with the initial distribution $\mu$ and $\boldsymbol{Z}'(t) := \begin{bmatrix} \boldsymbol{X}'(t) \\ \boldsymbol{Y}(t)  \end{bmatrix} \in \mathbb{Z}_{\geq 0}^{d'} $. 
    The $d'$-dimensional stochastic process $\Tilde{\boldsymbol{Z}}'(t) = \begin{bmatrix} \Tilde{\boldsymbol{X}}'(t) \\ \Tilde{\boldsymbol{Y}}(t)  \end{bmatrix} $ is defined via independent Poisson processes $\Tilde{R}_1, \dots, \Tilde{R}_J$ as follows:
    \begin{equation}
        \label{eq:FMP_model}
        \Tilde{\boldsymbol{Z}}'(t) = \Tilde{\boldsymbol{Z}}'(0) + \sum_{j=1}^{J} \Tilde{R}_j \left( \int_0^t \Tilde{a}_j \left( \Tilde{\boldsymbol{Z}}'(s), s \right) \diff s \right) \boldsymbol{\nu}_{j}' , \quad t \in [0,T]
    \end{equation}
    with 
    \begin{equation}
    \label{eq:FMP_a_tilde_def}
        \Tilde{a}_j (\Tilde{\boldsymbol{z}}', t) := \Econdmu{ a_j(\boldsymbol{Z}(t)) }{ \boldsymbol{Z}'(t) = \Tilde{\boldsymbol{z}}', \boldsymbol{Y}(s) = \boldsymbol{y}(s) , s \leq t}
    \end{equation}
    and $\Tilde{\boldsymbol{Z}}'(0) \overset{d}{=} \boldsymbol{Z}'(0)$. Then, the distribution of $\Tilde{\boldsymbol{Z}}'(t)$ conditioned on $\left\{ \Tilde{\boldsymbol{Y}}(s) = \boldsymbol{y}(s), s \leq t \right\}$ is the same as the distribution of $\boldsymbol{Z}'(t)$ conditioned on $\left\{ \boldsymbol{Y}(s) = \boldsymbol{y}(s), s \leq t \right\}$ for any $t \in [0, T]$.
\end{theorem}

\begin{proof}
    The proof is given in Appendix~\ref{sec:FMP_proof}.
\end{proof}

Next, we define the \ac{FMP} filtering problem as follows:
\begin{equation}
    \label{eq:pi_tilde_def}
    \tilde{\pi}'_{\boldsymbol{y}} (\boldsymbol{x}', t) := \Probcondmu{\tilde{\boldsymbol{X}}'(t) = \boldsymbol{x}' }{ \tilde{\boldsymbol{Y}}(s) = \boldsymbol{y}(s), s \leq t } .
\end{equation}
Theorem~\ref{th:FMP} guarantees that $\tilde{\pi}'_{\boldsymbol{y}} = \pi'_{\boldsymbol{y}}$. In other words, the solution of the filtering problem for the \ac{FMP} process $\tilde{\boldsymbol{Z}}$ is the same as \eqref{eq:filtering_problem_margin}. 

Similar to the standard \ac{MP} approach from Section~\ref{sec:2_MP}, the challenge of \ac{FMP} is the need to estimate the projected propensities \eqref{eq:FMP_a_tilde_def} numerically. We can consider \eqref{eq:FMP_a_tilde_def} a filtering problem for process $\boldsymbol{Z}$; therefore, known methods can be applied to solve it. In this work, we use the \acf{PF} introduced in Section~\ref{subsubsec:PF} with a small sample size and extrapolate the functions similarly to the previously described \ac{MP} approach. Algorithm~\ref{alg:FMP_FFSP} provides the general scheme of the \ac{FMP} approach.

Ensuring the consistency of the estimation with the \ac{FMP} entails additional challenges because, compared to the standard approach, the \ac{PF} and not just the \ac{MC} is applied as in the previous section because the \ac{FMP} approach requires observations $\{ \boldsymbol{y}(s), s \leq t \}$ to estimate the projected propensities $\tilde{a}_j(t)$. In contrast, in the \ac{MP} approach, the propensities \eqref{eq:MP_a_bar_def} are independent of observations and can be estimated off-line.

\begin{algorithm}[H]
\caption{\ac{FMP} for the filtering problem}
\label{alg:FMP_FFSP}
\begin{algorithmic}[1]
    \Require Initial distribution $\pi(\cdot, 0)$ according to \eqref{eq:pi0_def}, observations: jump times $t_1, \dots, t_n$ and values $\boldsymbol{y}(t_1), \dots, \boldsymbol{y}(t_n)$, sample size $M$, truncated state space $\mathsf{X}'_N$ for $\Tilde{\boldsymbol{X}}'$
    \State Sample $\boldsymbol{V}_1(0), \dots, \boldsymbol{V}_M(0)$ according to $\pi(\cdot, 0)$, set $w_1(0) = \dots = w_M(0) = 1$
    \For{$k \in \{ 0 \dots n \}$}
        \State Simulate $\{ \boldsymbol{V}_i(t), w_i \}_{i=1}^{M}$ for $t \in [t_k, t_{k+1}]$ with the \ac{PF} \cite{Rathinam2021PFwithExactState} for the full-dimensional \ac{SRN} $\boldsymbol{Z}$ 
        \State Resample $\{\boldsymbol{V}_i(t_{k+1})\}_{i=1}^{M}$ according to weights $\{w_i(t_{k+1})\}_{i=1}^{M}$, set all $w_i(t_{k+1}) = 1$.
        \State Estimate $\{\Tilde{a}_j (\cdot, t) \}_{j=1}^{J'}$ for $t \in [t_k, t_{k+1}]$ with the \ac{PF} and extrapolation for the \ac{FMP}-\ac{SRN} $\Tilde{\boldsymbol{Z}}$ 
        \State Compute $\Tilde{\rho}_{\boldsymbol{y}}'(\cdot, t)$  for the \ac{FMP}-\ac{SRN} $\Tilde{\boldsymbol{Z}}$ for $t \in [t_k, t_{k+1})$ by applying \ac{FFSP} to \eqref{eq:filtering_equation_rho}
        \State Compute $\Tilde{\rho}_{\boldsymbol{y}}'(\cdot, t)$  for the \ac{FMP}-\ac{SRN} $\Tilde{\boldsymbol{Z}}$ for $t = t_{k+1}$ by applying \ac{FFSP} to \eqref{eq:filtering_equation_rho_jump}
        \State Compute $\Tilde{\pi}_{\boldsymbol{y}}'(\cdot, t)$ for $t \in [t_k, t_{k+1}]$ by normalizing  $\Tilde{\rho}_{\boldsymbol{y}}'(\cdot, t)$ according to  \cite{DAmbrosio2022FFSP}
    \EndFor
\end{algorithmic}
\end{algorithm}



The presented \ac{FMP} approach is a combination of two known filtering algorithms: the \ac{PF} and \ac{FFSP}. The \ac{FMP} algorithm  exploits the advantages of both. Instead of employing the \ac{PF} to  estimate the conditional distribution directly (according to \eqref{eq:PF_weighed_avg}), it estimates the \ac{FMP} propensities. This replacement of the estimated function for the \ac{PF} could lower the variance and allow much fewer particles to control the error compared to applying the \ac{PF} to the entire filtering problem, particularly when estimating rare events (e.g., the tails of the conditional distribution). For the \ac{FFSP}, the dimensionality of the state space is lowered, significantly reducing computational complexity compared to applying \ac{FFSP} to the full-dimensional filtering problem. Therefore, one can consider the presented \ac{FMP} algorithm as a variance reduction technique for the \ac{PF}. In this context, the propensities $\Tilde{a}_j$ are treated as auxiliary variables given by the expectations with additional conditioning on $\boldsymbol{Z}'(t)$, lowering the variance. 


\begin{remark}
\label{remark:FMP_PF_refining}
    After applying the \ac{PF} in Algorithm~\ref{alg:FMP_FFSP}, one can address the original filtering problem with sampled particles $\{ \boldsymbol{V}_i(t), w_i \}_{i=1}^{M}$ and stop the computation if the obtained accuracy is satisfactory. In this sense, constructing $\tilde{\boldsymbol{Z}}'$ and applying \ac{FFSP} are refining steps for the \ac{PF}. 
\end{remark}






\subsection{Error Analysis}
\label{subsec:FMP_error_analysis}

This section provides an error analysis of the \ac{FMP} approach (Algorithm~\ref{alg:FMP_FFSP}). This section relabels $\pi'_{\boldsymbol{y}}$ as $\pi$ to simplify the notation because all \acp{PMF} used in this section are conditioned on the same trajectory $\boldsymbol{y}$ and marginalized to the species corresponding to $\boldsymbol{X}'$. Moreover, let $\{ \Tilde{a}_j^M \}_{j=1}^{J'}$ be the \ac{PF} estimator of the \ac{FMP} propensities $\{ \Tilde{a}_j \}_{j=1}^{J'}$ based on $M$ particles and $\Tilde{\boldsymbol{Z}}'^M$ be the approximation of the \ac{FMP}-\ac{SRN} obtained by replacing the propensities $\Tilde{a}_j$ with the estimates $\Tilde{a}_j^M$. 

Algorithm~\ref{alg:FMP_FFSP} returns an approximation of $\pi$ based on the following input parameters: the number of particles $M$, truncated state space $\mathsf{X}'_N$ for the \ac{FFSP}, and time step  $\Delta t$ for the numerical \ac{ODE} solver. To investigate how these parameters affect the accuracy of the approximation, we introduce the following auxiliary filtering problems:
\begin{itemize}
    \item Let
        $\pi (\boldsymbol{x}', t) = \Probcondmu{\boldsymbol{X}'(t) = \boldsymbol{x}'}{ \boldsymbol{Y}(s) = \boldsymbol{y}(s), s \leq t }$ be the solution to the original marginal filtering problem \eqref{eq:filtering_problem_margin}.
    \item Let
        $\Tilde{\pi} (x, t) = \Probcondmu{\Tilde{\boldsymbol{X}}'(t) = \boldsymbol{x}'}{ \Tilde{\boldsymbol{Y}}(s) = \boldsymbol{y}(s), s \leq t }$ be the solution to the filtering  problem for the process $\Tilde{\boldsymbol{Z}}' = \begin{bmatrix} \Tilde{\boldsymbol{X}}' \\  \Tilde{\boldsymbol{Y}} \end{bmatrix}$ .
    \item Let
        $\Tilde{\pi}^{M} (x,t) =  \Probcondmu{\Tilde{\boldsymbol{X}}'^M(t) = \boldsymbol{x}'}{ \Tilde{\boldsymbol{Y}}^M(s) = \boldsymbol{y}(s), s \leq t }$ be the solution to the filtering  problem for the process $\Tilde{\boldsymbol{Z}}'^M = \begin{bmatrix} \Tilde{\boldsymbol{X}}'^M \\  \Tilde{\boldsymbol{Y}}^M \end{bmatrix}$ .
        \item Let 
        $\Tilde{\pi}^{M}_{FFSP} $ be the \ac{FFSP} approximation of $\Tilde{\pi}^{M}$ with the truncated state space $\mathsf{X}'_{N}$.
    \item Let 
        $\Tilde{\pi}^{M, \Delta t}_{FFSP} $ be the approximation of $\Tilde{\pi}^{M}_{FFSP}$ obtained as a numerical solution of the \ac{FFSP} system using discretization with the time step $\Delta t$.
\end{itemize}

Next, the total error is decomposed as follows:

\begin{align*}
    \abs{ \pi(\boldsymbol{x}',t) - \Tilde{\pi}^{M, \Delta t}_{FFSP}(\boldsymbol{x}',t)} &\leq \underbrace{\abs{\pi(\boldsymbol{x}',t) - \Tilde{\pi}(\boldsymbol{x}',t)}}_{\text{Model reduction error}} 
    + \underbrace{\abs{\Tilde{\pi}(\boldsymbol{x}',t) - \Tilde{\pi}^{M} (\boldsymbol{x}', t)}}_{\text{Projection error}} \\
    &+ \underbrace{\abs{\Tilde{\pi}^{M} (\boldsymbol{x}',t) - \Tilde{\pi}^{M}_{FFSP} (\boldsymbol{x}',t)}}_{\text{Truncation error}} \\
    &+ \underbrace{\abs{ \Tilde{\pi}^{M}_{FFSP} (\boldsymbol{x}',t) - \Tilde{\pi}^{M, \Delta t}_{FFSP} (\boldsymbol{x}',t)}}_{\text{\ac{ODE} solver error}} .
\end{align*}

According to Theorem~\ref{th:FMP}, the model reduction error $\abs{\pi(\boldsymbol{x}',t) - \Tilde{\pi}(\boldsymbol{x}',t)}$ is zero.

The truncation error can be controlled by including more states in the corresponding \ac{FFSP} system. The \ac{ODE} solver error depends on the selected numerical method and can be controlled by the time step $\Delta t$. These errors can be reduced to the desired tolerance without substantial computational cost because the dimensionality of the hidden space is low after projection.

The projection error $\abs{\Tilde{\pi}(\boldsymbol{x}',t) - \Tilde{\pi}^{M} (\boldsymbol{x}', t)}$ depends on the number of particles $M$ to approximate the \ac{FMP} propensities $\Tilde{a}_1, \dots, \Tilde{a}_{J'}$. Even for a fixed trajectory $\boldsymbol{y}([0,T])$,  $\Tilde{\pi}^M(\boldsymbol{x}', t)$ is a random variable because it depends on $M$ random particles. As $\Tilde{a}_j^M$ is a \ac{PF} estimator, it converges to $\Tilde{a}_j$ with a rate of $O(M^{-1/2})$. Some technical assumptions are necessary to demonstrate the same  order of convergence for $\Tilde{\pi}^M$.

Similarly to the assumption \eqref{eq:assumption_bound_propens} for the full-dimensional \ac{SRN}, we assume that all propensities of the \ac{FMP}-\ac{SRN} are bounded. That is, there exists a function $\Tilde{C}_2: \mathsf{Y} \to \mathbb{R}_{\geq 0}$ such that, for any $t \in [0, T]$, the following holds:
\begin{equation}
\label{eq:assumption_bound_propens_FMP} \tag{A4}
    \sup_{\boldsymbol{x'} \in \mathsf{X}'} \sum_{j = 1}^{J'} \Tilde{a}_j \left( \boldsymbol{x}', \boldsymbol{y}, t \right) \leq C_2 (\boldsymbol{y}).
\end{equation}
All propensities should be bounded, not only observed ones as in \eqref{eq:assumption_bound_propens}.

\begin{theorem}[Sensitivity of the filtering problem for \acp{SRN}]
\label{th:sensitivity}
    Let $\Tilde{a}_j^{est}(\boldsymbol{z}', t)$ be approximations of propensities $\Tilde{a}_j(\boldsymbol{z}', t)$, satisfying
    \begin{equation}
        \label{eq:a_tilde_error_eps}
        \Emu{\abs{ \Tilde{a}_j(\boldsymbol{z}', t) - \Tilde{a}_j^{est}(\boldsymbol{z}', t) }} \leq \varepsilon, \quad j = 1, \dots, J'
    \end{equation}
    for all $\boldsymbol{z}' \in \mathsf{Z}'$ and $t \in [0, T]$. 
    Then, under the assumptions \eqref{eq:non_expl_cond} and \eqref{eq:assumption_bound_propens_FMP}, for all $t \in [0, T]$ 
    \begin{equation}
    \label{eq:projection_error_pi_eps}
        \Emu{ \sum_{\boldsymbol{x}' \in \mathsf{X}'} \abs{ \Tilde{\pi}(\boldsymbol{x}', t) - \Tilde{\pi}^{est}(\boldsymbol{x}', t) }} =  O(\varepsilon),
    \end{equation}
    where $\Tilde{\pi}^{est}(\boldsymbol{x}', t)$ is a solution of the filtering problem for the \ac{SRN} with propensities $\Tilde{a}_j^{est}(\boldsymbol{z}', t)$.
\end{theorem}

\begin{proof}
    Appendix~\ref{sec:FMP_error_proof} provides the proof.
\end{proof}

As an immediate consequence of this theorem, the projection error rate of the \ac{FMP} method is obtained when using the \ac{PF} to estimate the propensities.

\begin{corollary}[\ac{FMP} error]
\label{corollary:FMP_error_PF}
     If \eqref{eq:non_expl_cond}, \eqref{eq:PF_error_rate}, and \eqref{eq:assumption_bound_propens_FMP} hold, then 
    \begin{equation}
    \label{eq:projection_error_pi}
        \Emu{ \sum_{\boldsymbol{x}' \in \mathsf{X}'} \abs{ \Tilde{\pi}(\boldsymbol{x}', t) - \Tilde{\pi}^M(\boldsymbol{x}', t) }} =  O(M^{-1/2}),
    \end{equation}
    for all $t \in [0, T]$.
\end{corollary}


Although the order of error for \ac{FMP} is the same as for the \ac{PF}, the constant in front of $M^{-1/2}$ is expected to be smaller for \ac{FMP}. As we discussed earlier, the \ac{PF} suffers when estimating distributions due to the high variance of the indicator function. Whereas in the \ac{FMP} method, the \ac{PF} estimates the projected propensities, yielding a smaller variance, regardless of the final \ac{QOI}.

\begin{remark}
    The general form of Theorem~\ref{th:sensitivity} can be useful for other methods for estimating the propensities $\{\Tilde{a}_j\}_{j=1}^{J'}$. For instance, using \cite{leluc2023speeding, gerber2015sequential} could potentially lead to an error $O(M^{-p})$ with $p > 1/2$.
\end{remark}

