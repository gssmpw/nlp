\section{Proof of Theorem~\ref{th:MP}}
\label{sec:MP_proof}
\begin{proof}
    The result can be derived from \cite[Theorem~3.1]{Hammouda2023MP}, but this work presents an alternative proof based on the marginalization of the \ac{CME}.
    The \ac{PMF} $p(\boldsymbol{z}, t) = \Probmu{\boldsymbol{Z}(t) = \boldsymbol{z}}$ obeys the following:
    \begin{equation}
    \label{eq:CME}
        \frac{\mathrm{d}}{\mathrm{d} t} p(\boldsymbol{z}, t) = \sum_{j=1}^{J} a_j(\boldsymbol{z}-\boldsymbol{\nu}_j) p(\boldsymbol{z}-\boldsymbol{\nu}_j, t) - \sum_{j=1}^{J} a_j(\boldsymbol{z}) p(\boldsymbol{z}, t)
    \end{equation}
    with the initial condition $p(\cdot, 0)$, corresponding to the distribution $\mu$ of the random variable $\boldsymbol{Z}(0)$. The goal is to derive an equation for the probability function of the process $\boldsymbol{Z}'$: the marginal probability function $\boldsymbol{z}' \mapsto \sum\limits_{{\boldsymbol{z}}'' } p \left( \begin{bmatrix} \boldsymbol{z}' \\ {\boldsymbol{z}}'' \end{bmatrix}, t \right)$. To do so, we sum \eqref{eq:CME} over all states for $\boldsymbol{z}'' \in \mathbb{Z}^{\dim(\boldsymbol{Z}'')}$:
    \begin{align*}
        \sum_{{\boldsymbol{z}}'' } \frac{\mathrm{d}}{\mathrm{d} t} p \left( \begin{bmatrix} \boldsymbol{z}' \\ {\boldsymbol{z}}'' \end{bmatrix}, t \right) 
        &= \sum_{{\boldsymbol{z}}'' } \sum_{j=1}^{J} a_j \left( \begin{bmatrix} \boldsymbol{z}' - \boldsymbol{\nu}_j' \\ {\boldsymbol{z}}'' - \boldsymbol{\nu}_j'' \end{bmatrix} \right) p \left( \begin{bmatrix} \boldsymbol{z}' - \boldsymbol{\nu}_j' \\ {\boldsymbol{z}}'' - \boldsymbol{\nu}_j'' \end{bmatrix}, t \right)  \\
        &- \sum_{{\boldsymbol{z}}'' } \sum_{j=1}^{J} a_j \left( \begin{bmatrix} \boldsymbol{z}' \\ {\boldsymbol{z}}'' \end{bmatrix} \right) p \left( \begin{bmatrix} \boldsymbol{z}' \\ {\boldsymbol{z}}'' \end{bmatrix}, t \right).
    \end{align*}
    Under the non-explosivity assumption \eqref{eq:non_expl_cond}, the equation can be rewritten as follows:
    \begin{equation}
    \label{eq:MP_proof_1} 
    \begin{aligned}
         \frac{\mathrm{d}}{\mathrm{d} t} \left( \sum_{{\boldsymbol{z}}'' } p \left( \begin{bmatrix} \boldsymbol{z}' \\ {\boldsymbol{z}}'' \end{bmatrix}, t \right) \right)
         &= \sum_{j=1}^{J} \sum_{{\boldsymbol{z}}'' } a_j \left( \begin{bmatrix} \boldsymbol{z}' - \boldsymbol{\nu}_j' \\ {\boldsymbol{z}}'' - \boldsymbol{\nu}_j'' \end{bmatrix} \right) p \left( \begin{bmatrix} \boldsymbol{z}' - \boldsymbol{\nu}_j' \\ {\boldsymbol{z}}'' - \boldsymbol{\nu}_j'' \end{bmatrix}, t \right)  \\
         &- \sum_{j=1}^{J} \sum_{{\boldsymbol{z}}'' } a_j \left( \begin{bmatrix} \boldsymbol{z}' \\ {\boldsymbol{z}}'' \end{bmatrix} \right) p \left( \begin{bmatrix} \boldsymbol{z}' \\ {\boldsymbol{z}}'' \end{bmatrix}, t \right)
    \end{aligned}
    \end{equation}
    The left-hand side already has the desired marginal distribution. Consider the first sum on the right-hand side of \eqref{eq:MP_proof_1}:
    \begin{align*}
        &\sum_{{\boldsymbol{z}}'' } a_j \left( \begin{bmatrix} \boldsymbol{z}' - \boldsymbol{\nu}_j' \\ {\boldsymbol{z}}'' - \boldsymbol{\nu}_j''\end{bmatrix} \right) p \left( \begin{bmatrix}\boldsymbol{z}' - \boldsymbol{\nu}_j' \\ {\boldsymbol{z}}'' - \boldsymbol{\nu}_j'' \end{bmatrix}, t \right) \\ 
        &= \sum_{{\boldsymbol{z}}'' } a_j \left( \begin{bmatrix} \boldsymbol{z}' - \boldsymbol{\nu}_j' \\ {\boldsymbol{z}}'' \end{bmatrix} \right) p \left( \begin{bmatrix} \boldsymbol{z}' - \boldsymbol{\nu}_j' \\ {\boldsymbol{z}}'' \end{bmatrix}, t \right) \\
        &= \sum\limits_{{\boldsymbol{z}}'' } a_j \left( \begin{bmatrix} \boldsymbol{z}' - \boldsymbol{\nu}_j' \\ {\boldsymbol{z}}'' \end{bmatrix} \right)  \frac{ p \left( \begin{bmatrix} \boldsymbol{z}' - \boldsymbol{\nu}_j' \\ {\boldsymbol{z}}'' \end{bmatrix}, t \right) }{ \sum\limits_{{\boldsymbol{z}}'' } p \left( \begin{bmatrix}\boldsymbol{z}' - \boldsymbol{\nu}_j' \\ {\boldsymbol{z}}'' \end{bmatrix}, t \right)} \cdot \left( \sum_{{\boldsymbol{z}}'' } p \left( \begin{bmatrix} \boldsymbol{z}' - \boldsymbol{\nu}_j' \\ {\boldsymbol{z}}'' \end{bmatrix}, t \right)  \right) \\
        &=  \underbrace{ \Econdmu{a_j \left( \begin{bmatrix} \boldsymbol{Z}'(t) \\ \boldsymbol{Z}''(t) \end{bmatrix} \right)}{\boldsymbol{Z}'(t) = \boldsymbol{z}' - \boldsymbol{\nu}_j' } }_{\textstyle = \bar{a}_j (\boldsymbol{z}' - \boldsymbol{\nu}_j', t)} \cdot \left( \sum_{{\boldsymbol{z}}'' } p \left( \begin{bmatrix} \boldsymbol{z}' - \boldsymbol{\nu}_j' \\ {\boldsymbol{z}}'' \end{bmatrix}, t \right) \right).
    \end{align*}
    The denominator is zero only if the whole expression is zero; in this case, $(\boldsymbol{z}'-\boldsymbol{\nu}_j', \cdot)$ can be excluded from the state space because it is unreachable.
    
    Similarly, the second sum on the right-hand side of \eqref{eq:MP_proof_1} is transformed:
    \begin{align*}
        \sum_{{\boldsymbol{z}}'' } a_j \left( \begin{bmatrix} \boldsymbol{z}' \\ {\boldsymbol{z}}'' \end{bmatrix} \right) p \left( \begin{bmatrix} \boldsymbol{z}' \\ {\boldsymbol{z}}'' \end{bmatrix} , t \right) 
        &= \frac{\sum\limits_{{\boldsymbol{z}}'' } a_j\left( \begin{bmatrix} \boldsymbol{z}' \\ {\boldsymbol{z}}'' \end{bmatrix} \right) p\left( \begin{bmatrix} \boldsymbol{z}' \\ {\boldsymbol{z}}'' \end{bmatrix}, t \right)}{\sum\limits_{{\boldsymbol{z}}'' } p\left( \begin{bmatrix} \boldsymbol{z}' \\ {\boldsymbol{z}}'' \end{bmatrix}, t \right)} \left( \sum_{{\boldsymbol{z}}'' } p\left( \begin{bmatrix} \boldsymbol{z}' \\ {\boldsymbol{z}}'' \end{bmatrix}, t \right) \right) \\
        &=  \underbrace{ \Econdmu{a_j\left( \begin{bmatrix} \boldsymbol{z}' \\ {\boldsymbol{z}}'' \end{bmatrix} \right)}{\boldsymbol{Z}'(t) = \boldsymbol{z}' } }_{\textstyle = \bar{a}_j (\boldsymbol{z}', t)} \left( \sum_{{\boldsymbol{z}}'' } p\left( \begin{bmatrix} \boldsymbol{z}' \\ {\boldsymbol{z}}'' \end{bmatrix}, t \right) \right).
    \end{align*}
    The denominator here is also not zero due to the same reason.
    
    The results reveal that \eqref{eq:MP_proof_1} can be written as follows:
    \begin{align*}
        \frac{\mathrm{d}}{\mathrm{d} t} \left( \sum_{{\boldsymbol{z}}'' } p\left( \begin{bmatrix} \boldsymbol{z}' \\ {\boldsymbol{z}}'' \end{bmatrix}, t \right) \right) 
        &= \sum_{j=1}^{J} \bar{a}_j (\boldsymbol{z}' - \boldsymbol{\nu}_j', t) \left( \sum_{{\boldsymbol{z}}'' } p\left( \begin{bmatrix} \boldsymbol{z}' - \boldsymbol{\nu}_j' \\ {\boldsymbol{z}}'' \end{bmatrix}, t \right) \right) \\
        &- \sum_{j=1}^{J} \bar{a}_j (\boldsymbol{z}', t) \left( \sum_{{\boldsymbol{z}}'' } p\left( \begin{bmatrix} \boldsymbol{z}' \\ {\boldsymbol{z}}'' \end{bmatrix}, t \right) \right) .
    \end{align*}
    Thus, we obtained the \ac{ODE} for the probability function of the process $\boldsymbol{Z}'$, which is the same as the \ac{CME} for the process $\bar{\boldsymbol{Z}}'$. Furthermore, the initial conditions for these \acp{ODE} coincide because $\bar{\boldsymbol{Z}}'(0) \overset{d}{=} \boldsymbol{Z}'(0)$. Finally, the statement of the theorem follows from the uniqueness of the solution to the initial value problem.
\end{proof}







\section{Proof of Theorem~\ref{th:FMP}}
\label{sec:FMP_proof}

\begin{proof}  
    According to the filtering equation \eqref{eq:filtering_equation_rho}, the unnormalized conditional probability function $\rho_{\boldsymbol{y}}(\boldsymbol{x}, t)$ of $\boldsymbol{X}(t)$ for $t \in (t_k, t_{k+1})$ satisfies the following:
    \begin{align*}
        \frac{\mathrm{d}}{\mathrm{d} t} \rho_{\boldsymbol{y}}(\boldsymbol{x}, t) 
        &= \sum_{j \in \mathcal{U}} \rho_{\boldsymbol{y}}(\boldsymbol{x} - \boldsymbol{\nu}_{\boldsymbol{x}, j}, t) a_j \left( \boldsymbol{x}-\boldsymbol{\nu}_{\boldsymbol{x}, j}, \boldsymbol{y}(t_k) \right) - \sum_{j=1}^{J} \rho_{\boldsymbol{y}}(\boldsymbol{x}, t) a_j \left( \boldsymbol{x}, \boldsymbol{y}(t_k) \right).
    \end{align*}
    Summing these equations for all possible states for $\boldsymbol{X}''(t) \in \mathbb{Z}^{d''}$ yields
    \begin{align*}
        \sum_{\boldsymbol{x}'' \in \mathbb{Z}^{d''}} \frac{\mathrm{d}}{\mathrm{d} t} \rho_{\boldsymbol{y}} \left( \begin{bmatrix} \boldsymbol{x}' \\ \boldsymbol{x}'' \end{bmatrix} , t \right) 
        &= \sum_{\boldsymbol{x}'' \in \mathbb{Z}^{d''}}\sum_{j \in \mathcal{U}} a_j \left( \begin{bmatrix} \boldsymbol{x}' - \boldsymbol{\nu}_{\boldsymbol{x}, j}' \\ \boldsymbol{x}'' - \boldsymbol{\nu}_{\boldsymbol{x}, j}'' \end{bmatrix}, \boldsymbol{y}(t_k) \right) \rho_{\boldsymbol{y}} \left( \begin{bmatrix} \boldsymbol{x}' - \boldsymbol{\nu}_{\boldsymbol{x}, j}' \\ \boldsymbol{x}'' - \boldsymbol{\nu}_{\boldsymbol{x}, j}''\end{bmatrix} , t \right)  \\
        &- \sum_{\boldsymbol{x}'' \in \mathbb{Z}^{d''}} \sum_{j=1}^{J} a_j \left( \begin{bmatrix} \boldsymbol{x}' \\ \boldsymbol{x}'' \end{bmatrix}, \boldsymbol{y}(t_k) \right) \rho_{\boldsymbol{y}} \left( \begin{bmatrix} \boldsymbol{x}' \\ \boldsymbol{x}'' \end{bmatrix}, t \right) .
    \end{align*}
    Under the non-explosivity assumption \eqref{eq:non_expl_cond}, it can be rewritten as
    \begin{equation}
    \label{eq:FMP_proof_1} 
    \begin{aligned}
        \frac{\mathrm{d}}{\mathrm{d} t} \left( \sum_{\boldsymbol{x}'' \in \mathbb{Z}^{d''}} \rho_{\boldsymbol{y}} \left( \begin{bmatrix} \boldsymbol{x}' \\ \boldsymbol{x}'' \end{bmatrix}, t \right) \right) 
        &= \sum_{j \in \mathcal{U}} \sum_{\boldsymbol{x}'' \in \mathbb{Z}^{d''}} a_j \left( \begin{bmatrix} \boldsymbol{x}' - \boldsymbol{\nu}_{\boldsymbol{x}, j}' \\ \boldsymbol{x}'' - \boldsymbol{\nu}_{\boldsymbol{x}, j}'' \end{bmatrix}, \boldsymbol{y}(t_k) \right) \rho_{\boldsymbol{y}} \left( \begin{bmatrix} \boldsymbol{x}' - \boldsymbol{\nu}_{\boldsymbol{x}, j}' \\ \boldsymbol{x}'' - \boldsymbol{\nu}_{\boldsymbol{x}, j}''\end{bmatrix}, t \right)  \\
        &- \sum_{j=1}^{J} \sum_{\boldsymbol{x}'' \in \mathbb{Z}^{d''}} a_j \left( \begin{bmatrix} \boldsymbol{x}' \\ \boldsymbol{x}'' \end{bmatrix}, \boldsymbol{y}(t_k) \right) \rho_{\boldsymbol{y}} \left( \begin{bmatrix} \boldsymbol{x}' \\ \boldsymbol{x}'' \end{bmatrix}, t \right) .
    \end{aligned}
    \end{equation}

    Consider the first sum in \eqref{eq:FMP_proof_1}:
    \begin{align*}
        &\sum_{\boldsymbol{x}'' \in \mathbb{Z}^{d''}} a_j \left( \begin{bmatrix} \boldsymbol{x}' - \boldsymbol{\nu}_{\boldsymbol{x}, j}' \\ \boldsymbol{x}'' - \boldsymbol{\nu}_{\boldsymbol{x}, j}'' \end{bmatrix}, \boldsymbol{y}(t_k) \right) \rho_{\boldsymbol{y}} \left( \begin{bmatrix} \boldsymbol{x}' - \boldsymbol{\nu}_{\boldsymbol{x}, j}' \\ \boldsymbol{x}'' - \boldsymbol{\nu}_{\boldsymbol{x}, j}'' \end{bmatrix}, t \right) \\
        &= \sum_{\boldsymbol{x}'' \in \mathbb{Z}^{d''}} a_j \left( \begin{bmatrix} \boldsymbol{x}' - \boldsymbol{\nu}_{\boldsymbol{x}, j}' \\ \boldsymbol{x}'' \end{bmatrix}, \boldsymbol{y}(t_k) \right) \rho_{\boldsymbol{y}} \left( \begin{bmatrix} \boldsymbol{x}' - \boldsymbol{\nu}_{\boldsymbol{x}, j}' \\ \boldsymbol{x}'' \end{bmatrix}, t \right) \\
        &= \sum_{\boldsymbol{x}'' \in \mathbb{Z}^{d''}} a_j \left( \begin{bmatrix} \boldsymbol{x}' - \boldsymbol{\nu}_{\boldsymbol{x}, j}' \\ \boldsymbol{x}'' \end{bmatrix}, \boldsymbol{y}(t_k) \right) \frac{ \rho_{\boldsymbol{y}} \left( \begin{bmatrix} \boldsymbol{x}' - \boldsymbol{\nu}_{\boldsymbol{x}, j}' \\ \boldsymbol{x}'' \end{bmatrix}, t \right) }{ \sum\limits_{\boldsymbol{x}'' \in \mathbb{Z}^{d''}} \rho_{\boldsymbol{y}}\left( \begin{bmatrix} \boldsymbol{x}' - \boldsymbol{\nu}_{\boldsymbol{x}, j}' \\ \boldsymbol{x}'' \end{bmatrix}, t \right) } \cdot \left( \sum_{\boldsymbol{x}'' \in \mathbb{Z}^{d''}} \rho_{\boldsymbol{y}} \left( \begin{bmatrix} \boldsymbol{x}' - \boldsymbol{\nu}_{\boldsymbol{x}, j}' \\ \boldsymbol{x}'' \end{bmatrix}, t \right) \right) \\
        &= \sum_{\boldsymbol{x}'' \in \mathbb{Z}^{d''}} a_j \left( \begin{bmatrix} \boldsymbol{x}' - \boldsymbol{\nu}_{\boldsymbol{x}, j}' \\ \boldsymbol{x}'' \end{bmatrix}, \boldsymbol{y}(t_k) \right) \frac{ \pi_{\boldsymbol{y}} \left( \begin{bmatrix} \boldsymbol{x}' - \boldsymbol{\nu}_{\boldsymbol{x}, j}' \\ \boldsymbol{x}'' \end{bmatrix}, t \right) }{ \sum\limits_{\boldsymbol{x}'' \in \mathbb{Z}^{d''}} \pi_{\boldsymbol{y}} \left( \begin{bmatrix} \boldsymbol{x}' - \boldsymbol{\nu}_{\boldsymbol{x}, j}' \\ \boldsymbol{x}'' \end{bmatrix}, t \right) } \cdot \left( \sum_{\boldsymbol{x}'' \in \mathbb{Z}^{d''}} \rho_{\boldsymbol{y}} \left( \begin{bmatrix} \boldsymbol{x}' - \boldsymbol{\nu}_{\boldsymbol{x}, j}' \\ \boldsymbol{x}'' \end{bmatrix}, t \right) \right) .
    \end{align*}
    The last transition follows from dividing the numerator and denominator by the normalization factor $\sum\limits_{\boldsymbol{x}' \in \mathbb{Z}^{d'}} \sum\limits_{\boldsymbol{x}'' \in \mathbb{Z}^{d''}} \rho_{\boldsymbol{y}} \left( \begin{bmatrix} \boldsymbol{x}' \\ \boldsymbol{x}'' \end{bmatrix}, t \right)$. The denominator is zero only if all hidden states $\begin{bmatrix} \boldsymbol{x}' \\ \cdot \end{bmatrix}$ are unreachable and can be excluded.
    
    Moreover,
    \begin{align*}
        \frac{ \pi_{\boldsymbol{y}} \left( \begin{bmatrix} \boldsymbol{x}' - \boldsymbol{\nu}_{\boldsymbol{x}, j}' \\ \boldsymbol{x}'' \end{bmatrix}, t \right) }{ \sum\limits_{\boldsymbol{x}'' \in \mathbb{Z}^{d''}} \pi_{\boldsymbol{y}} \left( \begin{bmatrix} \boldsymbol{x}' - \boldsymbol{\nu}_{\boldsymbol{x}, j}' \\ \boldsymbol{x}'' \end{bmatrix}, t \right) } = \Probcondmu{ \boldsymbol{X}''(t) = \boldsymbol{x}''}{ \boldsymbol{X}'(t) =  \boldsymbol{x}' - \boldsymbol{\nu}_{\boldsymbol{x}, j}'  , \boldsymbol{Y}(s) = \boldsymbol{y}(s) , s \leq t }.
    \end{align*}
    Therefore, the first term on the right-hand side of \eqref{eq:FMP_proof_1} simplifies to 
    \begin{align*}
        \sum_{j \in \mathcal{U}} \underbrace{\Econdmu{a_j (\boldsymbol{Z}(t))}{ \boldsymbol{X}'(t) = \boldsymbol{x}'-\boldsymbol{\nu}_{\boldsymbol{x}, j}' , \boldsymbol{Y}(s) = \boldsymbol{y}(s), s \leq t}}_{\textstyle = \Tilde{a}_j (\boldsymbol{x}'-\boldsymbol{\nu}_{\boldsymbol{x}, j}', \boldsymbol{y}(t_k), t) } \left( \sum_{\boldsymbol{x}'' \in \mathbb{Z}^{d''}} \rho_{\boldsymbol{y}} \left( \begin{bmatrix} \boldsymbol{x}' \\ \boldsymbol{x}'' \end{bmatrix}, t \right) \right).
    \end{align*}
    
    The same procedure reveals that the second term on the right-hand side of \eqref{eq:FMP_proof_1} is equal to
    \begin{align*}
        \sum_{j = 1}^{J} \underbrace{\Econdmu{a_j (\boldsymbol{Z}(t))}{ \boldsymbol{X}'(t) = \boldsymbol{x}', \boldsymbol{Y}(s) = \boldsymbol{y}(s), s \leq t}}_{\textstyle = \Tilde{a}_j (\boldsymbol{x}', \boldsymbol{y}(t_k), t) } \cdot \left( \sum_{\boldsymbol{x}'' \in \mathbb{Z}^{d''}} \rho_{\boldsymbol{y}} \left( \begin{bmatrix} \boldsymbol{x}' \\ \boldsymbol{x}'' \end{bmatrix}, t \right) \right).
    \end{align*}
    Gathering all the results into \eqref{eq:FMP_proof_1} yields the following:
    \begin{align*}
        \frac{\mathrm{d}}{\mathrm{d} t} \left( \sum_{\boldsymbol{x}'' \in \mathbb{Z}^{d''}} \rho_{\boldsymbol{y}} \left( \begin{bmatrix} \boldsymbol{x}' \\ \boldsymbol{x}'' \end{bmatrix}, t \right) \right) 
        &= \sum_{j \in \mathcal{U}} \Tilde{a}_j (\boldsymbol{x}' - \boldsymbol{\nu}_{\boldsymbol{x}, j}', \boldsymbol{y}(t_k), t) \left( \sum_{\boldsymbol{x}'' \in \mathbb{Z}^{d''}} \rho_{\boldsymbol{y}} \left( \begin{bmatrix} \boldsymbol{x}'  - \boldsymbol{\nu}_{\boldsymbol{x}, j}' \\ \boldsymbol{x}'' \end{bmatrix}, t \right) \right) \\
        &- \sum_{j=1}^{J} \Tilde{a}_j (\boldsymbol{x}',  \boldsymbol{y}(t_k)) \left( \sum_{\boldsymbol{x}'' \in \mathbb{Z}^{d''}} \rho_{\boldsymbol{y}} \left( \begin{bmatrix} \boldsymbol{x}' \\ \boldsymbol{x}'' \end{bmatrix}, t \right) \right) .
    \end{align*}
    It is considered an \ac{ODE} for the following function:
    $$ 
        (\boldsymbol{x}', t) \mapsto \sum\limits_{\boldsymbol{x}'' \in \mathbb{Z}^{d''}} \rho_{\boldsymbol{y}} \left( \begin{bmatrix} \boldsymbol{x}' \\ \boldsymbol{x}'' \end{bmatrix}, t \right) .
    $$  
    This is exactly the filtering equation for $\Tilde{\boldsymbol{Z}}'$ between jumps. 
    
    Using the same summation procedure, also proves that the updating according to \eqref{eq:filtering_equation_pi_jump} at the jump times for the marginal distribution of $\boldsymbol{X}'$ is the same as that for $\Tilde{\boldsymbol{X}}'$. Finally, $\Tilde{\boldsymbol{Z}}'(0) \overset{d}{=} \boldsymbol{Z}'(0)$ ensures the same initial conditions for the filtering equation; hence, the solutions coincide.
\end{proof}







\section{Proof of Theorem~\ref{th:sensitivity}}
\label{sec:FMP_error_proof}
\begin{proof}



Consider $\Tilde{\pi}(\boldsymbol{x}',t)$ and $\Tilde{\pi}^{est} (\boldsymbol{x}', t)$ as solutions to the corresponding filtering equations. Let $\mathsf{X}' = \{ \boldsymbol{x}'_1, \boldsymbol{x}'_2, \dots \}$ be the infinite state space and $\Tilde{\pi}(t) = (\Tilde{\pi}(\boldsymbol{x}'_1, t), \Tilde{\pi}(\boldsymbol{x}'_2, t), \dots )^\top$  be the infinite-dimensional vector, then the corresponding filtering equation \eqref{eq:filtering_equation_pi} can be written as follows:
\begin{equation}
    \label{eq:filtering_pi_matrix}
    \frac{\mathrm{d}}{\mathrm{d} t} \Tilde{\pi}(t) = \mathcal{A}(t) \Tilde{\pi}(t) + \langle \alpha(t), \Tilde{\pi}(t) \rangle \cdot \Tilde{\pi}(t), \qquad t\in(t_k, t_{k+1}),
\end{equation}
where $\mathcal{A}(t)$ is a linear operator given by the infinite-dimensional matrix with the entries
\begin{align*}
    \mathcal{A}_{n m}(t) := 
    \begin{cases}
        - \sum\limits_{j = 1}^{J'} \Tilde{a}_j(\boldsymbol{x}_{n}, \boldsymbol{y}(t), t) & \text{if } \boldsymbol{x}_{n} = \boldsymbol{x}_{m} \\
        \Tilde{a}_j(\boldsymbol{x}_{m}, \boldsymbol{y}(t), t) & \text{if } \exists j \in \mathcal{U}': \boldsymbol{x}_{n}' = \boldsymbol{x}_{m}' + \boldsymbol{\nu}_{\boldsymbol{x}, j}' \\
        0 & \text{otherwise}
    \end{cases}
\end{align*}
and $\langle \alpha(t), \cdot \rangle$ is a linear functional given by a scalar product with the infinite-dimensional vector $\alpha(t)$ with entries
\begin{align*}
    \alpha_n(t) := \sum_{j \in \mathcal{O}} \Tilde{a}_j (\boldsymbol{x}_n', \boldsymbol{y}(t), t).
\end{align*}

Equation \eqref{eq:filtering_equation_pi_jump} can be written as follows:
\begin{equation}
    \label{eq:filtering_pi_jump_matrix}
    \Tilde{\pi}(t_k) = \frac{\mathcal{B}(t_k^-) \Tilde{\pi}(t_k^-)}{\norm{\mathcal{B}(t_k^-) \Tilde{\pi}(t_k^-)}_1},
\end{equation}
where $\mathcal{B}(t_k^-)$ is a linear operator given by the infinite-dimensional matrix with entries
\begin{align*}
    \mathcal{B}_{n m}(t_k^-) := 
    \begin{cases}
        \frac{1}{\abs{\mathcal{O}_k}} \Tilde{a}_j(\boldsymbol{x}_{m}', \boldsymbol{y}(t_k^-), t_k^-) & \text{if } \exists j \in \mathcal{O}_k: \boldsymbol{x}_{n}' = \boldsymbol{x}_{m}' + \boldsymbol{\nu}_{\boldsymbol{x}, j}' \\
        0 & \text{otherwise}.
    \end{cases}
\end{align*}
We denote by $\mathcal{A}^{est}$, $\alpha^{est}$, and $\mathcal{B}^{est}$ the corresponding operators obtained by replacing all propensities $\Tilde{a}$ with their its estimates $\Tilde{a}^{est}$. Therefore, $\Tilde{\pi}^{est}$ obeys
\begin{equation}
    \label{eq:filtering_piM_matrix}
    \frac{\mathrm{d}}{\mathrm{d} t} \Tilde{\pi}^{est}(t) = \mathcal{A}^{est}(t) \Tilde{\pi}(t) + \langle \alpha^{est}(t), \Tilde{\pi}^{est}(t) \rangle \cdot \Tilde{\pi}^{est}(t), \qquad t \in (t_k, t_{k+1}),
\end{equation} 
\begin{equation}
    \label{eq:filtering_piM_jump_matrix}
    \Tilde{\pi}^{est}(t_k) = \frac{\mathcal{B}^{est}(t_k^-) \Tilde{\pi}^{est}(t_k^-)}{\norm{\mathcal{B}^{est}(t_k^-) \Tilde{\pi}^{est}(t_k^-)}_1}.
\end{equation}

We show the statement of Theorem~\ref{th:sensitivity} by induction on jump times $t_0, t_1, \dots, t_n$. For $t_0 = 0$, the error is zero due to the equality of the initial distributions. Assume that $\Emu{\norm{\Tilde{\pi}(t) - \Tilde{\pi}^{est}(t)}_1} = O(\varepsilon)$ for all $t \in [0, t_k]$ with arbitrary fixed $k$. The goal is to show $\Emu{\norm{\Tilde{\pi}(t) - \Tilde{\pi}^{est}(t)}_1} = O(\varepsilon)$ for all $t \in [0, t_{k+1}]$. For $t \in (t_k, t_{k+1})$ from \eqref{eq:filtering_pi_matrix}, \eqref{eq:filtering_piM_matrix}, and the triangle inequality, we obtain
\begin{equation}
\label{eq:FMP_error_decomp}
\begin{aligned}
    \Emu{\norm{\Tilde{\pi}(t) - \Tilde{\pi}^{est}(t)}_1} &\leq \Emu{ \norm{ \Tilde{\pi}(t_k) - \Tilde{\pi}^{est}(t_k) }_1 } + \Emu{ \int_{t_k}^{t} \norm{\mathcal{A}(s) \Tilde{\pi}(s) - \mathcal{A}^{est}(s) \Tilde{\pi}^{est}(s) }_1 \diff s } \\ 
    &\phantom{\leq} + \Emu{ \int_{t_k}^{t} \norm{\langle \alpha(s), \Tilde{\pi}(s) \rangle \cdot \Tilde{\pi}(s) - \langle \alpha^{est}(s), \Tilde{\pi}^{est}(s) \rangle \cdot \Tilde{\pi}^{est}(s)}_1 \diff s }.
\end{aligned}
\end{equation}

Next, we apply the triangle inequality to the second term:
\begin{align*}
    &\Emu{ \int_{t_k}^{t} \norm{\mathcal{A}(s) \Tilde{\pi}(s) - \mathcal{A}^{est}(s) \Tilde{\pi}^{est}(s) }_1 \diff s } \\
    &\leq \Emu{ \int_{t_k}^{t} \norm{\mathcal{A}(s) \Tilde{\pi}(s) - \mathcal{A}(s) \Tilde{\pi}^{est}(s) }_1 \diff s } + \Emu{ \int_{t_k}^{t} \norm{\mathcal{A}(s) \Tilde{\pi}^{est}(s) - \mathcal{A}^{est}(s) \Tilde{\pi}^{est}(s) }_1 \diff s } \\
    &\leq \Emu{ \int_{t_k}^{t} \norm{ \mathcal{A}(s) }_1 \norm{ \Tilde{\pi}(s) -  \Tilde{\pi}^{est}(s) }_1 \diff s } + \Emu{ \int_{t_k}^{t} \norm{ \mathcal{A}(s) - \mathcal{A}^{est}(s) }_1 \norm{ \Tilde{\pi}^{est}(s) }_1 \diff s }.
\end{align*}
The assumption \eqref{eq:assumption_bound_propens_FMP} implies $\norm{\mathcal{A}(s)}_1 \leq 2 C_2(\boldsymbol{y}(t_k))$. In addition, $\norm{\Tilde{\pi}^{est}(s)}_1 = 1$ and, according to \eqref{eq:a_tilde_error_eps}, $\Emu{\norm{\mathcal{A}(s) - \mathcal{A}^{est}(s)}_1} = O(\varepsilon)$ for all $s \in (t_k, t)$. Therefore, the second term in $\eqref{eq:FMP_error_decomp}$ is bounded by the following:
\begin{align*}
    2 C_2(\boldsymbol{y}(t_k)) \cdot \Emu{ \int_{t_k}^{t} \norm{ \Tilde{\pi}(s) -  \Tilde{\pi}^{est}(s) }_1 \diff s } + C \varepsilon \cdot (t-t_k).
\end{align*}

We also use the triangle inequality to bound the third term in \eqref{eq:FMP_error_decomp}:
\begin{align*}
    &\Emu{ \int_{t_k}^{t} \norm{\langle \alpha(s), \Tilde{\pi}(s) \rangle \cdot \Tilde{\pi}(s) - \langle \alpha^{est}(s), \Tilde{\pi}^{est}(s) \rangle \cdot \Tilde{\pi}^{est}(s)}_1 \diff s } \\
    &\leq \Emu{ \int_{t_k}^{t} \norm{\langle \alpha(s), \Tilde{\pi}(s) \rangle \cdot \Tilde{\pi}(s) - \langle \alpha(s), \Tilde{\pi}(s) \rangle \cdot \Tilde{\pi}^{est}(s)}_1 \diff s } \\
    &\phantom{\leq} + \Emu{ \int_{t_k}^{t} \norm{\langle \alpha(s), \Tilde{\pi}(s) \rangle \cdot \Tilde{\pi}^{est}(s) - \langle \alpha^{est}(s), \Tilde{\pi}^{est}(s) \rangle \cdot \Tilde{\pi}^{est}(s)}_1 \diff s } \\
    &= \Emu{ \int_{t_k}^{t} \abs{\langle \alpha(s), \Tilde{\pi}(s) \rangle} \cdot \norm{\Tilde{\pi}(s) - \Tilde{\pi}^{est}(s)}_1 \diff s } \\
    &\phantom{\leq} + \Emu{ \int_{t_k}^{t} \norm{\Tilde{\pi}^{est}(s)}_1 \cdot \abs{\langle \alpha(s), \Tilde{\pi}(s) \rangle - \langle \alpha^{est}(s), \Tilde{\pi}^{est}(s) \rangle } \diff s } \\
    &\leq \Emu{ \int_{t_k}^{t} \norm{\alpha(s)}_{\infty} \cdot \norm{\Tilde{\pi}(s) - \Tilde{\pi}^{est}(s)}_1 \diff s } \\
    &\phantom{\leq} + \Emu{ \int_{t_k}^{t} \abs{\langle \alpha(s), \Tilde{\pi}(s) \rangle - \langle \alpha^{est}(s), \Tilde{\pi}^{est}(s) \rangle } \diff s }.
\end{align*}
The last inequality follows from H\"{o}lder's inequality, and $\norm{\Tilde{\pi}(s)} = \norm{\Tilde{\pi}^{est}(s)} = 1$. To further bound this expression, we use \eqref{eq:assumption_bound_propens_FMP} to obtain $\norm{\alpha(s)}_{\infty} = C_2(\boldsymbol{y}(t_k))$ and apply the triangle inequality again:
\begin{align*}
    \dots &\leq C_2(\boldsymbol{y}(t_k)) \cdot \Emu{ \int_{t_k}^{t} \norm{\Tilde{\pi}(s) - \Tilde{\pi}^{est}(s)}_1 \diff s } \\
    &\phantom{\leq} + \Emu{ \int_{t_k}^{t} \abs{\langle \alpha(s), \Tilde{\pi}(s) - \Tilde{\pi}^{est}(s) \rangle } \diff s } 
    + \Emu{ \int_{t_k}^{t} \abs{\langle \alpha(s) - \alpha^{est}(s), \Tilde{\pi}^{est} (s) \rangle } \diff s } \\
    &\leq C_2(\boldsymbol{y}(t_k)) \cdot \Emu{ \int_{t_k}^{t} \norm{\Tilde{\pi}(s) - \Tilde{\pi}^{est}(s)}_1 \diff s } \\
    &\phantom{\leq} + \Emu{ \int_{t_k}^{t}  \norm{\alpha(s)}_{\infty} \cdot \norm{ \Tilde{\pi}(s) - \Tilde{\pi}^{est}(s) }_1 \diff s } 
    + \Emu{ \int_{t_k}^{t} \norm{ \alpha(s) - \alpha^{est}(s) }_{\infty} \cdot \norm{ \Tilde{\pi}^{est} (s) }_1 \diff s } \\
    &\leq 2 C_2(\boldsymbol{y}(t_k)) \cdot \Emu{ \int_{t_k}^{t} \norm{\Tilde{\pi}(s) - \Tilde{\pi}^{est}(s)}_1 \diff s } + C \varepsilon \cdot (t - t_k).
\end{align*}
The last line follows from \eqref{eq:assumption_bound_propens_FMP} and \eqref{eq:a_tilde_error_eps}.

Gathering all bounds back into \eqref{eq:FMP_error_decomp} yields
\begin{align*}
    \Emu{\norm{\Tilde{\pi}(t) - \Tilde{\pi}^{est}(t)}_1} \leq \Emu{ \norm{ \Tilde{\pi}(t_k) - \Tilde{\pi}^{est}(t_k) }_1 } &+  4 C_2(\boldsymbol{y}(t_k)) \cdot \Emu{ \int_{t_k}^{t} \norm{\Tilde{\pi}(s) - \Tilde{\pi}^{est}(s)}_1 \diff s } \\
    & + 2C \varepsilon \cdot (t - t_k).
\end{align*}
Using Gr\"{o}nwall's inequality for $t \mapsto \Emu{\norm{ \Tilde{\pi}(t) - \Tilde{\pi}^{est} (t) }_1}$ results in
\begin{align*}
    \Emu{\norm{\Tilde{\pi}(t) - \Tilde{\pi}^{est}(t)}_1} \leq \left[ \Emu{ \norm{ \Tilde{\pi}(t_k) - \Tilde{\pi}^{est}(t_k) }_1 } + 2C \varepsilon \cdot (t - t_k) \right] \cdot \exp \big( 4 C_2(\boldsymbol{y}(t_k)) \cdot (t-t_k) \big),
\end{align*}
that is, 
\begin{align*}
    \Emu{\norm{\Tilde{\pi}(t) - \Tilde{\pi}^{est}(t)}_1} = O(\varepsilon) \quad \text{for all} \quad t \in (t_k, t_{k+1}). 
\end{align*}

To show the result for $t = t_{k+1}$, \eqref{eq:filtering_pi_jump_matrix} and \eqref{eq:filtering_piM_jump_matrix} are used as follows:
\begin{equation}
\label{eq:FMP_error_decomp_jump}
\begin{aligned}
    \Emu{\norm{\Tilde{\pi}(t_{k+1}) - \Tilde{\pi}^{est}(t_{k+1})}_1} &= \Emu{\norm{ \frac{\mathcal{B}(t_{k+1}^-) \Tilde{\pi}(t_{k+1}^-)}{\norm{\mathcal{B}(t_{k+1}^-) \Tilde{\pi}(t_{k+1}^-)}_1} - \frac{\mathcal{B}^{est}(t_{k+1}^-) \Tilde{\pi}^{est}(t_{k+1}^-)}{\norm{\mathcal{B}^{est}(t_{k+1}^-) \Tilde{\pi}^{est}(t_{k+1}^-)}_1} }_1} \\
    &\leq \Emu{\norm{ \frac{\mathcal{B}(t_{k+1}^-) \Tilde{\pi}(t_{k+1}^-)}{\norm{\mathcal{B}(t_{k+1}^-) \Tilde{\pi}(t_{k+1}^-)}_1} - \frac{\mathcal{B}^{est}(t_{k+1}^-) \Tilde{\pi}^{est}(t_{k+1}^-)}{\norm{\mathcal{B}(t_{k+1}^-) \Tilde{\pi}(t_{k+1}^-)}_1} }_1} \\
    &\phantom{\leq} + \Emu{\norm{ \frac{\mathcal{B}^{est}(t_{k+1}^-) \Tilde{\pi}^{est}(t_{k+1}^-)}{\norm{\mathcal{B}(t_{k+1}^-) \Tilde{\pi}(t_{k+1}^-)}_1} - \frac{\mathcal{B}^{est}(t_{k+1}^-) \Tilde{\pi}^{est}(t_{k+1}^-)}{\norm{\mathcal{B}^{est}(t_{k+1}^-) \Tilde{\pi}^{est}(t_{k+1}^-)}_1} }_1}, \\
\end{aligned}
\end{equation}
where the first term can be bounded by
\begin{align*}
    \dots &= \frac{1}{\norm{\mathcal{B}(t_{k+1}^-) \Tilde{\pi}(t_{k+1}^-)}_1} \Emu{\norm{ \mathcal{B}(t_{k+1}^-) \Tilde{\pi}(t_{k+1}^-) - \mathcal{B}^{est}(t_{k+1}^-) \Tilde{\pi}^{est}(t_{k+1}^-)  }_1 } \\
    &\leq \frac{1}{\norm{\mathcal{B}(t_{k+1}^-) \Tilde{\pi}(t_{k+1}^-)}_1} \Emu{\norm{\mathcal{B}(t_{k+1}^-)}_1 \cdot \norm{ \Tilde{\pi}(t_{k+1}^-) - \Tilde{\pi}^{est}(t_{k+1}^-) }_1 } \\
    &\phantom{\leq} + \frac{1}{\norm{\mathcal{B}(t_{k+1}^-) \Tilde{\pi}(t_{k+1}^-)}_1} \Emu{\norm{ \mathcal{B}(t_{k+1}^-) - \mathcal{B}^{est}(t_{k+1}^-)}_1 \cdot \norm{\Tilde{\pi}^{est}(t_{k+1}^-) }_1 } \\
    &\leq \frac{\norm{\mathcal{B}(t_{k+1}^-)}_1}{\norm{\mathcal{B}(t_{k+1}^-) \Tilde{\pi}(t_{k+1}^-)}_1} \Emu{ \norm{ \Tilde{\pi}(t_{k+1}^-) - \Tilde{\pi}^{est}(t_{k+1}^-) }_1 } \\
    &\phantom{\leq} + \frac{1}{\norm{\mathcal{B}(t_{k+1}^-) \Tilde{\pi}(t_{k+1}^-)}_1} \cdot C \varepsilon,
\end{align*}
and the second term can be bounded by
\begin{align*}
    \dots &= \Emu{ \norm{ \mathcal{B}^{est}(t_{k+1}^-) \Tilde{\pi}^{est}(t_{k+1}^-) }_1 \cdot \abs{ \frac{1}{\norm{\mathcal{B}(t_{k+1}^-) \Tilde{\pi}(t_{k+1}^-)}_1} - \frac{1}{\norm{\mathcal{B}^{est}(t_{k+1}^-) \Tilde{\pi}^{est}(t_{k+1}^-)}_1} } } \\
    &= \Emu{ \norm{ \mathcal{B}^{est}(t_{k+1}^-) \Tilde{\pi}^{est}(t_{k+1}^-) }_1 \cdot \abs{ \frac{ \norm{\mathcal{B}^{est}(t_{k+1}^-) \Tilde{\pi}^{est}(t_{k+1}^-)}_1 - \norm{\mathcal{B}(t_{k+1}^-) \Tilde{\pi}(t_{k+1}^-)}_1 }{\norm{\mathcal{B}(t_{k+1}^-) \Tilde{\pi}(t_{k+1}^-)}_1 \cdot \norm{\mathcal{B}^{est}(t_{k+1}^-) \Tilde{\pi}^{est}(t_{k+1}^-)}_1} } } \\
    &= \frac{1}{\norm{\mathcal{B}(t_{k+1}^-) \Tilde{\pi}(t_{k+1}^-)}_1} \Emu{ \abs{ \norm{\mathcal{B}^{est}(t_{k+1}^-) \Tilde{\pi}^{est}(t_{k+1}^-)}_1 - \norm{\mathcal{B}(t_{k+1}^-) \Tilde{\pi}(t_{k+1}^-)}_1 } } .
\end{align*}
Both $\mathcal{B}(t_{k+1}^-) \Tilde{\pi}(t_{k+1}^-)$ and $\mathcal{B}^{est}(t_{k+1}^-) \Tilde{\pi}^{est}(t_{k+1}^-)$ are elementwise nonnegative; thus, the second term is bounded by
\begin{align*}
    \dots &\leq \frac{1}{\norm{\mathcal{B}(t_{k+1}^-) \Tilde{\pi}(t_{k+1}^-)}_1} \Emu{ \norm{\mathcal{B}^{est}(t_{k+1}^-) \Tilde{\pi}^{est}(t_{k+1}^-) - \mathcal{B}(t_{k+1}^-) \Tilde{\pi}(t_{k+1}^-)}_1 }.
\end{align*}
This expression is exactly the first term; therefore, it has the same upper bound.

Inserting all bounds back into \eqref{eq:FMP_error_decomp_jump} yields
\begin{align*}
    \Emu{\norm{\Tilde{\pi}(t_{k+1}) - \Tilde{\pi}^{est}(t_{k+1})}_1} 
    &\leq \frac{2 \norm{\mathcal{B}(t_{k+1}^-)}_1}{\norm{\mathcal{B}(t_{k+1}^-) \Tilde{\pi}(t_{k+1}^-)}_1} \Emu{ \norm{ \Tilde{\pi}(t_{k+1}^-) - \Tilde{\pi}^{est}(t_{k+1}^-) }_1 } \\
    &\phantom{\leq} + \frac{2}{\norm{\mathcal{B}(t_{k+1}^-) \Tilde{\pi}(t_{k+1}^-)}_1} \cdot C \varepsilon.
\end{align*}
Previously, we have shown that $\Emu{ \norm{ \Tilde{\pi}(t_{k+1}^-) - \Tilde{\pi}^{est}(t_{k+1}^-) }_1 } = O(\varepsilon)$; therefore, $$\Emu{ \norm{ \Tilde{\pi}(t_{k+1}) - \Tilde{\pi}^{est}(t_{k+1}) }_1 } = O(\varepsilon).$$ 

Thus, we have shown that, under the induction assumption, $\Emu{ \norm{ \Tilde{\pi}(t) - \Tilde{\pi}^{est}(t) }_1 } = O(\varepsilon)$ for all $t \in [0, t_{k+1}]$. We conclude that the statement of Theorem~\ref{th:sensitivity} is true for all $t \in [0, t_n] = [0, T]$.


\end{proof}



