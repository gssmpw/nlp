This paper provides a framework for dimensionality reduction in a filtering problem for a special class of continuous-time Markov chains, \acfp{SRN}. This work considers a partially observed \acp{SRN} with a high-dimensional hidden state space and noise-free and exact observations. The goal is to estimate the conditional distribution of the hidden states for given observed trajectories. This work employs the \acf{MP} technique originally introduced for forward problems \cite{Hammouda2023MP} and extends it to the filtering problem to address the curse of dimensionality. The aim is to determine an \ac{SRN} of lower dimensionality that preserves the marginal conditional distributions of the original system. The novel approach, called \acf{FMP}, integrates the strengths of the \ac{MP}, \acf{PF} \cite{Rathinam2021PFwithExactState}, and \acf{FFSP} \cite{DAmbrosio2022FFSP}. It comprises two key steps: estimating the propensities of the  projected \ac{SRN} using a computationally efficient \ac{PF} with a sufficiently small number of particles and  solving the resulting low-dimensional filtering problem using \ac{FFSP}.

Several authors have addressed a nonlinear filtering problem for Markov processes with additive Gaussian noise  in the 1960s \cite{Stratonovich1965Conditional, Kushner1967Dynamical, Zakai1969Optimal}. Since then, various numerical algorithms have been developed \cite{Gordon1993PF, Cai1995adaptive, Lototsky1997SpectralApproach, Brigo1999ProjectionOnExp}. Recently, interest has been expressed in an efficient method for approximating the filtering problem for \acp{SRN}.

An \ac{SRN} describes the time evolution of a set of species/agents through reactions and is found in a wide range of applications, such as biochemical reactions, epidemic processes \cite{brauer2012mathematical, anderson2015stochastic}, and transcription and translation in genomics and virus kinetics \cite{srivastava2002stochastic, hensel2009stochastic} (see Section~\ref{subsec:SRNs} for a brief mathematical introduction and \cite{ben2020hierarchical, munker2024generic} for more details, and \cite{goutsias2013markovian} for a broader overview of applications). 

The solution to the filtering problem for the \ac{SRN} is infinite-dimensional; however, one can derive efficient methods for this problem under additional assumptions regarding the distribution shape or the process dynamics. In \cite{Wiederanders2022AutomatedGeneration}, the authors proposed a general framework for deriving equations for conditional moments for several distribution forms. Moreover, the equations for parameters of the exponential family of distributions were also obtained in \cite{Koyama2016ProjectionBased} based on the drift-diffusion approximation. In \cite{Golightly2011particleMCMC}, the authors also applied Langevin approximation to derive the Markov chain Monte Carlo particle method for the filtering problem. In this context, one can further approximate the \ac{SRN} by a linear system, enabling application of the well-known Kalman filter \cite{Folia2018LNAwithKF}. 

Several simulation-based methods called \acfp{PF} have been applied to solve the filtering problem for the \acp{SRN} with noisy observations \cite{Fang2022PF, Fang2023RPF}. This class of methods estimates the \ac{QOI} as an average of the simulated paths, weighted according to their likelihood given the observed trajectory, and employs resampling for numerical stability. There are also versions of the \ac{PF} for the case of noise-free observations \cite{Rathinam2021PFwithExactState, Rathinam2023TargetingAlg}. As an alternative to the \ac{PF}, the authors of \cite{DAmbrosio2022FFSP} developed the \acf{FFSP} method for approximating the conditional distribution as a solution to the filtering equation on a truncated state space. The filtering equation characterizes the evolution of the conditional expectation and is structurally similar to the \ac{CME}, so the complexity of its solution is comparable to the corresponding methods for \ac{CME}. The limitation of these methods is that they are computationally expensive in high dimensions (i.e., for \acp{SRN} with many species). This work presents two approaches to dimensionality reduction to overcome this difficulty. 

This work focuses on the filtering problem with noise-free and continuous in time observations, which was addressed in \cite{Rathinam2021PFwithExactState, Duso2018SelectedNodeSSA, Fang2022CMEmodularization}. We consider a $d$-dimensional \ac{SRN} $\boldsymbol{Z}$ with initial distribution $\boldsymbol{Z}(0) \sim \mu$ and split the state vector as follows:
$$
    \boldsymbol{Z}(t) = \begin{bmatrix}\boldsymbol{X}(t) \\ \boldsymbol{Y}(t) \end{bmatrix}, \quad t \in [0, T],
$$
where $\boldsymbol{X}(t)$ is a hidden part and $\boldsymbol{Y}(t)$ is the observed part. The filtering problem is to estimate the marginal distribution of $\boldsymbol{X}(t)$, given all observations accumulated until time $t$:
\begin{equation}
\nonumber
    \pi_{\boldsymbol{y}} (\boldsymbol{x}, t) := \Probcondmu{\boldsymbol{X}(t) = \boldsymbol{x} }{ \boldsymbol{Y}(s) = \boldsymbol{y}(s), s \leq t }.
\end{equation}
Here and further, the subscript $\mu$ emphasizes the dependence on the initial distribution.

The current numerical methods for the filtering problem are computationally expensive for large systems, e.g., when the system has many reactions with high rates or $\dim (\boldsymbol{X})$ is large. In practice, it is often necessary to estimate only the  marginal (potentially one-dimensional) distribution of some entries of $\boldsymbol{X}(t)$ influenced by only a subset of the reactions. For this case, we propose an approach that reduces the effective dimensionality of the filtering problem using \ac{MP}. The central idea of the \ac{MP} method for the filtering is schematically illustrated in Figure~\ref{fig:MP_diagram}.

\begin{figure}
    \centering
    \resizebox{0.8\textwidth}{!}{
    \begin{tikzpicture}[thick]
        % Define styles
        \tikzstyle{process} = [rectangle, draw, fill=green!20, text width=5cm, text centered, minimum height=1.5cm]
        \tikzstyle{state} = [rectangle, draw, fill=blue!20, text width=5cm, text centered, minimum height=1.5cm]
        \tikzstyle{decision} = [ellipse, draw, fill=cyan!20, text width=5cm, text centered, minimum height=1.5cm]
        \tikzstyle{arrow} = [thick, ->, >=stealth]
        \tikzstyle{dashed_arrow} = [thick, dashed, ->, >=stealth]
    
        % Nodes
        \node[state, fill=blue!30] (fullSRN) {\textbf{full-dimensional} SRN\\ $\boldsymbol{Z}(t) \in \mathbb{Z}^{d}$};
        \node[process, right=8cm of fullSRN] (fullFilter) {Solving  \textcolor{red}{\textbf{\underline{$d$-dimensional}}} system of filtering equations};
        \node[decision, below=3cm of fullFilter] (qoi) {\textbf{Marginal conditional distribution}};
        \node[state, below=3cm  of fullSRN, fill=blue!20] (projSRN) {\textbf{Projected SRN}\\ $\bar{\boldsymbol{Z}}'(t) \in \mathbb{Z}^{d'}$, \textcolor{black}{$d' \ll d$}};
        \node[process, right=1cm of projSRN] (reducedFilter) {Solving \textcolor{blue}{\textbf{\underline{$d'$-dimensional}}} system of filtering equations};
    
        % text nodes
        \node (MP) [text centered, below of=fullSRN,yshift=-0.8cm, text width=4cm, font={\bfseries\sffamily}] {\textbf{Markovian \\ Projection}};
        \node (Marg) [text centered, below of=fullFilter, yshift=-0.8cm, font={\bfseries\sffamily}] {\textbf{Marginalization}};
        
        
        % Arrows
        \draw [dashed] (fullSRN.south east) -- (projSRN.north);
        \draw [dashed] (fullSRN.south west) -- (projSRN.north);
        \draw [arrow] (fullSRN) -- (fullFilter);
        \draw [arrow] (projSRN) -- (reducedFilter);
        \draw [arrow] (reducedFilter.east) -- (qoi);
        \draw [dashed] (fullFilter.south east) -- (qoi.north);
        \draw [dashed] (fullFilter.south west) -- (qoi.north);
    
        % Curse of dim box
        \node[draw=red!50, line width=0.5mm, rounded corners, minimum height=2.7cm, minimum width=6.2cm, xshift=-0.3cm, yshift=0.4cm, inner sep=0pt] at (fullFilter) {};
        \node (CD) [text centered, above of=fullFilter, xshift=-1cm, yshift=0.3cm] { \textcolor{red}{\textbf{Curse of dimensionality}} };
        
    \end{tikzpicture}
    }
    \caption{
    A graphical illustration of the proposed projection methods for the filtering problem. Instead of solving a full $d$-dimensional system of filtering equations, \ac{MP} methods approximate the \ac{SRN} dynamics by another \ac{SRN} of lower dimensionality $d' \ll d$, allowing to work with significantly smaller system of filtering equations.
    }
    \label{fig:MP_diagram}
\end{figure}

The general idea of \ac{MP} is to mimic the marginal distribution of a multidimensional process via another Markov process of lower dimensionality. This approach was first proposed in \cite{Gyongy1986MP} for It\^o processes and has been employed in many applications \cite{piterbarg2006markovian, Bayer2019Implied, Bentata2009Mimicking}. Recently, this method was also applied to the \acp{SRN} to derive an efficient importance sampling \ac{MC} estimator for rare event probabilities by reducing the dimensionality of the underlying model \cite{Hammouda2023MP}, and to solve the \ac{CME} \cite{ocal2023model}. 

This work examines the \ac{MP} method for dimensionality reduction and extends it to the filtering problem with exact observations. The main contributions of this work are summarized as follows:
\begin{itemize}
    \item A dimensionality reduction for the filtering problem, based on the standard \ac{MP} method \cite{Hammouda2023MP}. Moreover, we provide an alternative proof for the \ac{MP} theorem (Theorem~\ref{th:MP}) in the context of \acp{SRN}.
    \item A novel projection method for dimensionality reduction for the filtering problem, \ac{FMP}, which  preserves the marginal conditional distribution (Theorem~\ref{th:FMP}).
    \item A numerical filtering algorithm developed based on the \ac{FMP} (Algorithm~\ref{alg:FMP_FFSP}), a combination of a \ac{PF} for estimating projected propensities and \ac{FFSP} for numerically solving the reduced dimensional filtering equations.
    \item An error analysis showing the convergence rate of the \ac{FMP} algorithm (Corollary~\ref{corollary:FMP_error_PF}) based on sensitivity analysis of the filtering problem with respect to perturbations in propensity functions (Theorem~\ref{th:sensitivity}).
    \item Numerical examples for large reaction networks highlighting the superior efficiency of projection methods over existing filtering algorithms.
\end{itemize}

The outline of this paper is as follows. The introduction provides the mathematical background of the \ac{SRN} models and discusses the filtering problem. Section~\ref{sec:2_MP} describes the adaptation of the standard \ac{MP} approach and its limitations in the filtering problem. Next, Section~\ref{sec:3_FMP} extends these ideas and presents a novel \ac{FMP} approach as a natural generalization of \ac{MP} for the filtering problem. It also provides an error analysis of the \ac{FMP} method, followed by two numerical examples  and a final discussion.

