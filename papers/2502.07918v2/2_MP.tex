To reduce dimensionality while maintaining the Markov property, we propose to use the \acf{MP} approach, which was originally derived for It\^o processes \cite{Gyongy1986MP, Bayer2019Implied} and recently adapted for \acp{SRN} \cite{Hammouda2023MP}. This approach is naive because it applies the \ac{MP} framework derived for the forward problem without conditioning on observations. The aim is to construct a $d'$-dimensional process $\bar{\boldsymbol{Z}}'$ with the same marginal (in time) distribution as $\boldsymbol{Z}'$. The crucial point is that this surrogate $\bar{\boldsymbol{Z}}'$ (unlike $\boldsymbol{Z}'$) is Markovian, allowing the filtering problem to be solved with classical methods.

\begin{theorem}[Markovian projection for \acp{SRN}]
    \label{th:MP}
    Let $\boldsymbol{Z}(t) = \begin{bmatrix} \boldsymbol{Z}'(t) \\ \boldsymbol{Z}''(t)\end{bmatrix}$ be a non-explosive (i.e., satisfying~\ref{eq:non_expl_cond}) \ac{SRN} with initial distribution $\mu$. 
    A $d'$-dimensional stochastic process $\bar{\boldsymbol{Z}}'$ via independent Poisson processes $\bar{R}_1, \dots, \bar{R}_J$ is defined as follows:
    \begin{equation}
    \label{eq:MP_model}
        \bar{\boldsymbol{Z}}'(t) = \bar{\boldsymbol{Z}}'(0) + \sum_{j=1}^{J}  \bar{R}_j \left( \int_0^t \bar{a}_j \left( \bar{\boldsymbol{Z}}'(s), s \right) \diff s \right) \boldsymbol{\nu}_{j}' , \quad t \in [0,T]
    \end{equation}
    with 
    \begin{equation}
    \label{eq:MP_a_bar_def}
        \bar{a}_j (\bar{\boldsymbol{z}}', t) := \Econdmu{ a_j(\boldsymbol{Z}(t)) }{ \boldsymbol{Z}'(t) = \bar{\boldsymbol{z}}'}, \quad \bar{\boldsymbol{z}}' \in \mathbb{Z}_{\geq 0}^{d'}
    \end{equation}
    and $\bar{\boldsymbol{Z}}'(0) \overset{d}{=} \boldsymbol{Z}'(0)$. \footnote{The symbol $\overset{d}{=}$ denotes the equality in distribution.} Then, $\bar{\boldsymbol{Z}}'(t)$ has the same distribution as $\boldsymbol{Z}'(t)$ for all $t \in [0, T]$.
\end{theorem}


\begin{proof}
    One can derive the statement from \cite[Theorem 3.1]{Hammouda2023MP}. Appendix~\ref{sec:MP_proof} also provides an alternative proof using the \ac{CME}.
\end{proof}


Theorem~\ref{th:MP} allows the construction of another \ac{SRN} $\bar{\boldsymbol{Z}}'$ containing only the species necessary for the filtering problem \eqref{eq:filtering_problem_margin} while preserving the marginal (in time) conditional distribution. Similar to $\boldsymbol{Z}'$, we split $\bar{\boldsymbol{Z}}' = \begin{bmatrix} \bar{\boldsymbol{X}}' \\  \bar{\boldsymbol{Y}}' \end{bmatrix}$ and define the \ac{MP} filtering problem as follows:
\begin{equation}
    \label{eq:pi_bar_def}
    \bar{\pi}'_{\boldsymbol{y}} (\boldsymbol{x}', t) := \Probcondmu{\bar{\boldsymbol{X}}'(t) = \boldsymbol{x}' }{ \bar{\boldsymbol{Y}}(s) = \boldsymbol{y}(s), s \leq t }.
\end{equation}
As $\dim{\bar{\boldsymbol{X}}'} = \dim{\boldsymbol{X}}' <  \dim{\boldsymbol{X}}$, it is expected that the \ac{MP} filtering problem can be solved much more efficiently than the original problem. In particular, for the \ac{FFSP} method, the truncated state space $\mathsf{X}'_N$ of $\bar{\boldsymbol{X}}'$ contains significantly fewer states than $\mathsf{X}_N$, and hence, fewer equations. 

Moreover, the projected \ac{SRN} may have fewer reactions because some $\nu_j'$ may be null vectors, especially when  $\dim{\boldsymbol{X}}' \ll  \dim{\boldsymbol{X}}$. Without loss of generality, we denote $\{ 1, \dots, J' \}$ with $J' \leq J$ the indices of reactions in the projected \ac{SRN}. All observed reactions from $\mathcal{O}$ are preserved, and the set of projected hidden reactions $\mathcal{U}'$ may be smaller than the set $\mathcal{U}$ for the full-dimensional system.

\begin{remark}
    New propensities $\{\bar{a}_j\}_{j=1}^{J'}$ depend not only on a current state $\bar{\boldsymbol{z}}'$ but also on time $t$, which can introduce some challenges. Algorithms adapted to time-dependent propensity functions (e.g., the modified next reaction method \cite[Section~5]{Anderson2007ModifiedNextReaction}) must be applied to simulate $\bar{\boldsymbol{Z}}'$.
\end{remark}

Applying the standard \ac{MP} to the filtering problem consists of two steps. The first step is to compute the \ac{MP} propensities \eqref{eq:MP_a_bar_def}. Some of the propensities can be computed analytically, whereas others can be approximated using the \ac{MC} estimator:
\begin{equation}
\label{eq:a_bar_est}
    \bar{a}_j (\bar{\boldsymbol{z}}', t) \approx \frac{\sum\limits_{i=1}^{M} 1_{\{ {\boldsymbol{Z}}_i'(t) = \bar{\boldsymbol{z}}' \}} a_j({\boldsymbol{Z}}_i(t)) }{ \sum\limits_{i=1}^{M} 1_{\{ {\boldsymbol{Z}}_i'(t) = \bar{\boldsymbol{z}}' \}} },
\end{equation}
where $\{ \boldsymbol{Z}_i \}_{i=1}^{M}$ are independent realizations of the full-dimensional process $\boldsymbol{Z}$. In practice, for some $(\bar{\boldsymbol{z}}', t)$, this estimate could be unreliable or singular due to the denominator being close to zero. In such cases, we reject the estimate and use extrapolation based on reliable estimates. 

The second step is solving the filtering equations for the \ac{MP}-\ac{SRN} of a lower dimensionality using the \ac{FFSP} method. 

Algorithm~\ref{alg:MP_FFSP} presents overall scheme for solving the filtering problem using the standard \ac{MP} approach.

The overall scheme for solving the filtering problem with the naive \ac{MP} approach is given in Algorithm~\ref{alg:MP_FFSP}.


\begin{remark}
    Other methods can be used to estimate the projected propensities, e.g., the discrete $L^2$ regression \cite[Section~3.2]{Hammouda2023MP}, which is efficient if the shape of the projected propensity functions is known.
\end{remark}

\begin{algorithm}[H]
\caption{Standard \ac{MP} approach for the filtering problem}
\label{alg:MP_FFSP}
\begin{algorithmic}[1]
    \Require Initial distribution $\pi(\cdot, 0)$ according to \eqref{eq:pi0_def}, observations: jump times $t_1, \dots, t_n$ and values $\boldsymbol{y}(t_1), \dots, \boldsymbol{y}(t_n)$, sample size $M$, truncated state space $\mathsf{X}'_N$ for $\bar{\boldsymbol{X}}'$
    \State Sample $\boldsymbol{Z}_1(0), \dots, \boldsymbol{Z}_M(0)$ from $\mu$
    \For{$k \in \{ 0 \dots n \}$}
        \State Simulate $\{\boldsymbol{Z}_i(t)\}_{i=1}^M$ for  $t \in [t_k, t_{k+1}]$ from the full-dimensional \ac{SRN} $\boldsymbol{Z}$ using the \ac{SSA}
        \State Estimate $\{\bar{a}_j (\cdot, t)\}_{j=1}^{J'}$ for $t \in [t_k, t_{k+1}]$ using \eqref{eq:a_bar_est} and extrapolation for the \ac{MP}-\ac{SRN} $\bar{\boldsymbol{Z}}$ 
        \State Compute $\bar{\rho}_{\boldsymbol{y}}'(\cdot, t)$  for the \ac{MP}-\ac{SRN} $\bar{\boldsymbol{Z}}$ for $t \in [t_k, t_{k+1})$ by applying \ac{FFSP} to \eqref{eq:filtering_equation_rho}
        \State Compute $\bar{\rho}_{\boldsymbol{y}}'(\cdot, t)$  for the \ac{MP}-\ac{SRN} $\bar{\boldsymbol{Z}}$ for $t = t_{k+1}$ by applying \ac{FFSP} to \eqref{eq:filtering_equation_rho_jump}
        \State Compute $\bar{\pi}_{\boldsymbol{y}}'(\cdot, t)$ for $t \in [t_k, t_{k+1}]$ by normalizing  $\bar{\rho}_{\boldsymbol{y}}'(\cdot, t)$ according to  \cite{DAmbrosio2022FFSP}
    \EndFor
\end{algorithmic}
\end{algorithm}

There is no guarantee that $\bar{\pi}'_{\boldsymbol{y}}$ defined in \eqref{eq:pi_bar_def} equals to the distribution of interest $\pi'_{\boldsymbol{y}}$ from \eqref{eq:filtering_problem_margin} because the filtering problem has a condition on the past process states, whereas the \ac{MP} theorem states only that marginal (in time) distributions of $\bar{\boldsymbol{Z}}'(t)$ and $\boldsymbol{Z}'(t)$ coincide for any fixed $t$. The following section proposes a new \ac{MP} method explicitly designed for the filtering problem to resolve this inconsistency.



