\section{Preliminary}
\label{sec:Preliminary}
% 补充一下IK和IDK的部分
\paragraph{\textit{(Definition 1. RAIT Dataset)}} 
The RAIT process can be described as follows: the initial LLM is prompted to answer all questions in the training set $D_{\text{src}}$. Based on the correctness of the responses, the samples are categorized into two groups. 
\textit{\textbf{\ding{182}}} Samples with correct responses are considered known knowledge of the LLM. These answers will remain unchanged and are referred to as \texttt{ik} samples, denoted as $D_{\text{ik}} = \{(x_{\text{ik}}, y_{\text{ik}})\}$ (where `ik' stands for `I know', $x_{\text{ik}}$ is the known question and $y_{\text{ik}}$ is the ground-truth label). \textit{\textbf{\ding{183}}} Conversely, samples with incorrect responses are treated as unknown knowledge. Their original answers are replaced with refusal responses such as ``I don't know'' forming $D_{\text{idk}} = \{(x_{\text{idk}}, y_{\text{idk}})\}$ (where `idk' stands for `I don't know', $x_{\text{ik}}$ is the unknown question and $y_{\text{ik}}$ is modified refusal response such as ``I don't know''). 
The constructed RAIT dataset, $D_{\text{rait}} = D_{\text{ik}} \cup D_{\text{idk}}$, is used to fine-tune the initial LLM, parameterized by $\theta$, to improve its ability to refuse to answer questions beyond its knowledge.

\paragraph{\textit{(Definition 2. Influence Formulation)}}
To estimate the influence of a training datapoint on a validation sample, we use the first-order Taylor expansion of the loss function \cite{Pruthi_Liu_Kale_Sundararajan_2020}\footnote{The reasons for using the influence formula are outlined in the appendix \ref{app:Reasons for Choosing Influence Formula}}. Specifically, for a model $\theta_t$ at step $t$, the loss on unobservant validation sample $x^{u}$ can be approximated as:
$
\mathcal{L}(x^{u},y^{u}; \theta_{t+1}) \approx \mathcal{L}(x^{u},y^{u}; \theta_t) + \langle \nabla \mathcal{L}(x^{u},y^{u}; \theta_t), \theta_{t+1} - \theta_t \rangle.
$
If the model is trained using Stochastic Gradient Descent (SGD) with batch size 1 and learning rate $\eta_t$, for the observant training sample $x^o$, the SGD update is written as:
$
\theta_{t+1} - \theta_t = -\eta_t \nabla \mathcal{L}(x^{o},y^{o}; \theta_t).
$
At this point, we can define the influence formula of $(x^{o},y^{o})$:
\begin{equation}
\small
\label{eq:influence_equation}
\begin{aligned}
\mathcal{I}(x^{o},y^{o},x^{u},y^{u}; \theta_{t}) \stackrel{\triangle}{=} & ~ \eta_t \langle \nabla \mathcal{L}(x^{o},y^{o}; \theta_t), \\ \quad \quad
& \nabla \mathcal{L}(x^{u},y^{u}; \theta_t) \rangle.
\end{aligned}
\end{equation}

\paragraph{\textit{(Task Definition)}}
The objective of this task is to leverage $D_{\text{rait}}$ to fine-tune a model and minimize the loss on two distinct types of test samples. Specifically, for samples that were previously incorrect, we aim for the model to output answers like ``I don't know'', while for correct samples, the predicted label should be as close as possible to the ground-truth label $y_{\text{ik}}$
% , improving upon the original model's performance
. The task can be formalized as minimizing the following loss:
\begin{equation}
\small
\begin{aligned}
\label{eq:task}
\min \bigl \{ \mathbb{E}_{x^{u}_{{\text{idk}}} \sim D_{{\text{idk}}}} &\left[ \Delta \mathcal{L}(x^{u}_{{\text{idk}}}, y^{u}_{{\text{idk}}}; \theta) \right ]\\ +& \mathbb{E}_{x^{u}_{{\text{ik}}} \sim D_{{\text{ik}}}} \left[ \Delta \mathcal{L}(x^{u}_{{\text{ik}}}, y^{u}_{{\text{ik}}}; \theta) \right ] \bigl\},
\end{aligned}
\end{equation}
In addition to minimizing it, a key objective of this task is to select the most suitable subset $\widetilde{D}_{\text{rait}} \subseteq D_{\text{rait}}$ for fine-tuning (c.f. Section~\ref{sec:Theoretical Analysis} for proof). By selecting optimal data from the RAIT dataset, we aim to improve the model's ability to refuse answers to unknown questions while minimizing over-refusal.

\section{Theoretical Analysis}
\label{sec:Theoretical Analysis}
This part is organized as $\mathbf{O}_1 \to \mathbf{O}_2$. Before obtaining formal observation results, we first propose two assumptions:

\paragraph{\textit{Assumptions 1. Distribution Assumption}}
\textit{We assume that the distributions of \texttt{ik} or \texttt{idk} from train and test sets are identically distributed, formally expressed as:}
$
\Pi_{D_{\text{idk}}^o} \sim \Pi_{D_{\text{idk}}^{u}},  \Pi_{D_{\text{ik}}^o} \sim \Pi_{D_{\text{ik}}^{u}}
$.

\paragraph{\textit{Assumptions 2. Orthogonality of Means}}
\textit{We further assume that the means of the gradient distributions for \texttt{idk} and \texttt{ik} are orthogonal as verified in Appendix~\ref{subsec:orthogonal_experiment}, and we have:}
\begin{equation}
\small
\label{eq:loss_decomposition}
\begin{aligned}
\Bigl \langle \mathbb{E}_{x_{*} } \left[ \nabla \mathcal{L}(x_{*},y_{\text{idk}}; \theta) \right],
\mathbb{E}_{x_{*} } \left[ \nabla \mathcal{L}(x_{*},y_{\text{ik}}; \theta) \right]
\Bigr \rangle \approx 0,
\end{aligned}
\end{equation}
where the \( * \) denotes the symbol of either \texttt{idk} or \texttt{ik}.

\subsection{Reducing Incorrectness ($\mathbf{O}_1$)}
\label{sec:Reducing Incorrectness}
We begin by focusing on minimizing the loss to improve the rejection rate, specifically aiming to minimize the first term of \eqref{eq:task} $\mathbb{E}_{x^{u}_{\text{idk}} \sim D_{\text{idk}}} \left[ \Delta \mathcal{L}(x^{u}_{\text{idk}}, y^{u}_{\text{idk}}; \theta) \right]$. Then, combining equation~\eqref{eq:influence_equation}, we can express this as:
\begin{equation}
\small
\label{eq:loss_decomposition_short}
\begin{aligned}
&\mathbb{E}_{x^{u}_{\text{idk}} \sim D_{\text{idk}}} \bigl[ \Delta \mathcal{L}(x^{u}_{\text{idk}}, y^{u}_{\text{idk}}; \theta) \bigl]  
\approx 
- \mathbb{E} _{(x^{u} _{\text{idk}}, x^o _{\text{idk}}) \sim D _{\text{idk}}} \\  &\left[ \mathcal{I}(x^{o} _{\text{idk}}, y^{o} _{\text{idk}}, x^{u} _{\text{idk}}, y^{u} _{\text{idk}}; \theta) \right]
\end{aligned} \noindent
\end{equation}
and the full proof is detailed in Appendix~\ref{app:More Proof on O1}.

Thus, samples with gradients similar to the average gradient direction of $D_{\text{idk}}$ are the most effective in reducing the model's hallucination rate.

\subsection{Alleviating Over-Refusal ($\mathbf{O}_2$)}
\label{sec:Alleviating Over-Refusal}
However, we observed that if we optimize the model merely depends on RAIT,
it leads to the issue of \textbf{over-refusal} (i.e., \texttt{ik} samples also tend to output ``I don't know''). Therefore, we delved deeper into the whole target in \eqref{eq:task} and derived the following( the full proof is detailed in Appendix \ref{app:More Proof on O2}):
\begin{equation}
\small
\label{eq:O2}
\begin{aligned}
&\mathbb{E}_{x^{u}_{\text{idk}} \sim D_{\text{idk}}} \left[ \Delta \mathcal{L}(x^{u}_{\text{idk}}, y^{u}_{\text{idk}}; \theta) \right ] 
+ \mathbb{E}_{x^{u}_{\text{ik}} \sim D_{\text{ik}}} \left[ \Delta \mathcal{L}(x^{u}_{\text{ik}}, y^{u}_{\text{ik}}; \theta) \right ] \\ 
\approx & - \left \{ \mathbb{E} _{x^{u} _{idk}, x^o _{idk} \sim D _{idk}} \left[ \mathcal{I}(x^{o} _{\text{idk}}, y^{o} _{\text{idk}}, x^{u} _{\text{idk}}, y^{u} _{\text{idk}}; \theta) \right] \right.  -\\
\quad &  \left . \mathbb{E} _{x^{u} _{\text{ik}} \sim D _\text{{ik}}, x^{o} _{\text{idk}} \sim D _{\text{idk}}} \left[ \mathcal{I}(x^{o} _{\text{idk}}, y^{o} _{\text{idk}}, x^{u} _{\text{ik}}, y^{u} _{\text{idk}}; \theta) \right] \right \}
\end{aligned} \noindent
\end{equation}


The first expectation term in equation \eqref{eq:O2} captures the reduction in the model's error rate, while the second term reflects the occurrence of over-refusal. Training samples where the difference between these two terms is smaller tend to exacerbate over-refusal, though they may also contribute to stronger overall model performance.

