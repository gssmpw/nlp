\section{Related Work}
\label{sec:Related Work}
% p1: 拒绝回答；  
\subsection{Refusal-Aware Instruction Tuning}
RAIT is a supervised technique designed to enhance the ability of LLMs to handle unanswerable or uncertain questions by training them to respond directly with ``I don't know''~\cite{R_Tuning,alignment_for_honesty,zhu2024utilizeflowsteppingriver} through supervised fine-tuning (SFT). 
In \citet{wan2024mitigating}, a knowledge-based verification mechanism is proposed to ensure that the model's knowledge remains consistent with external trusted sources to prevent the spread of misinformation.
Moreover, CoKE~\cite{cokeee} probes LLMs' knowledge boundaries via internal confidence given a set of questions and then informs the LLM's decision on whether to respond with ``I don't know'' based on the knowledge boundaries. Additionally, \citep{zhu2024utilizeflowsteppingriver} and \citep{ula} refine data filtering and modification by leveraging both response certainty and correctness.
Recent works have incorporated Low-Rank Adaptation (LoRA)~\cite{hulora} and AdaLoRA~\cite{Wolfe_2024} into RAIT to achieve further improvements. However, those RAIT methods tend to make LLMs more conservative, leading to incorrect and even \textbf{over-refusals}~\cite{cheng2024can}.

% p2: 梯度，less，entk，涟漪效应
\subsection{Gradient Effect on LLMs' Learning}
Gradient-based methods are central to recent advances in data selection. For instance, \citep{zhao2021dataset,Xia_Malladi_Gururangan_Arora_Chen,yang2024smalltolarges2lscalabledata} propose \textit{Dataset Condensation}, where synthetic data is created by matching the gradients or the learning trajectory of a deep model trained on a small synthetic set to those of a model trained on the full dataset. Similarly, \citep{killamsetty2021gradmatch,killamsetty2021subset} extend this concept with their \textit{Grad-Match} framework, which selects subsets of data that closely align with the gradient information from the full dataset, allowing for efficient training with minimal performance degradation.
More recently, \citep{ren2024learningdynamics,zhao2020dataset,qiao2024PGP,Bai_Zhang_Tao_Wu_Wang_Xu_2023} emphasize that gradients can dynamically influence the learning process of LLMs during fine-tuning. 
\citep{Liu_Jiang_Bai_Chen_Wang_2020,Xiao2024CertifiedRobustness} study the influence of gradient signal-to-noise ratio's result on the test set.
While gradient-based selection techniques are widely studied, applying these methods to RAIT to mitigate issues such as hallucinations and over-refusal remains largely unexplored, which presents an opportunity for further research in RAIT.