\section{Conclusion and Future Work}
\label{sec:Conclusion}
In this paper, we present \M, a Gradient-based Refusal-Aware Instruction Tuning Framework, which addresses the critical challenge of over-refusal in existing RAIT approaches. By leveraging insights derived from a gradient perspective, \M effectively distills refusal-aware datasets and incorporates an adaptive weighting mechanism during fine-tuning. Our experimental results demonstrate that \M not only mitigates hallucinations but also enhances the reliability and accuracy of LLM outputs.
Looking ahead, we aim to further investigate two key avenues of research. First, we plan to explore the dynamic trajectory influence of gradients throughout the RAIT process, which could provide deeper insights into how various training samples impact LLM refusal behavior. Second, we intend to examine the role of \M in detecting knowledge boundaries within LLMs, focusing on its potential contributions to enhancing LLM safety.

