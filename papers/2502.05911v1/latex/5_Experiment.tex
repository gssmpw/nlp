\section{Experiment}
\label{sec:Experiment}
In this section, we provide detailed information on experimental setup, and further analysis to validate the performance and rationality of \M.


\subsection{Experiment Setup}
\paragraph{Datasets.}
In this study, we assess the efficacy of \M in handling two distinct types of Question and Answering tasks: the knowledge-based Multiple Choice Question Answering (MCQA) and Open-ended Question Answering (OEQA). For the MCQA task, the test split of MMLU~\cite{MMLU} is adopted as the training dataset, while the validation split of the same serves as the In-Domain (ID) test set, and the ARC-c~\cite{ARC_C} test split is utilized as the Out-Of-Domain (OOD) test set. In the context of the OEQA task, we use the training split of TriviaQA~\cite{triviaqa} for training purposes, the development split of TriviaQA as the ID test set, and the validation split of NQ~\cite{nq} as the OOD test set. Additional information is provided in Table~\ref{table:dataset_details}.

\begingroup
\fontsize{9}{11}\selectfont
\setlength{\tabcolsep}{1mm}
% {\fontsize{9pt}{11pt}\selectfont
\begin{table}[h]
\centering
\caption{Datasets Details.}
\resizebox{1.0\linewidth}{!}{
\begin{tabular}{lcc}
\toprule
\textbf{} & \textbf{MCQA} & \textbf{OEQA} \\ 
\midrule
\textbf{Train}     & MMLU test (14,079)     & TriviaQA train (87,622)    \\ 
\textbf{ID Eval}   & MMLU val (1,540)       & TriviaQA dev (11,313)      \\ 
\textbf{OOD Eval}  & ARC-c dev (1,172)      & NQ dev (3,610)             \\ 
\bottomrule
\end{tabular}}
\label{table:dataset_details}
\end{table}
\endgroup



\paragraph{Baselines.}
To evaluate the performance of \M, we conducted comparisons with several existing approaches:
\textbf{Init-Basic}: Employs the initial LLM setup, utilizing standard question-answering prompts to guide the model in generating answers.
\textbf{Init-Refuse}: Builds on Init-Basic by incorporating instructions such as ``\textit{If you do not know the answer, please respond with `I don't know.'}'' to promote safer responses~\cite{bianchi2024safetytunedllamaslessonsimproving,zhangdefending}.
\textbf{Van-Tuning}: Randomly selects \(N_{\text{ik}} + N_{\text{idk}}\) samples from \(D_{\text{src}}\) for straightforward instruct-tuning, without any sample modification.
\textbf{R-Tuning}: Follows the settings from \cite{R_Tuning}, where samples in the RAIT dataset are modified based on the correctness of the model's replies.
\textbf{CRaFT}: This method is implemented according to~\cite{zhu2024utilizeflowsteppingriver}, addressing both static and dynamic conflicts within the RAIT dataset to provide a thorough evaluation of potential issues.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.7\linewidth]{figure/metric.pdf}
    \caption{Illustration of Truthful Helpfulness Score.}
    \label{fig:metric}
\end{figure}

\paragraph{Evaluation Metrics.}

We utilize the Truthful Helpfulness Score (THS) as detailed by~\cite{zhu2024utilizeflowsteppingriver} to assess the performance of LLMs after RAIT. Accuracy (\(P_c\)), error rate (\(P_w\)), THS, etc. are key metrics for evaluating the performance of models after RAIT. Among these, \(P_c\) and \(P_w\) form a competing pair, where optimizing for \(P_c\) often leads to a decline in \(P_w\). Focusing on only one of these metrics is insufficient to evaluate the model’s overall capability.
Thus, a singular and comprehensive metric is required to simplify the assessment process and eliminate the complexity of balancing multiple trade-off metrics.

For each test sample, we classify the response as correct, incorrect, or refused. From these categories, we calculate the accuracy (\(P_c\)), error rate (\(P_w\)), and refusal rate (\(P_r\)). We then set up a Cartesian coordinate system with \(P_c\) and \(P_w\) on the axes. The point \(S_1\) represents the coordinates of the baseline LLM, and \(S_2\) corresponds to the refined model.
If \(S_2\) is positioned below the line from the origin \(O\) to \(S_1\) (denoted as \(OS_1\)), then a larger area of the triangle \(\triangle OS_1S_2\) signifies an improvement in the model. If, however, \(S_2\) is above \(OS_1\), it indicates a reduction in performance. As shown in Figure \ref{fig:metric}, THS is defined as the ratio of the cross product of vectors \(\overrightarrow{OS_1}\) and \(\overrightarrow{OS_2}\) to the maximum possible value of this cross product:


\begin{equation}
\small
\label{eq:loss_decomposition}
\begin{aligned}
\text{THS} = (\overrightarrow{OS_2} \times \overrightarrow{OS_1}) / (\overrightarrow{OU} \times \overrightarrow{OS_1}).
\end{aligned}
\end{equation}

\input{latex/5_Experiment_Tables}

\paragraph{Implementation Details.}

In our studies, we utilized LLaMA2-7B-Chat and LLaMA3-8B-Instruct as the initial LLMs \( \theta_0 \). For the MCQA task, we selected 5,000 samples from the MMLU dataset for training purposes, and for the OEQA task, 10,000 samples from TriviaQA were used. With the exception of the Van-Tuning setting, where all samples were kept unchanged, other RAIT settings used a 1:4 ratio of \texttt{ik} samples to \texttt{idk} samples. In the MCQA and OEQA tasks, correctness is obtained using 5-shot and 3-shot setups\footnote{The reasons for using the few-shot settings are outlined in the appendix \ref{A5}}, respectively. More implementation details are listed in Appendix~\ref{app:imple}. In contrast to \cite{zhu2024utilizeflowsteppingriver}, to ensure the fairness of the experiments, we employ LoRA for training across both MCQA and OEQA tasks.

During both training and testing phases, XTuner~\footnote{https://github.com/InternLM/xtuner} was employed for RAIT experiments, which were conducted over 3 epochs with a maximum context length set to 2048. The LoRA~\cite{hulora} was implemented with the parameters: \(r=64\), \(\alpha=16\), dropout rate of 0.1, and a learning rate of \(2 \times 10^{-4}\). For evaluations, the 0-shot approach with greedy decoding was adopted. OpenCompass~\footnote{https://github.com/open-compass/opencompass} is used for all evaluations and correctness calculations. In the \M method, we assigned the hyperparameter \(\mathcal{T}_{\mathcal{C}}\) a value of 0.5 and \(\tau\) a value of 0.05. All experiments were executed on eight NVIDIA A100-80GB GPUs.




\subsection{Experiment Results}
We present the main experimental results, along with an ablation study of \M across various models in Table~\ref{table:main table}. A summary of the key findings is provided below.

\subsubsection{Main Results}
We assess the effectiveness of \M by addressing the challenges \textbf{\textit{C1}} and \textbf{\textit{C2}}, with the corresponding experimental results presented in Table~\ref{table:main table}. \\
\textbf{Comparison based on \textit{C1}:} \textbf{\textit{C1}} relates to the metric \(P_w\), where a lower \(P_w\) indicates better avoidance of hallucinations by the model. As shown in the results, our proposed \M achieves a significantly lower \(P_w\) compared to other baselines, demonstrating its effectiveness in reducing hallucination rates. \\
\textbf{Comparison based on \textit{C2}:} \textbf{\textit{C2}} focuses on minimizing hallucinations while maintaining accuracy, addressing the challenge of over-refusal. 
% To evaluate this, we use the Truthful Helpfulness Score (THS). 
\M surpasses existing methods in THS score with an average of 3.66.
Specifically, the THS results clearly show that our method significantly outperforms other baselines on both in-domain (ID) and out-of-domain (OOD) settings. For instance, on MMLU dataset, the LLaMA2-7B-Chat model achieves a THS score of 19.3, whereas the best-performing baseline, CRaFT, only reaches 12.5. Moreover, our approach consistently demonstrates superior performance on OOD datasets as well.

\subsubsection{Ablation Study}
We conduct ablation studies to evaluate the contribution of each component in \M, as presented in Table~\ref{table:main table}, using two variants: (1) \M without Refusal Influence, which follows the R-Tuning approach during the dataset distillation phase (denoted as \texttt{w/o} $\mathbf{O}_1$), and (2) \M without Stable Influence, where no weight adjustment is applied to emphasize the importance of \texttt{idk} samples (denoted as \texttt{w/o} $\mathbf{O}_2$). The results indicate that each component contributes positively to the overall performance of \M and the removal of any component leads to a noticeable decline in effectiveness. Specifically, replacing Refusal Influence-based dataset distillation with other baselines results in a significant increase in hallucination rate, underscoring the importance of Refusal Influence in addressing \textbf{\textit{C1}}. Additionally, the use of Stable Influence helps reduce over-refusal while maintaining a stable hallucination rate, effectively addressing the challenges posed by \textbf{\textit{C2}}. In addition, we conducted sensitivity experiments, the details of which can be found in the appendix \ref{A6}.

% \subsubsection{Sensitivity Study}
% \textbf{The effect of temperature on sample weight.} We analyzed the Stable Influence of the samples discussed in Stage 3 of \M and found that its values were relatively small. Consequently, it was necessary to adjust the temperature to better normalize the weight of each sample. To investigate the specific effects of temperature adjustments, we conducted experiments using the MMLU dataset and the LLaMA3-8B-Instruct model.
% 敏感性实验做完了，但是信息量太少不好画图展示，可能只能画表格
% T = [0.01, 0.05, 0.1, 0.2, 0.5, 1]
% THS = [36.6, 36.4, 36.5, 35.9, 35.5, 35.5]
% T_C = [0.3, 0.4, 0.5, 0.6, 0.7]
% THS = [37.4, 36.7, 36.4, 36.4, 36.3]

\begin{figure}[t]
    \centering
    % \vspace{-1.5cm}
    \includegraphics[width=1.0\linewidth]{figure/analysis.pdf}
    % \vspace{-0.74cm}
    \caption{Relationship between \(\mathcal{I}^{\text{ref}}\) and \(\mathcal{I}^{\text{over}}\) in MMLU performance on LLaMA2-7B-Chat and LLaMA3-8B-Instruct.}
    % \vspace{-0.3cm}
    \label{fig:analysis}
\end{figure}

\subsection{Analysis}
\textbf{The selection of \texttt{ik} samples is crucial.} Our analysis and experiments primarily focus on optimizing the selection of \texttt{idk} samples. However, the selection of \texttt{ik} samples is also crucial. We employed three different strategies: \texttt{ik-random}, where data is randomly selected from $D_{\text{ik}}$; \texttt{ik-bottom}, where the data with the lowest correctness from $D_{\text{ik}}$ is selected; and \texttt{ik-top}, the method used in \M, where the data with the highest correctness from $D_{\text{ik}}$ is chosen. We used the MMLU (ID) and ARC-c (OOD) datasets and conducted experiments with the LLaMA3-8B-Instruct model. The results are shown in Table 3. When using either the \texttt{ik-bottom} or \texttt{ik-random} methods, the model's hallucination reduction does not improve, and the refusal rate remains low. We believe the potential reason for this is that the \texttt{ik} samples selected by these methods may share similar characteristics with the \texttt{idk} samples, but different supervision signals were applied during the SFT process. This weakens the model’s ability to learn effective refusals. In contrast, the \texttt{ik-top} strategy used in \M helps to distinctly separate the features of the two types of samples, addressing the static conflict mentioned in \cite{zhu2024utilizeflowsteppingriver}.

\input{latex/5_Experiment_Analysis_Tables}


\textbf{Over-Refusal can only be alleviated, but not completely eliminated.}
During the RAIT process, we observed and analyzed the \texttt{idk} influence (corresponding to $O_{2}$) of \texttt{idk} samples on $D_{\text{ik}}$ and $D_{\text{idk}}$ using the LLaMA2-7B-Chat and LLaMA3-8B-Instruct model on the MMLU dataset. As shown in Figure~\ref{fig:analysis}, we identified a strong correlation between the two, with a Pearson Correlation Coefficient of 0.886. This correlation may be a contributing factor to the occurrence of Over-Refusal. While our proposed method, as indicated in Table~\ref{table:main table}, cannot fully eliminate Over-Refusal due to certain limitations, it significantly mitigates the issue.

