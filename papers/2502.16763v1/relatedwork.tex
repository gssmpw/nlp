\section{Literature Review}
The NTK framework \citep{NEURIPS2018_5a4be1fa} is a popular framework designed to provide insights into the continuous-time gradient descent (gradient flow) dynamics of fully connected feed-forward neural networks with widths tending to infinity. The initial results have been extended to discrete gradient descent \citep{NEURIPS2019_0d1a9651} as well as generalized to more architecture families like RNNs and Transformers \citep{yang2020tensorprogramsiineural, yang2021tensorprogramsiibarchitectural}. While the general NTK theory has been extensively studied, very few works use the framework to study the performance of neural architectures on specific tasks. Notably, the framework has been used to attempt to explain the ``double descent'' phenomenon \citep{Nakkiran2020Deep} observed in deep architectures \citep{pmlr-v119-adlam20a, singh2022phenomenology}. It has also been used to study the behavior of Residual Networks \citep{CSIAM-AM-3-4} and Physics-Informed Neural Networks \citep{WANG2022110768}. To the best of our knowledge, the closest work to ours is \cite{boix-adsera2024when}, where the authors use results from the general NTK theory to prove that Transformers can provably generalize out-of-distribution on template matching tasks. Furthermore, they show that feed-forward neural networks fail to generalize to unseen symbols for any template task, including copying, a special case of a permutation learning setting. In our paper, we show that feed-forward neural networks can indeed learn to copy without error with high probability. At first, this might seem to contradict \cite{boix-adsera2024when}. However, the key difference between our work and the work in \cite{boix-adsera2024when} lies in the problem setting. The setting in \cite{boix-adsera2024when} poses no restrictions to the input, whereas we require binary encoded input. Therefore, the model has access to all symbols during training. In particular, we specifically choose the training set, i.e. the standard basis, so that each symbol appears in every position. 
The restrictions above are what enable exact permutation learning.      

Lastly, various studies highlight the expressive power of neural networks through simulation results. For instance, \citet{siegelman95comp} demonstrates the Turing completeness of recurrent neural networks (RNNs), while \citet{hertrich2023provably} introduces specific RNN constructions capable of solving the shortest paths problem and approximating solutions to the knapsack problem. Moreover, other simulation studies on Transformers have established their Turing completeness \citep{perez2021attention, wei2022statistically} and showcased constructive solutions for linear algebra, graph-related problems \citep{giannou23a, pmlr-v235-back-de-luca24a, yang2023looped}, and parallel computation \citep{deluca2025positionalattentionexpressivitylearnability}. However, the results in these works are existential, and none considers the dynamics of the training procedure.