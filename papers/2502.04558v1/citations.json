[
  {
    "index": 0,
    "papers": [
      {
        "key": "wu_cognitive_2024",
        "author": "Wu, Siyu and Oltramari, Alessandro and Francis, Jonathan and Giles, C. Lee and Ritter, Frank E.",
        "title": "Cognitive {LLMs}: Towards Integrating Cognitive Architectures and Large Language Models for Manufacturing Decision-making"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "bajaj_generating_2023",
        "author": "Bajaj, Goonmeet and Pearce, Kate and Kennedy, Sean and Larue, Othalia and Hough, Alexander and King, Jayde and Myers, Christopher and Parthasarathy, Srinivasan",
        "title": "Generating Chunks for Cognitive Architectures"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "kirk_exploiting_2023",
        "author": "Kirk, James R. and Wray, Robert E. and Laird, John E.",
        "title": "Exploiting Language Models as a Source of Knowledge for Cognitive Agents"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "bommasani_opportunities_2022",
        "author": "Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and Altman, Russ and Arora, Simran and Arx, Sydney von and Bernstein, Michael S. and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and Brynjolfsson, Erik and Buch, Shyamal and Card, Dallas and Castellon, Rodrigo and Chatterji, Niladri and Chen, Annie and Creel, Kathleen and Davis, Jared Quincy and Demszky, Dora and Donahue, Chris and Doumbouya, Moussa and Durmus, Esin and Ermon, Stefano and Etchemendy, John and Ethayarajh, Kawin and Fei-Fei, Li and Finn, Chelsea and Gale, Trevor and Gillespie, Lauren and Goel, Karan and Goodman, Noah and Grossman, Shelby and Guha, Neel and Hashimoto, Tatsunori and Henderson, Peter and Hewitt, John and Ho, Daniel E. and Hong, Jenny and Hsu, Kyle and Huang, Jing and Icard, Thomas and Jain, Saahil and Jurafsky, Dan and Kalluri, Pratyusha and Karamcheti, Siddharth and Keeling, Geoff and Khani, Fereshte and Khattab, Omar and Koh, Pang Wei and Krass, Mark and Krishna, Ranjay and Kuditipudi, Rohith and Kumar, Ananya and Ladhak, Faisal and Lee, Mina and Lee, Tony and Leskovec, Jure and Levent, Isabelle and Li, Xiang Lisa and Li, Xuechen and Ma, Tengyu and Malik, Ali and Manning, Christopher D. and Mirchandani, Suvir and Mitchell, Eric and Munyikwa, Zanele and Nair, Suraj and Narayan, Avanika and Narayanan, Deepak and Newman, Ben and Nie, Allen and Niebles, Juan Carlos and Nilforoshan, Hamed and Nyarko, Julian and Ogut, Giray and Orr, Laurel and Papadimitriou, Isabel and Park, Joon Sung and Piech, Chris and Portelance, Eva and Potts, Christopher and Raghunathan, Aditi and Reich, Rob and Ren, Hongyu and Rong, Frieda and Roohani, Yusuf and Ruiz, Camilo and Ryan, Jack and R\u00e9, Christopher and Sadigh, Dorsa and Sagawa, Shiori and Santhanam, Keshav and Shih, Andy and Srinivasan, Krishnan and Tamkin, Alex and Taori, Rohan and Thomas, Armin W. and Tram\u00e8r, Florian and Wang, Rose E. and Wang, William and Wu, Bohan and Wu, Jiajun and Wu, Yuhuai and Xie, Sang Michael and Yasunaga, Michihiro and You, Jiaxuan and Zaharia, Matei and Zhang, Michael and Zhang, Tianyi and Zhang, Xikun and Zhang, Yuhui and Zheng, Lucia and Zhou, Kaitlyn and Liang, Percy",
        "title": "On the Opportunities and Risks of Foundation Models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "petroni_language_2019",
        "author": "Petroni, Fabio and Rockt\u00e4schel, Tim and Lewis, Patrick and Bakhtin, Anton and Wu, Yuxiang and Miller, Alexander H. and Riedel, Sebastian",
        "title": "Language Models as Knowledge Bases?"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "alivanistos_prompting_2023",
        "author": "Alivanistos, Dimitrios and Santamar\u00eda, Selene B\u00e1ez and Cochez, Michael and Kalo, Jan-Christoph and Krieken, Emile van and Thanapalasingam, Thiviyan",
        "title": "Prompting as Probing: Using Language Models for Knowledge Base Construction"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "wang_readprompt_2023",
        "author": "Wang, Zezhong and Ye, Luyao and Wang, Hongru and Kwan, Wai-Chung and Ho, David and Wong, Kam-Fai",
        "title": "{ReadPrompt}: A Readable Prompting Method for Reliable Knowledge Probing"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "qi_what_2023",
        "author": "Qi, Shuhan and Cao, Zhengying and Rao, Jun and Wang, Lei and Xiao, Jing and Wang, Xuan",
        "title": "What is the limitation of multimodal {LLMs}? A deeper look into multimodal {LLMs} through prompt probing"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "li_implicit_2021",
        "author": "Li, Belinda Z. and Nye, Maxwell and Andreas, Jacob",
        "title": "Implicit Representations of Meaning in Neural Language Models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "chen_is_2024",
        "author": "Chen, Nuo and Wu, Ning and Liang, Shining and Gong, Ming and Shou, Linjun and Zhang, Dongmei and Li, Jia",
        "title": "Is Bigger and Deeper Always Better? Probing {LLaMA} Across Scales and Layers"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "li_implicit_2021",
        "author": "Li, Belinda Z. and Nye, Maxwell and Andreas, Jacob",
        "title": "Implicit Representations of Meaning in Neural Language Models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "chen_is_2024",
        "author": "Chen, Nuo and Wu, Ning and Liang, Shining and Gong, Ming and Shou, Linjun and Zhang, Dongmei and Li, Jia",
        "title": "Is Bigger and Deeper Always Better? Probing {LLaMA} Across Scales and Layers"
      }
    ]
  }
]