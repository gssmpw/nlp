\newpage
\appendix
\section{Appendix}
\label{sec:appendix}

\subsection{Validated Hyperparameters of \method}
\label{sec:appendix:Effect of Hyperparameters_detail}
In Table~\ref{tab:appendix:besthyperparameter}, we report the validated values of the hyperparameters $\alpha$ and $\beta$ that provide the best performance on the validation set for each metric and dataset, where $\gamma$ is calculated as $\gamma = 1 - \alpha - \beta$.

\setlength{\tabcolsep}{15pt}
\begin{table}[h!]
\small
\caption{
    Validated values of the hyperparameters of \method, providing the best performance for each metric and dataset.
}
\label{tab:appendix:besthyperparameter}
\centering
\begin{tabular}{c|ccc|ccc}
\hline
\toprule
\textbf{Metric}  & \multicolumn{3}{c|}{\textbf{HR@10}} & \multicolumn{3}{c}{\textbf{NDCG@10}} \\
\midrule
\textbf{Datasets} & $\alpha$ & $\beta$ & $\gamma$ & $\alpha$ & $\beta$ & $\gamma$  \\
\midrule
\textbf{Taobao}  & 0              & 0.9   & 0.1         & 0               & 0.9 & 0.1             \\
\textbf{Tenrec}  & 0.3            & 0.6   & 0.1         & 0               & 0.6 & 0.4 \\
\textbf{Tmall}   & 0.7            & 0.2   & 0.1         & 0.7             & 0.2 & 0.1            \\
\bottomrule\hline
\end{tabular}
\end{table}


\subsection{Further Experiment on a Single Behavior Graph} 
\label{sec:appendix:single}

We additionally measured the performance of traditional methods in multi-behavior recommendation, which are designed for single-behavior graphs. 
Specifically, we used the interactions associated with the target behavior (e.g., \texttt{buy}) solely for their intended purpose.
As shown in Table~\ref{tab:appendix:SingleBehaviorCompareTable}, the performance is significantly low because the graph is extremely sparse when only single-behavior interactions are used.
In contrast, merging all interactions into a unified graph yields better performance than using a single-behavior graph, as it resolves the sparsity issue.
In Section~\ref{sec:experiments}, we report the unified graph's performance for each method as the baseline of \method.

\def\arraystretch{1.2} 
\setlength{\tabcolsep}{6pt}
\begin{table}[h]
\small
\caption{
Performance comparison of existing methods using either a single behavior graph or a unified behavior graph.
Relying on a single behavior results in poorer performance compared to utilizing all interactions across multiple behaviors.
\label{tab:appendix:SingleBehaviorCompareTable}
}
\centering
\begin{tabular}{cc|c|ccr|ccr}
\hline
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{\textbf{Methods}}} & \multicolumn{1}{c|}{\multirow{2}{*}{\textbf{Type}}} & \multicolumn{1}{c|}{\multirow{2}{*}{\textbf{Datasets}}} & \multicolumn{3}{c|}{\textbf{HR@10}}                   & \multicolumn{3}{c}{\textbf{NDCG@10}}                  \\ 

\multicolumn{1}{l}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{}  & \textbf{Single} & \textbf{Unified} & \textbf{\% impv.} & \textbf{Single} & \textbf{Unified} & \textbf{\% impv.} \\ \midrule

\multirow{3}{*}{\textbf{MF-BPR}}   &  \multirow{3}{*}{RL}          & \taobao                                        & 0.0371          & 0.0758           & 104.2\%            & 0.0177          & 0.0387           & 118.4\%            \\
&   & \tenrec                                        & 0.0092          & 0.1244           & 1249.5\%           & 0.0042          & 0.0575           & 1275.6\%           \\
&   & \tmall                                         & 0.0647          & 0.0855           & 32.0\%             & 0.0291          & 0.0423           & 45.4\%             \\ \midrule
\multirow{3}{*}{\textbf{LightGCN}}    &  \multirow{3}{*}{RL}                & \taobao                                        & 0.0368          & 0.1025           & 178.8\%            & 0.0216          & 0.0566           & 162.3\%            \\
 &    & \tenrec                                        & 0.0046          & 0.1069           & 2224.3\%           & 0.0023          & 0.0526           & 2147.9\%           \\
  &   & \tmall                                         & 0.0913          & 0.1162           & 27.3\%             & 0.0402          & 0.0625           & 55.3\%             \\ \midrule
\multirow{3}{*}{\textbf{BiRank}}       &  \multirow{3}{*}{GR}               & \taobao                                        & 0.0390          & 0.3034           & 678.6\%            & 0.0216          & 0.1517           & 602.2\%            \\
  &   & \tenrec                                        & 0.0046          & 0.2949           & 6300.0\%           & 0.0018          & 0.1257           & 6951.5\%           \\
 &    & \tmall                                         & 0.0849          & 0.3550           & 317.9\%            & 0.0519          & 0.1819           & 250.4\%            \\ \midrule
\multirow{3}{*}{\textbf{CoHITS}}          &  \multirow{3}{*}{GR}    & \taobao      & 0.0404          & 0.2128           & 426.9\%            & 0.0241          & 0.0988           & 310.1\%            \\
  &   & \tenrec                                        & 0.0046          & 0.2074           & 4400.0\%           & 0.0020          & 0.0957           & 4722.6\%           \\
  &   & \tmall                                         & 0.0735          & 0.2713           & 269.2\%            & 0.0458          & 0.1284           & 180.2\%            \\ \midrule
\multirow{3}{*}{\textbf{RWR}}               &  \multirow{3}{*}{GR}   & \taobao                                        & 0.0412          & 0.2130           & 417.5\%            & 0.0246          & 0.0988           & 301.4\%            \\
 &    & \tenrec                                        & 0.0000          & 0.2074           & $\infty$              & 0.0000          & 0.0962           & $\infty$              \\
  &   & \tmall                                         & 0.0726          & 0.2712           & 273.8\%            & 0.0452          & 0.1284           & 184.1\%            \\ \bottomrule \hline 
\end{tabular}
\end{table}


\newpage
\subsection{Efficiency Comparison with Representation Learning Methods}
%minseo
\label{sec:appendix:EfficiencyComparisonwithRepresentationLearningMethods}

We compared the graph ranking (GR) methods including \method with the representation learning (RL) and pattern mining (PM) methods in terms of running time and accuracy. 
For a fair comparison, we measured the wall-clock time (in seconds) required to generate ranking (or recommendation) scores for all users from the input graph. 
We applied early stopping to the RL methods, mirroring the convergence criteria used for the GR methods.
As shown in Table~\ref{tab:appendix:efficienycompare}, our \method provides the best accuracy while showing competitive speed compared to its competitors. 
Notably, the graph ranking approach, including our proposed \method, is significantly faster than the RL and PM approaches while also achieving higher accuracy, underscoring its strengths in both speed and accuracy.



\def\arraystretch{1.2} 
\setlength{\tabcolsep}{6pt}
\begin{table}[h]
%\vspace{-3mm}
\small
\centering
\caption{
\label{tab:appendix:efficienycompare}
Comparison of \method with representation learning (RL), graph ranking (GR), and pattern mining (PM) methods in terms of efficiency (Time) and accuracy (HR@10), where we measured the wall-clock time in seconds for the end-to-end process of generating recommendation scores for all users from the input graph.
Note that our \method is significantly faster than the RL and PM methods, and comparable to the GR methods, while achieving the best accuracy.
}
\begin{tabular}{cc|rc|rc|rc}
\hline
\toprule
\multicolumn{2}{c|}{\bf Datasets}       & \multicolumn{2}{c|}{\bf \taobao} & \multicolumn{2}{c|}{\bf \tenrec}  & \multicolumn{2}{c}{\bf \tmall}   \\
\textbf{Methods} & \textbf{Type}       & \textbf{Time (s) } & \textbf{HR@10}  & \textbf{Time (s)} & \textbf{HR@10}   & \textbf{Time (s)} & \textbf{HR@10}  \\ \midrule
MB-HGCN & RL  & 96.0               & 0.1261 & 126.4              & 0.1413 & 306.8              & 0.1133 \\
MuLe   & RL       & 764.4              & 0.1949 & 39.7             & 0.2097  & 3937.2               & 0.1920 \\
PKEF   & RL       & 2031.6             & 0.1349 & 2258.9             & 0.1222  & 1925.2             & 0.0968 \\
HEC-GCN   & RL    & 104.3              & 0.1905 & 134.6              & 0.1806  & 323.9              & 0.2673 \\ \midrule
RWR  & GR   & 2.1                & 0.2130 & 6.1               & 0.2712  & 11.4               & 0.2074 \\
CoHITS & GR  & 1.2               & 0.2128 & 3.5                & 0.2713  & 6.5                & 0.2074 \\
BiRank & GR  & 1.6                & 0.3034 & 6.6                & 0.3550  & 8.4                & 0.2949 \\
NRank  & GR        & 19.9               & 0.2989 & 4.8              & 0.3477  & 132.0              & 0.4562 \\
\midrule
BPMR  & PM        & 3567.9             & 0.2846 & 6753.1             & 0.3289  & 7300.2             & 0.4286 \\
\midrule
\bf \method & GR & 1.6                & 0.3324 & 8.3                & 0.3751  & 8.6                 & 0.4608 \\ \bottomrule \hline 
\end{tabular}

\end{table}



\subsection{Comparison of Different Cascading Sequences}
\label{sec:appendix:Performance_for_Different_Cascading_Sequences}

% context of this experiment
As described in Section~\ref{sec:exp:setting}, we fixed the cascading sequence $\C$ to the bold sequence shown in Table~\ref{tab:appendix:behaviorpertubation} for each dataset, assuming a natural sequence of user behaviors inspired by earlier works~\cite{LiuXWY00024, yin2024hecgcn, ChengCHLZGP23fqvn, YanCGSLSL24}.
% motivation of this experiment
However, the performance of \method can depend on the order of behaviors in $\C$, and the assumed sequence may therefore be suboptimal.
% setting
To examine the effect of the order of $\C$, we conducted an experiment in which the last behavior in $\C$ was fixed to the target behavior $b_t$, while the other behaviors were permuted.
% result
Table~\ref{tab:appendix:behaviorpertubation} presents the experimental results in terms of HR@10 and NDCG@10.
Notably, in \taobao and \tmall, the sequence assumed in Section~\ref{sec:experiments} demonstrates suboptimal accuracy compared to other sequences, whereas it achieves the best performance in \tenrec.
Nevertheless, the assumed sequence for each dataset delivers competitive performance relative to the other sequences, outperforming the competitors of \method.
This result suggests that our cascading approach is effective in providing accurate recommendation, but the optimal sequence $\C$ of user behaviors depends on datasets, indicating that learning such a sequence in this setting is a promising direction of future work.

%\def\arraystretch{1.2} 
\setlength{\tabcolsep}{17pt}
\begin{table}[h]
%\vspace{-3mm}
\small
\caption{
\label{tab:appendix:behaviorpertubation}
Performance of \method for different cascading sequences in terms of HR@10 and NDCG@10. 
The last behavior is fixed to the target behavior, while the others are permuted in the sequence, with the sequence used in Section~\ref{sec:experiments} highlighted in bold.
}
\centering
\begin{tabular}{c|l|cc}
\hline
\toprule
\textbf{Datasets}                 & \textbf{Cascading Sequences}                  & \multicolumn{1}{l}{\textbf{HR@10}} & \multicolumn{1}{l}{\textbf{NDCG@10}} \\ \midrule
\multirow{2}{*}{\taobao} & \bf{view$\rightarrow$cart$\rightarrow$buy}           & 0.3324                    & 0.1626                      \\
                        & cart$\rightarrow$view$\rightarrow$buy           & \bf 0.3409                    & \bf 0.1675                      \\ \midrule
\multirow{6}{*}{\tenrec} & \bf{view$\rightarrow$share$\rightarrow$like$\rightarrow$follow} & \bf 0.4793                    & \bf 0.2723                      \\
                        & view$\rightarrow$like$\rightarrow$share$\rightarrow$follow & 0.4747                    & 0.2700                      \\
                        & share$\rightarrow$view$\rightarrow$like$\rightarrow$follow & 0.4700                    & 0.2545                      \\
                        & share$\rightarrow$like$\rightarrow$view$\rightarrow$follow & 0.4654                    & 0.2544                      \\
                        & like$\rightarrow$view$\rightarrow$share$\rightarrow$follow & \bf 0.4793                    & 0.2698                      \\
                        & like$\rightarrow$share$\rightarrow$view$\rightarrow$follow & 0.4700                    & 0.2578                      \\ \midrule
\multirow{6}{*}{\tmall}  & \bf{view$\rightarrow$collect$\rightarrow$cart$\rightarrow$buy}  & 0.3751                    & 0.1871                      \\
                        & view$\rightarrow$cart$\rightarrow$collect$\rightarrow$buy  & 0.3699                    & 0.1849                      \\
                        & collect$\rightarrow$view$\rightarrow$cart$\rightarrow$buy  & 0.3954                    & 0.1999                      \\
                        & collect$\rightarrow$cart$\rightarrow$view$\rightarrow$buy  & 0.3968                    & \bf 0.2086                      \\
                        & cart$\rightarrow$view$\rightarrow$collect$\rightarrow$buy  & 0.3757                    & 0.1866                      \\
                        & cart$\rightarrow$collect$\rightarrow$view$\rightarrow$buy  & \bf 0.3974                    & 0.2037                      \\ 
                        \bottomrule \hline
\end{tabular}
\end{table}


\newpage
\subsection{Detailed Analysis on Effect of Hyperparameters}
\label{sec:appendix:details:hyperparams}

We report how the hyperparameters $\alpha$ and $\beta$ affect \method across all possible combinations in terms of HR@10 and NDCG@10. 
Figure~\ref{fig:appendix:Hyper-sens-detail} displays the experimental results, showing that the trends vary across the datasets.
In \taobao, smaller values of $\alpha$ and higher values of $\beta$ tend to yield better performance, while in \tenrec, moderate $\beta$ values perform better.
In \tmall, higher values of $\alpha+\beta$ tend to show higher accuracy.

\begin{figure}[h]
    \centering
    \subfigure[\taobao]{
        %\vspace{-3mm}
        \hspace{-5mm}
        \includegraphics[width=0.321\linewidth]{Hyper-sens-taobao.pdf}
        \hspace{-1mm}
        \label{fig:experiments:Hyper-sens:Taobao}
    }
    \subfigure[\tenrec]{
        \hspace{-3mm}
        \includegraphics[width=0.320\linewidth]{Hyper-sens-tenrec.pdf}
        \hspace{-1mm}
        \label{fig:experiments:Hyper-sens:Tenrec}
    }
    \subfigure[\tmall]{
        \hspace{-3mm}
        \includegraphics[width=0.32\linewidth]{Hyper-sens-tmall.pdf}
        \hspace{-1mm}
        \label{fig:experiments:Hyper-sens:Tmall}
    }

    \caption{
        \label{fig:appendix:Hyper-sens-detail}
        Detailed effect of hyperparameters in \method, where $\alpha$ controls the strength of query fitting, and $\beta$ controls the strength of cascading fitting. These hyperparameters are searched within the range $0 \leq \alpha + \beta \leq 1$ and $0 \leq \alpha, \beta \leq 1$. 
    }
\end{figure}




\subsection{Implementation Information of Competitors}
\label{sec:appendix:competitors:information}
%minseo - dines ref
We used open-source implementations for the competitors in our experiments, with detailed information provided below:
\begin{itemize}[leftmargin=9mm,noitemsep]
    \item{ 
        \textbf{MF-BPR}: \url{https://github.com/RUCAIBox/RecBole} 
    }
    \item{
        \textbf{LightGCN}: \url{        https://github.com/RUCAIBox/RecBole}
    }
    \item{
        \textbf{MB-HGCN}: 
        \url{https://github.com/MingshiYan/MB-HGCN}
    }
    \item{
        \textbf{MuLe}: \url{https://github.com/geonwooko/MULE}
    }
    \item{
        \textbf{PKEF}: \url{https://github.com/MC-CV/PKEF}
    }
    \item{
        \textbf{HEC-GCN}: \url{https://github.com/marqu22/HEC-GCN}
    }
    \item{
        \textbf{RWR}: \url{https://github.com/jinhongjung/pyrwr}
    }
    \item{
        \textbf{CoHITS}: \url{https://github.com/BrianAronson/birankr}
    }
    \item{
        \textbf{BiRank}: \url{https://github.com/BrianAronson/birankr}
    }
    \item{
        \textbf{NRank}: \url{https://github.com/BrianAronson/birankr}
    }
    \item{
        \textbf{BPMR}: \url{https://github.com/rookitkitlee/bpmr}
    }
\end{itemize}
