\section{Synthesizer}
\label{sec:synthesizer}

We now elaborate on the workings of the synthesizer. 
The hints synthesis process consists of two steps: hints generation and hints condensing. 

% We now discuss the two steps synthesizer takes, namely hints generating and condensing.
% Profiler prepares raw material/ingredient for synthesizer to generate hints, i.e., concise and straightforward rules, to guide providers to conduct adaptive allocation at runtime.
% For maintaining high accuracy, synthesizer requires to prepare a specific hint for each given slack.
% Yet, due to the variance and volatility of slacks, \namex may generate overwhelming hints, which not only incurs extra storage resource consumption but also  hurts the time-efficiency of adaptive allocations.
% To fix this issue, \namex effectively condenses the hints.
\subsection{Hints Generation}
\label{sec:synthesizer:generate}
To generate hints tables with high hit rates and high resource efficiency, the synthesizer requires a twofold effort.
First, it must explore all potential runtime time budgets for individual sub-workflows.
Second, the synthesizer needs to balance the trade-off between higher resource efficiency and the risk of SLO violation.
To this end, we reveal the following insights.

\mypara{Insight-1: Broad time budget range.}
The time budgets are calculated based on all possibilities between the 1st and 99th percentile (P1-P99) of the function execution time under a wide range of resource allocations, aiming to achieve high hit rates.
The range of time budgets therefore are formulated as
\begin{eqnarray}
    T_{min}= \sum_{i=1}^NL_i(1,K_{max}),
    T_{max}= \sum_{i=1}^NL_i(99,K_{min}),
\end{eqnarray}
where $K_{min}$/$K_{max}$ represents the minimum/maximum available resources,
and $N$ represents the numbers of functions in the given sub-workflows. Within this range, the synthesizer explores the potential time budgets with finer granularity in milliseconds, while evaluating their corresponding resource allocation.
The synthesizer can also be configured with higher percentiles (e.g., P99.9) to meet more stringent SLO targets.

\textbf{\textit{Insight-2: Moderate percentile exploration.}}
Diverse percentiles provide more opportunities for resource optimization, but come with exponentially higher time complexity for runtime resource adaptation.
Here, our insight is to only open percentile exploration for the head function of the current sub-workflow while fixing other functions with P99.
This moderate percentile exploration benefits the synthesizer with higher resource efficiency, derived from its attempt at lower percentiles for the head function.
Meanwhile, it effectively reduces the search space for non-head functions, allowing the synthesizer to achieve high time efficiency.

\textbf{\textit{Insight-3: Resilience-aware.}}
Despite the potential of higher resource efficiency, diverse percentile exploration may put functions at the risk of timeouts, making workflows prone to SLO violations.
To address this shortcoming, the synthesizer strictly restricts the timeout within the resilience (the achievable reduction in function execution time by scaling resource up to the maximum possible).
Within this ``safety zone", the synthesizer tries its best to maximize resource efficiency.

\mypara{Insight-4: Heavier head.}
As explained in~\S\ref{sec:bg:adaptive-allocation}, facing substantial variability of execution performance, runtime resource adaptation requires to carry out (head) function by (head) function, so as to keep its high accuracy.
This, however, may lead to sub-optimal decisions due to the mismatch between the local objective and the global objective.
Specifically, the local objective is to maximize the sub-workflow's resource efficiency, while the global objective is to maximize the whole workflow's resource efficiency.
The whole efficiency is determined by that of each sub-workflow's head function, rather than that of sub-workflows.
To address this issue, the synthesizer magnifies the local objective's weight for head functions, aiming to calibrate for the mismatch.

As for how to set the weight, our insight is to increase the weight when facing loose SLOs, and vice versa.
This is because loose SLOs indicate lower resource requirements, which brings about higher resilience (depicted in Figure~\ref{fig:exp:resilience:cores}).
Increasing the weight can better utilize this higher resilience to explore lower percentiles, such that the workflow achieves higher resource efficiency with SLO guarantees.

Hints demonstrates explicit resource allocation that can ensure the sub-workflow with its maximum resource efficiency, i.e., the minimum resource consumption, under given time budgets.
This problem thus is formulated as follows:
% \begin{eqnarray}
% 	\min && W\cdot k_1+p \cdot \sum_{i=2}^{N}k_i +(1-p)\cdot (N-1)\cdot K_M \label{eq:hints:obj}\\
% 	\text{subject to} &&
%  %percentile latency
%  L(p,k_1)+\sum_{i=2}^{N}L(99,k_i) \leq T, \label{eq:hints:time-budget}\\
%  %timeouts and resilience
% && D(p,k_1) \leq \sum_{i=2}^{N}R(99,k_i), \label{eq:hints:timeout-resilience}\\
% &&  1 ~\leq p ~\leq 99,~p \in \mathbb{Z},\\
% && 0 ~< k_i ~\leq K_{max},~k_i \in \mathbb{R}, ~\forall i.
% \end{eqnarray}
\begin{eqnarray}
	\min && W k_1+p  \sum_{i=2}^{N}k_i +(1-p) (N-1) K_{max} \label{eq:hints:obj}\\
	\text{subject to} &&
 %percentile latency
 L_1(p,k_1)+\sum_{i=2}^{N}L_i(99,k_i) \leq T, \label{eq:hints:time-budget}\\
 %timeouts and resilience
&& D_1(p,k_1) \leq \sum_{i=2}^{N}R_i(99,k_i), \label{eq:hints:timeout-resilience}\\
&&  1 \leq p \leq 99,~p \in \mathbb{Z},\\
&& K_{min}\leq k_i \leq K_{max},~k_i \in \mathbb{R}, ~\forall i.
\end{eqnarray}
where $W$ is the weight for the head function (Insight-4), and $T$ and $N$ denote the time budget and the number of functions in the sub-workflow, respectively.
%$K_{max}$ represent the maximum available CPU cores.
Notably, only the head function can explore lower percentile $p$ (Insight-2).
Equation~\ref{eq:hints:obj} expresses the sub-workflow's expected resource consumption.
Specifically, $\sum_{i=2}^{N}k_i$ and $(N-1)K_{max}$ denote non-head functions' resource requirement without and with the head function's timeout, the probability of which is $p$ and $1-p$, respectively.
Equation~\ref{eq:hints:time-budget} ensures the sub-workflow's execution latency within the time budget.
Equation~\ref{eq:hints:timeout-resilience} restricts that the possible timeout of the head function can not exceed the total resilience of downstream functions (Insight-3).

\begin{algorithm}[!t]
\small
\caption{Offline hints generation\label{alg:generate}}
 	\LinesNumbered    
    \KwIn{$\mathbf{F}= \left\langle f_1,\dots,f_N \right\rangle$: (sub-)workflow}
    \KwIn{$[T_{min},T_{max}]$: time budget range}
    \KwIn{$W,\mathbf{P}$: weight and candidate percentiles  for head function $f_1$}
	%\KwIn{$\left\langle T, \mathbf{H} \right\rangle$: time budget and hints table.}
    \KwOut{$\mathbf{H}=\{\left\langle  t, \{ k_1,\dots,k_N \} \right\rangle\}$: functions' provisioned CPU cores under given time budget $t$, i.e., hints table
	}
    $\mathbf{H} \leftarrow \emptyset$, $\mathbf{P} \leftarrow \emptyset$   \\
    \ForEach{$t \in [T_{min},T_{max}]$}
    {
    $\mathbf{H} \leftarrow \mathbf{H} \cup \{ \left \langle t, ~\texttt{generate}(\mathbf{F},t,\mathbf{P}) \right \rangle \}$ \\
    $\text{return}~\mathbf{H}$
    }
	\SetKwFunction{FMain}{\texttt{generate}}
    \SetKwProg{Fn}{Function}{:}{}
    
    \Fn{\FMain{$\mathbf{F},t,\mathbf{P}$}}{
    \If{$\left| \mathbf{F} \right| = 1$} 
    {
     \textbf{return} \texttt{min\_resource}($f_1,t$)
    }
    %$r_{min} \leftarrow \infty,~X \leftarrow \emptyset $ \\
     \If{$\mathbf{P} = \emptyset$} 
    {
     $\mathbf{P}=$\texttt{explore\_percentile}($\mathbf{F},t, K_{max}$)
    }
    $s_{min} \leftarrow \infty,~\mathbf{K} \leftarrow \emptyset $\\
    \ForEach{$p \in \mathbf{P}$}
    {
        \ForEach{$k \in [K_{min},K_{max}]$}   
        {
          $\mathbf{Z} \leftarrow $~\FMain{$\mathbf{F} \setminus f_1, t-L_1(p,k), \{P_{99}\}$}\\
          \If{$\mathbf{Z} \neq \emptyset \wedge  D(p,k) \leq \sum{R(\mathbf{Z},P_{99})}$}
          {
          $s \leftarrow W  k +p \sum{\mathbf{Z}} + (1-p)  (\left| \mathbf{F} \right| -1) K_{max}$ \\
          \If{$s \leq s_{min}$}
          {
            $s_{min} \leftarrow s, \mathbf{K} \leftarrow \{k\} \cup  \mathbf{Z}  $
          }
          }
        }            
    }
    \text{return}~$\mathbf{K}$
    }
\end{algorithm}

The algorithm for generating hints is listed in Algorithm~\ref{alg:generate}.
To ensure hints tables with high hit rates, the synthesizer explores all time budgets comprehensively (lines 2--4). 
Specifically, for a given sub-workflow $\mathbf{F}$, the synthesizer first determines the percentiles $\mathbf{P}$ that can ensure $\mathbf{F}$'s execution time below the required time budget $t$, with assuming the maximum available CPU cores for each function (lines 8--9).
Then, the synthesizer explores the resource allocation for both head and non-head functions, denoted as $k$ and $\mathbf{Z}$, under given percentile $p$. Its goal is to minimize the expected resource consumption $s$, while promising timeout $ D(p,k)$ restricted within resilience $\sum{R(\mathbf{Z},P_{99})}$ (lines 12--17).
To accelerate the generation, the synthesizer explores different percentiles concurrently.

\subsection{Hints Condensing}
\label{sec:synthesizer:condense}
The synthesizer fully utilizes the discreteness in both decision-making and decision-executing to condense hints.

\mypara{Insight-5: Repeated hints.} There are various discrete variables, such as batch sizes and CPU cores, involved in resource adaptation. 
This leads to a significant number of redundant hints that share the same adaptation decisions despite having different time budgets.

\mypara{Insight-6: Unused fields.}
The dependencies of adaptation (explained in \S\ref{sec:bg:adaptive-allocation}) compels Janus to rely solely on the fields for head functions in given hints to maintain adaptation accuracy.
Consequently, removing the fields for non-head functions helps compact the hints without compromising accuracy.
 
The algorithm for condensing hints is listed in Algorithm~\ref{alg:condense}.
Specifically, the synthesizer first sorts the given hints $\mathbf{H}$ in descending order by their time budget (line 2).
Then, it gradually fuses the hints $\mathbf{H}[l]$ that share the identical size for head function $k_1$ as shown in line 4--10.
Finally, it warps hints into a table with three fields: $T_{start}$, $T_{end}$, and $k$, indicating that the head function of the target sub-workflow should be resized to $k$ when the sub-workflow's time budgets is between $T_{start}$ and $T_{end}$.
 
 In addition, the weight for head functions impacts the decision-making.
 Thus, the synthesizer maintains individual hint tables for different weights.
 We will evaluate the effectiveness of condensing algorithm in \S\ref{exp:micro:condense}, which suggests a outstanding compression ratio without hurting accuracy. 
 
\begin{algorithm}[!t]
\small
\caption{Offline hints condensing \label{alg:condense}}
 \LinesNumbered    
    \KwIn{$\mathbf{H}= \{\left\langle t,\mathbf{K} \right\rangle$\}: raw hints table}
    \KwOut{$\mathbf{U} = [\left\langle T_{start}, T_{end}, k\right\rangle ]$: condensed hints table}
	\SetKwFunction{FMain}{\texttt{condense}}
    \SetKwProg{Fn}{Function}{:}{}
    
    \Fn{\FMain{$\mathbf{H}$}}{
    $\mathbf{H} \leftarrow$  \texttt{sort}($\mathbf{H}$)\\
    $\mathbf{U} \leftarrow \emptyset$, $q, i, j \leftarrow 0$\\
    \ForEach{$l \in [0,\left| \mathbf{H} \right |]$}
    {
        $t, \left\langle k_1,\dots, k_N \right\rangle \leftarrow \mathbf{H}[l]$ \\
        \If{$q = 0 \vee k_1 = q$}
        {
        $j \leftarrow j+1$
        }
        \Else
        {
        $\mathbf{U} \leftarrow \mathbf{U} \cup \{ \left \langle \mathbf{H}[i].t, \mathbf{H}[j].t, q \right \rangle\} $ \\
        $i, j \leftarrow l$, $q \leftarrow k_1$
        }      
    }
    \text{return}~$\mathbf{U}$
    }

\end{algorithm}




















