\section{Background and Motivation}
\label{sec:background}

We introduce the background on serverless workload serving and motivate the use of runtime resource adaptation to address resource inefficiency in existing serverless platforms.

\subsection{Resource Inefficiency with Early Binding}
% In current serverless platforms, developers are required to specify immutable sizes for their deployed functions.
% Then, providers consider functions' runtime workloads  (e.g., concurrency)  and resource usage to scale out/in their instances.
% Moreover, due to high runtime variability, functions must size their functions for worst-case scenarios.
% This, however, incurs considerable resource inefficiency.
Current serverless workflow platforms (e.g., AWS Step Functions~\cite{aws-step-function} and Azure Durable Functions~\cite{azure-durable-function}) offer the opportunity for developers to build various applications with advanced logic like chaining, branching, and parallel execution.
These applications can be defined by JSON-based structured languages (e.g., Amazon States Language) or other programming languages.
Meanwhile, developers require to specify resource configurations, including memory size, CPU cores, and scaling options, for individual functions---an early-binding approach.
The serverless platform is responsible for monitoring the workload intensity and resource usage at runtime and scaling out/in function instances accordingly.
To account for potential runtime variability, developers must size the functions in their application workflow accounting for the worst case in order to provide SLO guarantees over the end-to-end delay of request processing, e.g., the 99th percentile (P99) of the end-to-end delay must be within a given target. 
After deployment, the function sizes become immutable. The worst case is not representative and over-shoots most of the time, leading to resource inefficiency. 


To verify this claim, we conduct a data-driven analysis with a dataset from Microsoft Azure Functions~\cite{azure-dataset} to explicitly demonstrate the resource inefficiency issue. % , deriving from the worst-case based early bind.
To quantify the inefficiency, we define a metric called \emph{slack}---the margin between the actual execution time and the SLO, which is calculated as $1-l/T$ with $l$ and $T$ representing end-to-end latency and SLO, respectively.
Under certain SLO defined with P99 latency as done by existing works (e.g., \cite{osdi22-orion,mac22-wisefuse}),  we can see from Figure \ref{fig:bg:slack} that more than 60\% function invocations have slacks over 60\%.
Particularly, we analyze slacks of the top 100 most popular functions, whose invocations account for 81.6\% of the total function invocations. % (depicted in Figure~\ref{fig:bg:popular_func}) of overall invocations.
The result shows that only 20\% of the invocations of the popular functions (blue line in Figure~\ref{fig:bg:slack}) have slacks less than 40\%.
This means the majority of requests are processed faster than necessary.
Notably, in DAG-based workloads (i.e., Azure Durable Functions), the resource inefficiency further deteriorates wherein the ratio between the 95th percentile and 50th percentile is by up to three times \cite{mac22-wisefuse}.

% \begin{figure}[t!]
% \centering
% \includegraphics[width=0.25\textwidth]{./figure/motivation/Average_P99_cdf_top=100.pdf}
% \vspace{-0.3cm}
% \caption{Sufficient function slacks in production traces.}
% \label{fig:bg:slack}
% \end{figure}

\subsection{Runtime Dynamics}
\label{sec:bg:worst-case}

The resource inefficiency caused by the large slack can be mainly attributed to the over-provisioning of resources by the developer. This is to ensure that the SLO is guaranteed even in the worst case (i.e., P99). However, normal cases deviate from the worst case significantly due to runtime dynamics. 
In particular, we observe that functions face two major dynamic factors at runtime: varying working sets and inevitable performance interference. These two factors contribute significantly to the variance of the function execution time. 
% Functions face two remarkably dynamic factors at runtime: working sets and performance interference, which lead to considerable variance of execution latency.

\begin{figure*}[!t]
	\centering
	\subfloat[]{
		\includegraphics[width=0.24\textwidth]{./figure/motivation/Average_P99_cdf_top=100.pdf}
		\label{fig:bg:slack}
	}
	\hspace{8mm}
	\subfloat[]{
		\includegraphics[width=0.25\textwidth]{./figure/motivation/function-latency-ml-analyze-varying-worksets.pdf}
		\label{fig:bg:ml-func-latency}
	}
	\hspace{8mm}
	\subfloat[]{
	\includegraphics[width=0.28\textwidth]{./figure/motivation/coresident-perf.pdf}   
	\label{fig:bg:perf-inteference}
	}
	%\vspace{-0.1cm}
	\caption{(a) slacks of function invocations in production traces, (b) function latency variance caused by varying input worksets for functions object detection (OD), question answering (QA), and and text-to-speech (TS), respectively,
 (c) performance interference attributed to co-location of homogeneous function with different dominant resource demands.}
 %\vspace{-0.4cm}
\end{figure*}

%'ml-analyze':{'text-to-speech': 'text-to-speech', 'question-answer': 'question answer',
%                      'object-detection': 'object detection'
\textbf{\textit{Varying working sets.}} 
The working set, i.e., input data like videos, audios, and texts, can have varying sizes.
Taking Microsoft Azure Function Blobs (storage service) as an example, their data size difference can be as high as nine orders of magnitude~\cite{azure-function-blob}.
Such a large difference results in substantial variance of the execution time even for the same function~\cite{socc21-faast,eurosys21-ofc}.
Specifically, we measure the execution time of three functions under different working sets (detailed in \S\ref{exp:setup}).
Figure~\ref{fig:bg:ml-func-latency} illustrates the results, where we can observe a variance of up to 3.8 times in function execution caused by varying working set sizes.

% \begin{figure}[t!]
% \centering
% \includegraphics[width=0.25\textwidth]{././figure/motivation/function-latency-ml-analyze-varying-worksets.pdf}
% \vspace{-0.3cm}
% \caption{Function latency variance caused by varying input worksets}
% \label{fig:bg:ml-func-latency}
% \end{figure}	

\textbf{\textit{Performance interference.}}
% On the other hand, function deployment, which decides when and where to deploy functions, is completely undertaken by providers.
For simplicity and security, commercial serverless platforms, such as Alibaba Function Compute, Microsoft Azure, and AWS Lambda, exclusively deploy function instances belonging to the same tenant, or even belonging to the same function, in the same virtual machine~\cite{socc22-owl,atc18-peek-bench}.
For example, the empirical study in~\cite{socc22-owl} shows that in Alibaba Function Compute 65\% of the virtual machines exclusively deploy instances of the same function.
This co-location of homogeneous function instances, however, can incur severe resource contention on the same resource dimensions, particularly for network bandwidth and memory bandwidth of virtual machines~\cite{sc21-gsight,micro19-faaSprofiler,socc22-owl,atc18-peek-bench}.
To verify this observation, we use a virtual machine to run a function increasing the number of co-located instances from one to six while measuring the execution time of four different functions with resource dominance on different dimensions namely computing, I/O, network, and memory, respectively (detailed in \S\ref{exp:setup}). 
As shown in Figure~\ref{fig:bg:perf-inteference}, the co-location of homogeneous functions leads to substantial resource contention and performance interference, prolonging the function execution time up to 8.1 times. The performance interference is often hard to model and predict.

% this co-residency results in substantial increase of execution latency by up to 8.1 times,leading to considerable variance in function execution time.
% when compared with that with concurrency as one.

%for CPU-, IO-, network- and memory-intensive functions as the concurrency rises from one to six.
%Figure shows that significant performance interference can be observed, . 
%compared with the inclusive deployment (concurrency as one), 
% this exclusive deployment (gray bar) results in substantial increase of execution latency by up to 8.1$\times$ for CPU-, IO-, network- and memory-intensive functions as the concurrency rises from one to six.

% this exclusive deployment (gray bar) results in substantial increase of execution latency by up to 8.1$\times$ for CPU-, IO-, network- and memory-intensive functions as the concurrency rises from one to six.
% As depicted in Figure~\ref{fig:bg:concurrent_latency}, with the concurrency rising  from one to six,  the exclusive deployment results in substantial increase of execution latency by up to 8.1$\times$.
% This significantly magnifies execution latency variance.

% \begin{figure}[t!]
% \centering
% \includegraphics[width=0.25\textwidth]{./figure/motivation/coresident-perf.pdf}
% \vspace{-0.3cm}
% \caption{Performance interference attributed to co-residency of homogeneous function.}
% \label{fig:bg:perf-inteference}
% \end{figure}




\subsection{Runtime Resource Adaptation}
\label{sec:bg:adaptive-allocation}
To tackle the aforementioned resource inefficiency issue, we can adopt a late-binding approach through \emph{runtime resource adaptation}, which resizes functions on the fly based on runtime information (e.g., function slacks), achieving higher resource efficiency without violating SLO. For example, given a workflow as a chain of functions, the resource allocation of the downstream functions can be adjusted when the first function finishes execution. This way, the slack from the first function can be exploited to optimize resource efficiency. 

The idea sounds straightforward and has been considered in some existing works \cite{infocom22-stepconf,middleware20-fifer,socc21-llama,socc21-kraken,middleware20-xanadu}.
However, most of these works make an unrealistic assumption that either the developer performs the adaptation decision with access to runtime information or the serverless platform provider performs the adaptation with domain knowledge of the application workflow. These assumptions render these solutions impractical to deploy in real-world serverless systems. The information barrier between the developer and the provider calls for a new solution. 

We identify the following challenges and opportunities for a full-fledged design for runtime resource adaptation. 

\textbf{\textit{Skewed function execution time distribution.}} 
Resource allocation for a serverless workflow is typically done by leveraging performance profiles of all the functions in the workflow. 
During the offline profiling, the execution time distribution for each function is first obtained by running the function with a variety of sample inputs under different resource conditions. Then, given a time budget, existing approaches typically use P99 of the function execution time as a target and calculate the corresponding resource demands. However, due to the high runtime variability, the distribution of the function execution time is highly skewed where the difference between P50 and P99 can be as high as 100 times~\cite{socc23-huawei-cloud}. This means that if only the function execution time at a single percentile (P50 or P99) is used for resource allocation, there will be significant resource under-provisioning and over-provisioning for most requests at runtime. To address this issue, our idea is to allow for the exploration of the function execution time at diverse percentiles during resource allocation. 


% It is a prerequisite to profile execution latency for adaptive resource allocation.  
% As aforementioned, owing to a variety of unexpected runtime dynamics,  execution latency demonstrates skewed distributions, by up to 100$\times$ between 99\% percentile and 50\% percentile on Huawei cloud serverless~\cite{socc23-huawei-cloud} .
% This makes the current a single statistic (e.g., mean) or 99\% percentile distribution based profiling suffer significant under- and over-estimation.
% To fix this issue, our insight is to \textit{introduce more diverse percentiles to profile execution latency}. 

\textbf{\textit{Dependencies of adaptation decisions.}}
As the function execution progresses, a sub-workflow will be generated by removing the finished function(s) from the workflow. Within each sub-workflow, the resource adaptation decisions for remaining functions are dependent on each other due to the constraint imposed by the end-to-end latency SLO. For example, under-provisioning a function will result in a reduction of the time budget for executing its downstream functions, thus calling for more resources for these downstream functions to avoid SLO violations. Meanwhile, the selection of the percentile for the execution time of each function dictates resource-latency tradeoff for that function. For example, a higher percentile means that more resources will be allocated to ensure that more requests processed by the function will finish within the given time budget. On the contrary, a lower percentile means that more requests will risk SLO violation, but at the benefits of reduced resource consumption. To address such complex dependencies, we propose the following ideas: (1) We introduce two metrics (i.e., the timeout metric and the resilience metric detailed in \S\ref{sec:profilier}) to balance the resource adaptation decisions of the head function of the current sub-workflow and those of the remaining downstream functions. These metrics help us connect the decision making across sub-workflows and avoids sub-optimal adaptation decisions in each sub-workflow. 
(2) We explore lower percentiles for the head function and a high percentile (i.e., P99) for other functions in each sub-workflow. Using lower percentiles maximizes the opportunity for resource optimization since any over-time execution of the head function can later be compensated by resource adaptation in the next round. The high percentile ensures that the resource adaptation is not too radical to cause SLO violations. 

% Each workflow generates multiple sub-workflows as the execution moves forwards. 
% Within sub-workflows, the provisioning is inter-corrected.
% For instance, under-provisioning upstream functions may directly shrink the time budget for downstream functions, which dictates more resources required by the latter against (sub-) SLO violation. 
% This makes sub-workflows generally adopted as the basic unit to make adaptation decisions~\cite{socc21-llama,rtas22-fa2}. 
%  Moreover,  due to the high variance of execution performance, runtime adaptation requires to carry out function by function, i.e.,  discrete adaptation.
%  This, however, can easily lead to a sub-optimal (analyzed in~\S~\ref{sec:synthesizer:generate}).
% Our insight is to \emph{introduce a metric (i.e., resilience detailed in \S~\ref{sec:profilier}) to quantify the inter-correlation as well as a heuristic design (i.e., heavier head explained in \S~\ref{sec:synthesizer:generate})  to calibrate the sub-optimal,  such that resource adaptation can explore higher resource efficiency without SLO guarantee}.

% In particular, latency percentiles (introduced by the profiling)  involves resource adaptation as a new knob.
% Specifically, higher percentile earns  stronger guarantees in SLOs but may be highly prone to resource over-allocation because of its latency over-estimation, impairing resource efficiency.
% In contrast, decreasing percentiles offers the opportunity to explore higher resource efficiency, but suffers the risk of timeout, i.e., execution latency beyond specified time budget, and  may thus incur  SLO violations.
% Here, our insight is to \emph{moderately explore percentiles (detailed in~\S~\ref{sec:synthesizer:generate}), where head functions of  (sub-)workflows can explore lower percentiles because this creates the opportunity to reap higher resource efficiency while possible timeout can be recovered by subsequent functions' re-adaptive allocation.
% On the other head, non head functions maintain percentiles as 99\%}.
% This can well keep the trade-off between opportunities of exploring higher resource efficiency and risks of SLO violations. 
% Additionally, it effectively shrinks the searching space, benefiting the adaptation with higher time-efficiency.


\textbf{\textit{Tight resource adaptation window.}}
Runtime resource adaptation requires to calculate a new resource allocation decision for the remaining sub-workflow immediately when a function finishes execution. Since serverless functions are typically short-lived (less than 1s on average)~\cite{atc18-peek-bench,socc22-owl,atc20-serverless-in-the-wild,socc23-huawei-cloud}, the window for resource adaptation is quite tight. Assuming the serverless platform will perform the runtime adaptation on behalf of the developer since the platform has access to full runtime information, the resource adaptation decision making should be fast without involving complex calculations and logic or exploring a large space. As discussed before, the serverless platform provider does not have domain knowledge of the serverless workflow. Hence, the developer must pass the necessary information to the serverless platform for runtime adaptation decision making. Our idea is to let the developer synthesize critical hints containing resource allocation rules and options, which the serverless platform provider utilizes to perform runtime resource adaptation. The hints should be highly condensed so the serverless platform can make adaptation decisions quickly enough. 


% Apart from highly varying execution performance, serverless functions are also short-living (less than 1s on average)~\cite{atc18-peek-bench,socc22-owl,atc20-serverless-in-the-wild,socc23-huawei-cloud}, so is the window for adaptive allocation. 
% This variance and volatility calls for a well-preparation of hints for all possible runtime situations while promising them compact and straightforward enough for providers to easily take action.

% Here, our insight is to \emph{holistically synthesize hints in an offline manner, and then utilize the discreteness of adaptive allocation in both decision-making and decision-executing (detailed in~\S~\ref{sec:synthesizer:condense}) to fully condense the hints.
% Finally, hints are warped into a simple and compact table.
% Base on that, providers can accomplish the runtime adaption promptly and properly}.

To demonstrate the potential of runtime resource adaptation incorporating all the above ideas, we take a real-world serverless workflow (explained in \S\ref{exp:setup}) as an example, and evaluate its end-to-end latency (denoted by E2E) and resource consumption (CPU cores).
As illustrated in Figure~\ref{fig:bg:size}, the late-binding (blue triangle) reduces the resource consumption by up to 42.2\% compared with existing early-binding solutions (orange circle), while ensuring SLO guarantees. This highlights the significant gains from runtime resource adaptation. 


\begin{figure}[t!]
\centering
\includegraphics[width=0.45\textwidth]{./figure/motivation/size_early_bind_vs_ours.pdf}
%\vspace{-0.1cm}
\caption{Performance comparison between early-binding (left)~\cite{eurosys19-grandslam} and late-binding (runtime resource adaptation), where the CPU consumption (right) is normalized by the optimal obtained with exhaustive search.} 
%\vspace{-0.3cm}
\label{fig:bg:size}
\end{figure}

   
	






