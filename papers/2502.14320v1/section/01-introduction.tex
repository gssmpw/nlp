\section{Introduction}
Serverless computing has become a popular approach for implementing various cloud applications including web services~\cite{asplos23-beehive}, data processing~\cite{socc21-llama,arxiv22-pheromone} and more recently machine learning training/inference~\cite{socc21-morphling,atc21-infaas}. Serverless computing allows the developer to offload infrastructure management tasks to the cloud provider and ensures high resource elasticity through horizontal auto-scaling. Applications developed as serverless workflows can be represented by directed acyclic graphs (DAGs) where a node presents a function and an edge represents the data exchange between functions. When triggered by an event (i.e., a request), the functions will be executed according to the data flow specified by the DAG. 
Moreover, horizontal auto-scaling takes care of the number of function instances based on the real-time request intensity. Yet, the size (e.g., CPU cores and memory size) of each function instance is typically decided with an early-binding approach---the developer sets it according to the service-level objective (SLO), e.g., meeting the end-to-end latency target at the 99th percentile (P99) in the DAG~\cite{osdi22-orion,mac22-wisefuse}.

% Thanks to its advantage of resource auto-scaling,  serverless has rendered it into a promising solution for machine learning inference/training tasks~\cite{socc21-morphling,atc21-infaas}, web services~\cite{asplos23-beehive,asplos23-beehive}, data processing~\cite{socc21-llama,arxiv22-pheromone}, etc.
% These applications are deployed as serverless workflows, with the form of  a directed acyclic graph (DAG) where nodes represent functions and edges express functions' data flow.
% Currently, serverless platforms adopt an early binding serving pattern that requires developers to specify a size (e.g., CPU cores limits or memory limits) for each function, which should not be adjusted throughout its life-cycle.
% Once deployment, developers lose their control.
% Then, providers take over the workflows, and scale out/in (horizontally) function instances, considering real-time workloads (e.g., concurrency~\cite{lambda-concurrency} and CPU/memory usage~\cite{tencent-scalability}), without the privilege to vertically adjust function sizes.

The early-binding approach shoots for the worst case for SLO guarantee and hence leads to considerable resource over-provisioning. Empirically, we observe that the worst-case execution time can be orders of magnitude larger than that of the best case. For example, the gap between the 95th percentile and the 25th percentile of the workflow execution time of Microsoft Durable Functions can be as high as 80 times on average~\cite{osdi22-orion}. Such variability can be attributed to various runtime dynamics including varying input working set size~\cite{socc23-parrotfish,socc22-cypress,eurosys21-ofc,trans-xwj-1,infocom22-o2a,xbh-2,cvpr24-socialcircle,osdi22-orion,mac22-wisefuse} and performance interference~\cite{asplos23-aquatope,osdi20-firm,isca22-lukewarm,socc21-servermore,hpdc23-propack,xwj-2,wosc20-serverless-not-server-less,ic2e22-cpu-tams}. When the size of the function is decided based on the worst case, the resource utilization will be low for most requests. For example, production serverless traces from Huawei Cloud reveal that half of the deployed functions have CPU and memory usage at merely $10\%$ and $19.5\%$, respectively~\cite{socc23-huawei-cloud}. 

% A variety of dynamics at runtime result in remarkable variance of execution performance.
% These dynamics include  varying input working set~\cite{socc23-parrotfish,socc22-cypress,eurosys21-ofc,osdi22-orion,mac22-wisefuse},  performance interference~\cite{asplos23-aquatope,osdi20-firm,isca22-lukewarm,socc21-servermore,hpdc23-propack,wosc20-serverless-not-server-less,ic2e22-cpu-tams}, and unexpected software/hardware failures~\cite{socc22-owl,sosp21-harvest-vm-for-serverless}.
% Empirical study demonstrates that within Microsoft Azure Durable~\cite{azure-durable-function} workflows' execution latency suffers a statistical gap by 80$\times$ on average.
% That of  Huawei cloud serverless rises up to 100$\times$~\cite{socc23-huawei-cloud}.
% Consequently, for the sake of SLO guarantees, developers tend to size functions based on the worst-case, e.g., the largest working sets. 
% This, however, incurs substantial resource inefficiency.
% Production traces in Huawei cloud serverless suggests that half of deployed functions have CPU usage and memory usage merely as nearly 0.1\% and 19.5\%, respectively~\cite{socc23-huawei-cloud}.  

One promising approach for addressing such resource inefficiency is to allow for runtime resource adaptation at the request level. However, the practicality of such an approach is limited by the information barrier between the application developer and the serverless provider. Specifically, application developers do not have real-time access to runtime information necessary for per-request resource adaptation\footnote{Monitoring services like Azure Monitor~\cite{azure-monitor} and AWS CloudWatch~\cite{aws-cloudwatch} can report function runtime metrics only at one-minute intervals.}. Meanwhile, the serverless provider lacks the necessary domain knowledge of the application to fine-tune the resources without violating the SLO. 
Existing works like Kraken~\cite{socc21-kraken} and Xanadu~\cite{middleware20-xanadu} employ proactive and reactive resource scalers simultaneously to provision dynamic DAGs where only a subset of functions are invoked per request. Fifer~\cite{middleware20-fifer} and BATCH~\cite{sc20-batch} allow adjusting function sizes dynamically to achieve high resource utilization with SLO guarantee. While being effective in addressing resource inefficiency, all of them ignore the aforementioned information barrier in real-world systems, rendering them impractical for the current serverless service model.

% One way to fix the resource inefficiency is to adapt function sizes, i.e., resource allocation, at runtime.
% For example, Fifer~\cite{middleware20-fifer} and BATCH~\cite{sc20-batch} to dynamically adjust batch sizes while scaling functions for higher resource utilization with SLO guarantees.
% Kraken~\cite{socc21-kraken} and Xanadu~\cite{middleware20-xanadu} employ proactive and reactive resource scalers simultaneously to provision dynamic DAG.

% These work however \jing{seems} impracticable. % to achieve the desired adaptation.
% Specifically, in current serverless platforms developers have lost their control over deployed functions' sizes on the spot, unless re-deploy them.
% Yet,  apart from manual overheads of re-deployment,  developers actually are unable to obtain \textit{fresh} runtime information.
% Specifically, owing to functions' short living  (less than 1s on average)~\cite{atc20-serverless-in-the-wild,socc23-huawei-cloud}) and substantial variance (of execution performance),  runtime information is highly varying and volatile~\cite{socc22-owl}.
% By contrast, the monitor services, such as Azure Monitor~\cite{azure-monitor} and AWS CloudWatch~\cite{aws-cloudwatch},  reports functions' runtime metrics at one-minute intervals.
% This large gap deprives the opportunity of developers to make proper and timely decisions.
% %, far over function execution life-cycle.\jing{Does this stand?}
% On the other hand,  although providers are within striking distance of runtime information~\cite{socc22-owl}, they lack essential domain knowledge, due to  commercial confidentiality, thus incapable of  conducting adaptive allocation.

We propose \namex, a novel runtime resource adaptation framework for serverless workflows. The goal of \namex is to achieve high resource efficiency while guaranteeing workflow SLOs. To this end, \namex adopts a late-binding approach where the developer synthesizes hints containing rules and options for resource adaptation for the serverless provider to perform runtime adaptation on their behalf following the hints passed to them. During the execution of the serverless workflow, when a function in the application DAG finishes, the serverless platform collects the execution time of that function and derives the time budget for the rest of the workflow. Based on the derived time budget, \namex adjusts the sizes of downstream functions using the hints provided by the developer which are ensured to meet the SLO requirement. 

The developer synthesizes the hints through comprehensive profiling. Different from current practice which uses P99 of function execution time to calculate the resource allocation, \namex allows the developer to explore different percentiles and obtain the corresponding resource demands as part of the hints. Such detailed hints allow the serverless platform to perform fine-grained resource adaptation, exploiting runtime information to optimize resource allocation to its maximum potential. However, sharing the detailed profiling information and letting the serverless platform search in a large space at runtime for the best resource configuration come with significant space and time overhead. \namex addresses this issue by condensing the hints while retaining their quality. 

% We propose \namex---a first-of-its-kind middle-ware fully considering the practicality when conducting adaptive resource allocation for serverless workflows.
% The goal of \namex is to achieve high resource efficiency while guaranteeing SLOs.
% To this end, \namex exploits the bilateral efforts of developers and providers.
% On developers side, \namex utilizes diverse percentile distributions to profile runtime performance variance.
% Moreover,  \namex regards percentiles as a knob for exploring higher resource efficiency without violating SLOs. 
% Notably, to keep high time-efficiency \namex regulates developers to synthesize hints---comprehensive and straightforward adaption rules in an offline manner while fully condensing them into a compact table.
% On providers side, \namex takes advantage of providers' capability in  prompt runtime information collection while relying on the table to instruct them to accomplish proper runtime adaptations.
%Based on that, providers can promptly and accurately adapt resource at runtime.

Overall, this paper makes the following contributions. After introducing the background and motivating the idea (\S\ref{sec:background}), we
\begin{itemize}
    \item  present the design of \namex---a novel runtime resource adaptation framework for serverless workflows to achieve high resource efficiency following a late-binding approach (\S\ref{sec:system-overview}),
    \item present effective algorithms for synthesizing, condensing, and utilizing hints to realize resource- and time-efficient runtime resource adaptation (\S\ref{sec:synthesizer}), 
    \item implement \namex and perform extensive experiments with two real-world serverless workflows (\S\ref{sec:evaluation}). Experiment results show that \namex  is able to to improves resource efficiency by 29.9\% and 34.7\% on average respectively, compared with the state-of-the-art serverless system, while guaranteeing latency SLOs.
\end{itemize}
\S\ref{sec:relatedwork} discusses related work and \S\ref{sec:conclusion} draws final conclusions.  



