\section{Related Work}
\label{sec:relatedwork}

We summarize related work covering both early-binding and late-binding approaches for serverless resource management.

% \begin{table}
%     \centering
%     \begin{tabular}{c|c|c c}
%      Name  & \textbf{Early-bind} & \multicolumn{2}{c}{\textbf{Late-bind}}\\
%      \hline
%          &  & Decision making& Runtime adaptation\\
%     \hline
%          COSE~\cite{infocom20-cose}  &  \cellcolor{lightgray}&  & \\
%          SIMPPO~\cite{socc22-simppo}  & \cellcolor{lightgray} & & \\
%          FA2~\cite{rtas22-fa2}  & & &   \\
         
%          \jing{BATCH}~\cite{sc20-batch} & &   \cellcolor{lightgray}D &\cellcolor{lightgray}D 
%     \end{tabular}
%     \caption{D and P represent developers and providers.}
%     \label{tab:my_label}
% \end{table}

\subsection{Early Binding}
COSE~\cite{infocom20-cose}, Sizeless~\cite{middleware21-sizeless}, and Parrotfish~\cite{socc23-parrotfish} adopt machine learning to learn the cost/performance of functions with respect to different sizes, and then select ``best" function sizes, such that overall costs can be minimized without violating SLOs.
FA2~\cite{rtas22-fa2} fully considers the dependency of functions within a workflow and their uncertain execution paths to periodically adapt resources, aiming to minimize resource consumption while promising SLAs.
Aquatope~\cite{asplos23-aquatope} considers runtime performance interference to decide function sizes.
ORION~\cite{osdi22-orion} and WISEFUSE~\cite{mac22-wisefuse} observe skewed function execution latency and develop a distribution-based performance modeling to provision serverless DAGs.
\jing{GrandSLAM~\cite{eurosys19-grandslam} provisions functions with fixed and identical sizes, while dynamically batching and reordering requests within each function by considering runtime slacks, aiming to achieve higher throughput without violating SLOs.}
Additionally, Morhpling~\cite{socc21-morphling} and INFaaS~\cite{socc21-llama} focus on resource auto-configuration for ML-inference specific systems.
On the other hand, there exists research from the industry that helps developers decide function sizes, such as AWS Lambda Power Tuning~\cite{lambda-tuning} and AWS Compute Optimizer~\cite{lambda-compute-optimizer}.

\subsection{Late Binding}

Cirrus~\cite{socc19-cirrus} proposes a serverless framework to boost the performance of best-efforts tasks (i.e., ML training), by integrating a client-side to monitor the remote execution while adjusting its resource allocation.
Fifer~\cite{middleware20-fifer} leverages the slacks, generated at each stage, to adjust batch sizes and scale out/in containers for higher resource utilization with SLO guarantees.
Atoll~\cite{socc21-atoll} enables proactive resource scaling as well as deadline-aware scheduling to minimize SLO violations.
BATCH~\cite{sc20-batch} fully considers serverless workload burstiness (the intensity of arrival requests) to dynamically adjust function size (memory size) and batching parameters, for the sake of minimizing monetary cost without violating SLOs.
Kraken~\cite{socc21-kraken} and Xanadu~\cite{middleware20-xanadu} employ proactive and reactive resource scalers simultaneously to provision dynamic DAG workloads, which have uncertain execution paths, aiming to minimize resource consumption without SLO violations.
Cypress~\cite{socc22-cypress} enables input size-aware request batching and resource provisioning. 
Llama~\cite{socc21-llama} focuses on auto-tuning video analytics pipelines under heterogeneous serverless environments.
Erms~\cite{asplos23-erms}, FIRM~\cite{osdi20-firm}, and Sinan~\cite{asplos21-sinan} focus on improving resource efficiency without violating SLOs, for shared microservices.
Apart from auto-scaling, there are works focusing on serverless workflows scheduling~\cite{socc20-sequoia,arxiv22-resc,ic2e22-fusionize,socc20-wukong,atc21-sonic,atc21-faastlane,asplos22-faasflow,sigcomm24-yuanrong} and over-commit~\cite{socc22-owl,socc23-golgi}.

% For example, Sequoia~\cite{socc20-sequoia} offers multiple scheduling policies available to providers/developers to alleviate issues mid-chain drops.}

% \qf{Sequoia~\cite{socc20-sequoia} optimizes workflow scheduling strategies by leveraging real-time monitoring of system and function states.}

% \qf{Sonic~\cite{atc21-sonic} proposes a layered data storage architecture to address the performance bottlenecks caused by serverless functions' interaction. Faastlane~\cite{atc21-faastlane}, sharing the same concern, employs Intel Memory Protection Keys to ensure secure execution within threads and reduce function interaction costs. } 

% \qf{Sonic~\cite{atc21-sonic} and Faastlane~\cite{atc21-faastlane} focus on the overhead caused by data interactions between functions, and optimize function scheduling accordingly.}

% \qf{Wukong~\cite{socc20-wukong} and FaasFlow~\cite{asplos22-faasflow} highlight the overhead caused by the centralized scheduler and employ distributed sub-schedulers on worker nodes.}


% \qf{ORION~\cite{osdi22-orion} system emphasizes the optimization of serverless DAG workflows. It leverages the performance distribution of serverless functions to optimize the resource allocation for each function during the workflow's execution.} 

% \qf{Llama~\cite{socc21-llama}  is primarily focused on video processing, gathering statistics for each function to provide the optimal configuration for the workflow.}



% 


















