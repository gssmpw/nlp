\section{\namex System Design}
\label{sec:system-overview}
We present \namex---a novel resource adaptation framework for serving serverless workflows.
The goal of \namex is to maximize resource efficiency while limiting SLO violations. \namex achieves this goal via a bilaterally engaged approach to combat the information barrier between the application developer and the serverless platform provider. 

\begin{figure*}[t!]
\centering
\includegraphics[width=0.85\textwidth]{./figure/system-overview.pdf}
%\vspace{-0.1cm}
\caption{An overview of the system architecture of \namex. The proposed runtime resource adaptation framework bilaterally engages the application developer and the serverless platform provider, where the developer is responsible for the offline part while the provider is responsible for the online part.}
%\vspace{-0.4cm}
\label{fig:system-overview}
\end{figure*}

\subsection{Overview}
\label{sec:system-overview:fig}
Figure~\ref{fig:system-overview} depicts an overview of the system architecture. 
\namex consists of three core components: \emph{profiler}, \emph{synthesizer}, and \emph{adapter}. 
Specifically, the profiler and synthesizer are deployed on the developer side, which are run offline, while the adapter runs online on the provider side at runtime.

The general procedure of \namex is as follows: First, the profiler interacts with the developer to collect the domain knowledge of the application, such as the workflow structure, constitutional functions execution time under varying CPU cores and concurrency settings (i.e., batch sizes), and SLO requirements.
Afterwards, the profiler extracts functions' execution time distribution (to be used as the profiles) from the collected data using different percentiles.
Then, the synthesizer takes the profiles and generates the hints table, which contains rules and options for runtime resource adaptation.
This table is submitted to the adapter on the serverless platform.
During the execution of the serverless workflow, when a function finishes, the serverless platform collects the execution time of that function and derives the time budget for the rest of the workflow.
This derived time budget is reported to the adapter, which then searches in the received hints table and notifies the platform about the adaptation decision for downstream functions.
%while relying on the hints table to adapt function sizes accordingly. 
In addition, the adapter plays the role as supervisor who carefully monitors the number of table hit/miss rates.
If the miss rate exceeds a predefined threshold, the adapter sends feedback to the developer.
% 

Note that the developer and the provider do not generally require online, continuous interaction.
The coordination happens mostly only at the beginning of workflow deployment. 
It is expected that the submitted hints will be effective throughout the execution of the workflow. 
This is because the hints table contains fine-grained entries for time budgets produced by a comprehensive exploration of the synthesizer (detailed in \S\ref{sec:synthesizer:generate}). 
In very rare cases where hints table misses are severe (i.e., the miss rate exceeds a given threshold), the adapter notifies the developer and proposes re-triggering the profiler and synthesizer to regenerate the hints table. This regeneration process is done \emph{asynchronously} while workflow execution is still in progress, albeit with sub-optimal adaptation decisions from the adapter (explained in \S{\ref{sec:adapter}}). 

\jing{Janus performs per-workflow resource adaptation that restricts the exploitation of runtime slack within the same workflow. While this design may miss some cross-workflow optimization opportunities, it allows Janus to easily support complex scenarios, such as those involving highly parallel workflows. In a multi-user scenario, the hints are managed separately for each tenant and each workflow.}

\subsection{Profiler}
\label{sec:profilier}
% Here,  we discuss how to profile function execution latency.
% Based on that, two metrics are proposed as a preparation for synthesizing hints.
% %\subsection{Diverse percentiles based profiling}
% \textit{Diverse percentiles based profiling}
The profiler is responsible for collecting the execution time of functions under varying resources (i.e., CPU cores) and concurrency levels (i.e., batch sizes) while extracting execution time distribution by using different percentiles. 
The percentiles can be configured based on SLO requirements.
By default, we follow the widely used approach of meeting the end-to-end latency target at the 99th percentile (P99) as latency SLO~\cite{osdi22-orion,mac22-wisefuse}.
Therefore, we use percentiles ranging from 1\% to 99\% with a step of 5\% and the latency profiling of functions is done between P1 and P99. Latency numbers out of the P1-P99 range are not accounted for by Janus for optimization. 
Janus can accommodate more stringent SLO targets (e.g., at P99.9) by instructing the profiler and synthesizer to use higher percentiles (P99.9). 
% but at the cost of reduced overall resource efficiency. 


% As explained in \S{\ref{sec:bg:worst-case}}, function execution time is variable and forms a skewed distribution. 
% This renders existing resource allocation approaches that depend on a single percentile (e.g., the 99th) on such a distribution inadequate (i.e., either under-provisioning or over-provisioning) for a majority of function invocations.
% To tackle this issue, for any given batch size we introduce diverse percentiles on the function execution time distribution to calculate the resource demand, which is expressed as $L(p,k)$, with CPU cores and percentiles denoted as $k$ and $p$, respectively.

The diversity in percentiles brings more opportunities to achieve higher resource efficiency but comes at a higher risk of SLO violations.
Specifically, when setting percentiles lower than 99\%, it may cause under-estimation of function execution time, making functions prone to over-time execution, i.e., their actual execution time exceeds the profiled execution time.
To quantify the degree of potential over-time execution, we propose a metric called \emph{timeout}, which is expressed as
\begin{eqnarray}
     D(p,k) = L(99,k)-L(p,k),
\end{eqnarray}
where $L(p,k)$ represents the profiled execution time, with percentiles and CPU cores denoted as $k$ and $p$, respectively.
For preventing SLO violations, \namex must provision more processing resources for downstream functions to absorb such timeouts.
To this end, we propose a metric called \emph{resilience} to quantify the absorption capability, which is expressed as 
\begin{eqnarray}
    R(p,k)= L(p,K_{max})-L(p,k),
\end{eqnarray}
where $K_{max}$ denotes the maximum available resources.
Any timeout must be restricted within the upper bound of resilience, such that guaranteeing the SLO is still possible.

\subsection{Synthesizer}
% The synthesizer provides the intelligence of the system by generating and condensing hints in the form of a table.
% The goal of the synthesizer is to promise its generated hints with maximum resource efficiency under given time budgets.
% To this end, the synthesizer introduces percentiles as a knob to exploit a larger optimization space.
% Meanwhile, for meeting the time budget requirements, the synthesizer strictly restricts its exploration within a ``safety zone", where timeout does not exceed the resilience (explained in \S\ref{sec:synthesizer:generate}).

The synthesizer provides the intelligence of the system by generating and condensing hints in the form of a table.
The goal of the synthesizer is to produce hints with high hit rates and maximum resource efficiency.  
To this end, the synthesizer evaluates potential time budgets across a broad range considering achievable execution time of individual functions.
Based on that, the synthesizer explores diverse percentiles for functions to enhance their resource efficiency.
Moreover, the synthesizer leverages \emph{timeout} and \emph{resilience}---metrics to quantify the risk of SLO violations as detailed in \S\ref{sec:profilier}---to regulate the above exploration, aiming to provide SLO compliance.
%With that, it uses percentile as a knob to exploit a larger optimization space.
%In addition, the synthesizer restricts its exploration within a ``safety zone", where timeout does not exceed the resilience, for meeting the time budget requirements (explained in \S\ref{sec:synthesizer:generate}).

On the other hand, to keep hints tables' efficiency in both space and searching, the synthesizer makes full use of the discreteness in resource adaptation 
to condense the generated hints (detailed in \S\ref{sec:synthesizer:condense}).
Finally, the synthesizer provides a highly compact hints table with three simple fields: \textit{start}, \textit{end}, and \textit{size}.
This means any workflow with their time budget between \textit{start} and \textit{end} should be provisioned with resource amounts as \textit{size}, which can ensure the maximum resource efficiency without violating the available time budget.


% \jing{To promise hints tables with high hit rates, the synthesizer evaluates potential time budgets across a broad range.
% Specifically, it determines the upper and lower bounds of considered time budgets based on the achievable execution time of individual functions.
% Furthermore, time budgets are finely divided down to as little as 1 ms .
% }

% \jing{To keep hints tables' efficiency in both space and searching, the synthesizer makes full use of the discreteness in resource adaptation 
% to condense the generated hints (detailed in \S\ref{sec:synthesizer:condense}).}
% Finally, the synthesizer provides a highly compact hints table with three simple fields: \textit{start}, \textit{end}, and \textit{size}.
% This means any workflow with their time budget between \textit{start} and \textit{end} should be provisioned with resource amounts as \textit{size}, which can ensure the maximum resource efficiency for the (sub-)workflow without violating the available time budgets.

\subsection{Adapter}
\label{sec:adapter}
After a function in the workflow finishes, the adapter derives the available time budget for the remaining functions, and searches the hints table accordingly to figure out the appropriate resource allocation, such that the required time budget can be met with the minimum resource consumption.
If the above search results in a miss possibly due to unexpected runtime dynamics (detailed in~\S\ref{sec:bg:worst-case}), the adapter will scale functions up to the maximum available resources, to prevent SLO violations.
Afterwards, the adapter notifies the platform about the adaptation decision. 
\jing{This highly streamlined decision-making process enhances Janus's scalability.
}

On the other hand, the adapter continuously counts the hits and misses during hint table searches. 
In rare cases where the miss rate exceeds a predefined threshold, it assumes that the execution time distribution may have changed. 
In that case, the adapter notifies the developer and suggests triggering the profiler and synthesizer to regenerate hints tables asynchronously.
This asynchronous regeneration can strike the trade-off between resource- and time-efficiency in adaptation.

% \begin{algorithm}[!t]
%     \caption{Adapt resource online \label{alg:janus:adapt}}
%     \LinesNumbered    
%     \KwIn{$\mathbf{F}= \left\langle f_1,\dots,f_N \right\rangle$: (sub-)workflow}
%     \KwIn{$\mathbf{U}, T$: hints table and time budget/slack}
%     \KwOut{$k$: CPU cores for head function}
% 	\SetKwFunction{FMain}{\texttt{adapt}}
%     \SetKwProg{Fn}{Function}{:}{}
    
%     \Fn{\FMain{$\mathbf{F},\mathbf{U}, T$}}{
%     $ i \leftarrow \mathbf{U}.$\texttt{index}($T$)\\
%     \If{$i=\emptyset$}
%     {
%     $\mathbf{K} \leftarrow $\texttt{generate}($\mathbf{F},T, \emptyset$) \\
%     $\mathbf{U} \leftarrow $\texttt{condense}($\{\left \langle T, \mathbf{K}\right\rangle\}$)\\
%     }
%     \Else{
%     $\mathbf{K} \leftarrow \mathbf{U}[i]$
%     }
%     \text{return}~$\mathbf{K}[0]$
%     }

% \end{algorithm}