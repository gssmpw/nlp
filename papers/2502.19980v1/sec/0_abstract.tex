\begin{abstract}
\label{sec:abstract}
Recent studies highlight the promise of LLM-based prompt optimization, especially with TextGrad~\citep{yuksekgonul2024textgrad}, which automates ``differentiation'' via texts and backpropagates textual feedback provided by LLMs. This approach facilitates training in various real-world applications that do not support numerical gradient propagation or loss calculation.  It opens new avenues for optimization in decentralized, resource-constrained environments, suggesting that users of black-box LLMs (\emph{e.g.}, ChatGPT) could enhance components of LLM agentic systems (such as prompt optimization) through collaborative paradigms like federated learning (FL). In this paper, we systematically explore the potential and challenges of incorporating textual gradient into FL. Our contributions are fourfold.
\textbf{Firstly}, we introduce a novel FL paradigm, \underline{Fed}erated \underline{Text}ual \underline{Grad}ient (\ours{}), that allows FL clients to upload their locally optimized prompts derived from textual gradients, while the FL server aggregates the received prompts through text summarization. Unlike traditional FL frameworks, which are designed for numerical aggregation, \ours{} is specifically tailored for handling textual data, expanding the applicability of FL to a broader range of problems that lack well-defined numerical loss functions. 
\textbf{Secondly}, building on this design, we conduct extensive experiments to explore the feasibility of federated textual gradients. Our findings highlight the importance of properly tuning key factors (\emph{e.g.}, local steps) in FL training to effectively integrate textual gradients. 
\textbf{Thirdly}, We highlight a major challenge in federated textual gradient aggregation: retaining essential information from distributed prompt updates. Concatenation often produces prompts that exceed the LLM APIâ€™s context window, while summarization can degrade performance by generating overly condensed or complex text that lacks key context. 
\textbf{Last but not least}, in response to this issue, we improve the vanilla variant of \ours{} by providing actionable guidance to the LLM when summarizing client prompts by leveraging the Uniform Information Density principle. Such a design reduces the complexity of the aggregated global prompt, thereby better incentivizing the LLM's reasoning ability. Through this principled study, we enable the adoption of textual gradients in FL for optimizing LLMs, identify important issues, and pinpoint future directions, thereby opening up a new research area that warrants further investigation.
Our code is available on \url{https://github.com/ubc-tea/FedTextGrad}.


\end{abstract}
