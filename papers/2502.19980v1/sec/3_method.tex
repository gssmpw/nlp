\section{The Proposed \ours{} Method}

In this section, we first provide background on TextGrad, including its forward operation, backpropogation and how LLM-as-the-optimizer can be integrated with TextGrad (Section~\ref{subsec:2.1}). Next, we explain the analogy between textual and numerical gradients, and describe its extension into the FL setting - \ours{} (Section~\ref{subsec:2.2}). Finally, we present preliminary results across various LLM APIs using TextGrad and \ours{}, highlighting the performance drops (Section~\ref{subsec:2.3}).

\subsection{Preliminaries on TextGrad.}
\label{subsec:2.1}
TextGrad is a framework that leverages LLMs for iterative prompt optimization through natural language feedback, combining (1) a forward operation to generate and evaluate responses, (2) backpropagation-like updates using textual gradients, and (3) LLM-based optimization via Textual Gradient Descent to refine prompts effectively across tasks.

\paragraph{Forward Operation of TextGrad.}
As illustrated in Figure \ref{fig:fedtextgrad_framework}, the forward operation of TextGrad take input query and the \emph{Prompt} (parameter to be optimized) to a fixed LLM to generating responses. This \emph{Response} is then concatenated with the \emph{Evaluation Instruction} to form the input for the next LLM call for evaluation. The structure of the computational graph can be expressed as:
\[
\text{Query} + \text{Prompt} \xrightarrow{\text{LLM}} \text{Response} + \text{Evaluation Instruction} \xrightarrow{\text{LLM}} \text{Evaluation},
\]
where \(+\) denotes the concatenation operation.  The depth of this computational graph can be extended by adding intermediate response nodes before performing the final evaluation step. This extension accommodates a more complex step-by-step reasoning chain, which is analogous to adding more layers in a deep neural network.

\paragraph{Backpropogation of TextGrad.}
Based on the output of the forward operation, TextGrad proceeds with backpropagation to update the \emph{Prompt} by calculating \({\partial \text{Evaluation}}/{\partial \text{Prompt}}\) using the Chain Rule -- first computing the `gradient' with respect to the Response, \({\partial \text{Evaluation}}/{\partial \text{Response}}\), by collecting feedback on the \emph{Response} from the \emph{Evaluation}; then \({\partial \text{Response}}/{\partial \text{Prompt}}\), by obtaining prompt updates from Response using LLMs.
The textural gradient represents natural language feedback, such as: ``This response can be improved by...", guiding the adjustment of variables (\textit{e.g.}, the \emph{Prompt}) to optimize the downstream objective, similar to how numerical gradients function in traditional optimization. 
This approach allows for the iterative refinement of the \emph{Prompt}, analogous to the use of numerical gradients in backpropagation to optimize neural network weights.

\paragraph{LLMs-as-Optimizers in TextGrad.} After obtaining the `gradient' (${\partial \text{Evaluation}}/{\partial \text{Prompt}})$, Textual Gradient Descent (TGD) leverages LLMs to update the \emph{Prompt}, by iteratively refining it using the obtained textual `gradient', similar to the backpropagation process in neural networks. The update rule for the \emph{Prompt} is:
\[
\text{Prompt}_{\text{new}} = \text{TGD.step}\left( \text{Prompt}, {\partial \text{Evaluation}}/{\partial \text{Prompt}} \right), \tag{8}
\]
where textual gradients inform the optimization process. Essentially, {\tt{TGD.step($\cdot$)}} is implemented through an LLM call using a predefined instruction template: ``Below are the criticisms on \{Prompt\}: \{${\partial \text{Evaluation}}/{\partial \text{Prompt}}$\}. Incorporate the criticisms and generate an updated prompt."
\subsection{From TextGrad to \ours{}.}
\label{subsec:2.2}

We introduce \ours{}, a novel adaptation of TextGrad for FL environments. While our initial demonstration focuses on prompt optimization~\citep{pryzant2023automatic}, the methodology is versatile and can be applied to a wide range of tasks such as retrieval-augmented generation~\citep{lewis2020retrieval} and tool use~\citep{schick2024toolformer} supporting federated LLM agentic systems. 
\ours{} extends TextGrad by integrating textual gradient-based optimization into FL client local training. In this setup, clients optimize their local prompts using LLM-generated textual gradients, sharing these prompts instead of raw gradient updates with the central server. It mirrors \emph{FedAvg}~\citep{mcmahan2017communication}, where local model updates are aggregated at the server. Rather than aggregating numerical gradients, \ours{} aggregates natural language prompts across clients. The key innovation in \ours{} is enabling collaborative textual optimization in FL settings, where prompts are iteratively improved by individual FL clients and then aggregated to form a global prompt. The challenge here lies in defining an effective aggregation strategy for these local prompts. We first explore intuitive methods such as concatenation and summarization to evaluate their effectiveness across various LLM APIs and FL settings. 

\subsection{\ours{} Framework Description}
\label{subsec:2.3}
The \ours{} framework iteratively refines prompts through (1) client-specific updates using textual gradients, (2) server-side aggregation into a global prompt, and (3) redistribution to clients across communication rounds.
The detailed process, outlined in Algorithm~\ref{alg:fedtxg}, follows these steps:
\\
1. \textbf{Client Prompt Updates:} (Algorithm~\ref{alg:fedtxg}, steps 12-18): Each client \(i\) receives the global prompt \(P^t\) and fine-tunes it using its local dataset \(\mathcal{D}_i\). Textual gradients generated by the LLM guide this local optimization, producing an updated prompt \(P_i^t\), which captures the unique distribution of each client's data.
\\
2. \textbf{Server Prompt Aggregation} (Algorithm~\ref{alg:fedtxg}, step 9): The server collects the updated prompts \(P_i^t\) from all clients and aggregates them into a new global prompt \(P^{t+1}\). Aggregation strategies such as concatenation or summarization are used to integrate client updates.
\\
3. \textbf{Global Prompt Distribution} (Algorithm~\ref{alg:fedtxg}, steps 6-8): The server then distributes the updated global prompt \(P^{t+1}\) to all clients. This iterative process continues across several communication rounds, with each iteration refining the global prompt based on client-specific updates.

This iterative framework enables prompt updates at both local and global levels, ensuring the model adapts effectively to heterogeneous client environments.

\input{figure/algo_box}




































    
    





