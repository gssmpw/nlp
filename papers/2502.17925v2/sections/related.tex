\section{Related Work}
\label{sec:related}

\textbf{LLMs for Formal Proof Generation.} Large Language Models (LLMs) have demonstrated significant potential in the field of formal theorem proving \citep{yang2024formalmathematicalreasoningnew}, finding applications across various proof assistants \citep{yang2024leandojo, song2024largelanguagemodelscopilots, lama2024benchmarking}. Current research on LLM-based theorem proving primarily focuses on several key tasks. A prominent application is tactic suggestion. Following GPT-f \citep{polu2020generative}, LLMs are employed to predict the most promising next tactic given the current proof state. These methods are often coupled with proof search algorithms, such as best-first search \citep{yang2024leandojo} or majority voting \citep{zhou2024don}, to explore the proof space and discover complete proofs \citep{wu2024inference}. Other techniques, such as retrieval-augmented LLMs \citep{yang2024leandojo} and agentic approaches \citep{thakur2024incontextlearningagentformal}, provides further aids for tactic generation by selecting relevant lemmas and enabling multi-round proof refinement utilizing environment feedback. Moreover, emerging research directions include autoformalization  \citep{wu2022autoformalization,jiang2023multilingual}, which aims to translate informal mathematical text into formal proofs, and the direct generation of complete proof sketches  \citep{jiang2022draft, wang2024proving}, both of which can be combined with proof generation to enable large-scale training despite inherent proof data scarcity. Our work addresses the gap from local tactic prediction to a global understanding of the proof trajectory by focusing on predicting the number of remaining steps required for proof completion, offering a novel way for new applications of reinforcement learning in automated theorem proving.

\textbf{Interactive Tools for Formal Theorem Proving.} Mathematicians proving theorems in Lean can significantly benefit from interactive tools that integrate seamlessly into the Lean workflow and provide aids.
LLMStep \citep{welleck2023llmstep} extracts current proof states from Lean and sends it to a remote server for LLM-generated tactic suggestions. 
LeanCopilot \citep{song2024largelanguagemodelscopilots} improves the user experience by having fully native tactic suggestion and proof search tools in Lean, besides an additional functionality of premise selection, providing more comprehensive assistance for the proving process. 
CoqPilot \citep{Kozyrev_2024}, a VS Code extension for Coq, uses LLMs, among other generative methods, to fill in proof holes by an ``admit'' tactic.
Unlike these tactics or proof-centric approaches, we predict the number of remaining steps by adding a new tactic, \texttt{predict\_steps\_with\_suggestion} based on LeanCopilot, providing tactic suggestions ranked by the output number of remaining steps as a score.

\textbf{LLM Guidance in Search.} Effective proof search is essential for automated theorem proving. While scaling computational resources during search has led to significant advancements, as seen in AlphaGeometry \citep{trinh2024solving} and AlphaProof \citep{alphaproof2024ai} for IMO problems and in recent work on natural language reasoning \citep{lightman2023let,yang2022generating, zhang2024rest,xie2024monte} (including OpenAI's o1, o3 model \citep{jaech2024openai, xu2025towards}), proof search is a bit different. The vast search space of possible proof steps necessitates effective guiding mechanisms. This highlights the need for methods that can provide a global perspective on proof progress, which our work addresses by predicting the number of remaining steps.
