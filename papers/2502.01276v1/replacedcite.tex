\section{Related Work}
\label{sec:related-work}

Hyperparameter importance (HPI) has gained significant attention in machine learning due to its crucial role in justifying the need for HPO and in attributing performance improvements to specific hyperparameters ____.
A variety of approaches have been developed to assess how different hyperparameters affect the performance of resulting models, ranging from simple (surrogate-based) ablations ____ to sensitivity analyses and eliciting interactions between hyperparameters based on the functional ANOVA framework ____. 
In this work, we propose a novel approach to quantifying HPI using Shapley values, with a particular focus on capturing interactions between hyperparameters through Shapley interaction indices. We focus on quantifying interactions since, in ____, it has been noticed that interaction is occasionally comparably low, which could serve as a foundation for a new generation of HPO methods that do not assume interactions to be omnipresent.

Beyond quantifying HPI, to better understand the impact of hyperparameters and the tuning behavior of hyperparameter optimizers, other approaches have been proposed, such as algorithm footprints ____, partial dependence plots for hyperparameter effects____ or deriving symbolic explanations ____, providing an interpretable model for estimating the performance of a learner from its hyperparameters. In this work, we focus on quantifying the impact of tuning a hyperparameter on the performance.


%In this paper, we propose \tool, a post-hoc explanation framework for analyzing hyperparameter importance and interactions using Shapley values ____ and Shapley interaction indices ____. Stemming from the field of algorithmic game theory, Shapley values provide an additive decomposition of a given value function -- in our case, a performance measure -- across a set of players, which in this context represent hyperparameters. Unlike existing methods, Shapley values naturally handle correlations among hyperparameters and fairly distribute importance by considering all possible subsets of hyperparameters.

% Overall, we define \numgames games to quantify the importance of hyperparameters, each of which can be used to obtain different types of explanations either of a given hyperparameter configuration, of a hyperparameter search space, or an optimizer's characteristics.

%While we generate first insights with the help of our framework, we also showcase the usefulness of the explanations in a downstream task, performing hyperparameter optimization for the same dataset and performance measure as a proof of concept that our approach identifies, in fact, meaningful importances and interactions. In our experiments, focusing on hyperparameters identified as important with a low degree of interactions by \tool proves beneficial, resulting in better anytime performance. However, ignoring the presence of interactions deteriorates performance in turn. All in all, it provides evidence for the soundness and usefulness of \tool's explanations.