
\section{Experimental Results}\label{sec:experiments_main}

We validate the theoretical results of our work on numerical and two real-world experiments.
The details of the setup are presented in greater detail in the appendix (Section~\ref{sec:experiments_detailed}) and the code is provided in supplementary materials.
Our experiments assume bandit feedback, although in the appendix we also include results under the full feedback model.
We provide an overview of our setup first.

\textbf{Numerical problems.}
Firstly, we formulate three numerical problems, which are based on examples suggested in Sections~\ref{sec:assumptions_examples}.
We randomly generate monotone payoff operators that are linear (\textsc{Linear}) and a payoff function that admits a KL divergence potential (\textsc{kl}).
We also analyze a particular ``beach bar process'' (\textsc{bb}), a stateless version of the example presented in \citep{perrin2020fictitious}.
For numerical examples, we use $K=5$, and vary between various population sizes in $N=\{20,50,100, 200, 500, 1000\}$ to quantify the effect of finite $N$ and compare with theoretical bias bounds.
We set the parameters $\varepsilon, \tau$ using the theoretical values from Corollary~\ref{corollary:bandit}.

\textbf{Traffic flow simulation.}
Using the UTD19 dataset \citep{loder2019understanding}, we evaluate our algorithms on traffic congestion data on three different routes for accessing the city center of Zurich (\textsc{utd}).
The UTD19 dataset features many closed loop sensors across various urban roads in Zurich, providing granular measurements of road occupancy and traffic flow.
We use these real-world stationary detector measurements to approximate traveling times as a function of route occupancy with a kernelized regression model on three routes.
We then evaluate our algorithms on estimated traveling times.
The real-world data from the UTD19 dataset suggests the travel duration (and therefore the payoffs) are in fact non-increasing in the occupancy of each segment, and hence can be reasonably modeled by a monotone payoff.
Further empirical evaluation of monotonicity is discussed in Appendix~\ref{appendix:exp:traffic}.

\textbf{Access to the Tor network.}
We also run experiments on accessing the Tor network, which is a large decentralized network for secure communications and an active area of research in computer security \citep{jansen2014sniper,mccoy2008shining}.
The Tor network consists of many decentralized servers and access to the network is achieved by communicating with one of many entry guard servers (a list advertised publicly \citep{torentryguards}, some hosted by universities).
As the entry guards serve a wide public of users and each user is free to choose an entry point, the network is an ideal setting to test our algorithms.
We simulate 100 independent agents accessing Tor by choosing among $K=5$ entry servers every minute and use the real-world ping delays for bandit feedback.
Our empirical evaluations show that monotonicity is also a reasonable assumption for the Tor network experiment due to the fact that response times tend to be non-decreasing in occupation: we provide an empirical argument in Appendix~\ref{appendix:exp:tor}.

Overall, our experiments in both models and real-world use cases support our theory.
Firstly, our experiments verify learning in the sense of decreasing maximum exploitability $\max_{i\in\setN} \setE^i_{\text{exp}}(\{\vecpi^j\}_{j=1}^N)$ and mean distance to MF-NE given by $\frac{1}{N}\sum_i \|\vecpi^* - \vecpi^i_t\|_2$ during IL (Figure\ref{figure:main}-b,c).
As expected from Corollary~\ref{corollary:bandit}, the maximum exploitability oscillates but remains bounded (due to the effect of finite $N$).
Furthermore, the agents converge to policies closer to the MF-NE as $N$ increases (Figure\ref{figure:main}-c), empirically demonstrating that the MF-NE is an accurate description of the limiting behaviour of SMFG as $N\rightarrow\infty$.
The scale of the excess exploitability in our experiments decreases rapidly in $N$, allowing our results to be significant even for hundreds or thousands of agents.

\begin{figure}[h]
\begin{tabular}{ccc}
  \includegraphics[width=0.3\linewidth]{figures/n_dependence_toy_with_utd.png} & 
  \includegraphics[width=0.3\linewidth]{figures/linear_bandit_exploitability_curve.png} &   
  \includegraphics[width=0.3\linewidth]{figures/utd_l2_dist.png} \\
(a) & (b) & (c)
\end{tabular}
\caption{
Results for numerical problems \textsc{kl}, \textsc{bb}, \textsc{linear}, \textsc{utd}.
(a) Maximum exploitability of $N$ agents at convergence as a function of $N$ for different problems,
(b) The max. exploitability among $N$ agents during training with linear payoff (\textsc{linear}), for different $N$,
(c) The mean $\ell_2$ distance of agent policies during training to the MF-NE in the Zurich traffic flow simulation problem (\textsc{utd}).
}
\label{figure:main}
\end{figure}

\begin{figure}[h]
\begin{tabular}{ccc}
 \includegraphics[width=0.3\linewidth]{figures/tor_access_probability.png} &   \includegraphics[width=0.3\linewidth]{figures/tor_access_frequency.png} & \includegraphics[width=0.3\linewidth]{figures/tor_waiting_time.png}\\
(a) & (b) & (c)
\end{tabular}
\caption{
Results for the Tor network experiment.
(a) Average policies (probability distribution) over 5 servers of the 100 agents in the Tor network access experiment,
(b) Empirical distribution of agents over Tor entry servers during training on 5 servers (different colors indicate different entry servers),
(c) Average waiting times for Tor network access during training.
}
\label{figure:tor_exp}
\end{figure}

Our experimental results in traffic congestion and server access also support our theoretical claims.
Despite having no \emph{a priori} assumption of monotonicity, our methods efficiently converge.
We note that in the case of the network access experiments, we refrain from simulating thousands of agents to minimize network impact.
This implies that the delays have a high dependence on external factors as the behavior of other users will be dominant.
Nevertheless, our experiment indicates that our algorithm can produce competitive results in the wild (Figure~\ref{figure:tor_exp}).

Finally, we note that while there are no algorithms that have theoretical guarantees in the $N$ agent IL setting, we compare our results with a heuristic extension of online mirror descent \citep{perolat2022scaling} in the numerical problems, see Appendix~\ref{appendix:comparison_omd}.
Our results suggest a naive extension of OMD to our setting will lead to divergence or cycling.
