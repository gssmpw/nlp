[
  {
    "index": 0,
    "papers": [
      {
        "key": "geman2015visual",
        "author": "Geman, Donald and Geman, Stuart and Hallonquist, Neil and Younes, Laurent",
        "title": "Visual turing test for computer vision systems"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "antol2015vqa",
        "author": "Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi",
        "title": "Vqa: Visual question answering"
      },
      {
        "key": "malinowski2014multi",
        "author": "Malinowski, Mateusz and Fritz, Mario",
        "title": "A multi-world approach to question answering about real-world scenes based on uncertain input"
      },
      {
        "key": "goyal2017making",
        "author": "Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi",
        "title": "Making the v in vqa matter: Elevating the role of image understanding in visual question answering"
      },
      {
        "key": "liu2024visual",
        "author": "Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae",
        "title": "Visual instruction tuning"
      },
      {
        "key": "liu2025mmbench",
        "author": "Liu, Yuan and Duan, Haodong and Zhang, Yuanhan and Li, Bo and Zhang, Songyang and Zhao, Wangbo and Yuan, Yike and Wang, Jiaqi and He, Conghui and Liu, Ziwei and others",
        "title": "Mmbench: Is your multi-modal model an all-around player?"
      },
      {
        "key": "yu2023mm",
        "author": "Yu, Weihao and Yang, Zhengyuan and Li, Linjie and Wang, Jianfeng and Lin, Kevin and Liu, Zicheng and Wang, Xinchao and Wang, Lijuan",
        "title": "Mm-vet: Evaluating large multimodal models for integrated capabilities"
      },
      {
        "key": "li2024seed",
        "author": "Li, Bohao and Ge, Yuying and Ge, Yixiao and Wang, Guangzhi and Wang, Rui and Zhang, Ruimao and Shan, Ying",
        "title": "SEED-Bench: Benchmarking Multimodal Large Language Models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "johnson2017clevr",
        "author": "Johnson, Justin and Hariharan, Bharath and Van Der Maaten, Laurens and Fei-Fei, Li and Lawrence Zitnick, C and Girshick, Ross",
        "title": "Clevr: A diagnostic dataset for compositional language and elementary visual reasoning"
      },
      {
        "key": "yue2024mmmu",
        "author": "Yue, Xiang and Ni, Yuansheng and Zhang, Kai and Zheng, Tianyu and Liu, Ruoqi and Zhang, Ge and Stevens, Samuel and Jiang, Dongfu and Ren, Weiming and Sun, Yuxuan and others",
        "title": "Mmmu: A massive multi-discipline multimodal understanding and reasoning benchmark for expert agi"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "marino2019ok",
        "author": "Marino, Kenneth and Rastegari, Mohammad and Farhadi, Ali and Mottaghi, Roozbeh",
        "title": "Ok-vqa: A visual question answering benchmark requiring external knowledge"
      },
      {
        "key": "wang2015explicit",
        "author": "Wang, Peng and Wu, Qi and Shen, Chunhua and Hengel, Anton van den and Dick, Anthony",
        "title": "Explicit knowledge-based reasoning for visual question answering"
      },
      {
        "key": "wang2017fvqa",
        "author": "Wang, Peng and Wu, Qi and Shen, Chunhua and Dick, Anthony and Van Den Hengel, Anton",
        "title": "Fvqa: Fact-based visual question answering"
      },
      {
        "key": "zellers2019recognition",
        "author": "Zellers, Rowan and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin",
        "title": "From recognition to cognition: Visual commonsense reasoning"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "marino2019ok",
        "author": "Marino, Kenneth and Rastegari, Mohammad and Farhadi, Ali and Mottaghi, Roozbeh",
        "title": "Ok-vqa: A visual question answering benchmark requiring external knowledge"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "schwenk2022okvqa",
        "author": "Schwenk, Dustin and Khandelwal, Apoorv and Clark, Christopher and Marino, Kenneth and Mottaghi, Roozbeh",
        "title": "A-okvqa: A benchmark for visual question answering using world knowledge"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "jain2021select",
        "author": "Jain, Aman and Kothyari, Mayank and Kumar, Vishwajeet and Jyothi, Preethi and Ramakrishnan, Ganesh and Chakrabarti, Soumen",
        "title": "Select, substitute, search: A new benchmark for knowledge-augmented visual question answering"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "Wei2024MeasuringSF",
        "author": "Jason Wei and Nguyen Karina and Hyung Won Chung and Yunxin Joy Jiao and Spencer Papay and Amelia Glaese and John Schulman and William Fedus",
        "title": "Measuring short-form factuality in large language models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "he2024chinese",
        "author": "He, Yancheng and Li, Shilong and Liu, Jiaheng and Tan, Yingshui and Wang, Weixun and Huang, Hui and Bu, Xingyuan and Guo, Hangyu and Hu, Chengwei and Zheng, Boren and others",
        "title": "Chinese simpleqa: A chinese factuality evaluation for large language models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "Wei2024MeasuringSF",
        "author": "Jason Wei and Nguyen Karina and Hyung Won Chung and Yunxin Joy Jiao and Spencer Papay and Amelia Glaese and John Schulman and William Fedus",
        "title": "Measuring short-form factuality in large language models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "he2024chinese",
        "author": "He, Yancheng and Li, Shilong and Liu, Jiaheng and Tan, Yingshui and Wang, Weixun and Huang, Hui and Bu, Xingyuan and Guo, Hangyu and Hu, Chengwei and Zheng, Boren and others",
        "title": "Chinese simpleqa: A chinese factuality evaluation for large language models"
      }
    ]
  }
]