\documentclass[9pt,twocolumn,twoside]{pnas-new}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ARXIV instructions
% control+F ARXIV Throughout:
%    - main.text
%    - SI.tex
%    - pnasresearcharticle.sty
%    - pnassupportinginfo.sty
%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% FOR ARXIV, UNCOMMENT THIS %%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% remove PNAS branding
\setboolean{displaywatermark}{false} % Set to false to remove the watermark
\fancypagestyle{firststyle}{}
\pagestyle{fancy}
\fancyhf{} % Clear all headers and footers
\fancyfoot[R]{\textbf{\thepage}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% END ARXIV ADDITON SECTION %%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Use the lineno option to display guide line numbers if required.

\templatetype{pnasresearcharticle} % Choose template
% {pnasresearcharticle} = Template for a two-column research article
% {pnasmathematics} %= Template for a one-column mathematics article
% {pnasinvited} %= Template for a PNAS invited submission
%\usepackage{nameref}
\usepackage{siunitx}
\usepackage{mathtools}
\usepackage{xspace}
\usepackage{enumitem}
\usepackage{filecontents}

% all of this is to be able to references labels from SI.tex in this file
\usepackage{xr-hyper}
\makeatletter
\newcommand*{\addFileDependency}[1]{% argument=file name and extension
  \typeout{(#1)}
  \@addtofilelist{#1}
  \IfFileExists{#1}{}{\typeout{No file #1.}}
}
\makeatother
\newcommand*{\myexternaldocument}[1]{%
    \externaldocument{#1}%
    \addFileDependency{#1.tex}%
    \addFileDependency{#1.aux}%
}
\myexternaldocument{si}
\usepackage{hyperref}

\newcommand{\ttt}{\ensuremath{\Delta^{*}}\xspace}
\newcommand{\ttttr}{\ensuremath{\Delta^{*}_{\textrm{true}}}\xspace}
\newcommand{\tttpr}{\ensuremath{\Delta^{*}_{\textrm{pred}}}\xspace}
\newcommand{\ttrans}{\ensuremath{t^{*}}\xspace}

\begin{document}

\title{Interpretable Early Warnings using Machine Learning in an Online Game-experiment} 

% Use letters for affiliations, numbers to show equal authorship (if applicable) and to indicate the corresponding author
\author[a,b,1,2]{Guillaume Falmagne}
\author[a,b,1]{Anna B. Stephenson}
\author[a,b]{Simon A. Levin}

\affil[a]{High Meadows Environmental Institute, Princeton University, Princeton, NJ 08544}
\affil[b]{Department of Ecology and Evolutionary Biology, Princeton University, Princeton, NJ 08544}

% Please give the surname of the lead author for the running footer
\leadauthor{Falmagne}

% Please add a significance statement to explain the relevance of your work
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% FOR ARXIV, REMOVE SIGNIFICANCE STATEMENT %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\significancestatement{
% 110 words
%Critical transitions can model abrupt regime shifts in socio-ecological systems. While generic early warning signals that apply across systems have been investigated, no universal signal exists. We therefore propose a data-driven and system-specific approach to developing warning signals. Reddit's r/place game-experiment provides a rich socio-ecological dataset, which we use to train the first machine-learning-based early warning system to predict and explain transitions in a human behavioral system. We predict the time-to-transition using system-specific temporal variables, drastically improving upon standard early warning signals. Furthermore, analysis of the predictions provides insight into the dynamics driving these transitions. Our approach can be applied to other complex systems to foresee and understand transitions.

%Authors must submit a 120-word maximum statement about the significance of their research paper written at a level understandable to an undergraduate educated scientist outside their field of speciality. The primary goal of the significance statement is to explain the relevance of the work in broad context to a broad readership. The significance statement appears in the paper itself and is required for all research papers.
%}

% Please include corresponding author, author contribution and author declaration information
%\authorcontributions{G.F., A.B.S., and S.A.L. designed the research. G.F. and A.B.S. analyzed data and contributed new analytic tools. G.F., A.B.S., and S.A.L. wrote the paper.}
\authordeclaration{The authors declare no competing interest.}
\equalauthors{\textsuperscript{1}These authors contributed equally to the work.}
\correspondingauthor{\textsuperscript{2}To whom correspondence may be addressed. E-mail: g.falmagne@princeton.edu}

% At least three keywords are required at submission. Please provide three to five keywords, separated by the pipe symbol.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% FOR ARXIV REMOVE KEYWORDS %%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\keywords{early warning signals $|$ critical transitions $|$ machine learning $|$ collaborative games $|$ online experiments}
\begin{abstract}
%Please provide an abstract of no more than 250 words in a single paragraph. Abstracts should explain to the general reader the major contributions of the %article. References in the abstract must be cited in full within the abstract itself and cited in the text.

% word count: 228
Stemming from physics and later applied to other fields such as ecology, the theory of critical transitions suggests that some regime shifts are preceded by statistical early warning signals. 
Reddit's r/place experiment, a large-scale social game, provides a unique opportunity to test these signals consistently across thousands of subsystems undergoing critical transitions. In r/place, millions of users collaboratively created \textit{compositions}, or pixel-art drawings, in which transitions occur when one composition rapidly replaces another. We develop a machine-learning-based early warning system that combines the predictive power of multiple system-specific time series via gradient-boosted decision trees with memory-retaining features. Our method significantly outperforms standard early warning indicators. Trained on the 2022 r/place data, our algorithm detects half of the transitions occurring within 20 minutes at a false positive rate of just 3.7\%. Its performance remains robust when tested on the 2023 r/place event, demonstrating generalizability across different contexts. 
Using SHapley Additive exPlanations (SHAP) for interpreting the predictions, we investigate the underlying drivers of warnings, which could be relevant to other complex systems, especially online social systems. We reveal an interplay of patterns preceding transitions, such as critical slowing down or speeding up, a lack of innovation or coordination, turbulent histories, and a lack of image complexity. These findings show the potential of machine learning indicators in socio-ecological systems for predicting regime shifts and understanding their dynamics.

\end{abstract}


\dates{This manuscript was compiled on \today}
\doi{\url{www.pnas.org/cgi/doi/10.1073/pnas.XXXXXXXXXX}}

\maketitle

\thispagestyle{firststyle}

\ifthenelse{\boolean{shortarticle}}{\ifthenelse{\boolean{singlecolumn}}{\abscontentformatted}{\abscontent}}{}

%Use \firstpage to indicate which paragraph and line will start the second page and subsequent formatting. In this example, there are a total of 11 paragraphs on the %first page, counting the first level heading as a paragraph. The value {12} represents the number of the paragraph starting the second page. If a paragraph runs over %onto the second page, include a bracket with the paragraph line number starting the second page, followed by the paragraph number in curly brackets, e.g. "\firstpage[4]%{11}".

% ###### Introduction ##########

% If your first paragraph (i.e. with the \dropcap) contains a list environment (quote, quotation, theorem, definition, enumerate, itemize...), the line after the list may have some extra indentation. If this is the case, add \parshape=0 to the end of the list environment.
%\dropcap{T}his PNAS journal template is provided to help you write your work in the correct journal format. Instructions for use are provided below.
%Note: please start your introduction without including the word ``Introduction'' as a section heading (except for math articles in the Physical %Sciences section); this heading is implied in the first paragraphs.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%% ARXIV CHANGE FIRSTPAGE COMMAND %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\firstpage[1]{0} % for ARXIV 
%\firstpage[10]{4} % for PNAS

\dropcap{A}brupt transitions from one state to another are modeled as critical transitions, bifurcations, tipping points, or regime shifts. In social and ecological systems, shifts such as fishery collapses~\cite{jacksonHistoricalOverfishingRecent2001, petrieStructureStabilityExploited2009}, disease outbreaks~\cite{lagorioQuarantinegeneratedPhaseTransition2011, orozco-fuentesEarlyWarningSignals2019}, stock market crashes~\cite{vandewalleCrashOctober19871998}, or the tipping of Earth subsystems~\cite{armstrongmckayExceeding15degCGlobal2022} directly impact people’s lives. Detecting early signs of critical transitions could enable the relevant actors to prepare for, mitigate, or even avoid such transitions. Yet, finding robust early warning signals is no small task. Empirical data on many transitions in a system is needed to validate models of transitions or learn the patterns preceding them. 

%GF: I propose a line cut here?
Online social systems can offer such detailed observations of many subsystems with intercomparable complex dynamics, and one platform particularly well-suited to studying critical transitions is Reddit's r/place~\cite{Place2024}. In this event, which was part game, part social experiment, millions of users created collaborative art by changing the colors of pixels on a 
shared canvas, inspiring a host of new research to understand the resulting collective behaviors~\cite{armstrongCoordinationPeerProduction2018, rappazLatentStructureCollaboration2018, vachherUnderstandingCommunityLevelConflicts2020, litherlandInstructionVsEmergence2021, israeliFlyingColorsPredicting2023,mullerCompressionCulturalEvolution2018, wuLargescaleCollectiveDynamics2024, botelhoArtExpandedField2024}. On the canvas, conflict broke out as users fought over the limited space,
making r/place analogous to a socio-ecological system. Groups created \textit{compositions}\footnote{In other works discussing r/place, compositions, pixels, and pixel changes are sometimes called artworks, tiles, and updates.}---images representing the interests of their community---sometimes by attacking other compositions to rapidly replace their pixels, which we regard as transitions. In this work, we build a warning system for transitions in the social world of r/place, providing a new framework for predicting transitions and understanding their dynamics in large-scale complex systems. 

Critical slowing down, the slowing return of the system’s state after perturbations, has been widely investigated as a broadly applicable early warning signal~\cite{wisselUniversalLawCharacteristic1984, vannesSlowRecoveryPerturbations2007, schefferEarlywarningSignalsCritical2009, boettigerEarlyWarningSignals2013, boettigerPatternsPredictions2013}. 
Critical slowing down was shown in ecological experiments more than a decade ago~\cite{carpenterEarlyWarningsRegime2011, daiGenericIndicatorsLoss2012, dakosMethodsDetectingEarly2012}, and 
in theory decades earlier~\cite{wisselUniversalLawCharacteristic1984}. However, its theoretical grounds require the state to closely follow an equilibrium that moves due to a slow parameter change, such as in bifurcations~\cite{schefferEarlywarningSignalsCritical2009}, spinodal instabilities~\cite{levinPhaseTransitionsTheory2023}, continuous or second-order
phase transitions, and other reversible, non-catastrophic transitions~\cite{kefiEarlyWarningSignals2013}. 
Critical slowing down may not apply to transitions triggered by a fast parameter change, large perturbations~\cite{boettigerNoEarlyWarning2013}, or rate-induced tipping~\cite{ritchieEarlywarningIndicatorsRateinduced2016}; the opposite signal, critical speeding up, even appears in some systems~\cite{titusCriticalSpeedingEarly2020, pomeauCriticalSpeedvsCritical2011, gietkaSqueezingCriticalSpeeding2022}. 
Although other indicators have been proposed (see recent review in Ref.~\citenum{georgeEarlyWarningSignals2023}), notably based on network~\cite{wunderlingHowMotifsCondition2020,suweisEarlyWarningSigns2014}, dynamical~\cite{xuNonequilibriumEarlywarningSignals2023}, and spatial ~\cite{chenEigenvaluesCovarianceMatrix2019} properties, different warnings have been shown to precede different types of transitions. For some transitions, however, there may be no warnings at all~\cite{boettigerEarlyWarningSignals2013,schefferAnticipatingCriticalTransitions2012}, including when long transient dynamics take place before the transition~\cite{hastingsTransientPhenomenaEcology2018}. In the absence of a data-validated model, an empirical system cannot be assumed to show any generic warning. Since building empirically sound models is challenging for many complex systems, model-free methods to find early warning indicators are greatly needed.

Early warning indicators leveraging machine learning methods~\cite{georgeEarlyWarningSignals2023, 
obrienEWSmethodsPackageForecast2023} are model-independent and have been shown to outperform generic indicators in some systems~\cite{choiEarlyWarningCritical2022}. Because real-world systems often lack the large amount of data needed for training, some researchers have trained on simulated data~\cite{qiUsingMachineLearning2020, brettDynamicalFootprintsEnable2020, grassiaMachineLearningDismantling2021, buryDeepLearningEarly2021, debMachineLearningMethods2022, dylewskyUniversalEarlyWarning2023,miryDeepLearningDisease2025}. 
However, algorithms using simulated data can only discover predictive features that are embedded in the chosen simulated models, which may not capture all the relevant warning properties of a real-world transition. 
Models trained on synthetic data and then fine-tuned to empirical data might identify more warning signals~\cite{liuEarlyPredictorOnset2024}, but could still overlook features absent in the simulations and too subtle in the sparse tuning data.
Another approach is to find systems that provide large amounts of observational data to train on, which has been successful in medicine~\cite{tapakComparativeEvaluationTime2019, gaoMachineLearningBased2020, hylandEarlyPredictionCirculatory2020, kobylarzribeiroMachineLearningEarly2020}, economics ~\cite{samitasMachineLearningEarly2020, barthelemyEarlyWarningSystem2024} and engineering~\cite{maDatadrivenPowerSystem2018, lassetterUsingCriticalSlowing2021}. 
Nevertheless, techniques that train on large real-world datasets have not yet been applied to predict transitions in socio-ecological systems. 
Moreover, a standard issue with machine learning predictions is that they rarely provide more understanding of the system to experts or decision makers~\cite{rudinStopExplainingBlack2019}. This ``black-box'' aspect is not addressed in most studies predicting transitions with machine learning, which focus on the performance of the predictions at the expense of insights into the determinants of the transition.

We use gradient-boosted decision trees to predict the time remaining until impending transitions in Reddit’s r/place, and we analyze the resulting warnings with SHapley Additive exPlanations (SHAP)~\cite{lundbergUnifiedApproachInterpreting2017} to understand the mechanisms that drive these transitions. Our warning system predicts transitions well, outperforming each of the generic signals we tested using thresholding and Kendall's $\tau$~\cite{chenPracticalGuideUsing2022}. Training on time series of system-specific variables with a 7-hour memory for thousands of compositions, we obtain predictive power up to a few hours before transition. Our predictions are still significant when training on the 2022 event and testing on the 2023 event, which demonstrates that the algorithm exploits genuine and generalizable properties. 
By examining how different input features contribute to the predictions, we highlight a complex mixture of dynamical properties of compositions near transition, including critical slowing down or speeding up, a lack of innovation or coordination, a turbulent past, and image simplicity. %GF: need to expand that into 2 sentences. One detailing what features are and how they affect predictions. The other detailing more the warning indicators
To our knowledge, this analysis provides the first machine learning predictions of critical transitions using detailed observational data in a large-scale complex social system. It reveals drivers of transitions and showcases a framework for building and understanding data-driven warning signals that could be deployed in other socio-ecological scenarios. 

\begin{figure*}[hbtp]
\centering
\includegraphics{figures/overview_rplace.png}
\caption{Description of the r/place game, its compositions, and the transitions they undergo. \textbf{(a)} The rules of the game for a given user. \textbf{(b)} Snapshots of the full 2022 canvas at multiple points in time; some parts of this canvas were available only later in the game. \textbf{(c)} Fraction of pixels differing from the reference image (\texttt{diff pixels reference}) for the ``Chessboard'' and ``Star Wars: Episode IV -- A New Hope'' compositions as they undergo transition. Insets show snapshots of the compositions at different points in time. Time is measured from the beginning of the event.}
\label{fig:rplace}
\end{figure*}

\matmethods{
%\section*{Data and methods overview}
\label{section:trans-and-vars}

\begin{figure}[htbp]
\centering
\includegraphics{figures/ews_variables.png}
\caption{\textbf{(a-s)} The time-dependent variables used in the training of the algorithm, for the  ``Chessboard'' composition. See text %\nameref{subsec:vars} 
for explanations of all variables.}
\label{fig:ews-vars}
\end{figure}

\subsection*{The r/place game-experiment}

To predict transitions, we choose r/place~\cite{Place2024} as our study system, as it provides data on complex interactions of millions of participants. Presented as a game without a specific goal, the r/place event allowed registered Reddit users to select any pixel on a canvas, choose a new color from a palette, and then wait for a 5-minute \textit{cooldown} before changing another pixel (see Fig.~\ref{fig:rplace}a). This game-experiment has been hosted by Reddit three times: in 2017, 2022, and 2023. 
The striking complexity of the resulting collective art is evident
in the snapshots of the full 2022 canvas shown in Fig.~\ref{fig:rplace}b. Various aspects of the 2017 experiment have been studied~\cite{armstrongCoordinationPeerProduction2018, mullerCompressionCulturalEvolution2018, rappazLatentStructureCollaboration2018, vachherUnderstandingCommunityLevelConflicts2020, litherlandInstructionVsEmergence2021, israeliFlyingColorsPredicting2023, wuLargescaleCollectiveDynamics2024, botelhoArtExpandedField2024}, while the 2022 and 2023 events have been discussed only once~\cite{wuLargescaleCollectiveDynamics2024}. 

We use the full data of pixel changes publicly released by Reddit, which includes anonymized user identifiers for each pixel change, for the 2022 and 2023 events. The 2022 event welcomed 10.4 million participants who changed pixel colors 160 million times over 3.5 days, while the 2023 event saw 8.6 million participants making 134 million changes over 5.4 days. We use the 2022 event as our primary system because it was the most popular, with ten times more participants than in 2017, and we use the 2023 event to test the generality of our predictions. The canvas started with 1 million pixels and 16 color choices (8 in 2023) and was later expanded in discrete steps to 4 million pixels (6 million in 2023) with 32 color choices. Detailed rules, statistics, and data provenance on the r/place events are given in section~\ref{secSI:rplacedata} of the Supporting Information (SI), along with global canvas distributions in Fig.~\ref{figSI:rplace}.

In 2022, users organized to create about 10,900 compositions on the canvas, compared to 6,700 in 2023. These culturally meaningful drawings were often made by communities that previously existed on Reddit or other social media; some also spontaneously formed for the occasion.
We identify these compositions using the Atlas dataset~\cite{haagmansPlaceAtlasInitiative2024}. This crowdsourced map of the canvas specifies, for each composition, the borders of the image, the birth and death times, the communities involved, and descriptions of the depicted content. We minimally clean the Atlas and separate some compositions so that each is continuous in time and in canvas space (see SI section~\ref{secSI:compodata}).

\subsection*{State variable and reference image}
We define transitions in compositions using thresholds on a state variable, which must be carefully chosen. To this end, we first define concepts used throughout this text. The \textit{sliding window} is the 3-hour window preceding a certain time point. The \textit{mode color} is the color that held the longest over a time period, either a time step or the sliding window. At any given time, the \textit{reference image} contains, for each pixel within the composition borders, the \textit{reference color}, which is the mode color over the sliding window. 
The state variable is then the \textit{fraction of pixels differing from the reference image}; it indicates recent changes, or \textit{attacks}, to the ``usual'' image at any time point. \textit{Defense} changes restore attacked pixels to the reference color.

\subsection*{Definition of transitions} 
Our definition of a transition in a composition should represent what a user perceives as a sudden change in its image, which translates into a high fraction of differing pixels.  
Therefore, we define the transition time \ttrans as the moment this state variable both exceeds 0.35 and is 6 times higher than its average value over the sliding window. Changing these parameters does not significantly affect our predictions, which we show in a sensitivity analysis (SI section~\ref{secSI:sensitivity} and Fig.~\ref{figSI:sensitivity}). These thresholds ensure that a large portion of the image changes, and that this portion is much larger than usual. We also reject transitions that start from a patchwork of compositions (see examples in Fig.~\ref{figSI:notrans}). Because these transitions do not start from a single, coherent composition, this region of the canvas would not be monitored and defended before the new composition exists. Valid transitions include those where the composition returns to its pre-transition state as well as those where a new image takes over (see Fig.~\ref{fig:rplace}c for examples of each). More context and justification for how we define transitions is given in SI section~\ref{secSI:transitions}. Examples of compositions whose evolving images may resemble transitions but do not pass our criteria are shown in Fig.~\ref{figSI:notrans}.

\subsection*{Time series for each composition} 
\phantomsection 
\label{subsec:vars}
To construct the training data for our algorithm to predict transitions, we first calculate variables that reveal how compositions evolve. Each variable's time series captures different properties of the composition that we expect to have predictive power, including the dynamics of the image, pixel changes, and user activity. 
We compute each variable for each composition in 5-minute increments---a natural time scale considering the game's 5-minute cooldown rule---resulting in about 1000 time steps in 2022, and 1500 in 2023. Most variables are averaged over the time-step duration. The variables related to a per-pixel quantity are averaged over all active pixels, apart from those which we average over the decile of pixels with the highest values. We denote $t$ and $t-1$ as the current and previous time steps. The variables, plotted for an example transition in Fig.~\ref{fig:ews-vars}, are:

\setlist[description]{font=\normalfont\ttfamily}
\begin{description}[noitemsep]
    \item[diff pixels reference] (Fig.~\ref{fig:ews-vars}a). Fraction of pixels differing between the instantaneous image at $t$ and the reference image, as described above.
    \item[diff pixels instant] (Fig.~\ref{fig:ews-vars}b). Fraction of pixels differing between the instantaneous image at $t$ and the image composed of the mode colors in step $t-1$.
    \item[attack fraction] (Fig.~\ref{fig:ews-vars}c). Fraction of  pixel changes to a color different from the reference. 
    \item[n changes] (Fig.~\ref{fig:ews-vars}d). Number of pixel changes.
    \item[instability top] (Fig.~\ref{fig:ews-vars}e). Fraction of this time step spent in a non-mode color, averaged over the top decile of pixels.
    \item[variance] (Fig.~\ref{fig:ews-vars}f). $\frac{1}{2(n-1)}\sum_{i=0}^{n-1} D(t-i,\,\, t-i-1)^2$ where $n=10$ 
    time steps 
    and $D(t_1,t_2)$ is the fraction of pixels differing between the instantaneous images at times $t_1$ and $t_2$. This equals the standard variance
    in the gaussian and large-statistics limit. 
    \item[n colors] and \texttt{n colors top} (Fig.~\ref{fig:ews-vars}g,h). Number of colors used in a pixel during this time step, averaged over all pixels or over the top decile.
    \item[autocorr by case] (Fig.~\ref{fig:ews-vars}i). The relative change in the autocorrelation between $t$ and $t-1$, defined case-by-case with positive
    values when pixels change from the reference to the same color, and negative values when pixels change to different colors. 
    \item[autocorr non-mode] (Fig.~\ref{fig:ews-vars}j). The autocorrelation $\sum_{\textrm{colors}} c_t \, c_{t-1}$ where $c_{t}$ is the time spent in color $c$ in step $t$, except we set $c_{t}=0$ for the mode color of step $t$.
    \item[attack duration] and \texttt{attack duration top} (Fig.~\ref{fig:ews-vars}k,l). Time since the attack of a pixel currently in a non-reference color or duration of the most recent attack of a pixel, averaged over pixels attacked within the sliding window and over the top decile.
    \item[return rate] (Fig.~\ref{fig:ews-vars}m). Fraction of pixels attacked at $t-1$ that returned to the reference at $t$.
    \item[n users sw] (Fig.~\ref{fig:ews-vars}n). Number of users who made changes in the sliding window. 
    \item[changes/user sw] (Fig.~\ref{fig:ews-vars}o). Number of changes per user in the sliding window.
    \item[new users] (Fig.~\ref{fig:ews-vars}p). Fraction of users in step $t$ that were not active in the preceding sliding window.
    \item[redundant changes] (Fig.~\ref{fig:ews-vars}q). Fraction of pixel changes to the color that the pixel was already in. Users likely performed these changes to have their username attached to this pixel.
    \item[entropy change] (Fig.~\ref{fig:ews-vars}r). Change relative to the sliding window of an entropy proxy, the ratio of the compressed file size of the image to the image area, as introduced in Ref.~\citenum{martinianiQuantifyingHiddenOrder2019}. 
    \item[fractal dim change] (Fig.~\ref{fig:ews-vars}s). Change relative to the sliding window of the fractal dimension, calculated using the reticular box counting method separated by color as described in Ref.~\citenum{bisoiCalculationFractalDimension2001}.
\end{description}

We also define five variables that are trivially time-dependent for a given composition:

\begin{description}[noitemsep]
    \item[area.] The logarithm of the number of active pixels.
    \item[age.] The time from the birth of the composition in the Atlas to $t$.
    \item[canvas quadrant.] Which of the 3 (7 in 2023) canvas extensions the composition is placed in.
    \item[entropy.] The entropy averaged over the sliding window.
    \item[border corner center.] Desirability of locations on the canvas: $1$ for a composition close to a border or a center of the available canvas, $2$ for one close to a corner, $0$ otherwise.
\end{description}

Details, justifications and normalizations for the above variables, as well as additional variables that were implemented but not kept in the training dataset, are discussed in SI section~\ref{secSI:variables}. Large correlations might make some variables redundant in the training, which is a criterion to discard a number of variables (see SI section~\ref{secSI:featureselec}). The correlation matrix of all the variables used in the training is shown in Fig.~\ref{figSI:correlations}. Note that some variables explicitly relate to critical slowing down, such as the variance, autocorrelation, return rate, and duration of last attack; they are used to assess the presence of this generic signal. 

\subsection*{Machine learning warning system}

\begin{figure*}[htbp]
\vspace*{-3mm} % GF: hack because otherwise the figure+caption is too large and requires a whole page
\centering
\includegraphics{figures/ml_algorithm.png}
\caption{Workflow of our machine learning warning system. \textbf{(a)} Transitions at time $t^*$ and the associated target variable time-to-transition (\ttt) are identified based on changes in \texttt{diff pixels reference}. \textbf{(b)} The features for each time instance consist of each of 19 input variables recorded over 9-12 time ranges of a \SI{7}{\hour} memory, as well as 5 variables without memory. \textbf{(c)} Gradient-boosted decision trees are trained to predict the time-to-transition. \textbf{(d)} Predicted and true values of the time-to-transition are compared in the test sample. \textbf{(e)} The drivers of predictions are analyzed based on SHAP values at a given feature value.
}
\label{fig:ml-algo}
\end{figure*}

We build our warning system by training gradient-boosted decision trees with XGBoost~\cite{chenXGBoostScalableTree2016} to  predict the time-to-transition, $\ttt = t^* - t$. Our training data consists of 1.53 million  \textit{time instances}, each containing \textit{feature} values that provide predictive information for a given time step and composition. These features consist of the variables listed in the previous section, computed at an instance's time step or averaged over preceding time periods to emulate a 7-hour memory. 

\paragraph{Selection of time instances.} 

We select time instances to avoid spurious signals. In early versions of this work, we discovered that the transition requirement of a relative threshold on \texttt{diff pixels reference} caused the algorithm to 
exploit stable pre-transition periods for prediction, rather than using genuine warning signals.
Transitions can only be defined on a system in a stable or quasi-stable state, meaning this relative threshold is necessary. 
To prevent the optimization for stable periods, we require the past sliding-window average of \texttt{diff pixels reference} to be less than $0.35/6$ for all time instances. This reduces the size of our input dataset by 25\%. Other requirements on time instances are explained in SI section~\ref{secSI:filter}. Of the 14,160 compositions in 2022, only 6,291 have at least one time instance meeting our requirements, compared to 3,546 compositions out of 6,930 in 2023.

\paragraph{Target value: time-to-transition.}

The time-to-transition, or \ttt, which we aim to predict, is the time remaining until a transition, and is recorded for each instance (Fig.~\ref{fig:ml-algo}a). Accurate predictions are not expected beyond a few hours before transition; we therefore modify the time-to-transition to favor times close to transition. Specifically, we: (a) set $\ttt=$~\SI{12}{\hour} for all instances with $\ttt>$~\SI{12}{\hour} or in compositions with no transition; (b) assign progressively lower weights when $\ttt>$~\SI{3}{\hour}; (c) apply a logarithmic transform to \ttt (see SI section~\ref{secSI:target} on these three items); (d) use a training loss term in the objective function based on the \textit{relative} rather than the \textit{absolute} deviation between the predicted and true targets (see SI section~\ref{secSI:algo}). 

\paragraph{Feature building.}

To account for past dynamics, each of 19 time series is recorded with a 7-hour memory for each time instance. This memory consists of 9 or 12 features containing the variable averaged over adjacent time ranges preceding a time instance (see Fig.~\ref{fig:ml-algo}b and SI section~\ref{secSI:memory}). The five trivially time-dependent variables are recorded as features without memory. Variables used for training are summarized in Table~\ref{tabSI:variables}, and the 
exact time ranges of the memory are listed in Table~\ref{tabSI:timeranges}. 


\paragraph{Training the model.}

The resulting input data contains 172 features and one target value for 1.53 million time instances in 2022 and 1.34 million in 2023. When using 2022 data only, we attribute 80\% of the compositions, with all their instances, to the training dataset and the rest to the test dataset. We also separately train on the full 2022 data to test on the 2023 data. The algorithm outputs a predicted time-to-transition, $\tttpr$, for each instance of each test composition (Fig.~\ref{fig:ml-algo}d). The $\tttpr$ is then calibrated through a monotonic transformation, so that its average is closer to the true time-to-transition, $\ttttr$ (see SI section~\ref{secSI:calib}). Details on the model hyperparameters are given in SI section~\ref{secSI:algo}. 

\subsection*{Testing predictions in binary warning systems}

To compare our warning system to standard warning signals, we convert our predicted time-to-transition into a binary indicator of warning or no warning. A warning is issued if $\tttpr$ is within a set \textit{warning range} of, for example, $0$ to \SI{20}{\minute}. This warning is a true positive if \ttttr is below a certain threshold. We sweep over this threshold to create the receiver operator characteristic (ROC) and precision-recall (PR) curves, as explained in SI section~\ref{secSI:ROCPR}. We calculate ROC and PR curves for four warning ranges: \SI{20}{\minute}, \SI{1}{\hour}, \SI{3}{\hour} and \SI{6}{\hour} (see Figs.~\ref{figSI:ROC}a and~\ref{figSI:PR}a). We also compute binary warning signals for individual transitions (see SI section~\ref{secSI:testing} and Fig.~\ref{figSI:ROC}b).

We next build binary warnings based on the standard indicators of autocorrelation, return rate, and variance, using two methods. In the first, we use the Kendall's $\tau$~\cite{chenPracticalGuideUsing2022}, characterizing the increasing or decreasing trend of a time series in a $50$-minute ($10$ time step) time window. A warning is issued when $\tau$ reaches a threshold, which we sweep over to calculate the ROC and PR curves. In the second method, warnings are issued when the variable itself reaches the threshold. 

\subsection*{SHAP values to understand algorithm predictions}

SHAP values measure, for each instance, the contribution of a certain feature to the target value predicted by the algorithm~\cite{lundbergUnifiedApproachInterpreting2017}. The distributions of SHAP values over instances for each variable are shown in Fig.~\ref{figSI:shapdistr}. When averaged over instances, SHAP absolute values measure feature importance, which we use along with correlations between variables to prune variables and features (SI Section~\ref{secSI:featureselec}).

More importantly, SHAP values describe how the algorithm relates a given instance and its feature values to the proximity of transition. Therefore, they can point to characteristics of data that the algorithm associates with incoming transitions. We examine average SHAP values as a function of feature values; these curves for all 172 features are shown in Fig.~\ref{figSI:SHAPall} and ~\ref{figSI:SHAPnotime}. Because some feature distributions are fat-tailed, we use the percentiles of feature values among instances. 
We interpret the trends of these curves as various warning indicators identified by the algorithm. To ensure that these trends genuinely relate to transition-like dynamics, we only report the trends that are robust against changes in the pre-transition stable period requirement (see SI section~\ref{secSI:shap}). 

\begin{figure*}[h!]
\centering
\includegraphics{figures/results_eval.png}
\caption{Time-to-transition predictions. \textbf{(a)} Predicted time-to-transition \tttpr versus the true values \ttttr. The color shows the probability at a given \ttttr to predict a certain \tttpr value. To accommodate display on the log axis, \SI{100}{s} is added to all time-to-transition values. Perfect predictions would align with the grey line. 
\textbf{(b)} Probability distribution functions, constructed by kernel density estimation, of \tttpr at four different $\ttttr\pm $ \SI{5}{\minute} values. The darkest curve includes all instances for which there is no incoming transition. \textbf{(c)} ROC area under the curve (AUC) as a function of the warning range for the machine learning warning signal (dark blue), a single-variable standard warning signal using \texttt{variance} (light blue), and the machine learning warning signal tested on 2023 r/place data (red). The inset shows, as an example, the ROC curve used to compute the ROC AUC for the \SI{20}{\minute} warning range.}
\label{fig:true-v-pred}
\end{figure*}

} % for end of matmethods
\showmatmethods{}

\section*{Results}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%% Verified to this point in table reading %%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection*{Predicted time-to-transition} 

Our trained XGBoost model shows predictive power for the time-to-transition \ttt up to hours ahead of the transition. For lower \ttttr values, predictions are closer to the perfect-prediction line (Fig.~\ref{fig:true-v-pred}a): at $\ttttr=\SI{20}{\minute}$, the mode prediction is \SI{54}{\minute}; at $\ttttr=\SI{3}{\hour}$, the mode is \SI{2}{\hour} \SI{53}{\minute}, and at $\ttttr=\SI{6}{\hour}$, it is \SI{3}{\hour} \SI{25}{\minute}. As \ttttr grows, a peak in the distribution of \tttpr emerges around \SIrange{3}{4}{\hour}, corresponding to a bulk of instances the algorithm cannot classify (Fig.~\ref{fig:true-v-pred}b). While perfect predictions would sharply peak at \SI{12}{\hour} for the ``no transition'' curve, the mode prediction is actually \SI{3}{\hour} \SI{42}{\minute}. Nonetheless, performance is determined by the ordering and separation of the predicted values, as predictions are scaled by calibration. The monotonic increase of prediction modes with increasing \ttttr up to the maximum value is remarkable, as it shows that the algorithm succeeds in discriminating times \SI{3}{\hour} from transition from times \SI{6}{\hour} away. 

\subsection*{Performance against standard warning signals} 

Our machine learning warning system trained on many variables far outperforms single-variable, standard warning indicators, as shown by the higher area under the curve (AUC) for the ROC and PR curves (see Figs.~\ref{fig:true-v-pred}c,~\ref{figSI:ROC}a, and~\ref{figSI:PR}). Compared to the Kendall's $\tau$ warning calculated using our \texttt{variance} variable, which was the best-performing of the standard warning variables we computed, our algorithm has drastically more predictive power for all warning ranges.

\subsection*{Testing on data from the following year}

To further evaluate the performance of our early warning system, we trained on the entire 2022 r/place dataset and tested on the 2023 one. The 2023 predictions still hold significant predictive power, decreasing only slightly in performance compared to the 2022 predictions, as shown in the AUC values of the ROC and PR curves (Figs.~\ref{fig:true-v-pred}c and~\ref{figSI:PR}b). 

\subsection*{Evaluation by composition and transition}
\begin{figure}[tbh]
\centering
\includegraphics{figures/trajectories.png}
\caption{Trajectories of predicted versus true time-to-transition for three compositions. The red line indicates a perfect prediction. The insets show the composition at different points in time. \textbf{(a)} The ``Auburn University'' composition gives high-accuracy predictions. \textbf{(b)} ``1886'' gives low-accuracy predictions with oscillations. \textbf{(c)} ``Three Cheers For Sweet Revenge'' gives low-accuracy predictions with relatively constant values.}
\label{fig:traj}
\end{figure}

The above evaluation results are computed over all time instances of all compositions. However, we expect our algorithm to perform better for some transitions than others. We examine the per-composition predictions by calculating a ROC AUC for each transition in the 2022 test set, as discussed in SI section~\ref{secSI:percompo}. For a warning range of \SI{20}{\minute}, $41\%$ of the transitions have a ROC AUC greater than 0.8, compared to  $27\%$  at a range of \SI{1}{\hour} (Fig.~\ref{figSI:ROC}b). At the 20-minute range, $27$\% perform at or worse than random, compared to $38$\%  at a range of \SI{1}{\hour}. While our algorithm performs well on a significant portion of transitions, it is unable to predict some of them. 

For some compositions, our predictions are close to the perfect-prediction line as a composition approaches transition (Fig.~\ref{fig:traj}a). For compositions where the algorithm performs poorly and \tttpr oscillates in time (Fig.~\ref{fig:traj}b), there may be continually high activity. When there are no detectable warning signals, \tttpr should remain relatively constant (Fig.~\ref{fig:traj}c).  

To avoid many subsequent warning alarms, which could be inconvenient for a real-world transition, we implement a system with a \textit{warning cooldown} (see SI section~\ref{secSI:cooldownWarn}). Here, the system must ``cool down'' before issuing another warning, as in Ref.~\citenum{hylandEarlyPredictionCirculatory2020}. Requirements for such warnings are stricter, which inevitably leads to a lower performance for our cooldown warning system (see the ROC curve in Fig.~\ref{figSI:continuous-warn}).  

\subsection*{Interpretations of the warning system}

\begin{figure*}[tbh]
\centering
\includegraphics{figures/shap_values.png}
\caption{Interpretation of model predictions with SHAP values. \textbf{(a-f)} Feature percentiles versus mean SHAP values, classified based on curve trends into six pre-transition behaviors, which are described in the panel titles. Top titles describe the signal of a coming transition, and italicized subtitles provide an interpretation of the associated dynamics of the users and of the image of the composition. Grey arrows indicate the qualitative trend of the curves of a panel. Each legend label describes the curve of the same color as the label's text. Curves are drawn thinner when they show a trend that is not the focus of their respective panel.
}
\label{fig:shap}
\end{figure*}

We analyze the algorithm predictions to uncover mechanisms driving transitions in r/place, which may be transferrable to other complex systems. This approach helps mitigate the often overlooked ``black-box'' nature of machine learning predictions. 

Uncovering mechanisms starts with examining the 172 SHAP trends as a function of feature value (see Figs.~\ref{figSI:SHAPall} and~\ref{figSI:SHAPnotime}). Our SHAP plots represent time progressing toward the right, so that the right side of the plot (low SHAP) corresponds to feature behaviors that are typical close to transitions. A \textit{low} SHAP therefore designates instances and features values that the algorithm associates with \textit{closeness} to transition; a \textit{high} SHAP (left side of the plot) shifts predictions \textit{away} from transition. By grouping features that describe the same  trend and aspect of dynamics, we build evidence for distinct behaviors which can be considered potential warning signals. To find these behaviors, we first classify the variables for their role in the composition dynamics: strength of the attack or defense changes, image activity, user activity and engagement, image complexity, innovation, and coordination versus noise (see SI section~\ref{secSI:shap} for details on the classification). We uncover a set of 12 behaviors of compositions close to transition, shown in Figs.~\ref{fig:shap} and~\ref{figSI:SHAPinterp}. 

These behaviors span different aspects of activity and image dynamics and relate to recent or past features. First, a strong critical slowing down shows as a very high image activity (Fig.~\ref{fig:shap}a), as well as a dominating attack force against the defending community (Fig.~\ref{fig:shap}b) and a high user recruitment (Fig.~\ref{figSI:SHAPinterp}a). However, this slowing down coexists with a mild critical speeding up, reflected by high defense in the recent past (Fig.~\ref{fig:shap}c). 

Trends for past time features provide additional signals. A high past image activity suggests a large presence of past attacks (Fig.~\ref{figSI:SHAPinterp}b), which we refer to as a turbulent past. Past high user engagement (Fig.~\ref{figSI:SHAPinterp}c) could also indicate substantial past attacks that the defense reacted against. Though a turbulent or highly engaged past signals an approaching transition, low past activity can indicate a neglected composition, which could attract opportunistic attacks (Fig.~\ref{figSI:SHAPinterp}d). On the contrary, a very low past image activity may indicate a general lack of interest (Fig.~\ref{figSI:SHAPinterp}e), which makes the composition safer.

Attacked pixels left in their new color can indicate evolution of the image supported by the community, which we refer to as innovation. A lack of innovation is indicative of transitions (Fig.~\ref{fig:shap}d), which may suggest that a more innovative community is safer from transition. Coordinated activity rather than noisy activity, whether from the defending community or not, also indicates stronger compositions (Fig.~\ref{fig:shap}e). Unsurprisingly, low defense activity in the past is
typical close to transition (Fig.~\ref{figSI:SHAPinterp}f), which could mean that the defending community is unable or unmotivated to mobilize. Finally, images of higher complexity are also typically safer (Fig.~\ref{fig:shap}f).  

\section*{Discussion}
This work is, to our knowledge, the first machine-learning-based early warning indicator for transitions in a large-scale human social system. Some machine learning prediction systems using large empirical datasets have outperformed ours in fields such as medicine~\cite{gaoMachineLearningBased2020, hylandEarlyPredictionCirculatory2020}. However, social systems present unique challenges due to the high dimensionality of human behavior and the lack of comprehensive datasets. Decision trees using the r/place dataset tackle both these challenges while providing data-driven insights on the complexity of social dynamics that analytical models cannot offer.

We extract human-readable warning signals from the SHAP analysis of predictions. Many dynamical behaviors, rather than single, generic early warning signals, are found to indicate incoming transitions. These behaviors might apply to transitions in other socio-ecological systems and inform their managers. Some of our findings confirm intuitions from other approaches; for example, innovation has been discussed as contributing to adaptation and sustainability transitions~\cite{makitieDigitalInnovationsContribution2023}, but also as being insufficient preceding the collapse of ancient societies~\cite{tainterCollapseComplexSocieties1988, mascarenoCriticalTransitionsEcosystems2022}. Closer to the theoretical origins of critical slowing down~\cite{levinPhaseTransitionsTheory2023, wisselUniversalLawCharacteristic1984}, the higher risk of transition for simpler images also evokes the reduction of dimensionality due to power law dynamics close to second-order critical transitions. 

These insights capture the diversity of warning signs in a real-world system because we use a large and high-resolution empirical dataset. Forecasting abilities using deep learning have been shown in some ecology~\cite{debMachineLearningMethods2022, buryDeepLearningEarly2021} and epidemiology~\cite{miryDeepLearningDisease2025} studies with training data simulated from simple models inspired by disciplinary tradition. Unlike our algorithm using system-specific time series with features encoding their memory, these methods cannot reveal pre-transition phenomena that are not present in the simulated models. 
Using empirical data also improves the applicability to related systems, which is illustrated by the striking validity of our 2022 warning system when applied in 2023. Though the r/place experiments of 2022 and 2023 had similar rules, contextual differences altered the 2023 dynamics: for example, differences in expansions of the canvas size and available colors, total duration, cooldown times, moderator and bot activity, level of preparedness of communities, player motivations, and popularity of the game. 

While different compositions may show varied warning behaviors, some compositions may show no warnings at all. This cross-subsystem variation is illustrated by the diverse pre-transition behaviors of Figs.~\ref{fig:shap} and~\ref{figSI:SHAPinterp}. It is also supported by recent literature~\cite{boettigerEarlyWarningSignals2013}, which has proposed a number of indicators of varying generalizability~\cite{georgeEarlyWarningSignals2023}. A key advantage of a machine learning warning system is its potential to uncover any warning signals present in real-world data, even when they were not hypothesized in \textit{a priori} models. Some signals may seem contradictory when seen in the same or similar subsystems, as in the co-occurrence of large critical slowing down and mild critical speeding up in our results. Slowing down typically occurs very close to transition, while speeding up is an earlier, subtle signal, and compositions could show none, one, or both. While slowing down is well-established, speeding up is less conventional but has been discussed~\cite{titusCriticalSpeedingEarly2020, pomeauCriticalSpeedvsCritical2011, gietkaSqueezingCriticalSpeeding2022}. Interestingly, a simple logistic growth model~\cite{maySimpleMathematicalModels1976} displays a direct link between the increase of the reaction rate and the departure from a stable equilibrium. However, these and other analytic indicators all rely on separate, often incompatible models. 

The lack of a common framework to describe early warning indicators complicates comparisons between our r/place results and simple indicators from the literature. Different indicators apply to different types of transitions, and identifying the types is not trivial. For example, critical slowing down assumes small perturbations around an equilibrium that slowly moves towards a bifurcation (sometimes called \textit{B-tipping}), while some transitions are instead triggered by large perturbations that push the state outside the basin of attraction of the initial equilibrium (\textit{S-} for \textit{state-tipping})~\cite{boettigerBifurcationStateTipping2020}. For sufficiently large and fast perturbations, warning signals may~\cite{drakeEarlyWarningSignals2013} or may not~\cite{boettigerEarlyWarningSignals2012, boettigerNoEarlyWarning2013} be present. 
Interestingly, the theory of critical slowing down applies only to second-order, continuous phase transitions 
and to spinodal instabilities~\cite{levinPhaseTransitionsTheory2023}, but is not expected in abrupt, first-order transitions that are usually more alarming in real-world systems. Depending on how the transition is modeled, tipping can also be conceived as occurring when the state fails to track a fast-changing equilibrium (\textit{rate-induced}, or \textit{R-tipping})~\cite{ashwinTippingPointsOpen2012}; critical slowing down might exist but be delayed in these cases~\cite{ritchieEarlywarningIndicatorsRateinduced2016}. 
In addition, high-dimensional systems like ours may be more prone to transients, meaning long quasi-stable periods that eventually transition, potentially with no warning signals~\cite{hastingsTransientPhenomenaEcology2018}.
The transitions in our compositions might be of any type, or even mixed types; for example, coordinated attacks can be seen as a sudden perturbation (S-tipping) or as a fast change of an attack parameter (R-tipping). Our machine learning system does not rely on explicit modeling and can therefore account for this variety of transition dynamics.

As a consequence, a warning signal in our system might not fit into the framework of standard warning signals. This issue materializes as challenges and ambiguities in defining a state variable and its equilibrium. Transitioning systems in ecology, medicine, or physics are usually described by a variable summarizing their state. However, our subsystems are images; the information in all their pixels is hardly reducible to a scalar state variable. Critical slowing down relies on trends in scalar variables, such as variance, autocorrelation, or return rate. In r/place compositions, these quantities could be defined in many valid ways (see SI Section~\ref{secSI:variables} for an exhaustive list of variables we computed). As an example, we computed variance variables that fall into three categories: deviations from the long-term reference image (like our \texttt{diff pixels reference}), instantaneous changes in the image (like our \texttt{diff pixels instant}), or the variance of instantaneous deviations from a fast-adapting equilibrium (like our \texttt{variance}, a proxy of the variance of \texttt{diff pixels instant}). A covariance matrix describing the colors of all pixels would be the closest to a true variance but would be too high-dimensional to compute, interpret, and compare to the literature. As another example, attributing a sign to autocorrelation is difficult because color differences from the reference image lack a direction, as colors are unordered. 

More generally, we navigate multiple issues that do not have clear solutions. The first challenge is identifying the equilibrium from which the system departs, including the timescale over which the equilibrium should be evaluated, or even knowing whether an equilibrium exists\footnote{When compositions are out of equilibrium, the reference image is only an average of out-of-equilibrium states.}. Second, noise, which consists of small perturbations around equilibrium, is difficult to distinguish from coordinated attacks, which actively shift the equilibrium. While our results might in principle depend on these choices, the multiple options we compute often result in highly correlated variables, showing that these options reflect similar dynamics. 

To shed light on the impact of model design on observed warnings, and to illustrate the coexistence of slowing down and speeding up in a system, we design a toy model describing hypothetical dynamics in r/place compositions, presented in SI section~\ref{secSI:toymodel}. To extract meaningful conclusions about pre-transition dynamics, we must carefully determine the state variable, the type of transition, and the size of perturbations. In our model, the state variable is the deviation from the defended image (similar to our \texttt{diff pixels reference}), and the order parameters are the attack rate\footnote{The attacks could also be seen as perturbations external to the model, and not as a parameter.} and defense strength. We incorporate both an increase of defense user recruitment at medium-high deviations from the reference image---representing the mobilization of defense when the attack is not too abrupt---and a desertion of defense at very high deviations. Two types of transitions emerge: a B-tipping transition when decreasing the defense strength, and a second, R-tipping transition when increasing the attack rate. To probe pre-transition dynamics, we apply a small perturbation to the equilibrium, which has a non-zero value of the image deviations. When approaching the bifurcation-like transition, we observe a decrease of return rate, or slowing down; we instead see an increase, or speeding up, preceding the rate-induced transition. These observations show that seemingly contradictory warning signals, associated with different types of transitions, can exist within a single system. 

Approaching the rate-induced transition, the trend of the variance depends on what \textit{pseudo-mean} the deviations are computed from, as the mean and equilibrium are ill-defined in our r/place images. The toy model exemplifies repercussions of applying definitions from transition models to variables in a high-dimensional system. The pseudo-mean can be taken as the equilibrium that the state fails to track; but in r/place compositions, this theoretical equilibrium is unknown. Alternatively, the variance can be computed using a short-timescale sample mean---which is only approximate in our compositions, but we use it as the main \texttt{variance} variable. Lastly, the pseudo-mean of the fraction of differing pixels can simply be zero, which corresponds to using the reference image of our compositions. These three variance definitions can lead to different interpretations in the toy model, which underscores the consequences of model design. 

Though the r/place data offers unprecedented insights into large-scale human behavior, there are certain limitations. First, we rely on the user-annotated Atlas~\cite{haagmansPlaceAtlasInitiative2024} to classify the pixel change data into compositions. Omissions or inaccuracies from contributors can impact the image borders of compositions, as well as their birth and death times. We rectify some of these mistakes with minimal corrections to composition borders (see SI section~\ref{secSI:compodata}); these corrections only impact a small fraction of pixels and do not significantly modify the time series. The collective work of the Atlas contains crucial cultural information that automatic methods such as clustering~\cite{wuLargescaleCollectiveDynamics2024} or edge detection~\cite{cannyComputationalApproachEdge1986} cannot compensate for. Another issue is pixel changes that violated the 5-minute cooldown time. Moderators were not subject to the cooldown rule, and some users had multiple accounts or programmed bots to change pixels automatically (see SI section~\ref{secSI:rplacedata}). These pixel changes are hard to eliminate systematically. However, they contribute to the canvas dynamics observed by users and are therefore part of the experiment; they also constitute less than 1\% of changes in 2022. 

Learning from empirical data also requires caution in the study design; our algorithm would achieve better predictions if we ignored the practicalities of applying a warning system in a real-world scenario. The algorithm can optimize for artifacts that would not be present in a dataset collected live, rather than for genuine features of pre-transition periods. To approximate a live warning system, we: use only information preceding a time instance; use only instances preceded by a stable period; separate whole compositions between train and test samples; and reject compositions that are not yet monitored (see methods section and SI sections~\ref{secSI:transitions} and~\ref{secSI:filter}). We invite researchers in this field to be wary of showing high-performance predictions at the expense of real-world applicability.

Lastly, sorting through the large amount of information encoded in the SHAP curves of Fig.~\ref{figSI:SHAPall} is challenging, and our interpretations involve a degree of conjecture. We group the SHAP trends into distinct readable signals using our understanding of the r/place social system, but applying such interpretations to other systems would require comparable domain expertise. Moreover, SHAP values comes with inherent drawbacks, as their computation assumes feature independence and can be affected by overfitting (see SI section~\ref{secSI:shap}). Despite these difficulties, SHAP remains one of the few tools available for interpreting machine learning models and reveals insights into our system and possibly related ones.

Future work could test these insights in other socio-ecological systems where communities emerge and compete to achieve their goals. In addition, our predictive and interpretable approach is applicable not only to community-driven online platforms, but also to other systems that provide large and dense datasets. Another direction is to train a deep learning algorithm on individual pixel features rather than pixel-averaged features. This approach would bypass the difficulty of defining variables analogous to those in the early warning signals literature and may perform better, though these predictions would be significantly more difficult to interpret. By refining our warning systems and broadening their applicability, our interdisciplinary community can improve detection and understanding of transitions in complex systems. 

\section*{Conclusion}
We both predict transitions using a machine-learning-based warning system and translate its predictions into meaningful warning behaviors. Leveraging the large empirical dataset of r/place and emulating real-world constraints, we build a warning system suitable for practical monitoring, with a method transferrable to systems that provide similar data. Furthermore, the human-readable interpretations provide insights into pre-transition dynamics in an online social system. This is the first time that interpretable warnings have been developed with machine learning in an empirical system driven by human behavior. 

Unlike other warning systems, ours predicts a time-to-transition. This allows us to determine not just whether a transition is coming, but also when, which is key to an efficient response to a warning. We predict half of the incoming transitions within 20 minutes with only $3.7\%$ false positives and a ROC AUC of $0.833$. We also show predictive power up to 6 hours before the transition with a ROC AUC of $0.694$. Our algorithm far outperforms standard early warning signals. It also performs well when trained on 2022 data and tested on the 2023 experiment even though conditions in the two years differed, which demonstrates the generalizability of our results. 

We then interpret the algorithm's predictions using SHAP values to find human-readable warning signals. Our analysis reveals 12 behaviors that precede transitions. These include turbulent past image activity, simpler images, and lack of innovation or coordination. Strong defense reactions against a ramping-up attack force can also lead to both critical slowing down and critical speeding up. When used in a live setting, these human-readable warnings could suggest ways to protect a vulnerable composition. These insights may readily apply as qualitative warning indicators in socio-ecological systems with similar dynamics. 

We combine the high predictive performance of machine learning trained on empirical data with the explainability provided by SHAP values to extract readable warning signals. This work effectively improves the accuracy, applicability, and readability of warnings of transitions in complex adaptive systems. Our approach could be a model for the design of warning systems in multiple domains, from online social systems to earth systems and ecology. 

\subsection*{Data availability} 
All figure data is available on the Princeton Data Commons~\cite{stephenson_anna_2025}. % (\url{https://doi.org/10.34770/e8xh-5g68}). 
The code reproducing the results of this paper is available on Github at \url{https://github.com/AnnieStephenson/r-place-emergence/tree/EWSpaper}.

%\showmatmethods{} % Display the Materials and Methods section

\acknow{G.F. and A.B.S. are supported by a gift from William H. Miller III. A.B.S. is supported by funding from the Princeton University Dean for Research, and the High Meadows Environmental Institute. We thank Giuseppe Ferro, Chris Kempes, Mikhail Kuleshov, Nusrat Molla, Andrew Romans, and Emma Zajdela for helpful discussions.}

\showacknow{} % Display the acknowledgments section

\bibsplit[18]
%Use \bibsplit to split the references from the body of the text. Value "[2]" represents the number of reference in the left column (Note: Please avoid single column figures & tables on this page.)

% Bibliography
\makeatletter\@input{xx.tex}\makeatother

\bibliography{references,reference_data}


\end{document}


%\section*{Guide to using this template on Overleaf}

%Please note that whilst this template provides a preview of the typeset manuscript for submission, to help in this preparation, it will not necessarily be the final publication layout. For more detailed information please see the \href{https://www.pnas.org/page/authors/format}{PNAS Information for Authors}.

%If you have a question while using this template on Overleaf, please use the help menu (``?'') on the top bar to search for \href{https://www.overleaf.com/help}{help and tutorials}. You can also \href{https://www.overleaf.com/contact}{contact the Overleaf support team} at any time with specific questions about your manuscript or feedback on the template.

%\subsection*{Author Affiliations}

%Include department, institution, and complete address, with the ZIP/postal code, for each author. Use lower case letters to match authors with institutions, as shown in the example. PNAS strongly encourages authors to supply an \href{https://orcid.org/}{ORCID identifier} for each author. Individual authors must link their ORCID account to their PNAS account at \href{http://www.pnascentral.org/}{www.pnascentral.org}. For proper authentication, authors must provide their ORCID at submission and are not permitted to add ORCIDs on proofs.

%\subsection*{Submitting Manuscripts}

%All authors must submit their articles at \href{http://www.pnascentral.org/cgi-bin/main.plex}{PNAScentral}. If you are using Overleaf to write your article, you can use the ``Submit to PNAS'' option in the top bar of the editor window.

%\subsection*{Format}

%Many authors find it useful to organize their manuscripts with the following order of sections: title, author line and affiliations, keywords, abstract, significance statement, introduction, results, discussion, materials and methods, acknowledgments, and references. Other orders and headings are permitted.

%\subsection*{Manuscript Length}

%A standard 6-page article is approximately 4,000 words, 50 references, and 4 medium-size graphical elements (i.e., figures and tables). The preferred length of articles remains at 6 pages, but PNAS will allow articles up to a maximum of 12 pages.

%\subsection*{References}

%References should be cited in numerical order as they appear in text; this will be done automatically via bibtex, e.g. \cite{belkin2002using} and \cite{berard1994embedding,coifman2005geometric,phdthesis,masterthesis}. All references cited in the main text should be included in the main manuscript file.

%\subsection*{Data Archival}

%PNAS must be able to archive the data essential to a published article. Where such archiving is not possible, deposition of data in public databases, such as GenBank, %ArrayExpress, Protein Data Bank, Unidata, and others outlined in the \href{https://www.pnas.org/author-center/editorial-and-journal-policies#materials-and-data-availability}{Information for Authors}, is acceptable.

%\subsection*{Language-Editing Services}
%Prior to submission, authors who believe their manuscripts would benefit from professional editing are encouraged to use a language-editing service (see list at https://www.pnas.org/author-center/language-editing). PNAS does not take responsibility for or endorse these services, and their use has no bearing on acceptance of a manuscript for publication.


%\begin{table}[t!]
%\centering
%\caption{Comparison of the fitted potential energy surfaces and ab initio benchmark electronic energy calculations}
%\begin{tabular}{lrrr}
%Species & CBS & CV & G3 \\
%\midrule
%1. Acetaldehyde & 0.0 & 0.0 & 0.0 \\
%2. Vinyl alcohol & 9.1 & 9.6 & 13.5 \\
%3. Hydroxyethylidene & 50.8 & 51.2 & 54.0\\
%\bottomrule
%\end{tabular}

%\addtabletext{nomenclature for the TSs refers to the numbered species in the table.}
%\end{table}


%\subsection*{Digital Figures}

%EPS, high-resolution PDF, and PowerPoint are preferred formats for figures that will be used in the main manuscript. Authors may submit PRC or U3D files for 3D images; these must be accompanied by 2D representations in TIFF, EPS, or high-resolution PDF format. Color images must be in RGB (red, green, blue) mode. Include the font files for any text.

%Images must be provided at final size, preferably 1 column width (8.7cm). Figures wider than 1 column should be sized to 11.4cm or 17.8cm wide. Numbers, letters, and symbols should be no smaller than 6 points (2mm) and no larger than 12 points (6mm) after reduction and must be consistent.

%Figures and tables should be labelled and referenced in the standard way using the \verb|\label{}| and \verb|\ref{}| commands.

%Figure \ref{fig:frog} shows an example of how to insert a column-wide figure. To insert a figure wider than one column, please use the \verb|\begin{figure*}...\end{figure*}| environment. Figures wider than one column should be sized to 11.4 cm or 17.8 cm wide. Use \verb|\begin{SCfigure*}...\end{SCfigure*}| for a wide figure with side legends.

%\begin{SCfigure*}[\sidecaptionrelwidth][t!]
%\centering
%\includegraphics[width=11.4cm,height=11.4cm]{frog.pdf}
%\caption{This legend would be placed at the side of the figure, rather than below it.}\label{fig:side}
%\end{SCfigure*}


%\subsection*{Tables}
%Tables should be included in the main manuscript file and should not be uploaded separately.


%\subsection*{Single column equations}

%Authors may use 1- or 2-column equations in their article, according to their preference.

%To allow an equation to span both columns, use the \verb|\begin{figure*}...\end{figure*}| environment mentioned above for figures.

%Note that the use of the \verb|widetext| environment for equations is not recommended, and should not be used.

%\begin{figure*}[bt!]
%\begin{align*}
%(x+y)^3&=(x+y)(x+y)^2\\
%       &=(x+y)(x^2+2xy+y^2) \numberthis \label{eqn:example} \\
%       &=x^3+3x^2y+3xy^3+x^3.
%\end{align*}
%\end{figure*}



%\subsection*{Supporting Information Appendix (SI)}

%Authors should submit SI as a single separate SI Appendix PDF file, combining all text, figures, tables, movie legends, and SI references. SI will be published as provided by the authors; it will not be edited or composed. Additional details can be found in the \href{https://www.pnas.org/authors/submitting-your-manuscript#manuscript-formatting-guidelines}{PNAS Author Center}. The PNAS Overleaf SI template can be found \href{https://www.overleaf.com/latex/templates/pnas-template-for-supplementary-information/wqfsfqwyjtsd}{here}. Refer to the SI Appendix in the manuscript at an appropriate point in the text. Number supporting figures and tables starting with S1, S2, etc.

%Authors who place detailed materials and methods in an SI Appendix must provide sufficient detail in the main text methods to enable a reader to follow the logic of the procedures and results and also must reference the SI methods. If a paper is fundamentally a study of a new method or technique, then the methods must be described completely in the main text.

%\subsubsection*{SI Datasets}

%Supply .xlsx, .csv, .txt, .rtf, or .pdf files. This file type will be published in raw format and will not be edited or composed.


%\subsubsection*{SI Movies}

%Supply Audio Video Interleave (avi), Quicktime (mov), Windows Media (wmv), animated GIF (gif), or MPEG files. Movie legends should be included in the SI Appendix file. All movies should be submitted at the desired reproduction size and length. Movies should be no more than 10MB in size.

