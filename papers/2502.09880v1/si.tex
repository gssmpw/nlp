\documentclass[9pt,twoside]{pnas-new_SI}

%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% FOR ARXIV %%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
% go to "pnassupportinginfo.sty"
% comment out the line: \includegraphics[width=9.95cm]{pnas-logo}
% remember to uncomment for submission to PNAS
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% END FOR ARXIV %%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Use the lineno option to display guide line numbers if required.
\usepackage{multirow}
\usepackage{cellspace}
\usepackage{makecell}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{xspace}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{} % Clear all headers and footers

\templatetype{pnassupportinginfo}

% so that the full section.subsection numbers are  listed when referencing an SI section in the main text
\makeatletter
\renewcommand{\p@subsection}{\thesection.}
\makeatother


\newcommand{\ttt}{\ensuremath{\Delta^{*}}\xspace}
\newcommand{\ttttr}{\ensuremath{\Delta^{*}_{\textrm{true}}}\xspace}
\newcommand{\tttpr}{\ensuremath{\Delta^{*}_{\textrm{pred}}}\xspace}
\newcommand{\tfour}{\ensuremath{\widetilde{\Delta}^*}\xspace}
\newcommand{\ttrans}{\ensuremath{t^{*}}\xspace}

%\usepackage{lineno}
%\linenumbers

\begin{document}


\title{Interpretable Early Warnings using Machine Learning in an Online Game-experiment}
\author{Guillaume Falmagne, Anna B. Stephenson, and Simon A. Levin}
\correspondingauthor{Guillaume Falmagne\\E-mail: g.falmagne@princeton.edu}


%% Comment out or remove this line before generating final copy for submission; this will also remove the warning re: "Consecutive odd pages found".
% \instructionspage  

\maketitle

%% Adds the main heading for the SI text. Comment out this line if you do not have any supporting information text.
\SItext


%\section{Extended Materials and Methods}
\section{Data of r/place and compositions}
\subsection{r/place data and generalities}
\label{secSI:rplacedata}

\begin{figure}
\includegraphics{figures/SI_figures/SI_rplace_stats.png}
\centering
\caption{General statistics of the r/place pixel change data from 2022 and 2023. \textbf{(a), (b)} For 2022 (a) and 2023 (b), the heat map of the number of pixel changes over the course of the entire event (left), and the distribution of pixel changes across available colors (right); note that some colors and canvas regions were only available later in the game. \textbf{(c)} For 2022 (red) and 2023 (blue), distributions of the number of changes per pixel (left), and distributions of the number of pixel changes per user (right).}
\label{figSI:rplace}
\end{figure}

\paragraph{Canvas basic rules and statistics.}
We use the data from the 2022 and 2023 editions of the r/place game-experiment. These events offered an initially white canvas to all registered Reddit users without stating an explicit goal. Users could choose a new color for any pixel, but had to wait for at least a 5-minute \textit{cooldown} before modifying another pixel. Due to this time constraint, the users had to collaborate and organize to create drawings carrying cultural significance---which we call \textit{compositions}. The 2022 event featured 160.4 million pixel changes from 10.4 million users across 3.5 days; the 2023 event featured 133.8 million pixel changes from 8.6 million users across 5.4 days. It is important to note that different pixels attracted widely different attention; a few thousand pixels stayed white for the whole event, while the top left pixel in 2022 was modified about 98 thousand times. Similarly, about 2 million users performed a single pixel change, while some users performed more than 500 changes. General statistical distributions of the 2022 and 2023 canvas are shown in Fig.~\ref{figSI:rplace}.

\paragraph{Raw data.}
The data from all r/place editions (2017, 2022 and 2023) is publicly available from Reddit. We extract the data for 2022 and 2023 from \url{https://placedata.reddit.com/data/canvas-history/index.html}. The dataset contains, for each pixel change, the pixel location, the used color, the time it was performed (at millisecond precision), and an anonymized user tag---allowing us to link changes performed by the same Reddit user. We first convert this data into a structured numpy array that reduces information redundancy and compacts the data by replacing user tag string with integers and removing duplicate changes.

\paragraph{Canvas extension history.}
New colors and pixels were added at times unknown to the users. The canvas initially showed a million pixels, but reached 4 million pixels in 2022 (6 million in 2023). In addition, there were from 8 to 32 available colors to choose from. For reference, we show in Table~\ref{tabSI:extensions} the discrete changes in available pixels and colors and the times at which they occurred. These extensions are not considered to significantly change the dynamics we studied, as the compositions are relatively localized, so compositions on new canvas regions behave as if it were the beginning of a new game, and the number of colors did not seem to limit user activity.

Toward the end of both events, only changes to the color white were allowed for about an hour, so compositions appeared to rapidly vanish before the event closed---the so-called \textit{white-out}. An hour before the white-out in 2023, only five grayscale colors were allowed. All times where only white or greyscale colors were available are excluded from the analysis, as this reduction of available colors did not allow for maintenance of existing compositions. 

\begin{table}[h]
    \centering
    \textbf{2022}
    \vspace*{3mm}
    
    \begin{tabular}{r|c|c|c|c|c|c|c}
    time of extension (in s)& 0 & 99635& 99646& 195574& 195583 & 295410 & 300590\\
    \hline
    number of pixels & 1M & & 2M&& 4M&&end\\
    number of colors & 16 & 24 & & 32&& 1 (white) & end
    \end{tabular}

    \vspace*{3mm}
    \textbf{2023}
    \vspace*{3mm}

    \setlength{\tabcolsep}{4pt}
    \begin{tabular}{r|c|c|c|c|c|c|c|c|c|c|c|c|c}
    time of extension (in s)& 0 & 97208& 116999& 155754& 208964& 277192  & 277200 & 305994 &361992 & 362003 & 456228 &459029 & 463090\\
    \hline
    number of pixels & 1M &1.5M && 2M&3M && 4M&5M&&6M&&&end\\
    number of colors & 8 &      &16& &&24& &&32&& 5 (grayscale) &1 (white) & end
    \end{tabular}

    \vspace*{2mm}
    \caption{Time points at which the canvas was extended or offered more color choices.}
    \label{tabSI:extensions}
\end{table}


\paragraph{Cooldown.}
In general, the enforced cooldown between two consecutive pixel changes by the same user was 5 minutes. However, some users were capped at a 10 or 20-minute cooldown, notably if their Reddit account was not verified. Other changes in rules took place at the end of the 2023 event, where the cooldown was reduced incrementally: part of the users, chosen based on credibility criteria by moderators, were offered a 4-minute cooldown from second 273600. We neglect the effects of this change on composition dynamics, as it is small and concerns only a fraction of the users. Right after the white-out in 2023, the cooldown was gradually reduced for all users to 3 minutes, then 2, then 1, and finally 30 seconds. Times with these cooldown values were excluded already by excluding the white-out period.

\paragraph{Redundant changes.} 
Sometimes, users ``changed'' pixels using the same color the pixel was already in, potentially by mistake, out of boredom, or to have their user name attached to that pixel. There were 26.4 million such \textit{redundant} changes in 2022 and 17.7 million in 2023; they form an essential part of the canvas dynamics and should not be removed. Interestingly, 46 thousand (1.1 million) redundant changes in 2022 (in 2023) are also redundant in the user name, but we do not assign a special status to them since the motivations for making these changes may be similar to other redundant changes.

\paragraph{Moderators.}
Moderators from the Reddit team were given rights to modify many pixels at a time to erase inappropriate content. The changes made by moderators in a filled rectangle or circle of pixels are labeled in the raw data. However, the single-pixel changes by moderators are not labeled. We identify a portion of these by tagging as moderator changes those whose user tags are the same as for other explicit moderator changes; this is efficient only in 2022 as moderators in 2023 usually changed user tags at every action.
There were about 100 thousand explicit moderator changes in 2022 and 1.6 million in 2023. Though these changes break the 5-minute cooldown rules and could show as sudden peaks of activity in our variables, they are still part of the dynamics seen by users and constitute a negligible part of the user activity, and were therefore not discarded from the computation of our variables.

\paragraph{Multiple accounts and bots.}
Highly engaged users created multiple accounts to bypass the 5-minute cooldown. These accounts are listed as separate users in the data and considered separate in our analysis, as there is no way to distinguish them using the anonymized data. Though this is considered ``cheating'' and was fought against by the moderation team, it is still part of the canvas dynamics observed by all users, and thus should be included in our analysis. Some changes were also made by ``bots'', meaning without a human presence. Users programmed these bots to continue contributing toward their goals even when they were not actively playing. Bots also often relied on numerous ad-hoc Reddit accounts. This practice was frowned upon by the Reddit community, and was actively fought against by the r/place organizing team. However, this team could not detect all bots and their changes, so there was still some significant bot activity, in particular in 2023. An estimated 5 million pixel changes did not use the graphical interface of r/place in 2023. This number was likely smaller in 2022, when there were fewer widely-available tools to do so. Again, there is no infallible way to exclude these changes, but they are still part of the dynamics as they affected the canvas seen by users.

Even when excluding flagged moderator changes and the times with intentional reduced cooldown values in 2023, some changes were made by the same user within less than 5 minutes: 108 thousand changes in 2022 and 1.6 million in 2023. One source of these changes are moderator changes that are not identified, which also explains the much higher number in 2023 as there were more moderator changes that year. Other possible explanations include communication lags between user actions and Reddit servers where two changes from a user were recorded at the same time despite occuring with more than 5 minutes between them; or there could have been lags of Reddit servers themselves, allowing for two very close changes from the same user to be both recorded. Bots might have exploited server lags to perform faster changes, although we cannot verify this with the available dataset. Again, we neglect the effects of these cooldown-cheating changes as they are few and are part of the canvas dynamics visible to users. 

\subsection{Data of compositions}
Users in r/place spontaneously formed communities, each of which built pixel drawings they defended. These compositions form the subsystems we study and compare.


\label{secSI:compodata}
\paragraph{Crowdsourced data.}
We use the Atlas of all compositions referenced by users after each r/place edition ended~\cite{haagmansPlaceAtlasInitiative2024}, extracted from \url{https://raw.githubusercontent.com/placeAtlas/Atlas/master/web/Atlas.json} for 2022 and \url{https://raw.githubusercontent.com/placeAtlas/Atlas-2023/master/web/Atlas.json} for 2023. It contains canvas coordinates for the borders of the image over various time ranges with up to 30-minute resolution for each composition, as well as a name, a description, and often links to social media channels where the corresponding community organized---normally a subreddit forum, a Discord server, Youtube channel, or Twitch channel. Despite imperfections, this Atlas contains essential cultural information that an automatic detection algorithm would miss, so we emphasize that this crowdsourced data is key to this work. 

A majority of compositions have fixed borders, but some have different borders over different time ranges; in this case, we record pixel changes in the union of all borders, but we designate as \textit{active} only the pixels that are in the correct borders at a given time. Only changes of active pixels are included in the calculation of time series describing each composition.


\paragraph{Data cleaning.}
In practice, we build data objects that contain information about all pixel changes within the borders and time ranges of each composition. This pixel change information includes the time, user identifier, color identifier, position on the canvas; we also include more high-level information, such as whether the change is on an active pixel, from a moderator, redundant, or cheated the cooldown time. These objects are the input of the calculation of the time series describing each composition.

We performed some cleaning operations on the definition of compositions and their borders with minimal assumptions:
\begin{itemize}
  \setlength\itemsep{0.5mm}
    \item We remove duplicate compositions, defined as having
    more than 99\% spatial overlap and identical time ranges. We define \textit{spatial overlap} as the intersecting area of the two images divided by the area of the largest image. In practice, we kept the largest composition, merging metadata from both.
    \item We change the name of compositions that have different borders but the same name in the Atlas. 
    \item Rectangles are a common composition shape. To correct obvious mistakes in the drawing of the borders by contributors to the Atlas, we transform the compositions with a single time range and whose shape is close to rectangular into the smallest rectangle containing all pixels with the original border. We define a shape as close to a rectangle when both its dimensions exceed 10 pixels and its corners need to be moved by two pixels or less for the shape to be a rectangle.
    \item Compositions are mostly referenced thematically in the Atlas, such that the work of some communities that have been erased in one place but reappeared elsewhere is sometimes listed as a unique composition. 
    We consider `moved' compositions (that do not have any spatial overlap in different time ranges) as separate compositions. This significantly increases the number of studied subsystems.
    \item In compositions listing areas that do have a spatial overlap but are active on discontinuous time ranges, we include the gap between these time ranges so that the composition is defined on a continuous time range. In combination with the previous point, this means that compositions are made continuous in canvas space and in time.
\end{itemize}

Within a composition cleaned as above, there can be significant changes in the borders of the image, as encoded in the Atlas. Due to a border change, a composition's time series can show a discontinuity that is unrelated to canvas activity dynamics. We therefore define \textit{stable-area time ranges} over which the spatial overlap between images before and after any border changes always exceeds 90\%. We generally ignore times close to the start of a stable-area time range. When the computation of time series depends on multiple time steps, the necessary information is recorded over the union of all image borders. % stable\_area\_timeranges

In 2022, there were 10,890 compositions before separating non-overlapping areas and 14,160 compositions after separation. In 2023, there were 6,667 compositions before separation and 6,930 compositions after. Additional requirements are set for the training dataset: Only the 8,871 in 2022 (5,417 in 2023) clean compositions with more than 100 pixels are kept, to avoid small-statistics noise in the time series. From these, only 6,291 (3,546 in 2023) compositions have at least one time instance that passes all requirements for the training data.

\section{Transitions}
\label{secSI:transitions}
This work predicts transitions in a coherent way over thousands of subsystems, which first requires defining transitions in these subsystems. Most variables describing the state of each composition, which are our subsystems of choice, vary along a continuum. These variables often change substantially during a transition, but not in a binary way. Therefore, defining transitions necessarily involves setting arbitrary thresholds on a state variable. To our knowledge, no universal method exists to define transitions on a continuous state variable, so we rely on a system-specific appreciation of how users perceive a transitioned composition. This translates into an absolute and a relative threshold on \texttt{diff pixels reference}, the fraction of pixels differing from the reference image. The image must have 35\% of pixels differing from a proxy of what users perceive as the typical image of the composition, and that fraction must be 6 times higher than its average over the past sliding window. 

Another requirement for transitions is that they must begin at least one sliding window width after the start of a stable-area time range. This ensures that \texttt{diff pixels reference} is computed excluding jumps unrelated to canvas dynamics when the image borders change. % stable\_area\_timeranges in find_transitions()

\paragraph{Stability of pre-transition systems.}
We defined transitions to represent what human players would perceive as transitioning systems. However, to resemble a practical, real-world warning system, we had to reject some periods that might look like transitions to users; see two examples in Fig.~\ref{figSI:notrans}. First, requiring a relative threshold of 6 on the \texttt{diff pixels reference} ensures that the pre-transition system shows significant stability. 
A real-world warning system would not monitor unstable systems, as it would be unclear if they are already in transition or whether there is a clear state or equilibrium to transition from. This relative threshold combined with the absolute threshold of 0.35 ensures the abruptness of the regime shift; it would be difficult in our system to include smooth transitions, as nearly any gradual evolution of a composition image could then qualify as a transition. We checked that the quality of our machine learning predictions does not change significantly when varying these thresholds; this sensitivity study is shown in Fig.~\ref{figSI:sensitivity}. 

\paragraph{Transitions from a patchwork.}
For motivations of applicability to a live warning system, predicting transitions makes sense only in a system that is already monitored and considered of interest. 
Therefore, we exclude transitions from a patchwork of pre-existing compositions into one new composition. We could technically include these transitions in our study because in the full dataset, we already know this canvas area will become a composition; but this would not be known in a live warning system. For similar reasons, we also exclude the times before the start of an Atlas composition from the training data. 
Note that not labeling these periods as transitions reduces our apparent prediction performance: in addition to reducing the available training data, the dynamical properties of this type of transition would be easier to discriminate than those of the transitions we retain, as there are specific properties of composition patchworks that the algorithm could associate with the incoming creation of a composition. 

\paragraph{Time of the transition.}
The variable we aim to predict with our algorithm is the time remaining before the next transition, if one exists. To this end, we define the exact time of the transition using the values of \texttt{diff pixels reference} at the time step the transition was identified and at the previous time step. The time of transition \ttrans is the moment at which a linear interpolation of \texttt{diff pixels reference} crosses both transition thresholds. % transition\_start\_time\_simple function in the code

\begin{figure}[h!]
\centering
\includegraphics[width=0.75\textwidth]{figures/SI_figures/non-transition_examples.png}
\caption{Examples of compositions where no transitions are tagged despite a large image change. \textbf{(a)} The fraction of differing pixels (\texttt{diff pixels reference}) passes the transition threshold requirements, but the pre-transition image is a patchwork of compositions. \textbf{(b)} Fraction of differing pixels shows
too slow of a change to a new composition. In addition, the pre-transition image is not an Atlas composition, hence not a monitored subsystem.}
\label{figSI:notrans}
\end{figure}

\section{Composition-level time series and variables}
\label{secSI:variables}

For each composition, we define many time series variables that describe various aspects of its evolving state. These variables are computed at 5-minute time steps; we call the set of feature values of these variables at a given time step a \textit{time instance}. The 5-minute width of the time steps coincides with the cooldown, which is the most relevant time scale in the data. Let us describe in more detail all the time series and variables that we have defined with the expectation that they could contribute to predicting the next transition. They are organized by types of variables, including efforts to reproduce variables commonly used to assess critical slowing down. As explained in section~\ref{secSI:varselect}, only 19 times series and 5 time-independent variables are selected to be input in the training, for their higher contributions to the predictions and lower correlations. 

\subsection{Normalizations}

Here, we describe standard transformations that we apply to some variables input in the training. 

First, some variables are normalized by time and area units. The time unit is 5 minutes, meaning that variables are effectively already time-normalized considering our 5-minute time step. The area unit is the number of active pixels in the composition image at a given time step, 
which may change as the composition’s borders evolve in the Atlas.

Second, some variables are computed over or averaged over the past sliding window. This is a moving average whose range always ends at the considered time step.

Third, some variables have absolute values with different typical values in different compositions. To make values of these variables comparable among compositions, we instead consider relative changes in these variables. This is computed as the ratio of the variable at this time step to its average over the past sliding window---except for the autocorrelation where the sliding window average is instead subtracted, as the autocorrelation can have value zero.

Last, the averages over pixels or over the top decile of pixel values use only the pixels active at the considered time, \textit{i.e.} those summing to the current area. 

\subsection{State variable}

A major challenge in interpreting our results within the framework of early warning signals literature is the absence of direct equivalents in our system for the variables typically used as indicators. These indicators include the variance, lag-1 autocorrelation and rate of return after perturbation, computed on a state variable that represents the system’s overall health. However, our systems are high-dimensional with a number of image states increasing exponentially with the number of pixels and number of color, 
making them difficult to summarize with a single state variable. 
Some variables can adequately describe the stability of the system, such as the \texttt{diff pixels reference} variable we chose to define transitions. However, they are not simple scalar quantitative indicators, like population in ecology or price in economics, and they often do not conform to the paradigm of small perturbations around a well-defined equilibrium (see discussion in main text and section~\ref{secSI:toymodel}).

We therefore design multiple equivalents for variance, autocorrelation, and return rate, each offering a different approximation of standard early warning indicators which could capture distinct properties of the pre-transition periods. For the purpose of reaching higher performance of the algorithm, only the most predictive variables are kept. However, when interpreting the results, it should be noted that these variables do not precisely correspond to their conventional definitions in the literature.

\subsection{Variance}

The variance can be defined in many ways in our system. We explored two main approaches: estimating the variations of a scalar variable describing the image change or directly of the high-dimensional image. Let us consider first the latter. We start with variables that estimate linear variations as they have simpler definitions in the context of r/place, before considering variables with quadratic variations. Most of the proposed variance variables are very correlated, though they can still capture slightly different dynamical properties. 

\paragraph{Differing pixels and other linear variations.}

Multiple variables are based on the fraction of pixels that differ between images at two different times. The considered pixels are always the ones active at the considered time step, even when they differ from those in the borders of the past image.

The variable \texttt{diff pixels reference} compares the instantaneous image at time $t$, as seen by users on the canvas at the end of the considered time step, to the reference image in the sliding window as defined in the main text; this is normalized by area. The variable \texttt{diff pixels instant} compares the instantaneous image at time step $t$ to the image composed of the mode colors of the previous time step $t-1$; this is normalized by time and area. Another possibility is to compare to the instantaneous image at $t-1$, but this showed lower contribution to the predictions.

Another route relies on a measure of how stable the pixel colors are within a single time step. We define the instability of a pixel by the fraction of this time step that it spends in a color different than the mode color:
\begin{equation*}
    \textrm{instability} = \frac{1}{N_p}\sum_{p}\sum_{c\neq \textrm{mode}(p)} f_{p,c}
\end{equation*}
where $f_{p,c}$ is the fraction of this time step that pixel $p$ spent in color $c$, and the sum runs over the $N_p$ considered pixels and all colors that are not the mode color for pixel $p$. Averaging over pixels with the top decile of values results in the \texttt{instability top} selected variable (which is time normalized), while averaging over all pixels resulted in slightly lower performance.

A similar variable, which we excluded for its high correlations with instability and the fraction of differing pixels, is the cumulative attack time. It represents the average, over all pixels, of the fraction of this time step that a pixel spent in a color different from the reference color.

\paragraph{Quadratic pixel variations.} 

Though the image is not a scalar continuous variable, we can still get closer to the standard variance definition by computing quadratic variations of the color of each pixel. The following definitions are meant to estimate the spread of the distribution of colors that a given pixel has been in, relying on the quantity $S_p = \sum_c f_{p,c}^2$, instead of a linear sum of the $f_{p,c}$ fractions we discussed above. This quadratic sum equals $1$ when a single color is used for pixel $p$ this time step, while its theoretical minimum, occurring when the pixel spends an equal time in all colors, is $1/N_c$, where $N_c$ is the number of colors. 

As $S_p$ is anti-correlated with the spread of the color distribution, a first option for the variance is 
$$\frac{1}{N_p}\sum_p \frac{1}{S_p}.$$ 
Another option is to consider first the sum $S_p$ for all pixels before inverting it, which amounts to computing the spread of colors directly on the entire image: 
$$\frac{N_p}{\sum_p S_p}$$ 
Both these variance variables equal $1$ in fully inactive time steps, and $N_c$ when all pixels stay an equal time in all colors over the time step. 
We used the maximum $N_c=32$ along the whole time of the event because the highest reached values are far from the theoretical maximum, showing that the time-dependent number of available colors does not act as an upper bound. 

How widely time is distributed across a limited set of colors for a given pixel is similar to the dispersion of independent categorical variables, which is well represented by the variance of a multinomial distribution. In this context, it translates into $\sum_c f_{p,c} (1-f_{p,c}) = 1 - S_p$. Therefore, we define the multinomial-like variance as
$$1 - \frac{1}{N_p}\sum_p S_p.$$
This is also called the Gini impurity index in some contexts. A quantity of very close interpretation is the Shannon entropy of the color distribution of a pixel
$$-\sum_c f_{p,c} \log f_{p,c},$$
that we set aside as it is very highly correlated with the multinomial version.

A last similar possibility is to sum the squared color frequencies only for non-mode colors. For this, we define a \textit{non-mode dot product}: $$D(\vec{a},\vec{b}) = \left(\sum_i a_i b_i\right) - \max_i(a_i b_i),$$
where $\vec{a}$ and $\vec{b}$ are arbitrary vectors. In our usage, the vector components correspond to the time a pixel spent in each color, meaning there are 32 components. This results in the variance
$$ \frac{1}{N_p}\sum_p D(\vec{c}_p,\vec{c}_p) = \frac{1}{N_p}\sum_p [S_p - \max_c(f_{p,c}^2)].$$

When computed over all time steps and compositions, all the above quadratic variables showed very high correlations ($\rho>0.95$) with each other and with another more intuitive variable: the number of colors that a pixel is assigned within this time step. We end up using the pixel average \texttt{n colors} and top decile average \texttt{n colors top}, as they outperform all these variables. 

Another approach to close the gap with the standard variance formula for a 32-color pixel results in the seemingly linear variables explained earlier. Considering $t_i$ as infinitesimal time steps within the time step $\Delta t$ under study, we take every color at $t_i$ as a single point in a sample for which we calculate the variance:
$$\frac{1}{\Delta t}\sum_{t_i} (c_i - \langle c\rangle)^2 = \sum_{c} f_{p,c} (c - \langle c\rangle)^2 = \sum_{c\neq \langle c\rangle} f_{p,c}$$
The ``mean'' color $\langle c\rangle$ is not well defined as the color $c$ is a categorical and not a 
continuous variable, so we define it following two different assumptions. For the same reason, the difference of colors is not well defined, but we assume it is $1$ where the two discrete colors are different, and $0$ otherwise (neglecting that some color pairs could be considered more different than others). 
%When defining the ``mean'' color $\langle c\rangle$ as the mode color or the reference color, we obtain the instability or the cumulative attack fraction, respectively. 
if we define the ``mean'' color $\langle c\rangle$  as the mode color or the reference color, we recover the instability or the cumulative attack fraction, respectively. 


\paragraph{Variations of an existing time series.} 

A different approach is to summarize the state of the image in a scalar time series $v(t_i)$, before calculating at time $t_n$ the standard variance of its values over a past sliding window $(t_1,...,t_n)$. 
Here, we try to avoid the assumptions due to defining a mean image over the past sliding window, which we take in some cases to be the reference image. We can avoid the need for a mean in the variance via this approximated variance:
$$\sum_{t_i} \frac{n}{2(n-1)} v(t_i)^2,$$
which converges to the standard variance $\sum_{t_i} \frac{n}{n-1} (v(t_i)-\langle v\rangle)^2$ at large $n$. 
A variable that effectively describes the differences at the image level \textit{between each time step} (and not the difference from the mean) is \texttt{diff pixels instant}, which we use for $v$.
This is therefore the \texttt{variance} we use in the training, with a sliding window of 10 time steps (50 minutes). Out of the variance variables we calculate, this one is the most similar to those calculated to evaluate critical slowing down in the ecology literature. 

\subsection{Autocorrelation}

We define multiple variables that are analogs, for an image, to the lag-1 time autocorrelation of a scalar quantity. A first route relies on the same quadratic differences used to define the variance variables, applied to the color distributions of a pixel $f_{p,c}(t)$ in this time step and $f_{p,c}(t-1)$ in the previous time step. Using the non-mode dot product once again, a first autocorrelation variable, \texttt{autocorr non-mode}, is 
$$ \frac{1}{N_p}\sum_p D(\vec{c}_p(t),\vec{c}_p(t-1)) = \frac{1}{N_p}\sum_p \left[\left(\sum_c f_{p,c}(t)f_{p,c}(t-1)\right) - \max_c(f_{p,c}(t)f_{p,c}(t-1))\right].$$
Now using an analogy with the variance of a multinomial distribution, another autocorrelation variable is:
$$\frac{1}{N_p}\sum_p \left[\sum_c f_{p,c}(t)(1-f_{p,c}(t-1))\right].$$
Lastly, in analogy with the $\chi^2$ dissimilarity between two distributions, we also define the following autocorrelation:
$$\frac{1}{N_p}\sum_p  \left[\sum_c \frac{1}{2} (f_{p,c}(t)-f_{p,c}(t-1))^2\right].$$
These three variables are highly correlated over all time instances, so we kept only the best-performing one.

We also define a per-pixel autocorrelation variable 
that compares the color distributions in this time step $c_t$ and in the previous one $c_{t-1}$, with respect to a ``mean'' color distribution $c_{\textrm{ref}}$---that of the reference image. For each pixel, the case-by-case autocorrelation is: 
\[    
\begin{cases}
      0 & \text{ if } c_{t}=c_{t-1}=c_{\textrm{ref}} \\
      1 & \text{ if }  c_{t}=c_{t-1} \text{ and }  c_{t}\neq c_{\textrm{ref}} \\
      0 & \text{ if }  c_{t}\neq c_{t-1} \text{ and } (c_{t}=c_{\textrm{ref}} \text{ or } c_{t-1}=c_{\textrm{ref}}) \\
      -1 & \text{ if }  c_{t}\neq c_{t-1} \text{ and } c_{t}\neq c_{\textrm{ref}} \text{ and } c_{t-1}\neq c_{\textrm{ref}}
    \end{cases}
\]
\texttt{autocorr by case} is the average of the above over all pixels. We need this case-by-case definition because standard correlations require a notion of directionality lacking in the color space. This issue did not appear in the above discussion on variance, as the sign of the deviations do not matter there.

\subsection{Attack duration and return rate}

In addition to the variance and autocorrelation, the time or rate of return to equilibrium after a perturbation is another quantity used as evidence for critical slowing down. We take the reference image as our proxy for the equilibrium that the instantaneous image should return to. 
The return rate therefore measures the fraction of attacked pixels that are changed back to the reference color within one time step. We also introduce a related variable, the attack duration, which we initially designed as a return time on a longer time scale but then attributed a more nuanced interpretation.
 
The attack duration of a pixel is defined based on two cases. 
If the pixel is in an attack color, the attack duration is the time since the moment the pixel was attacked, meaning when the pixel left the reference color. For a pixel in the reference color, it is the duration of the last attack on this pixel, if this attack started within the sliding window. Pixels not attacked within the sliding window are ignored. We use as training variables both \texttt{attack duration}, the average over recently-attacked pixels, and \texttt{attack duration top}, the average of the top decile of pixel values. 

It is important to note that certain attacks against the reference might be innovations in the image, agreed upon by the community defending this composition. This is a problem when the time scale of innovations is shorter than the sliding window, meaning the reference image is not truly the equilibrium to return to. The consequence is that the \texttt{attack duration} can increase without indicating a lower performing community or a more likely transition---which is why we do not name this variable ``return time''. 

We define the \texttt{return rate} as a variable on a shorter time scale to partially avoid the issue of innovations introducing lingering differences from the reference. It considers all pixels that are in an attack color at the end of the previous time step and computes the fraction of these pixels that returned at least once to the reference color. 
There can still be attacked pixels that are actually innovations, but they contribute only a single pixel in the fraction, so they do not dominate over the defense reactions. On the contrary, innovations dominate in the \texttt{attack duration} variables because they can reach values of the order of the sliding window width, which is much larger than the typical reaction time of the defense. 

\subsection{Image complexity}
\label{secSI:imagecomplex}
We use two variables, the entropy and the fractal dimension, that estimate the complexity of the image composition. This is key in the dynamics of the community, as simpler images may be easier to coordinate for but might attract fewer supporters.

\paragraph{Entropy.}
We compute a proxy for an entropy measure known as the computable information density, introduced in Ref.~\citenum{martinianiQuantifyingHiddenOrder2019}, which is the ratio of the total  length of losslessly compressed binary data to the original length of the data. We tested a variety of different lossless compression algorithms: Lempel-Ziv 1977 (LZ77), Lempel-Ziv 1978 (LZ78), and Deflate. Due to a combination of computation speed and compression factor, we chose the LZ77 algorithm. We use the implementation of LZ77 from the open-source Sweetsourcod library~\cite{martinianiSweetsourcod2019}. Note that we are not the first to use image compression to characterize image complexity on r/place; M\"uller and Winters used compression to characterize the evolution of certain canvas compositions in the 2017 experiment, as well as the entire canvas~\cite{mullerCompressionCulturalEvolution2018}.

These compression algorithms require a one-dimensional representation of the data. We must therefore flatten our two-dimensional images. The naive approach is a simple row-by-row 
raveling, where rows are sequentially concatenated one after the other. An approach that aims to conserve the locality in the image is to use the Peano-Hilbert space-filling curve, also known as a Hilbert Scan~\cite{martinianiQuantifyingHiddenOrder2019}. Though the Hilbert scan can in theory lead to better compression rates than a simple ravel, we did not observe this consistently. Because the Hilbert scan showed limited compression benefits and significantly increased computation time, we opted instead to use a simple ravel.  

To obtain comparable values among compositions and favor dynamical signals within a composition, we use the \texttt{entropy change}, which is the ratio of the entropy to its sliding window average. Because of this normalization of the entropy measure, we only need to calculate the numerator of the computable information density, which is the length of the losslessly compressed linearized data describing the image. The denominator, the uncompressed data length, is proportional to the number of pixels. Since scaling factors will cancel out during the normalization, we can simply use the pixel number as the denominator. 

When calculating entropy values for a composition over the sliding window without normalizing by a per-composition reference value, as in our \texttt{entropy} variable, we instead need to introduce a new normalization to make sure that entropy values are comparable across different compositions. Since this entropy measure is known to scale with the size of the image (see SI appendix of Ref. \citenum{martinianiQuantifyingHiddenOrder2019}), we must normalize as a function of the image size. We therefore introduce the normalization:
$$
\textrm{Entropy}_\textrm{norm} = \frac{\textrm{Entropy}_{\textrm{comp}} - \textrm{Entropy}_{\textrm{min}}(A)}{\textrm{Entropy}_{\textrm{max}}(A) -\textrm{Entropy}_{\textrm{min}}(A)}
$$
where $\textrm{Entropy}_{\textrm{comp}}$ is the entropy of a composition; $\textrm{Entropy}_{\textrm{min}}(A)$ is the minimum entropy for an image of the same area $A$ (or number of pixels) as the composition; $\textrm{Entropy}_{\textrm{max}}(A)$ is the maximum entropy at a given area. %Because the denominator, the original data length, must be the same for each right-hand-side term, it cancels out of the expression, and we can again simply calculate the numerator, the compressed length. To find the minimum compressed length at a given area, we simply use $\log(A)$, which is what thecompressed length of a uniform image converges to~\cite{savari_redundancy_1998}. 
The minimum entropy is simply that of a blank image of a given size, which is proportional to $1/A$. 
To find the maximum entropy, we generate 10 images of the given image size by randomly choosing from 8, 16, 24, or 32 available colors depending on the number of available colors at that time. We then take the mean compressed length of the 10 images, and use this value as our maximum. 
Some images could be less compressible than a random image, but they are uncommon in our dataset, and the amount by which they are less compressible is not significant. 

\paragraph{Fractal dimension.}
The computation of the fractal dimension starts with separating the image into the 8, 16, 24, or 32 colors that are currently available to users. We use the reticular box counting method~\cite{bisoiCalculationFractalDimension2001}, separately for images composed of each single color of the original image: a grid of boxes is superimposed on top of the single-color image, and the number of boxes touched by the image is counted as a function of box size. At each box size, the grid is superimposed in four ways---by aligning the first box with each of the four corners. We take the average of these four box counts to minimize finite-size effects of the grid. We calculate the box counts for box size from 1 pixel up to 10\% of the smaller dimension of the bounding rectangle of the composition, requiring a maximum box size of at least 3 pixels, with a cap at 10 pixels. For each color, a power law is fitted to the mean box count as a function of the box size. The absolute value of the negative exponent is taken to be the fractal dimension for each color, and we calculate a scalar color-weighted fractal dimension by summing the dimensions of each color weighted by the fraction of pixels of that color in the composition. The weighted fractal dimension is $2$ when the color is uniform and decreases as the colored patch perimeters become more fractal. For the same reasons as for the entropy, we consider the \textit{change} in fractal dimension, \texttt{fractal dim change}, by calculating the ratio of the fractal dimension to its sliding window average.


\subsection{User activity}

Here, we present the variables associated with the activity of users changing pixels in a composition. 

First, we consider two variables related to the type of pixel change. We use the \texttt{redundant changes} as defined in section~\ref{secSI:rplacedata}. Then, we measure the \texttt{attack fraction} as the fraction of pixel changes in the time step that differ from the pixel's reference color. It is set to $0.5$ when there are no pixel changes in the time step. 

We then consider variables that count users. The number of users contributing to a composition in the sliding window, \texttt{n users sw}, is normalized by the number of time intervals (60) contained in the sliding window range and by its area. Then, \texttt{new users} is the fraction of users active in a composition and time step but not in the past sliding window. Another possibility is to consider the fraction of new users compared to those of the previous time step, which we excluded as it is often very close to $1$: only a tiny fraction of users consistently changes pixels in consecutive time steps. Lastly, \texttt{changes/users sw} measures the engagement of individual users; it is the ratio of the number of changes to the number of users over the sliding window.

\subsection{Time-independent per-composition}

We include in the training data five variables that are only trivially time dependent and, for four of them, have a typical value per composition:
\vspace{-2mm}
\begin{itemize}[noitemsep]
    \item \texttt{area} is the base 10 logarithm of the active area of the composition; 
    \item \texttt{entropy} is the entropy proxy computed as in section~\ref{secSI:imagecomplex} averaged over the sliding window;
    \item  The \texttt{age} and \texttt{border corner center} as defined in the main text.
    \item The \texttt{canvas quadrant}, which is the number of the canvas extension the composition is placed in, ordered by time of opening of this part of the canvas.
\end{itemize}

\subsection{Variables selected in the training}
\label{secSI:varselect}
As stated in the main text, only 19 time series from those listed in this section are kept in the training, as well as 5 variables with trivial time-dependence; their full names, short names, and short descriptions are listed in table~\ref{tabSI:variables}. The time series are chosen for training according to two criteria maximizing their combined predictive power. First, the correlation among the kept time series is minimized; the correlation matrix between the 24 kept training input variables and the true time-to-transition is shown in Fig.~\ref{figSI:correlations}. Second, the mean absolute SHAP value, is maximized---see main text for the definition of SHAP values and section~\ref{secSI:featureselec} for a full description of how they are used for feature and variable selection. The distribution of SHAP values over all time instances for each training variable is shown in Fig.~\ref{figSI:shapdistr}. 

%\renewcommand{\arraystretch}{1.2}
\setlength\cellspacetoplimit{4pt}
\setlength\cellspacebottomlimit{4pt}
\begin{table}[h!]
    \centering
\hspace*{-2mm}
    \begin{tabular}{c|c|Sc|c}
        %\textbf{Internal name}& % can probably remove when submitting, only for our use
        \textbf{Full name} & \textbf{Short name} & \textbf{Short description} & \makecell{\textbf{Coarse} \\\textbf{time} \\\textbf{ranges?}}
        \\
\hline
\multicolumn{4}{l}{\textit{With memory}}\\
\hline
    %frac\_pixdiff\_inst\_vs\_swref & 
    fraction of differing pixels vs reference & \texttt{diff pixels reference}  & fraction of pixels that differ between $t$ and the reference image  & \\
    %frac\_pixdiff\_inst\_vs\_stable& 
    fraction of differing pixels vs previous time & \texttt{diff pixels instant}
    & fraction of pixels that differ between $t$ and $t-1$ &\\
    %frac\_attack\_changes& 
    fraction of attack changes & \texttt{attack fraction} & \makecell{fraction of pixel changes whose color \\does not fit that of the reference image} &\\
    %n\_changes\_norm& 
    number of pixel changes & \texttt{n changes} &\makecell{number of pixel changes, \\normalized by time step size and image active area}&\checkmark\\
    %instability\_meantopdecile & 
    instability for top decile &\texttt{instability top} & \makecell{fraction of time step spent in non-mode colors, averaged over \\the decile of pixels with highest values, normalized by time step size} %The diversity in colors of pixels within a time interval
    \\
    %variance\_frac\_pixdiff\_inst & 
    variance of diff pixels instantaneous & \texttt{variance} & \makecell{variance of the \textit{diff pixels instantaneous} variable \\over last ten time steps: burstiness of image activity} & \checkmark \\
%n\_colors\_mean& 
number of colors per pixel & \texttt{n colors} & average number of colors shown by a pixel within this time step \\
%n\_colors\_meantopdecile& 
number of colors per top decile pixel &\texttt{n colors top} &\makecell{number of colors shown by a pixel within this time step, \\averaged over the decile of pixels with highest values}&\checkmark\\
%Autocorr\_bycase & 
change of autocorrelation case by case & \texttt{autocorr by case} & \makecell{autocorrelation comparing the colors that are both different from \\the reference between $t$ and $t-1$, minus its sliding window average} \\
%Autocorr\_subdom& 
autocorrelation from non-mode product & \texttt{autocorr non-mode} & \makecell{autocorrelation comparing within-time-step deviations \\to the mode color between $t$ and $t-1$} \\
%Returntime\_mean& 
duration of last attack & \texttt{attack duration} & \makecell{average duration for which \\pixels showed their most recent non-reference color} &\checkmark\\
%returntime\_meantopdecile& 
duration of last attack for top decile & \texttt{attack duration top} &\makecell{duration for which pixels showed their latest non-reference \\color, averaged over the decile of pixels with highest values}& \checkmark\\
%Returnrate& 
return rate&\texttt{return rate} & \makecell{average fraction of pixels in non-reference colors at $t-1$ \\that returned to the reference at $t$}
%Value 1: there were no attack colors at t-1
%Values 0 and 1 correspond to very small n\_changes.
%So high return times >2500 (low n\_changes) have only returnrate values 0 and 1.
%The evolution of return rate can only be compared to returntim<2500
&\\
%n\_users\_sw&
number of users in sliding window & \texttt{n users sw} & \makecell{number of active users in the past sliding window \\normalized by time step size and image active area} &\checkmark\\
%changes\_per\_user\_sw& 
changes per user in sliding window&\texttt{changes/user sw} & \makecell{number of changes per user, averaged over the past sliding window}&\checkmark\\
%frac\_new\_users\_vs\_sw& 
fraction of new users vs sliding window& \texttt{new users} & fraction of users that were not active in the past sliding window &\\
%frac\_redundant\_changes&
fraction of redundant changes & \texttt{redundant changes} & fraction of pixel changes that repeat the existing color &\\
%Entropy&
change of entropy vs sliding window & \texttt{entropy change}& image entropy divided by its sliding window average &\\
%Fractal\_dimension&
change of fractal dimension vs sw &\texttt{fractal dim change}&image fractal dimension divided by its sliding window average&\\
\hline
\multicolumn{4}{l}{\textit{Without memory}}\\
\hline
%log(area)& 
active area & \texttt{area} &logarithm of the number of pixels in the active image&--\\
%age& 
age from Atlas birth & \texttt{age}& time from the composition birth from the Atlas &--\\
%entropy\_sw& 
entropy in sliding window &\texttt{entropy}& \makecell{entropy of the image, normalized via the max and min entropy \\of an image of this area and averaged over past sliding window} &--\\
%canvas\_quadrant& 
canvas quadrant &\texttt{canvas quadrant}& canvas expansion number for this part of the canvas &--\\
%border\_corner\_center& 
special canvas position &\texttt{border corner center}& \makecell{if the composition is placed close to \\a border, a corner, or a center of the canvas} &--
\end{tabular}

\vspace{3mm}
    \caption{Variables used in the training. The short name is that used in figures and in the text when referring to this exact variable. The last column is checked for variables whose memory is recorded in 9 rather than 12 time range features.}
    \label{tabSI:variables}
\end{table}


\begin{figure}[p]%[h!]
\includegraphics{figures/SI_figures/SI_correlations.png}
\centering
\caption{Correlation coefficients between all training variables and the  time-to-transition, over all time instances used in the training.}
\label{figSI:correlations}
\end{figure}

\section{Data preparation and training of the machine learning algorithm}

We use the variables listed in the previous section computed for all compositions and time steps as input for training a gradient-boosted decision trees algorithm to predict the time-to-transition \ttt.

\subsection{Memory of time series embedded in the features}
\label{secSI:memory}

Many time series prediction algorithms train on values of the variables in the latest or the few latest time steps. However, we reach higher performance by considering a significant memory preceding each time instance. We choose to record a 7-hour memory for all time instances, using 9 to 12 scalar features per variable. This applies to the first 19 time series variables listed in Table~\ref{tabSI:variables}; the last 5 variables depend only trivially on time, so only the value at the time instance is used. 

Keeping the information about all 5-minute time steps in the 7-hour memory would result in 85 features per variable and high correlation among features; this would make the training much longer for a performance that might be similar, or worse, due to overfitting on non-discriminant features. Therefore, we use features that each correspond to the average over a time range within the 7-hour memory, with exact coverage of the memory by all features. Table~\ref{tabSI:timeranges} lists the time range covered by each feature, both in absolute time and in the number of time steps over which the variable is averaged. 
A finer resolution of time ranges is used for the more recent past, as more information about an incoming transition is expected there; features further in the past encode typical variable values in this composition, while the recent features describe more dynamical aspects---for example, a recent increase of this variable compared to its typical value.

To reduce the number of highly correlated variables, we use 9 coarser time features, rather than 12, for 7 of the 19 dynamic variables that evolve more slowly. Variables that include an average over the sliding window tend to show slower changes, such as \texttt{n users sw} or \texttt{attack duration}. We also use coarse time ranges for variables significantly correlated with other variables, such as \texttt{n changes} and \texttt{variance}. The last column of Table~\ref{tabSI:variables} specifies the time range features  used for coarse and non-coarse variables.

\begin{table}[h!]
    \centering
    \begin{tabular}{Sc|c|c|c|c}
    \makecell{\textbf{Time steps}\\ \textbf{to integrate}} &
    \makecell{\textbf{Integrated}\\ \textbf{time range}} & 
    \makecell{\textbf{Name for figures}\\\textbf{(average)}} & \makecell{\textbf{coarse} \\\textbf{time ranges?}} & \makecell{\textbf{non-coarse} \\\textbf{time ranges?}}  \\
    \hline
         0& 0--5~min& -- &\checkmark & \checkmark\\
         1& 5--10~min& 5~min & & \checkmark\\
         3-1& 5--20~min& 10~min &\checkmark & \\
         3-2& 10--20~min& 15~min & & \checkmark\\
         5-4& 20--30~min& 25~min & & \checkmark\\
         7-4& 20--40~min& 30~min &\checkmark & \\
         8-6& 30--45~min& 35~min & & \checkmark\\
         12-9& 45--65~min& 55~min & & \checkmark\\
         13-8& 40--70~min& 55~min &\checkmark & \\
         17-13& 1h5--1h30& 1.25~h & & \checkmark\\
         24-14& 1h10--2h05& 1.5~h &\checkmark & \\
         24-18& 1h30--2h05& 1.75~h & & \checkmark\\
         39-25& 2h05--3h20& 2.7~h %2h40
         &\checkmark & \checkmark\\
         54-40& 3h20--4h35& 3.9~h %3h55
         &\checkmark & \checkmark\\
         69-55& 4h35--5h50& 5.2~h %5hr10
         &\checkmark & \checkmark\\
         84-70& 5h50--7h05& 6.4~h %6hr25 
         &\checkmark & \checkmark
    \end{tabular}
    
    \vspace{3mm}
    \caption{Time ranges of the memory stored for each feature and time instance. Larger times correspond to earlier times in the memory. The central column is the midpoint of the time range, which is used as shortcuts in figures. The last two columns indicate whether a given time range feature is used for coarse or non-coarse variables, which are listed in Table~\ref{tabSI:variables}.}
    \label{tabSI:timeranges}
\end{table}

\subsection{Filtering of training dataset}
\label{secSI:filter}

To circumvent some data limitations, we filter the time instances that are kept in the training and testing dataset:
\begin{itemize}[noitemsep]
    \item As explained in the main text, instances must be preceded by a 3-hour stable period that fulfills our stability requirement for transitions.
    \item Some variables compute information over the 3-hour past sliding window. We require the time instance to be at least a sliding window width after the birth of the Atlas composition, ensuring variables are computed using information only from after the composition birth. As explained in the main text and in section~\ref{secSI:transitions}, this excludes transitions from a patchwork into an Atlas composition; we choose to reject these areas that would not be monitored beforehand. Also note that this requirement allows for an overlap of the 7-hour memory with times preceding the birth of the composition; knowledge of a recent transition into the current composition could help predictions, without being unrealistic in real-world applications.
    \item The memory should not overlap with significant changes in the borders of the image as it would result in artificial jumps in some variables. Therefore, the time instance should be at least 7 hours after the start of a stable area time range. We use a margin of 10 hours rather than 7 hours so that the 3-hour sliding window of variables evaluated 7 hours ago does not overlap with a change of image borders. A stable area time range cannot start before the opening of this canvas region.
    \item The time instance should precede the restrictions to grayscale or white colors (see Table~\ref{tabSI:extensions}) and the end of the composition as indicated in the Atlas. A 1-hour margin after the Atlas death is given when a transition is identified after the Atlas death.
    \item Transition periods are excluded: the time instance must not fall within a sliding window width after the start of a transition. In addition, \texttt{diff pixels reference} must not exceed transition thresholds, meaning its absolute and relative values should not both exceed 0.35 and 6, respectively. 
    \item Finally, to prevent near-duplicate instances in the training data, we do not include multiple time instances describing similar compositions at the same time. Using only the Atlas information on all compositions, we compile a list of compositions and times to reject. When two compositions have a spatial overlap exceeding 90\% and share some time steps, we exclude these time steps for the composition with the later Atlas birth. 
\end{itemize}
This results in 1.53 million instances in 2022 and 1.34 million in 2023.

\subsection{Feature selection}
\label{secSI:featureselec}


The gradient-boosted decision trees algorithm can be overtrained and perform worse when many highly correlated features are included for each instance. As a simple example, let us consider two identical (100\% correlated) features in the training: half of its predictive information will be extracted by the algorithm from the first feature, and half from the second. This would reduce the statistical significance of an extracted predictive property, which could drive its importance measure below the noise threshold and therefore make it indistinguishable from fluctuations of the training dataset. 

Pruning the input features is therefore key to reliable predictions. We perform this in two main steps: we first select the time series variables to keep in the training, then reject the lowest-performance time features. As explained in section~\ref{secSI:varselect}, our pruning criteria rely both on the correlations between variables (see Fig.~\ref{figSI:correlations}) and on the mean absolute SHAP values for each variable or feature (see Fig.~\ref{figSI:shapdistr}). 

The SHAPley additive values estimate for each instance how much each input feature changes the predicted target value (defined in section~\ref{secSI:target} as a transformation of the time-to-transition). A high absolute SHAP value hence indicates that this feature significantly affects the prediction for this instance. Therefore, the average of these absolute SHAP values over instances measures the importance of this feature in the prediction. When using this measure for a 
time series variable, we first arithmetically sum the SHAP values for each of its time features, representing the total effect of this variable on the predictions. The distribution of SHAP values over instances for each variable in Fig.~\ref{figSI:shapdistr} gives insight into how different variables contribute to the algorithm. Variables are ordered by the mean absolute SHAP so that the variables higher in the figure are the higher-performance ones; this ordering is used to isolate the variables with lowest mean absolute SHAP. 
Variable pairs with correlation coefficients above 0.9 were rejected by removing the variable with lowest mean absolute SHAP. Some variables with lower correlations than others but very low mean absolute SHAP were also removed. This pruning was performed by running preliminary versions of the training, the first one containing all the variables defined in section~\ref{secSI:variables}.


The 19 time series variables with 9 to 12 time features plus the 5 memory-less variables result in 212 features. At a late stage of algorithm tuning, we remove the 40 features with the lowest mean absolute SHAP, obtaining 172 final features. We determine these features in steps of 10 features, to account for the transfer of predictive power to non-rejected features that are correlated with rejected ones. At each step, we remove the 10 lowest-performing features, then rerun the algorithm; then we use the algorithm's results to find the next 10 features to remove. When we observe a significant decrease in our multiple performance evaluation criteria (see section~\ref{secSI:testing}), we stop the procedure and revert the last removal.

\subsection{Target value, weights and loss term}
\label{secSI:target}

The goal of the algorithm is to predict \ttt, the time to the next transition. However, we expect predictive power only up to a few hours before a transition, whereas \ttt could be as long as the duration of the experiment or be undefined where there are no identified transitions in that composition. Therefore, we make some structural decisions aimed at reducing the importance of higher \ttttr values. These decisions each bring important performance improvements.

First, \ttt is set to 12 hours when there is no future transition or when it is more than 12 hours away. Next, the target value we set to predict for each instance is not exactly \ttt, but 
$$\tfour = \log_{10}(100\xspace\textrm{ s} + \ttt) - 1.5$$
where \ttt is counted in seconds. Adding the 100 seconds in the logarithm prevents its argument from approaching 0, while maintaining a sufficient resolution of a third of a time step. Incorporating the logarithm favors the precision of predictions in lower \ttt values, as we do not expect generalizable properties that can discriminate \ttt values larger than a few hours. 

We then give lower weights to instances with a high \tfour. The weight is set to $1$ for $\ttttr<3$h, 0.4 for $\ttttr\geq12$h, and interpolated with a power law between these two values for the \ttttr values in between. 

Finally, we implement a preference for relative rather than absolute deviations in the algorithm minimization itself. The squared \textit{relative} deviation between the true and expected values rather than the more standard squared \textit{absolute} deviation is used as the loss term of the objective function for each instance in the objective function that is minimized in the training. 
The introduction of $-1.5$ in the above definition of \tfour is a last element favoring lower \ttt values, as the proximity of lower \ttt values to zero amplifies their arithmetic deviations when comparing them geometrically. 


\subsection{Algorithm setup, training, and hyperparameters}
\label{secSI:algo}

The input dataset must now be split into a training and a testing sample. When training and testing on 2022 data, 
we randomly select compositions for the training dataset that amount to 80\% of time instances and attribute the rest to the testing dataset. This ensures, as is standard, that the trained trees have no prior knowledge of the instances they are evaluated on, but also that no correlations across time within a given composition can be exploited by the training. In real-world scenarios, this precaution means that warning systems are trained on certain subsystems but must make predictions for entirely new ones. When testing on the 2023 data, the full 2022 data is used in the training. 

We then train gradient-boosted decision trees using XGBoost 1.7.5.~\cite{chenXGBoostScalableTree2016} in Python. The hyperparameters of the trained models directly impact the algorithm performance. They were loosely optimized on the test sample. The optimization criteria, based on the areas under the ROC and PR curves explained in section~\ref{secSI:ROCPR}, are the PR area for the $\ttt<1$~h and $\ttt<3$~h binary targets, the ROC area for the 1-hour target, and the ROC area at false positive rate less than 0.2, for the 1-hour and 3-hour targets. 

No independent validation sample was kept apart for the hyperparameter optimization, to avoid reducing the data available for training or testing. Instead, the random seed for selecting the training and testing samples was modified at a very late stage of the analysis, thereby breaking any excessive optimization on the evaluation of a specific testing sample. We also do not perform an extensive automated search in hyperparameter space, to avoid fluctuations in performance evaluations from being interpreted as genuine improvements in hyperparameters. Lastly, other design choices for the training data and algorithm significantly affect performance more than fine-tuning the hyperparameters.

Some of the hyperparameters add complexity in the trained model to minimize the loss term of the objective function, while others regularize the model to reduce overtraining. In the first category, we use a maximum tree depth (\texttt{max\_depth}) of 8, and 160 trees (\textit{a.k.a.} rounds, \texttt{num\_boost\_round}) in 2022 (100 trees when testing on 2023). In the second category, the learning rate (\texttt{learning\_rate}) is 0.035; the minimum summed weight in an end node of a tree (\texttt{min\_child\_weight}) is 8; the sub-sampling ratio of the instances (\texttt{subsample}) is 0.8 at each round; and the sub-sampling ratio of the features is 0.75 both at each round (\texttt{colsample\_bytree}) and at each tree level (\texttt{colsample\_level}). Other XGBoost parameters are kept at their default values. We also consider the weight of high true \tfour instances, 0.4, as a hyperparameter to optimize on.

\section{Testing and performance evaluation}
\label{secSI:testing}

\subsection{Calibration of model output}
\label{secSI:calib}
The actual predictive power of the algorithm lies only in the ranking of instances according to their predicted \tfour value. However, the typical values of the predicted target can be offset or scaled compared to true target values, and depend on irrelevant algorithm details and parameter choices. 


Therefore, we use the predicted and true \tfour values in the testing set to calibrate the output of the algorithm. No optimization is performed on the chosen calibration method, so there is no bias introduced by using the testing set. For the calibration, we first keep only the instances with $\tttpr< 3600~\textrm{s} + 3.5 \, \ttttr $. 
This rejects low $\ttttr$ instances that have high $\tttpr$, which are clear false negatives (undetected signal) that would excessively drive up the calibrated predictions. Then we perform a fit  in the $(\tfour_{\textrm{true}}, \tfour_{\textrm{predicted}})$ logarithmic space. We compute the median value of $\tfour_{\textrm{predicted}}$ versus $\tfour_{\textrm{true}}$, that we fit 
to continuous piecewise linear function with one breakpoint. This function has start and end points fixed at $(\ttttr, \tttpr) = (0,0)$ and $(12~\textrm{h},\, 20~\textrm{h})$. The fitted piecewise function is the calibration function, whose inverse is applied to the predicted \ttt shown in the evaluation results.

\subsection{ROC and PR curves}
\label{secSI:ROCPR}
The evaluation of the performance of an algorithm on a testing sample is usually reduced to quantities relating to a binary classification into signal and background instances, which is why we convert our results into binary warning systems of various \ttt warning ranges as explained in the main text. This allows us to count the true and false positives and negatives. The true (false) positive rate is the fraction of signal instances---those with $\ttttr$ inside the warning range---that have $\tttpr$ below (above) the set tolerance on predicted values. The precision, also known as purity, is the fraction of identified warnings that are true positives---in other words, the number of true positives divided by the total number of positives.

The receiver operator characteristic (ROC) curve shows the true positive rate versus the false positive rate. For a random classification, it follows the diagonal of the unit square of the plot and the area under the ROC curve equals 0.5, while it equals 1 for a perfect classification. The precision-recall (PR) curve shows the precision as a function of the true positive rate, also known as the the recall. It also equals 1 for a perfect classification, but specifies the fraction of signal in the sample, which, for example, is 0.3\% for a warning range of $20$~min. The ROC curves and areas under them are plotted for four warning ranges (20~min, 1h, 3h, and 6h) in Fig.~\ref{figSI:ROC}a, while the PR curves and areas under them for the same thresholds are plotted in Fig.~\ref{figSI:PR}.

\begin{figure}[h!]
\includegraphics{figures/SI_figures/SI_roc_eval.png}
\centering
\caption{\textbf{(a)} ROC curves for our machine learning algorithm trained and tested on 2022 r/place data (dark blue) and for a standard single-variable warning signal of variance (light blue), for four different warning ranges. \textbf{(b)} Histogram of areas under the ROC curves for time instances grouped by composition, for warning ranges of $20$~min (blue) and $1$~h (purple)}
\label{figSI:ROC}
\end{figure}

\begin{figure}[p]%[h!]
\includegraphics{figures/SI_figures/ml_eval_PR.png}
\centering
\caption{\textbf{(a)} Precision-Recall (PR) curves for our machine learning algorithm trained and tested on 2022 r/place data (dark blue) and for a standard single-variable warning signal of variance (light blue), at four different time thresholds for warnings. \textbf{(b)} Area under the PR curves as a function of warning threshold time for the machine learning warning signal (dark blue), a standard single-variable warning signal of variance (light blue), and for the machine learning warning signal tested on 2023 r/place data (red).}
\label{figSI:PR}
\end{figure}

When using such a warning system in practice, a system manager would set a threshold on the $\tttpr$ values under which a warning is issued. This corresponds to a certain point on the ROC and PR curves, meaning that modifying this threshold is a direct trade-off between the true and false positive rates desired by the system manager.

\subsection{Per-composition results} 
\label{secSI:percompo}

We also compute binary warning signals for individual transitions of individual compositions in the 2022 test data. A time instance is signal if it falls within the warning range of a transition. Note that only time sequences preceding a transition are considered so that there are possible true warnings, thereby excluding 
compositions with no transitions. To have sufficient precision, we keep only the 139 transitions with at least 30 time instances outside the warning range and 4 instances within it. There can be multiple transitions considered in a single composition. The distribution of ROC AUC values for each of these compositions is shown in Fig.~\ref{figSI:ROC}b.

This per-composition perspective is valuable when a warning system can be tested beforehand, allowing the threshold on the predicted quantity to be tuned to achieve the desired trade-off between true and false rates. However, it might be necessary to set a threshold before encountering a new system within the studied class of systems. Therefore, we also computed, at a given threshold on the predicted \ttt, the time of the first warning for each transition versus the false positive rate for all compositions, in a similar manner as for the ROC curve. This allows a system manager to estimate how early a transition can typically be warned for, versus the acceptable false positive rate.
%Fig.~\ref{fig:per-composition}b shows how early the first warning (followed by a continuous warning until the transition) for each transition occurred, compared to the false positive rate (of time instances) of all  \textit{compositions} (including those without transitions) at the same threshold on the predicted \ttt. We show the median of these two quantities among all transitions or compositions, and bands using their 10th, 30th, 70th and 90th percentiles. To get a first warning time of 1000s on the median composition, one would endure a 0.1 false positive rate on time instances of all compositions -- though the 10\% transitions that are easiest to predict would all have a first warning time above 8000s.

\subsection{cooldown warning system}
\label{secSI:cooldownWarn}
We also considered a warning system based on a cooldown, rather than considering each time instance separately, closer to the method of Ref.~\citenum{hylandEarlyPredictionCirculatory2020} and arguably closer to a real-world system management strategy. We then evaluate a ROC curve equivalent for this system for various warning ranges. There is no one-fits-all choice in the method, which must ultimately correspond to the need of a manager with respect to a specific system. For a certain warning range, we choose to count each true positive as the ratio of how early the transition was warned for (considering only warnings that are within the warning range, as premature warnings are false positives) to the width of the warning range; to calculate the rate, the sum of these scores is divided by the number of transitions. A false positive is a warning outside of the warning range preceding a transition, when this warning is not preceded by another warning closer than a warning range width; in the rate, the count is divided by the maximum number of false warnings (close to the cumulative time of all compositions divided by the warning range width). 

We show in Fig.~\ref{figSI:continuous-warn} the resulting curves; note that they are not strictly ROC curves due to our definition of the true warning score. They perform worse than our original warning system, which is expected as it is a harder task than predicting the time-to-transition for single time steps; however, we still obtain significant predictive power for the 20-minute warning range.
The same 139 pre-transition periods as in section~\ref{secSI:percompo} are used for the true positive rate, while the 227 compositions from the 2022 testing sample with more than 30 background instances are used to compute the false positive rate.

\subsection{Sensitivity analysis of parameter values}
\label{secSI:sensitivity}
Some parameters are of structural importance to this work: the width of the sliding window, used notably in defining the reference image and for obtaining typical values of time series in the past; and the relative and absolute thresholds on \texttt{diff pixels reference} for defining transitions, which determine how much sudden change in the images can qualify as transitions. Here, we check that our main results, in particular the quality of the predictions of our machine-learning algorithm, hold when varying the values of these parameters. The whole analysis is fully rerun with 6 variations of these parameters. The actual transitions and their predictions will inevitably differ, but our ability to successfully predict these incoming transitions should remain mostly unchanged.

This sensitivity study is shown in Fig.~\ref{figSI:sensitivity}, with sliding windows of 2 and 4 hours, absolute transition thresholds 0.25 and 0.45, and relative transition thresholds 4.5 and 7.5. The variations of the ROC curves for the 6 parameter variations compared to the nominal parameter values are small. The only identifiable pattern is that for variations where both absolute and relative thresholds are lower, the performance is significantly higher, and performance is lower for higher thresholds. This is easily understood as lower (less strict) thresholds result in a higher number of transitions in the sample, while the limited number of time instances near a transition is a clear factor restricting algorithm performance.

\begin{figure}
\includegraphics{figures/SI_figures/ml_eval_sens_ROC.png}
\centering
\caption{Performance varies only marginally with transition detection parameters and sliding window width. For both panels: combinations of values of sliding window reference width, absolute threshold, and relative threshold for transition detection are shown in different colors according to the legend. The nominal value chosen in the main text is shown in dark purple. \textbf{(a)} Receiver operating characteristic (ROC) curves for our machine learning algorithm trained and tested on 2022 r/place data, for the different parameter combinations at four different time thresholds for warnings. \textbf{(b)} Area under the ROC curves for our machine learning warning signal for the different parameter combinations as a function of the warning threshold time.}
\label{figSI:sensitivity}
\end{figure}

\begin{figure}[h!]
\includegraphics[height=0.95\textheight]{figures/SI_figures/shap_distributions.png}
\centering
\caption{Probability density distributions of SHAP values over time instances for each variable, calculated using kernel density estimation. The SHAP for a variable is the sum of the SHAP values of all time features associated with this variable. Variables are ordered according to the mean of the absolute values of the SHAP values.}
\label{figSI:shapdistr}
\end{figure}

\section{Interpretation of predictions}
\subsection{SHAP trends}
\label{secSI:shap}
To uncover the set of 12 pre-transition behaviors from the set of 172 SHAP percentile curves, we systematically go through a series of steps. First, we classify variables based on the aspect of composition dynamics that they describe. These categories are: strength of the attack or defense changes, image activity---which is related to the variance in the framework of critical slowing down---, user activity and engagement, image complexity, innovation, and coordination versus noise. Many variables fit into multiple categories. 
We then look for trends shared by multiple time features of variables in a given category. We often consider trends at only at high or low variable values to be distinct. We also separate the trends of recent time features from those of time features in the past memory. Finally, we assign an interpretation to each of these shared trends based on our knowledge of the game rules and system dynamics. This leads to 12 interpretative messages, each associated to a group of time features that describe similar dynamics. These behaviors are shown in Fig.~6 %\ref{fig:shap}
of the main text and Fig.~\ref{figSI:SHAPinterp}. For clarity, we show maximum one past and one recent time feature per variable for a given behavior, even when more features show the same trend.

Despite our systematic approach, these interpretations are still quite qualitative. There are contradictory interpretations of the variables and trends we observe. We discuss some of these potential contradictions below and provide further reasoning for why we present our chosen interpretations rather than alternatives. 
We also explain how we relied only on trends that were robust against our requirement of stability before transitions, which could affect what the algorithm identifies as warning signs. 


\paragraph{Contradictory variable interpretations.}
One prominent example of an ambiguous variable interpretation is in distinguishing innovations versus attacks. In our system, there is no sure way to identify whether a pixel change that does not match the reference image is an attack on the image, or an innovation that will eventually be adopted into the image by the defending community. We therefore must use context to interpret whether a trend in variables that can track either innovations or attacks represents one or the other. For instance, in Fig.~6%\ref{fig:shap}
d of the main text, we present a series of features that decrease as a predicted transition nears. These features are both recent and past time features, and the variables they originate from could be interpreted as either attacks or innovations. We conclude that if a recent time feature of such a variable decreases as a transition comes closer, it is most likely picking up on a decrease in innovations rather than a decrease in attacks. An increase in attacks would indeed be necessary for a transition to take place. Another argument for this interpretation is that the \texttt{attack duration} variable computes how long attack pixels stay in the image over a timescale longer than a typical attack, so it does capture what changes are approved by the defense.

For past time features, however, a lower attacking force could signal a coming transition (Fig.~\ref{figSI:SHAPinterp}c). If a composition is sufficiently neglected by defenders as well as attackers, it may signify that the composition is of low interest to its own community, which means it would be an easy target for an attack. Interestingly, a low past \texttt{attack duration} could signal either attacker neglect or a lack of image innovation; both are reasonable interpretations, so we classify past time-feature SHAP curves for this variable in both messages, rather than choosing a single interpretation. 

\paragraph{Contradictory trend interpretations.}
In some cases, the contradictory interpretations come not from interpreting what the 
feature and its associated variable represent, but from opposite trends in the same feature being both associated to a coming transition. For instance, we find that both low past activity and increased past activity can be transition signals (Fig.~\ref{figSI:SHAPinterp}c and f). However, these  seemingly contradictory signals can take place in different regimes of the feature values. For instance, the curve labeled ``\texttt{n changes} 2.7 h ago'', present in both Fig.~\ref{figSI:SHAPinterp}c and f, shows that an increase from a very low percentile value brings a predicted transition closer, but increasing from a mid-range value to very high value pushes the transition further. In this way, both positive and negative changes in activity level can signal a coming transition, depending on the activity level at which they start. Also note that these two contradictory signals can exist in different compositions, meaning that they do not necessarily appear together in the same subsystem.


\paragraph{Robustness versus stability requirement and prediction quality.}

We manually extract the trends that are significant in the SHAP curve of each feature. To verify the robustness of these trends, we run our pipeline with integer values from 1 to 6 for the relative threshold on \texttt{diff pixels reference} with which transitions are defined; we consider and discuss only the trends that hold when changing our fundamental definition of transitions. These tests ensure that the mentioned trends do not depend on the requirement of a stable period before the transition. We do see a substantial critical speeding up signal in the most recent feature of activity-related variables only at large relative thresholds, which we interpret as an artifact of the required pre-transition stable period: even though we consider only time instances whose preceding period is sufficiently stable on average (see section~\ref{secSI:filter}), the necessary onset of the increase of activity right before transition can be slightly compensated by lower activity before this onset. This could increase the frequency of decreasing trends---meaning speeding up---in these variables before a transition. However, there is still a mild critical speeding up signal, in particular in features 30 to 60 minutes before the time instance, as shown in Fig.~6c; these trends are robust against changes of the relative transition threshold. 

Another possible concern could be that the SHAP values originate from predictions that are not perfect. However, the algorithm still picks up on these trends to make better-than-random predictions, meaning that these trends hold at least part of the true dynamics of the pre-transition periods. Testing that the trends hold when varying the transition threshold is also a strong evidence that these trends are not overfitting artifacts.

\paragraph{Drawbacks of SHAP.}
First, SHAP assumes feature independence; our variables have significant correlations, but we controlled their magnitude using feature and variable pruning (see section~\ref{secSI:featureselec}). The power of a variable, quantified by its SHAP values, can then be split between correlated variables, affecting the magnitude of the effects shown in Fig.~6 %\ref{fig:shap}
of the main text and Fig.~\ref{figSI:SHAPinterp}. Second, SHAP values explain the algorithm's behavior as learned from the data, meaning that if the algorithm is overfitting, the explanations could reflect fluctuations of the training data rather than general patterns. 

\subsection{Toy model of canvas}
\label{secSI:toymodel}
Variables related to critical slowing down may be ambiguous in our system, as explained in section~\ref{secSI:variables}, and their dynamics close to transition can depend on modeling choices and on the type of transition. In addition, these variables often do not slow down close to a transition outside the context of small perturbations around a well-defined equilibrium, and they sometimes behave in ways that seem to contradict each other. We design a toy model of hypothetical dynamics of a composition on the canvas to illustrate the plausibility of such difficulties in our system.

The model consists of a two-dimensional differential equation system describing the fraction $f(t)$ of pixels differing from a \textit{fixed} (and not sliding as in our system) reference image, as well as the change in the number $n(t)$ of users defending the reference image:
\begin{eqnarray}
\frac{\textrm{d}f}{\textrm{d}t} &=& - r \, n(t) \frac{f(t)}{f(t)+f_m} + A (1-f(t)^{\beta}) \, \, ,\\
\frac{\textrm{d}n}{\textrm{d}t} &=& R ( f(t) - f(t)^{\alpha} ) - L \, \frac{n(t)}{n(t)+n_0} \, \, .    % gamma is set to 1 on the first f(t)^gamma term
\end{eqnarray}
The first term of $\frac{\textrm{d}f}{\textrm{d}t}$ is the decrease of the image differences from the defense users restoring the image their community aims for; $r$ is the rate of pixel changes per defense user, and $f_m$ is a small threshold below which users are not alarmed and do not make efforts to reduce the image differences. The second term represents the attacks on the image at rate $A$. These attacks decrease with the number of pixels available to attack, with exponent $\beta=1$ for indiscriminate attacks uniformly distributed on the canvas, and $\beta\gg1$ for more targeted attacks that aim at fully replacing a composition. The first term of $\frac{\textrm{d}n}{\textrm{d}t}$ represents the recruitment of users when the community is alarmed by large changes in the image, including a desertion term $- f(t)^{\alpha}$ when $f(t)$ is too close to $1$; $R$ is the recruitment rate; the exponent $\alpha$, constrained by $\alpha>1$, denotes how late the community switches from recruitment to abandonment, with higher values signifying a community remaining engaged until the image is nearly completely replaced. The motivation behind this recruitment term is to obtain an \textit{increase} of defense activity and return rate when the system approaches transition, rather than a critical slowing down. The last term of $\frac{\textrm{d}n}{\textrm{d}t}$ is a slow loss of users  as they gradually lose interest in the composition; $L$ is the rate of user loss and $n_0$ is the number of users in a core community that do not leave with time.

Using time units of minutes, we fix the following parameters: $\alpha=4$; $\beta=10$; $r=10^{-4}$ for the fraction of the image changed per user per minute, which corresponds to one pixel change per 5-minute interval in a 2000-pixel composition; $n_0=10$ users;  $f_m=0.01$; and $L=20$ users lost per minute when $f=0$. We consider the attack rate $A$ and the defense strength $R/L$ as two possible order parameters governing transitions of the composition from $f=0$ to $f=1$.

We then scan the equilibrium values, the return rate from an instantaneous perturbation 
(probed as a single small modification of $f(t)$), and the variance of $f(t)$ when a small Gaussian noise is applied to it, over $A$ and $R/L$ values. It should be noted that the variance is computed around the equilibrium value of $f(t)$, whereas in our system, we can only directly measure deviations from $f(t)=0$, which is how some of our variance variables are computed. Effectively taking the equilibrium to be zero would mean the equilibrium cannot evolve to differ from the long-term reference image. This is a possible source of confusion when comparing our r/place system to this model, and underscores the difficulty of defining appropriate variance, return rate, and state variables in a high-dimensional system.

When slowly decreasing $R/L$, so that $f(t)$ always follows its non-zero equilibrium, a second-order critical transition is reached: the equilibrium smoothly yet rapidly reaches $f=1$. In this case, we find a decreased return rate and increased variance, as the standard critical slowing down predicts. 

When we instead slowly increase $A$ from a low $f(t)$ equilibrium, the user recruitment adapts accordingly and always compensates for the increased attack; there is no bifurcation and the equilibrium of $f$ never reaches $1$. However, if $A$ undergoes a sudden increase, the number of users $n(t)$ fails to catch up fast enough and the defense fails, causing a rapid transition to $f=1$. This is a textbook example of rate-induced tipping~\cite{ritchieEarlywarningIndicatorsRateinduced2016}. The parameter space where tipping takes place, of course, depends on the initial value of $f$, and on the rate of increase of $A$ and its initial and final value, but the qualitative conclusions remain: the return rate increases because the number of users does. The variance decreases accordingly, when calculated on $f(t)$ itself over a short sliding window, that is, using the sample mean; however, the variance can increase when calculated based on deviations from the equilibrium or from zero, as $f(t)$ is drastically separating from that equilibrium. This can result in confusion as to how to interpret the contradictory behavior of such variables in terms of critical slowing down. This issue is even more pronounced when the variance is defined as deviations from $0$, as is the case in a few definitions of the variance in our system: the equivalent of the state variable $f(t)$ is then positively correlated with the variance, which therefore increases while the return rate also increases---resulting in contradictory critical slowing down interpretations.


%%% Each figure should be on its own page
\begin{figure}[!htb]
\includegraphics{figures/SI_figures/SI_shap_values_all_timefeat.png}
\centering
\caption{All SHAP curves for each time-dependent variable and corresponding time features. Plots show the variable percentile against the mean SHAP value across time instances. Plot limits were chosen to show detail at smaller values. The legend identifies time features using color.}
\label{figSI:SHAPall}
\end{figure}

\begin{figure}[!htb]
\includegraphics{figures/SI_figures/SI_shap_no_time.png}
\centering
\caption{SHAP curves for the variables that are recorded without memory. The variable percentile is plotted on the y-axis for \texttt{area}, \texttt{age} and \texttt{entropy}. The raw variable is plotted for \texttt{border corner center} and \texttt{canvas quadrant} since these two variables span only three distinct values.}
\label{figSI:SHAPnotime}

\bigskip
\bigskip
\bigskip
\bigskip

\includegraphics{figures/SI_figures/continuous_warning_ROC.png}
\centering
\caption{Performance significantly decreases when using a cooldown warning system. Plots show receiver operating characteristic (ROC) curves for our cooldown machine learning warning system as compared to the machine learning warning system presented in the main text. Both warning systems are trained and tested on 2022 r/place data, at three different time thresholds for warnings.}
\label{figSI:continuous-warn}
\end{figure}

\begin{figure}[!htb]
\includegraphics{figures/SI_figures/SI_shap_values_interpretation.png}
\centering
\caption{Additional interpretation of model predictions with SHAP values. \textbf{(a-f)} Feature percentiles versus mean SHAP values, classified based on curve trends into six pre-transition behaviors, which are described in the panel title. Top titles describe the signal of a coming transition, and italicized subtitles provide 
an interpretation of the associated dynamics of users and images of the canvas. 
Grey arrows indicate the qualitative trend of the curves. The text in each legend label describes the curve of the same color as the label's text. 
Curves are drawn thinner when they show a trend that is not the focus of their respective panel.}
\label{figSI:SHAPinterp}
\end{figure}



%%% Add this line AFTER all your figures and tables
\FloatBarrier

%\movie{Type legend for the movie here.}
%\dataset{dataset_two.txt}{Type or paste legend here. Adding longer text to show what happens, to decide on alignment and/or indentations for multi-line or paragraph captions.}

\bibliography{references}

\end{document}
