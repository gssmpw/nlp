@article{amatriain2024prompt,
  title={Prompt design and engineering: Introduction and advanced methods},
  author={Amatriain, X.},
  journal={arXiv},
  year={2024}
}

@article{chang2024efficient,
  title={Efficient Prompting Methods for {LLMs}: A Survey},
  author={Chang, K. and Xu, S. and Wang, C. and Luo, Y. and others},
  journal={arXiv},
  year={2024}
}

@article{gu2023systematic,
  title={A systematic survey of prompt engineering on vision-language foundation models},
  author={Gu, J. and Han, Z. and Chen, S. and Beirami, A. and others},
  journal={arXiv},
  year={2023}
}

@article{li2024prompt,
  title={Prompt Compression for {LLMs}: A Survey},
  author={Li, Z. and Liu, Y. and Su, Y. and Collier, N.},
  journal={arXiv},
  year={2024}
}

@article{liu2023pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, P. and Yuan, W. and Fu, J. and others},
  journal={ACM Computing Surveys},
  year={2023},
  publisher={ACM New York, NY}
}

@article{sahoo2024systematic,
  title={A systematic survey of prompt engineering in {LLMs}: Techniques and applications},
  author={Sahoo, P. and Singh, A. K. and Saha, S. and Jain, V. and others},
  journal={arXiv},
  year={2024}
}

@article{vatsal2024survey,
  title={A survey of prompt engineering methods in {LLMs} for different nlp tasks},
  author={Vatsal, S. and Dubey, H.},
  journal={arXiv},
  year={2024}
}

