\section{Methodology}

In this section, we present our Large Images are Gaussians (LIG) framework. We begin with the basics of 3DGS and its adaptation to 2D spaces. Subsequently, we delve into two primary components of our methodology: 1) the variant of 2DGS representation; 2) the Level-of-Gaussian mechanism; which provide an efficient and high-quality solution for optimizing large images containing numerous Gaussian points.

\subsection{Preliminaries}
\noindent \textbf{3D Gaussian Splatting (3DGS).} 
As proposed by \cite{kerbl20233d}, 3D Gaussian splatting employs a set of 3D Gaussians to represent 3D scenes. Each Gaussian is characterized by its mean
\( \bm x \in \mathbb{R}^{3}\), scale \(\bm s \in \mathbb{R}^{3}\), rotation $\bm r \in \mathbb{R}^{3}$, opacity $\alpha \in \mathbb{R}$, and color $\bm c \in \mathbb{R}^{c}$. Spherical harmonics can be used to further define view-dependent effects. The rendering process involves projecting these 3D Gaussians onto the image plane, resulting in 2D elliptical splats and performing $\alpha$-blending for each pixel in a front-to-back depth order. Compared to neural rendering techniques like Neural Radiance Fields (NeRF)~\cite{mildenhall2021nerf}, 3DGS provides faster rendering and efficient training capabilities.

\noindent \textbf{2D Gaussian Splatting (2DGS).}
In~\cite{zhang2024gaussianimage}, the Gaussians are adapted to 2D spaces and are defined by deduced parameters. We only need to formulate the 2D Gaussian points locating on the fixed plane corresponding to the image. Specifically, each 2D Gaussian can be described by its position $\bm \mu \in \mathbb{R}^{2}$, 2D covariance matrix $\bm \Sigma \in \mathbb{R}^{2\times 2}$, color coefficients $\bm c \in \mathbb{R}^3$, and opacity $o \in \mathbb{R}$. To ensure the positive semi-definite, $\bm \Sigma$ can be decomposed with Cholesky factorization or into a rotation matrix $\bm R \in \mathbb{R}^{2\times 2}$ and scaling matrix $\bm S \in \mathbb{R}^{2\times 2}$ following~\cite{kerbl20233d}, which altogether requires 3 parameter in 2D cases. The $\alpha$-blending, which calculates the color of pixel $i$ via
\begin{equation}
  \begin{aligned}
    \boldsymbol{C}_i = \sum_{n \in \mathcal{N}} \boldsymbol{c}_n \cdot \alpha_n \cdot T_n, \quad T_n = \prod_{m=1}^{n-1} (1 - \alpha_m),
  \end{aligned}
\end{equation}
where $T_n$ represents the accumulated transparency. And $\alpha_n$ is computed with 2D covariance $\boldsymbol{\Sigma}$ and opacity $o_n$:
\begin{equation}
  \begin{aligned}
    \alpha_n = o_n \cdot \exp(-\sigma_n), \quad \sigma_n = \frac{1}{2} \boldsymbol{d}_n^T \boldsymbol{\Sigma}_n^{-1} \boldsymbol{d}_n,
  \end{aligned}
\end{equation} 
where $\boldsymbol{d} \in \mathbb{R}^2$ is the displacement between the pixel center and the projected 2D Gaussian center. Moreover, with the accumulated summation mechanism~\cite{zhang2024gaussianimage}, the opacity can be integrated into the representation of color, resulting in arbitrary-value $\bm c_n' \in \mathbb{R}^3$ to reduce the number of parameters. In total, we have 8 parameters for each 2D Gaussian, with 2 parameters for position, 3 parameters for covariance, 3 parameters for weighted colors. And the color of pixel $i$ is computed as $\boldsymbol{C}_i = \sum_{n \in \mathcal{N}} \boldsymbol{c}_n' \cdot \exp(-\sigma_n).$
Both \cite{zhang2024gaussianimage} and \cite{zhang2024image} employ the 8 parameters formulation. We keep the accumulated summation mechanism and use 8 parameters but only change the representation of the covariance matrix.

\subsection{2D Gaussians Formulation}
We adopt a variant of representation and optimization strategy on 2D Gaussians. Our representation on each point differs only in 2D covariance matrix $\bm \Sigma \in \mathbb{R}^{2\times 2}$. If we decompose this into rotation matrix $\bm R$ and scaling matrix $\bm S$, we have a total of 3 variables. After extensive experiments on exploring the capabilities of 2DGS, we find that optimizing the decomposed parameters can be challenging when the Gaussian points are numerous. Therefore, we opt for optimizing the covariance matrix directly, which also requires 3 parameters considering the symmetry of the covariance matrix. The forward and backward kernel functions in CUDA are accordingly implemented for optimization.

As stated in~\cite{kerbl20233d}, covariance matrices have physical meaning when they are positive semi-definite. Despite that we cannot ensure its positive semi-definite via directly optimizing the upper triangular of the matrix, we can have two important assertions in 2DGS cases. Firstly, the Gaussian points do not necessarily need to retain their physical meaning in image fitting where the representations are considered as the semi-implicit fitters. And the covariance is only used to produce $\sigma_n$ as the weight of the color with an exponential activation. Secondly, we can filter out Gaussian points with covariance matrices that do not obey positive semi-definite in 2D cases. In detail, when computing the color for a certain pixels, removing all $\sigma_n < 0$ can eliminate points with invalid covariance matrices. Consequently, the color changes to 
\begin{equation}
  \begin{aligned}
    \boldsymbol{C}_i = \sum_{n \in \mathcal{N}, \sigma_n > 0} \boldsymbol{c}_n' \cdot \exp(-\sigma_n).
  \end{aligned}
\end{equation}
%
It is guaranteed that for any positive semi-definite matrix with a non-zero determinant, the inverse matrix will also be positive semi-definite, which implies
\begin{equation}
  \begin{aligned}
\boldsymbol{\Sigma}_n \text{ is positive semi-definite, } \boldsymbol{\Sigma}_n^{-1} \text{ exists} \\ \rightarrow \boldsymbol{\Sigma}_n^{-1} \text{ is positive semi-definite} \rightarrow \sigma_n > 0, \forall \boldsymbol{d}_n
  \end{aligned}
\end{equation}
As the contrapositive also holds true, for each pixel, Gaussian points that we filter out are not positive semi-definite.

Yet with the above operation,  we cannot ensure that all covariance matrices producing positive $\sigma$ have physical meanings, since the $\boldsymbol{d}_n$ is drawn from a finite set. Given the nature of the 2D cases, it is straightforward to determine whether a 2D symmetric matrix is positive semi-definite. Matrices without physical meaning can be strictly filtered out if this is a desired feature. We have included the relevant proofs and analysis in Supplementary Material for reference.

\begin{figure}[h]
\centering
\includegraphics[width=1.00\columnwidth]{figures/framework.pdf}
\caption{\textbf{Illustration of our proposed Level-of-Gaussian approach, aiming at fitting large images with two levels of Gaussian points.} In the first stage, we allocate parts of Gaussian points to form $L_0$ Gaussians for learning the low-frequency initialization from the down-sampled image. In the second stage, $L_1$ Gaussians learn the high-frequency details on the difference between the up-sampled estimation and the target. We present the abstract values of the difference and enhance the image for visualization.}
\label{framework}
\end{figure}

\subsection{Levels of 2D Gaussians}
Fig.~\ref{framework} provides an illustration of the Level-of-Gaussian mechanism. The concept of Level of Detail, which refers to the complexity of a 3D model representation, has been widely used in computer graphics. Existing works, which share core principles with our design, employ multi-scale designs for high-resolution signals. For instance, BungeeNeRF~\cite{xiangli2022bungeenerf} develops a progressive NeRF-based model to fit large scenes, while MINER~\cite{saragadam2022miner} opts to use multiple MLPs to fit images at different levels. Our design addresses similar concerns, which can be summarized in two main points: 1) the models for different levels and 2) the target signals at different levels. 

Our objective is to fit large images using levels of Gaussians. Unlike MINER, which employs grid-based MLPs that are sensitive to input coordinates for a fixed resolution, our levels of Gaussians can efficiently splatter all points and remain robust for target resolutions. In contrast to NeRF-based methods that primarily use multi-resolution targets to facilitate the training of MLPs, our design on levels is more focused on forcing the Gaussians to fit the retargeted one, which can be low-frequency structure and high-frequency details. This approach also allows us to convert the large images at the final level into normalized targets, \textit{i.e.,} the difference image. Given the additional training and inference costs of sequential training, we set the level number as 2, where each level learns either low-frequency or high-frequency information. A detailed analysis on the selection of the level number can be found in Supplementary Material.

Given a target image $I$, we optimize the Levels of 2D Gaussian Splatting $\{L_0(\mathcal{N}_0, T_0), L_1(\mathcal{N}_1, T_1)\}$, each of which has the corresponding 2D Gaussians $\mathcal{N}_i$ and the fitting target $T_i$.
First, we consider fitting image targets at multiple resolutions as earlier works and the targets naturally require different number of Gaussian points, which aligns with the network sizes in the neural field. We allocate a portion of the Gaussian points to learn the low-frequency initialization of the target images from the down-sampled image. Since the training target of $L_0$ is of lower resolution and can be simpler than that of $L_1$, we assign fewer points on $L_0$. Consequently, given a total Gaussian number of the Levels of Gaussians as $|\mathcal{N}|$, we have 
\begin{align}
|\mathcal{N}| = |\mathcal{N}_0|+|\mathcal{N}_1| = (1+r)|\mathcal{N}_1|
% |\mathcal{N}_0| &= r|\mathcal{N}_1|,
\end{align} 
where $r$ is the allocation ratio, set as 0.125 in our experiments. After the first-stage tuning, the $L_0$ produces low-frequency initialization that is used to produce the fitting target of $L_1$. Since the rendering only produces images of values between 0 and 1, we normalize the values of difference image via a min-max scaler. The min and max values should be saved in the model for inference, taking only two values for better performance.  The target $T_0$ and $T_1$ can be expressed as:
\begin{align}
T_0 &= {\rm{Down}}(I),\\
T_1 &= {\rm{Norm}}(I-{\rm{UP}}({{\rm{Render}}(L_0)})).
\end{align} 

During training, we set the same number of iterations for the two levels. The fitting is supervised with Mean Squared Error (MSE) loss for each stage. Experiments demonstrate that the two levels of fitting significantly improve performance on large images and only mildly increase the expenses on time for training and testing, each of which involves two rounds of splatting. Additionally, the two levels of Gaussians also reduce the training memory. This is because the first level is frozen when the second one is training, leading to a reduction in maximum number of points with gradients given a fixed total number of Gaussians.

