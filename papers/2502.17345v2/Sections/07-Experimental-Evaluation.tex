\section{Experimental Evaluation}\label{sec:evaluation}

In this section, we evaluate the performance of +Tour using our dataset. First, we describe the baseline used for comparison (Section~\ref{sec:eval1}). Then, we describe the evaluation methodology (Section~\ref{sec:eval2}). Finally, we discuss and draw conclusions based on the obtained results (Section~\ref{sec:eval3}).

\subsection{Baseline algorithm}\label{sec:eval1}
Since currently, PersTour~\cite{lim-personalized:18} is the state-of-the-art for PTIR exact solutions targeting the one-day, single-traveler case, we compare +Tour against PersTour. 
%PersTour solves the classical PTIR problem for a single tourist using an Integer Programming Model. 
However, PersTour does not consider MEC resources and service application demands while generating the itinerary. Thus, to use it to solve the MEC-PTIR problem, we adapt the algorithm as follows:

\begin{itemize}
    \item Since PersTour is designed for a single tourist to produce itineraries for every user $u \in \mathcal{U}_d$, we run $|\mathcal{U}_d|$ independent instances of PersTour, i.e., one instance per user.
    \item We then use the single itinerary generated by PersTour for each tourist as input to our implementation that solves the second stage of the MEC-PTIR problem. This approach may lead to infeasible solutions since PersTour generates a single itinerary for each tourist instead of a Pareto-front as the first {stage} of +Tour. When this happens, we solve the problem by relaxing the constraints of minimum allocation for service applications. Consequently, in terms of user experience, the effective performance of PersTour is even worse than the one shown in the following subsections. In the next sections, we refer to this modified version of PersTour as Resource-aware PersTour (RA-PersTour).
\end{itemize}

\subsection{Evaluation methodology}\label{sec:eval2}

In our evaluation, we consider that the MTC offers two applications for tourists: {MAR} and {MVS}, i.e., \\ $\mathcal{A}=\{\textrm{{MAR}}, \textrm{{MVS}}\}$. The requirements of an {MAR} application are taken from~\cite{garcia:18}, while the requirements of a {MVS} application are based on the Netflix stream service website\footnote{https://help.netflix.com/en/node/306}. Table~\ref{tab:appRequirements} shows the network and processing requirements for both applications.

\begin{table*}[!ht]
    \begin{minipage}[!ht]{.45\textwidth}
    \centering
    \footnotesize
    \captionof{table}{Requirements of the applications{, taken from \cite{garcia:18} and Netflix stream service website$^7$.}}
    \label{tab:appRequirements}
    \begin{tabular}{ccccc}
    \hline
    \textbf{Application} & $\boldsymbol{\lambda^{min}_{a}}$ & $\boldsymbol{\lambda^{max}_{a}}$ & $\boldsymbol{\psi^{min}_{a}}$ & $\boldsymbol{\psi^{max}_{a}}$ \\ \hline
    {MAR}             & 1 Mbps     &  10 Mbps & 0.1 RC   & 1 RC \\
    {MVS}               & 1.5 Mbps   &  25 Mbps & 0 (None) & 0 (None) \\
    \hline
    \end{tabular}
    \end{minipage}
\hspace{0.05\textwidth}
    \begin{minipage}[!ht]{.45\textwidth}
    \centering
    \footnotesize
    \captionof{table}{Evaluation scenarios.}
    \label{tab:evalScenarios}
    \begin{tabular}{ccc}
    \hline
    \textbf{Scenario} & $\boldsymbol{\lambda({v_{i}})}$ & $\boldsymbol{{\psi}_{m}}$ \\ \hline
    High network overload     & 75 Mbps   &  37.5 RCs \\
    Medium network overload   & 150 Mbps  &  37.5 RCs \\
    Low network overload      & 300 Mbps  &  37.5 RCs \\
    \hline
    \end{tabular}
    \end{minipage}
\end{table*}

We assume three scenarios for the ICT Infrastructure, as illustrated in Table~\ref{tab:evalScenarios}. Aligned with experimental evidence in~\cite{malandrino:18}, we define the high network overload scenario, where the amount of network resources available at each POI is 75 Mbps. We also define the medium and low network overload scenarios containing double and triple the amount of network resources at each POI. For the computing resources, we consider two MEC hosts ($|\mathcal{M}|= 2$), each one with 37.5 Reference Cores (RCs), i.e., ${\psi}_{m}=$ 37.5 RC, for all scenarios. Based on~\cite{garcia:18}, we assume that one RC is equivalent to an Intel Haswell i7-4770 @3.40GHz processing power.

For each city, we use the set of travel histories ($\mathcal{S}$) to generate a set with 250 users, i.e., for each city, we consider $|\mathcal{U}_d|=$250. We then provide the set of POIs ($G = (\mathcal{V},\mathcal{E})$), the ICT infrastructure scenario (Table~\ref{tab:evalScenarios}), and the set of users ($\mathcal{U}_d$) and their interests (extracted from $\mathcal{S}$) as input to +Tour and RA-PersTour. We evaluate both algorithms using leave-one-out cross-validation~\cite{kohavi:95}, i.e., for each user $u \in \mathcal{U}_d$, we use all travel sequences $S_u$ of $u$ to build her user's interest ($int_{u}(c), \ \forall \ c \in \mathcal{C}$), except the one we want to test. We also use the duration of the testing travel sequence to define, respectively, the user's budget ($b_u$) and the set of applications that she will consume during the tour ($\mathcal{A}_{u}$). The latter is defined based on our analysis presented in Figure~\ref{fig:POIs-Visiting-Time-Clustering} as follows. If the testing travel sequence belongs to the \textit{Quick-visited} group, we randomly assign one of the following options to $\mathcal{A}_{u}$: \{none\} or \{{MVS}\}. Otherwise, we randomly choose one of the following options to $\mathcal{A}_{u}$: \{{MVS}\}, \{{MAR}\}, or \{{MVS}, {MAR}\}. The rationality behind this approach is that users with short budgets will be willing to watch no application or fast {MVS}. Table~\ref{tab:modelParameters} along with Tables~\ref{tab:appRequirements} and~\ref{tab:evalScenarios} summarize the main parameters and values employed in our evaluation.

\begin{table}[htb]
\footnotesize
\centering
\caption{Model parameters.}
\label{tab:modelParameters}
\begin{tabular}{ll}
\hline
\textbf{Parameter} & \textbf{Value} \\ \hline
$|\mathcal{U}_d|$ & 250  \\
$|\mathcal{V}|$ & 19 - 84 \\ 
$|\mathcal{M}|$ & 2 \\ 
$\alpha$ & 0.5  \\
$\Delta{t}$ & 1 minute \\
$T$ & 480 minutes \\
\hline
\end{tabular}
\end{table}

%\begin{figure*}[!ht]
%    \subfloat[All sequences length.]{
%        \begin{tabular}{@{}ccc@{}}
%            \includegraphics[width=.132\textwidth]{Figures/Experimental-Evaluation/Gain/All/High.pdf} &
%            \includegraphics[width=.132\textwidth]{Figures/Experimental-Evaluation/Gain/All/Medium.pdf} &
%            \includegraphics[width=.132\textwidth]{Figures/Experimental-Evaluation/Gain/All/Low.pdf} \\
%        \end{tabular}
%    \label{fig:gain-All}}
%    \hfill
%    \subfloat[Sequences length greater than 3.]{
%        \begin{tabular}{@{}ccc@{}}
%            \includegraphics[width=.14\textwidth]{Figures/Experimental-Evaluation/Gain/G3/High.pdf} &
%            \includegraphics[width=.14\textwidth]{Figures/Experimental-Evaluation/Gain/G3/Medium.pdf} &
%            \includegraphics[width=.14\textwidth]{Figures/Experimental-Evaluation/Gain/G3/Low.pdf} \\
%        \end{tabular}
%    \label{fig:gain-G3}}
%    \caption{+Tour gain compared to RA-PersTour, separated by size of itineraries sequences.}
%    \label{fig:gain}
%\end{figure*}






%############################################################
\begin{table*}[hbt]
\centering

\footnotesize
\caption{Tour gain compared to RA-PersTour.}
\label{tab:gain}
\begin{tabular}{c|ccccc|ccccc|ccccc}
\hline
\multicolumn{16}{c}{\textbf{All sequences lengths}} \\\hline
\multicolumn{1}{c}{} & \multicolumn{5}{c|}{\textbf{High overload}} & \multicolumn{5}{c|}{\textbf{Medium overload}} & \multicolumn{5}{c}{\textbf{Low overload}} \\\hline
 & \textbf{LO} & \textbf{ME} & \textbf{OS} & \textbf{PE} & \textbf{TO} & 
\textbf{LO} & \textbf{ME} & \textbf{OS} & \textbf{PE} & \textbf{TO} & 
\textbf{LO} & \textbf{ME} & \textbf{OS} & \textbf{PE} & \textbf{TO} \\\hline
%------------------------------------------------------------------------------
+T AE & 0.653 & 0.794 & 0.584 & 0.514 & 0.672 & 0.746 & 0.911 & 0.687 & 0.602 & 0.797 & 0.872 & 0.942 & 0.798 & 0.718 & 0.874 \\\hline
RA AE & 0.649 & 0.731 & 0.552 & 0.461 & 0.657 & 0.744 & 0.852 & 0.665 & 0.579 & 0.793 & 0.869 & 0.885 & 0.791 & 0.704 & 0.870 \\\hline
Gain AE &0.67\%&\hspace{-0.2cm}8.64\%&\hspace{-0.2cm}5.67\%&\hspace{-0.2cm}11.47\% &\hspace{-0.2cm} 2.29\% &\hspace{-0.2cm} 0.32\% &\hspace{-0.2cm} 6.95\% &\hspace{-0.2cm} 3.24\% &\hspace{-0.2cm} 3.88\% &\hspace{-0.2cm} 0.49\% &\hspace{-0.2cm} 0.27\% &\hspace{-0.2cm} 6.41\% &\hspace{-0.2cm} 0.80\% &\hspace{-0.2cm} 2.03\% &\hspace{-0.2cm} 0.53\% \\\hline
%------------------------------------------------------------------------------
+T UE & 0.106 & 0.119 & 0.106 & 0.135 & 0.134 & 0.114 & 0.131 & 0.121 & 0.153 & 0.152 & 0.125 & 0.135 & 0.138 & 0.176 & 0.165 \\\hline
RA UE & 0.103 & 0.085 & 0.084 & 0.099 & 0.123 & 0.112 & 0.097 & 0.108 & 0.137 & 0.151 & 0.124 & 0.101 & 0.132 & 0.171 & 0.163 \\\hline
Gain UE &2.25\%&\hspace{-0.2cm}40.6\%&\hspace{-0.2cm}25.7\%&\hspace{-0.2cm}35.6\% &\hspace{-0.2cm} 8.85\% &\hspace{-0.2cm} 1.19\% &\hspace{-0.2cm} 35.5\% &\hspace{-0.2cm} 12.2\% &\hspace{-0.2cm} 11.2\% &\hspace{-0.2cm} 0.84\% &\hspace{-0.2cm} 1.08\% &\hspace{-0.2cm} 33.7\% &\hspace{-0.2cm} 4.42\% &\hspace{-0.2cm} 2.81\% &\hspace{-0.2cm} 0.94\% \\\hline
%------------------------------------------------------------------------------
\multicolumn{16}{c}{\textbf{Sequences greater than 3}} \\\hline
%------------------------------------------------------------------------------
+T AE & 0.904 & 0.863 & 0.843 & 0.840 & 0.845 & 0.937 & 0.952 & 0.917 & 0.901 & 0.932 & 0.941 & 0.990 & 0.952 & 0.949 & 0.982 \\\hline
RA AE & 0.868 & 0.642 & 0.603 & 0.482 & 0.756 & 0.917 & 0.749 & 0.751 & 0.756 & 0.908 & 0.921 & 0.796 & 0.906 & 0.914 & 0.954 \\\hline
Gain AE &4.15\%&\hspace{-0.2cm}34.3\%&\hspace{-0.2cm}39.7\%&\hspace{-0.2cm}74.2\% &\hspace{-0.2cm} 11.8\% &\hspace{-0.2cm} 2.18\% &\hspace{-0.2cm} 27.1\% &\hspace{-0.2cm} 22.2\% &\hspace{-0.2cm} 19.2\% &\hspace{-0.2cm} 2.57\% &\hspace{-0.2cm} 2.17\% &\hspace{-0.2cm} 24.4\% &\hspace{-0.2cm} 5.05\% &\hspace{-0.2cm} 3.77\% &\hspace{-0.2cm} 2.91\% \\\hline
%------------------------------------------------------------------------------
+T UE & 0.538 & 0.355 & 0.419 & 0.640 & 0.565 & 0.555 & 0.379 & 0.472 & 0.726 & 0.625 & 0.560 & 0.389 & 0.480 & 0.789 & 0.654 \\\hline
RA UE & 0.519 & 0.231 & 0.254 & 0.389 & 0.500 & 0.544 & 0.261 & 0.357 & 0.619 & 0.617 & 0.549 & 0.273 & 0.441 & 0.775 & 0.645 \\\hline
Gain UE &3.70\%&\hspace{-0.2cm}53.4\%&\hspace{-0.2cm}65.1\%&\hspace{-0.2cm}64.2\% &\hspace{-0.2cm} 12.9\% &\hspace{-0.2cm} 2.04\% &\hspace{-0.2cm} 45.2\% &\hspace{-0.2cm} 32.2\% &\hspace{-0.2cm} 17.3\% &\hspace{-0.2cm} 1.22\% &\hspace{-0.2cm} 2.02\% &\hspace{-0.2cm} 42.8\% &\hspace{-0.2cm} 8.90\% &\hspace{-0.2cm} 1.80\% &\hspace{-0.2cm} 1.41\% \\\hline
%------------------------------------------------------------------------------
\end{tabular}
\end{table*}
%############################################################









We use \textbf{Recall}, \textbf{Precision}, and \textbf{F-score} to evaluate +Tour and RA-PersTour. We also introduce two new metrics, namely, \textbf{Allocation Efficiency} (\textbf{AE}) and \textbf{User Experience} (\textbf{UE}) to assess the performance of the algorithms on allocating resources in the network edge and on the overall user experience provided by the recommended itinerary. Assuming that $S_{u}$ is the real-world testing travel sequence and $I_{u*}^k$ is the generated itinerary, these metrics are defined as follows.

\begin{itemize}
    \item \textbf{Recall}: the fraction of POIs from the real-world testing travel sequence that also exists in the generated itinerary.
    \item \textbf{Precision}: the fraction of POIs from the generated itinerary that also exists in the real-world testing travel sequence.
    \item \textbf{F-score}: the model accuracy represented by the harmonic mean of \textbf{Recall} and \textbf{Precision}.
    \item \textbf{Allocation Efficiency}: the amount of computing and network resource allocated to the generated itinerary, relative to the maximum amount demanded by the set of chosen applications, i.e.:
    {\setlength{\mathindent}{0cm}
    \begin{align}
    %\begin{split}
        & AE(I_{u*}^k) = \sum\limits_{v_{i} \in \mathcal{V} \setminus \{v_{0}, v_{n+1}\}}\frac{p(I_{u*}^k,v_{i})}{2|I_{u*}^k \setminus \{v_{0}, v_{n+1}\}|\lambda_{u}^{max}} \ + \nonumber \\
        & \sum\limits_{v_{i} \in \mathcal{V} \setminus \{v_{0}, v_{n+1}\}}\sum\limits_{m \in \mathcal{M}}\frac{q(I_{u*}^k,v_{i},m)}{2|I_{u*}^k \setminus \{v_{0}, v_{n+1}\}|\psi_{u}^{max}}.
    %\end{split}
\end{align}}    
    \item \textbf{User Experience}: determines the relation between the allocation efficiency associated with the generated itinerary (virtual experience) and the profit as perceived by the user for this itinerary (physical experience), i.e.:
    \begin{equation}
    UE(I_{u*}^k) = AE(I_{u*}^k)Norm(Prof(I_{u*}^k)).
    \end{equation}
\end{itemize}

\subsection{Results and discussions}\label{sec:eval3}

\begin{figure*}[!ht]
    \begin{tabular}{@{}ccccc@{}}
        \includegraphics[width=.18\textwidth]{Figures/Experimental-Evaluation/Itinerary/Greater-Than-3/London.pdf} &
        \includegraphics[width=.18\textwidth]{Figures/Experimental-Evaluation/Itinerary/Greater-Than-3/Melbourne.pdf} &
        \includegraphics[width=.18\textwidth]{Figures/Experimental-Evaluation/Itinerary/Greater-Than-3/Osaka.pdf} &
        \includegraphics[width=.18\textwidth]{Figures/Experimental-Evaluation/Itinerary/Greater-Than-3/Perth.pdf} &
        \includegraphics[width=.18\textwidth]{Figures/Experimental-Evaluation/Itinerary/Greater-Than-3/Toronto.pdf} \\
    \end{tabular}
\end{figure*}

\begin{figure*}[!ht]
    \begin{tabular}{@{}ccccc@{}}
        \includegraphics[width=.18\textwidth]{Figures/Experimental-Evaluation/Itinerary/Smaller-Than-3/London.pdf} &
        \includegraphics[width=.18\textwidth]{Figures/Experimental-Evaluation/Itinerary/Smaller-Than-3/Melbourne.pdf} &
        \includegraphics[width=.18\textwidth]{Figures/Experimental-Evaluation/Itinerary/Smaller-Than-3/Osaka.pdf} &
        \includegraphics[width=.18\textwidth]{Figures/Experimental-Evaluation/Itinerary/Smaller-Than-3/Perth.pdf} &
        \includegraphics[width=.18\textwidth]{Figures/Experimental-Evaluation/Itinerary/Smaller-Than-3/Toronto.pdf} \\
    \end{tabular}
\end{figure*}

\begin{figure*}[!ht]
    \begin{tabular}{@{}ccccc@{}}
        \includegraphics[width=.18\textwidth]{Figures/Experimental-Evaluation/AE/London.pdf} &
        \includegraphics[width=.18\textwidth]{Figures/Experimental-Evaluation/AE/Melbourne.pdf} &
        \includegraphics[width=.18\textwidth]{Figures/Experimental-Evaluation/AE/Osaka.pdf} &
        \includegraphics[width=.18\textwidth]{Figures/Experimental-Evaluation/AE/Perth.pdf} &
        \includegraphics[width=.18\textwidth]{Figures/Experimental-Evaluation/AE/Toronto.pdf} \\
    \end{tabular}
\end{figure*}

\begin{figure*}[!ht]
    \begin{tabular}{@{}ccccc@{}}
        \includegraphics[width=.18\textwidth]{Figures/Experimental-Evaluation/UE/London.pdf} &
        \includegraphics[width=.18\textwidth]{Figures/Experimental-Evaluation/UE/Melbourne.pdf} &
        \includegraphics[width=.18\textwidth]{Figures/Experimental-Evaluation/UE/Osaka.pdf} &
        \includegraphics[width=.18\textwidth]{Figures/Experimental-Evaluation/UE/Perth.pdf} &
        \includegraphics[width=.18\textwidth]{Figures/Experimental-Evaluation/UE/Toronto.pdf} \\
    \end{tabular}
    \caption{CDF with the distribution of results for high overload scenario, relative to the itinerary metrics (first two rows), and the allocation and user experience metrics (last two rows). In itinerary metrics, the first line represents results for sequence lengths greater than 3. The second line represents results for sequences smaller or equal to 3.}
    \label{fig:CDF-metrics}
\end{figure*}

We run all experiments in a virtual machine (VM) that runs Debian 11 GNU/Linux and is configured with 4 vCPUs, 32~GB RAM, and 136~GB of virtual disk. The VM is hosted on a 2 Intel Xeon Silver 4114 @2.20GHz server. The first stage of +Tour is implemented using C++. The second stage uses Python 3.8.2, docplex 2.23.222, and IBM ILOG CPLEX 20.1.0 (as the solver). The RA-PersTour algorithm is also implemented using Python 3.8.2, docplex 2.23.222, and IBM CPLEX 20.1.0.

{Table~\ref{tab:gain}} shows the gain obtained by +Tour {(+T)} over RA-PersTour {(RA)} when comparing both algorithms in terms of \textbf{AE} and \textbf{UE} for all scenarios {(London - LO, Melbourne - ME, Osaka - OS, Perth - PE and Toronto - TO)}. %\textcolor{red}{Figure~\ref{fig:gain-All} presents the results considering all itineraries.} 
We observe that +Tour outperforms RA-PersTour in all scenarios {when considering all sequence lengths}, especially the high network overload, showing gains up to 11\% for \textbf{AE} and 40\% for \textbf{UE}. Considering only itineraries with more than 3 POIs, %\textcolor{red}{as illustrated in Figure~\ref{fig:gain-G3},} 
the gains for \textbf{AE} and \textbf{UE} are even greater, reaching, respectively, 74\% and 65\%. The CDF for each metric, including recall, precision, and F-score, is presented in Figure~\ref{fig:CDF-metrics}.

Figure \ref{fig:CDF-metrics} shows a CDF for all evaluated metrics to better illustrate the results' distribution. As can be seen in the \textbf{AE} and \textbf{UE} corresponding rows (3 and 4), our solution never presents results inferior to RA-PersTour, at most equaling the results for sequences less than or equal to 3, when there is no flexibility in choosing an itinerary from the Pareto front. For \textbf{Recall}, \textbf{Precision}, and \textbf{F-score} (rows 1 and 2), we can see that +Tour has similar accuracy to RA-PersTour with lower accuracy at certain points. This loss is justified by the gain observed in \textbf{AE} and \textbf{UE} for sequences greater than 3.

Figure \ref{fig:time} shows the resolution time for +Tour's first and second phases. For all cities, except Melbourne, the total resolution time was less than 20 seconds. In Melbourne, the number of POIs is much higher than in all other cities. Therefore, it takes longer in phase 1, where the Pareto front of candidate itineraries is generated. In fact, for Melbourne, the first phase took approximately 656 seconds, while phase 2 reached 44, 47, and 69 seconds in the high, medium, and low scenarios, respectively. Indeed, our approach to solving the first stage of the problem using a dynamic programming version of the ESPPRC has proven to be very efficient, taking less than 11 minutes for Melbourne and less than 15 seconds for the other cities. This is an important result since the databases of other cities may demand scalability similar to the one observed in Melbourne.

\begin{figure}[!ht]
    \begin{tabular}{@{}ccc@{}}
        \includegraphics[width=.15\textwidth]{Figures/Experimental-Evaluation/Time/High.pdf} &
        \includegraphics[width=.15\textwidth]{Figures/Experimental-Evaluation/Time/Medium.pdf} &
        \includegraphics[width=.15\textwidth]{Figures/Experimental-Evaluation/Time/Low.pdf} \\
    \end{tabular}
    \caption{Time of solving the two phases of +Tour.}
    \label{fig:time}
\end{figure}

In general, based on the experiments carried out, our solution presents superior results regarding the allocation of resources, which improves the user experience when using the applications offered in the POIs. We observed gains of up to 74\% and 65\% in terms of resource allocation and user experience, respectively, while the accuracy of the itineraries remained similar to RA-PersTour. Finally, +Tour makes itinerary recommendations, considering realistically sized instances in a reasonable amount of time.