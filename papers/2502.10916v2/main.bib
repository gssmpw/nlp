@inproceedings{lin-2004-rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-1013",
    pages = "74--81",
}

@inproceedings{see-etal-2017-get,
    title = "Get To The Point: Summarization with Pointer-Generator Networks",
    author = "See, Abigail  and
      Liu, Peter J.  and
      Manning, Christopher D.",
    editor = "Barzilay, Regina  and
      Kan, Min-Yen",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1099",
    doi = "10.18653/v1/P17-1099",
    pages = "1073--1083",
    abstract = "Neural sequence-to-sequence models have provided a viable new approach for abstractive text summarization (meaning they are not restricted to simply selecting and rearranging passages from the original text). However, these models have two shortcomings: they are liable to reproduce factual details inaccurately, and they tend to repeat themselves. In this work we propose a novel architecture that augments the standard sequence-to-sequence attentional model in two orthogonal ways. First, we use a hybrid pointer-generator network that can copy words from the source text via pointing, which aids accurate reproduction of information, while retaining the ability to produce novel words through the generator. Second, we use coverage to keep track of what has been summarized, which discourages repetition. We apply our model to the CNN / Daily Mail summarization task, outperforming the current abstractive state-of-the-art by at least 2 ROUGE points.",
}

@article{reddy2019coqa,
  title={Coqa: A conversational question answering challenge},
  author={Reddy, Siva and Chen, Danqi and Manning, Christopher D},
  journal={Transactions of the Association for Computational Linguistics},
  volume={7},
  pages={249--266},
  year={2019},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{kwiatkowski-etal-2019-natural,
    title = "Natural Questions: A Benchmark for Question Answering Research",
    author = "Kwiatkowski, Tom  and
      Palomaki, Jennimaria  and
      Redfield, Olivia  and
      Collins, Michael  and
      Parikh, Ankur  and
      Alberti, Chris  and
      Epstein, Danielle  and
      Polosukhin, Illia  and
      Devlin, Jacob  and
      Lee, Kenton  and
      Toutanova, Kristina  and
      Jones, Llion  and
      Kelcey, Matthew  and
      Chang, Ming-Wei  and
      Dai, Andrew M.  and
      Uszkoreit, Jakob  and
      Le, Quoc  and
      Petrov, Slav",
    editor = "Lee, Lillian  and
      Johnson, Mark  and
      Roark, Brian  and
      Nenkova, Ani",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "7",
    year = "2019",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q19-1026",
    doi = "10.1162/tacl_a_00276",
    pages = "452--466",
    abstract = "We present the Natural Questions corpus, a question answering data set. Questions consist of real anonymized, aggregated queries issued to the Google search engine. An annotator is presented with a question along with a Wikipedia page from the top 5 search results, and annotates a long answer (typically a paragraph) and a short answer (one or more entities) if present on the page, or marks null if no long/short answer is present. The public release consists of 307,373 training examples with single annotations; 7,830 examples with 5-way annotations for development data; and a further 7,842 examples with 5-way annotated sequestered as test data. We present experiments validating quality of the data. We also describe analysis of 25-way annotations on 302 examples, giving insights into human variability on the annotation task. We introduce robust metrics for the purposes of evaluating question answering systems; demonstrate high human upper bounds on these metrics; and establish baseline results using competitive methods drawn from related literature.",
}

@inproceedings{banerjee-lavie-2005-meteor,
    title = "{METEOR}: An Automatic Metric for {MT} Evaluation with Improved Correlation with Human Judgments",
    author = "Banerjee, Satanjeev  and
      Lavie, Alon",
    editor = "Goldstein, Jade  and
      Lavie, Alon  and
      Lin, Chin-Yew  and
      Voss, Clare",
    booktitle = "Proceedings of the {ACL} Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization",
    month = jun,
    year = "2005",
    address = "Ann Arbor, Michigan",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W05-0909",
    pages = "65--72",
}

@article{brown1992class,
  title={Class-based n-gram models of natural language},
  author={Brown, Peter F and Della Pietra, Vincent J and Desouza, Peter V and Lai, Jennifer C and Mercer, Robert L},
  journal={Computational linguistics},
  volume={18},
  number={4},
  pages={467--480},
  year={1992}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{Dresner2003-DREROB-3,
	author = {Eli Dresner},
	doi = {10.1075/pc.11.2.12dre},
	journal = {Pragmatics and Cognition},
	number = {2},
	pages = {390--394},
	publisher = {John Benjamins Publishing Co.},
	title = {Review of Bunt \& Black (2000): Abduction, Belief and Context in Dialogue--Studies in Computational Pragmatics},
	volume = {11},
	year = {2003}
}

@misc{austin1962speech,
  title={Speech acts},
  author={Austin, JL},
  year={1962},
  publisher={Oxford}
}

@book{searle1969speech,
  title={Speech Acts: An Essay in the Philosophy of Language},
  author={Searle, J.R.},
  isbn={9780521096263},
  lccn={lc68024484},
  series={Cam: Verschiedene Aufl},
  url={https://books.google.co.uk/books?id=t3_WhfknvF0C},
  year={1969},
  publisher={Cambridge University Press}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@misc{manning2008introduction,
  title={Introduction to information retrieval},
  author={Manning, Christopher D},
  year={2008},
  publisher={Cambridge university press}
}

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@article{Chawla_2002,
   title={SMOTE: Synthetic Minority Over-sampling Technique},
   volume={16},
   ISSN={1076-9757},
   url={http://dx.doi.org/10.1613/jair.953},
   DOI={10.1613/jair.953},
   journal={Journal of Artificial Intelligence Research},
   publisher={AI Access Foundation},
   author={Chawla, N. V. and Bowyer, K. W. and Hall, L. O. and Kegelmeyer, W. P.},
   year={2002},
   month=jun, pages={321–357} }

@misc{yu2024breakingceilingllmcommunity,
      title={Breaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling}, 
      author={Yao-Ching Yu and Chun-Chih Kuo and Ziqi Ye and Yu-Cheng Chang and Yueh-Se Li},
      year={2024},
      eprint={2406.12585},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.12585}, 
}

@incollection{lawrence2012aifdb,
  title={AIFdb: Infrastructure for the argument web},
  author={Lawrence, John and Bex, Floris and Reed, Chris and Snaith, Mark},
  booktitle={Computational models of argument},
  pages={515--516},
  year={2012},
  publisher={IOS Press}
}

@article{10.1016/j.eswa.2007.10.042,
author = {Liu, Ying and Loh, Han Tong and Sun, Aixin},
title = {Imbalanced text classification: A term weighting approach},
year = {2009},
issue_date = {January, 2009},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {36},
number = {1},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2007.10.042},
doi = {10.1016/j.eswa.2007.10.042},
abstract = {The natural distribution of textual data used in text classification is often imbalanced. Categories with fewer examples are under-represented and their classifiers often perform far below satisfactory. We tackle this problem using a simple probability based term weighting scheme to better distinguish documents in minor categories. This new scheme directly utilizes two critical information ratios, i.e. relevance indicators. Such relevance indicators are nicely supported by probability estimates which embody the category membership. Our experimental study using both Support Vector Machines and Naive Bayes classifiers and extensive comparison with other classic weighting schemes over two benchmarking data sets, including Reuters-21578, shows significant improvement for minor categories, while the performance for major categories are not jeopardized. Our approach has suggested a simple and effective solution to boost the performance of text classification over skewed data sets.},
journal = {Expert Syst. Appl.},
month = jan,
pages = {690–701},
numpages = {12},
keywords = {Imbalanced data, Term weighting scheme, Text classification}
}

@inproceedings{10.1145/3077136.3080834,
author = {Liu, Jingzhou and Chang, Wei-Cheng and Wu, Yuexin and Yang, Yiming},
title = {Deep Learning for Extreme Multi-label Text Classification},
year = {2017},
isbn = {9781450350228},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3077136.3080834},
doi = {10.1145/3077136.3080834},
abstract = {Extreme multi-label text classification (XMTC) refers to the problem of assigning to each document its most relevant subset of class labels from an extremely large label collection, where the number of labels could reach hundreds of thousands or millions. The huge label space raises research challenges such as data sparsity and scalability. Significant progress has been made in recent years by the development of new machine learning methods, such as tree induction with large-margin partitions of the instance spaces and label-vector embedding in the target space. However, deep learning has not been explored for XMTC, despite its big successes in other related areas. This paper presents the first attempt at applying deep learning to XMTC, with a family of new Convolutional Neural Network (CNN) models which are tailored for multi-label classification in particular. With a comparative evaluation of 7 state-of-the-art methods on 6 benchmark datasets where the number of labels is up to 670,000, we show that the proposed CNN approach successfully scaled to the largest datasets, and consistently produced the best or the second best results on all the datasets. On the Wikipedia dataset with over 2 million documents and 500,000 labels in particular, it outperformed the second best method by 11.7\%~15.3\% in precision@K and by 11.5\%~11.7\% in NDCG@K for K = 1,3,5.},
booktitle = {Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {115–124},
numpages = {10},
keywords = {convolutional neural network, deep learning, extreme text classification, multi-label},
location = {Shinjuku, Tokyo, Japan},
series = {SIGIR '17}
}

@article{chavan2022large,
  title={Large Language Models for Multi-label Propaganda Detection},
  author={Chavan, Tanmay and Kane, Aditya},
  journal={arXiv preprint arXiv:2210.08209},
  year={2022}
}

@inproceedings{r-etal-2024-shot,
    title = "A Few-Shot Multi-Accented Speech Classification for {I}ndian Languages using Transformers and {LLM}{'}s Fine-Tuning Approaches",
    author = "R, Jairam  and
      G, Jyothish  and
      B, Premjith",
    editor = "Chakravarthi, Bharathi Raja  and
      Priyadharshini, Ruba  and
      Madasamy, Anand Kumar  and
      Thavareesan, Sajeetha  and
      Sherly, Elizabeth  and
      Nadarajan, Rajeswari  and
      Ravikiran, Manikandan",
    booktitle = "Proceedings of the Fourth Workshop on Speech, Vision, and Language Technologies for Dravidian Languages",
    month = mar,
    year = "2024",
    address = "St. Julian's, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.dravidianlangtech-1.1",
    pages = "1--9",
    abstract = "Accented speech classification plays a vital role in the advancement of high-quality automatic speech recognition (ASR) technology. For certain applications, like multi-accented speech classification, it is not always viable to obtain data with accent variation, especially for resource-poor languages. This is one of the major reasons that contributes to the underperformance of the speech classification systems. Therefore, in order to handle speech variability in Indian language speaker accents, we propose a few-shot learning paradigm in this study. It learns generic feature embeddings using an encoder from a pre-trained whisper model and a classification head for classification. The model is refined using LLM{'}s fine-tuning techniques, such as LoRA and QLoRA, for the six Indian English accents in the Indic Accent Dataset. The experimental findings show that the accuracy of the model is greatly increased by the few-shot learning paradigm{'}s effectiveness combined with LLM{'}s fine-tuning techniques. In optimal settings, the model{'}s accuracy can reach 94{\%} when the trainable parameters are set to 5{\%}.",
}

@Book{RePEc:wbk:wbpubs:22575,
  author={Kathleen Beegle and Luc Christiaensen and Andrew Dabalen and Isis Gaddis},
  title={{Poverty in a Rising Africa}},
  publisher={The World Bank Group},
  year=2016,
  month={},
  volume={},
  number={22575},
  series={World Bank Publications - Books},
  edition={},
  keywords={ Poverty Reduction - Development Patterns and Poverty Poverty Reduction - Poverty Lines Poverty Redu},
  doi={},
  isbn={ARRAY(0x611c6680)},
  abstract={Perceptions of Africa have changed dramatically. Viewed as a continent of wars, famines and entrenched poverty in the late 1990s, there is now a focus on “Africa rising” and an “African 21st century.” Two decades of unprecedented economic growth in Africa should have brought substantial improvements in well-being. Whether or not they did, remains unclear given the poor quality of the data, the nature of the growth process (especially the role of natural resources), conflicts that affect part of the region, and high population growth. Poverty in a Rising Africa documents the data challenges and systematically reviews the evidence on poverty from monetary and nonmonetary perspectives, as well as a focus on dimensions of inequality. Chapter 1 maps out the availability and quality of the data needed to track monetary poverty, reflects on the governance and political processes that underpin the current situation with respect to data production, and describes some approaches to addressing the data gaps. Chapter 2 evaluates the robustness of the estimates of poverty in Africa. It concludes that poverty reduction in Africa may be slightly greater than traditional estimates suggest, although even the most optimistic estimates of poverty reduction imply that more people lived in poverty in 2012 than in 1990. A broad-stroke profile of poverty and trends in poverty in the region is presented. Chapter 3 broadens the view of poverty by considering nonmonetary dimensions of well-being, such as education, health, and freedom, using Sen's (1985) capabilities and functioning approach. While progress has been made in a number of these areas, levels remain stubbornly low. Chapter 4 reviews the evidence on inequality in Africa. It looks not only at patterns of monetary inequality in Africa but also other dimensions, including inequality of opportunity, intergenerational mobility in occupation and education, and extreme wealth in Africa.},
  url={https://ideas.repec.org/b/wbk/wbpubs/22575.html}
}