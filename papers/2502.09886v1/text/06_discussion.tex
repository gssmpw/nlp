\section{Discussion}

We have proposed Video2Policy, a pipeline for generating simulated tasks from human videos. We show that our design enables us to effectively learn from human videos and generate high quality data.
As such, it is bottlenecked by the quality of these models, particularly mesh reconstruction and reward code generation. However, as these foundation models continue to improve we expect the performance of our method to improve as well. 
Nevertheless, our generated data can be used to train a general visuomotor policy that generalizes to unseen tasks and can be applied in the real.
We believe this is a step towards generalist robotic policies that can perform a wide range of tasks similar to the wide range of everyday human behavior. 

