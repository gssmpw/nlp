\section{Related work}
\label{sec:related}

In this section, we review prior research efforts that framed centroid-based clustering as a combinatorial optimization problem. Several studies have approached this with a particular focus on Quadratic Unconstrained Binary Optimization (QUBO) formulations.
Ref.____ and Ref.____ explored the representation of cluster centroids in QUBO under the assumption of equal cluster sizes, typically in the context of $k$-means clustering. Ref.____ extended this work by introducing a QUBO formulation of the $k$-medoids approach, which differs from $k$-means clustering by selecting $k$ representative data points (medoids) as cluster centers instead of calculating centroids based on the mean of the data points.

These works illustrate that centroid-based clustering algorithms, like $k$-means and $k$-medoids, can be formulated as combinatorial optimization problems, specifically QUBO, albeit under restricted conditions. A recurring assumption in these studies is the uniform distribution of data, which undesirably constrains clusters to be of approximately equal size. Moreover, the use of synthetic data in experiments raises concerns about the generalizability of these methods to real-world data. While Ref.____ proposed an iterative fractional cost approach to address the issue of uneven data distributions, their solution significantly increases computational complexity due to the need for hyperparameter tuning and iterative recalculations.

In contrast to previous approaches, our method does not require predefined cluster sizes or rely on computationally intensive iterative processes. It directly incorporates the number of data points in each cluster as a variable in the objective function, eliminating the assumption of fixed cluster sizes. This enables greater flexibility and adaptability to a wider range of data distributions.