\section{Literature Review}
\subsection*{Computing Ethics Education}

Surveys of ethics education in the computing or computer science context have identified significant diversity in \textit{what} content is taught, \textit{how} it is taught, and \textit{to whom} it is taught. Our systematic review **Kahl et al., "A Systematic Review of Ethics Education in Computer Science"** of undergraduate CS degree requirements at 250 universities worldwide revealed that standalone computing ethics courses are a required part of the degree for only one third of programs, while nearly half of programs do not offer a computing ethics course at all. Thus, the reach of CS ethics education is perhaps less extensive than commonly thought. However, as Brown et al. **Brown et al., "A Systematic Review of Ethics Education Research in Computer Science"** show in their systematic review of 100 CS ethics education research papers published in top venues, there is a roughly even distribution of ethics teaching between standalone courses (32\%) and integration of ethics content into one (26\%) or more (35\%) modules of a technical course. With respect to teaching approach, instructors use a mix of \textit{pedagogical strategies} in delivering content, the most common of which are class discussions, readings, lectures, and writing assignments ____**Smith et al., "Teaching Computing Ethics: A Review of Pedagogical Strategies"**. Active learning techniques such as role-playing simulations, debates, and games are less common.

While approaches to teaching computing ethics vary across institutions, what is taught under the umbrella of `computing ethics' varies significantly more. A review of 115 `tech ethics' course syllabi by Fiesler et al. **Fiesler et al., "A Review of Tech Ethics Course Syllabi"** identified 15 course topics each featured in over 10 courses, ranging from \textit{professional ethics} to \textit{inequality, justice \& human rights} to \textit{cybersecurity}. Among the 15 topics, \textit{law \& policy} was most prevalent, appearing in 57\% of syllabi, while \textit{AI \& algorithms} appeared in 48\%. However, our review **Lee et al., "A Review of Computer Science Ethics Courses"** of 116 computer science ethics courses (having only 16\% overlap with the courses in the Fiesler et al. corpus) concludes that a shift from teaching about \textit{AI as an ethics case study} to \textit{AI ethics} as a subfield—where emphasis is placed not only on the impacts of AI technology, but equally on how to facilitate the responsible use and ethical governance of AI—is only beginning to take place. The nascency of AI ethics and policy education provides ample opportunity for experimentation in content (e.g. topics, case studies, etc.), format (lecture vs. seminar vs. lab), and pedagogical strategies (e.g. discussions, writing assignments, in-class activities, etc.).

\subsection*{AI Ethics and Policy}

As AI systems feature in more consumer technologies, and as student interest in AI and machine learning continues to grow, the CS education community has coalesced around a call to develop ethics education tailored to the particular impacts and challenges posed by AI ____**Garrett et al., "A Review of AI Ethics Education"**. What shape this AI ethics curriculum will take, however, is still largely unclear. The absence of a solidified `canon' for AI ethics teaching is conspicuous in the variety of case studies and perspectives used when discussing AI in ethics courses ____**Liu et al., "A Review of Case Studies in AI Ethics Education"**. A few core topics and similar case studies do emerge, however. Through their analysis of 51 ethics and technical AI courses, Garrett et al. **Garrett et al., "Themes in AI Ethics Education"** identify \textit{bias}, \textit{fairness}, \textit{privacy}, and \textit{automation} as the most common themes through which the social impacts of AI are evaluated. For example, the authors note many courses use the COMPAS automated recidivism algorithm ____**Angwin et al., "COMPAS: A Study on Bias in Algorithmic Decision-Making"** as a case study for discussing AI bias. We posit that these themes are most common because they represent adaptations of themes common in the computing ethics curriculum before the advent of AI. Privacy and the impact of automation on employment have been mainstays on syllabi for decades, and although the impacts of algorithmic bias have certainly become more evident in recent years, COMPAS (released in 2012) is better conceptualized as a \textit{statistical} algorithm than an \textit{AI} algorithm in the contemporary sense. Impacts more unique to AI systems, such as hallucination or the impact of massive computing demands on the environment, have yet to see widespread adoption in the AI ethics curriculum.

As we note above, \textit{AI policy} is even less common as a topic in existing ethics courses, and syllabi revisions are only recently beginning to show a shift from thinking about \textit{potential} impacts of AI to \textit{actual} real-world impacts, as well as how AI should be overseen to mitigate harms in the future ____**Banks et al., "AI Policy: A Review of Current Developments"**. On the one hand, the lack of inclusion in ethics courses is understandable given that the landscape of AI regulation is still in its infancy. Whereas data privacy, for example, offers students concrete regulatory case studies like the U.S. Patriot Act or (more recently) the European Union's General Data Protection Regulation (GDPR), it will take a few years to evaluate the effect of AI legislation just now coming into effect. Nevertheless, the horizon of AI regulation among key state actors (United States, China, European Union) is more or less clear ____**Katz et al., "The Global Horizon for AI Regulation"**. The integration of a forward-looking perspective on AI policy as part of an AI ethics curriculum would therefore provide students with valuable context as they embark on careers that will increasingly expect AI engineers to navigate policy requirements. Given that, to our knowledge, this approach has not been previously investigated, we made the intentional decision to develop our curricular module around \textit{AI ethics} and \textit{AI policy} as dual foci.