Understanding sociodemographic characteristics is fundamental to computational social science (CSS), as it provides a lens to analyze behaviors, opinions, and interactions within online communities.
Reddit offers a rich platform for sociodemographic inference due to its diverse user base and activity patterns.
Existing methods often leverage user participation in specific subreddits to infer attributes such as gender, age, or partisan affiliation.




\subsection{Reddit data}

\spara{Sociodemographic proxies.}
Our work builds on prior research by leveraging predictive features based on user behavior---specifically participation by writing a post or comment on a subreddit.
Participation patterns are readily accessible and straightforward to extract from logs of Reddit user activity.
Unlike more complex features, such as linguistic or semantic text analysis, these patterns are computationally efficient to process and scalable to large datasets, thus making them ideal for widespread application.
While text-based features could theoretically provide richer insights, they present substantial challenges, particularly for token-limited architectures such as transformer-based models.
Their computational requirements make their usage impractical on the amount of data available on Reddit.
In addition, subreddit participation is a nearly universal activity among Reddit users, which ensures comprehensive coverage of the platform's diverse user base.
Participation patterns thus provide a compact and manageable representation of user behavior.
Focusing on the \num{10000} most popular subreddits, as suggested by \citet{waller2021quantifying}, allows to balance informativeness and computational feasibility.

\spara{Ground truth.}
A significant barrier to effective sociodemographic inference is the high cost of labeling.
Traditional survey methods, although reliable, are expensive, time-consuming, and difficult to scale to the vast datasets typically needed for CSS.
Alternative strategies, such as manual annotation or crowdsourcing platforms~\citep{zhang2016learning} such as Mechanical Turk, offer greater scalability but are not without limitations~\citep{kittur2008crowdsourcing,stritch2017opportunities}.
Annotator variability, inconsistency, and potential biases in labeling can compromise data quality~\citep{eickhoff2018cognitive,hettiachchi2021investigating}.
Furthermore, these methods often lack interpretability, transparency, and coherence, thus raising ethical concerns that are increasingly relevant in the context of responsible AI~\citep{barbosa2019rehumanized}.

Self-declared sociodemographic labels offer a robust and interpretable basis for model training~\cite{beller2014ma}.
By explicitly utilizing information that users voluntarily disclose, these labels eliminate ambiguities and reduce reliance on biased assumptions that are often required in purely behavioral or content-based inference methods.
Extracting self-declaration patterns from user messages enables accurate and transparent retrieval of disclosed information, ensuring that the model is grounded in user-provided data.
This approach aligns with ethical principles by leveraging consented data while providing a clear foundation for validation and reproducibility.
We refer to this desirable property as \emph{authenticity}: using as ground truth only demographic data that has been disclosed directly by the user.

\subsection{Modeling}

Numerous modeling strategies exist for sociodemographic inference, each with unique advantages and limitations.
Probabilistic models such as naive Bayes excel in handling uncertainty and are straightforward to implement.
Logistic regression, widely recognized for its simplicity and interpretability, is another viable option; however, it may encounter collinearity issues when processing features derived from popular subreddits with overlapping user bases.
Random forest models provide robust performance by capturing complex, non-linear relationships, but their lack of transparency can hinder interpretability.

Recent advancements in natural language processing (NLP) have introduced new possibilities to use textual data for more precise sociodemographic inference.
These models can extract nuanced patterns from user-generated text, achieving high accuracy when trained effectively.
However, NLP models also come with significant challenges, including high computational costs, the need for careful calibration to address biases in language use, and concerns about fairness and ethical compliance.
Given these constraints, as well as the focus of this paper on features derived from user participation rather than textual data, we consider NLP-based approaches beyond the scope of this study.

The current state-of-the-art (SOTA) for sociodemographic inference on Reddit, as outlined by~\citet{waller2021quantifying}, employs an unsupervised approach based on neural black-box embeddings and has been used extensively~\cite{colacrai2024navigating,del2023mental,hermida2023mental,xia2024integrated,monti2023evidence,hanley2023sub,corso2024longitudinal,lenti2024causal}.
While these models can be powerful, their inherent lack of interpretability poses challenges for sociodemographic inference, where transparency and explainability are key.
To address possible misclassification issues, a common approach typically uses only extreme model output scores to assign demographic attributes.
However, this practice has the obvious downside of arbitrarily reducing the number of users one is able to classify, thereby reducing the overall inclusiveness and effectiveness of the model.
Besides this limitation, the reliance on non-interpretable scores can lead to hard-to-spot errors in sociodemographic attribution.

\spara{Supervised models.}  
Training strategies present a flexible alternative for improving the accuracy and scalability of sociodemographic inference methods.
A range of approaches, including supervised and semi-supervised learning, can be tested to address challenges such as data sparsity and noisy labels.
Supervised methods leverage labeled data to train predictive models, while semi-supervised techniques additionally make use of the abundant unlabeled data available on platforms such as Reddit, potentially improving generalization even with limited labeled samples.

To explore enhancements in model performance, data augmentation techniques, such as oversampling and undersampling, can be employed~\cite{chawla2002smote,he2008adasyn}.
These methods enrich the training dataset by generating synthetic examples or balancing the dataset to reduce class imbalances, mitigating overfitting, and improving the modelâ€™s ability to learn diverse patterns~\cite{shorten2019survey}.
Additionally, stratification can be incorporated into the training process to ensure that the sociodemographic distribution within the dataset is accurately represented~\cite{shahrokh2014effect}.
This step is especially critical for sensitive labels, as it helps minimize biases and ensures equitable performance across different sociodemographic groups.


\spara{Tasks.}
The usage of sociodemographic inference can be broadly distinguished in two downstream tasks: classification and quantification.
Classification models aim to predict user-level sociodemographic attributes based on features derived from user behavior or content. Typically, the per-user label is then combined with some other quantity---for instance, some property of their comments~\cite{de2022social}.
Common attributes of interest include age, gender, affluence, and partisan affiliation.
While effective in identifying specific user characteristics, classification methods might raise ethical concerns if such data is shared with third parties, due to their reliance on sensitive data and potentially compromising user privacy.

In contrast, quantification focuses on estimating the prevalence of sociodemographic groups at the population level, thus offering a complementary perspective~\cite{gonzalez2017review}.
By emphasizing aggregate trends rather than individual predictions, quantification mitigates biases caused by misclassification errors in classification models and aligns more closely with the broader objectives of CSS~\cite{nature2021digital}.
For many applications, understanding group-level trends is sufficient, making quantification an essential and often more practical approach for sociodemographic research.
The distinction between classification and quantification is crucial, as the latter supports scalable, privacy-preserving analyses while maintaining the integrity of population-level insights.
