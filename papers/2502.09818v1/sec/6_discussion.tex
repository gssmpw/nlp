% \section{Limitations and Conclusion}
% \label{sec:limitations_and_conclusion}


% In this paper, we introduced \emph{I-ScienceQA}, a comprehensive benchmark designed to assess the robustness of Vision-Language Models against distractions in both visual and textual domains. By augmenting the \emph{ScienceQA} dataset with diverse forms of distractions, we simulated real-world conditions where input data is often imperfect, noisy. Our extensive evaluation across state-of-the-art VLMs revealed several key findings: (1) Most VLMs remain vulnerable to distractions, especially in the textual domain; (2) Larger models tend to be more robust but do not always guarantee improved performance, particularly when faced with complex bi-modal distractions; (3) Prompt engineering and robust vision encoder could only partially mitigate these vulnerabilities, there remains significant room for improvement in handling both textual and visual distractions.

% Our findings highlight the need for further research in developing more robust VLM models. As the use of VLMs expands across domains such as healthcare, education, and autonomous systems, it becomes increasingly important to build models that can handle the noisy data often encountered in real-world applications.

% While our work contributes valuable insights into the challenges of distraction robustness, it also has certain limitations:

% \begin{itemize}[leftmargin=2em] \setlength\itemsep{0em} \item Limited scope of distractions: Although we introduced a variety of textual and visual distractions, the dataset does not encompass all possible real-world noise. Future work could explore additional forms of noise, such as adversarial examples, corrupted images to further challenge the models.

% \item Model evaluation focus: Our study primarily focused on pre-trained VLMs. We did not explore the effects of fine-tuning models on noisy datasets that may be more resilient to distractions. Fine-tuning on noisy or augmented data could provide valuable insights into improving model robustness.

% \item Bimodal distractions: While we examined the compounded effects of bimodal distractions, we did not extensively explore how interaction effects between the two modalities influence model performance. Future research should analyze more closely how different types of visual and textual distractions interact and whether certain combinations are more detrimental than others.


% \item Defense techniques: Although we explored the use of prompt engineering and robust vision encoder as a defense mechanism, our study did not delve into other possible methods to enhance model robustness, such as vision segmentation\cite{lai2023lisa}. Exploring these techniques could offer more comprehensive solutions for improving VLM performance in noisy environments.

% \end{itemize}

% In summary, while the \emph{I-ScienceQA} benchmark provides a valuable tool for evaluating VLM robustness, there is much work to be done in advancing models that can consistently navigate noisy, real-world data. Future research should focus on expanding the range of distractions, investigating fine-tuning techniques, and exploring other defense strategies to create more resilient VLMs.