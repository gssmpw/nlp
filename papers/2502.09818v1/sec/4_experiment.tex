\section{Experimental Setup}
\label{sec:experimental_setup}

% In our experiments, we employ various VLMs, which are tested with samples from \emph{ScienceQA} benchmark and corresponding samples from \emph{I-ScienceQA} benchmark.

\subsection{Models}

% \begin{table}[h]
% \centering
% \small
% \begin{tabular}{@{}p{2.5cm}p{2.5cm}p{2.5cm}@{}}
% \toprule
% \textbf{Model Name} & \textbf{Language Model} & \textbf{Vision Encoder} \\
% \midrule
% Phi3-V & Not specified & Not specified \\
% \midrule
% LLaVA & Vicuna & CLIP ViT-L/14 \\
% \midrule
% InstructBLIP & Vicuna & CLIP ViT-G/14 \\
% \midrule
% Qwen2-VL & QwenLM & CLIP ViT-L \\
% \midrule
% InternVL2 & InternLM2 & InternViT \\
% \midrule
% CogVLM2 & LLaMA3 & EVA-CLIP-E \\
% \midrule
% GPT-4o & Not specified & Not specified \\
% \bottomrule
% \end{tabular}
% \caption{Models' Language and Vision Encoder Components}
% \label{tab:models}
% \end{table}


To evaluate the robustness of VLMs, we employ 14 advanced VLMs. Regarding model size, we consider both small and large models, with sizes ranging from 1B to 34B parameters. In terms of model accessibility, we include both open-source models such as LLaVA~\citep{liu2023llava} and proprietary models such as GPT-4o. VLMs include LLaVA-1.5 (7B, 13B)~\citep{liu2023llava}, InstructBLIP-Vicuna (7B, 13B)~\citep{dai2023instructblip}, Phi3-V (4B)~\citep{phi3vfinetuning2023}, InternVL2 (1B, 2B, 8B, 26B)~\citep{chen2024far}, CogVLM2 (19B)~\citep{hong2024cogvlm2visuallanguagemodels}, Qwen2-VL (2B, 8B)~\citep{wang2024qwen2vlenhancingvisionlanguagemodels}, and GPT-4o. 

\subsection{Evaluation Metrics}

To assess the robustness of the model $\mathcal{F}$, we utilize the following evaluation metrics:

\begin{itemize}[leftmargin=*, itemsep=0pt, topsep=0pt, parsep=2pt, partopsep=0pt]
    \item \textbf{Exact Match} The metric $\mathrm{Accuracy}(\mathcal{F}; \mathcal{D})$ represents the mean exact match score of the model $\mathcal{F}$ across all test instances $\mathcal{D}$, where $y_d$ is the correct output for instance $d$. The exact match score equally weights all individual test instances and is calculated as:
    \begin{align*}
        \mathrm{Accuracy}(\mathcal{F}; \mathcal{D}) = 
            \frac{
                \sum_{d \in \mathcal{D}} 
                    \mathbf{1}\left[
                        \mathcal{F}(d) = y_d
                    \right]
            }{
                |\mathcal{D}|
            }
    \end{align*}
    
    \item \textbf{Exact Match Degradation} This metric quantifies the impact of distractions on the model's performance. For an exact match score $A_{\mathcal{F}, \mathcal{D}}$ achieved by $\mathcal{F}$ on the original dataset $\mathcal{D}$ and its corresponding score $A_{\mathcal{F}, \mathcal{D}'}$ on the dataset with added distractions $\mathcal{D}'$, the degradation in performance is computed as:
    % \wjdd{this $\Delta$ can be negative and positive? how to interprete?}
    \begin{align*}
        \Delta \mathrm{Accuracy}(\mathcal{F}) = A_{\mathcal{F}, \mathcal{D}'} - A_{\mathcal{F}, \mathcal{D}},
    \end{align*}
        where $A_{\mathcal{F}, \mathcal{D}'}$ denotes the model's exact match score on samples with distractions. The value of $\Delta \mathrm{Accuracy}(\mathcal{F})$ is always less than or equal to zero ($\Delta \mathrm{Accuracy}(\mathcal{F}) \leq 0$). A value of zero indicates that the model's performance remains unchanged despite the introduction of distractions, showcasing high robustness. Negative values indicate a decline in performance caused by distractions, with lower values reflecting higher vulnerability to such distractions. Therefore, the closer $\Delta \mathrm{Accuracy}(\mathcal{F})$ is to zero, the more robust the model is against distractions.
\end{itemize}


\section{Experimental results}
 
\label{sec:experiment results}

\begin{table*}[ht]
  \centering
  \caption{Performance of various models under different scenarios of distractions. The \textit{Original} columns display the exact match scores on the samples of the \emph{ScienceQA} benchmark. The \textit{Distraction} columns present corresponding results on the \emph{I-ScienceQA} benchmark, including both exact match scores and exact match degradation (shown in parentheses). Values marked as \textit{N/A} indicate that the model requires both text and image inputs and are therefore excluded from evaluation under that section.}
  \label{tab:overall results}
  \resizebox{\textwidth}{!}{
  \begin{tabular}{l|cc|cc|cc|cc}
    \toprule
    \textbf{Model} & \multicolumn{2}{c|}{\textbf{Add Image(\%)}} & \multicolumn{2}{c|}{\textbf{Insert Image(\%)}} & \multicolumn{2}{c|}{\textbf{Add Hints(\%)}} & \multicolumn{2}{c}{\textbf{Insert Hint(\%)}} \\
    \cline{2-9}
    & \textbf{Original} & \textbf{Distraction} & \textbf{Original} & \textbf{Distraction} & \textbf{Original} & \textbf{Distraction} & \textbf{Original} & \textbf{Distraction} \\
    \midrule
    Phi3v (4B) & N/A & 91.15 & N/A & 83.52 & N/A & N/A & N/A & N/A \\
    Instructblip (7B) & N/A & 41.05 & N/A & 35.45 & N/A & N/A & N/A & N/A \\
    Instructblip (13B) & N/A & 47.26 & N/A & 47.80 & N/A & N/A & N/A & N/A \\
    Qwen2-VL-Instruct (2B) & 63.30 & 63.30 (0.00) & 63.80 & 63.26 (-0.54) & 60.80 & 54.45 (-6.35) & 72.45 & 64.20 (-8.25) \\
    Qwen2-VL-Instruct (7B) & 83.10 & 83.10 (0.00) & 68.40 & 68.08 (-0.32) & 75.65 & 68.00 (-7.65) & 77.40 & 74.10 (-3.30) \\
    Llava (7B) & 71.30 & 68.05 (-3.25) & 68.75 & 66.36 (-2.39) & 69.70 & 63.80 (-5.90) & 70.55 & 69.30 (-1.25) \\
    Llava (13B) & 72.90 & 72.00 (-0.90) & 72.10 & 69.60 (-2.50) & 72.15 & 67.45 (-4.70) & 73.10 & 71.80 (-1.30) \\
    Llava (34B) & 88.05 & 87.50 (-0.55) & 81.55 & 79.51 (-2.04) & 84.65 & 82.65 (-2.00) & 85.50 & 83.00 (-2.50) \\
    Internvl2 (1B) & 85.60 & 79.70 (-5.90) & 88.10 & 83.47 (-4.63) & 87.80 & 80.55 (-7.25) & 85.90 & 82.85 (-3.05) \\
    Internvl2 (2B) & 91.35 & 86.75 (-4.60) & 93.50 & 90.23 (-3.27) & 91.40 & 82.35 (-9.05) & 93.65 & 91.50 (-2.15) \\
    Internvl2 (8B) & 95.45 & \textbf{94.45} (-1.00) & 96.90 & 94.23 (-2.67) & 94.80 & \textbf{93.60} (-1.20) & 97.60 & 95.90 (-1.70) \\
    Internvl2 (26B) & 95.35 & 93.40 (-1.95) & 97.40 & 95.14 (-2.26) & 95.20 & 92.80 (-2.40) & 97.55 & 96.55 (-1.00) \\
    CogVLM2 (19B) & 73.30 & 71.70 (-1.60) & 89.35 & 87.47 (-1.88) & 78.60 & 70.50 (-8.10) & 84.15 & 80.85 (-3.30) \\
    GPT-4o & 93.50 & 93.00 (-0.50) & 80.70 & 78.56 (-2.14) & 89.50 & 87.50 (-2.00) & 86.00 & 84.05 (-1.95) \\
    \bottomrule
  \end{tabular}
  }
\end{table*}

\autoref{tab:overall results} presents a comprehensive evaluation of various  models across different scenarios of distractions, measured under both original and distraction settings. For each scenario, the exact match degradation due to distractions is quantified in parentheses, providing insight into the robustness of each model against distractions. \textbf{The results exhibit differing degrees of degradation in model performance when exposed to distractions, highlighting the variability in the models' abilities to focus on relevant data}. It is important to note that the Phi3v and InstructBLIP models, which can only process inputs containing both textual and visual components, were evaluated exclusively on the \textbf{Add Image} and \textbf{Insert Image} scenarios. In this discussion, we analyze the models' performances in each scenario of distraction, focusing on both the exact match score and the exact match degradation score.



Firstly, in the \textbf{Add Image} scenario, models are evaluated on their ability to handle additional visual distraction. Notably, the Internvl2 (8B) model achieves the highest performance in the distraction scenario with a score of 94.45, exhibiting a minimal decrease of $-1.00$ from its original score of 95.45. Similarly, GPT-4o maintains high performance with an exact match score of 93.00 and a slight reduction of $-0.50$. In contrast, smaller models like Llava (7B) and Internvl2 (1B) show more significant drops in performance, with exact match scores of 68.05 ($-3.25$) and 79.70 ($-5.90$), respectively. These results suggest that \textbf{larger models tend to be more robust against visual distractions in this context}.

In the \textbf{Insert Image} scenario, where visual distraction are embedded into existing visual input, the performance trends are consistent. The Internvl2 (8B) model again demonstrates robustness with a exact match scores of 94.23 and a decrease of $-2.67$ from its original score of 96.90. Interestingly, the Qwen2-VL-Instruct (2B) and Qwen2-VL-Instruct (7B) models show minimal performance degradation, with exact match scores of 63.26 ($-0.54$) and 68.08 ($-0.32$), respectively. Despite smaller reduction in exact match score, these models have worse performance. 

When examining the \textbf{Add Hint} scenario, which involves injected textual distraction, the impact of distractions becomes more pronounced. Most models experience larger decreases in performance. The Internvl2 (2B) model, for instance, has an exact match score of 82.35, reflecting a significant drop of $-9.05$ from its original score of 91.40. Even the higher-performing Internvl2 (8B) and Internvl2 (26B) models face reductions to exact match scores of 93.60 ($-1.20$) and 92.80 ($-2.40$), respectively. These findings highlight that \textbf{adding textual distractions poses a greater challenge to the models compared to visual distractions, possibly due to the complexity of processing  textual information}. 

Lastly, in the \textbf{Insert Hint} scenario, where textual distractions are interspersed within existing text, models generally show moderate performance degradation. The Internvl2 (8B) model maintains a high exact match score of 95.90, with a decrease of $-1.70$ from its original score of 97.60. Similarly, GPT-4o achieves a exact match scores of 84.05, reflecting a decrease of $-1.95$. However, models like Qwen2-VL-Instruct (2B) exhibit a larger drop to a exact match scores of 64.20 ($-8.25$), indicating vulnerability to inserted textual distractions. These results suggest that \textbf{while some models are adept at managing inserted hints, others may struggle, potentially due to differences in their attention mechanisms or the diversity of their training data}.