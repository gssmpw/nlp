\section{Limitations and Conclusion}
\label{sec:limitations_and_conclusion}


In this paper, we introduced \emph{I-ScienceQA}, a comprehensive benchmark designed to assess the robustness of Vision-Language Models against distractions. By augmenting the \emph{ScienceQA} dataset with diverse forms of distractions, we simulated real-world conditions where input data is often imperfect, noisy. Our extensive evaluation across state-of-the-art VLMs revealed several key findings: (1) Most VLMs remain vulnerable to distractions, especially in the textual domain; (2) Larger models tend to be more robust but do not always guarantee improved performance, particularly when faced with complex bi-modal distractions; (3) Prompt engineering and robust vision encoder could only partially mitigate these vulnerabilities, there remains significant room for improvement. Our findings highlight the need for further research in developing more robust VLM models. As the use of VLMs expands across domains such as healthcare, education, and autonomous systems, it becomes increasingly important to build models that can handle the noisy data often encountered in real-world.

While our work contributes valuable insights into the challenges of distraction robustness, it also has limitations:

\begin{itemize}[leftmargin=2em] \setlength\itemsep{0em} \item Limited scope of distractions: Although we introduced a variety of textual and visual distractions, the dataset does not encompass all possible real-world noise. 
% Future work could explore additional forms of noise, such as corrupted images to further challenge the models.

\item Model evaluation focus: Our study primarily focused on pre-trained VLMs. We did not explore the effects of adversary fine-tuning models on noisy datasets that may be more resilient to distractions.

\item Bimodal distractions: While we examined the compounded effects of bimodal distractions, we did not extensively explore how interaction effects between the two modalities influence model performance. 
% Future research should analyze more closely how different types of visual and textual distractions interact.


\item Defense techniques: Although we explored the use of prompt engineering and robust vision encoder as a defense mechanism, our study did not delve into other possible methods to enhance model robustness, such as vision segmentation\cite{lai2023lisa}. 
% Exploring these techniques could offer more comprehensive solutions for improving VLM performance in noisy environments.
\end{itemize}

In summary, while the \emph{I-ScienceQA} benchmark provides a valuable tool for evaluating VLM robustness, there is much work to be done in advancing models that can consistently navigate noisy real-world data. Future research should focus on expanding the range of distractions, investigating robust fine-tuning techniques, and exploring defense strategies to improve robustness of VLMs.