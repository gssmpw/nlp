\subsection{Main Results}
\input{Tables/MainExp}
The results on the Bird benchmark are presented in Table~\ref{tab:model-comparison}. Results on the Spider benchmark and its robustness variants are deferred to Appendix~\ref{apx:spider}. 

% At each training stage, the models were evaluated on the development set using three common inference strategies: Greedy, Pass@1, and Maj@K. 

\textbf{Vanilla Models Struggle to Achieve Performance Gains in the DPO Stage.} 
%Vanilla models showed limited performance improvements during the DPO stage. 
%For both the Greedy and Maj@16 metrics, the gains during the DPO stage hovered around zero.
%Although all models demonstrated some improvement in Pass@1 during the DPO stage compared to SFT, the magnitude of improvement was small. 
%Moreover, Pass@1 consistently emerged as the weakest inference strategy across nearly all models, making it difficult to conclude that model performance was meaningfully enhanced. %
For Greedy and Maj@16, DPO gains are minimal or even negative, and improvements for the Pass@1 strategy are marginal as well. Models showing performance degradation after DPO tend to worsen as training progresses, indicating that directly applying DPO in the vanilla setting may impair performance.

% We also observe that for models experiencing performance degradation during the DPO stage, the degradation tend to worsen as training progressed. Note that, checkpoints from earlier in the training process were selected for reporting, which likely underestimates the extent of the damage caused by DPO training.

\textbf{Models with Synthetic CoT Achieve Stable and Significant Gains in the DPO Stage.}
%Models trained with synthesized CoT data demonstrated consistent and significant performance improvements during the DPO stage. 
These gains are evident across all base models and inference strategies. Even when CoT models outperform vanilla models in the SFT stage, the performance gains from CoT remain consistently significant during the subsequent DPO stage. Moreover, this phenomenon persists even when replacing GPT-4o-mini with much weaker LLMs (e.g., Qwen2.5-1.5B-Instruct) to synthesize CoT solutions, confirming the benefit of the CoT solution style per se for DPO, as discussed in Appendix~\ref{apx:qualityablation}.

% for synthesized CoT models compared to the vanilla setting

% These gains are obvious and can be observed across all base models and inference strategies employed during evaluation. Even when synthesized CoT models already outperformed Vanilla models after the SFT stage, the performance gains achieved during the DPO stage are consistent obvious for synthesized CoT models compared to the Vanilla setting.

\textbf{Synthesized CoT plus DPO Exhibit Higher Performance Ceilings.} 
%In practice, we are often concerned with the maximum achievable performance of a base model on the Text-to-SQL task, regardless of the training stage or inference strategy. 
As shown in the $\Delta$EX column in Table~\ref{tab:model-comparison}, all base models trained with CoT-enhanced data through the SFT and DPO pipeline achieved higher performance ceilings. This indicates that integrating CoT synthesis with DPO is highly effective for the Text-to-SQL task, offering a promising new approach to developing improved Text-to-SQL models. With our straightforward pipeline, Qwen2.5-14B-Instruct achieves the second-best performance on the Bird development set among all open-source models, despite having significantly fewer parameters, as shown in Table~\ref{tab:BestModels}.

\input{Tables/BestLocalModel}

\subsection{Error Analysis}\label{sec:errorAnalysis}
\input{Tables/ErrorAnalysis}
To understand how DPO affects model generation and identify areas where CoT enhances DPO, we meticulously analyze errors made by Qwen2.5-7B-Instruct using the greedy decoding strategy. As shown in Table~\ref{table:ErrorAnalysis}, errors are classified into our pre-defined categories, with correction rates before and after DPO presented for each. Full explanations and examples of our classification criteria, along with detailed error statistics, are available in Appendix~\ref{apx:analysis}. We find that, except for Syntax Errors, synthesized CoT improves DPO's ability to correct errors across all other categories.

% To better understand how DPO alters the model's generation outcomes and to identify the areas where synthesized CoT improves DPO performance, we analyzed the errors made by the Qwen2.5-7B-Instruct model before and after DPO training under the greedy inference strategy. 

% As shown in Table~\ref{table:ErrorAnalysis}, errors are classified by our defined categories, and the correction rates before and after DPO for each category are presented. Full explanations and examples of our classification criteria, along with detailed error statistics, can be found in Appendix~\ref{apx:analysis}. We can find that, except for Syntax Errors, the synthesized CoT enhanced DPO's ability to correct errors across all other categories.

\textbf{DPO Excels at Correcting Errors Caused by Ignoring Details.} Error types with a correction rate exceeding 25\% during DPO are highlighted in bold. These errors primarily stem from the model's failure to pay sufficient attention to details. For instance, \underline{NULL/DISTINCT} (Fix 40.0\% with CoT) errors arise when the model overlooks missing or duplicate values in the relevant columns, leading to incorrect query results. Similarly, \underline{Column Sequence} (Fix 42.9\% with CoT) errors occur when the model does not return columns in the order specified in the question. 

% \textbf{CoT Provides Logical Guidance to Help DPO Address Complex Errors.} Error types with significant fix rate improvements often benefited from the reasoning introduced by CoT. For example, \underline{JOIN} errors (Fix 32.1\%, +16.5\% with CoT) frequently occur when the required information resides in two tables that need to be joined via a third intermediate table. Without CoT, the model might attempt to directly join the two tables on an incorrect key. CoT explicitly outlines the logic of table joins in its step-by-step reasoning process, making it easier for DPO to identify and correct such errors. In contrast, for intuitive error types such as \underline{Hallucination} (Fix 27.2\%, +3.5\% with CoT) and \underline{Date} (Fix 30.4\%, +7.3\% with CoT), the contribution of CoT is relatively small. These errors typically arise from mismatches between the SQL query and the information provided in the database prompt, which does not need complicated reasoning processes. Thus, vanilla DPO is already capable of addressing effectively.

%when the required information resides in two tables that cannot be directly joined. Instead, an intermediate table is needed to facilitate the join. 

\textbf{CoT Provides Logical Guidance to Enhance DPO's Error Correction.} Error types with significant improvement often benefit from CoT's reasoning nature. For example, \underline{JOIN} errors (Fix 32.1\%, +16.5\% with CoT) frequently occur when the required information resides in two tables that need to be joined via a third intermediate table. Without CoT, the model might attempt to directly join the two tables on an incorrect key. CoT's step-by-step logic clarifies these joins, aiding DPO in error correction. Conversely, for intuitive errors like \underline{Hallucination} (Fix 27.2\%, +3.5\% with CoT) and \underline{Date} (Fix 30.4\%, +7.3\% with CoT), CoT's impact is smaller. These errors stem from mismatches between SQL queries and database information, which vanilla DPO already can address effectively.
More analysis about DPO's effect with or without CoT reasoning can be found in Appendix~\ref{apx:analysis}.

% \begin{itemize}[leftmargin=0.5em]
%     %\setlength{\itemindent}{0em}
%     \item \underline{Table} (Fix~15.9\%) and \underline{Column} (Fix~16.1\%) Errors: These errors stem from the model's failure to correctly identify the tables and columns relevant to the question, a key challenge in schema linking. Many Text-to-SQL approaches specifically focus on improving performance in this area.
%     \item \underline{Complex Operation} (Fix~12.5\%) Errors: These errors involve difficulties in learning complex operations. To address this, some methods introduce intermediate representations, such as TA-SQL\citep{qu2024ta-sql} or Nat-SQL\citep{gan2021nat-sql}, to simplify the learning process for models.
%     \item \underline{Syntax Errors} (Fix~13.3\%): These errors occur when the generated SQL query is syntactically invalid. Recent work has proposed post-generation execution and repair strategies to ensure that the returned SQL is executable.
% \end{itemize}


%To some extent, the strength of DPO is orthogonal to the directions pursued by existing Text-to-SQL methods. We believe that incorporating DPO into the pipelines of these methods could lead to further performance improvements. 
