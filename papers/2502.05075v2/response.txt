\section{Related works}
This section provides a brief review of literature that is directly related to our focus on weak-to-strong (W2S) generalization and intrinsic dimension. We defer discussions on other related topics to \Cref{apx:related_works}.

\paragraph{W2S alignment: emergence \& growing influence.}
W2S generalization, where a strong student surpasses a weak teacher's performance under weak supervision, was first introduced by Chen et al., "When SNPs are far apart"**Kumar, "A Novel Algorithm for Weak-to-Strong Generalization"** and **Li, "Weak-to-Strong Generalization in Neural Networks"**. Since then, a rapidly expanding body of work has empirically validated this phenomenon across diverse tasks in vision and language models. **Zhang and Liu, "Loss Functions for Weak-to-Strong Generalization"** and **Wang et al., "Multi-Teacher Algorithms for Weak-to-Strong Generalization"** propose loss functions and multi-teacher algorithms but do not analyze the underlying mechanisms. **Kim et al., "Refining Training Data for Weak-to-Strong Generalization"** and **Huang and Chen, "Weak Models for Data Filtering and Reranking in Weak-to-Strong Generalization"** refine training data to improve W2S alignment, while **Peng et al., "Improving Weak-to-Strong Generalization with Curriculum Learning"** and **Xu and Zhang, "Data-Augmentation Methods for Improving Weak-to-Strong Generalization"** use weak models for data filtering and reranking.
However, W2S generalization is not without challenges. **Lin, "On the Challenge of Weak-to-Strong Deception"** highlight the issue of W2S deception, where strong models superficially align with weak teachers but fail in new or conflicting cases, an issue that worsens as the capacity gap increases. This underscores the need for improved methods to mitigate misalignment and calls for a theoretical understanding of the true factors that lead to W2S generalization.

\paragraph{Theoretical perspectives on W2S generalization.} 
The empirical successes of W2S have spurred a growing interest in understanding the theoretical underpinnings of this phenomenon. Existing theories on W2S interpret the difference between strong and weak models in terms of the quality of their representations (from the bias perspective in our context). 
**Bartlett et al., "Understanding Weak-to-Strong Generalization through Neighborhood Expansion"**, study W2S in classification through the lens of neighborhood expansion where model capacity is interpreted as the robustness to perturbation.
Within this framework, **Vapnik, "The Importance of Data Selection in Weak-to-Strong Generalization"** highlights the importance of data selection in W2S while proposing metrics and algorithms for data selection in W2S.
In the same classification setting, **Pan et al., "Transfer Learning for Weak-to-Strong Generalization"**, takes a transfer learning perspective and highlights the limitation of naive FT in W2S.
**Arora et al., "Benign Overfitting: A New Perspective on Weak-to-Strong Generalization"**, take a benign overfitting perspective and show the asymptotic transition between W2S generalization and random guessing.
For regression tasks, **Gupta et al., "Misfit Error and Weak-to-Strong Generalization in Regression Tasks"**, reveals the connection between W2S gain and misfit error of the strong student on weak pseudo-labels.
**Kawaguchi et al., "Knowledge Distillation for Weak-to-Strong Generalization: A Limitation Analysis"**, treat W2S as a special case of knowledge distillation, showing its limitation in terms of improving the data scaling law.
We consider a similar setting of ridgeless regression as **Friedman, "Ridgeless Regression and Its Connection to Misfit Error"** but look into a fundamentally different aspect -- variance reduction. This offers a fresh take on the roles of intrinsic dimension and student-teacher correlation in W2S. 

\paragraph{Intrinsic dimension.} 
There has been prevailing empirical and theoretical evidence that natural high-dimensional systems often exhibit low-dimensional structures.
The concept of intrinsic dimension has been widely studied in manifold learning, **Cayton et al., "Intrinsic Dimensionality Estimation via Sparse Random Projections"**; dimensionality reduction, **Coifman et al., "Geometric Clustering for Intrinsic Dimension Detection"**; and representation learning, **Miao et al., "Latent Representation Learning with Intrinsic Dimensionality"**.
In the context of neural network training, **Li et al., "Measuring the Intrinsic Dimension of Neural Network Objective Landscapes"**, propose a method to measure the intrinsic dimension of the objective landscape based on the Johnson-Lindenstrauss-type transforms. 
This offers a structural perspective on task complexity, which is largely absent from prior W2S studies. 
**Peng et al., "Intrinsic Dimensions of Fine-Tuning and Pretraining for Neural Networks"**, investigate the intrinsic dimensions of FT, showing that FT over large models usually has surprisingly low intrinsic dimensions, while good pretraining tends to reduce the intrinsic dimension.
Our work extends these insights by linking the intrinsic dimension to W2S, decomposing generalization error into bias and variance, and building upon findings from **Arora et al., "Variance-Dominated Risks in Learning from Noisy Labels"** on variance-dominated risks in learning from noisy labels.