% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}


% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").


@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}



@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}


@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{li2023starcoder,
  title={StarCoder: may the source be with you!},
  author={Li, Raymond and Allal, Loubna Ben and Zi, Yangtian and Muennighoff, Niklas and Kocetkov, Denis and Mou, Chenghao and Marone, Marc and Akiki, Christopher and Li, Jia and Chim, Jenny and others},
  journal={arXiv preprint arXiv:2305.06161},
  year={2023}
}

@article{collins2023evaluating,
  title={Evaluating Language Models for Mathematics through Interactions},
  author={Collins, Katherine M and Jiang, Albert Q and Frieder, Simon and Wong, Lionel and Zilka, Miri and Bhatt, Umang and Lukasiewicz, Thomas and Wu, Yuhuai and Tenenbaum, Joshua B and Hart, William and others},
  journal={arXiv preprint arXiv:2306.01694},
  year={2023}
}


@article{imani2023mathprompter,
  title={Mathprompter: Mathematical reasoning using large language models},
  author={Imani, Shima and Du, Liang and Shrivastava, Harsh},
  journal={arXiv preprint arXiv:2303.05398},
  year={2023}
}



@article{metamath2023,
  title={Metamath: Bootstrap your own mathematical questions for large language models},
  author={Yu, Longhui and Jiang, Weisen and Shi, Han and Yu, Jincheng and Liu, Zhengying and Zhang, Yu and Kwok, James T and Li, Zhenguo and Weller, Adrian and Liu, Weiyang},
  journal={arXiv preprint arXiv:2309.12284},
  year={2023}
}

@article{fu2022complexity,
  title={Complexity-based prompting for multi-step reasoning},
  author={Fu, Yao and Peng, Hao and Sabharwal, Ashish and Clark, Peter and Khot, Tushar},
  journal={arXiv preprint arXiv:2210.00720},
  year={2022}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}


@article{rubin2021learning,
  title={Learning to retrieve prompts for in-context learning},
  author={Rubin, Ohad and Herzig, Jonathan and Berant, Jonathan},
  journal={arXiv preprint arXiv:2112.08633},
  year={2021}
}


@article{golovneva2022roscoe,
  title={Roscoe: A suite of metrics for scoring step-by-step reasoning},
  author={Golovneva, Olga and Chen, Moya and Poff, Spencer and Corredor, Martin and Zettlemoyer, Luke and Fazel-Zarandi, Maryam and Celikyilmaz, Asli},
  journal={arXiv preprint arXiv:2212.07919},
  year={2022}
}

@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}


@article{fu2022complexity,
  title={Complexity-based prompting for multi-step reasoning},
  author={Fu, Yao and Peng, Hao and Sabharwal, Ashish and Clark, Peter and Khot, Tushar},
  journal={arXiv preprint arXiv:2210.00720},
  year={2022}
}

@article{lee2023platypus,
  title={Platypus: Quick, cheap, and powerful refinement of llms},
  author={Lee, Ariel N and Hunter, Cole J and Ruiz, Nataniel},
  journal={arXiv preprint arXiv:2308.07317},
  year={2023}
}






@article{gou2023tora,
  title={Tora: A tool-integrated reasoning agent for mathematical problem solving},
  author={Gou, Zhibin and Shao, Zhihong and Gong, Yeyun and Yang, Yujiu and Huang, Minlie and Duan, Nan and Chen, Weizhu and others},
  journal={arXiv preprint arXiv:2309.17452},
  year={2023}
}


@article{GSM8K,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{MATH,
  title={Measuring mathematical problem solving with the math dataset},
  author={Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2103.03874},
  year={2021}
}

@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}

@article{thoppilan2022lamda,
  title={Lamda: Language models for dialog applications},
  author={Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and others},
  journal={arXiv preprint arXiv:2201.08239},
  year={2022}
}


@article{chowdhery2023palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={240},
  pages={1--113},
  year={2023}
}

@article{manyika2023overview,
  title={An overview of Bard: an early experiment with generative AI},
  author={Manyika, James and Hsiao, Sissie},
  journal={AI. Google Static Documents},
  volume={2},
  year={2023}
}

@article{hoffmann2022training,
  title={Training compute-optimal large language models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={arXiv preprint arXiv:2203.15556},
  year={2022}
}

@article{rae2021scaling,
  title={Scaling language models: Methods, analysis \& insights from training gopher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
  journal={arXiv preprint arXiv:2112.11446},
  year={2021}
}


@article{shepherdmath,
  title={Math-shepherd: Verify and reinforce llms step-by-step without human annotations},
  author={Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, RX and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Y and Sui, Zhifang},
  journal={CoRR, abs/2312.08935},
  year={2023}
}


@article{llama2,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}


@misc{taori2023stanford,
  title={Stanford alpaca: An instruction-following llama model},
  author={Taori, Rohan and Gulrajani, Ishaan and Zhang, Tianyi and Dubois, Yann and Li, Xuechen and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori B},
  year={2023}
}
@article{dettmers2023qlora,
  title={Qlora: Efficient finetuning of quantized llms},
  author={Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2305.14314},
  year={2023}
}
@article{chiang2023vicuna,
  title={Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality},
  author={Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E and others},
  journal={See https://vicuna. lmsys. org (accessed 14 April 2023)},
  year={2023}
}

@article{xu2023wizardlm,
  title={Wizardlm: Empowering large language models to follow complex instructions},
  author={Xu, Can and Sun, Qingfeng and Zheng, Kai and Geng, Xiubo and Zhao, Pu and Feng, Jiazhan and Tao, Chongyang and Jiang, Daxin},
  journal={arXiv preprint arXiv:2304.12244},
  year={2023}
}

@article{zeng2022glm,
  title={Glm-130b: An open bilingual pre-trained model},
  author={Zeng, Aohan and Liu, Xiao and Du, Zhengxiao and Wang, Zihan and Lai, Hanyu and Ding, Ming and Yang, Zhuoyi and Xu, Yifan and Zheng, Wendi and Xia, Xiao and others},
  journal={arXiv preprint arXiv:2210.02414},
  year={2022}
}
@misc{GPT-J,
  title={GPT-J-6B: A 6 billion parameter autoregressive language model},
  author={Wang, Ben and Komatsuzaki, Aran},
  year={2021}
}


@article{black2022gpt,
  title={Gpt-neox-20b: An open-source autoregressive language model},
  author={Black, Sid and Biderman, Stella and Hallahan, Eric and Anthony, Quentin and Gao, Leo and Golding, Laurence and He, Horace and Leahy, Connor and McDonell, Kyle and Phang, Jason and others},
  journal={arXiv preprint arXiv:2204.06745},
  year={2022}
}


@article{workshop2022bloom,
  title={Bloom: A 176b-parameter open-access multilingual language model},
  author={Workshop, BigScience and Scao, Teven Le and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c{c}}ois and others},
  journal={arXiv preprint arXiv:2211.05100},
  year={2022}
}






@article{lu2022survey,
  title={A survey of deep learning for mathematical reasoning},
  author={Lu, Pan and Qiu, Liang and Yu, Wenhao and Welleck, Sean and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:2212.10535},
  year={2022}
}


@article{zhang2022automatic,
  title={Automatic chain of thought prompting in large language models},
  author={Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Smola, Alex},
  journal={arXiv preprint arXiv:2210.03493},
  year={2022}
}




@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {$L_1$}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
  url={https://dl.acm.org/doi/abs/10.1145/1273496.1273501}
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK},
    url={https://www.cambridge.org/core/books/algorithms-on-strings-trees-and-sequences/F0B095049C7E6EF5356F0A26686C20D3}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005},
	url={https://www.jmlr.org/papers/volume6/ando05a/ando05a.pdf}
}

@article{ct1965,
  title={An algorithm for the machine calculation of complex {F}ourier series},
  author={Cooley, James W. and Tukey, John W.},
  journal={Mathematics of Computation},
  volume={19},
  number={90},
  pages={297--301},
  year={1965},
  url={https://www.ams.org/journals/mcom/1965-19-090/S0025-5718-1965-0178586-1/S0025-5718-1965-0178586-1.pdf}
}



@article{yao2022react,
  title={React: Synergizing reasoning and acting in language models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  journal={arXiv preprint arXiv:2210.03629},
  year={2022}
}

@book{daniel2017thinking,
  title={Thinking, fast and slow},
  author={Daniel, Kahneman},
  year={2017}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{schulmanreinforcement,
  title={Reinforcement learning from human feedback: Progress and challenges, 2023},
  author={Schulman, John},
  journal={URL https://www. youtube. com/watch}
}


@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}

@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}

@article{zhou2023solving,
  title={Solving challenging math word problems using gpt-4 code interpreter with code-based self-verification},
  author={Zhou, Aojun and Wang, Ke and Lu, Zimu and Shi, Weikang and Luo, Sichun and Qin, Zipeng and Lu, Shaoqing and Jia, Anya and Song, Linqi and Zhan, Mingjie and others},
  journal={arXiv preprint arXiv:2308.07921},
  year={2023}
}

@article{chung2024scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={70},
  pages={1--53},
  year={2024}
}

@inproceedings{zelikman2022star,
  title={Star: Self-taught reasoner bootstrapping reasoning with reasoning},
  author={Zelikman, Eric and Wu, Yuhuai and Mu, Jesse and Goodman, Noah D},
  booktitle={Proceedings of the 36th International Conference on Neural Information Processing Systems},
  pages={15476--15488},
  year={2022}
}


@article{bai2023qwen,
  title={Qwen technical report},
  author={Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and others},
  journal={arXiv preprint arXiv:2309.16609},
  year={2023}
}

@article{mosaicml2023introducing,
  title={Introducing mpt-7b: A new standard for open-source, commercially usable llms, 2023},
  author={MosaicML NLP Team and others},
  journal={URL www. mosaicml. com/blog/mpt-7b. Accessed},
  pages={05--05},
  year={2023}
}

@article{penedo2023refinedweb,
  title={The RefinedWeb dataset for Falcon LLM: outperforming curated corpora with web data, and web data only},
  author={Penedo, Guilherme and Malartic, Quentin and Hesslow, Daniel and Cojocaru, Ruxandra and Cappelli, Alessandro and Alobeidli, Hamza and Pannier, Baptiste and Almazrouei, Ebtesam and Launay, Julien},
  journal={arXiv preprint arXiv:2306.01116},
  year={2023}
}


@article{yue2023mammoth,
  title={Mammoth: Building math generalist models through hybrid instruction tuning},
  author={Yue, Xiang and Qu, Xingwei and Zhang, Ge and Fu, Yao and Huang, Wenhao and Sun, Huan and Su, Yu and Chen, Wenhu},
  journal={arXiv preprint arXiv:2309.05653},
  year={2023}
}

@article{bi2024deepseek,
  title={Deepseek llm: Scaling open-source language models with longtermism},
  author={Bi, Xiao and Chen, Deli and Chen, Guanting and Chen, Shanhuang and Dai, Damai and Deng, Chengqi and Ding, Honghui and Dong, Kai and Du, Qiushi and Fu, Zhe and others},
  journal={arXiv preprint arXiv:2401.02954},
  year={2024}
}

@article{xu2024chatglm,
  title={ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline},
  author={Xu, Yifan and Liu, Xiao and Liu, Xinghan and Hou, Zhenyu and Li, Yueyan and Zhang, Xiaohan and Wang, Zihan and Zeng, Aohan and Du, Zhengxiao and Zhao, Wenyi and others},
  journal={arXiv preprint arXiv:2404.02893},
  year={2024}
}


@article{luo2023wizardmath,
  title={Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct},
  author={Luo, Haipeng and Sun, Qingfeng and Xu, Can and Zhao, Pu and Lou, Jianguang and Tao, Chongyang and Geng, Xiubo and Lin, Qingwei and Chen, Shifeng and Zhang, Dongmei},
  journal={arXiv preprint arXiv:2308.09583},
  year={2023}
}



@inproceedings{yang2019unremarkable,
  title={Unremarkable AI: Fitting intelligent decision support into critical, clinical decision-making processes},
  author={Yang, Qian and Steinfeld, Aaron and Zimmerman, John},
  booktitle={Proceedings of the 2019 CHI conference on human factors in computing systems},
  pages={1--11},
  year={2019}
}

@inproceedings{ribeiro2016should,
  title={" Why should i trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}

@inproceedings{wang2020human,
  title={From human-human collaboration to Human-AI collaboration: Designing AI systems that can work together with people},
  author={Wang, Dakuo and Churchill, Elizabeth and Maes, Pattie and Fan, Xiangmin and Shneiderman, Ben and Shi, Yuanchun and Wang, Qianying},
  booktitle={Extended abstracts of the 2020 CHI conference on human factors in computing systems},
  pages={1--6},
  year={2020}
}

@article{lee2023rlaif,
  title={Rlaif: Scaling reinforcement learning from human feedback with ai feedback},
  author={Lee, Harrison and Phatale, Samrat and Mansoor, Hassan and Lu, Kellie and Mesnard, Thomas and Bishop, Colton and Carbune, Victor and Rastogi, Abhinav},
  journal={arXiv preprint arXiv:2309.00267},
  year={2023}
}

@article{marion2023less,
  title={When less is more: Investigating data pruning for pretraining llms at scale},
  author={Marion, Max and {\"U}st{\"u}n, Ahmet and Pozzobon, Luiza and Wang, Alex and Fadaee, Marzieh and Hooker, Sara},
  journal={arXiv preprint arXiv:2309.04564},
  year={2023}
}

@article{shinn2024reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{azerbayev2023llemma,
  title={Llemma: An open language model for mathematics},
  author={Azerbayev, Zhangir and Schoelkopf, Hailey and Paster, Keiran and Santos, Marco Dos and McAleer, Stephen and Jiang, Albert Q and Deng, Jia and Biderman, Stella and Welleck, Sean},
  journal={arXiv preprint arXiv:2310.10631},
  year={2023}
}

@article{mitra2024orca,
  title={Orca-Math: Unlocking the potential of SLMs in Grade School Math},
  author={Mitra, Arindam and Khanpour, Hamed and Rosset, Corby and Awadallah, Ahmed},
  journal={arXiv preprint arXiv:2402.14830},
  year={2024}
}

@article{lu2024mathgenie,
  title={MathGenie: Generating Synthetic Data with Question Back-translation for Enhancing Mathematical Reasoning of LLMs},
  author={Lu, Zimu and Zhou, Aojun and Ren, Houxing and Wang, Ke and Shi, Weikang and Pan, Junting and Zhan, Mingjie and Li, Hongsheng},
  journal={arXiv preprint arXiv:2402.16352},
  year={2024}
}

@article{liu2023tinygsm,
  title={Tinygsm: achieving> 80\% on gsm8k with small language models},
  author={Liu, Bingbin and Bubeck, Sebastien and Eldan, Ronen and Kulkarni, Janardhan and Li, Yuanzhi and Nguyen, Anh and Ward, Rachel and Zhang, Yi},
  journal={arXiv preprint arXiv:2312.09241},
  year={2023}
}

@article{yao2024tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@article{bubeck2023sparks,
  title={Sparks of artificial general intelligence: Early experiments with gpt-4},
  author={Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and others},
  journal={arXiv preprint arXiv:2303.12712},
  year={2023}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}


@article{hagendorff2022thinking,
  title={Thinking Fast and Slow in Large Language Models},
  author={Hagendorff, Thilo and Fabi, Sarah and Kosinski, Michal},
  journal={arXiv preprint arXiv:2212.05206},
  year={2022}
}

@inproceedings{fu2024drive,
  title={Drive like a human: Rethinking autonomous driving with large language models},
  author={Fu, Daocheng and Li, Xin and Wen, Licheng and Dou, Min and Cai, Pinlong and Shi, Botian and Qiao, Yu},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={910--919},
  year={2024}
}

@inproceedings{yang2024embodied,
  title={Embodied multi-modal agent trained by an llm from a parallel textworld},
  author={Yang, Yijun and Zhou, Tianyi and Li, Kanxue and Tao, Dapeng and Li, Lusong and Shen, Li and He, Xiaodong and Jiang, Jing and Shi, Yuhui},
  booktitle={CVPR},
  year={2024}
}

@article{brohan2023rt,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}

@article{hicke2023chata,
  title={ChaTA: Towards an Intelligent Question-Answer Teaching Assistant using Open-Source LLMs},
  author={Hicke, Yann and Agarwal, Anmol and Ma, Qianou and Denny, Paul},
  journal={arXiv preprint arXiv:2311.02775},
  year={2023}
}

@article{wang2023mathcoder,
  title={Mathcoder: Seamless code integration in llms for enhanced mathematical reasoning},
  author={Wang, Ke and Ren, Houxing and Zhou, Aojun and Lu, Zimu and Luo, Sichun and Shi, Weikang and Zhang, Renrui and Song, Linqi and Zhan, Mingjie and Li, Hongsheng},
  journal={arXiv preprint arXiv:2310.03731},
  year={2023}
}

@article{xie2024monte,
  title={Monte Carlo Tree Search Boosts Reasoning via Iterative Preference Learning},
  author={Xie, Yuxi and Goyal, Anirudh and Zheng, Wenyue and Kan, Min-Yen and Lillicrap, Timothy P and Kawaguchi, Kenji and Shieh, Michael},
  journal={arXiv preprint arXiv:2405.00451},
  year={2024}
}

@article{chen2024tree,
  title={When is Tree Search Useful for LLM Planning? It Depends on the Discriminator},
  author={Chen, Ziru and White, Michael and Mooney, Raymond and Payani, Ali and Su, Yu and Sun, Huan},
  journal={arXiv preprint arXiv:2402.10890},
  year={2024}
}

@article{brandfonbrener2024verified,
  title={Verified Multi-Step Synthesis using Large Language Models and Monte Carlo Tree Search},
  author={Brandfonbrener, David and Raja, Sibi and Prasad, Tarun and Loughridge, Chloe and Yang, Jianang and Henniger, Simon and Byrd, William E and Zinkov, Robert and Amin, Nada},
  journal={arXiv preprint arXiv:2402.08147},
  year={2024}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@inproceedings{joshi2023improving,
  title={Improving Multi-Hop Reasoning in LLMs by Learning from Rich Human Feedback},
  author={Joshi, Nitish and Kalyanaraman, Koushik and Hu, Zhiting and Chellapilla, Kumar and He, He and Li, Li Erran},
  booktitle={Neuro-Symbolic Learning and Reasoning in the era of Large Language Models},
  year={2023}
}

@inproceedings{wang2024human,
  title={Human-LLM collaborative annotation through effective verification of LLM labels},
  author={Wang, Xinru and Kim, Hannah and Rahman, Sajjadur and Mitra, Kushan and Miao, Zhengjie},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--21},
  year={2024}
}

@inproceedings{huang2023chatgpt,
  title={Is chatgpt better than human annotators? potential and limitations of chatgpt in explaining implicit hate speech},
  author={Huang, Fan and Kwak, Haewoon and An, Jisun},
  booktitle={Companion proceedings of the ACM web conference 2023},
  pages={294--297},
  year={2023}
}


@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{jin2024impact,
  title={The impact of reasoning step length on large language models},
  author={Jin, Mingyu and Yu, Qinkai and Zhao, Haiyan and Hua, Wenyue and Meng, Yanda and Zhang, Yongfeng and Du, Mengnan and others},
  journal={arXiv preprint arXiv:2401.04925},
  year={2024}
}

@article{toshniwal2024openmathinstruct,
  title={Openmathinstruct-1: A 1.8 million math instruction tuning dataset},
  author={Toshniwal, Shubham and Moshkov, Ivan and Narenthiran, Sean and Gitman, Daria and Jia, Fei and Gitman, Igor},
  journal={arXiv preprint arXiv:2402.10176},
  year={2024}
}

@article{yuan2023scaling,
  title={Scaling relationship on learning mathematical reasoning with large language models},
  author={Yuan, Zheng and Yuan, Hongyi and Li, Chengpeng and Dong, Guanting and Lu, Keming and Tan, Chuanqi and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.01825},
  year={2023}
}

@article{lecun2022path,
  title={A path towards autonomous machine intelligence version 0.9. 2, 2022-06-27},
  author={LeCun, Yann},
  journal={Open Review},
  volume={62},
  number={1},
  pages={1--62},
  year={2022}
}


@article{weston2023system,
  title={System 2 Attention (is something you might need too)},
  author={Weston, Jason and Sukhbaatar, Sainbayar},
  journal={arXiv preprint arXiv:2311.11829},
  year={2023}
}


@article{yu2024distilling,
  title={Distilling system 2 into system 1},
  author={Yu, Ping and Xu, Jing and Weston, Jason and Kulikov, Ilia},
  journal={arXiv preprint arXiv:2407.06023},
  year={2024}
}

@article{Azerbayev2023LlemmaAO,
  title={Llemma: An Open Language Model For Mathematics},
  author={Zhangir Azerbayev and Hailey Schoelkopf and Keiran Paster and Marco Dos Santos and Stephen Marcus McAleer and Albert Q. Jiang and Jia Deng and Stella Biderman and Sean Welleck},
  journal={ArXiv},
  year={2023},
  volume={abs/2310.10631},
  url={https://api.semanticscholar.org/CorpusID:264172303}
}

@article{Brown2020LanguageMA,
  title={Language Models are Few-Shot Learners},
  author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeff Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Ma-teusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  journal={ArXiv},
  year={2020},
  volume={abs/2005.14165},
  url={https://api.semanticscholar.org/CorpusID:218971783}
}

@article{wang2024chain,
  title={Chain-of-thought reasoning without prompting},
  author={Wang, Xuezhi and Zhou, Denny},
  journal={arXiv preprint arXiv:2402.10200},
  year={2024}
}

@article{zhou2024wall,
  title={WALL-E: World Alignment by Rule Learning Improves World Model-based LLM Agents},
  author={Zhou, Siyu and Zhou, Tianyi and Yang, Yijun and Long, Guodong and Ye, Deheng and Jiang, Jing and Zhang, Chengqi},
  journal={arXiv preprint arXiv:2410.07484},
  year={2024}
}

@article{gao2024embedding,
  title={Embedding Self-Correction as an Inherent Ability in Large Language Models for Enhanced Mathematical Reasoning},
  author={Gao, Kuofeng and Cai, Huanqia and Shuai, Qingyao and Gong, Dihong and Li, Zhifeng},
  journal={arXiv preprint arXiv:2410.10735},
  year={2024}
}

@book{stern1912psychologischen,
  title={Die psychologischen Methoden der Intelligenzpr{\"u}fung und deren Anwendung an Schulkindern},
  author={Stern, William},
  volume={5},
  year={1912},
  publisher={JA Barth}
}

@article{carpenter1990one,
  title={What one intelligence test measures: a theoretical account of the processing in the Raven Progressive Matrices Test.},
  author={Carpenter, Patricia A and Just, Marcel A and Shell, Peter},
  journal={Psychological review},
  volume={97},
  number={3},
  pages={404},
  year={1990},
  publisher={American Psychological Association}
}

@incollection{raven2003raven,
  title={Raven progressive matrices},
  author={Raven, Jean},
  booktitle={Handbook of nonverbal assessment},
  pages={223--237},
  year={2003},
  publisher={Springer}
}

@article{bilker2012development,
  title={Development of abbreviated nine-item forms of the Raven’s standard progressive matrices test},
  author={Bilker, Warren B and Hansen, John A and Brensinger, Colleen M and Richard, Jan and Gur, Raquel E and Gur, Ruben C},
  journal={Assessment},
  volume={19},
  number={3},
  pages={354--369},
  year={2012},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@inproceedings{zhang2019raven,
  title={Raven: A dataset for relational and analogical visual reasoning},
  author={Zhang, Chi and Gao, Feng and Jia, Baoxiong and Zhu, Yixin and Zhu, Song-Chun},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5317--5327},
  year={2019}
}

@inproceedings{evans1964heuristic,
  title={A heuristic program to solve geometric-analogy problems},
  author={Evans, Thomas G},
  booktitle={Proceedings of the April 21-23, 1964, spring joint computer conference},
  pages={327--338},
  year={1964}
}

@misc{thurstone1941factorial,
  title={Factorial studies of Intelligence},
  author={Thurstone, LL},
  year={1941},
  publisher={University of Chicago press}
}

@article{hoshen2017iq,
  title={Iq of neural networks},
  author={Hoshen, Dokhyam and Werman, Michael},
  journal={arXiv preprint arXiv:1710.01692},
  year={2017}
}

@article{malkinski2023review,
  title={A review of emerging research directions in abstract visual reasoning},
  author={Ma{\l}ki{\'n}ski, Miko{\l}aj and Ma{\'n}dziuk, Jacek},
  journal={Information Fusion},
  volume={91},
  pages={713--736},
  year={2023},
  publisher={Elsevier}
}

@article{hill2019learning,
  title={Learning to make analogies by contrasting abstract relational structure},
  author={Hill, Felix and Santoro, Adam and Barrett, David GT and Morcos, Ari S and Lillicrap, Timothy},
  journal={arXiv preprint arXiv:1902.00120},
  year={2019}
}

@inproceedings{zhang2020machine,
  title={Machine number sense: A dataset of visual arithmetic problems for abstract and relational reasoning},
  author={Zhang, Wenhe and Zhang, Chi and Zhu, Yixin and Zhu, Song-Chun},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={02},
  pages={1332--1340},
  year={2020}
}




@article{jiang2024marvel,
  title={MARVEL: Multidimensional Abstraction and Reasoning through Visual Evaluation and Learning},
  author={Jiang, Yifan and Zhang, Jiarui and Sun, Kexuan and Sourati, Zhivar and Ahrabian, Kian and Ma, Kaixin and Ilievski, Filip and Pujara, Jay},
  journal={arXiv preprint arXiv:2404.13591},
  year={2024}
}

@article{lu2023mathvista,
  title={Mathvista: Evaluating mathematical reasoning of foundation models in visual contexts},
  author={Lu, Pan and Bansal, Hritik and Xia, Tony and Liu, Jiacheng and Li, Chunyuan and Hajishirzi, Hannaneh and Cheng, Hao and Chang, Kai-Wei and Galley, Michel and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2310.02255},
  year={2023}
}

@inproceedings{wang2015automatic,
  title={Automatic generation of raven’s progressive matrices},
  author={Wang, Ke and Su, Zhendong},
  booktitle={Twenty-fourth international joint conference on artificial intelligence},
  year={2015}
}

@inproceedings{mandziuk2019deepiq,
  title={DeepIQ: A human-inspired AI system for solving IQ test problems},
  author={Ma{\'n}dziuk, Jacek and {\.Z}ychowski, Adam},
  booktitle={2019 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2019},
  organization={IEEE}
}

@inproceedings{webb2020learning,
  title={Learning representations that support extrapolation},
  author={Webb, Taylor and Dulberg, Zachary and Frankland, Steven and Petrov, Alexander and O’Reilly, Randall and Cohen, Jonathan},
  booktitle={International conference on machine learning},
  pages={10136--10146},
  year={2020},
  organization={PMLR}
}

@article{lipton2004discrimination,
  title={Discrimination of large and small numerosities by human infants},
  author={Lipton, Jennifer S and Spelke, Elizabeth S},
  journal={Infancy},
  volume={5},
  number={3},
  pages={271--290},
  year={2004},
  publisher={Taylor \& Francis}
}

@article{chollet2019measure,
  title={On the measure of intelligence},
  author={Chollet, Fran{\c{c}}ois},
  journal={arXiv preprint arXiv:1911.01547},
  year={2019}
}

@article{kazemi2023geomverse,
  title={Geomverse: A systematic evaluation of large models for geometric reasoning},
  author={Kazemi, Mehran and Alvari, Hamidreza and Anand, Ankit and Wu, Jialin and Chen, Xi and Soricut, Radu},
  journal={arXiv preprint arXiv:2312.12241},
  year={2023}
}


@inproceedings{yue2024mmmu,
  title={Mmmu: A massive multi-discipline multimodal understanding and reasoning benchmark for expert agi},
  author={Yue, Xiang and Ni, Yuansheng and Zhang, Kai and Zheng, Tianyu and Liu, Ruoqi and Zhang, Ge and Stevens, Samuel and Jiang, Dongfu and Ren, Weiming and Sun, Yuxuan and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9556--9567},
  year={2024}
}
@article{ahrabian2024curious,
  title={The curious case of nonverbal abstract reasoning with multi-modal large language models},
  author={Ahrabian, Kian and Sourati, Zhivar and Sun, Kexuan and Zhang, Jiarui and Jiang, Yifan and Morstatter, Fred and Pujara, Jay},
  journal={arXiv preprint arXiv:2401.12117},
  year={2024}
}

@inproceedings{liu2025mmbench,
  title={Mmbench: Is your multi-modal model an all-around player?},
  author={Liu, Yuan and Duan, Haodong and Zhang, Yuanhan and Li, Bo and Zhang, Songyang and Zhao, Wangbo and Yuan, Yike and Wang, Jiaqi and He, Conghui and Liu, Ziwei and others},
  booktitle={European conference on computer vision},
  pages={216--233},
  year={2025},
  organization={Springer}
}

@article{snow1984topography,
  title={The topography of ability and learning correlations},
  author={Snow, RE},
  journal={Advances in the psychology of human intelligence/Erlbaum},
  year={1984}
}



@article{fleuret2011comparing,
  title={Comparing machines and humans on a visual categorization test},
  author={Fleuret, Fran{\c{c}}ois and Li, Ting and Dubout, Charles and Wampler, Emma K and Yantis, Steven and Geman, Donald},
  journal={Proceedings of the National Academy of Sciences},
  volume={108},
  number={43},
  pages={17621--17625},
  year={2011},
  publisher={National Acad Sciences}
}

@article{van2021much,
  title={How much intelligence is there in artificial intelligence? A 2020 update},
  author={Van der Maas, Han LJ and Snoek, Lukas and Stevenson, Claire E},
  journal={Intelligence},
  volume={87},
  pages={101548},
  year={2021},
  publisher={Elsevier}
}

@article{malkinski2022deep,
  title={Deep learning methods for abstract visual reasoning: A survey on raven's progressive matrices},
  author={Ma{\l}ki{\'n}ski, Miko{\l}aj and Ma{\'n}dziuk, Jacek},
  journal={arXiv preprint arXiv:2201.12382},
  year={2022}
}

@article{liu2023hidden,
  title={On the hidden mystery of ocr in large multimodal models},
  author={Liu, Yuliang and Li, Zhang and Yang, Biao and Li, Chunyuan and Yin, Xucheng and Liu, Cheng-lin and Jin, Lianwen and Bai, Xiang},
  journal={arXiv preprint arXiv:2305.07895},
  year={2023}
}

@article{malkinski2024reasoning,
  title={Reasoning Limitations of Multimodal Large Language Models. A case study of Bongard Problems},
  author={Ma{\l}ki{\'n}ski, Miko{\l}aj and Pawlonka, Szymon and Ma{\'n}dziuk, Jacek},
  journal={arXiv preprint arXiv:2411.01173},
  year={2024}
}

@article{mitchell2021abstraction,
  title={Abstraction and analogy-making in artificial intelligence},
  author={Mitchell, Melanie},
  journal={Annals of the New York Academy of Sciences},
  volume={1505},
  number={1},
  pages={79--101},
  year={2021},
  publisher={Wiley Online Library}
}

@article{nie2020bongard,
  title={Bongard-logo: A new benchmark for human-level concept learning and reasoning},
  author={Nie, Weili and Yu, Zhiding and Mao, Lei and Patel, Ankit B and Zhu, Yuke and Anandkumar, Anima},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={16468--16480},
  year={2020}
}


@techreport{bongard1968recognition,
    title = {The recognition problem},
    author = {Bongard, Mikhail Moiseevich},
    year = {1968},
    institution = {Foreign Technology Div Wright-Patterson AFB Ohio}
}

@misc{qvq-72b-preview,
    title = {QVQ: To See the World with Wisdom},
    url = {https://qwenlm.github.io/blog/qvq-72b-preview/},
    author = {Qwen Team},
    month = {December},
    year = {2024}
}

@article{Qwen2VL,
  title={Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and Fan, Yang and Dang, Kai and Du, Mengfei and Ren, Xuancheng and Men, Rui and Liu, Dayiheng and Zhou, Chang and Zhou, Jingren and Lin, Junyang},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}

@misc{liu2024llavanext,
    title={LLaVA-NeXT: Improved reasoning, OCR, and world knowledge},
    url={https://llava-vl.github.io/blog/2024-01-30-llava-next/},
    author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Li, Bo and Zhang, Yuanhan and Shen, Sheng and Lee, Yong Jae},
    month={January},
    year={2024}
}


@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and Millican, Katie and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@misc{anthropic_claude3,
  author = {{Anthropic}},
  title = {{The Claude 3 Model Family: Opus, Sonnet, Haiku}},
  howpublished = {\url{https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf}},
  year = {2024},
  note = {Accessed: 2025-01-11}
}

@article{wang2023amber,
  title={Amber: An llm-free multi-dimensional benchmark for mllms hallucination evaluation},
  author={Wang, Junyang and Wang, Yuhang and Xu, Guohai and Zhang, Jing and Gu, Yukai and Jia, Haitao and Yan, Ming and Zhang, Ji and Sang, Jitao},
  journal={arXiv preprint arXiv:2311.07397},
  year={2023}
}

@article{fu2024video,
  title={Video-mme: The first-ever comprehensive evaluation benchmark of multi-modal llms in video analysis},
  author={Fu, Chaoyou and Dai, Yuhan and Luo, Yongdong and Li, Lei and Ren, Shuhuai and Zhang, Renrui and Wang, Zihan and Zhou, Chenyu and Shen, Yunhang and Zhang, Mengdan and others},
  journal={arXiv preprint arXiv:2405.21075},
  year={2024}
}

@article{li2023comprehensive,
  title={A comprehensive study of GPT-4V's multimodal capabilities in medical imaging},
  author={Li, Yingshu and Liu, Yunyi and Wang, Zhanyu and Liang, Xinyu and Liu, Lingqiao and Wang, Lei and Cui, Leyang and Tu, Zhaopeng and Wang, Longyue and Zhou, Luping},
  journal={medRxiv},
  pages={2023--11},
  year={2023},
  publisher={Cold Spring Harbor Laboratory Press}
}

@article{zhang2024mme,
  title={MME-RealWorld: Could Your Multimodal LLM Challenge High-Resolution Real-World Scenarios that are Difficult for Humans?},
  author={Zhang, Yi-Fan and Zhang, Huanyu and Tian, Haochen and Fu, Chaoyou and Zhang, Shuangqing and Wu, Junfei and Li, Feng and Wang, Kun and Wen, Qingsong and Zhang, Zhang and others},
  journal={arXiv preprint arXiv:2408.13257},
  year={2024}
}

@inproceedings{hu2021stratified,
  title={Stratified rule-aware network for abstract visual reasoning},
  author={Hu, Sheng and Ma, Yuqing and Liu, Xianglong and Wei, Yanlu and Bai, Shihao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={2},
  pages={1567--1574},
  year={2021}
}

@article{yin2023survey,
  title={A survey on multimodal large language models},
  author={Yin, Shukang and Fu, Chaoyou and Zhao, Sirui and Li, Ke and Sun, Xing and Xu, Tong and Chen, Enhong},
  journal={arXiv preprint arXiv:2306.13549},
  year={2023}
}

@inproceedings{tai2024link,
  title={Link-context learning for multimodal llms},
  author={Tai, Yan and Fan, Weichen and Zhang, Zhao and Liu, Ziwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={27176--27185},
  year={2024}
}


@article{liu2020logiqa,
  title={Logiqa: A challenge dataset for machine reading comprehension with logical reasoning},
  author={Liu, Jian and Cui, Leyang and Liu, Hanmeng and Huang, Dandan and Wang, Yile and Zhang, Yue},
  journal={arXiv preprint arXiv:2007.08124},
  year={2020}
}

@article{zhang2024cmmmu,
  title={Cmmmu: A chinese massive multi-discipline multimodal understanding benchmark},
  author={Zhang, Ge and Du, Xinrun and Chen, Bei and Liang, Yiming and Luo, Tongxu and Zheng, Tianyu and Zhu, Kang and Cheng, Yuyang and Xu, Chunpu and Guo, Shuyue and others},
  journal={arXiv preprint arXiv:2401.11944},
  year={2024}
}

@article{checa2015role,
  title={The role of intelligence quotient and emotional intelligence in cognitive control processes},
  author={Checa, Purificaci{\'o}n and Fern{\'a}ndez-Berrocal, Pablo},
  journal={Frontiers in psychology},
  volume={6},
  pages={1853},
  year={2015},
  publisher={Frontiers Media SA}
}

@article{raven2000raven,
  title={The Raven's progressive matrices: change and stability over culture and time},
  author={Raven, John},
  journal={Cognitive psychology},
  volume={41},
  number={1},
  pages={1--48},
  year={2000},
  publisher={Elsevier}
}