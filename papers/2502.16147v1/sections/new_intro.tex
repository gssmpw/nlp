Large language models (LLMs) have demonstrated impressive capabilities in natural language processing tasks \cite{touvron2023llama1,achiam2023gpt}, yet their internal representations of abstract concepts, i.e., numbers, space, and time, remain largely opaque. Recent research suggests that LLMs construct structured "world models," encoding relationships in ways that can be systematically analyzed \cite{petroni2019language,radford2019language}. For instance, studies have shown that spatial and geographical information is embedded in low-dimensional subspaces, where model performance correlates with data exposure \cite{gurneelanguage,godey2024scaling}. Similarly, numerical representation is influenced by tokenization strategies, with base-10 encoding proving more efficient for numeric reasoning tasks than higher-base tokenizations \cite{zhou2024scaling}.

The \textit{linear hypothesis} of internal representations \cite{park2023linear} posits that concepts in LLMs are structured within geometric, linear subspaces, facilitating interpretability and manipulation. This framework suggests that numerical properties follow systematic, monotonic trends \cite{heinzerling2024monotonic}. As a result, it has been commonly assumed that numerical values are represented in a uniform linear fashion \cite{zhu2025language}. However, recent probing studies \cite{zhu2025language,levy2024language} challenge this assumption, revealing a non-uniform encoding of numbers in LLMs, where precision decreases for larger values. These findings raise questions about how artificial systems internalize numerical representations, particularly in relation to the scaling of numbers. Do LLMs preserve a uniform spacing of numerical values, and if not, what is the nature of their positioning?

% Do LLMs preserve a uniform spacing of numerical values, or does their representation become increasingly compressed as magnitudes grow? 

% To what extent does the structure of these representations depend on the range and distribution of numbers encountered during training? These questions naturally lead to an investigation of whether LLMs encode numerical values in a manner similar to human cognition, as suggested by the \textit{logarithmic mental number line hypothesis}.
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/log_mental_line.png} % Replace 'example-image' with your image filename
    \caption{\textit{Logarthmic mental number line hypothesis} asserts that humans innately percieve numbers on a logarithmic scale. Image source \cite{fritz2013development}.}
    \label{fig log line}
\end{figure}

Such questions naturally lead to an investigation of whether LLMs encode numerical values in a way that mirrors human cognition, as suggested by the \textit{logarithmic mental number line hypothesis}. This hypothesis posits that humans perceive numerical magnitudes nonlinearly, following a logarithmic rather than a uniform linear scale (see Figure \ref{fig log line}). Rooted in psychophysical studies like the Fechner-Weber law, this idea is supported by behavioral experiments showing that young children and individuals with limited formal education tend to map numbers logarithmically when placing them on a spatial axis \cite{fechner1860elemente, dehaene2003neural, siegler2003development}. While formal training shifts numerical perception toward a more linear scale, logarithmic encoding persists in tasks involving estimation and large-number processing \cite{dehaene2008log, moeller2009children}. 

% Moreover, numerical comparison tasks reveal a ratio-dependent effect, where difficulty depends on relative rather than absolute differences, further supporting the idea that human numerical intuition relies on compressed representations to optimize cognitive efficiency. 

% Such a question naturally lead to an investigation of whether LLMs encode numerical values in a manner similar to human cognition, as encapsulated by \textit{logarithmic mental number line hypothesis}.  The latter suggests that humans perceive and process numerical magnitudes in a nonlinear, logarithmic fashion, rather than on a uniform linear scale (see Figure \ref{fig log line}). This idea is rooted in psychophysical studies, particularly the Fechner-Weber law, which posits that perceived differences between stimuli follow a logarithmic relationship rather than an absolute one \cite{fechner1860elemente,dehaene2003neural}. Behavioral experiments have shown that young children and individuals from cultures with limited formal education tend to place numbers on a logarithmic scale when asked to map numerical values onto a spatial axis, suggesting that this mode of representation may be innate or cognitively efficient \cite{dehaene2008log, siegler2003development, moeller2009children}. As individuals receive formal mathematical training, their numerical perception gradually shifts toward a more linear representation, particularly for familiar ranges of numbers, though logarithmic encoding remains evident in certain contexts such as estimation and large-number processing. 

% The "linear hypothesis" of internal representations \cite{park2023linear} posits that concepts in LLMs are structured in geometric, linear subspaces, supporting interpretability and manipulation. This has led to the assumption that numerical values are encoded in a uniform linear fashion \cite{zhu2025language}. However, recent findings suggest a more nuanced picture. Probing studies \cite{zhu2025language,levy2024language} indicate that LLMs exhibit a non-uniform encoding of numbers, where precision decreases for larger values, a pattern reminiscent of logarithmic compression in human cognition. 

% This idea is rooted in psychophysical studies, particularly the Fechner-Weber law, which posits that perceived differences between stimuli follow a logarithmic relationship rather than an absolute one \cite{fechner1860elemente,dehaene2003neural}. The \textit{logarithmic mental number line hypothesis} suggests that humans perceive and process numerical magnitudes in a nonlinear, logarithmic fashion, rather than on a uniform linear scale (see Figure \ref{fig log line}).  In contrast, LLMs trained on higher-base numeral systems struggle with numerical extrapolation, reinforcing the idea that smaller values are represented with finer granularity \cite{zhou2024scaling}.


% Inspired by this we turn to artificial systems and investigate whether LLMs encode numerical values in a manner analogous to the human logarithmic mental number line. By analyzing hidden representations across model layers, we examine the geometric structure of numerical magnitudes and their underlying trends. Our approach utilizes dimensionality reduction techniques, including Principal Component Analysis (PCA) and Partial Least Squares (PLS), to extract dominant numerical features and analyze their spatial organization. While both methods reveal that numerical representations largely reside in a linear subspace, we find systematic sublinearity in their internal structure: distances between consecutive numbers decrease as values increase. Notably, we observe differences in how PCA and PLS capture this effect, indicating that while a linear transformation can expose structured numerical encoding, simple linear probes \footnote{PLS is a linear probe that first projects the input data onto a lower-dimensional subspace before maximizing the covariance with the target.} may miss the underlying non-uniformity.

Inspired by this, we investigate whether LLMs encode numerical values in a manner analogous to the human logarithmic mental number line. By analyzing hidden representations across model layers, we examine the geometric structure of numerical magnitudes and their underlying trends. Our approach first employs dimensionality reduction techniques, including Principal Component Analysis (PCA) and Partial Least Squares (PLS), to transform the hidden representations onto a one-dimensional number line, that best fits its dominant numerical features. Second, using Spearman rank coefficient and geometric non-linear regression, we specifically test whether two key properties reminiscent of human numerical cognition (order preservation in representations and a compression effect where distances between consecutive numbers decrease as values increase) emerge in LLMs.

While both PCA and PLS reveal that numerical representations largely reside in a linear subspace, only PCA captures systematic sublinearity, suggesting that simple linear probes\footnote{PLS is a linear probe that projects input data onto a lower-dimensional subspace, maximizing covariance with the target.} may overlook the underlying non-uniformity in LLMs’ numerical encoding.


% Inspired by this, we turn to artificial systems and investigate whether LLMs encode numerical values in a manner analogous to the human logarithmic mental number line. By analyzing hidden representations across model layers, we examine the geometric structure of numerical magnitudes and their underlying trends. Using dimensionality reduction techniques such as PCA to extract dominant numerical features, we test whether two key properties reminiscent of the human logarithmic mental number line—order preservation in representations and a compression effect where distances between consecutive numbers decrease as values increase—emerge in LLMs. 

% While numerical representations largely reside in a linear subspace, we find systematic sublinearity in their internal structure, suggesting a departure from uniform encoding and raising questions about the extent to which LLMs develop human-like numerical abstractions.

\paragraph{Contributions} We summarize our main finding in the following: 
\begin{itemize}
    \item
    % We refine the linear hypothesis by showing that numerical magnitude in LLMs is not uniformly spaced but exhibits structured compression, providing new insights into interpretability and numerical reasoning in LLMs.
    % We introduce a methodology to analyze the geometric structure of numerical representations, offering a framework for probing numerical abstractions in artificial neural networks.
    We introduce a methodology for analyzing the geometric structure of number representations, offering a systematic approach to studying numerical abstractions in artificial neural networks.
    \item 
    % We provide empirical evidence that LLMs encode numerical values in a structured yet non-uniform manner, aligning with the logarithmic mental number line observed in human cognition.
    We provide empirical evidence that LLMs encode numerical values in a structured yet non-uniform way, revealing systematic compression reminiscent of the human logarithmic mental number line. Our findings refine the linear hypothesis by showing that numerical magnitudes in LLMs are not evenly spaced but follow a structured compression pattern.    
\end{itemize}

\begin{figure*}[ht!]
    \centering
    \includegraphics[width=\linewidth]{figures/overview_horizontal.pdf} % Replace 'example-image' with your image filename
    \caption{The overall graphical representation of our method. Numbers are passed to the model in form of a prompt and the internal representations are captured from the embeddings corresponding to token '='. At every layer, we perform PCA projections onto one and two dimensional subspaces and pick a layer with highest explained variance ($\sigma^2$) score to further analyze monotonicity and scaling of number representations.}
    \label{fig pipeline}
\end{figure*}