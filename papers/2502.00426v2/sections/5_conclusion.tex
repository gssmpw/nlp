\section{Conclusion}
\label{conclusion}
{This work presents a novel framework, namely \testv~which \texttt{dilates} and \texttt{erodes} the support set to enhance the zero-shot generalization capability of video classification methods during test time. \testv~applies multiple prompts to enrich the support set~(\texttt{Dilation}) and then mines critical supporting samples from the support set with learnable spatio-temporal weights~(\texttt{Erosion}). Our method demonstrated superior performance to existing state-of-arts on four benchmarks. While \testv~effectively adapts pre-trained models~(i.e., CLIP) to out-of-distribution domains during test time for video data, it still has two potential limitations: \textbf{i)} extra spatio-temporal tuning costs may increase with the length of the video~(i.e., long video). \textbf{ii)} relying on the quality of LLMs and text-to-video generation models.

% \testv~includes two modules, i) Multi-prompting Support-set Dilation~(\textbf{MSD}): dilates the support set by feeding multiple descriptions into the text-to-video model to generate videos for each class; ii) Temporal-aware Support-set Erosion~(\textbf{TSE}): erodes the support set by adjusting the contribution of supporting cues with learnable weights at different temporal scales for mining action cues from the support set. 



}