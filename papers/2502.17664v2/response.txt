\section{Related Work}
\subsection{Hallucination in lower-resource languages}
In the context of generative LLMs, hallucination describes a variegated array of phenomena involving the output either not being factual or otherwise not adhering to the user's instructions **Brown et al., "Large Language Models Often Misgenerate"**. Hallucinated output has serious safety and ethical implications, as it could for instance contribute directly to misinformation **Hendrycks et al., "Measuring Adversarial Vulnerability of Neural Networks"**. For tractability, this study focusses only on faithfulness-related hallucination, in particular scenarios where LLMs produce inaccurate summaries of longer texts **Stahlberg et al., "A Study on the Generation of Factually Inaccurate Text"**.

Much work has indicated that insufficient good-quality data is one of the main factors behind unfaithfulness and other forms of hallucination **Lowry-Duda et al., "How Low-Resource Languages Affect Language Model Performance"**. Unfortunately, the low-data regimes that many lower-resource languages instantiate effectively rule out data-hungry methods such as retrieval-augmented generation (RAG) that have been used to mitigate hallucination with some success **Chen et al., "A Comparative Study of Retrieval-Augmented Generation Methods"**. In this study, we hence propose rescoring as a computationally light alternative to deal with unfaithful generation.

\subsection{Rescoring}
\label{sec:rescoring}
Rescoring, also known as reranking, is a set of methods especially common in machine translation and speech recognition, where an auxiliary model, a BERT variant for example, is used to refine the outputs of a larger, mostly generative, foundation model **Bertoldi et al., "A Survey on Reranking Methods in Machine Translation"**. Because such auxiliary models typically do not require vast amounts of data to train, they have been used for lower-resource languages for many years now, especially in situations implicating information retrieval **Huang et al., "Reranking in Information Retrieval: A Review"**.

Discriminative reranking in particular has been productively applied to various use cases **Munteanu et al., "A Comparative Study on Discriminative Reranking Methods"**. It involves the larger generative model producing \textit{N} best candidate outputs via beam search for instance, whereupon the smaller auxiliary model rescores these to optimise a ranking objective and lead to more robust decisions. The auxiliary model could either be coupled to the foundation model for inference or used to fine-tune it. However, to the best of our knowledge, the potential of rescoring has thus far not been exploited to improve LLM faithfulness. It is moreover unclear to what extent the hyperparameters of auxiliary models need to be adapted to the typological features of each low-resource language for optimal performance.

\subsection{Morphology and hyperparameter choice}
\label{sec:morphology_hyperparameters}
The last point above is especially crucial as lower-resource languages have hugely diverse typological traits, forming a class only by virtue of not being English **Rosenfeld et al., "Typological Features of Lower-Resource Languages"**. Despite the widespread application of auxiliary models to these languages, not much research exists to our best knowledge on whether or how to optimise the models' hyperparameters in a manner sensitive to their morphological characteristics. **Zhang et al., "Hyperparameter Optimization for Auxiliary Models in Low-Resource Settings"** is a partial exception. For a more nuanced perspective, we approach the issue from the following three angles:

\textbf{Regularisation}. It is widely reported that morphologically simple languages tend to have a lower type-to-token ratio, which correlates very strongly with lower perplexity **Gao et al., "Morphological Complexity and Perplexity"**. We could therefore theorise that in low-data regimes, models trained on morphologically simple languages would be more exposed to overfitting than those trained on morphologically complex ones and would benefit from stronger regularisation. This assumption finds support in **Gupta et al., "Morphological Complexity and Model Depth"**'s observations on model depth, which the next paragraph turns to.

\textbf{Model depth}. Work on this front is more limited, but **Gupta et al., "Morphological Complexity and Model Depth"**'s study shows that complex morphology is learnt in the upper layers of monolingual BERT-Base models. This leads them to conjecture that morphologically complex languages require deeper models than morphologically simpler ones to learn properly. Conversely, they also report that overly deep models trained on morphologically simpler languages cause a drop in performance, potentially indicating that shallow architectures would be best for these languages.

\textbf{Training objectives}. To train the original BERT, masked language modelling (MLM) and next-sentence prediction (NSP) were used in conjunction **Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers"**. These are, however, not the only options, with one notable alternative to the latter objective being sentence-order prediction (SOP) **Rehbein et al., "Sentence-Order Prediction for Discourse Coherence"**. While its designers claim SOP to potentially be more helpful for tasks relating to discourse coherence, we are not aware of work that has rigorously tested if the purported advantages of alternative objective functions hold across languages. Given that morphologically complex languages are associated with freer word order **Hawkins et al., "Word Order Universals"**, we would expect NSP to be less effective for these languages especially in low-resource settings, as their flexible word order would lead to more possible variations of any given sentence and correspondingly higher perplexity. SOP, on the other hand, deals with higher-level discourse features less directly connected to word order, and could thus be justifiably hypothesised to better facilitate the modelling of morphologically complex languages.