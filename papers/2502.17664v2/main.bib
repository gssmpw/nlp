@article{guerreiro2023hallucinations,
    title = "Hallucinations in Large Multilingual Translation Models",
    author = "Guerreiro, Nuno M.  and
      Alves, Duarte M.  and
      Waldendorf, Jonas  and
      Haddow, Barry  and
      Birch, Alexandra  and
      Colombo, Pierre  and
      Martins, Andr{\'e} F. T.",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "11",
    year = "2023",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2023.tacl-1.85/",
    doi = "10.1162/tacl_a_00615",
    pages = "1500--1517",
    abstract = "Hallucinated translations can severely undermine and raise safety issues when machine translation systems are deployed in the wild. Previous research on the topic focused on small bilingual models trained on high-resource languages, leaving a gap in our understanding of hallucinations in multilingual models across diverse translation scenarios. In this work, we fill this gap by conducting a comprehensive analysis{---}over 100 language pairs across various resource levels and going beyond English-centric directions{---}on both the M2M neural machine translation (NMT) models and GPT large language models (LLMs). Among several insights, we highlight that models struggle with hallucinations primarily in low-resource directions and when translating out of English, where, critically, they may reveal toxic patterns that can be traced back to the training data. We also find that LLMs produce qualitatively different hallucinations to those of NMT models. Finally, we show that hallucinations are hard to reverse by merely scaling models trained with the same data. However, employing more diverse models, trained on different data or with different procedures, as fallback systems can improve translation quality and virtually eliminate certain pathologies."
}

@inproceedings{otmakhova2022cross,
    title = "Cross-linguistic Comparison of Linguistic Feature Encoding in {BERT} Models for Typologically Different Languages",
    author = "Otmakhova, Yulia  and
      Verspoor, Karin  and
      Lau, Jey Han",
    editor = "Vylomova, Ekaterina  and
      Ponti, Edoardo  and
      Cotterell, Ryan",
    booktitle = "Proceedings of the 4th Workshop on Research in Computational Linguistic Typology and Multilingual NLP",
    month = jul,
    year = "2022",
    address = "Seattle, Washington",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.sigtyp-1.4/",
    doi = "10.18653/v1/2022.sigtyp-1.4",
    pages = "27--35",
    abstract = "Though recently there have been an increased interest in how pre-trained language models encode different linguistic features, there is still a lack of systematic comparison between languages with different morphology and syntax. In this paper, using BERT as an example of a pre-trained model, we compare how three typologically different languages (English, Korean, and Russian) encode morphology and syntax features across different layers. In particular, we contrast languages which differ in a particular aspect, such as flexibility of word order, head directionality, morphological type, presence of grammatical gender, and morphological richness, across four different tasks."
}

%Devlin et al. (2019): https://bibbase.org/service/mendeley/bfbbf840-4c42-3914-a463-19024f50b30c/file/6375d223-e085-74b3-392f-f3fed829cd72/Devlin_et_al___2019___BERT_Pre_training_of_Deep_Bidirectional_Transform.pdf.pdf
@article{devlin2019bert,
  title={{BERT}: Pre-training of deep bidirectional transformers for language understanding},
  author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  journal={arXiv preprint arXiv:1810.04805},
  year={2019},
  url={https://aclanthology.org/N19-1423/}
}

@inproceedings{berbatova2023evaluating,
    title = "Evaluating Hallucinations in Large Language Models for {B}ulgarian Language",
    author = "Berbatova, Melania  and
      Salambashev, Yoan",
    editor = "Hardalov, Momchil  and
      Kancheva, Zara  and
      Velichkov, Boris  and
      Nikolova-Koleva, Ivelina  and
      Slavcheva, Milena",
    booktitle = "Proceedings of the 8th Student Research Workshop associated with the International Conference Recent Advances in Natural Language Processing",
    month = sep,
    year = "2023",
    address = "Varna, Bulgaria",
    publisher = "INCOMA Ltd., Shoumen, Bulgaria",
    url = "https://aclanthology.org/2023.ranlp-stud.6/",
    pages = "55--63",
    abstract = "In this short paper, we introduce the task of evaluating the hallucination of large language models for the Bulgarian language. We first give definitions of what is a hallucination in large language models and what evaluation methods for measuring hallucinations exist. Next, we give an overview of the multilingual evaluation of the latest large language models, focusing on the evaluation of the performance in Bulgarian on tasks, related to hallucination. We then present a method to evaluate the level of hallucination in a given language with no reference data, and provide some initial experiments with this method in Bulgarian. Finally, we provide directions for future research on the topic."
}

@misc{leong2023bhasa,
      title={{BHASA}: A Holistic {S}outheast {A}sian Linguistic and Cultural Evaluation Suite for Large Language Models}, 
      author={Wei Qi Leong and Jian Gang Ngui and Yosephine Susanto and Hamsawardhini Rengarajan and Kengatharaiyer Sarveswaran and William Chandra Tjhi},
      year={2023},
      eprint={2309.06085},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.06085}, 
}

@article{khedar2024automatic,
title = {Automatic speech recognition using advanced deep learning approaches: A survey},
journal = {Information Fusion},
volume = {109},
pages = {102422},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102422},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524002008},
author = {Hamza Kheddar and Mustapha Hemis and Yassine Himeur},
keywords = {Automatic speech recognition, Deep transfer learning, Transformers, Federated learning, Reinforcement learning},
abstract = {Recent advancements in deep learning (DL) have posed a significant challenge for automatic speech recognition (ASR). ASR relies on extensive training datasets, including confidential ones, and demands substantial computational and storage resources. Enabling adaptive systems improves ASR performance in dynamic environments. DL techniques assume training and testing data originate from the same domain, which is not always true. Advanced DL techniques like deep transfer learning (DTL), federated learning (FL), and deep reinforcement learning (DRL) address these issues. DTL allows high-performance models using small yet related datasets, FL enables training on confidential data without dataset possession, and DRL optimizes decision-making in dynamic environments, reducing computation costs. This survey offers a comprehensive review of DTL, FL, and DRL-based ASR frameworks, aiming to provide insights into the latest developments and aid researchers and professionals in understanding the current challenges. Additionally, Transformers, which are advanced DL techniques heavily used in proposed ASR frameworks, are considered in this survey for their ability to capture extensive dependencies in the input ASR sequence. The paper starts by presenting the background of DTL, FL, DRL, and Transformers and then adopts a well-designed taxonomy to outline the state-of-the-art (SOTA) approaches. Subsequently, a critical analysis is conducted to identify the strengths and weaknesses of each framework. Additionally, a comparative study is presented to highlight the existing challenges, paving the way for future research opportunities.}
}

%Qiu et al. (2023): https://arxiv.org/pdf/2305.13632
@article{qiu2023detecting,
  title={Detecting and mitigating hallucinations in multilingual summarisation},
  author={Qiu, Yifu and Ziser, Yftah and Korhonen, Anna and Ponti, Edoardo M and Cohen, Shay B},
  journal={arXiv preprint arXiv:2305.13632},
  year={2023},
  url={https://arxiv.org/pdf/2305.13632}
}

%Huang et al. (2024): https://ar5iv.labs.arxiv.org/html/2311.05232
@article{huang2023survey,
  title={A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions},
  author={Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and others},
  journal={arXiv preprint arXiv:2311.05232},
  year={2023},
  url={https://ar5iv.labs.arxiv.org/html/2311.05232}
}

%Kirchenbauer \& Barns (2024): https://files.osf.io/v1/resources/pv7r5/providers/osfstorage/6657166cd835c421594ce333?format=pdf&action=download&direct&version=1
@article{kirchenbauer2024hallucination,
  title={Hallucination reduction in large language models with retrieval-augmented generation using {W}ikipedia knowledge},
  author={Kirchenbauer, Jason and Barns, Caleb},
  year={2024},
  publisher={OSF},
  url={https://files.osf.io/v1/resources/pv7r5/providers/osfstorage/6657166cd835c421594ce333?format=pdf&action=download&direct&version=1}
}

%Tonmoy et al. (2024) https://arxiv.org/abs/2401.01313
@misc{tonmoy2024comprehensive,
      title={A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models}, 
      author={S. M Towhidul Islam Tonmoy and S M Mehedi Zaman and Vinija Jain and Anku Rani and Vipula Rawte and Aman Chadha and Amitava Das},
      year={2024},
      eprint={2401.01313},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.01313}, 
}

%Jin et al. (2024): https://dl.acm.org/doi/pdf/10.1145/3589334.3645643
@inproceedings{jin2024better,
  title={Better to ask in English: Cross-lingual evaluation of large language models for healthcare queries},
  author={Jin, Yiqiao and Chandra, Mohit and Verma, Gaurav and Hu, Yibo and De Choudhury, Munmun and Kumar, Srijan},
  booktitle={Proceedings of the ACM on Web Conference 2024},
  pages={2627--2638},
  year={2024},
  url={https://dl.acm.org/doi/pdf/10.1145/3589334.3645643}
}

@inproceedings{mielke2019kind,
    title = "What Kind of Language Is Hard to Language-Model?",
    author = "Mielke, Sabrina J.  and
      Cotterell, Ryan  and
      Gorman, Kyle  and
      Roark, Brian  and
      Eisner, Jason",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url={https://aclanthology.org/P19-1491/},
    doi = "10.18653/v1/P19-1491",
    pages = "4975--4989",
    abstract = "How language-agnostic are current state-of-the-art NLP tools? Are there some types of language that are easier to model with current methods? In prior work (Cotterell et al., 2018) we attempted to address this question for language modeling, and observed that recurrent neural network language models do not perform equally well over all the high-resource European languages found in the Europarl corpus. We speculated that inflectional morphology may be the primary culprit for the discrepancy. In this paper, we extend these earlier experiments to cover 69 languages from 13 language families using a multilingual Bible corpus. Methodologically, we introduce a new paired-sample multiplicative mixed-effects model to obtain language difficulty coefficients from at-least-pairwise parallel corpora. In other words, the model is aware of inter-sentence variation and can handle missing data. Exploiting this model, we show that {\textquotedblleft}translationese{\textquotedblright} is not any easier to model than natively written language in a fair comparison. Trying to answer the question of what features difficult languages have in common, we try and fail to reproduce our earlier (Cotterell et al., 2018) observation about morphological complexity and instead reveal far simpler statistics of the data that seem to drive complexity in a much larger sample."
}

@Article{levshina2022frequency,
AUTHOR = {Levshina, Natalia},
TITLE = {Frequency, Informativity and Word Length: Insights from Typologically Diverse Corpora},
JOURNAL = {Entropy},
VOLUME = {24},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {280},
URL = {https://www.mdpi.com/1099-4300/24/2/280},
PubMedID = {35205578},
ISSN = {1099-4300},
ABSTRACT = {Zipf’s law of abbreviation, which posits a negative correlation between word frequency and length, is one of the most famous and robust cross-linguistic generalizations. At the same time, it has been shown that contextual informativity (average surprisal given previous context) is more strongly correlated with word length, although this tendency is not observed consistently, depending on several methodological choices. The present study examines a more diverse sample of languages than the previous studies (Arabic, Finnish, Hungarian, Indonesian, Russian, Spanish and Turkish). I use large web-based corpora from the Leipzig Corpora Collection to estimate word lengths in UTF-8 characters and in phonemes (for some of the languages), as well as word frequency, informativity given previous word and informativity given next word, applying different methods of bigrams processing. The results show different correlations between word length and the corpus-based measure for different languages. I argue that these differences can be explained by the properties of noun phrases in a language, most importantly, by the order of heads and modifiers and their relative morphological complexity, as well as by orthographic conventions.},
DOI = {10.3390/e24020280}
}


%Lan et al. (2020): https://arxiv.org/pdf/1909.11942
@article{lan2019albert,
  title={Albert: A lite {BERT} for self-supervised learning of language representations},
  author={Zhenzhong Lan and Mingda Chen and Sebastian Goodman and Kevin Gimpel and Piyush Sharma and Radu Soricut},
  journal={arXiv preprint arXiv:1909.11942},
  year={2019},
  url={https://arxiv.org/pdf/1909.11942}
}

%Nijs et al. (2025): https://pmc.ncbi.nlm.nih.gov/articles/PMC11765092/
@article{nijs2025word,
  title={Is word order responsive to morphology? {Disentangling} cause and effect in morphosyntactic change in five {Western European} languages},
  author={Nijs, Julie and Van de Velde, Freek and Cuyckens, Hubert},
  journal={Entropy},
  volume={27},
  number={1},
  pages={53},
  year={2025},
  url={https://pmc.ncbi.nlm.nih.gov/articles/PMC11765092/}
}

%Comrie (1989): Comrie, Bernard. Language universals and linguistic typology: Syntax and morphology. University of Chicago Press, 1989.
@book{comrie1989language,
  title={Language universals and linguistic typology: Syntax and morphology},
  author={Comrie, Bernard},
  year={1989},
  publisher={University of Chicago Press}
}

@inproceedings{gerz2018relation,
    title = "On the Relation between Linguistic Typology and (Limitations of) Multilingual Language Modeling",
    author = "Gerz, Daniela  and
      Vuli{\'c}, Ivan  and
      Ponti, Edoardo Maria  and
      Reichart, Roi  and
      Korhonen, Anna",
    editor = "Riloff, Ellen  and
      Chiang, David  and
      Hockenmaier, Julia  and
      Tsujii, Jun{'}ichi",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1029/",
    doi = "10.18653/v1/D18-1029",
    pages = "316--327",
    abstract = "A key challenge in cross-lingual NLP is developing general language-independent architectures that are equally applicable to any language. However, this ambition is largely hampered by the variation in structural and semantic properties, i.e. the typological profiles of the world`s languages. In this work, we analyse the implications of this variation on the language modeling (LM) task. We present a large-scale study of state-of-the art n-gram based and neural language models on 50 typologically diverse languages covering a wide variety of morphological systems. Operating in the full vocabulary LM setup focused on word-level prediction, we demonstrate that a coarse typology of morphological systems is predictive of absolute LM performance. Moreover, fine-grained typological features such as exponence, flexivity, fusion, and inflectional synthesis are borne out to be responsible for the proliferation of low-frequency phenomena which are organically difficult to model by statistical architectures, or for the meaning ambiguity of character n-grams. Our study strongly suggests that these features have to be taken into consideration during the construction of next-level language-agnostic LM architectures, capable of handling morphologically complex languages such as Tamil or Korean."
}

%Hasan et al. (2021): https://aclanthology.org/2021.findings-acl.413.pdf
@misc{hasan2021xlsum,
      title={{XL}-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages}, 
      author={Tahmid Hasan and Abhik Bhattacharjee and Md Saiful Islam and Kazi Samin and Yuan-Fang Li and Yong-Bin Kang and M. Sohel Rahman and Rifat Shahriyar},
      year={2021},
      eprint={2106.13822},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.13822}, 
}

@article{rimell2016relpron,
    author = {Rimell, Laura and Maillard, Jean and Polajnar, Tamara and Clark, Stephen},
    title = {{RELPRON}: A Relative Clause Evaluation Data Set for Compositional Distributional Semantics},
    journal = {Computational Linguistics},
    volume = {42},
    number = {4},
    pages = {661-701},
    year = {2016},
    month = {12},
    abstract = {This article introduces RELPRON, a large data set of subject and object relative clauses, for the evaluation of methods in compositional distributional semantics. RELPRON targets an intermediate level of grammatical complexity between content-word pairs and full sentences. The task involves matching terms, such as “wisdom,” with representative properties, such as “quality that experience teaches.” A unique feature of RELPRON is that it is built from attested properties, but without the need for them to appear in relative clause format in the source corpus. The article also presents some initial experiments on RELPRON, using a variety of composition methods including simple baselines, arithmetic operators on vectors, and finally, more complex methods in which argument-taking words are represented as tensors. The latter methods are based on the Categorial framework, which is described in detail. The results show that vector addition is difficult to beat—in line with the existing literature—but that an implementation of the Categorial framework based on the Practical Lexical Function model is able to match the performance of vector addition. The article finishes with an in-depth analysis of RELPRON, showing how results vary across subject and object relative clauses, across different head nouns, and how the methods perform on the subtasks necessary for capturing relative clause semantics, as well as providing a qualitative analysis highlighting some of the more common errors. Our hope is that the competitive results presented here, in which the best systems are on average ranking one out of every two properties correctly for a given term, will inspire new approaches to the RELPRON ranking task and other tasks based on linguistically interesting constructions.},
    issn = {0891-2017},
    doi = {10.1162/COLI_a_00263},
    url = {https://doi.org/10.1162/COLI\_a\_00263},
    eprint = {https://direct.mit.edu/coli/article-pdf/42/4/661/1808031/coli\_a\_00263.pdf},
}

%Edman & Bylinina (2023): https://arxiv.org/pdf/2311.01955
@article{edman2023too,
  title={Too much information: Keeping training simple for {BabyLMs}},
  author={Edman, Lukas and Bylinina, Lisa},
  journal={arXiv preprint arXiv:2311.01955},
  year={2023},
  url={https://arxiv.org/pdf/2311.01955}
}

@ONLINE{wikidump,
    author = {{Wikimedia Foundation}},
    title  = "Wikimedia Downloads",
    year   = "2023",
    url    = "https://dumps.wikimedia.org",
    note   = "Retrieved November 15, 2024"
}

@article{duc2024towards,
    title={Towards Comprehensive {Vietnamese} Retrieval-Augmented Generation and Large Language Models},
    author={Quang Duc Nguyen and Hai Son Le and Duc Nhan Nguyen and Dich Nhat Minh Nguyen and Thanh Huong Le and Viet Sang Dinh},
    journal={arXiv preprint arXiv:2403.01616},
    url = {https://arxiv.org/abs/2403.01616},
    year={2024}
}

@misc{pl-news,
  title = {{Polish news dataset}},
  author={Wiktor Sobański},
  howpublished = "\url{https://huggingface.co/datasets/WiktorS/polish-news}",
  year={2023}

}

@misc{RichNachos_Georgian_Corpus,
  author = {Giorgi Kldiashvili},
  title = {Georgian Corpus},
  year = {2024},
  publisher = {Hugging Face},
  howpublished = {\url{https://huggingface.co/datasets/RichNachos/georgian-corpus}}
}

@book{bird2009natural,
  title={Natural Language Processing with Python},
  author={Bird, Steven and Klein, Ewan and Loper, Edward},
  year={2009},
  publisher={O'Reilly Media}
}

@misc{underthesea,
  author = {Underthesea Team},
  title = {Underthesea: Vietnamese {NLP} Toolkit},
  year = {n.d.},
  publisher = {GitHub},
  howpublished = {\url{https://github.com/undertheseanlp/underthesea}}
}

@article{Nguyen2023PhoGPT,
  title   = {{PhoGPT}: Generative Pre-training for {Vietnamese}},
  author  = {Nguyen, Dat Quoc and Nguyen, Linh The and Tran, Chi and Nguyen, Dung Ngoc and Phung, Dinh and Bui, Hung},
  journal = {arXiv preprint arXiv:2311.02945},
  year    = {2023},
  url     = {https://arxiv.org/abs/2311.02945}
}

@misc{Davit6174_Georgian_DistilBERT_MLM,
  author       = {Davit Kurtskhalia},
  title        = {Georgian {DistilBERT-MLM}},
  howpublished = {\url{https://huggingface.co/Davit6174/georgian-distilbert-mlm}}, year = {n.d.}
}

@inproceedings{Mroczkowski2021HerBERT,
  title     = {{HerBERT}: Efficiently Pretrained Transformer-based Language Model for {Polish}},
  author    = {Mroczkowski, Robert and Rybak, Piotr and Wróblewska, Alina and Gawlik, Ireneusz},
  booktitle = {Proceedings of the 8th Workshop on Balto-Slavic Natural Language Processing},
  pages     = {1--10},
  year      = {2021},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.bsnlp-1.1}
}

%Google Research: https://github.com/google-research/bert#bert
@article{turc2019,
  title={Well-Read Students Learn Better: On the Importance of Pre-training Compact Models},
  author={Turc, Iulia and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1908.08962v2}, url = {https://arxiv.org/abs/1908.08962}, 
  year={2019}
}

%Wikinews contributors: Wikinews contributors. (n.d.). Wikinews. Wikimedia Foundation. Retrieved November 15, 2024, from https://www.wikinews.org
@misc{wikinews,
    author = {{Wikinews contributors}},
    title = {Wikinews},
    year = {2024},
    howpublished = {Wikimedia Foundation},
    url = {https://www.wikinews.org},
    note = {Retrieved November 15, 2024}
}

@inproceedings{arnett2025language,
    title = "Why do language models perform worse for morphologically complex languages?",
    author = "Arnett, Catherine  and
      Bergen, Benjamin",
    editor = "Rambow, Owen  and
      Wanner, Leo  and
      Apidianaki, Marianna  and
      Al-Khalifa, Hend  and
      Eugenio, Barbara Di  and
      Schockaert, Steven",
    booktitle = "Proceedings of the 31st International Conference on Computational Linguistics",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.coling-main.441/",
    pages = "6607--6623",
    abstract = "Language models perform differently across languages. It has been previously suggested that morphological typology may explain some of this variability (Cotterell et al., 2018). We replicate previous analyses and find additional new evidence for a performance gap between agglutinative and fusional languages, where fusional languages, such as English, tend to have better language modeling performance than morphologically more complex languages like Turkish. We then propose and test three possible causes for this performance gap: morphological alignment of tokenizers, tokenization quality, and disparities in dataset sizes and measurement. To test the morphological alignment hypothesis, we present MorphScore, a tokenizer evaluation metric, and supporting datasets for 22 languages. We find some evidence that tokenization quality explains the performance gap, but none for the role of morphological alignment. Instead we find that the performance gap is most reduced when training datasets are of equivalent size across language types, but only when scaled according to the so-called {\textquotedblleft}byte-premium{\textquotedblright}{---}the different encoding efficiencies of different languages and orthographies. These results suggest that languages of particular morphological types are not intrinsically advantaged or disadvantaged in language modeling. Differences in performance can be attributed to disparities in dataset size. These findings bear on ongoing efforts to improve performance for low-performing and under-resourced languages."
}

%Discriminative Reranking for Machine Translation (2004): https://aclanthology.org/N04-1023.pdf
@inproceedings{shen2004discriminative,
  title={Discriminative reranking for machine translation},
  author={Shen, Libin and Sarkar, Anoop and Och, Franz Josef},
  booktitle={Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics: HLT-NAACL 2004},
  pages={177--184},
  year={2004},
  url={https://aclanthology.org/N04-1023.pdf}
}


%Litschko et al., 2022: https://arxiv.org/pdf/2204.02292 (BERT, IR)
@article{litschko2022parameter,
  title={Parameter-efficient neural reranking for cross-lingual and multilingual retrieval},
  author={Litschko, Robert and Vuli{\'c}, Ivan and Glava{\v{s}}, Goran},
  journal={arXiv preprint arXiv:2204.02292},
  year={2022},
  url={https://arxiv.org/pdf/2204.02292}
}

%Shen et al. (2024): https://arxiv.org/pdf/2412.20061 (IR)
@article{shen2024comparative,
  title={Comparative Analysis of Listwise Reranking with Large Language Models in Limited-Resource Language Contexts},
  author={Shen, Yanxin and Wang, Lun and Shi, Chuanqi and Du, Shaoshuai and Tao, Yiyi and Shen, Yixian and Zhang, Hang},
  journal={arXiv preprint arXiv:2412.20061},
  url={https://arxiv.org/pdf/2412.20061},
  year={2024}
}

%Lee et al. (2014): https://www.isca-archive.org/interspeech_2014/lee14c_interspeech.pdf (graphs)
@inproceedings{lee2014graph,
  title={Graph-based re-ranking using acoustic feature similarity between search results for spoken term detection on low-resource languages},
  author={Lee, Hung-yi and Zhang, Yu and Chuangsuwanich, Ekapol and Glass, James R},
  booktitle={Fifteenth Annual Conference of the International Speech Communication Association},
  year={2014},
  url={https://www.isca-archive.org/interspeech_2014/lee14c_interspeech.pdf}
}

%Mizumoto \& Matsumoto (2017): https://aclanthology.org/N16-1133.pdf
@inproceedings{mizumoto2016discriminative,
  title={Discriminative reranking for grammatical error correction with statistical machine translation},
  author={Mizumoto, Tomoya and Matsumoto, Yuji},
  booktitle={Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={1133--1138},
  year={2016},
  url={https://aclanthology.org/N16-1133.pdf}
}







