
\documentclass[letterpaper, 10 pt, conference]{ieeeconf}


\IEEEoverridecommandlockouts                              %

\overrideIEEEmargins                                      %

\pdfminorversion=4


\usepackage{graphics} %
\usepackage{epsfig} %
\usepackage{amsmath} %
\usepackage{amssymb}  %
\usepackage{multirow}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{cite}
\usepackage{hyperref}
\usepackage[caption=false]{subfig} %
\usepackage{adjustbox}
\usepackage{array}
\usepackage{caption}


\title{\LARGE \bf
Co-evolution-based Metal-binding Residue Prediction with \\Graph Neural Networks

}

\author{Sayedmohammadreza Rastegari, Sina Tabakhi, Xianyuan Liu, Wei Sang, and Haiping Lu%
\thanks{}%
\thanks{Sayedmohammadreza Rastegari is with Faculty of Computer Engineering,
        University of Isfahan, Isfahan, Iran
        {\tt\small \{s.mohammadreza.rastegari@gmail.com\}}.}%
\thanks{Sina Tabakhi and Xianyuan Liu are with School of Computer Science and Centre for Machine Intelligence, University of Sheffield, Sheffield, United Kingdom
        {\tt\small \{\{stabakhi1, xianyuan.liu\} @sheffield.ac.uk\}}.}%
\thanks{Wei Sang is with School of Basic Medical Sciences and Institute of Medical Technology, Shanxi Medical University, Taiyuan, China
    {\tt\small \{sangwei@sxmu.edu.cn\}}.}%
\thanks{Haiping Lu is with School of Computer Science and Centre for Machine Intelligence, University of Sheffield, Sheffield, United Kingdom, and Institute of Big Data Science and Industry, Shanxi University, Taiyuan, China
        {\tt\small \{h.lu@sheffield.ac.uk\}}.}%
}


\begin{document}


\maketitle
\thispagestyle{empty}
\pagestyle{empty}





\begin{abstract}

In computational structural biology, predicting metal-binding sites and their corresponding metal types is challenging due to the complexity of protein structures and interactions. Conventional sequence- and structure-based prediction approaches cannot capture the complex evolutionary relationships driving these interactions to facilitate understanding, while recent co-evolution-based approaches do not fully consider the entire structure of the co-evolved residue network. In this paper, we introduce {\normalfont\texttt{MBGNN}} (\underline{M}etal-\underline{B}inding \underline{G}raph \underline{N}eural \underline{N}etwork) that utilizes the entire co-evolved residue network and effectively captures the complex dependencies within protein structures via graph neural networks to enhance the prediction of co-evolved metal-binding residues and their associated metal types. Experimental results on a public dataset show that {\normalfont{\texttt{MBGNN}}} outperforms existing co-evolution-based metal-binding prediction methods, and it is also competitive against recent sequence-based methods, showing the potential of integrating co-evolutionary insights with advanced machine learning to deepen our understanding of protein-metal interactions. The {\normalfont\texttt{MBGNN}} code is publicly available at \href{https://github.com/SRastegari/MBGNN}{https://github.com/SRastegari/MBGNN}.
\newline

\indent \textit{Index Terms}— Metal-binding sites, Co-evolutionary analysis, Graph neural networks, Machine learning, Computational biology
\end{abstract}



\section{INTRODUCTION}

\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{./MBGNN.pdf}
    \caption{Overview of \texttt{MBGNN}'s pipeline.
    (a) Co-evolved network construction starts with a protein of interest (POI) chain sequence, followed by multiple sequence alignment (MSA). Then, the MSA Transformer and a protein language model (PLM) are utilized to identify co-evolved pairs and obtain residue-level embeddings, respectively. Once the pairs are extracted, they are organized into co-evolved residue networks, and each residue is mapped to its corresponding PLM-derived embedding. 
    (b) The metal-binding predictor processes these networks using the average probabilities produced by GNNs trained on different folds of data using an \textit{M}-fold ensemble strategy to identify metal-binding residues.
    (c) Predicted metal-binding residues are assembled into new co-evolved networks, and each residue is mapped to its corresponding PLM-derived embedding again. The metal-type predictor takes the newly identified co-evolved residue networks and classifies their associated metal type into one of the 11 categories, using probabilities of GNN models again trained using an \textit{M}-fold ensemble strategy.}
    \label{fig:visualabstract}
\vspace{-5pt}
\end{figure*}


Detecting protein interactions with small molecules and ions, known as ligands, is crucial to uncovering their biological functions. These interactions drive essential cellular processes \cite{p1,p2,p3,gladyshev2013comparative} and have critical applications in drug discovery and biotechnology. Among the various types of ligands, metal ions play a significant role by binding to specific sites on proteins and contributing to structural stability and catalysis. With more than one-third of all proteins in the proteome capable of binding metal ions\cite{cheng2023co}, it is essential to identify metal-binding \textit{residues} -- the specific amino acids that facilitate these interactions. However, detecting these residues is challenging due to the complexity of protein structures, the concealed nature of binding sites, the diversity of metal ions, and the limited number of residues involved. As experimental methods are costly and time-consuming, computational approaches offer faster and more scalable alternatives for accurate predictions.

There are three main computational approaches for predicting metal-binding sites. \textit{Structure-based} approach relies on features derived from the three-dimensional structures of proteins\cite{lin2016mib, 10.1093/bioinformatics/btac534}. \textit{Sequence-based} approach focuses on features extracted from the amino acid sequences of proteins\cite{lmetalsite, mionic, cui2019predicting}. \textit{Multimodal} approach utilizes both structural and sequential information\cite{10.1093/bioinformatics/btaa110}. The performance of the structure-based approach relies on the availability of accurate three-dimensional protein structures, which are not always accessible. Meanwhile, the current sequence-based approach is often limited to detecting only a narrow range of ions\cite{mionic}. A review of all of these approaches is provided in \cite{XIA2024102793,ye2022comprehensive}.
 
Given these challenges, there is a pressing need for new computational techniques that can accurately identify metal-binding sites while offering improved performance. 
Advances in high-throughput sequencing have generated vast amounts of genomic data across many species, enabling a deeper analysis of sequence-based information such as \textit{co-evolution} signals between residues. By performing multiple sequence alignment (MSA), i.e., aligning the sequences of a protein of interest (POI) from multiple species, researchers can now construct a comprehensive evolutionary history of a POI. This analysis reveals both residues that have been conserved throughout evolution and pairs of residues that exhibit high covariance, meaning they have changed together over time to maintain productive interactions and follow functional, structural, and folding constraints\cite{chakrabarti2010structural, sandler2014functional}. Co-evolution data is often represented in a contact map, which allows for the precise detection of long-range interactions within sequences\cite{balakrishnan2011learning,morcos2011direct,gobel1994correlated, shindyalov1994can, jones2012psicov,martin2005using}.

MetalNet\cite{cheng2023co} is a recent co-evolution-based method for identifying metal-binding residue pairs, focusing on CHED residues (cysteine, histidine, glutamic acid, and aspartic acid), as these residues are found much more frequently at metal-binding sites.
MetalNet generates contact maps by employing MSA Transformer\cite{pmlr-v139-rao21a}, extracts co-evolved CHED pairs, applies machine learning (ML) to predict metal-binding pairs, and assembles them into networks for metal-type prediction using motif-matching. MetalNet2 \cite{10.1093/nsr/nwae391} enhances MetalNet by incorporating residue-level embeddings from a protein language model (PLM) and replacing motif matching with an ML-based metal-type predictor. Although both models are the first co-evolution-based approaches for predicting metal-binding sites and demonstrate that co-evolution information can be valuable, they have limitations that affect their performance. Neither model utilizes the entire co-evolved residue network structure to identify metal-binding sites. Specifically, MetalNet employs a motif-matching method for metal detection, which lacks the capability to predict metal-related sites in new network structures and singleton pairs. On the other hand, while MetalNet2 can make predictions, it no longer uses the network structure and analyzes residue pairs in isolation. These factors reduce the predictive power and accuracy of both models.

To address these limitations, we introduce \texttt{MBGNN} (\underline{M}etal-\underline{B}inding \underline{G}raph \underline{N}eural \underline{N}etwork), a new co-evolution-based method for predicting metal-binding residues and their corresponding metal types with a focus on CHED residues. \texttt{MBGNN} links co-evolved CHED residue pairs by identifying common residues and constructs co-evolved residue networks to leverage their overall structure for improved predictions. To learn an effective representation for each residue within its associated co-evolved network, we employ graph representation learning, particularly graph neural networks (GNNs)\cite{khoshraftar2024survey, velivckovic2023everything, corso2024graph}. GNNs enable the capture of the topological structure of co-evolutionary relationships, thereby improving the detection of metal-binding residues and the classification of metal types while overcoming the limitations of traditional motif-matching methods. To enhance the performance in metal-binding and metal-type prediction, we implement an $M$-fold ensemble strategy, which mitigates the imbalance between metal-binding and non-binding residues, as well as among residues associated with different metal types. We evaluate \texttt{MBGNN} against co-evolution-based models, as well as sequence-based models. The comparisons demonstrate that \texttt{MBGNN} significantly improves overall performance, particularly in the precision of detecting metal-binding residues.

\section{METHODOLOGY}
\label{sec:method}
\texttt{MBGNN}'s pipeline consists of three main components: ``\textit{Co-evolved Residue Network Construction}'', ``\textit{Metal-binding Predictor}'', and ``\textit{Metal-type Predictor}''. In this section, we provide a detailed discussion of each component, as well as the ensemble strategy used to enhance prediction performance. Fig. \ref{fig:visualabstract} shows an overview of \texttt{MBGNN}'s pipeline.

\subsection{Co-evolved Residue Network Construction}
\label{subsubsec:feat}
To prepare the input data for \texttt{MBGNN}'s metal-binding predictor based on a POI chain's sequence, we first perform MSA for the sequence using ColabFold MMseq2 \cite{mirdita2022colabfold}. As required for the MSA Transformer model, we then subsample a maximum of $B$ aligned sequences, choosing those that maximize the Hamming distance. These sequences are then passed into the MSA Transformer model, ESM-MSA-1b, to generate contact maps, with a contact threshold of greater than 0.1 to indicate co-evolutionary relationships. This process follows that used by MetalNet2 to extract co-evolved CHED residue pairs. Finally, the resulting co-evolved CHED residue pairs that share common residues are assembled into co-evolved residue networks.

In recent years, it has been shown that using embeddings obtained by protein language models as initial features is beneficial practice for various downstream tasks\cite{10.1093/nsr/nwae391, lmetalsite, mionic,  jha2022prediction,jha2023graph, bepler2021learning}. Therefore, for the initial features of each residue, we generate ESM2\cite{lin2023evolutionary} (esm2-t33-650M-UR50D) residue-level embeddings for the protein chain’s sequence. Each ESM2 embedding has a dimensionality of \( L \times 1280 \), where \( L \) is the length of the chain's sequence. Consequently, each residue is represented by a $1280$-dimensional feature vector. These embeddings are then mapped to their corresponding residues within each constructed co-evolved residue network. 

Formally, constructed co-evolved residue networks for each POI can be represented as a collection of graphs:
\begin{equation}
    \mathcal{G} = \{G_1, G_2, \dots, G_k\},
\end{equation}
where $k$ is the number of POI's co-evolved residue networks, and each \( G_i = (\mathcal{V}_i, \mathcal{E}_i, \mathbf{X}_i) \) is a connected graph defined as follows:
\begin{itemize}
    \item \( \mathcal{V}_i = \{v_1, v_2, \dots, v_{|\mathcal{V}_i|}\} \) is the set of nodes (residues) in the \(i\)-th graph (co-evolved residue network);
    \item \( \mathcal{E}_i = \{(v_a, v_b) : \text{contact}(v_a,v_b) > 0.1\} \) is the set of edges representing co-evolutionary relationships between residues \( v_a \) and \( v_b \), where \(\text{contact}(v_a,v_b)\) is the co-evolution score derived from the MSA Transformer;
    \item \( \mathbf{X}_i \in \mathbb{R}^{|\mathcal{V}_i| \times 1280} \) is the node feature matrix, where each row represents the 1280-dimensional embedding of a residue in \( \mathcal{V}_i \), derived from ESM2.
\end{itemize}

This set of graphs, \(\mathcal{G}\), forms the input to \texttt{MBGNN}'s metal-binding predictor.

We then extract the residues predicted to be metal-binding by the metal-binding predictor and construct new networks based on them for \texttt{MBGNN}'s metal-type predictor. The nodes in these new networks represent the predicted metal-binding residues, and their initial features are, again, the embeddings generated by ESM2.

The resulting set of graphs can be defined as:
\begin{equation}
\mathcal{G}' = \{G'_1, G'_2, \dots, G'_m\},
\end{equation}
where $m$ is the number of POI's co-evolved metal-binding residue networks where each \( G'_i = (\mathcal{V'}_i, \mathcal{E'}_i, \mathbf{X}'_i) \) is a connected graph constructed as follows:
\begin{itemize}
    \item \( \mathcal{V'}_i = \{v'_1, v'_2, \dots, v'_{|\mathcal{V'}_i|}\} \) is the set of nodes, where each node corresponds to a residue predicted to be metal-binding by the metal-binding predictor;
    \item \( \mathcal{E'}_i = \{(v'_a, v'_b): \text{contact}(v'_a,v'_b) > 0.1\} \) is the set of edges between residues \( v_a' \) and \( v_b' \) that share a co-evolutionary relationship, determined by a contact threshold of 0.1;
    \item \( \mathbf{X}'_i \in \mathbb{R}^{|\mathcal{V'}_i| \times 1280} \) is the node feature matrix, where each row represents the 1280-dimensional embedding of a residue in \( \mathcal{V'}_i \), derived from ESM2.
\end{itemize}

By following these procedures on a POI's sequence, we construct the graphs for \texttt{MBGNN}'s metal-binding and metal-type predictors.

\subsection{Metal-binding Predictor}
\label{subsec:mbp}
To learn effective representations for each node in a co-evolved residue network for the downstream task of classifying them as metal-binding or non-binding, we implemented a SAGEConv-based GNN model\cite{hamilton2017inductive} with $N_1$ layers, where $N_1$ denotes the number of layers in the network. Each layer applies the SAGEConv operation, which aggregates information from neighboring nodes to update the representation of each node. As explained in Section \ref{subsec:dataset}, the initial representation of each node is a 1280-dimensional feature vector. The first layer transforms these input features into a lower-dimensional hidden representation of $d$-dimension, and the subsequent layers iteratively refine this representation for each node and help to consider information from further nodes in the same network.

The SAGEConv operation is defined as:
\begin{equation}
    \mathbf{h}_i' = \mathbf{W}_1 \mathbf{h}_i + \mathbf{W}_2 \cdot \text{mean}_{j \in \mathcal{N}(i)} \mathbf{h}_j,
\end{equation}
where:  
\begin{itemize}
    \item \(\mathbf{h}_i'\) is the updated representation of node \(i\);
    \item \(\mathbf{h}_i\) is the current representation of node \(i\);  
    \item \(\mathcal{N}(i)\) represents the set of neighbors of node \(i\);
    \item \(\mathbf{W}_1\) and \(\mathbf{W}_2\) are learnable weight matrices for self-features and neighbor aggregation, respectively;
    \item \(\text{mean}_{j \in \mathcal{N}(i)} \mathbf{h}_j\) computes the mean of the feature vectors of all neighbors of the node \(i\).  
\end{itemize}

In our model, each SAGEConv layer, except for the final layer, is followed by batch normalization to stabilize training and a ReLU as an activation function. The final SAGEConv layer outputs the representations used for classification, which pass through a softmax activation function to produce classification probabilities for each of the metal-binding and non-binding classes.



\subsection{Metal-type Predictor}

The goal of the metal-type predictor is to identify the specific type of metal associated with each residue in the graphs formed by residues predicted to be metal-binding by the \texttt{MBGNN} metal-binding predictor. Following the approach described in Section \ref{subsec:mbp}, we employed a similar SAGEConv-based GNN architecture with $N_2$ layers, where $N_2$ denotes the number of layers in the network. In this architecture, each layer updates the representation of each residue node by aggregating information from its neighboring nodes through the SAGEConv operation. Each SAGEConv layer is followed by batch normalization and a ReLU activation function, except for the final layer. The first SAGEConv layer reduces the input features to a lower-dimensional hidden space, while the subsequent layers refine these representations even further. The final layer maps the learned residue-level representations to the output dimension corresponding to the different metal types. These outputs then pass through a softmax activation function to generate classification probabilities for each metal type.

\subsection{$M$-fold Ensemble Strategy}
\label{subsec:mfold}
As we will show in Section \ref{subsec:dataset}, there are two kinds of severe class imbalance: one is between the metal-binding and non-binding classes, and the other is between different metal types. We found that this problem can lead to overfitting and non-convergence when training our models. To address this issue and create powerful predictors, we employed an $M$-fold ensemble strategy to combine the predictions of $M$ models, which is quite similar to the method described in \cite{XIA2023168091}. Specifically, we divided the training set for both the metal-binding predictor and the metal-type predictor into $M$ folds. On each iteration, one fold is used as the validation set, while the remaining folds serve as the training set to train the predictor. As a result, $M$ predictors are trained in total. Finally, we average the predicted probabilities from the $M$ predictors for each class to obtain the final predicted probability, which is then used as the ultimate prediction.

\section{EXPERIMENTS}
In this section, we first describe the dataset and its preprocessing steps used for the training and evaluation of \texttt{MBGNN}. We then outline the implementation details and experimental setup, followed by a comparison of \texttt{MBGNN} with other metal-binding site prediction models and a discussion of the results. A sensitivity analysis is also provided in this section.
\subsection{Dataset and Preprocessing} 
\label{subsec:dataset}
We used the dataset provided by MetalNet2, which consisted of 4,449 metal-binding protein chains collected from the Protein Data Bank (PDB) as of May 2023. The dataset contained a training set and a fixed hold-out test set, which respectively included 18,230 and 1,981 metal-binding CHED residues. Furthermore, 11 metal types were considered as labels for each metal-binding residue, including Zn, Ca, Mg, Mn, Fe, SF$_4$, Ni, Cu, Co, FeS, and Fe$_3$S. Fig. \ref{fig:metal_dist} shows the distribution of metal types in the dataset, highlighting the imbalance among different metal types.

Following the procedures explained in Section \ref{subsubsec:feat}, we extracted the graphs from the sequences in the training and test sets, which were used for training and evaluating \texttt{MBGNN}'s metal-binding predictor. Co-evolved residues present in the dataset were labeled as 1, indicating metal-binding, while those not present were labeled as 0, indicating non-binding. Moreover, to prepare the training data for \texttt{MBGNN}'s metal-type predictor, training graphs were created by assembling co-evolved metal-binding residues from the training set. For evaluation, we constructed graphs with the residues from the test set that were predicted to be metal-binding for \texttt{MBGNN}'s metal-type predictor. Each residue was labeled according to its associated metal, with each corresponding to a specific metal type. Table \ref{tab:bin_graphs} presents a summary of the number of graphs and co-evolved residues extracted from the sequences in the dataset for each predictor.


\begin{figure}[!t]
    \centering
    \includegraphics[width=0.9\columnwidth]{./Metal_dist.png}
    \caption{Distribution of metal types in the dataset.}
    \label{fig:metal_dist}
\end{figure}

\begin{table}[ht]
\centering
\caption{Summary of Extracted Co-evolved Residues and Graphs for \texttt{MBGNN}'s Metal-binding and Metal-type Predictors.}
\renewcommand{\arraystretch}{1.3} %
\begin{tabular}{l r}
\hline
\textbf{Metal-binding predictor data} & \textbf{Count} \\ 
\hline
Train Graphs & 38,010 \\ 
Train Co-evolved Residues & 148,163 \\ 
Train Co-evolved Metal-binding Residues & 17,004 \\
Test Graphs & 4,235 \\
Test Co-evolved Residues & 16,447 \\
Test Co-evolved Metal-binding Residues & 1,826 \\
\hline
\textbf{Metal-type predictor data} & \textbf{Count} \\ 
\hline
Train Graphs & 4,153 \\
Test Graphs & 380 ± 7$^{*}$ \\
\hline
\end{tabular}
\label{tab:bin_graphs}

\vspace{0.5cm}
{\raggedright \footnotesize $^{*}$ The number of test graphs for the metal-type predictor depends on the metal-binding predictor's performance, averaged over 5 runs.\par}
\vspace{-5pt}
\end{table}

\begin{figure*}[t]
    \centering
    \subfloat[Performance comparison with co-evolution-based methods]{
        \includegraphics[width=0.95\linewidth]{mt.png}
        \label{fig:a}}\\
    \subfloat[Performance comparison with LMetalSite]{
        \includegraphics[width=0.95\linewidth]{lm.png}
        \label{fig:b}}\\
    \subfloat[Performance comparison with M-Ionic]{
        \includegraphics[width=0.95\linewidth]{mio.png}
        \label{fig:c}}
    \caption{Performance comparison of \texttt{MBGNN} for metal-type prediction on the fixed hold-out test set against co-evolution-based methods (a) and sequence-based methods, i.e., LMetalSite (b) and M-Ionic (c). In all subfigures, the ``Mean'' column represents the macro average of the values of the metal columns.
    }
    \label{fig:allres}
\vspace{-5pt}
\end{figure*}

\subsection{Implementation Details}
For feature extracting, we subsampled a maximum of $B=64$ aligned sequences after performing multiple sequence alignment with ColabFold MMseq2 to prepare the MSA Transformer input as explained in Section \ref{subsubsec:feat}.

For training \texttt{MBGNN}’s metal-binding predictor, we followed the $M$-fold ensemble strategy described in Section \ref{subsec:mfold}. We randomly shuffled and split the extracted metal-binding/non-binding training graphs into six folds ($M=6$). For training, one fold was used as the validation set, and the remaining five were used for training. This process resulted in six independently trained metal-binding predictor models, with their averaged outputs used in the final pipeline. These models were implemented using PyTorch (version 2.3.0)\cite{10.5555/3454287.3455008} and PyG (version 2.6.1)\cite{fey2019fast}. The best-performing model, selected based on the F1 score on the validation set, was chosen for the final predictor. The training was performed using the Adam optimizer with a learning rate of 0.001, weight decay of 0.0001, and cross-entropy loss as the objective function. The hidden-dimension parameters of all metal-binding predictor models were set to 64, and five SAGEConv layers ($N_1=5$) were used in the model.

For training \texttt{MBGNN}’s metal-type predictor, we applied the same $M$-fold ensemble strategy, splitting the dataset into six folds ($M=6$). One fold was designated as the validation set, while the remaining five were for training. The final prediction was the average of the six model's outputs. Based on the F1 score during validation in each iteration, the best-performing model was selected for use in the final predictor. The training hyperparameters remained consistent with those of the metal-binding predictor, except for a weight decay of 0.0005 in the Adam optimizer and the hidden dimension size of 512. Five SAGEConv layers were used, i.e., $N_2=5$.

Hyperparameter selection and optimization were done using Optuna (version 4.1.0)\cite{akiba2019optuna}.


\subsection{Results}
\label{subsec:res}


\begin{table}[t]
\centering
\caption{Performance Comparison of Metal-binding and Metal-type Prediction on the Fixed Hold-Out Test Set (\textbf{Best in Bold}, \underline{Second Best} in Underline). Baseline Results were Obtained from Their Papers and Publicly Available Repositories.}
\label{tab:performance_comparison}
\renewcommand{\arraystretch}{1.3} %
\begin{tabular}{lccc}
\hline
\textbf{Metric}        & \textbf{MetalNet\cite{cheng2023co}} & \textbf{MetalNet2\cite{10.1093/nsr/nwae391}} & \texttt{MBGNN} \textbf{(Ours)} \\ \hline
\multicolumn{4}{c}{\textbf{Metal-binding Prediction}} \\ \hline
Precision             & 0.6173          & \underline{0.8256}          & \textbf{0.8822} \\
Recall                & 0.6189          & \underline{0.7002}
& \textbf{0.7032} \\
F1 Score              & 0.6181          & \underline{0.7577}          & \textbf{0.7826} \\ \hline
\multicolumn{4}{c}{\textbf{Metal-type Prediction}} \\ \hline
Precision             & 0.1721          & \underline{0.5252}          & \textbf{0.7194} \\
Recall                & 0.2563          & \textbf{0.5352} & \underline{0.4924}\\
F1 Score              & 0.1564          & \underline{0.5207}          & \textbf{0.5543} \\ \hline

\end{tabular}

\vspace{-5pt}
\end{table}


We compared the performance of \texttt{MBGNN} with two co-evolution-based methods, MetalNet and MetalNet2. We reported the precision, recall, and F1 scores for both metal-binding residue and metal-type predictions on the fixed hold-out test set. The performance of metal-binding residue prediction and the macro average of metrics for metal-type prediction are presented in Table \ref{tab:performance_comparison}, while the performance for each of the 11 metal types is illustrated in Fig. \ref{fig:a}. The results presented in this section correspond to the best F1 scores achieved for metal-type classification, and detailed results demonstrating the robustness of \texttt{MBGNN} are presented in Section \ref{subsec:sens}. The results of MetalNet and MetalNet2 were extracted from the publicly available MetalNet2 repository\protect\footnotemark[1] as they were evaluated on the same hold-out test set.

\footnotetext[1]{MetalNet2 repository: \href{https://github.com/wangchulab/MetalNet2}{https://github.com/wangchulab/MetalNet2}.}


As presented in Table \ref{tab:performance_comparison}, by leveraging the co-evolved residue network and the information it provided, \texttt{MBGNN} led to significant improvements in both precision and recall for predicting metal-binding residues, resulting in a higher F1 score. Specifically, the precision of metal-binding residue prediction increased by about 6\% compared to MetalNet2, highlighting the model’s ability to reduce false positives while maintaining strong recall. Additionally, \texttt{MBGNN} improved metal-type prediction, achieving an approximately 19\% increase in precision and about 3\% boost in the overall F1 score relative to MetalNet2. As Fig. \ref{fig:a} illustrated, these improvements were also evident for most of the metals with limited training samples, such as Co, Ni, and FeS, where \texttt{MBGNN} outperformed other methods. We also observed that MetalNet2 achieved higher recall by predicting multiple metals per residue due to its pairwise approach, which treated residue pairs independently. This method artificially inflated recall at the expense of precision, frequently assigning multiple metal types to the same residue and increasing false positives. In contrast, \texttt{MBGNN} overcame this limitation by leveraging the full network of co-evolved residue interactions through GNNs, enabling more precise predictions while maintaining robust recall. By reducing false positives, \texttt{MBGNN} achieved higher precision, F1 score, and overall reliability in metal-binding prediction.

We also compared \texttt{MBGNN} with two sequence-based approaches that use deep learning and embeddings generated by a PLM to predict the metal types associated with each residue: LMetalSite\cite{lmetalsite} and M-Ionic\cite{mionic}. The results of LMetalSite\protect\footnotemark[1] and M-Ionic\protect\footnotemark[2] were obtained from their publicly available server and repository, respectively.

\footnotetext[1]{LMetalSite server: \href{https://bio-web1.nscc-gz.cn/app/lmetalsite}{https://bio-web1.nscc-gz.cn/app/lmetalsite}.}
\footnotetext[2]{M-Ionic repository: \href{https://github.com/TeamSundar/m-ionic}{https://github.com/TeamSundar/m-ionic}.}

First, we compared \texttt{MBGNN} to LMetalSite, which predicted only four essential metal types for residues: Zn, Mg, Ca, and Mn. To ensure a fair comparison, we extracted residues from the hold-out test set that corresponded to these metal types, ensuring that their protein chains were not included in the LMetalSite training data. We then evaluated the classification performance of both models on these residues, with the results shown in Fig. \ref{fig:b}. The results demonstrated that \texttt{MBGNN} significantly outperformed LMetalSite in terms of precision and F1 score across all four metal types and the macro average. This highlighted \texttt{MBGNN}’s ability to make accurate predictions by effectively leveraging co-evolutionary information. Specifically, the precision advantage underscored \texttt{MBGNN}’s ability to reduce false positives while maintaining robust predictive performance. However, LMetalSite demonstrated better recall, possibly because it could consider residues without a co-evolution relationship, enabling it to classify more residues. This indicated that it could be beneficial to leverage co-evolution data when available while being able to make predictions based on other types of information when co-evolution data is not present.

To compare \texttt{MBGNN} with M-Ionic, we extracted residues containing seven shared metal types from the hold-out test set: Ca, Co, Cu, Fe, Mg, Mn, and Zn. Likewise, we only selected protein chains that were not included in M-Ionic's training data and extracted M-Ionic results for their CHED residues. The results of this comparison in metal-type prediction were presented in Fig. \ref{fig:c}. Again, \texttt{MBGNN} demonstrated a better overall F1 score, while M-Ionic achieved a higher recall for reasons similar to those of LMetalSite. More specifically, \texttt{MBGNN} showed a significant improvement in both precision and F1 score across most of the metal types and in the macro average. Notably, the precision of \texttt{MBGNN} consistently outperformed M-Ionic, particularly for underrepresented metals such as Co, where the precision gap was substantial. In terms of F1 score, \texttt{MBGNN} also outperformed M-Ionic for most of the metal types, reflecting its balanced performance between precision and recall. The macro-average F1 score further underscored the robustness of \texttt{MBGNN}, with improvements evident for almost all of the metal types, even those with fewer training samples. Given that both \texttt{MBGNN} and M-Ionic used embeddings obtained from ESM2 as the initial feature of the residues, these results demonstrated the positive effect of considering the co-evolved residue network instead of considering residues and their embeddings in isolation, when possible.



\subsection{Sensitivity Analysis}
\label{subsec:sens}
To verify the robustness of the model, we repeated the entire training and testing process of the pipeline five times, each with a different random seed. Table \ref{tab:mbgnn_results} presented the results of these repetitions, highlighting the stability and reliability of the model's performance across different runs. The best F1 score from the metal-type classifier, achieved in run 5, was used as the final predictor.


\begin{table}[t]
\centering
\caption{Performance of \texttt{MBGNN} across Five Training Runs (1-5) on the Fixed Hold-Out Test Set, Reported as Mean $\pm$ Std, where Std is the Standard Deviation.}
\label{tab:mbgnn_results}
\renewcommand{\arraystretch}{1.1} %
\setlength{\tabcolsep}{3pt} %
\begin{tabular}{l|ccccc|c}
\hline
\textbf{Metric} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} & \textbf{Mean $\pm$ Std} \\ \hline
\multicolumn{7}{c}{\textbf{Metal-binding Prediction}} \\ \hline
Precision  & 0.8876 & 0.8752 & 0.8771 & 0.8810 & 0.8822 & \textbf{0.8806 $\pm$ 0.0048} \\
Recall     & 0.7017 & 0.7148 & 0.7097 & 0.6951 & 0.7032 & \textbf{0.7049 $\pm$ 0.0076} \\
F1 Score   & 0.7838 & 0.7869 & 0.7846 & 0.7771 & 0.7826 & \textbf{0.7830 $\pm$ 0.0037} \\ \hline
\multicolumn{7}{c}{\textbf{Metal-type Prediction}} \\ \hline
Precision  & 0.7042 & 0.6894 & 0.7106 & 0.6748 & 0.7194 & \textbf{0.6997 $\pm$ 0.0177} \\
Recall     & 0.4933 & 0.4953 & 0.4929 & 0.4969 & 0.4924 & \textbf{0.4942 $\pm$ 0.0019} \\
F1 Score   & 0.5474 & 0.5481 & 0.5525 & 0.5518 & 0.5543 & \textbf{0.5509 $\pm$ 0.0030} \\ \hline
\end{tabular}
\vspace{-5pt}
\end{table}


\section{Conclusion}
In this paper, we introduced \texttt{MBGNN}, a novel computational method for predicting metal-binding residues using the co-evolution signal. \texttt{MBGNN} utilized the complete network of co-evolved residues and leveraged graph neural networks to identify metal-binding residues and assign them to one of 11 metal types. 

\texttt{MBGNN} addressed the limitations of the existing co-evolution-based approaches and demonstrated that leveraging co-evolved residue networks with graph neural networks can significantly enhance the precision and overall F1 score of metal-binding residue predictions and their associated metal-type predictions compared with other co-evolution-based and recent sequence-based baselines. By incorporating co-evolutionary relationships into the form of a network, \texttt{MBGNN} demonstrated a clear advantage over existing methods, excelling in precision and reliably predicting a broad range of metal types. In addition, \texttt{MBGNN} enhanced the detection of underrepresented metals.

One limitation of our model is that it exclusively classifies co-evolved residues, limiting its ability to predict residues without co-evolutionary information. This limitation suggests an opportunity to develop a new type of method that combines the network of co-evolved residues with additional sequence or structural data, potentially improving recall without sacrificing precision.




\bibliographystyle{ieeetr}
\bibliography{root}

\end{document}
