\section{Related Works}
Our study is relevant to several machine learning fields, including continual learning, transfer learning, and especially transferability estimation. In the following, we provide an overview of previous works directly related to ours.


\subsection{Continual Learning}

CL aims at building and continuously adapting a model through a sequence of tasks so that the model can perform well on all tasks it has observed____. However, when the model is updated on new tasks, SGD training, which assumes i.i.d.~data, usually leads to a decline in performance on earlier tasks. This phenomenon is referred to as catastrophic forgetting____ and has been the primary subject of research on CL. Numerous strategies have been suggested to mitigate this issue, including regularization-based methods____, episodic memory-based methods____, parameter isolation-based methods____, and Bayesian methods____. Besides algorithmic efforts to reduce catastrophic forgetting, some recent works also look at the role of forward transfer____ and backward transfer____.

Although a learner may retain information from previous tasks, it is often more crucial to employ the acquired knowledge to efficiently learn new tasks (referred to as forward transfer) and to retain the previous knowledge (known as backward transfer)____. ____ argued that the enhancement in accuracy does not necessarily improve the forward transfer and backward transfer. On the other hand, ____ showed that the relatedness between tasks can affect the model's performance. In this paper, we will explore the relationships between accuracy, forward transfer, and backward transfer in CL. To the best of our knowledge, the most similar to our work is ____, which also showed that less forgetting leads to better forward transfer, but their models are overconfident on the trained auxiliary output layer and are more time-consuming to train.

In terms of task selection, real-world data can be accumulated to form a batch of tasks____, and training them sequentially in chronological order may not be optimal. Therefore, optimizing the model's performance requires selecting the right tasks in the right order. ____ indicated that task orders could significantly impact CL algorithms' effectiveness. In this work, we also develop a novel algorithm to determine a task order that can give a good accuracy for CL algorithms.


\subsection{Transferability Measures}

CL can be considered a generalization of transfer learning where we need to continuously transfer knowledge from previous tasks to current ones. In transfer learning, transferability measures____ have emerged as a tool to estimate the easiness of knowledge transfer from a source to a target task. These measures could be used to analyze task relations____, ranking checkpoints____, or model selection____. Recent attempts in this area____ aim to develop transferability measures that are well-correlated with the test accuracy of the target task. 

Label-based estimators____ rely on the relationship between source and target labels to construct transferability measures. However, they could be restrictive due to the assumption that source and target tasks shared the same inputs____ or could be inaccurate due to the overfitting of the last layer to source domains____. These issues are addressed in subsequent works using the feature layer. For instance, LogME____ measures the transferability based on the log marginal likelihood of the target labels given the extracted features. TransRate____ uses the mutual information between extracted features and labels to estimate transferability. Other works compute the domain distance____, intra-class distance____, or combine with inter-class distance____ to construct their measures. Recently, physics-inspired and energy-based methods____ have emerged as a promising approach to this problem. In this paper, we shall generalize this notion of transferability measure to define the sequence transferability measures, which can estimate the transferability of CL algorithms on a sequence of tasks.