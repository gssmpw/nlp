\section{Related work}
\label{sec:related_work}

\noindent\textbf{Single-Level Analyses.}
Many existing algorithms extract structure at \textit{single} levels of the music structural hierarchy. To extract segmentation, The Music Structure Analysis Framework (MSAF) toolkit~\cite{msaf} features factorization-based techniques, including ordinal linear discriminant analysis~\cite{olda}, convex nonnegative matrix factorization~\cite{cnmf}, checkerboard~\cite{checkerboard}, spectral clustering~\cite{sCluster}, the Structural Features algorithm~\cite{sf}, 2D-Fourier Magnitude Coefficients~\cite{2dfmc}, and the Variable Markov Oracle~\cite{vmo_segmentation}. Motif discovery algorithms search for disjoint, repeating, and possibly overlapping patterns in a piece. String-based approaches~\cite{vmo_motifs} represent music as a chromagram and detect patterns with sub-string matching, and geometry-based approaches~\cite{Hsiao_2023_motifs} represent music as multidimensional point sets, and translatable subsets identify patterns. Recent approaches in harmony identification are centered around neural networks, such as using transformers to incorporate chord segmentation into the recognition process~\cite{chen_2019_harmony,harmonytransformerV2}. Until very recently, the Melodia algorithm was the state of the art in melody extraction, but recent approaches have shifted to neural networks~\cite{kosta_22_melody,midibert}. 

\smallskip\noindent\textbf{Integrated Models of Structure.}
Music theorists have attempted to unify the structural hierarchy with frameworks such as Schenkerian theory~\cite{schenkerian} and the Generative Theory of Tonal Music (GTTM)~\cite{gttm}. Schenkerian analysis applies a series of reductions that progressively simplify a musical piece by removing layers of structure. Attempts to automatically derive Scherkerian analyses are intractable for all but very short pieces, and have low accuracy~\cite{schenkerian}. GTTM generates four different structural hierarchies (grouping structure, metrical structure, time-span tree, and prolongational tree) for a piece of music, to model human cognition~\cite{gttm_implementation}. Computational implementations GTTM (e.g. the Automatic Timespan Tree Analyser~\cite{gttm_implementation}) cannot handle polyphonic music, and are not fully automatic. Improved results with these theories are unlikely, as neither gives the precision required for complete computational implementation~\cite{marsden2013}.

Such theoretical limitations led to a modern interpretation of the structural hierarchy: segmentation, motifs (disjoint/repeating patterns), rhythm, harmony, and melody~\cite{msaf,milne,dai2024}. Many approaches partially encode the hierarchy in graphs: topographic mappings for melodic progressions ~\cite{mokbel2009_graph}, graphs for interactions between sections, melody, harmony and rhythm ~\cite{cmu_dannenberg_2020}, multi-edge graphs for bar-level relations~\cite{music_structure_lit_review}, and undirected graphs for melodies and their reductions ~\cite{orio2009}. The prototype graph~\cite{young_2022} is a bipartite network relating prototype elements to the music they represent. Attempts to model the structural hierarchy with formal grammars~\cite{smallest_grammar,repetition_grammars_ismir2023} are limited to segmentation and motifs.

None of these approaches encapsulate the entire hierarchy, and to our knowledge, there have also been no attempts to synthesize representative structure from a music corpus.