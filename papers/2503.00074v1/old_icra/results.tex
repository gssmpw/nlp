\begin{table*}[!ht]
\centering
\rowcolors{3}{}{white}
\caption{Comparison of the model and prediction method.}
\label{table:comparison}
\resizebox{\textwidth}{!}{\begin{tabular}{| c | c |c c c|c c c|c c c|c c c|}
\hline
\multicolumn{2}{|c|}{Training settings} & \multicolumn{12}{c|}{Test environments with: } \\
\hline
\multirow{2}{*}{Methods}  & \multirow{2}{*}{Trained with}
& \multicolumn{3}{c|}{250 robots}
& \multicolumn{3}{c|}{500 robots} 
% & \multicolumn{3}{c|}{750 robots} 
& \multicolumn{3}{c|}{1000 robots}
& \multicolumn{3}{c|}{Average} \\ %\cline{3-18}
                                &
                                &  RMSE & MAPE[\%] & MAE 
                                &  RMSE & MAPE[\%] & MAE 
                                &  RMSE & MAPE[\%] & MAE 
                                % &  RMSE[m] & MAPE[\%] & MAE[rad]
                                &  RMSE & MAPE[\%] & MAE\\
\hline\hline
\multirow{1}{*}{Naive ($A^*$)} 
                                &        
                                & 8.06 & 8.36 & 3.59 
                                & 13.45 & 12.79 & 6.80 
                                & 42.29 & 26.08 & 24.83
                                % & NaN & NaN & NaN 
                                & 21.27 & 15.74 & 11.74\\
\hline\hline
\rowcolor{lightgray}\cellcolor{white}               
                                & \cellcolor{white} 250 robots
                                & 7.18 & 4.59 & 3.19
                                & 12.26 & 8.75 & 5.99
                                & 38.36 & 21.15 & 21.81
                                % & NaN & NaN & NaN 
                                & 19.27 & 11.50 & 10.33 \\
                                
\cellcolor{white}
                                & 500 robots
                                & 7.47 & 4.25 & 3.05
                                & 11.99 & 8.31 & 5.75
                                & 39.15 & 21.27 & 22.28
                                % & NaN & NaN & NaN 
                                & 19.54 & 11.28 & 10.36 \\
                                
                                % & 750 robots
                                % & NaN & NaN & NaN
                                % & NaN & NaN & NaN
                                % & NaN & NaN & NaN
                                % & NaN & NaN & NaN 
                                % & NaN & NaN & NaN\\
                                
\rowcolor{lightgray}\cellcolor{white}
\multirow{-3}{*}{IMS}
                                & \cellcolor{white} 1000 robots 
                                & 7.36 & 4.53 & 3.15
                                & 11.70 & 8.31 & 5.66
                                & 37.79 & 20.46 & 21.30
                                % & NaN & NaN & NaN 
                                & 18.95 & 11.1 & 10.04\\
                                
% \cellcolor{white}\multirow{-4}{*}{IMS}
%                                 & 1-1000 robots 
%                                 & NaN & NaN & NaN
%                                 & NaN & NaN & NaN
%                                 & NaN & NaN & NaN
%                                 % & NaN & NaN & NaN 
%                                 & NaN & NaN & NaN\\
\hline \hline
% \rowcolor{lightgray}
\cellcolor{white}
                                & \cellcolor{white}250 robots
                                % RMSE,  MAPE,  MAE
                                & \textbf{6.14} & \textbf{3.72} & \textbf{2.52}
                                & 9.58 & 7.09 & 4.60
                                & 31.33 & 17.17 & 17.03
                                % & NaN & NaN & NaN 
                                & 15.68 & 9.33 & 8.05 \\
                                
\rowcolor{lightgray}
\cellcolor{white}               
                                & \cellcolor{white}500 robots
                                % RMSE,  MAPE,  MAE
                                & 6.38 & 3.78 & 2.60
                                & 9.17 & \textbf{6.91} & \textbf{4.44}
                                & 28.42 & 16.16 & 15.51
                                % & NaN & NaN & NaN 
                                & 14.66 & 8.95 & 7.52\\
                                
                                % & 750 robots
                                % & NaN & NaN & NaN
                                % & NaN & NaN & NaN
                                % & NaN & NaN & NaN
                                % & NaN & NaN & NaN 
                                % & NaN & NaN & NaN\\
                                
% \rowcolor{lightgray}
\cellcolor{white} 
\multirow{-3}{*}{DMS}              
                                &\cellcolor{white} 1000 robots 
                                % RMSE,  MAPE,  MAE
                                & 6.37 & 4.03 & 2.70
                                & \textbf{9.05} & 7.02 & 4.45
                                & \textbf{25.69} & \textbf{15.39} & \textbf{13.93}
                                % & NaN & NaN & NaN 
                                & \textbf{13.70} & \textbf{8.81} & \textbf{7.03}\\
                                
% \cellcolor{white}\multirow{-4}{*}{DMS}
%                                 & 1-1000 robots 
%                                 & NaN & NaN & NaN
%                                 & NaN & NaN & NaN
%                                 & NaN & NaN & NaN
%                                 % & NaN & NaN & NaN 
%                                 & NaN & NaN & NaN\\
\hline

\end{tabular}}
\end{table*}

\section{Results}
\label{sec:results}
\begin{figure}
    \centering
    \includegraphics[width=0.49\textwidth]{images/Results/final_250.png}
    \caption{The absolute errors are plotted over the path length for the three \ac{DMS} models on the 250 robot test dataset. The shaded areas are the standard deviation over and under the mean absolute error for each of the three models.}
    \label{fig:length-comparison}
\end{figure}
% \begin{enumerate}
    % \item (Table) Compare DMS, IMS, and naive (All the loss functions) \ref{table:comparison}. 
    % \item (Graph) Prediction error over the length of the path.
    % \item (Graph) Prediction error over the number of robots.
% \end{enumerate}

\subsection{Method comparisons}
The first experiment compares the performance of the naive method, which does not use conflict-aware correction, the \ac{IMS} method, and the \ac{DMS} method. As shown in Table \ref{table:comparison}, using conflict-aware correction with either \ac{IMS} or \ac{DMS} significantly reduces error. Comparing the \ac{IMS} and \ac{DMS} methods, it is clear that the \ac{DMS} method is able to learn more from the training data. It is due to the accumulated error issue in \ac{IMS}, as explained in Section \ref{sec:IMS-vs-DMS}. There is a disparity between the training and testing phases, and as the density of robots rises and more conflict happens in the environment, the harder it is for the \ac{IMS} method to adapt to incorrect predictions. The best trained \ac{IMS} model improves the average \ac{MAPE} by 29.5$\%$ compared to the naive method, while the best \ac{DMS} model improves by 44$\%$. 

The second experiment demonstrates the relationship between prediction error and path length. As depicted in Fig. \ref{fig:length-comparison},  the prediction error generated by multi-step prediction methods accumulates in proportion to the path length. Since each prediction is based on the previous prediction, the standard deviation increases rapidly as the number of prediction iterations increases. Around the path length of $175$, the error curve plateau due to less number of robots moving, and hereby less conflict occurs. The standard deviation under the \ac{MAE} curve is smaller compared to above the curve. This depicts that the majority of the predictions lie beneath the \ac{MAE} curve with a smaller error. Contrarily, the standard deviation over the \ac{MAE} curve lies farther away, indicating that the model does not accurately predict a fewer number of paths, therefore generating big standard deviation errors.
% Since the three models have roughly the same curve structure, it seems the dataset could contain some outliers that all models are having trouble predicting.

\subsection{Generalization under different robot densities}
The third and final experiment demonstrates the generalization of the models in environments of varying densities. This is highly pertinent given that the number of robots can vary based on the season, demand, and business case. Therefore, for the industry to freely add or remove robots without retraining, the generalization of the model is of great importance.
As shown in Table \ref{table:comparison}, three different models trained on a dataset containing $250$, $500$, and $1000$ robots are compared at different densities. The results indicate that training in environments of high density generalizes well to environments of low density. This indicates that none of the models are overfitting to any density-specific features in the graph representation. 

The \ac{DMS} models trained with the same number of robots as in the test scenario generally perform slightly better, as depicted in bold in Table. \ref{table:comparison}. However, in the $500$ robot test environment, the $1000$ robot \ac{DMS} model outperforms the $500$ robot \ac{DMS} model in terms of \ac{RMSE}. As more conflicts are happening in higher density environments, the $1000$ robot \ac{DMS} model is generally trained on paths much longer compared to the $500$ robot \ac{DMS} model. As a result, since \ac{RMSE} is sensitive to longer paths as they are accumulating more errors, as shown in experiment two, the $1000$ robot \ac{DMS} is better suited for outliers occurring within the $500$ robot test dataset.
The last column of Table \ref{table:comparison} shows average results in all the test environments. The \ac{DMS} model trained on $1000$ robots has proven to be the most generalized model.