\section{Related work}
\label{sec:related_work}
% \noindent Plan for this section
% \begin{enumerate}
%     \item Traditional methods
%     \item state of the art in ETA pred
%     \item state of the art in multi-agent prediction
% \end{enumerate}
 % This section introduces the foundation of \ac{MAPF}, \ac{GNN}, and \ac{STSF} to understand further the design choices of \ac{CAMAGP}.
\subsection{Traditional \ac{MAPF} solutions}
The problem of \ac{MAPF} \cite{Mapf} involves determining a conflict-free path for each agent on a graph to reach their respective destinations. The passage of time is divided into discrete timesteps, during which each agent executes an atomic action in a synchronized manner, either moving to an adjacent node or remaining in their current location. The types of conflicts are described in \cite{Mapf}, but the ones considered in this paper are the following four conflicts: Vertex, edge, swapping, and cycle conflicts. Vertex conflicts happen when agents are in the same position at the same time. Edge conflicts happen when agents travel along or across the same edge. Swapping conflicts happen when two agents exchange positions. Cycle conflicts happen when multiple agents form a cycling movement.

% While the proposed work does not directly solve the \ac{MAPF} problem, it is tightly correlated. Its primary objective is to validate the discovered route by assuming imperfect plan execution and forecasting conflicts along the route. 
Offline path planning algorithms for the \ac{MAPF} problem are a class of solvers that first perform all computations in a single continuous interval and return a plan for the agents to follow. These plans are generated before the agents begin to move, and the agents follow the plan without any additional computation. This means that the plan cannot contain parts where agents collide. Some offline solvers, such as \ac{CBS} \cite{CBS}, aim to find optimal solutions according to a predefined cost function. However, these methods may not be able to scale up to larger systems due to the exponential growth of the search space as the number of agents increases \cite{yu2013structure}. Other offline algorithms, the \ac{HCA*}\cite{HCA*} and \ac{PIBT}\cite{PIBT}, sacrifice optimality or completeness in order to reduce computation time by using a spatiotemporal reservation table to coordinate agents and avoid collisions. 
A major weakness in offline path planning algorithms is that agents frequently have imperfect plan execution capabilities and cannot perfectly synchronize their motions, leading to frequent and time-consuming replanning \cite{ma2017overview}. This is addressed in \cite{honig2016multi}, where a post-processing framework is proposed, using a simple temporal graph to establish a plan-execution scheduler that guarantees safe spacing between robots. The framework exploits the slack in time-constraints to absorb some of the imperfect plan executions and prevent time-intensive replanning.
The work of \cite{MU} extends the method presented in \cite{M*} for a multi-agent path planner called uncertainty M* that considers collision likelihood to construct the belief space for each agent.
% In \cite{MU}, a multi-agent path planner called uncertainty M* that considers uncertainty in its path planning. The uncertainty M* plans a path through the belief space for each agent and coordinates only likely-to-collide agents using a strategy similar to the prior approach M*\cite{M*}. 
However, this does not guarantee to remove conflicts caused by imperfect plan execution, so an online path planning algorithm is commonly needed for solving these conflicts when they occur.

Online path planning algorithms are a class of solvers that compute partial solutions in real-time, allowing agents to adjust their plans as they execute them. A simple approach for online \ac{MAPF} is \ac{LRA*} \cite{LRA*}, which plans paths for each agent while ignoring other agents. Once the agents start moving, conflicts are resolved locally by constructing detours or repairs for some agents. Another notable online \ac{MAPF} solver is the \ac{WHCA*} algorithm \cite{HCA*}, which is an online variant of the \ac{HCA*} algorithm. \ac{WHCA*} uses a spatiotemporal reservation table to coordinate agents, but only reserves limited paths, splitting the problem up into smaller sections. As agents follow the partially-reserved paths, a new cycle begins from their current locations. In the traditional \ac{WHCA*}, a different ordering of agents is used in each cycle to allow a balanced distribution of the reservation table. An extension of the \ac{WHCA*} is proposed in \cite{COWHCA*}, where a priority is computed based on minimizing future conflicts, improving the success rate, and lowering the computation time. Learning-based methods for online planning are also showing promising results. In \cite{ robotics11050109}, an end-to-end online planning method is introduced, using reinforcement learning to generate safe pathing in dense environments. \cite{9424371} introduces the use of \ac{GNN} for local communication and imitation learning for learning the conflict resolution of \ac{CBS} in multi-agent environments.

\subsection{Spatio-temporal graph neural networks}
A spatio-temporal graph is a combination of spatio representing space or structural information and temporal representing time-varying information. 
Accordingly, if any system consists of a structural relationship between space and time, it can be represented as a spatio-temporal graph. These graphs can be used to design a neural network capable of handling static structures and time-varying characteristics. 
% We can define a spatio-temporal graph as a function of static structure and time-varying features:
% $$G = (V, E, X_{v(t)}, X_{e(t)})$$  
% where $G$ represents the graph, $V$ is the set of nodes, $E$ is the set of edges, $X_{v(t)}$ is the set of node-features at a given time $t$, and $X_{e(t)}$ is the set of edge-features at a given time $t$.

To work with spatio-temporal graphs, we must process a sequence of graph data to build a spatio-temporal embedding that may be used for regression, classification, clustering, or correlation prediction\cite{malla2021social}. The spatial block can be any conventional \ac{GNN} \cite{battaglia2018relational}, while the temporal block can be any approach for learning over sequences of data, such as temporal convolution\cite{temporal-conv, temporal-conv-2} or temporal attention\cite{temporal-attention}. 
Various spatio-temporal \acp{GNN}  conform to the encoding-processing-decoding paradigm \cite{GOOGLE_ETA,battaglia2018relational, keisler2022forecasting}. This paradigm enables us to accommodate the iterative nature of \ac{STSF} and pathfinding algorithms. 
Improving these alignments has been shown to improve \acp{GNN} generalization to a more diverse distribution of graphs\cite{velivckovic2019neural}.
% 

\subsection{\ac{ETA} prediction and spatio-temporal sequence forecasting}
\label{sec:IMS-vs-DMS}
% Generally, \ac{ETA} predictions fall into the category of the \ac{STSF} problem.
The \ac{STSF} problem aims to predict a sequence of length $L$ into the future based on past observations and auxiliary data. The general learning strategies for multi-step forecasting fall into two major categories: \ac{IMS} estimation and \ac{DMS} estimation\cite{forecast_survey}. The \ac{IMS} strategy trains a one-step-ahead forecasting model and iteratively feeds the generated samples to the one-step-ahead forecaster to produce a multi-step-ahead forecast.
There are two main benefits of the \ac{IMS} strategy:
the one-step-ahead forecaster is simple to train because it only needs to consider the one-step-ahead forecasting error, and it can be used to generate predictions of any length. The work of \cite{DCRNN} demonstrates how accounting for graph structure significantly reduces forecasting error across multiple horizons.
% Improving previous work, \cite{Gman} proposes the graph multi-attention network, a transform attention mechanism to transform the historical traffic features into future representations. This attention mechanism models direct relationships between historical and future time steps to alleviate the problem of error propagation.
% This design of spatial GNN combined with temporal component has yielded several subsequent proposals; STGCN\cite{STGCN}, GaAN\cite{GaAN}, ST-GRAT\cite{STGRAT}, and GMAN\cite{Gman}.
However, there is a disparity between the training and testing phase in \ac{IMS}.
In the training phase, the $L$th-step prediction is generated using the ground truths of the previous $L - 1$ steps, while in the testing phase, the model is provided with its previous prediction of the $L - 1$ steps rather than ground truths. This disparity makes the model susceptible to accumulating forecasting errors \cite{bengio2015scheduled}.

\ac{DMS} circumvent the accumulated error issue seen in \ac{IMS} by directly minimizing the long-term prediction error. Rather than training a single model, \ac{DMS} trains a distinct model $m_h$ for each forecasting horizon h. Therefore, the \ac{DMS} approach can support up to $L$ internal models. In order to separate the model size from the number of forecasting steps $L$, we can also construct $m_h$ by recursively applying the one-step-ahead forecaster $m_1$ in order to compute the multi-step-ahead forecasting error. It is worth noting that a multi-step-ahead forecasting error differs from a one-step-ahead forecasting error. Multi-step-ahead forecasting error accumulates the error during the sequence, while one-step-ahead forecasting error only minimizes for one step.
% This recursive \ac{DMS} method is widely adopted in deep learning-based methods including, Google maps\cite{GOOGLE_ETA}, Stg2seq\cite{Stg2seq}, Graph WaveNet\cite{wavenet}, and StemGNN\cite{StemGNN}.
Using \ac{DMS} does not come without cost\cite{chevillon2007direct}. \ac{DMS} is more computationally expensive than \ac{IMS}. For multi-model DMS, $L$ models need to be stored and trained, while recursive \ac{DMS} needs to apply $m_1$ for $\mathcal{O}(L)$ steps. Both cases require a large amount of memory storage or longer training time than solving the \ac{IMS} method. On the other hand, the \ac{IMS} training process is easily parallelizable since each forecasting horizon can be trained independently\cite{Goodfellow-et-al-2016}.

% Papers spatial–temporal graph neural network, GOOGLE_ETA,
In\cite{GOOGLE_ETA}, a homogeneous spatio-temporal \ac{GNN} method for predicting \ac{ETA} is proposed. While the main architecture consists of basic \ac{GNN} building blocks, they propose utilizing a combination of the recursive \ac{DMS} and multi-model \ac{DMS} to improve long horizon predictions. 
% Five models are trained using the recurrent \ac{DMS} for predicting $0$, $10$, $20$, $30$, and $60$ minutes into the futures. The model predicts the time it takes to traverse each node in the system during these five timeslots.
In \cite{huang2022dueta}, a focus on modeling traffic congestion propagation into a congestion-sensitive graph structure is proposed.
% Specifically, instead of directly using the road network as a graph, a congestion-sensitive graph based on the correlations of traffic patterns is introduced.
% In addition, a route-aware graph transformer layer is proposed to directly learn the road segment's long-distance correlations. 
In addition, a route-aware graph transformer layer is proposed enabling \acp{GNN} to capture the interactions between any road segments that are spatially distant but highly correlated with traffic conditions.
A novel heterogeneous graph structure is proposed in \cite{hong2020heteta}, which models both road features and historical data as heterogeneous information. It introduces edge features containing structural information on the relationship between nodes. In addition, three components are introduced to model temporal information from recent periods, daily periods, and weekly periods respectively. Each component comprises temporal convolutions and graph convolutions to learn representations of the spatio temporal heterogeneous information. 

% While all the above-mentioned methods generate excellent results, they focus mainly on the features of the road and consider only a single vehicle traversing the graph. None of the models consider other types of vehicles driving in the environment or how the traffic is influenced due to the driver choosing the route. As a result, such models are not easily converted into multi-vehicle solutions.

The methods mentioned above focus mainly on the features of the road and consider only a single vehicle traversing the graph. None of the models consider other types of vehicles driving in the environment or how the traffic is influenced due to the driver choosing the route. As a result, such models are not easily converted into multi-vehicle solutions.


% you should make comments and comparisons with these papers. One by one, please tell us what they have done and why it is good or bad. What is missing? and what contributions are made after this paper?

%Generally speaking, DMS is preferred for short-term prediction, where the dimensionality of data is very large, and only short-term predictions are required [5], [6]. IMS is preferred for long-term forecasts where the forecasting horizons are long, which are generally above 12 [4], [13] and can be as long as 100 [14].

% \textcolor{red}{Google maps example}
% When looking into how \ac{GNN} \cite{GOOGLE_ETA}



% Mapper
% Graph Neural Networks for Decentralized Multi-Robot Path Planning