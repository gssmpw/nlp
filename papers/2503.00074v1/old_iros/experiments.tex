\section{Experimental Setup}
\label{sec:experiments}
This section concisely describes of the generated training and evaluation datasets, along with the error metrics used for evaluation and training parameters. The first set of experiments focuses on evaluating the accuracy of the \ac{ETA} prediction model, as it is a critical factor for the success of the proposed framework. The second set of experiments compares the proposed framework with state-of-the-art offline planners to assess its overall performance.

\subsection{Simulation environment and noise}
The simulation scenario is based on a discrete grid world where each agent carries out a single action at each time step. The movement of the robots is modeled to operate at full velocity, and as such, the inclusion of noise in the simulation would not result in increased speed. On the contrary, the presence of noise would slow down the movement of the robots, causing them to force a wait action when the noise accumulates to a certain extent.
Offline path planners are evaluated in terms of their robustness to conflicts and imperfections in plan execution due to noise. The experiment is designed to assess the impact of varying levels of imperfect plan execution noise, which are set to the following degrees: $\{0\%, 0.00001\%, 0.0001\%, 0.001\%, 0.01\%\}$. These levels correspond to the probability of a forced wait action resulting from accumulated noise.

We develop the \ac{ETA} prediction module without taking into account the presence of noise in order to avoid any potential bias towards a pre-defined noise level. 
% Although it could be argued that noise could be considered a simplified motion model parameter, for the purpose of ensuring fairness in comparison with other planning methods, the decision was made not to include noise in the training process of the prediction module. 
However, during the evaluation of the overall framework, noise was introduced to all methods to conduct a more comprehensive analysis.

The experiments utilize the \ac{WHCA*} priority method as the online planner to resolve any conflicts that may arise during the simulation. This method was chosen for its simplicity, efficiency, and integration of priority selection into the algorithm.


\subsection{Estimate time of arrival prediction}
\subsubsection{Training data}
\begin{figure}[t]
   \centering
   \includegraphics[width=0.49\textwidth]{images/experiments/Maps-2.pdf}
   \caption{The figure illustrates several examples of the maps utilized in training the multi-agent \ac{ETA} prediction module (enclosed in red), and the map utilized for evaluating the overall performance of the system (enclosed in blue). The depiction of the black pixels indicates occupied spaces, while the white pixels signify unoccupied areas.}
   \label{fig:map_examples}
\end{figure}

The \ac{GNN} is trained on $5000$ unique generated warehouse environments of the size of a maximum $100\times 100$ meter. A few examples of generated maps are displayed in Fig. \ref{fig:map_examples}. The environments are populated with $N=\{250,500,1000\}$ robots, each with a corresponding goal point randomly distributed around the environment. 
%Different
The naive path is computed using the $A^*$ algorithm, which is used as initial input to the \ac{GNN} model. \ac{PIBT} and \ac{CBS} are not chosen as naive path planning methods for a couple of reasons. First, they modify the path of all robots and not just a single robot. Second, as the training simulation does not consider any noise or imperfect plan execution, this is the perfect scenario for these methods, resulting in no conflicts. After performing the simulation, the actual arrival time is recorded and used as the label.

\subsubsection{Evaluation criteria}
The loss function used during training is the \ac{MAPE}. \ac{MAPE} computes the percentage between predicted values $\hat{y}$ and ground truth $y$: $MAPE = \frac{1}{m}\sum_{i=1}^{m}| \hat{y_i} - y_i | / y_i.$ It is the most popular metric for \ac{ETA} prediction tasks, as the percentage penalizes the relative distance error, making it robust against outliers compared to \ac{RMSE}, which is strongly penalizing the outliers with big errors.

\subsubsection{Training parameters}
The training and evaluation are conducted using an NVIDIA GeForce RTX 3090Ti GPU with 24GB VRAM. A high amount of VRAM is proven essential when training as the space required for computing the gradient of long temporal graphs is very high. However, the gradient is not computed during inference time, so a large amount of VRAM is no longer required. Due to the extensive use of VRAM, only a batch size of one is used during training. We use the Adam optimizer, while the learning rate $\gamma=0.001$ was scheduled to decay with $0.75$ every $8$th epoch. Each model has roughly trained 20 epochs, which with our hardware configuration, would take $36$ to $48$ hours.
While training takes a long time to complete, the inference time is between $400$ to $700$ ms depending on the number of robots and the length of the paths.

\subsection{Evaluation of the offline path planners}
% In this experiment, the performance of offline path planners is evaluated in terms of their robustness to conflicts and imperfections in plan execution due to noise. The experiment is designed to assess the impact of varying levels of imperfect plan execution noise, which are set to the following degrees: $\{0\%, 0.00001\%, 0.0001\%, 0.001\%, 0.01\%\}$. These levels correspond to the probability of a forced wait action resulting from accumulated noise.
% Four different offline path planning methods will be compared for their robustness in the presence of conflicts and plan execution noise. The methods to be compared include: $A^*$, \ac{PIBT}, \ac{CBS}, and \ac{CAMETA}.

The proposed method \ac{CAMETA} is evaluated against other offline path planning methods, including $A^*$, \ac{PIBT}, and \ac{CBS} with respect to their robustness in the presence of conflicts and plan execution noise.
The $A^*$ is chosen as a method that does not take into account the presence of other agents or conflicts in the paths being planned. \ac{PIBT} is chosen as a suboptimal method that is designed to be computationally efficient and considers both all agents and conflicts. \ac{CBS} is chosen as an optimal method. Although less computationally efficient than \ac{PIBT} and cannot run in real-time, it is able to determine the optimal paths for all agents.
% Finally, \ac{CAMETA} is a conflict-aware approach, which aims to minimize conflicts by estimating the time required to resolve the whole path, including the conflict, rather than relying on paths that are conflict-free.

The environment chosen for the experiment is shown in Fig. \ref{fig:map_examples} enclosed in blue. The map features both open spaces as well as corridors and potential bottlenecks. Each experiment will be conducted with $500$ agents and repeated $100$ times with different seeds of noise to eliminate a method being unlucky with the noise. However, the starting position and destination of robots will remain the same across all methods and seeds. The average \textit{makespan}, which is the average time for all robots to finish, and the sum of costs are presented in the results section.