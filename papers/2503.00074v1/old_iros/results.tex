\input{LargeObjects/ETAResultTable.tex}
% \input{LargeObjects/CostResultTable.tex}
\section{Results}
\label{sec:results}

% \begin{figure}
%     \centering
%     \includegraphics[width=0.49\textwidth]{images/Results/final_250.png}
%     \caption{The absolute errors are plotted over the path length for the three \ac{DMS} models on the 250 robot test dataset. The shaded areas are the standard deviation over and under the mean absolute error for each of the three models.}
%     \label{fig:length-comparison}
% \end{figure}
% \begin{enumerate}
    % \item (Table) Compare DMS, IMS, and naive (All the loss functions) \ref{table:comparison}. 
    % \item (Graph) Prediction error over the length of the path.
    % \item (Graph) Prediction error over the number of robots.
% \end{enumerate}
% \begin{figure*}
%     \centering
%     % \begin{subfigure}[b]{0.2\textwidth}
%     %      \centering
%     %      \includegraphics[width=\textwidth]{images/Results/paper_448x448_3.png}
%     %     %  \caption{The plot shows the increase in sum of costs as noise is applied in various degrees.}
%     %      \label{fig:socs}
%     % \end{subfigure}
%     % \vspace*{\fill}
%     %  \hfill
%     \begin{subfigure}[b]{0.45\textwidth}
%          \centering
%          \includegraphics[width=\textwidth]{images/Results/noise_soc_results-1.pdf}
%         %  \caption{The plot shows the increase in sum of costs as noise is applied in various degrees.}
%      \end{subfigure}
%      \hfill
%      \begin{subfigure}[b]{0.45\textwidth}
%          \centering
%          \includegraphics[width=\textwidth]{images/Results/noise_makespan_results-1.pdf}
%         %  \caption{The plot shows the increase in makespan as noise is applied in various degrees.}
%      \end{subfigure}
    
%     \caption{The two plots illustrates the results of noise in various degrees can greatly affect both sum of costs and makespan.}
%     \label{fig:noise-results}
% \end{figure*}

\subsection{Estimate time of arrival prediction}
\subsubsection{Method comparisons}
The first experiment compares the performance of the naive method, which does not use conflict-aware correction, the \ac{IMS} method, and the \ac{DMS} method. As shown in Table \ref{table:comparison}, using conflict-aware correction with either \ac{IMS} or \ac{DMS} significantly reduces error.
It can be seen that the \ac{DMS} methods perform better than \ac{IMS} methods due to the accumulated error nature in \ac{IMS},
% Comparing the \ac{IMS} and \ac{DMS} methods, it is clear that the \ac{DMS} method is able to learn more from the training data. It is due to the accumulated error issue in \ac{IMS},
as explained in Section \ref{sec:IMS-vs-DMS}. There is a disparity between the training and testing phases, and as the density of robots rises and more conflict happens in the environment, the harder it is for the \ac{IMS} method to adapt to incorrect predictions. The best trained \ac{IMS} model improves the average \ac{MAPE} by 29.5$\%$ compared to the naive method, while the best \ac{DMS} model improves by 44$\%$. 

% The second experiment demonstrates the relationship between prediction error and path length. As depicted in Fig. \ref{fig:length-comparison},  the prediction error generated by multi-step prediction methods accumulates in proportion to the path length. Since each prediction is based on the previous prediction, the standard deviation increases rapidly as the number of prediction iterations increases. Around the path length of $175$, the error curve plateau due to less number of robots moving, and hereby less conflict occurs. The standard deviation under the \ac{MAE} curve is smaller compared to above the curve. This depicts that the majority of the predictions lie beneath the \ac{MAE} curve with a smaller error. Contrarily, the standard deviation over the \ac{MAE} curve lies farther away, indicating that the model does not accurately predict a fewer number of paths, therefore generating big standard deviation errors.

% Since the three models have roughly the same curve structure, it seems the dataset could contain some outliers that all models are having trouble predicting.

\subsubsection{Generalization under different robot densities}
The second experiment demonstrates the generalization of the models in environments of varying densities. This is highly pertinent given that the number of robots can vary based on the season, demand, and business case. Therefore, for the industry to freely add or remove robots without retraining, the generalization across densities is of great importance.
As shown in Table \ref{table:comparison}, three different models trained on a dataset containing $250$, $500$, and $1000$ robots are compared at different densities. The results indicate that training in environments of high density generalizes well to environments of low density. This implies that none of the models are overfitting to any density-specific features in the graph representation. 

The \ac{DMS} models trained with the same number of robots as in the test scenario generally perform slightly better, as depicted in bold in Table. \ref{table:comparison}. However, in the $500$ robot test environment, the $1000$ robot \ac{DMS} model outperforms the $500$ robot \ac{DMS} model in terms of \ac{RMSE}. As more conflicts are happening in higher density environments, the $1000$ robot \ac{DMS} model is generally trained on paths much longer compared to the $500$ robot \ac{DMS} model. As a result, since \ac{RMSE} is sensitive to longer paths as they are accumulating more errors, as shown in experiment two, the $1000$ robot \ac{DMS} is better suited for outliers occurring within the $500$ robot test dataset.
The last column of Table \ref{table:comparison} shows average results in all the test environments. The \ac{DMS} model trained on $1000$ robots has proven to be the most generalized model.

\subsection{Evaluation of the offline path planners}

\begin{figure}[t]
   \centering
   \includegraphics[width=0.49\textwidth]{images/Results/noise_makespan_results.pdf}
   \caption{The plot shows the increase in makespan as noise is applied in various degrees. As the cost function priorities the agents with the tightest schedule, a stable makespan can be seen for \ac{CAMETA}.}
   \label{fig:noise-results-makespan}
\end{figure}
\begin{figure}[t]
   \centering\includegraphics[width=0.49\textwidth]{images/Results/noise_soc_results.pdf}
   \caption{The plot shows the increase in sum of costs as noise is applied in various degrees. Both \ac{PIBT} and \ac{CBS} rises as the noise increases, while $A^*$ and \ac{CAMETA} is less affected by the noise.}
   \label{fig:noise-results-soc}
\end{figure}
% The results of the path planners under the influence of noise are presented in Fig. \ref{fig:noise-results-makespan} and Fig. \ref{fig:noise-results-soc}. The \ac{CBS} method yielded the optimal solution at a noise level of $0\%$, which highlights the disparity between this method and the real-time counterparts. While the \ac{CBS} algorithm demonstrates superior performance in terms of \ac{SOC} compared to other methods, its computational time was extremely long, taking four hours to generate the optimal solution.

% The \ac{CAMETA} and \ac{PIBT} methods yielded comparable results at $0\%$ noise, with \ac{CAMETA} outperforming \ac{PIBT} by utilizing the exploration of alternative paths with fewer conflicts. In contrast, \ac{PIBT} only resolved conflicts based on the $A^*$ algorithm, incorporating 'wait' actions and priority inheritance. 
% The basic $A^*$ method yielded the poorest results at this noise level, as expected, due to the lack of conflict resolution in the planning.

% As the noise level increased, \ac{PIBT} demonstrated a decrease in performance due to the coordinated nature of its planned paths, which left little room for error. The additional moves planned for conflict resolution did not align with the expected conflicts, leading to the generation of even more conflicts, resulting in a rapid increase in total moves required to resolve everything as the noise level increased. This is reflected in Fig. \ref{fig:noise-results-soc} as a rapid increase in \ac{SOC} for the \ac{PIBT} method. The online planner, \ac{WHCA*}, took over to resolve conflicts as the noise level increased. However, due to the extra moves already planned for conflicts, conflicts arising from noise were harder to resolve.

% Both the basic $A^*$ and \ac{CAMETA} methods demonstrated a stable pattern as the noise level increased, as they relied on conflicts being resolved in real-time, making it easier for the online planner to correct. However, \ac{CAMETA} exhibited much better overall results in terms of total \ac{SOC} and makespan, as it reduced the number of conflicts by allowing for longer routes and distributing traffic, resulting in noise not affecting the planned path as much.

% Overall, the results suggest that while \ac{CBS} may provide the optimal solution in terms of \ac{SOC}, it is not a feasible solution for real-time applications. On the other hand, \ac{CAMETA} exhibits more promising and stable performance in terms of real-time path planning under noisy conditions.


The results of the path planners under the effect of noise are presented in Fig. \ref{fig:noise-results-makespan} and Fig. \ref{fig:noise-results-soc}. The \ac{CBS} method yields the optimal solution at a noise level of $0\%$, which highlights the disparity between this method and the real-time counterparts. While the \ac{CBS} algorithm demonstrates superior performance in terms of \ac{SOC} compared to other methods, its computational time is extremely long, taking four hours to generate the optimal solution.

The \ac{CAMETA} and \ac{PIBT} methods yield comparable results at $0\%$ noise, with \ac{CAMETA} outperforming \ac{PIBT} by utilizing the exploration of alternative paths with fewer conflicts. In contrast, \ac{PIBT} only resolves conflicts based on the $A^*$ algorithm, incorporating 'wait' actions and priority inheritance.
The basic $A^*$ method yields the poorest results at this noise level, as expected, due to the lack of conflict resolution in the planning. As the noise level increases, \ac{PIBT} demonstrates a decrease in performance due to the coordinated nature of its planned paths, which leaves little room for error. The additional moves planned for conflict resolution do not align with the expected conflicts, leading to even more conflicts, resulting in a rapid increase in total moves required to resolve everything as the noise level increases. This is reflected in Fig. \ref{fig:noise-results-soc} as a rapid increase in \ac{SOC} for the \ac{PIBT} method. The online planner, \ac{WHCA*}, resolves conflicts as the noise level increases. However, due to the extra moves already planned for conflicts, conflicts arising from noise are harder to resolve.

Both the basic $A^*$ and \ac{CAMETA} methods demonstrate a stable pattern as the noise level increases, as they rely on conflicts being resolved in real-time, making it easier for the online planner to correct. However, \ac{CAMETA} exhibits better results in terms of total \ac{SOC} and makespan, as it reduces the number of conflicts by allowing for longer routes and distributing traffic, resulting in noise not affecting the planned path as much.

Overall, the results illustrate that while \ac{CBS} may provide the optimal solution in terms of \ac{SOC}, it is not a feasible solution for real-time applications. On the other hand, \ac{CAMETA} exhibits more promising and stable performance in terms of real-time path planning under noisy conditions.