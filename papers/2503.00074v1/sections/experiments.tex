\section{Experimental Setup}
\label{sec:experiments}
This section concisely describes the generated training and evaluation datasets and the error metrics used for evaluation and training parameters. The first set of experiments focuses on evaluating the accuracy of the \ac{ETA} prediction model, as it is a critical factor for the success of the proposed framework. The second set of experiments compares the proposed framework with state-of-the-art global planners to assess its overall performance.

\subsection{Simulation environment and noise}
% The simulation scenario is based on a discrete grid world where each agent carries out a single action at each time step. However, accurately modeling noise in such a setting can be challenging, as a full action would need to be performed at each time step, resulting in noise having a significant impact within a single time step. 
% To address this challenge and simplify the incorporation of noise, the movement of the agents is modeled to operate at full velocity. As such, the inclusion of noise in the simulation would not result in increased speed. On the contrary, the presence of noise would slow down the movement of the agents, causing them to force a wait action.
Global path planners are evaluated in terms of their robustness to conflicts and imperfections in plan execution due to noise. The experiment is designed to assess the impact of varying levels of imperfect plan execution noise, which are set to the following degrees: $\{0\%, 0.00001\%, 0.0001\%, 0.001\%, 0.01\%\}$. These levels correspond to the probability of a forced wait action resulting from accumulated noise.

We develop the \ac{ETA} prediction module without considering the presence of noise to avoid any potential bias towards a pre-defined noise level. However, during the evaluation of the overall framework, noise was introduced to all methods to conduct a more comprehensive analysis.

The experiments utilize the \ac{WHCA*} priority method as the local planner to resolve any conflicts that may arise during the simulation. This method was chosen for its simplicity, efficiency, and integration of priority selection into the algorithm. A constant time constraint is applied for all agents, prioritizing agents with longer paths. 

\subsection{Estimate time of arrival prediction}
\subsubsection{Training data}
\begin{figure}[t]
   \centering
   \includegraphics[width=0.49\textwidth]{images/experiments/Maps-2.pdf}
   \caption{The figure illustrates several examples of the maps utilized in training the multi-agent \ac{ETA} prediction module (enclosed in red), and the map utilized for evaluating the overall performance of the system (enclosed in blue). The depiction of the black pixels indicates occupied spaces, while the white pixels signify unoccupied areas.}
   \label{fig:map_examples}
\end{figure}

The \ac{GNN} is trained on $5000$ unique generated warehouse environments of the size of a maximum $100\times 100$ meter. A few generated map examples are displayed in Fig. \ref{fig:map_examples}. The environments are populated with $N=\{250,500,1000\}$ robots, each with a corresponding goal point randomly distributed around the environment. 
%Different
The naive path is computed using the $A^*$ algorithm, which is used as initial input to the \ac{GNN} model. \ac{PIBT} and \ac{CBS} are not chosen as naive path planning methods for a couple of reasons. First, they modify the path of all robots and not just a single robot. Second, as the training simulation does not consider any noise or imperfect plan execution, this is the perfect scenario for these methods, resulting in no conflicts. After performing the simulation, the actual arrival time is recorded and used as the label.

\subsubsection{Evaluation criteria}
The loss function used during training is the \ac{MAPE}. \ac{MAPE} computes the percentage between predicted values $\hat{y}$ and ground truth $y$: $MAPE = \frac{1}{m}\sum_{i=1}^{m}| \hat{y_i} - y_i | / y_i.$ It is the most popular metric for \ac{ETA} prediction tasks, as the percentage penalizes the relative distance error, making it robust against outliers compared to \ac{RMSE}, which strongly penalizes the outliers with big errors.

\subsubsection{Training parameters}
The training and evaluation are conducted using an NVIDIA GeForce RTX 3090Ti GPU with 24GB VRAM. A high amount of VRAM is proven essential when training as the space required for computing the gradient of long temporal graphs is very high. However, the gradient is not computed during inference time, so a large amount of VRAM is no longer required. Due to the extensive use of VRAM, only a batch size of one is used during training. We use the Adam optimizer, while the learning rate $\gamma=0.001$ was scheduled to decay with $0.75$ every $8$th epoch. Each model has roughly trained 20 epochs, which with our hardware configuration, would take $36$ to $48$ hours.
While training takes a long time to complete, the inference time is between $400$ to $700$ ms depending on the number of robots and the length of the paths.

\subsection{Evaluation of the global path planners}
% In this experiment, the performance of global path planners is evaluated in terms of their robustness to conflicts and imperfections in plan execution due to noise. The experiment is designed to assess the impact of varying levels of imperfect plan execution noise, which are set to the following degrees: $\{0\%, 0.00001\%, 0.0001\%, 0.001\%, 0.01\%\}$. These levels correspond to the probability of a forced wait action resulting from accumulated noise.
% Four different global path planning methods will be compared for their robustness in the presence of conflicts and plan execution noise. The methods to be compared include: $A^*$, \ac{PIBT}, \ac{CBS}, and \ac{CAMETA}.

The proposed method \ac{CAMETA} is evaluated against other global path planning methods, including $A^*$, \ac{PIBT}, and \ac{CBS} with respect to their robustness in the presence of conflicts and plan execution noise.
The $A^*$ is chosen as a method that does not take into account the presence of other agents or conflicts in the paths being planned. \ac{PIBT} is chosen as a suboptimal method that is designed to be computationally efficient and considers both all agents and conflicts. \ac{CBS} is chosen as an optimal method. Although less computationally efficient than \ac{PIBT} and cannot run in real-time, it can determine the optimal paths for all agents.
% Finally, \ac{CAMETA} is a conflict-aware approach, which aims to minimize conflicts by estimating the time required to resolve the whole path, including the conflict, rather than relying on conflict-free paths.

The environment chosen for the experiment is shown in Fig. \ref{fig:map_examples} enclosed in blue. The map features both open spaces as well as corridors and potential bottlenecks. Each experiment will be conducted with $500$ agents and repeated $100$ times with different seeds of noise to eliminate a method being unlucky with the noise. However, the starting position and destination of robots will remain the same across all methods and seeds. The average \textit{makespan}, which is the average time for all robots to finish, and the \ac{SOC} are presented in the results section.