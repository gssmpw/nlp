%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}


\newcommand{\mehdi}[1]{\textcolor{red}{#1}}

\newcommand{\adrian}[1]{\textcolor{blue}{#1}}


% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{mPOLICE: Provable Enforcement of Multi-Region Affine Constraints in Deep Neural Networks}


\begin{document}

\twocolumn[
    \icmltitle{mPOLICE: Provable Enforcement of Multi-Region Affine Constraints in \\ Deep Neural Networks}

    % It is OKAY to include author information, even for blind
    % submissions: the style file will automatically remove it for you
    % unless you've provided the [accepted] option to the icml2024
    % package.

    % List of affiliations: The first argument should be a (short)
    % identifier you will use later to specify author affiliations
    % Academic affiliations should list Department, University, City, Region, Country
    % Industry affiliations should list Company, City, Region, Country

    % You can specify symbols, otherwise they are numbered in order.
    % Ideally, you should not use this facility. Affiliations will be numbered
    % in order of appearance and this is the preferred way.
    % \icmlsetsymbol{equal}{*}

    \begin{icmlauthorlist}
    \icmlauthor{Mohammadmehdi Ataei}{adsk}
    \icmlauthor{Hyunmin Cheong}{adsk}
    \icmlauthor{Adrian Butscher}{adsk}
    % \icmlauthor{Firstname4 Lastname4}{sch}
    % \icmlauthor{Firstname5 Lastname5}{yyy}
    % \icmlauthor{Firstname6 Lastname6}{sch,yyy,comp}
    % \icmlauthor{Firstname7 Lastname7}{comp}
    % %\icmlauthor{}{sch}
    % \icmlauthor{Firstname8 Lastname8}{sch}
    % \icmlauthor{Firstname8 Lastname8}{yyy,comp}
    % %\icmlauthor{}{sch}
    % %\icmlauthor{}{sch}
    \end{icmlauthorlist}

    \icmlaffiliation{adsk}{Autodesk Research, Toronto, Canada}

    \icmlcorrespondingauthor{Mohammadmehdi Ataei}{mehdi.ataei@autodesk.com}

    % You may provide any keywords that you
    % find helpful for describing your paper; these are used to populate
    % the "keywords" metadata in the PDF but will not be shown in the document
    \icmlkeywords{Constraint Satisfaction, Affine Constraints, Deep Neural Networks, Convex Optimization, Reinforcement Learning, Physics-Based Machine Learning}

    \vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Deep neural networks are increasingly employed in fields such as climate modeling, robotics, and industrial control, where strict output constraints must be upheld. Although prior methods like the POLICE algorithm can enforce affine constraints in a single convex region by adjusting network parameters, they struggle with multiple disjoint regions, often leading to conflicts or unintended affine extensions. We present mPOLICE, a new method that extends POLICE to handle constraints imposed on multiple regions. mPOLICE assigns a distinct activation pattern to each constrained region, preserving exact affine behavior locally while avoiding overreach into other parts of the input domain. We formulate a layer-wise optimization problem that adjusts both the weights and biases to assign unique activation patterns to each convex region, ensuring that constraints are met without conflicts, while maintaining the continuity and smoothness of the learned function. Our experiments show the enforcement of multi-region constraints for multiple scenarios, including regression and classification, function approximation, and non-convex regions through approximation. Notably, mPOLICE adds zero inference overhead and minimal training overhead.
\end{abstract}

\section{Introduction}
Deep neural networks (DNNs) have achieved remarkable success in a wide range of domains, from computer vision and natural language processing to scientific simulations and decision-making tasks. Nonetheless, many real-world applications require these models to produce outputs that satisfy strict constraints. Such constraints often arise from domain knowledge, safety requirements, physical laws, or regulatory guidelines. For example, in climate modeling and fluid simulations, boundary conditions must hold to ensure physically plausible predictions~\citep{PhysRevLett.126.098302,XIE2024117223}; and in robotics, guaranteeing feasible, collision-free trajectories is critical for safety~\citep{kondo2024cgd,bouvier2024policed,bouvier2024learning}.

However, enforcing hard constraints within DNNs is difficult. Traditional training approaches and architectures do not guarantee that constraints will be satisfied, often relying on soft penalties, data augmentation, or post-processing techniques that do not offer any provable guarantees~\citep{kotary2021end,kotary2024learning}. Moreover, strategies that rely on sampling-based corrections or complicated architectures can degrade performance and robustness, or fail to scale efficiently to high-dimensional spaces and complex constraints~\citep{Li_2018_ECCV,tordesillas2023rayen}.

On the other hand, the POLICE algorithm proposed by ~\citeauthor{police} is a technique that guarantees provably optimal linear (affine) constraint enforcement for DNNs within a single convex region defined over the input space by a number of vertices, doing so without adding inference-time overhead and without sacrificing the model's general expressiveness outside that region. POLICE was specifically designed to handle affine constraints deterministically by adjusting the network's biases to provably meet the desired constraints. The method has recently found success in reinforcement learning applications, where it was applied to learn control policies with provable safety guarantees~\citep{bouvier2024policed,bouvier2024learning}. However, the original method is fundamentally limited to enforcing constraints in only one convex region~\citep{bouvier2024learning}. In fact, naïvely extending it to multiple regions introduces conflicts and often yields unintended affine behavior over the convex hull of these regions (see \cref{fig:convexhull}); both the POLICE paper and subsequent work in robotics and RL have noted this limitation and highlighted this challenge as an important future research topic~\citep{bouvier2024policed,bouvier2024learning,police}.

In this paper, we present a novel extension of POLICE, referred to as mPOLICE, that overcomes this limitation and enables the exact enforcement of affine constraints in multiple disjoint convex regions simultaneously. Our key insight is to assign unique activation patterns to each constrained region. By doing so, we ensure that each region is distinguished in the network's internal representation, preventing unwanted affine extrapolation across combined regions. We build on the rigorous theoretical foundation provided by the original POLICE framework~\citep{police}, and integrate recent advances in constrained optimization with deep learning~\citep{kotary2021end,kotary2024learning,PhysRevLett.126.098302,Li_2018_ECCV,tordesillas2023rayen,bouvier2024learning,zhong2023neural} to achieve robust and reliable constraint enforcement.

\textbf{Our contributions can be summarized as follows:}
\begin{itemize}
    \item We introduce an algorithm to assign unique neuron activation patterns for each constrained region, ensuring no conflicts arise when enforcing affine constraints in multiple disjoint regions of the input domain.
    \item Our approach ensures that affine constraints remain localized to the intended regions without limiting the network's learning of complex behavior elsewhere.
    \item Our method is seamlessly integrated into standard training procedures, imposes no additional inference overhead, and maintains the continuity and smoothness of the learned function.
    \item We demonstrate that our method can be used for non-convex constraint regions by placing multiple disjoint convex regions in close proximity.

\end{itemize}

By enabling reliable constraint enforcement in multiple disjoint regions, our approach expands the applicability of DNNs to a broader class of tasks that require satisfying hard constraints. This development paves the way for safer autonomous systems, more trustworthy physical simulations, and compliance-driven industrial applications where exact adherence to constraints is non-negotiable.

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\textwidth]{figs/policevsmpolice.png}
    \caption{Comparison of single-region enforcement (POLICE) versus multi-region enforcement (mPOLICE). Each colored zone represents a distinct convex region where affine behavior must be preserved. The single-region approach enforces the same ReLU activation pattern for all these zones, which forces the network to be affine over their combined convex hull (middle). In contrast, mPOLICE assigns unique neuron activation patterns to each region, preventing unintended affine extrapolation across disjoint areas (right).}
    \label{fig:convexhull}
\end{figure*}


\subsection{Related Work}
The integration of constraints into neural networks and training has been explored across various contexts. Early research focused on using neural networks to solve constrained optimization problems through penalty methods for analog circuits~\citep{286888,995659}, and foundational work in applied dynamic programming established theoretical links between neural representations and optimization~\citep{bellman2015applied}. More recently, the paradigm of \emph{Learning to Optimize} has gained traction, blending machine learning and combinatorial optimization to solve complex constrained problems efficiently~\citep{kotary2021end,kotary2024learning}, guiding the optimization process with generative models \cite{giannone2023aligning, picard2024generative}, and solving problems with constraints due to physical laws or domain rules~\citep{PhysRevLett.126.098302,doi:10.1137/21M1397908,XIE2024117223,pmlr-v168-djeumou22a}.

Beyond penalty methods, techniques have emerged to enforce constraints directly through the network architecture. For instance, approaches have been developed to ensure monotonicity, convexity, or linear constraints on the network output~\citep{Li_2018_ECCV,tordesillas2023rayen,konstantinov2024imposing,zhong2023neural}. Physics-informed neural networks (PINNs) have become popular for embedding differential constraints derived from physical systems directly into the training process~\citep{NEURIPS2021_df438e52,NEURIPS2021_d5ade38a}, and other strategies impose affine or inequality-based constraints to guarantee safe and consistent predictions~\citep{kondo2024cgd,bouvier2024policed,bouvier2024learning}. Another method developed specifically for Bayesian optimization uses a transformer-based model to predict the expected improvements for constraints \cite{yu2024fast}, based on the idea that transformers can do Bayesian inference \cite{muller2021transformers}.

The POLICE algorithm~\citep{police} contributed to this landscape by offering a systematic method to enforce affine constraints in a single convex region without increasing inference complexity. However, POLICE did not address the complexities arising when multiple disjoint constrained regions must be handled simultaneously. Our work builds on POLICE and extends it to multiple regions, bridging a critical gap in the literature and providing a new foundation for multi-region constrained DNN training.

\section{Methodology}
\label{sec:methodology}

In this section, we present a detailed methodology for ensuring the affine behavior of deep ReLU networks across multiple disjoint convex regions of the input space. Our development extends the single-region POLICE algorithm to handle multiple regions simultaneously and integrates new techniques for sign assignment and constraint enforcement. The goal is to ensure that, within each specified region, the network remains strictly affine and meets the affine constraints given, while avoiding unintended affine extrapolations beyond these regions.

\subsection{Piecewise Affine Structure of ReLU Networks}

A feedforward ReLU network defines a continuous piecewise affine function. Formally, each layer $\ell$ computes
\[
    \boldsymbol{z}^{(\ell)}=\boldsymbol{W}^{(\ell)}\boldsymbol{x}^{(\ell)}+\boldsymbol{b}^{(\ell)}, \quad \boldsymbol{x}^{(\ell+1)}=\sigma(\boldsymbol{z}^{(\ell)}),
\]
where $\boldsymbol{W}$ and $\boldsymbol{b}$ are the layer $\ell$'s weights and biases, with $\boldsymbol{x}^{(1)}=\boldsymbol{x}$ where $\boldsymbol{x}$ is input to the network and $\sigma(u)=\max(u,0)$. Each ReLU neuron introduces half-space constraints splitting the input domain into two regions depending on its sign. Stacking $L$ layers yields a finite set of simultaneously satisfiable inequalities that produce a finite collection of $T$ convex polytopes $\{\mathcal{R}_r\}_{r=1}^T$. On each such polytope, the activation pattern is fixed, making $f_{\boldsymbol{\theta}}(\boldsymbol{x})$ an affine function $\boldsymbol{A}_r \boldsymbol{x} + \boldsymbol{c}_r$. This piecewise affine property is central: ensuring each region $R_i$ lies entirely within one such polytope guarantees that $f_{\boldsymbol{\theta}}$ is affine on $R_i$. Note that the same property is applicable to any network with linear or piecewise linear activations (e.g., Leaky-ReLU).


\subsection{Problem Setup and Preliminaries}
\label{subsec:problem_setup}
Consider a deep neural network $f_{\boldsymbol{\theta}}:\mathbb{R}^D \to \mathbb{R}^K$ with parameters $\boldsymbol{\theta}$. Assume there are $N$ disjoint convex polytopal regions $\{R_i\}_{i=1}^N$. Each region $R_i$ can be described by a finite set of vertices $\{\boldsymbol{v}_p^{(i)}\}_{p=1}^{P_i}$. Enforcing constraints in these regions involves ensuring that  $\forall \boldsymbol{x}\in R_i$, the network outputs $f_{\boldsymbol{\theta}}(\boldsymbol{x})$ satisfy certain linear conditions, such as
\begin{align}
    &\boldsymbol{E}_i f_{\boldsymbol{\theta}}(\boldsymbol{x}) = \boldsymbol{f}_i.\label{eqn:equality} \\
    &\boldsymbol{C}_i f_{\boldsymbol{\theta}}(\boldsymbol{x}) \leq \boldsymbol{d}_i,\label{eqn:inequality}
\end{align}
These combined constraints can encode important domain knowledge. The key difficulty is that simply sampling $f_{\boldsymbol{\theta}}$ cannot guarantee constraint satisfaction in $\boldsymbol{x}\in R_i$.

A solution can be to impose \emph{affinity} over $R_i$ by restricting each region $R_i$ to a unique affine polytope $\mathcal{R}_r$. Then, $f_{\boldsymbol{\theta}}$ becomes a linear function on $R_i$:
\[
    f_{\boldsymbol{\theta}}(\boldsymbol{x}) \;=\;
    \mathbf{\Lambda}_i \,\boldsymbol{x} \;+\; \boldsymbol{\gamma}_i, 
    \quad \boldsymbol{x} \in R_i,
\]
An affine constraint over $R_i$ (e.g., \cref{eqn:equality} or \cref{eqn:inequality}) then only needs to be checked on the \emph{finite} set of vertices $\{\mathbf{v}_p^{(i)}\}_{p=1}^{P_i}$. This reduces the infinite-dimensional verification to a finite set of linear equations or inequalities:
\[
    \boldsymbol{E}_i\,(\mathbf{\Lambda}_i\,\mathbf{v}_p^{(i)} + \boldsymbol{\gamma}_i)
    \;=\;
    \boldsymbol{f}_i,
    \quad
    \text{or}
    \quad
    \boldsymbol{C}_i\,(\mathbf{\Lambda}_i\,\mathbf{v}_p^{(i)} + \boldsymbol{\gamma}_i)
    \;\le\;
    \boldsymbol{d}_i.
\]


The key difficulty is that $f_{\theta}$ may not be affine on $R_i$ initially, nor may $R_i$ align with a single affine polytope of the piecewise affine decomposition induced by the network's (Leaky)-ReLU activations.

\subsection{From Single to Multiple Regions and the Convex Hull Problem}
\label{subsec:from_single_to_multi_regions}

The original POLICE algorithm \citep{police} was designed to ensure the exact affine behavior of a deep ReLU network $f_{\boldsymbol{\theta}}$ within a single convex region $R$. By enforcing consistent pre-activation sign patterns across all vertices of that region, the algorithm guarantees that $R$ is contained within a single activation polytope of the network's piecewise affine decomposition (this is a known property of such networks~\citep{montufar2014number}. See Theorem~\ref{thm:concise_proof} in Appendix for a simple formal proof). At a high level, given $R = \{\boldsymbol{v}_1, \ldots, \boldsymbol{v}_P\}$, the algorithm identifies a binary sign pattern $\boldsymbol{s} = (s_1, \ldots, s_{D})$ and adjusts the parameters so that:
\begin{equation}
\label{eq:police_single_region_constraint}
0 \leq \min_{p \in [P]} (\boldsymbol{H}_{p,k} s_k), \quad \text{for all } k \in \{1, \ldots, D\} \,,
\end{equation}
where $\boldsymbol{H} \triangleq \boldsymbol{V}^{(\ell)}(\boldsymbol{W}^{(\ell)})^T + \mathbf{1}_{P}(\boldsymbol{b}^{(\ell)})^{T}$ is the pre-activation matrix of layer $\ell$ over the vertices of $R$. Here, $s_k \in \{-1,+1\}$ encodes on which side of the hyperplane defined by the $k$-th neuron the region $R$ is placed. By ensuring that all vertices share the same sign pattern, $R$ is effectively ``trapped'' inside a single affine polytope of the network. As a result, $f_{\boldsymbol{\theta}}$ behaves as a linear (affine) function on $R$.

However, this approach implicitly assumes that we are dealing with \emph{only one} region. When extending this idea to multiple disjoint convex regions $\{R_i\}_{i=1}^{N}$, a fundamental complication arises: if we apply the original POLICE logic independently to each region, naively using the same mechanism, we end up assigning the same or compatible sign patterns to multiple distinct regions. If two or more regions share an identical activation pattern, the network is not merely affine on each of these regions \emph{in isolation}, but on their entire convex hull. This phenomenon is what we refer to as the \emph{convex hull problem}.

The root cause lies in the minimum operation used in the original POLICE formulation. By taking the minimum across all vertices within a set and requiring non-negativity, the method seeks a single activation pattern that fits all vertices in the set—implicitly constructing one global affine polytope that encompasses them. When applied to multiple target regions simultaneously, this approach either inadvertently links the regions together (if their vertices are combined) or only enforces the constraint on the most recently processed region, if the enforcement is applied sequentially.

To solve this problem, we must assign \emph{distinct} activation patterns to each region. By ensuring that no two regions share the same sign pattern, we prevent them from collapsing into the same affine polytope. This uniqueness ensures that affine constraints remain truly local: each region is ``cordoned off'' in its own polytope, precluding the formation of unintended affine behavior over their combined convex hull. This problem is illustrated with an example in~\cref{fig:convexhull}.

\subsection{Problem Formulation: Multi-Region Sign Assignment and Parameter Adjustments}
\label{subsec:problem_formulation_multi_region}

We now formulate the general problem of assigning unique sign patterns to multiple disjoint convex regions and adjusting the network parameters accordingly. Suppose we have a feedforward ReLU network $f_{\boldsymbol{\theta}}$ of depth $L$ with parameters $\boldsymbol{\theta}$. Let $\{R_i\}_{i=1}^N$ be the set of $N$ disjoint convex regions, each described by its vertices $\boldsymbol{v}_p^{(i)}$. We wish to ensure that each region $R_i$ is contained in a distinct affine polytope of the piecewise affine decomposition induced by the network.

Concretely, we introduce sign variables
\[
    \text{sign}_{n}^{(i,\ell)} \;\in\; \{+1,\,-1\},
\]
where $\ell \in \{1,\dots,L-1\}$ indexes the layer and $n$ indexes the neuron in layer $\ell$. The sign variable $\text{sign}_{n}^{(i,\ell)}$ encodes that region $R_i$ is placed entirely in the half-space defined by
\[
    \text{sign}_{n}^{(i,\ell)} 
    \bigl(
        \mathbf{w}_{n}^{(\ell)\top}\,\mathbf{v}_p^{(i,\ell)} 
        \;+\; 
        b_n^{(\ell)}
    \bigr) 
    \;\ge\; \delta,
    \quad
    \forall\,p \,\in\, \{1,\dots,P_i\},
\]
with $\mathbf{v}_p^{(i,\ell)}$ denoting the vertices after passing through $\ell - 1$ layers and $\delta \ge 0$ a small margin. To force each $R_i$ into a \emph{unique} activation polytope, no two regions may share the same global sign pattern across all neurons and layers.

Formulating these requirements as constraints, we can define the following non-convex optimization problem:
\[
\begin{aligned}
&\min_{\{\mathbf{w}_n^{(\ell)},\,b_n^{(\ell)},\,\text{sign}_{n}^{(i,\ell)}\}}
\quad
\Phi\bigl(\boldsymbol{\theta}\bigr)
\quad
\text{subject to}\\
&\quad \text{sign}_{n}^{(i,\ell)}
    \Bigl(
        \mathbf{w}_{n}^{(\ell)\top}\,\mathbf{v}_p^{(i,\ell)} 
        + b_{n}^{(\ell)}
    \Bigr)
    \;\ge\;
    \delta,
    \;\;
    \forall\,p,i,n,\ell,\\
&\quad \exists\, n,\ell \;\text{such that}\ \;
    \text{sign}_{n}^{(i,\ell)}
    \;\neq\;
    \text{sign}_{n}^{(j,\ell)},
    \;\;
    \forall\,i\neq j.
\end{aligned}
\]
where $\Phi(\boldsymbol{\theta})$ is an objective function reflecting the primary learning task plus regularization terms. The two sets of constraints can be described as \emph{region-consistency constraints} and \emph{uniqueness constraints}, respectively. The former enforces that for each region $R_i$ and each layer $\ell$, the sign pattern is the same, while the latter enforces that no two regions share the same sign pattern. 

% These requirements can be summarized by two sets of constraints:
% \begin{enumerate}
% \item \textbf{Region-Consistency Constraints:} For each region $R_i$ and each layer $\ell$, enforce
% \begin{align*}
%     \text{sign}_{n}^{(i,\ell)}\bigl(\mathbf{w}_{n}^{(\ell)\top}\mathbf{v}_p^{(i,\ell)} + b_{n}^{(\ell)}\bigr) &\ge \delta, \\
%     &\forall\, p \in \{1,\dots,P_i\},\; \forall\, n,\ell.
% \end{align*}

% \item \textbf{Uniqueness Constraints:} For any pair $(i,j)$ with $i \neq j$, there must exist at least one layer $\ell$ and neuron $n$ such that
% \[
%     \text{sign}_{n}^{(i,\ell)} 
%     \;\neq\;
%     \text{sign}_{n}^{(j,\ell)},
% \]
% ensuring that no two regions share the same activation pattern.
% \end{enumerate}
% Satisfying these constraints involves both selecting $\text{sign}_{n}^{(i,\ell)}$ and adjusting $\{\mathbf{w}_n^{(\ell)}, b_n^{(\ell)}\}$ so that they obey the half-space inequalities. In principle, this can be posed as a large-scale non-convex optimization problem:
% \[
% \begin{aligned}
% &\min_{\{\mathbf{w}_n^{(\ell)},\,b_n^{(\ell)},\,\text{sign}_{n}^{(i,\ell)}\}}
% \quad
% \Phi\bigl(\boldsymbol{\theta}\bigr)
% \quad
% \text{subject to}\\
% &\quad \text{sign}_{n}^{(i,\ell)}
%     \Bigl(
%         \mathbf{w}_{n}^{(\ell)\top}\,\mathbf{v}_p^{(i,\ell)} 
%         + b_{n}^{(\ell)}
%     \Bigr)
%     \;\ge\;
%     \delta,
%     \;\;
%     \forall\,p,i,n,\ell,\\
% &\quad \exists\, n,\ell \;\text{such that}\ \;
%     \text{sign}_{n}^{(i,\ell)}
%     \;\neq\;
%     \text{sign}_{n}^{(j,\ell)},
%     \;\;
%     \forall\,i\neq j.
% \end{aligned}
% \]
% where $\Phi(\boldsymbol{\theta})$ is an objective function reflecting the primary learning task plus regularization terms.

Solving this problem, which takes the form of a mixed-integer problem assuming the sign variables are binary, is NP-Hard. Hence, in practice, we can employ heuristics to determine $\text{sign}_{n}^{(i,\ell)}$ first, and then solve simpler sub-problems (e.g., quadratic or linear programs) to enforce the assigned half-space constraints by adjusting $\{\mathbf{w}_n^{(\ell)}, b_n^{(\ell)}\}$ at each layer separately. This strategy offers a balance of efficiency and accuracy in ensuring that each region maintains a distinct and consistent activation pattern.


\subsection{Strategies for Sign Assignment}
\label{subsec:assigning_unique_patterns}
We propose two heuristic methods for determining each region’s signs:

\paragraph{Majority Voting.} 
For each region $R_i$, we examine its vertex pre-activations $\{z_n^{(\ell)}(\mathbf{v}_p^{(i)})\}$ at layer $\ell$. We then set $\text{sign}_n^{(i,\ell)} = +1$ if the most number of $\{z_n^{(\ell)}(\mathbf{v}_p^{(i)})\}$ are positive; otherwise, we choose $-1$. Zeros are treated as positive if they appear. This is a simple, low-cost strategy and often provides reliable region separation, especially when each neuron has a clear tendency to be either positive or negative over $R_i$.
    
\paragraph{Pre-Activation Mean-based.} For each region $R_i$ and neuron $n$ in layer $\ell$, we compute the average of the pre-activations over the vertices of $R_i$. Specifically, let
\[
    m_{n}^{(i,\ell)} \;=\; \frac{1}{P_i} \sum_{p=1}^{P_i} z_n^{(\ell)}\bigl(\mathbf{v}_p^{(i)}\bigr),
\]
where $z_n^{(\ell)}(\boldsymbol{x}) = \mathbf{w}_n^{(\ell)\top}\boldsymbol{x} + b_n^{(\ell)}$. We then set $\text{sign}_{n}^{(i,\ell)} = +1$ if $m_{n}^{(i,\ell)} \ge 0$ and $-1$ otherwise. When $m_{n}^{(i,\ell)}$ is extremely close to zero, we may impose a small margin to avoid sign ambiguity.

Selecting the right approach depends on how pre-activations distribute across vertices. The mean-based method works well when they cluster around distinct positive or negative values, making outliers less influential and providing stability under mild variations. By contrast, majority voting is simpler if nearly all vertices share the same sign. It is robust to small sets of outliers but can become unstable if the region straddles the boundary, where a near-even split may flip the result.

Note that the above selection process is done repeatedly during training.

\paragraph{Ensuring uniqueness.}
Once we assign sign patterns $\{\text{sign}_n^{(i,\ell)}\}$ to each region $R_i$, we must confirm that no two distinct regions share the same pattern across \emph{all} layers. Should $R_i$ and $R_j$ have identical signs for every neuron, $f_{\boldsymbol{\theta}}$ would place them in the exact same affine polytope, creating the \emph{convex hull} problem. To break ties, we identify any pair of identical patterns and forcibly flip signs for a small subset of neurons (often those with pre-activations closest to zero) in at least one layer for one region. This guarantees uniqueness across the entire network depth.

\subsection{Enforcing Signs Patterns}
\label{subsec:enforcing_signs}
Although sign assignment dictates the target polytope for each region, it does not guarantee that the network parameters already respect those assignments. One might attempt a bias-only scheme \cite{police} to assign new sign patterns; however, as demonstrated in Appendix~\ref{app:contradiction_bias_only}, restricting updates to only biases can lead to unsatisfiable constraints when enforcing sign patterns across multiple disjoint regions. Consequently, we must adjust both the weights and biases to ensure that each region $R_i$ remains within its designated polytope throughout the network.

To solve this issue, we can solve a small quadratic (or linear) program to fine-tune both $\mathbf{w}_n^{(\ell)}$ and $b_n^{(\ell)}$ with minimal parameter shifts. Concretely, we collect linear constraints
\[
    \text{sign}_n^{(i,\ell)} \,
    \Bigl(
      \mathbf{w}_n^{(\ell)\top} \mathbf{v}_p^{(i,\ell)} 
      + b_n^{(\ell)}
    \Bigr) \,\ge\, \delta
\]
for all $p$ and $i$, then solve for each layer $l$
\begin{align*}
    &\min_{\Delta \mathbf{w}_n^{(\ell)},\, \Delta b_n^{(\ell)}}
    \;\;
    \|\Delta \mathbf{w}_n^{(\ell)}\|^2 + \|\Delta b_n^{(\ell)}\|^2 \\
    &\text{subject to the above half-space constraints.}
\end{align*}
This yields a minimal-norm update to each layer’s parameters that enforces the assigned signs exactly. Although this might seem computationally expensive, we will show that solving this problem can have minimal cost during training.

\subsection{Imposing Affine Constraints during Training}
\label{subsec:imposingconst}
In \cref{subsec:problem_setup}, we noted that once the network is forced to be affine within $R_i$, it is sufficient to check constraint satisfaction at the finite set of vertices $\{\mathbf{v}_p^{(i)}\}_{p=1}^{P_i}$.

To enforce these during training, we augment the loss function with penalty terms that measure deviations at each constrained vertex. We can introduce a tolerance $\varepsilon$ that defines how strictly each vertex must satisfy the constraints. The penalty terms can have the form of 
\[
\begin{aligned}
\mathcal{L}_{\text{eq},\,\varepsilon} &= \sum_{i,p} \bigl\|\boldsymbol{E}_i \bigl(\boldsymbol{\Lambda}_i \, \mathbf{v}_p^{(i)} + \boldsymbol{\gamma}_i \bigr) - \boldsymbol{f}_i \bigr\|^2 \\
&\quad \text{subject to} \quad \bigl\|\boldsymbol{E}_i f_{\boldsymbol{\theta}}(\mathbf{v}_p^{(i)}) - \boldsymbol{f}_i \bigr\| \le \varepsilon,
\end{aligned}
\]
\[
\mathcal{L}_{\text{ineq},\,\varepsilon}
\;=\;
\sum_{i,p} \Bigl\|\max\bigl(\boldsymbol{C}_i \bigl(\boldsymbol{\Lambda}_i \, \mathbf{v}_p^{(i)} + \boldsymbol{\gamma}_i \bigr) - (\boldsymbol{d}_i + \varepsilon),\; \mathbf{0}\bigr)\Bigr\|^2.
\]
We combine these with the primary loss to form the total objective, which we minimize subject to the sign-consistency constraints from \cref{subsec:from_single_to_multi_regions}. After each enforcement step (which includes the sign assignment step plus solving the convex optimization problem), we refit the network’s parameters so that each region’s assigned activation pattern remains consistent and the resulting affine function at each region’s vertices satisfies the prescribed constraints up to the desired tolerance. This process preserves exact or near-exact constraint satisfaction on every point $\boldsymbol{x}\in R_i$.


\section{Experiments}

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.92\textwidth]{figs/spiral.png}
    \caption{Multi-region constraint enforcement on a spiral classification task, with the loss curve initially spiking at epoch 30 after the first enforcement step but steadily converging over subsequent epochs. The violet square’s convex polytope is highlighted with a green dashed boundary, illustrating how the network enforces affine behavior locally.}
    \label{fig:spiral}
\end{figure*}

\subsection{Classification and Regression}
\label{subsec:classificationandregression}
We empirically evaluate our multi-region enforcement framework on a two-dimensional spiral classification task and a regression task as shown in \cref{fig:convexhull}. Notably, the same process is applied to both tasks, independent of the learning objective, as described earlier using the methods in Section~\ref{subsec:assigning_unique_patterns} with majority voting.

For the classification task shown in~\cref{fig:spiral}, we define two disjoint square regions along the spiral arms where the output must exhibit linear behavior and assign distinct activation patterns to each region. The network consists of a single layer with 32 neurons and a linear output, trained using Binary Cross Entropy (BCE) loss. For the regression task shown in~\cref{fig:convexhull}, the network was trained with Mean Squared Error (MSE) loss on the target field for 3000 epochs, with enforcement applied every 50 epochs, including at the end of training, to ensure guaranteed satisfaction.

For the experiment in~\cref{fig:spiral} we ran 30 unconstrained epochs to let the network learn the overall decision boundary, then apply sign and parameter updates after each epoch. As shown in Figure~\ref{fig:spiral}, the loss curve exhibits an initial spike when constraints are first enforced (at epoch 30), followed by a steady decline over subsequent epochs. Each enforcement step raises the final loss because enforcing linear behavior in the two squares removes network nonlinearity in those regions. A final enforcement step ensures that each square resides in a single affine polytope.

We follow the visualization techniques from \citep{humayun2022splinecam,humayun2022exact} to depict the network’s polytope partitions with white lines. Before enforcement (epoch 30), several partition boundaries pass through both squares, but none cross them afterward, indicating that each square is indeed captured by a single polytope. The inset region highlighted by a green dashed boundary shows how one constrained subdomain maintains strict affine behavior while adjacent areas remain free to model nonlinear transitions.

\subsection{Non-Convex Approximation}
We empirically show that, given that a non-convex shape can be decomposed into multiple convex regions, our method allows approximating a non-convex affine region by placing disjoint convex regions in close proximity. In \cref{fig:non_convex}, the network is trained to learn a saddle background field subject to two affine regions. The left plot shows the two squares are separated by a large gap, so the space between them comprises multiple polytopes (black lines) with no guarantee of affine behavior. In contrast, in the right plot, the squares are placed extremely close to each other (within ten times machine precision), so the region between them effectively becomes the boundary between the two polytopes, enabling a non-convex shape to be approximated by two closely aligned convex shapes. In many practical scenarios, such as discrete reinforcement learning, this gap can be treated as a buffer that the dynamics skip over. This shows the effectiveness of our method in approximating non-convex shapes through carefully placed convex regions.

\begin{figure*}[ht]
\centering
\includegraphics[width=1.0\linewidth]{figs/non-convex.png}
\caption{Two affine regions approximating a saddle background field. On the left, the large gap between squares spans several polytopes, yielding no affine guarantees between them. On the right, placing the squares very close turns the gap into a shared boundary of two polytopes, effectively approximating a non-convex shape with two convex pieces.}
\label{fig:non_convex}
\end{figure*}



\subsection{Constraint Enforcement}


\begin{figure*}[ht]
    \centering
    \includegraphics[width=1.0\linewidth]{figs/performance_plots.png}
    \caption{Enforce time analysis for varying model parameters. 
    (Left) Enforce time as a function of vertices for different widths with fixed depth of 2. 
    (Middle) Enforce time as a function of vertices for different depths with fixed width of 32. 
    (Right) Enforce time as a function of depth for different widths with fixed vertices of 8. 
    The results show a rapid increase in enforce time with depth and width, while vertices contribute to a more linear growth. The combined effect of high depth and width leads to the most significant performance cost.}
    \label{fig:performance_analysis}
\end{figure*}


\begin{figure}[t]
\centering
\includegraphics[width=1.0\linewidth]{figs/constrained_sin.png}
\caption{Neural network approximation of constrained $\sin(x)$ with enforced affine constraints.}
\label{fig:constrained_sin}
\end{figure}
We train a neural network to approximate \(\sin(x)\) with constraints in two disjoint intervals. In  
\[
R_1 = \left[\frac{\pi}{3}, \frac{3\pi}{4}\right],
\]

\( f_{\boldsymbol{\theta}}(x) \) is constrained to \(\sin\left(\frac{\pi}{3}\right)\). In  
\[
R_2 = \left[\pi + \frac{\pi}{3}, \pi + \frac{3\pi}{4}\right],
\]
it must satisfy \( f_{\boldsymbol{\theta}}(x) \leq -0.5 \).
To satisfy these constraints, we assign a unique activation pattern to each region and adjust the network’s weights and biases to enforce the conditions precisely at the region vertices. This strategy guarantees affine behavior within each region while preserving the network’s freedom elsewhere.

To maintain constraint satisfaction during training, we compute a standard data MSE loss and an additional constraint loss $\mathcal{L}_{\text{constraint}}=\mathcal{L}_{\text{ineq}} + \mathcal{L}_{\text{eq}}$ as discussed in~\cref{subsec:imposingconst} that measures violations at region vertices. The total loss is

\[
\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{data}} + \lambda\,\mathcal{L}_{\text{constraint}},
\]

where $\lambda$ is a penalty weight that starts at zero for a number of ``warm-up'' epochs and grows if constraints are not satisfied, which ensures that constraint violations do not dominate the optimization at early stages but are eventually penalized more heavily if they persist. The fine-tuning process continues for a fixed number of epochs and terminates early if the constraint violation drops below a tolerance $\epsilon$.

The results of the example are shown in~\cref{fig:constrained_sin}. We begin with 1000 epochs (over 1024 sample points) as a ``warm-up,'' setting $\lambda=0$ until the network learns the overall trend of the background field. In the subsequent enforcement fine-tuning step, $\mathcal{L}_{\text{constraint}}$ is gradually increased over 200 epochs until the constraint tolerance is met. The training time for each step is provided in~\cref{tab:constraint_time_comparison}. As shown, the second enforcement step accounts for approximately $23\%$ of the total training time. MSE over the background field increases after enforcement (excluding the constraint regions), indicating that enforcing the constraint can reduce the network's expressiveness.

\begin{table}[ht]
    \centering
    \caption{Comparison of steps based on MSE, constraint violation, and runtime.}
    \begin{tabular}{lccc}
        \hline
        Step      & MSE      & Violation  & Time (s) \\
        \hline
        Baseline    & 0.004368 & 0.025971   & 46.87    \\
        Enforcement & 0.007158 & 0.000765   & 14.14    \\
        \hline
    \end{tabular}
    \label{tab:constraint_time_comparison}
\end{table}

\subsection{Computational Efficiency}

We evaluate the scalability and efficiency of our method by analyzing the enforce time under various parameters, including the number of vertices, width, and depth of the network. \cref{fig:performance_analysis} shows how a single enforce step changes with these parameters.

We studied a problem with two circular disjoint regions with the number of vertices ranging from 8 to 64 for a spiral background field, while also varying the width from 8 to 64 and the depth from 2 to 8. As expected, enforcement time increases with all three parameters. The left plot shows a steady rise in enforcement time with the number of vertices, but this effect is more pronounced at larger widths, indicating that width significantly contributes to computational complexity. The middle plot highlights that increasing the number of vertices causes a steady increase in enforcement time, and this effect is amplified when the depth is also increased, suggesting that the depth has an exponential impact on computational cost. The right plot reinforces this observation by showing that, for a fixed number of vertices, increasing the depth causes a rapid rise in enforcement time, especially at larger widths. Note that our method depends on these three parameters and is independent of the input-space data size.

We used the SCS convex solver \cite{ocpb:16} for solving the parameter adjustment problem. Since the solver is not GPU-based, the vertices of each layer must be transferred to the CPU for processing, and the results must be sent back to the GPU for each enforcement step, introducing communication overhead. Comparing enforcement time to overall training time is not straightforward, as it depends on various factors, including these transfer operations, the frequency of enforcement during training, and the size of the training data. In the examples presented in~\cref{subsec:classificationandregression}, enforcement increases total training time by approximately 5–25\%, while our method imposes zero overhead during inference, given that after the training the weights and biases are fully adjusted. We have not prioritized further optimization of enforcement performance.

\section{Conclusion}
\label{sec:conclusion}

We have introduced mPOLICE, a novel method for enforcing affine constraints in deep neural networks over multiple disjoint convex regions. We show that assigning a unique activation pattern to each constrained region prevents the convex hull problem present in the POLICE method. This enables localized constraint enforcement sans unintended affine extrapolation beyond designated regions.

Our methodology combines theoretical guarantees with practical enforcement strategies. We formulated the problem as a constraint optimization problem, leveraging activation sign assignment and constrained parameter adjustments to ensure that each region remains within a distinct ReLU polytope. Our empirical results demonstrate that mPOLICE successfully enforces multi-region constraints in diverse settings, including classification, regression, and imposing affinity on non-convex regions using approximation with disjoint polytopes in proximity. Importantly, our approach maintains minimal training overhead and introduces no additional inference-time cost, making it suitable for real-world deployment in safety-critical applications. 

Future research directions include exploring the application of mPOLICE in reinforcement learning, physical simulations, and Neural Implicit Representation where enforcing constraints across multiple regions will be critical for their practical deployment.


% \clearpage
\newpage

\section*{Impact Statement}

This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here.

\bibliography{main}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\section{Proof}
\begin{theorem}[Consistent Activation Pattern Implies Single ReLU polytope]
    \label{thm:concise_proof}
    Let $f_{\boldsymbol{\theta}}$ be a feedforward ReLU network of depth $L$, and let 
    \[
      R \;=\; \mathrm{conv}\{\boldsymbol{v}_1,\dots,\boldsymbol{v}_P\}
    \]
    be a convex region in the input space. Suppose that for each layer, 
    the sets of pre-activation signs associated to a vertex is the same (either all non-negative or all non-positive). Then $R$ lies in a single activation polytope of $f_{\boldsymbol{\theta}}$.
    \end{theorem}
    
    
    \begin{proof}
    First, consider the base case for layer 1. For a first-layer neuron $z_i^{(1)}(\boldsymbol{x})$, if its value at every vertex of $R$ 
    has the same sign, then by convexity and linearity of $z_i^{(1)}(\cdot)$, it remains that sign 
    for all points $\boldsymbol{x} \in R$, given that a point $x \in R$ can be written as a linear combination of the vertices with coefficients in $[0,1]$ a.k.a.\ a convex combination of the vertices. Hence, each neuron in layer 1 is consistently ``on'' ($\ge0$) 
    or ``off'' ($\le0$) throughout $R$. 
    
    Next, assume as the inductive hypothesis that, for all neurons in layer $\ell$, the pre-activation 
    sign is constant across $R$. Then the output of the ReLU activation at layer $\ell$ is
    \[
    \boldsymbol{x}^{(\ell+1)}=\max(\boldsymbol{z}^{(\ell)},0),
    \]
    which is an affine map that zeroes the coordinates where $z_i^{(\ell)} \le 0$.
    
    For the pre-activations at layer $\ell+1$, we have
    \[
       z_j^{(\ell+1)}(\boldsymbol{x})
       \;=\;
       \boldsymbol{w}_j^{(\ell+1)}\,\boldsymbol{x}^{(\ell+1)}(\boldsymbol{x})
       \;+\;
       b_j^{(\ell+1)}.
    \]
    Since $\boldsymbol{x}^{(\ell+1)}$ is affine on $R$, $z_j^{(\ell+1)}$ is also affine on $R$. If $z_j^{(\ell+1)}$ has a consistent 
    sign at all vertices of $R$, it retains that sign throughout $R$. 
    
    By induction, this consistency holds for all neurons in all layers up to layer $L$, so $R$ lies entirely in one activation polytope. 
    Hence, $f_{\boldsymbol{\theta}}(\boldsymbol{x})$ is affine on $R$.
    \end{proof} 

\section{Example: Contradiction in the Bias-Only Approach}
\label{app:contradiction_bias_only}

Consider a single-layer ReLU network with one neuron
\[
z(x) \;=\; w\,x \;+\; b,\quad \text{output} \;=\; \max(z(x),\,0).
\]
Suppose $w > 0$. We define two disjoint regions on the real line:
\[
R_1 \;=\; [\,0,\,1\,], 
\quad
R_2 \;=\; [\,2,\,3\,].
\]
Assume we wish to enforce a positive sign pattern on $R_1$ (i.e., $z(x) \geq 0$ for all $x \in R_1$) and a negative sign pattern on $R_2$ (i.e., $z(x) \leq 0$ for all $x \in R_2$). A simple bias-only approach attempts to find a single bias $b$ such that
\[
\min_{\,x \in R_1} [\,w\,x + b\,] \;\ge\; 0
\quad\text{and}\quad
\max_{\,x \in R_2} [\,w\,x + b\,] \;\le\; 0.
\]
Since $w > 0$, the first condition implies
\[
w \cdot 0 + b \;\ge\; 0
\quad\Longrightarrow\quad
b \;\ge\; 0.
\]
The second condition implies
\[
\max_{\,x \in [2,3]} [\,w\,x + b\,] 
\;=\;
3\,w \;+\; b 
\;\le\; 0
\quad\Longrightarrow\quad
b 
\;\le\; -\,3\,w.
\]
For any $w > 0$, the requirement $b \geq 0$ and $b \leq -3w$ is clearly unsatisfiable, illustrating how the bias-only scheme fails to reconcile simultaneous sign assignments across multiple disjoint regions.


% You can have as much text here as you want. The main body must be at most $8$ pages long.
% For the final version, one more page can be added.
% If you want, you can use an appendix like this one.  

% The $\mathtt{\backslash onecolumn}$ command above can be kept in place if you prefer a one-column appendix, or can be removed if you prefer a two-column appendix.  Apart from this possible change, the style (font size, spacing, margins, page numbering, etc.) should be kept the same as the main body.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}
