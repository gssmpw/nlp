\section{Related Work}
The integration of constraints into neural networks and training has been explored across various contexts. Early research focused on using neural networks to solve constrained optimization problems through penalty methods for analog circuits~\citep{286888,995659}, and foundational work in applied dynamic programming established theoretical links between neural representations and optimization~\citep{bellman2015applied}. More recently, the paradigm of \emph{Learning to Optimize} has gained traction, blending machine learning and combinatorial optimization to solve complex constrained problems efficiently~\citep{kotary2021end,kotary2024learning}, guiding the optimization process with generative models \cite{giannone2023aligning, picard2024generative}, and solving problems with constraints due to physical laws or domain rules~\citep{PhysRevLett.126.098302,doi:10.1137/21M1397908,XIE2024117223,pmlr-v168-djeumou22a}.

Beyond penalty methods, techniques have emerged to enforce constraints directly through the network architecture. For instance, approaches have been developed to ensure monotonicity, convexity, or linear constraints on the network output~\citep{Li_2018_ECCV,tordesillas2023rayen,konstantinov2024imposing,zhong2023neural}. Physics-informed neural networks (PINNs) have become popular for embedding differential constraints derived from physical systems directly into the training process~\citep{NEURIPS2021_df438e52,NEURIPS2021_d5ade38a}, and other strategies impose affine or inequality-based constraints to guarantee safe and consistent predictions~\citep{kondo2024cgd,bouvier2024policed,bouvier2024learning}. Another method developed specifically for Bayesian optimization uses a transformer-based model to predict the expected improvements for constraints \cite{yu2024fast}, based on the idea that transformers can do Bayesian inference \cite{muller2021transformers}.

The POLICE algorithm~\citep{police} contributed to this landscape by offering a systematic method to enforce affine constraints in a single convex region without increasing inference complexity. However, POLICE did not address the complexities arising when multiple disjoint constrained regions must be handled simultaneously. Our work builds on POLICE and extends it to multiple regions, bridging a critical gap in the literature and providing a new foundation for multi-region constrained DNN training.