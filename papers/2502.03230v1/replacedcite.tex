\section{Related Work}
\label{sec:realted work}
Text-based Person Anomaly Search better addresses real-world requirements by considering both appearance and action descriptions. This approach allows for the precise identification of target pedestrians exhibiting normal or abnormal behaviors among numerous candidates. Here, we review related techniques: Text-based Person Search, Person Anomaly Detection, and Vision Language Pre-training.

\subsection{Text-based Person Search}
Text-based Person Search____ is a research field combining pedestrian re-identification and cross-modal retrieval, with the aim of retrieving pedestrian images using natural language descriptions. The core of TPS involves feature extraction and semantic alignment: discriminative features are extracted through pre-processing and end-to-end frameworks, while semantic alignment is achieved via cross-modal attention mechanisms and generative methods. Although TPS technology has significantly advanced in recent years, it still encounters challenges like modal heterogeneity in practical applications.

\subsection{Person Anomaly Detection}
Anomaly detection is a crucial issue garnering significant attention across numerous research and application domains, particularly in safety. Person anomaly detection, specifically tailored for safety, focuses on identifying and analyzing activities that deviate from normal behavior patterns to enhance safety and responsiveness. Currently, most pedestrian anomaly detection methods predominantly rely on video data rather than images, aiming to identify abnormal behavior events. This research is addressed as a one-class classification problem ____, an unsupervised learning challenge ____, or a supervised/weakly supervised issue ____.

\begin{figure*}[tbh]
  \centering
  \includegraphics[width=0.85\textwidth]{images/Overall.pdf}
  \caption{(a)X-VLM for Text-based Person Anomaly Search. (b)When two similar text descriptions with different answers yield the same result, compare the confidence scores for these answers. Replace the answer with the lower confidence score by using the answer from the group where the confidence score is lower than the current score.}
  \label{fig: Overall}
\end{figure*}

\subsection{Vision Language Pre-training}
Visual Linguistic Pre-training (VLP)____ is a collaborative training model integrating vision and language. It aims to extract rich visual and semantic features from large-scale multimodal data by simultaneously learning visual and linguistic tasks. To enhance image-text association learning and improve multimodal comprehension, single-stream____ and dual-stream architectures____ are designed to process and fuse visual and verbal information differently. Additionally, to better capture semantic relationships between vision and language, researchers have proposed various pre-training objectives, such as masked language modeling____, visual-language matching____, and other task-specific objectives____. Notably, VLP advancement relies on large-scale, high-quality datasets. Consequently, with continuous technological advancements and improved dataset quality, VLP is poised to excel in multimodal understanding, generative tasks, and practical application performance.