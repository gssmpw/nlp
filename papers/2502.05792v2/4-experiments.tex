\section{Experiments}

\subsection{Simulation Settings}
\label{sec:exp_settings}
\textbf{Scenarios.}
We first conduct experiments where the simulated human motions replicate hypothesised human behaviours in long-term repeated interactions, as described below:
% We first evaluate the prediction performance of AToM in three different simulation scenarios. 
% The simulated human motions replicate real-life human behaviours in long-term repeated interactions, as described below.
\begin{enumerate}
    \item \textbf{Scenario 1: 2-agent position exchange.} The robot exchanges positions with the human in a free navigation setting. Across 8 repeated rounds, the simulated human demonstrates an increasing speed while reducing social distance.
    \item \textbf{Scenario 2: 3-agent corridor overtake.} The robot navigates in a narrow corridor with one human in front and another human coming from the opposite direction. Across 8 repeated rounds, we hypothesize that the simulated human in front is pushing a trolley with increasing weights. Therefore they demonstrate a decreasing speed. Their detour is first increased and then decreased. The other simulated human demonstrates an increasing speed while reducing social distance.
    \item \textbf{Scenario 3: 2-agent doorway negotiation.} The robot and the human both need to move through a narrow doorway. Across 15 repeated rounds, the simulated human demonstrates three stages of behaviours, shifting from being ``conservative" to ``cooperative" and to ``aggressive".
\end{enumerate}

% \begin{figure*}[ht]
%     \centering
%     \includegraphics[width=\textwidth]{quantitative_1_2.jpg}
%     \caption{Quantitative comparisons for Scenario 1 and Scenario 2. The simulation setup is illustrated on the left. We compare the prediction accuracy using ADE, and the efficiency and safety in resulting robot plans using Detour and Minimum Distance.}
%     % AToM achieves the best accuracy and results in improving efficiency while maintaining safety.}
%     \vspace{-5mm}
%     \label{fig:quantitative_12}
% \end{figure*}

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{qualitative_2.jpg}
    \vspace{-3mm}
    \caption{Comparison between the predicted and ground truth trajectories in the first, the middle, and the last round of Scenario 2. Predictions are plotted at the second timestep.}
    % Human behaviours vary between different rounds. AToM is able to capture this change and adjust its predictions to reflect dynamic human internal belief.}
    \vspace{-5mm}
    \label{fig:qualitative_2}
\end{figure}


\textbf{Dynamics.}
Our method is dynamics-agnostic. For ease of implementation, both the human and the robot are modelled using a 2D single integrator where $\dot{x} = x + v\Delta t$. The robot speed is capped at $1.0m/s$ in the first two scenarios and $0.6m/s$ in Scenario 3. The simulated human speed ranges from $0.35m/s$ to $1.2m/s$. For the behavioural parameters, we choose $\boldsymbol{\theta} = [v\_max, d]^\top$ for each agent which controls the maximum speed and preferred social radius. We set process and measurement noise with empirical values.

\textbf{Baselines.}
We compare AToM to four human prediction baselines that are commonly used in social robot navigation:
\begin{enumerate}
    \item Constant Velocity (\textbf{CV}) assumes that humans tend to maintain their speed and direction.
    \item Social Force model (\textbf{SF}) \cite{helbing1995social} calculates human moving direction by a weighted combination of goal attraction, obstacle repulsion, and neighbours repulsion.
    \item \textbf{Trajectron++} \cite{salzmann2020trajectron++} is a dynamics-integrated neural network that considers interactions between pedestrians within a neighboorhood.
    \item \textbf{Memonet} \cite{xu2022remember} is a goal-conditioned neural network that predicts human trajectories based on goal positions.
\end{enumerate}
For SF, we tune the force weights for each scenario. For both Trajectron++ and Memonet, we use the pretrained weight provided by the authors. For Memonet, we skip the goal prediction step and feed the true human goal positions to the trajectory generation sub-network.

\textbf{Implementation Details.}
Our method is planner-agnostic. We choose a recent sampling-based Model Predictive Controller Pred2Nav \cite{poddar2023crowd} as the planning module in all experiments. We execute the first planned action and re-plan at every step. 
% For the first two scenarios, the human trajectories are recorded and replayed when testing with different methods. For the third scenario, the simulated human is keyboard-controlled and follows specific rules for each of the three behaviours: 1) conservative human always allows the robot to pass first, 2) cooperative human only allows the robot to pass first if they moves slower than the robot, 3) aggressive human always passes first. The human speed between each repeated round is different, but this speed variation is the same when testing with different methods. 
All experiments are conducted on a Morefine M9 Pro Mini PC.

\textbf{Evaluation Metrics.} For the first two scenarios, 1) Average Displacement Error (\textbf{ADE}) measures the distance between the true and predicted human trajectories, averaged over all steps, 2) \textbf{Detour} measures how far the robot deviates from the shortest path to goal, averaged over all steps, 3) \textbf{Minimum Distance} measures the closest distance between human and robot within a round. 
% We exclude the prediction at initial timestep for all evaluations because CV requires at least 2 observations to predict. 
For Scenario 3, 
% the robot needs to decide whether to pass the doorway before or after the human. Inaccurate predictions could either confuse the robot to wait for the human unnecessarily or lead to collisions. Therefore, 
we use \textbf{Time-to-goal} to measure how long the robot takes to reach the goal. We consider it a collision if the distance between human and robot is smaller than 0.5m.

% \begin{figure}
%     \centering
%     \includegraphics[width=\linewidth]{quantitative_3.jpg}
%     \caption{Quantitative comparison between AToM and SF in Scenario 3. We compare the number of steps the robot takes to reach the goal which reflects the efficiency. We mark the rounds where collisions happens using red crosses.}
%     % AToM enables the robot to pass through the doorway safely and efficiently in all rounds of experiments.}
%     \vspace{-5mm}
%     \label{fig:quantitative_3}
% \end{figure}

% \begin{figure}
%     \centering
%     \includegraphics[width=0.8\linewidth]{qualitative_2.jpg}
%     \caption{Comparison between the predicted and ground truth trajectories in the first, the middle, and the last round of Scenario 2. Predictions are plotted at the second timestep.}
%     % Human behaviours vary between different rounds. AToM is able to capture this change and adjust its predictions to reflect dynamic human internal belief.}
%     \vspace{-5mm}
%     \label{fig:qualitative_2}
% \end{figure}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\textwidth]{failures.jpg}
    \vspace{-5mm}
    \caption{On the left, we compare the predicted trajectories in a sample round from Scenario 2. On the right, we plot three consecutive steps from Scenario 3, where SF prediction misleads the robot into a collision highlighted by the red circle.}
    % \vspace{-2mm}
    \label{fig:failures}
\end{figure*}


\subsection{Quantitative Evaluation}
% The quantitative comparison results are presented in Fig. \ref{fig:quantitative_12} for the first two scenarios, and in Fig. \ref{fig:quantitative_3} for Scenario 3. 
\textbf{Accuracy.}
From Fig. \ref{fig:quantitative_12}-a1 and Fig. \ref{fig:quantitative_12}-b1, we can see that the prediction error of AToM is significantly lower than the baseline methods. 
Memonet shows the worst accuracy in both scenarios as it tends to predict equally spaced waypoints between the current and goal positions which is unrealistic.
CV and Trajectron++ perform similarly and cannot handle situations when the human deviates from a straight path to give way to the robot. CV only shows good accuracy for Human 2 in Scenario 2 whose path is mostly straight. 
SF generates trajectories with unnatural sharp turns when avoiding obstacles and other agents. 
In comparison, AToM models humans that ``look into the future" and can therefore predict smooth and realistic trajectories. 
An important observation is that AToM is the only method that demonstrates decreasing error over the rounds, which shows that our adaptive model becomes more accurate with each update. The decreasing error for human-predicted robot trajectories reflects how humans improve their internal beliefs about the robot over repeated interactions.

\textbf{Efficiency and Safety.}
We now evaluate how human prediction accuracy affects downstream robot planning. We compare efficiency and safety jointly because satisfying one may sacrifice another. 
From Fig. \ref{fig:quantitative_12}-a2-a3 and Fig. \ref{fig:quantitative_12}-b2-b3, the planned robot trajectory using AToM shows decreasing detour which represents increasing efficiency, while maintaining a safe distance from humans. 
Memonet prediction leads to an over-conservative robot, as it models aggressive humans who move straight towards the goal. 
% It fails to maintain a safe distance in later rounds from Scene 2 because the robot falls into a false belief that there is more space on the left side of the corridor, which can be seen later in the qualitative analysis. 
CV and Trajectron++ predictions lead to more efficient robot plans compared to ours, but with a compromise on safety as the minimum distance from human is significantly lower. 
SF shows a similar detour to ours, but its inaccurate prediction leads to untimely avoidance in later rounds when humans are moving fast. 
The effect of inaccurate predictions becomes more noticeable in Scenario 3. We select SF to compare with because obstacle avoidance is critical in this scenario. As shown in Fig. \ref{fig:quantitative_3}, the robot can reach its goal faster with AToM predictions. With inaccurate predictions from SF, the robot tends to wait at the doorway even when the human intends to wait for the robot. 
In 7 out of the 15 rounds when the human is moving with high speed or intends to pass the doorway first, SF model fails to predict the correct human motion and leads to collisions. 
In comparison, our model predicts human behaviours that align with the simulation settings (Sec. \ref{sec:exp_settings}), allowing the robot to wait for the human when necessary to ensure safety.
% In comparison, our model learns that the human is being conservative in the first 5 rounds, gradually allowing the robot to pass without waiting. In the rest of the rounds, our model predicts human intentions accurately, allowing the robot to wait for the human when necessary to ensure safety.

% \begin{figure*}[ht]
%     \centering
%     \includegraphics[width=\textwidth]{failures.jpg}
%     \caption{On the left, we compare the predicted trajectories in a sample round from Scenario 2. On the right, we plot three consecutive steps from Scenario 3, where SF prediction misleads the robot into a collision highlighted by the red circle.}
%     \vspace{-5mm}
%     \label{fig:failures}
% \end{figure*}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{hardware.jpg}
    \vspace{-5mm}
    \caption{On the left, we demonstrate the 2 situations where either the human or the robot passes the doorway first. On the right, we present the time taken for the robot to reach the goal. We highlight 2 participants who show demonstrative behaviours. The rounds where the human gives way to the robot are labelled with thick dots. The faded areas correspond to the 95\% confidence interval from all participants.}
    \vspace{-3mm}
    \label{fig:hardware}
\end{figure}

\subsection{Qualitative Evaluation}
Fig. \ref{fig:qualitative_2} illustrates predicted trajectories from AToM in 3 different rounds. Our method accurately captures the evolving human behaviours over repeated interactions. 
The initial prediction is inaccurate as it does not capture how Human 1 gives way to the robot. As the experiment continues, the human models are correctly updated to reflect socially aware behaviours and evolving speeds. 
% From round 5 to round 8, Human 1 moves with decreasing detour and increasing speed while human 2 moves back to a straight line with decreasing speed, as we described in \ref{sec:exp_settings}. This change is successfully captured by our dynamic model. 
Since the human-predicted robot trajectory is also getting more accurate, we can say that Human 1 chooses to move more efficiently because they develop a more accurate belief of the robot's collision-avoidance behaviour. This interpretability to dynamic human motions is unique to our AToM model.

Unsatisfactory robot plans using baseline predictions are shown in Fig. \ref{fig:failures}. CV and Trajectron++ overestimate the amount of space and cause the robot to move too close to the actual humans. 
On the contrary, Memonet predicts aggressive humans which forces the robot to take a large detour to avoid both humans. 
SF generates unnatural trajectories that are misleading for the robot. 
% models humans that only react without prediction, resulting in trajectories that are not only unnatural and inaccurate but also misleading for the robot. 
As shown in the example from Scenario 3, SF predicts that the human moves straight towards the wall and makes a sharp turn near the wall boundary. With this false prediction, the robot decides to pass first and a collision occurs. 
In comparison, our method correctly infers that the human intends to pass the doorway first, forcing the robot to wait for the human. From the human's perspective, they predict the robot will wait at the doorway, which explains why the human chooses to pass first with confidence.

\subsection{User Study}
As AToM demonstrates promising performance in simulations, we therefore conduct a real user study for the 2-agent doorway negotiation scenario. 
We recruited 10 participants from the campus community with no prior experience interacting with the robot. Each participant is only given the instruction to walk through the doorway and the experiment is repeated for 20 rounds.
We use Agilex Ranger Mini as the robot platform and Vicon motion capture system to obtain the positions and velocities of each agent.
Sample rounds can be found in the supplementary video.

Different from the pre-defined humans in simulations, real humans each show their unique preferences and evolving behaviours. 
In Fig. \ref{fig:hardware}, the two example participants demonstrate completely different behaviours. What is common is that when the participant shows consistent behaviours (Participant 1 always crosses first after round 5, Participant 2 crosses first during rounds 6-11 but decides to give way after round 15), the robot moves with increasing efficiency. Because AToM predictions get more accurate during these rounds, the robot can decide on the correct move with less confusion. In terms of safety, all rounds are completed without collision.