\section{PFL on device training}

\subsection{On device training data}

Training data are generated during inference time through user's explicit feedback.  These data are stored on device. Each training record includes feature values, ground truth labels and metadata. On device data storage system provides a mechanism whereby a particular task can filter out records which satisfy certain matching criteria specified by PFL server. For example, it is possible to match on device OS versions, or target a specific set of data produce by a specific on-device asset through this mechanism.  

\subsection{Federate statistics}

We use Federated Statistics, \cite{CorriganGibbs2017PrioPR}, which is Apple’s end-to-end platform for learning histogram queries from sensitive data on-device, to run histogram queries from on-device data to gain training data insights, such as how much data are available to participate in the PFL training. Before we launch PFL training, as part of the feasibility study, using the FedStats query, we found that ABSOLUTE NUMBER of devices have at least 1 valid sample to participate in PFL training thereby satisfying our data requirements. This shows us that we can complete PFL training iterations with reasonable latency and achieve model convergence. 

\subsection{On device plug-in design}

To enable real devices to process local data and contribute to a Personalized Federated Learning (PFL) task, an on-device plugin was developed. The primary objectives of the plugin are to process local data stored on the device using parameters defined in the PFL task description and attachments, compute a model update or generate training statistics and metrics, and then send these results to a central server for aggregation.
The plugin also includes an on-device differential privacy component. It ensures user privacy and security by applying differential privacy (DP) techniques and encrypting the model updates or training statistics before transmission, protecting sensitive data throughout the process.

The training workflow shown in Figure~\ref{fig 4} involves several key components to ensure on-device data processing and training while maintaining privacy and security:

\begin{enumerate}
    \item \textbf{Inference Framework and On-device Data Store:} The inference framework collects training data and stores it in the On-device Data Store, which is essential for PFL tasks.
    \item \textbf{Data Utilization by FedStats Server:} The FedStats Server utilizes the data stored on the device to aggregate statistics or provide insights into data distribution without directly accessing raw data.
    \item \textbf{PFL Plugin and On-device Orchestration:} The PFL plugin processes local data using task descriptions and parameters provided by the On device orchestration, which communicates with the PFL Server to receive these descriptions and attachments. This runs in a secure and isolated environment as sandboxed process.
    \item \textbf{Differential Privacy and Encryption:} After processing the data and computing model updates or training statistics, these outputs are passed through the Differential Privacy component. It applies DP techniques to anonymize and secure the data, adding noise to protect user privacy. The aggregated and encrypted updates are then sent back to the PFL Server.
    \item \textbf{Model updates at PFL Server:} The PFL Server aggregates updates from multiple devices, contributing to overall model training without compromising individual data privacy.
\end{enumerate}

\begin{figure}
\centering
\includegraphics[width=\textwidth]{figures/live_training_diagram.png}
\caption{PFL on device training workflow}
\label{fig 4}
\end{figure}

\subsection{On device evaluation}

To process local records, the plug-in will use the task sent from the server to devices, as well as model files and any additional files required by the plug-in. For example, in our case, app selection model can be trained on-device and the difference between the model parameter values before and after on-device training represent the result to be aggregated on a server for PFL training. 

We use custom-built tool to configure the necessary parameters for training a model or computing statistics on-device for a particular PFL task. Metrics will be computed at this stage in the plug-in, which will also be sent to a server for aggregation. When training ML models using PFL, metrics include training loss and training/evaluation accuracy. We also compute additional user facing metrics in Section 2.2. Metrics will be sent in the metadata field to the server from devices, along with encrypted results. 

\subsection{PFL training results}

We conducted several training cycles on different sizes of traffic. The results are summarized in Table~\ref{Result},

\begin{table}
\centering
\begin{tabular}{c|cc}
Model&CDER&Disambiguation Rate\\\hline
Baseline&89.18\%&1.99\%\\
PFL trained model&89.86\%&1.99\%\end{tabular}
\caption{\label{Result}Model Evaluation Results}
\end{table}
The PFL trained model showed about 0.6\% of absolute gain in CDER while keeping the same Disambiguation rate over our baseline model. The model’s gain is mainly due to users' change in behavior over time. The old (baseline) model trained on older server side data has drifted away from more recent data. The PFL model was trained on more recent data which captured this distribution change in user behavior.

We have also A/B tested this PFL trained model. Our A/B experiment was conducted for 2 weeks on about 15M devices. The PFL trained model achieved a 0.07\% gain in the top-line metric of system task completion rate and a 15.6\% decrease in the Disambiguation rate. This indicates our PFL trained model improved user experience by correctly predicting users' intended apps.



