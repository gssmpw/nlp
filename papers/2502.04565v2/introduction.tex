
\section{Introduction}

Behavior modeling and app prediction are essential for creating intelligent virtual assistants and personalized user experiences. These techniques\cite{Tongaonkar2013UnderstandingMA}, \cite{Wang2020AHA}, \cite{Yu2017SmartphoneAU} analyze user interactions to forecast behaviors, such as app usage or feature preferences, using machine learning algorithms.
With the rise of mobile usage, accurately predicting user interactions is key to improving engagement and personalizing content. However, this process often requires extensive data collection, raising privacy concerns.
Private Federated Learning PFL \cite{Fu2024DifferentiallyPF} addresses these concerns by enabling decentralized training of machine learning models, keeping data on the user's device while sharing only model updates with privacy guarantees. Wu et al. \cite{Wu2021HierarchicalPF} propose a hierarchical personalized federated learning (HPFL) framework that enhances user modeling by balancing global patterns with local personalization, all while maintaining data privacy.


In this work, we apply the PFL framework to train a predictive model for app selection, ensuring user privacy by keeping data local on individual devices. PFL allows each device to compute model updates based on its own data, which are then aggregated by a central server to refine a global model without ever accessing raw data. This approach not only preserves privacy but also enables better personalization through the HPFL framework, which tailors models to individual users while maintaining the benefits of a collective learning process. Section 2 will present the modeling and PFL details. Followed by offline simulation experiments and on device training set up in Sections 3 and 4. In the end, we will share our learnings and conclusions for using PFL techniques to train industrial applications. 