%%%%%%%%%%%%%%%%%%%%%%%%% intro %%%%%%%%%%%%%%%%%%%%%%%%%
% In software development, the advent of Large Language Models (LLMs) like GPT-4 \cite{gpt4} has disrupted the way developers approach coding and software maintenance. These models have shown remarkable proficiency in generating code snippets and providing coding assistance in limited contexts. Products like Github Copilot have been very successful commercially, with over 1 million paying customers \cite{zdnet}.

% However, LLM's utility is significantly hampered when it comes to dealing with real-world complexities. Addressing a bug often requires traversing through a vast repository, comprehending how functions interact across various files, or identifying a minor mistake within complex code. Thus, the ability to comprehend and manipulate code within the broader scope of an entire codebase remains a challenging frontier for LLMs, specifically due to their limited context window.

% However, even as the context window of LLMs increases to 100K tokens \cite{anthropic100k}, empirically we find that the quality of responses decreases while the risk of hallucination and overall cost increases \cite{lostincontext}. Both research \cite{resesarchlongcontext} and industry \cite{pinecone} sources find that a short, high-quality (retrieved) context performs significantly better than a longer, lower-quality context. Hence, well-tuned Information Retrieval (IR) methods like BM25 with robust reranking pipelines have the potential to help here, narrowing down the search scope immensely to provide better context to LLMs.

% Current code search research primarily targets function or snippet-level queries, neglecting the intricacies of repository-level search. Repository-level search provides a holistic view of the codebase, including the history and rationale behind changes, as reflected in commit messages and code evolution across versions. This perspective transcends source code, considering file interactions over time within the overall software architecture. Repository-level search is crucial for understanding complex code dependencies and dynamics, making it essential for effective software development and maintenance.

% \paragraph{Task Definition} We define the task of repository-level code search as follows: given a user query $q$, find a list of files $F$ which are most likely to address the question or bug raised in $q$. Importantly, along with searching the current state of the repository, we consider the previous commit history of this and potentially other repository (if they encountered similar issues in their existence, somewhere in their commit history, it would exist). Importantly, we want to retrieve a file list, however, the dataset we have is at the commit level, with one file edited per row, and that same file can be edited across multiple commits, either before or after that commit's timestamp. Hence, two important points arise 1. while training on past commit history, we must mask out future versions of the files to prevent leakage and 2. thinking about which version of files to use for reranking (todo - maybe remove - explored more in Sec \ref{sec:bertrr} and \ref{sec:coderr}).

% Repository-level search provides an in-depth perspective of a codebase, highlighting not just the source code but also the inter-file interactions within the software architecture over time. This comprehensive view is vital for grasping the complex dependencies and dynamics of the code. Utilizing the rich data from commits across numerous repositories—where each commit includes a natural language message and a list of modified files—can greatly enhance the search and understanding of repository-level code. In defining the task of repository-level code search, we aim to match a user query $q$ with a list of files $F$ that most likely address the question or bug presented in $q$. This is based on the repository's previous commit history, and the challenge is to effectively utilize commit-level data, where each row corresponds to one file modified per commit, with files possibly edited multiple times across different commits.

% Repository-level search offers a comprehensive view of the codebase, considering not just the source code but also the interactions between files over time within the software architecture. This perspective is crucial for understanding complex code dependencies and dynamics. Notably, there is a wealth of freely available data in the form of commits across thousands of repositories. Each commit provides a natural language commit message as input, along with a list of modified files. Leveraging this commit data could significantly enhance repository-level code search and understanding.

% In this paper, we tackle this task novel approach to repository-level code search that leverages this commit data to provide a more comprehensive and effective search experience. Our method goes beyond current state-of-the-art techniques by considering the full repository context and leveraging the rich information available in commit histories.


% In this work, we adopt a multistage reranking approach for the task of repository-level code search. The current system is designed to pinpoint the most likely files to be fetched in response to user queries or bug reports, such as `The context window breaks every time I click' or `The contributor gallery doesn't display the user's Github handle when active'. In future work, relevant portions from these files can be sent to a capable LLM like GPT4 or CodeLlama \cite{codellama}, to recommend relevant code changes for such issues. We hypothesize this should lead to significantly better generations. Currently, we use both natural language (commit messages) and code (commit diffs) as relevance indicators to filter out relevant files for the given user query. Broadly, we start with a Github repository, index just the commit messages for the quick initial BM25 retrieval, and test various BERT reranking configurations on other relevance indicators to generate a final ranking. Finally, we evaluate our system on modified test queries by transforming past commit messages using an LLM, to mimic real Github issues.

% We start by querying the GitHub API to find the most starred repositories of all time. We then filter the non-code related repositories (such as \mono{EbookFoundation/free-programming-books} having 300K+ stars, but is just a collection of useful links, not a software) using the \mono{language} attribute from API response matching against a list of all major programming languages. Still, we found many non-software repositories remaining, presumably because of having a \mono{language} attribute even with one code file. So, we manually select about 100 most popular GitHub software repositories, such as \mono{react}, \mono{pytorch}, \mono{angular}, \mono{kafka}, etc.

% Next, we scrape the contents of these repositories to extract relevant information mentioned in the objectives. We first tried using Github API, but that quickly became infeasible given the millions of API calls needed. Instead, we clone each repository and use git commands locally to query for the given information (e.g., \mono{git show --name-only <commit-hash>} to get a list of files modified for a given commit, or \mono{git show <commit-hash>:<file-path>} to get a version of the file at a particular commit). We also filter non-code files such as READMEs or config files, by matching against a programming extensions list\footnote{\url{https://github.com/Siddharth-Gandhi/ds/blob/main/misc/code_extensions.json}}.