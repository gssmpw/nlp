(1) Our results may under-represent the potential of LLMs to perform as automatic labelers and content creators as we did not systematically tune our prompts.
%For the labelling task, we stopped our initial ad-hoc prompt development when Llama3 exceeded baseline performance early (results in Table~\ref{t:results-s2} vs.\ Table~\ref{t:results-s1-b}).
%The prompt design for conversation generation also was stopped as soon as LLM output showed plausible output and a high rate of instruction following.
%
(2) While the dataset we selected for this study meets our age group and platform type requirements, the data is not ideal as it is produced by role-playing in a controlled setting rather than a collection of real conversations and as it is translated from Italian to English, potentially showing characteristics that
are unlikely to occur naturally in English conversations.
% \newcite{REF} validate the English translation.
%A further limitation is that we have not performed a human evaluation of the generated data, see future work above.

