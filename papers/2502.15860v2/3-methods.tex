

% \subsection{Notations}  %% commented out as we do not use them

% The notations used throughout this paper are summarized in Table ~\ref{t:notations}.

% \begin{table}
%     \centering
%     \small % Reduce font size for the table (optional)
%     \begin{tabular}{|l|c|}
%         \hline
%         \textbf{Notation} & \textbf{Description}  \\
%         \hline
%         $X_{\text{tr}}$ & Training set inputs (messages) 
%         \\\hline
%         $y_{\text{tr}}^{\text{gold}}$ & Gold labels for $X_{\text{tr}}$\\
%         \hline
%         $y_{\text{tr}}^{\text{llm}}$ & Synthetic labels for $X_{\text{tr}}$ \\ \hline
%          $X_{\text{val}}$ & Validation set inputs \\
%          \hline
%         $y_{\text{val}}^{\text{gold}}$ & Gold labels for $X_{\text{val}}$ \\
%         \hline
%         $y_{\text{val}}^{\text{llm}}$ & Synthetic labels for $X_{\text{val}}$ \\ \hline
%         $X_{\text{test}}$ & Test set inputs \\
%         \hline
%         $y_{\text{test}}^{\text{gold}}$ & Gold labels for $X_{\text{test}}$ \\
%         \hline
%         $y_{\text{test}}^{\text{llm}}$ & Synthetic labels for $X_{\text{test}}$ \\ \hline
%         $(X, y)_{\text{tr}}^{\text{llm}}$ & Synthetic training data \\
%         \hline
%          $(X, y)_{\text{val}}^{\text{llm}}$ & Synthetic validation data \\  
%          \hline
%     \end{tabular}
%     % ACL style has the caption below the table or figure
%     \caption{Summary of notations used in the paper}
%     \label{t:notations} 
% \end{table}


\subsection{Overview of Scenarios}

%In this study, we
We investigate the role of LLMs in CB detection, focusing on their utility under varying data availability conditions
and under the assumption that direct use of LLMs as a classifier is too expensive due to the high volume of messages to be checked.
%To establish
As a baseline for comparison, we %first
evaluate a scenario in which a
lightweight, BERT-based
classifier is trained exclusively on gold-standard, manually labeled authentic data without %any
LLM involvement.
We then define three additional scenarios with different data availability
and that use LLMs in different ways.
%, each illustrating how LLMs can aid in CB detection depending on the availability and quantity of authentic data.
%The scenarios are as follows.

%To establish a baseline for comparison, in the first scenario, we evaluate a setup that relies exclusively on training a classifier using gold-standard, manually labeled authentic data with no LLM involvement. We then define three other distinct scenarios, each corresponding to
% %% JW: The following is unneccesary vague as the scenarios are more specifically
% %% about the way the synthetic data is used, apart from the zero-shot LLM.
% a unique way LLMs can be integrated into the detection pipeline.
% These scenarios range from directly serving as classifiers to generating synthetic data or labels for training. 

\paragraph{Scenario 1: Baseline}

This scenario represents the ideal situation where sufficient
%manually labeled (
gold-standard data is available for fine-tuning %a classic encoder such as
BERT.
It serves as the benchmark for evaluating the effectiveness of other approaches.
In this setup, no synthetic data or LLMs are involved.
%The system relies entirely on human annotations.
This scenario is feasible if resources such as time, budget and expert annotators are abundant. However, it often proves impractical due to the
%high costs and scalability
challenges of manual labeling.



\paragraph{Scenario 2: LLM as Classifier}  \label{s:m:sc2}

This scenario applies when labeled authentic data is unavailable, and there is no intention to train a separate classifier for CB detection. Instead, an instruction-tuned
LLM is used directly as a classifier, leveraging its pre-trained knowledge and its ability to follow instructions
to identify CB instances.
%This approach is particularly useful in contexts that require rapid deployment or when computational or time resources are limited for training a new model. 
The primary advantage of this method is its elimination of the need for labeled data and training time. However, there are trade-offs. While an LLM can handle nuanced language patterns, it may be less efficient and incur higher computational costs
compared to simpler BERT-based classifiers with a classification head and fine-
tuned on a labeled dataset.
%% JW: add reference to large zero-shot study in NLP
We explore two prompting strategies for generating synthetic labels:
\textit{(a)} guideline-enhanced (GE) prompts, guiding the LLM with detailed labeling instructions and
\textit{(b)} guidelne-free (GF) prompts, allowing the LLM to generate labels without such guidelines.

\paragraph{Scenario 3: Fully Synthetic Data}

In this scenario, only a small set of manually labeled gold data is available for testing, with no access to authentic data for training or validation.
%To address this, we
We
use an LLM to generate a fully synthetic dataset, consisting of both synthetic messages and corresponding labels, for training and validation.
This approach is particularly valuable in low-resource domains or emerging tasks where authentic data is scarce or difficult to collect.
It is especially useful in situations where creating authentic datasets is costly, time-consuming, or ethically challenging, such as annotating harmful or sensitive content or working with vulnerable populations.
The effective

%Commented for indusrty track \subsubsection{Scenario 4: Data Augmentation with Synthetic Data}
%This scenario assumes the availability of a moderate amount of gold-labeled data for training and validation, which may be insufficient to achieve optimal performance. To augment the dataset, we use an LLM to generate additional synthetic data, which is then combined with the gold-labeled data during training and validation. The experiment systematically varies the ratio of synthetic-to-gold data to evaluate its impact on model performance. This scenario explores how LLMs can supplement authentic data, striking a balance between scalability and accuracy.


\paragraph{Scenario 4: Synthetic Labels for Unlabeled Data} \label{s:m:sc4}

This scenario addresses the common situation where resources for manual annotation are limited. Here, gold-standard labeled data is available only for the test set, while a significant amount of unlabeled authentic data is available for training and validation.
%This scenario demonstrates the utility of LLMs in resource-constrained settings, enabling cost-effective dataset creation from unannotated corpora.
To utilize the unlabeled data, we label it using the best prompting strategy (GE or GF) from scenario~2.

% \subsubsection{Summary of Scenarios}
% Table~\ref{t:scenario-summary} presents an overview of the data used in the baseline system and each scenario, specifying the datasets utilized for training, validation, and testing. For Scenario 2, where no classifier is trained and the LLM is used directly as a classifier, only the test set is included.
% \begin{table}
%     \centering
%     \small % Reduce font size for the table (optional)
%     \begin{tabularx}{\columnwidth}{|X|X|X|X|}
%         \hline
%         \textbf{Scenario} & \textbf{Train} & \textbf{Validation} & \textbf{Test} \\
%         \hline
%          1 & $X_{\text{tr}}, y_{\text{tr}}^{\text{gold}}$ & $X_{\text{val}}, y_{\text{val}}^{\text{gold}}$ &  $X_{\text{test}}, y_{\text{test}}^{\text{gold}}$ \\
%         \hline
%            2 & - & - & $X_{\text{test}}, y_{\text{test}}^{\text{gold}}$ \\
%         \hline
%           3 & $(X, y)_{\text{tr}}^{\text{llm}}$ & $(X, y)_{\text{val}}^{\text{llm}}$ & $X_{\text{test}}, y_{\text{test}}^{\text{gold}}$ \\
%         \hline
%          4 & $X_{\text{tr}}, y_{\text{tr}}^{\text{llm}}$ & $X_{\text{val}}, y_{\text{val}}^{\text{llm}}$ &  $X_{\text{test}}, y_{\text{test}}^{\text{gold}}$ \\ \hline
       
%         % 4 & $X_{\text{tr}}, y_{\text{tr}}^{\text{llm}} + X_{\text{tr}}, y_{\text{tr}}^{\text{gold}}$ & $X_{\text{val}}, y_{\text{val}}^{\text{llm}}+ X_{\text{val}}, y_{\text{val}}^{\text{gold}}$ & $X_{\text{test}}, y_{\text{test}}^{\text{gold}}$ \\ \hline
%         % 4 & $(X, y)_{\text{tr}}^{\text{llm}} + X_{\text{tr}}, y_{\text{tr}}^{\text{gold}}$ & $(X, y)_{\text{val}}^{\text{llm}}+ X_{\text{val}}, y_{\text{val}}^{\text{gold}}$ & $X_{\text{test}}, y_{\text{test}}^{\text{gold}}$ \\ \hline
%     \end{tabularx}
%     % ACL style has the caption below the table or figure
%     \caption{Overview of data used in each scenario}
% \label{t:scenario-summary} 
% \end{table}





% \subsection{Intrinsic Evaluation Metrics}

% Intrinsic evaluation examines the inherent qualities of datasets, enabling the assessment of linguistic diversity, emotional tone, and conversational structure independently from task-specific performance. For our CB detection task, we utilize \textbf{four} categories of intrinsic metrics to compare the authentic dataset with LLM-generated synthetic data. These categories are: 1) lexical and linguistic characteristics, %including metrics such as Mean Words per Message, Mean Word Length, and Type-Token Ratio; 
% 2) content and CB indicators, 
% %such as rate of Harmful Messages, Bully Messages, Victim Messages, and Toxicity; 
% 3) sentiment and emotional tone, 
% %which classifies messages into negative, positive, or neutral; 
% and 4) dialogue act distribution.
% %categorizing messages into types such as Question, Statement, Greeting, Accept/Reject, and Other. 
% These categories are critical for understanding the fundamental differences between authentic and synthetic data in the context of CB detection, as they provide insight into how well the synthetic data replicates the linguistic, emotional, and conversational behaviors that are typically present in real-world online interactions.

% To ensure a fair comparison between the authentic and synthetic datasets, we first normalize both dataset by employing pre-processing techniques such as tokenization using NLTK \cite{loper-bird-2002-nltk} and punctuation handling. Additionally, data is segmented into equal-sized token slices to account for metrics that are influenced by corpus size.

% Sentiment scores are measured using VADER \cite{hutto2014vader}, a sentiment analysis tool optimized for short social media texts. Dialogue acts are classified using a Naive Bayes model trained on the NLTK \texttt{nps-chat} corpus,
% following \newcite[Chp.~6, Sec.~2.2]{bird2009natural}.\footnote{
%     While no citation is provided by \newcite{bird2009natural}, the source
%     of this corpus seems to be
%     \newcite{forsyth-martell-2007-lexical,forsyth-etal-2010-nps}.
% }
%



% Natural Language Processing with Python, by Steven Bird, Ewan Klein and Edward Loper
% Chapter 6, section 2.2 "Identifying Dialogue Act Types"
% refers to Chapter 2, section 1.2 "Web and Chat Text", for the
% NPS Chat Corpus but provides no source or citation.
%  
% An unrelated 2011 paper cites an "NPS Chat Corpus of North American English chat
% conversations (Forsyth and Martell 2007)".
%   * Forsyth, Eric. M. and Craig H. Martell (2007), Lexical and discourse analysis
%     of online chat dialog, Proceedings of the First IEEE International Conference
%     on Semantic Computing (ICSC) 2007, pp. 19â€“26.
%   * data collected in 2006
%   * approximately 500,000 chat posts gathered from various online services
%   * 10,567 posts tagged in Release 1.0
%   * available on http://faculty.nps.edu/cmartell/NPSChat.htm (page no longer
%     exists but is archived, e.g. on
%     http://web.archive.org/web/20190510121556/http://faculty.nps.edu/cmartell/NPSChat.htm
%        - "If you want just the data, you can get it through the Linguistic Data
%          Consortium.  It is catalog number LDC2010T05."
%        - This page asked for the 2007 paper above to be cited "when referring to
%          the NPS Chat Corpus".
%
% There is a 2010 thesis from Naval Postgraduate School, Monterey, California, by
% J. R. Hitt entitled "Implementation and Performance exploration of a cross-genre
% part of speech tagging methodology to determine dialog act tags in the chat
% domain".
%   * credits Lin and Forsyth
%


% Type-Token Ratio (TTR), which is calculated by dividing the number of unique words by the total tokens in fixed-size slices, serves as a normalized measure of vocabulary diversity. Toxicity scores, which represent the ratio of messages containing profanity, are derived using a publicly available profanity list \cite{surge2023profanity}.


\subsection{Evaluation Metrics}

We choose accuracy of label prediction for development decisions and reporting since the labels are reasonably balanced in the authentic test data with 30.3\% items labeled with the minority
label.\footnote{In the appendix, we further report macro average F1 scores that are also widely used in the area of harmful content detection.}
In scenarios 1, 3 and 4,
we train BERT\_base\_uncased \cite{devlin-etal-2019-bert}, a 110M parameter transformer model, with a linear classification head
% using
% the HuggingFace transformers library \cite{wolf-etal-2020-huggingface}
to detect harm, assigning binary labels to text messages.
To address noise from randomness in training, we train at least 45 models for each setting and report average accuracy and standard deviation.