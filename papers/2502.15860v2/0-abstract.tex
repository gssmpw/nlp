Cyberbullying (CB) presents a pressing threat, especially to children, underscoring the urgent need for robust detection systems to ensure online safety. However, progress in developing such systems is hindered by the scarcity of large, labeled datasets that are specifically tailored for specialized tasks and the target age groups.
Creating these datasets relies heavily on human annotation, which not only strains resources but also raises significant ethical and legal concerns due to annotatorsâ€™ exposure to harmful content, not withstanding the acquisition of this type of data from vulnerable populations such as children. In this paper, we address these challenges by leveraging Large Language Models (LLMs) to generate synthetic data and labels.
Our experiments demonstrate that synthetic data enables BERT-based CB classifiers to achieve performance close to that of those trained on fully authentic datasets (75.8\% vs. 81.5\% accuracy). Additionally, LLMs can effectively label authentic yet unlabeled data, allowing BERT classifiers to attain a comparable performance level (79.1\% vs. 81.5\% accuracy). These results highlight the potential of LLMs as a scalable, ethical, and cost-effective solution for generating data for CB detection.

%\textbf{\textcolor{red} {Content Warning: This article contains examples of offensive language.}} %, all examples are taken from existing datasets to illustrate their composition.}}