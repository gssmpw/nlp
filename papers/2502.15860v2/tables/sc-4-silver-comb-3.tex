
\begin{table}
\centering
\begin{tabular}{lrcc}
\textbf{Labels} & \textbf{Size}  & \textbf{Dev.} & \textbf{Test}  \\
\hline
LA  &   20\%  &   74.8\% $\pm$    1.9  &   73.7\% $\pm$    1.7  \\
LA  &   50\%  &   79.3\% $\pm$    1.5  &   78.0\% $\pm$    1.3  \\
LA  &   80\%  &   80.1\% $\pm$    0.9  &   78.8\% $\pm$    1.0  \\
LA  &   100\%  &   \textbf{80.4\%} $\pm$    1.0  &   \textbf{79.1\%} $\pm$    1.0  \\
\hline
GPT  &   20\%  &   72.0\% $\pm$    1.7  &   72.6\% $\pm$    1.6  \\
GPT  &   50\%  &   75.1\% $\pm$    1.7  &   76.4\% $\pm$    1.3  \\
GPT  &   80\%  &   76.2\% $\pm$    1.1  &   77.2\% $\pm$    0.9  \\
GPT  &   100\%  &   77.1\% $\pm$    0.9  &   77.9\% $\pm$    0.9  \\
\hline
Grok  &   20\%  &   71.3\% $\pm$    2.6  &   70.4\% $\pm$    3.0  \\
Grok  &   50\%  &   75.0\% $\pm$    1.6  &   74.2\% $\pm$    2.0  \\
Grok  &   80\%  &   76.1\% $\pm$    1.1  &   74.4\% $\pm$    1.6  \\
Grok  &   100\%  &   76.3\% $\pm$    1.2  &   75.2\% $\pm$    1.7  \\
\hline
\end{tabular}
\caption{Development and test set accuracy in scenario~4: training BERT-based classifiers on the training split of the
authentic data with synthetic labels predicted by
(a) LA = Llama 3.3, removing dataset items for which no label is found in the LLM output,
(b) GPT = GPT-4o and
(c) Grok;
at least
85 repetitions with different random seeds;
also shown for comparison results for training on samples
of 20\%, 80\% and 50\%
(sampling without replacement;
both the training set and the development set are sampled
to the given relative size of the authentic data split)
}
\label{t:results-s4-c}
\end{table}
