In this paper, we explored the potential of LLM-generated synthetic data for cyberbullying detection, evaluating its effectiveness in three scenarios. %, including direct classification and data augmentation for training.
Our results highlight that synthetic data can significantly reduce the reliance on human annotators while maintaining competitive model performance, especially in low-resource settings. However, we also observed that the quality and utility of synthetic data depend heavily on prompt design and data selection strategies.

For future work, we want to expand the set of data availability scenarios to include data augmentation, where authentic and synthetic data are combined.
Furthermore, we plan to work with social scientists working in online safety %who are part of the project team given the expertise needed
to plan a human evaluation of the synthetic data.
%
We also plan to investigate how temperature settings during label and conversation generation affect data diversity and model performance.%, including whether mixing outputs from different temperature settings
%in an ensemble
%yields improvements.

Future work may also want to more systematically tune the prompts than we did.
Our results may under-represent the full potential of LLMs to perform as automatic labelers and content creators.

Additionally, we want to try removing messages that are labeled with a low confidence score from the training data, similarly to, e.g., self-training \cite{yarowsky-1995-unsupervised}. %,blum-mitchell-1998-combining}.
Finally, we intend to explore % methods for
selecting subsets of synthetic data based on their similarity to authentic data
for better alignment with real-world patterns.

