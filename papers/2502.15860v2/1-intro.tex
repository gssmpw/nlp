The rapid proliferation of social media platforms has raised concerns over the prevalence of cyberbullying (CB), particularly among vulnerable populations like children. %\cite{}. 
Detecting and mitigating CB is crucial to maintaining a safe digital environment and minimizing its psychological impact \cite{arif-etal-2024-impact}. However, creating high-quality labeled datasets for training CB detection models remains a significant challenge. Traditional data collection methods, which are based on human annotators, are costly, time-consuming, and pose ethical and legal concerns. Annotators may experience emotional distress or harm when exposed to harmful content, raising questions about their well-being \cite{alemadi-Zaghouani-2024-emotional}. This highlights the need for alternative approaches to generate labeled datasets without requiring human annotators to engage directly with harmful content. One promising solution is to use large language models (LLMs) for the annotation of data, instructing an instruct-tuned model to perform the task.

Since detecting CB is particularly important in protecting children online, our industry partner aims to integrate built-in child-protection software into children's smartphones to ensure safer internet use. By analyzing incoming and outgoing data on a child's device, the software filters offensive content, including CB, and alerts parents if any imminent danger is detected. As part of this initiative, we investigate the use of LLMs to create datasets for CB detection.
However, collecting CB content produced by children is difficult. Age information on public social media sites is unreliable and a large part of CB happens in closed groups. Furthermore, obtaining consent involves the parents, who may not be interested in (or may not have time to consider) taking part in a research study.
A solution may be to use LLMs to generate conversations between children.

LLMs have shown remarkable capabilities to generate human-like text and perform various NLP tasks, including text classification and sentiment analysis \cite{brown-etal-2020-language}. These models can generate synthetic data that mimic authentic content and, as automatic annotators, alleviate both the financial and ethical burdens associated with manual annotation. Recent studies have demonstrated the utility of LLM-generated data in NLP tasks where authentic datasets are scarce or difficult to acquire \cite{li-etal-2023-synthetic, he-etal-2022-generate, ghanadian-etal-2024-socially, yoo-etal-2021-gpt3mix}.

In this paper, we explore the potential of LLM-generated datasets for CB detection. We investigate several scenarios for integrating LLMs into the CB detection task. Through these experiments, we aim to determine the extent to which synthetic data can improve CB detection performance, considering different levels of availability of manually labeled authentic data. All synthetic datasets, along with the synthetic labels generated for the authentic dataset, will be made available upon request for research purposes.