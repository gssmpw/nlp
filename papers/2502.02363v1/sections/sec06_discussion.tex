We proposed FAB-PPI as a Bayes-informed method to significantly improve the performance of PPI in the presence of high quality predictions. In doing so, we showed that the horseshoe represents a sensible default prior for FAB-PPI, contrary to the seemingly natural choice of a Gaussian prior. However, several options may be worth exploring.

In particular, the horseshoe prior was chosen due to its popularity and key properties: (i) its spike at zero (ii) power-law tails and  (iii) the closed-form expression for the marginal density $\pi(y)$. However, many other scale-mixture of Gaussians models share these properties.
For example, the family of priors with a beta prime (aka inverted beta) prior over the variance~\citep{Polson2012}, which includes the horseshoe, normal-exponential-gamma~\citep{Griffin2011} and other robust priors \citep{Berger1980,Strawderman1971} as special cases, share the same three properties.
On the other hand, some other standard priors such as the Laplace prior~\citep{Park2008} or normal-gamma prior~\citep{Caron2008,Griffin2010} do not have power-law tails and therefore do not offer the same robustness guarantees. Other priors, such as the student-t, lack an analytical expression for $\pi(y)$, therefore requiring additional numerical approximation to be applied to FAB-PPI.

Furthermore, we used the scale $\sigma$ of the noise in the generative model as the scale for both the horseshoe and Gaussian priors, as this allows us to obtain a simple, parameter-free approach, which generally performs well.
Alternatively, one could consider a prior scale of $\eta\sigma$, where $\eta$ is a hyperparameter to be tuned using a validation set.
However, in the case of the horseshoe, this renders the marginal likelihood intractable. While using a rescaled horseshoe prior for FAB-PPI remains feasible through numerical integration, as shown in \cref{fig:real_forest_scaled_supplementary}, this increases the computational cost of the method.
By contrast, a rescaled Gaussian prior would not encounter this issue.
Furthermore, we conjecture that choosing a scale that does not depend on $\sigma$ may resolve the inconsistency of the estimator based on a Gaussian prior, which was discussed in \cref{sec:fabppi_mean_estimation}. \looseness=-1

As a potential drawback, FAB-PPI shares the computational limitations of the PPI approach \citep{Angelopoulos2023}, which are discussed in \citet{Angelopoulos2023a}. In particular, except for particular cases such as mean estimation and linear regression, the method requires evaluating $\widehat m_\theta + \widehat\Delta_\theta$ over a grid of values of $\theta$. This can be computationally expensive, especially in high-dimensional settings.
