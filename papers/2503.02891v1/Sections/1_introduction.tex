\section{Introduction}
Deep learning architectures have evolved significantly in recent years, with transformers emerging as one of the most transformative breakthroughs. Transformers initially introduced for natural language processing (NLP) by Vaswani et al.~\cite{vaswani2017attention} in 2017 replaced recurrent models such as long short-term memory (LSTMs)~\cite{hochreiter1997long} and gated recurrent~\cite{chung2014empirical}, leveraging self-attention mechanisms to capture long-range dependencies in sequential data efficiently.

Following the tremendous success of transformers in NLP, researchers adapted their architecture for computer vision (CV), leading to the development of vision transformers (ViTs)~\cite{dosovitskiy2020image}. Unlike convolutional neural networks (CNNs)~\cite{krizhevsky2012imagenet}, which rely on hierarchical feature extraction, ViTs model visual data by processing images as sequences of patch embeddings, enabling global context modeling via self-attention. 
Since the introduction of ViTs~\cite{dosovitskiy2020image}, research interest in ViT-based models has grown exponentially, as reflected in the increasing number of publications each year~(Figure~\ref{fig:current_trends}a). This surge in publications highlights ViTs' dominance in CV tasks, driven by their state-of-the-art (SOTA) performance across various tasks, including image classification~\cite{dosovitskiy2020image,liu2021swin}, object detection~\cite{carion2020end,zhang2021vit}, and segmentation~\cite{hatamizadeh2022unetr,li2023lvit}.

While ViT-based models have demonstrated significant capabilities, the substantial size of these models presents major challenges for practical deployment. For instance, ViT-Huge includes over 632M parameters~\cite{dosovitskiy2020image} and recently extended to 22B parameters~\cite{dehghani2023scaling},  demanding extensive computational resources. These memory and processing requirements make direct deployment on resource-constrained edge devices impractical without optimization. To overcome these limitations, researchers have explored various model compression techniques to reduce computational overhead while preserving performance. As ViTs continue to gain prominence in CV tasks (Figure~\ref{fig:current_trends}a), there has been a parallel increase in research focused on optimizing their efficiency through compression techniques (Figure~\ref{fig:current_trends}b). Techniques such as pruning~\cite{liang2021pruning,bai2022dynamically}, quantization~\cite{lin2021fq,li2023repq}, and knowledge distillation (KD)~\cite{gou2021knowledge,lin2022knowledge} on ViT have gained traction, offering solutions to reduce model size, improve inference speed, and lower power consumption without significantly compromising accuracy.
\begin{figure}[]
  \centering
  \includegraphics[scale=0.28]{assets/current_trends.png}
  \caption{(a) The prevalence of transformer-based models in computer vision has led to a substantial increase in research publications. (b) Given their high computational complexity, model compression techniques are critical for reducing redundancy and improving efficiency. These advancements are essential for optimizing ViTs for hardware acceleration and real-world deployment on resource-constrained platforms~\cite{dimensions_data}.}
  \label{fig:current_trends}
\end{figure}
However, compression techniques alone are often insufficient to meet real-time applications' stringent latency and throughput requirements on edge devices. To achieve uninterrupted inference in resource-constrained edge devices, acceleration techniques optimize ViT execution by leveraging hardware-aware optimizations, efficient non-linear operations, and efficient resource allocations. These approaches address the inherent on-device computational bottlenecks of ViTs, such as the quadratic complexity of self-attention and the inefficiencies in processing patch embeddings. Recent advancements in accelerating techniques, including the use of specialized or custom accelerators (e.g., graphics processing units (GPUs), tensor processing units (TPUs), and field-programmable gate arrays (FPGAs)) and optimized libraries (e.g., TensorRT), have further expanded the possibilities for accelerating ViTs on edge devices. By bridging the gap between model-level optimizations and hardware-specific execution, software-hardware (SW-HW) co-design also plays a pivotal role in deploying ViTs on devices~\cite{fan2022m3vit,dong2023heatvit,wang2022via}. Compression techniques, optimized software tools, and hardware-aware acceleration strategies~\cite{nag2023vita, wang2022via,you2023vitcod} provide a pathway toward efficient, low-latency ViT inference, unlocking new possibilities for autonomous systems, mobile vision applications, and real-time processing on edge devices.

This survey provides a comprehensive review of both model compression and acceleration strategies tailored for ViT, with a particular focus on their applicability to edge devices such as GPUs, central processing units (CPUs), FPGAs, and application-specific integrated circuits (ASICs). We systematically categorize and analyze the latest advancements in pruning, quantization, knowledge distillation, and hardware-aware optimizations. Furthermore, we explore emerging acceleration techniques, which aim to reduce latency and improve energy efficiency. By synthesizing insights from a broad range of studies, this survey serves as a valuable resource for researchers and practitioners seeking to deploy ViTs on edge devices.
\subsection{Motivations and Contribution}
ViTs have revolutionized CV tasks, achieving SOTA performance across tasks such as image classification, object detection, and segmentation. However, their high computational cost, memory footprint, and energy consumption present significant challenges for deployment on resource-constrained edge devices. While various optimization techniques exist for ViTs, a comprehensive review that unifies ViT-focused model compression, software tools, evaluation metrics, and hardware acceleration strategies for edge deployment remains underexplored. Existing surveys typically address these aspects in isolation, lacking a holistic analysis that connects them. Table~\ref{tab:current_survey} compares existing surveys on ViT model compression and acceleration techniques.
\input{Tables/table_current_surveys}

This survey addresses this gap by systematically analyzing model compression techniques (pruning, quantization, knowledge distillation) and hardware-aware acceleration strategies (efficient attention mechanisms, SW-HW co-design, FPGA optimizations, etc.). By analyzing insights from a broad range of studies, this survey serves as a valuable resource for researchers and practitioners seeking to deploy ViTs on edge devices. The main contributions of our survey are as follows:
\begin{enumerate}
    \item We systematically categorize and analyze pruning, quantization, and KD to optimize ViTs in resource-constrained environments while maintaining accuracy.
    \item We investigate current tools for efficient inference and hardware-aware accelerating techniques to enhance ViTs inference efficiency across edge platforms like GPUs, FPGAs, and TPUs.
    \item By Providing a structured roadmap for integrating compression and acceleration techniques, we offer comparative analyses and identify challenges and future research directions for real-time, low-power ViT applications.
\end{enumerate}
\subsection{Literature Collection and Organizations}
Our literature search was conducted across major academic databases, including \textbf{Google Scholar, IEEE Xplore, arXiv, and the ACM Digital Library}, to ensure comprehensive coverage of relevant research. We utilized targeted search queries with keywords such as \textbf{vision transformer, acceleration techniques, edge devices, software-hardware co-design, pruning, quantization, and knowledge distillation} to identify studies relevant to this survey. A total of 170 papers were collected, with works published up to January 2025 considered for inclusion. Figure~\ref{fig:key_concepts} illustrates the key concepts discussed in this survey. However, the final selection of papers was determined based on their relevance to key research questions. A paper was included in this survey if it addressed the following criteria:
\begin{enumerate}
    \item Does the paper propose a compression technique for improving ViT efficiency in terms of computational cost or energy consumption?
    \item Does the paper provide a comparative analysis of ViT acceleration techniques or benchmark performance across different hardware platforms?
    \item Does the paper explore the integration of ViTs with hardware-aware optimizations, including software-hardware co-design strategies?
\end{enumerate}
The remainder of the survey is organized as follows. Section~\ref{model_com} presents an in-depth discussion on model compression techniques, including pruning, quantization, and knowledge distillation, which enhance ViT efficiency while preserving performance across various computer vision tasks. Following this, Section~\ref{tools_for_edge} explores an overview of current software tools, optimization frameworks, and evaluation metrics designed for efficient edge inference across different edge devices. Section~\ref{acce_tech} delves further into hardware-aware accelerating techniques, focusing on optimizations for non-linear operations (e.g., softmax, GELU, and LayerNorm) and current SOTA SW-HW co-design techniques and provides a comprehensive performance comparison of the SOTA techniques. Furthermore, Section~\ref{cha_fu} discusses key challenges and future research directions, identifying multiple avenues for advancing ViT acceleration and deployment on edge devices. Finally, we conclude this
paper in Section~\ref{conclusion}.
\begin{figure}[]
  \centering
  \includegraphics[scale=0.28]{assets/key_concepts.png}
  \caption{Key concepts discussed in this survey.}
  \label{fig:key_concepts}
\end{figure}