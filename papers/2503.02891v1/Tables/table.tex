% \begin{table}[ht]
% \centering
% \caption{Pros, cons, and use-cases for different quantization methods in ViT models}
% \label{table:quan_classification}
% \begin{adjustbox}{width=1\textwidth}
% \begin{tabular}{c|c|c|c|c|c|c}
% \hline
%  \textbf{\makecell{\\Aspects of\\ quantization}} &\textbf{Techniques} & \textbf{Description} & \textbf{Pros} & \textbf{Cons} & \textbf{Target Devices} & \textbf{Vision tasks} \\
% \hline
% \multirow{2}{*}{\textbf{\makecell{\\Fine-tuning\\ methods}}} &\makecell{\\Post-training\\quantization(PTQ)\\ ~\cite{habi2021hptq,kluska2020post}} & \makecell{\\Adjust the weights\\without finetuning } & \makecell{\\Possible with \\limited data \& Low\\ computational intensive} & \makecell{\\Accuracy drop \& \\Limited adaptation} & \makecell{\\Mobile phone\\ FPGA\\NVIDIA Jetson Nano} & \makecell{\\Object detection\\Image classification} \\
% \cline{2-7}
%  &\makecell{\\Quantization-aware\\training(QAT)\\ ~\cite{kim2020frostnet,zhang2023qd,cormier2021towards}} & \makecell{\\Incorporates the quantization\\ process into the forward \\and backward propagation\\ steps of the training algorithm} & \makecell{\\Better accuracy\\ than PTQ} & \makecell{\\Complex \& High \\computational intensive} & \makecell{\\GPU\\ FPGA\\ASICs} & \makecell{\\Semantic segmentation\\Object detection\\Anomaly Detection} \\
% \hline

% \multirow{2}{*}{\textbf{\makecell{\\Calibration\\ methods}}} &\makecell{\\Static\\quantization~\cite{fan2019static,liu2021improving}} & \makecell{\\Apply quantization\\into weights \& \\activation to low precision\\before deployment} & \makecell{\\Computationally \\efficient} & \makecell{\\Accuracy\\drop} & \makecell{\\Mobile phone\\ FPGA} & \makecell{\\Object detection\\Image classification} \\
% \cline{2-7}
% &\makecell{\\Dynamic\\quantization~\cite{liu2022instance,huang2023structured}} & \makecell{\\Quantized the weights\\ statically but activations are\\ quantized dynamically at\\ runtime based on data \\being processed} & \makecell{\\High accuracy} & \makecell{\\Slow \& Require more \\resources at runtime} & \makecell{\\FPGA\\Autonomous vehicles} & \makecell{\\Image segmentation\\Object detection} \\
% \hline
% \multirow{2}{*}{\textbf{\makecell{\\Quantization\\scheme}}} &\makecell{\\Uniform~\cite{fangxin2020ausn,fang2020post}} & \makecell{\\ Fixed step size \\between \\quantization levels} & \makecell{\\Simple \& Fast} & \makecell{\\Not adaptive to \\data distribution} & \makecell{\\Digital camera\\ Voice recorder} & \makecell{\\Binary image creation} \\
% \cline{2-7}
% &\makecell{\\Non-uniform~\cite{oh2022non,jeon2022mr}} & \makecell{\\Adaptive step size\\ based on \\data distribution} & \makecell{\\High accuracy\\ \& Efficient bandwidth} & \makecell{\\More complexity \\Specific to data distribution} & \makecell{\\MRI scanner\\Robots} & \makecell{\\Image compression} \\

% \hline
% \multirow{2}{*}{\textbf{Granularity}} & \makecell{\\Layer-wise~\cite{li2019fully,chu2019mixed,tzelepis2019deep}} & \makecell{\\All weights \& activations\\ within a layer \\are quantized using\\ same scale} & \makecell{\\Simple \& sub-optimal\\ accuracy} & \makecell{\\Less flexible \\Accuracy drop} & \makecell{\\Raspberry pi\\ Google coral edge TPU\\}&\makecell{\\Image classification\\Object detection} \\
% \cline{2-7}
% & \makecell{\\Channel-wise~\cite{zhang2022mffnet,li2019fully,xie2023joint}} & \makecell{\\Each channels quantized\\with same scaling factors} & \makecell{\\Flexible \& High\\accuracy} &\makecell{\\ Complex \& High\\ computational overhead} & \makecell{\\Nvidia Jetson series} & \makecell{\\Facial Recognition; \\Image segmentation\\Object detection\\} \\
% \hline

% \multirow{2}{*}{\textbf{Others}} & \makecell{\\Mixed-Precision~\cite{chu2019mixed,chu2021mixed,xu2023q}} & \makecell{\\Quantized with different\\
% bit precision for\\ each layer} & \makecell{\\Performance Optimization\\ for low-precision quantization} & \makecell{\\Complex \& need\\extended search processes} & \makecell{\\GPU\\ FPGA\\ASICs}&\makecell{\\Image classification\\Object detection\\Medical imaging} \\
% \cline{2-7}
% & \makecell{\\Hardware-aware~\cite{wang2019haq,dong2021hao}} & \makecell{\\Quantization parameters\\according to the\\ hardware resources } & \makecell{\\hardware specific\\optimization} &\makecell{\\ Less flexible \& complex\\ } & \makecell{\\GPU\\TPU\\FPGA} & \makecell{\\Facial Recognition; \\Facial Recognition\\Augmented reality(AR)\\} \\
% \hline
% \end{tabular}
% \end{adjustbox}
% \end{table}

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \renewcommand{\arraystretch}{0.4}
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \begin{table}[]
% \small
% \caption{Pros and cons for different quantization methods in ViT models.}
% \label{table:quan_classification}
% \begin{tabular}{c|c|c|c|c}
% \hline
% \textbf{\begin{tabular}[c]{@{}c@{}}Aspects of \\ quantization\end{tabular}} &
%   \textbf{Techniques} &
%   \textbf{Description} &
%   \textbf{Pros} &
%   \textbf{Cons} \\ \hline
% \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Fine-tuning\\ methods\end{tabular}} &
%   \begin{tabular}[c]{@{}c@{}}Post-training \\ quantization\\ (PTQ)\end{tabular} &
%   \begin{tabular}[c]{@{}c@{}}Adjust the weights \\ without fine-tuning\end{tabular} &
%   \begin{tabular}[c]{@{}c@{}}Possible with \\ limited data \\ \& \\ low computational \\ intensive\end{tabular} &
%   \begin{tabular}[c]{@{}c@{}}Accuracy drop \& \\ limited adaptation\end{tabular} \\ \cline{2-5} 
%  &
%   \begin{tabular}[c]{@{}c@{}}Quantization-\\ aware training\\ (QAT)\end{tabular} &
%   \begin{tabular}[c]{@{}c@{}}Incorporates the \\ quantization process \\ into the forward \&\\ backward propagation \\ steps of the \\ training algorithm\end{tabular} &
%   \begin{tabular}[c]{@{}c@{}}Better accuracy\\ than PTQ\end{tabular} &
%   \begin{tabular}[c]{@{}c@{}}Complex \& high \\ computational \\ intensive\end{tabular} \\ \hline
% \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Calibration \\ methods\end{tabular}} &
%   \begin{tabular}[c]{@{}c@{}}Static \\ quantization\end{tabular} &
%   \begin{tabular}[c]{@{}c@{}}Apply quantization \\ into weights \& \\ activation to low \\ precision \\ before deployment\end{tabular} &
%   \begin{tabular}[c]{@{}c@{}}Computationally \\ efficient\end{tabular} &
%   Accuracy drop \\ \cline{2-5} 
%  &
%   \begin{tabular}[c]{@{}c@{}}Dynamic \\ quantization\end{tabular} &
%   \begin{tabular}[c]{@{}c@{}}Activations are \\ quantized dynamically\\ at runtime based \\ on data \\ being processed\end{tabular} &
%   High accuracy &
%   \begin{tabular}[c]{@{}c@{}}Slow \& require \\ more resources \\ at runtime\end{tabular} \\ \hline
% \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Quantization \\ scheme\end{tabular}} &
%   Uniform &
%   \begin{tabular}[c]{@{}c@{}}Fixed step size \\ between \\ quantization levels\end{tabular} &
%   Simple \& fast &
%   \begin{tabular}[c]{@{}c@{}}Not adaptive to \\ data distribution\end{tabular} \\ \cline{2-5} 
%  &
%   Non-uniform &
%   \begin{tabular}[c]{@{}c@{}}Adaptive step size\\  based on \\ data distribution\end{tabular} &
%   \begin{tabular}[c]{@{}c@{}}High accuracy \& \\ efficient bandwidth\end{tabular} &
%   \begin{tabular}[c]{@{}c@{}}More complexity \\ to data distribution\end{tabular} \\ \hline
% \multirow{2}{*}{Granularity} &
%   Layer-wise &
%   \begin{tabular}[c]{@{}c@{}}All weights \&\\  activations within \\ a layer is quantized\\  using the same scale\end{tabular} &
%   \begin{tabular}[c]{@{}c@{}}Simple \& sub-\\ optimal accuracy\end{tabular} &
%   \begin{tabular}[c]{@{}c@{}}Less flexible \& \\ accuracy drop\end{tabular} \\ \cline{2-5} 
%  &
%   Channel-wise &
%   \begin{tabular}[c]{@{}c@{}}Each channel \\ quantized with \\ same scaling factors\end{tabular} &
%   \begin{tabular}[c]{@{}c@{}}Flexible \& \\ high accuracy\end{tabular} &
%   \begin{tabular}[c]{@{}c@{}}Complex \& high \\ computational \\ overhead\end{tabular} \\ \hline
% \multirow{2}{*}{Others} &
%   Mixed-Precision &
%   \begin{tabular}[c]{@{}c@{}}Quantized with \\ different bit precision\\  for each layer\end{tabular} &
%   \begin{tabular}[c]{@{}c@{}}Performance \\ optimization \\ for low-precision \\ quantization\end{tabular} &
%   \begin{tabular}[c]{@{}c@{}}Complex \& need \\ extended search \\ processes\end{tabular} \\ \cline{2-5} 
%  &
%   Hardware-aware &
%   \begin{tabular}[c]{@{}c@{}}Quantization \\ parameters according\\ to the hardware \\ resources\end{tabular} &
%   \begin{tabular}[c]{@{}c@{}}Hardware specific \\ optimization\end{tabular} &
%   \begin{tabular}[c]{@{}c@{}}Less flexible \&\\  complex\end{tabular} \\ \hline
% \end{tabular}
% \end{table}
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[]
\centering
\caption{Pros and cons for different quantization methods in ViT models.}
\label{table:quan_classification}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{c|c|c|c|c}
\hline
\textbf{\begin{tabular}[c]{@{}c@{}}Aspects of\\ quantization\end{tabular}} &
  \textbf{Techniques} &
  \textbf{Description} &
  \textbf{Pros} &
  \textbf{Cons} \\ \hline
\multirow{2}{*}{Quantization schemes} &
  \begin{tabular}[c]{@{}c@{}}Uniform\\ ~\cite{fangxin2020ausn,fang2020post}\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Fixed step size between \\ quantization levels\end{tabular} &
  Simple \& Fast &
  \begin{tabular}[c]{@{}c@{}}Not adaptive to \\ data distribution\end{tabular} \\ \cline{2-5} 
 &
  \begin{tabular}[c]{@{}c@{}}Non-uniform \\ ~\cite{oh2022non,jeon2022mr}\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Adaptive step size based\\ on data distribution\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}High accuracy \& \\ Efficient bandwidth\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}More complexity Specific \\ to data distribution\end{tabular} \\ \hline
\multirow{2}{*}{Quantization approaches} &
  \begin{tabular}[c]{@{}c@{}}Post-training \\ quantization(PTQ) ~\cite{habi2021hptq,kluska2020post}\end{tabular} &
  Adjust the weights without finetuning &
  \begin{tabular}[c]{@{}c@{}}Possible with limited data \\ \& Low computational intensive\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Accuracy drop \& \\ Limited adaptation\end{tabular} \\ \cline{2-5} 
 &
  \begin{tabular}[c]{@{}c@{}}Quantization-aware \\ training(QAT) ~\cite{kim2020frostnet,zhang2023qd,cormier2021towards}\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Incorporates the quantization process into\\ the forward and backward propagation steps\\ of the training algorithm\end{tabular} &
  Better accuracy than PTQ &
  \begin{tabular}[c]{@{}c@{}}Complex \& High \\ computational intensive\end{tabular} \\ \hline
\multirow{2}{*}{Calibration methods} &
  \begin{tabular}[c]{@{}c@{}}Static quantization\\ ~\cite{fan2019static,liu2021improving}\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Apply quantization into weights activation \\ to low precision before deployment\end{tabular} &
  Computationally efficient &
  Accuracy drop \\ \cline{2-5} 
 &
  \begin{tabular}[c]{@{}c@{}}Dynamic quantization\\ ~\cite{liu2022instance,huang2023structured}\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Quantized the weights statically but \\ activations are quantized dynamically at \\ runtime based on data being processed\end{tabular} &
  High accuracy &
  \begin{tabular}[c]{@{}c@{}}Slow \& Require more \\ resources at runtime\end{tabular} \\ \hline
\multirow{2}{*}{Granularity} &
  \begin{tabular}[c]{@{}c@{}}Layer-wise \\ ~\cite{li2019fully,chu2019mixed,tzelepis2019deep}\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}All weights activations within a layer\\ are quantized using same scale\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Simple \& sub-optimal \\ accuracy\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Less flexible \\ Accuracy drop\end{tabular} \\ \cline{2-5} 
 &
  \begin{tabular}[c]{@{}c@{}}Channel-wise\\ ~\cite{zhang2022mffnet,li2019fully,xie2023joint}\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Each channels quantized with same\\ scaling factors\end{tabular} &
  Flexible \& High accuracy &
  \begin{tabular}[c]{@{}c@{}}Complex \& High \\ computational overhead\end{tabular} \\ \hline
\multirow{2}{*}{Others} &
  \begin{tabular}[c]{@{}c@{}}Mixed-Precision\\ ~\cite{chu2019mixed,chu2021mixed,xu2023q,wang2019haq}\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Quantized with different bit precision\\ for each layer\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Performance Optimization for\\ low-precision quantization\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Complex \& need extended\\ search processes\end{tabular} \\ \cline{2-5} 
 &
  \begin{tabular}[c]{@{}c@{}}Hardware-aware\\ ~\cite{wang2019haq,dong2021hao}\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Quantization parameters according\\ to the hardware resources\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Hardware specific \\ optimization\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}Less flexible \& \\ complex\end{tabular} \\ \hline
\end{tabular}%
}
\vspace{-3mm}
\end{table}




