% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[]
\centering
\caption{The overview of popular software tools for deploying deep learning models on different hardware architectures.}
\label{softwaretools}
\renewcommand{\arraystretch}{0.95}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{c|c|c|ccc}
\hline
\multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Tool \\ Name\end{tabular}}} &
  \multirow{2}{*}{\textbf{Type}} &
  \multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Key \\ features\end{tabular}}} &
  \multicolumn{3}{c}{\textbf{Supported edge devices}} \\ \cline{4-6} 
 &
   &
   &
  \multicolumn{1}{c|}{\textbf{FPGA}} &
  \multicolumn{1}{c|}{\textbf{GPU}} &
  \textbf{CPU} \\ \hline
Xilinx Vivado design suite~\footref{vivado} &
  Toolkit &
  Used for synthesis, simulation, and configuring Xilinx FPGAs &
  \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Xilinx \\ FPGA\end{tabular}} &
  \multicolumn{1}{c|}{No} &
  No \\ \hline
Intel Quartus Prime~\footref{quartus} &
  Toolkit &
  Used for synthesis, place-and-route, and programming. &
  \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Intel\\ FPGA\end{tabular}} &
  \multicolumn{1}{c|}{No} &
  No \\ \hline
OpenVINO~\footref{Openvinotoolkit} &
  Toolkit &
  Optimized inference, supports multiple frameworks, Intel hardware-focused &
  \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Intel\\ FPGA\end{tabular}} &
  \multicolumn{1}{c|}{Yes} &
  Yes \\ \hline
Vitis AI~\footref{vitis} &
  Engine &
  Model compression, xmodel generation, diverse pretrained model &
  \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Xilinx \\ FPGA\end{tabular}} &
  \multicolumn{1}{c|}{No} &
  No \\ \hline
Hls4ml~\footref{hls4ml} &
  Library &
  High-level synthesis for FPGA, supports various frameworks &
  \multicolumn{1}{c|}{Yes} &
  \multicolumn{1}{c|}{No} &
  No \\ \hline
FINN~footref{finn} &
  Engine &
  Quantized models, based on Vitis AI, streaming dataflow for inference &
  \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Xilinx \\ FPGA\end{tabular}} &
  \multicolumn{1}{c|}{No} &
  No \\ \hline
TensorRT~\footref{tensorrt} &
  Engine &
  High-performance AI inference on NVIDIA GPUs &
  \multicolumn{1}{c|}{No} &
  \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}NVIDIA\\ GPU\end{tabular}} &
  No \\ \hline
NVIDIA Triton Inference Server~\footref{triton} &
  Inference Server &
  Scalable inference serving, multi-model deployment, Provide model analyzer &
  \multicolumn{1}{c|}{No} &
  \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}NVIDIA\\ GPU\end{tabular}} &
  x86, ARM \\ \hline
oneDNN~\footref{onednn} &
  Library &
  Optimized deep learning performance, cross-platform &
  \multicolumn{1}{c|}{No} &
  \multicolumn{1}{c|}{Experimental} &
  Intel CPU, ARM \\ \hline
ONNX Runtime~\footref{onnxrun} &
  Engine &
  Open-source inference, hardware-specific execution providers &
  \multicolumn{1}{c|}{Yes} &
  \multicolumn{1}{c|}{Yes} &
  Yes \\ \hline
\end{tabular}%
}
\vspace{-3mm}
\end{table}