\documentclass[10pt, conference]{IEEEtran}  % Comment this line out
                                                          % if you need a4paper
%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4
                                                          % paper

\IEEEoverridecommandlockouts                              % This command is only
                                                          % needed if you want to
                                                          % use the \thanks command

% \maxdeadcycles=500
\usepackage{lipsum} % For dummy text example
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{cite}
% \usepackage{syntax}
\usepackage{mathtools, cuted}
\usepackage{booktabs}
\usepackage{threeparttable}
\usepackage{comment}
\usepackage{authblk}
\usepackage{graphics}
\usepackage{threeparttable}
\usepackage[table,xcdraw]{xcolor}
\usepackage{multicol}
\usepackage{multirow}
\newcommand{\name}{\texttt{SALTY}}
\usepackage{xcolor}
% \usepackage{algorithm}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\SetKwRepeat{Do}{do}{while}%
% \usepackage{algpseudocode}
\usepackage{amsmath,amssymb}
% \usepackage[noend]{algpseudocode}
\usepackage{caption}
\usepackage{paralist}
\usepackage{dblfloatfix}
\usepackage{subcaption}
% \usepackage[caption=false,font=footnotesize]{subfigure}
% \usepackage{fixltx2e}
\usepackage{setspace}
\usepackage{wrapfig}
\usepackage[hyphens]{url}
\usepackage{amsthm}
\usepackage{relsize}
\usepackage{amssymb}% http://ctan.org/pkg/amssymb
\usepackage{pifont}% http://ctan.org/pkg/pifont
\usepackage{float}
\usepackage{graphicx}

\usepackage[table,xcdraw]{xcolor}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
% \usepackage{amssymb}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\linespread{1}

% \algnewcommand\algorithmicforeach{\textbf{for each}}
% \algdef{S}[FOR]{ForEach}[1]{\algorithmicforeach\ #1\ \algorithmicdo}


% \makeatletter
% \newcommand{\multiline}[1]{%
%   \begin{tabularx}{\dimexpr\linewidth-\ALG@thistlm}[t]{@{}X@{}}
%     #1
%   \end{tabularx}
% }
% \makeatother


\begin{document}



\title{SALTY: Explainable Artificial Intelligence Guided Structural Analysis for Hardware Trojan Detection}


\author[1]{Tanzim Mahfuz}
\author[2]{Pravin Gaikwad}
\author[1]{Tasneem Suha}
\author[2]{Swarup Bhunia}
\author[1]{Prabuddha Chakraborty}
\affil[1]{Department of Electrical \& Computer Engineering, University of Maine, Orono, ME, USA}
\affil[2]{Department of Electrical \& Computer Engineering, University of Florida, Gainesville, FL, USA}




\date{}








\maketitle
\thispagestyle{fancy}

% -- Clear all header/footer fields --
\fancyhf{}


% -- Put custom text in the center of the footer --
\fancyfoot[C]{\large \textbf{ \textcolor{blue}{Â© This paper has been accepted for publication at 43\textsuperscript{rd} IEEE VLSI Test Symposium (VTS), 2025}}}
\renewcommand{\footrulewidth}{0.4pt}
% -- Typically for IEEEtran we set these to 0 --
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
% \thispagestyle{empty}
% \pagestyle{plain}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{abstract}
Hardware Trojans are malicious modifications in digital designs that can be inserted by untrusted supply chain entities. Hardware Trojans can give rise to diverse attack vectors such as information leakage (e.g. MOLES Trojan) and denial-of-service (rarely triggered bit flip). Such an attack in critical systems (e.g. healthcare and aviation) can endanger human lives and lead to catastrophic financial loss. Several techniques have been developed to detect such malicious modifications in digital designs, particularly for designs sourced from third-party intellectual property (IP) vendors. However, most techniques have scalability concerns (due to unsound assumptions during evaluation) and lead to large number of false positive detections (false alerts). Our framework (\name) mitigates these concerns through the use of a novel Graph Neural Network architecture (using Jumping-Knowledge mechanism) for generating initial predictions and an Explainable Artificial Intelligence (XAI) approach for fine tuning the outcomes (post-processing). Experiments show $>98\%$ True Positive Rate (TPR) and True Negative Rate (TNR), significantly outperforming state-of-the-art techniques across a large set of standard benchmarks.  

% The design and production of integrated circuits primarily rely on a globally spread semiconductor supply chain that involves several entities and introduces numerous vulnerabilities at different stages. The presence of these vulnerabilities in the supply chain allows attackers to embed malicious modifications (hardware Trojans) in digital designs. In order to combat this issue, many machine learning techniques have been developed to identify hardware Trojans at different levels of abstraction including gate-level representation. While much attention has been given to effectively identifying Trojans, little attention has been towards understanding the underlying reasons behind the success or failure of such detections. In order to address this gap, we propose a hardware Trojan detection/analysis framework that can not only effectively identify Trojans without any prior knowledge of the design but can also provide insights into the intent of the detected Trojans as well as provide explanation behind why this structure was predicted as a Trojan. This automated framework, by supplying such  knowledge, will allow security experts to obtain better understanding of both the threat and the predicted Trojan structures.
% We observe that X-DFS offers robust targeted security and also has the ability to unravel human-understandable defense strategies. 

\end{abstract}

\begin{IEEEkeywords}
Hardware Trojans, Hardware Security and Trust, Explainable Artificial Intelligence
\end{IEEEkeywords}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Introduction}
The global distributed supply chain has a massive economic advantage but suffers from security and trust concerns. Most modern semiconductor companies operate in a fabless model, including economic giants such as NVIDIA, Apple, AMD, Qualcomm, and Broadcom that are driving the current AI wave. Most small semiconductor business are following the same example set by these larger companies. Most of these companies often acquire/license application-specific design blocks (also called IPs) from third-party vendors around the world, integrate these IPs into their core design, and send the final design to other entities for fabrication/testing/packaging. This distributed model opens up the system to a variety of threat vectors such as hardware Trojans, intellectual property theft, and privacy compromise through reverse engineering. 

In this study, we focus on hardware Trojans which are intentional malicious modifications in digital designs that can lead to certain non-characteristic behavior of the system in-field \cite{derms}. Such attacks can be carried out by malicious third-party IP vendors (3PIP), rogue employees in the design house, and an untrusted foundry. Typically hardware Trojans have a very small footprint (compared to the original design) in terms of area/power/delay and are rarely triggered during the system testing phase. Hence, it is a difficult task to detect these modifications in massive digital designs. Recent works such as VIPR \cite{gaikwad2023hardware, hoque2018hardware} and TrojanSAINT \cite{lashen2023trojansaint} have attempted to detect these Trojans in digital designs using different Artificial Intelligence (AI) techniques with varying degrees of success. VIPR suffers from low True Positive Rate (TPR) while TrojanSAINT has massive instability issues (performs poorly on certain designs). The post-processing techniques introduced in VIPR are inspiring, but lack dynamism and flexibility. Other techniques such as GNN4Gate \cite{cheng2022gnn4gate}, FAST-GO \cite{imangholi2024fast}, NHTD \cite{hasegawa2023node} have major scalability/practicality concerns because of unsound evaluation choices (trained and tested on similar benchmark structures). 

In this work, we propose \textbf{SALTY} (\textbf{S}tructural \textbf{A}I for Exp\textbf{l}ainable \textbf{T}rojan Anal\textbf{y}sis), a novel hardware Trojan detection framework (golden free) that attempts to mitigate the concerns and shortcomings of existing frameworks. \name~ utilizes a novel Graph Neural Network (GNN) with Jumping Knowledge (JK) mechanism while leveraging design structural features similar to SAIL \cite{chakraborty2021sail} (a reverse engineering framework). The JK-mechanism reduces the risk of over-smoothing by aggregating hidden layer embeddings. This allows the model to attain a much higher TPR and TNR compared to other state-of-the-art GNNs. Artificial Intelligence (AI) and statistical models are often not fully aware of the domain constraints and make irrational decisions (hallucination) leading to poor performance. To tackle this concern, we utilize explainability techniques to draw insights about when and how our AI models fail to make correct decisions. This insight allows us to build a dynamic post-processing module that can further enhance the performance of \name. We evaluate our framework on a large set of standard TrustHub benchmarks ($>15$) and compare the results against seven other state-of-the-art (SOTA) Trojan detection techniques. We observe significant performance improvements (TPR/TNR combined) and enhanced visibility into the Trojan detection process (via explainability).   
\input{fig_latex/methodology}
In particular, we make the following contributions:
\begin{enumerate}
    \item Designed a novel Graph Neural Network (GNN) that utilizes Jumping Knowledge (JK) mechanism for efficient hidden layer embedding aggregation.
    \item Developed a novel explainability guided dynamic post-processing module that can boost Trojan detection performance by removing hallucinations.
    \item Implemented the \name~framework as a highly parameterized tool and integrated it into the EDA flow. 
    \item Robust generalization in hardware Trojan detection, enabling the identification of Trojans in entirely unseen benchmarks without prior exposure to similar structures.
    \item Extensively evaluated \name~with $>15$ benchmarks against seven SOTA Trojan detection frameworks.
\end{enumerate}

% Introduction on HT issue.
% How researchers have started to tackle the issue.
% Trend towards ML and GNN.
% Their limitations.
% Proposed method.



\section{Related Works}\label{sec:background} 

% This section presents essential background information on hardware Trojan attacks, along with strategies for countermeasuring such attacks.

% What's HT, detection, detection using ML 
A hardware Trojan (HT) is a malicious alteration or addition to a hardware design during its creation or assembly. These Trojans compromise the hardware by creating vulnerabilities or unintended functions, ranging from small circuits leaking data to system-disrupting modifications. Their stealth and dormancy make detection and mitigation difficult. 
% Detecting hardware Trojans involves identifying deviations from expected behavior or structural anomalies within hardware designs. Traditional hardware Trojan detection methods include functional testing, side-channel analysis, and golden model comparison. Functional testing identifies unintended behavior, side-channel analysis examines anomalies in physical parameters like power and timing, and golden model comparison validates designs against trusted references. These methods face challenges with scalability, data dependency, and detecting advanced Trojans in complex circuits, highlighting the need for more advanced, data-driven techniques.
% In recent years, machine learning (ML) has proven to be a potent method for detecting hardware Trojans. Using data-driven algorithms, ML models can identify patterns and abnormalities from training datasets, facilitating automated, scalable, and precise detection. Graph-based methods, such as Graph Neural Networks (GNNs), have gained particular attention because of their ability to model hardware structures as graphs, capturing complex interdependencies within circuits. These ML approaches offer significant advancements in Trojan detection by addressing limitations of scalability, adaptability, and golden-model dependency.
Detecting hardware Trojans (HTs) remains a crucial research focus, prompting the development of various frameworks and methods to tackle this issue. In this section, we examine significant progress made in the domain, particularly emphasizing machine learning and graph-based approaches, and discuss their advantages and drawbacks. 

% Machine Learning-Based Detection Frameworks
% The authors in~\cite{gaikwad2023hardware} present VIPR, a novel machine learning-based framework to verify the trust of third-party hardware IPs, eliminating the need for golden models. The framework employs pseudo-self-referencing training and post-processing algorithms to enhance hardware Trojan detection accuracy and reduce false positives. However, its dependency on synthetic Trojan insertion and feature selection limits its applicability to real-world designs with diverse Trojan structures. The authors in~\cite{li2020xgboost} propose a hybrid detection framework that uses XGBoost, combining static and dynamic analysis to improve the detection accuracy at the gate level. While effective, the framework's reliance on labeled datasets and its computational complexity hinder its scalability and generalization to diverse hardware designs.


Various frameworks that leverage machine learning have been developed to detect hardware Trojans, each offering its advantages and drawbacks. VIPR \cite{gaikwad2023hardware} improves detection accuracy without relying on golden models through pseudo-self-referencing and post-processing, yet it is limited by its dependence on synthetic Trojans and feature selection. A hybrid XGBoost framework \cite{li2020xgboost} integrates static and dynamic analysis but faces issues with scalability and generalizability due to computational demands and dataset reliance. Graph Neural Networks (GNNs) effectively represent circuits as graphs, facilitating accurate detection. TrojanSAINT \cite{lashen2023trojansaint} breaks circuits into subgraphs to extract features, although it experiences challenges with reduced accuracy and scalability. GNN4Gate \cite{cheng2022gnn4gate} facilitates automatic Trojan detection without the need for golden models; however, it necessitates the manual design of various features, which complicates its application to real-world scenarios. GNN4HT \cite{chen2024gnn4ht} expands detection to gate-level and RTL designs, but is hampered by high interclass similarity and limited generalization due to insufficient data set augmentation. FAST-GO \cite{imangholi2024fast} employs Graph Convolutional Networks (GCNs) enhanced with improved features and dynamic thresholds for scalable detection. R-HTDetector \cite{hasegawa2022r} boosts robustness through adversarial training. NHTD-GL \cite{hasegawa2023node} automates feature extraction to detect threats at the node level. These methods operate at the net level and encounter difficulties with imbalanced datasets and feature initialization, while also lacking the ability to localize Trojans. 

 % In \cite{gaikwad2023hardware}, VIPR is introduced as a machine learning framework for verifying third-party hardware IPs without golden models, using pseudo-self-referencing and post-processing to improve Trojan detection, though limited by synthetic Trojan reliance and feature selection. Similarly, \cite{li2020xgboost} presents a hybrid XGBoost-based framework for gate-level detection, combining static and dynamic analysis, but faces challenges in scalability and generalization due to dataset dependency and computational complexity.

% Authors in~\cite{gaikwad2023hardware} presents a machine-learning-based framework for trust verification of third-party hardware IPs, eliminating the need for golden models. It leverages pseudo-self-referencing training and post-processing algorithms to enhance hardware Trojan detection accuracy and reduce false positives. The framework's dependency on synthetic Trojan insertion and feature selection limits its applicability to real-world designs with diverse Trojan structures.
% Authors in~\cite{li2020xgboost}, proposes a hybrid detection framework that uses XGBoost to enhance the accuracy of gate-level hardware Trojan detection by combining static and dynamic analysis. However, its reliance on labeled datasets and computational complexity limits its scalability and generalization to diverse hardware designs.

% Graph Neural Network (GNN)-Based Approaches
% Graph neural networks (GNNs) have emerged as a promising tool for hardware Trojan detection, enabling the modeling of circuit structures as graphs for more accurate analysis. The TrojanSAINT framework employs GNNs in gate-level netlists~\cite{lashen2023trojansaint}. It simplifies large circuits into smaller subgraphs using GraphSAINT~\cite{zeng2019graphsaint} and extracts features such as gate types and input/output distances. TrojanSAINT achieves a high true positive rate, but misclassifies many normal nodes, reducing recognition accuracy. The authors in~\cite{cheng2022gnn4gate} propose GNN4Gate, a bidirectional GNN framework to model circuit graphs and integrate signal features, achieving automated, golden-free detection and localization of Trojan gates. The authors in ~\cite{chen2024gnn4ht} introduce GNN4HT, a two-stage GNN framework to detect hardware Trojans and classify their functionalities. Both works have average true positive and true negative rates that are acceptable but fall short of state-of-the-art performance, limiting their effectiveness in diverse Trojan detection scenarios. 

% Graph neural networks (GNNs) are effective for hardware Trojan detection by modeling circuits as graphs. TrojanSAINT~\cite{lashen2023trojansaint} leverages GNNs to analyze gate-level netlists, using subgraph sampling and feature extraction, but faces scalability issues and reduced accuracy from graph simplifications. GNN4Gate employs bidirectional GNNs for automated, golden-free Trojan detection, but reliance on extensive training data and local feature characteristics limits its scalability. The authors in~\cite{chen2024gnn4ht} present GNN4HT, a two-stage GNN framework for gate-level and RTL designs that faces challenges with high inter-class similarity and limited data due to its reliance on dataset augmentation. 

% TrojanSAINT is a hardware Trojan detection framework using Graph Neural Networks (GNNs) on gate-level netlists. It simplifies large circuits into smaller subgraphs with GraphSAINT and extracts features such as gate types and input/output distances. To address dataset imbalance, it adjusts classification thresholds for better detection. However, despite threshold tuning, it can struggle with extreme imbalances, and simplifying netlists into undirected, unweighted graphs can reduce detection accuracy. Scalability is also a challenge because of the computational expense of handling very large circuits. Furthermore, using the same benchmark for validation and testing can lead to biased or overly optimistic results.
% \cite{cheng2022gnn4gate} introduces a new method for detecting gate-level hardware Trojans using a bidirectional GNN framework. This approach, which models circuit graphs and integrates signal features, allows for accurate, automated, golden-free detection and localization of Trojan gates. However, its reliance on extensive training data and local feature focus limits its scalability and adaptability to incomplete netlists or varied Trojan designs, challenging its broader use in complex hardware.
% A study in~\cite{chen2024gnn4ht} presents a two-stage Graph Neural Network framework for detecting hardware Trojans and classifying functionalities. The first stage uses graph modeling for precise localization, while the second applies data augmentation and classification to identify Trojan functionalities, achieving better accuracy at gate-level and RTL designs. However, its reliance on dataset augmentation may hinder performance with limited or diverse data, and it struggles with high inter-class similarity or underrepresented functionalities.     
\input{Table/Data_Splitting}

% Further improvements in Graph-Based Methods
% Recent studies have further refined graph-based approaches to enhance detection capabilities. The~\cite{imangholi2024fast} present FAST-GO, a graph-convolutional network-based framework that combines optimized feature selection and dynamic thresholding for efficient and scalable detection. However, its dependency on imbalanced datasets and the lack of output post-processing limit its adaptability to varied benchmarks and complex Trojan designs. The R-HTDetector~\cite{hasegawa2022r} work presents a resilient detection framework using adversarial training to counter gate modification attacks. Although robust against specific attack scenarios, its dependence on adversarial training metrics restricts its flexibility for diverse architectures and novel attack vectors. In~\cite{hasegawa2023node}, the authors introduce NHTD-GL, a graph-based learning framework for the node-level detection of hardware Trojans. By automating the extraction of structural and functional features, the framework achieves scalability and precision. However, its reliance on precise initial feature representation and imbalanced datasets may impact its adaptability in diverse or real-world applications.

% Recent studies enhance graph-based hardware Trojan detection. FAST-GO~\cite{imangholi2024fast} leverages GCNs with refined feature selection and dynamic thresholds for scalable detection but lacks adaptability due to imbalanced datasets and absence of post-processing. R-HTDetector uses adversarial training for robustness against gate modification attacks, but it does not offer native hardware Trojan localization~\cite{hasegawa2022r}. NHTD-GL automates feature extraction for node-level detection but faces challenges from imbalanced datasets and feature initialization, affecting real-world use \cite{hasegawa2023node}.

% In ~\cite{imangholi2024fast} a graph-convolutional network-based framework is presented in~\cite{imangholi2024fast} for detecting hardware Trojans in gate-level netlists, combining high precision, scalability, and efficiency through optimized feature selection and dynamic thresholding. However, its dependence on imbalanced datasets and lack of output post-processing limit its adaptability to varied benchmarks and complex Trojan designs.
% The authors in~\cite{hasegawa2022r} present "R-HTDetector," a resilient hardware Trojan detection framework that utilizes adversarial training to boost resistance to gate modification attacks. The approach generates adversarial examples in the training phase, which strengthens the model's robustness while ensuring high detection accuracy on various circuit benchmarks. Nonetheless, its dependence on particular adversarial training metrics and specific scenarios might restrict its flexibility when dealing with highly varied circuit architectures and novel attack vectors.
% The study detailed in~\cite{hasegawa2023node} introduces "NHTD-GL," a graph-based learning framework designed for accurate node-level detection of hardware Trojans in gate-level netlists. This framework leverages sophisticated graph modeling and domain expertise to automate the extraction of both structural and functional features, providing a scalable and precise method for identifying malicious nodes without requiring extensive manual feature engineering. However, its reliance on precise initial feature representation and imbalanced datasets could restrict its scalability and resilience in diverse or real-world applications.

% \subsection{GNN: Graph Neural Network}

%Pravin
% Graph Neural Networks (GNNs) efficiently represent a graph's structural characteristics by enabling the exchange of information among its nodes. A directed graph \( G(V, E) \) consists of a set of nodes \( V \) and edges \( E \), where each node \( v \in V \) is associated with a feature vector \( f_v \). The initial embedding, also known as the feature vector, encapsulates the distinctive attributes of the node. Graph Neural Networks (GNNs) function by collecting data from the local neighborhood \( N(v) \) of a node, so that each node acquires embeddings from its adjacent nodes through the connecting edges. The update function, which can be learned, merges the node's present embedding with the compiled embeddings of its neighbors to calculate a new embedding. Through this iterative process, nodes gather information about both their characteristics and those of neighboring nodes. At the level of graphs, representations are generally formed by combining, averaging, or using a max operation across all node embeddings. \textcolor{blue}{Need to add info related what is used in methodology at high level. Like a high level intro to GNN + GNN intro diagram if you want it}

% Different DFS techniques have been proposed over the years for thwarting diverse IC and supply chain attacks. However, to the best of our knowledge, there does not exist an explainable Artificial Intelligence (XAI) framework that can automatically search the DFS solution space towards finding the optimal solution and at the same time provide human-understandable reasoning behind the said solution choice. 

%Tanzim
% Graph Neural Networks (GNNs) have emerged as powerful tools for processing graph-structured data because they effectively capture complex relationships through message passing mechanisms \cite{wu2020comprehensive}. This capability makes GNNs particularly suitable for tasks where understanding the topology and connectivity patterns is essential, such as hardware Trojan detection, where structural relationships between components can indicate malicious modifications. In our work, we employ Graph Attention Networks (GATs) \cite{velickovic2017graph}, which enhance standard GNNs by incorporating attention mechanisms to assign different weights to neighboring nodes.


\section{Motivations}\label{sec:motivation} 
\subsection{Generalization to Entirely Unseen Digital Designs}
A key motivation for our work is to achieve robust generalization in hardware Trojan detection across completely unseen designs. Therefore, a detection framework must be capable of identifying Trojans in completely new designs without having been trained or validated on similar structures. Table~\ref{table:data_splitting} highlights the summary of current approaches.
% where existing SOTA works lacks generalization.
\subsection{Informed Post Processing - Minimize AI Hallucinations}
While techniques like VIPR \cite{gaikwad2023hardware} have investigated post-processing, such approaches are static in nature and fail to take the advantage of more intricate patterns. We hypothesize that explainability techniques \cite{xdfs,ribeiro2016should,arrieta2020explainable, doshi2017towards, guidotti2018survey} can provide deeper insight into AI models opening pathways for more robust post-processing that can foster trust and minimize the AI hallucinations.   

% As AI models are deployed in decision-critical domain, ensuring that AI systems are understandable to humans is essential for fostering trust, and enabling accountability by illuminating the rationale behind specific outputs~\cite{xdfs,ribeiro2016should,arrieta2020explainable}. Explainable AI (XAI) aims to address these by broadly categorizing them into intrinsic interpretability where the model architecture is designed to be understandable and post-hoc interpretability which involves analyzing and explaining the model's decisions after training~\cite{doshi2017towards,guidotti2018survey}.

% \subsection{Golden-Free Detection}
% Due to the scarcity or even non-existence of golden chips, it is imperative to develop detection methodologies that do not rely on such references. A golden-free detection model overcomes these limitations, making it critically important for practical applications. 

% \subsection{Scalability and Diversity}
% A framework must exhibit scalability to various netlists, regardless of their size or complexity. This challenge is compounded by the fact that hardware Trojans typically constitute a very small portion of the circuit, difficult to locate in an intricate circuit, leading to highly imbalanced datasets that can bias the training process.


\section{Methodology}\label{sec:method}
% Inspired by Sec.~\ref{sec:motivation}, we have developed the \name~framework which automatically: (i) Extract knowledge from the digital designs and develop an ML model using the generated data. (ii) Incorporate Explainable AI (XAI) to demonstrate how interpretability enhances the framework's ability to handle unseen data through human-readable rules that reveal the model's inference reasoning process. The overview of the \name~is illustrated in Fig.\ref{fig:method}.

Inspired by Sec.~\ref{sec:motivation}, we have developed the \name~framework which: (i) Integrates the Jumping Knowledge mechanism to boost performance on unseen designs; (ii) Utilize explainable AI for reducing AI hallucinations. The overview of the \name~is illustrated in Fig.\ref{fig:method}.
\input{Algo/datamodel}
 % The process begins with transferring the digital designs (including Trojans) into graphs. A graph is defined as ($G\textsubscript{r} = {V, E}$), where $V$ represents the vertices and $E$ denotes the hyperedges connecting elements within $V$.  In this study, $V$ = wires of a digital design, while $E$ = connections between the wires.
 %Algo.~\ref{algo:Model Genesis} provides a detailed explanation of the initial stages, from graph generation to model creation. Algo.~\ref{algo:Model Genesis} accepts the Trojan-inserted design ($\mathcal{D}$), the corresponding ground truth ($\mathcal{T}_{lb}$) for Trojan and non-Trojan wires, and the locality ($\mathcal{L}$) as input parameters.The prepared dataset is subsequently utilized for model development ($M_d$) and training, with the trained model being stored ($\mathbb{M}$) in line 10.
\subsection{Knowledge Discovery \& Model Design}
Let's assume, a graph $G_r$ = $(V,E)$ is defined, where $V$ represents vertices and $E$ denotes hyperedges. Here, $V$: wires in a digital design, and $E$: connections between wires. Algo.~\ref{algo:Model Genesis} outlines the initial stages from graph generation to model creation using the Trojan inserted design ($\mathcal{D}$), ground truth ($\mathcal{T}_{lb}$) for wire labels, and locality ($\mathcal{L}$) as inputs. Locality ($\mathcal{L}$) takes care of the number of neighbors that needs to be collected from the sub-graph. In line 1, the \textit{graphify} constructs $G_r$, with connection details $E_d$ (edge-index), in line 2. Subsequently, all nodes ($\mathcal{D}_{wires}$) of the graph are gathered, and the structural features of each wire and the corresponding true label from ($\mathcal{T}_{lb}$) are extracted and organized into the dataset ($X\_data$, $Y\_data$)(lines 4-7). \name~employs local structural features of the sub-design, similar to the approach used in SAIL \cite{chakraborty2018sail} and SAIL-based works \cite{chakraborty2024learning}. The structural features of a wire describe its local placement and how it connects to other wires through the gates it interacts with. In a subgraph, we encode the connectivity using an adjacency matrix and represent gate types through one-hot encoding, similar to \cite{xdfs}. Fig.~\ref{fig:method} illustrates the structural features extraction process, showing how the gates are vectorized and how the dataset is created via feature extraction and labeling. We utilize the Breadth-First Search (BFS) algorithm to explore neighboring gates around a specific wire - the one for which we are extracting features and assigning a label. The dataset is used for  training and the trained model, $\mathbb{M}$ is returned in line 10. In this work, we have used Graph Attention Networks (GATs) \cite{velickovic2017graph} and Jumping Knowledge (JK) mechanism \cite{xu2018representation} which extend traditional GCN by introducing attention procedures, allowing the model to assign different importance to focus on the most relevant parts of the graph which is crucial for detecting subtle patterns associated with Trojans \cite{wu2020comprehensive}. Given a graph with node features $f_i$ for each node $i \in V$, a single GAT layer computes the updated node features $f_i'$ as follows:

\[
f_i' = \sigma \left( \sum_{j \in X(i)} \alpha_{ij} Wf_j \right)
\]
% \vspace{-0.1in}
where: $X(i)$ is the set of neighboring nodes of node $i$, $W$ is a learnable weight matrix, $\sigma$ is a non-linear activation function, $\alpha_{ij}$ are the attention coefficients computed by:

\[
\alpha_{ij} = \frac{\exp \left( \text{LeakyReLU} \left( v^\top \left[ Wf_i \, \| \, Wf_j \right] \right) \right)}
{\sum_{k \in X(i)} \exp \left( \text{LeakyReLU} \left( v^\top \left[ Wf_i \, \| \, Wf_k \right] \right) \right)}
\]
Here, $v$ is a learnable weight vector, $\|$ denotes concatenation, and LeakyReLU is an activation function. The JK mechanism \cite{xu2018representation} combines information from different layers of GATs, addressing the issue of over-smoothing. Assuming we have node representations from $L$ layers, $\{f_i^{(1)}, f_i^{(2)}, \dots, f_i^{(L)}\}$, the JK mechanism aggregates these representations into a final node embedding $f_i^{JK}$ using:

\[
f_i^{JK} = \big\|_{l=1}^L f_i^{(l)}
\]
This approach retains information from all layers without loss. \name~consists of two sequential GAT layers aggregating with Jumping Knowledge which are fed into the $softmax$ activation layer. For the classification, we assign each node to the class corresponding to the highest predicted probability. 
\input{Algo/xai}
\subsection{Explainable AI: Post Processing Development}
 To introduce interpretability, we have used PyTorch Geometric's Explainer module, designed to identify influential nodes and edges in GNNs \cite{fey2019fast}. Within this module, we have leveraged the $Captum$-$Explainer$ algorithm \cite{kokhlikyan2020captum}. While other frameworks like SHAP \cite{lundberg2017unified} and LIME \cite{ribeiro2016should} are widely used for model interpretability, they may not effectively capture the complex relationships inherent in graph data. We utilize \textit{Integrated Gradients} \cite{sundararajan2017axiomatic}, a gradient-based attribution method from $Captum$-$Explainer$ that quantifies the contribution of each input feature to the model's prediction by integrating the gradients along a path from a baseline input to the actual input. For an input $\mathbf{x}$ and a baseline $\mathbf{x}'$, the attribution $\text{\textit{IG}}_{f_i}(\mathbf{x})$ for feature $f_i$ is calculated as:

\[
\text{\textit{IG}}_{f_i}(\mathbf{x}) = (x_{f_i} - x'_{f_i}) \times \int_{\alpha=0}^1 \frac{\partial F\left(x' + \alpha \times (x - x')\right)}{\partial x_{f_i}} \, d\alpha
\]
where $F$ is the model's output and $\alpha$ is a scaling factor between $0$ and $1$. Algo.~\ref{algo:XAI Development} explains the automated XAI process that enhances framework performance. Lines 1â3 extract the graph, edge-index, and structural features for each wire from the test design. Line 4 uses the trained model to predict non-Trojan and Trojan wires and lengths of the predictions stored in $x$ and $y$. The parameter $n$ specifies the number of top feature scores that the $Captum$-$Explainer$ module will provide. We eventually obtain top $n$ feature scores for both non-Trojan and Trojan nets from $F_0$ and $F_1$, respectively, which effectively distinguish between the two types of wires, in line 6. Aiming to detect Trojan nodes as accurately as possible, we take the top n average feature scores for both Trojan and non-Trojan wires (denoted as $\mathcal{K}$ and $\mathcal{V}$ array), in lines 7â9. The inputs $\mathcal{N}$ and $\mathcal{T}_{h}$ are crucial, as they determine when a non-Trojan node, initially predicted as non-Trojan (a false negative) should be reclassified as Trojan (a true positive). Specifically, $\mathcal{N}$ acts as a multiplier to check if summation of feature scores of a non-Trojan net is equal to or exceeds $\mathcal{N}$ times summation of the average feature scores of non-Trojan nets, line 11. Similarly, $\mathcal{T}_h$ represents the minimum allowable difference between summation of feature scores of a non-Trojan net and summation of the average feature scores of Trojan nets required for reclassification, line 12. If either condition is met, we adjust the prediction accordingly (prediction switched) in line 14. Finally, we calculate the True Positive Rate (TPR) and True Negative Rate (TNR) based on these updated predictions, as detailed in Sec.~\ref{sec:results}.
\input{Table/SAIL-HT_Locality}
\section{Results \& Analysis}\label{sec:results} 
% Next, we evaluate the effectiveness of \name~.
% by comparing it with the state-of-the-art approaches. We provide comprehensive explanations of the model's decision-making process using XAI results and extract human-understandable rationale.

\input{Table/SAIL-HT_main}
\input{fig_latex/explainability_Trojans}
\subsection{Experimental Setup}
To validate our proposed framework, we have established a comprehensive experimental setup to assess its effectiveness. In both algorithms, we set the parameter $\mathcal{L}$ = $7$. For algorithm~\ref{algo:XAI Development} specifically, we have used $\mathcal{N}$ = $2$, $\mathcal{T}_h$ = $0.1$, and $n$ = $10$ to inform decisions based on the XAI features. Our experiments utilize digital designs obtained from Trust-Hub \cite{trsuthub}. Regarding training parameters, we employed a weighted binary cross-entropy loss function with a batch size of $64$, the Adam optimizer, and learning rate $0.005$. $20\%$ of the training data was set aside for validation purposes. Thus, training, validation, and test datasets are mutually exclusive and unknown to each other. The number of epochs is determined using early stopping criteria based on the validation set. We assess the performance of the proposed method using the metrics of True Positive Rate (TPR) and True Negative Rate (TNR). The TPR, also known as sensitivity, quantifies the proportion of actual positive cases (Trojan nodes) that are correctly identified by the model. Conversely, the TNR, or specificity, measures the proportion of actual negative cases (non-Trojan nodes) that are accurately classified. These metrics are calculated using the following equations:

\[
\begin{aligned}
\textit{TPR} &= \frac{\textit{TP}}{\textit{TP} + \textit{FN}} \quad & \textit{TNR} &= \frac{\textit{TN}}{\textit{TN} + \textit{FP}}
\end{aligned}
\]
%Following a practical model training strategy, we ensure that when a design like rs232\_t1000 is used for testing, no designs from the rs232 family are included neither in training nor in validation sets (shown in Table~\ref{table:data_splitting}).
% \input{Table/SAIL_HT_general}
% \subsection{\name~Detecting Trojans}
% We evaluate the performance of various Graph Neural Network (GNN) architectures, including Graph Convolutional Networks (GCN), GCN with Jumping Knowledge (GCN+JK), Graph Attention Networks (GAT), and GAT with Jumping Knowledge (GAT+JK). Additionally, we use the XAI-enhanced version of GAT+JK (XAI GAT+JK). We assess these models using the True Positive Rate (TPR) and True Negative Rate (TNR) as evaluation metrics. The comparative analysis, presented in Table~\ref{tab:self_comparison}, shows that the XAI GAT+JK model outperforms the other architectures, achieving the highest TPR and TNR scores. This superior performance highlights the effectiveness of integrating explainable AI techniques with GAT+JK, enhancing the model's ability to accurately detect Trojan nodes while maintaining a low false positive rate and we name this XAI GAT+JK as \name.

\subsection{\name~for Different Locality Sizes}
We also experiment the performance of \name~ with different locality sizes ($\mathcal{L}$) for structural features extraction, specifically sizes of $5$, $7$, and $10$. The results, summarized in Table~\ref{tab:localities}, indicate that $\mathcal{L}$ = $7$ yields the highest accuracy in detecting hardware Trojans. Our observation finds that $\mathcal{L}$ = $7$ can be attributed to an optimal balance between context and relevance. A smaller locality size, such as $5$, may not capture sufficient structural information surrounding each node, potentially missing critical patterns associated with Trojan circuits. On the other hand, increasing the locality size to $10$ or more introduces a larger context but also brings in additional irrelevant or noisy information. 


\input{fig_latex/explainability_nonTrojans}
\input{Table/Rules}
\subsection{Comparison with the State-of-the-Art}
We further evaluate our proposed framework against several state-of-the-art hardware Trojan detection methods, including VIPR, TrojanSAINT, GNN4Gate, GNN4HT, FAST-GO, R-HTDET, and NHTD. We have also evaluated the performance of several GNN architectures (our own built) on GCN, GCN+JK, GAT, GAT+JK, and XAI-enhanced GAT+JK. As summarized in Table~\ref{tab:sail-ht_main}, XAI-enhanced GAT+JK of \name~outperforms these existing methods by achieving a TPR of $98.47\%$ and a TNR of $98.14\%$. In our approach, we ensure that no benchmarks from the same circuit family are included in either the training or validation datasets. For instance, benchmarks like s38417\_t100, s38417\_t200, and s38417\_t300, which belong to the same circuit family (SCF) of s38417, are excluded from training and validation when evaluating any benchmark from s38417 (shown in Table~\ref{table:data_splitting}). This methodology closely mirrors practical applications where the test data is entirely unknown during the model development phase. Prior works such as GNN4Gate, FAST-GO, R-HTDET and others include benchmarks from the same circuit family in their training sets potentially reduce generalization to new designs. Among them, TrojanSAINT employs a practical training approach, but exhibits a TPR of $82.07\%$ and a TNR of $83.33\%$. As including designs from the same circuit family can potentially enhance model familiarity, NHTD is more effective at correctly identifying non-Trojan nodes, but less capable of detecting actual Trojan instances. 
% By strictly avoiding any overlap between the benchmark families used in training, validation, and testing, \name~more accurately reflects real-world conditions. 


\subsection{Important features for Trojan nodes}
Figure~\ref{fig:explainability_one} provides a comprehensive illustration of the feature scores conducted using XAI for detecting Trojan nodes. The analysis spans across two distinct benchmarks: s35932\_t200 and s38417\_t200. Each plot represents the top $n=10$ features ranked by their contribution to the model's decision-making process. The aim is to showcase what features are important for the Trojan nodes. $G1$, $G2$ represent gates in the subgraph, with numerical labels denoting their order and values next to them indicate the logic gate type when structural features are gathered using BFS. $Adj-23$ indicates adjacency connections between $G2$ and $G3$. Observation from s38417\_t200: The most influential feature is $G2\_AND$, followed by $G3\_AND$. Connection between $G2$, $G3$ (Adj-23) is significant. 

\subsection{Explainability: Enhanced Findings}

Fig.~\ref{fig:explainability_two} shows the feature distribution analysis which highlights the model's decision-making process for Trojan and non-Trojan nodes (see Fig.~\ref{fig:explainability_two}A) as well as aids in improving its classification accuracy (see Fig.~\ref{fig:explainability_two}B \& Table~\ref{tab:sail-ht_main}). A clear distinction is observed, where Trojan nodes exhibit significantly higher feature values compared to non-Trojan nodes. This sharp difference between the feature scores allows the model to effectively differentiate Trojan nodes from non-Trojan nodes. Fig.~\ref{fig:explainability_two}B delves into finding false negatives within the classification from non-Trojan nodes. In this case, certain non-Trojan nodes show unexpectedly high feature values, almost similar to those of Trojan nodes. Finally, such instances are reclassified as true positives (non-Trojan into Trojan).  
\subsection{Generating Human-Readable Rules}
 The $Captum$-$Explainer$ algorithm helps creating rules from model's decision process. In s35932\_t200 benchmark, the gates $G1$, $G2$, $G3$, $G5$ all are AND gates (Fig.~\ref{fig:explainability_one}) which significantly influences the model's prediction toward identifying a Trojan node. This rule along with other benchmarks' feature scores are translated into human-readable rules in Table~\ref{table:rules}. Additionally, the table highlights two common rules that are applicable across all benchmarks. We deduce that the presence of an AND gate in the local neighborhood plays a pivotal role in steering the prediction toward detecting a Trojan. 











\section{Conclusion}
Detecting malicious modifications in digital designs is crucial for ensuring trust and security of modern electronics driving the recent advances in Artificial Intelligence. State-of-the-art hardware Trojans detection solutions suffer from scalability concerns, lack detection precision/stability, and can be a victim of AI hallucinations. To mitigate these concerns, we propose \name~that utilizes Jumping Knowledge mechanism to improve performance and an explainability-guided dynamic post-processing module for minimizing AI hallucinations. \name~outperformed all SOTA Trojan detection frameworks across a large set of benchmarks. Future works will extend \name~for detecting other threats (e.g. side-channel leakage, fault injection vulnerability).        

% \section{Acknowledgment}
% This material is based upon work supported by the National Science Foundation (NSF) under Grant No. 2350363 and Grant No. 2316399.
% \clearpage

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,sail-ht}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}






