\section{Conclusion and Future Directions}
In this paper, we propose a comprehensive benchmark NumericBench   to evaluate the six  fundamental numerical  abilities of LLMs, including number recognition, arithmetic operations, contextual retrieval, comparison, summary, and logical reasoning. 
Our experiments reveal significant gaps in LLMs' numerical reasoning, as even state-of-the-art models like GPT-4 and DeepSeek struggle with simple arithmetic, number retrieval, and multi-step reasoning. 
These shortcomings are from tokenization issues, training paradigms, and architectural limitations, highlighting the need for more numerically-aware modeling approaches.

To address these gaps, there are several future directions worth exploring. Firstly,  numerically-aware tokenizers can be developed to treat numbers as continuous magnitudes, which fundamentally enables large language models to better understand numerical concepts.
Secondly, instead of the next-token prediction objective,  pretraining objectives specifically tailored to numerical reasoning can be designed. 
This could help models become more adept at solving numerical problems.
Thirdly, incorporating structured numerical datasets can enhance real-world applicability by grounding models in more accurate and practical numerical contexts.
Lastly, research into suitable positional embeddings and hybrid symbolic-numeric model architectures for numeric data is promising to improve the numerical abilities of LLMs.
Together, these advancements have the potential to bridge the gap between large language models' linguistic and numerical reasoning capabilities.

