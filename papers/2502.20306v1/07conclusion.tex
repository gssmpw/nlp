\section{Conclusion}
\label{sec:conclusion}
In this paper, we present \name, the first approach to defend gaze estimation models against backdoor attacks. We identify the unique characteristics of backdoored gaze estimation models, based on which we introduce a novel suite of techniques to reverse engineer the trigger function for backdoored gaze estimation models without the need to enumerate all the outputs. Our comprehensive experiments in both digital and physical worlds show that \name is consistently effective in defending gaze estimation models against six backdoor attacks that are triggered by input-aware patterns, input-independent patterns, and physical objects. We also adapt seven state-of-the-art classification defenses, showing that they are ineffective for gaze estimation, while {\name} consistently outperforms them. 