% ---------------------------------------------------------------------------
% Author guideline and sample document for EG publication using LaTeX2e input
% D.Fellner, v1.20, Jan 18, 2023

\documentclass{egpubl}
\usepackage{eg2025}
 % For creating the colored boxes

% --- for  Annual CONFERENCE
% \ConferenceSubmission   % uncomment for Conference submission
\ConferencePaper        % uncomment for (final) Conference Paper
% \STAR                   % uncomment for STAR contribution
% \Tutorial               % uncomment for Tutorial contribution
% \ShortPresentation      % uncomment for (final) Short Conference Presentation
% \Areas                  % uncomment for Areas contribution
% \Education              % uncomment for Education contribution
% \Poster                 % uncomment for Poster contribution
% \DC                     % uncomment for Doctoral Consortium
%
% --- for  CGF Journal
% \JournalSubmission    % uncomment for submission to Computer Graphics Forum
% \JournalPaper         % uncomment for final version of Journal Paper
%
% --- for  CGF Journal: special issue
% \SpecialIssueSubmission    % uncomment for submission to , special issue
% \SpecialIssuePaper         % uncomment for final version of Computer Graphics Forum, special issue
%                          % EuroVis, SGP, Rendering, PG
% --- for  EG Workshop Proceedings
% \WsSubmission      % uncomment for submission to EG Workshop
% \WsPaper           % uncomment for final version of EG Workshop contribution
% \WsSubmissionJoint % for joint events, for example ICAT-EGVE
% \WsPaperJoint      % for joint events, for example ICAT-EGVE
% \WsPoster          % uncomment for Poster contribution
% \WsShortPaper      % uncomment for Short Paper contribution
%  \WsWiP     % uncomment for Work in Progress contribution
% \Expressive        % for SBIM, CAe, NPAR
% \DigitalHeritagePaper
% \PaperL2P          % for events EG only asks for License to Publish

% --- for EuroVis 
% for full papers use \SpecialIssuePaper
% \STAREurovis   % for EuroVis additional material 
% \EuroVisPoster % for EuroVis additional material 
% \EuroVisShort  % for EuroVis additional material
% \MedicalPrize  % uncomment for Medical Prize (Dirk Bartz) contribution, since 2021 part of EuroVis

% Licences: for CGF Journal (EG conf. full papers and STARs, EuroVis conf. full papers and STARs, SR, SGP, PG)
% please choose the correct license
%\CGFStandardLicense
\CGFccby
%\CGFccbync
%\CGFccbyncnd

% !! *please* don't change anything above
% !! unless you REALLY know what you are doing
% ------------------------------------------------------------------------
\usepackage[T1]{fontenc}
\usepackage{dfadobe}  

% ---------------------------
%\biberVersion
\BibtexOrBiblatex
%\usepackage[backend=biber,bibstyle=EG,citestyle=alphabetic,backref=true]{biblatex} 
%\addbibresource{egbibsample.bib}
% ---------------------------  
\electronicVersion
\PrintedOrElectronic
% for including postscript figures
% mind: package option 'draft' will replace PS figure by a filename within a frame
\ifpdf \usepackage[pdftex]{graphicx} \pdfcompresslevel=9
\else \usepackage[dvips]{graphicx} \fi

\usepackage{cite}  % comment out for biblatex with backend=biber
\usepackage{tcolorbox}
\usepackage{colortbl} % For coloring table cells
\usepackage{xcolor}   % For defining custom colors
\usepackage{tabularx} % Add this in the preamble
\usepackage{egweblnk} 
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{gensymb}
\usepackage{overpic}
\usepackage{longtable}
\usepackage{array}
\usepackage{tikz}
\usetikzlibrary{arrows.meta}
\usepackage{graphicx}
\usepackage{bm}
\usepackage[normalem]{ulem}

\captionsetup{labelfont=bf,textfont=it}

% end of prologue

\newcommand{\revision}[1]{#1}
\newcommand{\revGD}[1]{#1}


\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\tAbs}[1]{| #1 |}
\newcommand{\G}{\ensuremath{\mathcal{G}}}
\newcommand{\Dim}{\ensuremath{\mathcal{D}}}
\newcommand{\vr}[1]{\ensuremath{\bm{#1}}}
\newcommand{\mat}[1]{\ensuremath{\bm{#1}}}
\newcommand*\diff{\mathop{}\!\mathrm{d}}
% \newcommand{\colvecXYZ}{%
%   \begin{pmatrix}
%   x \\
%   y \\
%   z
%   \end{pmatrix}
% }
% \newcommand{\colvecXY}{%
%   \begin{pmatrix}
%   x \\
%   y
%   \end{pmatrix}
% }
\newcommand{\colvecXYZ}{(x, y, z)^T}
\newcommand{\colvecXY}{(x, y)^T}

\newcommand{\avec}[0]{\ensuremath{\vr{a}}}
\newcommand{\bvec}[0]{\ensuremath{\vr{b}}}
\newcommand{\xvec}[0]{\ensuremath{\vr{x}}}
\newcommand{\yvec}[0]{\ensuremath{\vr{y}}}
\newcommand{\zvec}[0]{\ensuremath{\vr{z}}}
\newcommand{\ray}[0]{\ensuremath{\mathcal{R}}}
\newcommand{\pixel}[0]{\ensuremath{\vr{p}}}

\newcommand{\Ctns}[0]{\ensuremath{\tr{C}}}
\newcommand{\Gammatns}[0]{\ensuremath{\tr{\Gamma}}}


% \newcommand{\killed}[1]{\sout{#1}}
%\newcommand{\killed}[1]{}
% ---------------------------------------------------------------------

\title[Does 3D Gaussian Splatting Need Accurate Volumetric Rendering?]{Does 3D Gaussian Splatting Need Accurate Volumetric Rendering?}
%%\title[Harmonizing 3D Gaussian Splatting with Volume Rendering]%
%%{Harmonizing 3D Gaussian Splatting with Volume Rendering}

% for anonymous conference submission please enter your SUBMISSION ID
% \author[Anonymous Authors]
% {\parbox{\textwidth}{\centering paper1067
	% }
% }
% instead of the author's name (and leave the affiliation blank) !!
% for final version: please provide your *own* ORCID in the brackets following \orcid; see https://orcid.org/ for more details.
\author[A. Celarek, G. Kopanas, G. Drettakis, M. Wimmer, B. Kerbl]
{\parbox{\textwidth}{\centering A. Celarek$^{1}$, G. Kopanas$^{2, 3, 4}$\orcid{0009-0002-5829-2192}, G. Drettakis$^{3, 4}$\orcid{0000-0002-9254-4819}, M. Wimmer$^{1}$\orcid{0000-0002-9370-2663} and B. Kerbl$^{1}$\orcid{0000-0002-5168-8648}
				%        S. Spencer$^2$\thanks{Chairman Siggraph Publications Board}
			}
		\\
		% For Computer Graphics Forum: Please use the abbreviation of your first name.
		{\parbox{\textwidth}{\centering $^1$TU Wien, Austria, $^2$Google, United Kingdom, $^3$Inria, France, $^4$Université Côte d'Azur, France
						%        $^2$ Another Department to illustrate the use in /papers from authors
						%             with different affiliations
					}
			}
	}
% ------------------------------------------------------------------------

% if the Editors-in-Chief have given you the data, you may uncomment
% the following five lines and insert it here
%
% \volume{36}   % the volume in which the issue will be published;
% \issue{1}     % the issue number of the publication
% \pStartPage{1}      % set starting page


%-------------------------------------------------------------------------
\begin{document}
	
\teaser{
\begin{overpic}[width=\linewidth]{figures/teaser}
\put(18,24){\Large \textbf{4k Gaussians}}
\put(4,2){\large 3D Gaussian Splatting}
\put(33,2){\large Ray Marching}
\put(66,24){\Large \textbf{100k Gaussians}}
\put(54,2){\large 3D Gaussian Splatting}
\put(83,2){\large Ray Marching}
\end{overpic}
 %\includegraphics[]{figures/teaser}
 %\centering
  \caption{\textsc{Lego} scene from the NeRF-synthetic dataset. %From left to right: 
  \textbf{Left}: 4k Gaussians, rendered with 3D Gaussian Splatting and with extinction-based volume ray marching. \textbf{Right}: 100k Gaussians with the same two techniques. While the more principled ray-marching technique yields superior quality for fewer Gaussians, this benefit vanishes in qualitative and quantitative assessment when increasing their number. }
\label{fig:teaser}
}
	
\maketitle
%-------------------------------------------------------------------------
\begin{abstract}
Since its introduction, 3D Gaussian Splatting (3DGS) has become an important reference method for learning 3D representations of a captured scene, allowing real-time novel-view synthesis with high visual quality and fast training times.  Neural Radiance Fields (NeRFs), which preceded 3DGS, are based on a principled ray-marching approach for volumetric rendering. In contrast, while sharing a similar image formation model with NeRF, 3DGS uses a hybrid rendering solution that builds on the strengths of volume rendering and primitive rasterization. A crucial benefit of 3DGS is its performance, achieved through a set of approximations, in many cases with respect to volumetric rendering theory. A naturally arising question is whether replacing these approximations with more principled volumetric rendering solutions can improve the quality of 3DGS.
In this paper, we present an in-depth analysis of the various approximations and assumptions used by the original 3DGS solution. We demonstrate that, while more accurate volumetric rendering can help for low numbers of primitives, the power of efficient optimization and the large number of Gaussians allows 3DGS to outperform volumetric rendering despite its approximations. 

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10010147.10010371.10010382.10010385</concept_id>
       <concept_desc>Computing methodologies~Image-based rendering</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010147.10010371.10010396.10010401</concept_id>
       <concept_desc>Computing methodologies~Volumetric models</concept_desc>
       <concept_significance>400</concept_significance>
       </concept>
   <concept>
       <concept_id>10010147.10010371.10010372.10010373</concept_id>
       <concept_desc>Computing methodologies~Rasterization</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
   <concept>
       <concept_id>10010147.10010371.10010372.10010374</concept_id>
       <concept_desc>Computing methodologies~Ray tracing</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Image-based rendering}
\ccsdesc[400]{Computing methodologies~Volumetric models}
\ccsdesc[300]{Computing methodologies~Rasterization}
\ccsdesc[300]{Computing methodologies~Ray tracing}


\printccsdesc   
\end{abstract}  
%-------------------------------------------------------------------------
\section{Introduction}

Neural Radiance Fields (NeRFs)~\cite{mildenhall2020nerf,barron2022mipnerf360} revolutionized novel-view synthesis by introducing a differentiable rendering optimization based on \emph{principled} volumetric ray marching. \revision{This common volume rendering formulation is inspired by physical principles (although it uses a simplified model as an approximation of real, physics-based behavior)}. 
Key to \revision{NeRF's} success was the representation of scene geometry as a continuous, differentiable volume of \emph{optical density}.
% making optimization much easier, and enabling impressive visual quality of the reconstructions.
However, the volumetric ray marcher and neural network architecture made rendering and training excessively slow.
% Spatial data structures, hash-grids, and other improvements~\cite{yu2021plenoctrees,mueller2022instant} greatly accelerated training, but at the cost of reduced quality.
% While complex multi-step combinations of these methods have recently accelerated NeRF rendering~\cite{MERF,SMERF}, underlying training times remain high.
Several methods have been proposed to enhance performance \cite{yu2021plenoctrees, mueller2022instant, MERF, SMERF}, but these improvements often involve trade-offs, such as reduced visual quality.

3D Gaussian Splatting (3DGS)~\cite{kerbl3Dgaussians} uses a \emph{hybrid, primitive-based} rendering method.
% It exploits volumetric rendering to maintain the ``soft'' component that facilitates optimization for 3D reconstruction, giving it the same image formation model as NeRF, but also builds on point-based rasterization methods for extremely fast training and rendering.
It leverages volumetric rendering principles to preserve the differentiable component and aligns its image formation model with that of NeRF, which aids in optimizing 3D reconstruction.
Furthermore, it employs point-based rasterization methods for both training and rendering, significantly reducing the computational demands relative to NeRF.
However, in contrast to NeRF, \revision{3DGS learns an \emph{opacity} value \revision{for each Gaussian primitive} that it uses for fast alpha blending.
%This learned opacity allows geometry to smoothly fade in and out during scene optimization.
%As we discuss below, 3DGS 
In fact, 3DGS significantly deviates from volume rendering theory}, making many simplifying assumptions and approximations compared to more principled approaches to achieve its fast computation.
Thus, a natural question to ask is: Can the visual fidelity of 3DGS improve if we remove these approximations and use principled volume rendering solutions instead?
In this paper, we perform an in-depth analysis of 3DGS to answer this question.

% We start by analyzing and clarifying the different approximations and assumptions of 3DGS.
% We clarify the difference between the learned opacity value in 3DGS and the standard optical density used in NeRF and volumetric rendering in general.
We explicitly clarify the difference between the learned opacity value in 3DGS and the extinction function used in volumetric rendering (extinction is referred to as ``density'' in the NeRF~\cite{mildenhall2020nerf} literature).
To illustrate this difference and to allow further analysis, we introduce an extinction-based splatting solution.
% We investigate the impact of using opacity on 3DGS-style optimization and notably study the effect of the number of Gaussian primitives used.
% Our experiments show that for small numbers of primitives, the opacity-based splatting solutions perform worse than density splatting.
Our experiments show that for small numbers of primitives, the extinction-based solution performs better than opacity-based splatting.
However, this is reversed with more primitives, where opacity splatting performs best.
As we will analyze further, as Gaussians grow in number, rendering them with 3DGS becomes equally expressive to volumetric rendering.

One of the reasons 3DGS is so fast is its approach to resolving visibility, which is done via a single global sorting step.
This again is an approximation, since Gaussians are sorted based only on their centers.
This results in problematic popping, which has been identified in previous work~\cite{radl2024stopthepop}.
% In addition, the spatial overlap of Gaussians is ignored, which affects the computation of correct attenuation of light in conventional volumetric rendering.
In addition, spatial overlap of Gaussians is not handled, essentially ignoring parts of the conventional volumetric rendering integral.
In order to study the impact of this approximation, we implemented a ray-marching algorithm on 3D Gaussians.
% We show that this approximation has negligible impact, especially with a large number of Gaussians.
We show that these approximations have negligible impact on still images, especially with a large number of Gaussians.

Several other approximations are made by 3DGS: in particular, self-attenuation is not treated correctly, and a Gaussian's projected shape in screen space is approximate~\cite{huang2024erroranalysis3dgaussian}. We show that these also have little impact on the effectiveness of 3DGS.
% For all approximations, having a smooth energy landscape for optimization appears to be much more important than the accuracy of any volumetric rendering component.

\noindent
To summarize, in this paper, we systematically analyze and assess the approximations made in 3DGS. Specifically:

\begin{itemize}
	\item We introduce a mathematical framework that allows us to clarify the differences between 3DGS and accurate volumetric rendering (i.e., opacity \emph{vs.\ }extinction-based rendering) 
   \item We introduce extinction-based splatting and ray-marching algorithms for Gaussian primitives to analyze this difference. In this context, we also provide a closed-form solution for splatting self-attenuated Gaussians.
	\item Our analysis shows that opacity-based splatting results in lower error compared to extinction-based methods given a sufficiently high number of primitives.
    \item We also show that for a low number of Gaussians, correct overlap resolution and extinction-based rendering improves image quality, while correct sorting does not affect results as much.
	% \item We investigate other approximations of 3DGS compared to volumetric rendering, and show that they are absorbed by the optimization and do not \BKmodif{significantly} affect the result.
%\sout{   \item \AC{As a side product of our analysis, we provide a closed-form solution for splatting self-attenuated Gaussians.}}
\end{itemize}

%Overall, the analysis presented in this paper clarifies 
%where 3DGS stands compared to accurate volumetric rendering, 
%the relationship of 3DGS (and its approximations) to accurate volumetric rendering.
Overall, this work fills an important gap in the understanding of 3DGS as a rendering technique 
and provides an in-depth analysis of how the method can achieve quality rivaling the state of the art, despite several simplifying assumptions and approximations.


%Differentiable volume rendering has become an essential building block for novel-view synthesis and 3D reconstruction. 
%The continuous framework in which volume rendering is defined allows regressing volumetric 3D representations whose rendered appearance matches target input images.
%\emph{Neural Radiance Fields (NeRFs)} \todo{CITE} and \emph{3D Gaussian Splatting for Real-Time Radiance Field Rendering (3DGS)}\cite{kerbl3Dgaussians} are both based on this principle: they use a differentiable volumetric rendering routine to integrate the intensity along each pixel's view ray. 
%The scene is then learned by minimizing the photometric loss between the integrated result and the target images.
%Given the intractability of exhaustive integration along view rays through a volumetric scene, both methods include design choices that trade compute time for rendering accuracy.
%NeRF---an image-order method---trains by using guided, stochastic sampling to compute a numerical solution of the volumetric rendering Equation \ref{eq:volumetric_integration}.
%3DGS---an object-order approach---does not rely on sampling; however, it uses several approximations to accelerate image formation. 
%While some of them are inherited from elliptical weighted average (EWA) splatting (\reftodo{Zwicker}) and have clear implications, others are unique to the 3DGS method.
%
%Although these approximations provide significant performance benefits that enable real-time inference, they are also the cause of several issues. For example, they create obvious popping artifacts, which are particularly noticeable when the camera is moving and the number of Gaussian primitives is low. 
%Other artifacts are less obvious, requiring a high degree of familiarity with the method and scene to identify them. 
%Hence, it remains an open question whether 3DGS falls short of the quality that a principled, exact volume rendering method can achieve, and if so, by how much.
%Some of these design choices also have consequences for the portability of 3DGS: while it is tempting to interpret a trained set of Gaussians as mixtures of density, their integration via volume rendering yields visual results that differ significantly from the splatted renderings.
%This is due to the opacity-based representation of 3DGS, which demands its own rendering logic and is incompatible with most established volumetric light transport simulations.
%%Attempts to render them as a Gaussian mixture necessarily leads to significant visual differences.
%%
%%EWA volume splatting trades rendering error (bias) against compute time.
%%Looking closer at the math behind 3DGS we see, that it does not follow the exact formulation of EWA volume splatting.
%
%
%%As the 3DGS authors show, their approach leads to a stable and high quality algorithm for novel-view synthesis.
%%In this paper, we investigate the difference between these two formulations and show that the opacity based formulation has better learning results.
%%Additionally, we look at the impact on novel-view synthesis by the approximations used in EWA volume splatting method as proposed by \reftodo{EWA Volume splatting}.
%
%To address these issues, this paper provides a detailed analysis of the approximations used in 3DGS.
%Based on the underlying rendering theory and associated previous work, we showcase how the method deviates from principled volume integration.
%We empirically assess the impact of these approximations: to ablate their effect, we derive and prototype multiple 3D Gaussian rendering variants, including a ray marching-based approach. Doing so enables us to develop a deep understanding and draw conclusions about the strengths, weaknesses, and applicability of 3DGS.
%The authors of 3DGS argue that most negative side effects of their approximations vanish or become negligible as the number of Gaussians (i.e., the model size) increases, leading to densely packed primitives with small diameters and opacities. We investigate this claim in a detailed evaluation, comparing several Gaussian renderer variants with different integration policies from principled to approximate.
%
%Finally, our insights allow us to formalize a new splatting-based optimization routine that inherits the performance benefits of the original method but ensures a consistent appearance when rendered with conventional volume integration.
%Hence, our work provides an important first step toward making 3DGS models directly usable in sophisticated light transport simulations, such as state-of-the-art production renderers.
%%
	

\section{Related Work}
\begin{comment}
Volume rendering is concerned about how light scatters in participating media, e.g. clouds, smoke, but also wax and skin / flesh.
Such media can absorb, create, and scatter photons.
This is described by the volumetric rendering integral, and volumetric path tracers are capable of computing the solution to such integrals.
\reftodo{some vol pt refs}
Often, scattering can be discarded as the full gamut of effects is not necessary.
This results in the somewhat simplified Equation \ref{eq:volumetric_integration}.
\reftodo{simplified, used in vis}

NERFs take Equation \ref{eq:volumetric_integration}, a differentiable rendering algorithm based on ray marching, a data model based on multi-layer perceptrons (MLPs), and learn their weights by means of backpropagation through the ray marcher and gradient decent. \reftodo{..}

EWA splatting, introduced by \reftodo{zwicker et. al} is a method to compute an approximation of Equation \ref{eq:volumetric_integration}.
To do so, the volumetric data is stored in Gaussian mixtures, which are then sorted and projected to the screen.

3D Gaussian Splatting for Real-Time Radiance Field Rendering (3DGS) basically took the EWA splatting algorithm, simplified it a bit more (by using the opacity formulation), made it even faster, and made it possible to learn Gaussian mixtures by backpropagation and gradient decent.

Stop the pop (STP) is an improvement on 3DGS, where they implemented a per-pixel sorting step and hierarchical culling to make it tracktable \todo{is that correct? extend as i know really little about it}.
\end{comment}
Volume rendering equations and theory~\cite{Max95, Novak18Course} were developed to explain and model how light scatters in participating media, e.g. clouds, smoke, but also wax and skin/flesh. Such media can emit, absorb, and scatter photons. This is described by the volumetric rendering integral, and volumetric path tracers are capable of computing the solution to such integrals.
This theory proved useful for modern image-based 3D reconstruction methods. 

In the context of novel-view synthesis, NeRF~\cite{mildenhall2020nerf} uses a simplified volume rendering model that only considers emission and absorption, ignoring scattering. %to a simple emission-absorption volume by ignoring scattering.
For every position, density and directional outgoing radiance are stored in an MLP. This allows recovering
a 3D volumetric scene representation for a set of unstructured images using Stochastic Gradient Descent (SGD). For every iteration of SGD, NeRF renders an image via ray marching, sampling an MLP along the ray, and computing the volumetric integral using quadrature. 
Since this process is differentiable, the weights of the MLP receive gradients, continuously pushing image formation closer to the ground truth. 
% This forward rendering model is differentiable, which allows %\GDmodif{the computation of}
% \AC{computing } % sounds more direct to adam, and, if changing to 'the computation of', then 'upodte the weights' should be also changed, and i wouldn't even know the correct grammar there
% the gradients and updating the weights of the MLP such that the rendered image is closer to the ground-truth images. 
%Doing this, for enough iterations and enough images, allows the optimization of a 3D representation that allows faithful rendering of the 3D scene from any novel view.

Ray marching paired with quadrature provides an accurate solution of the volume rendering integral, but historically, rasterization is faster, albeit less accurate. Elliptical Weighted Average (EWA) splatting~\cite{ewa_splatting} is an efficient algorithm for rendering volumes through rasterization. It is based on Heckbert's thesis~\cite{heckbert1989fundamentals} and traditional signal processing. EWA volume splatting considers discrete samples of density and color and reconstructs the underlying continuous signal in screen space. In practice, the volume is represented with Gaussian primitives that are splatted and alpha-blended on screen. To allow for fast rasterization, a series of assumptions and simplifications are made: 1) Gaussian primitives do not overlap in 3D, 2) self-attenuation---i.e., the reduction of light intensity along a ray inside a primitive---is ignored, 3) the perspective projection is linearized and approximated by a first-order Taylor expansion, and 4) $e^{-x}$ is approximated by the faster $1-x$.
%Note also that 3DGS builds on a wealth of point-based rendering literature~\cite{lassner2021pulsar,wiles2020synsin,zhang2022differentiable,kopanas2021point, Yifan:DSS:2019}.
%\GK{Let's move this GD modification further up where we talk about EWA and maybe add some traditional point based graphics papers?}. GD: Done

3D Gaussian Splatting (3DGS)~\cite{kerbl3Dgaussians} is a fast and high-quality alternative for NeRF.
3DGS builds on EWA Volume Splatting and several other works on point-based rendering~\cite{lassner2021pulsar,wiles2020synsin,zhang2022differentiable,kopanas2021point, Yifan:DSS:2019}, while simplifying the formulation even further.
% These simplifications proved significantly important for efficient back-propagation through SGD. # adam doesn't think so. it wasn't that hard to implement the gradient for self attenuation and it's efficient (computationally)
Most notably, 3DGS significantly simplifies the handling of transparency (respectively its inverse, opacity). \revision{Instead of computing transparency by integrating extinction along a finite segment of a ray according to the volume rendering equation, 3DGS just assigns one single opacity value per primitive. This value is not related to an integrated extinction, as we will show in more detail in Sec.~\ref{sec:anal_opa_vs_dens}. }
%Most notably, 3DGS replaces extinction in the formulation of EWA with opacity:
%Instead of integrating extinction along a ray to compute opacity -- as shown in Sec.~\ref{sec:anal_opa_vs_dens} -- 3DGS models opacity as a global property of the primitives.
The 3DGS opacity value therefore has no \revision{direct equivalent in volume rendering theory}, but it allows the splatted primitives to have a constant transparency, no matter the viewing direction, and allows for optimizing a well-behaved and bounded scalar.
The subtle difference between opacity and extinction is often overlooked in subsequent work, or the quantities are even conflated~\cite{guedon2023sugar,bolanos2024gaussian,lee2024gscore,huang2023photo}.
In this paper, we will analyze the differences and the impact of these approximations and seek to find their importance in terms of final quality for forward rendering, as well as the full optimization process.

A wealth of literature has appeared following up on the original 3DGS paper:
In line with our own work, Mip-Splatting~\cite{yu2023mip} identifies an approximation for convolution used in 3DGS and introduces a principled pre-filtering of the underlying signal to provide a correct solution for antialiasing, allowing consistent multi-scale and multi-resolution training.
Concurrent work has explored various methods to leverage benefits of ray-Gaussian intersection.
These approaches typically involve creating shells around Gaussian functions and employing conventional ray-tracing techniques to query the Gaussians.
Condor et al.\ and Zhou et al.\ concentrate on principled volumetric path tracing; however, the first does not demonstrate competitive reconstruction quality \cite{condor2024dontsplatgaussiansvolumetric}, while the latter addresses geometry reconstruction rather than novel-view synthesis\cite{zhou2024unified}.
Moenne-Loccoz et al. implement a range of ray-tracing effects, including motion blur and refraction, and they utilize ray tracing for scene composition \cite{3dgrt2024}.
Their method identifies the point of highest density, but does not incorporate volumetric marching.
Their reconstruction performance is comparable to that of 3DGS.
Finally, Blanc et al.\ use a ray-marching method that traverses the scene with a fixed step size.
However, rather than enabling direct comparison and analysis, their work focuses on improving 3DGS reconstruction quality, which they achieve by complementing the view-dependent representation with spherical Gaussians \cite{blanc2024raygaussvolumetricgaussianbasedray}.
%Notably, none of the existing studies provide a comprehensive analysis of the image formation model.
% \cite{zhou2024unifiedgaussianprimitivesscene} #Unified Gaussian Primitives for Scene Representation and Rendering: I don't think this one should be included just because it uses Gaussians. They implemented a full blown path tracer on CPU and don't deal in learning a model from photos. it's very cool, but a different direction.
For further analysis of the research that succeeds 3DGS, we redirect the readers to the following surveys\cite{chen2024survey,fei20243d,wu2024recent,dalal2024gaussian}.

\revision{
\section{Overview}

Our goal is to analyze the various approximations of 3DGS and their effect on visual quality. The first step in this analysis is a detailed mathematical framework (Sec.~\ref{sec:math}), starting from first principles of volumetric rendering, and then presenting a consistent notation for image formation methods based on Gaussian primitives. This presentation clarifies the mathematical properties of 3DGS and EWA (on which it is based), clearly presenting some of the approximations these techniques use. We then provide our in-depth assessment of 3DGS representations and approximations (Sec.~\ref{sec:analysis}). We first perform a detailed mathematical analysis. Importantly, we then introduce a set of algorithms, progressively replacing each of the identified approximations, allowing us to experimentally evaluate their respective effect on the visual quality of Gaussian-based rendering. Their respective implementations (Sec.~\ref{sec:impl}) enable us to run an extensive experimental analysis (Sec.~\ref{sec:experiments}), leading to several significant insights into which approximations matter, and under which conditions.
}
% Here is bold with $\mat{\Sigma} \boldsymbol{\mat{\Sigma}}\bm{\mat{\Sigma}} \mathcal{R} \boldsymbol{\mathcal{R}}\bm{\mathcal{R}}\mathcal{\bm{R}}\mathcal{\boldsymbol{R}}\boldsymbol{R} x \boldsymbol{x}\bm{x} $
%\AC{\section{Background (Version B)}}
% \section{Mathematical Framework for Analysis}
\section{Mathematical Framework}
\label{sec:math}

In the following, we revisit the necessary theory and provide the mathematical tools required for our in-depth analysis. 
We first recall the classic volumetric rendering integral.
With this as a basis, we show how Gaussian functions can be used as a representation of extinction within this integral.
Finally, we make the connection to elliptical weighted average (EWA) splatting and 3DGS, which is required for the subsequent theoretical and experimental analysis.
It is important to note that the former models volumetric extinction,  which is also the case for NeRF methods~\cite{mildenhall2020nerf}. Our analysis is thus also relevant in understanding how 3DGS relates to NeRF.
\revision{A list of recurring symbols in our analysis is provided in Table \ref{tab:symbols}).}


\begin{table}[h]
\revision{
    \centering
    \renewcommand{\arraystretch}{1.2}
        \caption{\revision{List of commonly used symbols in this paper.}}
    \begin{tabularx}{\linewidth}{c X}
        \hline
        Symbol & Meaning \\
        \hline
        $I$ & Image function, parameterized by pixel $\vr{p}$\\
        $f$ & Extinction coefficient function\\
        $o$ & Opacity function (used in 3DGS)\\
        $\ray$ & Viewing ray, parameterized by distance $t$\\
        $c$ & Constant or view-dependent color\\
        %$\mathcal{N_D}$ & PDF of a $\mathcal{D}$-dimensional Normal distribution\\ 
        $\mathcal{G}^n_\mathcal{D}$ & Normalized $\mathcal{D}$-dimensional Gaussian function \\
        $\mathcal{G}^u_\mathcal{D}$ & Unnormalized $\mathcal{D}$-dimensional Gaussian function \\
        $\mu, \mu'$ & Mean and projected mean \\
        $\Sigma, \Sigma'$ & Covariance matrix and projected covariance matrix \\
        $a, a'$ & Amplitude and projected amplitude of unnormalized Gaussian function\\$\mathcal{I}_\mathcal{D}$ & Normalization factor for the exponential part of a $\mathcal{D}$-dimensional normalized Gaussian function\\
        $w$ & Weight (integral) of normalized Gaussian function\\
        $_i,_j$ & Subscripts to refer to the attributes of the $i$-th or $j$-th Gaussian in a mixture or along a viewing ray\\
        $\theta$ & Data term modeling a Gaussian's appearance\\
        \hline
    \end{tabularx}

    \label{tab:symbols}
    }
\end{table}

\subsection{The Volumetric Rendering Integral}
The integral for direct volume rendering with attenuation and source terms \revision{(Eq.\ 1 in \cite{max_et_al, Max95})} is given by:
\begin{align}
	\label{eq:volumetric_integration}
	I(\pixel) = \int_0^\infty c(\ray,t) f(\ray(t)) e^{-\int_0^t f(\ray(\tau)) \diff{\tau}} \diff{t},
\end{align}
where $\ray$ is the viewing ray going through pixel $\pixel$, parameterized by \revision{distance} $t$ \revision{along the ray} to obtain a three dimensional point on $\ray$ at that distance. \revision{Further, }$c$ is the function returning the (wavelength- and view-dependent) radiance at $\ray(t)$ in the direction of $\ray$, and $f$ is the function returning the extinction coefficient (or, for matter, particle density) at $\ray(t)$.
In this integral, $c(\ray, t) f(\ray(t))$ models the entire source (emission and in-scattering) and $e^{-\int_0^t f(\ray(\tau)) \diff{\tau}}$ the entire attenuation (absorption and out-scattering) of light.
This simplified model is also employed for the derivation of NeRF methodology \cite{mildenhall2020nerf}, where the extinction coefficient is referred to as \emph{density}.
It does not explicitly consider the scattering of light, which means that light refraction (e.g., through glass) is not modeled.
Notwithstanding the lack of this nuance, the formulation is powerful enough to describe such scattering implicitly, that is, by attenuating all light and sourcing appropriate new light through emission.
% This model, which is also employed for the derivation of NeRF methodology \cite{mildenhall2020nerf}, does not explicitly consider scattering of light.


\subsection{3D Gaussian Data Model}


\label{sec:gaussian_data_model}
Eq.~\ref{eq:volumetric_integration} does not assume a specific representation for extinction in the domain of integration.
The following specialize it for a \emph{Gaussian representation} of the extinction function, as is used by EWA splatting \cite{ewa_splatting}, 3D Gaussian splatting \cite{kerbl3Dgaussians}, and others. 
We first define $\Dim$-dimensional Gaussian functions. A familiar example is their use in the Gaussian (or \emph{normal}) \revision{distribution's PDF:
\begin{align}\label{eq:normal_dist}
	\mathcal{N}_\Dim(\vr{x};\vr{\vr{\mu}}, \mat{\Sigma}) = \frac{1}{\mathcal{I}_\Dim(\Sigma)} e^{-\frac{1}{2}(\vr{x}-\vr{\vr{\mu}})^T\mat{\Sigma}^{-1}(\vr{x}-\vr{\vr{\mu}})},
\end{align}
}
where 
\vr{x} is a point in $\mathbb{R}^{\Dim}$,
$\vr{\vr{\mu}}$ is the ${\Dim}$-dimensional position (mean), $\mat{\Sigma}$ the shape (covariance matrix), and \revision{$\mathcal{I}_\Dim(\mat{\Sigma})$} is the unbounded integral of the exponential part, ensuring that $\mathcal{N}_\Dim$ integrates to one:
\begin{align}
	\label{eq:exponential_integral}
    \revision{
	\mathcal{I}_\Dim(\mat{\Sigma}) = \int_{\mathbb{R}^\Dim} e^{-\frac{1}{2}(\vr{x}-\vr{\vr{\mu}})^T\mat{\Sigma}^{-1}(\vr{x}-\vr{\vr{\mu}})} \diff \xvec = \sqrt{(2\pi)^\Dim det(\mat{\Sigma})}.
    }
\end{align}

\paragraph*{Normalised Gaussian functions} are the basic building block of EWA splatting.
There, they are paired with an additional weight parameter $w$, which effectively models the \emph{total} capacity of the corresponding Gaussian to block and emit light:
\begin{align}\label{eq:gaussian_definition_normalised}
    \revision{
	\mathcal{G}^n_\Dim(\vr{x}, w, \vr{\mu}, \mat{\Sigma}) = w \mathcal{N}_\Dim(\vr{x}; \vr{\mu}, \mat{\Sigma}),
    }
\end{align}
Since $\mathcal{N}_\Dim$ integrates to 1, $w$ is equivalent to the unbounded integral of the full normalized Gaussian function:
% The normalisation of $\mathcal{N}_\Dim$ makes the unbounded integral of $\mathcal{G}^n$ independent of the shape $\mat{\Sigma}$:
\begin{align}
    \label{eq:total_gaussian_integral}
	\int_{\mathbb{R}^\Dim} \mathcal{G}^n_\Dim(\xvec, w, \vr{\mu}, \mat{\Sigma}) \diff \xvec = w.
\end{align}
% A consequence of the normalisation of $\mathcal{N}_\Dim$ is the independence of the integral from the shape $\mat{\Sigma}$.
% This makes the integration along an axis (orthographic projection) simple.
% For instance, integrating along the z axis of a 3D integral results in a 2D integral with the same weight:
% \begin{align}
% 	\mathcal{G}^n_2\left(\colvecXY, w, \vr{\mu}', \mat{\Sigma}'\right) = \int_{-\infty}^\infty \mathcal{G}^n_\Dim\left(\colvecXYZ, w, \vr{\mu}, \mat{\Sigma} \right) \diff z,
% \end{align}
% This normalised notation simplifies integration along an axis (projection) and convolution, as $w$ does not change, respectively the two weights are multiplied in the case of convolution. \BKmodif{Don't get this}
%If the Gaussian would represent particle density of gas or other matter, we could say that $w$ is the total \emph{mass} of matter. 



\paragraph*{Unnormalised Gaussian functions} are defined by
\begin{align}\label{eq:gaussian_definition_unnormalised}
\revision{\mathcal{G}^u_\Dim(\vr{x}, a, \vr{\mu}, \mat{\Sigma}) = a \mathcal{I}_\Dim(\mat{\Sigma})  \mathcal{N}_\Dim(\vr{x}; \vr{\mu}, \mat{\Sigma}),}
\end{align}
where $a$ is the amplitude, or value, at $\vr{\mu}$, and all other variables are the same as in the normalised case.
This representation is used in 3DGS, where $a$ equates to ``opacity'', i.e., the \emph{peak} capacity of a Gaussian to block/emit light \emph{at its center}. Its evaluation is easier compared to that of normalized Gaussians, since \revision{$\mathcal{I}_\Dim(\mat{\Sigma})$} and the normalisation factor in $\mathcal{N}_\Dim$ cancel each other out. %as the computation of the normalisation factor $\frac{1}{i_\Dim}$ can be avoided.
Note that it is always possible to convert between the normalised and unnormalised parameterization of a given Gaussian using
\begin{align}\label{eq:gaussian_definition_conversion}
\revision{
	a = \frac{w}{\mathcal{I}_\Dim(\mat{\Sigma})}.
    }
\end{align}
%If the Gaussians are assumed to represent particle density of matter, we could say that $a$ is the \emph{peak density}.

\paragraph*{Image formation:} 
%In the following, we denote
% \paragraph*{Gaussian mixtures} combine multiple Gaussian functions via summation. In the following, we denote % covers more than just gaussian mixtures
%normalised Gaussians with a shorthand $g_i(\vr{x}) = \mathcal{G}^n_3(\vr{x}, w_i, \vr{\mu}_i, \mat{\Sigma}_i)$ for a particular 3D Gaussian. 
To use Gaussian functions for volume rendering, the extinction function is modeled by a mixture of Gaussians:
\begin{align}
    \label{eq:gmm}
    \revision{
	f(\xvec) = \sum_{i=0}^N \mathcal{G}^n_3(\vr{x}, w_i, \vr{\mu}_i, \mat{\Sigma}_i).
    }
\end{align}
\revision{
Each Gaussian can be supplemented by a (learnable) function $c_i(\ray)$, which returns the radiance value for a given view ray $\ray$}.
In the case of 3DGS, the directional radiance is modeled with spherical harmonics, but other representations are possible as well. %We assume that radiance is constant along a ray for a particular Gaussian, and thus, 
Gaussians can serve as the basis for the radiance function \revision{on ray $\ray$ at $t$}:
%The $c_i$s are then weighted with the Gaussians to get the final radiance:
\revision{
\begin{align}
	c(\ray, t) = \sum_{i=0}^N c_i(\ray) \mathcal{G}^n_3(\vr{x}, w_i, \vr{\mu}_i, \mat{\Sigma}_i) .
\end{align}
}
\revision{Using the shortand 
$\mathcal{G}_3^n(\vr{x}, i) = \mathcal{G}^n_3(\vr{x}, w_i, \vr{\mu}_i, \mat{\Sigma}_i)$ for compactness, we can substitute extinction and radiance (color) functions into Eq.~\ref{eq:volumetric_integration} to arrive at a 3D Gaussian-based solution for volume rendering:
\begin{align}
    \label{eq:volumetric_integration_c}
	I(\pixel) = &\int_0^\infty \sum_{i=0}^N c_i(\ray)\mathcal{G}_3^n(\ray(t), i) e^{-\int_0^t \sum_{i=0}^N \mathcal{G}_3^n(\ray(t), i) \diff{\tau}} \diff{t} 
    %\\ \nonumber
     %         &+ c_b e^{-\int_0^\infty f_\mathcal{G}(\ray(\tau)) \diff{\tau}},
\end{align}
}

\subsection{EWA and 3D Gaussian Splatting}
\label{sec:bg_3dgs}
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/integ_v_splat.pdf}
    \caption{\revision{A setup with two Gaussian primitives (center). For each viewing ray, volumetric integration (top) considers the intersection with all primitives and evaluates their joint extinction at each point along the ray. In splatting (bottom), Gaussians are projected to flat, camera-facing disks. Each 2D disk provides an isolated contribution to the ray, which 3DGS blends in the order of projected means.}}
    \label{fig:splatting}
\end{figure}
Eq.~\ref{eq:volumetric_integration_c} represents a basic solution for volumetric integration of Gaussian mixtures along a ray.
However, the image formation models used in EWA and 3DGS are, at best, an approximation of this integral. 
The focus of our work is to clarify how EWA and 3DGS relate to volumetric integration and consider the \revision{implications of} algorithmic choices for approximations in the above integral.



To avoid the high cost of volume integration, both EWA and 3DGS simplify the rendering of 3D Gaussians by reducing them to 2D Gaussians that can be easily ``splatted''.
Intuitively, it seems desirable that the appearance of splatted 2D Gaussians matches the result of volumetrically rendering their 3D counterparts. 
With this perspective, we can consider how splatting-based approaches \revision{deviate from} Eq.~\ref{eq:volumetric_integration_c}:
\revision{First, Gaussians are assumed \emph{not to overlap}} and are sorted based on their means, front to back, by view-space depth of the 3D Gaussian position.
\emph{Within} a Gaussian, the color $c_i$ is uniform; view-dependent $c_i$ of 3DGS are evaluated w.r.t.\ the mean only. % GD: SH make it view dependent
Also \emph{within} a Gaussian, continuous accumulation of extinction and the corresponding effect on its appearance is not considered. %Assuming orthographic projection, t
\revision{Further ignoring perspective distortion, EWA exploits these simplifications to find the 2D extinction contribution function $f_i$ of Gaussian $i$ from its 3D definition \revision{(see Fig.~\ref{fig:splatting})}. This disk-like 2D function is found by projecting a 3D Gaussian along a view axis:}
\begin{align}
	\label{eq:gaussian2d_ewa}
    \revision{f_i(\vr{p}) = \mathcal{G}^n_2(\pixel, w_i, \vr{\mu}'_i, \mat{\Sigma}'_i) = \int_{-\infty}^\infty \mathcal{G}^n_3(\ray(t), w_i, \vr{\mu}_i, \mat{\Sigma}_i) \diff t,}
\end{align}
where $\vr{\mu}'$ and $\mat{\Sigma}'$ are projected 2D mean and covariance matrix, and normalised Gaussians are used.
% version a, abbreviated notation without differential and some functions called without parameter
%\BKmodif{
This corresponds to the marginal distribution of a normal distribution, which is again a normal distribution, thus we have
% \begin{align}
%     w = \int_{\mathbb{R}^2} w\mathcal{N}_2 = \int_{\mathbb{R}^2} G_i(\pixel) =\int_{\mathbb{R}^3} \mathcal{G}^n_3 =  
%     \int_{\mathbb{R}^3} w\mathcal{N}_3,
%     \label{eq:integra_of_normalised_2d3dgaussians_is_wl}
% \end{align} 
% version b, same equation fuller notation. it's still abbreviated as mu and sigma and in two cases w is missing
\begin{align}
\label{eq:integra_of_normalised_2d3dgaussians_is_wl}
     \int_{\mathbb{R}^3} w\mathcal{N}_3 (\xvec, \vr{\mu}, \mat{\Sigma}) \diff \xvec &= \int_{\mathbb{R}^3} \mathcal{G}^n_3 (\xvec, w, \vr{\mu}, \mat{\Sigma}) \diff \xvec
     \\ \nonumber = \int_{\mathbb{R}^2} w\mathcal{N}_2(\pixel, \vr{\mu}', \mat{\Sigma}') \diff \pixel &= \int_{\mathbb{R}^2} \mathcal{G}^n_2(\pixel, w, \vr{\mu}', \mat{\Sigma}') \diff \pixel = w,
\end{align}
i.e., $w$ is preserved across all projections of a 3D Gaussian.
Recall that the mixture of Gaussians for EWA defines an \emph{extinction function} that is the same quantity as the density learned by NeRF. 
%While the analysis here focuses on EWA splatting, the clarification of the distinction between density and ``opacity'' is useful in the context of NeRFs as well.}\AC{todo: they mention opacity only once by saying density is 'differential opacity'. I believe they didn't want to say extinction coefficient for some reason. saying that density is 'differential opacity' sounds dubious to me, because if i'm not wrong, that would mean, that integrated density gives opacity. however, opacity arises from exp(-integrated density). TL;DR: i think we should remove this clarification, but i'm not certain enough to do it.}


\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/ewa/ewa_plot.png}
    \caption{\revision{A flat 3D Gaussian (one scale dimension is 0), positioned in a slanted angle to the camera. Blue shows exact projection;
    %that is not a normal distribution any more in 2D, 
    notice the skewness between the top and bottom.
    %of the distribution.
    Red iso-curves show the affine approximation first used in EWA, a camera-facing disk.}}
    \label{fig:ewa-approximation}
\end{figure}

\revision{In contrast, 3DGS uses unnormalized Gaussians and preserves 2D \emph{amplitude} $a'$  (which they call "opacity") across all projections:}
\begin{align}
    \label{eq:gaussian2d_3dgs}
    \revision{
	o_i(\pixel) = \mathcal{G}^u_2(\pixel, a_i', \vr{\mu}'_i, \mat{\Sigma}'_i)
    }
\end{align}
We will shortly see that due to this convention, 3DGS does not allow for defining a corresponding 3D extinction (or density) function $\mathcal{G}_3$ in the established volume integration framework; in particular, we must \emph{add view-dependent factors} to consolidate the two.


\revision{The computation of $\Sigma'$ involves the transformation of the Gaussian from world-space coordinates to screen space. Gaussian distributions are closed under affine transformations, however, perspective projection is usually non-linear. To circumvent this, EWA and 3DGS approximate perspective transformation with its locally-affine counterpart (see Fig.~\ref{fig:ewa-approximation}), using first-order Taylor expansion:}
%While there is a direct solution for $\Sigma'$ in Eq.~\ref{eq:gaussian2d_ewa} and \ref{eq:gaussian2d_3dgs} for orthographic projections, it can only be approximated for perspective projections---a 3D Gaussian becomes a 2D Gaussian under orthographic, but not under perspective projection. The locally affine solution of $\mat{\Sigma}'$ under projection is computed as:
\begin{align}
	\mat{J} &= \begin{pmatrix}
		1 / \vr{\mu}_2 & 0 & -\vr{\mu}_{0}/\vr{\mu}^2_{2} \\
		0 & 1 / \vr{\mu}_{2} & -\vr{\mu}_{1}/\vr{\mu}^2_{2} \\
		\vr{\mu}_{0}/l & \vr{\mu}_{1}/l & \vr{\mu}_{2}/l \\
	\end{pmatrix}\nonumber\\
	\label{eq:splatting_transformation_of_covariance}
	\mat{\Sigma}' &= \mat{JW}\mat{\Sigma} \mat{W}^T\mat{J}^T,
\end{align}
where $\vr{\mu}$ is the Gaussian's position in camera space, $l=\lVert \vr{\mu} \rVert_2$ and $\mat{W}$ the transformation to camera space \revision{(Eq.\ 29 and 31 in \cite{ewa_splatting})}.

Finally, the attenuation term is approximated by the first-order Taylor expansion of $e^x$, which is $\approx 1-x$.
Applying all these approximations to Eq. \ref{eq:volumetric_integration_c} yields \revision{the image function (Eq.\ 3 in \cite{kerbl3Dgaussians})}:
\begin{equation}
	\label{eq:alphablend}
    \revision{
	I(\pixel) = \sum_{i=0}^N c_i(\ray) g_i(\pixel)\prod_{j=0}^{i - 1}(1-g_j(\pixel)) + c_b \prod_{i=0}^N(1-g_i(\pixel)),
    }
\end{equation}
% \GK{I THINK THERE IS AN ISSUE: $G_i$ has been defined (Eq 11) with normalized Gaussians. Here we are talking about 3DGS, so the equation above is incorrect, no?}
where %$I$ is the resulting image, $c_i$ is an evaluation of the spherical harmonics in the viewing direction, 
\revision{$c_b$ is the background color, $i$ iterates over Gaussians on ray $\ray$ going through $\vr{p}$, and $g_i$ is the $i$-th Gaussian's partial contribution, either extinction (Eq.~\ref{eq:gaussian2d_ewa}) for EWA, or opacity (Eq.~\ref{eq:gaussian2d_3dgs}) for 3DGS.}

%\todo{This paragraph feels a little out of place, where's the transition?}


\section{Analysis of 3DGS Representation and Approximations}
\label{sec:analysis}

Given the above mathematical framework, 
we now present a detailed analysis of splatting algorithms compared to accurate volumetric rendering and assess the representation and approximations.
In Sec.~\ref{sec:anal_opa_vs_dens}, we expand on the key difference between the EWA and 3DGS splatting image formation method, i.e., the use of 2D opacity instead of extinction-based values \revision{(see Fig.~\ref{fig:rendering_methods})}.




%\GD{I put the sentence back, this is the idea of "overview", ie explain why you are saying the things that follow}
%\revGD{Our goal is to experimentally evaluate the effect of the different approximations in 3DGS (some of which it shares with EWA). To do this, }
% \sout{We further \revision{aim to} }
% \revGD{define a set of}
\revision{We also aim} to experimentally evaluate the \revision{\emph{effect}} of the different approximations in 3DGS \revision{and EWA}. To do this, we define a set of algorithms that replace each specific approximation with the more principled volumetric rendering solution. We start this in
%To evaluate the significance of this difference, in 
Sec.~\ref{sec:ewabasedsplat}, where we adapt the 3DGS method to implement an extinction-based algorithm that uses splatting, making it more similar to EWA.
%Both 3DGS and EWA splatting ignore the effect of light attenuation \emph{within} a Gaussian (which we call self-attenuation) and approximate the attenuation term.
%Both 3DGS and EWA ignore light attenuation \emph{within} a Gaussian (which we call self-attenuation). 
In Sec.~\ref{sec:self_attenuation_and_exp}, we propose an extended version of extinction-based splatting that correctly accounts for light attenuation \emph{within} a Gaussian (self-attenuation).
%Finally, since 3DGS is a \emph{primitive-based} approach, like with other rasterization pipelines, its rules for visibility of primitives have a significant impact on the image formation model.
%3DGS inherently ignores primitive overlap along depth and coarsely resolves visibility with a single sample per primitive.
Sec.~\ref{sec:overlap_proj} then examines issues arising from 3DGS taking substantial liberties in resolving visibility during rendering, entirely ignoring Gaussian overlap, and using only a single depth value per Gaussian for ordering.
%and discuss how the depth sorting approximation used by 3DGS can be addressed.
To \revision{evaluate their impact in practice}, we introduce a differentiable ray marcher for 3D Gaussians that correctly handles per-pixel order and primitive overlap.

\subsection{A Unified Framework for Gaussian Extinction Functions}
\label{sec:anal_opa_vs_dens}
%\GD{See above}
%\revGD{
Our goal is to analyze the effect of the different choices made by traditional volumetric extinction-based EWA and ``opacity''-based 3DGS. To this end, we
%To do this, we need to 
%\revision{To enable a detailed comparison of the different splatting approaches, we}
provide a unified framework for computing Gaussian-based extinction functions across EWA and 3DGS. 
We introduce an abstract data term $\theta$, stored (and potentially learned) per Gaussian, from which its appearance is derived.
%\revision{We will provide derivations} for unnormalised Gaussian functions (Eq.~\ref{eq:gaussian_definition_unnormalised}) \revision{which are more convenient for rendering}.
% directly, since they are more efficient to evaluate in practice. % AC: the difference in performance is most likely not measurable 
To prepare the necessary foundation for evaluating \revision{the different approaches} in 3D (e.g., for ray marching) and 2D (e.g., for 2D splatting), we will focus on solutions for computing the 3D and 2D amplitude parameters $a$ and $a'$ of \revision{unnormalised} Gaussian functions $\mathcal{G}^u_3$ and $\mathcal{G}^u_2$\revision{, since they are more convenient for rendering}. %= \varphi(\theta)$ and $a' = \varphi'(\theta)$, where $\varphi$ / $\varphi'$ are defined by the data model, respectively the computation necessary to compute the 2D integral.



\begin{figure}[t]
	\centering
        \hspace*{\fill}
	\begin{subfigure}[t]{0.32\columnwidth}
		\includegraphics[width=\linewidth]{figures/fig2/rendering}
		\caption{Viewing Scenario}
	\end{subfigure}%
    	\hfill
	\begin{subfigure}[t]{0.32\columnwidth}
		\includegraphics[width=\linewidth]{figures/rendering_methods/density_splatter_exp_self_shadowing.png}
		\caption{EWA-based}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[t]{0.32\columnwidth}
		\includegraphics[width=\linewidth]{figures/rendering_methods/opacity_splatter.png}
		\caption{3DGS-based}
	\end{subfigure}%
	% \hfill
	% \begin{subfigure}[t]{0.21\textwidth}
	% 	\includegraphics[width=\linewidth]{figures/rendering_methods/density_splatter_1minusX_no_self_shadowing.png}
	% 	\caption{EWA-based splatting (OTS) w\textbackslash\ Taylor expansion \& clamping}
	% \end{subfigure}%
	%\hspace{1mm}
	%\begin{subfigure}[t]{0.24\textwidth}
	%\includegraphics[width=\linewidth]{figures/rendering_methods/density_splatter_exp_no_self_shadowing.png}
	%\caption{Without self-attenuation (splatting or volume marching)}
	%\end{subfigure}%

  \hspace*{\fill}
	\caption{\revision{Illustration of rendering methods for the non-overlapping, anisotropic Gaussians in (a). The left-hand Gaussian presents its thinnest side, the one in the middle is at a 45\degree\ angle and the right-hand one shows its thickest side. (b) EWA-based splatting preserves the integral of Gaussian extinction and thus the three Gaussians appear progressively darker. (c) With 3DGS-based splatting, all Gaussians have the same opacity (and thus intensity) at their center.}}  %However, it still approximates attenuation via Taylor expansion $(1-x)$, yielding sharp borders. (d) Using the extinction factor $exp(-x)$ and self-attenuation yields the expected smooth solution of Equation \ref{eq:volumetric_integration}.
	\label{fig:rendering_methods}
\end{figure}


% In this section we look at the evaluation of Gaussians, therefore the unnormalised definition (Eq.~\ref{eq:gaussian_definition_unnormalised}) is easier to understand.
% For rendering, we want to evaluate 3D Gaussians, e.g. for ray marching, and 2D Gaussians, e.g. for splatting.
% In this section, we will therefore look at $a$, the evaluation factor of the unnormalised 3D Gaussian $\mathcal{G}^u_3$, respectively $a'$, for the 2D case.

\paragraph*{EWA Splatting} uses normalised Gaussians and the stored per-Gaussian data term $\theta$ corresponds to $w$, the total integral of each normalised Gaussian function.
%; the Gaussian mixture used~(Eq.~\ref{eq:gmm}) represents a standard volumetric extinction function. %the integral of $\mathcal{G}^n_3$.
% The marginal distribution of a normal distribution is again a normal distribution, hence it follows 
% \begin{align}
%     w = \int_{\mathbb{R}^2} w\mathcal{N}_2 = \int_{\mathbb{R}^2} G_i(\pixel) =\int_{\mathbb{R}^3} \mathcal{G}^n_3 =  
%     \int_{\mathbb{R}^3} w\mathcal{N}_3 .
%     \label{eq:integra_of_normalised_2d3dgaussians_is_wl}
% \end{align} 

From the conversion between parameterizations in Eq.~\ref{eq:gaussian_definition_conversion}, \revision{we get unnormalised Gaussian amplitudes
\begin{align}
\label{eq:a_mass_formulation}
	a &=\frac{\theta}{\mathcal{I}_3(\mat{\Sigma})},
\end{align}
and
\begin{align}
	\label{eq:aprime_mass_formulation}
	a' &=\frac{\theta}{\mathcal{I}_2(\mat{\Sigma'})},
\end{align}
%where $\mathcal{I}_3$ and $\mathcal{I}_2$ are the normalization factors for the exponential part of the 3D and 2D Gaussian function, respectively (Eq.~\ref{eq:exponential_integral}).
%, and $\theta$ is the learned weight (adjusted by gradient descent).
%GD Inverted the presentation to give the visual intuition first
%The change in 
where $\mathcal{I}_3$ and $\mathcal{I}_2$ are the normalization factors for the exponential part of the 3D Gaussian function and its 2D projection in the current view, respectively} (Eq.~\ref{eq:exponential_integral}).
The behavior of $a'$ can be observed in Fig.~\ref{fig:rendering_methods}b, where we clearly see that the peak intensity increases with distance travelled through the Gaussian. This is the expected behavior when Gaussians model volumetric extinction.
% In this paper, we call this a density based model, as it is possible to infer directionally consistent 3D density values.



Assuming the Gaussians describe density of matter, $\theta$ in this formulation would represent the total \emph{mass} of a single Gaussian ``particle cloud''.
Intuitively, marginalizing a 3D representation of density $\mathcal{G}_3$ along an axis should turn it into a 2D Gaussian with the same total mass, and this is indeed the case for EWA.
Eq.~\ref{eq:aprime_mass_formulation} \revision{and Fig.~\ref{fig:extingi}a illustrate} this: the total mass $\theta$ does not change with the view, but the projected shape $\mat{\Sigma}'$ does, and therefore \revision{$\mathcal{I}_2(\Sigma')$} and $a'$ do too.

\paragraph*{3D Gaussian Splatting,} on the other hand, stores an ``opacity'' term on the 3D primitives, which is a constant, view-independent quantity for amplitude $a'$ of \revision{projected} Gaussians in 2D directly:
%on the other hand stores in $\theta$ a view-independent "opacity" term for $a'$ of Gaussian splats in 2D directly:
\begin{align}
	\label{eq:aprime_opacity_formulation}
	a' = \theta.
\end{align}
Note that compared to Eq.~\ref{eq:aprime_mass_formulation}, the view-dependent factor $\mathcal{I}_2^{-1}$ is missing.
%As a corollary, Eq.~\ref{eq:integra_of_normalised_2d3dgaussians_is_wl} does \emph{not} hold for 3DGS: 
While EWA preserves the \emph{integral} of Gaussian extinction functions, 3DGS preserves the \emph{amplitude} of projected Gaussians in 2D, \emph{regardless of viewing direction}. Intuitively, this means that the distance travelled along the ray within each Gaussian primitive does not affect the peak opacity of the primitive; this can be clearly seen in Fig.~\ref{fig:rendering_methods}c, where the resulting image-space splats have the same intensity at the center.
An alternative interpretation is that 3DGS uses a volumetric rendering model with \emph{view-dependent} extinction, implying that the density (and mass) of a supposed \revision{Gaussian particle} cloud varies with the viewpoint---contradicting the physically\revision{-inspired} volume integration framework \revision{(see Fig.~\ref{fig:extingi}b)}.
%produces the appearance of 3D primitives with \emph{view dependent} mass.
% This is incompatible with the established physically-based volume integration framework.
%This analysis clarifies \emph{how} 3DGS differs significantly from volume rendering, which is the theoretical foundation for EWA splatting and NeRFs.

As a consequence, there is no globally valid parameterisation of $\mathcal{G}_3$ from the Gaussian shape and the data term $\theta$ in 3DGS.
However, we can recover the view-dependent solution for $a$ in 3D from $\theta$.
We again use Eq.~\ref{eq:gaussian_definition_conversion} to convert the 2D opacity $\theta$ to $w$ and back to $a$:
\begin{align}
\revision{
\label{eq:a_opacity_formulation}
    w = \mathcal{I}_2(\mat{\Sigma'})\theta, \quad 
	a =\frac{w}{\mathcal{I}_3(\mat{\Sigma})} = \frac{\mathcal{I}_2(\mat{\Sigma'})}{\mathcal{I}_3(\mat{\Sigma})}\theta,
    }
\end{align}
% This can be verified by looking at Eqs.~\ref{eq:a_mass_formulation} and \ref{eq:aprime_mass_formulation}.
% Recall, that these equations describe what happens during integration along an axis, as the weight $w$ of normalised Gaussians stays the same in that case.
% In 3DGS, $a'$ is fixed for all directions (Eq.~\ref{eq:aprime_opacity_formulation}).
% We can plug it into Eq.~\ref{eq:aprime_mass_formulation}, isolate $\theta$, and then plug it into Eq.~\ref{eq:a_mass_formulation} to compute $a$:
%\begin{align}
%	
%\end{align}
%where $i_2$, $i_3$ are the unbounded integrals of the exponential part (Eq.~\ref{eq:exponential_integral}) of the 2D screen-space Gaussian for the current view and the 3D Gaussian, respectively.
%This gives us a process for computing view-dependent Gaussian amplitude $a$, usable to evaluate extinction in 3D.
\revision{While this derivation does not benefit splatting-based techniques, it is still useful since it} permits the use of the 3DGS image formation model in the 3D domain (e.g., for ray marching).
% us a process for computing view-dependent Gaussian amplitude $a$, usable to evaluate extinction in 3D.

% Similarly, the unbounded integral of the 3D Gaussian $w = i_2\theta$ %(the $w$ parameter of $\mathcal{G}^n_3$).
% %We see that it 
% also changes with direction. % (via $i_2$).
% Assuming the mental model of volume integration, with Gaussians describing volumetric particle or gas density, this would mean, that peak density ($a$) and total mass ($w$) depend on the viewing direction, which is outside of the established framework.

\revision{We note that 3DGS' use of} view-independent opacity is not only an approximation for the sake of performance, but also a 
%conscious % only the 3DGS authors know this -- the submission is anonymous
design decision that clearly works well in practice. However, this fundamental distinction between 3DGS and volumetric extinction-based solutions such as EWA splatting and NeRFs is sometimes overlooked in literature, and in some cases, ``extinction'', ``density'', and ``opacity'' are even conflated~\cite{guedon2023sugar,bolanos2024gaussian,lee2024gscore,huang2023photo}. 


\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/formulations/combined}
	\caption{\revision{Behaviors for the different formulations when changing covariance and fixing $\theta=1$ for a Gaussian primitive. For illustration, we use 2D Gaussian functions: Plotted curves indicate their contribution after projecting/marginalizing them along the vertical and horizontal "viewing axis". The left side varies the Gaussian covariance uniformly, while the right stretches it to produce anisotropy.
    (a) In EWA, $\theta$ represents the Gaussian's \emph{total} extinction, i.e., its integral (area under the curve): as we change the covariance, we must thus adapt its amplitude. (b) In contrast, 3DGS preserves the amplitude of the Gaussian's projection: all curves peak at the same value, regardless of covariance shift or projection axis. For anisotropic Gaussians (right), area under the curve \emph{varies} with the viewing axis. (c) OTS also uses $\theta$ to store the projected Gaussian amplitude, but through its thinnest side specifically, preserving total extinction across different projection axes (i.e., view directions).}}
	\label{fig:extingi}
\end{figure}
%In our analysis, we observe that the well-behaved and bounded opacity of 3DGS outperforms our EWA-based solution (see Sec.~\ref{sec:experiments}) once enough Gaussians are present in the model.
% \GD{@GK please add 1-2 sentences here}
% It is however important to investigate whether it is possible to have a \emph{density-based} splatting method with equivalent performance, and if so, what challenges this involves.

\subsection{Optimization with EWA-based Extinction}
\label{sec:ewabasedsplat}
% AC: 
% We now turn back to EWA based Gaussians and investigate possibilities to improve training results.
% Using normalised Gaussians as in Eqs.~\ref{eq:a_mass_formulation} and \ref{eq:aprime_mass_formulation} is suboptimal for gradient descent as learning becomes unstable:

% BK:
% Having analyzed the discrepancy between 3DGS and volume rendering theory, we investigate how to close this gap.
% Therefore, we turn back to the more adhering \emph{EWA-based} Splatting and optimizing its data term, i.e., learning the parameter for a \emph{view-independent} extinction $\theta$ of each Gaussian (i.e., its \emph{mass}).
% Using normalised Gaussians as in Eqs.~\ref{eq:a_mass_formulation} and \ref{eq:aprime_mass_formulation} is suboptimal for gradient descent:

% AC2:

Having analyzed the deviation of 3DGS from volume rendering theory, we shift our focus to \revision{the more principled} \emph{EWA-based} splatting.
Our aim is to identify the necessary modifications required to adapt EWA-based splatting for gradient-descent-based optimization \revision{like 3DGS}.
Directly learning \revision{$\theta$ as the weight $w$ of normalized Gaussians (Eq.~\ref{eq:a_mass_formulation} and \ref{eq:aprime_mass_formulation}) impedes training speed and robustness}: % speed and robustness since the screen-space amplitude $a'$ now depends on the shape and size of the Gaussian:
Consider the case of a single camera capturing a Gaussian that has already reached the appropriate opacity for the object it represents. If the Gaussian changes in size (e.g., to better fit the object's shape), $\theta$ is not affected. However, $\mathcal{I}_3$ and $\mathcal{I}_2$ will change, and $a'$ inversely so. Hence, expanding the Gaussian implicitly renders it more transparent \revision{and shrinking makes it more opaque (see Fig.~\ref{fig:extingi}a)}.
% Returning to the analogy of a gas cloud, the mass $\theta$ should change together with the size and shape $\mat{\Sigma}$ to maintain the same appearance.
%\AC{Returning to the analogy of a gas cloud, if the optimizer wants to increase the size and shape $\mat{\Sigma}$, it at the same time also must increase its mass $\theta$, otherwise it would become more transparent.}

% We can directly use Eq.~\ref{eq:a_opacity_formulation} to adjust the factors and learn $\theta$ with differentiable rendering using
%\AC{
We want to find a parameterization that adheres to Eq.~\ref{eq:gaussian2d_ewa} and has robust behavior.
Our initial idea is to learn peak extinction:
\revision{\begin{align}
	a = \theta \nonumber, \quad
	a' = \theta \frac{\mathcal{I}_3(\mat{\Sigma})}{\mathcal{I}_2(\mat{\Sigma'})},
\end{align}
}
where $a'$ was derived using Eq.~\ref{eq:gaussian_definition_conversion} again.
%As the cloud expands parallel to the image plane, its mass increases, thereby somewhat reducing the covariate shift.
%However, this formulation remains unstable:
%To accurately represent solid surfaces, the model must be capable of producing opaque primitives.
This somewhat offsets the initial issue, but only to the degree to which changes in $\mathcal{I}_3$ and $\mathcal{I}_2$ are correlated. 
Unfortunately, this is not generally the case. Consider a Gaussian trying to model a flat solid surface, frontally facing the current view: to appear opaque, an almost-flat Gaussian requires a much higher extinction than a thicker Gaussian \revision{(Fig.~\ref{fig:extingi}a, right)}.
%Achieving opacity with thin Gaussians necessitates high extinction values, which in turn requires a high peak extinction $a$.
%}

To ensure robustness under optimization as well as the ability to model thin, solid objects,
we therefore arrive at a scheme we call \emph{opacity-thin-side} (OTS). 
OTS dynamically scales the learned weight $\theta$ such that $a'= \theta$ when looking at the Gaussian facing its thinnest side (i.e., viewing along its shortest axis).
Under rotation it behaves like other EWA-based Gaussians, i.e., the 3D unbounded integral is view-independent, and the 2D projection is an ordinary integral \revision{(see Fig.~\ref{fig:extingi}c).
This is achieved by
\begin{align}
	\label{eq:gaussian_weight_ots}
	a = \theta \frac{\mathcal{I}^*_2(\mat{\Sigma})}{\mathcal{I}_3(\mat{\Sigma})}, \quad
	a' = \theta \frac{\mathcal{I}^*_2(\mat{\Sigma})}{\mathcal{I}_2(\mat{\Sigma'})},
\end{align}
with $\mathcal{I}^*_2$ being the largest possible $\mathcal{I}_2$, which can be computed as:
\begin{align}
	\mathcal{I}^*_2(\mat{\Sigma}) = 2 \pi \sqrt{\lambda_1\lambda_2},\nonumber
\end{align}
}
where $\lambda_1$ is the largest and $\lambda_2$ the second-largest eigenvalue of the 3D covariance matrix.
\revision{With this, OTS contains all necessary definitions for robust, optimizable splatting with EWA-based extinction.}
%This is computationally cheap if the covariance is stored in the form of three axis-aligned scaling factors (i.e., the eigenvalues) and a rotation, as, e.g., done in the case of 3DGS.


\subsection{Attenuation and Self-Attenuation}
\revision{
\label{sec:self_attenuation_and_exp}
% Using density based Gaussians, e.g. by employing the OTS scheme, is a step into the direction towards more accurate volumetric rendering.



Both EWA splatting and 3DGS ignore how a Gaussian's extinction affects its own appearance. We call this \emph{self-attenuation}: it affects the visual result, even when Gaussians do not overlap (see Figure \ref{fig:selfattn}). For the attenuation of one Gaussian by another, both EWA and 3DGS approximate $e^{-g(\pixel)}$ with the first two terms of its Taylor series expansion, $1-g(\pixel)$ (Eq.~\ref{eq:alphablend}).
Note that this solution \emph{cannot} be used directly if $g(\pixel)$ can exceed $1$; this, however, is the case in our OTS solution, where an unrestricted $\theta$, associated with a Gaussian's \emph{mass}, is learned. A na\"{i}ve solution is to simply clamp $g(\pixel)$ in Eq.~\ref{eq:alphablend} to $[0, 1)$, but this results in sharp, non-Gaussian falloffs, as well as the elimination of gradients, which are essential for training. %: the result is shown in Fig.~\ref{fig:rendering_methods}c.
%Compared to 3DGS rendering, we clearly observe a tendency to preserve the mass of the Gaussian, 
%but the falloff in the right-most Gaussian of (c) is unnaturally sharp.

\begin{figure}
\includegraphics[width=\columnwidth]{figures/self-attn.pdf}
\caption{\revision{Impact of self-attenuation. For a ray intersecting a 3D Gaussian, ignoring (blue) and accounting for (red/lower) self-attenuation show similar initial behavior in Gaussians with identical parameters. However, as the ray goes on, self-attenuation gradually reduces the Gaussian's ability to emit/extinguish additional light, due to the extinction already accumulated since entering it.}}
\label{fig:selfattn}
\end{figure}

%Compared to 3DGS, using EWA-like integration is already a step toward more accurate volumetric rendering.
To address attenuation in a principled manner, we revisit Eq.~\ref{eq:volumetric_integration_c}.
%Another step is possible by using a closed-form solution of the volumetric integral (Eq.~\ref{eq:volumetric_integration_c}) for 
We first consider the case of a Gaussian mixture with just one Gaussian (index 0) intersecting a viewing ray. We move the ray's starting point to $-\infty$ to ensure that it traverses the entire Gaussian:
%, introducing negligible integration error if the Gaussian is sufficiently far in front of the origin.
\begin{align}
	\label{eq:volumetric_equation_single_gaussian}
	I(\pixel) = c_0(\ray) \int_{-\infty}^\infty \mathcal{G}^n_3(\ray(t), 0) e^{-\int_{-\infty}^t \mathcal{G}^n_3(\ray(\tau), 0) \diff{\tau}} \diff{t},
\end{align}
For simplicity, EWA and 3DGS set the exponential term---the self-attenuation---to $1$. However, it is possible to derive a closed-form solution if we use the 2D Gaussian extinction $f_i$ defined in Eq.~\ref{eq:gaussian2d_ewa}:
\begin{align}
	\label{eq:volumetric_equation_single_gaussian_closed_form}
	I(\pixel) = c_0(\ray) \left(1 - e^{-f_0(\vr{p})} \right).
\end{align}
% Applying these changes to Eq. \ref{eq:volumetric_equation_single_gaussian} yields
% \begin{align}
% 	\label{eq:volumetric_single_gaussian_ewa}
% 	I(\pixel) = c_0(\ray) G_0(\pixel) + c_b \; (1-G_0(\pixel)),
% \end{align}

% To understand the mathematical implications of this approximation, we consider a setup of a camera ray intersecting a single Gaussian.
% We will later extend this setup to several, non-overlapping Gaussians.
% For symmetry, we move the starting point of the ray to $-\infty$, introducing negligible integration error if the Gaussian is sufficiently far in front of the origin.
% Equation \ref{eq:volumetric_integration_c} becomes
% \begin{align}
% 	\label{eq:volumetric_equation_single_gaussian}
% 	I(\pixel) = c_0(\ray) \int_{-\infty}^\infty g_0(\ray(t)) e^{-\int_{-\infty}^t g_0(\ray(\tau)) \diff{\tau}} \diff{t} + c_b \: e^{-G_0(\pixel)},
% \end{align}
% where $c_0(\ray)$ is the evaluation of (view-dependent) color for ray $\ray$ that goes through pixel $\pixel$;
% $g_0(\ray(t))$ is the evaluation of the 3D Gaussian;
% $c_b$ is the background of the current Gaussian (either the scene background or, more generally, the background and remaining Gaussians);
% Finally, $G_0(\pixel) = \int_{-\infty}^\infty g_0(\ray(t)) \diff{t}$.

% As discussed above, EWA splatting and 3DGS replace $e^{-G_0(\pixel)}$ with the first two terms of its Taylor series expansion, $1-G_0(\pixel)$.
% Applying these changes to Eq. \ref{eq:volumetric_equation_single_gaussian} yields
% \begin{align}
% 	\label{eq:volumetric_single_gaussian_ewa}
% 	I(\pixel) = c_0(\ray) G_0(\pixel) + c_b \; (1-G_0(\pixel)),
% \end{align}
% % \TODO{The 3DGS paper does not have a background term. I suggest the following @GK please check}
% % \GK{The 3DGS paper doesnt have it because it assumes black background color so the color term is zero. The code is already implemented as Adam suggest's here, so depending how rigorous we want to be we can ignore this issue.}
% % \GDmodif{Note that the second terms is not explicitly present in the original 3DGS paper, but does not change the reasoning presented here.}
% which can be verified by setting $N=0$ in Eq.~\ref{eq:alphablend}.
% Note that this equation \emph{cannot} be used directly if $G_0(\pixel)$ can exceed $1$; this, however, is the case in our EWA-based splatting, where an unrestricted quantity associated with a Gaussian's \emph{mass}, is learned.
% A na\"{i}ve solution is to simply clamp $G_0(\pixel)$ to $[0, 1)$: the result is shown in Fig.~\ref{fig:rendering_methods}c.
% Compared to 3DGS rendering, we clearly observe a tendency to preserve the mass of the Gaussian, 
% but the falloff in the right-most Gaussian of (c) is unnaturally sharp. 



% However, 

% The proof for this solution is provided in Appendix \ref{ap:proof_volumetric_equation_single_gaussian_closed_form}.
The proof for this solution is provided in the supplemental material.
When splatting a single Gaussian, this approach accurately accounts for self-attenuation and exponential extinction, and has been used for producing the rendering in Figure \ref{fig:rendering_methods}c.}
\revision{Exploiting the assumption of non-overlapping Gaussians that splatting inherently depends on, this solution easily extends to multiple Gaussians:
%We have verified that splatting individual Gaussians using this formulation perfectly matches our ray-marched solutions (see experimental results below).
\begin{equation}
	\label{eq:self_attenuation_blend}
	I(\pixel) = \sum_{i=0}^N c_i(\ray) \left(1 - e^{-f_i(\pixel)} \right) \prod_{j=0}^{i - 1}(e^{-f_j(\pixel)}) + c_b \prod_{i=0}^N(e^{-f_i(\pixel)}),
\end{equation}
%which can be used as a replacement for Eq.~\ref{eq:alphablend}.
Note that it also removes the need for clamping, since any $f_i(\pixel) \in [0, \infty)$ yields coefficients $\in [0, 1)$, making it compatible with OTS.


% Although the 3DGS approach is based on the volume rendering integral shown in Equation \ref{eq:volumetric_integration}, several simplifications and approximations are used to trade integration accuracy for computational efficiency.
% Some of them are inherited from EWA splatting, others are new.
% Specifically, in 3DGS:
% \begin{itemize}
	%     \item Learned weights represent screen space opacity, not mass or optical density. The volumetric rendering integral is not considered for individual Gaussians.
	%     \item There is no specific processing for overlapping Gaussians, even though they are very frequent in the reconstructed representations.
	%     \item Gaussians are sorted globally front to back.
	%     \item The color of a Gaussian depends on the viewing direction, not the position within the Gaussian.
	%     \item The shape in screen space is not accurate, as projection mapping of the covariance matrix is approximated using a local affine approximation.
	% \end{itemize}

% \subsection{Overlap and Projection}
% \label{sec:overlap_proj}
% %In the above, we have discussed the important distinction between 3DGS- and EWA-splatting-based methods, and analysed the approximation of self-attenuation.
% So far, we have restricted our discussion to the cases of non-overlapping Gaussians and ignored all issues related to correct depth sorting.
% However, both of these play a key role in the formation of images from complex Gaussian models (see Fig.~\ref{fig:overlapping_1d_gaussians}).

% 3DGS renders Gaussians for a view ray $\ray$ sequentially, aggregating one by one the Gaussian's complete contribution along its intersection with $x$. 
% Not accounting for its other approximations, this sequential aggregation is equivalent to volume integration, \emph{as long as Gaussians do not overlap}.
% However, the traversal order is established globally, based on the Gaussians' \emph{mean} view space depth.
% Thus, it ignores the orientation and shape of Gaussians, which can cause their actual visibility to vary between pixels (see Figure \ref{fig:overlap_and_sorting}a). 
% In 3DGS, a single order is established for all pixels (Figure \ref{fig:overlap_and_sorting}b), thus changes in visibility occur abruptly, leading to visible popping artifacts, especially when primitives are large.

% Recently introduced \emph{StopThePop} splatting \cite{radl2024stopthepop} proposes a hierarchical sorting solution to efficiently generate per-pixel orderings:
% along each view ray, the distance where a Gaussian's opacity peaks defines its sorting key (Figure \ref{fig:overlap_and_sorting}c).
% Although StopThePop helps to reduce popping artifacts, it does not perform exact volumetric integration of overlapping Gaussians.
% The correct treatment of overlap during splatting would require significant modifications of the algorithm, with detailed book-keeping of entry and exit events for each ray as it traverses 3D Gaussians.
% Realizing these modifications without impacting 3DGS's performance is a challenging task.

% Other issues arise when considering Gaussians' projections.
% The shape of a 3D Gaussian's 2D splat is approximated using the Jacobian at its mean (Equation \ref{eq:splatting_transformation_of_covariance}).
% This approximation is motivated by perspective projection being a non-linear transformation; hence, the actual projected shape of a 3D Gaussian is a non-trivial quadric, whose exact computation is much more complex.
% For most camera models, the simplified transformation in Equation \ref{eq:splatting_transformation_of_covariance} is reasonably accurate, especially for small Gaussians close to the focal point. However, the effects of distortion can become significant as Gaussians grow or move to peripheral regions, resulting in a geometrically inconsistent appearance of a Gaussian from different viewpoints.
% \BKmodif{Could we reference "Optimal Projection for 3D Gaussian Splatting"? Basically say "they have treated this, so we are not investigating it in detail, but inherently do it in the ray marcher".}

% While incorrect visibility, overlap treatment, and perspective projection pose clear deviations from standard volume rendering methodology, it is unclear whether these approximations have a significant impact in practice.
% To answer this question, we provide a ray marching based implementation of volumetric integration \reftodo{ray-marching papers}.
% % To answer this question, we provide a ray marching rendering \GD{solution based on splatting}
% %variant 
% % for volumetric integration\GD{, that produces results equivalent to more traditional ray-marching~\cite{}}\reftodo{ray-marching papers}.
% This renderer samples 3D Gaussians along view rays in 3D, thus correctly accounting for projection.
% Furthermore, it actually evaluates the full Gaussian mixture  $f(x(t))$ at each sample location along view ray $x$, correctly accounting for overlap (see Figure \ref{fig:overlap_and_sorting}d).
}

\subsection{Visibility}
\label{sec:overlap_proj}
So far, our analysis has neglected the issues of Gaussian overlap and depth sorting (see Fig.~\ref{fig:splatting}); yet both impact the rendering of Gaussian models.
%The EWA foundation of 3DGS assumes non-overlapping Gaussian primitives, rendering
3DGS renders Gaussians sequentially, based on their mean view space depth.
When Gaussians overlap in 3D, this causes popping artifacts due to abrupt changes in visibility, especially with large primitives (Fig.~\ref{fig:overlap_and_sorting}b).
StopThePop (STP) \cite{radl2024stopthepop} mitigates this issue by using per-pixel sorting. However, it does not resolve overlap during splatting (Fig.~\ref{fig:overlap_and_sorting}c).
Proper visibility resolution in the spirit of volumetric rendering requires modifications for integration along a ray, impacting performance.
To assess the importance of exact visibility for scene reconstruction and novel-view synthesis, we have designed a principled ray marching-based renderer for 3D Gaussians (Sec.~\ref{sec:raymarcher}): It evaluates the full Gaussian mixture in $f$ and accurately handles overlap (see Fig.~\ref{fig:overlap_and_sorting}d).


% \begin{figure}
% 	\centering
% 	\resizebox{0.8\linewidth}{!}{
% 		\begin{tikzpicture}[scale=1, every node/.style={scale=1.5}]
% 			% Define Gaussian function
% 			\def\gaussA{\x,{2*exp(-(\x-1)*(\x-1)/2)}}
% 			\def\gaussB{\x,{1.5*exp(-(\x+1)*(\x+1)/2)}}
			
% 			% Plot the first Gaussian
% 			\draw[thick,color={rgb:orange,1;yellow,1},domain=-4:4,smooth,variable=\x] plot ({\gaussA}) node[right] {};
			
% 			% Plot the second Gaussian
% 			\draw[thick,red,domain=-4:4,smooth,variable=\x] plot ({\gaussB}) node[right] {};
			
% 			% Draw the axes
% 			\draw[thick,-{Stealth[length=3mm]}] (-4.5,0) -- (4.5,0) node[right] {$x$};
% 			\draw[thick,-{Stealth[length=3mm]}] (-4.0,-0.5) -- (-4.0,2.5) node[above] {};
			
% 			% Labels
% 			\node[above] at (-2.2,1) {$g_0$};
% 			\node[above] at (2.4,1.2) {$g_1$};
			
% 		\end{tikzpicture}
% 	}
% 	\caption{
% 		Overlapping Gaussian curves along a viewing ray.
% 		This situation is treated differently depending on the algorithm.
% 		Per-Gaussian sorting might sort $g_1$ before $g_0$, depending on the orientation and geometry.
% 		Per-pixel sorting more accurately always blends $g_0$ in front of $g_1$.
% 		Only ray marching correctly blends the overlapping area by making small integration steps.
% 	}
% 	\label{fig:overlapping_1d_gaussians}
% \end{figure}


\begin{figure*}
	\centering
        \hspace*{\fill}
	\begin{subfigure}[t]{0.24\textwidth}
		\includegraphics[width=0.8\linewidth,trim=0 2cm 0cm 0, clip]{figures/fig2/4a.png}
		\caption{Viewing Scenario}
	\end{subfigure}%
	\hspace{1mm}
	\begin{subfigure}[t]{0.24\textwidth}
		\scalebox{-1}[1]{\includegraphics[width=0.8\linewidth,trim=0 2cm 0cm 0, clip]{figures/overlap/schraeg_orig_rot_gelb.png}}
		\caption{Per-Gaussian sorting (3DGS)}
	\end{subfigure}%
	\hspace{1mm}
	\begin{subfigure}[t]{0.24\textwidth}
		\scalebox{-1}[1]{\includegraphics[width=0.8\linewidth,trim=0 2cm 0cm 0, clip]{figures/overlap/schraeg_sorted_rot_gelb.png}}
		\caption{Per-pixel sorting (STP)}
	\end{subfigure}%
	\hspace{1mm}
	\begin{subfigure}[t]{0.24\textwidth}
		\scalebox{-1}[1]{\includegraphics[width=0.8\linewidth,trim=0 2cm 0cm 0, clip]{figures/overlap/schraeg_marcher_rot_gelb.png}}
		\caption{Exact integration (ray marcher)}
	\end{subfigure}%
         \hspace*{\fill}
	\caption{Visibility in Gaussian Splatting. Illustration of the effect of sorting and overlap when rendering the 2-Gaussians setup shown in (a). The two Gaussians have the same position and are at 90\degree\ to each other. (b) shows the behaviour of the original 3DGS paper: One of the Gaussians ends up in front as a global sort is used. (c) shows the effect of a per-pixel sort (StopThePop). Only (d) correctly mixes the colours.}
	\label{fig:overlap_and_sorting}
\end{figure*}

Additionally, projection distortions arise from the non-linear nature of perspective transformation, which is only approximated by the Jacobian at the Gaussians’ position (Equation \ref{eq:splatting_transformation_of_covariance}).
While reasonable for small Gaussians near the focal point, distortion becomes significant for larger Gaussians at peripheral regions.
Previous work partially addresses this projection inconsistency \cite{huang2024erroranalysis3dgaussian}, but cannot fully eliminate the approximations.
Again, our ray-marching implementation provides a testbed to examine the importance of precise perspective projection for 3D Gaussians.

\section{Implementation}
\label{sec:impl}
This section discusses the implementation details for the rendering algorithms.
We build these algorithms on top of the original 3DGS code base; this enables meaningful comparisons since the alterations for replacing each specific approximation are kept to a minimum.
First, we describe the modifications made to 3DGS for a consistent comparison, and to implement the EWA-based (OTS) variant and self-attenuation.
We continue by describing the details of our 3D Gaussian ray-marching solution.
All newly developed gradient computations for these modifications were rigorously validated through unit testing against numerical approximations.
Finally, we discuss the necessary changes to initialization.
All source code is available on \url{github.com/cg-tuwien/does_3d_gaussian_splatting_need_accurate_volumetric_rendering}.
 % tried to reformulate with fewer sentences starting with "We"

\subsection{Modifying 3DGS-Based Splatting (3DGS \& 3DGS+STP)}
In 3DGS, the rendering process is split into several passes:
$\vr{\mu}'$ and $\mat{\Sigma}'$ are computed as described \revision{in Sec.~\ref{sec:bg_3dgs}} in a per-primitive pass.
Also in this pass, the RGB color is computed by evaluating spherical harmonics for the direction from camera to position $\vr{\mu}_i$.
Next, Gaussians are sorted first by affected screen-space tiles and then by depth for rendering.
%, using $3$ standard deviations to test for primitive-tile overlap.
%Then, the Gaussians are sorted globally, such that a per-tile list of Gaussians is created.
Finally, in the rendering pass, for each pixel in a tile, its portion of the sorted list is traversed.
For each entry, the Gaussian's contribution is computed by evaluating the \revision{projected} 2D Gaussian, multiplied with the RGB color, and blended following Equation \ref{eq:alphablend}.
In practice, the traversal can stop early if the remaining transmittance \revision{$\prod_{j=0}^{i-1}(1 -f_i)$} drops below a given threshold.

In order to be consistent with the EWA-based variant and the ray marcher, we used a convolution instead of a dilation for anti-aliasing as described by \cite{yu2023mip}.
For StopThePop (3DGS+STP) \cite{radl2024stopthepop}, we used a configuration enabling hierarchical sorting with culling and their convolution \revision{correction} for anti-aliasing.

\subsection{EWA-Based Splatting (OTS)}
In the per-primitive pass (Sec.~\ref{sec:bg_3dgs}) we changed the computation of $a'$ to follow Eq.~\ref{eq:gaussian_weight_ots}.
$\vr{\mu}'$ and $\mat{\Sigma}'$ are computed as is.
In addition, we note that the $\mat{\Sigma}'$ is affected by perspective projection and can change for a given Gaussian, depending on its screen-space position.
Consequently, to preserve the integral of the extinction coefficient, the weight $a'$ must be multiplied by the determinant of the Jacobian, as done by Zwicker et al.\ \cite{ewa_splatting}.
In the rendering kernel, it is necessary to clamp $f_i(x)$, as 2D Gaussians can now produce values greater than 1 (see Sec.~\ref{sec:self_attenuation_and_exp}).
Incidentally, this clamp was already present in the 3DGS codebase for numerical stability \cite{kerbl3Dgaussians}.

\subsection{EWA-Based Splatting with Self-Attenuation (OTS+SAtn)}
\label{sec:impl_extinction_and_self_shadowing}
Implementing Eq.~\ref{eq:self_attenuation_blend} requires changing the render- or rasterisation kernel.
Doing so in forward rendering mode is trivial.
However, computing the gradient in the backward pass required switching from back-to-front traversal to front-to-back, requiring an extensive rewrite (see supplemental material).
The self-attenuation version does not use the Taylor approximation for $\texttt{exp}$ in the attenuation factor (Eq. \ref{eq:volumetric_integration_c}) and therefore a ray integral of $1$ would not result in an opacity value of $1$.
Hence, we cannot use the sigmoid activation, because Gaussians could not become fully opaque from all directions.
Instead, we use the softplus activation with $\beta = 2$.

\subsection{Ray Marching (OTS Marcher \& 3DGS Marcher)}
\label{sec:raymarcher}
% Ray tracing solutions for 3D Gaussian-based representations are actively explored in concurrent work \todo{CITE stuff}\cite{condor2024dontsplatgaussiansvolumetric}\cite{3dgrt2024}.
% However, these usually resort to a discrete primitive sorting, albeit per-pixel, similar to the results of STP.
Our ray marcher performs adaptive sampling along each ray to accurately resolve Gaussian overlap to compute the volumetric integral with a precision governed by the sample count.
%This principled image formation is significantly slower, especially when compared to the rasterizer implemented by 3DGS.
% This principled image formation is significantly slower, especially when compared to hardware-accelerated solutions \cite{3dgrt2024}.
% \GD{Ray-marching can be implemented with GPU-based ray-tracing API such as NVIDIA Optix~\cite{}. However, we chose to use the same CUDA framework as the original 3DGS approach to allow a more meaningful comparison.}\TODO{Add citation}
% \todo{reformulate: to me the Optix solution is kinda odd, it seems to work, but it sounds like a hack. the conventional way of implementing ray marching is taking small steps on a ray and evaluating the function. I would say, that our approach is more traditional/conventional, and maybe more principled (maybe? at least some of the papers had approximations). using the same cuda framework is an implementation detail, and debatable (i reimplemented almost everything, though it's still the same architecture). "allow a more meaningful comparison" -> i think one could argue about that. shouldn't any ray marching solution do the same thing? so our solution is not adding meaning compared to other ray marching solutions (that are exact up to numerical error). TLDR: just mention that there are other implementations, and ours is not the fastest but does the job. }
% We implemented a CUDA-based differentiable ray marcher as an alternative rendering backend for the 3DGS framework.
% The same parametrization of Gaussian density was used, i.e., the OTS scheme.
Two variants were implemented, one follows the 3DGS model of opacity (3DGS Marcher), and the other the \revision{extinction-based} model with the OTS scheme (OTS Marcher), with differences being explained in Sec.~\ref{sec:anal_opa_vs_dens}.
Consequently, we can reuse the data structures (tensors with weights, positions, scales, and rotations), activation functions, and learning rates.
It is possible to ray march scenes learned with splatting, and vice-versa, but the reconstruction is less accurate.
The rendering pipeline shares similarities with 3DGS, including a per-primitive pass, identical tiling and sorting kernels, and a per-pixel rendering kernel.
However, the key distinction is the traversal and integration of 3D Gaussian primitives.

Ray marching fundamentally involves making incremental steps along a ray and evaluating the Gaussian mixture.
At each step, all Gaussians are intersected with the viewing ray, creating 1D Gaussians.
These are integrated analytically between step positions.
Effectively this creates bins of variable extent, each holding ray-mixture-integrals for opacity and colours.
% The final color is computed by blending the bins, following Equation \ref{eq:volumetric_integration}.
% The process can be seen as an outer product as all bins are combined with all Gaussians.
For this to be accurate, it is essential to adapt bin borders to the Gaussian data.
We do this by iterating over the mixture twice, first establishing bin borders and then for analytical integration.
Finally, the bins are blended together following the volume integral in Eq.~\ref{eq:volumetric_integration}.
% Again, we tested all gradients with numerical unit tests.
Further details are in the supplemental material. 
While performance is not the main focus of this paper, we note that our ray marcher, implemented in CUDA, is considerably slower than splatting (between one and two orders of magnitude, depending on the scene).
This is in spite of us following the guidelines for efficient GPU programming, highlighting the implementation challenges of principled rendering variants.
\revision{Although recent research demonstrates high performance for \emph{ray-tracing} Gaussians~\cite{3dgrt2024}, in contrast to \emph{ray marching}, their solution does not account for primitive overlap in the integration.}

\subsection{Initialization}
% The aim of the paper is not to develop a better algorithm, but to understand the factors that are important in doing so.
% With that in mind, we aimed to create a controlled environment, where we limit the number of parameters to evaluate the effect only of the differences between methods.
% As part of this effort, we removed adaptive densification in order to be able to regulate the number of Gaussians.

The original 3DGS solution initializes trainings of the NeRF-synthetic dataset~\cite{mildenhall2020nerf} by placing Gaussians randomly within the unit cube and setting a constant opacity.
Using this approach, the overall opacity increases with the number of Gaussians, preventing convergence for very large counts.
As a solution, we fit a power function that returns an appropriate opacity for the number of Gaussians used (\revision{see supplemental material for  details}).
This approach was repeated for the \revision{OTS and OTS+SAtn} variants.

\subsection{Learning Rates}
The learning rates for 3DGS were adjusted with densification in mind.
Therefore, we performed a grid search to find optimal learning rates for all algorithms on 5 of our test scenes with 60,000 Gaussians.
Results show that the OTS, and OTS+SAtn variants (splatters and marchers) all need a slightly lower learning rate for the weight.
All other learning rates are the same for all algorithms.
The exact numbers can be found in our code.

\section{Evaluation}
\label{sec:experiments}
We conducted several numerical experiments to determine which approximations have a significant impact on the reconstruction quality of 3D Gaussian splatting.
% \TODO{Following repetition from above ? Merge} % adam is confused, i think this is an old comment, no?
To avoid having too many different variables that would complicate analysis and to isolate each method's ability to optimize Gaussian primitives, we have removed the 3DGS densification logic from the optimization process and instead list the achieved metrics for different numbers of randomly initialized Gaussians.

In a similar spirit, we perform our evaluation on the established NeRF synthetic dataset~\cite{mildenhall2020nerf}, which provides a well-defined environment with exhaustive camera coverage, such that scenes can be optimized from randomly initialized Gaussians. However, these scenes focus mostly on solid objects:
to further assess the impact of correct volumetric rendering in detail, we created additional volumetric datasets with varying parameters for transparency, frequency, scattering coefficients, and color.
These volumetric scenes are shown in Fig.~\ref{fig:somefigs}, \ref{fig:example_burning_ficus}, and \ref{fig:example_materials}. 

\begin{figure}[h]
    \centering
	\begin{subfigure}[t]{0.24\linewidth}
		\includegraphics[width=\linewidth]{figures/examples/volumetric_scenes/gt_explosion_2_test040.png}
		\caption*{\textsc{Explosion}}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[t]{0.25\linewidth}
		\includegraphics[width=\linewidth]{figures/examples/volumetric_scenes/gt_wdas_cloud_2_test040.png}
		\caption*{\textsc{Cloud 2}}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[t]{0.25\linewidth}
		\includegraphics[width=\linewidth]{figures/examples/volumetric_scenes/gt_wdas_cloud_3_test040.png}
		\caption*{\textsc{Cloud 3}}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[t]{0.26\linewidth}
		\includegraphics[width=\linewidth]{figures/examples/volumetric_scenes/gt_coloured_wdas_test040.png}
		\caption*{\textsc{Colored Cloud}}
	\end{subfigure}%
    \caption{Four volumetric scenes, from left to right: \textsc{Explosion}, \textsc{WDAS Cloud} 2 and 3, \textsc{Colored WDAS Cloud}.}
    \label{fig:somefigs}
\end{figure}

\begin{table*}[htbp]
\centering
% \caption{Averages over all scenes (individual results in Appendix \ref{ap:full_results}). \todo{careful, results without ship atm.}}
\caption{Averages over all scenes (individual results in the supplemental material). Red is best, orange second and yellow is third.}
\input{tables/table_all_avg}
\label{tab:results_psnr}
\end{table*}


\subsection{Results}

For each scene and rendering method described so far, we evaluate three established image-quality metrics (SSIM, PSNR, LPIPS).
For each rendering method, the optimization described by 3DGS is performed for 30k iterations. Our supplemental video shows several scenes rendered with the different algorithms at 4k and 1 million Gaussians. The videos help to convey the popping issue with 3DGS, as well as illustrate the quality trends discussed below.




Tab.~\ref{tab:results_psnr} lists the results obtained over all tested scenes, and Fig.~\ref{fig:results_ssim_avg_all} through \ref{fig:results_lips_avg_all} illustrate them visually. Per-scene results are provided in our supplemental material. With the exception of special cases, which we discuss below, the full results establish several insightful trends. The most striking is the dependence on model size: while ray marchers with correct volumetric integration are superior for lower Gaussian counts, they are eventually matched or surpassed by 3DGS as the number of Gaussians increases.
A similar trend can be observed for EWA-based splatters (OTS and OTS+SAtn): they also perform better than 3DGS for small model sizes but are outperformed for larger ones. Concrete examples of this behavior are given in Figure~\ref{fig:teaser} and \ref{fig:example_burning_ficus}. In the following, we discuss these trends for individual variants in detail and explore their causes.


\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{tables/ssim_avg_all_plot}
	\caption{SSIM averages over all scenes for each model size.}
	\label{fig:results_ssim_avg_all}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=\linewidth]{tables/psnr_avg_all_plot}
\caption{PSNR averages over all scenes for each model size.}
\label{fig:results_psnr_avg_all}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=\linewidth]{tables/lpips_avg_all_plot}
\caption{LPIPS averages over all scenes for each model size.}
\label{fig:results_lips_avg_all}
\end{figure}

\paragraph*{3DGS-Based Splatting vs. Ray Marching}
Compared to 3DGS, the presented 3DGS ray-marching variant is more faithful to volumetric integration. In addition to exact projection, it avoids discontinuities in the optimization due to the strict per-primitive sorting, which affects both 3DGS (popping) and STP (see Fig.~\ref{fig:overlap_and_sorting}). Discontinuities and projection errors are most notable when Gaussians are large, which explains the advantage of the 3DGS Marcher with fewer primitives: Since there are fewer Gaussians to model the full scene, they also remain larger on average. Note that the more fine-granular ordering of STP yields a slight advantage over 3DGS. As the number of Gaussians increases, so does the ability to model fine scene details for all methods. With more Gaussians, the ability to consider overlap becomes insignificant, as Gaussians become so small that overlap is mostly avoided. In addition, 3DGS and STP have distinct advantages: first, in preserving opacity, they can trivially produce fine structures (anisotropic Gaussians) that appear solid from all sides. Second, discontinuities in the model via the enforced discrete primitive ordering can now be exploited to reproduce high-frequency detail and view-dependent effects.
Lastly, the computation of the volumetric integral becomes prone to numerical imprecision as the number of samples rises. Thus, the effectiveness of 3DGS is strongly tied to the use of larger primitive counts, which its fast rendering pointedly facilitates.


\begin{figure*}
	\centering
        \hspace*{\fill}
	\begin{subfigure}[t]{0.16\linewidth}
		\includegraphics[width=\linewidth]{figures/examples/burning_ficus_4k_test040/gt_annot.png}
		\caption{Overview}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[t]{0.16\linewidth}
		\includegraphics[width=\linewidth]{figures/examples/burning_ficus_4k_test040/cut_3dgs.png}
		\caption{3DGS 4k}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[t]{0.16\linewidth}
	\includegraphics[width=\linewidth]{figures/examples/burning_ficus_4k_test040/cut_ots_and_satn.png}
	\caption{OTS + SAtn 4k}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[t]{0.16\linewidth}
	\includegraphics[width=\linewidth]{figures/examples/burning_ficus_4k_test040/cut_3dgs_marcher.png}
	\caption{3DGS Marcher 4k}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[t]{0.16\linewidth}
	\includegraphics[width=\linewidth]{figures/examples/burning_ficus_4k_test040/cut_ots_marcher.png}
	\caption{OTS Marcher 4k}
	\end{subfigure}%
	\hspace*{\fill}

 \hspace*{\fill}
	\begin{subfigure}[t]{0.16\linewidth}
	\includegraphics[width=\linewidth]{figures/examples/burning_ficus_4k_test040/cut_gt.png}
	\caption{Ground Truth}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[t]{0.16\linewidth}
	\includegraphics[width=\linewidth]{figures/examples/burning_ficus_972k_test040/cut_3dgs.png}
	\caption{3DGS 1M}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[t]{0.16\linewidth}
	\includegraphics[width=\linewidth]{figures/examples/burning_ficus_972k_test040/cut_ots_and_satn.png}
	\caption{OTS + SAtn 1M}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[t]{0.16\linewidth}
	\includegraphics[width=\linewidth]{figures/examples/burning_ficus_972k_test040/cut_3dgs_marcher.png}
	\caption{3DGS Marcher 1M}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[t]{0.16\linewidth}
	\includegraphics[width=\linewidth]{figures/examples/burning_ficus_972k_test040/cut_ots_marcher.png}
	\caption{OTS Marcher 1M}
	\end{subfigure}%
 \hspace*{\fill}
	\caption{\textsc{Burning Ficus} with 4k and 1M Gaussians. The OTS renderers and the 3DGS Marcher have an advantage when using few Gaussians. In these cases, they manage to achieve a crispier reconstruction of delicate structures. Volumetric effects like smoke are unaffected. For the second row, squared error w.r.t.\ ground truth is shown in bottom left corner.}
	\label{fig:example_burning_ficus}
\end{figure*}


\begin{figure*}
	\centering
	%	\begin{subfigure}[t]{0.12\linewidth}
		%		\includegraphics[width=\linewidth]{figures/examples/materials/972k/gt_annot.png}
		%		\caption{Overview}
		%	\end{subfigure}%
	%	\hfill
	\begin{subfigure}[t]{0.12\linewidth}
		\includegraphics[trim=0cm 0cm 0.3cm 0cm, clip,width=\linewidth]{figures/examples/materials/972k/gt_annot.png}
		\caption{GT}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[t]{0.12\linewidth}
		\includegraphics[trim=0cm 0cm 0.3cm 0cm, clip,width=\linewidth]{figures/examples/materials/972k/cut_3dgs_error.png}
		\caption{3DGS}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[t]{0.12\linewidth}
		\includegraphics[trim=0cm 0cm 0.3cm 0cm, clip,width=\linewidth]{figures/examples/materials/972k/cut_ots_marcher_error.png}
		\caption{OTS Marcher}
	\end{subfigure}%
	\begin{subfigure}[t]{0.12\linewidth}
		\includegraphics[trim=0cm 0cm 0.3cm 0cm, clip,width=\linewidth]{figures/examples/wdas_1/972k/gt_annot.png}
		\caption{Overview}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[t]{0.12\linewidth}
		\includegraphics[width=\linewidth]{figures/examples/wdas_1/972k/cut_gt.png}
		\caption{GT}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[t]{0.12\linewidth}
		\includegraphics[width=\linewidth]{figures/examples/wdas_1/972k/cut_3dgs.png}
		\caption{3DGS}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[t]{0.12\linewidth}
		\includegraphics[width=\linewidth]{figures/examples/wdas_1/972k/cut_ots_marcher.png}
		\caption{OTS Marcher}
	\end{subfigure}%
	\caption{(a--c)  \textsc{Materials} with 1M Gaussians:. Especially at grazing angles (object silhouettes), EWA-based approaches capture reflections more accurately, especially on object silhouettes, leading to lower squared error. (d--g) \textsc{WDAS Cloud} 1 scene with 1M Gaussians: Similar to \emph{Materials}, silhouettes are better captured with the more physically-inspired model. Squared error shown as insets.}
	\label{fig:example_materials}
\end{figure*}

An exception to this general trend can be observed in the \textsc{Materials} scene, where error metrics consistently favor the EWA-based methods OTS, OTS+SAtn, and OTS Marcher (see Table \ref{tab:results_materials_psnr}): %\BKmodif{WHY?}
Here, the image error is governed by reflections, especially at grazing angles on reflective objects (see Fig.~\ref{fig:example_materials}, left). This can be explained by the ability of EWA-based methods to produce Gaussians that are clearly visible at one angle (silhouettes), but see-through at others (frontal view) to model reflective Fresnel-like effects.% The contents of the reflection exhibit significantly higher spatial resolution than the rest of the scene.
%However, the resolution of the Gaussians was fixed at initialization due to the densification being disabled.
%Consequently, the OTS and marcher solutions benefit from their ability to operate with a reduced number of Gaussians.
%This is also visible in PSNR (Table \ref{tab:results_materials_psnr}).
% \GD{ADD the table with the numbers just for this scene}




% \begin{figure}
% \centering
% \begin{subfigure}[t]{0.5\linewidth}
%     \includegraphics[width=\linewidth]{figures/examples/gt_ship_annotated.png}
%     \caption{Ground truth}
% \end{subfigure}%
% \hfill
% \begin{subfigure}[t]{0.5\linewidth}
%     \includegraphics[width=\linewidth]{figures/examples/inria_splatter_ship_300k_cut.png}
%     \caption{3DGS}
% \end{subfigure}%
% \hfill
% \begin{subfigure}[t]{0.5\linewidth}
%     \includegraphics[width=\linewidth]{figures/examples/self_shadow_splatter_ship_300k_cut.png}
%     \caption{Self-shadowed splatter}
% \end{subfigure}%
% \hfill
% \begin{subfigure}[t]{0.5\linewidth}
% \includegraphics[width=\linewidth]{figures/examples/vol_marcher_ship_300k_cut.png}
% \caption{Volume marcher}
% \end{subfigure}
% \caption{Ship with 324k Gaussians. This view from the ship is only used in testing. The Gaussians floating over the ship deck are blended with the ship and water in the training views. When shown from the side, they are less visible using opacity compared to density. This is an advantage for the \GDmodif{original 3DGS} opacity formulation. \todo{update}}
% \label{fig:example_ship}
% \end{figure}


\newcommand{\first}[1]{\cellcolor{red!30}#1}

% Command for orange cell color
\newcommand{\second}[1]{\cellcolor{orange!30}#1}

% Command for yellow cell color
\newcommand{\third}[1]{\cellcolor{yellow!30}#1}


\begin{table}
		\caption{PSNR error metrics (db) for the \textsc{Materials} scene.}
  \scalebox{0.89}
	{
		\setlength{\tabcolsep}{3pt} % Adjust column separation (default is 6pt)
		\begin{tabular}{lr|r|r|r|r|r}
		\toprule
		& \multicolumn{6}{c}{Number of Gaussians} \\
		Algorithm & 4 000 & 12 000 & 36 000 & 100 000 & 330 000 & 1 000 000 \\
		\midrule
		3DGS & 22.48 & 24.42 & 26.23 & 27.74 & 28.81 & 29.54 \\
		3DGS + STP & 22.46 & 24.50 & 26.34 & 27.84 & 28.85 & 29.54 \\
		OTS & \second{23.65} & \second{25.62} & \first{27.28} & \third{28.51} & \third{29.43} & \second{29.95} \\
		OTS + SAtn & \third{23.59} & \third{25.61} & \second{27.26} & \first{28.59} & \second{29.44} & \first{29.96} \\
		3DGS marcher & 23.39 & 25.52 & 27.08 & 28.21 & 29.09 & 29.66 \\
		OTS marcher & \first{23.68} & \first{25.68} & \third{27.24} & \second{28.58} & \first{29.45} & \third{29.94} \\
		\bottomrule
		\end{tabular}
	}

	\label{tab:results_materials_psnr}
\end{table}

% \begin{figure}
% 	\centering
% 	\begin{subfigure}[t]{0.5\linewidth}
% 		\includegraphics[width=\linewidth]{figures/examples/wdas_1/972k/gt_annot.png}
% 		\caption{Overview}
% 	\end{subfigure}%
% 	\hfill
% 	\begin{subfigure}[t]{0.5\linewidth}
% 		\includegraphics[width=\linewidth]{figures/examples/wdas_1/972k/cut_gt.png}
% 		\caption{GT}
% 	\end{subfigure}%
% 	\hfill
% 	\begin{subfigure}[t]{0.5\linewidth}
% 		\includegraphics[width=\linewidth]{figures/examples/wdas_1/972k/cut_3dgs.png}
% 		\caption{3DGS}
% 	\end{subfigure}%
% 	\hfill
% 	\begin{subfigure}[t]{0.5\linewidth}
% 		\includegraphics[width=\linewidth]{figures/examples/wdas_1/972k/cut_ots_marcher.png}
% 		\caption{OTS marcher}
% 	\end{subfigure}%
% 	\caption{WDAS Cloud 1 scene with 1m Gaussians: This highly transparent scene is the only one where the OTS marcher maintains an advantage up to 1m Gaussians. In this case, the more physically accurate model proves beneficial.}
% 	\label{fig:example_wdas1}
% \end{figure}

\paragraph*{3DGS-Based vs. EWA-Based Rendering}
Our test results show that for a small number of Gaussians, the EWA-based splatting solutions---OTS and OTS+SAtn---perform better than 3DGS-based splatting, closely matching the advantage of the slower ray-marching methods.
This aligns with the above trends: enforcing volumetric rendering properties yields better results with fewer Gaussians.
However, there is no discernible difference between OTS and OTS+SAtn, suggesting that self-attenuation is negligible for reconstruction quality.
As before, increasing the number of Gaussians eventually gives 3DGS-based splatting an advantage: It can more easily produce fine anisotropic structures (e.g., stripes, poles, branches) with identical opacity from all directions, which is particularly useful when modeling solid objects.
Accordingly, the volumetric, low-density \textsc{WDAS Cloud 1} scene is an exception to this trend: here, the more principled, EWA-based variants show an advantage regardless of model size (Fig.~\ref{fig:example_materials}, right).

We observe similar results when comparing the 3DGS Marcher and OTS Marcher: while the latter performs slightly better for small models, it is eventually surpassed as the model size grows. These results seem to confirm that 3DGS-based rendering---i.e., preserving a Gaussian's amplitude across views---is more effective in large models than conventional volumetric integration.

%A concrete example of this can be seen in Fig.~\ref{fig:example_ship}, where floating artifacts are less visible for the original 3DGS approach for 330K Gaussians and in Fig.~\ref{fig:example_burning_ficus} where EWA-based method have an advantage with 4K primitives.
%Contrary to our intuition, the effect is less pronounced on the volumetric scenes.


% \subsection{Sorting and Overlap with OTS}
% \GD{We also,} % we 
% compare the OTS based splatting methods with volume marching.
% We see no conclusive difference between the methods.
% In this setting, the accurate integration method doesn't seem to make a difference\GD{. However, we do not measure popping.} \GD{Shouldnt this be below?}

% \subsection{Sorting and Overlap with 3DGS}
% There is no significant difference between 3DGS and STP regardless the number of Gaussians, indicating that the error measures are not suitable for measuring popping. % (no surprise).
% Comparing these two \GD{methods} to volume marching with the 3DGS formulation, we see, that correct treatment of overlap significantly improves the results for a low number of Gaussians.
% For a large number of Gaussian, pure 3DGS is best again.

\revision{

\subsection{Training and Rendering Performance}
Our ray marching implementations are intended to provide guidelines or achievable quality with correct volume rendering and are not optimized, thus training a single scene can take several hours. All splatting methods require similar computation time (10--20 minutes for training), however, we assess more nuanced differences to identify potential tradeoffs and benefits in particular settings: OTS trains the fastest consistently, with a 3\% \emph{speedup} compared to 3DGS. For small models (4k), OTS+SAtn optimizes 3\% slower than 3DGS on average; 
Its overhead gradually rises as models become larger and plateaus at 10\% for 1M Gaussians.
During rendering, OTS and OTS+SAtn are, on average, 28\% and 43\% slower, respectively, across all scenes.
No trend with regard to number of Gaussians is visible.
%\todo{continue}
%We did not find these figures significantly affected by image resolution; hence, using OTS+SAtn for its higher quality on fewer Gaussians only incurs a slight overhead during optimization, and none for inference. Using OTS instead of 3DGS for few Gaussians even \emph{accelerates} training and rendering, along with higher quality.
}

\revision{
\section{Limitations and Future Work}
Our evaluation investigated quality and performance on small-scale scenes because they explicitly do not require \emph{densification}. %This is intentional: 
Our assessment considers multiple parameters, (opacity vs. density, overlap, and self-attenuation) whose impact we want to isolate and quantify. Densification introduces complexity that aggravates objective conclusions, e.g., 3DGS densification is governed by gradient magnitude, and thus can yield different numbers of Gaussians for techniques with different gradient flow. However, we provide tentative results for larger scenes in our supplemental material. 

We also did not explore specialized use cases (relighting, sparse captures, dynamic scenes) where our new variants could potentially exceed previous work; This analysis is beyond the scope of this paper. However, the increased accuracy in the \textsc{Materials} scene suggests that EWA-based splatting helps reconstruct extreme material properties and thus might benefit inverse rendering use cases.
}

\section{Discussion and Conclusion}

Our in-depth analysis of Gaussian-primitive rendering approaches allowed us to clarify the distinction between using volumetric extinction (EWA-based) and ``opacity'' (3DGS-based) rendering in clear mathematical terms, which had caused significant confusion in the past. We also clearly identified several other approximations used in 3DGS. 
To allow careful experimental analysis of the effect of each approximation, we defined a set of algorithms which progressively replaced each approximation used in 3DGS with the principled volumetric rendering approach.
%This analysis allowed to define a set of image formation algorithms, 
%which we used to experimentally evaluate the effect of approximations %used in 3DGS for optimizing novel-view synthesis. 

A key insight of this analysis is that accurate integration of Gaussians (e.g., using ray marching) provides advantages for a low number of Gaussians.
However, our results also show that, in practice, the advantage of these slow, principled methods in small models is closely matched by our EWA-based splatting method (OTS), preserving the rendering and optimization speed of the original 3DGS.

%In order to avoid popping, it should be combined with STP.
On the other hand, our experiments show that using the simpler splatters and ``opacity''-based models provides better results as the number of Gaussians increases.
We hypothesize that this behavior is due to the simpler approach providing a more opportunistic optimization landscape, exploiting, e.g., discontinuities to model finer details.
Thus, rather than using a complex, principled image formation, 3DGS relies on using larger models, paired with an inexpensive extinction function and a more approximate visibility resolution, which turns out to be most effective with more primitives.

Our analysis provides the mathematical foundation for understanding how 3DGS relates to volume rendering, offering insight into the effectiveness of the algorithm. We hope that our analysis will lead to further theoretical and practical developments, e.g., allowing interoperability between NeRF and 3DGS representations.

\section{Acknowledgments}
G. Drettakis was supported by the ERC Advanced Grant FUNGRAPH (788065, \url{https://project.inria.fr/fungraph}), and acknowledges support from NVIDIA and Adobe.

%-------------------------------------------------------------------------
% bibtex
\bibliographystyle{eg-alpha-doi} 
\bibliography{article}       

% biblatex with biber
% \printbibliography  


\end{document}

