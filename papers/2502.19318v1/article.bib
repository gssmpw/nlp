

@InCollection{max_et_al,
  author =	{Max, Nelson and Chen, Min},
  title =	{{Local and Global Illumination in the Volume Rendering Integral}},
  booktitle =	{Scientific Visualization: Advanced Concepts},
  pages =	{259--274},
  series =	{Dagstuhl Follow-Ups},
  ISBN =	{978-3-939897-19-4},
  ISSN =	{1868-8977},
  year =	{2010},
  volume =	{1},
  editor =	{Hagen, Hans},
  publisher =	{Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{https://drops.dagstuhl.de/entities/document/10.4230/DFU.SciViz.2010.259},
  URN =		{urn:nbn:de:0030-drops-27090},
  doi =		{10.4230/DFU.SciViz.2010.259},
  annote =	{Keywords: Volume Rendering, Illumination Model}
}

@article{zhou2024unified,
  title={Unified Gaussian Primitives for Scene Representation and Rendering},
  author={Zhou, Yang and Wu, Songyin and Yan, Ling-Qi},
  journal={arXiv preprint arXiv:2406.09733},
  year={2024}
}

@inproceedings{yu2021plenoctrees,
      title={{PlenOctrees} for Real-time Rendering of Neural Radiance Fields},
      author={Alex Yu and Ruilong Li and Matthew Tancik and Hao Li and Ren Ng and Angjoo Kanazawa},
      year={2021},
      booktitle={ICCV},
}
@article{Andersson2020,
  author    = {Pontus Andersson and
               Jim Nilsson and
               Tomas Akenine{-}M{\"{o}}ller and
               Magnus Oskarsson and
               Kalle {\AA}str{\"{o}}m and
               Mark D. Fairchild},
  title     = "{FLIP: {A} Difference Evaluator for Alternating Images}",
  journal   = {Proceedings of the ACM on Computer Graphics and Interactive Techniques},
  volume    = {3},
  number    = {2},
  pages     = {15:1--15:23},
  year      = {2020},
  doi={10.1145/3406183}
}

@article{SMERF,
author = {Duckworth, Daniel and Hedman, Peter and Reiser, Christian and Zhizhin, Peter and Thibert, Jean-Fran\c{c}ois and Lu\v{c}i\'{c}, Mario and Szeliski, Richard and Barron, Jonathan T.},
title = {SMERF: Streamable Memory Efficient Radiance Fields for Real-Time Large-Scene Exploration},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3658193},
doi = {10.1145/3658193},
abstract = {Recent techniques for real-time view synthesis have rapidly advanced in fidelity and speed, and modern methods are capable of rendering near-photorealistic scenes at interactive frame rates. At the same time, a tension has arisen between explicit scene representations amenable to rasterization and neural fields built on ray marching, with state-of-the-art instances of the latter surpassing the former in quality while being prohibitively expensive for real-time applications. We introduce SMERF, a view synthesis approach that achieves state-of-the-art accuracy among real-time methods on large scenes with footprints up to 300 m2 at a volumetric resolution of 3.5 mm3. Our method is built upon two primary contributions: a hierarchical model partitioning scheme, which increases model capacity while constraining compute and memory consumption, and a distillation training strategy that simultaneously yields high fidelity and internal consistency. Our method enables full six degrees of freedom navigation in a web browser and renders in real-time on commodity smartphones and laptops. Extensive experiments show that our method exceeds the state-of-the-art in real-time novel view synthesis by 0.78 dB on standard benchmarks and 1.78 dB on large scenes, renders frames three orders of magnitude faster than state-of-the-art radiance field models, and achieves real-time performance across a wide variety of commodity devices, including smartphones. We encourage readers to explore these models interactively at our project website: https://smerf-3d.github.io.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {63},
numpages = {13},
keywords = {neural radiance fields, volumetric representation, image synthesis, real-time rendering, deep learning}
}



@article{MERF,
author = {Reiser, Christian and Szeliski, Rick and Verbin, Dor and Srinivasan, Pratul and Mildenhall, Ben and Geiger, Andreas and Barron, Jon and Hedman, Peter},
title = {MERF: Memory-Efficient Radiance Fields for Real-time View Synthesis in Unbounded Scenes},
year = {2023},
issue_date = {August 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3592426},
doi = {10.1145/3592426},
abstract = {Neural radiance fields enable state-of-the-art photorealistic view synthesis. However, existing radiance field representations are either too compute-intensive for real-time rendering or require too much memory to scale to large scenes. We present a Memory-Efficient Radiance Field (MERF) representation that achieves real-time rendering of large-scale scenes in a browser. MERF reduces the memory consumption of prior sparse volumetric radiance fields using a combination of a sparse feature grid and high-resolution 2D feature planes. To support large-scale unbounded scenes, we introduce a novel contraction function that maps scene coordinates into a bounded volume while still allowing for efficient ray-box intersection. We design a lossless procedure for baking the parameterization used during training into a model that achieves real-time rendering while still preserving the photorealistic view synthesis quality of a volumetric radiance field.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {89},
numpages = {12},
keywords = {neural radiance fields, volumetric representation, image synthesis, real-time rendering, deep learning}
}



@article{mueller2022instant,
    author = {Thomas M\"uller and Alex Evans and Christoph Schied and Alexander Keller},
    title = {Instant Neural Graphics Primitives with a Multiresolution Hash Encoding},
    journal = {ACM Trans. Graph.},
    issue_date = {July 2022},
    volume = {41},
    number = {4},
    month = jul,
    year = {2022},
    pages = {102:1--102:15},
    articleno = {102},
    numpages = {15},
    url = {https://doi.org/10.1145/3528223.3530127},
    doi = {10.1145/3528223.3530127},
    publisher = {ACM},
    address = {New York, NY, USA},
}

@article{barron2022mipnerf360,
    title={Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields},
    author={Jonathan T. Barron and Ben Mildenhall and 
            Dor Verbin and Pratul P. Srinivasan and Peter Hedman},
    journal={CVPR},
    year={2022}
}

@inproceedings{Novak18Course,
	author 		= {Nov\'{a}k, Jan and Georgiev, Iliyan and Hanika, Johannes and K\v{r}iv\'{a}nek, Jaroslav and Jarosz, Wojciech},
	title 		= {Monte Carlo Methods for Physically Based Volume Rendering},
	booktitle 	= {ACM SIGGRAPH 2018 Courses},
	series 		= {SIGGRAPH '18},
	year 		= {2018},
	isbn 		= {978-1-4503-5809-5},
	location 	= {Vancouver, British Columbia, Canada},
	pages 		= {14:1--14:1},
	articleno 	= {14},
	numpages 	= {1},
	url 		= {http://doi.acm.org/10.1145/3214834.3214880},
	doi 		= {10.1145/3214834.3214880},
	publisher 	= {ACM},
	address 	= {New York, NY, USA},
}

@article{3dgrt2024,
    author = {Moenne-Loccoz, Nicolas and Mirzaei, Ashkan and Perel, Or and de Lutio, Riccardo and Martinez Esturo, Janick and State, Gavriel and Fidler, Sanja and Sharp, Nicholas and Gojcic, Zan},
    title = {{3D Gaussian Ray Tracing}: Fast Tracing of Particle Scenes},
    journal = {ACM Transactions on Graphics},
    year = {2024},
}

@misc{condor2024dontsplatgaussiansvolumetric,
      title={Don't Splat your Gaussians: Volumetric Ray-Traced Primitives for Modeling and Rendering Scattering and Emissive Media}, 
      author={Jorge Condor and Sebastien Speierer and Lukas Bode and Aljaz Bozic and Simon Green and Piotr Didyk and Adrian Jarabo},
      year={2024},
      eprint={2405.15425},
      archivePrefix={arXiv},
      primaryClass={cs.GR},
      url={https://arxiv.org/abs/2405.15425}, 
}
@misc{blanc2024raygaussvolumetricgaussianbasedray,
      title={RayGauss: Volumetric Gaussian-Based Ray Casting for Photorealistic Novel View Synthesis}, 
      author={Hugo Blanc and Jean-Emmanuel Deschaud and Alexis Paljic},
      year={2024},
      eprint={2408.03356},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.03356}, 
}
@misc{zhou2024unifiedgaussianprimitivesscene,
      title={Unified Gaussian Primitives for Scene Representation and Rendering}, 
      author={Yang Zhou and Songyin Wu and Ling-Qi Yan},
      year={2024},
      eprint={2406.09733},
      archivePrefix={arXiv},
      primaryClass={cs.GR},
      url={https://arxiv.org/abs/2406.09733}, 
}

@inproceedings{huang2024erroranalysis3dgaussian,
    title={On the Error Analysis of 3D Gaussian Splatting and an Optimal Projection Strategy},
    author={Letian Huang and Jiayang Bai and Jie Guo and Yuanqi Li and Yanwen Guo},
 booktitle={ECCV},
    year={2024}
}

@inproceedings{kopanas2021point,
  title={Point-Based Neural Rendering with Per-View Optimization},
  author={Kopanas, Georgios and Philip, Julien and Leimk{\"u}hler, Thomas and Drettakis, George},
  booktitle={Computer Graphics Forum},
  volume={40},
  number={4},
  pages={29--43},
  year={2021},
  organization={Wiley Online Library}
}

@inproceedings{zhang2022differentiable,
  title={Differentiable point-based radiance fields for efficient view synthesis},
  author={Zhang, Qiang and Baek, Seung-Hwan and Rusinkiewicz, Szymon and Heide, Felix},
  booktitle={SIGGRAPH Asia 2022 Conference Papers},
  pages={1--12},
  year={2022}
}

@inproceedings{wiles2020synsin,
  title={Synsin: End-to-end view synthesis from a single image},
  author={Wiles, Olivia and Gkioxari, Georgia and Szeliski, Richard and Johnson, Justin},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={7467--7477},
  year={2020}
}

@inproceedings{lassner2021pulsar,
  title={Pulsar: Efficient sphere-based neural rendering},
  author={Lassner, Christoph and Zollhofer, Michael},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1440--1449},
  year={2021}
}

@article{dalal2024gaussian,
  title={Gaussian Splatting: 3D Reconstruction and Novel View Synthesis, a Review},
  author={Dalal, Anurag and Hagen, Daniel and Robbersmyr, Kjell G and Knausg{\aa}rd, Kristian Muri},
  journal={arXiv preprint arXiv:2405.03417},
  year={2024}
}

@article{wu2024recent,
  title={Recent advances in 3d gaussian splatting},
  author={Wu, Tong and Yuan, Yu-Jie and Zhang, Ling-Xiao and Yang, Jie and Cao, Yan-Pei and Yan, Ling-Qi and Gao, Lin},
  journal={arXiv preprint arXiv:2403.11134},
  year={2024}
}

@article{fei20243d,
  title={3D Gaussian as a New Vision Era: A Survey},
  author={Fei, Ben and Xu, Jingyi and Zhang, Rui and Zhou, Qingyuan and Yang, Weidong and He, Ying},
  journal={arXiv preprint arXiv:2402.07181},
  year={2024}
}

@article{Yifan:DSS:2019, 
    author = {Yifan, Wang and
              Serena, Felice and
              Wu, Shihao and
              {\"{O}}ztireli, Cengiz and
              Sorkine{-}Hornung, Olga},
    title = {Differentiable Surface Splatting for Point-based Geometry Processing}, 
    journal = {ACM Transactions on Graphics (proceedings of ACM SIGGRAPH ASIA)}, 
    volume = {38}, 
    number = {6}, 
    year = {2019}, 
}

@article{chen2024survey,
  title={A survey on 3d gaussian splatting},
  author={Chen, Guikun and Wang, Wenguan},
  journal={arXiv preprint arXiv:2401.03890},
  year={2024}
}

@article{huang2023photo,
  title={Photo-slam: Real-time simultaneous localization and photorealistic mapping for monocular, stereo, and rgb-d cameras},
  author={Huang, Huajian and Li, Longwei and Cheng, Hui and Yeung, Sai-Kit},
  journal={arXiv preprint arXiv:2311.16728},
  year={2023}
}

@article{seiskari2024gaussian,
  title={Gaussian Splatting on the Move: Blur and Rolling Shutter Compensation for Natural Camera Motion},
  author={Seiskari, Otto and Ylilammi, Jerry and Kaatrasalo, Valtteri and Rantalankila, Pekka and Turkulainen, Matias and Kannala, Juho and Rahtu, Esa and Solin, Arno},
  journal={arXiv preprint arXiv:2403.13327},
  year={2024}
}

@article{yu2023mip,
  title={Mip-splatting: Alias-free 3d gaussian splatting},
  author={Yu, Zehao and Chen, Anpei and Huang, Binbin and Sattler, Torsten and Geiger, Andreas},
  journal={arXiv preprint arXiv:2311.16493},
  year={2023}
}

@inproceedings{lee2024gscore,
  title={GSCore: Efficient Radiance Field Rendering via Architectural Support for 3D Gaussian Splatting},
  author={Lee, Junseo and Lee, Seokwon and Lee, Jungi and Park, Junyong and Sim, Jaewoong},
  booktitle={Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
  pages={497--511},
  year={2024}
}

@article{bolanos2024gaussian,
  title={Gaussian Shadow Casting for Neural Characters},
  author={Bolanos, Luis and Su, Shih-Yang and Rhodin, Helge},
  journal={arXiv preprint arXiv:2401.06116},
  year={2024}
}

@article{guedon2023sugar,
  title={Sugar: Surface-aligned gaussian splatting for efficient 3d mesh reconstruction and high-quality mesh rendering},
  author={Gu{\'e}don, Antoine and Lepetit, Vincent},
  journal={arXiv preprint arXiv:2311.12775},
  year={2023}
}

@article{heckbert1989fundamentals,
  title={Fundamentals of texture mapping and image warping},
  author={Heckbert, Paul S},
  year={1989},
  publisher={Citeseer}
}

@article{radl2024stopthepop,
  author    = {Radl, Lukas and Steiner, Michael and Parger, Mathias and Weinrauch, Alexander and Kerbl, Bernhard and Steinberger, Markus},
  title     = {{StopThePop: Sorted Gaussian Splatting for View-Consistent Real-time Rendering}},
  journal   = {ACM Transactions on Graphics},
  number    = {43},
  volume    = {4},
  articleno = {64},
  year      = {2024},
}

@inproceedings{mildenhall2020nerf,
 title={NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis},
 author={Ben Mildenhall and Pratul P. Srinivasan and Matthew Tancik and Jonathan T. Barron and Ravi Ramamoorthi and Ren Ng},
 year={2020},
 booktitle={ECCV},
}

@book{PBRT3e,
    title = {Physically Based Rendering: From Theory to Implementation (3rd ed.)},
    author = {Matt Pharr and Wenzel Jakob and Greg Humphreys},
    isbn = {9780128006450},
    pages = {1266},
    year = {2016},
    month = oct,
    edition = {3rd},
    publisher = {Morgan Kaufmann Publishers Inc.},
    address = {San Francisco, CA, USA}
}

@ARTICLE{Max95,
  author={Max, N.},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Optical models for direct volume rendering}, 
  year={1995},
  volume={1},
  number={2},
  pages={99-108},
  keywords={Optical scattering;Light scattering;X-ray scattering;Stimulated emission;Absorption;Interpolation;Optical computing;Rendering (computer graphics);Grid computing;Computational modeling},
  doi={10.1109/2945.468400}}


@Article{kerbl3Dgaussians,
      author       = {Kerbl, Bernhard and Kopanas, Georgios and Leimk{\"u}hler, Thomas and Drettakis, George},
      title        = {3D Gaussian Splatting for Real-Time Radiance Field Rendering},
      journal      = {ACM Transactions on Graphics},
      number       = {4},
      volume       = {42},
      month        = {July},
      year         = {2023}
}
@article{ewa_splatting,
  title={EWA splatting},
  author={Zwicker, Matthias and Pfister, Hanspeter and Van Baar, Jeroen and Gross, Markus},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  volume={8},
  number={3},
  pages={223--238},
  year={2002},
  publisher={IEEE}
}

@article{zeltner2021monte,
  title={Monte Carlo estimators for differential light transport},
  author={Zeltner, Tizian and Speierer, S{\'e}bastien and Georgiev, Iliyan and Jakob, Wenzel},
  journal={ACM Transactions on Graphics (TOG)},
  volume={40},
  number={4},
  pages={1--16},
  year={2021},
  publisher={ACM New York, NY, USA}
}
