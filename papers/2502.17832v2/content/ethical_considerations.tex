\section{Ethical Considerations}
% Not included in the page limit

Our work highlights a critical vulnerability in multimodal RAG systems by demonstrating knowledge poisoning attacks. While we show that even partial or black-box access can be leveraged to degrade multimodal RAG system performance and the authenticity of its generated outputs, our intent is to inform the research community and practitioners about the risks of blindly relying on external knowledge sources, e.g., KBs, that can be tampered with. We neither advocate malicious exploitation of these vulnerabilities nor release any tools designed for real-world harm. All experiments are conducted on public datasets with no user-identifying information. Our study underscores the importance of continued research on securing retrieval-augmented models in rapidly growing fields such as multimodal RAG frameworks.