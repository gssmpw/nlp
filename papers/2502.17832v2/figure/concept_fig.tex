
\begin{figure*}[!t]
\centering
    \includegraphics[width=\textwidth]{figure/files/two_settings_final.pdf}
    % \begin{minipage}[t]{0.51\textwidth}
    % \centering
    % \includegraphics[width=\textwidth]{figure/files/figure1.pdf}
    %  \subcaption{Poisoned Data Generation.}
    %  \label{fig:data_gen}
    % \end{minipage}    
    % \begin{minipage}[t]{0.48\textwidth}
    % \centering
    % \includegraphics[width=\textwidth]{figure/files/figure2.pdf}
    %  \subcaption{Multimodal RAG with Poisoning Attack.}
    %  \label{fig:mllm_rag}
    % \end{minipage}
    
    
\caption{\textbf{Poisoning Attack against Multimodal RAG Framework.} \textsc{MM-PoisonRAG} injects adversarial knowledge into the multimodal KB, causing the retriever to retrieve poisoned knowledge, which then cascades through the reranker and generator, ultimately leading to incorrect outputs. \textsc{MM-PoisonRAG} consists of two attack strategies: (1) \textit{Localized Poisoning Attack} generates query-specific misinformation, guiding the generator to produce an attacker-controlled answer (e.g., \texttt{Red}). (2) \textit{Globalized Poisoning Attack} introduces a single nonsensical knowledge entry, forcing the generator to produce a random incorrect answer (e.g., \texttt{Sorry}) for all queries.} 
% \violet{it's unclear to me what's the query for your retriever and why the poisoned image will be retrieved.}

\label{fig:concept_fig}
% \vspace{-0.05in}
\end{figure*}