\documentclass[twoside]{article}

\usepackage{aistats2025}
\usepackage[english]{babel}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{dsfont}
\usepackage{outlines}
\usepackage{float}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage[round]{natbib}
\renewcommand{\bibname}{References}
\renewcommand{\bibsection}{\subsubsection*{\bibname}}

\bibliographystyle{plainnat}
%\bibliography{bibliography} % don't remove this line 
% \addbibresource{bibliography.bib}
%\usepackage[backend=biber, style=alphabetic,]{biblatex}
% If your paper is accepted, change the options for the package
% aistats2024 as follows:
%
%\usepackage[accepted]{aistats2024}
%
% This option will print headings for the title of your paper and
% headings for the authors names, plus a copyright note at the end of
% the first column of the first page.

% If you set papersize explicitly, activate the following three lines:
%\special{papersize = 8.5in, 11in}
%\setlength{\pdfpageheight}{11in}
%\setlength{\pdfpagewidth}{8.5in}

% If you use natbib package, activate the following three lines:
%\usepackage[round]{natbib}
%\renewcommand{\bibname}{References}
%\renewcommand{\bibsection}{\subsubsection*{\bibname}}

% If you use BibTeX in apalike style, activate the following line:
%\bibliographystyle{apalike}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem*{remark}{Remark}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}


% Custom operators/commands
\input{preamble2.tex}

\newcommand{\D}{\mathcal{D}}
\newcommand{\TPR}{\mathrm{TPR}} % True Positive Rate (e.g. Sensitivity, Recall)
\newcommand{\TNR}{\mathrm{TNR}} % True Negative Rate
\newcommand{\FPR}{\mathrm{FPR}} % False Positive Rate
\newcommand{\FNR}{\mathrm{FNR}} % False Negative Rate

\newcommand{\FSD}{\succeq_1}    % first-order stochastic dominance
% independence, from https://tex.stackexchange.com/questions/79434/double-perpendicular-symbol-for-independence
\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}

\usepackage{xcolor}
\newcommand{\jack}[1]{{\color{teal} \sf [Jack: #1]}}
\newcommand{\judy}[1]{{\color{violet} \sf [Judy: #1]}}



\newcommand{\support}{\textrm{supp}}



\begin{document}
% \BOGO{consistent pronouns for Hirer?}
% \BOGO{when do we say ''candidate'' vs ''Applicant''?}

% If your paper is accepted and the title of your paper is very long,
% the style will print as headings an error message. Use the following
% command to supply a shorter title of your paper so that it can be
% used as headings.
%
%\runningtitle{I use this title instead because the last one was very long}

% If your paper is accepted and the number of authors is large, the
% style will print as headings an error message. Use the following
% command to supply a shorter version of the authors names so that
% they can be used as headings (for example, use only the surnames)
%
%\runningauthor{Surname 1, Surname 2, Surname 3, ...., Surname n}

\twocolumn[

\aistatstitle{Two Tickets are Better than One: Fair and Accurate Hiring Under Strategic LLM Manipulations}

\aistatsauthor{ Lee Cohen \And Jack Hsieh \And Connie Hong \And Judy Hanwen Shen }

\aistatsaddress{ Stanford University } ]

%\BOGO{nice to have if we have time: generalization bounds?}
%\BOGO{for C\&J: short connection to outcome distinguishability: provide definition. baseline (i.e. analogue for real life) is privileged group}

%\BOGO{introduce general hiring system/policy?, introduce two-ticket, elaborate on outcome indistinguishability in theory section. mention it (with a figure?) again in empirical (move to appendix if needed for this)}



% \lc{Alternative title ideas:\\
% Strategic Classification in the Era of LLMs: Two Tickets are Better and Fairer Than One\\
% Fool Me Once, I'll Test Twice: A Two-Ticket Framework for Fair and Accurate Screening in the LLM Era

%CURIS poster title: Algorithmic Fairness in  Hiring: A Two-Ticket Scheme for Equity with LLMs?

%llms, strat classification, two tickets, improvements (accuracte & fair)

%
% Two Tickets are Better than One: Fair and Accurate Hiring Under Strategic LLM Manipulations  


% A two-ticket scheme for fair and accurate hiring under LLM manipulation 
% }
\begin{abstract}
 

%\lc{[Lee- slightly more detailed version:] 
In an era of increasingly capable large language models (LLMs), job seekers are turning to generative AI tools to enhance their application materials. However, unequal access to LLMs can harm both employers and applicants by reducing accuracy and exacerbating fairness disparities. To address these challenges, we introduce a new variant of the strategic classification framework tailored for manipulations performed using LLMs. We propose a ``two-ticket'' system, where the hiring algorithm applies an additional LLM manipulation to each submitted application and considers this modified version together with the original submitted application. We establish theoretical guarantees for this system in a stochastic setting, showing that it improves both the fairness and accuracy of hiring decisions when the true positive rate is maximized subject to no false positives. Finally, we empirically validate the performance of our system on real resumes using an open-source applicant tracking system for resume screening.



%\lc{
%[Old version with minor corrections:] Can resumes generated by large-language models (LLMs) increase the chances of success for job applicants? At what fairness cost does it give advantages to well-resourced job applicants? To combat these urgent issues of accuracy and fairness in an era where generative models growingly influence application materials, we propose (1) a strategic-classification informed model to understand and analyze the dynamics in text-based applications (e.g., hiring) hiring and generative content. With this formulated model, we also propose (2) a “two-ticket” system that suggests the dual evaluation of submitted applications, along with generative model edit versions can inform better fairness, and in some scenarios, even better hiring accuracy.}
   % Can resumes generated by large-language models (LLMs) increase the chances of success for job applicants, but also unfairly give advantages to previously unqualified, but well-resourced job applicants? To combat these urgent issues of accuracy and fairness in an era where generative models growingly influence application materials, we propose (1) a strategic-classification informed model to understand and model the dynamics in hiring and generative content. With this formulated model, we also propose that (2) a “two-ticket” system that suggests the dual evaluation of submitted applications, along with generative model edit versions can inform better fairness, and in some scenarios, even better hiring accuracy.
\end{abstract}
%\BOGO{for C\&J: one-paragraph, directs us toward the right reviewers}

\section{Introduction}

% introduce the importance of algorithmic hiring
    Hiring decisions can profoundly impact an individual's professional path and long-term success. As algorithmic tools are increasingly deployed to recommend or make these decisions, they have rightfully come under scrutiny from economists~\citep{van2020hiring}, journalists~\citep{Lytton.2024}, and policymakers~\citep{cityofny}. Incorporating AI tools that may exhibit undue biases and unexplainable behavior is a major challenge in achieving accountability in these algorithmic hiring systems~\citep{amazon_ai_bias}.  %\textcolor{blue}{Lee: we could add something like this commented link, maybe even in a footnote:} % https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK0AG/
% discuss added complexity of generated content

    While algorithmic hiring systems are designed with the goal of hiring the best candidates, these systems may not be robust to candidates manipulating their application materials~\citep{ats_hack}. This problem has been studied through the lens of strategic classification where the goal is to design a strategy-proof selection algorithm~\citep{Hardt2015,kleinberg2020classifiers, levanon2021strategic}. 
    With the recent proliferation of generative AI services now widely used by job seekers, a new variable in the algorithm hiring cycle has been introduced. 
    %\textcolor{blue}{Lee: how about we start by describing LLMs in the context of strategic classification+hiring, then move to fairness?} 
    Specifically, inequality may now also arise when job candidates have unequal access to different tiers of Large Language model (LLM) services. Job candidates who are able to access more premium LLM services may achieve unfair advantage in the screening stage of automatic hiring algorithms. While job seekers have long had access to varying levels of support from spell checkers to career coaches, the strategic improvement of application materials may be more prevalent than ever before. Moreover, the interactions between hiring algorithms and (often stochastic) application-enhancing generative AI tools emerge as a unique setting to examine equity and strategic behavior. For example, recent works have found that LLMs as judges will favor responses generated by the same model~\citep{panickssery2024llm}.

    % discuss the need to study strategic manipulation and outline our contributions
    Motivated by this complex yet realistic interaction between generated applicant materials and algorithmic hiring algorithms, our work presents a first step into modeling and analyzing algorithmic hiring ecosystems in the era of generative AI. In summary, our contributions are as follows: 
    \begin{itemize}
        \item We translate the empirical behavior of LLMs used for job applications into a bespoke model of strategic classification (Section \ref{sec: model}).  
        
        \item 
        %We prove that existing resume screening systems may result in disparate outcomes for candidates who do not have access to the best LLMs. 
        We show theoretically and empirically that under existing hiring systems, disparity in access to LLMs leads to disparity in hiring outcomes, even under \textit{stochastic} manipulations (\Cref{sec: disparities}).
        
        \item We introduce a two-ticket system that guarantees smaller outcome disparities among applicants and higher hiring accuracy for employers (Section \ref{sec: two-ticket system}). 
        
        % \item We are the first to provide theoretical guarantees for \textit{stochastic} manipulation  in $\R^d$ for any $d\in \N$ (\Cref{sec: model,sec: two-ticket system}).
        
        \item We validate our theoretical model and results through a case study using real resumes and an open-source resume screening system (\Cref{sec: empirical experiments}).
    \end{itemize}
    
    %First, we motivate our analysis with an empirical justification of how applying LLM modifications can improve resumes from the lens of a resume screening model. We then show how existing score based resume systems are not robust to these manipulations and cause disparate outcomes for groups who cannot access LLM modifications. Finally, we propose a two-ticket scheme that achieves... 

    %\BOGO{add bullet points here to clearly highlight contributions}

    %While prior works have focused on the biases arising from automating different stages of the hiring process, 
    
    %Classification algorithms have long supported hiring processes: specifically, they are used to properly categorize and identify attributes from input data points. Practicing fair hiring and screening is challenging given the increasingly large volume of applications. Moreover, choices made by candidates can interfere with classification outcomes --- a phenomenon known as the ``strategic classification'' problem.
    %\newline\linebreak
    %The recent proliferation of accessible generative AI further complicates strategic choices and classification in hiring. Using models such as GPT-3.5 and LlaMA, candidates can further subvert traditional hiring systems by presentting LLM-generated application materials. This introduces two interconnected wrinkles to strategic classification. The first is the increasing homogeneity of application materials. Repeated interactions with LLMs can produce more lexically homogeneous writing \cite{padmakumar2024does}, potentially making it harder for a hiring firm to distinguish between candidates. The second is greater ease of manipulation. LLMs allow candidates to more easily edit their application materials for a specific job, further homogenizing application quality.

\section{Related Work} \label{sec: related work}

\textbf{Fairness in Algorithmic Hiring} Studies both before and after the adoption of online hiring platforms have consistently found discrimination in hiring outcomes based on race, gender, and age~\citep{bertrand2004emily, kline2022systemic}.  \cite{raghavan2020mitigating} study the screening stage of algorithmic hiring algorithms. These studies connect legal perspectives from hiring law with algorithmic approaches to mitigating disparate impact. In fact, mitigating biases has been described as crucial to ``ethicality of the AI tool design''~\citep{hunkenschroer2022ethics}. As far as proposed solutions, \cite{lin2021engineering} suggest ``augmentation-based" interventions where AI-assisted decision can best achieve equitable outcomes. 

\textbf{Strategic Classification}
Strategic Classification was initially introduced in the form of a Stackelberg game in ~\cite{Hardt2015} to address the impact of manipulative tactics on classification problems. Since then, several works have provided a modified Strategic Manipulation game that model disparities in manipulation abilities~\citep{Hu2019, milli2019social, chen2020strategic}, which we drew upon in our work. Furthermore, we utilize techniques from \cite{Braverman2020} to describe ``random'' classifiers in light of non-deterministic strategic manipulations. 

\textbf{Behavior and Risks of Generative Models} While guidance counselors and career coaches alike now recommend using generative AI tools to help with application materials~\citep{Verma_Renjarla_2024, Chamorro_2024} despite a plethora of risks highlighted by recent research. For example, LLMs have been shown to hallucinate which may mislead employers~\citep{huang2023survey} or memorize text which can result in unintended plagiarism~\citep{carlini2022quantifying}. These behaviors are hard to anticipate a priori; thus the benefits of applying LLMs to application materials may be stochastic. 

% Hallucinations
% Memorization
% Stochastic 
% Responsible usage policies 
% Lack of diversity

% maybe 5-ish
%citiations to reference - noise in random classification aka randomized classifier, Lee cohen & FP objective, 
% appendix: paragraph on?
% don't have to justify every citation
% related work in strategic mainpulation - last sentence is the one that is most similar, and then maybe one sentence about what we've done.
%\textbf{Generative Models in the Hiring Ecosystem}

% as a last sentence
% what work do we add to that is the most similar --- does this apply / group / social cost?
% e.g. thus far, no works have focused on the LLM

% LLM and Societal Challenges
    
\section{Empirical Motivation: LLM Manipulations on Resumes} \label{sec: empirical motivation}

\begin{figure*}[h]
    \centering
        \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[height=2.0in]{Diagrams/chatgpt.png}
        \caption{Resume Scores over Sequential LLM Manipulations}
    \end{subfigure}%
    ~ 
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[height=2.0in]{Diagrams/differentllms.png}
        \caption{Resume Scores Across Different LLMs}
    \end{subfigure}
    \caption{Results from LLM Experiments on the Prompt: ``Can you improve my resume?''}
    \label{fig:llm-demo}
\end{figure*}
%\BOGO{goal: what is our motivation for LLM manipulations on resumes}
%Caption place holder \lc{you should describe the expiremnt done here, preferably with the prompt. A Reader should understand our paper by looking at the figures} \BOGO{how many resumes, which types}
%\BOGO{scatter plot of original vs manipulated score? (with y = x line)}
%\BOGO{word-frequency? elaborate on this section}
%\BOGO{no work on this theoretically or empirically, this section is about specific empirical experiments for how LLMs effect \emph{resumes}}

Our modeling of LLM manipulations is motivated by three key findings from our experiments in understanding existing LLM tools. First of all, we used LLMs to modify resumes from the Djinni Dataset \citep{drushchak-romanyshyn-2024-introducing} with the following prompt: ``can you improve my resume?''. We also included additional instructions to prevent any fabrication of resume experiences \footnote{See Appendix \ref{sec:experiment-details}.}. These un-modified and modified resumes were then evaluated through the open-source Resume Matcher software. Namely, we used Resume Matcher to produce a ``resume score'' for each candidate's resume, which ranged in value from 0 to 100, that embodied the resume's aptitude for our inputted job posting (the larger the score, the more adept one is). The job description which we scored our applicants against was specifically for a \textit{Project Manager}, or henceforth, \textit{PM}, job posting. From these experiments, we identified three overall key behaviors of LLM Manipulations.
\begin{enumerate}
    \item LLM manipulations improve resume scores.
    % improved resumes in accordance to their match with different job roles. \judy{Does this mean llms improve resume scores?}
    \item LLM manipulations vary by tool price: 
    % improvement in resume score positively correlated to the costs of each tool.
    higher-priced LLMs improve resume scores more.
    \item Improvements from LLM manipulations stagnate. Specifically, sequentially applying the same LLM to the same resume leads to fewer and fewer changes.
    % flatten out?
\end{enumerate}
%just dumpingwriting right now apologies
We first and foremost observed that LLM manipulations were highly effective in helping candidates appear more qualified. %This is illustrated through our manipulation of the following resume (refer to the Appendix for the prompt): %picture
Figure~\ref{fig:llm-demo}a illustrates that applying a single round of LLM improvements drastically improves scores generated by a resume screening system. Qualitatively, we observed a drastic improvement in writing quality; the LLMs were able to transform resumes mostly containing bullet points about the applicant's interests or skills into more effective resumes delineating the different previous roles an applicant had. 

%\judy{is it paragraphs?}. However, when we instructed ChatGPT to "improve" our \textit{resume}, we observed that the writing became formatted more effectively, adopting a role-by-role structure akin to that of traditional resumes.

%picture
A second observation that motivates our study of disparities is the disparate outcomes resulting from applying different LLMs to an applicant's resume. According to various leaderboards, \textsc{ChatGPT-4o} is a more capable large language model than \textsc{Mixtral-8x7B} Model\footnote{At the time of writing, \textsc{ChatGPT-4o} is ranked \#2 on the Chatbot Arena leaderboard and \textsc{Mixtral-8x7B} is ranked \#77 (\url{https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard})}. Consequently, \textsc{ChatGPT-4o} produced higher resume scores for 75\% of resumes while \textsc{Mixtral-8x7B} only produced higher resume scores for 50\% of resumes (Figure \ref{fig:llm-demo}b). Digger into the actual manipulated resumes, \textsc{ChatGPT-4o} better adhered to the traditional structure and elements of a resume. %for example, while Mistral put together an outline of the inputted resume, Chat-GPT 4.0 also added additional and necessary elements such as a resume description, and even placeholders for one's educational history.
%picture of mistral ai vs chatgpt
%More quantitatively, we found that Mistral AI demonstrated less improvement compared to ChatGPT 4.0. Specifically, the rate of improvement, defined as the percentage of resumes whose scores increased following LLM manipulation, was 50\% for Mistral AI, while ChatGPT 4.0 achieved a 75\% rate of improvement.

Finally, we also empirically observe that repeated manipulations do not significantly alter resumes. The first round of modifications typically standardizes language and formatting according to a conventional resume structure; however, the second round of manipulations does not deviate substantially from the first. This observation is also illustrated by similarity of the resume score distributions of the once and twice modified resumes in Figure~\ref{fig:llm-demo}. Our finding here hence supports existing evidence that large language models tend to favor their own generated inputs~\cite{panickssery2024llm}.

Finally, we observed that large language models (LLMs) improved the writing quality of the inputted resumes, albeit with variable quality across different LLM models and iterations. These observations regarding the impact of LLM manipulations on resume improvements were quantitatively assessed using our scoring system, as illustrated in Figure \label{fig:llm-demo}b. The figure demonstrates that scores generally increase with LLM manipulations; however, these increases are contingent upon the specific LLM model and the number of iterations employed.

All in all, these three key observations regarding LLM manipulations—the potential for resume improvement, the variation in results across multiple iterations, as well as differences in results among various LLM models—serve to motivate our proposed model of these strategic manipulations in Section \ref{sec: model}.

\section{%Our Hiring 
Model} \label{sec: model}

\subsection{Preliminaries}
%Let $x = (x_1, x_2)  \in \mathcal{X}$, where $\mathcal{X} \subseteq \mathbb{R}^2$ be the applicant features. 
%\lc{Lee: commented out here}
% \subsection{Foundational Definitions}
% We introduce some foundational definitions that will allow us to construct our model for traditional and two-ticket hiring. 
% \subsubsection{The Candidate Space}


% We first define our representation of the candidates applying for the job. We represent each candidate as a triplet \((\bm{x}, g, y)\), representing the candidate's resume features, group membership, and true label.

Let us first define our representation of the candidates applying for a posted job. We represent each candidate as a triplet \((\bm{x}, g, y)\), where \(\bm{x} \in \mathbb{R}^{m+n}\) represents the candidate's original (unmodified) resume features, \(g \in \{A, B\}\) denotes the group membership, with $A$ indicating the privileged group and $B$ indicating the underprivileged group, and \(y \in \{0,1\}\) represents the true label, with $0$ corresponding to an unqualified candidate and $1$ to a qualified candidate. It is important to note that we do not require that \(\bm{x}\) fully determines \(y\).

\lc{Lee: do we write that our model also accommodates manipulations that are not done by LLMs (e.g., a friend that works for HR?} \jack{DISCUSS: should we include this as a footnote? i feel like we might have to defend this assertion more?}


\textcolor{teal}{We categorize resume features as either ``LLM-alterable'' and ``LLM-unalterable''. ``LLM-alterable'' features are features that the candidates (and potentially hirers) using LLMs are capable of alter and are willing to alter. For example, LLM-alterable features might include writing style and organizational structure. ``LLM-unalterable'' features are features that the candidates (and hirers) are either unable or unwilling to alter, due to either limitations of the LLM or constraints on how far candidates are willing to stretch the truth in their resumes.} \BOGO{DISCUSS: we didn't like the term ``LLM-alterable'', but I couldn't think of an alternative term that captures the concept. Any suggestions to replace/edit this description are very welcome.}

Our model accommodates any combination of LLM-unalterable and LLM-alterable features in the feature space. In particular, we express each candidate's resume features as an \((m+n)\)-dimensional feature vector in \(\R^{m+n}\):
\[\bm{x} = [x_1, x_2, \dots, x_m, c_1, c_2, \dots, c_n] \]
where \(x_1, x_2, \dots x_m\) are LLM-alterable features, while \(c_1, c_2, \dots, c_n\) are LLM-unalterable features.\footnote{Note that that if all features are LLM-unalterable (\(m = 0\)), then the scenario reduces to traditional non-strategic classification.} For example, suppose the Hirer is looking to hire a Java Developer. Then \(x_1\) might represent the resume writing quality and \(x_2\) might represent the candidate's expressed enthusiasm for the job. On the other hand, \(c_1\) might represent the candidates's level of education and \(c_2\) might represent their technical skills at object-oriented programming. %The rationale for splitting features in these two categories will become clearer when we discuss LLM manipulations later in the paper.
% Namely, \(x_1\) represents the resume's writing quality, whereas $x_2$ embodies the underlying skill of each resume. For example, if the Hirer seeks to hire for a \textit{Java Developer}, $x_2$ may represent the candidate's true programming skills in Java. For convenience, we let \(\mathcal{X} = \R^2\) represent the feature vector space. Though our candidate feature space may seem limited, it can incorporate any general feature space as follows: let $z$ be a rich text resume that candidates present, and candidates' features can be simplified to be $(x_1 = q_1(z), x_2=q_2(z))$ where $q_1$ and $q_2$ are functions that map text features to the writing quality and underlying relevant skills conveyed by each resume respectively (i.e.,  $q_1, q_2: \mathcal{Z} \rightarrow [0, 1]$). For clarity, we move forward with the two-dimensional abstraction of the problem. \jack{
%     I'm not sure whether this is exactly equivalent to two-dimensional, but we should be able to get the same results since the logic is mostly the same. The rest from here on out assumes a \(m+n\)-dimensional feature space for generality's sake --- we can always change it back to just \(\R^2\) if we wish. - connie: should we add this in appendix?
% }

% Next, we express each candidate's group membership as a label \(g \in \{A, B\}\). We designate Group \(A\) to be the privileged group and Group \(B\) to be the underprivileged group.

% Finally, we express each candidate's true label as a binary classification label \(y \in \{0,1\}\). A label of \(0\) indicates that the candidate is truly unqualified for the position, while a label of \(1\) indicates that the candidate is truly qualified for the position. We do not require that \(\bm{x}\) fully determines \(y\). 

We model the candidate population as a joint distribution \(\D\) over feature vectors, group memberships, and true labels. We define the random variable triplet \((\bm{X}, G, Y) \sim \D\) with \(\bm{X} \in \mathcal{X}\), \(G \in \{A, B\}\), and \(Y \in \{0,1\}\). Moreover, we assume that both groups have identical distribution over resume feature vectors, and that the true label is independent of group membership. That is, we assume that \(\bm{X}\) and \(G\) are independent and that \(Y\) and \(G\) are conditionally independent given \(\bm{X}\).

% We define the random variable triplet \((\bm{X}, G, Y) \sim \D\) where \(\bm{X} \in \mathcal{X}\) designates the candidate's feature vector, \(G \in \{A, B\}\) designates the candidate's group membership, and \(Y \in \{0,1\}\) designates the candidate's true label. \judy{This seems repeated from the previous paragraph} Moreover, we assume that both groups have the same resume feature vector distribution, and that the true label is independent of group membership. That is, we assume that \(\bm{X}\) and \(G\) are independent and that \(Y\) and \(G\) are conditionally independent given \(\bm{X}\). \lc{Lee: where do we say that hirer doesn't know g,y?}


%Formally, applicant resumes are represented by a set of features $x = (x_1, x_2)  \in \mathcal{X}$, where $\mathcal{X} \subseteq \mathbb{R}^2$. For each applicant $x  = [x_1, x_2] \in \mathcal{X}$, we see that $x_1 \in \mathbb{R}$ represents the resume's writing quality, whereas $x_2$ embodies the ``true" underlying skill of each resume. 

%For example, if a hiring firm would be to seek a person for \textit{Java Developer} role, we see that $x_2$ would represent the applicant's true programming skills in Java. Higher values of $x_1$ and $x_2$ also represent higher levels of writing skills and technical skills, respectively. In this whole paper, we also assume that the applicant resumes $\mathcal{X}$ are uniformly distributed over $[0, 1] \times [0, 1] \in \mathbb{R}^2$.

\subsection{LLM Manipulation}
We now introduce our model for LLM manipulation of resumes. 

%independent, but not identical
\begin{definition}[Mathematical formulation of Strategic LLM Manipulation]
    \label{def: formulation of LLM}

    An \emph{LLM manipulation} is a random function \(L:\mathcal X \rightarrow \mathcal X\) characterized by a series of (not necessarily independent) real-valued random variables \(\chi_1, \chi_2, \dots, \chi_m\). When called upon a feature vector \(\bm{x} = [x_1, \dots, x_m, c_1, \dots, c_n]\),
    \begin{enumerate}
        \item \(L\) \emph{replaces} each \(x_i\) with a value drawn from \(\chi_i\) for \(1 \leq i \leq m\).
        \item \(L\) \emph{preserves} the value of \(c_j\) for \(1 \leq j \leq n\).
    \end{enumerate}
    In other words,
    \[L([x_1, \dots, x_m, c_1, \dots, c_n]) = 
    [\chi_1, \dots, \chi_m, c_1, \dots, c_n].
    \] 
\end{definition}
 
%\footnote{add footnote/or discussion section for this, our model can be extended to a case where \chis are dependent, explain general proof}

%Connie! - Done 9/26
Our formulation of LLM manipulations is based on the understanding that LLMs can standardize LLM-alterable aspects such as writing quality, style, and organization, but cannot alter certain inherent features of a resume, when instructed with a prompt asking for improvements to the resume. This perspective is informed by our empirical observations detailed in \Cref{sec: empirical motivation}. Our experiments first indicated that LLM manipulations effectively overwrite writing style attributes. This is captured in our model, where the LLM-alterable features are redistributed according to a fixed random distribution. 
% Furthermore, this distribution can vary from one run to another; for instance, we have observed that repeated LLM-manipulations tend to diminish their impact on resume content. 
% jack: the above sentence is a bit confusing to me, since it suggests the distribution shifts from run to run. in reality, our assumption is that the distribution stays the same, while the value drawn from the distribution can of course change from run to run
In contrast, LLM-unalterable features—such as job experience, technical skills, and educational background—remain unchanged, assuming there are no hallucinations or intentional misrepresentations. After all, fabricating knowledge about one's technical qualifications can have fatal consequences: it is a common practice for employers to permanently blacklist dishonest candidates from their workplaces. To ensure that Hiring managers can isolate ``truly" qualified candidates, it is also in the hiring manager's best interest to ensure LLM prompts maintain factual integrity. Our experimental LLM prompts also work to elicit this outcome - specifically, we prompt the LLM by using words such as ``imperative" or ``neccesary" when commanding it to not add any new facts that are not present in the original resume.
\jack{DISCUSS: Should this explanation be reduced to only talk about the effect on the LLM-alterable features (overwriting), since the LLM-alterable vs LLM-unalterable difference was already discussed?}


    \begin{figure}[t]{}
        \centering
        \includegraphics[width=0.5\textwidth]{Diagrams/LLM_function.png}
        \caption{Visualization of \textit{LLM Manipulation} Function - preserves $x_2$, while ``overwriting" $x_1$.}
    \end{figure}
    \begin{remark}
        \(L\) could represent more than a single run of an LLM --- it might instead represent the cumulative effect of a user's use of an LLM, potentially over multiple runs.
    \end{remark}

    We assume that each Candidate Group \(g\) has access to its own LLM \(L_g\). Likewise, the Hirer also access to its own LLMs that are separate from the Applicants'. %We also assume that the Hirer has access to (potentially) several different LLMs: for convenience of comparison, we assume the Hirer has access to two different LLMs, \(L_H^{(1)}\) and \(L_H^{(2)}\).
   % \BOGO{don't introduce 1 and 2 here: bring it up only when we need it}

\subsubsection{Hiring Systems}
    \BOGO{DISCUSS: should we introduce the Applicant and Hirer, in general terms, in the intro?
    
    \Relatedly, when should we use ``Applicant'' vs. ``candidate''? 
    My thought is that a candidate refers to a specific triplet \(\bm{x}, g, y\), whereas the Applicant refers to the agent operating over the candidate pool.
    }
    
    Our work focuses on investigating jobs with large volumes of applications: for this reason, we assume that the ``Hirer" parses and represents each candidate's resume as a real-valued ``score". This score reflects a candidate's aptitude, allowing the Hirer to quickly assess candidates and reduce inefficiencies from subjective, person-to-person evaluations. More specifically, our model assumes that the Hirer first uses some fixed scorer to evaluate the applicants' resumes. We represent this scorer as a function \(s:\mathcal{X} \to \R\). We make no assumptions about \(s\) other than that it is monotonically non-decreasing.
    %\BOGO{DISCUSS: How to frame the scoring system?} 
    
    Note that we assume that the Hirer has no control over \(s\). In practice, the Hirer usually cannot fully customize their deployed scorer. She can, at best, choose the least flawed scorer available and tweak it accordingly. We assume that \(s\) is the final scoring system that the Hirer settles upon.
    
    Moreover, we assume that LLMs and this scorer are the only methods by which the Hiring System interacts directly with the resumes. The Hirer therefore decides who to hire using only the resulting scores of (possibly LLM-edited) resumes. 


\subsubsection{Strategic LLM Manipulation}
    We now conceptualize LLM manipulation by the Applicant as a form of strategic manipulation. Specifically, we assume that a candidate with resume feature vector \(\bm{x}\) and group membership \(g\) has access to two manipulations: the identity manipulation (staying at \(\bm{x}\)) and the group \(g\) LLM-manipulation (moving to a value drawn from \(L_g(\bm{x})\)). The second manipulation is stochastic in nature: however, the Applicant is able to choose its submitted resume-vector, $\bm{x}'$, between their original resume \(\bm{x}\) and their Group \(g\) LLM-edited resume \(L_g(\bm{x})\) \emph{after} the value is drawn and know which has better score. 
    % mention here how there is no cost to manipulation because of an intrinsic attribute of privilege non-privilege, which is more in depth described in Section 5.

\subsection{Traditional Hiring with Applicant LLM Manipulation}

\subsubsection{Strategic LLM Classification Game}
    We finally introduce our strategic LLM classification game for traditional hiring with Applicant LLM manipulation. Informally, a candidate in our game can use the LLM available to their group to edit their resume --- the candidate then chooses which of these two resumes (its original and its manipulated) to submit to the Hirer.

    \fbox{\begin{minipage}{\linewidth}
        \begin{definition}[\textsc{Traditional} Hiring with Applicant LLM Manipulation]
            \label{def: traditional hiring with Applicant LLM manipulation}
            % Let \(A\) be the advantaged group and \(B\) be the disadvantaged group. Let \(\D_A\) and \(\D_B\) be the probability distribution of resume feature vectors over \(\R^2\) for group \(A\) and \(B\) respectively. Let \(p_A\) and \(p_B\) be the population proportions for group \(A\) and \(B\) respectively
            The Hirer and the Applicant play the following Stackelberg game.
            \begin{enumerate}
                \item The Hirer commits to some threshold \(\tau \in \R\). 
            
                \item Each candidate \((\bm{x}, g, y)\) chooses to submit either their original resume \(\bm{x}' = \bm{x}\) or their LLM-edited resume \(\bm{x}' = L_g(\bm{x})\).

                % Detailed
                % represented by the triplet \((\bm{x}, g, y)\), generates a LLM-edited version \(L_g(\bm{x})\) using Group \(g\)'s LLM. The candidate then chooses to submit either their original resume (\(\bm{x}' = \bm{x}\)) or their LLM-edited resume (\(\bm{x}' = L_g(\bm{x})\)).
    
                \item The Hirer accepts candidates according to the classifier \(f_\tau(\bm{x}') = \one[s(\bm{x}') \geq \tau]\). 
                
                % receives and scores the submitted (potentially edited) resumes and accepts each candidate if the score surpasses the threshold: that is, 
            \end{enumerate}
            
            Each player has the following payoffs:
            \begin{enumerate}
                \item The candidate payoff is whether they are accepted: \(\one[f_\tau (\bm{x}') = 1]\).
                
                \item The Hirer's payoff is defined according to the ``No False Positives Objective'', which we define below.
            \end{enumerate}
        \end{definition}
    \end{minipage} }
    
    \begin{definition}[No False Positives Objective]
        \label{def: no false positives objective}
        The \textit{No False Positives Objectives} is achieved when the Hirer maximizes true positive rate subject to no false positives, where
        \begin{align*}
            \textrm{TPR} &= \P(f_\tau(\bm{x}') = 1 \mid Y = 1) \\
            \textrm{FPR} &= \P(f_\tau(\bm{x}') = 1 \mid Y = 0).
        \end{align*}
    \end{definition}

    We assume that there are many applicants, so the cost of missing qualified individuals is less than the cost of interviewing unqualified applicants.
    % leave for appendix?
    \begin{remark}
        Note that unlike classic strategic classification, our game does not directly assume that the Applicant has perfect knowledge about \(f_{\tau}\), since in reality, hiring systems are often opaque. However, we assume that candidates \emph{do} know which of the two versions of their resume will score higher. As such, our game is functionally equivalent to the Applicant having perfect knowledge about \(f_\tau\). A best-responding candidate in Group \(g\) will therefore submit
        \begin{align*}
            \bm{x}'_g = \argmax_{\bm{z} \in \{\bm{x}, L_g(\bm{x})\}} s(z).
        \end{align*}
    \end{remark}
    
     Under the assumption that applicants are best-responding, we reformulate the No False Positive Objective as the following constrained optimization problem as the Hirer's objective:
    \begin{align*}
        % \tau^* &= 
        %\argmax_{\tau \in \mathbb{R}} 
        \tau^* = &\argmax_{\tau \in \R}
        \P(f_\tau(\bm{x}') = 1 \mid Y = 1) \\
        &\text{subject to }
        \P(f_\tau(\bm{x}') = 1 \mid Y = 0) = 0
        % \sum_{g \in \{A, B\}} p_g * P_{x \sim D_g}(f_\tau(x'_g) =1 \mid y = 1) \\
        % \text{s.t.} & 0=\sum_{g \in \{A, B\}} p_g *\space P_{x \sim D_g}(f_\tau(x') = 0 | y = 0)
        .
    \end{align*}
    (If there are multiple thresholds that optimize the objective, it will be convenient for us to let \(\tau^*\) denote the smallest such threshold.)
    
    % \lc{Lee: maybe use $f_\tau$ instead of $f$ and then $\tau^*=argmax_\tau...$}
    %Connie - Fix above alignment later.
    Observe that the Hirer also does not know and cannot infer whether a resume has been edited or from which group a resume comes. Rather, the Hirer must use the same scoring system and threshold for all candidates.    %\(\bm{x}' \coloneqq \argmax_{\bm{z} \in \{\bm{x}, \hat{\bm{x}}\} } s(\bm{z})\).
    
\section{Disparities in Traditional Hiring with Unequal Applicant LLM Manipulation}
\label{sec: disparities}

%rename title
We first demonstrate that when applications enhance their resumes' in today's hiring screening systems, disparities between the groups in LLM quality lead to disparities in hiring outcomes. We begin by defining a useful metric for disparity in hiring outcomes. We assume that the resume features vectors for groups A and B follow the same distribution. %It is therefore appropriate to compare the acceptance probabilities for identical resume feature vectors for Group \(A\) and Group \(B\). 
We then define the individual outcome disparity: 

    \begin{definition}
        \label{def: individual outcome disparity}
        Given a resume feature vector \(\bm{x} \in \mathcal{X}\), the \emph{individual outcome disparity} $D$ is defined as
        \begin{equation*}
            D(\bm{x}) = \P_{L_A}(f_\tau(\bm{x}'_A) = 1) - \P_{L_B}(f_\tau(\bm{x}'_B) = 1), 
        \end{equation*}
        
        where \(\bm{x}'_g = \argmax_{\bm{z} \in \{\bm{x}, L_g(\bm{x})\} } s(\bm{z})\) for \(g \in \{A, B\}\).
    \end{definition}


    Observe that if the original unmanipulated resume is accepted (that is, \(f_\tau(\bm{x}) = 1\)), then \(D(\bm{x}) = 0\).
    
    % \BOGO{this outcome disparity compares the \emph{same} resume's outcomes for the two different groups, where as typical fairness metrics compare performance over the entire groups. I'm using this individualized metric since it is the easiest to work with for now} %ok cool - leave this comment for time being

    We now introduce a useful way to compare the quality of LLMs. We first recall the notion of multivariate stochastic dominance as provided by \cite{levhari1975efficiency}. 
    
    \begin{definition}
        Let \(Z_1, Z_2\) be random variables over \(\mathcal{X}\). For any \(a \in \mathcal{X}\), let \(F_k(a) = \P(Z_k \leq a)\), where \(\leq\) denotes componentwise order. We say that \(Z_1\) \emph{stochastically dominates} \(Z_2\) if for any open lower set \(S \subseteq \mathcal{X}\),
        \begin{equation*}
            \int_S dF_1 \leq \int_S dF_2.
        \end{equation*}
    \end{definition}
    This is a generalization of (first-order) univariate stochastic dominance to multivariate distributions. Intuitively, stochastic dominance requires that the generalized CDF of \(Z_1\) must always be ``less'' than the generalized CDF of \(Z_2\). Furthermore, \cite{levhari1975efficiency} provides the following key property about stochastic dominance.
    
    \begin{proposition}
        \label{prop: stochastic dominance utility}
        \(Z_1\) stochastically dominates \(Z_2\) if and only if for every non-decreasing function \(u\),
        \[\E[u(Z_1)] \geq \E[u(Z_2)].\]
    \end{proposition}

    We use this definition to define our ordering over LLM quality.
    \begin{definition}
        Let \(L_1, L_2\) be LLM manipulations. We say that \(L_1\) \emph{dominates} \(L_2\) if for all \(x \in \mathcal{X}\), \(L_1(x)\) stochastically dominates \(L_2(x)\).        
    \end{definition}
    In more informal terms, an LLM \( L_1 \) may be considered ``better'' than \( L_2 \) if it stochastically dominates \( L_2 \), indicating that \( L_1 \) has a greater likelihood of attribute improvement than \( L_2 \).
    % note that the relevant notion of equality here is equality in distribution, not statewise equality

    We now show that a better LLM under this ordering leads to a better hiring outcome.

    \begin{proposition}
        \label{prop: hiring outcome disparity}
        Suppose \(L_A\) dominates \(L_B\). Then for all \(\bm{x} \in \mathcal{X}, D(\bm{x}) \geq 0\).
    \end{proposition}
    \begin{proof}
        Fix \(\bm{x} \in \mathcal{X}\). If \(f_\tau(\bm{x}) = 1\), then trivially \(D(\bm{x}) = 0\). We therefore focus on the case that \(f_\tau(\bm{x}) = 0\). In this case, note that
        \begin{equation*}
            \P_{L_g}(f_\tau(\bm{x}'_g) = 1) = \E_{L_g}[f_\tau(L_g(\bm{x}))]. 
        \end{equation*}
        Since \(s\) is non-decreasing, \(f_\tau(\bm{x}) = \one[s(\bm{x}) \geq \tau]\) is also non-decreasing. Since \(L_A\) dominates \(L_B\), \(L_A(\bm{x})\) stochastically dominates \(L_B(\bm{x})\), so by \Cref{prop: stochastic dominance utility},
        \begin{gather*}
            \E_{L_g}[f_\tau(L_A(\bm{x}))] \geq \E_{L_g}[f_\tau(L_B(\bm{x}))] 
        \\  \implies
            \P_{L_g}(f_\tau(\bm{x}'_A) = 1) \geq 
            \P_{L_g}(f_\tau(\bm{x}'_B) = 1)
        \\  \implies
            D(\bm{x}) \geq 0.
            \qedhere
        \end{gather*}
    \end{proof}
    \BOGO{DISCUSS: should the above be a theorem or a proposition?}

    \begin{remark}
        \label{rem: null LLM}
        
        We find it helpful to artificially define a ``null LLM'' \(L_\varnothing\) that is dominated by all other LLMs. We might informally conceptualize \(L_\varnothing\) as having random variables \(\chi_i = -\infty\) for \(1 \leq i \leq m\). This allows us to simulate the \emph{absence} of access to an LLM in our strategic classification game, as its output will always be rejected by a Hirer or applicant in favor of the original input. Furthermore, this allows us to conceptualize traditional hiring as a special case of two-ticket hiring in which the Hirer deploys the null LLM. 

        \BOGO{DISCUSS: where should the above remark go? before \Cref{prop: hiring outcome disparity}?}
        % \lc{Lee: can we use the identity instead of absence} \judy{I agree with Lee here, it is possible that the LLM doesn't help, but do emphasized that its rejected by the user and never submitted (not rejected by our two ticket system)}
        % \BOGO{This null LLM is worse than all others in our constructed ordering}

        %\BOGO{for J\&L: is it too unrigorous to define a random variable that takes an infinite value? the null LLM is a very convenient notion (it allows us to say that having no LLM is ``worse'' than any other LLM, using our existing definition of ``worse''), but its definition is a little sus\\        
       % alternatively, we could force all features to be nonnegative and define the null LLM as \(\chi_i = 0\)
       % }
    \end{remark}

    \subsection{Empirical Observations}

        \BOGO{empirical result here: Show that there is a chance in acceptance rates with vs without LLM (i.e. relative to the actual best No False Positives Objective threshold). Show acceptance rates for privileged group vs unprivileged group in the context of an actual hiring problem.}

    
    % \BOGO{this argument requires that \(\chi_g, i\) are independent from each other, since coupling each entry pairwise ignores dependence between the entries.
    
    % The proposition fails if there is dependence. As a counterexample (discrete, but the same principle applies for continuous):
    %     for \(\mathcal{X} = \R^2 \times \R\), \(s([x_1, x_2, y]) = x_1 + x_2 + y\), \(\tau = 2\), and \(\bm{x} = [0,0,0]\), \(L_A\) and \(L_B\) are given by
    %     \begin{table}[H]
    %         \centering
    %         \begin{tabular}{l|l|l}
    %         \(p(x_{A,1},x_{A,2})\) & \(x_{A,1} = 0\) & \(x_{A,1} = 1\) \\ \hline
    %         \(x_{A,2} = 0\)  & \(0\)  & \(1/2\)  \\ \hline
    %         \(x_{A,2} = 1\)  & \(1/2\)  & \(0\)
    %         \end{tabular}
    %     \end{table}

    %     \begin{table}[H]
    %         \centering
    %         \begin{tabular}{l|l|l}
    %             \(p(x_{B,1},x_{B,2})\) & \(x_{B,1} = 0\) & \(x_{B,1} = 1\) \\ \hline
    %             \(x_{B,2} = 0\)  & \(2/3\)     & \(0\)   \\ \hline
    %             \(x_{B,2} = 1\)  & \(0\)   & \(1/3\)
    %         \end{tabular}
    %     \end{table}

    %     we can see that \(L_A \succ L_B\) but \(\P(s(\hat{\bm{x}}_B) \geq \tau) = 0 < \frac{1}{3} = \P(s(\hat{\bm{x}}_B) \geq \tau)\).
    % }

% \subsection{LLM Manipulation}
% We thus proceed formally by modeling the use of LLMs for strategic manipulations of resume attributes. 
% \begin{definition}{(LLM Manipulations)}
%     LLM Manipulations are functions of the following form:
%      \begin{align*}
%       L \colon \chi & \longrightarrow \chi_L \times \mathbb{R} \\[-1ex]
%       x & \longmapsto [\chi_L, x_2]
%     \end{align*}
%     where $\chi_L \sim \mathcal{U}[l, u]$ for some fixed interval $[l, u] \subseteq \mathbb{R}$.
% \end{definition}
% \begin{remark}{(LLM-Modified Resumes)}
%     An LLM modified resume, $x_1$, is then one output of $L(x_1)$.
% \end{remark}
% Given this model of LLM manipulations, let us now consider the effect of an LLM $L$ on each of the resume features. We see that, in line with our empirical observations of LLM behaviour, that:
% \begin{enumerate}
% 	\item LLM manipulations homogenizes the first feature (writing skills) to a random variable $\chi$, which is independent of the applicant's original resume quality. 
% 	\item LLMs do not modify the second feature (an applicant's underlying technical skill). 
% \end{enumerate}
% The best response of an applicant, given access to LLM Manipulation, is to hence report a $x' =\argmax_{x} \{x, L(x)\}$. Afterall, as our firms deploy threshold classifiers, we naturally see that the higher the applicant reported features, the higher the score, and naturally, an increased chance of acceptance. 
% \subsection{The Two Ticket System}
% \begin{remark}{(Traditional Hiring Schemes)}
%     Hence, to motivate our design of the two-ticket system, we consider a one-ticket scenario, which can be best used to describe existing hiring schemes.
    
% \end{remark}
\section{Combating LLM Disparities: ``Two-Ticket'' Hiring System}
\label{sec: two-ticket system}

    To counteract the disparity in hiring outcomes caused by disparities in LLM access, we propose a modified hiring system where the Hirer performs their own round of LLM manipulation. The intuition is that running a resume through a high-quality LLM twice changes the resume much less on the second run than on the first. We show that bestowing both groups with the benefit of a round of high-quality LLM manipulation therefore may help level the playing field.
    
    \subsection{Modified Strategic Classification Game\lc{: Two-Tickets}}
        We present the modified strategic classification game under this ``two-ticket system''. This two-ticket system is identical to traditional hiring except that the Hirer now uses her own LLM to edit each submitted resume. The Hirer then scores the best of these two versions to determine whether to accept each candidate.

        \fbox{\begin{minipage}{\linewidth}
            \begin{definition}[\textsc{Two-Ticket} Hiring \lc{Lee: DISCUSS: should we call it a scheme or hiring scheme?} with Applicant LLM Manipulation]
                \label{def: two-ticket hiring with Applicant LLM manipulation}
                \phantom{so it doesn't overflow the line}
                \begin{enumerate}
                    \item The Hirer commits to some threshold \(\tau \in \R\) \textcolor{teal}{and some LLM \(L_H\)}.
                    
                    % Condensed
                    \item Each candidate \((\bm{x}, g, y)\) chooses to submit either their original resume \(\bm{x}' = \bm{x}\) or their LLM-edited resume \(\bm{x}' = L_g(\bm{x})\).
                    
                    % More explained
                    % Each candidate, represented by the triplet \((\bm{x}, g, h)\), generates a LLM-edited version of their resume \(L_g(x)\) and chooses to submit either their original resume (\(\bm{x}' = \bm{x}\)) or their LLM-edited resume (\(\bm{x}' = L_g(\bm{x})\)). \BOGO{shorten, can explain process outside definition. Just provide the actual things inside the actual definition box.}
        
                    \item 
                    \textcolor{teal}{The Hirer chooses to consider the higher scoring resume among the submitted resume \(\bm{x}'' = \bm{x}'\) and the LLM-edited submission \(\bm{x}'' = L_H(\bm{x}')\)}.
                    
                    % % Detailed
                    % \textcolor{teal}{The Hirer receives the submitted (potentially edited) resumes and generates their own LLM-edited version \(L_H(\bm{x}')\) using their committed LLM. The Hirer then chooses to review the \emph{higher scoring} resume among the submitted resume (\(\bm{x}'' = \bm{x}'\)) and the Hirer-edited resume (\(\bm{x}'' = L_H(\bm{x}')\)).}\lc{Lee: we should motivate the maximum before the definition. Otherwise the reader will be confused} \jack{do you mean motivate why the Hirer considers both versions, or the paragraph that follows the definition?}
            
                    \item 
                    The Hirer accepts candidates according to the classifier \(f_\tau(\bm{x}') = \one[s(\bm{x}'') \geq \tau]\). 
                    % The Hirer accepts a candidate if \(s(\bm{x}'') \geq \tau\).
    
                \end{enumerate}
                
                Each player then has the following payoffs:
                \begin{enumerate}
                    \item The candidate payoff is the \textcolor{teal}{probability that they are accepted}: \(\P_{L_H}(f_\tau (\bm{x}'') = 1)\).
                    
                    \item The Hirer's payoff is defined by the ``No False Positives Objective'' given in \Cref{def: no false positives objective}.
                \end{enumerate}
            \end{definition}
        \end{minipage} }
        
           % More specifically, we see that the hirer's objective can be interpreted as the following constrainted optimization problem. In the case of the Two-Ticket 
        
        In practice, the Hirer scores both the submitted resume and the Hirer-edited resume, and accepts the candidate if one of the scores passes the threshold. This is where our name ``Two-Ticket Hiring'' comes from: each candidate is essentially given two avenues to acceptance.\footnote{Traditional hiring can be analogously thought of as ``One-Ticket'' hiring, as the candidate's submitted resume is their only avenue to acceptance.} This is equivalent to the above definition: our chosen presentation emphasizes the symmetry of the Hirer's LLM manipulation and the Applicant's LLM manipulation.

        While LLM manipulations generally improve resume quality, there is a chance that they can decrease a candidate's score (\Cref{sec: empirical motivation}). To ensure that candidates are not unfairly harmed by LLM manipulations, we safeguard against this possibility by requiring the Hirer to evaluate on the maximum of the candidate's submitted and its Hirer-edited version of each resume. %We see that the Hirer still considers the applicant's self-presented resume in this hiring scheme. 
        %\jack{DISCUSS: should we mention why we don't want the possibility of the LLM harming the applicant's score? - Connie: DONE, added "to ensure candidates..}

        Observe that the traditional hiring game defined in \Cref{def: traditional hiring with Applicant LLM manipulation} can be considered a special case of the two-ticket hiring game defined in \Cref{def: two-ticket hiring with Applicant LLM manipulation}, where \(L_H\) is the null LLM discussed in \Cref{rem: null LLM}. Thus, we compare the behavior of two different \emph{two-ticket} games: namely, the game under \textsc{Traditional} hiring (\Cref{def: traditional hiring with Applicant LLM manipulation}) and the game under \textsc{Two-Ticket} Hiring Systems (\Cref{def: two-ticket hiring with Applicant LLM manipulation}), which differ only in the Hirer's choice of LLM and threshold in our formalization. %Comparing traditional hiring to two-ticket hiring can therefore be considered a special case of this comparison.

    \subsection{Guaranteed ``Two-Ticket'' Improvements}
        We now prove that under certain circumstances, two-ticket hiring can decrease the hiring outcome disparity between the two groups.
    
        For \(k \in \{1, 2\}\), we define Hiring System \(k\) to be the two-ticket system using Hirer LLM \(L_H^{(k)}\) and system-dependent threshold \(\tau^{(k)}\), resulting in deployed classifier \(f^{(k)}\). Let \(D^{(k)}(\bm{x})\) denote the individual outcome disparity for Hiring System \(k\). To compare the \textsc{Traditional} hiring system with the \textsc{Two-Ticket} hiring system, we denote the \textsc{Traditional} hiring system as $k=1$ with \(L_H^{(k)} = L_\varnothing\). However, we will see later on that this ``traditional" Hiring System \(1\) may alternatively denote a different \textsc{Two-Ticket} system.
        
        We first define a useful condition on our Hiring systems.
        \begin{definition}
            \label{def: threshold-consistency condition}
            % For any random variable \(Z\), let \(\support{\,Z}\) denote the support of \(Z\).

            % Let \(\mathcal{X}_{Y = 0} = \support (\bm{X} \mid Y = 0)\) denote the set of resume feature vectors of the negative class.
            We say Hirer LLM \(L_H^{(k)}\) satisfies the \emph{threshold-consistency condition} if
            \begin{align*}
                \max_{\substack{
                    \bm{x}' = L_H^{(k)}(\bm{x}) \\
                    \bm{x} \sim \D \mid Y = 0
                }}
                s(\bm{x}').
                \leq
                \max_{\substack{
                    \bm{x}' \in \{\bm{x}, L_A(\bm{x}), L_B(\bm{x})\} \\
                    \bm{x} \sim \D \mid Y = 0
                }}
                s(\bm{x}').
                % \max_{\bm{x}' = L_H^{(k)}, \bm{x} \in \mathcal{X}} s(L_H(\bm{x})) \leq 
                % \max \biggr(
                %     &\max_{L_A, \bm{x} \in \mathcal{X}} s(L_A(\bm{x})), \\
                %     &\max_{L_B, \bm{x} \in \mathcal{X}} s(L_B(\bm{x})), \\
                %     &\max_{\bm{x} \in \mathcal{X}} s(\bm{x})
                % \biggr)
            \end{align*}
        \end{definition}
        \BOGO{DISCUSS: is this mathematical definition clear or ambiguous? how hard is it to interpret?}
        In other words, the theshold-consistency condition requires that the maximum score attainable by a negative individual when using the Hirer's LLM is at most the maximum score attainable by an negative individual when using either group's LLM or no LLM. Note that when \(L_A\) dominates \(L_B\), then \(L_B\) is redundant.

        \BOGO{does this explanation of why it is reasonable to assume the threshold-consistency condition make sense?}
        In general, we expect that the threshold-consistency condition is easy to satisfy, so long as the Hirer does not employ an LLM that is more effective than the highest quality candidate LLM, namely Group \(A\)'s LLM. Moreover, under the No False Positives objective, the threshold-consistency condition implies an immediate  and intuitive property: the same threshold can be used to achieve the No False Positives Objective across both systems.

        \begin{lemma}
            \label{lem: when threshold stays the same}
            If \(L_H^{(1)}\) and \(L_H^{(2)}\) satisfy the threshold-consistency condition, then \(\tau^{*(1)} = \tau^{*(2)}\).
        \end{lemma}
        \begin{proof}
            It is not difficult to see that, assuming a continuous distribution over scores, 
            \(\tau^{*(k)}\) is the maximum score achievable by a candidate with true label \(Y = 0\). That is,
            \begin{align*}
                \tau^{*(k)} = \max s(\bm{x}''_g)
            \end{align*}
            where
            \begin{align*}
                &\bm{x}''_g \in \{\bm{x}'_g, L_H^{(k)} (\bm{x}'_g)\} 
            \\  \text{ and }
                &\bm{x}'_g \in \{\bm{x}, L_g(\bm{x})\}
            \\  \text{and }
                &\bm{x} \sim \D \mid Y = 0.
            \end{align*}
            The threshold-consistency condition guarantees exactly that \(\bm{x}''_g = \bm{x}_g'\) suffices to achieve the maximum. In this case, the Hirer's LLM plays no role in determining the threshold. Thus, the same threshold achieves the No False Positive Objective for both Hiring System 1 and 2. 
        \end{proof}
       
        \BOGO{DISCUSS: we provide 5 proofs in total, some of which are fairly short. should they all be moved to supplementary materials?}
        Before introducing our main result about outcome disparity, we introduce a simple lemma that allows us to reexpress the probability of acceptance under a \textsc{Two-Ticket} system.
        \begin{lemma}
            \label{lem: expression for two-ticket acceptance probability}
            With Hirer LLM \(L_H\) and threshold \(\tau\), the probability that the candidate \((\bm{x}, g, y)\) is accepted is
            \begin{gather*}
                \P_{L_g, L_H}(f_\tau(\bm{x}''_g) = 1) =
            \\
                1 - 
                \one[s(\bm{x}) \leq \tau]
                \P_{L_g}\paren{
                    s(L_g(\bm{x}) \leq \tau
                }
                \P_{L_H}\paren{
                    s(L_H(\bm{x})) \leq \tau
                }
                .
            \end{gather*}
        \end{lemma}
        \begin{proof}
            If \(s(\bm{x}) \geq \tau\), then trivially \(\P_{L_g, L_H}(f_\tau(\bm{x}''_g) = 1) = 1\). We therefore focus on the case that \(f_\tau(\bm{x}) = 0\). In this case, note that
            \begin{gather*}
                \P_{L_g, L_H}(f_\tau(\bm{x}''_g) = 0)
            \\  = 
                \P_{L_g, L_H}\paren{
                    s(\bm{x}''_g) \leq \tau
                }
            \\  = 
                \P_{L_g, L_H}\paren{
                    s(\bm{x}'_g) \leq \tau \cap
                    s(L_H(\bm{x}'_g)) \leq \tau
                }.
            \end{gather*}
            Observe from the definition of LLM manipulation that \(L_H(\bm{x}'_g)\) and \(\bm{x}'_g\) are conditionally independent given \(\bm{x}\). Thus,
            \begin{gather*}
                \P_{L_g, L_H}(f_\tau(\bm{x}''_g) = 0)
            \\  = 
                \P_{L_g}\paren{
                    s(\bm{x}'_g) \leq \tau
                }
                \P_{L_g, L_H}\paren{
                    s(L_H(\bm{x}'_g)) \leq \tau
                }
                .
            \end{gather*}
            Furthermore, observe that \(L_H(\bm{x}'_g)\) is equal in distribution to \(L_H(\bm{x})\). We obtain
            \begin{gather*}
                \P_{L_g, L_H}(f_\tau(\bm{x}''_g) = 0)
            \\  = 
                \P_{L_g}\paren{
                    s(L_g(\bm{x}_g)) \leq \tau
                }
                \P_{L_H}\paren{
                    s(L_H(\bm{x}_g)) \leq \tau
                }
                .
            \end{gather*}
            Taking the complement yields the lemma.
        \end{proof}

        We now introduce our main result about outcome disparity under a \textsc{Two-Ticket} system.
        \begin{theorem}
            \label{thm: two-ticket improves outcome disparity}
            Suppose \(L_A\) dominates \(L_B\), and \(L_H^{(2)}\) dominates \(L_H^{(1)}\). Furthermore, suppose \(L_H^{(1)}\) and \(L_H^{(2)}\) both satisfy the threshold-consistency condition. Then for all \(\bm{x} \in \mathcal{X}\), \(D^{(2)}(\bm{x}) \leq D^{(1)}(\bm{x})\).
        \end{theorem}
        \begin{proof}
            For convenience, let \(\tau = \tau^{*(1)}  = \tau^{*(2)}\) be the common threshold that achieves the No False Positives Objective.  Fix \(\bm{x} \in \mathcal{X}\). If \(f^{(1)}_\tau(\bm{x}) = f^{(2)}_\tau(\bm{x}) = 1\), then trivially \(D^{(1)}(\bm{x}) = D^{(2)}(\bm{x}) = 0\). We therefore focus on the case that \(f^{(1)}_\tau(\bm{x}) = f^{(2)}_\tau(\bm{x}) = 0\). By \Cref{lem: expression for two-ticket acceptance probability},
            \begin{align*}
                D^{(k)}(\bm{x})
                &= \P_{L_A, L_H^{(k)}}(f_\tau(\bm{x}''_A) = 1) - 
                \P_{L_B, L_H^{(k)}}(f_\tau(\bm{x}''_B) = 1)
            \\  &= 
                \P_{L_H^{(k)}}\paren{
                    s(L_H^{(k)}(\bm{x})) \leq \tau
                } \cdot d(\bm{x})
            % \\
            %     &\paren{
            %         \P_{L_B}\paren{
            %         s(L_B(\bm{x}) \leq \tau
            %         }
            %         - 
            %         \P_{L_A}\paren{
            %         s(L_A(\bm{x}) \leq \tau
            %         }
            %     }
            \end{align*}
            where 
            \(
            \displaystyle
            d(\bm{x}) = 
            \P_{L_B}\paren{
                s(L_B(\bm{x}) \leq \tau
            }
            - 
            \P_{L_A}\paren{
                s(L_A(\bm{x}) \leq \tau
            }
            \).
            Observe that \(d(\bm{x})\) does not depend on the Hiring System \(k\). Thus,
            \begin{gather*}
                D^{(2)}(\bm{x}) - D^{(1)}(\bm{x})
            =
                - \delta (\bm{x}) \cdot d(\bm{x}).
            \end{gather*}
            where
            \(\displaystyle
                \delta(\bm{x}) = 
                \P_{L_H^{(1)}}(
                    s(L_H^{(1)}(\bm{x})) \leq \tau
                ) - 
                \P_{L_H^{(2)}}(
                    s(L_H^{(2)}(\bm{x})) \leq \tau
                )
            \).
            Since \(L_A\) dominates \(L_B\) by assumption, by \Cref{prop: hiring outcome disparity}, \(d(\bm{x}) \geq 0\). By a very similar argument, since \(L_H^{(2)}\) dominates \(L_H^{(1)}\), \(\delta(\bm{x}) \geq 0\). It follows that
            \[D^{(2)}(\bm{x}) - D^{(1)}(\bm{x}) \leq 0.\qedhere\]
        \end{proof}

        \begin{remark}
            Note that the threshold-consistency condition is only necessary to guarantee that \(\tau^{*(1)} = \tau^{*(2)}\). Indeed, \Cref{thm: two-ticket improves outcome disparity} applies under alternative Hirer objectives if the optimal deployed threshold is the same for Hiring System 1 and 2.
        \end{remark}

        Under the No False Positives Objective, this decrease in individual outcome disparity naturally implies a decrease in \emph{group} outcome disparity and increase in accuracy (true positive rate) for both groups. 
        \begin{corollary}
            \label{cor: two-ticket improves group fairness}
            Define the true positive rate on Group \(g\) under Hiring System \(k\) as 
            \begin{align*}
                \TPR_g^{(k)} = \P\paren{
                    f^{(2)}_{\tau^{*(2)}}(\bm{x}''_A) = 1 \mid Y = 1
                }.
            \end{align*}
            Then with the same assumptions as \Cref{thm: two-ticket improves outcome disparity}, we have
            \begin{enumerate}
                \item \(\abs{\TPR_A^{(2)} - \TPR_B^{(2)}} \leq \abs{\TPR_A^{(1)} - \TPR_B^{(1)}}\).

                \item \(\TPR_g^{(2)} \geq \TPR_g^{(1)}\) for \(g \in \{A, B\}\).
            \end{enumerate}
        \end{corollary}
        \begin{proof}
            The first part follows almost immediately from \Cref{thm: two-ticket improves outcome disparity} by taking the expectation of the individual outcome disparity over the candidate distribution conditioned on \(Y = 1\).

            The second part follows from an application of \Cref{lem: expression for two-ticket acceptance probability} and a near-identical argument to \Cref{prop: hiring outcome disparity}.
        \end{proof}
        \jack{please take a look at above corollary when y'all have a chance}

        % From \Cref{def: two-ticket hiring with Applicant LLM manipulation}, a threshold that achieves the No False Positives Objective is\judy{Explain $z$, why is it not just x}: 
        %     \begin{equation*}
        %         \tau^* = \max_{\bm{z}''} s(\bm{z}'')
        % \end{equation*}
        % where 
        % \begin{align*}
        %     \bm{z}'' &\in \{\bm{z}'\} \cup \support(L_H(\bm{z}')) \\
        %     \bm{z}' &\in \{\bm{z}\} \cup \support(L_A(\bm{z})) \cup \support(L_B(\bm{z})) \\
        %     \bm{z} &\in \support(\bm{x} \mid H = 0) 
        % \end{align*}

\subsection{Connection to outcome indistinguishability?}

% One way to think about our approach is through the lens of \textit{Outcome Indistinguishability}~\cite{} between two predictors- . 
% Outcome indistinguishability refers to the concept where, given two predictors, the outcomes they produce cannot be reliably distinguished from one another. 
% To see this perspective, consider two individuals with the same feature vector, $x\in \mathbb{R}^{m+n}$. One of these individuals is in the privileged group and one is not. The question a screening software will output the same score for both of them (as we would want it to).

% In the one-ticket system, as we observe in... 
% \lc{Lee: add a reference to the exp. in section 3},
% there is a non-negligible difference between the scores of the unmodified and modified resumes. As a result, the 

% In contrast, since we observe that scores do not change significantly in the second run of LLM manipulation (compared to the first), we get that in the two-ticket system, our two individuals are no longer ``distinguishable''.  \lc{[[Lee: can we add what is the maximal difference in score between once modified and twice modified resume?]]}

% In the one-ticket system the enhanced resumes of the privileged group and the   
% Through our two ticket system, we are making everyone align with the privileged group (especially in a large n system): if the accuracy of the privileged group is bad, there is a problem with the screening software which needs to be addressed, but it is unfair to give the privileged group an advantage.

% Since the disparity in true positive rates between the privileged and unprivileged group decreases in the two ticket system, then there is outcome indistinguishability between the \textit{privileged} and \textit{unprivileged group}: namely, the outcome of the TPR is more similar across the both. 
% summarize main results here
\judy{Lee and I will look at this }
%\BOGO{just a high-level discussion: we want the unprivileged group to be indistingusihable from the privileged group}

%% Add in a section here - data on problems with hiring? OCT-02-2024
%how did we pick resumes (i.e. length)
\section{Case Study: Resume Screening in the Technology Sector}
    \label{sec: empirical experiments}

We validate our theoretical results using a real dataset of resumes using an open-source resume screening tool. Specifically, we compared the performance of \textsc{Traditional} hiring system to our new \textsc{Two-Ticket} hiring system. Our experiments show a significant increase ($p<$ \judy{TODO}) in classifier accuracy and a significant ($p<$ \judy{TODO}) decrease in group disparities.

We sample 520 resumes from the Djiini dataset \citep{drushchak-romanyshyn-2024-introducing}, a collection of resumes of applications for technology sector jobs. Half of our sample (260 resumes) were written for UI-UX roles and the other half were written for Project Manager roles. We chose these two categories since the resumes in these two categories were the least similar in terms of embedding distance.

We use an open-source resume scorer, Resume-Matcher\footnote{\url{https://github.com/srbhr/Resume-Matcher}}, to evaluate project manager qualifications among our 520 candidates. This resume scorer outputs a resume score between 0 and 100 relative to a Project Manager job posting which provides; this tool an approximation to \textit{applicant tracking systems} that contains a resume scoring step. 

We randomly sample half of all candidates to be in a \textit{privileged} group (Group A), and the remaining in an \textit{underprivileged} group (Group B).

Candidates in the \textit{privileged} group could modify their resumes, whereas \textit{underprivileged} resumes could not, replicating differing levels of LLM-quality, per defined in \Cref{def: formulation of LLM}. We also assume candidates our best-responding: as such, \textit{privilged} candidates would submit their maximal scoring resume amongst their choice of a modified and unmodified resume, whereas \textit{unprivileged} candidates could only submit their original, unmodified resumes. Finally, we applied LLM modifications using \textsc{ChatGPT-4o} with prompting that asked for improvements without hallucinations\footnote{See Appendix \ref{sec:experiment-details} for details.}. 

Our focus in simulating the Hirer's strategy was focused on comparing the performance of our two-ticket strategy with a standard SVM classifier on submitted resume scores, which does not take strategic LLM-manipulation into account.

We initially employed a standard SVM classifier from Python's sklearn library to establish a threshold for the resume scores that aligns with our theoretical objective: this threshold maximizes the classifier's True Positive Rate on the training set while maintaining a False Positive Rate of 0 (see \cref{def: no false positives objective}). Using this approach, we obtained performance metrics for our control traditional SVM classifier, providing insights into traditional hiring systems under the influence of applicant manipulations.

Next, to replicate our "two-ticket" strategy empirically, we also incorporate further data-preprocessing. Specifically, under the two-ticket strategy, the Hirer also modifies each submitted resume using its own language model. The Hirer then assesses candidates on the highest-scoring resume among both the submitted resume and the Hirer-modified version of the submitted resume. In our experiment, the Hirer and the candidates used the same language model (ChatGPT-4o) and the same prompt for their modifications: however, future experiments can also incorporate variations introduced with different language models and prompts.

We then evaluated the traditional SVM classifier and two-ticket classifer on our dataset of 520 candidates by first splitting it randomly into a 70\% training sample and 30\% testing sample. After training the ``traditional" SVM classifier on our training sample to identify a ``conservatively-optimal" threshold, we then utilized this threshold\footnote{Here, we replicate our "threshold-consistency" assumption (\Cref{def: threshold-consistency condition}).} to calculate two following metrics on our testing sample: first, the true positive rates of each classifiers, and second, the ``Group Outcome TPR Disparity" between the privileged and underprivileged candidates of each classifier \footnote{This disparity is defined as $|TPR_A-TPR_B|$, i.e. the absolute difference in True Positive Rate between the \textit{privileged} and \textit{underprivileged} group of candidates \cite{Hu2019}.}.

After calculating these parameters from our dataset, we created confidence intervals to capture the uncertainty of replicating this experiment on different raining and testing sample splits. Specifically, we generated 1000 train-test splits of size 520. For each of these train-test splits, we then repeated the steps outlined in the previous paragraph on these bootstrapped datasets to create a distribution of our True Positive Rates and group outcome disparity values, resulting in confidence intervals around our calculated metrics. Our findings are summarized in Table 1.

%After calculating these parameters from our dataset, we created confidence intervals to capture the uncertainty of replicating this experiment on new datasets from a "universal" population. Specifically, we generated bootstrapped datasets of size 520 by sampling with replacement from our original dataset of 520 candidates. We then repeated the steps outlined in the previous paragraph on these bootstrapped datasets to create a distribution of our True Positive Rates and group outcome disparity values, resulting in confidence intervals around our calculated metrics. Our findings are summarized in Table 1.

\begin{table}[h]
\caption{Metrics w/ 95\% Confidence Interval} \label{sample-table}
\begin{center}
\begin{tabular}{lll}
\textbf{}  &\textbf{TPR}  &\textbf{TPR Disparity} \\
\hline \\
Traditional SVM         &0.024 \pm 0.09 & 0.00409 \pm 0.12 \\
Two-Ticket SVM             &0.108 \pm 0.08 & 0.04269 \pm 0.06 \\
BS Differences  &0.084 \pm 0.04 & 0.0386 \pm 0.051 \\
95\% BS Diffs Range &[0.05, 0.163] & [-0.0619, 0.139] \\
\end{tabular}
\end{center}
\end{table}
%Shortened BS to Bootstrapped, will reformat later.
Our results hence most prominently indicate significant improvements in True Positive Rates under Two Ticket Strategies, though less significant improvements in our Disparity Metrics. Though we see that our 95\% confidence interval covers a potential decrease in disparity when transitioning to the Two-Ticket classifier, it remains statistically insignificant: further discussion on this result can be found in the below section.
\section{Discussion}

Our work first initiates a study of modeling techniques for non-deterministic strategic manipulations that are emblematic of LLM tools: this work hence has a range of applications in investigating the presence of LLMs in graduate school admissions, or even research-grant applications, to name a few. Provided with these LLM manipulation modeling tools, our work also explores strategies to create fair and equitable classification systems. We believe these initial LLM characterization tools and our initial design of a ``fair" Two-Ticket System can aid in the further design of equitable and accurate classification algorithms in response to strategic LLM manipulations.

Nonetheless, our model of LLM manipulations remains limited in fully embodying the diverse nature of these non-deterministic strategic behaviors. 

First and foremost, our empirical observations and model of LLM manipulations were based on data collected from a single, “generalized” prompt: “Can you improve my resume?” This prompt did not reference a specific job description or title. After all, we found that more descriptive prompts, especially those mentioning a specific position, led to significant and irreconcilable, manipulations affecting both the hirer and candidate. For instance, in our experiments, including “project manager” in our prompt (“Can you improve my resume for a project manager role?”) would drastically increase the occurrence of the word “project manager” in our unqualified (or UI/UX designer) resumes \footnote{Per our previous experiments, we still used additional prompting to combat false information - though this still did little to combat the ``false" use of the term "Project Manager".}. As Resume Scorer also relied heavily on the cosine-similarity between the word embeddings of our inputted resume and matched job description, we discovered that incorporating the word “project manager” in the prompt hence unfairly increased the score performance of UI/UX designers, as phenomena that can be credited solely to their fabricated use of the term “project manager” (regardless of whether or not they had ``true” project management experience). Consequently, our deployed SVM classifiers struggled with low accuracy, largely due to these drastic applicant LLM manipulations. This made it challenging to ensure any improvement from our "Two-Ticket" System, as manipulated resumes from unqualified candidates now closely resembled those of qualified candidates.

Our model also clearly distinguishes between LLM-alterable and unalterable features. However, as LLM tools become more sophisticated, it becomes increasingly difficult to differentiate between these two sets of features, as indicated by some preliminary experiments. For example, we utilized Chat-GPT to modify a UI/UX designer's resume for a specific project manager job posting from an anonymous company, which emphasized the importance of interpersonal skills like mentorship, leadership, and collaboration in their desired candidates. We found, surprisingly, that the outputted resume seemed to focus on trivial aspects of the UI/UX designer’s experiences, for example, emphasizing and elaborating on their experiences mentoring interns, as opposed to their more dedicated work in designing user-facing products. 

Ultimately, the underlying candidate maintains the same qualifications in both versions of their resumes. However, in emphasizing and elaborating on their project management experiences, no matter how trivial they may seem, LLM-modifications hence hold large potential in making them appear more qualified for the desired role. This thus indicates a future need in our work to address the relationship between such LLM-alterable and “unalterable” features.

Many automated hiring systems also already have alarmingly large various biases (\cite{amazon_ai_bias}) - hence reducing the impact of the improvements proposed by our 'Two-Ticket' System. In our own work, we hand-selected our experiment's scoring system (Resume Matcher) because of its supposed accuracy: however, future testing with other resume screening softwares may indicate even more biased and faulty systems. To better inform our model and work, future auditing work should hence systematically evaluate the potential disparities that arise across many professions and application tracking systems under LLM manipulations.

Finally, we aim to relax our ``Threshold-Consistency" (\Cref{def: threshold-consistency condition}) condition in order to establish more robust and universal guarantees of the improvements introduced by our ``Two-Ticket" system. 
%\lc{limitation- the results could be different if we do not use the same prompt + 
%If the accuracy of the privileged group is bad then there is a problem with the screening software + overall, under mild assumptions, we show that the problem of strategic manipulation done by LLMs is no longer a problem}

In summary, our findings apply only to mild manipulations that generally preserve the distinction between unqualified and qualified candidates in our "hiring" classification task. In addition to enhancing the robustness of our theoretical results, further work is needed to accurately represent the diverse nature of LLMs in our strategic model, as well as to expand the efficacy of our "Two-Ticket" strategy.

\lc{Lee: discuss multi-ticket scheme+ fix bibliography- for papers, I usually use dblp and we should only have the following fields: author, title, publisher/conference, and year- remove everything else.} 
\bibliography{bibliography}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Checklist}


% %%% BEGIN INSTRUCTIONS %%%
The checklist follows the references. For each question, choose your answer from the three possible options: Yes, No, Not Applicable.  You are encouraged to include a justification to your answer, either by referencing the appropriate section of your paper or providing a brief inline description (1-2 sentences). 
Please do not modify the questions.  Note that the Checklist section does not count towards the page limit. Not including the checklist in the first submission won't result in desk rejection, although in such case we will ask you to upload it during the author response period and include it in camera ready (if accepted).

\textbf{In your paper, please delete this instructions block and only keep the Checklist section heading above along with the questions/answers below.}
% %%% END INSTRUCTIONS %%%


 \begin{enumerate}


 \item For all models and algorithms submitted, check if you include:
 \begin{enumerate}
   \item A clear description of the mathematical setting, assumptions, algorithm, and/or model. [Yes/No/Not Applicable]
   \item An analysis of the properties and complexity (time, space, sample size) of any algorithm. [Yes/No/Not Applicable]
   \item (Optional) Anonymized source code, with specification of all dependencies, including external libraries. [Yes/No/Not Applicable]
 \end{enumerate}


 \item For any theoretical claim, check if you include:
 \begin{enumerate}
   \item Statements of the full set of assumptions of all theoretical results. [Yes/No/Not Applicable]
   \item Complete proofs of all theoretical results. [Yes/No/Not Applicable]
   \item Clear explanations of any assumptions. [Yes/No/Not Applicable]     
 \end{enumerate}


 \item For all figures and tables that submit empirical results, check if you include:
 \begin{enumerate}
   \item The code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL). [Yes/No/Not Applicable]
   \item All the training details (e.g., data splits, hyperparameters, how they were chosen). [Yes/No/Not Applicable]
         \item A clear definition of the specific measure or statistics and error bars (e.g., with respect to the random seed after running experiments multiple times). [Yes/No/Not Applicable]
         \item A description of the computing infrastructure used. (e.g., type of GPUs, internal cluster, or cloud provider). [Yes/No/Not Applicable]
 \end{enumerate}

 \item If you are using existing assets (e.g., code, data, models) or curating/releasing new assets, check if you include:
 \begin{enumerate}
   \item Citations of the creator If your work uses existing assets. Yes
   \item The license information of the assets, if applicable. 
   Yes, we note this dataset is under MIT Licence in the appendix 
   \item New assets either in the supplemental material or as a URL, if applicable. Not Applicable
   \item Information about consent from data providers/curators. 
   Yes, yes we note that the dataset create adheres to fair use and are willing to remove individuals upon request in the appendix
   \item Discussion of sensible content if applicable, e.g., personally identifiable information or offensive content. 
   Yes, we note that the resumes are anonymized 
 \end{enumerate}

 \item If you used crowdsourcing or conducted research with human subjects, check if you include:
 \begin{enumerate}
   \item The full text of instructions given to participants and screenshots. Not Applicable
   \item Descriptions of potential participant risks, with links to Institutional Review Board (IRB) approvals if applicable. Not Applicable
   \item The estimated hourly wage paid to participants and the total amount spent on participant compensation. Not Applicable
 \end{enumerate}

 \end{enumerate}


\input{supplementary}


\end{document}
