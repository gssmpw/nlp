\begin{abstract}
 

In an era of increasingly capable foundation models, job seekers are turning to generative AI tools to enhance their application materials. However, unequal access to and knowledge about generative AI tools can harm both employers and candidates by reducing the accuracy of hiring decisions and giving some candidates an unfair advantage. 
To address these challenges, we introduce a new variant of the strategic classification framework tailored to manipulations performed using large language models, accommodating varying levels of manipulations and stochastic outcomes. 
We propose a ``two-ticket'' scheme, where the hiring algorithm applies an additional manipulation to each submitted resume and considers this manipulated version together with the original submitted resume. We establish theoretical guarantees for this scheme, showing improvements for both the fairness and accuracy of hiring decisions when the true positive rate is maximized subject to a no false positives constraint. We further generalize this approach to an $n$-ticket scheme and prove that hiring outcomes converge to a fixed, group-independent decision, eliminating disparities arising from differential LLM access. Finally, we empirically validate our framework and the performance of our two-ticket scheme on real resumes using an open-source resume screening tool.



\end{abstract}

\section{Introduction}
Hiring decisions can profoundly impact an individual's professional path and long-term success. As algorithmic tools are increasingly deployed to recommend or make these decisions, they have rightfully come under scrutiny from economists~\citep{hu2018short, van2020hiring}, journalists~\citep{Lytton.2024}, and policy makers~\citep{cityofny}. AI tools that exhibit undue biases and unexplainable behavior present a major barrier to achieving accountability in these algorithmic hiring schemes~\citep{amazon_ai_bias}. Although algorithmic hiring tools are designed with the goal of hiring the best candidates, these tools may not be robust to candidates manipulating their application materials~\citep{ats_hack}. This problem has been studied through the lens of \textit{strategic classification} where individuals can manipulate their inputs (e.g., a job application) to influence the decision made by a classifier (e.g., a hiring algorithm)~\citep{Hardt2015,kleinberg2020classifiers, levanon2021strategic}. The goal of the hiring side is to design a strategy-proof selection algorithm, while the goal of the applicants is to maximize their utility: the difference between the benefit of receiving a positive prediction and the cost of manipulation. The ``best response'' is then the optimal way an individual should modify their input, when the classifier's behavior is known, to achieve the highest utility. The challenge lies in designing classifiers that are robust to such manipulations while maintaining fairness and accuracy.
    
With the recent proliferation of generative AI services that are now widely used by job seekers \citep{Chamorro_2024}, a new variable has been introduced in the algorithm hiring cycle and strategic classification. Writing or editing a resume using generative AI has become accessible and widespread.
%ChatGPT alone has 300 million weekly users as of January 2025~\citep{DemandSage_2025}, and 
In a recent survey, 57\% of respondents admitted to using AI to create their resume~\citep{Canva_2025}. 
%In this new world, job candidates who have the knowledge and resources to access a better language model service may benefit disproportionately. 
%Job candidates who have access to more premium LLM services (e.g., ChatGPT-4.0) are unlikely to edit their resumes using more basic versions (e.g., ChatGPT-3.5) and will instead rely on their preferred modelâ€”whether it's Claude, GPT, or another option. 
Since candidates have no knowledge of 
how employers make hiring decisions, %which ATS (Applicant Tracking System) model is deployed by the hirer, 
the optimal strategic classification response becomes straightforward: candidates edit their resumes using their preferred AI tool, opting for a premium version if they recognize its advantages and can afford it. As a result, those accessing better models may gain an unfair advantage in the selection stage of automatic hiring algorithms. Thus, companies might be filtering for candidates who used the best LLMs rather than candidates who are the most qualified. 


The interactions between hiring algorithms and application-enhancing generative AI tools create a unique setting to examine fairness and strategic behavior. Since manipulation in this setting is low-effort, many candidates will choose to manipulate their resumes, even without a guaranteed positive prediction. This contrasts with the classic model, where individuals manipulate their input only when a positive outcome is achieved.
%While job seekers have long had access to varying levels of support from spell checkers to career coaches, the strategic improvement of application materials may be more prevalent than ever before. 
%Notably, inequality may now also arise when job candidates have unequal access to different tiers of Large Language Model (henceforth, LLM) services due to differences in costs or knowledge of their performances. %Job candidates who are able to access (more premium) LLM services may achieve an unfair advantage in the screening stage of automatic hiring algorithms.
%Marginalized groups may experience further setbacks if there exist cost barriers to premium LLM services during the job application process. 
Moreover, strategic classification in the era of LLMs introduces two key challenges: (1) unlike prior group-based fairness settings, the hirer cannot directly determine whether an application has been manipulated or which LLM was used, and (2) unlike the classic strategic classification setting, manipulations are stochastic, as LLM outputs are inherently non-deterministic. Motivated by this complex yet realistic interaction between strategically generated application materials and algorithmic hiring algorithms, our work presents a first step into modeling and analyzing algorithmic hiring ecosystems in the era of generative AI; our contributions are as follows: 
    \begin{itemize}
        \item We show that some (more expensive) models enhance resume relevance scores more than other models, and that the benefits of repeated LLM manipulations stagnate (\Cref{sec: empirical motivation}).
        %applying the same LLM to an application that has already been manipulated by it does not significantly change the application's evaluation score in the screening process.
        \item We translate the empirical behavior of LLMs used for job applications into a realistic model for strategic classification %bespoke model of strategic classification 
        (\Cref{sec: model}).  
        \item  
        We prove that under existing hiring schemes, disparities in access to LLMs lead to disparities in hiring outcomes, even under \textit{stochastic} manipulations (\Cref{sec: disparities}) and an unknown deployed model.
        
        \item We introduce a two-ticket scheme where the hiring algorithm applies an additional LLM manipulation to each submitted resume and considers this manipulated version together with the original submitted resume. We prove that this scheme improves disparities among candidates and accuracy for employers. We also generalize the two-ticket scheme to an $n$-ticket scheme, proving that the $n$-ticket scheme eliminates group-dependent disparities as $n\rightarrow \infty$, with outcomes converging exponentially to a fixed, group-independent decision  (\Cref{sec: two-ticket scheme}).
        
        \item We validate our theoretical model and results through a case study using real resumes and an open-source resume scoring algorithm (\Cref{sec: empirical experiments}), demonstrating that our two-ticket scheme enhances both fairness and accuracy in practice.
    \end{itemize}
    

\section{Related Work} \label{sec: related work}

\textbf{Fairness in Algorithmic Hiring} Audits of hiring systems have consistently found discrimination in outcomes based on race, gender, and age~\citep{bertrand2004emily, kline2022systemic}.  \citet{raghavan2020mitigating} study the screening stage of the hiring algorithms and connect legal perspectives with algorithmic approaches to mitigate the disparate impact. 
%Mitigating biases has also been described as crucial to the ``ethicality of the AI tool design''~\citep{hunkenschroer2022ethics}. 
In terms of proposed solutions, \citep{lin2021engineering} suggest ``augmentation-based'' interventions where AI-assisted decisions can best achieve equitable outcomes. A key assumption of prior work is access to (explicit or inferred) group membership. In our work, the hiring side has no knowledge of the group membership of candidates, yet we can mitigate bias nevertheless.  

\textbf{Strategic Classification}
~\citet{Hardt2015} introduce strategic classification as a Stackelberg game to address the impact of manipulative tactics on classification problems. We draw on several later works that provided a modified strategic classification game that models disparities in manipulation abilities~\citep{Hu2019, milli2019social, chen2020strategic, diana2024minimax}. Furthermore, we utilize techniques from \citep{Braverman2020} to describe ``random'' classifiers in light of stochastic strategic manipulations. Similarly to several previous works~\citep{GhalmeNETR21, cohen2024bayesian}, we assume that the deployed classifier is unknown to the candidates.

\textbf{Behavior and Risks of Generative Models} 
Guidance counselors and career coaches alike now recommend using generative AI tools to help with application materials~\citep{Verma_Renjarla_2024, Chamorro_2024}. However, recent research has highlighted a plethora of risks. For example, LLMs have been shown to hallucinate, which may mislead employers~\citep{huang2023survey} or memorize text, which can result in unintended plagiarism~\citep{carlini2022quantifying}. Since unintended plagiarism is difficult for job applicants to detect using these tools;  the benefits of applying LLMs to application materials may be stochastic. 

    
\section{Empirical Motivation: Stochastic Resume Manipulation using LMMs} \label{sec: empirical motivation}
\begin{figure*}[ht]
    \centering
        \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{imgs/DD_PM_1round.pdf}
        \caption{DoorDash Product Manager Job Posting}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{imgs/google_ux_1round.pdf}
        \caption{Google UX Designer Job Posting}
    \end{subfigure}%
    \caption{Resume score distribution of 50 qualified (matching occupation) and 50 unqualified (different occupation) resumes before and after LLM manipulations for two job descriptions. Models such as \textsc{GPT-4o} and \textsc{Claude-3.5-Sonnet} and \textsc{DeepSeek-V3} generate a distribution of unqualified resumes that is indistinguishable from qualified resumes without manipulation for the Product Manager job and significantly enhance the scores of the qualified resumes for the UX Designer position.}
    \label{fig:llm-resume-dd}
\end{figure*}

\begin{figure*}[ht]
    \centering
        \centering
    \begin{subfigure}[t]{0.6\textwidth}
        \centering
        \includegraphics[width=\textwidth]{imgs/DD_PM_mapping.pdf}
        \caption{Resulting score improvement after applying LLM manipulation with different models.}
        \label{fig:mapping}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{0.35\textwidth}
        \centering
        \includegraphics[width=\textwidth]{imgs/doordash_pm_1vs2rounds.pdf}
        \caption{Resume Scores over Sequential LLM Manipulations}
        \label{fig:two-rounds}
    \end{subfigure}%
    \caption{(a) Applying LLM manipulations to resumes result in stochastic outcomes: even when the average score increases (e.g., \textsc{DeepSeek-V3}, some resumes receive lower scores after manipulation). (b) Repeatedly using LLMs to enhance a resume results in stagnating improvements.}
    \label{fig:observations-a-c}
\end{figure*}


Since prior works in strategic classification focus on deterministic manipulations, we empirically motivate our theoretical model of stochastic LLM manipulations. We prompt a variety of models to improve technology sector resumes \citep{drushchak-romanyshyn-2024-introducing}.\footnote{See Appendix \ref{app:experiment-details} for prompt details and prompt analysis experiments to reduce hallucinations.}  We used a general prompt to simulate a job applicant who is aiming to apply to multiple jobs with the same enhanced resume (e.g., via recruitment agency).
%Given the increasing over-saturation of hiring in the tech industry, we believe the "general" nature of this prompt effectively captures how individuals might seek to enhance their resumes. For instance, due to the time constraints and the sheer volume of available positions, candidates may not be able to tailor their resumes for every job they apply to, and rather, submit the same resume for multiple relevant job postings. 
The resumes were then evaluated against the target job descriptions through open source software that scores resumes against a designated job description to produce a \textit{relevance score}. This type of simple scoring model, as a first filter for resumes, is widespread with 98.4\% of Fortune 500 companies using them within applicant tracking systems~\citep{jobscan2025}.
%for each resume between 0 and 100 that reflects the relevance of the resume to the job description. 
We identified three key behaviors of LLM manipulations: 
\begin{enumerate}
    \item LLM manipulations stochastically enhance resume scores (Figure\ref{fig:mapping}),
    \item The effectiveness of LLM manipulations varies by model: newer, premium LLMs improve resume scores more (Figure~\ref{fig:llm-resume-dd}),
    \item Improvements from manipulations stagnate with repetition: applying the same LLM repeatedly to the same resume results in diminishing changes (Figure~\ref{fig:two-rounds}). 
\end{enumerate}

Figure~\ref{fig:llm-resume-dd} illustrates that using a simple job-agnostic prompt with an input resume significantly improves the scores computed by a resume screening system. Qualitatively, we observed a drastic improvement in writing quality (examples available in Appendix~\ref{app:best-responding candidates}); the LLMs were able to transform resumes mostly containing bullet points about the candidate's interests or skills into more effective, reworded resumes delineating prior roles. However, scores did not improve monotonically across resumes; some resume scores decreased after applying LLM manipulation (Figure \ref{fig:mapping}). 

A second observation that motivates our study of disparities is the differential outcomes resulting from applying different LLMs to a candidate's resume. Figure ~\ref{fig:llm-resume-dd} shows the post-manipulation resume scores on a broad set of models. Using the dotted lines as a reference for the median score of the original resumes of the qualified group, it is evident that applying different LLMs has different effects on the outcome relevance score. Distinguishing qualified and unqualified candidates is already a difficult task, but candidate manipulation makes it harder. Some models, particularly the higher cost-to-access models (e.g., \textsc{Claude-3.5-Sonnet}, \textsc{GPT-4o}) improved the resume scores of the unqualified resumes so that they were indistinguishable or better than the qualified resumes without LLM manipulations, while cheaper or free-to-access models (e.g., \textsc{GPT-3.5-Turbo}, \textsc{Mixtral-8x7B-Instruct}) did not significantly improve scores on average of the unmanipulated resumes regardless of qualification.\footnote{Model pricing rapidly changes for consumer platforms. Furthermore, not all models are available on consumer platforms. We include a cost analysis for API access to simulate third-party career services with tiered offerings in Table \ref{tab:API-summary}.} By qualitatively inspecting the manipulated resumes, we found that LLMs yielding larger score improvements (e.g., \textsc{ChatGPT-4o}) better adhered to the traditional elements of a resume while less effective models simply reorganized the input resume. For example, \textsc{ChatGPT-4o} also added additional elements such as a resume summary and dedicated sections for educational history.\footnote{Representative examples can be found in Appendix \ref{app:best-responding candidates}.} We also found that all of the newer, premium models (particularly \textsc{Claude-3.5-Sonnet}), increased the average similarity in embedding distance between resumes after manipulation (Figure~\ref{fig:resume_sim}). 

Finally, we also observed that repeated manipulations did not significantly alter resumes. %\textcolor{blue}{LC: Is it a qualitative argument or can we back this up by data (assuming we're referring to the scores and not the actual resumes)}.
The first round of modifications typically standardized language and formatting according to a conventional resume structure. However, a second round of manipulations did not deviate substantially from the first. This observation is also illustrated by the similarity of the resume score distributions of the once and twice-manipulated resumes (see Figure~\ref{fig:two-rounds}).  

Together, these three key observations regarding LLM manipulations --- the potential for resume improvement, the differences in results among various LLM models, and stagnation in changes from multiple iterations  --- motivate our proposed model of these strategic manipulations in \Cref{sec: model}. 
\section{%Our Hiring 
Model} \label{sec: model}


% \subsection{Preliminaries}
We represent each candidate as a triplet \((\bm{x}, g, y)\), where \(\bm{x} \in \mathbb{R}^{d}\) represents the candidate's original (unmanipulated) resume features, \(g \in \{P, U\}\) denotes the group membership, with $P$ indicating the privileged group and $U$ indicating the unprivileged group, and \(y \in \{0,1\}\) represents the true label, with $0$ indicating an unqualified candidate and $1$ indicating a qualified candidate. It is important to note that we do not require that \(\bm{x}\) fully determines \(y\).



Our model accommodates any combination of $d_1$ \textit{fundamental} and $d_2$ \textit{style} features in the feature space (i.e., $d=d_1+d_2$). Fundamental features ($x_1, x_2, \dots, x_{d_1}$) refer to technical attributes such as programming skills, years of experience, or educational background, whereas style features ($c_1, c_2, \dots, c_{d_2}$) refer to attributes about a resume's presentation such as writing quality, vocabulary, and grammar.\footnote{If all features are fundamental features (\(d_1 = 0\)), then the scenario reduces to traditional non-strategic classification.} Overall, we express each candidate's resume features as an \(d\)-dimensional feature vector in \(\R^{d}\):
\[\bm{x} = [x_1, x_2, \dots, x_{d_1}, c_1, c_2, \dots, c_{d_2}]. \]


We model the candidate population as a joint distribution \(\D\) over feature vectors, group memberships, and true labels. We define the random variable triplet \((\bm{X}, G, Y) \sim \D\) with \(\bm{X} \in \mathcal{X}\), \(G \in \{P, U\}\), and \(Y \in \{0,1\}\). Moreover, we assume that both groups have identical distributions over resume feature vectors, and that the true label is independent of group membership. In other words, we assume that \(\bm{X}\) and \(G\) are independent and that \(Y\) and \(G\) are conditionally independent given \(\bm{X}\). For our model to be appropriate, each group comprises a non-negligible proportion of the population: that is, \(\mathbb{P}(G = P), \mathbb{P}(G = U) > 0\).

\subsection{LLM Manipulation}
    We assume some candidates are manipulating using  LLMs~\citep{Verma_Renjarla_2024, ats_hack}. In what follows, we now formalize our model for LLM manipulation of resumes. 

    \begin{definition}[Mathematical formulation of Strategic LLM Manipulation]
        \label{def: formulation of LLM}
    
        An \emph{LLM manipulation} is a random function \(L:\mathcal X \rightarrow \mathcal X\) characterized by a series of (not necessarily independent) real-valued random variables \(\chi_1, \chi_2, \dots, \chi_{d_1}\). When called upon a feature vector \(\bm{x} = [x_1, \dots, x_{d_1}, c_1, \dots, c_{d_2}]\),
        \begin{enumerate}
            \item \(L\) \emph{replaces} each \(x_i\) with a value drawn from \(\chi_i\) for \(1 \leq i \leq d_1\).
            \item \(L\) \emph{preserves} the value of \(c_j\) for \(1 \leq j \leq d_2\).
        \end{enumerate}
        In other words,
        \[L([x_1, \dots, x_{d_1}, c_1, \dots, c_{d_2}]) = 
        [\chi_1, \dots, \chi_{d_1}, c_1, \dots, c_{d_2}].
        \] 
    \end{definition}
    Our formulation of LLM manipulations is based on our observations that LLMs can standardize style features such as writing quality, vocabulary, and organization --- to the point that the original values are irrelevant and are redistributed according to a distribution dependently only on the LLM. On the other hand, candidates would like LLMs to preserve their fundamental features. Changes to their fundamental features may be extremely costly to the candidate, as hirers may decide to blacklist or dismiss dishonest candidates. The prompts for our experiments also work to elicit this outcome: to minimize the chances of hallucination, our prompt states explicitly that is ``imperative that the new resume do not add any facts that are not in the original resume''. We manually inspected some sampled outputs to confirm that generated outputs contained no hallucinations (though we have not inspected all the outputs).
    \begin{figure}[t]{}
        \centering
        \includegraphics[height=2.0in]{imgs/llmmanipulations.png}
        \caption{Visualization of an \textit{LLM Manipulation} \(L\) over \(\mathcal{X} = \R^2\) with one style feature ($x_1$) and one fundamental feature ($x_2$). Modifying $x_1$ may move the candidate into the acceptance region (in blue).}
    \end{figure}
    This perspective is informed by our empirical observations detailed in \Cref{sec: empirical motivation}. Our experiments first indicated that LLM manipulations effectively overwrite writing style attributes. This is captured in our model, where the style features are redistributed according to a fixed random distribution. 

    \begin{remark}
        \(L\) could represent a single use or multiple uses of an LLM to improve a resume.
    \end{remark}

\subsubsection{Hiring Schemes}
    In our hiring scheme, we define the \emph{Hirer} who is making the hiring decisions and the \emph{Candidate} who is applying for the job. Our work focuses on job positions receiving large volumes of applications: for this reason, we assume that the Hirer 
    evaluates 
    each candidate's resume 
    by assigning each a real-valued score. 
    More specifically, our model assumes that the Hirer uses some fixed scorer to evaluate the candidates resumes (in the experiments we use Resume Matcher as the scorer). We represent this scorer as a function \(s:\mathcal{X} \to \R\). We make no assumptions about \(s\) other than that it is monotonically non-decreasing.
    
    Note that we assume that the Hirer has no control over \(s\). In practice, employers have little control over the scorers purchased from applicant screening software providers at the candidate screening stage. They can, at best, choose the best scorer available (e.g., most accurate)  and tweak it accordingly. In our model, the resume score is how the Hirer decides which candidates move on to the next stage. This implies that the Hirer does not have the resources to manually filter resumes for only fundamental features. This reflects the widespread usage of applicant tracking systems (ATS) by employers.
    

    We assume that each Candidate group \(g\) has access to its own LLM, \(L_g\). Likewise, the Hirer also has access to their own LLMs that are separate from the Candidates'.


\subsection{Traditional Hiring with LLM Manipulations}

    We now introduce our strategic LLM classification game for traditional hiring with Candidate LLM manipulation. A candidate can use the LLM available to their group (\(L_g\)) to manipulate their resume --- the candidate then chooses which of these two resumes (original or manipulated) to submit to the Hirer.
        
    The Hirer determines a threshold $\tau\in \R$ and accepts candidates with scores equal to or larger than the threshold. Namely, the Hirer decision regarding a candidate with a submitted resume $x'$ is \(f_\tau(\bm{x}') = \one[s(\bm{x}') \geq \tau]\). We assume that there are many candidates, so the cost of missing qualified individuals is less than the cost of interviewing or accepting unqualified candidates. Minimizing false positives is a natural objective in the context of hiring as hiring unqualified candidates (or inviting them for an interview) is costly. False positive has been studied in the context of fairness (e.g.,~\citet{cohen_et_al:LIPIcs.FORC.2020.1},~\citet{Blum22}), and strategic classification (e.g.,~\citet{AhmadiBBN22},~\citet{shao2023strategic}). In this vein, we introduce the No False Positives Objective. 

    \begin{definition}[No False Positives]
        \label{def: no false positives objective}
        The \textit{No False Positives Objective} is achieved when the Hirer maximizes true positive rate (TPR) subject to no false positives. The optimization problem is: 
        \begin{align*}
        \begin{array}{ll}
        \mbox{maxmize}_{\tau}  & \TPR(\tau) \\
        \mbox{subject to} & \FPR(\tau) = 0
        \end{array}
        \end{align*}
        where        
        \begin{align*}
            \textrm{TPR}(\tau) &= \P(f_\tau(\bm{x}') = 1 \mid Y = 1)\quad \text{and} \\
            \textrm{FPR}(\tau) &= \P(f_\tau(\bm{x}') = 1 \mid Y = 0).
        \end{align*}  
        We let \(\tau^*\) denote the minimum threshold in the solution set.
    \end{definition}
    Our work specifically focuses on classifiers that optimize true positive rates: this approach will specifically inform our further study of disparities between groups in \Cref{sec: disparities}. We aim to satisfy a specific case of \textit{Equalized Odds} \citep{hardt2016equality} when the false positive rate is fixed at zero, which is a special case of equal false positive rates across groups. 
    
    \fbox{\begin{minipage}{\linewidth}
        \begin{definition}[\textsc{Traditional} Hiring Scheme under LLM Manipulation]
            \label{def: traditional hiring with Candidate LLM manipulation} 
            The Hirer and the Candidate play the following Stackelberg game.
            \begin{enumerate}
                \item The Hirer commits to a scorer $s$ and a  threshold \(\tau \in \R\), both unknown to candidates. 
            
                \item Each candidate \((\bm{x}, g, y)\) chooses to submit either their original resume \(\bm{x}' = \bm{x}\) or their LLM-manipulated resume \(\bm{x}' = L_g(\bm{x})\).

    
                \item The Hirer accepts candidates according to the threshold classifier \(f_\tau(\bm{x}') = \one[s(\bm{x}') \geq \tau]\). 
                
            \end{enumerate}
            
            Each player has the following payoffs:
            \begin{enumerate}
                \item The Candidate payoff is whether they are accepted: \(\one[f_\tau (\bm{x}') = 1]\).
                
                \item The Hirer's payoff is defined according to the No False Positives Objective (\Cref{def: no false positives objective}).
            \end{enumerate}
        \end{definition}
    \end{minipage} }
    \begin{remark}
        Unlike classic strategic classification, our game does not directly assume that the Candidate has perfect knowledge about \(f_{\tau}\): after all, hiring schemes are often opaque. However, we assume that candidates know which of the two versions (unmanipulated and manipulated) of their resume will score higher. Additionally, since writing a prompt in an LLM is very easy, we assume it has negligible cost and that each candidate will use the more advanced LLM if they have access to it (i.e., a candidate from the privileged group will not use $L_U$). %As such, our game is functionally equivalent to the Candidate having perfect knowledge about \(f_\tau\). 
        A best-responding candidate in group \(g\) will therefore submit
        \begin{align*}
            \bm{x}'_g = \argmax_{\bm{z} \in \{\bm{x}, L_g(\bm{x})\}} s(z).
        \end{align*}
    \end{remark}
    In our model, candidates do not incur costs for prompting their LLM for the manipulation or for selecting the better application. This is in contrast to prior work in strategic classification, where manipulations, such as getting multiple credit cards, require time and effort~\citep{Hardt2015}. Our model does however separate $L_P$ and $L_U$: this is equivalent to how privileged groups in prior works are given larger budgets when costs are incurred~\citep{milli2019social}. 
     
    The Hirer does not know and may not infer whether a resume has been manipulated or from which group a resume comes. Rather, the Hirer must use the same scoring scheme and threshold for all candidates.    
    
    
\section{Disparities in Traditional Hiring with Unequal Candidate LLM Manipulation}
\label{sec: disparities}
    In this section, we show that, under a traditional hiring scheme, disparities in LLM qualities between candidate groups can lead to disparities in hiring outcomes. We begin by defining a useful metric for disparity in hiring outcomes. Since we assume that groups \(P\) and \(U\) have the same unmanipulated feature vector distribution,  
    we define the resume outcome disparity as follows.
    \begin{definition}
        \label{def: resume outcome disparity}
        Given a resume feature vector \(\bm{x} \in \mathcal{X}\), the \emph{resume outcome disparity} $\Delta$ is defined as
        \begin{equation*}
            \Delta(\bm{x}) = \P_{L_P}(f_\tau(\bm{x}'_P) = 1) - \P_{L_U}(f_\tau(\bm{x}'_U) = 1), 
        \end{equation*}
        
        where \(\bm{x}'_g = \argmax_{\bm{z} \in \{\bm{x}, L_g(\bm{x})\} } s(\bm{z})\) for \(g \in \{P, U\}\).
    \end{definition}


    Observe that if the original unmanipulated resume is accepted (that is, \(f_\tau(\bm{x}) = 1\)), then \(\Delta(\bm{x}) = 0\). 
    
    To address the differences in the output quality of different LLMs, we use the notion of multivariate stochastic dominance as provided by \citep{levhari1975efficiency}. 
    
    \begin{definition}[\citep{levhari1975efficiency}]
        Let \(Z_1, Z_2\) be random variables over \(\mathcal{X}\). For any \(a \in \mathcal{X}\), let \(F_k(a) = \P(Z_k \leq a)\), where \(\leq\) denotes component-wise order. We say that \(Z_1\) \emph{stochastically dominates} \(Z_2\) if for any open lower set \(S \subseteq \mathcal{X}\),
        \begin{equation*}
            \int_S dF_1 \leq \int_S dF_2.
        \end{equation*}
    \end{definition}
    This is a generalization of (first-order) univariate stochastic dominance to multivariate distributions. Intuitively, stochastic dominance requires that the generalized CDF of \(Z_1\) must always be ``less'' than the generalized CDF of \(Z_2\). Stochastic dominance induces a partial order over multivariate random variables. Furthermore, we use the following key property about stochastic dominance.
    
    \begin{lemma}[\citep{levhari1975efficiency}]
        \label{lem: stochastic dominance utility}
        \(Z_1\) stochastically dominates \(Z_2\) if and only if for every non-decreasing function \(u\),
        \[\E[u(Z_1)] \geq \E[u(Z_2)].\]
    \end{lemma}

    We use this definition to define our ordering over LLM quality.
    \begin{definition}
        Let \(L_1, L_2\) be LLM manipulations. We say that \(L_1\) \emph{dominates} \(L_2\) (\(L_1 \succeq L_2\)) if for all \(\bm{x} \in \mathcal{X}\), \(L_1(\bm{x})\) stochastically dominates \(L_2(\bm{x})\).        
    \end{definition}
    Informally, an LLM \( L_1 \) may be considered ``better'' than \( L_2 \) if it stochastically dominates \( L_2 \) on each input, indicating that \( L_1 \) has a greater likelihood of feature improvement than \( L_2 \). Note that this only implies that \(L_1\) \emph{tends} to produce a better output than \(L_2\); \(L_2\) may produce a better output than \(L_1\) on certain realizations of their stochastic outputs.

    \begin{remark}
        \label{rem: null LLM}
         To simulate the absence of access to an LLM in our strategic classification game, it is helpful to artificially define a ``null LLM'' (\(L_\varnothing\)) that is dominated by all other LLMs. We might informally conceptualize \(L_\varnothing\) as having random variables \(\chi_i = -\infty\) for \(1 \leq i \leq d_1\). This allows us to conceptualize traditional hiring as a special case of \textsc{Two-Ticket} hiring in which the Hirer deploys the null LLM which does not provide an additional ``ticket'' for the candidate. 
    \end{remark}

    We now show that, under this definition, using a better LLM on the same resume leads to a better hiring outcome.

    \begin{restatable}{theorem}{theoremOne}
        \label{thm: hiring outcome disparity}
        Suppose \(L_P \succeq L_U\). Then for all \(\bm{x} \in \mathcal{X}, \Delta(\bm{x}) \geq 0\).
    \end{restatable}
    % Proof sketch
    \begin{proof}[(\textit{Proof Sketch})]
        Since \(\P_{L_g}(f_{\tau}(\bm{x}'_g) = 1) = \E_{L_g}[f_{\tau}(\bm{x}'_g)]\) and \(f_{\tau}\) is non-decreasing, we can apply \Cref{lem: stochastic dominance utility} to show that \(\P_{L_P}(f_\tau(\bm{x}'_P) = 1) \geq \P_{L_U}(f_\tau(\bm{x}'_U) = 1)\).        
    \end{proof}

    This disparity in resume outcomes naturally leads to disparity in group outcomes. Under the No False Positives Objective, it is natural to measure group outcomes by comparing groups' true positive rates. We denote the TPR over a group \(g\) as
    \begin{equation*}
        \TPR_g = 
        \P\paren{
            f_\tau(\bm{x}'_g) = 1 \mid Y = 1, G = g
        }.
    \end{equation*}
   To address fairness, we define the disparity between the TPRs of two groups. This fairness notion has been studied previously in the context of strategic classification (e.g.,~\citep{Keswani23}).
    \begin{definition}
        \label{def: TPR disparity}
        The \emph{TPR disparity} \(\Delta_{\TPR}\) is defined as 
        \[\Delta_{\TPR} = \TPR_P - \TPR_U.\]
    \end{definition}
 Having defined the TPR disparity, we show that qualified candidates from the privileged group have a higher (or equal) probability of being accepted compared to qualified candidates from the unprivileged group.
    \begin{restatable}{corollary}{corollaryOne}
        \label{cor: traditional is group-unfair}
        Suppose \(L_P \succeq L_U\). Then,
        \[\Delta_{\TPR} \geq 0.\]
    \end{restatable}
    \begin{proof}[(\textit{Proof Sketch})]
        This follows from applying \Cref{thm: hiring outcome disparity} over candidates with \(Y = 1\).
    \end{proof}
    


\section{Combating LLM Disparities: Two-Ticket Scheme}
\label{sec: two-ticket scheme}

    To counteract the disparity in hiring outcomes due to unequal LLM access, we propose a modified hiring scheme where the Hirer performs their own round of LLM manipulation over the possibly manipulated applications. Our motivating experiments (\Cref{sec: empirical motivation}) show that running a resume through a high-quality LLM twice changes the resume much less on the second run than on the first. We show that bestowing both groups with the benefit of a round of high-quality LLM manipulation can help level the playing field.

    \subsection{Two-Ticket Scheme}
        We present the modified strategic classification game under the \textsc{Two-Ticket} scheme. This scheme is identical to \textsc{Traditional} hiring except that the Hirer now uses their own LLM (\(L_H\)) to manipulate each submitted resume. The Hirer then scores the best of these two versions to determine whether to accept each candidate.
        
        \fbox{
        \begin{minipage}{\linewidth}
            \begin{definition}[\textsc{Two-Ticket} Hiring Scheme under LLM Manipulation]
                \label{def: two-ticket hiring with Candidate LLM manipulation}
                \phantom{so it does not overflow the line}
                \begin{enumerate}
                    \item The Hirer commits to a scorer $s$ and a  threshold \(\tau \in \R\), both unknown to candidates 
                    \textcolor{blue}{and some LLM \(L_H\)}.\footnote{The text in \textcolor{blue}{blue} distinguishes our \textsc{Two-Ticket} hiring scheme from the \textsc{Traditional} hiring scheme.}
                    
                    % Condensed
                    \item Each candidate \((\bm{x}, g, y)\) chooses to submit either their original resume \(\bm{x}' = \bm{x}\) or their\\ LLM manipulated resume \(\bm{x}' = L_g(\bm{x})\).
                    
        
                    \item\label{clause:max}\textcolor{blue}{The Hirer chooses to consider the higher scoring resume among the submitted resume\\ \(\bm{x}'' = \bm{x}'\) and the LLM-manipulated submission \(\bm{x}'' = L_H(\bm{x}')\).}
                    
                    \item 
                    The Hirer accepts candidates according to the threshold classifier \(f_\tau(\bm{x}'') = \one[s(\bm{x}'') \geq \tau]\). 
    
                \end{enumerate}
                
                Each player then has the following payoffs:
                \begin{enumerate}
                    \item The candidate payoff is \textcolor{blue}{the probability that they are accepted: \(\P_{L_H}(f_\tau (\bm{x}'') = 1)\)}.
                    
                    \item The Hirer's payoff is defined according to the No False Positives Objective (Definition~\ref{def: no false positives objective}).
                \end{enumerate}
            \end{definition}
        \end{minipage} 
        }\\
        
        In practice, the Hirer scores both the submitted resume and the Hirer LLM-manipulated resume, and accepts the candidate if one of the scores passes the threshold. 
        This is where our name ``Two-Ticket Hiring'' comes from: each candidate is essentially given two avenues to acceptance.\footnote{Traditional hiring can be analogously thought of as ``One-Ticket'' hiring, as the candidate's submitted resume is their only avenue to acceptance.} This is equivalent to the above definition: our chosen presentation emphasizes the symmetry of the Hirer's LLM manipulation and the Candidate's LLM manipulation.

        While LLM manipulations generally improve resume quality, there is a chance that they can decrease a candidate's score (\Cref{sec: empirical motivation}). To ensure that candidates are not unfairly harmed by LLM manipulations, we safeguard against this possibility by requiring the Hirer to evaluate the maximum of the candidate's submitted and its Hirer-manipulated version of each resume. 

        The \textsc{Traditional} hiring game (Definition~\ref{def: traditional hiring with Candidate LLM manipulation}) can be considered a special case of the \textsc{Two-Ticket} hiring game (Definition~\ref{def: two-ticket hiring with Candidate LLM manipulation}), where \(L_H\) is the null LLM discussed in \Cref{rem: null LLM}. Thus, we compare the behavior of two different \textsc{Two-Ticket} games: the game under \textsc{Traditional} hiring (Definition~\ref{def: traditional hiring with Candidate LLM manipulation}) and the game under \textsc{Two-Ticket} hiring schemes (Definition~\ref{def: two-ticket hiring with Candidate LLM manipulation}), which differ only in the Hirer's choice of LLM and threshold in our formalization.

    \subsection{Guaranteed Two-Ticket Improvements}
        We now prove that under natural 
        %circumstances
        conditions, a \textsc{Two-Ticket} hiring scheme can decrease the resume outcome disparity between the two groups, leading to improvement in accuracy and fairness.
    
        For \(k \in \{1, 2\}\), we define Hiring Scheme \(k\) to be the \textsc{Two-Ticket} scheme using Hirer LLM (\(L_H^{(k)}\)) and scheme-dependent threshold \(\tau^{(k)}\), resulting in deployed classifier \(f^{(k)}\). Let \(\Delta^{(k)}(\bm{x})\) and \(\Delta_{\TPR}^{(k)}\) denote the resume and group outcome disparity respectively for Hiring Scheme \(k\). To compare the \textsc{Traditional} hiring scheme with the \textsc{Two-Ticket} hiring scheme, we denote the \textsc{Traditional} hiring scheme as $k=1$ with \(L_H^{(1)} = L_\varnothing\). With this definition, we are guaranteed that \(L_H^{(2)} \succeq L_H^{(1)}\). Note, however, that the following results still apply if Hiring Scheme \(1\) is a \textsc{Two-Ticket} hiring scheme with a non-null Hirer LLM.

        Our results apply when the same threshold can be used to achieve the No False Positives Objective across both schemes. We show that when the Hirer chooses LLMs that are stochastically dominated by the privileged group LLM, it is sufficient (though not necessary) to guarantee that the optimal threshold does not change.
        
        
        \begin{restatable}{lemma}{lemmaOne}
            \label{lem: when threshold stays the same}
            If \(L_P \succeq L_H^{(1)}, L_H^{(2)}\), then \(\tau^{*(1)} = \tau^{*(2)}\).
        \end{restatable}
        
        Before introducing our main results on outcome disparity, we reformulate the probability of acceptance under the \textsc{Two-Ticket} hiring scheme. 
        \begin{restatable}{lemma}{lemmaTwo}
            \label{lem: expression for two-ticket acceptance probability}
            
            For Hirer LLM \(L_H\) and threshold \(\tau\), the probability that a  candidate \((\bm{x}, g, y)\) is accepted is
            \begin{gather*}
                \P_{L_g, L_H}(f_\tau(\bm{x}''_g) = 0) =
                1 - 
                \one[s(\bm{x}) < \tau]\cdot
                \P_{L_g}\paren{
                    s(L_g(\bm{x})) < \tau
                }\cdot
                \P_{L_H}\paren{
                    s(L_H(\bm{x})) < \tau
                }
                .
            \end{gather*}
        \end{restatable}
        % Proof Sketch
        \begin{proof}[(\textit{Proof Sketch})]
            This follows from \Cref{def: two-ticket hiring with Candidate LLM manipulation}, using that \(L_H(\bm{x}'_g)\) and \(\bm{x}'_g\) are conditionally independent given \(\bm{x}\).
        \end{proof}

       Using \Cref{lem: expression for two-ticket acceptance probability}, we derive our main result showing the improvement in resume outcome disparity by shifting from a \textsc{Traditional} to a \textsc{Two-Ticket} scheme.
        \begin{restatable}{theorem}{theoremTwo}
            \label{thm: two-ticket improves outcome disparity}
            Let \(\tau^{*(1)} = \tau^{*(2)}\), \(L_P \succeq L_U\), and \(L_H^{(2)} \succeq L_H^{(1)}\). Then for all \(\bm{x} \in \mathcal{X}\), \(\Delta^{(2)}(\bm{x}) \leq \Delta^{(1)}(\bm{x})\).
        \end{restatable}

        \begin{remark}
            \Cref{lem: when threshold stays the same} provides a simple and sufficient but not necessary condition that \(\tau^{*(1)} = \tau^{*(2)}\) under the No False Positives Objective. In fact, \Cref{thm: two-ticket improves outcome disparity} applies under \emph{any} Hirer objective so long as the optimal deployed threshold is the same for Hiring Scheme 1 and 2.
        \end{remark}

        Under the No False Positives Objective, the decrease in resume outcome disparity immediately implies a decrease in \emph{group} outcome disparity and an increase in accuracy (or equivalently, true positive rate under the No False Positives Objective) for both groups. 
        
        \begin{restatable}{corollary}{corollaryTwo}
            \label{cor: two-ticket improves group fairness and accuracy}
             Let \(\TPR_g^{(k)}\) denote the true positive rate over group \(g\) under Hiring Scheme \(k\). Let \(\tau^{*(1)} = \tau^{*(2)}\), \(L_P \succeq L_U\), and \(L_H^{(2)} \succeq L_H^{(1)}\), then: 
            \begin{enumerate}
                \item 
                \(\abs{\Delta_{\TPR}^{(2)}} \leq \abs{\Delta_{\TPR}^{(1)}}\).
                % \(\abs{\TPR_P^{(2)} - \TPR_U^{(2)}} \leq \abs{\TPR_P^{(1)} - \TPR_U^{(1)}}\).

                \item \(\TPR_g^{(2)} \geq \TPR_g^{(1)}\) for \(g \in \{P, U\}\).
                
                \item \(\TPR^{(2)} \geq \TPR^{(1)}\).
            \end{enumerate}
        \end{restatable}
        Since the threshold $\tau^*$ already prevents false positives (\Cref{def: no false positives objective}), (3) also implies that accuracy does not decrease.

\subsection{The $n$-Ticket Scheme and Group Dependence Bias Mitigation}
While the two-ticket scheme helps mitigate disparities, it may not be sufficient since the privileged group has the advantage of a ``better'' first ticket. Since we consider stochastic manipulations, the first ticket still increases acceptance probability. We therefore propose generalizing the idea to an $n$-\textit{Ticket Hiring Scheme}. Let $L_H^{n}$ be the application of the two-ticket scheme $n\in \mathbb N$ times using LLM $L_H$ (the $n$-ticket scheme).

That is, for any $\bm x\in \mathbb \mathcal{X}$, Clause~\ref{clause:max} in \Cref{def: two-ticket hiring with Candidate LLM manipulation} is repeated $n$ times, each time after the first with $\bm{x}''$ as the submitted resume. We will show that by applying the $n$-ticket scheme, the outcome becomes independent of group membership.

We start by defining a contraction operator and stating Banach's Fixed Point Theorem, which will be useful in the proof of the main theorem in this section.
\begin{definition}
Let $(Z,d)$ be a metric space. A function $T:Z\rightarrow Z$ is a contraction operator if there exists $k\in(0,1)$ such that
\[
d(T(z), T(z')) \leq k \, d(z, z') \quad \text{for all } z,z' \in Z.
\]
\end{definition}

\begin{theorem}[Banach's Fixed Point~\citep{Banach1922}]  Let $T:Z\rightarrow Z$ be a contraction 
operator. Then,
\begin{itemize}
\item The equation $T(z) = z$ has a unique solution $z^* \in Z$.
\item For any $z_0 \in Z$, $\lim\limits_{n \to \infty} T^n(z_0) = z^*$. Furthermore, $|T^n(z_0) - z^*| \leq \mathcal{O}(k^n)$, where $k$ is the contraction coefficient. 
\end{itemize}
\end{theorem}


Before we state the main theorem, we note that the way the $n$-ticket scheme is defined is such that once an applicant has at least one (possibly LLM-manipulated) resume that receives a score above the threshold $\tau$, it is guaranteed that they will be accepted (outcome of $1$) even if we increase the number of tickets: this arises from the fact that the Hirer takes the \textit{maximum} of the applicant's $n$ ``tickets''. In the main theorem, we show that for an infinite amount of tickets, the outcome becomes independent of the group membership. 
\begin{restatable}{theorem}{thmNticket}
    \label{thm: n-ticket}
    Let $\tau$ be the threshold used by the Hirer in each step of the $n$-ticket scheme. If $L_H \succeq L_P \succeq L_U$, applying the $n$-ticket scheme and taking the limit as $n \to \infty$, then any applicant $\bm{x} \in \mathcal{D}$ is guaranteed to receive a group-independent outcome, $o = o(\bm{x},L_H) \in \{0,1\}$.  
Furthermore, there exists $k_{\bm x} \in [0,1)$, that depends on $L_H$ and $\bm{x}$, such that  
$$|\P(f_\tau(L_H^{n}(L_g(\bm{x}))) = 1)- o| \leq \mathcal{O}(k_{\bm x}^n).$$
\end{restatable}
 

To prove the theorem, we show that providing an additional ticket for an applicant $\bm x$ is a contraction operator on $[0,1]$, independent of group membership, and show the existence of a Banach fixed point (See Appendix~\ref{sec: appendix proof} for full proof).


The theorem implies that by using the $n$-ticket scheme with an LLM as least as strong as the privileged group, the Hirer can significantly reduce any group-dependency bias in the hiring scheme, and the probability of not receiving the right outcome for the applicant drops exponentially in the number of tickets.

As a corollary, the probability of a disparity in outcomes of candidates with the same feature vector but different groups and the TPR disparity drop exponentially with $n$.

\begin{restatable}{corollary}{corNticket}
            \label{cor: n-ticket}
    % Let $\tau$ be the threshold used by the Hirer in each step of the $n$-ticket scheme.  doesn't seem to be used
    If $L_H \succeq L_P \succeq L_U$, then for every unmodified resume $\bm x\in \mathcal{X}$, there exists  $k_{\bm x}\in[0,1)$ that depends on $L_H$ and $\bm x$ such that for any $n\geq 2$, 
    $\P(f_\tau(L_H^{n}(L_U(\bm{x}))) \ne f_\tau(L_H^{n}(L_P(\bm{x})))\leq O(k_{\bm x}^n)$. Hence, 
    \begin{enumerate}
        \item $|\Delta_{TPR}^{(n)}|\leq \mathcal{O}(k^n)$,    
    where $k=\max_{\bm x} k_{\bm x}$.
    \item  \(\TPR_g^{(n)} \geq \TPR_g^{(n-1)}\) for \(g \in \{P, U\}\) and every $n> 1$.
    \item \(\TPR^{(n)} \geq \TPR^{(n-1)}\) for every $n> 1$. 
    \end{enumerate}
Since the threshold $\tau^*$ already prevents false positives (\Cref{def: no false positives objective}), (3) also implies that accuracy does not decrease.
\end{restatable}








\begin{table*}[t]
\label{tab:main-results}
\small
    \centering
    %\renewcommand{\arraystretch}{0.9}  % Reduce row height
    \begin{tabular}{cccccc}
    \toprule
        && \multicolumn{2}{c}{PM Role} & \multicolumn{2}{c}{UX Designer Role} \\

        \textbf{Condition} & \textbf{Method} & \textbf{TPR} & \textbf{TPR Disparity} &   \textbf{TPR} & \textbf{TPR Disparity} \\
        \midrule
        $U$:    No LLMs, $P$:\textsc{GPT-4o} & Traditional    &$0.11 \pm 0.004$  & $0.10 \pm 0.005$ & $0.22 \pm 0.008$  & $ \pm0.27 \pm 0.006$\\
        & Two-Ticket     & $0.14 \pm 0.005$  & $ 0.05 \pm 0.005$   & $0.38 \pm 0.008$  & $ 0.01 \pm 0.007$\\
        \midrule
        $U$:    \textsc{GPT-3.5}, $P$:\textsc{GPT-4o} & Traditional    & $0.09 \pm 0.004$  & $ 0.09 \pm 0.005$ & $0.26 \pm 0.010$  & $ \pm0.15 \pm 0.008$ \\
        & Two-Ticket     & $0.11 \pm 0.004$  & $ 0.08 \pm 0.005$   & $0.30 \pm 0.010$  & $ \pm0.08 \pm 0.007$\\
        \midrule
        $U$:    \textsc{GPT-4o-mini}, $P$:\textsc{GPT-4o} 
        & Traditional    & $0.12 \pm 0.004$  & $ 0.04 \pm 0.005$ & $0.33 \pm 0.010$  & $ 0.00 \pm 0.007$  \\
        & Two-Ticket     & $0.13 \pm 0.007$  & $ 0.03 \pm 0.010$  & $0.36 \pm 0.010$  & $-0.01 \pm 0.008$ \\
        \bottomrule
    \end{tabular}
    \caption{Resume screening results where Groups $P$ and $U$ have access to various models of \textsc{GPT} family models for a PM and Design Job description respectively. Results are presented with 95\% CIs computed over 500 train-test splits.}
    \label{tab: combined_results_all}
\end{table*}

\section{Empirical Validation: Resume Selection in the Technology Sector}
\label{sec: empirical experiments}
   In this section, we empirically validate our theoretical results by closely simulating a hiring scenario in which an employer has two positions to fill. We examined 520 resumes from the Djiini dataset \citep{drushchak-romanyshyn-2024-introducing}, which includes resumes from the technology sector. Our sample consisted of equal parts UI/UX designers and project managers (PM). To replicate a real-world applicant tracking system, we used an open-source resume scorer, Resume Matcher,\footnote{This open-source resume scorer is designed to mimic applicant tracking systems that many hiring companies use for ranking applicant relevance~\citep{jobscan2025}. Job applicants can use these ATS tools improve their resume relevance. To the best of our knowledge, ResumeMatcher is the only open-source ATS tool available (\url{https://resumematcher.fyi/}).} to assign a relevance score (e.g., 0--100) for all resumes against a PM job description and a UX job description. Finally, we note that Resume-Matcher assigns its scores based on word-similarity metrics between the inputted resumes and target job descriptions.

    We examine the GPT family of OpenAI models due to its widespread use.~\footnote{ChatGPT is reported to have 2.4 billion monthly visits in March 2024, 10 times the next most popular platform~\citep{zhu2024ranked}.} We randomly assigned half of the resumes to group \(P\) (privileged) and the remaining half to group \(U\) (unprivileged). Only the candidates assigned to group \(P\) could manipulate their resumes with the same model as the employer (\textsc{GPT-4o}). The resumes in group \(U\) could only access \textsc{GPT-3.5-turbo}, \textsc{GPT-4o-mini}, or no LLM at all) to edit the original resumes with a prompt asking for the resumes to be improved.~\footnote{Appendix \ref{app:experiment-details} includes prompts and model versions \& costs.} Our theoretical results assume candidates to be best-responding, hence in our experiments, the candidates would submit the higher scoring resume between their choice of their LLM manipulated and original resume.  
    
    The Hirer learns a threshold that maximizes the true positive rate while minimizing the false positive rate (this objective approximates the objective of no false positives in~\Cref{def: no false positives objective}). In the \textsc{Traditional} hiring scheme, the Hirer directly uses the input resumes from the two groups. For the \textsc{Two-Ticket} scheme, the Hirer also manipulates each submitted resume with the employer model (\textsc{ChatGPT-4o}). The Hirer then acts on the higher-scoring resume between the submitted and Hirer-manipulated versions of the resume. In both schemes, the Hirer has no knowledge about which individuals belong to which group; thus, membership-based fairness interventions cannot be applied to our setting. 

    %Under the \textsc{Traditional} hiring scheme, we then computed the optimal threshold classifier that minimized the False Positive Rate while ensuring a non-zero True Positive Rate (this objective approximates the No False Positives Objective in~\Cref{def: no false positives objective}). The threshold used was computed on the training split and then used to compute the Accuracy, True Positive Rate, and TPR Disparity (\Cref{def: TPR disparity}) metrics on the test split. 

    Table~\ref{tab: combined_results_all} shows the empirical verification of our theoretical results: the performance of the \textsc{Traditional} hiring scheme and the \textsc{Two-Ticket} hiring scheme validated in both job descriptions we consider for 520 resumes. True positive rates (TPR) were improved and TPR disparities were reduced by the \textsc{Two-Ticket} scheme. The improvement was evident when group $U$ used a weaker modification (\textsc{GPT-3.5-turbo} or no LLM). When group $U$ used a similar level LLM (\textsc{GPT-4o-mini}), there was no improvement in the magnitude of disparity~\footnote{At the time of our submission, \textsc{GPT-4o-mini} is offered for free by OpenAI. However, before \textsc{GPT-4o-mini} was released (after \textsc{GPT-4o} was released), \textsc{GPT-3.5-turbo} was the free model offered. In the future, LLM providers may offer new versions of models where the paid version is much better than the free version.}. Our results demonstrate that our proposed method helps better discern qualified candidates from candidates using stronger LLM manipulations~\footnote{All Code and Data Available at \url{https://github.com/heyyjudes/llm-hiring-ecosystem}}.
    
    %All tables confirm that applying our \textsc{Two-Ticket} scheme both decreased the Group Outcome Disparity and improved the Hirer accuracy and TPR (as first presented in \Cref{cor: two-ticket improves group fairness and accuracy}). The improvements for each metric for the two schemes were calculated by subtracting the \textsc{Traditional} scheme value from the \textsc{Two-Ticket} value \textit{for each split}. For example, the negative values for the improvement in TPR disparity show that the average disparity decreased from the \textsc{Traditional} to \textsc{Two-Ticket} system in the runs. We derived confidence intervals by repeating the evaluation over 500 random $70\%$-$30\%$ train-test splits. 

\section{Discussion}
%c 
Our work is a first step towards understanding and designing better selection algorithms under stochastic LLM manipulations. Similarly to prior work~\citep{Hu19}, we show that members of the privileged group are more easily admitted or hired. Here, privilege includes both providing a more advanced LLM and knowledge of the performance of different LLMs. In our model, the Hirer does not know \textit{a priori} whether a candidate has manipulated their resume. Our theoretical results imply that using the \textsc{Two-Ticket} scheme, both the TPR and the TPR disparity are improved even without this knowledge. Specifically, our theoretical results suggest that this improvement is greatest when the Hirer deploys an LLM that is as strong as possible, while being weaker than the candidate's strongest LLM. Therefore, careful thought and evaluation must be used when applying our \textsc{Two-Ticket} scheme in practice. 

Although our findings focus on manipulations that preserve the distinguishability between negative and positive labels within our candidate screening task, future work should investigate the full spectrum of LLM choices. This is particularly impactful when companies may introduce increasingly premium LLM services. Moreover, our \textsc{Two-Ticket} scheme can be generalized to many other scenarios beyond hiring in which candidates can manipulate their materials. 

As our work focused on simple prompts to capture a low-effort (zero-cost) manipulation, future work should address the variable behavior of LLMs that can arise from using different or more prescriptive prompts. Although we provide a theoretical guarantee for improvements in our \textsc{Two-Ticket} scheme, relaxing the condition that the optimal threshold does not change could help establish stronger guarantees. Lastly, our experiments use the only open source ATS system available; future audits of actual hiring systems should test black-box and human-in-the-loop systems. 

\section{Impact Statement}
This paper is a theoretical work that examines the effect of an increasing number of job applications being produced by generative AI. Notably, we do not advocate for hiring systems using AI but study the problem of candidates using AI to modify their resumes. We developed this project to address the potential downstream impacts of generative AI. We do not foresee negative consequences to our analysis at this time. Our work by no means is comprehensive in studying the allocation of opportunities in the era of generative AI. We hope that future works continue to examine this area of sociotechnical AI safety. 