\section{RELATED WORKS}
\label{sec2}

Early accident anticipation aims to estimate the probability of future accidents based on perceptual information from the current scene. Based on the differences in traffic scene modeling approaches, we categorize early accident prediction research into attention-based methods and graph convolution network (GCN) -based methods.
\subsection{Attention-based Methods}

Attention-based accident scene modeling methods **Chan et al., "Dynamic-Spatial-Attention for Traffic Accident Prediction"**__**Zeng et al., "Soft Attention Mechanism for Relative Spatial Relationships"** leverage the capability of attention mechanisms to dynamically focus on key features that may lead to traffic accidents, which have gained increasing attention in recent years. For example, Chan et al. **Chan et al., "Dynamic-Spatial-Attention for Traffic Accident Prediction"** first introduced a Dynamic-Spatial-Attention (DSA) mechanism, which effectively addressed the limitation of earlier studies that overlooked dynamically changing features in video data and improved the accident prediction accuracy significantly. Zeng et al. **Zeng et al., "Soft Attention Mechanism for Relative Spatial Relationships"** proposed a novel soft attention mechanism using a Dynamic Parameter Prediction layer to model the relative spatial relationships and appearance couplings between agents and risk areas, which addressed the often-neglected impact of complex interactions among traffic participants on accident risk assessment. Shah et al. **Shah et al., "Context-Aware Attention for Small-Sized Objects"** integrated contextual information into the Faster R-CNN model, focusing the model's attention on small-sized objects. Corcoran et al. **Corcoran et al., "Temporal Feature Extraction for Early Traffic Accident Anticipation"** emphasized the importance of temporal feature extraction for early traffic accident anticipation by proposing a dual-stream dynamic attention recurrent convolutional neural network framework. Wang et al. **Wang et al., "Multi-task Attention Network for Lane Detection"** proposed a Multi-task Attention Network (MATNet) for lane detection, incorporating spatial and channel attention mechanisms to effectively enhance lane feature recognition. Li et al. **Li et al., "Attention-Based Spatial Segmentation Network for Traffic Scenes"** focused on understanding traffic scenes, particularly on accurately segmenting different traffic participants in complex environments. They introduced an Attention-Based Spatial Segmentation Network (ABSSNet), which improved the accuracy and efficiency of segmenting important detection objects like vehicles and pedestrians in complex traffic scenes. Bao et al. **Bao et al., "Attention Mechanism with Deep Reinforcement Learning for Accident Prediction"** combined attention mechanisms with deep reinforcement learning (DRL) and proposed two attention mechanisms (Bottom-Up \& Top-Down) that simulate the human visual system, enabling the model to dynamically adjust its focus on the environment and identify key factors that may lead to accidents. Karim **Karim et al., "Grad-CAM for Traffic Accident Prediction"** introduced a post-hoc attention mechanism Grad-CAM, to generate saliency maps, which visualize the regions of interest that the model focuses on when performing traffic accident prediction tasks. For early prediction of collisions between autonomous and non-autonomous vehicles, Fatima et al. **Fatima et al., "Feature Aggregation for Abnormal Event Detection"** proposed a Feature Aggregation (FA) module that identifies abnormal events in video sequences by calculating the weighted sum of features of all objects in a given frame and refining each object's features. The Vision Transformer **Dosovitskiy et al., "Vision Transformers"** (ViT) is a powerful image model introduced in recent years with self-attention mechanisms. Inspired by this, Kang et al. **Kang et al., "Vision Transformer with Temporal Attention for Traffic Accident Prediction"** proposed the Vision Transformer with Temporal Attention (ViT-TA). This transformer accurately classified critical situations around traffic accidents and highlighted key objects in accident conflict scenes based on attention maps, identifying potential causes of accidents. Besides integrating attention mechanisms into spatial scene modeling, Karim et al. **Karim et al., "Dynamic Spatio-temporal Attention Network for Traffic Scenes"** constructed a Dynamic Spatio-temporal Attention Network (DSTA), which incorporated a Dynamic-Temporal-Attention (DTA) module to track and analyze the development of key temporal features throughout the video sequence, thereby enabling early warnings of potential accidents. In their latest research, Karim et al. **Karim et al., "Attention-Guided Multi-stream Feature Fusion Network"** developed an Attention-Guided Multi-stream Feature Fusion Network (AM-Net). In this network, the attention mechanism selectively weights features, determining which features were more critical for risk prediction and adjusting the feature fusion weights accordingly, which provided greater flexibility in handling complex and dynamic traffic environments.

\subsection{GCN-based Methods}

Spatial relationships between traffic agents are also important cues for early accident anticipation, as they often indicate potential interactions that may lead to collisions. As such, numerous studies **Guo et al., "Attention-Based Spatio-Temporal Graph Convolutional Network"** have leveraged Graph Convolutional Networks (GCN) ____ to intuitively model spatial relationships between traffic agents. For example, Guo et al. **Guo et al., "Attention-Based Spatio-Temporal Graph Convolutional Network"** proposed the Attention-based Spatio-Temporal Graph Convolutional Network (ASTGCN), which utilized GCN's ability to process data directly on the original graph-structured traffic network and captures the spatial features of different nodes within the traffic network effectively. Similarly, Diao et al. **Diao et al., "Dynamic Spatio-Temporal Graph Convolutional Neural Network"** introduced the Dynamic Spatio-Temporal Graph Convolutional Neural Network (DST-GCNN) to specifically capture the spatiotemporal dynamics of traffic data. Building on this, Liu et al. **Liu et al., "Spatio-Temporal Relationship Graph Convolutional Network"** proposed a Spatio-Temporal Relationship Graph Convolutional Network (STR-GCN), which uses GCN to capture the spatial positional relationships of pedestrians within traffic scenes and their interactions with other traffic participants. Zhao et al. **Zhao et al., "Traffic Graph Convolutional Network for Traffic Accident Prediction"** combined the advantages of GCN's ability to capture spatial structural features in traffic networks with Recurrent Neural Networks (RNN) ____ for analyzing temporal sequence data, creating a framework (T-GCN) capable of handling both spatial and temporal characteristics of traffic data. Considering the uncertainty in spatial relationships among traffic participants, Bao **Bao et al., "Uncertainty Analysis for Graph Convolutional Network"** introduced uncertainty analysis into his research. This approach, which quantifies uncertainty within the GCN framework, adds a new dimension to accident prediction. Malawade et al. **Malawade et al., "Spatiotemporal Scene Graph Embedding Model"** enhanced the understanding of dynamic changes in traffic scenes by utilizing Graph Neural Networks and Long Short-Term Memory (LSTM) ____ to construct a spatiotemporal scene graph embedding model (SG2VEC). Wang et al. **Wang et al., "Dynamic Traffic Elements for Spatiotemporal Graph Construction"** innovatively incorporated dynamic traffic elements (such as historical vehicle trajectories) into the construction of spatiotemporal graphs. By analyzing the complex interactions among these elements through GCN, they identified key features affecting accident collisions. Most recently, Thakur **Thakur et al., "Dual-Layer Nested Graph Architecture for Traffic Accident Prediction"** proposed a dual-layer nested graph architecture (GraphGraph), where the inner graph captures interactions among objects within video frames, and the outer graph analyzes spatiotemporal relationships between frames. This nested graph structure allows GraphGraph to effectively integrate global spatiotemporal information while capturing and understanding the complex dynamics among traffic elements over time.

\subsection{Limitations of existing methods}

Despite significant progress in accident anticipation, existing attention-based and graph convolution-based methods exhibit limitations in accurately capturing spatial relationships. They fail to incorporate depth features, hindering accurate 3D scene reconstruction from 2.5D video perspectives. This limitation leads to challenges in distinguishing collisions from mere overlap of traffic participants, resulting in false positive alerts. Furthermore, these methods overlook the impact of occluded key participants that are crucial for risk identification in complex scenarios, and tend to miss key features by focusing solely on either global information or local details.