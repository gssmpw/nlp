\section{RELATED WORKS}
\label{sec2}

Early accident anticipation aims to estimate the probability of future accidents based on perceptual information from the current scene. Based on the differences in traffic scene modeling approaches, we categorize early accident prediction research into attention-based methods and graph convolution network (GCN) -based methods.
\subsection{Attention-based Methods}

Attention-based accident scene modeling methods \cite{karim2022dynamic,fatima2021global,chan2017anticipating,bao2020uncertainty,zeng2017agent,shah2018cadp,corcoran2019traffic,wang2020multitask,li2021abssnet,karim2022toward,dosovitskiy2020image,kang2022vision,karim2023attention} leverage the capability of attention mechanisms to dynamically focus on key features that may lead to traffic accidents, which have gained increasing attention in recent years. For example, Chan et al. \cite{chan2017anticipating} first introduced a Dynamic-Spatial-Attention (DSA) mechanism, which effectively addressed the limitation of earlier studies that overlooked dynamically changing features in video data and improved the accident prediction accuracy significantly. Zeng et al. \cite{zeng2017agent} proposed a novel soft attention mechanism using a Dynamic Parameter Prediction layer to model the relative spatial relationships and appearance couplings between agents and risk areas, which addressed the often-neglected impact of complex interactions among traffic participants on accident risk assessment. Shah et al. \cite{shah2018cadp} integrated contextual information into the Faster R-CNN model, focusing the model's attention on small-sized objects. Corcoran et al. \cite{corcoran2019traffic} emphasized the importance of temporal feature extraction for early traffic accident anticipation by proposing a dual-stream dynamic attention recurrent convolutional neural network framework. Wang et al. \cite{wang2020multitask} proposed a Multi-task Attention Network (MATNet) for lane detection, incorporating spatial and channel attention mechanisms to effectively enhance lane feature recognition. Li et al. \cite{li2021abssnet} focused on understanding traffic scenes, particularly on accurately segmenting different traffic participants in complex environments. They introduced an Attention-Based Spatial Segmentation Network (ABSSNet), which improved the accuracy and efficiency of segmenting important detection objects like vehicles and pedestrians in complex traffic scenes. Bao et al. \cite{bao2020uncertainty} combined attention mechanisms with deep reinforcement learning (DRL) and proposed two attention mechanisms (Bottom-Up \& Top-Down) that simulate the human visual system, enabling the model to dynamically adjust its focus on the environment and identify key factors that may lead to accidents. Karim \cite{karim2022toward} introduced a post-hoc attention mechanism Grad-CAM, to generate saliency maps, which visualize the regions of interest that the model focuses on when performing traffic accident prediction tasks. For early prediction of collisions between autonomous and non-autonomous vehicles, Fatima et al. \cite{fatima2021global} proposed a Feature Aggregation (FA) module that identifies abnormal events in video sequences by calculating the weighted sum of features of all objects in a given frame and refining each object's features. The Vision Transformer \cite{dosovitskiy2020image} (ViT) is a powerful image model introduced in recent years with self-attention mechanisms. Inspired by this, Kang et al. \cite{kang2022vision} proposed the Vision Transformer with Temporal Attention (ViT-TA). This transformer accurately classified critical situations around traffic accidents and highlighted key objects in accident conflict scenes based on attention maps, identifying potential causes of accidents. Besides integrating attention mechanisms into spatial scene modeling, Karim et al. \cite{karim2022dynamic} constructed a Dynamic Spatio-temporal Attention Network (DSTA), which incorporated a Dynamic-Temporal-Attention (DTA) module to track and analyze the development of key temporal features throughout the video sequence, thereby enabling early warnings of potential accidents. In their latest research, Karim et al. \cite{karim2023attention} developed an Attention-Guided Multi-stream Feature Fusion Network (AM-Net). In this network, the attention mechanism selectively weights features, determining which features were more critical for risk prediction and adjusting the feature fusion weights accordingly, which provided greater flexibility in handling complex and dynamic traffic environments.

\subsection{GCN-based Methods}

Spatial relationships between traffic agents are also important cues for early accident anticipation, as they often indicate potential interactions that may lead to collisions. As such, numerous studies \cite{malawade2022spatiotemporal,bao2020uncertainty,guo2019attention,diao2019dynamic,liu2020spatiotemporal,zhao2019t,wang2023gsc,sun2024maformer,thakur2024graph} have leveraged Graph Convolutional Networks (GCN) \cite{kipf2016semi} to intuitively model spatial relationships between traffic agents. For example, Guo et al. \cite{guo2019attention} proposed the Attention-based Spatio-Temporal Graph Convolutional Network (ASTGCN), which utilized GCN's ability to process data directly on the original graph-structured traffic network and captures the spatial features of different nodes within the traffic network effectively. Similarly, Diao et al. \cite{diao2019dynamic} introduced the Dynamic Spatio-Temporal Graph Convolutional Neural Network (DST-GCNN) to specifically capture the spatiotemporal dynamics of traffic data. Building on this, Liu et al. \cite{liu2020spatiotemporal} proposed a Spatio-Temporal Relationship Graph Convolutional Network (STR-GCN), which uses GCN to capture the spatial positional relationships of pedestrians within traffic scenes and their interactions with other traffic participants. Zhao et al. \cite{zhao2019t} combined the advantages of GCN's ability to capture spatial structural features in traffic networks with Recurrent Neural Networks (RNN) \cite{godard2017unsupervised} for analyzing temporal sequence data, creating a framework (T-GCN) capable of handling both spatial and temporal characteristics of traffic data. Considering the uncertainty in spatial relationships among traffic participants, Bao \cite{bao2020uncertainty} introduced uncertainty analysis into his research. This approach, which quantifies uncertainty within the GCN framework, adds a new dimension to accident prediction. Malawade et al. \cite{malawade2022spatiotemporal} enhanced the understanding of dynamic changes in traffic scenes by utilizing Graph Neural Networks and Long Short-Term Memory (LSTM) \cite{shi2015convolutional} to construct a spatiotemporal scene graph embedding model (SG2VEC). Wang et al. \cite{wang2023gsc} innovatively incorporated dynamic traffic elements (such as historical vehicle trajectories) into the construction of spatiotemporal graphs. By analyzing the complex interactions among these elements through GCN, they identified key features affecting accident collisions. Most recently, Thakur \cite{thakur2024graph} proposed a dual-layer nested graph architecture (GraphGraph), where the inner graph captures interactions among objects within video frames, and the outer graph analyzes spatiotemporal relationships between frames. This nested graph structure allows GraphGraph to effectively integrate global spatiotemporal information while capturing and understanding the complex dynamics among traffic elements over time.

\subsection{Limitations of existing methods}

Despite significant progress in accident anticipation, existing attention-based and graph convolution-based methods exhibit limitations in accurately capturing spatial relationships. They fail to incorporate depth features, hindering accurate 3D scene reconstruction from 2.5D video perspectives. This limitation leads to challenges in distinguishing collisions from mere overlap of traffic participants, resulting in false positive alerts. Furthermore, these methods overlook the impact of occluded key participants that are crucial for risk identification in complex scenarios, and tend to miss key features by focusing solely on either global information or local details.