

\documentclass{article}
\usepackage{makecell}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{multirow}


\usepackage{hyperref}
\usepackage[dvipsnames,svgnames, table,xcdraw]{xcolor}
\definecolor{mediumpurple}{rgb}{0.58, 0.44, 0.86}
\newcommand{\gamename}[1]{\textbf{\color{mediumpurple}{#1}}}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{enumerate}

\usepackage[normalem]{ulem}
\useunder{\uline}{\ul}{}


\usepackage{blindtext}

\usepackage[T1]{fontenc}
\usepackage{subfiles} 
\usepackage{amsmath} 
\usepackage{amsthm}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{subfigure}

\usepackage{pdfpages}
\usepackage{amsfonts}
\usepackage{paralist}
\usepackage{booktabs} % To thicken table lines

\input{math_commands.tex}



\newcommand{\theHalgorithm}{\arabic{algorithm}}

\usepackage[accepted]{icml2025}


\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{tcolorbox}
\usepackage{mathtools}
\tcbuselibrary{listingsutf8} 
\usepackage{xcolor}
\usepackage{amsthm}
\definecolor{codeborder}{RGB}{50, 100, 200}  
\definecolor{codebackground}{RGB}{245, 245, 245}  
\definecolor{titlebg}{RGB}{220, 230, 250} 
\definecolor{titleborder}{RGB}{50, 100, 200}  


\newtcolorbox[auto counter, number within=section]{codebox}[2][]{%
    colback=codebackground, 
    colframe=codeborder,  
    coltitle=black, 
    colbacktitle=titlebg,  
    coltitle=Black,  
    fonttitle=\bfseries,  
    boxrule=1.2pt, 
    arc=5pt,  
    listing only, 
    listing options={
        language=Python,
        basicstyle=\ttfamily\footnotesize,
        keywordstyle=\color{blue},
        stringstyle=\color{red},
        commentstyle=\color{gray},
        showstringspaces=false,
        columns=flexible,
        breaklines=true,
        inputencoding=utf8,  
        extendedchars=true
    },
    title=Python Code: #2,  
    #1
}



\newcommand{\ie}{i.e.,\ }
\newcommand{\eg}{e.g.,\ }


\usepackage{smile}
\usepackage{cases}
\newcommand{\lose}{\textnormal{lose}}
\newcommand{\win}{\textnormal{win}}
\newcommand{\gt}{\textnormal{gt}}

\newcommand{\model}{\textcolor{RoyalBlue}{\textsc{SiriuS}}}
%

\newcommand{\norm}[1]{\Big\lVert#1 \Big\rVert}
\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}




\usepackage[capitalize,noabbrev]{cleveref}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}


\usepackage[textsize=tiny]{todonotes}


\icmltitlerunning{\textcolor{RoyalBlue}{SiriuS}: Self-improving Multi-agent Systems via Bootstrapped Reasoning}

\begin{document}

\twocolumn[
\icmltitle{\textcolor{RoyalBlue}{SiriuS}: \textcolor{RoyalBlue}{S}elf-\textcolor{RoyalBlue}{i}mp\textcolor{RoyalBlue}{r}ov\textcolor{RoyalBlue}{i}ng M\textcolor{RoyalBlue}{u}lti-agent \textcolor{RoyalBlue}{S}ystems via Bootstrapped Reasoning}

\vspace{-10pt}
\begin{icmlauthorlist}
\icmlauthor{Wanjia Zhao}{yyy}
\icmlauthor{Mert Yuksekgonul}{yyy}
\icmlauthor{Shirley Wu}{yyy}
\icmlauthor{James Zou}{yyy}
\end{icmlauthorlist}

\icmlaffiliation{yyy}{Stanford University}
\icmlcorrespondingauthor{Wanjia Zhao}{wanjiazh@cs.stanford.edu}
\icmlcorrespondingauthor{James Zou}{jamesz@cs.stanford.edu}

\vskip 0.3in
]

\printAffiliationsAndNotice{} % otherwise use the standard text.

\begin{abstract}
Multi-agent AI systems powered by large language models (LLMs) are increasingly applied to solve complex tasks. However, these systems often rely on fragile, manually designed prompts and heuristics, making optimization difficult.
A key challenge in optimizing multi-agent systems is acquiring suitable training data for specialized agents. 
We introduce \model{}, a self-improving, reasoning-driven optimization framework for multi-agent systems. Central to our approach is the construction of an experience library: a repository of high-quality reasoning trajectories. The library is built by retaining reasoning steps that lead to successful outcomes, providing a robust training set for optimizing multi-agent system. Additionally, we introduce a library augmentation procedure that refines unsuccessful trajectories, further enriching the library. 
\model{} boosts performance by 2.86\% to 21.88\% on reasoning and biomedical QA and enhances agent negotiation in competitive settings. Our results show that \model{} enhances multi-agent performance while generating reusable data for self-correction and self-play enhancement in the future. Code are available \href{https://github.com/zou-group/sirius}{here}.


\end{abstract}

\input{section/intro}
% \input{section/formulation}
\input{section/method}

\input{section/experiment}
\input{section/relatedwork}
\input{section/conclusions}
\newpage
\bibliography{icml2025}
\bibliographystyle{icml2025}

\newpage
\appendix
\onecolumn
\input{section/appendix}

% You can have as much text here as you want. The main body must be at most $8$ pages long.
% For the final version, one more page can be added.
% If you want, you can use an appendix like this one.  

% The $\mathtt{\backslash onecolumn}$ command above can be kept in place if you prefer a one-column appendix, or can be removed if you prefer a two-column appendix.  Apart from this possible change, the style (font size, spacing, margins, page numbering, etc.) should be kept the same as the main body.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
