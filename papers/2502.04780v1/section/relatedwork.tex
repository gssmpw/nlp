\section{Related Work}
\textbf{Enhancing Reasoning in Single-Agent Systems.}
Building on the reasoning capabilities of state-of-the-art foundation models \citep{schulman2022chatgpt,openai2023gpt,liu2024deepseek}, recent research explores approaches beyond scaling model parameters. Chain-of-Thought \citep{wei2022chain} enhances reasoning through step-by-step inference, while Tree of Thoughts \citep{yao2024tree}, Graph of Thought \citep{besta2024graph}, and Program of Thoughts \citep{chen2022program} structure reasoning as tree searches with backtracking. Reasoning with Planning (RAP) \citep{hao2023reasoning} incorporates explicit planning, and Reflexion \citep{shinn2024reflexion} enables self-evaluation and refinement. \cite{wu24avatar} introduce contrastive reasoning for instruction generation, while TextGrad \citep{yuksekgonul2024textgrad} applies gradient-based optimization to refine outputs. These methods enhance reasoning through structured decomposition, search, and planning.

\textbf{Self-improvement.}
 Self-improving models~\citep{huang2022large,yu2023teaching,yuan2024self,zhang2024small,welleck2022generating,peng2024regenesis} have garnered increasing attention for their potential to enhance reasoning capabilities through iterative feedback and refinement.
 Several studies~\citep{zelikman2022star,li2024large,pang2024iterative,lee2024llm2llm}employ bootstrapping strategies by leveraging self-generated rationales, while others~\citep{yuan2024self,chen2024improving,ramji2024self,guo2025deepseek} introduce a self-refinement mechanism through reinforcement learning.
 
\textbf{Multi-Agent Systems with LLMs.} \textbf{Multi-Agent Systems with LLMs.} Recent advancements in multi-agent systems ~\citep{smitshould,de2023emergent,guo2024large,li2024survey,han2024llm,wang2024rethinking,sun2024llm} highlight the potential of large language models in tackling complex tasks. Society of Minds~\citep{du2023improving} enables agents to exchange answers, fostering collaboration.  Mixture-of-Agents~\citep{wang2024mixture} employs a layered architecture where agents refine responses based on prior outputs. CoMM~\citep{chen2024comm} enhances problem-solving through structured communication and role division. Multi-Persona~\citep{liang2023encouraging} encourages diverse agent behaviors by assigning distinct personas.
ChatEval~\citep{chan2023chateval} explores different multi-agent debate strategies for interaction and response management.
DMAS~\citep{chen2024scalable} explores token-efficient multi-agent planning frameworks to improve coordination and task success.Building on advances in multi-agent systems, recent work has explored fine-tuning with independently specialized agents that interact to generate diverse reasoning chains~\citep{subramaniam2025multiagent}. Unlike these approaches, our method prioritizes collaborative optimization through a shared experience library, enabling agents to collectively learn from and refine successful reasoning trajectories.



