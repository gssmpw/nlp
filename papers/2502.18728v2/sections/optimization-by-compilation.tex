In this section, we give a formal account of the intuitions
reflected in Section~\ref{subsubsec:optimization-via-compilation}
and~\cref{subsubsec:staging}.
We will describe the
branch-and-bound semiring (Section~\ref{subsec:bb semiring}),
a class of lattice semirings (recall Definition~\ref{def:latticed semiring})
equipped with an additional total order that is \textit{compatible} with the existing lattice.
Afterwards, we introduce the BBIR
how it represents MEU and MMAP
(Section~\ref{subsec:msp jsp}),
and how it admits a polynomial time upper- and lower-bound
algorithm (Section~\ref{subsec:bounds}),
lending itself well to a branch-and-bound
approach (Section~\ref{subsec:meu with evidence}).

\subsection{The Branch-and-Bound Semiring}
\label{subsec:bb semiring}

In Section~\ref{subsubsec:optimization-via-compilation},
we introduced the definition of a lattice semiring
(Definition~\ref{def:latticed semiring}) and how it generalizes the
interchange law between max and sum
($\max_{x} \sum_y f(x,y) \leq \sum_y \max_x f(x,y)$) in the reals.
However, in a lattice semiring,
$\sqsubseteq$ is a partial order, so in general elements may not be able to be compared:
for example, in the expectation semiring, we cannot compare the values $(0.5, 1)$ and $(1,0)$
as $0.5 \leq 1$ but $1 \not\leq 0$.
However, if we were to compare the values $(0.5, 1)$ and $(1,0)$ as
values of
$\AMC{}$ corresponding to total (as opposed to partial) policies,
then the comparison is
obvious: we select $(0.5, 1)$ as it has the higher utility.
To reflect this intuition, we enrich lattice semirings with a total order,
which gives the definition of a branch-and-bound semiring:

\begin{definition}[Branch-and-Bound Semiring]\label{def:branch-and-bound semiring}
  A branch-and-bound semiring is a lattice semiring
  $(\mathcal R, \oplus, \otimes, \mathbf 0, \mathbf 1, \sqsubseteq)$
  equipped with an additional total order
  $\leq$ such that for all $a,b \in \mathcal R$,
  $a \sqsubseteq b$ implies $a \leq b$,
  which we henceforth call \emph{compatibility}.
\end{definition}

The real semiring $\R$ is a branch-and-bound semiring
in which the two orders are identical: the usual total order on the reals.
However, the intuition above is reflected most prominently in the expectation semiring:

\begin{proposition}\label{prop:S is bb semiring}
  The expectation semiring $\mathcal S$,
  as seen in Definition~\ref{def:expectation semiring},
  forms a branch-and-bound semiring with:
  \begin{enumerate*}
    \item $(p,u) \sqsubseteq (q,v)$ iff $p \leq q$ and $u \leq v$,
    with join $\bigsqcup$ being a coordinatewise max and
    meet $\bigsqcap$ being a coordinatewise min, and
    \item $(p,u) \leq (q,v)$ iff $u < v$ or $u=v$ and $p \leq q$.
  \end{enumerate*}
\end{proposition}

\begin{proof}
  Let $(p,u), (q,v) \in \mathcal S$ such that
  $(p,u) \sqsubseteq (q,v)$. Then $u \leq v$;. if $u <v$ we are done.
  If $u=v$ then $p \leq q$ and we are done.
\end{proof}

The distinction between $\sqsubseteq$ and $\leq$ is required when
comparing partial and total policies in~\cref{subsec:bounds}.
Compatibility will be required when we know, for $p \sqsubseteq q$,
that $p$ and $q$ are associated with total policies as opposed to partial.

% Continuing the intuition outlined
% for Definition~\ref{def:branch-and-bound semiring},
% recall that the AMC over $\mathcal S$ computes the
% expected utility, particularly that the expected
% utility of a policy.
% If we know two policies, then we can simply evaluate
% the expected utility of both and pick the greater; this
% is reflected in $\leq$
% in Proposition~\ref{prop:S is bb semiring}.
% On the other hand, $\sqsubseteq$ allows us to compare
% \textit{partial policies}--that is, a deterministic assignment
% to only \textit{some} components of the action space.
% How we reduce a partially evaluated expected utility calculation
% of a partial policy into a value in $\mathcal S$ is done through
% the join; we will see this in Section~\ref{subsec:bounds}.
% \sh{After reading
% this again, I do feel like either we should move a bunch of this to section 2,
% or try to move some of section 2 here; I'm not sure which is best, and
% we may need to wait until after the deadline to make these adjustments unless you
% see a quick way to do it. }

\subsection{The Branch-and-Bound IR}\label{subsec:msp jsp}
Now that we have defined the branch-and-bound semiring, we are ready
to reconstruct the branch-and-bound circuits in the
motivating examples in Section~\ref{sec:overview}.
% We had a motivating example (Figure~\ref{fig:bb-overview})
% that was then compiled to a binary decision diagram
% (Figure~\ref{fig:motiv-a-bdd}).
What additional information should the BDD in Figure~\ref{fig:motiv-a-bdd} have to fully represent
a decision scenario?
Of course we should specify which variables
to optimize over and which to not, and weights for all variables
present. But additionally we need to incorporate potential \textit{evidence}
showing the events to condition on as we evaluate the program.
We represent exactly this set of information in the BBIR.

\begin{definition}[Branch-and-bound IR]\label{def:bbir}
  A branch-and-bound intermediate representation (BBIR)
  over a branch-and-bound semiring $\mathcal B$
  is a
  tuple $\BBIR$ in which:
  \begin{itemize}
    \item $\{\varphi_i\}$ are propositional formulae
    in the factorized representation of a
    multi-rooted BDD~\citep{darwiche2002knowledge,clarke2018handbook},
    \item $X \subseteq \bigcup_i vars(\varphi_i)$ a selection of variables
    on which to branch over,
    \item $w : \bigcup_i lits(\varphi_i) \to \mathcal B$ a weight function.
  \end{itemize}
\end{definition}

% Over a BBIR we can define optimization problems over Boolean formulae.


% \begin{definition}[Max-Sum Problem]\label{def:msp over bbir}
%   Let $\BBIR$ be a BBIR over a branch-and-bound semiring
%   $\mathcal B$ and $\psi \in \{\varphi\}$.
%   Let $inst(X)$ be the set of all assignments of variables in $X$.
%   Then the max-sum problem (MSP) of $\psi$ over the BBIR is
%   \begin{equation}
%     MSP(\psi) = \max_{\pi \in inst(X)} \bigoplus_{m \models \psi|_{\pi}} f(m, \pi).
%   \end{equation}
% \end{definition}

% We demonstrate how this optimization problem aptly generalizes
% the MEU problem, along with several others
% present in the literature to showcase its generality.

We demonstrate below the definition of MEU and MMAP over BBIR below.

\subsubsection{The MEU Problem with Evidence}\label{subsubsec:meu}

Here, we give a formulation of the
MEU problem with evidence, a generalization of the MEU problem
addressed in~\cref{subsec:dappl-overview}
which allows us to eventually handle
\dapplcode{observe} statements in \dappl{}.
In particular we introduce an additional $\AMC$
in the denominator of the optimization function.
This additional model count can be handled by efficient
computation of bounds;
see Section~\ref{subsec:meu with evidence}
for full detail.

We represent this problem as a BBIR
$(\{\varphi \land \gamma_{\pi} : \pi \in \mathcal A\}, A, w)$, in which:

\begin{enumerate}[leftmargin=*]
  \item $\varphi$ is the Boolean formula detailing the control and data flow
  of the decision making model,
  \item $\gamma_{\pi}$ represent witnessed evidence for
  each policy $\pi \in \mathcal A$, where $\mathcal A$ is the collection of
  all possible policies (i.e., complete instantiations of choices)
  \item $A$ is the collection of variables representing choices.
  % on which we define instantiations (assignments) of $A$ as $inst(A) = \mathcal A$, and
  \item $w$ a weight function to denote rewards.
\end{enumerate}
On which the MEU problem reduces to the following optimization problem:
{\footnotesize\begin{equation}\label{eq:bbir-meu}
  \MEUfn{(\{\varphi \land \gamma_{\pi} : \pi \in \mathcal A\}, A, w)}
    \triangleq \max_{\pi \in \mathcal A} \frac{\AMC(\varphi|_{\pi} \land \gamma_{\pi},w)_{\EU}}{\AMC(\gamma_{\pi}, w)_{\Pr}},
\end{equation}}
where division is the normal division in $\R$  with the additional property that
division by $0$ is defined as $-\infty$.
The subscript $\EU$ and $\Pr$ denote the first and second projections over the expectation semiring,
referring to the $\AMC$ invariant proven in~\cref{appendix:amc invariant}.

To give a concrete example of this optimization problem, consider the example of~\cref{fig:motivation-dappl},
with the \dapplcode{observe} statement uncommented.
We can define
\begin{equation}
  \varphi = (u \land \varphi_u) \lor (\overline u \land \varphi_{\overline u}),
  \qquad
  \gamma_u = \gamma_{\overline u} = r,
  \qquad
  A = \{u\},
\end{equation}
where $\varphi_u$ and $\varphi_{\overline u}$ are
defined in~\cref{eq:formula-umbrella,eq:formula-no-umbrella} and $w$ are the weights
as defined in~\cref{sub@fig:bb circuit example}. Then we observe that
{\footnotesize
\begin{equation}
  \MEUfn{\{\varphi \land \gamma_i \mid i \in \{u, \overline u\}\}, A, w}
  = \max \left\{
  \frac{\AMC(\varphi_u \land r)_{\EU}}{\AMC(r)_{\Pr}},
  \frac{\AMC(\varphi_{\overline u} \land r)_{\EU}}{\AMC(r)_{\Pr}}
  \right\}
  = 10,
\end{equation}
}
validating the computations in~\cref{eqn:example-with-observe}.
\subsubsection{The Marginal Maximum A Posteriori (MMAP) Problem}\label{subsubsec:mmap}

We conclude with a formulation of the MMAP problem in full generality over a BBIR.
$\pineappl$ supports a limited form of conditioning, where observations can only occur
with a call to MMAP or a query (see~\cref{subsec:pineappl-sem} for details),
but we present a formulation of the MMAP problem which supports global conditioning.
We do so by defining the
BBIR $(\{\varphi, \gamma\}, M, w)$ where:

\begin{enumerate}[leftmargin=*]
  \item $M$ are our \emph{MAP variables} to compute the most likely state of,
  a subset of the variables of $\varphi$,
  \item $\varphi$ is our probabilistic model and $\gamma$ is our evidence to condition on,
  with $vars(\varphi) = M \cup V \cup E$ disjoint sets of variables where $E$
  is some set of variables representing priors and $V$ are probabilistic variables, and
  \item $w$ is a weight function with codomain in the real branch-and-bound semiring
  $\R$ where $\sqsubseteq, \leq$ are the usual total order.
\end{enumerate}

Then we can solve the following optimization problem for some priors $e \in inst(E)$,
where $inst$ denotes the set of all instantiations to a set of variables and $\varphi|_m$
denotes the formula derived by applying the literals of $m$ to $\varphi$:
{\footnotesize
\begin{align}\label{eq:bbir-mmap}
  \mathrm{MMAP}{(\{\varphi, \gamma\}, M, w, e)}
  &= \argmax_{m \in inst(M)} \sum_{\substack{v \in inst(V), \\ m \cup v \cup e \models \varphi}}
  \Pr[m \cup v \cup e \mid \gamma|_e]
  = \argmax_{m \in inst(M)} \frac{\AMC_\R(\varphi|_{m,e} \land \gamma|_e)}{\AMC(\gamma|_e)}.
\end{align}
}

When there are no priors, we elide $e$ in the arguments.
To give a concrete example of this problem, consider the example
given in the first four lines of~\cref{fig:motiv-pineappl}.
We can define:

{\footnotesize
\begin{equation*}
  \varphi =  \texttt{disease} \leftrightarrow f_{0.5} \land
  \texttt{headache} \leftrightarrow (\texttt{disease} \land f_{0.7} \lor \overline{\texttt{disease}} \land f_{0.1}).
  \qquad
  \gamma = \texttt{headache},
  \qquad
  M = \texttt{disease},
\end{equation*}
}
where $w(f_{n}) = 1 - w(\overline{f_{n}})$,
and the weight is 1 for all other literals.
\noindent Then we observe that with $V = \{f_{0.5}, f_{0.7}, f_{0.1}\}$,

{\footnotesize
\begin{align*}
  \mathrm{MMAP}{(\{\varphi, \gamma\}, \{\texttt{disease}\},w)}
  &=\max \left\{
    \sum_{\substack{v \in inst(V), \\
    v \cup \texttt{disease} \models \varphi}} \Pr\left[\texttt{disease} \cup v \mid \gamma\right],
    \sum_{\substack{v \in inst(V), \\
    v \cup \overline{\texttt{disease}} \models \varphi}} \Pr\left[\overline{\texttt{disease}} \cup v \mid \gamma\right],
  \right\} \\
  &=\max\{0.92, 0.08\} = 0.92,
\end{align*}
}
validating the computations in~\cref{eq:mmap-motiv-pineappl}.

Prior work, such as that of~\citet{huang2006solving} and~\citet{lee2016exact},
have leveraged
techniques in knowledge compilation to solve the MMAP problem via
a branch-and-bound algorithm.
Our method, to the best of our knowledge,
is the first method to generalize this approach beyond MMAP.


\subsection{Efficiently Upper-Bounding Algebraic Model Counts on BBIR}
\label{subsec:bounds}

We have demonstrated how the BBIR can represent important optimization problems
over probabilistic inference, as promised in~\cref{fig:bb-overview}.
However, a new problem representation
is moot without
gains in efficiency. Where does that happen?

Recall from Definition~\ref{def:bbir}
that the BBIR is over a branch-and-bound semiring, on which the
partial order $\sqsubseteq$ allowed the comparison of partially computed
algebraic model counts.
This is where the BBIR comes into play: it allows us to give an
upper- or lower-bound of partially computed algebraic model counts
on \textit{any} formula defined within the BBIR.
This is efficient--in particular, polynomial in the size of BBIR, more specifically
the BDD within. Thus, we can fully take advantage of the factorization of the
BDD while maintaining a way to compare partially computed values of AMC:

% To make this precise, we first need a definition.

\begin{definition}[Partial policies and completions]\label{def:partial policy}
  Let $\BBIR$ be a BBIR.
  Then, we can define $P$ a \emph{partial policy} of
  $X$ as instantiation of a subset of variables in $X$.
  A \textit{completion} $T$ of $P$ is an instantiation of variables of $X$
  such that $P \subseteq T$.
\end{definition}

\begin{figure}
  \begin{subfigure}[t]{0.37\linewidth}
    \begin{mdframed}{\footnotesize\begin{algorithmic}[1]
      \Procedure{$ub$}{$\BBIR, \varphi, P$}
      \State $pm \gets \bigotimes_{p \in P} w(p)$
      \State $acc \gets h(\varphi|_P, X,w)$
      \State \textbf{return} $pm \otimes acc$
      \EndProcedure
    \end{algorithmic}}
    \end{mdframed}
    \caption{The upper bound algorithm $ub$ takes in a BBIR, $\varphi \in \{\varphi\}$,
    and a $P$ a partial policy of $X$
    to find an upper bound of $\AMC(\varphi|_{T},w)$ for any completion $T$ of $P$.}
    \label{algorithm:ub}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{0.6\textwidth}
    \begin{mdframed}{\footnotesize\begin{algorithmic}[1]
      \Procedure{$h$}{$\varphi, X, w$}
      \If {$\varphi = \top$} \textbf{return 1}
      \ElsIf {$\varphi = \bot$} \textbf{return 0}
      \Else{ \textbf{let }$v \gets \mathrm{root}(\varphi)$}
        \If{$v \in X$}  \textbf{return}
        $w(v) \otimes h(\varphi|_v) \sqcup w(\overline v) \otimes h(\varphi|_{\overline v}$)
        \Else{ \textbf{return}
        $w(v)\otimes h(\varphi|_v) \oplus w(\overline v)\otimes h(\varphi|_{\overline v}$)}
        \EndIf
      \EndIf
      \EndProcedure
    \end{algorithmic}}
    \end{mdframed}
    \caption{The helper function $h$ as seen on Line 3 in Fig.~\ref{algorithm:ub}. }
    \label{algorithm:h}
  \end{subfigure}
  \caption{A single top-down pass upper-bound function. The function $\mathrm{root}$
  returns the topmost variable in the BDD. In order to scale efficiently, these
  procedures must be memoized; we omit these details.}
  \label{fig:h}
\end{figure}

With this definition in mind, we can give the pseudocode for our
upper bound algorithm in \Cref{fig:h}.
Algorithm~\ref{algorithm:h} runs in polynomial-time
in the size of the BBIR, as it is known
conditioning takes polynomial time in a
binary decision diagram~\citep{darwiche2002knowledge}.
However, it is not clear what \Cref{algorithm:ub} is
upper-bounding.
The key is observing that, at any choice variable, taking the join $\sqcup$
greedily chooses the best possible value,
without caring about whether it is associated to a policy or not.
This allows us to upper-bound all completions $T$ of $P$,
as we demonstrate in the following theorem, proven in~\cref{appendix:proof ub correctness}.

\begin{theorem}\label{thm:ub correctness}
  Let $\BBIR$ be a BBIR and let $\varphi \in \{\varphi_i\}$. Let $P$ be a partial policy of $X$.
  Then for all completions $T$ of $P$ we have
  \begin{equation}\label{eq:ub correctness}
    ub(\BBIR, \varphi, P)
      \sqsupseteq \bigoplus_{m \models \varphi|_T} \bigotimes_{\ell \in m \cup T} w(\ell)
      = \AMC(\varphi|_T) \bigotimes_{\ell \in T} w(\ell).
  \end{equation}
\end{theorem}

Importantly, we can define a dual \textit{lower bound} algorithm $lb$
by taking Algorithm~\ref{algorithm:h}
and changing the join $\sqcup$ in line 5 to a meet $\sqcap$.
This proves vital when achieving full generality of the branch-and-bound,
as a simultaneous
lower and upper bound is required to maintain sound pruning in the presence of evidence.
We also state an important Lemma
that holds for both upper-and lower-bounds,
whose proof amounts to observing that for
total policies, no join is ever done when bounding,
leading to an exact value.

\begin{lemma}\label{lemma:ub on total policy is amc}
  For any BBIR $\BBIR$ and $\varphi \in \{\varphi\}$, for any total policy $T$
  of $X$, we have
  \begin{equation}
    ub(\BBIR, \varphi, T) =lb(\BBIR, \varphi, T)= \AMC(\varphi|_T, w).
  \end{equation}
\end{lemma}

\subsection{Upper Bounds in Action: a General Branch-and-Bound Algorithm}
\label{subsec:meu with evidence}

We have, so far, demonstrated some of the theory and intuition that leads into
the BBIR, and the efficient upper- and lower-bound operation it supports.
Now,
we can use it to our full advantage to implement a general branch-and-bound style
algorithm to solve optimization problems expressed over BBIR.
This subsumes a previous algorithm for MMAP by~\citet{huang2006solving}
and generalizes it to MEU and to any other branch and bound semiring.

The algorithm is given in Algorithm~\ref{algorithm:bb}. It finds the maximum of an
objective function $f$
(for example, the problems of~\cref{eq:bbir-meu,eq:bbir-mmap})
given an upper-bound $\mathsf{UB}_f$ for $f$ over partial policies,
which we describe for MEU and MMAP in~\cref{appendix:ub_f}.
$\mathsf{UB}_f$ for MEU and MMAP take full advantage of
Algorithm~\ref{algorithm:ub}, and are completed in polynomial time.

% For notational simplicity, instead of using the BBIR
% $(\{\varphi \land \gamma_{\pi} : \pi \in \mathcal A\}, A, w)$,
% we will use
% the tuple $(\{\varphi, \gamma\}, A, w)$
% in which $\gamma$ is the formula in which
% for all $\pi \in \mathcal A$, $\gamma|_{\pi} = \gamma_{\pi}$.
% For a given BBIR for MEU, and a policy $\pi \in \mathcal A$,
% we write $
%   \mathrm{EU}(\pi) =
%   \frac{\AMC((\varphi \land \gamma)|_{\pi}, w)_{\EU}}{\AMC(\gamma|_{\pi})_{\Pr}}
% $, with $w$ implicit.
% Note that this can be solved via two calls to $ub$,
% on $(\varphi \land \gamma)|_{\pi}$
% and $\gamma|_{\pi}$ respectively;
% this is an application of Lemma~\ref{lemma:ub on total policy is amc}.
% More generally, for any value $(a,b) \in \mathcal S$ and $r \in \R$, we define
% scalar division for $\mathcal S$:
% \begin{equation}
%   \frac{(a,b)}{r} = \begin{cases}
%     \paren{\frac a r , \frac b r} & r \neq 0, \\
%     (0, -\infty) & r = 0.
%   \end{cases}
% \end{equation}

\begin{figure}
  \begin{mdframed}{\footnotesize\begin{algorithmic}[1]
    \Procedure{$bb$}{$\BBIR,
    R,
    b,
    P_{curr}$}
    \If {$R = \eset$}
      \State $n = f(P_{curr})$
      \Comment{$P_{curr}$ will be a total policy of $X$}
      \State \textbf{return } $\max(n, b)$\Comment{max uses the total order.}
    \Else
       \State $r = pop(R)$
       \For {$\ell \in \{r, \overline r\}$}
        \State $m = \mathsf{UB}_f((\{\varphi|_{\ell}\}, X, w), P_{curr} \cup \{\ell\})$\label{line:join}
        \If {$m \not\sqsubseteq b$} \label{line:prune}
          \State $n = bb(\{\varphi|_{\ell}, \gamma|_{\ell}\}, R, b, P_{curr} \cup \{\ell\})$
          \Comment{$n$ will always be from a policy}
          \State $b = \max(n,b)$
        \EndIf
       \EndFor
       \State \textbf{return } $b$
    \EndIf
  \EndProcedure
  \end{algorithmic}}\end{mdframed}
  \caption{The branch-and-bound style algorithm
  calculating the optimum of a function $f$ admitting an upper-bound function
  $\mathsf{UB}_f$ for every partial policy.
  The tuple $\BBIR$ is a BBIR,
  $R$ is the remaining search space (initialized to $X$),
  $b$ is a lower-bound,
  and $P_{curr}$ is the current partial policy (initialized to $\emptyset$).}
  \label{algorithm:bb}
\end{figure}

We give a quick walkthrough of \Cref{algorithm:bb}. If $R = \eset$,
we hit a base case, in which our accumulated policy, $P_{curr}$ is
a total policy. We evaluate the expected utility and update our upper bound
accordingly. If $R \neq \eset$, then we let $r$ be some variable in $R$ and
$\ell \in \{r, \overline r\}$ a literal.
Then we consider the extension of partial policy $P_{curr}$ with $\{\ell\}$,
which is still a partial policy. We compute an upper bound for the BBIR
conditioned on this partial policy to form $m$.

The pruning is at Line~\ref{line:prune}; if $m \not\sqsubseteq b$, then
there is no recursion, pruning any policies containing
$P_{curr} \cup \{\ell\}$. This pruning is sound, as shown by the
following theorem, proven in~\cref{appendix:soundness of bb proof}.

\begin{theorem}\label{thm:soundness of bb}
  Algorithm~\ref{algorithm:bb}
  solves the MEU and MMAP problems of~\cref{subsubsec:mmap,subsubsec:meu}.
  % More generally, given that $\mathsf{UB}_f$ is sound, Algorithm~\ref{algorithm:bb}
  % solves the optimization problem $\max_{\pi \in inst(X)} f(\pi)$.
\end{theorem}

\textit{Remark.}
It should be noted that, although we have put in hard work to take advantage of
the factorized representation of the BBIR as much as possible,
\Cref{algorithm:bb} can run in possibly exponential time with respect
to the size of $A$ in the worst case. This is because in the worst case we still
face the \textit{search-space explosion} discussed in
Section~\ref{sec:overview}.  The worst case will happen when there is no
pruning: if the guard of Line~\ref{line:prune} is always satisfied, we will
iterate through all possible partial models, which is of size $2^{|A|}$.

However,
we ensured that the inner-loop of partial and total policy evaluation (\cref{line:join}
of \Cref{algorithm:bb}) runs in polynomial time \textit{with respect
to the size of the already factorized representation of the BBIR}.
So, even though we have a search-space explosion,
we can much more efficiently search through that policy space than an approach
that does not leverage compilation.


%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: "../oopsla-appendix.tex"
%%% End:
