\begin{figure*}[]
\centering
\begin{subfigure}[b]{0.25\linewidth}
 \centering
 \begin{tikzpicture}
  \begin{axis}[
  height=3.5cm,
  width=3.5cm,
  grid=major,
  ymode=log,
  xlabel={\# Solved Cancer},
  legend style={at={(0em,5em)},anchor=west},
  legend columns=-1,
  ylabel={Time (s)},
  % ymin=0,
  xmin=0,
  ]
  \addplot[mark=none, thick, blue] table [x index={0}, y index={1}] {\CancerPNCactus};
  \addlegendentry{\pineappl{}}
  \addplot[mark=none, dashed, thick, red] table [x index={0}, y index={1}] {\CancerPLCactus};
  \addlegendentry{\problog{}}
  \end{axis}
  \end{tikzpicture}
  % \caption{Cancer.}
\end{subfigure}
~~~
\begin{subfigure}[b]{0.25\linewidth}
 \centering
 \begin{tikzpicture}
  \begin{axis}[
  height=3.5cm,
  width=4cm,
  grid=major,
  ymode=log,
  xlabel={\# Solved Sachs},
  % ymin=0,
  ymin=0.001,
  ]
  \addplot[mark=none, thick, blue] table [x index={0}, y index={1}] {\SachsPNCactus};
  \addplot[mark=none, dashed, thick, red] table [x index={0}, y index={1}] {\SachsPLCactus};
  \end{axis}
  \end{tikzpicture}
  % \caption{Sachs.}
\end{subfigure}
~~~
\begin{subfigure}[b]{0.2\linewidth}
 \centering
 \begin{tikzpicture}
  \begin{axis}[
  height=3.5cm,
  width=3.5cm,
  grid=major,
  ymode=log,
  xlabel={\# Solved Insurance},
  % ymin=0,
  ymin=0.001,
  ]
  \addplot[mark=none, thick, blue] table [x index={0}, y index={1}] {\InsurancePNCactus};
  \end{axis}
  \end{tikzpicture}
  % \caption{Insurance.}
\end{subfigure}
~
\begin{subfigure}[b]{0.2\linewidth}
 \centering
 \begin{tikzpicture}
  \begin{axis}[
  height=3.5cm,
  width=3.5cm,
  grid=major,
  ymode=log,
  xlabel={\# Solved Alarm},
  % ymin=0,
  ymin=0.001,
  ]
  \addplot[mark=none, thick, blue] table [x index={0}, y index={1}] {\AlarmPNCactus};
  \end{axis}
  \end{tikzpicture}
  % \caption{Alarm.}
\end{subfigure}
\caption{Cactus plots visualizing the number of solved benchmarks for \problog{} and \pineappl{}.
Plots without \problog{} results indicate that \problog{} failed to complete a single MMAP query.
% Each
% of these benchmarks are computing sets of \map{} queries on the specified model.}
}
\label{fig:cactus}
\end{figure*}

Here we aim to establish that the BBIR
is an effective target for scalably solving MMAP. First we note that, when specialized
to the real semiring, our approach specializes to the
approach in \citet{huang2006solving} for solving MMAP for Bayesian networks:
hence, we focus our evaluation instead on comparing against existing PPL implementations of MMAP and do elide comparing against Bayesian network baselines.
We compared \pineappl{} against
\problog{}, which uses an
enumerative strategy to solve MMAP, much like MEU.
% Indeed, its strategy for MMAP is to use
% existing transformations from MMAP to MEU problems~\citep{maua2016equivalences}
% and solve the MEU problem instead~\cite{van2010dtproblog}.
% By doing this $\problog$ with MMAP inherits the limitations
% $\dtproblog$: This is no longer true, we compared to problog2, which just does
% enumeration
MMAP in \problog{} is not first-class and can only be performed once every
program run, thus there is no possibility for meta-optimization.
There is no standard set of probabilistic programming problems to
benchmark the performance of MMAP, let alone meta-optimization.
Thus, we introduce a simple, illustrative
selection of benchmarks based on discrete Bayesian networks and compiled these
networks into equivalent \pineappl{} and \problog{} programs. The ``Cancer'' and ``Sachs''
networks are small enough to run MMAP queries over the entire powerset of
possible variables. For the ``Alarm'' and ``Insurance'' networks, we selected 5
variables uniformly at random, and ran the powerset of possible queries over
those 5 variables.

Figure~\ref{fig:cactus} gives a cactus plot showing the
relative performance of these two MMAP inference algorithms on four selected
Bayesian networks. To our
knowledge, these are by far the largest probabilistic programs that exact MMAP
inference has been performed on. On two of the examples (Insurance and Alarm),
\problog{} failed to complete a single MMAP query within the time limit,
mirroring the results of~\cref{subsec:dappl-eval}.

\subsubsection{Scalability of Meta-Optimization}
\label{subsubsec:meta-optimization-eval}
\begin{figure}[t!]
  \begin{subfigure}{0.45\textwidth}
    \begin{pineapplcodeblock}[basicstyle=\tiny\ttfamily]
m = true;
loop n {
  if m {
    x = flip 0.5; y = flip 0.5;
    if x && y { z = flip 0.5; }
    else { z = flip 0.5; }
  } else {
    x = flip 0.5; y = flip 0.5;
    if !x && !y { z = flip 0.5;}
    else { z = flip 0.5; }
  }
  (m) = mmap(z);
}
pr(z)\end{pineapplcodeblock}
    \caption{Template for $\pineappl$ program to demonstrate scaling of MMAP calls.}
    \label{fig:mmap-scaling-program-pineappl}
  \end{subfigure}\hfill
  \begin{subfigure}{0.45\textwidth}
    \begin{tikzpicture}
      \begin{axis}[
        height=5cm,
        ymin=0,
        ymax=5,
        % xmin=1,
        grid=major,
        width=6.5cm,
        xlabel={\# Nested MMAP Queries},
        ylabel={Time (s)},,
        legend columns=6,
        legend style={at={(4.3em,9.2em)},anchor=north, font=\footnotesize}
        % legend style={at={(0.5,1)},anchor=south},
        ]
        \addplot[mark=none, thick, blue] table [x index={0}, y index={1}] {\Nested};
        \addlegendentry{\pineappl{}};
        \addplot[mark=none, thick, orange, dashed] table [x index={0}, y index={1}] {\Nestedfit};
        \addlegendentry{$O(x^2)$};
      \end{axis}
    \end{tikzpicture}
   \caption{Performance of nested MMAP (blue).
   The plot fits to $O(x^2)$ (orange) with $r^2 = 0.996$.}
   \label{fig:pineappl-nested}
  \end{subfigure}
  \caption{Evaluating the scalability of nested calls to MMAP in $\pineappl$
    programs}
\end{figure}

To demonstrate the utility of staged compilation of BBIR, we construct
$\pineappl$ programs with sequential nested calls to \pineapplcode{mmap}. In
particular, we instantiate line 2 of the program in
\cref{fig:mmap-scaling-program-pineappl} with values ranging from 2 to 140,
corresponding to the number of loop iterations.
Bounded
loops are a hygenic macro in $\pineappl$ that expand to their unrolling with
fresh names (the details of this expansion are described in~\citet{cho2025scaling}).
Since $\pineappl$ programs compile to circuits,
inference performance is not parameter sensitive, hence the use of
\pineapplcode{flip 0.5} for all randomness in the program.

Recall from the motivating example of~\cref{subsec:pineappl-overview} that
evaluating of each call to \pineapplcode{mmap} at the end of compilation
will cause exponential blowup in performance.
This is because we will need to compute and compare marginal probabilities over
Boolean formulae
exponential in the number of variables that we \pineapplcode{mmap} over.
However, BBIR allows for staged compilation, which is reflected in~\cref{fig:pineappl-compl},
which drastically reduces such blowup, as seen in~\cref{fig:pineappl-nested}.
With staged compilation, we face quadratic-time scaling in
the number of calls to \pineapplcode{mmap} despite the exponential blowup in assignment to variables,
as there are only a fixed number of variables defined
before each subsequent \pineapplcode{mmap} call.


%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: "../oopsla-appendix.tex"
%%% End:
