The Achilles' heel of probabilistic programming languages (PPLs) is \textit{scalability}.
The primary task of probabilistic programs,
probabilistic inference,
is \#P-hard~\citep{roth1996hardness} even when restricted to only Boolean random variables,
which amounts to counting accepting inputs
for an NP-complete problem.
Intuitively, this complexity stems from a \textit{state-space explosion}:
there are exponentially many probabilistic outcomes in the number of random variables,
and one must add up the probability of an
arbitrarily large subset of these outcomes to perform inference.

Monumental strides have been taken to make PPLs scalable.
One such stride is the development of the \textit{reasoning-via-compilation} scheme,
which is currently the
state-of-the-art approach for exact inference for many kinds of
probabilistic programs and graphical models~\citep{holtzen2020scaling,fierens2015inference,li2023scallop}.
The essence of reasoning-via-compilation is to identify \emph{tractable target
languages} that (1) support efficient reasoning, and (2) exploit
program structure to scale.
Tractable target languages capture a class of tractable problem
instances:
for example, in probabilistic
inference, knowledge compilation data-structures like binary decision diagrams (BDDs),
despite their inexpressiveness as a language~\citep{darwiche2002knowledge},
have proven very successful in practice as tractable targets because
they scale by exploiting conditional independence, a property that is abundant in many
real-world probabilistic programs~\citep{holtzen2020scaling}.
% One such stride was the \textit{factorization} of probabilistic inference, as
% defined as a probabilistic program,
% via program structure~\citep{holtzen2020scaling,de2007problog,saad2021sppl}.
% By compiling a (discrete) probabilistic program into a probability-weighted
% Boolean formula, one can take advantage of tractable, factored representations of
% the Boolean formula to factorize inference.
% \citet{holtzen2020scaling} demonstrated that binary decision diagrams (BDDs),
% a certain tractable representation of Boolean formulae,
% naturally exploit repeated sub-structure in the program as conditional independence
% in order to scale. Compiling to a BDD can be expensive, but once it is compiled,
% probabilistic inference becomes \textit{efficient in the size of the BDD},
% which allows inference to scale.


But, many practical real-world problems require additional reasoning \textit{on top of} inference,
increasing the complexity of an already hard problem.
In this paper, we focus on the additional task of \textit{optimization over inference},
in which an objective function over probabilistic inference must be optimized.
Such problems are ubiquitous and have been studied through the lenses of
game theory~\citep{osborne2004introduction},
probabilistic graphical models~\citep{howard2002comments,puterman1978modified,koller2009probabilistic},
reinforcement learning~\citep{busoniu2008comprehensive},
and beyond.
Often, such tasks require \textit{meta-reasoning}, or nested reasoning,
in which computed optimal values inform the next step of inference, which
serves to increase the complexity of reasoning about such problems~\citep{lew2023probabilistic,rainforth2018nesting,zhang2022reasoning}.
Despite their inherent difficulty,
optimization problems over inference have had broad applicability in
medical diagnosis~\citep{heckerman1992toward,lee2014applying},
image segmentation~\citep{bioucas2016bayesian},
and AI planning~\citep{kiselev2014policy}.

The high complexity of optimization over inference has two root causes.
The first is the state-space explosion as described before.
The second is \textit{search-space explosion}: to find the optimal value,
in the worst case one must traverse and compare all possible values the objective function can take,
which often causes significant blowup.
Indeed, the complexity of the two optimization problems we will study in this paper,
maximum expected utility (MEU) and marginal maximum a posteriori (MMAP),
is $NP^{PP}$-hard, so it is still $NP$-hard even with a probabilistic polynomial-time ($PP$) oracle
to perform fast inference~\citep{maua2016equivalences}.

MEU and MMAP are examples of \emph{discrete finite-horizon decision-making
problems with deterministic policies}.
Such decision-making problems are quite common in diagnosis and
planning, and have typically been represented using decision-theoretic Bayesian networks~\citep[Ch. 16]{russell2016artificial}
and influence
diagrams~\citep{howard2005influence,sanner2010relational}.
Despite their intractability, they are remarkably simple, lacking features such as loops and continuous random variables,
differentiating them from related decision-making problems under uncertainty such as
Markov decision processes (MDPs)~\citep{sutton2018reinforcement} or
optimal value-of-information problems where the goal
is to decide what kinds of events to observe~\citep[\S 16.6]{russell2016artificial}.
% Despite the prevalence of optimization problems over inference, there are relatively
% few languages that can specify such problems and leverage the scalability of
% reasoning-via-compilation.
% There exist decision-theoretic languages such as \dtproblog~\citep{van2010dtproblog},
% Bayesian decision diagrams~\citep{nath2009language,boutilierdecision,sanner2010relational},
% and PRISM~\citep{dehnert2017storm,kwiatkowska2002prism}, as well as
% a MMAP extension of $\problog$.
% However, there does not exist yet a general tractable target language to specify
% such optimization problems \'a la BDDs for inference, let alone one that supports
% meta-inference. \sh{it almost feels like this paragraph can be skipped; not sure.
% it feels a bit weak, and gives too much credit to DT-problog IMO.}

% For example, \textit{maximum expected utility} (MEU) problems
% require finding an optimal policy (a deterministic assignment) with respect to a set of choices
% to maximize an expected reward under uncertainty.
% MEU problems have found applications in game theory, reinforcement learning, medical
% diagnosis~\citep{heckerman1992toward}, and beyond
% ~\citep{kochenderfer2015decision,howard2002comments,busoniu2008comprehensive,puterman1978modified}.
% Similarly, \textit{marginal maximum a posteriori} (MMAP) problems compute the \textit{meta-inference} task
% of finding the most
% likely assignment to a subset of random variables
% given evidence, to be reused as a first-class value in the probabilistic program \sh{bundling up a few ideas
% here; first-class MMAP is new, should be discussed separately}.
% MMAP problems have found usage in image segmentation, AI planning, medical diagnosis,
% and more~\citep{lee2014applying,kiselev2014policy,bioucas2016bayesian}.

% The common element of the MEU and the MMAP problem is that they both optimize over probabilistic inference.
% In the worst case, additional to the state-space explosion of probabilistic inference, there is also a
% \textit{search-space explosion}: to find the maximum expected reward (in the case of MEU) or
% the most likely assignment (in the case of MMAP), one must search over assignments to variables,
% of which there are exponentially many.
% Indeed, the complexity of MEU and MMAP is $NP^{PP}$,
% so it is still NP with a probabilistic polynomial-time oracle
% to perform inference~\citep{maua2016equivalences}.

% The increasing prevalence of problems requiring optimization over probabilistic inference
% implies the need for languages to specify such problems.
% For MEU, decision-theoretic languages such as \dtproblog~\citep{van2010dtproblog}, Bayesian
% decision
% diagrams~\citep{nath2009language,boutilierdecision,sanner2010relational},
% % SmartChoices~\citep{abadi2021smart,carbune2018smartchoices},
% and PRISM~\citep{dehnert2017storm,kwiatkowska2002prism} have found
% application in algorithm design, planning, and targeted advertising.
% For MMAP, the only language that has first-class MMAP inference is $\problog$, although
% general-purpose PPLs that can perform meta-inference, such as
% Church~\citep{goodman2012church}, Anglican~\citep{tolpin2016design},
% and Gen~\citep{cusumano2019gen}, can specialize their meta-inference to perform MMAP.

\textit{What is an effective target language to express problems such as MEU and MMAP}?
Generalizing the reasoning-via-compilation perspective,
we present \textit{optimization-via-compilation}, a compilation scheme
supporting efficient probabilistic inference and, additionally, \textit{efficient pruning} of non-optimal values,
at the cost of no builtin loops or continuous random variables \'a la BDDs.
Our new tractable target language, which we call the \emph{branch-and-bound
intermediate representation} (BBIR),
\textit{factorizes} the state space of a probabilistic program to manage state-space explosion
and \textit{prunes} the search space
via a branch-and-bound approach to manage search-space explosion.
The compilation in BBIR can also be \textit{staged}, in which a partially compiled BBIR can
be queried for optimal values to be used further along in compilation, allowing for
\textit{meta-optimization}.
This culminates in $\dappl$ and $\pineappl$,
simple discrete probabilistic languages with bounded loops
expressing MEU and MMAP problems,
that demonstrate the performance and generality of optimization-via-compilation, as laid out by~\cref{fig:bb-overview}.
\begin{figure}
  \centering
  \scalebox{0.8}{
  \begin{tikzpicture}[decoration=snake]
    \node[draw, above=3pt] (dappl) {\dappl{}};
    \node[draw, below=3pt] (pineappl) {\pineappl{}};
    \node[draw, right = 100pt] (wbf) {Semiring-weighted Boolean formula};
    \node[draw, right = of wbf] (bbir) {BBIR};
    \node[draw, right = of bbir, xshift=15pt] (out) {Output};
    \draw[->, decorate] (dappl) -- (wbf) node[midway, above=5pt] {\cref{sec:dappl}};
    \draw[->, decorate] (pineappl) -- (wbf) node[midway, below=5pt] {\cref{sec:pineappl}};
    \draw[->, decorate] (wbf) -- (bbir) node[midway, above] {};
    \draw[->] (bbir) edge [loop] (bbir) node[right, above=30pt] {\cref{sec:bbir}};
    \draw[->, decorate] (bbir) -- (out) node[midway, below=5pt] {\cref{sec:bbir}};
  \end{tikzpicture}
  }
  \caption{Overview of the optimization-via-compilation scheme and associated sections of the paper. }
  \label{fig:bb-overview}
\end{figure}
In sum, we make the following contributions:
\begin{itemize}[leftmargin=*]
  \item (\cref{sec:bbir}): We identify a new intermediate
  representation for solving max-over-sum problems called the
  \emph{branch-and-bound intermediate representation} (BBIR).  The key feature
  of BBIR is that it supports efficient (i.e., polynomial-time) computation of
  upper-bounds of partially computed values of the objective function,
  at the cost of lacking support for dynamically bounded loops, almost surely-terminating loops and continuous random variables.
  We show how the BBIR can represent optimization problems over inference, and how BBIR admits an algorithm that uses
  its efficient upper bounds to find optima via pruning.
  \item (\cref{sec:dappl}): We develop \dappl{}, a discrete-valued
  functional decision-theoretic probabilistic programming language with Bayesian
  conditioning. We give a semantics-preserving
  compilation scheme from \dappl{} to BBIR, and prove it correct.
  \item (\cref{sec:pineappl}): We develop $\pineappl$, a discrete-valued
  imperative probabilistic programming language in which MMAP queries, a meta-optimization query,
  are a first-class primitive
  on top of inference. This mid-program optimization is performed using
  staged compilation~\citep{chambers2002staged,rompf2010lightweight,devito2013terra} and
  querying of partially compiled BBIR, which we again prove sound with respect to
  the semantics of $\pineappl$.
  \item (\cref{sec:eval}): We empirically validate the effectiveness of
  our optimization-via-compilation strategy and show that it
  outperforms existing approaches to solving MEU and MMAP in discrete probabilistic programs
  while simultaneously supporting the novel feature of meta-optimization.
\end{itemize}
