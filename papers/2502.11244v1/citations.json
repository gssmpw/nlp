[
  {
    "index": 0,
    "papers": [
      {
        "key": "geiger2021causal",
        "author": "Atticus Geiger and Hanson Lu and Thomas F Icard and Christopher Potts",
        "title": "Causal Abstractions of Neural Networks"
      },
      {
        "key": "stolfo2023a",
        "author": "Alessandro Stolfo and Yonatan Belinkov and Mrinmaya Sachan",
        "title": "A Mechanistic Interpretation of Arithmetic Reasoning in Language Models using Causal Mediation Analysis"
      },
      {
        "key": "gurnee2023finding",
        "author": "Wes Gurnee and Neel Nanda and Matthew Pauly and Katherine Harvey and Dmitrii Troitskii and Dimitris Bertsimas",
        "title": "Finding Neurons in a Haystack: Case Studies with Sparse Probing"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "zou2023transparency",
        "author": "Andy Zou Long Phan Sarah Chen James Campbell Phillip Guo Richard Ren Alexander Pan Xuwang Yin Mantas Mazeika Ann-Kathrin Dombrowski Shashwat Goel Nathaniel Li Michael J. Byun Zifan Wang Alex Mallen Steven Basart Sanmi Koyejo Dawn Song Matt Fredrikson Zico Kolter Dan Hendrycks",
        "title": "Representation Engineering: A Top-Down Approach to AI Transparency"
      },
      {
        "key": "chen2024findingsafetyneuronslarge",
        "author": "Jianhui Chen and Xiaozhi Wang and Zijun Yao and Yushi Bai and Lei Hou and Juanzi Li",
        "title": "Finding Safety Neurons in Large Language Models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "vig2019multiscalevisualizationattentiontransformer",
        "author": "Jesse Vig",
        "title": "A Multiscale Visualization of Attention in the Transformer Model"
      },
      {
        "key": "wu2025retrieval",
        "author": "Wenhao Wu and Yizhong Wang and Guangxuan Xiao and Hao Peng and Yao Fu",
        "title": "Retrieval Head Mechanistically Explains Long-Context Factuality"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "NEURIPS2019_2c601ad9",
        "author": "Michel, Paul and Levy, Omer and Neubig, Graham",
        "title": "Are Sixteen Heads Really Better than One?"
      },
      {
        "key": "meng2023locatingeditingfactualassociations",
        "author": "Kevin Meng and David Bau and Alex Andonian and Yonatan Belinkov",
        "title": "Locating and Editing Factual Associations in GPT"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "gould2023successorheadsrecurringinterpretable",
        "author": "Rhys Gould and Euan Ong and George Ogden and Arthur Conmy",
        "title": "Successor Heads: Recurring, Interpretable Attention Heads In The Wild"
      },
      {
        "key": "wang2023interpretability",
        "author": "Kevin Ro Wang and Alexandre Variengien and Arthur Conmy and Buck Shlegeris and Jacob Steinhardt",
        "title": "Interpretability in the Wild: a Circuit for Indirect Object Identification in {GPT}-2 Small"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "geiger2021causal",
        "author": "Atticus Geiger and Hanson Lu and Thomas F Icard and Christopher Potts",
        "title": "Causal Abstractions of Neural Networks"
      },
      {
        "key": "stolfo2023a",
        "author": "Alessandro Stolfo and Yonatan Belinkov and Mrinmaya Sachan",
        "title": "A Mechanistic Interpretation of Arithmetic Reasoning in Language Models using Causal Mediation Analysis"
      },
      {
        "key": "gurnee2023finding",
        "author": "Wes Gurnee and Neel Nanda and Matthew Pauly and Katherine Harvey and Dmitrii Troitskii and Dimitris Bertsimas",
        "title": "Finding Neurons in a Haystack: Case Studies with Sparse Probing"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "zou2023transparency",
        "author": "Andy Zou Long Phan Sarah Chen James Campbell Phillip Guo Richard Ren Alexander Pan Xuwang Yin Mantas Mazeika Ann-Kathrin Dombrowski Shashwat Goel Nathaniel Li Michael J. Byun Zifan Wang Alex Mallen Steven Basart Sanmi Koyejo Dawn Song Matt Fredrikson Zico Kolter Dan Hendrycks",
        "title": "Representation Engineering: A Top-Down Approach to AI Transparency"
      },
      {
        "key": "chen2024findingsafetyneuronslarge",
        "author": "Jianhui Chen and Xiaozhi Wang and Zijun Yao and Yushi Bai and Lei Hou and Juanzi Li",
        "title": "Finding Safety Neurons in Large Language Models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "vig2019multiscalevisualizationattentiontransformer",
        "author": "Jesse Vig",
        "title": "A Multiscale Visualization of Attention in the Transformer Model"
      },
      {
        "key": "wu2025retrieval",
        "author": "Wenhao Wu and Yizhong Wang and Guangxuan Xiao and Hao Peng and Yao Fu",
        "title": "Retrieval Head Mechanistically Explains Long-Context Factuality"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "NEURIPS2019_2c601ad9",
        "author": "Michel, Paul and Levy, Omer and Neubig, Graham",
        "title": "Are Sixteen Heads Really Better than One?"
      },
      {
        "key": "meng2023locatingeditingfactualassociations",
        "author": "Kevin Meng and David Bau and Alex Andonian and Yonatan Belinkov",
        "title": "Locating and Editing Factual Associations in GPT"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "gould2023successorheadsrecurringinterpretable",
        "author": "Rhys Gould and Euan Ong and George Ogden and Arthur Conmy",
        "title": "Successor Heads: Recurring, Interpretable Attention Heads In The Wild"
      },
      {
        "key": "wang2023interpretability",
        "author": "Kevin Ro Wang and Alexandre Variengien and Arthur Conmy and Buck Shlegeris and Jacob Steinhardt",
        "title": "Interpretability in the Wild: a Circuit for Indirect Object Identification in {GPT}-2 Small"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "xie2018mitigating",
        "author": "Cihang Xie and Jianyu Wang and Zhishuai Zhang and Zhou Ren and Alan Yuille",
        "title": "Mitigating Adversarial Effects Through Randomization"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "xiao2024ritfisrobustinputtesting",
        "author": "Mingxuan Xiao and Yan Xiao and Hai Dong and Shunhui Ji and Pengcheng Zhang",
        "title": "RITFIS: Robust input testing framework for LLMs-based intelligent software"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "kenton2024scalableoversightweakllms",
        "author": "Zachary Kenton and Noah Y. Siegel and J\u00e1nos Kram\u00e1r and Jonah Brown-Cohen and Samuel Albanie and Jannis Bulian and Rishabh Agarwal and David Lindner and Yunhao Tang and Noah D. Goodman and Rohin Shah",
        "title": "On scalable oversight with weak LLMs judging strong LLMs"
      },
      {
        "key": "wang-etal-2024-languages",
        "author": "Wang, Wenxuan  and\nTu, Zhaopeng  and\nChen, Chang  and\nYuan, Youliang  and\nHuang, Jen-tse  and\nJiao, Wenxiang  and\nLyu, Michael",
        "title": "All Languages Matter: On the Multilingual Safety of {LLM}s"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "YAO2024100211",
        "author": "Yifan Yao and Jinhao Duan and Kaidi Xu and Yuanfang Cai and Zhibo Sun and Yue Zhang",
        "title": "A survey on large language model (LLM) security and privacy: The Good, The Bad, and The Ugly"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "sachdeva2025turninglogicprobing",
        "author": "Rachneet Sachdeva and Rima Hazra and Iryna Gurevych",
        "title": "Turning Logic Against Itself : Probing Model Defenses Through Contrastive Questions"
      },
      {
        "key": "banerjee2024unethicalinstructioncentricresponsesllms",
        "author": "Somnath Banerjee and Sayan Layek and Rima Hazra and Animesh Mukherjee",
        "title": "How (un)ethical are instruction-centric responses of LLMs? Unveiling the vulnerabilities of safety guardrails to harmful queries"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "10.5555/3692070.3694246",
        "author": "Wolf, Yotam and Wies, Noam and Avnery, Oshri and Levine, Yoav and Shashua, Amnon",
        "title": "Fundamental limitations of alignment in large language models"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "li2023rainlanguagemodelsalign",
        "author": "Yuhui Li and Fangyun Wei and Jinjing Zhao and Chao Zhang and Hongyang Zhang",
        "title": "RAIN: Your Language Models Can Align Themselves without Finetuning"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "bhardwaj2024languagemodelshomersimpson",
        "author": "Rishabh Bhardwaj and Do Duc Anh and Soujanya Poria",
        "title": "Language Models are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models through Task Arithmetic"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "hazra2024safetyarithmeticframeworktesttime",
        "author": "Rima Hazra and Sayan Layek and Somnath Banerjee and Soujanya Poria",
        "title": "Safety Arithmetic: A Framework for Test-time Safety Alignment of Language Models by Steering Parameters and Activations"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "banerjee2024safeinfercontextadaptivedecoding",
        "author": "Somnath Banerjee and Sayan Layek and Soham Tripathy and Shanu Kumar and Animesh Mukherjee and Rima Hazra",
        "title": "SafeInfer: Context Adaptive Decoding Time Safety Alignment for Large Language Models"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "xu2024safedecodingdefendingjailbreakattacks",
        "author": "Zhangchen Xu and Fengqing Jiang and Luyao Niu and Jinyuan Jia and Bill Yuchen Lin and Radha Poovendran",
        "title": "SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware Decoding"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "xie2018mitigating",
        "author": "Cihang Xie and Jianyu Wang and Zhishuai Zhang and Zhou Ren and Alan Yuille",
        "title": "Mitigating Adversarial Effects Through Randomization"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "xiao2024ritfisrobustinputtesting",
        "author": "Mingxuan Xiao and Yan Xiao and Hai Dong and Shunhui Ji and Pengcheng Zhang",
        "title": "RITFIS: Robust input testing framework for LLMs-based intelligent software"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "kenton2024scalableoversightweakllms",
        "author": "Zachary Kenton and Noah Y. Siegel and J\u00e1nos Kram\u00e1r and Jonah Brown-Cohen and Samuel Albanie and Jannis Bulian and Rishabh Agarwal and David Lindner and Yunhao Tang and Noah D. Goodman and Rohin Shah",
        "title": "On scalable oversight with weak LLMs judging strong LLMs"
      },
      {
        "key": "wang-etal-2024-languages",
        "author": "Wang, Wenxuan  and\nTu, Zhaopeng  and\nChen, Chang  and\nYuan, Youliang  and\nHuang, Jen-tse  and\nJiao, Wenxiang  and\nLyu, Michael",
        "title": "All Languages Matter: On the Multilingual Safety of {LLM}s"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "YAO2024100211",
        "author": "Yifan Yao and Jinhao Duan and Kaidi Xu and Yuanfang Cai and Zhibo Sun and Yue Zhang",
        "title": "A survey on large language model (LLM) security and privacy: The Good, The Bad, and The Ugly"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "sachdeva2025turninglogicprobing",
        "author": "Rachneet Sachdeva and Rima Hazra and Iryna Gurevych",
        "title": "Turning Logic Against Itself : Probing Model Defenses Through Contrastive Questions"
      },
      {
        "key": "banerjee2024unethicalinstructioncentricresponsesllms",
        "author": "Somnath Banerjee and Sayan Layek and Rima Hazra and Animesh Mukherjee",
        "title": "How (un)ethical are instruction-centric responses of LLMs? Unveiling the vulnerabilities of safety guardrails to harmful queries"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "10.5555/3692070.3694246",
        "author": "Wolf, Yotam and Wies, Noam and Avnery, Oshri and Levine, Yoav and Shashua, Amnon",
        "title": "Fundamental limitations of alignment in large language models"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "li2023rainlanguagemodelsalign",
        "author": "Yuhui Li and Fangyun Wei and Jinjing Zhao and Chao Zhang and Hongyang Zhang",
        "title": "RAIN: Your Language Models Can Align Themselves without Finetuning"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "bhardwaj2024languagemodelshomersimpson",
        "author": "Rishabh Bhardwaj and Do Duc Anh and Soujanya Poria",
        "title": "Language Models are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models through Task Arithmetic"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "hazra2024safetyarithmeticframeworktesttime",
        "author": "Rima Hazra and Sayan Layek and Somnath Banerjee and Soujanya Poria",
        "title": "Safety Arithmetic: A Framework for Test-time Safety Alignment of Language Models by Steering Parameters and Activations"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "banerjee2024safeinfercontextadaptivedecoding",
        "author": "Somnath Banerjee and Sayan Layek and Soham Tripathy and Shanu Kumar and Animesh Mukherjee and Rima Hazra",
        "title": "SafeInfer: Context Adaptive Decoding Time Safety Alignment for Large Language Models"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "xu2024safedecodingdefendingjailbreakattacks",
        "author": "Zhangchen Xu and Fengqing Jiang and Luyao Niu and Jinyuan Jia and Bill Yuchen Lin and Radha Poovendran",
        "title": "SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware Decoding"
      }
    ]
  }
]