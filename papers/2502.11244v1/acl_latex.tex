% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[]{acl}
%\usepackage[dvipsnames]{xcolor}
\usepackage{bbm}
% Standard package includes
\usepackage{multirow}
\usepackage{placeins}
\usepackage{times}
\usepackage{latexsym}
\usepackage{tablefootnote}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
%\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{enumerate}
\usepackage{hyperref}
\usepackage{url}
\usepackage{wrapfig,lipsum,booktabs}
\usepackage{newtxtext} % you want true small caps
\usepackage{lettrine}
\usepackage{colortbl}
\usepackage{xcolor}
\usepackage{array}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{mathrsfs}
\usepackage{amsmath}
\definecolor{lightgray}{gray}{0.9}
\definecolor{darkergray}{gray}{0.85}
\definecolor{Lavender}{RGB}{230,230,250}
\definecolor{LimeGreen}{RGB}{50,205,50}
\definecolor{NavyBlue}{RGB}{0, 0, 128}
\definecolor{Red}{RGB}{255,0,0}
\definecolor{ForestGreen}{RGB}{34, 139, 34}
\definecolor{RoyalBlue}{RGB}{65, 105, 225}
\definecolor{Maroon}{RGB}{128, 0, 0}
\definecolor{CornflowerBlue}{RGB}{100, 149, 237}
\definecolor{Orange}{RGB}{255, 165, 0}

\usepackage{booktabs}
\usepackage{multirow}
\usepackage{pgfplots}
\usepgfplotslibrary{groupplots}
\pgfplotsset{compat=1.18}
\usepackage{soul}
\usepackage{paralist}
%\usepackage[usenames,dvipsnames]{color}
%\usepackage[most]{tcolorbox}
\usepackage{mdframed,lipsum}

\newcommand{\am}[1]{\textcolor{red}{#1 -- AM}}
\newcommand{\rh}[1]{\textcolor{blue}{#1 -- RH}}
\newcommand{\snb}[1]{\textcolor{teal}{#1 -- SNB}}
% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

% \title{Mechanistic Interpretability for Multilingual Safety: Fine-Grained Parameter Steering in Large Language Models}

\definecolor{lightred}{rgb}{1, 0.7, 0.7}
\definecolor{lightblue}{rgb}{0.7, 0.7, 1}
\definecolor{darkred}{rgb}{0.6, 0, 0}
\definecolor{darkblue}{rgb}{0, 0, 0.6}

%\usepackage[table]{xcolor}
\definecolor{E3F2E3}{HTML}{E3F2E3}
\pgfplotsset{compat=1.18}
\newmdenv[
  topline=false,
  bottomline=false,
  skipabove=\topsep,
  skipbelow=\topsep,
  leftline=true,
  rightline=true,
  linecolor=NavyBlue,
  linewidth=2pt,
  innertopmargin=5pt,
  innerbottommargin=5pt,
  innerrightmargin=5pt,
  innerleftmargin=5pt,
  backgroundcolor=gray!10,
  roundcorner=10pt
]{stylishframe}

% \title{}
\title{\textsc{Soteria}: Language-Specific Functional Parameter Steering for Multilingual Safety Alignment}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

% \author{First Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\\And
%   Second Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\}

\author{Somnath Banerjee$^\dagger$, Sayan Layek$^\dagger$, Pratyush Chatterjee$^\dagger$,\\ \textbf{Animesh Mukherjee}$^\dagger$\textbf{,} \textbf{Rima Hazra}$^\mp$ \\\\
$^\dagger$ Indian Institute of Technology Kharagpur\\
$^\mp$ INSAIT, Sofia University ``St. Kliment Ohridski''
}

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
\begin{abstract}
Ensuring consistent safety across multiple languages remains a significant challenge for large language models (LLMs). We introduce \textsc{Soteria}, a lightweight yet powerful strategy that locates and minimally adjusts the “\textit{functional heads}” most responsible for harmful content generation in each language. By altering only a fraction of parameters, \textsc{Soteria} drastically reduces policy violations without sacrificing overall model performance, even in low-resource settings. To rigorously evaluate our approach, we also present \emph{XThreatBench}, a specialized multilingual dataset capturing fine-grained harmful behaviors drawn from real policy guidelines. Experiments with leading open-source LLMs (e.g., Llama, Qwen, Mistral) show that \textsc{Soteria} consistently improves safety metrics across high-, mid-, and low-resource languages. These findings highlight a promising path toward scalable, linguistically attuned, and ethically aligned LLMs worldwide. The source code and dataset are available at:~\url{https://github.com/NeuralSentinel/Soteria}
\end{abstract}

\section{Introduction}
% \textcolor{Red}{Motivation on why we need multilingual safety when we have english safety present.
% Motivation on why task specific fine tune will not the actual solution.
% Motivation on our proposed dataset.}\\
% Ensuring safety across multiple languages is becoming increasingly important, especially for smaller-parameter language models like Llama 3 8B Mistral v0.3 7B, which can be more practical to deploy in low-resource contexts (Touvron et al., 2023; Zhou et al., 2023). These models, while potentially easier to handle due to their reduced size, also face unique challenges in maintaining consistent safety standards across different languages and cultural settings (Wang et al., 2023). Recent studies emphasize that smaller models may inadvertently generate harmful or culturally insensitive content if not carefully aligned, highlighting the need for robust safety protocols tailored to multilingual environments (Johnson et al., 2023). By focusing on safety for these compact models, we can ensure responsible AI practices while broadening the benefits of language technologies to diverse communities worldwide (Castillo et al., 2024; Kim \& Park, 2024). Such efforts are crucial in building trust, fostering inclusivity, and promoting ethical AI use on a global scale.

% Tokenization lies at the core of modern language models, yet most tokenizers remain optimized for English text, creating significant mismatches when applied to other languages [1], [2]. For instance, languages with complex morphology (such as Turkish or Finnish) or those that do not always rely on clear word boundaries (such as Chinese or Thai) often get fragmented into subword units that are meaningless or extremely short, undermining the ability of safety filters to detect harmful content [3], [4]. Furthermore, culturally specific idioms or expressions can be split incorrectly, introducing confusion that leads to either undetected risks or frequent false alarms [5]. A seemingly straightforward workaround—translating content into English before applying safety checks—falls short because translation systems themselves can introduce distortions or omit critical context, particularly for low-resource languages [6]. These translation-based pipelines risk diluting culturally embedded meaning, thus allowing harmful or offensive content to slip through. Consequently, building genuinely multilingual safety solutions demands tokenization and content moderation approaches that align with the linguistic and cultural intricacies of each language, rather than relying on English-centric methods or translations that lose nuance.\\
% While fine-tuning can help narrow performance gaps for specific tasks and languages, it cannot fully overcome the foundational limitations in a model’s architecture and tokenization design. Smaller models like Llama 2 7B remain anchored to an English-centric subword vocabulary, so fine-tuning alone seldom reconfigures these deeper structural biases [7]. This shortfall becomes even more evident in languages with complex morphologies or script variations, where the inadequate tokenization stymies accurate understanding regardless of how much additional data is provided [2]. Moreover, acquiring high-quality, large-scale multilingual datasets for fine-tuning can be both expensive and time-consuming, and doing so repeatedly for each language or domain quickly inflates operational costs [7]. Hence, while fine-tuning offers incremental improvements, it does not constitute a holistic solution for truly multilingual safety—especially when larger, more inherently multilingual models like GPT-4 can better handle diverse linguistic complexities from the outset [9].

% Large language models (LLMs) such as ChatGPT (OpenAI, 2023a), GPT-4 (OpenAI, 2023b), Claude (Anthropic, 2023), and Llama (Touvron et al., 2023) have demonstrated strong performance across a wide range of language tasks (Singhal et al., 2022; Choi et al., 2023; Rezayi et al., 2023). However, existing countermeasures—such as red teaming, content filtering, and reinforcement learning from human feedback—are predominantly engineered for English, creating vulnerabilities that malicious instructions (“jailbreaks”) can exploit (Ganguli et al., 2022; Hartvigsen et al., 2022; Christiano et al., 2017; Ouyang et al., 2022; Bai et al., 2022; Perez et al., 2022). Although extensive pre-training endows LLMs with some multilingual capability, consistent safety in non-English settings remains challenging. This issue is especially pronounced in smaller-parameter models (e.g., Llama 3 8B, Mistral v0.3 7B), which are often deployed in low-resource environments and risk producing harmful or linguistically insensitive outputs when primarily aligned with English (Touvron et al., 2023; Zhou et al., 2023; Wang et al., 2023). Consequently, robust multilingual safety protocols are crucial for the responsible worldwide deployment of AI (Johnson et al., 2023; Castillo et al., 2024; Kim \& Park, 2024).

% \noindent A key obstacle to achieving such multilingual safety lies in tokenization. Most current LLMs rely on English-centric subword vocabularies (Touvron et al., 2023), which can fragment words incorrectly in languages with complex morphologies (e.g., Turkish, Finnish) or ambiguous word boundaries (e.g., Chinese, Thai). This improper segmentation impairs the detection of harmful content and distorts culturally specific idioms (Hartvigsen et al., 2022; Welbl et al., 2021; Kim \& Park, 2024). While translating user queries into English before applying moderation filters has been proposed, this strategy often discards essential context—particularly in under-resourced languages (Bang et al., 2023).

% \noindent In addition, fine-tuning alone cannot fully resolve the structural biases that stem from an LLM’s architecture or vocabulary. Even substantial fine-tuning efforts fall short of correcting an English-dominant subword system, as seen in Llama 2 7B (Touvron et al., 2023), especially for languages featuring multiple scripts or intricate morphological structures (Johnson et al., 2023). Collecting large multilingual datasets for each round of fine-tuning is both costly and time-intensive (Castillo et al., 2024), meaning that smaller-scale modifications yield only marginal improvements. By contrast, larger-parameter models often demonstrate improved multilingual capabilities, a benefit arising from their higher-capacity internal representations. This expanded capacity allows them to encode diverse linguistic features and handle more complex patterns across multiple languages (Lai et al., 2023; Zhang et al., 2023a).

% \noindent To build on these insights, we focus on recently introduced models such as Llama 3.1 8B, which incorporate enhanced multilingual pretraining but continue to struggle with filtering prohibited or harmful content (Touvron et al., 2023; Bang et al., 2023; Wang et al., 2023). Addressing these gaps, we present a hand-curated dataset of prohibited categories—derived from Meta’s content guidelines and annotated by experts to capture nuanced cultural and idiomatic expressions more accurately than automated translations (Hartvigsen et al., 2022; Welbl et al., 2021). Using this dataset, we introduce \texttt{Soteria}, a novel technique for safe multilingual generation that locates internal “functional neurons” specific to each language and directs them away from harmful outputs by altering only $\sim$0.001\% of model parameters, thereby efficiently suppressing toxic or policy-violating responses without diminishing the model’s overall performance. This selective parameter adjustment substantially mitigates the risk of harmful content generation, demonstrating that the precise calibration of multilingual fluency and safety can yield LLMs that are both culturally adaptive and ethically grounded.
% Our contributions are summarized as follows:

% Large language models (LLMs) such as GPT-4o~\cite{openai2024gpt4technicalreport}, Claude~\cite{Claude3S}, and Llama~\cite{touvron2023llamaopenefficientfoundation} have reshaped the AI landscape by achieving remarkable outcomes across diverse tasks from text generation to question answering, largely due to extensive pre-training on varied corpora~\cite{zhou2023controlledtextgenerationnatural, kamalloo-etal-2023-evaluating, nguyen-etal-2024-democratizing}. However, earlier works often tested these models’ multilingual abilities by translating queries into English~\cite{zhao2024largelanguagemodelshandle}, which poses a significant challenge for truly global coverage. Although new LLMs adopt advanced tokenizers to better handle non-English inputs, most safety measures such as red teaming and content filtering remain Anglocentric~\cite{zhang2023donttrustchatgptquestion, lai-etal-2024-llms, wang-etal-2024-languages,https://doi.org/10.48550/arxiv.2406.10602}. Consequently, non-English scenarios are comparatively under-protected, and smaller-parameter models (e.g., 8B, 7B) often deployed in low-resource contexts face heightened risks of harmful or culturally insensitive outputs~\cite{banerjee2025navigatingculturalkaleidoscopehitchhikers} when aligned mostly with English~\cite{banerjee2024safeinfercontextadaptivedecoding, hazra-etal-2024-safety}. Robust multilingual safety protocols are therefore indispensable for responsible AI deployment worldwide~\cite{wang-etal-2024-languages, lu2024learnunlearnmultilingualllms}.\\
LLMs such as GPT-4o~\cite{openai2024gpt4technicalreport}, Claude~\cite{Claude3S}, and Llama~\cite{touvron2023llamaopenefficientfoundation} have revolutionized the AI landscape by delivering impressive performance across tasks ranging from text generation to question answering. These breakthroughs stem from extensive pre-training on large, diverse corpora~\cite{zhou2023controlledtextgenerationnatural, kamalloo-etal-2023-evaluating, nguyen-etal-2024-democratizing}. Yet, much of the early research on LLMs’ multilingual capabilities relied on translating English queries into non-English, a strategy that obscures genuine multilingual performance~\cite{zhao2024largelanguagemodelshandle}. Although newer LLMs feature advanced tokenizers that handle non-English inputs more effectively, key safety measures, including red teaming and content filtering remain predominantly English centric~\cite{zhang2023donttrustchatgptquestion,https://doi.org/10.48550/arxiv.2406.10602}.\\
As a result, non-English use cases are comparatively under-protected, and especially smaller-parameter models (e.g., 8B or 7B) often implemented in low-resource settings are at greater risk of generating harmful or culturally insensitive outputs~\cite{banerjee2025navigatingculturalkaleidoscopehitchhikers}. Moreover, prior work on safety mechanisms has focused mainly on English, overlooking the nuances and needs of broader linguistic communities~\cite{banerjee2024safeinfercontextadaptivedecoding, hazra-etal-2024-safety}. In this context, it becomes clear that robust, multilingual safety protocols are essential to protect users and maintain linguistic sensitivity across the globe~\cite{wang-etal-2024-languages, lu2024learnunlearnmultilingualllms}.\\
% A major barrier to robust multilingual safety stems from tokenization~\cite{petrov2023language, hong-etal-2024-accelerating}. Though some newer LLMs incorporate enhanced multilingual tokenizers\footnote{https://huggingface.co/blog/llama31}, most still rely on English-centric subword vocabularies (e.g., Byte-Pair Encoding or SentencePiece) predominantly trained on English corpora~\cite{touvron2023llama2openfoundation, jiang2023mistral7b}. %This approach often over-segments languages with intricate morphology (e.g., Turkish, Finnish)~\cite{ataman-federico-2018-evaluation, bojar-etal-2018-findings} or ambiguous word boundaries~\cite{agrawal-etal-2024-translation}, inflating token counts and distorting key semantic or syntactic features. Such segmentation mismatches can undermine harmful content detection and distort culturally specific idioms~\cite{cevik2022tokenclassificationdisambiguatingmedical, wang-2019-revisiting}. 
% Next, translating user queries into English before applying moderation filters a prevalent “bridging strategy” carries the risk of translation errors, which can lead to incorrect content classification~\cite{bang-etal-2023-multitask}.
% % \begin{figure}[!ht]
% % \centering
% % \scriptsize
% % \includegraphics[width=0.48\textwidth]{latex/images/Untitled.pdf}
% % \caption{}
% % \label{fig:mainfig}
% % \end{figure}
% \noindent Further complicating matters, fine-tuning alone cannot fully resolve the systemic constraints stemming from an LLM’s architecture or English-dominant tokenization. Even extensive fine-tuning efforts, often prove insufficient for languages with multiple scripts or complex morphology. In addition, building large-scale multilingual datasets for every fine-tuning cycle is prohibitively expensive and time-intensive~\cite{yu2022countingdatasetssurveymultilingual}, limiting potential gains under resource constraints. Although larger-parameter models generally exhibit more robust multilingual proficiencies, this tactic may be infeasible in low-resource or real-time contexts~\cite{nguyen2024democratizingllmslowresourcelanguages, chelombitko2024qtokcomprehensiveframeworkevaluating}.
A major obstacle to robust multilingual safety lies in the limitations of early tokenizers~\cite{petrov2023language, hong-etal-2024-accelerating}, which were not designed properly to capture the rich morphological and script diversity in global languages~\cite{ali-etal-2024-tokenizer}. As a result, LLMs built on these tokenizers struggle to generate linguistically relevant and accurate outputs in non-English settings, undermining the effectiveness of any safety measures. While newer models incorporate more sophisticated multilingual tokenizers\footnote{\url{https://huggingface.co/blog/llama31}}, prior efforts largely treated multilingual support as an afterthought added later via fine-tuning rather than integrated as a core capability~\cite{richburg2024multilinguallargelanguagemodels}. This approach often relies on ``bridging strategies,'' such as translating queries into English before applying moderation filters, a practice that can distort content classification~\cite{bang-etal-2023-multitask,  lai-etal-2024-llms}. Even extensive fine-tuning typically fails to address deeper, English-dominant architectural constraints, especially for languages with multiple scripts or highly complex morphology. Moreover, creating large-scale multilingual datasets for each fine-tuning cycle is prohibitively expensive and time-intensive~\cite{yu2022countingdatasetssurveymultilingual}. Although scaling up to larger-parameter models can bolster multilingual proficiency, such approaches may be infeasible in low-resource or time-sensitive contexts~\cite{nguyen2024democratizingllmslowresourcelanguages, chelombitko2024qtokcomprehensiveframeworkevaluating}. 

\noindent Building on these insights, we focus on recently introduced models, which offer improved multilingual capability. We curate a specialized dataset \textit{\underline{XThreatBench}} of prohibited categories, derived from Meta’s content guidelines to identify safety concerns more accurately. Using this dataset, we propose \textsc{Soteria}, a novel strategy for safe multilingual generation that locates language-specific ``\textit{functional heads}'' and selectively tunes only about $\sim$3\% of the model parameters. By redirecting these heads away from harmful outputs, \textsc{Soteria} effectively suppresses toxic or policy-violating responses without degrading overall model performance. Through this precise calibration of multilingual fluency and safety, we demonstrate that LLMs can be both linguistically adaptive and ethically grounded. Our contributions are summarized as follows:
\begin{stylishframe}
\begin{compactitem}

\item To the best of our knowledge, we are the first to introduce a multilingual parameter-efficient safety mechanism -- \textsc{Soteria} -- that modifies only about $\sim$3\%
 of the model’s language-specific “functional heads,” effectively reducing harmful outputs without compromising overall performance.

\item We introduce \textit{\underline{XThreatBench}}, a multilingual dataset covering harm categories derived from Meta’s content guidelines, closing critical gaps in existing safety benchmarks.

\item Our experiments encompass a broad linguistic spectrum from high- to low-resource to demonstrate that these safety enhancements are not confined to English or high-resource settings.
\end{compactitem}
\end{stylishframe}
\section{Related work}

\textbf{Mechanistic interpretability}: This section explores how internal LLM components (neurons, layers, attention heads) shape model behaviors \cite{geiger2021causal, stolfo2023a, gurnee2023finding}. Early work identified key neurons \cite{zou2023transparency, chen2024findingsafetyneuronslarge}, but recent studies underscore attention heads’ critical roles in various language tasks \cite{vig2019multiscalevisualizationattentiontransformer, wu2025retrieval}. Ablation approaches reveal certain heads are crucial for syntactic parsing and factual reasoning \cite{NEURIPS2019_2c601ad9, meng2023locatingeditingfactualassociations}, yet their safety implications remain underexplored \cite{gould2023successorheadsrecurringinterpretable, wang2023interpretability}. This gap highlights the need for fine-grained analysis to enhance transparency and safety.\\
%explores how internal components of LLMs, such as neurons, layers, and attention heads, contribute to model behaviors~\cite{geiger2021causal, stolfo2023a, gurnee2023finding}. While early research focused on identifying key neurons responsible for model behavior~\cite{zou2023transparency, chen2024findingsafetyneuronslarge}, recent studies reveal that attention heads play crucial roles in various language tasks~\cite{vig2019multiscalevisualizationattentiontransformer, wu2025retrieval}. Ablation techniques, commonly used to identify critical parameters, have shown that specific attention heads are essential for syntactic parsing and factual reasoning~\cite{NEURIPS2019_2c601ad9, meng2023locatingeditingfactualassociations}. However, the safety impact of attention heads remains underexplored compared to their contributions to other capabilities~\cite{gould2023successorheadsrecurringinterpretable, wang2023interpretability}, highlighting the need for fine-grained analysis to enhance model transparency and safety.\\
\textbf{Safety alignment}: Efforts to ensure LLM safety focus on mitigating adversarial prompts \cite{xie2018mitigating}, designing robust filtering \cite{xiao2024ritfisrobustinputtesting}, and maintaining dynamic oversight \cite{kenton2024scalableoversightweakllms, wang-etal-2024-languages}. Early studies \cite{YAO2024100211} expose key vulnerabilities and propose ethical risk frameworks. Subsequent work \cite{sachdeva2025turninglogicprobing, banerjee2024unethicalinstructioncentricresponsesllms} reveals how subtle prompt manipulations can evade safeguards, prompting research into attack strategies \cite{10.5555/3692070.3694246} and defenses like RAIN \cite{li2023rainlanguagemodelsalign}. Others emphasize dynamic monitoring \cite{bhardwaj2024languagemodelshomersimpson} and adaptive safety mechanisms, including safety arithmetic \cite{hazra2024safetyarithmeticframeworktesttime} for test-time alignment and SafeInfer \cite{banerjee2024safeinfercontextadaptivedecoding}, SafeDecoding~\cite{xu2024safedecodingdefendingjailbreakattacks} for decoding-time alignment.
% Efforts to ensure the safety of LLMs have increasingly focused on mitigating adversarial prompts~\cite{xie2018mitigating}, designing robust filtering systems~\cite{xiao2024ritfisrobustinputtesting}, and maintaining dynamic oversight~\cite{kenton2024scalableoversightweakllms, wang-etal-2024-languages}. Initial explorations~\cite{YAO2024100211} highlight key vulnerabilities and propose ethical frameworks for risk assessment in AI systems. More recent findings~\cite{sachdeva2025turninglogicprobing, banerjee2024unethicalinstructioncentricresponsesllms} illustrate how subtle prompt manipulations can bypass existing safety measures, prompting researchers to investigate both attack strategies~\cite{10.5555/3692070.3694246} and robust defensive solutions such as RAIN~\cite{li2023rainlanguagemodelsalign}. Other studies emphasize the importance of dynamic monitoring and adaptive safety mechanisms~\cite{bhardwaj2024languagemodelshomersimpson}, with novel approaches like \textit{safety arithmetic}~\cite{hazra2024safetyarithmeticframeworktesttime} for test-time alignment and SafeInfer~\cite{banerjee2024safeinfercontextadaptivedecoding} for decoding-time alignment further advancing the field. Building upon these efforts~\cite{xu2024safedecodingdefendingjailbreakattacks} have proposed the SafeDecoding method which is a safety-aware decoding strategy for LLMs, to defend against jailbreak attacks.
\vspace{-0.1cm}
\section{Methodology}
In this section, we present our methodology for identifying and mitigating harmful behavior in LLMs. We first introduce the underlying components of autoregressive LLMs (Section~\ref{sec:prelim}), focusing on their transformer decoder layers and attention mechanisms. We then describe our framework (Section~\ref{sec:framework}) for identifying important attention heads that are crucial for task-solving and language-specific processing, followed by the procedure to remove harm-inducing directions from these heads.
\subsection{Preliminaries}
\label{sec:prelim}
We define an autoregressive LLM as $\mathcal{M}$, which comprises multiple transformer decoder layers, denoted by $\mathcal{L}$.
Each transformer decoder layer consists of two fundamental modules -- multi-head attention ($MHA$) and feed-forward network ($FFN$). 
The outputs of $MHA$ and $FFN$ modules in layer $l \in \mathcal{L}$ are denoted by $atn^l$ and $mlp^l$, respectively.
The hidden state of a transformer decoder layer $l$ is denoted by $ht_l$. 
The hidden state $ht_l$ is computed as shown in Equation~\ref{eq:transbasic} where $ht_{l-1}$ represents the hidden state from the previous layer $l-1$.
\begin{figure}[h]
\centering
\scriptsize
\includegraphics[width=0.48\textwidth]{images/mulling.pdf}
\caption{\footnotesize Schematic diagram of the \textsc{Soteria}.}
\label{fig:mainfig}
\vspace{-0.3cm}
\end{figure}
\begin{equation}
\vspace{-0.2cm}
\label{eq:transbasic}
    ht_{l} = ht_{l-1} + mlp^{l} + atn^{l}
\end{equation}

\noindent Mathematically, the output $atn^{l}$ of $MHA$ module is further obtained using Equation~\ref{eq:mulheadComp} in which each attention head is represented as $h_i^l$ where $i \in \mathcal{I}$ denotes the $i^{th}$ attention head and $|\mathcal{I}|$ denotes the number of heads in each layer $l$.  $W^O_l \in \mathbb{R}^{|\mathcal{I}|\cdot d_k \times d_m}$ projects ($O$ - Projection) the concatenated heads to the model dimension whereby the head $h_i^l$ has a dimension of $d_k$ and the hidden dimension of the model is $d_m$.
Each head $h_i^l$ is derived as given in Equation~\ref{eq:headcalc} in which $W_i^Q$, $W_i^K$ and $W_i^V$ denote the learned weight matrices for the query $Q$, key $K$, and values $V$ of the $i^{th}$ head. 

\begin{equation}
\vspace{-0.2cm}
\label{eq:mulheadComp}
atn_l = \text{concat}(h_1^l, \dots,h_{\mathcal{I}}^l)\cdot W^O_l
\end{equation}
\vspace{-0.3cm}
\begin{equation}
\label{eq:headcalc}
h_i^l = \text{attention}(Q W_i^Q, K W_i^K, V W_i^V)
\end{equation}

\noindent In this work, similar to~\cite{todd2024functionvectors}, we adopt the attention definition proposed by~\cite{elhage2021mathematical} rather than the one introduced in~\cite{vaswani2017}. The study in ~\cite{elhage2021mathematical} highlights that the formulation in ~\cite{vaswani2017} can be interpreted as decomposing weight matrix $W^O_{l}$ into a block form $[W_{l1}^{O} \; W_{l2}^{O} \; \dots \; W_{l\mathcal{I}}^{O}]$, allowing $h_{i}^l$ to be directly projected into residual stream space. Each block $W_{li}^O \in \mathbb{R}^{d_k \times d_m}$ determines how information from $h_i^l$ is transformed into the final model dimension. We use the output $atn_{i}^l$ corresponding to $i^{th}$ head as written in Equation~\ref{eq:attnoutheadwise}. %\am{In order to keep parity with $h_{i}^l$ I have changed $atn_{l}^i$ to $atn_{i}^l$. Please cross-check and also update Figure 1.}\rh{fixed. please verify}%\am{The symbols are all jumbled up. How are $atn_l$ in eq 1 and eq 2 related; are they same (you earlier uses different symbols -- hence asking)? Next $h_{i}^{l}$ is undefined. Also the connection between $atn_{i}^l$ and $atn_{l}$ is not clear. Finally what is the difference between $_{l}^i$ and $_{i}^{l}$?}\textcolor{blue}{modified}

\begin{equation}
\vspace{-0.2cm}
\label{eq:attnoutheadwise}
    atn_{i}^l = h_{i}^{l} \cdot W_{li}^{O} \in \mathbb{R}^{d_m}
\end{equation}
% \[
% W_o =
% \begin{bmatrix}
% W_o^{(1)} \\ W_o^{(2)} \\ \vdots \\ W_o^{(h)}
% \end{bmatrix}
% \]
% Each block $W_o^{(i)} \in \mathbb{R}^{d_k \times d_m}$ maps the output of the corresponding attention head to the model’s dimension, determining the final contribution of $h_i$ as follows:
% \[
% \text{head}_i W_o^{(i)}
% \]
%If a specific head is removed or given more weight, its corresponding submatrix in \( W_o \) determines the projection effect.
% \begin{equation}
% \text{Attn}(Q, K, V) = \text{softmax}\left(\frac{Q K^\top}{\sqrt{d_k}}\right) V
% \end{equation}
% $h^{l_{i-1}}$ is the hidden state of the $l_{i-1}$ layer and $H^{l_{i-1}}$ is the hidden states in the previous layer of the whole sequence.
% $a^{l_i}_j$ is the projection of output of $j_{th}$ attention head in ~\text{mul-attn$^i$} into the hidden state of layer $l_i$. So, the equation~\ref{eq:transbasic} can be written as in Equation~\ref{eq:transoutput}.
% \begin{equation}
% \label{eq:transoutput}
%     h^{l_i} = h^{l_{i-1}} + mlp^{l_i} +  \sum_{j \leq J} a^{l_i}_j
% \end{equation}
% In this work, we follow ~\cite{elhage2021mathematical} definition of attention than the definition given in  ~\cite{vaswani2017}. Paper~\cite{elhage2021mathematical} observe that the formulation given in paper~\cite{vaswani2017} is same as dividing the weight matrix $W^O_{l_{i}}$ into a block form $[W_{\ell1}^{O} \; W_{\ell2}^{O} \; \dots \; W_{\ell J}^{O}]$ and projecting the $head_{i}$ into the residual stream space directly. In our formulation of $a^{l_i}_j$, we use this view. We basically use the output $a^{l_i}_j$ as the notion given in equation~\ref{eq:attnoutheadwise}.
% \begin{equation}
% \label{eq:attnoutheadwise}
%     a^{l_i}_j = \text{head}_{l_i}^j W_{l_ij}^{O} \in \mathbb{R}^{d}
% \end{equation}
% We mainly focus on the attention heads since these are the major components in order to move information between different token positions.\\

\noindent In this study, we consider a set of languages $\ell \in \mathscr{L}$. To identify important attention heads for each language $\ell$, we define a set of tasks, denoted by $t \in \mathcal{T}$, specific to each language. 
To mitigate harmful direction, we fine-tune a language model with the same backbone as $\mathcal{M}$ using a dataset $\mathcal{D}_H$ consisting of harmful instances resulting in a harmful model $\mathcal{M}_H$. The dataset $\mathcal{D}_H$ consists of a collection of harmful questions paired with their corresponding harmful answers.

\subsection{Our framework}
\label{sec:framework}
In our framework, we first identify important attention heads (i.e., $atn_i^l$ for the $i^{th}$ head) and subsequently remove the harm direction from the target model. \\
\noindent \textbf{Identifying important attention heads}: Our objective is to identify attention heads that contribute to both task-solving and language-specific processing. To analyze the role of attention heads in task completion across languages, we translate all tasks into a specific language $\ell$. Unlike prior approaches~\cite{tang-etal-2024-language}, we emphasize task relevance to ensure that the identified heads capture task-specific linguistic information. 
% This is crucial, as the attention heads responsible for solving a task in a particular language may also play a significant role in that language's broader contextual understanding.
Following~\cite{todd2024functionvectors}, each task $t$ comprises a dataset containing a set of prompts, denoted by $\mathscr{P}^t$. A prompt $p_k^t \in \mathscr{P}^t$ is represented as $p_k^t = \left[ (q_{k_1}, r_{k_1}), \cdots, (q_{k_K}, r_{k_K}), q_{k_Q} \right]$, where the target answer $r_{k_Q}$ for question $q_{k_Q}$ is not included in the prompt. Using this prompt $p_k^t$, the next-token prediction function $\mathcal{M}(p_k^t)$ ranks the correct answer highest, allowing us to assess the contribution of specific attention heads to both task performance and language processing.\\
We provide the prompt $p_k^t$ to language model $\mathcal{L}$ so that it can predict the correct answer for the question $q_{k_Q}$. 
Our objective is to identify model components with a causal role in multilingual processing during the prediction of $r_{k_Q}$. For each attention head $atn_i^{l}$ and task dataset $\mathscr{P^t}$, we compute mean condition activations $\hat{atn_{i}^{l}}_t$ in Equation~\ref{eq:meanact}. In Equation~\ref{eq:meanact}, $atn_{i}^l(p_k^t)$ is the attention output of prompt $p_k^t$ for $i^{th}$ attention head.

\begin{figure}[t]
\centering
\scriptsize
\includegraphics[width=0.48\textwidth]{images/heads.pdf}
\caption{\footnotesize Identified top 20 heads for Llama 3.1 for Spanish and Bengali.}
\label{fig:heads}
\vspace{-0.3cm}
\end{figure}

\begin{equation}
\vspace{-0.2cm}
\label{eq:meanact}
    \hat{atn_{i}^{l}}_t = \frac{1}{|\mathscr{P}_t|} \sum_{p_k^t \in \mathscr{P}_t} atn_{i}^l(p_k^t)
\end{equation}

\noindent In parallel, we have a corrupted prompt $\hat{p}_{i}^k$ where the responses are shuffled $\hat{p}_i^k = \left[ (q_{k_1}, \hat{r}_{k_1}), \cdots, (q_{k_K}, \hat{r}_{k_K}), q_{k_Q} \right]$. 
Next, we pass the corrupted prompt $\hat{p}_{k}^t$ through the language model $\mathcal{L}$ and replace a specific attention head activation $atn_{i}^l(\hat{p}_k^t)$ with the actual mean task conditioned activation $\hat{atn_{i}^{l}}_t$. %\am{Undefined. $l$ and $\ell$ are mixed up.}
We attempt to understand how much the actual task conditioned activation can help to predict the correct answer. Further we measure the causal indirect effect (CIE) toward recovering the correct answer $r_{k_Q}$ as shown in Equation~\ref{eq:cie}.
% \begin{equation}
% \text{CIE}(atn_{l}^i \mid \hat{p}_i^t) = \mathcal{L}\left(\hat{p}_i^t \mid atn_{l}^i := \hat{atn}_{lt}^i\right)[r_{i_Q}] - \mathcal(\hat{p}_i^t)[r_{i_Q}].
% \end{equation}
\begin{equation}
\label{eq:cie}
\begin{aligned}
\text{CIE}(atn_{i}^l \mid \hat{p}_k^t) &= 
\mathcal{M}\left(\hat{p}_k^t \mid atn_{i}^l := \hat{atn}_{it}^l\right)[r_{k_Q}] \\
&\quad - \mathcal{M}(\hat{p}_k^t)[r_{k_Q}]
\end{aligned}
\end{equation}

%\am{$f$ is undefined, $y$ is undefined.}~\rh{modified the equation 6}
% \begin{equation}
% \text{AIE}(a_{\ell j}) =
% \frac{1}{|\mathcal{T}|} \sum_{t \in \mathcal{T}} \frac{1}{|\tilde{P}_t|}
% \sum_{\tilde{p}_i^t \in \tilde{P}_t} \text{CIE}(a_{\ell j} \mid \tilde{p}_i^t).
% \end{equation}
\noindent Further, we obtain the average indirect effect \text{AIE} of an attention $atn_{i}^l$ ($AIE(atn_{i}^l)$) by averaging the causal indirect effect across all the tasks and their corrupted prompts.
To identify the set of attention heads with the strongest causal effects, we iterate the same process for all the attention heads in the language model $\mathcal{L}$ (see Figure~\ref{fig:heads}). We also repeat the whole process for every language $\ell \in \mathscr{L}$. %\am{This section is a total mess. It is impossible to understand the workings of the algorithm for the mixup of symbols. I would also strongly suggest to draw some hypothetical figure to explain the idea. Also the symbols in Figure 1 do not match perfectly with the notations in text.}\rh{modified}

\noindent \textbf{Removal of harm direction}: According to Equation~\ref{eq:attnoutheadwise}, each block $W_{li}^O$ determines the transformation of information from $h_i^l$ to the output $atn^l_i$. Given an important attention $atn^l_i$, we consider the associated block $W_{li}^O$ for harm direction removal. We focus solely on the $O$-projection weight, avoiding unnecessary changes to other layer weights, which could compromise the model's broader capabilities. Following \cite{hazra-etal-2024-safety} we compute the harm vector \textcolor{red}{$H_v$} by taking the element-wise difference between the $\mathcal{M}_{H}$ and $\mathcal{M}$. 
Further, we keep only those parameters of \textcolor{red}{$H_v$} as per selected blocks ($W_{li}^O$ for $i^{th}$ head) of the $W^O_l$ and make the other parameters zero. The harm vector with retained parameters is denoted by $\hat{H}_v$. The safe model \textcolor{ForestGreen}{$\hat{\mathcal{M}}$} is expressed as follows.
% Once we obtain the important attention heads $a^{l_i}_j$ which is computed by (Equation 6). Every block of $W^{O}_{l_i}$ is used to project the $head_j$ and obtain the $a^{l_i}_{j}$. So we target each block which is associated with $head_j$ to modify in order to remove the harm direction. We consider the same backbone model as $\mathcal{L}$ and fine-tune it with the dataset $D_{H}$. Dataset $D_{H}$ consists of harmful questions and their harmful responses in English language. The fine-tuned model is denoted by $\mathcal{L}_{H}$. 
\begin{equation}
\vspace{-0.2cm}
    \boxed{\textcolor{ForestGreen}{\hat{\mathcal{M}}} = \mathcal{M} - \lambda * \textcolor{red}{\hat{H}_v}}
\end{equation}
where $\lambda$ is a hyperparameter.
\section{Language and dataset}

\begin{figure*}[t]
\centering
\scriptsize
\includegraphics[width=0.80\textwidth]{images/multijail.pdf}
\caption{\footnotesize Results on the \textit{MultiJail} dataset. Red bars represent the base model's unsafe outputs, while blue bars denote outputs from the safe model \textsc{Soteria}. Languages are categorized by resource availability: H (high resource), M (mid resource), and L (low resource). The substantial reduction in unsafe content across high-, mid-, and low-resource languages highlights the effectiveness of the \textsc{Soteria} compared to the base model. The ASR values presented here range from 0 to 1. To express them as percentages, simply multiply by 100. Lower is better.}
\label{fig:multijail}
\vspace{-0.4cm}
\end{figure*}

\noindent\textbf{Languages}: Following~\cite{deng2024multilingualjailbreakchallengeslarge}, we consider twelve languages across \textit{high-}, \textit{medium-} and \text{low-resource} categories. From the high-resource language category, we consider \textcolor{RoyalBlue}{English (\texttt{En}), Chinese (\texttt{Zh}), German (\texttt{De}), French (\texttt{Fr})}, and \textcolor{RoyalBlue}{Spanish (\texttt{Es})}. For the medium-resource language category,  \textcolor{RoyalBlue}{Arabic (\texttt{Ar}), Thai (\texttt{Th}), Bulgarian (Bg)}, and \textcolor{RoyalBlue}{Hindi (\texttt{Hi})}. For low-resource language category, we include \textcolor{RoyalBlue}{Tamil (\texttt{ta}), Bengali (\texttt{bn})}, and \textcolor{RoyalBlue}{Telugu (\texttt{te})}.

%  HRL(>1%) Russian (ru), German (de), Chinese (zh), Japanese (ja), French (fr),
%  Spanish (es), Italian (it), Dutch (nl), Portuguese (pt), Vietnamese (vi)
%  MRL(>0.1%) Indonesian (id), Swedish (sv), Arabic (ar), Farsi (fa), Korean (ko),
%  Greek (el), Thai (th), Ukrainian (uk), Bulgarian (bg), Hindi (hi)
%  LRL(<0.1%) Bengali(bn), Tamil (ta), Urdu (ur), Malayalam (ml), Marathi (mr), Tel
% ugu (te), Gujarati (gu), Burmese (my), Javanese (jv), Swahili (sw)

\noindent \textbf{Datasets}: We assess \textsc{Soteria} using two established datasets, \textit{MultiJail}~\cite{deng2024multilingual} and \textit{XSafety}~\cite{wang-etal-2024-languages}. In addition, we introduce a new multilingual safety dataset \textit{XThreatBench}, constructed based on the policy violations outlined by Meta~\cite{qi2023finetuning}. A detailed description of each dataset follows. We include the dataset details of \textit{XSafety} and the corresponding experimental results in the Appendix~\ref{appn:xsafetyexp} due to space constraints.\\ 
%Why we propose that dataset?
%Languages --> 	English (En)		Chinese (Zh)				German ()		French ()		Spanish		
% Arabic (ar), thai, Bulgarian, hindi,
% tamil, bengali, telegu, 
\noindent \underline{\textit{MultiJail}}: This dataset is the first multilingual translated jailbreak benchmark designed to assess the safety vulnerabilities of large language models across multiple languages. It contains 3150 manually translated queries across 10 languages, covering high-resource (\textit{English, Chinese, Italian, Vietnamese}), medium-resource (\textit{Arabic, Korean, Thai}), and low-resource (\textit{Bengali, Swahili, Javanese}) languages. Built from harmful queries in the GPT-4 report~\cite{openai2024gpt4technicalreport} and Anthropic’s red-teaming dataset~\cite{ganguli2022redteaminglanguagemodels}, it explores unintentional and intentional jailbreaks, where translation itself serves as a jailbreak method. For our experiments, we use \textit{google translate}\footnote{\url{https://translate.google.com}} to translate English queries into other languages when they are not present in the dataset.\\
\noindent \underline{\textit{XThreatBench}}: We propose a multilingual safety benchmark on general harm designed to rigorously evaluate LLM vulnerabilities across \textbf{10} high-risk categories, including \textit{\textcolor{Maroon}{\textbf{sexual content}}, \textcolor{Maroon}{\textbf{child exploitation}}, \textcolor{Maroon}{\textbf{economic fraud}}, \textcolor{Maroon}{\textbf{hate speech}}, \textcolor{Maroon}{\textbf{illegal activities}}, \textcolor{Maroon}{\textbf{cyber threats}}, \textcolor{Maroon}{\textbf{physical harm}}, \textcolor{Maroon}{\textbf{political manipulation}}, \textcolor{Maroon}{\textbf{privacy violations}},} and \textit{\textcolor{Maroon}{\textbf{deception}}}. \textit{XThreatBench} features \textbf{3,000} adversarial prompts across \textbf{12} languages ensuring native linguistic authenticity with generic harm. Each category contains \textbf{25} instances, systematically crafted to test LLM safety mechanisms against general attack scenarios, evasive jailbreak tactics, and multilingual exploits. To maximize adversarial quality, we implemented a three-stage verification process, combining partial human intervention, \textit{GPT-4 based filtering}, and \textit{Perspective API based toxicity scoring} (retaining only queries with a toxicity score of 0.75+). Unlike existing benchmarks, \textit{XThreatBench} adheres to safety policies while offering a robust, multilingual evaluation framework for assessing LLM safety in high-risk, adversarial environments.
%Unlike existing benchmark adhereing more on safety policies, \textit{XThreatBench} provides a robust, multilingual evaluation framework for assessing LLM safety in high-risk, adversarial environments.

\section{Experimental setup}
In this section, we first introduce the language models used in our evaluation, selected for their multilingual capabilities and diverse linguistic distributions. Next, we define our evaluation metric, \textit{attack success rate} (ASR), to quantify safety violations. Subsequently, we describe the jailbreak attack baselines. To benchmark our proposed safety mechanism, we compare it against existing English language-centric safety alignment approaches. 
%We show that \textsc{Soteria} ensures language inclusivity by enabling harm mitigation across multiple languages through targeted attention head selection. 

%\textcolor{red}{Need to add tasks using which we detect language specific tasks. Need to make a section for this} ~\rh{Added}

\subsection{Language models}
\begin{figure*}[t]
\centering
\scriptsize
\includegraphics[width=0.80\textwidth]{images/xharmbench.pdf}
\caption{\footnotesize Results on the \textit{XThreatBench} dataset. Red bars represent the base model's unsafe outputs, while blue bars denote outputs from the safe model \textsc{Soteria}. Languages are categorized by resource availability: H (high-resource), M (mid-resource), and L (low-resource). The substantial reduction in unsafe content across high-, mid-, and low-resource languages highlights the effectiveness of \textsc{Soteria} compared to the base model. The ASR values presented here range from 0 to 1. To express them as percentages, simply multiply by 100. Lower is better.}
\label{fig:xthreatbench}
\vspace{-0.3cm}
\end{figure*}
We use four open-weight language models to evaluate our proposed safety mechanism. We consider instruction-tuned versions of \texttt{llama3.1-8b-instruct}~\cite{grattafiori2024llama3herdmodels}, \texttt{Qwen2-7B-Instruct}~\cite{yang2024qwen2technicalreport}, \texttt{Mistral-7B-Instruct-v0.3}~\cite{jiang2023mistral7b}, \texttt{Phi-3.5-mini-instruct}~\cite{abdin2024phi3technicalreporthighly}. We select these models because they are widely used instruction-tuned LLMs with diverse multilingual capabilities. They perform well in high-resource languages such as English and Chinese, while their support for medium- and low-resource languages varies. This selection allows us to evaluate safety mechanisms across different linguistic distributions and understand their effectiveness in multilingual settings.
\vspace{-0.2cm}
\subsection{Language specific tasks used}
Following the tasks outlined in \cite{todd2024functionvectors}, we use five datasets: (1) \textit{agnews}, a text classification dataset of news headlines and early article sentences labeled as business, science/technology, sports, or world; (2) \textit{antonym}, where each input word requires generating its opposite; (3) \textit{country-capital}, comprising 197 country-capital pairs and requiring the capital city given a country; (4) \textit{country-currency}, listing countries alongside their currencies; and (5) \textit{sentiment}, which contains 1167 movie review sentences labeled as either \textit{positive} or \textit{negative}. Further, we translate these task datasets into specific languages and identify the attention heads.

% Following different tasks from ~\cite{todd2024functionvectors}, we utilize five datasets -- \textit{agnews}, \textit{antonym}, \textit{country-capital}, \textit{country-currency} and \textit{sentiment}. In case of \textit{agnews}, A text classification dataset where inputs are news headlines and the first few sentences of the article, and the labels are the category of the news article. Labels include Business, Science/Technology, Sports, and World~\cite{}. In \textit{Antonym}, Given an input word, generate the word with opposite meaning. In \textit{Country-Capital}, Given a country name, generate the capital city. This dataset contains 197 country-capital city pairs. \textit{Country-Currency} is the  a list of countries and their currencies.
% We utilize ~\textit{sentiment} dataset having movie review sentences and binary label either `positive' or `negative'. This dataset is having 1167 instances.
\subsection{Evaluation metrics}

Following previous studies~\cite{chao2024jailbreakingblackboxlarge, qi2023finetuningalignedlanguagemodels}, we assess the safety standards of language models using the attack success rate (ASR). ASR measures the proportion of harmful responses generated by the model out of the total number of harmful queries and is defined as follows.

{\scriptsize\[
\text{ASR} = \frac{\text{\# responses not aligned with \textit{Safety}}}{\text{\# input queries to LLM}}
\] }
We classify a response as harmful or unethical if it violates the usage policies of OpenAI\footnote{\url{https://openai.com/policies/usage-policies}} and Meta\footnote{\url{https://ai.meta.com/llama/use-policy}}.
\subsubsection{GPT-4o as a safety evaluator}
To reliably and efficiently assess a model’s safety performance, we employ GPT-4o as the annotator, leveraging its strong alignment with human judgments on harmful responses~\cite{qi2023finetuningalignedlanguagemodels, banerjee2024safeinfercontextadaptivedecoding, hazra-etal-2024-safety}. In particular, we adopt the evaluation prompt\footnote{\textit{Given
the following text, analyze and assess its ethical implications.
Determine whether the content adheres to ethical standards
or if there are elements that raise ethical concerns.}} proposed by~\cite{banerjee2024safeinfercontextadaptivedecoding}. Cases in which GPT-4o declines to provide annotations due to content filtering are excluded from our calculations. A lower ASR score indicates a safer model.
\subsection{Baselines}
We compare our multilingual safety mechanism with the following safety mechanism techniques, which involve language model parameters. The descriptions of these baselines are as follows.\\
\noindent \textbf{(1) Safety arithmetic}~\cite{hazra-etal-2024-safety}: The safety arithmetic framework improves model safety across the base, fine-tuned, and edited models where safety risks emerge due to fine-tuning artefacts, or unintended editing consequences. It adjusts model parameters and realigns the latent space to reduce harmful outputs and ensure safer content generation.\\
% The safety arithmetic framework applies to three main model types base models, supervised fine-tuned (SFT) models, and edited models where safety risks emerge due to biases, fine-tuning artifacts, or unintended editing consequences. It removes harmful tendencies by adjusting model parameters and then aligns its latent space to generate safer content.\\
% It proceeds in two stages: (a) harm direction removal, which adjusts the model parameters to eliminate harmful tendencies, and (b) safety alignment, which steers the model’s latent space toward generating safer content. \\
\noindent \textbf{(2) \textsc{Resta}}~\cite{bhardwaj2024languagemodelshomersimpson}: 
% This method restores safety in fine-tuned LLMs by adding a safety vector, derived from the difference between a safety-aligned and an unaligned model, to the compromised model’s parameters. 
This method restores safety in fine-tuned LLMs by adding a safety vector from the difference between a safety-aligned and an unaligned model.
It counteracts safety degradation from supervised fine-tuning and enhances alignment using drop and rescale (DARE)~\cite{yu2024languagemodelssupermario} to remove redundant delta parameters before applying \textsc{Resta}.\\
% This method restores safety in fine-tuned LLMs through a simple arithmetic adjustment of model parameters. It operates by adding a safety vector, computed as the difference between a safety-aligned model and its unaligned counterpart obtained via fine-tuning on harmful instruction datasets, to the compromised model’s parameters. This process effectively counters safety degradation introduced by supervised fine-tuning (SFT). The method also employs drop and rescale (DARE)~\cite{yu2024languagemodelssupermario} to remove redundant delta parameters before applying \textsc{Resta}, further enhancing safety alignment.\\
\noindent \textbf{(3) TIES}~\cite{yadav2023tiesmergingresolvinginterferencemerging}: In this method, we consider the top 3\% of parameters in the harm vector $H_v$ and then subtract the trimmed harm vector from the target language model.\\
\noindent \textbf{(3) Self-defense}~\cite{deng2024multilingual}: %\rh{Somnath, we need to tell why did not we compare the self defence of multilingual ICLR 2024 paper. Data is unaavilable}\snb{Done}
We could not compare the self-defense method which suggests that simple fine-tuning with a specific dataset can restore multilingual safety, due to the unavailability of the dataset mentioned in the paper.

% \subsection{All language inclusivity}
% We extend our experiments across different languages one at a time. For each language, we first obtain the top $k$ heads based on the average indirect effect (see Equation~{})\am{missing}. Then, we select only the heads that appear in the top $k$ for the majority of languages. Finally, we consider these selected heads in the harm direction removal phase.


% \noindent \textbf{AutoDAN}~\cite{liu2024autodangeneratingstealthyjailbreak}:
% AutoDAN is an automated jailbreak attack method which employs a hierarchical genetic algorithm to optimize structured discrete data, ensuring that the generated prompts remain semantically meaningful while effectively inducing model misalignment. AutoDAN initializes its search using handcrafted jailbreak prompts and iteratively improves them through paragraph-level and sentence-level modifications, leveraging crossover and mutation techniques. Unlike prior token-level adversarial attacks, AutoDAN avoids reliance on gradient information, making it more resistant to perplexity-based detection methods.\\
% \noindent \textbf{Greedy Coordinate Gradiant (GCG)}~\cite{zou2023universaltransferableadversarialattacks}: Greedy Coordinate Gradient (GCG) is an attack method that generates adversarial suffixes to bypass alignment in language models. It optimizes these suffixes to increase the likelihood of harmful responses using a combination of greedy search and gradient-based token selection. Unlike previous methods, GCG evaluates multiple token replacements per iteration, improving its effectiveness. It also generalizes attacks across different prompts and models, making the adversarial suffixes highly transferable to both open-source and proprietary LLMs.\\
% \noindent \textbf{Deep Inception}~\cite{li2024deepinceptionhypnotizelargelanguage}: DeepInception is a method that exploits the personification capabilities of large language models (LLMs) to bypass safety constraints through a multi-layered, nested instruction approach. Instead of issuing direct harmful prompts, which are often rejected, DeepInception guides the model into generating harmful content by embedding it within a fictional, multi-layered scenario. Inspired by the Milgram experiment, this method induces a "self-losing" state in which the model progressively adheres to the nested instructions without recognizing their adversarial intent. By framing the jailbreak attempt as a staged discussion among fictional characters across multiple layers, the model generates responses that would typically be blocked in a conventional setting.
%AutoDAN, GCG, Deep Inception
\begin{figure}[h]
\centering
\scriptsize
\includegraphics[width=0.37\textwidth]{images/baseline.pdf}
\caption{\footnotesize Comparison of \textsc{Soteria} with other baselines\protect\footnotemark.}
\label{fig:xharmbench}
\vspace{-0.4cm}
\end{figure}
\footnotetext{We define average of High resources as High, and similarly for Mid and Low. This also holds for Figure~\ref{fig:tradeoff} and Table~\ref{tab:jailbreak}.}
\begin{table*}[t]
\centering
% \scriptsize
\resizebox{0.8\textwidth}{!}{
%\setlength{\tabcolsep}{1pt} % Reduce column spacing
% \renewcommand{\arraystretch}{1.0} % Reduce row spacing
\begin{tabular}{lrrrrrrrrrrrrrrrrrrrrrrrr}
\hline \hline
\multicolumn{1}{l|}{{\color[HTML]{000000} }}                                     & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{En}}}                            & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Zh}}}                            & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Es}}}                            & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Fr}}}                            & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{De}}}                            & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Hi}}}                            & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Ar}}}                            & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Th}}}                            & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Bg}}}                            & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Bn}}}                            & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Ta}}}                            & \multicolumn{2}{c}{{\color[HTML]{000000} \textbf{Te}}}          \\ \cline{2-25} 
\multicolumn{1}{l|}{{\color[HTML]{000000} }}                                     & \multicolumn{10}{c|}{\textbf{High resource}}                                                                                                                                                                                                                                                                                                                                                                                           & \multicolumn{8}{c|}{\textbf{Mid resource}}                                                                                                                                                                                                                                                                                                        & \multicolumn{6}{c}{\textbf{Low resource}}                                                                                                                                                                                                 \\ \cline{2-25} 
\multicolumn{1}{l|}{\multirow{-3}{*}{{\color[HTML]{000000} \textbf{Lang}}}} & \multicolumn{1}{c}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{SU}}                   & \multicolumn{1}{c}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{SU}}                   & \multicolumn{1}{c}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{SU}}                   & \multicolumn{1}{c}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{SU}}                   & \multicolumn{1}{c}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{SU}}                   & \multicolumn{1}{c}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{SU}}                   & \multicolumn{1}{c}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{SU}}                   & \multicolumn{1}{c}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{S}}                   & \multicolumn{1}{c}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{SU}}                   & \multicolumn{1}{c}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{SU}}                   & \multicolumn{1}{c}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{SU}}                   & \multicolumn{1}{c}{\textbf{B}} & \multicolumn{1}{c}{\textbf{SU}} \\ \hline
\multicolumn{25}{c}{\textbf{Multijail}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \\ \hline
\multicolumn{1}{l|}{{\color[HTML]{000000} \textbf{Llama 3.1}}}                   & 0.43                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.26} & 0.51                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.2}  & 0.37                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.2}  & 0.41                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.1}  & 0.36                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.19} & 0.54                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.22} & 0.32                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.23} & 0.49                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.34} & 0.39                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.2}  & 0.34                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.32} & 0.52                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.22} & 0.3                            & \cellcolor[HTML]{E3F2E3}0.16   \\
\multicolumn{1}{l|}{\textbf{Qwen 2}}                                             & 0.35                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.25} & 0.23                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.1}  & 0.13                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.11} & 0.2                            & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.04} & 0.23                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.06} & 0.37                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.2}  & 0.08                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.08} & 0.26                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.08} & 0.15                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.1}  & 0.14                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.11} & 0.47                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.34} & 0.3                            & \cellcolor[HTML]{E3F2E3}0.28   \\
\multicolumn{1}{l|}{\textbf{Mistral v3}}                                         & 0.35                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.12} & 0.37                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.08} & 0.2                            & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.19} & 0.27                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.19} & 0.29                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.22} & 0.27                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.18} & 0.32                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.28} & 0.33                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.28} & 0.25                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.17} & 0.2                            & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.02} & 0.1                            & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.04} & 0.05                           & \cellcolor[HTML]{E3F2E3}0.02   \\
\multicolumn{1}{l|}{\textbf{Phi 3.5}}                                            & 0.21                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.04} & 0.22                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.04} & 0.18                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.1}  & 0.25                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0}    & 0.16                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.04} & 0.35                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.2}  & 0.21                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.18} & 0.21                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.2}  & 0.19                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.14} & 0.16                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.15} & 0.26                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.22} & 0.23                           & \cellcolor[HTML]{E3F2E3}0.21   \\ \hline
\multicolumn{25}{c}{\textbf{XThreatBench}}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \\ \hline
\multicolumn{1}{l|}{\textbf{Llama 3.1}}                                          & 0.21                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.13} & 0.25                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.18} & 0.22                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.12} & 0.18                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.1}  & 0.21                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.1}  & 0.17                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.17} & 0.29                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.23} & 0.23                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.13} & 0.29                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.22} & 0.28                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.18} & 0.2                            & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.19} & 0.13                           & \cellcolor[HTML]{E3F2E3}0.11   \\
\multicolumn{1}{l|}{\textbf{Qwen 2}}                                             & 0.14                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.09} & 0.12                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.04} & 0.12                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.09} & 0.11                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.05} & 0.1                            & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.06} & 0.14                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.13} & 0.15                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.1}  & \cellcolor[HTML]{e6ffff}{0.18}                           & \multicolumn{1}{r|}{\cellcolor[HTML]{e6ffff}0.18} & 0.14                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.1}  & \cellcolor[HTML]{e6ffff}{0.13}                           & \multicolumn{1}{r|}{\cellcolor[HTML]{e6ffff}0.13} & \cellcolor[HTML]{e6ffff}{0.22}                           & \multicolumn{1}{r|}{\cellcolor[HTML]{e6ffff}0.22} & 0.18                           & \cellcolor[HTML]{E3F2E3}0.13   \\
\multicolumn{1}{l|}{\textbf{Mistral v3}}                                         & 0.16                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.1}  & 0.26                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.13} & 0.18                           & \multicolumn{1}{l|}{\cellcolor[HTML]{E3F2E3}0.04} & 0.23                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.18} & \cellcolor[HTML]{e6ffff}{0.16}                           & \multicolumn{1}{r|}{\cellcolor[HTML]{e6ffff}0.16} & 0.26                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.15} & 0.3                            & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.26} & 0.24                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.23} & 0.3                            & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.14} & 0.25                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.08} & 0.06                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.02} & 0.05                           & \cellcolor[HTML]{E3F2E3}0      \\
\multicolumn{1}{l|}{\textbf{Phi 3.5}}                                            & 0.07                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.02} & \cellcolor[HTML]{e6ffff}{0.12}                           & \multicolumn{1}{r|}{\cellcolor[HTML]{e6ffff}0.12} & 0.09                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.07} & 0.14                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.07} & 0.06                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.05} & 0.13                           & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.11} & 0.14                           & \multicolumn{1}{r|}{\cellcolor[HTML]{ffddcc}0.18} & 0.05                           & \multicolumn{1}{r|}{\cellcolor[HTML]{ffddcc}0.16} & 0.14                           & \multicolumn{1}{r|}{\cellcolor[HTML]{ffddcc}0.16} & 0.14                           & \multicolumn{1}{r|}{\cellcolor[HTML]{ffddcc}0.17} & 0.1                            & \multicolumn{1}{r|}{\cellcolor[HTML]{E3F2E3}0.06} & 0.12                           & \cellcolor[HTML]{E3F2E3}0.18   \\ \hline \hline
\end{tabular}
}
\caption{\footnotesize Results from \textsc{SoteriaU}. We identify functional neurons by selecting the majority of heads across all languages and then retaining 50\% of the most significant heads. \textbf{B}: base model, \textbf{SU}: \textsc{SoteriaU}. \colorbox{LimeGreen!10}{Green} = lower, \colorbox{CornflowerBlue!15}{blue} = equal, \colorbox{Orange!20}{red} = higher vs. base model.}%\am{If we are comparing Sotiera with base then that is not correct. We should compare Sotiera with the most competing baseline.}\snb{I have added the caption. We are considering this differently to showcase the possibility in case a LLM knows multiple language. Whereas we are considering baselines from only safety perspective.}}
\label{tab:allLanguageInc}
\vspace{-0.4cm}
\end{table*}

\section{Main results}
Here we demonstrate the results from \textsc{Soteria} across different languages in Figure~\ref{fig:multijail} and Figure~\ref{fig:xthreatbench}.\\
\noindent \textbf{Results for different datasets}:\\
\noindent \underline{\textit{MultiJail}}: Evaluation of our proposed method \textsc{Soteria} across multiple language models demonstrates substantial disparities in adversarial robustness across high-resource, medium-resource, and low-resource languages (see Figure~\ref{fig:multijail}).
%(\texttt{En}, \texttt{Zh}, \texttt{Es}, \texttt{Fr}, \texttt{De})
For high-resource languages, the ASR is moderately high, with Llama 3.1 and Qwen 2 exceeding 50\% ASR in certain languages. However, after applying \textsc{Soteria}, ASR is reduced by 40–60\%, with \texttt{En} and \texttt{Es} showing the most substantial reductions, dropping to nearly 20–25\% ASR in the safe models. \texttt{Zh}, however, exhibits a less consistent decline, with some models retaining ASR levels above 30\%, indicating that adversarial robustness is still incomplete for logographic scripts. For medium-resource languages 
%(\texttt{Hn}, \texttt{Ar}, \texttt{Th}, \texttt{Bg})
, ASR reductions are less pronounced compared to high-resource languages. The base model's ASR for these languages is often higher than 50\%. After applying our safety mechanisms, the ASR drops by approximately 30–50\%, with the most effective reductions observed in \texttt{Hn} and \texttt{Bg}, where ASR reaches 25–35\% post-safety alignment. 
%However, \texttt{Ar} and \texttt{Th} remain above 35\% ASR in multiple models, suggesting that current safety strategies struggle with morphological complexity and non-Latin scripts. 
Notably, Mistral 0.3 and Phi 3.5 outperform Llama 3.1 and Qwen 2 in these languages, with ASR reductions exceeding 50\% in some cases.%(\texttt{Bn}, \texttt{Ta}, \texttt{Te})
Low-resource languages present the greatest challenge, as their baseline ASR is the highest among all language groups, often exceeding 60\%. Despite safety interventions, ASR reductions are minimal, typically ranging between 15–30\%. Even in the best-performing models, the final ASR rarely drops below 40\%.
Llama 3.1 and Qwen 2 struggle the most, with ASR remaining as high as 50\% even after applying our safety mechanism. In contrast, Mistral 0.3 and Phi 3.5 achieve slightly better reductions but still maintain ASR levels around 35--45\%. \\
%These findings suggest that \textsc{Soteria} Soteria significantly enhances adversarial robustness, reducing ASR by 40–60\% in high-resource languages, with \texttt{En} and \texttt{Es} dropping to 20–25\%. It also achieves notable ASR reductions of up to 50\% in medium-resource languages like \texttt{Hn} and \texttt{Bg}. Mistral 0.3 and Phi 3.5 perform particularly well, consistently outperforming Llama 3.1 and Qwen 2 in multiple languages.\\
% These findings suggest that safety fine-tuning is disproportionately optimized for high-resource languages, leaving low-resource languages significantly more vulnerable to adversarial attacks even after intervention.
% Across all models, Mistral 0.3 and Phi 3.5 exhibit the most effective ASR reductions, particularly in high- and medium-resource languages, with reductions often exceeding 50\%. Conversely, Llama 3.1 and Qwen 2 consistently retain higher ASR levels post-intervention, particularly in non-Latin and low-resource languages.\\
%indicating that current safety mechanisms fail to generalize effectively to low-resource linguistic settings. 
% Llama 3.1 and Qwen 2 struggle the most, with after employing our safety mechanism, ASR remaining as high as 50\%, whereas Mistral 0.3 and Phi 3.5 achieve slightly better reductions, but still retain ASR levels around 35–45\%. 
% \begin{figure}[t]
% \centering
% \scriptsize
% \includegraphics[width=0.50\textwidth]{images/Graphs.pdf}
% \caption{}
% \label{fig:main}
% \end{figure}
\noindent \underline{\textit{XThreatBench}}: In case of this dataset (see Figure~\ref{fig:xthreatbench}), the evaluation of ASR across different language models reveals notable variations in vulnerability before and after the application of \textsc{Soteria}. In high-resource languages, base models exhibit ASR values ranging from approximately 25--35\%, with Llama 3.1 and Qwen 2 showing the highest susceptibility. Post-safety interventions, ASR is reduced significantly to 5–15\%, demonstrating the efficacy of the mitigation strategies. In medium-resource languages, initial ASR ranges between 20--40\%, with Mistral 0.3 showing comparatively lower vulnerability. After applying \textsc{Soteria}, ASR declines to 10--20\%, though the reduction is less pronounced than in high-resource languages. Low-resource languages remain the most vulnerable, with base ASR values between 25--30\%, and post-safety using \textsc{Soteria}, ASR still hovering around 10--20\%, indicating persistent risks despite intervention. Among all models, Phi 3.5 consistently demonstrates the lowest post-safety ASR across all language groups, staying within 5\%–15\%.%, suggesting stronger inherent alignment. %These results underscore the need for improved multilingual safety mechanisms, especially for low-resource languages, to ensure equitable harm mitigation across linguistic groups.

\noindent \textbf{General capabilities}: We evaluate our framework’s impact on overall model capabilities using utility tests (MMLU~\cite{hendrycks2021measuringmassivemultitasklanguage} 5-shot and TruthfulQA~\cite{lin2022truthfulqameasuringmodelsmimic}). The results closely mirror each base model’s performance. For the safe version of Llama 3.1, we observe the MMLU performance at 72.9 (vs.~73 from the baseline), and TruthfulQA at 44.14 (vs. 44.14 for the baseline). The safe version of Qwen exactly matched its base values (70.3, 54.2). Mistral yielded 61.79 MMLU (vs. 61.84) and 59.34 TruthfulQA (vs. 59.37), while Phi also retained its baseline scores of 69 (MMLU) and 64 (TruthfulQA).

\noindent \textbf{Comparison with the baselines}: We compare \textsc{Soteria} with three English-centric safety alignment methods as discussed above -- safety-arithmetic, \textsc{Resta}, and \textsc{TIES} -- by examining the ASR values for high-, medium-, and low-resource languages. Figure~\ref{fig:xharmbench} presents the results for two models, Llama 3.1 and Qwen 2, using the \textit{Multijail} and \textit{XThreatBench} datasets.
Across all baselines, \textsc{Soteria} consistently achieves the lowest ASR. On Llama 3.1 with the \textit{Multijail} dataset, the baseline method’s ASR ranges from 30–40\% in high-resource languages, while for \textsc{Soteria} it is about 15–20\%. Both \textsc{TIES} and \textsc{Resta} provide moderate decreases (30–35\%), and safety-arithmetic does slightly better (25–30\%). However, \textsc{Soteria} consistently outperforms these methods by 5–10\%. Similar trends hold for medium- and low-resource languages.
A comparable trend is also observed from Qwen 2. For \textit{Multijail}, the baseline ASR is approximately 28–30\% in high-resource settings, whereas \textsc{TIES}, \textsc{Resta}, and safety-arithmetic reduce it to 20–25\%. \textit{Soteria} pushes the ASR even lower, to around 15–20\%. These findings also generalize to \textit{XThreatBench}, reinforcing the robustness of \textsc{Soteria} across diversely resourced languages, models and datasets.
% We compare Soteria with three baseline english centric safety alignment methods -- safety arithmetic, \textsc{Resta} and \textsc{TIES}. To compact the result, we compare the average ASR in high-resource languages, medium-resource and low-resource languages across different methods. The results are shown in Figure~\ref{fig:xharmbench}. We conduct this comparison on two models -- Llama3.1 and Qwen2. Across all the baselines, our proposed framework Soteria consistently achieves the lowest attack success rates (ASR). In case of Llama3 with Multijail dataset, the baseline method’s ASR hovers around 30–40\% in the high-resource setting, while Soteria reduces it to roughly 15–20\%. TIES and \textsc{Resta} show moderate decreases (often 30–35\%), and Safety Arithmetic improves further (approximately 25–30\%); however, Soteria outperforms others. Similar trends appear in mid- and low-resource scenarios, with Soteria maintaining a 5–10\% lower ASR than the $2^{nd}$ best technique.
% A comparable pattern emerges on Qwen. Under Multijail, baseline ASR in the high-resource case is about 28–30\%, whereas TIES, \textsc{Resta}, and Safety Arithmetic reduce it into the 20–25\% range. Soteria brings the rate even lower, to around 15–20\%. XThreatBench results mirror this advantage: Soteria typically stands at least 5\% below its competitors, confirming its robustness in diverse languages and resource conditions.
%\am{What do you propose to put here?}\rh{added}


%\subsection{Individual languages}
\section{Language universals}
We extend our experiments by applying the \textsc{Soteria} framework across all languages together, rather than treating each language independently. However to do so, one needs to identify a set of attention heads that are active for all languages, i.e., capturing the universal characteristics of languages, aka \textit{language universals}~\cite{Dryer1998}.
For each language \(\ell \in \mathscr{L}\), we first measure the average indirect effect (AIE) of each attention head, AIE\(_{\ell}(atn_i^l)\), and select the top \(k\) heads based on these values. We then compile a consensus across languages by identifying the heads that rank in the top \(k\) for at least 75\% of the languages. This majority-based criterion ensures that we capture heads consistently important across the different languages. Finally, we use this refined set of heads in the harm-direction removal phase, thereby reinforcing the safety alignment in a way that remains robust across all the different languages. We call this version of the model \textsc{SoteriaU} indicating its universal nature.\\
% We extend our experiments on employing safety alignment method Soteria in different languages altogether. For each language $\ell \in \mathscr{L}$, we first obtain the top $k$ heads based on the average indirect effect $AIE_{\ell}(atn_i^l)$\am{missing}\rh{fixed}. We follow the majority and select top $k$ heads which occurred in majority of the languages. To make the selection crisp, we choose only those heads which occurs in top $k$ of 75\% of the languages.
% Finally, we consider these selected heads in the harm direction removal phase.
\noindent \textbf{Results}: We observe that the \textsc{SoteriaU} consistently produces lower ASR compared to three base models across all tested languages and model backbones (see Table~\ref{tab:allLanguageInc}). For example, for the \textit{Multijail} dataset, Llama 3.1’s ASR in English drops from 43\% (base) to 26\% (safe), while in Chinese it decreases from 51\% to 20\%. Similar reductions are observed for Qwen 2 (35\% to 25\% in English), Mistral 0.3 (35\% to 12\% in English), and Phi 3.5 (21\% to 4\% in English), demonstrating that \textsc{SoteriaU} effectively curtails harmful responses. This pattern persists for the \textit{XThreatBench} dataset as well, where the safe configurations again achieve notably lower ASRs across languages (e.g., Phi 3.5’s English ASR goes from 7\% to 2\%).
In the mid-resource languages like Arabic in \textit{Multijail}, Llama 3.1’s ASR drops from 32\% to 23\%, while in low-resource Tamil, it decreases from 52\% to 22\%. Across both the \textit{Multijail} and \textit{XThreatBench} datasets, \textsc{SoteriaU} consistently outperforms the base models by lowering harmful outputs in a language-agnostic manner. These results highlight the robustness and effectiveness \textsc{SoteriaU}, regardless of whether the language is high-, mid or low-resourced. %\am{Which figure/table are you referring to?}\rh{Table-1. Referred in the text}
\begin{figure}[h]
\centering
\scriptsize
\includegraphics[width=0.35\textwidth]{images/parameter.pdf}
\caption{\footnotesize Trade-off between ASR and \% heads probed.}
\label{fig:tradeoff}
\vspace{-0.3cm}
\end{figure}
\section{LLM jailbreaks}
We employ recent jailbreak methods to evaluate the robustness of \textsc{Soteria}.\\
\noindent \textbf{POATE}~\cite{sachdeva2025turninglogicprobing}: The POATE jailbreak method manipulates LLMs using contrastive reasoning, subtly reframing harmful queries into their opposites. Unlike direct exploits, it combines adversarial templates to bypass safety measures and trigger unintended responses.\\
% Recently, a jailbreak technique called POATE has demonstrated that LLMs can be effectively manipulated through contrastive reasoning. Unlike previous methods that rely on overt malicious intent, POATE subtly reframes harmful queries into polar opposite prompts combined with adversarial templates to bypass safety mechanisms and elicit unintended responses.\\
\noindent \textbf{Refusal direction}~\cite{arditi2024refusallanguagemodelsmediated}: 
LLMs' refusal behaviour follows a single identifiable direction in activation space. Removing this refusal direction (RDR) bypasses safety measures, enabling harmful responses, while adding it increases refusals. This discovery led to a white-box jailbreak method using a rank-one weight modification to disable refusals with minimal impact on other functions.
% Refusal behavior in LLMs is governed by a single, identifiable direction in their activation space. By erasing this `refusal direction' (RDR) from model activations, researchers were able to bypass the model’s safety mechanism, allowing responses to harmful instructions. Conversely, adding this direction caused models to refuse even harmless queries. This finding led to the development of a white-box jailbreak method using a simple rank-one weight modification, which disables refusal with minimal impact on other model capabilities.
%To evaluate the effectiveness of \textsc{Soteria} against straightforward harmful query inputs, we use three datasets -- \textit{MultiJail}, \textit{XSafety} and our dataset \textit{XThreatBench}. %\am{You have only shown results for MultuJail and XThreatBench. No results in XSafety.}

\noindent \textbf{Results}: For both the \textit{MultiJail} and \textit{XThreatBench} evaluations for the Llama 3.1 8B model, our strategy consistently yields lower ASR than the baseline jailbreaks, indicating a substantial reduction in the model’s vulnerability (see Table~\ref{tab:jailbreak}). In \textit{MultiJail}, POATE’s high threat setting decreases from 0.53 to 0.33, and RDR drops from 0.49 to 0.29. Mid and low threat scenarios show similar improvements. In \textit{XThreatBench}, the reduction is even more pronounced: POATE’s high threat rate falls from 0.46 to 0.13 and RDR goes from 0.30 to 0.11. These results demonstrate that \textsc{Soteria} significantly mitigates the impact of advanced jailbreak techniques across all threat levels for Llama 3.1 8B\footnote{Results are similar for other models and are not shown due to paucity of space.}.

%\section{Trade-off between ASR and \% heads probed}
\section{ASR vs. \% heads probed}
%\section{Result on jailbreak attacks}
Figure~\ref{fig:tradeoff} shows how the ASR changes as we vary the percentage of attention heads in the model, for three different resource settings. All three settings initially exhibit their highest ASRs at 25\% heads, suggesting that using only a small fraction of heads leaves the model more vulnerable. When the percentage of heads increases to 50\%, ASRs drop noticeably across the board, indicating a clear gain in robustness at this midpoint. 
%Specifically, the High‐resource langauges achieve the largest reduction in ASR,
If we use more than 50\% heads, increasingly smaller improvement rates are observed.  This shows that after a certain point, adding more heads brings less benefit. Assuming that each layer in a 8B model has $\sim32$ heads and there are $\sim32$ such layers, we need to probe $0.5\times32\times32=512$ heads. Further the dimension of the corresponding projection matrix $W^{O}_{li}$ is $\sim4096\times128$. Thus, roughly the \% of heads probed is only {\scriptsize $\left( \frac{512 (heads) \times 128 (dimension) \times 4096 (params)}{8\mathrm{B}}\right)\times100 \sim 3\%$}
\begin{table}[h]
\centering
% \scriptsize
\resizebox{0.35\textwidth}{!}{
\begin{tabular}{lllllll}
\hline
\multicolumn{1}{l|}{}               & \multicolumn{2}{c|}{\textbf{High}}                                & \multicolumn{2}{c|}{\textbf{Mid}}                                 & \multicolumn{2}{c}{\textbf{Low}}             \\ \hline
\multicolumn{7}{c}{\textbf{MultiJail}}                                                                                                                                                                                     \\ \hline
\multicolumn{1}{l|}{}               & \textbf{Base-J} & \multicolumn{1}{l|}{\textbf{S-J}}                & \textbf{Base-J} & \multicolumn{1}{l|}{\textbf{S-J}}                & \textbf{Base-J} & \textbf{S-J}                \\ \hline
\multicolumn{1}{l|}{\textbf{POATE}} & 0.53          & \multicolumn{1}{l|}{\cellcolor[HTML]{E4F7E3}0.33} & 0.61          & \multicolumn{1}{l|}{\cellcolor[HTML]{E4F7E3}0.36} & 0.62          & \cellcolor[HTML]{E4F7E3}0.36 \\
\multicolumn{1}{l|}{\textbf{RDR}}   & 0.49          & \multicolumn{1}{l|}{\cellcolor[HTML]{E4F7E3}0.29} & 0.53          & \multicolumn{1}{l|}{\cellcolor[HTML]{E4F7E3}0.30} & 0.61          & \cellcolor[HTML]{E4F7E3}0.36 \\ \hline
\multicolumn{7}{c}{\textbf{XThreatBench}}                                                                                                                                                                                  \\ \hline
\multicolumn{1}{l|}{\textbf{POATE}} & 0.46          & \multicolumn{1}{l|}{\cellcolor[HTML]{E4F7E3}0.13} & 0.45          & \multicolumn{1}{l|}{\cellcolor[HTML]{E4F7E3}0.18} & 0.44          & \cellcolor[HTML]{E4F7E3}0.19 \\
\multicolumn{1}{l|}{\textbf{RDR}}   & 0.30          & \multicolumn{1}{l|}{\cellcolor[HTML]{E4F7E3}0.11} & 0.39          & \multicolumn{1}{l|}{\cellcolor[HTML]{E4F7E3}0.16} & 0.37          & \cellcolor[HTML]{E4F7E3}0.16 \\ \hline
\end{tabular}
}
\caption{Robustness of \textsc{Soteria} against SOTA jailbreak attacks. \textbf{S-J}: \textsc{Soteria}.}
\label{tab:jailbreak}
\vspace{-0.5cm}
\end{table}
% Please add the following required packages to your document preamble:
% \usepackage[table,xcdraw]{xcolor}
% Beamer presentation requires \usepackage{colortbl} instead of \usepackage[table,xcdraw]{xcolor}



% \section{Engines}

% To produce a PDF file, pdf\LaTeX{} is strongly recommended (over original \LaTeX{} plus dvips+ps2pdf or dvipdf). Xe\LaTeX{} also produces PDF files, and is especially suitable for text in non-Latin scripts.

%\section{Preamble}

% The first line of the file must be
% \begin{quote}
% \begin{verbatim}
% \documentclass[11pt]{article}
% \end{verbatim}
% \end{quote}

% To load the style file in the review version:
% \begin{quote}
% \begin{verbatim}
% \usepackage[review]{acl}
% \end{verbatim}
% \end{quote}
% For the final version, omit the \verb|review| option:
% \begin{quote}
% \begin{verbatim}
% \usepackage{acl}
% \end{verbatim}
% \end{quote}

% To use Times Roman, put the following in the preamble:
% \begin{quote}
% \begin{verbatim}
% \usepackage{times}
% \end{verbatim}
% \end{quote}
% (Alternatives like txfonts or newtx are also acceptable.)

% Please see the \LaTeX{} source of this document for comments on other packages that may be useful.

% Set the title and author using \verb|\title| and \verb|\author|. Within the author list, format multiple authors using \verb|\and| and \verb|\And| and \verb|\AND|; please see the \LaTeX{} source for examples.

% By default, the box containing the title and author names is set to the minimum of 5 cm. If you need more space, include the following in the preamble:
% \begin{quote}
% \begin{verbatim}
% \setlength\titlebox{<dim>}
% \end{verbatim}
% \end{quote}
%where \verb|<dim>| is replaced with a length. Do not set this length smaller than 5 cm.

%\section{Document Body}

%\subsection{Footnotes}

%Footnotes are inserted with the \verb|\footnote| command.\footnote{This is a footnote.}

%\subsection{Tables and figures}

%See Table~\ref{tab:accents} for an example of a table and its caption.
%\textbf{Do not override the default caption sizes.}

% \begin{table}
%   \centering
%   \begin{tabular}{lc}
%     \hline
%     \textbf{Command} & \textbf{Output} \\
%     \hline
%     \verb|{\"a}|     & {\"a}           \\
%     \verb|{\^e}|     & {\^e}           \\
%     \verb|{\`i}|     & {\`i}           \\
%     \verb|{\.I}|     & {\.I}           \\
%     \verb|{\o}|      & {\o}            \\
%     \verb|{\'u}|     & {\'u}           \\
%     \verb|{\aa}|     & {\aa}           \\\hline
%   \end{tabular}
%   \begin{tabular}{lc}
%     \hline
%     \textbf{Command} & \textbf{Output} \\
%     \hline
%     \verb|{\c c}|    & {\c c}          \\
%     \verb|{\u g}|    & {\u g}          \\
%     \verb|{\l}|      & {\l}            \\
%     \verb|{\~n}|     & {\~n}           \\
%     \verb|{\H o}|    & {\H o}          \\
%     \verb|{\v r}|    & {\v r}          \\
%     \verb|{\ss}|     & {\ss}           \\
%     \hline
%   \end{tabular}
%   \caption{Example commands for accented characters, to be used in, \emph{e.g.}, Bib\TeX{} entries.}
%   \label{tab:accents}
% \end{table}

% As much as possible, fonts in figures should conform
% to the document fonts. See Figure~\ref{fig:experiments} for an example of a figure and its caption.

% Using the \verb|graphicx| package graphics files can be included within figure
% environment at an appropriate point within the text.
% The \verb|graphicx| package supports various optional arguments to control the
% appearance of the figure.
% You must include it explicitly in the \LaTeX{} preamble (after the
% \verb|\documentclass| declaration and before \verb|\begin{document}|) using
% \verb|\usepackage{graphicx}|.

% \begin{figure}[t]
%   \includegraphics[width=\columnwidth]{example-image-golden}
%   \caption{A figure with a caption that runs for more than one line.
%     Example image is usually available through the \texttt{mwe} package
%     without even mentioning it in the preamble.}
%   \label{fig:experiments}
% \end{figure}

% \begin{figure*}[t]
%   \includegraphics[width=0.48\linewidth]{example-image-a} \hfill
%   \includegraphics[width=0.48\linewidth]{example-image-b}
%   \caption {A minimal working example to demonstrate how to place
%     two images side-by-side.}
% \end{figure*}

%\subsection{Hyperlinks}

% Users of older versions of \LaTeX{} may encounter the following error during compilation:
% \begin{quote}
% \verb|\pdfendlink| ended up in different nesting level than \verb|\pdfstartlink|.
% \end{quote}
% This happens when pdf\LaTeX{} is used and a citation splits across a page boundary. The best way to fix this is to upgrade \LaTeX{} to 2018-12-01 or later.

%\subsection{Citations}

% \begin{table*}
%   \centering
%   \begin{tabular}{lll}
%     \hline
%     \textbf{Output}           & \textbf{natbib command} & \textbf{ACL only command} \\
%     \hline
%     \citep{Gusfield:97}       & \verb|\citep|           &                           \\
%     \citealp{Gusfield:97}     & \verb|\citealp|         &                           \\
%     \citet{Gusfield:97}       & \verb|\citet|           &                           \\
%     \citeyearpar{Gusfield:97} & \verb|\citeyearpar|     &                           \\
%     \citeposs{Gusfield:97}    &                         & \verb|\citeposs|          \\
%     \hline
%   \end{tabular}
%   \caption{\label{citation-guide}
%     Citation commands supported by the style file.
%     The style is based on the natbib package and supports all natbib citation commands.
%     It also supports commands defined in previous ACL style files for compatibility.
%   }
% \end{table*}

% Table~\ref{citation-guide} shows the syntax supported by the style files.
% We encourage you to use the natbib styles.
% You can use the command \verb|\citet| (cite in text) to get ``author (year)'' citations, like this citation to a paper by \citet{Gusfield:97}.
% You can use the command \verb|\citep| (cite in parentheses) to get ``(author, year)'' citations \citep{Gusfield:97}.
% You can use the command \verb|\citealp| (alternative cite without parentheses) to get ``author, year'' citations, which is useful for using citations within parentheses (e.g. \citealp{Gusfield:97}).

% A possessive citation can be made with the command \verb|\citeposs|.
% This is not a standard natbib command, so it is generally not compatible
% with other style files.

\nocite{Ando2005}




%The \LaTeX{} and Bib\TeX{} style files provided roughly follow the American Psychological Association format.
%If your own bib file is named \texttt{custom.bib}, then placing the following before any appendices in your \LaTeX{} file will generate the references section for you:
% \begin{quote}
% \begin{verbatim}
% \bibliography{custom}
% \end{verbatim}
% \end{quote}

% You can obtain the complete ACL Anthology as a Bib\TeX{} file from \url{https://aclweb.org/anthology/anthology.bib.gz}.
% To include both the Anthology and your own .bib file, use the following instead of the above.
% \begin{quote}
% \begin{verbatim}
% \bibliography{anthology,custom}
% \end{verbatim}
% \end{quote}

% Please see Section~\ref{sec:bibtex} for information on preparing Bib\TeX{} files.

% \subsection{Equations}

% An example equation is shown below:
% \begin{equation}
%   \label{eq:example}
%   A = \pi r^2
% \end{equation}

% Labels for equation numbers, sections, subsections, figures and tables
% are all defined with the \verb|\label{label}| command and cross references
% to them are made with the \verb|\ref{label}| command.

% This an example cross-reference to Equation~\ref{eq:example}.

% \subsection{Appendices}

% Use \verb|\appendix| before any appendix section to switch the section numbering over to letters. See Appendix~\ref{sec:appendix} for an example.

%\section{Bib\TeX{} Files}
%\label{sec:bibtex}

% Unicode cannot be used in Bib\TeX{} entries, and some ways of typing special characters can disrupt Bib\TeX's alphabetization. The recommended way of typing special characters is shown in Table~\ref{tab:accents}.

% Please ensure that Bib\TeX{} records contain DOIs or URLs when possible, and for all the ACL materials that you reference.
% Use the \verb|doi| field for DOIs and the \verb|url| field for URLs.
% If a Bib\TeX{} entry has a URL or DOI field, the paper title in the references section will appear as a hyperlink to the paper, using the hyperref \LaTeX{} package.

\section{Conclusion}
We introduce \textsc{Soteria}, a lightweight yet powerful safety alignment method that fine-tunes language-specific ``functional neurons'' in multilingual LLMs. By adjusting only a fraction of parameters, \textsc{Soteria} effectively curbs policy violations across high-, mid-, and low-resource languages without compromising overall performance. Our \textit{XThreatBench} dataset, derived from real-world policy violations, demonstrates that this targeted parameter steering outperforms baseline safety approaches. These results highlight the value of language-aware interpretability and the practicality of scalable multilingual safeguards, advancing inclusive and ethically responsible AI.

% We introduced \textsc{Soteria}, a lightweight yet powerful safety alignment method that selectively adjusts language-specific “functional neurons” in multilingual LLMs. By altering only a fraction of parameters, \textsc{Soteria} significantly reduces policy-violating outputs across high-, mid-, and low-resource languages without degrading overall performance. Our new \textit{XThreatBench} dataset, built from real-world policy violations, shows that this fine-grained parameter steering achieves marked improvements over baseline safety approaches. These findings underscore both the importance of language-tailored interpretability and the feasibility of deploying multilingual safeguards at scale, thereby paving the way for more inclusive and ethically responsible AI systems worldwide.
\section{Limitation}

A key limitation of \textsc{Soteria} lies in its reliance on per-language functional neuron identification, which requires accurate language segmentation and task-based data in each target language. In practice, resource constraints, limited training data, and complexities in script variation or morphology can reduce the precision of head selection. Moreover, although \textsc{Soteria} improves safety across many languages, it does not guarantee comprehensive coverage of every cultural nuance or emergent harmful behavior.
\section{Ethical Consideration}
In designing and evaluating \textsc{Soteria}, we prioritized responsible data use and clear ethical practices: \emph{XThreatBench} was curated exclusively from synthetic or publicly available prompts crafted to evaluate harmful scenarios without including any personal or sensitive user data. We aligned our methodology with widely recognized industry norms, ensuring minimal data collection and protecting user privacy. Moreover, we respected the cultural nuances that shape perceptions of harm by incorporating broad content moderation principles from organizations like Meta and OpenAI. By balancing robust multilingual safety mechanisms with careful attention to legitimate expression and cultural diversity, our approach aims to foster a more secure yet equitable AI environment.
\bibliography{custom}

\appendix

\section{Additional experiment}
\label{appn:xsafetyexp}
\begin{table*}[h]
\centering
% \scriptsize
\resizebox{1.0\textwidth}{!}{
\begin{tabular}{l|cccccccccc|cccccccc|cccccc}
\hline
\multicolumn{1}{c|}{{\color[HTML]{000000} }}                            & \multicolumn{10}{c|}{\textbf{High Resource}}                                                                                                                                                                                                                                                                                                                                                                           & \multicolumn{8}{c|}{\textbf{Mid Resource}}                                                                                                                                                                                                                                                                                                         & \multicolumn{6}{c}{\textbf{Low Resource}}                                                                                                                                                                                                                    \\ \cline{2-25} 
\multicolumn{1}{c|}{{\color[HTML]{000000} }}                            & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{En}}}                             & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Zh}}}                             & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{De}}}                             & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Fr}}}                             & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Es}}}        & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Bg}}}                             & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Hi}}}                             & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Th}}}                                               & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Ar}}}        & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Bn}}}                             & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Te}}}                                               & \multicolumn{2}{c}{{\color[HTML]{000000} \textbf{Ta}}}         \\ \cline{2-25} 
\multicolumn{1}{c|}{\multirow{-3}{*}{{\color[HTML]{000000} Languages}}} & \multicolumn{1}{c|}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{S}}                   & \multicolumn{1}{c|}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{S}}                   & \multicolumn{1}{c|}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{S}}                   & \multicolumn{1}{c|}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{S}}                   & \multicolumn{1}{c|}{\textbf{B}} & \textbf{S}                   & \multicolumn{1}{c|}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{S}}                   & \multicolumn{1}{c|}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{S}}                   & \multicolumn{1}{c|}{\textbf{B}}                   & \multicolumn{1}{c|}{\textbf{S}}                   & \multicolumn{1}{c|}{\textbf{B}} & \textbf{S}                   & \multicolumn{1}{c|}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{S}}                   & \multicolumn{1}{c|}{\textbf{B}}                   & \multicolumn{1}{c|}{\textbf{S}}                   & \multicolumn{1}{c|}{\textbf{B}} & \textbf{S}                   \\ \hline
{\color[HTML]{000000} \textbf{llama3.1-8b-instruct}}                    & \multicolumn{1}{c|}{0.12}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.05} & \multicolumn{1}{c|}{0.14}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.07} & \multicolumn{1}{c|}{0.12}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.03} & \multicolumn{1}{c|}{0.09}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.03} & \multicolumn{1}{c|}{0.08}       & \cellcolor[HTML]{C9D5B0}0.01 & \multicolumn{1}{c|}{0.17}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.08} & \multicolumn{1}{c|}{0.12}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.05} & \multicolumn{1}{c|}{0.11}                         & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.05} & \multicolumn{1}{c|}{0.09}       & \cellcolor[HTML]{C9D5B0}0.06 & \multicolumn{1}{c|}{0.13}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.08} & \multicolumn{1}{c|}{0.11}                         & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.07} & \multicolumn{1}{c|}{0.13}       & \cellcolor[HTML]{C9D5B0}0.08 \\ \hline
{\color[HTML]{000000} \textbf{Qwen2-7B-Instruct}}                       & \multicolumn{1}{c|}{0.08}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.05} & \multicolumn{1}{c|}{0.03}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.02} & \multicolumn{1}{c|}{0.04}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.03} & \multicolumn{1}{c|}{0.04}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.02} & \multicolumn{1}{c|}{0.03}       & \cellcolor[HTML]{C9D5B0}0.02 & \multicolumn{1}{c|}{0.05}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.02} & \multicolumn{1}{c|}{0.06}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.05} & \multicolumn{1}{c|}{0.04}                         & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.03} & \multicolumn{1}{c|}{0.03}       & \cellcolor[HTML]{C9D5B0}0.02 & \multicolumn{1}{c|}{0.07}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.04} & \multicolumn{1}{c|}{0.07}                         & \multicolumn{1}{c|}{\cellcolor[HTML]{C0F2F5}0.07} & \multicolumn{1}{c|}{0.09}       & \cellcolor[HTML]{C9D5B0}0.08 \\ \hline
{\color[HTML]{000000} \textbf{Mistral-7B-Instruct-v0.3}}                & \multicolumn{1}{c|}{0.11}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.03} & \multicolumn{1}{c|}{0.1}        & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.02} & \multicolumn{1}{c|}{0.08}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.04} & \multicolumn{1}{c|}{0.1}        & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.06} & \multicolumn{1}{c|}{0.06}       & \cellcolor[HTML]{C9D5B0}0.03 & \multicolumn{1}{c|}{0.09}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.05} & \multicolumn{1}{c|}{0.11}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.05} & \multicolumn{1}{c|}{0.08}                         & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.06} & \multicolumn{1}{c|}{0.08}       & \cellcolor[HTML]{C9D5B0}0.1  & \multicolumn{1}{c|}{0.08}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.02} & \multicolumn{1}{c|}{0.04}                         & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.01} & \multicolumn{1}{c|}{0.02}       & \cellcolor[HTML]{C9D5B0}0.01 \\ \hline
{\color[HTML]{000000} \textbf{Phi-3.5-mini-instruct}}                   & \multicolumn{1}{c|}{0.08}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.01} & \multicolumn{1}{c|}{0.11}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.05} & \multicolumn{1}{c|}{0.06}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.02} & \multicolumn{1}{c|}{0.09}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.03} & \multicolumn{1}{c|}{0.06}       & \cellcolor[HTML]{C9D5B0}0.02 & \multicolumn{1}{c|}{0.07}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.06} & \multicolumn{1}{c|}{0.09}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.05} & \multicolumn{1}{c|}{\cellcolor[HTML]{FFFFFF}0.08} & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.06} & \multicolumn{1}{c|}{0.09}       & \cellcolor[HTML]{C9D5B0}0.07 & \multicolumn{1}{c|}{0.04}       & \multicolumn{1}{c|}{\cellcolor[HTML]{C9D5B0}0.03} & \multicolumn{1}{c|}{\cellcolor[HTML]{FFFFFF}0.05} & \multicolumn{1}{c|}{\cellcolor[HTML]{C0F2F5}0.05} & \multicolumn{1}{c|}{0.02}       & \cellcolor[HTML]{C0F2F5}0.02 \\ \hline
\end{tabular}
}
\caption{\footnotesize Results on the \textit{XSafety} dataset. \textbf{B} represent the base model’s unsafe outputs, while \textbf{S} denote
outputs from \textsc{Soteria}. The substantial reduction in unsafe content across high-, mid-, and low-resource
languages highlight the effectiveness of the \textsc{Soteria} compared to the base model. Lower is better. \colorbox{LimeGreen!10}{Green} = lower, \colorbox{CornflowerBlue!15}{blue} = equal, \colorbox{Orange!20}{red} = higher vs. base model.}
\label{tab:my-table}
\end{table*}
\begin{table*}[h]
\centering
% \scriptsize
\resizebox{1.0\textwidth}{!}{
\begin{tabular}{l|rrrrrrrrrr|rrrrrrrr|rrrrrr}
\hline
\multicolumn{1}{c|}{{\color[HTML]{000000} }}                            & \multicolumn{10}{c|}{\textbf{High Resource}}                                                                                                                                                                                                                                                                                                                                                                              & \multicolumn{8}{c|}{\textbf{Mid Resource}}                                                                                                                                                                                                                                                                                                            & \multicolumn{6}{c}{\textbf{Low Resource}}                                                                                                                                                                                                                      \\ \cline{2-25} 
\multicolumn{1}{c|}{{\color[HTML]{000000} }}                            & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{En}}}                             & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Zh}}}                             & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{De}}}                             & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Fr}}}                             & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Es}}}           & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Bg}}}                             & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Hi}}}                             & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Th}}}                                               & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Ar}}}           & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Bn}}}                             & \multicolumn{2}{c|}{{\color[HTML]{000000} \textbf{Te}}}                                               & \multicolumn{2}{c}{{\color[HTML]{000000} \textbf{Ta}}}           \\ \cline{2-25} 
\multicolumn{1}{c|}{\multirow{-3}{*}{{\color[HTML]{000000} Languages}}} & \multicolumn{1}{c|}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{S}}                   & \multicolumn{1}{c|}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{S}}                   & \multicolumn{1}{c|}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{S}}                   & \multicolumn{1}{c|}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{S}}                   & \multicolumn{1}{c|}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{S}} & \multicolumn{1}{c|}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{S}}                   & \multicolumn{1}{c|}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{S}}                   & \multicolumn{1}{c|}{\textbf{B}}                   & \multicolumn{1}{c|}{\textbf{S}}                   & \multicolumn{1}{c|}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{S}} & \multicolumn{1}{c|}{\textbf{B}} & \multicolumn{1}{c|}{\textbf{S}}                   & \multicolumn{1}{c|}{\textbf{B}}                   & \multicolumn{1}{c|}{\textbf{S}}                   & \multicolumn{1}{c|}{\textbf{B}} & \multicolumn{1}{c}{\textbf{S}} \\ \hline
{\color[HTML]{000000} \textbf{llama3.1-8b-instruct}}                    & \multicolumn{1}{r|}{0.12}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.06} & \multicolumn{1}{r|}{0.14}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.11} & \multicolumn{1}{r|}{0.12}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.07} & \multicolumn{1}{r|}{0.09}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.04} & \multicolumn{1}{r|}{0.08}       & \cellcolor[HTML]{C9D5B0}0.03    & \multicolumn{1}{r|}{0.17}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.09} & \multicolumn{1}{r|}{0.12}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.07} & \multicolumn{1}{r|}{0.11}                         & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.07} & \multicolumn{1}{r|}{0.09}       & \cellcolor[HTML]{C9D5B0}0.04    & \multicolumn{1}{r|}{0.13}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.12} & \multicolumn{1}{r|}{0.11}                         & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.05} & \multicolumn{1}{r|}{0.13}       & \cellcolor[HTML]{C9D5B0}0.08   \\ \hline
{\color[HTML]{000000} \textbf{Qwen2-7B-Instruct}}                       & \multicolumn{1}{r|}{0.08}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.06} & \multicolumn{1}{r|}{0.03}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C0F2F5}0.03} & \multicolumn{1}{r|}{0.04}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.01} & \multicolumn{1}{r|}{0.04}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.02} & \multicolumn{1}{r|}{0.03}       & \cellcolor[HTML]{C9D5B0}0.03    & \multicolumn{1}{r|}{0.05}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.03} & \multicolumn{1}{r|}{0.06}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.04} & \multicolumn{1}{r|}{0.04}                         & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.02} & \multicolumn{1}{r|}{0.03}       & \cellcolor[HTML]{C9D5B0}0.03    & \multicolumn{1}{r|}{0.07}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.05} & \multicolumn{1}{r|}{0.07}                         & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.04} & \multicolumn{1}{r|}{0.09}       & \cellcolor[HTML]{C9D5B0}0.04   \\ \hline
{\color[HTML]{000000} \textbf{Mistral-7B-Instruct-v0.3}}                & \multicolumn{1}{r|}{0.11}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.02} & \multicolumn{1}{r|}{0.1}        & \multicolumn{1}{r|}{\cellcolor[HTML]{C0F2F5}0.1}  & \multicolumn{1}{r|}{0.08}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.01} & \multicolumn{1}{r|}{0.1}        & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.04} & \multicolumn{1}{r|}{0.06}       & \cellcolor[HTML]{C9D5B0}0.05    & \multicolumn{1}{r|}{0.09}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C0F2F5}0.09} & \multicolumn{1}{r|}{0.11}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.06} & \multicolumn{1}{r|}{0.08}                         & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.1}  & \multicolumn{1}{r|}{0.08}       & \cellcolor[HTML]{C9D5B0}0.1     & \multicolumn{1}{r|}{0.08}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.02} & \multicolumn{1}{r|}{0.04}                         & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0}    & \multicolumn{1}{r|}{0.02}       & \cellcolor[HTML]{C9D5B0}0.01   \\ \hline
{\color[HTML]{000000} \textbf{Phi-3.5-mini-instruct}}                   & \multicolumn{1}{r|}{0.08}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.01} & \multicolumn{1}{r|}{0.11}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.04} & \multicolumn{1}{r|}{0.06}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.03} & \multicolumn{1}{r|}{0.09}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.01} & \multicolumn{1}{r|}{0.06}       & \cellcolor[HTML]{C9D5B0}0.04    & \multicolumn{1}{r|}{0.07}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.06} & \multicolumn{1}{r|}{0.09}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.07} & \multicolumn{1}{r|}{\cellcolor[HTML]{FFFFFF}0.08} & \multicolumn{1}{r|}{\cellcolor[HTML]{F5D0D0}0.09} & \multicolumn{1}{r|}{0.09}       & \cellcolor[HTML]{C0F2F5}0.09    & \multicolumn{1}{r|}{0.04}       & \multicolumn{1}{r|}{\cellcolor[HTML]{C0F2F5}0.04} & \multicolumn{1}{r|}{\cellcolor[HTML]{FFFFFF}0.05} & \multicolumn{1}{r|}{\cellcolor[HTML]{C9D5B0}0.04} & \multicolumn{1}{r|}{0.02}       & \cellcolor[HTML]{C0F2F5}0.02   \\ \hline
\end{tabular}
}
\caption{\footnotesize Results from \textsc{Soteria}. We identify functional neurons by selecting the majority of heads across all languages and then retaining 50\% of the most significant heads. \textbf{B}: base model, \textbf{S}: \textsc{Soteria}. \colorbox{LimeGreen!10}{Green} = lower, \colorbox{CornflowerBlue!15}{blue} = equal, \colorbox{Orange!20}{red} = higher vs. base model.}
\label{tab:xsafety_universal}
\end{table*}
\noindent \underline{\textit{XSafety}}: This is a multilingual safety benchmark designed to evaluate LLMs across multiple languages. It consists of 2,800 manually translated instances covering 14 safety categories in 10 widely spoken languages: \textit{English, Chinese, Spanish, French, Bengali, Arabic, Hindi, Russian, Japanese,} and \textit{German}. Built from existing monolingual safety datasets, \textit{XSafety} was translated and verified by annotators, ensuring cross-lingual consistency. The benchmark reveals significant safety gaps in non-English responses, emphasizing the need for multilingual safety alignment. For our experiments, we use \textit{google translate}\footnote{\url{https://translate.google.com}} to translate English queries into other languages when they are not present in the dataset.

\subsection{Result for XSafety dataset}
\begin{figure*}[h]
\centering
\scriptsize
\includegraphics[width=1.0\textwidth]{images/all_in_one_heatmap_grid.pdf}
\caption{\footnotesize Identified top 20 heads for Llama 3.1 8B for all languages.}
\label{fig:headsall}
\end{figure*}
The results presented in Table \ref{tab:my-table} illustrate the substantial improvements achieved by integrating the \textsc{Soteria} framework across a wide range of languages and language models. The comparison between the baseline models (\textbf{B}) and the safe models (\textbf{S}) reveals a significant reduction in unsafe outputs across high-, mid-, and low-resource languages. This consistent improvement underscores the effectiveness of \textsc{Soteria} as a robust and scalable solution for mitigating unsafe content generation in multilingual LLMs.\\
\noindent In high-resource languages such as English, Chinese, German, French, and Spanish, the impact of \textsc{Soteria} is particularly noteworthy. For example, in English, the unsafe output rate for the Llama 3.1 model drops from 0.12 in the baseline to 0.05 with \textsc{Soteria}. Similar improvements are observed in Chinese (0.14 to 0.07) and German (0.12 to 0.03), reflecting a substantial reduction in unsafe behavior. The safe versions of models like Qwen 2 and Mistral show comparable improvements, with Qwen 2 reducing the unsafe rate in Chinese from 0.03 to 0.02 and Mistral achieving a reduction in English from 0.11 to 0.03. These results demonstrate that \textsc{Soteria} not only improves safety for individual models but also generalizes effectively across different architectures and languages.\\
\noindent Mid-resource languages such as Bulgarian, Hindi, Thai, and Arabic pose additional challenges due to their relatively limited training data. Despite these difficulties, \textsc{Soteria} delivers significant reductions in unsafe outputs across all models. For instance, in Bulgarian, the unsafe rate for Llama 3.1 drops from 0.17 to 0.08, a nearly 50\% improvement. Similar trends are seen in Hindi, where the rate falls from 0.12 to 0.05, and Thai, with a reduction from 0.11 to 0.05. Qwen 2 also demonstrates strong performance improvements in these languages, particularly in Hindi, where it reduces the unsafe rate to 0.05. Even in Arabic, which presents unique challenges, models like Mistral and Phi 3.5 achieve remarkably low unsafe rates, indicating that \textsc{Soteria} is effective in maintaining safety across diverse linguistic and cultural contexts.\\
\noindent The performance of \textsc{Soteria} in low-resource languages such as Bengali, Telugu, and Tamil further validates its adaptability and scalability. Low-resource languages often exhibit higher baseline unsafe output rates due to their underrepresentation in training data. However, \textsc{Soteria} consistently reduces these rates, demonstrating its capacity to address safety concerns in less-resourced linguistic settings. In Bengali, for example, Llama 3.1 reduces the unsafe rate from 0.13 to 0.08, while Telugu and Tamil see similar improvements, with reductions from 0.11 to 0.07 and 0.13 to 0.08, respectively. Notably, Mistral and Phi 3.5 continue to perform exceptionally well, with Mistral achieving an impressively low unsafe rate of 0.01 in Tamil.\\
\noindent The results presented across these language groups make it clear that \textsc{Soteria} offers a transformative approach to improving safety in large language models. The consistent reductions in unsafe outputs, ranging from high-resource to low-resource languages, highlight the robustness and generalizability of the framework.
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage[table,xcdraw]{xcolor}
% Beamer presentation requires \usepackage{colortbl} instead of \usepackage[table,xcdraw]{xcolor}


\subsection{XSafety (language universal)}


In Table~\ref{tab:xsafety_universal} for high-resource languages such as English, Chinese, German, French, and Spanish, the reduction in unsafe outputs is substantial. For example, in English, the unsafe rate for Llama 3.1 drops from 0.12 to 0.06, and in German, it declines from 0.12 to 0.07. Similar improvements are observed across other high-resource languages. Qwen 2 reduces the unsafe rate in French from 0.04 to 0.02 and shows consistent gains across other languages like Chinese and Spanish. Mistral stands out in English, where it brings down the unsafe rate from 0.11 to 0.02. These reductions reflect the precision with which \textsc{Soteria} identifies and mitigates unsafe content while maintaining the language models’ core functionality.\\
\noindent The mid-resource languages -- Bulgarian, Hindi, Thai, and Arabic -- further illustrate \textsc{Soteria}’s adaptability. Bulgarian, for instance, sees a significant improvement with Llama 3.1 reducing the unsafe rate from 0.17 to 0.09, and Hindi experiences a similar reduction from 0.12 to 0.07. Mistral also achieved substantial progress in Bulgarian, reducing unsafe outputs to 0.09. These results are a clear indicator that \textsc{Soteria} effectively addresses the unique challenges presented by languages with moderately available resources, ensuring more controlled output across different linguistic patterns and complexities.\\
\noindent In low-resource languages such as Bengali, Telugu, and Tamil, where limited data often results in higher baseline unsafe rates, \textsc{Soteria} continues to deliver meaningful reductions. Llama 3.1 reduces the unsafe rate in Bengali from 0.13 to 0.08, while Telugu sees an improvement from 0.11 to 0.05. Tamil shows equally promising results, with multiple models significantly lowering unsafe outputs. Notably, Mistral reduces the unsafe rate in Tamil to 0.01, demonstrating that \textsc{Soteria} can extend its impact even to data-scarce settings without requiring extensive retraining or language-specific adjustments.\\
\noindent Overall, the results highlight \textsc{Soteria}’s capacity to improve model safety at scale, offering a practical and efficient approach to reducing unsafe outputs across languages with diverse resource levels. The consistent reduction in unsafe rates across models and languages indicates that \textsc{Soteria} is not only scalable but also robust in its generalization across linguistic and cultural boundaries.


% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage[table,xcdraw]{xcolor}
% Beamer presentation requires \usepackage{colortbl} instead of \usepackage[table,xcdraw]{xcolor}

\section{Attention head patterns and their implications}

One intriguing characteristic of LLMs is how their top-valued language‐specific attention heads tend to cluster by resource level of the language. Analyses of a smaller-parameter model (e.g., Llama 3.1 8B‐parameter variant) reveal that high‐resource languages (such as \textit{English, Chinese, Spanish, German}, and \textit{French}) and mid‐resource languages (such as \textit{Hindi, Arabic, Thai}, and \textit{Bulgarian}) exhibit peak attention heads in roughly the same mid‐level layers (e.g., layers 12–20 with head indices 16–24). Meanwhile, for low‐resource languages the strongest attention heads manifest in later layers (e.g., layers 28–31 with head indices 15–23)~(see Figure~\ref{fig:headsall}).\\
\noindent \textbf{(1) Language-specific universal heads}: Despite the differences in where each language’s top heads appear, some heads consistently contribute to cross‐lingual understanding -- the so‐called ``universal'' heads. Identifying and enhancing these universal heads can make the model’s latent space more cohesive across languages, improving zero‐shot or few‐shot performance for underrepresented languages.\\
\noindent \textbf{(2) Future directions}: Beyond raw performance, attention‐head analysis also provides new insights to tackle task-specific attention heads, misalignment, and hallucination issues. If certain heads consistently carry problematic correlations, shifting or refining their latent space (``\textcolor{red}{\textit{steer them to a safe side}}'') can enhance overall alignment and trustworthiness.\\
\noindent These findings underscore the delicate interplay between multilingualism and architectural depth in multilingual models. By homing in on the most influential heads and understanding why they appear where they do, we gain powerful levers for improving cross‐lingual performance, minimizing unsafe content generation, and facilitating more robust language support, even for the world’s most resource sparse tongues.
\end{document}
