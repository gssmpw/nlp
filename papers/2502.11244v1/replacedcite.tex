\section{Related work}
\textbf{Mechanistic interpretability}: This section explores how internal LLM components (neurons, layers, attention heads) shape model behaviors ____. Early work identified key neurons ____, but recent studies underscore attention headsâ€™ critical roles in various language tasks ____. Ablation approaches reveal certain heads are crucial for syntactic parsing and factual reasoning ____, yet their safety implications remain underexplored ____. This gap highlights the need for fine-grained analysis to enhance transparency and safety.\\
%explores how internal components of LLMs, such as neurons, layers, and attention heads, contribute to model behaviors____. While early research focused on identifying key neurons responsible for model behavior____, recent studies reveal that attention heads play crucial roles in various language tasks____. Ablation techniques, commonly used to identify critical parameters, have shown that specific attention heads are essential for syntactic parsing and factual reasoning____. However, the safety impact of attention heads remains underexplored compared to their contributions to other capabilities____, highlighting the need for fine-grained analysis to enhance model transparency and safety.\\
\textbf{Safety alignment}: Efforts to ensure LLM safety focus on mitigating adversarial prompts ____, designing robust filtering ____, and maintaining dynamic oversight ____. Early studies ____ expose key vulnerabilities and propose ethical risk frameworks. Subsequent work ____ reveals how subtle prompt manipulations can evade safeguards, prompting research into attack strategies ____ and defenses like RAIN ____. Others emphasize dynamic monitoring ____ and adaptive safety mechanisms, including safety arithmetic ____ for test-time alignment and SafeInfer ____, SafeDecoding____ for decoding-time alignment.
% Efforts to ensure the safety of LLMs have increasingly focused on mitigating adversarial prompts____, designing robust filtering systems____, and maintaining dynamic oversight____. Initial explorations____ highlight key vulnerabilities and propose ethical frameworks for risk assessment in AI systems. More recent findings____ illustrate how subtle prompt manipulations can bypass existing safety measures, prompting researchers to investigate both attack strategies____ and robust defensive solutions such as RAIN____. Other studies emphasize the importance of dynamic monitoring and adaptive safety mechanisms____, with novel approaches like \textit{safety arithmetic}____ for test-time alignment and SafeInfer____ for decoding-time alignment further advancing the field. Building upon these efforts____ have proposed the SafeDecoding method which is a safety-aware decoding strategy for LLMs, to defend against jailbreak attacks.
\vspace{-0.1cm}