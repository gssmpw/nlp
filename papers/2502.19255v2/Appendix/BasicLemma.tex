\section{Useful Lemmas}\label{appx:basic_lemma}

\begin{lemma}[Convex Hull Fulfills Assump.~\ref{assump:policy}]\label{lem:convex_hull_property}
    Given $\Pi$ satisfying Assump.~\ref{assump:policy}, $\conv(\Pi)$ also satisfies Assump.~\ref{assump:policy}.
\end{lemma}
\begin{proof}
    The realizability condition is obviously. We verify Assump.~\ref{assump:policy}.
    Note that for any $\pi \in \conv(\Pi)$, there exists $\lambda^1,...,\lambda^n \geq 0$ and $\pi^1,...,\pi^n \in \Pi$, s.t. $\sum_{i=1}^n \lambda^i = 1$ and $\pi = \sum_{i=1}^n \lambda^i \pi^i$, which implies,
    \begin{align*}
        \forall s,a\quad & \frac{\pi(a|s)}{\pi_\textref(a|s)} = \sum_{i=1}^n \lambda^i \frac{\pi^i(a|s)}{\pi_\textref(a|s)} \geq \exp(-\frac{\Rmax}{\beta}),
        & \frac{\pi(a|s)}{\pi_\textref(a|s)} = \sum_{i=1}^n \lambda^i \frac{\pi^i(a|s)}{\pi_\textref(a|s)} \leq \exp(\frac{\Rmax}{\beta}).
    \end{align*}
    Therefore, $\conv(\Pi)$ fulfills Assump.~\ref{assump:policy}-(II), which finishes the proof.
\end{proof}

\begin{lemma}[MLE Guarantees; Adapated from Lemma C.6 in \citep{xie2024exploratory}]\label{lem:MLE_Estimation}
    Consider a policy class $\Pi$ satisfying Assump.~\ref{assump:policy}, and recall the reward class $\cR^\Pi$ converted by Eq.~\eqref{eq:reward_class_conversion}.
    Given a dataset $\cD := \{(s^i,a^i,\ta^i,y^i,\pi^i)\}_{i\leq |\cD|}$ satisfying Cond.~\ref{cond:seq_data} and any $\delta\in(0,1)$, w.p. $1-\delta$,
    %
    %
    %
    %
    %
    \begin{align*}
        \forall r\in\cR^\Pi,~\frac{1}{|\cD|}\sum_{i \leq |\cD|} \EE_{s\sim\rho,a\sim\pi^i(\cdot|s),\ta\sim\pi_\textref(\cdot|s)}[\mH^2(\mP_{r}(\cdot|s,a,\ta)\| \mP_{r^*}(\cdot|s,a,\ta))] \leq L_{\cD}(r) - L_{\cD}(r^*) + \frac{2}{|\cD|}\log\frac{|\Pi|}{\delta}.
    \end{align*}
    %
    %
    %
\end{lemma}
\begin{proof}
    The proof is almost identical to Lemma C.6 in \citep{xie2024exploratory}, except we replace $\mP_\pi$ in their paper by $\mP_r$. So we omit it here.
    Besides, note that our NLL loss is normalized, while \citep{xie2024exploratory} consider unnormalized version. This results in the additional $\frac{1}{|\cD|}$ factor here.
\end{proof}
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

\begin{lemma}[From reward error to Hellinger  Distance]\label{lem:r_err_to_Hellinger}
    Given any policy $\pi$, any reward function $r$ with bounded value range $[-\Rmax,{\Rmax}]$, and another arbitrary $\tpi$ with positive support on $\cS\times\cA$, we have:
    \begin{align*}
        &\EE_{s\sim\rho,a\sim\pi(\cdot|s),\ta\sim\pi_\textref(\cdot|s)}[|\Big(r^*(s,a) - r^*(s,\ta)\Big) - \Big(r(s,a) - r(s,\ta)\Big)|] \\
        \leq & 8\sqrt{2}e^{2{\Rmax}} \sqrt{\cov^{\pi|\tpi} \cdot \EE_{s\sim\rho,a\sim\tpi(\cdot|s),\ta\sim\pi_\textref(\cdot|s)}[\mH^2(\mP_{r}(\cdot|s,a,\ta)\|\mP_{r^*}(\cdot|s,a,\ta))]}.
    \end{align*}
\end{lemma}
\begin{proof}
    For any reward function $r$, we have:
    \begin{align*}
        &\Big|\Big(\EE_{\rho,\pi}[r^*] - \EE_{\rho,\pi_\textref}[r^*]\Big) - \Big(\EE_{\rho,\pi}[r] - \EE_{\rho,\pi_\textref}[r]\Big)\Big| \\
        \leq & \EE_{s\sim\rho,a\sim\pi(\cdot|s),\ta\sim\pi_\textref(\cdot|s)}[|\Big(r^*(s,a) - r^*(s,\ta)\Big) - \Big(r(s,a) - r(s,\ta)\Big)|] \\
        \leq & 4e^{2{\Rmax}} \EE_{s\sim\rho,a\sim\pi(\cdot|s),\ta\sim\pi_\textref(\cdot|s)}[|\sigma\Big(r^*(s,a) - r^*(s,\ta)\Big) - \sigma\Big(r(s,a) - r(s,\ta)\Big)|] \tag{Lem.~\ref{lem:sigmoid} with $C = 2\Rmax$} \\
        = & 4e^{2{\Rmax}} \sum_{s,a,\ta} \sqrt{\rho(s) \pi_\textref(\ta|s)} \frac{\pi(a|s)}{\sqrt{\tpi(a|s)}} \\
        &\quad\quad\quad\quad\qquad\qquad \cdot \sqrt{\rho(s) \pi_\textref(\ta|s)}\sqrt{\tpi(a|s)}\Big|\sigma\Big(r^*(s,a) - r^*(s,\ta)\Big) - \sigma\Big(r(s,a) - r(s,\ta)\Big)\Big| \\
        \leq & 4e^{2{\Rmax}} \sqrt{\sum_{s,a,\ta} \rho(s) \pi_\textref(\ta|s) \frac{\pi^2(a|s)}{\tpi(a|s)}} \\
        &\quad\quad\quad\quad\qquad\qquad \sqrt{\EE_{s\sim\rho,a\sim\tpi(\cdot|s),\ta\sim\pi_\textref(\cdot|s)}[\Big|\sigma\Big(r^*(s,a) - r^*(s,\ta)\Big) - \sigma\Big(r(s,a) - r(s,\ta)\Big)\Big|^2]} \tag{Cauchyâ€“Schwarz inequality} \\
        =& 4e^{2{\Rmax}} \sqrt{\cov^{\pi|\tpi}} \cdot \sqrt{\EE_{s\sim\rho,a\sim\tpi(\cdot|s),\ta\sim\pi_\textref(\cdot|s)}[\Big|\sigma\Big(r^*(s,a) - r^*(s,\ta)\Big) - \sigma\Big(r(s,a) - r(s,\ta)\Big)\Big|^2]} \numberthis\label{eq:eq_ref_2}.
    \end{align*}
    Note that, 
    \begin{align*}
        &\EE_{s\sim\rho,a\sim\tpi(\cdot|s),\ta\sim\pi_\textref(\cdot|s)}[\Big|\sigma\Big(r^*(s,a) - r^*(s,\ta)\Big) - \sigma\Big(r(s,a) - r(s,\ta)\Big)\Big|^2]\\
        \leq & 8 \EE_{s\sim\rho,a\sim\tpi(\cdot|s),\ta\sim\pi_\textref(\cdot|s)}[|\sqrt{\sigma(r^*(s,a) - r^*(s,\ta))} - \sqrt{\sigma(r(s,a) - r(s,\ta))}|^2] \tag{$(x-y)^2 \leq 4(x+y)(\sqrt{x} - \sqrt{y})^2$}\\
        \leq & 8 \EE_{s\sim\rho,a\sim\tpi(\cdot|s),\ta\sim\pi_\textref(\cdot|s)}[\mH^2(\mP_{r}(\cdot|s,a,\ta)\|\mP_{r^*}(\cdot|s,a,\ta))]\numberthis\label{eq:eq_ref_1}.
    \end{align*}
    By plugging into Eq.~\eqref{eq:eq_ref_2}, we finish the proof.
\end{proof}

\begin{lemma}[Sigmoid Function]\label{lem:sigmoid}
    Given $x,y \in [-C, C]$ for some $C > 0$,
    \begin{align*}
        |x - y| \leq 4\exp(C)|\sigma(x) - \sigma(y)|.
    \end{align*}
\end{lemma}
\begin{proof}
    Without loss of generality, we assume $x \geq y$. Because $\sigma(\cdot)$ is a monotonically increasing function and it is continuous, we know there exists $z \in [y, x]$ s.t. 
    \begin{align*}
        \frac{\sigma(x) - \sigma(y)}{x - y} = \sigma'(z) = \sigma(z)(1 - \sigma(z)) = \sigma(z) \sigma(-z).
    \end{align*}
    Because $x,y \in [-C,C]$, we have $\sigma(-C) \leq \sigma(z) \leq \sigma(C)$.
    Note that the axis of symmetry of function $f(a) = a(1-a)$ is $1/2$ and $\frac{1}{2} - \sigma(C) = \sigma(-C) - \frac{1}{2}$. Therefore,
    \begin{align*}
        |x - y| =& \frac{1}{\sigma'(z)}|\sigma(x) - \sigma(y)| \leq (1 + \exp(C))(1 + \exp(-C)) \cdot |\sigma(x) - \sigma(y)| \\
        \leq & 2(1+\exp(C))|\sigma(x) - \sigma(y)| \leq 4\exp(C)|\sigma(x) - \sigma(y)|
    \end{align*}
\end{proof}

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%


%
%
%
%
%
%
%
%
%
%
%
%
%

