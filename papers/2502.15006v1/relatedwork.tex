\section{Related Work}
\noindent\textbf{Sampling-based MPC.} 
Sampling-based MPC has become a popular alternative to traditional MPC methods that use gradient-based solvers, in part due to the advent of parallel computing and the recent advances in GPU hardware.
By not using gradients, sampling-based MPC can be applied to any problem without having specific requirements on the problem structure.
MPPI \cite{InfoMPPI} is a popular sampling-based MPC approach that formulates a variational inference problem, then solves it in the case of the Gaussian distribution, having strong connections to stochastic optimal control \cite{TubeMPPI} and maximum entropy control \cite{so2022maximum}.
Separately, the Cross-Entropy Method (CEM) \cite{rubinstein1999cross} has become popular in the reinforcement learning community \cite{wang2021variational}, in part due to its simplicity.
Both approaches were recently shown to be part of the VIMPC family of MPC algorithms~\cite{okada2020variational}. 
Consequently, some works have looked at expanding the VIMPC family to include different choices of divergences \cite{wang2021variational} and sampling distributions beyond Gaussians \cite{lambert2020stein,okada2020variational}.

\beforetextbf{}

\noindent\textbf{Safety in Sampling-based MPC.}
Research efforts such as \cite{RAMPPI} and \cite{UncertaintyPushingMPPI} assess the risk associated with uncertain areas in the state space during the exploration phase, and enhance MPPI's safety by incorporating a risk penalty into its cost function. 
While these methods empirically enhance safety, they lack formal assurances. 
Another class of MPPI alternatives, for instance, \cite{TubeMPPI, L1Adaptive}, leverage an auxiliary tracking controller to follow the MPPI output trajectories, improving robustness against unforeseeable disruptions, but these improvements are limited when the simulation-to-reality gap is significant. 
More recently, the use of Control Barrier Functions (CBF)~\cite{MPPI-CBF,Shield-MPPI} has offered formal safety guarantees for MPPI controllers. 
Nonetheless, \cite{MPPI-CBF}  is restricted to linear systems with saturating CBFs, and also neglects control input limits. 
This can lead to Gaussian control distributions constrained by a CBF-based chance constraint, increasing the likelihood of local optima due to limited exploration. 
In contrast,~\cite{Shield-MPPI} and ~\cite{yin2024chance} incorporate a CBF into the cost function and resolve a local optimization problem to reinforce CBF safety conditions for more complex nonlinear systems. 
However, the approach in ~\cite{Shield-MPPI} and ~\cite{yin2024chance} uses a distance-based CBF while ignoring the control limits. Our proposed Neural Shield MPPI (NS-MPPI) controller, as a specific form of the proposed NS-VIMPC framework, effectively resolves the critical issues identified in \cite{MPPI-CBF} and \cite{Shield-MPPI}.

\beforetextbf{}

\noindent\textbf{Different Proposal Distributions for VIMPC.}
There are many works that investigate the sampling distribution of VIMPC.
The MPPI variant in~\cite{CCMPPI} uses covariance steering to assign a terminal covariance to the sampling distribution, but this relies on expert knowledge on how the covariance should be designed.
Reference~\cite{power2022variational} learns a normalizing flow to approximate the optimal distribution, but it does not address the problem of recursive feasibility on its own.
Another direction looks at changing the effective sampling distribution by modifying the underlying dynamics system to be more amenable to calculations.
The works \cite{TubeMPPI, L1Adaptive} leverage an auxiliary tracking controller, thus changing the sampling distribution to be the output of the stable tracking controller. However, this requires the construction of such an auxiliary tracking controller, which can be difficult to perform for arbitrary nonlinear discrete-time systems.
In contrast, our proposed resampling-based rollouts (RBR) can be viewed as a way of easily improving the proposal distribution \textit{without} the need for any specialized problem structure.

\beforetextbf{}

\noindent\textbf{Duality between Control and Inference.}
The proposed resampling strategy in our work is similar in spirit to \cite{xie2020factor,qadri2022incopt} in that
factor graphs, a method used originally for estimation, is adapted for control purposes.
In \cite{zhang2023optimal} a linear optimal control was used to improve the performance of particle filters.
However, to the best of our knowledge, our approach is the first to adopt the resampling mechanism from particle filters
to improve the performance of sampling-based MPC controllers.

\beforetextbf{}

\noindent\textbf{Control Barrier Functions.} 
Designing CBFs with control-invariant safe sets is not a trivial task. As a result, previous works only seek saturating CBFs that do not consider input constraints \cite{Robotarium, lindemann2018control, xu2018safe}. Some works use hand-tuned CBFs to prevent saturation \cite{wei2022safe, clark2021verification}, which can lead to overly conservative safe sets. Other works develop CBFs with input constraints for specific types of systems \cite{cortez2022safe, cortez2021robust}. The emerging neural CBFs \cite{zhang2023neural, yu2023sequential, qin2021learning, zhang2024gcbf+} allow for more general dynamics utilizing machine learning techniques; however, they can still saturate the control limits. 
Our novel approach trains a neural CBF, conditioned on the entire system state and accounting for control limits,  so as to discover a large control-invariant set. 
The proposed novel NS-VIMPC control framework utilizes this Neural CBF to improve the efficiency of sampling by redirecting control sequences to previously identified safe states, thereby focusing sampling efforts in secure regions. 
This efficient sampling method will be discussed in detail later in Section~\ref{sec:NSMPPI}. 
 As a result, NS-VIMPC tackles the challenge of exploration versus exploitation by adaptively distributing computational resources, governed by an innovative neural CBF.