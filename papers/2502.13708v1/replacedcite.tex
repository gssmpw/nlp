\section{RELATED WORKS}
\label{sec:related_works}
In the context of robotic navigation, the capability of perceiving the environment by relying only on visual sensors is still one of the most open challenges, especially in complex harsh scenarios.
In the following, we provide a comprehensive literature review on V-SLAM and VO algorithms.
Then, as we propose an active approach, we also provide a literature overview of approaches based on this paradigm. 
Finally, we highlight the contribution of our work.
% , especially regarding robustness and pose accuracy. In the following, we provide a comprehensive literature review on visual SLAM and visual odometry algorithms focusing on harsh scenarios.

% {In recent years, different methods and solutions have evolved according to sensor and computation capabilities advancement.}


\textbf{Visual SLAM and VO.} 
V-SLAM and VO algorithms have been actively explored and improved from the first works ____ and ____. ORB-SLAM3 ____ and LDSO ____ represent milestones in the State-of-the-Art for feature-based and direct methods, respectively. Afterwards, the exploitation of depth cameras and Inertial Measurement Units (IMU) lead to Visual-Inertial (VI) methods, like MSCKF ____, OKVIS ____, VINS-Mono ____, and OPEN-VINS ____. 
%use nonlinear filters like the Extended Kalman Filter (EKF) to fuse visual and inertial information ____, as well as 3D map optimization techniques ____.
Despite the advancements in accuracy and overall robustness, harsh illumination conditions are still an open challenge ____. One critical element is the dependence on ideal illumination to perceive sufficient environmental information ____. 

Deep Learning (DL) approaches leverage Convolutional Neural Networks (CNNs) to mitigate the non-ideal conditions: they can compute features invariant to geometric and photometric changes, including illumination, background, viewpoint, and scale ____. These techniques are exploited by end-to-end approaches that can be easily adapted
to different setups (monocular, stereo, and RGB-D) such as DROID-SLAM ____ that leverage on recurrent iterative updates of camera pose and pixel-wise depth through a Dense Bundle Adjustment layer. Other approaches take advantage of Graph Convolutional Neural Networks (GCNs)  and RGB-D sensors ____. Hybrid approaches like DXSLAM ____ use DL-based methods for extracting features, which are then integrated into geometric VO/SLAM. 
However, no works consider low-light environments except for some adaptations for underwater applications ____ that cannot be used in the context of ground robotics.


%a seminal study of the effectiveness of Hybrid approach is presented in \textcolor{blue}{[LF$^2$SLAM]}. The study proposed in \textcolor{blue}{[Lavoro ORBSLAM vs. DSO]} indicates that the combined use of different light intensities and processing images with an enhancing GAN network would dramatically impact performance in pose estimation.


\textbf{Active Approaches in low-light Conditions.}
Dealing with dark scenarios by only equipping the robotic platform with static light sources poses severe constraints on the effectiveness of V-SLAM methods, especially in challenging environments where the features are not uniformly distributed in the scene. Conversely, an active lighting approach that exploits the movement of the light source could significantly improve the performance of the vision-based algorithms. %in dark conditions. 

In general, the use of an active perception system ____ consists of leveraging the movement of the robot to actively acquire data from the environment to obtain information more relevant to the specific task. 
The literature presents classical and learned approaches for the design of the active controller. Classical approaches are often based on information-driven systems ____ to guide the visual algorithm toward more informative regions. On the other hand, learned ones mostly rely on Deep Reinforcement Learning (DRL) ____ to train suitable end-to-end policies that directly map input data to control actions. While the latter strategies achieved impressive performance results, they lack robustness, which is more crucial in challenging scenarios like the one considered here. Consequently, the few contributions that propose an active method in this setting are all information-driven.

% \textcolor{red}{
% Considering only stationary anchors poses severe limitations on the applicability of such methods. On the other hand, in more challenging scenarios where each platform can be moved independently, an active approach could considerably enhance the localization performance in an infrastructure-less setting.
% Active perception systems ____ take advantage of the robot motion in order to \textit{actively} acquire data from the environment and obtain more useful information with respect to the specific task of interest.}

% \textcolor{red}{To deal with this complex decision-making problem, recent studies are using Deep Reinforcement Learning approaches to train control policies suitable for active tasks ____, achieving remarkable results in terms of generalization, performance, and robustness. Among these, the problem of active localization was also considered. In ____, the authors address the global localization problem on an \textit{occupancy-grid} map with an active approach driven by DRL. The method employs RGB images for localization and the goal of the policy is to move the robot to acquire the views of the environment that better disambiguate its position in the map. The method shows remarkable performance on mazes, however, several assumptions limit its applicability in real-world scenarios. These drawbacks are addressed in ____ where the authors improve the previous approach and test their policy on a real robotic platform. Recently, the focus has shifted to active SLAM ____, which uniÔ¨Åes the localization and the mapping problems. The goal is to actively control a robot performing SLAM to reduce both the uncertainty in its localization and the representation of the map.}

% When using an active light source to compensate for the lack of light, it is possible to deal with camera parameters ____; nevertheless, changing sensor parameters (i.e., shutter speed, sensor sensitivity) or lens aperture leads to a higher level of noise, a drop in FPS, as well as losing focus, which would interfere with pose estimation activities.

The authors in ____  propose a novel automated camera-exposure control algorithm to enhance vision-based localization in complex environments with dynamic illumination. However, dynamically changing the exposure or, in general,  sensor parameters (\textit{i.e.}, shutter speed, sensor sensitivity) could lead to a higher level of noise and/or a drop in frame rate ____, which can negatively impact vision algorithms. The work in ____ adopts near-infrared (NIR) light for visual SLAM in challenging lighting conditions, achieving promising results. Nevertheless, NIR images might exhibit less texture than visible light images, particularly in low-texture environments. Additionally, the requirement for specialized NIR devices and the reliance on depth sensors can limit the applicability of this approach.


% Additionally, in very low light conditions, the frame rate could drop to very low values, further affecting the performance. 
In ____, a gimbal camera is used as an active device to enhance V-SLAM accuracy and robustness in challenging environments. In particular, the authors introduce a map representation based on feature distribution-weighted Fisher information coupled with an information-gradient-based local view planner to move the camera view for obtaining maximal environmental information. Nevertheless, only environments with poor features are considered, while dark or low-light conditions are not considered.


% \textcolor{red}{Automatic explosure ____ could be considered an active approach for adapting the camera to scenarions charcterized by varing lighting conditions. However, when ... . }


% \textcolor{red}{ This article ____ develops a novel view planning ap
% proach of actively perceiving areas with maximal informa
% tion to address the mentioned problem; a gimbal camera is
 % used as the main sensor. }

 \begin{figure*}[t]
     \centering
     \includegraphics[width=\linewidth]{Include/Images/method_new.png}\\
     \caption{The image depicts the proposed active illumination framework, designed to enhance the performance of VO and V-SLAM algorithms in low-light environments. The framework employs two parallel image streams: a high-rate stream for real-time V-SLAM processing and a low-rate stream for feature analysis. The low-rate stream is enhanced by EnlightenGAN and then processed by the Feature Focus Block to identify areas rich in visual features. This information guides a 2-axis moving light source to dynamically illuminate these areas, ensuring the high-rate V-SLAM pipeline receives images with improved feature visibility. The adaptive illumination strategy increases the accuracy and robustness in challenging low-light conditions.}
     %This adaptive illumination strategy aims to bolster V-SLAM robustness and accuracy in challenging lighting conditions.
     \label{fig:framework_overview}
     \vspace{-1em}
\end{figure*}


\subsection{Contributions}
Although active approaches have shown significant results in enhancing the performance of visual algorithms in challenging environments, to the best of our knowledge, no previous work has proposed an active strategy specifically tailored for low-light conditions. Therefore, we introduce a new framework that incorporates a novel information-driven active approach capable of illuminating areas with high feature density. Specifically:

% \textcolor{red}{While important results have been demonstrated by active approaches for enhancing the performance of visual algorithms in challenging environments, to the best of our knowledge there are no previous works that proposed an active strategy specifically tailored for low-light conditions. Consequently, we present a new framework that incorporates a novel information-driven with a moving light source to illuminate areas with an high feature density. Specifically:}
%Thanks to the developed active methodologies, all the aforementioned works contributed with important improvements in terms of localization performance. However, since UWB-based infrastructure-less relative localization systems {\color{blue}are only recently emerging}, to the best of our knowledge there are not in literature active approaches specifically tailored for this task. Therefore, in this work we present multiple contributions:

\begin{itemize}
    \item We design a novel method to dynamically identify in low-light conditions the portion of the image that contains the highest number of features;
    \item We propose a new information-driven active method that controls a movable light source in order to illuminate texture-rich areas of the environment;
    \item We build a robotic platform equipped with a controllable light source, and through extensive real-world experiments, we demonstrate that our approach significantly outperforms the current state-of-the-art methods.
\end{itemize}