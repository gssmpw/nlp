\section{Related Work}
% \paragraph{Early tree modeling}
\noindent\textbf{Early tree modeling.}
Early studies employed fractals and repetitive structures~\cite{smith1984plants}, L-systems~\cite{lindenmayer1968mathematical,prusinkiewicz1986graphical, prusinkiewicz2012algorithmic}, particle systems~\cite{reeves1985approximate, neubert2007approximate}, and biological growth rules \cite{de1988plant}. 
The influence of physical and environmental conditions on the tree structure has also been taken into account, considering biomechanical properties \cite{Zhao2013,10.1145/3072959.3073655,Maggioli23}, fire~\cite{Pirk:2017}, wind~\cite{Pirk14ToG,Shao:2021:GraphLearning}, and climate \cite{10.1145/3528223.3530146}. The modeling of root systems has also been addressed for a variety of trees \cite{Li:2023:Rhizomorph}. On another trajectory, modeling large ecosystems \cite{makowski2019synthetic} has been addressed, as well as the simulation of devastating wildfires \cite{Haedrich:2021:Wildfires,Kokosza:2024:Scintilla} within these systems.
A related problem is inverse procedural modeling, which aims to encode given inputs as a procedural model~\cite{stava2014inverse,guo2020inverse}.


% Similarly, Lewis~\cite{lewis1999three} developed a three-dimensional plant modeling system aimed at simulating trees for remote sensing applications.
\noindent\textbf{Tree modeling using deep learning.}
% \paragraph{Tree modeling using deep learning}
Advancements in deep learning have facilitated significant progress in tree generation, ranging from tree reconstruction from images \cite{Li:2021:ReconstructBotanicalTrees} to the use of transformer architectures to generate L-system grammars~\cite{lee2023latent}. As relying on the syntax of the L-system restricts precise control over intricate details in generated structures, Zhou et al.~\cite{zhou2023deeptree} explore deep learning for tree generation by focusing on the local context. However, their approach mainly considers the parent nodes and lacks comprehensive global structural awareness. Lee et al.~\cite{lee2025tree} introduce a dataset and employ diffusion models to generate trees from a single image. Similarly, Li et al.~\cite{li2024svdtree} utilize voxel-based diffusion to produce coarse semantic representations for tree reconstructions from single-view images. 

% Du et al.~\cite{du2019adtree} presented Adtree, an accurate and automatic modeling system for laser-scanned trees, enhancing the precision of tree reconstructions from point cloud data.

% Furthermore, Palubicki et al.~\cite{palubicki2009self} developed self-organizing tree models for image synthesis, allowing for more dynamic and adaptable tree representations. McQuillan et al.~\cite{mcquillan2018algorithms} proposed algorithms for inferring context-sensitive L-systems, improving the flexibility and applicability of L-system-based models in diverse scenarios.

These deep learning-based methods generally depend on indirect representations, such as L-systems or voxel-based diffusion techniques, which limit their ability to exert fine-grained control over tree structures. In contrast, our approach seeks to bridge this gap by investigating a native representation of trees, thereby facilitating more effective and detailed control over the generated models.


\noindent\textbf{3D generative modeling.}
% \paragraph{3D generative modeling}
Generative models have made significant advancements, evolving from variational autoencoders (VAEs) \cite{kingma2013auto} and generative adversarial networks (GANs)~\cite{10.1145/3422622} to diffusion models~\cite{song2020score, ho2020denoising, Na:2024:LennardJonesLayer} and autoregressive models~\cite{esser2021taming}. 
%These models have been instrumental in generating high-quality data across various domains.
In 3D data generation, early approaches utilized voxel-based representations~\cite{voxelhane2017hierarchical}, which suffer from high memory consumption and limited resolution. Point cloud-based methods~\cite{luo2021diffusion} are more efficient but lack explicit surface connectivity. Implicit field-based models~\cite{chen2019learning, zhang20233dshape2vecset,zhang2024lagem} represent 3D shapes as continuous functions, enabling high-resolution surface reconstruction but often requiring complex post-processing to extract meshes. Mesh-based generative models aim to generate 3D meshes with explicit surface representations directly~\cite{chen2020bsp,alliegro2023polydiff}. 
% BSP-Net \cite{chen2020bsp} represents shapes using Binary Space Partitioning trees but is limited in handling complex topologies. 
% PolyGen~\cite{nash2020polygen} models triangle meshes autoregressively by sequentially generating vertices and faces, which can be computationally intensive. PoliDiff~\cite{alliegro2023polydiff} introduces discrete diffusion for mesh generation, improving sample quality but still facing limitations in mesh complexity.

Autoregressive transformer-based methods such as MeshGPT \cite{siddiqui2024meshgpt}, LLaMA-Mesh~\cite{wang2024llama}, MeshXL~\cite{chen2024meshxl}, PivotMesh~\cite{weng2024pivotmesh}, and others have been proposed to improve mesh generation by predicting mesh elements using self-attention. MeshAnything ~\cite{chen2024meshanything} and MeshAnythingV2 ~\cite{chen2024meshanything2}, and EdgeRunner~\cite{tang2024edgerunner} implement mesh generation conditioned on point clouds. However, when performing unconditional generation, most of these methods can only generate meshes with 800 to 1600 faces, which is insufficient for modeling complex structures like trees.
%
Our approach addresses this limitation by proposing a representation more suitable for tree modeling. Leveraging the properties of this representation, we propose to use an hourglass transformer architecture~\cite{nawrot2021hierarchical,hao2024meshtron} to achieve higher efficiency and generate detailed meshes with significantly more faces, capturing the intricate structures of trees more effectively.