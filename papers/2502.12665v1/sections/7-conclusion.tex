\section{Conclusion}
In this paper, we propose {\name}, a novel retrieval-based KV cache reduction method.
First, we propose Windowed Rotary Position Embedding to decouple the positional dependency from query and key states after position embedding.
Then, we propose query-aware vector quantization to achieve an accurate attention score approximation.
Next, we introduce the heterogeneous inference design for KV cache offloading
% , which can reduce data transfer.
which increases available batch size.
Experimental results demonstrate that {\name} achieves lower performance degradation with comparable or lower overhead compared to existing methods, thereby boosting long context serving throughput by up to \(2.7 \times\).
% Finally, we evaluate {\name} extensive experiments and show that {\name} can achieve a lower performance degradation with similar or lower overhead compared to existing methods, thereby increasing long context serving throughput by up to \(2.7 \times\).