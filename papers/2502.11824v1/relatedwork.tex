\section{Background and Related Work}
\subsection{UABSA and TASD Tasks}
In the current work, we mainly cover two types of mainstream ABSA tasks, from UABSA to TASD. 

\paragraph{Unified ABSA (UABSA)} is a basic form of ABSA tasks. It extracts aspect terms and predicts their sentiment polarities \cite{li2019unified, Chen_Qian_2020, zhang-etal-2021-towards-generative}. It can also be formulated as an (\textit{aspect term, sentiment polarity}) pair extraction problem \cite{zhang-etal-2021-towards-generative}. For the example ``\textit{The service was great, but the food was bad.}'', it aims to extract two pairs: (\textit{service, positive}) and (\textit{food, negative}). 

\paragraph{Target-Aspect-Sentiment Detection (TASD)} is an extended task for UABSA with an additional aspect category, which belongs to a pre-defined category set. It aims to detect all (\textit{aspect term, aspect category, sentiment polarity}) triplets for a given sentence \cite{wan2020target, zhang-etal-2021-towards-generative}. For the same example sentence in the previous paragraph, it should extract the triplets: (\textit{service, service\#\#general, positive}) and (\textit{food, food\#\#quality, negative}), where the ``\textit{service\#\#general}'' and ``\textit{food\#\#quality}'' correspond to the categories of the respective aspect terms. 



\subsection{Current Multilingual ABSA Datasets} 
Research in multilingual ABSA has been constrained by limited datasets, with most focusing on English. SemEval workshops introduced early datasets for restaurant and laptop reviews \citep{pontiki-etal-2014-semeval, pontiki-etal-2015-semeval}, later expanding to Chinese, Turkish, and Spanish \citep{pontiki-etal-2016-semeval}. Other efforts, like GermEval-2017 for German \citep{wojatzki2017germeval}, ABSITA-2020 for Italian \citep{de2020ate}, SemEval-2023 for African languages \citep{muhammad2023semeval}, and Polish-ASTE \cite{lango-etal-2024-polish}, added linguistic diversity but often focused on sentence-level analysis. Recent datasets like ROAST extended coverage to two other low-resource languages, Hindi and Telugu, and incorporated review-level ABSA analysis across multiple domains \citep{chebolu2024roast}. Despite these advances, existing datasets lack broad domain coverage, linguistic variety, and parallelism essential for robust multilingual evaluation. Also, current datasets limit in standardization and diversity to make it possible for broader model robustness checks \cite{chebolu-etal-2023-review}. Therefore, broadening the variety of ABSA datasets is crucial for advancing both research and applications.


\begin{figure*}[htbp] 
\centering 
\includegraphics[width=1\linewidth]{figs/annotation.pdf} 
\caption{The construction process of the M-ABSA dataset.} 
\label{fig:construction_process} 
\end{figure*}

\subsection{Methods for Multilingual ABSA}
Early multilingual ABSA methods rely on supervised learning with annotated data, using translation systems and alignment algorithms for cross-lingual label projection \citep{lin2014cross, klinger2015instance, lambert2015aspect, barnes2016exploring}. However, these methods struggle with scalability and translation quality \citep{zhou2015clopinionminer}. Subsequent works leverage cross-lingual word embeddings trained on parallel corpora to align representations across languages, enabling language-agnostic ABSA \citep{barnes2016exploring, wang2018transition}. Multilingual pre-trained language models
% like mBERT \citep{devlin2018bert} and XLM-R \citep{conneau2019unsupervised} 
further improved performance through fine-tuning and data augmentation \citep{xu2019bert, phan2021exploring}. More recently, large language models have been explored for zero-shot multilingual ABSA \citep{wu2024evaluating}. Although these models offer scalability, they still fall short of fine-tuned models in low-resource scenarios. In this work, we evaluate basic baselines on our curated multilingual dataset, establishing a new benchmark to support future ABSA research.