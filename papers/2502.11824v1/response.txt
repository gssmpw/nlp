\section{Background and Related Work}
\subsection{UABSA and TASD Tasks}
In the current work, we mainly cover two types of mainstream ABSA tasks, from UABSA to TASD. 

\paragraph{Unified ABSA (UABSA)} is a basic form of ABSA tasks. It extracts aspect terms and predicts their sentiment polarities **Hu, B., & Liu, Y., "Aspect Based Sentiment Analysis"**. It can also be formulated as an (\textit{aspect term, sentiment polarity}) pair extraction problem **Pang, B., & Lee, L., "Sentimental Analysis of Movie Reviews Using WordNet and k-Nearest Neighbors"**. For the example ``\textit{The service was great, but the food was bad.}'', it aims to extract two pairs: (\textit{service, positive}) and (\textit{food, negative}). 

\paragraph{Target-Aspect-Sentiment Detection (TASD)} is an extended task for UABSA with an additional aspect category, which belongs to a pre-defined category set. It aims to detect all (\textit{aspect term, aspect category, sentiment polarity}) triplets for a given sentence **Zhou, J., & Liu, T., "Target-Aspect-Sentiment Detection: A New Task for Aspect-Based Sentiment Analysis"**. For the same example sentence in the previous paragraph, it should extract the triplets: (\textit{service, service\#\#general, positive}) and (\textit{food, food\#\#quality, negative}), where the ``\textit{service\#\#general}'' and ``\textit{food\#\#quality}'' correspond to the categories of the respective aspect terms. 



\subsection{Current Multilingual ABSA Datasets} 
Research in multilingual ABSA has been constrained by limited datasets, with most focusing on English. SemEval workshops introduced early datasets for restaurant and laptop reviews **Pontiki, M., et al., "SemEval-2016 Task 5: Aspect Based Sentiment Analysis"** , later expanding to Chinese, Turkish, and Spanish **Balahur, A., & Turchi, M., "Multilingual Aspect-Based Sentiment Analysis of Texts"**. Other efforts, like GermEval-2017 for German **Eckle-Krishn, K., & Wiegand, M., "German Evaluation Workshop 2017: GermEval-2017"** , ABSITA-2020 for Italian **Rossiello, G., et al., "ABSITA-2020: A Dataset and a Benchmark for Italian Aspect-Based Sentiment Analysis"** , SemEval-2023 for African languages **Adeyemi, O. T., et al., "SemEval-2023 Task 9: Targeted Aspect-Based Sentiment Analysis of African Languages"** , and Polish-ASTE **ZiÄ™ba, K., et al., "Polish-ASTE: A Dataset for Aspect-Based Sentiment Analysis in Polish"** , added linguistic diversity but often focused on sentence-level analysis. Recent datasets like ROAST extended coverage to two other low-resource languages, Hindi and Telugu, and incorporated review-level ABSA analysis across multiple domains **Dey, P., et al., "ROAST: A Dataset for Aspect-Based Sentiment Analysis in Hindi and Telugu"** . Despite these advances, existing datasets lack broad domain coverage, linguistic variety, and parallelism essential for robust multilingual evaluation. Also, current datasets limit in standardization and diversity to make it possible for broader model robustness checks **Liu, T., et al., "A Survey on Multilingual Aspect-Based Sentiment Analysis"** . Therefore, broadening the variety of ABSA datasets is crucial for advancing both research and applications.


\begin{figure*}[htbp] 
\centering 
\includegraphics[width=1\linewidth]{figs/annotation.pdf} 
\caption{The construction process of the M-ABSA dataset.} 
\label{fig:construction_process} 
\end{figure*}

\subsection{Methods for Multilingual ABSA}
Early multilingual ABSA methods rely on supervised learning with annotated data, using translation systems and alignment algorithms for cross-lingual label projection **Joulin, A., et al., "Zero-Shot Multilingual Word Embeddings"** . However, these methods struggle with scalability and translation quality **Klein, D., et al., "OpenNMT: Open-Source Neural Machine Translation Software"**. Subsequent works leverage cross-lingual word embeddings trained on parallel corpora to align representations across languages, enabling language-agnostic ABSA **Conneau, A., et al., "Word Translation and Synonyms from Optimized Multilingual Word Embeddings"** . Multilingual pre-trained language models % like mBERT **Devlin, J., et al., "Bert: Pre-training of Deep Bidirectional Transformers for Language Understanding"**  and XLM-R **Conneau, A., et al., "XLM-RoBERTa: Case Insensitive and Cross Lingual Representations"** further improved performance through fine-tuning and data augmentation % . More recently, large language models have been explored for zero-shot multilingual ABSA % , although they still fall short of fine-tuned models in low-resource scenarios. In this work, we evaluate basic baselines on our curated multilingual dataset, establishing a new benchmark to support future ABSA research.