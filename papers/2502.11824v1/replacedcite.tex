\section{Background and Related Work}
\subsection{UABSA and TASD Tasks}
In the current work, we mainly cover two types of mainstream ABSA tasks, from UABSA to TASD. 

\paragraph{Unified ABSA (UABSA)} is a basic form of ABSA tasks. It extracts aspect terms and predicts their sentiment polarities ____. It can also be formulated as an (\textit{aspect term, sentiment polarity}) pair extraction problem ____. For the example ``\textit{The service was great, but the food was bad.}'', it aims to extract two pairs: (\textit{service, positive}) and (\textit{food, negative}). 

\paragraph{Target-Aspect-Sentiment Detection (TASD)} is an extended task for UABSA with an additional aspect category, which belongs to a pre-defined category set. It aims to detect all (\textit{aspect term, aspect category, sentiment polarity}) triplets for a given sentence ____. For the same example sentence in the previous paragraph, it should extract the triplets: (\textit{service, service\#\#general, positive}) and (\textit{food, food\#\#quality, negative}), where the ``\textit{service\#\#general}'' and ``\textit{food\#\#quality}'' correspond to the categories of the respective aspect terms. 



\subsection{Current Multilingual ABSA Datasets} 
Research in multilingual ABSA has been constrained by limited datasets, with most focusing on English. SemEval workshops introduced early datasets for restaurant and laptop reviews ____, later expanding to Chinese, Turkish, and Spanish ____. Other efforts, like GermEval-2017 for German ____, ABSITA-2020 for Italian ____, SemEval-2023 for African languages ____, and Polish-ASTE ____, added linguistic diversity but often focused on sentence-level analysis. Recent datasets like ROAST extended coverage to two other low-resource languages, Hindi and Telugu, and incorporated review-level ABSA analysis across multiple domains ____. Despite these advances, existing datasets lack broad domain coverage, linguistic variety, and parallelism essential for robust multilingual evaluation. Also, current datasets limit in standardization and diversity to make it possible for broader model robustness checks ____. Therefore, broadening the variety of ABSA datasets is crucial for advancing both research and applications.


\begin{figure*}[htbp] 
\centering 
\includegraphics[width=1\linewidth]{figs/annotation.pdf} 
\caption{The construction process of the M-ABSA dataset.} 
\label{fig:construction_process} 
\end{figure*}

\subsection{Methods for Multilingual ABSA}
Early multilingual ABSA methods rely on supervised learning with annotated data, using translation systems and alignment algorithms for cross-lingual label projection ____. However, these methods struggle with scalability and translation quality ____. Subsequent works leverage cross-lingual word embeddings trained on parallel corpora to align representations across languages, enabling language-agnostic ABSA ____. Multilingual pre-trained language models
% like mBERT ____ and XLM-R ____ 
further improved performance through fine-tuning and data augmentation ____. More recently, large language models have been explored for zero-shot multilingual ABSA ____. Although these models offer scalability, they still fall short of fine-tuned models in low-resource scenarios. In this work, we evaluate basic baselines on our curated multilingual dataset, establishing a new benchmark to support future ABSA research.