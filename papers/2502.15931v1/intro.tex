% !TEX root = ./main_arxiv.tex
\section{Introduction}

% \ajcomment{Mainly I want to write more about the effects of multiple strategic actors, cite some real world examples, etc.}

Over the past decade, social media has experienced rapid growth in both usage and significance. Online social networks, which allow users to share updates about their lives and opinions with a broad audience instantaneously, are now utilized by billions of people globally. These platforms serve various purposes, such as being informed about politics, news, health-related updates, products, and many more \citep{backstrom2012four,young2006diffusion,banerjee2013diffusion,shearer2021news}. 

Unfortunately, networks can induce polarization, with the network connections serving as a pathway for social discord to increase \cite{musco2018minimizing,chen2021adversarial,wang2024relationship,gaitonde2020adversarial}. This is a well-studied sociological phenomenon called the \textit{filter-bubble theory} \citep{pariser2011filter}. The filter-bubble theory argues that personalized algorithms used by online platforms, such as search engines and social media, selectively display content that aligns with a user's past behaviors, preferences, and beliefs. This customization creates an \textit{``invisible algorithmic editing''} of the web, isolating individuals within their own ideological bubbles where they encounter only information that reinforces their existing views. As a result, users are less likely to be exposed to diverse perspectives, potentially narrowing their worldview and fostering polarization. \citet{pariser2011filter} warns that such bubbles undermine democratic discourse by limiting opportunities for individuals to engage with challenging or unfamiliar ideas.
% \ajcomment{We might want to de-emphasize polarization if we go with a different framing around economics and market competition. For now I like this though.}

Additionally, social networks can be manipulated by malicious entities in order to create discord and cause disagreement. For instance,  the 2017 indictment of the Russian Internet Research Agency (IRA) by the U.S. Department of Justice Special Counsel’s Office alleged that the IRA leveraged multiple social media accounts and targeted advertising to achieve \textit{``a strategic goal to sow discord in the U.S. political system, including the 2016 U.S. presidential election''} \citep{mueller2018united}. In 2019, \citet{twitter2019hongkong} disclosed that at least 936 accounts attempted to induce discord in Hong Kong, to e.g. hinder protesters’ ability to organize effectively during the independence movement. As social media continues to proliferate, it is likely that these types of external interferences will become increasingly common. Additionally, networks of Facebook pages have targeted Americans with sports betting scams, amplifying their reach by disseminating provocative conspiracy theories about political figures and natural disasters \citep{wired2024profiteers}. These schemes leverage the economics of the internet, where engagement with inflammatory content is monetized, and social media algorithms inadvertently amplify such content, enabling bad actors to exploit audiences for profit.

To model the opinions' evolution, computer scientists, sociologists, and statisticians have relied on the framework of \emph{opinion dynamics} where the users' opinions coevolve according to a weighted network $G = (V, E, w)$, and each user updates their opinion as a combination of their own intrinsic opinion as well as the opinions of their neighbors \citep{Friedkin1990}. This model of opinion exchange has the advantage of taking into account both network interactions and their own intrinsic opinion. So far, all of the existing works consider a single actor who has the ability to act on the network to induce disagreement or polarization \cite{musco2018minimizing,chen2021adversarial,wang2024relationship,tsourakakis-2024,gaitonde2020adversarial,racz2023towards,Chitra2020}.  

\begin{figure}
    \centering
    \includegraphics[height=2in]{figures/karate_club_1.pdf}
    \includegraphics[height=2in]{figures/karate_club_4.pdf}

    \caption{Visualization of the strategic equilibrium ($\bz^\prime$) on the Karate Club Graph for two different choices of $S$. The truthful intrinsic opinions have been taken to be $\bs = \bu_2$ where $\bu_2$ is the Fiedler eigenvector of $G$. The white nodes correspond to the nodes in $S$. For the other nodes, the nodes colored in blue (resp. red) correspond to nodes whose public opinion $\bz^\prime_i$ increased (resp. decreased), i.e., $(\bz^\prime_i - \bz_i) / \bz_i \ge 0$ (resp. $(\bz^\prime_i - \bz_i) / \bz_i < 0$) after $\bs'$ was chosen.}
    \label{fig:visualization}
\end{figure}

In this work, we lift the assumption of requiring a single actor (such as the platform) to act as an adversary to induce polarization or disagreement and consider the case of several decentralized actors. It is known that empirically, a very small percentage ($25\%$) of the users in a network need to disagree to sway consensus \citep{centola2018experimental}. Moreover, real-world social networks involve {\em multiple } malicious actors, who use different levels of manipulation and hate speech based on their individual goals~\citep{wired2024profiteers}. In this paper, we attempt to provide a theoretical basis for this phenomenon: specifically, in our setting, we assume that there is a set $S \subseteq V$ of strategic agents whose goal is to report false intrinsic opinions ($\bs'$) that are different from their true intrinsic opinions ($\bs \neq \bs'$). Their goal is to influence others while not deviating much from their neighbors; namely, they want to reach an equilibrium where their neighbors agree with them. 

For instance, assume a social network where a set of $S$ of political actors want the network to believe that their stance on a topic (e.g., abortion, elections, drug legalization, etc.) is the best. They achieve this by adversarially reporting different intrinsic opinions. This ensures that their influence is both persuasive and credible within the local network context. Such adversarial behavior can result in significantly different (cf. \cref{fig:visualization}) and highly polarized equilibria, where the strategic agents' opinions appear dominant despite not reflecting the actual intrinsic views of the majority. 

Our work investigates the conditions under which these strategic manipulations are successful, the extent of their impact on network-wide opinion dynamics, and how platforms can learn from observing these manipulated equilibria to mitigate such impacts.
%This corresponds to learning the set of strategic actors. 

\subsection{Our Contributions}

In this paper, we ask the following research question (RQ): 

\begin{quote}
    \textit{\textbf{(RQ)} What if a set of strategic actors with \textbf{possibly conflicting goals} tries to manipulate the consensus by strategically reporting beliefs different than their true beliefs?}
\end{quote}
 

We rely on the Friedkin-Johnsen (FJ) model \citep{Friedkin1990}, where the opinions of agents coevolve via the help of a weighted undirected network $G = (V = [n], E, w)$ with non-negative weights. According to the FJ model, the agents possess intrinsic opinions $s$ and express opinions $z$, which they update via the following rule for each agent $i$:  

\begin{equation}\label{eq:fj_dynamics}
    \bz_i(t + 1) = \frac {\alpha_i \bs_i + (1 - \alpha_i) \sum_{i \sim j} w_{ij} \bz_j(t)} {1 + \sum_{i \sim j} w_{ij}}.
\end{equation}

where $\alpha_i \in (0, 1)$ is $i$'s susceptibility to persuation \citep{abebe2018opinion}. We additionally define $\Tilde \alpha_i = \alpha_i / (1 - \alpha_i)$ to be the normalized susceptibility parameter corresponding to $i$. This update rule corresponds to the best-response dynamics arising from minimizing the quadratic cost function for each $i$ \citep{bindel2011,abebe2018opinion}:

\begin{equation} \label{eq:cost_fcn}
    c_i(\bz_i, \bz_{-i}) = (1 - \alpha_i) \sum_{i \sim j} w_{ij} (\bz_i - \bz_j)^2 + \alpha_i (\bz_i - \bs_i)^2.
\end{equation}

The Pure Strategy Nash Equilibrium (PSNE) can be written as $z = ((I - A)L + A)^{-1} A \bs = B \bs$ where $L$ is the Laplacian of graph $G$, $A = \mathrm{diag}(\alpha_1, \dots, \alpha_n)$ is the diagonal matrix of susceptibilities. When an external \textit{single actor aims to induce disagreement or polarization} -- see, e.g., \citet{gaitonde2020adversarial,racz2022towards,musco2018minimizing} -- the adversary is coined with optimizing the objective function 

\begin{equation*}
    \sum_{i \in [n]} c_i(\bz_i, \bz_{-i}) = \bs^T ((I - A)L + A)^{-1} A f(L) ((I - A)L + A)^{-1} A \bs,
\end{equation*}

where $f(L)$ is a function of the Laplacian of $G$, either with optimizing towards $\bs$ \citep{gaitonde2020adversarial}, or the graph itself \citep{musco2018minimizing,racz2022towards}. 

Usually, as we also discussed earlier, many adverse actions on social networks come from \textit{several independent strategic adversaries} who try to manipulate the network by infiltrating intrinsic opinions $\bs_i^\prime$, which are different from their true stances $\bs_i$ but are simultaneously close to $\bs_i$. Unlike previous works, these ``adversaries'' can have conflicting goals. 
\renewcommand{\bs}{\bm{s}}
\renewcommand{\RR}{\mathbb{R}}

Concretely, the true opinions of the agents are $\bs_1, ..., \bs_n \in \RR$, and there is a set $S$ of deviating agents who report $\{ \bs_i^\prime \}_{i \in S}$. 
The goal of the strategic agents is to minimize the cost function of \cref{eq:cost_fcn} at consensus $z^\prime = ((I - A)L + A)^{-1} A \bs^\prime$ where $\bs^\prime$ 
is the vector which has entries $\bs_i$ for all $i \notin S$ and $\bs_i^\prime$ for all $i \in S$. The local optimization of agent $i$ becomes:

\begin{equation} \label{eq:strategic_cost}
    \min_{\bs_i^\prime \in \RR} c_i \left (\bz^\prime = ((I - A)L + A)^{-1} A \bs^\prime \right ).
\end{equation}


\noindent Our {contributions} are as follows. 

\paragraph{Characterizing Nash Equilibria with Multiple Adversaries.} We give the Nash equilibrium of the game defined by \cref{eq:strategic_cost}, and show that all Nash-optimal strategies are pure. The Pure Strategy Nash Equilibrium (PSNE) that is given by solving a constrained linear system. Given the PSNE of the game, we characterize the actors who can have the most influence in strategically manipulating the network. 

% In the case of one deviator ($|S| = 1$) we show that the optimal strategic opinion $\bs_i^\prime$ is a linear function of the true opinion $\bs_i$. 

% The effect size depends on the diagonal entries of the equilibrium matrix $B$, and the bias depends on the equilibrium matrix, as well as the vector of internal opinions $\bs$, the weights of edges adjacent to $i$, and the susceptibility parameters $\alpha_j$ of the agents. 

\paragraph{Real-World Experiments to Understand Properites of Equilibria.} We apply our framework to real-world social network data from Twitter and Reddit \citep{Chitra2020}, and data from the Political Blogs (Polblogs) dataset \citep{adamic2005political}. We find that the influence of strategic agents can be rather significant as they can significantly increase polarization and disagreement, as well as increase the overall ``cost'' of the consensus. 

\paragraph{Analysis of Equilibrium Outcomes Under Different Sets of Strategic Actors.} Various metrics for network polarization and disagreement are sensitive to the choice of {\em who} acts strategically, in nontrivial ways. For example, adding more strategic agents can sometimes {\em decrease} the Disagreement Ratio at equilibrium (Figure~\ref{fig:ratios_number_of_deviators}), due to  counterbalancing effects. 
To address the effects of manipulation, we give worst-case upper bounds on the \textit{Price of Misreporting} (PoM), which is analogous to well-studied Price of Anarchy bounds (see, for example, \citet{bhawalkar2013,roughgarden2011local}), and suggest ways that the platform can be used to mitigate the effect of strategic behavior on their network. 

\paragraph{Learning Algorithms for the Platform.} We give  an efficient algorithm for the platform to detect if manipulation has occurred (Algorithm~\ref{alg:hypothesis_testing}), based on a hypothesis test with the publicly reported opinions $\bz^\prime$. Next, we give an algorithm to infer {\em who} manipulated the network (the set of strategic agents $S$)  from $\bz^\prime$, as long as the size of $S$ is sufficiently small. Our algorithm is inspired by the robust regression algorithm of \citet{torrent-2015}, and is practical for real-world networks. It  \textit{(i)} requires the platform to have access to node embeddings $X$ which have been shown computable even in billion-scale networks such as Twitter \citep{el2022twhin}, and \textit{(ii)} can be computed in time $(n + m)^{O(1)}$, where $n$ is the number of nodes and $m$ is the number of edges of the network. Our algorithms have high accuracy on real-world datasets from Twitter, Reddit, and Polblogs. 
%Also, we give sufficient conditions for the maximum size of $S$ when the embeddings of the nodes correspond to a stochastic block model with $K$ communities and show that as long as the smallest community is of size $\Theta (n/K)$ recovery of $S$ is possible as long as $|S| = O(n/K)$. 

% We find that polarization metrics and agents' costs depend on on 

% influence of strategic agents can be rather significant


% \ajcomment{Rewrite this.}

% \begin{itemize}
%     \item We characterize the Nash Equilibrium of the game defined by \cref{eq:strategic_cost}. Specifically, we show that the game has a Pure Strategy Nash Equilibrium (PSNE) that is given by solving a constrained linear system. Given the PSNE of the game, we characterize the actors who can have the most influence in strategically manipulating the network. In the case of one deviator ($|S| = 1$) we show that the optimal strategic opinion $\bs_i^\prime$ is a linear function of the true opinion $\bs_i$ and the effect size depends on the diagonal entries of the equilibrium matrix $B$, and the bias depends on the equilibrium matrix, the vector of internal opinions $\bs$ the link weights of edges adjacent to $i$, and the susceptibility parameters of the agents.  
%     \item We apply our framework to real-world social network data from Twitter and Reddit \citep{Chitra2020}, and data from the Political Blogs (polblogs) dataset \citep{adamic2005political}. We find that the influence of strategic agents can be rather significant as they can significantly increase polarization and disagreement, as well as increase the overall ``cost'' of the consensus.  
%     \item Analysis of equilibrium outcomes under different sets of strategic actors. 
%     To address this, we give worst-case upper bounds on the \textit{Price of Misreporting} (PoM), which is analogous to the well-studied Price of Anarchy bounds (see, for example, \citet{bhawalkar2013,roughgarden2011local}) and suggest ways that the platform can be used to mitigate the effect of strategic behavior on their network. 
%     \item We give an efficient learning algorithm for the platform to infer the set of strategic agents $S$ from observing their publicly reported opinions $\bz^\prime$ as long as the size of $S$ is sufficiently small. Our algorithm is inspired by the robust regression algorithm of \citet{torrent-2015}, and is practical for real-world networks: \textit{(i)} requires the platform to have access to node embeddings $X$ which have been shown computable even in billion-scale networks such as Twitter \citep{el2022twhin}, and \textit{(ii)} can be computed in polynomial time in the number of nodes $n$ and edges $m$ of the network.  We apply our algorithm to the real-world datasets from Twitter, Reddit, and Polblogs and show that our algorithm can recover the strategic set $S$ each time with high accuracy. Also, we give sufficient conditions for the maximum size of $S$ when the embeddings of the nodes correspond to a stochastic block model with $K$ communities and show that as long as the smallest community is of size $\Theta (n/K)$ recovery of $S$ is possible as long as $|S| = O(n/K)$. 
%     % \item \mpcomment{In the sequel, we lift the need for node embeddings and provide a general algorithm that requires only graph information, and the publicly reported opinions $\bz^\prime$ can recover $|S|$ as long as $|S| \le blah$. Contrary to the previously mentioned robust regression algorithm, this algorithm is based on performing a goodness-of-fit test and assumes prior information on the vector of intrinsic opinions $\bs$.}=
% \end{itemize}


\subsection{Preliminaries and Notations}

% \ajcomment{Need to define that $\bx_i$ is the i entry, and $\bx_{k;\ell}$ is the $\ell$ entry of $\bx_i$.}
The set $[n]$ denotes $\{ 1, \dots, n \}$. $\| \bx \|_p$ denotes the $\ell_p$-norm of vector $\bx$, whose $i$-th entry is denoted by $\bx_i$. $X \succeq 0$ denotes that the matrix $X$ is positive semi-definite and $\| X \|_2$ corresponds to the spectral norm of $X$. The Laplacian of the graph $G$ is denoted by $L = D - W$ where $W$ is the weight matrix of the graph, which has entries $w_{ij} \ge 0$, and $D$ is the diagonal degree matrix with diagonal entries $D_{ii} = \sum_{i \sim j} w_{ij}$. The Laplacian has eigenvalues $0 = \lambda_1 \le \lambda_2 \le \dots \le \lambda_n$. For any undirected and connected graph $G$, $L$ is symmetric and PSD, so we can write the eigendecomposition of $L$ as: 
\begin{equation}
    L = \sum_{i \in [n]} \lambda_i \bu_i \bu_i^T \succeq 0,
\end{equation}

where $\bu_1, \dots, \bu_n$ are orthonormal eigenvectors. Moreover, $\bu_1 = (1 / \sqrt n) \one$, where $\one$ is the column vector of all 1s. $U$ denotes the matrix which has the eigenvectors of $L$ as columns; i.e., such that $L = U^T \Lambda U$ where $\Lambda = \mathrm{diag} (\lambda_1, \dots, \lambda_n)$ is the diagonal matrix of $L$'s eigenvalues. $L_i$ denotes the $i$-restricted Laplacian which corresponds to the Laplacian of the graph with all edges that are non-adjacent to $i$ being removed, and, similarly, $L_{\{ u, v \}}$ corresponds to the Laplacian of an edge $\{ u, v\}$. Note that $L_i = \sum_{i \sim j} L_{\{ i, j \}}$. For a function $f(L)$ of the Laplacian we write $f(L) = U^T f(\Lambda) U$ where $f(\Lambda) = \mathrm{diag} (f(\lambda_1), \dots, f(\lambda_n))$. For brevity, regarding the equilibrium $z$ of the FJ model, we write $B =((I - A)L + A)^{-1} A$, such that $\bz = B \bs$ and $\bz^\prime = B \bs^\prime$. Finally $\be_1, \dots, \be_n \in \RR^n$ denote the canonical basis. 

We define the total cost of an equilibrium $\bz$ to be 
\begin{equation}
    C(\bz) = \sum_{i \in [n]} c_i(\bz).
\end{equation}

We define the platform-wide metrics to be
\begin{align}
    \textrm{Polarization Ratio} \qquad \mathcal P(\bz) &= \sum_{i \in [n]} (\bz_i - \bar z)^2, \text{ where } \bar z = \frac 1 n \sum_{i \in [n]} \bz_i, \\
    \textrm{Disagreement Ratio} \qquad \mathcal D(\bz) &= \sum_{i, j \in [n]} w_{ij} (\bz_i - \bz_j)^2 = \bz^T L \bz. 
\end{align}
% where $\mathcal P(\bz), \mathcal D(\bz)$ are the {\em Polarization Ratio}
% where we assume that the platform does not have access to the susceptibility parameters $\alpha_i$ (i.e., the $\alpha_i$s are endogenous and private to each agent). \ajcomment{We may not want to say private $\alpha_i$ if learning algo requires it.} 

Finally, we define the \textit{``Price of Misreporting''} (PoM), which is analogous to the Price of Anarchy~\cite{roughgarden2005selfish}. The PoM is the ratio of the cost $C(\bz^\prime)$ when the agents are deviating, and the cost $C(\bz)$ when the agents are reporting truthfully, i.e.,   
\begin{equation}
    \pom := \frac {C(\bz^\prime)}{C(\bz)}.
    \label{eq:pom}
\end{equation}
Unlike the Price of Anarchy (PoA), the equilibrium $\bz$ in the denominator of Eq.~\eqref{eq:pom} is the Nash equilibrium for the Friedkin-Johnson dynamics without manipulation. In the PoA, the denominator would be $C(\bz^*)$, where $\bz^*$ is a socially optimal equilibrium~\cite{bindel2011}. 
Since we study strategic manipulations as a meta-game with respect to the base game of FJ dynamics, it is more relevant for us to compare $\bz^\prime$ with $\bz$ than with $\bz^*$. Note that $C(\bz^*) \leq C(\bz) \leq C(\bz^\prime)$, so $\mathsf{PoA} \geq \pom \ge 1$ always. 

\subsection{Related Work}

\paragraph{Opinion Dynamics} Opinion dynamics are well-studied in computer science and economics, as well as sociology, political science, and related fields. There have been many models proposed for opinion dynamics, such as with network interactions as we study in this paper (FJ model) \citep{Friedkin1990,Bindel2015}, bounded confidence dynamics (Hegselman-Krausse Model) \citep{hegselmann2002opinion}, coevolutionary dynamics \citep{bhawalkar2013} as well as many variants of them; see, for example \citet{abebe2018opinion,hazla2019geometric,fotakis2016opinion,fotakis2023opinion,tsourakakis-2024}. The work of \citep{bindel2011} shows bounds on the Price of Anarchy (PoA) between the PSNE and the welfare-optimal solution for the FJ model, and the subsequent work of \cite{bhawalkar2013} shows PoA bounds for the coevolutionary dynamics. Additionally, the opinion dynamics have been modeled by the control community; see, for example, \citep{nedic2012,de2022,bhattacharyya2013convergence,chazelle2011total}. 

As in these works, we treat the FJ model as a basis. However, our work is significantly different as it studies a framework where any subset $S \subseteq [n]$ of strategic agents can {\em deviate} from their truthful intrinsic opinions, as opposed to studying the evolution of the expressed opinions and their PSNE in the FJ model. In our model, each strategic agent $i \in S$ can only choose a single entry $\bs_i^\prime$ of the overall deviation $\bs^\prime$, but pays a cost based on the resulting equilibrium ($\bz^\prime = B \bs^\prime$), which depends on the choices of other members of $S$. 

\paragraph{Disagreement and Polarization in Social Networks} Motivated by real-world manipulation of social networks in, e.g., the 2016 US election, a recent line of work studies polarization and strategic behavior in opinion dynamics \cite{gaitonde2020adversarial,gaitonde2021polarization,Chen2022,wang2024relationship,tsourakakis-2024,ristache2025countering}. 
\citet{Chen2022} consider a model in which an adversary can control $k \leq n$ nodes' internal opinions and seeks to maximize polarization at equilibrium. Similarly, \citet{gaitonde2020adversarial} considers a single adversary who can modify intrinsic opinions $\bm{s}$ belonging to an $\ell_2$-ball. More recent work also studies modification of agents' susceptibility parameters $\alpha_i$ to alter the median opinion at equilibrium~\cite{ristache2025countering}. By contrast, we study a setting in which any subset $S \subseteq [n]$ can be strategic. Unlike previous works, these ``adversaries'' can have conflicting goals in our model.

% \ajcomment{Write more here. Real world examples of multiple adversaries?}

\paragraph{Manipulation of Dynamic Games.} Opinion dynamics are a widely studied instance of a network game, which is a game played by nodes in a network with payoffs depending on the actions of their neighbors~\cite{kearns2001graphical, tardos-2004}. In addition to the manipulation of opinion dynamics, researchers have studied strategic manipulation of financial network formation~\cite{jalan-chakrabarti-2024}. In the non-network setting, researchers have studied the manipulation of recommendation systmes from a game-theoretic perspective~\cite{ben2018game}, as well as security games~\cite{nguyen2019deception}, repeated auctions~\cite{kolumbus2022auctions} and Fisher markers with linear utilities~\cite{kolumbus2023asynchronous}. 

% \blue{Cite more work here?}
% Moreover, works in multi-agent learning consider optimal play against a learning algorithm~\cite{deng-2019, camara2020mechanisms, assos2024maximizing}, but only a single agent against a single learner. By contrast we study strategic behavior by 
% in network games, in which an agent must consider not only their neighbors, but the neighbors of their neighbors, and so on. 

% \paragraph{Anomaly Detection in Graphs.} Our work is also related to the anomaly detection literature in networks. One work closely related to ours is the work of \citet{chen2022antibenford} where the authors want to detect Anti-Benford subgraphs in a large transaction or financial graph. The Anti-Benford subgraphs consist of a set of nodes that perform many transactions that significantly deviate from Benford's law, and the authors develop a hypothesis test to detect such graphs. Similarly, the work of \citet{agarwal2020chisel} proposes a framework based on a chi-squared statistic to perform a graph similarity search.  In our paper, similarly, we develop a robust regression and a hypothesis testing algorithm that is able to detect nodes that are strategic and misreport their opinions. Additionally, our work assumes the strategic behavior of the agents, whereas the works of \citep{agarwal2020chisel,chen2022antibenford} do not. 

% In a similar spirit, the work of \citet{jalan-chakrabarti-2024} studies financial networks, whereas a subset of strategic agents has incentives to misreport their own local network connections in order to obtain higher utility, and develop algorithms that can identify the set of such agents. Our paper works in a similar flavor, however, in a significantly different application domain and context, which corresponds to social networks.


\paragraph{Learning from Strategic Data.} We develop learning algorithms which observe the (possibly manipulated) equilibrium $\bz^\prime$ to detect if manipulation occurred, and if so who was responsible. The former problem relates to anomaly detection in networks. \citet{chen2022antibenford} develop a hypothesis test to detect such fraud in financial transaction neteworks, by testing if certain subgraphs deviate from Benford's Law. Similarly, \citet{agarwal2020chisel} propose a framework based on a $\chi^2$-statistic to perform graph similarity search. 

The problem of recovering the set of deviators relates to the broader literature of learning from observations of network games. Most works give learning algorithms for games {\em without} manipulation~\cite{irfan-2014,garg-2016,de2016learning,leng-2020-learning,rossi2022learning,jalan-2023}. But our data $\bz^\prime$ can be a manipulated equilibrium, which is a {\em strategic sources} of data~\cite{zampetakis2020statistics}. Learning algorithms for strategic sources are known for certain settings such as linear classifiers with small-deviation assumptions~\citep{chen2020learning}, or binary classifiers in a linear reward model~\citep{harris2023strategic}. When agents can modify their features to fool a known algorithm, even strategy-robust classifiers such as \cite{hardt2016strategic} can be inaccurate~\cite{ghalme2021strategic}.  
Since agents can deviate arbitrarily in our model, we use a robust regression method with guarantees against {\em adversarial} corruptions~\citep{torrent-2015}, similar to the learning algorithms in~\citep{kapoor2019corruption,russo2023analysis}. The work of \citet{jalan-chakrabarti-2024} studies learning from financial networks with strategic manipulations, which is in a similar spirit to our work but differs significantly in the application domain and context. 

% Our setting is closest to that of \citet{jalan-chakrabarti-2024}, who give 

% .  A growing body of work studies learning from ``strategic sources'' of data such as $\bz^\prime$. 

%  \citet{chen2020learning} study strategy-awareness for linear classification, but assume that agents can only misreport data up to an $\eps$-ball. Our setting is closer to that of \citet{ghalme2021strategic}, who show that agents who are evaluated by a third-party classifier (e.g. for approval for a bank loan) can strategically modify their features to game the classifier, even if the classifier used is strategy-robust in the sense of \cite{hardt2016strategic}. 
% \cite{harris2023strategic} give a $\Tilde{O}(n^{(d+1)/(d+2)})$-regret algorithm for online binary classification against $n$ strategic agents with $d$-dimensional features, but in a linear reward model. Finally, \cite{daskalakis-2015} give a mechanism to encourage strategic data providers to report truthful data, but in a model where the data providers have no incentive to hurt the classifier's accuracy (e.g. crowdsourcing).

% \paragraph{Network Games.} Network games, also known as graphical games, involve $n$ agents whose payoffs are influenced by the actions of their neighbors~\cite{littman2001efficient, roughgarden2004bounding,roughgarden2011local}. A substantial body of research examines learning from observations of such games~\cite{irfan2018causal,garg2016learning,rossi2022learning,leng2020learning}. These studies typically focus on games with finite or one-dimensional action spaces, whereas in our model, each of the $n$ agents operates in an $n$-dimensional action space.

% Furthermore, another area of research explores influencing the outcomes of network games. Most of these studies address games with one-dimensional action spaces and a single strategic actor~\cite{galeotti2020targeting,gaitonde2020adversarial,gaitonde2021polarization, wang2024relationship}. In contrast, we consider arbitrary sets of strategic actors. Recent works have also examined scenarios with multiple strategic actors, such as in repeated auctions~\cite{kolumbus2022auctions} and Fisher markets with linear utilities~\cite{kolumbus2023asynchronous}. While our work shares a similar motivation, it centers on opinion formation.

% Our work is broadly concerned with strategic considerations in machine learning systems, and is at the intersection of growing fields such as artificial intelligence, algorithmic game theory, and multi-agent learning. 

% {\bf Network games with strategic behavior and learning.} Network games, or graphical games, involve $n$ agents whose payoffs depend on the actions of their neighboring agents~\cite{kearns2001graphical, tardos-2004}. A large body of work studies learning from observations of network games~\cite{irfan-2014,garg-2016,de2016learning,leng-2020-learning,rossi2022learning}. All of these works study games with finite or one-dimensional action spaces, whereas each of the $n$ agents in our model has an $n$-dimensional action space. This results in a vector of contracts $\bm{w}_k \in \RR^n$ for each agent $k$. The correlations between entries of $\bm{w}_k$ can have strategic consequences, as we show in Section~\ref{sec:welfare}. 


% {\bf Learning from strategic sources.} 
% %Agents in our model wish to estimate other agents' beliefs from observing the stable networks generated by strategic negotiations (Section~\ref{sec:learning}).  
% \cite{chen2020learning} study strategy-awareness for linear classification, but assume that agents can only misreport data up to an $\eps$-ball. Our setting is closer to that of \cite{ghalme2021strategic}, who show that agents who are evaluated by a third-party classifier (e.g. for approval for a bank loan) can strategically modify their features to game the classifier, even if the classifier used is strategy-robust in the sense of \cite{hardt2016strategic}. 
% \cite{harris2023strategic} give a $\Tilde{O}(n^{(d+1)/(d+2)})$-regret algorithm for online binary classification against $n$ strategic agents with $d$-dimensional features, but in a linear reward model. Finally, \cite{daskalakis-2015} give a mechanism to encourage strategic data providers to report truthful data, but in a model where the data providers have no incentive to hurt the classifier's accuracy (e.g. crowdsourcing).
%\blue{a few more cites about mechanism design for strategy aware statistics?}

% {\bf Multi-agent learning.} In terms of the ``five agendas'' of multi-agent learning \cite{shoham2007if}, we consider our work closest to the ``Prescriptive, non-cooperative'' agenda. The goal of this program is to design agents that are optimal for environments consisting of other learning agents. Several works study the problem of optimal play against a learning algorithm \cite{deng-2019, camara2020mechanisms, assos2024maximizing}, but each of these considers a single player against a single learner. Our work is more related to strategic behavior in network games, in which an agent must consider not only their neighbors, but the neighbors of their neighbors, and so on. 



% \mpcomment{I added the refs, but it may need more writing to make sure it looks different}

% \ajcomment{Add refs from old paper. Emphasize Nisan-Kolumbus paper on how to manipulate your learning algorithm.}

\subsection{Real-world Datasets}
% \blue{split it up into bullets with enum. have a table.}
To support our results, we use data grounded in practice, which have also been used in previous studies to study polarization and disagreement (cf. \citet{Musco2018,Chitra2020,wang2024relationship,adamic2005political}). Specifically, we use Twitter, Reddit, and Political blog networks, summarized in Table~\ref{tab:networks} summarizes these. Both the Twitter and Reddit datasets are due to \citet{Chitra2020}. The vectors $\bs$ of initial opinions for both are obtained via sentiment analysis and also follow the post-processing of \citet{wang2024relationship}.

\paragraph{(1) Twitter dataset.} These data correspond to debate over the Delhi legislative assembly elections of 2013. Nodes are Twitter users, and edges refer to user interactions. 

\paragraph{(2) Reddit dataset.} These data correspond to political discussion on the \texttt{r/politics} subreddit. Nodes are who posted in the \texttt{r/politics} subreddit, and there is an edge between two users $i,j$ if two subreddits (other than \texttt{r/politics}) exist that both $i,j$ posted on during the given time period. 

\paragraph{(3) Political Blogs (Polblogs) dataset.} These data, due to \citet{adamic2005political}, contain opinions from political blogs (liberal and conservative). Edges between blogs were automatically extracted from a crawl of the front page of the blog. Each blog is either liberal -- where we assign a value $\bs_i = -1$ -- or conservative -- where we assign $\bs_i = +1$.

% \ajcomment{Cite Musco, Musco Tsourakakis and Chen Racz, Wang Kleinberg on simulations and their validity -- move it into real world data subsection.}
% 2. The Reddit dataset has $n = 556$ nodes and $m = 8969$ edges. Nodes are users who posted in the \texttt{r/politics} subreddit, and there is an edge between two users if two subreddits (other than \texttt{r/politics}) exist that both users posted during the given time period. The vectors $\bs$ of initial opinions are obtained via sentiment analysis and also follow the post-processing of \citet{wang2024relationship}. 

% The Political Blogs -- or Polblogs, for brevity --  dataset is due to \citet{adamic2005political} and contains political blogs (liberal and conservative) and links between blogs were automatically extracted from a crawl of the front page of the blog. Each blog is either liberal -- where we assign a value $\bs_i = -1$ -- or conservative -- where we assign $\bs_i = +1$. The Polblogs dataset has $n = 1490$ and $m = 
% 16178$. 

\begin{table}
\centering
\begin{tabular}{lccl}
\hline
Network & Nodes ($n$) & Edges ($m$) & Description \\
\hline
Twitter & 548 & 3,638 & User interactions during 2013 Delhi elections. \\
Reddit & 556 & 8,969 & User interactions in r/politics subreddit \\
Polblogs & 1,490 & 16,178 & Liberal and conservative blog network \\
\hline
\end{tabular}
\caption{Summary of the social network datasets we use.}
\label{tab:networks}
\end{table}

% \ajcomment{need to insert a table here.}
% \ajcomment{We could also move the figure with the degrees of the datasets here.}