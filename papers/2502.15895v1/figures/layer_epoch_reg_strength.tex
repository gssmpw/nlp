% \begin{figure}[!h]
%     \centering
%     % First image on the left
%     \begin{subfigure}{0.33\linewidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/3d_plot.png}
%         \caption{TextVQA, PT}
%     \end{subfigure}%
%     \begin{subfigure}{0.33\linewidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/3d_plot_layers-2.png}
%         \caption{TextVQA, FT}
%     \end{subfigure}%
%     \begin{subfigure}{0.33\linewidth}
%         \centering
%         \includegraphics[width=\linewidth]{figures/3d_plot_iteration-2.png}
%         \caption{TextVQA, LP}
%     \end{subfigure}%
    
%     \caption{Variation of the Average Projection Strength $\omega$ of all Layers over Iterations. We present the results of $\mu \in \{0.01, 0.1, 0.5, 1, 100\}$. We use the sliding window with window sizes of 50 and 200 to visualize the results for DomainNet-oVQA (Real) and VQAv2. The projection strength $\omega$ is dynamic over iterations, growing from small to large and converging in the end.}
%     \label{fig:variation}
% \end{figure}

\begin{figure}[!h]
    \centering
    \begin{subfigure}{0.6\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/3d_plot.png}
        \caption{3D Overview of the Variation of Regularization Strength across Layers and Epochs.}
        \label{fig:3d}
    \end{subfigure}%
    \begin{subfigure}{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/3d_plot_layers-2.png}
        \caption{Layer-Wise Regularization Strength}
        \label{fig:layer}
        \vspace{0.5cm} % Adjust space between the two figures on the right
        \includegraphics[width=\textwidth]{figures/3d_plot_iteration-2.png}
        \caption{Dynamic Regularization Across Epochs}
        \label{fig:epoch}
    \end{subfigure}
    \caption{\textbf{Visualization of the Variation in Regularization Strength ($\lambda$) across Layers over Epochs.} Fig.~\ref{fig:3d} is an 3D view of R=regularization strength dynamics across layers and epochs. The X-axis represents training epochs, the Y-axis represents model layers (vision in blue, language in orange), and the Z-axis represents the regularization strength $\lambda$ applied to each layer. Fig.~\ref{fig:layer} projects the data onto the plane formed by layers (Y) and regularization strength (Z). Fig.~\ref{fig:epoch} projects the data onto the plane formed by epochs (X) and regularization strength (Z).}
    \label{fig:layer_epoch_reg_strength}
\end{figure}