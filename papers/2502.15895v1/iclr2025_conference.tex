
\documentclass{article} % For LaTeX2e
\usepackage{iclr2025_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{tikz}

\usepackage{hyperref}
\usepackage{url}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
% Disable line numbering
\algrenewcommand\alglinenumber[1]{}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors

\usepackage{amsmath,amsfonts,amssymb}
\usepackage{graphicx}
% \usepackage{subfigure}
\usepackage{color}
\usepackage{amsthm}
\usepackage{multirow}
\usepackage{float}
\floatstyle{plaintop}
\restylefloat{table}
\usepackage{caption}
\usepackage{enumitem}
% \usepackage{algorithm}
% \usepackage[ruled]{algorithm2e}

\usepackage[tableposition=top]{caption}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{verbatim}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{hypothesis}{Hypothesis}
\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}

\usepackage{wrapfig}
\usepackage{bm}
\usepackage{adjustbox}

% \usepackage[dvipsnames]{xcolor}
% \definecolor{citecolor}{HTML}{0071bc}
% \usepackage{listings}
% \usepackage{xcolor}
% \usepackage{wrapfig}
% \usepackage[table]{xcolor}
\usepackage{tablefootnote}

\usepackage[textsize=tiny]{todonotes}
\newcommand{\zkn}[1]{\todo[color=orange!20, size=\tiny]{Zsolt: #1}}
\newcommand{\zk}[1]{\textcolor{blue}{Zsolt: #1}}

\setlength{\marginparwidth}{2cm}
% Uncomment to remove the todonotes/comments
\renewcommand{\zk}[1]{}
\renewcommand{\zkn}[1]{}


\title{Directional Gradient Projection for Robust Fine-Tuning of Foundation Models}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{Chengyue Huang, Junjiao Tian, Brisa Maneechotesuwan, Shivang Chopra, Zsolt Kira\\
Georgia Institute of Technology \\
\texttt{\{chuang475,jtian73,bmaneech3,shivangchopra11,zkira\}@gatech.edu} \\
% \And
% Ji Q. Ren \& Yevgeny LeNet \\
% Department of Computational Neuroscience \\
% University of the Witwatersrand \\
% Joburg, South Africa \\
% \texttt{\{robot,net\}@wits.ac.za} \\
% \AND
% Coauthor \\
% Affiliation \\
% Address \\
% \texttt{email}
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
Robust fine-tuning aims to adapt large foundation models to downstream tasks while preserving their robustness to distribution shifts. Existing methods primarily focus on constraining and projecting current model towards the pre-trained initialization\zkn{mention projecting from what to what} based on the\zkn{and make clear what is ``their'' as it often incorporates $\theta_0$ as well} magnitudes between fine-tuned and pre-trained weights, which often require extensive hyper-parameter tuning and can sometimes result in underfitting. In this work, we propose \textbf{Di}rectional \textbf{Gra}dient \textbf{P}rojection (\emph{DiGraP}), a novel layer-wise trainable method that incorporates directional information from gradients to bridge regularization and multi-objective optimization. Besides demonstrating our method on image classification, as another contribution we generalize this area to the multi-modal evaluation settings for robust fine-tuning. Specifically, we first bridge the uni-modal and multi-modal gap by performing analysis on Image Classification reformulated Visual Question Answering (VQA) benchmarks\zkn{This is a bit misleading as it leverages prior work that does this, and also we test on many VQA datasets that don't do this.} and further categorize ten out-of-distribution (OOD) VQA datasets by distribution shift types and degree (i.e. near versus far OOD). %We also observe that previous work has only been evaluated in uni-modal settings, with coarse distribution shifts that don't distinguish between near and far out-of-distribution (OOD) cases.
Experimental results show that \emph{DiGraP} consistently outperforms existing baselines across Image Classfication and VQA tasks with discriminative and generative backbones, improving both in-distribution (ID) generalization and OOD robustness.\footnote{The code is available at \url{https://github.com/chengyuehuang511/DiGraP}}

% Be methodical, rigorous. Add more insights, comparing methods and explaining why.
\end{abstract}

\input{sections/introduction}
\input{sections/related_works}
% \input{sections/vqa_datasets}
% \input{sections/ood_robustness_methods}
\input{sections/method}
\input{sections/experiments}
\input{sections/ablation_study}
\input{sections/conclusion}

% \clearpage
% \input{sections/rebuttals}

% \subsubsection*{Author Contributions}
% If you'd like to, you may include  a section for author contributions as is done
% in many journals. This is optional and at the discretion of the authors.

\clearpage
% \subsubsection*{Acknowledgments}
% Use unnumbered third level headings for the acknowledgments. All
% acknowledgments, including those to funding agencies, go at the end of the paper.

\bibliography{iclr2025_conference}
\bibliographystyle{iclr2025_conference}

% \appendix
\input{sections/appendix}


\end{document}
