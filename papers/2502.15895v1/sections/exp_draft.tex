% two parts: pretrained weights + gained weights

\input{tables/imagenet_results}
\input{tables/domainnet_results}

\textbf{Finetuning on VQAv2 improves little on object identification OOD tasks.} While fine-tuning VQAv2 leads to a substantial improvement compared to the pretraining model on both near and far traditional VQA OOD datasets, the performance of the pretrained model is comparable under the new image-generated VQA OOD setting (both ImageNet-oVQA and DomainNet-oVQA). This indicates that fine-tuning on the traditional VQA datasets focuses more on improving the reasoning ability while neglecting object identification capabilities, since traditional VQA datasets mainly contain counting or yes/no questions. \textcolor{red}{TODO: fine-tune on DomainNet and ImageNet}

\textbf{VLMs fine-tuned on VQAv2 are weak in classifying fine-grained objects.} PaliGemma-3B outperforms CLIP ResNet50 on DomainNet but underperforms CLIP ViT on ImageNet. The performance is especially worse when we ask a general question for PaliGemma-3B. This may due to ImageNet including fine-grained classes such as dog breeds or car models. After generating a follow-up question based on the answer for the general question, the performance of PaliGemma-3B improves by a large margin (around $10\%$). \textcolor{red}{TODO: CLIP ViT for DomainNet}

\textbf{Selectively imposing regularization on certain layers during fine-tuning benefits the models in general, while WiSE only works when zero-shot performance is good.} There is a huge gap between the zero-shot and fine-tune results under traditional VQA datasets while close under the image-generated VQA benchmarks. WiSE-FT only works for the latter setting while SPD is benefitial for either cases. When WiSE is working, adding SPD sometimes further improves the results. 

\textbf{SPD alone sometimes outperforms WiSE-SPD even when WiSE works.} ImageNet-R, ImageNet-S, DomainNet-Sketch, DomianNet-Painting, DomianNet-Infograph, DomainNet-Quickdraw.


% another part
\subsection{Evaluation on Image-generated VQA Benchmarks}
We build novel VQA benchmarks based on several visual classification tasks (ImageNet, DomainNet) that are commonly used for evaluating existing OOD robustness algorithms and provide comprehensive comparisons of the baselines with both generative and discriminative backbones. 

\input{tables/imagenet_results}
\input{tables/domainnet_results}

\textbf{Finetuning on VQAv2 improves little on object identification OOD tasks.} While fine-tuning VQAv2 leads to a substantial improvement compared to the pretraining model on both near and far traditional VQA OOD datasets, the performance of the pretrained model is comparable under the new image-generated VQA OOD setting (both ImageNet-oVQA and DomainNet-oVQA). This indicates that fine-tuning on the traditional VQA datasets focuses more on improving the reasoning ability while neglecting object identification capabilities, since traditional VQA datasets mainly contain counting or yes/no questions. \textcolor{red}{TODO: fine-tune on DomainNet and ImageNet}

\textbf{VLMs fine-tuned on VQAv2 are weak in classifying fine-grained objects.} PaliGemma-3B outperforms CLIP ResNet50 on DomainNet but underperforms CLIP ViT on ImageNet. The performance is especially worse when we ask a general question for PaliGemma-3B. This may due to ImageNet including fine-grained classes such as dog breeds or car models. After generating a follow-up question based on the answer for the general question, the performance of PaliGemma-3B improves by a large margin (around $10\%$). \textcolor{red}{TODO: CLIP ViT for DomainNet}

\textbf{Selectively imposing regularization on certain layers during fine-tuning benefits the models in general, while WiSE only works when zero-shot performance is good.} There is a huge gap between the zero-shot and fine-tune results under traditional VQA datasets while close under the image-generated VQA benchmarks. WiSE-FT only works for the latter setting while SPD is benefitial for either cases. When WiSE is working, adding SPD sometimes further improves the results. 

\textbf{SPD alone sometimes outperforms WiSE-SPD even when WiSE works.} ImageNet-R, ImageNet-S, DomainNet-Sketch, DomianNet-Painting, DomianNet-Infograph, DomainNet-Quickdraw.