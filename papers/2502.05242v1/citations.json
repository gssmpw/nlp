[
  {
    "index": 0,
    "papers": [
      {
        "key": "liu2023towards",
        "author": "Liu, Dongrui and Deng, Huiqi and Cheng, Xu and Ren, Qihan and Wang, Kangrui and Zhang, Quanshi",
        "title": "Towards the difficulty for a deep neural network to learn concepts of different complexities"
      },
      {
        "key": "zhou2024explaining",
        "author": "Zhou, Huilin and Zhang, Hao and Deng, Huiqi and Liu, Dongrui and Shen, Wen and Chan, Shih-Han and Zhang, Quanshi",
        "title": "Explaining generalization power of a dnn using interactive concepts"
      },
      {
        "key": "ren2024identifying",
        "author": "Ren, Jie and Guo, Qipeng and Yan, Hang and Liu, Dongrui and Zhang, Quanshi and Qiu, Xipeng and Lin, Dahua",
        "title": "Identifying semantic induction heads to understand in-context learning"
      },
      {
        "key": "ren2024towards",
        "author": "Ren, Qihan and Xu, Yang and Zhang, Junpeng and Xin, Yue and Liu, Dongrui and Zhang, Quanshi",
        "title": "Towards the dynamics of a dnn learning symbolic interactions"
      },
      {
        "key": "dang2024explainable",
        "author": "Dang, Yunkai and Huang, Kaichen and Huo, Jiahao and Yan, Yibo and Huang, Sirui and Liu, Dongrui and Gao, Mengxi and Zhang, Jie and Qian, Chen and Wang, Kun and others",
        "title": "Explainable and interpretable multimodal large language models: A comprehensive survey"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "liu2025latent",
        "author": "Liu, Runtao and Khakzar, Ashkan and Gu, Jindong and Chen, Qifeng and Torr, Philip and Pizzati, Fabio",
        "title": "Latent guard: a safety framework for text-to-image generation"
      },
      {
        "key": "liu2024efficient",
        "author": "Liu, Yi and Yu, Junzhe and Sun, Huijia and Shi, Ling and Deng, Gelei and Chen, Yuqi and Liu, Yang",
        "title": "Efficient Detection of Toxic Prompts in Large Language Models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "Nostalgebraist2020",
        "author": "nostalgebraist",
        "title": "interpreting GPT: the logit lens"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "gao2024scaling",
        "author": "Gao, Leo and la Tour, Tom Dupr{\\'e} and Tillman, Henk and Goh, Gabriel and Troll, Rajan and Radford, Alec and Sutskever, Ilya and Leike, Jan and Wu, Jeffrey",
        "title": "Scaling and evaluating sparse autoencoders"
      },
      {
        "key": "lieberum2024gemma",
        "author": "Lieberum, Tom and Rajamanoharan, Senthooran and Conmy, Arthur and Smith, Lewis and Sonnerat, Nicolas and Varma, Vikrant and Kram{\\'a}r, J{\\'a}nos and Dragan, Anca and Shah, Rohin and Nanda, Neel",
        "title": "Gemma scope: Open sparse autoencoders everywhere all at once on gemma 2"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "chen2024selfie",
        "author": "Chen, Haozhe and Vondrick, Carl and Mao, Chengzhi",
        "title": "Selfie: Self-interpretation of large language model embeddings"
      },
      {
        "key": "ghandeharioun2024patchscope",
        "author": "Ghandeharioun, Asma and Caciularu, Avi and Pearce, Adam and Dixon, Lucas and Geva, Mor",
        "title": "Patchscope: A unifying framework for inspecting hidden representations of language models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "bills2023language",
        "author": "Bills, Steven and Cammarata, Nick and Mossing, Dan and Tillman, Henk and Gao, Leo and Goh, Gabriel and Sutskever, Ilya and Leike, Jan and Wu, Jeff and Saunders, William",
        "title": "Language models can explain neurons in language models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "nye2021show",
        "author": "Nye, Maxwell and Andreassen, Anders Johan and Gur-Ari, Guy and Michalewski, Henryk and Austin, Jacob and Bieber, David and Dohan, David and Lewkowycz, Aitor and Bosma, Maarten and Luan, David and others",
        "title": "Show your work: Scratchpads for intermediate computation with language models"
      },
      {
        "key": "wei2022chain",
        "author": "Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others",
        "title": "Chain-of-thought prompting elicits reasoning in large language models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "huang2023can",
        "author": "Huang, Shiyuan and Mamidanna, Siddarth and Jangam, Shreedhar and Zhou, Yilun and Gilpin, Leilani H",
        "title": "Can large language models explain themselves? a study of llm-generated self-explanations"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "turpin2024language",
        "author": "Turpin, Miles and Michael, Julian and Perez, Ethan and Bowman, Samuel",
        "title": "Language models don't always say what they think: unfaithful explanations in chain-of-thought prompting"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "li2024open",
        "author": "Li, Tianlong and Zheng, Xiaoqing and Huang, Xuanjing",
        "title": "Open the Pandora's Box of LLMs: Jailbreaking LLMs through Representation Engineering"
      },
      {
        "key": "yin2024lofit",
        "author": "Yin, Fangcong and Ye, Xi and Durrett, Greg",
        "title": "LoFiT: Localized Fine-tuning on LLM Representations"
      },
      {
        "key": "qian2024towards",
        "author": "Qian, Chen and Zhang, Jie and Yao, Wei and Liu, Dongrui and Yin, Zhenfei and Qiao, Yu and Liu, Yong and Shao, Jing",
        "title": "Towards tracing trustworthiness dynamics: Revisiting pre-training period of large language models"
      },
      {
        "key": "zhang2024real",
        "author": "Zhang, Honggen and Zhao, Xufeng and Molybog, Igor and Zhang, June",
        "title": "REAL: Response Embedding-based Alignment for LLMs"
      },
      {
        "key": "zhang2024better",
        "author": "Zhang, Jie and Liu, Dongrui and Qian, Chen and Gan, Ziyue and Liu, Yong and Qiao, Yu and Shao, Jing",
        "title": "The better angels of machine personality: How personality relates to llm safety"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "wei2024diff",
        "author": "Wei, Lai and Tan, Zhiquan and Li, Chenghai and Wang, Jindong and Huang, Weiran",
        "title": "Diff-eRank: A Novel Rank-Based Metric for Evaluating Large Language Models"
      },
      {
        "key": "azaria2023internal",
        "author": "Azaria, Amos and Mitchell, Tom",
        "title": "The internal state of an LLM knows when it's lying"
      },
      {
        "key": "xu2024good",
        "author": "Xu, Yi and Xue, Bo and Sheng, Shuqian and Deng, Cheng and Ding, Jiaxin and Shen, Zanwei and Fu, Luoyi and Wang, Xinbing and Zhou, Chenghu",
        "title": "Good Idea or Not, Representation of LLM Could Tell"
      },
      {
        "key": "azaria2023internal",
        "author": "Azaria, Amos and Mitchell, Tom",
        "title": "The internal state of an LLM knows when it's lying"
      },
      {
        "key": "orgad2024llms",
        "author": "Orgad, Hadas and Toker, Michael and Gekhman, Zorik and Reichart, Roi and Szpektor, Idan and Kotek, Hadas and Belinkov, Yonatan",
        "title": "Llms know more than they show: On the intrinsic representation of llm hallucinations"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "zhang2024reef",
        "author": "Zhang, Jie and Liu, Dongrui and Qian, Chen and Zhang, Linfeng and Liu, Yong and Qiao, Yu and Shao, Jing",
        "title": "Reef: Representation encoding fingerprints for large language models"
      },
      {
        "key": "sevastjanova2022lmfingerprints",
        "author": "Sevastjanova, Rita and Kalouli, A and Beck, Christin and Hauptmann, Hanna and El-Assady, Mennatallah",
        "title": "LMFingerprints: Visual explanations of language model embedding spaces through layerwise contextualization scores"
      },
      {
        "key": "yang2024fingerprint",
        "author": "Yang, Zhiguang and Wu, Hanzhou",
        "title": "A Fingerprint for Large Language Models"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "li2024inference",
        "author": "Li, Kenneth and Patel, Oam and Vi{\\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin",
        "title": "Inference-time intervention: Eliciting truthful answers from a language model"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "rosati2024representation",
        "author": "Rosati, Domenic and Wehner, Jan and Williams, Kai and Bartoszcze, {\\L}ukasz and Atanasov, David and Gonzales, Robie and Majumdar, Subhabrata and Maple, Carsten and Sajjad, Hassan and Rudzicz, Frank",
        "title": "Representation noising effectively prevents harmful fine-tuning on LLMs"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "zou2024improving",
        "author": "Zou, Andy and Phan, Long and Wang, Justin and Duenas, Derek and Lin, Maxwell and Andriushchenko, Maksym and Kolter, J Zico and Fredrikson, Matt and Hendrycks, Dan",
        "title": "Improving alignment and robustness with circuit breakers"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "li2024wmdp",
        "author": "Li, Nathaniel and Pan, Alexander and Gopal, Anjali and Yue, Summer and Berrios, Daniel and Gatti, Alice and Li, Justin D and Dombrowski, Ann-Kathrin and Goel, Shashwat and Phan, Long and others",
        "title": "The wmdp benchmark: Measuring and reducing malicious use with unlearning"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "wu2024reft",
        "author": "Wu, Zhengxuan and Arora, Aryaman and Wang, Zheng and Geiger, Atticus and Jurafsky, Dan and Manning, Christopher D and Potts, Christopher",
        "title": "Reft: Representation finetuning for language models"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "qian2024dean",
        "author": "Qian, Chen and Liu, Dongrui and Zhang, Jie and Liu, Yong and Shao, Jing",
        "title": "Dean: Deactivating the coupled neurons to mitigate fairness-privacy conflicts in large language models"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "he2020momentum",
        "author": "He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross",
        "title": "Momentum contrast for unsupervised visual representation learning"
      },
      {
        "key": "chen2020simple",
        "author": "Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey",
        "title": "A simple framework for contrastive learning of visual representations"
      },
      {
        "key": "zbontar2021barlow",
        "author": "Zbontar, Jure and Jing, Li and Misra, Ishan and LeCun, Yann and Deny, St{\\'e}phane",
        "title": "Barlow twins: Self-supervised learning via redundancy reduction"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "radford2021learning",
        "author": "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others",
        "title": "Learning transferable visual models from natural language supervision"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "cahyawijaya2024high",
        "author": "Cahyawijaya, Samuel and Chen, Delong and Bang, Yejin and Khalatbari, Leila and Wilie, Bryan and Ji, Ziwei and Ishii, Etsuko and Fung, Pascale",
        "title": "High-Dimension Human Value Representation in Large Language Models"
      }
    ]
  }
]