\section{Related Work}
\textbf{Interpretability of LLMs.} Global interpretability methods provide insight into the internal mechanisms of LLM ____. Previously, external modules are often trained to identify semantic information from intermediate representations ____. Some methods also project representations into the vocabulary space ____ or other interpretable space ____. Due to the powerful capabilities of LLMs, they are utilized to explain representations with natural language by directly decoding representations ____ or summarizing patterns of representations ____. When an LLM serves as the explained model and the explaining tool simultaneously in these above approaches, they can be called self-explaining methods. Self-explaining methods use models to explain themselves. Instead of explaining representations, chain-of-thought prompting (CoT, ____) enables LLMs to tell how they make predictions and improves reasoning ability. However, ____ and ____ show that CoT may provide unfaithful explanations and bring potential dangers to the utilization of LLMs.

\textbf{Representations of LLMs.} Several works focus on representations of LLMs instead of their output on tasks of LLMs' alignment ____, evaluation ____ and copyright protection ____. ____ design steering vectors and insert them into model representations to control model generations without training. ____, ____ and ____ perform machine unlearning by rotating the representation of harmful samples or pushing them towards a random distribution. What's more, ____ performs intervention functions precisely on the model's target layer and the target position of the input tokens. ____ disentangles LLMsâ€™ awareness of fairness and privacy by deactivating the entangled neurons in representations.

\textbf{Contrastive Learning.} Contrastive self-supervised learning on computer vision utilizes positive and negative pairs constructed by data augmentation to learn general and high-quality representations ____. ____ connects natural language and visual modality through contrastive learning of text-image pairs. Recent work extracts human value representations of LLMs by applying multi-view contrastive Learning ____. 


\begin{figure*}[t]
    \vspace{-5pt}
    \centering
    \includegraphics[width=1\linewidth, clip]{methods_v12.pdf}
    \vspace{-15pt}
    \caption{\textbf{Overview of \methodFamilyName{}.} \methodFamilyName{} disentangles representations by maximizing the examples' similarities from the same concept, and minimizing the examples' similarities from the different concepts. Meanwhile, \methodFamilyName{} utilizes constraints of $l_2$ distance and KL distance on representations and probabilities respectively before and after the disentanglement to maintain the general capabilities of LLMs. }\label{fig:method}
    \vspace{-10pt}
\end{figure*}