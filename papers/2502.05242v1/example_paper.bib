@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{cahyawijaya2024high,
  title={High-Dimension Human Value Representation in Large Language Models},
  author={Cahyawijaya, Samuel and Chen, Delong and Bang, Yejin and Khalatbari, Leila and Wilie, Bryan and Ji, Ziwei and Ishii, Etsuko and Fung, Pascale},
  journal={arXiv preprint arXiv:2404.07900},
  year={2024}
}

@article{li2024inference,
  title={Inference-time intervention: Eliciting truthful answers from a language model},
  author={Li, Kenneth and Patel, Oam and Vi{\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{zou2024improving,
  title={Improving alignment and robustness with circuit breakers},
  author={Zou, Andy and Phan, Long and Wang, Justin and Duenas, Derek and Lin, Maxwell and Andriushchenko, Maksym and Kolter, J Zico and Fredrikson, Matt and Hendrycks, Dan},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}

@article{chan2022redunet,
  title={ReduNet: A white-box deep network from the principle of maximizing rate reduction},
  author={Chan, Kwan Ho Ryan and Yu, Yaodong and You, Chong and Qi, Haozhi and Wright, John and Ma, Yi},
  journal={Journal of machine learning research},
  volume={23},
  number={114},
  pages={1--103},
  year={2022}
}


@inproceedings{he2020momentum,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9729--9738},
  year={2020}
}

@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}

@inproceedings{liu2025latent,
  title={Latent guard: a safety framework for text-to-image generation},
  author={Liu, Runtao and Khakzar, Ashkan and Gu, Jindong and Chen, Qifeng and Torr, Philip and Pizzati, Fabio},
  booktitle={European Conference on Computer Vision},
  pages={93--109},
  year={2025},
  organization={Springer}
}

@inproceedings{liu2024efficient,
  title={Efficient Detection of Toxic Prompts in Large Language Models},
  author={Liu, Yi and Yu, Junzhe and Sun, Huijia and Shi, Ling and Deng, Gelei and Chen, Yuqi and Liu, Yang},
  booktitle={Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
  pages={455--467},
  year={2024}
}

@article{gao2024scaling,
  title={Scaling and evaluating sparse autoencoders},
  author={Gao, Leo and la Tour, Tom Dupr{\'e} and Tillman, Henk and Goh, Gabriel and Troll, Rajan and Radford, Alec and Sutskever, Ilya and Leike, Jan and Wu, Jeffrey},
  journal={arXiv preprint arXiv:2406.04093},
  year={2024}
}

@article{lieberum2024gemma,
  title={Gemma scope: Open sparse autoencoders everywhere all at once on gemma 2},
  author={Lieberum, Tom and Rajamanoharan, Senthooran and Conmy, Arthur and Smith, Lewis and Sonnerat, Nicolas and Varma, Vikrant and Kram{\'a}r, J{\'a}nos and Dragan, Anca and Shah, Rohin and Nanda, Neel},
  journal={arXiv preprint arXiv:2408.05147},
  year={2024}
}

@article{templeton2024scaling,
       title={Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet},
       author={Templeton, Adly and Conerly, Tom and Marcus, Jonathan and Lindsey, Jack and Bricken, Trenton and Chen, Brian and Pearce, Adam and Citro, Craig and Ameisen, Emmanuel and Jones, Andy and Cunningham, Hoagy and Turner, Nicholas L and McDougall, Callum and MacDiarmid, Monte and Freeman, C. Daniel and Sumers, Theodore R. and Rees, Edward and Batson, Joshua and Jermyn, Adam and Carter, Shan and Olah, Chris and Henighan, Tom},
       year={2024},
       journal={Transformer Circuits Thread},
       url={https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html}
    }

@article{chen2024selfie,
  title={Selfie: Self-interpretation of large language model embeddings},
  author={Chen, Haozhe and Vondrick, Carl and Mao, Chengzhi},
  journal={arXiv preprint arXiv:2403.10949},
  year={2024}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@misc{cai2024internlm2,
      title={InternLM2 Technical Report},
      author={Zheng Cai and Maosong Cao and Haojiong Chen and Kai Chen and Keyu Chen and Xin Chen and Xun Chen and Zehui Chen and Zhi Chen and Pei Chu and Xiaoyi Dong and Haodong Duan and Qi Fan and Zhaoye Fei and Yang Gao and Jiaye Ge and Chenya Gu and Yuzhe Gu and Tao Gui and Aijia Guo and Qipeng Guo and Conghui He and Yingfan Hu and Ting Huang and Tao Jiang and Penglong Jiao and Zhenjiang Jin and Zhikai Lei and Jiaxing Li and Jingwen Li and Linyang Li and Shuaibin Li and Wei Li and Yining Li and Hongwei Liu and Jiangning Liu and Jiawei Hong and Kaiwen Liu and Kuikun Liu and Xiaoran Liu and Chengqi Lv and Haijun Lv and Kai Lv and Li Ma and Runyuan Ma and Zerun Ma and Wenchang Ning and Linke Ouyang and Jiantao Qiu and Yuan Qu and Fukai Shang and Yunfan Shao and Demin Song and Zifan Song and Zhihao Sui and Peng Sun and Yu Sun and Huanze Tang and Bin Wang and Guoteng Wang and Jiaqi Wang and Jiayu Wang and Rui Wang and Yudong Wang and Ziyi Wang and Xingjian Wei and Qizhen Weng and Fan Wu and Yingtong Xiong and Chao Xu and Ruiliang Xu and Hang Yan and Yirong Yan and Xiaogui Yang and Haochen Ye and Huaiyuan Ying and Jia Yu and Jing Yu and Yuhang Zang and Chuyu Zhang and Li Zhang and Pan Zhang and Peng Zhang and Ruijie Zhang and Shuo Zhang and Songyang Zhang and Wenjian Zhang and Wenwei Zhang and Xingcheng Zhang and Xinyue Zhang and Hui Zhao and Qian Zhao and Xiaomeng Zhao and Fengzhe Zhou and Zaida Zhou and Jingming Zhuo and Yicheng Zou and Xipeng Qiu and Yu Qiao and Dahua Lin},
      year={2024},
      eprint={2403.17297},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{meta2024introducing,
  title={Introducing Llama 3.1: Our most capable models to date},
  author={Meta, AI},
  journal={Meta AI Blog},
  volume={12},
  year={2024}
}

@article{team2024gemma,
  title={Gemma 2: Improving open language models at a practical size},
  author={Team, Gemma and Riviere, Morgane and Pathak, Shreya and Sessa, Pier Giuseppe and Hardin, Cassidy and Bhupatiraju, Surya and Hussenot, L{\'e}onard and Mesnard, Thomas and Shahriari, Bobak and Ram{\'e}, Alexandre and others},
  journal={arXiv preprint arXiv:2408.00118},
  year={2024}
}

@article{yang2024qwen2,
  title={Qwen2. 5 Technical Report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024}
}

@inproceedings{zbontar2021barlow,
  title={Barlow twins: Self-supervised learning via redundancy reduction},
  author={Zbontar, Jure and Jing, Li and Misra, Ishan and LeCun, Yann and Deny, St{\'e}phane},
  booktitle={International conference on machine learning},
  pages={12310--12320},
  year={2021},
  organization={PMLR}
}

@inproceedings{schroff2015facenet,
  title={Facenet: A unified embedding for face recognition and clustering},
  author={Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={815--823},
  year={2015}
}

@inproceedings{hadsell2006dimensionality,
  title={Dimensionality reduction by learning an invariant mapping},
  author={Hadsell, Raia and Chopra, Sumit and LeCun, Yann},
  booktitle={2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06)},
  volume={2},
  pages={1735--1742},
  year={2006},
  organization={IEEE}
}

@article{zhang2024reef,
  title={Reef: Representation encoding fingerprints for large language models},
  author={Zhang, Jie and Liu, Dongrui and Qian, Chen and Zhang, Linfeng and Liu, Yong and Qiao, Yu and Shao, Jing},
  journal={arXiv preprint arXiv:2410.14273},
  year={2024}
}

@ARTICLE{2024arXiv241104986W,
       author = {{Wu}, Zhaofeng and {Yu}, Xinyan Velocity and {Yogatama}, Dani and {Lu}, Jiasen and {Kim}, Yoon},
        title = "{The Semantic Hub Hypothesis: Language Models Share Semantic Representations Across Languages and Modalities}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computation and Language},
         year = 2024,
        month = nov,
          eid = {arXiv:2411.04986},
        pages = {arXiv:2411.04986},
          doi = {10.48550/arXiv.2411.04986},
archivePrefix = {arXiv},
       eprint = {2411.04986},
 primaryClass = {cs.CL},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2024arXiv241104986W},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{zhang2024llm,
  title={LLM as a Mastermind: A Survey of Strategic Reasoning with Large Language Models},
  author={Zhang, Yadong and Mao, Shaoguang and Ge, Tao and Wang, Xun and de Wynter, Adrian and Xia, Yan and Wu, Wenshan and Song, Ting and Lan, Man and Wei, Furu},
  journal={arXiv preprint arXiv:2404.01230},
  year={2024}
}

@inproceedings{nazi2024large,
  title={Large language models in healthcare and medical domain: A review},
  author={Nazi, Zabir Al and Peng, Wei},
  booktitle={Informatics},
  volume={11},
  number={3},
  pages={57},
  year={2024},
  organization={MDPI}
}

@inproceedings{madsen2024self,
  title={Are self-explanations from Large Language Models faithful?},
  author={Madsen, Andreas and Chandar, Sarath and Reddy, Siva},
  booktitle={Findings of the Association for Computational Linguistics ACL 2024},
  pages={295--337},
  year={2024}
}

@article{madsen2024interpretability,
  title={Interpretability Needs a New Paradigm},
  author={Madsen, Andreas and Lakkaraju, Himabindu and Reddy, Siva and Chandar, Sarath},
  journal={arXiv preprint arXiv:2405.05386},
  year={2024}
}

@article{ghandeharioun2024patchscope,
  title={Patchscope: A unifying framework for inspecting hidden representations of language models},
  author={Ghandeharioun, Asma and Caciularu, Avi and Pearce, Adam and Dixon, Lucas and Geva, Mor},
  journal={arXiv preprint arXiv:2401.06102},
  year={2024}
}

@inproceedings{wei2024diff,
  title={Diff-eRank: A Novel Rank-Based Metric for Evaluating Large Language Models},
  author={Wei, Lai and Tan, Zhiquan and Li, Chenghai and Wang, Jindong and Huang, Weiran},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}


@article{dang2024explainable,
  title={Explainable and interpretable multimodal large language models: A comprehensive survey},
  author={Dang, Yunkai and Huang, Kaichen and Huo, Jiahao and Yan, Yibo and Huang, Sirui and Liu, Dongrui and Gao, Mengxi and Zhang, Jie and Qian, Chen and Wang, Kun and others},
  journal={arXiv preprint arXiv:2412.02104},
  year={2024}
}

@article{chuang2021measuring,
  title={Measuring generalization with optimal transport},
  author={Chuang, Ching-Yao and Mroueh, Youssef and Greenewald, Kristjan and Torralba, Antonio and Jegelka, Stefanie},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={8294--8306},
  year={2021}
}

@article{ji2024beavertails,
  title={Beavertails: Towards improved safety alignment of llm via a human-preference dataset},
  author={Ji, Jiaming and Liu, Mickel and Dai, Josef and Pan, Xuehai and Zhang, Chi and Bian, Ce and Chen, Boyuan and Sun, Ruiyang and Wang, Yizhou and Yang, Yaodong},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{Nostalgebraist2020,
  title={interpreting GPT: the logit lens},
  author={nostalgebraist},
  url={https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens},
  year={2020}
}

@article{bills2023language,
  title={Language models can explain neurons in language models},
  author={Bills, Steven and Cammarata, Nick and Mossing, Dan and Tillman, Henk and Gao, Leo and Goh, Gabriel and Sutskever, Ilya and Leike, Jan and Wu, Jeff and Saunders, William},
  journal={URL https://openaipublic. blob. core. windows. net/neuron-explainer/paper/index. html.(Date accessed: 14.05. 2023)},
  volume={2},
  year={2023}
}

@article{qian2024dean,
  title={Dean: Deactivating the coupled neurons to mitigate fairness-privacy conflicts in large language models},
  author={Qian, Chen and Liu, Dongrui and Zhang, Jie and Liu, Yong and Shao, Jing},
  journal={arXiv preprint arXiv:2410.16672},
  year={2024}
}

@article{turpin2024language,
  title={Language models don't always say what they think: unfaithful explanations in chain-of-thought prompting},
  author={Turpin, Miles and Michael, Julian and Perez, Ethan and Bowman, Samuel},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{nye2021show,
  title={Show your work: Scratchpads for intermediate computation with language models},
  author={Nye, Maxwell and Andreassen, Anders Johan and Gur-Ari, Guy and Michalewski, Henryk and Austin, Jacob and Bieber, David and Dohan, David and Lewkowycz, Aitor and Bosma, Maarten and Luan, David and others},
  journal={arXiv preprint arXiv:2112.00114},
  year={2021}
}

@article{chen2023models,
  title={Do models explain themselves? counterfactual simulatability of natural language explanations},
  author={Chen, Yanda and Zhong, Ruiqi and Ri, Narutatsu and Zhao, Chen and He, He and Steinhardt, Jacob and Yu, Zhou and McKeown, Kathleen},
  journal={arXiv preprint arXiv:2307.08678},
  year={2023}
}

@article{huang2023can,
  title={Can large language models explain themselves? a study of llm-generated self-explanations},
  author={Huang, Shiyuan and Mamidanna, Siddarth and Jangam, Shreedhar and Zhou, Yilun and Gilpin, Leilani H},
  journal={arXiv preprint arXiv:2310.11207},
  year={2023}
}

@article{hendrycks2020measuring,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}

@article{hendrycksmath2021,
  title={Measuring Mathematical Problem Solving With the MATH Dataset},
  author={Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt},
  journal={NeurIPS},
  year={2021}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{zhong2023agieval,
  title={Agieval: A human-centric benchmark for evaluating foundation models},
  author={Zhong, Wanjun and Cui, Ruixiang and Guo, Yiduo and Liang, Yaobo and Lu, Shuai and Wang, Yanlin and Saied, Amin and Chen, Weizhu and Duan, Nan},
  journal={arXiv preprint arXiv:2304.06364},
  year={2023}
}

@article{li2024salad,
  title={Salad-bench: A hierarchical and comprehensive safety benchmark for large language models},
  author={Li, Lijun and Dong, Bowen and Wang, Ruohui and Hu, Xuhao and Zuo, Wangmeng and Lin, Dahua and Qiao, Yu and Shao, Jing},
  journal={arXiv preprint arXiv:2402.05044},
  year={2024}
}

@article{huttenlocher1993comparing,
  title={Comparing images using the Hausdorff distance},
  author={Huttenlocher, Daniel P and Klanderman, Gregory A. and Rucklidge, William J},
  journal={IEEE Transactions on pattern analysis and machine intelligence},
  volume={15},
  number={9},
  pages={850--863},
  year={1993},
  publisher={IEEE}
}

@inproceedings{roy2007effective,
  title={The effective rank: A measure of effective dimensionality},
  author={Roy, Olivier and Vetterli, Martin},
  booktitle={2007 15th European signal processing conference},
  pages={606--610},
  year={2007},
  organization={IEEE}
}

@article{rottger2023xstest,
  title={Xstest: A test suite for identifying exaggerated safety behaviours in large language models},
  author={R{\"o}ttger, Paul and Kirk, Hannah Rose and Vidgen, Bertie and Attanasio, Giuseppe and Bianchi, Federico and Hovy, Dirk},
  journal={arXiv preprint arXiv:2308.01263},
  year={2023}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@article{rosati2024representation,
  title={Representation noising effectively prevents harmful fine-tuning on LLMs},
  author={Rosati, Domenic and Wehner, Jan and Williams, Kai and Bartoszcze, {\L}ukasz and Atanasov, David and Gonzales, Robie and Majumdar, Subhabrata and Maple, Carsten and Sajjad, Hassan and Rudzicz, Frank},
  journal={arXiv preprint arXiv:2405.14577},
  year={2024}
}

@article{li2024wmdp,
  title={The wmdp benchmark: Measuring and reducing malicious use with unlearning},
  author={Li, Nathaniel and Pan, Alexander and Gopal, Anjali and Yue, Summer and Berrios, Daniel and Gatti, Alice and Li, Justin D and Dombrowski, Ann-Kathrin and Goel, Shashwat and Phan, Long and others},
  journal={arXiv preprint arXiv:2403.03218},
  year={2024}
}

@article{wu2024reft,
  title={Reft: Representation finetuning for language models},
  author={Wu, Zhengxuan and Arora, Aryaman and Wang, Zheng and Geiger, Atticus and Jurafsky, Dan and Manning, Christopher D and Potts, Christopher},
  journal={arXiv preprint arXiv:2404.03592},
  year={2024}
}

@article{solomon2022k,
  title={k-variance: A clustered notion of variance},
  author={Solomon, Justin and Greenewald, Kristjan and Nagaraja, Haikady},
  journal={SIAM Journal on Mathematics of Data Science},
  volume={4},
  number={3},
  pages={957--978},
  year={2022},
  publisher={SIAM}
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@book{villani2009optimal,
  title={Optimal transport: old and new},
  author={Villani, C{\'e}dric and others},
  volume={338},
  year={2009},
  publisher={Springer}
}

@article{jiang2020neurips,
  title={Neurips 2020 competition: Predicting generalization in deep learning},
  author={Jiang, Yiding and Foret, Pierre and Yak, Scott and Roy, Daniel M and Mobahi, Hossein and Dziugaite, Gintare Karolina and Bengio, Samy and Gunasekar, Suriya and Guyon, Isabelle and Neyshabur, Behnam},
  journal={arXiv preprint arXiv:2012.07976},
  year={2020}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{li2023large,
  title={Large language models in finance: A survey},
  author={Li, Yinheng and Wang, Shaofei and Ding, Han and Chen, Hang},
  booktitle={Proceedings of the fourth ACM international conference on AI in finance},
  pages={374--382},
  year={2023}
}

@article{barrault2024large,
  title={Large Concept Models: Language Modeling in a Sentence Representation Space},
  author={Barrault, Lo{\"\i}c and Duquenne, Paul-Ambroise and Elbayad, Maha and Kozhevnikov, Artyom and Alastruey, Belen and Andrews, Pierre and Coria, Mariano and Couairon, Guillaume and Costa-juss{\`a}, Marta R and Dale, David and others},
  journal={arXiv e-prints},
  pages={arXiv--2412},
  year={2024}
}

@article{inan2023llama,
  title={Llama guard: Llm-based input-output safeguard for human-ai conversations},
  author={Inan, Hakan and Upasani, Kartikeya and Chi, Jianfeng and Rungta, Rashi and Iyer, Krithika and Mao, Yuning and Tontchev, Michael and Hu, Qing and Fuller, Brian and Testuggine, Davide and others},
  journal={arXiv preprint arXiv:2312.06674},
  year={2023}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{lang2024theoretical,
  title={Theoretical Analysis of Weak-to-Strong Generalization},
  author={Lang, Hunter and Sontag, David and Vijayaraghavan, Aravindan},
  journal={arXiv preprint arXiv:2405.16043},
  year={2024}
}

@article{villani2009wasserstein,
  title={The wasserstein distances},
  author={Villani, C{\'e}dric and Villani, C{\'e}dric},
  journal={Optimal transport: old and new},
  pages={93--111},
  year={2009},
  publisher={Springer}
}

@article{huang2024empirical,
  title={An empirical study of llm-as-a-judge for llm evaluation: Fine-tuned judge models are task-specific classifiers},
  author={Huang, Hui and Qu, Yingqi and Liu, Jing and Yang, Muyun and Zhao, Tiejun},
  journal={arXiv preprint arXiv:2403.02839},
  year={2024}
}

@article{abburi2023generative,
  title={Generative ai text classification using ensemble llm approaches},
  author={Abburi, Harika and Suesserman, Michael and Pudota, Nirmala and Veeramani, Balaji and Bowen, Edward and Bhattacharya, Sanmitra},
  journal={arXiv preprint arXiv:2309.07755},
  year={2023}
}

@article{chen2023token,
  title={Token prediction as implicit classification to identify LLM-generated text},
  author={Chen, Yutian and Kang, Hao and Zhai, Vivian and Li, Liangze and Singh, Rita and Raj, Bhiksha},
  journal={arXiv preprint arXiv:2311.08723},
  year={2023}
}

@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16000--16009},
  year={2022}
}

@article{zeng2024similar,
  title={Similar data points identification with llm: A human-in-the-loop strategy using summarization and hidden state insights},
  author={Zeng, Xianlong and Gao, Yijing and Song, Fanghao and Liu, Ang},
  journal={arXiv preprint arXiv:2404.04281},
  year={2024}
}

@article{huang2024vaccine,
  title={Vaccine: Perturbation-aware alignment for large language model},
  author={Huang, Tiansheng and Hu, Sihao and Liu, Ling},
  journal={arXiv preprint arXiv:2402.01109},
  year={2024}
}

@article{li2024getting,
  title={Getting More Juice Out of the SFT Data: Reward Learning from Human Demonstration Improves SFT for LLM Alignment},
  author={Li, Jiaxiang and Zeng, Siliang and Wai, Hoi-To and Li, Chenliang and Garcia, Alfredo and Hong, Mingyi},
  journal={arXiv preprint arXiv:2405.17888},
  year={2024}
}

@inproceedings{cherti2023reproducible,
  title={Reproducible scaling laws for contrastive language-image learning},
  author={Cherti, Mehdi and Beaumont, Romain and Wightman, Ross and Wortsman, Mitchell and Ilharco, Gabriel and Gordon, Cade and Schuhmann, Christoph and Schmidt, Ludwig and Jitsev, Jenia},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2818--2829},
  year={2023}
}

@misc{2023opencompass,
    title={OpenCompass: A Universal Evaluation Platform for Foundation Models},
    author={OpenCompass Contributors},
    howpublished = {\url{https://github.com/open-compass/opencompass}},
    year={2023}
}

@article{xu2024good,
  title={Good Idea or Not, Representation of LLM Could Tell},
  author={Xu, Yi and Xue, Bo and Sheng, Shuqian and Deng, Cheng and Ding, Jiaxin and Shen, Zanwei and Fu, Luoyi and Wang, Xinbing and Zhou, Chenghu},
  journal={arXiv preprint arXiv:2409.13712},
  year={2024}
}

@article{orgad2024llms,
  title={Llms know more than they show: On the intrinsic representation of llm hallucinations},
  author={Orgad, Hadas and Toker, Michael and Gekhman, Zorik and Reichart, Roi and Szpektor, Idan and Kotek, Hadas and Belinkov, Yonatan},
  journal={arXiv preprint arXiv:2410.02707},
  year={2024}
}

@article{yin2024lofit,
  title={LoFiT: Localized Fine-tuning on LLM Representations},
  author={Yin, Fangcong and Ye, Xi and Durrett, Greg},
  journal={arXiv preprint arXiv:2406.01563},
  year={2024}
}

@article{azaria2023internal,
  title={The internal state of an LLM knows when it's lying},
  author={Azaria, Amos and Mitchell, Tom},
  journal={arXiv preprint arXiv:2304.13734},
  year={2023}
}

@article{li2024open,
  title={Open the Pandora's Box of LLMs: Jailbreaking LLMs through Representation Engineering},
  author={Li, Tianlong and Zheng, Xiaoqing and Huang, Xuanjing},
  journal={arXiv preprint arXiv:2401.06824},
  year={2024}
}

@inproceedings{sevastjanova2022lmfingerprints,
  title={LMFingerprints: Visual explanations of language model embedding spaces through layerwise contextualization scores},
  author={Sevastjanova, Rita and Kalouli, A and Beck, Christin and Hauptmann, Hanna and El-Assady, Mennatallah},
  booktitle={Computer Graphics Forum},
  volume={41},
  number={3},
  pages={295--307},
  year={2022},
  organization={Wiley Online Library}
}

@article{yang2024fingerprint,
  title={A Fingerprint for Large Language Models},
  author={Yang, Zhiguang and Wu, Hanzhou},
  journal={arXiv preprint arXiv:2407.01235},
  year={2024}
}

@article{zhang2024real,
  title={REAL: Response Embedding-based Alignment for LLMs},
  author={Zhang, Honggen and Zhao, Xufeng and Molybog, Igor and Zhang, June},
  journal={arXiv preprint arXiv:2409.17169},
  year={2024}
}

@article{bartlett2017spectrally,
  title={Spectrally-normalized margin bounds for neural networks},
  author={Bartlett, Peter L and Foster, Dylan J and Telgarsky, Matus J},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

###################################### arxiv #####################################################

@article{qian2024towards,
  title={Towards tracing trustworthiness dynamics: Revisiting pre-training period of large language models},
  author={Qian, Chen and Zhang, Jie and Yao, Wei and Liu, Dongrui and Yin, Zhenfei and Qiao, Yu and Liu, Yong and Shao, Jing},
  journal={arXiv preprint arXiv:2402.19465},
  year={2024}
}

@article{zhang2024better,
  title={The better angels of machine personality: How personality relates to llm safety},
  author={Zhang, Jie and Liu, Dongrui and Qian, Chen and Gan, Ziyue and Liu, Yong and Qiao, Yu and Shao, Jing},
  journal={arXiv preprint arXiv:2407.12344},
  year={2024}
}

@article{ren2024derail,
  title={Derail Yourself: Multi-turn LLM Jailbreak Attack through Self-discovered Clues},
  author={Ren, Qibing and Li, Hao and Liu, Dongrui and Xie, Zhanxu and Lu, Xiaoya and Qiao, Yu and Sha, Lei and Yan, Junchi and Ma, Lizhuang and Shao, Jing},
  journal={arXiv preprint arXiv:2410.10700},
  year={2024}
}

@article{hu2024vlsbench,
  title={Vlsbench: Unveiling visual leakage in multimodal safety},
  author={Hu, Xuhao and Liu, Dongrui and Li, Hao and Huang, Xuanjing and Shao, Jing},
  journal={arXiv preprint arXiv:2411.19939},
  year={2024}
}

@article{ren2024identifying,
  title={Identifying semantic induction heads to understand in-context learning},
  author={Ren, Jie and Guo, Qipeng and Yan, Hang and Liu, Dongrui and Zhang, Quanshi and Qiu, Xipeng and Lin, Dahua},
  journal={arXiv preprint arXiv:2402.13055},
  year={2024}
}

@article{liu2023towards,
  title={Towards the difficulty for a deep neural network to learn concepts of different complexities},
  author={Liu, Dongrui and Deng, Huiqi and Cheng, Xu and Ren, Qihan and Wang, Kangrui and Zhang, Quanshi},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={41283--41304},
  year={2023}
}

@inproceedings{zhou2024explaining,
  title={Explaining generalization power of a dnn using interactive concepts},
  author={Zhou, Huilin and Zhang, Hao and Deng, Huiqi and Liu, Dongrui and Shen, Wen and Chan, Shih-Han and Zhang, Quanshi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={15},
  pages={17105--17113},
  year={2024}
}

@article{ren2024towards,
  title={Towards the dynamics of a dnn learning symbolic interactions},
  author={Ren, Qihan and Xu, Yang and Zhang, Junpeng and Xin, Yue and Liu, Dongrui and Zhang, Quanshi},
  journal={arXiv preprint arXiv:2407.19198},
  year={2024}
}

@article{shen2021interpreting,
  title={Interpreting representation quality of dnns for 3d point cloud processing},
  author={Shen, Wen and Ren, Qihan and Liu, Dongrui and Zhang, Quanshi},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={8857--8870},
  year={2021}
}