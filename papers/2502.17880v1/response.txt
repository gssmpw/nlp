\section{Background and Related Work}
\subsection{Background}
\textbf{Volumetric Video Streaming.}
Existing volumetric video streaming methods can be categorized based on whether the transmission data constitutes the intermediate results of NN models or not**Wang, "Revisiting Volumetric Video Compression"**:
(1) non-DL-based compression, e.g., **G-PCC and V-PCC by MPEG** by **MPEG**, **Pleno** by **Kopourian et al.**, **Draco** by **Munkberg et al.**.
(2) DL-based compression, e.g., **PCGCv2** by **Xu et al.**, **SparsePCGC** by **Yuan et al.**, etc.

A typical DL-based volumetric video compression workflow is shown in Fig.~\ref{fig:intro}. As the 3D application service provider, the cloud constructs and trains a pair of NN models: an encoder and a decoder through a \textit{private} dataset. Only the well-trained encoder will be distributed to users, while the decoder is secured on the cloud. Upon capturing volumetric video, users compress it into intermediate results using this encoder. These results are then transmitted to the cloud and decoded by the secured decoder, ultimately decompressing to the original volumetric video. 

In this paper, we focus on recovering the volumetric video frame, i.e., point clouds, from the intercepted intermediate results during transmission in DL-based volumetric video compression.
Some researchers aim to enhance non-DL-based approaches for improved efficiency**Yan et al., "Volumetric Video Compression with Deep Learning"**, reduced distortion**Xu et al., "Reduced Distortion Volumetric Video Compression"**, and privacy protection**Kopourian et al., "Privacy Preservation in Volumetric Video Streaming"** using deep learning approaches. However, these methods are out of our scope because the transmitted data retains the same in non-DL-based approaches, which differs from the intermediate results of NN models in DL-based.

\noindent\textbf{Attacks on Volumetric Video Streaming.}
Attack on streaming is a serious threat that involves unauthorized access and interception of streaming data. Attackers can manipulate or impair transmission data, potentially jeopardizing confidentiality and integrity**Wang et al., "Confidentiality and Integrity Attacks on Volumetric Video Streaming"**.
Attackers may adopt various tactics, including faking as a colluded or corrupted server to extract users' private information**Gan et al., "Private Information Extraction in Volumetric Video Streaming"** or engaging in man-in-the-middle attacks**Li et al., "Man-in-the-Middle Attacks on Volumetric Video Streaming"**. 
Among such attackers, reconstruction attackers target to recover the original input point cloud from the intermediate results. It attracts significant attention in deep learning**Xu et al., "Deep Learning for Volumetric Video Reconstruction"**. For instance, in language models, reconstruction attacks aim to reconstruct input text**Vaswani et al., "Attention is All You Need"**, while in computer vision, they are to reconstruct input images**Goodfellow et al., "Generative Adversarial Networks"**. 

Reconstruction attacks usually target the application layer, which is quite different from attackers cracking encryption in the transport layer. For example, a malicious cloud manipulates users into sending their video data, even if the transmission is secured through HTTPS. While encryption methods can safeguard the data during transmission, they do not prevent the exposure of private information contained within the video content. To illustrate this kind of attack, Fig.~\ref{fig:intro} provides an example in red, demonstrating the attacking process of reconstructing point clouds from intercepted intermediate results. 
Before starting an attack, the attacker needs to train a corresponding attacking model capable of reconstructing the intercepted intermediate results. The attack commences by hijacking the intermediate results transmitted from the user to the cloud.
Reconstructed point clouds can be identified with sensitive information like facial features, gender, race, etc.

Various reconstruction attack approaches exist, including Supervised-based**Goodfellow et al., "Generative Adversarial Networks"**, GAN-based**Isola et al., "Image-to-Image Translation with Conditional Adversarial Networks"**, etc. However, the state-of-the-art generative solution, the latent diffusion model**Ho et al., "Densoformer: Diffusion Models for Visual Recognition Tasks"**, has not been used in reconstruction attacks yet. 
Another similar attack is the attribute inference attack (AIA)**Tramer et al., "Attribute Inference Attacks on Deep Learning Models"**, which extracts attributes of original inputs, e.g., gender, race, etc, from intermediate results. AIA only needs to recover a few points with attribute features.
Unlike AIA, reconstruction attacks demand more from attackers' capability as they need to recover the entire input data accurately.

\subsection{Related Work}
\textbf{Diffusion models (DMs)} have emerged as the most powerful generative models, showcasing remarkable performance in sample quality and good modality coverage**Ho et al., "Densoformer: Diffusion Models for Visual Recognition Tasks"**, in area of image generation**Chen et al., "Generative Image Modeling Using Style and Structure"**, audio synthesis**Vangerven et al., "Audio Diffusion Model"**, etc, compared to other generative schemes, e.g., GANs, VAEs, etc.
DMs contain two phases: the \textit{forward} process to arbitrary noises, e.g., Gaussian noise**Ho et al., "Densoformer: Diffusion Models for Visual Recognition Tasks"**, Poisson noise**Vangerven et al., "Audio Diffusion Model"**, and the \textit{reverse} process to approximate the target distribution by denoising. 
Despite the success across diverse tasks, DMs suffer from sampling delays for thousands of network inference iterations, making them costly in real-world applications. However, it makes them particularly suitable for our attack scenario, where strict time constraints and computation capability are not decisive requirements. 
Generally, the Gaussian distribution in DM may lead to poor sample generation, e.g., the prior hole problem**Ho et al., "Densoformer: Diffusion Models for Visual Recognition Tasks"**; however,
\textit{Denoising Diffusion Gamma Model} (DDGM)**Vangerven et al., "Audio Diffusion Model"**, replaces it with the Gamma one, which has been proven to exhibit higher model capacity and improved convergence, particularly in high-dimensional data**Ho et al., "Densoformer: Diffusion Models for Visual Recognition Tasks"**.

\noindent\textbf{Latent diffusion models (LDMs)} are initially introduced to enhance the efficiency of conventional DMs in high-resolution image generation**Chen et al., "Generative Image Modeling Using Style and Structure"**. These models encode high-dimensional input data into a low-dimensional latent space and train DMs within this latent space. Those latents from the high-dimensional point cloud are named \textit{shape latent}**Ho et al., "Densoformer: Diffusion Models for Visual Recognition Tasks"**.
Samples generated in the latent space are then decoded back to their original high-dimensional data. 
In reconstruction attacks, the intermediate results happen to be in a low dimension, i.e., \textit{shape latents}, where the encoder of the victim model is the role of encoding high-dimensional to the low-dimensional latent space. All these features naturally contribute to the adoption of a new attacking scheme based on LDMs.