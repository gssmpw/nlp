\section{Introduction}

\begin{figure}[!t]
    \centering
    \includegraphics[width=1\linewidth]{data/movti.pdf}
    \caption{ \small Performance and computation comparison of fine-tuning methods in NLP and CV Tasks. (a) For NLP on LLaMA3.1-8B, SSH achieves 7.93 GPT-4 score, closely matching full fine-tuning's 7.95 score, while using less than 0.1\% of the parameters. (b) In CV tasks, SSH achieves 77.4\% accuracy, matching the performance of full fine-tuning with significantly fewer parameters. (c) \& (d) SSH reduces up to 55\% of GFLOPs compared to FourierFT in both NLP and CV tasks, providing significant computation efficiency gains.
    }
    \label{fig:mov}
\end{figure}


Pretrained foundation models, such as GPT-4~\cite{islam2024gpt}, LLaMA3.1~\cite{touvron2023llama}, and Vision Transformers (ViT)\cite{dosovitskiy2020image}, have demonstrated remarkable performance across diverse natural language processing (NLP)\cite{huang2024gradient,tao2024robustness,shen2024comparative,shen2024altgen,shen2024parameter} and vision tasks~\cite{huang2025image2text2image,huang2024novel}. 
This success can largely be attributed to the unprecedented growth in model size~\cite{wei2022emergent}. 
However, as these models scale up to billions of parameters, adapting them for downstream tasks in various domains presents significant computational~\cite{shen2023thermal,shen2023thermal1,shen2022tcps,niknam20233d} and memory challenges~\cite{guo2024easter,aghapour2024piqi}. 
Fully fine-tuning these large models becomes prohibitively expensive, both in terms of memory consumption and computational resources. 
For instance, fine-tuning the LLaMA3.1 model with 8 billion parameters requires 60GB of GPU memory. 
While parameter-efficient fine-tuning (PEFT) methods like LoRA~\cite{hu2022lora} and QLoRA~\cite{dettmers2024qlora} can reduce memory requirements to 16GB and 6GB, respectively, they still fall short when applied to larger models such as LLaMA3.1 70B, which demands up to 48GB of memory, even with Q-LoRA.

LoRA and its successors~\cite{lialin2023relora,renduchintala2024tiedlora,liu2024dora} have made substantial progress by introducing low-rank adaptations and quantization techniques to mitigate the memory overhead when fine-tuning large models. 
%However, these methods primarily operate in the weight space of the original models, and efficiency remains to be improved. 
Despite their ability to reduce the number of trainable parameters, as these methods primarily operate in the weight space of the original models, they still face limitations in terms of overall computational efficiency and GPU memory requirements, especially when scaling to massive models.

A promising alternative to address this bottleneck is to leverage the frequency transformations, which offer a more compact representation of model weights with less trainable parameters. 
Recent work on frequency-based PEFT, such as the discrete Fourier transform (DFT) approach~\cite{gao2024parameter}, has shown that transforming weight matrices into the spectral domain and updating spectral components can significantly reduce the number of trainable parameters. However, DFT operates in the complex domain, introducing potential computational overhead and numerical instability~\cite{press2007numerical}, particularly in large-scale models~\cite{gao2024parameter}. 
Such numerical inaccuracies inevitably degrade the performance. Moreover, the asymmetry between DFT and its inverse (iDFT) complicates forward and backward transformations, increasing computational intensity. 

To address these challenges, we propose a novel fine-tuning framework, \textbf{S}parse \textbf{S}pectrum Adaptation via Discrete \textbf{H}artley Transform (SSH).
The advantage of leveraging DHT over DFT~\cite{gao2024parameter} is twofold.
Firstly, DHT integrates both cosine and sine components in a single operation. It avoids the imaginary number computation, simplifies the computations and improves the numerical stability.
Secondly, its symmetry—where the inverse transformation is identical to the forward—streamlines the fine-tuning process, allowing efficient transitions between time and frequency domains. 
SSH selectively fine-tunes the most critical frequency components, identifies through the energy compaction properties, and efficiently recovers weight updates via inverse DHT. By capitalizing on the symmetrical nature of DHT and reducing parameter usage, SSH provides a highly parameter-efficient and computationally optimized fine-tuning strategy.

As shown in Fig.~\ref{fig:mov}(a) \& (b), SSH achieves comparable performance in both instruction tuning with the LLaMA3.1-8B model and image classification with the ViT 85.8M model, with significantly fewer parameters than LoRA and FourierFT. 
%Specifically, SSH attains higher accuracy with just 25\% of the parameters used by FourierFT. 
Fig.~\ref{fig:mov}(c) \& (d) further demonstrate its superior computational efficiency, requiring 55\% fewer GFLOPs than FourierFT. 
This is due not only to reduce the parameter count but also to avoid the complex number handling required by FourierFT, where real and imaginary parts must be processed separately.

Concretely, our contribution is threefold.
\begin{itemize}
\item We introduce \textbf{SSH}, a novel PEFT method based on discrete Hartley transform.
It simplifies operations and enhances numerical stability by avoiding complex arithmetic.
\item An energy-based frequency selection strategy is proposed to help SSH selectively fine-tune the most critical frequency components.
\item SSH shows superior performance and computational efficiency across various NLP, vision, and multi-modal tasks, achieving significant parameter savings and GFLOPs reduction.
\end{itemize}