@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International conference on machine learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}
@article{liao2023make,
  title={Make Pre-trained Model Reversible: From Parameter to Memory Efficient Fine-Tuning},
  author={Liao, Baohao and Tan, Shaomu and Monz, Christof},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}
@article{gomez2017reversible,
  title={The reversible residual network: Backpropagation without storing activations},
  author={Gomez, Aidan N and Ren, Mengye and Urtasun, Raquel and Grosse, Roger B},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@inproceedings{yi2024learning,
  title={Learning Spectral-decomposited Tokens for Domain Generalized Semantic Segmentation},
  author={Yi, Jingjun and Bi, Qi and Zheng, Hao and Zhan, Haolan and Ji, Wei and Huang, Yawen and Li, Yuexiang and Zheng, Yefeng},
  booktitle={ACM Multimedia 2024},
  year={2024}
}
@article{zhao2024dr,
  title={Dr2Net: Dynamic Reversible Dual-Residual Networks for Memory-Efficient Finetuning},
  author={Zhao, Chen and Liu, Shuming and Mangalam, Karttikeya and Qian, Guocheng and Zohra, Fatimah and Alghannam, Abdulmohsen and Malik, Jitendra and Ghanem, Bernard},
  journal={Conference on Computer Vision and Pattern Recognition},
  year={2024}
}
@article{zhao2024galore,
  title={Galore: Memory-efficient llm training by gradient low-rank projection},
  author={Zhao, Jiawei and Zhang, Zhenyu and Chen, Beidi and Wang, Zhangyang and Anandkumar, Anima and Tian, Yuandong},
  journal={International Conference on Machine Learning},
  year={2024}
}
@article{liu2024dora,
  title={DoRA: Weight-Decomposed Low-Rank Adaptation},
  author={Liu, Shih-Yang and Wang, Chien-Yi and Yin, Hongxu and Molchanov, Pavlo and Wang, Yu-Chiang Frank and Cheng, Kwang-Ting and Chen, Min-Hung},
  journal={International Conference on Machine Learning},
  year={2024}
}
@article{hu2022lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={International Conference on Learning Representations},
  year={2022}
}
@inproceedings{lialin2023relora,
  title={ReLoRA: High-Rank Training Through Low-Rank Updates},
  author={Lialin, Vladislav and Muckatira, Sherin and Shivagunde, Namrata and Rumshisky, Anna},
  booktitle={Workshop on Advancing Neural Network Training: Computational Efficiency, Scalability, and Resource Optimization (WANT@ NeurIPS 2023)},
  year={2023}
}
@article{xia2024chain,
  title={Chain of lora: Efficient fine-tuning of language models via residual learning},
  author={Xia, Wenhan and Qin, Chengwei and Hazan, Elad},
  journal={International Conference on Machine Learning},
  year={2024}
}
@article{kopiczko2024vera,
  title={Vera: Vector-based random matrix adaptation},
  author={Kopiczko, Dawid Jan and Blankevoort, Tijmen and Asano, Yuki Markus},
  journal={International Conference on Learning Representations},
  year={2024}
}
@article{salimans2016weight,
  title={Weight normalization: A simple reparameterization to accelerate training of deep neural networks},
  author={Salimans, Tim and Kingma, Durk P},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}
@article{chen2015fast,
  title={Fast low-rank estimation by projected gradient descent: General statistical and algorithmic guarantees},
  author={Chen, Yudong and Wainwright, Martin J},
  journal={arXiv preprint arXiv:1509.03025},
  year={2015}
}
@article{chen2019non,
  title={Non-convex projected gradient descent for generalized low-rank tensor regression},
  author={Chen, Han and Raskutti, Garvesh and Yuan, Ming},
  journal={Journal of Machine Learning Research},
  volume={20},
  number={5},
  pages={1--37},
  year={2019}
}
@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
}
@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}
@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}
@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16000--16009},
  year={2022}
}
@inproceedings{xie2022simmim,
  title={Simmim: A simple framework for masked image modeling},
  author={Xie, Zhenda and Zhang, Zheng and Cao, Yue and Lin, Yutong and Bao, Jianmin and Yao, Zhuliang and Dai, Qi and Hu, Han},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9653--9663},
  year={2022}
}
@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}
@article{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}
@inproceedings{tan-bansal-2019-lxmert,
    title = "{LXMERT}: Learning Cross-Modality Encoder Representations from Transformers",
    author = "Tan, Hao  and
      Bansal, Mohit",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1514",
    doi = "10.18653/v1/D19-1514",
    pages = "5100--5111",
}
@article{zhang2022opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}
@article{le2023bloom,
  title={Bloom: A 176b-parameter open-access multilingual language model},
  author={Le Scao, Teven and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c{c}}ois and Gall{\'e}, Matthias and others},
  year={2023}
}
@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}
@inproceedings{tay2023ul2,
  title={UL2: Unifying Language Learning Paradigms.},
  author={Tay, Yi and Dehghani, Mostafa and Tran, Vinh Q and Garcia, Xavier and Wei, Jason and Wang, Xuezhi and Chung, Hyung Won and Bahri, Dara and Schuster, Tal and Zheng, Huaixiu Steven and others},
  booktitle={ICLR},
  year={2023}
}
@article{li2021prefix,
  title={Prefix-tuning: Optimizing continuous prompts for generation},
  author={Li, Xiang Lisa and Liang, Percy},
  journal={arXiv preprint arXiv:2101.00190},
  year={2021}
}
@inproceedings{lester2021power,
  title={The power of scale for parameter-efficient prompt tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  booktitle={EMNLP},
  year={2021}
}
@article{razdaibiedina2023residual,
  title={Residual prompt tuning: Improving prompt tuning with residual reparameterization},
  author={Razdaibiedina, Anastasia and Mao, Yuning and Hou, Rui and Khabsa, Madian and Lewis, Mike and Ba, Jimmy and Almahairi, Amjad},
  journal={Findings of the Association for Computational Linguistics},
  year={2023}
}
@article{wang2023non,
  title={Non-Intrusive Adaptation: Input-Centric Parameter-efficient Fine-Tuning for Versatile Multimodal Modeling},
  author={Wang, Yaqing and Wu, Jialin and Dabral, Tanmaya and Zhang, Jiageng and Brown, Geoff and Lu, Chun-Ta and Liu, Frederick and Liang, Yi and Pang, Bo and Bendersky, Michael and others},
  journal={arXiv preprint arXiv:2310.12100},
  year={2023}
}
@article{rebuffi2017learning,
  title={Learning multiple visual domains with residual adapters},
  author={Rebuffi, Sylvestre-Alvise and Bilen, Hakan and Vedaldi, Andrea},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{pfeiffer2020adapterfusion,
  title={Adapterfusion: Non-destructive task composition for transfer learning},
  author={Pfeiffer, Jonas and Kamath, Aishwarya and R{\"u}ckl{\'e}, Andreas and Cho, Kyunghyun and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2005.00247},
  year={2020}
}
@article{ruckle2020adapterdrop,
  title={Adapterdrop: On the efficiency of adapters in transformers},
  author={R{\"u}ckl{\'e}, Andreas and Geigle, Gregor and Glockner, Max and Beck, Tilman and Pfeiffer, Jonas and Reimers, Nils and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2010.11918},
  year={2020}
}
@article{hambardzumyan2021warp,
  title={Warp: Word-level adversarial reprogramming},
  author={Hambardzumyan, Karen and Khachatrian, Hrant and May, Jonathan},
  journal={arXiv preprint arXiv:2101.00121},
  year={2021}
}
@article{liu2023gpt,
  title={GPT understands, too},
  author={Liu, Xiao and Zheng, Yanan and Du, Zhengxiao and Ding, Ming and Qian, Yujie and Yang, Zhilin and Tang, Jie},
  journal={AI Open},
  year={2023},
  publisher={Elsevier}
}
@article{lin2020exploring,
  title={Exploring versatile generative language model via parameter-efficient transfer learning},
  author={Lin, Zhaojiang and Madotto, Andrea and Fung, Pascale},
  journal={arXiv preprint arXiv:2004.03829},
  year={2020}
}
@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}
@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}
@article{shoeybi2019megatron,
  title={Megatron-lm: Training multi-billion parameter language models using model parallelism},
  author={Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1909.08053},
  year={2019}
}
@article{lepikhin2020gshard,
  title={Gshard: Scaling giant models with conditional computation and automatic sharding},
  author={Lepikhin, Dmitry and Lee, HyoukJoong and Xu, Yuanzhong and Chen, Dehao and Firat, Orhan and Huang, Yanping and Krikun, Maxim and Shazeer, Noam and Chen, Zhifeng},
  journal={arXiv preprint arXiv:2006.16668},
  year={2020}
}
@article{liao2023parameter,
  title={Parameter-efficient fine-tuning without introducing new latency},
  author={Liao, Baohao and Meng, Yan and Monz, Christof},
  journal={arXiv preprint arXiv:2305.16742},
  year={2023}
}
@article{liu2022few,
  title={Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning},
  author={Liu, Haokun and Tam, Derek and Muqeeth, Mohammed and Mohta, Jay and Huang, Tenghao and Bansal, Mohit and Raffel, Colin A},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={1950--1965},
  year={2022}
}

@article{liu2024tuning,
  title={Y-tuning: An efficient tuning paradigm for large-scale pre-trained models via label representation learning},
  author={Liu, Yitao and An, Chenxin and Qiu, Xipeng},
  journal={Frontiers of Computer Science},
  volume={18},
  number={4},
  pages={184320},
  year={2024},
  publisher={Springer}
}
@article{sung2022lst,
  title={Lst: Ladder side-tuning for parameter and memory efficient transfer learning},
  author={Sung, Yi-Lin and Cho, Jaemin and Bansal, Mohit},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={12991--13005},
  year={2022}
}
@article{zhou2024autopeft,
  title={Autopeft: Automatic configuration search for parameter-efficient fine-tuning},
  author={Zhou, Han and Wan, Xingchen and Vuli{\'c}, Ivan and Korhonen, Anna},
  journal={Transactions of the Association for Computational Linguistics},
  volume={12},
  pages={525--542},
  year={2024},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}
@article{zoph2016neural,
  title={Neural architecture search with reinforcement learning},
  author={Zoph, Barret and Le, Quoc V},
  journal={arXiv preprint arXiv:1611.01578},
  year={2016}
}
@misc{mao2022unipelt,
      title={UniPELT: A Unified Framework for Parameter-Efficient Language Model Tuning}, 
      author={Yuning Mao and Lambert Mathias and Rui Hou and Amjad Almahairi and Hao Ma and Jiawei Han and Wen-tau Yih and Madian Khabsa},
      year={2022},
      eprint={2110.07577},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{he2022unified,
      title={Towards a Unified View of Parameter-Efficient Transfer Learning}, 
      author={Junxian He and Chunting Zhou and Xuezhe Ma and Taylor Berg-Kirkpatrick and Graham Neubig},
      year={2022},
      eprint={2110.04366},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{mahabadi2021parameterefficient,
      title={Parameter-efficient Multi-task Fine-tuning for Transformers via Shared Hypernetworks}, 
      author={Rabeeh Karimi Mahabadi and Sebastian Ruder and Mostafa Dehghani and James Henderson},
      year={2021},
      eprint={2106.04489},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{NEURIPS2021_081be9fd,
 author = {Karimi Mahabadi, Rabeeh and Henderson, James and Ruder, Sebastian},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {1022--1035},
 publisher = {Curran Associates, Inc.},
 title = {Compacter: Efficient Low-Rank Hypercomplex Adapter Layers},
 url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/081be9fdff07f3bc808f935906ef70c0-Paper.pdf},
 volume = {34},
 year = {2021}
}
@inproceedings{zhang2023adaptive,
title={Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning },
author={Qingru Zhang and Minshuo Chen and Alexander Bukharin and Pengcheng He and Yu Cheng and Weizhu Chen and Tuo Zhao},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=lq62uWRJjiY}
}
@misc{hyeonwoo2023fedpara,
      title={FedPara: Low-Rank Hadamard Product for Communication-Efficient Federated Learning}, 
      author={Nam Hyeon-Woo and Moon Ye-Bin and Tae-Hyun Oh},
      year={2023},
      eprint={2108.06098},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@inproceedings{NEURIPS2023_faacb7a4,
 author = {Qiu, Zeju and Liu, Weiyang and Feng, Haiwen and Xue, Yuxuan and Feng, Yao and Liu, Zhen and Zhang, Dan and Weller, Adrian and Sch\"{o}lkopf, Bernhard},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {79320--79362},
 publisher = {Curran Associates, Inc.},
 title = {Controlling Text-to-Image Diffusion by Orthogonal Finetuning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/faacb7a4827b4d51e201666b93ab5fa7-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}
@misc{liu2024parameterefficient,
      title={Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization}, 
      author={Weiyang Liu and Zeju Qiu and Yao Feng and Yuliang Xiu and Yuxuan Xue and Longhui Yu and Haiwen Feng and Zhen Liu and Juyeon Heo and Songyou Peng and Yandong Wen and Michael J. Black and Adrian Weller and Bernhard Schölkopf},
      year={2024},
      eprint={2311.06243},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{renduchintala2024tiedlora,
      title={Tied-Lora: Enhancing parameter efficiency of LoRA with weight tying}, 
      author={Adithya Renduchintala and Tugrul Konuk and Oleksii Kuchaiev},
      year={2024},
      eprint={2311.09578},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{yeh2024navigating,
title={Navigating Text-To-Image Customization: From Ly{CORIS} Fine-Tuning to Model Evaluation},
author={SHIH-YING YEH and Yu-Guan Hsieh and Zhidong Gao and Bernard B W Yang and Giyeong Oh and Yanmin Gong},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=wfzXa8e783}
}
@misc{ponti2022combining,
      title={Combining Modular Skills in Multitask Learning}, 
      author={Edoardo M. Ponti and Alessandro Sordoni and Yoshua Bengio and Siva Reddy},
      year={2022},
      eprint={2202.13914},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@InProceedings{Mangalam_2022_CVPR,
    author    = {Mangalam, Karttikeya and Fan, Haoqi and Li, Yanghao and Wu, Chao-Yuan and Xiong, Bo and Feichtenhofer, Christoph and Malik, Jitendra},
    title     = {Reversible Vision Transformers},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {10830-10840}
}
@inproceedings{NIPS2017_f9be311e,
 author = {Gomez, Aidan N and Ren, Mengye and Urtasun, Raquel and Grosse, Roger B},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {The Reversible Residual Network: Backpropagation Without Storing Activations},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/f9be311e65d81a9ad8150a60844bb94c-Paper.pdf},
 volume = {30},
 year = {2017}
}
@misc{frankle2019lottery,
      title={The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks}, 
      author={Jonathan Frankle and Michael Carbin},
      year={2019},
      eprint={1803.03635},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@InProceedings{pmlr-v119-frankle20a,
  title = 	 {Linear Mode Connectivity and the Lottery Ticket Hypothesis},
  author =       {Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel and Carbin, Michael},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {3259--3269},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/frankle20a/frankle20a.pdf},
  url = 	 {https://proceedings.mlr.press/v119/frankle20a.html}
}

@InProceedings{pmlr-v97-koratana19a,
  title = 	 {{LIT}: Learned Intermediate Representation Training for Model Compression},
  author =       {Koratana, Animesh and Kang, Daniel and Bailis, Peter and Zaharia, Matei},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {3509--3518},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/koratana19a/koratana19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/koratana19a.html}
}
@misc{hinton2015distilling,
      title={Distilling the Knowledge in a Neural Network}, 
      author={Geoffrey Hinton and Oriol Vinyals and Jeff Dean},
      year={2015},
      eprint={1503.02531},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
@misc{sanh2020distilbert,
      title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter}, 
      author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
      year={2020},
      eprint={1910.01108},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{chen2016training,
      title={Training Deep Nets with Sublinear Memory Cost}, 
      author={Tianqi Chen and Bing Xu and Chiyuan Zhang and Carlos Guestrin},
      year={2016},
      eprint={1604.06174},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{larsen2022degrees,
      title={How many degrees of freedom do we need to train deep networks: a loss landscape perspective}, 
      author={Brett W. Larsen and Stanislav Fort and Nic Becker and Surya Ganguli},
      year={2022},
      eprint={2107.05802},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{gurari2018gradient,
      title={Gradient Descent Happens in a Tiny Subspace}, 
      author={Guy Gur-Ari and Daniel A. Roberts and Ethan Dyer},
      year={2018},
      eprint={1812.04754},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@InProceedings{pmlr-v80-lee18a,
  title = 	 {Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace},
  author =       {Lee, Yoonho and Choi, Seungjin},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {2927--2936},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/lee18a/lee18a.pdf},
  url = 	 {https://proceedings.mlr.press/v80/lee18a.html}
}
@inproceedings{NEURIPS2020_70d85f35,
 author = {Chaudhry, Arslan and Khan, Naeemullah and Dokania, Puneet and Torr, Philip},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {9900--9911},
 publisher = {Curran Associates, Inc.},
 title = {Continual Learning in Low-rank Orthogonal Subspaces},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/70d85f35a1fdc0ab701ff78779306407-Paper.pdf},
 volume = {33},
 year = {2020}
}

@InProceedings{pmlr-v80-shazeer18a,
  title = 	 {Adafactor: Adaptive Learning Rates with Sublinear Memory Cost},
  author =       {Shazeer, Noam and Stern, Mitchell},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {4596--4604},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/shazeer18a/shazeer18a.pdf},
  url = 	 {https://proceedings.mlr.press/v80/shazeer18a.html}
}
@misc{dettmers20228bit,
      title={8-bit Optimizers via Block-wise Quantization}, 
      author={Tim Dettmers and Mike Lewis and Sam Shleifer and Luke Zettlemoyer},
      year={2022},
      eprint={2110.02861},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@inproceedings{NEURIPS2023_3122aaa2,
 author = {Li, Bingrui and Chen, Jianfei and Zhu, Jun},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {15136--15171},
 publisher = {Curran Associates, Inc.},
 title = {Memory Efficient Optimizers with 4-bit States},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/3122aaa22b2fe83f9cead1a696f65ceb-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}
@misc{lv2023parameter,
      title={Full Parameter Fine-tuning for Large Language Models with Limited Resources}, 
      author={Kai Lv and Yuqing Yang and Tengxiao Liu and Qinghui Gao and Qipeng Guo and Xipeng Qiu},
      year={2023},
      eprint={2306.09782},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{kitaev2020reformer,
  title={Reformer: The efficient transformer},
  author={Kitaev, Nikita and Kaiser, {\L}ukasz and Levskaya, Anselm},
  journal={arXiv preprint arXiv:2001.04451},
  year={2020}
}
@misc{wang2019glue,
      title={GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding}, 
      author={Alex Wang and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},
      year={2019},
      eprint={1804.07461},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{JMLR:v21:20-074,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {140},
  pages   = {1--67},
  url     = {http://jmlr.org/papers/v21/20-074.html}
}
@misc{lewis2019bart,
      title={BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension}, 
      author={Mike Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and Abdelrahman Mohamed and Omer Levy and Ves Stoyanov and Luke Zettlemoyer},
      year={2019},
      eprint={1910.13461},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}
@misc{kingma2017adam,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{knuth1976big,
  title={Big omicron and big omega and big theta},
  author={Knuth, Donald E},
  journal={ACM Sigact News},
  volume={8},
  number={2},
  pages={18--24},
  year={1976},
  publisher={ACM New York, NY, USA}
}
@inproceedings{srebro2005rank,
  title={Rank, trace-norm and max-norm},
  author={Srebro, Nathan and Shraibman, Adi},
  booktitle={International conference on computational learning theory},
  pages={545--560},
  year={2005},
  organization={Springer}
}
@article{tian2020understanding,
  title={Understanding self-supervised learning with dual deep networks},
  author={Tian, Yuandong and Yu, Lantao and Chen, Xinlei and Ganguli, Surya},
  journal={arXiv preprint arXiv:2010.00578},
  year={2020}
}
@article{bentivogli2009fifth,
  title={The Fifth PASCAL Recognizing Textual Entailment Challenge.},
  author={Bentivogli, Luisa and Clark, Peter and Dagan, Ido and Giampiccolo, Danilo},
  journal={TAC},
  volume={7},
  number={8},
  pages={1},
  year={2009},
  publisher={Citeseer}
}

@article{he2021towards,
  title={Towards a unified view of parameter-efficient transfer learning},
  author={He, Junxian and Zhou, Chunting and Ma, Xuezhe and Berg-Kirkpatrick, Taylor and Neubig, Graham},
  journal={arXiv preprint arXiv:2110.04366},
  year={2021}
}

@article{diao2022black,
  title={Black-box prompt learning for pre-trained language models},
  author={Diao, Shizhe and Huang, Zhichao and Xu, Ruijia and Li, Xuechun and Lin, Yong and Zhou, Xiao and Zhang, Tong},
  journal={arXiv preprint arXiv:2201.08531},
  year={2022}
}



@article{zhang2303adaptive,
  title={Adaptive budget allocation for parameter-efficient fine-tuning. Preprint (2023)},
  author={Zhang, Q and Chen, M and Bukharin, A and He, P and Cheng, Y and Chen, W and Zhao, T},
  journal={arXiv preprint arXiv:2303.10512},
  year={2023}
}

@article{kopiczko2023vera,
  title={Vera: Vector-based random matrix adaptation},
  author={Kopiczko, Dawid Jan and Blankevoort, Tijmen and Asano, Yuki Markus},
  journal={arXiv preprint arXiv:2310.11454},
  year={2023}
}

@article{gao2024parameter,
  title={Parameter-Efficient Fine-Tuning with Discrete Fourier Transform},
  author={Gao, Ziqi and Wang, Qichao and Chen, Aochuan and Liu, Zijing and Wu, Bingzhe and Chen, Liang and Li, Jia},
  journal={arXiv preprint arXiv:2405.03003},
  year={2024}
}

@inproceedings{xu2020learning,
  title={Learning in the frequency domain},
  author={Xu, Kai and Qin, Minghai and Sun, Fei and Wang, Yuhao and Chen, Yen-Kuang and Ren, Fengbo},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={1740--1749},
  year={2020}
}

@inproceedings{ehrlich2019deep,
  title={Deep residual learning in the jpeg transform domain},
  author={Ehrlich, Max and Davis, Larry S},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={3484--3493},
  year={2019}
}

@article{zhu2024novel,
  title={A novel asymmetrical autoencoder with a sparsifying discrete cosine stockwell transform layer for gearbox sensor data compression},
  author={Zhu, Xin and Yang, Daoguang and Pan, Hongyi and Karimi, Hamid Reza and Ozevin, Didem and Cetin, Ahmet Enis},
  journal={Engineering Applications of Artificial Intelligence},
  volume={127},
  pages={107322},
  year={2024},
  publisher={Elsevier}
}

@article{cheng2024new,
  title={A New Two-Sided Sketching Algorithm for Large-Scale Tensor Decomposition Based on Discrete Cosine Transformation},
  author={Cheng, Zhiguang and Yu, Gaohang and Cai, Xiaohao and Qi, Liqun},
  journal={arXiv preprint arXiv:2404.16580},
  year={2024}
}

@article{vavekanandllama,
  title={Llama 3.1: An In-Depth Analysis of the Next-Generation Large Language Model},
  year={2024},
  author={Vavekanand, Raja and Sam, Kira}
}


@article{dettmers2024qlora,
  title={Qlora: Efficient finetuning of quantized llms},
  author={Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{novikova2017e2e,
  title={The E2E dataset: New challenges for end-to-end generation},
  author={Novikova, Jekaterina and Du{\v{s}}ek, Ond{\v{r}}ej and Rieser, Verena},
  journal={arXiv preprint arXiv:1706.09254},
  year={2017}
}

@misc{taori2023stanford,
  title={Stanford alpaca: An instruction-following llama model},
  author={Taori, Rohan and Gulrajani, Ishaan and Zhang, Tianyi and Dubois, Yann and Li, Xuechen and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori B},
  year={2023}
}


@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  journal={Technical Report TR-2009},
  publisher={Toronto, ON, Canada}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{cheng2017remote,
  title={Remote sensing image scene classification: Benchmark and state of the art},
  author={Cheng, Gong and Han, Junwei and Lu, Xiaoqiang},
  journal={Proceedings of the IEEE},
  volume={105},
  number={10},
  pages={1865--1883},
  year={2017},
  publisher={IEEE}
}

@inproceedings{krause20133d,
  title={3d object representations for fine-grained categorization},
  author={Krause, Jonathan and Stark, Michael and Deng, Jia and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE international conference on computer vision workshops},
  pages={554--561},
  year={2013}
}

@inproceedings{parkhi2012cats,
  title={Cats and dogs},
  author={Parkhi, Omkar M and Vedaldi, Andrea and Zisserman, Andrew and Jawahar, CV},
  booktitle={2012 IEEE conference on computer vision and pattern recognition},
  pages={3498--3505},
  year={2012},
  organization={IEEE}
}

@inproceedings{cimpoi2014describing,
  title={Describing textures in the wild},
  author={Cimpoi, Mircea and Maji, Subhransu and Kokkinos, Iasonas and Mohamed, Sammy and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3606--3613},
  year={2014}
}

@article{helber2019eurosat,
  title={Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification},
  author={Helber, Patrick and Bischke, Benjamin and Dengel, Andreas and Borth, Damian},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  volume={12},
  number={7},
  pages={2217--2226},
  year={2019},
  publisher={IEEE}
}

@article{zheng2024judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{chiang2023vicuna,
  title={Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality},
  author={Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E and others},
  journal={See https://vicuna. lmsys. org (accessed 14 April 2023)},
  volume={2},
  number={3},
  pages={6},
  year={2023}
}


@article{aghajanyan2020intrinsic,
  title={Intrinsic dimensionality explains the effectiveness of language model fine-tuning},
  author={Aghajanyan, Armen and Zettlemoyer, Luke and Gupta, Sonal},
  journal={arXiv preprint arXiv:2012.13255},
  year={2020}
}

@article{sun2021long,
  title={Do long-range language models actually use long-range context?},
  author={Sun, Simeng and Krishna, Kalpesh and Mattarella-Micke, Andrew and Iyyer, Mohit},
  journal={EMNLP2021},
  year={2021}
}

@article{wen2022transformers,
  title={Transformers in time series: A survey},
  author={Wen, Qingsong and Zhou, Tian and Zhang, Chaoli and Chen, Weiqi and Ma, Ziqing and Yan, Junchi and Sun, Liang},
  journal={IJCAI 2023},
  year={2023}
}

@article{dong2023survey,
  title={A survey on long text modeling with transformers},
  author={Dong, Zican and Tang, Tianyi and Li, Lunyi and Zhao, Wayne Xin},
  journal={arXiv preprint arXiv:2302.14502},
  year={2023}
}

@article{pochimireddy2023fast,
  title={Fast DFT Computation for Signals with Structured Support},
  author={Pochimireddy, Charantej Reddy and Siripuram, Aditya and Osgood, Brad},
  journal={IEEE Transactions on Information Theory},
  year={2023},
  publisher={IEEE}
}

@article{nagai2020completing,
  title={Completing density functional theory by machine learning hidden messages from molecules},
  author={Nagai, Ryo and Akashi, Ryosuke and Sugino, Osamu},
  journal={npj Computational Materials},
  volume={6},
  number={1},
  pages={43},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{liu2024sora,
  title={Sora: A review on background, technology, limitations, and opportunities of large vision models},
  author={Liu, Yixin and Zhang, Kai and Li, Yuan and Yan, Zhiling and Gao, Chujie and Chen, Ruoxi and Yuan, Zhengqing and Huang, Yue and Sun, Hanchi and Gao, Jianfeng and others},
  journal={arXiv preprint arXiv:2402.17177},
  year={2024}
}

@article{islam2024gpt,
  title={GPT-4o: The Cutting-Edge Advancement in Multimodal LLM},
  author={Islam, Raisa and Moushi, Owana Marzia},
  journal={Authorea Preprints},
  year={2024},
  publisher={Authorea}
}

@article{he2020deberta,
  title={Deberta: Decoding-enhanced bert with disentangled attention},
  author={He, Pengcheng and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu},
  journal={arXiv preprint arXiv:2006.03654},
  year={2020}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

@inproceedings{liu2024improved,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26296--26306},
  year={2024}
}

@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={arXiv preprint arXiv:2206.07682},
  year={2022}
}

@book{press2007numerical,
  title={Numerical recipes 3rd edition: The art of scientific computing},
  author={Press, William H},
  year={2007},
  publisher={Cambridge university press}
}


@article{rani2024content,
  title={Content-based medical image retrieval using fractional Hartley transform with hybrid features},
  author={Rani, K Vijila and Prince, M Eugine and Therese, P Sujatha and Shermila, P Josephin and Devi, E Anna},
  journal={Multimedia Tools and Applications},
  volume={83},
  number={9},
  pages={27217--27242},
  year={2024},
  publisher={Springer}
}

@article{ma2021high,
  title={High-efficiency single-pixel imaging using discrete Hartley transform},
  author={Ma, Mengchao and Sun, Qianzhen and Gao, Xicheng and Wang, Guan and Deng, Huaxia and Zhang, Yi and Guan, Qingtian and Zhong, Xiang},
  journal={AIP Advances},
  volume={11},
  number={7},
  year={2021},
  publisher={AIP Publishing}
}

@article{coutinho2021low,
  title={Low-complexity three-dimensional discrete Hartley transform approximations for medical image compression},
  author={Coutinho, V{\'\i}tor A and Cintra, Renato J and Bayer, F{\'a}bio M},
  journal={Computers in Biology and Medicine},
  volume={139},
  pages={105018},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}



@article{lei2018tvqa,
  title={Tvqa: Localized, compositional video question answering},
  author={Lei, Jie and Yu, Licheng and Bansal, Mohit and Berg, Tamara L},
  journal={arXiv preprint arXiv:1809.01696},
  year={2018}
}

@article{li2020hero,
  title={Hero: Hierarchical encoder for video+ language omni-representation pre-training},
  author={Li, Linjie and Chen, Yen-Chun and Cheng, Yu and Gan, Zhe and Yu, Licheng and Liu, Jingjing},
  journal={arXiv preprint arXiv:2005.00200},
  year={2020}
}


@inproceedings{zhou2018towards,
  title={Towards automatic learning of procedures from web instructional videos},
  author={Zhou, Luowei and Xu, Chenliang and Corso, Jason},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2018}
}


@inproceedings{lei2020tvr,
  title={Tvr: A large-scale dataset for video-subtitle moment retrieval},
  author={Lei, Jie and Yu, Licheng and Berg, Tamara L and Bansal, Mohit},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXI 16},
  pages={447--463},
  year={2020},
  organization={Springer}
}
@inproceedings{sung2022vl,
  title={Vl-adapter: Parameter-efficient transfer learning for vision-and-language tasks},
  author={Sung, Yi-Lin and Cho, Jaemin and Bansal, Mohit},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5227--5237},
  year={2022}
}

@inproceedings{tang2022rethinking,
  title={Rethinking graph neural networks for anomaly detection},
  author={Tang, Jianheng and Li, Jiajin and Gao, Ziqi and Li, Jia},
  booktitle={International Conference on Machine Learning},
  pages={21076--21089},
  year={2022},
  organization={PMLR}
}

@article{yang2016exact,
  title={Exact joint sparse frequency recovery via optimization methods},
  author={Yang, Zai and Xie, Lihua},
  journal={IEEE Transactions on Signal Processing},
  volume={64},
  number={19},
  pages={5145--5157},
  year={2016},
  publisher={IEEE}
}


@article{azizi2024lamda,
  title={LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation},
  author={Azizi, Seyedarmin and Kundu, Souvik and Pedram, Massoud},
  journal={arXiv preprint arXiv:2406.12832},
  year={2024}
}

@article{liu2024aflora,
  title={AFLoRA: Adaptive Freezing of Low Rank Adaptation in Parameter Efficient Fine-Tuning of Large Models},
  author={Liu, Zeyu and Kundu, Souvik and Li, Anni and Wan, Junrui and Jiang, Lianghao and Beerel, Peter Anthony},
  journal={arXiv preprint arXiv:2403.13269},
  year={2024}
}

@article{narayan2018don,
  title={Don't give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization},
  author={Narayan, Shashi and Cohen, Shay B and Lapata, Mirella},
  journal={arXiv preprint arXiv:1808.08745},
  year={2018}
}

@article{hermann2015teaching,
  title={Teaching machines to read and comprehend},
  author={Hermann, Karl Moritz and Kocisky, Tomas and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{huang2024novel,
  title={A novel evaluation framework for image2text generation},
  author={Huang, Jia-Hong and Zhu, Hongyi and Shen, Yixian and Rudinac, Stevan and Pacces, Alessio M and Kanoulas, Evangelos},
  journal={arXiv preprint arXiv:2408.01723},
  year={2024}
}

@article{shen2023thermal,
  title={Thermal management for 3d-stacked systems via unified core-memory power regulation},
  author={Shen, Yixian and Schreuders, Leo and Pathania, Anuj and Pimentel, Andy D},
  journal={ACM Transactions on Embedded Computing Systems},
  volume={22},
  number={5s},
  pages={1--26},
  year={2023},
  publisher={ACM New York, NY}
}

@inproceedings{shen2022tcps,
  title={TCPS: a task and cache-aware partitioned scheduler for hard real-time multi-core systems},
  author={Shen, Yixian and Xiao, Jun and Pimentel, Andy D},
  booktitle={Proceedings of the 23rd ACM SIGPLAN/SIGBED International Conference on Languages, Compilers, and Tools for Embedded Systems},
  pages={37--49},
  year={2022}
}

@inproceedings{niknam20233d,
  title={3d-ttp: Efficient transient temperature-aware power budgeting for 3d-stacked processor-memory systems},
  author={Niknam, Sobhan and Shen, Yixian and Pathania, Anuj and Pimentel, Andy D},
  booktitle={2023 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)},
  pages={1--6},
  year={2023},
  organization={IEEE}
}

@inproceedings{shen2023thermal1,
  title={Thermal management for s-nuca many-cores via synchronous thread rotations},
  author={Shen, Yixian and Niknam, Sobhan and Pathania, Anuj and Pimentel, Andy D},
  booktitle={2023 Design, Automation \& Test in Europe Conference \& Exhibition (DATE)},
  pages={1--6},
  year={2023},
  organization={IEEE}
}

@article{guo2024easter,
  title={Easter: Learning to split transformers at the edge robustly},
  author={Guo, Xiaotian and Jiang, Quan and Shen, Yixian and Pimentel, Andy D and Stefanov, Todor},
  journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  volume={43},
  number={11},
  pages={3626--3637},
  year={2024},
  publisher={IEEE}
}

@inproceedings{aghapour2024piqi,
  title={Piqi: Partially quantized dnn inference on hmpsocs},
  author={Aghapour, Ehsan and Shen, Yixian and Sapra, Dolly and Pimentel, Andy and Pathania, Anuj},
  booktitle={Proceedings of the 29th ACM/IEEE International Symposium on Low Power Electronics and Design},
  pages={1--6},
  year={2024}
}


@inproceedings{huang2025image2text2image,
  title={Image2text2image: A novel framework for label-free evaluation of image-to-text generation with text-to-image diffusion models},
  author={Huang, Jia-Hong and Zhu, Hongyi and Shen, Yixian and Rudinac, Stevan and Kanoulas, Evangelos},
  booktitle={International Conference on Multimedia Modeling},
  pages={413--427},
  year={2025},
  organization={Springer}
}

@article{shen2024parameter,
  title={Parameter-efficient fine-tuning via selective discrete cosine transform},
  author={Shen, Yixian and Bi, Qi and Huang, Jia-Hong and Zhu, Hongyi and Pathania, Anuj},
  journal={arXiv preprint arXiv:2410.09103},
  year={2024}
}

@article{shen2024altgen,
  title={AltGen: AI-Driven Alt Text Generation for Enhancing EPUB Accessibility},
  author={Shen, Yixian and Zhang, Hang and Shen, Yanxin and Wang, Lun and Shi, Chuanqi and Du, Shaoshuai and Tao, Yiyi},
  journal={arXiv preprint arXiv:2501.00113},
  year={2024}
}

@article{shen2024comparative,
  title={Comparative Analysis of Listwise Reranking with Large Language Models in Limited-Resource Language Contexts},
  author={Shen, Yanxin and Wang, Lun and Shi, Chuanqi and Du, Shaoshuai and Tao, Yiyi and Shen, Yixian and Zhang, Hang},
  journal={arXiv preprint arXiv:2412.20061},
  year={2024}
}

@article{huang2024gradient,
  title={Gradient Weight-normalized Low-rank Projection for Efficient LLM Training},
  author={Huang, Jia-Hong and Shen, Yixian and Zhu, Hongyi and Rudinac, Stevan and Kanoulas, Evangelos},
  journal={arXiv preprint arXiv:2412.19616},
  year={2024}
}

@article{tao2024robustness,
  title={Robustness of Large Language Models Against Adversarial Attacks},
  author={Tao, Yiyi and Shen, Yixian and Zhang, Hang and Shen, Yanxin and Wang, Lun and Shi, Chuanqi and Du, Shaoshuai},
  journal={arXiv preprint arXiv:2412.17011},
  year={2024}
}
