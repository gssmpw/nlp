\documentclass[runningheads]{llncs}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{threeparttable}
\usepackage{siunitx}
\usepackage{bbding}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{appendix}
\usepackage[section]{placeins}


\begin{document}
\title{Online Controller Synthesis for Robot Collision Avoidance: A Case Study}
\author{Yuheng Fan\inst{1} \and Wang Lin\inst{1 (}\Envelope\inst{)}}

\authorrunning{Y. Fan et al.}
\titlerunning{SADEEPDECS}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\renewcommand{\inst}[1]{%
  \ifhmode\unskip\fi % 仅在水平模式下使用 \unskip
  \textsuperscript{#1}%
}
\institute{
\inst{1}School of Information Science and Technology, Zhejiang Sci-Tech University, Hangzhou, China \\
\email{linwang@zstu.edu.cn}
}

\maketitle

\begin{abstract}
The inherent uncertainty of dynamic environments poses significant challenges for modeling robot behavior, particularly in tasks such as collision avoidance. This paper presents an online controller synthesis framework tailored for robots equipped with deep learning-based perception components, with a focus on addressing distribution shifts. Our approach integrates periodic monitoring and repair mechanisms for the deep neural network perception component, followed by uncertainty reassessment. These uncertainty evaluations are injected into a parametric discrete-time markov chain, enabling the synthesis of robust controllers via probabilistic model checking. To ensure high system availability during the repair process, we propose a dual-component configuration that seamlessly transitions between operational states. Through a case study on robot collision avoidance, we demonstrate the efficacy of our method, showcasing substantial performance improvements over baseline approaches. This work provides a comprehensive and scalable solution for enhancing the safety and reliability of autonomous systems operating in uncertain environments.
\end{abstract}

\section{Introduction}
In an increasing number of application fields, autonomous systems employ neural networks\cite{DNN1} as components to perceive changes in the environment, with applications ranging from autonomous vehicles\cite{acex1,acex2,acex3} and healthcare\cite{hcex1,hcex2,hcex3} to finance\cite{fcex,fcex2}. In autonomous driving, neural networks are utilized for tasks such as traffic sign detection, object perception, and classification. In finance, they perceive data fluctuations and assess risks. In healthcare, they are employed for perceiving vein locations, recognizing suturing actions, and tracking medical instruments. These applications often involve safety-critical domains, where ensuring system security is both crucial and challenging.

Existing approach, such as \textbf{DeepDECS}\cite{deepdecs,closedloopanalysis}, integrates uninterpretable DNNs with classical modeling techniques enabling the formal analysis of DNN-perceptive autonomous systems. This method utilizes probabilistic model checking to synthesize the controller that satisfies system specifications. However, a limitation of this method: it is based on the assumption that the training data for the DNN perception component is representative of actual operating conditions. In real-world environments, the distribution of input may change over time, leading to degraded prediction performance of the neural network and, consequently, distortion of the system model.

To address this limitation, this paper presents an online controller synthesis approach, \textbf{SADEEPDECS}(\textbf{S}elf-\textbf{A}daptive \textbf{DeepDECS}), designed to enhance the adaptability and robustness of DNN-perceptive autonomous systems in dynamic environments. Our method ensures that the system's runtime average performance adheres to quantized specifications as much as possible by periodically monitoring the DNN's performance using sliding window mechanism and continuously updating the neural network to enhance its robustness. To enhance system adaptability, we leverage uncertainty quantification results from the updated neural network to synthesize new controller. Additionally, we introduce a dual-component configuration that allows simultaneous prediction and repair. This configuration guarantees high availability of the autonomous system.

The main contributions of this paper are as follows:
\begin{itemize}
    \item Propose a repair process that improves robustness and adaptability.
    \item Introduce a dual-component configuration that ensures high availability.
    \item Demonstrate the efficacy of our approach through robot collision avoidance.
\end{itemize}
\subsubsection{Related Work}
The uncertainty quantification evaluates the neural component using the confusion matrix\cite{deepdecs}. For controller synthesis, PRISM\cite{prism} is used to perform property quantification on the instantiated DTMC\cite{DTMC}. The simulation physics engine used is Box2D\cite{box2d}. Runtime verification involves monitoring system executions to ensure adherence to desired properties. Kejstová et al.\cite{kejstova2018model} discuss the adaptation of existing software model checkers for precise runtime verification, enabling the reuse of model checking tools in new contexts. Additionally, Carzaniga et al. integrated redundancy mechanisms with testing and analysis techniques to either rollback\cite{rollback} executions or compensate\cite{compensate} for the effects of failures, thereby enhancing system reliability. Distribution shifts\cite{conceptdrift} pose significant challenges to the performance of DNNs. Bar-Shalom et al.\cite{barshalom2022window} propose a window-based method for detecting distribution shifts in DNNs, enabling timely interventions to maintain model accuracy. Barrabés et al.\cite{barrabes2023adversarial} introduce an adversarial learning framework to detect and correct feature shifts, enhancing the resilience of DNNs to distributional changes. 

\section{Problem Statement}
Robot collision avoidance is a critical capability that enables robots to navigate safely through dynamic environments. As shown in Figure \ref{fig:rbtca}, the blue represents the moving robot, and the red represents the colliding robot. The blue robot moves along the planned path on a grid map with random obstacles with a constant speed, while the red robot appears randomly in its surroundings. A assumption is that at most one red robot can appear near the blue robot during its movement. The perception component takes the position of the colliding robot ($x_1$, $x_2$), angle ($x_3$), velocity ($x_4$), and angular velocity ($x_5$) as inputs, and returns whether a collision will occur during the current movement. The collision avoidance controller is designed to determine whether the robot should continue moving based on the perception result. As shown in Figure~\ref{fig:caarch}, the robot continuously perceives environmental information through sensors such as radars, cameras, or LiDAR. The robot's DNN perception component predicts based on sensor data, and the collision avoidance controller generates control signals. These signals are passed to lower-level controllers (e.g., motor, brake, or steering controllers) to regulate the robot's actions.
\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[height=0.1\textheight]{pic/rbtca.eps}
        \caption{Robot Collision Scenario}
        \label{fig:rbtca}
    \end{subfigure}
    \hspace{5pt}
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[height=0.1\textheight, width=\textwidth]{pic/caarch.eps}
        \caption{System Architecture}
        \label{fig:caarch}
    \end{subfigure}
    \caption{Robot Collision Avoidance}
\end{figure}
To formally analyze the robot's collision avoidance behavior, we model the system as a parametric discrete-time markov chain (pDTMC), as depicted in Figure~\ref{dtmcmodel}. The robot moves step-by-step along a planned path, and the model focuses on its behavior during a single step. The robot first checks whether a colliding robot appears in its vicinity. If a colliding robot is detected, the perception component predicts whether a collision will occur. Based on the prediction, the controller issues a control signal, either to wait and recheck or to proceed with the movement. The parameters \( p_{\text{collider}} \) and \( p_{\text{occ}} \) represent the probability of a colliding robot appearing and the probability of a collision occurring, respectively. These are set to \( p_{\text{collider}} = 80\% \) and \( p_{\text{occ}} = 25\% \). The probabilities $p_{00}$, $p_{01}$, $p_{10}$, and \( p_{11} \) represent the DNN's prediction accuracy: no collision predicted as no collision, no collision predicted as collision, collision predicted as no collision, and collision predicted as collision, respectively. These probabilities abstract the DNN into a probabilistic component. The controller parameters \( c_1 \) and \( c_2 \) represent the probabilities of moving when the DNN predicts no collision and collision, respectively.
\begin{figure}[htbp]
    \centering
    \includegraphics[height=0.2\textheight]{pic/pDTMC.eps}
    \caption{pDTMC for One-Step Movement}
    \label{dtmcmodel}
\end{figure}
To formalize system requirements, we use probabilistic computation tree logic(PCTL) \cite{PCTL1}. We focus on two key properties: safety and time efficiency. These properties are encoded in PCTL as follows:
\begin{equation}
    \label{specification}
\begin{array}{l}
\mathcal{P}[\lnot \text{collision U done}] \geq 90\% \\
\mathcal{R}^{\text{time}}[\text{F done}] \leq 15 
\end{array}
\end{equation}
Since multiple sets of controller parameters may satisfy these conditions, we select the parameters that maximize the safety probability while satisfying the time efficiency constraint. The optimization objective is:
\begin{equation}
\label{opt}
\begin{array}{l}
\text{maximize} \, \mathcal{P}[\lnot \text{collision U done}] \text{ subject to } \mathcal{R}^{\text{time}}[ \text{F done}] \leq 15.
\end{array}
\end{equation}
The DNN perception component is a binary classifier predicting whether a collision will occur (0: no collision, 1: collision). The initial DNN perception component is trained using datasets \(\mathcal{X}_{\text{train}}\), \(\mathcal{X}_{\text{test}}\), and \(\mathcal{X}_{\text{val}}\). However, these datasets may not be representative of the operational environment. The component is evaluated on \(\mathcal{X}_{\text{confusion}}\), producing a confusion matrix \(\mathcal{C}\), where \(\mathcal{C}_{ij}\) represents the number of instances of class \(i\) predicted as class \(j\). The confusion matrix is:
\[ 
\mathcal{C} = \begin{bmatrix} 2000 & 290 \\ 10 & 200 \end{bmatrix}.
\]
The probabilities \( p_{00}, p_{01}, p_{10}, \) and \( p_{11} \) are calculated as:
\[
p_{ik} = \frac{\mathcal{C}_{ik}}{\sum_{j=0}^{1} \mathcal{C}_{ij}},
\]
yielding:
\[
p_{00} = 87.34\%, \quad p_{01} = 12.66\%, \quad p_{10} = 4.76\%, \quad p_{11} = 95.24\%.
\]
These probabilities and candidate controller parameters are injected into pDTMC to get a DTMC. We utilize PRISM to quantilize some controller parameters and filter the optimal controller parameters \( x_1 = 0.0 \) and \( x_2 = 1.0 \), which satisfy the time constraint while maximizing safety probability:
\begin{equation}
\begin{array}{l}
\mathcal{P}[\lnot \text{collision U done}] = 93.51\% \\
\mathcal{R}^{\text{time}}[\text{F done}] = 11.86.
\end{array}
\end{equation}

After operating for time \( T_0 \), \(\mathcal{X}_{\text{window}}\) was collected by a sliding window. We use \(\mathcal{X}_{\text{window}}\) to evaluate the perception compoennt and result in a new confusion matrix \(\mathcal{C}^{\prime}\):
\[ 
\mathcal{C}^{\prime} = \begin{bmatrix} 1000 & 200 \\ 1200 & 100 \end{bmatrix}.
\]
The new probabilities are:
\[
    %83.33%， 16.67%  92.31% 7.69%
p^{\prime}_{00} = 83.33\%, \quad p^{\prime}_{01} = 16.67\%, \quad p^{\prime}_{10} = 92.31\%, \quad p^{\prime}_{11} = 7.69\%.
\]
Injecting these probabilities and the previously synthesized controller parameters into the pDTMC yields:
\begin{equation}
\begin{array}{l}
\mathcal{P}[\lnot \text{collision U done}] = 78.78\% \\
\mathcal{R}^{\text{time}}[\text{F done}] = 11.28.
\end{array}
\end{equation}
We observe about 15\% decrease in safety probability due to distribution shift, indicating that such shifts can distort the model, consequently, the formal analysis at the beginning is not valid any more .

% Our research goal is to design a runtime monitoring and correction method to address the challenges posed by distribution shifts on the robustness of the DNN perception component and the adaptability of the controller, ensuring that the system maintains safety and time efficiency in dynamic environments. Specifically, we aim to promptly detect and correct the decline in DNN prediction accuracy, and adjust the controller parameters based on the updated DNN uncertainty quantification results. This will ensure that the system responds to environmental changes in a stable and efficient manner, while ensuring that the correction and prediction processes do not disrupt the system's stable operation.

% Consider an implementation which enables autonomous updates of DNN perception components to address environmental dynamics, adjusting controller parameters to maintain compliance with system specifications. The implementation comprises: 1) A robotic collision-avoidance simulator integrating map obstacles, dynamic agents, and safety controllers; 2) A neural-network perception service; 3) A runtime adaptation module with repair capabilities; 4) Formal verification service through pDTMC models analyzed via PRISM. Component coordination is achieved through cache-mediated communication, enabling efficient cross-component data exchange. This hybrid architecture integrates numerical simulation, machine learning adaptation, and probabilistic model checking to preserve safety guarantees under environmental uncertainties.

% We plan to detect distribution shift by continuously monitoring the performance of the DNN and the system (e.g., time efficiency and safety rate). For instance, if the accuracy drops below 90\%, or if the time efficiency and safety rate violate the specification (\ref{specification}), we consider it as detecting a distribution shift. To mitigate the impact of distribution shift, we retrain the DNN using the original data along with newly collected counterexamples, with the goal of enabling the DNN to learn new environmental knowledge. Since the performance of the DNN changes, the previous uncertainty quantification needs to be redone, and the originally instantiated DTMC is no longer applicable. Therefore, we need to inject the new uncertainty quantification results of the DNN into the pDTMC. After injecting the results into the pDTMC, we re-synthesize the controller parameters to select those that meet the optimization objective (\ref{opt}), ensuring they comply with the specification (\ref{specification}) as much as possible. Since the DNN perception component cannot make predictions while updating parameters, we introduce redundancy to implement the repair process as a parallel operation.

We plan to detect distribution shifts by continuously monitoring system performance. For example, if the accuracy drops below 90\%, or if the time efficiency and safety rate violate the specification (\ref{specification}), we consider it a distribution shift. To mitigate its impact, we retrain the DNN to enable it to learn new environmental knowledge. As the DNN's performance changes, the previous uncertainty quantification must be redone, and the originally instantiated DTMC becomes invalid. Therefore, we inject the new uncertainty quantification results into the pDTMC and re-synthesize the controller parameters to meet the optimization objective (\ref{opt}), ensuring compliance with the specification (\ref{specification}). Since the DNN perception component cannot predict during parameter updates, we introduce redundancy to execute the repair process in parallel.
\section{SADEEPDECS}
The SADEEPDECS framework consists of two core modules:
\begin{itemize}
    \item \textbf{Repair Process}: This module is designed to detect distribution shifts, retrain the neural network to adapt to environmental changes, and synthesize corresponding control parameters to ensure that the system behavior complies with the given specifications.
    \item \textbf{Dual-Component Configuration}: By introducing a redundant component, this module enables the repair process and the prediction process to operate in parallel. This design avoids operational interruptions caused by parameter updates in the DNN perception component, thereby ensuring high system availability.
\end{itemize}
\begin{figure}
\centering
\includegraphics[height=0.25\textheight]{pic/arch.eps}
\caption{The system interacts with the environment, and a monitor oversees its behavior. A cache is used for data exchange between the system and the monitor. Two components with identical functional modules play different roles, where blue indicates active status and yellow indicates inactive status.} \label{fig:arch}
\end{figure}
\subsection{Repair process}
This process is designed to update the DNN, improving the robustness of the perception component. Additionally, it updates the controller parameters, enabling system adaptation and enhancing the safety of the system's behavior. In the figure \ref{fig:arch}, the monitor tracks the system's input and output, detects prediction errors by analyzing observations, and records counterexamples. It uses sliding windows to monitor system behavior, assess performance to identify distribution shifts, and issues repair signals when necessary. The core objective of this process is to construct a sequence \( \langle \mathbf{q}_0, \mathbf{q}_1, \ldots, \mathbf{q}_n, \ldots \rangle \), where \( \mathbf{q}_i = (\boldsymbol{\phi}_i, \boldsymbol{\kappa}_i) \), \( i \in \mathbb{N} \). Here, \( \boldsymbol{\phi}_i \) and \( \boldsymbol{\kappa}_i \) denote the DNN parameters and controller parameters at \( t = i T_{\text{monitor}} \), with \( T_{\text{monitor}} > 0 \) being the monitoring shift period.

\subsubsection{Initial Neural Network Training and Synthesis}
Set \( \mathbf{q}_0 = (\boldsymbol{\phi}_0, \boldsymbol{\kappa}_0) \). Train and evaluate \( \boldsymbol{\phi}_0 \) using pre-collected datasets \( \mathcal{X}_{\text{train}}, \mathcal{X}_{\text{val}}, \mathcal{X}_{\text{test}} \). Assume the neural network \( \hat{y} = h_{\boldsymbol{\phi}}(\mathbf{x}) \), \( \hat{y} \in \mathbb{R}^k \). The overall loss of \( \boldsymbol{\phi} \) on dataset \( \mathcal{X} \) is \( L_{\boldsymbol{\phi}}(\mathcal{X}) \). Update \( \boldsymbol{\phi} \) via stochastic gradient descent \cite{DNN1}. At each training epoch, evaluate \( \boldsymbol{\phi} \) on \( \mathcal{X}_{\text{val}} \) by computing \( L_{\boldsymbol{\phi}}(\mathcal{X}_{\text{val}}) \). Select the best \( \boldsymbol{\phi}^* \) based on the lowest validation loss: 
\[ \boldsymbol{\phi}^* = \arg\min_{\boldsymbol{\phi}_t} L_{\boldsymbol{\phi}_t}(\mathcal{X}_{\text{val}}) \]

Next, conduct uncertainty evaluation of the neural network. Let \( \mathcal{U} \) represent the uncertainty quantification process, with \( \mathcal{X}_{\text{confusion}} \) as the dataset for it. The output \( \mathbf{u} \) represents the quantification results:
\[ \mathbf{u}_0 = \mathcal{U}(\boldsymbol{\phi}_0, \mathcal{X}_{\text{confusion}}) \]
\( \mathbf{u}_0 \) captures the DNN's prediction uncertainty based on \( \mathcal{X}_{\text{confusion}} \), and \( \mathcal{U} \) can be implemented variably depending on the selected uncertainty quantification method.

After uncertainty quantification, start the controller synthesis. \( \mathcal{M}(\mathbf{u}, \boldsymbol{\kappa}) \) is a pDTMC describing the system behavior, where \( \mathbf{u} \in \mathbb{R}^d \) is from \( \mathcal{U} \) and \( \boldsymbol{\kappa} \in \mathbb{R}^n \) is the candidate controller parameters. Instantiate \( \mathbf{u}_0 \) into \( \mathcal{M}(\mathbf{u}, \boldsymbol{\kappa}) \) as:
\[ \mathcal{M}_{\mathbf{u}_0} = \mathcal{M}(\mathbf{u}_0, \boldsymbol{\kappa}) \]
Here, \( \mathcal{M}_{\mathbf{u}_0} \) is the partially instantiated pDTMC with \( \mathbf{u}_0 \) fixed and \( \boldsymbol{\kappa} \) free.

Suppose injecting \( \mathbf{candidate} \) into \( \mathcal{M}_{\mathbf{u}_0} \) gives \( \mathcal{M}_{\mathbf{u}_0, \mathbf{candidate}} \). Let the controller parameter space be \( \mathcal{K} \subseteq \mathbb{R}^n \), each dimension \( i \) bounded by \( [a_i, b_i] \), and the discretization step \( \delta_i = \frac{b_i - a_i}{m_i - 1} \), where \( m_i \) is the number of discretized points. Then the discretized controller parameter set \( \mathcal{CTLP} \) is:
\[ \mathcal{CTLP} = \prod_{i = 1}^{n} \left\{ a_i + k_i \delta_i \mid k_i \in \mathbb{N}, a_i + k_i \delta_i \leq b_i \right\} \]

Let \( \mathcal{QR}_{0, \varphi} \) be the quantization results set of state specification \( \varphi \in \mathcal{S} \), and \( \mathcal{QR}_{0, \varphi^{\text{rwd}}} \) for reward specification \( \varphi^{\text{rwd}} \in \mathcal{S}^{\text{rwd}} \). Each element is obtained by injecting a candidate from \( \mathcal{CTLP} \) into \( \mathcal{M}_{\mathbf{u}_0} \), getting the DTMC, and evaluating with PRISM.

\( \mathcal{QR}_{0, \varphi} \) is the probability vector of \( \varphi \) for all candidates in \( \mathcal{CTLP} \):
\[ \mathcal{QR}_{0, \varphi, i} = pmc(\varphi, \mathcal{M}_{\mathbf{u}_0, \mathbf{candidate}_i}) \]
Similarly, \( \mathcal{QR}_{0, \varphi^{\text{rwd}}} \) is the expected reward vector:
\[ \mathcal{QR}_{0, \varphi^{\text{rwd}}, i} = pmc(\varphi^{\text{rwd}}, \mathcal{M}_{\mathbf{u}_0, \mathbf{candidate}_i}) \]

Define \( \mathcal{QR}_{0} \) as the concatenation of relevant sets. Select control parameters:
\[ \boldsymbol{\kappa}_0 = filter(\mathcal{CTLP}, \mathcal{QR}_{0}) \]
Thus, \( \mathbf{q}_0 \) is constructed. For \( \mathbf{q}_{i + 1} \) at \( t = (i + 1)T_{\text{monitor}} \):

\subsubsection{New Neural Network and Controller Parameters}
% \paragraph{Detect Shift and Update DNN. }
Set thresholds \( threshold_1 \) and \( threshold_2 \) for distribution shift detection and evaluating new DNN adequacy. Compute the accuracy of \( \boldsymbol{\phi}_i \) on \( \mathcal{X}_{\text{window}} \):
\begin{equation}
    \label{eq:accuracy}
    Accuracy(\boldsymbol{\phi}_i, \mathcal{X}_{\text{window}}) = \frac{\sum_{\mathbf{x} \in \mathcal{X}_{\text{window}}} \mathcal{I}(h_{\boldsymbol{\phi}_i}(\mathbf{x}), y)}{\# \mathcal{X}_{\text{window}}}
\end{equation}
where
\[ \mathcal{I}(a, b) = \begin{cases}
1, & \text{if } a = b \\
0, & \text{otherwise}
\end{cases} \]

If \( Accuracy(\boldsymbol{\phi}_i, \mathcal{X}_{\text{window}}) \geq threshold_1 \), then \( \mathbf{q}_{i + 1} = \mathbf{q}_i \). Otherwise, detect a distribution shift and start DNN repair. Also update if system behavior violates specs (e.g., safety rate < 90\% or expected time > 15).

Use counterexample dataset \( \mathcal{CE} \) from \( [iT_{\text{monitor}}, (i + 1)T_{\text{monitor}}) \), split it:
\[ \mathcal{CE} = \{\mathcal{CE}_{\text{train}}, \mathcal{CE}_{\text{val}}, \mathcal{CE}_{\text{confusion}}, \mathcal{CE}_{\text{test}}\} \]
Update datasets:
\begin{equation}
\begin{array}{llllll}
\mathcal{X}_{\text{train}} &\leftarrow \mathcal{X}_{\text{train}} &\cup \quad\mathcal{CE}_{\text{train}} & \quad
\mathcal{X}_{\text{val}} &\leftarrow \mathcal{X}_{\text{val}} &\cup \quad\mathcal{CE}_{\text{val}} \\
\mathcal{X}_{\text{confusion}} &\leftarrow \mathcal{X}_{\text{confusion}} &\cup \quad\mathcal{CE}_{\text{confusion}}& \quad
\mathcal{X}_{\text{test}} &\leftarrow \mathcal{X}_{\text{test}} &\cup \quad\mathcal{CE}_{\text{test}}
\end{array}
\end{equation}
Sample to construct:
\begin{equation}
\begin{array}{llllll}
\mathcal{X}^{\prime}_{\text{train}} &= sample(\mathcal{X}_{\text{train}}&, D_{\text{train}}) & \quad \mathcal{X}^{\prime}_{\text{val}} &= sample(\mathcal{X}_{\text{val}}&, D_{\text{val}}) \\
\mathcal{X}^{\prime}_{\text{confusion}} &= sample(\mathcal{X}_{\text{confusion}}&, D_{\text{confusion}}) &\quad \mathcal{X}^{\prime}_{\text{test}} &= sample(\mathcal{X}_{\text{test}}&, D_{\text{test}})
\end{array}
\end{equation}
Train a new DNN \( h_{\boldsymbol{\phi}_{i + 1}}(\mathbf{x}) \). If \( Accuracy(\boldsymbol{\phi}_{i + 1}, \mathcal{X}^{\prime}_{\text{test}}) < threshold_2 \), set \( \mathbf{q}_{i + 1} = \mathbf{q}_i \). Otherwise, proceed with uncertainty quantification and synthesis.

% \paragraph{Uncertainty Quantification and Synthesis. }
Perform \( \mathcal{U}(\boldsymbol{\phi}_{i + 1}, \mathcal{X}^{\prime}_{\text{confusion}}) \) to get \( \mathbf{u}_{i + 1} \). Use it and \( \mathbf{candidate} \) from \( \mathcal{CTLP} \) to derive \( \mathcal{M}_{\mathbf{u}_{i + 1}, \mathbf{candidate}} \), and obtain \( \mathcal{QR}_{i + 1} \) via PRISM. Select next controller parameters: 
\[ \boldsymbol{\kappa}_{i + 1} = filter(\mathcal{CTLP}, \mathcal{QR}_{i + 1}) \]
% Now, \( \mathbf{q}_{i + 1} \) is successfully constructed.

% \subsection{Dual-component configuration}
% This configuration is designed to enable the system to operate in parallel between the prediction and repair processes without interruption, ensuring high availability of the system. Figure \ref{fig:arch} presents the overall architecture of the system. We introduce redundancy, i.e., two functionally identical yet role-distinct components. The running component is used for prediction, while the repair component handles repair and synthesis. Bright yellow indicates an inactive functional module, and blue means it is active. Once the repair component has completed the repair process, update the controller parameters and switch the roles of these two components.
\subsection{Dual-Component Configuration}
\label{sec:dual_config}

The proposed architecture enables parallel operation between prediction and repair processes without system interruption, ensuring high availability. As shown in Figure~\ref{fig:arch}, bright yellow indicates an inactive functional module, and blue means it is active. We introduce redundancy which make the system employs two functionally identical yet role-specific components:

\begin{itemize}[leftmargin=*,noitemsep]
    \item \textbf{Prediction Component}:
    \begin{itemize}[leftmargin=2em]
        \item Processes sensor data streams through the \textit{Prediction Module}
        \item Generates collision/non-collision perception result using DNN inference
        \item Maintains inactive \textit{Repair Module}
    \end{itemize}
    
    \item \textbf{Repair Component}:
    \begin{itemize}[leftmargin=2em]
        \item Executes three-phase repair pipeline in the \textit{Repair Module}:
        \begin{enumerate}[label=(\roman*)]
            \item DNN update
            \item Uncertainty quantification
            \item Controller parameter discretization and synthesis using PRISM
        \end{enumerate}
        \item Maintains inactive \textit{Prediction Module}
    \end{itemize}
\end{itemize}

\noindent The repair component is activated when the monitor issues repair signals detected in the cache. Component role switching occurs after the repair component completes its process and controller parameters are updated. This reconfiguration swaps the activation states of functional modules, thereby exchanging the operational responsibilities between the two components. 

\section{Experimental Evaluation}
In this section, we present the experimental evaluation of \textbf{SADEEPDECS} for robot collision avoidance under distribution shift.

\subsection{Experiment Setup}
We construct two types of environmental inputs (information of the colliding robot) and training dataset to evaluate different methods. The input space is defined as:
\[
x_1 \in [-10, 10], \quad x_2 \in [0, 10], \quad x_3 \in [0, 2\pi], \quad x_4 \in [0, 2], \quad x_5 \in \left[-\frac{\pi}{2}, \frac{\pi}{2}\right].
\]
The training dataset is constructed as a non-representative dataset \(\mathcal{D}_0\) by uniformly sampling points from a neighborhood \(\epsilon_0\) (a small value, for example, 0.1) around a point \(c_0\) in the input space. Environmental inputs are generated in two ways:
\begin{itemize}
    \item \textbf{Uniform Sampling}: Points are uniformly sampled from the input space.
    \item \textbf{Random Walk}: Starting from a training data sample point \(c_0\), a random walk is performed in the input space to reach a point \(c_1\), and points are sampled from the neighborhood \(\epsilon_1\) of \(c_1\). This process is repeated to construct the environmental inputs.
\end{itemize}
% We refer to experiments using these two types of input data as \textit{uniform sampling} and \textit{random walk}, respectively.

Using the pre-collected dataset \(\mathcal{D}_0\), we train an initial deep neural network \(h_{\boldsymbol{\phi}}(\mathbf{x})\) and synthesize the controller parameters \(\boldsymbol{\kappa}\). And we set $p_{collider}=80\%$, $p_{occ}=25\%$. We evaluate three methods:
\begin{itemize}
    \item \textbf{NO}: the system is exposed to distribution shift without repair process.
    \item \textbf{RANDOM}: everything is same as \textbf{NO} method, but the perception component is random guessing.
    \item \textbf{SADEEPDECS}:  \textbf{NO} method with repair process and dual-component configuration.
\end{itemize}
At the beginning, all different methods employ the same neural network and controller parameters($\boldsymbol{\phi}$, \(\boldsymbol{\kappa}\)). For the \textbf{SADEEPDECS} method, we set \(T_{\text{monitor}} = 1250\), \(D_{\text{window}} = \#\mathcal{X}_{\text{window}} = 1000\), \(threshold_1 = 90\%\), and \(threshold_2 = 80\%\). The starting and ending points are randomly selected. Pre-constructed benchmarks are used for simulation, recording approximately 150,000 steps of movement. The map, obstacles, and robot movement simulation are built using Box2D. The grid size on the map is 10 units, and the mobile robot moves with a uniform speed of 1 unit per second. The evaluation of controller parameters is conducted through PRISM.
\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{pic/accuracy.eps}
        \caption{}
    \end{subfigure}
    \hspace{-15pt}
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{pic/safety.eps}
        \caption{}
    \end{subfigure}
    \hspace{-15pt}
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{pic/time.eps}
        \caption{}
    \end{subfigure}
    \vspace{-10pt}
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{pic/accuracy-rw.eps}
        \caption{}
    \end{subfigure}
    \hspace{-15pt}
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{pic/safety-rw.eps}
        \caption{}
    \end{subfigure}
    \hspace{-15pt}
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{pic/time-rw.eps}
        \caption{}
    \end{subfigure}
    \caption{Runtime monitoring results for two experiments.}
    \label{fig:result}
\end{figure}
\begin{table}[htbp]
    \centering
    \caption{Average performance across different methods and experiments.}
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
        \hline
        \multirow{2}{*}{} & \multicolumn{3}{c|}{Accuracy} & \multicolumn{3}{c|}{Safety} & \multicolumn{3}{c|}{Time}\\ 
        \cline{2-10}
        & \textbf{SA} & \textbf{NO} & \textbf{RA} & \textbf{SA} & \textbf{NO} & \textbf{RA} & \textbf{SA} & \textbf{NO} & \textbf{RA}\\
        \hline
        \textbf{US}  & \textbf{85.9\%} & 68.6\% & 50.1\% & \textbf{90.5\%} & 78.6\% & 81.2\% & 11.9 & \textbf{11.8} & 14.3 \\ \hline
        \textbf{RW}  & \textbf{80.2\%} & 70.6\% & 50.0\% & \textbf{91.3\%} & 82.5\% & 84.1\% & 12.0 & \textbf{11.8} & 14.4 \\ \hline
    \end{tabular}
    \label{tab:result}
\end{table}
\subsection{Discussion and Lessons Learned}
The average performance of different experiments and methods is summarized in Table \ref{tab:result}, where \textbf{SA} (\textbf{SADEEPDECS}), \textbf{RA} (\textbf{RANDOM}), \textbf{US} (Uniform Sampling), and \textbf{RW} (Random Walk) are used as abbreviations. During operation, we observed that \textbf{SADEEPDECS} meets the safety specification and time efficiency (\ref{specification}) on average, although its time efficiency is slightly lower compared to \textbf{NO}. Notably, the safety of \textbf{NO} is even lower than that of \textbf{RA}, indicating that when the DNN perception component makes predictions in a distribution-shift environment, the system's safety can deteriorate to a level worse than random guessing. Furthermore, the average accuracy during operation is significantly higher than the other two methods, contributing to a more robust perception component.

As shown in Figure \ref{fig:result}, where (a), (b), and (c) represent the results of the \textit{uniform sampling} experiment and (d), (e), and (f) represent the results of the \textit{random walk} experiment, we found that when distribution shift occurs due to insufficient training dataset but the input distribution remains unchanged, the performance improvement during the repair process is relatively smooth. In contrast, in the \textit{random walk} experiment, where the data distribution changes over time and the training data is non-representative, performance fluctuations emerge during the repair process.

The system did not experience any interruptions caused by prediction and repair during the experimental process, providing preliminary validation of the feasibility and efficacy of the dual-component configuration.
\section{Conclusion}
This work presents a window-based monitoring framework for DNN perception components that leverages redundancy to separate repair from prediction, thereby achieving high availability, robustness, and adaptability of DNN-perceptive autonomous systems. Our approach enables the system to synthesize controllers online in the event of input distribution shift and enhances behavioral safety during prolonged system operation. Future work could explore other DNN repair methods and incorporate techniques for predicting shifts in advance to further enhance monitoring performance. Additionally, we aim to expand case studies by applying the method to other DNN-perceiving autonomous systems to further demonstrate its versatility.



\begin{thebibliography}{8}
\bibitem{acex1}
Tabernik, Domen, and Danijel Skočaj. "Deep learning for large-scale traffic-sign detection and recognition." IEEE transactions on intelligent transportation systems 21.4 (2019): 1427-1440. \doi{10.1109/TITS.2019.2913588}

\bibitem{acex2}
Grigorescu, Sorin, et al. "A survey of deep learning techniques for autonomous driving." Journal of field robotics 37.3 (2020): 362-386. \doi{10.1002/rob.21918}

\bibitem{acex3}
Tian, Yuchi, et al. "Deeptest: Automated testing of deep-neural-network-driven autonomous cars." Proceedings of the 40th international conference on software engineering. 2018. \doi{10.1145/3180155.31802}

\bibitem{hcex1}
Chen, Alvin I., et al. "Deep learning robotic guidance for autonomous vascular access." Nature Machine Intelligence 2.2 (2020): 104-115. \doi{10.1038/s42256-020-0148-7}

\bibitem{hcex2}
Qin, Yidan, et al. "Autonomous hierarchical surgical state estimation during robot-assisted surgery through deep neural networks." IEEE Robotics and Automation Letters 6.4 (2021): 6220-6227. \doi{10.1109/LRA.2021.3091728}

\bibitem{hcex3}
Huang, Yisen, et al. "A surgeon preference-guided autonomous instrument tracking method with a robotic flexible endoscope based on dVRK platform." IEEE Robotics and Automation Letters 7.2 (2022): 2250-2257. \doi{10.1109/LRA.2022.3143305}

\bibitem{deepdecs}
Calinescu, Radu, et al. "Controller Synthesis for Autonomous Systems with Deep-Learning Perception Components." IEEE Transactions on Software Engineering, pp.1374-1395 (2024). \doi{10.1109/TSE.2024.3385378}

\bibitem{closedloopanalysis}
Păsăreanu, Corina S., et al. "Closed-loop analysis of vision-based autonomous systems: A case study." International conference on computer aided verification. Cham: Springer Nature Switzerland, 2023. \doi{10.1007/978-3-031-37706-8_15}

\bibitem{conceptdrift}
Gama, João, et al. "A survey on concept drift adaptation." ACM computing surveys (CSUR) 46.4 (2014): 1-37. \doi{10.1145/2523813}

\bibitem{prism}
Kwiatkowska, Marta, Gethin Norman, and David Parker. "PRISM 4.0: Verification of probabilistic real-time systems." Computer Aided Verification: 23rd International Conference, CAV 2011, Snowbird, UT, USA, July 14-20, 2011. Proceedings 23. Springer Berlin Heidelberg, 2011. \doi{10.1007/978-3-642-22110-1_47}


\bibitem{fcex}
Ozbayoglu, Ahmet Murat, Mehmet Ugur Gudelek, and Omer Berat Sezer. "Deep learning for financial applications: A survey." Applied soft computing 93 (2020): 106384. \doi{10.1016/j.asoc.2020.106384}

\bibitem{fcex2}
Duan, Jing. "Financial system modeling using deep neural networks (DNNs) for effective risk assessment and prediction." Journal of the Franklin Institute 356.8 (2019): 4716-4731. \doi{10.1016/j.jfranklin.2019.01.046}

\bibitem{kejstova2018model}
Kejstová, Katarína, Petr Ročkai, and Jiří Barnat. "From model checking to runtime verification and back." Runtime Verification: 17th International Conference, RV 2017, Seattle, WA, USA, September 13-16, 2017, Proceedings 17. Springer International Publishing, 2017. \doi{10.1007/978-3-319-67531-2_14}

\bibitem{barshalom2022window}
Bar Shalom, Guy, Yonatan Geifman, and Ran El-Yaniv. "Window-based distribution shift detection for deep neural networks." Advances in Neural Information Processing Systems 36 (2024). 

\bibitem{barrabes2023adversarial}
Barrabés, Míriam, et al. "Adversarial learning for feature shift detection and correction." Advances in Neural Information Processing Systems 36 (2024).

\bibitem{rollback}
Carzaniga, Antonio, et al. "Automatic recovery from runtime failures." 2013 35th International Conference on Software Engineering (ICSE). IEEE, 2013. \doi{10.1109/ICSE.2013.6606624}

\bibitem{compensate}
Carzaniga, Antonio, et al. "Automatic workarounds: Exploiting the intrinsic redundancy of web applications." ACM Transactions on Software Engineering and Methodology (TOSEM) 24.3 (2015): 1-42. \doi{10.1145/2755970}

\bibitem{zhang2022empirical}
Hu, Qiang, et al. "An empirical study on data distribution-aware test selection for deep learning enhancement." ACM Transactions on Software Engineering and Methodology (TOSEM) 31.4 (2022): 1-30. \doi{10.1145/3511598}

\bibitem{PCTL1}
Bianco, Andrea, and Luca De Alfaro. "Model checking of probabilistic and nondeterministic systems." International Conference on Foundations of Software Technology and Theoretical Computer Science. Berlin, Heidelberg: Springer Berlin Heidelberg, 1995. \doi{10.1007/3-540-60692-0_70}

\bibitem{PDTMC1}
Daws, Conrado. "Symbolic and parametric model checking of discrete-time Markov chains." Theoretical Aspects of Computing-ICTAC 2004: First International Colloquium, Guiyang, China, September 20-24, 2004, Revised Selected Papers 1. Springer Berlin Heidelberg, 2005. \doi{10.1007/978-3-540-31862-0_21}

\bibitem{DNN1}
LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. "Deep learning." nature 521.7553 (2015): 436-444. \doi{10.1038/nature14539}

\bibitem{box2d}
Parberry, Ian. Introduction to Game Physics with Box2D. CRC Press, 2017. \doi{10.4324/9781315380636}

\bibitem{DTMC}
Arapostathis, Ari, Ratnesh Kumar, and S-P. Hsu. "Control of Markov chains with safety bounds." IEEE Transactions on Automation Science and Engineering 2.4 (2005): 333-343. \doi{10.1109/TASE.2005.853392}
\end{thebibliography}

\end{document}
