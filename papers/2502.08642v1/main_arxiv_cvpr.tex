
\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage[pagenumbers]{cvpr} %
\usepackage{minitoc}
\renewcommand \thepart{}
\renewcommand \partname{}

\usepackage[dvipsnames]{xcolor}


\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,citecolor=cvprblue]{hyperref}
\usepackage{tikz,lipsum}
\usepackage[most]{tcolorbox}
\usepackage[capitalize]{cleveref}
\usepackage{multirow}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{tabularx}
\usepackage{makecell}


\def\confName{CVPR}
\def\confYear{2025}

\title{\vspace{-0.8cm}SwiftSketch: A Diffusion Model for Image-to-Vector Sketch Generation\vspace{-0.3cm}}



\author{\hspace{-1cm} Ellie Arar$^{1}$ \hspace{-0.8cm} 
\and Yarden Frenkel$^{1}$ \hspace{-0.8cm}
\and Daniel Cohen-Or$^{1}$ \hspace{-0.8cm} 
\and Ariel Shamir$^{2}$ \hspace{-0.8cm}
\and Yael Vinker$^{1,3}$ \hspace{-1cm}
\and \hspace{0.9\linewidth} \and
$^{1}$Tel Aviv University \\ {\tt\small \{elliearar, Yf2, dcor\}@mail.tau.ac.il}\and $^{2}$Reichman University  \\ {\tt\small arik@runi.ac.il} \and $^{3}$MIT \\ {\tt\small yaelvink@mit.edu} \vspace{-0.5cm}\\ \and {\tt\small \href{https://swiftsketch.github.io/}{https://swiftsketch.github.io/} } \vspace{-0.6cm}
}


\newcommand{\methodname}{{SwiftSketch\xspace}}


\begin{document}
\doparttoc %
\faketableofcontents %

\twocolumn[{%
\vspace{-0.65cm}
\maketitle
\renewcommand\twocolumn[1][]{#1}%
\vspace{-0.8cm}
\begin{center}
    \centering
    \includegraphics[width=0.95\linewidth]{figs/swift_teaser2.pdf}
    \captionsetup{type=figure}
    \vspace{-0.3cm}
    \caption{SwiftSketch is a diffusion model that generates vector sketches by denoising a Gaussian in stroke coordinate space (top). It generalizes effectively across diverse classes and takes under a second to produce a single high-quality sketch (bottom).}
    \label{fig:teaser}
\end{center}
}]
\begin{abstract}
\vspace{-0.4cm}
Recent advancements in large vision-language models have enabled highly expressive and diverse vector sketch generation. However, state-of-the-art methods rely on a time-consuming optimization process involving repeated feedback from a pretrained model to determine stroke placement. Consequently, despite producing impressive sketches, these methods are limited in practical applications.
In this work, we introduce \emph{SwiftSketch}, a diffusion model for image-conditioned vector sketch generation that can produce high-quality sketches in less than a second.
SwiftSketch operates by progressively denoising stroke control points sampled from a Gaussian distribution. 
Its transformer-decoder architecture is designed to effectively handle the discrete nature of vector representation and capture the inherent global dependencies between strokes.
To train SwiftSketch, we construct a \emph{synthetic} dataset of image-sketch pairs, addressing the limitations of existing sketch datasets, which are often created by non-artists and lack professional quality. For generating these synthetic sketches, we introduce ControlSketch, a method that enhances SDS-based techniques by incorporating precise spatial control through a depth-aware ControlNet.
We demonstrate that SwiftSketch generalizes across diverse concepts, efficiently producing sketches that combine high fidelity with a natural and visually appealing style.
\end{abstract}

   
\input{arxiv_sec/1_intro}
\input{arxiv_sec/2_prev_work}
\input{arxiv_sec/3_method}
\input{arxiv_sec/4_results}
\input{arxiv_sec/5_conclusions}

\section{Acknowledgements}
We thank Guy Tevet and Oren Katzir for their valuable insights and engaging discussions. We also thank Yuval Alaluf, Elad Richardson, and Sagi Polaczek for providing feedback on early versions of our manuscript. 
This work was partially supported by Joint NSFC-ISF Research Grant no. 3077/23 and Isf 3441/21.

\begin{figure*}
    \centering
    \includegraphics[width=0.87\linewidth]{figs/results/swiftsketch_seen.pdf}
    \vspace{-0.2cm}
    \caption{Sketches generated by SwiftSketch for seen categories, using input images not included in the training data.}
    \label{fig:qualitative-swift-seen}
\end{figure*}



\begin{figure*}
    \centering
    \includegraphics[width=0.87\linewidth]{figs/results/swiftsketch_unseen.pdf}
    \vspace{-0.2cm}
    \caption{Sketches generated by SwiftSketch for unseen categories.}
    \label{fig:qualitative-swift-unseen}
\end{figure*}


\input{tables/quali_opt}

{
    \small
    \bibliographystyle{ieee_fullname}
    \bibliography{main}
}

\clearpage
\appendix
\setcounter{page}{1}

\newpage
\twocolumn[
\centering
\Large
\textbf{\thetitle}\\
\vspace{2em}Supplementary Material \\
\vspace{1.0em}
] %

   

\part{}
\vspace{-20pt}
\parttoc

\input{arxiv_sec/7_supp}


\end{document}
