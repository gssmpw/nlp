@Article{Liu2020,
  author     = {Liu, Yiming and Yu, F. Richard and Li, Xi and Ji, Hong and Leung, Victor C. M.},
  journal    = {IEEE Commun. Surveys Tuts.},
  title      = {Blockchain and Machine Learning for Communications and Networking Systems},
  year       = {2020},
  number     = {2},
  pages      = {1392-1431},
  volume     = {22},
  comment    = {本文总结了大量区块链与机器学习领域的论文，各从四个方面论证两项技术可以融合并应用于通信网络系统中，并列举了一些需要进一步研究的问题。},
  doi        = {10.1109/COMST.2020.2975911},
  file       = {:2020Liu - Blockchain and Machine Learning for Communications and Networking Systems.pdf:PDF},
  groups     = {ML and Blockchain, Applications of Optimization, ML and BC, Applications of Optimization ML and BC},
  keywords   = {Blockchain, Machine Learning, Communication, Wireless Network},
  ranking    = {rank3},
  readstatus = {read},
}

@Article{Baldominos2019,
  author     = {Alejandro Baldominos and Yago Saez},
  journal    = {Entropy},
  title      = {Coin.{AI}: A Proof-of-Useful-Work Scheme for Blockchain-Based Distributed Deep Learning},
  year       = {2019},
  month      = jul,
  number     = {8},
  pages      = {723},
  volume     = {21},
  abstract   = {One decade ago, Bitcoin was introduced, becoming the first cryptocurrency and establishing the concept of ``blockchain'' as a distributed ledger. As of today, there are many different implementations of cryptocurrencies working over a blockchain, with different approaches and philosophies. However, many of them share one common feature: they require proof-of-work to support the generation of blocks (mining) and, eventually, the generation of money. This proof-of-work scheme often consists in the resolution of a cryptography problem, most commonly breaking a hash value, which can only be achieved through brute-force. The main drawback of proof-of-work is that it requires ridiculously large amounts of energy which do not have any useful outcome beyond supporting the currency. In this paper, we present a theoretical proposal that introduces a proof-of-useful-work scheme to support a cryptocurrency running over a blockchain, which we named Coin.AI. In this system, the mining scheme requires training deep learning models, and a block is only mined when the performance of such model exceeds a threshold. The distributed system allows for nodes to verify the models delivered by miners in an easy way (certainly much more efficiently than the mining process itself), determining when a block is to be generated. Additionally, this paper presents a proof-of-storage scheme for rewarding users that provide storage for the deep learning models, as well as a theoretical dissertation on how the mechanics of the system could be articulated with the ultimate goal of democratizing access to artificial intelligence.},
  comment    = {提出一种新的共识机制Coin.AI进行分布式大规模神经架构搜索。只有在训练的模型性能超过某一阈值之后才能挖出新的块，通过一种将哈希映射为网络结构的机制实现每个区块哈希对应一个神经网络结构，文中提出一种生成语法，通过迭代实现哈希到网络结构的映射。此外还采用一种存储证明机制奖励为深度学习模型提供存储的用户，获胜的矿工会将模型上传给R个保管者，每个离开网络的保管者都需要将模型转交给另一个保管者，这使得网络上存在R个模型副本。此外这种存储证明机制也可以应用到训练数据集上使矿工快速获得这些数据。},
  doi        = {10.3390/e21080723},
  file       = {:2019julBaldominos - Coin.AI_ a Proof of Useful Work Scheme for Blockchain Based Distributed Deep Learning.pdf:PDF},
  groups     = {ML and Blockchain},
  keywords   = {blockchain, cryptocurrency, neural networks, deep learning, proof-of-work},
  priority   = {prio3},
  publisher  = {{MDPI} {AG}},
  ranking    = {rank2},
  readstatus = {read},
}

@Article{Wei2022,
  author   = {Wei, Yunkai and An, Zixian and Leng, Supeng and Yang, Kun},
  journal  = {IEEE Internet of Things Journal},
  title    = {Evolved PoW: Integrating the Matrix Computation in Machine Learning into Blockchain Mining},
  year     = {2022},
  pages    = {1-1},
  comment  = {提出Evolved-Proof-of-Work，将机器学习中的矩阵运算合并到区块链挖矿的过程中。为了挖矿的公平性设计了奖励调整机制。},
  doi      = {10.1109/JIOT.2022.3165973},
  file     = {:2022Wei - Evolved PoW_ Integrating the Matrix Computation in Machine Learning into Blockchain Mining.pdf:PDF},
  groups   = {ML and Blockchain},
  keywords = {blockchain, matrix computation, evolved proof-of-work, consensus, machine learning},
  ranking  = {rank2},
}

@Article{Liu2021,
  author     = {Yuan Liu and Yixiao Lan and Boyang Li and Chunyan Miao and Zhihong Tian},
  journal    = {Comput. Networks},
  title      = {Proof of Learning ({PoLe}): Empowering neural network training with consensus building on blockchains},
  year       = {2021},
  issn       = {1389-1286},
  month      = nov,
  pages      = {108594},
  volume     = {201},
  abstract   = {The advent of neural network (NN) based deep learning, especially the recent development of the automatic design of networks, has brought unprecedented performance gains at heavy computational cost. On the other hand, in order to generate a new consensus block, Proof of Work (PoW) based blockchain systems routinely perform a huge amount of computation that does not achieve practical purposes but to solving a difficult cryptographic hash puzzle problem.In this study, we propose a new consensus mechanism, Proof of Learning (PoLe), which directs the computation spent for block consensus toward optimization of neural networks. In our design, the training and testing data are released to the entire blockchain network and the consensus nodes train NN models on the data, which serves as the proof of learning. As a core component of PoLe, we design a secure mapping layer (SML) to prevent consensus nodes from cheating, which can be straightforwardly implemented as a linear NN layer. When the consensus on the blockchain network is achieved, a new block is appended to the blockchain. We experimentally compare the PoLe protocol with Proof of Work (PoW) and show that PoLe can achieve a more stable block generation rate, which leads to more efficient transaction processing. Experimental evaluation also shows the PoLe can achieve a stable block generation rate without significantly sacrificing training performance.},
  comment    = {提出新共识机制Proof of Learning，将产生区块共识的算力导入到神经网络的优化中。作者设计了安全映射层SML，将模型训练者的身份与其模型的输入数据转换绑定，从而防止节点通过偷窃其他节点模型或者对模型预训练作弊。SML层通过线性神经网络层实现，安全性能以及对模型训练的影响需要进一步研究。
作者声称与Baldominos2019、BravoMarquez2019、Lihu2020三篇文章相比更优越，同时实现了神经网络任务自定义、禁止预训练、模型防偷窃三种特性。

采用Proof of Learning共识机制的网络中主要有两种节点：数据节点与共识节点。共识过程实际上分为两个阶段，第一个阶段数据节点向网络广播训练任务、支付报酬，该任务会加入区块中的任务列表，共识节点选择最有价值的任务开始、下载训练数据、创建SML层在数据节点提供的模型的输入层前，然后训练模型，训练正确率大于数据节点要求的正确率之后创建区块并向其他共识节点广播；如果数据节点发布测试集或者超过最大训练时间，则进入第二阶段，开始对接收到的区块进行验证，对SML层验证后确定区块时间戳是否早于测试集发布的时间戳，计算区块中模型在测试集上的正确率，正确率最高的有效块将会成为获胜的区块。
区块中存储了获胜共识节点从数据节点接收到的任务的列表，分为尚未解决任务列表与新任务列表。
部分奖励会分配给叔块的产生者，分配量根据公式（1）决定。
通过三个实验，文章证明了：（1）PoLe的出块时间方差显著地低于PoW（2）SML层对模型性能的影响较小（3）如果恶意变更SML层来复用模型或偷窃模型，模型性能会严重劣化。
（介绍SML层的章节中不太理解IPFE与IPFE-FH，如何通过SML层验证某个矿工产生了模型？）},
  doi        = {10.1016/j.comnet.2021.108594},
  file       = {:2021Liu - Proof of Learning (PoLe)_ Empowering Neural Network Training with Consensus Building on Blockchains.pdf:PDF},
  groups     = {ML and Blockchain},
  keywords   = {Consensus mechanism, Proof of Learning, Secure mapping layer, Machine Learning},
  priority   = {prio3},
  ranking    = {rank4},
  readstatus = {read},
}

@Article{Shibata2019,
  author     = {Shibata, Naoki},
  journal    = {IEEE Access},
  title      = {Proof-of-Search: Combining Blockchain Consensus Formation With Solving Optimization Problems},
  year       = {2019},
  month      = nov,
  pages      = {172994-173006},
  volume     = {7},
  comment    = {本文介绍了一种区块链共识机制PoS，该机制允许客户花费一定虚拟币使区块链网络搜索指定优化问题的解，这使得采用这种共识机制的区块链网络能将一部分算力用于解决实际问题。本文比较详细地介绍这种共识机制地运行方式并举例说明。},
  doi        = {10.1109/ACCESS.2019.2956698},
  file       = {:2019Shibata - Proof of Search_ Combining Blockchain Consensus Formation with Solving Optimization Problems.pdf:PDF},
  groups     = {Optimization and Blockchain},
  keywords   = {Protocols, Peer-to-peer computing, Bitcoin, Optimization, Robustness},
  ranking    = {rank4},
  readstatus = {read},
}

@Article{Tschorsch2016,
  author     = {Tschorsch, Florian and Scheuermann, Björn},
  journal    = {IEEE Commun. Surveys Tut.},
  title      = {Bitcoin and Beyond: A Technical Survey on Decentralized Digital Currencies},
  year       = {2016},
  month      = {3rd Quart.},
  number     = {3},
  pages      = {2084-2123},
  volume     = {18},
  comment    = {本文在各方面对比特币进行了详细介绍，有助于了解PoW、分布式账本等区块链系统的核心概念。},
  doi        = {10.1109/COMST.2016.2535718},
  file       = {:2016Tschorsch - Bitcoin and Beyond_ a Technical Survey on Decentralized Digital Currencies.pdf:PDF},
  groups     = {Blockchain Surveys},
  keywords   = {Bitcoin, Blockchain, Distributed Ledger},
  ranking    = {rank5},
  readstatus = {skimmed},
}

@Article{Davidovic_2022,
  author     = {Tatjana Davidovic and Milan Todorovic and Dusan Ramljak and Tatjana Jaksic Kruger and Luka Matijevic and Djordje Jovanovic and Dragan Urosevic},
  title      = {{COCP}: Blockchain Proof-of-Useful-Work Leveraging Real-Life Applications},
  year       = {2022},
  month      = {sep},
  booktitle  = {2022 Fourth International Conference on Blockchain Computing and Applications ({BCCA})},
  comment    = {提出一种将组合优化与区块链融合的共识协议。},
  doi        = {10.1109/BCCA55292.2022.9922117},
  file       = {:2022sepDavidovic - COCP_ Blockchain Proof of Useful Work Leveraging Real Life Applications.pdf:PDF},
  groups     = {Optimization and Blockchain},
  keywords   = {Energy resolution, Consensus protocol, Computational efficiency, Distributed computing, Optimization},
  publisher  = {{IEEE}},
  ranking    = {rank3},
  readstatus = {read},
}

@Article{Zarrin_2021,
  author     = {Javad Zarrin and Hao Wen Phang and Lakshmi Babu Saheer and Bahram Zarrin},
  journal    = {Cluster Computing},
  title      = {Blockchain for decentralization of internet: prospects, trends, and challenges},
  year       = {2021},
  month      = {may},
  number     = {4},
  pages      = {2841--2866},
  volume     = {24},
  comment    = {本文主要介绍了多种共识协议，探讨新兴网络技术与区块链技术的融合的可能性以及互联网去中心化的构想。},
  doi        = {10.1007/s10586-021-03301-8},
  file       = {:2021mayZarrin - Blockchain for Decentralization of Internet_ Prospects, Trends, and Challenges.pdf:PDF},
  groups     = {Blockchain Surveys},
  keywords   = {Blockchain, Consensus algorithms, Decentralization, Decentralized cloud, Future internet},
  publisher  = {Springer Science and Business Media {LLC}},
  ranking    = {rank3},
  readstatus = {read},
}

@Article{Oyinloye2021BlockchainCA,
  author     = {Damilare Peter Oyinloye and Je Sen Teh and Norziana Jamil and Moatsum Alawida},
  journal    = {Symmetry},
  title      = {Blockchain Consensus: An Overview of Alternative Protocols},
  year       = {2021},
  month      = jul,
  pages      = {1363},
  volume     = {13},
  comment    = {介绍了当前流行的区块链共识协议以及替代的协议，并通过一些指标对比这些共识协议。(关注PoSe PoE PoL)},
  doi        = {10.3390/sym13081363},
  file       = {:2021Oyinloye - Blockchain Consensus_ an Overview of Alternative Protocols.pdf:PDF},
  groups     = {Blockchain Surveys},
  ranking    = {rank4},
  readstatus = {skimmed},
}

@InProceedings{Fitzi2022,
  author    = {Fitzi, Matthias and Kiayias, Aggelos and Panagiotakos, Giorgos and Russell, Alexander},
  booktitle = {Proc. 42nd Annu. Int. Cryptology Conf. (CRYPTO'22)},
  title     = {Ofelimos: Combinatorial Optimization via Proof-of-Useful-Work},
  year      = {2022},
  address   = {Santa Barbara, USA},
  month     = aug,
  pages     = {339--369},
  abstract  = {Minimizing the energy cost and carbon footprint of the Bitcoin blockchain and related protocols is one of the most widely identified open questions in the cryptocurrency space. Substituting the proof-of-work (PoW) primitive in Nakamoto's longest-chain protocol with a proof of useful work (PoUW) has been long theorized as an ideal solution in many respects but, to this day, the concept still lacks a convincingly secure realization.},
  comment   = {提出DPLS算法以及基于此算法的PoUW区块链共识协议。DPLS是一种复杂本地搜索算法，适合实施于PoUW共识协议中来构建去中心化的组合优化问题求解器。文章中严格证明了该共识协议的安全性。},
  doi       = {10.1007/978-3-031-15979-4_12},
  file      = {:2022Fitzi - Ofelimos_ Combinatorial Optimization Via Proof of Useful Work.pdf:PDF;:Fitzi2021 - Ofelimos_ Combinatorial Optimization Via Proof of Useful Work _ a Provably Secure Blockchain Protocol.pdf:PDF},
  groups    = {Optimization and Blockchain},
  isbn      = {978-3-031-15979-4},
  keywords  = {Blockchain, consensus, proof-of-useful-work, stochastic local search, combinatorial optimization},
  ranking   = {rank4},
}

@InProceedings{9025613,
  author     = {Li, Boyang and Chenli, Changhao and Xu, Xiaowei and Jung, Taeho and Shi, Yiyu},
  booktitle  = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  title      = {Exploiting Computation Power of Blockchain for Biomedical Image Segmentation},
  year       = {2019},
  pages      = {2802-2811},
  comment    = {提出一种利用矿工算力进行生医图像分片任务的PoUW共识系统。},
  doi        = {10.1109/CVPRW.2019.00339},
  file       = {:2019Li - Exploiting Computation Power of Blockchain for Biomedical Image Segmentation.pdf:PDF},
  groups     = {Applications of Optimization, ML and BC, Applications of Optimization ML and BC},
  keywords   = {Task analysis, Image segmentation, Biomedical imaging, Training, Biological system modeling, Computational modeling, Blockchain, Machine Learning},
  ranking    = {rank1},
  readstatus = {skimmed},
}

@Article{Haouari2022,
  author     = {Mohamed Haouari and Mariem Mhiri and Mazen El-Masri and Karim Al-Yafi},
  journal    = {Inf. Process. Manage.},
  title      = {A novel proof of useful work for a blockchain storing transportation transactions},
  year       = {2022},
  issn       = {0306-4573},
  month      = jan,
  number     = {1},
  pages      = {102749},
  volume     = {59},
  abstract   = {Proof-of-Work (PoW) is a common mechanism used to validate peer-to-peer transactions and maintain highly secured immutability of the blockchain. However, this mechanism has been criticized due to its inefficient use of computing resources and its limited usefulness. In this paper, we propose the Proof-of-Useful-Work (PoUW) as an alternative mechanism for transaction validation that puts the squandered computing resources to beneficial use. The main premise is to replace the mathematical puzzle, which constitutes a fundamental part of the Proof-of-Work mechanism, with NP-hard optimization problems whose solutions benefit the participants of the blockchain. We demonstrate its usefulness in the context of transportation. Accordingly, PoUW-based blockchain not only tracks, manages and validates transactions, but also optimizes transportation requests profiting its ecosystem. We describe the framework of the proposed PoUW along with the associated optimization model and the miner’s reward mechanism.},
  comment    = {提出一种基于聚类问题的PoUW共识协议，并介绍了一种基于该共识协议存储运输请求并优化运输成本的区块链系统。该研究的创新之处在于通过区块链系统解决交通运输请求聚类问题，不仅可以充分利用区块链网络中的算力解决这一有实际意义的NP-hard问题，还能帮助用户减少运输成本，有利于区块链生态系统的构建。作者在文中详细解释了该PoUW共识协议的运作流程，矿工从用户处接收运输请求，收集到一定量运输请求后矿工提取所有具有相同出发地与到达地的运输请求并开始求解优化问题，一旦获得一个成本低于阈值的可行解就向其他矿工广播，其他矿工验证通过之后将该解连同交易信息一同随新区块添加到区块链。为了使该区块链系统可持续，作者设计了一种激励机制，公平分配经过优化之后节省的运输成本。},
  doi        = {10.1016/j.ipm.2021.102749},
  file       = {:2022Haouari - A Novel Proof of Useful Work for a Blockchain Storing Transportation Transactions.pdf:PDF},
  groups     = {Optimization and Blockchain, Applications of Optimization, ML and BC, Applications of Optimization ML and BC},
  keywords   = {Blockchain, Supply chain, Proof of Useful Work, NP-hard optimization problem, Application},
  ranking    = {rank5},
  readstatus = {skimmed},
}

@Article{Ball2017,
  author         = {Marshall Ball and Alon Rosen and Manuel Sabin and Prashant Nalini Vasudevan},
  journal        = {IACR Cryptol. ePrint Arch.},
  title          = {Proofs of Useful Work},
  year           = {2017},
  month          = feb,
  pages          = {203},
  volume         = {2017},
  comment        = {(理论性强)提出PoWs共识机制，此共识机制基于正交向量、3SUM等计算问题以及所有可以化简到这些问题的问题，可以把挖矿所需要的能量用于这些有实际意义的问题。此外总结对PoUW协议的要求、PoUW需要具有的基本算法模型等	。},
  file           = {:2017Ball - Proofs of Useful Work.pdf:PDF},
  groups         = {PoUW},
  keywords       = {Proofs of work, Fine-Grained, Delegation, Blockchain},
  qualityassured = {qualityAssured},
  ranking        = {rank3},
}

@InProceedings{Loe2018,
  author     = {Loe, Angelique Faye and Quaglia, Elizabeth A.},
  booktitle  = {Proc. 1st Workshop Cryptocurrencies Blockchains Distrib. Syst. (CryBlock'18)},
  title      = {Conquering Generals: An {NP}-Hard Proof of Useful Work},
  year       = {2018},
  address    = {Munich, DE},
  month      = jun,
  pages      = {54-59},
  abstract   = {Proof of Work systems are used in cryptocurrencies to obtain consensus in distributed peer-to-peer systems that share no trust. Miners of cryptocurrency compete by engaging in the Proof of Work to solve a cryptographic challenge. The first to successfully provide a solution to the challenge wins by minting new currency. The process of mining also simultaneously prevents double-spending through the creation of an append-only distributed database known as the blockchain. The most widely adopted Proof of Work is the Hashcash scheme and the most widely deployed miners are ASIC-based. Despite the popularity of Hashcash, two issues are commonly identified its use. Firstly, the high energy consumption of the scheme is perceived as wasteful because the solutions found provide no useful output, and secondly, the computational complexity class of the scheme is not formally known. Based on these deficiencies, we propose a novel Proof of Work system which achieves the following goals:- to provide a fiscally incentivized platform for algorithm research that aims to optimize an NP-Hard computational problem. This provides indirect insight into the P Versus NP Clay Institute Millennium problem, thus providing useful output.- to construct a challenge within a known hard computational complexity class.- to ensure the Proof of Work created is inclusive of ASIC hardware. Our proposal is a hybrid Proof of Work system that initially uses the Hashcash scheme and which subsequently constructs an instance of the NP-Hard Travelling Salesman Problem. We build on the ambitions of others to develop Proofs of Useful Work. We differentiate our paper from related work as the first to consider the current capital investment into ASIC hardware, thus including them in our proposal.},
  comment    = {提出一种PoUW共识协议，在保留工作量证明（避免ASIC硬件的浪费）的同时引入旅行商问题，每个区块间隔分为两个阶段分别做工作量证明以及完成TSP问题实例，（严格定义问题的计算复杂度类？）。},
  doi        = {10.1145/3211933.3211943},
  file       = {:2018Loe - Conquering Generals_ an NP Hard Proof of Useful Work.pdf:PDF},
  groups     = {Optimization and Blockchain},
  isbn       = {9781450358385},
  keywords   = {Blockchain, Consensus, Optimization, Travelling Salesman Problem},
  location   = {Munich, Germany},
  numpages   = {6},
  ranking    = {rank3},
  readstatus = {skimmed},
}

@InProceedings{Chatterjee2019,
  author     = {Chatterjee, Krishnendu and Goharshady, Amir Kafshdar and Pourdamghani, Arash},
  booktitle  = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
  title      = {Hybrid Mining: Exploiting Blockchain's Computational Power for Distributed Problem Solving},
  year       = {2019},
  address    = {New York, NY, USA},
  pages      = {374–381},
  publisher  = {Association for Computing Machinery},
  series     = {SAC '19},
  abstract   = {In today's cryptocurrencies, Hashcash proof of work is the most commonly-adopted approach to mining. In Hashcash, when a miner decides to add a block to the chain, she has to solve the difficult computational puzzle of inverting a hash function. While Hashcash has been successfully adopted in both Bitcoin and Ethereum, it has attracted significant and harsh criticism due to its massive waste of electricity, its carbon footprint and environmental effects, and the inherent lack of usefulness in inverting a hash function. Various other mining protocols have been suggested, including proof of stake, in which a miner's chance of adding the next block is proportional to her current balance. However, such protocols lead to a higher entry cost for new miners who might not still have any stake in the cryptocurrency, and can in the worst case lead to an oligopoly, where the rich have complete control over mining.In this paper, we propose Hybrid Mining: a new mining protocol that combines solving real-world useful problems with Hashcash. Our protocol allows new miners to join the network by taking part in Hashcash mining without having to own an initial stake. It also allows nodes of the network to submit hard computational problems whose solutions are of interest in the real world, e.g. protein folding problems. Then, miners can choose to compete in solving these problems, in lieu of Hashcash, for adding a new block. Hence, Hybrid Mining incentivizes miners to solve useful problems, such as hard computational problems arising in biology, in a distributed manner. It also gives researchers in other areas an easy-to-use tool to outsource their hard computations to the blockchain network, which has enormous computational power, by paying a reward to the miner who solves the problem for them. Moreover, our protocol provides strong security guarantees and is at least as resilient to double spending as Bitcoin.},
  comment    = {提出混合挖矿协议(Hybrid Mining)，激励矿工解决现实世界中有用的问题但仍旧与传统的工作量证明机制保持兼容。},
  doi        = {10.1145/3297280.3297319},
  file       = {:2019Chatterjee - Hybrid Mining_ Exploiting Blockchain's Computational Power for Distributed Problem Solving.pdf:PDF},
  groups     = {PoUW},
  isbn       = {9781450359337},
  keywords   = {distributed problem solving, blockchain, proof of work, mining},
  location   = {Limassol, Cyprus},
  numpages   = {8},
  ranking    = {rank3},
  readstatus = {skimmed},
}

@InProceedings{Du2022,
  author    = {Du, Yao and Leung, Cyril and Wang, Zehua and Leung, Victor C.M.},
  booktitle = {2022 IEEE/ACM 30th International Symposium on Quality of Service (IWQoS)},
  title     = {Accelerating Blockchain-enabled Distributed Machine Learning by Proof of Useful Work},
  year      = {2022},
  pages     = {1-10},
  comment   = {本文讨论基于区块链的去中心化机器学习在IoT中的应用。提出了一种全新的PoUW共识协议，通过区块链算力加速DML，通过解多路数字分区问题在多个MEC(Multi-access edge computing)服务器之间调度DML任务从而最小化区块链带来的延迟。
1. blockchain based DML, aggregated by miner successfully generate new block
2. uPoW, in which the "useful work" is the solution of task scheduling problem in the DML framework.},
  doi       = {10.1109/IWQoS54832.2022.9812927},
  file      = {:2022Du - Accelerating Blockchain Enabled Distributed Machine Learning by Proof of Useful Work.pdf:PDF},
  groups    = {ML and Blockchain, Applications of Optimization ML and BC, Optimization and Blockchain},
  keywords  = {Training, Schedules, Simulation, Machine learning, Quality of service, Benchmark testing, Internet of Things},
  ranking   = {rank2},
}

@Article{Philippopoulos2020,
  author       = {Philippopoulos, Pericles and Ricottone, Alessandro and G. Oliver, Carlos},
  journal      = {Ledger},
  title        = {Difficulty Scaling in Proof of Work for Decentralized Problem Solving},
  year         = {2020},
  month        = aug,
  volume       = {5},
  abstractnote = {&amp;lt;p&amp;gt;We propose DIPS (Difficulty-based Incentives for Problem Solving), a simple modification of the Bitcoin proof-of-work algorithm that rewards blockchain miners for solving optimization problems of scientific interest. The result is a blockchain which redirects some of the computational resources invested in hash-based mining towards scientific computation, effectively reducing the amount of energy ‘wasted’ on mining. DIPS builds the solving incentive directly in the proof-of-work by providing a reduction in block hashing difficulty when optimization improvements are found. A key advantage of this scheme is that decentralization is not greatly compromised while maintaining a simple blockchain design. We study two incentivization schemes and provide simulation results showing that DIPS is able to reduce the amount of hash-power used in the network while generating solutions to optimization problems.&amp;lt;/p&amp;gt;},
  comment      = {提出DIPS算法，将部分用于工作量证明机制的算力重定向到科学计算。对矿工的激励方式实际上是减少哈希难度，从而简化区块链的设计。},
  doi          = {10.5195/ledger.2020.194},
  file         = {:2020AugustPhilippopoulos - Difficulty Scaling in Proof of Work for Decentralized Problem Solving.pdf:PDF},
  groups       = {Optimization and Blockchain},
  keywords     = {Proof of work, optimization, blockchain},
  ranking      = {rank3},
  url          = {https://ledger.pitt.edu/ojs/ledger/article/view/194},
}

@Article{Oliver2017,
  author   = {Oliver, Carlos and Ricottone, Alessandro and Philippopoulos, Pericles},
  title    = {Proposal for a fully decentralized blockchain and proof-of-work algorithm for solving NP-complete problems},
  year     = {2017},
  month    = {08},
  comment  = {提出激励矿工完成NP完备计算问题的想法。},
  file     = {:2017Oliver - Proposal for a Fully Decentralized Blockchain and Proof of Work Algorithm for Solving NP Complete Problems.pdf:PDF;:2017Oliver - Proposal for a Fully Decentralized Blockchain and Proof of Work Algorithm for Solving NP Complete Problems.pdf:PDF},
  groups   = {PoUW},
  keywords = {blockchain, NP-complete problems},
  ranking  = {rank3},
}

@Article{Ileri2016,
  author   = {Atalay Mert Ileri and Halil Ibrahim Ozercan and Alper Gundogdu and Ahmet Senol and M. Yusuf {\"O}zkaya and Can Alkan},
  journal  = {ArXiv},
  title    = {Coinami: A Cryptocurrency with DNA Sequence Alignment as Proof-of-work},
  year     = {2016},
  volume   = {abs/1602.03031},
  comment  = {通过加密货币系统激励志愿者投入更多资源帮助处理基因序列数据。},
  file     = {:2016Ileri - Coinami_ a Cryptocurrency with DNA Sequence Alignment As Proof of Work.pdf:PDF},
  groups   = {PoUW},
  keywords = {Blockchain},
  ranking  = {rank2},
}

@Article{Mehta2022,
  author   = {Shikha Mehta and Mukta Goyal and Dinesh Kumar Saini},
  journal  = {Int. J. Fuzzy Syst. Appl.},
  title    = {Efficient Bitcoin Mining Using Genetic Algorithm-Based Proof of Work},
  year     = {2022},
  pages    = {1-17},
  volume   = {11},
  comment  = {提出通过遗传算法优化工作量证明机制下的区块链挖矿，提升挖矿效率。},
  doi      = {10.4018/ijfsa.296593},
  file     = {:2022Mehta - Efficient Bitcoin Mining Using Genetic Algorithm Based Proof of Work.pdf:PDF},
  groups   = {Optimization and Blockchain},
  keywords = {Blockchain, PoW, Genetic Algorithm, Optimization},
  ranking  = {rank3},
}

@InProceedings{Toulemonde2022,
  author    = {Toulemonde, Ambre and Besson, Loic and Goubin, Louis and Patarin, Jacques},
  booktitle = {Proceedings of the 2022 ACM Conference on Information Technology for Social Good},
  title     = {Useful Work: A New Protocol to Ensure Usefulness of PoW-Based Consensus for Blockchain},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {308–314},
  publisher = {Association for Computing Machinery},
  series    = {GoodIT '22},
  abstract  = {The blockchain is a new technology that attracts several actors since 2009, and in particular in the financial domain with the emergence of cryptocurrencies such as the well-known Bitcoin. In a blockchain, seen also as a distributed ledger or a chain of blocks, the participants use a consensus protocol to add new data into the ledger. For example, in the Bitcoin Proof-of-Work consensus protocol, the participants have to unnecessarily invest a huge amount of energy to add a new block of transactions, and therefore to also win the coin associated to this block. Several consensus protocols have been proposed to overcome this waste and resource intensive process. In this paper, we present a new consensus protocol for blockchain technologies called Useful Work (UW). Our UW protocol is based on the Proof-of-Stake and Proof-of-Work mechanisms where the computing work is dedicated to useful problems. The participants get a chance to win coins after performing honest and useful work for a submitted problem. We present a high-level description of our UW protocol that is configurable and propose some variants of the protocol. We discuss also some new and well-known issues that our protocol prevents.},
  comment   = {提出一种基于PoW与PoS机制的共识机制，通过投票机制选出待解决的问题以及新币的分配，最终确保算力与内存都用于解决有用的问题。},
  doi       = {10.1145/3524458.3547248},
  file      = {:2022Toulemonde - Useful Work_ a New Protocol to Ensure Usefulness of PoW Based Consensus for Blockchain.pdf:PDF},
  groups    = {PoUW},
  isbn      = {9781450392846},
  keywords  = {Proof-of-Stake, Proof-of-Work, Approval-based Group Voting., Useful Work, Consensus, Blockchain},
  location  = {Limassol, Cyprus},
  numpages  = {7},
  ranking   = {rank2},
}

@InProceedings{Gilad2017,
  author    = {Gilad, Yossi and Hemo, Rotem and Micali, Silvio and Vlachos, Georgios and Zeldovich, Nickolai},
  booktitle = {Proceedings of the 26th Symposium on Operating Systems Principles},
  title     = {Algorand: Scaling Byzantine Agreements for Cryptocurrencies},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {51–68},
  publisher = {Association for Computing Machinery},
  series    = {SOSP '17},
  abstract  = {Algorand is a new cryptocurrency that confirms transactions with latency on the order of a minute while scaling to many users. Algorand ensures that users never have divergent views of confirmed transactions, even if some of the users are malicious and the network is temporarily partitioned. In contrast, existing cryptocurrencies allow for temporary forks and therefore require a long time, on the order of an hour, to confirm transactions with high confidence.Algorand uses a new Byzantine Agreement (BA) protocol to reach consensus among users on the next set of transactions. To scale the consensus to many users, Algorand uses a novel mechanism based on Verifiable Random Functions that allows users to privately check whether they are selected to participate in the BA to agree on the next set of transactions, and to include a proof of their selection in their network messages. In Algorand's BA protocol, users do not keep any private state except for their private keys, which allows Algorand to replace participants immediately after they send a message. This mitigates targeted attacks on chosen participants after their identity is revealed.We implement Algorand and evaluate its performance on 1,000 EC2 virtual machines, simulating up to 500,000 users. Experimental results show that Algorand confirms transactions in under a minute, achieves 125x Bitcoin's throughput, and incurs almost no penalty for scaling to more users.},
  comment   = {介绍一种采用拜占庭共识协议的加密货币，采用可验证随机函数VRF来实现抽签，被选择的节点参与拜占庭协议对当前的交易达成共识并且低延时无分叉。通过实验发现Algorand能在一分钟内确认交易，吞吐量远优于比特币。},
  doi       = {10.1145/3132747.3132757},
  file      = {:2017Gilad - Algorand_ Scaling Byzantine Agreements for Cryptocurrencies.pdf:PDF},
  groups    = {Blockchain Theory},
  isbn      = {9781450350853},
  keywords  = {Blockchain, Consensus},
  location  = {Shanghai, China},
  numpages  = {18},
  ranking   = {rank3},
}

@InProceedings{Syafruddin2019,
  author    = {Syafruddin, Willa Ariela and Dadkhah, Sajjad and Köppen, Mario},
  booktitle = {Proc. 2019 IEEE Cong. Evol. Comput. (CEC)},
  title     = {Blockchain Scheme Based on Evolutionary Proof of Work},
  year      = {2019},
  address   = {Wellington, NZ},
  month     = jun,
  pages     = {771-776},
  comment   = {提出将解旅行商问题作为工作量证明机制，使得区块链能完成一些有用的工作，提出在区块链中采用一种万能启发式算法。（与[Loe2018]的区别？）},
  doi       = {10.1109/CEC.2019.8790128},
  file      = {:2019Syafruddin - Blockchain Scheme Based on Evolutionary Proof of Work.pdf:PDF},
  groups    = {Optimization and Blockchain},
  keywords  = {Blockchain, Optimization, Urban areas, Cryptography, Peer-to-peer computing, Task analysis, Encoding},
  ranking   = {rank3},
}

@Article{Hu2022,
  author   = {Hu, Dou and Chen, Jiacheng and Zhou, Haibo and Yu, Kai and Qian, Bo and Xu, Wenchao},
  journal  = {IEEE Transactions on Vehicular Technology},
  title    = {Leveraging Blockchain for Multi-Operator Access Sharing Management in Internet of Vehicles},
  year     = {2022},
  number   = {3},
  pages    = {2774-2787},
  volume   = {71},
  comment  = {提出一种基于区块链的无线服务提供商（WSP）协作框架，通过演化博弈的方式研究汽车的WSP选择问题（实现接入资源的去中心化管理）；提出DPoW，采用代表节点代表汽车完成区块链共识；采用ADMM优化算法优化共识协议参数。},
  doi      = {10.1109/TVT.2021.3136364},
  file     = {:2022Hu - Leveraging Blockchain for Multi Operator Access Sharing Management in Internet of Vehicles.pdf:PDF},
  groups   = {Optimization and Blockchain, Applications of Optimization, ML and BC, Applications of Optimization ML and BC},
  keywords = {Blockchains, Games, Base stations, Internet of Things, Optimization, Bandwidth, Vehicular ad hoc networks, Application, Wireless Network},
  ranking  = {rank4},
}

@InProceedings{Fu2021,
  author    = {Fu, Yangqing and Wong, Pooi-Mun and Chui, Chee-Kong},
  booktitle = {2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  title     = {Smart Contract with Machine Learning for Multi-objective Optimization in Manufacturing Quality Control},
  year      = {2021},
  pages     = {380-385},
  comment   = {提出一种用于生产质量控制的智能合约系统，采用随机森林算法解决生产中的多目标优化问题。智能合约保护优化算法和数据，对机器学习算法的结果打分来决定节点的选择，达成共识。（机器学习算法与智能合约如何协作？）},
  doi       = {10.1109/SMC52423.2021.9658776},
  file      = {:2021Fu - Smart Contract with Machine Learning for Multi Objective Optimization in Manufacturing Quality Control.pdf:PDF},
  groups    = {ML and Blockchain, Optimization and Blockchain, Applications of Optimization ML and BC},
  keywords  = {Machine learning algorithms, Smart contracts, Quality control, Production, Machine learning, Manufacturing, Blockchains, Optimization},
  ranking   = {rank1},
}

@Article{AbirELAzzaoui2021,
  author   = {Abir EL Azzaoui, Tae Woo Kim, Yi Pan, and Jong Hyuk Park},
  journal  = {Human-centric Computing and Information Sciences},
  title    = {A Quantum Approximate Optimization Algorithm Based on Blockchain Heuristic Approach for Scalable and Secure Smart Logistics Systems},
  year     = {2021},
  number   = {46},
  volume   = {11},
  comment  = {提出一种基于区块链改进的Quantum approximate optimization algorithm来改善智能运输系统的可扩展性并降低成本。},
  doi      = {10.22967/HCIS.2021.11.046},
  file     = {:2021Abir EL Azzaoui - A Quantum Approximate Optimization Algorithm Based on Blockchain Heuristic Approach for Scalable and Secure Smart Logistics Systems.pdf:PDF},
  groups   = {Optimization and Blockchain},
  keywords = {Quantum Approximate Optimization Algorithm, Blockchain, Smart Logistics, Supply Chain, Smart Transportation, Application},
  ranking  = {rank2},
  url      = {http://hcisj.com/articles/?HCIS202111046},
}

@Article{Liu2018,
  author   = {Liu, Mengting and Yu, F. Richard and Teng, Yinglei and Leung, Victor C. M. and Song, Mei},
  journal  = {IEEE Transactions on Vehicular Technology},
  title    = {Computation Offloading and Content Caching in Wireless Blockchain Networks With Mobile Edge Computing},
  year     = {2018},
  number   = {11},
  pages    = {11008-11021},
  volume   = {67},
  comment  = {提出一种基于移动边缘计算MEC的无线区块链框架，将计算密集的挖矿操作转移至附近的边缘计算节点，并且将区块链哈希数据缓存在MEC服务器上，从而在移动设备上节省计算与存储资源。作者对这种框架进行性能分析并提出基于ADMM的算法来改善这一框架的效率与可行性。},
  doi      = {10.1109/TVT.2018.2866365},
  file     = {:2018Liu - Computation Offloading and Content Caching in Wireless Blockchain Networks with Mobile Edge Computing.pdf:PDF},
  groups   = {Optimization and Blockchain, ML and Blockchain},
  keywords = {Task analysis, Computational modeling, Device-to-device communication, Wireless communication, Servers, Edge computing, Wireless Network, Application, Blockchain, Optimization},
  ranking  = {rank2},
}

@Article{Xiong2018,
  author   = {Xiong, Zehui and Zhang, Yang and Niyato, Dusit and Wang, Ping and Han, Zhu},
  journal  = {IEEE Communications Magazine},
  title    = {When Mobile Blockchain Meets Edge Computing},
  year     = {2018},
  number   = {8},
  pages    = {33-39},
  volume   = {56},
  doi      = {10.1109/MCOM.2018.1701095},
  file     = {:2018Xiong - When Mobile Blockchain Meets Edge Computing.pdf:PDF},
  groups   = {Blockchain Surveys},
  keywords = {Edge computing, Cloud computing, Data mining, Bitcoin, Servers, Heterogeneous networks, Internet of Things, Multiaccess communication, Blockchain, Wireless Network},
  ranking  = {rank2},
}

@InProceedings{Zuo2020,
  author    = {Zuo, Yiping and Zhang, Shengli and Han, Yu and Jin, Shi},
  booktitle = {2020 IEEE/CIC International Conference on Communications in China (ICCC)},
  title     = {Computation Resource Allocation in Mobile Blockchain-enabled Edge Computing Networks},
  year      = {2020},
  pages     = {617-622},
  comment   = {提出一种 Hash computing ordering机制，将移动边缘计算服务器上的资源可信、公平地进行分配，并提出交替优化算法实现哈希计算需求地最佳随机数选择策略（？）。},
  doi       = {10.1109/ICCC49849.2020.9238904},
  file      = {:2020Zuo - Computation Resource Allocation in Mobile Blockchain Enabled Edge Computing Networks.pdf:PDF},
  groups    = {Optimization and Blockchain},
  keywords  = {Games, Stability analysis, Servers, Resource management, Task analysis, Optimization, Edge computing, Wireless Network},
  ranking   = {rank3},
}

@Article{Du2021,
  author   = {Du, Jianbo and Sun, Yan and Sun, Aijing and Lu, Guangyue and Chang, Zhixian and Cao, Haotong and Feng, Jie},
  journal  = {Security and Communication Networks},
  title    = {Cost-Effective Optimization for Blockchain-Enabled NOMA-Based MEC Networks},
  year     = {2021},
  month    = {07},
  pages    = {1-9},
  volume   = {2021},
  comment  = {提出一种，基于NOMA、采用移动边缘计算技术的区块链框架，采用一种最小化系统成本的低复杂度算法，对算力分配、用户集群、准入控制等进行联合优化。},
  doi      = {10.1155/2021/8259817},
  file     = {:202107Du - Cost Effective Optimization for Blockchain Enabled NOMA Based MEC Networks.pdf:PDF},
  groups   = {Applications of Optimization ML and BC},
  keywords = {Blockchain, Mobile Edge Computing, Wireless Network, Optimization},
  ranking  = {rank3},
}

@Article{Nguyen2020,
  author   = {Dinh C. Nguyen and Pubudu N. Pathirana and Ming Ding and Aruna Seneviratne},
  journal  = {Journal of Network and Computer Applications},
  title    = {Blockchain for 5G and beyond networks: A state of the art survey},
  year     = {2020},
  issn     = {1084-8045},
  pages    = {102693},
  volume   = {166},
  abstract = {The fifth generation (5G) wireless networks are on the way to be deployed around the world. The 5G technologies target to support diverse vertical applications by connecting heterogeneous devices and machines with drastic improvements in terms of high quality of service, increased network capacity and enhanced system throughput. However, 5G systems still remain a number of security challenges that have been mentioned by researchers and organizations, including decentralization, transparency, risks of data interoperability, and network privacy vulnerabilities. Furthermore, the conventional techniques may not be sufficient to deal with the security requirements of 5G. As 5G is generally deployed in heterogeneous networks with massive ubiquitous devices, it is quite necessary to provide secure and decentralized solutions. Motivated from these facts, in this paper we provide a state-of-the-art survey on the integration of blockchain with 5G networks and beyond. In this detailed survey, our primary focus is on the extensive discussions on the potential of blockchain for enabling key 5G technologies, including cloud computing, edge computing, Network Function Virtualization, Network Slicing, and D2D communications. We then explore and analyse the opportunities that blockchain potentially empowers important 5G services, ranging from spectrum management, data sharing, network virtualization, resource management to interference management, federated learning, privacy and security provision. The recent advances in the applications of blockchain in 5G Internet of Things are also surveyed in a wide range of popular use-case domains, such as smart healthcare, smart city, smart transportation, smart grid and UAVs. The main findings derived from the comprehensive survey on the cooperated blockchain-5G networks and services are then summarized, and possible research challenges with open issues are also identified. Lastly, we complete this survey by shedding new light on future directions of research on this newly emerging area.},
  comment  = {一篇关于5G移动通信系统与区块链的综述。},
  doi      = {10.1016/j.jnca.2020.102693},
  file     = {:2020Nguyen - Blockchain for 5G and beyond Networks_ a State of the Art Survey.pdf:PDF},
  groups   = {Blockchain Surveys},
  keywords = {5G networks, Blockchain, 5G Internet of Things, 5G services, Machine learning, Security and privacy, Wireless Network},
  ranking  = {rank3},
  url      = {https://www.sciencedirect.com/science/article/pii/S1084804520301673},
}

@InProceedings{Cui2019,
  author    = {Cui, Huan and Chen, Zhiyong and Liu, Ning and Xia, Bin},
  booktitle = {2019 IEEE International Conference on Communications Workshops (ICC Workshops)},
  title     = {Blockchain-Driven Contents Sharing Strategy for Wireless Cache-Enabled D2D Networks},
  year      = {2019},
  pages     = {1-5},
  comment   = {提出一种区块链激励机制，基站分配部分算力来挖矿并把挖矿的收益分配给通过D2D通信分享内容的移动设备。作者借助凸规划开发了一种 caching placement scheme来最大化（内容分享收益-计算资源成本)。},
  doi       = {10.1109/ICCW.2019.8757177},
  file      = {:2019Cui - Blockchain Driven Contents Sharing Strategy for Wireless Cache Enabled D2D Networks.pdf:PDF},
  groups    = {Optimization and Blockchain},
  keywords  = {Device-to-device communication, Blockchain, Mobile handsets, Wireless communication, Edge computing, Servers, Data mining, Convex Optimization, Wireless Network},
  ranking   = {rank4},
}

@Article{Guo2020,
  author   = {Guo, Shaoyong and Hu, Xing and Guo, Song and Qiu, Xuesong and Qi, Feng},
  journal  = {IEEE Transactions on Industrial Informatics},
  title    = {Blockchain Meets Edge Computing: A Distributed and Trusted Authentication System},
  year     = {2020},
  number   = {3},
  pages    = {1972-1983},
  volume   = {16},
  comment  = {提出一种基于区块链和边缘计算技术的分布式、可行认证系统，通过边缘计算提高认证效率。},
  doi      = {10.1109/TII.2019.2938001},
  file     = {:2020Guo - Blockchain Meets Edge Computing_ a Distributed and Trusted Authentication System.pdf:PDF},
  groups   = {Applications of Optimization ML and BC},
  keywords = {Blockchain, Authentication, Edge computing, Peer-to-peer computing, Cloud computing, Internet of Things, Wireless Network},
  ranking  = {rank4},
}

@Article{Cao2020,
  author   = {Cao, Bin and Wang, Xuesong and Zhang, Weizheng and Song, Houbing and Lv, Zhihan},
  journal  = {IEEE Network},
  title    = {A Many-Objective Optimization Model of Industrial Internet of Things Based on Private Blockchain},
  year     = {2020},
  number   = {5},
  pages    = {78-83},
  volume   = {34},
  comment  = {采用改进的Two_Arch2算法来针对私有链的可扩展性、去中心化程度、时延以及成本进行多目标优化。},
  doi      = {10.1109/MNET.011.1900536},
  file     = {:2020Cao - A Many Objective Optimization Model of Industrial Internet of Things Based on Private Blockchain.pdf:PDF},
  groups   = {Optimization and Blockchain},
  keywords = {Blockchain, Scalability, Security, Internet of Things, Optimization, Industrial facilities},
  ranking  = {rank3},
}

@Article{Hassija2022,
  author   = {Vikas Hassija and Rahul Ratnakumar and Vinay Chamola and Soumya Agarwal and Aryan Mehra and Salil S. Kanhere and Huynh Thi Thanh Binh},
  journal  = {Sustainable Computing: Informatics and Systems},
  title    = {A machine learning and blockchain based secure and cost-effective framework for minor medical consultations},
  year     = {2022},
  issn     = {2210-5379},
  pages    = {100651},
  volume   = {35},
  abstract = {With the ever-increasing awareness among people regarding their health, visiting a doctor has become quite common. However, with the onset of the COVID-19 pandemic, home-based consultations are gaining popularity. Nevertheless, the worries over privacy and the lack of willingness to assist patients by the medical professionals in the online consultation process have made current models ineffective. In this paper, we present an advanced protected blockchain-based consultation model for minor medical conditions. Our model not only ensures users’ privacy but by incorporating a calculation model, it also offers an opportunity for consulting end-users to voluntarily take part in the consultation process. Our work proposes a smart contract based on machine learning to be implemented for the prediction of a score of a professional who consults based on various prioritized parameters. This is done by using word2vec and TF-IDF weighting to classify the question and cosine similarity scores for detailed orientation analysis. Based on this score, the patient is charged, and simultaneously, the responder is awarded ether. An incentivized method leads to more accessible healthcare while reducing the cost itself.},
  comment  = {提出一种基于区块链的轻症病人咨询框架。},
  doi      = {10.1016/j.suscom.2021.100651},
  file     = {:2022Hassija - A Machine Learning and Blockchain Based Secure and Cost Effective Framework for Minor Medical Consultations.pdf:PDF},
  groups   = {Applications of Optimization ML and BC},
  keywords = {Machine learning, NLP, Naive Bayes, Logistic regression, Minor consultations, Ethereum, Blockchain, Application},
  ranking  = {rank3},
  url      = {https://www.sciencedirect.com/science/article/pii/S2210537921001347},
}

@Article{Tahir2020,
  author   = {Tahir, Mohammad and Habaebi, Mohamed Hadi and Dabbagh, Mohammad and Mughees, Amna and Ahad, Abdul and Ahmed, Kazi Istiaque},
  journal  = {IEEE Access},
  title    = {A Review on Application of Blockchain in 5G and Beyond Networks: Taxonomy, Field-Trials, Challenges and Opportunities},
  year     = {2020},
  pages    = {115876-115904},
  volume   = {8},
  comment  = {一篇关于5G移动通信系统与区块链的综述。},
  doi      = {10.1109/ACCESS.2020.3003020},
  file     = {:2020Tahir - A Review on Application of Blockchain in 5G and beyond Networks_ Taxonomy, Field Trials, Challenges and Opportunities.pdf:PDF},
  groups   = {Blockchain Surveys},
  keywords = {5G mobile communication, Blockchain, Security, Cloud computing, Computer architecture, Throughput, Reliability},
  ranking  = {rank2},
}

@Article{Dai2019,
  author   = {Dai, Hong-Ning and Zheng, Zibin and Zhang, Yan},
  journal  = {IEEE Internet of Things Journal},
  title    = {Blockchain for Internet of Things: A Survey},
  year     = {2019},
  number   = {5},
  pages    = {8076-8094},
  volume   = {6},
  comment  = {有关区块链与物联网的综述。},
  doi      = {10.1109/JIOT.2019.2920987},
  file     = {:2019Dai - Blockchain for Internet of Things_ a Survey.pdf:PDF},
  groups   = {Blockchain Surveys},
  keywords = {Blockchain, Internet of Things, Security, Interoperability, Industries, Privacy, Intelligent sensors},
  ranking  = {rank3},
}

@Article{Jiang2020,
  author   = {Jiang, Xiantao and Yu, F. Richard and Song, Tian and Ma, Zhaowei and Song, Yanxing and Zhu, Daqi},
  journal  = {IEEE Internet of Things Journal},
  title    = {Blockchain-Enabled Cross-Domain Object Detection for Autonomous Driving: A Model Sharing Approach},
  year     = {2020},
  number   = {5},
  pages    = {3681-3692},
  volume   = {7},
  comment  = {提出一种新的机器学习模型共享方法。该方法基于区块链与移动边缘计算，用以改善自动驾驶系统的跨域目标识别性能。},
  doi      = {10.1109/JIOT.2020.2967788},
  file     = {:2020Jiang - Blockchain Enabled Cross Domain Object Detection for Autonomous Driving_ a Model Sharing Approach.pdf:PDF},
  groups   = {Applications of Optimization ML and BC},
  keywords = {Object detection, Blockchain, Adaptation models, Computational modeling, Autonomous vehicles, Training, Reliability, Machine Learning, Application},
  ranking  = {rank3},
}

@Article{Fu2020,
  author   = {Fu, Yuchuan and Yu, Fei Richard and Li, Changle and Luan, Tom H. and Zhang, Yao},
  journal  = {IEEE Wireless Communications},
  title    = {Vehicular Blockchain-Based Collective Learning for Connected and Autonomous Vehicles},
  year     = {2020},
  number   = {2},
  pages    = {197-203},
  volume   = {27},
  comment  = {提出基于区块链的集体学习框架，使互联自动驾驶汽车本地训练模型并上传从而利用这些汽车的“集体智能”。},
  doi      = {10.1109/MNET.001.1900310},
  file     = {:2020Fu - Vehicular Blockchain Based Collective Learning for Connected and Autonomous Vehicles.pdf:PDF},
  groups   = {Applications of Optimization ML and BC},
  keywords = {Data models, Computational modeling, Servers, Data privacy, Machine learning, Application},
  ranking  = {rank2},
}

@Article{Ning2021,
  author   = {Zhaolong Ning and Shouming Sun and Xiaojie Wang and Lei Guo and Song Guo and Xiping Hu and Bin Hu and Ricky Y. K. Kwok},
  journal  = {IEEE Transactions on Mobile Computing},
  title    = {Blockchain-Enabled Intelligent Transportation Systems: A Distributed Crowdsensing Framework},
  year     = {2021},
  pages    = {4201-4217},
  volume   = {21},
  comment  = {提出一个基于区块链的群体感知框架，保证智能交通系统能够安全高效运作。作者根据提出的系统模型构建了一个多目标问题并将其拆分成两个问题分别用基于强化学习的算法与DIADEM算法解决，从而实现更高的系统安全性与更低的延迟。},
  doi      = {10.1109/tmc.2021.3079984},
  file     = {:2021Ning - Blockchain Enabled Intelligent Transportation Systems_ a Distributed Crowdsensing Framework.pdf:PDF},
  groups   = {Applications of Optimization ML and BC},
  keywords = {Distributed traffic management, blockchain, deep reinforcement learning, vehicular crowdsensing, multi-objective optimization, machine learning},
  ranking  = {rank4},
}

@Article{Zuo2021,
  author   = {Zuo, Yiping and Jin, Shi and Zhang, Shengli and Zhang, Yan},
  journal  = {IEEE Internet of Things Journal},
  title    = {Blockchain Storage and Computation Offloading for Cooperative Mobile-Edge Computing},
  year     = {2021},
  number   = {11},
  pages    = {9084-9098},
  volume   = {8},
  comment  = {作者主要研究移动边缘计算辅助下的区块链系统中计算量分担、块存储、与资源服务定价问题。作者将这三个问题放入一个三阶段Stackelberg博弈问题中考虑，并分析每个阶段的优化问题，提出一种基于反向诱导的迭代算法，实现Stackelberg博弈的纳什均衡。},
  doi      = {10.1109/JIOT.2021.3056656},
  file     = {:2021Zuo - Blockchain Storage and Computation Offloading for Cooperative Mobile Edge Computing.pdf:PDF},
  groups   = {Optimization and Blockchain},
  keywords = {Blockchain, Stackelberg Game, Task analysis, Computational modeling, Servers, Internet of Things, Data mining, Optimization, Wireless Network},
  ranking  = {rank3},
}

@Article{Nguyen2021,
  author   = {Nguyen, Dinh and Ding, Ming and Pathirana, Pubudu and Seneviratne, Aruna and Li, Jun and Poor, Vincent},
  journal  = {IEEE Transactions on Mobile Computing},
  title    = {Cooperative Task Offloading and Block Mining in Blockchain-based Edge Computing with Multi-agent Deep Reinforcement Learning},
  year     = {2021},
  pages    = {1-1},
  doi      = {10.1109/TMC.2021.3120050},
  file     = {:2021Nguyen - Cooperative Task Offloading and Block Mining in Blockchain Based Edge Computing with Multi Agent Deep Reinforcement Learning.pdf:PDF},
  groups   = {ML and Blockchain},
  keywords = {Blockchain, mobile edge computing, task offloading, block mining, deep reinforcement learning, machine learning},
  ranking  = {rank2},
}

@Article{Cao2019,
  author   = {Cao, Bin and Li, Yixin and Zhang, Lei and Zhang, Long and Mumtaz, Shahid and Zhou, Zhenyu and Peng, Mugen},
  journal  = {IEEE Network},
  title    = {When Internet of Things Meets Blockchain: Challenges in Distributed Consensus},
  year     = {2019},
  number   = {6},
  pages    = {133-139},
  volume   = {33},
  comment  = {有关区块链与物联网的综述。},
  doi      = {10.1109/MNET.2019.1900002},
  file     = {:2019Cao - When Internet of Things Meets Blockchain_ Challenges in Distributed Consensus.pdf:PDF},
  groups   = {Blockchain Surveys},
  keywords = {Blockchain, Internet of Things, Supply chains, Peer-to-peer computing, Bitcoin, Telecommunications},
  ranking  = {rank3},
}

@Article{Lu2020,
  author   = {Lu, Yunlong and Huang, Xiaohong and Zhang, Ke and Maharjan, Sabita and Zhang, Yan},
  journal  = {IEEE Transactions on Vehicular Technology},
  title    = {Blockchain Empowered Asynchronous Federated Learning for Secure Data Sharing in Internet of Vehicles},
  year     = {2020},
  number   = {4},
  pages    = {4298-4311},
  volume   = {69},
  comment  = {提出一种基于联邦学习的新区块链架构，在车联网中实现更低的传输负载并解决隐私问题。对于节点选择问题采用深度强化学习机制来提升异步联邦学习的效率。},
  doi      = {10.1109/TVT.2020.2973651},
  file     = {:2020Lu - Blockchain Empowered Asynchronous Federated Learning for Secure Data Sharing in Internet of Vehicles.pdf:PDF},
  groups   = {FL and Blockchain, Applications of Optimization ML and BC},
  keywords = {Data sharing, Blockchain, Asynchronous federated learning, Deep reinforcement learning, Internet of Vehicles, Machine Learning, Wireless Network},
  priority = {prio1},
  ranking  = {rank5},
}

@Article{Qiu2021,
  author   = {Qiu, Chao and Wang, Xiaofei and Yao, Haipeng and Du, Jianbo and Yu, F. Richard and Guo, Song},
  journal  = {IEEE Internet Things J.},
  title    = {Networking Integrated Cloud–Edge–End in {IoT}: A Blockchain-Assisted Collective {Q}-Learning Approach},
  year     = {2021},
  month    = aug,
  number   = {16},
  pages    = {12694-12704},
  volume   = {8},
  comment  = {本文提出了一种基于区块链的集体Q学习方法，在边缘物联网节点上通过学习智能。轻量节点上训练部分学习层并通过区块链共享学习结果。
collaborative Q-learning: integrate deep Q-learning with blockchain
propose a novel proof of learning consensus mechanism that selects the IoT node that reduces the learning loss function to the greatest extent.},
  doi      = {10.1109/JIOT.2020.3007650},
  file     = {:2021Qiu - Networking Integrated Cloud–Edge–End in IoT_ a Blockchain Assisted Collective Q Learning Approach.pdf:PDF},
  groups   = {RL and Blockchain},
  keywords = {Internet of Things, Blockchain, Training, Computational modeling, Cloud computing, Machine learning, Resource management},
  ranking  = {rank5},
}

@Article{Qu2021,
  author     = {Qu, Xidi and Wang, Shengling and Hu, Qin and Cheng, Xiuzhen},
  journal    = {IEEE Trans. Parallel Distrib. Syst.},
  title      = {Proof of Federated Learning: A Novel Energy-Recycling Consensus Algorithm},
  year       = {2021},
  month      = aug,
  number     = {8},
  pages      = {2074--2085},
  volume     = {32},
  comment    = {提出Proof of Federated Learning(PoFL)，将原本用于工作量证明的算力重新投入到联邦学习中。 作者仿照PoW矿池设计了一种联邦挖矿机制，矿池成员各自基于私有数据训练机器学习模型，由矿池管理员聚合这些模型。矿池管理员在计算正确率之后打包区块。全节点验证这些块并从中选出正确率最高的作为获胜矿池。获胜矿池将模型发送给requester并获得奖励。 PoFL所面临的最大问题是隐私数据所有权与使用权的分离可能在模型训练与验证过程中造成隐私泄露，偏离了联邦学习的初衷。隐私泄露一般在两种情况下发生：数据提供者向矿池提供数据时以及requester与矿池分享测试数据时以及计算正确率时。作者设计了一种基于博弈的反向数据追踪机制以及隐私保护模型验证机制分别应对这两种情况。 基于博弈的反向数据追踪机制中设计了一种价格机制将矿池交易数据的概率以及购买价格与矿池的私有信息以及声誉挂钩。隐私保护模型验证机制中包含基于同态加密的标签预测机制以及基于多方安全计算的标签比较机制。文中通过大量仿真展现了PoFL的效率与有效性。},
  doi        = {10.1109/TPDS.2021.3056773},
  file       = {:2021Qu - Proof of Federated Learning_ a Novel Energy Recycling Consensus Algorithm.pdf:PDF},
  groups     = {FL and Blockchain},
  keywords   = {Blockchain, Collaborative work, federated learning, consensus algorithm, incentive mechanism, machine learning},
  priority   = {prio2},
  ranking    = {rank5},
  readstatus = {skimmed},
}

@InProceedings{Chenli2020,
  author    = {Chenli, Changhao and Li, Boyang and Jung, Taeho},
  booktitle = {Proc. 16th IEEE World Cong. Services (SERVICES'20)},
  title     = {{DLchain}: Blockchain with Deep Learning as Proof-of-Useful-Work},
  year      = {2020},
  address   = {Honolulu, HI, USA},
  month     = sep,
  pages     = {43--60},
  abstract  = {Blockchains based on Proof-of-Work can maintain a distributed ledger with a high security guarantee but also lead to severe energy waste due to the useless hash calculation. Proof-of-Useful-Work (PoUW) mechanisms are alternatives, but finding hard puzzles with easy verification and useful results is challenging. Recent popular deep learning algorithms require large amount of computation resources due to the large-scale training datasets and the complexity of the models. The work of deep learning training is useful, and the model verification process is much shorter than its training process. Therefore, in this paper, we propose DLchain, a PoUW-based blockchain using deep learning training as the hard puzzle. Theoretical analysis shows that DLchain can achieve a security level comparable to existing PoW-based cryptocurrency when the miners' best interest is to maximize their revenue. Notably, this is achieved without relying on common assumptions made in existing PoUW-based blockchain such as globally synchronized timestamps. Simulated experiments also show that the extra network delay caused by data transfer and the full nodes' validation is acceptable.},
  comment   = {提出新的共识机制DLChain，利用区块链的分布式计算资源改善模型训练精度。此机制的DL训练过程与其他采用DL的PoUW共识机制不同，不需要全局同步的时间戳等其他优点。（与其他同类机制的具体区别?）

DlchainHybrid chain with permissioned part used to publish tasks and permissionless part implements PoUW consensus.

compared with [Chenli2019], testset based two-stage verification scheme is forgone because it requires  globally synchronized timestamp and .},
  doi       = {10.1007/978-3-030-59595-1_4},
  file      = {:2020Chenli - DLchain_ Blockchain with Deep Learning As Proof of Useful Work.pdf:PDF},
  groups    = {ML and Blockchain},
  isbn      = {978-3-030-59595-1},
  keywords  = {Blockchain, Consensus, Machine Learning, Deep Learning},
  priority  = {prio3},
  ranking   = {rank3},
}

@Article{Qu2022,
  author     = {Qu, Youyang and Uddin, Md Palash and Gan, Chenquan and Xiang, Yong and Gao, Longxiang and Yearwood, John},
  journal    = {ACM Computing Surveys},
  title      = {Blockchain-Enabled Federated Learning: A Survey},
  year       = {2022},
  issn       = {0360-0300},
  month      = {nov},
  number     = {4},
  volume     = {55},
  abstract   = {Federated learning (FL) has experienced a boom in recent years, which is jointly promoted by the prosperity of machine learning and Artificial Intelligence along with emerging privacy issues. In the FL paradigm, a central server and local end devices maintain the same model by exchanging model updates instead of raw data, with which the privacy of data stored on end devices is not directly revealed. In this way, the privacy violation caused by the growing collection of sensitive data can be mitigated. However, the performance of FL with a central server is reaching a bottleneck, while new threats are emerging simultaneously. There are various reasons, among which the most significant ones are centralized processing, data falsification, and lack of incentives. To accelerate the proliferation of FL, blockchain-enabled FL has attracted substantial attention from both academia and industry. A considerable number of novel solutions are devised to meet the emerging demands of diverse scenarios. Blockchain-enabled FL provides both theories and techniques to improve the performance of FL from various perspectives. In this survey, we will comprehensively summarize and evaluate existing variants of blockchain-enabled FL, identify the emerging challenges, and propose potentially promising research directions in this under-explored domain.},
  address    = {New York, NY, USA},
  articleno  = {70},
  comment    = {区块链赋能联邦学习。},
  doi        = {10.1145/3524104},
  file       = {:2022novQu - Blockchain Enabled Federated Learning_ a Survey.pdf:PDF},
  groups     = {FL and Blockchain},
  issue_date = {April 2023},
  keywords   = {blockchain, countermeasures, Federated learning, attacks, Machine Learning},
  numpages   = {35},
  publisher  = {Association for Computing Machinery},
  ranking    = {rank4},
}

@InProceedings{Chenli2019,
  author     = {Changhao Chenli and Boyang Li and Yiyu Shi and Taeho Jung},
  booktitle  = {Proc. 2019 IEEE Int. Conf. Blockchain Cryptocurrency (ICBC)},
  title      = {Energy-recycling Blockchain with Proof-of-Deep-Learning},
  year       = {2019},
  address    = {Seoul, KR},
  month      = may,
  pages      = {19-23},
  comment    = {提出Proof-of-Deep-Learning共识机制，当且仅当适当的深度学习模型产生时才产生新区块，与当前流行的PoW共识机制兼容。
与Proof-of-Learning类似，将共识的形成分为两个阶段，第一个阶段model requester发布训练集，矿工在训练完成之后上传包含模型哈希的区块头；第二阶段model requester发布测试集，full node根据区块头下载模型、验证模型哈希是否与矿工匹配、根据矿工提供的超参数/初始权重/轮次数复现模型以验证矿工是否将算力用于训练（个人认为没有必要）、计算模型在测试集上的性能指标、对矿工的性能进行排序。
为了解决区块间隔短、模型正确率不够高（会导致区块链的不可修改性降低，更容易遭受双花攻击）的问题，作者提出发布测试集可以延迟到数个区块产生、模型正确率不再显著增加之后，这种方案使得前一区块的阶段二可以与之后区块的阶段一重叠。文章似乎没有描述full nodes之间如何取得共识。},
  doi        = {10.1109/BLOC.2019.8751419},
  file       = {:2019Chenli - Energy Recycling Blockchain with Proof of Deep Learning.pdf:PDF},
  groups     = {ML and Blockchain},
  keywords   = {Blockchain, Sustainability, Deep Learning, Machine Learning},
  ranking    = {rank2},
  readstatus = {read},
}

@Article{Li2021,
  author   = {Li, Yuzheng and Chen, Chuan and Liu, Nan and Huang, Huawei and Zheng, Zibin and Yan, Qiang},
  journal  = {IEEE Network},
  title    = {A Blockchain-Based Decentralized Federated Learning Framework with Committee Consensus},
  year     = {2021},
  month    = {Jan./Feb.},
  number   = {1},
  pages    = {234-241},
  volume   = {35},
  comment  = {The blockchain-based federated learning framework with committee consensus [Li2021] mitigates the impact of malicious clients and central server with a committee consensus mechanism.

提出基于区块链的委员会共识联邦学习框架（Blockchain-based Federated Learning framework with Committee consensus, BFLC）以解决基于区块链的联邦学习的安全问题，通过委员会共识避免恶意中心服务器与节点的影响。
Blockchain structure: composed of update blocks and model blocks. k consecutive blocks accomodates parameter updates during a training round: parameter updates stored in update blocks and the aggregated global model stored in model block. Smart contract is used when aggregating the global model.
Commited is elected at the end of each training round, with three options: random selection, selection based on scores and multi-optimized selection. Models updates are validated by the elected committe},
  doi      = {10.1109/MNET.011.2000263},
  file     = {:2021Li - A Blockchain Based Decentralized Federated Learning Framework with Committee Consensus.pdf:PDF},
  groups   = {FL and Blockchain},
  keywords = {blockchain, convolutional neural nets, data privacy, optimization, storage management, federated learning, machine learning, Consensus},
  ranking  = {rank3},
}

@InProceedings{Abhiroop2022,
  author    = {{T.}, Abhiroop and Babu, Sarath and Manoj, {B.} {S.}},
  booktitle = {2022 14th International Conference on COMmunication Systems \& NETworkS (COMSNETS)},
  title     = {A Machine Learning Consensus Based Light-Weight Blockchain Architecture for Internet of Things},
  year      = {2022},
  pages     = {1-6},
  comment   = {本文为资源受限的边缘设备提出一种基于机器学习共识的轻量区块链系统，通过使用机器学习算法对物联网传感数据进行分类，判断其是否为真实数据，根据模型的预测结果来形成共识、产生新区块。},
  doi       = {10.1109/COMSNETS53615.2022.9668487},
  file      = {:2022Abhiroop - A Machine Learning Consensus Based Light Weight Blockchain Architecture for Internet of Things.pdf:PDF},
  groups    = {ML and Blockchain},
  keywords  = {Internet of Things (IoT), blockchain, distributednetworks, consensus, machine learning},
}

@Article{li2020dlbc,
  author       = {Boyang Li and Changhao Chenli and Xiaowei Xu and Yiyu Shi and Taeho Jung},
  journal      = {arXiv preprint arXiv:1904.07349},
  title        = {{DLBC}: A Deep Learning-Based Consensus in Blockchains for Deep Learning Services},
  year         = {2020},
  month        = jan,
  comment      = {提出DLBC共识机制，主要采用生物医学图像分片模型训练代替哈希运算。此机制能同时处理多个任务，实现了根据任务难度的评级机制，并应用DNN水印改善鲁棒性。

DNN水印原理：https://yangleisx.github.io/post/paper-uchida/},
  eprint       = {1904.07349},
  eprinttype   = {arxiv},
  file         = {:2020Li - DLBC_ a Deep Learning Based Consensus in Blockchains for Deep Learning Services.pdf:PDF},
  groups       = {ML and Blockchain},
  keywords     = {Blockchain, Deep Learning, Machine Learning, Consensus, Proof-of-Useful-Work},
  primaryclass = {cs.DC},
  ranking      = {rank2},
  readstatus   = {skimmed},
}

@Misc{ma2022hdcoin,
  author       = {Dongning Ma and Sizhe Zhang and Xun Jiao},
  title        = {HDCoin: A Proof-of-Useful-Work Based Blockchain for Hyperdimensional Computing},
  year         = {2022},
  comment      = {文章中提出HDCoin共识机制，将大脑启发式的超维运算(HDC)任务应用到区块链挖矿机制中，矿工之间通过比较模型测试准确率进行竞争，获胜矿工的模型会记录在链上，通过不同的HDC问题配置来实现难度自适应调整。},
  eprint       = {2202.02964},
  eprinttype   = {arxiv},
  file         = {:2022Ma - HDCoin_ a Proof of Useful Work Based Blockchain for Hyperdimensional Computing.pdf:PDF},
  groups       = {ML and Blockchain},
  keywords     = {Blockchain, Proof of Useful work, Machine Learning},
  primaryclass = {cs.CR},
  ranking      = {rank2},
}

@Article{LI2022100089,
  author     = {Boyang Li and Qing Lu and Weiwen Jiang and Taeho Jung and Yiyu Shi},
  journal    = {Blockchain: Res. Appl.},
  title      = {A collaboration strategy in the mining pool for proof-of-neural-architecture consensus},
  year       = {2022},
  issn       = {2096-7209},
  month      = dec,
  number     = {4},
  pages      = {100089},
  volume     = {3},
  abstract   = {In most popular public accessible cryptocurrency systems, the mining pool plays a key role because mining cryptocurrency with the mining pool turns the non-profitable situation into profitable for individual miners. In many recent novel blockchain consensuses, the deep learning training procedure becomes the task for miners to prove their workload. Thus, the computation power of miners will not purely be spent on the hash puzzle. In this way, the hardware and energy will support the blockchain service and deep learning training simultaneously. While the incentive of miners is to earn tokens, individual miners are motivated to join mining pools to become more competitive. In this paper, we are the first to demonstrate a mining pool solution for novel consensuses based on deep learning. The mining pool manager partitions the full searching space into subspaces, and all miners are scheduled to collaborate on the Neural architecture search (NAS) tasks in the assigned subspace. Experiments demonstrate that the performance of this type of mining pool is more competitive than that of an individual miner. Due to the uncertainty of miners' behaviors, the mining pool manager checks the standard deviation of the performance of high reward miners and prepares backup miners to ensure completion of the tasks of high reward miners.},
  comment    = {为基于深度学习算法的PoUW共识机制提出一种相适应的矿池机制，将整个搜索空间分成几个子空间，并调度矿工在分配的空间中协作完成神经架构搜索(NAS)任务。
Boyang Li et al. proposed PoNAS, which uses Neural Architecture Searching(NAS) problems as the useful work and devised a mining pool based collaboration strategy to optimize task scheduling.},
  doi        = {10.1016/j.bcra.2022.100089},
  file       = {:2022Li - A Collaboration Strategy in the Mining Pool for Proof of Neural Architecture Consensus.pdf:PDF},
  groups     = {ML and Blockchain},
  keywords   = {Blockchain, Consensus, Deep learning, Mining pool, Neural architecture search (NAS), Blockchain, Consensus, Deep learning, Mining Pool, Neuralarchitecture search, Machine Learning},
  ranking    = {rank2},
  readstatus = {skimmed},
}

@Article{Kim2020,
  author   = {Kim, Hyesung and Park, Jihong and Bennis, Mehdi and Kim, Seong-Lyun},
  journal  = {IEEE Commun. Lett.},
  title    = {Blockchained On-Device Federated Learning},
  year     = {2020},
  month    = jun,
  number   = {6},
  pages    = {1279-1283},
  volume   = {24},
  comment  = {提出一种基于区块链的联邦学习架构BlockFL，通过这一架构可以交换、验证本地的学习模型，借助共识机制避免训练数据的中心化，并解决传统联邦学习架构中的单点失效问题。
blockchain store scores and models, accomplishing tamper-proof model exchange and validation.
the author build an end-to-end latency model adjusting block generation interval according to communication, computation, and PoW delays.},
  doi      = {10.1109/LCOMM.2019.2921755},
  file     = {:2020Kim - Blockchained on Device Federated Learning.pdf:PDF},
  groups   = {FL and Blockchain},
  keywords = {On-device machine learning, federated learning, blockchain, latency, Machine Learning},
  ranking  = {rank4},
}

@Article{Lu2020a,
  author   = {Lu, Yunlong and Huang, Xiaohong and Dai, Yueyue and Maharjan, Sabita and Zhang, Yan},
  journal  = {IEEE Trans. Ind. Inform.},
  title    = {Blockchain and Federated Learning for Privacy-Preserved Data Sharing in Industrial {IoT}},
  year     = {2020},
  month    = jun,
  number   = {6},
  pages    = {4177-4186},
  volume   = {16},
  comment  = {提出一种基于区块链的安全数据分享架构，将数据共享问题转化为联邦学习模型共享问题，再通过作者提出的训练质量证明机制(PoQ)将数据模型训练与共识机制结合，充分利用节点的算力并提升数据共享架构的效率。
committee consensus Proof-of-Quality
The committee leader is selected based on the quality of the
trained model.
consensus messages are shared among committee members.},
  doi      = {10.1109/TII.2019.2942190},
  file     = {:2020Lu - Blockchain and Federated Learning for Privacy Preserved Data Sharing in Industrial IoT.pdf:PDF},
  groups   = {FL and Blockchain},
  keywords = {Data sharing, federated learning, industrial Internet of Things (IIoT), permissioned blockchain, privacy-preserved, Machine Learning, Proof of Training Quality, Consensus},
  priority = {prio2},
  ranking  = {rank4},
}

@Article{Pokhrel2020,
  author   = {Pokhrel, Shiva Raj and Choi, Jinho},
  journal  = {IEEE Transactions on Communications},
  title    = {Federated Learning With Blockchain for Autonomous Vehicles: Analysis and Design Challenges},
  year     = {2020},
  number   = {8},
  pages    = {4734-4746},
  volume   = {68},
  comment  = {提出一种基于区块链的资质联邦学习系统，以分布式的方式将oVML模型的更新通过区块链交换、验证。对系统延时进行全面分析，同时考虑了通信、共识延迟，并给出最小化延时的优化算法。},
  doi      = {10.1109/TCOMM.2020.2990686},
  file     = {:2020Pokhrel - Federated Learning with Blockchain for Autonomous Vehicles_ Analysis and Design Challenges.pdf:PDF},
  groups   = {FL and Blockchain, Applications of Optimization ML and BC},
  keywords = {n-vehicle machine learning, federated learning, blockchain, delay analysis, consensus delay, low delay, application},
  priority = {prio3},
  ranking  = {rank5},
}

@Article{Qiu2019,
  author   = {Qiu, Xiaoyu and Liu, Luobin and Chen, Wuhui and Hong, Zicong and Zheng, Zibin},
  journal  = {IEEE Transactions on Vehicular Technology},
  title    = {Online Deep Reinforcement Learning for Computation Offloading in Blockchain-Empowered Mobile Edge Computing},
  year     = {2019},
  number   = {8},
  pages    = {8050-8062},
  volume   = {68},
  comment  = {提出一种新的基于深度强化学习的无模型的在线算力分担方法。作者先将算力分担问题转化成马尔可夫决策过程，同时考虑数据处理与挖矿任务。采用深度强化学习应对动态环境解决计算复杂性。最后通过自适应遗传算法在不影响性能的前提下加速收敛。},
  doi      = {10.1109/TVT.2019.2924015},
  file     = {:2019Qiu - Online Deep Reinforcement Learning for Computation Offloading in Blockchain Empowered Mobile Edge Computing.pdf:PDF},
  groups   = {RL and Blockchain},
  keywords = {Online computation offloading, blockchain, mobile edge computing, deep reinforcement learning, wireless network, Machine Learning, Genetic Algorithm},
  ranking  = {rank4},
}

@Article{Liu2019,
  author   = {Liu, Mengting and Yu, F. Richard and Teng, Yinglei and Leung, Victor C. M. and Song, Mei},
  journal  = {IEEE Transactions on Industrial Informatics},
  title    = {Performance Optimization for Blockchain-Enabled Industrial Internet of Things (IIoT) Systems: A Deep Reinforcement Learning Approach},
  year     = {2019},
  number   = {6},
  pages    = {3559-3570},
  volume   = {15},
  comment  = {针对区块链物联网应用，文章提出一种基于深度强化学习的性能优化框架，优化可扩展性并保证延迟、去中心化程度与安全性。此框架通过深度强化学习方法根据当前物联网环境选择区块生成者与共识协议(自适应共识协议)，并调整区块大小与区块间隔。},
  doi      = {10.1109/TII.2019.2897805},
  file     = {:2019Liu - Performance Optimization for Blockchain Enabled Industrial Internet of Things (IIoT) Systems_ a Deep Reinforcement Learning Approach.pdf:PDF},
  groups   = {RL and Blockchain},
  keywords = {Blockchain, deep reinforcement learning(DRL), industrial Internet of Things (IIoT), performance optimization, machine learning},
  ranking  = {rank2},
}

@Article{Feng2020,
  author   = {Feng, Jie and Richard Yu, F. and Pei, Qingqi and Chu, Xiaoli and Du, Jianbo and Zhu, Li},
  journal  = {IEEE Internet of Things Journal},
  title    = {Cooperative Computation Offloading and Resource Allocation for Blockchain-Enabled Mobile-Edge Computing: A Deep Reinforcement Learning Approach},
  year     = {2020},
  number   = {7},
  pages    = {6214-6228},
  volume   = {7},
  comment  = {提出一种算力分担与资源分配框架，设计了针对MEC系统计算速率和区块链交易吞吐量的多目标优化函数，将两者的联合优化建模为一个马尔可夫决策过程问题，通过设计演员-评论员算法对算力分担决策、资源分配、区块大小与区块间隔四个变量进行联合优化。},
  doi      = {10.1109/JIOT.2019.2961707},
  file     = {:2020Feng - Cooperative Computation Offloading and Resource Allocation for Blockchain Enabled Mobile Edge Computing_ a Deep Reinforcement Learning Approach.pdf:PDF},
  groups   = {RL and Blockchain},
  keywords = {Asynchronous advantage actor–critic (A3C), blockchain, computation offloading, mobile-edge computing(MEC), transaction throughput, wireless network, Machine learning, Blockchain},
  ranking  = {rank4},
}

@Article{He2021,
  author   = {He, Ying and Wang, Yuhang and Qiu, Chao and Lin, Qiuzhen and Li, Jianqiang and Ming, Zhong},
  journal  = {IEEE Internet of Things Journal},
  title    = {Blockchain-Based Edge Computing Resource Allocation in IoT: A Deep Reinforcement Learning Approach},
  year     = {2021},
  number   = {4},
  pages    = {2226-2237},
  volume   = {8},
  comment  = {提出一种基于区块链、采用边缘计算的物联网通用框架，并在这一框架的基础上采用A3C演员-评论员算法解决边缘计算资源分配问题。},
  doi      = {10.1109/JIOT.2020.3035437},
  file     = {:2021He - Blockchain Based Edge Computing Resource Allocation in IoT_ a Deep Reinforcement Learning Approach.pdf:PDF},
  groups   = {RL and Blockchain},
  keywords = {Asynchronous advantage actor–critic (A3C)algorithm, blockchain, edge-centric computing, Internet ofThings (IoT), Machine learning},
  ranking  = {rank4},
}

@Article{Chawla2003,
  author   = {Nitesh V Chawla and Thomas E Moore and Lawrence O Hall and Kevin W Bowyer and W.Philip Kegelmeyer and Clayton Springer},
  journal  = {Pattern Recognition Letters},
  title    = {Distributed learning with bagging-like performance},
  year     = {2003},
  issn     = {0167-8655},
  number   = {1},
  pages    = {455-471},
  volume   = {24},
  abstract = {Bagging forms a committee of classifiers by bootstrap aggregation of training sets from a pool of training data. A simple alternative to bagging is to partition the data into disjoint subsets. Experiments with decision tree and neural network classifiers on various datasets show that, given the same size partitions and bags, disjoint partitions result in performance equivalent to, or better than, bootstrap aggregates (bags). Many applications (e.g., protein structure prediction) involve use of datasets that are too large to handle in the memory of the typical computer. Hence, bagging with samples the size of the data is impractical. Our results indicate that, in such applications, the simple approach of creating a committee of n classifiers from disjoint partitions each of size 1/n (which will be memory resident during learning) in a distributed way results in a classifier which has a bagging-like performance gain. The use of distributed disjoint partitions in learning is significantly less complex and faster than bagging.},
  comment  = {通过实验得出结论：过大的数据集实际上可以通过简单分区得到的一组分类器来处理，其性能有望至少与bagging方法相当或更好或者比单一分类器更好。},
  doi      = {10.1016/S0167-8655(02)00269-6},
  file     = {:2003Chawla - Distributed Learning with Bagging like Performance.pdf:PDF},
  groups   = {Distributed Learning},
  keywords = {Distributed learning, Bagging, Large data sets, Ensembles, Multiple classifiers},
  ranking  = {rank3},
  url      = {https://www.sciencedirect.com/science/article/pii/S0167865502002696},
}

@InProceedings{Ostapowicz2019,
  author    = {Ostapowicz, Micha{\l} and {\.{Z}}bikowski, Kamil},
  booktitle = {Web Information Systems Engineering -- WISE 2019},
  title     = {Detecting Fraudulent Accounts on Blockchain: A Supervised Approach},
  year      = {2019},
  address   = {Cham},
  editor    = {Cheng, Reynold and Mamoulis, Nikos and Sun, Yizhou and Huang, Xin},
  pages     = {18--31},
  publisher = {Springer International Publishing},
  abstract  = {Applications of blockchain technologies got a lot of attention in recent years. They exceed beyond exchanging value and being a substitute for fiat money and traditional banking system. Nevertheless, being able to exchange value on a blockchain is at the core of the entire system and has to be reliable. Blockchains have built-in mechanisms that guarantee whole system's consistency and reliability. However, malicious actors can still try to steal money by applying well known techniques like malware software or fake emails. In this paper we apply supervised learning techniques to detect fraudulent accounts on Ethereum blockchain. We compare capabilities of Random Forests, Support Vector Machines and XGBoost classifiers to identify such accounts basing on a dataset of more than 300 thousands accounts. Results show that we are able to achieve recall and precision values allowing for the designed system to be applicable as an anti-fraud rule for digital wallets or currency exchanges. We also present sensitivity analysis to show how presented models depend on particular feature and how lack of some of them will affect the overall system performance.},
  comment   = {通过SVM、随机森林以及XGBOOST算法检测区块链系统中的欺诈账号。},
  doi       = {10.1007/978-3-030-34223-4_2},
  file      = {:2019Ostapowicz - Detecting Fraudulent Accounts on Blockchain_ a Supervised Approach.pdf:PDF},
  groups    = {Applications of Optimization ML and BC},
  isbn      = {978-3-030-34223-4},
  keywords  = {Machine Learning, Blockchain, xgboost, random forests, svm},
  ranking   = {rank2},
}

@InProceedings{Song2021,
  author    = {Song, Dongxiang and Wang, Yiran and Yuan, Mingju},
  booktitle = {Data Mining and Big Data},
  title     = {An Improved Method of Blockchain Consortium Chain Consensus Mechanism Based on Random Forest Model},
  year      = {2021},
  address   = {Singapore},
  editor    = {Tan, Ying and Shi, Yuhui and Zomaya, Albert and Yan, Hongyang and Cai, Jun},
  pages     = {148--157},
  publisher = {Springer Singapore},
  abstract  = {As blockchain technology has attracted more and more attention from all walks of life, the industry application prospects of alliance chains are very broad. Consensus algorithms are very important in blockchain applications. Now the alliance chain mainly uses the PBFT consensus algorithm, but the main node selection step of the algorithm needs to be maintained by all nodes in the alliance chain, which has high consumption and high latency performance and low security. The problem. This paper uses the integrated learning random forest model of machine learning by adding a credit scoring mechanism, taking the characteristic data of some influencing factors of the alliance chain that affect the selection of the master node as input, the selection of the master node as the observation sample, and the training sample to obtain the prediction model. The predicted master node is used to replace the master consensus node selection step in the PBFT algorithm to complete the consensus, and RFBFT (Random Forest Byzantine Fault-Tolerant Algorithm) is proposed. The high accuracy of the experimental random forest prediction model ensures the accuracy and safety of the master node selection. Comparing the algorithms before and after the improvement, the consumption of RFBFT is reduced by 20{\%} and the delay is reduced by 19{\%}, which improves the operation of the alliance chain. Performance and safety.},
  comment   = {通过Random Forest算法优化主节点选择，来改善PBFT共识算法的联盟链的性能。},
  doi       = {10.1007/978-981-16-7502-7_17},
  file      = {:2021Song - An Improved Method of Blockchain Consortium Chain Consensus Mechanism Based on Random Forest Model.pdf:PDF},
  groups    = {ML and Blockchain},
  isbn      = {978-981-16-7502-7},
  keywords  = {random forest, machine learning, blockchain, Alliance chain, PBFT},
  ranking   = {rank1},
}

@Article{Subathra2022,
  author   = {Subathra, G. and Antonidoss, A. and Singh, Bhupesh Kumar},
  journal  = {Security and Communication Networks},
  title    = {Decentralized {Consensus} {Blockchain} and {IPFS}-{Based} {Data} {Aggregation} for {Efficient} {Data} {Storage} {Scheme}},
  year     = {2022},
  issn     = {1939-0114},
  month    = jul,
  note     = {Publisher: Hindawi},
  pages    = {3167958},
  volume   = {2022},
  abstract = {By the development and advancement of blockchain technique, Internet of Things (IoT) proliferation driven devices and the application of blockchain-enabled IoT alter the view and operating infrastructure of the smart networks. The blockchain is responsible for supporting decentralized systems and offers secured means of authentication, management, and access to IoT system thereby deploying smart contracts offered by Ethereum. The increasing demand and the blockchain expansion generate huge volume of sensitive data. The growing demand and expansion of blockchain-IoT systems is generating large volume of sensitive data. Furthermore, distributed denial-of-service (DDoS) attacks are regarded as the most promising threats for smart contracts in the blockchain-based systems. Therefore, there is a need to detect and classify the attack type and the data should be stored in server more securely with the use of blockchain and data aggregation method. For this purpose, this presented technique aims at introducing decentralized consensus blockchain and Interplanetary file system (IPFS) based data aggregation for effective classification and data storage. The attack is detected using meta-hyperparameter random forest (MHP-RF) classifier. Once the attack is detected, the transaction information is stored in server securely by means of smart contract-based blockchain system. The transaction handling stage classifies the transaction type as normal or abnormal one which then followed by execution of business logic by smart contract thereby appending the transaction of blockchain in the network cloud. The consensus blockchain technique is employed with the use of PoW-enabled scheme integrated with Elgamal-based data aggregation. Therefore, the system security is improved and the intrusion is prevented greatly. The performance analysis of the system is analyzed in terms of accuracy, precision, recall, F-score, Encryption time, decryption time, execution time, and space complexity. The attained outcomes are compared with traditional approaches to prove the effectiveness of proposed strategy. The proposed system is said to be effective in time consumption, classifier performance, and in overcoming space complexity issues.},
  comment  = {采用随机森林算法检测针对智能合约的DDoS攻击},
  doi      = {10.1155/2022/3167958},
  editor   = {Amin, Ruhul},
  file     = {:2022JulySubathra - Decentralized Consensus Blockchain and IPFS Based Data Aggregation for Efficient Data Storage Scheme.pdf:PDF},
  groups   = {ML and Blockchain},
  keywords = {DDoS, Blockchain, Smart Contract, Machine Learning},
  ranking  = {rank1},
}

@Article{Sagi2018,
  author     = {Sagi, Omer and Rokach, Lior},
  journal    = {WIREs Data Mining and Knowledge Discovery},
  title      = {Ensemble learning: A survey},
  year       = {2018},
  number     = {4},
  pages      = {e1249},
  volume     = {8},
  abstract   = {Ensemble methods are considered the state-of-the art solution for many machine learning challenges. Such methods improve the predictive performance of a single model by training multiple models and combining their predictions. This paper introduce the concept of ensemble learning, reviews traditional, novel and state-of-the-art ensemble methods and discusses current challenges and trends in the field. This article is categorized under: Algorithmic Development > Ensemble Methods Technologies > Machine Learning Technologies > Classification},
  comment    = {集成学习综述。介绍集成学习的基础与起源、集成学习的工作方式与优点、集成学习面对的挑战、常用集成学习方法。

Class imbalance， Concept drift，Curse of dimensionality},
  doi        = {10.1002/widm.1249},
  eprint     = {https://wires.onlinelibrary.wiley.com/doi/pdf/10.1002/widm.1249},
  file       = {:2018Sagi - Ensemble Learning_ a Survey.pdf:PDF},
  groups     = {Distributed Learning},
  keywords   = {boosting, classifier combination, ensemble models, machine-learning, mixtures of experts, multiple classifier system, random forest},
  ranking    = {rank4},
  readstatus = {skimmed},
}

@Article{Chawla2004,
  author     = {N. Chawla and Lawrence O. Hall and K. Bowyer and W. Philip Kegelmeyer},
  journal    = {J. Mach. Learn. Res.},
  title      = {Learning Ensembles from Bites: A Scalable and Accurate Approach},
  year       = {2004},
  pages      = {421-451},
  volume     = {5},
  comment    = {提出一种能利用bagging和boosting的集成学习方法，在分布式环境下将数据集随机分区，将这些分立的新数据集分配给不同处理器，采用Breiman的pasting bites方法训练得到大量分类器，最后通过多数投票进行预测。作者提出两种算法pasting DIvote与pasting DRvote，两者主要区别在于，DIvote根据分类器的预测结果对数据集进行加权采样，而DRvote不加权直接对数据进行有放回采样。作者在不同数据集上采用决策树与神经网络进行大量实验，发现虽然DRvote不需要根据预测结果采样速度更快，但DRvote准确度实际上不如DIvote，并且DIvote方法将数据集拆分成分立子集，占用内存更少，可扩展性更强。与分布式boosting方法[Lazarevic2002]相比，DIvote方法不仅不需要跨处理器通信，准确率也没有明显低于分布式boosting。},
  file       = {:2004Chawla - Learning Ensembles from Bites_ a Scalable and Accurate Approach.pdf:PDF},
  groups     = {Distributed Learning},
  keywords   = {ensembles, bagging, boosting, diversity, distributed learning},
  priority   = {prio2},
  ranking    = {rank3},
  readstatus = {skimmed},
  url        = {https://jmlr.org/papers/volume5/chawla04a/chawla04a.pdf},
}

@Article{Ganaie2021,
  author   = {M. A. Ganaie and Minghui Hu and Muhammad Tanveer and Ponnuthurai Nagaratnam Suganthan},
  journal  = {Engineering Applications of Artificial Intelligence},
  title    = {Ensemble deep learning: A review},
  year     = {2021},
  pages    = {105151},
  volume   = {115},
  comment  = {关于集成模型的综述。},
  doi      = {10.1016/j.engappai.2022.105151},
  file     = {:2021Ganaie - Ensemble Deep Learning_ a Review.pdf:PDF},
  groups   = {Distributed Learning},
  keywords = {Ensemble Learning, Deep Learning},
  ranking  = {rank3},
}

@Article{Predd2006,
  author   = {Predd, J.B. and Kulkarni, S.B. and Poor, H.V.},
  journal  = {IEEE Signal Processing Magazine},
  title    = {Distributed learning in wireless sensor networks},
  year     = {2006},
  number   = {4},
  pages    = {56-69},
  volume   = {23},
  comment  = {一篇关于无线传感器网络的综述，探讨在这一种网络中实现非参数化分布式学习的可能性与优势（？），结合现有的中心化情形下的传统机器学习进行分析。},
  doi      = {10.1109/MSP.2006.1657817},
  file     = {:2006Predd - Distributed Learning in Wireless Sensor Networks.pdf:PDF},
  groups   = {Distributed Learning},
  keywords = {Wireless Sensor Networks, Distributed Learning},
  ranking  = {rank2},
}

@Article{Wang2022,
  author     = {Wang, Yuntao and Peng, Haixia and Su, Zhou and Luan, Tom H. and Benslimane, Abderrahim and Wu, Yuan},
  journal    = {IEEE J. Sel. Areas Commun.},
  title      = {A Platform-Free Proof of Federated Learning Consensus Mechanism for Sustainable Blockchains},
  year       = {2022},
  month      = dec,
  number     = {12},
  pages      = {3305-3324},
  volume     = {40},
  comment    = {提出一种无平台的联邦学习证明机制，设计了新的区块结构、交易类型以及基于积分的激励机制、设计了用户级别的差分隐私算法实现保护隐私的联邦挖矿、设计了经过优化的矿池形成算法

A credit-based Algorand BA protocol is devised where a committee of validators is elected randomly by weighted VRF based on credit value of nodes to urge them to behave honestly and actively.},
  doi        = {10.1109/JSAC.2022.3213347},
  file       = {:2022Wang - A Platform Free Proof of Federated Learning Consensus Mechanism for Sustainable Blockchains.pdf:PDF},
  groups     = {FL and Blockchain},
  keywords   = {Blockchain, AI-inspired consensus, federated learning, dynamic pool formation, Machine learning},
  priority   = {prio2},
  ranking    = {rank5},
  readstatus = {skimmed},
}

@InProceedings{Raikwar2021,
  author     = {Raikwar, Mayank and Gligoroski, Danilo},
  booktitle  = {2021 3rd Conference on Blockchain Research \& Applications for Innovative Networks and Services (BRAINS)},
  title      = {R3V: Robust Round Robin VDF-based Consensus},
  year       = {2021},
  pages      = {81-88},
  comment    = {提出R3V共识算法，根据年龄以一种轮询方式选择候选领袖，然后让这些候选者竞争解决可验证延迟函数从而成为区块领袖。相比其他PoS共识协议，R3V能有效对抗多种针对PoS协议的攻击，并且能源消耗更低、通信复杂度更低并且更加公平。
R3V需要两大重要要素：身份建立以及VDF的可行性。身份建立基于TEE（文中用SGX距离但是Intel已经只在服务器CPU上保留SGX），已经有多种共识协议使用。VDF是比较新的密码学原语，在共识协议中的应用还没有经过深入探索。},
  doi        = {10.1109/BRAINS52497.2021.9569781},
  file       = {:2021Raikwar - R3V_ Robust Round Robin VDF Based Consensus.pdf:PDF},
  groups     = {Blockchain Theory},
  keywords   = {Proof of Work, Consensus protocol, Complexity theory, Delays, Stakeholders, Round robin, Blockchain},
  priority   = {prio3},
  ranking    = {rank3},
  readstatus = {read},
}

@Article{WarnatHerresthal2021,
  author   = {Stefanie Warnat-Herresthal and Hartmut Schultze and Krishnaprasad Lingadahalli Shastry and Sathyanarayanan Manamohan and Saikat Mukherjee and Vishesh Garg and Ravi Sarveswara and Kristian H{\"a}ndler and Peter Pickkers and N. Ahmad Aziz and Sofia Ira Ktena and Florian Tran and Michael Bitzer and Stephan Ossowski and Nicolas Casadei and Christian Herr and Daniel Petersheim and Uta Behrends and Fabian Kern and Tobias Fehlmann and Philipp Schommers and Clara Lehmann and Max Augustin and Jan Rybniker and Janine Altm{\"u}ller and Neha Mishra and Joana P. Bernardes and Benjamin Kr{\"a}mer and Lorenzo Bonaguro and Jonas Schulte-Schrepping and Elena De Domenico and Christian Siever and Michael Kraut and Milind Desai and Bruno Monnet and Maria Saridaki and Charles Martin Siegel and Anna Drews and Melanie Nuesch-Germano and Heidi Theis and Jan Heyckendorf and Stefan Schreiber and Sarah Kim-Hellmuth and Jacob Nattermann and Dirk Skowasch and Ingo Kurth and Andreas Keller and Robert Bals and Peter J. N{\"u}rnberg and Olaf Riess and Philip C Rosenstiel and Mihai G. Netea and Fabian J. Theis and Sach Mukherjee and Michael Backes and Anna C. Aschenbrenner and Thomas Ulas and Monique M. B. Breteler and Evangelos J. Giamarellos‐Bourboulis and Matthijs Kox and Matthias Becker and Sorin Cristian Cheran and Michael Woodacre and Eng Lim Goh and Joachim L. Schultze},
  journal  = {Nature},
  title    = {Swarm Learning for decentralized and confidential clinical machine learning},
  year     = {2021},
  pages    = {265 - 270},
  volume   = {594},
  comment  = {提出新的分布式机器学习方法Swarm Learning，结合区块链与边缘计算技术，免于中心化的协调者，实现隐私保护。文章中通过四个案例展现这一方法在进行疾病甄别时可行性和优势。},
  doi      = {10.1038/s41586-021-03583-3},
  file     = {:2021Warnat-Herresthal - Swarm Learning for Decentralized and Confidential Clinical Machine Learning.pdf:PDF},
  groups   = {ML and Blockchain, Applications of Optimization ML and BC,},
  keywords = {Blockchain, Machine Learning, edge computing, Application},
  ranking  = {rank4},
}

@Article{Platt2023,
  author         = {Platt, Moritz and McBurney, Peter},
  journal        = {Algorithms},
  title          = {Sybil in the Haystack: A Comprehensive Review of Blockchain Consensus Mechanisms in Search of Strong Sybil Attack Resistance},
  year           = {2023},
  issn           = {1999-4893},
  number         = {1},
  volume         = {16},
  abstract       = {Consensus algorithms are applied in the context of distributed computer systems to improve their fault tolerance. The explosive development of distributed ledger technology following the proposal of &lsquo;Bitcoin&rsquo; led to a sharp increase in research activity in this area. Specifically, public and permissionless networks require robust leader selection strategies resistant to Sybil attacks in which malicious attackers present bogus identities to induce byzantine faults. Our goal is to analyse the entire breadth of works in this area systematically, thereby uncovering trends and research directions regarding Sybil attack resistance in today&rsquo;s blockchain systems to benefit the designs of the future. Through a systematic literature review, we condense an immense set of research records (N = 21,799) to a relevant subset (N = 483). We categorise these mechanisms by their Sybil attack resistance characteristics, leader selection methodology, and incentive scheme. Mechanisms with strong Sybil attack resistance commonly adopt the principles underlying &lsquo;Proof-of-Work&rsquo; or &lsquo;Proof-of-Stake&rsquo; while mechanisms with limited resistance often use reputation systems or physical world linking. We find that only a few fundamental paradigms exist that can resist Sybil attacks in a permissionless setting but discover numerous innovative mechanisms that can deliver weaker protection in system scenarios with smaller attack surfaces.},
  article-number = {34},
  comment        = {系统分析近年对抗女巫攻击的工作，从抗女巫攻击特性、领袖选举方法、激励机制三个方面对这些工作进行分类。女巫攻击对抗能力强的机制通常采用PoW与PoS底层的原理；弱机制通常采用声望系统或者物理世界链接。只有少数范例可以在无权限环境下对抗女巫攻击，但也发现一些能在弱保护下减少攻击面的创新机制。
（一篇引用了大量共识机制文章的综述，看上去很全面，重点在分类分析方面）},
  doi            = {10.3390/a16010034},
  file           = {:2023Platt - Sybil in the Haystack_ a Comprehensive Review of Blockchain Consensus Mechanisms in Search of Strong Sybil Attack Resistance.pdf:PDF},
  groups         = {Blockchain Surveys},
  keywords       = {blockchain, distributed ledger technology, consensus protocol, Sybil attack, member selection, leader selection},
  ranking        = {rank3},
  url            = {https://www.mdpi.com/1999-4893/16/1/34},
}

@InProceedings{Bizzaro2020,
  author     = {Francesco Bizzaro and Mauro Conti and Maria Silvia Pini},
  booktitle  = {Proc. 2020 {IEEE} Int. Conf. Blockchain},
  title      = {Proof of Evolution: Leveraging blockchain mining for a cooperative execution of Genetic Algorithms},
  year       = {2020},
  address    = {Rhodes, GR},
  month      = nov,
  pages      = {450-455},
  abstract   = {2020 IEEE International Conference on Blockchain (Blockchain);2020; ; ;10.1109/Blockchain50366.2020.00065},
  comment    = {Proof of Evolution思路与Proof of Search类似，但是融合了遗传算法，并使得矿工之间可以进行协作，提高接近最优解的几率。
遗传算法中比较重要的的概念有个体、染色体、种群、基因和适合度，个体是指单个可行的解，染色体是指多个个体的编码表示，染色体由基因组成，种群是一组个体的集合，适合度是给每个个体评分的函数。遗传算法的执行是一个迭代的过程，每一次迭代都会更新种群，这一过程称为繁殖，繁殖过程中会对种群的选择集进行复制、变异和交叉操作，满足终止条件后停止迭代。
PoE相比PoS，主要的变化在于miniblock的结构、搜索器、激励机制以及矿工之间共享解的机制。
miniblock中的nonce在PoS中由solution和evaluation两部分组成，但是在PoE中由可能解、适合度和复杂度三部分组成。复杂度根据任务的初级操作加权计算得到，初级操作的权重由前一区块的哈希以及矿工公钥决定，因此对复杂度进行验证可以避免矿工复用结果或者偷窃其他矿工的成果，此外复杂度还可以实现挖矿难度根据任务难度的自适应调整。
PoE中的搜索器与PoS类似但是运行的是GA遗传算法。
PoE中还存在一个种群分享机制，使得矿工之间可以在区块建立之后分享本地的种群，在不同矿工的种群之间进行交叉，有助于改善遗传算法最终解的质量。这一机制实现了矿工之间的协作。为了激励矿工进行协作，需要将原本由客户支付、分配给找到最佳解矿工的奖励分配给分享种群的矿工。
作者通过理论证明了PoE可以将大部分操作用于执行遗传算法，通过实验证明了PoE中矿工协作的机制可以对遗传算法最终的适应度产生一定增益，并且如果遗传算法中的参数随机设置可以获得更高的性能增益。},
  doi        = {10.1109/blockchain50366.2020.00065},
  file       = {:2020novBizzaro - Proof of Evolution_ Leveraging Blockchain Mining for a Cooperative Execution of Genetic Algorithms.pdf:PDF},
  groups     = {Optimization and Blockchain},
  keywords   = {Consensus Protocols, Genetic Algorithms, Cooperation, Optimization},
  priority   = {prio2},
  ranking    = {rank4},
  readstatus = {read},
}

@Article{Domeniconi2009,
  author     = {Domeniconi, Carlotta and Al-Razgan, Muna},
  journal    = {ACM Trans. Knowl. Discov. Data},
  title      = {Weighted Cluster Ensembles: Methods and Analysis},
  year       = {2009},
  issn       = {1556-4681},
  month      = {jan},
  number     = {4},
  volume     = {2},
  abstract   = {Cluster ensembles offer a solution to challenges inherent to clustering arising from its ill-posed nature. Cluster ensembles can provide robust and stable solutions by leveraging the consensus across multiple clustering results, while averaging out emergent spurious structures that arise due to the various biases to which each participating algorithm is tuned. In this article, we address the problem of combining multiple weighted clusters that belong to different subspaces of the input space. We leverage the diversity of the input clusterings in order to generate a consensus partition that is superior to the participating ones. Since we are dealing with weighted clusters, our consensus functions make use of the weight vectors associated with the clusters. We demonstrate the effectiveness of our techniques by running experiments with several real datasets, including high-dimensional text data. Furthermore, we investigate in depth the issue of diversity and accuracy for our ensemble methods. Our analysis and experimental results show that the proposed techniques are capable of producing a partition that is as good as or better than the best individual clustering.},
  address    = {New York, NY, USA},
  articleno  = {17},
  comment    = {加权聚类集成方法的研究，采用输入聚类的多样性生成共识分区，共识函数利用与聚类相关的加权向量？？？},
  doi        = {10.1145/1460797.1460800},
  file       = {:2009janDomeniconi - Weighted Cluster Ensembles_ Methods and Analysis.pdf:PDF},
  groups     = {Distributed Learning},
  issue_date = {January 2009},
  keywords   = {consensus functions, Cluster ensembles, subspace clustering, data mining, text data, accuracy and diversity measures},
  numpages   = {40},
  publisher  = {Association for Computing Machinery},
  ranking    = {rank1},
}

@Article{Verbraeken2020,
  author     = {Verbraeken, Joost and Wolting, Matthijs and Katzy, Jonathan and Kloppenburg, Jeroen and Verbelen, Tim and Rellermeyer, Jan S.},
  journal    = {ACM Comput. Surv.},
  title      = {A Survey on Distributed Machine Learning},
  year       = {2020},
  issn       = {0360-0300},
  month      = {mar},
  number     = {2},
  volume     = {53},
  abstract   = {The demand for artificial intelligence has grown significantly over the past decade, and this growth has been fueled by advances in machine learning techniques and the ability to leverage hardware acceleration. However, to increase the quality of predictions and render machine learning solutions feasible for more complex applications, a substantial amount of training data is required. Although small machine learning models can be trained with modest amounts of data, the input for training larger models such as neural networks grows exponentially with the number of parameters. Since the demand for processing training data has outpaced the increase in computation power of computing machinery, there is a need for distributing the machine learning workload across multiple machines, and turning the centralized into a distributed system. These distributed systems present new challenges: first and foremost, the efficient parallelization of the training process and the creation of a coherent model. This article provides an extensive overview of the current state-of-the-art in the field by outlining the challenges and opportunities of distributed machine learning over conventional (centralized) machine learning, discussing the techniques used for distributed machine learning, and providing an overview of the systems that are available.},
  address    = {New York, NY, USA},
  articleno  = {30},
  comment    = {分布式机器学习方法的综述，提出用集成学习方法结合多种机器学习算法，提出分布式机器学习系统的拓扑结构，提出分布式学习生态系统的构想。
提及Gossip Learning。},
  doi        = {10.1145/3377454},
  file       = {:2020marVerbraeken - A Survey on Distributed Machine Learning.pdf:PDF},
  groups     = {Distributed Learning},
  issue_date = {March 2021},
  keywords   = {Distributed machine learning, distributed systems},
  numpages   = {33},
  publisher  = {Association for Computing Machinery},
  ranking    = {rank4},
}

@InProceedings{Shi2018,
  author    = {Shi, Shaohuai and Wang, Qiang and Chu, Xiaowen},
  booktitle = {2018 IEEE 16th Intl Conf on Dependable, Autonomic and Secure Computing, 16th Intl Conf on Pervasive Intelligence and Computing, 4th Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress(DASC/PiCom/DataCom/CyberSciTech)},
  title     = {Performance Modeling and Evaluation of Distributed Deep Learning Frameworks on GPUs},
  year      = {2018},
  pages     = {949-957},
  comment   = {使用四种深度学习框架对四节点密集GPU集群（用InfiniBand连接）在三种模型上的性能进行测试分析。建立了测量同步SGD加速倍率的模型，然后对单GPU、多GPU、多机器三种情形下进行性能测试。},
  doi       = {10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.000-4},
  file      = {:2018Shi - Performance Modeling and Evaluation of Distributed Deep Learning Frameworks on GPUs.pdf:PDF},
  groups    = {Distributed Learning},
  keywords  = {Deep Learning, GPU, Distributed SGD, Convolutional Neural Networks, Deep Learning Frameworks, Distributed Learning},
  ranking   = {rank2},
  url       = {https://ieeexplore.ieee.org/document/8512002},
}

@InProceedings{Taghizadeh2020,
  author     = {Taghizadeh, Saeed and Shabankhah, Mahmood and Moeini, Ali and Kamandi, Ali},
  booktitle  = {Data Science: From Research to Application},
  title      = {A New Distributed Ensemble Method with Applications to Machine Learning},
  year       = {2020},
  address    = {Cham},
  editor     = {Bohlouli, Mahdi and Sadeghi Bigham, Bahram and Narimani, Zahra and Vasighi, Mahdi and Ansari, Ebrahim},
  pages      = {44--58},
  publisher  = {Springer International Publishing},
  abstract   = {The main objective of this paper is to introduce a new ensemble learning model which takes advantage of the data which is originally distributed among a group of local centers. In this model, we first train a group of client nodes which have access only to their own local data sets. High classification rate is not required in this phase. In the second phase, the master node learns which client nodes are more likely to classify correctly a given data instance. Therefore, only the responses of these effective nodes will be used in the classification step. A major advantage of our algorithm, as the experimental results confirm, is that the network can obtain high classification rates by using a relatively small fraction of the whole data set. Moreover, this learning scheme is fairly general and can be employed in other contexts as well.},
  comment    = {设计了DYABoost算法，采用Learn++算法（一种增量学习方法）作为算法的核心，并避免Learn++算法中的顺序操作。在训练样本数量少的情况下，这种方法具有更高的准确率。算法分为两个阶段，第一阶段Client在本地训练集上训练得到弱模型，然后Master节点与Client交互后根据开始训练，得到哪个客户能否在特定输入数据上最有可能得到正确结果。最后测试阶段需要结合Client与Master节点产生的模型进行判断，具体见Algorithm2。},
  doi        = {10.1007/978-3-030-37309-2_5},
  file       = {:2020Taghizadeh - A New Distributed Ensemble Method with Applications to Machine Learning.pdf:PDF},
  groups     = {Distributed Learning},
  isbn       = {978-3-030-37309-2},
  keywords   = {Ensemble methods, Machine learning, Distributed learning, AdaBoost, Big data},
  ranking    = {rank1},
  readstatus = {read},
}

@Article{Canzian2013,
  author   = {Luca Canzian and Yu Zhang and Mihaela van der Schaar},
  journal  = {IEEE Transactions on Signal and Information Processing over Networks},
  title    = {Ensemble of distributed learners for online classification of dynamic data streams},
  year     = {2013},
  pages    = {180-194},
  volume   = {1},
  comment  = {提出一种在线集成学习方法Perceptron Weighted Majority（PWM），实现对来自分布式、多种类、动态数据源的数据的分类。方案中有多个分布式本地分类器，设计了一种机制根据数据动态调整模型聚合规则（加权多数规则）。
每个学习者都负责不同的数据源，对每个数据源的新数据训练模型、进行预测，最终通过加权多数规则将这些预测进行结合得到最终预测。得到最终预测之后的学习者得到真值，并根据这些信息采用感知机（Perceptron）规则更新聚合权重。
（数学推导很多）},
  doi      = {10.1109/TSIPN.2015.2470125},
  file     = {:2013Canzian - Ensemble of Distributed Learners for Online Classification of Dynamic Data Streams.pdf:PDF},
  groups   = {Distributed Learning},
  keywords = {Online learning, distributed learning, ensemble of classifiers, dynamic streams, concept drift, classification},
  ranking  = {rank4},
}

@Article{Feng2022,
  author   = {Feng, Lei and Yang, Zhixiang and Guo, Shaoyong and Qiu, Xuesong and Li, Wenjing and Yu, Peng},
  journal  = {IEEE Network},
  title    = {Two-Layered Blockchain Architecture for Federated Learning Over the Mobile Edge Network},
  year     = {2022},
  number   = {1},
  pages    = {45-51},
  volume   = {36},
  comment  = {本文中提出适用于联邦学习的双层区块链架构，同时考虑本地设备与MEC节点，由两种区块链组成：本地模型更新链LMUC、全局模型更新链GMUC。LMUC中的区块用来记录联邦学习参与者的本地模型更新结果，引入了D2D通信来快速完成LMUC建立共识时的传输。GMUC通过减轻恶意设备与不正常MEC节点造成的训练失败，安全实现全局模型的更新，提升联邦学习的可信度以及效率。通过智能合约奖励参与联邦学习的移动边缘设备。


MEC：Mobile Edge Computing},
  doi      = {10.1109/MNET.011.2000339},
  file     = {:2022Feng - Two Layered Blockchain Architecture for Federated Learning Over the Mobile Edge Network.pdf:PDF},
  groups   = {Applications of Optimization ML and BC},
  keywords = {Blockchain, Federated learning, Wireless Network, Edge Network, Machine Learning},
  ranking  = {rank2},
}

@Article{Nguyen2022,
  author   = {Nguyen, Dinh C. and Hosseinalipour, Seyyedali and Love, David J. and Pathirana, Pubudu N. and Brinton, Christopher G.},
  journal  = {IEEE Journal on Selected Areas in Communications},
  title    = {Latency Optimization for Blockchain-Empowered Federated Learning in Multi-Server Edge Computing},
  year     = {2022},
  number   = {12},
  pages    = {3373-3390},
  volume   = {40},
  comment  = {开发了一种卸载策略使移动设备能够将数据传输到相关联的边缘服务器。提出一种基于共识机制的分布式ML模型聚合方案，借助P2P区块链网络通信来构建全局模型。设计一种深度强化学习方案（采用演员评论员算法），旨在综合考虑数据卸载决策、移动设备传输功率、数据卸载的传输带宽分配等因素最小化系统延迟。},
  doi      = {10.1109/JSAC.2022.3213344},
  file     = {:2022Nguyen - Latency Optimization for Blockchain Empowered Federated Learning in Multi Server Edge Computing.pdf:PDF},
  groups   = {Applications of Optimization ML and BC},
  keywords = {Federated learning, blockchain, edge computing, actor-critic learning, network optimization, Machine Learning, Reinforcement Learning, Consensus},
  ranking  = {rank4},
}

@Article{Xiao2020,
  author   = {Xiao, Liang and Ding, Yuzhen and Jiang, Donghua and Huang, Jinhao and Wang, Dongming and Li, Jie and Vincent Poor, H.},
  journal  = {IEEE Transactions on Communications},
  title    = {A Reinforcement Learning and Blockchain-Based Trust Mechanism for Edge Networks},
  year     = {2020},
  number   = {9},
  pages    = {5460-5470},
  volume   = {68},
  comment  = {设计了一种基于区块链的MEC信任机制对抗自私边缘攻击以及伪造服务记录攻击，使MEC节点能更好地改善移动设备的性能。提出一种基于强化学习的CPU分配算法，在不知道网络模型与移动服务生成的情况下根据（费用-计算成本）来分配边缘CPU资源，提升MEC节点的利用率。},
  doi      = {10.1109/TCOMM.2020.2995371},
  file     = {:2020Xiao - A Reinforcement Learning and Blockchain Based Trust Mechanism for Edge Networks.pdf:PDF},
  groups   = {Applications of Optimization ML and BC},
  keywords = {Blockchain, mobile edge computing, deepreinforcement learning, Machine Learning},
  ranking  = {rank1},
}

@InProceedings{Liu2019a,
  author    = {Liu, Mengting and Teng, Yinglei and Yu, F. Richard and Leung, Victor C. M. and Song, Mei},
  booktitle = {ICC 2019 - 2019 IEEE International Conference on Communications (ICC)},
  title     = {Deep Reinforcement Learning Based Performance Optimization in Blockchain-Enabled Internet of Vehicle},
  year      = {2019},
  pages     = {1-6},
  comment   = {为区块链赋能车联网场景提出一种新的基于深度强化学习的性能优化框架，通过选择区块生成者、区块大小和区块间隔最大化交易吞吐量的同时保证区块链去中心化、延迟以及安全。},
  doi       = {10.1109/ICC.2019.8761206},
  file      = {:2019Liu - Deep Reinforcement Learning Based Performance Optimization in Blockchain Enabled Internet of Vehicle.pdf:PDF},
  groups    = {RL and Blockchain, Applications of Optimization ML and BC},
  keywords  = {Blockchain, Internet of Vehicle, Deep Reinforcement Learning, Machine Learning},
  ranking   = {rank2},
}

@Article{Asheralieva2021,
  author   = {Asheralieva, Alia and Niyato, Dusit},
  journal  = {IEEE Transactions on Cognitive Communications and Networking},
  title    = {Bayesian Reinforcement Learning and Bayesian Deep Learning for Blockchains With Mobile Edge Computing},
  year     = {2021},
  number   = {1},
  pages    = {319-335},
  volume   = {7},
  comment  = {为矿工的决策设计了一种基于部分可观测马尔可夫决策过程（POMDP）贝叶斯强化学习算法，使矿工能够通过在与移动环境和其他矿工的交互中动态调整策略、更新信念，达到贝叶斯纳什均衡之后可以最大化矿工的预期长期收益。提出一种新的无监督贝叶斯深度学习算法，通过贝叶斯神经网络近似POMDP无法观测状态的不确定性，从而降低贝叶斯强化学习算法的指数复杂度。},
  doi      = {10.1109/TCCN.2020.2994366},
  file     = {:2021Asheralieva - Bayesian Reinforcement Learning and Bayesian Deep Learning for Blockchains with Mobile Edge Computing.pdf:PDF},
  groups   = {Applications of Optimization ML and BC},
  keywords = {Bayesian methods, blockchains, deep learning,game theory, incomplete information, machine learning, mobileedge computing, partially-observable Markov decision process,reinforcement learning, resource management},
  ranking  = {rank1},
}

@InProceedings{Jia2021,
  author    = {Jia, Hengrui and Yaghini, Mohammad and Choquette-Choo, Christopher A. and Dullerud, Natalie and Thudi, Anvith and Chandrasekaran, Varun and Papernot, Nicolas},
  booktitle = {Proc. 2021 IEEE Symp. Secur. Privacy (SP)},
  title     = {Proof-of-Learning: Definitions and Practice},
  year      = {2021},
  address   = {San Francisco, CA, USA},
  month     = may,
  pages     = {1039-1056},
  comment   = {通过机器学习中SGD算法中积累的信息产生工作量证明。},
  doi       = {10.1109/SP40001.2021.00106},
  file      = {:2021Jia - Proof of Learning_ Definitions and Practice.pdf:PDF},
  groups    = {ML and Blockchain},
  keywords  = {Blockchain, Machine Learning, Consensus},
  ranking   = {rank1},
}

@InProceedings{Zhang2022,
  author    = {Zhang, Rui and Liu, Jian and Ding, Yuan and Wang, Zhibo and Wu, Qingbiao and Ren, Kui},
  booktitle = {2022 IEEE Symposium on Security and Privacy (SP)},
  title     = {“Adversarial Examples” for Proof-of-Learning},
  year      = {2022},
  pages     = {1408-1422},
  comment   = {提出一种通过adversarial example来spoof Proof-of-Learning: Definitions and Practice中工作量证明机制的方法。},
  doi       = {10.1109/SP46214.2022.9833596},
  file      = {:2022Zhang - “Adversarial Examples” for Proof of Learning.pdf:PDF},
  groups    = {ML and Blockchain},
  keywords  = {Blockchain, Machine Learning, Consensus},
  ranking   = {rank1},
}

@InProceedings{Oza2005,
  author    = {Oza, N.C.},
  booktitle = {2005 IEEE International Conference on Systems, Man and Cybernetics},
  title     = {Online bagging and boosting},
  year      = {2005},
  pages     = {2340-2345 Vol. 3},
  volume    = {3},
  comment   = {介绍了一种在线版本的Bagging和Boosting算法，通过实验对比了在线版本与批处理版本算法的性能。},
  doi       = {10.1109/ICSMC.2005.1571498},
  file      = {:2005Oza - Online Bagging and Boosting.pdf:PDF},
  groups    = {Distributed Learning},
  keywords  = {Bagging, boosting, ensemble learning, online learning},
  ranking   = {rank2},
}

@Article{Breiman_1996,
  author    = {Leo Breiman},
  journal   = {Mach. Learn.},
  title     = {Bagging predictors},
  year      = {1996},
  month     = aug,
  number    = {2},
  pages     = {123--140},
  volume    = {24},
  comment   = {提出Bagging方法，在训练集上通过有放回采样自举出训练集副本作为新的训练集，生成多个训练集副本并在这些副本上训练生成多个版本的预测器。如果预测果预测数值结果则对这些预测器的结果取平均，如果预测器输出类别则对这些预测器的结果进行多数投票。该方法能够改善性能良好但是不稳定的预测方法，降低预测结果的方差从而提高准确率，使预测器更加接近最优，通过在多个数据集上训练分类树以及回归树的实验验证了Bagging方法的有效性。（Bagging的起源）},
  doi       = {10.1007/BF00058655},
  file      = {:1996augBreiman - Bagging Predictors.pdf:PDF},
  groups    = {Distributed Learning},
  keywords  = {Aggregation, Bootstrap, Averaging, Combining, Machine Learning, Ensemble Learning},
  publisher = {Springer Science and Business Media {LLC}},
  ranking   = {rank4},
}

@Article{Zhou2002,
  author   = {Zhi-Hua Zhou and Jianxin Wu and Wei Tang},
  journal  = {Artificial Intelligence},
  title    = {Ensembling neural networks: Many could be better than all},
  year     = {2002},
  issn     = {0004-3702},
  number   = {1},
  pages    = {239-263},
  volume   = {137},
  abstract = {Neural network ensemble is a learning paradigm where many neural networks are jointly used to solve a problem. In this paper, the relationship between the ensemble and its component neural networks is analyzed from the context of both regression and classification, which reveals that it may be better to ensemble many instead of all of the neural networks at hand. This result is interesting because at present, most approaches ensemble all the available neural networks for prediction. Then, in order to show that the appropriate neural networks for composing an ensemble can be effectively selected from a set of available neural networks, an approach named GASEN is presented. GASEN trains a number of neural networks at first. Then it assigns random weights to those networks and employs genetic algorithm to evolve the weights so that they can characterize to some extent the fitness of the neural networks in constituting an ensemble. Finally it selects some neural networks based on the evolved weights to make up the ensemble. A large empirical study shows that, compared with some popular ensemble approaches such as Bagging and Boosting, GASEN can generate neural network ensembles with far smaller sizes but stronger generalization ability. Furthermore, in order to understand the working mechanism of GASEN, the bias-variance decomposition of the error is provided in this paper, which shows that the success of GASEN may lie in that it can significantly reduce the bias as well as the variance.},
  comment  = {提出一种集成方法GASEN，用来证明在某些情况下用多个神经网络模型集成代替完整的神经网络的可行性。},
  doi      = {10.1016/S0004-3702(02)00190-X},
  file     = {:2002Zhou - Ensembling Neural Networks_ Many Could Be Better Than All.pdf:PDF},
  groups   = {Distributed Learning},
  keywords = {Neural networks, Neural network ensemble, Machine learning, Selective ensemble, Boosting, Bagging, Genetic algorithm, Bias-variance decomposition},
  priority = {prio2},
  ranking  = {rank3},
  url      = {https://www.sciencedirect.com/science/article/pii/S000437020200190X},
}

@Article{Hu2022a,
  author   = {Xinyuan Hu and Yuan Zeng and Chao Qin and Dezhuang Meng},
  journal  = {Energy Reports},
  title    = {Bagging-based neural network ensemble for load identification with parameter sensitivity considered},
  year     = {2022},
  issn     = {2352-4847},
  note     = {2022 The 5th International Conference on Electrical Engineering and Green Energy},
  pages    = {199-205},
  volume   = {8},
  abstract = {Extensive installation of measuring devices in power systems promotes the application of the artificial intelligence (AI) in load identification. However, the convergence problems of training and the relatively low accuracy hinder the AI method from further development. In this study, a neural network ensemble method considering parameter sensitivity is proposed to solve these problems. In this method, with distributed generation considered, the parameters of the load model are classified according to the response uniqueness, and identified separately by multiple base learners according to its features. Additionally, ensemble algorithm is introduced for the higher accuracy, and Bagging strategy is used to ensure the diversity of learners through sampling the train set. Numerical simulations on a real power grid system validate the applicability of the proposed method in the field of parameter identification.},
  doi      = {10.1016/j.egyr.2022.08.056},
  file     = {:2022Hu - Bagging Based Neural Network Ensemble for Load Identification with Parameter Sensitivity Considered.pdf:PDF},
  groups   = {Distributed Learning},
  keywords = {Parameter identification, Ensemble learning, Bagging, Parameter sensitivity, Generalized composite load model},
  ranking  = {rank1},
  url      = {https://www.sciencedirect.com/science/article/pii/S2352484722015001},
}

@InProceedings{Boneh2018,
  author    = {Boneh, Dan and Bonneau, Joseph and B{\"u}nz, Benedikt and Fisch, Ben},
  booktitle = {Advances in Cryptology -- CRYPTO 2018},
  title     = {Verifiable Delay Functions},
  year      = {2018},
  address   = {Cham},
  editor    = {Shacham, Hovav and Boldyreva, Alexandra},
  pages     = {757--788},
  publisher = {Springer International Publishing},
  abstract  = {We study the problem of building a verifiable delay function (VDF). A {\$}{\$}{\backslash}text {\{}VDF{\}}{\$}{\$}VDFrequires a specified number of sequential steps to evaluate, yet produces a unique output that can be efficiently and publicly verified. {\$}{\$}{\backslash}text {\{}VDF{\}}{\$}{\$}VDFs have many applications in decentralized systems, including public randomness beacons, leader election in consensus protocols, and proofs of replication. We formalize the requirements for {\$}{\$}{\backslash}text {\{}VDF{\}}{\$}{\$}VDFs and present new candidate constructions that are the first to achieve an exponential gap between evaluation and verification time.},
  doi       = {10.1007/978-3-319-96884-1_25},
  file      = {:2018Boneh - Verifiable Delay Functions.pdf:PDF},
  groups    = {Others},
  isbn      = {978-3-319-96884-1},
}

@InProceedings{Zheng2017,
  author    = {Zheng, Zibin and Xie, Shaoan and Dai, Hongning and Chen, Xiangping and Wang, Huaimin},
  booktitle = {2017 IEEE International Congress on Big Data (BigData Congress)},
  title     = {An Overview of Blockchain Technology: Architecture, Consensus, and Future Trends},
  year      = {2017},
  pages     = {557-564},
  doi       = {10.1109/BigDataCongress.2017.85},
  file      = {:2017Zheng - An Overview of Blockchain Technology_ Architecture, Consensus, and Future Trends.pdf:PDF},
  groups    = {Blockchain Surveys},
  keywords  = {Survey, Blockchain},
  ranking   = {rank4},
  url       = {https://ieeexplore.ieee.org/document/8029379},
}

@Article{Xiao2020a,
  author   = {Xiao, Yang and Zhang, Ning and Lou, Wenjing and Hou, Y. Thomas},
  journal  = {IEEE Communications Surveys \& Tutorials},
  title    = {A Survey of Distributed Consensus Protocols for Blockchain Networks},
  year     = {2020},
  number   = {2},
  pages    = {1432-1465},
  volume   = {22},
  doi      = {10.1109/COMST.2020.2969706},
  file     = {:2020Xiao - A Survey of Distributed Consensus Protocols for Blockchain Networks.pdf:PDF},
  groups   = {Blockchain Surveys},
  keywords = {Blockchain, distributed consensus, fault tolerance, protocol design},
  ranking  = {rank4},
}

@Misc{Nakamoto2008,
  author = {Nakamoto, Satoshi},
  title  = {Bitcoin: A peer-to-peer electronic cash system},
  year   = {2008},
  file   = {:2008Nakamoto - Bitcoin_ a Peer to Peer Electronic Cash System.pdf:PDF},
  groups = {Others},
  url    = {https://bitcoin.org/bitcoin.pdf},
}

@Article{deVries2018,
  author   = {Alex {de Vries}},
  journal  = {Joule},
  title    = {Bitcoin's Growing Energy Problem},
  year     = {2018},
  issn     = {2542-4351},
  number   = {5},
  pages    = {801-805},
  volume   = {2},
  abstract = {The electricity that is expended in the process of mining Bitcoin has become a topic of heavy debate over the past few years. It is a process that makes Bitcoin extremely energy-hungry by design, as the currency requires a huge amount of hash calculations for its ultimate goal of processing financial transactions without intermediaries (peer-to-peer). The primary fuel for each of these calculations is electricity. The Bitcoin network can be estimated to consume at least 2.55 gigawatts of electricity currently, and potentially 7.67 gigawatts in the future, making it comparable with countries such as Ireland (3.1 gigawatts) and Austria (8.2 gigawatts). Economic models tell us that Bitcoin's electricity consumption will gravitate toward the latter number. A look at Bitcoin miner production estimates suggests that this number could already be reached in 2018.},
  doi      = {10.1016/j.joule.2018.04.016},
  file     = {:2018de Vries - Bitcoin's Growing Energy Problem.pdf:PDF},
  groups   = {Others},
  keywords = {Blockchain, Bitcoin, Energy Consumption},
}

@Article{Liu2022,
  author   = {Liu, Ji and Huang, Jizhou and Zhou, Yang and Li, Xuhong and Ji, Shilei and Xiong, Haoyi and Dou, Dejing},
  journal  = {Knowledge and Information Systems},
  title    = {From distributed machine learning to federated learning: a survey},
  year     = {2022},
  issn     = {0219-3116},
  month    = apr,
  number   = {4},
  pages    = {885--917},
  volume   = {64},
  abstract = {In recent years, data and computing resources are typically distributed in the devices of end users, various regions or organizations. Because of laws or regulations, the distributed data and computing resources cannot be aggregated or directly shared among different regions or organizations for machine learning tasks. Federated learning emerges as an efficient approach to exploit distributed data and computing resources, so as to collaboratively train machine learning models. At the same time, federated learning obeys the laws and regulations and ensures data security and data privacy. In this paper, we provide a comprehensive survey of existing works for federated learning. First, we propose a functional architecture of federated learning systems and a taxonomy of related techniques. Second, we explain the federated learning systems from four aspects: diverse types of parallelism, aggregation algorithms, data communication, and the security of federated learning systems. Third, we present four widely used federated systems based on the functional architecture. Finally, we summarize the limitations and propose future research directions.},
  doi      = {10.1007/s10115-022-01664-x},
  file     = {:2022AprilLiu - From Distributed Machine Learning to Federated Learning_ a Survey.pdf:PDF;:https\://link.springer.com/content/pdf/10.1007/s10115-022-01664-x.pdf:},
  groups   = {Distributed Learning},
  keywords = {Federated learning, Distributed system, Parallel computing, Security, Privacy},
}

@InBook{Galakatos2018,
  author    = {Galakatos, Alex and Crotty, Andrew and Kraska, Tim},
  editor    = {Liu, Ling and {\"O}zsu, M. Tamer},
  pages     = {1196--1201},
  publisher = {Springer New York},
  title     = {Distributed Machine Learning},
  year      = {2018},
  address   = {New York, NY},
  isbn      = {978-1-4614-8265-9},
  booktitle = {Encyclopedia of Database Systems},
  comment   = {分布式机器学习的概念（定义）},
  doi       = {10.1007/978-1-4614-8265-9_80647},
  file      = {:2018Galakatos - Distributed Machine Learning.pdf:PDF},
  groups    = {Distributed Learning},
  ranking   = {rank4},
}

@Article{梁伦2021,
  author   = {梁伦},
  journal  = {东南大学硕士论文},
  title    = {基于区块链的拜占庭容错分布式机器学习算法研究},
  year     = {2021},
  abstract = {随着时代的发展,机器学习的训练集规模与模型复杂度不断增长,单机训练模型已无法适应大规模数据环境。近年来,分布式机器学习因其具有海量数据处理能力以及灵活的扩展性,获得了越来越多的关注。然而,分布式机器学习在蓬勃发展的同时也面临着一些安全和隐私保护方面的挑战,拜占庭攻击是分布式机器学习中潜在的安全威胁。目前已有的分布式机器学习框架可以分为中心化框架和非中心化框架两种,在本文考虑的中心化的分布式机器学习框架中,训练节点和中心节点都有可能受到拜占庭攻击。如果训练节点受到拜占庭攻击,它会发送错误的局部模型给中心节点,会使训练模型性能变差;如果中心节点受到拜占庭攻击,它会得到错误的全局梯度,并得到错误的机器学习模型。目前众多学者已经对分布式机器学习中的拜占庭攻击问题进行了研究。然而,目前关于分布式机器学习中拜占庭攻击问题的研究仍然存在以下不足:现有工作假设中心节点是诚实可靠,研究算法来抵御训练节点受到拜占庭攻击,同时他们的算法鲁棒性较差;针对中心节点受到拜占庭攻击的情况,现有工作采用已有的共识算法,这些算法存在通信复杂度较高、无法辨识恶意节点等缺点。本文主要针对以上的不足点进行研究,重点研究分布式机器学习中的拜占庭攻击问题。本文主要的贡献如下:1.本文提出了一个基于联盟链技术的分布式机器学习框架,称为SLC(Secure Learning Chain)。SLC能用于基于梯度下降算法的分布式机器学习算法中,并且有效解决分布式机器学习中的拜占庭攻击问题和训练数据隐私保护问题。对于分布式机器学习中训练节点受到拜占庭攻击的问题,SLC可以采用现有的拜占庭容错分布式梯度下降算法来聚合局部梯度,减少拜占庭训练节点的错误梯度对模型的影响。针对分布式机器学习中中心节点受到拜占庭攻击的问题,SLC将分布式机器学习与区块链技术相结合,利用区块链的共识算法选取共识节点参与梯度聚合,减少拜占庭中心节点对模型的影响。针对分布式机器学习中数据隐私泄露的问题,SLC引入差分隐私机制,每个训练节点在发送出的局部梯度上加入噪声,并用时刻会计算法来跟踪训练过程中的隐私损失。2.针对分布式机器学习中训练节点会受到拜占庭攻击的情况,本文提出了一种鲁棒的拜占庭容错分布式梯度下降算法,称为MAKA(Mixed Acc-based multi-Krum Aggregation)。MAKA算法通过选取一定数量最优的局部梯度完成梯度聚合。MAKA算法在训练的开始阶段计算每个节点的局部梯度与最接近的若干个局部梯度的欧式距离之和,将和作为每个节点的得分,然后根据得分选出一定数量最优的局部梯度完成梯度聚合;模型预训练完成之后MAKA算法用每个局部梯度更新模型,然后计算每个节点的测试集准确率,根据测试集准确率选出一定数量最优的局部梯度完成梯度聚合。实验证明了该算法能够有效解决训练节点受到拜占庭攻击的问题,并且相对于其它算法,MAKA算法的鲁棒性更好。3.针对分布式机器学习中中心节点会受到拜占庭攻击的情况,本文提出了一种基于共识机制的拜占庭中心节点容错算法,称为IPBFT(Identifiable Practical Byzantine Fault Tolerance)。IPBFT算法能够用于联盟链中,并且能够容忍不超过K-13个恶意节点,其中K是总节点数。同时,IPBFT算法在正常情况下只选取了一部分节点参与共识,使得它的通信复杂度优于Po W、PBFT等常用共识算法,并且引入了超时机制,使得IPBFT算法能够辨别恶意中心节点。},
  annote   = {The following values have no corresponding Zotero field:SR 1A3 曹向辉PB 东南大学CL 硕士DS CNKI},
  doi      = {10.27014/d.cnki.gdnau.2021.001641},
  groups   = {Distributed Learning},
  keywords = {Blockchain, 拜占庭攻击, 差分隐私, 分布式机器学习, 分布式梯度下降, 区块链, Byzantine Attacks, Differential Privacy, Distributed Gradient Descent, Distributed Machine Learning},
  language = {中文;},
  ranking  = {rank1},
}

@Article{Breiman2000,
  author   = {Breiman, Leo},
  title    = {Pasting Bites Together For Prediction In Large Data Sets And On-Line},
  year     = {2000},
  month    = {11},
  file     = {:200011Breiman - Pasting Bites Together for Prediction in Large Data Sets and on Line.pdf:PDF},
  groups   = {Distributed Learning},
  keywords = {pasting bites, machine learning},
  ranking  = {rank4},
  url      = {https://www.stat.berkeley.edu/~breiman/pastebite.pdf},
}

@Article{Lazarevic2002,
  author   = {Lazarevic, Aleksandar and Obradovic, Zoran},
  journal  = {Distributed and Parallel Databases},
  title    = {Boosting {Algorithms} for {Parallel} and {Distributed} {Learning}},
  year     = {2002},
  issn     = {1573-7578},
  month    = mar,
  number   = {2},
  pages    = {203--229},
  volume   = {11},
  abstract = {The growing amount of available information and its distributed and heterogeneous nature has a major impact on the field of data mining. In this paper, we propose a framework for parallel and distributed boosting algorithms intended for efficient integrating specialized classifiers learned over very large, distributed and possibly heterogeneous databases that cannot fit into main computer memory. Boosting is a popular technique for constructing highly accurate classifier ensembles, where the classifiers are trained serially, with the weights on the training instances adaptively set according to the performance of previous classifiers. Our parallel boosting algorithm is designed for tightly coupled shared memory systems with a small number of processors, with an objective of achieving the maximal prediction accuracy in fewer iterations than boosting on a single processor. After all processors learn classifiers in parallel at each boosting round, they are combined according to the confidence of their prediction. Our distributed boosting algorithm is proposed primarily for learning from several disjoint data sites when the data cannot be merged together, although it can also be used for parallel learning where a massive data set is partitioned into several disjoint subsets for a more efficient analysis. At each boosting round, the proposed method combines classifiers from all sites and creates a classifier ensemble on each site. The final classifier is constructed as an ensemble of all classifier ensembles built on disjoint data sets. The new proposed methods applied to several data sets have shown that parallel boosting can achieve the same or even better prediction accuracy considerably faster than the standard sequential boosting. Results from the experiments also indicate that distributed boosting has comparable or slightly improved classification accuracy over standard boosting, while requiring much less memory and computational time since it uses smaller data sets.},
  comment  = {文中提出一种框架，可高效地通过boosting方法合并在大数据集上训练的特殊分类器，该框架的设计目标是用比单个处理器更少的迭代次数取得最大预测准确度。作者提出两种Boosting算法的变体，一种变体是适用于共享内存系统的并行化，另一种变体则是更加适合数据在不同地点分开存储的情形，是一种分布式boosing学习算法。第二种变体中，所有拥有数据的节点每个boosting轮回在本地的数据集上学习得到分类器，互相交换模型并在本地数据集上对多个模型加权集成，随后所有节点交换这些集成模型并再次集成得到最终的模型。作者通过实验证明该方法计算高效、性能与在中心化数据上使用boost算法相当甚至更好。},
  doi      = {10.1023/A:1013992203485},
  file     = {:2002MarchLazarevic - Boosting Algorithms for Parallel and Distributed Learning.pdf:PDF},
  groups   = {Distributed Learning},
  keywords = {parallel boosting, distributed boosting, heterogeneous databases},
  priority = {prio2},
  ranking  = {rank4},
}

@InProceedings{Cooper2017,
  author    = {Cooper, Jeff and Reyzin, Lev},
  booktitle = {2017 55th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
  title     = {Improved algorithms for distributed boosting},
  year      = {2017},
  pages     = {806-813},
  doi       = {10.1109/ALLERTON.2017.8262822},
  file      = {:2017Cooper - Improved Algorithms for Distributed Boosting.pdf:PDF},
  groups    = {Distributed Learning},
  keywords  = {boost, distributed learning},
  priority  = {prio3},
}

@InProceedings{Tu2018,
  author    = {Tu, Zhipeng and Wang, Yinghui and Hong, Yiguang},
  booktitle = {2018 37th Chinese Control Conference (CCC)},
  title     = {Distributed Boosting Algorithm Over Multi-agent Networks},
  year      = {2018},
  pages     = {7153-7157},
  doi       = {10.23919/ChiCC.2018.8483173},
  file      = {:2018Tu - Distributed Boosting Algorithm Over Multi Agent Networks.pdf:PDF},
  groups    = {Distributed Learning},
  keywords  = {Multi-agent systems, distributed design, boosting, classification},
  priority  = {prio3},
}





@Article{Zheng2018,
  author   = {Zheng, Zibin and Xie, Shaoan and Dai, Hong-Ning and Chen, Xiangping and Wang, Huaimin},
  journal  = {International Journal of Web and Grid Services},
  title    = {Blockchain challenges and opportunities: a survey},
  year     = {2018},
  number   = {4},
  pages    = {352-375},
  volume   = {14},
  abstract = {Blockchain has numerous benefits such as decentralisation, persistency, anonymity and auditability. There is a wide spectrum of blockchain applications ranging from cryptocurrency, financial services, risk management, internet of things (IoT) to public and social services. Although a number of studies focus on using the blockchain technology in various application aspects, there is no comprehensive survey on the blockchain technology in both technological and application perspectives. To fill this gap, we conduct a comprehensive survey on the blockchain technology. In particular, this paper gives the blockchain taxonomy, introduces typical blockchain consensus algorithms, reviews blockchain applications and discusses technical challenges as well as recent advances in tackling the challenges. Moreover, this paper also points out the future directions in the blockchain technology.},
  doi      = {10.1504/IJWGS.2018.095647},
  eprint   = {https://www.inderscienceonline.com/doi/pdf/10.1504/IJWGS.2018.095647},
  file     = {:2018Zheng - Blockchain Challenges and Opportunities_ a Survey.pdf:PDF},
  groups   = {Blockchain Surveys},
  ranking  = {rank4},
}

@Article{王飞跃2016,
  author   = {袁勇 and 王飞跃},
  journal  = {自动化学报},
  title    = {区块链技术发展现状与展望},
  year     = {2016},
  issn     = {0254-4156},
  number   = {04},
  pages    = {481-494},
  volume   = {42},
  doi      = {10.16383/j.aas.2016.c160158},
  file     = {:2016袁勇 - 区块链技术发展现状与展望.pdf:PDF},
  groups   = {Blockchain Surveys},
  keywords = {Survey, Blockchain},
  ranking  = {rank2},
}

@Article{Wang2019,
  author   = {Wang, Wenbo and Hoang, Dinh Thai and Hu, Peizhao and Xiong, Zehui and Niyato, Dusit and Wang, Ping and Wen, Yonggang and Kim, Dong In},
  journal  = {IEEE Access},
  title    = {A Survey on Consensus Mechanisms and Mining Strategy Management in Blockchain Networks},
  year     = {2019},
  pages    = {22328-22370},
  volume   = {7},
  doi      = {10.1109/ACCESS.2019.2896108},
  file     = {:2019Wang - A Survey on Consensus Mechanisms and Mining Strategy Management in Blockchain Networks.pdf:PDF},
  groups   = {Blockchain Surveys},
  keywords = {Blockchain, permissionless consensus, Byzantine fault tolerance, block mining, incentivemechanisms, game theory, P2P networks},
  ranking  = {rank1},
}

@Article{曾诗钦2020,
  author   = {曾诗钦 and 霍如 and 黄韬 and 刘江 and 汪硕 and 冯伟},
  journal  = {通信学报},
  title    = {区块链技术研究综述：原理、进展与应用},
  year     = {2020},
  issn     = {1000-436X},
  number   = {01},
  pages    = {134-151},
  volume   = {41},
  file     = {:2020曾诗钦 - 区块链技术研究综述：原理、进展与应用.pdf:PDF},
  groups   = {Blockchain Surveys},
  keywords = {Survey, Blockchain},
  ranking  = {rank1},
}

@Article{袁勇2018,
  author   = {袁勇 and 倪晓春 and 曾帅 and 王飞跃},
  journal  = {自动化学报},
  title    = {区块链共识算法的发展现状与展望},
  year     = {2018},
  issn     = {0254-4156},
  number   = {11},
  pages    = {2011-2022},
  volume   = {44},
  doi      = {10.16383/j.aas.2018.c180268},
  file     = {:2018袁勇 - 区块链共识算法的发展现状与展望.pdf:PDF},
  groups   = {Blockchain Surveys},
  keywords = {Survey, Blockchain},
  ranking  = {rank2},
}

@InProceedings{Xinyi2018,
  author    = {Xinyi, Yang and Yi, Zhang and He, Yulin},
  booktitle = {Proc. 10th Int. Conf. Commun. Softw. Networks (ICCSN'18)},
  title     = {Technical Characteristics and Model of Blockchain},
  year      = {2018},
  address   = {Chengdu, CN},
  month     = jul,
  pages     = {562-566},
  doi       = {10.1109/ICCSN.2018.8488289},
  file      = {:2018Xinyi - Technical Characteristics and Model of Blockchain.pdf:PDF},
  groups    = {Blockchain Theory},
  keywords  = {Blockchain, Bitcoin, distributed, decentralization, trustlessness, technical model},
  ranking   = {rank2},
}

@Article{Zhai2019,
  author    = {Sheping Zhai and Yuanyuan Yang and Jing Li and Cheng Qiu and Jiangming Zhao},
  journal   = {Journal of Physics: Conference Series},
  title     = {Research on the Application of Cryptography on the Blockchain},
  year      = {2019},
  month     = {feb},
  number    = {3},
  pages     = {032077},
  volume    = {1168},
  abstract  = {Blockchain is an innovative application model that integrates distributed data storage, peer-to-peer transmission, consensus mechanisms, digital encryption technology and other computer technologies. It is decentralized, secure, and Information disclosure. In the blockchain, digital encryption technology has a core position. The security of user information and transaction data is a necessary condition for the promotion of blockchain. The development of cryptography technology promotes and restricts the further development of blockchain. This paper outlines the infrastructure of blockchain, including the data layer, network layer, consensus layer, contract layer and application layer. The principles of encryption technology is introduced briefly, such as hash function, asymmetric cryptosystem, digital signature. The application of cryptography in all levels of blockchain is analyzed, including data layer, network layer, consensus layer, etc. It shows that cryptography runs through the whole blockchain system. The existing security problems of blockchain is analyzed, and the future research direction is expected.},
  doi       = {10.1088/1742-6596/1168/3/032077},
  file      = {:2019febZhai - Research on the Application of Cryptography on the Blockchain.pdf:PDF},
  groups    = {Blockchain Surveys},
  keywords  = {Blockchain, Cryptography},
  publisher = {IOP Publishing},
}

@Book{Swan2015,
  author    = {Swan, Melanie},
  publisher = {" O'Reilly Media, Inc."},
  title     = {Blockchain: Blueprint for a new economy},
  year      = {2015},
  isbn      = {978-1-491-92049-7},
  file      = {:2015Swan - Blockchain_ Blueprint for a New Economy.pdf:PDF},
  groups    = {Others,},
  keywords  = {Blockchain},
}

@Book{邱锡鹏2020,
  author    = {邱锡鹏},
  publisher = {机械工业出版社},
  title     = {神经网络与深度学习},
  year      = {2020},
  address   = {北京},
  isbn      = {9787111649687},
  file      = {:2020邱锡鹏 - 神经网络与深度学习.pdf:PDF},
  groups    = {B, Others},
  keywords  = {Neural Network, Deep Learning, Machine Learning},
}

@Article{Wang2023,
  author     = {Wang, Qin and Yu, Jiangshan and Chen, Shiping and Xiang, Yang},
  journal    = {ACM Comput. Surv.},
  title      = {SoK: DAG-Based Blockchain Systems},
  year       = {2023},
  issn       = {0360-0300},
  month      = {mar},
  number     = {12},
  volume     = {55},
  abstract   = {Limitations on high latency and low scalability of classical blockchain systems retard their adoptions and applications. Reconstructed blockchain systems have been proposed to avoid the consumption of competitive transactions caused by linear sequenced blocks. These systems, instead, structure transactions/blocks in the form of Directed Acyclic Graph (DAG) and consequently rebuild upper layer components. The promise of DAG-based blockchain systems is to enable fast confirmation (complete transactions within million seconds) and high scalability (attach transactions in parallel) without significantly compromising security. However, this field still lacks systematic work that summarises DAG techniques. To bridge the gap, this Systematization of Knowledge (SoK) provides a comprehensive analysis of ever-existing and ongoing DAG-based blockchain systems. We abstract a general model to capture the main features and identify six types of design patterns. Then, we evaluate these systems from the perspectives of structure, consensus, property, security, and performance. We further discuss the trade-off between different factors, open challenges, and the potentiality of DAG-based solutions, indicating their promising directions for future research.},
  address    = {New York, NY, USA},
  articleno  = {261},
  comment    = {对现有的基于DAG（有向无环图）的全面分析。采用DAG是为了改善链式结构区块链交易确认慢、低吞吐量、扩展性差的缺点。},
  doi        = {10.1145/3576899},
  file       = {:2023marWang - SoK_ DAG Based Blockchain Systems.pdf:PDF},
  groups     = {Blockchain Theory},
  issue_date = {December 2023},
  keywords   = {DAG-based blockchain, SoK, performance},
  numpages   = {38},
  publisher  = {Association for Computing Machinery},
  ranking    = {rank4},
}

@Article{Cao2020a,
  author   = {Bin Cao and Zhenghui Zhang and Daquan Feng and Shengli Zhang and Lei Zhang and Mugen Peng and Yun Li},
  journal  = {Digital Communications and Networks},
  title    = {Performance analysis and comparison of PoW, PoS and DAG based blockchains},
  year     = {2020},
  issn     = {2352-8648},
  number   = {4},
  pages    = {480-485},
  volume   = {6},
  abstract = {In the blockchain, the consensus mechanism plays a key role in maintaining the security and legitimation of contents recorded in the blocks. Various blockchain consensus mechanisms have been proposed. However, there is no technical analysis and comparison as a guideline to determine which type of consensus mechanism should be adopted in a specific scenario/application. To this end, this work investigates three mainstream consensus mechanisms in the blockchain, namely, Proof of Work (PoW), Proof of Stake (PoS), and Direct Acyclic Graph (DAG), and identifies their performances in terms of the average time to generate a new block, the confirmation delay, the Transaction Per Second (TPS) and the confirmation failure probability. The results show that the consensus process is affected by both network resource (computation power/coin age, buffer size) and network load conditions. In addition, it shows that PoW and PoS are more sensitive to the change of network resource while DAG is more sensitive to network load conditions.},
  doi      = {10.1016/j.dcan.2019.12.001},
  file     = {:2020Cao - Performance Analysis and Comparison of PoW, PoS and DAG Based Blockchains.pdf:PDF},
  groups   = {Blockchain Theory},
  keywords = {Blockchain, Proof of work, Proof of stake, Direct acyclic graph, Performance comparison},
  url      = {https://www.sciencedirect.com/science/article/pii/S2352864819301476},
}

@Article{Wu2022,
  author         = {Wu, Qiang and Xi, Liang and Wang, Shiren and Ji, Shan and Wang, Shenqing and Ren, Yongjun},
  journal        = {Sensors},
  title          = {Verifiable Delay Function and Its Blockchain-Related Application: A Survey},
  year           = {2022},
  issn           = {1424-8220},
  number         = {19},
  volume         = {22},
  abstract       = {The concept of verifiable delay functions has received attention from researchers since it was first proposed in 2018. The applications of verifiable delay are also widespread in blockchain research, such as: computational timestamping, public random beacons, resource-efficient blockchains, and proofs of data replication. This paper introduces the concept of verifiable delay functions and systematically summarizes the types of verifiable delay functions. Firstly, the description and characteristics of verifiable delay functions are given, and weak verifiable delay functions, incremental verifiable delay functions, decodable verifiable delay functions, and trapdoor verifiable delay functions are introduced respectively. The construction of verifiable delay functions generally relies on two security assumptions: algebraic assumption or structural assumption. Then, the security assumptions of two different verifiable delay functions are described based on cryptography theory. Secondly, a post-quantum verifiable delay function based on super-singular isogeny is introduced. Finally, the paper summarizes the blockchain-related applications of verifiable delay functions.},
  article-number = {7524},
  comment        = {如果需要了解VDF相关的信息，可以看这篇综述，写得比较全},
  doi            = {10.3390/s22197524},
  file           = {:2022Wu - Verifiable Delay Function and Its Blockchain Related Application_ a Survey.pdf:PDF},
  groups         = {B, Blockchain Surveys},
  keywords       = {verifiable delay function, blockchain, algebraic assumption, structural assumption},
  pubmedid       = {36236623},
  ranking        = {rank4},
  url            = {https://www.mdpi.com/1424-8220/22/19/7524},
}

@InProceedings{Landerreche2020,
  author    = {Landerreche, Esteban and Stevens, Marc and Schaffner, Christian},
  booktitle = {Financial Cryptography and Data Security},
  title     = {Non-interactive Cryptographic Timestamping Based on Verifiable Delay Functions},
  year      = {2020},
  address   = {Cham},
  editor    = {Bonneau, Joseph and Heninger, Nadia},
  pages     = {541--558},
  publisher = {Springer International Publishing},
  abstract  = {We present the first treatment of non-interactive publicly-verifiable timestamping schemes in the Universal Composability framework. Inspired by the timestamping properties of Bitcoin, we use non-parallelizable computational work that relates to elapsed time to avoid previous impossibility results on non-interactive timestamping. We introduce models of verifiable delay functions (VDF) related to a clock and non-interactive timestamping in the UC-framework. These are used to present a secure construction that provides improvements over previous concrete constructions. Namely, timestamps forged by the adversary are now limited to a certain time-window that depends only on the adversary's ability to compute VDFs more quickly and on the length of corruption. Finally, we discuss how our construction can be added to non-PoW blockchain protocols to prevent costless simulation attacks.},
  doi       = {10.1007/978-3-030-51280-4_29},
  file      = {:2020Landerreche - Non Interactive Cryptographic Timestamping Based on Verifiable Delay Functions.pdf:PDF},
  groups    = {Others},
  isbn      = {978-3-030-51280-4},
  keywords  = {Non-interactive cryptographic timestamping, Universal composability, Verifiable delay functions, Time-lock cryptography},
}

@InProceedings{Ephraim2020,
  author    = {Ephraim, Naomi and Freitag, Cody and Komargodski, Ilan and Pass, Rafael},
  booktitle = {Advances in Cryptology – EUROCRYPT 2020: 39th Annual International Conference on the Theory and Applications of Cryptographic Techniques, Zagreb, Croatia, May 10–14, 2020, Proceedings, Part III},
  title     = {Continuous Verifiable Delay Functions},
  year      = {2020},
  address   = {Berlin, Heidelberg},
  pages     = {125–154},
  publisher = {Springer-Verlag},
  abstract  = {We introduce the notion of a continuous verifiable delay function (cVDF): a function g which is (a) iteratively sequential—meaning that evaluating the iteration of g (on a random input) takes time roughly t times the time to evaluate g, even with many parallel processors, and (b) (iteratively) verifiable—the output of can be efficiently verified (in time that is essentially independent of t). In other words, the iterated function is a verifiable delay function (VDF) (Boneh et al., CRYPTO ’18), having the property that intermediate steps of the computation (i.e., for ) are publicly and continuously verifiable.We demonstrate that cVDFs have intriguing applications: (a) they can be used to construct that only require an initial random seed (and no further unpredictable sources of randomness), (b) enable where any part of the VDF computation can be verifiably outsourced, and (c) have deep complexity-theoretic consequences: in particular, they imply the existence of depth-robust moderately-hard Nash equilibrium problem instances, i.e. instances that can be solved in polynomial time yet require a high sequential running time.Our main result is the construction of a cVDF based on the repeated squaring assumption and the soundness of the Fiat-Shamir (FS) heuristic for . We highlight that when viewed as a (plain) VDF, our construction requires a weaker FS assumption than previous ones (earlier constructions require the FS heuristic for either super-logarithmic round proofs, or for arguments).},
  doi       = {10.1007/978-3-030-45727-3_5},
  file      = {:2020Ephraim - Continuous Verifiable Delay Functions.pdf:PDF},
  groups    = {Others},
  isbn      = {978-3-030-45726-6},
  keywords  = {VDF},
  location  = {Zagreb, Croatia},
  numpages  = {30},
}

@Article{Wesolowski2020,
  author     = {Wesolowski, Benjamin},
  journal    = {J. Cryptol.},
  title      = {Efficient Verifiable Delay Functions},
  year       = {2020},
  issn       = {0933-2790},
  month      = {oct},
  number     = {4},
  pages      = {2113–2147},
  volume     = {33},
  abstract   = {We construct a verifiable delay function (VDF). A VDF is a function whose evaluation requires running a given number of sequential steps, yet the result can be efficiently verified. They have applications in decentralised systems, such as the generation of trustworthy public randomness in a trustless environment, or resource-efficient blockchains. To construct our VDF, we actually build a trapdoor VDF. A trapdoor VDF is essentially a VDF which can be evaluated efficiently by parties who know a secret (the trapdoor). By setting up this scheme in a way that the trapdoor is unknown (not even by the party running the setup, so that there is no need for a trusted setup environment), we obtain a simple VDF. Our construction is based on groups of unknown order such as an RSA group or the class group of an imaginary quadratic field. The output of our construction is very short (the result and the proof of correctness are each a single element of the group), and the verification of correctness is very efficient.},
  address    = {Berlin, Heidelberg},
  doi        = {10.1007/s00145-020-09364-x},
  file       = {:2020octWesolowski - Efficient Verifiable Delay Functions.pdf:PDF},
  groups     = {Others},
  issue_date = {Oct 2020},
  keywords   = {RSA, Time-lock puzzle, Class group, Randomness beacon, VDF},
  numpages   = {35},
  publisher  = {Springer-Verlag},
}

@Misc{Pietrzak2018,
  author       = {Krzysztof Pietrzak},
  howpublished = {Cryptology ePrint Archive, Paper 2018/627},
  month        = apr,
  note         = {\url{https://eprint.iacr.org/2018/627}},
  title        = {Simple Verifiable Delay Functions},
  year         = {2018},
  abstract     = {We construct a verifable delay function (VDF) by showing how the Rivest-Shamir-Wagner time-lock puzzle can be made publicly verifiable.

Concretely, we give a statistically sound public-coin protocol to prove that a tuple $(N,x,T,y)$ satisfies $y=x^{2^T}\pmod N$ where the prover doesn&#39;t know the factorization of $N$ and its running time is dominated by solving the puzzle, that is, compute $x^{2^T}$, which is conjectured to require $T$ sequential squarings. To get a VDF we make this protocol non-interactive using the Fiat-Shamir heuristic.

The motivation for this work comes from the Chia blockchain design, which uses a VDF as a key ingredient. For typical parameters ($T\le 2^{40},N=2048$), our proofs are of size around $10KB$, verification cost around three RSA exponentiations and computing the proof is $8000$ times faster than solving the puzzle even without any parallelism.},
  doi          = {10.4230/LIPIcs.ITCS.2019.60},
  file         = {:2018AprilPietrzak - Simple Verifiable Delay Functions.pdf:PDF},
  groups       = {Others},
  keywords     = {Verifiable delay functions, Time-lock puzzles},
  url          = {https://eprint.iacr.org/2018/627/20190430:122513},
  version      = {20190430:122513},
}

@Article{Huang2022,
  author  = {Huang, Huawei and Kanhere, Salil and Kang, Jiawen and Xiong, Zehui and Zhang, Lei and Krishnamachari, Bhaskar and Bertino, Elisa and Yang, Sichao},
  journal = {IEEE Journal on Selected Areas in Communications},
  title   = {Guest Editorial Special Issue on Intelligent Blockchain for Future Communications and Networking: Technologies, Trends, and Applications},
  year    = {2022},
  number  = {12},
  pages   = {3299-3304},
  volume  = {40},
  doi     = {10.1109/JSAC.2022.3212898},
  file    = {:2022Huang - Guest Editorial Special Issue on Intelligent Blockchain for Future Communications and Networking_ Technologies, Trends, and Applications.pdf:PDF},
  groups  = {Blockchain Surveys},
  ranking = {rank3},
}

@Article{Cui2022,
  author   = {Cui, Laizhong and Su, Xiaoxin and Zhou, Yipeng},
  journal  = {IEEE J. Sel. Areas Commun.},
  title    = {A Fast Blockchain-Based Federated Learning Framework With Compressed Communications},
  year     = {2022},
  month    = dec,
  number   = {12},
  pages    = {3358-3372},
  volume   = {40},
  comment  = {BCFL: use the Topk algorithm to compress model updates},
  doi      = {10.1109/JSAC.2022.3213345},
  file     = {:2022DecemberCui - A Fast Blockchain Based Federated Learning Framework with Compressed Communications.pdf:PDF},
  groups   = {FL and Blockchain},
  keywords = {Federated learning, blockchain, compression,convergence},
  ranking  = {rank3},
}

@Article{张亮2019,
  author   = {张亮 and 刘百祥 and 张如意 and 江斌鑫 and 刘一江},
  journal  = {计算机工程},
  title    = {区块链技术综述},
  year     = {2019},
  issn     = {1000-3428},
  number   = {05},
  pages    = {1-12},
  volume   = {45},
  doi      = {10.19678/j.issn.1000-3428.0053554},
  file     = {:2019张亮 - 区块链技术综述.pdf:PDF},
  groups   = {Blockchain Surveys},
  keywords = {Survey, Blockchain},
  ranking  = {rank1},
}

@Article{Deng2012,
  author  = {Deng, Li},
  journal = {IEEE Signal Process. Mag.},
  title   = {The {MNIST} Database of Handwritten Digit Images for Machine Learning Research [Best of the Web]},
  year    = {2012},
  month   = nov,
  number  = {6},
  pages   = {141-142},
  volume  = {29},
  doi     = {10.1109/MSP.2012.2211477},
  file    = {:2012Deng - The MNIST Database of Handwritten Digit Images for Machine Learning Research [Best of the Web].pdf:PDF},
  groups  = {Others},
}

@InProceedings{Ma2020,
  author    = {Ma, Zhijie and Zhao, Qinglin and Yuan, Jianwen and Zhou, Xiaobo and Feng, Li},
  booktitle = {2020 IEEE International Conference on Smart Internet of Things (SmartIoT)},
  title     = {Fork Probability Analysis of PoUW Consensus Mechanism},
  year      = {2020},
  pages     = {333-337},
  doi       = {10.1109/SmartIoT49966.2020.00060},
  file      = {:2020Ma - Fork Probability Analysis of PoUW Consensus Mechanism.pdf:PDF},
  groups    = {PoUW},
}

@Book{Encyclopedia2018,
  author    = {Ling Liu and M. Tamer Özsu},
  publisher = {Springer New York},
  title     = {Encyclopedia of Database Systems},
  year      = {2018},
  address   = {NY},
  edition   = {2},
  isbn      = {978-1-4614-8265-9},
  number    = {1},
  volume    = {1},
  doi       = {10.1007/978-1-4614-8265-9},
  groups    = {Distributed Learning},
}

@InProceedings{Hoffmann2022,
  author    = {Hoffmann, Felix},
  booktitle = {2022 IEEE 1st Global Emerging Technology Blockchain Forum: Blockchain \& Beyond (iGETblockchain)},
  title     = {Challenges of Proof-of-Useful-Work (PoUW)},
  year      = {2022},
  pages     = {1-5},
  comment   = {分析了传统PoW协议的本质性质，并分析现有的PoUW系统中用以保留这些性质的措施。},
  doi       = {10.1109/iGETblockchain56591.2022.10087185},
  file      = {:2022Hoffmann - Challenges of Proof of Useful Work (PoUW).pdf:PDF;:Hoffmann2022a - Challenges of Proof of Useful Work (PoUW).pdf:PDF},
  groups    = {PoUW},
  priority  = {prio3},
  ranking   = {rank4},
}

@Book{Hastie_2009,
  author    = {Trevor Hastie and Robert Tibshirani and Jerome Friedman},
  publisher = {Springer},
  title     = {The Elements of Statistical Learning},
  year      = {2009},
  isbn      = {978-0-387-84858-7},
  doi       = {10.1007/978-0-387-84858-7},
  file      = {:2009Hastie - The Elements of Statistical Learning.pdf:PDF},
  groups    = {Distributed Learning, Others},
  keywords  = {Statistical Learning, Machine Learning},
  ranking   = {rank5},
}

@InProceedings{Ray2019,
  author    = {Ray, Susmita},
  booktitle = {2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon)},
  title     = {A Quick Review of Machine Learning Algorithms},
  year      = {2019},
  pages     = {35-39},
  comment   = {有决策树分类方法的介绍。},
  doi       = {10.1109/COMITCon.2019.8862451},
  file      = {:2019Ray - A Quick Review of Machine Learning Algorithms.pdf:PDF},
  groups    = {Others},
  keywords  = {Gradient Descent, Logistic Regression, Support Vector Machine, K Nearest Neighbor, Artificial Neural Network, Decision Tree, Back Propagation Algorithm, Bayesian Learning, Naïve Bayes},
  ranking   = {rank4},
}

@InProceedings{Abdualgalil2020,
  author    = {Abdualgalil, Bilal and Abraham, Sajimon},
  booktitle = {2020 International Conference on Emerging Trends in Information Technology and Engineering (ic-ETITE)},
  title     = {Applications of Machine Learning Algorithms and Performance Comparison: A Review},
  year      = {2020},
  pages     = {1-6},
  doi       = {10.1109/ic-ETITE47903.2020.490},
  file      = {:2020Abdualgalil - Applications of Machine Learning Algorithms and Performance Comparison_ a Review.pdf:PDF},
  groups    = {Others},
  keywords  = {Machine learning, Supervised learning, KNearest Neighbours, SVM, Prediction},
}

@InProceedings{Decker2013,
  author    = {Decker, Christian and Wattenhofer, Roger},
  booktitle = {IEEE P2P 2013 Proceedings},
  title     = {Information propagation in the Bitcoin network},
  year      = {2013},
  pages     = {1-10},
  doi       = {10.1109/P2P.2013.6688704},
  file      = {:2013Decker - Information Propagation in the Bitcoin Network.pdf:PDF},
  groups    = {Blockchain Theory},
  keywords  = {Blockchain, Bitcoin, Fork Rate,},
}

@Article{Birman2007,
  author     = {Birman, Ken},
  journal    = {SIGOPS Oper. Syst. Rev.},
  title      = {The Promise, and Limitations, of Gossip Protocols},
  year       = {2007},
  issn       = {0163-5980},
  month      = {oct},
  number     = {5},
  pages      = {8–13},
  volume     = {41},
  abstract   = {Recent years have seen a surge of interest in gossip protocols, with proposals to apply them for purposes ranging from autonomic self-management, repair of inconsistencies, reliable multicast and distributed search. Yet the field of distributed computing is littered with technologies that had initial promise, but were ultimately rejected by the industry. Researchers who measure their work through its impact need to ask some tough, basic questions. What are the uses to which gossip is particularly well-matched, and what are its limitations? What alternatives are there to gossip-based solutions, and when would we be better-off using a non-gossip protocol? When, in effect, is gossip the technology of choice?},
  address    = {New York, NY, USA},
  doi        = {10.1145/1317379.1317382},
  file       = {:2007octBirman - The Promise, and Limitations, of Gossip Protocols.pdf:PDF},
  groups     = {Others},
  issue_date = {October 2007},
  numpages   = {6},
  publisher  = {Association for Computing Machinery},
}

@Article{Saldamli2022,
  author    = {Gokay Saldamli and Charit Upadhyay and Devika Jadhav and Rohit Shrishrimal and Bapugouda Patil and Lo'ai Tawalbeh},
  journal   = {Cluster Computing},
  title     = {Improved gossip protocol for blockchain applications},
  year      = {2022},
  month     = {jan},
  number    = {3},
  pages     = {1915--1926},
  volume    = {25},
  doi       = {10.1007/s10586-021-03504-z},
  file      = {:2022janSaldamli - Improved Gossip Protocol for Blockchain Applications.pdf:PDF},
  groups    = {Others},
  keywords  = {Blockchain, Cryptocurrency, Synchronization, Convergence, Gossip protocol},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Lihu2020,
  author     = {Andrei Lihu and Jincheng Du and Igor Barjaktarevic and Patrick Gerzanics and Mark Harvilla},
  journal    = {arXiv preprint arXiv:2001.09244},
  title      = {A Proof of Useful Work for Artificial Intelligence on the Blockchain},
  year       = {2020},
  month      = jan,
  comment    = {设计了一种基于机器学习的PoUW共识协议，矿工通过进行DNN训练来获得奖励。
作者精心设计了一种PoW/PoS混合区块链，称之为PAI区块链。作者从包括环境、交易、任务、质押、协议、流程、算法等方面详细对系统进行介绍。PAI区块链是一个由六种角色的节点相互协作以保证运行的区块链。
ML的训练流程：主要参与模型训练过程的是工作节点（Working Nodes）包括矿工和监督者。矿工在Cients提交任务之前需要购买ticket（BUY_TICKETS）来获取参与训练任务的机会，借助VRF获知是否参与训练任务后发送JOIN_TASK交易。矿工通过算法1在被分配到的minibatch上迭代并与其他矿工交换训练过程中的信息，如minibatch哈希、权重更新等，在训练的过程中出块。每一次训练迭代都选出一名监督者，需要记录矿工发送的所有信息（message history），帮助矿工证明它们诚实完成机器学习任务。（速度快的矿工需要等待速度慢的矿工、消息传输的延迟、有限带宽都可能会严重降低效率，第七章提出了一些方案提升性能；虽然监督者记录了所有信息，但是要根据这些信息验证矿工的工作成本其实很高）。Clients向评估者提供测试集，2/3以上的评估者产生相同结果则达成共识，向Clients发布最优模型。
PoUW共识机制：本地模型与本地梯度链接做两次哈希产生工作量证明的nonce。为了保证挖矿节点将算力输出到ML任务中（避免矿工通过计算哈希完成工作量证明）矿工必须在提交区块的k次迭代之前提交zero-nonce block。（保证nonce 会受到训练过程中信息的影响，矿工来不及遍历timestamp的值并计算哈希）。
矿工挖出的块的验证工作委托给给验证者，根据挖出块的区块哈希选择验证者，验证者检查区块合法性、检查ticket与ML任务的有效性、根据message history判断矿工是否作弊。

激励方面，矿工得到区块奖励以及部分Client的费用，监督者与评估者收到Client奖励的一部分，验证者分得区块奖励的一部分。（不同角色之间奖励的平衡比较难把握）

在第七小节在经济、性能、安全方面进行分析。},
  eprint     = {2001.09244},
  eprinttype = {arxiv},
  file       = {:2020Lihu - A Proof of Useful Work for Artificial Intelligence on the Blockchain.pdf:PDF},
  groups     = {ML and Blockchain},
  keywords   = {Machine learning, blockchain, proof of useful work, mining, PAI coin, project PAI, artificial intelligence},
  ranking    = {rank3},
  readstatus = {read},
}

@Article{Bamakan2020,
  author   = {Seyed Mojtaba Hosseini Bamakan and Amirhossein Motavali and Alireza {Babaei Bondarti}},
  journal  = {Expert Systems with Applications},
  title    = {A survey of blockchain consensus algorithms performance evaluation criteria},
  year     = {2020},
  issn     = {0957-4174},
  pages    = {113385},
  volume   = {154},
  abstract = {How to reach an agreement in a blockchain network is a complex and important task that is defined as a consensus problem and has wide applications in reality including distributed computing, load balancing, and transaction validation in blockchains. Over recent years, many studies have been done to cope with this problem. In this paper, a comparative and analytical review on the state-of-the-art blockchain consensus algorithms is presented to enlighten the strengths and constraints of each algorithm. Based on their inherent specifications, each algorithm has a different domain of applicability that yields to propose several performance criteria for the evaluation of these algorithms. To overview and provide a basis of comparison for further work in the field, a set of incommensurable and conflicting performance evaluation criteria is identified and weighted by the pairwise comparison method. These criteria are classified into four categories including algorithms’ throughput, the profitability of mining, degree of decentralization and consensus algorithms vulnerabilities and security issues. Based on the proposed framework, the pros and cons of consensus algorithms are systematically analyzed and compared in order to provide a deep understanding of the existing research challenges and clarify the future study directions.},
  doi      = {10.1016/j.eswa.2020.113385},
  file     = {:2020Bamakan - A Survey of Blockchain Consensus Algorithms Performance Evaluation Criteria.pdf:PDF},
  groups   = {Blockchain Surveys},
  keywords = {Blockchain, Consensus algorithms, Performance evaluation criteria, Security vulnerability, Trust and permission models},
  ranking  = {rank3},
  url      = {https://www.sciencedirect.com/science/article/pii/S0957417420302098},
}

@Article{Madni2023,
  author  = {Madni, Hussain Ahmad and Umer, Rao Muhammad and Foresti, Gian Luca},
  journal = {IEEE Access},
  title   = {Blockchain-Based Swarm Learning for the Mitigation of Gradient Leakage in Federated Learning},
  year    = {2023},
  pages   = {16549-16556},
  volume  = {11},
  doi     = {10.1109/ACCESS.2023.3246126},
  file    = {:2023Madni - Blockchain Based Swarm Learning for the Mitigation of Gradient Leakage in Federated Learning.pdf:PDF},
  groups  = {FL and Blockchain},
  ranking = {rank2},
}

@Article{Males2023,
  author    = {Maleš, Uroš and Ramljak, Dušan and Jakšić Krüger, Tatjana and Davidović, Tatjana and Ostojić, Dragutin and Haridas, Abhay},
  journal   = {Symmetry},
  title     = {Controlling the Difficulty of Combinatorial Optimization Problems for Fair Proof-of-Useful-Work-Based Blockchain Consensus Protocol},
  year      = {2023},
  issn      = {2073-8994},
  month     = {Jan},
  number    = {1},
  pages     = {140},
  volume    = {15},
  doi       = {10.3390/sym15010140},
  file      = {:2023JanMaleš - Controlling the Difficulty of Combinatorial Optimization Problems for Fair Proof of Useful Work Based Blockchain Consensus Protocol.pdf:PDF},
  groups    = {Optimization and Blockchain},
  publisher = {MDPI AG},
}

@Article{Zhu2023,
  author     = {Zhu, Juncen and Cao, Jiannong and Saxena, Divya and Jiang, Shan and Ferradi, Houda},
  journal    = {ACM Computing Surveys},
  title      = {Blockchain-Empowered Federated Learning: Challenges, Solutions, and Future Directions},
  year       = {2023},
  issn       = {0360-0300},
  month      = {feb},
  number     = {11},
  volume     = {55},
  abstract   = {Federated learning is a privacy-preserving machine learning technique that trains models across multiple devices holding local data samples without exchanging them. There are many challenging issues in federated learning, such as coordinating participants’ activities, arbitrating their benefits, and aggregating models. Most existing solutions employ a centralized approach, in which a trustworthy central authority is needed for coordination. Such an approach incurs many disadvantages, including vulnerability to attacks, lack of credibility, and difficulty in calculating rewards. Recently, blockchain was identified as a potential solution for addressing the abovementioned issues. Extensive research has been conducted, and many approaches, methods, and techniques have been proposed. There is a need for a systematic survey to examine how blockchain can empower federated learning. Although there are many surveys on federated learning, few of them cover blockchain as an enabling technology. This work comprehensively surveys challenges, solutions, and future directions for blockchain-empowered federated learning (BlockFed). First, we identify the critical issues in federated learning and explain why blockchain provides a potential approach to addressing these issues. Second, we categorize existing system models into three classes: decoupled, coupled, and overlapped, according to how the federated learning and blockchain functions are integrated. Then we compare the advantages and disadvantages of these three system models, regard the disadvantages as challenging issues in BlockFed, and investigate corresponding solutions. Finally, we identify and discuss the future directions, including open problems in BlockFed.},
  address    = {New York, NY, USA},
  articleno  = {240},
  doi        = {10.1145/3570953},
  file       = {:2023febZhu - Blockchain Empowered Federated Learning_ Challenges, Solutions, and Future Directions.pdf:PDF},
  groups     = {FL and Blockchain},
  issue_date = {November 2023},
  keywords   = {incentive mechanisms, blockchain-based federated learning, client selection, federated learning, Blockchain},
  numpages   = {31},
  publisher  = {Association for Computing Machinery},
  ranking    = {rank5},
}

@Article{Shafay2023,
  author   = {Shafay, Muhammad and Ahmad, Raja Wasim and Salah, Khaled and Yaqoob, Ibrar and Jayaraman, Raja and Omar, Mohammed},
  journal  = {Cluster Computing},
  title    = {Blockchain for deep learning: review and open challenges},
  year     = {2023},
  issn     = {1573-7543},
  month    = feb,
  number   = {1},
  pages    = {197--221},
  volume   = {26},
  abstract = {Deep learning has gained huge traction in recent years because of its potential to make informed decisions. A large portion of today’s deep learning systems are based on centralized servers and fall short in providing operational transparency, traceability, reliability, security, and trusted data provenance features. Also, training deep learning models by utilizing centralized data is vulnerable to the single point of failure problem. In this paper, we explore the importance of integrating blockchain technology with deep learning. We review the existing literature focused on the integration of blockchain with deep learning. We classify and categorize the literature by devising a thematic taxonomy based on seven parameters; namely, blockchain type, deep learning models, deep learning specific consensus protocols, application area, services, data types, and deployment goals. We provide insightful discussions on the state-of-the-art blockchain-based deep learning frameworks by highlighting their strengths and weaknesses. Furthermore, we compare the existing blockchain-based deep learning frameworks based on four parameters such as blockchain type, consensus protocol, deep learning method, and dataset. Finally, we present important research challenges which need to be addressed to develop highly trustworthy deep learning frameworks.},
  doi      = {10.1007/s10586-022-03582-7},
  file     = {:2023FebruaryShafay - Blockchain for Deep Learning_ Review and Open Challenges.pdf:PDF},
  groups   = {ML and Blockchain},
  priority = {prio3},
}

@InProceedings{Merlina2019,
  author    = {Merlina, Andrea},
  booktitle = {Proceedings of the 20th International Middleware Conference Doctoral Symposium},
  title     = {BlockML: A Useful Proof of Work System Based on Machine Learning Tasks},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {6–8},
  publisher = {Association for Computing Machinery},
  series    = {Middleware '19},
  abstract  = {The computation required by permissionless blockchains to securely moderate the block proposal rate is wasteful both in terms of energy and computation. We present BlockML, an alternative system that replaces Bitcoin's crypto puzzle with the training of Machine Learning (ML) models, providing a useful side product to the consensus protocol of permissionless blockchains.},
  doi       = {10.1145/3366624.3368156},
  file      = {:2019Merlina - BlockML_ a Useful Proof of Work System Based on Machine Learning Tasks.pdf:PDF},
  groups    = {ML and Blockchain},
  isbn      = {9781450370394},
  keywords  = {machine learning, useful proof of work, blockchain},
  location  = {Davis, California},
  numpages  = {3},
}

@Article{Yuksel2012,
  author  = {Yuksel, Seniha Esen and Wilson, Joseph N. and Gader, Paul D.},
  journal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title   = {Twenty Years of Mixture of Experts},
  year    = {2012},
  month   = aug,
  number  = {8},
  pages   = {1177-1193},
  volume  = {23},
  doi     = {10.1109/TNNLS.2012.2200299},
  file    = {:2012Yuksel - Twenty Years of Mixture of Experts.pdf:PDF},
  groups  = {Mixture of Experts},
}

@Article{Masoudnia2014,
  author   = {Masoudnia, Saeed and Ebrahimpour, Reza},
  journal  = {Artificial Intelligence Review},
  title    = {Mixture of experts: a literature survey},
  year     = {2014},
  issn     = {1573-7462},
  month    = aug,
  number   = {2},
  pages    = {275--293},
  volume   = {42},
  abstract = {Mixture of experts (ME) is one of the most popular and interesting combining methods, which has great potential to improve performance in machine learning. ME is established based on the divide-and-conquer principle in which the problem space is divided between a few neural network experts, supervised by a gating network. In earlier works on ME, different strategies were developed to divide the problem space between the experts. To survey and analyse these methods more clearly, we present a categorisation of the ME literature based on this difference. Various ME implementations were classified into two groups, according to the partitioning strategies used and both how and when the gating network is involved in the partitioning and combining procedures. In the first group, The conventional ME and the extensions of this method stochastically partition the problem space into a number of subspaces using a special employed error function, and experts become specialised in each subspace. In the second group, the problem space is explicitly partitioned by the clustering method before the experts’ training process starts, and each expert is then assigned to one of these sub-spaces. Based on the implicit problem space partitioning using a tacit competitive process between the experts, we call the first group the mixture of implicitly localised experts (MILE), and the second group is called mixture of explicitly localised experts (MELE), as it uses pre-specified clusters. The properties of both groups are investigated in comparison with each other. Investigation of MILE versus MELE, discussing the advantages and disadvantages of each group, showed that the two approaches have complementary features. Moreover, the features of the ME method are compared with other popular combining methods, including boosting and negative correlation learning methods. As the investigated methods have complementary strengths and limitations, previous researches that attempted to combine their features in integrated approaches are reviewed and, moreover, some suggestions are proposed for future research directions.},
  doi      = {10.1007/s10462-012-9338-y},
  file     = {:2014AugustMasoudnia - Mixture of Experts_ a Literature Survey.pdf:PDF},
  groups   = {Mixture of Experts},
}

@InProceedings{Toyoda2019,
  author    = {Toyoda, Kentaroh and Zhang, Allan N.},
  booktitle = {Proc. 2019 IEEE Int. Conf. Big Data},
  title     = {Mechanism Design for An Incentive-aware Blockchain-enabled Federated Learning Platform},
  year      = {2019},
  address   = {Los Angeles, CA, USA},
  month     = dec,
  pages     = {395-403},
  abstract  = {Recent technological evolution enables Artificial Intelligence (AI) model training by users' mobile devices, which accelerates decentralized big data analysis. In particular, Federated Learning (FL) is a key enabler to realize decentralized AI model update without user's privacy disclosure. However, since the behaviour of workers, who are assigned a training task, cannot be monitored, the state-of-the-art methods require a special hardware and/or cryptography to force the workers behave honestly, which hinders the realization. Furthermore, although blockchain-enabled FL has been proposed to give workers reward, any rigorous reward policy design has not been discussed. In this paper, to tackle these issues, we present a novel method using mechanism design, which is an economic approach to realize desired objectives under the situation that participants act rationally. The key idea is to introduce repeated competition for FL so that any rational worker follows the protocol and maximize their profits. With mechanism design, we propose a generic full-fledged protocol design for FL on a public blockchain. We also theoretically clarify incentive compatibility based on contest theory which is an auction-based game theory in economics.},
  comment   = {The authors propose a FL framework based on public blockchain ledger. They alleged it could be implemented in existing public blockchain system(e.g. etherum) with smart contract. They outlined the working procedures of the system. They put emphasis on the system's advantage over existing schemes that it could enable requestors to monitor workers and rewards are distributed fairly.
There 're some issues to be solved	(many details of the protocol are to be outlined).},
  doi       = {10.1109/BigData47090.2019.9006344},
  file      = {:2019DecToyoda - Mechanism Design for an Incentive Aware Blockchain Enabled Federated Learning Platform.pdf:PDF},
  groups    = {FL and Blockchain},
  ranking   = {rank3},
}

@Misc{Chhetri2023,
  author        = {Bipin Chhetri and Saroj Gopali and Rukayat Olapojoye and Samin Dehbash and Akbar Siami Namin},
  title         = {A Survey on Blockchain-Based Federated Learning and Data Privacy},
  year          = {2023},
  archiveprefix = {arXiv},
  comment       = {Introduce the essential components and underlying principles of the Blockchain based federated learning schemes and give a review of existing literature based on different privacy preserving techniques.},
  eprint        = {2306.17338},
  file          = {:2023Chhetri - A Survey on Blockchain Based Federated Learning and Data Privacy.pdf:PDF},
  groups        = {FL and Blockchain},
  primaryclass  = {cs.LG},
  ranking       = {rank3},
}

@Article{Miao2022,
  author   = {Miao, Yinbin and Liu, Ziteng and Li, Hongwei and Choo, Kim-Kwang Raymond and Deng, Robert H.},
  journal  = {IEEE Transactions on Information Forensics and Security},
  title    = {Privacy-Preserving Byzantine-Robust Federated Learning via Blockchain Systems},
  year     = {2022},
  issn     = {1556-6021},
  pages    = {2848-2861},
  volume   = {17},
  abstract = {Federated learning enables clients to train a machine learning model jointly without sharing their local data. However, due to the centrality of federated learning framework and the untrustworthiness of clients, traditional federated learning solutions are vulnerable to poisoning attacks from malicious clients and servers. In this paper, we aim to mitigate the impact of the central server and malicious clients by designing a Privacy-preserving Byzantine-robust Federated Learning (PBFL) scheme based on blockchain. Specifically, we use cosine similarity to judge the malicious gradients uploaded by malicious clients. Then, we adopt fully homomorphic encryption to provide secure aggregation. Finally, we use blockchain system to facilitate transparent processes and implementation of regulations. Our formal analysis proves that our scheme achieves convergence and provides privacy protection. Our extensive experiments on different datasets demonstrate that our scheme is robust and efficient. Even if the root dataset is small, our scheme can achieve the same efficiency as FedSGD.},
  comment  = {adopt cosine similarity to compare local trusted gradient updates at server with updates from clients to identify malicious gradients.
Blockchain is used to make the whole process transparant},
  doi      = {10.1109/TIFS.2022.3196274},
  file     = {:2022Miao - Privacy Preserving Byzantine Robust Federated Learning Via Blockchain Systems.pdf:PDF},
  groups   = {FL and Blockchain},
  ranking  = {rank3},
}

@InProceedings{Kucharavy2023,
  author    = {Kucharavy, Andrei and Monti, Matteo and Guerraoui, Rachid and Dolamic, Ljiljana},
  booktitle = {Proceedings of the Companion Conference on Genetic and Evolutionary Computation},
  title     = {Byzantine-Resilient Learning Beyond Gradients: Distributing Evolutionary Search},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {295–298},
  publisher = {Association for Computing Machinery},
  series    = {GECCO '23 Companion},
  abstract  = {Modern machine learning (ML) models are capable of impressive performances. However, their prowess is not due only to the improvements in their architecture and training algorithms but also to a drastic increase in computational power used to train them.Such a drastic increase led to a growing interest in distributed ML, which in turn made worker failures and adversarial attacks an increasingly pressing concern. While distributed byzantine resilient algorithms have been proposed in a differentiable setting, none exist in a gradient-free setting.The goal of this work is to address this shortcoming. For that, we introduce a more general definition of byzantine-resilience in ML - the model-consensus, that extends the definition of the classical distributed consensus. We then leverage this definition to show that a general class of gradient-free ML algorithms - (1, λ)-Evolutionary Search - can be combined with classical distributed consensus algorithms to generate gradient-free byzantine-resilient distributed learning algorithms. We provide proofs and pseudo-code for two specific cases - the Total Order Broadcast and proof-of-work leader election.To our knowledge, this is the first time a byzantine resilience in gradient-free ML was defined, and algorithms to achieve it - were proposed.},
  doi       = {10.1145/3583133.3590719},
  file      = {:2023Kucharavy - Byzantine Resilient Learning beyond Gradients_ Distributing Evolutionary Search.pdf:PDF},
  groups    = {ML and Blockchain},
  isbn      = {9798400701207},
  keywords  = {byzantine fault tolerance, gradient-free optimization, distributed machine learning, evolutionary search},
  location  = {Lisbon, Portugal},
  numpages  = {4},
}

@Article{Li2018,
  author  = {Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  journal = {Advances in neural information processing systems},
  title   = {Visualizing the loss landscape of neural nets},
  year    = {2018},
  volume  = {31},
  file    = {:2018Li - Visualizing the Loss Landscape of Neural Nets.pdf:PDF},
  groups  = {Others},
  url     = {https://proceedings.neurips.cc/paper_files/paper/2018/file/a41b3bb3e6b050b6c9067c67f663b915-Paper.pdf},
}

@Article{Dai2019a,
  author  = {Dai, Yueyue and Xu, Du and Maharjan, Sabita and Chen, Zhuang and He, Qian and Zhang, Yan},
  journal = {IEEE Network},
  title   = {Blockchain and Deep Reinforcement Learning Empowered Intelligent 5G Beyond},
  year    = {2019},
  number  = {3},
  pages   = {10-17},
  volume  = {33},
  comment = {In this paper, blockchain and AI is intergrated to improve the performance of wireless networks.
Contributions:
1. secure and intelligent architecture for next-generation wireless networks.
2. a D2D content caching scheme with reinforcement learning techniques utilized to maximize system utility.},
  doi     = {10.1109/MNET.2019.1800376},
  file    = {:2019Dai - Blockchain and Deep Reinforcement Learning Empowered Intelligent 5G beyond.pdf:PDF},
  groups  = {RL and Blockchain},
  ranking = {rank2},
}

@InProceedings{Shoker2017,
  author    = {Shoker, Ali},
  booktitle = {2017 IEEE 16th International Symposium on Network Computing and Applications (NCA)},
  title     = {Sustainable blockchain through proof of exercise},
  year      = {2017},
  pages     = {1-9},
  comment   = {In this piece of work, authors devise a proof of useful work consensus replacing useless hashing puzzles with scientific matrix computation.},
  doi       = {10.1109/NCA.2017.8171383},
  file      = {:2017Shoker - Sustainable Blockchain through Proof of Exercise.pdf:PDF},
  groups    = {ML and Blockchain},
  ranking   = {rank3},
}

@Article{Forero2010,
  author     = {Forero, Pedro A. and Cano, Alfonso and Giannakis, Georgios B.},
  journal    = {J. Mach. Learn. Res.},
  title      = {Consensus-Based Distributed Support Vector Machines},
  year       = {2010},
  issn       = {1532-4435},
  month      = {aug},
  pages      = {1663–1707},
  volume     = {11},
  abstract   = {This paper develops algorithms to train support vector machines when training data are distributed across different nodes, and their communication to a centralized processing unit is prohibited due to, for example, communication complexity, scalability, or privacy reasons. To accomplish this goal, the centralized linear SVM problem is cast as a set of decentralized convex optimization sub-problems (one per node) with consensus constraints on the wanted classifier parameters. Using the alternating direction method of multipliers, fully distributed training algorithms are obtained without exchanging training data among nodes. Different from existing incremental approaches, the overhead associated with inter-node communications is fixed and solely dependent on the network topology rather than the size of the training sets available per node. Important generalizations to train nonlinear SVMs in a distributed fashion are also developed along with sequential variants capable of online processing. Simulated tests illustrate the performance of the novel algorithms.},
  comment    = {A fully distributed SVM is proposed, with communication overhead only related to network topology, better scalability than centralized methods as well as robustness to node failure and noisy inter-node communications. Despite those advantages, such algorithm guarantees convergence to centralized SVM performance. Distributed SVM problems are tackled by decompositing centralized SVM problems into decentralized convex optimization subproblems and then applying consensus constraints to those problems.},
  doi        = {10.5555/1756006.1859906},
  file       = {:2010augForero - Consensus Based Distributed Support Vector Machines.pdf:PDF},
  groups     = {Distributed Learning},
  issue_date = {3/1/2010},
  numpages   = {45},
  publisher  = {JMLR.org},
  ranking    = {rank4},
}

@Misc{Chatterjee2023,
  author        = {Diptendu Chatterjee and Prabal Banerjee and Subhra Mazumdar},
  title         = {Chrisimos: A useful Proof-of-Work for finding Minimal Dominating Set of a graph},
  year          = {2023},
  archiveprefix = {arXiv},
  comment       = {a new PoUW scheme in which the useful work is to find a minimal dominating set for real-life graph instances. New fork selection rule used.},
  eprint        = {2308.04407},
  file          = {:2023Chatterjee - Chrisimos_ a Useful Proof of Work for Finding Minimal Dominating Set of a Graph.pdf:PDF},
  groups        = {Optimization and Blockchain},
  primaryclass  = {cs.CR},
  ranking       = {rank3},
}

@InProceedings{Chaurasia2021,
  author    = {Chaurasia, Yash and Subramanian, Visvesh and Gujar, Sujit},
  booktitle = {2021 IEEE International Conference on Blockchain (Blockchain)},
  title     = {PUPoW: A Framework for Designing Blockchains with Practically-Useful-Proof-of-Work & VanityCoin},
  year      = {2021},
  pages     = {122-129},
  doi       = {10.1109/Blockchain53845.2021.00026},
  file      = {:2021Chaurasia - PUPoW_ a Framework for Designing Blockchains with Practically Useful Proof of Work & VanityCoin.pdf:PDF},
  groups    = {PoUW},
  ranking   = {rank2},
}

@InProceedings{BravoMarquez2019,
  author     = {Bravo-Marquez, Felipe and Reeves, Steve and Ugarte, Martín},
  booktitle  = {Proc. 2019 IEEE Int. Conf. Decentralized Appl. Infrastruct. (DAPPCON)},
  title      = {Proof-of-Learning: A Blockchain Consensus Mechanism Based on Machine Learning Competitions},
  year       = {2019},
  address    = {Newark, CA, USA},
  month      = apr,
  pages      = {119-124},
  abstract   = {This article presents WekaCoin, a peer-to-peer learning models and experiments will be beneficial to the
cryptocurrency based on a new distributed consensus protocol whole of society.
called Proof-of-Learning. Proof-of-learning achieves distributed WekaCoin nodes operate in a peer-to-peer network where
consensus by ranking machine learning systems for a given
task. The aim of this protocol is to alleviate the computational a group of nodes called “trainers” submit machine learning
waste involved in hashing-based puzzles and to create a public models for tasks that were previously published by other nodes
distributed and verifiable database of state-of-the-art machine in the network called “suppliers”. These models are executed
learning models and experiments. on data that was not observed by the trainers during training},
  comment    = {介绍WekaCoin的共识机制PoL，通过这一机制可以完全将算力用于有意义的模型训练中，但是需要以一个可以接受的速率保证机器学习任务的供给。
该共识机制中设计了三种交易类型，分别为标准交易、任务发布交易与模型交易，共识中涉及三种角色：supplier、trainer、validator。
supplier是提供机器学习竞赛的平台，需要通过任务发布交易发布机器学习任务。在任务发布交易中除了任务信息还包含了报酬以及发布测试集的区块高度。supplier必须及时在区块链达到约定的区块高度之后发布测试集，之后从validator处得到模型。
trainer选择一个任务进行训练，通过模型交易支付参与费并将训练好的模型的哈希值注册在区块链上，并在supplier发布测试数据之后将模型数据上传。（没有办法避免其他节点得到模型哈希值之后抢先注册在区块链上）
validator根据trainer提交的模型交易中的哈希值在IPFS上下载模型，并在supplier提供的测试数据上评估该模型。之后根据性能指标产生候选排行表，产生新块。最后通过流言协议将新块和候选排行发送给其他验证者。验证者之间相互验证，得到“真”候选排行。最后validator合并候选排行和候选块，在一定次数的迭代之后得到共识区块和共识排行。（通过VRF实现加密货币抽签，确定委员会成员；通过存储证明方法对每个节点加权，被选择的可能性与节点存储的数据集、模型的容量成比例，但是这两点似乎没有体现在验证过程中。）
最后在区块提交阶段在区块中添加交易完成激励的分配。任务奖励分配给排名最高的trainer，任务主持费用平均分配给所有有效的validator，排名前25%的trainer返还任务参与费而剩余的参与费平均分配给validator，新的weka币平分给所有有效validator。（这种分配方式可能无法对trainer产生足够激励。）

(nodes plays a particular role voluntarily?)},
  doi        = {10.1109/DAPPCON.2019.00023},
  file       = {:2019Bravo-Marquez - Proof of Learning_ a Blockchain Consensus Mechanism Based on Machine Learning Competitions.pdf:PDF},
  groups     = {ML and Blockchain},
  keywords   = {Machine learning, Task analysis, Blockchain, Protocols, Data models, Training, Bitcoin},
  priority   = {prio3},
  ranking    = {rank4},
  readstatus = {read},
}

@Misc{Rambhatla2021,
  author        = {Sai Saketh Rambhatla and Michael Jones and Rama Chellappa},
  title         = {To Boost or not to Boost: On the Limits of Boosted Neural Networks},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2107.13600},
  file          = {:2021Rambhatla - To Boost or Not to Boost_ on the Limits of Boosted Neural Networks.pdf:PDF},
  groups        = {Others},
  primaryclass  = {cs.LG},
}

@Misc{Dotan2021,
  author        = {Maya Dotan and Saar Tochner},
  month         = jul,
  title         = {Proofs of Useless Work -- Positive and Negative Results for Wasteless Mining Systems},
  year          = {2021},
  abstract      = {Many blockchain systems today, including Bitcoin, rely on Proof of Work (PoW). Proof of work is crucial to the liveness and security of cryptocurrencies. The assumption when using PoW is that a lot of trial and error is required on average before a valid block is generated. One of the main concerns raised with regard to this kind of system is the inherent need to "waste" energy on "meaningless" problems. In fact, the Bitcoin system is believed to consume more electricity than several small countries. In this work we formally define three properties that are necessary for wasteless PoW systems: (1) solve "meaningful" problems (2) solve them efficiently and (3) be secure against double-spend attacks. These properties aim to create an open market for problem-solving, in which miners produce solutions to problems in the most efficient way (wasteless). The security of the system stems from the economical incentive created by the demand for solutions to these problems. We analyze these properties, and deduce constraints that must apply to such PoW systems. In our main result, we conclude that under realistic assumptions, the set of allowed problems must be preimage resistant functions in order to keep the system secure and efficient.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2007.01046},
  eprint        = {2007.01046},
  file          = {:2021JulyDotan - Proofs of Useless Work Positive and Negative Results for Wasteless Mining Systems.pdf:PDF},
  groups        = {Optimization and Blockchain},
  keywords      = {Cryptography and Security (cs.CR), Distributed / Parallel / Cluster Computing (cs.DC), Multiagent Systems (cs.MA), FOS: Computer and information sciences},
  primaryclass  = {cs.CR},
  publisher     = {arXiv},
}

@Misc{Krizhevsky2009,
  author  = {Alex Krizhevsky},
  title   = {Learning Multiple Layers of Features from Tiny Images},
  year    = {2009},
  comment = {cifar10
cifar100},
  file    = {:2009Krizhevsky - Learning Multiple Layers of Features from Tiny Images.pdf:PDF},
  groups  = {Others},
  url     = {https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf},
}

@InProceedings{Zeng2023,
  author    = {Zeng, Guobing and Zhang, Ronghui and Gao, Ning and Wu, Sheng and Jiang, Chunxiao and Jing, Xiaojun},
  booktitle = {ICC 2023 - IEEE International Conference on Communications},
  title     = {An Attack-Resistant Federated Edge Learning Framework for Integrated Sensing, Computing and Communications System},
  year      = {2023},
  pages     = {547-552},
  doi       = {10.1109/ICC45041.2023.10278723},
  file      = {:2023Zeng - An Attack Resistant Federated Edge Learning Framework for Integrated Sensing, Computing and Communications System.pdf:PDF},
  groups    = {FL and Blockchain},
  ranking   = {rank3},
}

@Misc{Im2017,
  author        = {Daniel Jiwoong Im and Michael Tao and Kristin Branson},
  title         = {An empirical analysis of the optimization of deep network loss surfaces},
  year          = {2017},
  archiveprefix = {arXiv},
  eprint        = {1612.04010},
  file          = {:2017Im - An Empirical Analysis of the Optimization of Deep Network Loss Surfaces.pdf:PDF},
  groups        = {Others},
  primaryclass  = {cs.LG},
}

Related Material

[pdf] [bibtex]
@InProceedings{Szegedy2015,
  author    = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle = {Proc. 2015 IEEE Conf. Comput. Vision Pattern Recognit. (CVPR)},
  title     = {Going Deeper With Convolutions},
  year      = {2015},
  address   = {Boston, MA, USA},
  month     = jun,
  doi       = {10.1109/cvpr.2015.7298594},
  file      = {:2015JuneSzegedy - Going Deeper with Convolutions.pdf:PDF},
  groups    = {Others},
}

@Article{Kohli2023,
  author   = {Varun Kohli and Sombuddha Chakravarty and Vinay Chamola and Kuldip Singh Sangwan and Sherali Zeadally},
  journal  = {Digital Communications and Networks},
  title    = {An analysis of energy consumption and carbon footprints of cryptocurrencies and possible solutions},
  year     = {2023},
  issn     = {2352-8648},
  number   = {1},
  pages    = {79-89},
  volume   = {9},
  abstract = {There is an urgent need to control global warming caused by humans to achieve a sustainable future. CO2 levels are rising steadily, and while countries worldwide are actively moving toward the sustainability goals proposed during the Paris Agreement in 2015, we are still a long way to go from achieving a sustainable mode of global operation. The increased popularity of cryptocurrencies since the introduction of Bitcoin in 2009 has been accompanied by an increasing trend in greenhouse gas emissions and high electrical energy consumption. Popular energy tracking studies (e.g., Digiconomist and the Cambridge Bitcoin Energy Consumption Index (CBECI)) have estimated energy consumption ranges from 29.96 ​TWh to 135.12 ​TWh and 26.41 ​TWh to 176.98 ​TWh, respectively for Bitcoin as of July 2021, which are equivalent to the energy consumption of countries such as Sweden and Thailand. The latest estimate by Digiconomist on carbon footprints shows a 64.18 MtCO2 emission by Bitcoin as of July 2021, close to the emissions by Greece and Oman. This review compiles estimates made by various studies from 2018 to 2021. We compare the energy consumption and carbon footprints of these cryptocurrencies with countries around the world and centralized transaction methods such as Visa. We identify the problems associated with cryptocurrencies and propose solutions that can help reduce their energy consumption and carbon footprints. Finally, we present case studies on cryptocurrency networks, namely, Ethereum 2.0 and Pi Network, with a discussion on how they can solve some of the challenges we have identified.},
  doi      = {https://doi.org/10.1016/j.dcan.2022.06.017},
  file     = {:2023Kohli - An Analysis of Energy Consumption and Carbon Footprints of Cryptocurrencies and Possible Solutions.pdf:PDF},
  groups   = {Others},
  keywords = {Blockchain, Carbon footprint, Climate change, Cryptocurrency, Sustainability},
  url      = {https://www.sciencedirect.com/science/article/pii/S2352864822001390},
}

@Electronic{Cambridge,
  author      = {{Cambridge Centre for Alternative Finance}},
  note        = {accessed: Feb. 28, 2024},
  title       = {Cambridge bitcoin electricity consumption index},
  url         = {https://ccaf.io/cbnsi/cbeci},
  groups      = {Others},
  lastchecked = {18.02.2024},
}

@InProceedings{Gervais2016,
  author    = {Gervais, Arthur and Karame, Ghassan O. and W\"{u}st, Karl and Glykantzis, Vasileios and Ritzdorf, Hubert and Capkun, Srdjan},
  booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
  title     = {On the Security and Performance of Proof of Work Blockchains},
  year      = {2016},
  address   = {New York, NY, USA},
  pages     = {3–16},
  publisher = {Association for Computing Machinery},
  series    = {CCS '16},
  abstract  = {Proof of Work (PoW) powered blockchains currently account for more than 90\% of the total market capitalization of existing digital cryptocurrencies. Although the security provisions of Bitcoin have been thoroughly analysed, the security guarantees of variant (forked) PoW blockchains (which were instantiated with different parameters) have not received much attention in the literature. This opens the question whether existing security analysis of Bitcoin's PoW applies to other implementations which have been instantiated with different consensus and/or network parameters.In this paper, we introduce a novel quantitative framework to analyse the security and performance implications of various consensus and network parameters of PoW blockchains. Based on our framework, we devise optimal adversarial strategies for double-spending and selfish mining while taking into account real world constraints such as network propagation, different block sizes, block generation intervals, information propagation mechanism, and the impact of eclipse attacks. Our framework therefore allows us to capture existing PoW-based deployments as well as PoW blockchain variants that are instantiated with different parameters, and to objectively compare the tradeoffs between their performance and security provisions.},
  doi       = {10.1145/2976749.2978341},
  file      = {:2016Gervais - On the Security and Performance of Proof of Work Blockchains.pdf:PDF},
  groups    = {Blockchain Simulator},
  isbn      = {9781450341394},
  keywords  = {bitcoin, blockchain, performance, security},
  location  = {Vienna, Austria},
  numpages  = {14},
  url       = {https://doi.org/10.1145/2976749.2978341},
}

@Article{Alharby2020,
  author   = {Alharby, Maher and van Moorsel, Aad},
  journal  = {Frontiers in Blockchain},
  title    = {BlockSim: An Extensible Simulation Tool for Blockchain Systems},
  year     = {2020},
  issn     = {2624-7852},
  volume   = {3},
  abstract = {Both in the design and deployment of blockchain solutions many performance-impacting configuration choices need to be made. We introduce BlockSim, a framework and software tool to build and simulate discrete-event dynamic systems models for blockchain systems. BlockSim is designed to support the analysis of a large variety of blockchains and blockchain deployments as well as a wide set of analysis questions. At the core of BlockSim is a Base Model, which contains the main model constructs common across various blockchain systems organized in three abstraction layers (network, consensus, and incentives layer). The Base Model is usable for a wide variety of blockchain systems and can be extended easily to include system or deployment particulars. The BlockSim software tool provides a simulator that implements the Base Model in Python. The paper describes the Base Model, the simulator implementation, and the application of BlockSim to Bitcoin, Ethereum and other consensus algorithms. We validate BlockSim simulation results by comparison with performance results from actual systems and from other studies in the literature. We close the paper by a BlockSim simulation study of the impact of uncle blocks rewards on mining decentralization, for a variety of blockchain configurations.},
  doi      = {10.3389/fbloc.2020.00028},
  file     = {:2020Alharby - BlockSim_ an Extensible Simulation Tool for Blockchain Systems.pdf:PDF},
  groups   = {Blockchain Simulator},
  url      = {https://www.frontiersin.org/articles/10.3389/fbloc.2020.00028},
}

@InProceedings{Netzer2012,
  author    = {Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Baolin and Ng, Andrew Y and others},
  booktitle = {NIPS 2011 Workshop Deep Learn. Unsupervised Feature Learn.},
  title     = {Reading Digits in Natural Images with Unsupervised Feature Learning},
  year      = {2011},
  address   = {Granada, ES},
  month     = dec,
  pages     = {1-9},
  comment   = {SVHN
不确定是否有论文集出版},
  file      = {:2011DecemberNetzer - Reading Digits in Natural Images with Unsupervised Feature Learning.pdf:PDF},
  groups    = {Others},
  intype    = {presented at the},
}

@InProceedings{Pass2017,
  author    = {Pass, Rafael and Seeman, Lior and Shelat, Abhi},
  booktitle = {Advances in Cryptology -- EUROCRYPT 2017},
  title     = {Analysis of the Blockchain Protocol in Asynchronous Networks},
  year      = {2017},
  address   = {Cham},
  editor    = {Coron, Jean-S{\'e}bastien and Nielsen, Jesper Buus},
  pages     = {643--673},
  publisher = {Springer International Publishing},
  abstract  = {Nakamoto's famous blockchain protocol enables achieving consensus in a so-called permissionless setting---anyone can join (or leave) the protocol execution, and the protocol instructions do not depend on the identities of the players. His ingenious protocol prevents ``sybil attacks'' (where an adversary spawns any number of new players) by relying on computational puzzles (a.k.a. ``moderately hard functions'') introduced by Dwork and Naor (Crypto'92).},
  comment   = {Bitcoin Backbone Protocol的后续工作

笔记：https://blog.csdn.net/qq_44026293/article/details/126015629},
  file      = {:2017Pass - Analysis of the Blockchain Protocol in Asynchronous Networks.pdf:PDF},
  groups    = {Blockchain Theory},
  isbn      = {978-3-319-56614-6},
  priority  = {prio2},
  ranking   = {rank5},
}

@Article{Xu2023jul,
  author     = {Xu, Jie and Wang, Cong and Jia, Xiaohua},
  journal    = {ACM Comput. Surv.},
  title      = {A Survey of Blockchain Consensus Protocols},
  year       = {2023},
  issn       = {0360-0300},
  month      = jul,
  number     = {13s},
  pages      = {1-35},
  volume     = {55},
  abstract   = {Blockchain consensus protocols have been a focus of attention since the advent of Bitcoin. Although classic distributed consensus algorithms made significant contributions to the development of blockchain consensus protocols, there are still many issues to be resolved due to the complexity and diversity of the blockchain. In this survey, we summarize the state-of-the-art blockchain consensus protocols. We first introduce the theoretical basis, models, and challenges of blockchain consensus protocols. Then, we present the existing blockchain protocols in the categories of proof-based protocols, committee-based protocols, and other miscellaneous protocols. Finally, we analyze their performance and discuss future research directions by comparing existing protocols.},
  address    = {New York, NY, USA},
  articleno  = {278},
  doi        = {10.1145/3579845},
  file       = {:2023julXu - A Survey of Blockchain Consensus Protocols.pdf:PDF},
  groups     = {Blockchain Surveys},
  issue_date = {December 2023},
  keywords   = {Blockchain consensus, cryptocurrency, security, scalability, decentralization},
  numpages   = {35},
  publisher  = {Association for Computing Machinery},
  ranking    = {rank5},
}

@Article{Yue2021,
  author   = {Yue, Kaifeng and Zhang, Yuanyuan and Chen, Yanru and Li, Yang and Zhao, Lian and Rong, Chunming and Chen, Liangyin},
  journal  = {IEEE Commun. Surveys Tut.},
  title    = {A Survey of Decentralizing Applications via Blockchain: The {5G} and Beyond Perspective},
  year     = {2021},
  month    = {4th Quart.},
  number   = {4},
  pages    = {2191-2217},
  volume   = {23},
  doi      = {10.1109/COMST.2021.3115797},
  file     = {:2021Yue - A Survey of Decentralizing Applications Via Blockchain_ the 5G and beyond Perspective.pdf:PDF},
  groups   = {Blockchain Surveys},
  keywords = {Blockchains,5G mobile communication,Security,Privacy,Smart contracts,Tutorials,Technological innovation,Blockchain,decentralize,DApp,5G and beyond,permissionless blockchain,permissioned blockchain},
}

@InProceedings{He2016,
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle = {Proc. 29th IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR'16)},
  title     = {Deep Residual Learning for Image Recognition},
  year      = {2016},
  address   = {Las Vegas, NV, USA},
  month     = jun,
  pages     = {770-778},
  comment   = {ResNet},
  doi       = {10.1109/CVPR.2016.90},
  file      = {:2016He - Deep Residual Learning for Image Recognition.pdf:PDF},
  groups    = {Others},
  keywords  = {Training,Degradation,Complexity theory,Image recognition,Neural networks,Visualization,Image segmentation},
}

@Article{Lecun1998,
  author   = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal  = {Proc. IEEE},
  title    = {Gradient-based learning applied to document recognition},
  year     = {1998},
  month    = nov,
  number   = {11},
  pages    = {2278-2324},
  volume   = {86},
  comment  = {LeNet},
  doi      = {10.1109/5.726791},
  file     = {:1998NovemberLecun - Gradient Based Learning Applied to Document Recognition.pdf:PDF},
  groups   = {Others},
  keywords = {Neural networks,Pattern recognition,Machine learning,Optical character recognition software,Character recognition,Feature extraction,Multi-layer neural network,Optical computing,Hidden Markov models,Principal component analysis},
}

@InProceedings{Huang2017,
  author    = {G. Huang and Z. Liu and L. Van Der Maaten and K. Q. Weinberger},
  booktitle = {Proc. 30th IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR'17)},
  title     = {Densely Connected Convolutional Networks},
  year      = {2017},
  address   = {Honolulu, HI, USA},
  month     = jul,
  pages     = {2261-2269},
  abstract  = {Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections-one between each layer and its subsequent layer-our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less memory and computation to achieve high performance. Code and pre-trained models are available at https://github.com/liuzhuang13/DenseNet.},
  comment   = {DenseNet},
  doi       = {10.1109/CVPR.2017.243},
  file      = {:2017JulyHuang - Densely Connected Convolutional Networks.pdf:PDF},
  groups    = {Others},
  issn      = {1063-6919},
  keywords  = {training,convolution,network architecture,convolutional codes,neural networks,road transportation},
}

@InProceedings{Sandler2018,
  author    = {M. Sandler and A. Howard and M. Zhu and A. Zhmoginov and L. Chen},
  booktitle = {Proc. 31th IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR'18)},
  title     = {{MobileNetV2}: Inverted Residuals and Linear Bottlenecks},
  year      = {2018},
  address   = {Salt Lake City, UT, USA},
  month     = jun,
  pages     = {4510-4520},
  abstract  = {In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efficient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3. is based on an inverted residual structure where the shortcut connections are between the thin bottleneck layers. The intermediate expansion layer uses lightweight depthwise convolutions to filter features as a source of non-linearity. Additionally, we find that it is important to remove non-linearities in the narrow layers in order to maintain representational power. We demonstrate that this improves performance and provide an intuition that led to this design. Finally, our approach allows decoupling of the input/output domains from the expressiveness of the transformation, which provides a convenient framework for further analysis. We measure our performance on ImageNet [1] classification, COCO object detection [2], VOC image segmentation [3]. We evaluate the trade-offs between accuracy, and number of operations measured by multiply-adds (MAdd), as well as actual latency, and the number of parameters.},
  doi       = {10.1109/CVPR.2018.00474},
  file      = {:2018junSandler - MobileNetV2_ Inverted Residuals and Linear Bottlenecks.pdf:PDF},
  groups    = {Others},
  keywords  = {manifolds,neural networks,computer architecture,standards,computational modeling,task analysis},
}

@InProceedings{Vaswani2017,
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {Attention is All you Need},
  year      = {2017},
  editor    = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  publisher = {Curran Associates, Inc.},
  volume    = {30},
  comment   = {Transformer structure is proposed in this paper.},
  file      = {:2017Vaswani - Attention Is All You Need.pdf:PDF},
  groups    = {Others},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
}

@InProceedings{Montresor2009,
  author    = {Montresor, Alberto and Jelasity, Mark},
  booktitle = {2009 IEEE Ninth International Conference on Peer-to-Peer Computing},
  title     = {PeerSim: A scalable P2P simulator},
  year      = {2009},
  pages     = {99-100},
  comment   = {P2P simulator, not simply for blockchain, Java based, feature: scalability, but only suitable for network level simulation},
  doi       = {10.1109/P2P.2009.5284506},
  file      = {:2009Montresor - PeerSim_ a Scalable P2P Simulator.pdf:PDF},
  groups    = {Fully Distributed Learning, Blockchain Simulator},
  keywords  = {Peer to peer computing,Protocols,Java,Engines,Writing,Topology,Monitoring,Discrete event simulation,Scalability,Testing},
}

@Book{Boyd2011,
  author   = {Boyd, Stephen and Parikh, Neal and Chu, Eric and Peleato, Borja and Eckstein, Jonathan},
  title    = {Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers},
  year     = {2011},
  comment  = {A distributed optimization technique based on ADMM(Alternating Direction Method of Multipliers)

**分布式优化**},
  doi      = {10.1561/2200000016},
  file     = {:2011Boyd - Distributed Optimization and Statistical Learning Via the Alternating Direction Method of Multipliers.pdf:PDF},
  groups   = {Distributed Learning},
  keywords = {Artificial Intelligence,Machine Learning,Optimization and Control Theory,Computer Science},
}

@Article{Jacobs1991,
  author  = {Jacobs, Robert A. and Jordan, Michael I. and Nowlan, Steven J. and Hinton, Geoffrey E.},
  journal = {Neural Comput.},
  title   = {Adaptive Mixtures of Local Experts},
  year    = {1991},
  month   = mar,
  number  = {1},
  pages   = {79-87},
  volume  = {3},
  doi     = {10.1162/neco.1991.3.1.79},
  file    = {:1991MarchJacobs - Adaptive Mixtures of Local Experts.pdf:PDF},
  groups  = {Mixture of Experts},
}

@Patent{Manamohan2023,
  nationality = {United States},
  number      = {US11605013B2},
  year        = {2023},
  yearfiled   = {2018},
  assignee    = {Hewlett Packard Enterprise Development LP},
  author      = {Manamohan, Sathyanarayanan and Shastry, Krishnaprasad Lingadahalli and Garg, Vishesh},
  day         = {14},
  dayfiled    = {17},
  month       = mar,
  monthfiled  = {#oct#},
  note        = {US Patent 11,605,013},
  title       = {System and method of decentralized machine learning using blockchain},
  type        = {patentus},
  file        = {:US11605013.pdf:PDF},
  groups      = {ML and Blockchain},
  publisher   = {Google Patents},
}

@Article{Kang2020,
  author   = {Kang, Jiawen and Xiong, Zehui and Niyato, Dusit and Zou, Yuze and Zhang, Yang and Guizani, Mohsen},
  journal  = {IEEE Wirel. Commun.},
  title    = {Reliable Federated Learning for Mobile Networks},
  year     = {2020},
  month    = apr,
  number   = {2},
  pages    = {72-80},
  volume   = {27},
  comment  = {reputation score to evaluate each FL worker

use consortium chain to manage reputation},
  doi      = {10.1109/MWC.001.1900119},
  file     = {:2020Kang - Reliable Federated Learning for Mobile Networks.pdf:PDF},
  groups   = {FL and Blockchain},
  keywords = {Mobile handsets,Task analysis,Machine learning,Data models,Training data,Data privacy,Training data,Metasearch},
  ranking  = {rank1},
}

@Article{Garay2024,
  author     = {Garay, Juan and Kiayias, Aggelos and Leonardos, Nikos},
  journal    = {J. ACM},
  title      = {The Bitcoin Backbone Protocol: Analysis and Applications},
  year       = {2024},
  issn       = {0004-5411},
  month      = aug,
  number     = {4},
  pages      = {1--49},
  volume     = {71},
  abstract   = {Bitcoin is the first and most popular decentralized cryptocurrency to date. In this work, we extract and analyze the core of the Bitcoin protocol, which we term the Bitcoin backbone, and prove three of its fundamental properties which we call Common Prefix, Chain Quality, and Chain Growth in the static setting where the number of players remains fixed. Our proofs hinge on appropriate and novel assumptions on the “hashing power” of the protocol participants and their interplay with the protocol parameters and the time needed for reliable message passing between honest parties in terms of computational steps. A takeaway from our analysis is that, all else being equal, the protocol’s provable tolerance in terms of the number of adversarial parties (or, equivalently, their “hashing power” in our model) decreases as the duration of a message passing round increases.Next, we propose and analyze applications that can be built “on top” of the backbone protocol, specifically focusing on Byzantine agreement (BA) and on the notion of a public transaction ledger. Regarding BA, we observe that a proposal due to Nakamoto falls short of solving it, and present a simple alternative which works assuming that the adversary’s hashing power is bounded by 1/3. The public transaction ledger captures the essence of Bitcoin’s operation as a cryptocurrency, in the sense that it guarantees the liveness and persistence of committed transactions. Based on this notion, we describe and analyze the Bitcoin system as well as a more elaborate BA protocol and we prove them secure assuming the adversary’s hashing power is strictly less than 1/2. Instrumental to this latter result is a technique we call 2-for-1 proof-of-work (PoW) that has proven to be useful in the design of other PoW-based protocols.},
  address    = {New York, NY, USA},
  articleno  = {25},
  doi        = {10.1145/3653445},
  file       = {:2024AugustGaray - The Bitcoin Backbone Protocol_ Analysis and Applications.pdf:PDF},
  groups     = {Blockchain Theory},
  issue_date = {August 2024},
  keywords   = {Blockchain protocols, proof of work, cryptocurrencies, consensus},
  numpages   = {49},
  priority   = {prio2},
  publisher  = {Association for Computing Machinery},
  ranking    = {rank5},
  readstatus = {read},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Applications of Optimization ML and BC\;0\;1\;0x8066ccff\;\;机器学习、优化理论、区块链技术融合为其他应用赋能\;;
1 StaticGroup:Blockchain Surveys\;0\;1\;0x999999ff\;\;\;;
1 StaticGroup:Distributed Learning\;0\;0\;0x1a3399ff\;\;\;;
1 StaticGroup:Mixture of Experts\;0\;1\;0xffb366ff\;\;\;;
1 StaticGroup:ML and Blockchain\;0\;1\;0x8099ffff\;\;机器学习赋能区块链\;;
2 StaticGroup:FL and Blockchain\;0\;0\;0x669966ff\;\;联邦学习赋能区块链\;;
2 StaticGroup:RL and Blockchain\;0\;1\;0xb3e6b3ff\;\;强化学习赋能区块链\;;
1 StaticGroup:Optimization and Blockchain\;0\;1\;0x00ffffff\;\;优化赋能区块链\;;
1 StaticGroup:Others\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Blockchain Simulator\;0\;1\;0xb3b34dff\;\;\;;
1 StaticGroup:Blockchain Theory\;0\;0\;0xffff4dff\;\;\;;
1 StaticGroup:PoUW\;0\;1\;0x62cdbcff\;\;\;;
}
