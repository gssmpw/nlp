\section{Introduction}


Image restoration (IR) is a challenging low-level computer vision task focused on generating visually appealing high-quality (HQ) images from low-quality (LQ) images (e.g. noisy, blurry). Image deblurring \cite{kupyn2019deblurgan,whang2022deblurring}, blind face restoration \cite{wang2021towards,li2020blind}, image super-resolution \cite{dong2012nonlocally,dong2015image}, image denoising, inpainting, and colorization can be categorized under IR. The scope of IR applications is extensive, encompassing mobile photography, surveillance, remote sensing, and medical imaging.  

Algorithms that tackle the IR problem are commonly evaluated by two types of metrics: 1) a distortion metric (e.g. PSNR) that quantifies some type of discrepancy between the reconstructed images and the ground truth; 2) perceptual quality (PQ) metric (e.g. FID \cite{heusel2017gans}) that intends to assess the appeal of reconstructed images to a human observer. The distortion and PQ metrics are usually
at odds with each other leading to a distortion-perception trade-off \cite{blau2018perception}. This trade-off can be viewed as a Pareto frontier, which can be framed as an optimization problem by minimizing distortion while achieving a given perception index. Out of all points on the distortion-perception Pareto frontier, the main goal of the IR task is to find the point where the estimator achieves minimal average distortion under a constraint of \emph{perfect} perceptual index \cite{ohayon2024posterior}. A solution for this problem \cite{freirich2021a} can be obtained by initially using a minimum mean square error (MMSE) estimator, followed by sampling from the posterior distribution of visually appealing images given the MMSE output.


\begin{figure*}[t] 
\includesvg[width=1.0\textwidth]{images/psnr_fid_fps_size_v2.svg}
\caption{\textbf{Comparison between \name and diffusion \& flow-based baselines methods.} \name is the smallest and fastest method while maintaining PSNR (higher is better) and FID (lower is better) competitive with state-of-the-art results. The results were obtained using the CelebA-Test dataset for blind face restoration.}
\label{fig:performance}
\end{figure*}


Recently, several approaches have explored this direction, proposing two-stage algorithms \cite{yue2024difface,lin2023diffbir,rombach2022high,zhu2024flowie,10681246,ohayon2024posterior}. In the first stage, a neural network is utilized to correct the distortion error. Then, in the second stage, a conditional generative model is employed to sample visually appealing images conditioned on the output of the first stage. Typically, the first stage is trained to minimize a distortion metric (e.g. $\ell_1$, $\ell_2$), while the second stage is trained using a diffusion \cite{sohl2015deep, ho2020denoising} or a flow matching objective. \cite{AlbergoV23, lipman2023flow, liu2023flow} 


Although these methods achieve state-of-the-art results, deploying them on edge devices such as mobile phones or image sensors is challenging due to significant memory and computational requirements. The high demands stem from three main reasons: (i) the transformer-based architecture used by these methods, which incurs substantial computation and memory costs; (ii) state-of-the-art approaches based on diffusion or flow matching necessitate multiple neural function evaluations (NFE) during inference, posing difficulties for edge devices; (iii) many methods operate directly in pixel space, demanding high computational costs, particularly at high resolutions.

In this work, we address the challenge of providing an efficient algorithm for IR that exhibits significantly improved resource efficiency in terms of memory consumption and computational cost, while maintaining an equivalent level of performance. We achieve this by suggesting ELIR, an Efficient Latent Image Restoration method. \name includes two stages. First, we introduce the Latent MMSE estimator, which computes the conditional expectation of the latent representation given the latent representation of the degraded image, yielding the latent posterior mean. Second, we suggest latent consistency flow matching (LCFM), an integration of latent flow matching \cite{dao2023flow} and consistency flow matching \cite{yang2024consistencyfm}. To the best of our knowledge, this approach is presented here for the first time. LCFM aims to reduce both the number of NFEs and the computational cost of each NFE. We emphasize that \name uniquely integrates Latent MMSE and LCFM, allowing the complete execution of the procedure within the latent space, which significantly reduces the computational costs associated with processing high-resolution images. In addition, we suggest replacing the transformer-based architecture with a convolution-based one that can be efficiently implemented on edge devices. 

We conducted a set of experiments to validate \name and highlight its benefits in terms of distortion, perceptual quality, model size, and latency. Specifically, we evaluate \name on blind face restoration, super-resolution, image denoising, inpainting, and colorization. In all tasks, we demonstrate significant efficiency improvements compared to diffusion \& flow-based methods. Our model size is reduced by 4 to 45 times, and we achieve between 4 to 270 times increase in frames per second (FPS) processing speed. \name achieves these improvements without sacrificing distortion or perceptual quality, remaining competitive with state-of-the-art approaches (Figure~\ref{fig:performance}).


Our contributions are summarized as follows:
\begin{itemize}
    
    \item We introduce the Latent Minimum Mean Square Error estimator (Latent MMSE) which approximates the posterior mean in the latent space. 
    
    \item We integrate latent flow matching with consistency flow matching for the first time, which reduces the NFEs as well as the cost of each evaluation.

    \item We performed experiments on various tasks including blind face restoration, image super-resolution, image denoising, inpainting, and colorization. The results show a 4-45$\times$ reduction in memory size and a 4-270$\times$ reduction in latency compared to state-of-the-art diffusion \& flow-based methods while maintaining competitive performance.
        
\end{itemize}



