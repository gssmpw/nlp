\begin{figure}[t!]
%\vspace{-0.2in}
\centering
\begin{minipage}{\linewidth}
\centering
\begin{algorithm}[H]
\small
\caption{ Sampling Algorithm of HOG-Diff }
    \textbf{Input:} Trained denoising network $\bm{s}_{\theta}^{(k)}$, 
    diffusion time split $\{\tau_0,\cdots,\tau_K\}$,
    number of sampling steps $M_k$
\begin{algorithmic}[1]
\STATE $t \leftarrow \tau_K$
\STATE $\widehat{\bm{X}}_{\tau_K}\sim \mathcal{N}(\bm{0}, \bm{I})$ and $\widehat{\bm{\Lambda}}_{\tau_K}\sim \mathcal{N}(\bm{0}, \bm{I})$
\STATE $\widehat{\bm{U}}_0 \sim \operatorname{Unif}\left(\{\bm{U}_0 \triangleq \operatorname{EigenVectors}(\bm{L}_0)\}\right)$
\STATE $\widehat{\bm{G}}_{\tau_K} \leftarrow (\widehat{\bm{X}}_{\tau_K},\widehat{\bm{\Lambda}}_{\tau_K},\widehat{\bm{D}}_{\tau_K}-\widehat{\bm{U}}_0 \widehat{\bm{\Lambda}}_{\tau_K} \widehat{\bm{U}}_0 ^\top)$
\FOR{$k=K$ \textbf{to} $1$}
\FOR{$m=M_k-1$ \textbf{to} $0$}
\STATE $\bm{S}_{\bm{X}}, \bm{S}_{\bm{\Lambda}} \leftarrow \bm{s}^{(k)}_{\bm{\theta}}(\widehat{\bm{G}}_t, \widehat{\bm{G}}_{\tau_k},t)$
% Predict X
\STATE $\widehat{\bm{X}}_t \leftarrow \widehat{\bm{X}}_t - \left[
\theta_t \left( 1 + \frac{2}{e^{2\bar{\theta}_{t:\tau_k}}-1}  \right)(\widehat{\bm{X}}_{\tau_k} - \widehat{\bm{X}}_t)
-g_{k,t}^2 \bm{S_X} \right]\delta t 
+g_{k,t} \sqrt{\delta t} \bm{w}_{\bm{X}}$, $\bm{w}_{\bm{X}} \sim \mathcal{N}(\bm{0}, \bm{I})$ \COMMENT{Prediction step: $\bm{X}$}
% Predict eig
\STATE $\widehat{\bm{\Lambda}}_t \leftarrow \widehat{\bm{\Lambda}}_t - \left[
\theta_t \left( 1 + \frac{2}{e^{2\bar{\theta}_{t:\tau_k}}-1}  \right)(\widehat{\bm{\Lambda}}_{\tau_k} - \widehat{\bm{\Lambda}}_t)
-g_{k,t}^2 \bm{S_\Lambda} \right] \delta t
+g_{k,t} \sqrt{\delta t}  \bm{w}_{\bm{\Lambda}}$, $\bm{w}_{\bm{\Lambda}} \sim \mathcal{N}(\bm{0}, \bm{I})$ \COMMENT{Prediction step: $\bm{\Lambda}$}
\STATE $\widehat{\bm{L}}_t \leftarrow \widehat{\bm{U}}_0 \widehat{\bm{\Lambda}}_t \widehat{\bm{U}}_0^\top$
\STATE $\widehat{\bm{A}}_t \leftarrow \widehat{\bm{D}}_t - \widehat{\bm{L}}_t$
\STATE $t \leftarrow t - \delta t$
\ENDFOR
\STATE $\widehat{\bm{A}}_{\tau_{k-1}} = \operatorname{quantize}(\widehat{\bm{A}}_t)$\COMMENT{Quantize if necessary}
\STATE $\widehat{\bm{G}}_{\tau_{k-1}} \leftarrow (\widehat{\bm{X}}_t,\widehat{\bm{\Lambda}}_t,\widehat{\bm{A}}_t)$ 
\ENDFOR
\STATE \textbf{Return:} $\widehat{\bm{X}}_0$, $\widehat{\bm{A}}_0$ \COMMENT{$\tau_0 = 0$}
\end{algorithmic}
\label{alg:sample}
\end{algorithm}
\end{minipage}
%\vspace{-0.3in}
\end{figure}