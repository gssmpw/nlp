\begin{table}[t]
\centering
\caption{Evaluation of Spatio-Temporal Errors Across Open-Source models and TUMTraffic-Qwen Baseline.}
\resizebox{0.5\textwidth}{!}{

\begin{tabular}{l|cc|c}
\midrule

\textbf{Model} & \textbf{Temporal E↓} & \textbf{Spatial E↓} & \textbf{ST E↓} \\ \midrule

\multicolumn{4}{c}{Open-Source Models} \\ \midrule

LLAVA-OneVision (0.5B)    & 0.7285 & 0.7212 & 0.8415        \\ 
LLAVA-OneVision (7B)     & 0.7680 & 0.7750 & 0.8142       \\ 

Qwen2-VL (2B)     & 0.7729 & 0.7793 & 0.8127                \\ 

Qwen2-VL (7B)    & 0.7615 & 0.7647 & 0.8032                 \\ 
\rowcolor{gray!10}
VideoLLaMA2 (7B-8F)   & \textbf{0.6225} & \textbf{0.6360} & \textbf{0.6896}     \\ 

VideoLLaMA2 (7B-16F)  & 0.7218 & 0.7383 & 0.7895            \\ 

% VideoLLAMA2.1 (7B-16F)  & 0.8444 & 0.8589 & 0.8855            \\
\midrule

\multicolumn{4}{c}{TUMTraffic-VideoQA Baseline} \\ \midrule



% 0.5B-f-vision        \\     
% 7B-f-vision                \\  \midrule
\rowcolor{gray!10}
0.5B-Spatial-Pooling   & 0.1220 & \textbf{0.1892} & \textbf{0.2600}  \\     
0.5B-MultiRes-Spatial-Pooling  & \textbf{0.1211} & 0.1894 & 0.2607  \\     
0.5B-MultiRes-Token-Pruning   & 0.1230 & 0.1934 & 0.2650   \\     
0.5B-MultiRes-Temporal-Pooling & 0.1228 & 0.1912 & 0.2629 \\   \midrule 

\rowcolor{gray!10}
7B-Spatial-Pooling   & \textbf{0.1083} & \textbf{0.1737} & \textbf{0.2382}  \\     
7B-MultiRes-Spatial-Pooling   & 0.1136 & 0.1822 & 0.2493   \\     
7B-MultiRes-Token-Pruning    & 0.1152 & 0.1748 & 0.2454   \\     
7B-MultiRes-Temporal-Pooling  & 0.1166 & 0.1790 & 0.2496  \\     
\midrule

\end{tabular}}

\label{table:model_errors}
\vspace{-2pt}

\end{table}



% \begin{table*}[hbt!]
% \centering
% \resizebox{\textwidth}{!}{
% \begin{tabular}{l | ccccc | ccc}
% \toprule
% \multirow{2}{*}{\textbf{Models}} & \multicolumn{5}{c|}{\textbf{Referred Object Captioning}} & \multicolumn{3}{c}{\textbf{Spatio-Temporal Grounding}} \\

% % \cline{2-9}
% & BlEU\_4↑ & ROUGE\_L↑ & CIDEr↑ & METEOR↑ & SPICE↑ & Temporal E\textdownarrow & Spatial E\textdownarrow & SpaTemp. E\textdownarrow \\

% \midrule
% \multicolumn{9}{c}{\textbf{Open-Source Models}} \\
% \midrule

% LLAVA-OneVision (0.5B) & 0.48 & 10.16 & 0.0102 & - & - & 0.7285 & 0.7212 & 0.8415 \\
% LLAVA-OneVision (7B) & 5.77 & 14.09 & 0.1326 & - & - & 0.7680 & 0.7750 & 0.8142 \\
% Qwen2-VL (2B) & 8.72 & 17.93 & 0.2086 & - & - & 0.7729 & 0.7793 & 0.8127 \\
% \rowcolor{gray!10} Qwen2-VL (7B) & \textbf{10.47} & \textbf{20.14} & \textbf{0.4119} & - & - & 0.7615 & 0.7647 & 0.8032 \\
% VideoLLAMA2 (7B-8F) & 6.25 & 19.94 & 0.2391 & - & - & \textbf{0.6225} & \textbf{0.6360} & \textbf{0.6896} \\
% \midrule
% \multicolumn{9}{c}{\textbf{TUMTraffic-VideoQA Baseline}} \\
% \midrule
% 0.5B Spatial-Pooling & 34.99 & 50.44 & 2.5195 & 35.24 & 46.35 & 0.1220 & \textbf{0.1892} & \textbf{0.2600} \\
% 0.5B MultiRes-Spatial-Pooling & 34.91 & 50.26 & 2.4306 & 35.20 & 45.75 & \textbf{0.1211} & 0.1894 & 0.2607 \\
% 0.5B MultiRes Token Pr. & 35.07 & 50.79 & \textbf{2.5730} & 35.30 & 46.48 & 0.1230 & 0.1934 & 0.2650 \\
% \rowcolor{gray!10} 0.5B MultiRes-Temp-Pooling & \textbf{35.63} & \textbf{51.00} & 2.5464 & \textbf{35.77} & \textbf{47.17} & 0.1228 & 0.1912 & 0.2629 \\
% \midrule
% 7B Spatial-Pooling & 36.74 & 52.04 & 2.5613 & 36.42 & 47.32 & \textbf{0.1083} & \textbf{0.1737} & \textbf{0.2382} \\
% \rowcolor{gray!10} 7B MultiRes Spatial-Pooling & 37.60 & \textbf{53.26} & \textbf{2.6113} & \textbf{37.31} & \textbf{49.16} & 0.1136 & 0.1822 & 0.2493 \\
% 7B MultiRes Token Pr. & \textbf{37.83} & 52.31 & 2.6162 & 36.56 & 47.80 & 0.1152 & 0.1748 & 0.2454 \\
% 7B MultiRes Temp-Pooling & 37.48 & 52.58 & 2.4236 & 36.85 & 48.53 & 0.1166 & 0.1790 & 0.2496 \\
% \bottomrule
% \end{tabular}
% }
% \caption{Performance and error evaluation of Open-Source models and TUMTraffic-VideoQA on Referred Object Captioning.}
% \label{tab:merged_results}
% \end{table*}
