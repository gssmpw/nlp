
\section{Conclusions and Future Works}

In this work, we introduce TUMTraffic-VideoQA, a novel benchmark aimed at advancing spatio-temporal video understanding in complex real-world traffic scenarios. The dataset provides a large-scale collection of high-quality videos and annotations specifically curated for roadside surveillance, covering three fundamental tasks: multi-choice video QA, spatio-temporal grounding, and referred object captioning within a unified evaluation framework. Extensive evaluations using SOTA VLMs, along with the introduction of the TUMTraffic-Qwen baseline model, establish a strong foundation for future research and development.  TUMTraffic-VideoQA serves as a comprehensive benchmark to facilitate further advancements in traffic video analysis and contribute to the development of next-generation traffic foundation models.

% In this work, we introduce TUMTraffic-VideoQA, a novel benchmark designed for Spatio-temporal video understanding in complex traffic scenarios. TUMTraffic-VideoQA provides a large-scale, high-quality dataset specifically curated for roadside surveillance, complemented by diverse evaluation metrics to assess Spatio-temporal reasoning. It unifies three essential tasks—multi-choice video QA, Spatio-temporal grounding, and referred object captioning—within a unified evaluation framework. Through extensive experiments, we establish strong baselines across multiple state-of-the-art models, offering valuable insights into their capabilities and limitations. The open release of TUMTraffic-VideoQA aims to drive further research, serving as a comprehensive resource to enhance video understanding models and foster innovation in intelligent traffic analysis systems.