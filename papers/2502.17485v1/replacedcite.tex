\section{Related Work}
\label{RW1}
\emph{FL}-based models are vulnerable to attacks and violate data security and privacy. Also, because the data distribution of enterprises is non-IID, it leads to the divergence of the model, and as a result, the model's accuracy decreases. Due to this issue, many approaches have been developed over the past years to reduce privacy concerns and solve the non-IID challenge (e.g., ____, ____, ____, ____, ____, ____, ____, ____, ____, ____).In this section, we first review some approaches that reduce security and privacy concerns. Then, we will review the most important recent works that addressed the non-IID challenge.

A HE-based Privacy-Preserving approach is proposed in ____. This approach has high resistance against model poisoning attacks and guarantees model privacy. Specifically, this approach uses CS to detect model poisoning attacks, measuring the distance between two encoded gradients. 

In ____, a Privacy-Preserving method is proposed that guarantees the local model's privacy against poisoning attacks. The main idea of this algorithm in identifying the poisoning attack is to measure the direction and magnitude of the gradients in the cipher text mode and remove the suspicious models from the aggregation process. Therefore, the proposed method guarantees the correctness of aggregation of local users' models on the server side, which leads to the Privacy-Preserving of local users' models. 

In ____, a robust federated aggregation-based approach ({\textsc{RFA}}) that is resistant to poisoning attacks is proposed. Two algorithms have been used in {\textsc{RFA}}. The aggregation operation of all local models is performed on the server side using the first algorithm at high speed. The second algorithm performs the personalization of gradients in clients.

One of the most common \emph{FL} averaging methods is {\textsc{FedAvg}}. This algorithm trains a global model by randomly selecting the clients ____. Another algorithm that emerged as an improved {\textsc{FedAvg}} algorithm was the {\textsc{FedProx}}. This algorithm is compatible with non-IID data and has used Euclidean distance to improve the global model efficiency ____. Another popular algorithm, introduced as adaptive server optimization, is {\textsc{FedAdam}}. This algorithm guarantees the model convergence against non-IID data ____.

Several works exist on decentralized FL with and without noisy channels, server/client selection, and dynamic model parameter updates. 

In ____, three decentralized FL algorithms are proposed to solve imperfect communication between different agents. In the first algorithm, noise has been added to the algorithm's parameters to simulate the scenario of noisy communication channels. In addition to adding noise to the algorithm's parameters in the second algorithm, it averages rumors before gradient optimization. Finally, in the third algorithm, noise shares gradients through noisy communication channels instead of parameters. 

Li et al. ____ proposed a method called FEDBN for cancer detection without sharing privacy-sensitive data. The main challenge that FEDBN faces is to solve the problem of feature skewness of medical images under a non-IID setting. In FEDBN, the local data regarding distribution in the feature space is skewed, and this scenario is identified as a feature skewness challenge. This type of non-IID data is a critical problem in many real-world scenarios, typically where local clients are responsible for heterogeneity in feature distributions. However, image appearance can vary greatly due to different imaging machines and hospital protocols, such as intensity and contrast. In this method, local batch normalization has been used to reduce feature skewness before averaging the models. In particular, FEDBN keeps the local batch normalization parameters consistent with the global model in the aggregation step to reduce the feature bias in non-IID data.

Chen et al. ____ proposed a method called CalFAT to deal with the challenge of label skewness under non-IID data. Label skew leads to unequal class probabilities and heterogeneous local models. In this method, the problem of label skew was studied, and a root cause was revealed, i.e., the instability of local model training and the issues of natural accuracy reduction. In particular, CalFAT is proposed to deal with the instability issue by adaptively calibrating logits to balance classes. Therefore, CalFAT optimization can lead to locally homogeneous models and, as a result, stable training, faster convergence, and better final performance.

Gu et al. ____ presented an algorithm called FedBR to solve the feature and label distribution skew. Current approaches are limited by slow and unstable convergence due to data diversity in different clients. In FedBR, this bi-skewness is due to the bias of local updates in FL, where the biased local classifiers cannot classify the unseen data effectively. Therefore, the FedBR algorithm aims to use pseudo-data to reduce the local learning bias of features and classifiers. Specifically, the FedBR algorithm has two main components. The first component helps reduce bias in local classifiers by balancing the output of local models. The second component helps to learn local features similar to global ones, but they differ from those learned from other data sources. This work solves the feature and label distribution skew under the FedBR algorithm.

In ____, a \emph{FL} framework is proposed to solve the non-IID challenge, especially the feature and label distribution skew, called FedFA. A feature and label distribution skew in which different clients have an unbalanced number of features and labels belonging to the target features and labels. The presence of feature and label bias among clients leads to a vicious cycle between classifier divergence and feature inconsistency among client models, which reduces training performance. Specifically, in FedFA, feature anchors are used as a loss function to align features and labels and calibrate classifiers across clients simultaneously. This allows the client models to be updated in the same feature space with fixed classifiers during local training. As a result, the FedFA framework solves the challenge of features and label skews among local models so that the model accuracy does not decrease in the face of these skews, which leads to an increase in efficiency.

In Table \ref{tab1}, all related approaches were compared in terms of robustness to non-IID, privacy-preserving, and security. In summarizing this section, the main differences between the $\textsc{FedAnil}$ model with existing approaches are as follows:

\vspace{-\topsep}
\begin{itemize}
  \setlength{\parskip}{0pt}
  \setlength{\itemsep}{0pt plus 1pt}
	\item According to ____, in the existing non-IID approaches, only one of these, Label skew, Feature, Temporal skew, and Quantity skew, have been discussed, and no research has been done together on both these skews. However, in $\textsc{FedAnil}$, non-IID is addressed from two perspectives: Feature and Label skew.
	\item In the existing approaches to solve the Label and Feature distribution skew, more research has been done from the perspective of Noise-based feature imbalance skew and Synthetic future imbalance skew, and less research has been done on Real-world feature imbalance skew. However, in $\textsc{FedAnil}$, non-IID is addressed from the perspective of Real-world feature imbalance skew.
	\item The existing approaches focused on the part of the attacks, for example, poisoning attacks or inference attacks to protect the training data and client parameters privacy; But {$\textsc{FedAnil}$} focuses on both categories of poisoning and inference attacks and the model privacy and accuracy are well preserved.
\end{itemize}
\vspace{-\topsep}

\begin{table}
  \caption{Comparison between $\textsc{FedAnil}$ and the related work}.
  \setlength{\tabcolsep}{4.0\tabcolsep}% Shrink \tabcolsep by 30%
  \centering
  %\rowcolors{12}{green!80!yellow!50}{green!70!yellow!40}
   \begin{tabular}{p{4.0cm}|p{1.3cm}|p{1.3cm}|p{1.3cm}}
  %\begin{tabular}{ *{6}{c} }
    \toprule
    \textbf{Ref} & \textbf{robust non-IID} & \textbf{Privacy-Preserving} & \textbf{Secure}\\
    \midrule
    ____&\textcolor{red}{\xmark}&\textcolor{ForestGreen}{\cmark}&\textcolor{ForestGreen}{\cmark}\\
    ____&\textcolor{red}{\xmark}&\textcolor{ForestGreen}{\cmark}&\textcolor{red}{\xmark}\\
    ____&\textcolor{ForestGreen}{\cmark}&\textcolor{ForestGreen}{\cmark}&\textcolor{red}{\xmark}\\
    ____&\textcolor{ForestGreen}{\cmark}&\textcolor{ForestGreen}{\cmark}&\textcolor{red}{\xmark}\\
    ____&\textcolor{ForestGreen}{\cmark}&\textcolor{ForestGreen}{\cmark}&\textcolor{red}{\xmark}\\
    ____&\textcolor{ForestGreen}{\cmark}&\textcolor{ForestGreen}{\cmark}&\textcolor{red}{\xmark}\\
    ____&\textcolor{red}{\xmark}&\textcolor{ForestGreen}{\cmark}&\textcolor{ForestGreen}{\cmark}\\
    ____&\textcolor{red}{\xmark}&\textcolor{ForestGreen}{\cmark}&\textcolor{red}{\xmark}\\
    ____&\textcolor{ForestGreen}{\cmark}&\textcolor{ForestGreen}{\cmark}&\textcolor{red}{\xmark}\\
    ____&\textcolor{ForestGreen}{\cmark}&\textcolor{ForestGreen}{\cmark}&\textcolor{red}{\xmark}\\
    ____&\textcolor{ForestGreen}{\cmark}&\textcolor{ForestGreen}{\cmark}&\textcolor{red}{\xmark}\\
    ____&\textcolor{ForestGreen}{\cmark}&\textcolor{ForestGreen}{\cmark}&\textcolor{red}{\xmark}\\
    \textbf{$\textsc{FedAnil}$}&\textcolor{ForestGreen}{\cmark}&\textcolor{ForestGreen}{\cmark}&\textcolor{ForestGreen}{\cmark}\\
    
    \bottomrule
  \end{tabular}
  \label{tab1}
\end{table}