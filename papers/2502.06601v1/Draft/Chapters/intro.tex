\vspace{-9mm}
\section{Introduction}
\vspace{-1mm}
\label{sec:intro}
\looseness=-1
Bayesian analysis of data has become increasingly popular and is widely used in numerous scientific disciplines.
In politics, predictive models based on public polling and other factors play a crucial role in the discourse around the state of a campaign.
Throughout the COVID-19 pandemic, models that estimate the infectiousness of the virus, the efficacy of public health measures, and the future course of the pandemic became critical to government planning and the public's understanding of the pandemic~\citep{Cooper2020-covidmodel}. In cryogenic electron microscopy (cryo-EM), the posterior over an unknown 3D atomic-resolution molecular structure is explored given image observations~\citep{Glaeser2021-cryoem}. 
% \marcus{Cite applications for above}. \sar{Motivate via tabular experiments as well.}

\looseness=-1
While recent years have made such methods more accessible \citep{bingham2019pyro,carpenter2017stan,StatSoftReview}, they still remain computationally burdensome.
Further, in practical contexts where new observations are continuously available, the analysis must be re-run every time new data becomes available, e.g., when new case counts become available, previous measurements are corrected, or when applied to different geographic regions.
As a result practitioners adopt approximations~\citep{welling2011bayesian,gelfand2000gibbs,brooks1998markov}, simplify their models~\citep{hoffman2013stochastic,blei2017variational} or reduce the frequency with which they perform their analyses.

\looseness=-1
A common thread is that the probabilistic model defining the relationship between its parameters and the observations is fixed. Poll aggregation models use hierarchical time series models~\citep{Athanasopoulos-hierarchicalts,chen2023-pollaggregation}, infectious diseases are studied using variants on compartment models~\citep{Tang2020-diseasemodels}, and cryo-EM uses a linear image formation model~\citep{Glaeser2021-cryoem}. This makes these applications ideal candidates for amortized inference~\citep{morris2013recognition,paige2016inference,kingma2013auto,rezende2014stochastic,stuhlmuller2013learning}.

\looseness=-1
Multiple approaches leverage neural networks to learn functions that map an observed \emph{dataset} directly to a posterior distribution~\citep{garnelo2018neural,cranmer2020sbireview} or model the posterior predictive directly~\citep{garnelo2018conditional,muller2021transformers,garg2022can,hollmann2022tabpfn}. They sidestep the need for iterative procedures, e.g., Markov chain Monte Carlo (MCMC) sampling~\citep{gelfand2000gibbs,hoffman2014no} or standard variational inference (VI) and efficiently handle permutation invariance stemming from \textit{iid} observations using Transformers and DeepSets~\citep{Zaheer2017deepsets,vaswani2017attention,lee2019set}. If learned properly, this mapping allows generalization to new datasets passed in context in zero-shot.

However, analysis into evaluating different in-context posterior estimation objectives is currently lacking. The goal of such estimators is to model the posterior distribution by leveraging observations in context as opposed to invoking iterative estimation procedures again from scratch. We provide a rigorous analysis into different training objectives, i.e. forward and reverse KL objectives, where the former is equivalent to neural posterior estimation in simulation-based inference \citep{cranmer2020sbireview} and the latter has connections to neural processes \citep{garnelo2018neural}. However, NP only model the posterior over some unstructured latent variable (akin to \citet{kingma2013auto,rezende2014stochastic}) with the objective being a proxy to maximum likelihood while we are interested in a fully Bayesian treatment of all parameters defining the likelihood.

Our benchmark considers a wide variety of probabilistic models and evaluates different design choices in inferring the posterior over their parameters. We look at different permutation invariant architectures, parametrizations for the approximate density, as well as training objectives. Our evaluation criteria tests for both in-distribution (ID) and out-of-distribution (OoD) generalization, and relies on a simple masking procedure to amortize posterior estimation over datasets with a variable number of features, inching closer towards a generalist in-context Bayesian learner $-$ as evidenced by its generalization capabilities on real-world tasks zero-shot through only pre-training on synthetic data.

Generally, real-world datasets do not exactly follow standard models, e.g., while practitioners often rely on linear models, data rarely follows them exactly. We further evaluate the estimators on tasks where the assumed probabilistic model is incorrect (misspecification), or where we only have access to samples but not underlying parameters, which is a common paradigm in most machine learning tasks.
% This is a common paradigm in machine learning as we often do not have access to the true model class or the right priors, and is termed as misspecification. 
% 
Our detailed experiments provide clear insights into the architectural choices that lead to better amortized posterior estimation, through the lens of both predictive and sample-based metrics. Our contributions include
\begin{itemize}[topsep=0pt,parsep=1pt,partopsep=0pt,leftmargin=3mm] %leftmargin=*,
  \setlength\itemsep{0pt}
    \item Providing a general framework for in-context Bayesian posterior estimation with different training objectives.
    % \item Performing a rigorous analysis of different objectives that can be used to train the amortized estimators.
    \item Benchmarking various design choices like architectural backbones, parametrizations of approximate density and training objectives through extensive ablations.
    \item Evaluating the ability of estimators to generalize OoD when the modeling assumption is different from the underlying true model class (misspecification), especially to real-world tasks when trained only on synthetic data.
\end{itemize}