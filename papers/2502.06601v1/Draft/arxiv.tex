%%%%%%%% ICML 2023 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass[10pt]{article} % For LaTeX2e
\input{Paper Draft/math_commands.tex}

\usepackage{paper}
% \usepackage[preprint]{paper}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{booktabs} % for professional tables
\usepackage{multicol}
\usepackage{multirow}
\usepackage{enumitem}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{wrapfig}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}
\usepackage[textsize=tiny]{todonotes} 

\newcommand{\sstd}[1]{\textcolor{black}{\tiny{$\pm #1$}}}
\newcommand{\std}[1]{}
\newcommand{\highlight}[1]{\colorbox{blue!10}{#1}}
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2023} with \usepackage[nohyperref]{icml2023} above.
\definecolor{mydarkblue}{rgb}{0,0.08,0.45}
\hypersetup{ %
    colorlinks=true,
    linkcolor=mydarkblue,
    citecolor=mydarkblue,
    filecolor=mydarkblue,
    urlcolor=mydarkblue,
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\title{Amortizing Bayesian Posterior Inference in \\Tractable Likelihood Models}

\author{\name Sarthak Mittal \email sarthmit@gmail.com\\
\addr Mila, Universit\'e de Montr\'eal
\AND
\name Niels Leif Bracher \email nbracher@yorku.ca \\
\addr York University, Vector Institute
\AND
\name Guillaume Lajoie \email g.lajoie@umontreal.ca \\
\addr Mila, Universit\'e de Montr\'eal
\AND
\name Priyank Jaini \email pjaini@google.com \\
\addr Google DeepMind
\AND
\name Marcus A Brubaker \email mab@eecs.yorku.ca \\
\addr York University, Vector Institute 
% \name Kyunghyun Cho \email kyunghyun.cho@nyu.edu \\
%       \addr Department of Computer Science\\
%       University of New York
%       \AND
%       \name Raia Hadsell \email raia@google.com \\
%       \addr DeepMind
%       \AND
%       \name Hugo Larochelle \email hugolarochelle@google.com\\
%       \addr Mila, Universit\'e de Montr\'eal \\
%       Google Research\\
%       CIFAR Fellow
}

% The \author macro works with any number of authors. Use \AND 
% to separate the names and addresses of multiple authors.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\def\month{MM}  % Insert correct month for camera-ready version
\def\year{YYYY} % Insert correct year for camera-ready version
\def\openreview{\url{https://openreview.net/forum?id=XXXX}} % Insert correct link to OpenReview for camera-ready version

\begin{document}

\maketitle
\begin{abstract}
\looseness=-1
Bayesian inference provides a natural way of incorporating prior beliefs and assigning a probability measure to the space of hypotheses. However, it is often infeasible in practice as it requires expensive iterative routines like MCMC to approximate the posterior distribution. Not only are these methods computationally expensive, but they must also be re-run whenever new observations are available, making them impractical or of limited use. To alleviate such difficulties, we amortize the posterior parameter inference for probabilistic models through permutation invariant architectures. While this paradigm is briefly explored in Simulation Based Inference (SBI), Neural Processes (NPs) and Gaussian Process (GP) kernel estimation, a more general treatment of amortized Bayesian inference in known likelihood models has been largely unexplored. We additionally utilize a simple but strong approach to further amortize on the dimensionality of observations, allowing a single system to infer variable dimensional parameters. In particular, we rely on the reverse-KL based amortized Variational Inference (VI) approach to train inference systems and compare them with forward-KL based SBI approaches across different architectural setups. We conduct thorough experiments to demonstrate the effectiveness of our proposed approach, especially in real-world and model misspecification settings.
\end{abstract}

\input{Paper Draft/Chapters/intro}
\input{Paper Draft/Chapters/background}
\input{Paper Draft/Chapters/method}
% \input{ICML/Chapters/related_work}
\input{Paper Draft/Chapters/experiments}
\input{Paper Draft/Chapters/discussion}
\input{Paper Draft/Chapters/conclusion}

% \include{ICLR/Chapters/todo}
% \subsubsection*{Author Contributions}
% If you'd like to, you may include  a section for author contributions as is done
% in many journals. This is optional and at the discretion of the authors.

% \subsubsection*{Acknowledgments}
% Use unnumbered third level headings for the acknowledgments. All
% acknowledgments, including those to funding agencies, go at the end of the paper.
\section*{Impact Statement}
This work studies amortizing variational inference for Bayesian posterior estimation which is a widespread strategy for performing inference in statistics. It provides a natural way of quantifying uncertainty and potentially leading to more robust predictions. While we do not foresee any negative impacts of progress in this area, we encourage caution when applying the methodologies in practice. 

\section*{Acknowledgements}
The authors would like to acknowledge the computing resources provided by the Mila cluster to enable the experiments outlined in this work. SM acknowledges the support of UNIQUE's scholarship.
GL acknowledges the support of the Canada CIFAR AI Chair program, NSERC Discovery Grant RGPIN-2018-04821, and a Canada Research Chair in Neural Computations and Interfacing. 
MAB acknowledges the support of the Canada First Research Excellence Fund (CFREF) for the Vision: Science to Applications (VISTA) program, NSERC Discovery Grant RGPIN-2017-05638 and Google.
The authors also thank NVIDIA for computing resources.


% \input{Paper Draft/Tables/misspecification_and_posterior}
\clearpage
\bibliography{references}
\bibliographystyle{paper}
\clearpage
\appendix
\onecolumn
\section*{\LARGE Appendix}
\input{Paper Draft/Appendix/related_work}
\input{Paper Draft/Appendix/equivariances}
\input{Paper Draft/Appendix/probabilistic_models}
\input{Paper Draft/Appendix/metrics}
\input{Paper Draft/Appendix/architecture_details}
\input{Paper Draft/Appendix/experiment_details}
\input{Paper Draft/Appendix/datasets}
\input{Paper Draft/Appendix/results}

\end{document}