\begin{table}[t]
    \centering
    \small
    \def\arraystretch{1.25}
    \setlength{\tabcolsep}{4pt}
    \begin{tabular}{l lcr | cc | cccc }
        \toprule
        & & & & \multicolumn{2}{c|}{\textit{$L_2$ Loss} ($\downarrow$)} & \multicolumn{4}{c}{\textit{Accuracy} ($\uparrow$)}\\

        \textbf{Setup} & & $q_\varphi$ & \textbf{Model} & \multicolumn{2}{c|}{\textbf{NLR}} & \multicolumn{4}{c}{\textbf{NLC}} \\
        
        & & & & \textit{1D} & \textit{25D} & \textit{2D-2cl} & \textit{2D-5cl} & \textit{25D-2cl} & \textit{25D-5cl} \\
        \midrule
\multirow{11}{*}{\rotatebox[origin=c]{90}{\textsc{tanh}}} 
& \multirow{3}{*}{Baseline} & - & Random & $52.72$\std{$0.5$} & $55.16$\std{$0.0$} & $50.16$\std{$0.1$} & $19.83$\std{$0.2$} & $50.02$\std{$0.2$} & $20.00$\std{$0.1$} \\
& & - & Optimization & $0.56$\std{$0.0$} & $30.22$\std{$0.1$} & $96.76$\std{$0.0$} & $89.99$\std{$0.0$} & $69.51$\std{$0.0$} & $40.43$\std{$0.0$} \\
& & - & MCMC & $0.39$\std{$0.0$} & $32.41$\std{$0.9$} & $94.23$\std{$0.2$} & $81.42$\std{$0.2$} & $53.16$\std{$0.8$} & $24.49$\std{$0.4$} \\
\cmidrule{4-10}
& \multirow{2}{*}{Fwd-KL} & \multirow{4}{*}{\rotatebox[origin=c]{90}{Gaussian}} & DeepSets & $53.83$\std{$0.5$} & $56.02$\std{$0.1$} & $50.07$\std{$0.4$} & $19.95$\std{$0.2$} & $49.91$\std{$0.1$} & $19.93$\std{$0.0$} \\
& & & Transformer & $53.89$\std{$0.6$} & $56.82$\std{$0.3$} & $50.07$\std{$0.4$} & $20.18$\std{$0.2$} & $49.91$\std{$0.1$} & $20.09$\std{$0.1$} \\
& \multirow{2}{*}{Rev-KL} & & DeepSets & $0.89$\std{$0.0$} & $27.98$\std{$0.0$} & $50.04$\std{$0.4$} & $19.99$\std{$0.2$} & $49.91$\std{$0.1$} & $19.97$\std{$0.0$} \\
& & & Transformer & $0.87$\std{$0.0$} & \highlight{$25.17$\std{$4.0$}} & $61.64$\std{$16.8$} & $19.99$\std{$0.2$} & $49.92$\std{$0.1$} & $19.95$\std{$0.1$} \\
\cmidrule{4-10}
& \multirow{2}{*}{Fwd-KL} & \multirow{4}{*}{\rotatebox[origin=c]{90}{Flow}} & DeepSets & $52.46$\std{$0.5$} & $55.85$\std{$0.1$} & $50.47$\std{$0.1$} & $19.79$\std{$0.1$} & $49.93$\std{$0.0$} & $20.06$\std{$0.0$} \\
& & & Transformer & $52.44$\std{$0.5$} & $55.84$\std{$0.1$} & $50.45$\std{$0.1$} & $20.04$\std{$0.1$} & $49.94$\std{$0.0$} & $20.19$\std{$0.0$} \\
& \multirow{2}{*}{Rev-KL} & & DeepSets & \highlight{$0.68$\std{$0.0$}} & $27.97$\std{$0.0$} & $50.67$\std{$0.1$} & $19.72$\std{$0.1$} & $49.99$\std{$0.1$} & $20.06$\std{$0.1$} \\
& & & Transformer & $0.70$\std{$0.0$} & $27.97$\std{$0.0$} & \highlight{$86.37$\std{$0.2$}} & $19.78$\std{$0.1$} & $50.00$\std{$0.2$} & $20.02$\std{$0.1$} \\
\midrule
\multirow{11}{*}{\rotatebox[origin=c]{90}{\textsc{relu}}}
& \multirow{3}{*}{Baseline} & - & Random & $1082.06$\std{$3.7$} & $13301.74$\std{$109.1$} & $49.68$\std{$0.6$} & $20.18$\std{$0.1$} & $49.74$\std{$0.1$} & $20.08$\std{$0.2$} \\
& & - & Optimization & $2.01$\std{$0.1$} & $1858.40$\std{$2.6$} & $98.01$\std{$0.2$} & $96.81$\std{$0.0$} & $80.30$\std{$0.1$} & $61.30$\std{$0.0$} \\
& & - & MCMC & \textsc{N/A} & \textsc{N/A} & $88.39$\std{$0.9$} & $52.78$\std{$1.9$} & $66.16$\std{$0.1$} & $35.49$\std{$0.7$} \\
\cmidrule{4-10}
& \multirow{2}{*}{Fwd-KL} & \multirow{4}{*}{\rotatebox[origin=c]{90}{Gaussian}} & DeepSets & $821.57$\std{$3.4$} & $10877.36$\std{$200.8$} & $60.77$\std{$0.5$} & $31.66$\std{$0.2$} & $58.35$\std{$0.3$} & $19.88$\std{$0.1$} \\
& & & Transformer & $786.67$\std{$6.7$} & $10845.96$\std{$86.3$} & $61.21$\std{$0.5$} & $32.12$\std{$0.1$} & $58.28$\std{$0.3$} & $30.17$\std{$0.2$} \\
& \multirow{2}{*}{Rev-KL} & & DeepSets & $1.38$\std{$0.1$} & $2048.08$\std{$9.8$} & $74.11$\std{$0.2$} & $49.53$\std{$0.3$} & $66.41$\std{$0.1$} & $46.12$\std{$0.2$} \\
& & & Transformer & $2.36$\std{$0.4$} & \highlight{$1976.32$\std{$43.0$}} & $87.77$\std{$3.9$} & \highlight{$76.33$\std{$1.0$}} & $66.35$\std{$0.1$} & $30.01$\std{$0.3$} \\
\cmidrule{4-10}
& \multirow{2}{*}{Fwd-KL} & \multirow{4}{*}{\rotatebox[origin=c]{90}{Flow}} & DeepSets & $676.46$\std{$15.2$} & $8236.22$\std{$77.0$} & $62.90$\std{$0.4$} & $33.21$\std{$0.2$} & $60.28$\std{$0.1$} & $20.12$\std{$0.1$} \\
& & & Transformer & $646.60$\std{$36.1$} & $8075.57$\std{$94.2$} & $63.71$\std{$0.7$} & $34.11$\std{$0.1$} & $61.45$\std{$0.2$} & $32.70$\std{$0.1$} \\
& \multirow{2}{*}{Rev-KL} & & DeepSets & \highlight{$1.32$\std{$0.1$}} & $2040.10$\std{$2.6$} & $74.98$\std{$0.2$} & $61.65$\std{$0.5$} & $68.06$\std{$0.1$} & \highlight{$47.05$\std{$0.3$}} \\
& & & Transformer & $2.92$\std{$0.2$} & $1987.58$\std{$43.7$} & \highlight{$92.31$\std{$0.3$}} & $76.03$\std{$0.2$} & \highlight{$68.41$\std{$0.2$}} & $45.96$\std{$0.1$} \\
\bottomrule
    \end{tabular}
    \caption{\textbf{Fixed-Dim Posterior Prediction:} Experimental results for posterior inference on fixed dimensional datasets evaluated on estimating the parameters of nonlinear regression (NLR) and classification (NLC) setups, with 2 layered MLP with different activation functions in the probabilistic model. We also consider a multi-class classification setup. We consider different backbone architectures and parametric distributions $q_\varphi$, and use dataset-specific Bayesian and point estimates as baselines. $L_2$ Loss and Accuracy refer to the expected posterior-predictive $L_2$ loss and accuracy respectively. Here, cl refers to the number classes.}
    \label{tab:fixed_dim_2_layer}
\end{table}