\begin{table}[t]
    \centering
    \small
    \def\arraystretch{1.25}
    \setlength{\tabcolsep}{4pt}
    \begin{tabular}{l lcr | cc | cccc }
        \toprule
        & & & & \multicolumn{2}{c|}{\textit{$L_2$ Loss} ($\downarrow$)} & \multicolumn{4}{c}{\textit{Accuracy} ($\uparrow$)}\\

        \textbf{Setup} & & $q_\varphi$ & \textbf{Model} & \multicolumn{2}{c|}{\textbf{NLR}} & \multicolumn{4}{c}{\textbf{NLC}} \\
        
        & & & & \textit{1D} & \textit{25D} & \textit{2D-2cl} & \textit{2D-5cl} & \textit{25D-2cl} & \textit{25D-5cl} \\
        \midrule
\multirow{11}{*}{\rotatebox[origin=c]{90}{\textsc{tanh}}}
& \multirow{3}{*}{Baseline} & - & Random & $34.48$\std{$0.7$} & $53.62$\std{$0.1$} & $50.09$\std{$0.1$} & $20.03$\std{$0.3$} & $49.96$\std{$0.0$} & $20.09$\std{$0.1$} \\
& & - & Optimization & $0.28$\std{$0.0$} & $12.02$\std{$0.0$} & $97.21$\std{$0.0$} & $93.41$\std{$0.0$} & $75.67$\std{$0.0$} & $49.41$\std{$0.0$} \\
& & - & MCMC & $0.30$\std{$0.0$} & $16.25$\std{$0.2$} & $95.80$\std{$0.1$} & $89.48$\std{$0.2$} & $65.08$\std{$0.1$} & $34.77$\std{$0.3$} \\
\cmidrule{4-10}
& \multirow{2}{*}{Fwd-KL} & \multirow{4}{*}{\rotatebox[origin=c]{90}{Gaussian}} & DeepSets & $34.74$\std{$0.7$} & $53.38$\std{$0.1$} & $50.14$\std{$0.4$} & $19.86$\std{$0.1$} & $50.12$\std{$0.1$} & $19.99$\std{$0.1$} \\
& & & Transformer & $34.75$\std{$0.8$} & $53.48$\std{$0.3$} & $50.14$\std{$0.4$} & $20.06$\std{$0.1$} & $50.12$\std{$0.1$} & $20.13$\std{$0.1$} \\
& \multirow{2}{*}{Rev-KL} & & DeepSets & $0.41$\std{$0.0$} & $25.99$\std{$0.0$} & $90.05$\std{$0.2$} & $19.84$\std{$0.2$} & $50.11$\std{$0.1$} & $20.00$\std{$0.1$} \\
& & & Transformer & $0.41$\std{$0.0$} & \highlight{$10.89$\std{$0.0$}} & $89.43$\std{$0.3$} & $78.03$\std{$0.1$} & $50.13$\std{$0.1$} & $20.01$\std{$0.1$} \\
\cmidrule{4-10}
& \multirow{2}{*}{Fwd-KL} & \multirow{4}{*}{\rotatebox[origin=c]{90}{Flow}} & DeepSets & $33.30$\std{$2.0$} & $53.35$\std{$0.4$} & $49.88$\std{$0.1$} & $20.23$\std{$0.0$} & $50.03$\std{$0.1$} & $20.04$\std{$0.1$} \\
& & & Transformer & $10.60$\std{$0.2$} & $53.58$\std{$0.5$} & $49.87$\std{$0.1$} & $20.41$\std{$0.1$} & $50.02$\std{$0.1$} & $20.17$\std{$0.1$} \\
& \multirow{2}{*}{Rev-KL} & & DeepSets & \highlight{$0.38$\std{$0.0$}} & $26.53$\std{$0.0$} & $89.97$\std{$0.1$} & $49.00$\std{$0.2$} & $49.99$\std{$0.1$} & $19.98$\std{$0.1$} \\
& & & Transformer & \highlight{$0.38$\std{$0.0$}} & \highlight{$10.89$\std{$0.0$}} & \highlight{$90.56$\std{$0.5$}} & \highlight{$81.79$\std{$0.1$}} & $49.95$\std{$0.1$} & $20.02$\std{$0.1$} \\
\midrule
\multirow{11}{*}{\rotatebox[origin=c]{90}{\textsc{relu}}}
& \multirow{3}{*}{Baseline} & - & Random & $64.52$\std{$1.6$} & $793.13$\std{$7.4$} & $50.08$\std{$0.6$} & $20.00$\std{$0.1$} & $49.82$\std{$0.3$} & $19.94$\std{$0.2$} \\
& & - & Optimization & $0.32$\std{$0.0$} & $95.08$\std{$0.1$} & $97.49$\std{$0.0$} & $95.66$\std{$0.0$} & $80.06$\std{$0.0$} & $59.39$\std{$0.0$} \\
& & - & MCMC & \textsc{N/A} & $106.90$\std{$0.8$} & $96.37$\std{$0.2$} & $93.07$\std{$0.1$} & $73.23$\std{$0.1$} & $45.98$\std{$0.3$} \\
\cmidrule{4-10}
& \multirow{2}{*}{Fwd-KL} & \multirow{4}{*}{\rotatebox[origin=c]{90}{Gaussian}} & DeepSets & $50.00$\std{$1.0$} & $682.23$\std{$4.6$} & $59.52$\std{$0.1$} & $31.48$\std{$0.2$} & $59.57$\std{$0.2$} & $29.50$\std{$0.1$} \\
& & & Transformer & $50.73$\std{$1.3$} & $678.11$\std{$6.6$} & $59.91$\std{$0.2$} & $32.16$\std{$0.2$} & $59.76$\std{$0.2$} & $29.78$\std{$0.1$} \\
& \multirow{2}{*}{Rev-KL} & & DeepSets & $0.43$\std{$0.0$} & $124.46$\std{$1.4$} & $91.59$\std{$0.1$} & $85.61$\std{$0.2$} & $62.57$\std{$0.3$} & $32.99$\std{$0.1$} \\
& & & Transformer & $0.42$\std{$0.0$} & $99.28$\std{$2.2$} & $91.68$\std{$0.3$} & $85.36$\std{$0.3$} & \highlight{$76.46$\std{$0.0$}} & $47.72$\std{$2.3$} \\
\cmidrule{4-10}
& \multirow{2}{*}{Fwd-KL} & \multirow{4}{*}{\rotatebox[origin=c]{90}{Flow}} & DeepSets & $15.31$\std{$0.3$} & $549.13$\std{$3.5$} & $61.98$\std{$0.1$} & $33.55$\std{$0.7$} & $60.98$\std{$0.2$} & $30.78$\std{$0.1$} \\
& & & Transformer & $16.37$\std{$0.3$} & $530.95$\std{$2.5$} & $75.68$\std{$0.2$} & $38.42$\std{$2.4$} & $61.12$\std{$0.1$} & $30.94$\std{$0.1$} \\
& \multirow{2}{*}{Rev-KL} & & DeepSets & \highlight{$0.39$\std{$0.0$}} & $125.90$\std{$1.2$} & \highlight{$93.13$\std{$0.0$}} & \highlight{$86.93$\std{$0.2$}} & $63.87$\std{$0.1$} & $33.31$\std{$0.1$} \\
& & & Transformer & \highlight{$0.39$\std{$0.0$}} & \highlight{$97.83$\std{$0.4$}} & $92.92$\std{$0.2$} & $86.50$\std{$0.1$} & $75.75$\std{$0.8$} & \highlight{$49.38$\std{$0.6$}} \\
\bottomrule
    \end{tabular}
    \caption{\textbf{Fixed-Dim Posterior Prediction:} Experimental results for posterior inference on fixed dimensional datasets evaluated on estimating the parameters of nonlinear regression (NLR) and classification (NLC) setups, with 1 layered MLP with different activation functions in the probabilistic model. We also consider a multi-class classification setup. We consider different backbone architectures and parametric distributions $q_\varphi$, and use dataset-specific Bayesian and point estimates as baselines. $L_2$ Loss and Accuracy refer to the expected posterior-predictive $L_2$ loss and accuracy respectively. Here, cl refers to the number classes.}
    \label{tab:fixed_dim_1_layer}
\end{table}
