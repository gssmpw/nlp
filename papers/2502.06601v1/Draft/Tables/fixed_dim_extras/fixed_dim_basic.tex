\begin{table}[t]
    \centering
    \small
    \def\arraystretch{1.25}
    \setlength{\tabcolsep}{4pt}
    \begin{tabular}{lcr | ccc | cc }
        \toprule
         &  &  & \multicolumn{3}{c|}{\textit{$L_2$ Loss} ($\downarrow$)} & \multicolumn{2}{c}{\textit{Accuracy} ($\uparrow$)}\\

        & $q_\varphi$ & \textbf{Model} & \multicolumn{3}{c|}{\textbf{GMM}} & \multicolumn{2}{c}{\textbf{LC}} \\
        
        & & & \textit{2D-2cl} & \textit{2D-5cl} & \textit{5D-5cl} & \textit{2D-5cl} & \textit{100D-5cl} \\
        \midrule
\multirow{3}{*}{Baseline} & - & Random & $1.88$\std{$0.0$} & $0.72$\std{$0.0$} & $5.06$\std{$0.1$} & $20.28$\std{$0.4$} & $20.03$\std{$0.0$} \\
& - & Optimization & $0.17$\std{$0.0$} & $0.12$\std{$0.0$} & $0.43$\std{$0.0$} & $92.04$\std{$0.0$} & $42.31$\std{$0.0$} \\
& - & MCMC & $0.20$\std{$0.0$} & $0.13$\std{$0.0$} & $0.65$\std{$0.1$} & $85.18$\std{$0.2$} & $31.73$\std{$0.2$} \\
\cmidrule{3-8}
\multirow{2}{*}{Fwd-KL} & \multirow{4}{*}{\rotatebox[origin=c]{90}{Gaussian}} & DeepSets & $0.91$\std{$0.0$} & $0.53$\std{$0.0$} & $2.42$\std{$0.0$} & $70.96$\std{$0.3$} & $19.94$\std{$0.1$} \\
& & Transformer & $0.92$\std{$0.0$} & $0.53$\std{$0.0$} & $2.44$\std{$0.0$} & $71.00$\std{$0.2$} & $26.82$\std{$0.1$} \\
\multirow{2}{*}{Rev-KL} & & DeepSets & \highlight{$0.19$\std{$0.0$}} & $0.13$\std{$0.0$} & $0.49$\std{$0.0$} & $86.94$\std{$0.1$} & $21.60$\std{$0.4$} \\
& & Transformer & $0.20$\std{$0.0$} & \highlight{$0.12$\std{$0.0$}} & $0.52$\std{$0.0$} & $87.05$\std{$0.1$} & $32.62$\std{$0.2$} \\
\cmidrule{3-8}
\multirow{2}{*}{Fwd-KL} & \multirow{4}{*}{\rotatebox[origin=c]{90}{Flow}} & DeepSets & $0.23$\std{$0.1$} & $0.22$\std{$0.0$} & $0.65$\std{$0.0$} & $88.12$\std{$0.1$} & $20.02$\std{$0.1$} \\
& & Transformer & $0.23$\std{$0.1$} & $0.25$\std{$0.0$} & $0.57$\std{$0.1$} & \highlight{$88.95$\std{$0.1$}} & $27.05$\std{$0.2$} \\
\multirow{2}{*}{Rev-KL} & & DeepSets & \highlight{$0.19$\std{$0.0$}} & $0.13$\std{$0.0$} & $0.52$\std{$0.0$} & $88.09$\std{$0.2$} & $21.05$\std{$0.2$} \\
& & Transformer & \highlight{$0.19$\std{$0.0$}} & \highlight{$0.12$\std{$0.0$}} & \highlight{$0.48$\std{$0.0$}} & $88.21$\std{$0.0$} & \highlight{$33.20$\std{$0.3$}} \\
\bottomrule
    \end{tabular}
    \caption{\textbf{Fixed-Dim Posterior Prediction:} Experimental results for posterior inference on fixed dimensional datasets evaluated on estimating the (a) means of Gaussian mixture model (GMM), and (b) parameters for linear classification (LC) for additional probabilistic model setups (eg. multi-class). We consider different backbone architectures and parametric distributions $q_\varphi$, and use dataset-specific Bayesian and point estimates as baselines. $L_2$ Loss and Accuracy refer to the expected posterior-predictive $L_2$ loss and accuracy respectively. Here, cl refers to the number of clusters for GMM and number of classes for LC.} 
    \label{tab:fixed_dim_basic}
\end{table}
