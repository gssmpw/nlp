\begin{figure*}
     \centering
     \captionsetup[subfigure]{font=tiny}
     \begin{subfigure}[b]{0.16\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Draft/Plots/fixed_dim/gaussian.pdf}
         \caption*{Mean of Gaussian}
         \label{fig:gaussian}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.16\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Draft/Plots/fixed_dim/linear_regression.pdf}
         \caption*{Linear Regression}
         \label{fig:linear_regression}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.16\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Draft/Plots/fixed_dim/nonlinear_regression.pdf}
         \caption*{Nonlinear Regression}
         \label{nonlinear_regression}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.16\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Draft/Plots/fixed_dim/gmm.pdf}
         \caption*{Gaussian Mixture}
         \label{fig:gmm}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.16\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Draft/Plots/fixed_dim/linear_classification.pdf}
         \caption*{Linear Classification}
         \label{fig:linear_classification}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.16\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Draft/Plots/fixed_dim/nonlinear_classification.pdf}
         \caption*{Nonlinear Classification}
         \label{fig:nonlinear_classification}
     \end{subfigure}
    \vspace{-4mm}
    \caption{\textbf{Amortized Bayesian Posterior Estimation:} Illustration of predictions from the reverse KL in-context estimator. Model predictions, true predictions and sample points are shown in red, black and blue respectively. Additionally for classification, we label sample points with their ground-truth class, and draw the decision boundary according to the model.}
    % We see that the learned amortized variational distribution appropriately captures the underlying distributions.}
    % We see that the learned amortized variational distribution appropriately captures at least a mode of the posterior. For the Gaussian and Regression experiments, samples from the dataset are shown in blue, the ground-truth parameter in black, and predictions from the inference model in red. For Classification experiments, samples from the dataset are shown coloured according to their appropriate class label, and the decision boundary is obtained from an ensemble of predictions obtained from the inference model.}
    \vspace{-6mm}
    \label{fig:fixed_dim}
\end{figure*}
