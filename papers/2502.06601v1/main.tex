%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}
\input{Draft/math_commands.tex}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{booktabs} % for professional tables
\usepackage{multicol}
\usepackage{multirow}
\usepackage{enumitem}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{wrapfig}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
% \usepackage[capitalize,noabbrev]{cleveref}
\usepackage[textsize=tiny]{todonotes}

\newcommand{\sstd}[1]{\textcolor{black}{\tiny{$\pm #1$}}}
\newcommand{\std}[1]{}
\newcommand{\highlight}[1]{\colorbox{blue!10}{#1}}
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
% \usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}

% Use the following line for the initial blind version submitted for review:
\usepackage[preprint]{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
% \usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[nameinlink,capitalize,noabbrev]{cleveref}

\newcommand{\ie}{\textit{i.e.}}
\newcommand{\eg}{\textit{e.g.}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}
\expandafter\def\expandafter\normalsize\expandafter{%
    % \setlength\abovedisplayskip{3pt}%
    % \setlength\belowdisplayskip{3pt}%
    % \setlength\abovedisplayshortskip{-4pt}%
    % \setlength\belowdisplayshortskip{2pt}%
}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\icmltitlerunning{Amortized In-Context Bayesian Posterior Estimation}

\begin{document}

\twocolumn[
\icmltitle{Amortized In-Context Bayesian Posterior Estimation}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Sarthak Mittal}{udem,mila}
\icmlauthor{Niels Leif Bracher}{rpi}
\icmlauthor{Guillaume Lajoie}{udem,mila}
\icmlauthor{Priyank Jaini}{gdm}
\icmlauthor{Marcus Brubaker}{gdm,york,vector}
\end{icmlauthorlist}

\icmlaffiliation{udem}{Universit\'e de Montreal}
\icmlaffiliation{mila}{Mila}
\icmlaffiliation{york}{York University}
\icmlaffiliation{gdm}{Google DeepMind}
\icmlaffiliation{vector}{Vector Institute}
\icmlaffiliation{rpi}{Rensselaer Polytechnic Institute}

\icmlcorrespondingauthor{Sarthak Mittal}{sarthmit@gmail.com}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{\icmlEqualContribution} 
\printAffiliationsAndNotice{}% otherwise use the standard text.

\begin{abstract}
Bayesian inference provides a natural way of incorporating prior beliefs and assigning a probability measure to the space of hypotheses. Current solutions rely on iterative routines like Markov Chain Monte Carlo (MCMC) sampling and Variational Inference (VI), which need to be re-run whenever new observations are available. Amortization, through conditional estimation, is a viable strategy to alleviate such difficulties and has been the guiding principle behind simulation-based inference, neural processes and in-context methods using pre-trained models. In this work, we conduct a thorough comparative analysis of amortized in-context Bayesian posterior estimation methods from the lens of different optimization objectives and architectural choices. Such methods train an amortized estimator to perform posterior parameter inference by conditioning on a set of data examples passed as context to a sequence model such as a transformer. In contrast to language models, we leverage permutation invariant architectures as the true posterior is invariant to the ordering of context examples. Our empirical study includes generalization to out-of-distribution tasks, cases where the assumed underlying model is misspecified, and transfer from simulated to real problems. Subsequently, it highlights the superiority of the reverse KL estimator for predictive problems, especially when combined with the transformer architecture and normalizing flows.
\end{abstract}

\input{Draft/Chapters/intro}
\input{Draft/Chapters/preliminaries}
\input{Draft/Chapters/method}
\input{Draft/Chapters/experiments}
\input{Draft/Chapters/discussion}
\clearpage
\section*{Acknowledgements}
The authors would like to acknowledge the computing resources provided by the Mila cluster to enable the experiments outlined in this work. SM acknowledges the support of UNIQUE's scholarship.
GL acknowledges the support of the Canada CIFAR AI Chair program, NSERC Discovery Grant RGPIN-2018-04821, and a Canada Research Chair in Neural Computations and Interfacing. 
MAB acknowledges the support of the Canada First Research Excellence Fund (CFREF) for the Vision: Science to Applications (VISTA) program, NSERC Discovery Grant RGPIN-2017-05638 and Google.
The authors also thank NVIDIA for computing resources.

\section*{Impact Statement}
We provide a comprehensive evaluation of different approaches and design choices in performing Bayesian posterior estimation for a wide variety of probabilistic models. We believe that analysis into such amortized estimators could lead to more efficient and scalable Bayesian methods that can lead to robust predictions and better OoD generalization. Thus, we believe that our work generally advances the field of machine learning through careful and thorough benchmarking. There are many potential societal
consequences of our work, none of which we feel must be
specifically highlighted here.
\bibliography{references}
\bibliographystyle{icml2025}

\clearpage
\appendix
\onecolumn
\section*{\LARGE Appendix}
\input{Draft/Appendix/related_work}
\input{Draft/Appendix/equivariances}
\input{Draft/Appendix/probabilistic_models}
\input{Draft/Appendix/metrics}
\input{Draft/Appendix/architecture_details}
\input{Draft/Appendix/experiment_details}
\input{Draft/Appendix/datasets}
\input{Draft/Appendix/results}

\end{document}