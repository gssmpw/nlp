\section{Related Work}
\label{sec:related_work}
% \subsection{Human Conversation Dataset in E-commerce}
% Obviously, it is ideal to have a human-generated dialogue dataset from real e-commerce scenarios. \citet{10.1145/3539618.3591878} collect 8k of pre-sales dialogues in E-commerce scenarios from the Taobao platform, then design and develop baselines for 5 downstream tasks. Unfortunately, this valuable dataset has not been released, presumably due to various reasons such as privacy issues and conflict of commercial interests. A workaround is manually collecting a human-generated e-commerce dialogue dataset. However, the cost of collecting a large-scale one can be enormous. \citet{Bernard:2023:SIGIR} collect 64 human-written conversations in the e-commerce domain, covering three typical goals: search, recommendation, and question answering. Despite the naturalness of their dataset, it is too small for training downstream models. 

%Despite the difficulty of collecting a human-generated e-commerce dialogue dataset, prior works have been developing CPS systems based on machine-generated e-commerce datasets. 
%\citet{ai2017learning} learned a joint framework based on a hierarchical embedding model for personalized product search without involving conversations. \
\vspace{-0.5em}
\paragraph{Conversational Product Search.}

\citet{zhang2018towards} proposed a seminal CPS system that unified conversational product search and recommendation, and actively asked questions to understand user needs. 
Their framework predicts both the true item and the next question at each conversation turn. 
\citet{bi2019conversational} extended this by predicting the probability of an aspect-value pair being positive or negative to enhance conversational product ranking performance. 
\citet{zou2022learning} learned a joint representation of users, queries, items, and conversations to retrieve target items within a latent semantic space. 
\citet{xiao-etal-2021-end} created an online shopping conversational dataset by transferring the utterance structures from movie domain conversations. They used proprietary search behavior data to supervise the construction of intent flow.% in the dialogue. %In this work, we follow \cite{zhang2018towards, bi2019conversational, zou2022learning} to use product aspect-value pairs to perform the product search and construct conversations. 

A fundamental issue in prior studies~\cite{zhang2018towards,bi2019conversational,zou2022learning} is that all the proposed CPS models are evaluated using slotted templates specifically designed for clarification questions. 
%A key aspect of CPS involves determining what question to ask in each conversation turn to gain a deeper understanding of users' preferences.
%Due to the absence of a good e-commerce conversational dataset, %\shervin{Not clear what is CPS data, and if dialogues are the input or output.} 
%most prior work~\cite{zhang2018towards,bi2019conversational,zou2022learning} used slotted templates for clarification questions. 
%They primarily focused on representation learning of queries and items in simulated conversations, and assumed the trained conversational product ranker would work correctly.
The weaknesses of such an evaluation are twofold. First, as the quality of simulated conversations is not assessed and may be of poor quality, the trained conversational product rankers might not generalize well to real conversations. Second, customers may lack sufficient product knowledge, making it unrealistic to expect them to always provide answers to the seller's questions. %For instance, a suggested question for lipstick, such as ``What finish type do you prefer?'' might be unfamiliar to a real customer who may not understand the meaning of `finish type' or be aware of the available options. Such conversations can create friction for customers and result in a negative overall customer experience.

The paucity of datasets significantly hinders CPS research. Many datasets used in prior works \cite{xiao-etal-2021-end, chen-etal-2020-jddc, zhao-etal-2022-jddc} are privately owned, which prevents reproduction and further reusing of their work for future studies.
On the other hand, \citet{Bernard:2023:SIGIR} released MG-ShopDial, a 64-conversation human-generated e-commerce dialogue dataset, %that accommodates conversational goals, such as search, recommendation, and question answering. 
we perform an in-depth comparison in \S\ref{sec:mgshopdial_comparison}. Moreover, \textit{due to commercial interests and privacy concerns, no large-scale human-generated CPS dataset is publicly available, and it will not likely exist in the future either}. % \shervin{What is novel about their method? maybe state it within the sentence in a few words.}
%Recently, \citet{10.1145/3539618.3591878} collected 8k of dialogues in E-commerce scenarios from the Taobao platform, then designed and developed baselines for 5 downstream tasks. However, this dataset is not publicly available, presumably due to privacy issues and conflict of commercial interests. 
%A workaround is manually collecting a human-generated e-commerce dialogue dataset. However, the cost of collecting a large-scale one can be enormous. \citet{Bernard:2023:SIGIR} collected 64 human-written conversations in the e-commerce domain, covering three typical goals: search, recommendation, and question answering. 
%Despite the naturalness of their dataset, it is expensive to collect such datasets at scale, as only 64 conversations were collected by volunteers without involving a search-engine backend. %shervin{Justify this claim by stating how many they collected, or what is the cost, etc.} 
%Each of their conversations consists of several recommendations of products, rather than performing a product search.
%Moreover, they require the annotators to fulfill all tasks on a checklist representing various intents. In real-world scenarios, customers exhibit varying levels of patience.


\textit{Our work aims to address the data scarcity issue by guiding LLMs to generate natural CPS conversations.} We prompt LLMs to generate conversations grounded on sampled customer preferences and product information from a real product catalog. %by incorporating the attributes selected by a decision tree from the product catalog, and the internal LLM knowledge to generate realistic, human-like conversations.
%Instead of training complex models to decide when and how to ask clarification questions, we adopt a simple and interpretable decision-tree based algorithm to dynamically select the product aspect which partitions the candidate product space most effectively during each conversation turn.
%By incorporating the knowledge from the product catalog and the internal LLM knowledge, %\shervin{Do we mean internal LLM knowledge?} 
%Our LLM-based shopping assistant can not only ask clarification questions but also provide available options obtained from product search results. %\shervin{State where the options come from.} 
%Depending on the complexity of the chosen product attributes, 
The customer is also allowed to ask sellers general knowledge questions, %(e.g., ``What does finish type mean?''), 
which is lacking in prior work~\cite{zhang2018towards,bi2019conversational,zou2022learning}. Overall, our generated dialogues in the \textit{WoS} dataset are more natural and diverse than prior simulated conversations. 
%Second, all prior CPS works generate conversations and perform searches based on the learned complex representations of the available item catalog. Consequently, the trained dialogue generation models may not transfer to newly added products. 
%In addition, the prior works' product ranker outputs are likely to converge before reaching the target products, while our decision tree-based search approach is theoretically guaranteed to always find an existing target product, as we explain in Section \ref{sec:approach}. Unlike \citet{zhang2018towards, bi2019conversational, zou2022learning}, by decoupling the conversation generation process from model representation learning, 
%We believe our dataset can be readily applied to various downstream tasks like conversational query generation and conversational product search.
We believe that our proposed method and datasets will be a valuable contribution to CPS and its sub-tasks.

\vspace{-0.5em}
\paragraph{Difference with Prior Work in Conversational Recommendation \& Search.}
Similar to previous CPS work, prior conversational recommendation (CR) systems studies \cite{li2018towards, hayati2020inspired, liu2020towards, liu2021durecdial, deng2021unified, zhang2022multiple} explored the recommendation strategies by learning both the user and item representations. Indeed, the problem of learning a conversation strategy for the seller to find proper product aspects that shorten the product-seeking process seems to be shared between CPS and CR.
A key difference between our work and prior studies is that \textit{we do not build a new CPS or CR system}, but instead focus on the creation of a dataset with natural conversations along with dialogue plans with decision trees and LLMs so that the dataset can be applied to improve the downstream tasks such as query generation and product ranking. Notably, our product retrievals build upon traditional approaches like BM25, incorporating conversational layers to achieve CPS. This sets our work apart from previous CPS efforts~\cite{zhang2018towards,bi2019conversational,zou2022learning}. Additionally, many CR works are in the movie domain \cite{li2018towards, hayati2020inspired, liu2020towards, liu2021durecdial} and there is no existing CPS dataset specifically tailored for the e-commerce domain. Our work addresses this gap by introducing a dataset, along with its corresponding dataset generation method, designed explicitly for the e-commerce domain.
%Prior conversational recommendation (CR) systems studies \cite{li2018towards, hayati2020inspired, liu2020towards, liu2021durecdial, deng2021unified, zhang2022multiple} explored the recommendation strategies by learning both the user and item representations. Indeed, the problem of learning a conversation strategy for the seller to find proper product aspects that shorten the product-seeking process seems to be shared between CPS and CR. However, other than the fact that many CR works are in the movie domain \cite{li2018towards, hayati2020inspired, liu2020towards, liu2021durecdial}, a key difference between our work and prior CR studies is that \textit{we do not build a new CPS or CR system by learning user or product representations}, but instead focus on the creation of a dataset with natural conversations along with dialogue plans with decision trees and LLMs, so that the dataset can be applied to improve the downstream tasks such as query generation and product ranking. All of our product retrievals are achieved on top of traditional approaches, e.g. BM25, which simply adds a conversation layer on top of the traditional product search to achieve CPS. This is also a major difference between our work and prior CPS work ~\cite{zhang2018towards,bi2019conversational,zou2022learning} which are much closer to CR than ours.