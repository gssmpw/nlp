
\section{Dialogue Generation Approach} 
\label{sec:approach}
%\zhiyu{This section should be revised. My thought is 1)describe purchase funnel at high level, and define the scope of our generated shopping conversations 2) define customer preference, how we classify different features (i.e., unwanted, ...) 3) DT-based Attribute Selection 4)dialogue instantiation with 2 strategies}
%\jason{I think we still have problem of presenting information in top-down view. Algorithm 1 contains so many different information that is never discussed before, and you reveal one by one in the next sections. I understand that you want to summarize overall process first and move into smaller pieces, but here you overwhelm readers with information in front, which is not really a summary}

%Although recent LLMs, e.g. GPT-4 \cite{openai2023gpt4} or LLaMA-2 \cite{touvron2023llama} can trivially generate natural shopping conversations, the products and features mentioned may be unrelated to the product catalog locally available, since the LLMs are not trained on the custom product metadata, and it is impractical to naively feed all product catalog information into the prompts. In this work, we propose a decision tree-based search strategy to resolve the following challenges: (1) How to generate conversations that are grounded to the local product catalog? And further, (2) How to ask good questions to find the desired products as soon as possible? 

%We aim to create human-like goal-oriented shopping conversations with each utterance paired with a generation plan, which can be used for training downstream product rankers.

%We begin by outlining the task definition and method in Section~\ref{sec:define}.
%We then explain our proposed approach for target-oriented e-commerce dialogue generation with decision tree branching (\method) in Sections~\ref{sec:define}-\ref{sec:verbalization}.
% Specifically, we describe how to simulate user profile in Section~\ref{sec:preference_sampling}, then how to plan the dialogue topics with decision tree in Section~\ref{sec:overall_dialogue_generation}, and how to generate the final dialogue with different verbalization strategies in Section~\ref{sec:verbalization}.
%Finally, we describe our strategies to further improve the naturalness of the generated conversations in Section~\ref{sec:improving_naturalness}.

% \subsection{Overview}
% \label{sec:define}

%We are given a product catalog $P=\{p_1, p_2, ..., p_N\}$, where each product $p_n$ is associated with a varying number of $m$ features or aspect-value pairs $\{(A_1, V_1), (A_2, V_2), ..., (A_m, V_m)\}$. 
As shown in Figure \ref{fig:illustration}, the goal is to generate a shopping dialogue given a selected set of preferences that is derived from a product ($p$), randomly sampled from a product catalog. \method generates dialogues in three steps:
%\shervin{Consider using a different symbol for the catalog.}
% \begin{equation} \small
%     Dialogue \gets TRACER(p)
% \end{equation}
% Figure \ref{fig:illustration} shows an example product search conversation between two agents.
% The seller agent uncovers the customer agent's \textit{preferences} %, which consist of a product category ($PC$), and product features that are \textit{wanted}, \textit{optional} or \textit{unwanted} by the customer (Section \ref{sec:preference_sampling}). 
% %The seller agent has access to a catalog search component to 
% %asks the customer
% by asking clarification questions about product aspects. %, and perform product searches based on the customer's responses. %\zhiyu{slightly mention the customer agent? profile construction?} % I believe it's already mentioned above.
% Different from prior work~\cite{zhang2018towards,bi2019conversational,zou2022learning}, \method also allows the customer to ask the seller for clarifications regarding product details.
%\method generates dialogues in three steps: %\shervin{Which step allows the customer to ask questions? it was in the previous sentence, and should be linked to a section as it's a ke contribution.} 
%\begin{enumerate}

1. Customer preference sampling (\S\ref{sec:preference_sampling}) assigns relevant product attributes from $p$ into three distinct preference groups. 

2. Dialogue planning (\S\ref{sec:overall_dialogue_generation}) fits decision trees to predict the sequence of product aspects to be addressed so that customers can find desired products with minimal effort. 

3. Verbalization (\S\ref{sec:verbalization}) utilizes customer preference, planned search trajectories, and prompt engineering to generate natural and relevant dialogues.
%\end{enumerate}

%In the following sections, we discuss each step in more detail.

%\vspace{-1em}
% \begin{algorithm}
% \caption{SampleConstraints}\label{alg:preference_sampling}
% \begin{algorithmic}
% \Function{SampleConstraints}{P, 
% keep\_rate, unwanted\_rate}
% \State $p \gets RandomChoice(P)$
% \State $PC \gets p.category$ 
% \LeftComment{$p.features = \{(A_1, V_1), (A_2, V_2), ..., (A_j, V_j)\}$}
% \State $target\_features \gets []$
% \For{each $(A_i, V_i)$ in $p.features$}
% \If{$random() < keep\_rate$} 
% \Comment{$random() \in [0,1).$}
% \State $target\_features.append((A_i, V_i))$
% \EndIf
% \EndFor
% \State $Wanted \gets []$
% \State $Unwanted \gets []$
% \For{each $(A_x, V_x)$ in $target\_features$}
% \If{$random() > unwanted\_rate$} 
% \State $Wanted.append((A_x, V_x))$
% \Else
% \LeftComment{Randomly select $V'_x \ne V_x$ and $V'_x \in Values(A_x)$.}
% \State $ V'_x \gets SwapFeature(A_x, V_x)$ 
% \State $Unwanted.append((A_x, V'_x))$
% \EndIf
% \EndFor
% \State \Return \textit{$PC, Wanted, Unwanted$}
% \EndFunction
% \end{algorithmic}
% \end{algorithm}

\begin{algorithm}[H]
\small
\caption{Decision Tree-Based Search Strategy}\label{alg:decision_tree_search}
\begin{algorithmic}
\Function{DecisionTreeSearch}{$RevPref$}
%\LeftComment{$Query = [PC, Plan]$}
\State $P_o \gets search(RevPref)$
\State $X, Y \gets MakeDataset(P_o)$
\State $Tree \gets DecisionTree.fit(X,Y)$
\State \Return \textit{$P_o, Tree$}
\EndFunction
\end{algorithmic}
\end{algorithm}
\vspace{-1.5em}

\begin{algorithm}[t!]

\small
\caption{Interactive and single-pass dialogue generation strategies from \S\ref{sec:verbalization}.}
\label{alg:decision_tree_dialogue_generation}
\begin{algorithmic}
\Require $LLM$, $preference$ % \Comment{Rule-based filter}
%\Require $interactive\_generation$ 
%\Comment{True or False}

% \LeftComment{\textbf{Stage 0}: Customer Preference Sampling.}
% \State $[PC, Wanted, Unwanted] \gets SampleConstraints()$
% \State $preference \gets [PC, Wanted, Unwanted]$

\LeftComment{\textbf{Stage 1}: Customer starts with a product category.}
%\If{$interactive\_generation$} 
    \State $Conv\_hist \gets []$ \Comment{Interactive generation}
    \State $Utterances \gets LLM.verbalize\_stage1(PC)$
    \State $Conv\_hist.extend(Utterances)$
%\EndIf
\LeftComment{\textbf{Stage 2}: Product search.}
%\State $P_o \gets Filter.search(PC)$
\State $Plan, Plan_{hist} \gets [], []$
\While{$|P_o|$ has not converged}
\State $RevPref \gets [PC, Plan_{hist}]$
\State $P_o, Tree \gets DecisionTreeSearch(RevPref)$
%\LeftComment{Traverse $Tree$ according to the customer preference to obtain a sequence of aspect-value-interest tuples.}
\State $Plan \gets Tree.traverse(preference)$ 
\LeftComment{$Plan = \{(A_1, V_1, I_1), ..., (A_d, V_d, I_d)\}$}
\State $Plan_{hist}.extend(Plan)$
%\If{$interactive\_generation$} 
    \State $Utterances \gets LLM.verbalize\_stage2(Plan, Conv\_hist)$
    \State $Conv\_hist.extend(Utterances)$
%\EndIf
\EndWhile

\LeftComment{\textbf{Stage 3}: Product recommendation.}
\State $p \gets RandomSample(P_o)$
%\If{$interactive\_generation$}
\State $Utterances \gets LLM.verbalize\_stage3(p, Conv\_hist)$ 
\State $Conv\_hist.extend(Utterances)$
%\Else 
\LeftComment{Single pass generation}
\State $Single\_pass\_conv \gets LLM.verbalize(preference, Plan_{hist}, p)$ 
%\EndIf

\State \textbf{Output}  $Conv\_hist$, $Single\_pass\_conv$
\end{algorithmic}
\end{algorithm}
\vspace{-0.5em}

\subsection{Customer Preference Sampling} \label{sec:preference_sampling}

Each product is associated with a varying number of features or aspect-value pairs, e.g. $\{(A_1, V_1), (A_2, V_2), ..., (A_m, V_m)\}$. %\shervin{Consider providing some examples of A-V pairs to help the reader. You could give an example for each of the three interest values below to make everything more concrete.}
For example, a tablet case can have associated features of \{(model, iPad), (color, blue), (material, TPU)\}. 
We randomly assign one of the following customer interest values ($I$) to each aspect of the sampled product $p$ :
\vspace{-1em}
\begin{itemize}
\setlength\itemsep{-0.5em}
    \item \textbf{Wanted}: customer is interested
    \item \textbf{Unwanted}: customer is NOT interested
    \item \textbf{Optional}: customer does not care much
\end{itemize}
\vspace{-1em}
%To generate the conversation plan, we start with sampling a target constraint as the customer preference at as stage 0 in Algorithm \ref{alg:decision_tree_dialogue_generation}. As Algorithm \ref{alg:preference_sampling} shows, we first randomly select a product $p$ from the catalog $P$. To ensure a reasonable number of customer product feature requirements, we only randomly keep 40\% of the product features to proceed. We then sample the product features of $p$ into mutually exclusive partitions of \textit{wanted} %\nikhita{Please stick to a single labeling scheme. You use both 'required' and 'wanted' as the labels right now.}
% and \textit{unwanted} features (aspect-value pairs) with respect to the customer's preference in the ratio of 2:3, since \textit{unwanted} features are less influential to the search results. Additionally, 

%\hl{Jason: This is still confusing to me. We claim that this is randomly assigned. Then, Wanted comes first and what do you mean "for pair from p assigned with unwanted"? Is this random sampling, or sequential process? Xiangci: random sampling. No sequential. First, then ... is for description only.}
The \textit{wanted} aspect-value pairs come directly from $p$. As for an aspect-value pair $(A_x,V_x)$ from $p$ assigned with \textit{unwanted}, we randomly replace $V_x$ with a value $V'_x \ne V_x$ as the customer's unpreferred value, where $V'_x$ appears as a value for $A_x$ in the product catalog, so that the \textit{unwanted} pair becomes $(A_x,V'_x)$. %to avoid \textit{unwanted} features disturbing the search results. 
For example, if $A_x$=``color'' and $V_x$=``blue'', $V'_x$ can be ``red''. 
We use the Product Category ($PC$) of product $p$, as well as the sampled \textit{wanted}, \textit{optional}, and \textit{unwanted} features to simulate the \textit{preference} of the customer agent: %\zhiyu{refer to the prompt ? could highlight the prompt in different colors for different components}
\vspace{-0.8em}
\begin{equation}
\small
    preference = [PC, (A_1,V_1,I_1), ..., (A_m,V_m,I_m)]
\vspace{-1em}
\end{equation}

where $I_i \in (wanted, unwanted, optional)$. When $I_i=optional$, we set $V_i$ as empty since the customer does not care about the value of the optional aspect.

\iffalse
In our setting, each product $p$ is always paired with a set of product aspect key value pairs, e.g. $\{(A_1, V_1), (color, blue), ..., (A_m, V_m)\}$. %\shervin{Consider providing some examples of A-V pairs to help the reader. You could give an example for each of the three interest values below to make everything more concrete.}
% For example, a tablet case can have associated features of \{(model, iPad), (color, blue), (material, TPU)\}. 
We randomly assign one of the following customer interest values ($I$) to each pair:
\vspace{-0.5em}
\begin{itemize}
\setlength\itemsep{-0.5em}
    \item \textbf{Wanted}: customer is interested
    \item \textbf{Unwanted}: customer is NOT interested
    \item \textbf{Optional}: customer does not care much
\end{itemize}
\vspace{-0.5em}
%To generate the conversation plan, we start with sampling a target constraint as the customer preference at as stage 0 in Algorithm \ref{alg:decision_tree_dialogue_generation}. As Algorithm \ref{alg:preference_sampling} shows, we first randomly select a product $p$ from the catalog $P$. To ensure a reasonable number of customer product feature requirements, we only randomly keep 40\% of the product features to proceed. We then sample the product features of $p$ into mutually exclusive partitions of \textit{wanted} %\nikhita{Please stick to a single labeling scheme. You use both 'required' and 'wanted' as the labels right now.}
% and \textit{unwanted} features (aspect-value pairs) with respect to the customer's preference in the ratio of 2:3, since \textit{unwanted} features are less influential to the search results. Additionally, 
First, the \textit{wanted} aspect-value pairs come directly from the target product. Then, if $color$ is assigned as \textit{unwanted} aspect, %\hl{The notation ambiguous. $V_x$ here is neither wanted or unwanted value ?} 
we sample a different value from the same aspect, e.g. $(color, red)$ as an \textit{unwanted} aspect-value pair.
%we randomly select a value $V'_x \ne V_x$ as the customer's preferred value, where $V'_x$ appears as a value for $A_x$ in $Catalog$. %to avoid \textit{unwanted} features disturbing the search results. 
%For example, if $A_x$=``color'' and $V_x$=``blue'', $V'_x$ can be ``red''. %\zhiyu{The description is unclear to me. How are wanted/optinal/unwanted feature value pairs decided? And is $V'_x$ the unwanted value? The meaning behind the symbol is also unclear. Could we elaborate the definition by listing three bullet items }
Overall, each customer preference is represented as a concatenated list of product category ($PC$) of $p$ and a list of product attribute key value pairs that are assigned to different interest values.

%We use the Product Category ($PC$) of product $p$, as well as the sampled \textit{wanted}, \textit{optional}, and \textit{unwanted} features to simulate the \textit{preference} of the customer agent: %\zhiyu{refer to the prompt ? could highlight the prompt in different colors for different components}
\begin{equation}  \small
    preference = [PC, (A_1,V_1,I_1), ..., (A_m,V_m,I_m)]
\end{equation}
where $I_i \in (wanted, unwanted, optional)$. For implementation details when $I_i$ is optional, we treat $V_i$ as empty.

\fi

\begin{table}%[t!]
\small
\begin{center}
%\setlength{\tabcolsep}{6pt} % Default value: 6pt
    \begin{tabular}{p{0.95\linewidth} }
    \hline
    \textbf{Instruction} \\ 
    You are a scriptwriter. For the aspects or aspect value pairs below, write a chat conversation between the customer and seller about the seller trying to narrow down the customer's need. \textbf{\textit{The seller knows well about the sold products, while the customer has limited knowledge about the products.}} [...] The customer should speak out first and say he/she wants to buy \{\{\textit{ProductCategory}\}\}. [...] You MUST cover ALL aspect-value pairs below, including the wanted, unwanted, and optional aspect-value pairs. \textbf{\textit{Make sure you reorganize and reorder the aspect value pairs and translate them into a natural conversation in a meaningful way.}} [...]  \\ \hdashline
    \textbf{Wanted / Optional / Unwanted Features} \\ 
  Aspect or aspect value pairs that the customer must say \{he wants to have / is optional / he does not want to have\} for the target product:  \\ 
  Aspect: \{\{\textit{Aspect}\}\}, Value: \{\{\textit{Value}\}\}; \\ 
  ... \\\hdashline
  \textbf{Candidate Value Examples} \\ 
    \textbf{\textit{Additionally, there are some common values for each aspect to be mentioned. The seller should use these typical values in his question:}} \\
    Aspect: \{\{\textit{Aspect}\}\}, Typical Values: \{\{\textit{$Value_1$}\}\}, \{\{\textit{$Value_2$}\}\}, \{\{\textit{$Value_3$}\}\}; \\ 
  ... \\\hdashline
%   \textbf{Format Instruction} \\
%   ... \\ \hdashline
\textbf{Final Instruction} \\
Output a conversation following all instructions above and make sure you double check if ALL aspect value pairs above are mentioned: \\ \hline
    \end{tabular}
    \caption{Simplified prompt format for single pass dialogue generation approach. Prompts in bold are designed for improving conversation naturalness (\S\ref{sec:improving_naturalness}).}
    \label{tab:simple_prompt}
    \vspace{-1.5em}
\end{center}
\end{table}


\subsection{Dialogue Planning with Decision Tree} \label{sec:overall_dialogue_generation}
Given a sampled \textit{preference}, dialogue planning as the next step determines the sequence of product aspects to be addressed in the conversation. 
% The sampled customer \textit{preference} is a list of product aspect-value-interest of the customer to be uncovered via the product search conversation.
Since previous studies on web search evaluation discovered that user effort is inversely correlated with user satisfaction \cite{al2010review}, we claim that real customers will also want to minimize their efforts in CPS. To reflect this intuition in dialogue generation, we focus on controlling the ``customer'' LLM to be aligned with expected customer behavior by intelligently deciding what to ask at each turn.

An intuitive approach is to utilize the concept of purity in decision trees \cite{mehta1996sliq, quinlan2014c4}. At each turn, given \textit{partially} revealed preference $RevPref$\footnote{$RevPref$ is initialized with $PC$ only and grows as more product features are revealed by the decision trees.}, the decision tree selects the next product attribute that maximally divides the current search space. This is important because in real applications, customers are also expected to reveal their preferences step-by-step. 

As Algorithm \ref{alg:decision_tree_search} shows, first, at each turn that requires search, a set of products ($P_o$) that satisfy $RevPref$ are retrieved from our search system. Note that our search system is a simple rule-based system that can filter out products based on $RevPref$. Then, product attribute features from $P_o$ are used for constructing a temporary training dataset to fit a decision tree, and we use all aspects from product catalog as features for each product. If a product does not have certain aspects, corresponding values are treated as empty. For example, let's consider a product from the \textit{tablet case} category with three features. Input features ($X$) can be represented as \{(model, iPad), (color, blue), (material, TPU)\} and the corresponding labels ($Y$) are represented as a string ``\textit{model:iPad\&color:blue\&material:TPU}''. In other words, products associated with the same aspect-value pairs all belong to the same leaf node of the decision tree. As a result, the fitted $Tree$ contains a structured collection of nodes whose attributes are the product aspect keys and split conditions are corresponding aspect values. %\hl{Jason: need to fix function title not going over extra line}

%\zhiyu{Could you crosscheck with Algorithm 1. This step ($P_o$ = Filter.search(Query))is executed in Algorithm 1 as well} \Xiangci{Yes.}

%We use all the aspects from $Catalog$ as the features for each product. If a product $p_n$ does not have an aspect, the corresponding value will be empty. %is represented using a bag of features in the form of $X_n=\{(A_1, V_1), (A_2, V_2), ..., (A_m, V_m)\}$. 
%We concatenate all aspect-value pairs of the product to be its label $y_n$. 

%\hl{Jason: This is happening each turn, is it revealed preference instead of preference?} % DT is not visible to the customer's pre-defined preference. After the DT is fitted, we use the pre-defined preference to find the planned customer's answer, so yes, here we should use preference, not RefPref
Lastly, given the fitted $Tree$ and $preference$, the best dialogue plan (a sequence of aspect-value-interest tuples) is generated. Specifically, we traverse starting from the root and choose the next child based on the customer $preference$'s corresponding values and interest of the product aspect of the parent node. Any traversed aspect that does not appear in $preference$ is $optional$, indicating the customer does not care about the product aspect. Note that decision tree is fitted individually for each aspect selection step and used together with additional strategies~
(\S \ref{sec:improving_naturalness}) to increase the naturalness of generated dialogues. This search and planning process (Algorithm \ref{alg:decision_tree_search}) iterates until every product in $P_0$ satisfies $preference$, or until there are no more product aspects to discuss (Algorithm \ref{alg:decision_tree_dialogue_generation} Stage 2).

%since we are only interested in product searches within each $preference$.

% Later, as part of the conversation, the seller asks the customer about the aspects following the $Plan$, and the customer provides their values and interests.  
%The depth of the tree equals the number of selected aspects to be discussed in the conversation. %This also results in multiple executions of $DecisionTreeSearch$. Since we simply use the decision tree to find the best ``search space divider'' for each stand-alone search scenario, without the need to generalize one decision tree to multiple unseen scenarios, it makes sense to overfit the decision tree at inference time.

%we can select a specific product aspect that maximally reduces the search space. This can be achieved by using catalog-level aspect distribution statistics to rank product aspects that minimizes entropy. Since this is how decision tree  works, we use it to perform this recursive partitioning. 

% partition the search space by the product aspect that maximally reduces the space. 

% As the objective of the conversation is to reduce the product search space at each conversation turn,

%and given the product ranking list, we have a precise understanding of the distribution of product aspects. This enables us to leverage global information in order to choose the most crucial aspect during each turn.
%An ideal method to perform this recursive partitioning is the Decision Tree algorithm \cite{mehta1996sliq, quinlan2014c4}. %\shervin{Cite some classic DT paper, maybe the c4.5 paper}
%Accordingly, we opt to fit decision trees for planning each dialogue.
%The dialogue plan for the conversation between the seller and the customer consists of a sequence of aspects $AS=[A_a, A_b, ...]$ that the seller asks the customer about, and the corresponding values $V$ and attitudes $Att$\shervin{We need another word, Attitude is not suitable.} (\textit{wanted, optional, or unwanted}) of the aspects $\{(A_a, V_a, Att_a), (A_b, V_b, Att_b), ..., (A_k, V_k, Att_k)\}$ that are answered by the customer.  
%such that the search results given the elicited customer preferences converge to a single target product in as few steps as possible. 
%This dialogue plan is verbalized into a conversation by prompting LLMs, where the seller and customer narrow down the potential product search space. Eventually, the seller's searches given the elicited customer preferences converge to a few products to recommend, that satisfy the customer's requirements.

% \paragraph{Decision Tree-Based Search Strategy.}%\nikhita{see earlier comments: I think this should be merged into Sec 3.3 as a subsection for better readability} 
% \label{sec:decision_tree_strategy}
% We leverage the decision tree algorithm to pick the best attributes to maximally divide the search space so that the number of candidate products quickly converges as more product aspects in $preference$ are uncovered. %\shervin {divide the space so the space converges? consider re-phrasing.} 
% %as the tree depth increases. 
% Specifically, as Algorithm \ref{alg:decision_tree_search} shows, each search procedure dynamically takes the retrieved product results $P_o$ from a rule-based $FacetedRanker$, which returns all products that satisfy all the \textit{wanted} features and filters out any products with \textit{unwanted} conditions from the target product category. %It then fits a decision tree based on the Gini index~\cite{mehta1996sliq} using the data constructed from $P_o$.
% Each $DecisionTreeSearch$ starts with an initial $Query$ consisting of product category $PC$ and product aspect-value-interest tuples $\{(A_1, V_1, I_1), ..., (A_i, V_i, I_i)\}$ \textit{previously elicited} from the customer. By searching $FacetedRanker$ with $Query$, we first obtain the search results $P_o$. 
% Then we construct the training dataset to fit a decision tree based on $P_o$. We use all the aspects from $Catalog$ as the features for each product. If a product $p_n$ does not have an aspect, the corresponding value will be empty. %is represented using a bag of features in the form of $X_n=\{(A_1, V_1), (A_2, V_2), ..., (A_m, V_m)\}$. 
% We concatenate all aspect-value pairs of the product to be its label $y_n$. For example, let's consider a product $p_n$ from the \textit{tablet case} category with three features. $X_n$ can be represented as \{(model, iPad), (color, blue), (material, TPU)\} and the corresponding $y_n$ is a string like ``\textit{model:iPad\&color:blue\&material:TPU}''. In other words, products associated with the same aspect-value pairs all belong to the same leaf node of the decision tree. Then we use the constructed inputs and labels, $X$ and $y$, to fit a decision tree $Tree$, which contains a structured collection of nodes whose attributes are the product aspects and split conditions are their values. 

% After each $DecisionTreeSearch$ execution, we traverse the returned $Tree$ and according to the customer preference $Preference$, we obtain the best $Plan$ (a sequence of aspect-value-interest tuples) for dialogue generation. Specifically, we start from the root node of $Tree$ and decide the next child node to visit based on the customer $Preference$'s corresponding values and interest of the product aspect of the parent node. Any traversed aspect that does not appear in $preference$ is $optional$, indicating the customer does not care about the product aspect.
% Later, as part of the conversation, the seller asks the customer about the aspects following the $Plan$, and the customer provides their values and interests.  
%The depth of the tree equals the number of selected aspects to be discussed in the conversation. %This also results in multiple executions of $DecisionTreeSearch$. Since we simply use the decision tree to find the best ``search space divider'' for each stand-alone search scenario, without the need to generalize one decision tree to multiple unseen scenarios, it makes sense to overfit the decision tree at inference time.

\subsection{Verbalization} 
\label{sec:verbalization}
%\jason{Is it possible to show some fraction of prompts and move entire prompt to appendix? We have multiple prompts and seems unrealistic to include everything in main sections}
We feed the given $preference$ and dialogue plan contexts through zero-shot prompting to generate dialogues, proposing two methods of verbalization. 

%The LLM uses several conversation turns to verbalize each $Plan$ after executing $DecisionTreeSearch$. 

%Our three-stages dialogue generation approach is described below, and also shown in Algorithm \ref{alg:decision_tree_dialogue_generation}. 
\vspace{-0.5em}
\paragraph{Interactive Generation.}
\label{sec:IG}
We use different prompts for the seller and customer (Appendix Tables \ref{tab:seller_prompt} and \ref{tab:customer_prompt}) agents so that they alternatively speak to each other utterance-by-utterance, like in the real world. %Since the conversation is interactive, the customer agent may be replaced by a human in principle. 
The agents respond based on the previous conversation history. To ensure that the LLM-powered agents follow the instructions to adhere to the pre-determined features, we use a \textit{dialogue state tracker} \cite{young2010hidden} to track the customer's \textit{wanted}, \textit{optional}, and \textit{unwanted} features, that have been mentioned and are to be mentioned after each utterance. This is implemented by a hybrid strategy of rule-based keyword matching and a GPT-4 functional call prompt similar to prompts in Table \ref{tab:customer_prompt}, except that the expected output is the updated inputs to the ``update\_dialogue\_state'' function in Table \ref{tab:customer_prompt} instead of response utterances. This complex mechanism implies that the interactive approach is more prone to errors, as we show in \S\ref{sec:human_evaluation}.


\vspace{-0.5em}
\paragraph{Single-Pass Generation.}
\label{sec:SG}
Alternatively, we propose a simpler approach by feeding all product features pre-determined by the decision tree plan into a single LLM, and generating the entire conversation with a single pass (Table \ref{tab:simple_prompt}, see full prompts in Table \ref{tab:single_pass_prompt}). Despite we lose the interactive capacity, the generated conversations have fewer errors, as we show in \S\ref{sec:human_evaluation}.

\subsection{Enhancing Conversational Naturalness}
Our overall approach is described in Algorithm \ref{alg:decision_tree_dialogue_generation}.
\vspace{-0.5em}
\paragraph{How conversation starts.}
When dialogue starts, similar to prior work~\cite{zhang2018towards,bi2019conversational,zou2022learning}, each customer always starts with the target product category as an initial request. For example, a customer asks for a lipstick recommendation in Figure \ref{fig:illustration}. 

\vspace{-0.5em}
\paragraph{How conversation ends.}
% \subsubsection{Stage 3} 
When all remaining products from $P_o$ satisfy $preference$, the seller agent randomly recommends one of the products to the customer. The conversation continues for up to three more turns to conclude the shopping journey. Note that we do not specifically define finding the exact target product as a stopping criteria. Instead, we consider search results converging to a ``product family'' that satisfies $preference$ is close enough to satisfy customer's shopping interest.

%\nikhita{why '3 turns' here?}\Xiangci{To avoid infinitely verbose conversation irrelevant to product search.} 
%or terminates early when either party mentions keywords such as ``shopping cart'' or ``purchase''. 
%Depending on the dialogue verbalization strategy (Section \ref{sec:verbalization}), LLMs can generate dialogues either incrementally, after each stage or search action, or in a single pass once all the product features to be included in the conversation have been determined.%\shervin{Do we need to mention the two strategies in the last sentence? Seems redundant.}

% \subsubsection{Stage 2}
% We repeatedly execute a decision tree search strategy, $DecisionTreeSearch$ (Algorithm \ref{alg:decision_tree_search}) to identify the aspects to converse about until the product search results converge, which means all products in the remaining candidate product set $P_o$ are qualifying products whose attribute-value pairs match the sampled user preferences, or alternatively, there are no more product aspects to be asked about.

%A decision tree search strategy, utilizing the search results from a simple rule-based product search component called $Filter$, is used to identify the aspects to converse about until the product search results converge (i.e., all product search results qualify the customer preference constraints).\shervin{This sentence is confusing. I though the preferences identified the aspects to talk about? Are we just ordering them in stage 2? and Why is it called Filter? maybe we can have a better name.} $Filter$ accesses the product catalog and can return products that match the product category and satisfy the aspect-value constraints. 
%We repeatedly execute $DecisionTreeSearch$ (Section \ref{sec:decision_tree_strategy}, Algorithm \ref{alg:decision_tree_search}) to obtain the $Filter$'s outputs $P_o$ and the decision tree $Tree$. During each step, we traverse $Tree$ according to the customer preference $Preference$ to obtain the conversation plan $Plan$, which is a sequence of aspect-value-interest tuples. As part of the conversation, the seller asks the customer about the aspects in $Plan$, and the customer provides their values and interests. Any traversed aspect that does not appear in $preference$ is $optional$ and its corresponding value is empty, indicating the customer does not care about the attribute or its value. Stage 2 continues until the size of $P_o$ converges, which means all products in $P_o$ are qualifying products whose attribute-value pairs match the sampled user preferences, or alternatively, there are no more product aspects to be asked about.\shervin{This section is very hard to follow. It needs a major rewriting.


% \subsection{Improving Conversation Naturalness}
% \subsubsection{Providing Typical Options as Hints}
\vspace{-0.5em}
\paragraph{Improving naturalness by adding hints.}
\label{sec:improving_naturalness}
 % \shervin{The aspects are not proposed by the decision tree, they come from the catalog? This makes it sound like the problem is caused by the DT, but it would exist with any other method.} 
Customers may not always be aware of available options for a given product aspect, which was not well-addressed in prior studies~\cite{zhang2018towards,bi2019conversational,zou2022learning}. 
It is more user-friendly to provide customers with options when asking clarification questions. For example, if the aspect under consideration is the size of a product's solid-state drive (SSD), a general customer may not know the typical storage size of SSDs. %\shervin{previous sentences made it sounds like the aspect itself is the problem, but its more about the values.}
To mitigate this, we propose to always require the seller to provide hints based on up to 3 most frequent values associated with the product aspect being discussed (e.g., 256GB, 512GB, or 1TB for SSD size). 
%\shervin{Minor comment: do we order them, or let the LLM do that?} 
Similar to the proposal of product aspects by the decision tree, we also dynamically retrieve the most frequent values of each product aspect from the remaining candidate set of products. Providing typical aspect values as examples can help clarify the meaning of the product aspect, especially when it may not be known to customers, without requiring two additional turns of clarification questions.
%in case it is non-intuitive but also avoids the customer from bringing novel information about the products, which violates the assumption that the customer knows little about the interested product. \zhiyu{customer can still ask things not in the options}

% \subsubsection{Leveraging Internal LLM Knowledge}
\vspace{-0.5em}
\paragraph{Improving naturalness by LLM knowledge.}
The aspects may not always be intuitive to the customer, since customers have different levels of knowledge and may not understand certain technical or specific product aspects. LLMs are known to have world knowledge internally, which can be used to ``smooth'' out conversations given non-intuitive product features. We encourage LLM-powered agents to clarify the meaning of aspects that require additional knowledge to be understood. We also allow the seller agent to reorder the decision tree-selected product features to be discussed, if multiple features are provided at the same time (See bolded prompts in Table \ref{tab:simple_prompt}, Appendix Tables  \ref{tab:seller_prompt}, \ref{tab:customer_prompt} \& \ref{tab:single_pass_prompt}). Note that the decision tree is used to globally select the best-k product aspects among all possible aspect values to be elicited from the customer. The LLM interprets and locally reorders selected product aspects to enhance the natural flow of the conversation.


