
\section{Introduction}\label{sec:intro}

E-commerce platforms use product search to help customers find items in billion-scale product catalogs. 
Current product search systems rely on a \textit{search-and-refine} process, where customers iteratively refine keywords expressing their shopping needs and then assess the top--$k$ results for relevance. %Customers frequently refine their query as they assess product aspects and their own needs.
%for customers' shopping needs are heavily dependent on customers' patience and product domain expertise.
This process is customer-driven, and without sufficient expertise or patience, may lead to suboptimal purchase decisions or shopping journey abandonment. 
Conversational Product Search (CPS)~\cite{zhang2018towards,bi2019conversational,zou2022learning} %is rapidly emerging as an alternative to traditional product search methods~\cite{vandic2012faceted,van2016learning,ai2017learning}. Specifically, CPS aims to 
address the limitations of traditional product search by adding a conversational layer into product search, which provides a more natural and delightful shopping experience than traditional systems.

% Traditional search box-based product search relies on customers to directly interact with the search engine. They have to iteratively skim through and compare an overwhelming number of returned candidate products, to manually refine the vast product space as per their requirements. This can be especially frustrating for customers with limited knowledge about their target product, who have to perform significant research to find an appropriate product search query for their needs. 

\begin{figure}[t!]
\centering
\includegraphics[width=0.5\textwidth]{figures/illustration_v3.pdf}
\vspace{-2.5em}
\caption{An example of generated shopping conversation using \method, which leverages the LLM with different roles and decision tree-based planning.% Given the LLM-powered customer's initial request, the LLM-powered seller leverages the decision tree-powered search component to find the best product aspects to clarify with the customer efficiently.% \hl{[Nikhita: This example is better than the previous one, but can we have one with more complex features where the customer asks the seller for the meaning of certain features? This cannot be easily realized via a template and is more valuable/interesting.]}
}
\vspace{-1.5em}
\label{fig:illustration}
\end{figure}

%\nikhita{Can we have a better example conversation in Fig. 1? The current one looks pretty trivial. Maybe one that our approach has actually generated.}


% Instead of providing the top--$k$ results, it introduces an interactive shopping assistant to help customers find products to meet their needs.
% CPS represents a faster, more natural and more convenient shopping experience.
%Instead of keywords, customers can express their needs, preferences, and dislikes in natural language, which are used by the assistant to provide accurate product recommendations. 
%

%However, there are several challenges involved in building intelligent CPS assistants.
%The scarcity of datasets makes the development of intelligent CPS assistants difficult. 
Nonetheless, existing product search systems are not optimized for either natural language queries or real dialogues. One solution involves training
%To maintain quality, existing search systems must be re-designed or fine-tuned on natural language queries. For instance, training 
a model to rewrite conversations into decontextualized queries \cite{yu2020few, wu2022conqrr}. %, or to rank products with respect to the conversational context \cite{yu2021few} becomes essential.
However, prior rewriting datasets do not cover the shopping domain. 
Another solution is to directly train CPS models with dialogues %In either way, the lack of high-quality shopping conversations is a challenge for training such models in practice \cite{tu2023ssp}. 
~\cite{zhang2018towards,bi2019conversational,zou2022learning}, but this approach often relies on synthetic datasets with templated content, which limits the realism of the trained models. Consequently, the effectiveness of these models on real dialogues remains uncertain. Recently, \citet{Bernard:2023:SIGIR} released a small-scale dataset with expensive human annotation. 
Overall, the scarcity of datasets presents a significant challenge in developing intelligent CPS assistants.
%More recent studies \cite{brown2020language, li-etal-2023-autoconv} suggest that harnessing the capabilities of LLMs may become a promising alternative for dataset creation, potentially more cost-effective and time-efficient than crowdsourcing. 



%\shervin{Before we start discussing this we need to introduce the challenges of building CPS, then position our paper and scope which challenges we address.}

%In this paper, we propose to solve the problem backward by first \textit{scalably generating} realistic and controllable conversations on e-commerce domain that are robust to aforementioned weak points, and apply generated conversations to downstream tasks. The novelty of our approach \method (\textbf{T}arget-oriented e-comme\textbf{R}ce di\textbf{A}logue generation with de\textbf{C}ision tr\textbf{E}e b\textbf{R}anching) comes in grounding LLMs to a generated conversational plan sampled from real product catalogs (as evidences) through a decision tree algorithm, as well as dynamically controlling the generation process based on simulated user preference. Figure~\ref{fig:illustration} illustrates a customer engaging with our proposed system. %This is a significant improvement from prior work~\cite{Bernard:2023:SIGIR,zou2022learning}, which are limited both in the scale of their generated conversations, as well as in their approach to generating such conversations -- which are primarily based on template filling and do not represent realistic and natural customer-seller conversations. 

%Specifically, we are interested in generating target-oriented, customer and seller interactions, where the goal is to find a suitable target product matching a customer's shopping requirement. 



 
% Compared to traditional product search, conversational product search (CPS)\shervin{We need a more crisp definition of CPS and and make it clear that this is what we work on.} builds a virtual shopping assistant to guide the customers in narrowing down their product requirements. However, prior CPS research has significant limitations. \citet{zou2022learning} learned\shervin{It suddenly starts to read like a Related Work section from this sentence. Intro should be high level.} a joint representation of user, query, and item, then selected product features to fill into a fixed conversational template between the user and the system. As a result, each turn is always in the fixed format of ``System: What XXX would you like?'' and ``User: I want YYY XXX.'', making them less interesting. Moreover, their conversation can easily be trivial, since their selected product features such as ``outstanding price'' and ``real quality'' do not practically improve the product search in real use cases. 
%
% \citet{Bernard:2023:SIGIR} collected only 64 human-annotated e-commerce conversations based on only 46 products, % less than 20 products for each of the 4 domainswhich focuses on the naturalness of the conversation while neglecting the product search perspective. This makes their approach not scalable to collect a dataset covering a large product catalog without a search component. %\jason{they neglected product search and now this is not scalable?} 
% To the best of our knowledge, there is currently no publicly available, large-scale, natural conversational product search dataset, thus significantly hindering CPS research.


% JC: without additional explanation, maybe better to comment these sentences. 
% not everyone will understand why "outstanding price" is trivial without looking into actual dialogs
% also not clear about the connection between domain adapation and learned representations
% Furthermore, since their ranker is based on the learned representations, the products are not guaranteed to be found and are likely to encounter the domain adaptation problem.


%\method leverages LLMs to generate the first its kind of large-scale CPS dataset that represents realistic customer-seller shopping conversations as validated through human evaluation (Section~\ref{sec:human_evaluation}). %We opt for using LLMs like GPT-4~\cite{openai2023gpt4} or LLaMA 2~\cite{touvron2023llama} in our work, due to their conversational and complex instruction following capabilities.
% We leverage large language models (LLMs) to create a large-scale, human-like CPS dataset. 
%Each conversation consists of two agents conversing with each other, namely, a customer and a seller, both of which are simulated by LLMs. We ensure that the customer's shopping needs are always well-defined and can be related to a specific target product from a given e-commerce product catalog.
%\shervin{It's not clear how we started talking about this: we should clearly state that real CPS conversation must be grounded in a catalog to be useful (has prior work done this?) and this is a challenge we tackle. Secondly, realistic conversations require the customer to have a need, we represent this need by building sets of aspects from the catalog (and pair this with a product that meets those needs), and then plan the dialog by using a decision tree to identify a realistic set of questions to guide the conversation.}
% 


%However, there are several challenges with using LLMs as is, which we address in this work: 1) LLMs lack sufficient pre-trained knowledge from the e-commerce domain, where access to product catalogs and their metadata is critical, and 2) LLMs' inability to effectively \textit{plan} a conversation, i.e., asking timely and concise clarification questions to customers to better understand their shopping needs, such that the conversations are both \textit{natural} and of \textit{reasonable length}.



% Our proposal for CPS is to leverage large language models (LLMs) to create a large-scale, human-like conversation dataset. We focus on shopping conversations, where the customer has a clear shopping need related to a specific target product. 
% 
% This allows for the collected dataset to be used for training downstream conversational product ranking models. 
% 
% Recent LLMs, e.g. GPT-4 \cite{openai2023gpt4}, and LLaMA 2~\cite{touvron2023llama}, are able to understand complex instructions and make human-like responses. In addition, they are less expensive than human annotators, thus making it possible to create a large-scale conversational dataset within a reasonable time-frame and budget. However, there are several challenges: (1) Since LLMs are not trained with an e-commerce product catalog, they do not have direct access to rich product metadata; (2) Asking useful and efficient clarification questions to keep the target-oriented\shervin{Where do we define what target-oriented means? It should be clear what target means early in the intro, where the task is defined.} CPS process as short as possible has to be explored; (3) It's unclear how to model customers' preferences without real-world shopping data.

%To address the above limitations of using LLMs to generate a large-scale CPS dataset, we propose an approach, called \textbf{T}arget-oriented e-comme\textbf{R}ce di\textbf{A}logue generation with de\textbf{C}ision tr\textbf{E}e b\textbf{R}anching (\method). 


%Our conversations start by simulating user preference through sampling a specific product from our product catalog, and assigning its product attributes into three classes: (1) wanted; (2) unwanted and (3) optional. Then, the first turn starts from a customer LLM agent expressing its \textit{initial} shopping need via a natural language query. The seller agent performs a search over the entire existing product catalog, filtering product search results based on user preference. Next, a decision tree (DT) is employed to \textit{iteratively} comb through the product search results, and choose the top product aspects with the highest selectivity based on the most recent search results.\footnote{In decision trees, nodes that appear near the root of the tree have a higher coverage of products, and as the nodes branch down, the coverage of products by each node decreases drastically.} The selected aspects are verbalized by the seller and asked to the customer as preference elicitation questions (cf. Appendix Table~\ref{tab:good_example}). In the next conversation turns, the customer interactively chooses a desired value for the seller-inquired product aspect. This is then used by the seller to refine the current product result-set, and decide on the next product aspect to further elicit the customer's preferences. If the customer desires, they may also ask the seller questions seeking explanations on certain product features. Thus, the use of DTs allows \method to find the shortest path (plan) to the product that accurately matches the customer's shopping needs. This is important because previous studies on web search evaluation \cite{zhang2017evaluating} identified that increased user effort (e.g., total time or turns spent during search) decreases user satisfaction.

%To this end, we make the following contributions:



% In this work, we propose to solve the aforementioned limitations with a novel %\nikhita{the novelty of the approach needs to be emphasized better}
% decision tree-based target-oriented e-commerce dialogue generation (DT2EDGe) approach. %\nikhita{called X: add a name for the approach} 
% It leverages a decision tree algorithm for dialogue planning, while the LLM prompting verbalizes the plans to a natural conversation. %\jason{can we motivate decision tree better? why is it important to narrow down search space?}
% Unlike learned joint representation models in prior works which may fail to propose valid product features for conversation generation and ranking, the decision tree robustly selects the best product feature to maximally divide the candidate space.\shervin{This is not easy to understand. The task and problems have not been clearly described so far to clearly show that dialogue planning is grounded in the catalog, and the plans are designed to find the shortest path to the product.} We use decision tree to dynamically propose product aspects to efficiently refine the product search results obtained in response to a customer query. Thus, the success of the product search is guaranteed in the fewest steps of clarification. 
% We then use LLM prompting approaches to generate \textit{Wizard-of-Shopping (WoS)}, a large-scale, human-like target-oriented CPS conversation dataset, that is grounded to the rich product catalog.
% We explore various techniques to enable diverse and natural sounding dialogue generation. Further, we demonstrate the usefulness of WoS by training downstream conversational query generators and conversational product rankers, that significantly outperform out-of-box baselines (MRR of 0.838 vs. 0.162). 

In order to tackle the above challenge, we propose a novel approach, \method (\textbf{T}arget-oriented e-comme\textbf{R}ce di\textbf{A}logue generation with de\textbf{C}ision tr\textbf{E}e b\textbf{R}anching) to simulate shopping conversations between two LLM agents. Specifically, we assign two distinct roles to each LLM: (1) a \underline{customer} with specified shopping interests (a.k.a. the "Apprentice"); 
(2) a \underline{seller} agent (a.k.a. the "Wizard") that has access to a product catalog. %The advantage of this setup is since we have full control on how to define shopping interests, dialogue generation becomes controllable. For example, we can easily generate one conversation for an imaginary customer who is interested in the latest iPhone 15 with black color and high storage capacity. However, early observations show that creating realistic, fluent and factually consistent conversations is a challenge itself mainly due to the known shortcomings of LLMs, such as hallucination, prompt brittleness, lack of controllability and planning~\cite{kaddour2023challenges}. 
%
%To address these challenges, we propose a novel approach, \method (\textbf{T}arget-oriented e-comme\textbf{R}ce di\textbf{A}logue generation with de\textbf{C}ision tr\textbf{E}e b\textbf{R}anching), which 
To overcome the known shortcomings of LLMs, such as hallucination, prompt brittleness, lack of controllability, and planning~\cite{kaddour2023challenges}, 
two agents leverage dialogue plans predicted from decision tree to ground dialogue generation. Since the decision tree is trained to select product attributes that maximally split the search space, customers are guaranteed to reach target products in the shortest number of search conditions, minimizing user effort \cite{al2010review}. Human evaluations further validate that the generated dialogues are highly natural and coherent since LLMs can easily convert dialogue plans to natural conversations (See Figure \ref{fig:illustration} as an example). Our contributions are the following:
\vspace{-0.5em}
\begin{itemize}
\setlength\itemsep{-0.5em}
    \item A highly controllable, scalable, and easy-to-apply dialog generation approach \method for different shopping domains.
    \item Release of \textit{Wizard-of-Shopping} (\textit{WoS}) dataset which includes 3.6k shopping conversations across 3 different product domains.
    \item Demonstrate the utility of \textit{WoS} by showing improvements in conversational query generation and product ranking tasks.
\end{itemize}
%LLMs to ground generation on  decision tree powered LLMs to plan and generate shopping conversations, that are grounded in a product catalog and a simulated user.
%\method-generated dialogue plans enable customers to find their target product via the shortest number of search steps, while also maintaining conversation naturalness. %\hl{The previous sentence reads like we are proposing a CPS method (``guides customers to find their target product''). Instead, we just talk about the properties of generated conversations}
% dialogue planning approach for generating a natural CPS dataset that grounds the LLM-generated conversations to the local product catalog, and guarantees the success of the target-oriented search within the fewest possible steps. %\jason{I think we can emphasize novelty of our dialog planning, and prompting is just for verbalization. Lets make it explicit so that readers do not think our paper is one of prompt engineering papers where LLMs do everything in blackbox.}
% (2) We use \method to create and release \textit{Wizard-of-Shopping} (\textit{WoS}), the first large-scale CPS dataset. WoS contains 3.6K shopping conversations across 3 different product domains, and is easily adaptable and generalizable to other e-commerce domains. %\hl{3 domains/categories sound very limited. Overall, we focus on e-commerce domain. We could claim we experimented on 3 categories and could be adapted to all other categories} %It can be also be used to improve other downstream applications such as product recommendation and query generation.
% We release the \textit{Wizard-of-Shopping}\footnote{This is a placeholder URL for our data release. } dataset, consisting of 19.8 utterances on average for 3224 conversations across 3 product domains. It is the first large-scale, realistic sounding dataset of conversations on product search.%\jason{how many utterances and conversations? what domains? should mention here}
% \item A dataset that can be used to improve other  downstream applications such as product recommendation and query generation.
% (3) We demonstrate the utility of \textit{WoS} by showing improvements in two CPS sub-tasks: Conversational Query Generation, and Product Ranking.


