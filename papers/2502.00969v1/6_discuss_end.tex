\section{Conclusions}
We propose a method, \method, to automatically generate target-oriented shopping conversations without any human annotations. 
% Unlike prior work that learns various user or item representations, \method adds a conversation layer on top of the traditional product search to achieve CPS. 
We leverage decision tree to explore the vast product search space, and construct a dialogue plan that minimizes the number of search steps required to retrieve a relevant product.
%We then successfully compute a dialogue plan that is suitable for feeding into LLMs as prompts, and that guarantees the success of product search with the fewest product features to be clarified.
The resulting corpus (\textit{WoS}), generated using single-pass approach with GPT-4, not only achieved highly natural (4.2/5.0) and coherent (4.7/5.0) ratings from human annotators, but also showed substantial improvements when applied to two downstream tasks. By releasing our dataset and approach, we hope to expedite the research and development of intelligent CPS systems in future.

%We further improve the naturalness of our generated conversations through carefully curated prompts, dynamically listing example product values and leveraging the internal knowledge of the LLMs. We use \method's single pass generation technique with GPT-4 to create and release the \textit{Wizard-of-Shopping} (\textit{WoS}) dataset. Human evaluation shows it is sufficiently natural. Finally, we utilize \textit{WoS} to fine-tune models for downstream CQG and CPR tasks, and find that they significantly outperform baselines not trained on our dialogue dataset. %without using our dataset for training. Therefore, we conclude that our collected CPS dataset can effectively improve the downstream tasks.


\section*{Limitations}
%\subsection{Limitations}
Despite the demonstrated potential of our \method approach and the \textit{WoS} dataset, there are still some limitations that we leave for future work. %\jason{maybe we should work on summarizing all these restrictions. We definitely should discuss limitations, but not sure it is the best place to enumerate all at the last paragraph of our paper. Maybe create a separate section called limitation on section 6?} 
%First, the diversity of our conversations is still insufficient. We find that high-performing LLMs including GPT-4 are not sensitive to instructions regarding \textit{customer persona} (e.g., customer patience, expertise level). Thus, there is no distinction between multiple customers across conversations other than search behavior preferences. 
%Next, \textit{WoS} conversations are all target-oriented with a similar conversation flow -- starting with stating the target product category, identifying the product feature requirements, and finally recommending a qualifying product to the customer. Consequently, 
First, \method does not consider more complicated shopping behavior such as comparison among similar products~\cite{vedula2022matters}. %, or allowing customers to change their mind and roll back to a previous state. 
In the future, we could extend the ability of \method and allow customers to choose a similar product in the search results for comparison with assistance from a LLM agent. 
Second, the quality of \textit{WoS} conversations relies on the quality of the product catalog. Since noise in the product catalog can directly propagate to the generated conversations. Methods proposed to curate and clean the product catalog~\cite{ghani2006text,yang2022mave,vedula2022matters} could be applied to further clean a product catalog. %Moreover, the vocabulary size \jason{this seems redundant. in different places you already talk about the OOV problem} of the product features may directly affect the diversity of the conversation, as well as the feasibility of using the interactive system as a virtual shopping assistant. 
Finally, since the decision tree treats every product aspect and value as a categorical label, the semantics of product features are under-utilized. Future work may further leverage the zero-shot ability of LLMs to mine the semantics of the product aspects, so that similar product features may be merged to produce a more natural and efficient dialogue plan.

\section*{Ethical Statements}
The potential risk of our work could be biased simulations of real-world users' behavior, such that the learned downstream CQG and CPR models are biased. As a result, the end user's will of shopping might be distorted by the CPS system. However, we note that this risk is hypothetical.