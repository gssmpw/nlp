\section{Related Work}
\subsection{Object Counting}
Object counting plays a crucial role in applications such as public safety, administration, and labor efficiency. Traditional methods____ are restricted to fixed categories and require retraining when new categories are introduced. In contrast, class-agnostic counting____ offers more flexible solutions, supporting scenarios with limited data and enabling few-shot, reference-less, and zero-shot counting methods.

\vspace{-10pt}
\paragraph{Few-shot object counting} addresses scenarios with limited annotated data. GMN____ formulates class-agnostic counting as a matching task, leading to FamNet____, which incorporates ROI Pooling. BMNet____ introduces a bilinear matching network to refine similarity assessments. LOCA____ enhances feature representation and exemplar adaptation, while CounTR____ uses transformers to scale counting tasks. CACViT____ integrates Vision Transformers (ViT) into object counting for improved performance.

\vspace{-10pt}
\paragraph{Zero-shot object counting} operates without the need for category-specific training data. CLIP-Count____ leverages CLIP to encode text and images separately, enabling semantic associations, while VLCount____ enhances text-image association learning. PseCo____ introduces a SAM-based framework for segmentation, dot mapping, and detection, offering broad applicability but requiring significant computational resources.

\vspace{-10pt}
\paragraph{Reference-less object counting} do not rely on specific references. ZSC____ generates prototypes using textual inputs and filters image patches, reducing labeling requirements but facing scalability challenges. While these methods are flexible and scalable, they often struggle with accuracy across diverse categories due to the absence of multi-category density map labels in most datasets.

\subsection{Counting Loss}
The most commonly used loss function in object counting is mean squared error (MSE) loss____, which effectively measures the difference between predicted and ground truth maps. To capture associations, GMN____ introduces a similarity loss that quantifies the relations between predicted and actual similarities, while FamNet____ incorporates a perturbation loss to increase robustness. LOCA____ adds an auxiliary loss to support multi-channel learning. Other methods____ employ an InfoNCE-based contrastive loss____ to distinguish target regions from the background, while VA-Count____ uses contrastive loss to differentiate between known and unknown classes.

However, these loss functions do not address the imbalance between single-label and multi-label data, which often leads models to indiscriminately count all objects. Inspired by Focal Loss____, we propose Focal-MSE, an error-sensitive loss function that enhances sensitivity to specific regions. Focal-MSE promotes intra-class compactness and inter-class distinctiveness, transforming counting into a probability metric for specified categories and ensuring precise counting while overcoming the limitations of traditional loss.


% \subsection{Dirichlet Distribution}