@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}
@book{em:86,
  editor  = "Engelmore, Robert and Morgan, Anthony",
  title   = "Blackboard Systems",
  year    = 1986,
  address = "Reading, Mass.",
  publisher = "Addison-Wesley",
}

@inproceedings{c:83,
  author  = "Clancey, William J.",
  year    = 1983,
  title   = "{Communication, Simulation, and Intelligent
Agents: Implications of Personal Intelligent Machines
for Medical Education}",
  booktitle="Proceedings of the Eighth International Joint Conference on Artificial Intelligence {(IJCAI-83)}", 
  pages   = "556-560",
  address = "Menlo Park, Calif",
  publisher = "{IJCAI Organization}",
}
@inproceedings{c:84,
  author  = "Clancey, William J.",
  year    = 1984,
  title   = "{Classification Problem Solving}",
  booktitle = "Proceedings of the Fourth National 
              Conference on Artificial Intelligence",
  pages   = "45-54",
  address = "Menlo Park, Calif.",
  publisher="AAAI Press",
}
@article{r:80,
  author = {Robinson, Arthur L.},
  title = {New Ways to Make Microcircuits Smaller},
  volume = {208},
  number = {4447},
  pages = {1019--1022},
  year = {1980},
  doi = {10.1126/science.208.4447.1019},
  publisher = {American Association for the Advancement of Science},
  issn = {0036-8075},
  URL = {https://science.sciencemag.org/content/208/4447/1019},
  eprint = {https://science.sciencemag.org/content/208/4447/1019.full.pdf},
  journal = {Science},
}
@article{r:80x,
  author  = "Robinson, Arthur L.",
  year    = 1980,
  title   = "{New Ways to Make Microcircuits Smaller---Duplicate Entry}",
  journal = "Science",
  volume  =  208,
  pages   = "1019-1026",
}
@article{hcr:83,
title = {Strategic explanations for a diagnostic consultation system},
journal = {International Journal of Man-Machine Studies},
volume = {20},
number = {1},
pages = {3-19},
year = {1984},
issn = {0020-7373},
doi = {https://doi.org/10.1016/S0020-7373(84)80003-6},
url = {https://www.sciencedirect.com/science/article/pii/S0020737384800036},
author = {Diane Warner Hasling and William J. Clancey and Glenn Rennels},
abstract = {This article examines the problem of automatte explanation of reasoning, especially as it relates to expert systems. By explanation we mean the ability of a program to discuss what it is doing in some understandable way. We first present a general framework in which to view explanation and review some of the research done in this area. We then focus on the explanation system for NEOMYCIN, a medical consultation program. A consultation program interactively helps a user to solve a problem. Our goal is to have NEOMYCIN explain its problem-solving strategies. An explanation of strategy describes the plan the program is using to reach a solution. Such an explanation is usually concrete, referring to aspects of the current problem situation. Abstract explanations articulate a general principle, which can be applied in different situations; such explanations are useful in teaching and in explaining by analogy. We describe the aspects of NEOMYCIN that make abstract strategic explanations possible—the representation of strategic knowledge explicitly and separately from domain knowledge— and demonstrate how this representation can be used to generate explanations.}
}
@article{hcrt:83,
  author  = "Hasling, Diane Warner and Clancey, William J. and Rennels, Glenn R. and Test, Thomas",
  year    = 1983,
  title   = "{Strategic Explanations in Consultation---Duplicate}",
  journal = "The International Journal of Man-Machine Studies",
  volume  = 20,
  number  = 1,
  pages   = "3-19",
}
@techreport{r:86,
  author  = "Rice, James",
  year    = 1986,
  title   = "{Poligon: A System for Parallel Problem Solving}",
  type    = "Technical Report", 
  number  = "KSL-86-19", 
  institution = "Dept.\ of Computer Science, Stanford Univ.",
}
@phdthesis{c:79,
  author  = "Clancey, William J.",
  year    = 1979,
  title   = "{Transfer of Rule-Based Expertise
through a Tutorial Dialogue}",
  type    = "{Ph.D.} diss.",
  school  = "Dept.\ of Computer Science, Stanford Univ.",
  address = "Stanford, Calif.",
}
@unpublished{c:21,
  author  = "Clancey, William J.",
  title   = "{The Engineering of Qualitative Models}",
  year    = 2021,
  note    = "Forthcoming",
}
@misc{c:22,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{c:23,
  title        = "Pluto: The 'Other' Red Planet",
  author       = "{NASA}",
  howpublished = "\url{https://www.nasa.gov/nh/pluto-the-other-red-planet}",
  year         = 2015,
  note         = "Accessed: 2018-12-06"
}
counting% Long form of conference & journal abbreviations -- especially for camera ready
@String(PAMI  = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV  = {Int. J. Comput. Vis.})
@String(CVPR  = {IEEE Conf. Comput. Vis. Pattern Recognit.})
@String(ICCV  = {Int. Conf. Comput. Vis.})
@String(ECCV  = {Eur. Conf. Comput. Vis.})
@String(NeurIPS = {Adv. Neural Inform. Process. Syst.})
@String(ICML  = {Int. Conf. Mach. Learn.})
@String(ICLR  = {Int. Conf. Learn. Represent.})
@String(ACCV  = {Asian Conf. Comput. Vis.})
@String(BMVC  = {Brit. Mach. Vis. Conf.})
@String(CVPRW = {IEEE Conf. Comput. Vis. Pattern Recognit. Worksh.})
@String(AAAI  = {AAAI})
@String(IJCAI = {IJCAI})
@String(ICIP  = {IEEE Int. Conf. Image Process.})
@String(ICPR  = {Int. Conf. Pattern Recognit.})
@String(ICASSP=	{ICASSP})
@String(ICME  = {Int. Conf. Multimedia and Expo})
@String(JMLR  = {J. Mach. Learn. Res.})
@String(TMLR  = {Trans. Mach. Learn Res.})
@String(TOG   = {ACM Trans. Graph.})
@String(TIP   = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TCSVT = {IEEE Trans. Circuit Syst. Video Technol.})
@String(TMM   = {IEEE Trans. Multimedia})
@String(ACMMM = {ACM Int. Conf. Multimedia})
@String(PR    = {Pattern Recognition})

@String(MNI	  = {Nature Mach. Intell.})
@String(SPL	  = {IEEE Sign. Process. Letters})
@String(VR    = {Vis. Res.})
@String(JOV	  = {J. Vis.})
@String(TVC   = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF   = {Comput. Graph. Forum})
@String(CVM   = {Computational Visual Media})


% Short form of conference & journal abbreviations -- especially for submission version
% if desired, remove these macros in favor of the above ones
@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NeurIPS = {NeurIPS})
@String(ICML  = {ICML})
@String(ICLR  = {ICLR})
@String(ACCV  = {ACCV})
@String(BMVC  =	{BMVC})
@String(CVPRW = {CVPRW})
@String(AAAI  = {AAAI})
@String(IJCAI = {IJCAI})
@String(ICIP  = {ICIP})
@String(ICPR  = {ICPR})
@String(ICASSP=	{ICASSP})
@String(ICME  =	{ICME})
@String(JMLR  = {JMLR})
@String(TMLR  = {TMLR})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(PR    = {PR})



@inproceedings{Alex2023segment,
  author       = {Alexander Kirillov and
                  Eric Mintun and
                  Nikhila Ravi and
                  Hanzi Mao and
                  Chlo{\'{e}} Rolland and
                  Laura Gustafson and
                  Tete Xiao and
                  Spencer Whitehead and
                  Alexander C. Berg and
                  Wan{-}Yen Lo and
                  Piotr Doll{\'{a}}r and
                  Ross B. Girshick},
  title        = {Segment Anything},
  booktitle    = {Proc. {IEEE/CVF} Int. Conf. Comput. Vis.},
  pages        = {3992--4003},
  year         = {2023}
}


@inproceedings{Li2023BLIP2,
  author       = {Junnan Li and
                  Dongxu Li and
                  Silvio Savarese and
                  Steven C. H. Hoi},
  title        = {{BLIP-2:} Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models},
  booktitle    = {Proc. Int. Conf. Mach. Learn},
  pages        = {19730--19742},
  year         = {2023}
}


@article{Liu2023DINO,
  author       = {Shilong Liu and
                  Zhaoyang Zeng and
                  Tianhe Ren and
                  Feng Li and
                  Hao Zhang and
                  Jie Yang and
                  Chunyuan Li and
                  Jianwei Yang and
                  Hang Su and
                  Jun Zhu and
                  Lei Zhang},
  title        = {Grounding {DINO:} Marrying {DINO} with Grounded Pre-Training for Open-Set
                  Object Detection},
  journal      = {arXiv:2303.05499},
  year         = {2023}
}

@inproceedings{ming2022delving,
  author       = {Yifei Ming and
                  Ziyang Cai and
                  Jiuxiang Gu and
                  Yiyou Sun and
                  Wei Li and
                  Yixuan Li},
  title        = {Delving into Out-of-Distribution Detection with Vision-Language Representations},
  booktitle   =   {Adv. Neural Inform. Process. Syst.},
  pages       =   {35087--35102},
  year        =   {2022}
}

@inproceedings{du2022learning,
  author       = {Yu Du and
                  Fangyun Wei and
                  Zihe Zhang and
                  Miaojing Shi and
                  Yue Gao and
                  Guoqi Li},
  title        = {Learning to Prompt for Open-Vocabulary Object Detection with Vision-Language
                  Model},
  booktitle =   {Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages     =   {14084--14093},
  year      =   {2022}
}

@inproceedings{song2022vision,
  author       = {Sibo Song and
                  Jianqiang Wan and
                  Zhibo Yang and
                  Jun Tang and
                  Wenqing Cheng and
                  Xiang Bai and
                  Cong Yao},
  title        = {Vision-Language Pre-Training for Boosting Scene Text Detectors},
  booktitle =   {Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages     =   {15681--15691},
  year      =   {2022}
}

@inproceedings{dou2022coarse,
  title        = {Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone},
  author       = {Zi{-}Yi Dou and
                  Aishwarya Kamath and
                  Zhe Gan and
                  Pengchuan Zhang and
                  Jianfeng Wang and
                  Linjie Li and
                  Zicheng Liu and
                  Ce Liu and
                  Yann LeCun and
                  Nanyun Peng and
                  Jianfeng Gao and
                  Lijuan Wang},
  booktitle    =   {Adv. Neural Inform. Process. Syst.},
  pages        =   {32942--32956},
  year         =   {2022}
}

@inproceedings{li2023clip,
  author       = {Siyuan Li and
                  Li Sun and
                  Qingli Li},
  title        = {CLIP-ReID: Exploiting Vision-Language Model for Image Re-identification
                  without Concrete Text Labels},
  booktitle    = {Proc. AAAI Conf. Artif. Intell.},
  pages        = {1405--1413},
  year         = {2023}
}

@article{he2023region,
  title        = {Region Generation and Assessment Network for Occluded Person Re-Identification},
  author       = {Shuting He and
                  Weihua Chen and
                  Kai Wang and
                  Hao Luo and
                  Fan Wang and
                  Wei Jiang and
                  Henghui Ding},
  journal   =   {IEEE Trans. Inf. Forensics Secur.},
  volume       = {19},
  pages        = {120--132},
  year      =   {2023}
}

@inproceedings{chen2023towards,
  title        = {Towards Modality-Agnostic Person Re-identification with Descriptive
                  Query},
  author       = {Cuiqun Chen and
                  Mang Ye and
                  Ding Jiang},
  booktitle =   {Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages     =   {15128--15137},
  year      =   {2023}
}

@inproceedings{xie2023unified,
  title        = {A Unified Multi-modal Structure for Retrieving Tracked Vehicles through
                  Natural Language Descriptions},
  author       = {Dong Xie and
                  Linhu Liu and
                  Shengjun Zhang and
                  Jiang Tian},
  booktitle =   {Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. Workshops},
  pages     =   {5418--5426},
  year      =   {2023}
}

@inproceedings{bai2023relation,
  author       = {Yang Bai and
                  Min Cao and
                  Daming Gao and
                  Ziqiang Cao and
                  Chen Chen and
                  Zhenfeng Fan and
                  Liqiang Nie and
                  Min Zhang},
  title        = {RaSa: Relation and Sensitivity Aware Representation Learning for Text-based
                  Person Search},
  booktitle    = {Proc. Int. Joint Conf. Artif. Intell.},
  pages        = {555--563},
  year         = {2023}
}

@inproceedings{Rad2021CLIP,
  author       = {Alec Radford and
                  Jong Wook Kim and
                  Chris Hallacy and
                  Aditya Ramesh and
                  Gabriel Goh and
                  Sandhini Agarwal and
                  Girish Sastry and
                  Amanda Askell and
                  Pamela Mishkin and
                  Jack Clark and
                  Gretchen Krueger and
                  Ilya Sutskever},
  title        = {Learning Transferable Visual Models From Natural Language Supervision},
  booktitle    = {Proc. Int. Conf. Mach. Learn},
  pages        = {8748--8763},
  year         = {2021}
}

@inproceedings{Li2022BLIP,
  author       = {Junnan Li and
                  Dongxu Li and
                  Caiming Xiong and
                  Steven C. H. Hoi},
  title        = {{BLIP:} Bootstrapping Language-Image Pre-training for Unified Vision-Language
                  Understanding and Generation},
  booktitle    = {Proc. Int. Conf. Mach. Learn},
  pages        = {12888--12900},
  year         = {2022}
}


@inproceedings{Bansal18zero,
  author       = {Ankan Bansal and
                  Karan Sikka and
                  Gaurav Sharma and
                  Rama Chellappa and
                  Ajay Divakaran},
  title        = {Zero-Shot Object Detection},
  booktitle    = {Proc. Eur. Conf. Comput. Vis.},
  pages        = {397--414},
  year         = {2018}
}

@inproceedings{zheng2021zero,
  author       = {Ye Zheng and
                  Jiahong Wu and
                  Yongqiang Qin and
                  Faen Zhang and
                  Li Cui},
  title        = {Zero-Shot Instance Segmentation},
  booktitle    = {Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages        = {2593--2602},
  year         = {2021}
}

@inproceedings{lu2019class,
  author       = {Erika Lu and
                  Weidi Xie and
                  Andrew Zisserman},
  title        = {Class-Agnostic Counting},
  booktitle    = {Proc. Asian Conf. Comput. Vis.},
  year         = {2018}
}

@inproceedings{ranjan2021learning,
  author       = {Viresh Ranjan and
                  Udbhav Sharma and
                  Thu Nguyen and
                  Minh Hoai},
  title        = {Learning To Count Everything},
  booktitle    = {Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages        = {3394--3403},
  year         = {2021}
}
}

@inproceedings{ranjan2022exemplar,
  title        = {Learning To Count Everything},
  author       = {Viresh Ranjan and
                  Udbhav Sharma and
                  Thu Nguyen and
                  Minh Hoai},
  booktitle={Proc. Asian Conf. Comput. Vis.},
  pages={3121--3137},
  year={2022}
}

@inproceedings{djukic2023low,
  author       = {Nikola Djukic and
                  Alan Lukezic and
                  Vitjan Zavrtanik and
                  Matej Kristan},
  title        = {A Low-Shot Object Counting Network With Iterative Prototype Adaptation},
  booktitle    = {Proc. IEEE/CVF Int. Conf. Comput. Vis.},
  pages        = {18826--18835},
  year         = {2023}
}

@inproceedings{liu2022countr,
  author       = {Chang Liu and
                  Yujie Zhong and
                  Andrew Zisserman and
                  Weidi Xie},
  title        = {CounTR: Transformer-based Generalised Visual Counting},
  booktitle    = {Proc. Brit. Mach. Vis. Conf.},
  pages        = {370},
  year         = {2022}
}

@inproceedings{shi2022represent,
  author       = {Min Shi and
                  Hao Lu and
                  Chen Feng and
                  Chengxin Liu and
                  Zhiguo Cao},
  title        = {Represent, Compare, and Learn: {A} Similarity-Aware Framework for
                  Class-Agnostic Counting},
  booktitle    = {Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages        = {9519--9528},
  year         = {2022}
}

@inproceedings{xu2023zero,
  author       = {Jingyi Xu and
                  Hieu Le and
                  Vu Nguyen and
                  Viresh Ranjan and
                  Dimitris Samaras},
  title        = {Zero-Shot Object Counting},
  booktitle    = {Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages        = {15548--15557},
  year         = {2023}
}

@inproceedings{jiang2023clip,
  author       = {Ruixiang Jiang and
                  Lingbo Liu and
                  Changwen Chen},
  title        = {CLIP-Count: Towards Text-Guided Zero-Shot Object Counting},
  booktitle    = {Proc. {ACM} Multimedia},
  pages        = {4535--4545},
  year         = {2023}
}

@inproceedings{rao2022denseclip,
  author       = {Yongming Rao and
                  Wenliang Zhao and
                  Guangyi Chen and
                  Yansong Tang and
                  Zheng Zhu and
                  Guan Huang and
                  Jie Zhou and
                  Jiwen Lu},
  title        = {DenseCLIP: Language-Guided Dense Prediction with Context-Aware Prompting},
  booktitle    = {Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages        = {18061--18070},
  year         = {2022}
}

@inproceedings{zhong2022regionclip,
  author       = {Yiwu Zhong and
                  Jianwei Yang and
                  Pengchuan Zhang and
                  Chunyuan Li and
                  Noel Codella and
                  Liunian Harold Li and
                  Luowei Zhou and
                  Xiyang Dai and
                  Lu Yuan and
                  Yin Li and
                  Jianfeng Gao},
  title        = {RegionCLIP: Region-based Language-Image Pretraining},
  booktitle    = {Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages        = {16772--16782},
  year         = {2022}
}

@inproceedings{zhou2023zegclip,
  author       = {Ziqin Zhou and
                  Yinjie Lei and
                  Bowen Zhang and
                  Lingqiao Liu and
                  Yifan Liu},
  title        = {ZegCLIP: Towards Adapting {CLIP} for Zero-shot Semantic Segmentation},
  booktitle    = {Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages        = {11175--11185},
  year         = {2023}
}

@article{lin2023gridclip,
  author       = {Jiayi Lin and
                  Shaogang Gong},
  title        = {GridCLIP: One-Stage Object Detection by Grid-Level {CLIP} Representation
                  Learning},
  journal      = {arXiv:2303.09252},
  year         = {2023}
}

@inproceedings{paiss2023teaching,
  author       = {Roni Paiss and
                  Ariel Ephrat and
                  Omer Tov and
                  Shiran Zada and
                  Inbar Mosseri and
                  Michal Irani and
                  Tali Dekel},
  title        = {Teaching {CLIP} to Count to Ten},
  booktitle    = {Proc. {IEEE/CVF} Int. Conf. Comput. Vis.},
  pages        = {3147--3157},
  year         = {2023}
}

@inproceedings{shi2024training,
  author       = {Zenglin Shi and
                  Ying Sun and
                  Mengmi Zhang},
  title        = {Training-free Object Counting with Prompts},
  booktitle    = {Proc. IEEE/CVF Winter Conf. Appl. Comput. Vis.},
  pages        = {322--330},
  year         = {2024}
}

@inproceedings{liang2023crowdclip,
  author       = {Dingkang Liang and
                  Jiahao Xie and
                  Zhikang Zou and
                  Xiaoqing Ye and
                  Wei Xu and
                  Xiang Bai},
  title        = {CrowdCLIP: Unsupervised Crowd Counting via Vision-Language Model},
  booktitle    = {Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages        = {2893--2903},
  year         = {2023}
}

@article{hobley2022learning,
  author       = {Michael A. Hobley and
                  Victor Prisacariu},
  title        = {Learning to Count Anything: Reference-less Class-agnostic Counting
                  with Weak Supervision},
  journal      = {arXiv:2205.10203},
  year         = {2022}
}

@article{wang2023gcnet,
  author       = {Mingjie Wang and
                  Yande Li and
                  Jun Zhou and
                  Graham W. Taylor and
                  Minglun Gong},
  title        = {GCNet: Probing self-similarity learning for Generalized Counting Network},
  journal      = {Pattern Recognit.},
  volume       = {153},
  pages        = {110513},
  year         = {2024}
}

@inproceedings{hsieh2017drone,
  author       = {Meng{-}Ru Hsieh and
                  Yen{-}Liang Lin and
                  Winston H. Hsu},
  title        = {Drone-Based Object Counting by Spatially Regularized Regional Proposal
                  Network},
  booktitle    = {Proc. {IEEE/CVF} Int. Conf. Comput. Vis.},
  pages        = {4165--4173},
  year         = {2017}
}

@inproceedings{yang2021class,
  author       = {Shuo{-}Diao Yang and
                  Hung{-}Ting Su and
                  Winston H. Hsu and
                  Wen{-}Chin Chen},
  title        = {Class-agnostic Few-shot Object Counting},
  booktitle    = {Proc. IEEE/CVF Winter Conf. Appl. Comput. Vis.},
  pages        = {869--877},
  year         = {2021}
}

@inproceedings{you2023few,
  author       = {Zhiyuan You and
                  Kai Yang and
                  Wenhan Luo and
                  Xin Lu and
                  Lei Cui and
                  Xinyi Le},
  title        = {Few-shot Object Counting with Similarity-Aware Feature Enhancement},
  booktitle    = {Proc. IEEE/CVF Winter Conf. Appl. Comput. Vis.},
  pages        = {6304--6313},
  year         = {2023}
}

@inproceedings{babu2022completely,
  author       = {Deepak Babu Sam and
                  Abhinav Agarwalla and
                  Jimmy Joseph and
                  Vishwanath A. Sindagi and
                  R. Venkatesh Babu and
                  Vishal M. Patel},
  title        = {Completely Self-supervised Crowd Counting via Distribution Matching},
  booktitle    = {Proc. Eur. Conf. Comput. Vis.},
  pages        = {186--204},
  year         = {2022}
}

@inproceedings{mundhenk2016large,
  author       = {T. Nathan Mundhenk and
                  Goran Konjevod and
                  Wesam A. Sakla and
                  Kofi Boakye},
  title        = {A Large Contextual Dataset for Classification, Detection and Counting
                  of Cars with Deep Learning},
  booktitle    = {Proc. Eur. Conf. Comput. Vis.},
  pages        = {785--800},
  year         = {2016}
}

@inproceedings{arteta2016counting,
  author       = {Carlos Arteta and
                  Victor S. Lempitsky and
                  Andrew Zisserman},
  title        = {Counting in the Wild},
  booktitle    = {Proc. Eur. Conf. Comput. Vis.},
  pages        = {483--498},
  year         = {2016}
}

@inproceedings{tyagi2023degpr,
  author       = {Aayush Kumar Tyagi and
                  Chirag Mohapatra and
                  Prasenjit Das and
                  Govind Makharia and
                  Lalita Mehra and
                  Prathosh AP and
                  Mausam},
  title        = {DeGPR: Deep Guided Posterior Regularization for Multi-Class Cell Detection
                  and Counting},
  booktitle    = {Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages        = {23913--23923},
  year         = {2023}
}

@InProceedings{Sun_2023_CVPR,
  author       = {Guolei Sun and
                  Zhaochong An and
                  Yun Liu and
                  Ce Liu and
                  Christos Sakaridis and
                  Deng{-}Ping Fan and
                  Luc {Van Gool}},
  title        = {Indiscernible Object Counting in Underwater Scenes},
  booktitle    = {Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages        = {13791--13801},
  year         = {2023}
}

@inproceedings{zhang2016vision,
  author       = {Zhimei Zhang and
                  Kun Liu and
                  Feng Gao and
                  Xianyun Li and
                  Guodong Wang},
  title        = {Vision-based vehicle detecting and counting for traffic flow analysis},
  booktitle    = {Proc. IEEE Int. Joint Conf. Neural Networks},
  pages        = {2267--2273},
  year         = {2016}
}

@inproceedings{zhu2023daot,
  author       = {Huilin Zhu and
                  Jingling Yuan and
                  Xian Zhong and
                  Zhengwei Yang and
                  Zheng Wang and
                  Shengfeng He},
  title        = {{DAOT:} Domain-Agnostically Aligned Optimal Transport for Domain-Adaptive
                  Crowd Counting},
  booktitle    = {Proc. {ACM} Multimedia},
  pages        = {4319--4329},
  year         = {2023}
}


@article{zhu2023find,
  author       = {Huilin Zhu and
                  Jingling Yuan and
                  Xian Zhong and
                  Liang Liao and
                  Zheng Wang},
  title        = {Find Gold in Sand: Fine-Grained Similarity Mining for Domain-Adaptive
                  Crowd Counting},
  journal      = {{IEEE} Trans. Multimedia},
  volume       = {26},
  pages        = {3842--3855},
  year         = {2024}
}

@inproceedings{ranjan2018iterative,
  author       = {Viresh Ranjan and
                  Hieu M. Le and
                  Minh Hoai},
  title        = {Iterative Crowd Counting},
  booktitle    = {Proc. Eur. Conf. Comput. Vis.},
  pages        = {278--293},
  year         = {2018}
}

@inproceedings{liu2020adaptive,
  author       = {Xiyang Liu and
                  Jie Yang and
                  Wenrui Ding and
                  Tieqiang Wang and
                  Zhijin Wang and
                  Junjun Xiong},
  title        = {Adaptive Mixture Regression Network with Local Counting Map for Crowd
                  Counting},
  booktitle    = {Proc. Eur. Conf. Comput. Vis.},
  pages        = {241--257},
  year         = {2020}
}

@inproceedings{kang2023vlcounter,
  author       = {Seunggu Kang and
                  WonJun Moon and
                  Euiyeon Kim and
                  Jae{-}Pil Heo},
  title        = {VLCounter: Text-Aware Visual Representation for Zero-Shot Object Counting},
  booktitle    = {Proc. {AAAI} Conf. Artif. Intell.},
  pages        = {2714--2722},
  year         = {2024}
}

@article{huang2023point,
  author       = {Zhizhong Huang and
                  Mingliang Dai and
                  Yi Zhang and
                  Junping Zhang and
                  Hongming Shan},
  title        = {Point, Segment and Count: {A} Generalized Framework for Object Counting},
  journal      = {arXiv:2311.12386},
  year         = {2023}
}

@inproceedings{nguyen2022few,
  author       = {Thanh Nguyen and
                  Chau Pham and
                  Khoi Nguyen and
                  Minh Hoai},
  title        = {Few-Shot Object Counting and Detection},
  booktitle    = {Proc. Eur. Conf. Comput. Vis.},
  pages        = {348--365},
  year         = {2022}
}

@inproceedings{gong2022class,
  author       = {Shenjian Gong and
                  Shanshan Zhang and
                  Jian Yang and
                  Dengxin Dai and
                  Bernt Schiele},
  title        = {Class-Agnostic Object Counting Robust to Intraclass Diversity},
  booktitle    = {Proc. Eur. Conf. Comput. Vis.},
  pages        = {388--403},
  year         = {2022}
}

@inproceedings{loshchilov2017decoupled,
  author       = {Ilya Loshchilov and
                  Frank Hutter},
  title        = {Decoupled Weight Decay Regularization},
  booktitle    = {Proc. Int. Conf. Learn. Represent.},
  year         = {2019}
}

@article{jiang2023t,
  author       = {Qing Jiang and
                  Feng Li and
                  Tianhe Ren and
                  Shilong Liu and
                  Zhaoyang Zeng and
                  Kent Yu and
                  Lei Zhang},
  title        = {T-Rex: Counting by Visual Prompting},
  journal      = {arXiv:2311.13596},
  year         = {2023}
}

@inproceedings{arteta2014interactive,
  author    = {Carlos Arteta and
               Victor S. Lempitsky and
               J. Alison Noble and
               Andrew Zisserman},
  title     = {Interactive Object Counting},
  booktitle = {Proc. Eur. Conf. Comput. Vis.},
  pages     = {504--518},
  year      = {2014}
}

@inproceedings{zhang2016single,
  author    = {Yingying Zhang and
               Desen Zhou and
               Siqin Chen and
               Shenghua Gao and
               Yi Ma},
  title     = {Single-Image Crowd Counting via Multi-Column Convolutional Neural
               Network},
  booktitle = {Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages     = {589--597},
  year      = {2016}
}

@inproceedings{WangX0024,
  author       = {Zhicheng Wang and
                  Liwen Xiao and
                  Zhiguo Cao and
                  Hao Lu},
  title        = {Vision Transformer Off-the-Shelf: {A} Surprising Baseline for Few-Shot
                  Class-Agnostic Counting},
  booktitle    = {Proc. AAAI Conf. Artif. Intell.},
  pages        = {5832--5840},
  year         = {2024},
}

@inproceedings{zhu2024zero,
  author       = {Huilin Zhu and
                  Jingling Yuan and
                  Zhengwei Yang and
                  Yu Guo and
                  Zheng Wang and
                  Xian Zhong and
                  Shengfeng He},
  title        = {Zero-shot Object Counting with Good Exemplars},
  booktitle      = {Proc. Eur. Conf. Comput. Vis.},
  year         = {2024}
}

@article{oord2018representation,
  author       = {A{\"{a}}ron {van den Oord} and
                  Yazhe Li and
                  Oriol Vinyals},
  title        = {Representation Learning with Contrastive Predictive Coding},
  journal      = {arXiv:1807.03748},
  year         = {2018}
}

@inproceedings{wen2021sphereface2,
  author       = {Yandong Wen and
                  Weiyang Liu and
                  Adrian Weller and
                  Bhiksha Raj and
                  Rita Singh},
  title        = {SphereFace2: Binary Classification is All You Need for Deep Face Recognition},
  booktitle    = {Proc. Int. Conf. Learn. Represent.},
  year         = {2022}
}

@article{everingham2010pascal,
  author       = {Mark Everingham and
                  Luc {Van Gool} and
                  Christopher K. I. Williams and
                  John M. Winn and
                  Andrew Zisserman},
  title        = {The Pascal Visual Object Classes {(VOC)} Challenge},
  journal      = {Int. J. Comput. Vis.},
  volume       = {88},
  number       = {2},
  pages        = {303--338},
  year         = {2010}
}

@inproceedings{regmi2024reweightood,
  title={ReweightOOD: Loss Reweighting for Distance-based OOD Detection},
  author={Regmi, Sudarshan and Panthi, Bibek and Ming, Yifei and Gyawali, Prashnna K and Stoyanov, Danail and Bhattarai, Binod},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages={131--141},
  year={2024}
}

@inproceedings{he2024gradient,
  author       = {Jiangpeng He and
                  Fengqing Zhu},
  title        = {Gradient Reweighting: Towards Imbalanced Class-Incremental Learning},
  booktitle    = {Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages        = {16668--16677},
  year         = {2024}
}

@inproceedings{qiu2023simple,
  author       = {Shikai Qiu and
                  Andres Potapczynski and
                  Pavel Izmailov and
                  Andrew Gordon Wilson},

  title        = {Simple and Fast Group Robustness by Automatic Feature Reweighting},
  booktitle    = {Int. Conf. Mach. Learn.},
  pages        = {28448--28467},
  year         = {2023}
}

@article{lin2017focal,
  author       = {Tsung{-}Yi Lin and
                  Priya Goyal and
                  Ross B. Girshick and
                  Kaiming He and
                  Piotr Doll{\'{a}}r},
  title        = {Focal Loss for Dense Object Detection},
  journal      = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
  volume       = {42},
  number       = {2},
  pages        = {318--327},
  year         = {2020}
}

@inproceedings{lin2024gramformer,
  author       = {Hui Lin and
                  Zhiheng Ma and
                  Xiaopeng Hong and
                  Qinnan Shangguan and
                  Deyu Meng},
  title        = {Gramformer: Learning Crowd Counting via Graph-Modulated Transformer},
  booktitle    = {Proc. AAAI Conf. Artif. Intell.},
  pages        = {3395--3403},
  year         = {2024}
}

@inproceedings{du2023domain,
  author       = {Zhipeng Du and
                  Jiankang Deng and
                  Miaojing Shi},
  title        = {Domain-General Crowd Counting in Unseen Scenarios},
  booktitle    = {Proc. AAAI Conf. Artif. Intell.},
  pages        = {561--570},
  year         = {2023}
}

@inproceedings{hobley2023abc,
  author       = {Michael A. Hobley and
                  Victor Adrian Prisacariu},
  title        = {{ABC} Easy as 123: {A} Blind Counter for Exemplar-Free Multi-Class
                  Class-agnostic Counting},
  booktitle    = {Proc. Eur. Conf. Comput. Vis.},
  year         = {2024}
}
@article{amini2023open,
  author       = {Niki Amini{-}Naieni and
                  Kiana Amini{-}Naieni and
                  Tengda Han and
                  Andrew Zisserman},
  title        = {Open-world Text-specified Object Counting},
  journal      = {arXiv:2306.01851},
  year         = {2023}
}