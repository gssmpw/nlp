\section{Evaluation}
To demonstrate the effectiveness of RouteFlow, we conducted a quantitative experiment and a user study.

\subsection{Quantitative Evaluation}
\label{sec:quantitative}



\noindent\textbf{Datasets}.
The quantitative evaluation was conducted on seven datasets from real-world applications: Taxi~\cite{yuan2011drive,yuan2010tdrive}, BirdMap~\cite{BirdMap}, Railway~\cite{railway},  MEIBook~\cite{mei}, OpenSkyAirline~\cite{opensky}, US Migration~\cite{holten2009force}, DanishAIS~\cite{DanishAIS}.
These datasets were collected from three common areas in trajectory data analysis, including transportation, sociology, and ecology.
We preprocessed the raw data through several steps, including noise filtering, trajectory compression, and merging of redundant trajectories.


\noindent\textbf{Baseline methods}.
We selected two state-of-the-art animated transition methods for comparison.
The first method, the focus+context grouping method (F+C), simultaneously facilitates tracking objects' movements and identifying the global trend by breaking down transitions into groups~\cite{zheng2018focus+}.
We used the default parameters reported in the paper.
The second method, the vector-field-based method (VF), is the state-of-the-art method in terms of tracking objects' movements by utilizing vector fields to generate smooth, non-linear paths~\cite{wang2017vector}.
As the original paper did not provide specific parameter settings, we performed a grid search to find the optimal parameters.
Moreover, since the vector-field-based method requires predefined groups, we used the grouping results from the focus+context grouping method for consistency.

\begin{figure*}[b]
  \centering
  \setlength{\abovecaptionskip}{1.2mm}
  \includegraphics[width=0.9\linewidth]{figures/quan_res_new.pdf}
  \put(-396,3){(a)}
  \put(-266,3){(b)}
  \put(-136,3){(c)}
  \caption{Object positions at a specific frame in the animations generated by three methods on the BirdMap dataset:
   (a) the focus+context grouping method~\cite{zheng2018focus+}; (b) the vector-field-based method~\cite{wang2017vector}; (c) RouteFlow. Here, overlaps are highlighted as red strokes, and the distributions of objects are shown as blue contours. 
  The metric values for these frames are displayed below each sub-figure.
  The detailed analysis of these values is provided in Appendix~\ref{sec:appendixB}.}
  \label{fig:quan-result}
  \Description{User study results in three tasks, including Friedman tests and pairwise Wilcoxon signed-rank tests on three methods.}
\end{figure*}

\noindent\textbf{Evaluation criteria}. 
Previous studies classified the metrics into three types: occlusion, deformation, and dispersion~\cite{chevalier2014not, dragicevic2011distortion, du2015trajectory, wang2017vector}.
We adopted the metrics summarized by Wang~\etal~\cite{wang2017vector} as they are tailored for objects with groups.



We denote all the frames in the animation as $T$, a particular frame as $t$, and
all the objects as $P$.

\myparagraph{Occlusion} measures the overlap between objects.
This metric is useful for evaluating the capability of an animation in facilitating the tracking of objects' movements.
High occlusion reduces the visibility and distinguishability of moving objects, making these objects harder to distinguish and track~\cite{chevalier2014not,dragicevic2011distortion}.


Specifically, \textit{overall occlusion} (occlusion$_o$) measures the overlap between all objects during the entire animation.
\begin{equation}
\text{occlusion}_o(T) = \notag \frac{1}{|T|} \sum_{t \in T} \frac{\sum_{p,q \in P, p\neq q} \text{overlap}(p, q, t)}{|P|(|P| - 1)},
\end{equation}
where $\text{overlap}(p, q, t)$ is an indicator function with value 1 if objects $p$ and $q$ overlap at frame $t$, and 0 otherwise.

\textit{Within-group occlusion} (occlusion$_w$) measures the overlap between objects in the same group.
\begin{equation}
\begin{aligned}
\text{occlusion}_w(T) = \notag \frac{1}{K}\sum_{i=1}^{K}\frac{1}{|T_{G_i}|} \sum_{t \in T_{G_i}} \frac{\sum_{p,q \in G_i, p\neq q} \text{overlap}(p, q, t)}{|G_i|(|G_i|-1)},
\end{aligned}
\end{equation}
where $K$ is the number of groups, $G_i$ is the set of objects in the $i$-th group, and $T_{G_i}$ is the frames of the group $G_{i}$.


\myparagraph{Deformation} measures the changes in distance between objects within the same group across consecutive time frames.
Lower deformation indicates that the relative object positions within the group remain stable, making it easier to track the objects of interest.

\begin{equation}
\begin{aligned}
& \text{deformation}(T) =  \notag \\
& \frac{1}{K} \sum_{i=1}^{K} \frac{1}{|T_{G_i}|} 
 \sum_{t \in T_{G_i}, t > 0}
 \frac{\sum_{p, q \in G, p \neq q} |\text{dist}(p, q, t) - \text{dist}(p, q, t - 1)|}{|G_i| (|G_i| - 1)}.
\end{aligned}
\end{equation}
$dist(p, q, t)$ is the distance between objects $p$ and $q$ at frame $t$.

\myparagraph{Dispersion} measures how spread out objects in the same group are.
Lower dispersion indicates that the members of a group are moving more closely together, enhancing the perception of the group as a whole.
This facilitates more effective tracking of the group's collective movements, thereby enhancing the identification of the global trend.

\begin{equation}
\begin{aligned}
\text{dispersion}(T) = \notag \frac{1}{K}\sum_{i=1}^{K}\frac{1}{|T_{G_i}|} \sum_{t \in T_{G_i}} \frac{\sum_{p,q \in {G_i}, p\neq q} \text{dist}(p, q, t)}{|{G_i}|(|{G_i}|-1)}.
\end{aligned}
\end{equation}

The aforementioned three metrics focus on tracking objects' movements and identifying the global trend.
To the best of our knowledge, there is no existing metric that adequately measures the preservation of local hotspots in animation.
Additionally, the employed real-world datasets lack ground truth for local hotspots. 
As a result, we supplement the evaluation of preserving local hotspots with a user study using several synthetic datasets, which is described in Sec.~\ref{sec:userstudy}.





\noindent\textbf{Results}. 
Table~\ref{tab:metric_result} presents the comparison results between RouteFlow and the baseline methods.
RouteFlow performs the best on all datasets and all metrics.

\input{tables/tab-runningtime}

\begin{figure*}[b]
  \centering
  \setlength{\abovecaptionskip}{0mm}
  \includegraphics[width=0.8\linewidth]{figures/datageneration_new.pdf}
  \put(-350,10){(a)}
  \put(-214,10){(b)}
  \put(-73,10){(c)}
  \caption{The data generation pipeline: (a) generate the global trend; (b) determine local hotspots; (c) create trajectories.}
  \label{fig:datageneration}
  \Description{Illustration of forces in our edge bundling algorithm.}
\end{figure*}

\myparagraph{Occlusion}.
RouteFlow achieves lower overall occlusion and within-group occlusion scores compared to the two baseline methods.
This improvement is mainly due to differences in object layout. 
The baseline methods do not explicitly optimize the overlaps within groups (Fig.~\ref{fig:quan-result}B and Fig.~\ref{fig:quan-result}C), and in particular, the vector-field-based method may even introduce overlaps between groups as it moves all objects simultaneously. 
In contrast, our incremental circle packing algorithm reduces overlaps by employing three strategies: 1) applying a non-overlap constraint to minimize occlusion between objects (Fig.~\ref{fig:quan-result}F), 2) keeping objects that converge or diverge together as a group (Fig.~\ref{fig:quan-result}G), and 
3) following the principle of ``first out, closest to the exit'' (Fig.~\ref{fig:quan-result}H).

\myparagraph{Deformation}.
Compared to the two baseline methods, RouteFlow exhibits the least deformation.
The focus+context grouping method changes the layout of every frame as objects follow their input trajectories.
Similarly, the vector-field-based method causes unsynchronized movements due to varying velocity vectors among objects at different positions, leading to layout changes in subsequent frames. 
Conversely, RouteFlow incrementally updates the layout only at local hotspots, with the aim of balancing readability and stability in these refinements.
This balance greatly reduces deformation during animated transitions.



\myparagraph{Dispersion}.
RouteFlow achieves lower dispersion compared to the other methods.
The focus+context grouping method, which groups objects based solely on their start and end positions, records the highest dispersion. 
This method might group objects with different trajectories together due to their similar start and end positions, increasing dispersion (Fig.~\ref{fig:quan-result}D).
The vector-field-based method, which generates the animation paths of objects using a vector field, tends to disperse the input trajectories (Fig.~\ref{fig:quan-result}A), leading to a less compact layout (Fig.~\ref{fig:quan-result}E) and high dispersion.
In contrast, our incremental circle packing algorithm keeps the objects compact (Fig.~\ref{fig:quan-result}F), resulting in lower dispersion.

\noindent\textbf{Running Time}. 
\label{para:runningtime}
Table~\ref{tab:time_result} shows the average running times for each module of our animation method on real-world datasets, where object sizes vary from 73 to 316.
The performance tests were conducted on a Windows PC with an Intel i9-13900K CPU.
We averaged results over five trials to minimize randomness.
The average running time per dataset is within 1 second, which is fast enough for designing animated transitions.
The object layout generation module is the most time-consuming because it requires incremental generation for the layout of each local hotspot.
In contrast, the trajectory-driven path generation module is less demanding and achieves stable results in 300 iterations.




\subsection{User Study}
\label{sec:userstudy}
We conducted a user study to evaluate how effectively people use RouteFlow to track objects' movements and identify the global trend and local hotspots.
% in comparison to the two baseline methods used in our quantitative experiments.
We formulated three hypotheses: participants perform more accurately with RouteFlow in tracking objects' movements (\textbf{H1}), identifying the global trend (\textbf{H2}), and locating local hotspots (\textbf{H3}) compared to two baseline methods, the focus+context grouping method and the vector-field-based method.

\newcommand{\track}{\textit{Task 1---Tracking objects' movements}}
\newcommand{\trend}{\textit{Task 2---Identifying the global trend}}
\newcommand{\hotspot}{\textit{Task 3---Locating local hotspots}}
\newcommand{\myquote}[1]{\textit{``#1''}}




\subsubsection{Study Setup}

\noindent\textbf{\\ Participants}. 
We recruited 15 participants (12 males and 3 females, denoted as P1-P15) from local universities.
They were graduate students majoring in computer science (12) and information design (3), aged from 22 to 32 years (\textit{mean} = 24.47, \textit{SD} = 2.53).
All of them reported to have normal vision and no color deficiencies.
Upon completion, each participant received a \$30 compensation, independent of their performance. 


\noindent\textbf{Apparatus}. 
The user study was conducted on a personal computer equipped with a 27-inch display with a resolution of 3840 $\times$ 2160 pixels and a 60 Hz refresh rate.
Objects were presented as circles with a radius of 9 pixels (0.20 cm), filled in black color, following the previous practice~\cite{du2015trajectory,wang2017vector}.
The animation window measured 1250 $\times$ 1250 pixels (27.0 $\times$ 27.0 cm) with a white background.
Participants were seated at a distance of 40 cm from the display.

\noindent\textbf{Datasets}.
We used synthetic data for a controlled study setting instead of real-world data, which may lack ground truth for the global trend and local hotspots.
This follows the common practice~\cite{du2015trajectory,wang2017vector}. 
Fig.~\ref{fig:datageneration} shows our dataset generation process, involving three steps.
First, we generated a smooth global trend trajectory using B-splines.
Next, we determined local hotspots by sampling points along the global trajectory and randomly classifying them as converging or diverging points.
Finally, we created trajectories for objects by adding random perturbations to the global trend, avoiding overlap between start and end positions.
To achieve better diversity and a certain level of complexity, we finalized our design through several iterations.
In the final iteration, there were two types of global trend (one or two bends in the B-spline), and three types of local hotspot assignment (1 convergence + 1 divergence, 2 convergences + 1 divergence, and 1 convergence + 2 divergences).
Each dataset included 30 trajectories.
To control the experiment duration and keep participants focused, we generated datasets for each combination of trend type and local hotspot type and conducted two repetitions per combination, resulting in 12 datasets (2 types of the global trend $\times$ 3 types of local hotspot assignment $\times$ 2 repetitions).


\noindent\textbf{Tasks design}.
Our study consisted of three tasks, each iterated and refined through small-scale pilot studies.
For each task, participants were asked questions with four options (one correct, three incorrect) along with an additional option for ``I am not sure.''

\track{}:
Participants were required to track the movement of target objects to identify their end positions, and then select one answer from five options.
This task design referred to the previous practices~\cite{du2015trajectory, wang2017vector}. 
We set the number of target objects to three, all from the same group, to simplify the task. 
We generated the incorrect options by randomly replacing the correct targets with their nearest neighbors based on their end positions.\looseness=-1


\trend{}:
Participants were asked to observe the overall movement of all objects to identify the global trend, and then select one answer from five options.
Initially, we set the background to be fully white, whereas feedback from the pilot study indicated difficulty in observing and locating the movements. 
To alleviate this issue, the background canvas was divided into 8 $\times$ 8 grid, colored alternatively in white and grey. 
The three incorrect options were generated by adding random perturbations to the correct trend, ensuring that they passed through different grids to be distinguishable from the correct option. 



\hotspot{}:
Participants were asked to identify the grids containing local hotspots.
Similar to \textit{Task 2}, to facilitate locating local hotspots, we employed a white and grey background canvas.
Each answer option included two marked grids: one for convergence and one for divergence.
Incorrect options were generated from the correct option by randomly replacing one correct grid with a neighboring grid.
To simplify the task, participants were allowed to click and mark grids that might assist them while viewing the animation and refer to these marks when answering.



\noindent\textbf{Study protocol}.
Participants started by signing consent and watching a tutorial video about the study procedure and tasks. 
We then provided three brief videos, each explaining a different animation method.
The study adopted a within-subjects design, requiring each participant to complete all three tasks using three different methods.\looseness=-1


For each task, we designed a practice session and a test session. 
The practice session familiarized participants with the interface and tasks, through six trials, two for each method. 
In each trial, participants initially saw all objects in grey points. 
Particularly, we highlighted the target objects in red for the tracking task. 
They then clicked to start the animation. 
All objects in the tracking task transitioned to grey and then to black within the first 0.5 seconds. In the other two tasks, the objects turned black directly. This allowed participants to recognize the target objects and prepare to follow their movements.
After the animation, participants clicked to start the question and could not review the animation anymore. 
In the practice session, we provided correct answers to help participants check their understanding and encouraged them to ask questions. 


After completing the practice session and confirming that they fully understood the tasks and methods, participants advanced to the test session, which consisted of 36 trials (12 datasets $\times$ 3 methods). 
Unlike the practice session, correct answers were no longer provided during the test session.
To counterbalance the order of methods, we divided 15 participants into five groups, three for each group. 
Within each group, we used an expanded Latin square and applied a cyclic shift to the method order for each participant.
Additionally, to alleviate the learning effect, we randomly mirrored and rotated the datasets. 
Participants were allowed to take short breaks after each task or whenever they requested one.
After finishing each task, we assessed participants' workload and fatigue levels using NASA's Task Load Index~\cite{sandra2006nasa} and asked about their preferred methods and the reasons for their preferences. For all trials, we recorded participants' answers and completion times.
The entire study lasted 75-90 minutes.

Thus, each participant finished 108 trials (3 tasks $\times$ 3 methods $\times$ 12 datasets), leading to 1,620 total trials (15 participants $\times$ 108 trials). Additional study details are provided in Appendix~\ref{sec:appendixC}, and results are provided in the supplemental material.


\begin{figure*}[t]
  \centering
  \setlength{\abovecaptionskip}{1.2mm}
  \includegraphics[width=\linewidth]{figures/user study result-new.pdf}
  \put(-427,3){(a)}
  \put(-287,3){(b)}
  \put(-145,3){(c)}
  \caption{
   % User study results on three tasks, including Friedman tests and pairwise Wilcoxon signed-rank tests for three methods. * indicating \textit{p} < 0.05, ** indicating \textit{p} < 0.01.
  User study results on three tasks: (a) task 1 --- tracking objects' movements; (b) task 2 --- identifying the global trend; (c) task 3 --- locating local hotspots. Here, * indicating \textit{p} < 0.05, ** indicating \textit{p} < 0.01.
  }
  \label{fig:user-study-result}
  \Description{User study results on three tasks, including Friedman tests and pairwise Wilcoxon signed-rank tests on three methods.}
  
\end{figure*}


\subsubsection{Result Analysis} 
We analyzed three types of data: the accuracy of multi-choice questions, participants' subjective ratings for workload, and their stated preferences.  

\noindent\textbf{Accuracy}.
For each task, we computed participants' average accuracy across different methods.
As data is not normally distributed, we conducted Friedman tests for each task. 
Moreover, we performed Wilcoxon signed-rank tests for pairwise comparison of different methods and used Bonferroni correction for multiple comparisons. 
We report the statistical test results and the box plots in Fig.~\ref{fig:user-study-result}.
The Friedman test results indicate significant differences among the methods in all three tasks: tracking objects' movements ($\chi^2(2)=23.16, p < 0.0001$), identifying the global trend ($\chi^2(2)=9.59, p = 0.00083$), and locating local hotspots ($\chi^2(2)=20.33, p < 0.0001$).
In the subsequent analysis, we focus on pairwise comparisons.





\track:
In pairwise comparisons, our RouteFlow method significantly outperforms the focus+context grouping method (average: 0.865 vs. 0.421, $p = 0.001$).
However, RouteFlow only shows a small difference compared to the vector-field-based method in average accuracy (0.865 vs. 0.930), and the paired test indicates no significant difference ($p = 0.275$).
Therefore, the results can \textbf{partially support H1}.
Participants using the focus+context grouping method show a significantly lowest accuracy.
This is because both our method and the vector-field-based method optimize the animation paths to reduce complexity, while the focus+context grouping method directly uses the input trajectories as its animation paths.
Correspondingly, the majority of participants (10 out of 15) reported that the animation paths in the focus+context grouping method were more complex and had greater occlusion compared to the other two methods.
This feedback aligns with our comparison results in Sec.~\ref{sec:quantitative}, where the focus+context grouping method achieves the highest within-group occlusion.
In addition, we asked participants about their different performances using RouteFlow and the vector-field-based method. 
P12 appreciated the grouping in RouteFlow for tracking, saying \myquote{The relative positions of objects are stable within the group. I can track one or two targets inside the group and use them as a reference to locate other targets.} 
However, we also received feedback expressing different opinions. For instance, P2 commented, \myquote{The objects in RouteFlow are grouped closely. I sometimes confuse the targets with other objects.} P2 preferred the vector-field-based method, noting \myquote{objects are relatively spread out. Even when occlusion occurs, it is easy to distinguish the targets by following their movements.}



\trend:
RouteFlow significantly outperforms the focus+context grouping method ($p = 0.021$) and the vector-field-based method ($p=0.028$), thereby \textbf{supporting H2}.
Participants described RouteFlow as having a sense of \myquote{unity} (P1, P2, P4, P10, and P11) and showing \myquote{a clear trend} (P1, P4, P5, P6, and P11).
Besides, they explained their performances using the two baseline methods related to the dispersion. 
P2 complemented that \myquote{Although [the focus+context grouping method] depicts a clear trend of each group, it requires memorizing and comparing the movements of several groups to get the global trend, which brings extra burden.}
P4 mentioned the vector-field-based method, saying \myquote{It is distracting to follow the objects that are dispersed in different locations but move synchronously.}
This feedback aligns with the quantitative result in Sec.~\ref{sec:quantitative}, where these baseline methods showed higher dispersion compared to RouteFlow.
Additionally, P1 commented that the animation design for groups of objects in RouteFlow can be a double-edged sword for capturing the global trend: \myquote{[It allows me] to infer the global trend based on groups' movements. However, it may be disrupted due to the convergence and divergence [of the groups].}
This further highlighted the importance of balancing the global trend and local hotspots.

\hotspot:
RouteFlow achieves an average accuracy of 0.832, which is significantly better than the focus+context grouping method ($p = 0.002$) and the vector-field-based method ($p=0.002$).
Therefore, the results can \textbf{support H3}.
Participants described the convergence and divergence of objects in RouteFlow as \myquote{clearly noticeable} (P1, P2, P12, P13, and P15) and \myquote{apparent} (P6, P8, and P10).
In contrast, the other two methods required extra cognitive effort.
Five participants (P2, P6, P11, P12, and P15) complained that animating different groups separately in the focus+context grouping method made it difficult to distinguish the locations where objects converge or diverge.
Although the vector-field-based method animated all objects together, users still found it difficult to identify local hotspots.
P11 commented from the spatial perspective, \myquote{Objects are dispersed. I cannot confidently tell the locations [of the local hotspots].}
P2 noticed \myquote{Objects do not pass through their shared positions simultaneously.}
This issue arises because, while the vector-field-based method animates objects concurrently, the local hotspot locations along their individual trajectories do not always align.
Thus, participants noted temporal discrepancies in the animation as objects passed through these local hotspots.\looseness=-1





\noindent\textbf{Workload}.
Fig.~\ref{fig:NASA} summarizes participants' workload and fatigue levels using NASA's Task Load Index~\cite{sandra2006nasa}, including mental demand, physical demand, temporal demand, effort, frustration, and performance.
We conducted Friedman tests for each dimension in each task, followed by Wilcoxon signed-rank tests with Bonferroni correction for pairwise comparison among different methods.
The Friedman test results show significant differences among the methods across all six dimensions for each task, except the effort dimension for \trend. 
Next, we focus on analyzing the pairwise comparison results. 

\begin{figure*}[t]
  \centering
  \setlength{\abovecaptionskip}{1.5mm}
  \includegraphics[width=\linewidth]{figures/NASA.pdf}
  \put(-388,3){(a)}
  \put(-239,3){(b)}
  \put(-89,3){(c)}
  \caption{Participants' workload and fatigue levels according to NASA's Task Load Index: (a) task 1 --- tracking objects' movements; (b) task 2 --- identifying the global trend; (c) task 3 --- locating local hotspots.
  Here, error bars show the 95\% confidence intervals.
  $\vcenter{\hbox{\includegraphics[height=0.012\textwidth]{figures/arrow.pdf}}}$ indicates that a smaller score is better, and vice versa.
   The results of pairwise Wilcoxon signed-rank tests are also shown, with * indicating \textit{p} < 0.05, ** indicating \textit{p} < 0.01, and *** indicating \textit{p} < 0.001.
  }
  \Description{Participants' workload and performance according to NASA's Task Load Index.}
  \label{fig:NASA}
\end{figure*}


\track: 
The Wilcoxon signed-rank tests indicate that both RouteFlow and the vector-field-based method perform better than the focus+context grouping method on all six dimensions, whereas there are no significant differences between RouteFlow and the vector-field-based method.
Further analysis of mean values and confidence intervals reveals a subtle difference: the vector-field-based method shows slightly lower mental and physical demands and effort than RouteFlow. 
This could be due to the relatively simpler animation paths for individual objects in the vector-field-based method~\cite{wang2017vector}, which might require less cognitive load for tracking compared to the bundled paths in RouteFlow.

\trend: 
The Wilcoxon signed-rank tests indicate that RouteFlow outperforms the focus+context grouping method in terms of mental demand, temporal demand, frustration, and performance dimensions.
This is because the focus+context grouping method demands extra memory and analytical burden to synthesize the movements of multiple groups into the global trend, which often leads to frustration. 


\hotspot: 
The Wilcoxon signed-rank tests indicate that RouteFlow outperforms the other two methods on the five dimensions, except for effort, where RouteFlow only outperforms the focus+contex grouping method.
These advantages align with participants' accuracy in completing the task.
Regarding the effort dimension, participants found the background grids during the animation helpful, as they reduced the effort needed to observe and locate movement.
% This makes the required effort relatively similar across all three methods.


\noindent\textbf{Preference}.
We also collected participants' preferences for the three methods in three tasks, as summarized in Fig.~\ref{fig:rank}.

\track: Participants' opinions varied. 
Eight participants preferred RouteFlow, and seven preferred the vector-field-based method.
This was slightly different from the overall subjective workload ratings, where participants thought RouteFlow brought a bit more mental and physical burden and effort.
We noticed that P10 and P15 performed equally accurately with RouteFlow and the vector-field-based method but reported higher subjective performance and preference for RouteFlow.
They commented that objects in RouteFlow were \myquote{less occluded}, making them \myquote{more convinced.}


\trend:
13 participants preferred RouteFlow.
Specifically, P1 appreciated that RouteFlow gradually revealed the global trend along with the group movement, just like \myquote{painting with a brush.}
In contrast, P6 preferred the focus+context grouping method, explaining \myquote{It is easier to connect the movements of different groups into a global trend.}
P10 liked the vector-field-based method and noted that \myquote{I need to memorize the positions objects pass through to identify the global trend. [The vector-field-based method] requires less memory burden, as I can observe objects moving simultaneously in the global trend.}

\hotspot: 
All participants ranked RouteFlow at the top, indicating a strong advantage of our method. 
Their reasons mainly focused on the clear and noticeable animated transitions, showing groups that were converging and diverging. 

\begin{figure}[t]
  \centering
  \setlength{\abovecaptionskip}{1.5mm}
  \includegraphics[width=1.0\linewidth]{figures/rank_new.pdf}
  \put(-196,3){(a)}
  \put(-110,3){(b)}
  \put(-30,3){(c)}
  \caption{Participants' preference ranks of different methods on three tasks:
  (a) task 1 --- tracking objects' movements; (b) task 2 --- identifying the global trend; (c) task 3 --- locating local hotspots.
  % Error bars show the 95\% confidence intervals (CIs).
  Here, smaller ranks indicate stronger preferences.}
  \Description{Participants' preference rank of different methods in three tasks.}
  \label{fig:rank}
\end{figure}