\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage[submission]{icml2024} with \usepackage[nohyperref]{icml2024} above.
\usepackage{hyperref}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
\usepackage[accepted]{icml2024}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

\usepackage{multirow}
\usepackage{enumitem}
\usepackage{tcolorbox}
\usepackage{pifont}
\usepackage{newtxmath}
\usepackage{colortbl}
\usepackage{xcolor}
\definecolor{lightblue}{RGB}{220, 220, 220}
\definecolor{lightgreen}{RGB}{144, 238, 144}
\definecolor{lightred}{RGB}{255, 182, 193}
\definecolor{darkerblue}{RGB}{150, 150, 150}
% \renewcommand{\mathcal}{\mathscr} 
% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TERMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{xspace}
\newcommand{\ie}{\textit{i.e.}}
\newcommand{\eg}{\textit{e.g.}}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Premise-Augmented Reasoning Chains for Enhanced Error Identification in Large Language Models}

\begin{document}

\twocolumn[
% \icmltitle{Connecting the Dots: Structuring Reasoning Chains for Verifiability in LLMs}
\icmltitle{Premise-Augmented Reasoning Chains Improve Error Identification\\in Math Reasoning with LLMs}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2024
% package.

\begin{icmlauthorlist}
\icmlauthor{Sagnik Mukherjee$^\ast$}{uiuc}
\icmlauthor{Abhinav Chinta$^\ast$}{uiuc}
\icmlauthor{Takyoung Kim}{uiuc}
\icmlauthor{Tarun Sharma}{uiuc}
\icmlauthor{Dilek Hakkani-Tur}{uiuc}
\end{icmlauthorlist}

\icmlaffiliation{uiuc}{University of Illinois at Urbana Champaign}

\icmlcorrespondingauthor{Sagnik Mukherjee}{sagnikm3@illinois.edu}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{\icmlEqualContribution}  % leave blank if no need to mention equal contribution

\begin{abstract}
% Chain-of-Thought (CoT) prompting enhances mathematical reasoning in large language models (LLMs) by enabling detailed step-by-step solutions. However, due to the verbosity of LLMs, this prompting approach introduces significant challenges in both traceability (logical flow) and verifiability (correctness). Importantly, mathematical reasoning allows each step to be derived from a small set of premises. For traceable and verifiable evaluation of reasoning chains in mathematical reasoning, we present a framework that identifies these premises to improve the evaluation of reasoning. We restructure conventional linear reasoning chains into \textbf{Premise Augmented Reasoning Chains (PARC)} by establishing premise links, thereby improving transparency and traceability. Through experiments with a PARC-based dataset that we built, namely \textbf{PERL (Premises and ERrors identification in LMs)}, we demonstrate that LLMs can reliably identify premises within complex reasoning chains. In particular, even open-source LLMs achieve 90\% recall in premise identification.  We also show that PARC helps to identify errors in reasoning chains more reliably. The accuracy of error identification improves by 6\% to 16\% when step-by-step verification is carried out in PARC under the premises.
% Our findings highlight the utility of premise-centric representations in addressing complex problem-solving tasks and open new avenues for improving the reliability of LLM-based reasoning evaluations.

Chain-of-Thought (CoT) prompting enhances mathematical reasoning in large language models (LLMs) by enabling detailed step-by-step solutions. However, due to the verbosity of LLMs, the resulting reasoning chains can be long, making it harder to verify the reasoning steps and trace issues resulting from dependencies between the steps that may be farther away in the sequence of steps. Importantly, mathematical reasoning allows each step to be derived from a small set of premises, which are a subset of the preceding steps in the reasoning chain. In this paper, we present a framework that identifies the premises for each step, to improve the evaluation of reasoning. We restructure conventional linear reasoning chains into \textbf{Premise Augmented Reasoning Chains (PARC)} by introducing premise links, resulting in a directed acyclic graph where the nodes are the steps and the edges are the premise links. Through experiments with a PARC-based dataset that we built, namely \textbf{PERL (Premises and ERrors identification in LLMs)}, we demonstrate that LLMs can reliably identify premises within complex reasoning chains. In particular, even open-source LLMs achieve 90\% recall in premise identification.  We also show that PARC helps to identify errors in reasoning chains more reliably. The accuracy of error identification improves by 6\% to 16\% absolute when step-by-step verification is carried out in PARC under the premises.
Our findings highlight the utility of premise-centric representations in addressing complex problem-solving tasks and open new avenues for improving the reliability of LLM-based reasoning evaluations.
\end{abstract}

\input{sections/intro}
\input{sections/related_work}
\input{sections/method}
\input{sections/experiments}
\input{sections/conclusion}

\bibliography{custom}
\bibliographystyle{icml2024}


\appendix
\input{sections/appendix}

\end{document}
