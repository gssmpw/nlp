\vspace{-2ex}
\section{Conclusion}
In this paper, we introduced a framework to enhance the evaluation of mathematical reasoning chains in large language models by transforming Linear Reasoning Chains into Premise Augmented Reasoning Chains. Through experiments with our annotated dataset, PERL, we empirically show that error identification under premises in PARC is more reliable and has higher accuracy than error identification under full context in LRC. We also show that LLMs can convert an LRC to PARC with no additional guidance, and then can do error identification under the premises in PARC. Further, we show that accumulation errors are particularly challenging to detect, and our method improves their identification by verifying each step under its premises.
\section{Impact Statement}
The broader impact of this research extends to multiple domains where step-by-step reasoning is critical, including automated theorem proving, educational AI tutors, and scientific discovery. By enabling more reliable self-verification mechanisms in LLMs, our approach contributes to the long-term goal of enhancing the transparency and trustworthiness of AI systems in high-stakes applications.

Potential ethical considerations include the risk of overreliance on LLM-generated verification without human oversight, particularly in domains where reasoning errors can have significant real-world consequences. 

This paper primarily aims to advance the field of Machine Learning by proposing a structured approach to reasoning evaluation. Although we acknowledge that any advances in LLM-based reasoning may have broader societal implications, we do not foresee any immediate ethical concerns beyond those generally associated with the development of AI reasoning systems.
% HERE
\section{Acknowledgments}
This research project has benefited from the Microsoft Accelerate Foundation Models Research (AFMR) grant program through which leading foundation models hosted by Microsoft Azure along with access to Azure credits were provided to conduct the research.

\label{sec:related_work}
% \heng{add some related work about information aggregation, include your SmartBook paper}\zhenhailong{added}

%\zhenhailong{add our distinctive contribution here compared with AssistantBench/MindSearch}

% \begin{comment}
%     \begin{itemize}
%         \item WebLinx \citepp{lu2024weblinx}
%         \item WebArena \citepp{zhou2023webarena}
%         \item WebGPT \citepp{nakano2021webgpt}
%         \item Mind2Web \citepp{deng2024mind2web}
%         \item AutoGPT \citepp{}
%     \end{itemize}
% \end{comment}
    