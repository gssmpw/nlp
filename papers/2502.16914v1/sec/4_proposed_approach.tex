\section{Proposed Approach} \label{proposed approach}
The choice of heart sound analysis in this study is driven by its unique diagnostic value, which complements other modalities such as ECG. Despite the advent of modern diagnostic techniques and sophisticated imaging modalities, cardiac auscultation and heart sounds remain invaluable diagnostic tools. While ECG is widely regarded as the gold standard for diagnosing cardiac rhythm disorders and ischemic heart disease, it may not capture certain aspects of cardiac function that heart sound analysis can, such as detecting murmurs, rubs, and other abnormal heart sounds indicative of structural abnormalities like valvular heart diseases or ventricular hypertrophy. Therefore, heart sound analysis provides additional, complementary information that can enhance diagnostic accuracy.

Researches has demonstrated that it is
possible to process spectrograms from audio data as images
and apply computer vision algorithms such as CNN \cite{verma_neural_2018, cabrera-ponce_detection_2020, hyder_acoustic_2017}. The core problem of the current approaches in using regular CNN-based computer vision methods on audio spectrogram representation lies in the distinctiveness of the spectrogram in comparison to other image data.

Visual transformers leverage attention mechanisms to capture dependencies between different parts of the input data. This allows them to model long-range dependencies more effectively than traditional CNNs, whose feature extraction is limited to local receptive fields. By aggregating information from across the entire spectrogram, transformers can show a global contextual understanding of the audio signal, enabling them to capture non-local dependencies and extract meaningful features from spectrograms.

\subsection{Spectral Data Visualization \& Analysis}
In spectral visualization and analysis, researchers employ various techniques to gain insights into the frequency content of signals. These methodologies enable the examination of how frequencies evolve over time, providing valuable information for tasks such as audio processing, speech recognition, and biomedical signal analysis.

\textbf{Spectrogram.}
Spectrograms stand as one of the primary tools in spectral visualization. They offer detailed representations of frequency spectra over time, revealing how the frequency composition of a signal changes temporally. By plotting frequency on the vertical axis, time on the horizontal axis, and intensity or magnitude using color or brightness, spectrograms provide a comprehensive view of signal dynamics. This detailed visualization allows analysts to identify specific features, patterns, and transient events within the signal, making spectrograms invaluable for tasks requiring fine-grained temporal frequency analysis.

\textbf{Spectral Centroid.}
In contrast to the detailed temporal-frequency mapping provided by spectrograms, spectral centroids offer a simplified summary of a signal's frequency content. The spectral centroid indicates the "center of mass" or average frequency of a signal within each time frame. This single-value representation reduces the complexity of the data while still providing a concise summary of the signalâ€™s frequency characteristics. Spectral centroids are particularly useful for enhancing computational efficiency and maintaining robustness against noise and variations in the signal. However, they lack the detailed temporal information that spectrograms provide.

The synergy in using spectrograms and spectral centroids with different models lies in their ability to capture distinct and complementary features of audio signals. Spectrograms provide a comprehensive visualization of the frequency content over time, highlighting complex, high-dimensional patterns. In contrast, spectral centroids and waveforms represent simpler, more repetitive features, which are well-suited to the strengths of CNNs in learning local patterns through convolution and pooling operations.

By employing a MoE approach, the proposed model effectively combines these diverse representations. The spectrograms allow the model to capture detailed, global time-frequency information, while the spectral centroids and waveforms facilitate the extraction of robust, localized features. This integration leverages the strengths of both ViT and CNNs, resulting in a more accurate and holistic analysis of heart sounds.

\subsection{MoE}
MoE is a powerful ensemble learning methodology used in machine learning and statistical modeling. Within ensemble methods, multiple models are combined to improve predictive performance compared to any individual model. MoE takes this concept a step further by combining various models and adjusting the weight of their contributions adaptively per the input data.

In MoE, the "experts" are individual models or learners, each specializing in a particular region of the input space or addressing specific patterns in the data. These experts make predictions independently based on their specialized knowledge. The key innovation of MoE lies in the gating network, which dynamically selects the most relevant expert or combination of experts for each input instance.

The gating network, often implemented as a neural network, learns to assign weights to the experts based on the input data. These weights determine the contribution of each expert to the final prediction. By adaptively combining the predictions of multiple experts, MoE can capture complex relationships in the data and achieve superior predictive performance compared to traditional ensemble methods. The flowchart of the proposed experiment, depicted in Figure \ref{fig:flowchart}, illustrates the entire process, from input data processing to the final output generated by the MoE.