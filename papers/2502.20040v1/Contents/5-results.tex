\section{Results and Analyses}

In this section, we present and analyze the speech enhancement performance and ASR results, and compare the model size and computational complexity as well. 

\subsection{Speech enhancement results}

Table~\ref{tab: se-mos} and \ref{tab: se-pesq} show the DNSMOS and PESQ scores, respectively. We analyze the results in the following aspects:

\input{Contents/Tables/R-SE-MOS}
\input{Contents/Tables/R-SE-PESQ}

\subsubsection{Comparing the training targets of logMel mapping and Mel ratio mask} For online processing, \emph{mapping} consistently outperforms \emph{mask} in DNSMOS, mainly due to the higher residual noise of \emph{mask}, which can be reflected by the much lower BAK scores of \emph{mask} on the very noisy CHiME4 and RealMAN test sets. When applying the predicted ratio mask on the noisy spectrogram, if speech is highly contaminated by noise, there will exist certain residual noise even if the predicted error of mask is small. By contrast, \emph{mapping} directly predicts the logMel-spectrogram of speech, which can avoid such residual noise. However, as shown in Table~\ref{tab: se-pesq}, \emph{mask} achieves higher PESQ scores than \emph{mapping} on the highly noisy CHiME4 and DNS (w.o. reverb) sets. PESQ measures the perceptual similarity of enhanced speech and reference clean speech. The higher PESQ scores indicates that \emph{mask} performs better on retrieving the target speech through extracting the target speech from the noisy speech with a mask. Directly \emph{mapping} may erroneously remove or boost those speech components highly contaminated by noise. The enhanced logMel-spectrograms are transformed to waveforms with a neural vocoder, and the speech quality measured with DNSMOS is more affected by the residual noise caused by \emph{mask} than the \emph{mapping} error of logMel-spectrogram. Fig~\ref{fig: r-mask-mapping} shows an example of the enhanced logMel-spectrogram by \emph{mask} and \emph{mapping}, which verifies our discussions. 

\input{Contents/Images/R-mask-mapping}

For offline processing, the differences between \emph{mask} and \emph{mapping} discussed above still present, but get much smaller, for example the difference of BAK scores on the CHiME4 and RealMAN test sets become much smaller. Compared to the online network, the offline network achieves much smaller prediction errors for both \emph{mask} and \emph{mapping}, thence their differences also become smaller as they both target the same clean speech.

\subsubsection{Comparing with oSpatialNet and SpatialNet-Mamba} oSpatialNet and SpatialNet-Mamba adopt the same network architectures and serve as the linear-frequency baselines for the proposed CleanMel networks. For both online and offline processing, the proposed Mel-spectrogram enhancement networks noticeably outperform their linear-frequency baselines in DNSMOS, but not necessarily in PESQ. This phenomenon is consistent with the findings in the VoiceFixer paper \cite{liu22voicefixer}. The GAN-based nerual vocoder is good at generating high-quality speech, but will possibly reduce the (PESQ) similarity of the enhance speech with the reference speech. 

\subsubsection{Comparing with online baseline networks}  Demucs \cite{defossez20demucs} performs well for denoising but not for dereverberation, as it achieves leading performance in DNSMOS P.835 on the (low-reverberation) CHiME4 and EARS sets, but not for other reverberant test sets. Although it was developed for multi-channel speech enhancement in \cite{quan2024oSpatialNet}, oSpatialNet also performs very well for single-channel speech enhancement compared with other comparison models. oSpatialNet and the proposed CleanMel network work better especially for dereverberation due to their narrow-band processing of room filter convolution.

\subsubsection{Comparing with offline baseline networks} VoiceFixer \cite{liu22voicefixer} is an important baseline for the proposed CleanMel network, as they both perform Mel-spectrogram enhancement. VoiceFixer adopts an advanced ResUNet. We can see that the proposed network noticeably outperforms VoiceFixer, which verifies the strong capability of the proposed cross-band and narrow-band combination network. StoRM \cite{Lemercier2023storm} is a diffusion-model-based generative network, which often achieves the SOTA performance for speech enhancement. The proposed network consistently outperforms StoRM. Their performance gaps of DNSMOS scores are not large, but the gaps of PESQ scores are very large. This indicates that although generative model can generate high-quality speech, but its fidelity to the source speech is hard to be ensured.
SpatialNet \cite{quan2024spatialnet}, especially its Mamba variant, i.e. SpatialNet-Mamba, as a pure discriminative speech enhancement network, achieves promising performance. 

Overall, by combining a powerful discriminative Mel-spectrogram enhancement network and a GAN-based generative neural vocoder, the proposed network achieves new SOTA speech enhancement performance for both online and offline processing, and for both denoising and dereverberation. By scaling up the proposed network, the performance can be further improved. Taking the \emph{mask} scheme as an example, compared to the small model, the large model noticeably improves the PESQ scores (although not the DNSMOS scores). The performance improvement of large model is clearly audible when listening to the enhanced speech demos.   


\subsection{ASR results}

\input{Contents/Tables/R-ASR-all} 

Table~\ref{tab: asr-all} presents the ASR results. We can observe that the ASR results are consistent with the common finding in the filed \cite{iwamoto22analysis} that single-channel speech enhancement networks usually do not help for ASR due to the speech artifacts caused by the networks. VoiceFixer performs Mel-spectrogram enhancement using an advanced ResUNet. The poor ASR results of VoiceFixer show that ResUNet brings severe artifacts to the enhanced Mel-spectrogram. StoRM does not work well for ASR, which further verifies that the generated speech has low fidelity to the source speech. 

One exception is SpatialNet, especially SpatialNet-Mamba, who show clear positive ASR effects on the REVERB-real and RealMAN sets. We believe that the advantages of SpatialNet lie in its narrow-band processing mechanism: i) narrow-band processing is especially efficient for modeling the much simpler narrow-band room filter convolution; ii) as discussed in \cite{li2019narrow}, narrow-band processing can avoid the so-called wide-band artifacts, such as the blurred and/or wrongly deleted/inserted wide-band spectra, which will be very harmful for ASR. 

The proposed CleanMel networks further improve the ASR performance on top of SpatialNet-Mamba. Directly enhancing the Mel-frequency spectra is more optimal for ASR than first enhancing the detailed linear-frequency spectra and then compressing to Mel-frequency. Compared to linear-frequency processing, the lower-dimensional Mel-frequency representation is easier to learn. However, this is more valid for the cross-band processing part, but not for the narrow-band (frequency-wise or dimension-wise) processing part. That is possibly why the proposed CleanMel networks are more advantageous on the denoising task of CHiME4  (more relying on cross-band processing) than the dereverberation task of REVERB  (more relying on narrow-band processing). For ASR, Mel ratio \emph{mask} performs better than logMel \emph{mapping}, but the performance gaps are not large. This indicates that ASR is less affected by the larger residual noise caused by \emph{mask} than the prediction error of logMel \emph{mapping}. Scaling up is very effective for further improving the ASR performance, as shown by the results of the large \emph{mask} model. 

Overall, by adopting an advanced backbone network (i.e. SpatialNet-Mamba), developing an effective Mel-spectrogram enhancement framework, and scaling up the model size, the proposed CleanMel-L-mask network achieves substantial ASR improvements relative to unprocessed speech. 

\subsection{Influence of neural vocoder to ASR performance}
\input{Contents/Tables/R-ASR-wav}
We use a GAN-based neural vocoder to transform the enhanced Mel-spectrogram to waveform, which may modify the original Mel-spectrogram and reduce the fidelity, although a Mel-spectrogram loss is adopted in the vocoder to maintain the Mel-spectrogram fidelity. Table~\ref{tab: asr-wav} compares the ASR results between taking as input the enhanced Mel-spectrogram and the vocoder waveform. Note that the ASR models used for VoiceFixer is re-trained accroding to its STFT and Mel-frequency setups. We can see that the neural vocoders indeed reduce the Mel-spectrogram fidelity and thus the ASR performance. However, the performance reductions are not significant, and the ASR results of vocoder waveform for each model closely insist on the results of its corresponding enhanced Mel-spectrogram. This means the vocoder waveform could be also an alternative/suboptimal choice for ASR. If it is not easy to re-train a CleanMel model according to the setups of a new ASR model, since vocoder waveform is irrelevant to those setups, our pre-trained checkpoints can be used.  

\subsection{Model size and computational complexity} 
\input{Contents/Tables/R-model-complexity}
Table~\ref{tab: model-complexity} shows the model size and computational complexity of the proposed model and comparison models. The proposed model is composed of a Mel-spectrogram enhancement network and an optional neural vocoder. The Mel-spectrogram enhancement network has a small model size and a large computational complexity, mainly due to the independent computation of frequencies with shared narrow-band blocks. Compared to linear-frequency sub-band/narrow-band processing networks, including FullSubNet, oSpatialNet, SpatialNet(-Mamba), the proposed Mel-spectrogram enhancement network has a smaller computational complexity, due to the much less frequencies to be processed, i.e. 80 Mel frequencies versus 256 linear frequencies. As a diffusion model, the computation of StoRM is much more expensive than other models. 



