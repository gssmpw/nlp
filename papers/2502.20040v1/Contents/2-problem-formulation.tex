\section{Problem formulation}

The noisy and reverberant single-channel speech signals can be represented in the time domain as
\begin{align}
\label{eq:td}
y(n) = s(n) * a(n) + e(n)
\end{align}
where $n$ stands for the discrete time index. $s(n)$ and $e(n)$ represents the clean source speech and ambient noise, respectively. $a(n)$ denotes RIR and $*$ the convolution operation. In this work, only static speaker is considered, thence the RIR is time-invariant. 
RIR is composed of the direct-path propagation, early reflections and late reverberation.

We conduct joint speech denoising and dereverberation in this work, which amounts to estimate the (Mel-spectrogram of) desired direct-path speech $x(n)=s(n) * a_\text{dp}(n)$ from microphone recording $y(n)$, where $a_\text{dp}(n)$ denotes the direct-path part in RIR. The training target of the proposed network and the training signals of neural vocoders will all be derived with $x(n)$.  

The proposed method is performed in the time-frequency domain. By applying STFT to Eq.~(\ref{eq:td}), based on the convolutive transfer function approximation \cite{li2019multichannel}, we can obtain:
\begin{align}
\label{eq:stft}
Y(f,t) \approx S(f,t) * A(f,t) + E(f,t)
\end{align}
where $f\in\{0,...,F-1\}$ and $t\in\{1,...,T\}$ denote the indices of frequency and time frame, respectively. $Y(f,t)$, $S(f,t)$ and $E(f,t)$ are the STFT of respective signals, and $X(f,t)$ is the STFT of direct-path speech.  $A(f,t)$ is the convolutive transfer function associated to $a(n)$. Convolution $*$ is conducted along time. In the STFT domain, the time domain convolution $s(n) * a(n)$ is decomposed as (frequency-independently) narrow-band convolutions $S(f,t) * A(f,t)$. Speech dereverberation in this work highly relies on learning this narrow-band convolution. 
For nosie reduction, one important way for discriminating between speech and stationary noise is to test the signal stationarity, which can be modeled in narrow-band as well. 



