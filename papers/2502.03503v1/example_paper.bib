@InProceedings{engstrom:etal:2019,
  title = 	 {Exploring the Landscape of Spatial Robustness},
  author =       {Engstrom, Logan and Tran, Brandon and Tsipras, Dimitris and Schmidt, Ludwig and Madry, Aleksander},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {1802--1811},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/engstrom19a/engstrom19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/engstrom19a.html},
  abstract = 	 {The study of adversarial robustness has so far largely focused on perturbations bound in $\ell_p$-norms. However, state-of-the-art models turn out to be also vulnerable to other, more natural classes of perturbations such as translations and rotations. In this work, we thoroughly investigate the vulnerability of neural network–based classifiers to rotations and translations. While data augmentation offers relatively small robustness, we use ideas from robust optimization and test-time input aggregation to significantly improve robustness. Finally we find that, in contrast to the $\ell_p$-norm case, first-order methods cannot reliably find worst-case perturbations. This highlights spatial robustness as a fundamentally different setting requiring additional study.}
}

@inproceedings{geva:etal:2023,
  title={Dissecting Recall of Factual Associations in Auto-Regressive Language Models},
  author={Geva, Mor and Bastings, Jasmijn and Filippova, Katja and Globerson, Amir},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={12216--12235},
  year={2023}
}

@inproceedings{asher:etal:2023,
  title={Limits for learning with large language models},
  author={Asher, Nicholas and Bhar, Swarnadeep and Chaturvedi, Akshay and Hunter, Julie and Paul, Soumya},
booktitle={12th Joint Conference on Lexical and
Computational Semantics (*Sem)},
year={2023},
publisher={Association for Computational
Linguistics}
}

@article{li:etal:2023,
  title={In-context learning with many demonstration examples},
  author={Li, Mukai and Gong, Shansan and Feng, Jiangtao and Xu, Yiheng and Zhang, Jun and Wu, Zhiyong and Kong, Lingpeng},
  journal={arXiv preprint arXiv:2302.04931},
  year={2023}
}

@article{wilcoxson:etal:2024,
  title={Polynomial Regression as a Task for Understanding In-context Learning Through Finetuning and Alignment},
  author={Wilcoxson, Max and Svendg{\aa}rd, Morten and Doshi, Ria and Davis, Dylan and Vir, Reya and Sahai, Anant},
  journal={arXiv preprint arXiv:2407.19346},
  year={2024}
}

@inproceedings{vonoswald:etal:2023,
  title={Transformers learn in-context by gradient descent},
  author={Von Oswald, Johannes and Niklasson, Eyvind and Randazzo, Ettore and Sacramento, Jo{\~a}o and Mordvintsev, Alexander and Zhmoginov, Andrey and Vladymyrov, Max},
  booktitle={International Conference on Machine Learning},
  pages={35151--35174},
  year={2023},
  organization={PMLR}
}


@article{akyurek:etal:2022,
  title={What learning algorithm is in-context learning? investigations with linear models},
  author={Aky{\"u}rek, Ekin and Schuurmans, Dale and Andreas, Jacob and Ma, Tengyu and Zhou, Denny},
  journal={arXiv preprint arXiv:2211.15661},
  year={2022}
}

@article{olsson:etal:2022,
  title={In-context learning and induction heads},
  author={Olsson, Catherine and Elhage, Nelson and Nanda, Neel and Joseph, Nicholas and DasSarma, Nova and Henighan, Tom and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and others},
  journal={arXiv preprint arXiv:2209.11895},
  year={2022}
}

@inproceedings{liu:etal:2024,
  title={Can Transformers Solve Least Squares to High Precision?},
  author={Liu, Jerry Weihong and Grogan, Jessica and Dugan, Owen M and Arora, Simran and Rudra, Atri and Re, Christopher},
  booktitle={ICML 2024 Workshop on In-Context Learning}
}

@book{ramsey:1931,
  title={The foundations of mathematics and other logical essays},
  author={Ramsey, Frank Plumpton},
  year={1931},
  publisher={K. Paul, Trench, Trubner \& Company, Limited}
}



@article{zhu:rudizicz:2020,
  title={An information theoretic view on selecting linguistic probes},
  author={Zhu, Zining and Rudzicz, Frank},
  journal={arXiv preprint arXiv:2009.07364},
  year={2020}
}


@incollection{lewis:1981,
  title={A Subjectivist’s Guide to Objective Chance},
  author={Lewis, David},
  booktitle={IFS: Conditionals, Belief, Decision, Chance and Time},
  editors={Harper, William Leonard and Pearce, GA and Stalnaker, Robert},
  pages={267--297},
  year={1981},
  publisher={Springer}
}

@article{hall:1994,
  title={Correcting the guide to objective chance},
  author={Hall, Ned},
  journal={Mind},
  volume={103},
  number={412},
  pages={505--517},
  year={1994},
  publisher={JSTOR}
}


@article{sinha:etal:2020unnatural,
  title={Unnatural language inference},
  author={Sinha, Koustuv and Parthasarathi, Prasanna and Pineau, Joelle and Williams, Adina},
  journal={arXiv preprint arXiv:2101.00010},
  year={2020}
}

@article{fawzi:froissard:2015,
  title={Manitest: Are classifiers really invariant?},
  author={Fawzi, Alhussein and Frossard, Pascal},
  journal={arXiv preprint arXiv:1507.06535},
  year={2015}
}

@article{JOLLI,
  author = 	 {Nicholas Asher and Soumya Paul },
  title = 	 {Strategic conversation under imperfect information: epistemic {M}essage {E}xchange games},
  journal = {{L}ogic, {L}anguage and {I}nformation},
  volume = {27.4},
  year = 	 2018,
  pages = {343-385}
}

@Book{kechris:1995,
 author = {Kechris, A},
 title = {Classical descriptive set theory},
 publisher = {Springer-Verlag},
 year = {1995},
 address = {New York},
 isbn = {0387943749}
 }

@article{muggleton:feng:1992,
  title={Efficient induction of logic programs},
  author={Muggleton, Stephen and Feng, Cao and others},
  journal={Inductive logic programming},
  volume={38},
  pages={281--298},
  year={1992}
}

@book{popper:1963,
  title={Conjectures and refutations: The growth of scientific knowledge},
  author={Popper, Karl},
  year={1963},
  publisher={routledge}
}

@phdthesis{plotkin:1972,
  title={Automatic methods of inductive inference},
  author={Plotkin, Gordon},
  year={1972},
  school={The University of Edinburgh}
}

@techreport{wolpert:macready:1995,
  title={No free lunch theorems for search},
  author={Wolpert, David H and Macready, William G and others},
  year={1995},
  institution={Technical Report SFI-TR-95-02-010, Santa Fe Institute}
}

@InProceedings{gradel:2008,
  author = 	 {E. Gr{\"a}del},
  title = 	 {Banach-{M}azur games on graphs},
  booktitle = {Foundations of Software Technology and Theoretical Computer Science (FSTTCS)},
  pages = 	 {364-382},
  year = 	 2008,
  editor = 	 {R. Hariharan and M. Mukund and V. Vinay}}

@article{hornik:etal:1989,
  title={Multilayer feedforward networks are universal approximators},
  author={Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  journal={Neural networks},
  volume={2},
  number={5},
  pages={359--366},
  year={1989},
  publisher={Elsevier}
}

@article{bietti:etal:2024,
  title={Birth of a transformer: A memory viewpoint},
  author={Bietti, Alberto and Cabannes, Vivien and Bouchacourt, Diane and Jegou, Herve and Bottou, Leon},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{von-Oswald:etal:2022,
  title={Transformers learn in-context by gradient descent},
  author={von Oswald, Johannes and Niklasson, Eyvind and Randazzo, Ettore and Sacramento, Jo{\~a}o and Mordvintsev, Alexander and Zhmoginov, Andrey and Vladymyrov, Max},
  journal={arXiv preprint arXiv:2212.07677},
  year={2022}
}

@misc{bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@ARTICLE{roberta:2019,
      title={RoBERTa: A Robustly Optimized BERT Pretraining Approach}, 
      author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
      year={2019},
      eprint={1907.11692},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{asher:hunter:2022,
  title={When learning becomes impossible},
  author={Asher, Nicholas and Hunter, Julie},
  booktitle={2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={107--116},
  year={2022}
}



@inproceedings{yu:etal:2023,
    title = "Characterizing Mechanisms for Factual Recall in Language Models",
    author = "Yu, Qinan  and
      Merullo, Jack  and
      Pavlick, Ellie",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.615/",
    doi = "10.18653/v1/2023.emnlp-main.615",
    pages = "9924--9959",
    abstract = "Language Models (LMs) often must integrate facts they memorized in pretraining with new information that appears in a given context. These two sources can disagree, causing competition within the model, and it is unclear how an LM will resolve the conflict. On a dataset that queries for knowledge of world capitals, we investigate both distributional and mechanistic determinants of LM behavior in such situations. Specifically, we measure the proportion of the time an LM will use a counterfactual prefix (e.g., {\textquotedblleft}The capital of Poland is London{\textquotedblright}) to overwrite what it learned in pretraining ({\textquotedblleft}Warsaw{\textquotedblright}). On Pythia and GPT2, the training frequency of both the query country ({\textquotedblright}Poland{\textquotedblright}) and the in-context city ({\textquotedblright}London{\textquotedblright}) highly affect the models' likelihood of using the counterfactual. We then use head attribution to identify individual attention heads that either promote the memorized answer or the in-context answer in the logits. By scaling up or down the value vector of these heads, we can control the likelihood of using the in-context answer on new data. This method can increase the rate of generating the in-context answer to 88{\%} of the time simply by scaling a single head at runtime. Our work contributes to a body of evidence showing that we can often localize model behaviors to specific components and provides a proof of concept for how future methods might control model behavior dynamically at runtime."
}


@inproceedings{geva:etal:2021,
  title={Transformer Feed-Forward Layers Are Key-Value Memories},
  author={Geva, Mor and Schuster, Roei and Berant, Jonathan and Levy, Omer},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={5484--5495},
  year={2021}
}


@inproceedings{geva:etal:2022,
  title={Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space},
  author={Geva, Mor and Caciularu, Avi and Wang, Kevin and Goldberg, Yoav},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={30--45},
  year={2022}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}
@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}
@book{stewart:2022,
  title={Galois theory},
  author={Stewart, Ian},
  year={2022},
  publisher={Chapman and Hall/CRC}
}

@article{brosowski:deutsch:1981,
  title={An elementary proof of the Stone-Weierstrass theorem},
  author={Brosowski, Bruno and Deutsch, Frank},
  journal={Proceedings of the American Mathematical Society},
  pages={89--92},
  year={1981},
  publisher={JSTOR}
}


@inproceedings{zhu:etal:2015,
  title={Aligning books and movies: Towards story-like visual explanations by watching movies and reading books},
  author={Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={19--27},
  year={2015}
}

@article{definetti:1937,
  title={La prévision : ses lois logiques, ses sources subjectives},
  author={De Finetti, Bruno},
  journal={Annales de l'institut {H}enri {P}oincaré},
  volume={7},
  pages={1--68},
  year={1937}
}
@book{russell:1903,
  title={Principles of mathematics},
  author={Russell, Bertrand},
  year={1903},
  city={New York},
  publisher={Norton Publishers, Second Edition}
}



@article{davidson:1967,
  title={Truth and Meaning},
  author={Davidson, Donald},
  journal={Synthese},
  volume={17},
  pages={304-323},
  year={1967}
}
@inproceedings{kalouli:etal:2022,
  title={Negation, Coordination, and Quantifiers in Contextualized Language Models},
  author={Kalouli, Aikaterini-Lida and Sevastjanova, Rita and Beck, Christin and Romero, Maribel},
  booktitle={Proceedings of the 29th International Conference on Computational Linguistics},
  pages={3074--3085},
  year={2022}
}

@inproceedings{li:etal:2021,
  title={Implicit Representations of Meaning in Neural Language Models},
  author={Li, Belinda Z and Nye, Maxwell and Andreas, Jacob},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={1813--1827},
  year={2021}
}

@article{rafailov:etal:2023,
  title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D and Finn, Chelsea},
  journal={arXiv preprint arXiv:2305.18290},
  year={2023}
}

@article{christiano:etal:2017,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{bai:etal:2022,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@article{ziegler:etal:2019,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}


@phdthesis{heim:1982,
AUTHOR = {I. Heim},
YEAR = {1982},
TITLE = {The Semantics of Definite and Indefinite Noun Phrases},
SCHOOL = {University of Massachussetts}
}

@incollection{kamp:1981,
AUTHOR = {Hans Kamp},
TITLE = {A Theory of Truth and Semantic Representation},
BOOKTITLE = {Formal Methods in the Study of Language},
EDITOR = {J.\ Groenendijk and  T.\ Janssen and M.\ Stokhof},  
PUBLISHER = {Mathematisch Centrum, Amsterdam},
YEAR = {1981},
PAGES = {277--322}
}

@article{chaturvedi:etal:2022,
    author = {Chaturvedi, Akshay and Bhar, Swarnadeep and Saha, Soumadeep and Garain, Utpal and Asher, Nicholas},
    title = "{Analyzing Semantic Faithfulness of Language Models via Input Intervention on Question Answering}",
    journal = {Computational Linguistics},
    pages = {1-37},
    year = {2024},
    month = {01},
    issn = {0891-2017},
    doi = {10.1162/coli_a_00493},
    url = {https://doi.org/10.1162/coli\_a\_00493},
    eprint = {https://direct.mit.edu/coli/article-pdf/doi/10.1162/coli\_a\_00493/2212762/coli\_a\_00493.pdf},
}

@inproceedings{li:etal:2023a,
    title = "{H}alu{E}val: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models",
    author = "Li, Junyi  and
      Cheng, Xiaoxue  and
      Zhao, Xin  and
      Nie, Jian-Yun  and
      Wen, Ji-Rong",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.397",
    doi = "10.18653/v1/2023.emnlp-main.397",
    pages = "6449--6464"
}

@inproceedings{kletz:etal:2023,
  title={Probing structural constraints of negation in Pretrained Language Models},
  author={Kletz, David and Candito, Marie and Amsili, Pascal},
  booktitle={Proceedings of the 24th Nordic Conference on Computational Linguistics (NoDaLiDa)},
  pages={541--554},
  year={2023}
}


@inproceedings{tenney:etal:2019,
  title={BERT rediscovers the classical NLP
pipeline},
  author={Tenney, Ian and Das, Dipanjan and Pavlick, Ellie},
  booktitle={In Proceedings of the 57th Annual
Meeting of the Association for Computational
Linguistics},
  pages ={4593–4601},
  year={2019}
}

@misc{wei:etal:2023,
      title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models}, 
      author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
      year={2023},
      eprint={2201.11903},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{tenney:etal:2018,
  title={What do you learn from context? Probing for sentence structure in contextualized word representations},
  author={Tenney, Ian and Xia, Patrick and Chen, Berlin and Wang, Alex and Poliak, Adam and McCoy, R Thomas and Kim, Najoung and Van Durme, Benjamin and Bowman, Samuel R and Das, Dipanjan and others},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{wang:cho:2019,
  title={BERT has a mouth, and it must speak: BERT as a Markov random field language model},
  author={Wang, Alex and Cho, Kyunghyun},
  journal={arXiv preprint arXiv:1902.04094},
  year={2019}
}


@article{ghazvininejad:etal:2019,
  title={Mask-predict: Parallel decoding of conditional masked language models},
  author={Ghazvininejad, Marjan and Levy, Omer and Liu, Yinhan and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1904.09324},
  year={2019}
}

@article{merrill:etal:2022,
  title={Entailment Semantics Can Be Extracted from an Ideal Language Model},
  author={Merrill, William and Warstadt, Alex and Linzen, Tal},
  journal={arXiv preprint arXiv:2209.12407},
  year={2022}
}

@article{talmor:etal:2020,
  title={oLMpics-on
what language model pre-training
captures},
  author={Talmor, Alon and Elazar,Yanai and Goldberg,Yoav and Berant, Jonathan},
  journal={Transactions of the Association for
Computational Linguistics},
  volume={8},
  pages= {743–758},
  year={2020}
}

@article{leblanc:1979,
  title={Probabilistic semantics for first-order logic},
  author={Leblanc, Hugues},
  journal={Zeitschrift für mathematische Logik und Grundlagen der Mathematik},
  volume={25},
  number={32},
  pages={497--509},
  year={1979},
  note={Wiley Online Library}
}


@article{steinert:etal:2019,
  title={Learnability and semantic universals},
  author={Steinert-Threlkeld, Shane and Szymanik, Jakub},
  journal={Semantics and Pragmatics},
  volume={12},
  number={4},
  year={2019}
}

@inproceedings{kuhnle:copestake:2019,
  title={The Meaning of “Most” for Visual Question Answering Models},
  author={Kuhnle, Alexander and Copestake, Ann},
  booktitle={Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
  pages={46--55},
  year={2019}
}


@Incollection{asher:pogodalla:2011,
          author="Asher, Nicholas and Pogodalla, Sylvain",
          editor="Onada, Takashi and Bekki, Daisuke and McCready, Eric",
          title="SDRT and Continuation Semantics",
          bookTitle="New Frontiers in Artificial Intelligence: JSAI-isAI 2010 Workshops, LENLS, JURISIN, AMBN, ISS, Tokyo, Japan, November 18-19, 2010, Revised Selected Papers",
          year="2011",
          publisher="Springer Berlin Heidelberg",
          address="Berlin, Heidelberg",
          pages="3--15",
          isbn="978-3-642-25655-4",
          doi="10.1007/978-3-642-25655-4_2",
          url="http://dx.doi.org/10.1007/978-3-642-25655-4_2"
}

@inproceedings{fernando:2022,
  title={Strings from neurons to language},
  author={Fernando, Tim},
  booktitle={Proceedings of the 3rd Natural Logic Meets Machine Learning Workshop (NALOMA III)},
  pages={1--10},
  year={2022}
}

@article{fernando:2004,
  title={A finite-state approach to events in natural language semantics},
  author={Fernando, Tim},
  journal={Journal of Logic and Computation},
  volume={14},
  number={1},
  pages={79--92},
  year={2004},
  publisher={OUP}
}

@book{dowty:etal:1981,
  title={Introduction to Montague semantics},
  author={Dowty, David R and Wall, Robert and Peters, Stanley},
  note={Synthese Library vol. 11},
  year={1981},
  publisher={Dordrecht}
}
 @book{asher:1993,
AUTHOR = {Nicholas Asher},
TITLE = {Reference to Abstract Objects in Discourse},
YEAR = {1993},
PUBLISHER = {Kluwer Academic Publishers}
}

@article{brunner:etal:2019,
  title={On identifiability in transformers},
  author={Brunner, Gino and Liu, Yang and Pascual, Damian and Richter, Oliver and Ciaramita, Massimiliano and Wattenhofer, Roger},
  journal={arXiv preprint arXiv:1908.04211},
  year={2019}
}

@inproceedings{degroote:2006,
  title={Towards a Montagovian account of dynamics},
  author={De Groote, Philippe},
  booktitle={Semantics and linguistic theory},
  volume={16},
  pages={1--16},
  year={2006}
}

@inproceedings{reynolds:1974,
  title={On the Relation between Direct and Continuation Semantics},
  author={John C. Reynolds},
  booktitle={International Colloquium on Automata, Languages and Programming},
  year={1974}
}
@book{kamp:reyle:1993,
AUTHOR = {H. Kamp and U. Reyle},
TITLE = {From Discourse to Logic: Introduction to Modeltheoretic
                  Semantics of Natural Language, Formal Logic and
                  Discourse Representation Theory},
YEAR = {1993},
PUBLISHER = {Kluwer Academic Publishers}
}


@Article{JPL,
  author = 	 {Nicholas Asher and Soumya Paul and Antoine Venant},
  title = 	 {Message Exchange Games in strategic conversations},
  journal = 	 {Journal of Philosophical Logic},
  year = 	 2017,
  volume = 	 {46.4},
  pages = {355-404},
  url = 	 {http://dx.doi.org/10.1007/s10992-016-9402-1}
}

@inproceedings{lamport:1980,
  title={Sometime is sometimes not never: On the temporal logic of programs},
  author={Lamport, L.},
  booktitle={Proceedings of the 7th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
  pages={174--185},
  year={1980},
  organization={ACM}
}

@article{mohammad:etal:2013,
  title={Computing lexical contrast},
  author={Mohammad, Saif M and Dorr, Bonnie J and Hirst, Graeme and Turney, Peter D},
  journal={Computational Linguistics},
  volume={39},
  number={3},
  pages={555--590},
  year={2013},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{asher:bhar:2024,
  title={Strong hallucinations from negation and how to fix them},
  author={Asher, Nicholas and Bhar, Swarnadeep},
  journal={arXiv preprint arXiv:2402.10543},
  year={2024}
}

@article{kruszewski:etal:2016,
  title={There is no logical negation here, but there are alternatives: Modeling conversational negation with distributional semantics},
  author={Kruszewski, Germ{\'a}n and Paperno, Denis and Bernardi, Raffaella and Baroni, Marco},
  journal={Computational Linguistics},
  volume={42},
  number={4},
  pages={637--660},
  year={2016},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}
@article{neyshabur:etal:2017general,
  title={Exploring generalization in deep learning},
  author={Neyshabur, Behnam and Bhojanapalli, Srinadh and McAllester, David and Srebro, Nati},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{kawaguchi:etal:2017generalization,
  title={Generalization in deep learning},
  author={Kawaguchi, Kenji and Kaelbling, Leslie Pack and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1710.05468},
  year={2017}
}

@article{colbrook:etal:2022,
  title={The difficulty of computing stable and accurate neural networks: On the barriers of deep learning and Smale’s 18th problem},
  author={Colbrook, Matthew J and Antun, Vegard and Hansen, Anders C},
  journal={Proceedings of the National Academy of Sciences},
  volume={119},
  number={12},
  pages={e2107151119},
  year={2022},
  publisher={National Acad Sciences}
}


@article{kassner:schutze:2019,
  title={Negated and misprimed probes for pretrained language models: Birds can talk, but cannot fly},
  author={Kassner, Nora and Sch{\"u}tze, Hinrich},
  journal={arXiv preprint arXiv:1911.03343},
  year={2019}
}

@inproceedings{traylor:etal:2021a,
  title={Transferring Representations of Logical Connectives},
  author={Traylor, Aaron and Pavlick, Ellie and Feiman, Roman},
  booktitle={Proceedings of the 1st and 2nd Workshops on Natural Logic Meets Machine Learning (NALOMA)},
  pages={22--25},
  year={2021}
}

@inproceedings{traylor2021b,
  title={AND does not mean OR: using formal languages to study language models’ representations},
  author={Traylor, Aaron and Feiman, Roman and Pavlick, Ellie},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
  pages={158--167},
  year={2021}
}

@inproceedings{ryb:etal:2022,
  title={AnaLog: Testing Analytical and Deductive Logic Learnability in Language Models},
  author={Ryb, Samuel and Giulianelli, Mario and Sinclair, Arabella and Fern{\'a}ndez, Raquel},
  booktitle={Proceedings of the 11th Joint Conference on Lexical and Computational Semantics},
  pages={55--68},
  year={2022}
}

@inproceedings{kassner:schutze:2020,
  title={Negated and Misprimed Probes for Pretrained Language Models: Birds Can Talk, But Cannot Fly},
  author={Kassner, Nora and Sch{\"u}tze, Hinrich},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={7811--7818},
  year={2020}
}
@inproceedings{hosseini:etal:2021,
  title={Understanding by Understanding Not: Modeling Negation in Language Models},
  author={Hosseini, Arian and Reddy, Siva and Bahdanau, Dzmitry and Hjelm, R Devon and Sordoni, Alessandro and Courville, Aaron},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={1301--1312},
  year={2021}
}

@incollection{vaneijk:kamp:1997,
author = {J.\ van Eijck and H.\ Kamp},
YEAR = {1997},
TITLE = {Representing Discourse in Context},
BOOKTITLE = {Handbook of Logic and Linguistics},
EDITOR = {Johan {van Benthem} and Alice {ter Meulen}},
PAGES = {179--237},
publisher = {Elsevier}
}

@book{pustejovsky:1995,
AUTHOR = {J. Pustejovsky},
YEAR = {1995},
TITLE = {The Generative Lexicon},
PUBLISHER = {{\sc mit} Press}
}

@inproceedings{naik-etal-2018stress,
  title={Stress Test Evaluation for Natural Language Inference},
  author={Naik, Aakanksha and Ravichander, Abhilasha and Sadeh, Norman and Rose, Carolyn and Neubig, Graham},
  booktitle={Proceedings of the 27th International Conference on Computational Linguistics},
  pages={2340--2353},
  year={2018}
}


@inproceedings{hossain-etal-2020-analysis,
  title={An analysis of natural language inference benchmarks through the lens of negation},
  author={Hossain, Md Mosharaf and Kovatchev, Venelin and Dutta, Pranoy and Kao, Tiffany and Wei, Elizabeth and Blanco, Eduardo},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={9106--9118},
  year={2020}
}
@article{brown:etal:2020,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}


@article{von-oswald:etal:2022,
  title={Transformers learn in-context by gradient descent},
  author={von Oswald, Johannes and Niklasson, Eyvind and Randazzo, Ettore and Sacramento, Jo{\~a}o and Mordvintsev, Alexander and Zhmoginov, Andrey and Vladymyrov, Max},
  journal={arXiv preprint arXiv:2212.07677},
  year={2022}
}
@article{garg:etal:2022,
  title={What can transformers learn in-context? a case study of simple function classes},
  author={Garg, Shivam and Tsipras, Dimitris and Liang, Percy S and Valiant, Gregory},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={30583--30598},
  year={2022}
}


@inproceedings{dai:etal:2023,
  title={Why Can GPT Learn In-Context? Language Models Implicitly Perform Gradient Descent as Meta-Optimizers},
  author={Dai, Damai and Sun, Yutao and Dong, Li and Hao, Yaru and Ma, Shuming and Sui, Zhifang and Wei, Furu},
  booktitle={ICLR 2023 Workshop on Mathematical and Empirical Understanding of Foundation Models},
  year={2023}
}


@inproceedings{graf:2019,
  title={A subregular bound on the complexity of lexical quantifiers},
  author={Graf, Thomas},
  booktitle={Proceedings of the 22nd Amsterdam colloquium},
  year={2019}
}

@article{raissi:etal:2017pinns,
  title={Physics informed deep learning (part i): Data-driven solutions of nonlinear partial differential equations},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
  journal={arXiv preprint arXiv:1711.10561},
  year={2017}
}

@incollection{villa:etal:2013,
  title={On learnability, complexity and stability},
  author={Villa, Silvia and Rosasco, Lorenzo and Poggio, Tomaso},
  booktitle={Empirical Inference},
  pages={59--69},
  year={2013},
  publisher={Springer}
}

@book{anthony:etal:1999,
  title={Neural network learning: Theoretical foundations},
  author={Anthony, Martin and Bartlett, Peter L and Bartlett, Peter L and others},
  volume={9},
  year={1999},
  publisher={cambridge university press Cambridge}
}

@inproceedings{siegelmann:sontag:1992,
  title={On the computational power of neural nets},
  author={Siegelmann, Hava T and Sontag, Eduardo D},
  booktitle={Proceedings of the fifth annual workshop on Computational learning theory},
  pages={440--449},
  year={1992}
}

@article{weiss:etal:2018,
  title={On the practical computational power of finite precision RNNs for language recognition},
  author={Weiss, Gail and Goldberg, Yoav and Yahav, Eran},
  journal={arXiv preprint arXiv:1805.04908},
  year={2018}
}



@book{siegelmann:2012,
  title={Neural networks and analog computation: beyond the Turing limit},
  author={Siegelmann, Hava T},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@Article{barwise:cooper:1981,
  author = 	 {Jon Barwise and Robin Cooper},
  title = 	 {Generalized Quantifiers in Natural
Language},
  journal = 	 lp,
  year = 	 1981,
  volume =	 4,
  number =	 1,
  pages =	 {159-219}
}

@article{kirkpatrick:etal:2017,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Acad Sciences}
}

@book{schilling:2017,
  title={Measures, integrals and martingales},
  author={Schilling, Ren{\'e} L},
  year={2017},
  publisher={Cambridge University Press}
}


@article{yuksekgonul:etal:2022,
  title={When and why vision-language models behave like bag-of-words models, and what to do about it?},
  author={Yuksekgonul, Mert and Bianchi, Federico and Kalluri, Pratyusha and Jurafsky, Dan and Zou, James},
  journal={arXiv preprint arXiv:2210.01936},
  year={2022}
}

@book{asher:2011,
 author="Nicholas Asher",
 year="2011",
 title="Lexical Meaning in Context: A web of words",
 publisher="Cambridge University Press"
 }


 @phdthesis{chaturvedi:2021,
author = {Akshay Chaturvedi},
year = {2021}, 
title = {On Adversarial Robustness of
Deep Learning Systems},
school = {Indian Statistical Institute, Kolkata, India}
}


@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@unpublished{chaturvedi:asher:2024,
author = {Akshay Chaturvedi and Nicholas Asher},
title = {Learning Semantic Structure through First-Order-Logic Translation},
note = {in review},
year = 2024
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

@article{liu:etal:2021prompt,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={arXiv preprint arXiv:2107.13586},
  year={2021}
}







@misc{coqa:19,
      title={Technical report on Conversational Question Answering}, 
      author={Ying Ju and Fubang Zhao and Shijie Chen and Bowen Zheng and Xuefeng Yang and Yunfeng Liu},
      year={2019},
      eprint={1909.10772},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{xlnet,
 author = {Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {XLNet: Generalized Autoregressive Pretraining for Language Understanding},
 url = {https://proceedings.neurips.cc/paper/2019/file/dc6a7e655d7e5840e66733e9ee67cc69-Paper.pdf},
 volume = {32},
 year = {2019}
}



@inproceedings{
tenney2018what,
title={What do you learn from context? Probing for sentence structure in contextualized word representations},
author={Ian Tenney and Patrick Xia and Berlin Chen and Alex Wang and Adam Poliak and R Thomas McCoy and Najoung Kim and Benjamin Van Durme and Sam Bowman and Dipanjan Das and Ellie Pavlick},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=SJzSgnRcKX},
}

@inproceedings{jang:etal:2022a,
  title={Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence},
  author={Jang, Mj and Mtumbuka, Frank and Lukasiewicz, Thomas},
  booktitle={Findings of the Association for Computational Linguistics: NAACL 2022},
  pages={2030--2042},
  year={2022}
}

@article{coqa,
    author = {Reddy, Siva and Chen, Danqi and Manning, Christopher D.},
    title = "{CoQA: A Conversational Question Answering Challenge}",
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {7},
    pages = {249-266},
    year = {2019},
    month = {05},
    abstract = "{Humans gather information through conversations involving a series of interconnected questions and answers. For machines to assist in information gathering, it is therefore essential to enable them to answer conversational questions. We introduce CoQA, a novel dataset for building Conversational Question Answering systems. Our dataset contains 127k questions with answers, obtained from 8k conversations about text passages from seven diverse domains. The questions are conversational, and the answers are free-form text with their corresponding evidence highlighted in the passage. We analyze CoQA in depth and show that conversational questions have challenging phenomena not present in existing reading comprehension datasets (e.g., coreference and pragmatic reasoning). We evaluate strong dialogue and reading comprehension models on CoQA. The best system obtains an F1 score of 65.4\\%, which is 23.4 points behind human performance (88.8\\%), indicating that there is ample room for improvement. We present CoQA as a challenge to the community at https://stanfordnlp.github.io/coqa.}",
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00266},
    url = {https://doi.org/10.1162/tacl\_a\_00266},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00266/1923252/tacl\_a\_00266.pdf},
}

@article{gaifman:1964,
  title={Concerning measures on Boolean algebras.},
  author={Gaifman, Haim},
  journal={Pacific Journal of Mathematics},
  number= {14},
  pages = {61–73},
  year={1964}
}


@book{chang:keisler:1973,
  title={Model theory},
  author={Chang, Chen Chung and Keisler, H Jerome},
  year={1973},
  publisher={North Holland, Elsevier}
}

@article{amnesic,
    author = {Elazar, Yanai and Ravfogel, Shauli and Jacovi, Alon and Goldberg, Yoav},
    title = "{Amnesic Probing: Behavioral Explanation with Amnesic Counterfactuals}",
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {9},
    pages = {160-175},
    year = {2021},
    month = {03},
    abstract = "{A growing body of work makes use of probing in order to investigate the working of neural models, often considered black boxes. Recently, an ongoing debate emerged surrounding the limitations of the probing paradigm. In this work, we point out the inability to infer behavioral conclusions from probing results, and offer an alternative method that focuses on how the information is being used, rather than on what information is encoded. Our method, Amnesic Probing, follows the intuition that the utility of a property for a given task can be assessed by measuring the influence of a causal intervention that removes it from the representation. Equipped with this new analysis tool, we can ask questions that were not possible before, for example, is part-of-speech information important for word prediction? We perform a series of analyses on BERT to answer these types of questions. Our findings demonstrate that conventional probing performance is not correlated to task importance, and we call for increased scrutiny of claims that draw behavioral or causal conclusions from probing results.1}",
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00359},
    url = {https://doi.org/10.1162/tacl\_a\_00359},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00359/1924189/tacl\_a\_00359.pdf},
}


@article{bert-mispellings,
  author    = {Lichao Sun and
               Kazuma Hashimoto and
               Wenpeng Yin and
               Akari Asai and
               Jia Li and
               Philip S. Yu and
               Caiming Xiong},
  title     = {Adv-BERT: {BERT} is not robust on misspellings! Generating nature
               adversarial samples on {BERT}},
  journal   = {CoRR},
  volume    = {abs/2003.04985},
  year      = {2020},
  url       = {https://arxiv.org/abs/2003.04985},
  eprinttype = {arXiv},
  eprint    = {2003.04985},
  timestamp = {Wed, 28 Oct 2020 14:53:39 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2003-04985.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
belinkov2018synthetic,
title={Synthetic and Natural Noise Both Break Neural Machine Translation},
author={Yonatan Belinkov and Yonatan Bisk},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=BJ8vJebC-},
}

@inproceedings{NEURIPS2019_2c601ad9,
 author = {Michel, Paul and Levy, Omer and Neubig, Graham},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Are Sixteen Heads Really Better than One?},
 url = {https://proceedings.neurips.cc/paper/2019/file/2c601ad9d2ff9bc8b282670cdd54f69f-Paper.pdf},
 volume = {32},
 year = {2019}
}

@inproceedings{
Brunner2020On,
title={On Identifiability in Transformers},
author={Gino Brunner and Yang Liu and Damian Pascual and Oliver Richter and Massimiliano Ciaramita and Roger Wattenhofer},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=BJg1f6EFDB}
}

@article{scholkopf2019causality,
      title={Causality for Machine Learning}, 
      author={Bernhard Schölkopf},
      year={2019},
      journal={arXiv preprint arXiv:1911.10500},
      eprint={1911.10500},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{rooth:1992,
  author = {M.\ Rooth},
  title = {A Theory of Focus Interpretation},
  journal = {Natural Language Semantics},
  year = {1992},
  volume = {1},
  number = {1},
  pages = {75--116},
  topic = {sentence-focus;alternatives;pragmatics;}
  }

@inproceedings{baroni:zamparelli:2010,
  title={Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space},
  author={Baroni, Marco and Zamparelli, Roberto},
  booktitle={Proceedings of the 2010 conference on empirical methods in natural language processing},
  pages={1183--1193},
  year={2010}
}
@incollection{karttunen:peters:1979,
  title={Conventional lmplicature},
  author={Karttunen, Lauri and Peters, Stanley},
  booktitle={Presupposition},
  pages={1--56},
  year={1979},
  publisher={Brill}
}
@phdthesis{groenendijk:stokhof:1984,
AUTHOR = {Jeroen Groenendijk and Martin Stokhof},
YEAR = {1984},
TITLE = {Studies on the Semantics of Questions and the Pragmatics of
                  Answers}, 
SCHOOL = {Centrale Interfaculteit, Amsterdam}
}

@article{squad,
  title={Squad: 100,000+ questions for machine comprehension of text},
  author={Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
  journal={arXiv preprint arXiv:1606.05250},
  year={2016}
}

@article{truong:etal:2023,
  title={Language models are not naysayers: An analysis of language models on negation benchmarks},
  author={Truong, Thinh Hung and Baldwin, Timothy and Verspoor, Karin and Cohn, Trevor},
  journal={arXiv preprint arXiv:2306.08189},
  year={2023}
}

@inproceedings{jang:etal:2022,
  title={BECEL: Benchmark for Consistency Evaluation of Language Models},
  author={Jang, Myeongjun and Kwon, Deuk Sin and Lukasiewicz, Thomas},
  booktitle={Proceedings of the 29th International Conference on Computational Linguistics},
  pages={3680--3696},
  year={2022}
}


@inproceedings{kusner2017counterfactual,
 author = {Kusner, Matt J and Loftus, Joshua and Russell, Chris and Silva, Ricardo},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {4066--4076},
 publisher = {Curran Associates, Inc.},
 title = {Counterfactual Fairness},
 volume = {30},
 year = {2017}
}

@book{barocas-hardt-narayanan,
  title = {Fairness and Machine Learning},
  author = {Solon Barocas and Moritz Hardt and Arvind Narayanan},
  publisher = {fairmlbook.org},
  note = {\url{http://www.fairmlbook.org}},
  year = {2019}
}

@inproceedings{asher:etal:2021,
  title={Fair and Adequate Explanations},
  author={Asher, Nicholas and Paul, Soumya and Russell, Chris},
  booktitle={International Cross-Domain Conference for Machine Learning and Knowledge Extraction},
  pages={79--97},
  year={2021},
  organization={Springer}
}
@article{mishra:etal:2022,
  title={Cross-Task Generalization via Natural Language Crowdsourcing Instructions},
  author={Mishra, Swaroop and Khashabi, Daniel and Baral, Chitta and Hajishirzi, Hannaneh},
  booktitle={60th Annual Meeting of the Association for Computational Linguistics, ACL 2022},
  pages={3470--3487},
  year={2022},
  organization={Association for Computational Linguistics (ACL)}
}

@inproceedings{poole:2011,
  title={Logic, probability and computation: Foundations and issues of statistical relational AI},
  author={Poole, David},
  booktitle={International Conference on Logic Programming and Nonmonotonic Reasoning},
  pages={1--9},
  year={2011},
  organization={Springer}
}

@article{ebrahimi:etal:2021,
  title={Towards bridging the neuro-symbolic gap: Deep deductive reasoners},
  author={Ebrahimi, Monireh and Eberhart, Aaron and Bianchi, Federico and Hitzler, Pascal},
  journal={Applied Intelligence},
  volume={51},
  pages={6326--6348},
  year={2021},
  publisher={Springer}
}

@article{ji:etal:2023,
  title={Survey of hallucination in natural language generation},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  journal={ACM Computing Surveys},
  volume={55},
  number={12},
  pages={1--38},
  year={2023},
  publisher={ACM New York, NY}
}


@article{van-deemter:2024,
  title={The Pitfalls of Defining Hallucination},
  author={van Deemter, Kees},
  journal={Computational Linguistics},
  pages={1--10},
  year={2024},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@inproceedings{chiang:etal:2023,
  title={Tighter bounds on the expressivity of transformer encoders},
  author={Chiang, David and Cholak, Peter and Pillay, Anand},
  booktitle={International Conference on Machine Learning},
  pages={5544--5562},
  year={2023},
  organization={PMLR}
}

@article{perez:etal:2021,
  title={Attention is turing-complete},
  author={P{\'e}rez, Jorge and Barcel{\'o}, Pablo and Marinkovic, Javier},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={75},
  pages={1--35},
  year={2021}
}


@article{deraedt:etal:2020,
  title={From statistical relational to neuro-symbolic artificial intelligence},
  author={De Raedt, Luc and Duman{\v{c}}i{\'c}, Sebastijan and Manhaeve, Robin and Marra, Giuseppe},
  journal={arXiv preprint arXiv:2003.08316},
  year={2020}
}

@inproceedings{olausson:etal:2023,
  title={LINC: A Neurosymbolic Approach for Logical Reasoning by Combining Language Models with First-Order Logic Provers},
  author={Olausson, Theo X and Gu, Alex and Lipkin, Ben and Zhang, Cedegao E and Solar-Lezama, Armando and Tenenbaum, Joshua B and Levy, Roger P},
  booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
  year={2023}
}

@article{rafailov:etal:2024,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{giannou:etal:2024,
  title={How Well Can Transformers Emulate In-context Newton's Method?},
  author={Giannou, Angeliki and Yang, Liu and Wang, Tianhao and Papailiopoulos, Dimitris and Lee, Jason D},
  journal={arXiv preprint arXiv:2403.03183},
  year={2024}
}


@book{blackburn2001modal,
  title={Modal logic, Cambridge Tracts in Theoretical Computer Science No.53},
  author={Blackburn, Patrick and De Rijke, Maarten and Venema, Yde},
  year={2001},
  publisher={Cambridge University Press}
}

@article{bai:etal:2024,
  title={Transformers as statisticians: Provable in-context learning with in-context algorithm selection},
  author={Bai, Yu and Chen, Fan and Wang, Huan and Xiong, Caiming and Mei, Song},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@article{zhang:etal:2024,
  title={Trained transformers learn linear models in-context},
  author={Zhang, Ruiqi and Frei, Spencer and Bartlett, Peter L},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={49},
  pages={1--55},
  year={2024}
}

@article{shalev:etal:2010,
  title={Learnability, stability and uniform convergence},
  author={Shalev-Shwartz, Shai and Shamir, Ohad and Srebro, Nathan and Sridharan, Karthik},
  journal={The Journal of Machine Learning Research},
  volume={11},
  pages={2635--2670},
  year={2010},
  publisher={JMLR. org}
}

@article{tarski:1944,
  title={The semantic conception of truth: and the foundations of semantics},
  author={Tarski, Alfred},
  journal={Philosophy and phenomenological research},
  volume={4},
  number={3},
  pages={341--376},
  year={1944},
  publisher={JSTOR}
}


@inproceedings{kobayashi:etal:2021,
  title={Incorporating Residual and Normalization Layers into Analysis of Masked Language Models},
  author={Kobayashi, Goro and Kuribayashi, Tatsuki and Yokoi, Sho and Inui, Kentaro},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  year={2021},
  organization={Association for Computational Linguistics}
}

@article{devillers:etal:2023,
  title={Semi-supervised Multimodal Representation Learning through a Global Workspace},
  author={Devillers, Benjamin and Mayti{\'e}, L{\'e}opold and VanRullen, Rufin},
  journal={arXiv preprint arXiv:2306.15711},
  year={2023}
}


@inproceedings{ferrando:etal:2022,
  title={Measuring the Mixing of Contextual Information in the Transformer},
  author={Ferrando, Javier and G{\'a}llego, Gerard I and Costa-juss{\`a}, Marta R},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={8698--8714},
  year={2022}
}
@article{driess:etal:2023,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={arXiv preprint arXiv:2303.03378},
  year={2023}
}

@article{li:etal:2019,
  title={Visualbert: A simple and performant baseline for vision and language},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1908.03557},
  year={2019}
}

@article{lu:etal:2019,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}


@article{zhou:etal:2020,
  title={Detecting hallucinated content in conditional neural sequence generation},
  author={Zhou, Chunting and Neubig, Graham and Gu, Jiatao and Diab, Mona and Guzman, Paco and Zettlemoyer, Luke and Ghazvininejad, Marjan},
  journal={arXiv preprint arXiv:2011.02593},
  year={2020}
}

@article{parikh:etal:2020,
  title={ToTTo: A controlled table-to-text generation dataset},
  author={Parikh, Ankur P and Wang, Xuezhi and Gehrmann, Sebastian and Faruqui, Manaal and Dhingra, Bhuwan and Yang, Diyi and Das, Dipanjan},
  journal={arXiv preprint arXiv:2004.14373},
  year={2020}
}

@inproceedings{kalyanpur:etal:2022,
  title={Braid: Weaving symbolic and neural knowledge into coherent logical explanations},
  author={Kalyanpur, Aditya and Breloff, Tom and Ferrucci, David A},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={36},
  number={10},
  pages={10867--10874},
  year={2022}
}


@article{riegel:etal:2020,
  title={Logical neural networks},
  author={Riegel, Ryan and Gray, Alexander and Luus, Francois and Khan, Naweed and Makondo, Ndivhuwo and Akhalwaya, Ismail Yunus and Qian, Haifeng and Fagin, Ronald and Barahona, Francisco and Sharma, Udit and others},
  journal={arXiv preprint arXiv:2006.13155},
  year={2020}
}


@article{groenendijk:stokhof:1991,
AUTHOR = {Jeroen Groenendijk and Martin Stokhof},
YEAR = {1991},
TITLE = {Dynamic Predicate Logic},
JOURNAL = {Linguistics and Philosophy},
VOLUME = {14},
number=1,
PAGES = {39--100},
PUBLISHER = {Kluwer Academic Publishers},
doi = {10.1007/BF00628304}
}

@article{lewis:1986,
  title={Probabilities of conditionals and conditional probabilities II},
  author={Lewis, David},
  journal={The Philosophical Review},
  volume={95},
  number={4},
  pages={581--589},
  year={1986},
  publisher={JSTOR}
}

@inproceedings{moramarco:etal:2022,
  title={Human Evaluation and Correlation with Automatic Metrics in Consultation Note Generation},
  author={Moramarco, Francesco and Korfiatis, Alex Papadopoulos and Perera, Mark and Juric, Damir and Flann, Jack and Reiter, Ehud and Savkov, Aleksandar and Belz, Anja},
  booktitle={ACL 2022: 60th Annual Meeting of the Association for Computational Linguistics},
  pages={5739--5754},
  year={2022},
  organization={Association for Computational Linguistics}
}


@article{maynez:etal:2020,
  title={On faithfulness and factuality in abstractive summarization},
  author={Maynez, Joshua and Narayan, Shashi and Bohnet, Bernd and McDonald, Ryan},
  journal={arXiv preprint arXiv:2005.00661},
  year={2020}
}

@article{longpre:etal:2021,
  title={Entity-based knowledge conflicts in question answering},
  author={Longpre, Shayne and Perisetla, Kartik and Chen, Anthony and Ramesh, Nikhil and DuBois, Chris and Singh, Sameer},
  journal={arXiv preprint arXiv:2109.05052},
  year={2021}
}

@article{goyal:etal:2020,
  title={Evaluating factuality in generation with dependency-level entailment},
  author={Goyal, Tanya and Durrett, Greg},
  journal={arXiv preprint arXiv:2010.05478},
  year={2020}
}

@article{filippova:2020,
  title={Controlled hallucinations: Learning to generate faithfully from noisy data},
  author={Filippova, Katja},
  journal={arXiv preprint arXiv:2010.05873},
  year={2020}
}

@article{sellam:etal:2020,
  title={BLEURT: Learning robust metrics for text generation},
  author={Sellam, Thibault and Das, Dipanjan and Parikh, Ankur P},
  journal={arXiv preprint arXiv:2004.04696},
  year={2020}
}

@article{dhingra:etal:2019,
  title={Handling divergent reference texts when evaluating table-to-text generation},
  author={Dhingra, Bhuwan and Faruqui, Manaal and Parikh, Ankur and Chang, Ming-Wei and Das, Dipanjan and Cohen, William W},
  journal={arXiv preprint arXiv:1906.01081},
  year={2019}
}

@article{huang:etal:2021,
  title={The factual inconsistency problem in abstractive text summarization: A survey},
  author={Huang, Yichong and Feng, Xiachong and Feng, Xiaocheng and Qin, Bing},
  journal={arXiv preprint arXiv:2104.14839},
  year={2021}
}

@book{kolmogorov:2018,
  title={Foundations of the theory of probability},
  author={Kolmogorov, Andre{\u\i} Nikolaevich},
  year={1933},
  publisher={Courier Dover Publications},
  note= {translated by A Bharaucha-Reid in the Second Edition.}
}


@article{nakano:etal:2021,
  title={Webgpt: Browser-assisted question-answering with human feedback},
  author={Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others},
  journal={arXiv preprint arXiv:2112.09332},
  year={2021}
}
@article{lin:etal:2021,
  title={Truthfulqa: Measuring how models mimic human falsehoods},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  journal={arXiv preprint arXiv:2109.07958},
  year={2021}
}

@article{vanrullen:kanai:2021,
  title={Deep learning and the global workspace theory},
  author={VanRullen, Rufin and Kanai, Ryota},
  journal={Trends in Neurosciences},
  volume={44},
  number={9},
  pages={692--704},
  year={2021},
  publisher={Elsevier}
}
@article{huang2020knowledge,
  title={Knowledge graph-augmented abstractive summarization with semantic-driven cloze reward},
  author={Huang, Luyang and Wu, Lingfei and Wang, Lu},
  journal={arXiv preprint arXiv:2005.01159},
  year={2020}
}

@inproceedings{cao2018faithful,
  title={Faithful to the original: Fact aware neural abstractive summarization},
  author={Cao, Ziqiang and Wei, Furu and Li, Wenjie and Li, Sujian},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@article{bowman:etal:2015,
  title={A large annotated corpus for learning natural language inference},
  author={Bowman, Samuel R and Angeli, Gabor and Potts, Christopher and Manning, Christopher D},
  journal={arXiv preprint arXiv:1508.05326},
  year={2015}
}

@article{williams:etal:2017,
  title={A broad-coverage challenge corpus for sentence understanding through inference},
  author={Williams, Adina and Nangia, Nikita and Bowman, Samuel R},
  journal={arXiv preprint arXiv:1704.05426},
  year={2017}
}

@inproceedings{gubelmann:handschuh:2022,
  title={Context matters: A pragmatic study of PLMs’ negation understanding},
  author={Gubelmann, Reto and Handschuh, Siegfried},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={4602--4621},
  year={2022}
}


@inproceedings{dagan:etal:2005,
  title={The pascal recognising textual entailment challenge},
  author={Dagan, Ido and Glickman, Oren and Magnini, Bernardo},
  booktitle={Machine learning challenges workshop},
  pages={177--190},
  year={2005},
  organization={Springer}
}

@inproceedings{petroni2019language,
  title={Language Models as Knowledge Bases?},
  author={F. Petroni and T. Rockt{\"{a}}schel and A. H. Miller and P. Lewis and A. Bakhtin and Y. Wu and S. Riedel},
  booktitle={In: Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2019},
  year={2019}
}
@inproceedings{elsahar-etal-2018-rex,
    title = "{T}-{RE}x: A Large Scale Alignment of Natural Language with Knowledge Base Triples",
    author = "Elsahar, Hady  and
      Vougiouklis, Pavlos  and
      Remaci, Arslen  and
      Gravier, Christophe  and
      Hare, Jonathon  and
      Laforest, Frederique  and
      Simperl, Elena",
    editor = "Calzolari, Nicoletta  and
      Choukri, Khalid  and
      Cieri, Christopher  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Hasida, Koiti  and
      Isahara, Hitoshi  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, H{\'e}l{\`e}ne  and
      Moreno, Asuncion  and
      Odijk, Jan  and
      Piperidis, Stelios  and
      Tokunaga, Takenobu",
    booktitle = "Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018)",
    month = may,
    year = "2018",
    address = "Miyazaki, Japan",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://aclanthology.org/L18-1544",
}

@inproceedings{li-etal-2016-commonsense,
    title = "Commonsense Knowledge Base Completion",
    author = "Li, Xiang  and
      Taheri, Aynaz  and
      Tu, Lifu  and
      Gimpel, Kevin",
    editor = "Erk, Katrin  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P16-1137",
    doi = "10.18653/v1/P16-1137",
    pages = "1445--1455",
}
@inproceedings{rajpurkar-etal-2016-squad,
    title = "{SQ}u{AD}: 100,000+ Questions for Machine Comprehension of Text",
    author = "Rajpurkar, Pranav  and
      Zhang, Jian  and
      Lopyrev, Konstantin  and
      Liang, Percy",
    editor = "Su, Jian  and
      Duh, Kevin  and
      Carreras, Xavier",
    booktitle = "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2016",
    address = "Austin, Texas",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D16-1264",
    doi = "10.18653/v1/D16-1264",
    pages = "2383--2392",
}

@article{diederik2014adam,
  title={Adam: A method for stochastic optimization},
  author={Diederik, P Kingma},
  journal={(No Title)},
  year={2014}
}

@article{bhattamishra2023understanding,
  title={Understanding in-context learning in transformers and llms by learning to learn discrete functions},
  author={Bhattamishra, Satwik and Patel, Arkil and Blunsom, Phil and Kanade, Varun},
  journal={arXiv preprint arXiv:2310.03016},
  year={2023}
}

@article{wu2023many,
  title={How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?},
  author={Wu, Jingfeng and Zou, Difan and Chen, Zixiang and Braverman, Vladimir and Gu, Quanquan and Bartlett, Peter L},
  journal={arXiv preprint arXiv:2310.08391},
  year={2023}
}

@article{raventos2024pretraining,
  title={Pretraining task diversity and the emergence of non-bayesian in-context learning for regression},
  author={Ravent{\'o}s, Allan and Paul, Mansheej and Chen, Feng and Ganguli, Surya},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{bai2024transformers,
  title={Transformers as statisticians: Provable in-context learning with in-context algorithm selection},
  author={Bai, Yu and Chen, Fan and Wang, Huan and Xiong, Caiming and Mei, Song},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@article{xie2021explanation,
  title={An explanation of in-context learning as implicit bayesian inference},
  author={Xie, Sang Michael and Raghunathan, Aditi and Liang, Percy and Ma, Tengyu},
  journal={arXiv preprint arXiv:2111.02080},
  year={2021}
}

@article{dong2022survey,
  title={A survey on in-context learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Ma, Jingyuan and Li, Rui and Xia, Heming and Xu, Jingjing and Wu, Zhiyong and Liu, Tianyu and others},
  journal={arXiv preprint arXiv:2301.00234},
  year={2022}
}

@article{fu2023transformers,
  title={Transformers learn higher-order optimization methods for in-context learning: A study with linear models},
  author={Fu, Deqing and Chen, Tian-Qi and Jia, Robin and Sharan, Vatsal},
  journal={arXiv preprint arXiv:2310.17086},
  year={2023}
}

@article{mahankali2023one,
  title={One step of gradient descent is provably the optimal in-context learner with one layer of linear self-attention},
  author={Mahankali, Arvind and Hashimoto, Tatsunori B and Ma, Tengyu},
  journal={arXiv preprint arXiv:2307.03576},
  year={2023}
}

@article{ahn2023transformers,
  title={Transformers learn to implement preconditioned gradient descent for in-context learning},
  author={Ahn, Kwangjun and Cheng, Xiang and Daneshmand, Hadi and Sra, Suvrit},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={45614--45650},
  year={2023}
}


@article{panwar2023context,
  title={In-context learning through the bayesian prism},
  author={Panwar, Madhur and Ahuja, Kabir and Goyal, Navin},
  journal={arXiv preprint arXiv:2306.04891},
  year={2023}
}

@article{zhang2023and,
  title={What and how does in-context learning learn? bayesian model averaging, parameterization, and generalization},
  author={Zhang, Yufeng and Zhang, Fengzhuo and Yang, Zhuoran and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2305.19420},
  year={2023}
}

@incollection{naim:asher:2024a,
  title={On Explaining with Attention Matrices},
  author={Naim, Omar and Asher, Nicholas},
  booktitle={ECAI 2024},
  pages={1035--1042},
  year={2024},
  publisher={IOS Press}
}
@unpublished{naim:asher:2024b,
  title={Re-examining learning linear functions in context},
  author={Naim, Omar and Asher, Nicholas},
  note={arXiv:2411.11465 [cs.LG]},
year = {2024}
}

@article{daubechies:etal:2022,
  title={Nonlinear approximation and (deep) ReLU networks},
  author={Daubechies, Ingrid and DeVore, Ronald and Foucart, Simon and Hanin, Boris and Petrova, Guergana},
  journal={Constructive Approximation},
  volume={55},
  number={1},
  pages={127--172},
  year={2022},
  publisher={Springer}
}
@article{wang2022interpretability,
  title={Interpretability in the wild: a circuit for indirect object identification in gpt-2 small},
  author={Wang, Kevin and Variengien, Alexandre and Conmy, Arthur and Shlegeris, Buck and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2211.00593},
  year={2022}
}

@article{nanda2023progress,
  title={Progress measures for grokking via mechanistic interpretability},
  author={Nanda, Neel and Chan, Lawrence and Lieberum, Tom and Smith, Jess and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2301.05217},
  year={2023}
}
@article{devore:1998,
  title={Nonlinear approximation},
  author={DeVore, Ronald A},
  journal={Acta numerica},
  volume={7},
  pages={51--150},
  year={1998},
  publisher={Cambridge University Press}
}

