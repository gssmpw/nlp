\section{Overview of  Techniques}
\label{outline:intro|>contributions|>techniques}

The proof of the convergence of the BIHT approximations for any GLM satisfying \ASSUMPTION \ref{assumption:p} adapts the following approach.
%taken in \cite{matsumoto2022binary} to show convergence in the noiseless setting.
It consists of two primary bounds on the approximation error:
%|>>|×××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××|>>|
\Enum[{\label{enum:contributions:1:a}}]{a}
a deterministic bound that relates the approximation error to an {\em invertibility condition} satisfied by Gaussian matrices, and
%×××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××
\Enum[{\label{enum:contributions:1:b}}]{b}
a probabilistic bound that describes this invertibility condition for Gaussian matrices.
%|<<|×××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××|<<|
The former of these bounds, \ref{enum:contributions:1:a}, is relatively straightforward to establish using standard techniques, including %the triangle inequality and
bounding of a recurrence relation.
On the other hand, the derivation of the latter bound, \ref{enum:contributions:1:b}, which is the primary technical contribution of this work, entails extensive analysis that constitutes the majority of this manuscript.
The establishment of the  invertibility condition for Gaussian covariate matrices in regard to this latter bound follows a similar approach to  \cite{matsumoto2022binary} (i.e., the noiseless case) to prove an analogous invertibility condition for Gaussian matrices therein, though there are some major technical differences, which are highlighted in \APPENDIX \ref{outline:intro|>contributions|>comparison-biht}.
%though there are differences in some technicalities.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\par %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%The following discussion offers some intuition
%%for
%behind
The intuition behind the argument for the probabilistic bound, \ref{enum:contributions:1:b}, is as follows.
The aforementioned invertibility condition (see Theorem~\ref{thm:main-technical:sparse}) upper bounds
%|>>|===========================================================================================|>>|
\begin{gather}
\label{eqn:contributions:1}
  \left\|
    \thetaStar
    -
    \frac{\thetaXXX}{\| \thetaXXX \|_{2}}
  \right\|_{2}
,\end{gather}
%|<<|===========================================================================================|<<|
where
%|>>|===========================================================================================|>>|
\(
    \thetaXXX
    \defeq
    \thetaXX + \hfFn[\JCoords]( \thetaStar, \thetaXX )
,\)
%|<<|===========================================================================================|<<|
uniformly for every \(  \thetaXX \in \ParamSpace  \) and every \(  \JCoords \subseteq [\n]  \), \(  | \JCoords | \leq \k  \), and for a particular random function, \(  \hfFn[\JCoords] : \R^{\n} \times \R^{\n} \to \R^{\n}  \), parameterized by the coordinate subset, \(  \JCoords  \), and dependent on the covariate matrix, \(  \CovM  \).
The specification of the function, \(  \hfFn[\JCoords]  \), which is determined by the GLM function \(  \fFn  \), is deferred to \SECTION 
\ref{outline:main-result|outline-of-pf} as this informal overview can be understood without its formal definition.
One can view an upper bound on the quantity of \EQUATION \eqref{eqn:contributions:1} to be a {\em single-step progress} towards estimating \(\thetaStar\) via the BIHT algorithm.
One
%critical
salient
%feature
characteristic
of the invertibility condition is that
%, much like the invertibility conditions of \cite{friedlander2021nbiht,matsumoto2022binary}, 
stronger guarantees are provided for points, \(  \thetaXX  \), which are closer to \(  \thetaStar  \).
The invertibility condition will be proved to hold for Gaussian covariate matrices with high probability.
Towards this, the quantity in \EQUATION \eqref{eqn:contributions:1} will be shown to describe a notion of deviation of the random vector \(  \thetaXXX  \) around its mean in the sense that
%|>>|===========================================================================================|>>|
%\begin{gather}
%\label{eqn:contributions:2}
\(
  \left\|
    \thetaStar
    -
    \frac{\thetaXXX}{\| \thetaXXX \|_{2}}
  \right\|_{2}
  =
  \left\|
    \frac{\thetaXXX}{\| \thetaXXX \|_{2}}
    -
    \frac{\E[ \thetaXXX ]}{\| \E[ \thetaXXX ] \|_{2}}
  \right\|_{2}
.\) %\end{gather}
%|<<|===========================================================================================|<<|
Furthermore, it can be shown that this deviation is roughly proportional to the deviation of the random function \(  \hfFn[\JCoords]  \) around its mean:
%|>>|===========================================================================================|>>|
\begin{gather}
\label{eqn:contributions:2b}
%  \left\|
%    \thetaStar
%    -
%    \frac{\thetaXXX}{\| \thetaXXX \|_{2}}
%  \right\|_{2}
%  =
  \left\|
    \frac{\thetaXXX}{\| \thetaXXX \|_{2}}
    -
    \frac{\E[ \thetaXXX ]}{\| \E[ \thetaXXX ] \|_{2}}
  \right\|_{2}
  \propto
  \| \hfFn[\JCoords]( \thetaStar, \thetaXX ) - \E[ \hfFn[\JCoords]( \thetaStar, \thetaXX ) ] \|_{2}
.\end{gather}
%|<<|===========================================================================================|<<|
%\MARK{As a brief aside, hidden from the \RHS of \EQUATION \eqref{eqn:contributions:2b} is a scaling term that can be calculated fairly directly. However, it is omitted above for simplicity as the following discussion will focus only on the deviation term shown on the \RHS of \eqref{eqn:contributions:2b}, whose characterization is significantly more technically challenging.}
The deviation of \(  \hfFn[\JCoords]  \) is then decomposed into (and upper bounded by) three components of deviation:
%|>>|×××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××|>>|
\Enum[{\label{enum:contributions:2:i}}]{i}
a global component for each point in a cover over the parameter space, \(  \ParamSpace  \), that is sufficiently far from \(  \thetaStar  \);
%×××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××
\Enum[{\label{enum:contributions:2:iii}}]{ii}
a local component for each point in the cover and every point in a small region surrounding it; and
%×××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××
\Enum[{\label{enum:contributions:2:ii}}]{iii}
a component which arises from the randomness of the GLM---specifically, through the function \(  \fFn  \).
%|<<|×××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××××|<<|
Upper bounds on the first and third components, \ref{enum:contributions:2:i} and \ref{enum:contributions:2:ii}, can be established  following Gaussian concentration.
Meanwhile, the second component, \ref{enum:contributions:2:iii}, relies on the local binary embeddings of \cite{oymak2015near}.
%Note that the prior works, \cite{friedlander2021nbiht,matsumoto2022binary}, also use these local binary embeddings for their convergence analysis of BIHT.
%The first, \ref{enum:contributions:2:i}, and second, \ref{enum:contributions:2:iii}, components work together to establish a global property for the cover over the parameter space, \(  \ParamSpace  \), and to then extend this property uniformly over the entire parameter space by showing that it does not change too much over small, local regions.

Notably, the two components, \ref{enum:contributions:2:i} and \ref{enum:contributions:2:iii}, do not depend on the random function \(  \fFn  \): they replace the random function \(  \fFn  \) with the deterministic \(  \Sign  \) function.
Thus, the third component, \ref{enum:contributions:2:ii}, entirely captures the deviation associated with the randomness induced by \(  \fFn  \).
The upper bounding of all three components exploits the statistical ``niceness'' of the Gaussian covariates.
%In particular, for the first, \ref{enum:contributions:2:i}, and third, \ref{enum:contributions:2:iii}, components, the angular uniformity of \iid Gaussian random vectors is crucial because
In particular, for the first component, \ref{enum:contributions:2:i}, the angular uniformity of \iid Gaussian random vectors is crucial because
%this property
it
controls the number of covariates involved in the computation of the random function, \(  \hfFn[\JCoords]  \). 
\begin{comment}
when evaluated at a given pair of points: roughly speaking, with high probability, the number of covariates is proportional to the angular distance between the pair of points.
As a consequence of this, the random function, \(  \hfFn[\JCoords]  \), is better-controlled---%
%has smaller central absolute moments%
has lower variance%
---when evaluated at pairs of points that are closer together, giving rise to stronger guarantees there,
%for such points.
which is necessary for the invertibility condition to hold.
\end{comment}
However, this breaks down when points are too close together as the number of samples involved in the computation of \(  \hfFn[\JCoords]  \) cannot be guaranteed to further decrease beyond a certain threshold (a distance on the order of \(  \epsilonX  \)).
%Hence, the control over the randomness of \(  \hfFn[\JCoords]  \) will no longer decay.
Once this occurs, the local guarantees provided by the local binary embeddings of \cite{oymak2015near} take over through \ref{enum:contributions:2:iii} to ensure that the randomness of \(  \hfFn[\JCoords]  \) is well-controlled to provide sufficient guarantees within these local regions.
%sufficient conditions on \(  \hfFn[\JCoords]  \) in these small regions.
The (sub)gaussianity of the covariates is also critical for bounding the third component of deviation, \ref{enum:contributions:2:ii}, though not
%specifically
strictly
through angular uniformity.
In effect, it limits the amount of deviation that can be introduced by the randomness of the GLM, which comes from standard knowledge.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\par %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
Taking a step back to examine the relationship between this invertibility condition and the convergence of BIHT, there are a couple key ideas underlying the behavior exhibited by the algorithm.
First, the last two components of deviation, \ref{enum:contributions:2:iii} and \ref{enum:contributions:2:ii},
%captured by the invertibility condition,
introduce error to the algorithm's approximations which is more or less ``baked in'' once the model and its covariates are fixed---that is, these contributions to the approximation error will not decay as the algorithm continues to iterate.
%``baked into'' the model once the model and its covariates are fixed---that is, these contributions to the approximation error will not decay as the algorithm continues to iterate.
In contrast, the first component of deviation, \ref{enum:contributions:2:i}, contributes error into the approximation which indeed decays.
Simply put, this is the consequence of the invertibility condition imposing a stronger bound for points which are closer to the true parameter, \(  \thetaStar  \).
%In essence, since the number of covariates involved in the evaluation of \(  \hfFn[\JCoords]  \) at a pair of points---and hence also the variance of \(  \hfFn[\JCoords]  \)---
In essence, since the number of covariates---and hence also the variance---involved in the evaluation of \(  \hfFn[\JCoords]  \) at a pair of points
decreases as the distance between the points decreases, the improvement of the approximation in one iteration of BIHT leads to even better control over \(  \hfFn[\JCoords]  \), and thus a better approximation, in the next iteration.
%The improvement of each approximation enables a better approximation in the subsequent iteration of BIHT.
However, because the invertibility condition only guarantees this improvement up to but not within small, local regions, the error cannot be guaranteed to reduce once the approximations reach the \(  \epsilonX  \)-ball around \(  \thetaStar  \).
At the same time, the error will remain within a small threshold due to the local result, \ie \ref{enum:contributions:2:iii}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

