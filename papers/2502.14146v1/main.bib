@inproceedings{gupta2019better,
  title={Better algorithms for stochastic bandits with adversarial corruptions},
  author={Gupta, Anupam and Koren, Tomer and Talwar, Kunal},
  booktitle={Conference on Learning Theory},
  pages={1562--1578},
  year={2019},
  organization={PMLR}
}

@article{lai1985asymptotically,
  title={Asymptotically efficient adaptive allocation rules},
  author={Lai, Tze Leung and Robbins, Herbert and others},
  journal={Advances in applied mathematics},
  volume={6},
  number={1},
  pages={4--22},
  year={1985}
}

@article{auer2002finite,
  title={Finite-time analysis of the multiarmed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Fischer, Paul},
  journal={Machine learning},
  volume={47},
  pages={235--256},
  year={2002},
  publisher={Springer}
}

@article{even2006action,
  title={Action Elimination and Stopping Conditions for the Multi-Armed Bandit and Reinforcement Learning Problems.},
  author={Even-Dar, Eyal and Mannor, Shie and Mansour, Yishay and Mahadevan, Sridhar},
  journal={Journal of machine learning research},
  volume={7},
  number={6},
  year={2006}
}

@article{bubeck2012regret,
  title={Regret analysis of stochastic and nonstochastic multi-armed bandit problems},
  author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={5},
  number={1},
  pages={1--122},
  year={2012},
  publisher={Now Publishers, Inc.}
}

@article{agrawal2017near,
  title={Near-optimal regret bounds for thompson sampling},
  author={Agrawal, Shipra and Goyal, Navin},
  journal={Journal of the ACM (JACM)},
  volume={64},
  number={5},
  pages={1--24},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@inproceedings{lykouris2018stochastic,
  title={Stochastic bandits robust to adversarial corruptions},
  author={Lykouris, Thodoris and Mirrokni, Vahab and Paes Leme, Renato},
  booktitle={Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing},
  pages={114--122},
  year={2018}
}

@article{denisov2020regret,
  title={Regret Analysis of a Markov Policy Gradient Algorithm for Multiarm Bandits},
  author={Walton, Neil and Denisov, Denis},
  journal={Mathematics of Operations Research},
  volume={48},
  number={3},
  pages={1553--1588},
  year={2023},
  publisher={INFORMS}
}

@article{kapoor2019corruption,
  title={Corruption-tolerant bandit learning},
  author={Kapoor, Sayash and Patel, Kumar Kshitij and Kar, Purushottam},
  journal={Machine Learning},
  volume={108},
  number={4},
  pages={687--715},
  year={2019},
  publisher={Springer}
}

@article{he2022nearly,
  title={Nearly optimal algorithms for linear contextual bandits with adversarial corruptions},
  author={He, Jiafan and Zhou, Dongruo and Zhang, Tong and Gu, Quanquan},
  journal={arXiv preprint arXiv:2205.06811},
  year={2022}
}

@article{liu2021cooperative,
  title={Cooperative stochastic multi-agent multi-armed bandits robust to adversarial corruptions},
  author={Liu, Junyan and Li, Shuai and Li, Dapeng},
  journal={arXiv preprint arXiv:2106.04207},
  year={2021}
}

@inproceedings{xu2021simple,
  title={Simple combinatorial algorithms for combinatorial bandits: corruptions and approximations},
  author={Xu, Haike and Li, Jian},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={1444--1454},
  year={2021},
  organization={PMLR}
}

@article{jin2020simultaneously,
  title={Simultaneously learning stochastic and adversarial episodic mdps with known transition},
  author={Jin, Tiancheng and Luo, Haipeng},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={16557--16566},
  year={2020}
}

@inproceedings{zhong2021probabilistic,
  title={Probabilistic sequential shrinking: A best arm identification algorithm for stochastic bandits with corruptions},
  author={Zhong, Zixin and Cheung, Wang Chi and Tan, Vincent},
  booktitle={International Conference on Machine Learning},
  pages={12772--12781},
  year={2021},
  organization={PMLR}
}

@article{slivkins2019introduction,
  title={Introduction to multi-armed bandits},
  author={Slivkins, Aleksandrs and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={12},
  number={1-2},
  pages={1--286},
  year={2019},
  publisher={Now Publishers, Inc.}
}

@book{meyn2012markov,
  title={Markov chains and stochastic stability},
  author={Meyn, Sean P and Tweedie, Richard L},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@article{zimmert2021tsallis,
  title={Tsallis-inf: An optimal algorithm for stochastic and adversarial bandits},
  author={Zimmert, Julian and Seldin, Yevgeny},
  journal={The Journal of Machine Learning Research},
  volume={22},
  number={1},
  pages={1310--1358},
  year={2021},
  publisher={JMLRORG}
}

@article{auer2002nonstochastic,
  title={The nonstochastic multiarmed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Freund, Yoav and Schapire, Robert E},
  journal={SIAM journal on computing},
  volume={32},
  number={1},
  pages={48--77},
  year={2002},
  publisher={SIAM}
}

@inproceedings{bubeck2012best,
  title={The best of both worlds: Stochastic and adversarial bandits},
  author={Bubeck, S{\'e}bastien and Slivkins, Aleksandrs},
  booktitle={Conference on Learning Theory},
  pages={42--1},
  year={2012},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{Pacchiano2022BestOB,
  title={Best of Both Worlds Model Selection},
  author={Aldo Pacchiano and Christoph Dann and Claudio Gentile},
  journal={ArXiv},
  year={2022},
  volume={abs/2206.14912},
  url={https://api.semanticscholar.org/CorpusID:250144854}
}

@inproceedings{honda2023follow,
  title={Follow-the-Perturbed-Leader Achieves Best-of-Both-Worlds for Bandit Problems},
  author={Honda, Junya and Ito, Shinji and Tsuchiya, Taira},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={726--754},
  year={2023},
  organization={PMLR}
}

@article{neu2016importance,
  title={Importance weighting without importance weights: An efficient algorithm for combinatorial semi-bandits},
  author={Neu, Gergely and G{\'a}bor, Bart{\'o}k},
  year={2016},
  publisher={Microtome Publishing}
}

@inproceedings{huang2022adaptive,
  title={Adaptive best-of-both-worlds algorithm for heavy-tailed multi-armed bandits},
  author={Huang, Jiatai and Dai, Yan and Huang, Longbo},
  booktitle={International Conference on Machine Learning},
  pages={9173--9200},
  year={2022},
  organization={PMLR}
}

@inproceedings{rejwan2020top,
  title={Top-$ k $ combinatorial bandits with full-bandit feedback},
  author={Rejwan, Idan and Mansour, Yishay},
  booktitle={Algorithmic Learning Theory},
  pages={752--776},
  year={2020},
  organization={PMLR}
}

@article{jin2021best,
  title={The best of both worlds: stochastic and adversarial episodic mdps with unknown transition},
  author={Jin, Tiancheng and Huang, Longbo and Luo, Haipeng},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={20491--20502},
  year={2021}
}

@inproceedings{sun2023revisiting,
  title={Revisiting sampling for combinatorial optimization},
  author={Sun, Haoran and Goshvadi, Katayoon and Nova, Azade and Schuurmans, Dale and Dai, Hanjun},
  booktitle={International Conference on Machine Learning},
  pages={32859--32874},
  year={2023},
  organization={PMLR}
}

@article{ma2019sampling,
  title={Sampling can be faster than optimization},
  author={Ma, Yi-An and Chen, Yuansi and Jin, Chi and Flammarion, Nicolas and Jordan, Michael I},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={42},
  pages={20881--20885},
  year={2019},
  publisher={National Acad Sciences}
}

@inproceedings{audibert2009minimax,
  title={Minimax Policies for Adversarial and Stochastic Bandits.},
  author={Audibert, Jean-Yves and Bubeck, S{\'e}bastien and others},
  booktitle={COLT},
  volume={7},
  pages={1--122},
  year={2009}
}

@article{zimmert2019connections,
  title={Connections between mirror descent, Thompson sampling and the information ratio},
  author={Zimmert, Julian and Lattimore, Tor},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{zimin2013online,
  title={Online learning in episodic Markovian decision processes by relative entropy policy search},
  author={Zimin, Alexander and Neu, Gergely},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}

@article{kalai2005efficient,
  title={Efficient algorithms for online decision problems},
  author={Kalai, Adam and Vempala, Santosh},
  journal={Journal of Computer and System Sciences},
  volume={71},
  number={3},
  pages={291--307},
  year={2005},
  publisher={Elsevier}
}

@article{abernethy2015fighting,
  title={Fighting bandits with a new kind of smoothness},
  author={Abernethy, Jacob D and Lee, Chansoo and Tewari, Ambuj},
  journal={Advances in Neural Information Processing Systems},
  volume={28},
  year={2015}
}

@article{chen2023dynamic,
  title={Dynamic Estimation Over Distributed Sensing Network With Communication Delays},
  author={Chen, Gang and Zhou, Yaoyao},
  journal={IEEE Transactions on Industrial Informatics},
  year={2023},
  publisher={IEEE}
}

@inproceedings{duanyi2023constructing,
  title={Constructing Adversarial Examples for Vertical Federated Learning: Optimal Client Corruption through Multi-Armed Bandit},
  author={Duanyi, YAO and Li, Songze and Ye, XUE and Liu, Jin},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

