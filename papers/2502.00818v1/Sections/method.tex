\section{Error-quantified conformal inference}

\subsection{Error quantification via smoothing feedback}
\vspace{-0.25em}
\label{ECI}

The online conformal inference framework developed by \citet{aci_gibbs2021adaptive} adopts the online learning technique to learn the thresholds $\{q_t\}_{t\geq 1}$ based on previously observed data.
Let $s_t = S(X_t, Y_t)$ and $\ell_t(q) = (s_t-q)(\mathds{1}\{s_t > q\}-\alpha)$ denotes the $(1-\alpha)$-th quantile loss.
When the label $Y_t$ is revealed, we can perform online (sub)gradient descent (OGD) as
\begin{equation}
\begin{aligned}
q_{t+1} =q_t-\eta\ \nabla \ell_t(q_t)= q_t+\eta(\mathrm{err}_t-\alpha), 
\label{quantile tracking}
\end{aligned}
\end{equation}
where $\text{err}_t=\mathds{1}\{s_t>q_t\} = \mathds{1}\{Y_t\not\in \hat{C}_t(X_t)\}$ is the miscoverage indicator and $\eta$ is the learning rate. The subgradient $\mathrm{err}_t-\alpha$ can be regarded as the feedback after observing label $Y_t$: if $\hat{C}_t(X_t)$ does not cover $Y_t$ (i.e., $\mathrm{err}_t=1$), OGD will increase the threshold to construct a more liberal prediction set in the next step; otherwise, OGD will construct a more conservative prediction set. In fact, ACI uses the same idea but updates the confidence level of the prediction set instead. Notice that the enrolled average of history feedback $\sum_{t=1}^T(\mathrm{err}_t-\alpha)/T$ is exactly the averaged miscoverage  we aim to control in \Cref{limit1}. Essentially, the long-term coverage guarantee of OGD or ACI comes from the equivalence between feedback and control.

However, subgradients of quantile loss $\ell_t$ can only take two values $1-\alpha$ and $-\alpha$, regarding the feedback value of coverage ($s_t \leq q_t$) and miscoverage ($s_t > q_t$) respectively. As a consequence, the feedback keeps the same value no matter how severe the miscoverage is or how conservative the coverage is. In other words, discrete feedback value does not exploit the information of the error. 

To address this issue, we consider smoothing the feedback when updating the thresholds. Let $f(x) \in [0,1]$ be a smooth approximation to the indicator $\mathds{1}(x>0)$, such as Sigmoid function, Gaussian error function, etc. Then we can approximate the quantile loss $\ell_t(q)$ via $\tilde{\ell}_t(q) = (f(s_t - q)-\alpha)(s_t-q)$. This smoothing technique was demonstrated in previous studies \citep{kaplan2017smoothed,fernandes2021smoothing}.
Applying OGD on the smoothed quantile loss $\{\tilde{\ell}_t(q)\}_{t\geq 1}$, we have the following fully smoothed update rule
\begin{equation}
    \label{eq:full_smoothed_rule}
\begin{aligned}
q_{t+1} &= q_t - \eta \nabla \tilde{\ell}_t(q_t)= q_t + \eta\cdot \big[f(s_t-q_t)-\alpha+(s_t-q_t) \nabla f(s_t-q_t)\big].
\end{aligned}
\end{equation}
Here we called $(s_t-q_t) \nabla f(s_t-q_t)$ as the \emph{error quantification} (EQ) term, which provides additional feedback based on the magnitude of error $s_t-q_t$.

To have a preliminary view of the effect of EQ term, we take Sigmoid function $f(x)=\frac{1}{1+\exp{(-cx)}}$ as an example, and show the curve of EQ function $x \nabla f(x)$ in \Cref{EQ_function_plot}. Firstly, the feedback from the EQ term has the same sign as subgradient $\mathrm{err}_t - \alpha$ by letting $x = s_t-q_t$, which means that it does not deviate from the direction of update in OGD. 
On the other hand, when $s_t$ significantly deviates from the current threshold $q_t$ (for example, an abrupt change point appears at time $t$), the EQ term tends to decrease as $s_t - q_t$ grows. This is to prevent the subsequent prediction sets from running out of control due to a single anomaly data point.

\begin{figure*}[h]
  \centering
  \includegraphics[width=0.65\textwidth]{figures/EQ_function_plot.pdf}
  \vspace{-0.6em}
  \caption{Dynamics of the EQ function across variable $x$, where $f(x)$ is Sigmoid function and $c=1$.}
  \label{EQ_function_plot}
  \vspace{-0.5em}
\end{figure*}
\vspace{-0.5em}
However, \Cref{eq:full_smoothed_rule} may introduce extra bias during the derivation process, as detailed in \Cref{explanations for extra bias}.
If we perform the fully smoothed update rule \eqref{eq:full_smoothed_rule}, we cannot directly control the averaged miscoverage gap $\sum_{t=1}^T\mathrm{err}_t/T -\alpha$ due to the smoothing bias.

Hence we keep the EQ term and replace $f(s_t-q_t)$ in \Cref{eq:full_smoothed_rule} with the miscoverage indicator $\operatorname{err}_t$, that is
\begin{equation}
    q_{t+1} = q_t + \eta \cdot \big[\text{err}_t - \alpha+  (s_t-q_t) \nabla f(s_t-q_t)\big].
    \label{ECI update}
\end{equation}
Formally, we propose \textit{Error-quantified Conformal Inference} (ECI) based on \eqref{ECI update}, which leverages the miscoverage indicator and the EQ term simultaneously to update thresholds with partially smoothed feedback.
Compared with OGD in \Cref{quantile tracking}, the feedback from EQ term is compensation over the original subgradient $\operatorname{err}_t -\alpha$. Clearly, for the same pair $(s_t, q_t)$, ECI can provide more feedback compared with OGD and fully smoothed rule in \Cref{eq:full_smoothed_rule}. We provide an ablation study in \Cref{full-smoothed way} to illustrate the importance of the EQ term.

%The main difference between \eqref{ECI update} and \eqref{quantile tracking} is that our method not only considers whether miscovering or not at the last time, but also aims to quantify the extent of miscoverage and conservativeness through $(s_t-q_t)\ \nabla f(s_t-q_t)$. 


%Essentially, this is the online subgradient descent. The subgradient of $ \rho_{1-\alpha}$ at 0 take any value in $ [-\alpha,1-\alpha]$ and these work set the subgradient as 0. 

%Since $\rho_{1-\alpha}$ is non-differentiable at 0, previous methods actually considers the subgradient, which makes $\nabla\rho_{1-\alpha}$ take any value in $[-\alpha,1-\alpha]$ at 0.  However, even though all the iterative points are differentiable (i.e. not 0), the subgradient descent with fixed stepsize will oscillate around the optimal point instead of converging. It's because $q_{t+1}-q_t$ is concrete, either $-\eta \alpha $ or $\eta(1-\alpha)$ and that's why ACI often returns trivial confidence interval. 


%Compared with \eqref{eq:full_smoothed_rule}, \eqref{half-smoothed-grad} keeps the actual value of indicator function $\text{err}_t$, and avoids the bias between smooth function $f(s_t-q)$ and $\mathds{1}(s_t>q)$.  

% Given a step size $\eta>0$, our online update is as follow:
% \begin{equation}
%     q_{t+1} = q_t + \eta \cdot \big[\text{err}_t - \alpha+  (s_t-q_t) \nabla f(s_t-q_t)\big].
%     \label{ECI update}
% \end{equation}

%\eqref{ECI update} includes not only the simple binary measure by an indicator function, but also error quantification  $(s_t-q) \nabla f(s_t-q)$. For convenience,  We call $(s_t-q) \nabla f(s_t-q)$  error quantification (EQ) term.

%If $f(x)=\min\{|cx+\frac{1}{2}|,1\}, $  $\nabla f \in \{c,0\}$, i.e. the added term is truncated linear to $x$. 





\subsection{Extended versions}
\vspace{-0.25em}
\textbf{ECI-cutoff.}
The EQ term reacts quickly to sudden distribution shifts like changepoints. However, when $q_t$ is slightly larger/smaller than $s_t$, the additional adjustment provided by the EQ term may lead to under/over coverage of prediction sets. For example, if $s_t \textcolor{blue}{<} q_t$ and $s_{t+1} \in \left[q_t-\eta_t\alpha+\eta_t(s_t-q_t) \nabla f(s_t-q_t) ,q_t-\eta_t \alpha \right]$, then adding the EQ term will cause miscoverage, i.e. $s_{t+1}>q_{t+1}$. Therefore, we introduce a cutoff to our added term: 
\begin{equation}
    q_{t+1} = q_t + \eta \cdot \bigg[(\text{err}_t - \alpha) + (s_t-q_t)\ \nabla f(s_t-q_t) \mathds{1}(|s_t-q_t| > h_t)\bigg],
    \label{ECI-cutoff update}
\end{equation}
where $h_t=h\max_{t-w\leq i,j \leq t}|s_i-s_j|$, and $h$ is a pre-determined threshold, $w$ is window length.

\textbf{ECI-integral.}
More information input generally means better performance. Note that \eqref{ECI update} only takes the information of one last timestep into consideration. A natural alternative is to integrate the error of more than a single step. Therefore, we propose the extended update:
\begin{equation}
    q_{t+1} = q_t + \eta \cdot \sum_{i=1}^t w_i\bigg\{\text{err}_i - \alpha+ (s_i-q_i)\ \nabla f(s_i-q_i)\bigg\},
    \label{ECI-integral update}
\end{equation}
where $\{w_i\}_{1\leq i\leq t}\subseteq[0,1]\text{ is a sequence of increasing weights with }\sum_{i=1}^tw_i=1.$
Equation \eqref{ECI-integral  update} evaluates the recent empirical miscoverage frequency and degree of miscovery when deciding whether or not to lower or raise $q_t$, making coverage more stable. 
%In practice, the weights can be $w_i:=\frac{0.95^{t-i}}{\sum_{j=1}^t0.95^{t-j}}$.
% \begin{equation}
% w_i:=\frac{0.95^{t-i}}{\sum_{j=1}^t0.95^{t-j}}.
% \label{weight_integral}
% \end{equation}



\subsection{Distribution-free coverage guarantees}
\vspace{-0.25em}
In this section, we outline the theoretical coverage guarantees of ECI. The detailed proofs are deferred in \Cref{proof}.  We first present two assumptions and briefly explain their feasibility. 

\begin{assumption}
    \label{assumption1}
     For any $t \in \mathbb{N_+}$, there exists $B>0$  such that $s_t \in [0,B]$.
    %and $\lim_{T \to \infty} \frac{\sum_{t=1}^T |s_t-s_{t+1}|}{T}=0$

\end{assumption}
\begin{assumption}
    \label{assumption2}
   $|x\nabla f(x)|\leq \lambda$ and $|\nabla f(x)|\leq c$ for any $x \in \mathbbm{R}$, where $\lambda, c>0$ are constants. 
\end{assumption}
\Cref{assumption1} assumes boundedness of scores, which is ubiquitous in online conformal literature \citep{aci_gibbs2021adaptive,pid_angelopoulos2024conformal,angelopoulos2024online}. For \Cref{assumption2}, note that a typical choice of $f$ is the Sigmoid function $\sigma(cx)$ with a scale parameter $c>0$. Then $$|\nabla f(x)|=c \cdot |\sigma(cx)(1-\sigma(cx))|\leq \frac{c}{4},$$
$$|x \nabla f(x)|=|cx\sigma(cx)(1-\sigma(cx))|<|cx \frac{e^{cx}}{1+e^{cx}}|<|cxe^{cx}|\leq\frac{1}{e}.$$  Thus \Cref{assumption2} is naturally satisfied. Moreover, if we consider ECI-cutoff and replace $\nabla f(x)$ by  $\nabla f_{h}(x)=\nabla f(x)\mathds{1}(|x|>h)$, then $$|\nabla f_h(x)|=c \cdot |\sigma(cx)(1-\sigma(cx))|\mathds{1}(|x|>h)<\frac{c}{1+e^{ch}},$$ 
which can be sufficiently small as long as we set $c$ to be large.\\

The following theorem provides a dynamic miscoverage bound when the learning rate is fixed. We prove it by showing that every miscoverage step will be followed by at least $N-1$ coverage step, where $N=\lfloor \alpha^{-1} \rfloor$, that is if $Y_t \notin \hat{C}_t$ happens, then $Y_{t+i} \in \hat{C}_{t+i}$ holds for $i=1,2,\cdots, N-1$.
\begin{theorem}
\label{theorem1}
    Assume that $\eta>2NB$, $c<\frac{\min\{\eta,N^2\}}{2N^2\left[B+(1-\alpha+\lambda)\eta\right]}$, where $N=\lfloor \frac{1}{\alpha} \rfloor$. Under \Cref{assumption1,assumption2}, the prediction sets generated by \eqref{ECI update} satisfies for any $T$,
    \begin{equation}
    \label{finite-sample coverage}
        \frac{1}{N}\sum_{t=T+1}^{T+N} \mathds{1}\{Y_t \notin \hat{C}_t\}\leq \frac{1}{N}.
    \end{equation}
\end{theorem}
As standard choices for $\alpha$ are $\{0.01,0.05,0.1,0.2\}$, if we further assume $\alpha=N^{-1}$ for some $N \in \mathbbm{N}$, it follows from \eqref{finite-sample coverage} that $\frac{1}{N}\sum_{t=T+1}^{T+N} \mathds{1}\{Y_t \notin \hat{C}_t\}\leq \alpha$ for any $T$, which immediately yields the long-term coverage guarantee in \Cref{limit1}.


We present the bound of averaged miscoverage error under adaptive learning rates. The result is also distribution-free and only needs a proper choice of learning rate sequence.
\begin{theorem}
\label{theorem2}
  Let $\{\eta_t\}_{t \geq 1}$ be an arbitrary positive sequence. Under \Cref{assumption1,assumption2},  the prediction sets generated by \eqref{ECI update} with adaptive learning rate $\eta_t$ satisfies:

\begin{equation}
    \bigg|\frac{1}{T} \sum_{t=1}^T (\text{err}_t-\alpha) \bigg|  \leq  \frac{(B+M_{T-1})\|\Delta_{1:T}\|_1}{T} +c \left[B+(1-\alpha+\lambda)M_{T-1}\right],
\end{equation}

where $\|\Delta_{1:T}\|_1=|\eta_1^{-1}|+\sum_{t=2}^T|\eta_t^{-1}-\eta_{t-1}^{-1}|, M_T = \max_{1\leq r \leq T}\eta_r$.
\end{theorem}
For the first term, following the analysis in \cite{angelopoulos2024online}, if the learning rate decreases over extended periods when the distribution appears stable, but then increases again, in a repetitive manner, $\|\Delta_{1:T}\|_1/T$ can be sufficiently small. To be specific, $\|\Delta_{1:T}\|_1\leq 2N_t/(\min_{t\leq T} \eta_t)$, where $N_T=\sum_{t=1}^T \mathds{1}\{\eta_{t+1}>\eta_{t}\}$ denotes the number of times the learning rate is increased. Hence, if $\eta_t$ does not decay
too quickly and the number of “resets” $N_T$ is $o(T)$ , the first term in the upper bound in \eqref{theorem2} will be within an acceptable range. For the second term, if we set $c$  as a sufficiently small value, then the second term is also limited to a small value. 






