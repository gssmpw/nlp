\section{Background and problem setup}
\vspace{-0.5em}
\subsection{Conformal inference}
\vspace{-0.5em}
Let $\hat{f}:\gX \to \gY$ be a prediction model trained on an independent training set. Given labeled data $\{(X_i,Y_i)\}_{i\leq n} \subset \gX \times \gY$ and test data $X_{n+1} \in \gX$, the objective is to construct a confidence set for the unknown label $Y_{n+1}$. To determine whether the candidate value $y$ is a reasonable estimate of $Y_{n+1}$, we define a non-conformity score function 
$S(\cdot,\cdot): \gX \times \gY \to \sR$. For example, in the regression task, we may take absolute residual score, scaled residual score \citep{lei2018distribution}, and conformalized quantile regression score \citep{romano2019conformalized}.
Generally, $S(X_i, Y_i)$ depends on the base model $\hat{f}$ and measures how well the prediction value $\hat{f}(X_i)$ conforms the true label $Y_i$.
Given the nominal level $\alpha \in (0,1)$, split conformal prediction \citep{papadopoulos2002inductive,lei2018distribution} outputs the prediction set $\hat{C}(X_{n+1})=\{y\in \gY: S(X_{n+1},y)\leq s\}$, where the threshold $s$ is the $\lceil(1-\alpha)(n+1)\rceil\text{-th smallest value among }\{S(X_i,Y_i)\}_{i=1}^n$. If $\{(X_i,Y_i)\}_{i=1}^{n+1}$ are exchangeable, we have the finite-sample coverage guarantee $\mathbbm{P}\{Y_{n+1} \in \hat{C}(X_{n+1})\}\geq 1-\alpha$.

In practice, split conformal prediction divides the labeled data into a training set for fitting the predictive model and a calibration set for computing non-conformity scores. There are other variants of conformal inference to better utilize the labeled data, like full conformal \citep{vovk2005algorithmic}, Jackknife+ \citep{barber2021predictive}. In many scenarios, data may exhibit a distribution shift and thus are no longer exchangeable. \citet{chernozhukov2018exact} extend conformal inference to ergodic cases with dependent data, but needs transformations of data to be a strong mixing series. \citet{oliveira2024split} study split conformal prediction for non-exchangeable data relying on some distributional assumptions.
We refer to \cite{tibshirani2019conformal}, \cite{podkopaev2021distribution}, \cite{barber2023conformal} and \cite{yang2024doubly} for more development dealing with non-exchangeable data.


 
\subsection{Conformal inference for sequential data}
\vspace{-0.5em}
Recently, significant efforts have been made to extend conformal inference to online schemes. \cite{aci_gibbs2021adaptive} proposed ACI which models the distribution shift in time series as a learning problem in a single parameter whose optimal value varies over time. Based on ACI, several works \citep{gibbs2024conformal,zaffran2022adaptive,bhatnagar2023improved,podkopaevadaptive,angelopoulos2024online,yang2024bellman} used online learning techniques to adaptively adjust the size of the prediction set based on recent observations. \citet{gibbs2024conformal} and \citet{bhatnagar2023improved} utilized meta-learning approaches to aggregate the results updated with multiple learning rates or experts, where main algorithms were adapted from \citet{gradu2023adaptive} and \citet{jun2017improved} respectively. In addition, \citet{podkopaevadaptive} extended the betting technique in \citet{orabona2016coin} to the conformal setting and proposed a new parameter-free algorithm. The methods mentioned above can achieve a long-term coverage guarantee without any assumptions about the data-generating process. \citet{xu2021conformal,xu2023conformal} casted the problem of constructing a conformal prediction set as predicting the quantile of a future residual and propose algorithms to adaptively re-estimate (conditional) quantiles. However, these methods are constrained by model and distribution assumptions and potentially suffer from over-fitting problems. \citet{weinstein2020online} and \citet{bao2024cap} investigated online selective conformal inference problem for i.i.d. data stream.


Closely related to our work is the Conformal PID algorithm of \cite{pid_angelopoulos2024conformal}, which simplifies and strengthens existing analyses in online conformal inference with ideas from control theory. Our algorithm differs from theirs by replacing the integration and scorecasting with the EQ term, and is thus able to yield significantly tighter prediction sets with valid coverage. A more detailed description of the competing methods is included in the \Cref{More details on existing methods}.


\subsection{Problem setup}
\vspace{-0.5em}
Suppose the time series data $\{(X_t,Y_t)\}_{t\geq 1} \subset \gX\times \gY$ are collected sequentially. At time $t$, our goal is to construct a prediction set $\hat{C}_t(X_t)$ for the unseen label $Y_t$ based on the machine learning model trained on previously observed data $\{(X_i,Y_i)\}_{i\leq t}$. 
Aligned with the standard conformal inference methods, we use a non-conformity score function $S_t(\cdot,\cdot): \mathcal{X}\times \mathcal{Y} \to \mathbbm{R}$ that may change over time. For example, in the regression task, $S_t(x,y) = |y-\hat{f}_t(x)|$ with the base model $\hat{f}_t$ trained at time $t$. Then we construct the conformal prediction set by
\begin{align}\label{eq:online_PI}
    \hat{C}_t(X_t)=\{y \in \mathcal{Y}: S_t(X_t,y) \leq q_t\},
\end{align}
where $q_t$ is the threshold that estimates or approximates $(1-\alpha)$-th quantile for the distribution of the non-conformity score $S_t(X_t, Y_t)$.

Note that if the data sequence $\{(X_i,Y_i)\}_{i\leq t+1}$ are i.i.d. or exchangeable, according to the split conformal prediction, taking $q_t$ in \Cref{eq:online_PI} to be the $(1-\alpha)(1+t^{-1})$-th sample quantile of $\{S_i(X_i,Y_i)\}_{i\leq t}$ yields a valid coverage guarantee $\sP\{Y_{t+1} \in \hat{C}_{t+1}(X_{t+1})\}\geq 1-\alpha$. However, in an adversarial setting where exchangeability does not hold, such as time series data with strong correlations or distribution shifts, it is very difficult to achieve such a real-time coverage guarantee. Recent works \citep{bhatnagar2023improved,angelopoulos2023prediction,angelopoulos2024online,podkopaevadaptive} began to consider the following long-term miscoverage control:
\begin{equation}
    \lim_{T \to \infty} \frac{1}{T}\sum_{t=1}^T\mathds{1}\{ Y_t \notin \hat{C}_t(X_t)\}=\alpha.
    \label{limit1}
\end{equation}
Hence, our primary target is to design an online algorithm to dynamically choose thresholds $\{q_t\}_{t\geq 1}$ that can achieve the control in \eqref{limit1} without any distributional assumptions about data.
