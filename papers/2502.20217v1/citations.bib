@inproceedings{isler_information_2016,
	location = {Stockholm, Sweden},
	title = {An information gain formulation for active volumetric 3D reconstruction},
	isbn = {978-1-4673-8026-3},
	url = {http://ieeexplore.ieee.org/document/7487527/},
	doi = {10.1109/ICRA.2016.7487527},
	eventtitle = {2016 {IEEE} International Conference on Robotics and Automation ({ICRA})},
	pages = {3477--3484},
	booktitle = {2016 {IEEE} International Conference on Robotics and Automation ({ICRA})},
	publisher = {{IEEE}},
	author = {Isler, Stefan and Sabzevari, Reza and Delmerico, Jeffrey and Scaramuzza, Davide},
	urldate = {2024-09-11},
	date = {2016-05},
    year = {2016},
}

@article{petracek_large-scale_2021,
	title = {Large-Scale Exploration of Cave Environments by Unmanned Aerial Vehicles},
	volume = {6},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {2377-3766, 2377-3774},
	url = {https://ieeexplore.ieee.org/document/9492802/},
	doi = {10.1109/LRA.2021.3098304},
	pages = {7596--7603},
	number = {4},
    year = {2021},
	journaltitle = {{IEEE} Robotics and Automation Letters},
	shortjournal = {{IEEE} Robot. Autom. Lett.},
	author = {Petracek, Pavel and Kratky, Vit and Petrlik, Matej and Baca, Tomas and Kratochvil, Radim and Saska, Martin},
	urldate = {2024-09-11},
	date = {2021-10},
	file = {Submitted Version:/Users/jimmychiun/Zotero/storage/AHWDZTSY/Petracek et al. - 2021 - Large-Scale Exploration of Cave Environments by Unmanned Aerial Vehicles.pdf:application/pdf},
}

@inproceedings{kleiner_rfid_2006,
	location = {Beijing, China},
	title = {{RFID} Technology-based Exploration and {SLAM} for Search And Rescue},
	isbn = {978-1-4244-0258-8 978-1-4244-0259-5},
	url = {http://ieeexplore.ieee.org/document/4059043/},
	doi = {10.1109/IROS.2006.281867},
    year = {2006},
	eventtitle = {2006 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems},
	pages = {4054--4059},
	booktitle = {2006 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems},
	publisher = {{IEEE}},
	author = {Kleiner, Alexander and Prediger, Johann and Nebel, Bernhard},
	urldate = {2024-09-11},
	date = {2006-10},
	file = {Full Text:/Users/jimmychiun/Zotero/storage/5AXMAJ6Z/Kleiner et al. - 2006 - RFID Technology-based Exploration and SLAM for Search And Rescue.pdf:application/pdf},
}

@ARTICLE{Zhou_2023,
  author={Zhou, Boyu and Xu, Hao and Shen, Shaojie},
  journal={IEEE Transactions on Robotics}, 
  title={RACER: Rapid Collaborative Exploration With a Decentralized Multi-UAV System}, 
  year={2023},
  volume={39},
  number={3},
  pages={1816-1835},
  keywords={Robots;Robot kinematics;Collaboration;Quadrotors;Task analysis;Resource management;Multi-robot systems;Aerial system;aerial systems;applications;cooperating robots;perception and autonomy},
  doi={10.1109/TRO.2023.3236945}}

@INPROCEEDINGS{yamauchi_1997,
  author={Yamauchi, B.},
  booktitle={Proceedings 1997 IEEE International Symposium on Computational Intelligence in Robotics and Automation CIRA'97. 'Towards New Computational Principles for Robotics and Automation'}, 
  title={A frontier-based approach for autonomous exploration}, 
  year={1997},
  volume={},
  number={},
  pages={146-151},
  keywords={Mobile robots;Orbital robotics;Sonar navigation;Artificial intelligence;Laboratories;Testing;Humans;Indoor environments;Space exploration},
  doi={10.1109/CIRA.1997.613851}}

@INPROCEEDINGS{Burgard_2000,
  author={Burgard, W. and Moors, M. and Fox, D. and Simmons, R. and Thrun, S.},
  booktitle={Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065)}, 
  title={Collaborative multi-robot exploration}, 
  year={2000},
  volume={1},
  number={},
  pages={476-481 vol.1},
  keywords={Collaboration;Robot kinematics;Robot sensing systems;Computer science;Costs;Mobile robots;Multirobot systems;Testing;Traveling salesman problems;Redundancy},
  doi={10.1109/ROBOT.2000.844100}}

@INPROCEEDINGS{Bircher_2016,
  author={Bircher, Andreas and Kamel, Mina and Alexis, Kostas and Oleynikova, Helen and Siegwart, Roland},
  booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Receding Horizon "Next-Best-View" Planner for 3D Exploration}, 
  year={2016},
  volume={},
  number={},
  pages={1462-1468},
  keywords={Vehicles;Robot sensing systems;Space exploration;Planning;Navigation;Three-dimensional displays},
  doi={10.1109/ICRA.2016.7487281}}

@INPROCEEDINGS{ariadne_2023,
  author={Cao, Yuhong and Hou, Tianxiang and Wang, Yizhuo and Yi, Xian and Sartoretti, Guillaume},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={ARiADNE: A Reinforcement learning approach using Attention-based Deep Networks for Exploration}, 
  year={2023},
  volume={},
  number={},
  pages={10219-10225},
  keywords={Deep learning;Solid modeling;Three-dimensional displays;Reinforcement learning;Robot sensing systems;Sensor systems;Real-time systems},
  doi={10.1109/ICRA48891.2023.10160565}}

@inproceedings{holz2010evaluating,
  title={Evaluating the efficiency of frontier-based exploration strategies},
  author={Holz, Dirk and Basilico, Nicola and Amigoni, Francesco and Behnke, Sven},
  booktitle={ISR 2010 (41st International Symposium on Robotics) and ROBOTIK 2010 (6th German Conference on Robotics)},
  pages={1--8},
  year={2010},
  organization={VDE}
}

@inproceedings{kulich2011distance,
  title={On distance utility in the exploration task},
  author={Kulich, Miroslav and Faigl, Jan and P{\v{r}}eu{\v{c}}il, Libor},
  booktitle={2011 IEEE International Conference on Robotics and Automation},
  pages={4455--4460},
  year={2011},
  organization={IEEE}
}

@article{dang2020graph,
  title={Graph-based subterranean exploration path planning using aerial and legged robots},
  author={Dang, Tung and Tranzatto, Marco and Khattak, Shehryar and Mascarich, Frank and Alexis, Kostas and Hutter, Marco},
  journal={Journal of Field Robotics},
  volume={37},
  number={8},
  pages={1363--1388},
  year={2020},
  publisher={Wiley Online Library}
}

@article{xu2021autonomous,
  title={Autonomous UAV exploration of dynamic environments via incremental sampling and probabilistic roadmap},
  author={Xu, Zhefan and Deng, Di and Shimada, Kenji},
  journal={IEEE Robotics and Automation Letters},
  volume={6},
  number={2},
  pages={2729--2736},
  year={2021},
  publisher={IEEE}
}

@inproceedings{Yamauchi_nearest_1998,
author = {Yamauchi, Brian},
title = {Frontier-based exploration using multiple robots},
year = {1998},
isbn = {0897919831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/280765.280773},
doi = {10.1145/280765.280773},
booktitle = {Proceedings of the Second International Conference on Autonomous Agents},
pages = {47–53},
numpages = {7},
keywords = {multi-robot teams, multi-agent coordination, mobile robots, map-building, exploration},
location = {Minneapolis, Minnesota, USA},
series = {AGENTS '98}
}

@InProceedings{chao_maans_2022,
author="Yu, Chao
and Yang, Xinyi
and Gao, Jiaxuan
and Yang, Huazhong
and Wang, Yu
and Wu, Yi",
title="Learning Efficient Multi-agent Cooperative Visual Exploration",
booktitle="Computer Vision -- ECCV 2022",
year="2022",
publisher="Springer Nature Switzerland",
address="Cham",
pages="497--515",
abstract="We tackle the problem of cooperative visual exploration where multiple agents need to jointly explore unseen regions as fast as possible based on visual signals. Classical planning-based methods often suffer from expensive computation overhead at each step and a limited expressiveness of complex cooperation strategy. By contrast, reinforcement learning (RL) has recently become a popular paradigm for tackling this challenge due to its modeling capability of arbitrarily complex strategies and minimal inference overhead. In this paper, we propose a novel RL-based multi-agent planning module, Multi-agent Spatial Planner (MSP). MSP leverages a transformer-based architecture, Spatial-TeamFormer, which effectively captures spatial relations and intra-agent interactions via hierarchical spatial self-attentions. In addition, we also implement a few multi-agent enhancements to process local information from each agent for an aligned spatial representation and more precise planning. Finally, we perform policy distillation to extract a meta policy to significantly improve the generalization capability of final policy. We call this overall solution, Multi-Agent Active Neural SLAM (MAANS). MAANS substantially outperforms classical planning-based baselines for the first time in a photo-realistic 3D simulator, Habitat. Code and videos can be found at https://sites.google.com/view/maans.",
isbn="978-3-031-19842-7"
}

@article{julia_comparison_2012,
	title = {A comparison of path planning strategies for autonomous exploration and mapping of unknown environments},
	volume = {33},
	rights = {http://www.springer.com/tdm},
	issn = {0929-5593, 1573-7527},
	url = {http://link.springer.com/10.1007/s10514-012-9298-8},
	doi = {10.1007/s10514-012-9298-8},
	pages = {427--444},
	number = {4},
	journaltitle = {Autonomous Robots},
	shortjournal = {Auton Robot},
	author = {Juliá, Miguel and Gil, Arturo and Reinoso, Oscar},
	urldate = {2024-09-12},
	date = {2012-11},
    year = {2012},
	langid = {english},
}

@INPROCEEDINGS{yu_apf_2021,
  author={Yu, Jincheng and Tong, Jianming and Xu, Yuanfan and Xu, Zhilin and Dong, Haolin and Yang, Tianxiang and Wang, Yu},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={SMMR-Explore: SubMap-based Multi-Robot Exploration System with Multi-robot Multi-target Potential Field Exploration Method}, 
  year={2021},
  volume={},
  number={},
  pages={8779-8785},
  keywords={Costs;Simultaneous localization and mapping;Conferences;Distributed databases;Collaboration;Robot sensing systems;Boosting},
  doi={10.1109/ICRA48506.2021.9561328}}

@Inbook{Nazif2011,
    author="Nazif, Ali Nasri and Davoodi, Alireza and Pasquier, Philippe",
    title="Multi-Agent Area Coverage Using a Single Query Roadmap: A Swarm Intelligence Approach",
    bookTitle="Advances in Practical Multi-Agent Systems",
    year="2011",
    pages="95--112",
    abstract="This paper proposes a mechanism for visually covering an area by means of a group of homogeneous reactive agents through a single-query roadmap called Weighted Multi-Agent RRT, WMA-RRT. While the agents do not know about the environment, the roadmap is locally available to them. In accordance with the swarm intelligence principles, the agents are simple autonomous entities, capable of interacting with the environment by obeying some explicit rules and performing the corresponding actions. The interaction between the agents is carried out through an indirect communication mechanism and leads to the emergence of complex behaviors such as multi-agent cooperation and coordination, path planning and environment exploration. This mechanism is reliable in the face of agent failures and can be effectively and easily employed in cluttered environments containing narrow passages. We have implemented and evaluated the algorithm in different domains and the experimental results confirm the performance and robustness of the system.",
    isbn="978-3-642-16098-1",
    doi="10.1007/978-3-642-16098-1_7",
}

@ARTICLE{hu_voronoi_2020,
  author={Hu, Junyan and Niu, Hanlin and Carrasco, Joaquin and Lennox, Barry and Arvin, Farshad},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={Voronoi-Based Multi-Robot Autonomous Exploration in Unknown Environments via Deep Reinforcement Learning}, 
  year={2020},
  volume={69},
  number={12},
  pages={14413-14423},
  keywords={Collision avoidance;Robot kinematics;Reinforcement learning;Robot sensing systems;Mobile robots;Navigation;Autonomous exploration;path planning;deep reinforcement learning;multi-vehicle systems;collision avoidance},
  doi={10.1109/TVT.2020.3034800}}

@article{niroui2019deep,
  title={Deep reinforcement learning robot for search and rescue applications: Exploration in unknown cluttered environments},
  author={Niroui, Farzad and Zhang, Kaicheng and Kashino, Zendai and Nejat, Goldie},
  journal={IEEE Robotics and Automation Letters},
  volume={4},
  number={2},
  pages={610--617},
  year={2019},
  publisher={IEEE}
}

@inproceedings{zhu2018deep,
  title={Deep reinforcement learning supervised autonomous exploration in office environments},
  author={Zhu, Delong and Li, Tingguang and Ho, Danny and Wang, Chaoqun and Meng, Max Q-H},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={7548--7555},
  year={2018},
  organization={IEEE}
}

@article{li2019deep,
  title={Deep reinforcement learning-based automatic exploration for navigation in unknown environment},
  author={Li, Haoran and Zhang, Qichao and Zhao, Dongbin},
  journal={IEEE transactions on neural networks and learning systems},
  volume={31},
  number={6},
  pages={2064--2076},
  year={2019},
  publisher={IEEE}
}

@INPROCEEDINGS{Mousavian_2019,
  author={Mousavian, Arsalan and Toshev, Alexander and Fišer, Marek and Košecká, Jana and Wahid, Ayzaan and Davidson, James},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)}, 
  title={Visual Representations for Semantic Target Driven Navigation}, 
  year={2019},
  volume={},
  number={},
  pages={8846-8852},
  keywords={Navigation;Visualization;Semantics;Training;Adaptation models;Robots;Task analysis},
  doi={10.1109/ICRA.2019.8793493}}

@INPROCEEDINGS{Henriques_2018,
  author={Henriques, Joao F. and Vedaldi, Andrea},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={MapNet: An Allocentric Spatial Memory for Mapping Environments}, 
  year={2018},
  volume={},
  number={},
  pages={8476-8484},
  keywords={Simultaneous localization and mapping;Cameras;Navigation;Streaming media;Three-dimensional displays;Task analysis;Geometry},
  doi={10.1109/CVPR.2018.00884}}

@inproceedings{chaplot2020learning,
  title={Learning To Explore Using Active Neural SLAM},
  author={Chaplot, Devendra Singh and Gandhi, Dhiraj and Gupta,
          Saurabh and Gupta, Abhinav and Salakhutdinov, Ruslan},
  booktitle={International Conference on 
             Learning Representations (ICLR)},
  year={2020}}

@article{gronauer_multi-agent_2022,
	title = {Multi-agent deep reinforcement learning: a survey},
	volume = {55},
	issn = {0269-2821, 1573-7462},
	url = {https://link.springer.com/10.1007/s10462-021-09996-w},
	doi = {10.1007/s10462-021-09996-w},
	shorttitle = {Multi-agent deep reinforcement learning},
	abstract = {Abstract
            The advances in reinforcement learning have recorded sublime success in various domains. Although the multi-agent domain has been overshadowed by its single-agent counterpart during this progress, multi-agent reinforcement learning gains rapid traction, and the latest accomplishments address problems with real-world complexity. This article provides an overview of the current developments in the field of multi-agent deep reinforcement learning. We focus primarily on literature from recent years that combines deep reinforcement learning methods with a multi-agent scenario. To survey the works that constitute the contemporary landscape, the main contents are divided into three parts. First, we analyze the structure of training schemes that are applied to train multiple agents. Second, we consider the emergent patterns of agent behavior in cooperative, competitive and mixed scenarios. Third, we systematically enumerate challenges that exclusively arise in the multi-agent domain and review methods that are leveraged to cope with these challenges. To conclude this survey, we discuss advances, identify trends, and outline possible directions for future work in this research area.},
	pages = {895--943},
	number = {2},
	journaltitle = {Artificial Intelligence Review},
	shortjournal = {Artif Intell Rev},
	author = {Gronauer, Sven and Diepold, Klaus},
	urldate = {2024-09-12},
	date = {2022-02},
    year = {2022},
	langid = {english},
	file = {Full Text:/Users/jimmychiun/Zotero/storage/VU3A5MFP/Gronauer and Diepold - 2022 - Multi-agent deep reinforcement learning a survey.pdf:application/pdf},
}

@inproceedings{Sunehag_2018, author = {Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vinicius and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z. and Tuyls, Karl and Graepel, Thore}, title = {Value-Decomposition Networks For Cooperative Multi-Agent Learning Based On Team Reward}, year = {2018}, publisher = {International Foundation for Autonomous Agents and Multiagent Systems}, address = {Richland, SC}, abstract = {We study the problem of cooperative multi-agent reinforcement learning with a single joint reward signal. This class of learning problems is difficult because of the often large combined action and observation spaces. In the fully centralized and decentralized approaches, we find the problem of spurious rewards and a phenomenon we call the "lazy agent'' problem, which arises due to partial observability. We address these problems by training individual agents with a novel value-decomposition network architecture, which learns to decompose the team value function into agent-wise value functions.}, booktitle = {Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems}, pages = {2085–2087}, numpages = {3}, keywords = {collaborative, dqn, multi-agent, neural networks, q-learning, reinforcement learning, value-decomposition}, location = {Stockholm, Sweden}, series = {AAMAS '18} }


@InProceedings{pmlr-v139-liu21j,
  title = 	 {Cooperative Exploration for Multi-Agent Deep Reinforcement Learning},
  author =       {Liu, Iou-Jen and Jain, Unnat and Yeh, Raymond A and Schwing, Alexander},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {6826--6836},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/liu21j/liu21j.pdf},
  url = 	 {https://proceedings.mlr.press/v139/liu21j.html},
  abstract = 	 {Exploration is critical for good results in deep reinforcement learning and has attracted much attention. However, existing multi-agent deep reinforcement learning algorithms still use mostly noise-based techniques. Very recently, exploration methods that consider cooperation among multiple agents have been developed. However, existing methods suffer from a common challenge: agents struggle to identify states that are worth exploring, and hardly coordinate exploration efforts toward those states. To address this shortcoming, in this paper, we propose cooperative multi-agent exploration (CMAE): agents share a common goal while exploring. The goal is selected from multiple projected state spaces by a normalized entropy-based technique. Then, agents are trained to reach the goal in a coordinated manner. We demonstrate that CMAE consistently outperforms baselines on various tasks, including a sparse-reward version of multiple-particle environment (MPE) and the Starcraft multi-agent challenge (SMAC).}
}

@misc{iqbal2021,
      title={Coordinated Exploration via Intrinsic Rewards for Multi-Agent Reinforcement Learning}, 
      author={Shariq Iqbal and Fei Sha},
      year={2021},
      eprint={1905.12127},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1905.12127}, 
}

@inproceedings{epciclr2020,
  author = {Qian Long and Zihan Zhou and Abhinav Gupta and Fei Fang and Yi Wu and Xiaolong Wang},
  title = {Evolutionary Population Curriculum for Scaling Multi-Agent Reinforcement Learning},
  booktitle = {International Conference on Learning Representations},
  year = {2020}
}

@article{wang_few_2020,
	title = {From Few to More: Large-Scale Dynamic Multiagent Curriculum Learning},
	volume = {34},
	rights = {https://www.aaai.org},
	issn = {2374-3468, 2159-5399},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/6221},
	doi = {10.1609/aaai.v34i05.6221},
	shorttitle = {From Few to More},
	abstract = {A lot of efforts have been devoted to investigating how agents can learn effectively and achieve coordination in multiagent systems. However, it is still challenging in large-scale multiagent settings due to the complex dynamics between the environment and agents and the explosion of state-action space. In this paper, we design a novel Dynamic Multiagent Curriculum Learning ({DyMA}-{CL}) to solve large-scale problems by starting from learning on a multiagent scenario with a small size and progressively increasing the number of agents. We propose three transfer mechanisms across curricula to accelerate the learning process. Moreover, due to the fact that the state dimension varies across curricula, and existing network structures cannot be applied in such a transfer setting since their network input sizes are fixed. Therefore, we design a novel network structure called Dynamic Agent-number Network ({DyAN}) to handle the dynamic size of the network input. Experimental results show that {DyMA}-{CL} using {DyAN} greatly improves the performance of large-scale multiagent learning compared with state-of-the-art deep reinforcement learning approaches. We also investigate the influence of three transfer mechanisms across curricula through extensive simulations.},
	pages = {7293--7300},
	number = {5},
	journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
	shortjournal = {{AAAI}},
	author = {Wang, Weixun and Yang, Tianpei and Liu, Yong and Hao, Jianye and Hao, Xiaotian and Hu, Yujing and Chen, Yingfeng and Fan, Changjie and Gao, Yang},
	urldate = {2024-09-12},
	date = {2020-04-03},
    year = {2020},
}

@misc{wakilpoor2020,
      title={Heterogeneous Multi-Agent Reinforcement Learning for Unknown Environment Mapping}, 
      author={Ceyer Wakilpoor and Patrick J. Martin and Carrie Rebhuhn and Amanda Vu},
      year={2020},
      eprint={2010.02663},
      archivePrefix={arXiv},
      primaryClass={cs.MA},
      url={https://arxiv.org/abs/2010.02663}, 
}


@InProceedings{pmlr-v97-iqbal19a,
  title = 	 {Actor-Attention-Critic for Multi-Agent Reinforcement Learning},
  author =       {Iqbal, Shariq and Sha, Fei},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {2961--2970},
  year = 	 {2019},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/iqbal19a/iqbal19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/iqbal19a.html},
  abstract = 	 {Reinforcement learning in multi-agent scenarios is important for real-world applications but presents challenges beyond those seen in single-agent settings. We present an actor-critic algorithm that trains decentralized policies in multi-agent settings, using centrally computed critics that share an attention mechanism which selects relevant information for each agent at every timestep. This attention mechanism enables more effective and scalable learning in complex multi-agent environments, when compared to recent approaches. Our approach is applicable not only to cooperative settings with shared rewards, but also individualized reward settings, including adversarial settings, as well as settings that do not provide global states, and it makes no assumptions about the action spaces of the agents. As such, it is flexible enough to be applied to most multi-agent learning problems.}
}

@ARTICLE{placed_2023,
  author={Placed, Julio A. and Strader, Jared and Carrillo, Henry and Atanasov, Nikolay and Indelman, Vadim and Carlone, Luca and Castellanos, José A.},
  journal={IEEE Transactions on Robotics}, 
  title={A Survey on Active Simultaneous Localization and Mapping: State of the Art and New Frontiers}, 
  year={2023},
  volume={39},
  number={3},
  pages={1686-1705},
  keywords={Simultaneous localization and mapping;Robots;Location awareness;Planning;Robot kinematics;Navigation;Uncertainty;Active perception;active simultaneous localization and mapping (SLAM);autonomous robotic exploration;belief-space planning (BSP);deep reinforcement learning (DRL);next best view;optimality criteria},
  doi={10.1109/TRO.2023.3248510}}


@InProceedings{pmlr-v229-liang23a,
  title = 	 {Context-Aware Deep Reinforcement Learning for Autonomous Robotic Navigation in Unknown Area},
  author =       {Liang, Jingsong and Wang, Zhichen and Cao, Yuhong and Chiun, Jimmy and Zhang, Mengqi and Sartoretti, Guillaume Adrien},
  booktitle = 	 {Proceedings of The 7th Conference on Robot Learning},
  pages = 	 {1425--1436},
  year = 	 {2023},
  volume = 	 {229},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--09 Nov},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v229/liang23a/liang23a.pdf},
  url = 	 {https://proceedings.mlr.press/v229/liang23a.html},
  abstract = 	 {Mapless navigation refers to a challenging task where a mobile robot must rapidly navigate to a predefined destination using its partial knowledge of the environment, which is updated online along the way, instead of a prior map of the environment. Inspired by the recent developments in deep reinforcement learning (DRL), we propose a learning-based framework for mapless navigation, which employs a context-aware policy network to achieve efficient decision-making (i.e., maximize the likelihood of finding the shortest route towards the target destination), especially in complex and large-scale environments. Specifically, our robot learns to form a context of its belief over the entire known area, which it uses to reason about long-term efficiency and sequence show-term movements. Additionally, we propose a graph rarefaction algorithm to enable more efficient decision-making in large-scale applications. We empirically demonstrate that our approach reduces average travel time by up to $61.4%$ and average planning time by up to $88.2%$ compared to benchmark planners (D*lite and BIT) on hundreds of test scenarios. We also validate our approach both in high-fidelity Gazebo simulations as well as on hardware, highlighting its promising applicability in the real world without further training/tuning.}
}

@inproceedings{wangviper_2024,
  title={ViPER: Visibility-based Pursuit-Evasion via Reinforcement Learning},
  author={Wang, Yizhuo and Cao, Yuhong and Chiun, Jimmy and Koley, Subhadeep and Pham, Mandy and Sartoretti, Guillaume Adrien},
  booktitle={8th Annual Conference on Robot Learning},
  year={2024},
}

@misc{christodoulou2019sac,
      title={Soft Actor-Critic for Discrete Action Settings}, 
      author={Petros Christodoulou},
      year={2019},
      eprint={1910.07207},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1910.07207}, 
}

@INPROCEEDINGS{chiun2024star,
  author={Chiun, Jimmy and Tan, Yan Rui and Cao, Yuhong and Tan, John and Sartoretti, Guillaume},
  booktitle={2024 24th International Conference on Control, Automation and Systems (ICCAS)}, 
  title={STAR: Swarm Technology for Aerial Robotics Research}, 
  year={2024},
  volume={},
  number={},
  pages={141-146},
  keywords={Location awareness;System performance;Stars;Swarm robotics;Object detection;Motion capture;Peer-to-peer computing;Maintenance;Collision avoidance;Robots;Aerial Robotics;Micro UAV;Landmark Localization;Robotic Application},
  doi={10.23919/ICCAS63016.2024.10773308}}

@ARTICLE{cao_large_24,
  author={Cao, Yuhong and Zhao, Rui and Wang, Yizhuo and Xiang, Bairan and Sartoretti, Guillaume},
  journal={IEEE Robotics and Automation Letters}, 
  title={Deep Reinforcement Learning-Based Large-Scale Robot Exploration}, 
  year={2024},
  volume={9},
  number={5},
  pages={4631-4638},
  keywords={Robots;Training;Planning;Predictive models;Simultaneous localization and mapping;Trajectory;Three-dimensional displays;View Planning for SLAM;reinforcement learning;motion and path planning},
  doi={10.1109/LRA.2024.3379804}}










