\begin{figure}[t]
	\begin{center}
		% \vspace{-0.2cm}
		\includegraphics[width=.5\textwidth]{AL_pics/dilation.pdf}
	\end{center}
	\vspace{-0.3cm}
	\caption{Point dilation operation. The point cloud is first projected onto a 2D binary occupancy grid and then dilated with a structural element. The new feature map covers many areas that were not occupied by the original point cloud, especially the region where the target box is located (blue box). The feature at the center position is of great interest to the detector.}
	\label{fig4}
	\vspace{-0.3cm}
\end{figure}

The point-wise receptive field is still limited to the space occupied by the original point cloud until \ref{sec:backbone}. In order to expand the learning scope of the model, we propose the Point Dilation Mechanism, which consists of two steps: point dilation and feature filling.

\textbf{Point Dilation (PD)}. Dilation (usually represented by $\oplus$) is one of the basic operations in mathematical morphology. Image dilation is a commonly used morphological processing algorithm in the field of image processing, which utilizes a structuring element to probe and expand the shapes present in the input image, aiming to connect connected regions or eliminate noise \cite{wu2010morphological}. Our PD method borrows the idea of image dilation to achieve spatial expansion. Specifically, for $F_4^p$ obtained from \ref{sec:backbone}, we use Eq. \ref{eq6} to sparsely project it onto a grid, resulting in $F_4^g$.
\begin{equation}
	\label{eq6}
	F_i^g=G(F_i^p, W,H,\epsilon)
\end{equation}
Where $G(\cdot)$ is the projection function, $W$ and $H$ are the width and height of the feature map respectively, and $\epsilon$ is another hyperparameter representing the spatial range of the computed point cloud. It is worth noting that in order to maintain unique indices for the sparse grid, for the sampled points that are projected onto the same grid, we sum their features along the feature dimension to obtain the feature of the current cell. At this point, the feature map is very sparse. We set the occupied cells to 1 and binarize the feature map, and then perform dilation operation:
\begin{equation}
	F_i^g\oplus B=\cup_{b\in B} {F_i^g}_b
\end{equation}
Where $B$ is a structuring element, and we use a $5\times 5$ matrix consisting entirely of 1s. This process is illustrated in Fig. \ref{fig5}, and the dilated binary feature map contains a significant amount of unoccupied space in the original point cloud.

\begin{figure}[t]
	\begin{center}
		% \vspace{-0.2cm}
		\includegraphics[width=.5\textwidth]{AL_pics/ff.pdf}
	\end{center}
	\vspace{-0.3cm}
	\caption{Feature Filling operation. We propose a feature filling method based on spatial separation coefficient. We use point-wise feature learning for Angle Coefficient and Scale Coefficient. The former is achieved by the superposition of spherical harmonics, while the latter is achieved by Gaussian probability density function. The new feature is the weighted sum of the inflated center feature and these two coefficients.}
	\label{fig5}
	\vspace{-0.3cm}
\end{figure}

\textbf{Feature Filling (FF)}. Although PD expands the occupancy space of the feature map, there are no learnable features available on these new cells, which presents a significant challenge in filling the features. We believe that the filled features must adhere to several principles: 1) Learnability: In theory, unoccupied cells and occupied cells should have equal importance in providing information, especially for the position of the target area. We must ensure that these cells have sufficient learning depth and flexibility. 2) Spatial correlation: Previous works such as 3DSSD and IA-SSD have shown that point-wise features at this stage can already regress the rough center position of the target. Therefore, the newly filled features should have a certain correlation with the dilation center to prevent feature fragmentation and preserve the predictive ability of the original dilation center. 3) Cross-correlation: It is evident that multiple dilation centers may affect the features of the same cell. The current cell should have the ability to connect multiple dilation centers to achieve multi-center interaction and learn features with a larger receptive field. To address this, we propose a feature learning method based on spatial separation coefficients. Specifically, we consider the angle and scale aspects and fill the angle and scale influence coefficients for the structuring element $B$. The features of the newly filled cell are then obtained by weighting the dilation center with the separation coefficients. For cells affected by multiple centers, a simple height compression is used to aggregate the features.

\textbf{Angle Coefficient (AC) $\alpha$.} The perception of objects in 3d space by humans or machines is influenced by the observation angle and viewpoint. Taking ray tracing as an example, the color of a certain grid in space varies when observed from different angles. We extend this consensus to feature space, where the features in the surrounding space are related to the angle between them and the expansion center. The conditions of learnability and angle correlation naturally lead us to think of the commonly used spherical harmonics coefficients in simple lighting descriptions.
\begin{equation}
	\label{eq8}
	\nabla^2 f=\frac{1}{r^2}\frac{\partial}{\partial r}(r^2\frac{\partial f}{\partial r}) + \frac{1}{r^2 \sin{\theta}} \frac{\partial}{\partial \theta} (\sin{\theta} \frac{\partial f}{\partial \theta}) + \frac{1}{r^2 \sin{\theta}^2}\frac{\partial^2 f}{\partial \varphi
		^2}=0
\end{equation}
The spherical harmonics are the angular part of the solution to the Laplace equation in spherical coordinates. The Laplace equation in spherical coordinates can be written as Eq. \ref{eq8}. Using the method of separation of variables, we can assume that $f(r,\theta,\varphi)=R(r)Y(\theta,\varphi)=R(r)\Theta(\theta)\Phi(\varphi)$. Here, $Y(\theta,\varphi)$ represents the angular part of the solution, which is also known as the spherical harmonics. More intuitively, the spherical harmonics can also be expressed as:
\begin{equation}
	\label{eq9}
	Y^m_l(\theta,\varphi)=(-1)^m\sqrt{\frac{(2l+1)}{4\pi}\frac{(l-|m|)!}{(l+|m|)!}}P^m_l(\cos{\theta})\exp(im\varphi)
\end{equation}
\begin{equation}
	\label{eq10}
	P^m_l(x)=(1-x^2)^{\frac{|m|}{2}}\frac{d^{|m|}}{dx^{|m|}}P_l(x)
\end{equation}
\begin{equation}
	\label{eq11}
	P_l(x)=\frac{1}{2^l l!}\frac{d^l}{dx^l}(x^2-1)^l
\end{equation}
The spherical harmonic function is only dependent on angles, where $l$ and $m$ are the degree index and order of the associated Legendre polynomial $P^m_l$. In computer graphics, the spherical harmonic function is similar to the Fourier transform in representing lighting. The result is obtained by weighting multiple spherical harmonic coefficients with the basis of spherical harmonic functions. The more spherical harmonic coefficients are used, the stronger the expressive power and the closer it is to the original function. In this method, we treat the dilation center as a sphere and calculate the angular coefficients of the new cell on the structuring element $B$ based on the spherical harmonic coefficients. Specifically, we use a prediction network $SH_\theta(\cdot)$ to regress the 16 spherical harmonic coefficients of the fourth order in $F^g_4$ for each dilation center. Then, the weighted calculation result is used as the angular coefficients of the new cell, as shown in Eq. \ref{eq12}.
\begin{equation}
	\label{eq12}
	\alpha=\sum_{l=0} \sum_{m=-1}^{l+1} c_l^m Y^m_l(\theta,\varphi)
\end{equation}
The input of Eq. \ref{eq12} are the angle between the center point of the newly inflated cell and the center of the cell where the inflation occurs.

\textbf{Scale Coefficient (SC) $\beta$.} As mentioned above, the current point-wise feature $F^g_4$ already contains certain geometric information, so the new cell features around it are scale-dependent on the dilation center. Similar to AC, SC is also reflected by the values filled in the structuring element $B$. Specifically, we use a Gaussian density function to calculate SC, taking the relative position between the dilated new cell and the cell where the dilation center is located, as well as the learned variance, as inputs. The formula is as follows:
\begin{equation}
	\label{eq13}
	\beta= G(x,\mu,\Sigma)
\end{equation}
\begin{equation}
	\label{eq14}
	G(x,\mu,\Sigma)=G(x_1,x_2,\dots,x_D,\mu,\Sigma)=\frac{1}{(2\pi)^{D/2}{\vert\Sigma\vert}^{1/2}} exp(-\frac{1}{2}(x-\mu)^T{\Sigma}^{-1}(x-\mu))
\end{equation}

\begin{figure}[t]
	\begin{center}
		% \vspace{-0.2cm}
		\includegraphics[width=.5\textwidth]{AL_pics/coffiefusion.pdf}
	\end{center}
	\vspace{-0.3cm}
	\caption{(a) Coefficients fusion. In order to maintain the nonlinearity of different cell features, we first decompose the point-wise features and weight them separately using AC and SC. The final feature is the sum of these two parts. (b) Height compression. For cells that are influenced by multiple dilation centers, we directly add their multiple features together, retaining the effect of each dilation center.}
	\label{fig6}
	\vspace{-0.3cm}
\end{figure}

In this method, $G(x, \mu, \Sigma)$ represents independent and identically distributed bivariate Gaussians, where $\mu$ is the position of the inflated center cell and $x$ is the position of the new cell. $\Sigma=\sigma^2E$ is a scaled identity matrix. We also add a scale prediction branch network $S_\theta(\cdot)$ to regress the variance of the inflated center, and then multiply it by a 2D identity matrix $E$ to calculate the final scale coefficient using Eq. \ref{eq13}.

\textbf{Coefficients Fusion.} The new features filled during the dilation process with angle and scale coefficients have a direct linear relationship with the dilation center, which is detrimental to the robustness of deep models. To address this, we adopt a channel-splitting approach for coefficients fusion, as shown in Fig. \ref{fig6} (a). Specifically, we split the point-wise features of the dilation center into two parts in the depth dimension, and multiply them with the angle and scale coefficients respectively. Finally, we sum them up to obtain the new point-wise features. Through this operation, the relationship variables between the new features and the dilation center increase to binary, maintaining the non-linearity of the new features. For cells influenced by multiple dilation centers, we want to preserve the effects of all dilation centers to connect the surrounding features. We achieve this by using a height compression operation as shown in Fig. \ref{fig6} (b), where the effects of all active dilation centers at that location are stacked, reducing the spatial complexity of the training and inference processes. Thus, we obtain a relatively dense 2D feature map.