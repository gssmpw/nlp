\input{PDM_val_car}

\textbf{Note.} Our model is trained in a single-stage multi-class manner. Thanks to the contributions of mmlab \cite{openpcdet2020}, the PDM-SSD model was trained using their open-source OpenPCDet\footnote{\url{https://github.com/open-mmlab/OpenPCDet}} architecture. Additionally, to show respect and fair competition to the authors of the baseline models, we retested their models with our environment on the \textit{val} set, marked as $X^*$. In the following sections, unless otherwise specified, PDM-SSD refers to the results of joint training, PDM-SSD(J).

\input{PDM_val_cyc}

\textbf{Evaluation on KITTI Dataset.} Tables \ref{tabel1} and \ref{tabel2} present the detection performance of PDM-SSD and some state-of-the-art models on \textit{Car} objects in the KITTI \textit{test} and \textit{val} benchmarks. We report their metrics in both 3D and BEV perspectives. In the KITTI benchmark, \textit{Car} objects are divided into three subsets ("Easy," "Moderate," and "Hard") based on difficulty levels. The results on the "Moderate" subset are commonly used as the primary indicator for final ranking. To provide a more intuitive comparison of PDM-SSD's superiority, we categorize the comparative models into three types: point-based, voxel-based, and point-voxel-based, with PDM-SSD belonging to the first category. Table \ref{tabel3} shows the detection results of PDM-SSD on \textit{Cyclist} objects. Table \ref{tabel4} displays the detection metrics of PDM-SSD, IA-SSD, and SPSNet at an IoU threshold of 0.5. Although this threshold is not commonly used for comparing model detection performance, it can reflect the differences in the models' object recall rates.

\input{PDM_val_car_5}

\textbf{Analysis.} It can be seen that: 
1) In the KITTI \textit{test} split, PDM-SSD performs the best among point-based detectors, with significant improvements of $0.58\% mAP$ and $1.17\% mAP$ over IA-SSD and DBQ-SSD, respectively. We believe that this is a result of PDM-SSD addressing the limited receptive field issue (details in \ref{sec:pdm}). 
2) PDM-SSD has advantages over some voxel-based and point-voxel-based detectors, outperforming Fast Point R-CNN by ($3.45\%, 3.47\%, 5.39\%$) and ($2.2\%, 2.08\%, 4.6\%$) in 3D and bev detection with 40 recall points, respectively. This is exciting because high-speed inference capability of 3D detectors is crucial for autonomous vehicles. 
3) As shown in Table \ref{tabel2}, with only the addition of PDM for auxiliary training, PDM-SSD(A) also achieves considerable gains over IA-SSD, with ($2.05\%, 0.37\%, 0.32\%$) improvement in 3D detection with 40 recall points. This indicates that PDM can help point-wise feature learning for more holistic features of objects, further enhancing the model's learning efficiency. 
4) In addition to the \textit{Car} category, PDM-SSD also provides significant assistance in detecting targets in the \textit{Cyclist} category, as shown in Table \ref{tabel3}. It outperforms IA-SSD by a large margin ($4.76\%, 0.64\%, 1.21\%$) with 11 recall points in terms of $AP_{3D}$, and achieves the best performance in the \textit{easy} level. 
5) As shown in Table \ref{tabel4}, when the IoU is 0.5, PDM-SSD outperforms IA-SSD in all metrics. It improves $AP_{3D}$ by $5.97\%$ and $1.95\%$ at 11 and 40 recall points, respectively, mainly due to the improvement in recall rate. This indicates that the complementarity of heatmap to the voting point set is useful, and recall rate is a prerequisite for a good detector performance. 
6) We conducted a Friedman test analysis \cite{jamaludin2022novel} to evaluate the effectiveness of our work. The final results are as follows: The Friedman test rank was conducted for all point-based detectors for all levels in the KITTI test set with $\alpha = 0.05$ and a degree of freedom of $d_f = 6$. The $p$ for $AP$ is $0.011 (\chi^2 = 16.57)$. As a result, PDM-SSD has an average rank of 1, which is the highest compared to other existing methods for $AP_{3D}$.

We visualized the detection results of three scenes in KITTI \textit{val} sets with PDM-SSD in Fig \ref{fig:detectiveresult}. The figures from left to right are respectively: the image and point clouds with predicted boxes, followed by the space covered by the dilated grid, the ground truth of the heatmap representing the covered space in the scene, and the predicted values of the heatmap. It can be observed that after dilation, the model's learnable space range has significantly increased, achieving almost complete coverage of the target area, especially the center position. The predicted heatmap also successfully identifies all the targets, proving the reliability of our learning method, which plays a positive role in complementing the vote points.


