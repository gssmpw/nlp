Let $P=\{p_n\}^N_{n=1}$ be a set of $N$ observed LiDAR points belonging to a scaene, where $p_n \in \mathbb{R}^{3}$ is a 3D point represented with spatial coordinates. Let $C$ be the centers location $C=\{c_m\}^M_{m=1}$ of the annotated ground-truth $M$ bounding boxes, $c_m=[c_{mx},~c_{my},~c_{mz},]\in \mathbb{R}^{3}$.
Due to the limitations of the resolution of the LiDAR, climate conditions, and occlusions, sparse and incomplete targets often appear in the scene, as shown in Fig. \ref{fig3}. Assuming the point cloud $P$ is voxelized into initial pillars $V=\{v_k\}^K_{k=1}$, where $K$ represents the number of pillars. Taking 2D sparse convolution as an example, after learning in the Grid-based detector with the convolutional layers stacked in the backbone network, the feature map can be simplified as:
\begin{equation}
	F^{g}_{i+1}=Pool(Conv(Padding(F^{g}_{i})))
\end{equation}
$i$ is the number of convolutional layers of the backbone. The padding layers in the network allocate the unoccupied space in the original point cloud, and the convolution layers and pooling layers fill these spaces with features. The receptive field of the current layer is:
\begin{equation}
	RF_{i+1}=RF_i+(k-1)\times S_i
\end{equation}
\begin{equation}
	S_i=\prod^{i}_{i=1}Sride_i
\end{equation}
Among them, $RF_{i+1}$ represents the receptive field of the current layer, $RF_i$ represents the receptive field of the previous layer, and $k$ represents the size of the convolution kernel. It can be seen that the receptive field of the model continuously increases, even learning features for the unoccupied space in the original point cloud. The feature maps of the Point-based backbone network can be represented as follows:
\begin{equation}
	\label{eq4}
	F^{p}_{i+1}=Pool(Group(Sampling(F^{p}_{i})))
\end{equation}
$i$ represents the stage of feature learning, $Sampling$ is the downsampling operation, $Group$ is the local feature aggregation operation, $Pool$ is the pooling layer, which is treated as a symmetric function to address the unordered nature of point clouds. Here, $F^{p}_{0}=E_{\theta}(P)$, where $E_{\theta}(\dots)$ is the feature augmentation network, usually a multi-layer perceptron or graph neural network, which expands the feature space of point clouds. As the number of learning stages increases, the query radius of the local feature extractor becomes larger to increase the receptive field of the model. However, the model only takes the original point cloud as input, and in the case where the target has points only in the local region, even if the query radius increases, the receptive field of the model remains the same, and the learning of local features still stays at the previous stage. Fig. \ref{fig3} illustrates this phenomenon intuitively. Under this problem, the model's ability to predict the semantics and geometry information of upsampled points on the target will decrease. The main purpose of PDM-SSD is to alleviate this problem.
