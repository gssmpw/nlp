The proposed PDM-SSD can be trained in an end-to-end fashion. In the 3D backbone, the sampling loss is calculated.
\begin{equation}
	L_{sample}=-\sum_{c=1}^C{(Mask_i \cdot CELoss_i)}
\end{equation}
\begin{equation}
	CELoss_i = s_i \log(\hat{s_i}) + (1-s_i)\log{1-\hat{s_i}}
\end{equation}
\begin{equation}
	Mask_i=\sqrt[3]{\frac{\min{f^*,b^*}}{\max{f^*,b^*}}\times \frac{\min{l^*,r^*}}{\max{l^*,r^*}} \times \frac{\min{u^*,d^*}}{\max{u^*,d^*}}}
\end{equation}
$CELoss$ is the cross-entropy loss for predicting the category of sampled points, which first appeared in IA-SSD. It greatly improves the recall rate of foreground points in sampled points. $Mask$ is the weight for the centrality of sampled points. $f^*,b^*,l^*,r^*,u^*,d^*$ represent the distances between the sampled points and the six faces of the target box. We borrowed the design from 3DSSD, which believes that points closer to the center are more conducive to accurately regressing semantic categories and geometric parameters. By multiplying the centrality with the cross-entropy loss, the closer the sampled points are to the center, the greater the loss will be. The model will prioritize improving the foreground probability $s_i$ of these points, so that during inference, the model will prioritize selecting these points. Although SPSNet has shown that points closer to the center are not necessarily better, it is still better than methods that sample foreground points equally. Besides, SPSNet requires extra time to learn the stability of points.

The loss in the detection head is divided into two parts: the point-based loss $L_{p}$ and the grid-based heatmap prediction loss $L_{heatmap}$. The former consists of three components: the loss of the vote points $L_{vote}$, the loss of point semantics prediction $L_{cls}$, and the loss of target box geometric parameter regression $L_{reg}$. Additionally, we also include a regularization loss in the training process of PDM-SSD.
\begin{equation}
	L_{all}=L_{sample}+L_{p}+L_{heatmap}+L_2
\end{equation}
\begin{equation}
	L_{p}=L_{vote}+L_{cls}+L_{reg}
\end{equation}
In particular, the box generation loss can be further decomposed into location, size, angle-bin, angle-res, and corner parts:
\begin{equation}
	L_{reg}=L_{loc}+L_{size}+L_{angle-bin} + L_{angle-res} + L_{corner}
\end{equation}
All these losses will be jointly optimized using a multi-task learning approach.