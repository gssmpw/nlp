\input{PDM_test}

\textbf{Benchmark datasets.} The KITTI dataset is a dataset sponsored by the Karlsruhe Institute of Technology and the Toyota Technological Institute at Chicago for research in the field of autonomous driving. The widely-used dataset contains 7481 training samples with annotations in the camera field of vision and 7518 testing samples. Following the common protocol, we further divide the training samples into a training set (3,712 samples) and a validation set (3,769 samples). Additionally, the samples are divided into three difficulty levels: simple, moderate, and hard based on the occlusion level, visibility, and bounding box size. The moderate average precision is the official ranking metric for both 3D and BEV detection on the KITTI website.

\textbf{Evaluation metrics.} To provide a comprehensive performance evaluation, we evaluated our PDM-SSD on both the KITTI 3D and BEV object detection benchmarks. Generally, average precision ($AP$) based on Intersection over Union (IoU) is commonly used for both the 3D and BEV tasks. The experiments primarily focused on the commonly-used \textit{Car} category and were evaluated using the average precision metric with an IoU threshold of 0.7. To ensure an objective comparison, we utilized both the $AP$ with 40 recall points ($AP_{40}$) and the {AP} with 11 recall points ($AP_{11}$). The 3D-NMS threshold for metric calculation was set at 0.1, and the object score threshold was set at 0.1.

\textbf{Training details.} To ensure fair comparison, the training parameters of PDM-SSD are kept consistent with IA-SSD. Specifically, we use the Adam optimizer with $\beta_1=0.9$ and $\beta_2=0.85$ to optimize PDM-SSD. The weight decay coefficient is set to 0.01, and the momentum coefficient is set to 0.9. The model is trained for 80 epochs with a batch size of 16 on a Nvidia A40 GPU. The initial learning rate is set to 0.01, which is decayed by 0.1 at 35 and 45 epochs and updated with the one cycle policy. We initialized the weights of the heatmap prediction network in the neck module with values generated from a normal distribution. The training range of point clouds in the KITTI dataset is $[0,-40,-3,70.4,40,1]$, corresponding to $[x_{min},y_{min},z_{min},x_{max},y_{max},z_{max}]$. The grid size in the neck module is $176\times 200$, the size of the structural element is $5\times 5$, and the scale of the spherical harmonic coefficients is 3. The hybrid head predicted heatmaps and added the top 256 points with the highest foreground probabilities to the vote point set. We applied common scene-level data augmentation strategies to enhance the robustness of the model, including: 1) randomly rotating the scene along the $z$ axis within the range of $[-4/\pi,4/\pi]$ with a probability of 50\%; 2) randomly flipping the scene along the $x-z$ plane; 3) randomly scaling the scene within the range of $[0.95,1.05]$. Moreover, a sufficient number of targets was necessary for PDM-SSD to learn a more complete feature distribution. To achieve this, we employed object-level data augmentation methods to transform objects from other scenes. Specifically, 15 cars were copied to the current scene.

\textbf{Base detector.} Currently, the well-performing point-based detectors are all PointNet-style detectors, and their structures are quite similar, with the main difference lying in the different downsampling methods. PDM-SSD takes IA-SSD, which performs the best in terms of accuracy and inference speed on KITTI, as the base detector. In the experiments, the backbone of PDM-SSD used for auxiliary training is exactly the same as IA-SSD, making it very intuitive to see the advantages of PDM-SSD. In Section \ref{sec:pdm}, we will also provide a detailed comparison between PDM-SSD and IA-SSD at the object level.

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{AL_pics/detective_result.pdf}
	\caption{The detection results of PDM-SSD on a subset of KITTI \textit{val} set samples. From left to right, respectively: image and point clouds with predicted bounding boxes, space covered by grids after point dilatation, ground truth of space coverage heatmap in the scene, and predicted values of space coverage heatmap in the scene.}
	\label{fig:detectiveresult}
\end{figure}