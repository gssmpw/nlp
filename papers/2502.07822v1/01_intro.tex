LiDAR (Light Detection and Ranging) is an active sensor with excellent anti-interference capability, and its output point cloud can provide an accurate 3D representation of the scene. 3D object detection from point clouds has become increasingly popular thanks to its wide applications, such as autonomous driving and virtual reality. Currently, many point cloud-based 3D detection models have been proposed and achieved state-of-the-art performance on various public datasets, such as KITTI \cite{geiger2012we} and Waymo \cite{sun2020scalability}.

The sparsity of point clouds is the main characteristic that distinguishes 3D object detection from traditional 2D detection, and efficiently representing the sparse and unordered point clouds is the key for subsequent processing \cite{fan2021rangedet}. The main approach is to transform the original point clouds into regular feature representations, including projecting the point clouds onto 2D images from a bird's-eye view (BEV) or frontal view (FV), or transforming them into dense 3D voxels \cite{simon_complex-yolo_2018,noauthor_multi-view_nodate,beltran2018birdnet,zeng2018rt3d,ali2018yolo3d,barrera2020birdnet+,CHEN2023110952}. Then, well-performing feature extractors and detectors in 2D image tasks can be directly used for 3D object detection. BEV and FV feature maps can be obtained from voxels and pillars by projecting the 3D feature. The feature maps are always dense 2D representations, where each pixel corresponds to a specific region and encodes the points' information in this region. Voxel-based detection methods preserve the spatial information of the original point clouds to a great extent based on the size of voxels, and using 3D convolutional neural networks can achieve desirable detection performance. Another stream of techniques follows the point-based pipeline to directly operate on raw point clouds \cite{zheng2021se, zhang2022not, shi2019pointrcnn, shi2020point, yang20203dssd, hu2021learning, hu2021sqn, hu2022sensaturban, wei2022spatial}. These detectors construct symmetric functions to deal with the unordered nature of point clouds and expand the receptive field through continuous downsampling and aggregation of local features to obtain rich spatial and semantic features.

\begin{figure}[t]
	\begin{center}
		% \vspace{-0.2cm}
		\includegraphics[width=.5\textwidth]{AL_pics/introduce.pdf}
	\end{center}
	\vspace{-0.3cm}
	\caption{(a) The basic structure of the Grid-based 3D detector. P/VFE means Pillar/Voxel Feature Encoder. This approach allows for obtaining dense feature maps from sparse point clouds as input. (b) The Point-based detector has a basic structure where sparse point clouds are inputted and undergo multiple stages of downsampling, feature learning, and local feature aggregation to obtain sparser point-wise features. (c) The basic structure of our PDM-SSD. Point-wise features obtained from the point-based 3D backbone are lifted to the grid level through PDM. This joint learning approach helps alleviate the limited receptive field problem in (b).}
	\label{fig1}
	\vspace{-0.3cm}
\end{figure}

In general, both grid-based and point-based detectors have distinct advantages and disadvantages. Specifically, grid-based detectors map all points to a regular feature space, which reduces the cost of model design. The padding operation in the convolution process also fills the unused space in the original point cloud with features. Through joint learning with dense detection heads like the center head \cite{yin2021center}, the grid-based detector can capture the overall features of the targets, making it robust to incomplete objects. However, these detectors require complex and parameter-heavy feature encoders, which puts them at a disadvantage in terms of inference speed. Additionally, due to the wide scene range and sparse point cloud in 3D object detection tasks, grid-based feature representations often contain many non-occupied grids, leading to computational waste. Although 2/3D sparse convolution can effectively address these issues, many inference libraries like TensorRT lack operators for sparse models, making their deployment challenging.

The point-based detector does not lose spatial information and theoretically can learn objects of any size and shape. Moreover, this type of detector does not contain operators like sparse convolution in its backbone, making it more suitable for practical deployment in terms of inference speed and memory consumption. However, these models can only extract information from existing points, and for objects with only local regions containing points, their receptive field cannot increase with the increase of the query radius. The feature space is limited to the regions with points, which makes them less robust in detecting sparse objects compared to grid-based detectors. Additionally, the challenge of point cloud sparsity is further amplified in point-based detection models, as the number of object points decreases significantly after progressive downsampling, leading to the loss of object features (especially for small objects) and the potential retention of noise (caused by sensors). This is also the main reason why the detection performance of point-based detectors is lower than that of grid-based detectors at present. Although works like 3D-SSD \cite{yang20203dssd} and IA-SSD \cite{zhang2022not} have improved the recall rate of foreground points by clever downsampling strategies, the issue of discontinuous receptive field in point-based detectors has not received enough attention.

Motivated by this, in this paper, we propose PDM-SSD that combines the advantages of both grid and point representations while overcoming their drawbacks. Instead of projecting points onto a regular grid, we directly use a PointNet-style 3D backbone to extract features from the original point cloud. This type of feature extractor has a small number of parameters and theoretically no spatial information loss. After several rounds of downsampling and feature aggregation, each sampled point stores both geometric and semantic information within its receptive field. Inside the PDM-SSD, sampled points are adaptively lifted onto a 2D grid using our Point Dilation Mechanism. By using spherical harmonics coefficients and Gaussian density functions, we fill the 2D grid with initial features in terms of direction and scale. In this way, the space that is not occupied by the original point cloud is also included in the learning scope of the model. By filling the initial features, subsequent feature learning is also supported. As both the point-wise features without spatial information loss and the grid-features with continuous receptive fields are aggregated, we design a hybrid detection head that can fully utilize these two types of features to decode the features. This allows PDM-SSD to improve the detection capability for incomplete objects while maintaining inference speed.  Extensive experiments have been conducted on the KITTI detection benchmark to verify the effectiveness and efficiency of our approach. PDM-SSD outperforms all state-of-the-art point-based single stage methods for multi-class detection and performs comparably to two-stage point-based and grid-based methods as well. To summarize, the contributions are listed as follows:

\begin{itemize}
	\item {We have evaluated the advantages and disadvantages of existing grid-based and point-based detectors, and proposed the Point Dilation Mechanism to combine the strengths of both representations. To the best of our knowledge, this is the first point-based method that addresses the issue of discontinuous receptive fields.}
	\item {We introduce a novel point-based single stage 3D detector, PDM-SSD, which surpasses all state-of-the-art point-based single stage methods for multi-class detection on the KITTI benchmark.}
	\item {Our proposed PDM-SSD strikes a good balance between accuracy and inference speed, making it a deployment-friendly model. Furthermore, we demonstrate that even when the Point Dilation Mechanism is used as an auxiliary network, significant benefits can still be achieved.}
\end{itemize}

The structure of this paper is as follows. Section \ref{sec:related} provides a review of existing works on LiDAR-based detectors. In Section \ref{sec:method}, we explicitly formulate the changes in receptive field of point-based and grid-based models during the process of feature learning, followed by a technical implementation of PDM-SSD. In Section \ref{sec:experiments}, we conduct experiments on the KITTI dataset to demonstrate the effectiveness of our method, and we perform ablation experiments to validate the rationality of PDM-SSD design. In addition, we also use a large number of object-level instances to illustrate the contributions of PDM-SSD in detecting difficult targets. Finally, Section \ref{sec:conclusion} concludes this paper and provides an outlook on future work.
