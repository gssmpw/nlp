\documentclass{article}


\usepackage{PRIMEarxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{fancyhdr}       % header
\usepackage{graphicx}       % graphics
\usepackage{multirow}
\usepackage{colortbl}
\usepackage{hhline}
\usepackage{color, xcolor}
\usepackage{ulem}
\graphicspath{{media/}}     % organize your images and other figures under media/ folder

%Header
\pagestyle{fancy}
\thispagestyle{empty}
\rhead{ \textit{ }} 

% Update your Headers here
\fancyhead[LO]{Running Title for Header}
% \fancyhead[RE]{Firstauthor and Secondauthor} % Firstauthor et al. if more than 2 - must use \documentclass[twoside]{article}



  
%% Title
\title{PDM-SSD: Single-Stage Three-Dimensional Object Detector With Point Dilation
%%%% Cite as
%%%% Update your official citation here when published 
\thanks{\textit{\underline{Citation}}: 
\textbf{Authors. Title. Pages.... DOI:000000/11111.}} 
}

\author{
  Ao Liang, Haiyang Hua, Jian Fang, Wenyu Chen Huaici Zhao* \\
  Key Laboratory of Opto-Electronic Information Processing, Chinese Academy of Sciences, 110016, Shenyang\\
  Shenyang Institute of Automation, Chinese Academy of Sciences, 110016, Shenyang \\
  University of Chinese Academy of Sciences, 100049, Beijing \\
  \texttt{\{liangao, hczhao\}@sia.cn} \\
  %% examples of more authors
 % \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}


\begin{document}
\maketitle


\begin{abstract}
One of the important reasons why grid/voxel-based three-dimensional (3D) object detectors can achieve robust results for sparse and incomplete targets in Light Detection And Ranging (LiDAR) scenes is that the repeated padding, convolution, and pooling layers in the feature learning process enlarge the model's receptive field, enabling features even in space not covered by point clouds. However, they require time- and memory-consuming 3D backbones. Point-based detectors are more suitable for practical application, but current detectors can only learn from the provided points, with limited receptive fields and insufficient global learning capabilities for such targets. In this paper, we present a novel Point Dilation Mechanism for single-stage 3D detection (PDM-SSD) that takes advantage of these two representations. Specifically, we first use a PointNet-style 3D backbone for efficient feature encoding. Then, a neck with Point Dilation Mechanism (PDM) is used to expand the feature space, which involves two key steps: point dilation and feature filling. The former expands points to a certain size grid centered around the sampled points in Euclidean space. The latter fills the unoccupied grid with feature for backpropagation using spherical harmonic coefficients and Gaussian density function in terms of direction and scale. Next, we associate multiple dilation centers and fuse coefficients to obtain sparse grid features through height compression. Finally, we design a hybrid detection head for joint learning, where on one hand, the scene heatmap is predicted to complement the voting point set for improved detection accuracy, and on the other hand, the target probability of detected boxes are calibrated through feature fusion. On the challenging Karlsruhe Institute of Technology and Toyota Technological Institute (KITTI) dataset, PDM-SSD achieves state-of-the-art results for multi-class detection among single-modal methods with an inference speed of 68 frames. We also demonstrate the advantages of PDM-SSD in detecting sparse and incomplete objects through numerous object-level instances. Additionally, PDM can serve as an auxiliary network to establish a connection between sampling points and object centers, thereby improving the accuracy of the model without sacrificing inference speed. Our code will be available at \url{https://github.com/AlanLiangC/PDM-SSD.git}.\end{abstract}


% keywords can be removed
\keywords{Autonomous driving \and 3D object detection \and Deep learning \and Point cloud proccessing}

\section{Introduction}
\input{01_intro}

\section{Related Work}
\label{sec:related}
\input{02_related_work}

\section{Method}
\label{sec:method}

\subsection{Overview}
\input{031_overview}

\subsection{Problem formulation}
\label{sec:pf}
\input{032_problem_formulation}


\subsection{PointNet style 3D backbone}
\label{sec:backbone}
\input{033_backbone}


\subsection{Neck with Point Dilation Mechanism}
\label{sec:neck}
\input{034_Neck}


\subsection{Hybrid Head}
\label{sec:head}
\input{035_Head}


\subsection{End-to-End Learning}
\label{sec:loss}
\input{036_loss}

\section{Experiments}
\label{sec:experiments}
In this section, we will provide detailed experimental results to demonstrate the efficiency and accuracy of PDM-SSD. Specifically, we introduced the specific settings and implementation details of the experiments in Section \ref{sec:setup}. Then, the comparison results between PDM-SSD and current state-of-the-art methods were reported in Section \ref{sec:comparison}. Following that, in Section \ref{sec:ablation}, a ablation study was conducted to demonstrate the rationality of the model design. Furthermore, the inference efficiency of PDM-SSD was analyzed in Section \ref{sec:runtime}. Finally, in Section \ref{sec:pdm}, we provided a large number of instances to demonstrate the superiority of PDM in sparse and incomplete object detection.

\subsection{Setup}
\label{sec:setup}
\input{041_setup}

\subsection{Comparison with State-of-the-Arts}
\label{sec:comparison}
\input{042_comparison}

\subsection{Ablation Study}
\label{sec:ablation}
\input{043_ablation}

\subsection{Runtime Analysis}
\label{sec:runtime}
\input{044_runtime}


\subsection{PDM Analysis}
\label{sec:pdm}
\input{045_pdm}

\section{Dicussion}
\label{sec:dicussion}
PDM-SSD provides a new approach to address the issue of discontinuous receptive fields in point-based detectors. It eliminates the complex process of integrating point and grid representations in the backbone and instead utilizes PDM to directly lift and fill features for sampled points within the neck module. This not only maintains a lightweight model but also exploits the advantages of both representations.
We have extensively demonstrated the superiority of PDM-SSD through numerous experiments, as described in Section \ref{sec:experiments}. In terms of detection accuracy, PDM-SSD surpasses the state-of-the-art point-based detectors and can compete with some voxel-based models. In terms of inference speed, PDM-SSD can run efficiently at 68 FPS, which is much higher than the scanning frequency of current LiDARs, making it suitable for practical applications. The auxiliary trained PDM-SSD (A) achieves even higher detection accuracy without sacrificing inference efficiency. Additionally, the model parameters of PDM-SSD are only 3.3MB, greatly reducing the deployment difficulty. In the object-level experimental analysis, we found that PDM-SSD effectively mitigates the issues of large vote point errors and low object box prediction probabilities caused by limited receptive fields in current point-based detectors. Overall, PDM-SSD has indeed identified new problems and made further advancements in the current research, demonstrating its value.

\textbf{Limitations and outlook.} Objectively speaking, PDM-SSD still has the following issues: 1) We avoided the detection of pedestrians in the KITTI dataset because the small volume and limited impact of pedestrians make the $5\times 5$ structural element unsuitable for detecting such targets. In future work, we will select different sizes of $B$ for different classes of objects. 2) In the scale coefficient of feature padding, we set two variables as independently and identically distributed, following the setting of heatmap in CenterNet \cite{yin2021center}. However, we believe this is not optimal, and in future work, we will split the Gaussian into a mixture of scale and rotation to learn the covariance and embed more geometric information into the learning process. 3) The final context learning module we used is still PointNet, which may not fully utilize the mixed features provided by the mixed head. In future work, we will design more sophisticated learning modules.

\section{Conclusion}
\label{sec:conclusion}
In this article, we propose single stage point-based 3D object detector called PDM-SSD. Our goal is to alleviate the limited receptive field issue while maintaining the fast inference speed of point-based detectors. Currently, point-based detectors can only learn features from existing points, and their receptive field is discontinuous and limited when the query radius expands, especially for sparse or extremely incomplete objects. This not only leads to large position errors in regression vote points but also results in prediction probabilities for object boxes lower than the threshold. PDM-SSD expands the learning space of the model through Point Dilation, specifically covering the unoccupied space near the center of the object in the original point cloud. Then, it fills these spaces with features that can be backpropagated, and the information from multiple dilation centers is connected through height compression. Finally, these features are jointly learned through a hybrid head. The experimental results show that PDM-SSD achieves competitive performance in terms of detection accuracy, surpassing all current point-based models in multiple metrics. In terms of inference speed, it fully meets the current application requirements. More importantly, from the object-level experiments, we can intuitively see the contributions of PDM-SSD in addressing the issues of current point-based detectors.

\section*{Acknowledgments}
This document is the results of the research project funded by the CAS Innovation Fund (E01Z040101)
%Bibliography
\bibliographystyle{unsrt}  
\bibliography{references}  


\end{document}
