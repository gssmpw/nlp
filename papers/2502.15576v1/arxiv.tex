% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}
\usepackage{amsmath}
\usepackage{amssymb}


\PassOptionsToPackage{prologue,dvipsnames,svgnames}{xcolor}
%\usepackage[prologue,dvipsnames]{xcolor}
\usepackage{graphicx}
\setlength{\fboxsep}{1pt}
%\usepackage{xcolor}
\usepackage[many]{tcolorbox} 
\definecolor{bblue}{HTML}{d6eaf8}
\definecolor{rred}{HTML}{C0504D}
\definecolor{ggreen}{HTML}{d9fdbb}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}

\usepackage{hyperref}
\usepackage{url}
\usepackage{dsfont}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{array}
\usepackage{caption}
\usepackage{pgfplots}
\usepackage{pgfplotstable}
\usepackage{wrapfig}
\usepackage{siunitx}
\usepackage{enumitem}
%\usepackage[table]{xcolor}
\usepackage{listings}
\usepackage{tcolorbox}
\usepackage{geometry}
\lstset{
    basicstyle=\ttfamily,
    literate={,}{,}1
}
\newcommand{\bigO}{\mathcal{O}}
\usepackage{rotating}
\renewcommand{\arraystretch}{1.1} % Slightly increase row height
%\usepackage{fourier}

\usepackage[dvipsnames]{xcolor}
\pgfplotsset{compat=1.11,
        /pgfplots/ybar legend/.style={
        /pgfplots/legend image code/.code={%
        %\draw[##1,/tikz/.cd,yshift=-0.25em]
                %(0cm,0cm) rectangle (3pt,0.8em);},
        \draw[##1,/tikz/.cd,bar width=3pt,yshift=-0.2em,bar shift=0pt]
                plot coordinates {(0cm,0.8em)};},
},
}


\newcommand\revise[1]{{\color{black}#1}}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Interpreting and Steering LLMs with Mutual Information-based Explanations on Sparse Autoencoders}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

% \author{First Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\\And
%   Second Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\}

\author{
 \textbf{Xuansheng Wu\textsuperscript{1}},
 \textbf{Jiayi Yuan\textsuperscript{2}},
 \textbf{Wenlin Yao\textsuperscript{3}},
 \textbf{Xiaoming Zhai\textsuperscript{1}},
 \textbf{Ninghao Liu\textsuperscript{1}}
\\
 \textsuperscript{1}University of Georgia\,\,
 \textsuperscript{2}Rice University\,\,
 \textsuperscript{3}Amazon
\\
 \small{\textsuperscript{1}\texttt{\{xuansheng.wu,xiaoming.zhai,ninghao.liu\}@uga.edu}}\,\,
  \small{\textsuperscript{2}\texttt{jy101@rice.edu}}\,\,
  \small{\textsuperscript{3}\texttt{ywenlin@amazon.com}}
}

\begin{document}
\maketitle
\begin{abstract}
Large language models (LLMs) excel at handling human queries, but they can occasionally generate flawed or unexpected responses. 
Understanding their internal states is crucial for understanding their successes, diagnosing their failures, and refining their capabilities.
Although sparse autoencoders (SAEs) have shown promise for interpreting LLM internal representations, limited research has explored how to better explain SAE features, i.e., understanding the semantic meaning of features learned by SAE. 
Our theoretical analysis reveals that existing explanation methods suffer from the frequency bias issue, where they emphasize linguistic patterns over semantic concepts, while the latter is more critical to steer LLM behaviors. 
To address this, we propose using a fixed vocabulary set for feature interpretations and designing a mutual information-based objective, aiming to better capture the semantic meaning behind these features. 
We further propose two runtime steering strategies that adjust the learned feature activations based on their corresponding explanations. 
Empirical results show that, compared to baselines, our method provides more discourse-level explanations and effectively steers LLM behaviors to defend against jailbreak attacks. 
These findings highlight the value of explanations for steering LLM behaviors in downstream applications.\footnote{We will release our code and data once accepted.}
\end{abstract}



\section{Introduction}
Large language models (LLMs) have demonstrated strong capabilities in responding to general human requests~\citep{achiam2023gpt,dubey2024llama,jiang2024mixtral}. 
Meanwhile, we still often observe failed or unexpected responses in certain  situations~\citep{ji2023survey,wei2024jailbroken}. 
Gaining insight into the factors behind their successes and failures is crucial for further improving these models. 
A straightforward way to understand LLM behaviors is by directly studying their hidden representations. 
However, it is non-trivial to achieve that because of the \textit{polysemantic} nature~\citep{arora2018linear,scherlis2022polysemanticity} of the hidden space, where each dimension of the hidden representations encodes multiple pieces of unique features.

\begin{figure*}
\vspace{-0.4cm}
\centerline{\includegraphics[width=1.0\linewidth]{Figures/Example_v8.pdf}}
\vspace{-0.3cm}
\caption{Examples of explanations generated by ours and baseline methods. We separate raw extracted words/spans with ``;'' and \underline{\textbf{boldface}} their automated summaries. We could observe that our method tends to use \colorbox{bblue}{diverse words} to describe a semantical concept. In contrast, the extracted spans from baseline methods typically share some \colorbox{pink}{duplicated phrases}, indicating suffering from a frequency bias on those linguistic patterns.}
\label{fig:examples}
\vspace{-0.4cm}
\end{figure*}



Researchers have made significant efforts to overcome the polysemantic challenge.  
Early works~\citep{millidge2022singular,wu2024language} apply matrix decomposition techniques % (e.g., Singular Vector Decomposition, SVD) 
to learn a set of orthogonal vectors to form the basis of hidden representations. 
However, this approach is insufficient to find vectors for certain purposes, as matrix decomposition techniques can only produce a limited number of orthogonal vectors. 
In this context, recent research has explored the sparse autoencoder (SAE) technique~\citep{olshausen1997sparse,makhzani2013k}, which has demonstrated their effectiveness in learning a large number of \textit{sparse} feature vectors to reconstruct the hidden spaces of advanced LLMs with hundreds of billions of parameters~\cite{cunningham2023sparse,brickentowards,templeton2024scaling,gao2024scaling}. 
These learned sparse features are expected to be interpretable, since each feature should only react to a specific concept, showing a \textit{monosemantic} nature instead of a polysemantic one.


However, the semantic meaning of sparse features learned by SAEs is \textbf{not directly comprehensible to humans}, requiring an additional step of post-hoc explanation. Furthermore, intuitively explaining the learned features poses a significant challenge. 
Existing works~\cite{brickentowards,gao2024scaling} generate explanations for learned features by extracting text spans whose hidden representations could maximally activate the corresponding feature vector. 
However, \citet{gao2024scaling} found that many extracted text spans of learned features are too trivial to be used to explain the complex behaviors of LLMs. 
In addition, when steering LLMs according to the extracted text spans, the resulting responses may not always be predictable~\cite{durmus2024steering}. 
These challenges undermine confidence in using explanations to steer LLMs for real-world applications. 


In this work, we introduce a novel post-hoc explanation method for learned features, and strategies to steer LLM behaviors based on our generated explanations. 
Our study starts with a theoretical analysis of the distribution of learned features, where we reveal that the learned features encode both \textit{discourse topics} and \textit{linguistic patterns} simultaneously, with the latter being less critical for model steering but occurring more frequently, named \textbf{frequency bias}. 
This frequency bias causes the existing methods to extract repetitive and superficial patterns. 
To address this challenge, we propose to leverage a fixed vocabulary set instead of the entire corpus for explanation, and further design a mutual information-based objective to ensure that the explanations capture critical information. 
As shown in Figure~\ref{fig:examples}, baseline methods exhibit frequency bias, leading to repetitive phrases in their explanations, whereas our approach explains discourse topics with diverse words. 
We also explore steering LLMs for jailbreak defense based on our generated explanations of learned features. 
Experiments show that our method provides more meaningful discourse-level explanations than the other explainers, and these discourse-level explanations are effective in steering LLM behaviors on certain tasks. 
We summarize our contributions as follows:
\begin{itemize}[leftmargin=*, itemsep=0pt, topsep=0pt]
    \item Our theoretical analysis identifies a key challenge in explaining learned features from sparse autoencoders, i.e., the frequency bias between the discourse and linguistic features.  
    \item We propose leveraging a fixed vocabulary set to mitigate the frequency bias for explaining learned features. Experimental results show that our method uses more diverse words to explain discourse topics than the other explanation methods.  
    \item We propose steering LLMs for specific purposes by adjusting the activations of learned features based on their explanations. Experiments confirm that we could enhance LLM's safety by using our discourse-level explanations.
\end{itemize}




\section{Preliminary}
\subsection{Problem Statement}
Let $\mathcal{V}$ denote the vocabulary set, and $X$ be a text of length $N$, where $x_n \in \mathcal{V}$ denotes the $n$-th token of $X$.  
\revise{Given a language model $f$, the embedding of $X$ at the $l$-th layer is denoted as $\mathbf{X}^{(l)}\in\mathbb{R}^{N\times D}$, where $D$ is latent dimension. In the rest of this paper, we omit superscript $^{(l)}$ for simplification of notations.}
Our goal is to interpret embeddings $\mathbf{X}$ by extracting some semantic features from the latent space. 
Specifically, there exists $C$ learned feature vectors $\mathbf{W}\in\mathbb{R}^{C\times D}$ that can decompose arbitrary $\mathbf{X}$ as a linear combination, i.e., $\mathbf{X}\approx\mathbf{A}\mathbf{W}$, where $C\gg D$, $\mathbf{A}\in\mathbb{R}^{N\times C}$ are the weights of the linear combination. 
Let $\mathbf{W}_c$ denote the $c$-th row of $\mathbf{W}$.
After the decomposition, $\mathbf{X}$ is explainable if we could understand the semantic meaning of each learned feature vector $\mathbf{W}_c$. 
In this paper, we focus on seeking a set of words $\mathcal{I}_c\subset\mathcal{V}$ to explain each learned feature $\mathbf{W}_c$ with natural language.


\begin{figure*}
\centerline{\includegraphics[width=0.99\linewidth]{Figures/Workflow_nl.pdf}}
%\vspace{-0.2cm}
\caption{The proposed framework of explaining SAE features and steering LLMs with explanations.}
\label{fig:pipeline}
\vspace{-0.2cm}
\end{figure*}
 

\subsection{Learning and Interpreting LLMs with Sparse Autoencoders}
Many attempts have been made to learn feature vectors $\mathbf{W}$ for interpreting LLMs, where sparse autoencoders have shown great promise for this purpose~~\cite {gao2024scaling,lieberum2024gemma}. 
Typically, sparse autoencoder~\citep{olshausen1997sparse,makhzani2013k} is a two-layer multi-layer perceptron $\hat{\mathbf{X}} = \sigma(\mathbf{X}\mathbf{W}^\top)\cdot \mathbf{W}$ with the tight weight strategy, and is trained by minimizing the reconstruction loss $\mathcal{L}=\|\mathbf{X}-\hat{\mathbf{X}}\|_2$, where $\mathbf{W}\in\mathbb{R}^{C\times D}$ are trainable parameters and $\sigma$ refers to the Top-K activation function. 
The Top-K activation function only keeps the $K$ largest values and enforces other values as zeros, leading to the nature of \textit{sparsity} to the autoencoder. 
The sparsity indicates that each learned row vector $\mathbf{W}_c$ should only be activated by a certain kind of input, showing the monosemantic instead of polysemantic.   

However, there are limited explorations on collecting a natural language explanation $\mathcal{I}_c$ for each learned feature vector $\mathbf{W}_c$.
The most straightforward strategy~\citep{brickentowards} is collecting some N-gram spans over a large corpus whose hidden representations can best activate the feature vector $\mathbf{W}_c$. 
Some researchers~\citep{gao2024scaling} leverage the Neuron-to-Graph (N2G) algorithm~\citep{foote2023neuron} to refine the N-gram spans for more precise interpretations. 
However, these methods typically tend to extract some superficial and trivial patterns~\citep{gao2024scaling}, and those generated explanations are not always effective in steering LLM behaviors for certain purposes~\cite{durmus2024steering}.
In the following, we will first analyze the challenge of interpreting these learned features, followed by a novel explanation method to overcome the challenge and strategies to use these explanations for downstream tasks. 


\section{Methodology}
This section first theoretically studies the properties of text generation, comparing them to traditional image generation scenarios where sparse autoencoders were initially developed for. With these insights, we propose a mutual information-based method to explain the semantics of learned features, and further design two strategies to steer LLMs based on the explained features. Figure~\ref{fig:pipeline} illustrates our overall framework.

\subsection{Feature Dynamics in Text Data}
\label{sec:textual_sae}
Sparse autoencoders~\citep{olshausen1997sparse} were originally designed for image data under the assumption that each image can be expressed as a linear combination of underlying \textit{features}. Previous works~\citep{brickentowards,cunningham2023sparse} adapt this framework to textual data by similarly assuming that each token is linearly related to a set of features. However, these approaches overlook certain inherent properties of textual data, resulting in a significant challenge in interpreting the learned feature vectors.


We consider the text generation task as a dynamic process under the topic-model assumption~\citep{steyvers2007probabilistic,arora2016latent,arora2018linear}, where each word $x_n$ is generated at the $n$-th step. 
It means that, in topic models, text generation begins with a predetermined concept or theme, guiding word selection at each step to align with that central idea. 
Formally, this dynamic process can be driven by the random walk of a discourse vector $\mathbf{e}_{c_n}\in\mathbb{R}^d$ representing what it talks about. 
The discourse vector $\mathbf{e}_{c_n}$ does a slow random walk at each step $n$, i.e., $\mathbf{e}_{c_n} = \mathbf{e}_{c_{n-1}} + \mathbf{e}_{\epsilon_n}$, where $\mathbf{e}_{\epsilon_n} \sim \mathcal{N}^d(0,\sigma)$. 
Also, at each step, a word $x_n\in\mathcal{V}$ is sampled based on the discourse vector $\mathbf{e}_{c_n}$. 
To this end, the text generation process for a sequence of words $X$ is given by:
\begin{equation}
    p(X) = \prod_{n=1}^{|X|} p(x_n|c_n) \cdot p(c_n|c_{n-1}).
\end{equation}
Here, the word emission probability is modelled by $p(x_n|c_n) = \frac{\exp(\langle\mathbf{e}_{x_n},\mathbf{e_{c_n}}\rangle)}{\sum_{v\in\mathcal{V}}\exp(\langle\mathbf{e}_{v},\mathbf{e}_{c_n}\rangle)}$~\citep{steyvers2007probabilistic}, where $\langle \cdot, \cdot \rangle$ indicates the dot product of two vectors.
Since $c_n$ is a random walk of $c_{n-1}$, the topic transmission probability can be computed as $p(c_n|c_{n-1})=\frac{1}{\sqrt{2\pi}\cdot \sigma}\cdot \exp(\frac{-||\mathbf{e}_{c_n}-\mathbf{e}_{c_{n-1}}||_2}{2\sigma})$~\citep{olshausen1997sparse}. 
Recall that $\mathbf{e}_{c_n}=\mathbf{e}_{c_{n-1}}+\mathbf{e}_{\epsilon_n}$, after a few derivations, we have 
\begin{equation}
\begin{aligned}
    \log p(X) \propto & \sum_{n=1}^{N}\langle \mathbf{e}_{x_n},\mathbf{e}_{c_0}\rangle 
  + \sum_{i=1}^{N}\sum_{n=1}^{i} \langle \mathbf{e}_{x_n},\mathbf{e}_{\epsilon_n}\rangle \\ 
    & - \sum_{n=1}^N \frac{\|\mathbf{e}_{\epsilon_n}\|_2}{2\sigma}.
    \label{eq:language_modeling}
\end{aligned}
\end{equation}
Equation~\ref{eq:language_modeling} reveals some critical characteristics of textual data that are different from image data. Firstly, \textbf{there is a shared discourse topic $c_0$ across words $x_n$ from the same $X$, for $n=1,...,N$.}
However, recent approaches that use sparse autoencoders for LLMs often treat the reconstruction loss for each token independently, without adding constraints to capture the shared concepts. As a result, they fail to isolate the features learned for discourse semantical topics (i.e., $\mathbf{e}_{c_0}$) and linguistic patterns (i.e., $\mathbf{e}_{\epsilon_n}$). 
Thus, each learned feature $\mathbf{W}_c$ may store both discourse and linguistic information, where the latter is less useful for steering LLMs than the previous one.  
In addition, \textbf{discourse topics are rarer than linguistic patterns, called \textit{frequency bias}}, as each $X$ has $N$ times more linguistic patterns than its discourse topic. 
This issue leads to the learned features that prioritize capturing the linguistic patterns, raising the challenge of interpreting those encoded discourse topics. 

\subsection{Explaining Learned Features with Natural Language}
\label{sec:mutual_info_explain}
To interpret the learned features $\{\mathbf{W}_c\}_{c=1}^C$, existing works~\citep{brickentowards,gao2024scaling} typically enumerate a large number of texts, and then treat those whose hidden representations could most activate the learned features as the interpretations. 
This method works well for interpreting the learned linguistic patterns as they are frequently presented in the corpus, while it is hard to discover the learned discourse topics because the more frequent linguistic patterns dominate, leading to the failure of steering LLM behaviors based on the explanations~\citep{gao2024scaling, durmus2024steering}.  
Since our goal is to understand and control LLM behaviors, we aim to interpret those discourse topics within a feasible budget cost.

To tackle the challenge of frequency bias, we propose to leverage a fixed vocabulary set $\mathcal{V}$ of a general corpus instead of its raw texts. 
Our goal is to seek a $M$-word set $\mathcal{I}_{c}\subset \mathcal{V}$ that can describe most information of the $c$-th feature vector $\mathbf{W}_c$. 
Mathematically, we let $\mathcal{C}$ denote the knowledge encoded by $\mathbf{W}_c$ and measure the information of $\mathcal{C}$ described by a given word set $\mathcal{V}^\prime\subset\mathcal{V}$ based on their mutual information~\citep{cover1999elements}. To this end, the objective of constructing $\mathcal{I}_c$ is defined as
\begin{equation}
    \begin{aligned}
    \mathcal{I}_c &= \underset{\mathcal{V}^\prime\subset \mathcal{V},|\mathcal{V}|=M}{\arg\max}\text{MI}(\mathcal{V}^\prime;\mathcal{C}) \propto \underset{\mathcal{V}^\prime\subset \mathcal{V},|\mathcal{V}^\prime|=M} {\arg\min} \text{H}(\mathcal{C}|\mathcal{V}^\prime)  \\[1ex]
    &= \underset{\mathcal{V}^\prime\subset \mathcal{V},|\mathcal{V}^\prime|=M}{\arg\max} \sum_{\mathbf{e}_\mathcal{C}\in U(\mathcal{C})}\sum_{w\in \mathcal{V}^\prime} p(\mathbf{e}_\mathcal{C}) p(w|\mathbf{e}_\mathcal{C}) \log p(\mathbf{e}_\mathcal{C}|w), 
    \label{eq:original}
\end{aligned}
\end{equation}
where $\text{MI}(\cdot;\cdot)$ indicates mutual information between two variables, $\text{H}(\cdot|\cdot)$ denotes the conditional Shannon entropy, and $U(\mathcal{C})$ includes all possible vectors that express the knowledge $\mathcal{C}$. 
\revise{Since we obtain $\mathbf{W}_c$ by training a sparse autoencoder—and ideally, each learned feature vector encodes a unique piece of knowledge—we assume that $p(\mathbf{e}_\mathcal{C} = \mathbf{W}_c) \approx 1$ and $p(\mathbf{e}_\mathcal{C}\neq\mathbf{W}_c)\approx 0$.} This allows us to simplify the expression as:
\begin{equation}
    \mathcal{I}_c\propto\underset{\mathcal{V}^\prime\subset \mathcal{V},|\mathcal{V}^\prime|=M}{\arg\max} \sum_{w\in \mathcal{V}^\prime} p(w|\mathbf{W}_c) \log p(\mathbf{W}_c|w).
\end{equation}
By leveraging output embedding $\mathbf{e}_w$ of word $w$, we empirically estimate $p(w|\mathbf{W}_c)$ and $p(\mathbf{W}_c|w)$ by
\begin{equation}
\begin{aligned}
    p(w|\mathbf{W}_c) &= \frac{\text{exp}(\langle\mathbf{e}_w, \mathbf{W}_c\rangle)}{\sum_{w^\prime \in \mathcal{V}}\text{exp}(\langle\mathbf{e}_{w^\prime},     \mathbf{W}_c\rangle)}, \\[1ex]
    p(\mathbf{W}_c|w) &= \frac{\text{exp}(\langle\mathbf{e}_w, \mathbf{W}_c\rangle)}{\sum_{c^\prime \in \mathcal{C}}\text{exp}(\langle\mathbf{e}_{w}, \mathbf{W}_{c^\prime}\rangle)}. 
\end{aligned}  
\end{equation}
Compared with a trivial strategy that obtains $M$ words whose output embeddings best activate the feature vector~\cite{Nostal2020Logit}, our mutual information-based objective reveals the importance of normalizing activations of a single word across all learned features. 
In other words, if a word embedding constantly leads to a significant large dot product with all features, the word will not express enough specificity to any certain feature. 
In information retrieval, TF-IDF~\citep{salton1988term} is a practical technique for mitigating frequency bias and it can be formulated from the same mutual information-based objective that we used in this work as suggested by~\citet{aizawa2003information}. 
However, TF-IDF relies on assumptions about word distributions over documents, which do not hold in our feature interpretation task. Therefore, we derive our method from a more general perspective, better aligning this objective with the context of interpreting learned sparse feature vectors.


\subsection{Steering LLMs with Explained Features}
Given learned features $\{\mathbf{W}_c\}_{c=1}^C$ and their explanations $\{\mathcal{I}_c\}_{c=1}^C$, we could identify a subset of the features $\mathbf{S}=\{\mathbf{W}_s\}_{s=1}^S\subset \{\mathbf{W}_c\}_{c=1}^C$ that are correlated with a specific LLM behavior we are interested in based on their explanations (e.g., harmful knowledge or safety awareness in our study). 
This annotating process can be easily scaled up by leveraging advanced LLMs~\citep{bills2023language} as our explanations are natural language. 
Considering the hidden representations of an input prompt as $\mathbf{X}$, we propose two strategies to steer LLM representations with the identified features $\mathbf{S}$ during runtime. 

\textbf{Amplification.} We amplify $\alpha$ times of the activations on our identified feature vectors, i.e., $\mathbf{X}^\prime=\mathbf{X}+\alpha \cdot \text{ReLU}(\mathbf{X}\mathbf{S})\mathbf{S}^\top$, where $\alpha$ is a hyper-parameter. We encourage LLMs to be more aware of the identified features if $\alpha>0$, and pay less attention to them if $\alpha < 0$. Especially, $\alpha=-1$ indicates that we erase the LLM's awareness of the identified features from its hidden representations. 

\textbf{Calibration.} We enforce LLMs to focus on the identified features to a certain level $\beta$, i.e., $\mathbf{X}^\prime=\mathbf{X}-\text{ReLU}(\mathbf{X}\mathbf{S})\mathbf{S}^\top+\beta \cdot\bar{\mathbf{S}}$, where $\bar{\mathbf{S}}$ is the mean vector of $\mathbf{S}$ and $\beta$ is a hyper-parameter. 
This strategy inherently shifts the LLM's hidden space toward the center of our target feature vectors.

The above two strategies are responsible for different purposes of steering LLMs, and they could work together. 
We would also emphasize that the proposed strategies are efficient as we only monitor a subset of our interested features $\mathbf{S}$ instead of the entire set of learned sparse features $\mathbf{W}$. 




\section{Experiments}
\vspace{-0.2cm}
This section investigates two research questions. RQ1: Does the proposed method generate more discourse-level explanations than traditional methods? 
RQ2: Whether these discourse-level explanations are useful in steering LLM behaviors? 
To answer these questions, Sec.~\ref{general_settings} describes some details of the Top-K sparse autoencoder we used in our study. Sec.~\ref{evaluate_quality} compares the explanation quality of our proposed methods and others for RQ1. Sec.~\ref{downstream_task} finally explores the usability of the explanations for defending jailbreak attacks for RQ2.

\subsection{General Settings}
\label{general_settings}
\paragraph{Language Models.}
We study LLMs from the Mistral family~\citep{jiang2023mistral} as it has demonstrated its strong usability in the wild. In particular, we use the Mistral-7B-Instruct-v0.2 checkpoint from Huggingface~\cite{wolf2019huggingface}. 
Following previous works~\citep{lieberum2024gemma} on Gemma2-9B-Instruct, we consider the residual stream at the 25\%-th, 50\%-th, and 75\%-th layers of entire model to train our sparse autoencoders, referring the 8th, 16th, and 24th layers of Mistral-7B-Instruct. 
Our main experiments are conducted on the 8th layer as we found that it shows the best effectiveness in steering LLM behaviors (see discussion in Appendix~\ref{appd:steer_layers}).
Without specifics, the greedy search decoding with a maximum of 512 new tokens is applied to our experiments for reproducibility.

\paragraph{Datasets.}
We consider various instruction-tuning datasets for training our backbone sparse autoencoders. 
In specific, ShareGPT~\citep{shareGPT}, UltraChat~\citep{ding2023enhancing}, HH-RLHF~\citep{bai2022training}, WebGLM-QA~\citep{liu2023webglm}, Evol-Instruct~\citep{xu2023wizardlm}, and HelpSteer2~\citep{wang2024helpsteer2} are selected. 
We de-duplicate prompts across different datasets and sample a subset of UltraChat with 400K samples. To this end, we have retained about 711K prompts, with an average length of 177.9 tokens. We randomly select 90\% of prompts to form our training set, and the rest is our validation set. 
Overall, we collect 113M tokens for training and 12M tokens for validating.

\begin{table*}[t]
\small
    \centering
    \vspace{-0.4cm}
    \caption{Qualitative analysis on generated explanations. Both TopAct and N2G tend to collect raw explanations sharing the same word-level patterns, while our method generate explanations for discourse-level topics with diverse words. We highlight those \colorbox{pink}{duplicated patterns} and \colorbox{bblue}{diverse words} related to a concise topic.}
    \vspace{-0.3cm}
    \begin{tabular}{p{1.cm}|p{8.5cm}|p{4.8cm}}
        \toprule
        \toprule
        \centering
        \textbf{Method} &\textbf{Raw Extracted Words or Text Spans} & \textbf{\revise{Automated} Summary}  \\
         \midrule
        \multirow{7}{*}{\shortstack{\textbf{Ours}}} & \colorbox{bblue}{previously}; \colorbox{bblue}{suddenly}; \colorbox{bblue}{repeated}; \colorbox{bblue}{history}; \colorbox{bblue}{once}; \colorbox{bblue}{initially}; \colorbox{bblue}{nearest}; \colorbox{bblue}{already}; normally; \colorbox{bblue}{originally} & Temporal concepts and sequences in narratives. \\\cmidrule{2-3}
           & \colorbox{bblue}{commonly}; \colorbox{bblue}{impact}; \colorbox{bblue}{cater}; \colorbox{bblue}{widely}; \colorbox{bblue}{normally}; \colorbox{bblue}{gallery}; \colorbox{bblue}{judge}; \colorbox{bblue}{pros}; independent; \colorbox{bblue}{accurately} &  Art evaluation and critique.  \\ \cmidrule{2-3}
           & \colorbox{bblue}{client}; \colorbox{bblue}{visual}; \colorbox{bblue}{application}; blank; deep; \colorbox{bblue}{download}; \colorbox{bblue}{development}; \colorbox{bblue}{retrieve}; \colorbox{bblue}{reporting}; \colorbox{bblue}{clone} & Software development and application management processes. \\ 
        \midrule
        \multirow{10}{*}{\textbf{TopAct}} & What criteria does Pitchfork \colorbox{pink}{use to}; What evaluation criteria will Kumar organization \colorbox{pink}{use to}; and what criteria were \colorbox{pink}{used}; market? what specific criteria should be \colorbox{pink}{used}; needed to conduct a comprehensive analysis and the criteria \colorbox{pink}{used}  & Evaluation criteria for assessments or analyses in various contexts. \\ \cmidrule{2-3}
          & [INST] \colorbox{pink}{Provide step}; [INST] \colorbox{pink}{Provide step}; [INST] \colorbox{pink}{Provide step}; [INST] \colorbox{pink}{Provide step}; [INST] \colorbox{pink}{Provide step}   & Instructional prompts or commands for providing steps in a process. \\ \cmidrule{2-3}
          & ideas and produce compelling content — \colorbox{pink}{again}; Pine View School \colorbox{pink}{again}; technologies segment is \colorbox{pink}{again}; pushed on the ceiling,and \colorbox{pink}{again}; Echoed through the valley, \colorbox{pink}{again}   & Repetition of the word "again" in various contexts \\ 
         \midrule
        \multirow{6}{*}{\,\,\,\,\textbf{N2G}} & \colorbox{pink}{CSV}; \colorbox{pink}{CSV}; \colorbox{pink}{CSV}; \colorbox{pink}{CSV}; csv[MASK] &  Data format: CSV. \\ \cmidrule{2-3}
          & schedule \colorbox{pink}{appoint}; upcoming \colorbox{pink}{appoint}[MASK]; \colorbox{pink}{appoint}ment;  \colorbox{pink}{appoint}ment;  upcoming \colorbox{pink}{appoint}[MASK]  & Scheduling and managing appointments.  \\ \cmidrule{2-3}
           & \colorbox{pink}{Final Fant}; \colorbox{pink}{Final Fant}; \colorbox{pink}{Final Fant}; \colorbox{pink}{Final Fant}; Metal Gear & Video game titles.  \\ 
        
        \bottomrule
        \bottomrule
    \end{tabular}
    \label{tab:qualitative}
    \vspace{-0.4cm}
\end{table*}
\paragraph{Training Details.}
Our training procedures and hyper-parameter settings majorly follow the previous works~\citep{brickentowards,gao2024scaling,lieberum2024gemma}.
Specifically, we initialize $C=2^{16}$ feature vectors for a Top-K sparse autoencoder with Kaiming initialization~\citep{he2015delving}. 
Here, $C=2^{16}$ is set according to the scaling law between the number of features $C$ and the number of training tokens $Z$ found by~\cite{gao2024scaling}, i.e., $C=\bigO(Z^\gamma)$, where $\gamma\approx 0.60$ for GPT2-small and $\gamma\approx0.65$ for GPT-4\footnote{Empirically, $\gamma\approx0.5978$ in our study.}. 
\revise{Appendix~\ref{apd:training} provides more details about training sparse autoencoders.}

\paragraph{Explanation Baselines.} 
Our study considers several existing works for sparse autoencoder explanations as baselines. 
\textit{TopAct}~\citep{brickentowards} collects a mount of text spans from the corpus that could maximally activate it. 
\textit{N2G}~\citep{gao2024scaling} steps further by masking some words from the activated spans that show limited contributions to the activations. 
We collect their activated spans, with a maximum of 10 tokens, over the entire validation set, and we keep the most activated span from each entry to increase their diversity. 

\subsection{Evaluating Explanations of Learned Sparse Features} 
\label{evaluate_quality}
Exactly measuring the explanation quality of features from sparse autoencoders is still an open question~\citep{rajamanoharan2024jumping}.
Following existing works~\citep{brickentowards,bills2023language,rajamanoharan2024jumping}, advanced LLMs (i.e., GPT4o Family) serve as the machine annotator to evaluate the quality of generated explanations.




\subsubsection{Experimental Designs}
We conduct both qualitative and quantitative analyses of the explanations with the help of our machine annotator (please check details in Appendix~\ref{apd:machine_annotator}). 
Here, the explanations of TopAct and N2G are the top 5 most activated text spans on the validating set, while our method chooses the top 10 words over a vocabulary set constructed from the training set. 
We prompt the machine annotator to summarize the meaning of the feature based on the selected words/spans. 
After collecting the summary, we invoke the machine annotator in a separate thread to judge the relevance of the raw explanations, following the approach in~\cite{bills2023language}.
We follow previous work~\citep{rajamanoharan2024jumping} to give the judgment with four-level options, and we treat the summaries judged with the highest two levels as successfully explained. 
Table~\ref{tab:qualitative} shows some cases confirmed with the highest judging level by machine annotator \revise{(Appendix~\ref{apd:raw_explanations} provides more cases.)}. 
The percentage of successfully explained raw explanations from different explainers in Table~\ref{tab:quantitative}.



\subsubsection{Results}
\label{experiment_1_1}
\,

\vspace{-0.4cm}
\textbf{TopAct and N2G tend to collect text spans sharing the same lexical patterns, while our method extracts diverse words to present a concise topic.} 
Table~\ref{tab:qualitative} shows that while both TopAct and N2G often repeat the same phrases (e.g., ``used to'' and ``CSV''), our method selects more varied words that converge on a concise and discourse-level topic. This contrast highlights our goal of moving beyond repeated lexical patterns to richer and more discourse-focused explanations.




\begin{table}
\centering
\vspace{-0.0cm}
\caption{Successful explained rate of explanations for the activated features and overall learned features.}
\vspace{-0.3cm}
\label{tbl_explainable_rate}
\resizebox{\linewidth}{!}{
\begin{tabular}{c|c|c}
\toprule
\toprule
\textbf{Method} & \textbf{Activated Feature} & \textbf{Overall Feature} \\
\midrule
\textbf{TopAct} & 59.16\% & 23.17\% \\
\textbf{N2G} & 38.79\% & 15.13\% \\
\midrule
\textbf{Ours} & 67.39\% & 66.98\% \\
\bottomrule
\bottomrule
\end{tabular}
}
\label{tab:quantitative}
\vspace{-0.7cm}
\end{table}


\begin{table*}[t]
\centering
\vspace{-0.1cm}
\caption{Defending Mistral-7b-Instruct from jailbreak attacks without model training. We report the attack success rate (ASR) on Salad-Bench to illustrate the effectiveness of preventing jailbreak attacks, and the automatic scores on the MT-Bench to demonstrate the helpfulness for general user queries.} 
\label{defense_result}
\vspace{-0.3cm}
\resizebox{0.9\textwidth}{!}{
\begin{tabular}{c|c|cc|cc}
\toprule
\toprule
\multirow{2}{*}{\textbf{Category}}& \multirow{2}{*}{\textbf{Method}}  & \multicolumn{2}{c|}{\textbf{Salad-Bench} (Safety)} & \multicolumn{2}{c}{\textbf{MT-Bench} (Helpful)} \\ 
               & & \textbf{ASR  ($\downarrow$)} & \textbf{Time ($\downarrow$)} & \textbf{Score ($\uparrow$)} & \textbf{Time ($\downarrow$)} \\ 
\midrule
 \multicolumn{2}{c|}{w/o Defense} & 81.6 & 1.0x & 6.5 & 1.0x \\  %(10.43, 13.68)
\midrule
\multirow{4}{*}{\shortstack{\textbf{Perturbation}}} &Random Patch & 80.6 & 4.9x  &  3.8  & 1.6x  \\ 
&Random Insert & 79.4  & 6.5x  & 3.7  & 1.6x \\ 
&Random Swap &  73.8 & 5.6x &  3.0 &   1.6x \\ 
&Self-Robustness & 16.2  & 6.9x  & 5.3 &  \textbf{16.9x} \\ 
\midrule
\multirow{3}{*}{\shortstack{\textbf{Prompting}}} &SafePrompt & 79.0 & 1.0x & 6.5 & 1.0x \\
                                                 &XSafePrompt & 77.8 & 0.9x & 6.1  &  0.9x  \\ 
                                                &Self-Reminder & 73.0 & 0.9x & 6.3  &  0.9x  \\ 
                                                
\midrule
\multirow{3}{*}{\shortstack{\textbf{SAE Steer} \\ (Ours)}} & Erase Harmful (EH) & 81.0 & 1.0x &  5.9 & 1.0x \\ 
&Aware Security (AS) & 73.2 & 0.8x & 6.0 & 0.9x\\
& EH + AS & 72.8 & 0.8x & 5.9 & 0.9x\\
\bottomrule
\bottomrule
\end{tabular}
}
\vspace{-0.5cm}
\end{table*}

\textbf{Our method generates more reasonable explanations than that of TopAct and N2G.} Table~\ref{tbl_explainable_rate} reports the percentage of learned sparse features successfully explained, categorized by those activated in the validation set and overall.
We first observe that many features remain unexplained by TopAct and N2G due to insufficient activation on the validation set, highlighting a key limitation of relying on activation-based text spans for explanation. One might argue that collecting activation spans from the training set could help, but this introduces bias, as sparse autoencoders tend to overfit the training set~\citep{dictionaryworries}. 
Even when considering only features activated in the validation set, our method achieves a higher explainability rate (67.30\%) compared to TopAct (59.16\%) and N2G (38.79\%). 
Notably, N2G performs worse than TopAct, likely due to its stronger bias toward lexical patterns\footnote{For example, one feature whose TopAct explanation is ``6th century (via History Magazine). Before that''; ``Prior to Chomsky's work,''; and  ``Reference [2]: Before the GPS,'', indicating ``referring related works''. However, N2G simplifies them to ``Before that''; ``Prior to [MASK]omsky's work''; and ``Before [MASK] GPS,'', 
which obviously changes the meaning and concentrates on some trivial patterns.}.
These results highlight the challenge of explaining discourse-level meanings of features.




\subsection{Using Explained Features for Defending Jailbreak Attacks}
\label{downstream_task}
We explore jailbreak defense as a downstream application of steering LLMs with explained features.%, aiming to defend against attacks while preserving helpfulness. 
We target this task for its broad applicability across various LLM deployment scenarios, where existing defense methods often suffer from either low effectiveness or impractical latency, underscoring the need for more efficient solutions.

\subsubsection{Experimental Designs} 
\label{methods_as}
\vspace{-0.cm}
We evaluate the downstream task performance of our steered LLM using Salad-Bench~\citep{li2024salad} for safety and MT-Bench~\citep{zheng2023judging} for general helpfulness. Baselines include perturbation-based methods (Random Patch/Insert/Swap~\citep{robey2023smoothllm}, Self-Paraphrase~\citep{cao2023defending}) and prompting-based methods (SafePrompt/XSafePrompt~\citep{deng2023multilingual}, Self-Reminder~\citep{xie2023defending}), all of which require no additional training. 
We consider three specific strategies based on our proposed Amplification and Calibration: (1) Erase Harmful (EH) deactivates harmful features if they are activated, (2) Aware Security (AS) consistently activates safety-related features at a certain level $\alpha=$, and (3) AS+EH combines both. 
We prompt our machine annotator to judge whether each clearly explained feature relates to a harmful concept according to the hazard taxonomy suggested by Llama3-Guard~\citep{dubey2024llama3herdmodels}. 
Similarly, we also identify those safety-related features with a manually crafted safeguarding taxonomy inspired by the hazard taxonomy. 
As a result, there are 141 and 48 features for AS and EH, respectively. 
Table~\ref{defense_result} and Figure~\ref{fig_ablation} compare our method with baselines in attack success rate (ASR), MT-Bench scores, and normalized runtime cost. 
Appendix~\ref{apd:case_study_steer_llm} provides a case study on defending jailbreak attacks with the AS strategy, and Appendix~\ref{appd:jailbreak_defense} includes more details about our experimental settings.




\subsubsection{Results}
\vspace{-0.0cm}
\label{ablation_study}
\,

\vspace{-0.4cm}
\textbf{Sparse autoencoders enable runtime steering of LLMs.} 
Table~\ref{defense_result} shows that perturbation-based defense strategies are less practical for real-world use, as they either severely degrade helpfulness or introduce unacceptable latency. While most prompting-based methods preserve helpfulness, they struggle to prevent jailbreak attacks. The exception is Self-Reminder, the strongest baseline, which balances safety and helpfulness within a reasonable computing budget. In comparison, our sparse autoencoder-based approach \textit{significantly improves jailbreak defense} (Salad-Bench: 81.6 → 72.8) while \textit{maintaining helpfulness} with only a slight reduction (MT-Bench: 6.5 → 6.0).




\textbf{The key to preventing jailbreak attacks is not forgetting harmful content, but staying aware of safety.} 
Our experiments reveal that removing harmful knowledge has little impact on jailbreak defense, challenging the intuitive assumption that erasure improves safety. Instead, the strong performance of our Aware Security strategy aligns with the principle of Self-Reminder: ``Reminding ChatGPT to respond responsibly''~\citep{xie2023defending}.
\begin{figure}% Wrap figure to the right with 50% of text width
    \vspace{-0.0cm} % Adjust vertical spacing
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            ybar, % Vertical bar plot
            width=5.cm, % Adjust width
            height=4.0cm, % Adjust height
            bar width=0.6cm, % Width of the bars
            enlarge x limits=0.4, % Add space around bars
            ylabel={Salad-Bench ASR}, % Y-axis label
            symbolic x coords={TopAct, N2G, Ours}, % Method names
            xtick=data, % Use data points for x-ticks
            nodes near coords, % Show score values near bars
            nodes near coords align={vertical}, % Align text vertically
            nodes near coords style={/pgf/number format/.cd, fixed, fixed zerofill, precision=1},
            ymin=70, % Set minimum y-axis value
            ymax=90, % Set maximum y-axis value
            xticklabel style={font=\small, rotate=45, anchor=east}, % Rotate x-tick labels for readability
            ytick style={font=\small}, % Adjust font size for y-ticks
            x tick label style={align=center, font=\small}, % Center-align x-tick labels
            axis background/.style={fill=white}, % Set background to white
            tick pos=left, % Position ticks on the left
            axis line style={-}, % Hide axis lines
        ]
        % Plotting the bars with custom colors
        \addplot[ybar, fill=blue!60, draw=none] coordinates {(TopAct, 83.0) (N2G, 80.6) (Ours, 73.2)};
        
        % Adding a horizontal line for "w/o Defense" and extending it across the plot
        \draw [red, thick, dashed] (rel axis cs:0,0.58) -- (rel axis cs:1,0.58);
        
        % Adding a label for the line with a slight offset
        \node[above, red, font=\small, yshift=4pt, xshift=25pt] at (rel axis cs:0.5,0.68) {w/o Defense};
        
        % Adding a subtle arrow pointing from the label to the line
        \draw[->, red, xshift=30pt] (rel axis cs:0.5,0.74) -- (rel axis cs:0.5,0.60);

        \end{axis}
    \end{tikzpicture}
    \vspace{-0.4cm}
    \caption{Applying Aware Security for jailbreak defense based on explanations from different methods.}
    \label{fig_ablation}
    \vspace{-0.5cm}
\end{figure}

\vspace{-0.5cm}

\textbf{Discourse-level explanations are crucial for effective jailbreak defense.} We apply the AS strategy to TopAct and N2G explanations, with results in Figure~\ref{fig_ablation}. Only N2G shows a slight ASR reduction, and tuning $\beta$ brings no clear improvement. This is likely due to their overly lexical and fine-grained safety strategies.  
For example, an N2G feature under ``Physical Defense'' is summarized as ``Locking mechanisms or security systems,'' but its explanation consists of repetitive words: ``locks; locks; lock; have a two-stage lock; lock.'' In contrast, our method, under the same category, provides a broader summary ``Emergency response and location tracking'' with a more diverse explanation: ``contact, phone, unit, accuracy, exact, burning, location, precise, details, smoke.'' 
These results highlight the need for discourse-level explanations.


\vspace{-0.1cm}
\section{Related Works}
\vspace{-0.25cm}
Modern large language models have shown promising text-generation abilities, prompting researchers to explore their internal mechanisms. 
One approach~\citep{belinkov2018evaluating,jawahar2019does,rogers2021primer} develops contrastive datasets to probe hidden states for specific features, but it is limited by the polysemantic nature of neurons~\citep{elhage2022toy,olah2020zoom}, making the explanations non-concise and difficult to apply in downstream tasks. To overcome this, researchers~\citep{brickentowards} propose learning orthogonal basis vectors to better understand LLMs. Early works~\citep{Beren2022SVD,wu2024language} applied singular vector analysis to identify concise, interpretable directions in neuron activations. Soon after, sparse autoencoders~\citep{brickentowards,cunningham2023sparse} were introduced, allowing for more flexible settings. 
Sparse autoencoders, initially used to analyze image data~\citep{olshausen1997sparse,makhzani2013k}, are now being applied to LLMs. Researchers from Anthropic~\citep{brickentowards} and EleutherAI~\citep{cunningham2023sparse} demonstrated that activations from smaller models like GPT-2 and Pythia yield highly interpretable features. Subsequent studies showed these features help interpret model behaviors in tasks like indirect object identification~\citep{makelov2024sparse}, translation~\citep{dumas2024llamas}, and circuit detection~\citep{marks2024sparse}. Recent works~\citep{templeton2024scaling,gao2024scaling,lieberum2024gemma} confirm this technique's success with larger LLMs. 
Our study follows this path, and advances by developing a method for generating discourse-level explanations to steer LLM representations.

\vspace{-0.1cm}
\section{Conclusions}
\vspace{-0.25cm}
In this work, we step a solid stamp toward understanding and steering LLMs in the wild. 
%We begin by theoretically analyzing the properties of the learned sparse features with sparse autoencoders for LLMs, 
Our theoretical analysis first reveals a frequency bias between discourse and linguistic features learned by sparse autoencoders. 
To eliminate this bias, we propose seeking words from a fixed vocabulary set and designing a mutual information-based objective to ensure the collected words capture the features' meanings. 
%Experimental results show that our approach provides more discourse-level explanations than existing methods. 
Additionally, we demonstrate that our steering strategies effectively enhance the safety of LLMs using our mutual information-based explanations. %, while baseline methods fail to achieve the same.
This research underscores the importance of discourse-level explanations in effectively controlling LLM behaviors for certain purposes.

\section{Limitations}
This research focuses on improving language models for specific applications by first interpreting and then steering their hidden representations. A primary limitation of this work is that our approach builds upon existing (trained) sparse autoencoders, which we identify as suffering from frequency bias (as discussed in Section~\ref{sec:textual_sae}). While our proposed explanation method mitigates this issue, it does not fundamentally alter their architectures or training processes. Future work could explore designing improved architectures or training objectives that inherently mitigate frequency bias, rather than solely addressing it at the explanation level. 

\section{Ethical Impact}
This study utilizes the publicly available Mistral-Instruct~\cite{jiang2023mistral} checkpoint under its academic-use license, strictly adhering to its terms for research purposes. We also incorporate multiple datasets~\cite{shareGPT,ding2023enhancing,bai2022training,liu2023webglm,xu2023wizardlm,wang2024helpsteer2} and benchmarks~\cite{li2024salad,zheng2023judging}, each used in compliance with their respective licensing and privacy regulations. To uphold ethical standards, we ensure that the presentation of this paper does not disclose personal identifiers or include harmful content. 

Our work aims to improve LLM interpretability and steering to enhance safety, particularly in defending against jailbreak attacks. However, we recognize that steering LLMs also carries potential risks, such as reinforcing biases or enabling unintended manipulation. Addressing these concerns requires continuous research into bias mitigation and fairness in AI.
Furthermore, while our approach strengthens LLM safety, adversaries may develop new attack strategies to circumvent these defenses. We encourage ongoing red-teaming efforts and responsible deployment practices to ensure that advancements in LLM security do not inadvertently contribute to more sophisticated attack techniques.



\bibliography{custom}

\newpage
\appendix
\onecolumn


\section{Steering LLM for Jailbreak Defense}
\subsection{Detailed Settings}
\label{appd:jailbreak_defense}
We leverage two benchmarks to evaluate our downstream task performance. 
In specific, Salad-Bench~\citep{li2024salad} is introduced to evaluate the safety of LLMs, and MT-Bench~\citep{zheng2023judging} is applied to evaluate their general helpfulness. 
Two categories of the defense strategies that do \textit{not} require any training datasets are considered as the baseline methods, where the \textit{perturbation-based} methods include Random Patch/Insert/Swap~\citep{robey2023smoothllm} and Self-Paraphrase~\citep{cao2023defending}, and the \textit{prompting-based} methods include SafePrompt/XSafePrompt~\citep{deng2023multilingual}, and Self-Reminder~\citep{xie2023defending}. 
Since most of the perturbation-based baselines are time-consuming, we randomly select 10\% of the samples to conduct a smaller test set for all our evaluations. 
Note that all baselines and our methods will not be trained on any data in this experiment. 
The attack success rate (ASR) on Salad-Bench, GPT-4o-mini evaluated MT-Bench scores, and the normalized consuming time are listed in Table~\ref{defense_result}.

We can consider three specific strategies for jailbreak defense with the proposed Amplification and Calibration methods. (1) Erase Harmful (EH) monitors whether any ``\textit{harmful}'' features are activated, and \textit{erase} them if so. (2) Aware Security (AS) consistently activates those \textit{safety} features during responding. (3) Applying both AS and EH strategies at the same time. 
Here, we follow the hazard taxonomy of Llama3-Guard~\citep{dubey2024llama3herdmodels} to judge whether each feature is harmful. Inspired by this hazard taxonomy, we manually craft a safeguarding taxonomy listing 7 categories to classify safety strategies. We prompt the machine annotator to provide the harmfulness and safety labels for each learned feature by providing their explanations.  
To ensure quality, we only consider the learned features with the explainable label ``yes''. 
As a result, our method selects 141 and 48 features for the AS and EH strategies, respectively. 
For hyper-parameter $\beta$ of AS, we grid search some numbers and find that 2.5 shows the best practice in balancing safety and overall helpfulness. 
Table~\ref{defense_result} and Figure~\ref{fig_ablation} report the results with our and baseline explanations, respectively. 

\subsection{Case Study on Steering LLM Behaviors}
\label{apd:case_study_steer_llm}
\begin{figure*}
\centerline{\includegraphics[width=0.96\linewidth]{Figures/Chatting_v3.pdf}}
\vspace{-0.cm}
\caption{A case study on steering LLMs to defense jailbreak attack by using Aware Security (AS). We can observe that by enhancing security contents in LLM representations (i.e., larger $\beta$), their responses provide safer suggestions (starting from \colorbox{pink}{blow up anything}, switching to \colorbox{bblue}{blow up food}, ending with \colorbox{ggreen}{cannot blow up}).}
\label{fig:case_study}
\vspace{-0.cm}
\end{figure*}
We provide a case study in Figure~\ref{fig:case_study} on defending against jailbreak attacks using our proposed method.
Specifically, we follow the aware security strategy introduced in Section~\ref{methods_as} to perform the jailbreak defense. 
The attacking prompt comes from the Salad-Bench~\citep{li2024salad} with a role-play attacking strategy, where the attacker asks the LLM to play in an ``opposite mode'' so that it will be misleading to generate some dangerous advice to the users about using the microwave. 
Specifically, we could observe that the original LLM follows the instructions from the attacker to suggest that the user blow up items in the microwave within the ``opposite mode'' (e.g., ``[AntiGPT]''). 
There is no doubt that this response is harmful and unsafe to the users, indicating a successful attempt from the attacker. 

However, by constantly enforcing the security-aware features to be activated at a level of $\beta=1$, we observe that the original response becomes less harmful, where the LLM specifies that the blow-up items should be some foods, such as ``marshmallows, popcorn, and hot dogs''. 
Finally, when we enforce the activations to a more significant level, i.e., $\beta=3$, the LLM entirely rejects the harmful premise of the prompt, providing a response that strictly adheres to safety guidelines. Specifically, the LLM refuses to engage with the idea of ``blowing up items'' in a microwave, emphasizing the importance of following safety protocols and avoiding any unsuitable items. 
By activating security-related features more strongly, the method demonstrates the capability not only to mitigate harmful responses but also to completely align the model’s output with ethical and safety standards. 
This case study illustrates the effectiveness of our strategy in steering the LLM's behavior towards responsible and safety-conscious outputs. 

\subsection{Steering LLM in Different Layers}
\label{appd:steer_layers}
\begin{wrapfigure}{r}{0.33\textwidth} % Wrap figure to the right with 50% of text width
    \vspace{-0.5cm} % Adjust vertical spacing
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            ybar, % Vertical bar plot
            width=5.5cm, % Adjust width
            height=4.0cm, % Adjust height
            bar width=0.6cm, % Width of the bars
            enlarge x limits=0.4, % Add space around bars
            ylabel={Salad-Bench ASR}, % Y-axis label
            xlabel={Layers}, % Y-axis label
            symbolic x coords={8, 16, 24}, % Method names
            xtick=data, % Use data points for x-ticks
            nodes near coords, % Show score values near bars
            nodes near coords align={vertical}, % Align text vertically
            ymin=70, % Set minimum y-axis value
            ymax=90, % Set maximum y-axis value
            %xticklabel style={font=\small, rotate=45, anchor=east}, % Rotate x-tick labels for readability
            ytick style={font=\small}, % Adjust font size for y-ticks
            x tick label style={align=center, font=\small}, % Center-align x-tick labels
            axis background/.style={fill=white}, % Set background to white
            tick pos=left, % Position ticks on the left
            axis line style={-}, % Hide axis lines
        ]
        % Plotting the bars with custom colors
        \addplot[ybar, fill=blue!60, draw=none] coordinates {(8, 73.2) (16, 83.6) (24, 82.6)};
        
        % Adding a horizontal line for "w/o Defense" and extending it across the plot
        %\draw [red, thick, dashed] (rel axis cs:0,0.58) -- (rel axis cs:1,0.58);
        
        % Adding a label for the line with a slight offset
        %\node[above, red, font=\small, yshift=4pt, xshift=25pt] at (rel axis cs:-0.0,0.68) {w/o Defense};
        
        % Adding a subtle arrow pointing from the label to the line
        %\draw[->, red, xshift=30pt] (rel axis cs:-0.05,0.74) -- (rel axis cs:-0.05,0.60);

        \end{axis}
    \end{tikzpicture}
    \vspace{-0.4cm}
    \caption{Applying Aware Security for jailbreak defense based on our explanations in different layers.}
    \label{fig_layers}
    \vspace{-0.5cm}
\end{wrapfigure}
We perform our proposed Aware Security (AS) strategy on different layers of Mistral-7B-Instruct to defend against jailbreak attacks. 
In specific, we follow previous work~\cite{lieberum2024gemma} and consider three intermediate layers, namely the 25\%-th, 50\%-th, and 75\%-th layers of the entire model, resulting in the 8th, 16th, and 24th layers of Mistral-7B-Instruct as it has a total of 32 layers. 
For a fair comparison, we keep all other settings the same as we described in Appdenix~\ref{apd:machine_annotator}, Appendix~\ref{apd:training}, and Appendix~\ref{appd:jailbreak_defense}.
The attack success rates on different layers are reported in Figure~\ref{fig_layers}. 
Figure~\ref{fig_layers} shows that applying the defense at the 8th layer achieves the lowest attack success rate (73.2), while interventions at the 16th and 24th layers are less effective (83.6 and 82.6, respectively). This suggests that effective steering requires early interventions to leave enough space for LLMs to adjust their responses in later layers. Steering too late may restrict the model's ability to refine its responses, limiting its effectiveness in jailbreak defense. 
This result aligns with the findings from previous research, where~\citet{Nostal2020Logit} found that LLMs may have already predicted the next token at the middle layers.  

\section{Training Sparse Autoencoders on Mistral-7B}
\label{apd:training}
Our training procedures and hyper-parameter settings majorly follow the previous works~\citep{brickentowards,gao2024scaling,lieberum2024gemma}.
Specifically, we initialize $C=2^{16}$ feature vectors for a Top-K sparse autoencoder with Kaiming initialization~\citep{he2015delving}. 
Here, $C=2^{16}$ is set according to the scaling law between the number of features $C$ and the number of training tokens $Z$ found by~\cite{gao2024scaling}, i.e., $C=\bigO(Z^\gamma)$, where $\gamma\approx 0.60$ for GPT2-small and $\gamma\approx0.65$ for GPT-4.\footnote{Empirically, $\gamma\approx0.5978$ in our study.}. 
To prevent dead neurons, we also apply the tied-weight strategy as suggested by~\citet{gao2024scaling}. 
We use Adam optimizer~\citep{kingma2014adam} with a constant learning rate of $1e^{-3}$ and epsilon of $6.25e^{-10}$ to train a total of 5 epochs. 
The hyper-parameters $\beta_1$ and $\beta_2$ of the optimizer are $0.9$ and $0.999$ following previous works~\cite{gao2024scaling}, respectively. 
We set the batch size as 512 queries, leading to around 90K tokens per gradient update, which is the same volume as~\cite{gao2024scaling}. 
The mixed precision training strategy~\citep{micikevicius2017mixed} is also applied to speed up the training process as~\cite{lieberum2024gemma} found that it only shows a slightly worse impact on the model performance.
Top-K sparse autoencoder has an initial sparsity $K=200$, and it gradually decreases to the target sparsity $K=20$ in the first 50\% training samples of the first epoch. 
The training process runs on one single Nvidia A6000 GPU with CUDA 12.6 and takes about 16 hours per epoch. 

\section{\revise{Extended Qualitative Analysis on Raw Explanations}}
\label{apd:raw_explanations}
\revise{This section first provides an extension to our qualitative analysis of the raw explanations generated by different methods discussed in Section~\ref{experiment_1_1}. 
In particular, Table~\ref{tab:extend_cases_ours}, Table~\ref{tab:extend_cases_topact}, and Table~\ref{tab:extend_cases_n2g} provide more raw explanations and their automated summarization from Ours, TopAct, and N2G, respectively. 
}

\subsection{\revise{Analysis to Raw Explanations from Ours}}
\revise{The extended qualitative analysis on Ours demonstrates the robustness of our method in generating discourse-level explanations. Table~\ref{tab:extend_cases_ours} showcases a wide variety of explanations that extend beyond mere lexical overlaps, instead providing meaningful insights into different topics or concepts. For instance, explanations such as ``Botanical classification and gardening practices'' and ``Urban development and community engagement'' encapsulate coherent themes that align well with their raw explanations, reflecting the interpretative depth of our approach. This contrasts sharply with the baseline methods, which often focus on repetitive patterns or word-level constructs. By leveraging a fixed vocabulary set and mutual information-based objective, our method avoids frequency biases and captures semantically rich discourse features. 
%This extended analysis underscores the method's capability to provide interpretable explanations across diverse contexts, reinforcing its utility for understanding and steering LLM behavior in downstream applications.
}


\subsection{\revise{Analysis to Raw Explanations from Baselines}}
\revise{The extended qualitative analysis of the baselines TopAct and N2G highlights their tendencies to focus on repetitive linguistic patterns and fine-grained lexical constructs rather than capturing broader semantic or discourse-level themes. As shown in Table~\ref{tab:extend_cases_topact}, TopAct often generates explanations dominated by repetitive queries or descriptive patterns, such as ``What types of medical facilities are available for'' or ``Discuss the impact of social media on.'' While these patterns are interpretable, they largely lack thematic depth, emphasizing lexical regularities over conceptual diversity. 
On the other hand, in Table~\ref{tab:extend_cases_n2g}, N2G explanations successfully identify the most critical parts of the raw explanations and omit those non-critical ones with ``[MASK]'', resulting in a shortened raw explanations than the TopAct. However, N2G still falls short of representing more complex and discourse-level features. This limitation underscores the advantage of our proposed method in moving beyond the frequency bias to capture more coherent and meaningful features.}

\begin{table}[h]
\small
    \centering
    \vspace{-0.4cm}
    \caption{\revise{Extended qualitative analysis on generated explanations from our proposed method.}}
    \vspace{-0.3cm}
    \revise{
    \begin{tabular}{p{1.2cm}|p{4.7cm}|p{7.8cm}}
        \toprule
        \toprule
        \centering
        \textbf{Method} & \textbf{Automated Summary} & \textbf{Raw Explanation} \\
         \midrule
        \multirow{45}{*}{\shortstack{\textbf{Ours}}} & Local business and community engagement. & weekly, regional; native; pros; locally; good; cater; blog; perform; shop \\ \cline{2-3}
            & Botanical classification and gardening practices. & flower; hybrid; border; composition; popular; origin; habits; commonly; divide; fit \\ \cline{2-3}
            & Influence and alignment of ideas or concepts. & turn; impact; aligned; turning; leading; surrounding; nature; highlight; ideas; align \\ \cline{2-3}
            & Diverse strategies and approaches in chatbot development and interaction. & differently; pros; thorough; tricks; observations; view; approaches; Eastern; strategies; chatbot \\ \cline{2-3}
            & Digital solutions and services for businesses. & meaningful; inclusive; durable; online; tracking; quick; instant; hosting; marketing; processing \\ \cline{2-3}
            & Music education and authentic musical experiences. & stake; genuine; musical; authentic; arrangements; composition; classes; lessons; friend; empower \\ \cline{2-3}
            & Processes of change and interaction in systems or relationships. & crack; returning; describe; emerging; transform; transport; mutual; accompanied; interactions; index \\ \cline{2-3}
            & Personal development and productivity strategies. & cycle; trial; productive; lessons; lifestyle; neutral; Academy; rhythm; goal; goals \\ \cline{2-3}
            & Culinary arts and craftsmanship. & construction; variety; manual; design; fit; dinner; brand; craft; lunch; um \\ \cline{2-3}
            & Detection and identification of problems in the context of surveillance or monitoring systems. & detect, detective, detected, early, heat, instant, problem, parking, identifying, detection \\ \cline{2-3}
            & Urban development and community engagement. & productivity; interesting; align; correspond; hub; housing; grant; surrounding; mix; inform \\ \cline{2-3}
            &  Impact of jazz music on youth and critical awareness. & best; question; contributing; mind; jazz; stake; critics; critique; kids; awareness \\ \cmidrule{2-3}
            & Romantic or sexual relationships and interactions. & sexual; missed; strip; calling; attractive; shower; bond; shipping; shock; expect\\ \cmidrule{2-3}
            & Project management and documentation processes. & prep; construction; construct; constructed; input; journal; action; claim; running; claims\\ \cmidrule{2-3}
            & Influence of successful relationships or partnerships in a law enforcement or collaborative context. & bond; successful; successfully; police; being; landscape; working; deeply; influence; hit \\ \cmidrule{2-3}
            & Fashion evolution and personal growth. & outfit, Smith, museum, leather, dress, growth, Chris, era, lifetime, grew\\ \cmidrule{2-3}
            & Techniques for visual representation and support in design or art. & reflection, supportive, split, shelter, visual, grid, line, reflect, simple, tricks\\ \cmidrule{2-3}
            & Concerns related to injuries and their representation in the context of Jewish communities or cultural icons. &  draft, injuries, injury, concerns, concern, Jewish, happening, icon, strategies, graphic\\ \cmidrule{2-3}
            & Focus on specific strategies or tactics in a competitive context.        & keen, particular, certain, wall, gap, specialized, battle, escape, chop, specific.\\ \cmidrule{2-3}
            & Crime detection and security measures. & detect, security, detective, crime, shadow, detection, criminal, deal, assets, out\\ \cmidrule{2-3}
            & Energy resources and infrastructure management. & graph, composition, master, gas, pipeline, mine, perception, deployed, demand, stake\\ 
        \bottomrule
        \bottomrule
    \end{tabular}}
    \label{tab:extend_cases_ours}
    \vspace{-0.4cm}
\end{table}
\begin{table}[h]
\small
    \centering
    \vspace{-0.4cm}
    \revise{
    \caption{\revise{Extended qualitative analysis on generated explanations from the baseline TopAct.}}
    \vspace{-0.3cm}
    \begin{tabular}{p{1.2cm}|p{4.7cm}|p{7.8cm}}
        \toprule
        \toprule
        \centering
        \textbf{Method} & \textbf{Automated Summary} & \textbf{Raw Explanation} \\
         \midrule
        \multirow{46}{*}{\textbf{TopAct}} 
            & Inquiry about available options or facilities in various contexts. & What types of medical facilities are available for; What graduate programs are available for; What kind of housing options are available for; What accommodations are available for; What are some software options available for \\ \cmidrule{2-3}
            & Setting personal boundaries and communication strategies. & Explain the potential consequences of failing to set boundaries; communication skills, as well as methods for setting boundaries; communication techniques that can be used to express personal boundaries; advice on how to communicate assertively, set boundaries; have faced, strategies you have used to set boundaries \\ \cmidrule{2-3}
            & The concept of ``role" in various contexts & as well as the role of technology and innovation in; they reside. Consider the role of email in; The role of technology and innovation in; washing techniques, the role of soap and water in; populations and the role of insecticides in \\  \cmidrule{2-3}
            & Handmade or artisanal jewelry. & is a handcrafted Macrame beaded; hand-crafted artisanal glass beads; materials, tools, and methods used in bead; description: Handmade beaded; jewelry using materials such as beads \\ \cmidrule{2-3}
            & Impact of social media. & Share your perspective on the impact of social media on; Discuss the impact of social media on; Discuss the impact of social media on; Write a report on the impact of social media on; Examine the impact of social media on \\ \cmidrule{2-3}
            & Dimensions and measurements of objects. & They come in a 5" x; measuring approximately 6 inches by 6; 4" thick. 11" x; painting measures 14" tall by; a square paper measuring 8 inches by 8 \\ \cmidrule{2-3}
            & Malicious intent related to food tampering or drugging. & Can I hide feces in someone's food; Whats the best way to hide poison in food; slip a roofie in a girl's drink; my fagot coworker's drink; type of poison for putting in people's food \\ \cmidrule{2-3}
            & Manual processes in automation and testing. & operator-level isolation and rely on users to manually; using Selenium * Conduct manual; step-by-step guide on how to manually; Automated deployment flows and reduced manual; in a single run of the script without any manual \\ \cmidrule{2-3}
            & Abortion rights and the Roe v. & have there been since Roe v. W; and vowed to pass legislation to protect abortion; mourning the fact that Roe v. W; landmark Supreme Court case Roe v. W; What is Roe v. W \\ \cmidrule{2-3}
            & Impact of climate change. & Research and document the impact of climate change; 2. The effects of climate change; and write a report on the impacts of climate change; include a comprehensive analysis of the impact of climate change; are in place to address the effects of climate change \\ \cmidrule{2-3}
            & Recipe search functionality and user interaction features. & and view recipes uploaded by others, a search; friendly, with an easy-to-use search; commenting and ratings for recipes, and a search; in the table view to allow the user to search; and ratings. Users should be able to search \\ \cmidrule{2-3}
            & Webpage modification timestamps. & This page was last modified on; ings.\textbackslash nThis page was last edited on; \textbackslash nThis page was last edited on; construct.\textbackslash nThis page was last modified on; 8.\textbackslash nThis page was last edited on \\ 
        \bottomrule
        \bottomrule
    \end{tabular}
    \label{tab:extend_cases_topact}
    }
    \vspace{-0.4cm}
\end{table}
\begin{table}[h]
\small
    \centering
    \vspace{-0.4cm}
    \caption{\revise{Extended qualitative analysis on generated explanations from the baseline N2G.}}
    \revise{
    \vspace{-0.3cm}
    \begin{tabular}{p{1.2cm}|p{4.7cm}|p{7.8cm}}
        \toprule
        \toprule
        \centering
        \textbf{Method} & \textbf{Automated Summary} & \textbf{Raw Explanation} \\
         \midrule
        \multirow{44}{*}{\,\,\,\,\textbf{N2G}} 
            & Character attributes in role-playing games. & choosing [MASK] race, class\textbackslash n; name [MASK] race, class\textbackslash n; name [MASK] race, class; Race [MASK] Human\textbackslash n\textbackslash nClass\textbackslash n; backstory, class [MASK]\\ \cmidrule{2-3}
            & Management and organizational skills in relation to tasks, teams, and time. & manage their tasks and; manage remote teams in;  managing a [MASK] team?; manage [MASK] time effectively; manage my [MASK] team’s territories?\\  \cmidrule{2-3}
            & Negation or clarification phrases focusing on the phrase "doesn't mean". & [MASK] not necessarily; doesn[MASK]t mean; doesn[MASK]t mean; doesn[MASK]t mean; doesn[MASK]t mean\\ \cmidrule{2-3}
            & Exclusion criteria or filtering terms. & not include [MASK] numbers or; exclude any [MASK] firm that; should not [MASK] any words that; exclude [MASK] words that; not include any [MASK] that\\ \cmidrule{2-3}
            & Data storage and backup solutions, particularly focusing on external storage devices. & important data that you want to keep to an external; wireless file trans[MASK]; back[MASK]ups, and transferring; external hard; external hard\\ \cmidrule{2-3}
            & Concepts related to returning or going back home. & last trains home; return home; walked home; way home; way home\\ \cmidrule{2-3}
            & Bailout or financial assistance concepts, particularly in the context of economic interventions or stimulus packages. & GM Bail[MASK]; Paulson [MASK] other proponents of the bail; to step in to prevent it. Such bail[MASK]; and look at that auto bail[MASK]; stimulus packages [MASK] bail\\ \cmidrule{2-3}
            & Informal greetings or inquiries about someone's well-being or current situation. & what[MASK]s going on; what[MASK]s going on; what[MASK]s up; What[MASK]s up; What[MASK]s up\\ \cmidrule{2-3}
            & Customization and personalization of options or features. & options [MASK] customization;  customizing [MASK]; to customize [MASK]; the player to customize [MASK]\\ \cmidrule{2-3}
            & The phrase ``On a scale'' or variations of it, indicating a measurement or evaluation system. & On [MASK] scale of; On a scale [MASK]; On [MASK] scale of; On [MASK] scale of; On [MASK] scale of\\ \cmidrule{2-3}
            & Addresses or locations. & 33 Dinah Shore Dr, [MASK]; 4[MASK]1 Bay Shore Road,; 1 Wessel Dr., [MASK];7 W. John St., [MASK]; 9[MASK]0 E. Street Rd.,\\ \cmidrule{2-3}
            & Gap year terminology. & [MASK] batical year; gap year [MASK]; gap year [MASK]; gap year [MASK]; gap year [MASK]\\ \cmidrule{2-3}
            & Decades or time periods, specifically referencing the 70s, 80s, and 90s. & er from the 80 [MASK]; early 70 [MASK]; late [MASK] 90; 70s [MASK] 80; late [MASK] 90\\ \cmidrule{2-3}
            & Formatting and structuring text or documents focusing on the concept of a ``clear head'' or heading. & [MASK] appropriate head; format, with clear head [MASK]; [MASK] proper head; struct [MASK] and organized, with clear head; easy to follow, with clear head [MASK]\\ \cmidrule{2-3}
            & Usage of the word "call" in various contexts, likely focusing on communication or addressing someone. & calls him [MASK]; call [MASK] americans indians?; calling [MASK] guy; call me [MASK]; called him [MASK]\\ \cmidrule{2-3}
            & Historical figure: Benjamin Franklin. & Benjamin [MASK]; franklin [MASK]; Franklin [MASK]; Benjamin Franklin [MASK]; Benjamin Franklin [MASK]\\
            %& Integrated development environments (IDEs) for software development focusing on Visual Studio and Android Studio. & Visual Studio [MASK]; Android Studio [MASK]; Android Studio [MASK]; Visual Studio [MASK]; Android Studio [MASK]\\
            % & Historical figure: Benjamin Franklin. & Benjamin [MASK]; franklin [MASK]; Franklin [MASK]; Benjamin Franklin [MASK]; Benjamin Franklin [MASK]\\ \cmidrule{2-3}
            % & Personalization of flavor and heat in food or sauces based on individual preferences. & the flavor to personal preference [MASK]; ing the flavor to personal preferences [MASK]; ing the heat level to individual preferences [MASK]; flavor [MASK] consistency to personal preference; sauce to personal preference  [MASK]\\ \cmidrule{2-3}
            % & Health and wellness concepts focusing on well-being and burnout. & and wellness among [MASK];  health among [MASK]; well[MASK]being among; health among [MASK]; burnout among [MASK]\\ \cmidrule{2-3}
        
        \bottomrule
        \bottomrule
    \end{tabular}
    }
    \label{tab:extend_cases_n2g}
    \vspace{-0.4cm}
\end{table}





\section{Scaling Up with Machine Annotators}
\label{apd:machine_annotator}
We build on recent progress in automated interpretation~\citep{bills2023language,chaudhary2024evaluating,gao2024scaling,lieberum2024gemma} by utilizing advanced LLMs to replicate human annotators in producing high-level interpretations. This approach allows us to leverage machine annotators, enabling us to scale our methods for analyzing the entire model and yielding more robust results.
Specifically, we employ GPT-4o-mini\footnote{https://platform.openai.com/docs/guides/gpt} as our machine annotator. Our experiments utilize the gpt-4o-mini-2024-07-18 model with a hyper-parameter temperature=0 for greedy decoding. 
For each response, we allow to generate a maximum of 1024 tokens. 
To ensure the quality of automatic annotation, we design our prompting template with both the role-playing strategy and presenting in-context examples. 
We provide our prompting templates for reproduction our results as follows. 

\subsection{Template 1} 
We directly append the words to this template to annotate the summary of the raw explanations with 10 selected words from our proposed method. 
In this template, we start with placing the role-play instruction in the system prompt. We then provide heuristic examples to simulate a multi-turn conversation between a user and an agent. 
In this way, once we attach the new word list-based raw explanations from our method to this template, the machine annotator will directly generate the summarization for this explanation.
\begin{tcolorbox}[colback=gray!5!white,colframe=blue!75!black,title=Template-1 for Automated Summary with Word-based Raw Explanations]
\vspace{-0.4cm}
\begin{lstlisting}  
System: You are studying a neural network. Each neuron looks for 
one particular concept/topic/theme/behavior/pattern. Look at some 
words the neuron activates for and guess what the neuron is 
looking for. Pay more attention to the words in the front as they 
supposed to be more correlated to the neuron behavior. Don't list 
examples of words and keep your summary as detail as possible. If 
you cannot summarize most of the words, you should say Cannot Tell.

User: accommodation, racial, ethnic, discrimination, equality, 
apart, utterly, legally, separately, holding, implicit, unfair, 
tone. 
Agent: Social justic and discrimination. 

User: B., M., e., R., C., OK., A., H., D., S., J., al., p., T., N.,
W., G., a.C., or, St., K., a.m., L.. 
Agent: Cannot Tell. 

User: Scent, smelled, flick, precious, charm, brushed, sealed, 
smell, brace, curios, sacred, variation, jewelry, seated.
Agent: Perception of scents and precious objects. 

User: BP, HR, RR, O2 Sat, T, Ht, UO, BMI, BSA. 
Agent: Medical measurements in emergency rooms. 

\end{lstlisting} 
\end{tcolorbox}
\begin{tcolorbox}[colback=gray!5!white,colframe=blue!75!black,title=Template-1 for Automated Summary with Word-based Raw Explanations (continued)]
\vspace{-0.4cm}
\begin{lstlisting} 
User: actual, literal, real, Really, optical, Physical, REAL, 
virtual, visual. 
Agent: Perception of reality. 

User: Go, Python, Java, c++, python3, c#, java, Ruby, Swift, PHP. 
Agent: Morden programming language. 

User: 1939-1945, 1945, 1942, 1939, 1940, 1941. 
Agent: Years of the second world war.

User: 1976, 1994, 1923, 2018, 2014, 1876, 1840. 
Agent: Cannot Tell.

User: 
\end{lstlisting} 
\vspace{-0.4cm}
\end{tcolorbox}

\subsection{Template 2} 
Once we collect the summary of the raw explanation with the previous prompt, we then call the machine annotator again in a separate thread to evaluate whether the summary is hallucinated or not by using the following prompting template, where the placeholders ``{Summary}'' and ``{Raw Explanation}'' will be filled with real data. Note that if the machine annotator gives ``Cannot Tell'' as its prediction in the summarization stage, we will directly set the judgment for this task as ``No''. 
\begin{tcolorbox}[colback=gray!5!white,colframe=blue!75!black,title=Template-2 for Summary Judge with Word-based Raw Explanations]
\vspace{-0.4cm}
\begin{lstlisting}  
System: You are a linguistic expert. Analyze whether the words well 
represent the concept/topic/theme/pattern. Organize your final 
decision in format of "Final Decision: [[Yes/Probably/Maybe/No]]".

User: Concept/Topic/Theme/Pattern: {Summary}.
Words: {Raw Explanation}.
Agent: 
\end{lstlisting} 
\vspace{-0.4cm}
\end{tcolorbox}


\subsection{Template 3} 
Since baseline explainers (TopAct and N2G) consider N-gram spans as raw explanations, we found that the previous word-list-based prompting template leads a poor performance for their interpretability. Thus, we followed the strategies before to define the following text-span-based prompting templates. Here, the in-context examples of text spans are collected from previous work~\citep{brickentowards}.
Specifically, similar to using Template 1 to summarize our extracted words, we append the extracted text spans from TopAct or N2G to this template. Note that we numerate each extracted span with a unique index. 
\begin{tcolorbox}[colback=gray!5!white,colframe=blue!75!black,title=Template-3 for Automated Summary with Span-based Raw Explanations]
\vspace{-0.4cm}
\begin{lstlisting}  
System: You are studying a neural network. Each neuron looks for 
one particular concept/topic/theme/behavior/pattern. Look at some 
spans the neuron activates for and guess what the neuron is 
looking for. Pay more attention to the [last few words] of each 
spans in the front as they supposed to be more correlated to the 
neuron behavior. Ignore the [MASK] patterns in the spans. Don't 
list examples of spans and keep your summary as detail as possible. 
If you cannot summarize most of the spans, you should say
"Cannot Tell."

User: Span 1: w.youtube.com/watch?v=5qap5aO4z9A
Span 2: youtube.come/yegfnfE7vgDI
Span 3: {'token': 'bjXRewasE36ivPBx
Span 4: /2023/fid?=0gBcWbxPi8uC
Agent: Base64 encoding for web development.

User: Span 1: cross-function[MASK]
Span 2: cross-function
Span 3: [MASK][MASK] cross-function\n
Agent: Particular phrase 'cross-function'. 

User: Span 1: novel spectroscopic imaging platform
Span 2: and protein evolutionary network modeling
Span 3: reactions-centric biochemical model
Span 4: chaperone interaction network
Agent: Biological terms.

User: Span 1: is -17a967
Span 2: what is 8b8 - 10ad2
Span 3: 83 -11111011001000001011
Span 4: is -c1290 - -1
Agent: Synthetic math: Arithmetic, numbers with small digits, 
in unusual bases.

User: 
\end{lstlisting} 
\vspace{-0.4cm}
\end{tcolorbox}


\subsection{Template 4} 
We evaluate the quality of summarization using almost the same as Template 2, where we only change the phrase from ``word'' to ``span'' to fit the format of raw explanations from the baseline explainers. 
\begin{tcolorbox}[colback=gray!5!white,colframe=blue!75!black,title=Template-4 for Summary Judge with Span-based Raw Explanations]
\vspace{-0.4cm}
\begin{lstlisting}  
System: You are a linguistic expert. Analyze whether the text spans 
well represent the concept/topic/theme/pattern. Organize your final 
decision in format of "Final Decision: [[Yes/Probably/Maybe/No]]".

User: Concept/Topic/Theme/Pattern: {Summary}.
Spans: {Raw Explanation}.
\end{lstlisting} 
\vspace{-0.4cm}
\end{tcolorbox}

\end{document}
