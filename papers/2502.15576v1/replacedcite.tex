\section{Related Works}
\vspace{-0.25cm}
Modern large language models have shown promising text-generation abilities, prompting researchers to explore their internal mechanisms. 
One approach____ develops contrastive datasets to probe hidden states for specific features, but it is limited by the polysemantic nature of neurons____, making the explanations non-concise and difficult to apply in downstream tasks. To overcome this, researchers____ propose learning orthogonal basis vectors to better understand LLMs. Early works____ applied singular vector analysis to identify concise, interpretable directions in neuron activations. Soon after, sparse autoencoders____ were introduced, allowing for more flexible settings. 
Sparse autoencoders, initially used to analyze image data____, are now being applied to LLMs. Researchers from Anthropic____ and EleutherAI____ demonstrated that activations from smaller models like GPT-2 and Pythia yield highly interpretable features. Subsequent studies showed these features help interpret model behaviors in tasks like indirect object identification____, translation____, and circuit detection____. Recent works____ confirm this technique's success with larger LLMs. 
Our study follows this path, and advances by developing a method for generating discourse-level explanations to steer LLM representations.

\vspace{-0.1cm}