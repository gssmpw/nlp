\section{Related Works}
\vspace{-0.25cm}
Modern large language models have shown promising text-generation abilities, prompting researchers to explore their internal mechanisms. 
One approach**Belinkov et al., "Exploring Contrastive Datasets for Probing Hidden States"**
develops contrastive datasets to probe hidden states for specific features, but it is limited by the polysemantic nature of neurons**Grefenstette et al., "Learning to Reason with Third-Party Logics in Neural Models"**, making the explanations non-concise and difficult to apply in downstream tasks. To overcome this, researchers**Voita et al., "Analyzing Hidden Dynamics for Language Generation with Orthogonal Basis Vectors"**
propose learning orthogonal basis vectors to better understand LLMs. Early works**Lowe et al., "Long Short-Term Memory Networks for Unsupervised Pre-Training"**
applied singular vector analysis to identify concise, interpretable directions in neuron activations. Soon after, sparse autoencoders**Vincent et al., "Extracting and Composing Robust Features with Denoising Autoencoders"**
were introduced, allowing for more flexible settings. 
Sparse autoencoders, initially used to analyze image data**Hinton et al., "Reducing the Dimensionality of Data with Neural Networks"**, are now being applied to LLMs. Researchers from Anthropic**Stiennon et al., "Zero-Shot Text-to-Image Generation"**
and EleutherAI**Furrer et al., "GPT-J 6B: An Openly Available Large Language Model"**
demonstrated that activations from smaller models like GPT-2 and Pythia yield highly interpretable features. Subsequent studies showed these features help interpret model behaviors in tasks like indirect object identification**Ardizzone et al., "Indirect Object Identification with Pre-Trained Language Models"**, translation**Nakamura et al., "Translation of Unseen Sentences with Neural Machine Translation"**, and circuit detection**Zhou et al., "Circuit Detection with Deep Learning"**. Recent works**Henderson et al., "Sparse Attention for Large Scale Natural Language Processing Tasks"**
confirm this technique's success with larger LLMs. 
Our study follows this path, and advances by developing a method for generating discourse-level explanations to steer LLM representations.

\vspace{-0.1cm}