
\section{Introduction}

% 芯片发展迅速，光刻耗资巨大，模拟器能节约成本，有许多新提出的模拟器，但是Resist model成为它们的制约

The rapidly growing demand for computational density in modern AI applications, such as LLMs \cite{liu2024deepseek,achiam2023gpt,wang2024moreaupruner} and generative AI (GenAI)\cite{rombach2022high,wang2023evaluation} models,4,5 poses significant challenges to the electronics industry. As semiconductor nodes continue to shrink and transistor counts rise, optical lithography\cite{mack2007fundamental}, a critical technology in semiconductor manufacturing, has become indispensable in current integrated circuit (IC) fabrication processes, accounting for approximately 30\% to 40\% of production costs. To reduce these costs, various lithography simulators have been developed\cite{banerjee2013iccad,chen2024open,fuilt,watanabe2017accurate,fuhner2014artificial}. Recent advancements leverage the computational power of GPUs and machine learning (ML)\cite{yu2007true,wang2023diffpattern,watanabe2017accurate,wang2024chatpattern,chen2024ultra} techniques to accelerate simulations. However, their inadequate resist modeling capabilities reduce the overall effectiveness and accuracy of these lithography simulators.


The basic principle behind the operation of a photoresist is the change in solubility of the resist in a developer upon exposure to light\cite{mack2007fundamental}. The modeling of the resist process\cite{dill1975characterization,mack1987development} commonly involves multiple steps after exposure. These steps include post-exposure bake (PEB), development, and postbake. A simplified process is illustrated in \Cref{fig:pipeline}. During exposure, a strong acid is generated. However, this acid alone does not change the solubility of the resist. During the PEB process, the photogenerated acid catalyzes a reaction that alters the solubility of the polymer resin in the resist. This reaction creates a solubility differential between the exposed and unexposed regions of the resist. Additionally, the PEB process facilitates acid diffusion, which helps to remove standing waves. Development\cite{sethian1996fast} is one of the most critical steps in the photoresist process. In this step, the resist dissolves in the developer, leaving behind the designed patterns on the photoresist. These patterns are used for further pattern transfer. Finally, postbake is applied to harden the resist image. This step ensures that the resist can withstand harsh environments, such as implantation or etching. 

In the early stages of lithography, researchers focused on accurately modeling the physical-chemical processes to predict and control the resist behavior, achieving significant success at larger nodes\cite{thackeray2013pursuit,smith2004lithographic}. However, as lithography progresses to advanced, smaller nodes, strict analytical modeling of the resist process becomes increasingly difficult due to the intricate physical-chemical interactions\cite{thackeray2007chemically} at the nanometer scale and the growing complexity of production techniques\cite{thackeray2011materials}. In recent years, a variety of threshold-based\cite{randall1999variable} and network-based resist models\cite{zach2004neural} have been developed. Threshold-based methods are valued for their simplicity and computational efficiency but are constrained by limited model capacity. In contrast, network-based methods leverage neural networks to model the resist process, iteratively updating the network's parameters using existing aerial-wafer image pairs. While network-based methods excel at predicting data with distributions similar to the training set, their generalization to unseen data remains uncertain, and the resulting models often lack interpretability and explainability.


\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{resist.pdf}
    \caption{Illustration of a positive resist process.}
    \label{fig:pipeline}
\end{figure}


The core principle of TorchResist is to regularize the resist model using off-the-shelf analytical formulations while delegating parameter calibration to well-established numerical methods, leveraging a given calibration dataset. This strict formulation ensures sufficient model capacity while serving as a strong regularizer, enabling TorchResist to achieve robust generalization on unseen data. Unlike existing network-based methods, which often involve millions of trainable parameters, TorchResist is designed with fewer than twenty interpretable parameters, allowing it to converge efficiently on relatively small datasets. Additionally, by utilizing modern differentiable programming tools and harnessing the parallel computing power of GPUs, TorchResist significantly accelerates both calibration and inference processes.





\minisection{Differentiable Programming and Parallel Computation}
Differentiable programming, supported by tools like TensorFlow\cite{tensorflow2015-whitepaper}, PyTorch\cite{paszke2019pytorch}, and JAX\cite{jax2018github}, enables efficient optimization of computational models through automatic differentiation, with forward and backward methods for gradient computation. Its applications span probabilistic programming, Bayesian inference, robotics, and computational lithography. GPU parallel computing accelerates these tasks by processing multiple operations concurrently, significantly reducing computation time in areas such as semiconductor lithography, where it handles mask and resist results simultaneously, enhancing efficiency in high-performance computing.


