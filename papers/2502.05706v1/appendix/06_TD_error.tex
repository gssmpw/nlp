\subsection{Proof of Theorem \ref{theorem:td-error-decomposition}, TD Error Decomposition to Martingale and Remainder}
\label{app:proof-TD-error}
\begin{theoremapp*}[TD Error Decomposition]
Under the assumptions of polynomial ergodicity \ref{theorem:polynomial-ergodicity}, step size decay \ref{ass:step-size-decay}, Hölder continuity of the feature mapping \ref{ass:holder-continuous-features}, and bounded feature vectors \ref{ass:bounded-features}, the TD error \( e_t \) can be decomposed as:
\[
e_t = M_t + R_t,
\]
where: \(M_t = \sum_{k=1}^{t} d_k\) is a martingale with \( \{d_k\} \) being a martingale difference sequence.
\( R_t \) is the remainder term capturing the systematic bias.
\end{theoremapp*}
\begin{proof}
\;\newline
\paragraph{1. Assumptions:}
\begin{enumerate}
    \item \textbf{Step Size Conditions:} The learning rates \( \{\alpha_t\} \) satisfy \( \sum_{t=1}^\infty \alpha_t = \infty \) and \( \sum_{t=1}^\infty \alpha_t^2 < \infty \). 
    \item \textbf{Bounded Features:} \ref{ass:bounded-features} The gradient \( \nabla_\theta V_\theta(x_t) \) is uniformly bounded, i.e., there exists a constant \( C > 0 \) such that \( \|\nabla_\theta V_\theta(x_t)\| \leq C \) for all \( t \).
    \item \textbf{Markov Chain Properties:} The state sequence \( \{x_t\} \) forms an irreducible and aperiodic Markov chain with a unique stationary distribution.
    \item \textbf{Hölder Continuity} \ref{ass:holder-continuous-features}: The feature mapping \( f: S \to \mathbb{R}^d \) is Hölder continuous with exponent \( \gamma \in (0, 1] \) and constant \( C_\gamma > 0 \). Formally, for all \( s, s' \in S \), then we have \(\|f(s) - f(s')\| \leq C_\gamma \|s - s'\|^\gamma.\)
\end{enumerate}
The TD error can be decomposed as:
\[
\theta_t - \theta^* = M_t + R_t
\]
where \( M_t \) is a martingale and \( R_t \) is a remainder term.

% Optional: Definitions Section (Place this before the theorem if preferred)
\begin{definition}[Martingale]
\label{def:martingale}
A sequence of random variables \( \{M_t\}_{t \geq 0} \) adapted to a filtration \( \{\mathcal{F}_t\}_{t \geq 0} \) is called a \textbf{martingale} if it satisfies the martingale property:
\begin{align*}
\mathbb{E}[M_{t+1} | \mathcal{F}_t] &= M_t \forall t \geq 0\\
\mathbb{E}[|M_{t}|] &< \infty \quad \forall t \geq 0
\end{align*}
\end{definition}

\begin{definition}[Martingale Difference Sequence]
\label{def:martingale-difference-sequence}
A sequence of random variables \( \{d_t\}_{t \geq 1} \) adapted to a filtration \( \{\mathcal{F}_t\}_{t \geq 0} \) is called a \emph{martingale difference sequence} if:
\[
\mathbb{E}[d_t | \mathcal{F}_{t-1}] = 0 \quad \text{for all } t \geq 1
\]
\end{definition}


\;\newline
\paragraph{1) TD Update Rule:}
\[
\theta_{t+1} = \theta_t + \alpha_t \delta_t \nabla_\theta V_\theta(x_t)
\]
where \( \delta_t \) is the Temporal Difference (TD) error.

\paragraph{2) TD Error Expression:}
\[
\delta_t = r_t + \gamma V_\theta(x_{t+1}) - V_\theta(x_t)
\]
where \( r_t \) is the reward at time \( t \) and \( \gamma \) is the discount factor.

\paragraph{3) Decomposition by Subtracting \( \theta^* \):}
\begin{align*}
\theta_{t+1} - \theta^* &= \theta_t - \theta^* + \alpha_t \delta_t \nabla_\theta V_\theta(x_t) \\
&= \theta_t - \theta^* + \alpha_t (\delta_t - \mathbb{E}[\delta_t|\mathcal{F}_{t-1}])\nabla_\theta V_\theta(x_t) \\
&\quad + \alpha_t \mathbb{E}[\delta_t|\mathcal{F}_{t-1}]\nabla_\theta V_\theta(x_t)
\end{align*}

\paragraph{4) Iterative Summation:}
\[
\theta_t - \theta^* = (\theta_0 - \theta^*) + \sum_{k=1}^t \alpha_k (\delta_k - \mathbb{E}[\delta_k|\mathcal{F}_{k-1}])\nabla_\theta V_\theta(x_k) + \sum_{k=1}^t \alpha_k \mathbb{E}[\delta_k|\mathcal{F}_{k-1}]\nabla_\theta V_\theta(x_k)
\]
\[
= M_t + R_t
\]
where:
\[
M_t = \sum_{k=1}^t \alpha_k (\delta_k - \mathbb{E}[\delta_k|\mathcal{F}_{k-1}])\nabla_\theta V_\theta(x_k)
\]
is a martingale, and
\[
R_t = (\theta_0 - \theta^*) + \sum_{k=1}^t \alpha_k \mathbb{E}[\delta_k|\mathcal{F}_{k-1}]\nabla_\theta V_\theta(x_k)
\]
is the remainder term.

\paragraph{5) Martingale Property Verification:}
To verify that \( M_t \) is a martingale, we need to show that:
\[
\mathbb{E}[M_t | \mathcal{F}_{t-1}] = M_{t-1}
\]
where \( \mathcal{F}_{t-1} \) is the filtration representing all information up to time \( t-1 \).

\textbf{Computation:}
\begin{align*}
\mathbb{E}[M_t | \mathcal{F}_{t-1}] &= \mathbb{E}\left[ \sum_{k=1}^t \alpha_k (\delta_k - \mathbb{E}[\delta_k|\mathcal{F}_{k-1}])\nabla_\theta V_\theta(x_k) \Big| \mathcal{F}_{t-1} \right] \\
&= \sum_{k=1}^{t-1} \alpha_k (\delta_k - \mathbb{E}[\delta_k|\mathcal{F}_{k-1}])\nabla_\theta V_\theta(x_k) + \mathbb{E}\left[ \alpha_t (\delta_t - \mathbb{E}[\delta_t|\mathcal{F}_{t-1}])\nabla_\theta V_\theta(x_t) \Big| \mathcal{F}_{t-1} \right] \\
&= M_{t-1} + \alpha_t \nabla_\theta V_\theta(x_t) \mathbb{E}\left[ \delta_t - \mathbb{E}[\delta_t|\mathcal{F}_{t-1}] \Big| \mathcal{F}_{t-1} \right] \\
&= M_{t-1} + \alpha_t \nabla_\theta V_\theta(x_t) \left( \mathbb{E}[\delta_t | \mathcal{F}_{t-1}] - \mathbb{E}[\delta_t | \mathcal{F}_{t-1}] \right) \\
&= M_{t-1} + \alpha_t \nabla_\theta V_\theta(x_t) \times 0 \\
&= M_{t-1}
\end{align*}
Thus,
\begin{equation}\label{eq:martingale}
    M_t = \sum_{k=1}^t \alpha_k \left( \delta_k - \mathbb{E}[\delta_k | \mathcal{F}_{k-1}] \right) \nabla_\theta V_\theta(x_k)
\end{equation}
is Martingale.

\paragraph{6) Bounding the Remainder Term \( R_t \)}:
Under Hölder continuity, assume that:
\[
\|\mathbb{E}[\delta_k|\mathcal{F}_{k-1}]\nabla_\theta V_\theta(x_k)\| \leq L \|\theta_k - \theta^*\|^\gamma
\]
for some Hölder constant \( L \) and exponent \( \gamma \).

Then, the norm of the remainder can be bounded as:
\begin{equation}\label{eq:R_t}
\|R_t\| \leq \|\theta_0 - \theta^*\| + \sum_{k=1}^t \alpha_k \|\mathbb{E}[\delta_k|\mathcal{F}_{k-1}]\nabla_\theta V_\theta(x_k)\| \leq \|\theta_0 - \theta^*\| + \sum_{k=1}^t \alpha_k L \|\theta_k - \theta^*\|^\gamma
\end{equation}
This bound is crucial for applying stochastic approximation techniques, which require controlling the remainder term to ensure convergence of \( \theta_t \) to \( \theta^* \).

\paragraph{7) Conclusion:}
With \( M_t \) being a martingale and \( R_t \) appropriately bounded under the given assumptions, the decomposition:
\[
\theta_t - \theta^* = M_t + R_t
\]
holds, facilitating further analysis of the convergence properties of the TD learning algorithm.

\end{proof}