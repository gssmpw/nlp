\subsection{Proof of Lemma \ref{lemma:remainder-growth-term}, Remainder Growth Term}
\label{app:proof-remainder-growth-term}

\begin{lemma}[Remainder Term Convergence]
Under Hölder continuity \ref{ass:holder-continuous-features} and polynomial ergodicity \ref{theorem:polynomial-ergodicity}, step-condition \ref{ass:step-size-decay}, the remainder term satisfies:
\[
\|R_t\| \leq O(t^{-\gamma/2})
\]
where \( \gamma \) is the H\"older exponent.
\end{lemma}

\begin{proof}
\;\newline
\paragraph{1. Assumptions:}
\begin{enumerate}
    \item \emph{Hölder Continuity} \ref{ass:holder-continuous-features}: The function satisfies Hölder continuity with exponent \( \gamma \in (0, 1] \), i.e.,
    \[
    \|f(x) - f(y)\| \leq L \|x - y\|^\gamma \quad \forall x, y
    \]
    where \( L > 0 \) is the Hölder constant.
    
    \item \emph{Step Size Condition} \ref{ass:step-size-decay}: The step sizes are given by
    \[
    \alpha_k \;=\; \frac{C_\alpha}{k^\eta},\quad\sum_{k=1}^{\infty} \alpha_k = \infty,
\quad\text{and}\quad
\sum_{k=1}^{\infty} \alpha_k^2 < \infty.
    \]
    for some constant \( c > 0 \)

    \item \emph{TD Error Decomposition}: From Theorem \ref{theorem:td-error-decomposition}, the parameter estimate satisfies
    \[
    \theta_k - \theta^* = M_k + R_k.
    \]
    
    \item \emph{Martingale bounded Vartiance} from Lemma \ref{lemma:bounded-variance-martingale}: The martingale difference sequence satisfies
    \[
    \mathbb{E}[\|M_k\|^2] \leq C k^{-\beta}
    \]
    for some \( \beta > 1 \) and constant \( C > 0 \).
\end{enumerate}

\textbf{Proof Steps:}

\paragraph{2. Initial Bound on \( R_t \):}
From Eq. \ref{eq:R_t}
\[
\|R_t\| \leq \sum_{k=1}^t \alpha_k L \|\theta_k - \theta^*\|^\gamma
\]

\paragraph{3. Decomposition of \( \|\theta_k - \theta^*\| \):}
From the TD error decomposition:
\[
\theta_k - \theta^* = M_k + R_k
\]
Applying the triangle inequality:
\[
\|\theta_k - \theta^*\| \leq \|M_k\| + \|R_k\|
\]
Thus:
\[
\|\theta_k - \theta^*\|^\gamma \leq (\|M_k\| + \|R_k\|)^\gamma
\]
Using the inequality \( (a + b)^\gamma \leq a^\gamma + b^\gamma \) for \( a, b \geq 0 \) and \( \gamma \in (0, 1] \), we obtain:
\[
\|\theta_k - \theta^*\|^\gamma \leq \|M_k\|^\gamma + \|R_k\|^\gamma
\]

\paragraph{4. Bound on \( \|M_k\| \):}
From lemma \ref{lemma:bounded-variance-martingale} margingale variance bound:
\[
\mathbb{E}[\|M_k\|^2] \leq C k^{-\beta}
\]
Applying the Cauchy-Schwarz inequality:
\[
\|M_k\| \leq \sqrt{\mathbb{E}[\|M_k\|^2]} \leq \sqrt{C} k^{-\beta/2}
\]
Thus:
\[
\|M_k\|^\gamma \leq (\sqrt{C} k^{-\beta/2})^\gamma = C^{\gamma/2} k^{-\gamma\beta/2}
\]

\textbf{5. Substituting the Bounds into \( \|R_t\| \):}
\begin{align*}
\|R_t\| &\leq \sum_{k=1}^t \alpha_k L (\|M_k\|^\gamma + \|R_k\|^\gamma) \\
&= L \sum_{k=1}^t \alpha_k \|M_k\|^\gamma + L \sum_{k=1}^t \alpha_k \|R_k\|^\gamma \\
&\leq L \sum_{k=1}^t \frac{c}{k} C^{\gamma/2} k^{-\gamma\beta/2} + L \sum_{k=1}^t \frac{c}{k} \|R_k\|^\gamma \\
&= L c C^{\gamma/2} \sum_{k=1}^t k^{-1 - \gamma\beta/2} + L c \sum_{k=1}^t \frac{1}{k} \|R_k\|^\gamma \\
&\leq C' t^{-\gamma\beta/2} + L c \sum_{k=1}^t \frac{1}{k} \|R_k\|^\gamma
\end{align*}
where \( C' = L c C^{\gamma/2} \frac{1}{\gamma\beta/2 - 1} \) for \( \gamma\beta/2 > 1 \).

\textbf{6. Sequence Convergence Approach:}

To establish the convergence of \( \|R_t\| \) as \( t \to \infty \), we analyze the recursive inequality derived above using properties of convergent sequences.

\textbf{7. Recursive Inequality:}
From step 5, we have:
\[
\|R_t\| \leq C' t^{-\gamma\beta/2} + L c \sum_{k=1}^t \frac{1}{k} \|R_k\|^\gamma
\]
Define the sequence \( a_t = \|R_t\| \). The inequality becomes:
\[
a_t \leq C' t^{-\gamma\beta/2} + L c \sum_{k=1}^t \frac{1}{k} a_k^\gamma
\]

\textbf{8. Establishing a Bound for \( a_t \):}
Assume that \( a_t \leq D t^{-\gamma/2} \) for some constant \( D > 0 \) to be determined. Substituting this into the recursive inequality:
\[
a_t \leq C' t^{-\gamma\beta/2} + L c \sum_{k=1}^t \frac{1}{k} (D k^{-\gamma/2})^\gamma
\]
\[
= C' t^{-\gamma\beta/2} + L c D^\gamma \sum_{k=1}^t \frac{1}{k} k^{-\gamma^2/2}
\]
\[
= C' t^{-\gamma\beta/2} + L c D^\gamma \sum_{k=1}^t k^{-1 - \gamma^2/2}
\]

\textbf{9. Analyzing the Summation:}
The summation \( \sum_{k=1}^t k^{-1 - \gamma^2/2} \) converges as \( t \to \infty \) because \( \gamma^2/2 > 0 \). Specifically:
\[
\sum_{k=1}^t k^{-1 - \gamma^2/2} \leq \int_{1}^{t} x^{-1 - \gamma^2/2} \, dx + 1 = \frac{2}{\gamma^2} \left(1 - t^{-\gamma^2/2}\right) \leq \frac{2}{\gamma^2}
\]
Thus:
\[
a_t \leq C' t^{-\gamma\beta/2} + L c D^\gamma \cdot \frac{2}{\gamma^2}
\]

\textbf{10. Choosing \( D \) Appropriately:}
To satisfy \( a_t \leq D t^{-\gamma/2} \), we require:
\[
C' t^{-\gamma\beta/2} + L c D^\gamma \cdot \frac{2}{\gamma^2} \leq D t^{-\gamma/2}
\]
For sufficiently large \( t \), since \( \beta > 1 \), the term \( t^{-\gamma\beta/2} \) becomes negligible compared to \( t^{-\gamma/2} \). Therefore, it suffices to ensure:
\[
L c \cdot \frac{2}{\gamma^2} D^\gamma \leq D
\]
\[
\Rightarrow 2 L c \cdot \frac{1}{\gamma^2} D^\gamma \leq D
\]
\[
\Rightarrow 2 L c \cdot \frac{1}{\gamma^2} D^{\gamma - 1} \leq 1
\]
\[
\Rightarrow D^{1 - \gamma} \geq 2 L c \cdot \frac{1}{\gamma^2}
\]
Choosing:
\[
D = \left( 2 L c \cdot \frac{1}{\gamma^2} \right)^{\frac{1}{1 - \gamma}}
\]
ensures that the inequality holds. This choice is valid since \( \gamma \in (0, 1) \).

\textbf{11. Verifying the Bound for All \( t \):}
With the chosen \( D \), for sufficiently large \( t \), the bound \( a_t \leq D t^{-\gamma/2} \) holds. Additionally, the term \( C' t^{-\gamma\beta/2} \) becomes insignificant compared to \( D t^{-\gamma/2} \) as \( t \) increases because \( \gamma\beta/2 > \gamma/2 \).

\textbf{12. Conclusion:}
By the sequence convergence approach, we have established that:
\[
\|R_t\| = a_t \leq D t^{-\gamma/2}
\]
where \( D = \left( \frac{2 L c}{\gamma^2} \right)^{\frac{1}{1 - \gamma}} \).

Thus, under Hölder continuity and polynomial mixing with rate \( \beta > 1 \), the remainder term satisfies:
\[
\|R_t\| \leq O(t^{-\gamma/2})
\]
\end{proof}

