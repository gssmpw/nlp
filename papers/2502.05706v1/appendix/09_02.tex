\begin{lemma}[TD Error as a Martingale-Difference Sequence]
\label{lemma:td-error-mds}
\textbf{Statement.}
Let \( \{x_t\}_{t \geq 0} \) be the Markov chain of states, and let \( \theta^* \) be such that \( V_{\theta^*} \) satisfies the Bellman equation:
\[
V_{\theta^*}(x) = \mathbb{E}\left[ r(x) + \gamma V_{\theta^*}(x') \mid x \right],
\]
for all states \( x \), where \( x' \) is the next state after \( x \), \( r(x) \) is the reward function, and \( \gamma \in (0,1) \) is the discount factor. Define
\[
\delta_t(\theta^*) = r_t + \gamma V_{\theta^*}(x_{t+1}) - V_{\theta^*}(x_t).
\]
Then, with respect to the filtration \( \mathcal{F}_t = \sigma(x_0, \dots, x_t) \), we have
\[
\mathbb{E}\left[ \delta_t(\theta^*) \mid \mathcal{F}_t \right] = 0,
\]
which shows that \( \{\delta_t(\theta^*)\} \) is a martingale-difference sequence.
\end{lemma}

\begin{proof}
\;\newline
\paragraph{Step 1: TD Error Definition and Fixed Point.}
\begin{align}
    \delta_t(\theta^*) &= r_t + \gamma V_{\theta^*}(x_{t+1}) - V_{\theta^*}(x_t),
    \tag{\textit{Definition of \( \delta_t(\theta^*) \)}}
    \label{eq:td-error-def} \\
    V_{\theta^*}(x) &= \mathbb{E}\left[ r(x) + \gamma V_{\theta^*}(x') \mid x \right],
    \tag{\textit{Bellman equation for \( V_{\theta^*} \)}}
    \label{eq:fixed-point}
\end{align}
\paragraph{Step 2: Conditional Expectation with Respect to \( \mathcal{F}_t \).}
\begin{align}
    \mathbb{E}\left[ \delta_t(\theta^*) \mid \mathcal{F}_t \right] &= \mathbb{E}\left[ r_t + \gamma V_{\theta^*}(x_{t+1}) - V_{\theta^*}(x_t) \mid \mathcal{F}_t \right]
    \tag{\textit{Condition on \( \mathcal{F}_t \)}}
    \label{eq:cond-exp-start} \\
    &= r_t - V_{\theta^*}(x_t) + \gamma \mathbb{E}\left[ V_{\theta^*}(x_{t+1}) \mid x_t \right],
    \tag{\textit{Pull out terms known at time \( t \)}}
    \label{eq:pullout-known} \\
    \intertext{Since \( V_{\theta^*}(x_t) \) and \( r_t \) are \( \mathcal{F}_t \)-measurable, and by the Bellman equation~\eqref{eq:fixed-point},}
    \mathbb{E}\left[ r_t + \gamma V_{\theta^*}(x_{t+1}) \mid x_t \right] &= V_{\theta^*}(x_t).
    \tag{\textit{Substitute \( V_{\theta^*} \) as fixed point}}
    \label{eq:bellman-sub} \\
    \intertext{Hence,}
    \mathbb{E}\left[ \delta_t(\theta^*) \mid \mathcal{F}_t \right] &= \left[ r_t + \gamma \mathbb{E}\left[ V_{\theta^*}(x_{t+1}) \mid x_t \right] \right] - V_{\theta^*}(x_t) \\
    &= V_{\theta^*}(x_t) - V_{\theta^*}(x_t) \\
    &= 0.
    \tag{\textit{Martingale-difference property}}
    \label{eq:mds-property}
\end{align}
\paragraph{3. Conclusion:}
Since
\[
    \mathbb{E}\left[ \delta_t(\theta^*) \mid \mathcal{F}_t \right] = 0
\]
for all \( t \), the process \( \{\delta_t(\theta^*)\} \) is a \emph{martingale-difference sequence} with respect to \( \{\mathcal{F}_t\} \). This completes the proof.
\end{proof}