\subsection{Proof of Lemma \ref{lemma:bounded-variance-martingale}, Bounded Variance of Martingale Differences under Polynomial Mixing}
\label{app:proof-bounded-variance-martingale}

\begin{lemmaapp*}[Bounded Variance of Martingale Term]
Assuming polynomial ergodicity \ref{theorem:polynomial-ergodicity}, HÃ¶lder continuity of the feature mapping \ref{ass:holder-continuous-features}, bounded feature vectors \ref{ass:bounded-features}, and appropriate step size decay \ref{ass:step-size-decay}, the martingale term \( M_t \) satisfies:
\[
\mathbb{E}[\|M_t\|^2] \leq C t^{-\beta},
\]
where \( C \) is a constant dependent on the step size and mixing parameters, and \( \beta > 0 \) characterizes the rate at which the variance decays.
\end{lemmaapp*}

\begin{proof}
\;\newline
\paragraph{1. Assumptions and definitions:}
From equation \ref{eq:martingale}, we know that
\[
M_t = \sum_{k=1}^t \alpha_k \left( \delta_k - \mathbb{E}[\delta_k | \mathcal{F}_{k-1}] \right) \nabla_\theta V_\theta(x_k)
\]
is Martingale, where:
\begin{itemize}
    \item \( \alpha_k \) is the step size at iteration \( k \) as defined in Assumption \ref{ass:step-size-decay}
    \item \( \delta_k \) is the Temporal Difference (TD) error at iteration \( k \), as defined in Eq. \ref{def:delta}
    \item \( \mathcal{F}_{k-1} \) is the filtration representing all information up to time \( k-1 \)
    \item \( \nabla_\theta V_\theta(x_k) \) is the gradient of the value function with respect to the parameters \( \theta \) at state \( x_k \).
\end{itemize}

\paragraph{2. Orthogonality of Martingale Differences:}

Since \( M_t \) is martingale, the cross terms in the expectation \( \mathbb{E}[\|M_t\|^2] \) vanish. Specifically, for \( i \neq j \):
\[
\mathbb{E}\left[ \alpha_i \left( \delta_i - \mathbb{E}[\delta_i | \mathcal{F}_{i-1}] \right) \nabla_\theta V_\theta(x_i) \cdot \alpha_j \left( \delta_j - \mathbb{E}[\delta_j | \mathcal{F}_{j-1}] \right) \nabla_\theta V_\theta(x_j) \right] = 0
\]
This holds because:
\[
\mathbb{E}\left[ \delta_j - \mathbb{E}[\delta_j | \mathcal{F}_{j-1}] \Big| \mathcal{F}_{i} \right] = 0 \quad \text{for} \quad j > i
\]
due to the martingale difference property.

\paragraph{3. Computing the Second Moment:}
\begin{align*}
\mathbb{E}[\|M_t\|^2] &= \mathbb{E}\left[ \left\| \sum_{k=1}^t \alpha_k \left( \delta_k - \mathbb{E}[\delta_k | \mathcal{F}_{k-1}] \right) \nabla_\theta V_\theta(x_k) \right\|^2 \right]\\
&=\mathbb{E}\left[  \sum_{k=1}^t \left\|\alpha_k \left( \delta_k - \mathbb{E}[\delta_k | \mathcal{F}_{k-1}] \right) \nabla_\theta V_\theta(x_k) \right\|^2 \right]\quad\text{(Orthogonality)}\\
&=  \sum_{k=1}^t \mathbb{E}\left[\left\|\alpha_k \left( \delta_k - \mathbb{E}[\delta_k | \mathcal{F}_{k-1}] \right) \nabla_\theta V_\theta(x_k) \right\|^2 \right]\quad\text{(Linearity of Expectation)}\\
&=  \sum_{k=1}^t \alpha_k^2\mathbb{E}\left[
        \left(\delta_k - \mathbb{E}[\delta_k | \mathcal{F}_{k-1}] \right)^2
        \left\|\nabla_\theta V_\theta(x_k) \right\|^2
    \right]\quad\text{(Cauchy-Schwarz)}\\
&= \sum_{k=1}^t \alpha_k^2
        \mathbb{E}\left[\left( \delta_k - \mathbb{E}[\delta_k | \mathcal{F}_{k-1}] \right)^2\right]
        \mathbb{E}\left[\left\|\nabla_\theta V_\theta(x_k) \right\|^2\right]
    \quad\text{(Assuming Fast mixing and therefore approximate independence)}
\end{align*}

\paragraph{4. Boundedness of Gradients:}

Given bounded features (\textbf{Bounded Features}) in the Linear function approximation case, there exists a constant \( G > 0 \) such that:
\[
\left\| \nabla_\theta V_\theta(x_k) \right\| \leq G \quad \forall k
\]
Thus:
\[
\mathbb{E}\left[ \left\| \nabla_\theta V_\theta(x_k) \right\|^2 \right] \leq G^2
\]

\textbf{5. Applying Polynomial Mixing:}

Under polynomial mixing, the variance of the martingale differences satisfies:
\[
\mathbb{E}\left[ \left( \delta_k - \mathbb{E}[\delta_k | \mathcal{F}_{k-1}] \right)^2 \right] \leq C k^{-\beta}
\]
for some constant \( C > 0 \) and \( \beta > 1 \).

\paragraph{6. Combining the Bounds:}

Substituting the bounds from Steps 4 and 5 into the expression from Step 3:
\[
\mathbb{E}[\|M_t\|^2] \leq G^2 \sum_{k=1}^t \alpha_k^2 C k^{-\beta}
\]
\[
= C G^2 \sum_{k=1}^t \alpha_k^2 k^{-\beta}
\]

\paragraph{7. Bounding the Summation:}

Substitute \( \alpha_k = \frac{c}{k^a} \) into the summation:
\[
\sum_{k=1}^t \alpha_k^2 k^{-\beta} = c^2 \sum_{k=1}^t \frac{1}{k^{2a + \beta}}
\]
Since \( \beta > 1 \) and \( a > 0.5 \), the exponent \( 2a + \beta > 2 \), ensuring the convergence of the series. However, since we seek a bound that decays with \( t \), we need to analyze the partial sum up to \( t \).

For large \( t \), the partial sum can be approximated by:
\[
\sum_{k=1}^t \frac{1}{k^{2a + \beta}} \leq \int_{1}^{t} \frac{1}{x^{2a + \beta}} \, dx + 1 \leq \frac{1}{(2a + \beta - 1)} t^{-(2a + \beta - 1)} + 1
\]
Given \( 2a + \beta - 1 > 1 \) (since \( a > 0.5 \) and \( \beta > 1 \)), the summation behaves asymptotically as:
\[
\sum_{k=1}^t \frac{1}{k^{2a + \beta}} = O\left(t^{-(2a + \beta - 1)}\right)
\]

\paragraph{8. Final Bound on \( \mathbb{E}[\|M_t\|^2] \):}

Combining all the above:
\[
\mathbb{E}[\|M_t\|^2] \leq C G^2 c^2 \sum_{k=1}^t \frac{1}{k^{2a + \beta}} \leq C' t^{-(2a + \beta - 1)}
\]
where \( C' = \frac{C G^2 c^2}{2a + \beta - 1} + C G^2 c^2 \) (absorbing constants).

To satisfy the lemma's statement \( \mathbb{E}[\|M_t\|^2] \leq C t^{-\beta} \), we require:
\[
-(2a + \beta - 1) \leq -\beta \implies 2a + \beta - 1 \geq \beta \implies 2a \geq 1
\]
Given that \( a > 0.5 \), this inequality holds with equality when \( a = 0.5 \). Therefore, to ensure:
\[
\mathbb{E}[\|M_t\|^2] \leq C t^{-\beta}
\]
it suffices to choose \( a = 0.5 \). However, to strictly satisfy \( a > 0.5 \), we achieve a better decay rate:
\[
\mathbb{E}[\|M_t\|^2] = O\left(t^{-(2a + \beta - 1)}\right) \leq O\left(t^{-\beta}\right)
\]
since \( 2a + \beta - 1 > \beta \) for \( a > 0.5 \).

\paragraph{9. Conclusion:}

Therefore, under the given step size \( \alpha_k = \frac{c}{k^a} \) with \( a > 0.5 \) and polynomial mixing rate \( \beta > 1 \), the martingale difference sequence satisfies:
\[
\mathbb{E}[\|M_t\|^2] \leq C t^{-\beta}
\]
where \( C > 0 \) is a constant dependent on \( c \), \( G \), and the mixing rate parameters.

\end{proof}