@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{TheC3,
  title={The Claude 3 Model Family: Opus, Sonnet, Haiku},
  author={Anthropic},
  url={https://api.semanticscholar.org/CorpusID:268232499},
  year={2024}
}

@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and Millican, Katie and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@article{bai2023qwen,
  title={Qwen technical report},
  author={Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and others},
  journal={arXiv preprint arXiv:2309.16609},
  year={2023}
}

@misc{ai2024yi,
    title={Yi: Open Foundation Models by 01.AI},
    author={01. AI and : and Alex Young and Bei Chen and Chao Li and Chengen Huang and Ge Zhang and Guanwei Zhang and Heng Li and Jiangcheng Zhu and Jianqun Chen and Jing Chang and Kaidong Yu and Peng Liu and Qiang Liu and Shawn Yue and Senbin Yang and Shiming Yang and Tao Yu and Wen Xie and Wenhao Huang and Xiaohui Hu and Xiaoyi Ren and Xinyao Niu and Pengcheng Nie and Yuchi Xu and Yudong Liu and Yue Wang and Yuxuan Cai and Zhenyu Gu and Zhiyuan Liu and Zonghong Dai},
    year={2024},
    eprint={2403.04652},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@article{hendryckstest2021,
      title={Measuring Massive Multitask Language Understanding},
      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
      journal={Proceedings of the International Conference on Learning Representations (ICLR)},
      year={2021}
    }

@article{clark2018think,
  title={Think you have solved question answering? try arc, the ai2 reasoning challenge},
  author={Clark, Peter and Cowhey, Isaac and Etzioni, Oren and Khot, Tushar and Sabharwal, Ashish and Schoenick, Carissa and Tafjord, Oyvind},
  journal={arXiv preprint arXiv:1803.05457},
  year={2018}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{suzgun2022challenging,
  title={Challenging big-bench tasks and whether chain-of-thought can solve them},
  author={Suzgun, Mirac and Scales, Nathan and Sch{\"a}rli, Nathanael and Gehrmann, Sebastian and Tay, Yi and Chung, Hyung Won and Chowdhery, Aakanksha and Le, Quoc V and Chi, Ed H and Zhou, Denny and others},
  journal={arXiv preprint arXiv:2210.09261},
  year={2022}
}

@misc{lovin2023gpt,
  title={Gpt-4 performs significantly worse on coding problems not in its training data},
  author={Lovin, Brian},
  year={2023}
}

@inproceedings{bender2021dangers,
  title={On the dangers of stochastic parrots: Can language models be too big?��},
  author={Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle={Proceedings of the 2021 ACM conference on fairness, accountability, and transparency},
  pages={610--623},
  year={2021}
}

@article{kocon2023chatgpt,
  title={ChatGPT: Jack of all trades, master of none},
  author={Koco{\'n}, Jan and Cichecki, Igor and Kaszyca, Oliwier and Kochanek, Mateusz and Szyd{\l}o, Dominika and Baran, Joanna and Bielaniewicz, Julita and Gruza, Marcin and Janz, Arkadiusz and Kanclerz, Kamil and others},
  journal={Information Fusion},
  volume={99},
  pages={101861},
  year={2023},
  publisher={Elsevier}
}

@article{li2023open,
  title={An open source data contamination report for llama series models},
  author={Li, Yucheng},
  journal={arXiv preprint arXiv:2310.17589},
  year={2023}
}

@article{zhou2023don,
  title={Don't make your llm an evaluation benchmark cheater},
  author={Zhou, Kun and Zhu, Yutao and Chen, Zhipeng and Chen, Wentong and Zhao, Wayne Xin and Chen, Xu and Lin, Yankai and Wen, Ji-Rong and Han, Jiawei},
  journal={arXiv preprint arXiv:2311.01964},
  year={2023}
}

@article{ni2024training,
  title={Training on the Benchmark Is Not All You Need},
  author={Ni, Shiwen and Kong, Xiangtao and Li, Chengming and Hu, Xiping and Xu, Ruifeng and Zhu, Jia and Yang, Min},
  journal={arXiv preprint arXiv:2409.01790},
  year={2024}
}

@article{zhu2023dyval,
  title={Dyval: Graph-informed dynamic evaluation of large language models},
  author={Zhu, Kaijie and Chen, Jiaao and Wang, Jindong and Gong, Neil Zhenqiang and Yang, Diyi and Xie, Xing},
  journal={arXiv preprint arXiv:2309.17167},
  year={2023}
}

@article{lei2023s3eval,
  title={S3eval: A synthetic, scalable, systematic evaluation suite for large language models},
  author={Lei, Fangyu and Liu, Qian and Huang, Yiming and He, Shizhu and Zhao, Jun and Liu, Kang},
  journal={arXiv preprint arXiv:2310.15147},
  year={2023}
}

@inproceedings{zhu2024dynamic,
  title={Dynamic Evaluation of Large Language Models by Meta Probing Agents},
  author={Zhu, Kaijie and Wang, Jindong and Zhao, Qinlin and Xu, Ruochen and Xie, Xing},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@article{liucogmath,
  title={CogMath: Evaluating LLMs' Authentic Mathematical Ability from a Cognitive Perspective},
  author={Liu, Jiayu and Huang, Zhenya and Dai, Wei and Cheng, Cheng and Wu, Jinze and Sha, Jing and Liu, Qi and Wang, Shijin and Chen, Enhong}
}

@article{white2024livebench,
  title={Livebench: A challenging, contamination-free llm benchmark},
  author={White, Colin and Dooley, Samuel and Roberts, Manley and Pal, Arka and Feuer, Ben and Jain, Siddhartha and Shwartz-Ziv, Ravid and Jain, Neel and Saifullah, Khalid and Naidu, Siddartha and others},
  journal={arXiv preprint arXiv:2406.19314},
  year={2024}
}

@article{wang2018glue,
  title={Glue: A multi-task benchmark and analysis platform for natural language understanding},
  author={Wang, Alex},
  journal={arXiv preprint arXiv:1804.07461},
  year={2018}
}

@article{wang2019superglue,
  title={Superglue: A stickier benchmark for general-purpose language understanding systems},
  author={Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{srivastava2022beyond,
  title={Beyond the imitation game: Quantifying and extrapolating the capabilities of language models},
  author={Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri{\`a} and others},
  journal={arXiv preprint arXiv:2206.04615},
  year={2022}
}

@article{liang2022holistic,
  title={Holistic evaluation of language models},
  author={Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and others},
  journal={arXiv preprint arXiv:2211.09110},
  year={2022}
}

@article{he2024chinese,
  title={Chinese simpleqa: A chinese factuality evaluation for large language models},
  author={He, Yancheng and Li, Shilong and Liu, Jiaheng and Tan, Yingshui and Wang, Weixun and Huang, Hui and Bu, Xingyuan and Guo, Hangyu and Hu, Chengwei and Zheng, Boren and others},
  journal={arXiv preprint arXiv:2411.07140},
  year={2024}
}

@article{wei2024measuring,
  title={Measuring short-form factuality in large language models},
  author={Wei, Jason and Karina, Nguyen and Chung, Hyung Won and Jiao, Yunxin Joy and Papay, Spencer and Glaese, Amelia and Schulman, John and Fedus, William},
  journal={arXiv preprint arXiv:2411.04368},
  year={2024}
}

@article{lightman2023let,
  title={Let's verify step by step},
  author={Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl},
  journal={arXiv preprint arXiv:2305.20050},
  year={2023}
}

@misc{aime2024a,
  author       = {{AI-MO}},
  title        = {{Aime 2024}},
  year         = {2024},
  howpublished = {\url{https://huggingface.co/datasets/AI-MO/aimo-validation-aime}},
}


@misc{amc2023b,
  author       = {{AI-MO}},
  title        = {{amc 2023}},
  year         = {2023},
  howpublished = {\url{https://huggingface.co/datasets/AI-MO/aimo-validation-amc}},
}

@article{he2024olympiadbench,
  title={Olympiadbench: A challenging benchmark for promoting agi with olympiad-level bilingual multimodal scientific problems},
  author={He, Chaoqun and Luo, Renjie and Bai, Yuzhuo and Hu, Shengding and Thai, Zhen Leng and Shen, Junhao and Hu, Jinyi and Han, Xu and Huang, Yujie and Zhang, Yuxiang and others},
  journal={arXiv preprint arXiv:2402.14008},
  year={2024}
}

@article{xie2024order,
  title={Order Matters in Hallucination: Reasoning Order as Benchmark and Reflexive Prompting for Large-Language-Models},
  author={Xie, Zikai},
  journal={arXiv preprint arXiv:2408.05093},
  year={2024}
}

@article{blodgett2020language,
  title={Language (technology) is power: A critical survey of" bias" in nlp},
  author={Blodgett, Su Lin and Barocas, Solon and Daum{\'e} III, Hal and Wallach, Hanna},
  journal={arXiv preprint arXiv:2005.14050},
  year={2020}
}


@inproceedings{ahn2022knowledge,
  title={Why knowledge distillation amplifies gender bias and how to mitigate from the perspective of DistilBERT},
  author={Ahn, Jaimeen and Lee, Hwaran and Kim, Jinhwa and Oh, Alice},
  booktitle={Proceedings of the 4th Workshop on Gender Bias in Natural Language Processing (GeBNLP)},
  pages={266--272},
  year={2022}
}

@article{ferrara2023should,
  title={Should chatgpt be biased? challenges and risks of bias in large language models},
  author={Ferrara, Emilio},
  journal={arXiv preprint arXiv:2304.03738},
  year={2023}
}

@article{gallegos2024bias,
  title={Bias and fairness in large language models: A survey},
  author={Gallegos, Isabel O and Rossi, Ryan A and Barrow, Joe and Tanjim, Md Mehrab and Kim, Sungchul and Dernoncourt, Franck and Yu, Tong and Zhang, Ruiyi and Ahmed, Nesreen K},
  journal={Computational Linguistics},
  pages={1--79},
  year={2024},
  publisher={MIT Press 255 Main Street, 9th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{zheng2023judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46595--46623},
  year={2023}
}

@article{ben2006analysis,
  title={Analysis of representations for domain adaptation},
  author={Ben-David, Shai and Blitzer, John and Crammer, Koby and Pereira, Fernando},
  journal={Advances in neural information processing systems},
  volume={19},
  year={2006}
}

@inproceedings{jiang2024does,
  title={Does Data Contamination Make a Difference? Insights from Intentionally Contaminating Pre-training Data For Language Models},
  author={Jiang, Minhao and Liu, Ken and Zhong, Ming and Schaeffer, Rylan and Ouyang, Siru and Han, Jiawei and Koyejo, Sanmi},
  booktitle={ICLR 2024 Workshop on Navigating and Addressing Data Problems for Foundation Models},
  year={2024}
}

@article{lee2021deduplicating,
  title={Deduplicating training data makes language models better},
  author={Lee, Katherine and Ippolito, Daphne and Nystrom, Andrew and Zhang, Chiyuan and Eck, Douglas and Callison-Burch, Chris and Carlini, Nicholas},
  journal={arXiv preprint arXiv:2107.06499},
  year={2021}
}

@article{mcintosh2024inadequacies,
  title={Inadequacies of large language model benchmarks in the era of generative artificial intelligence},
  author={McIntosh, Timothy R and Susnjak, Teo and Arachchilage, Nalin and Liu, Tong and Watters, Paul and Halgamuge, Malka N},
  journal={arXiv preprint arXiv:2402.09880},
  year={2024}
}

@article{riddell2024quantifying,
  title={Quantifying contamination in evaluating code generation capabilities of language models},
  author={Riddell, Martin and Ni, Ansong and Cohan, Arman},
  journal={arXiv preprint arXiv:2403.04811},
  year={2024}
}

@article{sainz2023nlp,
  title={Nlp evaluation in trouble: On the need to measure llm data contamination for each benchmark},
  author={Sainz, Oscar and Campos, Jon Ander and Garc{\'\i}a-Ferrero, Iker and Etxaniz, Julen and de Lacalle, Oier Lopez and Agirre, Eneko},
  journal={arXiv preprint arXiv:2310.18018},
  year={2023}
}

@article{fan2023nphardeval,
  title={Nphardeval: Dynamic benchmark on reasoning ability of large language models via complexity classes},
  author={Fan, Lizhou and Hua, Wenyue and Li, Lingyao and Ling, Haoyang and Zhang, Yongfeng},
  journal={arXiv preprint arXiv:2312.14890},
  year={2023}
}

@article{dai2024unifying,
  title={Unifying Bias and Unfairness in Information Retrieval: A Survey of Challenges and Opportunities with Large Language Models},
  author={Dai, Sunhao and Xu, Chen and Xu, Shicheng and Pang, Liang and Dong, Zhenhua and Xu, Jun},
  journal={arXiv preprint arXiv:2404.11457},
  year={2024}
}


@article{chen2402humans,
  title={Humans or llms as the judge? a study on judgement biases, 2024},
  author={Chen, Guiming Hardy and Chen, Shunian and Liu, Ziche and Jiang, Feng and Wang, Benyou},
  journal={URL https://arxiv. org/abs/2402},
  volume={10669}
}


@article{ferrara2023fairness,
  title={Fairness and bias in artificial intelligence: A brief survey of sources, impacts, and mitigation strategies},
  author={Ferrara, Emilio},
  journal={Sci},
  volume={6},
  number={1},
  pages={3},
  year={2023},
  publisher={MDPI}
}

@article{vapnik1994measuring,
  title={Measuring the VC-dimension of a learning machine},
  author={Vapnik, Vladimir and Levin, Esther and Le Cun, Yann},
  journal={Neural computation},
  volume={6},
  number={5},
  pages={851--876},
  year={1994},
  publisher={MIT Press}
}

@misc{openai_chatgpt,
  author       = {OpenAI},
  title        = {ChatGPT},
  year         = {2023},
  url          = {https://chat.openai.com.chat},
}

@misc{openai_gpt4o,
  author       = {OpenAI},
  title        = {ChatGPT},
  year         = {2024},
  url          = {https://openai.com/index/hello-gpt-4o/},
}

@misc{2023opencompass,
    title={OpenCompass: A Universal Evaluation Platform for Foundation Models},
    author={OpenCompass Contributors},
    howpublished = {\url{https://github.com/open-compass/opencompass}},
    year={2023}
}

@article{ye2024justice,
  title={Justice or prejudice? quantifying biases in llm-as-a-judge},
  author={Ye, Jiayi and Wang, Yanbo and Huang, Yue and Chen, Dongping and Zhang, Qihui and Moniz, Nuno and Gao, Tian and Geyer, Werner and Huang, Chao and Chen, Pin-Yu and others},
  journal={arXiv preprint arXiv:2410.02736},
  year={2024}
}