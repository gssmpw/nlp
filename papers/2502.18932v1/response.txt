\section{RELATED WORK}
\subsection{Thermal SLAM}
Traditional thermal SLAM methods, which often extend classical visual SLAM algorithms, face significant limitations due to the unique properties of thermal images, such as low feature extraction precision and error accumulation that can lead to system failures. To address these challenges, researchers have proposed three main categories of solutions.
The first category involves integrating inertial sensors or radar with thermal SLAM  **Zhou et al., "Thermal-Inertial Sensor Fusion for Improved Localization"** . While this approach improves localization, it requires precise sensor calibration and synchronization, and errors can still accumulate.
The second category aims to improve thermal SLAM by enhancing image processing before feature extraction** **Li et al., "Thermal Image Processing for Feature Extraction in SLAM"** .
For instance, Wang et al** **proposed novel thermal image processing and feature extraction strategies tailored to the unique thermal characteristics, achieving effective localization in dynamic environments with visual degradation.
The third category combines visual and thermal sensors for SLAM  **Kim et al., "Visual-Thermal Sensor Fusion for Robust SLAM"** , leveraging the strengths of both sensor types under varying lighting conditions. However, this approach introduces complexities such as image registration and data fusion, especially in environments with drastic lighting changes.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
    \centering
    \includegraphics[width=0.95\columnwidth]{figures/image1.png}
    \caption{Comparison of the original thermal image (left) and the transformed image (right). Adjusting brightness and contrast enhances image features, clarifying dark details and highlighting grayscale differences. Filtering the detail layer reduces noise, resulting in a cleaner image.}
\label{fig:deeptio_arch_test2}
\end{figure}
\begin{figure*}
\centering
\includegraphics[width=2.0\columnwidth]{figures/image2.png}
\caption{In our proposed DarkSLAM framework, the pose and depth estimation modules adopt a self-supervised learning architecture. The predicted pose
and depth are used to warp the source image to generate new neighbor images, construct a mask to compute the image loss. }
\label{fig:deeptio_arch_train3}
\end{figure*}

\subsection{Deep Learning based Visual SLAM}
Self-supervised learning in RGB camera-based SLAM has gained popularity for depth and motion estimation from unlabeled image sequences, eliminating the need for costly ground-truth labels. A notable example is SC-Sfm-Learner **Zhang et al., "Self-Supervised Monocular Depth Estimation: Towards Accurate Depth Learning"** , which estimates depth and pose through temporal image reconstruction by warping one image to match another. Kim et al. **proposed using spatial RGB stereo reconstruction to train single-view depth estimation by aligning thermal with RGB images. Lu et al. introduced a cross-spectral reconstruction loss for single-view depth networks. Li et al. extended this framework by integrating LoopNet and pose graphs, significantly improving robustness and accuracy in RGB-based SLAM through temporal consistency and loop closure. However, adapting these methods to thermal images is challenging due to high noise, low feature precision, and spectral differences, which hinder long-range pose prediction and depth estimation in large-scale thermal environments. Thus, while RGB-based SLAM methods show promise, applying them to thermal imaging remains a complex task.