[
  {
    "index": 0,
    "papers": [
      {
        "key": "hou2024large",
        "author": "Hou, Yupeng and Zhang, Junjie and Lin, Zihan and Lu, Hongyu and Xie, Ruobing and McAuley, Julian and Zhao, Wayne Xin",
        "title": "Large language models are zero-shot rankers for recommender systems"
      },
      {
        "key": "zhang2023chatgpt",
        "author": "Zhang, Jizhi and Bao, Keqin and Zhang, Yang and Wang, Wenjie and Feng, Fuli and He, Xiangnan",
        "title": "Is chatgpt fair for recommendation? evaluating fairness in large language model recommendation"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "bender2021dangers",
        "author": "Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret",
        "title": "On the dangers of stochastic parrots: Can language models be too big?"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "zhang2023chatgpt",
        "author": "Zhang, Jizhi and Bao, Keqin and Zhang, Yang and Wang, Wenjie and Feng, Fuli and He, Xiangnan",
        "title": "Is chatgpt fair for recommendation? evaluating fairness in large language model recommendation"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "lucy2021gender",
        "author": "Lucy, L. and Bamman, D.",
        "title": "Gender and Representation Bias in GPT-3 Generated Stories"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "che2023federated",
        "author": "Che, Tianshi and Liu, Ji and Zhou, Yang and Ren, Jiaxiang and Zhou, Jiwen and Sheng, Victor S and Dai, Huaiyu and Dou, Dejing",
        "title": "Federated learning of large language models with parameter-efficient prompt tuning and adaptive optimization"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "ouyang2022training",
        "author": "Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others",
        "title": "Training language models to follow instructions with human feedback"
      },
      {
        "key": "bai2022training",
        "author": "Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others",
        "title": "Training a helpful and harmless assistant with reinforcement learning from human feedback"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "sharma2023framework",
        "author": "Sharma, Vandana and Mishra, Naman and Kukreja, Vinay and Alkhayyat, Ahmed and Elngar, Ahmed A",
        "title": "Framework for Evaluating Ethics in AI"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "greenwood2024user",
        "author": "Greenwood, Sophie and Chiniah, Sudalakshmee and Garg, Nikhil",
        "title": "User-item fairness tradeoffs in recommendations"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "hua2023up5",
        "author": "Hua, Wenyue and Ge, Yingqiang and Xu, Shuyuan and Ji, Jianchao and Zhang, Yongfeng",
        "title": "Up5: Unbiased foundation model for fairness-aware recommendation"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "hou2024large",
        "author": "Hou, Yupeng and Zhang, Junjie and Lin, Zihan and Lu, Hongyu and Xie, Ruobing and McAuley, Julian and Zhao, Wayne Xin",
        "title": "Large language models are zero-shot rankers for recommender systems"
      },
      {
        "key": "zhang2023chatgpt",
        "author": "Zhang, Jizhi and Bao, Keqin and Zhang, Yang and Wang, Wenjie and Feng, Fuli and He, Xiangnan",
        "title": "Is chatgpt fair for recommendation? evaluating fairness in large language model recommendation"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "borkan2019nuanced",
        "author": "Borkan, Daniel and Dixon, Lucas and Sorensen, Jeffrey and Thain, Nithum and Vasserman, Lucy",
        "title": "Nuanced metrics for measuring unintended bias with real data for text classification"
      },
      {
        "key": "lucy2021gender",
        "author": "Lucy, L. and Bamman, D.",
        "title": "Gender and Representation Bias in GPT-3 Generated Stories"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "zhang2023chatgpt",
        "author": "Zhang, Jizhi and Bao, Keqin and Zhang, Yang and Wang, Wenjie and Feng, Fuli and He, Xiangnan",
        "title": "Is chatgpt fair for recommendation? evaluating fairness in large language model recommendation"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "shafer2008tutorial",
        "author": "Shafer, Glenn and Vovk, Vladimir",
        "title": "A tutorial on conformal prediction."
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "dwork2012fairness",
        "author": "Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Richard",
        "title": "Fairness through awareness"
      }
    ]
  }
]