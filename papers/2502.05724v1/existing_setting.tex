
%\section{Issues with Existing Setting}

\section{Rethinking Directed Link Prediction}
In this section, we will first revisit the link prediction task for directed graphs and introduce a unified framework to assess the expressiveness of existing methods. Next, we examine the current experimental setups for directed link prediction and highlight several associated issues.

\textbf{Notation.} We consider a directed, unweighted graph $\gG = (V, E)$, with node set $V$ and edge set $E$. Let $n = |V|$ and $m = |E|$ represent the number of nodes and edges in $\gG$, respectively. We use $\mA$ to denote the adjacency matrix of $\gG$, where $\mA_{uv} = 1$ if there exists a directed edge from node $u$ to node $v$, and $\mA_{uv} = 0$ otherwise.
The Hermitian adjacency matrix of $\gG$ is denoted by $\mH$ and defined as $\mH = \mA_{\rm s} \odot \exp\left(i\frac{\pi}{2}\mathbf{\Theta}\right)$. Here, $\mA_{\rm s} = \mA \cup \mA^{\top}$ is the adjacency matrix of the undirected graph derived from $\gG$, and $\mathbf{\Theta} = \mA - \mA^{\top}$ is a skew-symmetric matrix.
We denote the out-degree and in-degree matrices of $\mA$ by $\mD_{\rm out} = {\rm diag}(\mA\vone)$ and $\mD_{\rm int} = {\rm diag}(\mA^{\top}\vone)$, respectively, where $\vone$ is the all-one vector. Let $\mX \in \mathbb{R}^{n \times d^{\prime}}$ denote the node feature matrix, where each node has a $d^{\prime}$-dimensional feature vector. Key notations of this paper are summarized in Appendix~\ref{app_notation}.



%In this section, we will replicate the link prediction tasks on directed graphs in the existing setup and discuss the associated issues. In addition, we will analyze the deep-seated reasons for these issues.

\subsection{Unified Framework for Directed Link Prediction}
The link prediction task on directed graphs is to predict potential directed links (edges) in an observed graph \( \gG^{\prime} \), with the given structure of \( \gG^{\prime} \) and node feature \( \mX \). Formally,
\begin{definition}\label{de_dlp}
\textbf{Directed link prediction problem}. Given an observed graph $\gG^{\prime}=(V, E^{\prime})$ and node feature $\mX$, the goal of directed link prediction is to predict the likelihood of a directed edge $(u,v) \in E^{\star}$ existing, where $E^{\star} \subseteq (V \times V) \setminus E^{\prime}$. The probability of edge $(u,v)$ existing is given by 
\begin{equation}
    p(u,v) = f(u \to v \mid \gG^{\prime}, \mX).
\end{equation}
\end{definition}
The $f(\cdot)$ denotes a prediction model, such as embedding methods or GNNs. 
%The threshold $\epsilon \in [0,1]$ determines whether an edge exists.
%\begin{equation}
%    E^{\star} = \left\{(u,v) \in (V \times V) \setminus E^{\prime} \mid p(u,v) \geq \epsilon \right\},
%\end{equation}
Unlike link prediction on undirected graphs~\cite{zhang2018link}, for directed graphs, it is necessary to account for directionality. Specifically, $p(u,v)$  and $p(v,u)$ are not equal; they represent the probability of a directed edge existing from node $u$ to node $v$, and from node $v$ to node $u$, respectively. To evaluate the expressiveness of existing methods for directed link prediction, we propose a unified framework: 
\begin{align}
    ({\bm \theta}_u, {\bm \phi}_u) &= \mathrm{Enc}(\gG^{\prime}, \mX, u), \quad \forall u \in V, \label{eq_encoder} \\
    p(u, v) &= \mathrm{Dec}({\bm \theta}_u, {\bm \phi}_u, {\bm \theta}_v, {\bm \phi}_v), \quad \forall (u, v) \in E^{\star}. \label{eq_decoder}
\end{align}
Here, $\mathrm{Enc}(\cdot)$ represents an encoder function, which includes various methods described in the Sec.~\ref{intro}. %These methods can be categorized into four types: source-target methods, gravity-inspired methods, single real-valued methods, and complex-valued methods. 
And ${\bm \theta}_u \in \mathbb{R}^{d_{\theta}}$, ${\bm \phi}_u \in \mathbb{R}^{d_{\phi}}$ are real-valued dual embeddings of dimensions ${d_{\theta}}$ and ${d_{\phi}}$, respectively. $\mathrm{Dec}(\cdot)$ is a decoder function tailored to the specific encoder method. This framework unifies existing methods for directed link prediction, as summarized in Table~\ref{table_fram}. More details are provided in Appendix~\ref{app_uni_fram}. Based on this framework, we have the following theorem.
\begin{theorem}\label{th_dual}
For the framework defined by Equations (\ref{eq_encoder}) and (\ref{eq_decoder}), if ${d_{\theta}}, {d_{\phi}} > 0$ and sufficiently large, there exist embeddings ${\bm \theta}_u, {\bm \phi}_u$ and a decoder $\mathrm{Dec}(\cdot)$ that can correctly compute the probability $p(u,v)$ of any directed edge $(u,v)$ in an arbitrary graph. Conversely, if ${d_{\theta}} = 0$ or ${d_{\phi}} = 0$, no such embeddings or decoders can compute the correct probability of any edges in an arbitrary graph.
\end{theorem}
The intuition behind the proof of this theorem is that dual embeddings can effectively reconstruct the structure of a graph. For example, in the source-target embeddings, we have $\mA_{uv} = \vs_u^{\top}\vt_v$, and in the complex-valued method, $\mH_{uv} = \vz_u \overline{\vz}_v$. The full proof can be found in Appendix~\ref{app_proof_th_dual}. Theorem~\ref{th_dual} demonstrates that dual embeddings are critical for preserving the asymmetry of directed graphs, and that a suitable decoder function is equally important. %To further highlight the significance of the decoder function,
%For decoder design, we present the following corollary:
\begin{corollary}\label{coro_de}
With dual embeddings $\bm{\theta}_u$ and $\bm{\phi}_u$, if there is no suitable decoder $\mathrm{Dec(\cdot)}$, the probability $p(u,v)$ of any edge $(u,v)$ cannot be computed correctly. In contrast, even with one single embedding ($\bm{\theta}_u$ or $\bm{\phi}_u = \varnothing$), a suitable decoder can improve the ability to compute edge probabilities.
\end{corollary}
The proof is given in Appendix~\ref{app_proof_cora_de}. This corollary shows that dual embeddings require suitable decoders for theoretical expressiveness, while single embeddings, though fundamentally limited, can still benefit from specific decoders in practice. For example, complex-valued methods using $\mathrm{MLP}\bigl({\bm\theta}_u \|{\bm\theta}_v \|\bm{\phi}_u \|\bm{\phi}_v\bigr)$~\cite{magnet} and single real-valued methods using $\mathrm{MLP}\bigl(\vh_u \| \vh_v\bigr)$~\cite{dpyg} have equal expressiveness if embedding dimensions are large.

%Existing methods for directed graph link prediction can be broadly categorized into \textbf{embedding-based methods} and \textbf{graph neural networks (GNNs)}. Embedding-based methods aim to preserve the asymmetry of directed graphs by generating two separate embeddings for each node: a source embedding $\vs_u$ and a target embedding $\vt_u$~\cite{eltra,odin}, which are also known as content/context representations~\cite{strap}. For an edge $(u, v)$, these methods use the source embedding $\vs_u$ 
%of node $u$ and the target embedding $\vt_v$ of node $v$ 
%to compute the probability $p(u,v) = \mathrm{Dec}(\vs_u, \vt_v)$. Here, $\vs_u, \vt_v \in \mathbb{R}^d$ are $d$-dimensional real-valued embeddings, and 
%$\mathrm{Dec}(\cdot)$ represents the decoder function, commonly chosen as the inner product or logistic regression.

%GNN-based methods, on the other hand, can be further divided into four distinct classes according to the types of embedding they generate. (1) The first class is similar to embedding-based methods, employing specialized propagation mechanisms to learn separate source and target embeddings for each node. (2) The second class, inspired by Newton’s law of universal gravitation, learns a real-valued embedding
%$\vh_u \in \mathbb{R}^d$ and a mass parameter $m_u \in \mathbb{R}^{+}$ for each node $u$, then computes $p(u,v) = \mathrm{Dec}(\vh_u, \vh_v, m_v)$. (3) The third class adopts a more traditional approach, learning a single embedding $\vh_u \in \mathbb{R}^d$ for each node and computing the probabilities as $p(u,v) = \mathrm{Dec}(\vh_u, \vh_v)$. (4) The last class is based on Hermitian adjacency matrices, learning complex-valued embeddings $\vz_u \in \mathbb{C}^d$ for each node and using $p(u,v) = \mathrm{Dec}(\vz_u, \vz_v)$ to obtain the edge probabilities.
%We have the following theorem.










%A directed graph \( G = (V, E) \), where \( V \) is the set of nodes, and \( E \subseteq V \times V \) is the set of directed edges. Node feature matrix \( \mathbf{X} \in \mathbb{R}^{|V| \times d} \), where each node has a feature vector of dimension \( d \).


   
%\textbf{Directionality Determination}:
%The directionality of edges between two nodes \( u \) and \( v \) is determined by evaluating the predictions \( f(u, v) \) and \( f(v, u) \):

%If \( f(u, v) \to 1 \) and \( f(v, u) \to 0 \), it indicates that there is a directed edge from \( u \) to \( v \).
%If \( f(v, u) \to 1 \) and \( f(u, v) \to 0 \), it indicates that there is a directed edge from \( v \) to \( u \).
%If \( f(u, v) \to 1 \) and \( f(v, u) \to 1 \), this suggests the presence of an undirected edge between \( u \) and \( v \) (i.e., a bidirectional edge).
%If \( f(u, v) \to 0 \) nor \( f(v, u) \to 0 \), then no edge exists between \( u \) and \( v \) in either direction.

%This approach ensures that the model not only predicts the existence of edges but also accurately captures the directionality or undirected nature of the relationship between nodes.


%\begin{theorem}
%Let $\gG = (V, E)$ be a directed graph with node set $V$ and edge set $E$, its adjacency matrix and Hermitian adjacency matrix denote as $\mA \in \mathbb{R}^{n \times n}$ and $\mH \in \mathbb{C}^{n \times n}$, respectively,  and let $d$ be a positive integer.

%\begin{enumerate}[label=(\alph*)]
%    \item If each node $v \in V$ is assigned an embedding $\vx_r(v) \in \mathbb{R}^d$, then there does not exist a function $f: \mathbb{R}^d \times \mathbb{R}^d \rightarrow \mathbb{R}$ such that the adjacency relationships of $G$ can be fully captured by $\mA_{ij} = f(\vx_r(v_i), \vx_r(v_j))$. Specifically, certain structures, such as the triangle with directed edges $(1 \rightarrow 2),\ (3 \rightarrow 1),\ (3 \rightarrow 2)$, cannot be effectively represented.

 %    \item If each node $v \in V$ is assigned an embedding $\vx_c(v) \in \mathbb{C}^d$, then the graph structure can be effectively represented. The Hermitian adjacency matrix $\mH$ can be decomposed as $\mH_{ij} = \vx_c(v_i)^* \overline{\vx}_c(v_j)$, from which the adjacency relationships of $G$ can be recovered.

%     \item If each node $v \in V$ is assigned two embeddings $\vx_s(v),\ \vx_t(v) \in \mathbb{R}^d$, then the graph structure can be effectively represented. There exists a function $g: \mathbb{R}^d \times \mathbb{R}^d \rightarrow \mathbb{R}$ such that the adjacency matrix $\mA$ of $G$ can be reconstructed via $\mA_{ij} = g(\vx_s(v_i), \vx_t(v_j))$.
% \end{enumerate}
% \end{theorem}

\begin{table*}[th]
\centering
\caption{Link prediction results on Cora dataset under the DUPLEX~\cite{duplex} setup: results without superscripts are from the DUPLEX paper, $^\dagger$ indicates reproduction with test set edges in training, and $^\ddagger$ indicates reproduction without test set edges in training.}
%\resizebox{\textwidth}{!}{
\begin{tabular}{@{}lllllll@{}}
\toprule

%\multicolumn{1}{l}{\multirow{2}{*}{Dataset}} & \multirow{2}{*}{Method} & \multicolumn{2}{c}{EP} & \multicolumn{2}{c}{DP} & 3C  & 4C  \\ \cmidrule(l){3-8} 
Method &EP(ACC) &EP(AUC) &DP(ACC) &DP(AUC) &3C(ACC) &4C(ACC) \\ \midrule
%\multicolumn{1}{l}{} & & ACC  & AUC  & ACC   & AUC  & ACC & ACC \\ \midrule
 MagNet &81.4$\pm$0.3 &89.4$\pm$0.1 &88.9$\pm$0.4 &95.4$\pm$0.2 &66.8$\pm$0.3 &63.0$\pm$0.3 \\
 DUPLEX &93.2$\pm$0.1 &95.9$\pm$0.1 &95.9$\pm$0.1 &97.9$\pm$0.2 &92.2$\pm$0.1 &88.4$\pm$0.4  \\ \midrule

 DUPLEX$^\dagger$ &93.49$\pm$0.21 &95.61$\pm$0.20 &95.25$\pm$0.16 &96.34$\pm$0.23  &92.41$\pm$0.21 &89.76$\pm$0.25 \\

 MLP$^\dagger$ &88.53$\pm$0.22	&\textbf{95.46$\pm$0.18}	&\textbf{95.76$\pm$0.21}	&\textbf{99.25$\pm$0.06}	&79.97$\pm$0.48	&78.49$\pm$0.26  \\ \midrule

 DUPLEX$^\ddagger$ &87.43$\pm$0.20 &91.16$\pm$0.24 &88.43$\pm$0.16 &91.74$\pm$0.38 &84.53$\pm$0.34 &81.36$\pm$0.46 \\
 MLP$^\ddagger$ &84.00$\pm$0.29	&\textbf{91.52$\pm$0.25}	&\textbf{90.83$\pm$0.16}	&\textbf{96.48$\pm$0.28}	&72.93$\pm$0.21	&71.51$\pm$0.20  \\
  \bottomrule

\end{tabular}
\label{tb:duplex}
\end{table*}




\subsection{Issues with Existing Experimental Setup}\label{issues}
The existing directed link prediction experimental setups can be broadly categorized into two types. The first is the \textbf{multiple subtask setup}, which includes existence prediction (EP), direction prediction (DP), three-type prediction (3C), and four-type prediction (4C). This approach treats directed link prediction as a multi-class classification problem that requires the prediction of positive, inverse, bidirectional, and nonexistent edges. More details are provided in Appendix~\ref{app_issues_subtask}. This setup is widely adopted by existing methods~\cite{magnet,dpyg,fiorini2023sigmanet,lin2023magnetic,duplex,lightdic}.

The other category is the \textbf{non-standardized setting} defined in various papers~\cite{strap,odin,dhypr,digae,coba}. These settings involve different datasets, inconsistent splitting methods, and varying evaluation metrics. We discuss the four issues with existing setups below. 


\textbf{Issue 1: The Multi-layer Perceptron (MLP) is a neglected but powerful baseline.} 
Most existing setups do not report MLP performance. We evaluate MLP across three popular multiple subtask setups: MagNet~\cite{magnet}, DUPLEX~\cite{duplex}, and PyGSD~\cite{dpyg} covering their different datasets and baselines. Figures~\ref{fig:dp} and~\ref{fig:ep} present the results of our reproduced MagNet experiments alongside the MLP results, showing that MLP performs comparably to MagNet on DP and EP tasks. Table~\ref{tb:duplex} shows the replicated DUPLEX experiments and MLP results on the Cora dataset, demonstrating that MLP achieves competitive performance. Interestingly, while DUPLEX represents the latest advancement in directed graph learning, MLP outperforms it in certain tasks. %Additional results for PyGSD and other datasets are provided in Appendix~\ref{app_issues_results}. 
These findings highlight the absence of basic baselines in prior work and suggest that current benchmarks lack sufficient challenge.

%In most existing setups, researchers have not reported the performance of MLP. We evaluate MLP in three recent and widely used multiple subtask setups: MagNet~\cite{magnet}, DUPLEX~\cite{duplex}, and PyGSD~\cite{dpyg}. Although these setups belong to the multiple subtask framework, they use different datasets and split settings, so we evaluate MLP across all of them. In Figures~\ref{fig:dp} and~\ref{fig:ep} , we reproduce the MagNet experiments and present the MLP results. The findings show that MLP performs comparably with MagNet in five datasets for both DP and EP tasks. In Table~\ref{tb:duplex}, we replicate DUPLEX experiments and report the MLP results on Cora, demonstrating that MLP delivers competitive performance. Notably, although DUPLEX is the latest advancement in directed graph learning research, MLP outperforms it on some tasks. Additional results for PyGSD and other datasets are provided in Appendix~\ref{app_issues_results}. These results show that MLP can perform strongly under the existing multiple subtask setups. On the one hand, this highlights the absence of basic baselines in prior research; on the other hand, it suggests that the current benchmark settings lack challenge.

%In most existing settings, researchers have not reported the results of the MLP. We evaluate MLP in three recent and common multiple subtask settings, including MagNet~\cite{magnet}, DUPLEX~\cite{duplex} and PyGSD~\cite{dpyg}. Although they are all use the multiple subtask setting, they have different dataset and splitting, so we evaluate in all of them. In Figure~\ref{fig:magnet_mlp}, we reproduce MagNet experiments and present the MLP results. The results indicate that MLP performs on par with MagNet in five datasets for both directed and existence link prediction tasks. In Table~\ref{tb:duplex}, we replicate the DUPLEX's experiments and report MLP results on Cora dataset, which also show MLP delivers competitive performance and consistently outperforms MagNet. Note that DUPLEX is the latest advancement research for directed graphs, but MLP outperforms it on EP and DP tasks. Due to the space constraints, we report more results of PyGSD and different datasets in the Appendix.

%These results naturally raise the question of why MLP can achieve such strong link prediction performance, even outperforming some GNN models specifically designed for directed graphs, such as MagNet and DUPLEX. 


%We believe two aspects are worth considering: (1) the current benchmark experiments are poorly designed and fail to fairly evaluate the ability of different methods to perform link prediction on directed graphs, and (2) MLP possesses an inherent capability to perform link prediction on directed graphs, making it essential to conduct a detailed analysis of their underlying mechanisms.

%We evaluated MLP in three recent and common benchmark settings and found that it performs comparable to state-of-the-art methods within these frameworks. The pioneering and widely used setting is derived from MagNet~\cite{magnet}, and numerous studies adopt this setup in their link prediction experiments~\cite{dpyg, duplex, lightdic}. 
%Two other important benchmark settings are PyGSD~\cite{dpyg} and DUPLEX~\cite{duplex}, both of which improve the MagNet setting. PyGSD is a software package designed for Signed and Directed Graphs, built on PyTorch Geometric (PyG). 
%We compare the baselines reported in PyGSD with MLP and present the results in Tables 2 and 3. Notably, in the Direction Link Prediction (DP) and Existence Link Prediction (EP) tasks across six datasets, MLP demonstrates competitive performance and achieves SOTA results on both tasks for the Texas and Wisconsin datasets. 
%DUPLEX represents the latest advancement in GNN research for directed graphs. Its paper provides a detailed comparison of the performance of existing methods for link prediction on directed graphs. We replicated their experiments and reported the MLP results under the same conditions, as outlined in Table 6 of the Appendix. The findings show that MLP delivers competitive performance and consistently outperforms MagNet.


%\begin{figure}[t]
%    \centering
%   \vspace{-2mm}
%   %\hspace{-3mm}  
%   \includegraphics[width=75mm]{figure/cora_bar_chart.pdf}
%   \vspace{-3mm}
%   \caption{Performance of DUPLEX's link prediction on Cora for the 4C task. Blue bars represent the number of samples in each class, while orange bars show the corresponding accuracy.}
%   \vspace{-2mm}
%    \label{fig:duplex_cls}
% \end{figure}




\textbf{Issue 2: Many benchmarks suffer from label leakage.}
%Link prediction is defined as the task of predicting which pairs of nodes may have unobserved edges between them, based on the structural information of the observed nodes and edges in a graph. In the link prediction task, edge information in the test set should not be accessible during model training; otherwise, it constitutes label leakage. The benchmarks established in MagNet and PyGSD exhibit label leakage, which occurs during the negative sampling process in training. Specifically, the model samples a large number of negative edges alongside positive edges during training, and this negative sampling inadvertently observed edges from the test set. For example, consider a social network where the user \( u \) follows the user \( v \). If the trained model is tasked with predicting this relationship but has already known the \( u \)-to-\( v \) relationship during negative sampling, the relationship will not be used as a negative sample. This type of label leakage in negative sampling has a limited effect when the number of nodes \( n \) in the graph is large, as there are more negative samples available. However, it significantly affects graphs with smaller \( n \), such as Texas or Cornell, where there are fewer negative samples available for selection.
As defined in Definition~\ref{de_dlp}, directed link prediction aims to predict potential edges from observed graphs, with the key principle that test edges must remain hidden during training to avoid label leakage. However, current setups often violate this principle. For example, 
1) MagNet, PyGSD, and DUPLEX expose test edges during negative edge sampling in the training process, indirectly revealing the test edges' presence to the model.
%resulting in test edges never being treated as negative samples and indirectly revealing their presence to the model.
2) LighDiC~\cite{lightdic} uses eigenvectors of the Laplacian matrix of the entire graph as input features, embedding test edge information in the training input. 
3) DUPLEX propagates information across the entire graph during training, making the test edges directly visible to the model. %These issues highlight serious label leakage concerns in existing setups. 
To investigate, we experiment with DUPLEX using its original code. As shown in Table~\ref{tb:duplex}, DUPLEX$^\dagger$ (original settings with label leakage) clearly outperforms DUPLEX$^\ddagger$ (propagation restricted to training edges) due to label leakage. A similar result is observed with MLP: MLP$^\dagger$ (using in/out degrees from test edges) significantly outperforms MLP$^\ddagger$ (using only training-edge degrees). These findings underscore that even the leakage of degree information can significantly impact performance.

%Since the setup of DUPLEX involves significant label leakage, we conduct experiments using the code provided, and the results on Cora are presented in Table~\ref{tb:duplex}. Here, DUPLEX$^\dagger$ represents the results reproduced with the original settings, while DUPLEX$^\ddagger$ is the results using only the training edges for propagation. DUPLEX$^\dagger$ performs better, probably due to label leakage. Interestingly, a similar result is observed with MLP: MLP$^\dagger$ uses in/out degrees derived from test edges as input features, while MLP$^\ddagger$ relies only on degrees from the training edges. The results show a significant performance boost for MLP$^\dagger$. These findings underscore that even leakage of degree information can greatly impact performance.
%and 2) degree information is crucial for link prediction tasks.

%The experimental setup of DUPLEX reveals significant label leakage, not only in negative sampling but also in the graph propagation process during training, where edges from the test set are used to propagate. This constitutes a critical label leakage, as graph propagation is heavily based on structural information, and accessing test edges during training is highly unreasonable. We conducted experiments using the code provided by DUPLEX and present the results in Table 6. In these experiments, DUPLEX$^\dagger$ represents the results reproduced based on the original settings, while DUPLEX$^\ddagger$ reflects the results obtained when only the training graph is used for propagation. The comparison reveals that DUPLEX$^\dagger$ achieves better results, primarily due to label leakage. 

%Interestingly, a similar phenomenon is observed with MLP. During training, MLP$^\dagger$ can also access edge information from the test set. However, since MLP does not perform graph propagation, we use the in/out degrees of the nodes as its input feature. Specifically, the input feature for MLP$^\dagger$ includes the in/out degrees derived from the test edges, while for MLP$^\ddagger$, it is limited to those of the training graph. The results demonstrate a significant performance boost for MLP$^\dagger$ over MLP$^\ddagger$, with MLP$^\dagger$ even outperforming MagNet. This observation highlights two key points: first, even slight leakage of degree information can substantially influence performance, and second, degree information plays a pivotal role in link prediction tasks.


%These issues underscore significant concerns about label leakage in current link prediction setups.



%\begin{figure}[t]
%    \centering
%   \vspace{-1mm}
%   %\hspace{-3mm}
%   \subfigure[Cora]{
%   \includegraphics[width=65mm]{figure/cora_bar_chart.pdf}
%   }
%   %\hspace{3mm}
%   %\vspace{-2mm}
%   \subfigure[Citeseer]{
%   \includegraphics[width=65mm]{figure/citeseer_bar_chart.pdf}}
%   \vspace{-1mm}
%   \caption{The link prediction results of MagNet as reported in the original paper, along with those of the reproduced MagNet and MLP.}
%   \vspace{-1mm}
%   \label{fig:duplex_cls}
% \end{figure}

%\textbf{Observation 3: The evaluation metric is too simple}. Most existing methods rely on accuracy as the evaluation metric, which is relatively simplistic compared to the metrics used for link prediction in undirected graphs.




\textbf{Issue 3: Multiple subtask setups result in class imbalances and limited evaluation metrics.}
The multiple subtask setups treat directed link prediction as a multi-class classification problem, causing significant class imbalances that hinder model training. For example, the 4C task in DUPLEX classifies edges into reverse, positive, bidirectional, and nonexistent. However, bidirectional edges are rare in real-world directed graphs, and reverse edges are often arbitrarily assigned, lacking meaningful physical significance. Figure~\ref{fig:imbalance} highlights the class imbalance and the challenge of predicting bidirectional edges on the Cora dataset. Additionally, these setups rely heavily on accuracy as an evaluation metric, which provides a limited and potentially misleading
assessment. Given the nature of link prediction, ranking metrics such as Hits@K and Mean Reciprocal Rank (MRR) are more suitable—a perspective well established in link prediction for undirected graphs~\cite{li2023evaluating}.

%Ranking metrics like Hits@K and Mean Reciprocal Rank (MRR), commonly used for undirected graphs~\cite{li2023evaluating}, are more suitable for link prediction.

%As described in Section 2, many existing methods approach link prediction on directed graphs as a multiclass classification problem.
%The multiple subtask setups treat directed link prediction as a multi-classification problem, leading to significant class imbalances and complicating model training. For example, the 4C task in DUPLEX aims to classify edges into four categories: reverse, positive, bidirectional, and nonexistent. However, in real-world directed graphs, bidirectional edges are typically rare, resulting in a low proportion. Additionally, reverse edges are often arbitrarily assigned in homogeneous graphs, lacking meaningful physical significance. %To address imbalances, the counts of reverse and non-existent edges are often artificially adjusted to equalize the number of edges in each class.
%Figure~\ref{fig:imbalance} illustrates the number of samples and the accuracy for each class of DUPLEX on the Cora dataset in the 4C task, showcasing the pronounced class imbalance and the difficulty in predicting bidirectional edges. Furthermore, this setting predominantly uses accuracy as an evaluation metric, which provides a limited and potentially misleading assessment. Given the nature of link prediction, ranking metrics such as Hits@K and Mean Reciprocal Rank (MRR) are more suitable—a perspective well-established in link prediction for undirected graphs~\cite{li2023evaluating}.

%The intuition behind link prediction is to estimate the likelihood that an edge will form between two nodes in the future. Therefore, 

%DUPLEX~\cite{duplex} defines the directed link prediction task as a four-class problem, with labels 0, 1, 2, and 3 representing reverse, positive, bidirectional, and nonexistent edges, respectively. 

%However, this approach results in significant class imbalance, complicating model training. 



\textbf{Issue 4: Lack of standardization in dataset splits and feature inputs.}
Current settings face inconsistent dataset splits. In multiple subtask setups, edges are typically split into 80\% for training, 5\% for validation, and 15\% for testing. However, class proportions are further manually adjusted for balance, which leads to varying training and testing ratios across different datasets. Non-standardized setups are more confusing, e.g., ELTRA~\cite{eltra} uses 90\% for training, STRAP~\cite{strap} uses 50\%, and DiGAE~\cite{digae} uses 85\%, making cross-study results difficult to evaluate.
%Current settings suffer from inconsistent dataset splits. In multiple subtask settings, the edges are typically split, with 80\% for training, 5\% for validation, and 15\% for testing. However, class proportions are further manually adjusted for balance, leading to varying training and testing ratios across datasets. Non-standardized settings are more confusing; for example, ELTRA~\cite{eltra} uses 90\% edges for training, STRAP~\cite{strap} uses 50\%, and DiGAE~\cite{digae} uses 85\%, making it difficult to compare the results reported between studies.
%Existing approaches lack standardized feature inputs. Embedding methods often ignore node features, while GNNs require them. For example, MagNet~\cite{magnet} and PyGSD~\cite{dpyg} use in/out degrees, DUPLEX~\cite{duplex} uses random normal distributions, LightDiC~\cite{lightdic} uses original node features or Laplacian eigenvectors, and DHYPR~\cite{dhypr} uses identity matrices. This inconsistency hinders reproducibility. As shown in Figure~\ref{fig:magnet_mlp} and Table~\ref{tb:duplex}, our reproduced results differ significantly from the reported ones, with some being better and others worse.
Feature input standards are also lacking. Embedding methods often omit node features, while GNNs require them. MagNet and PyGSD use in/out degrees, DUPLEX uses random normal distributions, LightDiC uses original features or Laplacian eigenvectors, and DHYPR~\cite{dhypr} uses identity matrices. This inconsistency undermines reproducibility. As shown in Figure~\ref{fig:magnet_mlp} and Table~\ref{tb:duplex}, reproduced results often deviate significantly, with some better and others worse.

%Due to the space constraints, more details and experimental results of this part are provided in Appendix~\ref{app_issues_results}. These issues highlight the need for a unified benchmark for directed graph link prediction, allowing fair evaluation and providing a foundation for future research.
More details and experimental results are provided in Appendix~\ref{app_issues_results}. These issues emphasize the need for a new benchmark for directed link prediction, allowing fair evaluation and providing a foundation for future research.











%\begin{table}[ht]
%\centering
%\caption{Performance comparison of different models on Three Classes Prediction (3C) task.}
%\resizebox{\textwidth}{!}{
%\begin{tabular}{ccccccc}
%\toprule
%Method & Cora-ML & Citeseer & Telegram & Cornell & Texas & Wisconsin \\ \midrule
%MLP  & 70.56 $\pm$ 0.78  & 64.97 $\pm$ 0.72  & 77.33 $\pm$ 0.49  & 63.05 $\pm$ 2.92  & 69.31 $\pm$ 3.91  & 67.33 $\pm$ 2.06 \\ \midrule 
%DGCN      & 69.05 $\pm$ 0.64  & 64.81 $\pm$ 0.59  & 78.65 $\pm$ 0.75  & 59.64 $\pm$ 4.83  & 65.29 $\pm$ 3.81  & 67.68 $\pm$ 3.29  \\ 
%DiGCN     & 67.88 $\pm$ 0.61  & 64.99 $\pm$ 0.90  & 78.40 $\pm$ 0.44  & 59.37 $\pm$ 2.90  & 64.53 $\pm$ 1.48  & 65.10 $\pm$ 3.57  \\
%DiGCNIB   & 70.71 $\pm$ 0.74  & 68.47 $\pm$ 0.69  & 80.01 $\pm$ 0.68  & 61.74 $\pm$ 3.32  & 67.47 $\pm$ 2.93  & 70.00 $\pm$ 2.36  \\ 
%MagNet    & 71.26 $\pm$ 0.64  & 65.07 $\pm$ 0.80  & 82.66 $\pm$ 0.38  & 60.43 $\pm$ 3.18  & 67.12 $\pm$ 3.15  & 67.89 $\pm$ 2.95 \\  \bottomrule
%\end{tabular}}
%\end{table}


