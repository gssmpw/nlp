\appendix
\onecolumn
\clearpage
\section*{Appendix Contents} % 
\begin{itemize}
  \item \hyperlink{app:app_notation}{Appendix A: Notation} ~~~~ p.\pageref{app_notation}
 \vspace{4pt}
   
  %\begin{itemize}[leftmargin=2em, nosep] % 2
  %  \item \hyperlink{app:lemma}{A.1: Technical Lemma} ~~~~ p.\pageref{app:lemma}
 % \end{itemize}
  
  \item \hyperlink{app:proof}{Appendix B: Proof} ~~~~ p.\pageref{app_proof}
  \vspace{4pt}
  \begin{itemize}[leftmargin=2em, nosep] % 2
    \item \hyperlink{app_proof_th_dual}{B.1: The proof of Theorem 2.2} ~~~~ p.\pageref{app_proof_th_dual} \\
    \item \hyperlink{app_proof_cora_de}{B.2: The proof of Corollary 2.3} ~~~~ p.\pageref{app_proof_cora_de}\\
    \item \hyperlink{app_proof_cora_de}{B.3: The proof of Lemma 4.1} ~~~~ p.\pageref{app_proof_cora_de}\\
    \item \hyperlink{app_proof_le_norm}{B.4: The proof of Lemma 4.2} ~~~~ p.\pageref{app_proof_le_norm}
  \end{itemize}
  \vspace{4pt}

   \item \hyperlink{app:related_work}{Appendix C: Related Work} ~~~~ p.\pageref{app:related_work}
   
   \vspace{4pt}
   \item \hyperlink{app_uni_fram}{Appendix D: Details of Unified Framework} ~~~~ p.\pageref{app_uni_fram}

   \vspace{4pt}
   \item \hyperlink{app_issues}{Appendix E: Issues with Existing Experimental Setup} ~~~~ p.\pageref{app_issues}
   \vspace{4pt}
   \begin{itemize}[leftmargin=2em, nosep] % 2
    \item \hyperlink{app_issues_subtask}{E.1: Details of multiple subtask setup} ~~~~ p.\pageref{app_issues_subtask} \\
    \item \hyperlink{app_issues_results}{E.2: Details of experimental setting and more results} ~~~~ p.\pageref{app_issues_results}
  \end{itemize}
   \vspace{4pt}
  \item \hyperlink{app_sdgae}{Appendix F: Details and Experimental Setting for SDGAE} ~~~~ p.\pageref{app_sdgae}
   \vspace{4pt}
   \begin{itemize}[leftmargin=2em, nosep] % 2
    \item \hyperlink{app_sdgae_conv}{F.1: More details of graph convolution} ~~~~ p.\pageref{app_sdgae_conv} \\
    \item \hyperlink{app_sdgae_setting}{F.2: Experimental setting} ~~~~ p.\pageref{app_sdgae_setting}
  \end{itemize}
  
  \vspace{4pt}
  \item \hyperlink{app:experiments}{Appendix G: More Details of DirLinkBench} ~~~~ p.\pageref{app:experiments}
  \vspace{4pt}
  \begin{itemize}[leftmargin=2em, nosep] % 2
    \item \hyperlink{app_dataset_baseline}{G.1: Datasets and baselines} ~~~~ p.\pageref{app_dataset_baseline} \\
    \item \hyperlink{app_bench_metric}{G.2: Metric description} ~~~~ p.\pageref{app_bench_metric} \\
    \item \hyperlink{app_bench_res_ana}{G.3: Additional results in analysis} ~~~~ p.\pageref{app_bench_res_ana}
    
  \end{itemize}

  \vspace{4pt}
  \item \hyperlink{app_complete_res}{Appendix H: Complete Results of DirLinkBench on Seven Datasets} ~~~~ p.\pageref{app_complete_res}
  \vspace{4pt}
   \begin{itemize}[leftmargin=2em, nosep] % 2
    \item \hyperlink{app_complete_res_cora}{H.1: Results on Cora-ML} ~~~~ p.\pageref{app_complete_res_cora} \\
    \item \hyperlink{app_complete_res_citeseer}{H.2: Results on CiteSeer} ~~~~ p.\pageref{app_complete_res_citeseer} \\
    \item \hyperlink{app_complete_res_photo}{H.3: Results on Photo} ~~~~ p.\pageref{app_complete_res_photo} \\
    \item \hyperlink{app_complete_res_computers}{H.4: Results on Computers} ~~~~ p.\pageref{app_complete_res_computers} \\
    \item \hyperlink{app_complete_res_wiki}{H.5: Results on WikiCS} ~~~~ p.\pageref{app_complete_res_wiki} \\
    \item \hyperlink{app_complete_res_slash}{H.6: Results on Slashdot} ~~~~ p.\pageref{app_complete_res_slash} \\
    \item \hyperlink{app_complete_res_epinion}{H.7: Results on Epinions} ~~~~ p.\pageref{app_complete_res_epinion} 
  \end{itemize}
  
   
\end{itemize}

\newpage

\hypertarget{app:app_notation}{} 
\section{Notation}\label{app_notation}
We summarize the main notations of the paper in Table~\ref{notation}.
\begin{table}[th]
\centering

\caption{Summation of main notations in this paper.}\label{tbl:def-notation}
\begin{tabular} {l|p{5.0in}} \hline
\toprule
{\bf Notation} &  {\bf Description}  \\ \midrule
$\gG=(V,E)$ & directed unweighted graph with node set $V$ and edge set $E$. \\ \midrule
$n, m$ & the number of nodes and edges, $n = |V|$ and $m = |E|$. \\ \midrule

$\mA$ & the adjacency matrix of $\gG$, $\mA_{uv} = 1$ for a edge from node $u$ to $v$, and $\mA_{uv} = 0$ otherwise. \\ \midrule

 $\mH$ & the Hermitian adjacency matrix, defined as $\mH = \mA_{\rm s} \odot \exp\left(i\frac{\pi}{2}\mathbf{\Theta}\right)$. \\ \midrule

$\mA_{\rm s}$ & the  adjacency matrix of the undirected graph derived from $\gG$, $\mA_{\rm s} = \mA \cup \mA^{\top}$. \\ \midrule

$\mathbf{\Theta}$ & the skew-symmetric matrix $\mathbf{\Theta} = \mA - \mA^{\top}$. \\ \midrule

$\mD_{\rm out}, \mD_{\rm int}$ & the out- and in-degree matrix of $\mA$, $\mD_{\rm out} = {\rm diag}(\mA\vone) $ and $\mD_{\rm int} = {\rm diag}(\mA^{\top}\vone)$. \\ \midrule

$\mX$ & the node feature matrix, $\mX \in \mathbb{R}^{n \times d^{\prime}}$ and $d^{\prime}$ is the dimension. \\ \midrule

$\bm{\theta}_u, \bm{\phi}_u$ & real-valued dual embeddings $\bm{\theta}_u\in \mathbb{R}^{d_\theta}, \bm{\phi}_u\in \mathbb{R}^{d_\phi}$, $d_\theta, d_\phi$ are the dimensions. \\ \midrule

$p(u,v)$ & the probability of directed edge $(u,v)$ existing. \\ \midrule

$\gG^{\prime}=(V, E^{\prime})$ & the observed/training graph with node set $V$ and edge set $E^{\prime}$. \\ \midrule

$\hat{\mA}$ & the adjacency matrix with added self-loops, $\hat{\mA}=\mA + \mI$. \\ \midrule

$\hat{\mD}_{\rm out}, \hat{\mD}_{\rm int}$ & the out- and in-degree matrix of $\hat{\mA}$. \\ \midrule

$\mathcal{S}(\hat{\mA})$ & the block matrix consisting of $\hat{\mA}$ and $\hat{\mA}^{\top}$. \\ \midrule

$\Tilde{\mA}$ & the normalized adjacency matrix, $\Tilde{\mA} =\hat{\mD}_{\rm out}^{-1/2}\hat{\mA}\hat{\mD}_{\rm in}^{-1/2}$. \\ \midrule

$\odot, \quad \|$ & the Hadamard product and concatenation process. \\ \midrule

$d, \quad d^{\prime}$ & the dimension of embeddings and feature matrix. \\

\bottomrule
\end{tabular}
\label{notation}
%\vspace{-3mm}
\end{table}

\input{appendix_proof}

\input{related_work}






\hypertarget{app_uni_fram}{} 
\section{Details of Unified Framework}\label{app_uni_fram}

\begin{table}[h]
\centering
\vspace{-4mm}
\caption{The unified framework for directed link prediction methods.}
\label{app_table_fram}
%\begin{tabular}{@{}l@{\quad}l@{\quad}l@{}}
\begin{tabular}{@{}lllllllll@{}}
\toprule
Encoder $\mathrm{Enc}(\cdot)$ 
 &\multicolumn{2}{l}{Embeddings $({\bm \theta_u}, {\bm \phi_u})$}
 &\multicolumn{6}{l}{Possible Decoder $\mathrm{Dec}(\cdot)$}\\
\midrule
Source-target  & $\vs_u = \bm{\theta}_u$,           & $\vt_u = \bm{\phi}_u$          & \multicolumn{2}{l}{$\sigma\bigl(\vs_u^{\top}\vt_v\bigr)$;} & \multicolumn{2}{l}{$\mathrm{LR}\bigl(\vs_u \odot \vt_v\bigr)$;} & \multicolumn{2}{l}{\quad$\mathrm{LR}\bigl(\vs_u \|\vt_v\bigr)$} \\[3.0pt]

Single real-valued  & $\vh_u = \bm{\theta}_u$,  & $\varnothing = \bm{\phi}_u$          & \multicolumn{2}{l}{$\sigma\bigl(\vh_u^{\top}\vh_v\bigr)$;} & \multicolumn{2}{l}{$\mathrm{MLP}\bigl(\vh_u \odot \vh_v\bigr)$;} & \multicolumn{2}{l}{\quad$\mathrm{MLP}\bigl(\vh_u \|\vh_v\bigr)$} \\[3.0pt]

Complex-valued  & \multicolumn{2}{l}{$\vz_u = \bm{\theta}_u\odot\exp\bigl(i\,\bm{\phi}_u\bigr)$}  & \multicolumn{2}{l}{$\mathrm{Direc}\bigl(\vz_u,\vz_v\bigr)$;} & \multicolumn{4}{l}{$\mathrm{MLP}\bigl(\bm{\theta}_u \|\bm{\theta}_v \|\bm{\phi}_u \|\bm{\phi}_v\bigr)$} \\[3.0pt]

Gravity-inspired  & $\vh_u = \bm{\theta}_u$,  &$m_u = g(\bm{\phi}_u)$         & \multicolumn{3}{l}{$\sigma\bigl(m_v - \lambda\log\|\vh_u-\vh_v\|_2^2\bigr)$;}              & \multicolumn{3}{l}{$\sigma\bigl(m_v - \lambda\log \bigl(\mathrm{dist}_{\mathbb{D}_c^{d'}}(\vh_u,\vh_v)\bigr)\bigr)$}  \\
\bottomrule
\end{tabular}
\end{table}

%Here, we introduce the details of the examples in our unified framework for directed link prediction methods. For the convenience of reading, we copy the Table~\ref{table_fram} from the main paper below.
%In Table~\ref{app_table_fram}, $\sigma$ is the activation function, e.g., $\mathrm{Sigmoid}$; $\mathrm{LR}$ denotes the logistic regression classifier and $\mathrm{MLP}$ denotes multilayer perceptron. $\odot$ and $\|$ denote the Hadamard product and concat process of vectors, respectively. For source-target encoder, we set source embedding $\vs_u = \bm{\theta}_u$, target embedding $\vt_u=\bm{\phi}_u$ for each node $u \in V$. The possible decoders include $\sigma\bigl(\vs_u^{\top}\vt_v\bigr)$, $\mathrm{LR}\bigl(\vs_u \odot \vt_v\bigr)$, and $\mathrm{LR}\bigl(\vs_u \|\vt_v\bigr)$, where $\vs_u^{\top}\vt_v$ denotes the inner product of source  and target embeddings, $\mathrm{LR}(\cdot)$ denotes logistic regression predictor. For single real-valued encoder, we set real-valued embedding $\vh_u = \bm{\theta}_u$ and $\bm{\phi}_u=\varnothing$, $\varnothing$ denotes nonexistent. The possible decoders include $\sigma\bigl(\vh_u^{\top}\vh_v\bigr)$, $\mathrm{MLP}\bigl(\vh_u \odot \vh_v\bigr)$, $\mathrm{MLP}\bigl(\vh_u \|\vh_v\bigr)$. For complex-valued encoder, we set complex-valued embedding $\vz_u=\bm{\theta}_u\odot\exp({i\bm{\phi}_u})$, where $i$ is the imaginary unit. The possible decoders include $\mathrm{Direc}\bigl(\vz_u,\vz_v\bigr)$ and $\mathrm{MLP}\bigl(\bm{\theta}_u \|\bm{\theta}_v \|\bm{\phi}_u \|\bm{\phi}_v\bigr)$, where $\mathrm{Direc}(\cdot)$ denotes the direction-aware decoder defined in DUPLEX~\cite{duplex}. For gravity-inspired encoder, we set real-valued embedding $\vh_u = \bm{\theta}_u$ and mass parameter $m_u = g(\bm{\phi}_u)$, where $g(\cdot)$ is a function or neural network for converting $\bm{\phi}_u$ to a scalar~\cite{dhypr}. The possible decoders include $\sigma\bigl(m_v - \lambda\log\|\vh_u-\vh_v\|_2^2\bigr)$ ~\cite{gragae} and $\sigma\bigl(m_v - \lambda\log \bigl(\mathrm{dist}_{\mathbb{D}_c^{d'}}(\vh_u,\vh_v)\bigr)\bigr)$~\cite{dhypr}, where $\lambda$ is a hyperparameter and $\mathrm{dist}_{\mathbb{D}_c^{d'}}(\cdot)$ denotes hyperbolic distance.

Here, we introduce the details of the examples within our unified learning framework for directed link prediction methods. For readability, we copy Table~\ref{table_fram} from the main paper in Table~\ref{app_table_fram}. Here, $\sigma$ represents the activation function (e.g., $\mathrm{Sigmoid}$), while $\mathrm{LR}$ and $\mathrm{MLP}$ denote the logistic regression predictor and the multilayer perceptron, respectively. The symbols $\odot$ and $\|$ represent the Hadamard product and the vector concatenation process, respectively.

For \underline{source-target encoder}, we define the source embedding as $\vs_u = \bm{\theta}_u$ and the target embedding as $\vt_u=\bm{\phi}_u$ for each node $u \in V$. Possible decoders include:
$\sigma\bigl(\vs_u^{\top}\vt_v\bigr)$,  
$\mathrm{LR}\bigl(\vs_u \odot \vt_v\bigr)$,  
$\mathrm{LR}\bigl(\vs_u \|\vt_v\bigr)$.  
Here, $\vs_u^{\top}\vt_v$ denotes the inner product of the source and target embeddings, while $\mathrm{LR}(\cdot)$ represents the logistic regression predictor.

For \underline{single real-valued encoder}, we define the real-valued embedding as $\vh_u = \bm{\theta}_u$ and set $\bm{\phi}_u=\varnothing$, where $\varnothing$ denotes nonexistence. Possible decoders include:
$\sigma\bigl(\vh_u^{\top}\vh_v\bigr)$,  
$\mathrm{MLP}\bigl(\vh_u \odot \vh_v\bigr)$,  
$\mathrm{MLP}\bigl(\vh_u \|\vh_v\bigr)$.  

For \underline{complex-valued encoder}, we define the complex-valued embedding as $\vz_u=\bm{\theta}_u\odot\exp({i\bm{\phi}_u})$, where $i$ is the imaginary unit. Possible decoders include:
$\mathrm{Direc}\bigl(\vz_u,\vz_v\bigr)$,  
$\mathrm{MLP}\bigl(\bm{\theta}_u \|\bm{\theta}_v \|\bm{\phi}_u \|\bm{\phi}_v\bigr)$.  
Here, $\mathrm{Direc}(\cdot)$ refers to the direction-aware decoder defined in DUPLEX~\cite{duplex}.

For \underline{gravity-inspired encoder}, we define the real-valued embedding as $\vh_u = \bm{\theta}_u$ and set the mass parameter $m_u = g(\bm{\phi}_u)$, where $g(\cdot)$ is a function or neural network that converts $\bm{\phi}_u$ into a scalar~\cite{dhypr}. Possible decoders include:
$\sigma\bigl(m_v - \lambda\log\|\vh_u-\vh_v\|_2^2\bigr)$ ~\cite{gragae},  
$\sigma\bigl(m_v - \lambda\log \bigl(\mathrm{dist}_{\mathbb{D}_c^{d'}}(\vh_u,\vh_v)\bigr)\bigr)$~\cite{dhypr}.  
Here, $\lambda$ is a hyperparameter and $\mathrm{dist}_{\mathbb{D}_c^{d'}}(\cdot)$ represents the hyperbolic distance.

\input{appendix_issues}



\input{appendix_sdgae}

\input{appendix_benchmark}

\input{appendix_allresults}