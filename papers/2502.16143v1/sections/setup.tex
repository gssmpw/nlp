\section{Experimental Setup}
In this section, we introduce datasets and baselines for the experimental setup.



% \subsection{Datasets}
% We experiment on two public datasets that explore hallucinations caused by conflicting knowledge and our Overshadowing dataset.

% Memotrap in appendix

% NQ-SWAP in appendix

% \paragraph{Overshadow. }
% As elaborated in \S~\ref{sec:formulation} (more details in~\ref{ssec: overshadowing_dataset}), our Overshadowing dataset contains more popular and less popular knowledge sets with varying relative knowledge popularity levels and relative knowledge representation levels, which will be utilized for further quantitative analysis.





% \subsection{Comparison Baselines}


% \paragraph{Hallucination Alarmer Comparisons. }
% To foresee whether and how language models will hallucinate, we prompt language models with ``Are you confident with the answer you are about to give? If not, what is the answer you are about to give?'' to judge whether they will hallucinate.
% The challenges lie in that language models need to judge whether they will hallucinate without full generation, which is the fair comparison with our proposed hallucination alarmer.


% \paragraph{Hallucination Elimination  Comparisons.}
% We compare our Self-Contrastive Decoding (SCD) method with baselines as follows:

% \textit{Greedy decoding} is the baseline of outputting tokens with optimal probability.
% We prompt language models to answer each question by \textit{Chain-of-Thought (Cot)} to involve deeper reasoning~\cite{wei2022chain}.
% \citet{madaan2024self} proposed \textit{Self-Reflection (SR)} to combine multiple sampled responses into a single input and then prompt the model to analyze the factual information from these sampled responses to generate a new, more accurate response.
% \citet{chen2023universal} proposes \textit{USC} to instruct LLMs to select the most consistent responses from their sampled responses.
% \citet{chuang2023dola} eliminated hallucinations by \textit{Dola} to identifying hallucinations in contrastive model layers. 


% \paragraph{Implementationa and Metric. }
% For the hallucination alarmer evaluation, we adopt accuracy as the metric. If we not only foresee the model will hallucinate but also predict the specific hallucinated output, the success prediction counts.
% For the hallucination elimination evaluation, we use the Exact Match (EM) metric following previous practices~\cite{longpre-etal-2021-entity}. Implementation details are elaborated in~\ref{ssec:implementation}.

