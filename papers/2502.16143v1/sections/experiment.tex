\section{Experimental Results}

%In this section, we first compare our method performance with other comparisons. Then we conduct quantitative and qualitative analysis to showcase when and why our method performs well. 


\subsection{Main Results}



We first experiment with our proposed hallucination alarmer to anticipate to-be-produced hallucination by the model on a given input. Then we compare our hallucination eliminator SCD with other comparisons.




\paragraph{Performance of Hallucination Alarmer. } 
\textit{Our hallucination alarmer exploiting knowledge overshadowing as the hallucination signal significantly outperforms the baseline on all three datasets.} 
Our hallucination alarmer successfully predicts 25.8\%, 24.7\%, and 47.0\% hallucinated output on MemoTrap, NQ-Swap, and Overshadow on average before full generation, mitigating the research gap of not only evaluating whether a language model will hallucinate but also anticipating the hallucination output with notable performance.


\paragraph{Performance of Hallucination Eliminator (SCD).}
\textit{Our method notably enhances the greedy decoding baseline performance by 27.9\%, 13.1\%, and 18.3\% on Overshadow, MemoTrap, and NQ-Swap benchmarks. }
Our method exhibits robust and superior performance compared with all other methods.

\textit{Baseline methods that elicit deeper reasoning steps of language models compromise their performance on the hallucinations caused by knowledge overshadowing. }
This demonstrates the tenacity of knowledge overshadowing.

\textit{Baseline methods that encourage self-consistency show unstable or even degraded performance on knowledge overshadowing.} The reasons may lie in that enhanced consistency may reinforce over-alignment on pre-trained bias brought by popular knowledge.


\subsection{Quantitative Analysis}
As shown in Figure~\ref{fig:quantitative_analysis}, the relative knowledge popularity level (r-KP) and the relative knowledge representation length (r-KL) can greatly influence knowledge overshadowing.
Hence we conduct quantitative analysis on model results of the synthetic dataset with controlled r-KL and r-KP to investigate how our hallucination eliminator SCD performs by varying r-KL and r-KP. 

\input{figures/eliminator}


As shown above, as the r-KL and r-KP increase, consistent with our previous findings, hallucination caused by knowledge overshadowing becomes more tenacious, namely, the more popular knowledge is generalized, the harder to excavate valuable information from the over-suppressed knowledge representations.


\subsection{Case study}

Here we showcase how our hallucination alarmer and eliminator (SCD) work with illustrations.

The popular knowledge introduced in the pre-training stage is the well-known quote ``Actions speak louder than words''. 
The contextual knowledge instructing the model to output ``Actions speak louder than thoughts'' is less popular and consequently overshadowed by the more popular original quote.
When the word ``thoughts'' representing less popular contextual knowledge is masked, the new input represents the more popular knowledge only.
Thus we can downweight the more popular knowledge (``Actions speak louder than'' associated with ``words'') by self-contrastive decoding. 
Specifically, the word ``thoughts'' encodes the overshadowed contextual knowledge in this case. 
After the contrastive decoding to downweight popular association between ``Actions speak louder than'' and ``words'', the correct output ``thoughts'' emerges.