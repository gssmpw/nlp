\section{Data Collection} \label{app_data}
% 首先，我们从PromptBase和LaPrompt上爬取了100组免费的模板（不包含具体的图片），并使用DALL-E 3和成相应的图片，得到相应的900张图片。然后，我们采用人工的方式去掉一些难以复现的数据，例如修饰词包含Arkhip Kuindzhi等艺术流派。然后，我们进行去重操作，删除一些风格，主体非常相似的图片，避免因数据的冗余性影响方法的评估。之后，我们对图片进行质量检测，检测主要包括主体对齐检测和风格一致性检测。若发现异常数据，则使用DALL-E 3重新生成，直到符合要求。最后，我们将我们的数据划分为Easy和Hard两类。Hard类的特征主要包括：有不常见的修饰词、主体描述不详细、图片细节丰富。总体数据的token数量分布如图5所示，Easy和Hard数据的token情况如表4所示。
Our data collection and preprocessing pipeline consists of several systematic steps. Initially, we collect 100 free templates (excluding specific images) from PromptBase and LaPrompt, subsequently generating 900 corresponding images using DALL-E 3. Through manual curation, we eliminate templates that prove challenging to reproduce, such as those containing specific artistic style descriptors (e.g., Arkhip Kuindzhi). We then perform deduplication to remove images with highly similar styles and subjects, thereby preventing evaluation bias from data redundancy.
The subsequent quality control process encompasses two primary aspects: subject alignment verification and style consistency assessment. When anomalous data is identified, we regenerate images using DALL-E 3 until they meet our quality criteria. Finally, we categorize our dataset into Easy and Hard classifications. The Hard category is characterized by: uncommon modifiers, abstract subject descriptions and rich image details. The token distribution of the complete dataset is illustrated in Figure~\ref{fig:data}, while Table~\ref{tb:data} presents a detailed breakdown of token statistics for both Easy and Hard categories.


\section{Extraction Pattern Detail} \label{app_pattern}
% 描述一张图片的风格需要包含不同的角度。EvoStealer的风格描述包含艺术风格，视觉Artistic Style, Visual Composition and Structure, Aesthetic and Emotional Atmosphere, and Medium and Material4个类别。表格4详细介绍了4个类别的具体情况。
Describing the style of an image requires including different perspectives. The style description of EvoStealer includes four categories: \textit{Artistic Style, Visual Composition and Structure, Aesthetic and Emotional Atmosphere}, and \textit{Medium and Material}.
\begin{itemize}
    \item Artistic Style: Include Genre, Era or Historical Style, Cultural and Technological Style.
    \item Visual Composition and Structure: Include Composition and Layout, Form and Structure, Scale, Movement, Perspective, Pattern and Ornamentation and Detail Level.
    \item Aesthetic and Emotional Atmosphere: Include Tone and Atmosphere, Emotional Atmosphere, Lighting and Shadow Effects,
    \item Medium and Material: Include Medium, Material, Technique, Texture, Surface, Color Palette, Brushwork, Line Quality, Strokes, Layering, Transparency, Opacity and Resolution.
\end{itemize}


\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{figures/data.pdf}
    \caption{Token frequency distribution of the dataset}
    \label{fig:data}
\end{figure}

\input{tables/app_data}


\section{Human Evaluation} \label{app_he}
% 我们采用人工评分的方式进行人类评估。首先，每个评分人员会收到benchmark的原图以及所有方法的窃取结果（包含2张in-domain和2张out-of-domain图片）。评分人员不知道图片是由哪个方法生成，并且3个评分人员不允许交流。对于in-domain数据，我们让评估人员评估图片主体和风格的相似性，目的是衡量窃取方法对示例图片的复原性。对于out-of-domain数据，由于目的是评估窃取的prompt（template）的泛化性，评估人员仅需要评估图片的风格相似性。每张图片按照1-5的分数进行评分，分数越高代表越相似(评分标准参考了Ne等人)。我们汇报最终的平均分。评分标准如下所示。
We implement a rigorous human evaluation protocol using a blinded manual scoring approach. Each evaluator is presented with the original benchmark images alongside extracted results from all methods, comprising two in-domain and two out-of-domain images per set. To maintain objectivity, evaluators are blinded to the generation methods and conduct their assessments independently, without inter-evaluator communication. The evaluation criteria are differentiated by image category:
\begin{itemize}
    \item For in-domain data: Evaluators assess both subject matter and stylistic similarity to measure template reproduction fidelity
    \item For out-of-domain data: Evaluation focuses exclusively on stylistic similarity to assess template generalization capability
\end{itemize}
Images are rated using a 5-point Likert scale, with higher scores indicating greater similarity. Final results are reported as mean scores across all evaluators. The detailed scoring criteria are presented below.
\begin{enumerate}
    \item \textbf{Completely Different:} The generated image exhibits no discernible similarities to the original, presenting entirely distinct content and stylistic elements.
    \item \textbf{Barely Similar:} While minimal thematic or elemental commonalities may exist between the original and generated images, they demonstrate significant divergence in both content and stylistic execution.
    \item \textbf{Somewhat Similar:} The generated image maintains recognizable correspondence to the original's content or subject matter, although notable stylistic variations are present.
    \item \textbf{Closely Similar:} The generated image demonstrates substantial fidelity to the original's content and subject matter, with only minor compositional variations.
    \item \textbf{Very Similar:} The generated image achieves near-identical reproduction, maintaining high fidelity to the original's content, style, and intricate details.
\end{enumerate}


\section{Ablation Comparison} \label{app_ablation}
\input{tables/ablation_comparison}
%在我们的抽取模板中，包括可控的Subject和Modifiers。另外，我们设计了灵活的Supplements来弥补Subject和Modifiers的不足。图6中展示了消去Supplements抽取模块对EvoStealer窃取效果的影响。
% 在第一个例子中，一个明显的公共特征是每个图片都包含花瓣，这一特征是在主语上。例如：“a floating umbrella covered in flowers”。由于图片元素的抽取是一张张图片的，因此很容易导致主语遗漏“surrounded by petals”这一特征。而这一特征能够被Supplements模块捕捉到，并且在差分进化过程中能够得以保留下来。消去Supplements导致图片缺少这一关键特征，从而影响最终效果。
% 第二个例子中，“dark yellow tone”属于Modifiers类别中的“Visual Composition and Structure”。由例子可以看到，Supplements能够捕捉Modifiers中的遗漏的特征，实现更优的窃取。
% 在第三个例子中，“symmetry”是由Supplements自行捕捉到的关键特征，它不属于Modifiers的分类中。由此可见，Supplements因为其灵活性，能够捕捉到额外的关键特征，进一步提高图片的生成质量。
Our extraction template incorporates controllable Subjects and Modifiers, complemented by a flexible Supplements module designed to address potential gaps in subject and modifier extraction. Figure~\ref{fig:ablation_comparison} demonstrates the impact of the Supplements module on EvoStealer's effectiveness.

The first case study illustrates how the Supplements module enhances feature detection. While analyzing images individually may cause oversight of shared characteristics—such as the presence of petals in 'a floating umbrella covered in flowers'—the Supplements module successfully captures these overlooked elements in Subject, thereby improving extraction accuracy. In the second case, the module demonstrates its ability to detect visual attributes that are overlooked by predefined modifier categories, such as 'dark yellow tone' within the 'Visual Composition and Structure' categories. The third case exemplifies the module's capacity to identify fundamental aesthetic properties like symmetry, which fall outside established modifier categories. These examples highlight how the Supplements module's flexibility enables the detection of additional key features, ultimately enhancing the quality of image generation.

\section{Evolution Progress} \label{app_progress}
\begin{figure*}[h!]
    \centering
    \includegraphics[width=\linewidth]{figures/evo_process.pdf}
    \caption{Results of each evolutionary cycle.}
    \label{fig:process}
\end{figure*}
\input{tables/failure_cases}
% 图7提供了EvoStealer在in-domain数据上，两种不同风格的数据上的迭代结果。从图7可知，随着迭代的进行，图片的风格逐步朝着ground truth的风格靠近。这说明，随着迭代的进行，EvoStealer能够逐步提升风格描述词的质量，以产生风格更为接近的图片。
Figure~\ref{fig:process} presents the iterative results of EvoStealer on in-domain data across two distinct styles. The figure demonstrates that with each iteration, the generated images progressively converge toward the ground truth style. This progression indicates that EvoStealer successfully refines the quality of style descriptors throughout its iterative process, resulting in images that increasingly approximate the target style. The visual comparison clearly illustrates the algorithm's capacity to incrementally improve stylistic fidelity through successive refinements.

\section{Cost Estimate} \label{app_cost}
The execution process of EvoStealer comprises three main stages: population initialization, differential evolution (including the fitness function), and image synthesis. We assess the cost from three perspectives: API call frequency, token consumption, and image generation. While API calls and image generation can be accurately and directly measured, token consumption is estimated. Given the instability of the model's output, only the input portion is estimated. For this analysis, we evaluate the cost of stealing a prompt template using EvoStealer, based on GPT-4o.

During the population initialization phase, EvoStealer performs two key operations: image element extraction (which generates <subject, modifiers, supplements> triples) and initial template synthesis. On average, this requires 10 calls to GPT-4o, consuming 1.6k tokens, with an estimated cost of approximately \$0.04. In the differential evolution phase, EvoStealer performs operations such as difference and commonality identification, mutation, mutation addition, and crossover. Additionally, for each offspring, template synthesis and image generation are required for both creation and evaluation. On average, this phase involves 125 API calls, consumes 117.5k tokens, and generates 25 images, resulting in a total cost of approximately \$1.30. In the image synthesis phase, only the optimal template is used to generate 9 images. This requires 9 API calls and 9 image generations, totaling \$0.36. Thus, the overall cost amounts to approximately \$1.70.


\section{Failure Cases} \label{app_failcases}

In this section, we will examine several typical failure cases. These failures stem either from the complexity of the images themselves and vague descriptions, or from the inherent limitations of the current EvoStealer method. Figure~\ref{fig:app_fail} illustrates representative examples.

A primary limitation is the system's inadequate interpretation of specific artistic styles. Analysis of PromptBase and LaPrompt platforms reveals that many prompt templates incorporate stylistic modifiers, such as "Arshile Gorky style," "Disney style," and "Renaissance style." However, the system struggles to accurately identify and replicate the distinctive characteristics of individual artists' techniques or historical artistic movements, resulting in significant stylistic disparities between generated and source images.

A second limitation concerns text recognition capabilities. The current EvoStealer implementation lacks explicit protocols for extracting textual elements from images. Despite MLLMs' inherent text recognition capabilities, this functionality remains underutilized in the present version—a limitation scheduled for address in future iterations.

The third limitation involves comprehensive detail preservation. When processing images with complex color palettes and rich content, EvoStealer may fail to capture fine-grained features, leading to degraded quality in the resultant prompt templates.



%在本部分，我们将展示一些典型的失败案例。这些失败有的源于图片的复杂性或描述的简略与抽象，有的则是由于当前EvoStealer方法的局限性所致。

% 无法捕捉特定的艺术流派特征。我们发现，在PromptBase和LaPrompt平台上，有一定比例的prompt template存在使用特定的艺术流派作为修饰词的现象。例如，"Arkhip Kuindzhi style", "Disney style" and "Renaissance style"。这些特定艺术家的风格或某种文化、历史时期的艺术风格难以被识别，因此导致合成的图片风格和原图存在差异。

% 对图片中的文字不敏感。当前版本的EvoStealer没有明确的指令制导对图片主体的抽取。尽管MLLMs有能力识别出图片中的文字，但这一点被当前版本的EvoStealer所忽略。我们将在后续迭代中改进此缺陷。

% 难以捕捉丰富的细节。EvoStealer无法完整的捕捉图片中的丰富的细节，特别是图片色彩，内容都非常多时，EvoStealer窃取的模板质量会下降。