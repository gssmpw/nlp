\section{Introduction}
% multimodal llm get great development, llm is sensitive to prompt quality.
% now, there are many website sell prompt, they give some example output. including text and image generation. many people try to reverse output to get prompt.
% however these method try to get a prompt, they divide a prompt into 2 parts:subjects and modfiers. they need finetune 2 model, but it makes little sense
% in this paper, we propose a new task, using some pictures to steal prompt template. Additionaly we propose a method to get prompt template. the method using differential evolution method.
% we do experiment on datasets. the result is....
% Our major contributions are as follow: 1/2/3.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/process.pdf}
    \caption{Top: Illustrating the legitimate development of text-to-image prompt templates. Bottom: Depicting unauthorized extraction of proprietary prompt templates}
    \label{fig1}
\end{figure}

% Recent advancements in text-to-image generation~\citep{liu2024visual,cao2024controllable}, particularly in multimodal large language models (MLLMs)~\citep{liu2024visual,wang2024qwen2} and diffusion models~\citep{ho2020denoising,sohl2015deep}, have significantly improved image generation performance. 
% However, crafting the perfect prompt to produce desired output images results remains a meticulous process that requires significant expertise and time investment.
% This challenge has catalyzed the emergence of prompt trading, a novel business model exemplified by platforms like PromptBase\footnote{https://promptbase.com/} and LaPrompt\footnote{https://laprompt.com/}. These services strategically offer sample images to incentivize prompt template purchases. From a copyright protection perspective, this practice introduces a critical research question: \textit{Can malicious actors exploit these sample images to systematically extract prompt templates?}


Recent advancements in text-to-image generation~\citep{liu2024visual,cao2024controllable}, particularly in multimodal large language models (MLLMs)~\citep{liu2024visual,wang2024qwen2} and diffusion models~\citep{ho2020denoising,sohl2015deep}, have significantly improved image generation performance. 
However, crafting the perfect prompt to produce desired output images results remains a meticulous process that requires significant expertise and time investment~(Refer to Figure~\ref{fig1}(top)).
This challenge has catalyzed the emergence of prompt trading, a novel business model exemplified by platforms like PromptBase\footnote{https://promptbase.com/} and LaPrompt\footnote{https://laprompt.com/}. On these platforms, creators upload meticulously crafted prompt templates~(viewable post-purchase) alongside multiple sample images~(publicly visible). Customers attracted to these samples can purchase the template, then merely modify the subject specification to generate new images that preserve the original stylistic elements.
In this context, the platform’s copyright and security vulnerabilities raise significant concerns. If attackers reverse-engineer the proprietary templates by analyzing the visible samples, they could significantly compromise sellers' intellectual property rights and threaten the platform's business model~(See Figure~\ref{fig1} (bottom)). We term this attack \textit{prompt template stealing}.

% Current research predominantly concentrates on prompt stealing attacks~\citep{shen2024prompt,sha2024prompt,naseh2024iteratively}, which seek to reconstruct the original prompts used to generate images. However, this target-specific attack approach deviates from the conventional prompt template design process (see Figure~\ref{fig1}), as stolen prompts may incorporate unique features of specific images, thereby undermining their generalizability. For example, in the case of the woman image located in Figure~\ref{fig1}, a stolen prompt might include the "golden sun" as a distinctive element. Nevertheless, a comparison with the other three images demonstrates that the "golden sun" is not a shared characteristic among them.

Existing methods for prompt stealing attacks~\citep{shen2024prompt,sha2024prompt,naseh2024iteratively} focus on reconstructing individual prompts for each sampled image, rather than recovering a general prompt template for the entire group of sampled images. As a result, the prompts reconstructed by these methods are specific to each image and lack generalizability, which limits their applicability in practical scenarios, as illustrated in Figure~\ref{fig1}. For example, in the case of the woman image located in Figure~\ref{fig1}, a stolen prompt might include the "golden sun" as a distinctive element. Nevertheless, a comparison with the other three images demonstrates that the "golden sun" is not a shared characteristic among them.

% Existing works like prompt stealing attacks~\citep{shen2024prompt,sha2024prompt,naseh2024iteratively}. However, the prompts generated by these studies are applicable only to a single image, making them unable to simulate realistic prompt template stealing scenarios. 
% Unlike these studies, the goal of prompt template stealing is to extract a generalized template, enabling the generation of images with a consistent style but different subjects by replacing key elements (e.g., the subject). Compared to methods that focus on stealing from a single image, the template's generalization ability makes the generation process more efficient and flexible. \Cref{fig:comparison} provides a comparison of the three lines.

% 现有的研究工作主要是prompt stealing attacks，它们的攻击目标是重建用于生成图像的原始提示。对于每张图片，它们针对每张图片生成一个特定的prompt。然而，这种面向特定目标图片的攻击策略与现有的prompt template设计过程存在gap（参考图1），窃取的prompt可能引入特定图片的独有特征，影响其泛化性。例如。对于图1左下部分的女士图片，窃取的prompt可能将图中的金色太阳作为一个特征添加到prompt。然而，对比其他3个图片可以看出，金色太阳并非共有特征。

%对于一张图片，这些工作通常是使用一个多类别分类器，筛选出和目标图片相似度高于某个阈值的修饰词。然而，这种贪婪的匹配策略可能会导致合成的prompt和目标图片


% 图1上半部分展示了创作者从设计prompt到发布的过程。

% 在这些平台上，创作者上传一个精心设计的prompt template（购买后可见）以及几张用这个template生成的示例图片（所有人可见）。顾客若喜欢这些风格的示例图片，便可购买此prompt template。顾客只需修改prompt template中的subject，即可生成风格相同的图片。

%在这个背景下，market的copyright和安全风险引人担忧。攻击者如果能够通过上传的样例窃取到对应的template，则会对卖家的知识产权，甚至是market的商业模式造成严重影响，如图1下半部分所示。我们称这种攻击为 prompt template stealing。





% Existing works like prompt stealing attacks~\citep{shen2024prompt,sha2024prompt,naseh2024iteratively}. However, the prompts generated by these studies are applicable only to a single image, making them unable to simulate realistic prompt template stealing scenarios. 
% Unlike these studies, the goal of prompt template stealing is to extract a generalized template, enabling the generation of images with a consistent style but different subjects by replacing key elements (e.g., the subject). Compared to methods that focus on stealing from a single image, the template's generalization ability makes the generation process more efficient and flexible. \Cref{fig:comparison} provides a comparison of the three lines.

To fill this gap,  we build a new and comprehensive benchmark named \data, comprising 50 prompt templates stratified across two difficulty levels (Easy and Hard) and spanning 9 distinct subjects, sourced from a specialized prompt trading platform. 
Utilizing DALL·E 3, we generated 450 images, with each group methodically partitioned into 5 in-domain and 4 out-of-domain images to systematically evaluate both model fitting capability and generalization performance. 

Besides, we introduce EvoStealer, a novel template stealing methodology derived from the differential mutation algorithm in evolutionary computation. Our approach strategically leverages mutation and crossover operations within the search space to effectively mitigate overfitting and circumvent local optima, precisely aligning with template stealing objectives. We integrate large language models (LLMs) spanning both open-source and closed-source domains, specifically utilizing InternVL2-26B, GPT-4o, and GPT-4o-mini. By combining these models with a differential evolution algorithm, we generate prompt templates characterized by exceptional stability and robust generalization capabilities. Comprehensive experimental evaluations are conducted across easy and hard difficulty levels. The results demonstrate EvoStealer's remarkable performance: the methodology efficiently reproduces images highly similar to original templates while simultaneously exhibiting strong cross-subject generalizability. This enables large-scale image generation maintaining consistent stylistic characteristics.

Our main contributions are as follows:

(1) To the best of our knowledge, this is the first systematic study on prompt template stealing, revealing its severity as an emerging security threat and empirically demonstrating its significant risk to intellectual property protection;

(2) This study introduces \data, the first benchmark for prompt template stealing, and EvoStealer, a plug-and-play attack framework that requires no fine-tuning, significantly improving practicality and scalability;

(3) We conducted extensive experiments on both open-source models (\intern) and closed-source models~(\gpta, \gpt), with results validating the effectiveness of EvoStealer.

% \begin{enumerate}
%     \item To the best of our knowledge, this study is the first to explore the concept of prompt template stealing. In contrast to prompt stealing attacks, stealing prompt templates offers greater practical value.  By replacing the subject, multiple images with a consistent style can be generated, making this approach more scalable.
%     \item We present a dataset for prompt template stealing, containing 50 templates and 9 subjects, and introduce EvoStealer, a method for stealing prompt templates. EvoStealer requires no fine-tuning and offers a simple, plug-and-play framework for easy integration.
%     \item We conducted extensive experiments on both open-source models (InterVL2-26B) and closed-source models~(GPT-4o, GPT-4o-mini), with results validating the effectiveness of EvoStealer.
% \end{enumerate}


% Recent studies have focused on extracting prompts from model outputs, typically dividing them into two categories: the subject and the modifiers. The subject defines the core content of the image, while the modifiers describe its style, such as resolution, light, and color temperature etc. These methods extract the subject and modifiers separately and combine them to generate a final prompt. Although effective, these approaches face two main challenges. First, they often concentrate on a single image, aiming to capture image details exhaustively to maximize the similarity between the generated and reference images. However, this process may introduce image-specific features, limiting the prompt's applicability to other images and reducing generalization when the subject is altered. Second, these methods generally require substantial data to fine-tune subject and modifier models (e.g., classification models), which not only demands significant human effort for data collection and annotation but also risks failing to capture image styles not addressed by the classifier. These limitations hinder their practical applicability.

