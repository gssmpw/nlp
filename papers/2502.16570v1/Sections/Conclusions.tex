\section{Conclusions} \label{sec:conclusion}

%In this work, we prototyped the use of Shannon entropy on the intermediate predictions of LLMs as an interpretability tool. In Section \ref{sec:exp-fingerprint}, we showed that the entropy profiles of LLM generated tokens identify the LLM's model family. Additionally, in Section \ref{sec:exp-ts} we showed that the same quantities can be used to identify the `task type', and in Section \ref{sec:exp-tm} we used them to distinguish between correct and wrong LLM generated answers. Importantly, all our experiments were conducted on widely used LLMs, up to 9B parameters in size, without any training nor fine-tuning, and only using the model's frozen decoder.

In this work, we prototyped a novel model-agnostic interpretability framework for large-scale transformer-based architectures grounded in information-theory. In Section \ref{sec:exp-fingerprint}, we showed that the entropy profiles of LLM intermediate predictions identify the LLM's model family. In Section \ref{sec:exp-vit} we conduct similar experiments on vision transformers, demonstrating the wide applicability of our framework. Additionally, in Section \ref{sec:exp-ts} we showed that the same entropy profiles can be used to identify the `task type' in LLMs, and in Section \ref{sec:exp-tm} we used them to distinguish between correct and wrong LLM generated answers. Importantly, all our experiments were conducted on frozen off-the-shelf large-scale transformers.

% 
% Non per arXiv
% 
% 
% \subsection{Limitations and Future Work}
% While this work paves the way to further investigations in information theoretic interpretability, it also presents a number of limitations. First, the concept of `task type' does not have a formal and well established definition. Second, our approach relies solely on entropy, an aggregate measure of information that may overlook subtle variations in signals. Finally, we do not yet have a theoretical explanation of why the phenomena observed occur and why they are caused by.

% With these limitations in mind, our methodology could be used to probe the reasoning capabilities of LLMs, for instance by comparing the entropy profile of a reasoning task vs.~a data retrieval task. If these happen to match, it could be an argument for the impossibility of LLMs to reason, whereas if they did not, it could be an argument for.\newline
% Moreover, we showed how different models possess different characteristic entropy profiles. We conjecture that these particular shapes are a byproduct of training procedure and architectural designs, but future research could focus on understanding the precise connections.\newline
% Another interesting line of research could focus on considering more fine-grained measures of information instead of just an aggregated one such as entropy.\newline
% Finally, recent literature explored the use of entropy for private inference (PI), where computations are performed on encrypted data without revealing users' sensitive information \cite{jha2025entropyguidedattentionprivatellms}. While previous work focused on the entropy of the attention mechanism, future research could use our methodology to develop PI-friendly applications of LLMs. 