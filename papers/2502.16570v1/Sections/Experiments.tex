\section{Experiments} \label{sec:exp}
The goal of our experiments is to demonstrate the effectiveness of entropy profiles in distinguishing computational signatures across various models and scenarios. In the first part, we explore how entropy profiles can differentiate between LLM families and characterize distinct tasks. In the second part, we apply our framework to the Vision Transformer architecture to assess whether insights from the LLM experiments can be similarly recovered.

% The aim of our experiments is to demonstrate the capability of entropy profiles in distinguishing computational signatures across various scenarios. Initially, we focus on classifying the task that a model is performing solely by examining its generated entropy profile. Subsequently, we extend this concept to determine if, for a specific task, it is feasible to differentiate between correct and incorrect task execution. Lastly, we illustrate how these entropy signatures are indicative of model families, with profiles becoming more pronounced as model sizes increase.

\subsection{Entropy-Lens for Large Language Models}
The experiments on LLMs focus on three key aspects. First, we demonstrate that entropy profiles are indicative of model families, with distinctions becoming more pronounced as model size increases. Second, we investigate whether the entropy profile of a model alone can be used to classify the task it is performing. Finally, we extend this analysis to assess whether entropy profiles can distinguish between correct and incorrect task execution.

\subsubsection{Entropy profiles identify model families} \label{sec:exp-fingerprint}
We assess whether aggregated entropy profiles can distinguish different model families by visualizing and analyzing those of 9 models from 3 different families (GPT, Gemma and LLama) with parameter counts ranging from 100M to 9B. 

We compute the mean of the entropy profiles obtained from 64 generated tokens, obtained with the prompt `\textit{The concept of entropy, a brief essay:}', as shown in Figure \ref{fig:entropy_fingerprints}.
We observe that the profiles relate uniquely to the model family, rather than a particular model, independently of its size. 

The GPT model class starts with high vocabulary entropy in the early layers, indicating a wide range of possible response tokens. Then, entropy gradually decreases—more smoothly than in other classes—leading to a low-entropy state, where the model narrows down to a small set of possible response tokens. \newline
The Gemma model class, on the other hand, starts with low entropy in the very first layers, then rises to higher entropy in the intermediate layers, and finally decreases to low entropy again just before the last layers, where the model is required to produce an output token. \newline
The Llama model class follows a similar pattern, but with a steeper rise, resulting in a higher entropy value maintained over a larger range of intermediate layers.

We observe that the equivalence between models of the same family but different sizes holds when looking at the entropy trend not as a function of the absolute layer index, but rather as the relative layer position within the model.

We conjecture that high entropy phases, whether in the early or intermediate layers, allow the model to explore more possibilities in its response, similarly to how temperature helps avoid getting stuck in local minima in optimization. Then, at the moment of selection, the distribution is `cooled down', forcing the output to be limited to a few possible tokens.

%We assess whether the entropy fingerprint can distinguish different models by visualizing and analyzing those of \fra{volevo mettere "of 9 models" però mi sembra che ne abbiamo visti di più ma questi sono a titolo esemplificativo} models with parameter counts ranging from 100M to 9B. In Fig. \ref{fig:entropy_fingerprints} we show, as an illustrative example, the entropy fingerprints of nine models, obtained using the prompt '\texttt{The concept of entropy, a brief essay:}', considering the first 64 tokens. These nine models belong to three families, which we found to correspond to the three distinct classes of entropy fingerprints. The GPT model class starts with high vocabulary entropy in the early layers, indicating a wide range of possible response tokens. Then, entropy gradually decreases—more smoothly than in other classes—leading to a low-entropy state, where the model narrows down to a small set of possible response tokens. The Gemma model class, on the other hand, starts with low entropy in the very first layers, then rises to higher entropy in the intermediate layers, and finally decreases to low entropy again just before the last layers, where the model is required to produce an output token. The Llama model class follows a similar pattern, but with a steeper rise, resulting in a higher entropy value maintained over a larger range of intermediate layers. One interpretation, which will require further analysis, is that the high entropy phase—whether in the early or intermediate layers—allows the model to explore more possibilities in its response. This is similar to how temperature in optimization helps avoid getting stuck in local minima. Then, at the moment of selection, the distribution is "cooled down", forcing the output to be limited to a few possible tokens.\fra{quali modelli sono tied?}\fra{mettere lo scaling}\fra{dire meglio che la curva, se riscalata, dovrebbe essere molto simile tra modelli dello stesso tipo ma diverso numero di parametri ma, a maggior ragione se non riscalata, dovrebbe essere diversa}

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\linewidth]{Figures/entropy_all.png}
    \caption{Average entropy profiles over 64 generated tokens per model. The $x$ axis is normalized for an easier comparison when models have a different number of layers.}
    \label{fig:entropy_fingerprints}
\end{figure}

\subsubsection{Entropy profiles identify task types} \label{sec:exp-ts}
%Although LLMs are trained to simply predict the next token of a sentence, there is consensus that not all prompts are the same, as they vary in complexity \citep{santu2023telergeneraltaxonomyllm} and in nature, such as reasoning vs.~information retrieval \citep{xu2025largereasoningmodelssurvey, chowdhury2024probingrankingllmsmechanistic}. 
We verify whether the entropy profiles can identify task types examining generative (continue a text), syntactic (count the number of words in a text), and semantic (extract the subject or moral of a text) tasks.

We do this with the \textit{TinyStories} dataset \citep{eldan2023tinystories}. For evaluation robustness, we construct for each task type three prompt templates using a combination of task-specific \texttt{task prompts}, reported in Appendix \ref{sec:appendix} Table \ref{tab:tinystories}, and a \texttt{story} from \textit{TinyStories}. These templates are:
\begin{itemize}
    \item Base, of the form \texttt{task prompt + story}
    \item Reversed, of the form \texttt{story + task prompt}
    \item Scrambled, of the form \texttt{task prompt + scrambled story} or \texttt{scrambled story + task prompt}, at random. A \texttt{scrambled story} is a `story' obtained by randomly shuffling the words in a given \texttt{story} from \textit{TinyStories}.
\end{itemize}
Note that, for a robust evaluation, we also use 2 possible \texttt{task prompt} variations, as per Table \ref{tab:tinystories}.

We generate 800 prompts per task type, $1/3$ of them with the base template, $1/3$ with the reversed template, and $1/3$ with the scrambled templates, for a total of 2400 prompts. We then apply our pipeline from Section \ref{sec:method} to classify the aggregated entropy profiles of these prompts against their task type using a k-NN classifier. The model was evaluated in a 10-fold cross-validation using the ROC-AUC score (one-vs-rest). Table \ref{tab:tiny-task} shows the results obtained for 6 models with parameter counts ranging from 1B to 9B. Figure \ref{fig:tiny_ent} shows the average entropy profiles per task type.

We observe that all k-NN classifiers (i.e. one for each LLM) achieve high accuracy in distinguishing entropy profiles, with a trend toward improved performance for larger models. 

%We conduct experiments on the \textit{TinyStories} dataset \citep{eldan2023tinystories}—containing short stories with simple vocabulary—to verify whether the entropy profile can effectively characterize three possible tasks: \textbf{continuation}, where the model is asked to continue a story; \textbf{counting}, where it must count the number of words in the given story; and \textbf{semantic}, where it analyzes the text. As shown in table \ref{tab:tinystories}, we use two possible prompt variations for each task—for example, asking the model to identify the subject of the sentence or summarize the story for the semantic task. Additionally, for each variation of every task, we evaluate the prompt with and without two confounding factors: asking the task question before and after the story (reverse) and randomly shuffling the story's words (scramble). For each possible prompt, we generate the entropy profile over 8 tokens and use a k-NN classifier to categorize the entropy profiles into the three possible tasks. The model was evaluated in 10-fold cross validation on a dataset comprising 2400 prompts (800 for each class/task) using the ROC-AUC score (one-vs-rest). Table \ref{tab:tiny-task} shows the results obtained for six models with parameter counts ranging from 1B to 9B. In Figure \ref{fig:tiny_ent} we show the average of the entropy profiles across all dataset examples. From the results, we observe that all k-NN classifiers achieve high accuracy in distinguishing entropy profiles, with a trend toward improved performance for larger models. Furthermore, the figure illustrates that these differences, while significant, remain subtle due to the high variance observed among profiles associated with different tasks.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.48\linewidth]{Figures/entropy_ts_Llama-3.2-3B-Instruct.png}
    \includegraphics[width=0.48\linewidth]{Figures/entropy_ts_gemma-2-2b-it.png}
    \caption{Average entropy profiles with shaded standard deviation for different task types: generative (continuation\_prompt 1 and 2), syntactic (counting\_prompt 1 and 2), and semantic (semantic\_prompt 1 and 2). These tasks are induced with the prompts described in Appendix \ref{sec:appendix}.  Left: Llama-3.2-Insruct. Right: Gemma-2-Instruct}
    \label{fig:tiny_ent}
\end{figure}


% so the results show that a simple k-NN can distinguish tasks based on the entropy fingerprint. The results do not depend on model size for the cases considered, nor do they show dependence on the model type. This suggests that the entropy fingerprint enables task classification in a way that is robust to both model size and architecture.

\begin{table}[ht]
\centering
\caption{ROC-AUC (one-vs-rest) results of different models on the TinyStories task classification. The standard deviation is calculated on the 10-fold cross-validation splits.}
\label{tab:tinystories_results}
\begin{tabular}{l c c}
\toprule
\textbf{Model} & \textbf{Model Size} & \textbf{k-NN ROC-AUC} \\ 
\midrule
Gemma-2-it & 2.1B  & 97.66 ± 0.47 \\  
Gemma-2-it & 8.9B  & 98.38 ± 0.50 \\  
Llama-3.2-Instruct & 1 B  & 94.94 ± 0.79 \\  
Llama-3.2-Instruct & 3 B    & 94.77 ± 0.93 \\  
Llama-3-Instruct   & 8 B    & 96.10 ± 0.67 \\  
Phi-3              & 3.6B  & 97.07 ± 0.87 \\  
\bottomrule
\end{tabular}
\label{tab:tiny-task}
\end{table}


\subsubsection{Entropy profiles identify correct task execution} \label{sec:exp-tm}
We test whether entropy profiles can identify correct and wrong answers generated by LLMs using the Massive Multitask Language Understanding (MMLU) dataset \cite{hendrycks2021measuringmassivemultitasklanguage}. \newline
MMLU consists of multiple-choice questions across 57 subjects, ranging from history and physics to law, mathematics, and medicine. The difficulty levels span from elementary to professional, making it a benchmark for evaluating language models on specialized domains. Each dataset entry contains: a question string, four answer choices and a label indicating the correct answer.

We evaluated two models, a Llama-3.2 with 3B parameters Instruct and a Gemma-2 with 2B parameters, by presenting the multiple-choice questions in three different formats (as per Table \ref{tab:mmlu_prompts} in Appendix \ref{sec:appendix}):
\begin{itemize}
\item Base: A minimal version containing the topic, the question, and multiple-choice answers.
\item Instruct: A version with a brief explanation that it's a multiple-choice test where only one option should be selected.
\item Humble: A version that also instructs the model to pick a completely random option if it doesn't know the answer.
\end{itemize}

Then, we applied our pipeline to extract and aggregate and the responses' entropy profiles and classify them against the correctness of the corresponding LLM-generated answer. We train a k-NN classifier for each LLM and validate it using 10-fold cross-validation. We also conducted a t-test to compare our classifier to a dummy model. This dummy model generates predictions randomly, sampled from a distribution that reflects the proportion of correct and incorrect answers produced by the LLM, ensuring robustness against class imbalance. The results reject the null hypothesis with the k-NN achieving an AUC-ROC between 67.23 and 73.61, depending on prompt type and model (Table \ref{tab:model_comparison}).

% \rick{Toglierei questo paragrafo, oppure rendere più chiaro quello che vuole dire. Per quello che abbiamo scritto fino ad ora, non c'è ragione di pensare che una risposta corretta per law non valga come una corretta per physics. Qui invece sembra dire che le due, nonostante entambe corrette o sbagliate, sono di natura diversa.} \fra{questa parte era una mia interpretazione di un punto che aveva abbozzato chris, per me forse si potrebbe anche togliere ma parliamone con lui}
% It is important to note that MMLU tasks vary widely, leading to significant accuracy differences across models and an imbalance in correct vs. incorrect responses. This naturally makes the truth machine task easier for some tasks than others. Additionally, part of the entropy profile classification might be functioning as task classification, rather than purely assessing response correctness.

We observe that the instruct and humble prompts improve Llama's average accuracy, while for Gemma, this is only true for the instruct prompt.
Additionally, in Llama, the model's higher accuracy seems to be partially linked to greater difficulty in distinguishing correct from incorrect entropy profiles, though more rigorous analysis is needed to confirm this. In Gemma, however, this claim is harder to support.





% We wanted to further investigate what kind of information is encoded in entropy profiles.\\ 
% In particular, to test whether these profiles could serve as a truth machine for measuring the confidence of a model’s response, we first created a dataset of correct and incorrect answers using the Massive Multitask Language Understanding (MMLU) dataset \citep{hendrycks2021measuringmassivemultitasklanguage}. \newline
% MMLU consists of multiple-choice questions across 57 subjects, ranging from history and physics to law, mathematics, and medicine. The difficulty levels span from elementary to professional, making it a benchmark for evaluating language models across specialized domains. Each dataset entry contains: a question string, four answer choices and a label indicating the correct answer.\newline
% We evaluated two models: a Llama-3.2 with 3B parameters Instruct and a Gemma-2 with 2B parameters. By presenting the multiple-choice questions in three different formats (as shown in the table \ref{tab:mmlu_prompts}):
% \begin{itemize}
% \item Base: A minimal version containing the topic, the question, and multiple-choice answers.
% \item Instruct: A version with a brief explanation that it's a multiple-choice test where only one option should be selected.
% \item Humble: A version that also instructs the model to pick a completely random option if it doesn't know the answer.
% \end{itemize}
% We collected and evaluated the model’s responses. Finally, we assigned each entropy profile a label (correct or incorrect) based on whether the model’s answer was right or wrong. \newline 
% The resulting dataset of entropy profiles paired with response correctness was used to train and evaluate a k-NN classifier for each LLM. We validated the classifiers using 10-fold cross-validation, but due to class imbalance, we also conducted a t-test with the null hypothesis that our classifier performed equivalently to a dummy model sampling from the multinomial distribution of correct/incorrect responses. The results reject the null hypothesis and achieve an AUC-ROC of around 0.7.\newline

% \rick{Toglierei la parte che segue}
% It is important to note that MMLU tasks vary widely, leading to significant accuracy differences across models and an imbalance in correct vs. incorrect responses. This naturally makes the truth machine task easier for some tasks than others. Additionally, part of the entropy profile classification might be functioning as task classification, rather than purely assessing response correctness.\newline

% We observe that a more structured prompt improves Llama's average accuracy, while for Gemma, this is only partially true for the Instruct prompt but not for the Humble prompt, when compared to the Base prompt. Additionally, in Llama, the model's higher accuracy seems to be partially linked to greater difficulty in distinguishing correct from incorrect entropy profiles, though more rigorous analysis is needed to confirm this. In Gemma, however, this claim is harder to support.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{Figures/entropy_vit_all.png}
    \caption{Entropy profiles for ViT model families.}
    \label{fig:entropy-vit}
\end{figure}

\subsection{Entropy-Lens for Vision Transformers}\label{sec:exp-vit}
Finally, to demonstrate the versatility and robustness of our approach beyond language modeling, we analyze the entropy profiles of ViTs and DeiTs.

Using 20 classes from ImageNet-1K \citep{imagenet15russakovsky}, with 20 images per class, and without any modifications to our framework, we generate the entropy profiles shown in Figure \ref{fig:entropy-vit}. 
%\rick{Qui il messaggio pare essere che la parte interessante è la somiglianza di traiettorie tra ViTs e LLMs, ma da come avevo capito il messaggio figo è che anche per ViTs le entropie paiono identificare le famiglie dei modelli} \fra{secondo me ci stanno tutti e due. La somiglianza tra vision e nlp poi è un po' la cosa del tunnel e context extractor ma celata}
We observe that all profiles start with high entropy values, which then decrease, mostly in the final layers. This behavior is qualitatively similar to that of GPTs or larger LLaMa models (Section \ref{sec:exp-fingerprint}), suggesting a \textit{universal} pattern across domains as different as image processing and natural language processing.\newline
Focusing on computer vision models, we note that while ViT and DeiT families exhibit qualitatively similar trends, they differ quantitatively—ViTs start with higher entropy values, making them easily distinguishable from DeiTs.\newline
Notably, the only profile that stands out is that of ViT Large (with $\sim 300$M parameters), compared to the other models analyzed in this section, which have $\leq 86$M parameters.\newline
For ViT Large, entropy decreases more smoothly, appearing not only as a better approximation of the sharp drop seen in smaller models but possibly following a different behavior entirely, with the entropy decline starting earlier.\newline
We hypothesize a phase transition in entropy behavior as model size increases, occurring somewhere between $87$M and $307$M parameters.

\begin{table}[ht]
\centering
\caption{Performance comparison of different models and prompt types on MMLU accuracy and k-NN AUC-ROC score.}
\label{tab:model_comparison}
\begin{tabular}{l l c c}
\toprule
\textbf{Model} & \textbf{Prompt Type} & \textbf{LLM Accuracy} & \textbf{k-NN AUC-ROC} \\ 
\midrule
\multirow{3}{*}{Llama-3.2-3B-Instruct} 
    & Base     & 50.89 & 73.61 ± 1.52 \\ 
    & Humble   & 58.51 & 69.90 ± 1.06 \\ 
    & Instruct & 60.62 & 67.23 ± 1.62 \\ 
\midrule
\multirow{3}{*}{Gemma-2-2B-it}         
    & Base     & 56.10 & 71.88 ± 1.63 \\  
    & Humble   & 54.71 & 72.78 ± 1.15 \\  
    & Instruct & 56.38 & 68.36 ± 1.23 \\  
\bottomrule
\end{tabular}
\end{table}