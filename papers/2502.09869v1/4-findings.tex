\section{Findings} 
Our analyses revealed three types of user feedback and the ways this feedback aligns with users' purposes. We first present the three types of feedback: explicit feedback, intentional implicit feedback, and unintentional implicit feedback. 
%and how users leverage these feedback to achieve their purposes.
Then, we summarize four purposes for which users interacted with algorithms: content consumption, directed information seeking, content creation and promotion, and feed customization. Last, we showcase the relationships between purposes and the types of feedback adopted. We found that explicit feedback was primarily used for feed customization, while intentional implicit feedback emerged as crucial for feed customization, particularly in increasing content diversity and improving recommendation relevance. Unintentional implicit feedback was most commonly linked to content consumption and directed information seeking. We leverage the interview data to explain underlying motivations for adopting different feedback types to fulfill their purposes.

\subsection{Types of User Feedback for Personalized Recommendation Content}
% The primary difference between explicit and implicit feedback is whether users provide feedback to the system with or without their intentions. Our analyses suggests that within the implicit feedback category, users consciously leveraged implicit feedback mechanisms to customize the feeds. For example,. Thus, we considered a separate category, namely ``intentional implicit feedback,'' to highlight the active role users play in shaping their content feeds based on their knowledge of algorithms.

% \textit{Explicit feedback} refers to users' behaviors where they directly communicate their preferences and interests to personalized recommendation algorithms. \textit{Intentional implicit feedback} involves user behaviors that, while not explicitly stated as feedback, were consciously performed with the knowledge that these actions might be interpreted by the system to infer user interests. While the feedback is intentionally made by users, it remains implicit to the system, which continues to process them and infer user preferences as it would any implicit feedback. \textit{Unintentional implicit feedback} consists of user behaviors that allow algorithms to assess user preferences without any deliberate intention from the user to give feedback.

We identified six explicit feedback behaviors, nine intentional implicit feedback behaviors, and 13 unintentional implicit feedback behaviors. As mentioned in the Methods, intentional implicit feedback and unintentional implicit feedback were different in whether a user's behavior has the intention for providing feedback to the platforms or not. For example, users may like a post or follow a user out of appreciation, or they may do it to inform the algorithm their preferences. Given that unintentional implicit feedback is common and natural usage of platforms and had been studied as ``implicit feedback'' in a substantial body of prior research~\cite{kelly2003implicit,jannach2018recommending}, in this section, we focus on explaining explicit feedback and intentional implicit feedback. \autoref{tab:feedbackType} presents these behaviors along with corresponding features, polarity, acting scope, and the number of participants who reported them. \autoref{tab:unintentional} in \autoref{appendix:unintentional} presents the behaviors for unintentional implicit feedback, including creating, collecting, and sharing a post, commenting and viewing comments, browsing profile pages, purchasing, and more. %They were mostly common usage of the algorithm-mediated apps, and were already being studied by a substantial body of research, especially on implicit feedback.

\begin{table*}[]
\small
\caption{Summary of behaviors for different feedback types and their corresponding characteristics, including platform features involved, the polarity (positive or negative) of feedback, the scope of the behavior, and the number of participants.}
\label{tab:feedbackType}
\resizebox{\textwidth}{!}{%
\begin{tabular}{p{0.37\linewidth}p{0.18\linewidth}p{0.08\linewidth}p{0.14\linewidth}p{0.15\linewidth}}
\toprule
\textbf{Behavior} & \textbf{Features}& \textbf{Polarity} & \textbf{Minimum Scope} & \textbf{Participant Count} \\ \midrule
\textbf{Explicit Feedback} &  &  &  &  \\
Mark as not interested & Not interested & - & Object & 21 \\
Use/Follow hashtags & Collect hashtags* & + & Object & 4 \\
Report a post or user & Report & - & Object & 3 \\
Disable personalization & Personalization options & - & Class & 3 \\ 
Subscribe to interested topics & Choose your interests & + & Class & 3 \\
Block a user & Block & - & Object & 2 \\
\midrule
\textbf{Intentional Implicit Feedback} &  &  &  &  \\
Ignore or swipe past a post &  & - & Object & 20 \\
Initiate a new search & Search & + & Class & 19 \\
Click a post (or comments) to view &  & + & Object & 14 \\
Stop using the platform or switch platforms &  & - & Class & 12 \\
Dwell on a post &  & +  & Segment & 4 \\
Like a post & Like & + & Object & 2 \\
Follow a user & Follow & + & Object & 2 \\
Refresh the feed &  & - & Class & 2 \\
Talk for platform monitoring &  & + & Class & 1 \\
\bottomrule
\multicolumn{5}{l}{* denotes the behavior or the feature exclusive to the Xiaohongshu platform.}
\end{tabular}%
}
\vspace*{-10pt}
\end{table*}


\subsubsection{Explicit feedback}
The explicit feedback behaviors identified in our analyses occurred mostly at the object scope and were all supported by specific platform features. The most frequently used explicit feedback, reported by 21 participants, was marking a post as ``Not interested.'' Participants used it as negative feedback to inform the algorithm that they do not wish to see similar content in the future. P06 stated that this was \textit{``the most direct and easy way to express dislike, where you can proactively intervene with the algorithm with just one extra step.''} Participants provided various reasons for using the ``Not interested'' feature such as lack of interest in the post content, ads, and poor content quality. Sometimes expression of non-interest was more on granular and nuanced content level. For example, users might appreciate fashion content in general, but their tastes could vary widely, thus not all fashion-related posts were relevant to them (P08).
% 就有一段时间他我讲上一次我都不感兴趣，那是有段时间他老给我推送一个博主的穿搭视频，然后博主他穿搭是我完全不感兴趣的，他可能是那种成贵妇名媛风的那种感觉，然后我是不会喜我不是这种风格的
Several participants highlighted the importance of using this feature to reduce homogeneous content for a diverse and engaging feed. P13 noted that \textit{``more niche content might appear after marking many similar recommendations as `Not interested,' making your feed more diverse and encouraging you to spend more time on the platform.''}
% 但是有的时候你会发现，比如说你点了之后，他可能还是会举个例子，可能说我点了这个之后，你会发现他第二天还是出现，然后你可能第二天你还要点，你不是说你点一次他就能解决问题的，可能你要点好几次他才能解决问题。所以我理解可能是它这个系统可能也在试探你就试一下我减少一点，你有没有发现，然后再减少更多。所以其实我的理解你可能要一直的反馈，或者让他明确的感知到你其实不喜欢这个内容，然后他的那种才会逐渐的恢复到你喜欢的，但是你点一次肯定是没用，他还会再出现。
Although commonly used, some participants found that platforms did not respond to this feedback effectively or immediately. P12 mentioned that the effect was not satisfactory as \textit{``it stopped recommending closely related content, but continued to suggest somewhat related items,''} which led her to use it less frequently. Meanwhile, P08 and P12 observed that it often required multiple attempts before the algorithm significantly reduced similar content. P12 speculated that the platform required consistent feedback to make gradual adjustments:
\begin{quote}
    It's not a one-time solution... I think the platform is testing you by slightly reducing the frequency to see if you noticed, and then reducing it further. You need to keep providing feedback or make it clear that you really don't like this content, and then it will gradually adjust. (P12)
\end{quote}
% 但是有的时候你会发现，比如说你点了之后，他可能还是会举个例子，可能说我点了这个之后，你会发现他第二天还是出现，然后你可能第二天你还要点，你不是说你点一次他就能解决问题的，可能你要点好几次他才能解决问题。所以我理解可能是它这个系统可能也在试探你就试一下我减少一点，你有没有发现，然后再减少更多。所以其实我的理解你可能要一直的反馈，或者让他明确的感知到你其实不喜欢这个内容，然后他的那种才会逐渐的恢复到你喜欢的，但是你点一次肯定是没用，他还会再出现。
Other negative explicit feedback included blocking, reporting, and disabling personalization, which were less frequently used. Blocking was to prevent further interactions with specific users, effectively removing their content from the participant's feed. Reporting was to flag content to the platform's moderation team, signaling that the content violated community guidelines. Participants only resorted to blocking or reporting when they experienced strong negative reactions such as when the content was offensive and inappropriate. Unlike blocking and reporting that provide feedback to specific object (a post or user), disabling personalization operates at class scope to convey an overall dissatisfaction. Three participants had tried disabling the ``personalization options'' feature in Xiaohongshu, either due to privacy concerns or to avoid addiction by preventing the platform from over-learning their preferences. However, they eventually re-enabled it after finding the non-personalized feed much less relevant and engaging. As P01 reflected that his perspective changed after disabling and re-enabling personalization: 
\begin{quote}
    After disabling personalization, my Xiaohongshu usage dropped significantly as the content no longer appealed to me, so I turned the personalization back on. After re-enabling it, my perspective shifted. I realized that the benefit of having personalization on is that it saves a lot of time by providing targeted recommendations, especially when searching for something specific. (P01)
\end{quote}
% 其实就是第一是关闭个性化之后，也让我感受到确实在一定程度上小红书这个软件我的使用频率下降了，并且他推的一些文件不是文章或者说笔记都是我不喜欢的了，所以我又把个性化给打开了。 打开了之后和最开始开的过程又会有一个思路上的变化，就是会感觉其实打开个性化的好处就是它能帮你节省大量的时间，比如说你可能打开之后就是想搜这个东西，你就会发现小红书一直在非常垂直的给你推这个领域的东西，他会帮你去节省一些搜索类的时间，以及他能帮你快速的展露一些你想要看到的一些内容也好，或者一些其他的方面东西也好，反正一是他做的确实很垂直，第二是它的丰富度确实没有问题
While most explicit feedback was negative, participants mentioned two positive explicit feedback mechanisms. One was the use of hashtags to increase visibility when publishing posts, or to follow content of interest. On Xiaohongshu, users who were not content creators can collect specific hashtags to follow updates and receive recommendation content tagged with those hashtags. Yet P09 felt that the hashtag functions \textit{``mainly benefited content creators to drive traffic rather than the viewers.''} She wished the platform would make collecting hashtags at the class level more useful by providing notifications for new posts, especially in niche areas. 

The other positive explicit feedback was subscribing to topics of interest, which involved selecting preferred content categories or topics. This differs from following individual users or channels, as it informs the platform about users' general interests rather than subscribing to specific user-generated content. Though the platform allowed later edits, participants either did not notice this feature or felt it was unnecessary to make changes.

\subsubsection{Intentional implicit feedback} 
The majority of intentional implicit feedback behaviors were positive. These behaviors, without direct platform features to prompt users, mostly relied on users' spontaneous intention to provide feedback.

Ignoring (in Xiaohongshu) or swiping (in Douyin) past a post was the most common intentional implicit feedback observed by 20 participants. Ignoring a post was to deliberately not click certain posts in Xiaohongshu's recommendation feed. Participants would ``actively skip'' (P01, P07), ``filter out'' (P04), or ``not pay attention to'' (P11) posts they were not interested in. Participants often combined this behavior with its opposite---intentional click, a positive feedback behavior reported by 14 participants. Swiping past a post in Douyin was to fast skip a video without engaging with it. As a form of negative feedback to avoid uninterested or homogeneous content, several participants preferred ignoring or swiping past content over marking it as ``Not interested'' for its efficiency and subtlety. For instance, P25 considered some content was \textit{``facets of the real world''} that should not be marked, believing that even if the content was not personally engaging, it represented diverse aspects of society and reality. P07 believed that if many people marked content as ``Not interested,'' it might not reach those who needed it, so she chose to simply swipe past the content. Both P25 and P07 used ignoring or swiping past the content to convey \textit{subtle} negative feedback, as marking ``Not interested'' would cause the content to disappear immediately. Although this feedback was subtle, participants found it to be reasonably effective. For example, P27 said: \textit{``Swiping past is the quickest way I deal with videos I'm not interested in, and it (the platform) learns from that behavior.''}
% 如果说很多人都选择不感兴趣，他可能不会推给真正有需要的人，我觉得他这个帖子就会沉下去，但有的人是真的会需要这方面的信息，所以我不会选择不感兴趣，包括我也会看抖音抖音，他也会就是说让你选他也可以选不感兴趣，但是我就不太会学，我会直接视频就刷过去 (P07)

Another intentional implicit feedback frequently used by participants was to initiate a new search. This was a proactive approach to get more targeted recommendation content. Participants believed that searching for specific topics prompted the algorithm to update their profile and push more relevant content. Some participants also leveraged search, or clicking on irrelevant search recommendations, to seek diverse content or escape ``information cocoon'' (P22, P29, and P34). P12 stated that it could be viewed as negative feedback, indicating that the recommendation feeds were too constrained. She would \textit{``try to start a novel search to override the overwhelming content''} to inform the platform to show her something else.
% 然后我就有点下意识的想要搜索一些奇特的东西，我觉得能不能相当于是我在用我的行为告诉他，我不想看这也是想给我换别的这种感觉...我有的时候会企图用搜索来覆盖我之前就那些铺门盖地的东西 

While many participants observed obvious changes in recommendation feeds following search feedback, sometimes the algorithm's response might not be as accurate or immediate as intended. For example, P12 searched for exam centers but received various exam-related posts, such as good luck rituals, which she did not believe in but led to anxieties. P11 highlighted the algorithm's failure to capture her shift in interest:
\begin{quote}
   I was very into ``Haikyuu!!'' and searched for it many times. The frequent searches and repeated clicks on related content in the homepage led the algorithm to push a lot of ```Haikyuu!!'' mechandise. But then I moved on to another anime, the system continued to flood my feed with ``Haikyuu!!'' content. Even after I searched for the new anime, the platform still hadn't learned that my interest had shifted. (P11)
\end{quote}
% 包括后来我用小红书搜，我之前是很喜欢看排球少年，然后搜了排球少年，可能是由于次数过多，然后在首页也疯狂点击，就导致他开始给我推送非常多的关于排球少年的动漫周边之类的东西。
% 后来排球少年看完了，我又看了另外一部动漫，然后这时候他就完全干不过我首页的排球少年，就搜搜完之后，他还是没有出现在我的手艺，但其实我目前已经对排球少年没有那么大的热情了，这点就是小红书没有发现我的爱好已经转变了(P11)。 
Despite the frequent use of search to intentionally provide feedback, it was also naturally used for information seeking, which was listed as ``search for information'' in unintentional implicit feedback.

% Implicit search refers to search actions taken when users are intrigued by a particular post and seek further information. In particular, when users engage in directed information seeking, they continue to search for validation of the post. Several participants mentioned a feature provided by multiple platforms that prompts search queries for related content or presents a search link in the comment area suggesting trending searches. P18 explained:

% \begin{quote}
%     I often come across new online buzzwords or topics I'm unfamiliar with after watching a video. TikTok does a great job with this; under each video, if you open the comments section, there's a `Trending Searches' button at the top that you can click to quickly find explanations or more related content. This shows that it's not just me; many people search for related content after watching a video.
% \end{quote}
% Participant P11 reflected that following the search prompts will lead to more recommendations on related sub-genres.

There were 12 participants mentioning that they stopped using the platforms or switched to other platforms when they felt the recommendation content no longer aligned with their interests or became too repetitive. This disengagement could serve as negative feedback to \textit{``let the recommendation system cool down''} (P26). It also indicated a desire to regain control over their content consumption and avoid becoming overly dependent on algorithm-driven feeds. Some participants reported stop using or uninstalling apps when their feeds became monotonous. P19 observed that after watching a couple of OpenAI videos, the algorithm flooded him with AI related content. He managed this by temporarily stop using the app, and upon returning, the intensity of such recommendation contents had decreased. Others mentioned switching to platforms less reliant on personalized algorithms, seeking a fresh perspective or a break from repetitive content.

Other intentional implicit feedback included dwelling on or liking posts, following users, refreshing the feed, and even talking about certain topics to ``let the platform monitor.'' Participants intentionally adjusted their dwell time on a post to convey their preferences to platforms. For instance, watching a video to the end, or repeatedly, signaled strong interest. P08 noticed that the algorithm’s positive reinforcement from finishing a lengthy video was so strong that she had to mark related posts as ``Not interested'' multiple times to mitigate its influence. 
% 因为我可能就看了一次，我就点进去看了一次，然后他经常给我更新他的每条视频，我就很有点无语，然后我就给他点了不感兴趣，后来还给我推送了一次，然后我又点了一次不敢学，然后后来他就没给我退。 
% Researcher Z 11:19 
% 点了退了两次，它才消失在你的信息推送里面，你觉得他们为什么会假如说你说你才点了一次，然后他就老给你推，你觉得是为什么呢？ 
% 你之前有其他的也有这种情况吗？就只点了一次，然后就一直在推。 
% Participant 11:40 
% 有点记不住了，感觉好像没有，反正这是我印象比较深刻的一次，因为可能我当时看那个视频很长，但是我我给他看完了，因为我还看了评论，因为博主他是什么，我想想他是什么，他走那种，因为他好像很有钱，就是那种住国外，然后不用工作那种，然后我还是个学生，我就有点羡慕你知道吧？我就看完了他的视频看的那一条，他讲的他什么怎么攻，生活怎么样的那种，然后我看了之后，然后他就开始给我推他的穿搭，就一直给我推他的穿搭每一期的穿搭，我就不知道怎么办可能太长了，然后我给他看完了，我觉得这是最重要的原因。
Following users had become more about customizing the feeds than social connection. Participants were less likely to browse the ``Follow'' page on these platforms, as followed users' content was already integrated into their recommendation feeds. P09 stated that it was unnecessary to pay attention to whom she followed because the algorithm would automatically recommend content created by them as well as relevant content:
\begin{quote}
    I've followed 6,000 people. They’re like seeds—I don't care which company produced it as long as they grow into flowers... The algorithm prioritizes content from bloggers I follow, so I will still follow them when necessary, but I’m not interested in remembering their names. (P09)
\end{quote}
% 没必要我灌输6000多个人，我记啥名字？他们只是我所需要的，就像我需要的种子一样，我只要这个种子能种出花就行，我不管他哪个厂生产的，我懒得记，你只要种子好也就。
% Researcher W 27:36
% 你的意思是说您觉得其实不用关注博主，只要是根据您以往的搜索和点击的，模式算法自动会把这些相关的退给你，是这个意思吗？
% Participant 27:52
% 不是不用关注，是不用记住它的名字。我关注还是会关注的，因为它的算法也会考虑到我关注哪几位博主在有的时候手机上不会不是会有个小小小圆圈说你的关注吗？他被推到我眼前的概率不就更高一点，但对于我没有关注，所以我该关注会关注，但是他们具体叫什么我懒得。
Although some participants reported using following and liking to refine recommendation feeds, these actions were more commonly considered natural interactions with the platform to express appreciation, which we categorized as unintentional implicit feedback.

% Many participants mentioned that they often forward posts with friends via direct messages or chat groups if they think their friends would be interested. They sometimes forward these posts to other social media apps they commonly used for daily conversation. This sharing may leads to further discussion. Additionally, participants observed that forwarding and communicating around the content will influence recommendations. For example, P12 mentioned:

% \begin{quote}
%     I frequently interact with two friends, and the three of us have a group chat where they like to share various posts. Some of these posts interest me, while others do not, but I always respond positively out of politeness. I believe that this sharing process affects my homepage recommendations. Since we follow each other, the algorithm might assume that I like their content. Additionally, my positive responses to their posts might signal to the algorithm that I am interested in similar content.
% \end{quote}

Many participants expressed concerns about platforms monitoring their daily conversations both online and offline. One participant (P25) strategically leveraged the perceived surveillance to influence recommendation feeds by \textit{``deliberately talking loudly about certain topics to let the app overhear''} and receive more desirable content. 

\subsection{Purposes for Usage of Personalized Recommendation Platforms}
We categorized users' purposes that motivate users to interact with algorithms into: content consumption, directed information seeking, content creation and promotion, and feed customization. Understanding the purposes provides context for interpreting the feedback and helps tailor recommendation feeds to better meet users' needs. 

We categorized the high-level purposes that motivate users to interact with algorithms into: content consumption, directed information seeking, content creation and promotion, and feed customization.

\subsubsection{Content consumption} 
A common purpose reported by all participants was consuming recommendation content. This referred to browsing the ``Explore'' page in Xiaohongshu undirectedly, or engaging with the continuous stream of short videos in the ``For You'' page of Douyin, Kuaishou, or Bilibili Shorts. Sometimes it became part of a participant’s routine. For instance, P09 used the explore page in Xiaohongshu as a ``library'' to gain creative inspiration related to calligraphy or drawings. When users encountered content they found interesting or useful, they naturally took further actions, such as sharing it with friends, collecting it, or downloading it for later use. Conversely, users' dissatisfaction with the recommendation content, such as perceived low relevance or high homogeneity, would lead to the purpose of feed customization.

\subsubsection{Directed information seeking} 
Another purpose was seeking information more directedly, such as searching for skincare tips, recipes, or travel advice. This often involved validating and cross-checking information, prompting further actions based on the perceived quality and authenticity of the content, such as searching across platforms or consulting friends. Several other participants highlighted the immediacy and relevance of the information on personalized recommendation platforms, noting that they now relied less on search engines for \textit{``everyday inquiries''} (P12). For example, P12 used it to search for available exam centers and compare their conditions, she noted that \textit{``the platform provides timely and useful information, whereas Baidu's (a Chinese search engine) results tend to be outdated or more official.''}

% 我觉得基本上对我来说的话，还是能够给我比较大的信息的，比如说在当地他考试条件如何，他考点是否开放，基本上我觉得都能得到答案。想说某种程度上我觉得现在有一点像百度的那种作用。
% Researcher W 02:24
% 你觉得他跟百度比的话哪个更好，或者说是他们的不同在哪里？
% Participant 02:31
% 我觉得小红书其实比较怎么讲，我觉得算是及时性比较强的，因为它是一个你就感觉是有很多人在回答你的问题，百度的话其实我现在就不太上百度上搜东西了，我感觉可能更多的像搜索这种内容就是比较生活性的，然后百度的问题可能它会比较老，或者说它会比较官方专业性的那种，感觉还是不太一样，像比如生活日常类的东西，我就会在小红书上搜。
% Researcher W 03:03
% 您刚才说会有很多人来回答你指的是搜索行为是吧？搜索了以后会找到一些答案是吗？
% Participant 03:12
% 对，我之前也有发过帖子问一个专门的问题，但那个的话其实可能还是回复量比较少，我觉得这个好像就比较看大数据它会不会给你推送出去或者怎么样，所以说主要还是进行一个搜索的时候，能够得到答案比较多。
% Researcher W 03:31
% 您是说您之前发过一个帖子，那个帖子有有得到多少回复，然后有没有一些回复，你觉得还可以。
% Participant 03:42
% 人家当时新冠的时候就是我自己养的，然后我就想了解一下大概这个症状是不是或者怎么样。但是当时发的话，我看这浏览量是500多，但是回复只有一个，从也等于是对我来说也没有太大的一个用处的，反而是我去搜索一些东西来对应我自己还是比较有用。

\subsubsection{Content creation and promotion}
Several participants shared their experiences of posting content on these platforms, noting that whether a post can achieve widespread reach often hinged on their understanding of the algorithm and how well they could harness it. Committed posters would closely monitor their post traffic and speculate about the underlying mechanisms. P14, for instance, mentioned that the view counts of her posts sometimes caused her anxiety. She attributed the limited traffic to a  lack of comments. P18 mentioned strategically using hashtags and crafting catchy titles to boost the visibility of their posts. By content creation and promotion, participants leaned more about the algorithm. They then not only used this knowledge to increase their posts' visibility as content creators but also curated their own recommendation feeds as content consumers. For example, P12 observed that using specific tags boosted the visibility of her posts. Then, she searched by these tags to obtain more relevant content.

% A few participants also play the role of content creators other than consumer. When they post on these platforms, they often pay attention to the popularity-related data of these posts, such as views and likes. They also speculate about the underlying mechanisms driving this popularity, forming folk theories, and use these theories to achieve more popularity. Some participants also observed that after posting certain content, their recommended feeds would start featuring related topics. P11 reflected this experience:

% \begin{quote}
%     I once posted something about my idol. Although my post did not get much attention, the platform started recommending a lot of popular and related content in my feeds.
% \end{quote}

\subsubsection{Feed customization} 
The need for feed customization arose when users were not satisfied with the personalized recommendation feeds, leading to deliberate actions to shape their content. Our analysis identified four specific goals for feed customization: improving recommendation relevance, increasing content diversity, reducing inappropriate content, and protecting privacy. 

\textit{Improving recommendation relevance} was the most common goal, reported by 23 participants, who proactively took action to increase the presence of more relevant and interested content or reduce uninterested or irrelevant content in their feeds. In particular, participants noticed that while algorithms initially captured their preferences well, they struggled to adapt quickly when those interests changed. This delay in the algorithm's response required users to continuously guide it to keep their feeds relevant and engaging. 

% For example, P12 mentioned customizing the feed when it did not capture her change of interest in time:

% \begin{quote}
%     It (the platform) did correctly guess what I was interested in. But after I finished that exam, I didn’t really need that kind of content anymore, and I even started to resist it. But it kept pushing it to me anyway, so I subconsciously started searching for some unusual things. I felt like I was using my behavior to tell him that I didn’t want to see this anymore. (P12, female)
% \end{quote}
% 他的确是猜我感兴趣，确实猜到了，然后然后但是有的时候也会觉得也完全没必要，满屏都是这个东西，因为我所需要的内容我其实已经知道了，然后就像那段时间我考完那个试之后，我其实就不太需要这方面的内容了，甚至我比较抵触这方面的内容，他依然还是在给我做这些，然后我就有点下意识的想要搜索一些奇特的东西，我觉得能不能相当于是我在用我的行为告诉他，我不想看这也是想给我换别的这种感觉

\textit{Increasing content diversity} was reported by 18 participants who sought to break out of homogeneous content and enrich their feeds with a broader range of topics. Many participants felt tired or annoyed by seeing repetitive content. P15 mentioned she did not want to open Douyin anymore, saying, \textit{``I'm even experiencing browsing fatigue now, often feeling that I’m not exposed to any new ideas.''} Some participants worried that recommendation content too closely aligned with their personal preferences could narrow their perspectives or intensify polarized views. For example, P12 felt the platform was \textit{``deliberately trying to please you, and it wants you to know that it's pleasing you, which is not very smart and can trap you in the information cocoon.''} P28 said \textit{``We used to have our phones follow our minds, but now our minds follow our phones, so the outcome is inevitably becoming narrower and narrower.''} These concerns lead them to proactively increase the content diversity.

\textit{Reducing inappropriate content} was reported by 11 participants who would take action when they encountered content that triggered a strong negative reaction. The goal was primarily driven by a desire to filter out ads or inappropriate and offensive content to maintain a more enjoyable online environment. 

\textit{Protecting privacy} was a less reported feed customization goal. Only two participants mentioned taking action to protect their privacy, despite that many participants expressed repulsion and concern over the platforms' invasion of privacy, such as monitoring posts sharing with friends within the platform, tracking conversations on other social media, and even eavesdropping on offline conversations.

\subsection{Variation in Feedback Types Used Across User Purposes}
After classifying participants' purposes for use of personalized recommendation platforms, we further analyzed the relationship between these purposes and feedback types. We mapped the feedback types to the corresponding purposes through code co-occurrence analysis. The results showed that the feedback types used were highly associated with the purposes. Specifically, intentional implicit feedback and explicit feedback were primarily used for feed customization, with intentional implicit feedback used more towards increasing content diversity and improving recommendation relevance, and explicit feedback for improving recommendation relevance and reducing inappropriate content. Unintentional implicit feedback was most commonly linked to content consumption.




\subsubsection{Feedback types aligning with general purposes} 
The frequency distribution of the three feedback types and four general purposes is presented in \autoref{tab:purposeRelation}. Each participant might have reported multiple feedback behaviors with respective purposes, therefore the total occurrences ($n = 198$) is larger than the number of participants. Unintentional implicit feedback was presented 105 instances among different purposes, followed by intentional implicit feedback (58 instances) and explicit feedback (35 instances).

\begin{table*}[]
\caption{The frequencies of each feedback type---unintentional implicit feedback, intentional implicit feedback, and explicit feedback---across user purposes, including content creation and promotion, feed customization, content consumption, and directed information seeking.}
\label{tab:purposeRelation}
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{p{0.3\linewidth}p{0.25\linewidth}p{0.2\linewidth}p{0.15\linewidth}p{0.1\linewidth}}
\toprule
\textbf{Purpose} & \textbf{Unintentional implicit} & \textbf{Intentional implicit} & \textbf{Explicit} & \textbf{Sum} \\
\midrule
Content consumption & 63 & 9 & 1 & 73 \\
Feed customization & 5 & 44 & 31 & 80 \\
Directed information seeking & 25 & 5 & 1 & 31 \\
Content creation / promotion & 12 & 0 & 2 & 14 \\
\midrule
\textbf{Sum} & \textbf{105} & \textbf{58} & \textbf{35} & \textbf{198} \\
\bottomrule
\end{tabular}
}
\end{table*}

Overall, intentional implicit feedback (75.9\%, 44 out of 58 instances) and explicit feedback (88.6\%, 31 out of 35 instances) was predominately utilized for feed customization, while unintentional implicit feedback (60\%, 63 out of 105 instances) was most commonly associated with content consumption.

For content consumption, 63 instances highlighted natural interactions with the platform, such as liking, sharing, or saving posts to express appreciation or for future reference. Participants might also browse the content creator's profile page, view the search prompt, or search for additional information to learn more when something piques their interest. For instance, P18 often expanded the comment section to see the ``Trending searches'' provided by Douyin to quickly find explanations or more related content about the post. All these natural behaviors would then be regarded as unintentional implicit feedback by algorithms to refine recommendation feeds. Although participants performed these behaviors without (reporting) intention of influencing the algorithm, some participants noticed that the algorithm had responded to their behaviors. P18 noticed the platform started to recommend related content after she lingered at someone's profile page.

% Only nine instances opted for intentional implicit feedback by following posts and tracking creators that interested them. 

The purpose of feed customization had 44 instances of intentional implicit feedback, such as ignoring or swiping past a post, clicking on a post to view it, or initiating a search to shape recommendation feeds. For example, P27 mentioned that when customizing his feeds, he would spend more time on videos about snowboarding (new interest) rather than badminton (known interest). Additionally, 31 instances were explicit feedback, such as marking content as ``Not interested'' or blocking it, to actively intervene with the algorithm. %(P06).

For directed information seeking and content creation and promotion, the most common feedback behaviors were searching for information and creating posts respectively. Although in these circumstances, searching and posting actions were not performed deliberately for customizing the feed, the system still interpreted them as feedback and adjusted recommendation content accordingly. P11 noted that after posting about her favorite idol, the platform began recommending more popular and related content in her feed, even though her post itself attracted little attention. Two participants mentioned explicitly using hashtags for content promotion. For example, P05 used ``Note Inspiration''\footnote{A specific feature, just like a trending topic for posts, can be highlighted using hashtags. Posts with these hashtags tend to be clustered around a particular theme, often resulting in higher traffic and engagement.} on Xiaohongshu to promote the visibility of her posts.

%Moreover, there was a notable difference in that more people chose directed information seeking compared to self-posting on short video platforms, which were initially designed for social interaction with friends.

These findings demonstrated observable differences in feedback types when the user's intent was to customize feeds compared to when they engaged in activities like content creation or consumption. While feed customization primarily relied on intentional implicit and explicit feedback, other purposes are more associated with unintentional implicit feedback. 

\subsubsection{Feedback types driven by specific feed customization purposes}

\begin{table*}[]
\centering
\small
\caption{The frequencies of intentional implicit feedback and explicit feedback across four specific feed customization purposes, including increasing content diversity, improving recommendation relevance, reducing inappropriate content, and protecting privacy.}
%Unintentional implicit feedback is not included in this table because there were limited instances of its use for algorithm customization purpose.
\label{tab:feedback_algopurpose}
\resizebox{\textwidth}{!}{%
\begin{tabular}{p{0.3\linewidth}p{0.3\linewidth}p{0.2\linewidth}p{0.1\linewidth}}
\toprule
\textbf{Feed customization purpose} & \textbf{Intentional implicit feedback} & \textbf{Explicit feedback} & \textbf{Sum} \\ \midrule
Improving recommendation relevance & 18 & 14 & 32\\
Increasing content diversity & 24 & 5 & 29\\
Reducing inappropriate content & 2 & 10 & 12\\
Protecting privacy & 0 & 2 &  2\\ \midrule
\textbf{Sum} & \textbf{44} & \textbf{31 }& \textbf{75}\\
\bottomrule
\end{tabular}%
}
\vspace*{-8pt}
\end{table*}

% Most participants noted that the algorithms are generally effective at capturing their intentions and responding to their feedback, although it may require multiple interactions to observe the changes. However, this same accuracy in recommendations can also raise concerns among some users to protect their privacy or avoid the effects of an information cocoon. There are instances when participants decide they no longer want to continue with algorithm training and choose to stop using the platform. P15: 
% \begin{quote}
%     I feel that most of the viewpoints are homogeneous, and it's rare to encounter differing perspectives. I'm even experiencing browsing fatigue now—often feeling that I’m not exposed to any new ideas, and the content I see is incredibly dull. This has led me to either close the app or not open TikTok at all. (P15, female)
% \end{quote}

As \autoref{tab:feedback_algopurpose} depicts, for users aiming to improve recommendation relevance, both intentional implicit feedback (18 instances) and explicit feedback (14 instances) were frequently used.
% , while unintentional implicit feedback was rarely observed; therefore, it will not be discussed here. 
Ignoring or swiping past a post was the most used intentional implicit feedback, while marking as ``Not interested'' was the most common explicit feedback. P27 asserted that swiping away the content was already effective in signaling disinterest, eliminating the need for explicit marking. P11 explained that her choice between these feedback methods depended on the context and the degree of dislike. She would only use the marking as ``Not interested'' option when she \textit{``deeply detested''} the recommendation content. 
\begin{quote}
    I hadn't searched for ``The Wandering Earth'' before, but it still recommended it to me. This might be because ``The Wandering Earth'' is very popular lately, so the system tries to see if I'm interested. If I don't pay attention, they'll likely disappear. So, with these exploratory recommendations, unless I deeply detest them, I usually just swipe them away to get some new content. (P11)
\end{quote}
% 我觉得他可能会根据一些现在实时的热点推给我，比如说我之前说我没有搜索过流浪地球，但是他却推给我了，这样的情况可能就是因为流浪地球最近很火，所以他就尝试着推给我，看我有没有看过，但一般这种推送都非常的少，如果我不去注意的话，它可能就过去了，所以一般有这种试探性的推送，除非我真的对它深恶痛绝，我会点个不感兴趣，一般我就直接去刷新一下，换一批那种感觉

For detailed associations between specific feed customization purposes and feedback types, as illustrated in \autoref{tab:feedback_algopurpose}, when participants sought to improve content diversity, 24 out of 29 instances used intentional implicit feedback, with only five opting for explicit feedback. The primary implicit feedback behavior was initiating a new search. The participants discovered that searching certain topics increased the weight of related content in recommendation feeds, thus they strategically searched for new topics. As P06 speculated: \textit{``the system might update your user profile or data based on that search and then start pushing related content that aligns with your new interests.''}

In contrast, 10 out of 12 instances chose explicit feedback to reduce inappropriate content. The explicit feedback was perceived as quicker and more direct to address inappropriate content. Participants tended to mark content as ``Not interested'' when they found it low-quality, full of ads, or disturbing (P09 and P16). In cases of offensive personal attacks or strong disagreement with a creator's opinion, users were more likely to report or block. 
% P26 mentioned, ``I strongly disagreed with his (the blogger's) opinion, so I blocked him,'' and P34 commented:
% \begin{quote}
%     The internet is full of all kinds of weird things, and indeed, there were some rather odd users. Often, especially when someone behaved rudely, there was a tendency for me to block or delete them. (P34, female)
% \end{quote}

% P27 believed that this feature allowed users to control the content being recommended to them:
% \begin{quote}
%     Making good use of the search function was important. You needed to divide yourself into two modes: one for browsing aimlessly out of boredom, and another with a purpose. It was like using Bilibili; you needed to use it in two ways. It had both the features of Bilibili and Douyin; it just depended on how you switched between them. (P27, male)
% \end{quote}

Only two participants mentioned their attempt to protect privacy by explicitly disabling the personalization option. P01, concerned about the platform's data collection and user profiling practices, decided to turn off personalization to prevent Xiaohongshu from using his interactions to build a detailed user profile. P14 said that she tried disabling personalization to protect privacy, however, without knowing \textit{``whether it really worked.''} 
%These users did not receive clear feedback on whether their privacy was effectively protected.%

The results underscored how users' feed customization goals, along with their understanding of algorithms, drove their choice of feedback type for the personalized recommendation platforms. Overall, participants relied more on intentional implicit feedback to increase content diversity, whereas explicit feedback is more preferred for reducing inappropriate content. Participants aiming to improve recommendation relevance employed a mix of both implicit and explicit feedback. Meanwhile, participants concerned with protecting privacy took a more passive approach, seldom engaging with feedback mechanisms, in contrast to the active use of intentional implicit feedback by those aiming to increase content diversity. 
