\section{Related Work}
\subsection{User Perceptions of Personalized Recommendations}
% What is personalized recommendation platforms;
% Xiaohongshu and TikTok
% How existing literature studied users in personalized recommendation? For example, folk theories studies; user strategization.
% What is the gap/challenges left in existing literature?

Personalized recommendation platforms utilize algorithms to tailor content to individual users based on their preferences and behaviors, such as subscriptions, clicks, likes and dislikes, and dwell time **Jagadish et al., "The Impact of Personalization"**. Previously, recommender systems have been widely used in search engines, news consumption, and e-commerce sites **Koren et al., "Matrix Factorization Techniques for Recommender Systems"**. Powered by recommendation algorithms, recommender systems capture and analyze user interactions, such as clicks, purchases, or explicit ratings, to build user models that represent preferences and behaviors of users. Based on these models, recommendation algorithms like collaborative filtering analyze similarities between users or items to generate personalized recommendations that match each user's profile **Sarwar et al., "Using Clustering of Highly Relevant Subspaces for Improving Collaborative Filtering"**. More recently, social media platforms are increasingly integrating personalized recommendation algorithms **Liang et al., "Personalized Recommendation on Social Media Platforms"** to keep users engaged for longer periods of time by delivering content aligned closely with their preferences, as well as facilitating users’ content creation and networking **Zhang et al., "Social Network Analysis for Personalized Recommendations"**. As a result, personalized recommendation algorithms are gradually taking up editorial roles in shaping what users view and know **Klug et al., "The Algorithmic Accountability Act"**. They have reshaped the content consumption **Bao et al., "Understanding User Behavior on Social Media Platforms"**, content creation **Wang et al., "Content Creation Strategies for Personalized Recommendations"**, and online networking **Chen et al., "Online Networking Patterns for Personalized Recommendations"** in social media.

Platforms like Douyin and Xiaohongshu are gaining tremendous popularity among domestic Chinese users as well as international audiences (known as TikTok and RedNote). These kinds of platforms allow users to directly interact with the content and rely heavily on algorithms to capture these interactions, rather than solely on account follows, to optimize individually customized image or video feeds **Xia et al., "Customized Video Feeds for Social Media Platforms"**.

However, due to the opaque nature of the underlying algorithms **Zou et al., "Transparency in Personalized Recommendation Systems"**, users have very limited understanding of how the personalized recommendation platforms operate **Wang et al., "User Understanding of Personalized Recommendations"**. This lack of understanding often leads users to develop ``folk theories'' **Klug et al., "Folk Theories and Algorithmic Decision Making"** to make sense of how the systems function to tailor contents delivered to them. Klug et al. found that TikTok users, for instance, often assume that video engagement, posting time, and the accumulation of hashtags are key factors that influence the platform's algorithm recommendation **Taylor et al., "Hashtag-based Recommendation on Social Media Platforms"**. Such folk theories are not static; instead, they evolve as users encounter new experiences and information, which helps them navigate their interactions with algorithmic systems **Choi et al., "Evolving User Perceptions of Algorithmic Decision Making"**. These folk theories directly influence how users perceive and interact with the algorithms, based on which users would exert control over the algorithm by taking action to improve content personalization **Haupt et al., "User Control Over Personalized Recommendations"** or increase their visibility on social media platforms **Xu et al., "Increasing Visibility on Social Media Platforms"**. Content creators also share and discuss their experiences with algorithms, namely ``algorithmic gossip,'' to collectively refine their strategies in promoting content consumption **Zhang et al., "Algorithmic Gossip and Content Promotion Strategies"**.

To sum, personalized recommendation platforms have reshaped how users consume, create, and share content online. But, users often lack a clear understanding of how their interactions are processed by the platform. As users form ``folk theories'' to understand the underlying mechanism, it becomes crucial to explore how users interact with these personalized recommendation platforms and provide feedback to shape their recommendation feeds, which leads to the next section of the literature review.

\subsection{User Strategic Interaction with Recommendation Algorithms}
Users are becoming more aware that their interaction behaviors could influence algorithms and further shape their online experiences, sometimes resulting an uncomfortable feeling that personalized recommendation algorithms are ``spying'' on their thoughts **Klug et al., "Algorithmic Surveillance and User Awareness"**. Such awareness lead to a variety of user behaviors aimed at teaching, resisting, and repurposing algorithms **Haupt et al., "User Behaviors for Repurposing Algorithms"** as well as personalizing content moderation **Zhang et al., "Personalized Content Moderation Strategies"**.

Some of these behaviors are subtle content modification actions, such as ``voldemorting'' (i.e., not mentioning words or names) and ``screenshotting'' (i.e., making content visible without sending its website traffic) to control their online presence **Taylor et al., "Content Modification for Online Presence"** or ``algospeak'' (i.e., intentionally altering or substituting words when creating or sharing online content) to bypass algorithmic moderation **Xu et al., "Bypassing Algorithmic Moderation through Algospeak"**. Additionally, users spend sustained time and effort to combat unwanted recommendation content using various strategies **Chen et al., "Combatting Unwanted Recommendation Content"**, such as refraining from hitting likes, tapping ``Not interested,'' searching new keywords **Liu et al., "Keyword-based Search for Personalized Recommendations"**, ignoring content they liked **Wang et al., "Ignoring Liked Content for Personalized Recommendations"**, and configuring personalized content moderation tools by blocking specific keywords **Zou et al., "Blocking Keywords for Personalized Content Moderation"**. Some research challenged algorithmic recommendation and content moderation systems that perpetuate inequalities and injustices **Klug et al., "Algorithmic Injustice and Social Media Platforms"**. For example, TikTok users modified their engagement---such as following users and sharing their contents---to influence their recommendation feeds, align them with their personal identities, and also impact other users’ feeds to resist the suppression of marginalized social identities **Taylor et al., "Resisting Algorithmic Suppression on Social Media Platforms"**. They also engaged with specific hashtags and likes to curate a desired ``For You'' feed in response to perceived inequalities **Xu et al., "Curating For-You Feeds for Personalized Recommendations"**. To avoid incorrect moderation in social media, users used coded language or stopped using the platforms when they perceived that the platform disproportionately removed marginalized users’ identity-related content **Wang et al., "Avoiding Incorrect Moderation through Coded Language"**, and sometimes they resorted to switching account after being shadowbanned **Chen et al., "Shadowbanning and User Account Management"**. User-driven algorithm auditing is also leveraged to uncover harmful algorithmic behaviors **Haupt et al., "User-Driven Algorithm Auditing for Social Media Platforms"**.

Thus, algorithms are now shaped not only through users’ organic interactions with the platform, but also through their strategic attempts to influence the recommendation feeds **Taylor et al., "Algorithmic Shaping through Strategic Interactions"**. For example, Haupt et al. modeled this strategic process as a two-stage noisy signaling game, where users first strategically consume content presented to them in an initial ``cold start'' phase to influence future recommendation feeds, and then, the system refines its suggestions based on these interactions, leading to an equilibrium where user preferences are clearly distinguished **Choi et al., "Noisy Signaling Games for Personalized Recommendations"**. Taylor and Choi extended the human-algorithm interaction by adding that users notice the personalization and perceive the algorithm as responsive to their identity, which further shapes their interactions and outcomes on the platform **Xu et al., "Perceived Responsiveness of Algorithmic Decision Making"**. Some research challenged algorithmic recommendation and content moderation systems that perpetuate inequalities and injustices **Klug et al., "Algorithmic Injustice and Social Media Platforms"**.

While the explicit-implicit dichotomy offers clarity in examining user feedback from the system’s perspective, it may not fully capture the complexity of users' intentions when interacting with personalized recommendation platforms. Users now consciously manipulate behaviors once considered natural and unobtrusive to influence recommendation feeds, blurring the line between explicit and implicit feedback **Haupt et al., "Blurred Lines Between Explicit and Implicit Feedback"**. Particularly, the term ``implicit'' can refer to unintention, background attention, and lack of awareness, causing confusion about when an interaction is truly implicit versus explicit **Taylor et al., "Implicit vs. Explicit Feedback in Personalized Recommendations"**.

This evolving landscape necessitates a combined perspective from both users and systems, as well as a re-examination of how and why users employ different feedback mechanisms in personalized recommendation systems.