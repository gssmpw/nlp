\section{Related Work}
\subsection{User Perceptions of Personalized Recommendations}
% What is personalized recommendation platforms;
% Xiaohongshu and TikTok
% How existing literature studied users in personalized recommendation? For example, folk theories studies; user strategization.
% What is the gap/challenges left in existing literature?

Personalized recommendation platforms utilize algorithms to tailor content to individual users based on their preferences and behaviors, such as subscriptions, clicks, likes and dislikes, and dwell time ~\cite{adomavicius2005toward, setyani2019exploring,yi2014beyond}. Previously, recommender systems have been widely used in search engines, news consumption, and e-commerce sites \cite{schafer1999recommender,lu2015recommender,raza2022news}. Powered by recommendation algorithms, recommender systems capture and analyze user interactions, such as clicks, purchases, or explicit ratings, to build user models that represent preferences and behaviors of users. Based on these models, recommendation algorithms like collaborative filtering analyze similarities between users or items to generate personalized recommendations that match each user's profile~\cite{zanker2009case}. More recently, social media platforms are increasingly integrating personalized recommendation algorithms~\cite{guy2010social} to keep users engaged for longer periods of time by delivering content aligned closely with their preferences, as well as facilitating users’ content creation and networking ~\cite{seaver2019captivating,van2018networks, kang2022ai}. As a result, personalized recommendation algorithms are gradually taking up editorial roles in shaping what users view and know ~\cite{gillespie2014relevance}. They have reshaped the content consumption ~\cite{bucher2016algorithmic}, content creation ~\cite{devito2018people, bucher2018cleavage}, and online networking ~\cite{eriksson2021algorithmic} in social media.
Platforms like Douyin and Xiaohongshu are gaining tremendous popularity among domestic Chinese users as well as international audiences (known as TikTok and RedNote). These kinds of platforms allow users to directly interact with the content and rely heavily on algorithms to capture these interactions, rather than solely on account follows, to optimize individually customized image or video feeds ~\cite{Huang_2021, klug2021trick, Chen2019}. 

However, due to the opaque nature of the underlying algorithms ~\cite{gillespie2014relevance, pasquale2011restoring}, users have very limited understanding of how the personalized recommendation platforms operate ~\cite{eslami2015always}. This lack of understanding often leads users to develop ``folk theories'' ~\cite{devito2017algorithms, eslami2016first, ngo2022exploring, bucher2016algorithmic} to make sense of how the systems function to tailor contents delivered to them. Klug et al. found that TikTok users, for instance, often assume that video engagement, posting time, and the accumulation of hashtags are key factors that influence the platform's algorithm recommendation~\cite{klug2021trick}. Such folk theories are not static; instead, they evolve as users encounter new experiences and information, which helps them navigate their interactions with algorithmic systems ~\cite{devito2018people}. These folk theories directly influence how users perceive and interact with the algorithms, based on which users would exert control over the algorithm by taking action to improve content personalization ~\cite{haupt2023recommending} or increase their visibility on social media platforms ~\cite{burrell2019users, bucher2018cleavage}. Content creators also share and discuss their experiences with algorithms, namely ``algorithmic gossip,'' to collectively refine their strategies in promoting content consumption~\cite{bishop2019managing}. 

To sum, personalized recommendation platforms have reshaped how users consume, create, and share content online. But, users often lack a clear understanding of how their interactions are processed by the platform. As users form ``folk theories'' to understand the underlying mechanism, it becomes crucial to explore how users interact with these personalized recommendation platforms and provide feedback to shape their recommendation feeds, which leads to the next section of the literature review.


\subsection{User Strategic Interaction with Recommendation Algorithms}
Users are becoming more aware that their interaction behaviors could influence algorithms and further shape their online experiences, sometimes resulting an uncomfortable feeling that personalized recommendation algorithms are ``spying'' on their thoughts~\cite{ellison2020we,klug2021trick}. Such awareness lead to a variety of user behaviors aimed at teaching, resisting, and repurposing algorithms ~\cite{kim2023investigating} as well as personalizing content moderation ~\cite{jhaver2023personalizing}. 

Some of these behaviors are subtle content modification actions, such as ``voldemorting'' (i.e., not mentioning words or names) and ``screenshotting'' (i.e., making content visible without sending its website traffic) to control their online presence~\cite{van2018networks} or ``algospeak'' (i.e., intentionally altering or substituting words when creating or sharing online content) to bypass algorithmic moderation ~\cite{klug2023how}. Additionally, users spend sustained time and effort to combat unwanted recommendation content using various strategies ~\cite{papadamou2022just, ricks2022does}, such as refraining from hitting likes, tapping ``Not interested,'' searching new keywords~\cite{kim2023investigating}, ignoring content they liked~\cite{Cen_Ilyas_Allen_Li_Madry_2024}, and configuring personalized content moderation tools by blocking specific keywords~\cite{jhaver2022designing}. Some research challenged algorithmic recommendation and content moderation systems that perpetuate inequalities and injustices ~\cite{karizat2021algorithmic,bishop2018anxiety,rosenblat2016algorithmic,kasy2021fairness}. For example, TikTok users modified their engagement---such as following users and sharing their contents---to influence their recommendation feeds, align them with their personal identities, and also impact other users’ feeds to resist the suppression of marginalized social identities ~\cite{karizat2021algorithmic}. They also engaged with specific hashtags and likes to curate a desired ``For You'' feed in response to perceived inequalities ~\cite{simpson2021}. To avoid incorrect moderation in social media, users used coded language or stopped using the platforms when they perceived that the platform disproportionately removed
marginalized users’ identity-related content ~\cite{mayworm2024content}, and sometimes they resorted to switching account after being shadowbanned~\cite{yao2024blind}. User-driven algorithm auditing is also leveraged to uncover harmful algorithmic behaviors ~\cite{devos2022toward, shen2021everyday}. 

Thus, algorithms are now shaped not only through users’ organic interactions with the platform, but also through their strategic attempts to influence the recommendation feeds ~\cite{lee2022algorithmic}. For example, Haupt et al. modeled this strategic process as a two-stage noisy signaling game, where users first strategically consume content presented to them in an initial ``cold start'' phase to influence future recommendation feeds, and then, the system refines its suggestions based on these interactions, leading to an equilibrium where user preferences are clearly distinguished ~\cite{haupt2023recommending}. Taylor and Choi extended the human-algorithm interaction by adding that users notice the personalization and perceive the algorithm as responsive to their identity, which further shapes their interactions and outcomes on the platform ~\cite{taylor2022initial}. Some research also refer to users' purposeful manipulation as ``gaming'' the algorithm ~\cite{petre2019gaming,SHEPHERD2020102572, hardt2016strategic}. Content creators may ``play the visibility game'' by leveraging relational and simulated influence to gain commercial benefits~\cite{cotter2019playing}. While gaming could spur innovations and discover new uses for existing platforms ~\cite{bambauer2018algorithm}, the strategic adaptation of behaviors may as well be misinterpreted by the algorithm and degrade its accuracy ~\cite{Cen_Ilyas_Allen_Li_Madry_2024}.

These studies indicate that users consciously employ a variety of behaviors to influence algorithms and shape their recommendation feeds, guided by their perceptions or ``folk theories'' of how the algorithms work. However, limited research has connected these user perceptions with the platforms' underlying feedback mechanisms. Understanding how users' perceptions align with or diverge from the algorithm's intended responses---and how they interact to shape recommendation feeds---can inform improvements in feedback design for personalized recommendation systems.

\subsection{Implicit and Explicit User Feedback}
Feedback mechanisms play an important role in human-computer interaction. System feedback communicates the response to a user's action \cite{perez1996collaborative} , while user feedback can be used as a useful input for system optimization ~\cite{Spink/Losee:96}.  User interactions are captured and used as user feedback to refine recommendation feeds. In fields of information retrieval ~\cite{Spink/Losee:96} and recommender systems ~\cite{oard2001modeling}, these mechanisms are commonly divided into two categories: explicit and implicit feedback. \textit{Explicit feedback} relies on direct user input to specify their preferences, such as specifying keywords, marking documents, rating, or answering questions about their interests ~\cite{kelly2003implicit}. It usually represents a deliberate, unambiguous, and intentional quality assessment by a user ~\cite{jannach2018recommending}. However, explicit feedback mechanisms often impose a higher user cost, demanding additional effort beyond typical search behavior ~\cite{kelly2003implicit, gadanho2007addressing}. In contrast, \textit{implicit feedback} refers to all kinds of user interactions with the systems from which the system can indirectly infer user preferences ~\cite{jannach2018recommending}. It unobtrusively obtain user preferences based on their natural interactions, such as viewing, selecting, saving, and forwarding ~\cite{kelly2003implicit,jannach2018recommending}. 

Observable user behaviors used as feedback were categorized into several types, including examination, retention, social and public action, physical action, creation, and annotation, with explicit feedback behaviors mainly falling under the annotation category ~\cite{jannach2018recommending}. Among these behaviors, clicks have long been used as a major feedback mechanism by search engines as indicators of intent and relevance. Scholars attempted to analyze users' click behavior under search queries~\cite{zhang2011user,shen2012personalized} to optimize the ranking algorithms of search engines. The number of clicks on ads has also become the primary indicator of revenue for commercial search engines ~\cite{kim2011advertiser}. Because of the economic motivation, numerous studies have explored how to predict ad clicks more accurately in search engines ~\cite{jacques2015differentiation,liu2010personalized}. In social media platforms, more diverse traits are used to predict user preferences, such as the user's friend networks~\cite{ellison2020we}, posts~\cite{kim2016click}, likes~\cite{cheung2022influences, hu2022interest}, and bookmarks~\cite{klaisubun2007behavior}. Oard and Kim outlined the \textit{minimum scope} of different behaviors, which is the minimum level at which feedback is applied---whether it impacts a portion of an object (segment level, e.g., viewing comments of a post), an entire object (object level, e.g., collecting a post), or multiple objects (class level, e.g., platform-wide searches) ~\cite{oard2001modeling}. Jawaheer et al. compared different properties between implicit and explicit feedback. For instance, explicit feedback provides transparency but also required cognitive effort, thus only a small percentage of users actively provide it, often leading to bias toward those who are more expressive ~\cite{jawaheer2014modeling}. In terms of \textit{polarity}---the positive (preference) or negative (dislike) orientation of the feedback---explicit feedback contains both whereas implicit feedback is typically considered positive ~\cite{jawaheer2014modeling, hu2008collaborative}. These properties, along with factors like user goals ~\cite{nazari2022choice,liang2023enabling}, digital literacy ~\cite{devito2018people}, and task complexity ~\cite{white2005study}, all have potential influence on users' understanding and adoption of different feedback mechanisms. For example, skilled users rely on platform cues to grasp algorithms, while those with lower web skills depend on external guidance. Users with peacekeeping self-presentation goals tend to limit explicit hashtag use compared to those focused on authenticity ~\cite{devito2017algorithms}. Users are reluctant to provide explicit feedback in complex tasks but are more willing to do so in media and entertainment domains ~\cite{white2005study,jawaheer2014modeling}. Moreover, the interpretation and effectiveness of these feedback is also dependent on contextual factors including user characteristics ~\cite{jawaheer2014modeling} and system functionalities ~\cite{liu2024train}.

While the explicit-implicit dichotomy offers clarity in examining user feedback from the system’s perspective, it may not fully capture the complexity of users' intentions when interacting with personalized recommendation platforms. Users now consciously manipulate behaviors once considered natural and unobtrusive to influence recommendation feeds, blurring the line between explicit and implicit feedback. Particularly, the term ``implicit'' can refer to unintention, background attention, and lack of awareness, causing confusion about when an interaction is truly implicit versus explicit ~\cite{serim2019explicating}. 
This evolving landscape necessitates a combined perspective from both users and systems, as well as a re-examination of how and why users employ different feedback mechanisms in personalized recommendation systems.