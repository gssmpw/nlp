\section{\label{sec:method}Proposed Method}

\method consists of four interdependent modules working in a iterative feedback-loop (Fig~\ref{fig:pipeline}). 
The deviation analyzer examines system logs to identify anomalous events. 
The graph analyzer processes the anomalous events, constructs a graph, prunes benign nodes, and clusters suspicious nodes into communities. 
The LLM analyzer evaluates these communities, identifying attack patterns and assigning confidence scores. 
Finally, the temporal correlation engine preserves historical attack data, correlates events across time, and re-initiates analysis when necessary, ensuring continuous and adaptive threat detection.

\begin{figure}[ht]
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{0pt}
\centering
\includegraphics[width=\textwidth]{figures/pipeline}
\caption{Overview of the \method pipeline, with an example demonstrating the interaction between the four modules.}
\label{fig:pipeline}
\end{figure}

\noindent\textbf{Deviation Analyzer. }
The deviation analyzer serves as the foundation of \method's detection capabilities by identifying behavioral deviations in system logs (see example in Fig.~\ref{fig:deviation_analyzer}). 
It uses a local outlier factor (LOF) model provided with baseline system activities as a reference.
This model processes raw logs to produce a filtered graph of anomalous processes and their immediate lineage. %, establishing the first line of defense against potential threats.

\noindent\textit{(a) Log structure and notation.} The system logs capture detailed process-object interactions in the operating system. 
Each log entry $l_i$ in our dataset is represented as: 
  $l_i = (p_i, n_i, e_i, o_i, d_i, t_i)$,
where $p_i$ represents the process identifiers, $n_i$ the process name, $e_i$ the event type, $o_i$ the object identifiers, $d_i$ the object data, and $t_i$ the timestamp indicating time at which the event occurred. 
To efficiently process these logs, deviation analyzer employs a mapping mechanism that converts categorical variables into numerical representations while maintaining a bidirectional mapping for result interpretation.

\noindent\textit{(b) Outlier detection.} The anomalous event detection task involves several key steps. 
First, we preprocess the system logs by removing duplicate entries to ensure that unique process-object interactions are analyzed. 
The features used for anomaly detection include the numerical representations of the logs $\langle p_i, e_i, o_i \rangle$, which are standardized using \texttt{StandardScaler} to ensure uniform feature scaling.
\begin{equation}
A(l_i) =
\begin{cases}
1 & \text{if } \text{LOF}_k(l_i) > \tau, \\
0 & \text{otherwise}
\end{cases}
\end{equation}
where $\tau$ is the contamination threshold set at 0.1 and $k$ is the number of neighbors set at 20 used for density estimation by the LOF algorithm; these values were set based on an empirical study we performed.

\noindent\textit{(c) Filtered graph creation.} Based on the detected anomalous events (red arrows in Fig.~\ref{fig:deviation_analyzer}b), the deviation analyzer identifies the processes performing these events (red ovals in Fig.~\ref{fig:deviation_analyzer}c). 
Then, for each anomalous process identified, the deviation analyzer extracts: (1) the process's direct ancestors through fork events, which are identified by matching the object identifier $(o_i)$ with the anomalous process's identifier $(p_i)$, and (2) the process's immediate descendants, found by examining fork events where the anomalous process is the parent, as shown in Fig.~\ref{fig:deviation_analyzer}c (process $S2$).
Choosing one-hop lineage stems from a well-known property of system-level provenance graphs where a process is responsible for transferring data between two objects~\cite{inam2023sok}. 
This lineage tracking is formalized as:
\begin{equation}
R = \bigcup_{i} G_i \quad \forall l_i : A(l_i) = 1
\end{equation}
where $G_i$ represents the subgraph containing the anomalous process and its one-hop lineage as depicted in Fig.~\ref{fig:deviation_analyzer}d. \\

\begin{figure}[!t]
%\setlength{\abovecaptionskip}{3pt}
%\setlength{\belowcaptionskip}{0pt}
\centering
\includegraphics[width=1.2\textwidth]{figures/deviation}
\caption{Deviation analyzer: Detection of event-level anomalies, followed by the addition of the processes and their first-level ancestors and descendants for further analysis.}
\label{fig:deviation_analyzer}
\end{figure}

\noindent\textbf{Graph Analyzer. }
Using the filtered graph from the deviation analyzer as input, the graph analyzer examines relationships between processes, identifying potential points of infection, prunes benign nodes, and clusters the suspicious nodes using community detection algorithms (as illustrated in Fig.~\ref{fig:graph_analyzer}).

\noindent\textit{(a) Detection of initial infection points.} 
\method focuses on attacks originating from entities through network communication interfaces (sockets), which serve as the connection points between the victim's system and external entities (e.g., a user visiting a malicious website that downloads a payload to the system).
As illustrated in Fig~\ref{fig:graph_analyzer}, the socket is the object from which the attack was initiated. 
We refer to all such external sockets as initial infection points. 
In the example presented in Fig.~\ref{fig:graph_analyzer}a, socket object \textit{O1} is the initial infection point.

\noindent\textit{(b) Suspicious tag propagation.} The graph analyzer propagates the suspicious tags from the initial infection points to other nodes in the provenance graph; (initially, all of the processes that receive data from the initial infection points are tagged as suspicious.) 
Then, these tags are propagated to the nodes that receive data from these suspicious processes. 
Tags are thus propagated to all the entities that exist in the path. 
A tag propagation path only ends when: (1) a socket object is encountered, or (2) entities other than socket objects do not relay the data they receive.
Fig.~\ref{fig:graph_analyzer}b shows an example of tag propagation paths in the graph.
To formalize this propagation process, we define a tag propagation function $T: V \rightarrow {0,1}$ that marks vertices as suspicious:

\begin{equation}
T(v) =
\begin{cases}
1 & \text{if } v \in I \lor \left(\exists u \in V : (u,v) \in E \land \text{relaysData}(v)\right), \\
0 & \text{otherwise}
\end{cases}
\end{equation}

where $relaysData(v)$ is a Boolean function indicating whether vertex $v$ forwards its received data to other nodes, and $I$ is the set of all initial infection points.

\noindent\textit{(c) Pruning non-infected subgraphs.} After the tags have been propagated, the graph analyzer prunes all nodes that are not tagged and are therefore considered unimportant (illustrated in Fig.\ref{fig:graph_analyzer}c in which entities O3, O4, O5, O7, and O10 are removed).
Based on this pruning criteria, we can formally define the reduced graph $G_R = (V_R, E_R)$ as:

\begin{equation}
\begin{aligned}
V_R &= \{ v \in V \mid T(v) = 1\}, \\
E_R &= \{ (u, v) \in E \mid u, v \in V_R \}.
\end{aligned}
\end{equation}

\noindent\textit{(d) Community detection.} The Louvain algorithm is applied to the reduced graph, clustering related nodes into communities to identify groups of processes that may be working together in coordinated attack activities. We chose this algorithm since: (1) it efficiently handles large, high-dimensional graphs, (2) it is known for producing high-modularity partitions, and (3) prior studies have demonstrated its effectiveness in similar tasks~\cite{pei2016hercule}. 
This choice is further motivated by a key observation about APT behavior: attack-related activities typically form dense, interconnected communities within the provenance graph, with malicious processes exhibiting higher degrees of interaction among themselves than normal system processes, as demonstrated in~\cite{blondel2008fast}. 
By leveraging these behavioral patterns, the Louvain algorithm, combined with our temporal correlation engine, effectively identifies these related activities, revealing potential attack sequences that might otherwise remain hidden in the broader system activity.

\begin{figure}[ht]
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{0pt}
\centering
\includegraphics[width=\textwidth]{figures/graph}
\caption{Graph analyzer: Detection of infection points, followed by tag-propagation and iterative pruning of benign entities, resulting in a reduced graph structure optimized for further analysis.}
\label{fig:graph_analyzer}
\end{figure}

\noindent\textbf{LLM Analyzer.}
The LLM analyzer module constitutes the third module of the \method pipeline. 
Building on the communities identified by the graph analyzer, the LLM analyzer processes the system events corresponding to the community nodes to detect malicious behaviors. 
The LLM analyzer examines the relationships and temporal sequences of operations and determines whether an attack has been observed, provides a confidence score, and maps the malicious events to the corresponding stages of the kill chain. 
When the LLM concludes that the events in the communities are highly suspicious, the corresponding nodes in the reduced graph are tagged with the confidence score; the graph is then traversed and all of the traceable nodes (processes and objects) with their corresponding edges (events) are sent to the temporal correlation engine. 

\begin{figure}[!btp]
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{0pt}
\centering
\includegraphics[width=\textwidth]{figures/cot}
\caption{LLM analyzer: An illustration of the CoT reasoning.}
\label{fig:cot}
\end{figure}

\noindent The methodology adopts a three-stage chain-of-thought (CoT) reasoning framework to methodically analyze complex attack scenarios.
In the initial stage, the LLM leverages its internal knowledge to identify deviations from expected system behavior patterns, such as unauthorized file writes in sensitive directories, unexpected network connections, or abnormal process spawning. 
Processes exhibiting these suspicious activities or those that are unknown to the LLM are flagged for further investigation. 
In the second stage, the LLM analyzes the temporal sequence of actions associated with each flagged process, identifying suspicious patterns that could indicate compromise (e.g., a web server process making unexpected file system modifications or establishing unusual network connections).
Finally, in the third stage, the LLM investigates inter-process relationships in a community, highlighting patterns that suggest a cohesive attack summary. 
We formalize the method in an Algorithm in Appendix~\ref{app:algorithm}. An illustration of the analysis is depicted in Fig~\ref{fig:cot}. 

\noindent Following the multi-stage analysis, the LLM assigns confidence scores. Building on prior work showing LLMs perform better with rating scales than categorization~\cite{zhuang2024}, and leveraging Freitas et al.'s use of a 0.9 confidence threshold to forward effective responses~\cite{freitas2024}, we developed a confidence scoring mechanism. Our approach assigns confidence scores ($\sigma_a$) based on detected attack sequences: $\geq$0.9 for complete attack sequences, 0.8–0.9 for partial attack sequences, and 0.7–0.8 for detected suspicious patterns.

\method sets the alert threshold ($\delta$) at 0.8 to focus analyst attention on high-confidence detections of partial or complete attacks, filtering out lower-confidence findings that might lead to alert fatigue.
When ($\sigma_a \geq \delta$), the LLM returns a three-part response. 
First, it generates a comprehensive alert for security analysts, detailing the attack description, suspicious processes, sequence of events, and their mapping to kill chain stages. 
Second, it tags nodes ($Tag(c)$), marking all suspicious processes identified by the LLM within community $c$ with their respective confidence scores. 

\noindent Finally, by traversing the graph ($Trace(c)$), it examines the reduced graph $G_r$ from the graph analyzer module, propagating confidence scores to all nodes reachable from the tagged suspicious processes. If ($\sigma_a < \delta$), the system limits its response to tagging suspicious nodes and traversing the graph.
The response can be formalized as:
\begin{equation}
	Response(c, \sigma_a) = 
	\begin{cases}
		GenerateAlert(c) + Tag(c) + Trace(c) & \text{if } \sigma_a \geq \delta, \\
		Tag(c) + Trace(c) & \text{otherwise}.
	\end{cases}
\end{equation}
Tagged and traced nodes are collected to form an attack event set $T$ in tuple format $\{\, (p_i, e_i, o_i, t_i) \,\}$ and forwarded to the correlation engine, where $p_i$ represents the process identifier, $e_i$ the event type, $o_i$ the operation, and $t_i$ the timestamp.\\

\begin{figure}[!ht]
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{0pt}
\centering
\includegraphics[width=0.6\textwidth]{figures/llm}
\caption{LLM analyzer and temporal correlation engine: Analyzes system logs, tags malicious nodes, performs graph traversal, adds the tagged nodes to the attack set, and maintains historical context of attack evolution while considering memory constraints.}
\label{fig:llm_analyzer}
\end{figure}

\noindent\textbf{Temporal Correlation Engine.}
The temporal correlation engine serves as \method's orchestration module, managing both the prioritization of detected threats and the temporal aspects of long-term attack monitoring. 
It processes the attack set received from the LLM analyzer through two main mechanisms: dynamic set integration for threat assessment and rolling provenance updates for memory management.

\noindent\textit{(a) Dynamic set integration and risk stratification.} This process serves as the primary threat assessment mechanism by consolidating analysis results into a global attack set that tracks both ongoing and historical attacks. During this stage, behavioral correlation analysis leverages the confidence scores ($\sigma_a$) assigned by the LLM analyzer to identify related attack patterns, merging and filtering sets to consolidate partial APT activities into comprehensive attack chains, sorted by timestamps.
After merging, \method employs two core adjustment mechanisms that modify the initial LLM-assigned confidence scores: (1) Decay, which is applied when a tagged set continues to exhibit benign behavior over subsequent analysis windows. 
Without further suspicious activities supporting the initial classification, the confidence score gradually decreases. 
Once $\sigma_a$ falls below 0.7, the set is removed from active analysis and its nodes become eligible for pruning. (2) Reinforcement, which is activated when a set initially receives a lower confidence score (0.7 $\leq \sigma_a < 0.8$) due to early-stage attack indicators. As additional stages of the attack manifest in subsequent windows, the score increases proportionally, reflecting mounting evidence of malicious intent. This approach effectively identifies APTs that evolve slowly over time.

\noindent During set integration, \method maintains the same attack set structure $T$ and the confidence score threshold $\sigma_a$ (see LLM analyzer). 
The engine's queue management directly aligns with these thresholds: sets with $\sigma_a \geq 0.8$ enter the primary queue for immediate analyst attention, while those with $0.7 \leq \sigma_a < 0.8$ remain in the secondary queue for continued observation. 
\method continuously applies decay or reinforcement during subsequent integrations, adjusting confidence scores based on emerging evidence. 
This dual-queue prioritization process enables efficient allocation of analyst resources toward high-confidence attack chains while maintaining visibility of potentially developing threats.

\noindent\textit{(b) Rolling provenance graph updates.} \method implements a rolling provenance graph to manage memory usage when tracking long-term attacks. 
The graph continuously incorporates new process and event nodes from the system logs, with suspicious nodes being tagged with confidence scores by the LLM analyzer. 
For memory efficiency, \method removes untagged nodes after analyzing the time window $r$ and removes tagged nodes at regular intervals. % as mentioned in  paragraph ~\ref{para:decay}. 
This pruning is possible, because once suspicious activities are detected, their complete behavioral patterns and relationships are preserved in the attack sets $T$, making the actual graph nodes redundant after analysis. Through this efficient memory management technique, \method maintains comprehensive attack tracking capabilities for APTs while preventing unbounded graph growth. In Section~\ref{sec:discussion}, we present an example demonstrating how \method successfully identifies and tracks sophisticated attacks spanning multiple days.