\section{Evaluation Results}\label{sec:results}

\noindent\textbf{Performance Analysis of Deviation Analyzer.}
We start by evaluating the performance of the deviation analyzer, focusing on its detection capabilities and log reduction efficiency. 
The deviation analyzer demonstrates exceptional detection capabilities with 100\% recall on all datasets, successfully identifying every known attack event while maintaining a minimum log reduction of approximately 20 times across all datasets. 
Its adaptive thresholding mechanism (i.e., the contamination threshold) effectively distinguishes malicious patterns from benign system behaviors. 
The analyzer's efficiency in processing large-scale log data with minimal computational overhead makes it particularly valuable for real-time APT detection in enterprise environments. \\

\noindent\textbf{Performance Analysis of Graph Analyzer. }
Next, we examine the graph analyzer's effectiveness in preserving attack events while while significantly reducing the number of logs on diverse datasets. 
The graph analyzer demonstrates effective capabilities in preserving attack events while achieving significant log reduction on all datasets. 
We achieved a mean reduction of 95.58\% across the datasets, with standard deviations ranging from 1.98\% to 6.59\%, substantially reducing the computational overhead in analysis. 
In terms of recall, the analyzer maintains near-perfect attack event retention across datasets with rates consistently exceeding 99\%. 
This exceptional performance is demonstrated by minimal attack event loss - only three events across millions of log entries - showcasing the module's ability to preserve critical event information even in complex environments with diverse log patterns. 
These results suggest significant practical implications for large-scale security monitoring systems, where it can substantially reduce storage and processing requirements while maintaining comprehensive threat detection capabilities. \\

\noindent\textbf{Time Window-Based Performance Analysis of \method. }
Having established the effectiveness of two of the modules, we  evaluate \method's overall performance using a systematic time window-based approach. 
We employed a sliding window mechanism with 30-minute intervals and a 15-minute step size. 
This allowed for continuous monitoring and evaluation of system behavior. 
The CADETS dataset was divided into 714 windows, of which only 12 contained attack sequences, illustrating the imbalanced nature of the data. 
Similarly, the THEIA dataset comprised 303 windows, with nine containing attacks, reflecting a similar skew.
In addition, in this initial evaluation phase, we assessed several local language models. 
Among the candidates—Qwen 2.5, 
EXAONE 3.5, and LLama 3.1—Qwen 2.5 demonstrated superior and consistent performance on all datasets 
In Appendix ~\ref{app:model_eval} we provide detailed results of our comparative study for model selection. \\

\noindent\textbf{Event-Based Performance Analysis of \method. } 
While the window-based metrics provide a high-level view of \method's detection capabilities, a more granular event-based analysis is necessary to evaluate its practical utility for security operations. \method's primary objective is to alleviate the workload of security analysts. Instead of requiring analysts to perform extensive triage on large volumes of false positive alerts, \method automatically summarizes what it deems to be an attack, enabling analysts to quickly evaluate whether malicious activity is present in the system. Even in scenarios where alerts might be false positives, the consolidated summary containing IoCs can help analysts decide if further action is necessary. Since \method bases its summaries on identified attack events, it is critical to examine these events to understand the extent and accuracy of \method's detection capabilities.

\noindent Table~\ref{tab:attack_evaluation} highlights \method's capabilities on four diverse datasets. On the CADETS dataset, \method consistently demonstrates perfect precision coupled with high recall for all attacks. The method achieves perfect recall on the THEIA and Public Arena datasets, effectively detecting all attack events. For Blind Eagle, \method maintains high recall, underscoring its effectiveness in diverse environments and threat scenarios.

\begin{table}[ht]
\centering
\caption{Reduced Graph Metrics of \method: precision, recall, TP, FP, and FN across CADETS, THEIA, Public Arena, and Blind Eagle datasets.}
\label{tab:attack_evaluation}
\adjustbox{max width=0.99\textwidth}{%
\begin{tabular}{|l|c|c|c|c|c|c|}
\hline
\textbf{Dataset} & \textbf{Attack} & \textbf{TP} & \textbf{FP} & \textbf{FN} & \textbf{Precision} & \textbf{Recall} \\ 
\hline
\multirow{3}{*}{CADETS} 
    & Attack 1 & 13 & 0 & 1 & 1.00 & 0.93 \\ \cline{2-7}
    & Attack 2 & 25 & 0 & 2 & 1.00 & 0.93 \\ \cline{2-7}
    & Attack 3 & 19 & 0 & 1 & 1.00 & 0.95 \\ 
\hline
THEIA & Attack 1 & 32 & 47 & 0 & 0.40 & 1.00 \\ 
\hline
Public Arena & Attack 1 & 23 & 251 & 0 & 0.08 & 1.00 \\ 
\hline
Blind Eagle & Attack 1 & 31 & 35 & 5 & 0.46 & 0.86 \\ 
\hline
\end{tabular}
}
\end{table}

\noindent\textbf{Comparative Analysis.} We compare \method's performance for time-window based detection against state-of-the-art detection systems, including KAIROS, UNICORN, and DeepLog, on both the CADETS and THEIA datasets by adapting them to our time-window based approach. While Public Arena's parsers were unavailable and Blind Eagle's high-level log format was incompatible with provenance-based Intrusion Detection System, the comprehensive comparison on compatible datasets demonstrates \method's competitive performance on multiple key metrics, as summarized in Table~\ref{tab:performance-comparison}.

\begin{table}[ht]
\caption{Comparison of time-window based detection performance between  different methods on CADETS and THEIA datasets.}
\label{tab:performance-comparison}
\centering
\adjustbox{max width=0.99\textwidth}{%
\begin{tabular}{|l|l|c|cccc|ccc|}
\hline
\multirow{2}{*}{\textbf{Method}} & \multirow{2}{*}{\textbf{Dataset}} & 
\multirow{2}{*}{\textbf{Attack Identified}} & 
\multicolumn{4}{c|}{\textbf{Confusion Matrix}} & 
\multicolumn{3}{c|}{\textbf{Performance Metrics}} \\
\cline{4-10}
 & & & \textbf{TP} & \textbf{FN} & \textbf{FP} & \textbf{TN} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} \\
\hline
\multirow{2}{*}{SHIELD} 
  & CADETS & 3/3 & 7 & 5 & 17 & 685 & 0.29 & 0.58 & 0.39 \\
  & THEIA  & 2/2 & 6 & 3 & 4  & 290 & 0.60 & 0.67 & 0.63 \\
\hline
\multirow{2}{*}{KAIROS} 
  & CADETS & 2/3 & 9 & 3 & 10 & 692 & 0.64 & 0.75 & 0.69 \\
  & THEIA  & 2/2 & 5 & 4 & 11 & 283 & 0.31 & 0.55 & 0.40 \\
\hline
\multirow{2}{*}{Unicorn} 
  & CADETS & 3/3 & 4 & 8 & 28 & 674 & 0.13 & 0.33 & 0.18 \\
  & THEIA  & 2/2 & 4 & 5 & 23 & 271 & 0.15 & 0.44 & 0.22 \\
\hline
\multirow{2}{*}{DeepLog} 
  & CADETS & 3/3 & 9 & 3 & 683 & 19 & 0.01 & 0.75 & 0.03 \\
  & THEIA  & 2/2 & 4 & 5 & 60 & 234 & 0.06 & 0.44 & 0.11 \\
\hline
\end{tabular}
}
\end{table}

On the  CADETS dataset, \method successfully identified all attacks while maintaining balanced precision and recall metrics. Although KAIROS exhibited higher precision and recall, it failed to detect one attack, revealing a critical gap in coverage. UNICORN and DeepLog, while detecting all attacks, suffer from higher false positive rates. On THEIA, \method demonstrated superior performance, achieving the highest F1 Score among all evaluated approaches.

To further benchmark \method, we evaluated its event-based detection capabilities against other methods. Table~\ref{tab:method_comparison} presents a detailed comparison of \method, KAIROS, UNICORN, and DeepLog on the CADETS dataset. The results demonstrate \method's superior precision, maintaining perfect precision across all attacks while achieving consistently high recall. KAIROS exhibited mixed performance, achieving near-perfect recall but suffering from low precision and critically failing to detect an attack. In contrast, while UNICORN and DeepLog achieved high recall, they generated significant false positive alarms. \\

\begin{table}[!ht]
\centering
\caption{Comparison of event-level detection performance between  different methods on CADETS dataset.}
\label{tab:method_comparison}
\adjustbox{max width=0.99\textwidth}{%
\begin{tabular}{|l|c|c|c|c|c|c|}
\hline
\textbf{Method} & \textbf{Attack} & \textbf{TP} & \textbf{FP} & \textbf{FN} & \textbf{Precision} & \textbf{Recall} \\ 
\hline
\multirow{3}{*}{SHIELD} 
    & Attack 1 & 13 & 0 & 1 & 1.00 & 0.93 \\ \cline{2-7} 
    & Attack 2 & 25 & 0 & 2 & 1.00 & 0.93 \\ \cline{2-7}
    & Attack 3 & 19 & 0 & 1 & 1.00 & 0.95 \\ 
\hline
\multirow{3}{*}{KAIROS}
    & Attack 1 & 14 & 108 & 0 & 0.11 & 1.00 \\ \cline{2-7}
    & Attack 2 & 25 & 129 & 2 & 0.16 & 0.93 \\ \cline{2-7}
    & Attack 3 & \multicolumn{5}{c|}{Not detected} \\ 
\hline
\multirow{3}{*}{UNICORN}
    & Attack 1 & 14 & 3539 & 0 & 0.004 & 1.00 \\ \cline{2-7}
    & Attack 2 & 27 & 4561 & 0 & 0.006 & 1.00 \\ \cline{2-7}
    & Attack 3 & 20 & 3978 & 0 & 0.005 & 1.00 \\ 
\hline
\multirow{3}{*}{DeepLog}
    & Attack 1 & 6 & 3543 & 4 & 0.003 & 0.71 \\ \cline{2-7}
    & Attack 2 & 25 & 4561 & 2 & 0.005 & 0.93 \\ \cline{2-7}
    & Attack 3 & 11 & 3982 & 5 & 0.003 & 0.55 \\ 
\hline
\end{tabular}
}
\end{table}

\noindent\textbf{An Illustration of the Attack Summary Quality. }
While quantitative metrics (precision, recall etc.) demonstrate \method's detection efficacy, the system's ability to generate interpretable attack summaries is equally crucial. 
\method exhibits exceptional capabilities in generating comprehensive attack summaries that align with the cyber kill-chain framework. 
In Appendix~\ref{app:attack_summary}, we present the summary generated by \method for the THEIA dataset, which provides a detailed visualization of the complete attack progression. During the delivery phase, the system precisely identified shell code servers (\texttt{61.130.69.232} and \texttt{141.43.176.203}). It then accurately traced the exploitation chain through the firefox, clean, and profile processes. The analysis captured the installation of persistence mechanisms via \texttt{/etc/firefox/native-messaging-hosts/gtcache} and effectively tracked command and control (C2) activities. Additionally, \method identified potential data exfiltration patterns through the profile and mail processes, demonstrating its capability to trace the attack's impact comprehensively.
The aforementioned results substantiate \method's efficacy in generating detailed and structured attack summaries, accurately identifying crucial attack components across various stages of the kill chain.