\section{Introduction}

Advanced persistent threats (APTs) are becoming a growing concern for today's organizations due to their sophistication and stealth. 
The 2020 SolarWinds supply chain attack~\cite{lazarovitz2021deconstructing} in which attackers remained undetected for over nine months while compromising 18,000 organizations and major U.S. government agencies demonstrates the harm APTs can cause.
Another APT, APT-C-36 (Blind Eagle),\footnote{\small\url{https://www.trendmicro.com/en_us/research/21/i/apt-c-36-updates-its-long-term-spam-campaign-against-south-ameri.html}} has been actively targeting the financial and government sectors in South America since 2018, employing advanced social engineering and fileless malware techniques to evade detection while maintaining a long-term presence in compromised networks. These incidents, which show how APTs can persist undetected for long periods of time, highlight the urgent need for sophisticated detection approaches that can identify threats without overwhelming security analysts with false positives.

% current approaches
The analysis of system provenance data, which captures detailed relationships and interactions between processes, files, and network connections over time, has emerged as a promising approach for APT detection~\cite{zipperle2022provenance,inam2023sok}. 
By maintaining a comprehensive record of system activities and their dependencies, provenance data can expose subtle patterns and lateral movements characteristic of sophisticated attacks. 
Existing detection methods relied on expert-defined rules %and signatures 
to identify known attack patterns in provenance data~\cite{hossain2017sleuth,milajerdi2019holmes,hassan2020tactical,kurniawan2022krystal}. 
While effective against known threats, these rule-based approaches require constant updates and struggle with zero-day attacks. 
To address these limitations, researchers shifted toward machine learning-based anomaly detection methods that model normal system behavior to identify deviations. These approaches range from statistical analysis~\cite{hossain2017sleuth,hassan2019nodoze,wang2020you,kurniawan2022krystal,dong2023distdet,Li_2024} to deep learning models using path~\cite{du2017deeplog,zhang2019robust,guo2021logbert,alsaheel2021atlas} and graph-based architectures~\cite{han2020unicorn,wang2022threatrace,zengy2022shadewatcher,jia2023magic,yang2023prographer} for pattern recognition.

% limitations
However, current machine learning (ML) methods face two significant limitations. 
These methods require extensive training data and struggle to adapt to the dynamic nature of both system behaviors and evolving attack patterns, leading to a high rate of false positives. 
In addition, existing approaches for interpreting alerts rely on labeled training data, which are tedious to generate and quickly become outdated~\cite{alsaheel2021atlas,milajerdi2019holmes,hossain2017sleuth,hassan2020tactical}, or focus on ML explainability rather than the specific characteristics of attacks.

% llms for log analysis
Recent advances in large language models (LLMs) have introduced new capabilities for understanding and reasoning about complex system behaviors. 
These models, which have a remarkable ability to adapt to different contexts and provide logical explanations for their findings, could serve as the basis of new APT detection approaches, overcoming the shortcomings of existing approaches. 
However, LLMs also have two critical limitations. 
First, directly feeding raw system logs to LLMs is impractical and inefficient, requiring to provide them with pre-processed logs using traditional security analysis methods like anomaly detection. 
Second, LLMs are prone to hallucination, which can be addressed through multiple complementary techniques like prompt engineering, chain-of-thought reasoning, and validation checks.

% SHIELD intro
To address these challenges, we propose \method, a novel framework that combines unsupervised anomaly detection with language model reasoning for APT detection and investigation. 
Our framework accumulates system logs in a sliding window mechanism for analysis, while leveraging a temporal correlation engine to track the historical evolution of suspicious events to enable the detection of attacks spanning over a long period of time. 
The proposed short-window mechanism is critical for rapid threat identification, as it detects and responds to attacks with minimal latency. 
\method (1) employs statistical analysis to flag anomalous events; (2) constructs provenance graphs to determine relationships; (3) prunes benign activities; and (4) clusters suspicious events using community detection algorithms. 
These steps reduce large amounts of system events to concise groups of suspicious activities, preserving significant attack patterns. 
An LLM then performs multi-stage reasoning on the identified clusters, providing interpretable insights and mapping them to the APT kill chain. 

The temporal correlation engine continuously compares new alerts with historical events. 
It employs dynamic confidence scoring using decay and reinforcement mechanisms. 
The decay mechanism lowers the confidence score if flagged processes consistently exhibit benign behavior, while the reinforcement mechanism increases scores as additional attack stages are detected across time windows. 
This dual-mechanism approach maintains a comprehensive view of slow-evolving attacks while preserving real-time detection capabilities and ensuring low false positive rates. 
Unlike existing approaches that focus solely on anomaly or rule-based detection, \method combines these techniques with LLM-based reasoning to bridge the gap between detection and actionable security insights.

% validation
We evaluate \method on four diverse datasets: the DARPA Eng. 3 CADETS and THEIA datasets,\footnote{\scriptsize\url{https://github.com/darpa-
i2o/Transparent-Computing}} the Public Arena dataset\footnote{\scriptsize\url{https://github.com/security0528/PublicArena}}, and an in-house dataset containing the Blind Eagle APT-C-36 campaign. 
Using only 30\% of each dataset for training, \method achieved perfect precision on the CADETS dataset and maintained high recall (0.93-1.00) across all datasets. 
\method successfully tracked attacks spanning multiple days, with detailed attack narratives mapping precisely to APT stages from initial compromise through lateral movement and data exfiltration. 
Most notably, when analyzing the key CADETS attack sequence, \method identified 25 true positive events with zero false positives, while baseline methods generated over 4000 false events requiring analyst investigation.

% contribution
The key contributions of this work can be summarized as follows:
(1) To the best of our knowledge, we are the first to use LLMs for APT detection and investigation. 
By integrating LLM reasoning with traditional security analysis, our framework achieves high detection accuracy while minimizing false alarms.
(2) We developed a novel engine that can track attacks spanning over a long time period using dynamic confidence scoring with reinforcement and decay mechanisms, effectively identifying slow-evolving, stealth attacks.   
(3) We designed a novel framework capable of generating human-interpretable, comprehensive attack summaries that maps attack events to kill-chain stages. 
These summaries, enriched with relevant IoCs, enable security teams to quickly analyze and respond to potential threats.
(4) We leverage the capabilities of off-the-shelf LLMs, eliminating the need for traditional model training. 
Unlike deep learning-based methods, that suffer from concept drift, our system maintains adaptability through prompt-based contextualization of organizational changes.
    
%\end{enumerate}