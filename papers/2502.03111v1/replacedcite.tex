\section{Related Work}
%\fs{Maybe we can shorten by not talking so much about abstractive vs extractive?}

Meeting summarization has been studied for decades, with most pre-neural network approaches focusing on extractive summarization ____. While extractive summaries can be perfectly adequate for some domains like news ____, humans tend to prefer abstractive summaries ____ and most current research is focused on generative (neural) abstractive summarization models ____.

Research into abstractive meeting summarization has largely focused on neural methods, with work largely progressing in two complementary directions, both attempting to cope with the challenge of long inputs: 1) extending the transformer ____ architecture to scale to longer inputs, usually using a sparse attention paradigm ____ or a hierarchical representation approach ____. And 2) divide-and-conquer approaches that perform a segmentation on the source and use conventional summarization systems on the segments, sometimes with an additional refinement step on the segment summaries ____. The best summaries are currently obtained by Large Language Models (LLMs) producing abstractive summaries ____. %\mt{[This last sentence is a bit ambiguous because it is not clear if you refer to the best extractive/abstractive/direction1/direction2 approach.]}

Online summarization has largely been studied in the context of stream summarization and video summarization ____. In stream summarization, it is assumed that a large volume of content (usually tweets or news articles) is being generated all the time and the task is to summarize available content or sentiment on a given topic from this stream at a given time.
%The concept of latency is not usually discussed in this context\mt{why? Answering can help to highlight the difference with our scenario}.
The primary concern of these systems is to produce a summary of past content on demand, not to respond to new content in a timely fashion. As a result, the concept of latency is not usually discussed in this context.
Typical approaches include performing document retrieval as a summary ____ and constructing a language model from the content stream and generating a representative example as a summary ____. Both require orders of magnitude more content than is available in a typical meeting and cannot be applied to meeting summaries.

Video summarization is the task of selecting representative frames or sequences from a video to form a summary ____. While online systems exist ____, they are very specific to video and exclusively produce extractive summaries. Moreover, there exists, to our knowledge, no study of latency (how soon after the occurrence is a summary available) in this task.

%\mt{I guess it is missing a sentence that wraps up the fact that neither the approaches nor the evaluation protocols mentioned in these papers can be added to our scenario.}

In summary, while there are systems that perform summarization in an online fashion, their approaches and evaluation schemes are not suitable for our task.

%fs{I don't think we need to justify our use of ROUGE or our human eval criteria, I'm dropping this part.}

% An important aspect of the research on summarization is the evaluation of summary quality. ROUGE ____ remains the most widely used metric for automatically judging quality, despite criticism ____. In human evaluation, summaries are usually evaluated in some variation of adequacy (coverage and accurate representation of all important content), fluency (readability of the text), and relevance (covering only important content, ____), but there are no studies of intermediate summaries produced by online systems.