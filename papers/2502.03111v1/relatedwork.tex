\section{Related Work}
%\fs{Maybe we can shorten by not talking so much about abstractive vs extractive?}

Meeting summarization has been studied for decades, with most pre-neural network approaches focusing on extractive summarization \citep{waibel1998meeting,zechner2002automatic,tur2008calo,garg2009clusterrank,tixier2017combining}. While extractive summaries can be perfectly adequate for some domains like news \citep{zhong2020extractive}, humans tend to prefer abstractive summaries \citep{murray2010generating,zhang2023benchmarking} and most current research is focused on generative (neural) abstractive summarization models \citep{zhu2020hierarchical,fabbri2021convosumm,zhang2022summn}.

Research into abstractive meeting summarization has largely focused on neural methods, with work largely progressing in two complementary directions, both attempting to cope with the challenge of long inputs: 1) extending the transformer \citep{vaswani2017attention} architecture to scale to longer inputs, usually using a sparse attention paradigm \citep{brown2020language,fabbri2021convosumm,zhong2022dialoglm} or a hierarchical representation approach \citep{zhu2020hierarchical}. And 2) divide-and-conquer approaches that perform a segmentation on the source and use conventional summarization systems on the segments, sometimes with an additional refinement step on the segment summaries \citep{zhang2022summn,asi2022end,liu2022dynamic}. The best summaries are currently obtained by Large Language Models (LLMs) producing abstractive summaries \citep{zhang2023benchmarking}. %\mt{[This last sentence is a bit ambiguous because it is not clear if you refer to the best extractive/abstractive/direction1/direction2 approach.]}

Online summarization has largely been studied in the context of stream summarization and video summarization \citep{sequiera2018overview}. In stream summarization, it is assumed that a large volume of content (usually tweets or news articles) is being generated all the time and the task is to summarize available content or sentiment on a given topic from this stream at a given time.
%The concept of latency is not usually discussed in this context\mt{why? Answering can help to highlight the difference with our scenario}.
The primary concern of these systems is to produce a summary of past content on demand, not to respond to new content in a timely fashion. As a result, the concept of latency is not usually discussed in this context.
Typical approaches include performing document retrieval as a summary \citep{ge2016news} and constructing a language model from the content stream and generating a representative example as a summary \citep{olariu2014efficient}. Both require orders of magnitude more content than is available in a typical meeting and cannot be applied to meeting summaries.

Video summarization is the task of selecting representative frames or sequences from a video to form a summary \citep{apostolidis2021video}. While online systems exist \citep{lal2019online,zhao2014quasi}, they are very specific to video and exclusively produce extractive summaries. Moreover, there exists, to our knowledge, no study of latency (how soon after the occurrence is a summary available) in this task.

%\mt{I guess it is missing a sentence that wraps up the fact that neither the approaches nor the evaluation protocols mentioned in these papers can be added to our scenario.}

In summary, while there are systems that perform summarization in an online fashion, their approaches and evaluation schemes are not suitable for our task.

%fs{I don't think we need to justify our use of ROUGE or our human eval criteria, I'm dropping this part.}

% An important aspect of the research on summarization is the evaluation of summary quality. ROUGE \citep{lin2004rouge} remains the most widely used metric for automatically judging quality, despite criticism \citep{akter-etal-2022-revisiting}. In human evaluation, summaries are usually evaluated in some variation of adequacy (coverage and accurate representation of all important content), fluency (readability of the text), and relevance (covering only important content, \citealt{fabbri2021summeval,ghosal-etal-2023-overview}), but there are no studies of intermediate summaries produced by online systems.