\section{Related Works}
\subsection{LLMs for Code Domain.}
Large language models have been widely applied to coding tasks and have shown strong performance across various coding scenarios and evaluations. Most existing research focuses on code generation, with numerous techniques developed to enhance its quality. Some methods aim to improve the quality of synthetic code data \cite{wei2024magicoder, luo2024wizardcoder, lei2024autocoder}, enhance self-consistency \cite{le2024codechain, huang-etal-2024-enhancing}, or leverage feedback from human or LLM annotations \cite{chen2024improvingcodegenerationtraining, wu2023finegrained, tang-etal-2023-explain}. Other approaches utilize multi-agent collaboration frameworks to enhance code generation \cite{zhong2024debug, shinn2023reflexion, islam-etal-2024-mapcoder, madaan2023selfrefine, li2024codetreeagentguidedtreesearch}. However, these methods primarily focus on the correctness of the generated code, with relatively little emphasis on the efficiency of the generated code.

\subsection{Code Efficiency.}
Until recently, the academic community has only begun to pay significant attention to the efficiency of generated code. Recently, several efficiency-focused benchmarks \cite{EffiBench, du2024mercury, liu2024evaluatinglanguagemodelsefficient, qiu2024efficientllmgeneratedcoderigorous} have emerged, aiming to provide a more comprehensive evaluation of LLMsâ€™ ability to generate efficient code. However, empirical studies and evaluations of these benchmarks show that current LLMs still face significant challenges in generating efficient code. To improve code efficiency, recent research such as ECCO \cite{waghjale-etal-2024-ecco} adopts self-refinement, prompting LLMs to consider possible optimization strategies and refine their outputs. Effi-Learner \cite{EffiLearner} proposes a self-optimization framework that uses execution overhead profiles, feeding them back into the LLM to revise the code and reduce time overhead. However, these methods focus on enhancing the efficiency of code after it has been generated, rather than starting with the goal of generating both efficient and correct code from the beginning.