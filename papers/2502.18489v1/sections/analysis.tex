\section{Deeper Analysis}
\subsection{\tool Uniqueness Analysis.}
As mentioned in the Introduction, \tool has two distinct features: \textbf{\underline{Uniqueness 1:}} Separation of Efficiency Optimization into Logic and Code Domains, and \textbf{\underline{Uniqueness 2:}} The Order of Correctness and Efficiency. 
To gain a deeper understanding of these unique advantages, we conducted the following comparative experiments:
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=0pt,parsep=0pt]
    \item \textbf{w/o Uniqueness-1:} Rather than separating efficiency optimization into the logic and code domains, we prompt the LLM to generate code that is both efficient and correct. Then, based on the formalized task and the generated code, the LLM is queried to suggest any possible strategies for optimizing efficiency. Subsequently, we optimize the generated code according to these strategies, with the following steps remaining the same as in \tool. It is important to note that the difference between \textbf{w/o Uniqueness-1} and ECCO lies in the fact that ECCO provides correctness or efficiency strategies solely based on the code, whereas \textbf{w/o Uniqueness-1} generates efficiency-focused strategies based on both the formalized task and the generated code, followed by refinement for correctness.
    \item \textbf{w/o Uniqueness-2:} We changed the priority sequence of correctness and efficiency. In this approach, we first generate the code based on the formalized task and refine it for correctness. Then, we conduct algorithm exploration and implement optimal methods based on the formalized task and the refined code. Finally, we optimize the code using the explored algorithms and implementation suggestions.
\end{itemize}
The results of the uniqueness study are presented in Table \ref{tab:special_results}. As shown, in the absence of \textbf{Uniqueness-1}, the performance of Qwen2.5-Coder-32B-Instruct on Mercury showed a slight increase in Pass@1, but in other cases, the performance declined, particularly in terms of DPS\_norm on EvalPerf and eff@1 on ENAMEL. This underscores the importance of separating efficiency optimization into the logic and code domains. This separation effectively breaks down the challenge of optimizing code efficiency into manageable steps, making the overall optimization process more focused and targeted. On the other hand, in the absence of \textbf{Uniqueness-2}, both efficiency and correctness saw significant declines across all benchmarks and different LLM backbones. The main reason for this is that optimizing correctness before efficiency limits the LLM’s ability to explore efficient algorithms and practical optimizations. In fact, this approach often backfires, resulting in a situation where code correctness is sacrificed in the pursuit of efficiency. These findings further validate the "efficiency-first, correctness-later" strategy as a crucial approach for generating both efficient and correct code.

\begin{figure}
    \centering
    \includegraphics[width=0.50\textwidth]{figures/mercury.pdf}
    \caption{The Beyond@1 performance of \tool on tasks of varying difficulty levels in Mercury, with DeepSeek-V3 as the backbone.}
    \label{fig:Mercury}
\end{figure}

\subsection{Performance of Different Difficulty Levels.}
To evaluate the performance of \tool on tasks of varying difficulty levels, we conducted an analysis across three levels—Easy, Medium, and Hard—using Mercury with DeepSeek-V3 as the backbone. The results are shown in Figure \ref{fig:Mercury}. \tool consistently achieves the highest Beyond@1 metrics, outperforming other methods across tasks ranging from easy to difficult. This robust performance highlights the \tool’s effectiveness in tackling a broad spectrum of challenges. Additionally, we observed a significant drop in performance for ECCO on hard-level tasks. This decline is mainly due to the difficulty of providing valid optimization suggestions for complex code, a challenge that remains substantial for LLMs.

\subsection{Case Study.}
To provide a more intuitive demonstration of \tool, we conducted a case study, with the process detailed in Appendix \ref{appendix-casestudy}. It can be observed that methods like ECCO and Effi-Learner, which generate code first and then optimize for efficiency, are constrained by the algorithmic design and overall structure of the initial code, leading to only incremental improvements. In contrast, \tool breaks free from these constraints, enabling it to fully explore more efficient algorithms at a high level based on the task, while also incorporating practical level efficiency optimizations, thus achieving more effective efficiency optimization.