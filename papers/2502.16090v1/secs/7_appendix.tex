\appendix

\section{Implementation Details of MADGF}

\subsection{Plots used in Human Prompt Template}
\label{sec:plotsforhuman}

Table \ref{tab:humanplots} presents the plots used in the human prompt template. It includes 20 plots, with the numbers of \colorbox{wkblue}{true episodic memories} and  \colorbox{wkred}{hallucinatory episodic memories} marked in blue and red, respectively. The final plot is fixed as "say goodbye" to guide the conclusion of the conversation.

\input{tabs/plotsforhuman}


\subsection{Hallucinatory Plots used in Assistant Prompt Template}
\label{sec:hplotsforassist}

Table \ref{tab:assistplots1} provides an example of hallucinatory plots used in the assistant prompt template, aimed at guiding the assistant to avoid hallucination issues. The example includes four memories that did not occur in actual conversations, corresponding to the plots marked in red (\colorbox{wkred}{8, 10, 18}, and \colorbox{wkred}{19}) in Table \ref{tab:humanplots}.

\input{tabs/hplotsforassist}


\subsection{Common Plots used in Assistant Prompt Template}
\label{sec:cplotsforassist}

The common plots designed to prompt the AI assistant to proactively seek relevant information in a human-like manner. One example is "name, old, hobby, gender".

% Table \ref{tab:assistplots2} provides an example of common plots designed to prompt the AI assistant to proactively seek relevant information The in a human-like manner. An 

% \input{tabs/cplotsforassist}



\section{Extended Experiments on Temporal Awareness and Reasoning Capability of the Model}

To enhance and evaluate the temporal awareness and reasoning capabilities of the model, we have developed temporally aware and reasoning-enhanced training and testing datasets. We then conducted both quantitative and qualitative experimental analyses of Echo.
\vspace{-2mm}

\subsection{Temporal Reasoning Dataset}

\paragraph{Training Dataset}
We improved upon a portion of the training set proposed by Tan et.al \cite{tan2023towards} to create a dataset that emphasizes temporal awareness and reasoning. In the work by Tan et.al \cite{tan2023towards}, the data were entirely synthesized programmatically, with questions being relatively simplistic, lacking inquiries about specific days of the week or recent dates. Utilizing both programming techniques and manual annotations, we constructed an 8K training dataset. The data format adheres to Echo's training paradigm of user-time-assistant, making it highly suitable for Echo model training. Table \ref{tab:time_train} provides examples from our training dataset, which includes various complex scenarios for temporal reasoning questions, aiding in developing Echo's robust temporal awareness and reasoning skills after training.
\vspace{-3mm}

\input{tabs/time_train}

\paragraph{Evaluation Dataset}
We manually annotated a temporally aware and reasoning-enhanced evaluation dataset consisting of 292 instances, including 32 short-term (within one week) and 260 long-term test questions, as shown in Table \ref{tab:etime_test}. Each test question provides all possible keywords contained in the standard answer, allowing for accurate quantitative analysis of whether the model's output is correct through string matching.

\vspace{-3mm}

\input{tabs/time_test}


\subsection{Quantitative Analysis of Temporal Perception and Reasoning Ability}

On the Evaluation Dataset for Temporal Reasoning, we conducted a quantitative analysis. As in Section \ref{sec:experiment}, we selected LLAMA3-8b \cite{dubey2024llama} and ChatGLM3-6B \cite{glm2024chatglm} for open-source models, and for closed-source models, we employed GPT-3.5-turbo \cite{openai2023gpt4}, GPT-4 \cite{openai2023gpt4}, and ChatGLM3-turbo \cite{glm2024chatglm} for evaluation and comparison. When calculating the metrics, we detected keywords within the models' responses.

As shown in Table \ref{table:exp3}, we found that our Echo model still performs the best, with time-aware and reasoning abilities exceeding 90 in both short-term (98.1) and long-term (94.6) scenarios. In contrast, ChatGLM3-6B performed very poorly, with time-aware and reasoning abilities below 10 in both short-term (9.4) and long-term (8.8) scenarios. This indicates that the EM-Train dataset significantly improves the time-aware and reasoning capabilities of the models. Additionally, we observed that GPT-4 achieved suboptimal performance on long-term tests, but did not achieve suboptimal performance on short-term tests. Upon examining the model's outputs, we noticed that GPT-4 tends to produce errors and hallucinations in short-term temporal reasoning. For example, the correct answer was "The date the day before yesterday was July 1st, 2023.", but GPT-4's output was "The day before yesterday would have been July 2, 2023.".
 
% As shown in Table \ref{table:exp3}, we found that our Echo model still performs the best, with time-aware and reasoning abilities exceeding 90 in both short-term (98.1) and long-term (94.6) scenarios. In contrast, ChatGLM3-6B performed very poorly, with time-aware and reasoning abilities below 10 in both short-term (9.4) and long-term (8.8) scenarios. This indicates that the EM-Train dataset significantly improves the time-aware and reasoning capabilities of the models. "The date the day before yesterday was July 1st, 2023.","The day before yesterday would have been July 2, 2023."


% We tested the time-aware and reasoning capabilities of the models, as shown in Table \ref{table:exp3}. We found that our Echo model still performs the best, with time-aware and reasoning abilities exceeding 90 in both short-term (98.1) and long-term (94.6) scenarios. In contrast, ChatGLM3-6B performed very poorly, with time-aware and reasoning abilities below 10 in both short-term (9.4) and long-term (8.8) scenarios. This indicates that the EM-Train dataset significantly improves the time-aware and reasoning capabilities of the models.
\input{tabs/exp3}


\subsection{Qualitative Analysis of Temporal Perception and Reasoning Ability}

We present the qualitative analysis results of Echo in Figure \ref{fig:exp-demo3}. It is evident that the model can perceive the current time and perform reasoning tasks, such as correctly answering questions about the current season and how many years have passed since the first moon landing. Additionally, the model can also perceive and reason about past and future times. For example, it accurately answered questions about what the date will be 100 years and 20 years from now, how long until November, and how much time has passed since the first chat session.

\begin{figure*}[h]
\centering

\includegraphics[width=.9\linewidth]{figure/exp-demo3.pdf} \\

\caption{Examples of time perception and reasoning ability in the Echo.}
\label{fig:exp-demo3}
% \vspace{-1mm}
\end{figure*}



