\section{Dataset}

\subsection{EM-Train and Training Paradigm}
Based on MADGF in Section \ref{sec:approach}, we collected and created EM-Train. It consists of 15, 533 data entries, with an average of 16.75 conversation rounds per data entry and an average length of 8, 597 characters. Then, we trained the Echo model using the EM-Train dataset.

Compared to the conventional LLM training paradigm (user-assistant), we modified the training paradigm to user-time-assistant. As shown in Figure \ref{fig:paradigm} (a), in traditional LLMs, the chat template for instruction fine-tuning alternates between two roles: user and assistant. In our modified approach, as highlighted in red in Figure \ref{fig:paradigm} (b), we introduced an additional role, "observation," which includes temporal information. During training, the content of the observation does not participate in gradient updates, and the attention mask remains consistent with the traditional decoder-only method. During inference, whenever a user inputs a prompt, real-time information is automatically integrated into the context, enabling the creation of a time-aware AI assistant.

% \input{tabs/em_train}

% Then, we trained the Echo model using EM-Train. Compared to the conventional LLM training paradigm (user-assistant), we modified the training paradigm to user-time-assistant. This modification enables the model to better understand "what happened when". Figure \ref{fig:paradigm} illustrates the changes in the training paradigm, with the added time information highlighted in red.

%讲下训练标签label的变化，Figure \ref{fig:paradigm},没有梯度更新

\begin{figure}[h]
\centering

\includegraphics[width=.9\linewidth]{figure/paradigm.pdf} \\

\caption{Illustration of training paradigm changes.}
\label{fig:paradigm}
\vspace{-1mm}
\end{figure}

\begin{figure}[h]
\centering

\includegraphics[width=.9\linewidth]{figure/em_test.pdf} \\

\caption{Example of hard-level test point in EM-Test.}
\label{fig:em_test}
\vspace{-8mm}
\end{figure}

\subsection{EM-Test}

We manually developed a benchmark called EM-Test for evaluating the episodic memory of LLMs. Each test instance consists of multi-turn dialogues. In addition to dialogues that are not directly related to episodic memory testing, these dialogues may include multiple related historical dialogues and a corresponding test point, as shown in Figure \ref{fig:em_test}. At each test point, we annotate the test question (Question), the temporal context (Observation), and the reference answer (Reference Answer).

During testing, we provide all historical dialogues as conversation history to the model. Then, we input the test question and the temporal context to obtain the model's output. The model's output is either manually scored or compared against the reference answer to quantitatively evaluate the episodic memory capabilities of the LLMs.

We labeled the time span and difficulty of the test points to achieve more granular results. In terms of time span, we categorized them into eight types based on the required duration of episodic memory for answering questions: "just now," "one day," "few days," "one month," "few months," "one year," "few years," and "several decades." We also divided the difficulty of test points into easy and hard levels. For an easy-level test point, the model only needs to recall a simple scenario. For a hard-level test point, the model must possess complex episodic memory capabilities. Figure \ref{fig:em_test} provides an example of a hard-level test point. In this example, to answer “Did I take any days off from school this year?”, the model needs to recall writing a leave note for the user and the timing of that event being in the same year as the current one, to deduce the correct answer.

Additionally, we manually created the EM-Test-Without-Time scenario test set to evaluate the model's episodic memory ability without considering time information. Compared to EM-Test, EM-Test-Without-Time does not include temporal context and only considers easy and hard difficulty levels. Table \ref{tab:em_test} presents the relevant statistical information for both EM-Test and EM-Test-Without-Time.


\input{tabs/em_test}