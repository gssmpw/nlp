\begin{figure}[t!]
  \vspace{-2mm}
    \includegraphics[width=0.5\textwidth]{figure/radar_echo.pdf}
    \vspace{-6mm}
    \caption{The performance of LLMs across 7 time spans and and two difficulty levels in our EM-Test.}
    \label{fig:performance_llm}
    \vspace{-3mm}
\end{figure}

\section{Introduction}
\label{sec:intro}

Research on large language models (LLMs) has made significant advances in many fields \cite{naveed2023comprehensive,zhao2023survey}, such as mathematical problem \cite{liu2023mathematical}, programming \cite{zhang2023unifying}, and tool usage \cite{qin2024toollearningfoundationmodels}. However, these tasks primarily rely on semantic memory, with little focus on evaluating and enhancing the LLMs' episodic memory capabilities.

\begin{figure}[t!]
\centering

\includegraphics[width=.8\linewidth]{figure/em.pdf} \\
\vspace{1mm}
\caption{The relationship between episodic memory and long-term memory \cite{squire2004memory}.}
\label{fig:em}
\vspace{-5mm}
\end{figure}

Episodic memory is a crucial component of human memory \cite{tulving1983elements,tulving1972episodic}. As shown in Fig.~\ref{fig:em}, long-term memory \cite{squire2004memory} is mainly divided into declarative and non-declarative memory. Declarative memory further comprises semantic memory and episodic memory. Semantic memory involves the recollection of widely accepted concrete facts, which relate to knowledge independent of its context of acquisition \cite{moscovitch2016episodic}. It includes world knowledge, entity memory, language memory, and concept memory, among others. For example, "China is in Asia" or "1+2=3". In contrast, episodic memory refers to time-related event memories centered around the individual, such as "Last night, I bought tomatoes at Walmart".
In fact, episodic memory is not only a fundamental ability of humans but also a critical capability for LLMs, impacting their performance in any multi-turn Q\&A scenarios, such as role-playing \cite{wang2023rolellm}, psychological counseling \cite{ke2024exploring}, and AI teaching \cite{dan2023educhat}. Unfortunately, even the most advanced models (e.g., GPT-4) still perform poorly in terms of episodic memory, often suffering from logical inconsistencies and hallucinations. 
% Fig.~\ref{fig:em} provides examples of GPT-4o's subpar episodic memory performance in real-world scenarios. Example 1 illustrates a logical issue, while Example 2 highlights a hallucination problem.


Some methods \cite{zhong2024memorybank,barmann2024episodic,fountas2024human,packer2023memgpt,gao2024memory,hu2023chatdb} have been proposed to enhance the long-term memory capabilities of LLMs. These methods primarily use external storage to retain historical records and design operations to help LLMs retrieve this information for responses. However, these approaches can be time-consuming due to the operations on external storage, and context information may be arbitrarily segmented, leading to information loss. Additionally, these methods do not improve the model's inherent ability to process episodic memory. Episodic memory is thought to be constructive, meaning recall is the (re)construction of a past experience rather than the retrieval of a copy \cite{sprott1933remembering,schacter2012constructive}.

In practice, generative models have an inherent capability to construct and consolidate memories \cite{spens2024generative}. We argue that LLMs face a significant challenge in developing robust episodic memory capabilities due to the limited availability of high-quality episodic memory data. Such data is essential for training models to effectively handle complex, context-dependent interactions.

% In practice, generative models have the natural ability to construct and consolidate memories \cite{spens2024generative}. Our perspective is that LLMs encounter a challenge due to the scarcity of high-quality episodic memory dialogue data, which is necessary to achieve strong episodic memory capabilities.
% Generative models, on the other hand, do not require additional computational overhead to process historical records and have the natural ability to construct and consolidate memories \cite{spens2024generative}. However, generative models face the challenge of a lack of high-quality episodic memory dialogue data to achieve strong episodic memory capabilities.

First, we propose MADGF, a innovative Multi-Agent Data Generation Framework. MADGF simulates and controls multi-turn scenario dialogues between multiple human roles and an AI assistant. The collected dialogue data, named EM-Train, is used to train our Echo model.
In MADGF, three key components are designed: characters, plots, and environments. The design of characters and environments ensures a diverse range of dialogues, while plots guide the LLM to generate dialogue data with enhanced episodic memory capabilities. Additionally, the LLM's training paradigm is modified by incorporating temporal information into each conversation, enriching the temporal background in the interaction process.
% We fristly propose a novel Multi-Agent Data Generation Framework (MADGF). MADGF simulates and controls multi-turn scenario dialogues between multiple human characters and the AI assistant. The collected dialogue data, EM-Train, is used to train the our Echo model. In MADGF, we design three key elements: characters, scenarios, and environments. We first generate a large number of character profiles, each with personalized attributes such as name, hobbies, and social relationships, ensuring a wide variety of random human characters. Then, we design a rich repository of scenarios and use automation to form complex scenario chains. These scenario chains guide the LLM to transcend itself and generate dialogue data with stronger episodic memory capabilities. We incorporate time information into the environments, adding this information to each conversation to help the model understand "what happened when," aligning with the principle that time and events are inseparable in episodic memory \cite{roseboom2019activity,sherman2022trial}. Finally, under the guidance and control of the scenario chains, each character engages in lengthy conversations with an AI assistant named Echo, generating the EM-Train data. Additionally, we modify the training paradigm of the Echo model by incorporating time information into each conversation.

Next, we introduce EM-Test, a novel multi-turn dialogue benchmark designed to evaluate episodic memory capabilities. Each instance in EM-Test may contain multiple evaluation points, requiring the model not only to process long-context text effectively but also to recall, reason, and cognitively handle episodic memory information. Each evaluation point is tagged with both time and difficulty levels, enabling a comprehensive assessment.
To reduce manual evaluation efforts, we propose an approach that assesses model performance based on semantic similarity. The feasibility and effectiveness of approach is validated by its strong correlation with human evaluations.
% We introduce the EM-Test, a novel multi-turn dialogue benchmark designed to evaluate episodic memory capabilities. Each test case may contain multiple evaluation points, requiring the model to not only process long-context text effectively but also to recall, reason, and cognitively handle episodic memory information. Additionally, each evaluation point is tagged with both time and difficulty levels, providing a more comprehensive assessment from various perspectives.
% To reduce the need for manual evaluation, we propose a method that assesses model performance based on semantic similarity. The feasibility and effectiveness of this testing method are validated by demonstrating a strong correlation between its results and those obtained from human evaluations.
% To evaluate episodic memory capabilities, we propose an EM-Test. To our knowledge, EM-Test is the first multi-turn dialogue evaluation set where each turn of dialogue may contain multiple test points. EM-Test considers both time and difficulty dimensions. We categorize the time span of test point questions into eight types, ranging from "just now" to "several decades," allowing us to test the performance of LLMs across different time spans. Additionally, we classify the difficulty of test points into easy and difficult levels. We propose a new method for testing LLMs that achieves automatic scoring using semantic similarity. The feasibility of this testing method is validated by comparing it with human evaluation results.

Finally, we conducted both quantitative and qualitative experiments. The quantitative results show that Echo significantly outperforms state-of-the-art LLMs on the EM-Test. Additionally, the qualitative analysis reveals Echo's potential to exhibit human-like episodic memory capabilities.
% In sum, our research provides a preliminary exploration for LLMs to acquire episodic memory capabilities. 
% Our MADGF, EM-data, and Echo model are open-sourced at https://github.com/1920993165/echo.

