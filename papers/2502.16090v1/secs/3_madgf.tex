% \section{\rev{Improved Baselines of LLaVA}}
\section{Mutil-Agent Data Generation Framework}
\label{sec:approach}

The purpose of the Multi-Agent Data Generation Framework (MADGF) is to design multiple human characters interacting with an AI assistant. Through simulating daily conversations, a large multi-turn dialogue dataset enriched with episodic memories is collected for the training of the Echo model. To enhance the diversity and effectiveness of the conversation content, we initially devised three key elements: characters, plots, and environments. Extensive character cards, plots, and temporal information were then generated. Subsequently, we formulated a data generation process that utilizes this information to guide the LLM in producing high-quality episodic memory data (EM-Train).


\subsection{Characters, plots, and Environments}
\label{sec:three key}
\paragraph{Characters}
As illustrated in Figure \ref{fig:character}, the design of character cards encompasses seven attributes: "Name," "Occupation," "Age," "Gender," "Hobbies," "Personality," and "Social Relationships." Specifically, we randomly generated attribute values for all attributes except for "Social Relationships." Subsequently, we utilized the LLM to generate the "Social Relationships" attribute values based on the other six attributes. 


\begin{figure}[t!]
\centering

\includegraphics[width=.85\linewidth]{figure/character.pdf} \\

\caption{Example of character card.}
\label{fig:character}
% \vspace{-1mm}
\end{figure}

\paragraph{Plots}
The plots generated by LLMs differ significantly from actual real-life scenarios. Therefore, we manually created an event library, from which 20 events are sampled to form a plot. The library contains three types of events: common events, real events, and hallucinatory events. Common events are designed to enable the model to generate data based on semantic memory questions and answers while enriching the context. They include routine occurrences in daily life, such as greetings, inquiries about common knowledge, and discussions about career-related issues. Real events are events that have actually occurred and are related to episodic memory. They are used to prompt the human role to ask the Echo assistant if it remembers a related event. Hallucinatory events are fabricated events that have never occurred. They are used to prompt the human agent to ask the AI assistant about non-existent events and simultaneously remind the AI assistant not to be misled. Notably, since all event prompts are removed during the training of the Echo model, hallucinatory events help reduce the LLM's tendency to generate false information and enhance the model's understanding and reasoning abilities regarding episodic memory.


\paragraph{Environments}
In the design of environments, we initially considered only temporal information. We first established a series of time-stamped nodes arranged in chronological order (e.g., Monday, September 4, 2006, 21:42:56, Monday, September 4, 2006, 21:55:38). These time-stamped nodes are then automatically added to the conversation history between the human role and the Echo assistant, indicating the time at which each round of dialogue takes place.

\subsection{Data generation process}
\label{sec:dgp}


\paragraph{Prompt Design}

As illustrated in Figure \ref{fig:template}, we designed distinct prompt templates for both the human role and the Echo assistant. The highlighted sections in the figure are replaced with information from Section \ref{sec:three key}. Specifically:

\begin{itemize}
    \item \textbf{Human Role Prompt}: This includes the character card and all plot details, enabling the LLM to assume various human roles and engage in dialogues with the AI assistant according to different plots.
    
    \item \textbf{AI Assistant Prompt}: This incorporates both hallucinatory plots and common plots. This setup helps the LLM acting as the AI assistant to reduce episodic memory hallucinations and proactively seek relevant information in a human-like manner.
\end{itemize}

Based on these prompt templates, we generate initial prompts for the human and the Echo assistant, denoted as $P_u$ and $P_a$, respectively.


\paragraph{The Pseudocode of Data Generation Process}

Algorithm \ref{alg:data_generation} provides the pseudocode for the data generation process. We initialize and maintain two separate history records, $H_u$ and $H_a$, for the human role and the AI assistant using initial prompts $P_u$ and $P_a$, respectively. In lines 4-12 of Algorithm \ref{alg:data_generation}, we alternately control the two agents representing the human and the assistant to engage in dialogue. Temporal information is incorporated during the conversation in lines 6-8. We check if farewell phrases such as "goodbye" or "talk to you later" appear in the response. If any of these phrases are detected, or if the number of conversation rounds exceeds 60, the stopping criterion is considered to be met, and the current data generation process is terminated. Finally, we remove the initial prompt $P_a$ from $H_a$ to obtain the final dataset, denoted as $Data$, which constitutes one piece of data in our EM-Train dataset.

\begin{figure}[t!]
\centering

\includegraphics[width=.8\linewidth]{figure/template.pdf} \\

\caption{Prompt template in data generation process.}
\label{fig:template}
% \vspace{-1mm}
\end{figure}

\begin{algorithm}[ht]
    \caption{Pseudocode of Data Generation Process}
    \label{alg:data_generation}
    \begin{algorithmic}[1]
        \REQUIRE Initial prompts $P_u$ and $P_a$
        \ENSURE $Data$
        \STATE Initialize $H_u$, $H_a$
        \STATE $H_u \leftarrow H_u \cup P_u$
        \STATE $H_a \leftarrow H_a \cup P_a$
        \WHILE{stopping criterion not met}
            \STATE $answer_u \leftarrow LLM(H_u)$
            \STATE $time \leftarrow RandomNextTime(time)$
            \STATE $H_u \leftarrow H_u \cup answer_u \cup time$
            \STATE $H_a \leftarrow H_a \cup answer_u \cup time$
            \STATE $answer_a \leftarrow LLM(H_a)$
            \STATE $H_u \leftarrow H_u \cup answer_a$
            \STATE $H_a \leftarrow H_a \cup answer_a$
        \ENDWHILE
        \STATE $Data \leftarrow H_a \setminus P_a$
    \end{algorithmic}
\end{algorithm}


