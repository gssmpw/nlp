\section{Introduction}
\label{sec:intro}
Testing deep learning-based systems (DL)~\cite{GoodBengCour16} is a complex and critical task that shares similarities with traditional software testing, but presents unique challenges due to the data-driven nature of these systems.

% Large input space
These systems operate in high-dimensional input spaces, such as pixel values for images or token sequences for text. The large size and complexity of this input space make it practically impossible to test all possible inputs. Traditional testing techniques cannot cover such large input spaces, and identifying corner cases that could cause the model to fail requires specialized methods.
% Oracle problem
In addition, determining the correct output is not always straightforward, especially when dealing with complex tasks such as image classification or autonomous driving. The lack of a clear oracle, also known as the \textit{Oracle Problem}, makes it difficult to determine whether the system behavior is correct, as there is often no ground truth for comparison.
% Explainability
Furthermore, DL models are typically made up of many layers of interconnected neurons, making them complex and difficult to interpret~\cite{DBLP:journals/tse/ZhangHML22}.
As a consequence, they are often treated as black boxes that learn complex representations through data.

% Introduce metamorphic testing
Recently, a great deal of effort has been dedicated to using metamorphic testing~\cite{DBLP:conf/icse/ZhouLKGZ0Z020, DBLP:journals/pacmse/ChenJYGZC24} to address the aforementioned challenges.
Metamorphic testing evaluates the behavior of a DL model by systematically applying transformations to input data and examining the corresponding output changes. This approach relies on metamorphic relationships that formally define how input modifications affect the output~\cite{DBLP:conf/icse/DingKH17}.
Metamorphic testing for vision neural networks addresses the oracle problem by leveraging metamorphic relations to generate new test cases. This approach applies systematic transformations to existing test data while preserving ground truth labels (i.e., without affecting the expected output), enabling comprehensive testing without an explicit oracle.

Metamorphic testing has recently been employed in several approaches. Tian et al.~\cite{DBLP:conf/icse/TianPJR18} used transformations (such as adjustments to brightness, rotation, and blurring) on existing images to generate new test cases for DL-based autonomous driving systems. Although these transformations capture different behaviors of camera sensors, they do not represent realistic variations of the surrounding environment.
Zhang et al.~\cite{DBLP:conf/kbse/ZhangZZ0K18} applied Generative Adversarial Networks (GANs) to validate the behavior of the model in diverse scenarios. Although GANs provide an effective and scalable approach for generating large numbers of diverse test cases, they require a dedicated dataset for each target scenario and an ad-hoc training process to teach the generative model to map images from one domain to another (e.g., transforming images with sunny weather into images with rainy weather). This makes GAN-based testing resource-intensive, as it requires significant manual effort to create and synthesize new domains.

% Introduce DILLEMA
This paper introduces \approach (\textbf{DI}ffusion model and \textbf{L}arge \textbf{L}anguag\textbf{E} \textbf{M}odel for \textbf{A}ugmentation), a framework designed to enhance the robustness of DL applications by automatically augmenting existing image datasets. \approach utilizes a \textit{Captioning Model} (CM) to generate textual descriptions from input images. It uses a \textit{ Large Language Model} (LLM) to generate new descriptions, and a controllable \textit{Diffusion Model} (DM) to generate realistic high-quality images. Specifically, by taking advantage of pre-trained models that have been trained on large amounts of data, \approach generalizes well across various scenarios and datasets without the need for ad-hoc training (as required by approaches based on GANs~\cite{DBLP:conf/kbse/ZhangZZ0K18}).
We evaluated \approach using two popular datasets, ImageNet1K~\cite{DBLP:conf/cvpr/DengDSLL009} and SHIFT~\cite{DBLP:conf/cvpr/SunSPWGSTY22}.
The evaluation of DILLEMA covered multiple aspects, including the validity and hallucination rates of the generative models used. For example, the results show that the generated test cases maintained high validity, with more than $99.7\%$ augmented ImageNet1K images that preserved their original labels according to human evaluators.
Furthermore, empirical results demonstrate that the generated test suites uncover significantly more vulnerabilities compared to existing datasets. \approach revealed error rates more than $15$ times higher on ImageNet1K than the existing original test set. Furthermore, retraining with the augmented test cases improved robustness by up to $52.27\%$. 

The main contributions of this paper are as follows.

\noindent\textbf{Novel Metamorphic Testing Pipeline}.
    A framework to enhance DL models by automatically augmenting image datasets and generating new images using a combination of Captioning Model, Large Language Model, and Diffusion Model.
    
\noindent\textbf{Testing Dataset}.
    We released two additional datasets for testing DL applications: $125,000$ test cases for ImageNet1K classification and $10,000$ for SHIFT autonomous driving.
    
\noindent\textbf{Comprehensive Evaluation}.
    We assessed the approach's effectiveness and the realism of its generated images.

The remainder of this paper is structured as follows, \autoref{sec:solution} presents DILLEMA, \autoref{sec:eval} shows the empirical evaluation, \autoref{sec:related} introduces related work, and \autoref{sec:conclusion} concludes the paper.
