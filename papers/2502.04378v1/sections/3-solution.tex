\section{Methodology}
\label{sec:solution}

This paper presents \approach, a framework that improves the robustness of DL-based systems by generating realistic test images from existing datasets.
\approach leverages recent advances in text and visual models~\cite{DBLP:conf/cvpr/RombachBLEO22} to generate accurate synthetic images to test DL-based systems in scenarios that are not represented in the existing testing suite.

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{images/dillema-schema.drawio.pdf}
    \caption{\approach.}
    \label{fig:dillema}
    \vspace{-6mm}
\end{figure*}

% Describe inputs of \approach
The proposed methodology, as shown in \autoref{fig:dillema}, consists of five steps.
The input of our approach is an image (from the existing test cases) along with a textual description of the task assigned to the DL-based system. The output is a modified version of the input image based on new conditions. 

% Image Captioning
\subsection{Image Captioning}

The first step of \approach involves image captioning, which is the process of converting a given image to its textual description. The objective is to enable the application of recent advances in natural language processing to images. To achieve this, \approach brings the images into the textual domain, where language models can operate effectively.

Captions are generated as multi-sentence descriptions to capture key elements and provide a detailed representation of the image. Each sentence focuses on a different aspect of the scene, capturing a range of elements such as objects, environments, and contextual relationships. This approach increases the likelihood of capturing important details that a single-sentence description might miss, providing a more comprehensive textual description for the subsequent steps.

\subsection{Keyword Identification}

Once the image is converted into textual descriptions through the captioning process, the next step in \approach is Keyword Identification. This step aims to identify which elements of the image can be safely modified without altering the overall meaning or the primary task (e.g., object classification, semantic segmentation) associated with the image. 

In this phase, the LLM is used to analyze the captions generated in the previous step and identify a set of keywords that can potentially be altered. These keywords represent modifiable aspects of the image, such as colors, weather conditions, or object properties, while excluding core elements that are essential to the task. For example, when dealing with an image classification task involving a ``car'', altering the background color or lighting usually does not modify the label. Conversely, in a semantic segmentation task focused on road scenes, the road and critical objects (cars, pedestrians, traffic signals) must remain present, though certain attributes (e.g., color, weather conditions) can still be changed. By defining the task explicitly in the prompt, we ensure that only permissible alterations are suggested by the LLM.
\autoref{fig:classification_and_segmentation} illustrates how the constraints differ between classification (\autoref{fig:classification}) and segmentation (\autoref{fig:semantic_segmentation}). In classification, the focus is on identifying and preserving the labeled object (\emph{car}), while in segmentation, multiple objects must remain for valid ground-truth labels.

\begin{figure}[]
\centering
    \begin{subfigure}{.49\linewidth}
    \centering
    \includegraphics[width=\textwidth]{images/segment.png}
    \caption{Classification Task.}
    \label{fig:classification}
    \end{subfigure}
    \begin{subfigure}{.49\linewidth}
    \centering
    \includegraphics[width=\textwidth]{images/annotated.png}
    \caption{Segmentation Task.}
    \label{fig:semantic_segmentation}
    \end{subfigure}
\caption{
Label Preservation in Autonomous Driving Tasks.
}
\label{fig:classification_and_segmentation}
\vspace{-6mm}
\end{figure}

The process of identifying these keywords is guided by task constraints. \approach prompts the LLM with a specific task-related query, such as:

\begin{tcolorbox}[arc=.3em,left=.3em,right=.3em,top=.3em,bottom=.3em]
\begin{center}
\begin{minipage}[t]{.99\linewidth}
\textbf{Prompt}: \textit{
Given the task $<$TASK$>$ and an image described by the caption $<$CAPTION$>$, what are the key elements that can be modified in the caption so that the ground truth corresponding to the image does not change?
}
\end{minipage}
\end{center}
\end{tcolorbox}

Note that this represents an example of the prompts used in \approach, intended to clarify the type of information that we request from the LLM. To improve the effectiveness of the prompt, various advanced strategies can be adopted. For example, as detailed in \autoref{sec:eval:setup}, we configured \approach to use a one-shot in-context learning prompting strategy, allowing the LLM to provide better results by including an example within the prompt.

The identification of keywords is designed to be flexible and adaptable for different tasks. The LLM relies on its internal knowledge to evaluate the contextual relevance of each word in the caption, taking into account both syntactic and semantic relationships. For example, if the task is semantic segmentation in an autonomous driving scenario, elements such as road conditions, lighting, or vehicle color may be identified as modifiable keywords, while objects essential to the task, such as vehicles themselves, remain unchanged.

\subsection{Alternative Identification}

In this phase, the LLM is leveraged to generate alternatives for the identified keywords, providing variations that can be applied to the image without altering the overall task.

The goal of this step is to explore different possibilities for modifying the elements flagged in the previous step, such as changing the color of objects, adjusting environmental conditions (e.g., weather), or altering minor details, while keeping the core structure and purpose of the image intact. For example, if the keyword ``foggy'' was identified as a modifiable attribute in the caption ``a car driving down a foggy street'', the LLM could suggest alternatives like ``rainy'' or ``snowy''.
To execute this, \approach generates a prompt asking the LLM to propose alternatives for the identified keywords. 

The main challenge in this phase is to introduce meaningful variations to the image while keeping its semantic meaning intact. The LLM plays a key role by generating alternatives that align with the original caption and task, avoiding changes that could shift the focus of the task. We take advantage of the ability of the LLM to understand contextual subtleties to avoid proposing changes to critical elements such as replacing ``car'' with ``bicycle'' in a vehicle detection scenario. An example of a prompt used in this phase is:

\begin{tcolorbox}[arc=.3em,left=.3em,right=.3em,top=.3em,bottom=.3em]
\begin{center}
\begin{minipage}[t]{.99\linewidth}
\textbf{Prompt}: \textit{
Given the task $<$TASK$>$ and an image described by the caption $<$CAPTION$>$, what are the possible alternatives for these keywords $<$KEYWORDS$>$?
}
\end{minipage}
\end{center}
\end{tcolorbox}

This process focuses on generating contextually relevant and diverse modifications, allowing the system to produce meaningful test cases for the DL model at hand. The alternatives proposed for each keyword enable \approach to explore different conditions or attributes of objects, broadening the range of scenarios included in the original dataset.

\subsection{Counterfactual Caption Generation}

This phase is responsible for creating new textual descriptions, or counterfactual captions, by applying the alternatives generated in the previous step. These counterfactual captions describe how the image would look if certain elements were modified, enabling the system to explore new scenarios while preserving the core context of the original image.

In this step, the LLM takes the original caption and replaces the identified keywords with the newly generated alternatives. The goal is to produce a new version of the caption that reflects the desired modifications without changing the essential meaning of the image. For example, if the original caption was ``a gray car driving down a foggy street'', and the alternatives generated for the keywords ``gray car'' and ``foggy'' were ``red car'' and ``snowy'', the new counterfactual caption would be ``A red car driving down a snowy street''.

The amount of edits in the new prompt can be controlled by limiting the number of alternatives applied when generating the counterfactual captions. For example, applying only one alternative at a time allows for small incremental changes, allowing exploration of subtle variations of the original caption. In contrast, applying multiple alternatives simultaneously can produce larger transformations, introducing more diverse scenarios. This approach provides fine-grained control over the extent of modifications, enabling tailored exploration of different levels of change in the generated test cases.

This phase is critically important because it ensures that the generated caption remains coherent and meaningful despite the modifications. Although replacing certain words (such as ``gray'' with ``red'') might seem straightforward, many cases are more complex, requiring careful handling to avoid breaking the sentence's meaning or introducing contradictions. For example, consider a caption like ``a road in a tundra covered in snow during a snowy day''. Replacement of the word ``tundra'' with ``desert'' would result in ``a road in a desert covered in snow during a snowy day'', which is contextually unlikely.

In this step, the LLM is prompted with the following input:

\begin{tcolorbox}[arc=.3em,left=.3em,right=.3em,top=.3em,bottom=.3em]
\begin{center}
\begin{minipage}[t]{.99\linewidth}
\textbf{Prompt}: \textit{
Given the task $<$TASK$>$, modify the caption $<$CAPTION$>$ by applying some of the following transformation described by $<$ALTERNATIVES$>$.
}
\end{minipage}
\end{center}
\end{tcolorbox}

By asking the LLM to generate the new caption directly, rather than applying simple replacement rules from the alternative dictionary, \approach ensures that the LLM processes not only the specific word replacements but also the broader sentence context, maintaining the overall meaning while making necessary adjustments to prevent contradictions or illogical outcomes.
Additionally, by explicitly including the task description at every step of the interaction, the LLM is continuously reminded of the objective it is trying to achieve. This ensures that the generated captions respect the metamorphic relationships inherent in the test case, preserving the critical connections between elements of the image and their semantic meaning.

\begin{figure*}
\centering
    \centering
    \includegraphics[width=.98\textwidth]{images/dillema_example.drawio.pdf}
\caption{Image generation in \approach.}
\label{fig:controlled_generation}
% \vspace{-5mm}
\end{figure*}
\subsection{Controlled Text-to-Image Generation}

The final step of \approach generates a modified image based on the counterfactual caption produced in the previous phase. This step is where the transformation of the image occurs, and it is carried out using a control-conditioned text-to-image diffusion model~\cite{DBLP:conf/iccv/ZhangRA23}.  The key challenge here is not only to generate a new, realistic image that aligns with the counterfactual caption but also to ensure that the spatial structure of the original image is preserved so that the integrity of metamorphic relationships is maintained.

When generating a new test image, the spatial arrangement of key objects and elements must be preserved. For example, in the context of semantic segmentation for autonomous driving, if an image depicts a car driving down a road, the generated image must include the car in the same location as the original image relative to the road, even if its color or weather conditions are changed. This way, the transformations to be applied will only affect specific attributes (e.g., altering weather or object properties) without impacting the fundamental geometry or layout of the scene. On the other hand, a distorted spatial structure could mislead the test results, making it unclear whether a failure is due to the actual shortcomings of the model or due to irrelevant transformations in the image.

To achieve spatial structure preservation, \approach uses control-conditioned diffusion models. These models allow fine-grained control over the generated image by incorporating conditioning inputs that preserve the spatial layout of the original image while applying the desired modifications.

\autoref{fig:controlled_generation} showcases examples of test cases generated by \approach for image classification (top row) and semantic segmentation (bottom row).
For image classification, the input image belongs to the class \textit{bird}, described by the captioning model as ``A yellow bird on a twig''. The second column displays the conditioning input extracted from the original image to preserve spatial arrangements. The remaining columns show images generated from alternative captions produced by the LLM: Caption A (``A blue bird on a twig'') changes the bird color to blue, while Caption B (``A red bird on a twig'') changes it to red. 
These augmentations demonstrate \approach ability to alter specific attributes while maintaining spatial structure and preserving the relevance of the class \textit{bird}. 

For semantic segmentation, the input image depicts a road with two cars during cloudy weather, with the ground truth represented as a semantic map of pixel-level classifications. The captioning model describes it as ``A road with two cars in cloudy weather''. The second column provides the conditioning input to ensure spatial consistency during generation. Caption A (``A road with two cars during snowy weather'') introduces snow to the scene, while Caption B (``A road with two cars during sunset'') applies sunset lighting. Both augmentations preserve the layout of roads, vehicles, and pedestrians as defined by the ground truth semantic map.