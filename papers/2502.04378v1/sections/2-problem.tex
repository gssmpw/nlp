\section{Problem Statement}
\label{sec:problem}
\dav{Remove this section and merge with introduction}
% Intro to problem
% This section introduces the problem this paper aim to tackle and its main characteristics of the problem.
Testing DL-based systems is a complex and critical task that shares some similarities with traditional software testing but presents unique challenges due to the data-driven nature of these systems.

% Large input space
These systems operate in high-dimensional input spaces, such as pixel values for images or token sequences for text. The sheer size and complexity of this input space make it practically impossible to exhaustively test all possible inputs. Traditional testing techniques cannot cover such vast input spaces, and identifying corner cases that could cause the model to fail requires specialized methods.
% Oracle problem
Additionally, determining the correct output is not always straightforward, especially when dealing with complex tasks like image classification or autonomous driving. The lack of a clear oracle, also known as the \textit{Oracle Problem}, makes it difficult to determine whether the system behavior is correct, as there is often no ground truth for comparison.
% Explainability
Furthermore, DL models are typically composed of many layers of interconnected neurons, making them inherently complex and often difficult to interpret.
As a consequence, they are often treated as black boxes that learn complex representations through data.

Deep learning-based systems have made significant advancements in critical domains such as autonomous driving, healthcare, and robotics. 
However, despite their growing sophistication, these systems are prone to erroneous or unexpected behavior, especially in edge cases or under-distribution shifts. This can lead to catastrophic outcomes, such as accidents in autonomous driving or incorrect medical diagnoses, necessitating robust testing methods to ensure system reliability.

Unlike traditional software, where behavior is defined explicitly by code, DL systems learn complex representations from large datasets. This inherent complexity and opacity make testing these systems far more challenging. Key problems include:

Difficulties in Generating Diverse and Realistic Test Cases
Current testing techniques for DL systems, such as using manually labeled real-world datasets, suffer from the limited diversity of scenarios they can cover. Creating large-scale test data that accurately represents a wide variety of edge cases is both time-consuming and costly. Moreover, manual generation of corner cases—such as unusual weather conditions in autonomous driving—requires domain expertise and is often infeasible for large-scale testing.

Inadequacies of Simple Transformation Methods
Metamorphic testing has shown promise for generating new test cases by transforming existing ones. However, methods relying on simple transformations like brightness adjustment, rotation, or blurring fail to create the complexity needed to simulate real-world environments accurately. These transformations do not introduce the nuanced changes required to cover more diverse scenarios, limiting their ability to test system robustness effectively.

Limitations of GAN-based Augmentation
While Generative Adversarial Networks (GANs) have been applied to generate synthetic test cases, they come with their own set of challenges. GANs require a considerable amount of training and can only produce specific target domains (e.g., foggy weather, snowy roads), limiting their general applicability. Furthermore, training GANs is computationally expensive, and the quality of generated images often depends on the availability of high-quality target data, which is not always accessible.

Need for Scalable and Automated Testing Solutions
There is a clear need for scalable, automated frameworks that can generate diverse and realistic test cases without requiring domain-specific training or extensive manual input. Such a solution should be capable of generating synthetic data that reflects complex real-world scenarios while maintaining the accuracy of the original dataset's labels. The system must also be efficient in terms of computational resources to be practical for large-scale DL applications.

Given these challenges, there is an urgent need for a more robust and flexible approach to augmenting datasets and testing DL systems. DILLEMA aims to address these issues by leveraging the combined power of diffusion models and large language models (LLMs) to automatically generate high-quality, diverse, and contextually relevant test cases, providing a scalable and efficient solution for testing DL applications under distribution shifts.