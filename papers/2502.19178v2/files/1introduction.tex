\section{Introduction}
The advent of large language models (LLMs) has revolutionized the field of natural language processing (NLP), showcasing remarkable performance across various tasks, such as machine translation, sentiment analysis, semantic understanding, and multi-turn dialogues~\cite{OpenAI2023GPT4,touvron2023llama,yang2024qwen2,liu2024deepseek}. 
The powerful capabilities of LLMs have the potential to extend to numerous personalized scenarios, including platform search, recommendation, and online advertising, which are highly related to user experience~\cite{guu2020retrieval,bao2023tallrec,muhamed2021ctr}. Specifically, the information cocoons caused by collaborative filtering (CF)-based methods are always a critical challenge that jeopardizes user experience in personalization tasks~\cite{pariser2011filter,nguyen2014exploring}.
With rich worldwide knowledge and diversity, LLMs provide a chance to break the information cocoons of users and bring sufficient personalization~\cite{xu2024prompting,zhao2023recommender,zhang2023recommendation,wu2024survey}. One promising direction LLMs can take to provide personalization is incorporating user history interactions as contextual information~\cite{liu2023chatgpt,petrov2023generative,kang2023llms,geng2022recommendation,lyu2023llm}. Specifically, the user interaction data are collected from the behavioral interactions (e.g., click, favorite, add to cart, and purchase) between users and items in various scenarios, e.g., searching and recommendation. Therefore, user interaction data can provide abundant information regarding user interests and preferences, a valuable source for providing user-side context for prompting LLMs in personalization. 

% The advent of large language models (LLMs) has revolutionized the field of natural language processing (NLP), showcasing remarkable performance across various tasks, such as machine translation, sentiment analysis, semantic understanding, and multi-turn dialogues~\cite{OpenAI2023GPT4,touvron2023llama,yang2024qwen2,liu2024deepseek}. 
% The powerful capabilities of LLMs have the potential to extend to numerous personalized scenarios, including platform search, recommendation, and online advertising, which are highly related to user experience~\cite{guu2020retrieval,bao2023tallrec,muhamed2021ctr}. Specifically, the information cocoons caused by collaborative filtering (CF)-based methods are always a critical challenge that jeopardizes user experience in personalization tasks~\cite{pariser2011filter,nguyen2014exploring}.
% With rich worldwide knowledge and diversity, LLMs provide a chance to break the information cocoons of users and bring sufficient personalization~\cite{xu2024prompting,zhao2023recommender,zhang2023recommendation,wu2024survey}. One promising direction LLMs can take to provide personalization is incorporating user history interactions as contextual information~\cite{liu2023chatgpt,petrov2023generative,kang2023llms,geng2022recommendation,lyu2023llm}. Specifically, the user interaction data are collected from the behavioral interactions (e.g., click, favorite, add to cart, and purchase) between users and items in various scenarios, e.g., searching and recommendation. Therefore, user interaction data can provide abundant information regarding user interests and preferences, a valuable source for providing user-side context for prompting LLMs in personalization. 

Despite the promise of enhanced personalization by integrating user interaction history into the context of LLMs, this approach faces significant challenges. User interaction data can be lengthy and noisy~\cite{wang2021denoising,tian2022learning,qin2021world}, making direct incorporation as text prompts impractical in industrial settings.
First, the massive number of tokens in interaction sequences (e.g., tens of thousands) slows down the inference speed of LLMs, leading to unacceptable response times and negatively impacting user experience. Technically, the computational complexity of the attention mechanism---the core of LLMs---is enormous, scaling quadratically with the number of tokens $N$~\cite{vaswani2017attention}. Moreover, $N$ may even exceed the context limit of LLMs.
Second, users' redundant, repeated, and unintentional interactions across various scenarios can mislead LLMs into understanding user interests.
Inspired by advancements in recommendations, such as GRU4Rec~\cite{hidasi2015session} and SASRec~\cite{kang2018self}, a promising alternative to address this issue is compressing these interactions into more compact user embeddings using encoder models~\cite{li2023prompt,ning2024user,li2023personalized}. These user embeddings act as soft prompts, providing ``efficient'' (i.e., fewer tokens, higher value) contextual information. By extracting high-value information and filtering out irrelevant interactions, this embedding-based approach simultaneously addresses the aforementioned challenges.


% Despite the promise of personalization by integrating user interaction history into the LLMs' context, this approach faces significant challenges. User interaction data can be lengthy and noisy~\cite{wang2021denoising,tian2022learning,qin2021world}, making direct incorporation as text prompts impractical in industrial settings. 
% First, the massive number of tokens (e.g., tens of thousands) in interaction sequences retards LLMs' inference speed, leading to unbearable response time (RT) and jeopardizing user experience. Technically, the computational complexity of the attention mechanism (i.e., the core of LLMs) is enormous, quadratic to the number of tokens $N$, besides $N$ may even be out of the LLMs' context restriction~\cite{vaswani2017attention}.
% Second, users' redundant, repeated, and unintentional interactions in various scenarios can misdirect LLMs' understanding of user interests. 
% Inspired by advances in recommendations, such as GRU4Rec~\cite{hidasi2015session} and SASRec~\cite{kang2018self}, a promising alternative to tackling this issue is compressing these interactions into more compact user embeddings~\cite{li2023prompt,ning2024user,li2023personalized}, using encoder models. The user embeddings act as soft prompts, providing ``efficient'' (i.e., fewer tokens, higher value) contextual information.
% By focusing on extracting high-value information and filtering out irrelevant interactions, this embedding-based approach enables LLMs to generate personalized responses more efficiently.

While employing user embeddings to prompt LLMs offers a promising and efficient approach to personalization, several significant concerns emerge regarding their effectiveness: 
\begin{itemize}[leftmargin=*]
\item Can user embeddings capture the necessary information from user interactions and effectively convey it to LLMs? 
\item When contextualized through user embeddings, can LLMs perform traditional recommendation tasks successfully?
\item Do user embeddings serve as strong prompts that guide LLMs to produce personalized responses aligned with user interests?
\end{itemize}
Unfortunately, previous evaluations primarily concentrate on the traditional recommendation performance~\cite{fang2020deep,hidasi2015session,kang2018self}, such as user-item similarity scores and recall/rank metrics.
This focus leaves a gap in comprehensively assessing how user embeddings address these concerns in the LLM era.
To bridge this gap, we introduce \textbf{\name}, a novel Chinese \textbf{Bench}mark designed to evaluate the quality of \textbf{U}ser embeddings in prompting LLMs for personalized \textbf{Q}uestion \textbf{A}nswering. The interactive, personalized Q\&A paradigm aligns with the LLMs' parameterized nature. 
Notably, our approach stands out for its standardization and comprehensiveness in evaluating user embeddings.


% ensuring reliable and consistent evaluation.

% Current evaluation methods primarily focus on the similarity-based performance of user embeddings (e.g., calculating user-item similarity and aggregating recall/rank metrics), leaving a gap in comprehensive evaluation methods that assess the capability of user embeddings in prompting LLMs to address the aforementioned concerns. To bridge this gap, we introduce \name, a novel benchmark designed to evaluate the quality of user embeddings in prompting LLMs. Our evaluation paradigm is based on personalized interactive question answering, aligning with the nature of LLMs and diverging from traditional recommendation benchmarks. Moreover, our approach is characterized by its fairness and standardization, ensuring a reliable and consistent evaluation process.

% However, while using user embeddings as soft prompts for LLMs presents a potential and efficient solution to personalization, critical concerns remain regarding their effectiveness and reliability: (1) Can user embeddings capture the necessary information from user interactions for LLMs? (2) If contextualized by user embeddings, Can LLMs do traditional recommendations? (3) Can user embeddings be a strong prompt that guides the LLMs to output more personalized answers? 
% The existing evaluation methods focus on the similarity-based performance of user embeddings (e.g., calculating u-i similarity and aggregating the recall/rank metrics), leaving a gap in evaluation that can comprehensively assess user embeddings in prompting LLMs to address the above three concerns. To address this gap, we introduce \name, a novel benchmark designed to evaluate user embeddings' quality in prompting LLMs. We apply personalized interactive question answering as the evaluation paradigm, which conforms to LLMs' knowledge and differs from the existing recommendation benchmarks. Our approach is also distinguished by its fairness and standardization, ensuring a reliable evaluation process.

The standardized evaluation flow of \name includes three steps: 
(1) \textbf{Pre-training}: We utilize sufficient user interaction data to pre-train encoder models. 
(2) \textbf{Fine-tuning}: We align learned user embeddings with semantic space through fine-tuning, a step crucial for making LLMs capable of utilizing user embeddings for personalization.
(3) \textbf{Evaluating}: We evaluate user embeddings in prompting LLMs for task-specific personalized Q\&A.  
To provide a comprehensive assessment, we design three critical tasks that extend beyond conventional evaluations and address the previously mentioned concerns:
(1) \textbf{Sequence understanding} measures the qualities of user embeddings in prompting LLMs to understand direct features and match features, crucial for determining whether user embeddings can substitute massive feature engineering in the industry.
(2) \textbf{Action prediction} involves next-item and next-attribute predictions, reframing traditional recommendation tasks within a natural language paradigm.
(3) \textbf{Interest perception} focuses on modeling user interest, covering long- and short-term interests and interest trajectory, aligning closely with new industrial demands such as enhancing user experience. 
We evaluate various state-of-the-art user encoder models using \name, providing valuable insights for employing user embeddings in the LLM era. Furthermore, we explore the scalability of Transformer-based encoders in prompting LLMs for personalization.
Our work seeks not only to validate effective methodologies but also to lay the groundwork for future innovations in user personalization.


% The standardized evaluation flow of \name includes three steps: 
% (1) \textbf{Pre-training}: We utilize sufficient industrial user interaction data to pre-train encoder models. 
% (2) \textbf{Fine-tuning}: We align learned user embeddings with semantic spaces through fine-tuning, a step crucial for making LLMs capable of utilizing user embeddings for personalization.
% (3) \textbf{Evaluating}: We evaluate user embeddings in prompting LLMs in task-specific personalized Q\&A.  
% Regarding comprehensive assessment, we design three critical tasks, extending beyond conventional evaluations' limitations and covering previously raised concerns, listed as follows. 
% (1) \textbf{Sequence understanding}: measures the capabilities of user embeddings in prompting LLMs to understand direct features and match features, which is important as it relates to whether user embeddings can substitute massive feature engineering in the industry. 
% (2) \textbf{Action prediction}: includes next-item and next-attribute predictions, reconstructing traditional recommendation tasks using natural language. 
% (3) \textbf{Interest perception}: is related to modeling user interest, including long- and short-term interests and interest trajectory, highly related to new industrial demand (i.e., user experience). 
% We assess various state-of-the-art user encoder models on \name, offering valuable insights for employing user embeddings in the LLM era. Moreover, we explore the scalability of Transformer-based encoders in prompting LLMs in personalization.
% Our work seeks not only to validate effective methodologies but also to pave the way for future innovations in user personalization.

% The First, \name provides sufficient real user interaction data for pre-training encoder models. Then, \name aligns learned user embeddings with semantic spaces through fine-tuning, a step crucial for making LLMs capable of utilizing user embeddings for personalization. 
% Subsequently, we design three critical evaluation tasks: sequence understanding, action prediction, and interest perception, which advance beyond conventional evaluation. 
% The three tasks correspond to three concerns of user embeddings raised previously. 
% The sequence understanding task measures the capabilities of user embeddings in prompting LLMs to understand direct features and match features. Understanding features is important because it relates to whether user embedding can substitute massive feature engineering in the industry. 
% The action prediction task includes predicting the next item and attribute, closely related to the traditional recommendation task. 
% The interest perception task is related to modeling user interest, including long- and short-term interests and interest trajectory.
% We evaluate various state-of-the-art methods for modeling user embeddings through extensive experiments, offering valuable insights for optimizing and employing user embeddings. Moreover, we conduct experiments to reveal the scaling law in modeling user interests, leveraging the widely used Transformer-based models.
% Our work seeks not only to validate effective methodologies but also to pave the way for future innovations in user personalization.


The main contributions of our work are three-fold:

\begin{itemize}[leftmargin=*]

\item We introduce \name, a novel benchmark that comprehensively evaluates the user embeddings in prompting LLMs for personalization. This benchmark uniquely leverages personalized interactive question answering, distinguishing itself from traditional benchmarks.

% \item We construct a standardized assessing process to ensure evaluation reliability. 
% Our proposed assessment tasks comprehensively address the effectiveness of user embeddings, encompassing industrial recommendation focuses from both old and new eras. 

\item We construct a standardized assessing process to ensure evaluation reliability. 
Additionally, our proposed assessment tasks comprehensively address the effectiveness of user embeddings, encompassing industrial recommender system focuses from both old and new eras.

\item The data and code are open source, facilitating further research. Extensive experiments offer novel insights into learning user representations, providing guidelines for optimizing personalization and enhancing user experience in the LLM era.  

\end{itemize}


% \item We introduce \name, a novel benchmark for comprehensively evaluating the user embeddings in prompting LLMs for personalized question answering, addressing the gap in the evaluation of user embeddings' effectiveness in personalizing LLMs.

% \item We propose a systematic fine-turning method to align user embeddings into semantic spaces, guaranteeing fairness and reliability. To ensure a comprehensive evaluation, we build questions from three assessment dimensions: sequence understanding, action prediction, and interest perception.

% \item Our extensive evaluation on state-of-the-art methods offer valuable insights into methods leveraging user interactions in prompting LLMs, providing guidelines for optimizing LLMs personalization and enhancing user experience. Furthermore, we uncover the scaling law in modeling user interest with Transformers. 

