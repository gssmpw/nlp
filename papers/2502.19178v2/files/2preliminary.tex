\begin{figure}[t]
    \centering
    % \vspace{-4mm}
    \includegraphics[width=1.0\linewidth]{pics/compare.pdf}
    % \vspace{-4mm}
    \caption{
    A brief comparison of SRs and GRs.
    }
    \label{fig:compare}
    \vspace{-2mm}
    % \captionsetup{belowskip=-20pt}
\end{figure}


\section{Preliminary}
We briefly introduce how both previous and current recommender systems utilize user interactions, focusing on two prevailing branches: sequential recommendations (SRs) and generative recommendations (GRs). The brief comparison is illustrated in Figure~\ref{fig:compare}.

\subsection{Sequential Recommendations (SRs)}
Given a set of users \(\mathcal{U}=\{u_1,u_2,\cdots,u_{\vert\mathcal{U}\vert}\}\) and a set of items \(\mathcal{V}=\{v_1,v_2,\cdots,v_{\vert\mathcal{V}\vert}\}\), consider that the interaction sequence of user \(u_i\) is denoted as \(s_i=[v_{1}^i, v_{2}^i, \cdots, v_{n_i}^i]\). For user \(u_i\), SRs take \(s_i\) as input and calculate recommendation scores (e.g., cosine similarity) for candidate items, then output the top-\(k\) items most likely to be interacted with in the subsequent time step.

\subsection{Generative Recommendations (GRs)}
GRs represent a shift towards utilizing LLMs to generate more personalized recommendation results, divided into two main branches:

\subsubsection{\textbf{Text-based GRs.}} 
Text-based GRs directly leverage the textual information of interactions. Interacted items' IDs and textual attributes, such as titles, categories, and descriptions, are chronologically placed in pre-designed prompts to serve as user context. Given questions like "What item will the user click next," the LLMs generate responses such as "item $j$."

\subsubsection{\textbf{Embedding-based GRs.}}
In contrast, embedding-based GRs transform lengthy, noisy interaction sequences into information-dense user embeddings. These user embeddings, aligned to the semantic space by an adapter, act as soft prompts for LLMs, personalizing them further. Compared to text-based GRs, this approach requires fewer tokens to convey user context, enhancing efficiency and scalability. However, a critical question remains: "Can this approach provide comparable personalized performance to text-based GRs?" This question forms one of the core research focuses of this paper.


% \section{Preliminary}
% We briefly introduce how both previous and current recommender systems utilize user interactions, focusing respectively on two prevailing branches: sequential recommendations (SRs) and generative recommendations (GRs).
% The brief comparison is shown in Figure~\ref{fig:compare}.

% \subsection{Sequential Recommendations (SRs)}
% Given a set of users \(\mathcal{U}=\{u_1,u_2,\cdots,u_{\vert\mathcal{U}\vert}\}\) and a set of items \(\mathcal{V}=\{v_1,v_2,\cdots,v_{\vert\mathcal{V}\vert}\}\), consider that the interaction sequence of user \(u_i\) is denoted as \(s_i=[v_{1}^i, v_{2}^i, \cdots, v_{n_i}^i]\). For user \(u_i\), SRs take \(s_i\) as input and calculate the recommendation scores (e.g., cosine similarity) for candidate items, then output the top-\(k\) items that are most likely to be interacted with in the subsequent time step.

% \subsection{Generative Recommendations (GRs)}
% \subsubsection{\textbf{Text-based GRs.}} 
% GRs employ LLMs to generate more personalized recommendation results than SRs.
% One branch of GRs, text-based GRs, directly leverages the textual information of interactions. The interacted items' IDs and textual information, such as title, category, and description, are filled in the reserved positions chronologically in the pre-designed prompt, serving as user context. Then, given questions like "What item will the user click next," the LLMs will generate responses such as "item $j$."

% \subsubsection{\textbf{Embedding-based GRs.}}
% As the user interactions are usually lengthy and noisy, embedding-based GRs transform the interaction sequence into an information-dense form, i.e., user embeddings. The user embedding will be aligned to the semantic space by the adapter and then act as the soft prompt for LLMs, prompting them to be more personalized. Compared to text-based GRs, this approach needs far fewer tokens for the user context, meaning improved efficiency and scalability. The remaining concern is, "Can this approach provide comparable performance to text-based GRs?" Which is also the core research point of this paper. 