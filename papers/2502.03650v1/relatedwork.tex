\section{Related work about evolving Fuzzy Systems}
The evolving fuzzy rule-based model was introduced by \citet{angelov2001evolving}, this system has shown a notorious advantage compared to pure neural networks models, presenting evident and explainable results (\citealt{angelov2010evolving, leite2020overview}). \citet{rong2006sequential} developed the Sequential Adaptive Fuzzy Inference System that uses an extended Kalman filter to update the fuzzy rules (SAFIS). To overcome the limitations of SAFIS such as the complexity of the rule's influence and the difficulty to cope with high-dimensional input spaces, \citet{rong2011extended} proposed the extended version of SAFIS (ESAFIS). \citet{lughofer2008flexfis} created the Flexible Fuzzy Inference Systems (FLEXFIS), an algorithm that uses a linear polynomial to exploit the Takagi–Sugeno model, this model demands low computational cost and is adequate for online operations (\citealt{trawinski2011investigation}). \citet{lughofer2010sparsefis} presented a model that optimizes the consequent parameters and sparses out the unimportant rules, the Sparse Fuzzy Inference Systems (SparseFIS), using a numerical optimization mechanism to define a compact ruleset (\citealt{serdio2013data}).

\citet{vskrjanc2015evolving} implemented a model to deal with highly noisy data, the evolving Gustafson–Kessel Possibilistic c-Means clustering (eGKPCM). \cite{maciel2016evolving} developed the evolving Possibilistic Fuzzy Modeling approach (ePFM), which uses the Gustafson–Kessel (GK) clustering algorithm to identify clusters with different shapes and orientations while processing the data recursively. Also, this model uses utility measure to evaluate the quality of the current cluster structure. These implementations make the model robust to modeling volatility dynamics and nonlinear volatility forecasting with jumps.

\citet{ge2018self} detailed a model with self-learning parameters, the Self-evolving Fuzzy System (SEFS), this method improves the model’s accuracy by auto-adjusting the rule’s adding speed, reducing underfitting or overfitting. \citet{leite2019optimal} created the evolving Optimal Granular System (eOGS), making it possible to trade off multiple objectives. \citet{alves2020enhanced} implemented the Set-Membership (SM) and the Enhanced Set-Membership (ESM) in the ePL-KRLS (\citealt{alves2021novel}) model, the objective of the membership is to update the rate of change of the arousal index and control the rule creation speed, enhancing the performance of the models. Finally, \cite{ge2020learning} presented a model with self-learning thresholds, the evolving Fuzzy System Self-learning/adaptive Thresholds (EFS-SLAT). 

%% An overview of ePL-KRLS-FSM+