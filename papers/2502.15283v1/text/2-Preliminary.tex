\section{Preliminaries}

\textbf{Sealed-Bid Combinatorial Auction}. We consider sealed-bid CAs with a single bidder and $m$ items, $M=\{1,\ldots,m\}$.
The bidder has a {\em valuation function}, $v: 2^M \rightarrow \mathbb{R}_{\ge 0}$. Valuation $v$ is drawn independently from a distribution $F$ defined on the space of possible valuation functions $V$, determining how valuable each bundle $S\in 2^M$ is for the bidder. We consider bounded valuation functions: $v(S)\in[0, v_{\max}]$, $S\subset 2^M$, with $v_{\max}>0$, and they are normalized so that $v(\varnothing)=0$.
%
%\forall v_i\in \supp(F_i)$} \dcp{i just realized that we need a bounded domain $V_i$ for a grid to be well defined, right? comment on this.}
% We use $\vv$ to denote the value of the bidder for each of the $2^m$ bundles. 
The auctioneer  knows distribution $F$ but not the  valuation  $v$. The bidder reports their valuation function, perhaps untruthfully, as their {\em bid (function)}, $b\in V$. 

In CAs, a suitable {\em bidding language} is critical to allow a bidder to report their
bid without needing to enumerate a value for every possible bundle.  There
are many ways to do this, but a  common approach is to use the {\em XOR bidding language}, which allows bidders to submit bid prices for each of multiple bundles under an exclusive-or condition; in effect, only one bid price on a bundle can be accepted. Popular CA testbeds such as CATS~\citep{leyton2000towards} and SATS~\citep{weiss2017sats} employ this bidding language extensively.\footnote{When representing the values of multiple bidders these testbeds often also introduce so-called dummy items for distinguishing the bids of different 
bidders. Still, the semantics for a single bidder is, in effect, that of the XOR language.}
The semantics of the XOR bidding language is that the value on a bundle $S$ is the maximum bid price on
any bundle $S'$, submitted as part of the XOR bid, and for which $S'\subseteq S$. XOR bids are 
succinct for valuation functions in which the bidder is only interested in a bounded number
of possible bundles.

We seek an auction $(g,p)$ that maximizes expected revenue. Here, $g: V\rightarrow \mathcal{X}$ is the {\em allocation rule},  where $\mathcal{X}$ is the space of feasible allocations (i.e., no item allocated more than once), so that $g(b)\subseteq M$ denotes the set of items (perhaps empty) allocated to the bidder at bid $b$.
%
Also, $p: V\rightarrow \mathbb{R}_{\ge 0}$ is the {\em payment rule},
specifying the price associated with allocation $g(b)$. 
 %
The utility to the bidder with valuation function $v$ at bid  $b$ is $u(v;b)=v(g(b))-p(b)$, which is
the standard model of quasi-linearity so that values are in effect quantified in monetary units, say dollars.
%
 In full generality, the allocation and payment rules may be \emph{randomized}, with
 the bidder assumed to be risk neutral  and seeking
to maximize their 
expected utility.


In a \emph{dominant-strategy incentive compatible} (DSIC) auction, or {\em strategy-proof (SP)} auction, the bidder's utility is  maximized by bidding their true valuation $v$, whatever this valuation is; i.e., $u(v; v)\ge u(v;b)$, for $\forall v\in V, \forall b\in V$.
An auction is \emph{individually rational} (IR) if the bidder receives a non-negative utility when participating and truthfully reporting: $u(v;v)\ge 0$, for $\forall v\in V$.
Following the revelation principle, it is without loss of generality to focus on  
SP
auctions, as any auction that achieves a particular expected revenue in a dominant-strategy equilibrium
 can be transformed into an SP auction with the same expected revenue.
 %
 Optimal auction design therefore seeks to identify an SP and IR auction that maximizes the expected revenue, i.e., $\mathbb{E}_{v\sim \bm F}[p(v)]$. 

\textbf{Menu-Based CAs}. In a {\em menu-based auction}, allocation and payment rules  are
represented through a menu, $B$, consisting of
$K\ge 1$  {\em menu elements}.
%
We write $B=(B^{(1)},\ldots,B^{(K)})$, 
and the $k$th \emph{menu element}, $B^{(k)}$,
 specifies allocation probabilities on bundles,
 $\alpha^{(k)}: 2^M\rightarrow [0,1]$, and a {\em price}, $\beta^{(k)}\in \mathbb{R}$.
%
Here, we allow randomization, where  $\alpha^{(k)}(S)\in[0,1]$ denotes the
  probability that bundle $S\in 2^M$ is assigned to the bidder in menu element $k$. 
  % this assignment made independently of the 
  % assignment of some other item $j'\neq j$ (conditioned on the choice of
  % menu element $k$).
  %
   % \dcp{i'm wondering if this independent distribution is wlog for additive and unit-demand valuations---you can ask Sai and Michael if they know about anything.}
   %
  %
We refer to the menu $B$ as corresponding to a {\em menu-based representation 
of an auction.} The bidder with bid $b$ is assigned the element from menu $B$ that maximizes their utility according to the reported valuation: $k^*\in \arg\max_k \sum_{S\in 2^M}\alpha^{(k)}(S)b(S)-\beta^{(k)}$. We denote this optimal element by $(\alpha^*(b), \beta^*(b))$. 
The use of menu-based representations for auction design 
is without loss of generality and DSIC~\cite{hammond1979straightforward}.
%\dcp{need to explain how the allocation and payment rule is defined, via arg max given bid b and the menu} \dcp{need a bit more here, defining $\beta^*$ as the optimal element from menu $B$}
%
%In the context of menu-based auction design, the 
The optimal auction design problem is to find a menu-based representation that 
maximizes  expected revenue, i.e., $\mathbb{E}_{v\sim F}[ \beta^{*}(v)]$. Deep menu-based methods~\cite{dutting2024optimal,shen2019automated} in the differentiable economics literature~\cite{zheng2022ai,finocchiaro2021bridging,wang2023deep,ivanov2024principal,zhang2024position,hossain2024multi,rahme2020auction,ivanov2022optimal,curry2022differentiable,duan2023scalable} learn to generate such menus by neural networks.
%dcp cut among all  menus of a certain size.

% \tw{which means the number of elements in a menu?} \dcp{yes; now I say `among all menus` not `among all menu representations`. ok?}.  


\textbf{Diffusion Models and Continuous Normalizing Flow}. Diffusion models have  emerged as a powerful class of generative AI methods, spurring notable advances in a wide range of tasks such as image generation~\cite{rombach2022high,esser2024scaling}, video generation~\cite{ho2022video,ceylan2023pix2video,ho2022imagen}, molecular design~\cite{gruver2024protein}, text generation~\cite{lou2024discrete}, and multi-agent learning~\cite{wang2024diffusion}. At their core, these models perform a {\em forward noising process} in which noise is incrementally added to training data over multiple steps, gradually corrupting the original sample.
%\dcp{is `signal` right? or `sample`?} \tw{My opinion is that these works are rooted in the information theory, so they use "signal" a lot.} it's only used here in our paper, so I have dropped `signal`
%
A {\em reverse diffusion process} is then learned to iteratively remove noise, thereby reconstructing data from near-random initial states. In our setting, instead of reconstructing data, we extend the diffusion process to develop a tractable and differentiable method that optimizes a high-dimensional distribution.
%\tw{Do we need this here?}
%dcp -- yes, I like it

In particular, {\em score-based diffusion models} enjoy strong mathematical and physical underpinnings. The forward noising process is an {\em ItÃ´ stochastic differential equation} (SDE),
\begin{align}
    d\vx = \vf(\vx,t)dt + h(t)d\vw,
\end{align}
%
where $\vx(t) \in\mathbb{R}^\ell$ is the {\em state} at time $t$, for some $\ell\in \mathbb{Z}_{>0}$, $\vf(\cdot,t):\mathbb{R}^\ell\rightarrow\mathbb{R}^\ell$ is the {\em drift coefficient}, $h(\cdot):\mathbb{R}\rightarrow\mathbb{R}$ is the {\em diffusion coefficient}, and $\vw$ is the {\em standard Wiener process} (Brownian motion). Different forward processes are designed by specifying functional forms for $\vf(\cdot,t)$ and $h(\cdot)$. The generation of data is then based on the reverse process, which is  a diffusion process  given by the {\em reverse-time SDE}~\cite{anderson1982reverse},
%
\begin{align}
    d\vx = [\vf(\vx,t)-h(t)^2\nabla_\vx\log q_t(\vx)]dt + h(t)d\bar{\vw},\label{equ:r-sde}
\end{align}
%
where $dt$ is an infinitesimal negative timestep,  $\bar{\vw}$ is the {\em standard Brownian motion with reversed time flow},  and {\em $q_t(\vx)$ is the distribution of state  $\vx(t)$
at time $t$}.
The principal task in diffusion models is to learn the {\em score function}, $\nabla_\vx\log q_t(\vx)$, which has been effectively achieved using neural networks in recent work. This
enables solving the reverse-time SDE and  generating new data samples.  Notably, in the diffusion model  (and more broadly, generative AI) literature, $q_0(\vx)$ is typically a known target distribution over data samples from a pre-training dateset.
%\dcp{as $\vx_T$ given samples $\vs_0$?}

The reverse-time SDE (Eq.~\ref{equ:r-sde}) can be mathematically intricate, motivating the study of an equivalent, \emph{deterministic reverse process} modeled by an ordinary differential equation (ODE),
%
\begin{align}
    d\vx = [\vf(\vx,t)-\frac{1}{2}h(t)^2\nabla_\vx\log q_t(\vx)]dt,\label{equ:r-ode}
\end{align}
%
which  preserves the same marginal probability densities $\{q_t(\vx)\}_{t=0}^T$ as the SDE in Eq.~\ref{equ:r-sde}~\cite{song2021score}.
%
% Drawbacks of the normalizing flow include that we require the function $f$ to be invertible, and working its Jacobian might be expensive. We can consider a continuous version of normalizing flow where the function $f$ is applied an infinite time. 
%
Eq.~\ref{equ:r-ode} also highlights the connection between diffusion models and \emph{continuous normalizing flow}: each of them learns to transform and manipulate distributions by an ODE. Intuitively, a {\em continuous normalizing flow} transports an input $\vx_0\in \mathbb{R}^\ell$ to $\vx_t=\phi(t, \vx_0)$ at timestep $t\in[0,T]$.
%
Here, $\phi(t, \cdot):\mathbb{R}^\ell\rightarrow\mathbb{R}^\ell$ is the  \emph{flow}, and is governed by the ODE,
%
\begin{align}
    \frac{d}{dt}\vx_t = \varphi\left(t, \vx_t\right),\label{equ:f-ode}
\end{align}
%
where the vector field $\varphi: [0,T]\times \mathbb{R}^\ell\rightarrow \mathbb{R}^\ell$ specifies the  rate of
change of the state $\vx$.
%
Continuous normalizing flow \citep{chen2018neural} suggests to represent vector field $\varphi$ with a neural network. The flow $\phi$ transforms an initial distribution $p_0(\vx)$ to a final distribution $p_T(\vx)$ an time $T$.

% and the final distribution $p(z)=p_1(z_1)$ can be obtained by solving .

\textbf{Rectified Flow}. A bottleneck that restricts the use of continuous normalizing flow in large-scale problems is that the ODE (Eq.~\ref{equ:f-ode})
is hard to solve when the vector field $\varphi$ is complex.  The {\em rectified flow}~\cite{liu2022flow} addresses this by encouraging the flow to follow the linear path:
\begin{align}
    \min_\varphi \int_0^T \mathbb{E}_{\vx_0\sim p_0(\vx),\vx_T\sim p_T(\vx)}\left[\|(\vx_T-\vx_0)-\varphi(t, \vx_t)\|^2\right]dt, \ \ \ \vx_t = t\vx_T + (1-t)\vx_0.\label{equ:rf}
\end{align}

Here, the target distribution $p_T(\vx)$ (from which $\vx_T$ are sampled) and the initial distribution $p_0(\vx)$ (from which $\vx_0$ are sampled) are known. $\vx_t,t\in[0,T]$ is the interpolated point between $\vx_T$ and $\vx_0$, and the rectified flow encourages the vector field to align as closely as possible with the straight line $\vx_T-\vx_0$.

As discussed in the introduction, the application of diffusion models or continuous normalizing flow in generative AI tasks relies on access to a known target distribution $p_T(\vx)$, but in our optimal CA design task, $p_T(\vx)$ is unknown and needs to be optimized. 


% \dcp{same comment, do you want int from $0$ to $T$, and $Z_T$ not $Z_1$?}

% A rectified flow converting $X_0\sim p_0(\vx)$ to $X_T\sim p_1(z_1)$ \dcp{do you want $Z_T, p_T, z_T$ here?} is an ODE
% %
% \begin{align}
%     dZ_t = \varphi(t, Z_t) dt,
% \end{align}
%
% where $\varphi(t, Z_t)$ \dcp{earlier $\varphi(t, z_t)$}
% is trained to drive  $(Z_1-Z_0)$: