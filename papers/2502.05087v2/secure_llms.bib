@misc{cui2024diffusion,
      title={DiffusionShield: A Watermark for Copyright Protection against Generative Diffusion Models}, 
      author={Yingqian Cui and Jie Ren and Han Xu and Pengfei He and Hui Liu and Lichao Sun and Yue Xing and Jiliang Tang},
      year={2024},
      eprint={2306.04642},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2306.04642}, 
}

@misc{tang2023did,
      title={Did You Train on My Dataset? Towards Public Dataset Protection with Clean-Label Backdoor Watermarking}, 
      author={Ruixiang Tang and Qizhang Feng and Ninghao Liu and Fan Yang and Xia Hu},
      year={2023},
      eprint={2303.11470},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2303.11470}, 
}
@misc{li2023black,
      title={Black-box Dataset Ownership Verification via Backdoor Watermarking}, 
      author={Yiming Li and Mingyan Zhu and Xue Yang and Yong Jiang and Tao Wei and Shu-Tao Xia},
      year={2023},
      eprint={2209.06015},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2209.06015}, 
}

@article{langarizadeh2018dw,
  title={Effectiveness of anonymization methods in preserving patients' privacy: A systematic literature review},
  author={Langarizadeh, Mostafa and Orooji, Azam and Sheikhtaheri, Abbas},
  journal={Stud. Health Technol. Inform.},
  volume={248},
  year={2018}
}

@article{heider2020comp,
  title={A comparative analysis of speed and accuracy for three off-the-shelf {DE-identification} tools},
  author={Heider, Paul M and Obeid, Jihad S and Meystre, St{\'e}phane M},
  journal={AMIA Summits Transl. Sci. Proc.},
  volume={2020},
  year={2020}
}

@misc{kandpal2022dedup,
      title={Deduplicating Training Data Mitigates Privacy Risks in Language Models}, 
      author={Nikhil Kandpal and Eric Wallace and Colin Raffel},
      year={2022},
      eprint={2202.06539},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2202.06539}, 
}

@inproceedings{medmcqa,
  title = 	 {MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering},
  author =       {Pal, Ankit and Umapathi, Logesh Kumar and Sankarasubbu, Malaikannan},
  booktitle = 	 {Proceedings of the Conference on Health, Inference, and Learning},
  pages = 	 {248--260},
  year = 	 {2022},
  editor = 	 {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
  volume = 	 {174},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {07--08 Apr},
  publisher =    {PMLR},
  url = 	 {https://proceedings.mlr.press/v174/pal22a.html},
}

@misc{memo,
      title={Quantifying Memorization Across Neural Language Models}, 
      author={Nicholas Carlini and Daphne Ippolito and Matthew Jagielski and Katherine Lee and Florian Tramer and Chiyuan Zhang},
      year={2023},
      eprint={2202.07646},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2202.07646}, 
}

@InProceedings{koskela2020lr,
  title = 	 {Learning Rate Adaptation for Differentially Private Learning},
  author =       {Koskela, Antti and Honkela, Antti},
  booktitle = 	 {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
  pages = 	 {2465--2475},
  year = 	 {2020},
  editor = 	 {Chiappa, Silvia and Calandra, Roberto},
  volume = 	 {108},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {26--28 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v108/koskela20a/koskela20a.pdf},
  url = 	 {https://proceedings.mlr.press/v108/koskela20a.html},
}

@misc{tang2023dpadambc,
      title={DP-AdamBC: Your DP-Adam Is Actually DP-SGD (Unless You Apply Bias Correction)}, 
      author={Qiaoyue Tang and Frederick Shpilevskiy and Mathias Lécuyer},
      year={2023},
      eprint={2312.14334},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2312.14334}, 
}

@article{phi,
title = {Annotating longitudinal clinical narratives for de-identification: The 2014 i2b2/UTHealth corpus},
journal = {Journal of Biomedical Informatics},
volume = {58},
pages = {S20-S29},
year = {2015},
note = {Supplement: Proceedings of the 2014 i2b2/UTHealth Shared-Tasks and Workshop on Challenges in Natural Language Processing for Clinical Data},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2015.07.020},
url = {https://www.sciencedirect.com/science/article/pii/S1532046415001823},
author = {Amber Stubbs and Özlem Uzuner},
keywords = {Natural language processing, HIPAA, De-identification, Annotation},
}

@inproceedings{pubmedqa,
    title = "{P}ub{M}ed{QA}: A Dataset for Biomedical Research Question Answering",
    author = "Jin, Qiao  and
      Dhingra, Bhuwan  and
      Liu, Zhengping  and
      Cohen, William  and
      Lu, Xinghua",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1259",
    doi = "10.18653/v1/D19-1259",
    pages = "2567--2577",
}

@misc{medalpaca,
      title={MedAlpaca -- An Open-Source Collection of Medical Conversational AI Models and Training Data}, 
      author={Tianyu Han and Lisa C. Adams and Jens-Michalis Papaioannou and Paul Grundmann and Tom Oberhauser and Alexander Löser and Daniel Truhn and Keno K. Bressem},
      year={2023},
      eprint={2304.08247},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2304.08247}, 
}

@misc{meditron,
      title={MEDITRON-70B: Scaling Medical Pretraining for Large Language Models}, 
      author={Zeming Chen and Alejandro Hernández Cano and Angelika Romanou and Antoine Bonnet and Kyle Matoba and Francesco Salvi and Matteo Pagliardini and Simin Fan and Andreas Köpf and Amirkeivan Mohtashami and Alexandre Sallinen and Alireza Sakhaeirad and Vinitra Swamy and Igor Krawczuk and Deniz Bayazit and Axel Marmet and Syrielle Montariol and Mary-Anne Hartley and Martin Jaggi and Antoine Bosselut},
      year={2023},
      eprint={2311.16079},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.16079}, 
}

@inproceedings{mcmahan2016fedavg,
  title={Communication-Efficient Learning of Deep Networks from Decentralized Data},
  author={H. B. McMahan and Eider Moore and Daniel Ramage and Seth Hampson and Blaise Ag{\"u}era y Arcas},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2016},
  url={https://api.semanticscholar.org/CorpusID:14955348}
}

@misc{huang2022fl,
      title={Cross-Silo Federated Learning: Challenges and Opportunities}, 
      author={Chao Huang and Jianwei Huang and Xin Liu},
      year={2022},
      eprint={2206.12949},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2206.12949}, 
}

@misc{ye2024openfedllm,
      title={OpenFedLLM: Training Large Language Models on Decentralized Private Data via Federated Learning}, 
      author={Rui Ye and Wenhao Wang and Jingyi Chai and Dihan Li and Zexi Li and Yinda Xu and Yaxin Du and Yanfeng Wang and Siheng Chen},
      year={2024},
      eprint={2402.06954},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.06954}, 
}

@article{hu2021lora,
  author       = {Edward J. Hu and
                  Yelong Shen and
                  Phillip Wallis and
                  Zeyuan Allen{-}Zhu and
                  Yuanzhi Li and
                  Shean Wang and
                  Weizhu Chen},
  title        = {LoRA: Low-Rank Adaptation of Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2106.09685},
  year         = {2021},
  url          = {https://arxiv.org/abs/2106.09685},
  eprinttype    = {arXiv},
  eprint       = {2106.09685},
  timestamp    = {Tue, 29 Jun 2021 16:55:04 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2106-09685.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{li2018intrinsicdim,
      title={Measuring the Intrinsic Dimension of Objective Landscapes}, 
      author={Chunyuan Li and Heerad Farkhoor and Rosanne Liu and Jason Yosinski},
      year={2018},
      eprint={1804.08838},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1804.08838}, 
}

@misc{aghajanyan2020intrinsicdim,
      title={Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning}, 
      author={Armen Aghajanyan and Luke Zettlemoyer and Sonal Gupta},
      year={2020},
      eprint={2012.13255},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2012.13255}, 
}

@article{loraland,
  author    = {Timothy Wang and Justin Zhao and Will Van Eaton},
  title     = {LoRA Land: Fine-Tuned Open-Source LLMs that Outperform GPT-4},
  journal   = {Predibase Blog},
  year      = {2024},
  month     = {February},
  url       = {https://predibase.com/blog/lora-land-fine-tuned-open-source-llms-that-outperform-gpt-4}
}

@misc{ippolito2023verbatim,
      title={Preventing Verbatim Memorization in Language Models Gives a False Sense of Privacy}, 
      author={Daphne Ippolito and Florian Tramèr and Milad Nasr and Chiyuan Zhang and Matthew Jagielski and Katherine Lee and Christopher A. Choquette-Choo and Nicholas Carlini},
      year={2023},
      eprint={2210.17546},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2210.17546}, 
}

@misc{lee2022dedup,
      title={Deduplicating Training Data Makes Language Models Better}, 
      author={Katherine Lee and Daphne Ippolito and Andrew Nystrom and Chiyuan Zhang and Douglas Eck and Chris Callison-Burch and Nicholas Carlini},
      year={2022},
      eprint={2107.06499},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2107.06499}, 
}

@misc{powersgd,
      title={PowerSGD: Practical Low-Rank Gradient Compression for Distributed Optimization}, 
      author={Thijs Vogels and Sai Praneeth Karimireddy and Martin Jaggi},
      year={2020},
      eprint={1905.13727},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1905.13727}, 
}

@article{secfl,
  author    = {Tune Insight},
  title     = {Secure Federated Learning with Tune Insight encrypted computing platform},
  journal   = {LinkedIn Blogpost},
  year      = {2023},
  month     = {November},
  url       = {https://www.linkedin.com/pulse/secure-federated-learning-medical-images-tune-insight-encrypted-5q6pe}
}

@misc{wu2023pmcllama,
      title={PMC-LLaMA: Towards Building Open-source Language Models for Medicine}, 
      author={Chaoyi Wu and Weixiong Lin and Xiaoman Zhang and Ya Zhang and Yanfeng Wang and Weidi Xie},
      year={2023},
      eprint={2304.14454},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2304.14454}, 
}
@misc{singhal2023expert,
      title={Towards Expert-Level Medical Question Answering with Large Language Models}, 
      author={Karan Singhal and Tao Tu and Juraj Gottweis and Rory Sayres and Ellery Wulczyn and Le Hou and Kevin Clark and Stephen Pfohl and Heather Cole-Lewis and Darlene Neal and Mike Schaekermann and Amy Wang and Mohamed Amin and Sami Lachgar and Philip Mansfield and Sushant Prakash and Bradley Green and Ewa Dominowska and Blaise Aguera y Arcas and Nenad Tomasev and Yun Liu and Renee Wong and Christopher Semturs and S. Sara Mahdavi and Joelle Barral and Dale Webster and Greg S. Corrado and Yossi Matias and Shekoofeh Azizi and Alan Karthikesalingam and Vivek Natarajan},
      year={2023},
      eprint={2305.09617},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.09617}, 
}

@ARTICLE{singhal2023ka,
  title    = "Large language models encode clinical knowledge",
  author   = "Singhal, Karan and Azizi, Shekoofeh and Tu, Tao and Mahdavi, S
  Sara and Wei, Jason and Chung, Hyung Won and Scales, Nathan and
  Tanwani, Ajay and Cole-Lewis, Heather and Pfohl, Stephen and
  Payne, Perry and Seneviratne, Martin and Gamble, Paul and Kelly,
  Chris and Babiker, Abubakr and Sch{\"a}rli, Nathanael and
  Chowdhery, Aakanksha and Mansfield, Philip and Demner-Fushman,
  Dina and Ag{\"u}era y Arcas, Blaise and Webster, Dale and
  Corrado, Greg S and Matias, Yossi and Chou, Katherine and
  Gottweis, Juraj and Tomasev, Nenad and Liu, Yun and Rajkomar,
  Alvin and Barral, Joelle and Semturs, Christopher and
  Karthikesalingam, Alan and Natarajan, Vivek",
  journal  = "Nature",
  volume   =  620,
  number   =  7972,
  pages    = "172--180",
  month    =  aug,
  year     =  2023
}

@misc{medqa,
      title={What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams}, 
      author={Di Jin and Eileen Pan and Nassim Oufattole and Wei-Hung Weng and Hanyi Fang and Peter Szolovits},
      year={2020},
      eprint={2009.13081},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2009.13081}, 
}

@misc{mmlu,
      title={Measuring Massive Multitask Language Understanding}, 
      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
      year={2021},
      eprint={2009.03300},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2009.03300}, 
}

@inproceedings{jayaraman2019evaluating,
  title={Evaluating differentially private machine learning in practice},
  author={Jayaraman, Bargav and Evans, David},
  booktitle={28th USENIX Security Symposium (USENIX Security 19)},
  pages={1895--1912},
  year={2019}
}

@inproceedings{dwork2006calibrating,
  title={Calibrating noise to sensitivity in private data analysis},
  author={Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi and Smith, Adam},
  booktitle={Theory of Cryptography: Third Theory of Cryptography Conference, TCC 2006, New York, NY, USA, March 4-7, 2006. Proceedings 3},
  pages={265--284},
  year={2006},
  organization={Springer}
}

@inproceedings{brown2022does,
  title={What does it mean for a language model to preserve privacy?},
  author={Brown, Hannah and Lee, Katherine and Mireshghallah, Fatemehsadat and Shokri, Reza and Tram{\`e}r, Florian},
  booktitle={Proceedings of the 2022 ACM conference on fairness, accountability, and transparency},
  pages={2280--2292},
  year={2022}
}

@inproceedings {shokri2017mia,
author = { Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly },
booktitle = { 2017 IEEE Symposium on Security and Privacy (SP) },
title = {{ Membership Inference Attacks Against Machine Learning Models }},
year = {2017},
volume = {},
ISSN = {2375-1207},
pages = {3-18},
keywords = {Training;Data models;Predictive models;Privacy;Sociology;Statistics;Google},
doi = {10.1109/SP.2017.41},
url = {https://doi.ieeecomputersociety.org/10.1109/SP.2017.41},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = May
}

@article {chang2024miallm,
title={Context-Aware Membership Inference Attacks against Pre-trained Large Language Models}, 
author={Hongyan, Chang and Ali, Shahin Shamsabadi and Kleomenis, Katevas and Hamed, Haddadi and Reza, Shokri},
year={2024},
journal={arXiv preprint arXiv:2409.13745},
eprint={2409.13745},
archivePrefix={arXiv},
primaryClass={cs.CL},
url={https://arxiv.org/abs/2409.13745}, 
}

@inproceedings{kulynych2023arbitrary,
  title={Arbitrary decisions are a hidden cost of differentially private training},
  author={Kulynych, Bogdan and Hsu, Hsiang and Troncoso, Carmela and Calmon, Flavio P},
  booktitle={Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
  pages={1609--1623},
  year={2023}
}

@inproceedings{lukas2023analyzing,
  title={Analyzing leakage of personally identifiable information in language models},
  author={Lukas, Nils and Salem, Ahmed and Sim, Robert and Tople, Shruti and Wutschitz, Lukas and Zanella-B{\'e}guelin, Santiago},
  booktitle={2023 IEEE Symposium on Security and Privacy (SP)},
  pages={346--363},
  year={2023},
  organization={IEEE}
}

@inproceedings{feldman2020does,
  title={Does learning require memorization? a short tale about a long tail},
  author={Feldman, Vitaly},
  booktitle={Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing},
  pages={954--959},
  year={2020}
}

@article{dourish2004we,
  title={What we talk about when we talk about context},
  author={Dourish, Paul},
  journal={Personal and ubiquitous computing},
  volume={8},
  pages={19--30},
  year={2004},
  publisher={Springer}
}

@article{nissenbaum2004privacy,
  title={Privacy as contextual integrity},
  author={Nissenbaum, Helen},
  journal={Wash. L. Rev.},
  volume={79},
  pages={119},
  year={2004},
  publisher={HeinOnline}
}

@inproceedings{abadi2016deep,
  title={Deep learning with differential privacy},
  author={Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
  booktitle={Proceedings of the 2016 ACM SIGSAC conference on computer and communications security},
  pages={308--318},
  year={2016}
}

@article{liu2024differentially,
  title={Differentially private low-rank adaptation of large language model using federated learning},
  author={Liu, Xiao-Yang and Zhu, Rongyi and Zha, Daochen and Gao, Jiechao and Zhong, Shan and White, Matt and Qiu, Meikang},
  journal={ACM Transactions on Management Information Systems},
  year={2024},
  publisher={ACM New York, NY}
}

@article{li2021large,
  title={Large language models can be strong differentially private learners},
  author={Li, Xuechen and Tramer, Florian and Liang, Percy and Hashimoto, Tatsunori},
  journal={arXiv preprint arXiv:2110.05679},
  year={2021}
}

@inproceedings{tramer2022position,
  title={Position: Considerations for Differentially Private Learning with Large-Scale Public Pretraining},
  author={Tram{\`e}r, Florian and Kamath, Gautam and Carlini, Nicholas},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2022}
}

@inproceedings{carlini2019secret,
  title={The secret sharer: Evaluating and testing unintended memorization in neural networks},
  author={Carlini, Nicholas and Liu, Chang and Erlingsson, {\'U}lfar and Kos, Jernej and Song, Dawn},
  booktitle={28th USENIX security symposium (USENIX security 19)},
  pages={267--284},
  year={2019}
}

@article{ramaswamy2020training,
  title={Training production language models without memorizing user data},
  author={Ramaswamy, Swaroop and Thakkar, Om and Mathews, Rajiv and Andrew, Galen and McMahan, H Brendan and Beaufays, Fran{\c{c}}oise},
  journal={arXiv preprint arXiv:2009.10031},
  year={2020}
}

@article{carlini2022quantifying,
  title={Quantifying memorization across neural language models},
  author={Carlini, Nicholas and Ippolito, Daphne and Jagielski, Matthew and Lee, Katherine and Tramer, Florian and Zhang, Chiyuan},
  journal={arXiv preprint arXiv:2202.07646},
  year={2022}
}

@article{hans2024goldfish,
  title={Be like a Goldfish, Don't Memorize! Mitigating Memorization in Generative LLMs},
  author={Hans, Abhimanyu and Wen, Yuxin and Jain, Neel and Kirchenbauer, John and Kazemi, Hamid and Singhania, Prajwal and Singh, Siddharth and Somepalli, Gowthami and Geiping, Jonas and Bhatele, Abhinav and others},
  journal={arXiv preprint arXiv:2406.10209},
  year={2024}
}

@article{jagielski2022measuring,
  title={Measuring forgetting of memorized training examples},
  author={Jagielski, Matthew and Thakkar, Om and Tramer, Florian and Ippolito, Daphne and Lee, Katherine and Carlini, Nicholas and Wallace, Eric and Song, Shuang and Thakurta, Abhradeep and Papernot, Nicolas and others},
  journal={arXiv preprint arXiv:2207.00099},
  year={2022}
}

@article{nasr2023scalable,
  title={Scalable extraction of training data from (production) language models},
  author={Nasr, Milad and Carlini, Nicholas and Hayase, Jonathan and Jagielski, Matthew and Cooper, A Feder and Ippolito, Daphne and Choquette-Choo, Christopher A and Wallace, Eric and Tram{\`e}r, Florian and Lee, Katherine},
  journal={arXiv preprint arXiv:2311.17035},
  year={2023}
}

@inproceedings{carlini2021extracting,
  title={Extracting training data from large language models},
  author={Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Ulfar and others},
  booktitle={30th USENIX Security Symposium (USENIX Security 21)},
  pages={2633--2650},
  year={2021}
}

@inproceedings{mcmahan2017communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial intelligence and statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}

@article{kairouz2021advances,
  title={Advances and open problems in federated learning},
  author={Kairouz, Peter and McMahan, H Brendan and Avent, Brendan and Bellet, Aur{\'e}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and others},
  journal={Foundations and trends{\textregistered} in machine learning},
  volume={14},
  number={1--2},
  pages={1--210},
  year={2021},
  publisher={Now Publishers, Inc.}
}

@article{thakkar2020understanding,
  title={Understanding unintended memorization in federated learning},
  author={Thakkar, Om and Ramaswamy, Swaroop and Mathews, Rajiv and Beaufays, Fran{\c{c}}oise},
  journal={arXiv preprint arXiv:2006.07490},
  year={2020}
}

@article{hard2018federated,
  title={Federated learning for mobile keyboard prediction},
  author={Hard, Andrew and Rao, Kanishka and Mathews, Rajiv and Ramaswamy, Swaroop and Beaufays, Fran{\c{c}}oise and Augenstein, Sean and Eichner, Hubert and Kiddon, Chlo{\'e} and Ramage, Daniel},
  journal={arXiv preprint arXiv:1811.03604},
  year={2018}
}

@article{lehman2021does,
  title={Does BERT pretrained on clinical notes reveal sensitive data?},
  author={Lehman, Eric and Jain, Sarthak and Pichotta, Karl and Goldberg, Yoav and Wallace, Byron C},
  journal={arXiv preprint arXiv:2104.07762},
  year={2021}
}

@article{johnson2016mimic,
  title={MIMIC-III, a freely accessible critical care database},
  author={Johnson, Alistair EW and Pollard, Tom J and Shen, Lu and Lehman, Li-wei H and Feng, Mengling and Ghassemi, Mohammad and Moody, Benjamin and Szolovits, Peter and Anthony Celi, Leo and Mark, Roger G},
  journal={Scientific data},
  volume={3},
  number={1},
  pages={1--9},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{murphy2010serving,
  title={Serving the enterprise and beyond with informatics for integrating biology and the bedside (i2b2)},
  author={Murphy, Shawn N and Weber, Griffin and Mendis, Michael and Gainer, Vivian and Chueh, Henry C and Churchill, Susanne and Kohane, Isaac},
  journal={Journal of the American Medical Informatics Association},
  volume={17},
  number={2},
  pages={124--130},
  year={2010},
  publisher={BMJ Group}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{tirumala2022memorization,
  title={Memorization without overfitting: Analyzing the training dynamics of large language models},
  author={Tirumala, Kushal and Markosyan, Aram and Zettlemoyer, Luke and Aghajanyan, Armen},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={38274--38290},
  year={2022}
}

@article{antunes2022federated,
  title={Federated learning for healthcare: Systematic review and architecture proposal},
  author={Antunes, Rodolfo Stoffel and Andr{\'e} da Costa, Cristiano and K{\"u}derle, Arne and Yari, Imrana Abdullahi and Eskofier, Bj{\"o}rn},
  journal={ACM Transactions on Intelligent Systems and Technology (TIST)},
  volume={13},
  number={4},
  pages={1--23},
  year={2022},
  publisher={ACM New York, NY}
}

@article{nguyen2022federated,
  title={Federated learning for smart healthcare: A survey},
  author={Nguyen, Dinh C and Pham, Quoc-Viet and Pathirana, Pubudu N and Ding, Ming and Seneviratne, Aruna and Lin, Zihuai and Dobre, Octavia and Hwang, Won-Joo},
  journal={ACM Computing Surveys (Csur)},
  volume={55},
  number={3},
  pages={1--37},
  year={2022},
  publisher={ACM New York, NY}
}

@article{xu2021federated,
  title={Federated learning for healthcare informatics},
  author={Xu, Jie and Glicksberg, Benjamin S and Su, Chang and Walker, Peter and Bian, Jiang and Wang, Fei},
  journal={Journal of healthcare informatics research},
  volume={5},
  pages={1--19},
  year={2021},
  publisher={Springer}
}

@article{truex2019hybrid,
  author    = {Truex, Sherri and Baracaldo, Nathalie and Anwar, Anjum and others},
  title     = {A Hybrid Approach to Privacy-Preserving Federated Learning},
  journal   = {Informatik Spektrum},
  volume    = {42},
  pages     = {356--357},
  year      = {2019},
  month     = {October},
  doi       = {10.1007/s00287-019-01205-x},
  url       = {https://doi.org/10.1007/s00287-019-01205-x},
  publisher = {Springer},
  note      = {Published: 30 August 2019}
}

@misc{sebert2022fhedp,
      title={Protecting Data from all Parties: Combining FHE and DP in Federated Learning}, 
      author={Arnaud Grivet Sébert and Renaud Sirdey and Oana Stan and Cédric Gouy-Pailler},
      year={2022},
      eprint={2205.04330},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2205.04330}, 
}

@article{mireshghallah2022quantifying,
  title={Quantifying privacy risks of masked language models using membership inference attacks},
  author={Mireshghallah, Fatemehsadat and Goyal, Kartik and Uniyal, Archit and Berg-Kirkpatrick, Taylor and Shokri, Reza},
  journal={arXiv preprint arXiv:2203.03929},
  year={2022}
}

@misc{touvron2023llama2,
      title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
      author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
      year={2023},
      eprint={2307.09288},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.09288}, 
}

@misc{jiang2023mistral7b,
      title={Mistral 7B}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2023},
      eprint={2310.06825},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.06825}, 
}

@misc{huang2024demyst,
      title={Demystifying Verbatim Memorization in Large Language Models}, 
      author={Jing Huang and Diyi Yang and Christopher Potts},
      year={2024},
      eprint={2407.17817},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.17817}, 
}

@misc{jagielski2023forget,
      title={Measuring Forgetting of Memorized Training Examples}, 
      author={Matthew Jagielski and Om Thakkar and Florian Tramèr and Daphne Ippolito and Katherine Lee and Nicholas Carlini and Eric Wallace and Shuang Song and Abhradeep Thakurta and Nicolas Papernot and Chiyuan Zhang},
      year={2023},
      eprint={2207.00099},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2207.00099}, 
}

@misc{wolf2020hugging,
      title={HuggingFace's Transformers: State-of-the-art Natural Language Processing}, 
      author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
      year={2020},
      eprint={1910.03771},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1910.03771}, 
}

@misc{loshchilov2019adamw,
      title={Decoupled Weight Decay Regularization}, 
      author={Ilya Loshchilov and Frank Hutter},
      year={2019},
      eprint={1711.05101},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1711.05101}, 
}

@article{shi2023detecting,
  title={Detecting pretraining data from large language models},
  author={Shi, Weijia and Ajith, Anirudh and Xia, Mengzhou and Huang, Yangsibo and Liu, Daogao and Blevins, Terra and Chen, Danqi and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2310.16789},
  year={2023}
}

@inproceedings{kiyomaru2024comprehensive,
  title={A Comprehensive Analysis of Memorization in Large Language Models},
  author={Kiyomaru, Hirokazu and Sugiura, Issa and Kawahara, Daisuke and Kurohashi, Sadao},
  booktitle={Proceedings of the 17th International Natural Language Generation Conference},
  pages={584--596},
  year={2024}
}

@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}

@article{thirunavukarasu2023large,
  title={Large language models in medicine},
  author={Thirunavukarasu, Arun James and Ting, Darren Shu Jeng and Elangovan, Kabilan and Gutierrez, Laura and Tan, Ting Fang and Ting, Daniel Shu Wei},
  journal={Nature medicine},
  volume={29},
  number={8},
  pages={1930--1940},
  year={2023},
  publisher={Nature Publishing Group US New York}
}

@article{wu2023bloomberggpt,
  title={Bloomberggpt: A large language model for finance},
  author={Wu, Shijie and Irsoy, Ozan and Lu, Steven and Dabravolski, Vadim and Dredze, Mark and Gehrmann, Sebastian and Kambadur, Prabhanjan and Rosenberg, David and Mann, Gideon},
  journal={arXiv preprint arXiv:2303.17564},
  year={2023}
}

@inproceedings{li2023large,
  title={Large language models in finance: A survey},
  author={Li, Yinheng and Wang, Shaofei and Ding, Han and Chen, Hang},
  booktitle={Proceedings of the fourth ACM international conference on AI in finance},
  pages={374--382},
  year={2023}
}

@article{yang2022large,
  title={A large language model for electronic health records},
  author={Yang, Xi and Chen, Aokun and PourNejatian, Nima and Shin, Hoo Chang and Smith, Kaleb E and Parisien, Christopher and Compas, Colin and Martin, Cheryl and Costa, Anthony B and Flores, Mona G and others},
  journal={NPJ digital medicine},
  volume={5},
  number={1},
  pages={194},
  year={2022},
  publisher={Nature Publishing Group UK London}
}


@article{geiping2020inverting,
  title={Inverting gradients-how easy is it to break privacy in federated learning?},
  author={Geiping, Jonas and Bauermeister, Hartmut and Dr{\"o}ge, Hannah and Moeller, Michael},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={16937--16947},
  year={2020}
}

@article{huang2021evaluating,
  title={Evaluating gradient inversion attacks and defenses in federated learning},
  author={Huang, Yangsibo and Gupta, Samyak and Song, Zhao and Li, Kai and Arora, Sanjeev},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={7232--7241},
  year={2021}
}


@article{el2022differential,
  title={Differential privacy for deep and federated learning: A survey},
  author={El Ouadrhiri, Ahmed and Abdelhadi, Ahmed},
  journal={IEEE access},
  volume={10},
  pages={22359--22380},
  year={2022},
  publisher={IEEE}
}

@article{dettmers2024qlora,
  title={Qlora: Efficient finetuning of quantized llms},
  author={Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{mouchet2020lattigo,
title={Lattigo: A multiparty homomorphic encryption library in Go},
ISBN={978-3-000677-98-4},
url={https://infoscience.epfl.ch/handle/20.500.14299/193451},
DOI={10.25835/0072999},
booktitle={8th Workshop on Encrypted Computing \& Applied Homomorphic Cryptography (WAHC 2020)},
author={Mouchet, Christian Vincent and Bossuat, Jean-Philippe and Troncoso-Pastoriza, Juan Ramón and Hubaux, Jean-Pierre},
year={2020},
pages={64–70},
journal={Proceedings of the 8th Workshop on Encrypted Computing and Applied Homomorphic Cryptography},
keywords={Homomorphic Encryption | Secure Multiparty Computation | Implementation}
}

@misc{lattigo,
    title = {Lattigo open-source repository},
    howpublished = {Online: \url{https://github.com/tuneinsight/lattigo}},
    month = Aug,
    year = 2024,
    note = {EPFL-LDS, Tune Insight SA},
    key = {Lattigo v6}
}

@article{schwarzschild2024rethinking,
  title={Rethinking llm memorization through the lens of adversarial compression},
  author={Schwarzschild, Avi and Feng, Zhili and Maini, Pratyush and Lipton, Zachary C and Kolter, J Zico},
  journal={arXiv preprint arXiv:2404.15146},
  year={2024}
}

@article{gupta2022recovering,
  title={Recovering private text in federated learning of language models},
  author={Gupta, Samyak and Huang, Yangsibo and Zhong, Zexuan and Gao, Tianyu and Li, Kai and Chen, Danqi},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={8130--8143},
  year={2022}
}

@article{zhu2019deep,
  title={Deep leakage from gradients},
  author={Zhu, Ligeng and Liu, Zhijian and Han, Song},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{wu2023depn,
  title={Depn: Detecting and editing privacy neurons in pretrained language models},
  author={Wu, Xinwei and Li, Junzhuo and Xu, Minghui and Dong, Weilong and Wu, Shuangzhi and Bian, Chao and Xiong, Deyi},
  journal={arXiv preprint arXiv:2310.20138},
  year={2023}
}

@article{tang2024benign,
  title={Benign Overfitting in Out-of-Distribution Generalization of Linear Models},
  author={Tang, Shange and Wu, Jiayun and Fan, Jianqing and Jin, Chi},
  journal={arXiv preprint arXiv:2412.14474},
  year={2024}
}

@article{bartlett2020benign,
  title={Benign overfitting in linear regression},
  author={Bartlett, Peter L and Long, Philip M and Lugosi, G{\'a}bor and Tsigler, Alexander},
  journal={Proceedings of the National Academy of Sciences},
  volume={117},
  number={48},
  pages={30063--30070},
  year={2020},
  publisher={National Acad Sciences}
}

@inproceedings{rothchild2020fetchsgd,
  title={Fetchsgd: Communication-efficient federated learning with sketching},
  author={Rothchild, Daniel and Panda, Ashwinee and Ullah, Enayat and Ivkin, Nikita and Stoica, Ion and Braverman, Vladimir and Gonzalez, Joseph and Arora, Raman},
  booktitle={International Conference on Machine Learning},
  pages={8253--8265},
  year={2020},
  organization={PMLR}
}

@article{ivkin2019communication,
  title={Communication-efficient distributed SGD with sketching},
  author={Ivkin, Nikita and Rothchild, Daniel and Ullah, Enayat and Stoica, Ion and Arora, Raman and others},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{makkuva2023laser,
  title={Laser: Linear compression in wireless distributed optimization},
  author={Makkuva, Ashok Vardhan and Bondaschi, Marco and Vogels, Thijs and Jaggi, Martin and Kim, Hyeji and Gastpar, Michael C},
  journal={arXiv preprint arXiv:2310.13033},
  year={2023}
}

@article{rabbani2021comfetch,
  title={Comfetch: Federated Learning of Large Networks on Memory-Constrained Clients via Sketching},
  author={Rabbani, Tahseen and Feng, Brandon and Yang, Yifan and Rajkumar, Arjun and Varshney, Amitabh and Huang, Furong},
  journal={arXiv e-prints},
  pages={arXiv--2109},
  year={2021}
}

@inproceedings{dorfman2023docofl,
  title={DoCoFL: Downlink compression for cross-device federated learning},
  author={Dorfman, Ron and Vargaftik, Shay and Ben-Itzhak, Yaniv and Levy, Kfir Yehuda},
  booktitle={International Conference on Machine Learning},
  pages={8356--8388},
  year={2023},
  organization={PMLR}
}

@article{elesedy2023u,
  title={U-clip: On-average unbiased stochastic gradient clipping},
  author={Elesedy, Bryn and Hutter, Marcus},
  journal={arXiv preprint arXiv:2302.02971},
  year={2023}
}

@inproceedings{karimireddy2019error,
  title={Error feedback fixes signsgd and other gradient compression schemes},
  author={Karimireddy, Sai Praneeth and Rebjock, Quentin and Stich, Sebastian and Jaggi, Martin},
  booktitle={International Conference on Machine Learning},
  pages={3252--3261},
  year={2019},
  organization={PMLR}
}

@inproceedings{bernstein2018signsgd,
  title={signSGD: Compressed optimisation for non-convex problems},
  author={Bernstein, Jeremy and Wang, Yu-Xiang and Azizzadenesheli, Kamyar and Anandkumar, Animashree},
  booktitle={International Conference on Machine Learning},
  pages={560--569},
  year={2018},
  organization={PMLR}
}

@inproceedings{kenton2019bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina},
  booktitle={Proceedings of naacL-HLT},
  volume={1},
  pages={2},
  year={2019},
  organization={Minneapolis, Minnesota}
}

@inproceedings{gurbuzbalaban2021heavy,
  title={The heavy-tail phenomenon in SGD},
  author={Gurbuzbalaban, Mert and Simsekli, Umut and Zhu, Lingjiong},
  booktitle={International Conference on Machine Learning},
  pages={3964--3975},
  year={2021},
  organization={PMLR}
}