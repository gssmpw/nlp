\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/applications.pdf}
    \caption{\toolkit~can be used for versatile applications, such as for (a) physical motion guidance for strength exercises, (b) haptic feedback in VR, (c) collaborative body-actuated plays, and (d) artistic modulation of motion in real-time.
    }
    \label{fig:applications}
    \Description{ExoKit applications. (a) A person wears the exoskeleton with three actuated DoFs at the right arm. The person performs a strengthening exercise for the arms. The application is described in detail in the corresponding paragraph. (b) A user wears a 6 DoF exoskeleton and a VR headset. The user controls a virtual bird’s wings in VR while the exoskeleton resists the user’s motion to mimic air resistance. (c) Two people are playing a game. One person wears a sensing exoskeleton arm and the other a fully actuated one. The first person controls the other's arm movements to place colored rings on a repurposed ring toss game scaffold. (d) A person is dancing to music, while the exoskeleton adds jerks to arm movements through six actuated DoFs.}
\end{figure*}
\section{Validation}
We follow Ledo et al.'s strategies for evaluating HCI toolkits~\cite{ledo_2018}: (1)~With implemented functional example applications, we demonstrate how \toolkit~enables designers to easily customize exoskeleton's design and interactive behavior. (2)~With our first usage study, which combines elements of walkthrough demonstrations and free exploration, we gather insights in \toolkit's utility. (3) Finally, with a second usage study, in which participants built their own application with ExoKit, we gained insights into users' workflows and encountered challenges.


\subsection{Example Applications}\label{sec:applications}
We illustrate the broad applicability of \toolkit~ with four implemented application examples. These are illustrated in Figure~\ref{fig:applications}.
The examples have been selected to cover different application areas, exoskeleton configurations, and augmentation strategies. All have been implemented with the Arduino firmware. We report on the first one in more detail to demonstrate the workflow. 

\paragraphB{Designing motion guidance for strength exercises}
A promising area of exoskeletons is rehabilitation and home therapy. We used \toolkit~to assist in the correct execution of an upper arm exercise aimed at strengthening muscles, inspired by an example provided in Physio@Home~\cite{tang_2015}. In this exercise, the user stretches their arm out sideways and moves it up and down repetitively, ensuring the arms don’t leave the body plane. At the same time, the elbow must remain fully extended throughout the exercise. The exoskeleton’s role is to help the user maintain proper form during execution (Figure~\ref{fig:applications}a).
We began by addressing how to keep the user's shoulder movement aligned within the body’s side plane. To do this, we built an exoskeleton with an actuated joint at the shoulder (on the side) to modify sideway shoulder motions, along with a passive joint at the back. Initially, we used the \textit{constrainTo} function to lock the user's movement within a narrow area inside the desired body plane. However, we noticed that this reduces the user’s agency substantially. To give the user more control, we switched to the \textit{guideTowards} function, which guides the user back toward the desired plane. Since the shoulder can exert significant forces during this motion, we leveraged a stronger Dynamixel motor (XM540-W270-T). This motor provides enough power to apply both assisting and resisting forces at the shoulder and we fine-tuned the torques to be effective yet gentle. 
Once satisfied with the shoulder motion, we integrated an actuated joint for the elbow, using the weakest Dynamixel motor (XM430-W210-T) and added a \textit{lock} function to ensure that the elbow does not drift from the desired position as the user moves.


\paragraphB{Kinesthetic feedback for avatar embodiment in VR\@}
An important research area in VR is providing haptic feedback~\cite{teng_2022,gu_2016}. We implemented a VR environment that uses \toolkit~to create immersive kinesthetic feedback for embodying the motion of an avatar. In our application, a flying game, the user can control the motion of an avatar's wings, by moving one's arms, and feel the corresponding kinesthetic real-time feedback~(see Figure~\ref{fig:applications}b).
For instance, when embodying a dragon, characterized by heavy, powerful movements, a designer can adjust the exoskeleton’s 6 actuated DoFs with the \textit{resist} function to increase resistance, simulating large, forceful wing beats. Conversely, for a sparrow, with its fast and light motions, the designer can reduce resistance or even employ the \textit{amplify} feature to emphasize the sparrow's agility. Through iterative testing and adjustment of the \textit{resist} and \textit{amplify} parameters, we can fine-tune the kinesthetic feedback, creating avatar-specific haptic experiences.


\paragraphB{Collaborative body-actuated play}
Body-actuated play~\cite{patibanda_2022} leverages body-actuating technologies for novel kinds of creative, shared bodily experiences. Using \toolkit, we developed a collaborative game that demonstrates how designers can craft interactions between multiple players each wearing an exoskeleton. In this game, one player ~(P1) controls the body movements of another player~(P2). The  goal is to solve a physical color sorting game by making P2 sort as many rings correctly as time permits. 
P1 is wearing a 3-DoF exoskeleton arm with sensing capabilities that captures her movements. P2 wears a fully actuated 3-DoF exoskeleton that mirrors P1's motion in real time~
(see Figure~\ref{fig:applications}c). This behavior was rapidly implemented with the toolkit’s \textit{mirror} function, which supports customizable body remapping strategies in few lines of code. 
To make the game more demanding for advanced players, we developed a second level that adjusted how the transferred motions are scaled by changing one parameter in the software. Finally, we implemented a third level, that goes beyond a direct 1:1 mapping of body parts and instead maps P1's sideways shoulder motions onto P2's elbow motions, and P1's elbow motions onto P2's shoulder joint to challenge coordination. 

\paragraphB{Enhanced artistic performances}
Exoskeletons also offer interesting applications for artistic performances. Using \toolkit, we developed an arm exoskeleton that artistically modifies a dancer’s movements in real time. The dancer defines and executes the overall motion of the arms, while the exoskeleton enhances the style of the motion to be more jerky and robot-like~(see Figure~\ref{fig:applications}d).
By leveraging the pre-implemented \textit{jerk} function, the designer can introduce variability in the dancer’s movements, making them more abrupt. 
Designers can easily adjust jerk parameters, such as amplitude, frequency, and velocity, to suit the performance, from subtle modifications to exaggerated effects. 
Moreover, the toolkit allows designers to easily implement specific body gestures that serve as triggers for starting and stopping the motion augmentation. We implemented an ``arm stretched out'' gesture~(elbow is at 0 degree angle) for triggering the motion style modulation, ensuring the augmentation aligns with the dancer's intent and preferences.


% ---------------------------------

\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/workshop.pdf}
    \caption{Workshop participants first familiarized themselves with the provided prototype~(a), put it on and collaboratively adjusted the link sizes~(b, c), and experienced the provided functions on their bodies~(d, e).}
    \label{fig:workshop}
    \Description{(a) Participants standing around a mannequin wearing the exoskeleton prototype. (b) One participant wears the exoskeleton while another participant screws some chain segments at the lower arm to adjust the size to the user's dimension. (c) A similar scene with different participants. (d) One participant hands over an object to another participant who wears an exoskeleton. (e) Participant waves.}
\end{figure*}

\subsection{Usage Study 1: Experiencing ExoKit}
The objective of the first study was to gain insights into \toolkit's utility, understand how it aligns with the key design requirements, and identify opportunities for improvement. 

\subsubsection{Method}
To address this objective, we conducted a usage study with six participants in two workshop sessions. The workshop setting has been proven useful to evaluate toolkits in prior work~(e.g.,~\cite{pfeiffer_2016,sabnis_2023,lei_2022}). Each workshop combined walkthrough demonstrations~(cf.,~\cite{ledo_2018}), where participants are presented with ExoKit's functionalities, with phases of free exploration and discussion. 

\paragraphB{Participants} The first workshop was conducted with three participants experienced in interaction design, representing our target group of novice roboticists: a postdoctoral researcher experienced in interaction design for VR/AR~(ID1, 28, male) and two graduate students~(ID2 \& ID3, both 23, female and male) with research experience in interaction design for wearables and first hands-on experience with exoskeletons, respectively. The second session comprised three participants experienced in hardware and fabrication, serving as technical experts to provide feedback on the design and potential improvements: a postdoctoral researcher working on robotics and haptics~(HF1, 32, male), a PhD student primarily experienced in fabrication~(HF2, 24, female), and an undergraduate student with more than ten years of hardware tinkering experience~(HF3, 31, male). 

\paragraphB{Procedure} 
After providing informed consent, we introduced the workshop participants to \toolkit, presenting its conceptual space~(Figure~\ref{fig:conceptual_space}) and physical hardware components~(Section~\ref{sec:hardware}). 
Participants received an exoskeleton consisting of one fully actuated and one sensing arm, as well as a printed manual for all provided interface functions. 
In the first half of each workshop, they familiarized themselves with the functions offered by \toolkit~while the exoskeleton was still attached to a mannequin~(\autoref{fig:workshop}a). 
In the second half, each participant was prompted to wear the prototype and encouraged to adjust its components to fit their body~(\autoref{fig:workshop}b,c). Taking turns, the other group members then used the command-line interface to trigger desired functions~(\autoref{fig:workshop}d,e). 
The workshop was interleaved with rounds of discussion and short brainstorming sessions. 
Sessions were audio- and video-recorded for later analysis. Each session took 3 hours. 



\subsubsection{Results}
We collected findings based on our observations of participants' behaviors and statements. We group these results along key design considerations of \toolkit:


\paragraphB{Explorative, creative and iterative design}
Most importantly, in both workshops, the toolkit fostered a playful exploration of human-exoskeleton interactions, especially enabling rapid iterations on design parameters for various functionalities. Notably, the hardware group engaged deeply with extreme parameter settings to test the toolkit's limits, and quickly adopted a creative designer's perspective. For instance, they spontaneously crafted challenges for each other by leveraging motion transfer functions, where unconventional body remappings~(such as mapping a shoulder movement onto the elbow) complicated the fulfillment of the challenge~(\autoref{fig:workshop}d). HF2 later highlighted how this could bear potential to design fun collaborative and creativity-based interactions between users.
Similarly, in the interaction group, the exploration of resistance and amplification, and how these affected the body movements, immediately sparked ideas for possible applications, including a simulated weight-lifting in VR or leveraging them for avatar embodiment. 

In a follow-up brainstorming session, participants proposed more ideas across various domains: Ideas in healthcare included providing adaptive support for weak arms (ID2) and mirroring motions between therapists and patients to aid rehabilitation~(HF2). ID3 envisioned teleoperation scenarios, such as controlling a fatigued arm with the opposite limb during physically demanding tasks like wall painting. ID2 and ID3 also discussed about social applications, like providing hugs over a distance, enhanced with thermal feedback. Ideas for leisure and gaming featured interactive game interfaces and leveraging the exoskeleton to teach dancing or other sports~(HF2). Finally, participants also highlighted \toolkit’s prospective applications for STEM education~(ID2, ID3).

\paragraphB{Programmability and functional abstractions}
Participants found the provided functional abstractions generally easy to understand and quickly grasped the concepts. They further appreciated the offered parameters which allow to rapidly modify the strategies' effects, such as tuning the motion style with different jerk parameters, or experimenting with varying torques applied for the motion effort strategies. This underlines the toolkit's potential to empower its users to leverage complex exoskeleton functionalities encapsulated by the identified functional abstractions. 
Further, participants acknowledged that the provided functional abstractions provide a broad and generic support for various applications. HF3 indicated that for more specialized purposes, it would be advantageous if the designer can define their own augmentation strategies building upon the provided functionalities. This resonates with the different ways of programming offered by \toolkit~(cf. Figure~\ref{fig:programmability}), which facilitate the customization of new interactive behaviors. 
Finally, both groups suggested that for an initial interactive exploration of the provided augmentation strategies, a graphical user interface that visualizes predefined input parameter ranges for different functions would be a promising extension\footnote{Of note, the GUI presented in \autoref{subsec:interfaces} was implemented in response to this feedback.}.


\paragraphB{Wearability}
Both groups successfully adapted the exoskeleton’s size by adjusting the link lengths to their body sizes, demonstrating how the modular components can enhance ergonomics. The interaction group expressed themselves particularly positive about the wearing comfort and lightweight design. Especially ID2, who was familiar with other open-source exoskeleton prototypes, acknowledged that the prototype built with \toolkit~enhanced comfort. Finally, the hardware group offered suggestions to further improve wearability, as they criticized that attaching and detaching the prototype currently requires a second person. For instance, they suggested using more easily attachable backpack straps instead of the postural corrector, and sewing the joint elements directly onto some fabric to further enhance stability.


\paragraphB{Customizability of hardware}
To further customize \toolkit~to the versatile needs of HCI researchers, both groups emphasized the importance of being able to integrate additional sensing and actuation mechanisms, such as thermal feedback or vibration. This requirement is already supported by \toolkit's current infrastructure which is intentionally built on Arduino and thereof naturally compatible with a wide set of commonly used, relevant electronics. Additionally, HF3, who has a strong background in hobby tinkering, requested support for low-cost joint modules as the currently supported Dynamixel motors are comparatively expensive for private use beyond research.


% ---------------------------------

\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/soloDIY.pdf}
    \caption{Participants used ExoKit's software and hardware components~(a) to implement an application of their choice: 
    P1 created a sound synthesizer~(b), P2 an exoskeleton that teaches how to do an underhand toss~(c), and P3 a rowing application~(d).}
    \label{fig:solodiy}
    \Description{(a) A participant sits in front of a table. Around him, ExoKit's hardware components are spread out. Two screens in front of him display the user manual and a programming interface. (b)-(d) is a visual representation of the built applications which are described in subsection 6.3.}
\end{figure*}

\subsection{Usage Study 2: Prototyping with ExoKit}

The goal of the second study was to gain rich qualitative insights into how users approach the toolkit to build an application, their workflows, the components they would use and encountered challenges.

\subsubsection{Method}
Inspired by Lei et al.~\cite{lei_2022}, we conducted a usage study in which users engaged with ExoKit over a longer period of time. 

\paragraphB{Participants} We recruited three participants from the target group, all with an interest in learning about human-exoskeleton interactions: an undergraduate student with some theoretical knowledge of human-exoskeleton interaction who self-reported basic electronics and programming skills~(P1, 22, male), a graduate student with some background in design and fabrication of actuated systems, good electronics and basic programming skills ~(P2, 28, male), and a PhD student in HCI interested in sports and accessibility without any prior robotics experience but basic electronics and good programming skills (P3, 26, male).

\paragraphB{Procedure} Participants worked in a quiet space equipped with ExoKit (software, tools, user manual) and pre-fabricated hardware modules~(\autoref{fig:solodiy}a). In response to the feedback from usage study~1, we additionally introduced a GUI to facilitate first-time exploration, replacing the command-line interface~(cf., \autoref{subsec:interfaces}).
Participants were tasked with creating a functional human-exoskeleton interaction for an application of their choice, with no time constraints. The only requirement was to present a live demonstration at the end. 
After a brief introduction, we taught participants how to get the basic setup (comprising an Arduino, a connected motor and a programming interface) running. Next, participants familiarized themselves with the offered functions with the help of the GUI before starting to develop their own applications.
To gather in-depth qualitative insights, we conducted observations, took notes, and engaged in short conversations with the participants from time to time to assess their progress. 
The study concluded with semi-structured interviews, which were audio-recorded and transcribed for analysis.


\subsubsection{Results}
We thematically analyzed our notes and interview transcripts and generated the following themes: 

\paragraphB{Implemented applications}
	

{\renewcommand{\arraystretch}{1.4}
\begin{table*}[t]
    \centering  
    \begin{tabular}{p{0.4cm}  >{\columncolor[gray]{0.95}}p{2.5cm}  p{6.5cm}  >{\columncolor[gray]{0.95}}p{6.5cm}}
        \textbf{ID} & \textbf{Application} &  \textbf{Programming Interface \& Functions} & \textbf{Hardware Components} \\
        \hline
        \hline
        P1 & Sound synthesizer & Arduino library and Processing application; continuously streaming joint angle data \hspace*{\fill}(2.5 h) & 1 active elbow joint module, links, cuffs \hspace*{\fill}(20 min) \\
        \hline
        P2 & Teacher for learning a toss & Processing library; a sequence of joint and arm-wise \textit{moveTo()} \& \textit{lock()} functions \hspace*{\fill}(3.5 h) & 2 active (elbow \& shoulder side) and 1 passive shoulder back joint module, links, cuffs, back rail \& posture corrector \hspace*{\fill}(1.5 h) \\
        \hline
        P3 & Rowing trainer & Arduino library; a sequence of \textit{resist()} functions with variable torques, executed in parallel on both joints \hspace*{\fill}(40 min) & 2 active elbow \& 4 passive shoulder joint modules, links, cuffs, back rail \& posture corrector \hspace*{\fill}(3 h) \\
    \end{tabular}
    \caption{An overview of the applications built in the second usage study, including the software and hardware components that the participants decided to use. Within the indicated time, participants familiarized themselves with the library functions, implemented the software, and learned to assemble the exoskeleton prototype.}
    \Description{P1 built a sound synthesizer. He leveraged the Arduino library and built a Processing application. He took 2.5 hours for the software implementation. For the hardware assemble, he took 20 minutes and leveraged an active elbow joint module, links and cuffs. P2 created a wearable teaching device for learning a toss. He used the Processing library to implement a sequence of joint- and arm-wise moveTo() and lock() functions. He took 3.5 hours for the software. He assembled the hardware within 1.5 hours, leveraging an active elbow and shoulder side joint module and one passive module attached to the back of the shoulder, links, cuffs, and the back rail attached to the posture corrector. P3 built a rowing trainer. He used the Arduino library to implement a sequence of resist() functions with variable torques that are executed in parallel on both active elbow joints. For the software, he took 40 minutes. Buildung the hardware took 3 hours. He used 2 active elbow joint modules, 4 passive joint modules for the shoulder, links, cuffs, and the back rail attached to the posture corrector.}
    \label{tab:placeholder}
\end{table*}
}
P1 created a \textbf{sound synthesizer} where the position of the elbow joint is transformed into a sound in real-time (\autoref{fig:solodiy}b). 
Similar to a theremin, the farther the lower arm moves towards flexion, the higher the pitch becomes. The idea was inspired by the user manual which provides application ideas to inspire novel users, and resonated with P1's interests as he has \textit{``some colleagues [who] built an application to use novel input devices to create sounds''} .
P1 used the Arduino library to continuously stream motion data to an external application. He implemented a small Processing application to parse and sonify the incoming sensor data using Processing's sound library\footnote{Processing's sound library: \url{https://processing.org/reference/libraries/sound/index.html}, last accessed December 3, 2024}. 

P2 designed a \textbf{device that teaches him to do an underhand toss}, as he was \textit{``not particularly athletic and I thought that an exosuit could teach me to kind of perform this underhand toss''} (\autoref{fig:solodiy}c). Using two motors, P2 actuated the right shoulder and elbow to support flexion-extension.
With the help of the Processing library, P2 implemented the required motion sequence: both actuated joints first move to a neutral position, then the exoskeleton performs a throwing motion by moving the joints towards the targeted angles, followed by a brief lock to keep this position. 

P3 created a \textbf{training device for rowing}, using an exoskeleton with two actuated elbow joints to provide resistance during arm movements. P3 implemented a personalised training plan, in which the provided resistance increased in 5-second intervals to a user-defined maximum before gradually decreasing again. For a more realistic feeling, the resistance was only provided during elbow flexion. P1 synchronized his rowing movements with an online first-person rowing video for demonstration (\autoref{fig:solodiy}d).

\autoref{tab:placeholder} provides an overview of the software and hardware components that the participants used and the time they took to build the application.


Participants reflected on the learning curve, which could be expected given the multitude of modular software and hardware components with which the participants had to become familiar first. For instance, P3 stated: \textit{``I would have a huge advantage if I do it again because I mean at the end it is all very clear and I understand the modularity [\ldots] but it was just a lot to learn''}. 
Of note, in the end, all participants were able to design, build and implement their own exoskeleton interaction. 


\paragraphB{Different approaches to developing an application with ExoKit}
Interestingly, the three participants demonstrated three distinct approaches to building applications with ExoKit:  
P3 started by designing the complete hardware, considering \textit{``how large should the exoskeleton be, which joints should it involve, should it actually have all the joints and if yes should they be passive or not be passive''}, before programming the interaction in one go using the Arduino library.  
Contrary, P1 prioritized getting the programming logic right before assembling any hardware. Working only with a minimal hardware setup (a motor attached to the Arduino), he explained \textit{```because while the exo is not fully assembled, I found it easier to actually test the [functionalities] I wanted to use. Especially since I was not that familiar with ExoKit yet, I really enjoyed it was not assembled yet''}. 
P2, being less experienced in interaction design and programming, began by studying tutorials and his own body motions to identify the desired sequence, first drafting it on paper \textit{``to translate this into sort of like a programmatic approach''} and building the corresponding hardware. Afterwards, he deployed an iterative programming approach, gradually increasing the complexity and refining parameters.  
These distinct approaches highlight how ExoKit's modularity provides flexibility to accommodate users with different levels of experience and preferences.  

\paragraphB{The libraries' perceived ease of use depends on user's prior experience}
All participants highlighted that the GUI is \textit{``most ideal for exploration''} (P1) as it requires minimal input: \textit{``you just have to click, you don't have to enter numbers''} (P3). Moreover, the participants emphasized that their first application ideas were inspired during the initial exploration with the GUI, thereby demonstrating its effectiveness in supporting novice users. 
In contrast, we noted that the perceived ease of the Arduino library varied with participants' prior programming experiences, underscoring the importance of providing different programming interfaces. P3, with the most programming experience, found the Arduino library \textit{``easy enough''} for his needs. P1, a less experienced student, mentioned that
it was challenging in the beginning, but he eventually gained \textit{``enough knowledge to work and play with it''}.
For P2, we provided support after observing that he got stuck trying to learn the Arduino API, and pointed out the possibility of starting with a simpler programming interface first. %\textit{``As I don't have the strongest background in software development [\ldots] I did the mistake of trying to go about it in the most complicated way possible by seeing if I could implement it in the Arduino library''} 
P2 concluded that the Processing library aligned better with his skill level: \textit{``If the [GUI] is for people who have no programming experience and if using the Arduino library is for people who have lots of development experience, then I should stick to my strengths which is being in the middle''}.


\paragraphB{Helping users to help themselves}
Our study showed that ExoKit supports users to adopt their own workflows, but also revealed opportunities to improve support when they struggle.  
First, similar to the workshop studies, the participants quickly grasped the provided functional abstractions and explored parameters independently with the GUI, demonstrating the suitability of the abstraction levels and the provided support through the manual.  
Second, to program the interactions, P1 and P3 successfully built on code snippets provided in the manual and tailored them to their needs. P1 and P2 aspired even more examples and detailed code explanations in the manual as this would further ease the learning process. 
Third, P1 and P2, who independently assembled the hardware, emphasized that \textit{``the instruction manual made it pretty straightforward to figure out how it is to be assembled''} (P2), though P1 noted occasional confusion due to similar-looking parts. 
We observed similar moments of confusion for all participants, such as inserting the rigid link into the arm rail first in the wrong orientation. We see potential to reduce such mistakes by integrating more affordances and constraints into the 3D-printed components, mechanically preventing incorrect orientations or connections. Finally, participants recommended to further enhance the assembly instructions through videos (P3), more visuals (P2), or schematic drawings (P1). 