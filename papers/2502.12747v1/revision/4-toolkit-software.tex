\begin{figure}[b]
    \includegraphics[width=0.45\textwidth]{figures/newConcept_space.pdf}
    \caption{~\toolkit's key functionalities comprise basic functions and five augmentation strategies. They are conceptually organized in a two-dimensional space: Control determines whether the user is in full control of movement, is guided or constrained, or fully controlled by the exoskeleton. Augmentation complexity captures the degree of abstraction, from basic functions up to real-time modification of user movement.}
    \label{fig:conceptual_space}
    \Description{Two-dimensional space of ExoKit’s interaction concepts, with the x-axis ranging from user control to exoskeleton control, and the y-axis showing increasing augmentation complexity. The lowest complexity layer includes 3 basic functions: "Sensing only”,” Move" and "Lock". The middle layer comprises pre-defined sequences which feature the “Scripted Motions” strategy. The highest complexity is given by the real-time modifications layer, which covers "Motion Effort”, "Motion Style”, "Motion Transfer”, and "Motion Guidance”. These are described in more detail in the text.}
\end{figure}
\begin{figure*}[h]
    \centering
    \includegraphics[width=0.77\linewidth]{figures/basics.pdf}
    \caption{Basic functions offered by \toolkit: Moving a joint $j_i$ to an angle $\theta_i$ expressed as (a)~absolute w.r.t. $j_i$'s calibrated zero-degree angle, or (b)~relative to the joint's current angle; (c)~locking joint $j_i$ in place, or (d)~collecting real-time sensor data of selected joints.}
    \label{fig:move_to}
    \Description{The figure illustrates the basic functions of ExoKit as detailed in the caption and accompanying subsection.}
\end{figure*} 
\section{\toolkit's Interaction Concepts}\label{sec:concepts}

\toolkit's objective is to facilitate the design of interactions for arm-based exoskeletons. For this purpose, it provides functional abstractions, which designers can combine into meaningful interactions. 
Beyond basic sensing and actuation, we identified five essential clusters of motion augmentation strategies that are recurrently used in the state-of-the-art exoskeleton literature~\cite{gasperina_2021,proietti_2016,gull_2020,fernandez_2023,basteris_2014}. We have organised them in a conceptual space, which is defined by two key dimensions of motion augmentation~(see Figure~\ref{fig:conceptual_space}): \textit{control} and augmentation \textit{complexity}. 
\textit{Control} captures the extent of control the user vs.~the exoskeleton have over the movement. At one end of the spectrum, the user is in full control and therefore can move freely to any target position. As we move along this axis, the user's freedom is progressively reduced while the exoskeleton is taking over more control, up to a point where the exoskeleton fully controls the user's motion.
Augmentation \textit{complexity} starts from basic functions, like sensing and moving, to pre-defined sequences of basic functions, up to augmentation strategies that modify a user's motion in real-time through a feedback loop.

In the following, we start with presenting the basic functions, followed by the higher-level motion augmentation strategies: 

\subsection{Basic Functions}
Exoskeletons built with \toolkit~are composed of either one or two arms. Each arm consists of up to three joints $j_i, i \in \{1,2,3\}$, which each can be either passive, sensing, or actuated. 
As a prerequisite for the following actuation functionalities, the designer must register the exoskeleton's configuration and calibrate the absolute zero-degree position in software for each actuated or sensing joint $j_i$ once at system startup.


\paragraphB{Actuation}
An actuated joint $j_i$ can be moved to a certain position. As body-centered technology, exoskeleton motions can be defined through angles $\theta_i$ in the user's joint angle space. 
Here, we distinguish between angles that are absolute with respect to the calibrated zero-degree angle of joint $j_i$, and relative angles which describe an angle relative to the user's current position~(cf., Figure~\ref{fig:move_to}a, b).
\toolkit~enables designers to move a joint $j_i$~(\textit{moveTo()}) by specifying an absolute or relative target angle $\theta_i$, the range $\epsilon$ around $\theta_i$~(useful for approaching an area centered at $\theta_i$) and the velocity $\upsilon$. 
To fully prevent any user motion, a joint $j_i$ can also be locked (\textit{lock()}). This is achieved by activating the torque of the motor. Internally, the motor then maintains the position by continuously applying counterforces to the user's motion, thereby providing a locking experience for the user~(Figure~\ref{fig:move_to}c). 
For ease of programming, all functions are provided for controlling an individual joint only, a set of joints, or the entire arm at once. 

\paragraphB{Sensing}
\toolkit~provides real-time sensor data about the exoskeleton's physical angle configuration, motion velocity, acceleration, and applied torques~(Figure~\ref{fig:move_to}d). 
\toolkit~can continuously stream this sensor data from selected or all joints through a serial port connection, making the data easily accessible to external applications. Secondly, \toolkit~allows to use sensor data as conditional triggers in the firmware library: Developers can configure basic threshold- and range-based conditions about the exoskeleton's physical configuration~(speed, acceleration, angle and torque). For instance, these help to detecting when the user moves outside a specified range of motion or exceeds a certain speed. Further, designers can access more complex movement states, which provide insights into each joint's motion direction and help to assess if the user's arm is at a desired angle configuration (or \textit{pose}). 

\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/strategies.pdf}
    \caption{\toolkit~provides functional abstractions for five relevant classes of augmentation strategies which enable to (a)~replay a scripted motion on demand, (b)~continuously transfer one user's motions onto another one, (c)~augment a user's motion effort by amplifying or resisting her ongoing motions, (d)~alter the user's motion style, or (e)~guide the user towards or away from an area.}
    \label{fig:interaction_concepts}
    \Description{The figure illustrates functional abstractions provided by ExoKit as detailed in the caption and accompanying subsections.}
\end{figure*}


\subsection{Scripted Motions}
Building on the basic functions, designers can create and playback scripted sequences of motion, which are defined as a time series of basic move commands. 
Scripted body motions can be helpful to realize a specific repetitive motion with fixed parameters, or to play back motion sequences that serve as gestures~(e.g., waving) and kinesthetic notifications~\cite{catanua_2023}.
For illustrative purposes, we provide functions for executing a waving gesture with the arm~(\textit{gesture()})~(see Figure~\ref{fig:interaction_concepts}a), and for generating a vibrating sensation through rapid back-and-forth movements of adjustable amplitude and frequency~(\textit{vibrate()}). The latter serves as a haptic notification for the user which can be delivered either to a single joint, a set of joints or the full arm.

\subsection{Motion Transfer}

The concept of motion transfer involves transferring human motion in real-time from one joint to another joint, from one arm to another arm, or even from one user to another person. This offers flexible means for applications: These involve guiding another user's motion, such as for motion teaching and skill transfer ~\cite{nishida_2022,maekawa_2019} but also for creating shared kinesthetic experiences between users, or for programmatically remapping body input to output, such as mirroring an arm's movement to the other arm~\cite{pignolo_2012} or leveraging unemployed degrees of freedom for bodily control. 
\toolkit~offers functions that facilitate motion transfer between two joints or exoskeleton instances, where in every time interval, the state of the sensing joints is read and the mapped actuated joints are moved accordingly. 
Designers can mirror the input signal from a sensing joint onto an actuated counterpart~(\textit{mirror()})~(see Figure~\ref{fig:interaction_concepts}b) and optionally scale the motion up or down by a user-defined factor~$f$, while the system internally ensures that the scaled motion does not exceed the user's calibrated limits of their range of motion. 

\subsection{Modulating the Motion Effort}
Modulating the motion effort comprises interaction strategies in which the exoskeleton applies torques $\tau$ in or opposite to a user's inherent motion, while preserving the user's ability to freely navigate in space. 
The resulting feeling of physical assistance or resistance can be leveraged by designers to modulate how users perceive their own motion, with stronger torques $\tau$ resulting in a stronger effect. 
Examples where effort modulation can prove beneficial are rehabilitation, where assistance eases a patient's movements while resistance enhances the muscle strengthening~\cite{gasperina_2021,proietti_2016}, or virtual reality, where the immersiveness can be enhanced by adjusting the level of effort to better match the virtual environment~\cite{teng_2022}.
\toolkit~provides two pre-implemented functions which designers can use to increase~(\textit{resist()}) or decrease~(\textit{amplify()}) the motion effort, respectively, selectively for individual joints or applying to the entire exoskeleton. These functions include parameters that allow designers to adjust the assistive or resistive torque $\tau$ and to specify whether the strategy should be continuously active or only triggered when the user moves in a certain direction~(see Figure~\ref{fig:interaction_concepts}c).

\subsection{Modulating the Motion Style}

Modulating the motion style refers to interaction strategies that modify the observable characteristics of a user’s movement, such as speed or path, while keeping the user in control of the overall motion. These style modifications can range from subtle adjustments to more pronounced changes.
Examples of motion style modulation from the literature include exoskeletons that suppress tremor~\cite{lora_2021}, or exoskeletons that add perturbations to a user's movement, challenging their motion control~\cite{gasperina_2021}.
\toolkit~provides two pre-implemented functions to facilitate exploring modulations of motion style: (1)~The exoskeleton tries to keep a user's motion speed within a pre-defined range~(\textit{filterVelocity()}), by applying assistive torques $\tau$ if they are too slow or resisting ones if they are moving too fast. Designers can fine-tune these effects by setting the velocity range and the forces applied to maintain it. (2)~As an example of an artistic style modulation, the exoskeleton can introduce jerks~(\textit{addJerks()}) to augment a user's motion path for a more technical or robot-like motion style~(see Figure~\ref{fig:interaction_concepts}d). A jerk consists of a short randomized movement that creates a distortion in the user's movement. Designers can adjust this effect by specifying the minimum and maximum angular displacements, the time intervals between jerks, and the number of jerks.

\subsection{Motion Guidance}
Haptic guidance comprises strategies in which the exoskeleton applies forces with the goal of guiding a user towards a certain point or area. These strategies are situated in-between full user control and full exoskeleton, where both effectively collaborate toward a shared goal. Depending on how parameters are adjusted, the designer can trade-off user control vs.~exoskeleton control: exoskeleton control increases as guiding forces increase and as the range of motion becomes more constrained.
Examples of haptic guidance include tunneling approaches in rehabilitation, where the patient’s movement is locked within a predefined path or tunnel, and force fields that guide them back toward the center of it~\cite{guidali_2011,proietti_2016,gasperina_2021}. Beyond rehabilitation, they also hold promise in other areas, such as gaming and VR. 
\toolkit~provides three complementary functions~(see Figure~\ref{fig:guidance}):
(1)~The exoskeleton can constrain the range of motion of a joint $j_i$ to an area around an absolute angle $\theta_{i}$ with range $\epsilon$~(\textit{constrainTo()}). As soon as the user attempts to move beyond this range, the exoskeleton tries to move the user back to the boundary with maximum torque, thereby keeping the joint within the specified limits. 
(2)~The exoskeleton can guide the user towards an area centered around $\theta_i$ with range $\epsilon$~(\textit{guideTowards()}). Here, the exoskeleton applies assistive torques $\tau$ to $j_i$ when moving towards the desired area and resists otherwise~(see Figure. (3)~Lastly, the exoskeleton can keep a joint $j_i$ away from the area around $\theta_{i}$~(\textit{guideAway()}), applying resistance with torque $\tau$ if the user is approaching the area and assistive torques otherwise. In addition to defining angle $\theta_{i}$ and range $\epsilon$, designers can also specify the magnitude of the amplifying and resisting forces.

\begin{figure}[bt]
    \centering
    \includegraphics[width=\linewidth]{figures/guidance3.pdf}
    \caption{\toolkit's software features three functions for motion guidance: (a)~constraining a user's motion to an area centered around $\theta_i$ with range $\epsilon$, (b)~guiding a user towards this area, (c)~or guiding the user away from it.}
    \label{fig:guidance}
    \Description{The figure illustrates the motion guidance strategies implemented in ExoKit, as detailed in the caption and accompanying subsection.}
\end{figure}

\subsection{Programming Interfaces}\label{subsec:interfaces}

\toolkit~provides different interfaces to program the interactions, illustrated in Figure~\ref{fig:programmability}. Each interface is targeted at different experience levels, a recommended practice for end-user robot programming~\cite{ajaykumar_2021}. 
First, for novices in the early exploration stages, a simple command-line interface~(CLI) can be used for executing the basic functions and higher-level augmentation strategies. It abstracts away complex programming concepts such as conditions or loops. We also offer a graphical user interface~(GUI) programmed with Processing, which can be used in place of the CLI. The GUI allows novices to execute basic functions at the touch of a button, and tune parameters with sliders. Second, users can leverage a Processing library to define sequences of functions and strategies, enabling the programming of slightly more complex interactive behaviors.
Third, more experienced users can program complex behavior within the Arduino firmware. The firmware builds on trigger-action programming, realized through an object-oriented event-driven architecture, in which users can combine basic functions and higher-level augmentation strategies into their own customized interactions. Similar to other works on end-user robot programming ~(e.g.,~\cite{guerin_2015, angerer_2013, ur_2014}), users can define elements of parallelization, sequences, nested functions, or leverage incoming sensor data as conditional triggers. For more implementation details, see Appendix~\ref{subsec:implementation_sw} and the supplemental material. 

\begin{figure}[bt]
    \centering
    \includegraphics[width=\linewidth]{figures/programming_interfaces.pdf}
    \caption{\toolkit~provides a command-line interface and GUI, a Processing library, and an Arduino firmware library to program human-exoskeleton interactions.}
    \label{fig:programmability}
    \Description{Overview of ExoKit’s programming interfaces and their key features. The command-line interface and graphical user interface are designed for first-time users, allowing to call one augmentation at a time without access to conditional triggers. The Processing library targets novices which can define sequential function calls. The Arduino firmware is intended for experienced developers, supporting sequential, parallel, and nested operations with access to conditional triggers.}
\end{figure}