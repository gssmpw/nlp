\section{Related Works}
\subsection{Foundation Models}
Foundation models are large-scale, pre-trained models that can be fine-tuned for various downstream tasks in natural language processing____, computer vision____, and other domains including robotics and biology ____. Despite their versatility, these models are not inherently suitable for number-sensitive tasks, such as scientific computing ____, PDE discovery____, and time series forecasting ____, where high-precision solutions are critical.
Early attempts have been made to adapt foundation models or similar transformer-based structures for scientific computing tasks. Some approaches utilize pre-training and fine-tuning techniques____, though these methods often require additional computational cost for downstream tasks.
The In-Context Operator Network (ICON) ____ uses in-context learning to learn operators through example input-output pairs, which are few-shot learners and have demonstrated generalization capabilities for various differential equations ____. Zero-shot PDE foundation models integrate additional information to aid the prediction process. ICON-LM ____ enables in-context learning with both text descriptions of governing physics and numerical data in the model inputs, but outputs are numerical only. In this way, text is used as a label to signal which PDE or task is needed. The PROSE framework____ is a multimodal approach that encodes numerical data along with symbolic representations of the PDE. In recent work, PROSE has been shown capable of extrapolation ____ and improved generalization through fine-tuning ____.
Other methods achieve zero- or few-shot generalization by embedding PDE structures within the network architecture____.


\subsection{Multimodal Machine Learning}
Multimodal machine learning focuses on models capable of integrating data from various modalities ____. A key area of interest in this field is developing methods for information fusion across modalities, analyzing their interactions, and designing appropriate models and algorithms. For instance, in visual-language reasoning ____, combining visual data like images or videos and linguistic information such as captions or text descriptions ____ facilitates the development of models with enhanced multimodal understanding ____. Similarly, AI robots utilize multimodal sensors, including cameras, radar, and ultrasound, to interpret their environments and make well-informed decisions ____. Notably, the concept of a multimodal sentence was introduced in PaLM-E ____, where image and text can appear anywhere in the sentence and be processed in a flexible manner. 


\subsection{Transfer Learning}
Transfer learning has become a cornerstone of modern machine learning, enabling the adaptation of pre-trained models to specialized tasks with relatively limited data ____. In the context of large language models (LLMs), such as GPT and BERT, fine-tuning on domain-specific data allows the model to leverage its extensive pre-trained knowledge while focusing on the nuances of a target domain ____. For instance, fine-tuning GPT-2 or GPT-3 models on scientific texts has shown improved performance in tasks such as equation generation, technical summarization, and scientific question answering ____. In our work, which follows the operator learning paradigm, we fine-tune an LLM with examples of numerical equations, symbolic representations, and descriptive text to enhance its ability to generate meaningful and contextually relevant outputs. The inclusion of this step in our framework, aligns well with recent advancements in multimodal tasks ____, demonstrating the importance of adapting pre-trained LLMs to specialized contexts.