\section{Methodology}
% In this section, we begin by detailing the design of incremental scenarios, outlining the motivation and considerations behind each one. We then formally define the incremental 3D instance segmentation problem and introduce our proposed method to address it using a transformer-based model, emphasizing its key features and advantages.
In this section, we begin by formulating the incremental 3D instance segmentation problem and introduce our proposed method to address it using a transformer-based model. We then detail the design of incremental scenarios, outlining the motivation and considerations behind each one. 

% \begin{figure*}[!htb]
% \floatbox[{\capbeside\thisfloatsetup{
%     capbesideposition={right,top},
%     capbesidewidth=0.38\linewidth}
%     }]{figure}[0.93\FBwidth]
% {\includegraphics[width=0.6\textwidth]{fig/climb3d.pdf}}
% {\caption{\textbf{CLIMB-3D}: At phase $t$ (for $t > 1$), we create a copy of the previous phase model $\Phi^{\mathrm{T}}$ (teacher model) and designate it as $\Phi^{\mathrm{S}}$ (student model). Both $\Phi^{\mathrm{T}}$ and $\Phi^{\mathrm{S}}$ process the input point cloud simultaneously, producing predictions $\hat{y}_\mathrm{pseudo}$ and $\hat{y}$, respectively. To prevent the model from forgetting less frequent categories from previous tasks, we balance the predictions from $\Phi^{\mathrm{T}}$, resulting in a balanced output $\hat{y}^\mathrm{(w)}_\mathrm{pseudo}$. The concatenated vector of ground truth labels $[y, \hat{y}_\mathrm{pseudo}, \hat{y}^\mathrm{(w)}_\mathrm{pseudo}]$ is then compared with the predicted labels $\hat{y}$.}}
% \label{fig:climb3d}
% \end{figure*}

\begin{figure*}[t]
  \centering
  \includegraphics[width=.9\linewidth]{fig/climb3d.pdf}
  \caption{\textbf{CLIMB-3D}: 
  % At phase $t$ (for $t > 1$), we create a copy of the previous phase model $\Phi^{\mathrm{T}}$ (teacher model) and designate it as $\Phi^{\mathrm{S}}$ (student model). 
  At phase $t$ (for $t > 1$), we create a copy of the model from the previous phase, $\Phi^{\mathrm{T}}$ (the teacher model), and designate it as $\Phi^{\mathrm{S}}$ (the student model). 
  Both $\Phi^{\mathrm{T}}$ and $\Phi^{\mathrm{S}}$ process the input point cloud simultaneously, producing predictions $\hat{y}_\mathrm{pseudo}$ and $\hat{y}$, respectively. To prevent the model from forgetting less frequent categories from previous tasks, we balance the predictions from $\Phi^{\mathrm{T}}$, resulting in a balanced output $\hat{y}^\mathrm{(w)}_\mathrm{pseudo}$. The concatenated vector of ground truth labels $[y, \hat{y}_\mathrm{pseudo}, \hat{y}^\mathrm{(w)}_\mathrm{pseudo}]$ is then compared with the predicted labels $\hat{y}$. A loss function is applied based on this comparison, enabling the student model to learn from the differences between the predicted and the concatenated pseudo-ground truth labels
  }
  \label{fig:climb3d}
\end{figure*}

\subsection{Problem Formulation}
\label{sec:formulation}

The objective of 3D point cloud instance segmentation is to accurately identify and segment individual instances of objects within a given point cloud. Mathematically, the training dataset is represented as $\mathcal{D} = (\mathcal{P}, \mathcal{Y}) = \{(p_i, y_i)\}_{i=1}^N$, where $N$ is the total number of samples. Each sample consists of a colored point cloud $p_i \in \mathbb{R}^{M \times 6}$ of size $M$, where the point coordinates and color values are represented as $\{x, y, z, r, g, b\}$. The corresponding annotations are denoted as $y_i = \{(m_{i,j}, c_{i,j})\}_{j=1}^J$, where $m_{i,j}$ represents the instance mask for the $j$-th instance, and $c_{i,j} \in \mathcal{C} = \{1, \dots, C\}$ denotes the semantic label of the object category to which the instance belongs for the $i$-th point cloud. Here, $J$ represents the total number of instances in the $i$-th point cloud, and $C$ indicates the number of distinct object categories. During the learning process, the model $\Phi$ will process this dataset and output predictions $\hat{y}_{i,j} = (\hat{m}_{i,j}, \hat{c}_{i,j})$, where $\hat{m}_{i,j}$ represents the predicted instance mask and $\hat{c}_{i,j}$ denotes the predicted semantic label for the $j$-th instance in the $i$-th point cloud.

% To adapt the dataset to an incremental learning setting, we partition the object categories $\mathcal{C}$ and the dataset $\mathcal{D}$ into $T$ subsets, denoted as $\mathcal{C} = \mathcal{C}^1 \cup \cdots \cup \mathcal{C}^T$ and $\mathcal{D} = \mathcal{D}_1 \cup \cdots \cup \mathcal{D}^T$, respectively. 
% Each phase $t  \in \{1, \dots, T\}$ is associated with a specific subset $\mathcal{C}^t$ and the dataset $\mathcal{D}^t$ contains only annotations for objects belonging to the corresponding subset. 
To adapt the dataset to an incremental learning setting, we partition the object categories $\mathcal{C}$ into $T$ subsets, denoted as $\mathcal{C} = \mathcal{C}^1 \cup \cdots \cup \mathcal{C}^T$. 
Each phase $t  \in \{1, \dots, T\}$ is associated with a specific subset $\mathcal{C}^t$, and its corresponding dataset $\mathcal{D}^t$ which only contains annotations for objects belonging to the corresponding subset.
Formally, during the $t$-th phase of training, the dataset $\mathcal{D}^t = (\mathcal{P}, \mathcal{Y}^t) = \{(p_i, y_i^t)\}_{i=1}^N$ is defined, where $\mathcal{P}$ represents the point clouds shared across all phases, and $\mathcal{Y}^t$ contains annotations exclusively for objects belonging to the class subset $\mathcal{C}^t$. It is important to note that the 3D scenes within each phase can contain objects of any type from the entire object category set $\mathcal{C}$, but only the object belonging to $\mathcal{C}^t$ are annotated during that specific phase. After training for phase $t$ completes, the model is evaluated on a validation set containing the union of classes up to task $t$ (i.e., $\mathcal{C}^1 \cup \cdots \cup \mathcal{C}^t$). Training progresses to the next phase, $t+1$, where the model $\Phi$ observes the same set of 3D scenes $\mathcal{P}$ but with annotations for different object types belonging to the subset $\mathcal{C}^{t+1}$. This incremental training approach allows the model to gradually learn and adapt to new object categories over multiple phases.

\subsection{CLIMB-3D}
\label{sec:climb3d}

In our proposed framework (\Cref{fig:climb3d}), the incremental instance segmentation model undergoes phased training, as described in \cref{sec:formulation}, where carefully designed subsets of the dataset are introduced to handle various real-world scenarios discussed in \cref{sec:scenarios}. Formally, at phase $t$, when the model $\Phi^t$ is introduced with input data $\mathcal{D}^t = \{(p_i, y_i^t)\}_{i=1}^N$ and trained using \cref{eq:detr_loss}, a common issue arises where it tends to forget the knowledge acquired in the previous phase, leading to catastrophic forgetting \cite{mccloskey1989catastrophic}. To address this, we first draw inspiration from techniques developed in the 2D domain \cite{rebuffi2017icarl, li2017learning} and recent 3D semantic segmentation \cite{su2024balanced, Yang_2023_CVPR}, and adapt them for our setting. 
% However, these adaptations alone do not yield state-of-the-art performance; hence, we design a simple teacher-student knowledge distillation framework to retain previously learned knowledge. 
However, we observe that these adaptations alone fall short of achieving the desired performance levels; therefore, we propose a teacher-student knowledge distillation framework to effectively retain previously learned knowledge.
Additionally, we incorporate an imbalance correction module to handle the challenge of less frequent classes from earlier tasks.

% \vspace{-10pt}
% \paragraph{
\cpara{Exemplar Replay (ER)}
% } 
Inspired by the approach proposed by Buzzega et al. \cite{buzzega2020dark}, ER methods alleviate the issue of limited exposure to previous task data during training. By selectively storing a small subset of exemplars $\mathcal{E}_t$ from previous phases, the model can learn from both the current task data $\mathcal{D}_t$ and the replayed exemplars $\mathcal{E}_{1:t-1}$. This results in a combined dataset $\mathcal{D}_t \cup \mathcal{E}_{1:t-1}$, where $\mathcal{E}_{1:t-1}$ represents the exemplar memory formed by the union of all previous exemplar sets $\mathcal{E}_{1:t-1} = \mathcal{E}_{1}\cup~\dots~\cup \mathcal{E}_{t-1}$. The model undergoes a full iteration on $\mathcal{D}_t$ before replaying the exemplars. 

% \begin{equation}
%     \mathcal{L}_t = \mathbb{E}_{(p, y) \sim \mathcal{D}_t \cup \mathcal{E}_{1:t-1}} \left[ \ell(\Phi^{t}(p), y) \right]
% \end{equation}
Some previous 3D approaches adopt this strategy to retain knowledge but rely on a large exemplar set \cite{boudjoghra20243d}, which is often impractical in real-world scenarios. 
%To address this, we opt for a smaller exemplar set, this naturally resulted in reduced accuracy.
To address this, we choose a smaller exemplar set, creating a more challenging setup that requires the model to effectively manage and retain knowledge with limited resources, thereby testing its robustness and adaptability in practical applications.

% % \vspace{-10pt}
% \paragraph{
\cpara{Knowledge Distillation (KD) Module} 
% } 
% is a teacher-student module framework, where we maintain a copy of the previous trained model while learning current task.
In our incremental learning approach, we utilize a Knowledge Distillation (KD) module that incorporates a teacher-student framework, maintaining a copy of the previously trained model while learning the current task.
For $t > 1$, at the beginning of each training stage, the current model $\Phi^t$ is initialized as $\Phi^t \leftarrow \Phi^{t-1}$, where $\Phi^{t-1}$ represents the model trained in the previous phase. As the $\Phi^t$ is trained on the previous stage dataset, it holds information about the previous set of classes. 
% Hence it is naturally comes that we should use this model to help retain previous knowledge while learning the current task. 
Hence, we make use of this model to help retain previous knowledge while learning the current task. 
% Most of the continual learning methods does the feature level distillation which adds extra loss component $\mathcal{L}_\mathrm{KD}$ to the loss function. 

When presented with a new training point-cloud and label pair $(p, y^t)$, the output of the previous model is calculated as $\hat{y}_\mathrm{pseudo} = \Phi^\mathrm{t-1}(p)$, and a combined loss function is minimized. This combined loss comprises the $\mathcal{L}_{\mathrm{Seg}}(\hat{y}^t, y^t)$ loss, which measures the discrepancy between the predicted and ground truth labels, and the knowledge distillation loss $\mathcal{L}_\mathrm{KD}$, which encourages the similarity between the predictions of the current model and the previous model.
\begin{flalign}
    \label{eq:std_kd}
    \mathcal{L}_\mathrm{KD}(\hat{y}^t, \hat{y}_\mathrm{pseudo}) &= \mathcal{L}_\mathrm{mask}(\hat{m}^t_j, \hat{m}_{j, \mathrm{pseudo}}) \notag \\
    &\quad\quad\quad\quad + \lambda_\mathrm{cls}\mathcal{L}_\mathrm{cls}(\hat{c}^t_j, \hat{c}_{j, \mathrm{pseudo}})
\end{flalign}

However, as pointed out in previous works on object detection in 2D \cite{liu2023continual}, \Cref{eq:std_kd} is often biased towards the background classes, as the model tends to predict the background for most instances. Similarly, we propose selecting the top $K$ most confident predictions from the previous teacher model $\Phi^{t-1}$ and combining them with the ground truth labels, which then serve as pseudo-labels. By extracting the top $K$ confident samples from the output of $\Phi^{t-1}$ and combining them with the ground truth labels, the augmented label set becomes $y' = [y^t, \hat{y}_{\mathrm{pseudo}}^K]$. This augmented label set is then used to optimize the current model $\Phi$ with the $\mathcal{L}_\mathrm{Seg}$ loss function from \Cref{eq:detr_loss}.

% \vspace{-10pt}
% \paragraph{
\cpara{Imbalance Correction (IC) Module}
% }
Although retaining a few samples from previous tasks and selecting the most confident predictions from the previous model, $\Phi^{t-1}$, helps preserve information from prior tasks while learning new ones, we observed that this approach does not adequately address the class imbalance. Our analysis reveals that the most confident predictions from $\Phi^{t-1}$ are largely associated with the most frequent object categories, causing the model to forget less common classes. This issue can be mitigated by re-weighting the predictions based on the frequency of observed categories \cite{islam2021class}.

At task $t$, we only have access to the data and statistics of the current task; the previous task’s dataset and statistics are unavailable. 
% To approximate these missing statistics, we propose leveraging pseudo predictions from $\Phi^{t-1}$. 
To incorporate balancing elements despite the absence of previous stage statistics, we propose leveraging pseudo prediction statistics from $\Phi^{t-1}$.
During each iteration, we use $\Phi^{t-1}$ to generate pseudo labels and accumulate class frequency statistics for prior tasks throughout the current epoch training. At the end of each epoch, we combine the statistics of observed scene classes and predicted pseudo-classes, calculating the frequency $\mathbf{f}$ of all classes seen so far.

Formally, for each category $c$, we assign a weight $\mathbf{w}_c$ inversely proportional to its observed frequency in the predictions of $\Phi^{t-1}$ and the current dataset. The weight $\mathbf{w}_c$ is defined as: $\mathbf{w}_c = \frac{1}{\mathbf{f}(c) + \epsilon}$, where $\epsilon$ is a small constant to avoid division by zero. In the next epoch, predictions from $\Phi^{t-1}$ are re-weighted using $\mathbf{w}_c$, creating an adjusted high-confidence pseudo label set for less frequent categories: $\hat{y}_\mathrm{pseudo}^{(w)} = \mathbf{w}_c \cdot \hat{y}_\mathrm{pseudo}$. This re-weighting occurs at each epoch, allowing $\Phi^{t-1}$ to yield a broader set of less frequent classes. To ensure the model encounters both high-confidence and less frequent classes, we select the top $K$ high-confidence predictions both before and after re-weighting. The resulting augmented label space, which combines ground truth labels, original pseudo labels, and re-weighted pseudo labels, is given by: $y' = [y, \hat{y}_\mathrm{pseudo}^K, y_\mathrm{pseudo}^{(w),K}]$.

As this weighting scheme is applied only to previous model predictions, we further tune the current model to favor less frequent classes by incorporating the same weights $\mathbf{w}_c$ into the classification loss of \Cref{eq:detr_loss}. The adjusted segmentation loss becomes:

\begin{equation}
\label{eq:climb_loss}
\mathcal{L}_\mathrm{3DIS}(y'_j, \hat{y}_j) = \mathcal{L}_\mathrm{mask}(m'_j, \hat{m}_j) + \mathbf{w}'_c\mathcal{L}_\mathrm{cls}(c'_j, \hat{c}_j),
\end{equation}

\noindent where $\mathbf{w}'_c = \mathbf{w}_c \cdot \lambda_\mathrm{cls}$ represents the adjusted category weights. By re-weighting and augmenting both the label space and the loss function, our IC module ensures that both the current and previous models encounter pseudo labels spanning the long-tail distribution, addressing class imbalance and enabling more balanced learning.

\subsection{Designing Incremental Scenarios}
\label{sec:scenarios}

% \begin{figure*}[!htb]
% \floatbox[{\capbeside\thisfloatsetup{
%     capbesideposition={right,top},
%     capbesidewidth=0.43\textwidth}
%     }]{figure}[0.91\FBwidth]
% {\includegraphics[width=0.56\textwidth]{fig/scenarios.pdf}}
% {\caption{Incremental scenarios are grouped based on frequency of occurrence, semantic similarity, and random clustering. Different color clouds (\ccolorbox{lightblue}{}, \ccolorbox{lightorange}{}, \ccolorbox{lightgreen}{}) represent tasks in each scenario, while various shapes represent object categories, and \ccolorbox{lightgray}{} denotes the background. \textbf{Left:} Tasks are organized based on the frequency of object categories. \textbf{Middle:} Tasks are grouped by semantic similarity, where objects with similar shapes (e.g., circles, plus signs, and triangles) denote semantically similar classes and are thus grouped together. \textbf{Right:} In this fully random scenario, tasks may contain a mix of semantically similar, more frequent, or less frequent classes.}
% \label{fig:scenarios}}
% \end{figure*}

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{fig/scenarios.pdf}
  \caption{Incremental scenarios are grouped based on frequency of occurrence, semantic similarity, and random clustering. Different color clouds (\ccolorbox{lightblue}{}, \ccolorbox{lightorange}{}, \ccolorbox{lightgreen}{}) represent tasks in each scenario, while various shapes represent object categories, and \ccolorbox{lightgray}{} denotes the background. \textbf{Left:} Tasks are organized based on the frequency of object categories. \textbf{Middle:} Tasks are grouped by semantic similarity, where objects with similar shapes (e.g., circles, plus signs, and triangles) denote semantically similar classes. \textbf{Right:} In this fully random scenario, tasks may contain a mix of semantically similar, more frequent, or less frequent classes.}
  \label{fig:scenarios}
\end{figure}

While conventional incremental learning methods have numerous practical applications, they often assume an equal distribution of samples, which does not reflect real-world conditions. In practice, the number of object categories, $\mathcal{C}$, is typically large, with significant variability in category occurrence, shape, structure, and size. With these attributes in mind, we design three incremental learning scenarios, each addressing distinct aspects of real-world conditions, the design is highlighted in \Cref{fig:scenarios}.

% \vspace{-10pt}
% \paragraph{
\cpara{\ct{1} Frequency Scenarios (\fsplit)}
% }
This scenario acknowledges that datasets are often labeled based on the frequency of category occurrences. To accommodate this, we propose a split where the model initially learns from the most frequent categories and subsequently incorporates the less frequent ones in later stages. By prioritizing the training of frequently occurring categories, the model can establish a strong foundation before expanding its knowledge to handle rarer categories.

% \vspace{-10pt}
% \paragraph{
\cpara{\ct{2} Semantic Scenarios (\ssplit)}
% } 
In real-world environments, objects may exhibit similarities in appearance, and then moved to different environments, the model may encounter new objects that does not share similar semantic characteristics with previously seen categories. To address this, we introduce the \ssplit~ scenario. It involves grouping categories based on their semantic labels and incrementally training the model to handle these groups. This allows the model to generalize its knowledge across semantically similar categories, facilitating adaptation to new objects with similar characteristics. Unlike the \fsplit~ scenario, this scenario may include both frequent and infrequent categories within the same task. 

% \vspace{-10pt}
% \paragraph{
\cpara{\ct{3} Random Scenarios (\rsplit)}
% } 
In some cases, data labeling is based on the availability of objects rather than specific criteria. To account for this scenario, we design the \rsplit~ scenario. This scenario represents a completely random setting where each task can have any class, leading to varying degrees of class imbalance. By exposing the model to such diverse and imbalanced scenarios, we aim to enhance its ability to handle real-world situations where the availability of labeled data is unpredictable.

By designing these three incremental learning scenarios, we aim to provide a more realistic representation of object distributions, frequencies, and dynamics encountered in the real world.


