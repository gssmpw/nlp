\section{Related Work}
\label{sec:related}

In this section, we discuss related work in MBRL --- see e.g. ____ 
% and \url{https://github.com/opendilab/awesome-model-based-RL}
for more comprehensive reviews.
We can broadly divide MBRL along two axes.
The first axis is whether the world model (WM) is used for background planning
(where it helps train the policy by generating imagined trajectories),
or decision-time planning (where it is used for lookahead search at inference time). 
The second axis is whether the WM is a generative model of the observation space (potentially via a latent bottleneck) or whether is a latent-only model trained using a self-prediction loss
(which is not sufficient to generate full observations).

Regarding the first axis, prominent examples of decision-time planning methods that leverage a WM include MuZero ____ and EfficientZero  ____, which use Monte-Carlo tree search over a discrete action space, as well as TD-MPC2 ____, which uses the cross-entropy method over a continuous action space.
Although some studies have shown that decision-time planning can sometimes be better
than background planning ____, it is much slower, especially with large WMs such as transformers, since it requires rolling out future hypothetical trajectories at each decision-making step.
Therefore in this paper, we focus on background planning (BP).
Background planning originates from Dyna ____, which focused on tabular Q-learning.
Since then, many papers have combined the idea with deep RL methods: World Models ____,
Dreamer agents  ____,
SimPLe ____,
IRIS ____,
$\Delta$-IRIS ____,
Diamond ____,
DART ____, etc.

Regarding the second axis, 
many methods fit generative WMs of the
observations (images) using a 
model with low-dimensional latent variables,
either continuous (as in a VAE)
or discrete (as in a VQ-VAE).
This includes our method and most background planning methods above
\footnote{
%
A notable exception is 
Diamond ____,
which fits a diffusion world model
% of the form $p(O'|O,a)$
directly in pixel space,
rather than learning a latent WM. %and an autoencoder.
% $p(Q'|Q,a)$ and then decoding to image space
% via $p(O'|Q')$.
}.
In contrast, other methods fit non-generative WMs, which are trained using self-prediction loss---see ____ for a detailed discussion.
Non-generative WMs are more lightweight and therefore well-suited to decision-time planning with its large number of WM calls at every decision-making step.
However,
generative WMs are generally preferred for background planning, since it is easy to combine real and imaginary data for policy learning,
as we show below.

 
In terms of the WM architecture, many state-of-the-art models use transformers, e.g. 
IRIS ____,
$\Delta$-IRIS ____,
DART ____.
Notable exceptions are DreamerV2/3  ____, which use recurrent state space models,
although improved transformer variants have been proposed 
____.