\section{Related Work}
The following sections present related work on the topics of aesthetic outcomes of breast cancer treatment, inpainting and invertible networks.

\subsection{Aesthetic Outcomes of Breast Cancer Treatment} \label{sec:related-work}

The aesthetic evaluation of breast cancer treatment has been extensively researched in the literature, mostly focusing on objective metrics to quantify breast asymmetries. The existing metrics were proposed to evaluate two aspects of asymmetries within the breasts: nipple displacement and differences in the shape of the breasts. Regarding nipple asymmetries, Freitas \textit{et al.}, "Aesthetic Evaluation of Breast Cancer Treatment Using Transfer Learning" quantifies the horizontal and vertical displacement of the nipples in relation to the sternal notch.  Lee \textit{et al.}, "Quantifying Nipple Displacement in Breast Cancer Patients" evaluates the vertical displacement of the nipple in relation to the lowest point of the breast contour.  Park \textit{et al.}, "Horizontal Nipple Retraction: A Novel Metric for Evaluating Breast Asymmetry" measures the distance from each nipple to the external contour of the breast. Kim \textit{et al.}, "Upwards Nipple Retraction: An Objective Metric for Assessing Breast Asymmetry" measures the vertical distance between the nipples. Regarding metrics to measure asymmetries in the shape of the breasts, Lee \textit{et al.}, "Lower Breast Contour: A Novel Metric for Evaluating Breast Shape Asymmetry"  measures the vertical distance between the lowest point of each breast. Wang \textit{et al.}, "Breast Contour Difference, Breast Area Difference and Breast Overlap Difference: Metrics for Evaluating Breast Shape Asymmetry" measure the differences between the contour and shape of the breasts. These last three metrics are highly dependent on the placement of the endpoints of the breast contour, which is often characterized by high variability as it is difficult to pinpoint where the breast ends in a frontal image. In this work, we use these metrics to evaluate the proposed methodology. 

Regarding the prediction of the aesthetic results of breast cancer treatment, Freitas \textit{et al.}, "Aesthetic Evaluation of Breast Cancer Treatment Using Transfer Learning" propose two approaches to transfer breast asymmetries from post-operative patients into pre-operative images. First, they apply image warping to reposition the breast's contour. Nevertheless, this approach is incapable of manipulating the nipple and requires the manual annotation of the breast contour during inference. On a second approach, the authors use a weakly-supervised learning approach based on disentangled representation learning to isolate asymmetries in breast images from the patient's identity, enabling to alter asymmetries while preserving identity-related traits. Although this method succeeds at altering both breast and nipple, it overly changes the shape of the pre-operative patients' breasts to match those of the post-operative patients. Montenegro \textit{et al.}, "Weakly-Supervised Learning for Aesthetic Evaluation of Breast Cancer Treatment" extend the weakly-supervised approach by implementing a symmetry-based loss to promote higher resemblance between the original and generated images. Nevertheless, the resulting images lack visual quality. In this work, we propose a novel method to manipulate breast images that is simultaneously capable of generating realistic images and manipulating both the nipple and breast, through conditional image inpainting. 

\subsection{Inpainting}

Image inpainting corresponds to the image-to-image translation task of filling missing regions in images in coherence with the surrounding content. Inpainting has been applied for various purposes, including object removal and partial image generation. Most works train networks such as Autoencoders (AE), U-Net , "U-Net: Deep Learning for Image Denoising" and Fully Convolutional Networks , "Fully Convolutional Networks for Semantic Segmentation" to fill missing regions by reconstructing the ground-truth image . More recently, various works take advantage of deep generative models like Generative Adversarial Networks (GANs) , "Generative Adversarial Networks: A Survey" or Denoising Diffusion Probabilistic Models (DDPMs) , "Denoising Diffusion Probabilistic Models for Image Synthesis" to achieve more realistic predictions and higher variability within the inpainted region . Within inpainting, there are two research lines that are particularly relevant for this work: conditional inpainting, where the inpainting process is conditioned on some variable, and applications of inpainting to medical imaging. 

Regarding conditional inpainting, works on face inpainting often condition the inpainting network on facial landmarks by concatenating them with the input image that contains the missing regions . Other works condition the inpainting process on reference images  or on textual cues  by providing the respective embeddings as input to the network. In our case, we condition the inpainting process on nipple and lower breast annotations drawn over the covered breast, enabling the network to automatically understand where the nipple and lower breast should be drawn, and minimizing the amount of annotations required for the inpainting process. 

Within medical imaging, various works use GANs and autoencoders to improve the visual quality of the images by inpainting square regions, stripes or other arbitrary regions within medical images such as magnetic resonance images  and chest X-rays . Other works use inpainting to manipulate medical images for purposes such as straightening a patient's spine . Nevertheless, in all these works, the information that is covered in the input image, which may be useful for a more faithful reconstruction of the image, is not provided to the model and is, therefore, lost. In this work, we propose an inpainting model that uses information from the covered breast region to inpaint it, enabling a more realistic reconstruction and manipulation of the breast. 

\subsection{Invertible Networks}

Invertible networks perform exclusively invertible operations on their inputs, making it possible to obtain an input based on its output. These networks are widely used as the building blocks of normalizing flows  for unsupervised image generation tasks. For instance, RealNVP , "Real NVP: Real-valued Non-Volume Preserving" uses affine coupling layers that apply invertible affine transformations to the data. Glow , "Glow: Generative Flow for Estimation and Sampling" uses invertible $1\times 1$ convolutions along with affine coupling layers. More recently, invertible architectures, such as i-RevNet , "i-RevNet: Deep Invertible Generators" have been used for image classification tasks, enabling the reconstruction of the original image based on its latent features and avoiding loss of information. 
More similarly to our work, Liu \textit{et al.}, "Invertible Autoencoder for Image-to-Image Translation" develop an invertible autoencoder to perform image-to-image translation tasks like inpainting, by employing two Glow models as the encoder and decoder of the network. However, the autoencoder is only trained and evaluated in the inpainting direction, discarding the inverse direction of removing regions from an image. In our work, we develop invertible autoencoders based on Glow and i-RevNet, training them to perform both inpainting and segmentation on breast images, enabling the manipulation of unlabelled breast images.