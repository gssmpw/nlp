\section{Related Work}
\label{sec_relwork}
Remote Sensing Image Captioning (RSIC) has advanced significantly with deep learning techniques. Traditional methods relied on handcrafted feature extraction and statistical models, but the introduction of encoder-decoder architectures revolutionized the field____. The encoder extracts meaningful features from satellite and aerial imagery, while the decoder generates descriptive captions. 

Early RSIC models used convolutional and recurrent neural networks. Qu et al.,~[2016]____ proposed a deep multimodal neural network, integrating image and text embeddings for caption generation. Lu et al.,~[2017]____ contributed by introducing the RSICD dataset, addressing dataset limitations in SYDNEY and UCM. Hoxha et al.,~[2019]____ refined beam search strategies and image retrieval techniques using CNN-RNN models for better caption generation accuracy. Li et al.,~[2019]____ introduced a two-level attention mechanism that combines text-guided and semantic-guided attention to improve spatial correlation. Zhang et al.,~[2019]____ developed a multiscale cropping approach to improve fine-grained feature extraction.

To overcome the limitations of earlier methods, attention-based mechanisms were introduced to improve contextual modeling. Xu et al.,~[2015]____ pioneered attention-based image captioning, influencing subsequent RSIC works. Sumbul et al.,~[2020]____ explored summarization-driven attention to improve caption coherence. Despite improvements, these models struggled with long-term dependencies and feature aggregation inefficiencies. Li et al.,~[2021]____ proposed the RASG framework, integrating recurrent attention to refine context vectors. Wang et al.,~[2022]____ introduced GLCM, using global-local feature extraction for better word discrimination.

Transformer-based architectures brought about a paradigm shift in RSIC by enhancing sequence modeling and linguistic consistency____. Liu et al.,~[2022]____ introduced MLAT, a multilayer aggregated transformer that improves the utilization of multiscale features. Meng et al.,~[2023]____ developed the PKG transformer, incorporating graph neural networks to refine the relationship between objects. Zhang et al.,~[2023]____ introduced a stair attention mechanism, integrating CIDEr-based reinforcement learning for improved coherence. Despite these advancements, efficient encoder selection remained an open challenge. Wu et al.,____ proposed a dual transformer model integrating the Swin transformer for multiscale feature extraction.

A significant limitation is identified when evaluating these models. They predominantly emphasize the decoder instead of the encoder. However, selecting an effective encoder can substantially enhance performance in the RSIC. Taking into account this aspect, Das et al.,~[2024]____ conducted an investigation involving eight CNN-based encoders for RSIC. Their study used an LSTM as the decoder. The encoders were grouped on the basis of performance to determine the highest performing CNNs. The top performing CNNs were subsequently subjected to a subjective evaluation to determine the optimal choice. Their findings recognized ResNet as the most effective encoder. However, transformer-based models have garnered considerable attention in recent years. Recognizing these advances, this work conducts a similar experiment using twelve distinct encoders. It incorporates a transformer-based encoder along with a GPT-2 transformer-based decoder.