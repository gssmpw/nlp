\section{Related Work}
Autoformalization builds connections between natural language and formal languages \cite{quan-etal-2024-verification,quan-etal-2024-enhancing}. It also plays an important role in formal mathematical reasoning. For instance, proof autoformalization has been used as an intermediate step in automated theorem proving~\citep{jiang2023draft,tarrach2024more}. Deep learning models, such as transformers, have been applied to autoformalization. For example, \citet{cunningham-etal-2022-towards} developed a transformer-based model for autoformalizing of theorems along with their proofs in Coq. In recent years, with the increasing capabilities of LLMs, prompting-based methods have also demonstrated the ability to autoformalize mathematical statements in Isabelle~\citep{wu2022autoformalization,zhang-etal-2024-consistent,li2024autoformalize} and Lean~\citep{lu2024processdrivenautoformalizationlean4}. Despite recent progress in autoformalization, few studies have analyzed this task from an error perspective. Our work aim to address this gap.

There are a few benchmarks providing informal-formal mathemtical statement pairs. miniF2F dataset~\citep{zheng2022miniff} provided 488 mathematical statement pairs from high school and undergraduate level to Olympiad problems in Lean, Metamath, and Isabelle. ProofNet~\citep{azerbayev2023proofnet} benchmark contains 371 parallel formal theorem statements, natural language theorem statements, and natural language proofs in Lean. However, informal-Formal mathematical statement pairs are still scarce. Obtaining ground-truth formal codes requires specialists and there are many ways to formalize mathematical statements. In our work, we only provide the datasets in the natural language version and aim to develop methods without ground-truth formal codes.

%Error analysis is a common practice in machine learning. It aims to identify error patterns in model predictions and help developers enhance performance based on these patterns. In natural language processing, error analysis has been applied to natural language generation tasks such as machine translation and text summarization~\citep{lu-etal-2023-toward}, as well as code generation tasks~\citep{wang2024largelanguagemodelsfail}. Additionally, error analysis with prompting has been used to aid evaluation in translation tasks~\citep{lu-etal-2024-error}. Our work focuses on error analysis in the context of autoformalization to address the lack of research on error patterns in this task.