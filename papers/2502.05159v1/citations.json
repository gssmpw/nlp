[
  {
    "index": 0,
    "papers": [
      {
        "key": "carlini2021extracting",
        "author": "Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Ulfar and others",
        "title": "Extracting training data from large language models"
      },
      {
        "key": "carlini2022quantifying",
        "author": "Carlini, Nicholas and Ippolito, Daphne and Jagielski, Matthew and Lee, Katherine and Tramer, Florian and Zhang, Chiyuan",
        "title": "Quantifying memorization across neural language models"
      },
      {
        "key": "karamolegkou2023copyright",
        "author": "Karamolegkou, Antonia and Li, Jiaang and Zhou, Li and S{\\o}gaard, Anders",
        "title": "Copyright violations and large language models"
      },
      {
        "key": "sok_mem",
        "author": "Valentin Hartmann and Anshuman Suri and Vincent Bindschaedler and David Evans and Shruti Tople and Robert West",
        "title": "SoK: Memorization in General-Purpose Large Language Models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "schwarzschild2024rethinking",
        "author": "Schwarzschild, Avi and Feng, Zhili and Maini, Pratyush and Lipton, Zachary C and Kolter, J Zico",
        "title": "Rethinking llm memorization through the lens of adversarial compression"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "zhou2023quantifyinganalyzingentitylevelmemorization",
        "author": "Zhenhong Zhou and Jiuyang Xiang and Chaomeng Chen and Sen Su",
        "title": "Quantifying and Analyzing Entity-level Memorization in Large Language Models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "nasr2311scalable",
        "author": "Nasr, Milad and Carlini, Nicholas and Hayase, Jonathan and Jagielski, Matthew and Cooper, A Feder and Ippolito, Daphne and Choquette-Choo, Christopher A and Wallace, Eric and Tram{\\`e}r, Florian and Lee, Katherine",
        "title": "Scalable Extraction of Training Data from (Production) Language Models. arXiv 2023"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "carlini2022quantifying",
        "author": "Carlini, Nicholas and Ippolito, Daphne and Jagielski, Matthew and Lee, Katherine and Tramer, Florian and Zhang, Chiyuan",
        "title": "Quantifying memorization across neural language models"
      },
      {
        "key": "zhou2023quantifyinganalyzingentitylevelmemorization",
        "author": "Zhenhong Zhou and Jiuyang Xiang and Chaomeng Chen and Sen Su",
        "title": "Quantifying and Analyzing Entity-level Memorization in Large Language Models"
      },
      {
        "key": "biderman2024emergent",
        "author": "Biderman, Stella and Prashanth, Usvsn and Sutawika, Lintang and Schoelkopf, Hailey and Anthony, Quentin and Purohit, Shivanshu and Raff, Edward",
        "title": "Emergent and predictable memorization in large language models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "kandpal2022deduplicating",
        "author": "Kandpal, Nikhil and Wallace, Eric and Raffel, Colin",
        "title": "Deduplicating training data mitigates privacy risks in language models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "abadi2016deep",
        "author": "Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li",
        "title": "Deep learning with differential privacy"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "Anil2021",
        "author": "Anil, Rohan and Ghazi, Badih and Gupta, Vineet and Kumar, Ravi and Manurangsi, Pasin",
        "title": "Large-scale Differentially Private BERT"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "elkin2023can",
        "author": "Elkin-Koren, Niva and Hacohen, Uri and Livni, Roi and Moran, Shay",
        "title": "Can Copyright be Reduced to Privacy?"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "hans2024like",
        "author": "Hans, Abhimanyu and Wen, Yuxin and Jain, Neel and Kirchenbauer, John and Kazemi, Hamid and Singhania, Prajwal and Singh, Siddharth and Somepalli, Gowthami and Geiping, Jonas and Bhatele, Abhinav and others",
        "title": "Be like a Goldfish, Don't Memorize! Mitigating Memorization in Generative LLMs"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "mireshghallah2022memorization",
        "author": "Mireshghallah, Fatemehsadat and Naseri, Mohammadali and Holzenberger, Nils and Mani, Pratyush and Ramaswamy, Harsha Nori and Khani, Mohammad and Tran, Daniel and Tramer, Florian",
        "title": "Memorization in nlp fine-tuning methods"
      },
      {
        "key": "pinto2024extracting",
        "author": "Pinto, Francesco and Rauschmayr, Nathalie and Tram{\\`e}r, Florian and Torr, Philip and Tombari, Federico",
        "title": "Extracting training data from document-based VQA models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "maini2023can",
        "author": "Maini, Pratyush and Mozer, Michael C and Sedghi, Hanie and Lipton, Zachary C and Kolter, J Zico and Zhang, Chiyuan",
        "title": "Can neural network memorization be localized?"
      },
      {
        "key": "jang2022knowledge",
        "author": "Jang, Joel and Yoon, Dongkeun and Yang, Sohee and Cha, Sungmin and Lee, Moontae and Logeswaran, Lajanugen and Seo, Minjoon",
        "title": "Knowledge unlearning for mitigating privacy risks in language models"
      },
      {
        "key": "sakarvadia2024mitigating",
        "author": "Sakarvadia, Mansi and Ajith, Aswathy and Khan, Arham and Hudson, Nathaniel and Geniesse, Caleb and Chard, Kyle and Yang, Yaoqing and Foster, Ian and Mahoney, Michael W",
        "title": "Mitigating Memorization In Language Models"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "shumailov2024ununlearning",
        "author": "Shumailov, Ilia and Hayes, Jamie and Triantafillou, Eleni and Ortiz-Jimenez, Guillermo and Papernot, Nicolas and Jagielski, Matthew and Yona, Itay and Howard, Heidi and Bagdasaryan, Eugene",
        "title": "Ununlearning: Unlearning is not sufficient for content regulation in advanced generative ai"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "huang2024demystifyingverbatimmemorizationlarge",
        "author": "Jing Huang and Diyi Yang and Christopher Potts",
        "title": "Demystifying Verbatim Memorization in Large Language Models"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "ippolito2022preventing",
        "author": "Ippolito, Daphne and Tram{\\`e}r, Florian and Nasr, Milad and Zhang, Chiyuan and Jagielski, Matthew and Lee, Katherine and Choquette-Choo, Christopher A and Carlini, Nicholas",
        "title": "Preventing verbatim memorization in language models gives a false sense of privacy"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "abad2024copyright",
        "author": "Abad, Javier and Donhauser, Konstantin and Pinto, Francesco and Yang, Fanny",
        "title": "Copyright-Protected Language Generation via Adaptive Model Fusion"
      }
    ]
  }
]