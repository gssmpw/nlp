\section{Conclusion}
\sys offers several key advantages for mitigating memorized generation in language models: it operates without requiring access to model weights or training data, and makes no assumptions about the underlying training distribution. Our theoretical analysis proves that the probability of generating memorized sequences decays exponentially with length, providing strong guarantees against verbatim reproduction. These properties are validated through our empirical evaluation, which demonstrates a 10-800x reduction in verbatim generation while maintaining model performance across both controlled and real-world experiments. While our current implementation focuses on natural language, extending the approach to other domains such as code generation or multiple languages remains a promising direction for future work.

\section*{Impact Statement}
While \sys substantially reduces memorized generation in large language models, it should not be considered a complete solution to memorization-related concerns. Our method focuses specifically on mitigating reproduction of training data, rather than addressing broader privacy risks such as membership inference attacks or advanced adversarial techniques. Users should carefully evaluate their specific requirements for memorization mitigation and consider additional safeguards when handling sensitive data or deploying models in privacy-critical applications.
