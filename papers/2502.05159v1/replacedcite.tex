\section{Related Work}
\subsection{Memorization in LLMs}
LLMs have been shown to memorize and potentially reproduce copyrighted information from their training data ____.  This is demonstrated through prefix attacks, where models prompted with training data prefixes generate their memorized completions.____ formalize this notion based on adversarial compression, requiring that any memorized sequence must be longer than the prefix used to elicit it. ____ and ____ demonstrate that large-scale training data can be extracted without access to training prefixes. Studies further indicate a correlation between model scale and memorization, with larger models regurgitating higher proportions of their training data ____.


\subsection{Mitigating Memorization and Verbatim Generation}

\paragraph{Pre-training}
Several methods have been developed to reduce memorization and verbatim generation during the model training process. ____ propose de-duplication though the prevalence of near-duplicate content in large-scale datasets limits its effectiveness. Differential Privacy (DP) ____ provides rigorous privacy guarantees by bounding the influence of individual data points on model predictions. However, DP suffers from high computational costs and negatively impacts model performance ____, while potentially being overly restrictive to mitigate verbatim generation ____. Other approaches include excluding fixed fractions of tokens from loss computation ____ and early stopping during training ____. While these pre-training interventions can help reduce memorization, they are typically expensive to implement, often degrade model performance, and are not accessible to end users of the models.

\paragraph{Post-training}
Post-training approaches offer alternative strategies for addressing memorization. One line of work focuses on unlearning methods ____, which attempt to identify and modify hidden neurons and weights associated with memorized content. However, these models can still be prompted to reveal training data ____ and often suffer from degraded performance ____. This has led to the development of methods that modify model outputs rather than weights. For instance, ____ propose blocking generations that exactly match training data, though this approach is limited to exact matches and requires access to the training corpus. ____ present a model fusion approach that uses the weighted sum of logits from two models. The resulting distribution is constrained to be equidistant from the two models. However, this method requires at least two LLMs (with the same vocabulary and tokenizer) trained on disjoint datasets, doubles memory requirements, and can suffer from performance degradation when the distributions of the two training sets differ or one of the models is weak.