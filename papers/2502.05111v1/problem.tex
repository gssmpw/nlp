\section{Constraint-Aligned Decoding with Backtrack}\label{sec:problem}

\begin{itemize}
\item Consider a checker as a function $\mathcal{C}: \Sigma^\ast \rightarrow \{\top, -, \bot\}$ in which $\checker(w) = \bot$ means that any continuation of $w$ does not satisfy the constraint. $\checker(w) = \top$ means that $w$ satisfies the constraint, and $\checker(w) = -$ means that $w$ may have a continuation that satisfies the constraint. 
In grammar-constrained decoding, $\checker(w) = \bot$ if $w \notin \langpre(\grammar)$, $\checker(w) = \top$ if $w \in \lang(\grammar)$, 
and $\checker(w) = -$ if $w \in \langpre(\grammar) \setminus \lang(\grammar)$.

\item Existing constrained decoding problem assumes $\checker(w_{1:i}) = -$ only if 
there exists a next token $w_{i+1} \in \Sigma$ such that $\checker(w_{1:i+1}) \neq \bot$.
So, in this assumption, the constrained-decoding algorithm can guide output $w$ to satisfy $\checker(w) = \top$ by filtering next tokens $w_{i+1}$ such that $\checker(w_{1:i+1}) = \bot$
(but can still be trapped in infinite sequence such that $\forall i.\, \checker(w_{1:i}) = -$).

\item Now we weaken the assumption by deleting the above sssumption. So, $\checker(w_{1:i}) = -$ may not imply that there is a next token $w_{i+1}$ such that $\checker(w_{1:i} \cdot w_{i+1}) = \top$, so the constrained-decoding can stuck. 
\end{itemize}

\paragraph{Constraint-Aligned Decoding}
\[
\probgrammarpg{\prob}{\checker}(\sent)  = \frac{\indicator[\checker(\sent) = \top] \cdot \prob(\sent)}{\sum_{\sent'} \indicator[\checker(\sent') = \top] \cdot \prob(\sent')}
\]

