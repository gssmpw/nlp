In this section, 
% we first introduce our training and sampling approach and then 
we demonstrate the  benefits of regularization for diffusion empirically.
Rather than relying on large-scale pipelines and data,
which are subject to a number of other factors,
we study the influence of regularization in simple, well-explored setups. 
We present a toy example and the MNIST family dataset here, deferring additional simulations and setups to Appendix Section~\ref{sec:ComSim}.


\subsection{Toy example}
We first highlight the influence of regularization on the sampling process of a 3D toy example. 
We consider $2000$ three-dimensional, independent Gaussian samples with mean zero and covariance matrix $\allowbreak[0.08,0,0;0,1,0;0,0,1]$;
hence, the data fluctuate most around the $y$ and $z$ axes.
We then train two diffusion models, with the same data: 
the original denoising score matching and the same with an additional sparsity-inducing regularization (as proposed in~\eqref{dscorematchR}) and $r=0.001$.
Figure~\ref{fig:toy} visualizes the data (first panel) and the sampling process with $T=60$ for original score matching (second panel) and the regularized version (third panel).
Both models start from the blue dot. 
The figure shows that the regularized version provides a more focused sampling. %leading to a faster convergence.

\begin{figure*}[htbp]
    % First row: single centered image
    \begin{minipage}{0.27\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/Toy/toydata.png}
        % Caption or additional description for the centered image
    \end{minipage}
       \hfill
    % \vspace{1em} % Adjust vertical space between rows
    % Second row: three images
    \begin{minipage}{0.27\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/Toy/toyOr.png}
        % Caption or description for this image
    \end{minipage}
    \hfill
    \begin{minipage}{0.27\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/Toy/toyR.png}
        % Caption or description for this image
    \end{minipage}

    \caption{Visualizing the sampling process for 3D data (first panel) with original denoising score matching (second panel) versus regularized denoising score matching (third panel).
The original samples are depicted as red circles, blue circles indicate the starting points for sampling, and green circles represent the latent generated samples.
The red arrows illustrate the sampling paths. It is evident that regularized denoising score matching predominantly adheres to the two-dimensional sub-manifold (along the $Y$ and $Z$ axes), whereas the original denoising score matching explores the entire 3D space.
    }\label{fig:toy}
\end{figure*}
\subsection{MNIST}\label{sec:mnist}
We now compare original score matching  and the regularized version on \mnist~dataset~\citep{LeCun1998} including $n=50\,000$ training samples. 
We are interested to time steps $T\in \{500,50,20\}$ for sampling and we consider regularization with $\tuning=0.0005$ for $T=500$ and $\tuning=0.003$ for $T\in \{50,20\}$.
In fact, we set the tuning parameter as a decreasing function of $T$, let say $\tuning=f[T]\in O(c'/T)$ for a real constant $c\in (0,\infty)$.
Note that two models are already trained over the same amount of data and identical settings employing different objectives. 
For sampling (starting from pure noise), then we try different values of time steps $T\in \{500,50,20\}$. 
That means, for small values of $T$, we just need to pick up a \textbf{larger step size} as we always start from pure noise (see Algorithm~\ref{alg:samp}).
Figure~\ref{fig:MNIST} shows the results. While the original score matching fails to generate reasonable samples for small values of $T$, our proposed score function performs successfully even for $T=20$. 
In all our simulations, we use the same network structure, optimization method, and sampling approach with identical settings for both approaches (see Appendix~\ref{sec:netstr} for detailed settings). The only difference lies in the objective functions: one is regularized, while the other is not. While it could be argued that alternative network structures or sampling processes might enhance the quality of the generated images for original score matching, our focus remains on the core idea of regularization fixing all other factors and structures.  
We defer the enhanced versions of our simulations aimed at achieving higher-quality images to future works.
% We provide all the details regarding our simulations settings in the Appendix~\ref{sec:netstr}. 

\begin{figure*}[htbp]
    \centering
    % First row: single centered image
    \begin{minipage}{0.18\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/MNIST/MNIST-True.png}
        % Caption or additional description for the centered image
    \end{minipage}
    
    \vspace{0.2em} % Adjust vertical space between rows
    
    % Second row: three images
    \begin{minipage}{0.18\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/MNIST/MNISTOr500.png}
        % Caption or description for this image
    \end{minipage}
    % \hfill
    \hspace{9em} 
    \begin{minipage}{0.18\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/MNIST/MNISTweak500.png}
        % Caption or description for this image
    \end{minipage}
    
    \vspace{0.2em} 
    \begin{minipage}{0.18\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/MNIST/MNISTOr50.png}
        % Caption or description for this image
    \end{minipage}
    \hspace{9em} 
    % \hfill
    \begin{minipage}{0.18\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/MNIST/MNISTR50.png}
        % Caption or description for this image
    \end{minipage}
    
    \vspace{0.2em} 
    
    \begin{minipage}{0.18\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/MNIST/MNISTOr20.png}
        % Caption or description for this image
    \end{minipage}
    \hspace{9em} 
    % \hfill
    \begin{minipage}{0.18\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/MNIST/MNISTR20.png}
        % Caption or description for this image
    \end{minipage}
    
   
    
    \caption{
    Image generation using the original denoising score matching (left column) versus the regularized version (right column) for different time steps, 
$T=500,T=50$, and $T=20$ (from top to bottom). The middle column displays $81 $ original samples from the \mnist~dataset for comparison with images of dimensions  $\Dim=28\times28\times 1=784$. 
Our regularized version  generates high-quality images for  
$T=500$ (comparable to the original denoising score matching) and still produces good images for small $T$, while the original denoising score matching totally fails. 
}
    \label{fig:MNIST}
\end{figure*}




\subsection{FashionMNIST}\label{sec:fmnist}
We follow almost all the settings as in Section~\ref{sec:mnist} with $\tuning=0.0001$ for $T=500$ and $\tuning=0.002$ for $T\in \{70,50\}$ for \fmnist~dataset~\citep{Xiao2017} including $n=50\,000$ training samples.  
Results are provided in Figures~\ref{fig:FMNIST}. 
Following the generated images obtained using both approaches, and ensuring that all factors except the objective functions remain identical, we observe that the original score-matching approach produces samples that appear oversmoothed and exhibit imbalanced distributions (see the first image of the left panel of Figure~\ref{fig:FMNIST}).  
In contrast, our regularized approach with a considerably small tuning parameter, generates images that resemble the true data more closely and exhibit a more balanced distribution (see the first image of the right panel of Figure~\ref{fig:FMNIST}). 
For instance, the percentages of generated images for Sandals, Trousers, Dresses, Ankle Boots, and Bags are approximately $(0.0, 0.7, 2.0, 3.0, 4.0)$ using the original score matching, compared to $(8.0, 6.0, 8.0, 10.0, 10.0)$ with the regularized version, highlighting the clear imbalance in distribution for the original score matching.




\begin{figure*}[htbp]
    \centering
    \begin{minipage}{0.28\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/FMNIST/FMT.png}
        % Caption or additional description for the centered image
    \end{minipage}
    
    \vspace{0.1em} % Adjust vertical space between rows
    % First row
    \begin{minipage}{0.28\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/FMNIST/FMOr500.png}
        % \caption{Caption for figure 1}
    \end{minipage}
    \hspace{13em} 
    \begin{minipage}{0.28\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/FMNIST/Rweak500.png}
        % \caption{Caption for figure 4}
    \end{minipage}

    \vspace{0.1em} 
    
    \begin{minipage}{0.28\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/FMNIST/FMOr70.png}
        % \caption{Caption for figure 2}
    \end{minipage}
    \hspace{13em} % Adjust vertical space between rows
     \begin{minipage}{0.28\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/FMNIST/FMR70.png}
        % \caption{Caption for figure 5}
    \end{minipage}
    
\vspace{0.1em}

    \begin{minipage}{0.28\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/FMNIST/FMOr50.png}
        % \caption{Caption for figure 3}
    \end{minipage}
     \hspace{13em} % Adjust vertical space between rows
    \begin{minipage}{0.28\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Figures/FMNIST/FMR50.png}
        % \caption{Caption for figure 6}
    \end{minipage}
    
    \caption{Image generation using the original denoising score matching (left column) versus the regularized version (right column) for different time steps,  $T=500, T=70$, and $T=50$ (from top to bottom).  
    The middle column displays $256$ original samples from the
\fmnist~dataset for comparison with images of  dimensions $\Dim=28\times28\times 1=784$.
 Our regularized version generates high-quality images for  
$T=500$ (comparable to the original denoising score matching) and still produces good images even for 
samll $T$, while the original denoising score matching totally fails.
Another notable observation is that our regularization results in more balanced image generation, as evident when comparing our method to the original denoising score matching at $T=500$, where the latter produces overly smooth images.
}\label{fig:FMNIST}
\end{figure*}




