
\section{Auxiliary results and proofs}
In this section,  we first provide  two auxiliary results and then, we present detailed proofs of our main results.
Note that throughout our proofs, we will omit the index  $\x_t$ from $\nabla_{\x_t}\log \Fdd_t(\cdot)$ for simplicity in notations and simply write $\nabla\log \Fdd_t(\cdot)$.  

\subsection{Auxiliary results}\label{sec:Aux}
We denote the distribution of the latent steps in the reverse process, utilizing the sparse gradient vector, as
 $\Bds_{t-1|t}\deq\mathcal{N}(\x_{t-1};\us_t(\x_t),\sigma_t^2\Identity)$ with 

\begin{equation}\label{eq:mus}
    \us_t(\x_t)\deq\frac{1}{\sqrt{\alpha_t}}\bigl(\x_t+(1-\alpha_t)\nabla_{\x_t}\log \Fdds_t(\x_t)\bigr)\,.
\end{equation}
We then connect the conditional distributions $\Fdd_{t-1|t}(\x_{t-1}|\x_t) $ and $\Bdds_{t-1|t}(\x_{t-1}|\x_t)$ using the following lemma inspired by proof approach of~\citet{liang2024nonN}: 
\begin{lemma}[Tilting factor]\label{lem:tilfactor}
 For a fixed $\x_t$ we have 
 \begin{equation*}
  \Fdd_{t-1|t}(\x_{t-1}|\x_t)  \varpropto \Bdds_{t-1|t}(\x_{t-1}|\x_t)\exp\bigl( \zeta_{t,t-1}(\x_t,\x_{t-1})\bigr)
\end{equation*}
with $\zeta_{t,t-1}(\x_t,\x_{t-1})\deq \log \Fdd_{t-1}(\x_{t-1})-\sqrt{\alpha_t}\x_{t-1}^T\nabla \log \Fdds_t(\x_t)+f(\x_t)$, where $f(\x_t)$ is an arbitrary function of $\x_t$.
\end{lemma}
The notation $\propto$ in the Lemma~\ref{lem:tilfactor} means proportional. 
Lemma~\ref{lem:tilfactor} is employed in the proof of our Lemma~\ref{lem:RevError} and its 
detailed proof is presented in Section~\ref{proof:tilf}.
\begin{lemma}[Log-density of  backward process]\label{lem:logdeng}
 We have 
 \begin{align*}
     \sum_{t=1}^T&~\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}} \biggl[\log\frac{\Bdd^s_{t-1|t}(X_{t-1}|X_t)}{\BddA_{t-1|t}(X_{t-1}|X_t)}\biggr] \\
     &\le (1-\alpha_t) \sum_{t=1}^T \biggl(\sqrt{\E_{X_t\sim Q_t}\norm{\nabla\log \Fdd_t(X_t)-\nabla\log \Fdds_t(X_t)}^2\E_{X_t\sim Q_t}\norm{\nabla\log \Fdds_t(X_t)-\scaleh\scorefh(X_t,t)}^2}\\
    &~~~+ \frac{1}{2}\E_{X_t\sim Q_t}\norm{\scaleh\scorefh(X_t,t)-\nabla\log q^s_t(X_t)}^2\biggr)\,.
 \end{align*}   
\end{lemma}
Lemma~\ref{lem:logdeng} is employed in the proof our main Theorem~\ref{the:maindS} and its detailed proof is presented in Section~\ref{proof:loggaussian}.
\subsection{Proof of Theorem~\ref{the:maindS}}\label{proof:mainR}
\begin{proof}

The poof approach is based on decomposing the total error using the Markov property of the forward and the backward process. 
We then, employ our Lemma~\ref{lem:RevError} and Lemma~\ref{lem:emp} to handle individual terms. 


Following the proof approach proposed by~\citet[Equation~13]{liang2024nonN} (based on Markov property of the forward and the backward process), we can decompose the total  error as  
\begin{equation*}
    \KL(\Fd_0 ||\BdA_0) \le \KL(\Fd_T||\BdA_T)+\sum_{t=1}^{T} \E_{X_t\sim \Fd_t}\bigl[\KL\bigl(\Fd_{t-1|t}(.|X_t)||\BdA_{t-1|t}(.|X_t)\bigr)\bigr]\,.
\end{equation*}
We then employ the auxiliary function $\Fdds_t(\cdot)$ that  satisfies our Assumption~\ref{Assum:approxs} (it doesn't need to be necessarily unique). 
We also use the notation $\Bdd^s_t(\cdot)$ for the  reverse counterpart  of the auxiliary function $\Fdds_t(\cdot)$ (see~\eqref{eq:mus}).
 We then  rewrite the previous display employing $\Bdd^s_t(\cdot)$ and the definition of $\KL$:
\begin{align*}
    \KL(\Fd_0 ||\BdA_0) &\le \KL(\Fd_T||\BdA_T)+\sum_{t=1}^{T} \E_{X_t\sim \Fd_t}\bigl[\KL\bigl(\Fd_{t-1|t}(.|X_t)||\BdA_{t-1|t}(.|X_t)\bigr)\bigr]\\
    % &=\KL(\Fd_T||\BdA_T)+\sum_{t=1}^{T} \E_{X_t\sim \Fd_t}\biggl[\E_{X_{t-1}\sim \Fd_{t-1}}\biggl[\log\frac{\Fdd_{t-1|t}(X_{t-1}|X_t)}{\BddA_{t-1|t}(X_{t-1}|X_t)}\biggr]\biggr]\\
&=\underbrace{\KL(\Fd_T||\BdA_T)}_{\text{Term~1: Initialization error}}
% +\underbrace{\sum_{t=1}^{T} \E_{\x_t\sim \Fd_{t},\x_{t-1}\sim \Fd_{t-1}}\biggl[\log\frac{\Fdd_{t-1|t}(\x_{t-1}|\x_t)}{\Fdds_{t-1|t}(\x_{t-1}|\x_t)}\biggr]}_{\text{Term~2: Approximation error}}\\
+\underbrace{\sum_{t=1}^{T} \E_{X_t,X_{t-1}\sim \Fd_{t,t-1}}\biggl[\log\frac{\Fdd_{t-1|t}(X_{t-1}|X_t)}{\Bdd^s_{t-1|t}(X_{t-1}|X_t)}\biggr]}_{\text{Term~2: Reverse-step error}}\\
&~~~~+\underbrace{\sum_{t=1}^{T} \E_{X_t,X_{t-1}\sim \Fd_{t,t-1}}\biggl[\log\frac{\Bdd^s_{t-1|t}(X_{t-1}|X_t)}{\BddA_{t-1|t}(X_{t-1}|X_t)}\biggr]}_{\text{Term~3: Estimation error}}\,.
\end{align*}
We now need to study each term specified above individually. 


\emph{Term~1: Initialization error}

Under the Assumption~\ref{Assum:FSM} and the assumed step size in~\eqref{eq:stepsize}, we have 
with~\citet[Remark~1]{liang2024nonN} 
\begin{align*}
  \KL(\Fd_T||\BdA_T) \le  \COr\frac{\FSM}{T^2}\,.
\end{align*}



\emph{Term~2: Reverse-step error}

Under our Assumption~\ref{Assum:approxs} and Assumption~\ref{assum:ReDe}
and with Lemma~\ref{lem:RevError} we have  
\begin{align*}
    \sum_{t=1}^{T}~&\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}}\biggl[\log\frac{\Fdd_{t-1|t}(X_{t-1}|X_t)}{\Bdd^s_{t-1|t}(X_{t-1}|X_t)}\biggr]\notag\\
    &\le  \frac{\COr}{T}\bigl(s\DerBound^2+  s^2\DerBound^2+ s^2\DerBound^2\epsilon\bigr)+\COr\sqrt{s}\DerBound \epsilon+\deltaT\,.
  %  &~~~~+\sum_{t=1}^{T}\Bigl(\E_{X_{t}\sim \Fd_{t}}\bigl[ \E_{X_{t-1}\sim \Fd_{t-1|t}}[\log \Fdd_{t-1}(X_{t-1})-\log \Fdds_{t-1}(X_{t-1})]\notag\\
  % &~~~~ -\E_{X_{t-1}\sim \Bds_{t-1|t}}[\log \Fdd_{t-1}(X_{t-1})-\log \Fdds_{t-1}(X_{t-1})]\bigr]\Bigr)\,.
\end{align*}

\emph{Term~3: Estimation error}


We employ 1.~Lemma~\ref{lem:logdeng}, 2.~adding a zero-valued term, 3.~triangle inequality, and 4.~the definition of our estimator and some linear algebra to obtain 
\allowdisplaybreaks
\begin{align*}
    \sum_{t=1}^{T}~&\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}}\biggl[\log\frac{\Bdd^s_{t-1|t}(X_{t-1}|X_t)}{\BddA_{t-1|t}(X_{t-1}|X_t)}\biggr]\\
    &\le \frac{1-\alpha_t}{2}  \sum_{t=1}^{T} \E_{X_t\sim Q_t}\norm{\scaleh\scorefh(X_t,t)-\nabla\log q^s_t(X_t)}^2\\
    &~~~+(1-\alpha_t)\sum_{t=1}^T\sqrt{\E_{X_t\sim Q_t}\norm{\nabla\log \Fdd_t(X_t)-\nabla\log \Fdds_t(X_t)}^2\E_{X_t\sim Q_t}\norm{\nabla\log \Fdds_t(X_t)-\scaleh\scorefh(X_t,t)}^2}\\
     &= \frac{1-\alpha_t}{2}  \sum_{t=1}^{T} \biggl(\frac{1}{n} \sum_{i=1}^{n}  \norm{\scaleh\scorefh(\x_t^i,t)-\nabla\log q^s_t(\x_t^i)}^2+\E_{X_t\sim Q_t}\norm{\scaleh\scorefh(X_t,t)-\nabla\log q^s_t(X_t)}^2\\
     &~~~-\frac{1}{n} \sum_{i=1}^{n}  \norm{\scaleh\scorefh(\x_t^i,t)-\nabla\log q^s_t(\x_t^i)}^2\biggr)\\
     &~~~+(1-\alpha_t)\sum_{t=1}^T\sqrt{\E_{X_t\sim Q_t}\norm{\nabla\log \Fdd_t(X_t)-\nabla\log \Fdds_t(X_t)}^2\E_{X_t\sim Q_t}\norm{\nabla\log \Fdds_t(X_t)-\scaleh\scorefh(X_t,t)}^2}\\
     &\le \frac{1-\alpha_t}{2}  \sum_{t=1}^{T} \biggl(\frac{1}{n} \sum_{i=1}^{n}  \norm{\scaleh\scorefh(\x_t^i,t)-\nabla\log q_t(\x_t^i)}^2+\frac{1}{n} \sum_{i=1}^{n}  \norm{\nabla \log q_t(\x_t^i)-\nabla\log q^s_t(\x_t^i)}^2\\
     &~~~+\E_{X_t\sim Q_t}\norm{\scaleh\scorefh(X_t,t)-\nabla\log q^s_t(X_t)}^2
     -\frac{1}{n} \sum_{i=1}^{n}  \norm{\scaleh\scorefh(\x_t^i,t)-\nabla\log q^s_t(\x_t^i)}^2\biggr)\\
     &~~~+(1-\alpha_t) \sum_{t=1}^T \sqrt{\E_{X_t\sim Q_t}\norm{\nabla\log \Fdd_t(X_t)-\nabla\log \Fdds_t(X_t)}^2\E_{X_t\sim Q_t}\norm{\nabla\log \Fdds_t(X_t)-\scaleh\scorefh(X_t,t)}^2}\\
      &\le \frac{1-\alpha_t}{2} \sum_{t=1}^{T} \biggl(\frac{1}{n} \sum_{i=1}^{n}  \norm{\scale\scoref(\x_t^i,t)-\nabla\log q_t(\x_t^i)}^2+\tuning\scale^2-\tuning\scaleh^2+\frac{1}{n} \sum_{i=1}^{n}  \norm{\nabla \log q_t(\x_t^i)-\nabla\log q^s_t(\x_t^i)}^2\\
     &~~~+\Bigl|\E_{X_t\sim Q_t}\norm{\scaleh\scorefh(X_t,t)-\nabla\log q^s_t(X_t)}^2
     -\frac{1}{n} \sum_{i=1}^{n}  \norm{\scaleh\scorefh(\x_t^i,t)-\nabla\log q^s_t(\x_t^i)}^2\Bigr|\biggr)\\
     &~~~+(1-\alpha_t) \sum_{t=1}^T \sqrt{\E_{X_t\sim Q_t}\norm{\nabla\log \Fdd_t(X_t)-\nabla\log \Fdds_t(X_t)}^2\E_{X_t\sim Q_t}\norm{\nabla\log \Fdds_t(X_t)-\scaleh\scorefh(X_t,t)}^2}
\end{align*}
for arbitrary function $\scoref(\cdot,\cdot)$ with $\Theta\in \paramspaceone$ and $\scale\in (0,\infty)$.


Now, by collecting all the pieces of the proof we obtain 
\begin{align*}
     \KL(\Fd_0 ||\BdA_0) &\le \COr\frac{\FSM}{T^2}+\frac{\COr}{T}\bigl(s\DerBound^2+  s^2\DerBound^2+ s^2\DerBound^2\epsilon\bigr)+\COr\sqrt{s}\DerBound \epsilon+\deltaT \notag\\
  %  &~~~~+\sum_{t=1}^{T} \biggl(\E_{X_{t-1}\sim \Fd_{t-1|t}}[\log \Fdd_{t-1}(X_{t-1})-\log \Fdds_{t-1}(X_{t-1})]\\
  % &~~~~ -\E_{X_{t-1}\sim \Bds_{t-1|t}}[\log \Fdd_{t-1}(X_{t-1})-\log \Fdds_{t-1}(X_{t-1})]\biggr)\\
     &~~~+\frac{1-\alpha_t}{2}  \sum_{t=1}^{T} \biggl(\frac{1}{n} \sum_{i=1}^{n}  \norm{\scale\scoref(\x_t^i,t)-\nabla\log q_t(\x_t^i)}^2+\tuning\scale^2-\tuning\scaleh^2\\
      &~~~+\frac{1}{n} \sum_{i=1}^{n}  \norm{\nabla \log q_t(\x_t^i)-\nabla\log q^s_t(\x_t^i)}^2\\
     &~~~+\sup_{\NetP\in \paramspaceone}\Bigl|\E_{X_t\sim Q_t}\norm{\scaleh\scoref(X_t,t)-\nabla\log q^s_t(X_t)}^2
     -\frac{1}{n} \sum_{i=1}^{n}  \norm{\scaleh\scoref(\x_t^i,t)-\nabla\log q^s_t(\x_t^i)}^2\Bigr|\\
     &~~~+2\sqrt{\E_{X_t\sim Q_t}\norm{\nabla\log \Fdd_t(X_t)-\nabla\log \Fdds_t(X_t)}^2\E_{X_t\sim Q_t}\norm{\nabla\log \Fdds_t(X_t)-\scaleh\scorefh(X_t,t)}^2}\biggr)\,.
\end{align*}
A high level idea now is choosing the tuning parameter  $\tuning$ in such a way that the term $-\tuning\scaleh^2$ can dominate the  terms in the absolute value that are dependent over $\scaleh$. 
The point here is that the terms in the absolute value are growing in the sparse function space.
Employing Lemma~\ref{lem:emp}, we obtain for 
$\tuning\ge 8  \sqrt{2\log n /n}$ 
\begin{align*}
     \KL(\Fd_0 ||\BdA_0) &\le \frac{\COr\FSM}{T^2}+\frac{\COr}{T}\bigl(s\DerBound^2+  s^2\DerBound^2+ s^2\DerBound^2\epsilon\bigr)+\COr\sqrt{s}\DerBound \epsilon+\deltaT\notag\\
  %  &~~~~+\sum_{t=1}^{T} \biggl(\E_{X_{t-1}\sim \Fd_{t-1|t}}[\log \Fdd_{t-1}(X_{t-1})-\log \Fdds_{t-1}(X_{t-1})]\\
  % &~~~~ -\E_{X_{t-1}\sim \Bds_{t-1|t}}[\log \Fdd_{t-1}(X_{t-1})-\log \Fdds_{t-1}(X_{t-1})]\biggr)\\
     &~~~+\frac{1-\alpha_t}{2}   \sum_{t=1}^{T} \biggl(\inf_{\NetP\in \paramspaceone; \scale\in (0,\infty)}\biggl\{\frac{1}{n} \sum_{i=1}^{n}  \norm{\scale\scoref(\x_t^i,t)-\nabla\log q_t(\x_t^i)}^2+\tuning\scale^2\biggr\}\\
      &~~~+\frac{1}{n} \sum_{i=1}^{n}  \norm{\nabla \log q_t(\x_t^i)-\nabla\log q^s_t(\x_t^i)}^2+ s\DerBound^2\frac{\sqrt{2\log n}}{n}\\
      &~~~+2\sqrt{\E_{X_t\sim Q_t}\norm{\nabla\log \Fdd_t(X_t)-\nabla\log \Fdds_t(X_t)}^2\E_{X_t\sim Q_t}\norm{\nabla\log \Fdds_t(X_t)-\scaleh\scorefh(X_t,t)}^2}\biggr)
\end{align*}
with probability at least $1-32/n^2$.


Using Assumption~\ref{Assum:approxs},~\eqref{eq:stepsize}, and \eqref{eq:paramspace} we also obtain 
\begin{align*}
   (1-\alpha_t)  \sum_{t=1}^{T} &~\sqrt{\E_{X_t\sim Q_t}\norm{\nabla\log \Fdd_t(X_t)-\nabla\log \Fdds_t(X_t)}^2\E_{X_t\sim Q_t}\norm{\nabla\log \Fdds_t(X_t)-\scaleh\scorefh(X_t,t)}^2} \\
   &\le (1-\alpha_t)   \Bigl(\max_{t\in \{1,\dots,T\}} \sqrt{\E_{X_t\sim Q_t}\norm{\nabla\log \Fdds_t(X_t)-\scaleh\scorefh(X_t,t)}^2}\Bigr)\\
   &~~~~~\sum_{t=1}^{T} \sqrt{\E_{X_t\sim Q_t}\norm{\nabla\log \Fdd_t(X_t)-\nabla\log \Fdds_t(X_t)}^2}\\
  % & \le \frac{1-\alpha_t}{2}  (\scaleh+s\scaleS) \sum_{t=1}^{T} \sqrt{\E_{X_t\sim Q_t}\norm{\nabla\log \Fdd_t(X_t)-\nabla\log \Fdds_t(X_t)}_2^2} \\
   &\le \COr(\scaleh+\sqrt{s}\DerBound)\Esparsity \\
   &\le \COr\Esparsity \sqrt{s}\DerBound\\
   &\le \COr\sqrt{s}\DerBound\frac{1}{T}\,.
\end{align*}
Let's note that for the third inequality above we can follow the same approach as in~\citet[Page~155]{taheri2021} to conclude that for large enough tuning (just double it), $\scaleh\le 3\scaleS$ (where $\scaleS=\norm{\nabla\log \Fdds_t(X_t)}_{\infty}\approx \DerBound$) that gives us the space to remove $\scaleh$ from our bounds. 
Let's also note that under the Assumption~\ref{Assum:approxs} and \eqref{eq:stepsize}, we can also conclude that 
\begin{align*}
    (1-\alpha_t)  \sum_{t=1}^{T} \frac{1}{n} \sum_{i=1}^{n}  \norm{\nabla \log q_t(\x_t^i)-\nabla\log q^s_t(\x_t^i)}^2 \lesssim \Esparsity \le \frac{1}{T}\,.
\end{align*}
Finally, collecting   displays above, some simplifications, and  keeping the dominant factors gives us the desired results. 
\end{proof}



\subsection{Proof of Lemma~\ref{lem:RevError}}\label{proof:lemReverror}
\begin{proof}

 
We start the proof with Lemma~\ref{lem:tilfactor} that relates $\Fdd_{t-1|t}(\x_{t-1}|\x_t)$ and $\Bdd^s_{t-1|t}(\x_{t-1}|\x_t)$  by
\begin{align}
  \Fdd_{t-1|t}(\x_{t-1}|\x_t)  \varpropto \Bdds_{t-1|t}(\x_{t-1}|\x_t)\exp\bigl( \zeta_{t,t-1}(\x_t,\x_{t-1})\bigr)
\end{align}
with $\zeta_{t,t-1}(\x_t,\x_{t-1})= \log \Fdd_{t-1}(\x_{t-1})-\sqrt{\alpha_t}\x_{t-1}^T\nabla \log \Fdds_t(\x_t)+f(\x_t)$, where $f(\x_t)$ is an arbitrary function of $\x_t$.
Now, let's progress with adding a zero-valued term to the $\zeta_{t,t-1}(\x_t,\x_{t-1})$ 

\begin{align*}
\zeta_{t,t-1}(\x_t,\x_{t-1})&=\log \Fdds_{t-1}(\x_{t-1})-\sqrt{\alpha_t}\x_{t-1}^T\nabla \log \Fdds_t(\x_t)\\
&~~~+ \log \Fdd_{t-1}(\x_{t-1})-\log \Fdds_{t-1}(\x_{t-1})+f(\x_t)
\end{align*}
and set $f(\x_t)=-\log \Fdds_{t-1}(\us_t)+\sqrt{\alpha_t}(\us_{t})^{T}\nabla \log \Fdds_t(\x_{t})$. 
Then, we have 
\begin{align*}
  \zeta_{t,t-1}(\x_t,\x_{t-1})&= \log \Fdds_{t-1}(\x_{t-1})-\log \Fdds_{t-1}(\us_t)-(\x_{t-1}-\us_{t})^T\sqrt{\alpha_t}\nabla \log \Fdds_t(\x_{t})\\
  &~~~+ \log \Fdd_{t-1}(\x_{t-1})-\log \Fdds_{t-1}(\x_{t-1})\,.
\end{align*}
For a fixed $\x_t$, then we  have (the denominator is for normalization reason)
\begin{equation*}
    \Fdd_{t-1|t}(\x_{t-1}|\x_t) =\frac{\Bdds_{t-1|t}(\x_{t-1}|\x_t)\exp\bigl( \zeta_{t,t-1}(\x_t,\x_{t-1})\bigr)}{\E_{X_{t-1}\sim \Bds_{t-1|t}}\bigl[\exp\bigl( \zeta_{t,t-1}(\x_t,X_{t-1})\bigr)\bigr]}\,.
\end{equation*}
We then use the above display and Jensen's inequality to obtain  
\begin{align*}
   &\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}}\biggl[\log\frac{\Fdd_{t-1|t}(X_{t-1}|X_t)}{\Bdd^s_{t-1|t}(X_{t-1}|X_t)}\biggr]\\
   &=\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}}\Bigl[\zeta_{t,t-1}(X_t,X_{t-1})
   -\log \E_{X_{t-1}\sim \Bds_{t-1|t}}\bigl[\exp\bigl( \zeta_{t,t-1}(X_t,X_{t-1})\bigr)\bigr] \Bigr]\\
    &=\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}}\bigl[\zeta_{t,t-1}(X_t,X_{t-1})\bigr]
   -\E_{X_t\sim \Fd_{t}}\Bigl[\log \E_{X_{t-1}\sim \Bds_{t-1|t}}\bigl[\exp\bigl( \zeta_{t,t-1}(X_t,X_{t-1})\bigr)\bigr] \Bigr]\\
   &\le \E_{X_t,X_{t-1}\sim \Fd_{t,t-1}}\bigl[\zeta_{t,t-1}(X_t,X_{t-1})\bigr]
   -\E_{X_t\sim \Fd_{t}}\Bigl[ \E_{X_{t-1}\sim \Bds_{t-1|t}}\bigl[ \zeta_{t,t-1}(X_t,X_{t-1})\bigr] \Bigr]\,.
\end{align*}
% The second term in the last inequality above can be treated employing same approach as in~\citet[Lemma~7]{liang2024non}.
Now, let's rewrite 
\begin{align*}
  \zeta_{t,t-1}(\x_t,\x_{t-1})&= \log \Fdds_{t-1}(\x_{t-1})-\log \Fdds_{t-1}(\us_t)-(\x_{t-1}-\us_{t})^T\sqrt{\alpha_t}\nabla \log \Fdds_t(\x_{t})\\
  &~~~+ \log \Fdd_{t-1}(\x_{t-1})-\log \Fdds_{t-1}(\x_{t-1})\\
  &\eqd\zeta'_{t,t-1}(\x_t,\x_{t-1})+ \log \Fdd_{t-1}(\x_{t-1})-\log \Fdds_{t-1}(\x_{t-1})\,.
\end{align*}
We are now left with  three terms: 
1.~$\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}}[\zeta'_{t,t-1}(X_t,X_{t-1})]$, 2.~$\allowbreak \E_{X_t\sim \Fd_{t},X_{t-1}\sim \Bds_{t-1|t}}[\zeta'_{t,t-1}(X_t,X_{t-1})]$,
and 
3.~$\E_{X_{t}\sim \Fd_{t}}[\E_{X_{t-1}\sim \Fd_{t-1|t}}[\log \Fdd_{t-1}(X_{t-1})-\log \Fdds_{t-1}(X_{t-1})]-\E_{X_{t-1}\sim \Bds_{t-1|t}}[\log \Fdd_{t-1}(X_{t-1})-\log \Fdds_{t-1}(X_{t-1})]]$ and we need to study  1. and 2. in details: 


\emph{Term~1:} $\allowbreak \E_{X_t\sim \Fd_{t},X_{t-1}\sim \Bds_{t-1|t}}[\zeta'_{t,t-1}(X_t,X_{t-1})]$

We  1.~use the definition of  $\zeta'_{t,t-1}(X_t,X_{t-1})$, 2.~(Second order) Taylor expand $\log \Fdds_{t-1}(X_{t-1})$ around $\us_t$, 3.~use~\citet[Lemma~7]{liang2024nonN} that implies $\E_{X_{t-1}\sim \Bds_{t-1|t}}[(X_{t-1}^i-(\us)_t^i)^p]=0~~\forall p\ge 1~odd$ (we use the notation $X_{t}^i$ to referenec to the $i$th feature of the vector $X_{t}$), 4.using the fact that $X_{t-1}^i$ is conditionally independent of $X_{t-1}^j$ for $i\ne j$ and again $\E_{X_{t-1}\sim \Bds_{t-1|t}}[(X_{t-1}^i-(\us)_t^i)^p]=0~~\forall p\ge 1~odd$, and 5.~$\E_{X_{t-1}\sim \Bds_{t-1|t}}[(X_{t-1}^i-(\us)_t^i)^2]=(1-\alpha_t)/\alpha_t$ (see \eqref{eq:mus}) 

\begin{align*}
    \E&_{X_t\sim \Fd_{t},X_{t-1}\sim \Bds_{t-1|t}}[\zeta'_{t,t-1}(X_t,X_{t-1})]\\
    &=\E_{X_t\sim \Fd_{t},X_{t-1}\sim \Bds_{t-1|t}}\bigl[\log \Fdds_{t-1}(X_{t-1})-\log \Fdds_{t-1}(\us_t)-(X_{t-1}-\us_{t})^T\sqrt{\alpha_t}\nabla \log \Fdds_t(X_{t})\bigr]\\
    &\approx \E_{X_t\sim \Fd_{t},X_{t-1}\sim \Bds_{t-1|t}}\Bigl[\nabla\log \Fdds_{t-1}(\us_t)(X_{t-1}-\us_t)-(X_{t-1}-\us_{t})^T\sqrt{\alpha_t}\nabla \log \Fdds_t(X_{t})\\
    % &~~~~~~~~+\sum_{p=2}^{\infty} T_p(\log \Fdds_{t-1},X_{t-1},\us_t)\Bigr]\\
    &~~~~~~~~+\frac{1}{2}(X_{t-1}-\us_t)^T \nabla^2\log \Fdds_{t-1}(\us_t)(X_{t-1}-\us_t)\Bigr] \\
    &=\E_{X_t\sim \Fd_{t},X_{t-1}\sim \Bds_{t-1|t}}\Bigl[\frac{1}{2}(X_{t-1}-\us_t)^T \nabla^2\log \Fdds_{t-1}(\us_t)(X_{t-1}-\us_t)\Bigr] \\
    &=\frac{1}{2}\sum_{i=1}^{\Dim}  \E_{X_t\sim \Fd_{t}} \bigl[\bigl(\nabla^2\log \Fdds_{t-1}(\us_t)\bigr)_{ii}\E_{X_{t-1}\sim \Bds_{t-1|t}}\bigl(X_{t-1}^i-(\us_t)^i\bigr)^2\bigr]\\
    &=\frac{(1-\alpha_t)}{2\alpha_t}\sum_{i=1}^{\Dim}  \E_{X_t\sim \Fd_{t}} \bigl[\bigl(\nabla^2\log \Fdds_{t-1}(\us_t)\bigr)_{ii}\bigr]\,.
    % &\approx \frac{1}{2} \norm{\E_{X_t\sim \Fd_{t}}[\nabla^2\log \Fdds_{t-1}(\us_t)] }\norm{\E_{X_{t-1}\sim \Bds_{t-1|t}}[(X_{t-1}-\us_t)^T (X_{t-1}-\us_t)]} \tag{\MH{use higher order derivatives to skip that $\approx$}}\,.
    % &\le \frac{1}{2}\E_{X_t\sim \Fd_{t},X_{t-1}\sim \Bds_{t-1|t}}\norm{(X_{t-1}-\us_t)^T (X_{t-1}-\us_t)}\E_{X_t\sim \Fd_{t},X_{t-1}\sim \Bds_{t-1|t}}\norm{\nabla^2\log \Fdds_{t-1}\bigl(X_{t-1}+\tau(\us_t-X_{t-1})\bigr)}\\
    % & \le \frac{1}{2} \frac{s(1-\alpha_t)}{\alpha_t}\E_{X_t\sim \Fd_{t},X_{t-1}\sim \Bds_{t-1|t}}\norm{\nabla^2\log \Fdds_{t-1}\bigl(X_{t-1}+\tau(\us_t-X_{t-1})\bigr)} \tag{\MH{maybe employ~\citet[Lemma~7]{liang2024non}  with some assumptions over the sparsity of noise}}\,.
\end{align*}
Note that here (as well as for the Term~2), for keeping the proofs simple and tractable, we use a second-order Taylor expansion and employ the notation $\approx$.  However, higher-order expansions can also be applied without affecting the dominant rates. As we extend to higher-order Taylor expansions, the dominant factor remains  $O((1-\alpha_t)/\alpha_t)^2$, so we omit those terms for simplicity.  

\emph{Term~2:} $\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}}[\zeta'_{t,t-1}(X_t,X_{t-1})]$

Following the same approach as in previous step and some further linear algebra we obtain 

\begin{align*}
    &\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}}\bigl[\zeta'_{t,t-1}(X_t,X_{t-1})\bigr]\\
    &~~~~~=\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}}
    \bigl[\log \Fdds_{t-1}(X_{t-1})-\log \Fdds_{t-1}(\us_t)-(X_{t-1}-\us_{t})^T\sqrt{\alpha_t}\nabla \log \Fdds_t(X_{t})\bigr]\\
    &~~~~~\approx\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}}
    \Bigl[\nabla\log \Fdds_{t-1}(\us_t)(X_{t-1}-\us_t)-(X_{t-1}-\us_{t})^T\sqrt{\alpha_t}\nabla \log \Fdds_t(X_{t})\\
    % &~~~~~~~~+\sum_{p=2}^{\infty} T_p(\log \Fdds_{t-1},X_{t-1},\us_t)\Bigr]\\
    &~~~~~~~~+\frac{1}{2}(X_{t-1}-\us_t)^T \nabla^2\log \Fdds_{t-1}(\us_t)(X_{t-1}-\us_t)\Bigr] \\
    &~~~~~= (1-\sqrt{\alpha_t})\E_{X_t\sim \Fd_{t}}
    \bigl[\nabla\log \Fdds_{t-1}(\us_t)\E_{X_{t-1}\sim \Fd_{t-1|t}}[(X_{t-1}-\us_t)]\bigr]\\
    % &~~~~~~~~+\E_{X_t\sim \Fd_{t},X_{t-1}\sim \Fd_{t-1}}\Bigl[\sum_{p=2}^{\infty} T_p(\log \Fdds_{t-1},X_{t-1},\us_t)\Bigr]\,,
    &~~~~~~~~+\frac{1}{2}\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}}
    \bigl[(X_{t-1}-\us_t)^T \nabla^2\log \Fdds_{t-1}(\us_t)(X_{t-1}-\us_t)\bigr]\,.
\end{align*}



Employing~\citet[Lemma~8; first claim]{liang2024nonN},  we have $\E_{X_{t-1}\sim \Fd_{t-1|t}}[X_{t-1}]=\ut$.
That implies
\begin{align*}
    \E_{X_{t-1}\sim \Fd_{t-1|t}}[(X_{t-1}-\us_t)]
    &=\E_{X_{t-1}\sim \Fd_{t-1|t}}[X_{t-1}]-\us_t\\
    &=\ut-\frac{1}{\sqrt{\alpha_t}}\bigl(\x_t+(1-\alpha_t)\nabla\log \Fdds_t(\x_t)\bigr)\\
    &=\frac{(1-\alpha_t)}{\sqrt{\alpha_t}}\bigl(\nabla\log \Fdd_t(\x_t)-\nabla\log \Fdds_t(\x_t)\bigr)\,.
\end{align*}

Collecting  the pieces above together with Cauchy–Schwarz inequality we obtain  
\begin{align*}
    &\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}}\bigl[\zeta'_{t,t-1}(X_t,X_{t-1})\bigr]\\
    &~~~~~\le \frac{(1-\alpha_t)}{\sqrt{\alpha_t}}(1-\sqrt{\alpha_t})\sqrt{\E_{X_t\sim \Fd_{t}}\norm{
    \nabla\log \Fdds_{t-1}(\us_t)}^2\E_{X_t\sim \Fd_{t}}\norm{\nabla\log \Fdd_t(X_t)-\nabla\log \Fdds_t(X_t)}^2}\\
    &~~~~~~~~+\frac{1}{2}\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}}
    \Bigl[(X_{t-1}-\us_t)^T \nabla^2\log \Fdds_{t-1}(\us_t)(X_{t-1}-\us_t)\Bigr]\,.
\end{align*}
Now let's treat the second term in the inequality above by 1.~adding a zero-valued term, 2.~expanding the product, 3.~using~\citet[Lemma~8; second claim]{liang2024nonN} and the fact that terms two and three goes to zero and some rewriting 

   \begin{align}\label{eq:varXmus}
    \E_{X_{t}\sim \Fd_{t}}&\bigl[\E_{X_{t-1}\sim \Fd_{t-1|t}}[(X_{t-1}-\ut+\ut-\us_t)^T(X_{t-1}-\ut+\ut-\us_t)]\bigr] \notag\\
    &=\E_{X_{t}\sim \Fd_{t}}\bigl[\E_{X_{t-1}\sim \Fd_{t-1|t}}[(X_{t-1}-\ut)^T(X_{t-1}-\ut)]\bigr] \notag\\
    &+\E_{X_{t}\sim \Fd_{t}}\bigl[\E_{X_{t-1}\sim \Fd_{t-1|t}}[(X_{t-1}-\ut)^T(\ut-\us_t)]\bigr] \notag\\
    &+\E_{X_{t}\sim \Fd_{t}}\bigl[\E_{X_{t-1}\sim \Fd_{t-1|t}}[(\ut-\us_t)^T(X_{t-1}-\ut)]\bigr] \notag\\
    &+\E_{X_{t}\sim \Fd_{t}}\bigl[\E_{X_{t-1}\sim \Fd_{t-1|t}}[(\ut-\us_t)^T(\ut-\us_t)]\bigr] \notag\\
    &=\E_{X_{t}\sim \Fd_{t}}\Bigl [\frac{1-\alpha_t}{\alpha_t}\Identity+\frac{(1-\alpha_t)^2}{\alpha_t}\nabla^2 \log \Fdd_t(X_t)\Bigr]\notag\\
    &+\E_{X_{t}\sim \Fd_{t}}\biggl[\frac{(1-\alpha_t)^2}{\alpha_t}\bigl(\nabla\log\Fdds_t(X_t)-\nabla\log\Fdd_t(X_t)\bigr)^T\bigl(\nabla\log \Fdds_t(X_t)-\nabla\log \Fdd_t(X_t)\bigr)\biggr]\,.
   \end{align}
   Above results state that our term involving $(1-\alpha_t)\Identity/\alpha_t$ can be canceled out by the terms  from  Step~1. We  then need to study the remaining terms that all involve the nice factor $(1-\alpha_t)^2$. 

So, collecting all the pieces of the proof, we  1.~use the results from Term~1. and Term~2.,  2.~implying some linear algebra to expand the product, 3.~use~\eqref{eq:varXmus} and cancel out terms involving the multiple $(1-\alpha_t)$ (for simplicity we have ignored the last term in~\eqref{eq:varXmus} since it has a minor affect on our final rates), 4.~using our Assumption~\eqref{Assum:approxs}, $\E_{X_t\sim \Fd_{t}}\norm{
    \nabla\log \Fdds_{t-1}(\us_t)}^2 \le s \norm{\nabla\log \Fdds_{t-1}(\us_t)}_{\infty}^2\lessapprox s  \DerBound^2 $, 5.~once again use the Assumption~\eqref{Assum:approxs} that implies  $s$ sparsity between entries of $
    \nabla\log \Fdds_{t-1}(\us_t)$, that also implies sparsity for the second order derivative (it causes that just a fraction of entries get involved in those sums) (also note that the last term is appeared regarding the term that we neglected in~\eqref{eq:varXmus}), and  6.~use our Assumption over the step sizes~\eqref{eq:stepsize} to obtain 
\allowdisplaybreaks
\begingroup
     \begin{align*}
       \sum_{t=1}^T\E&_{X_t,X_{t-1}\sim \Fd_{t,t-1}}\biggl[\log\frac{\Fdd_{t-1|t}(X_{t-1}|X_t)}{\Bdd^s_{t-1|t}(X_{t-1}|X_t)}\biggr]\\
       &\le \sum_{t=1}^T\biggl(\frac{(1-\alpha_t)}{\sqrt{\alpha_t}}(1-\sqrt{\alpha_t})\sqrt{\E_{X_t\sim \Fd_{t}}\norm{
    \nabla\log \Fdds_{t-1}(\us_t)}^2\E_{X_t\sim \Fd_{t}}\norm{\nabla\log \Fdd_t(X_t)-\nabla\log \Fdds_t(X_t)}^2}\\
    &~~~~~~~~+\frac{1}{2}\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}}
    \Bigl[(X_{t-1}-\us_t)^T \nabla^2\log \Fdds_{t-1}(\us_t)(X_{t-1}-\us_t)\Bigr]\\
       &~~~~~~~~-\frac{1}{2}\sum_{i=1}^{\Dim}  \E_{X_t\sim \Fd_{t}} \bigl(\nabla^2\log \Fdds_{t-1}(\us_t)\bigr)_{ii}\Bigl(\frac{1-\alpha_t}{\alpha_t}\Bigr)\biggr) \\
       &~~~~+\sum_{t=1}^{T}\bigl(\E_{X_{t}\sim \Fd_{t}}[\E_{X_{t-1}\sim \Fd_{t-1|t}}[\log \Fdd_{t-1}(X_{t-1})-\log \Fdds_{t-1}(X_{t-1})]\\
    &~~~~-\E_{X_{t-1}\sim \Bds_{t-1|t}}[\log \Fdd_{t-1}(X_{t-1})-\log \Fdds_{t-1}(X_{t-1})]]\bigr)\\
       &\le \sum_{t=1}^T \biggl(\frac{(1-\alpha_t)}{\sqrt{\alpha_t}}(1-\sqrt{\alpha_t})\sqrt{\E_{X_t\sim \Fd_{t}}\norm{
    \nabla\log \Fdds_{t-1}(\us_t)}^2\E_{X_t\sim \Fd_{t}}\norm{\nabla\log \Fdd_t(X_t)-\nabla\log \Fdds_t(X_t)}^2}\\
    &~~~~~~~~+\frac{1}{2}\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}}
    \biggl[\sum_{i=1}^{\Dim}(X_{t-1}-\us_t)_i^2 \Bigl(\nabla^2\log \Fdds_{t-1}(\us_t)\Bigr)_{ii}\\   &~~~~~~~~+\sum_{i=1}^{\Dim}\sum_{j=1,j\ne i}^{\Dim}(X_{t-1}-\us_t)_i(X_{t-1}-\us_t)_j \Bigl(\nabla^2\log \Fdds_{t-1}(\us_t)\Bigr)_{ij}\Bigr]\\
       &~~~~~~~~-\frac{1}{2}\sum_{i=1}^{\Dim}  \E_{X_t\sim \Fd_{t}} \bigl(\nabla^2\log \Fdds_{t-1}(\us_t)\bigr)_{ii}\Bigl(\frac{1-\alpha_t}{\alpha_t}\Bigr)\biggr)  \\
 &~~~~+\sum_{t=1}^{T}\bigl(\E_{X_{t}\sim \Fd_{t}}[\E_{X_{t-1}\sim \Fd_{t-1|t}}[\log \Fdd_{t-1}(X_{t-1})-\log \Fdds_{t-1}(X_{t-1})]\\
    &~~~~-\E_{X_{t-1}\sim \Bds_{t-1|t}}[\log \Fdd_{t-1}(X_{t-1})-\log \Fdds_{t-1}(X_{t-1})]]\bigr)\\
       &\le \sum_{t=1}^T \biggl(\frac{(1-\alpha_t)}{\sqrt{\alpha_t}}(1-\sqrt{\alpha_t})\sqrt{\E_{X_t\sim \Fd_{t}}\norm{
    \nabla\log \Fdds_{t-1}(\us_t)}^2\E_{X_t\sim \Fd_{t}}\norm{\nabla\log \Fdd_t(X_t)-\nabla\log \Fdds_t(X_t)}^2}\\
    &~~~~~~~~+\frac{1}{2}\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}}
    \biggl[\sum_{i=1}^{\Dim}\frac{(1-\alpha_t)^2}{\alpha_t}\bigl(\nabla^2 \log \Fdd_t(X_t)\bigr)_{ii} \Bigl(\nabla^2\log \Fdds_{t-1}(\us_t)\Bigr)_{ii}\\   &~~~~~~~~+\sum_{i=1}^{\Dim}\sum_{j=1,j\ne i}^{\Dim}\frac{(1-\alpha_t)^2}{\alpha_t}\bigl(\nabla^2 \log \Fdd_t(X_t)\bigr)_{ij} \Bigl(\nabla^2\log \Fdds_{t-1}(\us_t)\Bigr)_{ij}\Bigr]\biggr)\\
  &~~~~+\sum_{t=1}^{T}\bigl(\E_{X_{t}\sim \Fd_{t}}[\E_{X_{t-1}\sim \Fd_{t-1|t}}[\log \Fdd_{t-1}(X_{t-1})-\log \Fdds_{t-1}(X_{t-1})]\\
    &~~~~-\E_{X_{t-1}\sim \Bds_{t-1|t}}[\log \Fdd_{t-1}(X_{t-1})-\log \Fdds_{t-1}(X_{t-1})]]\bigr)\\
    &\le \sum_{t=1}^T \biggl(\frac{(1-\alpha_t)}{\sqrt{\alpha_t}}(1-\sqrt{\alpha_t})\sqrt{s\DerBound^2\E_{X_t\sim \Fd_{t}}\norm{\nabla\log \Fdd_t(X_t)-\nabla\log \Fdds_t(X_t)}^2}\\
    &~~~~~~~~+\frac{1}{2}\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}}
    \biggl[\sum_{i=1}^{\Dim}\frac{(1-\alpha_t)^2}{\alpha_t}\bigl(\nabla^2 \log \Fdd_t(X_t)\bigr)_{ii} \Bigl(\nabla^2\log \Fdds_{t-1}(\us_t)\Bigr)_{ii}\\   &~~~~~~~~+\sum_{i=1}^{\Dim}\sum_{j=1,j\ne i}^{\Dim}\frac{(1-\alpha_t)^2}{\alpha_t}\bigl(\nabla^2 \log \Fdd_t(X_t)\bigr)_{ij} \Bigl(\nabla^2\log \Fdds_{t-1}(\us_t)\Bigr)_{ij}\Bigr]\biggr)\\
  &~~~~+\sum_{t=1}^{T}\bigl(\E_{X_{t}\sim \Fd_{t}}[\E_{X_{t-1}\sim \Fd_{t-1|t}}[\log \Fdd_{t-1}(X_{t-1})-\log \Fdds_{t-1}(X_{t-1})]\\
    &~~~~-\E_{X_{t-1}\sim \Bds_{t-1|t}}[\log \Fdd_{t-1}(X_{t-1})-\log \Fdds_{t-1}(X_{t-1})]]\bigr)\\
    &\le \sum_{t=1}^{T}\biggl(\frac{(1-\alpha_t)}{\sqrt{\alpha_t}}(1-\sqrt{\alpha_t})( \COr \sqrt{s}\DerBound\epsilon)+\frac{(1-\alpha_t)^2}{\alpha_t}(\COr s\DerBound^2) +\frac{(1-\alpha_t)^2}{\alpha_t}(\COr s^2\DerBound^2)+\frac{(1-\alpha_t)^2}{\alpha_t}(\COr s^2\DerBound^2\epsilon)\biggr)\\
    &~~~~+\sum_{t=1}^{T}\bigl(\E_{X_{t}\sim \Fd_{t}}[\E_{X_{t-1}\sim \Fd_{t-1|t}}[\log \Fdd_{t-1}(X_{t-1})-\log \Fdds_{t-1}(X_{t-1})]\\
    &~~~~-\E_{X_{t-1}\sim \Bds_{t-1|t}}[\log \Fdd_{t-1}(X_{t-1})-\log \Fdds_{t-1}(X_{t-1})]]\bigr)\\
&\le \COr \sqrt{s}\DerBound \epsilon+\frac{\COr s\DerBound^2}{T} +\frac{\COr s^2\DerBound^2}{T}+\frac{\COr s^2\DerBound^2\epsilon}{T}\\
    &~~~~~~~~+\sum_{t=1}^{T}\bigl(\E_{X_{t}\sim \Fd_{t}}[\E_{X_{t-1}\sim \Fd_{t-1|t}}[\log \Fdd_{t-1}(X_{t-1})-\log \Fdds_{t-1}(X_{t-1})]\\
    &~~~~~~~~-\E_{X_{t-1}\sim \Bds_{t-1|t}}[\log \Fdd_{t-1}(X_{t-1})-\log \Fdds_{t-1}(X_{t-1})]]\bigr)\,,
   \end{align*}
   \endgroup
as desired.  
Note that the constant $\COr$ is employed for absorbing all constants and it might change from line to line in the proofs. 
\end{proof}












\subsection{Proof of Lemma~\ref{lem:emp}}\label{proof:lememp}
\begin{proof}
Our proof approach is based on symmetrization of probabilities and  our sparsity  assumptions over $\nabla\log q^s_t(\x_t)$. 

Let's start with the application of symmetrization of probabilities with $\zeta_i$ for $i\in \{1,\dots,n\}$ as i.i.d. Rademacher random variables that are independent of the data~\citet[Lemma 16.1]{van2016estimation}, and employing Contrcation principle~\citep[Theorem~4.4]{ledoux2013probability} to obtain  
\allowdisplaybreaks
\begingroup
 \begin{align*}
     \Pr \biggl(\sup_{\NetP\in \paramspaceone}\Bigl|&\E_{X_t\sim Q_t}\norm{\scaleh\scoref(X_t,t)-\nabla\log q^s_t(X_t,t)}^2
     -\frac{1}{n} \sum_{i=1}^{n}  \norm{\scaleh\scoref(\x_t^i,t)-\nabla\log q^s_t(\x_t^i)}^2\Bigr| \ge 4\Rs\sqrt{\frac{2t}{n}}\biggr)\\
     &\le 4 \Pr \biggl(\sup_{\NetP\in \paramspaceone}\Bigl|\frac{1}{n} \sum_{i=1}^{n} \zeta_i \norm{\scaleh\scoref(\x_t^i,t)-\nabla\log q^s_t(\x_t^i)}^2\Bigr| \ge \Rs\sqrt{\frac{2t}{n}}\biggr)\\
     &\le 8 \Pr \biggl(\sup_{\NetP\in \paramspaceone}\Bigl|\frac{1}{n} \sum_{i=1}^{n} 2\zeta_i \bigl( \norm{\scaleh\scoref(\x_t^i,t)}^2+\norm{\nabla\log q^s_t(\x_t^i)}^2\bigr)\Bigr| \ge \Rs\sqrt{\frac{2t}{n}}\biggr)\\
     &\le 8 \Pr \biggl(\sup_{\NetP\in \paramspaceone}\Bigl|\frac{1}{n} \sum_{i=1}^{n} 2\zeta_i \bigl( \norm{\scoref(\x_t^i,t)}^2\Bigr| \ge \frac{\Rs}{2\scaleh^2}\sqrt{\frac{2t}{n}}\eqd t'\biggr)\\
     &~~~+8 \Pr \biggl(\sup_{\NetP\in \paramspaceone}\Bigl|\frac{1}{n} \sum_{i=1}^{n} 2\zeta_i \bigl( \norm{\nabla\log q^s_t(\x_t^i)}^2\Bigr| \ge \frac{\Rs}{2}\sqrt{\frac{2t}{n}}\eqd t''\biggr)\,.
     % &\le 32\exp\biggl(-\frac{n  t'^2}{s^4}\biggr)\,.
 \end{align*}
 \endgroup
 Then, we employ our definition that $\sup_{\NetP\in \paramspaceone} \norm{\scoref(\x_t^i,t)}_1\le 1$ that also implies  $\sup_{\NetP\in \paramspaceone} \norm{\scoref(\x_t^i,t)}^2\le 1$. 
 This, can reveal that random variables $z_i=\zeta_i \norm{\scoref(\x_t^i)}^2$ are bounded and have zero-mean. 
 So, we can employ Hoeffding's inequality~\citep[Theorem~2.6.3]{Vershynin2018} (where we used $K=\max_{i\in \{1,\dots,n\}} \norm{z_i}_{\Psi_2}\le C\norm{z_i}_{\infty}$ and $\norm{a}^2=1/n^2$). 
 Same can hold for $y_i=\zeta_i \norm{\nabla\log q^s_t(\x_t^i)}^2$, that is $y_i=\zeta_i \norm{\nabla\log q^s_t(\x_t^i)}^2$ are zero-mean random variables and bounded $\norm{\nabla\log q^s_t(\x_t^i)}^2 \le s \norm{\nabla\log q^s_t(\x_t^i)}_{\infty} \le s  \DerBound^2$, where we have used Assumption~\ref{Assum:approxs} and Assumption~\ref{assum:ReDe} to conclude that $\norm{\nabla\log q^s_t(\x_t^i)}_{\infty} \eqd \scaleS\approx \norm{\nabla\log q_t(\x_t^i)}_{\infty} \le  \DerBound$.
 Now, we can progress as following 
 \begin{align*}
     \Pr \biggl(\sup_{\NetP\in \paramspaceone}\Bigl|\E_{X_t\sim Q_t}\norm{\scaleh\scoref(X_t,t)&-\nabla\log q^s_t(X_t)}^2
     -\frac{1}{n} \sum_{i=1}^{n}  \norm{\scaleh\scoref(\x_t^i,t)-\nabla\log q^s_t(\x_t^i)}^2\Bigr| \ge 4\Rs\sqrt{\frac{2t}{n}}\biggr)\\
     &\le 8 \Pr \biggl(\sup_{\NetP\in \paramspaceone}\Bigl|\frac{1}{n} \sum_{i=1}^{n} \zeta_i \bigl( \norm{\st(\x_t^i,t)}^2\Bigr| \ge \frac{\Rs}{4\scaleh^2}\sqrt{\frac{2t}{n}}\eqd t'\biggr)\\
     &~~~+8 \Pr \biggl(\sup_{\NetP\in \paramspaceone}\Bigl|\frac{1}{n} \sum_{i=1}^{n} \zeta_i \bigl( \norm{\nabla\log q^s_t(\x_t^i)}^2\Bigr| \ge \frac{\Rs}{4}\sqrt{\frac{2t}{n}}\eqd t''\biggr)\\
     &\le 16\exp\biggl(-\frac{n  t'^2}{c}\biggr)+16\exp\biggl(-\frac{n  t''^2}{c's^2\DerBound^4}\biggr)\,.
 \end{align*} 
And  
 \begin{align*}
\Rs^2&\le  \sup_{\NetP\in \paramspaceone}\frac{1}{n}\sum_{i=1}^{n}  \E_{X_t\sim Q_t}\norm{\scaleh\scoref(X_t^i,t)-\nabla\log q^s_t(X_t^i)}^4\\
& \le 2\bigl(\scaleh^4+ s{\DerBound}^4\bigr)\,.
% \\
% &\le 4 \max (\scaleh^4,(s \scaleS)^4)\,.
 \end{align*}
 That leaves us with 
 \begin{align*}
      \Pr \biggl(\sup_{\NetP\in \paramspaceone}\Bigl|\E_{X_t\sim Q_t}\norm{\scaleh\scoref(X_t,t)&-\nabla\log q^s_t(X_t)}^2
     -\frac{1}{n} \sum_{i=1}^{n}  \norm{\scaleh\scoref(\x_t^i)-\nabla\log q^s_t(\x_t^i)}^2\Bigr| \\
     &\ge 8\bigl(\scaleh^2+s {\DerBound}^2\bigr)\sqrt{\frac{2t}{n}}\biggr)\\
     &\le 16\exp\biggl(-\frac{2t}{c}\biggr)+16\exp\biggl(-\frac{ 2t}{c'}\biggr)\,.
 \end{align*}
 That gives 
  \begin{align*}
      \Pr \biggl(\sup_{\NetP\in \paramspaceone}\Bigl|\E_{X_t\sim Q_t}\norm{\scaleh\scoref(X_t,t)&-\nabla\log q^s_t(X_t)}^2
     -\frac{1}{n} \sum_{i=1}^{n}  \norm{\scaleh\scoref(\x_t^i,t)-\nabla\log q^s_t(\x_t^i)}^2\Bigr| \\
     &\ge 8 \bigl (\scaleh^2+s {\DerBound}^2\bigr)\sqrt{\frac{2t}{n}}\ \biggr)\\
     &\le 32\exp\biggl(-\frac{2t}{c}\biggr)\,.
 \end{align*}
 For $t=\log (n)$, we reach 
  \begin{align*}
      \Pr \biggl(\sup_{\NetP\in \paramspaceone}\Bigl|\E_{X_t\sim Q_t}\norm{\scaleh\scoref(X_t,t)&-\nabla\log q^s_t(X_t)}^2
     -\frac{1}{n} \sum_{i=1}^{n}  \norm{\scaleh\scoref(\x_t^i,t)-\nabla\log q^s_t(\x_t^i)}^2\Bigr| \\
     &\ge 8 \bigl (\scaleh^2+s {\DerBound}^2\bigr)\sqrt{\frac{2t}{n}}\ \biggr)\\
     &\le 32\exp\biggl(-\frac{2\log n}{c}\biggr)\\
     &\lessapprox \frac{32}{n^2}\,.
 \end{align*}
%  And finally, we can follow the same approach as in~\citet[Page~155]{taheri2021} to conclude that for large enough tuning (just double it), $\scaleh\le 3\scaleS$ that gives us the space to remove $\scaleh$ from our bounds. 
%  That gives 
%  \begin{align*}
%       \Pr \biggl(\sup_{\scoref\in \mathcal{S}_1}\Bigl|\E_{X_t\sim Q_t}\norm{\scaleh\scoref(X_t,t)&-\nabla\log q^s_t(X_t)}^2
%      -\frac{1}{n} \sum_{i=1}^{n}  \norm{\scaleh\scoref(\x_t^i,t)-\nabla\log q^s_t(\x_t^i)}^2\Bigr| \\
%      &\ge \COr s {\DerBound}^2\sqrt{\frac{2t}{n}}\ \biggr)\\
%      &\le 32\exp\biggl(-\frac{2\log n}{c}\biggr)\\
%      &\lessapprox \frac{32}{n^2}\,,
%  \end{align*}
% where we absorb all constants in $\COr$ as desired.
\end{proof}

\subsection{Proof of Lemma~\ref{lem:tilfactor}}\label{proof:tilf}
\begin{proof}
The proof is based on some simple linear algebra and the definition of forward and backward processes. 

We  1.~use Bayes' rule, 2.~consider a fixed $\x_t$ ($\Fdd_t(\x_t)$ is omitted since $\x_t$ is fixed), 3.~definition of the forward process, and 4.~multiplying with a one-valued factor and some rewriting, and 4.~and some further rewriting 
\begin{align*}
  \Fdd_{t-1|t}(\x_{t-1}|\x_t) &=\frac{\Fdd_{t|t-1}(\x_t|\x_{t-1})\Fdd_{t-1}(\x_{t-1})}{\Fdd_{t}(\x_t)} \\
  & \propto \Fdd_{t|t-1}(\x_t|\x_{t-1})\Fdd_{t-1}(\x_{t-1})\\
 & \propto \Fdd_{t-1}(\x_{t-1}) \exp \biggl(-\frac{\norm{\x_t-\sqrt{\alpha_t}\x_{t-1}}^2}{2(1-\alpha_t)}\biggr)\\
 & \propto \Bdds_{t-1|t}(\x_{t-1}|\x_t)  \exp \biggl(\log \Fdd_{t-1}(\x_{t-1})+\frac{\alpha_t\norm{\x_{t-1}-\us_t}^2}{2(1-\alpha_t)}-\frac{\norm{\x_t-\sqrt{\alpha_t}\x_{t-1}}^2}{2(1-\alpha_t)}\biggr)\\
 % &=  \Bdds_{t-1|t}(\x_{t-1}|\x_t)  \exp \biggl(\log \Fdd_{t-1}(\x_{t-1})+\frac{\alpha_t\norm{\x_{t-1}-(\x_t/\sqrt{\alpha_t})-\bigl((1-\alpha_t)\nabla_{\x_t}\log \Fdds_t(\x_t)\bigr)/\sqrt{\alpha_t}}^2}{2(1-\alpha_t)}-\frac{\norm{\x_t-\sqrt{\alpha_t}\x_{t-1}}^2}{2(1-\alpha_t)}\biggr)\\
 &=  \Bdds_{t-1|t}(\x_{t-1}|\x_t)  \exp \biggl(\log \Fdd_{t-1}(\x_{t-1})+\frac{\alpha_t\norm{\x_{t-1}-\us_t}^2}{2(1-\alpha_t)}-\frac{\alpha_t\norm{\x_{t-1}-(\x_{t}/\sqrt{\alpha_t})}^2}{2(1-\alpha_t)}\biggr)
\end{align*}
 using the fact that  (see~\eqref{eq:mus})
\begin{align*}
   \Bdds_{t-1|t}(\x_{t-1}|\x_t) & \propto \exp\biggl(-\frac{\alpha_t\norm{\x_{t-1}-\us_t}^2}{2(1-\alpha_t)}\biggr)\,.
\end{align*}
We then use the fact that 
\begin{align*}
  \norm{\x_{t-1}-\us_t}^2-\norm{\x_{t-1}-(\x_{t}/\sqrt{\alpha_t})}^2&=\norm{\x_{t-1}-(\x_{t}/\sqrt{\alpha_t})+(\x_{t}/\sqrt{\alpha_t})-\us_t}^2-\norm{\x_{t-1}-(\x_{t}/\sqrt{\alpha_t})}^2\\
  &=2\bigl(\x_{t-1}-(\x_{t}/\sqrt{\alpha_t})\bigr)^T\bigl((\x_{t}/\sqrt{\alpha_t})-\us_t\bigr)+\norm{(\x_{t}/\sqrt{\alpha_t})-\us_t}^2\,.
\end{align*}
We then use~\eqref{eq:mus} to obtain 
\begin{align*}
 \frac{2\bigl(\x_{t-1}-(\x_{t}/\sqrt{\alpha_t})\bigr)^T\bigl((\x_{t}/\sqrt{\alpha_t})-\us_t\bigr)}{(1-\alpha_t)/\alpha_t}  & =-\bigl(\x_{t-1}-(\x_{t}/\sqrt{\alpha_t})\bigr)^T \sqrt{\alpha_t} \nabla\log \Fdds_t(\x_t)\\
 &=-\sqrt{\alpha_t}\x_{t-1}^T\nabla\log \Fdds_t(\x_t)+\x_t^T\nabla\log \Fdds_t(\x_t)\,.
\end{align*}
    
Collecting all the pieces above we obtain  
for a fixed $\x_t$ 
\begin{align*}
  \Fdd_{t-1|t}(\x_{t-1}|\x_t)  \varpropto \Bdds_{t-1|t}(\x_{t-1}|\x_t)\exp\bigl( \zeta_{t,t-1}(\x_t,\x_{t-1})\bigr)
\end{align*}
with $\zeta_{t,t-1}(\x_t,\x_{t-1})= \log \Fdd_{t-1}(\x_{t-1})-\sqrt{\alpha_t}\x_{t-1}^T\nabla \log \Fdds_t(\x_t)+f(\x_t)$, where $f(\x_t)$ can be considered as an arbitrary function of $\x_t$, since $\x_t$ was fixed (let's also note that the term $\norm{(\x_{t}/\sqrt{\alpha_t})-\us_t}^2$ is omitted since it is just dependent over $\x_t$).
That completes the proof. 


\end{proof}

\subsection{Proof of Lemma~\ref{lem:logdeng}}\label{proof:loggaussian}
\begin{proof}
We employ  the fact that   $\BddA$ and $\Bdd^s$ are both Gaussian with the same variance,   $\BdA_{t-1|t}=\mathcal{N}(\x_{t-1};\uth(\x_t),\sigma_t^2\Identity)$  and 
 $\Bds_{t-1|t}=\mathcal{N}(\x_{t-1};\us_t(\x_t),\sigma_t^2\Identity)$ with 
 \begin{equation*}
 \uth(\x_t)=\frac{1}{\sqrt{\alpha_t}}\bigl(\x_t+(1-\alpha_t)\scale\scoref(\x_t,t)\bigr)
\end{equation*}
and 
\begin{equation*}
    \us_t(\x_t)=\frac{1}{\sqrt{\alpha_t}}\bigl(\x_t+(1-\alpha_t)\nabla_{\x_t}\log \Fdds_t(\x_t)\bigr)\,.
\end{equation*}
We use 1.the Gaussian property, 2.~rewriting, 3.~add a zero-valued term, 4.~use the property that $\E_{X_{t-1}\sim \Fd_{t-1|t}}[X_{t-1}|\x_t]=\ut(\x_t)$, 5.~definitions of $\ut$, $\us$, and $\uth$ and Cauchy–Schwarz inequality  to obtain 
    \begin{align*}
        \E_{X_t,X_{t-1}\sim \Fd_{t,t-1}}& \biggl[\log\frac{\Bdd^s_{t-1|t}(X_{t-1}|X_t)}{\BddA_{t-1|t}(X_{t-1}|X_t)}\biggr]\\
        &=\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}} \biggl[\frac{\alpha_t}{2(1-\alpha_t)}(\norm{X_{t-1}-\uth(X_t)}^2-\norm{X_{t-1}-\us(X_t)}^2)\biggr]\\
        &=\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}} \biggl[\frac{\alpha_t}{(1-\alpha_t)}\bigl(X_{t-1}-\us_t(X_t)\bigr)^{T}\bigl(\us_t(X_t)-\uth(X_t)\bigr)\\
        &~~~~~+\frac{\alpha_t}{2(1-\alpha_t)}\norm{\us_t(X_t)-\uth(X_t)}^2\biggr]\\
        &=\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}} \biggl[\frac{\alpha_t}{(1-\alpha_t)}\bigl(X_{t-1}-\ut(X_t)+\ut(X_t)-\us_t(X_t)\bigr)^{T}\bigl(\us_t(X_t)-\uth(X_t)\bigr)\\
        &~~~~~+\frac{\alpha_t}{2(1-\alpha_t)}\norm{\us_t(X_t)-\uth(X_t)}^2\biggr]\\
        &=\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}} \biggl[\frac{\alpha_t}{(1-\alpha_t)}\bigl(\ut(X_t)-\us_t(X_t)\bigr)^{T}\bigl(\us_t(X_t)-\uth(X_t)\bigr)\\
        &~~~~~+\frac{\alpha_t}{2(1-\alpha_t)}\norm{\us_t(X_t)-\uth(X_t)}^2\biggr]\\
    &\le (1-\alpha_t)\sqrt{\E_{X_t\sim Q_t}\norm{\nabla\log \Fdd_t(X_t)-\nabla\log \Fdds_t(X_t)}^2\E_{X_t\sim Q_t}\norm{\nabla\log \Fdds_t(X_t)-\scaleh\scorefh(X_t,t)}^2}\\
    &~~~+\frac{1-\alpha_t}{2}  \E_{X_t\sim Q_t}\norm{\scaleh\scorefh(X_t,t)-\nabla\log q^s_t(X_t)}^2\,.
    \end{align*}
    That implies 
 \begin{align*}
     \sum_{t=1}^T~&\E_{X_t,X_{t-1}\sim \Fd_{t,t-1}} \biggl[\log\frac{\Bdd^s_{t-1|t}(X_{t-1}|X_t)}{\BddA_{t-1|t}(X_{t-1}|X_t)}\biggr] \\
     &\le (1-\alpha_t)\sum_{t=1}^T\sqrt{\E_{X_t\sim Q_t}\norm{\nabla\log \Fdd_t(X_t)-\nabla\log \Fdds_t(X_t)}^2\E_{X_t\sim Q_t}\norm{\nabla\log \Fdds_t(X_t)-\scaleh\scorefh(X_t,t)}^2}\\
    &~~~+ \frac{1-\alpha_t}{2}\sum_{t=1}^T~\E_{X_t\sim Q_t}\norm{\scaleh\scorefh(X_t,t)-\nabla\log q^s_t(X_t)}^2\,,
 \end{align*} 
 as desired.
\end{proof}



