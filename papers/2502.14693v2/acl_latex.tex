% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[final]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{tcolorbox}
\usepackage{url}
\usepackage{listings}
\usepackage{xparse}
\lstdefinestyle{pythonstyle}{
  language=Python,
  basicstyle=\ttfamily\small,
  keywordstyle=\bfseries\color{blue},
  commentstyle=\itshape\color{green!60!black},
  stringstyle=\color{red!70!black},
  showstringspaces=false,
  breaklines=true,
  frame=single
}

\lstdefinestyle{txtfile}{
    basicstyle=\scriptsize\ttfamily,
    backgroundcolor=\color{white},
    frame=single,
    rulecolor=\color{black!30},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray!50},
    numbersep=5pt,
    breaklines=true,
    breakatwhitespace=true,
    showstringspaces=false,
    tabsize=4,
    captionpos=b
}

%  more packages
\usepackage{tabularray}
\usepackage{color}
\usepackage{booktabs}
\usepackage{siunitx}
\usepackage{graphicx}
\usepackage{array}

\usepackage{listings}
\usepackage{xcolor}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{wrapfig}
\usepackage{tabularx}
\usepackage{subcaption}
% \usepackage{authblk}
\usepackage{pifont}% http://ctan.org/pkg/pifont

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}
\usepackage{amsmath}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}

% Added packages
\usepackage{amsfonts}
\usepackage{booktabs}
\usepackage{multirow}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{I-MCTS: Enhancing Agentic AutoML via Introspective Monte Carlo Tree Search}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

% \author{First Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\\And
%   Second Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\}

\author{
 \textbf{Zujie Liang\textsuperscript{1}}\quad
 \textbf{Feng Wei\textsuperscript{1}}\quad
 \textbf{Wujiang Xu\textsuperscript{2}}\quad
 \textbf{Lin Chen\textsuperscript{1}}\quad
 \textbf{Yuxi Qian\textsuperscript{1}}\quad
 \textbf{Xinhui Wu\textsuperscript{1}}
\\
\\
 \textsuperscript{1}Ant Group\;\;\;\;\;\;    
 \textsuperscript{2}Rutgers University
% \\
}

% \author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
% \\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
% \\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
% \\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
% \\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
% \\
% \\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
% \\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
% }

\newcommand{\methodname}{\textsc{I-MCTS}}

\begin{document}
\maketitle


\begin{abstract}
Recent advancements in large language models (LLMs) have shown remarkable potential in automating machine learning tasks. 
However, existing LLM-based agents often struggle with low-diversity and suboptimal code generation. 
While recent work~\cite{chi2024sela} has introduced Monte Carlo Tree Search (MCTS) to address these issues, limitations persist in the quality and diversity of thoughts generated, as well as in the scalar value feedback mechanisms used for node selection. 
In this study, we introduce Introspective Monte Carlo Tree Search (\textbf{\textit{I-MCTS}}), a novel approach that iteratively expands tree nodes through an introspective process that meticulously analyzes solutions and results from parent and sibling nodes. 
This facilitates a continuous refinement of the node in the search tree, thereby enhancing the overall decision-making process.
Furthermore, we integrate a Large Language Model (LLM)-based value model to facilitate direct evaluation of each node's solution prior to conducting comprehensive computational rollouts. 
A hybrid rewarding mechanism is implemented to seamlessly transition the Q-value from LLM-estimated scores to actual performance scores. 
This allows higher-quality nodes to be traversed earlier.
Applied to the various ML tasks, our approach demonstrates a
6\% absolute improvement in performance compared to the strong open-source AutoML agents, showcasing its effectiveness in enhancing agentic AutoML systems\footnote{Resource available at \url{https://github.com/jokieleung/I-MCTS}}.
\end{abstract}

\section{Introduction}
\label{sec:intro}


Recent advances in large language models (LLMs) have opened new frontiers in automating machine learning (AutoML) tasks~\cite{huang2024mlagentbench,chan2024mle}.
Compared to the traditional AutoML frameworks~\cite{feurer2015efficient, tang2024autogluon}, the LLM-based agents~\cite{sun2024survey} emerge as promising direction 
due to their remarkable capabilities on code generation~\cite{jimenez2023swe}, neural architecture design~\cite{zheng2023can} and model training~\cite{chi2024sela}. 
Overall, these LLM agent-based AutoML systems~\cite{Schmidt_Wu_Jiang,hong2024data,li2024autokaggle,chi2024sela} typically input with a natural language description on the dataset and the problem, 
after which the system directly generates a solution in an end-to-end manner. 
While recent works by \citet{Schmidt_Wu_Jiang} and \citet{hong2024data} have made significant strides in automating the machine learning workflow, replicating the adaptive and strategic behavior of expert human engineers remains a significant challenge. 
The primary limitation lies in their search processes, which typically involve only a single pass or trial. 
This constraint significantly hinders the generation of diverse and highly optimized workflows, a capability that human experts excel at through iterative refinement and strategic decision-making.
Recent work by ~\citet{chi2024sela} introduced Tree-Search Enhanced LLM Agents (SELA), leveraging Monte Carlo Tree Search (MCTS) to expand the search space. 
However, the search space is constrained by its reliance on a pre-generated, fixed insight pool derived from the initial problem description and dataset information.
This static nature inherently limits the diversity and adaptability of the search tree.
Moreover, SELA encounters significant limitations in improving the overall quality of solutions when relying exclusively on scalar experimental performance feedback. 
This reliance on simplistic scalar feedback mechanisms impedes the efficient identification and navigation of optimal pathways in complex machine learning tasks, where flexible re-assessment and adaptive strategies are usually needed.

To address these challenges, we present \textbf{I}ntrospective \textbf{M}onte \textbf{C}arlo \textbf{T}ree \textbf{S}earch (\textbf{\textit{I-MCTS}}), a novel framework that introduces two key innovations. First, our \textit{introspective node expansion} dynamically generates high-quality thought nodes through explicit analysis of parent and sibling node states. 
By incorporating reflective reasoning and feedback about prior solutions and their outcomes, this approach enables continuous quality improvement of the search tree nodes. 
Second, we develop a \textit{hybrid rewarding mechanism} that combines: 1) LLM-estimated evaluations predicting node potential through a comprehensive machine learning evaluation criteria, 
and 
2) actual performance scores on the development set from computational rollouts. 
Our adaptive reward blending strategy smoothly transitions Q-value from LLM-estimated values to actual values across search iterations.
This facilitates higher-quality nodes to be traversed earlier.

Overall, the principal contributions of this work are threefold:

\begin{itemize}
% \item We identify and formalize critical limitations in existing MCTS-based AutoML agents, particularly the static nature of thought generation and scalar value feedback mechanisms
\item We introduce I-MCTS, an innovative approach for agentic AutoML that incorporates an introspective node expansion process and a hybrid reward mechanism. This enhances both the quality and efficiency of tree searches in AutoML workflows.
    
\item Extensive experiments across diverse ML tasks demonstrate our method's superiority, achieving 6\% absolute performance gains over state-of-the-art baselines while maintaining computational efficiency.
\end{itemize}


% \section{Method}
\section{Introspective Monte Carlo Tree Search (I-MCTS)}
\label{sec:method}

As illustrated in Figure~\ref{fig:pipline}, our approach consists of two key components: a search module I-MCTS, and an LLM agent as the experiment executor. 
The Introspective Monte Carlo Tree Search (I-MCTS), builds upon the foundation of traditional MCTS but introduces two key innovations: 
(1) introspective node expansion through reflective solution generation, and (2) a hybrid reward mechanism combining LLM-estimated evaluations with empirical performance scores. 
These components work in tandem to enhance the quality and diversity of thought nodes while improving the efficiency of the search process. 
During each cycle, the selected path is passed to the LLM agent, which plans, codes, executes, and introspects the experiment, providing both scalar and verbal feedback to refine future searches. 
This iterative process continues until the termination criterion is met. 

\subsection{Preliminary}
We formalize the automated machine learning (AutoML) problem as a search process over possible experimental configurations. 
Given a problem description $p$ and dataset $D$ with metadata $d$, the objective is to identify an optimal pipeline configuration $c^* \in \mathcal{C}$ that maximizes a performance metric $s$ on development data. 
The search space $\mathcal{C}$ consists of configurations combining insights $\lambda_i^\tau$ across $T$ predefined stages of the ML workflow: $\tau_1$ (Exploratory Data Analysis), $\tau_2$ (Data Preprocessing), $\tau_3$ (Feature Engineering), $\tau_4$ (Model Training), and $\tau_5$ (Model Evaluation).

The LLM agent $E$ conducts each trial by building practical experimental pipelines from natural language requirements. 
Given an experiment configuration $c$, the agent produces a detailed plan $E_{\text{plan}}$ that consists of a sequence of task instructions $I^{\tau \in T}$ corresponding to each stage of the machine learning process. Next, the agent writes and executes code $\sigma^\tau$ for each task $\tau$ based on the respective instruction and gets the final execution score $s$. 
The complete set of code outputs $\sigma^{\tau \in T}$ is concatenated into a full solution $\sigma_{sol}$ to address the problem. This phase is referred to as $E_{\text{code \& execute}}$.
\begin{align}
    E_{\text{plan}}(p, d, c, LLM) & \rightarrow I^{\tau \in T} \\
    E_{\text{code \& execute}}(I^{\tau \in T}, D, LLM) & \rightarrow (\sigma^{\tau \in T}, s)
\end{align}

\begin{figure}[!t]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/I-MCTS.pdf}
    \caption{I-MCTS architecture featuring (a) Introspective node expansion through parent/sibling analysis, (b) Hybrid reward calculation combining LLM predictions and empirical scores. The red arrows indicate the introspective feedback loop that continuously improves node quality.}
    \label{fig:pipline}
\end{figure}

\subsection{Introspective Node Expansion}
\label{ssec:introspective}

Unlike static insight pools in prior work~\cite{chi2024sela}, 
I-MCTS utilizes the introspective expansion mechanism that dynamically generates high-quality thought nodes by leveraging solutions and results from parent and sibling nodes. 
This design mirrors the way human expert engineers backtrack and refine their solution dynamically, ensuring the agent can iteratively
improve its decision-making process based on past experiences.
Given a parent node $x_{\text{parent}}$ and its existing sibling nodes $x_{\text{sibling}}$, the introspective expansion process generates a new node $x_{\text{child}}$ by introspecting the solutions and results of these previous nodes. 
Specifically, the introspection mechanism use an LLM to evaluate the solutions $\sigma_{\text{sol}}(x_{\text{parent}})$ and $\sigma_{\text{sol}}(x_{\text{sibling}})$ associated with the parent and sibling nodes and identify strengths, weaknesses, issues and potential improvements in the solutions.
Then, the LLM generates a fine-grained and customized insight $\lambda_{\text{new}}$ that addresses the identified issues or builds upon the strengths. 
This insight is tailored to the current stage $\tau$ of the machine learning pipeline. The new insight $\lambda_{\text{new}}$ is used to create a child node $x_{\text{child}}$, which inherits attributes from the parent node while incorporating the refined insight. 
The child node is then added to the search tree.
This introspection process ensures that each new node is dynamically generated through a thoughtful analysis of prior solutions, leading to a continuous improvement in the quality of the search tree.
Also, the verbalized introspection feedback addresses the solely scalar feedback limitation.


\subsection{Hybrid Reward Mechanism}
\label{ssec:hybrid}

The primary objective of the evaluation phase is to assess the reward for the current node.
For machine learning tasks, a conventional approach~\cite{Schmidt_Wu_Jiang,chi2024sela} involves utilizing the performance metric on the development set as the reward. 
To derive a performance score of the given node involves rolling out from an intermediate state to a terminal state, which is quite costly since processes such as model training cost significant computational time. 
This limits the efficiency of node exploration.
To address these challenges, we introduce a hybrid reward mechanism for node evaluation which combines LLM-estimated evaluations with actual performance scores to guide the search process more efficiently. 
% \noindent\textbf{LLM-Estimated Evaluations}
% \label{subsubsec:llm-estimated}
For each node $x$, we employ an LLM-based value model $M_{\text{value}}$ to predict its potential performance. The value model takes as input the solution $\sigma_{\text{sol}}(x)$ and outputs an estimated score $s_{\text{LLM}}(x)$. This score is based on a comprehensive set of machine learning evaluation criteria, which is detailed in Appendix~\ref{app:llm_evaluation_schema}.
The LLM-estimated evaluation allows us to assess the quality of a node's solution before conducting computationally expensive rollouts. This early evaluation helps prioritize nodes with higher potential, improving the efficiency of the search process.
% \noindent\textbf{Actual Performance Scores}
% \label{subsubsec:actual-scores}
After the ``simulation"" of a node $x$, we obtain the actual performance score $s_{\text{actual}}(x)$ based on the development set, which reflects the true performance of the node's solution.
% \noindent\textbf{Adaptive Reward Blending}
% \label{subsubsec:adaptive-blending}
To smoothly transition from LLM-estimated values to actual performance scores, we implement an adaptive reward blending strategy. The Q-value $Q(x)$ for a node $x$ is updated as follows:

\begin{align}
    Q(x) = \alpha(x) \cdot s_{\text{LLM}}(x) + (1 - \alpha(x)) \cdot s_{\text{actual}}(x)
\end{align}

where $\alpha(x) = \frac{\gamma}{n_{\text{visits}(x)}+\gamma}$, a blending factor that decreases over the visit count increase, where $\gamma$ is a controlling constant.
This adaptive blending ensures that higher-quality nodes are traversed earlier in the search process, while still incorporating the true performance feedback as it becomes available.

\subsection{Tree Search Process}
\label{ssec:adaptive}

The overall search process can be summarized as:

\paragraph{Selection} At each iteration, we select node according to the UCT formula as:

\begin{align}
    \text{UCT}(x) = \frac{Q(x)}{n(x)} + \alpha_{\text{explore}} \sqrt{\frac{\ln n_{\text{visits}}(x_{\text{parent}})}{n(x)}}
\end{align}

\paragraph{Expansion} Child nodes are generated through the introspective process described in Section~\ref{ssec:introspective}, creating a dynamic search space that evolves based on simulation feedback.

\paragraph{Simulation} Each rollout executes the full pipeline while caching intermediate results. The LLM value model provides real-time estimates $v_{\text{LLM}}$ before computational execution.

\paragraph{Backpropagation} 
Upon simulation completion, the Q value is propagated backwards through the tree structure. 
This process updates the value and visit count of each parent node, from the simulated node to the root. Consequently, nodes associated with superior solutions receive higher priority in subsequent iterations.
This allows nodes representing more promising solutions to be prioritized in future rollouts.
Similar to \citet{chi2024sela}, I-MCTS implements a state-saving mechanism that caches the stage code for each node, which allows it to reuse previously generated code when a new configuration shares components with existing ones.


\section{Experiment}

We follow \citet{chi2024sela} to benchmark our method on 20 machine learning datasets, including 13 classification tasks and 7 regression tasks from the AutoML Benchmark (AMLB) ~\cite{gijsbers2024amlb} and Kaggle Competitions.
All datasets are split into training, validation, and test sets with a 6:2:2 ratio, details refer to Appendix~\ref{app:dataests}.
Each dataset is run three times using our method.
We also use the Normalized Score (NS) defined in Appendix ~\ref{app:metric}.
We adopt Qwen2.5-72B-Instruct~\cite{yang2024qwen2} as our LLM.
The temperature parameter is set to 0.2.
$\gamma$ is set to 0.2, while $\alpha_{\text{explore}}$ is set to 2.
Five baselines are included for comparison, including AutoGluon~\cite{tang2024autogluon}, AutoSklearn~\cite{feurer2022auto}, AIDE~\cite{Schmidt_Wu_Jiang}, Data Interpreter~\cite{hong2024data}, SELA~\cite{chi2024sela}.
We directly used the results reported in \citet{chi2024sela}.
Experiments are conducted based on the MetaGPT~\cite{hong2024metagpt} framework\footnote{\url{https://github.com/geekan/MetaGPT}}.
% ~\footnote{https://github.com/geekan/MetaGPT/tree/main/metagpt/ext/sela}.

\subsection{Main Results}

\begin{table}[t]
\centering
\resizebox{0.5\textwidth}{!}{
    \begin{tabular}{lccc}
        \toprule
        \textbf{Method} & \textbf{Top1 Rate} \%  & \textbf{Avg. NS} \% $\uparrow$ & \textbf{Avg. Best NS} \% $\uparrow$  \\
        \midrule
        AutoGluon   & 5.0 & 53.2 & 53.2 \\
        AutoSklearn  & 25.0 & 46.1 & 47.5  \\
        AIDE  & 5.0 & 47.1 & 51.8  \\
        Data Interpreter & 0.0 & 47.4 & 50.2 \\
        SELA & 20.0 & 53.3 & 54.7 \\
        \textbf{\methodname{}} & \textbf{45.0} & \textbf{58.6} & \textbf{59.8} \\
        \bottomrule
    \end{tabular}
    }
    \caption{Results of each AutoML framework on 20 tabular datasets. The ``Top1 Rate" column represents the rate of datasets where the method produces the best predictions across methods.}
    \label{table:main}
\end{table}

The experimental results demonstrate the superior performance of the proposed I-MCTS approach compared to other strong AutoML baselines. As shown in Table \ref{table:full-main-results}, I-MCTS achieves the highest overall normalized score (NS) of 58.6\% on average and 59.8\% for the best predictions across 20 diverse tabular datasets.
These results validate the effectiveness of I-MCTS's unique introspective node expansion process, which enables continuous solution refinement through meticulous analysis of parent and sibling nodes.
Also, the integration of an LLM-based value model and hybrid rewarding mechanism further contributes to the algorithm's success by facilitating early identification and traversal of high-quality nodes.
We include detailed results of each method in Appendix~\ref{app:detailed_result}.

\subsection{Ablation Study}

We follow \citet{chi2024sela} to use boston, colleges, credit-g, Click\_prediction\_small, GesturePhaseSegmentationProcessed, and mfeat-factors to dataset for ablation study. 
We systematically evaluate the contribution of each component within our proposed Introspective Monte Carlo Tree Search (I-MCTS) framework. The results, as presented in Table \ref{table:ablation_study}, illustrate the incremental benefits of incorporating both the Introspective Node Expansion (INE) and the hybrid reward mechanism (HRM).

\begin{table}[t]
\centering
\resizebox{0.4\textwidth}{!}{
% \begin{tabularx}{1.12\textwidth}
\begin{tabular}{lc}
    \toprule
    \textbf{Method} & \textbf{Avg. NS $\uparrow$}  \\
    \midrule
    Data Interpreter & 56.4 \\
    SELA (Random Search) & 58.6  \\
    SELA (MCTS) & 60.9   \\
    \methodname{} (w/o INE) & \textbf{61.1}  \\
    \methodname{} (w/o HRM) & \textbf{66.2}  \\
    \textbf{\methodname{} } & \textbf{66.8}  \\
    \bottomrule
\end{tabular}
}
\caption{Ablation Study for each search setting on the selected 6 datasets. ``\methodname{} (w/o INE)" means ``without "Introspective Node Expansion", while ``\methodname{} (w/o HRM)" means ``without "hybrid reward mechanism".}
\label{table:ablation_study}
\end{table}


\subsection{Case Study}

To demonstrate the superiority of our Introspective Monte Carlo Tree Search (I-MCTS) approach, we conduct a comprehensive visualization analysis of the tree search process using the \textit{\textbf{kick}} dataset. 
As show in Appendix~\ref{app:case},
our empirical results reveal that I-MCTS effectively leverages the introspective information from previous nodes to generate task-specific and actionable insights, while SELA exhibit significant homogeneity and lack specificity.
Furthermore, our hybrid reward mechanism enhances the exploration efficiency, enabling more effective identification of high-quality nodes within the same computational budget.





\section{Conclusion}

In this paper, we introduced \textbf{I}ntrospective \textbf{M}onte \textbf{C}arlo \textbf{T}ree \textbf{S}earch (\textbf{\textit{I-MCTS}}), a novel approach to enhance AutoML Agents. 
The method addresses key limitations in existing Tree-search-based LLM agents with respect to thought diversity, quality, and the efficiency of the search process.
Our experimental results highlight the potential of integrating introspective capabilities into tree search algorithms for AutoML Agents. 


\section*{Limitations}
While the proposed I-MCTS approach demonstrates significant improvements in AutoML agent performance, several limitations remain that warrant further investigation. First, the computational overhead of the introspective process, although beneficial for enhancing decision-making, introduces additional resource requirements. This limits the scalability of the method, particularly in scenarios where computational resources are constrained.
Future work should explore optimizations to reduce this overhead and investigate how the approach scales with increased computational power.

Second, the current evaluation of I-MCTS is primarily focused on structured data and tabular ML tasks. Its effectiveness on more complex and heterogeneous data types, such as image and text data, remains unexplored. Extending the application of I-MCTS to these domains could provide valuable insights into its generalizability and robustness across diverse machine learning tasks, such as Vison, NLP and RL tasks.

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
% \newpage
\bibliography{custom}

% \clearpage

\onecolumn
\appendix
% \section*{APPENDIX}

\input{appendix/appendix_overall}

\end{document}
