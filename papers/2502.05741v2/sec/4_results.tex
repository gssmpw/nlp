\section{Experiments}
\subsection{Experimental Setup}

\noindent\textbf{Training Details} \; 
For training, we utilize the first 400,000 images of the OpenImages dataset~\cite{Kuznetsova.2020.OpenImages}, which provides high-resolution images suitable for learned compression tasks. The proposed LALIC models are trained with a batch size of 8, using the Adam optimizer. 
% The training process minimizes a rate-distortion (R-D) loss, incorporating two distortion metrics: Mean Squared Error (MSE) and multi-scale structural similarity (MS-SSIM).
%
% The Adam optimizer is used for optimization, with an initial learning rate of \(1 \times 10^{-4}\). The model is trained using a rate-distortion (R-D) loss, where two distortion metrics—Mean Squared Error (MSE) and multi-scale structural similarity (MS-SSIM)—are employed. 
%
For MSE-optimized models, the Lagrange multipliers are set to \{0.0025, 0.0035, 0.0067, 0.0130, 0.0250, 0.0483\}, and for MS-SSIM optimized models, they are set to \{2.40, 4.58, 8.73, 16.64, 31.73, 60.50\}. The model is first trained for 40 epochs with a learning rate of \(1 \times 10^{-4}\). Then, the learning rate is decayed to \(1 \times 10^{-5}\) for an additional 4 epochs. Finally, we fine-tune the model using 512$\times$512 image crops for an additional 4 epochs. All experiments are conducted on an NVIDIA GeForce RTX 4090 GPU.


% \begin{figure*}[t]
%   \centering
%   \includegraphics[width=\textwidth]{fig/Performance-Kodak.png}
%   \caption{Rate-distortion performance evaluation on the Kodak dataset.}
%   \label{fig:perf-kodak}
% \end{figure*}

\begin{figure*}[h!]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{fig/perf-Kodak-update.pdf}
    % \caption{Performance evaluation on the Kodak dataset.}
    \label{fig:perf-kodak-psnr}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{fig/perf-kodak-msssim-update.pdf}
    % \caption{Performance evaluation on the Kodak dataset.}
    \label{fig:perf-kodak-msssim}
  \end{subfigure}
  \vspace{-1em}
  \caption{Rate-distortion performance on the Kodak dataset.}
  \label{fig:perf-kodak}
\end{figure*}

\begin{figure*}[htbp]
    \centering
    \begin{minipage}{0.48\linewidth}
        \centering
        \includegraphics[width=1\linewidth]{fig/perf-CLIC-update.pdf}
        \caption{Rate-distortion performance on the CLIC dataset.}
        \label{fig:perf-clic}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\linewidth}
        \centering
        \includegraphics[width=1\linewidth]{fig/perf-Tecnick-update.pdf}
        \caption{Rate-distortion performance on the Tecnick dataset.}
        \label{fig:perf-tecnick}
    \end{minipage}
\end{figure*}



% \begin{figure*}[h!]
%   \centering
%   \begin{subfigure}[b]{0.48\textwidth}
%     \includegraphics[width=\textwidth]{fig/perf-CLIC.pdf}
%     \caption{Performance evaluation on the CLIC dataset.}
%     \label{fig:perf-clic}
%   \end{subfigure}
%   \hfill
%   \begin{subfigure}[b]{0.48\textwidth}
%     \includegraphics[width=\textwidth]{fig/perf-Tecnick.pdf}
%     \caption{Performance evaluation on the Tecnick dataset.}
%     \label{fig:perf-clic2}
%   \end{subfigure}
%   \caption{Rate-distortion performance evaluations on the CLIC and Tecnick dataset.}
%   \label{fig:perf-clic-all}
% \end{figure*}

\noindent\textbf{Model Settings} \;
For the RWKV blocks, we use a layer number $L_1$, $L_2$, $L_3$, $L_4$ with a configuration of \{2, 4, 6, 6\}. The latent feature \( y \) has a channel dimension \( M \) of 320, and the hyper-latent feature \( z \) has a channel dimension \( N \) of 192. To balance model capacity and computational complexity, the channels in the analysis and synthesis transforms (\(g_a\) and \(g_s\)) are set to $96$, $144$, and $256$, respectively. For the entropy model, we use $5$ slices, with $2$ RWKV blocks in each channel context. Additional hyper-parameters are discussed in the supplementary materials. 

\noindent\textbf{Evaluation Metrics} \;
We evaluate the proposed model on three datasets: (1) the Kodak dataset~\cite{Kodak.1993.Lossless}, containing 24 images with 768 × 512 resolution; (2) the Tecnick dataset~\cite{Asuni.2014.Tecnick}, containing 100 images at 1200 × 1200 resolution; and (3) the CLIC Professional Validation dataset~\cite{CLIC.2021.Workshop}, consisting of 41 images with resolutions up to 2K. Both Peak Signal-to-Noise Ratio (PSNR) and Multi Scale Structure Similarity (MS-SSIM) are used to measure the distortion, while bits per pixel (BPP) is used to measure the bitrate.

\subsection{Rate-Distortion Performance}


We compare the rate-distortion (R-D) performance of our method with state-of-the-art approaches, including traditional image codecs like BPG and VTM-9.1, as well as recent learned image compression (LIC) models \cite{Balle.2018.Hyperprior, Cheng.2020.LIC, He.2022.ELIC, Liu.2023.TCM, Li.2023.FAT, Jiang.2023.MLICpp}. We use corresponding model checkpoints if available or R-D curves from paper to get the R-D points. Figure~\ref{fig:perf-kodak} presents the R-D performance on the Kodak dataset using PSNR and MS-SSIM metrics. In addition to Kodak, we evaluate PSNR on the Tecnick and CLIC datasets, as shown in Figure~\ref{fig:perf-clic} and Figure~\ref{fig:perf-tecnick}.


% Table: RD-Performance and Complexity of LIC Models
\begin{table*}[t]
    \centering


\begin{tabular}{lrrrrrrrr}
\hline
\multirow{2}{*}{Method}                   & \multirow{2}{*}{Enc(s)} & \multirow{2}{*}{Dec(s)} & \multirow{2}{*}{Mem(G)} & \multirow{2}{*}{FLOPs(G)} & \multirow{2}{*}{Params(M)} & \multicolumn{3}{c}{BD-Rate (PSNR)}                                                 \\ \cline{7-9} 
                                          &                         &                         &                         &                           &                            & \multicolumn{1}{c}{Kodak} & \multicolumn{1}{c}{CLIC} & \multicolumn{1}{c}{Tecnick} \\ \hline
VTM-9.1                                   & 171.633                 & 0.177                   & -                       & -                         & -                          & 0.00\%                    & 0.00\%                   & 0.00\%                      \\
Minnen20~\cite{Minnen.2020.Charm}   & 0.077                   & 0.101                   & 0.446                   & 208.95                    & 41.77                      & 1.11\%                    & -                        & -                           \\
Cheng20-Parallel~\cite{He.2022.ELIC} & 0.090                   & 0.042                   & 0.413                   & 369.70                    & 24.52                      & 4.08\%                    & -                        & -                           \\
ELIC~\cite{He.2022.ELIC}                  & 0.237                   & 0.120                   & 0.373                   & 332.42                    & 33.29                      & -7.02\%                   & -1.19\%                  & -7.64\%                     \\
MambaVC~\cite{Qin2024MambaVCLV}           & 0.229                   & 0.222                   & 5.813                   & 393.37                    & 47.88                      & -9.73\%                   & -                        & -                           \\ \hline
TCM-large~\cite{Liu.2023.TCM}             & 0.157                   & 0.151                   & 1.698                   & 700.66                    & 75.90                      & -11.73\%                  & -9.41\%                  & -10.93\%                    \\
FAT~\cite{Li.2023.FAT}                    & \textbf{0.140}          & \textgreater 10.000     & 1.076                   & \textbf{245.46}           & 69.78                      & -14.56\%                  & -10.79\%                 & -14.40\%                    \\
MLIC++~\cite{Jiang.2023.MLICpp}           & 0.190                   & 0.268                   & \textbf{0.630}          & 443.17                    & 83.27                      & -15.02\%                  & -14.45\%                 & -17.21\%                    \\ \hline
LALIC (Ours)                              & 0.274                   & \textbf{0.150}          & 0.841                   & 286.16                    & \textbf{63.24}             & \textbf{-15.26\%}         & \textbf{-15.41\%}        & \textbf{-17.63\%}           \\ \hline
\end{tabular}

    \caption{Rate-distortion (R-D) performance and computational complexity of various learned image compression models on the Kodak dataset, evaluated on an NVIDIA RTX 4090 GPU. Lower BD-Rate values indicate better R-D performance. Bold font denote the best performance among the recent SOTA methods. ”-” indicates an unavailable result. Note that we re-run the FAT method using the official github code. More details will be discussed in the supplementary materials.}
    \label{tab:performance}
\end{table*}

% TODO@donghui: just write we re-run the FAT-LIC method using the official github XXX. Not comment "FAT-LIC have a known issue with large decoding time in the paper, but can be discussed in the supplymentary."


As summarized in Table~\ref{tab:performance}, we further evaluate the BD-rate (PSNR) of different LIC methods. Our approach achieves state-of-the-art (SOTA) performance, surpassing VTM-9.1 by 15.26\% in BD-rate on the Kodak dataset. Furthermore, it demonstrates superior performance on high-resolution datasets, including the CLIC dataset (2K resolution) and the Tecnick dataset (1K resolution). These results highlight the global modeling capability of RWKV, which excels in handling high-resolution images by effectively capturing long-range dependencies. Additional quantitative results and subjective visual comparisons are provided in the supplementary materials.
% Note that MLIC++ performs exceptionally well at low bitrates but significantly underperforms at high bitrates, which may be attributed to its relatively complex entropy model. 

\subsection{Computational Complexity}

We evaluate the computational complexity of the proposed model across four metrics: encoding time, decoding time, inference GPU memory consumption, and forward FLOPs. These measurements provide a well-rounded assessment of complexity from various perspectives. As shown in Table~\ref{tab:performance}, our model demonstrates a competitive balance between efficiency and rate-distortion (R-D) performance.

\begin{table}[tb]
\centering
\begin{tabular}{@{}llrrr@{}}
\toprule
\#Layers  & SCCTX     & FLOPs/G & Params/M & BD-rate \\ \midrule
2,2,2,2   & Conv      & 163.95    & 27.61      & 0.00\%     \\
2,4,6,2   & Conv      & 233.87    & 35.64      & -2.50\%    \\
2,4,6,6   & Conv      & 239.20    & 42.57      & -1.68\%    \\
2,4,6,6   & Conv Plus & 304.23    & 62.08      & -2.74\%    \\
2,4,6,6   & RWKV      & 286.16    & 63.24      & \textbf{-3.50\%}    \\ \bottomrule
\end{tabular}
% \vspace{-1mm}
\caption{Ablation study on the effect of varying RWKV block numbers, and with Conv based or RWKV based entropy models, showing BD-rate gain on the Kodak dataset.}
% \vspace{-1mm}
\label{tab:ablation}
\end{table}

Our proposed LALIC model achieves competitive encoding and decoding times with the lowest parameters among recent methods that attain more than 10\% bitrate savings. Specifically, our model has an encoding time of 274 ms and a decoding time of 150 ms, reflecting a practical level of latency suitable for real-world applications. Furthermore, with 286.16 GFLOPs, our model demonstrates efficient computational complexity, validating the Bi-RWKV module’s strong and effective modeling capacity. This efficiency is particularly valuable in scenarios requiring both high compression performance and low computational overhead.


\subsection{Ablation Studies and Analysis}

% \begin{figure}
%   \centering
%   \includegraphics[width=0.96\linewidth]{fig/ablation-v2.pdf}
%   \vspace{-1mm}
%   \caption{RD-curves for different settings in the ablation study. } 
%   \vspace{-1mm}
%   \label{fig:ablation-rd}
% \end{figure}

%As redundancies are progressively eliminated, less information needs to be entropy coded, thereby enhancing compression efficiency. 
Learned visual compression involves two critical steps for redundancy removal: the powerful nonlinear transform and the delicate conditionally factorized Gaussian prior distribution to decorrelate the latent representation \( y \). To evaluate the effectiveness of the proposed LALIC architecture, we conducted ablation studies to analyze the impact of the Bi-RWKV nonlinear transform modules and the RWKV-SCCTX entropy model. Additionally, visualizations were provided to offer deeper insights into the design choices. 

%The studies focused on the following aspects:

%These experiments systematically assessed the model's performance under varying configurations, examining its sensitivity to key architectural components. Additionally, visualizations were provided to offer deeper insights into the design choices. The studies focused on the following aspects:

\noindent\textbf{Number of Bi-RWKV Blocks}. We first examine the effect of Bi-RWKV block count on model performance, aiming to understand the trade-off between model complexity and compression efficiency. As shown in Table~\ref{tab:ablation}, we use inference loss as a proxy for evaluating compression performance. Results indicate that increasing the number of RWKV blocks consistently improves performance, particularly when additional blocks are added to high-resolution stages. This suggests that a deeper configuration in early stages allows the model to capture more detailed spatial information, enhancing overall compression effectiveness.

\noindent\textbf{Entropy Model Configuration}. Building on a Conv based SCCTX entropy model \cite{He.2022.ELIC}, we further evaluate the effectiveness of our RWKV-SCCTX by introducing the Bi-RWKV block to model channel context and incorporating channel mix layers to modulate entropy parameters. Previous research \cite{Sheng.2024.NVC1B} underscores the importance of increasing context parameters to enhance compression performance. Following this insight, we define the Conv Plus SCCTX by expanding the dimension and depth of the context model. 

As shown in Table~\ref{tab:ablation}, the RWKV SCCTX achieves superior performance with nearly the same number of parameters as Conv Plus, while requiring fewer FLOPs. Compared to the baseline Conv SCCTX, the RWKV SCCTX delivers a significant reduction in BD-rate, demonstrating its capability to improve compression efficiency without excessively increasing computational complexity.


\begin{figure*}[h!]
  \centering
    \begin{subfigure}[b]{\textwidth}
        \includegraphics[width=\textwidth]{fig/kodim01.png.pdf}
        \label{fig:latent-sub1}
    \end{subfigure}
    \vspace{-6em}
    \begin{subfigure}[b]{\textwidth}
        \includegraphics[width=\textwidth]{fig/kodim03.png.pdf}
        \label{fig:latent-sub2}
    \end{subfigure}
    \vspace{4em}
  \caption{Effectiveness of the RWKV-based entropy model in improving compression efficiency. The middle two columns present the scaled deviation maps from the SCCTX model using either Conv or RWKV. The right two columns illustrate the uneven entropy distribution across the 5 channel slices.}
  \label{fig:latent-scale}
\end{figure*}


\begin{figure}[h!]
    \centering
    \begin{subfigure}[b]{0.15\textwidth}
        \includegraphics[width=\textwidth]{fig/ERF-AFT.png}
        \caption{AFT}
        \label{fig:erf-sub1}
    \end{subfigure}
    \begin{subfigure}[b]{0.15\textwidth}
        \includegraphics[width=\textwidth]{fig/ERF-AFT-Shift.png}
        \caption{AFT+Shift}
        \label{fig:erf-sub2}
    \end{subfigure}
    \begin{subfigure}[b]{0.15\textwidth}
        \includegraphics[width=\textwidth]{fig/ERF-BiWKV-Shift.png}
        \caption{BiWKV+Shift}
        \label{fig:erf-sub3}
    \end{subfigure}
    \begin{subfigure}[b]{0.15\textwidth}
        \includegraphics[width=\textwidth]{fig/Corr-AFT.pdf}
        \caption{AFT}
        \label{fig:corr-sub1}
    \end{subfigure}
    \begin{subfigure}[b]{0.15\textwidth}
        \includegraphics[width=\textwidth]{fig/Corr-AFT+Shift.pdf}
        \caption{AFT+Shift}
        \label{fig:corr-sub2}
    \end{subfigure}
    \begin{subfigure}[b]{0.15\textwidth}
        \includegraphics[width=\textwidth]{fig/Corr-WKV+Shift.pdf}
        \caption{BiWKV+Shift}
        \label{fig:corr-sub3}
    \end{subfigure}
  \caption{Visualization of different attention mechanisms. The top row shows the effective receptive field (ERF) \cite{Luo.2016.ERF} for the forward pass ($g_a$ and $h_a$) of the constructed models. A more extensively distributed dark area indicates a larger ERF. The bottom row presents the local correlation matrix of the normalized latent representation \((y - \mu)/\sigma\). Each value represents the Pearson correlation coefficient between the vector at a given location and the center location, computed along the channel dimension and averaged across all images in the Kodak dataset.} 
  \label{fig:attn-erf}
\end{figure}


To gain further insights into the improvements offered by RWKV-based context modeling, we analyze the quantization loss in the latent domain and the entropy distribution of the latent representation. The information loss during compression is quantified by the scaled deviation~\cite{Xie.2021.EInv} between \( \hat{\boldsymbol{y}} \) and \( \boldsymbol{y} \), defined as \( \epsilon = \operatorname{abs}(\hat{\boldsymbol{y}} - \boldsymbol{y}) / \Sigma \boldsymbol{y} \).

Figure~\ref{fig:latent-scale} illustrates the scaled deviation map and channel entropy distributions from the Kodak dataset. The results clearly indicate that the RWKV block significantly reduces latent deviation and concentrates entropy more effectively in the initial slices. This behavior highlights the RWKV's ability to balance global and local dependencies, enabling superior entropy modeling and more efficient compression.

\noindent\textbf{Attention Mechanisms in the Block}. We investigate the contributions of various internal components within the RWKV block, focusing on different attention mechanisms and the inclusion of an Omni-Shift layer. Table~\ref{tab:block-component} highlights the impact of these design choices on computational complexity and compression performance. As the attention mechanisms evolve, performance improves with increasing FLOPs, while the growth in parameter count remains minimal. Refer to supplementary materials for comparisons with other linear attention mechanisms.

% For a broader comparison, including other recent linear attention mechanisms, please refer to the analysis provided in the supplementary materials.

To demonstrate the influence of attention mechanisms on the network, Figure~\ref{fig:attn-erf} illustrates the effective receptive field (ERF) across different block configurations. These ERF visualizations reveal how distinct attention mechanisms and shift layers shape the receptive field, thereby impacting the model’s ability to capture contextual information. The shift layer effectively captures local context and broadens the receptive field, while transitioning from AFT to BiWKV enables the model to capture more global information. Furthermore, the enhanced attention mechanisms help reduce local correlations, as demonstrated by the Pearson correlation matrix.



\begin{table}[h!]
\centering
\begin{tabular}{@{}lrrr@{}}
\toprule
Attention              & $\Delta$FLOPs (G) & Params (M) & Loss   \\ \midrule
AFT         & 0.6028   & 62.83     & 0.5657 \\
AFT+Shift   & 4.9085   & 63.23     & 0.5604 \\
BiWKV+Shift & 6.8030   & 63.24     & 0.5551 \\ \bottomrule
\end{tabular}
\caption{Ablation study on the effects of different attention mechanisms in Bi-RWKV blocks. The $\Delta$FLOPs only counts the operations of attention layer or shift layer. Test R-D loss is used to indicate performance gain. %Note that this group are combined with proposed context model.
}
\label{tab:block-component}
\end{table}











