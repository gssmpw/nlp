% CVPR 2025 Paper Template; see https://github.com/cvpr-org/author-kit

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
\usepackage{cvpr}              % To produce the CAMERA-READY version
% \usepackage[review]{cvpr}      % To produce the REVIEW version
% \usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Import additional packages in the preamble file, before hyperref
\input{preamble}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, 
% e.g. with the file validation for the camera-ready version.

% If you comment hyperref and then uncomment it, you should delete *.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you should be clear).
\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,allcolors=cvprblue]{hyperref}
\usepackage{color}
\usepackage{multirow}
%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\paperID{4829} % *** Enter the Paper ID here
\def\confName{CVPR}
\def\confYear{2025}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Linear Attention Modeling for Learned Image Compression}

%%%%%%%%% AUTHORS - PLEASE UPDATE
% Donghui Feng, Zhengxue Cheng, Shen Wang, Ronghua Wu, Hongwei Hu, Guo Lu, Li Song
\author{
    Donghui Feng$^{1}$\thanks{Equal contribution.}, Zhengxue Cheng$^{1}$\footnotemark[1], Shen Wang$^{1}$, Ronghua Wu$^{2}$, Hongwei Hu$^{2}$, Guo Lu$^{1}$, Li Song$^{1}$\thanks{Corresponding author. Email: song\_li@sjtu.edu.cn} \\
    $^1$ Shanghai Jiao Tong University \quad $^2$ Ant Group\\
    % {\tt\small \{faymek, zxcheng, wangshen22206, luguo2014, song\_li\}@sjtu.edu.cn} \\
    % {\tt\small \{r.wu, Hongwei.huhw\}@antgroup.com}
}

% \author{Donghui Feng, Zhengxue Cheng, Shen Wang, Li Song\\
% Shanghai Jiao Tong University\\
% 800 Dongchuan Rd., Shanghai, China\\
% {\tt\small \{faymek, zxcheng, wangshen22206, song\_li\}@sjtu.edu.cn}
% % For a paper whose authors are all at the same institution,
% % omit the following lines up until the closing ``}''.
% % Additional authors and addresses can be added with ``\and'',
% % just like the second author.
% % To save space, use either the email address or home page, not both
% % \and
% % Zhengxue Cheng\\
% % Shanghai Jiao Tong University\\
% % 800 Dongchuan Rd., Shanghai, China\\
% % {\tt\small zxcheng@sjtu.edu.cn}
% }

\begin{document}
\maketitle
\input{sec/0_abstract}    
\input{sec/1_intro}
\input{sec/2_related}
\input{sec/3_method}
\input{sec/4_results}
\input{sec/5_conclusion}
\input{sec/6_acknowledgment}
{
    \small
    \bibliographystyle{ieeenat_fullname}
    % \bibliography{main}
    \begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Balle et~al.(2021)Balle, Chou, Minnen, Singh, Johnston, Agustsson, Hwang, and Toderici]{Balle.2021.NTC}
Johannes Balle, Philip~A. Chou, David Minnen, Saurabh Singh, Nick Johnston, Eirikur Agustsson, Sung~Jin Hwang, and George Toderici.
\newblock Nonlinear {{Transform Coding}}.
\newblock \emph{IEEE Journal of Selected Topics in Signal Processing}, 15\penalty0 (2):\penalty0 339--353, 2021.

\bibitem[Ballé et~al.(2017)Ballé, Laparra, and Simoncelli]{Balle17}
Johannes Ballé, Valero Laparra, and Eero~P. Simoncelli.
\newblock End-to-end optimized image compression.
\newblock In \emph{5th International Conference on Learning Representations, {{ICLR}} 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings}. OpenReview.net, 2017.

\bibitem[Ballé et~al.(2018)Ballé, Minnen, Singh, Hwang, and Johnston]{Balle.2018.Hyperprior}
Johannes Ballé, David Minnen, Saurabh Singh, Sung~Jin Hwang, and Nick Johnston.
\newblock Variational image compression with a scale hyperprior, 2018.

\bibitem[Bross et~al.(2021)Bross, Wang, Ye, Liu, Chen, Sullivan, and Ohm]{Bross.2021.VVC}
Benjamin Bross, Ye-Kui Wang, Yan Ye, Shan Liu, Jianle Chen, Gary~J. Sullivan, and Jens-Rainer Ohm.
\newblock Overview of the versatile video coding ({{VVC}}) standard and its applications.
\newblock \emph{IEEE Transactions on Circuits and Systems for Video Technology}, 31\penalty0 (10):\penalty0 3736--3764, 2021.

\bibitem[Bégaint et~al.(2020)Bégaint, Racapé, Feltman, and Pushparaja]{Begaint.2020.CompressAI}
Jean Bégaint, Fabien Racapé, Simon Feltman, and Akshay Pushparaja.
\newblock {{CompressAI}}: A {{PyTorch}} library and evaluation platform for end-to-end compression research, 2020.

\bibitem[Chen et~al.(2024)Chen, Huang, Xu, Pei, Chen, Li, Wang, Li, Lu, and Wang]{Chen2024VideoMS}
Guo Chen, Yifei Huang, Jilan Xu, Baoqi Pei, Zhe Chen, Zhiqi Li, Jiahao Wang, Kunchang Li, Tong Lu, and Limin Wang.
\newblock Video mamba suite: State space model as a versatile alternative for video understanding.
\newblock \emph{ArXiv}, abs/2403.09626, 2024.

\bibitem[Cheng et~al.(2020)Cheng, Sun, Takeuchi, and Katto]{Cheng.2020.LIC}
Zhengxue Cheng, Heming Sun, Masaru Takeuchi, and Jiro Katto.
\newblock Learned {{Image Compression With Discretized Gaussian Mixture Likelihoods}} and {{Attention Modules}}.
\newblock In \emph{Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}}, pages 7939--7948, 2020.

\bibitem[Datta(2024)]{Datta2024TheEO}
Akul Datta.
\newblock The evolution of rwkv: Advancements in efficient language modeling, 2024.

\bibitem[Duan et~al.(2024{\natexlab{a}})Duan, Wang, Chen, Zhu, Lu, Lu, Qiao, Li, Dai, and Wang]{Duan.2024.Vision-RWKV}
Yuchen Duan, Weiyun Wang, Zhe Chen, Xizhou Zhu, Lewei Lu, Tong Lu, Yu Qiao, Hongsheng Li, Jifeng Dai, and Wenhai Wang.
\newblock Vision-{{RWKV}}: {{Efficient}} and {{Scalable Visual Perception}} with {{RWKV-Like Architectures}}, 2024{\natexlab{a}}.

\bibitem[Duan et~al.(2024{\natexlab{b}})Duan, Wang, Chen, Zhu, Lu, Lu, Qiao, Li, Dai, and Wang]{Duan2024VisionRWKVEA}
Yuchen Duan, Weiyun Wang, Zhe Chen, Xizhou Zhu, Lewei Lu, Tong Lu, Yu Qiao, Hongsheng Li, Jifeng Dai, and Wenhai Wang.
\newblock Vision-rwkv: Efficient and scalable visual perception with rwkv-like architectures.
\newblock \emph{ArXiv}, abs/2403.02308, 2024{\natexlab{b}}.

\bibitem[Fei et~al.(2024)Fei, Fan, Yu, Li, and Huang]{Fei2024DiffusionRWKVSR}
Zhengcong Fei, Mingyuan Fan, Changqian Yu, Debang Li, and Junshi Huang.
\newblock Diffusion-rwkv: Scaling rwkv-like architectures for diffusion models.
\newblock \emph{ArXiv}, abs/2404.04478, 2024.

\bibitem[Gu and Dao(2023)]{Gu2023MambaLS}
Albert Gu and Tri Dao.
\newblock Mamba: Linear-time sequence modeling with selective state spaces.
\newblock \emph{ArXiv}, abs/2312.00752, 2023.

\bibitem[Guo et~al.(2024)Guo, Li, Dai, Ouyang, Ren, and Xia]{Guo2024MambaIRAS}
Hang Guo, Jinmin Li, Tao Dai, Zhihao Ouyang, Xudong Ren, and Shu-Tao Xia.
\newblock Mambair: A simple baseline for image restoration with state-space model.
\newblock In \emph{European Conference on Computer Vision}, 2024.

\bibitem[He et~al.(2022)He, Yang, Peng, Ma, Qin, and Wang]{He.2022.ELIC}
Dailan He, Ziming Yang, Weikun Peng, Rui Ma, Hongwei Qin, and Yan Wang.
\newblock {{ELIC}}: {{Efficient Learned Image Compression}} with {{Unevenly Grouped Space-Channel Contextual Adaptive Coding}}.
\newblock In \emph{2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})}, pages 5708--5717, 2022.

\bibitem[Ji et~al.(2024)Ji, Zou, Kui, Vera, and Ruan]{Ji2024DeformMambaNF}
Zexin Ji, Beiji Zou, Xiaoyan Kui, Pierre Vera, and Su Ruan.
\newblock Deform-mamba network for mri super-resolution.
\newblock \emph{ArXiv}, abs/2407.05969, 2024.

\bibitem[Jiang et~al.(2023)Jiang, Yang, Zhai, Gao, and Wang]{Jiang.2023.MLICpp}
Wei Jiang, Jiayu Yang, Yongqi Zhai, Feng Gao, and Ronggang Wang.
\newblock {{MLIC}}++: {{Linear Complexity Multi-Reference Entropy Modeling}} for {{Learned Image Compression}}.
\newblock In \emph{Proceedings of the 31st ACM International Conference on Multimedia}, pages 7618--7627, 2023.

\bibitem[Koyuncu et~al.(2022)Koyuncu, Gao, Boev, Gaikov, Alshina, and Steinbach]{Koyuncu.2022.CtxFormer}
A.~Burakhan Koyuncu, Han Gao, Atanas Boev, Georgii Gaikov, Elena Alshina, and Eckehard Steinbach.
\newblock Contextformer: {{A Transformer}} with {{Spatio-Channel Attention}} for {{Context Modeling}} in {{Learned Image Compression}}.
\newblock In \emph{Computer {{Vision}} – {{ECCV}} 2022}, pages 447--463. Springer Nature Switzerland, 2022.

\bibitem[Li et~al.(2023)Li, Li, Dai, Li, Zou, and Xiong]{Li.2023.FAT}
Han Li, Shaohui Li, Wenrui Dai, Chenglin Li, Junni Zou, and Hongkai Xiong.
\newblock Frequency-{{Aware Transformer}} for {{Learned Image Compression}}.
\newblock In \emph{The {{Twelfth International Conference}} on {{Learning Representations}}}. arXiv, 2023.

\bibitem[Liu et~al.(2023)Liu, Sun, and Katto]{Liu.2023.TCM}
Jinming Liu, Heming Sun, and Jiro Katto.
\newblock Learned {{Image Compression}} with {{Mixed Transformer-CNN Architectures}}.
\newblock In \emph{2023 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})}, pages 14388--14397. IEEE, 2023.

\bibitem[Liu et~al.(2024)Liu, Tian, Zhao, Yu, Xie, Wang, Ye, and Liu]{Liu2024VMambaVS}
Yue Liu, Yunjie Tian, Yuzhong Zhao, Hongtian Yu, Lingxi Xie, Yaowei Wang, Qixiang Ye, and Yunfan Liu.
\newblock Vmamba: Visual state space model.
\newblock \emph{ArXiv}, abs/2401.10166, 2024.

\bibitem[Liu et~al.(2021)Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and Guo]{Liu.2021.SwinT}
Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo.
\newblock Swin {{Transformer}}: {{Hierarchical Vision Transformer}} using {{Shifted Windows}}.
\newblock In \emph{2021 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})}, pages 9992--10002. IEEE, 2021.

\bibitem[Lu et~al.(2022)Lu, Guo, Shi, Cao, and Ma]{Lu.2022.TIC}
Ming Lu, Peiyao Guo, Huiqing Shi, Chuntong Cao, and Zhan Ma.
\newblock Transformer-based {{Image Compression}}.
\newblock In \emph{2022 {{Data Compression Conference}} ({{DCC}})}, pages 469--469, Snowbird, UT, USA, 2022. IEEE.

\bibitem[Luo et~al.(2016)Luo, Li, Urtasun, and Zemel]{Luo.2016.ERF}
Wenjie Luo, Yujia Li, Raquel Urtasun, and Richard Zemel.
\newblock Understanding the effective receptive field in deep convolutional neural networks.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[Ma et~al.(2024)Ma, Li, and Wang]{Ma2024UMambaEL}
Jun Ma, Feifei Li, and Bo Wang.
\newblock U-mamba: Enhancing long-range dependency for biomedical image segmentation.
\newblock \emph{ArXiv}, abs/2401.04722, 2024.

\bibitem[Minnen and Singh(2020)]{Minnen.2020.Charm}
David Minnen and Saurabh Singh.
\newblock Channel-{{Wise Autoregressive Entropy Models}} for {{Learned Image Compression}}.
\newblock In \emph{2020 {{IEEE International Conference}} on {{Image Processing}} ({{ICIP}})}, pages 3339--3343. IEEE, 2020.

\bibitem[Minnen et~al.(2018)Minnen, Ballé, and Toderici]{Minnen.2018.Joint}
David Minnen, Johannes Ballé, and George Toderici.
\newblock Joint {{Autoregressive}} and {{Hierarchical Priors}} for {{Learned Image Compression}}.
\newblock In \emph{Advances in {{Neural Information Processing Systems}} 31: {{Annual Conference}} on {{Neural Information Processing Systems}} 2018, {{NeurIPS}} 2018, 3-8 {{December}} 2018, {{Montréal}}, {{Canada}}.}, pages 10794--10803, 2018.

\bibitem[Peng et~al.(2023{\natexlab{a}})Peng, Alcaide, Anthony, Albalak, Arcadinho, Biderman, Cao, Cheng, Chung, Grella, GV, He, Hou, Lin, Kazienko, Kocon, Kong, Koptyra, Lau, Mantri, Mom, Saito, Song, Tang, Wang, Wind, Wozniak, Zhang, Zhang, Zhao, Zhou, Zhou, Zhu, and Zhu]{Peng.2023.RWKV}
Bo Peng, Eric Alcaide, Quentin Anthony, Alon Albalak, Samuel Arcadinho, Stella Biderman, Huanqi Cao, Xin Cheng, Michael Chung, Matteo Grella, Kranthi~Kiran GV, Xuzheng He, Haowen Hou, Jiaju Lin, Przemyslaw Kazienko, Jan Kocon, Jiaming Kong, Bartlomiej Koptyra, Hayden Lau, Krishna Sri~Ipsit Mantri, Ferdinand Mom, Atsushi Saito, Guangyu Song, Xiangru Tang, Bolun Wang, Johan~S. Wind, Stanislaw Wozniak, Ruichong Zhang, Zhenyuan Zhang, Qihang Zhao, Peng Zhou, Qinghua Zhou, Jian Zhu, and Rui-Jie Zhu.
\newblock {{RWKV}}: {{Reinventing RNNs}} for the {{Transformer Era}}, 2023{\natexlab{a}}.

\bibitem[Peng et~al.(2023{\natexlab{b}})Peng, Alcaide, Anthony, et~al.]{Bo.rwkv.2023}
Bo Peng, Eric Alcaide, Quentin Anthony, et~al.
\newblock Rwkv: Reinventing rnns for the transformer era, 2023{\natexlab{b}}.

\bibitem[Peng et~al.(2024)Peng, Goldstein, Anthony, Albalak, Alcaide, Biderman, Cheah, Ferdinan, Hou, l~aw Kazienko, Kranthikiran, Koco'n, Koptyra, Krishna, McClelland, Muennighoff, Obeid, Saito, Song, Tu, Wo'zniak, Du, Zhang, Zhao, Zhao, Zhou, Zhu, and Zhu]{Peng2024EagleAF}
Bo Peng, Daniel Goldstein, Quentin Anthony, Alon Albalak, Eric Alcaide, Stella Biderman, Eugene Cheah, Teddy Ferdinan, Haowen Hou, Przemys l~aw Kazienko, G Kranthikiran, Jan Koco'n, Bartlomiej Koptyra, Satyapriya Krishna, Ronald McClelland, Niklas Muennighoff, Fares Obeid, Atsushi Saito, Guangyu Song, Haoqin Tu, Stanislaw Wo'zniak, Xingjian Du, Ruichong Zhang, Bingchen Zhao, Qihang Zhao, Peng Zhou, Jian Zhu, and Ruijie Zhu.
\newblock Eagle and finch: Rwkv with matrix-valued states and dynamic recurrence.
\newblock \emph{ArXiv}, abs/2404.05892, 2024.

\bibitem[Qian et~al.(2022)Qian, Lin, Sun, Tan, and Jin]{Qian.2022.EntroFormer}
Yichen Qian, Ming Lin, Xiuyu Sun, Zhiyu Tan, and Rong Jin.
\newblock Entroformer: {{A Transformer-based Entropy Model}} for {{Learned Image Compression}}, 2022.

\bibitem[Qiao et~al.(2024)Qiao, Yu, Guo, Chen, Zhao, Sun, Wu, and Liu]{Qiao2024VLMambaES}
Yanyuan Qiao, Zheng Yu, Longteng Guo, Sihan Chen, Zijia Zhao, Mingzhen Sun, Qi Wu, and Jing Liu.
\newblock Vl-mamba: Exploring state space models for multimodal learning.
\newblock \emph{ArXiv}, abs/2403.13600, 2024.

\bibitem[Qin et~al.(2024)Qin, Wang, Zhou, Chen, Luo, An, Dai, Xia, and Wang]{Qin2024MambaVCLV}
Shiyu Qin, Jinpeng Wang, Yimin Zhou, Bin Chen, Tianci Luo, Baoyi An, Tao Dai, Shu-Tao Xia, and Yaowei Wang.
\newblock Mambavc: Learned visual compression with selective state spaces.
\newblock \emph{ArXiv}, abs/2405.15413, 2024.

\bibitem[Sheng et~al.(2023)Sheng, Li, Li, Li, Liu, and Lu]{Sheng.2023.TCM}
Xihua Sheng, Jiahao Li, Bin Li, Li Li, Dong Liu, and Yan Lu.
\newblock Temporal {{Context Mining}} for {{Learned Video Compression}}.
\newblock \emph{IEEE Transactions on Multimedia}, 25:\penalty0 7311--7322, 2023.

\bibitem[Sheng et~al.(2024)Sheng, Tang, Li, Liu, and Wu]{Sheng.2024.NVC1B}
Xihua Sheng, Chuanbo Tang, Li Li, Dong Liu, and Feng Wu.
\newblock {{NVC-1B}}: {{A Large Neural Video Coding Model}}, 2024.

\bibitem[Skodras et~al.(2001)Skodras, Christopoulos, and Ebrahimi]{Skodras.2001.JP2K}
Athanassios Skodras, Charilaos Christopoulos, and Touradj Ebrahimi.
\newblock The {{JPEG}} 2000 still image compression standard.
\newblock \emph{IEEE Signal processing magazine}, 18\penalty0 (5):\penalty0 36--58, 2001.

\bibitem[Sullivan et~al.(2012)Sullivan, Ohm, Han, and Wiegand]{Sullivan.2012.HEVC}
Gary~J. Sullivan, Jens-Rainer Ohm, Woo-Jin Han, and Thomas Wiegand.
\newblock Overview of the high efficiency video coding ({{HEVC}}) standard.
\newblock \emph{IEEE Transactions on circuits and systems for video technology}, 22\penalty0 (12):\penalty0 1649--1668, 2012.

\bibitem[Wallace(1992)]{Wallace.1992.JPEG}
Gregory~K. Wallace.
\newblock The {{JPEG}} still picture compression standard.
\newblock \emph{IEEE transactions on consumer electronics}, 38\penalty0 (1):\penalty0 xviii--xxxiv, 1992.

\bibitem[Xie et~al.(2021)Xie, Cheng, and Chen]{Xie.2021.EInv}
Yueqi Xie, Ka~Leong Cheng, and Qifeng Chen.
\newblock Enhanced {{Invertible Encoding}} for {{Learned Image Compression}}.
\newblock \emph{Proceedings of the 29th ACM International Conference on Multimedia}, pages 162--170, 2021.

\bibitem[Yang et~al.(2024{\natexlab{a}})Yang, Zhang, Zhao, Wei, and Xu]{Yang.2024.Restore-RWKV}
Zhiwen Yang, Hui Zhang, Dan Zhao, Bingzheng Wei, and Yan Xu.
\newblock Restore-{{RWKV}}: {{Efficient}} and {{Effective Medical Image Restoration}} with {{RWKV}}, 2024{\natexlab{a}}.

\bibitem[Yang et~al.(2024{\natexlab{b}})Yang, Zhang, Zhao, Wei, and Xu]{Yang2024RestoreRWKVEA}
Zhiwen Yang, Hui Zhang, Dan Zhao, Bingzheng Wei, and Yan Xu.
\newblock Restore-rwkv: Efficient and effective medical image restoration with rwkv.
\newblock \emph{ArXiv}, abs/2407.11087, 2024{\natexlab{b}}.

\bibitem[Yuan et~al.(2024)Yuan, Li, Qi, Zhang, Yang, Yan, and Loy]{Yuan2024MambaOR}
Haobo Yuan, Xiangtai Li, Lu Qi, Tao Zhang, Ming-Hsuan Yang, Shuicheng Yan, and Chen~Change Loy.
\newblock Mamba or rwkv: Exploring high-quality and high-efficiency segment anything model.
\newblock \emph{ArXiv}, abs/2406.19369, 2024.

\bibitem[Zhai et~al.(2021)Zhai, Talbott, Srivastava, Huang, Goh, Zhang, and Susskind]{Zhai.2021.AFT}
Shuangfei Zhai, Walter Talbott, Nitish Srivastava, Chen Huang, Hanlin Goh, Ruixiang Zhang, and Josh Susskind.
\newblock An {{Attention Free Transformer}}, 2021.

\bibitem[Zhou et~al.(2019)Zhou, Sun, Wu, and Wu]{Zhou.2019.EOI}
Lei Zhou, Zhenhong Sun, Xiangjian Wu, and Junmin Wu.
\newblock End-to-end {{Optimized Image Compression}} with {{Attention Mechanism}}.
\newblock In \emph{CVPR workshops}, 2019.

\bibitem[Zhou and Chen(2024)]{Zhou2024BSBPRWKVBS}
Xudong Zhou and Tianxiang Chen.
\newblock Bsbp-rwkv: Background suppression with boundary preservation for efficient medical image segmentation.
\newblock In \emph{ACM Multimedia}, 2024.

\bibitem[Zhu et~al.(2024)Zhu, Liao, Zhang, Wang, Liu, and Wang]{Zhu2024VisionME}
Lianghui Zhu, Bencheng Liao, Qian Zhang, Xinlong Wang, Wenyu Liu, and Xinggang Wang.
\newblock Vision mamba: Efficient visual representation learning with bidirectional state space model.
\newblock \emph{ArXiv}, abs/2401.09417, 2024.

\bibitem[Zhu et~al.(2021)Zhu, Yang, and Cohen]{Zhu.2021.TBTC}
Yinhao Zhu, Yang Yang, and Taco Cohen.
\newblock Transformer-based {{Transform Coding}}.
\newblock In \emph{International {{Conference}} on {{Learning Representations}}}, 2021.

\bibitem[Zou et~al.(2022)Zou, Song, and Zhang]{Zou.2022.DDW}
Renjie Zou, Chunfeng Song, and Zhaoxiang Zhang.
\newblock The {{Devil Is}} in the {{Details}}: {{Window-based Attention}} for {{Image Compression}}.
\newblock \emph{2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 17471--17480, 2022.

\bibitem[Kuznetsova et~al.(2020)Kuznetsova, Rom, Alldrin, Uijlings, Krasin, Pont-Tuset, Kamali et~al.]{Kuznetsova.2020.OpenImages}
Alina Kuznetsova, Hassan Rom, Neil Alldrin, Jasper Uijlings, Ivan Krasin, Jordi Pont-Tuset, Shahab Kamali, et~al.
\newblock The {{Open Images Dataset V4}}: Unified image classification, object detection, and visual relationship detection at scale.
\newblock \emph{International Journal of Computer Vision}, 128\penalty0 (7):\penalty0 1956--1981, 2020.

\bibitem[Kodak(1993)]{Kodak.1993.Lossless}
Eastman Kodak.
\newblock Kodak lossless true color image suite (photocd pcd0992).
\newblock 1993.

\bibitem[Asuni and Giachetti(2014)]{Asuni.2014.Tecnick}
Nicola Asuni and Andrea Giachetti.
\newblock Testimages: A large-scale archive for testing visual devices and basic image processing algorithms.
\newblock In \emph{STAG: Smart Tools and Applications in Computer Graphics}, pages 63--70, 2014.

\bibitem[CLIC(2021)]{CLIC.2021.Workshop}
CLIC.
\newblock Workshop and challenge on learned image compression.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2021.



\end{thebibliography}

}

% WARNING: do not forget to delete the supplementary pages from your submission 
\input{sec/X_suppl}

\end{document}