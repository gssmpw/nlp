\section{Introduction}
Robotic dexterous manipulation refers to the ability of a robot hand skillfully handling and manipulating objects for various target states with precision and adaptability. This capability has attracted significant attention because adept object manipulation for goals such as tool use is vital for robots to interact with the world. Many efforts have been devoted previously to push the ability of a dexterous hand toward human-level dexterity and versatility~\citep{rajeswaran2017learning,chen2023visual,chen2021system,akkaya2019solving,christen2022d,zhang2023artigrasp,qin2022dexmv,liu2022herd,wu2023learning,gupta2016learning,wang2023physhoi,mordatch2012contact,liu2024quasisim,Li2024ReinforcementLF}. This also aligns with our vision. 

Achieving human-level robotic dexterous manipulation is challenging due to two main difficulties: the intricate dynamics of contact-rich manipulation, which complicates optimization~\citep{pang2021convex,pang2023global,liu2024quasisim,Jin2024ComplementarityFreeMM}, and the need for robots to master a wide range of versatile skills beyond specific tasks. Previous approaches mainly resort to model-free reinforcement learning (RL)~\citep{chen2023visual,chen2021system,akkaya2019solving,christen2022d,zhang2023artigrasp,qin2022dexmv,liu2022herd,wu2023learning,gupta2016learning,wang2023physhoi} or model-based trajectory optimization (TO)~\citep{pang2021convex,pang2023global,Jin2024ComplementarityFreeMM,hwangbo2018per}. While RL requires task-specific reward designs, limiting its generalization, TO depends on accurate dynamics models with known contact states, restricting adaptability to new objects and skills. A promising alternative is to leverage human hand-object manipulation references, widely available through videos or motion synthesis, and focus on controlling a dexterous hand to track these references. This approach separates high-level task planning from low-level control, framing diverse skill acquisition as the development of a universal tracking controller.
However, challenges remain due to noisy kinematic references, differences in morphology between human and robotic hands, complex dynamics with rich contacts, and diverse object geometry and skills.
Existing methods struggle with these issues, often limiting themselves to simple tasks without in-hand manipulation~\citep{christen2022d,zhang2023artigrasp,wu2023learning,xu2023unidexgrasp,Luo2024GraspingDO,Singh2024HandObjectIP,Chen2024ViViDexLV} or certain specific skills~\citep{qin2022dexmv,liu2024quasisim,rajeswaran2017learning}.

In this work, we aim to develop a general-purpose tracking controller that can follow hand-object manipulation references across various skills and diverse objects. In particular, given a collection of kinematics-only human hand-object manipulation trajectories, the controller is optimized to drive a robotic dexterous hand to manipulate the object so that the resulting hand and object trajectories can closely mimic their corresponding kinematic sequences. 
We expect the tracking controller to exhibit strong versatility, generalize well to precisely track novel manipulations, and have strong robustness towards large kinematics noises and unexpected reference states. 


To achieve the challenging goal above, we draw three key observations: 1) learning is crucial for handling heterogeneous reference motion noises and transferring data prior to new scenarios, supporting robust and generalizable tracking control; 2) leveraging large-scale, high-quality robot tracking demonstrations that pair kinematic references with tracking action sequences can supervise and significantly empower neural controllers, as demonstrated by data-scaling laws in computer vision and NLP~\citep{Achiam2023GPT4TR,Brown2020LanguageMA}; 3) acquiring large and high-quality tracking demonstrations is challenging but we could utilize the data flywheel~\citep{Chiang2024ChatbotAA,Bai2023QwenTR} to iteratively improve the tracking controller and expand the demonstrations in a bootstrapping manner.


Based upon the previous observations, we propose \modelnamenspace, a novel neural tracking controller for dexterous manipulation, guided by human references. Specifically, given a collection of human hand-object manipulation trajectories, we first retarget the collection to kinematic robotic dexterous hand sequences to form a set of reference motions as data preparation. Our method then alternates between mining successful robot tracking demonstrations and training the controller with the mined demonstrations. To make sure the data flywheel functions effectively, we introduce two key designs. First, we carefully integrate reinforcement and imitation learning techniques to train a neural controller, ensuring its performance improves with more demonstrations while maintaining robustness against unexpected states and noise. Second, we develop a per-trajectory tracking scheme that uses the trained controller to mine diverse and high-quality tracking demonstrations through a homotopy optimization method. The scheme transfers the tracking prior from the controller to individual trajectories to ease per-trajectory tracking for better demonstration quality. Moreover, the scheme will convert a tracking reference into a series of gradually simplified reference motions so that tracking these references from simple to complex could help better track the original reference motion. This is akin to chain-of-thought and is very suitable for tracking complex reference motions to increase the demonstration diversity. The two designs above together with the iterative training enable \modelname to successfully track novel and challenging human references.


We demonstrate the superiority of our method and compare it with previous methods on challenging manipulation tracking tasks in two datasets, describing expressive hand-object interactions in daily and functional tool-using scenarios, involving complex object movements, difficult and subtle in-hand re-orientations, interactions with thin objects, and frequent hand-object rich contact variations. 
% We both conduct extensive experiments in the simulator, \emph{i.e.,} Isaac Gym~\citep{makoviychuk2021isaac}, to demonstrate the efficacy, generalization ability, and robustness of our tracker to accomplish a wide range of manipulation tracking tasks and even excellently track novel manipulation trajectories, and evaluate 
We conduct both extensive experiments in the simulator, \emph{i.e.,} Isaac Gym~\citep{makoviychuk2021isaac}, and evaluations in the real world, to demonstrate the efficacy, generalization ability, and robustness of our tracker to accomplish a wide range of manipulation tracking tasks and even excellently track novel manipulation trajectories (Figure~\ref{fig_intro_teaser}).
% both conduct 
% We conduct experiments in both the simulator, \emph{i.e.,} Isaac Gym~\citep{makoviychuk2021isaac},  and the real world to demonstrate the efficacy, generalization ability, and robustness of our tracker to accomplish a wide range of manipulation tracking tasks and even excellently track novel manipulation trajectories (Figure~\ref{fig_intro_teaser}). 
% We can track difficult manipulations involving expressive and complex object movements, detailed and subtle in-hand re-orientations, and frequent rich hand-object contact variations.
Our approach successfully surpasses the previous methods both quantitatively and qualitatively, achieving more than 10\% success rate than the previous best-performed method. Besides, we conduct further analysis and demonstrate the various recovery behaviors of our controller, demonstrating its robustness to unexpected situations. Thorough ablations are conducted to validate the efficacy of our designs.

Our contributions are threefold:
\begin{itemize} % [noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt,leftmargin=.5cm]
    \item We present a generalizable neural tracking controller that progressively improves its performance through iterative mining and incorporating high-quality tracking demonstrations.
    \item We introduce a training method that synergistically combines reinforcement learning and imitation learning. This approach leverages abundant high-quality robot tracking demonstrations to produce a controller that is generalizable, versatile, and robust.
    \item We develop a per-trajectory optimization scheme that employs our tracking controller within a homotopy optimization framework. We propose a data-driven way to generate homotopy paths, enabling solving challenging tracking problems.
\end{itemize}



