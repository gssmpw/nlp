\input{articles_cr/teaser_figure}


\begin{abstract}

We address the challenge of developing a generalizable neural tracking controller for dexterous manipulation from human references. This controller aims to manage a dexterous robot hand to manipulate diverse objects for various purposes defined by kinematic human-object interactions. Developing such a controller is complicated by the intricate contact dynamics of dexterous manipulation and the need for adaptivity, generalizability, and robustness. Current reinforcement learning and trajectory optimization methods often fall short due to their dependence on task-specific rewards or precise system models. We introduce an approach that curates large-scale successful robot tracking demonstrations, comprising pairs of human references and robot actions, to train a neural controller. Utilizing a data flywheel, we iteratively enhance the controller's performance, as well as the number and quality of successful tracking demonstrations. We exploit available tracking demonstrations and carefully integrate reinforcement learning and imitation learning to boost the controller's performance in dynamic environments. At the same time, to obtain high-quality tracking demonstrations, we individually optimize per-trajectory tracking by leveraging the learned tracking controller in a homotopy optimization method. The homotopy optimization, mimicking chain-of-thought, aids in solving challenging trajectory tracking problems to increase demonstration diversity. We showcase our success by training a generalizable neural controller and evaluating it in both simulation and real world. Our method achieves over a 10\% improvement in success rates compared to leading baselines. The project website with animated results is available at  \href{https://meowuu7.github.io/DexTrack/}{DexTrack}.
% and the number and quality of successful tracking demonstrations. 


% % We explore the problem of obtaining a generic controller for dexterous robotic hands 
% % learning a generalizable neural tracking controller for dexterous manipulation from human references. 
% We explore the problem of learning a generalizable neural tracking controller for dexterous manipulation from human references.
% % The task wishes for a versatile controller that can control a dexterous robot hand to accomplish various, challenging and expressive manipulation tasks specified by kinematic human-object manipulations. 
% This task wishes for a versatile controller capable of managing a dexterous robot hand to execute various complex and expressive manipulation tasks, as defined by kinematic human-object interactions.
% It is inherently challenged by the optimization difficulty resulting from intricate dynamics involved in dexterous manipulation and the expectation in the versatility, generalization ability, and robustness of the tracking controller.
% % to various, novel, and challenging manipulation tasks. 
% Either advanced model-free reinforcement learning (RL)-based techniques or model-based trajectory optimization fall short in resolving such huge challenges due to the demand on task-specific reward designs that largely hinder the generalization capability and the difficulty in complex system modeling in the dexterous manipulation scenario.
% Our key idea lies in leveraging high-quality abundant imitation-ready data to train a tracking controller and tackling the difficulties in acquiring such data by leveraging the data flywheel to curate high-quality data and improve the tracking controller in a bootstrapping manner.
% % by carefully combining reinforcement learning and imitation learning, 
% % jointly with RL and tackling the difficulties in acquiring such data by leveraging the data flywheel to curate high-quality data and improve the tracking controller in a bootstrapping manner.
% % leverage abundant, high-quality, imitation-ready data to facilitate the learning of a generalizable tracking controller.
% We carefully combine reinforcement learning and imitation learning to train the neural tracking controller to enhance its versatility, generalization ability, and robustness towards dynamic environment variations. To curate abundant high-quality imitation-ready data, we devise a per-trajectory tracking strategy using the tracking controller and a homotopy path generator, mimicking chain-of-thought, that can propose beneficial homotopy optimization paths to help us solve difficult single trajectory tracking problems. We showcase our success in training a versatile neural tracking controller with high generalization ability and robustness. Through extensive experiments conducted in both simulation and real world, our method demonstrates an improvement in success rates of over 10\% compared to the best-performing baseline. The project website with animated results is available at \href{https://projectwebsite7.github.io/gene-dex-manip/}{DexTrack}.
% % We demonstrate our success in training a versatile neural tracking controller with high generalization ability and robustness. We conduct extensive experiments in both the simulator and the real world, demonstrating capability of our method in boosting the success rate by 10\%+ from the best-performed baseline. The project website is available at \href{https://projectwebsite7.github.io/gene-dex-manip/}{DexTrack}. 
% % We conduct extensive experiments in both the simulator the real world, demonstrating the versatility, generalization ability, and robustness of our tracking controller,  capability of boosting the success rate by 10\%+ from the best-performed baseline. The project website is available at \href{https://projectwebsite7.github.io/gene-dex-manip/}{DexTrack}.
% % Isaac Gym and 
% % that effectively improves single trajectory tracking results via the tracking controller and a homotopy path generator, mimicking chain-of-thought, that can propose beneficial homotopy optimization paths. 
% % We leverage imitation learning and reinforcement learning to train the neural tracking controller to let it benefit from a large number of high-quality data and also be able to cope with dynamic state disturbances. To curate abundant high-quality imitation-ready data, we devise a per-trajectory tracking scheme that effectively improves single trajectory tracking results via the tracking controller and a homotopy path generator, mimicking chain-of-thought, that can propose beneficial homotopy optimization paths. 
% % We successfully train a universal tracking controller that enables a dexterous robot hand to adeptly interact with diverse objects to accomplish a wide range of novel and expressive manipulation tasks. 
% % with dynamics, rich hand-object contacts. 

% % Previous approaches are typically restricted to task-specific manipulation skill acquisition or only demonstrate the versatility in relatively simple tasks such as grasping, leaving 
% % the general dexterous tracking control largely unsolved~\eric{``Dexterous tracking control'' is not a good term. Dexterous is used to describe manipulation other than tracking.}. 
% % are typically limited by the unsatisfactory capability and versatility, leaving the universal dexterous tracking control largely unsolved. 
% % unsatisfactory task difficulties or being restricted in single trajectory tracking, leaving the universal dexterous tracking control largely unsolved. 
% % We propose to leverage the joint effort of reinforcement learning (RL) and the diverse and high-quality action-labeled data to open the possibility of training general tracking control policy. 
% % We wish to learn a versatile and generalizable neural controller by imitating abundant, high-quality data with actions to obtain the generalization ability towards veraious situations, and leveraging reinforcement learning to maintain the robustness and unepxted situations. However, acquiring  a large number of imitation-ready data itself is tricky and challenging. 
% % We propose to leverage abundant, high-quality, imitation-ready data to facilitate the learning of a generalizable tracking controller.
% % Since acquiring a large amount of imitiation-ready data with hgih-quality action sequences itself is very challenging, we devise a strategy w
% % But acquiring a large amount of imitation-ready data itself is very challenging. We propose to learn a tracking task structure prior model which is further leveraged to plan optimization paths so that we can solve difficult tracking problems via a homotopy method. 
% % model tracking task structure 
% % by 
% % transferring tracking data prior and a homotopy method propose
% % with the optimization paths generated by a homotopy generator. 
% % We design an iterative way to improve the imitation-ready data by data prior from the tracking controller and the tracking task structure prior, and enhance the tracking controller in a bootstrapping manner. 
% % improve the tracking controller 
% % But acquiring high-quality data itself
% % data to facilitate the tracking 
% % We design an iterative approach where we 1) curate high-quality action-labeled data taking the joint power of tracking prior from the tracking controller and tracking curriculum proposed by a learned curriculum scheduler, and 2) train the tracking controller taking advantage of the guidance from the labeled data. 
% % a universal controller that can generalize to adeptly complete various novel and challenging manipulation tasks. 
% % challenged by inherent difficulties from 
% % We explore the problem of learning a universal tracking controller from human references. The task wishes for a versatile controller that can control a dexterous robot hand to accomplish various challenging and expressive manipulation tasks specified by kinematic motions. It is challenged by inherent difficulties from the complex and intricate dynamics involved in dexterous manipulation and the wish for a universal controller that can generalize to adeptly complete various novel and challenging manipulation tasks. Previous approaches are typically limited by unsatisfactory task difficulties or being restricted in single trajectory tracking, leaving the universal dexterous tracking control largely unsolved. We propose to leverage the joint effort of reinforcement learning (RL) and the diverse and high-quality action-labeled data to open the possibility of training genera tracking control policy. We design an iterative approach where we 1) curate high-quality action-labeled data taking the joint power of tracking prior from the tracking controller and tracking curriculum proposed by a learned curriculum scheduler, and 2) train the tracking controller taking advantage of the guidance from the labeled data. We successfully train a universal tracking controller that enables a dexterous robot hand to adeptly interact with diverse objects to accomplish a wide range of novel and expressive manipulation tasks. We conduct extensive experiments in both Isaac Gym and the real world, demonstrating the capability of boosting the success rate by xx\%+ from the best-performed baseline. 
\end{abstract}