\section{Related Work}
\begin{figure*}[t]
    \centering
    \resizebox{0.9\textwidth}{!}{%
        \tikzfig{TikZ/protocol_comparison}
    }
    \caption{The three main approaches to content provenance. 
    Metadata-based provenance (top) uses an auxiliary manifest to attach a cryptographic signature and other metadata to the image---signature authentication yields provenance.
    Watermarking (middle) encodes a payload with provenance information directly into the image itself, and the payload can be decoded thereafter.
    Retrieval-based detection (bottom) maintains a global store of image embeddings where the store is queried to check if a candidate image is known.}
    \label{fig:misinformation_approaches}
\end{figure*}
We cover essential related work below.
For wider coverage, see Supplement~\ref{app:extended_rw}.
For a graphical overview of the main approaches to content provenance, see~\Cref{fig:misinformation_approaches}.

\textbf{Metadata-based provenance.}
Throughout the paper, we use metadata-based provenance to refer to strategies that attach signatures as additional metadata (See~\Cref{fig:misinformation_approaches}).
The C2PA~\textit{et al.}, "Digital Watermarking" standard is the current leading approach.
The attached metadata is referred to as a manifest.
This manifest contains cryptographic information attesting to the content's creation, modification, and distribution history.
The manifest is ``hard bound'' to the content using a cryptographic hash---even a one bit change in content would cause its hash to change and detach the manifest from its content.
% It is crucial that both the content and manifest are preserved in order for verification to succeed.
Both the content and manifest must be preserved in order for verification to succeed.

Metadata-based provenance can, in general, provide a comprehensive record of the content's history.
Due to its use of standardized cryptographic primitives, the system achieves a strong and well-defined notion of security.
Moreover, verifying a C2PA~\textit{et al.}, "Digital Watermarking" manifest is \textit{fully public}---anyone can verify the authenticity of a C2PA manifest by leveraging existing public-key infrastructure~\textit{ et al.}, "Secure Infrastructure for Digital Signatures".
% This is crucial in the context of attribution and copyright protection as it is not necessary to introduce trusted third-parties.

Conversely, the link between manifest and content is weak: it is trivial to detach the corresponding manifest from any arbitrary content.
% protected content
Adversarial detachment aside, existing web infrastructure cannot readily support the manifest.
Updating infrastructure to accommodate C2PA manifests is a time-consuming and costly endeavor.
To partially address this problem, the C2PA working group is considering a \textit{soft binding} extension where metadata can be re-attached to content using a perceptual hash computed from the content or a watermark embedded within the digital content.
The group has referenced a candidate algorithm~\textit{ et al.}, "Robust Perceptual Hashing" but any method that enables a ``similarity comparison'' between content is plausible.

\textbf{Watermarking.}
% Fundamentally, all watermarking schemes aim to hide information within the content itself without visibly perturbing the content.
Fundamentally, watermarking schemes aim to hide information within content itself without visibly perturbing the content.\footnote{We do not consider ``visible'' watermarking schemes as they alter content and are easily strippable.}
% The encoded information can enable provenance: in practice, the payload is usually a unique identifier that enables some form of external information retrieval or it directly holds origin-related information if the watermark capacity is large.
The encoded information can enable provenance: in practice, the payload is usually a unique identifier for external information retrieval or, if the watermark capacity is large, a data store for origin-related information.

% The commonality between watermarking schemes (see \autoref{app:extended_rw}) is that they are optimized for resistance to content modifications---the watermark payload should not be destroyed if transformed content is ``reasonably similar'' to the original watermarked image.
Common among watermarking schemes (see Supplement~\ref{app:extended_rw}) is their optimization to resist content modifications---the watermark payload should not be destroyed if transformed content is ``reasonably similar'' to the original watermarked image.
% In addition, the watermark meets a high degree of imperceptibility: to an untrained eye, watermarked versions of content are of the same quality as the base image.
In addition, the watermark meets a high degree of imperceptibility: to an untrained eye, an image and its watermarked counterpart are of the same quality.
Since the watermark embeds information into the image itself rather than additional metadata, it does not require any web infrastructure changes and can be dropped in to enable provenance immediately.
However, such systems are subject to the following concerns:

% \textit{Verifiability.} How can a user know that the trusted parties are performing honestly? 
% Consider the case where a model provider has an image generation model that they watermark with a proprietary algorithm and is verified without the need to provide a proof.
% An adversary crafts a malicious prompt that makes the model produce a dangerous image (e.g. a deepfake) which is then circulated online.
% Eventually, the image is passed through the proprietary detector that is also managed by the model provider.
% Crucially, the model provider is \textit{not} incentivized to take ownership of the image. 
% Instead of returning the true detector output (which may or may not be correct in the first place), it can simply output "no."--- since the scheme is not verifiable, this dishonesty will go uncaught.

\textit{Security.} 
There is no guarantee that proprietary algorithms are secure or correct, so end users cannot contextualize detection results.
In the text setting, post-hoc detectors commonly flag human-generated text as AI-generated, directly harming individuals~\textit{ et al.}, "Post-Hoc Detection of Text Generation".

\textit{Utility.} All known industry watermarks only permit trusted users to plant or detect watermarks---the watermark provider cannot release the detector or perform watermarking client-side as it weakens security.

\textbf{Retrieval-based detection.} 
The most straightforward approach to provenance is to maintain a large, continuously-updated database containing every AI-generated image.
This solution is problematic when (a) different model providers do not have unified storage or (b) scalability issues arise once the database reaches a critical size.
Other issues (such as privacy) can be partially ameliorated by using \textit{fingerprints}: instead of storing images directly, a succinct and robust representation of each image (a fingerprint) is stored that preserves the ability to measure similarity.
% The fingerprint should preserve the ability to measure similarity, i.e., it should be possible to determine if two fingerprints stem from the same root image.

Similarity comparisons arise in many areas of computer science beyond content fingerprinting~\textit{ et al.}, "Robust Similarity Measures", such as perceptual hashing~\textit{et al.}, "Perceptual Hashing for Image Recognition", copy detection~\textit{et al.}, "Copy Detection using Perceptual Hashing", and fuzzy matching~\textit{ et al.}, "Fuzzy Matching Algorithms".
In this work, we group these techniques under the umbrella of a ``robust embedding.''
In practice, robust embeddings are deployed for explicit material detection.
Examples are detection of non-consensual intimate image abuse~\textit{et al.}, "Non-Consensual Intimate Image Abuse Detection", online terrorism~\textit{ et al.}, "Online Terrorism Content Identification", and child sexual abuse material (CSAM)~\textit{ et al.}, "Child Sexual Abuse Material Detection".