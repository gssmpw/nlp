\section{Background and Related Work}
\label{sec:related-work}

Our work connects important lines of research on combinatorial optimization (especially MILPs), LLMs for MILP modeling, and automatic equivalence-checking methods for optimization formulations.

\subsection{Combinatorial Optimization and MILPs}

Combinatorial optimization (CO) broadly deals with finding an optimal object from a finite (or countably infinite) set of feasible candidates. Such problems arise in diverse fields, including operations research, computer science, and engineering, where discrete variables model decisions in practical scenarios such as routing, scheduling, or allocation of limited resources \cite{Papadimitriou82}. 

A foundational tool for combinatorial optimization is \emph{mixed-integer linear programming} (MILP), formulated as:
\begin{equation}
\label{eq:milp}
\begin{aligned}
& \min_{x \in \mathbb{R}^p \times \mathbb{Z}^{n-p}}  c^\top x \\
& \text{subject to} \quad A x \circ b, \quad \ell \leq x \leq u,
\end{aligned}
\end{equation}
where \( x \) is the vector of decision variables, \( c \) is the cost vector, \( A \) is the constraint coefficient matrix, and \( b \) is the vector of constraint bounds. The notation \( A x \circ b \) represents a system of linear constraints, where \( \circ \) denotes relational operators from the set \(\{\leq, \geq, =\}\). The variables \( x \) are partitioned into \( p \) continuous variables and \( n - p \) integer variables. Let \( x^* \) denote an optimal solution to \eqref{eq:milp}, and let \(z^* = c^\top x^*\) be the corresponding optimal objective value. If all decision variables are continuous (\( p = n \)), the problem is a \emph{linear program} (LP).
 MILPs capture many prominent combinatorial problems such as the traveling salesman problem (TSP) \cite{Applegate06}, knapsack problem \cite{Kellerer04}, and network design problems \cite{Johnson78}.

Many fundamental CO problems---including TSP and Knapsack---are known to be NP-hard. A key contribution to the theory of NP-completeness was provided by \citet{Karp10}, who demonstrated that a number of widely studied problems are mutually reducible in polynomial time (often referred to as ``Karp reductions''). These reductions establish deep structural connections among CO problems, showing that if a polynomial-time algorithm exists for one, it can be systematically adapted to solve many others. 


\subsection{Language Models for MILP Modeling}

The use of language models for MILP modeling has sparked considerable interest in the AI-for-OR community. The NL4Opt competition \cite{ramamonjison23} focused on using natural language processing (NLP) methods to formulate optimization problems based on their text descriptions. More recently, with the advent of LLMs, a number of LLM-based \emph{optimization copilots} aim to automate MILP modeling \cite{ mostajabdaveh24, ahmed24,li23,yu24,huang2024large,kadiouglu24, yang2024optibench}. %
Both the Chain-of-Experts \cite{xiao24} and OptiMUS \cite{Ahmaditeshizi24} frameworks designed LLM-based multi-agent systems to automate the modeling of complex optimization problems by leveraging the reasoning capabilities of the LLMs.  
\citet{tang24} further demonstrated the potential of LLMs by fine-tuning open-source models with synthetic data tailored for modeling optimization problems, achieving significant performance improvements over baseline methods. Building on these capabilities, LLM-powered chatbots have been used to allow users to interact with optimization models in a number of contexts including supply chain management \cite{li2023large}, meeting scheduling \cite{lawless2024want}, debugging infeasible models \cite{chen2023diagnosing}, and improving solver configurations \cite{lawless2024llms}.
These advancements highlight why LLMs are particularly suitable for MILP modeling: their ability to process and generate structured information from natural language aligns well with the requirements of optimization problem formulation.  
The rapid development of optimization copilots underscores
the need for reliable, scalable evaluation techniques.



\subsection{Existing Automatic Equivalence Checking Methods}%

The central task of evaluating optimization copilots 
is automatically checking 
whether the generated formulation 
is equivalent to a ground-truth correct one.
The earliest method used in the NL4OPT benchmark \citep{ramamonjison23} for evaluating formulation equivalence is \emph{canonical accuracy}, which looks at direct equivalence between declarations (e.g., objective, constraints) between a reference correct formulation and a generated formulation. 
This method is sensitive to permutations of the order of the declarations in a formulation and fails when multiple valid formulations exist for the same problem. 
The method used in benchmarks such as NLP4LP \citep{Ahmaditeshizi24}, MAMO \cite{huang24}, and IndustryOR \citep{tang24} is \emph{execution accuracy}, which evaluates whether two MILP formulations are equivalent by solving them (using a MILP solver such as Gurobi) and checking if they have the same optimal objective value. 
Execution accuracy is sensitive to variable re-scaling, which can create inconsistencies even when the formulations are functionally equivalent. 
To address these issues, recent approaches utilize Graph Edit Distance \citep{xing24} and a modified Weisfeiler-Lehman (WL) test \cite{wang24} to measure structural similarity between the generated and reference formulations. 
These methods offer insights into equivalence beyond the optimal objective value but have limitations.
They are particularly sensitive to structural modifications, such as adding cutting planes, 
which keeps the formulation equivalent but changes its structural information. 
Beyond these methods, \citet{steever22} proposed an image-based approach to detect structural similarity among large-scale MILPs.