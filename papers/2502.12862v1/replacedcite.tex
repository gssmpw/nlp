\section{Related Work}
\label{sec:RelWork}
On one hand, robotic agents are autonomous entities capable of planning, decision-making, and performing actions to achieve complex tasks. On the other hand, due to its AI nature, the abilities of large language models (LLMs) to respond to dynamic scenarios have enabled their incorporation into various robotic applications, resulting in LLMs-powered agents, where LLMs function as the brains of these agents. 

To effectively serve as the robot's brain, LLMs must have the ability to understand, generate, and interact with language that is grounded in a specific physical, social, or perceptual context of the environment in which they are operating. For example, when a person instructs a
robot to pick up a bottle, the LLM-powered agent must map the word ``bottle” to a particular set of percepts in its operational environment, and then produce a plan or policy that causes its end effector to create a stable grasp of the bottle and lift it. This process of learning the connections between percepts and actions is called \textit{grounded language} ____. This means the language is connected to real-world situations, environments, and tasks, enabling the LLM to interpret and respond to instructions, questions, or interactions in a way that is relevant to the physical world.



% Grounded language acquisition is the process  ____

% learning these connections between percepts and actions


% bridge the gap between abstract linguistic input and the concrete realities of the environment in which they are operating. This capability is crucial for tasks involving embodied agents, such as robots, that interact with the physical world.


From the LLM's perspective, modules and strategies employed in autonomous agents for founded language understanding, require planning, reasoning, feedback, and memory integration alongside human-like logic, step-by-step planning, and future-oriented reasoning. When tasked with a specific description, LLMs can understand and generate precise plans without additional training ____.
% \textcolor{red}{rephrase}On the other hand, reasoning employs a modified LLM as an AI model to analyze potential future outcomes and investigate alternative strategies for completing tasks ____. In open-loop systems, LLMs generate plans based on closed-loop methods that provide feedback to LLMs, enabling re-evaluation and updates to ensure accurate task completion ____. Numerous methods ____ employ LLMs in a closed-loop system, where feedback from action responses is used to re-evaluate and adjust the plan as needed. Depending on the acquired capabilities of LLMs, many fine-tuned methods, propose a better prompting approach, or utilize different modules to enhance agents’ performance. 
On the other hand, reasoning involves using an adapted LLM as an AI model to predict future outcomes and explore different strategies for task completion ____.  In open-loop systems, LLMs generate plans based on closed-loop methods that provide feedback to LLMs, enabling re-evaluation and updates to ensure accurate task completion ____. Several approaches ____ integrate LLMs into closed-loop systems, where feedback from actions is used to reassess and modify plans as necessary. Depending on the LLMs' capabilities, various methods either fine-tune the models, propose improved prompting strategies, or utilize different modules to boost agent's performance. More specifically, Song et al. ____ propose an LLM-Planner for a few-shot planning for embodied agents capable of dynamically re-planing based on environmental perception to produce more grounded plans. Singh et al. ____ introduced ProgPrompt, a LLM prompting scheme for robot task planning incorporating commonsense reasoning and code understanding via situated state feedback from the environment. Ding et al. ____, introduces LLM-GROP, a generalized prompting approach for object rearrangement tasks in varying scene geometry while Liu et al. ____ proposes an LLM-driven task planning approach called DELTA which translates environmental topology into actionable grounding knowledge.


In real-world scenarios, while LLMs excel at following instructions, their use in physically grounded tasks necessitates adjustments due to their limited real-world knowledge. 
%When tasked with a description and action sequence, LLMs can generate precise plans without additional training ____.
Recent studies have explored the ability of LLMs for few-shot high-level robotics task planning ____ for HRI, focusing on manipulation and navigation. In terms of manipulation, LLMs enhance a robot's ability and adaptability, leading to more effective performance in tasks such as object recognition, grasping, picking, and placing. They process visual and spatial data to identify the best methods for interacting with various objects ____. Regarding navigation, LLMs boost a robot’s ability to navigate through complex environments with precision and accuracy. They generate viable paths and trajectories while considering various environmental factors, which is particularly valuable in settings that require precise and adaptable navigation in dynamic environments ____. These studies utilize structured prompts containing predefined functions and examples to direct the model's generated responses. However, crafting prompts may present challenges due to the absence of matched natural language instructions linked to specific executable plans or sequences of robot actions, especially in real-world conditions. Having this in mind, our approach bypasses traditional search methods, directly producing a plan using custom-developed APIs that clearly describe the intended function behavior based on the robot's configurations that incorporate conditional reasoning and error correction.

% Following this principle, our approach bypasses traditional search methods, directly producing a plan that incorporates conditional reasoning and error correction. \textcolor{red}{this is few-shot learning}

\color{black}
Similar to our approach, ____, employ LLMs to generate open-domain plans in symbolic AI. Their methodology involves several steps: firstly, choosing a comparable task from the prompt example; secondly, generating task plans in an open-ended manner (answer search); and finally, aligning 1:1 predictions directly with robot actions. Additionally, ____, generates open-domain plans for robots using GPT-4. In this work, planning proceeds based on a high-level function library that allows ChatGPT to adapt to different robotics tasks. However, action-matching relies on predefined API functions derived from a simulator or a framework, thereby limiting the capabilities of a robot based on a generated text that ensures that the action is admissible in specific scenarios and not applicable in the real world.

The Transformer structure, introduced by ____, has revolutionized NLP and shown great potential in the field of robotics. It has been applied in various reinforcement learning-driven tasks ____ and pattern recognition ____. Additionally, model approaches such as SayCan ____ focus on connecting language models to interpret natural language commands and compute a value function that ranks the output actions available within a robot-specific library. On the other hand, RT-1 ____ follows an end-to-end strategy, learning how language commands directly map to low-level robotic actions without relying on intermediate high-level functions.

Ye et al. ____ proposed a robot control system called RoboGPT utilizing ChatGPT ____ to control a robotic arm manipulator. The distinguishing characteristic of their methodology lies in the incorporation of off-the-shelf functions for robot control adopting a user-on-the-loop architecture. They introduced an AI assistant that generates prompts, presents the prompts to human operators, and waits for further instructions to proceed to the executable plan, emphasizing on the trust level between humans and robots. Although their approach showcased an improved trust level between humans and robots, RoboGPT is based only on generic robotic functions, prioritizing the bidirectional communication between humans and robots.

Jin et al. ____ introduced a learning framework for robotic manipulation utilizing ChatGPT. The paper proposes leveraging a simulation environment and a natural language-based robotic API to enhance ChatGPT's problem-solving capabilities. The objective is to enable ChatGPT, through a trained agent called RobotGPT, to absorb knowledge at the task-planning level and improve task success rates by keeping ChatGPT in the loop acting as a decision, evaluation, and corrector until their code runs successfully. Their strategy, however, explores ChatGPT-generated code as a task planner which sometimes may produce minor bugs or syntax errors that cannot be directly applicable to real robots, and even if it could, it cannot guarantee the stability and safety of the system.

In contrast to the existing methodologies, this paper aims to enhance the capabilities of mobile robots by equipping them with planning abilities akin to human-level thinking, without imposing any limitations. This endeavor seeks to bridge the gap between humans and robots by leveraging secure and precise instructions from any LLM guided by natural language. More specifically, our proposed framework presents a holistic approach to open-domain planning for mobile robots. It employs a multi-phase strategy that combines the standardization and adaptability of high-level functions with the precision of direct action mapping to low-level robotic actions. These robotic functions are enclosed in a library suite that serves as a centralized repository, ensuring code reliability and unlocking the challenges of AI-generated code drift while employing LLMs for generating robotic-related code that may render the robot in invalid states that could compromise the robot's structural integrity or the failure of the assigned task. With modularity, version control, and comprehensive documentation, RobotIQ ensures consistency, facilitates updates, and enables easy management of any robotic platform, thereby allowing LLMs to translate user objectives expressed in natural language format into a logical sequence of high-level function calls, as depicted in Fig. \ref{fig:arch}.

\subsection{Contributions}
In a nutshell, the novelty of this paper lies in a system-focused contribution, namely RobotIQ, a framework designed for empowering mobile robots with human-level planning while integrating the following characteristics and software solutions:

% centered on RobotIQ, a framework designed to equip robots with advanced understanding and human-level planning capabilities

% , namely RobotIQ, for empowering mobile robots with human-level planning integrating the following unique characteristics and custom software solutions:

\begin{itemize}
    \item  A ROS-based API pipeline for robotic actions and AI integration with flexible LLM application,

    \item Development of well-defined API-wise control functions as a robotic library suite supporting modular control,
    
   % \item Fusion of the customized ROS library suite into the ChatGPT architecture,
   
    \item Enhance human-robot interactions where users can communicate with any robot in a natural language format by \textit{text} or \textit{voice} commands, 

    \item An open-source and easy-to-use robotic library suite for easy integration and adaptation across a wide range of robotic platforms and applications,
    
    \item A Sim-to-Real transfer learning-based policy for a robot navigation case.

    \item Evaluation of the proposed system in simulated and real-world experiments.

\end{itemize}

% Built upon the foundation of the Robot Operating System (ROS) ____, an open-source robotics middleware suite for a vast majority of ground, aerial, and underwater robotic vehicles and robotic arms, we offer to the research community a tool to develop and test custom solutions for any robotic application. The overall RobotIQ framework is open-source and publicly available\footnote{\url{https://github.com/emmarapt/RobotIQ.git}} to the community.


The theoretical contribution of this paper lies in simplifying the integration of intelligence (IQ) into robotic platforms. RobotIQ, offers flexibility by allowing a single framework to be used across a diverse array of robotic platforms, including ground, aerial, and underwater robots, as well as robotic arms while focusing on navigation, manipulation, perception, localization, and human-robot interaction presenting the most important capabilities in the field of robotics. 

A standout feature of our research is the development of a Sim-to-Real transfer learning-based policy for robot navigation, which represents a significant advancement in bridging the gap between simulation and real-world applications. This novel approach allows our system to effectively transfer learned behaviors from simulated environments to actual robotic operations, ensuring that navigation policies are both accurate and adaptable to real-world conditions. By leveraging this policy, our framework enhances the efficiency and reliability of robot navigation, setting a new benchmark in the field. This contribution not only addresses common challenges in transferring simulated knowledge but also demonstrates a substantial leap forward in improving real-world robotic performance.

Furthermore, built upon ROS, RobotIQ benefits from the robust tools and resources that ROS offers, ensuring compatibility with different hardware and software components and making it easier to deploy and extend the system across multiple robotic applications, leveraging the inherent advantages of ROS, such as its modularity, interoperability, and extensive community support. 

Our framework is designed to be compatible with any LLM, allowing it to integrate with a wide range of models and stay current with the latest AI advancements. This versatility enables users to customize the system based on specific needs, leveraging the unique strengths of different LLMs across different projects and industries, optimizing performance and resource usage by selecting the most appropriate model for each scenario. The ability to switch between LLMs also enhances the system's robustness, reducing the risk of underperformance in certain scenarios, and avoiding vendor lock-in ensures long-term sustainability and freedom in choosing technological solutions.

This universality is essential in an era where robotics applications are used in multiple industries, from healthcare and agriculture to manufacturing and exploration. By integrating advanced intelligence and NLP, robots can interact more effectively with humans, understand complex instructions, and adapt their behavior to dynamic environments, where they can interpret and act upon spoken commands in chaotic settings. The novelty of such a system lies in its holistic nature and in its departure from traditional approaches that rely on pre-defined API functions and are often limited to specific simulators or robots. Instead, an adaptable system like this provides a modular, customizable solution that extends beyond these constraints, offering a versatile tool for researchers and practitioners. This innovation not only enhances the efficiency and effectiveness of robotic systems but also accelerates the development of tailored solutions for various applications, leading to broader societal impacts. By addressing the need for a unified yet adaptable framework, this research supports the advancement of intelligent machines capable of making significant contributions to multiple industries, ultimately improving quality of life and driving progress on a global scale. To the best of our knowledge, RobotIQ is the first framework to (i) offer adaptability across various robotic platforms, (ii) support any machine learning, AI-based, and traditional approaches and translate them into API functions, and (iii) enable any LLM-based translation of natural language into programming code, all within a modular, public available and open-source framework\footnote{\url{https://github.com/emmarapt/RobotIQ.git}}.

% The overall RobotIQ framework is open-source and publicly available\footnote{\url{https://github.com/emmarapt/RobotIQ.git}} to the community.
% \color{black}


% Built upon the foundation of the Robot Operating System (ROS) ____, this research establishes a foundational framework for AI-based robotic systems that seamlessly incorporate natural language processing (NLP) and understanding. RobotIQ, owing to its modular and custom design streamlines the utilization of any robot including ground, aerial, and underwater robotic vehicles and robotic arms with LLMs and NLP capabilities. Unlike other systems that rely on pre-defined API functions connected to specific simulators or robots, RobotIQ stands out due to its modular and customizable design, extends to broader societal impacts and offers to the research community a tool to develop and test custom solutions for any robotic application, representing a significant step towards the advancement of intelligent machines and their potential to revolutionize multiple industries. The overall RobotIQ framework is open-source and publicly available\footnote{\url{https://github.com/emmarapt/RobotIQ.git}} to the community.
% \color{black}