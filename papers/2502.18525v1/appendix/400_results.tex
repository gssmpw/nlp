\section{Results}
\label{app:results}

Table~\ref{tab:full_model_performance} presents comprehensive results for all agent designs across 15 datasets in \bench{}. For comparison, we include previously reported state-of-the-art results, which represent the best performance achieved on individual datasets through various specialized approaches including finetuned models, custom tool interfaces, specific pipelines, prompts, inference strategies, and verifiers. 

It is important to note that direct comparisons on individual datasets may not provide a complete picture, as state-of-the-art results often utilize different model versions, computational budgets, and domain-specific tools. For example, the 55\% performance on SWE-Bench was achieved using significantly longer agent trajectories compared to \ours{}'s 20-iteration limit. Given statistical variations and differing evaluation conditions, we emphasize evaluating agents across the full range of tasks rather than focusing on individual dataset performance, as this better aligns with our goal of developing general-purpose SWE agents.
We make our best effort to include the latest publicly available results, however, there may be 
minor discrepancies.

Notably, on the Intercode dataset (Capture the Flag), the computer-use agent significantly outperforms the state-of-the-art method despite the latter (SWE-Agent-Enigma) employing numerous specialized tools for static analysis, dynamic analysis, and networking (See Table~\ref{tab:tool_comparison}). This improvement is statistically significant (p-value = 0.014, McNemar's test). While the agent did not rely on specific IDE tooling, this result highlights the advantages of a simple, general agent design and suggests the potential benefits of allowing agents to automatically identify optimal tools rather than imposing human priors on the system.

\input{tables/main_results}

\section{Additional Results}
\label{app:additional_results}

\input{tables/assisted_tools}

\paragraph{Training models to use IDE tools better would improve performance.}

In Section~\ref{sec:assisted_analysis}, we demonstrate that models can achieve superior performance when effectively utilizing IDE tools. However, our analysis reveals two primary limitations in current models' tool usage: (1) poor visual grounding and inability to handle complex tool interfaces, and (2) failure to prioritize IDE tool-based solutions over manual approaches.

To evaluate the second limitation specifically, we developed refactoring tasks within our `General-SWE' dataset. These tasks require agents to rename symbols across a project repository—an operation that cannot be reliably accomplished through simple search-and-replace due to potential naming conflicts and contextual variations. The IDE provides a robust solution through its rename feature, which leverages the complete AST to ensure accurate symbol renaming across the codebase. This operation requires only pressing F2 on a symbol and entering the new name. In our evaluation, the Claude agent initially achieved 0\% accuracy across four tasks when given no tool guidance. However, when explicitly prompted with "You can utilize the rename feature in VSCode to perform this task," its accuracy improved to 50\%.

We observed similar patterns across other tasks designed to evaluate tool usage. For instance, tasks that could be efficiently solved using the debugger showed limited success. While agents could sometimes set breakpoints, their poor visual grounding prevented them from effectively interpreting the debugging interface—particularly in understanding the current execution state and paused line location. These findings suggest significant potential for improving agent performance through better training on IDE tool utilization.

\paragraph{Successful Use of Tools}

We further show a couple of examples of successful tool use in Figure~\ref{fig:successful_tool_use-1}~\ref{fig:successful_tool_use-2}. However, we do note that while the agent is able to use the IDE tool through UI interaction, it still may not be able to make optimal use of it as shown in Figure~\ref{fig:chartmimic_example}.
