\section{RELATED WORK}
\label{sec:related}

% multivariate TSF
\paragraph{Multivariate time series forecasting.} Significant efforts have been dedicated to modeling and predicting sequential information using deep neural networks____. In particular, recurrent neural networks (RNNs) such as LSTM and GRU with their gating mechanisms obtained groundbreaking results on various vision and language tasks ____ across generative____ and augmentation____ tasks, among many others. Alas, not until recently, pure deep models were believed to be unable to outperform non-deep or hybrid tools____. Nevertheless, within a span of two years, pure deep methods based on RNNs____, feedforward networks____, and the Transformer____ have appeared, demonstrating competitive results and setting a new SOTA bar for long-term TSF.

Following these breakthroughs, numerous works have emerged, most of them are based on the Transformer architecture ____. Recently, a surprising work____ has shown remarkable TSF results with a simple single-layer linear model, competing and even surpassing the best models for that time. Notably, the linear model applied weights along the time axis, in contrast to the more conventional practice of applying weights along the variate axis. Subsequently, new SOTA techniques ____ and a recent foundation model for time series ____ have integrated a similar linear module as their final decoder to attain better forecasts.

%____. 

 % multi-task learning
\paragraph{Multi-task learning.} Improving learning on multiple tasks follows three different categories: \emph{gradient manipulation}, \emph{task grouping}, and \emph{architecture design}. Manipulating gradients is done by imposing weights____, shift gradient directions____, and add an optimization step to balance gradients or resolve conflicts____. In task grouping, previous works attempted to cluster different tasks based on similarity measures, thereafter assigning them to separate models____. Lastly, multiple forms of architecture design have been introduced to support MTL including hard-parameter sharing____, soft-parameter sharing____, and mixing solutions____. For time series data, a multi-gate mixture of experts for classification was suggested in____, whereas a soft-parameter sharing RNN-based model was proposed in____. However, most of the  multi-task techniques mentioned above focus mostly on vision problems. Consequently, little attention has been given to analyzing and mitigating the multi-task learning challenges for time series problems, particularly TSF.