% math
@book{boyd2004convex,
  title={Convex optimization},
  author={Boyd, Stephen and Vandenberghe, Lieven},
  year={2004},
  publisher={Cambridge university press}
}

% time series
@article{granger1969investigating,
  title={Investigating causal relations by econometric models and cross-spectral methods},
  author={Granger, Clive WJ},
  journal={Econometrica: journal of the Econometric Society},
  pages={424--438},
  year={1969},
  publisher={JSTOR}
}

@article{schreiber2000measuring,
  title={Measuring information transfer},
  author={Schreiber, Thomas},
  journal={Physical review letters},
  volume={85},
  number={2},
  pages={461},
  year={2000},
  publisher={APS}
}

@article{cohen2009pearson,
  title={Pearson correlation coefficient},
  author={Cohen, Israel and Huang, Yiteng and Chen, Jingdong and Benesty, Jacob and Benesty, Jacob and Chen, Jingdong and Huang, Yiteng and Cohen, Israel},
  journal={Noise reduction in speech processing},
  pages={1--4},
  year={2009},
  publisher={Springer}
}

% classic ML (clustering algorithm)
@book{hastie2009elements,
  title={The Elements of Statistical Learning: Data mining, Inference, and Prediction},
  author={Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome H and Friedman, Jerome H},
  volume={2},
  year={2009},
  publisher={Springer}
}


% deep learning
@article{hochreiter1997long,
  title={{Long Short-term Memory}},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  year={1997},
  publisher={MIT press}
}

@inproceedings{pascanu2013difficulty,
  title={On the difficulty of training recurrent neural networks},
  author={Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  booktitle={International conference on machine learning},
  pages={1310--1318},
  year={2013},
  organization={Pmlr}
}

@inproceedings{cho2014learning,
  author       = {Kyunghyun Cho and Bart van Merrienboer and {\c{C}}aglar G{\"{u}}l{\c{c}}ehre and Dzmitry Bahdanau and Fethi Bougares and Holger Schwenk and Yoshua Bengio},
  title        = {Learning Phrase Representations using {RNN} Encoder-Decoder for Statistical Machine Translation},
  booktitle    = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, {EMNLP}},
  pages        = {1724--1734},
  publisher    = {{ACL}},
  year         = {2014}
}

@book{goodfellow2016deep,
  title={{Deep Learning}},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT press}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{li2018visualizing,
  title={Visualizing the loss landscape of neural nets},
  author={Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{paszke2019pytorch,
  title={{PyTorch: An Imperative Style, High-Performance Deep Learning Library}},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

% TSF
@article{li2023revisiting,
  title={Revisiting long-term time series forecasting: An investigation on linear mapping},
  author={Li, Zhe and Qi, Shiyi and Li, Yiduo and Xu, Zenglin},
  journal={arXiv preprint arXiv:2305.10721},
  year={2023}
}

@article{liu2023itransformer,
  title={itransformer: Inverted transformers are effective for time series forecasting},
  author={Liu, Yong and Hu, Tengge and Zhang, Haoran and Wu, Haixu and Wang, Shiyu and Ma, Lintao and Long, Mingsheng},
  journal={arXiv preprint arXiv:2310.06625},
  year={2023}
}

@article{salinas2020deepar,
  title={{DeepAR: Probabilistic forecasting with autoregressive recurrent networks}},
  author={Salinas, David and Flunkert, Valentin and Gasthaus, Jan and Januschowski, Tim},
  journal={International Journal of Forecasting},
  volume={36},
  number={3},
  pages={1181--1191},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{oreshkin2020nbeats,
  author       = {Boris N. Oreshkin and Dmitri Carpov and Nicolas Chapados and Yoshua Bengio},
  title        = {{N-BEATS:} Neural basis expansion analysis for interpretable time series forecasting},
  booktitle    = {8th International Conference on Learning Representations, {ICLR}},
  year         = {2020}
}

@inproceedings{zhou2021informer,
  title={{Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting}},
  author={Zhou, Haoyi and Zhang, Shanghang and Peng, Jieqi and Zhang, Shuai and Li, Jianxin and Xiong, Hui and Zhang, Wancai},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  year={2021}
}

@article{wu2021autoformer,
  title={{Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting}},
  author={Wu, Haixu and Xu, Jiehui and Wang, Jianmin and Long, Mingsheng},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}


@inproceedings{zhou2022fedformer,
  title={{FEDformer: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting}},
  author={Zhou, Tian and Ma, Ziqing and Wen, Qingsong and Wang, Xue and Sun, Liang and Jin, Rong},
  booktitle={International Conference on Machine Learning},
  year={2022},
  organization={PMLR}
}

@inproceedings{zhang2022crossformer,
  title={{Crossformer: Transformer Utilizing Cross-Dimension Dependency for Multivariate Time Series Forecasting}},
  author={Zhang, Yunhao and Yan, Junchi},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}


@inproceedings{zeng2023transformers,
  title={Are transformers effective for time series forecasting?},
  author={Zeng, Ailing and Chen, Muxi and Zhang, Lei and Xu, Qiang},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={37},
  pages={11121--11128},
  year={2023}
} % number={9},

@inproceedings{nie2023time,
  author       = {Yuqi Nie and Nam H. Nguyen and Phanwadee Sinthong and Jayant Kalagnanam},
  title        = {{A Time Series is Worth 64 Words: Long-term Forecasting with Transformers}},
  booktitle    = {The Eleventh International Conference on Learning Representations, {ICLR}},
  year         = {2023}
}

@article{xue2023make,
  title={Make Transformer Great Again for Time Series Forecasting: Channel Aligned Robust Dual Transformer},
  author={Xue, Wang and Zhou, Tian and Wen, QingSong and Gao, Jinyang and Ding, Bolin and Jin, Rong},
  journal={arXiv preprint arXiv:2305.12095},
  year={2023}
}

% foundation models
@article{zhou2023one,
  title={One fits all: Power general time series analysis by pretrained lm},
  author={Zhou, Tian and Niu, Peisong and Sun, Liang and Jin, Rong and others},
  journal={Advances in neural information processing systems},
  volume={36},
  pages={43322--43355},
  year={2023}
}

@article{jin2023time,
  title={{LLM4TS: Aligning Pre-Trained LLMs as Data-Efficient Time-Series Forecasters}},
  author={Chang, Ching and Wang, Wei-Yao and Peng, Wen-Chih and Chen, Tien-Fu},
  journal={arXiv preprint arXiv:2308.08469},
  year={2023}
}

% multi-task learning
@inproceedings{misra2016cross,
  title={Cross-stitch networks for multi-task learning},
  author={Misra, Ishan and Shrivastava, Abhinav and Gupta, Abhinav and Hebert, Martial},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3994--4003},
  year={2016}
}

@inproceedings{ma2018modeling,
  title={Modeling task relationships in multi-task learning with multi-gate mixture-of-experts},
  author={Ma, Jiaqi and Zhao, Zhe and Yi, Xinyang and Chen, Jilin and Hong, Lichan and Chi, Ed H},
  booktitle={Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery \& data mining},
  pages={1930--1939},
  year={2018}
}

@inproceedings{chen2018gradnorm,
  title={Gradnorm: Gradient normalization for adaptive loss balancing in deep multitask networks},
  author={Chen, Zhao and Badrinarayanan, Vijay and Lee, Chen-Yu and Rabinovich, Andrew},
  booktitle={International conference on machine learning},
  pages={794--803},
  year={2018},
  organization={PMLR}
}

@article{sener2018multi,
  title={Multi-task learning as multi-objective optimization},
  author={Sener, Ozan and Koltun, Vladlen},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{zamir2018taskonomy,
  title={Taskonomy: Disentangling task transfer learning},
  author={Zamir, Amir R and Sax, Alexander and Shen, William and Guibas, Leonidas J and Malik, Jitendra and Savarese, Silvio},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3712--3722},
  year={2018}
}

@article{yu2020gradient,
  title={{Gradient Surgery for Multi-Task Learning}},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

@inproceedings{groenendijk2020multi,
  title={{Multi-Loss Weighting with Coefficient of Variations}},
  author={Groenendijk, Rick and Karaoglu, Sezer and Gevers, Theo and Mensink, Thomas},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={1469--1478},
  year={2020}
}

@inproceedings{standley2020tasks,
  title={Which tasks should be learned together in multi-task learning?},
  author={Standley, Trevor and Zamir, Amir and Chen, Dawn and Guibas, Leonidas and Malik, Jitendra and Savarese, Silvio},
  booktitle={International Conference on Machine Learning},
  pages={9120--9132},
  year={2020},
  organization={PMLR}
}

@inproceedings{ishihara2021multi,
  title={Multi-task learning with attention for end-to-end autonomous driving},
  author={Ishihara, Keishi and Kanervisto, Anssi and Miura, Jun and Hautamaki, Ville},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2902--2911},
  year={2021}
}

@article{fifty2021efficiently,
  title={{Efficiently Identifying Task Groupings for Multi-Task Learning}},
  author={Fifty, Chris and Amid, Ehsan and Zhao, Zhe and Yu, Tianhe and Anil, Rohan and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}

@article{zhang2021survey,
  title={A survey on multi-task learning},
  author={Zhang, Yu and Yang, Qiang},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={34},
  number={12},
  pages={5586--5609},
  year={2021},
  publisher={IEEE}
}

@article{liu2021conflict,
  title={{Conflict-Averse Gradient Descent for Multi-task Learning}},
  author={Liu, Bo and Liu, Xingchao and Jin, Xiaojie and Stone, Peter and Liu, Qiang},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}

@article{vandenhende2021multi,
  title={Multi-task learning for dense prediction tasks: A survey},
  author={Vandenhende, Simon and Georgoulis, Stamatios and Van Gansbeke, Wouter and Proesmans, Marc and Dai, Dengxin and Van Gool, Luc},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={44},
  number={7},
  pages={3614--3633},
  year={2021},
  publisher={IEEE}
}

@inproceedings{navon2022multi,
  author       = {Aviv Navon and Aviv Shamsian and Idan Achituve and Haggai Maron and Kenji Kawaguchi and Gal Chechik and Ethan Fetaya},
  title        = {Multi-Task Learning as a Bargaining Game},
  booktitle    = {International Conference on Machine Learning, {ICML}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {162},
  pages        = {16428--16446},
  publisher    = {{PMLR}},
  year         = {2022}
}

@article{song2022efficient,
  title={{Efficient and Effective Multi-task Grouping via Meta Learning on Task Combinations}},
  author={Song, Xiaozhuang and Zheng, Shun and Cao, Wei and Yu, James and Bian, Jiang},
  journal={Advances in Neural Information Processing Systems},
  year={2022}
}

@inproceedings{chen2020multi,
  title={Multi-Task Time Series Forecasting With Shared Attention},
  author={Chen, Zekai and Jiaze, E and Zhang, Xiao and Sheng, Hao and Cheng, Xiuzheng},
  booktitle={2020 International Conference on Data Mining Workshops (ICDMW)},
  pages={917--925},
  year={2020},
  organization={IEEE}
}

@inproceedings{guangyuan2022recon,
  title={{Recon: Reducing Conflicting Gradients From the Root For Multi-Task Learning}},
  author={Guangyuan, SHI and Li, Qimai and Zhang, Wenlong and Chen, Jiaxin and Wu, Xiao-Ming},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}







@article{olivares2023neural,
  title={{Neural basis expansion analysis with exogenous variables: Forecasting electricity prices with NBEATSx}},
  author={Olivares, Kin G and Challu, Cristian and Marcjasz, Grzegorz and Weron, Rafa{\l} and Dubrawski, Artur},
  journal={International Journal of Forecasting},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{challu2023nhits,
  title={{N-HiTS: Neural Hierarchical Interpolation for Time Series Forecasting}},
  author={Challu, Cristian and Olivares, Kin G and Oreshkin, Boris N and Ramirez, Federico Garza and Canseco, Max Mergenthaler and Dubrawski, Artur},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2023}
}


% rev refs
@inproceedings{kaufman2023data,
  title={Data representations’ study of latent image manifolds},
  author={Kaufman, Ilya and Azencot, Omri},
  booktitle={International Conference on Machine Learning},
  pages={15928--15945},
  year={2023},
  organization={PMLR}
}

@inproceedings{kaufman2024first,
  author       = {Ilya Kaufman and Omri Azencot},
  title        = {First-Order Manifold Data Augmentation for Regression Learning},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML}},
  year         = {2024}
}

@article{nochumsohn2024beyond,
  title={Beyond Data Scarcity: A Frequency-Driven Framework for Zero-Shot Forecasting},
  author={Nochumsohn, Liran and Moshkovitz, Michal and Avner, Orly and Di Castro, Dotan and Azencot, Omri},
  journal={arXiv preprint arXiv:2411.15743},
  year={2024}
}

@article{kaufman2024geometric,
  title={Analyzing Deep Transformer Models for Time Series Forecasting via Manifold Learning},
  author={Ilya Kaufman and Omri Azencot},
  journal={Transactions on Machine Learning Research, {TMLR}},
  year={2024}
} 

@inproceedings{naiman2024generative,
  author       = {Ilan Naiman and N. Benjamin Erichson and Pu Ren and Michael W. Mahoney and Omri Azencot},
  title        = {Generative Modeling of Regular and Irregular Time Series Data via
                  Koopman VAEs},
  booktitle    = {The Twelfth International Conference on Learning Representations,{ICLR}},
  year         = {2024}
}

@article{naiman2024utilizing,
  title={Utilizing Image Transforms and Diffusion Models for Generative Modeling of Short and Long Time Series},
  author={Ilan Naiman and Nimrod Berman and Itai Pemper and Idan Arbiv and Gal Fadlon and Omri Azencot},
  journal={Advances in Neural Information Processing Systems},
  year={2024}
} 

@article{ren2024learning,
  title={Learning physics for unveiling hidden earthquake ground motions via conditional generative modeling},
  author={Ren, Pu and Nakata, Rie and Lacour, Maxime and Naiman, Ilan and Nakata, Nori and Song, Jialin and Bi, Zhengfa and Malik, Osman Asif and Morozov, Dmitriy and Azencot, Omri and others},
  journal={arXiv preprint arXiv:2407.15089},
  year={2024}
}



