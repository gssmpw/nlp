\section{Experiments}
In this section, we empirically verify the effectiveness of our hyperparameter selection method.

We focus on our GCAN architecture, aiming to demonstrate our approach's effectiveness for selecting algorithm hyperparameters in our setup. To illustrate this, we compare the performance of GCAN with tuned hyperparameters against GAT and GCN.

For each dataset, we sample 20 random sub-graphs of 100 nodes to learn the optimal hyperparameter $\eta$ via backpropagation. A large disconnected graph is formed by combining these sub-graphs, allowing parameter values to vary across graphs while sharing a unified learnable $\eta$. The optimized hyperparameter is then tested on another 20 test sub-graphs from the same dataset.

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.99\linewidth]{fig/GCAN_learned_eta.png}
    \caption{Validation Accuracy (computed on the unlabeled nodes across 20 testing graphs) vs. iterations. GCAN competes with the better accuracy between GAT and GCN across datasets. }
    \label{fig:gcan_multi}
\end{figure*}

The results are shown in \Cref{fig:gcan_multi}. Note that GCN outperforms GAT on some datasets (e.g.\ CORA, Actor) and GAT performs better on others (e.g.\ CIFAR10, see also \cite{dwivedi2023benchmarking}). With GCAN, we can achieve the best performance on each dataset--in \Cref{fig:gcan_multi}, GCAN consistently achieves higher or comparable accuracy compared to both GAT and GCN across all datasets. Notably, GCAN demonstrates significant improvements in CIFAR10 and CORA, highlighting its effectiveness in these scenarios. 

% Additional experiments are located in the Appendix.
In \Cref{appendix:experiments}, we also conduct experiments to empirically verify the results in \Cref{sec:label_prop}. We show that by selecting the number of problem instances $m = O(\log n / \epsilon^2)$, the empirical generalization error is within $O(\epsilon)$, matching our theoretical results. We also have further details on the empirical setup and the variation of the accuracy of GCAN with the hyperparameter $\eta$ in the Appendix. 