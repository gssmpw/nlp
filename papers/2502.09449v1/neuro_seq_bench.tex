\documentclass[journal]{IEEEtran}
\usepackage{amsmath, amsfonts}
\allowdisplaybreaks

\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{cite}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
% updated with editorial comments 8/9/2021

\usepackage{multirow, booktabs}
\usepackage{graphicx}
\usepackage{xcolor}
\newcommand\cx{\textcolor{blue}}
\newcommand\xy{\textcolor{red}}
\newcommand\yc{\textcolor{green}}
\newcommand\yj{\textcolor{red}}
\usepackage[normalem]{ulem}
\useunder{\uline}{\ul}{}
\usepackage{amssymb}
\usepackage[hidelinks]{hyperref}
\usepackage{threeparttable}
\usepackage{makecell}
\usepackage{newtxtext,newtxmath}
\usepackage{siunitx}
\usepackage{todonotes}

\begin{document}
\title{Spiking Neural Networks for Temporal Processing: Status Quo and Future Prospects}

\author{ Chenxiang~Ma{*}, Xinyi Chen{*}, Yanchen Li{*}, Qu Yang, Yujie~Wu, Guoqi~Li,~\IEEEmembership{Member,~IEEE}, Gang~Pan,~\IEEEmembership{Senior Member,~IEEE}, Huajin~Tang,~\IEEEmembership{Senior~Member,~IEEE}, Kay~Chen~Tan,~\IEEEmembership{Fellow,~IEEE}, Jibin~Wu,~\IEEEmembership{Member,~IEEE}
\IEEEcompsocitemizethanks{
\IEEEcompsocthanksitem  *Chenxiang~Ma, Xinyi~Chen, and Yanchen~Li contributed equally to this article. Corresponding Author: Jibin~Wu (jibin.wu@polyu.edu.hk)
% \IEEEcompsocthanksitem Y.~Wu is with the Department of Computing, The Hong Kong Polytechnic University, Hong Kong SAR.
\IEEEcompsocthanksitem{Chenxiang~Ma, Xinyi~Chen, Yanchen~Li, Kay Chen Tan, and Jibin Wu are with the Department of Data Science and Artificial Intelligence, The Hong Kong Polytechnic University, Hong Kong SAR. Jibin Wu is also with the Department of Computing, The Hong Kong Polytechnic University, Hong Kong SAR}
\IEEEcompsocthanksitem{Qu Yang is with the Department of Electrical and Computer Engineering, National University of Singapore, Singapore 119077}
\IEEEcompsocthanksitem{Yujie Wu is with the Department of Computing, The Hong Kong Polytechnic University, Hong Kong SAR}
\IEEEcompsocthanksitem{Guoqi Li is with the Institute of Automation, Chinese Academy of Sciences, Beijing 100045, China}
\IEEEcompsocthanksitem{Gang Pan and Huajin Tang are with the State Key Laboratory of Brain-Machine Intelligence, College of Computer Science and Technology, MOE Frontier Science Center for Brain Science and Brain-Machine Integration, Zhejiang University, Hangzhou 310027, China}

% \IEEEcompsocthanksitem{J.~Wu is with the Department of Data Science and Artificial Intelligence, and Department of Computing, The Hong Kong Polytechnic University, Hong Kong SAR.}
}
}

\maketitle

\begin{abstract}
Temporal processing is fundamental for both biological and artificial intelligence systems, as it enables the comprehension of dynamic environments and facilitates timely responses. Spiking Neural Networks (SNNs) excel in handling such data with high efficiency, owing to their rich neuronal dynamics and sparse activity patterns. Given the recent surge in the development of SNNs, there is an urgent need for a comprehensive evaluation of their temporal processing capabilities. In this paper, we first conduct an in-depth assessment of commonly used neuromorphic benchmarks, revealing critical limitations in their ability to evaluate the temporal processing capabilities of SNNs. To bridge this gap, we further introduce a benchmark suite consisting of three temporal processing tasks characterized by rich temporal dynamics across multiple timescales. Utilizing this benchmark suite, we perform a thorough evaluation of recently introduced SNN approaches to elucidate the current status of SNNs in temporal processing. Our findings indicate significant advancements in recently developed spiking neuron models and neural architectures regarding their temporal processing capabilities, while also highlighting a performance gap in handling long-range dependencies when compared to state-of-the-art non-spiking models. Finally, we discuss the key challenges and outline potential avenues for future research.
\end{abstract}

\begin{IEEEkeywords}
 Spiking Neural Networks, Temporal Processing, Neuromorphic Benchmarks, Neuromorphic Computing
\end{IEEEkeywords}

\section{Introduction}
\IEEEPARstart{T}{emporal} processing is a fundamental capability that enables animals to perceive, plan, and act within dynamic environments. To effectively analyze and understand temporal data, a variety of models have been developed based on artificial neural networks (ANNs), such as Recurrent Neural Networks (RNNs)~\cite{RNN,LSTM}, Temporal Convolutional Networks (TCNs)~\cite{TCN}, Transformers~\cite{transformer}, and State Space Models~(SSMs)~\cite{SSM}. Despite their impressive performance in processing temporal data, these models often demand significant computational resources, which can limit their deployment on resource-constrained platforms~\cite{9043731}.

%\cite{event-basedvisionsurvey,wu2020deep,wu2018spiking}.
 
In contrast, Spiking Neural Networks (SNNs)~\cite{maass1997networks}, inspired by the computational principles of biological neural networks, offer an energy-efficient computational framework for temporal processing~\cite{10636118}. By employing a sparse spike-based representation, SNNs enable efficient event-driven computation, wherein spiking neurons activate solely in response to incoming spikes~\cite{roy2019towards,rapid2013}. This characteristic is particularly advantageous when implemented on neuromorphic chips~\cite{davies2018loihi,pei2019towards,ma2017darwin,Darwin3,yao2024nc}, where SNNs have demonstrated significantly enhanced energy efficiency compared to traditional ANNs~\cite{10.1162/neco_a_01245}. Beyond their energy efficiency, spiking neurons inherently function as stateful models, characterized by rich neuronal dynamics that arise from complex morphology, variations in ionic conductance, and the distribution of synaptic inputs~\cite{herz2006modeling}. These features endow SNNs with significant potential for representing and processing temporal data~\cite{wu2020deep,wu2018spiking,sequence2016}.

Recently, numerous approaches have been developed to enhance training efficiency~\cite{ptl,NEURIPS2022_523caec7,10254579,Xu_2023_CVPR,deng2022temporal,imloss,ijcai2023p335,zhu2024online,jiang2024ndot,shen2024rethinking} and representation power of SNNs~\cite{hybridcoding,attentionsnns,NEURIPS2023_b8734840,9328792,ternarySpike2024,xing2024spikelm,hu2024toward}. Despite these advancements, a clear consensus on how to evaluate these approaches in the context of temporal processing remains elusive. Additionally, the lack of standardized training and evaluation configurations across these studies complicates fair comparisons.
These challenges collectively impede the progress of the field and limit the real-world applicability of SNNs.
In this paper, we seek to address these issues by establishing a comprehensive evaluation benchmark specifically focused on temporal processing capabilities. Furthermore, we will assess existing approaches to elucidate the current state of the field and identify potential future research directions. An overview of the paper's structure is presented in Fig.~\ref{Fig:overview}.

Benchmarks are essential in Artificial Intelligence research, as they provide standardized datasets and evaluation metrics that facilitate consistent performance comparison, track progress, and promote reproducibility. Currently, the benchmarks commonly employed for SNN evaluation can be categorized into three groups. The first category comprises static image recognition datasets~\cite{lecun1998gradient, krizhevsky2009learning}, which require the conversion of static images into sequences, typically by replicating images along the time axis~\cite{eshraghian2023training}. The second category encompasses event-based vision datasets generated using neuromorphic sensors, such as Dynamic Vision Sensor (DVS) cameras. Some of these datasets are created by imposing artificial saccadic motion on static images~\cite{orchard2015converting, li2017cifar10}, while others directly capture real-world moving objects using DVS cameras~\cite{amir2017low,zhou2024enhancing}. The third category consists of audio classification datasets, which are either created using the original audio signals~\cite{warden2018speech,TIMIT} or converted into spike-based representations using biologically inspired encoding methods~\cite{pan2020efficient,cramer2020heidelberg}. While these benchmarks have significantly advanced neuromorphic computing research over the past decade~\cite{10636118,eshraghian2023training}, their effectiveness in evaluating the temporal processing capability remains unclear, potentially leading to inaccurate assessments and misleading conclusions. 

\begin{figure*}[!t]
\centering\includegraphics[width=0.95\linewidth]{figs/overview-v2.pdf}
\caption{(a) Overview of the paper organization. In Section~\ref{sec:STP}, we propose the Segregated Temporal Probe (STP) analytical tool for assessing the effectiveness of neuromorphic benchmarks in evaluating the temporal processing capabilities of SNN. In Section~\ref{sec:eval_bench}, using the STP, we discover that commonly used neuromorphic benchmarks are ineffective for assessing temporal processing performance. Then, we introduce a suite of temporal processing benchmarks in Section~\ref{sec:benchmark}. Based on this suite, we conduct a comprehensive benchmarking study to reveal the current status of SNNs for temporal processing in Section~\ref{sec:benchmarking}. Finally, we discuss key challenges and outline future directions in Section~\ref{sec:challenges}. (b) Illustration of the proposed STP. STP incorporates three algorithms (STBP, SDBP, and NoTD) that systematically disrupts the temporal processing pathways within an SNN to elucidate their significance. }
\label{Fig:overview}
\end{figure*}


To address this issue, we propose an analytical tool called the Segregated Temporal Probe (STP),  designed to evaluate the effectiveness of a benchmark dataset in assessing the temporal processing capabilities of SNNs. Specifically, STP incorporates three learning algorithms: Spatio-Temporal Backpropagation (STBP)~\cite{wu2018spatio}, Spatial Domain Backpropagation (SDBP), and No Temporal Domain~(NoTD). These algorithms systematically disrupt the temporal processing pathways within an SNN to elucidate their significance. In particular, STBP preserves the full temporal processing pathways of the SNN during both forward and backward passes, whereas SDBP stops gradient propagation along the temporal domain during the backward pass. In contrast, NoTD stops the propagation of information along the temporal domain during both passes, effectively treating each time step independently.

By applying STP to widely adopted neuromorphic benchmark datasets, we find that NoTD achieves performance comparable to STBP on static image recognition~\cite{lecun1998gradient, krizhevsky2009learning} and event-based vision datasets~\cite{orchard2015converting, li2017cifar10,amir2017low}. This finding suggests that these datasets can be effectively processed without relying on temporal processing capabilities of SNN models. For audio classification datasets~\cite{warden2018speech,cramer2020heidelberg,TIMIT}, both SDBP and STBP obtain similar performance, suggesting that temporal credit assignment during the backward pass is not necessary for these datasets. Consequently, these existing benchmark datasets do not adequately evaluate the temporal processing capability of SNNs. 


To bridge this gap and elucidate the status quo of the temporal processing capabilities of existing SNN approaches, we introduce a benchmark suite encompassing three temporal processing tasks characterized by rich temporal dynamics. Subsequently, we conduct a comprehensive evaluation of over thirty SNN approaches using this benchmark suite. Our benchmarking study reveals three significant findings that have not been previously reported: (1) Online learning algorithms~\cite{xiao2022online,meng2023towards}, which claim performance comparable to or even superior to STBP, often yield less competitive results on temporal processing tasks. This indicates that the omitted temporal gradients are crucial for learning temporal dependencies within such data. (2) Surrogate gradient functions~\cite{neftci2019surrogate} with smoother curves and reduced gradient mismatching, such as Triangle~\cite{deng2022temporal} and Sigmoid~\cite{adLIF}, prove to be more effective for temporal processing tasks. (3) Recent advancements in spiking neuron models that incorporate strategies such as additional memory states~\cite{TCLIF,LMH}, heterogeneous neuron parameters~\cite{PLIF,GLIF}, and enriched recurrent neuron dynamics~\cite{PMSN, ltc,dhsnn} demonstrate significant improvements over the simplified Leaky Integrated-and-Fire~(LIF) model~\cite{lif} in temporal processing. However, despite their considerable energy efficiency, these state-of-the-art (SOTA) SNN models still lag behind ANN models~\cite{LSTM,SSM} in their ability to model long-range temporal dependencies. 


Our major contributions in this work are summarized as follows: 
%\todo{please check if I change the original meanings}
\begin{itemize}
\item We propose an analytical tool, STP, for evaluating the effectiveness of neuromorphic benchmarks in assessing temporal processing capabilities. This tool facilitates the development of neuromorphic benchmarks specifically tailored for temporal processing.
\item We identify critical limitations in existing neuromorphic benchmarks regarding their evaluation of temporal processing capabilities and propose a new benchmark suite explicitly designed for this purpose. 
\item We conduct a comprehensive benchmarking study of over thirty SNN approaches to elucidate the current state of the field.
\item We develop an open-sourced library\footnote{Code is publicly available at \url{https://github.com/liyc5929/neuroseqbench}.} for neuromorphic temporal processing, which enables consistent performance comparisons across different approaches and facilitates the tracking of advancements in the field.
\end{itemize}



The remainder of this paper is organized as follows. Section~\ref{sec:STP} introduces the proposed STP tool, which is utilized to evaluate existing neuromorphic benchmarks for temporal processing in Section~\ref{sec:eval_bench}.  Section~\ref{sec:benchmark} presents a novel neuromorphic benchmark suite specifically designed for temporal processing. Subsequently, we conduct a comprehensive evaluation of over thirty SNN approaches in Section~\ref{sec:benchmarking} to elucidate the current state of the field. Section~\ref{sec:challenges} discusses key challenges and outlines potential future research directions. Finally, we conclude the paper in Section~\ref{sec:conclusion}.



\begin{figure}[!t]
\centering\includegraphics[width=0.9\linewidth]{figs/illustration_samples.pdf}
\caption{Visualization of samples in neuromorphic benchmarks. (a) Samples from event-based vision datasets: N-MNIST, CIFAR10-DVS, and DvsGesture (from top to bottom). (b) Samples from neuromorphic audio datasets: SHD (top) and SSC (bottom).}
\label{Fig:illustration_samples}
\end{figure}


\begin{figure}[!t]
\centering\includegraphics[width=0.96\linewidth, trim = 0 0 0 0, clip]{./figs/stbp_sdbp_notd.pdf}
\caption{Comparison of the computational graphs for three algorithms utilized in the STP. Forward and backward passes are denoted by black and red arrows, respectively.} 
\label{fig:stp}
\end{figure}


\section{Segregated Temporal Probe (STP)}
\label{sec:STP}

While existing neuromorphic benchmarks have significantly advanced the field of neuromorphic computing~\cite{10636118,eshraghian2023training}, it remains unclear whether these benchmarks effectively evaluate critical temporal information. 
This uncertainty is particularly evident in benchmarks adapted from static datasets~\cite{orchard2015converting, li2017cifar10}, where objects in individual frames often provide sufficient information for classification, as illustrated in Fig.~\ref{Fig:illustration_samples}(a). Consequently, we are motivated to explicitly analyze whether temporal processing capability is genuinely critical for achieving high performance on these benchmarks. To this end, we introduce the STP, which disrupts the temporal processing pathways within an SNN to elucidate their significance. 


As illustrated in Fig.~\ref{Fig:overview}(b), the STP tool comprises three learning algorithms: STBP~\cite{wu2018spatio}, SDBP, and NoTD. STBP serves as the baseline, retaining the entire temporal processing pathways, including both the forward pass of activation values and the backward pass of error gradients across time. In contrast, SDBP is designed to disrupt temporal processing during the backward pass while preserving it in the forward pass. NoTD, on the other hand, eliminates temporal processing entirely by processing each frame independently at each time step. In the following, we will use the LIF neuron model as an example to illustrate these algorithms. Fig.~\ref{fig:stp} provides a visualization that highlights the differences in the 
forward and backward passes of each algorithm. 

\paragraph{LIF Neuron Model} The LIF neuron model~\cite{lif} is one of the most widely used spiking neuron models due to its simplicity and analytical tractability~\cite{10636118}. As described in Eqs.~\eqref{eq:mem_update}--\eqref{eq:firing}, LIF neurons capture the dynamics of membrane potential, which continuously integrates input spikes from preceding neurons. When the membrane potential exceeds a specified firing threshold, a spike is generated, followed by a reset of the membrane potential to its resting state. 
\begin{align}
\boldsymbol{u}^{l}[t] &= \underbrace{\lambda \cdot \boldsymbol{u}^{l}[t - 1] \cdot (1 - \boldsymbol{s}^{l}[t-1])}_{\text{temporal processing}} +\, \boldsymbol{W}^{l} \cdot \boldsymbol{s}^{l-1}[t], \label{eq:mem_update}\\
\boldsymbol{s}^{l}[t]  &= \Theta (\boldsymbol{u}^{l}[t] - V_{\text{th}}), \\[0.7ex]
\Theta(x)&=\begin{cases}1, & x \geq 0, \\[0.5ex]
                        0, & \text{otherwise,}\end{cases}
\label{eq:firing}
\end{align}
where $\boldsymbol{u}^{l}[t]$ represents the membrane potential in layer $l$ at time step~$t$, $\lambda$ denotes a decay factor that determines the rate at which the membrane potential decays over time, and $\boldsymbol{s}^{l-1}[t]$ represents input spikes from the previous layer. $\boldsymbol{W}^{l}$ is the weight matrix, $\Theta(x)$ is the Heaviside step function, and $V_{\text{th}}$ denotes the firing threshold. The resting potential is typically set to zero in practice. 



\paragraph{STBP} STBP is a gradient-based learning algorithm specifically designed for SNNs~\cite{wu2018spatio}. After input spikes are propagated to the output layer $L$, a loss $\mathcal{L}$ is calculated by comparing the predictions with the target values. The backward pass then initiates, calculating the gradient of the loss with respect to each model parameter. By employing the chain rule, the gradient of the loss with respect to the weights of layer $l$ can be computed as follows:
\begin{align}
\!\frac{\partial \mathcal{L}}{\partial \boldsymbol{W}^{l}} &= \sum_{t=1}^{T}\frac{\partial \mathcal{L}}{\partial \boldsymbol{u}^{l}[t]} \cdot \frac{\partial \boldsymbol{u}^{l}[t]}{\partial \boldsymbol{W}^{l}} = \sum_{t=1}^{T}{\boldsymbol{\delta}^{l}[t]}^{\!\top} \cdot {\boldsymbol{s}^{l-1}[t]}^{\!\top}, \label{eq:weight}
\\[1.5ex]
\boldsymbol{\delta}^{l}[t]\!&=\!\begin{cases} 
\frac{\partial \mathcal{L}}{\partial \boldsymbol{u}^L[T]},  &l\!=\!L~\text{and}~t\!=\!T, \\[1.5ex] 
\boldsymbol{\delta}^{L}[t\!+\!1] \!\cdot\! \frac{\partial \boldsymbol{u}^{L}[t+1]}{\partial \boldsymbol{u}^{L}[t]}+\frac{\partial \mathcal{L}}{\partial \boldsymbol{u}^L[t]},  &l\!=\!L~\text{and}~t\!<\!T, \\[1.5ex] 
\boldsymbol{\delta}^{l+1}[T] \!\cdot\! \frac{\partial \boldsymbol{u}^{l+1}[T]}{\partial \boldsymbol{s}^{l}[T]} \!\cdot\! \frac{\partial \boldsymbol{s}^{l}[T]}{\partial \boldsymbol{u}^{l}[T]},  &l\!<\!L~\text{and}~t\!=\!T, \\[1.5ex] 
\boldsymbol{\delta}^{l}\![t\!+\!1]\frac{\partial \boldsymbol{u}^{l}\![t+1]}{\partial \boldsymbol{u}^{l}\![t]} + \boldsymbol{\delta}^{l+1}\![t] \frac{\partial \boldsymbol{u}^{l+1}\![t]}{\partial \boldsymbol{u}^{l}\![t]},\!\!\!&\!\text{otherwise,}\! \end{cases}
\label{eq:grad_m}
\end{align}
where $\boldsymbol{\delta}^{l}[t]\triangleq\frac{\partial \mathcal{L}}{\partial \boldsymbol{u}^{l}[t]}$, represents the error back-propagated from the last layer and the last time step. $T$ denotes the total number of time steps. The Heaviside step function is non-differentiable since its gradient, i.e., $\frac{\partial \boldsymbol{s}_{i}^{l}[t]}{\partial \boldsymbol{u}_{i}^{l}[t]}$, is zero except at the point where $\boldsymbol{u}_{i}^{l}[t]=V_{\text{th}}$, where it becomes infinite. To address this issue, a continuous surrogate gradient function~\cite{neftci2019surrogate} is often adopted to replace the non-differentiable Heaviside step function during the backward pass, as denoted by $\frac{\partial \boldsymbol{s}_i^{l}[t]}{\partial \boldsymbol{u}_i^{l}[t]} \approx \mathbb{H}\!\left(\boldsymbol{u}_i^{l}[t]\right)$.

\paragraph{SDBP} To illustrate SDBP, we begin by explicitly detailing the gradients associated with the temporal processing function. This is achieved by rewriting the error term $\boldsymbol{\delta}^{l}[t]$ under the general condition~($l<L~\text{and}~t<T$):
\begin{align}
\boldsymbol{\delta}^{l}[t] &= \boldsymbol{\delta}^{l+1}[t] \cdot \frac{\partial \boldsymbol{u}^{l+1}[t]}{\partial \boldsymbol{s}^{l}[t]} \cdot \frac{\partial \boldsymbol{s}^{l}[t]}{\partial \boldsymbol{u}^{l}[t]}\nonumber\\
&\phantom{=} + \underbrace{\sum_{t^\prime=t+1}^T
\boldsymbol{\delta}^{l+1}[t^{\prime}] \cdot \frac{\partial \boldsymbol{u}{^{l+1}}[t^\prime]}{\partial \boldsymbol{u}{^{l}}[t^\prime]} \cdot \frac{\partial \boldsymbol{u}{^{l}}[t^\prime]}{\partial \boldsymbol{u}{^{l}}[t]}}_{\text{temporal processing gradients}},
\label{eq:td_grad_m}
\end{align}
where the gradient at the current time step $t$ is influenced by a sum of the gradients from all subsequent time steps. This stems from the temporal processing function in Eq.~\eqref{eq:mem_update}. More concretely, the membrane potential at the current time step $t$ implicitly contributes to all membrane potentials at the subsequent time steps due to the decay and resetting processes over time. Accordingly, the errors at all subsequent steps need to be included in the computation of the error in the time $t$. 

SDBP keeps the same temporal processing function in the forward pass as STBP but omits it in the backward pass. Consequently, error signals generated at a given time step cannot be propagated back to previous time steps, limiting the use of error information to refine earlier predictions.  Formally, let  $\boldsymbol{\epsilon}^{l}[t]$ represent $\frac{\partial \mathcal{L}}{\partial \boldsymbol{u}^{l}[t]}$ in SDBP, the weight gradient at the layer $l$ is given by
\begin{align}
\nabla_{\boldsymbol{W}^{l}}\mathcal{L} &= \sum_{t=1}^T{\boldsymbol{\epsilon}^l[t]}^{\!\top} \cdot \frac{\partial \boldsymbol{u}^{l}[t]}{\partial\boldsymbol{W}^{l}} = \sum_{t=1}^T{\boldsymbol{\epsilon}^l[t]}^{\!\top} \cdot {\boldsymbol{s}^{l-1}[t]}^{\!\top},
\label{eq:tlg} 
\\[1.5ex]
\boldsymbol{\epsilon}^l[t] &= \begin{cases} 
\frac{\partial \mathcal{L}}{\partial \boldsymbol{u}^L[t]},  &l\!=\!L,\\[1.5ex] 
\boldsymbol{\epsilon}^{l+1}[t] \cdot \frac{\partial \boldsymbol{u}^{l+1}[t]}{\partial \boldsymbol{u}^{l}[t]},  &l\!<\!L.
\end{cases}
\label{eq:tlg2}
\end{align}



%\linespread{1.}
\begin{table}[!t]
\centering
\caption{Evaluation results of widely-used neuromorphic benchmarks. ``Acc." stands for ``accuracy".}
\setlength{\tabcolsep}{1.5mm}
%\resizebox{\textwidth}{!}{%
\begin{tabular}{l|c|ccc}
\hline
\textbf{Dataset} & \textbf{Time Step} (\(T\))   & \textbf{Method} & \textbf{Acc.} & \(\Delta\)\textbf{Acc.} \\ \hline
\multirow{3}{*}{MNIST~\cite{lecun1998gradient}} & \multirow{3}{*}{10}      & STBP   & 99.40    &  -      \\
                             && SDBP   & 99.27    & -0.13  \\
                             && NoTD   & 99.18    & -0.22  \\ \hline
\multirow{3}{*}{CIFAR10~\cite{krizhevsky2009learning}} & \multirow{3}{*}{4}     & STBP   & 94.86    & -       \\
                             && SDBP   & 94.74    & -0.12  \\
                             && NoTD   & 93.46    & -1.40  \\ \hline
\multirow{3}{*}{CIFAR100~\cite{krizhevsky2009learning}} & \multirow{3}{*}{4}     & STBP   & 74.57    & -       \\
                             && SDBP   & 74.35    & -0.22  \\
                             && NoTD   & 73.28    & -1.29  \\ \hline
\multirow{3}{*}{N-MNIST~\cite{orchard2015converting}} & \multirow{3}{*}{300}   & STBP   &  99.49   &  -      \\
                            & & SDBP   &  99.48   &  -0.01 \\
                            & & NoTD   &  99.09   &  -0.40 \\ \hline
\multirow{3}{*}{CIFAR10-DVS~\cite{li2017cifar10}}& \multirow{3}{*}{10}& STBP    &  78.50   &  -      \\
                             && SDBP   &  79.00   &  +0.50 \\
                             && NoTD   &  80.00   &  +1.50 \\ \hline
\multirow{3}{*}{DvsGesture~\cite{amir2017low}} &\multirow{3}{*}{20} & STBP   &  95.14   & -       \\
                             && SDBP   &  95.83   & +0.69  \\
                             && NoTD   &  94.44   & -0.70  \\ \hline
\multirow{3}{*}{GSC~\cite{warden2018speech}}   &\multirow{3}{*}{101}      & STBP   &  92.91   & -       \\
                             && SDBP   &  89.00   & -3.91  \\
                             && NoTD   &  77.53   & -15.38  \\ \hline
\multirow{3}{*}{SHD~\cite{cramer2020heidelberg}}  &\multirow{3}{*}{250}       & STBP   &  86.48   & -       \\
                             && SDBP   &  85.07   & -1.41  \\
                             && NoTD   &  68.51   & -17.97  \\ \hline
\multirow{3}{*}{SSC~\cite{cramer2020heidelberg}} &\multirow{3}{*}{250}        & STBP   &  67.13   & -       \\
                             && SDBP   &  66.03   & -1.10   \\
                             && NoTD   &  44.97   & -22.16   \\ \hline
\multirow{3}{*}{TIMIT~\cite{TIMIT}} &\multirow{3}{*}{100}         & STBP   &  57.07   & -       \\
                             && SDBP   &  53.24   & -3.83   \\
                             && NoTD   &  49.01   & -8.06   \\ \hline
\end{tabular}%
%}
\label{tab:res_exis_bench}
\end{table}

\paragraph{NoTD} NoTD is designed to eliminate temporal processing functions in both forward and backward passes, allowing each time step in the input sequence to be processed independently without interaction with other time steps. Consequently, NoTD cannot learn temporal relationships within sequences or integrate information over time for decision-making. Formally, the forward pass of layer $l$ in NoTD is given by
\begin{align}
\boldsymbol{u}^{l}[t] &= \boldsymbol{W}^{l} \cdot \boldsymbol{s}^{l-1}[t], \label{eq:notd_forward}\\[1.5ex]
\boldsymbol{s}^{l}[t]  &= \Theta (\boldsymbol{u}^{l}[t] - V_{\text{th}}).
\end{align}

%\todo{Please check the punctuation after each equation and captions of each figure/table.}

Compared to Eq.~\eqref{eq:mem_update}, Eq.~\eqref{eq:notd_forward} removes the temporal processing function, i.e., the membrane potential update process. 
In the backward pass, the weight gradient in NoTD is the same as Eqs.~\eqref{eq:tlg} and \eqref{eq:tlg2} in SDBP. %, since the gradients associated with the temporal processing function are eliminated in both SDBP and NoTD. 


\begin{figure*}[!t]
\centering\includegraphics[width=0.9\linewidth]{figs/dvsgesture_vis.pdf}
\caption{Qualitative results of samples from the DvsGesture dataset, along with the confident frame (highlighted with red boxes) selected by all the algorithms in STP. Labels are provided in the leftmost column. }
\label{Fig:dvsgesture_vis}
\end{figure*}

\paragraph{Evaluation Criteria}
To determine whether a dataset can effectively evaluate the temporal processing capabilities of SNNs, we train SNNs using the three algorithms on the dataset. The effectiveness of the dataset will be evaluated based on the relative performance of these algorithms: 
\begin{enumerate}
  \item If the performance of SDBP is comparable to or exceeds that of STBP, this suggests that temporal credit assignment during the backward pass may be unnecessary, indicating that the dataset is not suitable for evaluating temporal processing capabilities.
  \item If the performance of NoTD is comparable to or better than that of SDBP, it implies that the dataset can be effectively addressed without incorporating temporal interactions within the model, thus rendering it an inadequate benchmark.
  \item Conversely, if SDBP surpasses NoTD and STBP outperforms SDBP, this indicates that information integration across the time is essential, and that temporal credit assignment effectively facilitate this integration. Therefore, the benchmark is suitable for assessing the temporal processing capabilities of SNNs.
\end{enumerate}


\section{Evaluation of Neuromorphic Benchmarks Using STP}
\label{sec:eval_bench}
We conduct a comprehensive analysis of the existing neuromorphic benchmarks using the STP to reveal their critical limitations. 
%We further apply the proposed STP tool to analyze commonly used neuromorphic benchmarks. 
For each benchmark, we adhere to standard protocols from prior studies~\cite{wu2018spatio,xiao2022online,meng2023towards,duan2022temporal,ASGL,TCLIF}, which include dataset processing, data augmentation, network design, and training configurations. Detailed descriptions of these setups are provided in Appendix~\ref{app:imp_det_exsiting_bench}.

Our analysis begins with static image recognition benchmarks, including MNIST~\cite{lecun1998gradient}, CIFAR10~\cite{krizhevsky2009learning}, and CIFAR100~\cite{krizhevsky2009learning}. These datasets do not contain temporal information, as each input sequence is generated by repeating a static image along the time dimension. This is reaffirmed by our experimental results. As shown in Table~\ref{tab:res_exis_bench}, both NoTD and SDBP achieve accuracy comparable to STBP. This suggests that the capability to model temporal relationships is not necessary for high performance on these datasets.

Next, we examine event-based vision datasets. Results are presented in Table~\ref{tab:res_exis_bench}. For synthetic event-based datasets like N-MNIST~\cite{orchard2015converting} and CIFAR10-DVS~\cite{li2017cifar10}, NoTD performs similarly to or even outperforms both SDBP and STBP. This suggests that these datasets can be effectively addressed at the frame level without the need for temporal modeling. Interestingly, the DvsGesture dataset~\cite{amir2017low}, which captures human gestures in real time, is also effectively addressed by NoTD. This implies that the DvsGesture dataset does not require the model to have temporal processing capabilities for accurate recognition.


To understand these results, we conduct a qualitative analysis by visualizing samples from the DvsGesture dataset in Fig.~\ref{Fig:dvsgesture_vis}, along with the confident frame selected by each algorithm in STP. The confident frame is defined as the frame where the output layer has the strongest response. We observe that most samples have minimal changes over time, which allows accurate classification based on a single frame. The three algorithms often select the same confident frame, reinforcing that a single frame is sufficient for correct recognition without the need for temporal modeling. 

In cases where the algorithms choose different frames, as shown in Appendix Fig.~\ref{Fig:app_dvs_vis_diff_t}, the selected frames often have similar spatial features despite at different time steps. This demonstrates that these samples contain several informative frames adequate for pattern recognition. Additionally, certain classes, such as right arm clockwise and counterclockwise movements, seemingly necessitate temporal modeling due to their directional differences. However, both NoTD and SDBP successfully recognize these classes and select confident frames that align with STBP. This effectiveness can be attributed to the presence of distinguishable spatial features within these classes, which reduces the necessity for temporal modeling. Furthermore, we visualize samples correctly classified by STBP but not by NoTD in Appendix Fig.~\ref{Fig:app_dvs_vis_stbp_correct_notd_wrong}. We observe that the errors made by NoTD are primarily associated with spatial features rather than temporal cues. Similarly, as illustrated in Appendix Fig.~\ref{Fig:app_dvs_vis_stbpwrong}, the misclassifications by STBP are also linked to spatial features present within individual frames, rather than to temporal relationships across multiple frames. This analysis supports the conclusion that the primary challenge for achieving high-accuracy classification on the DvsGesture dataset resides in spatial pattern recognition rather than in temporal modeling.

Finally, we evaluate audio classification benchmarks, including GSC~\cite{warden2018speech}, SHD~\cite{cramer2020heidelberg}, SSC~\cite{cramer2020heidelberg}, and TIMIT~\cite{TIMIT}. Fig.~\ref{Fig:illustration_samples}(b) presents a visualization of randomly selected audio samples. By applying STP to these benchmarks, we find that a significant subset of samples can be accurately classified using only frame-level processing capabilities. This is evidenced by the moderate accuracy achieved by NoTD on these benchmarks. Furthermore, SDBP demonstrates substantially higher accuracy than NoTD, approaching the performance of STBP. This indicates that temporal interactions during the forward pass are critical for these tasks, while temporal credit assignment during the backward pass contributes only marginally to performance gains. Consequently, these benchmarks are not effective for evaluating temporal processing capabilities. 


\begin{figure}[!t]
    \centering    \includegraphics[width=0.95\linewidth]{figs/binadd.pdf}
    \caption{Illustration of the binary adding task, designed to test the ability of SNN models to capture long-range dependencies. The sequence length in this task is adjustable, allowing flexibility in controlling the task's difficulty.}
    \label{fig:binaryadd}
\end{figure}


In summary, our analysis utilizing the STP tool reveals that the current neuromorphic benchmarks are inadequate for evaluating the temporal processing capabilities of SNNs. 

% We apply our segregated temporal propagation framework to examine the widely used neuromorphic benchmarks, including three image recognition datasets (MNIST, CIFAR-10, and CIFAR-100), three event-based object recognition datasets (N-MNIST, CIFAR-10-DVS, and DvsGesture), and three audio-based classification datasets (SHD, SSC, and GSC).  We adopt commonly used settings for dataset preprocessing, data augmentation, network architectures, and training configurations in our experiments, and also ensure consistency across the STBP, SDBP, and NoTD training algorithms for fair comparisons. Detailed training setup can be found in Appendix.

% Empirical results are presented in Table~\ref{tab:res_exis_bench}. For image recognition datasets, the three learning algorithms yield nearly identical accuracy, suggesting that temporal error propagation or temporal information processing is not critical for accurate classification in these cases. This outcome is expected, as each static image sample in these datasets is converted into a sequence by repetition along the time dimension, without introducing meaningful temporal information that could enhance accuracy. Similarly, for event-based object recognition tasks, the three learning algorithms also achieve comparable accuracy. This indicates that momentary information is enough for high-accuracy classification on the N-MNIST and CIFAR-10-DVS datasets that are derived from static images, and even the DvsGesture dataset that captures human gestures directly using DVS. \textcolor{red}{Can we add some visualization to help the analyze? For example, to visualize the decision-making process, which part of the sequence the classifier gives more credit.} Therefore, these three event-based vision datasets are not suitable for evaluating the temporal processing capabilities of different methods. The same justification can be made on both GSC and SSC audio-based datasets, where the three learning algorithms consistently achieve similar accuracy.  For the SHD dataset, we observe a substantial accuracy gap between NoTD and STBP, but this accuracy gap narrows when comparing SDBP to STBP. This suggests that the significant difference between NoTD and STBP is primarily due to the role of temporal dynamics in facilitating error propagation along network layers rather than across time. In other words, the dataset does not effectively reward temporal error propagation and thus cannot adequately evaluate temporal processing capabilities. 

% In summary, our experiments reveal that the widely used neuromorphic benchmarks lack meaningful temporal information and are insufficient for assessing temporal processing capabilities. 






\section{Temporal Processing Benchmark Suite}
\label{sec:benchmark}
To bridge this gap, we present a new benchmark suite comprising three tasks in this section, along with a validation study to demonstrate their effectiveness in assessing temporal processing capabilities.

\subsection{Benchmark Suite}
% \label{sec:benchmarks}
To reveal the status quo of SNNs for temporal processing, we present a benchmark suite designed to comprehensively evaluate the temporal processing capabilities of existing SNN approaches. This suite incorporates three tasks with distinct modalities: language generation, pixel-level image classification, and mathematics. 


\begin{itemize}
\item{\textbf{Penn Treebank (PTB)}. PTB is a widely used language modeling dataset \cite{marcus1993building}, derived from Wall Street Journal articles, including various text types such as news reports, editorials, and financial analyses. In this task, the text is tokenized into individual words with a vocabulary size of 10,000. Each sample is then truncated into sequences of 70 tokens. The model is required to predict the next token at each time step based on the preceding input context. }
\item{\textbf{Permuted-Sequential MNIST (PS-MNIST)}. PS-MNIST is a sequence classification dataset derived from the MNIST dataset~\cite{lecun1998gradient}. Each gray-scaled image from the MNIST dataset is first flattened in row-major order into a sequence of length 784. The pixel order is then shuffled using a fixed random permutation matrix, disrupting locality to challenge the model's ability to model long-range dependencies. Finally, these pixels are fed to an SNN one pixel at a time, with the prediction made at the final time step.} %For SNNs, the cumulative sum of the readout layer across all time steps is defined as classifier outputs.

\item{\textbf{Binary Adding}. To challenge models in performing temporal processing over long distances, we propose a novel binary adding task. As illustrated in Fig.~\ref{fig:binaryadd}, we generate a synthetic $10$-class dataset with two input channels, denoted as $\{\boldsymbol{x}_1, \boldsymbol{x}_2\} \in \{0,1\}^ {T }$, where $\boldsymbol{x}_1$ represents a binary value sequence and $\boldsymbol{x}_2$ serves as an index indicator. The input sequence length $T$ can be flexibly adjusted to change the task difficulty. The binary value sequences $\boldsymbol{x}_1$ consist of $T$ entries randomly sampled from $\{0,1\}$, while the indicator sequence $\boldsymbol{x}_2$ assigns a value of $1$ to nine randomly selected indices and $0$ otherwise. The indicator sequence $\boldsymbol{x}_2$ acts as a pointer to indicate which entries in $\boldsymbol{x}_1$ should be added. The label is defined as $y=\sum_{t=1}^{T}{\boldsymbol{x}_1[t]\cdot\boldsymbol{x}_2[t]}$, which ranges from $0$ to $9$. The model must process the entire sequence before making a prediction, necessitating the ability to integrate information over a long time span. For a consistent comparison across different SNN approaches, we construct a fixed dataset containing $50,\!000$ training samples and $2,\!000$ testing samples.}
\end{itemize} 


\subsection{Validation of Benchmarks using the STP}
% \label{sec:benchmark_eval}

\begin{figure}[!t]
\centering\includegraphics[width=0.84\linewidth]{figs/acc_benchmarks.pdf}
\caption{Validation of the temporal processing benchmark suite through the STP}
\label{Fig:res_sequence_bench}
\end{figure}

We further apply the STP tool to validate the effectiveness of these three benchmarks in assessing temporal processing capabilities. Details of the training setups are provided in Appendix~\ref{app:imp_det_seq_bench}. As shown in Fig.~\ref{Fig:res_sequence_bench}, STBP significantly outperforms SDBP, which in turn substantially surpasses NoTD. This observation is consistent across all three benchmarks, demonstrating that these benchmarks contain critical temporal information that is necessary to be captured for high performance. Therefore, they can serve as effective benchmarks for evaluating the temporal processing capabilities of various SNN approaches.


% \linespread{1.}
% \begin{table}[!htb]
% \centering
% \caption{Results of the segregated temporal propagation framework on temporal processing benchmarks.}
% \setlength{\tabcolsep}{2.8mm}
% %\resizebox{\textwidth}{!}{%
% \begin{tabular}{c|c|ccc}
% \hline
% Dataset & T                     & Method & \textcolor{red}{Accuracy} & $\triangle$Performance\\ \hline
% \multirow{3}{*}{PTB} & \multirow{3}{*}{70}      & STBP   & 129.86    &  -      \\
%                              && SDBP   & 149.86    & -20.00  \\
%                              && NoTD   & 179.43    & -49.57  \\ \hline
% \multirow{3}{*}{PS-MNIST} & \multirow{3}{*}{784}     & STBP   & 57.45    & -       \\
%                              && SDBP   & 40.53    & -16.92  \\
%                              && NoTD   & 25.04    & -32.41  \\ \hline
% \multirow{3}{*}{Binary Adding} &\multirow{3}{*}{100}        & STBP   &  29.60   & -       \\
%                              && SDBP   &  15.50   & -   \\
%                              && NoTD   &  11.55   & -   \\ \hline
% \end{tabular}%
% %}
% \label{tab:res_sequence_bench}
% \end{table}




\section{Status Quo of SNNs for temporal processing}
\label{sec:benchmarking}
To assess the current state of SNNs in temporal processing, we further conduct a comprehensive study of over thirty recently developed SNN methods using our proposed benchmark suite. The evaluated methods encompass a wide range of aspects, including learning algorithms in Section~\ref{subsec:training_algo}, surrogate gradients in Section~\ref{subsec:sg}, normalization techniques in Section~\ref{subsec:norm}, neuron models in Section~\ref{subsec:neuron_models}, and neural architectures in Section~\ref{subsec:network_architecture}. For completeness, each method is evaluated using both feedforward and recurrent architectures~\cite{bellec2018long,bellec2020solution}. The Recurrent SNNs (RSNNs) incorporate recurrent weights to retain historical information, thereby offering improved memory capacity compared to feedforward architectures.


%\linespread{1.}
\begin{table}[!t]
\centering
\caption{Comparison of learning algorithms on temporal processing benchmarks. ``FF" and ``Rec." refer to ``feedforward" and ``recurrent" architectures, respectively. ``PPL" stands for ``perplexity."}
\begin{tabular}{l|cc|cc|cc}
\hline
\textbf{Dataset} & \multicolumn{2}{c|}{\begin{tabular}[c]{@{}c@{}}PTB \\ (\(T=70\))\end{tabular}} & \multicolumn{2}{c|}{\begin{tabular}[c]{@{}c@{}}PS-MNIST \\ (\(T=784\))\end{tabular}}
& \multicolumn{2}{c}{\begin{tabular}[c]{@{}c@{}}Binary Adding \\ (\(T=100\))\end{tabular}} \\ \hline
\textbf{Metric} & \multicolumn{2}{c|}{PPL ~$\downarrow$} & \multicolumn{2}{c|}{Acc.~$\uparrow$} & \multicolumn{2}{c}{Acc.~$\uparrow$} \\ \hline
\textbf{Method} & FF & Rec. & FF & Rec. & FF & Rec. \\ \hline
STBP~\cite{wu2018spatio} & 129.96 & 111.96 & 57.45 & 72.97 & 29.60 & 53.35 \\
T-STBP & 137.8 & 120.58 & 53.00 & 71.03 & 23.00 & 51.50 \\
E-prop~\cite{bellec2020solution} & - & 125.54 & - & 52.88 & - & 50.85 \\
OTTT~\cite{xiao2022online} & 141.77 & - & 44.61 & - & 17.20 & - \\
SLTT~\cite{meng2023towards} & 149.86 & - & 40.53 & - & 15.50 & - \\ \hline
\end{tabular}
\label{tab:training_algos}
\end{table}


To ensure a fair comparison across these methods, we re-implement each method to the best of our ability, utilizing their publicly available source codes and descriptions provided in their respective papers. We maintain consistent training setups across all methods. To optimize the hyperparameters for each method, we conduct a grid search; detailed information on the hyperparameters and training setups is available in our open-sourced library. We have open-sourced our code and benchmarks to facilitate future advancements in the field, and we welcome contributions from the neuromorphic computing community to expand our benchmark by including more tasks and recent SNN methods.



\begin{figure}[!htb]
    \centering\includegraphics[width=0.9\linewidth]{figs/sg.pdf}
    \caption{Comparison of different surrogate gradient functions.}
    \label{fig:sg}
\end{figure}


\subsection{Learning Algorithms}
\label{subsec:training_algo}
We begin by evaluating the performance of five SNN learning algorithms, including two offline learning algorithms (i.e., STBP~\cite{wu2018spatio}, Truncated-STBP~(T-STBP)) as well as three recently-proposed online learning algorithms (i.e., E-prop~\cite{bellec2020solution}, Online Training Through Time~(OTTT)~\cite{xiao2022online},  and Spatial Learning Through Time~(SLTT)~\cite{meng2023towards}). 
STBP is a standard gradient-based learning algorithm, which unfolds SNNs over both spatial and temporal domains and applies gradient descent to the entire computational graph. T-STBP processes input sequences in smaller segments, preventing error gradients from being backpropagated between these segments while preserving the complete temporal gradients within each individual segment. In contrast, the three online learning algorithms update SNNs at every time step, and they either partially or fully disregard temporal gradients to enable online learning. Specifically, E-prop achieves online learning in RSNNs by using eligibility traces, which accumulate presynaptic activities over time. Similarly, OTTT extends the mechanism of eligibility traces to feedforward SNNs, enabling effective online training for large-scale datasets. SLTT, on the other hand, ignores all temporal gradients, removing the need for additional traces while slightly compromising gradient precision.  



In our evaluation, we adhere to the original setups for these algorithms, applying OTTT and SLTT exclusively to feedforward SNNs, while E-prop is used solely for RSNNs. Results presented in Table~\ref{tab:training_algos} indicate that STBP consistently outperforms the other four learning algorithms across all three benchmarks, regardless of the architecture. This performance gap is attributed to the omission of temporal gradients in these algorithms, which leads to biased gradient estimations and impedes the accurate propagation of temporal errors.




%\linespread{1.}
\begin{table}[!t]
\centering
\caption{Comparison of surrogate gradient functions on temporal processing benchmarks. The  \textbf{best} model is highlighted in \textbf{bold}, and the {\ul second} best is {\ul underlined}.}
\setlength{\tabcolsep}{1.5mm}
\begin{tabular}{l|cc|cc|cc}
\hline
\textbf{Dataset} & \multicolumn{2}{c|}{\begin{tabular}[c]{@{}c@{}}PTB \\ (\(T=70\))\end{tabular}} & \multicolumn{2}{c|}{\begin{tabular}[c]{@{}c@{}}PS-MNIST \\ (\(T=784\))\end{tabular}}
& \multicolumn{2}{c}{\begin{tabular}[c]{@{}c@{}}Binary Adding \\ (\(T=100\))\end{tabular}} \\  \hline
\textbf{Metric} & \multicolumn{2}{c|}{PPL~$\downarrow$} & \multicolumn{2}{c|}{Acc.~$\uparrow$} & \multicolumn{2}{c}{Acc.~$\uparrow$}  \\ \hline
\textbf{Method} & FF & Rec. & FF & Rec. & FF & Rec. \\ \hline
Rectangle~\cite{wu2018spatio} & 129.96 & 111.96 & 57.45 & 72.97 & {\ul 29.60} & 53.35 \\
Triangle~\cite{deng2022temporal} & {\ul 127.78} & {\ul 108.98} & {\ul 62.96} & \textbf{77.15} & 28.20 & {62.90} \\
Multi-Gaussian~\cite{ALIF} & 130.01 & 112.74 & 57.01 & 71.96 & \textbf{32.20} & {\ul 65.60} \\
Sigmoid~\cite{adLIF} & \textbf{127.33} & \textbf{107.92} & \textbf{63.18} & {\ul 76.02} & {29.35} & \textbf{66.45} \\
ASGL~\cite{ASGL} & 128.14 & 113.18 & 58.32 & 66.00 & 26.15 & 46.70 \\ \hline
\end{tabular}
\label{tab:sg}
\end{table}


Notably, our findings contrast with previous studies~\cite{xiao2022online,bellec2020solution,meng2023towards} that reported nearly lossless performance for these online learning algorithms compared to STBP. This discrepancy stems from the fact that earlier evaluations were primarily on datasets with no or limited temporal information, such as CIFAR10, CIFAR10-DVS, and DvsGesture, where the absence of temporal gradients had a minimal effect. In contrast, our benchmarks necessitate effective learning over time, where the accurate calculation of temporal gradients is crucial. This experiment underscores the limitations of commonly used neuromorphic benchmarks and highlights a significant accuracy gap between existing online learning methods and STBP in temporal processing tasks.



\subsection{Surrogate Gradient Functions}
\label{subsec:sg}
%\xy{Furthermore,

To address the nondifferentiable activation functions used in SNNs, surrogate gradient methods \cite{8891809} are commonly employed. These methods retain the original step function during the forward pass while replacing it with a smooth and continuous function during the backward pass. In this section, we evaluate the performance of five most frequently used surrogate gradient functions: Rectangle \cite{bengio2013estimating, wu2018spatio}, Triangle \cite{8891809,deng2022temporal}, Sigmoid \cite{adLIF}, Multi-Gaussian \cite{ALIF}, and Adaptive Smoothing Gradient Learning (ASGL) \cite{ASGL}. Notably, ASGL~\cite{ASGL} not only smooths the step function during backpropagation but also partially replaces the step function in the forward pass with the integral of surrogate functions during training. This approach mitigates the gradient approximation error caused by the mismatch between actual and surrogate gradients, resulting in smoother training.


\begin{table}[!t]
\centering
\caption{Comparison of normalization methods on temporal processing benchmarks}
\begin{tabular}{l|cc|cc|cc}
\hline
\textbf{Dataset} & \multicolumn{2}{c|}{\begin{tabular}[c]{@{}c@{}}PTB \\ (\(T=70\))\end{tabular}} & \multicolumn{2}{c|}{\begin{tabular}[c]{@{}c@{}}PS-MNIST \\ (\(T=784\))\end{tabular}}
& \multicolumn{2}{c}{\begin{tabular}[c]{@{}c@{}}Binary Adding \\ (\(T=100\))\end{tabular}} \\  \hline
\textbf{Metric} & \multicolumn{2}{c|}{PPL~$\downarrow$} & \multicolumn{2}{c|}{Acc.~$\uparrow$} & \multicolumn{2}{c}{Acc.~$\uparrow$} \\ \hline
\textbf{Method} & FF & Rec. & FF & Rec. & FF & Rec. \\ \hline
w/o BN & 129.96 & 111.96 & 57.45 & 72.97 & 29.60 & 53.35 \\
TEBN~\cite{deng2022temporal} & 126.88 & 102.24 & \textbf{94.94} & \textbf{95.02} & \textbf{53.03} & \textbf{65.45} \\
TDBN~\cite{zheng2021going} & 127.04 & 101.54 & 72.74 & 88.60 & 35.55 & 64.10 \\
LayerNorm~\cite{ba2016layer} & \textbf{123.54} & \textbf{101.53} & 62.28 & 69.96 & 40.25 & 49.70 \\ \hline
\end{tabular}
\label{tab:bns}
\end{table}

Results in Table \ref{tab:sg} indicate that while the performance of different surrogate functions shows only minor differences in feedforward architectures, their impact is significantly more pronounced in recurrent architectures. This is due to the recurrent connection from the output spike at time $t-1$ to the membrane potential at time $t$, which introduces an additional pathway for gradient backpropagation. This iterative computation of surrogate gradients over time introduces additional challenges for SNN training. Fortunately, a well-shaped surrogate function can more effectively propagate gradients back to earlier time steps through this recurrent pathway, resulting in improved network convergence for recurrent architectures.


To identify the most suitable surrogate gradient functions for temporal processing tasks, we further rank their performance across the three tasks and two architectures. The average ranking is used as a score to quantify their effectiveness. Our results indicate that the Sigmoid~\cite{adLIF} and Triangle~\cite{deng2022temporal} functions achieve the top two average rankings, with scores of $0.67$ and $1.17$, respectively. This finding suggests that these two functions are more appropriate for temporal tasks. The superior performance of the Sigmoid and Triangle functions can be attributed to two factors. Firstly, their higher smoothness facilitates error propagation during SNN training~\cite{wu2018spatio, deng2022temporal, eshraghian2023training}. Additionally, the values of these surrogate functions provide a closer approximation to the ill-defined derivative of the step function, as illustrated by the dotted curves in Fig.~\ref{fig:sg}. Consequently, the gradient mismatch problem \cite{ASGL} can be more effectively alleviated, contributing to better training convergence. Finally, we examine the performance of the ASGL strategy~\cite{ASGL}. Despite the performance improvements observed in previous static tasks, our results indicate that this strategy is less effective for temporal processing tasks. This inefficacy primarily arises from the discrepancy between the spike generation function employed during training and that used during inference, which accumulates over time, particularly when handling long sequences. 






\subsection{Normalization Methods}
\label{subsec:norm}
Here, we evaluate the influence of normalization methods on the temporal processing performance of SNNs. Building upon the Batch Normalization (BN)~\cite{ioffe2015batch} method in ANNs, normalization methods have been developed specifically for SNNs to improve training stability and accelerate convergence. For example, Threshold-Dependent BN (TDBN)~\cite{zheng2021going} normalizes features across both batch and time dimensions and adjusts the normalized variance based on the threshold, which effectively mitigates the problems of gradient vanishing or explosion during training. Furthermore, Temporal Effective BN (TEBN)~\cite{duan2022temporal} incorporates trainable factors to rescale presynaptic inputs at each time step. This technique smooths temporal distributions of gradient norms and stabilizes training. In addition to TDBN and TEBN, we also assess Layer Normalization~(LayerNorm)~\cite{ba2016layer}, which is commonly used in non-spiking sequence models and can be seamlessly applied to SNNs.

Three major observations can be drawn from the results presented in Table~\ref{tab:bns}. First,  TEBN, TDBN, and LayerNorm all significantly enhance performance across the three benchmarks. Second, TEBN, in particular, shows substantial accuracy improvements on the PS-MNIST and binary adding tasks. The large improvement is attributed to the rescaling of presynaptic inputs with trainable factors at each time step in TEBN. This mechanism helps stabilize gradient flow over time and ensures that relevant information is preserved throughout the learning process. Third, LayerNorm proves to be particularly effective in language modeling tasks like PTB. Its ability to normalize across non-batch dimensions facilitates the learning of temporal sequences with varying effective lengths, leading to better performance in handling complex temporal data. 







\begin{figure*}[!t]
\centering\includegraphics[width=0.8\linewidth]{figs/snnvsann.pdf}
\caption{Comparison of advanced spiking and non-spiking sequence models. Each model is evaluated on the binary adding task with sequence lengths ranging from $200$ to $2400$.
} 
\label{Fig:snnrnn}
\end{figure*}


%\linespread{1.}
\begin{table}[!t] 
\centering
\caption{Comparison of spiking neuron models on temporal processing benchmarks. The  \textbf{best} model is highlighted in \textbf{bold}, the {\ul second} best is {\ul underlined}, and the \textit{third} best is \textit{italicized}.}
\setlength{\tabcolsep}{1.5mm}
\begin{tabular}{l|cc|cc|cc}
\hline
\textbf{Dataset} & \multicolumn{2}{c|}{\begin{tabular}[c]{@{}c@{}}PTB \\ (\(T=70\))\end{tabular}} & \multicolumn{2}{c|}{\begin{tabular}[c]{@{}c@{}}PS-MNIST \\ (\(T=784\))\end{tabular}}
& \multicolumn{2}{c}{\begin{tabular}[c]{@{}c@{}}Binary Adding \\ (\(T=100\))\end{tabular}} \\  \hline
\textbf{Metric} & \multicolumn{2}{c|}{PPL~$\downarrow$} & \multicolumn{2}{c|}{Acc.~$\uparrow$} & \multicolumn{2}{c}{Acc.~$\uparrow$} \\ \hline
\textbf{Network} & FF & Rec. & FF & Rec. & FF & Rec. \\ \hline
\textbf{\#Params.} & $\sim$5M & $\sim$6M & $\sim$90K & $\sim$160K & $\sim$20K & $\sim$40K \\ \hline
LIF & 129.96 & 111.96 & 57.45 & 72.97 & 29.60 & 53.35 \\
PLIF%$^{\textit{'ICCV21}}$
\cite{PLIF} & 123.76 & 105.64 & 55.86 & 77.32 & 29.40 & 53.25 \\
ALIF%$^{\textit{'NMI21}}$
\cite{ALIF} & 113.67 & 102.25 & 73.90 & 85.78 & 40.30 & 68.00 \\
adLIF%$^{\textit{'fnins22}}$
\cite{adLIF} & 118.52 & \textbf{97.22} & 85.93 & 89.53 & 42.00 & {99.05} \\
GLIF%$^{\textit{'NeurIPS22}}$
\cite{GLIF} & {\ul 111.58} & 103.07 & \textit{95.42} & {\ul 95.04} & 90.15 & 63.60 \\
LTC%$^{\textit{'NMI23}}$
\cite{ltc} & \textbf{104.10} & {\ul 99.09} & 86.33 & 90.94 & \textbf{100.00} & \textbf{100.00} \\
SPSN%$^{\textit{'NeurIPS23}}$
\cite{PSN} & 120.43 & - & 83.88 & - & 45.70 & - \\
TCLIF%$^{\textit{'AAAI24}}$
\cite{TCLIF} & 286.71 & 255.67 & 86.81 & \textit{92.08} & 19.10 & 19.90 \\
LM-H%$^{\textit{'ICLR24}}$
\cite{LMH} & 122.69 & 102.05 & 77.70 & 83.14 & \textit{99.25} & 96.10 \\
CLIF%$^{\textit{'ICML24}}$
\cite{CLIF} & 128.28 & 108.21 & 43.90 & 70.44 & 19.10 & 64.30 \\
DH-LIF%$^{\textit{'NC24}}$
\cite{dhsnn} & 115.61 & \textit{100.55} & 79.12 & 91.07 & 98.85 & \textit{99.35} \\
CELIF%$^{\textit{'ArXiv24}}$
\cite{CELIF} & \textit{112.35} & 106.52 & \textbf{97.76} & \textbf{97.66} & 48.40 &\textbf{100.00} \\
PMSN%$^{\textit{'ArXiv24}}$
\cite{PMSN} & 113.24 & - & {\ul 96.28} & - & \textbf{100.00} & - \\ 
\hline
\end{tabular}
\label{tab:neuron}
\end{table}


\subsection{Spiking Neuron Models}
\label{subsec:neuron_models}


In this section, we conduct a comprehensive benchmarking of existing spiking neuron models for temporal processing. The widely used LIF model~\cite{lif} has limited memory capacity and often suffers from the temporal gradient vanishing problem~\cite{TCLIF}, which results in relatively poor temporal processing capabilities. Recently, several advanced spiking neuron models have been proposed to provide enhanced temporal modeling capabilities. These models can be categorized into two main types. The first category encompasses single-compartment spiking neuron models, which represent biological neurons as undivided units with enriched neuronal dynamics. For instance, Parametric LIF (PLIF) \cite{PLIF} introduces a learnable leaky constant for each neuron, allowing the model to adapt to diverse decaying rates of the input. Adaptive LIF (ALIF) \cite{ALIF} and Liquid Time-Constant (LTC) \cite{ltc} models incorporate the adaptive threshold as an additional state variable, allowing the spiking neuron to retain information related to its firing history within the firing threshold. Furthermore, models such as Generalized Leaky Integrate-and-Fire (GLIF) \cite{GLIF}, Complementary Leaky Integrate-and-Fire (CLIF) \cite{CLIF}, adaptive Leaky Integrate-and-Fire (adLIF) \cite{adLIF}, and Context Embedding Leaky Integrate-and-Fire (CELIF) \cite{CELIF} integrate various biological mechanisms such as ion channels, complementary membrane potentials, adaptation currents, and temporal context to enhance neuronal dynamics of spiking neurons.

In another vein of research, several multi-compartment spiking neuron models have also been proposed. Inspired by P-R neurons in the hippocampus, the Two-Compartment LIF (TC-LIF) model \cite{TCLIF} is specifically designed to model interactions between the soma and dendrites. To further reduce the parameter constraints of the TC-LIF model, the Learnable Multi-Hierarchical (LM-H) model \cite{LMH} has been proposed, demonstrating more stable gradient propagation in deep networks. Going beyond models with meticulously designed two compartments, the Dendritic Heterogeneity LIF (DH-LIF) model \cite{dhsnn} endows multiple dendritic compartments with heterogeneous decaying time constants. To address concerns about the slow training speed of SNNs, recent research has also proposed several neuron models to enable parallel computation in the temporal dimension. The family of Parallel Spiking Neural (PSN) models \cite{PSN} transforms the charging dynamics of the membrane potential into a learnable decay matrix and bypasses the neuron's reset mechanism to enable parallel computation. Furthermore, the Parallel Multi-Compartment Neuron (PMSN) model \cite{PMSN} incorporates multiple interconnected neuronal compartments. These inter-compartment interactions can effectively represent temporal information across diverse timescales.

Since most of these advanced models are developed based on static image datasets, their efficacy for temporal processing tasks remains elusive. To this end, we comprehensively compare their performance against the LIF model on our temporal processing benchmarks.  It is important to note that different studies have adopted different numbers of learnable model parameters for their respective neuron models. To ensure a fair comparison, we proportionally adjust the number of neurons in the hidden layers so that all neuron models are evaluated with the same number of parameters as the baseline. As the results presented in Table \ref{tab:neuron}, the various neuron models exhibit varying degrees of improvement over the LIF model, highlighting their effectiveness in enhancing the temporal processing capabilities of SNNs. 

The observed improvements can be explained by several specific architectural features of these models. For instance, the improved performance achieved by ALIF can be attributed to 
the additional slow-decaying state variables, which facilitate information integration over longer timespans. Moreover, the heterogeneous decaying rate of state variables used in these models can further facilitate the establishment of temporal dependencies across different timescales, as demonstrated in models like GLIF and DH-LIF. Furthermore, models such as adLIF, TCLIF, LM-H, and PMSN incorporate recurrent interactions between neuronal variables. These enriched neuronal dynamics significantly enhance the integration of temporal information. Other strategies, such as the extended temporal receptive field employed by SPSN, the temporal context in CELIF, and the liquid decaying rate in LTC, also demonstrate the enhancement of temporal processing capability.

The results also highlight the importance of the time decaying factors in facilitating temporal processing. For instance, the TC-LIF neuron omits these decay factors, leading to continuous accumulation of information in the two membrane potential variables. While this configuration works well for static datasets, it encounters challenges when targets change over time, as observed in tasks such as the PTB and binary adding. This necessitates a neuron model capable of rapidly forgetting past information to respond promptly to new inputs. By mitigating the excessive accumulation of historical inputs, these decay factors ensure that the spiking neuron remains responsive to new stimuli over time.




\subsection{Comparison of Spiking and Non-Spiking Sequence Models}
\label{subsec:annvssnn}
Having demonstrated the effectiveness of various advanced SNN models in temporal processing,
we further benchmark their performance by comparing them against leading non-spiking sequence models. In the binary adding problem, models such as LM-H, DH-LIF, and PMSN using a feedforward architecture, as well as LTC and CELIF employing a recurrent architecture, can successfully accomplish the task with a sequence length of $T\!=\!100$. These results indicate competitive performance relative to prominent non-spiking RNN models such as Long Short-Term Memory (LSTM)~\cite{LSTM} and SSM~\cite{SSM}. To further figure out whether current advanced SNN models already achieve similar to or even surpass the performance of these RNN models, we quantify their long-range temporal processing capacity by varying $T$ from 100 to $200$, $400$, $600$, $800$, $1200$, $1600$, and $2400$. %\textcolor{red}{are we using the RNN structure for SNNs?}

As shown in Fig.~\ref{Fig:snnrnn}, the performance of LM-H and DH-LIF models degrades significantly when $T$ reaches $400$. The performance of CELIF model starts to degrade beyond $T\!=\!600$ and fails to learn any meaningful temporal information when $T\!=\!2400$. Similarly, both LTC and PMSN show varying degrees of degradation as the sequence length increases. In contrast, SSM and LSTM consistently achieve nearly $100\%$ accuracy, even at the challenging scenario when $T\!=\!2400$. Collectively, these observations highlight that a significant gap still exists between SNNs and ANNs in modeling long-range dependencies. 

%\linespread{1.}
\begin{table}[!t]
\begin{threeparttable}
\centering
\caption{Comparison of delay learning and neural architectures on temporal processing tasks. $T_{\text{in}}$ represents the internal time window of spiking neurons.
}
\setlength{\tabcolsep}{4.6pt}
\begin{tabular}{l|cc|cc|cc}
\hline
\textbf{Dataset} & \multicolumn{2}{c|}{\begin{tabular}[c]{@{}c@{}}PTB \\ (\(T=70\))\end{tabular}} & \multicolumn{2}{c|}{\begin{tabular}[c]{@{}c@{}}PS-MNIST \\ (\(T=784\))\end{tabular}} & \multicolumn{2}{c}{Binary Adding} \\ \hline
\textbf{Metric} & \multicolumn{2}{c|}{PPL~$\downarrow$} & \multicolumn{2}{c|}{Acc.~$\uparrow$} & \(T\)~$\uparrow$ & Acc.~$\uparrow$ \\ \hline
\textbf{\#Params.} & \multicolumn{2}{c|}{$\sim$5M} & \multicolumn{2}{c|}{$\sim$90K} & \multicolumn{2}{c}{$\sim$40K} \\ \hline
LIF & \multicolumn{2}{c|}{129.96} & \multicolumn{2}{c|}{57.45} & 100 & 34.15 \\
LIF w/ DCLS-Delays~\cite{DBLP:conf/iclr/HammouamriHM24} & \multicolumn{2}{c|}{89.87} & \multicolumn{2}{c|}{68.98} & 100 & 51.85 \\
\hline
TCN\tnote{*}\;\cite{TCN} & \multicolumn{2}{c|}{102.20} & \multicolumn{2}{c|}{95.10} & 1200 & 69.95 \\
%SpikingTCN ($T_{\text{in}}=4$) & \multicolumn{2}{c|}{104.80} & \multicolumn{2}{c|}{93.93} & 1200 & 64.65 \\ 
SpikingTCN & \multicolumn{2}{c|}{114.46} & \multicolumn{2}{c|}{93.76} & 1200 & 61.95 \\ 
LSTM\tnote{*}\;\cite{LSTM} & \multicolumn{2}{c|}{88.08} & \multicolumn{2}{c|}{92.41} & 2400 & 100 \\
Gated Spiking Neuron~\cite{hao2024towards} & \multicolumn{2}{c|}{99.98} & \multicolumn{2}{c|}{80.13} & 1200 & 29.85 \\ 
Transformer\tnote{*}\;\cite{transformer} & \multicolumn{2}{c|}{112.43} & \multicolumn{2}{c|}{97.64} & 2400 & 100 \\
Spike-Driven Transformer\tnote{4}\;\cite{yao2024spike} & \multicolumn{2}{c|}{152.41} & \multicolumn{2}{c|}{96.21} & 2400 & 98.15 \\ 
Spike-Driven Transformer\tnote{1}\;\cite{yao2024spike} & \multicolumn{2}{c|}{327.82} & \multicolumn{2}{c|}{95.01} & 2400 & 88.05 \\ 
\hline
\end{tabular}
\begin{tablenotes}\footnotesize
\item[*]\!Non-spiking models.
\item[4, 1] $T_{\text{in}}=4$ and $T_{\text{in}}=1$, respectively.
\end{tablenotes}
\label{tab:architecture}
\end{threeparttable}
\end{table}


\subsection{Delay Learning and Neural Architectures}
\label{subsec:network_architecture}

In addition to improving the neuronal dynamics of spiking neurons, many recent studies have also investigated the enhancement of interactions among neurons. This section provides a comprehensive evaluation of these approaches, focusing specifically on the delay learning mechanism and neural architecture designs. 

Inspired by neuronal signaling in the brain, delay learning approaches incorporate axonal delay, the time it takes for signals to travel along an axon, into neuron modeling. In our experiments, we utilize a SOTA delay learning method, DCLS-Delays~\cite{DBLP:conf/iclr/HammouamriHM24}, which leverages 1-D temporal convolutions to enable effective delay modeling. The results in Table~\ref{tab:architecture} show that the LIF model combined with DCLS-Delays consistently outperforms its counterpart without delay modeling across all three benchmarks. This improvement underscores the significant advantage of delay learning, allowing the model to effectively establish temporal dependencies through the delay line. 

\begin{table}[!t]
\begin{threeparttable}
\centering
\caption{Comparison of energy efficiency between spiking architectures and their non-spiking counterparts on temporal processing tasks. The ratio is calculated as the energy cost of the non-spiking architecture divided by that of its spiking counterpart.
}
\setlength{\tabcolsep}{1.1pt}
\begin{tabular}{l|cc|cc|cc}
\hline
\textbf{Dataset} & \multicolumn{2}{c|}{\begin{tabular}[c]{@{}c@{}}PTB \\ (\(T=70\))\end{tabular}} & \multicolumn{2}{c|}{\begin{tabular}[c]{@{}c@{}}PS-MNIST \\ (\(T=784\))\end{tabular}} & \multicolumn{2}{c}{\makecell[c]{Binary Adding\\$(T=1200)$}} \\ \hline
\textbf{Energy} (\SI{}{\nano\joule}) & Cost & Ratio & Cost  & Ratio  & Cost  & Ratio  \\ 
\hline
TCN\tnote{*}\;\cite{TCN} &6535.7  & - &302.8  & - &187.4  & - \\
SpikingTCN  & 1505.6 & 4.3 &13.4 & 22.61 &6.8 & 27.56 \\ 
LSTM\tnote{*}\;\cite{LSTM} &8244.8 & - & 393.6& - &158.4 & -   \\
Gated Spiking Neuron~\cite{hao2024towards} & 1038.7 & 7.9 & 21.6 & 18.2 & 9.6 & 16.5 \\
Transformer\tnote{*}\;\cite{transformer}  &10223.0 & - & 1420.2 & - & 1059.8 & -  \\
Spike-Driven Transformer\tnote{4}\;\cite{yao2024spike} &1826.3 & 5.6 &131.3 & 10.8 &109.2 &9.7  \\
Spike-Driven Transformer\tnote{1}\;\cite{yao2024spike} & 367.3 & 27.8 &30.0 & 47.3 &23.6 & 44.9 \\ 
\hline
\end{tabular}
\begin{tablenotes}\footnotesize
\item[*]\!Non-spiking models.
\item[4,1] $T_{\text{in}}=4$ and $T_{\text{in}}=1$, respectively.
\end{tablenotes}
\label{tab:energy}
\end{threeparttable}
\end{table}

In terms of neural architectures, 
some recent studies focus on adapting advanced non-spiking architectures into spiking counterparts~\cite{yao2024spike,hao2024towards}. Here, we compare three well-established neural architectures for temporal processing: LSTM~\cite{LSTM}, TCN~\cite{TCN}, and Transformer~\cite{transformer}, with their spiking variants -- Gated Spiking Neuron (GSN)~\cite{hao2024towards}, SpikingTCN, and Spike-Driven Transformer~\cite{yao2024spike}. LSTM employs gating mechanisms to dynamically control information storage and forgetting, which effectively alleviates the problems of gradient vanishing and exploding. Similarly, GSN also adopts the gating mechanism to control the storage and forgetting of historical information. Unlike LSTMs, which process temporal sequences through iterative updates, TCNs use dilated convolutions to efficiently capture long-range dependencies. Recently, Transformer architectures have transformed temporal processing through the self-attention mechanism. This architecture demonstrates superior capability in managing long-range temporal dependencies, along with enhanced temporal parallelism and scalability. 

For Transformer, its spiking variant replaces the original continuous activation functions with the discrete step function employed in spiking neurons. In addition, an internal time window~$T_{\text{in}}$ of the spiking neuron is utilized to calculate the firing rate, thereby expanding the representation space of spiking neurons. However, incorporating this extra time window incurs additional computational overhead. To evaluate its impact, we compare the performance of the Spike-Driven Transformer model with  $T_{\text{in}}\!=\!4$ and $T_{\text{in}}\!=\!1$. To ensure a fair comparison, all architectures are configured with a comparable number of parameters for the same task. For the binary adding task, the sequence length is gradually increased from \(100\) to \(2400\) until the architecture no longer performs. Both the maximum sequence length and accuracy are reported in Table~\ref{tab:architecture}.




A key observation from Table~\ref{tab:architecture} is that, although the performance of spiking architectures is generally inferior to that of their non-spiking counterparts, the performance gap is relatively small, particularly when $T_{\text{in}}\!=\!4$. While the GSN architecture exhibits a significant accuracy gap compared to LSTM, it outperforms many of the advanced spiking neuron models presented in Table~\ref{tab:neuron}. Notably, the Spike-Driven Transformer excels in the binary adding task, underscoring its strong capability to model long-range dependencies through self-attention. The relatively lower performance of Spike-Driven Transformer on PTB is likely due to the overfitting with the small dataset size, and it is anticipated that performance would improve on a larger dataset. Furthermore, the Spike-Driven Transformer experiences a significant drop in accuracy when $T_{\text{in}}\!=\!1$. This finding underscores the importance of utilizing an additional internal time window to enhance the representational capacity of spiking neurons, which is critical for bridging the performance gap with SOTA non-spiking sequence models. 

We further compare the energy efficiency of these spiking architectures with that of their non-spiking counterparts. The details of the energy consumption calculation are provided in Appendix \ref{sec:energy_·cost}. As shown in Table \ref{tab:energy}, spiking architectures are generally an order of magnitude more energy efficient than their non-spiking counterparts. This efficiency stems from the spike-based computation, which relies on efficient Accumulate (AC) operations rather than the more expensive Multiply-Accumulate (MAC) operations typically used in non-spiking architectures. Additionally, Spike-Driven Transformer with $T_{\text{in}}\!=\!4$ consumes approximately four times as much energy as the model with $T_{\text{in}}\!=\!1$. This indicates that the accuracy improvements afforded by the extra time window come at the expense of significantly increased energy consumption, potentially diminishing the competitiveness of SNNs. This trade-off warrants further investigation. Nonetheless, even with $T_{\text{in}}\!=\!4$, Spike-Driven Transformer still improves energy efficiency by dozens of times compared to its non-spiking counterpart. These results underscore the significant energy-saving benefit of SNNs, making them particularly advantageous for applications in energy-constrained environments.

% Despite this performance trade-off, a critical advantage of SNN-based architectures is their remarkable energy efficiency. To further quantify this, we conduct an comparison of empirical energy costs between non-spiking LSTM, TCN, and Transformer models and their spiking variants, the results are demonstrated in Table \ref{tab:energy}. The detailed derivation are provided in Appendix \ref{sec:energy_·cost}. 
%\xy{while non-spiking neural architectures require large amounts of energy-intensive  Multiply-Accumulate (MAC) operations, the event-based and sparse nature of SNNs enable them to use more efficient Accumulate (AC) operations, resulting in significantly improved energy efficiency. While the Spike-Driven Transformer with a time window of 4 incurs approximately four times energy cost compared to the version without the time window, it still achieves up to an order of magnitude improvement in efficiency over its ANN counterpart. This advantage highlights SNNs as promising alternatives for edge applications with ultra-low energy consumption, complementing their slightly lower performance by offering superior computational efficiency.} 


\section{Challenges and Future Directions}
\label{sec:challenges}
% In this section, we identify key challenges in current research on SNNs for temporal processing and highlight promising avenues for future exploration.

In this section, we identify four key challenges in current research on SNNs for temporal processing and propose some future directions to overcome these challenges. The primary challenge arises from the inadequacy of current neuromorphic benchmarks in evaluating SNNs' temporal processing capabilities. This limitation hinders the advancement of SNNs in effectively tackling tasks that involve complex and long-range temporal dependencies. To overcome this challenge, future research should prioritize the development of comprehensive neuromorphic benchmarks specifically designed to evaluate the SNN's abilities to capture long-range temporal dependencies. To ensure practical relevance, these benchmarks should encompass a diverse array of real-world temporal processing tasks that necessitate the maintenance of temporal context over extended durations. Additionally, they should be designed to emphasize the strengths of neuromorphic computing, such as high energy efficiency and low latency. By establishing these benchmarks, we can attain a more accurate assessment of SNN's performance in temporal processing, thereby facilitating their application in real-world temporal signal processing scenarios.

Another major challenge arises from the significant accuracy drops in online learning algorithms when applied to temporal processing tasks. While these algorithms have effectively enhanced the training efficiency and adaptability of SNNs, they often compromise the precision of temporal gradients, leading to suboptimal performance in learning long-range temporal dependencies. Addressing this challenge requires the development of a new generation of online or on-chip learning algorithms that can effectively and efficiently learn long-range temporal dependencies. This advancement would enable SNNs to continuously adapt to diverse and dynamic real-world scenarios.

The third challenge is that existing SNN models struggle to model long-range dependencies. The primary issues likely arise from optimization challenges, such as the vanishing gradient problem, where gradients associated with earlier time steps become exponentially smaller, resulting in a bias toward short-term dependencies. Additionally, current SNNs face difficulties in effectively storing and retrieving information over time, which hinders SNNs' capabilities in temporal processing. To address this challenge, future research should draw inspiration from the structures and functions of biological neural networks to create spiking neuron models and neural architectures with enhanced memory storage and information retrieval capabilities.

The last challenge concerns the prohibitive training time of SNNs for long sequences. Due to the inherently temporal nature of SNNs, training times in earlier SNN studies scale linearly with sequence length, especially for spiking neuron models that involve non-linear dynamics. This scaling makes it challenging to fully exploit the parallel processing capabilities of hardware accelerators like GPUs. Consequently, training SNNs can be excessively time-consuming, which limits researchers' ability to rapidly validate new ideas and iteratively refine SNN approaches. Despite recent advancements in temporal parallel spiking neuron models that significantly accelerate training, their reliance on linear recurrency as a prerequisite for parallelism fundamentally constrains their ability to capture the rich nonlinear dynamics present in biological neurons. Future work should focus on developing novel spiking neuron models that facilitate parallelized training over time, particularly by supporting the linearization of complex dynamics. Such advancements would drastically reduce training times, thereby enabling rapid development of SNN approaches.





% \subsection{Challenges}
% \textit{1) Current neuromorphic benchmarks are inadequate for evaluating the capabilities of SNNs in temporal processing. } Our benchmark analysis in Section~\ref{sec:eval_bench} has revealed that existing benchmarks primarily focus on assessing SNNs' ability to process spatial features, while neglecting crucial aspects of temporal processing. This limitation hinders the advancement of SNNs in effectively tackling tasks that involve complex and long-range temporal dependencies. 

% \textit{2) Online learning algorithms for SNNs face significant accuracy drops on temporal processing tasks.} While these algorithms have effectively enhanced the training efficiency and adaptability of SNNs, they often compromise the precision of temporal gradients, leading to suboptimal performance in learning long-range temporal dependencies~(see Section~\ref{subsec:training_algo}).

% \textit{3) Training SNNs for long sequences is very time-consuming}. SNNs are inherently temporal, as the computation of the current membrane potential depends on previous time steps. This characteristic often leads to training times in earlier SNN studies scaling linearly with sequence length, especially for spiking neuron models that involve non-linear dynamics. This scaling makes it challenging to fully exploit the parallel processing capabilities of hardware accelerators like GPUs. Consequently, training SNNs can be excessively time-consuming, particularly when handling long sequences that extend beyond thousands of time steps. This extensive training time limits researchers' ability to rapidly validate new ideas and iteratively refine SNN approaches.

% \textit{4) SNN models struggle to model long-range dependencies.} Understanding real-world temporal data often requires reasoning over extended timespans, exceeding thousands of time steps. Beyond the computational challenges of processing such long sequences, existing SNNs also find it difficult to effectively model long-range dependencies, as evidenced by our experiment in Section~\ref{subsec:annvssnn}. The primary issues likely arise from optimization challenges, such as the vanishing gradient problem, where gradients associated with earlier time steps become exponentially smaller, resulting in a bias toward short-term dependencies. Additionally, current SNNs face difficulties in effectively storing and retrieving information over time. Consequently, these challenges hinder SNNs' capabilities in temporal processing.

% \subsection{Future Directions}
% \textit{1) Develop comprehensive neuromorphic benchmarks for evaluating the capability of modeling long-range temporal dependencies.} These benchmarks should include a diverse set of real-world temporal processing tasks that require maintaining temporal context over extended periods. They should be designed to highlight the strengths of neuromorphic computing, incorporating datasets that are collected using neuromorphic sensors, such as event-based cameras. By establishing these benchmarks, we can achieve a more accurate assessment of SNNs' performance and encourage the advancement of SNN models tailored for real-world applications

% \textit{2) Develop effective SNN learning algorithms with enhanced performance on temporal processing tasks.} Novel online or on-chip learning algorithms should be designed to effectively and efficiently learn long-range temporal dependencies. This advancement will enable SNNs to continuously adapt to diverse and dynamic real-world scenarios.

% \textit{3) Develop efficient spiking neuron models and network architectures that effectively handle long-range dependencies while supporting parallelized training over time.}  Future research may draw inspiration from the structures and functions of biological neural networks to create spiking neuron models and network architectures with enhanced memory storage and information retrieval capabilities. Furthermore, these models should support parallelized training over time to significantly accelerate the training process, enabling rapid validation of new research ideas.


\section{Conclusion}
\label{sec:conclusion}
In this work, we introduce the STP, a novel analytical tool designed to evaluate the effectiveness of benchmarks in assessing the temporal processing capabilities of SNN. Our application of the STP to widely used neuromorphic benchmarks indicates that these benchmarks can often be addressed without modeling the temporal dependencies of distant inputs. This finding suggests a significant deficiency in temporal information within current benchmarks, rendering them inadequate for a comprehensive evaluation of various methods' temporal processing capabilities. 

To further elucidate the current state of SNN approaches in temporal processing, we developed a suite of benchmarks encompassing three distinct temporal processing tasks and conducted a thorough comparison of existing SNN methodologies. Our benchmarking study demonstrated the enhanced temporal processing capabilities of recently introduced spiking neuron models and architectures. However, it also revealed that, despite the significant energy efficiency of SNNs, there remains a notable performance gap compared to SOTA non-spiking sequence models, particularly in the context of long sequences. Moreover, we discuss the challenges and future directions for SNNs in temporal processing, emphasizing the urgent need for the development of specialized neuromorphic benchmarks, learning algorithms, and computational models specifically tailored to real-world temporal processing tasks.


\bibliographystyle{IEEEtran}
\bibliography{myRefs}

% \vspace{-5mm}

% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in, trim= 0 40 0 20, clip]{Biography/MaCX.pdf}}]{Chenxiang Ma} received the M.E. degree in computer science from Tianjin University, Tianjin, China, in 2022. He is currently pursuing the Ph.D. degree with the Department of Computing, The Hong Kong Polytechnic University, Hong Kong SAR, China. His current research interests include spiking neural networks, neuromorphic computing, and efficient artificial intelligence.
% \end{IEEEbiography}

% \vspace{-5mm}

% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in]{Biography/xinyi_chen.jpg}}]{Xinyi Chen} received the B.E. and M.Sc degree in Control Science and Engineering from Zhejiang University, China in 2019 and 2022, respectively. She is currently a Ph.D. candidate at the Department of Data Science and Artificial Intelligence, The Hong Kong Polytechnic University. Her research interests include Brain-inspired Machine Intelligence, Spiking Neural Networks, and Neuromorphic Computing.
% \end{IEEEbiography}

% \vspace{-5mm}


% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in, trim= 0 0 0 0, clip]{Biography/yanchen_li.jpg}}]{Yanchen Li} received the B.Eng. degree from the China University of Petroleum (East China), Qingdao, China, in 2021, and the M.Phil. degree from the Southern University of Science and Technology, Shenzhen, China, in 2024. He is currently pursuing the Ph.D. degree at the Department of Data Science and Artificial Intelligence, The Hong Kong Polytechnic University, where his research includes brain-inspired computing and machine learning systems.
% \end{IEEEbiography}

% \vspace{-5mm}

% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in, trim= 0 0 0 0, clip]{Biography/qu_yang.jpg}}]{Qu Yang} 
% received the B.Eng. and M.Sc degrees in electrical engineering from the National University of Singapore, Singapore, in 2016 and 2019, respectively. She graduated with a Ph.D. in electrical engineering from the National University of Singapore in 2024. Her current research interests include neuromorphic computing, speech processing, and large language models (LLM).
% \end{IEEEbiography}

% \vspace{-5mm}


% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in, trim= 1.5 2 1.5 1.5, clip]{Biography/yujie_wu.jpg}}]{Yujie Wu} 
% is currently a Research Assistant Professor in the Department of Computing at Hong Kong Polytechnic University. He received his B.E. degree from Lanzhou University, China, in 2016, and his Ph.D degree from Tsinghua University, Beijing, China, in 2021. From 2021 to 2024, he was a Postdoctoral Fellow at the Institute of Theoretical Computer Science at Graz University of Technology, Austria. His research interests include artificial general intelligence, computational neuroscience and neuromorphic computing. In the past five years, he has published more than 20 papers in renowned journals such as Nature, Science Robotics, Nature Communications, and Nature Computational Science.
% \end{IEEEbiography}

% \vspace{-5mm}


% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in, trim= 0 0 0 0, clip]{Biography/guoqi_li.jpg}}]{Guoqi Li}(Member, IEEE) 
% received the Ph.D. degree from Nanyang Technological University, Singapore, in 2011. From 2011 to 2014, he was a Scientist with the Data Storage Institute and the Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore. From 2014-2022, he was an Assistant professor and Associate professor at Tsinghua University, Beijing, China. Since 2022,he has been with the Institute of Automation, Chinese Academy of Sciences and the University of Chinese Academy of Sciences, where he is currently a Full professor. His current research interests include Brain-inspired Intelligence, Neuromorphic Computing and Spiking Neural Networks. He has authored or co-authored more than 170 papers in a number of prestigious journals including Nature, Nature Communications, Science Robotics, Proceedings of the IEEE, and top AI conference such as ICLR, NeurIPS, ICML, AAAI and so on. 

% Dr. Li has been actively involved in professional services such as serving as a Tutorial Chair, an International Technical Program Committee Member, a PC member, a Publication Chair, a Track Chair and workshop chair for several international conferences. He is an Editorial-Board Member for Control and Decision, and served as Associate Editors for Journal of Control and Decision and Frontiers in Neuroscience: Neuromorphic Engineering. He is a reviewer for Mathematical Reviews published by the American Mathematical Society and serves as a reviewer for a number of prestigious international journals and top AI conferences including ICLR, NeurIPS, ICML, AAAI and so on. He was the recipient of the 2018 First Class Prize in Science and Technology of the Chinese Institute of Command and Control, the Top ten scientific advances Award in China selected by the Ministry of science and technology, P.R. China as the backbone of the team member, and the 2020 Second Prize of Fujian Provincial Science and Technology Progress Award. He received the outstanding Young Talent Award of the Beijing Natural Science Foundation in 2021.

% \end{IEEEbiography}

% \vspace{-10mm}

% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in, trim= 0 0 0 0, clip]{Biography/gang_pan.jpg}}]{Gang Pan}(Senior Member, IEEE) 
% received the B.Eng. and Ph.D. degrees from Zhejiang University, Hangzhou, China, in 1998 and 2004, respectively. He is currently a Distinguished Professor with the College of Computer Science and Technology, Zhejiang University, where he is also the Director of the State Key Laboratory of Brain-Machine Intelligence. He has authored or coauthored more than 150 refereed papers, and has more than 70 patents granted. His research interests include brain-machine interfaces, brain-inspired computing, artificial intelligence, and pervasive computing. Dr. Pan has been honored with the NSFC Distinguished Young Scholars, IEEE TCSC Award for Excellence (Middle Career Researcher), and CCF-IEEE CS Young Scientist Award. He was also the recipient of the National Science and Technology Progress Award, two test-of-time paper awards, and several best paper awards. He is an Associate Editor for multiple prestigious journals including IEEE Transactions on Neural Networks and Learning Systems, and Coginative Neurodynamics.
% \end{IEEEbiography}

% \vspace{-5mm}

% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in, trim= 0 0 0 0, clip]{Biography/huajin_tang.jpg}}]{Huajin Tang}(Senior Member, IEEE) 
% received the B.E. degree from Zhejiang University, Hangzhou, China, in 1998, the M.E. degree from Shanghai Jiao Tong University, Shanghai, China, in 2001, and the Ph.D. degree from the National University of Singapore, Singapore, in 2005. He was a System Engineer with ST Microelectronics, Singapore, from 2004 to 2006. From 2006 to 2008, he was a Postdoctoral Fellow with the Queensland Brain Institute, University of Queensland, Brisbane, QLD, Australia. Since 2008, he has been the Head of the Robotic Cognition Laboratory, Institute for Infocomm Research, A*STAR, Singapore. He is currently a Professor with the College of Computer Science and Technology, Zhejiang University. His research interests include neuromorphic computing and robotic cognition. 

% Dr. Tang was the recipient of the 2016 IEEE Outstanding TNNLS Paper Award, 2019 IEEE Computational Intelligence Magazine Outstanding Paper Award, and 2023 Neural Networks Best Paper Award. He was an Associate Editor for IEEE Transactions on Neural Networks and Learning Systems, Frontiers in Neuromorphic Engineering, and Neural Networks. He is the EIC of IEEE Transactions on Cognitive and Developmental Systems, and also a Board of Governor Member of the International Neural Networks Society.

% \end{IEEEbiography}

% \vspace{-5mm}

% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in]{Biography/kctan.jpg}}]{Kay Chen Tan} 
% (Fellow, IEEE) received the B.Eng. degree (First Class Hons.) and the Ph.D. degree from the University of Glasgow, U.K., in 1994 and 1997, respectively. He is currently the Head and Chair Professor (Computational Intelligence) of the Department of Data Science and Artificial Intelligence, The Hong Kong Polytechnic University. He was the Editor-in-Chief of IEEE Transactions on Evolutionary Computation, and currently serves on the Editorial Board member of 10+ journals. He is currently an Honorary Professor at University of Nottingham in UK, and the Chief Co-Editor of Springer Book Series on Machine Learning: Foundations, Methodologies, and Applications. He is an IEEE Fellow.
% \end{IEEEbiography}

% \vspace{-5mm}

% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in]{Biography/jibin_wu.jpg}}]{Jibin Wu}(Member, IEEE)  
% received the B.E. and Ph.D degree in Electrical Engineering from National University of Singapore, Singapore in 2016 and 2020, respectively. Dr. Wu is currently an Assistant Professor in the Department of Data Science and Artificial Intelligence, The Hong Kong Polytechnic University. His research interests broadly include brain-inspired artificial intelligence, neuromorphic computing, computational audition, speech processing, and machine learning. 

% Dr. Wu has published over 40 papers in prestigious conferences and journals in artificial intelligence and speech processing, including NeurIPS, ICLR, AAAI, TPAMI, TNNLS, TASLP, and IEEE JSTSP. He is currently serving as the Associate Editors for IEEE Transactions on Neural Networks and Learning Systems and IEEE Transactions on Cognitive and Developmental Systems.
% \end{IEEEbiography}

\clearpage
\onecolumn
\input{appendix.tex}

% \section{Biography Section}
% If you have an EPS/PDF photo (graphicx package needed), extra braces are
%  needed around the contents of the optional argument to biography to prevent
%  the LaTeX parser from getting confused when it sees the complicated
%  $\backslash${\tt{includegraphics}} command within an optional argument. (You can create
%  your own custom macro containing the $\backslash${\tt{includegraphics}} command to make things
%  simpler here.)
 
% \vspace{11pt}

% \bf{If you include a photo:}\vspace{-33pt}
% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{fig1}}]{Michael Shell}
% Use $\backslash${\tt{begin\{IEEEbiography\}}} and then for the 1st argument use $\backslash${\tt{includegraphics}} to declare and link the author photo.
% Use the author name as the 3rd argument followed by the biography text.
% \end{IEEEbiography}

% \vspace{11pt}

% \bf{If you will not include a photo:}\vspace{-33pt}
% \begin{IEEEbiographynophoto}{John Doe}
% Use $\backslash${\tt{begin\{IEEEbiographynophoto\}}} and the author name as the argument followed by the biography text.
% \end{IEEEbiographynophoto}




\vfill

\end{document}


