\begin{algorithm}
    \caption{Speech-FT Procedure}
    \label{alg:speech-ft}
    \begin{algorithmic}[1]
        \STATE \textbf{Input:} Pre-trained model weights $\theta_0$, task prediction model $D$, fine-tuning task $\hat{t}$, scaling factor $\alpha$, stable fine-tuning rate $\beta$, total fine-tuning steps $S$
        \STATE \textbf{Output:} Fine-tuned model weights $\hat{\theta}$

        \STATE \textbf{Step 1: Freeze Downsampling Module}
        \STATE Load the pre-trained model with weights $\theta_0$
        \STATE Freeze the downsampling module

        \STATE \textbf{Step 2: Stable Fine-tuning on Task $\hat{t}$}
        \FOR{step $t = 1$ to $S$}
            \IF{$t \leq \beta \% \cdot S$}
                \STATE Update only the task prediction model $D$
            \ELSE
                \STATE Update the entire model except the downsampling module
            \ENDIF
        \ENDFOR

        \STATE \textbf{Step 3: Weight Space Interpolation}
        \STATE Let $\theta'$ be the model weights after fine-tuning
        \STATE Compute the merged model weights using linear interpolation:
        \[
            \hat{\theta} = (1 - \alpha) \cdot \theta_0 + \alpha \cdot \theta'
        \]
        \vspace{-2em}
        \STATE \textbf{Return} $\hat{\theta}$
        
    \end{algorithmic}
\end{algorithm}
