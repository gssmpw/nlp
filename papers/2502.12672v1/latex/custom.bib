@article{kulshreshtha2024sequential,
  title={Sequential editing for lifelong training of speech recognition models},
  author={Kulshreshtha, Devang and Dingliwal, Saket and Houston, Brady and Pappas, Nikolaos and Ronanki, Srikanth},
  journal={Interspeech},
  year={2024}
}
@inproceedings{li2022massively,
  title={Massively multilingual asr: A lifelong learning solution},
  author={Li, Bo and Pang, Ruoming and Zhang, Yu and Sainath, Tara N and Strohman, Trevor and Haghani, Parisa and Zhu, Yun and Farris, Brian and Gaur, Neeraj and Prasad, Manasa},
  booktitle={ICASSP},
  year={2022}
}
@article{houston2020continual,
  title={Continual learning for multi-dialect acoustic models},
  author={Houston, Brady and Kirchhoff, Katrin},
  journal={Interspeech},
  year={2020}
}
@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Neurips},
  year={2020}
}
@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={TASLP},
  year={2021}
}
@article{chen2022wavlm,
  title={Wavlm: Large-scale self-supervised pre-training for full stack speech processing},
  author={Chen, Sanyuan and Wang, Chengyi and Chen, Zhengyang and Wu, Yu and Liu, Shujie and Chen, Zhuo and Li, Jinyu and Kanda, Naoyuki and Yoshioka, Takuya and Xiao, Xiong and others},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  year={2022}
}
@article{chung2019unsupervised,
  title={An unsupervised autoregressive model for speech representation learning},
  author={Chung, Yu-An and Hsu, Wei-Ning and Tang, Hao and Glass, James},
  journal={Interspeech},
  year={2019}
}
@article{ling2020decoar,
  title={Decoar 2.0: Deep contextualized acoustic representations with vector quantization},
  author={Ling, Shaoshi and Liu, Yuzong},
  journal={arXiv preprint arXiv:2012.06659},
  year={2020}
}
@article{tang2023salmonn,
  title={Salmonn: Towards generic hearing abilities for large language models},
  author={Tang, Changli and Yu, Wenyi and Sun, Guangzhi and Chen, Xianzhao and Tan, Tian and Li, Wei and Lu, Lu and Ma, Zejun and Zhang, Chao},
  journal={ICLR},
  year={2023}
}
@article{lu2024desta,
  title={Desta: Enhancing speech language models through descriptive speech-text alignment},
  author={Lu, Ke-Han and Chen, Zhehuai and Fu, Szu-Wei and Huang, He and Ginsburg, Boris and Wang, Yu-Chiang Frank and Lee, Hung-yi},
  journal={Interspeech},
  year={2024}
}
@article{chu2024qwen2,
  title={Qwen2-audio technical report},
  author={Chu, Yunfei and Xu, Jin and Yang, Qian and Wei, Haojie and Wei, Xipin and Guo, Zhifang and Leng, Yichong and Lv, Yuanjun and He, Jinzheng and Lin, Junyang and others},
  journal={arXiv preprint arXiv:2407.10759},
  year={2024}
}
@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  year={2017}
}
@article{chen2021speech,
  title={Speech representation learning through self-supervised pretraining and multi-task finetuning},
  author={Chen, Yi-Chen and Yang, Shu-wen and Lee, Cheng-Kuang and See, Simon and Lee, Hung-yi},
  journal={arXiv preprint arXiv:2110.09930},
  year={2021}
}
@inproceedings{getman2024happens,
  title={What happens in continued pre-training? Analysis of self-supervised speech models with continued pre-training for colloquial Finnish ASR},
  author={Getman, Yaroslav and Gr{\'o}sz, Tam{\'a}s and Kurimo, Mikko},
  booktitle={Interspeech},
  year={2024}
}
@article{yang2021superb,
  title={Superb: Speech processing universal performance benchmark},
  author={Yang, Shu-wen and Chi, Po-Han and Chuang, Yung-Sung and Lai, Cheng-I Jeff and Lakhotia, Kushal and Lin, Yist Y and Liu, Andy T and Shi, Jiatong and Chang, Xuankai and Lin, Guan-Ting and others},
  journal={Interspeech},
  year={2021}
}
@article{tsai2022superb,
  title={SUPERB-SG: Enhanced speech processing universal performance benchmark for semantic and generative capabilities},
  author={Tsai, Hsiang-Sheng and Chang, Heng-Jui and Huang, Wen-Chin and Huang, Zili and Lakhotia, Kushal and Yang, Shu-wen and Dong, Shuyan and Liu, Andy T and Lai, Cheng-I Jeff and Shi, Jiatong and others},
  journal={ACL},
  year={2022}
}
@inproceedings{feng2023superb,
  title={Superb@ slt 2022: Challenge on generalization and efficiency of self-supervised speech representation learning},
  author={Feng, Tzu-hsun and Dong, Annie and Yeh, Ching-Feng and Yang, Shu-wen and Lin, Tzu-Quan and Shi, Jiatong and Chang, Kai-Wei and Huang, Zili and Wu, Haibin and Chang, Xuankai and others},
  booktitle={SLT},
  year={2023}
}
@article{mohamed2022self,
  title={Self-supervised speech representation learning: A review},
  author={Mohamed, Abdelrahman and Lee, Hung-yi and Borgholt, Lasse and Havtorn, Jakob D and Edin, Joakim and Igel, Christian and Kirchhoff, Katrin and Li, Shang-Wen and Livescu, Karen and Maal{\o}e, Lars and others},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  year={2022}
}
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  year={2021}
}
@inproceedings{wortsman2022robust,
  title={Robust fine-tuning of zero-shot models},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Kim, Jong Wook and Li, Mike and Kornblith, Simon and Roelofs, Rebecca and Lopes, Raphael Gontijo and Hajishirzi, Hannaneh and Farhadi, Ali and Namkoong, Hongseok and others},
  booktitle={ICML},
  year={2022}
}
@article{kumar2022fine,
  title={Fine-tuning can distort pretrained features and underperform out-of-distribution},
  author={Kumar, Ananya and Raghunathan, Aditi and Jones, Robbie and Ma, Tengyu and Liang, Percy},
  journal={ICML},
  year={2022}
}
@inproceedings{wortsman2022model,
  title={Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Gadre, Samir Ya and Roelofs, Rebecca and Gontijo-Lopes, Raphael and Morcos, Ari S and Namkoong, Hongseok and Farhadi, Ali and Carmon, Yair and Kornblith, Simon and others},
  booktitle={ICML},
  year={2022}
}
@inproceedings{rame2023model,
  title={Model ratatouille: Recycling diverse models for out-of-distribution generalization},
  author={Ram{\'e}, Alexandre and Ahuja, Kartik and Zhang, Jianyu and Cord, Matthieu and Bottou, L{\'e}on and Lopez-Paz, David},
  booktitle={ICML},
  year={2023}
}
@inproceedings{lin2024mitigating,
  title={Mitigating the alignment tax of rlhf},
  author={Lin, Yong and Lin, Hangyu and Xiong, Wei and Diao, Shizhe and Liu, Jianmeng and Zhang, Jipeng and Pan, Rui and Wang, Haoxiang and Hu, Wenbin and Zhang, Hanning and others},
  booktitle={EMNLP},
  year={2024}
}
@article{ilharco2022editing,
  title={Editing models with task arithmetic},
  author={Ilharco, Gabriel and Ribeiro, Marco Tulio and Wortsman, Mitchell and Gururangan, Suchin and Schmidt, Ludwig and Hajishirzi, Hannaneh and Farhadi, Ali},
  journal={arXiv preprint arXiv:2212.04089},
  year={2022}
}
@article{tomihari2024understanding,
  title={Understanding Linear Probing then Fine-tuning Language Models from NTK Perspective},
  author={Tomihari, Akiyoshi and Sato, Issei},
  journal={Neurips},
  year={2024}
}
@inproceedings{lin2023melhubert,
  title={Melhubert: A simplified hubert on mel spectrograms},
  author={Lin, Tzu-Quan and Lee, Hung-yi and Tang, Hao},
  booktitle={ASRU},
  year={2023}
}
@inproceedings{wang2023minisuperb,
  title={Minisuperb: Lightweight benchmark for self-supervised speech models},
  author={Wang, Yu-Hsiang and Chen, Huang-Yu and Chang, Kai-Wei and Hsu, Winston and Lee, Hung-yi},
  booktitle={ASRU},
  year={2023}
}
@article{garofolo1993darpa,
  title={DARPA TIMIT acoustic-phonetic continous speech corpus CD-ROM. NIST speech disc 1-1.1},
  author={DARPA-ISTO},
  journal={NASA STI/Recon technical report n},
  year={1993}
}
@inproceedings{panayotov2015librispeech,
  title={Librispeech: an asr corpus based on public domain audio books},
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={ICASSP},
  year={2015}
}
@article{cao2014crema,
  title={Crema-d: Crowd-sourced emotional multimodal actors dataset},
  author={Cao, Houwei and Cooper, David G and Keutmann, Michael K and Gur, Ruben C and Nenkova, Ani and Verma, Ragini},
  journal={IEEE transactions on affective computing},
  year={2014}
}
@inproceedings{rousseau2012ted,
  title={TED-LIUM: an Automatic Speech Recognition dedicated corpus.},
  author={Rousseau, Anthony and Del{\'e}glise, Paul and Esteve, Yannick},
  booktitle={LREC},
  year={2012}
}
@article{nagrani2020voxceleb,
  title={Voxceleb: Large-scale speaker verification in the wild},
  author={Nagrani, Arsha and Chung, Joon Son and Xie, Weidi and Zisserman, Andrew},
  journal={Computer Speech \& Language},
  year={2020}
}
@article{busso2008iemocap,
  title={IEMOCAP: Interactive emotional dyadic motion capture database},
  author={Busso, Carlos and Bulut, Murtaza and Lee, Chi-Chun and Kazemzadeh, Abe and Mower, Emily and Kim, Samuel and Chang, Jeannette N and Lee, Sungbok and Narayanan, Shrikanth S},
  journal={Language resources and evaluation},
  year={2008}
}
@article{yadav2024ties,
  title={Ties-merging: Resolving interference when merging models},
  author={Yadav, Prateek and Tam, Derek and Choshen, Leshem and Raffel, Colin A and Bansal, Mohit},
  journal={Neurips},
  year={2024}
}
@article{shi2020aishell,
  title={Aishell-3: A multi-speaker mandarin tts corpus and the baselines},
  author={Shi, Yao and Bu, Hui and Xu, Xin and Zhang, Shaoji and Li, Ming},
  journal={arXiv preprint arXiv:2010.11567},
  year={2020}
}
@article{lin2024daisy,
  title={DAISY: Data Adaptive Self-Supervised Early Exit for Speech Representation Models},
  author={Lin, Tzu-Quan and Lee, Hung-yi and Tang, Hao},
  journal={Interpseech},
  year={2024}
}
@article{ardila2019common,
  title={Common voice: A massively-multilingual speech corpus},
  author={Ardila, Rosana and Branson, Megan and Davis, Kelly and Henretty, Michael and Kohler, Michael and Meyer, Josh and Morais, Reuben and Saunders, Lindsay and Tyers, Francis M and Weber, Gregor},
  journal={LREC},
  year={2020}
}
@inproceedings{plantinga2024parameter,
  title={Parameter Averaging Is All You Need To Prevent Forgetting},
  author={Plantinga, Peter and Yoo, Jaekwon and Girma, Abenezer and Dhir, Chandra},
  booktitle={SLT},
  year={2024}
}
@inproceedings{ramesh2024task,
  title={Task Vector Algebra for ASR Models},
  author={Ramesh, Gowtham and Audhkhasi, Kartik and Ramabhadran, Bhuvana},
  booktitle={ICASSP},
  year={2024}
}
@article{murata2024attribute,
  title={An attribute interpolation method in speech synthesis by model merging},
  author={Murata, Masato and Miyazaki, Koichi and Koriyama, Tomoki},
  journal={Interspeech},
  year={2024}
}
@article{cheng2024task,
  title={Task Arithmetic for Language Expansion in Speech Translation},
  author={Cheng, Yao-Fei and Futami, Hayato and Kashiwagi, Yosuke and Tsunoo, Emiru and Teo, Wen Shen and Arora, Siddhant and Watanabe, Shinji},
  journal={arXiv preprint arXiv:2409.11274},
  year={2024}
}
@article{shi2023multi,
  title={Multi-resolution HuBERT: Multi-resolution speech self-supervised learning with masked unit prediction},
  author={Shi, Jiatong and Inaguma, Hirofumi and Ma, Xutai and Kulikov, Ilia and Sun, Anna},
  journal={ICLR},
  year={2023}
}
@article{yang2024large,
  title={A Large-Scale Evaluation of Speech Foundation Models},
  author={Yang, Shu-wen and Chang, Heng-Jui and Huang, Zili and Liu, Andy T and Lai, Cheng-I and Wu, Haibin and Shi, Jiatong and Chang, Xuankai and Tsai, Hsiang-Sheng and Huang, Wen-Chin and others},
  journal={TASLP},
  year={2024}
}
@article{lopes2011phone,
  title={Phone recognition on the TIMIT database},
  author={Lopes, Carla and Perdigao, Fernando},
  journal={Speech Technologies/Book},
  year={2011}
}
@article{wu2024emo,
  title={EMO-SUPERB: An in-depth look at speech emotion recognition},
  author={Wu, Haibin and Chou, Huang-Cheng and Chang, Kai-Wei and Goncalves, Lucas and Du, Jiawei and Jang, Jyh-Shing Roger and Lee, Chi-Chun and Lee, Hung-Yi},
  journal={arXiv preprint arXiv:2402.13018},
  year={2024}
}
@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}
@inproceedings{graves2006connectionist,
  title={Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks},
  author={Graves, Alex and Fern{\'a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
  booktitle={ICML},
  year={2006}
}
@inproceedings{yang2023fast,
  title={Fast-Hubert: an Efficient Training Framework for Self-Supervised Speech Representation Learning},
  author={Yang, Guanrou and Ma, Ziyang and Zheng, Zhisheng and Song, Yakun and Niu, Zhikang and Chen, Xie},
  booktitle={ASRU},
  year={2023}
}
@article{lin2023spurious,
  title={Spurious feature diversification improves out-of-distribution generalization},
  author={Lin, Yong and Tan, Lu and Hao, Yifan and Wong, Honam and Dong, Hanze and Zhang, Weizhong and Yang, Yujiu and Zhang, Tong},
  journal={ICLR},
  year={2024}
}
@article{wang2023task,
  title={Task-agnostic structured pruning of speech representation models},
  author={Wang, Haoyu and Wang, Siyuan and Zhang, Wei-Qiang and Suo, Hongbin and Wan, Yulong},
  journal={Interspeech},
  year={2023}
}
@article{shi2023ml,
  title={Ml-superb: Multilingual speech universal performance benchmark},
  author={Shi, Jiatong and Berrebbi, Dan and Chen, William and Chung, Ho-Lam and Hu, En-Pei and Huang, Wei Ping and Chang, Xuankai and Li, Shang-Wen and Mohamed, Abdelrahman and Lee, Hung-yi and others},
  journal={Interspeech},
  year={2023}
}
@inproceedings{shi2023findings,
  title={Findings of the 2023 ml-superb challenge: Pre-training and evaluation over more languages and beyond},
  author={Shi, Jiatong and Chen, William and Berrebbi, Dan and Wang, Hsiu-Hsuan and Huang, Wei-Ping and Hu, En-Pei and Chuang, Ho-Lam and Chang, Xuankai and Tang, Yuxun and Li, Shang-Wen and others},
  booktitle={ASRU},
  year={2023}
}
@inproceedings{huang2023ensemble,
  title={Ensemble knowledge distillation of self-supervised speech models},
  author={Huang, Kuan-Po and Feng, Tzu-Hsun and Fu, Yu-Kuan and Hsu, Tsu-Yuan and Yen, Po-Chieh and Tseng, Wei-Cheng and Chang, Kai-Wei and Lee, Hung-Yi},
  booktitle={ICASSP},
  year={2023}
}
@inproceedings{chang2024colld,
  title={COLLD: Contrastive Layer-to-Layer Distillation for Compressing Multilingual Pre-Trained Speech Encoders},
  author={Chang, Heng-Jui and Dong, Ning and Mavlyutov, Ruslan and Popuri, Sravya and Chung, Yu-An},
  booktitle={ICASSP},
  year={2024}
}
@inproceedings{lai2021semi,
  title={Semi-supervised spoken language understanding via self-supervised speech and language model pretraining},
  author={Lai, Cheng-I and Chuang, Yung-Sung and Lee, Hung-Yi and Li, Shang-Wen and Glass, James},
  booktitle={ICASSP},
  year={2021}
}