@article{cheng2024task,
  title={Task Arithmetic for Language Expansion in Speech Translation},
  author={Cheng, Yao-Fei and Futami, Hayato and Kashiwagi, Yosuke and Tsunoo, Emiru and Teo, Wen Shen and Arora, Siddhant and Watanabe, Shinji},
  journal={arXiv preprint arXiv:2409.11274},
  year={2024}
}

@article{houston2020continual,
  title={Continual learning for multi-dialect acoustic models},
  author={Houston, Brady and Kirchhoff, Katrin},
  journal={Interspeech},
  year={2020}
}

@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  year={2017}
}

@article{kulshreshtha2024sequential,
  title={Sequential editing for lifelong training of speech recognition models},
  author={Kulshreshtha, Devang and Dingliwal, Saket and Houston, Brady and Pappas, Nikolaos and Ronanki, Srikanth},
  journal={Interspeech},
  year={2024}
}

@article{kumar2022fine,
  title={Fine-tuning can distort pretrained features and underperform out-of-distribution},
  author={Kumar, Ananya and Raghunathan, Aditi and Jones, Robbie and Ma, Tengyu and Liang, Percy},
  journal={ICML},
  year={2022}
}

@inproceedings{li2022massively,
  title={Massively multilingual asr: A lifelong learning solution},
  author={Li, Bo and Pang, Ruoming and Zhang, Yu and Sainath, Tara N and Strohman, Trevor and Haghani, Parisa and Zhu, Yun and Farris, Brian and Gaur, Neeraj and Prasad, Manasa},
  booktitle={ICASSP},
  year={2022}
}

@article{murata2024attribute,
  title={An attribute interpolation method in speech synthesis by model merging},
  author={Murata, Masato and Miyazaki, Koichi and Koriyama, Tomoki},
  journal={Interspeech},
  year={2024}
}

@inproceedings{plantinga2024parameter,
  title={Parameter Averaging Is All You Need To Prevent Forgetting},
  author={Plantinga, Peter and Yoo, Jaekwon and Girma, Abenezer and Dhir, Chandra},
  booktitle={SLT},
  year={2024}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  year={2021}
}

@inproceedings{ramesh2024task,
  title={Task Vector Algebra for ASR Models},
  author={Ramesh, Gowtham and Audhkhasi, Kartik and Ramabhadran, Bhuvana},
  booktitle={ICASSP},
  year={2024}
}

@inproceedings{wortsman2022model,
  title={Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Gadre, Samir Ya and Roelofs, Rebecca and Gontijo-Lopes, Raphael and Morcos, Ari S and Namkoong, Hongseok and Farhadi, Ali and Carmon, Yair and Kornblith, Simon and others},
  booktitle={ICML},
  year={2022}
}

@inproceedings{wortsman2022robust,
  title={Robust fine-tuning of zero-shot models},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Kim, Jong Wook and Li, Mike and Kornblith, Simon and Roelofs, Rebecca and Lopes, Raphael Gontijo and Hajishirzi, Hannaneh and Farhadi, Ali and Namkoong, Hongseok and others},
  booktitle={ICML},
  year={2022}
}

