\section{Introduction}
\label{sec:introduction}

\begin{flushleft}
\leftskip=1cm\emph{``Don't teach. Incentivize.''} \\
\vspace{.3em}
\leftskip=4.55cm---\emph{Hyung Won Chung, OpenAI}
\end{flushleft}



\IEEEPARstart{A}{chieving} human-level intelligence requires refining the transition from \textit{System 1} to \textit{System 2} reasoning \cite{hua2022system, wei2022chain, wangself, zhouleast, zelikman2024star}. 
Dual-system theory suggests that human cognition operates through two modes: \textit{System 1}, which is fast, automatic, and intuitive, enabling quick decisions with minimal effort, and \textit{System 2}, which is slower, more analytical, and deliberate \cite{evans1984heuristic, kahneman2003maps}. 
While \textit{System 1} is efficient for routine tasks, it is prone to cognitive biases, especially in complex or uncertain situations, leading to judgment errors. 
In contrast, \textit{System 2} relies on logical reasoning and systematic thinking, resulting in more accurate and rational decisions \cite{huang2023towards, qiao2023reasoning, wang2023towards, shaikh2023second}. 
By mitigating the biases of \textit{System 1}, \textit{System 2} provides a more refined approach to problem-solving \cite{shao2024visual, zhangautomatic, hao2023reasoning, zhang2023meta}.


%across diverse domains

The development of foundational Large Language Models (LLMs)\footnote{In this paper, ``reasoning'' refers to answering questions involving complex, multi-step processes with intermediate steps. \textbf{Foundational LLMs:} LLMs with basic reasoning abilities, handling simple or single-step tasks. \textbf{Reasoning LLMs:} LLMs that excel in complex tasks like coding and mathematical proofs, incorporating a ``thinking'' process\textendash tasks that foundational LLMs struggle with.} has marked a major milestone in Artificial Intelligence (AI). 
Models such as GPT-4o \cite{gpt4o-0513} and DeepSeek-v3 \cite{liu2024deepseek} have demonstrated impressive capabilities in text generation, language translation, and a variety of perception tasks \cite{vaswani2017attention, DBLP:conf/naacl/DevlinCLT19, DBLP:journals/corr/abs-1907-11692, radford2018improving, radford2019language, brown2020language, ouyang2022training, touvron2023llama, zhao2023survey, liu2023llava, DBLP:conf/acl/ZhangY0L0C024}. 
These models, trained on extensive datasets and utilizing advanced algorithms, excel in understanding and generating human-like responses. 
However, despite their impressive achievements, foundational LLMs operate in a manner similar to \textit{System 1} reasoning, relying on fast, heuristic-driven decision-making. 
While they perform exceptionally well in providing rapid responses, they often fall short in scenarios requiring deep, logical analysis and precision in complex reasoning tasks. 
This limitation becomes especially clear in situations involving intricate problem-solving, logical analysis, or nuanced understanding, where these models do not yet match human cognitive abilities.

In contrast, reasoning LLMs represent a significant advancement in the evolution of language models. 
Models like OpenAI's o1/o3 \cite{openai_o1, o3-mini} and DeepSeek's R1 \cite{Deepseek-R1} are designed to emulate the slower, more deliberate reasoning associated with \textit{System 2} thinking. 
Unlike foundational LLMs, reasoning LLMs are equipped with mechanisms for processing information step-by-step, allowing them to make more accurate and rational decisions. 
This shift from fast-thinking, intuitive processes to more methodical, reasoning-driven models enables reasoning LLMs to tackle complex tasks, such as advanced mathematics \cite{cobbe2021training, kojima2022large, liu2023improving, zhu2023solving, ludynamic, lightmanlet}, logical reasoning \cite{yao2023thinking, yao2023beyond, wen2023mindmap, lei2023boosting, jin2024impact, besta2024graph, cheng2024self}, and multimodal reasoning \cite{you2023idealgpt, wu2024v, chen2024genome}, with expert-level performance, exhibiting human-like cognitive abilities. 
As a result, reasoning LLMs are increasingly seen as capable of achieving the deep, logical thinking needed for tasks that were once considered beyond AI's reach. 
The recent timeline of reasoning LLMs is presented in Figure \ref{fig:timeline}.

%highlighting core methods and the release of both open-source and closed-source reproduction projects, 

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.94\linewidth]{images/timeline.png}
    \caption{The recent timeline of reasoning LLMs, covering core methods and the release of open-source and closed-source reproduction projects.}
        \label{fig:timeline}
\end{figure*}

%with OpenAI's SuperAlign technology report from November 2023 serving as the starting point



% \begin{figure*}[t]
%     \centering
%     \includegraphics[width=0.95\linewidth]{images/ai_development.pdf}
%     \label{fig:ai_development}
%     \caption{The developmental stages of AI systems. Each stage introduced distinct characteristics, building upon the strengths of its predecessors, and highlights the gradual shift from rapid, intuitive approaches to more deliberate, reasoning-driven models. As AI has evolved, its practical applications have expanded, enabling more versatile and adaptive models for a wide range of real-world scenarios.}
% \end{figure*}

% Following the establishment of Dual-system theory, the development of Artificial Intelligence (AI) systems has mirrored the transition from \textit{System 1} to \textit{System 2} reasoning. 
% Early AI systems were grounded in symbolic logic and expert systems, relying on predefined rules and knowledge bases to make decisions \cite{newell1972human, evans1984heuristic, evans1990belief, luger1998artificial, albar2009heuristics}. These systems excelled in structured, well-defined tasks but struggled with ambiguity and uncertainty. 
% As AI advanced, statistical and probabilistic methods emerged, enabling machines to handle uncertainty and make predictions based on data \cite{jordan1999learning, bishop2006pattern, pearl2014probabilistic}. 
% While these models represented progress, they remained limited by their reliance on statistical patterns and lacked true reasoning capabilities. 
% The introduction of Deep Neural Networks (DNNs) \cite{hinton2006fast, hinton2006reducing, lecun2015deep} represented a significant advancement, enabling AI to achieve remarkable success in domains such as Computer Vision (CV) \cite{lecun1995convolutional, krizhevsky2012imagenet, hinton2012deep, he2016deep, huang2017densely} and Natural Language Processing (NLP) \cite{hochreiter1997long, hochreiter1997long, DBLP:conf/emnlp/ChoMGBBSB14, sutskever2014sequence}. 
% While Deep Learning (DL) models are powerful, they remain heavily reliant on large datasets and pattern recognition. 
% This makes them comparable to \textit{System 1} thinking, characterized by rapid, intuitive decision-making, but lacking the deeper, more deliberate reasoning associated with \textit{System 2}. 
% Despite their success in many applications, these models often struggle with complex, abstract reasoning tasks.



\begin{figure*}[t]
\centering
\resizebox{0.95\textwidth}{!}{\input{trees/tax}}
\caption{The primary organizational structure of the survey.}
\label{fig:structure}
\end{figure*}


\subsection{Structure of the Survey}


This survey offers a comprehensive overview of the key concepts, methods, and challenges involved in the development of reasoning LLMs. 
As illustrated in Figure \ref{fig:structure}, this survey is organized as follows:
\begin{enumerate}[itemindent=0em]

\item Section \ref{early_srs} offers a concise overview of the progress in foundational LLMs (Section \ref{f_llm}) and the early development of key \textit{System 2} technologies, including symbolic logic systems (Section \ref{symb_exp}), Monte Carlo Tree Search (MCTS) (Section \ref{mcts}), and Reinforcement Learning (RL) (Section \ref{rl}), highlighting how their combination has paved the way for reasoning LLMs. 

\item Section \ref{replication} introduces reasoning LLMs and outlines their construction process. 
Specifically, Section \ref{o1_features} presents the characteristics of reasoning LLMs from two perspectives: output behavior (Section \ref{output_behaviour}) and training dynamics (Section \ref{dynamic_perspective}), emphasizing their differences from foundational LLMs. 
Section \ref{foundations} identifies the core methods necessary for achieving advanced reasoning capabilities, focusing on five aspects: Structure Search (Section \ref{structure_search}), Reward Modeling (Section \ref{prm}), Self Improvement (Section \ref{self-improve}), Macro Action (Section \ref{macro_action}), and Reinforcement Fine-Tuning (Section \ref{rl_supervise}). 
Each section delves into the specific characteristics of these methods and introduces representative reasoning LLMs for each approach. 
Section \ref{evolutionary} traces the evolutionary stages of reasoning LLMs. 

\item Section \ref{benchmark} evaluates representative reasoning LLMs. Specifically, Section \ref{benchmark_category} reviews current mainstream reasoning benchmarks, covering both plain text and multimodal benchmarks across various task types. Section \ref{metrics} outlines the current evaluation metrics, while Section \ref{performance_compare} analyzes and compares the performance of mainstream reasoning LLMs with their foundational counterparts based on these benchmarks.

\item Section \ref{future} highlights the limitations of existing reasoning LLMs and outlines several promising future development directions for these models.

\item Finally, we conclude the paper in Section \ref{conclusion} and provide a real-time tracking \href{https://github.com/zzli2022/Awesome-Slow-Reason-System}{{GitHub Repository}} to monitor the latest developments in the field. 

\end{enumerate}
We hope this survey serves as a valuable resource, fostering innovation and progress in this rapidly evolving domain.






% It explores the following Research Questions (RQs):

% \begin{enumerate}[leftmargin=1cm, label=\textbf{RQ\arabic{*}}:]


% \item What is the early development of key technologies in \textit{System 2}, and how have their advancements, especially when integrated with foundational LLMs, paved the way for reasoning LLMs? (Section \ref{early_srs})

% \item What are the features of reasoning LLMs, and how do they differ from foundational LLMs? (Section \ref{o1_features})

% \item What are the key technologies to achieve advanced reasoning capabilities in LLMs? (Section \ref{foundations})

% \item What are the various stages in the development of reasoning LLMs? (Section \ref{evolutionary})

% \item What are the current mainstream reasoning benchmarks? (Section \ref{benchmark_category})

% \item How can reasoning LLMs be evaluated on mainstream reasoning benchmarks, and what evaluation metrics are employed? (Section \ref{metrics})


% \item How do representative reasoning LLMs perform on these reasoning benchmarks? (Section \ref{performance_compare})

% \item What are the current limitations of reasoning LLMs, and what are the potential future directions for their development? (Section \ref{future})

% \end{enumerate}


% the connections and differences between our work and

% \begin{table}[tbp]
%   \centering
%   \caption{Summary of related literature.}
%     \resizebox{0.98\linewidth}{!}{
%     \begin{tabular}{lcl}
%     \toprule[1.2pt]
%     {\textbf{Literature}} & \textbf{Survey} & \textbf{Contribution}  \\
%   % \\ % & LLMs & Train  & Agents \\
%     \hline
    
%       \rowcolor[rgb]{ .949,  .949,  .949}  Wu et al. \cite{Compare_o1} & \redcross & {Comparative Analysis of o1 Model and foundational LLMs.} \\ % A COMPARATIVE STUDY ON REASONING PATTERNS OF OPENAIâ€™S O1 MODEL 

%   Xiang et al. \cite{TowardsSystem2ReasoninLLM} & \redcross & {System-2 LLMs Reproduction Technical Report From Meta-CoT Perspective.}  \\ % Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Thought

%      \rowcolor[rgb]{ .949,  .949,  .949}   Qin et al. \cite{o1_Journey_Part1} & \redcross & {O1 Reproduction Technical Report from Search-based Long-CoT Synthesize.} \\ % O1 Replication Journey: A Strategic Progress Report -- Part 1, ## Enhancing LLM Reasoning with Reward-guided Tree Search

%   Jiang et al. \cite{o1_Journey_Part2} & \redcross & {O1 Reproduction Technical Report From the Perspective of Long-CoT Distillation.}   \\ % O1 Replication Journey--Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesson? ## Imitate, Explore, and Self-Improve: A Reproduction Report on Slow-thinking Reasoning Systems ## redstar: does scaling long-cot data unlock better slow-reasoning systems?

%      \rowcolor[rgb]{ .949,  .949,  .949}   Zeng et al. \cite{Scaling_of_Search_Learning} & \redcross & {O1 Reproduction Technical Report From  Reinforcement Learning Perspective.} \\ % Scaling of Search and Learning: A Roadmap to Reproduce o1 from Reinforcement Learning Perspective

%  Ji et al. \cite{Test_Time_Computing} & \color[RGB]{3,191,61}{\Checkmark} & {A Survey for Test-Time Computing Scaling.}   \\ % Test-time Computing: from System-1 Thinking to System-2 Thinking

%        \rowcolor[rgb]{ .949,  .949,  .949} Xu et al. \cite{LargeReasonModel} & \color[RGB]{3,191,61}{\Checkmark} & {A Survey of Reinforced Reasoning with LLMs.} \\ % Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models
     
%     \hline
%   \textbf{Ours} & \color[RGB]{3,191,61}{\Checkmark} & {A Survey of Reasoning from \textit{System 1} to \textit{System 2} in LLMs.} \\ % 
%     \bottomrule[1.2pt]
%     \end{tabular}%
%     }
%   \label{tab:memory_relatedwork}%
% \end{table}%



\subsection{Contribution of the Survey}



% As shown in Table \ref{tab:memory_relatedwork}, 

Recently, several analyses and replications of specific technical approaches have been conducted \cite{Compare_o1, TowardsSystem2ReasoninLLM, o1_Journey_Part1, o1_Journey_Part2, huang2025o1, Slow_Thinking_with_LLMs_2, RedStar, Scaling_of_Search_Learning}, yet there remains a lack of systematic analysis and organization. 
Research \cite{Test_Time_Computing} has focused only on slow-thinking methods during testing. 
Meanwhile, studies \cite{besta2025reasoning, zhang2024llm, LargeReasonModel} have primarily concentrated on training or achieving reasoning LLMs, often from the perspective of RL.

Our survey distinguishes itself from and contributes to the existing literature in the following ways:
\begin{enumerate}[itemindent=0em]
\item Rather than focusing on a single technical approach, we offer a comprehensive overview of the key concepts, methods, and challenges involved in reasoning LLMs.

\item We summarize the key advancements of early \textit{System 2} and how they have paved the way for reasoning LLMs, specifically in combination with foundational LLMs\textendash a crucial aspect often overlooked in previous works.

\item We present a more thorough and inclusive summary of the core methods necessary for constructing reasoning LLMs, including but not limited to RL.

\end{enumerate}






% A summarized taxonomy of reasoning LLMs is presented in Figure \ref{fig:tax}.

% \subsection{Structure of the Survey}

























