\documentclass[12pt, a4paper]{article}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{microtype}
\usepackage{fancyhdr}


% 页面布局
\usepackage{geometry}
\geometry{left=2.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm}

% 自定义命令
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\text{Var}}

\usepackage{array}
\usepackage{booktabs}
\usepackage{float}
\usepackage{caption}
\usepackage{cite}
\usepackage{amsmath}

\bibliographystyle{abbrvnat}
% \setcitestyle{authoryear}

\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{array}

\usepackage{multirow}
\usepackage{comment}
%\setcitepstyle{authoryear}
\usepackage{mathtools}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\usepackage{amsfonts}
%\usepackage{blindtext}
\usepackage{url}
\usepackage{amsthm}

%\OneAndAHalfSpacedXI
%%\DoubleSpacedXI
%%\DoubleSpacedXII

% Optional LaTeX Packages
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{tikz}
% Private macros here (check that there is no clash with the style)

% Natbib setup for author-number style
\usepackage{natbib}

% 标题和作者
\title{Learning to Collaborate: A Capability Vectors-based Architecture for Adaptive Human-AI Decision Making}

\author{Renlong Jie\thanks{Dr. Renlong Jie is an Associate Professor at the School of Management, Northwestern Polytechnical University, Xi'an, China. Email: jierenlong@nwpu.edu.cn}}



\begin{document}
\maketitle


\begin{abstract}
Human-AI collaborative decision making has emerged as a pivotal field in recent years. Existing methods treat human and AI as different entities when designing human-AI systems. However, as the decision capabilities of AI models becoming closer to human beings, it is necessary to build a uniform framework for capability modeling and ‌integrating. In this study, we propose a general architecture for human-AI collaborative decision making, wherein we employ learnable capability vectors to represent the decision-making capabilities of both human experts and AI models. These capability vectors are utilized to determine the decision weights of multiple decision makers, taking into account the contextual information of each decision task. Our proposed architecture accommodates scenarios involving multiple human-AI decision-makers with varying capabilities. Furthermore, we introduce a learning-free approach to establish a baseline using global collaborative weights. Experiments on image classification and Hatespeech detection demonstrate that our proposed architecture significantly outperform the current state-of-the-art methods in image classification task and sentiment analysis, especially for the case with large non-expertise capability level. Overall, our method provides an effective and robust collaborative decision-making approach that integrates diverse human/AI capabilities within a unified framework.
\end{abstract}


\section{Introduction}

With the fast increasing of AI capability in recent years, human-AI collaborative system has become an important topic of study. Especially in the era of large language models, AI model can do much more language-based tasks with surprisingly high quality \citep{OpenAI2023GPT4}, which makes human-AI collaboration a promising way in improving the productivity in a variety of subjects. 

Existing studies have shown that these collaborative system can provide better decision quality compared with human-only or AI-only systems. For example, in skin cancer recognition, it is found that good quality AI-based support of clinical decision-making improves diagnostic accuracy over that of either AI or human doctors alone, and that the least experienced clinicians gain the most from AI-based support \citep{Tschandl2020Human}. In general image recognition, human-AI collaboration can provide a performance improvement from both human-only or AI-only system through learning to deter \citep{Predict2018Madras, Hussein2020Consistent, verma2022calibrated, Krishnamurthy2023Enhancing} or probability merging \citep{kerrigan2021combining, Singh2023On}. For more complex tasks such as text generation, empirical evidence has shown that human-AI collaboration can improve both the efficiency and quality of writing \citep{Noy2023Experimental}. 

However, most existing studies on collaborative decision-making focus only on a limited subset of scenarios and could fail to generalize across various decision-makers with differing capabilities. Therefore, we argue that it is essential to develop a unified architecture capable of accommodating a wide range of collaborative decision-making scenarios, including multiple decision-makers, output merging, and decision-maker selection. Traditionally, research on human-AI collaborative decision-making treats humans and AI models as independent entities. Yet, recent advancements in AI systems, particularly large language models (LLMs), have led to the acquisition of skill sets that closely resemble those of human decision-makers \citep{OpenAI2023GPT4}. As a result, the gap between the decision-making capabilities of humans and AI is narrowing. In fact, for some particular types of decision tasks, it is even smaller than the difference between different human beings. To uniformly model the decision related capabilities of different humans and AI models, we introduce capability vectors, which is comparable to user embedding in recommendation systems \citep{zhang2019deep}, and can be either pre-defined or learnt. Based on capability vectors, we build a joint collaborative decision making architecture for selection-based decision tasks. This architecture can be applied for the scenario of multiple decision makers, and applies a weighted merging of output vectors from all decision makers involved. Experiments demonstrate the effectiveness of the proposed architecture and use of capability vectors. The main contributions of our study can be given as follows:
\begin{itemize}
\item We introduce the learnable capability vectors to uniformly model the decision related capabilities of both different human experts and different AI models. 
\item We develop a learning method that can train the capability vectors as well as generating the decision weights of a set of decision makers for generating the final decision score.
\item We propose a generalized architecture for hybrid human-AI decision making based on a weighted combination of scores from multiple decision makers, capable of handling the decision of classification or generation models.
\item Additionally, we introduce a learning-free baseline approach by converting model output into a one-hot vector plus random noises, and apply a probabilistic model for searching the optimal global collaborative weights and predicting the final accuracy.
\end{itemize}



\section{Related Works}


\subsection{Collaboration Mechanisms}

Traditionally, many studies on human-AI collaboration focus on using a model to determine whether to apply AI or human experts to get the final decision. \citet{Predict2018Madras} proposed a two-stage framework containing an automated model and an external decision-maker as in rejection learning \citep{Cortes2016Learning, Zhang2023A}, and generalizes rejection learning by considering the effect of other agents in the decision-making process. \citet{Hussein2020Consistent} further explored the method to learn a predictor that can either predict or choose to defer the decision task to a downstream expert. They also developed a novel reduction to cost sensitive learning where a consistent surrogate loss is given. \citet{verma2022calibrated} pointed out that the multi-class framework in \citep{Hussein2020Consistent} is not calibrated with respect to expert correctness, and propose an L2D system based on one-vs-all classifiers that is able to produce calibrated probabilities of expert correctness. Although many studies focus on building calibrated predictors, \citet{vodrahalli2022uncalibrated} show that even when the original AI model is well-calibrated, AI models as more confident than they actually are can improve human-AI performance.
Moreover, \citet{Is2021Bansal} argue that the most accurate AI is not necessary the best teammate in AI advised decision making, and AI systems should be trained in a human-centered manner, directly optimized for team performance. \citet{kerrigan2021combining} develop a set of methods that combine the probabilistic output of a model with the class-level output of a human. They show that the accuracy of the combination model is driven by not only the accuracies of individual human and model, but also by the model's confidence. 

% \citet{Mao2023Two} investigates a two-stage scenario for learning to defer with multiple experts, where a predictor is derived in the first stage by training with a common loss function, and a deferral function is learned in the second stage to assign the most suitable expert to each input.

Some other works are dedicated in the case of ddecision makers. \citet{Hemmer2022Forming} point out that in real-world situations several human experts with varying capabilities may be available, and develop a method that trains a classifier to complement the capabilities of multiple human experts by allocating each instance to the most suitable team member. \citet{Singh2023On} show that combining multiple human labels with the model's probabilistic output can lead to significant improvement in accuracy, which is achieved by an approach to merge the predicted labels from multiple humans with the model's probabilistic output. 
\citet{da2020harnessing} investigates how herding behavior affects the accuracy of consensus forecasts on a crowd-based corporate earnings platform, and concludes that encouraging independent forecasting and limiting information access can enhance the wisdom of crowds. \citet{he2022wisdom} conducts a comprehensive comparison of 58 prominent models of risky choice using 19 behavioral datasets, revealing that model crowds outperform individual models in predicting choice behavior, suggesting that combining multiple models provides a more accurate understanding of decision-making processes.
\citet{zou2024} introduces a
statistical method for assessing ensembles of any size and
investigates the optimal human-machine ratio as well as the
impact of ensemble size on the performance of human-machine
collaboration. \citet{Mao2023Principled} presents a study of surrogate losses and algorithms for the general problem of learning to defer with multiple experts.
% , and developed a new family of surrogate losses specifically tailored for the multiple-expert setting. 
\citet{mao2024two} further explores a two-stage learning scenario for deferring decisions to multiple experts, where a predictor is trained using a common loss function, and subsequently a deferral function is learned to assign inputs to the most suitable expert. 

% \citet{Gupta2023Take} propose a technique that optimizes the cost of seeking the expert's advice while using the AI model to improve accuracy, where both the expert's cost for each prediction and the misclassification cost of the combined human-AI model are considered. 

% \citet{Cao2023In} point out that the popular estimators for learning to defer parameterized with softmax provide unbounded estimates for the likelihood of deferring which makes them uncalibrated. They show that the cause of this issue is due to the symmetric nature of the surrogate losses used and not due to softmax, and propose a novel statistically consistent asymmetric softmax-based surrogate loss that can produce valid estimates without the issue of unboundedness. 

Some papers focus on theoretical analysis of collaborative decision making. \citet{lamberson2012optimal} analyzes the optimal composition of a forecasting group based on type coherence, where forecasters of the same type share expected accuracy and higher covariance. \citet{steyvers2022bayesian} presents a Bayesian framework for integrating predictions and confidence scores from both humans and AI algorithms to enhance performance in classification tasks, which demonstrates that hybrid systems can outperform individual human or machine predictions even if their accuracy levels differ, as long as these differences are within a certain bound. \citet{zou2024} explores the dynamics of multi-human and multi-machine interactions within hybrid human-machine systems and introduces a novel statistical framework to assess integration accuracy. 

\subsection{Capability Modeling.}

There exists many metrics for evaluating human capabilities. 
For instance, the Intelligence Quotient (IQ) and Emotional Intelligence Quotient (EQ) are widely utilized to quantify the two major aspects of human intelligence \citep{1945The, Mayer2001Emotional}. In addition to these single-value metrics, various studies have employed multi-dimensional representations to model human personality traits, such as the Big Five personality model and the Myers-Briggs Type Indicator \citep{Goldberg1990An, pittenger1993measuring, Myers1999MBTI}. 
% There are also language tests TOFEL, IELTS, PETS, and professional competence tests such as Bar Exam and CPA exam, which also evaluate human's capabilities in different fields. 
Furthermore, language proficiency assessments like TOEFL, IELTS, and PETS, along with professional competency examinations such as the Bar Exam and CPA exam, evaluate human capabilities across different domains. Simultaneously, there is a growing body of research focused on assessing the capabilities of AI models. Task-specific models are typically evaluated using metrics relevant to their respective tasks, such as accuracy or recall for classification tasks, and BLEU or ROUGE scores for language generation tasks. For models designed to perform multiple tasks, their capabilities can be assessed through a combination of metrics derived from these various tasks.
% For task-specific models, they can generally be evaluated by corresponding task-related metrics, such as accuracy or recall for classification tasks, BLEU or Rouge for language generation tasks. For the models capable of doing multiple tasks, the capability can be evaluated by the set of multiple metrics from these tasks. 
Additionally, large language models (LLMs), which are capable of executing a wide range of language-based tasks akin to human performance, often require human evaluation for comprehensive assessment. Numerous benchmarks have been established for evaluating LLMs \citep{Chang2023A}. Some studies have even explored the application of IQ as a metric for evaluating AI models \citep{Liu2019How, Holzinger2019KANDINSKY, Kim2021Exploring}. 

As AI models increasingly exhibit capabilities that overlap with those of humans, it becomes imperative to develop unified evaluation metrics for both entities. Such metrics should extend beyond singular indices like IQ and may take the form of learnable vectors, akin to token embeddings used in natural language processing. 
% We contend that establishing these unified evaluation frameworks is crucial for developing a robust human-AI collaborative system with enhanced generalization capabilities.
% This can be more than a single index such as IQ, but can be learnable vectors just like token embeddings for a vocabulary. 
We believe this is crucial for developing a robust human-AI collaborative system with enhanced generalization capabilities.

\section{Preliminary}

This study applies a transformer encoder to build the combination weights from decision makers. Transformer is a widely utilized deep learning architecture for processing sequential data \citep{vaswani2017attention}, where the input for each sequential step is represented by an embedding vector. Let the input sequence be denoted as $\mathbf{X}=[\mathbf{x}_1,...,\mathbf{x}_n]$, where each $\mathbf{x}_i$ is a vector. The dimension of the input sequence is $n\times d_e$, where $d_e$ is the dimension of each embedding vector $\mathbf{x}_i$ and $n$ is the sequence length. For language, visual or time series data, usually positional encoding is needed as model parameters of transformers do not distinguish the absolute or relative position of the sequence. In addition, segment embeddings can be added for distinguishing segments of the input sequences. Therefore, the final input representation is given by: $\mathbf{Z}=\mathbf{X}+PE+SE$. A transformer encoder consists of a stack of multiple transformer encoder blocks.
Each block comprises a multi-head self-attention mechanism and a point-wise feed-forward neural network, with two residual connections and layer normalization applied following both the multi-head attention and feed-forward operations.
% each of them is build up with a multi-head self-attention and point-wise feed-forward neural network, while two residual connections with layer normalizations are inserted after the multi-head attention and feed-forward operations. 
Ultimately, the output of a transformer encoder remains a sequence of vectors that retains the same dimensionality as $\mathbf{Z}$. Typically, linear transformations can be applied to a single output embedding or a pooled output embedding for regression or classification tasks.
% Usually, we can apply linear transformations on a single or pooled output embedding for regression or classification tasks. 
% \begin{equation}
% \begin{split}
%     \text{MultiHead}(Q,K,V)&=\text{Concat}(\text{head}_1,...,\text{head}_h)W_o\\
%     \text{head}_i&=\text{SelfAttention}(QW_{{Q}_i}, KW_{{K}_i}, VW_{{K}_i})
%     \end{split}
% \end{equation}
% where the self-attention block is a scaled Dot-Product self attention. $\mathbf{Q}, \mathbf{K}, \mathbf{V}$ are different copies of the transformer block's input, which is $\mathbf{Z}$ for the first layer. 

\section{Method}

Existing studies have shown that combining the human prediction with model probabilities can lead to higher accuracies than model or human alone, while the parameters of the combination method can be estimated effectively \citep{kerrigan2021combining}. It is also noticed that a naive combination of humans with AI model can lead to poor accuracy, and selecting a subset
of humans and combine their labels in an intelligent strategy is important \citep{Singh2023On}. However, although \citet{Singh2023On} consider the combination method by the expertise of human experts, they use confusion matrix to model the expertise, which is not adaptive to more complex decision tasks or classification task with a large number of categories. Moreover, the confusion matrix is superficial representation of human's capability for recognizing images. For example, color blindness can not be represented by the confusion matrix among image categories but can affect the human's capability for recognizing or classification tasks. 

To better model the underlying capabilities of human or AI that may determine their decision performance in a collaborative system, we introduce learnable capability vectors. They can be applied in determining the optimal collaborative decision mechanism or decision weights for different decision tasks, and can be trained or pre-defined. This is comparable to the user or item embedding in recommendation systems \citep{yu2016user, barkan2016item2vec, zhang2019deep, ghasemi2021user}, or word/token embedding in natural language processing \citep{kenton2019bert}. We assume each candidate decision maker has a capability vector, and all candidate decision makers can formulate a vocabulary. Overall, our method is build upon the following three assumptions:
\begin{itemize}
\item There are many AI models or human with different capabilities, which can be represented by capability vectors with the same set of dimensions.
\item The optimal collaborative mechanism or decision weight for each decision maker is not fixed, but should be determined along with the other decision makers as well as the decision task.
\item The performance of collaborative decision making is determined by capability vectors of decision makers, the decision task and the collaborative decision mechanism.
\end{itemize}


\subsection{Model architecture} \label{Sec:4.1}

We explore a generalized framework for human-AI decision-making.
Given a decision task associated with a decision context, we can get $n$ decision choices, which can be pre-defined or generated by a human-AI system. 
% Then we need to select the optimal choice from them by using a set of decision makers combined with human and AI models.
Our objective is to identify the optimal choice among these options by leveraging a combination of human experts and AI models as decision-makers. In this study, we propose to use a weighted linear combination of scores from all the decision makers to evaluate the goodness of each decision choice, and use that to rank the choices and make the final decision selection. The main architecture is shown in Figure ~\ref{Fig:1}. 
\begin{figure*}[th]
\begin{center}
 \includegraphics[width=1.0\linewidth]{Figures/Figure_1_Main_Model.jpg}
 \caption{The diagram of the proposed architecture. The candidate decision options may be either pre-defined or generated by models or human experts. We employ a weighted aggregation of the scores assigned by each decision maker to each option in order to derive the final score for each choice. The weights assigned to each decision maker are determined by a weight generation model, which takes into account the capability vectors and the embedding of the decision task.} \label{Fig:1}
\end{center}
\end{figure*}
% The candidate decision choices can be pre-defined or provided by model or human experts. We apply a weighted combination of decision makers' score on each choice to form the final score of each choice. The decision weight for each decision maker is generated by the weight generation model based on capability vectors and decision task embedding.
Assume that we have $m$ decision makers, whose capability vectors are ${\mathbf{c}_1,...,\mathbf{c}_m}$. Then the weight generation model can give the weighting scores:
\begin{equation}
w_1, w_2,...,w_m = f(\mathbf{c}_1,...,\mathbf{c}_m;\mathbf{x};\mathbf{\theta})
\label{Eq:1}
\end{equation}
where $f(.)$ is the weights generation model. In this study, we use a transformer encoder for this component, while $\theta$ is the set of model parameter, and $x$ is the embedding of the decision task information. $w_1,...w_m$ are the decision weights for the decision makers. Usually, the size of a capability vector is different from that of the embedding of the input decision context. Therefore, we need to add an extra linear transformation layer on the capability vectors or the task embeddings for aligning the dimensions $w_i=\mathbf{h}_{N_i}\mathbf{W}_{hw}$, $i=\{1,...,m\}$, where $\mathbf{W}_{hw}\in \mathbb{R}^{d\times 1}$ and $\mathbf{h}_{N_i} \in \mathbb{R}^{1\times d}$. Meanwhile, if the number of the decision makers $m$ is not fixed, we need to add a separation embedding between the capability embeddings and the decision context embeddings before being processed by the multi-head attention module. In addition, we apply a learnable positional embedding as in BERT to distinguish the positional information of each embeddings \citep{kenton2019bert}. 

In the side of decision makers, assume that there are $n$ possible decision outcomes, and each of them will be assessed by all of the decision makers and be assigned with $m$ scores. Therefore, we can get a score matrix $\mathbf{S}\in \mathbb{R}^{m\times n}$. Given the generated weights of the decision makers, the final scores of the candidate decision outcomes can be given by:
\begin{equation}
\mathbf{s}_f = \mathbf{w} \mathbf{S}
\end{equation}
where $\mathbf{w}=\{w_1,w_2,...,w_m\}\in \mathbb{R}^{1\times m}$, and $\mathbf{s}_f\in \mathbb{R}^{1\times n}$ is the vector of final scores of all the decision choices. We use a Softmax function to normalize the output, and then the weight of each category is given by:
\begin{equation}
a_i = \frac{e^{s_{f_i}}}{\sum_i^m e^{s_{f_i}}}
\end{equation}
where $i$ is the index of each category. Assume that the labels of the optimal decision among the candidate decision outcomes are given in the format of one-hot vector ${y^{(1)},...,y^{(N)}}$. Then we can use a cross-entropy loss for model training:
\begin{equation}
  L = -\frac{1}{N}\sum_{i=1}^N\sum_{j=1}^n y^{(i)}_k \log a^{(i)}_k
  \label{Eq:4}
\end{equation}
where $N$ is the number of examples in the labeled data batch. In general, the proposed architecture ensures that: (1) We apply a weighted combination of the decisions scores or decision selections from multiple decision makers with different capabilities, no matter humans or AI models, which include the case of probability combination as discussed in \citep{kerrigan2021combining}. (2) The decision weights depend on both the decision task and the capabilities of decision makers in a continuous space, which can be generalized to out-of-sample decision makers given the uniformly defined capability vectors. (3) Both the weight generation model and the capability vectors are learnable in an end-to-end manner given sufficient training data.

In decision tasks like image classification, it is possible that different human experts have different capabilities. For example, an expert that is familiar with botany is more capable in recognizing botany types while an expert that is familiar with animals is more capable in recognizing animal types. In our method, the capability vectors will involve these difference between experts. For the weight generation model, it only need to recognize if a image is about a botany or an animal, and give the suitable expert more decision weights based on the capability vectors, while it does not need to make fine-grained recognition for the image. This make it possible to use a less powerful weight model to achieve high-accuracy collaborative decision making with existing model and human experts.


\subsection{Learning mechanism of capability vectors}

To learn the capability vectors, we assign each expert an unique one-hot vector as the initial capability representation, and then a linear transformation is applied for convert the one-hot capability representation to capability vector. As the parameters of the linear transformation are learnable, then the obtained capability vectors can be considered as learnable ones (from scratch). We use Figure ~\ref{Fig:2} to illustrate the workflow of this mechanism. We use a matrix comprised of the one-hot vectors of all or a subset of selected decision makers, and do matrix multiplication with a capability matrix of all decision makers to get the matrix of selected capability vectors. It is then concatenate with a separation embedding and a task embedding. The concatenated vector sequence is input to the weights generation model shown in Figure~\ref{Fig:1}. The capability matrix can be updated with back-propagation through the gradients from the final decision errors. This mechanism is comparable with the learning of word/token embeddings for pretrained language models, while each decision maker can be considered as a token in the vocabulary. The difference is that the order of capability vectors does not matter for the default collaborative decision mechanism presented in Figure~\ref{Fig:1} (we believe that there will be alternative mechanisms where the order do matter, which can be considered in future works). Moreover, there is an extra task embedding that should be distinguished from the capability vector sequence. Usually, the size of capability embedding vectors $d_c$ should be much smaller than the vocabulary size $d_v$ for capturing the relationships between different decision makers (e.g. capability similarity or complementarity) and achieving better generalization. We provide two strategies: a. Use a transformer encoder weight generation model with a smaller hidden size, which may require an extra linear mapping for reducing the dimension of task embedding; b. Do a low-rank decomposition on the original capability matrix $\mathbf{C}\rightarrow \mathbf{U} \mathbf{V}^T$, where $\mathbf{C}\in \mathbb{R}^{d_v\times d_e}, \mathbf{U}\in \mathbb{R}^{d_v\times d_c}, \mathbf{V}\in \mathbb{R}^{d_c\times d_e}$ ($d_c<<d_v$) and consider the intermediate representation with lower dimension as the capability representation. We will compare the two strategies in the experiments.
% Thus, the input information to weight generation model is a sequence of embedding. 
% \[
% \begin{pmatrix}
% \mathbf{c}_1 \\
% \mathbf{c}_2 \\
% \vdots \\
% \mathbf{c}_m \\
% \end{pmatrix}
% \]
\begin{figure*}[th]
\begin{center}
 \includegraphics[width=0.85\linewidth]{Figures/Figure_3-7.jpg}
 \caption{The diagram of the dimension alignment and the learning of capability vectors. At each iteration, we sample a subset of decision makers along with their corresponding one-hot vectors, to predict their respective weights. The final decision is derived from the weighted combination from all their scores. Furthermore, the capability matrix is subject to learning through back-propagation.} \label{Fig:2}
\end{center}
\end{figure*}

\subsection{Permutation invariance and positional encoding}

% In the proposed weight generation model with function mapping given in Eq.(\ref{Eq:1}), the position of the capability vectors of different decision maker does not matter. That means when we do a permutation on the order of decision makers or capability vectors, the output combination weights will be permuted accordingly, while the final output or performance of the architecture will not be changed. Thus we have:
In the proposed weight generation model, as described by the function mapping in Eq. (\ref{Eq:1}), the specific arrangement of the capability vectors corresponding to different decision-makers is inconsequential. This implies that permuting the order of the decision-makers or their associated capability vectors will result in a corresponding permutation of the output combination weights, while the final output and overall performance of the architecture remain unchanged. Thus, we can express this property mathematically as follows:
\begin{align}
&a(w_1,...w_m,\mathbf{s}_1,...,\mathbf{s}_m) \notag \\
&=a(w_{\sigma(1)},...,w_{\sigma(1)},\mathbf{s}_{\sigma(1)},...,\mathbf{s}_{\sigma(m)})\\
&a( f(\mathbf{c}_1,...,\mathbf{c}_m;\mathbf{x};\mathbf{\theta}),\mathbf{s}_1,...,\mathbf{s}_m) \notag\\
&=a( f(\mathbf{c}_{\sigma(1)},...,\mathbf{c}_{\sigma(m)};\mathbf{x};\mathbf{\theta}),\mathbf{s}_{\sigma(1)},...,\mathbf{s}_{\sigma(m)})
\end{align}
% where $\sigma(1),...,\sigma(m)$ is a permutation of original indices $1,...,m$. As the absolute position and relative position does not matter, we do not add positional encoding on the capability embeddings. Instead, we use a token type embedding to distinguish the capability embeddings and the task embedding.
where \(\sigma(1),..., \sigma(m)\) represents a permutation of the original indices \(1,...,m\). Given that both absolute and relative positions are irrelevant in this context, we do not incorporate positional encoding into the capability embeddings. Instead, we utilize a token type embedding to differentiate between the capability embeddings and the task embedding. This approach ensures that the model maintains its performance characteristics regardless of the arrangement of the decision-makers.


% \subsection{Calibration}

% In the context of collaborative decision making, we call a confidence estimate $\hat{P}_i$ to be calibrated if $\hat{P}_i$ represents the true probability that decision choice $i$ is the correct or optimal one. In \citep{kerrigan2021combining}, it is found that by using a confusion matrices-based combination technique to combine classiﬁer probabilities with human labels, the combined system can be better calibrated than the model alone. In our study, we can get the scores on each decision choice from multiple decision makers. It is natural to build a confidence estimate that one item is the optimal decision based on the weighted summation of the corresponding scores.

\section{A Learning-free Baseline for Multi-class Classification} \label{Sec:thm}

\subsection{Competence modeling of human experts.}

As discussed above, we use a vector to represent the competence of a human expert, which can be either learned or pre-defined, and should be mapped to the same dimension of the input embeddings. Here we discuss the modeling of real human expert's decision process, which means given a task instance, how is the expert's decision is generated.

In the case of classification problem, some existing works assume that a human expert can predict the correct label for a subset of classes, while making random selections for other classes \citep{Hussein2020Consistent}. However, in real world, an educated human expert does have the ability of doing some level of correct choice. For example, it is not likely that one classifies an animal as a vehicle, while sometime one may ``not sure'' if a photo is about one person or another. Therefore, we can assume that a human expert has one or multiple expertise categories, in which they can make close to 100\% correct decisions. For other categories, they can make correct decision with a limited probability $p$, and make random choice in other cases with probability $1-p$. 

\subsection{Expected decision accuracy of collaborative systems.}

We propose a learning-free baseline method by combining the model outputs with human predictions based on the competence model discussed above. Initially, we consider the scenario with one human expert and one AI model for collaborative decision making on classification tasks. Based on the above assumption for human experts, we can derive the weighted combination of model output and human expert's choice. In a straightforward case, we combine a one-hot vector representing the label selected by the human expert with the output vector generated by the AI model. 

\subsubsection{Building the combined output vector}

Let \( n \) denote the total number of categories. We define \( b_y \) and \( b_j \) as the output values corresponding to the true labeled class \( 1 \leq y \leq n \) and other classes \( 1 \leq j \leq n \) (\( j \neq y \)) in the output vector of the combined model, respectively. Let \( \alpha \) represent the combination weight of the model output, implying that the weight of the human expert's contribution is \( 1 - \alpha \). We consider two cases based on whether the true label \( y \) belongs to the expert's expertise set \( E \) or not, and calculate the combined output values for each index \( y \) and \( j \) in the combined output vector for both cases:
\begin{itemize}
\item Case 1: $y\in E$.
% In this scenario, the true label \( y \) is within the human expert's expertise set \( E \). The combined value at the true label's index in the output vector is given by:
    % \[
    % b_y = \alpha a^1_y + (1 - \alpha)
    % \]
    % % where \( a^1_y \) is the model's output at index \( y \), and the human expert correctly predicts and assigns a value of 1 at index \( y \). For other indices \( j \neq y \), the model predicts a logit \( a^1_j \), while the human expert assigns a value of 0 at index \( j \). Therefore, the combined value at index \( j \) is:
    % \[
    % b_j = \alpha a^1_j
    % \]
\begin{align}
    b_y &= \alpha a^1_y+ (1-\alpha)\\
    b_j &= \alpha a^1_j
\end{align}

\item Case 2: $y\notin E$.
\begin{align}
    b_y &= \alpha a^1_y+ (1-\alpha),\quad P = p + \frac{1}{n-K}(1-p)\\
    b_y &= \alpha a^1_y,\quad P = \frac{n-K-1}{n-K}(1-p)\\
    b_j &= \alpha a^1_j,\quad P = p + \frac{n-K-1}{n-K}(1-p)\\
    b_j &= \alpha a^1_j+ (1-\alpha),\quad P = \frac{1}{n-K}(1-p)
\end{align}

% \[
% \begin{aligned}
% b_y &= \alpha a^1_y + (1 - \alpha), & P &= p + \frac{1}{n - K}(1 - p) \\
% b_y &= \alpha a^1_y, & P &= \frac{n - K - 1}{n - K}(1 - p) \\
% b_j &= \alpha a^1_j, & P &= p + \frac{n - K - 1}{n - K}(1 - p) \\
% b_j &= \alpha a^1_j + (1 - \alpha), & P &= \frac{1}{n - K}(1 - p)
% \end{aligned}
% \]
\end{itemize}

In Case 1, the true label \( y \) is situated within the categories of expertise \( E \) possessed by the human expert. In this scenario, the combined value at the index corresponding to the true label in the output vector is expressed as \( b_y = \alpha a^1_y + (1 - \alpha) \), where \( a^1_y \) denotes the model's output at index \( y \). If the human expert correctly predicts the label and assigns a value of 1 at index \( y \), the resulting combined value at this index becomes \( b_y \) as delineated above. Conversely, for any index \( j \neq y \), the model outputs a logit \( a^1_j \), while the human expert assigns a value of zero at index \( j \).

In Case 2, the true label lies outside the human expert's categories of expertise. The probability that the human expert assigns a value of 1 at the true label index \( y \) comprises two components: the probability \( p \) of making a correct decision despite the lack of expertise, and the probability of making a random yet correct guess. It is important to note that the expert can only make guesses among categories that fall outside their expertise set \( E \), as they are aware that the true label is not included in \( E \). Consequently, the probability of making a correct guess is given by \( \frac{1}{n-K}(1 - p) \), leading to the total probability that \( b_y \) receives a vote from the human expert being \( P_a = p + \frac{1}{n-K}(1 - p) \).

Following a similar rationale, we can ascertain the probabilities associated with other categories \( j \neq y \) receiving or not receiving a human expert's vote. For the sake of clarity in subsequent discussions, we define \( P_a = p + \frac{1}{n-K}(1 - p) \) and \( P_b = \frac{n-K-1}{n-K}(1 - p) \).

\subsubsection{Model output approximation}

% Next, we model the output of the AI model in the collaborative system. For classification model like ResNet or BERT classifier, the model outputs a logits vector and take the category with largest logit value as the predicted label. We assume that the output logit vector of a classification model can be transformed to a one-hot vector of the real label $y$ plus a random noise $\delta_j$ on all the positions $j$ of the vector. Then the probability of getting one of values with index $j\neq y$ greater than 1 is the error rate of the classification model. We use a normal distribution $\delta_i\sim N(o, \sigma^2)$ to model the noise added to the one-hot representation, which is assumed to be independent and identically distributed (i.i.d.). Eq.(~\ref{Eq:noise}) shows the procedure to get the predicted label from the model output using this assumption.
% \begin{equation}
% [a_1,...,a_y,...,a_n]\stackrel{\text{map}}{\rightarrow}[\delta_1,...,1+\delta_y,...,\delta_n]\stackrel{\text{denoise}}{\rightarrow}[0,...,1,...,0]
% \label{Eq:noise}
% \end{equation}
% where the mapping can be any linear or non-linear order preserving functions that shared among all instances. We assume that there exist a order preserving function $g(.)$ provides a good enough approximation such that:
% \[
% g(a_1,...,a_y,...,a_n)\simeq [\delta_1,...,1+\delta_y,...,\delta_n]
% \]
% where $g$ can be estimated by methods like Maximum likelihood, Bayesian inference, or neural networks.

Next, we model the output of the AI system within the collaborative framework. In classification models such as ResNet or BERT, the model generates a logits vector from which the category corresponding to the highest logit value is selected as the predicted label. We posit that the output logits vector of a classification model can be transformed into a one-hot vector representing the true label \( y \), augmented by random noise \( \delta_j \) added to all positions \( j \) in the vector. Consequently, the probability of obtaining a value \( \delta_j \) at any index \( j \neq y \) that exceeds $1+\delta_y$ corresponds to the error rate of the classification model.

To model the noise introduced to the one-hot representation, we employ a normal distribution \( \delta_j \sim N(0, \sigma^2) \), assuming that the noise terms are independent and identically distributed (i.i.d.). The process of deriving the predicted label from the model output under these assumptions is illustrated in Equation (\ref{Eq:noise}):
%\begin{equation}
\begin{align}
[a_1, \ldots, a_y, \ldots, a_n] \stackrel{\text{map}}{\rightarrow} [\delta_1, \ldots, 1 + \delta_y, \ldots, \delta_n] \notag \\
\stackrel{\text{denoise}}{\rightarrow} [0, \ldots, 1, \ldots, 0]
\label{Eq:noise}
\end{align}

% \end{equation}
Here, the mapping function can be any order-preserving linear or nonlinear function shared across all instances. We assume the existence of an order-preserving function \( g(\cdot) \) that provides a sufficiently accurate approximation such that:
\[
g(a_1, \ldots, a_y, \ldots, a_n) \simeq [\delta_1, \ldots, 1 + \delta_y, \ldots, \delta_n]
\]
The function \( g \) can be estimated using various methods, including Maximum Likelihood Estimation, Bayesian Inference, or neural network approaches.

\subsubsection{Searching for the optimal combination weights}

% If we take make a transformation and let the smallest logit value to be 0, and the logit value of real ground-truth label to be 1, then 
Next, we focus on estimating the optimal values for the combination weights \( \alpha \) and \( 1 - \alpha \). We analyze two scenarios based on whether the expert provides a correct or incorrect vote concerning the ground-truth label. The weighted combined outputs for the label index \( y \) and the non-label index \( j \) are defined as follows:

\begin{itemize}
\item Case 1: The expert makes a correct vote on the ground-truth label.
\begin{align}
b_y &= \alpha(\delta_y + 1) + (1 - \alpha) = \alpha\delta_y + 1, \\
b_j &= \alpha\delta_j 
\end{align}
In this case, the system arrives at the correct decision if and only if \( b_y > b_j \) for all \( j \neq y \). This condition can be expressed as \( \delta_y - \delta_j > -\frac{1}{\alpha} \).

\vspace{0.5em}
\item Case 2: The expert makes an incorrect vote, failing to vote for the ground-truth label.
\begin{align}
b_y &= \alpha(\delta_y + 1), \\
b_j &= \alpha\delta_j + (1 - \alpha) \quad \text{or} \quad b_j = \alpha\delta_j
\end{align}
In this case, if the \( j \)-th category receives a vote, the condition \( b_y > b_j \) translates to \( \delta_y - \delta_{j_1} > -\frac{1 - 2\alpha}{\alpha} \). Conversely, if the \( j \)-th category does not receive a vote, the condition simplifies to \( \delta_y - \delta_j > -1 \).
\end{itemize}
% Next, we need to find a way to estimate the optimal value of combination weights $\alpha$ and $1-\alpha$.
% For the two cases that the expert make a correct or a wrong vote on the ground-truth label, the weighted combined output on the label index $y$ and non-label index $j$ are given by:
% \begin{itemize}
% \item The expert make a correct vote on the ground-truth label.
% \begin{equation}
% \begin{split}
% b_y = \alpha(\delta_y +1) + (1-\alpha) = \alpha\delta_y+1,\quad b_j = \alpha\delta_j 
% \end{split}
% \end{equation}
% In this case, the system makes the correct decision only when $b_y>b_j$ for any $j\neq y$, which requires $\delta_y-\delta_j>-\frac{1}{\alpha}$.
% \vspace{0.5em}
% \item The expert make a wrong vote without voting on the ground-truth label.
% \begin{equation}
% \begin{split}
% b_y = \alpha(\delta_y +1),\quad b_j = \alpha\delta_j + (1-\alpha)\text{ or }b_j = \alpha\delta_j
% \end{split}
% \end{equation}
% In this case, when $j$th category gets a vote, $b_y>b_j$ requires $\delta_y-\delta_{{j}_1}>-\frac{1-2\alpha}{\alpha}$, when $j$th category does not get a vote, $b_y>b_j$ requires $\delta_y-\delta_j>-1$.
% \end{itemize}
This analysis lays the groundwork for optimizing the combination weights \( \alpha \) and \( 1 - \alpha \) based on the performance of the expert's votes in relation to the ground-truth labels. We subsequently examine the overall probability that 
$b_y>b_j$ for any $j\neq y$ within the framework of the weighted combination strategy. Leveraging the relationship between joint and conditional probabilities, we can express the expected accuracy of the human-AI system as follows:
% We then consider the general probability that $b_y>b_j$ for any $j\neq y$ by using the weighted combination strategy. By using the relationship between joint and conditional probabilities, the expected accuracy of the human-AI system can then be given by:
\begin{equation}
\begin{split}
P_1(b_y>b_j) =&P(y\in E, b_y>\max\{b_j\}_{j\neq y})+P(y\notin E, b_y>\max\{b_j\}_{j\neq y})\\
=& P(y\in E)P(b_y>\max\{b_j\}_{j\neq y}|y\in E) + P(y\notin E)P(b_y>\max\{b_j\}_{j\neq y}|y\notin E)\\
=& \frac{K}{n}P(\delta_y-\max\{\delta_j\}>-\frac{1}{\alpha}) + \frac{n-K}{n}(P(\delta_y-\delta_{{j}_1}>\frac{1-2\alpha}{\alpha}, \\
&\delta_y-\max\{\delta_{j}\}>-1)P_b + P(\delta_y-\max\{\delta_j\}>-\frac{1}{\alpha})P_a)\\
=& \frac{K}{n}\prod_{j\neq y} P(\delta_y-\delta_j>-\frac{1}{\alpha}) + \frac{n-K}{n}(P_b P(\delta_y-\delta_{{j}_1}>\frac{1-2\alpha}{\alpha}) \\
&\prod_{j\neq y, j_1}P(\delta_y-\delta_{j}>-1) + P_a\prod_{j\neq y} P(\delta_y-\delta_j>-\frac{1}{\alpha}))
\label{Eq:11}
\end{split}
\end{equation}
% \begin{align*}
% &P_1(b_y>b_j) =P(y\in E, b_y>\max\{b_j\}_{j\neq y})\\
% &+P(y\notin E, b_y>\max\{b_j\}_{j\neq y})\\
% &= P(y\in E)P(b_y>\max\{b_j\}_{j\neq y}|y\in E)\\
% &+ P(y\notin E)P(b_y>\max\{b_j\}_{j\neq y}|y\notin E)\\
% &= \frac{K}{n}P(\delta_y-\max\{\delta_j\}>-\frac{1}{\alpha})\\
% &+ \frac{n-K}{n}(P(\delta_y-\delta_{{j}_1}>\frac{1-2\alpha}{\alpha},\\
% &\delta_y-\max\{\delta_{j}\}>-1)P_b\\ 
% &+ P(\delta_y-\max\{\delta_j\}>-\frac{1}{\alpha})P_a)\\
% &= \frac{K}{n}\prod_{j\neq y} P(\delta_y-\delta_j>-\frac{1}{\alpha})\\
% &+ \frac{n-K}{n}(P_b P(\delta_y-\delta_{{j}_1}>\frac{1-2\alpha}{\alpha}) \\
% &\prod_{j\neq y, j_1}P(\delta_y-\delta_{j}>-1) + P_a\prod_{j\neq y} P(\delta_y-\delta_j>-\frac{1}{\alpha}))
% \label{Eq:11}
% \end{align*}
where $P_a = p + \frac{1}{n-K}(1-p)$ and $P_b= \frac{n-K-1}{n-K}(1-p)$ and \( K \) represents the size of the expert's expertise set \( |E| \). Under our assumptions, we model the difference \( \delta_y - \delta_j \) as following a normal distribution, specifically \( \delta_y - \delta_j \sim N(1, \sigma_D) \), with \( \sigma_D = \sqrt{2}\sigma \). Given that the true label is uniformly distributed, the probabilities associated with the expert's expertise set are \( P(y \in E) = \frac{K}{n} \) for falling within the expertise set (Case 1) and \( P(y \notin E) = \frac{n-K}{n} \) for falling outside of it (Case 2). In Case 2, the probabilities that the expert makes a correct or incorrect guess are denoted by \( P_a \) and \( P_b \), respectively. Furthermore, based on our modeling of the outputs from the AI system, the accuracy of the base AI model can be expressed as: $P_0(b_y>b_j) = P(\delta_y-\delta_j>-1)$.
% \begin{equation}
% P_0(b_y>b_j) = P(\delta_y-\delta_j>-1)
% \end{equation}
where we assume that $\delta_y, \delta_j\sim N(0,\sigma)$, and the difference between two Gaussian random variables $\delta_y - \delta_j\sim N(0,2\sigma^2)$. Therefore, the accuracy of the AI model is given by:
\begin{align}
Acc&=P(b_y>\max\{b_j\}_{j\neq y}) \nonumber\\
&=(\int^{\infty}_{-1}\exp^{-\frac{x^2}{2\sigma_D^2}}dx)^{n-1} \nonumber\\
&= (\Phi(\frac{1}{\sigma_D}))^{n-1}
\end{align}
while $\sigma_D$ and $\sigma$ can be estimated with: $\sigma_D = 1/\Phi^{-1}((Acc)^{1/(n-1)})$.
For a model with a classification accuracy of $90\%$, the corresponding $\sigma_D=0.441$ and $\sigma=0.312$. Table~\ref{tab:sigma} shows the estimated values of $\sigma_D$ and $\sigma$ under a set of different model accuracies. 
% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table}[htbp]
  \centering
    \begin{tabular}{ccccccccccc}
    \toprule
    \textbf{Acc} & 0.5   & 0.55  & 0.6   & 0.65  & 0.7   & 0.75  & 0.8   & 0.85  & 0.9   & 0.95 \\
    \midrule
    $\sigma_D$ & 0.692  & 0.658  & 0.626  & 0.596  & 0.567  & 0.538  & 0.508  & 0.476  & 0.441  & 0.395  \\
    $\sigma$ & 0.489  & 0.465  & 0.443  & 0.422  & 0.401  & 0.380  & 0.359  & 0.337  & 0.312  & 0.279  \\
    \bottomrule
    \end{tabular}%
    \caption{Estimated $\sigma_D$ and $\sigma$ under different model accuracies for 10-class classification.}
  \label{tab:sigma}%
\end{table}%

The condition for the human-AI system gives a better prediction than the base AI model is $P_1(b_y>b_j)> P_0(b_y>b_j)$, while the greater $P_1(b_y>b_j) - P_0(b_y>b_j)$, the higher advantage can be achieved by using combination collaborative strategy. Based on Eq.(\ref{Eq:11}), $P_1(b_y>b_j)>P_0(b_y>b_j)$ requires that:
\begin{equation}
\begin{split}
F(\alpha) =& \frac{K}{n}(\int^{\infty}_{-\frac{1}{\alpha}}\exp^{-\frac{x^2}{2\sigma_D^2}}dx)^{n-1}\\
&+ \frac{n-K}{n}(P_b(\int^{\infty}_{\frac{1-2\alpha}{\alpha}}\exp^{-\frac{x^2}{2\sigma_D^2}}dx)(\int^{\infty}_{-1}\exp^{-\frac{x^2}{2\sigma_D^2}}dx)^{n-2}\\ &+ P_a(\int^{\infty}_{-\frac{1}{\alpha}}\exp^{-\frac{x^2}{2\sigma_D^2}}dx)^{n-1})
- (\int^{\infty}_{-1}\exp^{-\frac{x^2}{2\sigma_D^2}}dx)^{n-1}\\
&= \frac{K}{n}(\Phi(\frac{1}{\alpha\sigma_D}))^{n-1} + \frac{n-K}{n}(P_b(\Phi(\frac{2\alpha-1}{\alpha\sigma_D})\Phi(1/\sigma_D)^{n-2}\\ &+ P_a(\Phi(\frac{1}{\alpha\sigma_D}))^{n-1})
- (\Phi(\frac{1}{\sigma_D}))^{n-1}\\
>&0
\label{Eq:14}
\end{split}
\end{equation}
where $\Phi(.)$ is the cumulative distribution of the standard normal density. To maximize $F(\alpha)$ w.r.t. $\alpha$, we can apply numerical methods such as grid search. We show the case with $n=10$ and varing combinations of $K$, $\sigma_D$ and $p$ as in Figure~\ref{Fig:curve}.
% % , extra results as well as the code for grid search are given in Appendix. 
% We observe that different values of $K$ generally does not change the shapes of the accuracy curves, but the heights of curves will increase with the increase of $K$. With a larger value of $sigma_D$, which indicates a higher noise and a lower prediction accuracy by the AI model, the optimal value of $\alpha$ will be smaller. When both $K$ and $\sigma_D$ are large, the optimal $\alpha$ can be reduced to 0, which means we only use human expert's prediction. Meanwhile, with different values of non-expertise correct probability $p$, the changes of shapes can be small, but the accuracies with low $\alpha$ increases as the increase of $p$.
Our observations indicate that while different values of \( K \) do not significantly alter the shapes of the accuracy curves, the heights of these curves tend to increase with larger values of \( K \). In contrast, an increase in \( \sigma_D \), which signifies greater noise and consequently lower prediction accuracy from the AI model, results in a smaller optimal value of \( \alpha \). Notably, when both \( K \) and \( \sigma_D \) are large, the optimal \( \alpha \) may converge to zero, suggesting a reliance solely on the predictions of human experts. Furthermore, while variations in the non-expertise correct probability \( p \) may lead to minimal changes in the shapes of the accuracy curves, we observe that the accuracies at lower values of \( \alpha \) increase as \( p \) rises.
\begin{figure*}[th]
\begin{center}
 \includegraphics[width=1.0\linewidth]{Figures/P_curve.pdf}
 \caption{Estimated accurate probability under different collaborative settings. In each subplot, x-axis corresponds to different value of $\alpha$, and we utilize different colors for different values of $p$s.} \label{Fig:curve}
\end{center}
\end{figure*}

Overall, we establish a learning-free baseline by applying optimized global combination weights that integrate model outputs with human labels. This baseline serves as a benchmark to evaluate the effectiveness of instance-aware collaborative methods in multi-class classification tasks.
% In general, we provide a learning-free baseline by applying optimized global combination weights by combining model outputs with human labels, which can be applied to check the effectiveness of instance-aware collaborative methods for multi-class classification tasks.


% \begin{theorem}
% For classification task, if an expert has $K$ full expertise categories among $n$ total categories, the AI model has a relative variance $\sigma_D^2$. Then the optimal weight for model is $\alpha^*=\frac{2}{\sigma_D^2 r+2}=\frac{2}{\sigma_D^2 \log\frac{(n-K)P_a+K}{(n-K)P_b}+2}$ if uniform weight is used for all examples. 
% \end{theorem}

% The proof of this theorem is given in Appendix~\ref{Sec:A.1}. The main idea is to maximize the probability that the argument of the maximum in the combined vector is the real label.

% \begin{theorem}
% For classification task, if an expert has $K$ full expertise categories among $n$ total categories, the AI model has a relative variance $\sigma_D^2$. If separated weights are used for the cases that the real label fell in and fell out the human expert's expertise set, then the optimal weight for model is $\alpha^*_1=0$ for the case that the real label fell in the expertise set, and $\alpha^*_2=\frac{2}{\sigma^2_D\log\frac{P_a}{P_b}+2}$ for the case that the real label fell out of the expertise set. 
% \end{theorem}

% The proof is similar to the proof of Theorem 1 and is given in Appendix~\ref{Sec:A.2}. However, we set two different sets of human-AI weights based on if the real label belongs to the expert's expertise set.

% We can see that we we apply separated combination weights for the cases that the real label fell in and fell out of the expert's expertise categories, the optimal weights does not rely on the number of expertise categories $K$. As $\frac{2}{\sigma^2_D\log\frac{P_a}{P_b}+2}>\frac{2}{\sigma_D^2 \log\frac{(n-K)P_a+K}{(n-K)P_b}+2}$, using separated weight will lead to a higher weight for the AI model when the real label fell out of the expertise categories. When $p$ is sufficiently large that makes $P_a>P_b$, the optimal weight of AI model $\alpha^*_2<1$. This indicates that traditional way of using either human expert or AI model to make the final decision can be sub-optimal for classification tasks.

% Although it is possible to reach close-form solution for the optimal combination weights, in real application our assumptions is usually not well satisfied, and the decision model of human experts is unknown. The proposed architecture in Section~\ref{Sec:4.1} can be applied to handle more complicate cases including the case of multiple experts, or complicate expertise structures.



% \subsection{Baseline Methods}

% We compare of the proposed architecture with two baseline models. 

% We consider a case of learning to defer with multiple experts. Assume that we have $n$ experts, and each of them has a prediction for the input decision task, which can be either in one-hot or probability distribution form. 

% The output of the router is a probability distribution over all experts. We apply a Gumble-Softmax to generate the selection of the expert, and apply the expert's prediction as the final prediction. That is, assume that we have $M$ experts.
% \begin{equation*}
% \setlength{\abovedisplayskip}{3pt}
% \setlength{\belowdisplayskip}{3pt}
%     \begin{split}
%         y_i &= \text{GumbleSoftmax}(\pi_i, T)\\
%         &=\text{Softmax}((g_i + log \pi_i)/T), \,i =1,2,...,M\\
%         % &=\frac{\exp(g_i + log \pi_i)/T)}{\sum_{j=1}^k \exp(g_j + log \pi_j)/T)}, \,i =1,2,...,M\\
%         \end{split} % \label{Eq:1}
% \end{equation*}
% where $\pi_i$ is the probability of selecting the $i$th expert given by the router, $T$ is the temperature of the softmax function. $g_i$ is a random variable following a gumble distribution:
% \begin{equation*}
% \setlength{\abovedisplayskip}{3pt}
% \setlength{\belowdisplayskip}{3pt}
%   g_i = -\log(-\log(u_i)),\, u_i \sim U(0,1)
% \end{equation*}
% In backward path, straight through is used for back propagation. Assume that $\mathbf{o}=\text{One\_Hot}(\mathbf{y})$, then we have:
% \begin{equation}
% \hat{\mathbf{o}} = (\mathbf{o}-\mathbf{y})_f + \mathbf{y}
% \end{equation}
% where $(.)_f$ means the we consider the inner item as a fixed value in back propagation. Although $\mathbf{o}$ is an one-hot vector, as $\mathbf{y}$ is differentiable and the other items are fixed, we can get the gradient of the loss w.r.t. $\hat{\mathbf{o}}$. The final prediction vector can be given by:
% \begin{equation}
%     \mathbf{a} = \sum_i^M \hat{o}_i \mathbf{s}_i,
% \end{equation}
% where $\mathbf{s}_i$ is the score given by the $i$th expert. Then we can use the real labels and the cross-entropy loss in Eq.~\ref{Eq:4} to get the final loss.

% If we use softmax instead of gumble softmax, and apply a weighted combination of the predictions from all experts, it comes the case without using capability vectors. However, as the router is trained for fixed set of experts, it can not be applied for the case with uncertain or a large number of experts.


\section{Experiments}

\subsection{Datasets and Decision Tasks.}

We focus on two image classification datasets and one sentiment classification dataset for collaborative decision-making, including CIFAR10, CIFAR100 and Hatespeech. \textbf{CIFAR-10} \citep{Krizhevsky2009A} comprises 60,000 color images, each measuring 32x32 pixels. These images are categorized into 10 distinct classes, with each class containing 6,000 images. The dataset is divided into 50,000 training images and 10,000 test images. \textbf{CIFAR-100} consists of 60,000 32x32 color images spread across 100 classes, which are further organized into 20 super-classes \citep{Krizhevsky2009A}. Each class contains 600 images, with 5 classes per super-class. Each image is annotated with a ``fine'' label indicating its specific class and a ``coarse'' label representing its super-class. \textbf{Hatespeech} dataset consist of 24,783 tweets annotated as hate speech, oﬀensive language or neither \citep{davidson2017automated}. For our experiments with CIFAR-10 and CIFAR-100, we utilize the first 45,000 instances from the training set as the training data, reserving the remaining 5,000 instances for validation, while the original test set is employed as the test data. In the case of the Hatespeech dataset, we use the first 80\% of the data for training, the following 10\% for validation, and the rest 10\% for testing.


\subsection{Experimental settings}

We consider multiple scenarios of human-AI collaborative decision making, including collaborative decision by multiple human expert, collaborative decision by one model and one human expert, and collaborative decision by one model and multiple human experts.
We compare our method with traditional learning to defer methods, and check the effectiveness in improving the classification accuracy. We report the medium test accuracies of 5 trials using the checkpoints with the minimum validation loss in 200 epochs' of training. All experiments are run in Pytorch 2.3.0 with 2 Nvidia RTX 4090 GPUs.

\subsection{Collaborative decision by two human experts} \label{Sec:two_expert}

\subsubsection{Fixed decision makers}
At first, we consider a simple scenario. Assume we have two human experts. The first is familiar with animals, and the second is familiar with vehicles. However, we do not know the expertise of them before comparing their decision with the ground-truth labels. We assume that for CIFAR10 dataset, the \textbf{first human expert} can make correct classification on the images of birds, cats, horse, dog deer and frog, while \textbf{the second human expert} can make correct classification on the images of airplane, automobile, ship and truck. As there are only two decision makers, we can use two different capability vector to represent their decision capacity on image classification. We set $\mathbf{c}_1 = (0,1)$ and $\mathbf{c}_2 = (1,0)$, and map these two capability vectors to capability embedding vectors with linear transformations $c'_1 =  \mathbf{c}_1 \mathbf{W}_c$, $c'_2 =  \mathbf{c}_2 \mathbf{W}_c$, where $c'_1, c'2\in \mathbb{R}^{1\times d}$, $\mathbf{W}_c\in \mathbb{R}^{2\times d}$, and $d$ is the input embedding dimension. Meanwhile, we apply a pre-trained ResNet-18 to extract the feature of images \citep{he2016deep}, where the top-level representation has a length of 512. Thus we set the input embedding dimension to be 512.
We use a 4-layer 8-head transformer encoder with hidden size equal to 512. We use a transformer encoder as the weights generation model, and apply the segment embeddings to distinguish the positions of capability vectors and task embeddings. An Adam optimizer with a learning rate equals to 1e-5 is applied for optimization, while the batch size is set to be 64. We compare three settings of the feature extractor: a. \textbf{No task embedding}: We only apply capability vectors without using task embedding to determine the combination weights of decision makers, which results in the same combination weights for all task instance; b. \textbf{Fixed task embedding}: We use a finetuned Resnet-18 on CIFAR10 with fixed model parameters; c. \textbf{Full version}: We initialize the model with a Resnet-18 finetuned on CIFAR10, while the parameter can be further updated during the end-to-end training on collaborative decision making tasks. The results are given in Table~\ref{tab:1}. It shows that the proposed collaboration mechanism with tunable image representation extractor achieve the optimal classification accuracy. Given this finding, we use flexible feature extractors in the following experiments.
% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table}[htbp]
  \centering{\small
    \begin{tabular}{cc}
    \toprule
    \toprule
    \textbf{Settings} & \textbf{Accuracy} \\
    \midrule
    No task embedding & 81.83 \\
    Fixed task embedding & 93.10 \\
    % ResNet-18 & 95.2 \\
    Full version & \textbf{97.82} \\
    \bottomrule
    \bottomrule
    \end{tabular}}%
    \caption{Results of collaborative decision with two human experts on CIFAR 10 image classification task.}
  \label{tab:1}%
\end{table}%

\subsubsection{Random sampled decision makers} \label{Sec:6.3.2}

For changeable decision makers, the use of capability vector is essential as it is necessary to identify each decision maker's capability. We assume that there are $M$ candidate decision makers, while each time only a subset of them participate in collaborative decision making. Consider the multiple classification task with 10 categories as for CIFAR10. We further assume that each human expert can have expertise in one to ten categories, which means there will be $2^{10}=1024$ possible expert capabilities. Based on this assumption, we build \textbf{expert vocabularies with different sizes $M$} by sampling the expertise categories (with replacement) as a binary vector across all possible expert capabilities (i.e. from 1024 combinations). For each training or evaluation instance, we sample different 2 experts from the expert vocabulary for both training and testing. We consider three settings: (a) Use learnable capability matrix as is shown in Figure~\ref{Fig:2}; (b) Use fixed capability matrix; (c) Do not use capability vectors, just determine the two combination weights by the input image representations. We fixed the system random seed to 42 and compare different settings with the shared expert vocabulary. We apply an Adam optimizer with a learning rate of 1e-5 and the batch size equals to 64. The results are shown in Table~\ref{tab:cap_diff_exp}.
% % Table generated by Excel2LaTeX from sheet 'Sheet8'
% \begin{table}[htbp]
%   \centering
%     \begin{tabular}{cccccc}
%     \toprule
%     \textbf{Vocab. Size} & \textbf{10}    & \textbf{30}    & \textbf{100}   & \textbf{300}   & \textbf{1000} \\
%     \midrule
%     Learnable & \textbf{71.34} & \textbf{70.12} & \textbf{71.18} & \textbf{70.89} & \textbf{71.83} \\
%     Fixed & 71.18 & 69.72 & 70.64 & 69.16 & 69.25 \\
%     None  &  66.01 &  66.08 &  67.52 & 67.7  & 68.21 \\
%     \bottomrule
%     \end{tabular}%
%     \caption{The effect of learnable capability vectors with different number of experts in the vocabulary.}
%   \label{tab:cap_diff_exp}%
% \end{table}%

% Table generated by Excel2LaTeX from sheet 'Sheet8'

% \begin{table}[htbp]
%   \centering
%     \begin{tabular}{ccccccc}
%     \toprule
%     \toprule
%     Size  & Settings & 10    & 30    & 100   & 300   & 1000 \\
%     \midrule
%     \multirow{2}[2]{*}{Small} & Learnable & \textbf{71.34} & \textbf{70.12} & \textbf{71.18} & \textbf{70.89} & \textbf{71.83} \\
%           & Fixed & 71.18 & 69.72 & 70.64 & 69.16 & 69.25 \\
%     \midrule
%     \multirow{2}[2]{*}{Large} & Learnable & 73.04 & \textbf{73.36} & \textbf{74.91} & \textbf{74.53} & \textbf{73.16} \\
%           & Fixed & \textbf{73.15} & 73.32 & 74.84 & 74.22 & 71.39 \\
%     \midrule
%     \multicolumn{2}{c}{None} & 66.01 & 66.08 & 67.52 & 67.7  & 68.21 \\
%     \bottomrule
%     \bottomrule
%     \end{tabular}%
%     \caption{The effect of learnable capability vectors with different number of experts in the vocabulary.}
%   \label{tab:cap_diff_exp}%
% \end{table}%

% Table generated by Excel2LaTeX from sheet 'Sheet8'
\begin{table}[htbp]
  \centering{\small
    \begin{tabular}{ccccccc}
    \toprule
    \toprule
    Size  & Settings & 10    & 30    & 100   & 300   & 1000 \\
    \midrule
    \multirow{3}[2]{*}{Small} & Learnable & \textbf{71.34} & \textbf{70.12} & \textbf{71.18} & \textbf{70.89} & \textbf{71.83} \\
          & Fixed & 71.18 & 69.72 & 70.64 & 69.16 & 69.25 \\
          & None  & 66.01 & 66.08 & 67.52 & 67.7  & 68.21 \\
    \midrule
    \multirow{3}[2]{*}{Large} & Learnable & 73.04 & \textbf{73.36} & \textbf{74.91} & \textbf{74.53} & \textbf{73.16} \\
          & Fixed & \textbf{73.15} & 73.32 & 74.84 & 74.22 & 71.39 \\
          & None  & 65.85 & 66.07 & 67.66 & 67.93 & 68.39 \\
    \bottomrule
    \bottomrule
    \end{tabular}}%
    \caption{The effect of learnable capability vectors with different number of experts $M$ in the vocabulary. }
  \label{tab:cap_diff_exp}%
\end{table}%

We notice that given the same model size, as the vocabulary size of decision makers becomes larger, the advantage of using learnable capability vectors becomes larger. Notice that the weight of capability matrix only takes less than 1\% extra parameters of the weight generation model. This finding can be applied in building collaborative annotation systems with large number of candidate annotators. Moreover, the learning behavior of the capability vectors is investigated in Section~\ref{Sec:7.2}. 

\subsection{Collaborative decision by one model and one human-expert.}

To investigate the performance of our method on human-AI collaborative decision making, we initially focus on a scenario involving a single AI model and a human expert. Utilizing the strategy outlined in Section~\ref{Sec:two_expert}, we employ two one-hot vectors to differentiate between the AI model and the human expert. Subsequently, we apply a linear transformation to convert these vectors into their corresponding learned capability vectors, ensuring that they match the dimensionality of the task representation embedding.
% We follow the strategy in Section~\ref{Sec:two_expert} to use two one-hot vector to distinguish them, and apply a linear transformation to map them to their learned capability vectors with the same dimension as the embedding of task representation. 
Our collaborative decision-making framework is then implemented and assessed across three classification datasets: CIFAR-10, CIFAR-100, and Hatespeech.

% We perform collaborative decision making with our method on three classification datasets including CIFAR10, CIFAR100 and Hatespeech.

\subsubsection{Results on CIFAR10} \label{Sec:cifar10}

% We assume a random sampled capability vector to label the human expert's decision on the classification task. Meanwhile, we use a ResNet-18 as a model expert, we use its probabilistic outputs on each categories to calculate the weigted combination with the human expert's decision. The final weighted combination vector is used for predict the final label. We consider two settings, the first is we direct use the capability vector that we sampled, the second is we let the model to learn the capability vectors based on the final predictions.

In the first experiment, we follow \citep{Hussein2020Consistent} to simulate multiple synthetic experts of varying competence: if the image belongs to the ﬁrst $k$ classes with $k=1,2,...,10$,  the expert predicts the correct label of the image, otherwise the expert predicts uniformly over all classes. We use a tunable resnet-18 pre-trained on CIFAR-10 as the feature extractor, and a 28-layer Wide-Resnet same with that in \citep{Hussein2020Consistent} is applied as the AI classifier to be collaborative with human expert. 
% We first pre-train the WideResnet-28 and then initialize the AI classifier in the whole architecture using the pre-trained weights for our method. 
To ensure that the AI classifier is the same for our method and the baseline method, we reproduce the baseline method in \citep{Hussein2020Consistent} with 200 epochs of training, and then use the weights of the AI classifier to initialize the classifier of our proposed model. For training the whole architecture, we apply an Adam optimizer with a learning rate of 1e-5 and a batch size of 64, with 200 epochs of training. We take different levels of expert's competence $k$, and compare the performance of our method with a set of baseline methods including Global (the proposed global weighted output merging methods in Section~\ref{Sec:thm}), Consistent \citep{Hussein2020Consistent}, Confidence \citep{raghu2019algorithmic}, OracleReject and MPZ18 \citep{Predict2018Madras}. The results are given in Table ~\ref{tab:2}. We can learn that our proposed architecture provide a consistent improvement from the baseline methods. In addition, there is no extra hyper-parameter involved in the loss function to be optimized. We also notice that if we extend the training epochs to 500 for the baseline method in \citep{Hussein2020Consistent}, gain of the system accuracy is not significant.

% % Table generated by Excel2LaTeX from sheet 'Sheet2'
% \begin{table}[htbp]
%   \centering
%     \begin{tabular}{ccccccccccc}
%     \toprule
%     \toprule
%     k     & 1     & 2     & 3     & 4     & 5     & 6     & 7     & 8     & 9     & 10 \\
%     \midrule
%     Ours  & 91.8  & 92.1  & 92.92 & 94.67 & 95.52 & 97.08 & 97.95 & 98.63 & 99.33 & 100 \\
%     $L^{.5}_{CE}$ & 90.92 & 91.01 & 91.94 & 92.69 & 93.66 & 96.03 & 97.11 & 98.25 & 99    & 100 \\
%     $L^1_{CE}$  & 90.41 & 91    & 91.47 & 92.42 & 93.4  & 95.06 & 96.49 & 97.3  & 97.7  & 100 \\
%     Confidence & 90.47 & 90.56 & 90.71 & 91.41 & 92.52 & 94.15 & 95.5  & 97.35 & 98.05 & 100 \\
%     OracleReject & 89.54 & 89.51 & 89.48 & 90.75 & 90.64 & 93.25 & 95.28 & 96.52 & 98.16 & 100 \\
%     \[MPZ18\] & 90.4  & 90.4  & 90.4  & 90.4  & 90.4  & 90.4  & 90.4  & 94.48 & 95.09 & 100 \\
%     \bottomrule
%     \bottomrule
%     \end{tabular}%
%       \caption{Comparison of System accuracy between our method and baselines with varying expert competence on CIFAR10.}
%   \label{tab:2}%
% \end{table}%

% Table generated by Excel2LaTeX from sheet 'Sheet2'
\begin{table}[htbp]
  \centering{\small
    \begin{tabular}{ccccccccccc}
    \toprule
    \toprule
    k     & 1     & 2     & 3     & 4     & 5     & 6     & 7     & 8     & 9     & 10 \\
    \midrule
    Ours  & 95.53 & 95.85 & 96.16 & 97.21 & 97.66 & 98.47 & 98.96 & 99.25 & 99.66 & 100 \\
    Global & 94.68 & 94.99 & 95.40 & 95.89 & 96.46 & 97.11 & 97.85 & 98.71 & 100.0 & 100 \\
    Consistent & 94.63 & 95.26 & 95.53 & 95.89 & 96.31 & 98.08 & 98.71 & 99.14 & 99.42 & 100 \\
    Confidence & 90.47 & 90.56 & 90.71 & 91.41 & 92.52 & 94.15 & 95.5  & 97.35 & 98.05 & 100 \\
    OracleReject & 89.54 & 89.51 & 89.48 & 90.75 & 90.64 & 93.25 & 95.28 & 96.52 & 98.16 & 100 \\
    \textnormal{MPZ18} & 90.4  & 90.4  & 90.4  & 90.4  & 90.4  & 90.4  & 90.4  & 94.48 & 95.09 & 100 \\
    \bottomrule
    \bottomrule
    \end{tabular}}%
      \caption{Comparison of system accuracy between our method and baselines with varying expert competence on CIFAR10. Among the baseline methods, for Consistent method, we reproduce the experiments by ourself. For other methods, we directly apply the reported results in \citep{Hussein2020Consistent}.}
  \label{tab:2}%
\end{table}%

To further investigate the effect of human expert with relatively larger non-expertise capability level, we fix $k=5$ and change the non-expertise capability level by using different probability $p$. Using the same optimizer and hyper-parameter setting, the results are given in Table~\ref{tab:3}. We observe that our method achieve higher accuracy compared with the baseline models. Again, the proposed global weighted merging baseline achieves competitive performances compared with instance aware methods, but still outperformed by the proposed instance aware weighted merging architecture. In addition, we observe that as the non-expertise capability level increase, the baseline L2D method in \citep{Hussein2020Consistent} has an accuracy drop when $p$ lies between 0.5 and 0.9. Meanwhile, the our proposed method, the system accuracy generally increases with the increase of non-expertise capability level. One possible explanation is that as the non-expertise capability level get close to the model accuracy, the baseline method may have instability in learning or be sensitive to hyper-parameter settings, which can be better resolved by merging the output of the model with human expert's decision.
\begin{table}[htbp]
  \centering{\small
  \resizebox{\linewidth}{!}{
    \begin{tabular}{cccccccccccc}
    \toprule
    \toprule
          & 0     & 0.1   & 0.2   & 0.3   & 0.4   & 0.5   & 0.6   & 0.7   & 0.8   & 0.9   & 1 \\
    \midrule
    Ours  & 97.66 & 97.79 & 97.94 & 98.09 & 98.35 & 98.32 & 98.6  & 98.78 & 98.75 & 99.14 & 100 \\
    Global  & 96.46 & 96.71 & 96.97 & 97.25 & 97.54 & 97.85 & 98.18  & 98.53 & 98.91 & 99.36 & 100 \\
    Consistent & 96.31 & 96.58 & 96.9  & 97.15 & 97.13 & 97.29 & 95.23 & 93.88 & 92.94 & 95.6  & 100 \\
    \bottomrule
    \bottomrule
    \end{tabular}}}%
     \caption{Comparison of system accuracy between our method and baselines with non-expertise capability level on CIFAR10 with $k=5$.}
  \label{tab:3}%
\end{table}%

\subsubsection{Results on CIFAR100.}

We further conduct an experiment on CIFAR 100, in which there are 100 classes and 20 super-classes of images. Instead of predicting the labels of fine-grained classes, we predict the labels of super-classes. We train a Wide-ResNet-28 on this classification task and get an accuracy of 73.33\%, and utilize the pretrained model to initialize the AI classifier in both our proposed architecture and the baseline learning to defer method. We then compare our method with two alternative approaches:(a) Global, weighted output merging approach proposed in Section~\ref{Sec:thm}; (b) Consistent learning to defer estimator \citep{Hussein2020Consistent}, where each time the decision is made by only one expert or AI model. We tune the hyper-parameter of learning rates for both settings with a set of $\{1e^{-3}, 3e^{-4}, 1e^{-4}, 3e^{-5}, 1e^{-5}, 3e^{-6}, 1e^{-6}\}$. The results of varying expert competence is given in Table~\ref{tab:cifar100_ve}.
% Table generated by Excel2LaTeX from sheet 'Sheet6'
\begin{table}[htbp]
  \centering{\small
  \resizebox{\linewidth}{!}{
    \begin{tabular}{cccccccccccc}
    \toprule
    \toprule
          & 0     & 2     & 4     & 6     & 8     & 10    & 12    & 14    & 16    & 18    & 20 \\
    \midrule
    Ours  & 73.33 & 78.95 & 79.68 & 81.2  & 82.99 & 85.19 & 87.01 & 91.06 & 94.39 & 97.43 & 100 \\
    Global  & 73.33 & 74.30 & 76.17 & 78.45  & 81.02 & 83.81 & 86.83 & 90.06 & 93.56 & 97.51 & 100 \\
    Consistent & 73.33 & 76.99 & 78.61 & 79.65 & 82.25 & 81.43 & 86.06 & 83.1  & 89.37 & 94.36 & 100 \\
    \bottomrule
    \bottomrule
    \end{tabular}}}%
    \caption{Experiment on CIFAR100-superclass with varying expert competence.}
  \label{tab:cifar100_ve}%
\end{table}%
It is shown that with the same initialized AI classifier and the experts' competences, our method outperforms the baseline L2D method significantly in the cases of effective human-AI collaboration. Global weighted merging method achieve very competitive results as $k$ gets larger. Similary as in Section~\ref{Sec:cifar10}, we further investigate the effective of varying non-expertise capability levels with expert competence level $k=5$.
The results are shown in Table~\ref{tab:cifar100_ne}. We observe that our method has a greatest advantage over the baseline around $p=0.7$, and for other non-expertise capability levels, it is possible that the advantage is smaller than the advantage at $p=0.0$.
% Table generated by Excel2LaTeX from sheet 'Sheet6'
\begin{table}[htbp]
  \centering{\small
    \begin{tabular}{ccccccccccc}
    \toprule
    \toprule
          & 0     & 0.1   & 0.2   & 0.3   & 0.4   & 0.5   & 0.6   & 0.7   & 0.8   & 0.9 \\
    \midrule
    Ours  & 85.19 & 85.62 & 86.43 & 86.67 & 87.88 & 88.97 & 90.01 & 91.6  & 93.47 & 96.03 \\
    Global & 77.27 & 78.95 & 80.75 & 82.67 & 84.70 & 86.83 & 89.06 & 91.42  & 93.94 & 96.66 \\
    Consistent & 81.43 & 82.14 & 83.2  & 84.19 & 85.82 & 86.55 & 86.71 & 87.27 & 91.06 & 95.43 \\
    \bottomrule
    \bottomrule
    \end{tabular}}%
    \caption{Experiment on CIFAR100-superclass with different non-expertise capability levels.}
  \label{tab:cifar100_ne}%
\end{table}%


\subsubsection{Results on HateSpeech}

We also conducted experiments on Hate speech dataset, in which we apply the proposed architecture and baseline methods to determine if an instance is hatespeech, offensive language or neither. We follow \citep{Hussein2020Consistent} to create the synthetic experts for this task, which is: (a) If the tweet is in AAE then with probability $p$
the expert predict the correct label and otherwise predict uniformly at random. (b) If the
tweet is not in AAE, the expert predict the correct label with probability $q$ and otherwise predict uniformly at random. Also, we consider three different expert probabilities $p$ and $q$, corresponding to a fair expert ($p=q=0.9$), a biased expert towards AAE ($p=0.75, q=0.9$), and a biased expert towards non AAE tweets ($p=0.9, q=0.75$). We use a pre-trained transformer encoder on Hatespeech to initialize our model as well as the classifier in the baseline model. We use a Adam optimizer with a learning rate of 1e-6 and a batch size of 32. The results are shown in Table~\ref{tab:hatespeech}. The collaborative method largely outperforms the model-only and human-only methods. Moreover, compared with the method of consistent estimator given in \citep{Hussein2020Consistent}, our method achieves significant improvements for non-AAE biased and fair setting. 

% Table generated by Excel2LaTeX from sheet 'Sheet5'
\begin{table}[htbp]
  \centering{\small
    \begin{tabular}{cccc}
    \toprule
    \toprule
    p,q   & 0.75,0.9 & 0.9,0.75 & 0.9,0.9 \\
    \midrule
    Ours  & 94.96 & \textbf{94.62} & \textbf{95.88} \\
    Consistent & \textbf{95.14} & 93.68 & 95.63 \\
    Expert & 88.11 & 89.14 & 93.95 \\
    Model & 92.73 & 92.79 & 92.81 \\
    \bottomrule
    \bottomrule
    \end{tabular}}%
    \caption{Results for our method and baselines on the hate speech detection task.}
  \label{tab:hatespeech}%
\end{table}%

\subsection{Collaborative decision by one model and multiple human experts.}

To investigate the effectiveness of the proposed architecture for the scenario with multiple human experts, we assume that we have multiple human experts with different expertise sets with equal size, for which each expert can have only 1 or 2 expertise categories. We consider the collaborative decision making by one model and these human experts. Also, we consider the case of solely using these experts for collaborative decision making without collaboration with AI model. The experiments are done on CIFAR10. We adopt a pretrained ResNet-18 model as the classifier as well as the image representation extractor. A 6 layer transformer encoder with 8 heads and a embedding dimension of 512 is applied. An Adam optimizer with a learning rate of 1e-5, and a batch size of 64 are applied. The result of the case that each expert has only 1 expertise category is shown in Table~\ref{tab:mul_exp_1}, where $s$ is the size of experts group. We observe that when the number of experts is small, the performance of both AI+experts system and experts-only system increase linearly. However, when the number of experts becomes large, the increasing trends diminishes slowly. This indicates that we need to apply heavy hyper-parameter tuning or use a more powerful weight generation model for handling the collaboration with a large number of experts.
% Table generated by Excel2LaTeX from sheet 'Sheet4'
% \begin{table}[htbp]
%   \centering
%     \begin{tabular}{cccccccccccc}
%     \toprule
%       s    & 0     & 1     & 2     & 3     & 4     & 5     & 6     & 7     & 8     & 9     & 10 \\
%     \midrule
%     AI+Experts & 89.47 & 91.8  & 92.11 & 92.53 & 93.02 & 92.91 & 93.59 & 93.63 & 93.66 & 93.52 & 93.55 \\
%     Experts & 0     & 19    & 25.78 & 31.21 & 35.68 & 39.31 & 41.96 & 45.78 & 48.97 & 52.77 & 56.12 \\
%     \bottomrule
%     \end{tabular}%
%     \caption{Collaborative decision making with multiple experts. Each experts has 1 expertise category.}
%   \label{tab:mul_exp_1}%
% \end{table}%
% Table generated by Excel2LaTeX from sheet 'Sheet4'
\begin{table}[htbp]
  \centering{\small
    \resizebox{\linewidth}{!}{
    \begin{tabular}{cccccccccccc}
    \toprule
    \toprule
          & 0     & 1     & 2     & 3     & 4     & 5     & 6     & 7     & 8     & 9     & 10 \\
    \midrule
    AI+experts & 93.52 & 95.82 & 96.76 & 97.21 & 97.2  & 97.3  & 97.29 & 97.34 & 97.27 & 97.28 & 97.38 \\
    Experts & 0     & 19    & 25.78 & 31.21 & 35.68 & 39.31 & 41.96 & 45.78 & 48.97 & 52.77 & 56.12 \\
    \bottomrule
    \bottomrule
    \end{tabular}}}
     \caption{Comparison of system accuracy with varying number of experts.}
  \label{tab:mul_exp_1}%
\end{table}%

In the second experiment of multiple expert collaborative decision making. we assume that each expert has an expertise set with size 2, and the 5 experts have expertise sets $\{1,2\}$, $\{3,4\}$, $\{5,6\}$, $\{7,8\}$, $\{9,10\}$, respectively. The result of this case that is shown in Table~\ref{tab:mul_exp_2}. Here We observe that similar trend is shown by the table. The propose method provide a significant improvement of the system accuracy as number of expert increases, but there is a diminishing marginal utility effect when the expert number is large.
% Table generated by Excel2LaTeX from sheet 'Sheet4'
\begin{table}[htbp]
  \centering{\small
    \begin{tabular}{ccccccc}
    \toprule
    \toprule
          & 0     & 1     & 2     & 3     & 4     & 5 \\
    \midrule
    AI+Experts & 89.47 & 92.18 & 93.71 & 94.89 & 94.75 & 94.86 \\
    Experts & 0     & 28    & 40.23 & 46.5  & 53.22 & 60.13 \\
    \bottomrule
    \bottomrule
    \end{tabular}}%
    \caption{Collaborative decision making with multiple experts. Each expert has 2 expertise categories.}
  \label{tab:mul_exp_2}%
\end{table}%



% \subsection{Collaborative decision by multiple models and multiple human experts.}

% We further consider the case that we have multiple models and multiple human experts. We use two ResNet-18 trained on CIFAR10 with different label noising settings. 



\section{Analysis}

\subsection{Effect of non-expertise capability levels.}
We visualize the accuracy curves with different non-expertise correct probability for both the proposed method and the baseline consistent estimator in \citep{Hussein2020Consistent}, which is given by Figure~\ref{Fig:non_expertise accuracy}. We can clearly observe that in both cases the baseline method has a breakdown of increasing trends when the non-expertise capability level is close to the accuracy of AI model. Especially on CIFAR10 dataset, the accuracy drop to about 93\%-95\% when the non-expertise capability level is between 0.6 and 0.9. In contrast, our proposed architecture show monotonic increase trends in both cases.
\begin{figure}[th]
\begin{center}
 \includegraphics[width=1.0\linewidth]{Figures/Non_exp_prob.pdf}
 \caption{Diagram of accuracy under different non-expertise capability levels.} 
 \label{Fig:non_expertise accuracy}
\end{center}
\end{figure}

\subsection{Learning behavior of capability vectors with different vocabulary sizes.} \label{Sec:7.2}
For the experiments of random sampled decision makers with different vocabularies (see Section~\ref{Sec:6.3.2}), we investigate the change of average absolute correlations between capability vectors with respect to the learning steps, which is shown in Figure~\ref{Fig:corr}(a). We set different vocabulary sizes in $\{10, 30, 100, 300\}$, and apply a single linear mapping from one-hot decision maker representations to the capability embeddings with size 16, which have the same size with the hidden embedding. 
% Our observations indicate that, for larger vocabulary sizes, there is a clear upward trend in the absolute correlation between capability vectors as training progresses. This phenomenon can be attributed to the total of 1024 distinct capability configurations available; as the number of decision makers increases, the modeling of similar capabilities becomes more pronounced, leading to heightened average correlation values.
We observe that when the experts' vocabulary is relatively large, there is an increasing trend of the correlation between capability vectors as the training step gets larger. Our explanation is that as there are in total 1024 different capability settings, when the number of decision makers becomes larger, the change of modeling similar capability also becomes larger, resulting in a larger average correlation value. 
% In addition, we also investigate if the correlation between learned capability vectors will approach to the correlation between the underlying binary vectors of the capabilities. We take the absolute values of the difference between these two correlation matrices, and trace the change of the average as the increase of training steps. The quantity at $t$th step is given by:
Furthermore, we investigate whether the correlation between the learned capability vectors converges towards the correlation between the underlying binary vectors representing the capabilities. To quantify this, we compute the absolute differences between the two correlation matrices and track the average deviation over the course of training. Specifically, at the $t$-th training step, this metric is defined as:
\begin{equation}
D_{corr,t} = \frac{1}{M^2}\sum_{i=1}^M \sum_{j=1}^M |\rho^{\text{cap}}_{ij, t}-\rho^{\text{bin}}_{ij, t}|,
\end{equation}
where $M$ is the vocabulary size of decision makers, $\rho^{\text{cap}}_{ij, t}$ and $\rho^{\text{bin}}_{ij, t}$ are the entries of \textbf{the correlation matrix between the learned capability vectors in the vocabulary} and \textbf{the correlation matrix between the binary vectors of underlying pre-defined expertise sets of decision makers}, respectively, and step $t$. The results are shown in Figure~\ref{Fig:corr}(b). Notably, for vocabulary sizes of 10, 30, and 100, we observe a clear trend of decreasing average absolute differences between the two correlation matrices. 
% We can see that when the total number of decision makers are 10, 30 and 100, there are clear trends of decreasing of the average absolute difference between two correlation matrices. 
As for the case of 300 decision makers in the vocabulary, $D_{corr,t}$ slightly increases from 0.334 to 0.339, which may due to the learning of too many capability vectors simultaneously makes it hard to capture the correlations. 
\begin{figure}[th]
\begin{center}
 \includegraphics[width=1.0\linewidth]{Figures/Corr_curve.pdf}
 \caption{Diagram of the learning curves of capability vectors including: (a) The average of absolute correlation between capability vectors and (b) The average of absolute difference between the correlation of capability vectors and correlation of corresponding binary vectors of expertise set.} 
 \label{Fig:corr}
\end{center}
\end{figure}

% \subsection{Ablation study}
% We conduct a set of ablation studies to check the effectiveness of each component of the proposed architecture. We consider the following alternative settings: (a) Without the embedding of tasks. (b) Using the fixed capabilities vectors. (c) Using fixed task representation extractor. (d) Dimension reduction on the task representation. (e) Normalizing the combining weights with Softmax. 

\section{Discussion}

\subsection{Comparing with related works}
The proposed architecture adopts a strategy of merging the output vectors from both AI models and human experts, rather than merely deciding whether to defer the task to a human. In contrast to the work by \citep{kerrigan2021combining}, which also focuses on output vector combination, our method incorporates a representation learning mechanism instead of relying on a naive Bayesian estimator based on a confusion matrix. This allows our approach to seamlessly accommodate multiple experts in an end-to-end manner.


While \citep{kerrigan2021combining} utilizes real human labels from the CIFAR-10H and ImageNet-16H datasets as the outputs from human experts, these datasets are annotated by a diverse group of human experts. Consequently, their estimation may not effectively adapt to the varying capabilities of different experts. Furthermore, their methodology rests on the assumption of conditional independence, which is often not satisfied in practice.


Our architecture also facilitates human-AI collaborative decision-making involving multiple AI models and multiple human experts. This is achieved through the learning of capability vectors in a uniform dimensional space. Related studies on human-AI collaborative decision-making with multiple experts typically employ different datasets or base models in their experiments. For instance, \citep{mao2024two} utilize ResNet-4 as the predictive AI model, while employing ResNet-10, ResNet-16, and ResNet-28 with increasing capacities as the human experts, focusing on the CIFAR-10 and SVHN image classification datasets. Additionally, \citet{Hemmer2022Forming} investigate three distinct tasks, including Hate Speech detection, CIFAR-100 classification, and the NIH Dataset.
% The proposed architecture takes the strategy of merging the output vectors of AI and human expert rather than determining whether or not defer the task to human. Compared with \citep{kerrigan2021combining}, which is another work with output vector combining, our method introduces a representation learning mechanism instead of using naive Bayesian estimator based confusion matrix, and can easily handle the case with multiple expert in an end-to-end manner. They use real human labels in CIFAR-10H and ImageNet-16H to as the human expert's output. However, these datasets are labeled by many different human experts, thus the estimation can not well adapt to experts with different capability. Also their work relies on the assumption of conditional independence, which is usually not satisfied.

% The proposed architecture can also handle human-AI collaborative decision making with multiple AI and multiple human experts, this is achieved by learning capability vectors in uniform dimensions. Related studies on human-AI collaborated decision making with multi-expert applies different datasets or different base models in their experiment. For example, \citep{mao2024two} use ResNet-4 for the prediction AI model, and use ResNet-10, ResNet-16, ResNet-28 with increasing capacity as the experts. They work on CIFAR 10 and SVHN image classification datasets. \citet{Hemmer2022Forming} work on three different tasks including Hate Speech, CIFAR-100 and NIH Dataset. 
% For HateSpeech, they applies a pretrained GloVe word embeddings with a single hidden neural network as the classiﬁer and allocation system, and use synthetic experts with different correct probability for African-American English and non-African English. For CIFAR100, they use a ResNet-18 pretrained on ImageNet as fixed feature extractors, and use a single-hidden-layer neural network as the classifier and allocation system. Meanwhile, they use synthetic experts with sampled perfectly predicted subclasses, while remaining subclasses are predicted uniformly at random across all superclasses. For NIH Dataset, they use a ResNet-18 pretrained on CheXpert dataset as fixed feature extractor, and use a single-hidden-layer neural network as the classifier and allocation system. In \citep{verma2023learning} works on HAM1000 (for skin lesions diagnosis), Galaxy-Zoo (for galaxy classiﬁcation) and HateSpeech. They use a ResNet-34 and a ResNet-50 for HAM10000 and Galaxy-Zoo respectively, and a fasttext representation followed by a ConvNet for HateSpeech. A 8-layer MLPMixer is used to simulate HAM10000’s expert, while the provided human annotations are sampled to simulate the expert predictions for Galaxy-Zoo and HateSpeech.

\subsection{Potential application scenarios}

In addition to traditional human-machine collaborative decision-making scenarios, the proposed method can be applied to a broader range of situations, specifically including collaborative labeling, decision participant selection, and large-scale multi-task training.

\textbf{Collaborative Annotation}: Crowdsourcing platforms typically employ a large number of temporary annotators. For each annotation task, annotators are randomly assigned to perform the labeling. However, due to variations in the skills and areas of expertise among different annotators, the quality of the annotations may be compromised. By employing a collaborative decision-making model based on capability vectors, we can learn the capability vectors of annotators from historical annotation data. This model not only facilitates collaboration among multiple annotators based on their capability vectors but also allows for the integration of annotations from both the annotators and auxiliary models. This approach can enhance the quality of annotations and improve overall annotation efficiency.
 
\textbf{Decision maker selection}: Based on the assumptions of our method, the performance of collaborative decision making can be determined by the capability vectors of decision makers, as well as the task embedding. Therefore, given the task instance, the performance can be determined by the set selection of decision makers. Further, given the task instance and part of the decision makers, the performance can be determined by the rest decision makers. We can build a predictive model for predicting the final performance of collaborative decision making based on decision makers' capability vectors and the task embedding. This can be used for selecting part or all decision makers for each particular task instance. One example is assigning editor/reviewers for research article reviewing, where each editor/reviewer can be considered as a decision maker with an associated capability vector.

\textbf{Large-scale multitask training}: Our method can be applied for classification tasks, regression tasks and generation tasks. For comparing the existing methods we focus on classification task in our experiments. For regression task, capability vectors of decision makers can determine the weights for the predicted values from all the decision makers. As to generation task, we can apply a weighted combination of scores from multiple decision makers on each of multiple generated results (e.g. generated by human writers and/or a set of LLM agents), and use it to determine which generated result to be selected. The decision makers' capability vectors can be applied for a variety of related tasks, which is comparable to the training of token embeddings on multiple language processing tasks with transformer-based models. The trained capability vectors can potentially be generalized to a larger set of tasks.  

\section{Conclusion}

In this study, we present a human-AI collaborative decision-making architecture based on capability vectors, applicable to both generative and discriminative decision tasks. By utilizing capability vectors, we can uniformly model the decision intelligence of human experts and AI models across the same set of dimensions. Additionally, we developed a learning-free global weighted merging method for collaborative decision-making involving one human expert and one AI model specifically for classification tasks, which can be applied as a baseline for check the effectiveness of instance-aware weighted merging methods. For image classification tasks and sentiment analysis task, 
% we use semantic representation of each categorical and similarity metrics to build the capability model of each experts. 
Our experiments, conducted on image classification and sentiment analysis tasks, demonstrate that the proposed method outperforms existing approaches across various human-AI collaborative scenarios. We show that for a widely used expert model in classification tasks, our method is more robust to the change of non-expertise capability level. In addition, the proposed method can be applied for multiple expert collaborative decision with or without AI decision makers. 

In future works, empirical studies involving real human experts can be done to further investigate the effectiveness of our architecture when applied in real world. More complex human decision modelings with confidence scores can also be explored.
% Further empirical studies can be done by using real human experts to check the effectiveness of our architecture. 
% In addition, our method can be applied for for collaborative decision for evaluating generated results, which can be applied for managerial decision making or textual answer evaluation.
Moreover, our method can be extended to collaborative decision-making for evaluating generated results, which holds significant potential for applications in managerial decision-making and textual answer evaluation. We believe there remains considerable opportunity for further exploration of the proposed architecture, which is left for the future studies.





\bibliography{Reference}

\newpage


\appendix

\end{document}
