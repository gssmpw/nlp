\section{Introduction}
\label{sec:intro}

% Diffusion-based text-to-image generation models~\citep{ramesh2022hierarchical, saharia2022photorealistic, rombach2022high}, trained on large datasets, have recently achieved impressive results in generating photorealistic images from textual prompts. Despite their advanced performance, these models are limited when it comes to generating user-defined concepts, which are difficult to describe accurately with text alone. This limitation has led to a growing interest in the field of subject-driven text-to-image generation \citep{DB, TI}. In this task, given a small image dataset (3-5 images) of a given subject, we want to introduce the knowledge of this subject into the pre-trained text-to-image diffusion model and learn to generate it in different contexts described by textual prompts.

Diffusion-based text-to-image generation models~\citep{ramesh2022hierarchical, saharia2022photorealistic, rombach2022high}, trained on large datasets, have recently achieved impressive results in generating photorealistic images from textual prompts. Despite their advanced performance, these models have limitations in generating user-defined concepts, that are difficult to describe accurately using text alone. This limitation has led to increased interest in subject-driven text-to-image generation \citep{DB, TI}. In this task, given a small image dataset (3-5 images) of a given subject, we want to introduce the knowledge of this subject into the pre-trained text-to-image diffusion model and learn to generate it in different contexts described by textual prompts.

% Simultaneously preserving the identity of the concept and the ability to adapt it to the new context is a difficult balance to achieve and the main challenge in personalized image generation. On the one hand, the model must generate high-fidelity images of the concepts, even if it has never encountered them during the pre-training phase. On the other hand, the model should not overfit in order to retain the ability to follow different textual descriptions of the scenes. 

Balancing the preservation of a concept's identity with its adaptation to a new context is the main challenge in personalized image generation. On the one hand, the model must generate high-fidelity images of the concepts, even if it has never encountered them during the pre-training phase. On the other hand, the model should not overfit to retain the ability to follow different textual descriptions of the scenes. 

% To achieve a better balance between concept fidelity and editability, modern methods introduce a variety of training process improvements. These include fine-tuning parameterizations \citep{DB, TI, CD, svdiff, r1e, ortogonal}, regularizations \citep{DB, CD}, and encoder-based paradigms \citep{elite}. For more detailed review see Appendix~\ref{app:related_work}. Another direction is to utilize sampling methods applied after training to enhance an already fine-tuned model. The main idea of such methods~\citep{profusion, photoswap} is to combine the sampling trajectories of prompts with concept and superclass tokens (e.g., for a dog concept we mix trajectories for two prompts: \textit{"a purple V*"} and \textit{"a purple dog"}, see Figure~\ref{fig:sampling}). The sampling-based approaches can provide a cost-effective, training-free way to improve the balance between concept identity and its editability. While fine-tuning and sampling methods are two distinct strategies to addressing the same issue, current research often does not distinguish between these methodologies. As an example, current works~\citep{profusion, photoswap} introduce complex sampling procedures alongside fixed fine-tuning, leaving unclear the impact of sampling on generation results and whether it can be integrated with other fine-tuning strategies. Furthermore, they do not compare the proposed strategies against naive sampling approaches, resulting in a lack of insight into how superclass trajectories influence the sampling process.
% In summary, the personalized generation sampling process remains underexplored, with three main open challenges: (1) \textit{The impact of superclass trajectory integration is under-researched}, as previous work has not fully elucidated how the incorporation of superclass trajectories affects the generation output. (2) \textit{Simple sampling baselines are often overlooked}, and their potential remains undervalued. (3) \textit{Limitations imposed by fine-tuning strategies}; current sampling methods are almost always tied to specific fine-tuning schemes, which restricts the ability to study sampling independently and hampers fair comparisons between different approaches.

Modern techniques introduce various improvements to the training process to balance concept fidelity and editability. These include fine-tuning parameterizations \citep{DB, TI, CD, svdiff, r1e, ortogonal}, regularizations \citep{DB, CD}, and encoder-based paradigms \citep{elite}. For a more comprehensive overview, see Appendix~\ref{app:related_work}. Another direction is to use sampling methods applied after training to improve an already fine-tuned model. The main idea of such methods~\citep{profusion, photoswap} is to combine the sampling trajectories of prompts with concept and superclass tokens (e.g., for a dog concept, we mix trajectories for two prompts: \textit{"a purple V*"} and \textit{"a purple dog"}, see Figure~\ref{fig:sampling}). Sampling-based approaches can provide a cost-effective, training-free way to improve the balance between concept identity and editability. Although fine-tuning and sampling are two distinct strategies to address the same issue, current research frequently overlooks the differences between these methodologies. For example, current works~\citep{profusion, photoswap} introduce complex sampling procedures alongside fixed fine-tuning, leaving unclear the impact of sampling on generation, as does its compatibility with other fine-tuning strategies. Furthermore, they do not compare the proposed strategies with naive sampling approaches, resulting in a lack of understanding of how superclass trajectories influence the sampling process.
In summary, the personalized generation sampling process remains underexplored, with three main open challenges: (1) \textit{The impact of superclass trajectory integration is under-researched}, as previous work has not fully elucidated how the incorporation of superclass trajectories affects the generation output. (2) \textit{Limitations imposed by fine-tuning strategies}; current sampling methods are almost always tied to specific fine-tuning schemes, which limits the ability to study sampling independently and hampers fair comparisons between different approaches. (3) \textit{Simple sampling baselines are often overlooked}, and their potential remains undervalued.

% To address these challenges, we propose several contributions aimed at advancing the understanding and application of sampling strategies in personalized text-to-image generation. Our work explores the impact of sampling methods beyond fine-tuning strategies, establishing simple yet powerful baselines. Specifically, we make the following key contributions:

To address these challenges, we propose several contributions to advance the understanding and application of sampling strategies in personalized text-to-image generation. Our work explores the impact of sampling methods beyond fine-tuning, establishing simple yet powerful baselines. In particular, we make the following key contributions:

\textbf{1. A systematic and comprehensive analysis of how superclass trajectories influence the sampling process.} We investigate various combinations of concept and superclass trajectories, including Switching, Mixed, and Masked sampling techniques, along with their hybrid variants. We carefully ablate hyperparameters across all methods, assess their importance, and retain only the most impactful ones.

% \textbf{2. A finetuning-independent evaluation of various sampling strategies.} We compare various sampling methods, including naive approaches, applied to a fixed fine-tuned model to analyze the impact of the sampling beyond the fine-tuning strategy. Moreover, we demonstrate how these strategies can be applied effectively across different fine-tuning methods, including various fine-tuning parameterizations, text embedding optimization, and hypernetworks.

\textbf{2. A finetuning-independent evaluation of various sampling strategies.} We compare various sampling methods, including naive approaches, applied to a fixed fine-tuned model, to analyze the impact of the sampling beyond the fine-tuning strategy. Moreover, we demonstrate how to effectively apply these strategies across architectures and different fine-tuning methods, including various parameterizations, text embedding optimization, and hypernetworks.

% \textbf{3. A framework for selecting the most suitable sampling method for specific generation tasks.} We perform a fair comparison of sampling methods based on trade-offs between concept fidelity, adaptability, and computational efficiency and build a framework for determining the most appropriate sampling method for specific scenarios.

\textbf{3. A framework for selecting the most appropriate sampling method for specific generation tasks.} We conduct a fair comparison of sampling methods based on trade-offs between concept fidelity, adaptability, and computational efficiency, and build a framework for identifying the most appropriate sampling method for specific scenarios.
