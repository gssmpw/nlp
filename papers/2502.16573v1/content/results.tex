\subsection{Model Evaluation}
Evaluating LawPal’s performance is essential to ensure its accuracy, efficiency, and reliability as a legal assistant. As a Retrieval-Augmented Generation (RAG) system, its effectiveness depends on FAISS’s retrieval accuracy and DeepSeek-R1:5B’s response generation quality. The evaluation process covers retrieval relevance, response correctness, computational efficiency, robustness against adversarial inputs, and user feedback, ensuring LawPal meets real-world legal standards.  

Retrieval accuracy is a key focus, as FAISS must fetch the most relevant legal documents. Metrics such as Precision@K\cite{yu2019disparity}, Mean Reciprocal Rank (MRR) and Normalized Discounted Cumulative Gain (NDCG)\cite{schwartz2021ensemble} assess how well LawPal prioritizes relevant legal texts. High scores indicate that users receive accurate legal content efficiently. The quality of generated responses is evaluated using BLEU and ROUGE scores, which measure textual similarity and key information retention. A Legal Consistency Score (LCS)\cite{wang2021equality} ensures alignment with statutes, case law, and judicial interpretations. Additionally, human legal experts review responses to validate accuracy and applicability. LawPal achieves over 90\% legal accuracy, though occasional errors arise in ambiguous legal queries, highlighting areas for improvement.  

\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[scale=0.75]
            \begin{axis}[
            xlabel={Query Complexity Level},
            ylabel={Processing Time (ms)},
            grid=both,
            scale only axis=true,
            legend pos=north east,
            style={ultra thick},
            axis line style={ultra thick},
            ]
            \addplot+[no markers] table[x=QueryComplexityLevel,y=ProcessingTime,col sep=comma]{results/Query_Processing.csv};
        \end{axis}
        \end{tikzpicture}
        \caption{Query Processing Time Analysis in LawPal}
\end{figure}

Computational efficiency is another critical factor. FAISS-based retrieval takes 10-50 milliseconds, while response generation by DeepSeek-R1:5B ranges from 800 to 1500 milliseconds, ensuring real-time legal assistance. Scalability tests confirm stable performance under heavy query loads. LawPal is also tested against adversarial inputs, including misleading legal questions, misinformation attacks, and ambiguous queries. The chatbot consistently distinguishes legal nuances, rejects speculative claims, and requests clarification when necessary.

Through structured evaluation, LawPal demonstrates high accuracy, efficiency, and resilience, making legal knowledge more accessible and reliable for users in India. The query processing time analysis measures the efficiency and speed of LawPal in retrieving and generating responses for legal queries. Since legal queries can range from simple fact-based questions to complex multi-law interpretations, understanding how query complexity affects processing time is critical for evaluating the system’s performance.

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=8cm]{query2.png}
%     \caption{Query Processing Time Analysis in LawPal}
%     \label{fig:rVisualization of knowledge graph}
% \end{figure}

LawPal’s query resolution pipeline consists of:
\begin{itemize}
    \item Query Embedding Generation → DeepSeek-R1:5B converts the legal query into a vector representation.
\end{itemize}
\begin{itemize}
    \item FAISS Vector Retrieval → The query embedding is compared with pre-indexed legal text chunks, retrieving the most relevant ones.
\end{itemize}
\begin{itemize}
    \item Response Generation → The retrieved legal context is passed to DeepSeek-R1:5B, which synthesizes a human-like response.
\end{itemize}
\begin{itemize}
    \item Post-processing \& Display → The generated response is formatted and displayed to the user.
\end{itemize}

To evaluate processing time, different types of legal queries were tested:
\begin{itemize}
    \item Simple Queries: Direct legal references, such as "What is the punishment for IPC Section 420?"
\end{itemize}
\begin{itemize}
    \item Moderate Queries: Requires retrieval of multiple legal references, such as "What are the legal remedies for breach of contract?"
\end{itemize}
\begin{itemize}
    \item Complex Queries: Involves multi-law, multi-case legal interpretations, such as "How does the Supreme Court define reasonable restrictions under Article 19(1)(a)?"
\end{itemize}

User feedback plays a crucial role in evaluating LawPal’s usability and effectiveness. Tested by lawyers, law students, and legal aid seekers, the chatbot receives 85\% user satisfaction** for accuracy and reliability. Legal professionals praise its efficient case law retrieval, while students appreciate its structured responses. However, some users request multilingual support for regional Indian languages, highlighting an area for improvement.  

Comparative testing shows LawPal outperforms rule-based legal chatbots and keyword-based search engines by delivering fact-based, up-to-date legal responses. Its ability to rank relevant legal texts higher ensures superior accuracy. Despite its strengths, challenges remain in handling multi-jurisdictional queries and synthesizing long-context legal provisions. Some specialized areas, like corporate and international law, require further fine-tuning.  

Overall, LawPal effectively integrates document retrieval with generative AI, offering precise legal assistance. While future improvements in jurisdiction-specific accuracy and multilingual support are needed, it sets a high standard for AI-driven legal research and consultation.

\subsection{Model Comparison: Comparison of FAISS and Chroma }

The choice of FAISS over Chroma in the LawPal architecture is driven by its superior retrieval speed, scalability, and efficiency in handling high-dimensional vector searches. FAISS incorporates multiple optimization techniques such as Product Quantization (PQ), Inverted Indexing (IVF), and Hierarchical Navigable Small World (HNSW) graphs, whereas Chroma primarily relies on HNSW alone. This combination allows FAISS to retrieve legal text chunks more efficiently, making it a better fit for high-speed legal queries in a Retrieval-Augmented Generation (RAG) system.  

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=8cm]{CHROMA.png}
%     \caption{Overall Result of comparing FAISS and Chroma with different number of top documents}
%     \label{Overall Result of comparing FAISS and Chroma with different number of top documents}
% \end{figure}
FAISS excels in legal document retrieval due to its superior context recall, ensuring no crucial legal provisions are missed. It consistently outperforms Chroma in recall rates, which is essential for accuracy in a legal AI chatbot like LawPal. While Chroma offers greater stability with large retrievals, it does not improve recall performance significantly.  

FAISS’s scalability and GPU acceleration enable efficient handling of large datasets, making it ideal for high-demand legal applications requiring real-time query resolution. Though Chroma provides similar context precision, recall is equally critical in legal AI, and FAISS balances both effectively.  

A challenge in evaluating retrieval models is reliance on LLM-based metrics like RAGAS\cite{es-etal-2024-ragas}, which align with human assessments only 70\% of the time, highlighting the need for expert validation. By integrating FAISS, LawPal ensures fast, comprehensive, and precise legal document retrieval, making it the superior vector store choice for legal AI.

\subsection{Model Validation}

Validating LawPal ensures its legal accuracy, consistency, and reliability through expert evaluations, adversarial testing, and benchmarking against legal AI systems. The goal is to confirm that its Retrieval-Augmented Generation (RAG) framework produces factually correct, contextually appropriate responses while minimizing errors.  

Legal correctness is assessed by comparing LawPal’s responses against Supreme Court judgments, government statutes, and legal commentaries. Expert reviews confirm an accuracy rate of over 90\%, though minor discrepancies arise in ambiguous legal provisions. Consistency testing ensures stable responses across repeated queries, with a variation rate below 5\% due to generative rephrasing rather than legal inconsistency.  

For robustness, LawPal is tested with complex and misleading legal queries. It correctly differentiates similar legal concepts and flags misinformation, refusing to propagate incorrect statements. Comparative benchmarking highlights its superiority over rule-based legal chatbots and keyword-based search engines by retrieving and synthesizing legal content dynamically, ensuring greater relevance and precision.  

User testing with lawyers, law students, and general users indicates high satisfaction with LawPal’s legal retrieval and clarity. However, multilingual support is a key area for future improvement. Limitations include occasional struggles with multi-jurisdictional queries and specialized legal domains, requiring ongoing fine-tuning.  

Overall, LawPal proves to be an accurate, reliable, and legally sound AI assistant. While enhancements in jurisdictional nuances and niche legal fields are needed, its strong validation scores and superior performance establish it as a leading tool for accessible legal knowledge.