[
  {
    "index": 0,
    "papers": [
      {
        "key": "lin-etal-2022-truthfulqa",
        "author": "Lin, Stephanie  and\nHilton, Jacob  and\nEvans, Owain",
        "title": "{T}ruthful{QA}: Measuring How Models Mimic Human Falsehoods"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "HaluEval",
        "author": "Junyi Li and Xiaoxue Cheng and Wayne Xin Zhao and Jian-Yun Nie and Ji-Rong Wen ",
        "title": "HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "yang2018hotpotqa",
        "author": "Yang, Zhilin and Qi, Peng and Zhang, Saizheng and Bengio, Yoshua and Cohen, William W and Salakhutdinov, Ruslan and Manning, Christopher D",
        "title": "HotpotQA: A dataset for diverse, explainable multi-hop question answering"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "moon2019opendialkg",
        "author": "Moon, Seungwhan and Shah, Pararth and Kumar, Anuj and Subba, Rajen",
        "title": "Opendialkg: Explainable conversational reasoning with attention-based walks over knowledge graphs"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "see2017get",
        "author": "See, Abigail and Liu, Peter J and Manning, Christopher D",
        "title": "Get to the point: Summarization with pointer-generator networks"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "yu2023kola",
        "author": "Yu, Jifan and Wang, Xiaozhi and Tu, Shangqing and Cao, Shulin and Zhang-Li, Daniel and Lv, Xin and Peng, Hao and Yao, Zijun and Zhang, Xiaohan and Li, Hanming and others",
        "title": "KoLA: Carefully Benchmarking World Knowledge of Large Language Models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "dong2023bamboo",
        "author": "Dong, Zican and Tang, Tianyi and Li, Junyi and Zhao, Wayne Xin and Wen, Ji-Rong",
        "title": "BAMBOO: A Comprehensive Benchmark for Evaluating Long Text Modeling Capacities of Large Language Models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "min2023factscore",
        "author": "Min, Sewon and Krishna, Kalpesh and Lyu, Xinxi and Lewis, Mike and Yih, Wen-tau and Koh, Pang Wei and Iyyer, Mohit and Zettlemoyer, Luke and Hajishirzi, Hannaneh",
        "title": "FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "umapathi2023med",
        "author": "Umapathi, Logesh Kumar and Pal, Ankit and Sankarasubbu, Malaikannan",
        "title": "Med-halt: Medical domain hallucination test for large language models"
      },
      {
        "key": "kang2023deficiency",
        "author": "Kang, Haoqiang and Liu, Xiao-Yang",
        "title": "Deficiency of Large Language Models in Finance: An Empirical Examination of Hallucination"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "lightman2023let",
        "author": "Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl",
        "title": "Let's Verify Step by Step"
      },
      {
        "key": "varshney2023stitch",
        "author": "Varshney, Neeraj and Yao, Wenlin and Zhang, Hongming and Chen, Jianshu and Yu, Dong",
        "title": "A stitch in time saves nine: Detecting and mitigating hallucinations of llms by validating low-confidence generation"
      },
      {
        "key": "gou2023critic",
        "author": "Gou, Zhibin and Shao, Zhihong and Gong, Yeyun and Shen, Yelong and Yang, Yujiu and Duan, Nan and Chen, Weizhu",
        "title": "Critic: Large language models can self-correct with tool-interactive critiquing"
      },
      {
        "key": "vu2023freshllms",
        "author": "Vu, Tu and Iyyer, Mohit and Wang, Xuezhi and Constant, Noah and Wei, Jerry and Wei, Jason and Tar, Chris and Sung, Yun-Hsuan and Zhou, Denny and Le, Quoc and others",
        "title": "Freshllms: Refreshing large language models with search engine augmentation"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "yin2023woodpecker",
        "author": "Yin, Shukang and Fu, Chaoyou and Zhao, Sirui and Xu, Tong and Wang, Hao and Sui, Dianbo and Shen, Yunhang and Li, Ke and Sun, Xing and Chen, Enhong",
        "title": "Woodpecker: Hallucination correction for multimodal large language models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "chen2023alpagasus",
        "author": "Chen, Lichang and Li, Shiyang and Yan, Jun and Wang, Hai and Gunaratna, Kalpa and Yadav, Vikas and Tang, Zheng and Srinivasan, Vijay and Zhou, Tianyi and Huang, Heng and others",
        "title": "Alpagasus: Training a better alpaca with fewer data"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "elaraby2023halo",
        "author": "Elaraby, Mohamed and Lu, Mengyin and Dunn, Jacob and Zhang, Xueying and Wang, Yu and Liu, Shizhu",
        "title": "Halo: Estimation and reduction of hallucinations in open-source weak large language models"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "tian2023fine",
        "author": "Tian, Katherine and Mitchell, Eric and Yao, Huaxiu and Manning, Christopher D and Finn, Chelsea",
        "title": "Fine-tuning Language Models for Factuality"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "elaraby2023halo",
        "author": "Elaraby, Mohamed and Lu, Mengyin and Dunn, Jacob and Zhang, Xueying and Wang, Yu and Liu, Shizhu",
        "title": "Halo: Estimation and reduction of hallucinations in open-source weak large language models"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "azaria2023internal",
        "author": "Azaria, Amos and Mitchell, Tom",
        "title": "The internal state of an llm knows when its lying"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "li2023inference",
        "author": "Li, Kenneth and Patel, Oam and Vi{\\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin",
        "title": "Inference-Time Intervention: Eliciting Truthful Answers from a Language Model"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "zou2023representation",
        "author": "Zou, Andy and Phan, Long and Chen, Sarah and Campbell, James and Guo, Phillip and Ren, Richard and Pan, Alexander and Yin, Xuwang and Mazeika, Mantas and Dombrowski, Ann-Kathrin and others",
        "title": "Representation engineering: A top-down approach to ai transparency"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "yu2023kola",
        "author": "Yu, Jifan and Wang, Xiaozhi and Tu, Shangqing and Cao, Shulin and Zhang-Li, Daniel and Lv, Xin and Peng, Hao and Yao, Zijun and Zhang, Xiaohan and Li, Hanming and others",
        "title": "KoLA: Carefully Benchmarking World Knowledge of Large Language Models"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "lin-etal-2022-truthfulqa",
        "author": "Lin, Stephanie  and\nHilton, Jacob  and\nEvans, Owain",
        "title": "{T}ruthful{QA}: Measuring How Models Mimic Human Falsehoods"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "HaluEval",
        "author": "Junyi Li and Xiaoxue Cheng and Wayne Xin Zhao and Jian-Yun Nie and Ji-Rong Wen ",
        "title": "HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models"
      }
    ]
  }
]