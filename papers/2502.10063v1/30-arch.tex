\section{Strassen Architecture}
\label{smm:sec:arch}
The proposed architectures achieve a more efficient implementation of \sa than what is possible through execution on CPUs and GPUs by pipelining and performing the extra additions and data movement steps at all levels of recursion in parallel with the matrix multiplications.
The architectures are functionally equivalent to conventional multisystolic array designs while allowing the theoretical complexity reductions of \sa to be translated directly into hardware resource savings.

\subsection{Memory Layout and Access Algorithm}
\label{smm:sec:mem-layout}

In order to perform the extra Strassen data movement and addition steps at all levels of recursion in parallel with the matrix multiplications, the architecture reads one row/column at a time of the \A and \B input matrix \subblocks from the lowest level of recursion in \eq{smm:eq:strass-first} simultaneously.
This generates and provides all \T and \Ss \subblocks one row/column at a time for performing all the matrix multiplications in \eq{smm:eq:strass-last} at the lowest level of recursion in parallel.
The \T and \Ss \subblocks are all immediately generated from the \A and \B input \subblocks and consumed in parallel like this to eliminate any additional execution time or hardware resources needed for storing/re-accessing them for later use.

\begin{figure}
  \centering
  \includegraphics[scale=.75]{smm-mem-layout.eps}
  \caption{Example data layout for the \A matrix in memory for an architecture implementing Strassen matrix multiplication for 2 levels of recursion  (\smmArch?2).
    Each address $i$ contains every $m^{th}$ row of \A concatenated together starting at row $i$ (notated as \m.A'{i:m:,:}).
    To help illustrate this, the gray coloured rows are all elements of \A belonging to address 0, which forms \m.A'{0:m:,:} containing row 0 of every \A \subblock from the lowest level of recursion in \eq{smm:eq:strass-first}.
    The organization for the \B matrices in memory are the same, except that the order of the elements is transposed compared to the \A matrix layout shown here.}
  \label{smm:fig:mem}
\end{figure}

To achieve this, each \AB matrix fed into the MXU is divided into $4^r$ equal \subblocks of size $m$\by$k$ for \A and of size $k$\by$n$ for \B, where each row/column $i$/$j$ of each \A/\B \subblock is stored in the accelerator's \A and \B memories at location $i$/$j$ plus an offset.
An example of this memory layout for implementing 2 levels of Strassen recursion is shown in \fig{smm:fig:mem}.
This means that each \A memory location $i$ is a vector containing every $m^{th}$ row of \A starting at row $i$ concatenated together (notated as \Av), and each \B memory location $j$ is a vector containing every $n^{th}$ column of \B starting at column $j$ concatenated together (notated as \Bv).
This allows one row or column of all $4^r$ \A/\B \subblocks from the lowest level of recursion in \eq{smm:eq:strass-first} to all be read at once from a single memory location and fed into the MXU each clock cycle.
\Av and \Bv rows/columns are then read consecutively when feeding the \AB blocks into the MXU.

As shown in \eq{smm:eq:strass-first}, the input \AB matrices at each level of recursion are divided into four \block quadrants labelled \An and \Bn of size $M$\by$K$ for \An quadrants and of size $K$\by$N$ for \Bn quadrants.
The portions of each \Av and \Bv vector belonging to quadrant \An and \Bn are notated as \Anv and \Bnv.
The MXU then computes and returns row $i$ of all \C \subblocks from the lowest level of recursion in \eq{smm:eq:strass-last} in every clock cycle $i$, allowing \Cv to be stored in the same format as \A in memory for if \C will later be taken as an \A input for a later matrix multiplication.


\subsection{Strassen Multisystolic Array Design}
\begin{figure}
  \centering
  \includegraphics[scale=.89]{smm-mxu-top.eps}
  \caption{Top-level diagram of the proposed \smmArch multisystolic array architecture for implementing Strassen matrix multiplication \seq for $r$ levels of recursion in hardware.}
  \label{smm:fig:smm-mxu}
\end{figure}
\begin{figure}
  \centering
  \includegraphics[scale=.89]{smm-mxu-additions.eps}
  \caption{Internal structure of the \smmArch MXU addition vectors from \fig{smm:fig:smm-mxu}.
  }
  \label{smm-add-units}
\end{figure}

\Figure \ref{smm:fig:smm-mxu} shows the proposed \smmArch multisystolic array architecture.
Rather than having one $X$\by$Y$ MXU with $X$ columns and $Y$ rows of MAC units for efficiently multiplying matrices down to size $X$\by$Y$, this architecture consists of $7^r$ smaller $X/2^r$\by$Y/2^r$ MXUs that together efficiently multiply matrices down to the same size but at a higher throughput.
Furthermore, it achieves this with fewer MAC units than a conventional multisystolic array design.
This both allows smaller matrices to be multiplied at a higher utilization and increases the throughput per MAC unit.

The \Av and \Bv vectors read into the MXU are first divided into their four \Anv and \Bnv portions depending on which quadrant of \A/\B each element belongs to as shown in \fig{smm:fig:smm-mxu}.
They then pass through the \A/\B addition vectors shown in \fig{smm-add-units} (a) and (b) to form the \Tv/\Sv matrices.
The \A/\B addition vectors both contain 5 addition vectors each consisting of $K$ scalar adders or subtractors, where $K$ is the width of the four \m.A?{ij} \blocks and the height of the four \m.B?{ji} \blocks as defined in \secn{smm:sec:mem-layout}.
The 7 \Tv/\Sv vectors then pass into the next level of \smmArch?{r-1} MXUs to perform the 7 matrix \block multiplications.
The \Qv vectors of the matrix \block multiplication outputs then pass through the \Qv addition vectors shown in \fig{smm-add-units} (c) consisting of 8 addition vectors each containing $N$ scalar adders or subtractors.
This forms the final \C product, where $N$ is the width of the four \m.B?{ji} \blocks as defined in \secn{smm:sec:mem-layout}.

Each of the 7 \smmArch?{r-1} MXUs can contain 7 more \smmArch?{r-2} MXUs for implementing another level of \s recursion and repeating the process above, or they can be instantiated as a baseline \mmArch?\zero MXU shown in \Figure \ref{smm:fig:MM-mxu}.
For implementing the next level of \smmArch?{r-2} MXUs inside each \smmArch?{r-1} MXU, each \Tv/\Sv input passed into an \smmArch?{r-1} MXU will then be considered as the full \Av/\Bv inputs within that MXU and are split again into the next level of four \Anv/\Bnv vectors.
The dimensions of the matrix \blocks being read/computed and the number of scalar adders in the addition vectors within each \smmArch?{r-1} MXU will then be reduced by a factor of 2 at each level of recursion.
For fixed-point implementations, the \Tv/\Sv inputs to each \smmArch?{r-1} MXU that were formed from an addition or subtraction in the \A or \B vector addition units will have an increased bitwidth by 1 bit.


\subsection{Baseline Designs}

\begin{figure}
  \centering
  \includegraphics[scale=1.2]{smm-baseline-mm0-mxu.eps}
  \caption{Baseline \mmArch?\zero single-systolic array architecture that implements conventional matrix multiplication \eq{smm:eq:mmZero} in hardware, provided for completeness and clarity.
    It is instantiated at the lowest level of recursion in the \smmArch and \mmArch MXU architectures.
    $X$ here represents the width of the $a$ and $b$ vectors entering the \mmArch?\zero MXU, and $Y$ represents the width of the $c$ vectors exiting the MXU.}
  \label{smm:fig:MM-mxu}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[scale=.78]{smm-baseline-mmr-mxu.eps}
  \caption{Baseline \sAlg.{\mm?r} multisystolic array architecture for implementing conventional blocked matrix multiplication \eq{smm:eq:mm} for $r$ levels of recursion in hardware.}
  \label{smm:fig:multi-mm-mxu}
\end{figure}

We later compare the \smmArch?r architectures with baseline \mmArch multisystolic array architectures shown in \fig{smm:fig:multi-mm-mxu} which execute \eq{smm:eq:mm} in parallel for $r$ levels of recursion.
The baseline \mmArch architectures are functionally identical to the \smmArch architectures, but they consist of $8^r$ smaller $X/2^r$\by$Y/2^r$ MXUs rather than $7^r$.
\Figure \ref{smm:fig:MM-mxu} also shows the internal structure of each baseline \mmArch?\zero MXU present at the lowest level of recursion in each \smmArch and \mmArch architecture, and \fig{smm:fig:pes} shows the internal structure of the processing elements (PE)s inside the \mmArch?\zero MXUs.

\begin{figure}
  \centering
  \includegraphics[scale=.8]{smm-PE.eps}
  \caption{The internal PE structure of each \mmArch?\zero MXU from \fig{smm:fig:MM-mxu}, provided for completeness.
    Here, $w_a$ is the additional bitwidth added to account for accumulation, equal to $\ceil{\tx{log}_2(X)}$, where $X$ is the width of the $a$ and $b$ vectors entering the \mmArch?\zero MXU.
  }
  \label{smm:fig:pes}
\end{figure}
