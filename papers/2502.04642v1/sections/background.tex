\section{Background and Problem Formulation}
\label{sec:background-and-problem-formulation}

%% TODO:
% - Biographies.
% - Headers.
% - Index Terms.
% - Footers, funding information, date of submission.
% - index terms, keywords.
% - change logo
% - change link color and algorithm comment color.
% - Word limit for abstract.
% 
% - Code: add readme with figure.
% - arXiv version.


%% Checklist:
% - Change online to dynamic in the title and elsewhere.
% - Check spelling in American English.
% - Use `robust BiMPC' instead of `robust MPC' (introduction, arXiv).
% - Check if acknowledgments are needed.
% - Section headings should be capitalized, but theorem names should not (arXiv).
% - Use 'incentive hierarchical MPC' instead of 'incentivized hierarchical MPC' (introduction, arXiv).
% - Use Assumptions, Secs, etc (introduction, arXiv).
% - Check punctuation of equations (and text above) and text alignment below equations (arXiv).
% - Team-optimal should be hyphenated.

% - Check dimensions of variables (arXiv).
% - Use := appropriately (arXiv).

% - Use singular instead of plural. For example, incentive instead of incentives, input instead of inputs, state instead of states.
% - Functions with cdot instead of variables.


\subsection{Convex Analysis}
\label{subsec:convex-analysis}

For a function $f: \real^n \rightarrow \exreal$, the epigraph of $f$ is defined as $\epi{f} = \{(x, t) \in \real^{n+1}: f(x) \leq t, x \in \dom{f}\}$.
% Note that $\epi{f} \subset \real^{n+1}$ even though $f$ takes values in $\exreal$.
Note that $\epi{f} \subset \real^{n+1}$.
A function $f: \real^n \rightarrow \real \cup \{\infty\}$ is a closed proper convex function if $\epi{f}$ is a closed, nonempty, and convex set respectively~\cite[Sec.~4, Sec.~7]{rockafellar1997convex}.
% For a convex function $f: \real^n \rightarrow \real$ with $\dom{f} \neq \real^n$, we can define its extended-value extension $\tilde{f}: \real^n \rightarrow \real \cup \{\infty\}$ as  $\tilde{f}(x) = \infty \ \forall x \notin \dom{f}$ and $\tilde{f}(x) = f(x)$ otherwise~\cite[Sec.~3.1.2]{boyd2004convex}.
% The function $f$ is convex if and only if its extended-value extension $\tilde{f}$ is convex.
% We use $f$ interchangeably with $\tilde{f}$ throughout the paper, emphasizing the distinction when necessary.


\subsubsection{Subdifferential of a Convex Function}
\label{subsubsec:subdifferential-of-a-convex-function}

The subdifferential of a convex function $f: \real^n \rightarrow \exreal$ at $x$ is~\cite[Sec.~23]{rockafellar1997convex}
\begin{equation}
\label{eq:subdifferential-definition}
    \partial{f}(x) = \{v \in \real^n: f(z) \geq f(x) + \langle v, z-x\rangle, \ \forall z\}.
\end{equation}
% \hidetext{$\partial{f}(x)$ defines the set of linear functionals that bound $f$ from below, and touch $f$ at $x$.}
$\partial{f}$ is called the subdifferential of $f$.
For all $x$, $\partial{f}(x)$ is a closed, convex set~\cite[Sec.~23]{rockafellar1997convex}.
A proper convex function $f$ is subdifferentiable on $\relint(\dom{f})$, and $\partial{f}(x)$ is non-empty and bounded if and only if $x \in \setint(\dom{f})$~\cite[Th.~23.4]{rockafellar1997convex}.
% In this paper, we assume that proper convex functions are subdifferentiable on their entire domain.


\subsubsection{Conjugate of a Convex Function}
\label{subsubsec:conjugate-of-a-convex-function}

For a convex function $f$, its conjugate $f^*: \real^n \rightarrow \exreal$ is defined as~\cite[Sec.~12]{rockafellar1997convex}
\begin{equation}
\label{eq:conv-analysis-conjugate}
    f^*(v) = \textstyle{\sup}_x \ (\langle x, v\rangle - f(x)).
\end{equation}
For a proper convex function $f$, $f^*$ is a closed proper convex function~\cite[Thm.~12.2]{rockafellar1997convex}.
For a closed proper convex function $f$, $f^{**} = f$~\cite[Cor.~12.2.1]{rockafellar1997convex}, \changes{and the subdifferential of $f^*$ is given by~\cite[Thm.~23.5]{rockafellar1997convex}}
\begin{equation}
\label{eq:conv-analysis-conjugate-subgrad}
    \partial{f^*}(v) = \textstyle{\argmax}_x \ (\langle x, v\rangle - f(x)).
\end{equation}
% The dual norm $\lVert \cdot \rVert_*$ corresponding to a norm $\lVert \cdot \rVert$ is defined as $\lVert y\rVert_* = \sup \{y^\top x: \lVert x\rVert \leq 1\}$ \cite[App.~A.1.6]{boyd2004convex}.


\subsubsection{Strong Convexity and Lipschitz Smoothness}
\label{subsubsec:strong-convexity-and-lipschitz-smoothness}

% A function $f: \real^n \rightarrow \exreal$ is strongly convex with modulus $\constsc > 0$, if $\dom{f}$ is convex and $\forall \ x_1, x_2 \in \dom{f}, \alpha \in (0, 1)$,
% \begin{equation}
% \begin{split}
%     f(\alpha x_1 + (1-\alpha)x_2) \leq & \ \alpha f(x_1) + (1-\alpha)f(x_2) \\
%     & \ - \frac{\constsc \alpha (1-\alpha)}{2} \lVert x_1 - x_2 \rVert^2.
% \end{split}
% \end{equation}
% % \hidetext{i.e., at each $x$, $f$ can be bound from below by a quadratic function with hessian $\constsc I$, that touches $f$ at $x$.}
% $f$ is strongly convex with modulus $\constsc$ if and only if $f - (\constsc/2)\lVert \cdot \rVert^2$ is convex~\cite[Prop.~IV.1.1.2]{hiriart1996convex}.
% A proper function $f: \real^n \rightarrow \real \cup \{\infty\}$ is strongly convex with modulus $\constsc > 0$, if $\dom{f}$ is convex and $f - (\constsc/2)\lVert \cdot \rVert^2$ is convex~\cite[Prop.~IV.1.1.2]{hiriart1996convex}.
A proper function $f: \real^n \rightarrow \real \cup \{\infty\}$ is strongly convex with modulus $\constsc > 0$ \changes{(abbreviated as $\constsc$-strongly convex)}, if $\dom{f}$ is convex and for all $x \in \dom{f}$ and $v \in \partial f(x)$,
\begin{equation}
    f(z) \geq f(x) + \langle v, z - x\rangle + (\constsc/2) \lVert z - x\rVert^2, \quad \forall z.
\end{equation}
\changes{A function $f$ is $\constsc$-strongly convex if and only if $f - (\constsc/2)\lVert \cdot\rVert^2$ is convex~\cite[Prop.~IV.1.1.2]{hiriart1996convex}.}
Strongly convex functions with closed domains have unique minima.
So by \eqref{eq:conv-analysis-conjugate-subgrad}, the conjugate of a strongly convex function is differentiable (see Prop.~\ref{prop:duality} below).
A differentiable function $f: \real^n \rightarrow \exreal$ is Lipschitz smooth with constant $\constls > 0$ \changes{(abbreviated as $\constls$-smooth)} if $\nabla f$ is Lipschitz continuous with constant $\constls$ on $\dom{f}$, i.e.,
\begin{equation}
    \lVert \nabla f(x^1) - \nabla f(x^2) \rVert \leq \constls \lVert x^1 - x^2 \rVert, \ \forall x^1, x^2 \in \dom{f}.
\end{equation}

There is a duality between strongly convex functions and Lipschitz smooth convex functions as follows. %(also see~\cite{zhou2018fenchel}).
\begin{proposition}~\cite[Thm.~X.4.2.1, Thm.~X.4.2.2]{hiriart1993convex}
\label{prop:duality}
    If a proper function $f: \real^n \rightarrow \real \cup \{\infty\}$ is $\constsc$-strongly convex, then $\dom{f^*} = \real^n$ and $f^*$ is $(1/\constsc)$-smooth.
    % If $f$ is convex and $\constls$-smooth with $\dom{f} = \real^n$, then $f^*$ is $(1/\constls)$-strongly convex on any convex subset of $\dom(\partial f^*)$.
\end{proposition}


\subsubsection{Dual Cones}
\label{subsubsec:dual-cones}

Let $\mathset{K} \subset \real^n$ be a closed convex cone.
Then, $\mathset{K}$ defines a relation $\preceq_\mathset{K}$ on $\real^n$ as follows:
$x^1 \preceq_\mathset{K} x^2$ if and only if $x^2-x^1 \in \mathset{K}$~\cite[Sec.~2.4]{boyd2004convex}.
\hidetext{Note that $\preceq_\mathset{K}$ is not a partial order on $\real^n$ (it is transitive and reflexive but might not be antisymmetric).}
The dual cone $\mathset{K}^*$ of a cone $\mathset{K}$ is defined as~\cite[Sec.~2.6]{boyd2004convex}
\begin{equation}
\label{eq:dual-cone-def}
    \mathset{K}^* = \{v: \langle v, x\rangle \geq 0, \forall x \in \mathset{K}\}.
\end{equation}
The dual cone $\mathset{K}^*$ depends on the inner product chosen on $\real^n$.
For any cone $\mathset{K}$, $\mathset{K}^*$ is a closed convex cone. % ~\cite[Ex.~2.31]{boyd2004convex}.


\subsubsection{Convex Vector Functions}
\label{subsubsec:convex-vector-functions}

Let $\mathset{K} \subset \real^m$ be a closed convex cone.
A function $f: \real^n \rightarrow \real^m$ is called $\mathset{K}$-convex if $\dom{f}$ is convex and for all $x^1, x^2 \in \dom{f}$ and $\alpha \in [0, 1]$,
\begin{equation}
\label{eq:k-convex-function}
    f(\alpha x^1 + (1-\alpha) x^2) \preceq_\mathset{K} \alpha f(x^1) + (1-\alpha) f(x^2).
\end{equation}
For any $\mathset{K}$-convex function $f$ and $\lambda \succeq_{\mathset{K}^*} 0$, $\langle \lambda, f(\cdot) \rangle$ is a convex function~\cite[Sec.~3.6.2]{boyd2004convex}.

In the subsequent sections, we will use convex analysis to compute optimal incentives for the hierarchical MPC problem.
Next, we motivate and describe the hierarchical MPC problem.

\subsection{Motivating Example}
\label{subsec:motivating-example}

As a motivating example for the hierarchical MPC formulation in the next subsection, we consider the charging of a population of EVs.
Given the unit price of electricity, each EV determines its electricity consumption by considering the total price of electricity, battery degradation, and current state of charge (SoC).
For the same electricity price, each EV can have different consumption depending on its SoC.
An independent system operator (ISO) determines the amount of electricity generated, the amount stored in a storage battery,
and the electricity price.
The ISO's goal is to minimize a social cost, which comprises the cost of electricity generation and the cost of not meeting the EV consumption demand.
In particular, the ISO's cost only considers the average EV consumption demand (computed using current EV SoCs); for the same average consumption, individual consumption may depend on the EV SoC.
Similarly, the ISO determines electricity generation based only on the average consumption.

Such a hierarchical problem is an incentive Stackelberg game (see Sec.~\ref{subsubsec:incentive-Stackelberg-games}), where the leader (the ISO) provides incentives (electricity prices) to the followers (the EV population) to minimize the social cost.
The following subsection provides a general hierarchical MPC formulation applicable to the above example.
In Secs.~\ref{sec:linear-incentives-for-hierarchical-mpc}-\ref{sec:multiple-lompcs}, we develop an algorithm to solve the hierarchical MPC problem, and in Sec.~\ref{sec:numerical-examples}, we apply our method to the EV charging example.
We will occasionally refer to the EV charging example to provide intuition.


\subsection{Hierarchical MPC Formulation}
\label{subsec:hierarchical-formulation}

We consider a hierarchical control system consisting of multiple lower-level systems and an upper-level system as a generalization of the dynamics in \cite{mintz2018control}.
Let $\mathset{M}$ be an index set denoting the set of lower-level systems, with $M := |\mathset{M}|$.
For $i \in \mathset{M}$, the $i$-th lower-level system has state $y^i \in \real^\Ny$ and %inputs $w^i \in \real^\Nw$ and $u \in \real^\Nu$.
\changes{input $(u, w^i) \in \real^\Nu \times \real^\Nw$}.
We define $\bm{w} := (w^1, ..., w^{M})$.
The upper-level system has state $x \in \real^\Nx$ and input $\nu := (u, \bm{w})$.
The hierarchical system has coupled linear dynamics given by,
\begin{equation}
\label{eq:coupled-dynamics}
\begin{split}
    x_{k+1} & = A^u x_k + B^u_1 u_k + B^u_2 w_k, \\
    y^i_{k+1} & = A^l y^i_k + B^l_1 u_k + B^l_2 w^i_k, \quad i \in \mathset{M}, \\
    w_k & := \frac{1}{M} \sum_{i \in \mathset{M}} w^i_k,
\end{split}
\end{equation}
\changes{where the superscripts `u' and `l' refer to the upper and lower-level systems, respectively.
Variable subscripts represent time, and superscripts are used for the index set $\mathset{M}$.
The superscript $(\cdot)^*$ denotes an optimal value, while the superscript $(\cdot)^{(k)}$ denotes the $k$-th iterate of a sequence.}
% where $A^u \in \real^{\Nx \times \Nx}$, $B^u_1 \in \real^{\Nx \times \Nu}$, $B^u_2 \in \real^{\Nx \times \Nw}$, $A^l \in \real^{\Ny \times \Ny}$, $B^l_1 \in \real^{\Ny \times \Nu}$, and $B^l_2 \in \real^{\Ny \times \Nw}$.
We define $\bm{y} := (y^1, ..., y^{M})$ as the joint state of all the lower-level systems, and $\xi := (x, \bm{y})$ as the state of the entire system.
Note that the upper-level system dynamics depend on the average $w_k$, similar to the EV charging example in Sec.~\ref{subsec:motivating-example}.

\subsubsection{Lower-level MPC Problem}
\label{subsubsec:lower-level-mpc-problem}

%For $i \in \mathset{M}$, 
The $i$-th lower-level MPC (LoMPC) problem with horizon $\horizon$ optimizes the input sequence $w^i_{0:\horizon-1} = (w^i_0, ..., w^i_{\horizon-1}) \in \real^{\Nw\horizon}$, given the initial state $\xi_0$ and the input sequence $u_{0:\horizon-1} = (u_0, ..., u_{\horizon-1}) \in \real^{\Nu\horizon}$.
The symbols $\xi$, $x$, $\bm{y}$, $\nu$, $u$, and $\bm{w}$ are overloaded to also represent $\xi_{0:\horizon}$, $x_{0:\horizon}$, $\bm{y}_{0:\horizon}$, $\nu_{0:\horizon-1}$, $u_{0:\horizon-1}$, and $\bm{w}_{0:\horizon-1}$ respectively.
The variables used in the hierarchical MPC are tabulated in Tab.~\ref{tab:hierarchical-mpc-variable-definitions}.
The $i$-th LoMPC problem is given by,
\begin{subequations}
\label{eq:ith-lompc}
\begin{alignat}{6}
    % (y^{i*}, w^{i*})(\xi_0, u) \in \ & \argmin_{y^i, w^i} \ g^i(y^i, w^i; \xi_0, u), \span\span\span\span\span\span \label{subeq:ith-lompc-cost} \\
    % & \ \text{s.t} \quad
    % & \ \text{s.t} \quad
    \min_{y^i, w^i} \ & g^i(y^i, w^i; \xi_0, u), \span\span\span\span\span\span \label{subeq:ith-lompc-cost} \\
    \text{s.t} \quad &
    && y^i_{k+1}   &&= A^l y^i_k + B^l_1 u_k + B^l_2 w^i_k, \ \ && k \in \langle \horizon \rangle, \label{subeq:ith-lompc-dynamics} \\
    &&& y^i_k \in \mathset{Y}, \ w^i_k \in \mathset{W}, \span\span \ && k \in \langle \horizon \rangle, \label{subeq:ith-lompc-stage-constraints} \\
    &&& y^i_N \in \mathset{Y}_\Omega, \span\span\span\span\span\span \label{subeq:ith-lompc-terminal-constraints}
\end{alignat}
\end{subequations}
where $\mathset{Y}, \ \mathset{Y}_\Omega\subset \real^\Ny$ and $\mathset{W} \subset \real^\Nw$ are closed convex sets, and $\langle \horizon \rangle := \{0, ..., \horizon-1\}$.
The function $g^i$ is parametrized by the input $u$ from the bilevel MPC and $\xi_0$.
The constraints in \eqref{eq:ith-lompc} can be added to the cost using the indicator function (see Sec.~\ref{subsec:notations}) to obtain a reduced LoMPC problem as follows:
\begin{equation}
\label{eq:reduced-ith-lompc}
w^{i*}(\xi_0, u) := \textstyle{\argmin}_{w^i} \ g^i(w^i; \xi_0, u),
\end{equation}
where the symbol $g^i$ is overloaded to represent the new cost function, where the constraints from \eqref{eq:ith-lompc} are added to the cost \changes{using the indicator function}.
We will work with the simple formulation of the cost function, \eqref{eq:reduced-ith-lompc}, for the theory and use the full formulation, \eqref{eq:ith-lompc}, for the implementation.
The assumptions on $g^i$ are as follows:
\begin{assumption} (Properties of $g^i$)
\label{assum:properties-of-gi}
    $g^i(\cdot \, ; \xi_0, u)$ is a closed proper function and $\constsc$-strongly convex, for all $(\xi_0, u)$.
    Further, $g^i(\cdot \: ; \xi_0, u)$ is subdifferentiable on its domain for each $(\xi_0, u)$.
\end{assumption}
Since $g^i(\cdot \,; \xi_0, u)$ is closed and strongly convex, a unique optimum for $w^i$ exists, given \eqref{eq:ith-lompc} is feasible (see Sec.~\ref{subsubsec:strong-convexity-and-lipschitz-smoothness}).

For the EV charging example in Secs.~\ref{subsec:motivating-example} and \ref{sec:numerical-examples}, $y^i_k$ is the SoC and $w^i_k$ is the charging rate of EV $i$ at time $k$.
The LoMPC cost function $g^i$ comprises tracking costs for maximum SoC and costs for high charging rates.


\subsubsection{Bilevel MPC Problem}
\label{subsubsec:bilevel-mpc-problem}

Given the initial state $\xi_0$, the bilevel MPC (BiMPC) problem optimizes the input sequence $\nu = (u, \bm{w})$, subject to the constraint that $w^i$ is obtained as the optimal solution of the LoMPC problem \eqref{eq:reduced-ith-lompc}.
In other words, the BiMPC accounts for the fact that each LoMPC solves an optimization problem to determine its input.
The BiMPC problem is given by,
\begin{subequations}
\label{eq:bimpc}
\begin{alignat}{6}
    % (\xi^*, \nu^*)(\xi_0) \in \ & \argmin_{\xi, \nu=(u,w)} f(\xi, \nu; \xi_0), \span\span\span\span\span\span \label{subeq:bimpc-cost} \\
    % & \ \text{s.t} \quad
    \min_{x, \nu=(u,\bm{w})} \ & f(x, u, w; \xi_0), \span\span\span\span\span\span \label{subeq:bimpc-cost} \\
    \text{s.t} \quad &
    && w^i = \textstyle{\argmin}_{w^i} \ g^i(w^i; \xi_0, u), && i \in \mathset{M}, \label{subeq:bimpc-w-optimality} \\
    &&& x_{k+1} = A^u x_k + B^u_1 u_k + B^u_2 w_k, \ \ && k \in \langle \horizon \rangle, \label{subeq:bimpc-dynamics} \\ 
    &&& w_k = \frac{1}{M} \sum_{i \in \mathset{M}} w^i_k, \ \ && k \in \langle \horizon \rangle, \span\span\span\span \\
    &&& x_k \in \mathset{X}, \ u_k \in \mathset{U}, \ && k \in \langle \horizon \rangle, \label{subeq:bimpc-stage-constraints} \\
    &&& x_N \in \mathset{X}_\Omega, \span\span\span\span\span\span \label{subeq:bimpc-terminal-constraints}
\end{alignat}
\end{subequations}
where $\mathset{X}, \ \mathset{X}_\Omega \subset \real^\Nx$ and $\mathset{U} \subset \real^\Nu$ are closed convex sets, and $f$ is jointly continuous in $(x, u, w)$.
Note that the cost function $f$ depends on the average $w = (w_1, ..., w_{N-1})$.
% While no particular assumptions on \eqref{eq:bimpc}, other than the existence of a minimum, are needed, we consider $f$ to be a convex function and $\mathset{X}$, $\mathset{X}_\Omega$, $\mathset{U}$ to be convex sets for the numerical examples (also nonlinear $x$-dynamics).
Similar to the LoMPC problem, the constraints \eqref{subeq:bimpc-dynamics}, \eqref{subeq:bimpc-stage-constraints}, and \eqref{subeq:bimpc-terminal-constraints} can be added to the cost \eqref{subeq:bimpc-cost} using the indicator function to obtain the reduced BiMPC problem as follows:
\begin{subequations}
\label{eq:reduced-bimpc}
\begin{alignat}{6}
    \hspace{-5pt} \nu^*(\xi_0) \in \ && \argmin_{\nu=(u, \bm{w})} \ & f(u, w; \xi_0), \span\span\span\span \label{subeq:reduced-bimpc-cost} \\
    && \ \text{s.t} \quad &
    w^i &&= \textstyle{\argmin}_{w^i} \, g^i(w^i; \xi_0, u), \, && i \in \mathset{M}, \hspace{-5pt} \label{subeq:reduced-bimpc-w-optimality} \\
    &&& w_k &&= \frac{1}{M} \sum_{i \in \mathset{M}} w^i_k, && \hspace{-5pt} k \in \langle N\rangle. \hspace{-5pt}
\end{alignat}
\end{subequations}
The optimization problems \eqref{eq:reduced-ith-lompc} and \eqref{eq:reduced-bimpc} define the hierarchical MPC problem.
At each time step, the current state $\xi(t)$ is provided to the BiMPC \eqref{eq:reduced-bimpc}, and the first input $\nu^*_0$ from the optimal input sequence $\nu^*$ is applied to get the next state.
Throughout the paper, we assume that \eqref{eq:reduced-bimpc} is feasible and has an optimal solution for all $\xi_0$.

For the EV charging example in Secs.~\ref{subsec:motivating-example} and \ref{sec:numerical-examples}, $x_k$ is the SoC of the storage battery controlled by the ISO at time $k$ and $u_k$ is the amount of electricity generated.
The dynamics \eqref{subeq:bimpc-dynamics} corresponds to energy balance, and the cost function $f$ is a social cost comprising electricity generation cost and EV electricity demand cost.

Dividing the problem of control selection for the hierarchical system into a multi-level problem such as \eqref{eq:reduced-bimpc} can result in a loss of controllability or stabilizability properties of the overall hierarchical system if the cost functions $g^i$ are selected inappropriately~\cite{mintz2018control}.
% Intuitively, the lower-level MPC problem \eqref{eq:reduced-ith-lompc} enforces a constraint on the control $\nu$, given by \eqref{subeq:reduced-bimpc-w-optimality}, which restricts it to a subset of the original control space.
% If the cost function $g^i$ is selected inappropriately, the reduced control space can cause a loss of controllability or stabilizability.
% Further, solution techniques for hierarchical MPC problems, such as those given by \eqref{eq:reduced-ith-lompc} and \eqref{eq:reduced-bimpc}, are often restricted to specific problem structures and require knowledge of the cost function $g^i$ of the LoMPC.

\begin{table}[tbp]
% \footnotesize
\setlength\extrarowheight{2pt}
\caption{Hierarchical MPC variable definitions}\label{tab:hierarchical-mpc-variable-definitions}
\begin{tabularx}{\columnwidth}{|c|c|L|}
\hline
Variable & Domain & Definition \\ \hline
$(y^i_k, w^i_k, u_k)$ & $\real^{\Ny+\Nw+\Nu}$ & State and input of $i$-th lower-level system at time $k$ \\
$(y^i, w^i)$ & $\real^{\Ny(\horizon+1)+\Nw\horizon}$ & $\bigl((y^i_0, ..., y^i_\horizon), (w^i_0, ..., w^i_{\horizon-1})\bigr)$ \\
$(\bm{y}, \bm{w})$ & $\real^{\Ny(\horizon+1) M+\Nw \horizon M}$ & $\bigl((y^1, ..., y^M), (w^1, ..., w^M)\bigr)$ \\
$(w, w_k)$ & $\real^{\Nw\horizon+\Nw}$ & Averages: $\bigl(1/M \, \Sigma_i w^i, 1/M \, \Sigma_i w^i_k\bigr)$ \\ \hline
$(x_k, u_k, \bm{w}_k)$ & $\real^{\Nx+\Nu+\Nw M}$ & State and input of upper-level system at time $k$ \\
$(x, u)$ & $\real^{\Nx(\horizon+1)+\Nu\horizon}$ & $\bigl((x_0, ..., x_\horizon), (u_0, ..., u_{\horizon-1})\bigr)$ \\ \hline
$\xi$ & $\real^{(\Nx+\Ny M)(\horizon+1)}$ & $(x, \bm{y})$, state of the full system \\
$\nu$ & $\real^{(\Nu+\Nw M)\horizon}$ & $(u, \bm{w})$, input of the full system \\
\hline
\end{tabularx}
\end{table}

The hierarchical MPC problem given by \eqref{eq:reduced-ith-lompc} and \eqref{eq:reduced-bimpc} is a Stackelberg game, where the BiMPC \eqref{eq:reduced-bimpc} is the leader, and the LoMPCs \eqref{eq:reduced-ith-lompc} are the followers.
As discussed in Sec.~\ref{subsubsec:incentive-Stackelberg-games}, we consider the incentive Stackelberg game variation, where the BiMPC provides an additional incentive to the LoMPCs.
Incentive variables impose penalties (or rewards) on the LoMPCs in addition to the cost function $g^i$ and thus grant the BiMPC influence over the LoMPC output.
Fig.~\ref{fig:hierarchical-mpc-formulation} depicts a flowchart of the incentive hierarchical MPC problem.
We make the following assumption about the incentive hierarchical MPC problem, formally defined in Sec.~\ref{subsec:linear-incentives-and-incentive-controllability}.

\begin{assumption} (Privacy of LoMPCs)
\label{assum:privacy-of-lompc}
    The cost functions $g^i$ are unknown to the BiMPC, apart from $\dom{g^i}$.
    The BiMPC can query the optimal solution $w^{i*}$ from the $i$-th LoMPC for any given $(\xi_0, u)$ and incentive.
\end{assumption}

In the following two sections, we first consider the case of a single LoMPC (i.e., when $M = 1$).
In Sec.~\ref{sec:linear-incentives-for-hierarchical-mpc}, we define a linear incentive structure and the notion of incentive controllability.
We prove that an optimal incentive for the incentive hierarchical MPC can be computed iteratively, even when the LoMPC cost function is unknown.
In Sec.~\ref{sec:linear-convex-incentives}, we extend the formulation in Sec.~\ref{sec:linear-incentives-for-hierarchical-mpc} to linear-convex incentives.
In Sec.~\ref{sec:multiple-lompcs}, we consider the case of multiple LoMPCs (i.e., when $M > 1$) with linear-convex incentives and propose a robust formulation for the incentive hierarchical MPC.


% % \todo{Add an intro statement.}
% We follow the notations in~\cite{mintz2018control}.
% Consider a dynamical system with state $\xi \in \real^\Nxi$ and inputs $\nu \in \real^\Nnu$, and the linear discrete-time dynamics given by $\xi_{k+1} = A\xi_k + B\nu_k$, where $A \in \real^\NA, B \in \real^\NB$.
% Let the states decompose as $\xi^\top = \bigl[ x^\top \ y^\top \bigr]$, and the inputs decompose as $\nu^\top = \bigl[ u^\top \ w^\top \bigr]$, where $x \in \real^\Nx$ and $u \in \real^\Nu$.
% The input matrix is decomposed as $B = \bigl[ B_1 \ B_2 \bigr]$, where $B_1 \in \real^\NBone$.

% We consider a hierarchical MPC problem with horizon $\horizon$, as follows:
% The lower-level MPC problem optimizes the input sequence $w_{0:\horizon-1} = (w_0, w_{1}, ..., w_{\horizon-1})$, given the input sequence $u_{0:\horizon-1} = (u_0, u_{1}, ..., u_{\horizon-1})$ and the initial state $\xi_0$.
% The symbols $\xi, \ \nu, \ u, \ w$ are overloaded to also represent the sequences $\xi_{0:\horizon}, \ \nu_{0:\horizon-1}, \ u_{0:\horizon-1}, \ w_{0:\horizon-1}$ respectively.
% The subscripts to represent time are used when appropriate.
% The lower-level MPC (LoMPC) problem is then given by,
% \begin{subequations}
% \label{eq:lompc}
% \begin{alignat}{6}
%     (\xi^*, w^*)(\xi_0, u) \in \ & \argmin_{\xi, w} \ g(\xi, w; \xi_0, u), \span\span\span\span\span\span \label{subeq:lompc-cost} \\
%     & \ \text{s.t} \quad
%     && \xi_{k+1}   &&= A\xi_k + B\nu_k, \; && k \in \langle \horizon \rangle, \label{subeq:lompc-dynamics} \\
%     &&& y_k \in \mathset{Y}, \ w_k \in \mathset{W}, \span\span \ && k \in \langle \horizon \rangle, \label{subeq:lompc-stage-constraints} \\
%     &&& y_N \in \mathset{Y}_\Omega, \span\span\span\span\span\span \label{subeq:lompc-terminal-constraints}
% \end{alignat}
% \end{subequations}
% where $\mathset{Y}, \ \mathset{Y}_\Omega\subset \real^\Ny$ and $\mathset{W} \subset \real^\Nw$ are closed convex sets, and $\langle \horizon \rangle = \{0, ..., \horizon-1\}$.
% The cost function $g$ is parametrized by the input sequence $u$ from the bilevel MPC and $\xi_0$. % and is a closed proper convex function in $(\xi, w)$ for each $(\xi_0, u)$, and $\constsc$-strongly convex in $w$ for each $(\xi, u)$.
% The constraints in \eqref{eq:lompc} can be incorporated into the cost using the indicator function to obtain a reduced LoMPC problem as,
% \begin{equation}
% \label{eq:reduced-lompc}
% w^*(\xi_0, u) = \argmin_{w} \ g(w; \xi_0, u),
% \end{equation}
% where the symbol $g$ is overloaded to represent the new cost function, where the constraints from \eqref{eq:lompc} are added to the cost.
% We will work with the simple formulation of the cost function, \eqref{eq:reduced-lompc}, for the theory and use the full formulation, \eqref{eq:lompc}, for the implementation.
% The assumptions on $g$ are as follows,
% \begin{assumption} (Properties of $g$)
% \label{assum:properties-of-g}
%     $g(\cdot \: ; \xi_0, u)$ is a closed proper function and $\constsc$-strongly convex, for all $(\xi_0, u)$.
%     Further, $g(\cdot \: ; \xi_0, u)$ is subdifferentiable on its domain for each $(\xi_0, u)$.
% \end{assumption}
% Since %$\xi$ is uniquely determined given $\xi_0, u$, and $w$, and 
% $g$ is strongly convex in $w$ and closed, a unique optimum for $w$ exists, given \eqref{eq:lompc} is feasible (see Sec.~\ref{subsubsec:strong-convexity-and-lipschitz-smoothness}).

% Given the initial state $\xi_0$, the bilevel MPC (BiMPC) problem optimizes the input sequence $\nu = (u, w)$, subject to the constraint that $w$ is obtained as the optimal solution of the LoMPC problem \eqref{eq:reduced-lompc}.
% The BiMPC problem is given by,
% \begin{subequations}
% \label{eq:bimpc}
% \begin{alignat}{6}
%     (\xi^*, \nu^*)(\xi_0) \in \ & \argmin_{\xi, \nu=(u,w)} f(\xi, \nu; \xi_0), \span\span\span\span\span\span \label{subeq:bimpc-cost} \\
%     & \ \text{s.t} \quad
%     && w = \argmin_w \ g(w; \xi_0, u), \span\span\span\span\span\span \label{subeq:bimpc-w-optimality} \\
%     &&& \xi_{k+1}   &&= A\xi_k + B\nu_k, \ && k \in \langle \horizon \rangle, \label{subeq:bimpc-dynamics} \\ 
%     &&& \xi_k \in \Xi, \ \nu_k \in \mathset{V}, \span\span \ && k \in \langle \horizon \rangle, \label{subeq:bimpc-stage-constraints} \\
%     &&& \xi_N \in \Xi_\Omega, \span\span\span\span\span\span \label{subeq:bimpc-terminal-constraints}
% \end{alignat}
% \end{subequations}
% where $\Xi, \ \Xi_\Omega \subset \real^\Nxi$ and $\mathset{V} \subset \real^\Nnu$ are closed sets, and $f$ is a continuous function.
% While no particular assumptions on \eqref{eq:bimpc}, other than the existence of a minimum, is needed, we consider $f$ to be a convex function and $\Xi, \ \Xi_\Omega, \ \mathset{V}$ to be convex sets for the numerical examples.
% Similar to the LoMPC problem, the constraints \eqref{subeq:bimpc-dynamics}-\eqref{subeq:bimpc-terminal-constraints} are added to the cost \eqref{subeq:bimpc-cost} % using the indicator function
% to obtain a reduced BiMPC problem as,
% \begin{subequations}
% \label{eq:reduced-bimpc}
% \begin{alignat}{6}
%     \nu^*(\xi_0) \in \ & \argmin_{\nu=(u, w)} f(\nu; \xi_0), \label{subeq:reduced-bimpc-cost} \\
%     & \ \text{s.t} \quad
%     w = \argmin_w \ g(w; \xi_0, u). \label{subeq:reduced-bimpc-w-optimality}
% \end{alignat}
% \end{subequations}
% The two optimization problems \eqref{eq:reduced-lompc} and \eqref{eq:reduced-bimpc} define the hierarchical MPC problem.
% At each time step, the current state is used as an input to \eqref{eq:reduced-bimpc}, and the first control $\nu^*_0$ from the optimal control sequence $\nu^*$ is applied to get the next state.

% Dividing the problem of control selection for the dynamical system into a multi-level problem such as \eqref{eq:reduced-bimpc} can result in a loss of controllability or stabilizability properties of the overall dynamical system if the cost function $g$ is selected inappropriately~\cite{mintz2018control}.
% % Intuitively, the lower-level MPC problem \eqref{eq:reduced-lompc} enforces a constraint on the control $\nu$, given by \eqref{subeq:reduced-bimpc-w-optimality}, which restricts it to a subset of the original control space.
% % If the cost function $g$ is selected inappropriately, the reduced control space can cause a loss of controllability or stabilizability.
% Further, solution techniques for hierarchical MPC problems, such as those given by \eqref{eq:reduced-lompc} and \eqref{eq:reduced-bimpc}, are often restricted to specific problem structures and require knowledge of the cost function $g$ of the LoMPC.

% % One possible solution to this problem is to parameterize the cost function $g$ and select the parameters online (i.e., dynamically) to ensure there is no loss of controllability or stabilizability.
% % Here, the parameters would be an additional input from the BiMPC \eqref{eq:reduced-bimpc} to the LoMPC \eqref{eq:reduced-lompc}.
% % Moreover, since the parameters allow the BiMPC to tune the cost function of the LoMPC, knowledge of the LoMPC cost function might not be necessary.
% % In this paper, we analyze the properties of such parameterizations of the LoMPC cost function.
% % The parameters the BiMPC provides to the LoMPC are called \emph{incentives}.

% The hierarchical MPC problem given by \eqref{eq:reduced-lompc} and \eqref{eq:reduced-bimpc} is also a Stackelberg game, where the BiMPC \eqref{eq:reduced-bimpc} is the leader, and the LoMPC \eqref{eq:reduced-lompc} is the follower.
% As discussed in Sec.~\ref{subsubsec:incentive-Stackelberg-games}, we consider the incentive Stackelberg game variation, where the BiMPC provides an additional incentive to the LoMPC.
% Incentive variables impose penalties (or rewards) on the LoMPC in addition to the cost function $g$ and thus grant the BiMPC influence over the LoMPC control.
% We make the following assumption about the incentive hierarchical MPC problem.

% \begin{assumption} (Privacy of LoMPC)
% \label{assum:privacy-of-lompc}
%     The cost function $g$ of the LoMPC is unknown to the BiMPC, apart from $\dom{g}$.
%     The BiMPC has access to the optimal solution $w^*$ from the LoMPC for any given $(\xi_0, u)$ and incentive.
% \end{assumption}

% In Sec.~\ref{sec:linear-incentives-for-hierarchical-mpc}, we define a linear incentive structure and the notion of incentive controllability.
% We prove that an optimal incentive for the incentive hierarchical MPC can be computed iteratively, even when the LoMPC cost function $g$ is unknown.
% In Sec.~\ref{sec:linear-convex-incentives}, we extend the formulation in Sec.~\ref{sec:linear-incentives-for-hierarchical-mpc} to general linear-convex incentives.
% In Sec.~\ref{sec:multiple-lompcs}, we consider the case where the hierarchical MPC problem consists of multiple LoMPCs and propose a robust formulation for the incentive hierarchical MPC.

% % As a first step to designing the parametric cost function, we discuss the following question:
% % for a fixed $u$, what is the set of optimal solutions $w^*$ obtained by all possible incentives?
% % If the set of such optimal solutions $w^*$ is large, then the BiMPC has more freedom to influence the optimal solution of the LoMPC by selecting an appropriate incentive.
% % In the following subsection, we provide a counterexample where the set of optimal solutions of a parametric cost function can have an arbitrarily small volume.
% % This implies that the parametric cost function must be chosen carefully to effectively allow the BiMPC to influence the LoMPC optimal solutions.

% % In Sec.~\ref{sec:linear-incentives-for-bilevel-optimization}, we add a linear cost term to the LoMPC cost function and show that such an incentive structure allows the BiMPC to arbitrarily choose the LoMPC optimal solutions without knowledge of the LoMPC cost function.
% % We extend the analysis for linear incentives to general convex-concave incentives in Sec.~\ref{sec:convex-concave-incentives}.
% % In Sec.~\ref{sec:multiple-lompcs}, we consider a case where the bilevel optimization consists of a single BiMPC instance providing a shared incentive to multiple LoMPCs.
