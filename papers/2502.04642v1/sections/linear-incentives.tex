\section{Linear Incentives for Hierarchical MPC}
\label{sec:linear-incentives-for-hierarchical-mpc}

In this section, we propose an incentive hierarchical MPC that adds a linear incentive term to the LoMPC cost function.
For the EV charging example, the total electricity price is a linear incentive for the EVs, as explained in the following subsection.
We consider the case of a single LoMPC (i.e., when $M = 1$) and denote the state, input, and cost function of the LoMPC by $y$, $w$, and $g$, respectively.
We define the notion of incentive controllability and show that the incentive hierarchical MPC satisfies this property.
We also provide an iterative method to compute an optimal incentive without knowing the LoMPC cost function $g$.


\subsection{Linear Incentives and Incentive Controllability}
\label{subsec:linear-incentives-and-incentive-controllability}

Let $g(w; \xi_0, u, \lambda)$ be the incentive LoMPC cost function given by,
\begin{equation}
\label{eq:incentivized-lompc-cost}
    g(w; \xi_0, u, \lambda) := g(w; \xi_0, u) + \langle \lambda, w\rangle,
\end{equation}
where $\lambda \in \real^{\Nw\horizon}$ is the incentive to the LoMPC \changes{and $\langle \lambda, w\rangle$ is the linear incentive term.}
For the EV charging example in Secs.~\ref{subsec:motivating-example} and \ref{sec:numerical-examples}, $\lambda$ is the unit price of electricity, and $\langle \lambda, w\rangle$ is the total price paid by the EV.
The LoMPC problem \eqref{eq:reduced-ith-lompc} with an incentive is as follows:
\begin{equation}
\label{eq:incentivized-lompc}
w^*(\xi_0, u, \lambda) := \textstyle{\argmin}_{w} \ (g(w; \xi_0, u) + \langle \lambda, w\rangle),
% \begin{split}
%     w^*(\xi_0, u, \lambda) & = \argmin_w \ g(w; \xi_0, u, \lambda), \\
%     & = \argmin_{w} \ g(w; \xi_0, u) + \langle \lambda, w\rangle,
% \end{split}
\end{equation}
where the BiMPC problem provides both $u$ and $\lambda$ as inputs to the LoMPC.
As discussed in Sec.~\ref{subsubsec:bilevel-mpc-problem}, incentives impose additional penalties or rewards on the LoMPC and can be used to influence $w^*$.
By Assumption~\ref{assum:properties-of-gi}, the cost function of the LoMPC problem \eqref{eq:incentivized-lompc} is a closed proper function, $\constsc$-strongly convex, and subdifferentiable for all values of $\lambda$.
So, there is a unique solution to \eqref{eq:incentivized-lompc} for all values of $\lambda$.
The BiMPC problem \eqref{eq:reduced-bimpc} with an incentive is as follows:
\begin{subequations}
\label{eq:incentivized-bimpc}
\begin{alignat}{6}
    (\nu^*, \lambda^*)(\xi_0) \in \ && \argmin_{\nu=(u,w), \lambda} & f(\nu; \xi_0), \label{subeq:incentivized-bimpc-cost} \\
    && \ \text{s.t} \quad &
    w = \textstyle{\argmin}_w \ g(w; \xi_0, u, \lambda). && \label{subeq:incentivized-bimpc-w-optimality}
\end{alignat}
\end{subequations}
The BiMPC dynamically chooses the incentive $\lambda$ at each time step.
The optimization problems \eqref{eq:incentivized-lompc} and \eqref{eq:incentivized-bimpc} define the incentive hierarchical MPC problem.
The incentive BiMPC problem \eqref{eq:incentivized-bimpc} is nontrivial to solve due to the optimality constraint \eqref{subeq:incentivized-bimpc-w-optimality}.
\changes{
% Our approach solves \eqref{eq:incentivized-bimpc} by first computing an optimal $\nu^*$ and then iteratively computing an optimal $\lambda^*$.
% In this subsection, we prove that this two-step approach is equivalent to solving \eqref{eq:incentivized-bimpc}.
% The following subsection then discusses an iterative method to compute optimal incentives $\lambda^*$.
In the rest of the section, we discuss a solution method for \eqref{eq:incentivized-bimpc}.
}
%
%
%%% Option 1: State definitions first and then the theorem.
Following \cite[Sec.~7.4]{basar1998dynamic} and \cite[Def.~1]{mukaidani2020incentive}, we first define a team-optimal solution for the incentive hierarchical MPC problem as follows.
\begin{definition} (Team-optimal solution)
\label{def:team-optimal-solution}
For a given $\xi_0$, a team-optimal solution of the incentive hierarchical MPC is an optimal solution $\nu^* = (u^*, w^*)$ of the following problem:
\begin{subequations}
\label{eq:equivalent-bimpc}
\begin{alignat}{6}
    \nu^*(\xi_0) \in \ && \argmin_{\nu=(u,w)} \ & f(\nu; \xi_0), \label{subeq:equivalent-bimpc-cost} \\
    && \ \text{s.t} \quad &
    w \in \dom g(\cdot \; ; \xi_0, u). \label{subeq:equivalent-bimpc-w-feasibility}
\end{alignat}
\end{subequations}
\end{definition}
Recall from Sec.~\ref{subsubsec:lower-level-mpc-problem} that the constraint \eqref{subeq:equivalent-bimpc-w-feasibility} is equivalent to enforcing the state and input constraints \eqref{subeq:ith-lompc-dynamics}-\eqref{subeq:ith-lompc-terminal-constraints}. % (for the single LoMPC problem considered).
We assume that a team-optimal solution exists for all initial states $\xi_0$.
Next, we define incentive controllability (this definition is similar to the one in \cite[Sec.~7.4]{basar1998dynamic} and \cite{ho1982control}, adapted to the problem considered in this paper).
\begin{definition} (Incentive controllability)
\label{def:incentive-controllability}
The incentive hierarchical MPC is called incentive controllable if, for all $\xi_0$ and corresponding team-optimal solutions $\nu^*=(u^*, w^*)$, there exists an incentive $\lambda^*$ such that $w^*$ is optimal for \eqref{eq:incentivized-lompc} with $(u, \lambda) = (u^*, \lambda^*)$, i.e., $w^* = w^*(\xi_0, u^*, \lambda^*)$.
\end{definition}
The following result states that the incentive hierarchical MPC is incentive controllable and shows that \eqref{eq:incentivized-bimpc} can be solved using a two-step approach.

\begin{theorem} (Linear incentive controllability)
\label{thm:bimpc-equivalence}
Under Assumption~\ref{assum:properties-of-gi}, the incentive hierarchical MPC problem, \eqref{eq:incentivized-lompc} and \eqref{eq:incentivized-bimpc}, is incentive controllable.
Further, the incentive BiMPC \eqref{eq:incentivized-bimpc} is equivalent to \eqref{eq:equivalent-bimpc}.
For any team-optimal solution $\nu^* = (u^*, w^*)$ and $-\lambda^* \in \partial_w g(w^*; \xi_0, u^*)$, $(\nu^*, \lambda^*)$ is an optimal solution of \eqref{eq:incentivized-bimpc}.
\end{theorem}

\begin{proof}
Under Assumption~\ref{assum:properties-of-gi}, $g(\cdot \,; \xi_0, u, \lambda)$ is a closed proper function, $\constsc$-strongly convex, and subdifferentiable.
Let $\nu^*=(u^*,w^*)$ be a team-optimal solution for some $\xi_0$.
Then, $w^*$ (uniquely) minimizes $g(w; \xi_0, u^*, \lambda)$ if and only if $-\lambda \in \partial_w g(w^*; \xi_0, u^*) \neq \emptyset$~\cite[Thm.~23.5]{rockafellar1997convex}.
This means that if $-\lambda^* \in \partial_w g(w^*; \xi_0, u^*)$ then $w^*$ is optimal for \eqref{eq:incentivized-lompc} with $(u, \lambda) = (u^*, \lambda^*)$.
Thus, the incentive hierarchical MPC is incentive controllable.

Next, we show the equivalence of \eqref{eq:incentivized-bimpc} and \eqref{eq:equivalent-bimpc}.
For any feasible solution $(\nu, \lambda)$ of \eqref{eq:incentivized-bimpc}, $\nu$ is also feasible for \eqref{eq:equivalent-bimpc} and has the same cost.
Similarly, if $\nu=(u, w)$ is feasible for \eqref{eq:equivalent-bimpc} and $-\lambda \in \partial_w g(w; \xi_0, u)$, then $(\nu, \lambda)$ is feasible for \eqref{eq:incentivized-bimpc} and has the same cost.
Thus, \eqref{eq:incentivized-bimpc} and \eqref{eq:equivalent-bimpc} are equivalent.
\end{proof}

Thm.~\ref{thm:bimpc-equivalence} shows that \eqref{eq:incentivized-bimpc} can be solved by first finding a team-optimal solution $\nu^*=(u^*, w^*)$ using \eqref{eq:equivalent-bimpc} and then choosing $\lambda^* \in -\partial_w g(w^*; \xi_0, u^*)$ as an optimal incentive for \eqref{eq:incentivized-bimpc}.
%
%
%%% Option 2: State theorem and then definitions.
% The following result shows that \eqref{eq:incentivized-bimpc} is equivalent to a simpler optimization problem.
%
% \begin{theorem}
% \label{thm:bimpc-equivalence}
% Under Assumption~\ref{assum:properties-of-gi}, the incentive BiMPC \eqref{eq:incentivized-bimpc} is equivalent to the following optimization problem:
% % \begin{subequations}
% % \label{eq:equivalent-bimpc}
% % \begin{alignat}{6}
% %     \nu^*(\xi_0) \in \ && \argmin_{\nu=(u,w)} \ & f(\nu; \xi_0), \label{subeq:equivalent-bimpc-cost} \\
% %     && \ \text{s.t} \quad &
% %     w \in \dom g(\cdot \; ; \xi_0, u). \label{subeq:equivalent-bimpc-w-feasibility}
% % \end{alignat}
% % \end{subequations}
% For any optimal solution $\nu^* = (u^*, w^*)$ of \eqref{eq:equivalent-bimpc} and $-\lambda^* \in \partial_w g(w^*; \xi_0, u^*)$, $(\nu^*, \lambda^*)$ is an optimal solution of \eqref{eq:incentivized-bimpc}.
% \end{theorem}
%
% \begin{proof}
% Under Assumption~\ref{assum:properties-of-gi}, $g(\cdot \,; \xi_0, u, \lambda)$ is a closed proper function, $\constsc$-strongly convex, and subdifferentiable.
% Then, $w^*$ uniquely minimizes $g(w; \xi_0, u^*, \lambda)$ if and only if~\cite[Thm.~23.5]{rockafellar1997convex}, $-\lambda \in \partial_w g(w^*; \xi_0, u^*) \neq \emptyset$.
% % \begin{equation*}
% % \begin{split}
% %     & 0 \in \partial_w g(w^*; \xi_0, u^*, \lambda) = \partial_w g(w^*; \xi_0, u^*) + \{\lambda\}, \\
% %     \Leftrightarrow \quad & -\lambda \in \partial_w g(w^*; \xi_0, u^*) \neq \emptyset,
% % \end{split}
% % \end{equation*}
% % where the addition between the two sets in the first line is the Minkowski sum (see Sec.~\ref{subsubsec:analyis}).
% %
% This means that for any $\bar{w} \in \dom g(\cdot \, ; \xi_0, u^*)$, if $-\lambda \in \partial_w g(\bar{w}; \xi_0, u^*)$ then $\bar{w}$ uniquely minimizes $g(w; \xi_0, u^*) + \langle \lambda, w\rangle$.
% So, for any feasible solution $\nu = (u, w)$ of \eqref{eq:equivalent-bimpc}, we can find a feasible solution $(\nu, \lambda)$ of \eqref{eq:incentivized-bimpc} with the same cost.
% Thus, \eqref{eq:incentivized-bimpc} and \eqref{eq:equivalent-bimpc} are equivalent.
% % \unskip
% \end{proof}
%
% \begin{algorithm}[h]
% \small
% \DontPrintSemicolon 
% \textbf{Input:} $\xi_0$\;
% \textbf{Output:} $\xi^*, \nu^*, \lambda^*$
%
% $(u^*, \tilde{w}) \gets $ optimal solution from \eqref{eq:equivalent-bimpc} with input $\xi_0$\;
% $\lambda^* \gets$ random vector from $-\partial_w g(\tilde{w}; \xi_0, u^*)$\;
% $w^* \gets$ optimal solution of \eqref{eq:incentivized-lompc} with inputs $(\xi_0, u^*, \lambda^*)$\;
% $\xi^* \gets$ solution from linear dynamics with inputs $(\xi_0, u^*, w^*)$\;
% \textbf{Return: } $\xi^*, (u^*, w^*), \lambda^*$
% \caption{Subgradient Method}
% \label{alg:subgradient-method}
% \end{algorithm}
%
% Thm.~\ref{thm:bimpc-equivalence} shows that \eqref{eq:equivalent-bimpc} and \eqref{eq:incentivized-bimpc} are equivalent.
% The constraint \eqref{subeq:equivalent-bimpc-w-feasibility} is equivalent to the state and input constraints \eqref{subeq:ith-lompc-dynamics}-\eqref{subeq:ith-lompc-terminal-constraints}.
% Thus, we can first solve the optimization problem \eqref{eq:equivalent-bimpc} to obtain $\nu^* = (u^*, w^*)$, and then use $\lambda^* \in -\partial_w g(w^*; \xi_0, u^*)$ as the incentive to the LoMPC, which results in $w^*$ being the unique optimal solution for \eqref{eq:incentivized-lompc}.
% Following \cite[Sec.~7.4]{basar1998dynamic}\hidetext{$\ $and \cite[Def.~1]{mukaidani2020incentive}}, we define a team-optimal solution as follows.
% \begin{definition} (Team-optimal solution)
% \label{def:team-optimal-solution}
% For a given $\xi_0$, an optimal solution $\nu^* = (u^*, w^*)$ of \eqref{eq:equivalent-bimpc} is called a team-optimal solution of the incentive hierarchical MPC.
% \end{definition}
%
% We assume that a team-optimal solution exists for all initial states $\xi_0$.
% Next, we define incentive controllability (this definition is similar to the one in \cite[Sec.~7.4]{basar1998dynamic} and \cite{ho1982control}, adapted to the problem considered in this paper).
% \begin{definition} (Incentive controllability)
% \label{def:incentive-controllability}
% The incentive hierarchical MPC is called incentive controllable if, for all $\xi_0$ and the corresponding team-optimal solution $\nu^*=(u^*, w^*)$, there exists an incentive $\lambda^*$ such that $w^*$ is optimal for \eqref{eq:incentivized-lompc}.
% \end{definition}
%
% The following assumption is made on the feasibility of \eqref{eq:equivalent-bimpc}.
% \begin{assumption}
% \label{assum:equivalent-bimpc}
% For all initial states $\xi_0$, the optimization problem \eqref{eq:equivalent-bimpc} is feasible, and a minimum exists.
% \end{assumption}
%
% Using the definitions above, we can now restate Thm.~\ref{thm:bimpc-equivalence}.
% \begin{corollary} (Linear incentive controllability)
% \label{cor:bimpc-equivalence}
% The incentive hierarchical MPC problem, \eqref{eq:incentivized-lompc} and \eqref{eq:incentivized-bimpc}, is incentive controllable.
% \end{corollary}
%
\hidetext{
\begin{remark} (Incentive controllability for general incentives)
\label{rem:incentive-controllability-for-general-incentives}
In the next section, we consider general incentives of the form $\langle \lambda, \phi(w)\rangle$, where $\lambda \succeq_{\mathset{K}^*} 0$ and $\phi$ is a $\mathset{K}$-convex function for a closed convex cone $\mathset{K}$ (see Sec.~\ref{subsubsec:convex-vector-functions}).
For such incentives, incentive controllability does not necessarily hold.
We provide a counterexample in Appendix~\ref{app:incentive-controllability-for-general-incentives-a-counterexample}.
% This motivates the use of linear incentives.
\end{remark}
}
%
However, computing such an optimal incentive $\lambda^*$ for a given $w^*$ requires the explicit knowledge of $g$.
In the following subsection, we show that optimal incentives can be computed iteratively without knowing $g$ or its subdifferential.


\subsection{Iterative Method for Optimal Incentives}
\label{subsec:iterative-method}

To simplify notation, we assume that the team-optimal solution $\nu^*$ is available after solving the optimization problem \eqref{eq:equivalent-bimpc} and we suppress the variables $(\xi_0, u^*)$ in the cost function $g$, and write it as $g(w; \lambda) = g(w) + \langle \lambda, w\rangle$.
Given $w^*$, the goal is to find $\lambda^*$ such that $w^* = \argmin_w g(w; \lambda^*)$.
Such an optimal incentive $\lambda^*$ exists from Thm.~\ref{thm:bimpc-equivalence}, which shows that $\partial g$ can be used to find $\lambda^*$.
However, $\partial g$ is unknown to the BiMPC (see Assumption~\ref{assum:privacy-of-lompc}).
Instead, we can query the optimal solution of the LoMPC \eqref{eq:incentivized-lompc} for any incentive $\lambda$, which is computed as $w^*(\lambda) = \argmin_w g(w; \lambda)$.
The following result shows that access to the LoMPC as a black-box solver is sufficient to iteratively compute incentives $\lambda^{(k)}$, such that $\argmin_w g(w; \lambda^{(k)}) \rightarrow w^*$ as $k \rightarrow \infty$.

\begin{theorem} (Iterative method for linear incentives)
\label{thm:iterative-method}
% Let Assumptions~\ref{assum:properties-of-gi} and \ref{assum:privacy-of-lompc} hold, and $w^* \in \dom{g}$.
Let Assumption~\ref{assum:properties-of-gi} hold, and $w^* \in \dom{g}$.
Let $\lambda^{(k)}$, $w^{(k)}$ be iterates satisfying
\begin{subequations}
\label{eq:iterative-method-const-step}
\begin{align}
    w^{(k)} & = w^*(\lambda^{(k)}) = \textstyle{\argmin}_w \ (g(w) + \langle \lambda^{(k)}, w\rangle), \label{subeq:iterative-method-const-step-gradient} \\
    \lambda^{(k+1)} & = \lambda^{(k)} + \constsc (w^{(k)} - w^*), \label{subeq:iterative-method-const-step-flow}
\end{align}
\end{subequations}
where $\constsc$ is the modulus of strong convexity of $g$.
Then, $w^{(k)} \rightarrow w^*$ %with a convergence rate of $O(1/\sqrt{\constsc k})$.
with the rate given by $\lVert w^{(k)} - w^*\rVert = O(1/\sqrt{\constsc k})$.
\end{theorem}

\begin{proof}
\changes{We define a dual function $\bar{g}^*$ corresponding to the closed proper and $\constsc$-strongly convex function $g$ as follows:
\begin{equation}
\label{eq:iterative-method-proof-dual-function}
    \bar{g}^*(\lambda) = \textstyle{\min}_w \ (g(w) + \langle \lambda, w\rangle).
\end{equation}
Note that $\bar{g}^*(\lambda) = -g^*(-\lambda)$, where $g^*$ is the conjugate of $g$ (see Sec.~\ref{subsubsec:conjugate-of-a-convex-function}).
So, by Prop.~\ref{prop:duality}, $\bar{g}^*$ is a $(1/\constsc)$-smooth concave function and $\dom(\bar{g}^*) = \real^{\Nw\horizon}$.
Now consider the function $\tilde{g}^*(\lambda) := \bar{g}^*(\lambda) - \langle w^*, \lambda \rangle$.
$\tilde{g}^*$ is concave and $(1/\constsc)$-smooth.
The gradient of $\tilde{g}^*$ is given by \eqref{eq:conv-analysis-conjugate-subgrad} as
\begin{equation*}
    \nabla \tilde{g}^*(\lambda) = \nabla \bar{g}^*(\lambda) - w^* = \textstyle{\argmin}_w \ (g(w) + \langle \lambda, w\rangle) - w^*.
\end{equation*}
So, if $\lambda$ is a critical point of $\tilde{g}^*$, then it must satisfy
\begin{equation*}
    \nabla \tilde{g}^*(\lambda) = 0 \Rightarrow w^* = \textstyle{\argmin}_w \ (g(w) + \langle \lambda, w\rangle).
\end{equation*}
In other words, $w^* = \argmin_w \ g(w; \lambda)$,
meaning $\lambda$ is an optimal incentive to achieve the solution $w^*$.
At least one critical point of $\tilde{g}^*$ exists because $g$ is assumed to be subdifferentiable (Assumption~\ref{assum:properties-of-gi}) and $w^* \in \dom{g}$ (it is obtained from \eqref{eq:equivalent-bimpc}).

Gradient ascent on $\tilde{g}^*$ with the constant step size of $\constsc$ converges because $\tilde{g}^*$ is $(1/\constsc)$-smooth~\cite[Sec.~1.2.3]{nesterov2018lectures}.
Gradient ascent for $\tilde{g}^*$ is of the form:
\begin{align*}
    \lambda^{(k+1)} = \lambda^{(k)} + m\nabla \tilde{g}^*(\lambda^{(k)}) = \lambda^{(k)} + m(w^*(\lambda^{(k)}) - w^*).
\end{align*}
Then, replacing $w^*(\lambda^{(k)})$ with $w^{(k)}$ in the above equation using \eqref{subeq:iterative-method-const-step-gradient}, we obtain \eqref{eq:iterative-method-const-step}.
Since $(w^{(k)}-w^*)$ is the gradient of $\tilde{g}^*$, it converges to zero with %a convergence rate of $O(1/\sqrt{\constsc k})$
the rate given by $\lVert w^{(k)} - w^*\rVert = O(1/\sqrt{\constsc k})$~\cite[Eq.~1.2.22]{nesterov2018lectures}.}
\unskip
%
% Consider the conjugate $g^*$ of $g$ (see Sec.~\ref{subsubsec:conjugate-of-a-convex-function}).
% Since $g$ is closed proper and $\constsc$-strongly convex,
% \begin{align*}
%     g^*(\mu) & = -\textstyle{\min}_w \ (g(w) - \langle \mu, w\rangle).
% \end{align*}
% By Prop.~\ref{prop:duality}, $g^*$ is an $(1/\constsc)$-smooth function and $\dom{g^*} = \real^{\Nw\horizon}$.
% Now consider the function $\tilde{g}^*(\mu) := g^*(\mu) - \langle w^*, \mu \rangle$.
% $\tilde{g}^*$ is a convex function and $(1/\constsc)$-smooth.
% The gradient of $\tilde{g}^*$ is given by \eqref{eq:conv-analysis-conjugate-subgrad} as
% \begin{equation*}
%     \nabla \tilde{g}^*(\mu) = \nabla g^*(\mu) - w^* = \textstyle{\argmin}_w \ (g(w) - \langle \mu, w\rangle) - w^*.
% \end{equation*}
% So, if $\mu$ is a critical point of $\tilde{g}^*$, then it must satisfy
% \begin{equation*}
%     \nabla \tilde{g}^*(\mu) = 0 \Rightarrow w^* = \textstyle{\argmin}_w \ (g(w) - \langle \mu, w\rangle).
% \end{equation*}
% \changes{In other words, $w^* = \argmin_w \ g(w; -\mu)$},
% meaning $-\mu$ is an optimal incentive to achieve the solution $w^*$.
% At least one critical point $\mu$ of $\tilde{g}^*$ exists because $g$ is assumed to be subdifferentiable (Assumption~\ref{assum:properties-of-gi}) and $w^* \in \dom{g}$ (it is obtained from \eqref{eq:equivalent-bimpc}).
%
% Gradient descent on $\tilde{g}^*$ with the constant step size of $\constsc$ converges because $\tilde{g}^*$ is $(1/\constsc)$-smooth~\cite[Sec.~1.2.3]{nesterov2018lectures}.
% Gradient descent for $\tilde{g}^*$ is of the form:
% \begin{align*}
%     \mu^{k+1} = \mu^k - m\nabla \tilde{g}^*(\mu^k) = \mu^k - m(w^*(-\mu^k) - w^*).
% \end{align*}
% Replacing $\mu^k$ with $-\lambda^k$ and using \eqref{subeq:iterative-method-const-step-gradient}, we obtain \eqref{eq:iterative-method-const-step}.
% Since $(w^k-w^*)$ is the gradient of $\tilde{g}^*$, it converges to zero with a convergence rate of $O(1/\sqrt{\constsc k})$~\cite[Eq.~1.2.22]{nesterov2018lectures}.
% \unskip
\end{proof}

% \hidetext{
% \begin{remark}
% A result similar to Thm.~\ref{thm:iterative-method} can be obtained using consensus ADMM~\cite{boyd2011distributed}.
% % The proof for a more general example is given in the following subsection.
% The statement and proof of this result are provided in Appendix~\ref{app:iterative-method-consensus-admm}, Lem.~\ref{lem:iterative-method-consensus-admm}.
% \end{remark}
% }

\hidetext{
Although Thm.~\ref{thm:iterative-method} shows that the $w$ iterates converge to the desired optimal solution $w^*$, the $\lambda$ iterates might not converge.
Next, we provide a sufficient condition for $g$ such that there exists an optimal incentive $\lambda^*$ for any $w^* \in \dom g$ that is uniformly bounded.
This allows us to place constraints on the $\lambda$ iterates in \eqref{subeq:iterative-method-const-step-flow} to prevent them from becoming unbounded.

\begin{assumption} (Lipschitz continuity of $g$)
\label{assum:lipschitz-continuity-g}
    $\dom{g}$ has a nonempty interior and $g$ is Lipschitz continuous on its domain with constant $\constlipschitz$, i.e.,
    \begin{equation*}
    \label{eq:assum-lipschitz-continuity-g}
        |g(w^1) - g(w^2)| \leq \constlipschitz \lVert w^1 - w^2\rVert, \quad \forall w^1, w^2, \in \dom{g}.
    \end{equation*}
\end{assumption}

Under Assumptions~\ref{assum:properties-of-gi} and \ref{assum:lipschitz-continuity-g}, we have the following result, which provides bounds on optimal incentives for any $w^* \in \dom{g}$.
As a side note, if $g$ is Lipschitz continuous and $\constsc$-strongly convex on its domain, then $\dom{g}$ is bounded.

\begin{lemma} (Bounded optimal incentive)
\label{lem:bounded-optimal-incentive}
Let Assumptions~\ref{assum:properties-of-gi} and \ref{assum:lipschitz-continuity-g} hold.
Then, for any $w^* \in \dom{g}$, $\exists \lambda^*$ such that $\lVert \lambda^* \rVert \leq \constlipschitz$ and $w^* = \argmin_w g(w; \lambda^*)$.
\end{lemma}

\begin{proof}
By Thm.~\ref{thm:bimpc-equivalence}, we have to show that for any $w^* \in \dom{g}$, $\exists \lambda^*$ such that $\lVert \lambda^* \rVert \leq \constlipschitz$ and $\lambda^* \in \partial g(w^*)$.
First, we show that for any $w^* \in \setint(\dom{g}) \neq \emptyset$, $\partial g(w^*) \subset \{\lambda: \lVert \lambda \rVert \leq \constlipschitz\}$.
Assume otherwise; then $\exists w^* \in \setint(\dom{g})$ and $\lambda' \in \partial g(w^*)$ such that $\lVert \lambda' \rVert > \constlipschitz$.
Then
%since $w^* \in \setint(\dom{g})$ and
using \eqref{eq:subdifferential-definition}, for small $\epsilon > 0$,
\begin{equation*}
    g(w^* + \epsilon \lambda'/\lVert \lambda'\rVert) \geq g(w^*) + \langle \lambda', \epsilon \lambda'/\lVert \lambda'\rVert \rangle = g(w^*) + \epsilon \lVert \lambda' \rVert.
\end{equation*}
By the Lipschitz continuity assumption \eqref{eq:assum-lipschitz-continuity-g}, we have
\begin{equation*}
    g(w^* + \epsilon \lambda'/\lVert \lambda'\rVert) - g(w^*) \leq \constlipschitz \epsilon < \epsilon \lVert \lambda' \rVert,
\end{equation*}
which is a contradiction.
So, $\forall w^* \in \setint(\dom{g})$, $\partial g(w^*) \subset \{\lambda: \lVert \lambda \rVert \leq \constlipschitz\}$.

Next, for $w^* \in \setbd(\dom{g})$, the boundary of $\dom{g}$, let $\{w^k\} \rightarrow w^*$ and $\lambda^k \in \partial g(w^k)$, where $w^k \in \setint(\dom{g}) \ \forall k$.
Since $\lVert \lambda^k \rVert \leq \constlipschitz \ \forall k$, by Bolzano-Weierstrass theorem~\cite[Thm.~2.42]{rudin1964principles}, there exists a limit point $\lambda^*$ of $\{\lambda^k\}$ with $\lVert \lambda^* \rVert \leq \constlipschitz$.
Finally, since the graph of $\partial g$ is a closed set~\cite[Thm.~24.4]{rockafellar1997convex}, $\lambda^* \in \partial g(w^*)$.
\end{proof}

% \begin{remark}
% Lem.~\ref{lem:bounded-optimal-incentive} allows us to consider only the incentives in $\{\lambda: \lVert \lambda \rVert \leq \constlipschitz\}$ for the iterative method, Alg.~\ref{alg:iterative-method}.
% This is also useful for other gradient-based algorithms, such as cutting plane schemes \cite{hiriart1993convex}.
% % Lem.~\ref{lem:bounded-optimal-incentive} is important because although Thm.~\ref{thm:iterative-method} guarantees convergence of iterates $w^k$ to $w^*$, there may be some iterations where the error $\lVert w^k - w^*\rVert$ does not decrease.
% % This happens when $w^k$ is a kink point of $g$, i.e. when $\partial_w g(w^k)$ is not a singleton set.
% % If the BiMPC instance \eqref{eq:equivalent-bimpc} has imperfect knowledge about $\dom{g}$, then it might happen that $w^* \notin \dom{g}$.
% % Then, Lem.~\ref{lem:bounded-optimal-incentive} allows us to prematurely terminate the iterative method when $\lVert \lambda^k \rVert > \constlipschitz$.
% \end{remark}
}


\begin{table*}[tbp]
\footnotesize
\setlength\extrarowheight{2pt}
\caption{Properties of the dual functions and main results}\label{tab:properties-of-the-dual-functions-and-main-results}
\begin{tabularx}{\textwidth}{|l||C|C|C|}
\hline
% Header
\multicolumn{1}{|c||}{\multirow{2}{*}{Property}} & \multicolumn{2}{c|}{Single LoMPC ($M = 1$)} & \multicolumn{1}{c|}{Multiple LoMPCs ($M > 1$)} \\
\cline{2-4}
& \multicolumn{1}{c|}{Linear incentives (Sec.~\ref{sec:linear-incentives-for-hierarchical-mpc})} & \multicolumn{1}{c|}{Linear-convex incentives (Sec.~\ref{sec:linear-convex-incentives})} & \multicolumn{1}{c|}{Linear-convex incentives (Sec.~\ref{sec:multiple-lompcs})} \\
\hline
% Gradient of the dual function
Gradient of the dual function $\bar{g}^*$ & Eq.~\eqref{eq:conv-analysis-conjugate-subgrad} & Lem.~\ref{lem:linear-convex-incentive-conjugate-grad} & $-$ \\
% Lipschitz smoothness
Lipschitz smoothness of $\bar{g}^*$ & Prop.~\ref{prop:duality} & Lem.~\ref{lem:linear-convex-lipschitz-smooth-dual} & $-$ \\
\hline
% Incentive controllability
Incentive controllability (Def.~\ref{def:incentive-controllability}) & Thm.~\ref{thm:bimpc-equivalence} & Assumption~\ref{assum:linear-convex-incentive-controllability} & Lem.~\ref{lem:bounded-incentive-controllability} \\
% Iterative method for optimal incentives
Iterative method for optimal incentives & Thm.~\ref{thm:iterative-method} & Thm.~\ref{thm:linear-convex-incentives-iterative-method} & Thm.~\ref{thm:linear-convex-incentives-iterative-method} \\
% BiMPC reformulation
Incentive BiMPC reformulation & Def.~\ref{def:team-optimal-solution} & Def.~\ref{def:team-optimal-solution} & Thm.~\ref{thm:robust-bimpc-formulation} \\
\hline
\end{tabularx}
\end{table*}


To summarize the results in this section, we have shown that adding a linear incentive to the LoMPC cost results in incentive controllability and allows the BiMPC to select an optimal incentive to achieve the team-optimal solution.
Moreover, optimal incentives can be calculated iteratively without knowing the LoMPC cost.
In the next section, we build upon the definitions and results in this section and consider a linear-convex incentive structure, which is a generalization of the linear incentive. % $\langle \lambda, w\rangle$.
% We show several results analogous to those for linear incentives.
% In particular, 
We show that an analog of the iterative method, Thm.~\ref{thm:iterative-method}, can be used for linear-convex incentives.
% In Sec.~\ref{sec:multiple-lompcs}, we use the framework developed in Sec.~\ref{sec:linear-convex-incentives} for the case where the hierarchical MPC problem consists of multiple LoMPCs with nonidentical cost functions.
