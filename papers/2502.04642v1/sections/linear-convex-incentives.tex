\section{Linear-Convex Incentives}
\label{sec:linear-convex-incentives}

In this section, we consider linear-convex incentives of the form $\langle \lambda, \phi(w)\rangle$, which is linear in $\lambda$ and convex in $w$.
We consider the case of a single LoMPC (i.e., when $M = 1$) and assume that $\phi$ is known to the BiMPC.
The results in this section follow the general outline for the linear incentive case in Sec.~\ref{sec:linear-incentives-for-hierarchical-mpc}.
First, we state assumptions on the function $\phi$ and then define a dual function $\bar{g}^*$ in $\lambda$, similar to the conjugate function $g^*$.
We then prove a duality result similar to Prop.~\ref{prop:duality}.
Finally, assuming incentive controllability, we derive an iterative method for linear-convex incentives.
% This allows us to use gradient-based optimization algorithms to solve the incentive hierarchical MPC problem.
% \todo{Finally, we show that our algorithm is similar to the dual ascent method with augmented Lagrangian for constrained optimization.}
The results in this section are a generalization of the results in Sec.~\ref{sec:linear-incentives-for-hierarchical-mpc}, see Tab.~\ref{tab:properties-of-the-dual-functions-and-main-results} for a comparison.

A linear-convex incentive $\langle \lambda, \phi(w) \rangle$ is a generalization of the linear incentive $\langle \lambda, w\rangle$.
For the EV charging example, linear-convex incentives can be used for nonlinear electricity pricing.
Linear-convex incentives can also be used to encode the fact that unit electricity prices are nonnegative, as we will show in Sec.~\ref{sec:numerical-examples}.
The LoMPC problem \eqref{eq:reduced-ith-lompc} with a linear-convex incentive structure is as follows:
\begin{equation}
\label{eq:linear-convex-incentivized-lompc}
w^*(\xi_0, u, \lambda) := \textstyle{\argmin}_{w} \ g(w; \xi_0, u) + \langle \lambda, \phi(w) \rangle.
\end{equation}

% We define concave-convex incentives as follows.
% \begin{definition}(Concave-Convex Incentives)
% \label{def:convex-concave-incentive}
%     A concave-convex incentive $\phi: \Lambda \times \real^{(\Nw)\horizon} \rightarrow \exreal$ is a continuous function, where $\Lambda$ is a closed convex set with nonempty interior.
%     For each $\lambda \in \Lambda$, $\phi(\lambda, \cdot)$ is a convex function with $\dom{\phi(\lambda, \cdot)} = \real^{(\Nw)\horizon}$.
%     For each $w \in \real^{(\Nw)\horizon}$, $-\phi(\cdot, w)$ is a closed proper convex function and subdifferentiable at each $\lambda \in \Lambda$.
% \end{definition}
Similar to Sec.~\ref{subsec:iterative-method}, we assume that the team-optimal solution $\nu^*$ is available after solving the optimization problem \eqref{eq:equivalent-bimpc} and drop the dependence of $g$ on $(\xi_0, u^*)$ for the rest of this section.
We define a linear-convex incentive as follows.
\begin{definition}(Linear-convex incentive)
\label{def:linear-convex-incentive}
    Let $\mathset{K} \subset \real^\Nlambda$ be a closed convex cone and $\phi: \real^{\Nw\horizon} \rightarrow \real^\Nlambda$ be a continuously differentiable $\mathset{K}$-convex function (see Sec.~\ref{subsubsec:convex-vector-functions}).
    Then the function $\bar{\phi}: \mathset{K}^* \times \real^{\Nw\horizon} \rightarrow \real$, with $\bar{\phi}(\lambda, w) := \langle \lambda, \phi(w) \rangle$ is called a linear-convex incentive.
\end{definition}

\begin{remark}
\label{rem:linear-convex-incentive-componentwise}
    If $\phi$ is a vector function that is convex in each of its components, then $\phi$ is $\mathset{K}$-convex for the cone of nonnegative vectors, $\mathset{K} = \real^{\Nlambda}_+$.
    $\mathset{K}$ is self-dual, i.e., $\mathset{K}^* = \mathset{K} = \real^{\Nlambda}_+$.
\end{remark}

Since $\phi$ is a $\mathset{K}$-convex function, $\langle \lambda, \phi(\cdot) \rangle$ is a convex function for any given $\lambda \succeq_{\mathset{K}^*} 0$ (see Sec.~\ref{subsubsec:convex-vector-functions}).
So, for each $\lambda \succeq_{\mathset{K}^*} 0$, $\langle \lambda, \phi(\cdot) \rangle$ is a closed proper convex function and differentiable at each $w \in \real^{\Nw\horizon}$.
For the EV charging example in Sec.~\ref{subsec:motivating-example}, we choose $\mathset{K}$ as the set of nonnegative vectors $\real^{\Nlambda}_+$.
This corresponds to the fact that the unit price of electricity cannot be negative.
This nonnegativity constraint motivates the linear-convex incentives used in this section.

% \todo{Remark on differentiability of $\phi$.}

Following the outline of Sec.~\ref{sec:linear-incentives-for-hierarchical-mpc}, we define a dual function $\bar{g}^*: \mathset{K}^* \rightarrow \exreal$, similar to \eqref{eq:conv-analysis-conjugate}, as follows:
\begin{equation}
\label{eq:linear-convex-dual}
    \bar{g}^*(\lambda) := \textstyle{\min}_w \ (g(w) + \langle \lambda, \phi(w) \rangle).
\end{equation}
Note that $\bar{g}^*$ is similar to the dual function in \eqref{eq:iterative-method-proof-dual-function}.
Tab.~\ref{tab:definitions-for-symbols-used-in-the-paper} tabulates the symbols in the paper, which are used consistently through Secs.~\ref{sec:linear-incentives-for-hierarchical-mpc}-\ref{sec:multiple-lompcs}, and can be used as a quick reference.
The minimum in $w$ exists for each $\lambda$ because $\langle \lambda, \phi(\cdot)\rangle + g$ is $\constsc$-strongly convex.
Now we prove a result on the differentiability of $\bar{g}^*$, similar to \eqref{eq:conv-analysis-conjugate-subgrad}.

% \begin{lemma}
% \label{lem:convex-concave-incentive-conjugate-subgrad}
% Under Assumptions \ref{assum:properties-of-g} and \ref{assum:convex-concave-incentive}, $\bar{g}^*$ is a proper convex function with $\dom{\bar{g}^*} = \Lambda$.
% Also, for each $\lambda \in \setint(\Lambda)$,
% \begin{equation}
% \label{eq:convex-concave-incentive-conjugate-subgrad}
%     \partial \bar{g}^*(\lambda) = \partial_\lambda (-\phi)(\lambda, w^*(\lambda)), 
% \end{equation}
% where $w^*(\lambda)$ is the unique maximum of \eqref{eq:convex-concave-conjugate},
% \begin{equation*}
%     w^*(\lambda) = \argmax_w \{-\phi(\lambda, w) - g(w)\}.
% \end{equation*}
% \end{lemma}

% \begin{proof}
% Since $-\phi(\cdot, w)$ is a convex function for each $w$ and $\bar{g}^*$ is the pointwise supremum of convex functions, $\bar{g}^*$ is convex~\cite[Sec.~3.2.3]{boyd2004convex}.
% Moreover, since $g + \phi(\lambda, \cdot)$ is $\constsc$-strongly convex (by Assumption~\ref{assum:properties-of-g}) with a closed convex domain for each $\lambda$, \eqref{eq:convex-concave-conjugate} has a unique maximum and $\bar{g}^*(\lambda) < \infty$ for each $\lambda$.
% So, $\dom{\bar{g}^*} = \Lambda$.

% Since $\bar{g}^*$ is a proper convex function, it is subdifferentiable on the interior of its domain, $\setint(\Lambda)$.
% That the subdifferential of $\bar{g}^*$ is given by \eqref{eq:convex-concave-incentive-conjugate-subgrad} follows directly from \cite[Prop.~A.22]{bertsekas1971control} and the fact that \eqref{eq:conv-analysis-conjugate} has a unique maximum.
% \end{proof}

\begin{lemma} (Convexity and gradient of $-\bar{g}^*$)
\label{lem:linear-convex-incentive-conjugate-grad}
Under Assumption~\ref{assum:properties-of-gi}, Def.~\ref{def:linear-convex-incentive}, and \eqref{eq:linear-convex-dual}, $-\bar{g}^*$ is a proper convex function with $\dom{\bar{g}^*} = \mathset{K}^*$.
$-\bar{g}^*$ is differentiable for each $\lambda \in \mathset{K}^*$, with
\begin{equation}
\label{eq:linear-convex-incentive-conjugate-grad}
    \nabla (-\bar{g}^*)(\lambda) = -\phi(w^*(\lambda)), 
\end{equation}
where $w^*(\lambda)$ is the unique minimum of \eqref{eq:linear-convex-dual}, i.e.,
\begin{equation}
\label{eq:linear-convex-incentive-conjugate-grad-w}
    w^*(\lambda) = \textstyle{\argmin}_w \ (g(w) + \langle \lambda, \phi(w)\rangle).
\end{equation}
Further, $w^*(\cdot)$ is a continuous function on $\mathset{K}^*$.
\end{lemma}

\begin{proof}
The proof is provided in Appendix~\ref{subapp:proof-linear-convex-incentive-conjugate-grad}.
\end{proof}

Lem.~\ref{lem:linear-convex-incentive-conjugate-grad} shows that $-\bar{g}^*$ is a continuously differentiable convex function, with gradient given by $\nabla \bar{g}^*(\lambda) = \phi(w^*(\lambda))$.
% Since, for a given incentive $\lambda$, the LoMPC \eqref{eq:linear-convex-incentivized-lompc} computes the optimal solution $w^*(\lambda)$ of \eqref{eq:linear-convex-dual}, Lem.~\ref{lem:linear-convex-incentive-conjugate-grad} allows us to compute the gradient of $\bar{g}^*$ at $\lambda$ without knowing $g$ (see Assumption~\ref{assum:privacy-of-lompc}).
Similar to Prop.~\ref{prop:duality}, the following result shows that $-\bar{g}^*$ is a Lipschitz smooth function.
We use this result in Thm.~\ref{thm:linear-convex-incentives-iterative-method} to show the convergence of an iterative method for calculating optimal incentives, similar to Thm.~\ref{thm:iterative-method} (see Tab.~\ref{tab:properties-of-the-dual-functions-and-main-results}).

\begin{lemma} (Lipschitz smoothness of $-\bar{g}^*$)
\label{lem:linear-convex-lipschitz-smooth-dual}
    Under Assumption~\ref{assum:properties-of-gi}, Def.~\ref{def:linear-convex-incentive}, and \eqref{eq:linear-convex-dual}, $-\bar{g}^*$ satisfies the following inequality for any $\lambda, \bar{\lambda} \in \mathset{K}^*$:
    \begin{equation}
    \label{eq:linear-convex-lipschitz-smooth}
    \begin{split}
        \hspace{-5pt} -\bar{g}^*(\lambda) \leq -\bar{g}^*(\lambda; \bar{\lambda}) := & -\bar{g}^*(\bar{\lambda}) + \langle \lambda - \bar{\lambda}, -\phi(\bar{w})\rangle \\
        & + 1/(2\constsc) \lVert D \phi(\bar{w})^\top (\lambda - \bar{\lambda}) \rVert^2,
    \end{split}
    \end{equation}
    where $\bar{w} = w^*(\bar{\lambda}) = \argmin_w \{g(w) + \langle \bar{\lambda}, \phi(w)\rangle\}$, $\constsc$ is the modulus of strong convexity of $g$, \changes{and $D\phi$ is the Jacobian of the vector function $\phi$}.
   In particular, when restricted to any compact domain, $-\bar{g}^*$ is Lipschitz smooth.
\end{lemma}

\begin{proof}
The proof is provided in Appendix~\ref{subapp:proof-linear-convex-lipschitz-smooth-dual}.
\end{proof}

\begin{table}[tbp]
\footnotesize
\setlength\extrarowheight{2pt}
\caption{Definitions for symbols used in the paper}\label{tab:definitions-for-symbols-used-in-the-paper}
\begin{tabularx}{\columnwidth}{|c|ll|L|}
\hline
% Header
Symbol & \multicolumn{2}{|l|}{Definition} & Meaning \\
\hline
% Cost function
$g^i(w^i; \xi_0, u)$ & Sec.~\ref{sec:linear-incentives-for-hierarchical-mpc}: & \eqref{eq:reduced-ith-lompc} & LoMPC cost (also $g^i(w^i)$) \\
\hline
% Incentive cost function and optimal solution
$g^i(w^i; \xi_0, u, \lambda)$ & Sec.~\ref{sec:linear-incentives-for-hierarchical-mpc}: & \eqref{eq:incentivized-lompc-cost}, \eqref{eq:incentivized-lompc} & Incentive LoMPC cost and \\[-2pt] 
$w^{i*}(\xi_0, u, \lambda)$ & Sec.~\ref{sec:linear-convex-incentives}: & \eqref{eq:linear-convex-incentivized-lompc} & optimal solution (also \\[-1.5pt]
& Sec.~\ref{sec:multiple-lompcs}: & \eqref{eq:parametric-form-gi} & $g^i(w^i; \lambda)$ and $w^{i*}(\lambda)$) \\
\hline
% Robust BiMPC solution
$(u^*, \hat{w}^*)(\xi_0)$ & Sec.~\ref{sec:multiple-lompcs}: & \eqref{eq:robust-bimpc} & Team-optimal solution \\[-2pt]
& & & for robust BiMPC \\
\hline
% Concave dual functions
$\bar{g}^*$, $\tilde{g}^*$ & Sec.~\ref{sec:linear-incentives-for-hierarchical-mpc}: & \eqref{eq:iterative-method-proof-dual-function} & Concave dual functions \\[-2pt]
& Sec.~\ref{sec:linear-convex-incentives}: & \eqref{eq:linear-convex-dual}, \eqref{eq:linear-convex-dual-transformed} & (related to the conjugate \\[-2pt]
& Sec.~\ref{sec:multiple-lompcs}: & \eqref{eq:bounded-incentive-controllability-conjugate-g} & function $g^*$, \eqref{eq:conv-analysis-conjugate}) \\
\hline
% Concave quadratic under-approximations
$\bar{g}^*(\cdot \,; \bar{\lambda})$ & Sec.~\ref{sec:linear-convex-incentives}: & \eqref{eq:linear-convex-lipschitz-smooth}, \eqref{eq:linear-convex-dual-transformed-lower-bound} & Concave quadratic \\[-1.5pt]
$(\tilde{g}^*(\cdot \,; \bar{\lambda}))$ & & & under-approximation of $\bar{g}^*$ ($\tilde{g}^*$) at $\bar{\lambda}$ \\
\hline
\end{tabularx}
\end{table}

Lem.~\ref{lem:linear-convex-lipschitz-smooth-dual} shows that the dual function $-\bar{g}^*$ can be majorized, i.e., bounded from above, by a quadratic function $-\bar{g}^*(\cdot \: ; \bar{\lambda})$ anchored at $\bar{\lambda}$.
Lems.~\ref{lem:linear-convex-incentive-conjugate-grad} and \ref{lem:linear-convex-lipschitz-smooth-dual} discuss the properties of the dual function $\bar{g}^*$.
In the rest of the section, we consider the incentive controllability property of the incentive hierarchical MPC and show that an iterative method can be used to compute an optimal incentive.
%
\hidetext{As noted in Rem.~\ref{rem:incentive-controllability-for-general-incentives}, incentive controllability does not necessarily hold for linear-convex incentives. (remove text ahead)}
Unlike for linear incentives, incentive controllability does not necessarily hold for linear-convex incentives.
From Def.~\ref{def:incentive-controllability}, incentive controllability holds if for all $w^* \in \dom{g}$, $\exists \lambda^* \in \mathset{K}^*$ such that $w^* = \argmin_w \{g(w) + \langle \lambda^*, \phi(w)\rangle\}$.
Using the optimality condition for $g(w) + \langle \lambda^*, \phi(w)\rangle$~\cite[Thm.~23.8]{rockafellar1997convex}, $w^*$ must satisfy
\begin{equation}
\label{eq:linear-convex-incentive-controllability-condition}
    -D \phi(w^*)^\top \lambda^* \in \partial g(w^*),
\end{equation}
for some $\lambda^* \in \mathset{K}^*$.
Using the above condition, we make the following assumption on the incentive structure.

\begin{assumption} (Linear-convex incentive controllability)
\label{assum:linear-convex-incentive-controllability}
$\phi$ satisfies the following properties:
\begin{enumerate}[leftmargin=*]
    %\item $\phi$ is injective, i.e., $\phi(w_1) = \phi(w_2) \Rightarrow w_1 = w_2$.
    % \item $\phi(w_1) \preceq_{\mathset{K}} \phi(w_2) \Rightarrow \phi(w_1) = \phi(w_2), \ \forall w_1, w_2$.
    \item $\phi(w^1) \preceq_{\mathset{K}} \phi(w^2) \Rightarrow w^1 = w^2, \ \forall w^1, w^2$.

    \item $\forall w^* \in \dom{g}$, $\exists \lambda^* \in \mathset{K}^*$, such that \eqref{eq:linear-convex-incentive-controllability-condition} holds.
\end{enumerate}
\end{assumption}

Following the discussion above, incentive controllability holds for linear-convex incentives when Assumption~\ref{assum:linear-convex-incentive-controllability} holds.
In the following remark, we identify a family of functions $\phi$ that satisfy Assumption~\ref{assum:linear-convex-incentive-controllability}.

\begin{remark}
\label{rem:linear-convex-incentive-controllability}
One class of linear-convex incentives that always satisfies Assumption~\ref{assum:linear-convex-incentive-controllability} is of the form $\langle \lambda_l, w\rangle + \langle \lambda_c, \phi_c(w)\rangle$, where $\phi_c$ is continuously differentiable and $\mathset{K}_c$-convex for some closed convex cone $\mathset{K}_c$, $\lambda_l \in \real^{\Nw\horizon}$, $\lambda_c \in (\mathset{K}_c)^*$, $\lambda = (\lambda_l, \lambda_c)$, and $\phi(w) = (w, \phi_c(w))$.
Here, $\mathset{K} = \{\mathbb{0}_{\Nw\horizon}\} \times \mathset{K}_c$, and $\mathset{K}^* = \real^{\Nw\horizon} \times (\mathset{K}_c)^*$.
Consequently, adding a linear-convex incentive to a linear incentive retains the incentive controllability property, Def.~\ref{def:incentive-controllability}.
\end{remark}

We make the following observation about the dual function $-\bar{g}^*$.
Given $w^* \in \dom{g}$, we define the function $\tilde{g}^*$ as follows:
\begin{equation}
\label{eq:linear-convex-dual-transformed}
    \tilde{g}^*(\lambda) := \bar{g}^*(\lambda) - \langle\lambda, \phi(w^*) \rangle.
\end{equation}
If $\lambda$ is a critical point of $\tilde{g}^*$, then by Lem.~\ref{lem:linear-convex-incentive-conjugate-grad},
\begin{equation*}
    \nabla \tilde{g}^*(\lambda) = 0 \ \Rightarrow \ \phi(w^*(\lambda)) - \phi(w^*) = 0.
\end{equation*}
By Assumption~\ref{assum:linear-convex-incentive-controllability}, this implies that $w^*(\lambda) = w^*$, i.e., $\lambda$ is an optimal incentive for $w^*$.
Thus, we claim that minimizing $-\tilde{g}^*$ results in an optimal incentive.
By Lem.~\ref{lem:linear-convex-lipschitz-smooth-dual}, for any $\lambda, \bar{\lambda} \in \mathset{K}^*$,
\begin{equation}
\label{eq:linear-convex-dual-transformed-lower-bound}
    -\tilde{g}^*(\lambda) \leq -\tilde{g}^*(\lambda \, ; \bar{\lambda}) := -\bar{g}^*(\lambda \, ; \bar{\lambda}) + \langle \lambda, \phi(w^*) \rangle,
\end{equation}
where $\bar{g}^*(\cdot \, ; \bar{\lambda})$ is defined in \eqref{eq:linear-convex-lipschitz-smooth} (see Tab.~\ref{tab:definitions-for-symbols-used-in-the-paper} for a summary).
So, $-\tilde{g}^*$ is majorized by the quadratic function $-\tilde{g}^*(\cdot \, ;\bar{\lambda})$.
Thus, to minimize $-\tilde{g}^*$, we can follow an iterative method where we minimize the majorization $-\tilde{g}^*(\cdot \,; \lambda^{(k)})$ at the iterate $\lambda^{(k)}$ to obtain the next iterate $\lambda^{(k+1)}$.
The following theorem, one of this paper's main results, formalizes the above discussion and guarantees the convergence of the majorization-minimization procedure.

\begin{theorem} (Iterative method for linear-convex incentives)
\label{thm:linear-convex-incentives-iterative-method}
Let Assumptions~\ref{assum:properties-of-gi} and \ref{assum:linear-convex-incentive-controllability} hold, and $w^* \in \dom{g}$.
Let $\lambda^{(k)}$ and $w^{(k)}$ be iterates satisfying
\begin{subequations}
\label{eq:linear-convex-incentives-iterative-method-const-step}
%%
% \begin{align}
%     w^{k} & = w^*(\lambda^k) = \argmin_w (g(w) + \langle \lambda^k, \phi(w)\rangle), \label{subeq:linear-convex-incentives-iterative-method-const-step-gradient} \\
%     \lambda^{k+1} & \in \begin{aligned}[t]
%     \argmin_{\lambda \in \mathset{K}^*} \bigl( & 1/(2\constsc) \lVert D\phi(w^k)^\top (\lambda - \lambda^k) \rVert^2 \\
%     & + \epsilon \lVert \lambda - \lambda^k \rVert^2 - \langle \lambda, \phi(w^k) - \phi(w^*) \rangle \bigr),
%     \end{aligned} \label{subeq:linear-convex-incentives-iterative-method-const-step-flow}
% \end{align}
%%
% \begin{alignat}{4}
%     w^{(k)} & = w^*(\lambda^{(k)}) = \textstyle{\argmin}_w \ (g(w) + \langle \lambda^{(k)}, \phi(w)\rangle), \span\span \label{subeq:linear-convex-incentives-iterative-method-const-step-gradient} \\
%     % \lambda^{k+1} & = \argmin_{\lambda \in \mathset{K}^*} \ \bigl( \ && 1/(2\constsc) \lVert D\phi(w^k)^\top (\lambda - \lambda^k) \rVert^2 \label{subeq:linear-convex-incentives-iterative-method-const-step-flow} \\
%     % &&& + \epsilon_k \lVert \lambda - \lambda^k \rVert^2 - \langle \lambda, \phi(w^k) - \phi(w^*) \rangle \ \bigr), \nonumber
%     \lambda^{(k+1)} & = \textstyle{\argmin}_{\lambda \in \mathset{K}^*} \ \bigl( -\tilde{g}^*(\lambda; \lambda^{(k)}) + \epsilon_k \lVert \lambda - \lambda^{(k)} \rVert^2 \bigr), \label{subeq:linear-convex-incentives-iterative-method-const-step-flow}
% \end{alignat}
%%
\begin{flalign}
    & w^{(k)} = w^*(\lambda^{(k)}) = \textstyle{\argmin}_w \, (g(w) + \langle \lambda^{(k)}, \phi(w)\rangle), \span\span \hspace{-5pt} \label{subeq:linear-convex-incentives-iterative-method-const-step-gradient} \\
    & \lambda^{(k+1)} = \textstyle{\argmin}_{\lambda \in \mathset{K}^*} \, \bigl(\epsilon^{(k)} \lVert \lambda - \lambda^{(k)} \rVert^2 -\tilde{g}^*(\lambda; \lambda^{(k)}) \bigr), \hspace{-15pt} && \label{subeq:linear-convex-incentives-iterative-method-const-step-flow}
\end{flalign}
\end{subequations}
where $\tilde{g}^*(\lambda; \lambda^{(k)}) := \bar{g}^*(\lambda; \lambda^{(k)}) - \langle \lambda, \phi(w^*)\rangle$, $\bar{g}^*(\cdot \, ; \lambda^{(k)})$ is the quadratic function defined in \eqref{eq:linear-convex-lipschitz-smooth}, and $\epsilon^{(k)} > 0$ is a bounded regularization weight.
If $\{\lambda^{(k)} \}$ is a bounded sequence, then $\lim_{k \rightarrow \infty} w^{(k)} = w^*$.

At each iteration, there is a guaranteed dual cost decrease:
\begin{align}
\label{eq:linear-convex-incentives-iterative-method-dual-cost-decrease}
     \tilde{g}^*(\lambda^{(k)}) - \tilde{g}^*(\lambda^{(k+1)}) \leq & -\tilde{g}^*(\lambda^{(k+1)}; \lambda^{(k)}) + \tilde{g}^*(\lambda^{(k)}; \lambda^{(k)}) \nonumber \\
    & + \epsilon^{(k)} \lVert \lambda^{(k+1)} - \lambda^{(k)}\rVert^2,
\end{align}
where $\tilde{g}^*(\lambda) := \bar{g}^*(\lambda) - \langle \lambda, \phi(w^*)\rangle$.

For any optimal incentive $\lambda^*$, and $\bar{\lambda} \in \mathset{K}^*$ such that $D\phi(w^*)^\top (\bar{\lambda} - \lambda^*) = 0$, $\bar{\lambda}$ is also an optimal incentive.
\end{theorem}

\begin{proof}
The proof is provided in Appendix~\ref{subapp:proof-linear-convex-incentives-iterative-method}.
\end{proof}

Similar to the iterative method for linear incentives, Thm.~\ref{thm:iterative-method}, the sequence $\{\lambda^{(k)}\}$ obtained from \eqref{eq:linear-convex-incentives-iterative-method-const-step} need not converge.
However, given an optimal incentive $\lambda^*$ (obtained as a limit point of $\{\lambda^{(k)}\}$), Thm.~\ref{thm:linear-convex-incentives-iterative-method} provides us a method to find other optimal incentives.
If $\bar{\lambda} \in \mathset{K}^*$ is such that $D\phi(w^*)^\top (\bar{\lambda} - \lambda^*) = 0$, then $\bar{\lambda}$ is also an optimal incentive.
As noted in the following remark, we can use this property to find an optimal incentive that minimizes some cost function.

\begin{remark} (Optimal incentive regularization)
\label{rem:optimal-incentive-regularization}
Let $\lambda^*$ be any optimal incentive obtained using ~\eqref{eq:linear-convex-incentives-iterative-method-const-step} and $c \in \real^{\Nlambda}$.
Then any solution $\bar{\lambda}$ to the conic program
\begin{equation}
\label{eq:optimal-incentive-regularization}
\begin{split}
    \min_{\lambda \in \mathset{K}^*} \ & \langle \lambda, c \rangle, \\
    \text{s.t} \quad & D\phi(w^*(\lambda^*))^\top (\lambda - \lambda^*) = 0,
\end{split}
\end{equation}
is also an optimal incentive.
Eq.~\eqref{eq:optimal-incentive-regularization} can be used to regularize along the set of optimal incentives.
For instance, in the EV charging example considered in Sec.~\ref{subsec:motivating-example}, the incentive $\lambda$ denotes the unit price of electricity, and we choose $c = \phi(w^*(\lambda^*))$ to minimize the total price paid by the EVs.
\end{remark}

\begin{remark}
Following Rem.~\ref{rem:linear-convex-incentive-controllability}, if we choose $\phi(w) = w$ and $\mathset{K} = \{\mathbb{0}_{\Nw\horizon}\}$, the linear-convex incentive $\langle \lambda, \phi(w)\rangle$ is the same as the linear incentive $\langle \lambda, w\rangle$.
In this case, Lem.~\ref{lem:linear-convex-incentive-conjugate-grad}, Lem.~\ref{lem:linear-convex-lipschitz-smooth-dual}, and Thm.~\ref{thm:linear-convex-incentives-iterative-method} are equivalent to \eqref{eq:conv-analysis-conjugate-subgrad}, Prop.~\ref{prop:duality}, and Thm.~\ref{thm:iterative-method} respectively (see Tab.~\ref{tab:properties-of-the-dual-functions-and-main-results} for a comparison).
\end{remark}

\hidetext{
TODO: subsection on equivalence between dual ascent and our algorithm, from the perspective of incentive compatibility
}

To summarize the results in this section, we first define a linear-convex incentive structure in Def.~\ref{def:linear-convex-incentive} and a corresponding dual function in \eqref{eq:linear-convex-dual}.
We prove the convexity properties of the dual function in Lems.~\ref{lem:linear-convex-incentive-conjugate-grad} and \ref{lem:linear-convex-lipschitz-smooth-dual}.
Next, we show that the hierarchical MPC problem, with the incentive LoMPC \eqref{eq:linear-convex-incentivized-lompc}, is incentive controllable when Assumption~\ref{assum:linear-convex-incentive-controllability} holds.
Finally, Thm.~\ref{thm:linear-convex-incentives-iterative-method} shows that for any team-optimal solution $\nu^* = (u^*, w^*)$, an optimal incentive $\lambda^*$ can be found iteratively, without the knowledge of the LoMPC cost function $g$.

In the following section, we consider the hierarchical MPC problem for the case of multiple LoMPCs (i.e., when $M > 1$), as defined in Sec.~\ref{subsec:hierarchical-formulation}.
We use the tools developed in Secs.~\ref{sec:linear-incentives-for-hierarchical-mpc} and \ref{sec:linear-convex-incentives} to propose an algorithm that solves a particular case of the incentive hierarchical MPC problem.

% \todo{add result about suboptimality}
