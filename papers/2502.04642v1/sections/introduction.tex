\section{Introduction}
\label{sec:introduction}

% Literature review: dual methods in optimization (check other hierarchical data-driven methods), vector optimization, and utopia points.

Complex control subsystems that interact with each other can be broadly classified into two categories, depending on the type of information flow: distributed and hierarchical.
% Controllers with a hierarchical structure have been studied in the context of nonlinear control using Lyapunov functions~\cite{nonlinear2002khalil, kokotovic1999singular}, contraction analysis-based methods for cascading systems (see~\cite{dey2023incremental}, for example).
In distributed systems, information is passed between local regulators, while in hierarchical systems, a high-level coordinating algorithm passes information to local regulators; see ~\cite{scattolini2009architectures} for classifications.
% The control subsystems in the distributed setting can be non-cooperative, with each subsystem optimizing for a different cost function, or cooperative, where the subsystems cooperate to minimize a global cost function.
% Likewise, in the hierarchical setting, the coordinating algorithm and the local regulators could be designed to achieve a high-level goal, or the coordinator could be developed independently of the local regulators; see ~\cite{scattolini2009architectures} for classifications.
Stackelberg games are leader-follower games where the leader announces its strategy to the followers, with the goal of minimizing the leader cost function~\cite{simaan1973stackelberg}.
We consider a hierarchical MPC problem where each lower-level system solves a convex MPC problem (LoMPC) to determine its control input.
The upper-level system solves a bilevel MPC problem (BiMPC), which selects the upper-level system inputs subject to the constraint that the lower-level system inputs are optimal for the LoMPC.
Such bilevel optimization problems can be viewed as Stackelberg games and are challenging due to the implicit optimality constraints.
In this paper, we analyze an incentive Stackelberg game variation, where the BiMPC provides additional incentives to the LoMPC that allow the BiMPC to steer the LoMPC inputs.


\begin{figure}%[!htp]
    \centering
    \includegraphics[width=0.99\columnwidth]{figures/hierarchical-mpc-formulation.png}
    \caption{A flowchart depicting the incentive hierarchical MPC formulation.
    Given the current state $\xi(t) = (x(t), \bm{y}(t))$, the bilevel controller (the BiMPC) provides upper-level input $u$ and an incentive to the lower-level systems, which compute the lower-level input $\bm{w}$ using the LoMPCs.
    We assume that the BiMPC can query the lower-level system inputs for different incentives. % multiple times every time interval.
    The controller output $(u, \bm{w})$ is then used to update the upper-level system state.
    The BiMPC and the LoMPCs together comprise the hierarchical MPC problem.
    In the EV charging example considered in Secs.~\ref{subsec:motivating-example} and \ref{sec:numerical-examples}, the BiMPC is solved by an ISO to determine the amount of electricity generation, while the LoMPCs are solved by EVs to determine charging rates.
    The incentive provided by the ISO is the unit price of electricity.
    }
    \label{fig:hierarchical-mpc-formulation}
\end{figure}


\subsection{Related Work}
\label{subsec:related-work}

\subsubsection{Distributed MPC}
\label{subsubsec:distributed-mpc}

In distributed MPC, the information shared between the local regulators consists of predicted system states or control inputs~\cite{scattolini2009architectures,negenborn2014distributed}.
The local regulators can be cooperative~\cite{amigoni2007formal,venkat2008distributed}, or non-cooperative~\cite{betti2013distributed}.
Existing works also consider sparse communication topologies~\cite{negenborn2007efficient}.
Some standard solution methods for distributed MPCs are robust MPC techniques~\cite{mayne2005robust} (for non-cooperative settings) and operator splitting methods like ADMM~\cite{boyd2011distributed} (for cooperative settings).
Control theoretical properties such as stability have also been studied for distributed MPC~\cite{venkat2005stability}.


\subsubsection{Hierarchical MPC}
\label{subsubsec:hierarchical-mpc}

In hierarchical MPC, the high-level coordinator shares its predicted control signal with the local regulators, and the goal is to optimize a high-level cost function~\cite{scattolini2007hierarchical,findeisen1980control}.
Solution techniques for hierarchical MPC include ADMM~\cite{braun2018hierarchical,zhang2020improved}, multiparametric programming~\cite{gupta2023hierarchical}, waypoint tracking~\cite{koeln2018two,koeln2020vertical}, tube-MPC~\cite{kogel2023safe,raghuraman2022hierarchical,picasso2010mpc}, and aggregation methods~\cite{johansson2012distributed}.
Price coordination is another class of methods relevant to our work, which uses Lagrange multipliers to link constraints across various subsystems.
The prices are iteratively computed to ensure global consensus among all the participating subsystems~\cite{mesarovic2000theory, findeisen1980control, negenborn2007efficient, amigoni2007formal, tatara2007control, negenborn2007multi}.


\subsubsection{Incentive Stackelberg Games}
\label{subsubsec:incentive-Stackelberg-games}

% Stackelberg games are hierarchical settings where one player, the leader, announces their strategy to the other, the follower~\cite{simaan1973stackelberg}.
% The goal is to choose the best strategy for the leader.
% Stackelberg games differ from hierarchical MPC because the follower strategy is fixed (and possibly unstable), and only the leader strategy is analyzed~\cite{mintz2018control}.
Stackelberg games can be formulated as bilevel optimization problems, and optimal leader strategies can be obtained by reformulating the bilevel problem to a single-level problem~\cite{zugno2013bilevel,jamaludin2015bilevel,ouattara2018duality}.
The control theoretical properties of hierarchical MPC as a Stackelberg game are studied in~\cite{mintz2018control}.
A subclass of Stackelberg games is incentive Stacklberg games, where, in addition to the leader strategy, an incentive is provided to the follower by the leader~\cite{mukaidani2020incentive,ho1982control,li2002approach}.
The game is said to be \emph{incentive controllable} if the leader can find incentives such that, given the leader strategy, the optimal follower strategy coincides with the optimal team strategy~\cite{ho1982control} (also see \cite[Sec.~2]{mukaidani2020incentive}).
In this paper, we extend the discussion in \cite{mintz2018control} to incentive Stackelberg games.
We define and discuss sufficient conditions for incentive controllability from the perspective of MPC.

\subsubsection{Dynamic Pricing for EV Charging}
\label{subsubsec:dynamic-pricing-for-ev-charging}

We consider a dynamic price control example for electric vehicle (EV) charging to demonstrate the algorithm proposed in this paper.
Dynamic price control is one approach to reconcile the mismatch between electricity supply and demand at different times of the day and can be formulated as a Stackelberg game~\cite{zugno2013bilevel,mintz2018control,ma2013decentralized,zou2017efficient}.
Dynamic price control aims to reduce the spikes in electricity generation by shifting the electricity demand to different times of the day.
Ideally, the electricity consumption pattern obtained using dynamic pricing achieves demand valley-filling~\cite{ma2013decentralized,zou2017efficient}.


\hidetext{
As a remark, another field of literature that uses the leader-follower connections discussed in this paper for optimal control is Hierarchical Reinforcement Learning (HRL)~\cite{pateria2021hierarchical}.
In HRL, the leader RL controller computes a leader control and a desired state for the follower RL controller.
The method proposed in this paper is similar to this approach in the sense that the incentives provided by the leader MPC define a desired input sequence for the follower MPC.
Existing literature studies the suboptimality of HRL for different timescales of the subsystems~\cite{nachum2018near}, using concepts similar to incentive controllability.
HRL has been applied for the control of hierarchical systems, for example, for quadrotor control~\cite{zhao2021hierarchical, Li2021ASH}.
}


% This paper considers a hierarchical MPC problem as an incentive Stackelberg game.
% To fix the terminology for the rest of the paper, following~\cite{mintz2018control}, the leader MPC is called the bilevel MPC (or BiMPC), and the follower MPC is called the low-level MPC (or LoMPC).
% The cost function of the LoMPC is assumed to be fixed and unknown to the BiMPC, and a known incentive cost is added to the LoMPC.
% First, the BiMPC computes an optimal input sequence.
% Then, the BiMPC sends the LoMPC an incentive and the BiMPC optimal inputs.
% The LoMPC computes its optimal inputs using the BiMPC inputs and the incentive.
% The first control inputs from the BiMPC and LoMPC optimal input sequences are applied to the system, and the process is repeated for subsequent timesteps.


\subsection{Contributions}
\label{subsec:contribution}

The contributions of our paper are as follows:
(a) We extend the discussion in \cite{mintz2018control} on hierarchical MPC as Stackelberg games to incentive Stackelberg games.
For the hierarchical MPC problem, we define incentive controllability and team-optimal solutions.
An incentive that achieves the team-optimal solution is defined as an optimal incentive.
We show that for the case of a single LoMPC, the
% under weak assumptions on the LoMPC cost and the incentive structure,
optimal linear-convex incentives can be found iteratively without knowing the LoMPC cost function.
Our analysis relies on tools from convex analysis and duality theory.
\hidetext{Our algorithm is similar to the dual ascent algorithm with augmented Lagrangians for convex optimization problems~\cite[Sec.~2.3]{boyd2011distributed}; we make this connection concrete in the later sections.}
(b) For the case of multiple LoMPCs, we compute linear-convex incentives that achieve the team-optimal solution up to an error bound.
We provide a single-level robust MPC reformulation of the BiMPC, whose optimal solution has bounded error compared to the team-optimal solution.
(c) We demonstrate our algorithm for dynamic price control for EV charging.
Our algorithm scales well with the EV population size and does not require the EV cost function.


\subsection{Paper Structure}
\label{subsec:paper-structure}

The paper is structured as follows:
Sec.~\ref{sec:background-and-problem-formulation} provides background on convex analysis and motivates and states the hierarchical MPC problem.
Sec.~\ref{sec:linear-incentives-for-hierarchical-mpc} defines linear incentives and incentive controllability for the hierarchical MPC and provides an iterative algorithm to calculate the optimal incentives.
Sec.~\ref{sec:linear-convex-incentives} extends the analysis in Sec.~\ref{sec:linear-incentives-for-hierarchical-mpc} to linear-convex incentives.
Sec.~\ref{sec:multiple-lompcs} considers the case where the hierarchical MPC problem with linear-convex incentives consists of multiple LoMPCs and provides a robust MPC formulation. % that is boundedly suboptimal compared to the BiMPC.
A dynamic price control example for EV charging is considered in Sec.~\ref{sec:numerical-examples} and conclusions are presented in Sec.~\ref{sec:conclusions}.


\subsection{Notations}
\label{subsec:notations}

The following notations are used throughout the paper:
%
% \subsubsection{Analysis}
% \label{subsubsec:analyis}
$\exreal = \real \cup \{-\infty, +\infty\}$ is the set of extended real numbers.
The Minkowski sum of two sets $\mathset{A}, \mathset{B} \subset \real^n$ is $\mathset{A} + \mathset{B} = \{a+b: a \in \mathset{A}, b \in \mathset{B}\}$.
% \hidetext{$\psd^n$ and $\mathpd^n$ are the sets of positive semidefinite and positive definite matrices in $\real^{n \times n}$ respectively.}
$\langle \cdot, \cdot \rangle$ represents an arbitrary inner product on the vector space considered, and $\lVert \cdot \rVert$ is the corresponding norm.
Note that the transpose of a linear map $A: \real^n \rightarrow \real^m$, $A^\top$, depends on the inner products defined on the domain $\real^n$ and co-domain $\real^m$.
$\dom{f}$ is the domain of the function $f$. % and $\epi{f}$ is the epigraph of $f$.
For a set $\mathset{C}$, $\relint{\mathset{C}}$ is the relative interior of $\mathset{C}$ \cite[Sec.~2.1.3]{boyd2004convex}.
%, i.e., the interior of $\mathset{C}$ with respect to the subspace topology of the affine hull of $\mathset{C}$.
$\indicator{\mathset{C}}: \real^n \rightarrow \exreal$ is the indicator function of a set $\mathset{C} \subset \real^n$, where $\indicator{\mathset{C}}(x) = 0 \ \forall x \in \mathset{C}$ and $\indicator{\mathset{C}}(x) = \infty \ \forall x \notin \mathset{C}$.
%
% \subsubsection{Indexing}
We also define $\langle \horizon \rangle := \{0, ..., \horizon-1\}$ and $[\horizon] := \{0, ..., \horizon\}$.
% \hidetext{The Kronecker product of $A \in \real^{m_1 \times n_1}$ and $B \in \real^{m_2 \times n_2}$ is denoted as $A \otimes B \in \real^{(m_1 + m_2) \times (n_1 + n_2)}$, with $[A {\otimes} B]_{m_2i_1 + i_2, n_2j_1 + j_2} = [A]_{i_1, j_1} [B]_{i_2, j_2}, \ \forall i_1 \in \langle m_1 \rangle, i_2 \in \langle m_2 \rangle, j_1 \in \langle n_1 \rangle, j_2 \in \langle n_2 \rangle$.}
For a function $\phi: \real^n \rightarrow \real^r$ and $x \in \dom{\phi}$, $D\phi(x): \real^n \rightarrow\real^r$ is the derivative of $\phi$.
For a real-valued function $f: \real^n \rightarrow \real$, $\nabla f$ is the gradient of $f$ (when $f$ is differentiable) and $\partial f$ is the subdifferential of $f$ (see Sec.~\ref{subsubsec:subdifferential-of-a-convex-function}).
Subscripts such as $D_x \phi, \partial_x f$ denote the differentiation variable.

% \subsubsection{Convex Analysis} (see Sec.~\ref{subsec:convex-analysis})
% For any convex function $f$, $\partial{f}(x)$, the set of subgradients of $f$ at $x$, is the subdifferential of $f$ at $x$.
% \changes{For any convex function $f$, the set of subgradients of $f$ at $x$ is called the subdifferential of $f$ at $x$ and denoted by $\partial{f}(x)$.}
% $\dom{f}$ is the domain of the function $f$. % and $\epi{f}$ is the epigraph of $f$.
% For a set $\mathset{C}$, $\relint{\mathset{C}}$ is the relative interior of $\mathset{C}$ \cite[Sec.~2.1.3]{boyd2004convex}.
% %, i.e., the interior of $\mathset{C}$ with respect to the subspace topology of the affine hull of $\mathset{C}$.
% $\indicator{\mathset{C}}: \real^n \rightarrow \exreal$ is the indicator function of a set $\mathset{C} \subset \real^n$, where $\indicator{\mathset{C}}(x) = 0 \ \forall x \in \mathset{C}$ and $\indicator{\mathset{C}}(x) = \infty \ \forall x \notin \mathset{C}$.
% \hidetext{$\proj_x$ is the projection operator, mapping a set in $(x, y)$ coordinates onto the $x$ coordinates.}
% For a closed convex cone $\mathset{K}$, the relation $a \preceq_\mathset{K} b$ holds if and only if $b-a \in \mathset{K}$.
