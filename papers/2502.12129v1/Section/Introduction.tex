 % \add{how about introducing with a focus on distributed setting . That is the focus of most of the theorems.}


Reliable compression of an information source for efficient storage is a central problem in information theory. A key question involves the asymptotic characterization of the rate required to compress a source that can be recovered up to a certain degree of measured loss, which is known as the lossy source coding problem. In the case of classical sources, Shannonâ€™s rate-distortion theory (RDT) \cite{shannon1959coding} established that the optimal rate for lossy data compression for a memoryless source is given by the mutual information between the source and its reconstruction. In this theory, Shannon introduced a \textit{local} error criterion based on averaged symbol-wise distortion between the reconstruction and the original source, using metrics like the Hamming distance and mean squared error.

% The Slepain-Wolf (SW) \cite{slepian1973noiseless} and Wyner-Ziv (WZ) \cite{wyner1976rate} theorems extends the Shannon's lossy source coding problem by incorporating side information available  at the decoder. While Slepain-Wolf theorem focuses on lossless coding, the goal of Wyner-Ziv theorem is to achieve a desired level of distortion, characterized using the averaged local error criterion between the original source and its reconstruction, while minimizing the required rate. The rate-distortion function for Wyner-Ziv coding is given by the mutual information between the source and the compressed representation, conditioned on the side information. 

The Wyner-Ziv (WZ) \cite{wyner1976rate} theorem extends Shannon's lossy source coding framework to a network setting where correlated side information about the source is available only at the decoder. 
It characterizes distortion using the averaged local error criterion while minimizing the required rate by utilizing side information to reconstruct the source.  
The WS rate-distortion function is characterized by the mutual information between the source and an auxiliary random variable conditioned on the side information. 

Considering side information in the quantum realm,  
Devetak and Winter \cite{devetak2003classical} explored lossless classical compression with quantum side information (QSI), demonstrating that quantum correlations can reduce the required classical compression rate. 
% The authors in \cite{yard2009Optimal} extended this work to lossless quantum compression with QSI, providing the optimal compression rate when quantum data is compressed with quantum side information available at the decoder. 
In the domain of lossy classical compression with QSI, Luo et al. \cite{luo2009channel} characterized the rate region when classical data is compressed in the presence of QSI at the decoder. 
In the context of the quantum-classical (QC) case, Datta et al. \cite{datta2013quantum} explored QC compression using QSI. The authors derived an asymptotic QC rate-distortion function in terms of single-letter quantum mutual information conditioned on the quantum side information and characterized distortion through a local error criterion, which is a QC analogue to those found in Shannon's and WZ's lossy source coding problems.

In our previous work \cite{sohail2023unique}, we developed a new formulation of the lossy source coding problem, called \textit{rate-channel theory} (RCT), which departs from the local error criterion to characterize distortion and employs a \textit{global} error criterion based on the posterior (backward) channel. In RCT, a single-letter posterior channel is given that characterizes the nature of loss instead of a single-letter distortion function. The goal is to construct a coding system such that the joint effect of producing a reconstruction sequence from the source sequence closely matches the effect of the $n$-product posterior channel on the non-product reconstruction sequence, manifesting as a block error constraint. This new formulation enables a single-letter asymptotic characterization for lossy source coding problems in terms of coherent information, quantum mutual information, and mutual information for fully quantum, QC, and classical setup, respectively \cite{atif2023lossy}. This has further inspired research on the rate-distortion-perception trade-off with a conditional distribution perception measure \cite{salehkalaibar2024rate} and quantum soft-covering lemma \cite{atif2023quantum}.

Motivated by these developments, we formulate the side information setting of the WZ incorporating a global error constraint using the notion of a posterior channel that produces the source from its reconstruction and side information available at the decoder. In this setting, instead of a single-letter distortion function, we are given a single-letter posterior channel capturing the nature of the loss. The goal is to construct an encoder and a decoder such that the joint effect of the producing reconstruction from the source sequence using side information available at the decoder is close to the effect of the $n$-product posterior channel acting on the non-product reconstruction sequence and side information, manifesting as a block error constraint. Similarly, we formulate the QC-QSI problem incorporating a global error constraint using the notion of a posterior classical-quantum (CQ) channel that produces the reference of the source and the side information using the reconstruction. We provide an inner bound in terms of the single-letter mutual information and quantum mutual information conditioned on side information for classical and QC cases, respectively (see Theorems \ref{thm:QC-QSI} and \ref{thm:C-CSI}). Furthermore, we provide the connection between RDT and rate-channel theory. In particular, we show that a lossy compression protocol using global error criterion also achieves optimal rate-distortion function for a specific distortion function and distortion level (see Theorem \ref{thm:connection}).

As for the inner bound, we use Winter's measurement compression protocol \cite{winter1999coding} to construct an encoding POVM, sequential decoder \cite{wilde2013sequential} using typical projectors for constructing decoding POVMs, and Sen's non-commutative union bound \cite{sen2012achieving}. For C-CSI, we employ likelihood encoders \cite{cuff2010coordination, atif2022source} for constructing randomized encoders. For detailed analysis, please refer to \cite{sohail2025WZ}.





% \add{add the contribution on classical side information with global error criterion}

% In the quantum setting, the problem of lossy source coding have dealt in a range of works. Barnum \cite{barnum2000quantum} introduced a local distortion criterion based on averaged symbol-wise entanglement fidelity between the reconstruction and the original source with the aim of characterizing the asymptotic performance limit for the lossy source coding problem. 
% % Other works in this area, including \cite{datta2012quantum, wilde2013quantum, khanian2021rate,  
% Datta et al. \cite{datta2013quantum} formulated a lossy quantum-classical (QC) source coding problem, using a local error criterion defined as the symbol-wise quantum-classical distortion with respect to a single-letter distortion observable. The authors derived a single-letter expression for the asymptotic QC rate-distortion function \cite{datta2013quantum}, given by minimal quantum mutual information with respect to a QC state. Other works in this area, including \cite{datta2012quantum, wilde2013quantum, khanian2021rate, khanian2022general, devetak2002quantum, bennett2014quantum}, have further explored these problems. In \cite{atif2023lossy}, the lossy quantum compression problem was revisited from a global error perspective, leading to the characterization of a single-letter asymptotic performance limit in terms of the coherent information of the posterior CPTP map.

% As our next set of contributions, we incorporate the global error perspective toward the results on quantum side information, and offer new insights into the lossy compression problem in the presence of QSI. We first consider the classical source .. \add{remaining contributions}.



% \newpage
% A fundamental problem in information theory is the reliable compression of an information source for its efficient storage. An immediate question to ask for this problem is what is the asymptotic characterization of the rate required to compress a source that can be recovered up to a certain degree of measured loss, such problem in information theory is known as lossy source coding problem. For classical source, Shannon \cite{shannon1959coding} in his rate-distortion theory (RDT) proved that, for a memoryless source, the optimal rate of lossy data compression is the mutual information between the source and its reconstruction. In RDT, he introduced a \textit{local} error criterion as averaged symbol-wise distortion between the reconstruction and the original source, for the Hamming distance and the mean
% squared error. The authors in \cite{datta2012quantum} extended the classical information about a quantum source while suffering a bounded error between the quantum source and its reconstruction, namely, the lossy quantum-classical (QC) source coding problem. In this case, the authors used the same local error criterion as symbol-wise QC
% distortion observable. For this problem, a single-letter expression for the asymptotic QC rate-distortion function was obtained in \cite{datta2013quantum} in terms of 
% minimal quantum mutual information, where the minimization is over all POVMs satisfying the distortion constraint. 

% As for the lossy quantum regime, Barnum \cite{barnum2000quantum} conjectured minimum coherent information as an asymptotic performance limit by introducing a local distortion criterion as averaged symbol-wise entanglement fidelity based on partial trace operations between the reconstruction and the reference of the original source. Other works along this line include \cite{datta2012quantum,wilde2013quantum,khanian2021rate,khanian2022general,devetak2002quantum,bennett2014quantum}. In contrast, authors in \cite{sohail2023unique} introduced a new formulation, namely, rate-channel theory, for the lossy source coding problem based on the posterior (backward) channel that produces the source from its reconstruction. This new formulation uses the \textit{global} error criterion as opposed to the approach of local symbol-wise error criterion studied in the literature. Here, instead of a single-letter distortion function, we are given a single-letter posterior channel that characterizes the nature of the loss incurred in the encoding and decoding operations. 
% We want to construct an encoder and a decoder 
% such that the joint effect of 
% producing a reconstruction sequence 
% from the source sequence 
% is close to the effect of the $n$-product posterior channel acting on the non-product reconstruction sequence, manifesting as a block error constraint. 
% In the quantum setup, the posterior channel is referred to as posterior CPTP maps that produce the reference of the source from that of the reconstruction. In \cite{atif2023lossy} provides a single-letter characterization of the asymptotic performance limit of loss   

% \add{introduce side information}

% \add{PLACEHOLDER}
% We consider a fundamental task of compressing the classical information about a quantum source while suffering a bounded error between the quantum source and its reconstruction, namely, the lossy quantum-classical (QC) source coding problem \cite{datta2013quantum}. In this setting, the sender performs a collective measurement on several copies of the quantum source, producing a classical sequence. The sender compresses the classical sequence and sends it to the receiver over a noiseless classical channel. The receiver then outputs a classical sequence using a classical decoding map while incurring a bounded reconstruction error, which is measured by an additive single-letter distortion observable. 
% % This problem was considered in \cite{datta2013quantum}. 
% For this problem, a single-letter expression for the asymptotic QC rate-distortion function was obtained in \cite{datta2013quantum} in terms of 
% % characterization in terms of 
% minimal quantum mutual information, where the minimization is over all POVMs satisfying the distortion constraint. Here, the POVM construction used was borrowed from the measurement compression protocol \cite{winter}.
% % The POVM used in the coding theorem 
% The average single-letter error criterion is inspired by the corresponding additive single-letter distortion criterion in the lossy classical source coding formulation of Shannon \cite{shannon1959coding}, where a single-letter characterization is available. The motivation for considering a single-letter error criterion is the strong converse of the lossless source coding theorem, which states that the entropy bound cannot be breached even when the asymptotic probability of block error is relaxed to any number in $(0,1)$ \cite[Theorem 1.1]{csiszar2011information}.
% % \textbf{remove Schumacher} In the lossless quantum regime, Schumacher \cite{schumacher1995quantum} proved that a quantum source could be compressed at a rate given by von Neumann entropy while suffering a small error between the reconstruction and the quantum source. In this setting, the error is defined for the entire block, also called a block error.

% % A rate-distortion version of the lossy QC source coding problem was considered in \cite{datta2013quantum}. 
% %  Datta \emph{et.al.} \cite{datta2013quantum} studied this problem, however, in the rate-distortion setting. 

% % In the lossless classical regime, Shannon \cite{shannon1948mathematical} proved that a classical source could be compressed at a rate given by entropy with a bounded error. In this setting, the error is defined for the entire block, known as a block error. 
% % In this work, we  consider a new formulation of the lossy QC source coding problem with a block error constraint instead of the average symbol-wise error criterion. 
% % We  characterize a rate function no larger than von Neumann entropy  while allowing for bounded error in the reconstruction. 
% % We use a global error criterion as opposed to the  approach of local symbol-wise error studied in the literature.
% % We motivate this formulation with the following observations.
% % The average symbol-wise error criterion is inspired by the corresponding additive single-letter distortion criterion in the classical source coding formulation of Shannon \cite{shannon1959coding}, where a  single-letter characterization is available.
% % The motivation for considering a single-letter error criterion is the strong converse of the lossless source coding theorem, which states that the entropy bound cannot be breached even when the asymptotic probability of block error is relaxed to any number in $(0,1)$ \cite[Theorem 1.1]{csiszar2011information}.
% % Toward answering this question, we take a closer look at the classical discrete memoryless setting.  We find that 

% In addition to Shannon's work on the rate-distortion problem \cite{shannon1959coding}, 
% there have been several works discussing the lossy source compression problem \cite{berger1975rate}. 
% A concept that has received particular attention is the notion of a backward channel \cite[Problem 8.3]{csiszar2011information}, which characterizes the posterior distribution of the source given the reconstruction. The structure of this channel has been studied in \cite{gallager1968information,berger1971rate,gerrish1963estimation}. 
% % Although the forward channel, relating the reconstruction to the source, achieving the rate-distortion function need not be unique, the resulting backward channel is indeed unique. 
% Moreover, the rate-distortion achievability result in \cite[Theorem 7.3]{csiszar2011information} is shown by constructing a channel code for a backward channel with a large probability of error and by using the encoder of the latter as a decoder of the former and vice versa.
% Highlighting this duality further, inspired by results on the output statistics of good channel codes \cite{shamai1997empirical},
% \cite{pradhan2004approximation} shows that 
% % Pradhan \cite{pradhan2004approximation} showed 
% % The $n$-letter actual posterior conditional distribution of the source vector given the reconstruction vector of any rate-distortion achieving code converges  to the $n$-product of the unique minimum-mutual-information backward channel conditional distribution. In other words, 
% the induced   $n$-letter posterior channel asymptotically becomes discrete memoryless in the normalized divergence for any rate-distortion achieving code, despite the block encoding and decoding operations.
% % Cuff  \textit{et al.} in \cite{cuff2010coordination} studied empirical coordination, a concept similar to the rate-distortion. However, the distortion criterion requirement is replaced by the condition that the joint empirical distribution converges to 
% % the desired joint distribution in total variation. Weissman and Ordentlich in \cite{weissman2005empirical} showed that the $k$th-order empirical distribution of a good rate-distortion code converges in
% % distribution to the unique distribution that minimizes the $k$th-order
% % rate-distortion function. Schieler and Cuff in \cite{schieler2013connection} established that the input-output joint distribution of any rate-distortion achieving codes converges in normalized divergence to the output-input joint distribution of discrete memoryless channel characterized by reverse test channel conditional distribution. Kostina and Verdu \cite{kostina2015output} showed for any rate-distortion achieving codes, the distribution of the input given the output converges in normalized divergence to rate-distortion achieving distribution of the
% % input given the output. In the context of channel coding, Shamai and Verdu \cite{shamai1997empirical} showed that for any capacity-achieving codes, the output distribution at the memoryless channel converges in normalized divergence to the unique capacity-achieving output distribution. 
% % Further developments on this concept have been made in 
% For further developments on this concept, see \cite{kanlis1996typicality,weissman2005empirical,cuff2010coordination,schieler2013connection,kostina2015output}. 
% % This channel also plays a fundamental role in Bayesian estimation and detection theory \cite{poor1998introduction}, e.g., maximum a posteriori (MAP) estimation.
% Therefore, we ask the question, can we use such a channel to formulate a lossy QC source coding problem?

% % Those that are of particular interest to us are the works of Verdu and ..., which have demonstrated that given a code that achieves the single-letter source compression limit of the rate distortion problem, that is, the mutual information between source and its reconstruction, also exhibits an interesting behaviour when it comes to the so called the reverse test channel. In particular, the reverse test channel resulting from such codes behaves like a  product channel, with 1 revealing the closeness in normalized divergence and 2 in total variation.

% % As another observation, a similar duality connection exists between the classical-quantum communication problem \cite{holevo1998capacity,schumacher1997sending} and the quantum-classical rate-distortion problem \cite{winter, datta2013quantum}, with both performance limits characterized in terms of single-letter Holevo information. This has been further explored in \cite{cheng2019duality}.

% % in the quantum-classical setting have been recently explored. In particular, classical source coding with quantum side information,
% % and channel coding over classical-quantum channels.

% % \noindent \textbf{Contributions of this work:}
% In light of this, we develop a new formulation of the lossy QC and classical source coding problems 
% based
% on the notion of a posterior channel that produces the source from its reconstruction. In the QC setup, we refer to this as a posterior classical-quantum (CQ) channel that relates the reference of the source with the reconstruction. Furthermore, we consider a block error constraint instead of the average symbol-wise error criterion. Invariably, the block error constraint of the new formulation can be shown to be stronger than the additive distortion constraint used in the standard rate-distortion one.
% % using a global error criterion.  
% Here, instead of a single-letter distortion function, we are given a single-letter posterior channel that characterizes the nature  of the loss incurred in the encoding and decoding operations. 
% We want to construct an encoder and a decoder 
% % with the constraint 
% such that the joint effect of 
% % encoding and decoding -- to
% % produce 
% producing a reconstruction sequence 
% from the source sequence 
% % -- 
% is close to the effect of the $n$-product posterior channel acting on the non-product reconstruction sequence, manifesting as a block error constraint. 
% % to produce the  source sequence.
% The closeness is measured using the trace distance in the QC case and the total variation in the classical case.
% % Although  posterior (backward) channels have been extensively studied classically, such channels have not received enough attention in the context of lossy quantum source coding problem.
% % such a channel is not explicitly defined in a purely quantum setting.
% % A related concept is the 
% % Petz recovery map
% % % is one such channel 
% % which has found significant relevance in  information-theoretic problems \cite{petz1986sufficient,barnum2002reversing,hayden2004structure}. However, we take a different approach and consider a quantum channel, i.e., a CPTP map, acting on the reference of the reconstruction to produce the reference of the source, whose existence is guaranteed using Uhlmann's theorem.  
% % We refer to this as a posterior reference map.

% % We consider a CQ channel that acts on the compressed message and produces the quantum source. We refer to this as a posterior reference map.


% % As one of the main contributions of our work, we provide a new formulation for the lossy QC and classical source coding problems. 
% We provide a single-letter characterization of the asymptotic performance limit using 
% the minimal quantum mutual information and the minimal mutual information of the posterior channel in the QC and classical setup, respectively, where the minimization is over all reconstruction distributions (see Theorem \ref{thm:qclossysourcecoding} and \ref{thm:clsrate_distortion}). 
% % In the classical setup,  determines the single-letter characterization of the asymptotic performance limit of the classical source coding problem.
%  As for the achievability of Theorems \ref{thm:qclossysourcecoding} and  \ref{thm:clsrate_distortion}, we use Winter's measurement compression protocol \cite{winter} to construct the encoding POVM, and the likelihood encoder as discussed in \cite{cuff2013distributed,atif2022source} to construct the randomized encoder, respectively.
% Proof of the converse of Theorem \ref{thm:qclossysourcecoding} uses inequalities 
%  % discussed in \cite[Ch. 11]{wilde_arxivBook} 
%  such as
%  % \cite[Section 11.9.2]{wilde_arxivBook}, 
%  the concavity of conditional quantum entropy, and the continuity of quantum mutual information. Similar tools are used for the converse of Theorem \ref{thm:clsrate_distortion}.
% % The paper is organized as follows. We provide some necessary notations and definitions in Section \ref{QLSC:sec:prelim}. In Section \ref{QLSC:sec:mainResults}, we formulate the problems  and provide the main results. We provide examples corresponding to these results in section \ref{QLSC:sec:examples}. 
% % In Sections \ref{sec:qcproof} and \ref{sec:clsproof}, we provide proofs of the main results. 
% % Finally, Section \ref{sec:conclusion} concludes the paper.
