\section{Formative Study}
To understand how large language models could support diagramming-based prewriting, we conducted a formative study involving 10 participants with daily writing habits ranging from news articles to fiction writing. We used snowball sampling to recruit students in writing- or creativity-related majors (e.g., creative media, design, English literature etc.). All participants were ethnically Chinese, and English was their second language.

\subsection{Protocol}
After participants consented to the study, we asked them to develop a science fiction or thriller story plot using an LLM together with the traditional tools (a pen and a piece of paper) for diagramming or illustrating their ideas.
Participants accessed the LLM using the GPT-3 playground interface.
They were asked to think aloud during the prewriting process.
After completing the tasks, we asked participants to reflect on their experiences and strategies.

The whole process was audio-taped, screen-recorded, and later transcribed for analysis. Two coders performed thematic analysis \cite{corbin2014basics} of the transcripts with reference to the screen recording to extract collaboration strategies, patterns, and breakdowns. The coders later held a discussion to reach a consensus on the themes.

\subsection{Findings}
We report the findings of our formative study in two themes: human-LLM collaboration workflow and common challenges encountered. We found our participants already anthropomorphized the LLM as a collaborator, and delegated to it distinct tasks for both divergent and convergent thinking.
% We first summarise how users leveraged the LLM to support prewriting, and clarify the functions and expected initiative of the LLM during the process. Then we report the two most significant challenges, progress tracking and communication breakdown.
%% Ideally say something related to our later design choice here

\subsubsection{Human-LLM Collaboration Workflow: Tasks and Initiative} \label{the_usage_of_LLMs_for_prewriting}
We observed that participants already implemented the parallel thinking strategy consciously or unconsciously.
They expected the LLM to perform multiple but distinctive functions, including generating additional ideas, elaborating on concepts, organizing fleeting thoughts, and enriching existing writing with details.
These functions were typically seen in creativity processes, covering both convergent and divergent thinking phases.
% From the first to the third stage, ideas become increasingly concrete, articulated, and formalised.
% This human-LLM collaboration workflow aligns with previous conceptualisations of the creativity process in both Psychology \cite{wallas1926art} and Human-Computer Interaction (HCI) \cite{frich2019mapping,shneidenmab2003supporting}, because prewriting is inherently a stage of creativity, or a stage of discovery as described by Rohman \cite{rohman1965pre}.

We found that users almost always preferred to take the initiative during the whole collaboration process, unless they ran out of ideas. They would use LLMs mostly to enrich their ideas with details, such as bridging a logical gap in a plot or providing a nuanced portrait of a scene.
Only when users had no initial ideas or hit writer's block, would they let the LLM take the initiative to generate ideas. P3 described the ideal role of LLM as similar to a ``\textit{second mind}'' that ``\textit{processes all the context in parallel}'' and ``\textit{provides ideas when requested}'', while he could still take control of the general prewriting process.

Meanwhile, we also noticed that users were generally tolerant and did not mind following the ideas in LLM output, which were often initially vague or confusing. Some users (P3-4, P8-9) were found to spend a long time iteratively refining their own prompts to improve the LLM's output.

\subsubsection{Challenges: Progress Tracking \& Communication Breakdown} \label{progress_tracking}
\paragraph{\underline{Progress Tracking}}
Many of our participants (P2-4, P6-7) particularly emphasized that tracking collaboration progress, and maintaining the ever-changing collaboration history while prewriting with the LLM was challenging. Because prewriting is iterative, and LLM generations can be random, our participants frequently needed to expand on specific points within a lengthy piece of writing in a new context, or re-generate content from a previous version. On such occasions, some participants (e.g., P2, P7, P10) mentioned they would need examples, suggestions, or templates as a reference to polish their prompts, and requested features to maintain the history of collaboration with LLM. 
%Progress tracking was considered by P7 to be even more challenging in semi-structured strategies such as diagrams, because different types of generations at each request can be easily conflated with users' content.
\paragraph{\underline{Communication Breakdown}}
The uncertainty of prompt-based communication can often cause LLMs to generate unsatisfactory or even nonsensical results during prewriting. P2 and P4 reflected that, to effectively communicate with an LLM, proper and sufficient context should be articulated via prompts, which can be difficult in complex writing tasks. On these occasions, instead of rewriting their prompts, most participants (e.g., P1-4, P6, P9-10) chose to provide more context and ask LLMs to polish previous output. For example, P4 found the ending of an LLM-generated science fiction lacks originality. Instead of deleting the result and requesting a new one, she asked the LLM to avoid using banal superhero endings and explore existential questions, using an imperative sentence as if giving feedback to a human collaborator.

\subsection{Summary}
Our formative study reveals the creative nature of human-LLM collaboration during prewriting, where LLMs could offer additional perspectives and handle a range of complex ideation tasks. Although participants would like to take control most of the time, it is particularly beneficial that LLMs can run in parallel with users' diagramming activities and provide assistance when requested. During the collaboration, participants often found progress tracking and communication with the LLM using a conversational interface challenging. They requested features to support managing collaboration progress, and favoured an incremental feedback process to facilitate iteration.

\section{Design Goals}
Our primary design goal is to integrate LLMs into a diagramming-based interface to facilitate the application of the parallel thinking strategy in prewriting. We first introduce how we derive the core idea of ``microtasking'' to operationalize parallel thinking, and then report our three design goals to support a microtasking workflow.

\subsubsection*{\textbf{Microtasking for parallel thinking}}
%We are deeply inspired by P3's account of LLMs' collaboration role a ``second mind'', which resonates with the idea of ``parallel thinking'' proposed in the book ``\textit{Six Thinking Hats}'' \cite{de2017six,bono1985six}. 
The notion of ``parallel thinking'' separates the human thinking process into distinct functions and roles. 
%Similarly, LLMs can process a variety of complex but distinct tasks that run in parallel with the user's own thinking process.
In reality, parallel thinking can often be practiced through group collaboration, where each of the distinct roles can be played by different individuals or groups in parallel. We seek to simulate group collaboration to break down prewriting workflows into smaller, manageable, and independent tasks that support both divergent and convergent thinking processes.
%so that each task handled by LLMs can contribute in parallel to efficiently provide productive and creative results.

To this end, we adopt the concept of ``microtasks'', commonly used in crowd sourcing \cite{latoza2014microtask,chen2017retool}, collaborative writing \cite{iqbal2018multitasking,birnholtz2013write,teevan2016supporting}, and group brainstorming \cite{chilton2019visiblends,teevan2016supporting}. Previous studies suggest that a microtasking workflow simplifies complex tasks \cite{cheng2015break,kokkalis2013taskgenies}, facilitates recovery from interruptions, and leads to higher quality of results \cite{cheng2015break}. Similarly, in a human-LLM collaboration scenario, we expect small manageable microtasks that require little context of one another to run concurrently can make complex prewriting tasks easier to coordinate, and save the need to iteratively articulate complex context in prompts.
Specifically, we derive the following three design goals to implement this idea. 

\input{microtasks}

\subsubsection*{\textbf{Goal 1: Scaffold visual-diagramming-based prewriting with microtasks}}
We aim to scaffold the prewriting process with a diagramming tool that supports common strategies such as concept mapping, mind mapping, outlining, etc. To enable natural collaboration with an LLM while diagramming, we are inspired by the concept of ``macros'' \cite{kurlander1992history} and seek to address the uncertainty of collaboration goals by defining default microtasks, and allowing users to customise their requirements or rapidly delegate their own microtasks.

Our formative study inspired us to draw upon existing literature on creativity support tools (CSTs) beyond prewriting itself to define default microtasks, as the collaboration workflow appeared to be a typical creativity process. We conducted a survey of both CST and writing tool literature by searching two academic databases, ACM Digital Library and Google Scholar, using three keywords: ``writing'', ``prewriting'', and ``creativity support''. We reviewed the top 100 entries for each keyword.
%We then performed a thematic analysis of system design papers among top 100 entries of each search result (200 entries in total), recording their key features and functions. Afterwards, we grouped these features or functions into different categories to derive our pre-defined microtasks.
Based on this survey, we identified 6 microtasks: ``Brainstorm'', ``Elaborate'', ``Summarise'', ``Draft'', ``Freewrite'', and ``Associate'', as summarised in \autoref{table:microtasks}. Of these microtasks, ``Brainstorm'' and ``Associate'' are typical divergent thinking tasks seen in existing CSTs (e.g., conceptual blending of \cite{wang2021popblends,chilton2019visiblends}, attribute detection of \cite{jeon2021fashionq}, group ideation of \cite{teevan2016supporting,wang2010idea}, etc.)
``Draft'' and ``Freewrite'' are common features in prewriting tools \cite{lu2018inkplanner,sadauskas2015mining}. ``Elaborate'' and ``Summarise'' are commonly used in the literature of writing support~\cite{uto2015academic,dang2022beyond}, as convergent thinking tasks to help articulate or organise existing ideas.

\subsubsection*{\textbf{Goal 2: Facilitate task management}}
Task management is crucial in human collaboration. In our scenario, a user acts as a leader who determines the goals and progress of the collaboration. Therefore, she should be granted sufficient control to manage microtasks. To this end, we further derive three sub-goals from the literature on human collaboration and our formative study.
\paragraph{\textbf{Goal 2.1: Provide awareness}}
The awareness information about other collaborators while using groupware \cite{gutwin2002descriptive} is vital in tasks such as collaborative writing \cite{birnholtz2013write} and collaborative learning \cite{fransen2011mediating}. On a prewriting interface (e.g., a diagramming canvas), where elements can be loosely organised and often scattered around, it might be hard to notice other collaborators' operations without proper design support. Therefore we seek to provide awareness features so that users can easily track the status of each microtask, and the results returned by each microtask.
As informed by ~\cite{gluck2007matching}, we aim to design different levels of awareness features that match the utility of different interruption types.

\paragraph{\textbf{Goal 2.2: Support progress tracking}}
Progress tracking is an essential aspect of many collaboration tasks, especially collaborative writing \cite{birnholtz2013write,birnholtz2012tracking}. Our formative study suggests that it is also a concern while collaborating with an LLM. We aim to help users manage the results of each microtask in a less demanding way, so that they do not clutter users' diagrams but can be merged into them once accepted.
\paragraph{\textbf{Goal 2.3: Facilitate human feedback}}
Feedback is essential for improvements \cite{dow2011shepherding,haug2021feeasy,huang2018feedback}. In our formative study, users generally preferred feedback-like communication upon unsatisfactory generations. Therefore we aim to facilitate user feedback to enhance LLM-generated content. In our system, the ``feedback'' is provided to an LLM, which implies that it should convert user requirements into actionable prompts.

\subsubsection*{\textbf{Goal 3: Apply mixed initiative}}
Although users preferred to maintain control most of the time in our formative study, they still wanted the LLM to take the initiative when running out of ideas, a common hurdle during prewriting. Sometimes, they even expected the LLM to further clarify or improve its output. Therefore, we aim to apply the principle of ``mixed initiative'' \cite{horvitz1999principles}, and allow a microtasking LLM to infer the focus of attention of the user to determine the timing of suggestions. To keep users in control and minimize the cost of inference errors, we aim to enable users to manage the initiative of each individual microtask. 