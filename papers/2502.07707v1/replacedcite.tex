\section{Related Work}
% In this section, we discuss works that are closely relevant to our approach from the following three lines.

% \vspace{0.5em}
% \noindent
\textbf{Egocentric Visual Query Localization.} Egocentric visual query localization (EgoVQL) is an emerging and important computer vision task. Since its introduction in____, EgoVQL has received extensive attention in recent years owing to its importance in numerous applications. Early methods____ often utilize a bottom-up multi-stage framework, which sequentially and independently performs frame-level object detection, nearest peak temporal detection across the video, and bidirectional object tracking around the peak, to achieve EgoVQL. Despite the straightforwardness, this bottom-up design easily causes compounding errors across stages, thus degrading performance. Besides, the involvement of multiple detection and tracking components in this design leads to high complexities as well as inefficiency of the entire system, limiting its practicability. To deal with these issues, the recent method of____ introduces a single-stage end-to-end framework for EgoVQL with Transformer____, eliminating the need for multiple components and meanwhile showing promising target localization performance.

In this work, we propose to exploit target knowledge directly from the video and utilize it as guidance to refine features for better localization. \textbf{\emph{Different}} from aforementioned approaches____ which mainly explore the object information from only the provided query for localization, PRVQL is able to leverage cues from both the given query and mined target information for EgoVQL, significantly improving robustness, especially in presence of severe appearance variations and cluttering background.

\begin{figure*}[!t]
	\centering
        \includegraphics[width=1\textwidth]{figs/fig2.pdf}\vspace{-2mm}
	\caption{Overview of PRVQL, which aims to explore target knowledge directly from videos via AKG and SKG and applies it as guidance to refine query and video features with QFR and VFR for improving localization in EgoVQL through a multi-stage progressive architecture.}
	\label{fig:framework}\vspace{-4mm}	
\end{figure*}

\vspace{0.5em}
\noindent
\textbf{Query-based Visual Localization.} Query-based visual localization, broadly referring to localizing the target of interest from images or videos given a specific query (image or text), is a crucial problem in computer 
vision, and consists of a wide range of related tasks, including one-shot object detection____, visual object tracking____, visual grounding____, spatio-temporal video grounding____, pedestrian search____, \etc. Despite sharing some similarity with the above tasks in localizing the target, this work is \textbf{\emph{distinctive}} by focusing on spatially and temporally searching for the target from egocentric videos, which is challenging due to frequent and heavy object appearance variations under the first-person views.

\vspace{0.5em}
\noindent
\textbf{Progressive Learning Approach.} Multi-stage progressive learning is a popular strategy to improve performance, and has been successfully applied for various tasks. For example, the works of____ introduce the cascade architecture to progressively refine the bounding boxes or features for improving object detection. The work in____ presents a sptio-temporal progressive network for video action detection. The methods in____ introduce progressive refinement network for multi-scale semantic segmentation. The methods of____ apply progressive learning to improve features for saliency detection. The method in____ proposes to progressively learn more accurate anchors for enhancing tracking. The work from____ progressively transfers person pose for image generation. \textbf{\emph{Different}} than these works, we focus on progressive refinement for improving EgoVQL.