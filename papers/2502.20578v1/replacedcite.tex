\section{Related Work}
\textbf{Interpreting CLIP models.}
CLIP interpretability research follows two main directions: a direct interpretation of CLIP's behavior and using CLIP to explain other models. 
Direct interpretation studies focus on understanding CLIP's components through feature attributions____, residual transformations____, attention heads ____, and individual neurons____. 
____ discovered CLIP's tendency to focus on image backgrounds through saliency analysis, while ____ identified CLIP's multimodal neurons responding consistently to concepts across modalities. 
For model explanation, CLIP is used to analyze challenging examples____, robustness to distribution shifts____, and label individual neurons____.
In this work, we explore both directions in Section~\ref{sec:application} via the detection of semantic concepts learned by CLIP using MSAE (Section~\ref{sec:concept-naming}) and the analysis of biases in downstream models built on MSAE-explained CLIP embeddings (Section~\ref{sec:main_bias}).


\textbf{Mechanistic interpretability.}
Mechanistic interpretability seeks to reverse engineer neural networks analogously to decompiling computer programs____. 
While early approaches focus on generating natural language descriptions of individual neurons ____, the polysemantic nature of neural representations makes this challenging. 
A breakthrough comes with sparse autoencoders~(SAEs)____, which demonstrate the ability to recover monosemantic features. 
Recent architectural advancements like Gated____ and TopK SAE variants____ improve the sparsity--reconstruction trade-off, enabling successful application to LLMs____, diffusion models____, and medical imaging____. 
Recent work on SAE-based interpretation of CLIP embeddings ____ shows promise in extracting interpretable features. 

\textbf{Concept-based explainability.}
Concept-based explanations provide interpretability by identifying human-coherent concepts within neural networks' latent spaces. 
While early approaches relied on manually curated concept datasets____, recent work has explored automated concept extraction ____ and explicit concept learning ____, with successful applications in out-of-distribution detection ____, image generation ____, and medicine ____. 
However, existing methods often struggle to scale to modern transformer architectures with hundreds of millions of parameters. 
Our approach addresses this limitation by first training SAE without supervision on concept learning, then efficiently mapping unit-norm decoder columns to defined vocabulary concepts using cosine similarity with CLIP embeddings.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%