[
  {
    "index": 0,
    "papers": [
      {
        "key": "sutton1991dyna",
        "author": "Sutton, Richard S",
        "title": "Dyna, an integrated architecture for learning, planning, and reacting"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "MBPO",
        "author": "Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey",
        "title": "When to trust your model: Model-based policy optimization"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "katsigiannis2017dreamer",
        "author": "Katsigiannis, Stamos and Ramzan, Naeem",
        "title": "DREAMER: A database for emotion recognition through EEG and ECG signals from wireless low-cost off-the-shelf devices"
      },
      {
        "key": "deramerv2",
        "author": "Hafner, Danijar and Lillicrap, Timothy and Norouzi, Mohammad and Ba, Jimmy",
        "title": "Mastering atari with discrete world models"
      },
      {
        "key": "dreamerv3",
        "author": "Danijar Hafner and Jurgis Pasukonis and Jimmy Ba and Timothy Lillicrap",
        "title": "Mastering Diverse Domains through World Models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "PlaNet",
        "author": "Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James",
        "title": "Learning latent dynamics for planning from pixels"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "PETS",
        "author": "Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey",
        "title": "Deep reinforcement learning in a handful of trials using probabilistic dynamics models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "bhardwaj2020information",
        "author": "Bhardwaj, Mohak and Handa, Ankur and Fox, Dieter and Boots, Byron",
        "title": "Information theoretic model predictive q-learning"
      },
      {
        "key": "LOOP",
        "author": "Sikchi, Harshit and Zhou, Wenxuan and Held, David",
        "title": "Learning off-policy with online planning"
      },
      {
        "key": "hansen2022TDMPC",
        "author": "Hansen, Nicklas and Wang, Xiaolong and Su, Hao",
        "title": "Temporal difference learning for model predictive control"
      },
      {
        "key": "DMPC",
        "author": "Zhou, Guangyao and Swaminathan, Sivaramakrishnan and Raju, Rajkumar Vasudeva and Guntupalli, J Swaroop and Lehrach, Wolfgang and Ortiz, Joseph and Dedieu, Antoine and L{\\'a}zaro-Gredilla, Miguel and Murphy, Kevin",
        "title": "Diffusion model predictive control"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "hansen2023tdmpc2",
        "author": "Hansen, Nicklas and Su, Hao and Wang, Xiaolong",
        "title": "Td-mpc2: Scalable, robust world models for continuous control"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "BEAR",
        "author": "Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey",
        "title": "Stabilizing off-policy q-learning via bootstrapping error reduction"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "BEAR",
        "author": "Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey",
        "title": "Stabilizing off-policy q-learning via bootstrapping error reduction"
      },
      {
        "key": "td3bc",
        "author": "Fujimoto, Scott and Gu, Shixiang Shane",
        "title": "A minimalist approach to offline reinforcement learning"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "BCQ",
        "author": "Fujimoto, Scott and Meger, David and Precup, Doina",
        "title": "Off-policy deep reinforcement learning without exploration"
      },
      {
        "key": "AWR",
        "author": "Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey",
        "title": "Advantage-weighted regression: Simple and scalable off-policy reinforcement learning"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "IQL",
        "author": "Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey",
        "title": "Offline reinforcement learning with implicit q-learning"
      },
      {
        "key": "XQL",
        "author": "Garg, Divyansh and Hejna, Joey and Geist, Matthieu and Ermon, Stefano",
        "title": "Extreme q-learning: Maxent rl without entropy"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "LOOP",
        "author": "Sikchi, Harshit and Zhou, Wenxuan and Held, David",
        "title": "Learning off-policy with online planning"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "MBOP",
        "author": "Argenson, Arthur and Dulac-Arnold, Gabriel",
        "title": "Model-based offline planning"
      }
    ]
  }
]