\section{Background and Related Work}
\subsection{Neural Code Models}
The success of neural language models in the natural language domain has inspired researchers to apply similar methods to programming languages. 
To alleviate the software engineering workload, a large plethora of research has explored automating SE tasks, such as vulnerability detection~\cite{linevul}, bug-fixing~\cite{bugfixwild}, code translation~\cite{codexglue}, code clone detection~\cite{mou2016} and code summarization~\cite{iyer2016summarizing}. 
Specifically, the techniques involve training neural language models on data from public repositories such as GitHub and Stack Overflow~\cite{codet5}.
Leveraging the naturalness properties of human written code, these neural code models have learned useful patterns that unlock their potential as practical software development assistants~\cite{assetorliability}.

\subsection{Curriculum Learning}

Replicating the pedagogical learning process of humans, CL is a training strategy that gradually increases the difficulty of examples presented to the model~\cite{clbengio}, which contrasts with the conventional unordered training schedule.
CL has been effective for a wide range of model architectures and tasks~\cite{curricnn,curricsurvey}. 
It improves model performance on complex examples by aligning training schedules with the model's skill-acquiring pace~\cite{curricnmt}.
Using generated programs, Na√Ør et al.~\cite{curriccode} investigated the effects of CL in code completion, whilst Liu et al.~\cite{liu-etal-2023-code} focused on the task of code execution in competitive programming.
Although conventional difficulty measures such as length and cyclomatic complexity were investigated, these studies focused on synthetic programming problems, which may not generalise to real-world software.
In terms of real-world SE, CL has been employed in tasks, such as code clone detection, code search~\cite{wangcl} and automated program repair~\cite{apr_cl}, however, the methods largely focused on augmenting code to create difficult synthetic examples.
Additionally, past studies mainly focused on the final result, rather than investigating how the code model improves during CL, leaving us with an opaque understanding of the process.
Past studies have also yet to investigate the code-to-text task of code summarization.