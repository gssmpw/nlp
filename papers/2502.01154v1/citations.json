[
  {
    "index": 0,
    "papers": [
      {
        "key": "Shen2023DoAN",
        "author": "Xinyue Shen and Zeyuan Johnson Chen and Michael Backes and Yun Shen and Yang Zhang",
        "title": "\"Do Anything Now\": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "Shen2023DoAN",
        "author": "Xinyue Shen and Zeyuan Johnson Chen and Michael Backes and Yun Shen and Yang Zhang",
        "title": "\"Do Anything Now\": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models"
      },
      {
        "key": "Shah2023ScalableAT",
        "author": "Rusheb Shah and Quentin Feuillade--Montixi and Soroush Pour and Arush Tagade and Stephen Casper and Javier Rando",
        "title": "Scalable and Transferable Black-Box Jailbreaks for Language Models via Persona Modulation"
      },
      {
        "key": "Wei2023JailbrokenHD",
        "author": "Alexander Wei and Nika Haghtalab and Jacob Steinhardt",
        "title": "Jailbroken: How Does LLM Safety Training Fail?"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "Zou2023UniversalAT",
        "author": "Andy Zou and Zifan Wang and J. Zico Kolter and Matt Fredrikson",
        "title": "Universal and Transferable Adversarial Attacks on Aligned Language Models"
      },
      {
        "key": "Guo2021GradientbasedAA",
        "author": "Chuan Guo and Alexandre Sablayrolles and Herv'e J'egou and Douwe Kiela",
        "title": "Gradient-based Adversarial Attacks against Text Transformers"
      },
      {
        "key": "Shin2020ElicitingKF",
        "author": "Taylor Shin and Yasaman Razeghi and Robert L Logan IV and Eric Wallace and Sameer Singh",
        "title": "Eliciting Knowledge from Language Models Using Automatically Generated Prompts"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "Alon2023DetectingLM",
        "author": "Gabriel Alon and Michael Kamfonas",
        "title": "Detecting Language Model Attacks with Perplexity"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "Liu2023AutoDANGS",
        "author": "Xiaogeng Liu and Nan Xu and Muhao Chen and Chaowei Xiao",
        "title": "AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "Yu2023GPTFUZZERRT",
        "author": "Jiahao Yu and Xingwei Lin and Zheng Yu and Xinyu Xing",
        "title": "GPTFUZZER: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "Chao2023JailbreakingBB",
        "author": "Patrick Chao and Alexander Robey and Edgar Dobriban and Hamed Hassani and George J Pappas and Eric Wong",
        "title": "Jailbreaking Black Box Large Language Models in Twenty Queries"
      },
      {
        "key": "Mehrotra2023TreeOA",
        "author": "Anay Mehrotra and Manolis Zampetakis and Paul Kassianik and Blaine Nelson and Hyrum Anderson and Yaron Singer and Amin Karbasi",
        "title": "Tree of Attacks: Jailbreaking Black-Box LLMs Automatically"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "Wei2022ChainOT",
        "author": "Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Ed Huai-hsin Chi and F. Xia and Quoc Le and Denny Zhou",
        "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"
      },
      {
        "key": "Yao2023TreeOT",
        "author": "Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik Narasimhan",
        "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "Wei2023JailbreakAG",
        "author": "Zeming Wei and Yifei Wang and Yisen Wang",
        "title": "Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations"
      },
      {
        "key": "AnilManyshotJ",
        "author": "Cem Anil and Esin Durmus and Mrinank Sharma and Joe Benton and Sandipan Kundu and Joshua Batson and Nina Rimsky and Meg Tong and Jesse Mu and Daniel Ford and Francesco Mosconi and Rajashree Agrawal and Rylan Schaeffer and Naomi Bashkansky and Samuel Svenningsen and Mike Lambert and Ansh Radhakrishnan and Carson E. Denison and Evan Hubinger and Yuntao Bai and Trenton Bricken and Tim Maxwell and Nicholas Schiefer and Jamie Sully and Alex Tamkin and Tamera Lanham and Karina Nguyen and Tomasz Korbak and Jared Kaplan and Deep Ganguli and Samuel R. Bowman and Ethan Perez and Roger Grosse and David Kristjanson Duvenaud",
        "title": "Many-shot Jailbreaking"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "Brown2020LanguageMA",
        "author": "Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeff Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Ma-teusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei",
        "title": "Language Models are Few-Shot Learners"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "Paulus2024AdvPrompterFA",
        "author": "Anselm Paulus and Arman Zharmagambetov and Chuan Guo and Brandon Amos and Yuandong Tian",
        "title": "AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs"
      },
      {
        "key": "Xie2024JailbreakingAA",
        "author": "Zhihui Xie and Jiahui Gao and Lei Li and Zhenguo Li and Qi Liu and Lingpeng Kong",
        "title": "Jailbreaking as a Reward Misspecification Problem"
      },
      {
        "key": "Basani2024GASPEB",
        "author": "Advik Raj Basani and Xiao Zhang",
        "title": "GASP: Efficient Black-Box Generation of Adversarial Suffixes for Jailbreaking LLMs"
      },
      {
        "key": "Wang2024DiffusionAttackerDP",
        "author": "Hao Wang and Haotao Li and Junda Zhu and Xinyuan Wang and Chengwei Pan and Minlie Huang and Lei Sha",
        "title": "DiffusionAttacker: Diffusion-Driven Prompt Manipulation for LLM Jailbreak"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "Alon2023DetectingLM",
        "author": "Gabriel Alon and Michael Kamfonas",
        "title": "Detecting Language Model Attacks with Perplexity"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "Wei2023JailbreakAG",
        "author": "Zeming Wei and Yifei Wang and Yisen Wang",
        "title": "Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "Robey2023SmoothLLMDL",
        "author": "Alexander Robey and Eric Wong and Hamed Hassani and George J. Pappas",
        "title": "SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "Zhou2024RobustPO",
        "author": "Andy Zhou and Bo Li and Haohan Wang",
        "title": "Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "Sadasivan2024FastAA",
        "author": "Vinu Sankar Sadasivan and Shoumik Saha and Gaurang Sriramanan and Priyatham Kattakinda and Atoosa Malemir Chegini and Soheil Feizi",
        "title": "Fast Adversarial Attacks on Language Models In One GPU Minute"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "Paulus2024AdvPrompterFA",
        "author": "Anselm Paulus and Arman Zharmagambetov and Chuan Guo and Brandon Amos and Yuandong Tian",
        "title": "AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs"
      }
    ]
  }
]