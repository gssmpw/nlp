\section{Introduction}
\label{sec:Intro}
Mobile devices are integral to our daily lives, with users frequently relaunching and running various applications to meet their diverse needs~\cite{lebeck2020end, low-end2, deng2019measuring}. To fulfill user expectations of seamless and rapid application relaunch, mobile systems preserve all execution-related data (called \emph{anonymous data} in Linux~\cite{anonymous}), such as stack and heap, in main memory. This practice, known as \emph{keeping applications alive in the background}~\cite{kim2019ezswap, bergman2022znswap, lebeck2020end, son2021asap, end2024more},
enables faster relaunches. However, it also results in significant main memory capacity requirements for each application. 

As the demand for memory capacity in mobile applications grows and the number of applications running simultaneously increases,  available memory is becoming an increasingly scarce resource on mobile devices~\cite{liang2020acclaim, son2021asap, end2024more, lebeck2020end}.
When memory capacity pressure is high, current mobile systems use a \emph{RAM-based compressed swap scheme} (called \emph{ZRAM}~\cite{zram1,zram2}) to compress unused anonymous data into a specific memory region, called \emph{zpool}~\cite{zpool}, rather than directly swapping the data into secondary storage (i.e., NAND flash memory). This approach achieves shorter application relaunch latency because decompression is much faster than swapping data from secondary storage into main memory and relaunching terminated applications.

We observe that the state-of-the-art \emph{ZRAM} scheme still prolongs relaunch latency and wastes CPU time due to two major reasons. First, it does not differentiate between hot and cold data, resulting in frequent and unnecessary compression and decompression. Systems might compress hot data when an application is in the background and decompress it when brought back to the foreground, even though enough memory space is available. The unnecessary compression and decompression not only prolongs application relaunch times but also wastes CPU resources. Second, it does not take advantage of different compression chunk sizes and data locality, leading to long compression and decompression times during application relaunch. As users typically switch between applications more than 100 times daily~\cite{deng2019measuring}, these frequent long-latency relaunches can negatively impact the overall user experience on mobile devices~\cite{predict1, predict2, predict3, context-aware, ubcomp6, ubcomp21, ubcomp23, ubcomp34, context, predict-privacy1, predict-privacy2, predict-privacy3, mobisysfastapp}.

The \textbf{goal} of this work is to minimize application relaunch latency and reduce wasted CPU  usage while maximizing the number of live background applications for an enhanced user experience.
To achieve this goal, we characterize the anonymous data of real mobile applications used on a real modern mobile phone (i.e., Google Pixel 7~\cite{Pixel7}). Our experimental characterization yields three new observations. First, we classify anonymous data into three categories: i) Hot data, used during relaunch and impacting relaunch latency; ii) Warm data, potentially used during application execution after relaunch; and iii) Cold data, usually not used again. We observe that hot data is usually similar between consecutive relaunches.
Second, when compressing the same amount of anonymous data, small-size compression, which involves compressing data in smaller chunks, is very fast, while large-size compression achieves a better compression ratio.
Third, there is locality in data access in \emph{zpool} when swapping in anonymous data during application relaunch, meaning the data tends to be stored in contiguous or nearby memory locations in \emph{zpool}. Thus, we can predict the next set of data to be used at the beginning of a relaunch.

Based on these observations, we propose a new hotness-aware and size-adaptive compressed swap scheme for mobile devices, called \proposal, that incorporates \textbf{three key techniques}:
First, a low-overhead hotness-aware data organization scheme aims to separate hot and cold data. \proposal tries to maintain hot data and compressed warm data in main memory while swapping compressed cold data to secondary storage.
Second, a size-adaptive compression scheme takes advantage of different compression chunk sizes. It uses small-size compression for identified hot and warm data to ensure fast relaunch and execution, while using large-size compression for cold data to achieve a high compression ratio.
Third, a proactive decompression scheme predicts the next set of data to be used and performs decompression in advance for such data, further mitigating the negative impact of data swapping back into main memory and decompression latency on application relaunch.


We implement and evaluate \proposal on a commercial smartphone,
Google Pixel 7~\cite{Pixel7} with the latest Android 14 operating system~\cite{Android14}.
We test \proposal with over 30 combinations of commonly-used concurrently-running mobile applications. Our experimental evaluation results show that, on average, \proposal reduces application relaunch latency by 50\% and decreases the CPU usage of compression and decompression procedures by 15\% compared to the state-of-the-art compressed swap scheme for mobile devices.

This work makes the following key contributions:
\begin{itemize}
    \item We are the first to quantitatively demonstrate the inefficiency of the state-of-the-art compressed swap scheme in mobile systems, highlighting its long application relaunch latency and high CPU usage, and identifying the root causes of these problems.  
    \item We make three new observations from real mobile applications. First, data used during application relaunch is usually similar between consecutive relaunches. Second, when compressing the same amount of anonymous data, small-size compression is very fast, while large-size compression achieves a better compression ratio. Third, there is locality in data access when swapping in anonymous data during application relaunch.
    \item We propose a new hotness-aware and size-adaptive compressed swap scheme, \proposal, for mobile devices. This scheme incorporates three key techniques: low-overhead hotness identification, size-adaptive compression, and proactive and predictive decompression.
    \item We evaluate \proposal on a real smartphone with a cutting-edge Android operating system. Our evaluation results show that our solution surpasses the state-of-the-art in terms of both application relaunch latency and CPU usage. To foster further research in the design and optimization of mobile compressed swap techniques, we open-source our implementations at https://github.com/CMU-SAFARI/Ariadne.
\end{itemize}






