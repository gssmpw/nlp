\section{Evaluation Methodology}
\label{sec:evaluation}

\noindent\textbf{Experimental platform.} 
We implement and evaluate \proposal on a real commercial smartphone,
Google Pixel 7~\cite{Pixel7} with the latest Android 14 operating system~\cite{Android14}.
We list the detailed real system configuration in Table~\ref{tab:phones}.

\begin{table}[h!]
\centering
\caption{Experimental Platform Configuration.}
\footnotesize
\begin{tabular}{c|c|c}
\hline
\textbf{Name} & \textbf{System}& \textbf{Memory \& Storage} \\ \hline
\hline
 & CPU: 8 cores  & 12GB DRAM\\
Google  &2x 2.85 GHz Cortex-X1 ~\cite{dempsey2021reviews} \& &\\
Pixel 7 &2x 2.35 GHz Cortex-A78 ~\cite{al2023comparative} \& & 128GB flash\\
&4x 1.8 GHz Cortex-A55~\cite{seo2020optimized} & \\
& Android: 14; Linux 5.10.157~\cite{Android14} & UFS3.1\\
\hline
\end{tabular}
\label{tab:phones}
\end{table}

\noindent\textbf{Workloads.}
We execute ten %selected 
popular applications (Twitter, YouTube, TikTok, Edge, Firefox, Google Earth, Google Maps, BangDream, Angry Birds, and TwitchTV) via MonkeyRunner~\cite{monkey} to collect mobile workload traces.\footnote{Recent studies~\cite{liang2020acclaim, liang2022cachesifter} show that mobile users often run more than eight applications concurrently.}
Using mobile workload traces makes our methodology and results reproducible, as opposed to running real applications that execute differently for each different test. We use the collected traces for both insight analysis and final evaluation results. For example, we use the collected page data in traces as the input of compression and decompression algorithms for both the state-of-the-art \emph{ZRAM} scheme and \proposal. This allows us to reproducibly and consistently compare their compression latency, decompression latency, and compression ratio.
A trace is composed of the page frame number (PFN),  \emph{ZRAM} sector, source application number (UID), and page data that needs to be compressed, swapped-in or swapped-out.
We create \emph{ten} traces. Our procedure for creating each trace is as follows. First, for each trace, we select a target application out of ten applications to launch and execute. Second, we put the target application in the background and launch the other nine applications. To capture more information across various usage scenarios, we launch the nine applications in different orders, creating several (e.g., three) distinct usage scenarios for each target application. Third, we relaunch the target application to collect its relaunch information.

To prevent interference during each trace creation and ensure the reproducibility of our methodology, we perform the following three actions for each trace collection: i) we close all applications and clear their cache files before rebooting the smartphone to eliminate the impact of old cache files, ii) after rebooting the smartphone, we clean the cache again to eliminate the impact of potentially buffered data in main memory, and iii) we use the same applications with the same user account and perform the same sequence of activities using an auto-testing script via MonkeyRunner~\cite{monkey} to avoid human bias.

To foster further research in the design and optimization of mobile compressed swap techniques, we open-source all our source code, traces, and scripts at https://github.com/CMU-SAFARI/Ariadne.



\noindent\textbf{Evaluated Schemes.} We evaluate two compressed swap schemes:
\noindent\textbf{ 1)} \emph{ZRAM}~\cite{zram1, zram2, new-zram, merge-zram}, which is the state-of-the-art compressed swap scheme used in modern Android systems. ZRAM employs Least Recently Used (LRU)~\cite{LRU} as the default policy for selecting data to compress. With LRU, the system selects the least recently used pages for compression. Modern Android systems optimize memory page organization by grouping data based on the associated application. This solution only supports single-page-size (i.e., 4KB) compression to avoid potential penalties (as discussed in Section~\ref{sec:compress}) and does  \emph{not} allow data to be decompressed \emph{before} it is required by the system, avoiding memory capacity waste and unnecessary CPU usage if the decompressed data will not be used.

\noindent\textbf{2)} Different versions of \proposal, which is our proposed compressed swap scheme. We evaluate \proposal under different configurations, whose parameters are shown in Table~\ref{table:3}.
$S$ represents the size of  \emph{zpool}, which is set to 3GB. This parameter determines the maximum number of compressed pages that can be stored in  \emph{zpool} and consequently affects user experience in two ways: 1) The size of \emph{zpool} impacts the number of writes to the NAND flash memory 
and its overall lifetime, and 2) it affects the relaunch-related data placement, thereby impacting application relaunch latency.
$Small Size$, $Medium Size$, and $Large Size$ represent the compression chunk sizes for hot list, warm list, and cold list, respectively. They serve as inputs for compression algorithms and affect both the compression ratio and compression latency. We denote these size configurations as $Small Size$\--$Medium Size$\--$Large Size$ (e.g., 1K-2K-16K) for each version of \proposal in Section~\ref{sec:evel}.


\begin{table}[h!]
\vspace{0.5em}
\centering
\caption{Summary of parameters used by \proposal.}
\label{table:3}
\footnotesize
\begin{tabular}{c|c|c}
  \hline
  \textbf{Parameter}          & \textbf{ Description} & \textbf{Setting (B)} \\  \hline \hline
  $S$ & Size of ZRAM partition& 3G \\  \hline 
  $Small Size$ & Compression chunk size for hot list & 256,512,1K \\  \hline
  $Medium Size$ & Compression chunk size for warm list & 2K,4K \\  \hline
  $Large Size$ & Compression chunk size for cold list & 16K,32K \\  \hline
\end{tabular}
\end{table}

During an application relaunch, the system fetches all the launch-related data into main memory. In the optimal case, all data resides in main memory (DRAM). In other scenarios, we consider two situations: i) where data in the \emph{hot} list is in main memory while other data is in either \emph{ZRAM} or flash memory-based swap space, and ii) where all data needs to be read from either \emph{ZRAM} or flash memory-based swap space. The first scenario excludes hot list data from compression and decompression operations, and the second scenario applies compression and decompression on data in all lists. We abbreviate these two scenarios as EHL (exclude hot list) and AL (all lists).




\noindent\textbf{Evaluated Metrics.}
We evaluate \proposal using three major sets of metrics.
First, we assess the impact of \proposal on factors that influence user experience, including application relaunch latency and the CPU usage due to compression and decompression.
Second, we analyze the auxiliary metrics, including compression/decompression latency, compression ratio, and the accuracy and coverage of data hotness level identification.
Third, we analyze memory capacity and CPU usage associated with our full \proposal implementation (not just compression/decompression).