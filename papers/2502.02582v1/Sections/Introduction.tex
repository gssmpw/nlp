% INTRO STARTS HERE

A core objective of materials science is the discovery of new synthesizable structures and compounds with the potential to meet critical societal demands.
The development of new materials such as room-temperature superconductors \citep{boeri_2021_2022}, high-performance alloys with exceptional mechanical properties \citep{gludovatz_fractureresistant_2014, gludovatz_exceptional_2016, george_highentropy_2019}, advanced catalysts \citep{strmcnik_design_2016, nakaya_catalysis_2023}, and materials for energy storage and generation \citep{liu_advanced_2010, snyder_complex_2008} hold the potential to drive technological revolutions.

% A core objective of materials science is the discovery of new synthesizable structures and compounds with the potential to meet critical societal demands.
% % Throughout history, materials such as bronze or steel emerged through thousands of years of experimentation, catalyzing technological breakthroughs at the time of their discovery.
% % Today, next-generation materials -- including room-temperature superconductors \cite{boeri_2021_2022}, high-performance alloys with exceptional mechanical properties \cite{gludovatz_fractureresistant_2014, gludovatz_exceptional_2016, george_highentropy_2019}, advanced catalyst materials \cite{strmcnik_design_2016, nakaya_catalysis_2023}, and materials for energy storage and generation \cite{liu_advanced_2010, snyder_complex_2008} -- hold similar revolutionary potential.
% Historically, materials have been the hidden force behind technological revolutions. For instance, bronze and steel emerged through millennia of experimentation, defining entire epochs of human civilization. As scientific understanding advanced, the pace of such discoveries accelerated dramatically, from millennia to centuries. In the 20th century, silicon---a material virtually unknown just a century earlier---catalyzed the semiconductor revolution, laying the foundation for modern computing and telecommunication. 
% Today, the development of new materials spans decades, but artificial intelligence (AI) is poised to dramatically accelerate this process, potentially driving technological revolutions at an unprecedented pace. In particular, next-generation materials---including room-temperature superconductors \cite{boeri_2021_2022}, high-performance alloys with exceptional mechanical properties \cite{gludovatz_fractureresistant_2014, gludovatz_exceptional_2016, george_highentropy_2019}, advanced catalysts \cite{strmcnik_design_2016, nakaya_catalysis_2023}, and materials for energy storage and generation \cite{liu_advanced_2010, snyder_complex_2008}---hold such revolutionary potential.

% Throughout the 20\textsuperscript{th} century, computational methods built upon advances in crystallography and density functional theory, which allowed for extraction of a crystal's structure and from that, the calculation of its properties.
% With 21\textsuperscript{st} century advances in computational resources and methods, the inverse question can be explored: for properties of interest such as stability, can we design new materials?
% \zs{Shall we put the 3rd and 4th paragraphs in a separate section for Related Works? We don't seem to have one. These two paragraphs can be the first subsection - Traditional Methods. The second subsetion will be generaetive modeling methods.}
% % A material structure and composition collectively determine its electronic, optical, and mechanical properties, which in turn define its functionality.
% Exploring the vast compositional and structural landscape of multicomponent materials with novel properties is essential, yet exhaustive experimental screening is infeasible \cite{cantor_multicomponent_2021}. Quantum and classical molecular simulation offer a powerful alternative, enabling a more targeted and efficient exploration.
% % Decades of computational advancements have been instrumental in enabling the accurate prediction of material structures and properties, driving progress in materials discovery. \ph{Since our introduction is quite long, we could maybe just cut the previous paragraph.}
% In recent decades, both experimental \cite{potyrailo_combinatorial_2011, maier_early_2019} and computational \cite{jain_highthroughput_2011, curtarolo_highthroughput_2013} high-throughput pipelines have led to a proliferation of databases for materials' crystal structures \cite{bergerhoff_inorganic_1983, mehl_aflow_2017} and simulations \cite{blaiszik_materials_2016, vita_colabfit_2023, fuemmeler2024advancing}. These advances have already facilitated the development of more accurate machine-learned interatomic potentials \cite{batzner_e3equivariant_2022, batatia_mace_2022, chen_universal_2022}.

% % inverse design of novel compositions and their stable structures, however, has become significantly more tractable through the application of machine-learning methods \cite{butler_machine_2018, schmidt_recent_2019}.
% Still, efficiently sampling the manifold of stable materials structures under diverse constraints---such as composition and target properties---remains a major challenge. Traditional approaches to materials discovery have relied on first-principles electronic structure methods such as DFT---or higher levels of theory, depending on the property \cite{booth2013towards, PhysRevB.89.205427, PhysRevB.102.045146}---which, while powerful and fairly accurate, are very computationally expensive. These methods include \textit{ab initio} random structure searching (AIRSS) \cite{pickard_initio_2011} or genetic algorithms for structure and phase prediction \cite{tipton_grand_2013}, both of which have successfully predicted new crystal structures, some of which have even been experimentally realized \cite{oganov_structure_2019}.
% %Genetic Algorithm for Structure and Phase prediction
% However, the high computational cost of these approaches has limited the scope and speed of material exploration, highlighting the need for cutting-edge ML techniques to significantly accelerate the discovery of stable inorganic crystalline materials.

% \subsection{Generative modeling of inorganic materials}

% \mm{add writing for these references}
% SchNet \cite{schutt_schnet_2018}
% GemNet \cite{gasteiger_gemnet_2024}
% CrystalGAN \cite{nouira_crystalgan_2019}

% A material structure and composition collectively determine its electronic, optical, and mechanical properties, which in turn define its functionality.
Exploring the vast compositional and structural landscape of multicomponent materials with novel properties is essential, yet exhaustive experimental screening is infeasible \citep{cantor_multicomponent_2021}. Quantum and classical molecular simulation offer a powerful alternative, enabling a more targeted and efficient exploration.
% Decades of computational advancements have been instrumental in enabling the accurate prediction of material structures and properties, driving progress in materials discovery. \ph{Since our introduction is quite long, we could maybe just cut the previous paragraph.}
In recent decades, both experimental \citep{potyrailo_combinatorial_2011, maier_early_2019} and computational \citep{jain_highthroughput_2011, curtarolo_highthroughput_2013} high-throughput pipelines have led to a proliferation of materials databases for crystal structures \citep{bergerhoff_inorganic_1983, mehl_aflow_2017} and simulations \citep{blaiszik_materials_2016, vita_colabfit_2023, fuemmeler2024advancing}. These advances have already facilitated the development of more accurate machine-learned interatomic potentials \citep{batzner_e3equivariant_2022, batatia_mace_2022, chen_universal_2022}.
%\looseness=-1

% inverse design of novel compositions and their stable structures, however, has become significantly more tractable through the application of machine-learning methods \cite{butler_machine_2018, schmidt_recent_2019}.
Still, efficiently sampling the manifold of stable materials structures under diverse constraints---such as composition and target properties---remains a major challenge. Traditional approaches to materials discovery have relied on first-principles electronic structure methods such as DFT---or more sophisticated theory, depending on the property \citep{booth2013towards, PhysRevB.89.205427, PhysRevB.102.045146}---which, while powerful and fairly accurate, are very computationally expensive. These methods include \textit{ab initio} random structure searching (AIRSS) \citep{pickard_initio_2011} or genetic algorithms for structure and phase prediction \citep{tipton_grand_2013}, both of which have successfully predicted new crystal structures and some of which have even been experimentally realized \citep{oganov_structure_2019}.
%Genetic Algorithm for Structure and Phase prediction
However, the high computational cost of these approaches has limited the scope and speed of material exploration, highlighting the need for cutting-edge ML techniques to significantly accelerate the discovery of stable inorganic crystalline materials.

\subsection{Related works}

Recent advances in machine learning techniques have generated significant interest in applying data-driven approaches for inorganic materials discovery. Among these, Graph Networks for Materials Exploration (GNoME) has demonstrated remarkable success by coupling coarse sampling strategies for structure and composition with AIRSS that leverages a highly accurate machine-learned interatomic potential (MLIP) to predict material stability, leading to the identification of millions of new candidate crystal structures~\citep{merchant_scaling_2023}. 
% GNoME integrates the MLIP within an active learning framework, combining it with two complementary sampling strategies to identify promising structures: one perturbs existing crystal structures to generate viable candidates, while the other explores novel compositions, which are subsequently evaluated using ab initio random structure searching (AIRSS). 
% This combined approach enhanced the efficiency of structure and composition exploration, pushing the boundaries of computational materials discovery.
%Approaches such as Graph Networks for Materials Exploration (GNoME) have shown great promise by predicting millions of new compounds and using AIRSS for relaxing to a stable structure \cite{merchant_scaling_2023}.
Other frameworks have approached the generation of composition and structure jointly through fully ML-based methods. Crystal Diffusion Variational Autoencoder (CDVAE) leverages variational autoencoders and a graph neural network representation to sample new crystal structures from a learned latent space \citep{xie_crystal_2022}. To date, state-of-the-art performance in both crystal structure prediction for given compositions and \emph{de novo} generation of novel stable materials has been achieved by diffusion models such as DiffCSP \citep{jiao_crystal_2023} and MatterGen \citep{zeni_generative_2025}, as well as conditional flow-matching frameworks such as FlowMM \citep{miller_flowmm_2024}. 

While these approaches have demonstrated that ML can push the boundaries of computational materials discovery, it remains uncertain whether score-based diffusion or flow-matching represent the definitive methodological frameworks for this problem. Furthermore, the extent to which the optimal approach depends on the training data remains an open question. Thus far, each new method has typically outperformed its predecessors across datasets.

%For other types of materials, such as molecular crystals, models perform sequence prediction with recurrent neural networks (RNNs) or use reinforcement learning to sequentially build crystal or molecular structures \cite{sanchez-lengeling_inverse_2018}. 

%Similarly, as discussed above, frameworks like Riemannian flow-matching are designed to imbue the learned generative process with respect to certain geometries \cite{lipman_flow_2024}.

%Generative model $\supset$ Flows $\supset$ Flow Matching $\supset$ Diffusion model

%Flows can be considered a subset of possible Generative model and Flow matching is one of the subset of Flow methods, with Diffusion models being a special case of Flow matching. We provide a generalized framework...
%Here we write some sentences about how flow models and diffusion models are just subsets of a broader framework called stochastic interpolants. We foreshadow the explanations we are about to provide and discuss why this is an exciting advance. We cite other papers that have extended stochastic interpolants to similar problems  and we highlight how freaking cool it is that we did this for materials which has never been done before.


\subsection{Our contribution}

The work we present in this paper is the first implementation and extension of the stochastic interpolants (SIs) framework \citep{albergo_stochastic_2023} for the modeling and generation of inorganic crystalline materials. SIs are a unifying framework that encompasses both flow-based and diffusion-based methods as specific instances, while offering a more general and flexible framework for generative modeling. In this context, SIs define a stochastic process that interpolates between pairs of samples from a known base distribution and a target distribution of inorganic crystals. By learning the drift terms of either ordinary differential equations (ODEs) or stochastic differential equations (SDEs), new samples can be generated by numerically integrating these equations. The flexibility of the SI framework stems from the ability to tailor the choice of interpolants, and the incorporation of an additional random latent variable, further enhancing its expressivity. With their many degrees of freedom, SIs thus provide an ideal framework for optimizing generative models for materials design.

%While related approaches such as stochastic flow-matching have been %applied to problems such as prediction of protein backbones \cite{bose_se3stochastic_2024}, stochastic interpolants feature a much more flexible means of generative modeling.
%The stochastic interpolant framework is an ideal choice for its many tunable degrees of freedom in both interpolation path as well as amount of stochasticity; it can also reproduce both conditional flow matching and score-based diffusion under specific conditions.

We implement the SI framework in the open-source Open Materials Generation (OMG) package, released alongside this paper. OMG allows to train and benchmark models for two materials generation tasks: \emph{Crystal structure prediction} (CSP) which only learns to generate atomic positions and lattice vectors for a given composition, and \emph{de novo generation} (DNG) which learns to generate both crystal structure and composition to predict novel materials. 
% This framework provides a versatile and scalable platform for advancing generative modeling in materials discovery.
We discover that optimizing interpolation schemes for different degrees of freedom---particularly fractional coordinates in the crystal representation---substantially improves performance across diverse datasets. As a result, our approach achieves a new state of the art---outperforming both DiffCSP \citep{jiao_crystal_2023} and FlowMM \citep{miller_flowmm_2024}---in CSP and DNG across all evaluated datasets for both existing, revised, and new performance measures.
% In our ground-up implementation of OMG, we refine existing evaluation metrics that were originally established by CDVAE and later adopted by DiffCSP and FlowMM, while also introducting additional performance measures.
%Moreover, OMG achieves comparable or better performance compared to the most recently released MatterGen model~\cite{mattergen_microsoft_2025}.
% While we were unable to perform a direct comparison with MatterGenâ€™s reported values for DNG---since they performed relaxations by DFT---our results appear to be either comparable (S.U.N. rate) or significantly better (RMSD). \mm{let's wait for GOD model}