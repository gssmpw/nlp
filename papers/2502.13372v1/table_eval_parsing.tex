\begin{table}[t]
% \small
\footnotesize
% \scriptsize
\centering
\resizebox{\linewidth}{!}{%
\begin{tabular}{lccccc}
\toprule
\multirow{2}{*}{\begin{tabular}[l]{@{}c@{}}\dslname{} program\\synthesis method\end{tabular}} & \multicolumn{5}{c}{Prompt Type}                     \\ \cline{2-6}
                                 & \begin{tabular}[c]{@{}c@{}}Single\\atomic\end{tabular} & \begin{tabular}[c]{@{}c@{}}Spatially\\relative\end{tabular} & \begin{tabular}[c]{@{}c@{}}Temporally\\relative\end{tabular} & \begin{tabular}[c]{@{}c@{}}Spatio-\\temporally\end{tabular}  & \multicolumn{1}{|l}{Overall} \\
\hline
LLM-based                 & \textbf{96.5\%}   & \textbf{97.1\%}            & \textbf{97.7\%}            & \textbf{90.9\%} & \multicolumn{1}{|l}{\textbf{95.1\%}}    \\
Semantic Parser                & 87.1\%   & 86.3\%            & 92.4\%            & 76.8\% & \multicolumn{1}{|l}{84.7\%}    \\
\bottomrule
\end{tabular}%
}
\caption{
Success rate for our LLM-based \dslname{} program synthesizer and a baseline semantic parser.
% \maneesh{Maybe move rest of paragraph to table caption.}
We determine the success rate by first computing the string difference
between the LLM synthesized \dslname{} program and the corresponding ground truth
program. We count a success only when there is no difference.
%
We note that requiring a perfect string match is a 
stringent test for success as the underlying semantics of
the two programs may match even without an exact string match.
%
%We leave a looser comparison (e.g. at the level of AST matching) to
%future work.
}
% \vspace{-3em} %% commented out for arxiv
\label{tab:eval_parsing}
\end{table}
