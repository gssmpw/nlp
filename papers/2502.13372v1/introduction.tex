\section{Introduction}
\label{sec:introduction}

\maneesh{We need to decide what the main contributions of this work are. I don't think they are really
  about motion graphics -- that happens to be the domain and is important, but far more important are the
  ideas of using semantic parsing to do program verification of LLM generated motion graphics code. We need
  to put together a title that reflects the contributions and focus the paper from the beginning on the main
  problem we are solving and our corresponding contributions.}

% \maneesh{I think we need to open the introduction by talking about
% the problem we are trying to solve -- converting natural language
% descriptions of animation into motion graphics animations. The first
% paragraph(s) should motivate why this is an important problem and
% very quickly say that researchers have developed strategies for
% doing this in other domains. I wouldn't mention KeyFramer and
% LogoMotion here as those are not the major pubs in this direction of
% work. Those can come in related work. End by explaining that we are
% following in this line of work using an LLM to convert from natural
% language to motion graphics programs.}  what is motion graphics
Motion graphics is a type of animation widely used in advertising,
user interfaces, and digital storytelling.
% current approaches, why bad
Recent text-to-animation generation approaches~\cite{gal2024breathing,
  luo2023videofusion, chen2024videocrafter2, wang2023modelscope} have
made it possible to generate animations in a frame-by-frame
representation from natural language descriptions.
% program approach good, 
However, editing these low-level sequences of pixels and frames can be
tedious and time consuming.  In contrast, prior
work~\cite{zhang2023motion} has demonstrated that representing motion
graphics animations as objects and motions offer many advantages, such
as meaningful abstractions closely aligned with human cognition and
flexible and precise control parameters.
\maneesh{Not sure what the main point of this paragraph is. I think it is far too focused on Motion Graphics and not enough on the problem we are really aiming to solve -- program verification.}

% in other domains, what other people have done
Existing techniques have explored synthesizing programs from natural
language prompts for other visual tasks;
SceneCraft~\cite{hu2025scenecraft} uses large language models (LLMs)
to create 3D scenes as Blender programs, while
VISPROG~\cite{gupta2023visprog} and
ViperGPT~\cite{surismenon2023vipergpt} prompt LLMs to generate
programs in domain specific languages (DSL) for visual question
answering tasks.  We adopt this line of work to use an LLM as a
synthesizer to produce motion graphics programs from natural language
descriptions.
\maneesh{We don't need to say what others have done in the intro. I think we need to fist say
what problem we are addressing -- namely verification of LLM generated code.}


% \maneesh{This paragraph is very important as it
%   is introducing the key issue we will be solving. We have given the
%   high-level problem in the paragraph 1 -- natural language to motion
%   graphics animation. This paragraph needs to set up the more specific
%   problem of verification of LLM generated animation
%   code. Hallucination is not the same as producing outputs that do not
%   match the user's intentions. In this paper we should focus on the
%   latter, not the former. We don't need to bring in the the prior work
%   in this paragraph. Instead the key thing is to state the specific problem of verification and then directly go to saying what we do in this paper.}
%% our focus of problem
However, solely relying on LLMs to interpret user prompts may produce
outputs that deviate from the intended constraints specified by a user
in the input prompt~\cite{tseng2024keyframer, liu2024logomotion}.
This can result in programs that are syntactically executable but
semantically incorrect or misaligned with user expectations.  For
example, ``translate the circles to the canvas center'' contains a
post-state constraint on the translation motion for the circle
objects, but the animation program generated by the LLM may violate
that constraint (Figure~\ref{fig:teaser}).  To fix this problem, the
user would need to manually inspect the rendered animation and adjust
corresponding parameters in the program.
\maneesh{This paragraph is partly setting up the problem we are addressing, thought it is long and it doesn't
  need to be in contrast to what others have done. It also doesn't introduce the issue of verification. We need to talk about the problem more
  generally. This introduction is focusing too much on prior work. Also we should
  avoid the term ``misalignment''. This is a poorly defined term. }

\maneesh{I think we need one paragraph that introduces the specific
  problem that we are going to focus on (namely verification of LLM
  generated animation) rather than all the text that we have so
  far. Next paragraph can say what we do.}


% \maneesh{This paragraph needs to explain the key idea of how we do verification. Specifically it needs to explain how we use a semantic parser (and say what a semantic parser is) to convert the prompt into first order logic -- combined with the notions of semantics of time. These sentences are going to be very important as they will tell the reader the main ideas/contributions of our verification approach. Need to also say human can be in-the-loop for correction after the verification finds an error. Remove the relationship to prior work here. Intro only needs to reference the most important prior work.}
% \maneesh{Should plan a teaser and what might be included in that. Also how it will be referenced in the introduction.}
%% our work
In our work, we introduce a novel text-to-animation system that
improves LLM-based program synthesis with a program verification
pipeline.
%% synthesis
To generate motion graphics programs, we prompt an LLM with a static
SVG image, documentation of an animation API, and natural language
descriptions of motions.
%% verification DSL
For program verification, we propose a first-order logic (FOL)-based
DSL that uses Neo-Davidsonian event
semantics~\cite{davidson2001logical, parsons1990events} to represent
various motion constraints expressed in the input prompt with a set of
predicates, such as a motion's \texttt{direction} and \texttt{origin}.
% notions of timing
In motion graphics, temporal sequencing of motions is just as
important as how each individual motion is carried out, so we adopt
Allen's interval algebra~\shortcite{allen1983interval} to model the
temporal relationship constraints between any two motions, like
\texttt{precedes(m\_1, m\_2)}.
% give some reason and benefit and example
The modularity and composability of our FOL DSL allow us to model
constraints expressed in complex natural language descriptions of
motions in the form of verification programs by joining constraint
predicates with logical operators (Figure~\ref{fig:teaser})
\maneesh{This paragraph is nice. I think we will need to demonstrate the composability. Two things though. Depending on the first paragraph and title the reader should know that we will be use an LLM to generate the code. This is not a contribution and the sentence on it should be either eliminated or shortened if possible. More importantly, This paragraph doesn't talk about closing the loop and feeding back the verification results to the user for manual correction or to the LLM for LLM-based correction. That is also a critical piece of this system.}

%% semantic parser
In order to produce these verification programs in a reliable,
deterministic manner, we build a rule-based semantic parser that
extracts motions constraints from natural language prompts, instead of
using another LLM~\cite{brown2024large}.
% we can handle conflated expressions
Unlike previous approaches, our parser uses dependency parsing and
fine-tuned text classification models to process prompts that contain
\textit{conflations}, a linguistic phenomenon in which a single
expression adds multiple constraints on a
motion~\cite{talmy1975motion}.  For example, ``expand'' is a single
verb that constraints both the motion \texttt{type} (scaling) and
\texttt{direction} (an increase in size).
%% human in the loop for correction
We execute the verification program against the rendered animation
produced by the animation program to check if all constraints are met
and inform the user with the verification results.  In case of
violations, the user can feed the results back into the LLM for
correction, improving program synthesis results in a human-in-the-loop
manner.
\maneesh{We can decide later if we need the detail on how the verifier work (first two sentences). We don't need to contrast with previous approaches.}

% \maneesh{Needs to end with sentences summarizing the results of our evaluation.}
%% evaluation
To evaluate our work, we first parameterized the space of natural
language descriptions of motions based on Talmy's framework of motion
semantics that categorizes motion into components such as Figure,
Manner, Path, and Ground~\cite{talmy1975motion}.  By generating
prompts across different dimensions of this taxonomy, we assess our
system's ability to produce accurate verification and animation
programs.  We also explore the effectiveness of various LLMs for
program synthesis and evaluate the impact of replacing components of
our deterministic verifier with LLMs.  \jiaju{summarize evaluation
  results} Finally, we demonstrate the expressiveness of our system by
showing a variety of result animations.  \maneesh{We probably need to
  emphasize the evaluation as being a bigger contribution. I don't
  think people have developed good methods for evaluating these tools
  and we should promise release of the test prompts and other things
  (e.g. gold parses, etc.). Should give numbers here about how well we
  perform on these tests and talk about the high-level vs. low-level
  parameterization of the prompts and prompt templates. }

\vspace{0.5em}
\noindent
In summary, we make two main contributions:
\begin{enumerate}
    \item A text-to-animation system that improves LLM-based program
      synthesis with a program verification pipeline that uses a
      semantic parser to convert natural language into verification
      programs with composable FOL-based motion and timing predicates.\maneesh{This should focus on semantic parsing-based verification using FOL and Allen stuff, not on text-to-animation system. Could have a second bullet point automatically looping that back to the LLM -- though we would want to fully automate this loop and check that it either converges or ends with an incorrect program -- we need to do this check anyway.}
    % \maneesh{Should emphasize further the approach to verification with semantic parsing and FOL and notions of timing.}
    \item A taxonomy of natural language prompts describing motions. We use this to show which types of prompts are challenging to LLMs but can be properly processed with our verification pipeline. \maneesh{Need to be more precise about this and its use in the context of evaluating the space of prompts in which our system can work over.}
    % \maneesh{Should better explain why this is important.}
\end{enumerate}


%% ------ introduction v 1.0 ------

%% motivate programs, turn focus to motion graphics
% Programs have been applied in many areas of computer graphics as
% structured, symbolic descriptions of complex visual tasks and
% contents, such as L-systems~\cite{guo2020lsystems} and fractals for
% procedural modeling and the GLSL language~\cite{rost2009glsl} to
% specify shaders.  In the domain of animation, Scalable Vector
% Graphics (SVG)~\cite{svg2} is a widely adopted representation of
% animated 2D vector graphics. Expressing animation as objects and
% motions offer many advantages over working directly with pixels and
% frames, such as meaningful abstractions closely aligned with human
% cognition and flexible and precise control parameters.

%% but writing them manually can be hard, so recent work on LLMs for program synthesis
% Despite these benefits of visual programs, authoring such programs
% manually can be challenging and time-consuming due to their inherent
% complexity and the need for domain expertise.
% %
% The emergence of large language models (LLMs) have enabled the
% possibilities of automatically synthesizing visual programs from
% textual prompts.
% %
% Recent work like VISPROG~\cite{gupta2023visprog} and
% ViperGPT~\cite{surismenon2023vipergpt} prompt LLMs with domain
% specific language (DSL) documentation to generate interpretable
% programs for visual question answering tasks.  Systems like
% KeyFramer~\cite{tseng2024keyframer} and
% LogoMotion~\cite{liu2024logomotion} leverage LLMs to translate natural
% language descriptions into SVG-based animation programs, simplifying
% the design process for motion graphics, a type of 2D animations used
% widely in advertising, animated logos, and digital storytelling.


% %% problem of recent work
% However, current LLM-based systems are susceptible to hallucinations,
% as they may produce outputs that deviate from the intended constraints
% specified by a user in the input prompt.
% This can result in programs that are syntactically executable but semantically incorrect or misaligned with user expectations.
% % prior verification work in image generation
% In the image generation domain, works like TIFA~\cite{hu2023tifa} and
% Davidsonian Scene Graph~\cite{cho2024davidsonian} uses LLMs to
% generate a list of requirements from an image prompt and uses a visual
% language model (VLM) to check if the generated images satisfy this
% list of requirements.


% %% our work
% Inspired by prior work, we introduce a novel text-to-animation system that improves LLM-based program synthesis with program verification.
% %% synthesis
% For program synthesis, we similarly leverage an LLM to generate animation code within a specified animation API. 
% %% verification
% For program verification, we propose a first-order logic (FOL)-based DSL that uses Neo-Davidsonian event semantics~\cite{davidson2001logical, parsons1990events} to represent various motion constraints expressed in the input prompt.
% In contrast to prior work that also uses LLM for verification~\cite{hu2025scenecraft}, we provide a rule-based deterministic semantic parser that converts natural language prompts into a verification program written in our FOL DSL.
% Executing the verification program checks if all constraints are met.
% If any violations are detected, they are automatically fed back into the conversation with the LLM for correction, improving program synthesis results.

%% evaluation
% Our evaluation includes developing a taxonomy of motion prompts based on Talmy's framework of motion semantics that categorizes motion into components such as Figure, Manner, Path, and Ground~\cite{talmy1975motion}.
% By generating prompts across different dimensions of this taxonomy, we assess our system's ability to produce accurate verification and animation programs. 
% We also explore the effectiveness of various LLMs for program synthesis and evaluate the impact of replacing components of our deterministic verifier with LLMs.

% %% summary of contributions
% \vspace{0.5em}
% \noindent
% In summary, we make two main contributions:
% \begin{enumerate}
%     \item A text-to-animation system that combines LLM-based program synthesis with FOL-based program verification.
%     \item A taxonomy of natural language prompts describing motion graphics.
% \end{enumerate}




% Program representations in computer graphics, such as L-system, shader, and SVG.
% producing these programs manually can be difficult, recent work explored synthesizing them with LLMs, such as VISPROG and VIPERGPT to visual qa, and KeyFramer and LogoMotion for text-to-animation.

% However,  because of LLM's hallucination problem, the result can be unpredictably wrong.
% a prompt may contain explicit constraints that the LLM violates.


% In our work, we propose a text-to-animation system wih program synthesis and program verification.
% We use a LLM to synthesis animation program written in a provided animation API
% In the program verification workflow, we parse prompt into a FOL-based verification program that reflects the constraints indicated by the prompt.
% executing the program returns results that show if all the constraints are satsified
% when violations are found, we automatically feed it into the conversation for LLM to fix it.

% To evaluate our work, we first propose a taxonomy of the prompt space.
% We base our taxonomy on Talmy's break down of motion semantics into Figure, Manner, Path, and Ground
% we generate prompts procedurally across different dimensions of the prompt space, and evaluate our system's ability generating correct programs given these prompts
% We evaluate our system with different LLMs for program synthesis, and also swap out differnet components of our deterministic verifier with LLMs.



% Contribution
% System
% Verifier, into program synthesis loop
% The way of performing verification for the animation prompts

% Evaluation
% Parametrized design space of inputs
% Why these are the relevant axes?
% Which part LLM works better? Which part for the verifier?
% Comparisons
% LLM parser
% Swap part of the rule-based parser pipeline


%         - contributions
%             - in the checks that we do and how we communicate the checks into the system
%             - writing checks and use the check results as feedback to the LLM to improve the program generation result
%                 - chooses what to check
%                     - what constraints can be generated from a prompt, and which of those are useful?
%                     - CONTRIBUTION: how much variability can the constraint identifier handle?
%                         - quantify what it can do and what can’t do
%                 - do the checking
%                     - evaluation: is the check api expressive enough?
%                         - “these functions cover large enough functionalities”
%                 - feedback to the program
%     - three parts!

% - evaluation
%     - pair input prompt with a bunch of programs
%         - some of which follows the prompt, some of which violates (parts of) the prompt
%             - EVALUATE: can the constraint finder identify the constraints
%             - EVALUATE: can these constraints be checked properly
%             - EVALUATE: are the constraint checking results helpful in correcting the violations in the original program?




% LocalWords:  GLSL shaders Scalable SVG LLMs VISPROG ViperGPT DSL
% LocalWords:  interpretable KeyFramer LogoMotion LLM TIFA SceneCraft
% LocalWords:  Davidsonian VLM Talmy's verifier allen modularity
% LocalWords:  composability parameterization composable
