\begin{figure*}[t!]
    \centering
    \includegraphics[width=\textwidth]{figs/fig_parser.pdf}
    \caption{
        Our rule-based semantic parser consists of five main steps and serves as a baseline alternative to our LLM-based approach (Section~4 main paper) for converting natural language prompts into \dslname{} programs. 
    }
    \label{fig:parser}
\end{figure*}

\section{Synthetic Test Data Generation}
\label{sec:prompt_generation}
%
%To evaluate our motion graphics synthesis and verification pipeline,
We synthetically generated a test dataset consisting of text prompts
describing an animation, paired with ground truth \dslname{} programs.
%
We include our test dataset in supplemental materials and will release the
dataset along with the scripts for generating it to encourage further
research.
% \maneesh{make sure we do this.}

Our approach is to first define an animation using a scene graph that
explicitly represents each {\em atomic motion} using the seven atomic
motion attributes; {\tt agt, type, dir, mag, orig,
  dur} and {\tt post} (Table~1 main paper). Each atomic motion may also include a reference object and a
reference motion.  From this animation scene graph, we generate a
ground truth \dslname{} verification program by directly converting
each object and atomic motion into \dslname{} predicates.

%% data structure
% \maneesh{Probably don't need to show motion data structures explicitly}
% Here, {\tt mot1} and {\tt mot2} are two such motions
% \vspace{-3mm}
% \setlength{\columnsep}{-1cm}
% \begin{multicols}{2}
% \begin{verbatim}
% mot1 =
% Motion(
%   type = "translate",
%   agent = [obj1],
%   magnitude = 100.0,
%   direction = [0, 1],
%   duration = 0.5,
% )
% \end{verbatim}
% \columnbreak
% \begin{verbatim}
% mot2 =
% Motion(
%   type = "rotate",
%   agent = [obj1],
%   post = ["top", "border"],
%   post_reference = [obj2],
% )
% \end{verbatim}
% \end{multicols}
% \vspace{-3mm}
% \noindent
% Each {\tt obj} variable above is defined using a similar structure for
% object attributes such as {\tt color} and {\tt shape}.

%To add temporal sequencing relations between these motions, we use one
%array to put the motion variables in sequence (e.g. \texttt{[mot\_1,
%    mot\_2]}), and another array to store the timing relations
%(e.g. \texttt{[none, before]} means that \texttt{mot\_1} itself has no
%timing constraints but \texttt{mot\_1} must happen before
%\texttt{mot\_1} with \texttt{before(mot\_1, mot\_2)}).

% templates

We also use the animation scene graph to generate multiple variations
of a natural language text prompt.  Our approach is to use a set of
templates that can describe an atomic motion or objects in
the scene in terms of their attributes.
%
For example, a general template for an atomic motion is {\tt <motion
  type verb>} {\tt <agent object>} {\tt <dir>} {\tt <mag>} {\tt
  <orig>} {\tt <dur>} {\tt <post>}.
%
In English sentences verbs and objects are usually next to one
another, but their ordering can be either verb-object or object-verb.
%
Our sentence-level template for verb-object ordering, uses three
different variations on imperative sentences: (1) ``translate the blue
square'', (2) ``animate the blue square to translate'', and (3) ``make
the blue square translate.''
%
Our template for object-verb ordering, uses present tense with either
active voice (e.g. ``the blue circle translates'') or passive voice
(e.g. ``the blue circle is translated'').
%%
%Our template for object first, then verb, uses present
%tense with either active voice (e.g. ``the blue circle translates'') or
%passive voice (e.g. ``the blue circle is translated'').  
%Our template for 
%verb before object, uses three different variations on
%imperative sentences: (1) ``translate the blue square'', (2) ``animate
%the blue square to translate'', and (3) ``make the blue square
%translate.''
%
For each atomic motion in our scene graph, we choose a sentence-level template
and fill the template parameters by mapping motion attributes
and their values to natural language phrases. 
%
For example, if the value of the \texttt{direction} attribute is
\texttt{[0, 1]} and the motion {\tt type} is ``translation'' we map
the direction to the concept ``up''.
%% variation
To increase variation in the output prompts, we build a dictionary of
synonymous expressions for each such concept sourced from
thesaurus.com, synonym.com, WordNet~\cite{miller1994wordnet}, and
GPT-4o\,\cite{hurst2024gpt}.  For example, for the concept
``up'', we obtain synonymous expressions like ``upward'',
``northward'', ``towards the top'', etc.
%
%
%% Our approach is to consider each atomic motion and manually build
%% a map from the value of 
%% of each
%% its attributes to associated concepts based on its motion type attribute. 
%% %
%% For example, if the value of the \texttt{direction} attribute is ``[0,
%%   1]'' and the motion {\tt type} is ``translation'' we map the
%% direction to the concept ``up''.
%% %
%% For each such concept, we create a dictionary of synonymous expressions
%% sourced from Thesauraus.com, WordNet~\cite{WordNet} and 
%% ChatGPT-4o\,\cite{}\maneesh{need citation}. For the concept ``up'', we
%% thus obtain synonymous expressions like ``upward'', ``northward'', ``towards
%% the top'', etc.
%% %
%% We similarly obtain synonyms for concepts mapped to object attributes.
%
%% sentence structure in english and ordering

To further increase prompt language variation, we vary the ordering of
the motion attributes in the general template.  For example, ``The square translates for 0.5
seconds'' can be reordered as ``For 0.5 seconds, the square
translates'' and ``The square, for 0.5 seconds, translates.''  Our
prompt generator includes all permutations of the motion attributes.
%
To ensure that all the different prompt ordering variations form
grammatical English we use pyrealb~\cite{lapalme2024pyrealb} to which
handles details like verb-object agreement and conjugation.

Finally, we add another class of prompt variations by taking one of
the template-based prompts and asking GPT-4o to rewrite
it with as many variations as possible. These LLM-generated variations
tend to be more diverse in sentence structure than the variations
produced by our template-based algorithm.

To produce our final test dataset, we build a set of 56 animation
scene graphs. 12 of these graphs are of type single atomic motions, 12
of type temporally relative, 14 of type spatially relative, and 18 of
type spatio-temporally relative.
% and accompanying static SVG images.
From those, we generated 56 \dslname{} verification programs as well
as 5600 prompt variations.  80\% of the prompt variations are
based on synonyms and reordering, while the remaining 20\% are from
\texttt{GPT-4o} rewrites.


%% \jiaju{TODO: talk about fully LLM generated sentences}
%% The goal of this algorithm is to generate variations of motion
%% prompts.  For example, ``Translate the square, and then scale it up,''
%% ``The square slides. Afterwards, it expands,'' and ``Make the square
%% shift. Subsequently, enlarge it.'' are three syntactically different
%% ways of expressing the same sequence of motions.

%% To generate prompt variations, we first define a representation of
%% \textit{atomic motions} with a dictionary structure that contains keys
%% for each of the seven motion attributes. In addition, each attribute
%% has a \texttt{reference} key that allows for the specification of
%% reference objects for that attribute.  Below we show two example
%% atomic motion definitions.
%% \vspace{-3mm}
%% \setlength{\columnsep}{-1cm}
%% \begin{multicols}{2}
%% \begin{verbatim}
%% mot_1 =
%% Motion(
%%   type = "translate",
%%   agent = [object_1],
%%   magnitude = 100.0,
%%   direction = [0, 1],
%%   duration = 0.5,
%% )
%% \end{verbatim}
%% \columnbreak
%% \begin{verbatim}
%% mot_2 =
%% Motion(
%%   type = "rotate",
%%   agent = [object_1],
%%   post = ["top", "border"],
%%   post_reference = [object_2],
%% )
%% \end{verbatim}
%% \end{multicols}
%% \vspace{-3mm}
%% Each \texttt{object\_i} variable above is defined in a
%% similar structure with keys that map to color and shape values.  To
%% add temporal sequencing relations between these motions, we use one
%% array to put the motion variables in sequence (e.g. \texttt{[mot\_1,
%%     mot\_2]}), and another array to store the timing relations
%% (e.g. \texttt{[none, before]} means that \texttt{mot\_1} itself has no
%% timing constraints but \texttt{mot\_1} must happen before
%% \texttt{mot\_1} with \texttt{before(mot\_1, mot\_2)}).

%% Having the motions represented this way allows us to both 1) generate
%% ground truth verification programs by directly converting the
%% key-values pairs to predicates and 2) generate prompt variations.  To
%% generate sentences in natural language, we first map the value of each
%% key to their corresponding concepts based on the motion type.  For
%% example, we convert the value of \texttt{direction} to the concept
%% ``up'' as its motion type is translation.  For each concept, we create
%% a vocabulary of synonymous expressions sourced from 1) thesauraus and
%% WordNet~\cite{WordNet} and 2) by prompting \texttt{gpt-4o} (e.g. for
%% the concept ``up'', we have expressions like ``up'', ``northward'',
%% ``towards the top'', etc.

%% %% sentence structure in english and ordering
%% Besides synonyms, we use two more ways to introduce variety.  The
%% first is using different syntactic structures to specify the object
%% and the motion verb.  There are two categories: to say the object
%% first and then the verb, or reverse.  For the former, we use present
%% tense with active voice (e.g. ``the blue circle translates'') and
%% passive voice (e.g. ``the blue circle is translated'').  To place the
%% verb before the object, we use three different variations of
%% imperative sentences: 1) ``translate the blue square'', 2) ``animate
%% the blue square to translate'', and 3) ``make the blue square
%% translate.''
%% %
%% The second way for variety is to place the motion attributes in
%% different orders.  For example, ``The square translates for 0.5
%% seconds'' can be reordered as ``for 0.5 seconds, the square
%% translates'' and ``the square, for 0.5 seconds, translates.''  We have
%% included all permutations of the motion attributes.

%% Therefore, for each motion variable, we can generate a wide range of
%% prompts by placing units of synonymous expressions that each describe
%% a motion attribute into different orderings with various sentence
%% structures.  We add expressions for sequencing constraints onto single
%% motion sentences to produce the final prompt.  For implementation, we
%% utilize pyrealb~\cite{Pyrealb} to handle low-level grammar
%% realizations such as subject-verb agreement and conjugation.

% LocalWords:  WordNet ChatGPT reorderings pyrealb YY ZZ agt dir dur
% LocalWords:  LLM
