@misc{Auxier_2019, title={5 things to know about Americans and their smart speakers}, url={https://www.pewresearch.org/fact-tank/2019/11/21/5-things-to-know-about-americans-and-their-smart-speakers/}, abstractNote={As Americans integrate smart speakers into their homes, many owners express concerns over data collection and personalization. Here are five key findings.}, journal={Pew Research Center}, author={Auxier, Brooke}, year={2019}, language={en-US} }

@inproceedings{Axtell_Munteanu_2021, address={New York, NY, USA}, series={CHI ’21}, title={Tea, Earl Grey, Hot: Designing Speech Interactions from the Imagined Ideal of Star Trek}, ISBN={978-1-4503-8096-6}, url={https://doi.org/10.1145/3411764.3445640}, DOI={10.1145/3411764.3445640}, abstractNote={Speech is now common in daily interactions with our devices, thanks to voice user interfaces (VUIs) like Alexa. Despite their seeming ubiquity, designs often do not match users’ expectations. Science fiction, which is known to influence design of new technologies, has included VUIs for decades. Star Trek: The Next Generation is a prime example of how people envisioned ideal VUIs. Understanding how current VUIs live up to Star Trek’s utopian technologies reveals mismatches between current designs and user expectations, as informed by popular fiction. Combining conversational analysis and VUI user analysis, we study voice interactions with the Enterprise’s computer and compare them to current interactions. Independent of futuristic computing power, we find key design-based differences: Star Trek interactions are brief and functional, not conversational, they are highly multimodal and context-driven, and there is often no spoken computer response. From this, we suggest paths to better align VUIs with user expectations.}, note={event-place: Yokohama, Japan}, booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems}, publisher={Association for Computing Machinery}, author={Axtell, Benett and Munteanu, Cosmin}, year={2021}, collection={CHI ’21} }

@inproceedings{Baughan_Wang_Liu_Mercurio_Chen_Ma_2023, address={Hamburg Germany}, title={A Mixed-Methods Approach to Understanding User Trust after Voice Assistant Failures}, ISBN={978-1-4503-9421-5}, url={https://dl.acm.org/doi/10.1145/3544548.3581152}, DOI={10.1145/3544548.3581152}, booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems}, publisher={ACM}, author={Baughan, Amanda and Wang, Xuezhi and Liu, Ariel and Mercurio, Allison and Chen, Jilin and Ma, Xiao}, year={2023}, month=apr, pages={1–16}, language={en} }

@book{Black_1962, title={Models and Metaphors: Studies in Language and Philosophy}, ISBN={978-0-8014-0041-4}, url={https://www.jstor.org/stable/10.7591/j.ctvr6971f}, abstractNote={Description not available.}, publisher={Cornell University Press}, author={Black, Max}, year={1962} }

@article{Blackwell_2006, title={The reification of metaphor as a design tool}, volume={13}, ISSN={1073-0516}, DOI={10.1145/1188816.1188820}, abstractNote={Despite causing many debates in human-computer interaction (HCI), the term “metaphor” remains a central element of design practice. This article investigates the history of ideas behind user-interface (UI) metaphor, not only technical developments, but also less familiar perspectives from education, philosophy, and the sociology of science. The historical analysis is complemented by a study of attitudes toward metaphor among HCI researchers 30 years later. Working from these two streams of evidence, we find new insights into the way that theories in HCI are related to interface design, and offer recommendations regarding approaches to future UI design research.}, number={4}, journal={ACM Transactions on Computer-Human Interaction}, author={Blackwell, Alan F.}, year={2006}, month=dec, pages={490–530} }

@article{Brahnam_Karanikas_Weaver_2011, title={(Un)dressing the interface: Exposing the foundational HCI metaphor “computer is woman”}, volume={23}, ISSN={0953-5438}, DOI={10.1016/j.intcom.2011.03.008}, abstractNote={Two fundamental (and oftentimes opposing) metaphors have directed much of HCI design: HCI is communication and HCI is direct manipulation. Beneath these HCI metaphors, however, is the unspoken metaphor of computer is woman. In this paper we expose this foundational metaphor. We begin by identifying the origin of computer is woman in the early history of computing. Drawing upon postmodern feminist theory, we then explore how this metaphor has resulted in the feminization of HCI is communication and second person interfaces. We show how images of femininity proliferate, becoming the projected images of male fantasies and ideals of womanhood. In becoming these idealized images, the interface is revealed as man in female drag. Finally, not only do we undress the interface to uncover how HCI is communication wraps the computer’s difference from human being within the more basic metaphor of computer is woman, but we also disclose dangers that can arise when this metaphor goes unacknowledged and unexamined.}, number={5}, journal={Interacting with Computers}, author={Brahnam, Sheryl and Karanikas, Marianthe and Weaver, Margaret}, year={2011}, month=sep, pages={401–412} }

@inproceedings{Braun_Mainz_Chadowitz_Pfleging_Alt_2019, address={New York, NY, USA}, series={CHI ’19}, title={At Your Service: Designing Voice Assistant Personalities to Improve Automotive User Interfaces}, ISBN={978-1-4503-5970-2}, url={https://doi.org/10.1145/3290605.3300270}, DOI={10.1145/3290605.3300270}, abstractNote={This paper investigates personalized voice characters for in-car speech interfaces. In particular, we report on how we designed different personalities for voice assistants and compared them in a real world driving study. Voice assistants have become important for a wide range of use cases, yet current interfaces are using the same style of auditory response in every situation, despite varying user needs and personalities. To close this gap, we designed four assistant personalities (Friend, Admirer, Aunt, and Butler) and compared them to a baseline (Default) in a between-subject study in real traffic conditions. Our results show higher likability and trust for assistants that correctly match the user’s personality while we observed lower likability, trust, satisfaction, and usefulness for incorrectly matched personalities, each in comparison with the Default character. We discuss design aspects for voice assistants in different automotive use cases.}, booktitle={Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems}, publisher={Association for Computing Machinery}, author={Braun, Michael and Mainz, Anja and Chadowitz, Ronee and Pfleging, Bastian and Alt, Florian}, year={2019}, month=may, pages={1–11}, collection={CHI ’19} }

@book{Cameron_Maslen_2010, address={London}, title={Metaphor Analysis: Research Practice in applied Linguistics, Social Sciences and the Humanities}, ISBN={978-1-84553-446-2}, url={http://www.equinoxpub.com/books/showbook.asp?bkid=363&keyword=9781845534479}, abstractNote={Metaphor is recognised as an important way of thinking constructing analogies and making connections between ideas and an important way of using language to explain abstract ideas or to find indirect but powerful ways of conveying feelings. By investigating peoples use of metaphors, we can better understand their emotions, attitudes and conceptualisations, as individuals and as participants in social life. This book describes practice in the analysis of metaphor in real-world discourse. When real-world language use is taken as the site of metaphor study, researchers face methodological issues that have only recently begun to be addressed. The contributors to this volume have all had to find ways to deal with methodological issues in their own research and have developed techniques that are brought together here. Using as a basis the discourse dynamics approach to metaphor developed by the editor, the book explores links between theory and empirical investigation, exemplifies data analysis and discusses issues in research design and practice. Particular attention is paid to the processes of metaphor identification, categorisation and labelling, and to the use of corpus linguistic and other computer-assisted methods.}, publisher={Equinox}, author={Cameron, Lynne and Maslen, Robert}, editor={Cameron, Lynne and Maslen, Robert}, year={2010}, month=jun, language={en} }

@inbook{Carroll_Mack_Kellogg_1988, address={Amsterdam}, title={Chapter 3 - Interface Metaphors and User Interface Design}, ISBN={978-0-444-70536-5}, url={https://www.sciencedirect.com/science/article/pii/B9780444705365500087}, DOI={10.1016/B978-0-444-70536-5.50008-7}, abstractNote={This chapter discusses interface metaphors and the user interface design. The integration of operational, structural, and pragmatic approaches to metaphors can provide guidance and a starting point for the design of a user interface that integrates a central metaphor, with a carefully analyzed similarity basis and a set of planned mismatches, with myriad other interface elements that support and exploit the matches and mismatches inhering in the metaphor. Metaphoric comparisons and interface presentations do more than render static denotative correspondences. They have motivational and affective consequences for users. They interact with and frame users’ problem-solving efforts in learning about the target domain. Metaphors have been employed to increase the initial familiarity of the target domain, but they have an inevitable further role to play. The ultimate problem that the user should solve is to develop an understanding of the target domain itself—a mental model. Interface metaphors should also be viewed as tools proffered to users for articulating mental models.}, booktitle={Handbook of Human-Computer Interaction}, publisher={North-Holland}, author={Carroll, John M. and Mack, Robert L. and Kellogg, Wendy A.}, editor={Helander, MARTIN}, year={1988}, month=jan, pages={67–85}, language={en} }

@article{Carroll_Thomas_1982, title={Metaphor and the Cognitive Representation of Computing Systems}, volume={12}, ISSN={2168-2909}, DOI={10.1109/TSMC.1982.4308795}, abstractNote={In learning, people develop new cognitive structures by metaphorically extending old ones. The metaphors spontaneously generated by new users will predict the ease with which they can master a computer system. Systems which through their interface suggest inefficacious metaphors will accordingly be more difficult to learn and to that extent unacceptable.}, number={2}, journal={IEEE Transactions on Systems, Man, and Cybernetics}, author={Carroll, John M. and Thomas, John C.}, year={1982}, month=mar, pages={107–116} }

@article{Chan_Fu_Li_Yao_Desai_Prpa_Wang_2024, title={Human and LLM-Based Voice Assistant Interaction: An Analytical Framework for User Verbal and Nonverbal Behaviors}, url={http://arxiv.org/abs/2408.16465}, DOI={10.48550/arXiv.2408.16465}, abstractNote={Recent progress in large language model (LLM) technology has significantly enhanced the interaction experience between humans and voice assistants (VAs). This project aims to explore a user’s continuous interaction with LLM-based VA (LLM-VA) during a complex task. We recruited 12 participants to interact with an LLM-VA during a cooking task, selected for its complexity and the requirement for continuous interaction. We observed that users show both verbal and nonverbal behaviors, though they know that the LLM-VA can not capture those nonverbal signals. Despite the prevalence of nonverbal behavior in human-human communication, there is no established analytical methodology or framework for exploring it in human-VA interactions. After analyzing 3 hours and 39 minutes of video recordings, we developed an analytical framework with three dimensions: 1) behavior characteristics, including both verbal and nonverbal behaviors, 2) interaction stages--exploration, conflict, and integration--that illustrate the progression of user interactions, and 3) stage transition throughout the task. This analytical framework identifies key verbal and nonverbal behaviors that provide a foundation for future research and practical applications in optimizing human and LLM-VA interactions.}, note={arXiv:2408.16465 [cs]}, number={arXiv:2408.16465}, publisher={arXiv}, author={Chan, Szeyi and Fu, Shihan and Li, Jiachen and Yao, Bingsheng and Desai, Smit and Prpa, Mirjana and Wang, Dakuo}, year={2024}, month=sep }

@article{Chin2024Like,
  title={Like my aunt Dorothy: Effects of conversational styles on perceptions, acceptance, and metaphorical descriptions of voice assistants during later adulthood},
  author={Chin, Jessie and Desai, Smit and Lin, Sheny and Mej{\'i}a, Shannon},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={8},
  number={CSCW1},
  article={88},
  pages={1-22},
  year={2024},
  month={Apr},
  doi={10.1145/3637365},
  url={https://doi.org/10.1145/3637365}
}

@article{Clark_Doyle_Garaialde_Gilmartin_Schlögl_Edlund_Aylett_Cabral_Munteanu_Edwards_et_al._2019, title={The State of Speech in HCI: Trends, Themes and Challenges}, volume={31}, ISSN={0953-5438}, DOI={10.1093/iwc/iwz016}, abstractNote={Speech interfaces are growing in popularity. Through a review of 99 research papers this work maps the trends, themes, findings and methods of empirical research on speech interfaces in the field of human–computer interaction (HCI). We find that studies are usability/theory-focused or explore wider system experiences, evaluating Wizard of Oz, prototypes or developed systems. Measuring task and interaction was common, as was using self-report questionnaires to measure concepts like usability and user attitudes. A thematic analysis of the research found that speech HCI work focuses on nine key topics: system speech production, design insight, modality comparison, experiences with interactive voice response systems, assistive technology and accessibility, user speech production, using speech technology for development, peoples’ experiences with intelligent personal assistants and how user memory affects speech interface interaction. From these insights we identify gaps and challenges in speech research, notably taking into account technological advancements, the need to develop theories of speech interface interaction, grow critical mass in this domain, increase design work and expand research from single to multiple user interaction contexts so as to reflect current use contexts. We also highlight the need to improve measure reliability, validity and consistency, in the wild deployment and reduce barriers to building fully functional speech interfaces for research.Most papers focused on usability/theory-based or wider system experience research with a focus on Wizard of Oz and developed systemsQuestionnaires on usability and user attitudes often used but few were reliable or validatedThematic analysis showed nine primary research topicsChallenges identified in theoretical approaches and design guidelines, engaging with technological advances, multiple user and in the wild contexts, critical research mass and barriers to building speech interfaces}, number={4}, journal={Interacting with Computers}, author={Clark, Leigh and Doyle, Philip and Garaialde, Diego and Gilmartin, Emer and Schlögl, Stephan and Edlund, Jens and Aylett, Matthew and Cabral, João and Munteanu, Cosmin and Edwards, Justin and R Cowan, Benjamin}, year={2019}, month=jun, pages={349–371} }

@article{Colburn_Shute_2008, series={The Philosophy of Computer Science}, title={Metaphor in computer science}, volume={6}, ISSN={1570-8683}, DOI={10.1016/j.jal.2008.09.005}, abstractNote={The language of computer science is laced with metaphor. We argue that computer science metaphors provide a conceptual framework in which to situate constantly emerging new ontologies in computational environments. But how computer science metaphors work does not fit neatly into prevailing general theories of metaphor. We borrow from these general theories while also considering the unique role of computer science metaphors in learning, design, and scientific analysis. We find that computer science metaphors trade on both preexisting and emerging similarities between computational and traditional domains, but owing to computer science’s peculiar status as a discipline that creates its own subject matter, the role of similarity in metaphorical attribution is multifaceted.}, number={4}, journal={Journal of Applied Logic}, author={Colburn, T. R. and Shute, G. M.}, year={2008}, month=dec, pages={526–533}, collection={The Philosophy of Computer Science}, language={en} }

@inproceedings{Cowan_Pantidi_Coyle_Morrissey_Clarke_Al-Shehri_Earley_Bandeira_2017, address={New York, NY, USA}, series={MobileHCI ’17}, title={“What Can I Help You with?”: Infrequent Users’ Experiences of Intelligent Personal Assistants}, ISBN={978-1-4503-5075-4}, url={http://doi.acm.org/10.1145/3098279.3098539}, DOI={10.1145/3098279.3098539}, abstractNote={Intelligent Personal Assistants (IPAs) are widely available on devices such as smartphones. However, most people do not use them regularly. Previous research has studied the experiences of frequent IPA users. Using qualitative methods we explore the experience of infrequent users: people who have tried IPAs, but choose not to use them regularly. Unsurprisingly infrequent users share some of the experiences of frequent users, e.g. frustration at limitations on fully hands-free interaction. Significant points of contrast and previously unidentified concerns also emerge. Cultural norms and social embarrassment take on added significance for infrequent users. Humanness of IPAs sparked comparisons with human assistants, juxtaposing their limitations. Most importantly, significant concerns emerged around privacy, monetization, data permanency and transparency. Drawing on these findings we discuss key challenges, including: designing for interruptability; reconsideration of the human metaphor; issues of trust and data ownership. Addressing these challenges may lead to more widespread IPA use.}, note={00000 
event-place: Vienna, Austria}, booktitle={Proceedings of the 19th International Conference on Human-Computer Interaction with Mobile Devices and Services}, publisher={ACM}, author={Cowan, Benjamin R. and Pantidi, Nadia and Coyle, David and Morrissey, Kellie and Clarke, Peter and Al-Shehri, Sara and Earley, David and Bandeira, Natasha}, year={2017}, pages={43:1-43:12}, collection={MobileHCI ’17} }

@inproceedings{DeVito_Birnholtz_Hancock_French_Liu_2018, address={New York, NY, USA}, series={CHI ’18}, title={How People Form Folk Theories of Social Media Feeds and What it Means for How We Study Self-Presentation}, ISBN={978-1-4503-5620-6}, url={https://dl.acm.org/doi/10.1145/3173574.3173694}, DOI={10.1145/3173574.3173694}, abstractNote={Self-presentation is a process that is significantly complicated by the rise of algorithmic social media feeds, which obscure information about one’s audience and environment. User understandings of these systems, and therefore user ability to adapt to them, are limited, and have recently been explored through the lens of folk theories. To date, little is understood of how these theories are formed, and how they tie to the self-presentation process in social media. This paper presents an exploratory look at the folk theory formation process and the interplay between folk theories and self-presentation via a 28-participant interview study. Results suggest that people draw from diverse sources of information when forming folk theories, and that folk theories are more complex, multifaceted and malleable than previously assumed. This highlights the need to integrate folk theories into both social media systems and theories of self-presentation.}, booktitle={Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems}, publisher={Association for Computing Machinery}, author={DeVito, Michael A. and Birnholtz, Jeremy and Hancock, Jeffery T. and French, Megan and Liu, Sunny}, year={2018}, month=apr, pages={1–12}, collection={CHI ’18} }

@inproceedings{Desai_Chin_2023, address={New York, NY, USA}, series={CHI ’23}, title={OK Google, Let’s Learn: Using Voice User Interfaces for Informal Self-Regulated Learning of Health Topics among Younger and Older Adults}, ISBN={978-1-4503-9421-5}, url={https://doi.org/10.1145/3544548.3581507}, DOI={10.1145/3544548.3581507}, abstractNote={In this paper, we present Health Buddy, a voice agent integrated into commercially available Voice User Interfaces (VUIs) to support informal self-regulated learning (SRL) of health-related topics through multiple learning strategies and examine the efficacy of Health Buddy on learning outcomes for younger and older adults. We conducted a mixed-factorial-design experiment with 26 younger and 25 older adults, assigned to three SRL strategies (within-subjects): monologue, dialogue-based scaffolding building, and conceptual diagramming. We found that while younger adults benefit more from scaffolding building and conceptual diagramming, both younger and older adults showed equivalent learning outcomes. Furthermore, interaction fluency (operationalized by the number of conversational breakdowns) was associated with learning outcomes regardless of age. While older adults did not experience less fluent conversations, interaction fluency affected their technology acceptance toward VUIs more than younger ones. Our study discusses age-related learning differences and has implications for designing VUI-based learning programs for older adults.}, booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems}, publisher={Association for Computing Machinery}, author={Desai, Smit and Chin, Jessie}, year={2023}, month=apr, pages={1–21}, collection={CHI ’23} }

@inproceedings{Desai_Hu_Lundy_Chin_2023, address={New York, NY, USA}, series={HAI ’23}, title={Using Experience-Based Participatory Approach to Design Interactive Voice User Interfaces for Delivering Physical Activity Programs with Older Adults}, ISBN={9798400708244}, url={https://dl.acm.org/doi/10.1145/3623809.3623827}, DOI={10.1145/3623809.3623827}, abstractNote={Voice User Interfaces (VUIs) are popular among older adults, who find them easy to use and perceive them as social companions. However, there is a lack of research on voice-based applications to support physical activities for older adults. To address this gap, we present “Workout Pal,” a voice agent designed to deliver physical activities to older adults. We conducted a mixed-methods study involving ten older adults to understand their perceptions and design priorities when interacting with Workout Pal. Questionnaires and semi-structured interviews were used to assess their experience, while experience-based co-design sessions facilitated collaboration in exploring the design space and identifying design requirements. Our findings highlight the feasibility and design preferences for smart speaker-based physical activity programs. The study contributes by sharing the design and development of Workout Pal, illustrating a novel co-design approach with older adults, and providing design implications tailored to the specific needs of older adults. The design guidelines emphasize the importance of sociability, voice design, and individualization. This research supports the development of elder-friendly VUIs helping older adults live independently and engage in physical activities.}, booktitle={Proceedings of the 11th International Conference on Human-Agent Interaction}, publisher={Association for Computing Machinery}, author={Desai, Smit and Hu, Xinhui and Lundy, Morgan and Chin, Jessie}, year={2023}, month=dec, pages={180–190}, collection={HAI ’23} }

@inproceedings{Desai_Lundy_Chin_2023, address={New York, NY, USA}, series={CUI ’23}, title={“A Painless Way to Learn:” Designing an Interactive Storytelling Voice User Interface to Engage Older Adults in Informal Health Information Learning}, ISBN={9798400700149}, url={https://dl.acm.org/doi/10.1145/3571884.3597141}, DOI={10.1145/3571884.3597141}, abstractNote={We present “Mystery Agent,” an interactive storytelling voice user interface (VUI) equipped with self-regulated learning strategies to deliver informal health-related learning to older adults through a murder mystery story. We conducted a mixed methods user study with 10 older adults to evaluate Mystery Agent, using usability and perception-based questionnaires, followed by a semi-structured interview and co-design activity to generate design insights and identify design priorities. We found older adults had a positive experience interacting with Mystery Agent and considered storytelling to be an appropriate and engaging way to learn health information. However, older adults identified credibility, compassion, and control as crucial factors influencing long-term use. To address this, we present design guidelines using Mystery Agent as an example to help practitioners and researchers devise novel solutions to address the informal health information learning needs of older adults.}, booktitle={Proceedings of the 5th International Conference on Conversational User Interfaces}, publisher={Association for Computing Machinery}, author={Desai, Smit and Lundy, Morgan and Chin, Jessie}, year={2023}, month=jul, pages={1–16}, collection={CUI ’23} }

@inproceedings{Desai_Twidale_2022, address={New York, NY, USA}, series={CUI ’22}, title={Is Alexa like a computer? A search engine? A friend? A silly child? Yes.}, ISBN={978-1-4503-9739-1}, url={https://dl.acm.org/doi/10.1145/3543829.3544535}, DOI={10.1145/3543829.3544535}, abstractNote={In this provocation, we analyze metaphors used by 14 end-users in semi-structured interviews to describe their interactions with Voice User Interfaces (VUIs). We identified four key metaphor groups—computer, search engine, friend, and silly child—that can help us understand how individual end-users perceive VUIs differently based on the conversational context. A consideration of these four groups draws attention to the issues with reductionist implementations of system personas and role-based performances and the problems of fixating on humanness as a metaphor. Fortunately, using metaphor analysis can also help in ideating solutions to these issues.}, booktitle={Proceedings of the 4th Conference on Conversational User Interfaces}, publisher={Association for Computing Machinery}, author={Desai, Smit and Twidale, Michael}, year={2022}, month=sep, pages={1–4}, collection={CUI ’22} }

@article{Desai_Twidale_2023, title={Metaphors in Voice User Interfaces: A Slippery Fish}, volume={30}, ISSN={1073-0516, 1557-7325}, DOI={10.1145/3609326}, abstractNote={We explore a range of different metaphors used for Voice User Interfaces (VUIs) by designers, end-users, manufacturers, and researchers using a novel framework derived from semi-structured interviews and a literature review. We focus less on the well-established idea of metaphors as a way for interface designers to help novice users learn how to interact with novel technology, and more on other ways metaphors can be used. We find that metaphors people use are contextually fluid, can change with the mode of conversation, and can reveal differences in how people perceive VUIs compared to other devices. Not all metaphors are helpful, and some may be offensive. Analyzing this broader class of metaphors can help understand, perhaps even predict problems. Metaphor analysis can be a low-cost tool to inspire design creativity and facilitate complex discussions about sociotechnical issues, enabling us to spot potential opportunities and problems in the situated use of technologies.}, number={6}, journal={ACM Transactions on Computer-Human Interaction}, author={Desai, Smit and Twidale, Michael}, year={2023}, month=dec, pages={1–37}, language={en} }

@article{Epley_Waytz_Cacioppo_2007, title={On Seeing Human: A Three-Factor Theory of Anthropomorphism}, volume={114}, DOI={10.1037/0033-295x.114.4.864}, number={4}, journal={Psychological Review}, author={Epley, Nicholas and Waytz, Adam and Cacioppo, John T.}, year={2007}, pages={864–886} }

@inproceedings{Feldman_2024, address={New York, NY, USA}, series={CUI ’24}, title={The Voice: Lessons on Trustworthy Conversational Agents from “Dune”}, ISBN={9798400705113}, url={https://dl.acm.org/doi/10.1145/3640794.3665890}, DOI={10.1145/3640794.3665890}, abstractNote={The potential for untrustworthy conversational agents presents a significant threat for covert social manipulation. Taking inspiration from Frank Herbert’s Dune&nbsp;[12], where the Bene Gesserit Sisterhood uses the Voice for influence, manipulation, and control of people, we explore how generative AI provides a way to implement individualized influence at industrial scales. Already, these models can manipulate communication across text, image, speech, and most recently video. They are rapidly becoming affordable enough for any organization of even moderate means to train and deploy. If employed by malicious actors, they risk becoming powerful tools for shaping public opinion, sowing discord, and undermining organizations from companies to governments. As researchers and developers, it is crucial to recognize the potential for such weaponization and to explore strategies for prevention, detection, and defense against these emerging forms of sociotechnical manipulation.}, booktitle={Proceedings of the 6th ACM Conference on Conversational User Interfaces}, publisher={Association for Computing Machinery}, author={Feldman, Philip Gregory}, year={2024}, month=jul, pages={1–5}, collection={CUI ’24} }

@article{Gentner_Hoyos_2017, title={Analogy and Abstraction}, volume={9}, rights={Copyright © 2017 Cognitive Science Society, Inc.}, ISSN={1756-8765}, DOI={10.1111/tops.12278}, abstractNote={A central question in human development is how young children gain knowledge so fast. We propose that analogical generalization drives much of this early learning and allows children to generate new abstractions from experience. In this paper, we review evidence for analogical generalization in both children and adults. We discuss how analogical processes interact with the child’s changing knowledge base to predict the course of learning, from conservative to domain-general understanding. This line of research leads to challenges to existing assumptions about learning. It shows that (a) it is not enough to consider the distribution of examples given to learners; one must consider the processes learners are applying; (b) contrary to the general assumption, maximizing variability is not always the best route for maximizing generalization and transfer.}, number={3}, journal={Topics in Cognitive Science}, author={Gentner, Dedre and Hoyos, Christian}, year={2017}, pages={672–693}, language={en} }

@book{Heckel_1984, title={The elements of friendly software design}, ISBN={978-0-446-38040-9}, url={http://archive.org/details/elementsoffriend00heck}, abstractNote={Bibliography: p. 193-202; Includes index}, publisher={New York: Warner Books}, author={Heckel, Paul}, year={1984}, language={eng} }

@book{Hofstadter_1995, address={New York, NY, US}, series={Fluid concepts and creative analogies:  Computer models of the fundamental mechanisms of thought}, title={Fluid concepts and creative analogies:  Computer models of the fundamental mechanisms of thought}, ISBN={978-0-465-05154-0}, abstractNote={[This book explores a] vision of the mind in which perception, at an abstract level, is the key: perception of situations, of patterns, of patterns among patterns, even perception of one’s perceptions.  2 ideas pervade the research. One is that the key question to answer is “What is a concept?” This means understanding how concepts overlap and trigger one another, how their fluid boundaries come about, how they give rise to generalizations and analogies, and so on. The 2nd idea is that mental activity is fundamentally parallel, with many tiny agents independently carrying out small “subcognitive” acts and collectively building up coherent mental structures.  With these intuitions as guides, Hofstadter and the members of the Fluid Analogies Research Group have developed computer models [of these processes].  Psychologists, philosophers, and artificial-intelligence researchers will find [this book presents a] new view of mind. (PsycINFO Database Record (c) 2016 APA, all rights reserved)}, publisher={Basic Books}, author={Hofstadter, Douglas R.}, year={1995}, pages={ix, 518}, collection={Fluid concepts and creative analogies:  Computer models of the fundamental mechanisms of thought} }

@book{Indurkhya_2013, title={Metaphor and Cognition: An Interactionist Approach}, ISBN={978-94-017-2252-0}, abstractNote={Many metaphors go beyond pionting to the existing similarities between two objects -- they create the similarities. Such metaphors, which have been relegated to the back seat in most of the cognitive science research, are the focus of attention in this study, which addresses the creation of similarity within an elaborately laid out interactive framework of cognition. Starting from the constructivist views of Nelson Goodman and Jean Piaget, this framework resolves an apparent paradox in interactionism: how can reality not have a mind-independent ontology and structure, but still manage to constrain the possible worlds a cognitive agent can create in it?  A comprehensive theory of metaphor is proposed in this framework that explains how metaphors can create similarities, and why such metaphors are an invaluable asset to cognition. The framework is then applied to related issues of analogical reasoning, induction, and computational modeling of creative metaphors.}, note={Google-Books-ID: foTrCAAAQBAJ}, publisher={Springer Science \& Business Media}, author={Indurkhya, B.}, year={2013}, month=mar, language={en} }

@book{Johnson-Laird_1983, title={Mental models : towards a cognitive science of language, inference, and consciousness}, url={https://hal.archives-ouvertes.fr/hal-00702919}, abstractNote={Mental Models offers nothing less than a unified theory of the major properties of mind: comprehension, inference, and consciousness. In spirited and graceful prose, Johnson-Laird argues that we apprehend the world by building inner mental replicas of the relations among objects and events that concern us. The mind is essentially a model-building device that can itself be modeled on a digital computer. This book provides both a blueprint for building such a model and numerous important illustrations of how to do it. In several key areas of cognition, Johnson-Laird shows how an explanation based on mental modeling is clearly superior to previous theory. For example, he argues compellingly that deductive reasoning does not take place by tacitly applying the rules of logic, but by mentally manipulating models of the states of affairs from which inferences are drawn. Similarly, linguistic comprehension is best understood not as a matter of applying inference rules to propositions derived from sentences, but rather as the mind’s effort to construct and update a model of the situation described by a text or a discourse. Most provocative, perhaps, is Johnson-Laird’s theory of consciousness: the mind’s necessarily incomplete model of itself allows only a partial control over the many unconscious and parallel processes of cognition. This an extraordinarily rich book, providing a coherent account of much recent experimental work in cognitive psychology, along with lucid explanations of relevant theory in linguistics, computer science, and philosophy Not since Miller, Galanter, and Pribram’s classic Plans and the Structure of Behavior has a book in cognitive science combined such sweep, style, and good sense. Like its distinguished predecessor, Mental Models may well serve to fix a point of view for a generation. (http://books.google.fr/books?id=FS3zSKAfLGMC&printsec=frontcover&hl=fr#v=onepage&q&f=false)}, publisher={Cambridge, MA: Harvard University Press}, author={Johnson-Laird, Philip N.}, year={1983} }

@inproceedings{Jung_Kim_So_Kim_Oh_2019, address={New York, NY, USA}, series={CHI EA ’19}, title={TurtleTalk: An Educational Programming Game for Children with Voice User Interface}, ISBN={978-1-4503-5971-9}, url={https://dl.acm.org/doi/10.1145/3290607.3312773}, DOI={10.1145/3290607.3312773}, abstractNote={Interest in programming education for children is growing. This research explores the possibilities of utilizing voice user interface (VUI) in children’s programming education. We designed an interactive educational programming game called TurtleTalk, which converts the various utterances of children into code using a neural network and displays the results on a screen (Figure 1). Through VUI, children can move the turtle, the voice agent of the game, to the target location and learn the basic programming concepts of “sequencing” and “iteration.” We conducted a preliminary user study where eight children played the game and took part in a posthoc interview. The results showed that voice interaction with TurtleTalk led children to be more immersed in the game and understand the elements of programming with ease and confidence.}, booktitle={Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems}, publisher={Association for Computing Machinery}, author={Jung, Hyunhoon and Kim, Hee Jae and So, Seongeun and Kim, Jinjoong and Oh, Changhoon}, year={2019}, month=may, pages={1–6}, collection={CHI EA ’19} }

@inproceedings{Jung_Qiu_Bozzon_Gadiraju_2022, address={New Orleans LA USA}, title={Great Chain of Agents: The Role of Metaphorical Representation of Agents in Conversational Crowdsourcing}, ISBN={978-1-4503-9157-3}, url={https://dl.acm.org/doi/10.1145/3491102.3517653}, DOI={10.1145/3491102.3517653}, booktitle={CHI Conference on Human Factors in Computing Systems}, publisher={ACM}, author={Jung, Ji-Youn and Qiu, Sihang and Bozzon, Alessandro and Gadiraju, Ujwal}, year={2022}, month=apr, pages={1–22}, language={en} }

@book{Keller_2003, address={Cambridge, Mass.}, title={Making Sense of Life: Explaining Biological Development with Models, Metaphors, and Machines}, ISBN={978-0-674-01250-9}, abstractNote={What do biologists want? If, unlike their counterparts in physics, biologists are generally wary of a grand, overarching theory, at what kinds of explanation do biologists aim? How will we know when we have “made sense” of life? Such questions, Evelyn Fox Keller suggests, offer no simple answers. Explanations in the biological sciences are typically provisional and partial, judged by criteria as heterogeneous as their subject matter. It is Keller’s aim in this bold and challenging book to account for this epistemological diversity―particularly in the discipline of developmental biology.In particular, Keller asks, what counts as an “explanation” of biological development in individual organisms? Her inquiry ranges from physical and mathematical models to more familiar explanatory metaphors to the dramatic contributions of recent technological developments, especially in imaging, recombinant DNA, and computer modeling and simulations.A history of the diverse and changing nature of biological explanation in a particularly charged field, Making Sense of Life draws our attention to the temporal, disciplinary, and cultural components of what biologists mean, and what they understand, when they propose to explain life.}, publisher={Harvard University Press}, author={Keller, Evelyn Fox}, year={2003}, month=oct, language={English} }

@article{Khadpe_Krishna_Fei-Fei_Hancock_Bernstein_2020, title={Conceptual Metaphors Impact Perceptions of Human-AI Collaboration}, volume={4}, ISSN={2573-0142}, DOI={10.1145/3415234}, abstractNote={With the emergence of conversational artificial intelligence (AI) agents, it is important to understand the mechanisms that influence users’ experiences of these agents. In this paper, we study one of the most common tools in the designer’s toolkit: conceptual metaphors. Metaphors can present an agent as akin to a wry teenager, a toddler, or an experienced butler. How might a choice of metaphor influence our experience of the AI agent? Sampling a set of metaphors along the dimensions of warmth and competence---defined by psychological theories as the primary axes of variation for human social perception---we perform a study $(N=260)$ where we manipulate the metaphor, but not the behavior, of a Wizard-of-Oz conversational agent. Following the experience, participants are surveyed about their intention to use the agent, their desire to cooperate with the agent, and the agent’s usability. Contrary to the current tendency of designers to use high competence metaphors to describe AI products, we find that metaphors that signal low competence lead to better evaluations of the agent than metaphors that signal high competence. This effect persists despite both high and low competence agents featuring identical, human-level performance and the wizards being blind to condition. A second study confirms that intention to adopt decreases rapidly as competence projected by the metaphor increases. In a third study, we assess effects of metaphor choices on potential users’ desire to try out the system and find that users are drawn to systems that project higher competence and warmth. These results suggest that projecting competence may help attract new users, but those users may discard the agent unless it can quickly correct with a lower competence metaphor. We close with a retrospective analysis that finds similar patterns between metaphors and user attitudes towards past conversational agents such as Xiaoice, Replika, Woebot, Mitsuku, and Tay.}, number={CSCW2}, journal={Proceedings of the ACM on Human-Computer Interaction}, author={Khadpe, Pranav and Krishna, Ranjay and Fei-Fei, Li and Hancock, Jeffrey T. and Bernstein, Michael S.}, year={2020}, month=oct, pages={1–26}, language={en} }

@article{Kim_Choudhury_2021, title={Exploring older adults’ perception and use of smart speaker-based voice assistants: A longitudinal study}, volume={124}, ISSN={0747-5632}, DOI={10.1016/j.chb.2021.106914}, abstractNote={Thanks to their conversational capabilities, smart speaker-based voice assistants are gaining attention for their potential to support the aging population, though the empirical evidence is still scarce. This paper aims to obtain empirical evidence on older adults’ experiences with a voice assistant. We especially focused on how their perception and use change over time as they progress from novice to more experienced users through a longitudinal field deployment study. We deployed Google Home devices in the homes of twelve older adults aged 65 and above and studied their use for sixteen weeks. Results show that the benefits our participants perceived have incrementally changed from enjoying simplicity and convenience of operation in the early phase of the study to not worrying about making mistakes and building digital companionship as they got used to using it. Results also show that participants confronted several challenges that evolved from the unfamiliarity with a voice assistant in their first interactions to coping with the functional errors due to limited speech technology as they got used to using it. Based on the results, we discuss design implications that could foster better user experiences with a voice assistant among older adults.}, journal={Computers in Human Behavior}, author={Kim, Sunyoung and Choudhury, Abhishek}, year={2021}, month=nov, pages={106914}, language={en} }

@inproceedings{Kuzminykh_Sun_Govindaraju_Avery_Lank_2020, address={New York, NY, USA}, series={CHI ’20}, title={Genie in the Bottle: Anthropomorphized Perceptions of Conversational Agents}, ISBN={978-1-4503-6708-0}, url={https://dl.acm.org/doi/10.1145/3313831.3376665}, DOI={10.1145/3313831.3376665}, abstractNote={This paper presents a qualitative multi-phase study seeking to identify patterns in users’ anthropomorphized perceptions of conversational agents. Through a comparative analysis of behavioral perceptions and visual conceptions of three agents - Alexa, Google Assistant, and Siri - we first show that the perceptions of an agent’s character are structured according to five categories: approachability, sentiment toward a user, professionalism, intelligence, and individuality. We then explore visualizations of the agents’ appearance and discuss the specifics assigned to each agent. Finally, we analyze associative explanations for these perceptions. We demonstrate that the anthropomorphized behavioral and visual perceptions of agents yield structural consistency and discuss how these perceptions are linked with each other and system features.}, booktitle={Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems}, publisher={Association for Computing Machinery}, author={Kuzminykh, Anastasia and Sun, Jenny and Govindaraju, Nivetha and Avery, Jeff and Lank, Edward}, year={2020}, month=apr, pages={1–13}, collection={CHI ’20} }

@book{Lakoff_Johnson_1980, title={Metaphors We Live By}, ISBN={978-0-226-47099-3}, abstractNote={The now-classic Metaphors We Live By changed our understanding of metaphor and its role in language and the mind. Metaphor, the authors explain, is a fundamental mechanism of mind, one that allows us to use what we know about our physical and social experience to provide understanding of countless other subjects. Because such metaphors structure our most basic understandings of our experience, they are “metaphors we live by”—metaphors that can shape our perceptions and actions without our ever noticing them.  In this updated edition of Lakoff and Johnson’s influential book, the authors supply an afterword surveying how their theory of metaphor has developed within the cognitive sciences to become central to the contemporary understanding of how we think and how we express our thoughts in language.}, note={Google-Books-ID: r6nOYYtxzUoC}, publisher={University of Chicago Press}, author={Lakoff, George and Johnson, Mark}, year={1980}, language={en} }

@article{Lee_Frank_IJsselsteijn_2021, title={Brokerbot: A Cryptocurrency Chatbot in the Social-technical Gap of Trust}, volume={30}, ISSN={1573-7551}, DOI={10.1007/s10606-021-09392-6}, abstractNote={Cryptocurrencies are proliferating as instantiations of blockchain, which is a transparent, distributed ledger technology for validating transactions. Blockchain is thus said to embed trust in its technical design. Yet, blockchain’s technical promise of trust is not fulfilled when applied to the cryptocurrency ecosystem due to many social challenges stakeholders experience. By investigating a cryptocurrency chatbot (Brokerbot) that distributed information on cryptocurrency news and investments, we explored social tensions of trust between stakeholders, namely the bot’s developers, users, and the bot itself. We found that trust in Brokerbot and in the cryptocurrency ecosystem are two conjoined, but separate challenges that users and developers approached in different ways. We discuss the challenging, dual-role of a Brokerbot as an object of trust as a chatbot while simultaneously being a mediator of trust in cryptocurrency, which exposes the social-technical gap of trust. Lastly, we elaborate on trust as a negotiated social process that people shape and are shaped by through emerging ecologies of interlinked technologies like blockchain and conversational interfaces.}, number={1}, journal={Computer Supported Cooperative Work (CSCW)}, author={Lee, Minha and Frank, Lily and IJsselsteijn, Wijnand}, year={2021}, month=feb, pages={79–117}, language={en} }

@inproceedings{Lockton_Singh_Sabnis_Chou_Foley_Pantoja_2019, address={New York, NY, USA}, series={C\&amp;C ’19}, title={New Metaphors: A Workshop Method for Generating Ideas and Reframing Problems in Design and Beyond}, ISBN={978-1-4503-5917-7}, url={https://dl.acm.org/doi/10.1145/3325480.3326570}, DOI={10.1145/3325480.3326570}, abstractNote={Metaphors are important at multiple levels within design and society-from the specifics of interfaces, to wider societal imaginaries of technology and progress. Exploring alternative metaphors can be generative in creative processes, and for reframing problems strategically. In this pictorial we introduce an inspiration card workshop method using juxtaposition (or bisociation) to enable participants to explore novel metaphors for hard-to-visualise phenomena, drawing on a provisional set of inspiration material. We demonstrate the process through illustrating creative workshops in France, Portugal, Chile, and the USA, and reflect on benefits, limitations, and potential development of this format for use within interaction design.}, booktitle={Proceedings of the 2019 Conference on Creativity and Cognition}, publisher={Association for Computing Machinery}, author={Lockton, Dan and Singh, Devika and Sabnis, Saloni and Chou, Michelle and Foley, Sarah and Pantoja, Alejandro}, year={2019}, month=jun, pages={319–332}, collection={C\&amp;C ’19} }

@inproceedings{Luger_Sellen_2016, address={New York, NY, USA}, series={CHI ’16}, title={“Like Having a Really Bad PA”: The Gulf between User Expectation and Experience of Conversational Agents}, ISBN={978-1-4503-3362-7}, url={https://dl.acm.org/doi/10.1145/2858036.2858288}, DOI={10.1145/2858036.2858288}, abstractNote={The past four years have seen the rise of conversational agents (CAs) in everyday life. Apple, Microsoft, Amazon, Google and Facebook have all embedded proprietary CAs within their software and, increasingly, conversation is becoming a key mode of human-computer interaction. Whilst we have long been familiar with the notion of computers that speak, the investigative concern within HCI has been upon multimodality rather than dialogue alone, and there is no sense of how such interfaces are used in everyday life. This paper reports the findings of interviews with 14 users of CAs in an effort to understand the current interactional factors affecting everyday use. We find user expectations dramatically out of step with the operation of the systems, particularly in terms of known machine intelligence, system capability and goals. Using Norman’s “gulfs of execution and evaluation” [30] we consider the implications of these findings for the design of future systems.}, booktitle={Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems}, publisher={Association for Computing Machinery}, author={Luger, Ewa and Sellen, Abigail}, year={2016}, month=may, pages={5286–5297}, collection={CHI ’16} }

@inproceedings{Lupetti_Murray-Rust_2024, address={New York, NY, USA}, series={CHI ’24}, title={(Un)making AI Magic: A Design Taxonomy}, ISBN={9798400703300}, url={https://dl.acm.org/doi/10.1145/3613904.3641954}, DOI={10.1145/3613904.3641954}, abstractNote={This paper examines the role that enchantment plays in the design of AI things by constructing a taxonomy of design approaches that increase or decrease the perception of magic and enchantment. We start from the design discourse surrounding recent developments in AI technologies, highlighting specific interaction qualities such as algorithmic uncertainties and errors and articulating relations to the rhetoric of magic and supernatural thinking. Through analyzing and reflecting upon 52 students’ design projects from two editions of a Masters course in design and AI, we identify seven design principles and unpack the effects of each in terms of enchantment and disenchantment. We conclude by articulating ways in which this taxonomy can be approached and appropriated by design/HCI practitioners, especially to support exploration and reflexivity.}, booktitle={Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems}, publisher={Association for Computing Machinery}, author={Lupetti, Maria Luce and Murray-Rust, Dave}, year={2024}, month=may, pages={1–21}, collection={CHI ’24} }

@inproceedings{McMillan_Jaber_2021, address={New York, NY, USA}, series={CUI ’21}, title={Leaving the Butler Behind: The Future of Role Reproduction in CUI}, ISBN={978-1-4503-8998-3}, url={https://doi.org/10.1145/3469595.3469606}, DOI={10.1145/3469595.3469606}, abstractNote={Speech technologies are increasing in popularity by offering new interaction modalities for their users. Despite the prevalence of these devices, and the rapid improvement of the underlying technology, how we actually interact with these devices has remained wrapped up in the metaphors of command and control based around the problematic reproduction of the role of butler, maid, or personal assistant. In this paper we explore the issues around focusing our development and research on making a ‘better’ subordinate, and point to some opportunities to replace and refresh the status quo.}, booktitle={CUI 2021 - 3rd Conference on Conversational User Interfaces}, publisher={Association for Computing Machinery}, author={McMillan, Donald and Jaber, Razan}, year={2021}, month=jul, pages={1–4}, collection={CUI ’21} }

@article{Moser_2000, title={Metaphor Analysis in Psychology—Method, Theory, and Fields of Application}, volume={1}, rights={Copyright (c) 2000 Karin S. Moser}, ISSN={1438-5627}, url={https://www.qualitative-research.net/index.php/fqs/article/view/1090}, DOI={10.17169/fqs-1.2.1090}, abstractNote={The analysis of metaphors is a classical research theme in linguistics, but has received very little attention in psychological research so far. Metaphor analysis—as conceptualized in cognitive linguistics—is proposed here as a qualitative method for psychological research for several reasons. Metaphors are culturally and socially defined, yet they also represent a basic cognitive strategy of analogical problem solving. Metaphors are context-sensitive, yet at the same time they are abstract models of reality much in the same way as mental models and schemata in cognitive psychology. The multifaceted properties of metaphors allow for the study of micro-interactions between cognition and culture in open and qualitative research designs. They also enable the bridging of the gap between quantitative-experimental and qualitative approaches in psychology. Because metaphors are of high plausibility in everyday experience, metaphors are a valuable tool for interventions in applied fields of research such as organizational and work psychology.
URN: urn:nbn:de:0114-fqs0002212}, number={22}, journal={Forum Qualitative Sozialforschung / Forum: Qualitative Social Research}, author={Moser, Karin S.}, year={2000}, month=jun, language={en} }

@inproceedings{Motalebi_Cho_Sundar_Abdullah_2019, address={New York, NY, USA}, series={CSCW ’19 Companion}, title={Can Alexa be your Therapist? How Back-Channeling Transforms Smart-Speakers to be Active Listeners}, ISBN={978-1-4503-6692-2}, url={https://dl.acm.org/doi/10.1145/3311957.3359502}, DOI={10.1145/3311957.3359502}, abstractNote={Smart-speakers such as Amazon Alexa are becoming increasingly popular among the general population. These devices support a wide range of user-initiated tasks. However, their current interaction capabilities are limited to quick turn-takings and short dialogues, which leads to limited user engagement. In this project, we aim to enhance the user engagement and interaction abilities of a smart-speaker by transforming it into an active listener. Specifically, we explored how providing random back-channelling (i.e., verbal continuers including “hm”, “uhum”, “aha”, “yeah”) can result in longer interactions and more sustained user engagement. The findings of the study have implications for usability and future design of smart-speakers. We also explored how the enhanced interactions in smart-speakers through back-channeling can be used for self-centered therapy leading to betTer emotional and social support.}, booktitle={Companion Publication of the 2019 Conference on Computer Supported Cooperative Work and Social Computing}, publisher={Association for Computing Machinery}, author={Motalebi, Nasim and Cho, Eugene and Sundar, S. Shyam and Abdullah, Saeed}, year={2019}, month=nov, pages={309–313}, collection={CSCW ’19 Companion} }

@inbook{Neale_Carroll_1997, address={Amsterdam}, title={Chapter 20 - The Role of Metaphors in User Interface Design}, ISBN={978-0-444-81862-1}, url={https://www.sciencedirect.com/science/article/pii/B9780444818621500868}, DOI={10.1016/B978-044481862-1.50086-8}, abstractNote={One common approach that designers have exploited for controlling complexity is to ground user interface actions, tasks, and goals in a familiar framework of concepts that are already understood. Such a framework is called a user interface metaphor. The extensive use of metaphors has had a dramatic impact on user interface design practices. Metaphors allow the transference or mapping of knowledge from a source domain to a target domain, enabling humans to use specific prior knowledge and experience for understanding and behaving in situations that are novel or unfamiliar. Through this process, one’s knowledge in the target domain is enriched by borrowing existing representations from the source domain. The fact that the associations between the source and target are hidden is the essence of metaphor. The user interface of the computer is the target domain for interface metaphors. Interface metaphors help establish user expectations and encourage predictions about system behavior. A good example is the desktop metaphor. This metaphor portrays the operating system of the computer as similar to objects, tasks, and behaviors found in physical office environments. The desktop metaphor is actually a composite of many metaphors. Most systems have a global metaphor to provide the basis of interaction that is supported by many auxiliary metaphors. This chapter presents a variety of examples that illustrate the use of metaphor. The chapter reviews classifications of interface metaphor types. Mismatches between source and target domains and the circumstances that create them are also described in the chapter. This chapter discusses the role that metaphors have in communicating the designer’s model, structuring users’ models of the interface, and their impact on the human-machine communication process.}, booktitle={Handbook of Human-Computer Interaction (Second Edition)}, publisher={North-Holland}, author={Neale, Dennis C. and Carroll, John M.}, editor={Helander, Marting G. and Landauer, Thomas K. and Prabhu, Prasad V.}, year={1997}, month=jan, pages={441–462}, language={en} }

@book{Norman_2013, address={New York, New York}, edition={Revised edition}, title={The Design Of Everyday Things}, ISBN={978-0-465-05065-9}, publisher={Basic Books}, author={Norman, Don}, year={2013}, month=nov, language={English} }

@misc{Olmstead_2017, title={Nearly half of Americans use digital voice assistants, mostly on their smartphones}, url={https://www.pewresearch.org/fact-tank/2017/12/12/nearly-half-of-americans-use-digital-voice-assistants-mostly-on-their-smartphones/}, abstractNote={Voice-controlled digital assistants are being incorporated into a wide range of consumer products, and many U.S. adults say they now use these applications.}, journal={Pew Research Center}, author={Olmstead, Kenneth}, year={2017}, language={en-US} }

@inbook{Piccinini_2003, address={Dordrecht}, series={Studies in Cognitive Systems}, title={Turing’s Rules for the Imitation Game}, ISBN={978-94-010-0105-2}, url={https://doi.org/10.1007/978-94-010-0105-2_5}, DOI={10.1007/978-94-010-0105-2_5}, abstractNote={In the 1950s, Alan Turing proposed his influential test for machine intelligence, which involved a teletyped dialogue between a human player, a machine, and an interrogator. Two readings of Turing’s rules for the test have been given. According to the standard reading of Turing’s words, the goal of the interrogator was to discover which was the human being and which was the machine, while the goal of the machine was to be indistinguishable from a human being. According to the literal reading, the goal of the machine was to simulate a man imitating a woman, while the interrogator — unaware of the real purpose of the test — was attempting to determine which of the two contestants was the woman and which was the man. The present work offers a study of Turing’s rules for the test in the context of his advocated purpose and his other texts. The conclusion is that there are several independent and mutually reinforcing lines of evidence that support the standard reading, while fitting the literal reading in Turing’s work faces severe interpretative difficulties. So, the controversy over Turing’s rules should be settled in favor of the standard reading.}, booktitle={The Turing Test: The Elusive Standard of Artificial Intelligence}, publisher={Springer Netherlands}, author={Piccinini, Gualtiero}, editor={Moor, James H.}, year={2003}, pages={111–120}, collection={Studies in Cognitive Systems}, language={en} }

@inproceedings{Pradhan_Lazar_2021, address={New York, NY, USA}, series={CUI ’21}, title={Hey Google, Do You Have a Personality? Designing Personality and Personas for Conversational Agents}, ISBN={978-1-4503-8998-3}, url={https://dl.acm.org/doi/10.1145/3469595.3469607}, DOI={10.1145/3469595.3469607}, abstractNote={Conversational agents designed to interact through natural language are often imbued with human-like personalities. At times, the agent might also have a distinct persona with traits such as gender, age, or a backstory. Designing such personality or persona for conversational agents has become a common design practice. In this work, we review the emerging literature on designing agent persona or personality, and reflect on these approaches, along with the personas that are created for common conversational agents. We discuss open questions with regards to three aspects: meeting user needs, the ethics of deception, and reinforcing social stereotypes through conversational agents. We hope this work can provoke researchers and practitioners to critically reflect on their approach for designing personality or persona of conversational agents.}, booktitle={Proceedings of the 3rd Conference on Conversational User Interfaces}, publisher={Association for Computing Machinery}, author={Pradhan, Alisha and Lazar, Amanda}, year={2021}, month=jul, pages={1–4}, collection={CUI ’21} }

@inproceedings{Purington_Taft_Sannon_Bazarova_Taylor_2017, address={New York, NY, USA}, series={CHI EA ’17}, title={“Alexa is My New BFF”: Social Roles, User Satisfaction, and Personification of the Amazon Echo}, ISBN={978-1-4503-4656-6}, url={http://doi.acm.org/10.1145/3027063.3053246}, DOI={10.1145/3027063.3053246}, abstractNote={Amazon’s Echo and its conversational agent Alexa open exciting opportunities for understanding how people perceive and interact with virtual agents. Drawing from user reviews of the Echo posted to Amazon.com, this case study explores the degree to which user reviews indicate personification of the device, sociability level of interactions, factors linked with personification, and influences on user satisfaction. Results indicate marked variance in how people refer to the device, with over half using the personified name Alexa but most referencing the device with object pronouns. Degree of device personification is linked with sociability of interactions: greater personification co-occurs with more social interactions with the Echo. Reviewers mentioning multiple member households are more likely to personify the device than reviewers mentioning living alone. Even after controlling for technical issues, personification predicts user satisfaction with the Echo.}, note={00000 
event-place: Denver, Colorado, USA}, booktitle={Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems}, publisher={ACM}, author={Purington, Amanda and Taft, Jessie G. and Sannon, Shruti and Bazarova, Natalya N. and Taylor, Samuel Hardman}, year={2017}, pages={2853–2859}, collection={CHI EA ’17} }

@inproceedings{Sadek_Calvo_Mougenot_2023, address={New York, NY, USA}, series={CUI ’23}, title={Trends, Challenges and Processes in Conversational Agent Design: Exploring Practitioners’ Views through Semi-Structured Interviews}, ISBN={9798400700149}, url={https://dl.acm.org/doi/10.1145/3571884.3597143}, DOI={10.1145/3571884.3597143}, abstractNote={The aim of this study is to explore the challenges and experiences of conversational agent (CA) practitioners in order to highlight their practical needs and bring them into consideration within the scholarly sphere. A range of data scientists, conversational designers, executive managers and researchers shared their opinions and experiences through semi-structured interviews. They were asked about emerging trends, the challenges they face, and the design processes they follow when creating CAs. In terms of trends, findings included mixed feelings regarding no-code solutions and a desire for a separation of roles. The challenges mentioned included a lack of socio-technical tools and conversational archetypes. Finally, practitioners followed different design processes and did not use the design processes described in the academic literature. These findings were analyzed to establish links between practitioners’ insights and discussions in related literature. The goal of this analysis is to highlight research-practice gaps by synthesising five practitioner needs that are not currently being met. By highlighting these research-practice gaps and foregrounding the challenges and experiences of CA practitioners, we can begin to understand the extent to which emerging literature is influencing industrial settings and where more research is needed to better support CA practitioners in their work.}, booktitle={Proceedings of the 5th International Conference on Conversational User Interfaces}, publisher={Association for Computing Machinery}, author={Sadek, Malak and Calvo, Rafael A and Mougenot, Celine}, year={2023}, month=jul, pages={1–10}, collection={CUI ’23} }

@inproceedings{Sciuto_Saini_Forlizzi_Hong_2018, address={New York, NY, USA}, series={DIS ’18}, title={“Hey Alexa, What’s Up?”: A Mixed-Methods Studies of In-Home Conversational Agent Usage}, ISBN={978-1-4503-5198-0}, url={http://doi.acm.org/10.1145/3196709.3196772}, DOI={10.1145/3196709.3196772}, abstractNote={In-home, place-based, conversational agents have exploded in popularity over the past three years. In particular, Amazon’s conversational agent, Alexa, now dominates the market and is in millions of homes. This paper presents two complementary studies investigating the experience of households living with a conversational agent over an extended period of time. First, we gathered the history logs of 75 Alexa participants and quantitatively analyzed over 278,000 commands. Second, we performed seven in-home, contextual interviews of Alexa owners focusing on how their household interacts with Alexa. Our findings give the first glimpse of how households integrate Alexa into their lives. We found interesting behaviors around purchasing and acclimating to Alexa, in the number and physical placement of devices, and in daily use patterns. Participants also uniformly described interactions between children and Alexa. We conclude with suggestions for future improvement for intelligent conversational agents.}, note={00000 
event-place: Hong Kong, China}, booktitle={Proceedings of the 2018 Designing Interactive Systems Conference}, publisher={ACM}, author={Sciuto, Alex and Saini, Arnita and Forlizzi, Jodi and Hong, Jason I.}, year={2018}, pages={857–868}, collection={DIS ’18} }

@inbook{Trajkova_Martin-Hammond_2020, address={New York, NY, USA}, title={“Alexa is a Toy”: Exploring Older Adults’ Reasons for Using, Limiting, and Abandoning Echo}, ISBN={978-1-4503-6708-0}, url={https://doi.org/10.1145/3313831.3376760}, abstractNote={Intelligent voice assistants (IVAs) have the potential to support older adults’ independent living. However, despite a growing body of research focusing on IVA use, we know little about why older adults become IVA non-users. This paper examines the reasons older adults use, limit, and abandon IVAs (i.e., Amazon Echo) in their homes. We conducted eight focus groups, with 38 older adults residing in a Life Plan Community. Thirty-six participants owned an Echo for at least a year, and two were considering adoption. Over time, most participants became non-users due to their difficulty finding valuable uses, beliefs associated with ability and IVA use, or challenges with use in shared spaces. However, we also found that participants saw the potential for future IVA support. We contribute a better understanding of the reasons older adults do not engage with IVAs and how IVAs might better support aging and independent living in the future.}, booktitle={Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems}, publisher={Association for Computing Machinery}, author={Trajkova, Milka and Martin-Hammond, Aqueasha}, year={2020}, month=apr, pages={1–13} }

@article{Turk_2016, title={Home invasion}, volume={232}, ISSN={0262-4079}, DOI={10.1016/S0262-4079(16)32318-1}, abstractNote={Voice-activated assistants like Alexa already do our bidding. Why do we want them to be our friends too, asks Victoria Turk}, number={3104}, journal={New Scientist}, author={Turk, Victoria}, year={2016}, month=dec, pages={16–17}, language={en} }

@misc{Wang_Goel_2022, title={Mutual Theory of Mind for Human-AI Communication}, url={https://arxiv.org/abs/2210.03842v2}, abstractNote={New developments are enabling AI systems to perceive, recognize, and respond with social cues based on inferences made from humans’ explicit or implicit behavioral and verbal cues. These AI systems, equipped with an equivalent of human’s Theory of Mind (ToM) capability, are currently serving as matchmakers on dating platforms, assisting student learning as teaching assistants, and enhancing productivity as work partners. They mark a new era in human-AI interaction (HAI) that diverges from traditional human-computer interaction (HCI), where computers are commonly seen as tools instead of social actors. Designing and understanding the human perceptions and experiences in this emerging HAI era becomes an urgent and critical issue for AI systems to fulfill human needs and mitigate risks across social contexts. In this paper, we posit the Mutual Theory of Mind (MToM) framework, inspired by our capability of ToM in human-human communications, to guide this new generation of HAI research by highlighting the iterative and mutual shaping nature of human-AI communication. We discuss the motivation of the MToM framework and its three key components that iteratively shape the human-AI communication in three stages. We then describe two empirical studies inspired by the MToM framework to demonstrate the power of MToM in guiding the design and understanding of human-AI communication. Finally, we discuss future research opportunities in human-AI interaction through the lens of MToM.}, journal={arXiv.org}, author={Wang, Qiaosi and Goel, Ashok K.}, year={2022}, month=oct, language={en} }

@inproceedings{Wang_Saha_Gregori_Joyner_Goel_2021, address={New York, NY, USA}, series={CHI ’21}, title={Towards Mutual Theory of Mind in Human-AI Interaction: How Language Reflects What Students Perceive About a Virtual Teaching Assistant}, ISBN={978-1-4503-8096-6}, url={https://dl.acm.org/doi/10.1145/3411764.3445645}, DOI={10.1145/3411764.3445645}, abstractNote={Building conversational agents that can conduct natural and prolonged conversations has been a major technical and design challenge, especially for community-facing conversational agents. We posit Mutual Theory of Mind as a theoretical framework to design for natural long-term human-AI interactions. From this perspective, we explore a community’s perception of a question-answering conversational agent through self-reported surveys and computational linguistic approach in the context of online education. We first examine long-term temporal changes in students’ perception of Jill Watson (JW), a virtual teaching assistant deployed in an online class discussion forum. We then explore the feasibility of inferring students’ perceptions of JW through linguistic features extracted from student-JW dialogues. We find that students’ perception of JW’s anthropomorphism and intelligence changed significantly over time. Regression analyses reveal that linguistic verbosity, readability, sentiment, diversity, and adaptability reflect student perception of JW. We discuss implications for building adaptive community-facing conversational agents as long-term companions and designing towards Mutual Theory of Mind in human-AI interaction.}, booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems}, publisher={Association for Computing Machinery}, author={Wang, Qiaosi and Saha, Koustuv and Gregori, Eric and Joyner, David and Goel, Ashok}, year={2021}, month=may, pages={1–14}, collection={CHI ’21} }

@inproceedings{Wang_Yang_Shao_Abdullah_Sundar_2020, address={New York, NY, USA}, series={CHI ’20}, title={Alexa as Coach: Leveraging Smart Speakers to Build Social Agents that Reduce Public Speaking Anxiety}, ISBN={978-1-4503-6708-0}, url={https://dl.acm.org/doi/10.1145/3313831.3376561}, DOI={10.1145/3313831.3376561}, abstractNote={Public speaking anxiety is one of the most common social phobias. We explore the feasibility of using a conversational agent to reduce this anxiety. We developed a public-speaking tutor on the Amazon Alexa platform that enables users to engage in cognitive reconstruction exercises. We also investigated how the sociability of the agent might affect its performance as a tutor. A user study of 53 college students with fear of public speaking showed that the interaction with the agent served to assuage pre-speech state anxiety. Agent sociability improved the sense of interpersonal closeness, which was associated with lower pre-speech anxiety. Moreover, sociability of the agent increased participants’ satisfaction and their willingness to continue engagement. Our findings, thus, have implications not only for addressing public speaking anxiety in a scalable way but also for the design of future conversational agents using smart speaker platforms.}, booktitle={Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems}, publisher={Association for Computing Machinery}, author={Wang, Jinping and Yang, Hyun and Shao, Ruosi and Abdullah, Saeed and Sundar, S. Shyam}, year={2020}, month=apr, pages={1–13}, collection={CHI ’20} }

