@article{HEMATI2025106920,
title = {Continual learning in the presence of repetition},
journal = {Neural Networks},
volume = {183},
pages = {106920},
year = {2025},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2024.106920},
url = {https://www.sciencedirect.com/science/article/pii/S0893608024008499},
author = {Hamed Hemati and Lorenzo Pellegrini and Xiaotian Duan and Zixuan Zhao and Fangfang Xia and Marc Masana and Benedikt Tscheschner and Eduardo Veas and Yuxiang Zheng and Shiji Zhao and Shao-Yuan Li and Sheng-Jun Huang and Vincenzo Lomonaco and Gido M. {van de Ven}},
keywords = {Continual learning, Class-incremental learning, Repetition, Competition},
abstract = {Continual learning (CL) provides a framework for training models in ever-evolving environments. Although re-occurrence of previously seen objects or tasks is common in real-world problems, the concept of repetition in the data stream is not often considered in standard benchmarks for CL. Unlike with the rehearsal mechanism in buffer-based strategies, where sample repetition is controlled by the strategy, repetition in the data stream naturally stems from the environment. This report provides a summary of the CLVision challenge at CVPR 2023, which focused on the topic of repetition in class-incremental learning. The report initially outlines the challenge objective and then describes three solutions proposed by finalist teams that aim to effectively exploit the repetition in the stream to learn continually. The experimental results from the challenge highlight the effectiveness of ensemble-based solutions that employ multiple versions of similar modules, each trained on different but overlapping subsets of classes. This report underscores the transformative potential of taking a different perspective in CL by employing repetition in the data stream to foster innovative strategy design.}
}

@article{belouadah2021comprehensive,
  title={A comprehensive study of class incremental learning algorithms for visual tasks},
  author={Belouadah, Eden and Popescu, Adrian and Kanellos, Ioannis},
  journal={Neural Networks},
  volume={135},
  pages={38--54},
  year={2021},
  publisher={Elsevier}
}

@online{clvision_challenge_2024,
  title = {{5th CLVISION CVPR} Workshop Challenge},
  year = 2023,
  url = {https://sites.google.com/view/clvision2024},
  urldate = {2024-12-18}
}

@article{empirical_catastrophic,
  title={An empirical investigation of catastrophic forgetting in gradient-based neural networks},
  author={Goodfellow, Ian J and Mirza, Mehdi and Xiao, Da and Courville, Aaron and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1312.6211},
  year={2013}
}

@article{ensembles,
  title={Ensemble deep learning: A review},
  author={Ganaie, Mudasir A and Hu, Minghui and Malik, AK and Tanveer, M and Suganthan, PN},
  journal={Engineering Applications of Artificial Intelligence},
  volume={115},
  pages={105151},
  year={2022},
  publisher={Elsevier}
}

@article{ewc,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Acad Sciences}
}

@article{experience_based_il,
  title={Three scenarios for continual learning},
  author={Van de Ven, Gido M and Tolias, Andreas S},
  journal={arXiv preprint arXiv:1904.07734},
  year={2019}
}

@InProceedings{fetril,
    author    = {Petit, Gr\'egoire and Popescu, Adrian and Schindler, Hugo and Picard, David and Delezoide, Bertrand},
    title     = {FeTrIL: Feature Translation for Exemplar-Free Class-Incremental Learning},
    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    month     = {1},
    year      = {2023},
    pages     = {3911-3920}
}

@article{french1999catastrophic,
  title={Catastrophic forgetting in connectionist networks},
  author={French, Robert M},
  journal={Trends in cognitive sciences},
  volume={3},
  number={4},
  pages={128--135},
  year={1999},
  publisher={Elsevier}
}

@article{hemati2023class,
  title={Class-Incremental Learning with Repetition},
  author={Hemati, Hamed and Cossu, Andrea and Carta, Antonio and Hurtado, Julio and Pellegrini, Lorenzo and Bacciu, Davide and Lomonaco, Vincenzo and Borth, Damian},
  journal={arXiv preprint arXiv:2301.11396},
  year={2023}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@inproceedings{icarl,
  title={icarl: Incremental classifier and representation learning},
  author={Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander and Sperl, Georg and Lampert, Christoph H},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={2001--2010},
  year={2017}
}

@article{il2a,
  title={Class-Incremental Learning via Dual Augmentation},
  author={Zhu, Fei and Cheng, Zhen and Zhang, Xu-Yao and Liu, Cheng-lin},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={14306--14318},
  year={2021}
}

@article{incremental_repetition,
  title={Is class-incremental enough for continual learning?},
  author={Cossu, Andrea and Graffieti, Gabriele and Pellegrini, Lorenzo and Maltoni, Davide and Bacciu, Davide and Carta, Antonio and Lomonaco, Vincenzo},
  journal={Frontiers in Artificial Intelligence},
  volume={5},
  pages={829842},
  year={2022},
  publisher={Frontiers Media SA}
}

@article{lwf,
  title={Learning without forgetting},
  author={Li, Zhizhong and Hoiem, Derek},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={40},
  number={12},
  pages={2935--2947},
  year={2017},
  publisher={IEEE}
}

@ARTICLE{marc_survey1,
  author={Masana, Marc and Liu, Xialei and Twardowski, Bartłomiej and Menta, Mikel and Bagdanov, Andrew D. and van de Weijer, Joost},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Class-Incremental Learning: Survey and Performance Evaluation on Image Classification}, 
  year={2023},
  volume={45},
  number={5},
  pages={5513-5533},
  doi={10.1109/TPAMI.2022.3213473}
}

@ARTICLE{marc_survey2,
  author={De Lange, Matthias and Aljundi, Rahaf and Masana, Marc and Parisot, Sarah and Jia, Xu and Leonardis, Aleš and Slabaugh, Gregory and Tuytelaars, Tinne},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={A Continual Learning Survey: Defying Forgetting in Classification Tasks}, 
  year={2022},
  volume={44},
  number={7},
  pages={3366-3385},
  doi={10.1109/TPAMI.2021.3057446}
}

@inproceedings{mas,
  title={Memory aware synapses: Learning what (not) to forget},
  author={Aljundi, Rahaf and Babiloni, Francesca and Elhoseiny, Mohamed and Rohrbach, Marcus and Tuytelaars, Tinne},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={139--154},
  year={2018}
}

@inproceedings{masana2020ternary,
  title={Ternary Feature Masks: continual learning without any forgetting},
  author={Masana, Marc and Tuytelaars, Tinne and van de Weijer, Joost},
  booktitle={Proc. IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  year={2021}
}

@InProceedings{pass,
    author    = {Zhu, Fei and Zhang, Xu-Yao and Wang, Chuang and Yin, Fei and Liu, Cheng-Lin},
    title     = {Prototype Augmentation and Self-Supervision for Incremental Learning},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {6},
    year      = {2021},
    pages     = {5871-5880}
}

@InProceedings{plastil,
    author    = {Petit, Gr\'egoire and Popescu, Adrian and Belouadah, Eden  and Picard, David and Delezoide, Bertrand},
    title     = {PlaStIL: Plastic and Stable Memory-Free Class-Incremental Learning},
    booktitle = {Second Conference on Lifelong Learning Agents (CoLLAs)},
    month     = {8},
    year      = {2023}
}

@inproceedings{praka,
  title={Prototype Reminiscence and Augmented Asymmetric Knowledge Aggregation for Non-Exemplar Class-In\-cremental Learning},
  author={Shi, Wuxuan and Ye, Mang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1772--1781},
  year={2023}
}

@article{rolnick2019experience,
  title={Experience replay for continual learning},
  author={Rolnick, David and Ahuja, Arun and Schwarz, Jonathan and Lillicrap, Timothy and Wayne, Gregory},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{ssre,
  title={Self-sustaining representation expansion for non-exemplar class-incremental learning},
  author={Zhu, Kai and Zhai, Wei and Cao, Yang and Luo, Jiebo and Zha, Zheng-Jun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9296--9305},
  year={2022}
}

@ARTICLE{stability_plasticity,
AUTHOR={Mermillod, Martial and Bugaiska, Aurélia and BONIN, Patrick},   
TITLE={The stability-plasticity dilemma: investigating the continuum from catastrophic forgetting to age-limited learning effects},      
JOURNAL={Frontiers in Psychology},      
VOLUME={4},           
YEAR={2013},      
URL={https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00504},       
DOI={10.3389/fpsyg.2013.00504},      
ISSN={1664-1078}   
}

@InProceedings{survey_class_incremental,
author="Yang, Dejie
and Zheng, Minghang
and Wang, Weishuai
and Li, Sizhe
and Liu, Yang",
editor="Lu, Huchuan
and Ouyang, Wanli
and Huang, Hui
and Lu, Jiwen
and Liu, Risheng
and Dong, Jing
and Xu, Min",
title="Recent Advances in Class-Incremental Learning",
booktitle="Image and Graphics",
year="2023",
publisher="Springer Nature Switzerland",
address="Cham",
pages="212--224",
abstract="A large number of deep learning models have been applied in a wide range of fields nowadays. However, most existing models can only generalize to the categories in the training set and are unable to learn new categories incrementally. In practical applications, new categories or tasks will constantly emerge, which requires models to continuously learn new category knowledge like humans while maintaining existing category knowledge. Such the learning process, i.e., class-incremental learning (CIL), abstracts more attention from the research community. CIL faces several challenges, such as imbalanced data distribution, limited model memory capacity, and the catastrophic forgetting of category representation. Therefore, we provide an up-to-date and detailed overview of CIL methods in this survey, including data-based, model-based, and representation-based approaches. We also discuss the impact of pre-trained models on CIL and compare the latest methods on widely-used benchmarks. Finally, we summarize the challenges and future directions of CIL.",
isbn="978-3-031-46308-2"
}

