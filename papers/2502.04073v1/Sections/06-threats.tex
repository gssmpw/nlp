\section{Threats to Validity}
\label{Section:Threats}

In this section, we describe potential threats to the validity of our research method and the actions we took to mitigate them.

\textbf{Internal Validity.} The accuracy of our analysis is primarily dependent on the precision of the refactoring mining tools, as these tools may miss the detection of some refactorings. However, previous studies \citep{silva2016we,tsantalis2018accurate,silva2017refdiff} report that \texttt{RefactoringMiner} and \texttt{RefDiff} have high precision and recall scores compared to other state-of-the-art refactoring detection tools, giving us confidence in using the tools. Another potential threat to validity is related to commit messages. \textcolor{black}{This study does not exclude commits containing tangle code changes \citep{herzig2016impact,kirinuki2014hey}, where developers made changes related to different tasks and one of these tasks could be related to quality improvement. If these changes were committed at once, there is a possibility that the individual changes merge and that the original task cannot be traced back. Similarly to the previous study \cite{pantiuchina2018improving}, we did not consider filtering out such changes in this study}. Moreover, our manual analysis is time-consuming and error-prone, which we tried to mitigate by focusing mainly on commits known to contain refactorings. 

Another potential threat to validity is sample bias, where the choice of the data can directly impact the results. Therefore, we explored a large sample of projects from the SmartSHARK dataset \citep{trautsch2021msr}, to ensure the quality of the findings and diversify the sources to reduce the bias of the data belonging to the same entity. The qualitative analysis was conducted by a single author, which could introduce bias into the process. However, commits that were debatable were discarded. We also provide our dataset online for further refinement and analysis. %During our qualitative analysis, we consideblack only commits where a consensus between authors was reached on whether a message clearly states the removal of duplicate code. Commits that were debatable were discarded. We also provide our dataset online for further refinement and analysis.

\textbf{Construct Validity.} A potential threat to construct validity relates to the set of metrics, as it may miss some properties of the selected internal quality attributes. To address this potential threat, we mitigate it by choosing well-known metrics that encompass various properties of each attribute, as reported in the literature \citep{chidamber1994metrics}.

\textbf{External Validity.} Our analysis was limited to only open-source Java projects. However, we were able to examine 128 projects, which were well-commented and exhibited diversity in terms of size, contributors, number of commits, and refactorings. \textcolor{black}{Still, we believe that the results found in this study are largely language-agnostic. However, certain language-specific characteristics, such as syntax complexity and tooling support, can influence duplication patterns. Although we expect similar trends across languages with similar paradigms, a comprehensive analysis encompassing various languages is recommended to confirm this generalization.}

%Still, we believe that the removal of duplicates is largely language-agnostic. However, certain language-specific characteristics, such as syntax complexity and tooling support, can influence duplication patterns. Although we expect similar trends across languages with similar paradigms, a comprehensive analysis encompassing various languages is suggested to is recommended to confirm this generalization.