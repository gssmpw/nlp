% 
% Annual Cognitive Science Conference
% Sample LaTeX Paper -- Proceedings Format
% 




%% Change "letterpaper" in the following line to "a4paper" if you must.

\documentclass[10pt,letterpaper]{article}

\usepackage{cogsci}

\cogscifinalcopy % Uncomment this line for the final submission 

\usepackage{graphicx}
\usepackage{pslatex}
\usepackage{apacite}
\usepackage{float} % Roger Levy added this and changed figure/table
                   % placement to [H] for conformity to Word template,
                   % though floating tables and figures to top is
                   % still generally recommended!

%\usepackage[none]{hyphenat} % Sometimes it can be useful to turn off
%hyphenation for purposes such as spell checking of the resulting
%PDF.  Uncomment this block to turn off hyphenation.


%\setlength\titlebox{4.5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 4.5cm (the original size).
%%If you do, we reserve the right to require you to change it back in
%%the camera-ready version, which could interfere with the timely
%%appearance of your paper in the Proceedings.

\title{The Dynamics of Collective Creativity in Human-AI Social Networks}
 
\author{
\large
\textbf{Shota Shiiku\textsuperscript{1, 5}, Raja Marjieh\textsuperscript{2}, Manuel Anglada-Tort\textsuperscript{3, 5}, Nori Jacoby\textsuperscript{4, 5}} \\
\textsuperscript{1}Graduate School of Science and Technology, Shizuoka University, Hamamatsu, Japan\\
\textsuperscript{2}Department of Psychology, Princeton University, Princeton, USA\\
\textsuperscript{3}Department of Psychology, Goldsmiths, University of London, London, UK\\
\textsuperscript{4}Department of Psychology, Cornell University, Ithaca, USA \\
\textsuperscript{5}Max Planck Institute for Empirical Aesthetics, Frankfurt am Main, Germany
}


\begin{document}

\maketitle

\begin{abstract}
Generative AI is reshaping modern culture, enabling individuals to create high-quality outputs across domains such as images, text, and music. However, we know little about the impact of generative AI on collective creativity. This study investigates how human-AI interactions shape collective creativity within experimental social networks. We conducted large-scale online experiments with 879 participants and AI agents in a creative writing task. Participants (either humans or AI) joined 5×5 grid-based networks, and were asked to iteratively select, modify, and share stories. Initially, AI-only networks showed greater creativity (rated by a separate group of 94 human raters) and diversity than human-only and human-AI networks. However, over time, hybrid human-AI networks became more diverse in their creations than AI-only networks. In part, this is because AI agents retained little from the original stories, while human-only networks preserved continuity. These findings highlight the value of experimental social networks in understanding human-AI hybrid societies.
%However, its influence on collective action remains largely unexplored, in part because of the lack of scalable experimental methods to study hybrid societies as a unit of analysis
%However, its influence on collective action and cultural evolution remains largely unexplored. 

\textbf{Keywords:} 
social networks; collective intelligence; large language models; creativity
\end{abstract}

\section{Introduction}
From cave paintings to symphonies, creativity has defined the human experience – our ability to imagine new possibilities and bring them to life. Today, we stand at a fascinating turning point as generative artificial intelligence (AI) – or AI agents – are transforming the creative process by which humans formulate ideas and put them into practice \cite{epstein2023art}. These AI agents are not merely assisting tools but active partners in the creative process \cite{collins2024building, brinkmann2023machine}, collaborating with writers, musicians, and artists in unprecedented ways. In this hybrid society, networks of interacting humans and intelligent machines constitute complex social systems for which the quality of the collective outcomes cannot be deduced from either human or AI behaviour alone \cite{tsvetkova2024new}. However, studying how collective creativity emerges in hybrid networks of humans and AI agents remains a key challenge.

While generative AI has been shown to increase the quality and efficiency of routine tasks – such as customer support, programming, and academic writing \cite{vaccaro2024combinations}, its impact on human creativity remains poorly understood. Some evidence suggests that human-AI collaboration may enhance individual's creativity \cite{doshi2024generative, lee2024empirical}, increasing the efficiency and speed of generating new ideas. In contrast, other evidence suggests that aesthetic and cultural biases embedded in generative AI models can limit global diversity, leading to homogenization effects in art and culture \cite{anderson2024homogenization, doshi2024generative}. Although this research has begun to demonstrate the potential impacts of generative AI on human creativity, it has thus far been difficult to quantify how much of human creative potential is driven by specific interactions, and how these can be enhanced by human-AI collaboration. In part, this is because studying these processes in controlled and scalable experimental settings is challenging.

Here, we developed an automated experimental pipeline to study collective creativity in social networks involving humans and generative AI, building on our recent method for integrating human participants within simulated experimental social networks \cite{marjieh2025characterizing}. In each “generation” of the experiment, participants (either human or AI) select and modify creative stories from their network neighbours and share their creations with participants in the next generation (Figure \ref{story_example}A). Over time, features of the collective creations emerge and evolve (e.g., quality, diversity), allowing us to establish causal links between experimental conditions – such as different levels of human-AI interaction –  and the emergence of collective creativity. Specifically, we systematically compare (1) human-only, (2) AI-only, and (3) human-AI collaboration within the same simulated networks (Figure \ref{story_example}B). We focus on storytelling, an iterative cognitive process \cite{hayes2012modeling, flower1981cognitive} central to many creative problems in the real-word, such as scientific writing, entertainment, marketing, and design. This creative modality has substantial opportunities for generative AI to collaboratively ideate and create with humans, for example, by helping to brainstorm new ideas, generate storylines, and improve their writing style and tone \cite{collins2024building, doshi2024generative}.


Our approach offers valuable insights into the conditions that enable effective human-AI collaboration and the dynamics of these interactions — particularly how diversity and creativity emerge and shift over iterative creative processes. More broadly, this work highlights the potential of real-world experiments with ecologically valid, open-ended tasks as a powerful approach for studying human-AI collective intelligence and creativity. 
% \newpage


\begin{figure*}[t]
\begin{center}
\includegraphics[width=\textwidth]{./figures/overviews.png}
\caption{Experimental framework for studying collective creativity. (A) Participants join social networks and engage in a creative writing task where short stories are selected, modified, and transmitted over many iterations (B) We study three network configurations: human-only, AI-only, and human-AI. (C) The creativity of stories is assessed by a separate group of human raters.}
\end{center}
\label{story_example}
\end{figure*} 

\section{Background}
\subsection{AI as a Tool}

Generative AI models can now produce high-quality, human-like content across various modalities, including text (Vaswani et al., 2017; Ouyang et al., 2022), images (Ramesh et al., 2022), and speech (Kumar et al., 2023). This has led to the development of a diverse range of AI-driven tools. 
These include coding assistants like GitHub Copilot, applications in medicine (Jumper et al., 2021), robotics (Murphy, 2019), autonomous vehicles (Badue et al., 2021), and even AI-assisted scientific research (Romera-Paredes, 2024).

Yet, how effective are AI tools? Despite increasing investment in development, research on AI-assisted decision-making presents mixed findings. While some studies indicate that AI enhances performance in domains such as healthcare, customer service, and scientific research \cite{liu2021understanding,chen2023understanding}, others suggest the opposite \cite{bansal2021does, zhang2020effect}. A recent systematic review and meta-analysis of 106 experimental studies (Vaccaro et al., 2024) confirmed this divide, though, on average, human-AI teams performed better than humans working alone.
One promising approach to improving human-AI collaboration is to conceptualize AI as a “thought partner”—an active participant in cognitive processes that engages in reciprocal dialogue with human users (Collins et al., 2024). Unlike traditional AI tools, machine “thought partners” dynamically infer human intentions and internal states, adapting their responses in ways that mirror human-to-human interactions, thereby fostering deeper and more productive collaboration.

\subsection{Human-AI Collaboration}

The integration of AI into human society has far-reaching implications, particularly at the collective level. AI influences not just individuals but also the broader dynamics of social systems \cite{ brinkmann2023machine}. Thus, it is becoming incredibly important to understand the role of generative AI in shaping collective behavior, focusing on the emergent structures that arise from interactions between multiple individuals and AI agents simultaneously \cite{burton2024large, tsvetkova2024new}.

Recent advances in computational and experimental techniques now make it possible to study how collective behavior emerges in social networks \cite{centola2022network, malone2022handbook}. Researchers have examined the effects of network size and topology in artificial social networks composed of human agents, revealing how structural factors influence consensus formation and collective intelligence \cite{centola2015spontaneous, derex2013experimental, rand2011dynamic}. For instance, \citeA{shirado2017locally} demonstrated that introducing noise into a system—such as simple bot agents—can enhance consensus by pushing the system out of local minima. However, previous studies have focused almost exclusively on simple, one-dimensional tasks, where solutions are predefined within the problem space, such as problem-solving, inference, and decision-making. Creativity, in contrast, requires engagement with open-ended challenges, vast exploration-exploitation spaces, and complex problem-solving environments. 

\subsection{Creativity Research }

Human creativity research has extensively used psychometric measures of creative processes for decades \cite{kaufman2010cambridge}. Traditional ``creativity tests''  -- such as the Structure of the Intellect divergent production tests \cite{guilford1967nature} and Tests of Creative Thinking \cite{torrance1966torrance} -- remain in wide use in creativity research to this day. These tests rely on simple measures of association, such as generating lists of non-repeating words or brainstorming novel uses for a given object. Advances in computational models of semantic networks provide powerful solutions to address limitations in previous research, allowing researchers to quantitatively examine how people navigate a semantic space of concepts and revealing key search strategies associated with creativity \cite{beaty2023associative}. Moreover, some studies have explored open-ended creative tasks that do not rely on language, such as visual art creation on grid-based images, modeling the balance between exploration and exploitation in creative processes using computational approaches \cite{kumar2024comparing, hart2017creative, hart2018creative}. However, this research primarily treats creativity at the individual level and does not consider AI as an integral part of the creative process.

\subsection{Collective Creativity in Human-AI Hybrid Societies}
The introduction of AI is fundamentally reshaping human creativity \cite{epstein2023art}, where AI agents not only collaborate with individuals but also shape the social environments in which humans operate \cite{tsvetkova2024new}. This nonlinear influence presents a significant challenge for studying human-AI interactions at a collective level. \citeA{doshi2024generative} demonstrated that while generative AI can enhance individual creativity, it may simultaneously reduce collective diversity, the range and originality of ideas produced by a group. Although this study provides an important initial look at the collective consequences of AI-driven creativity, it did not capture how these effects evolve among diverse agents interacting over time within social networks. 

Our approach addresses these limitations by introducing a method that is both ecologically valid and open-ended, enabling the study of large-scale social interactions involving hundreds of participants within social networks. Here, we leveraged our recent capability to design experiments that incorporate real human participants within experimental social networks \cite{marjieh2025characterizing}.
By using iterative storytelling as a creative task, we examine how ideas propagate, transform, and diversify in networks the involve humans, AI, and hybrid human-AI collaborations. This framework allows us to analyze the complex interplay between human and AI agents in dynamic creative processes at a collective level.




\section{Method}
\subsection{Participants}
Participants were recruited online via Prolific\footnote{\url{www.prolific.com}}. All participants were recruited from the UK and identified English as their native language. In total, we recruited 879 human participants and conducted 996 calls to GPT-4o~\cite{hurst2024gpt}, using the version released on September 3, 2024. Particiapnts provided informed consent in accordance with an approved ethics protocol (Max Planck Ethics Council \#202142), and were compensated at a rate of £9 per hour. 


\begin{figure*}[t] 
\centering
 \includegraphics[width=\textwidth]{./figures/creativity_diversity.png} 
 \caption{ The dynamics of collective creativity. (A) Mean creativity ratings of stories over time, as evaluated by human participants.
(B) Diversity of stories (inverse similarity) over time. The horizontal axis represents the 25 iterations, grouped into five sets of five iterations each. Error bars represent one standard deviation, computed across participants. (C-D) Creativity and diversity gain: The improvement in measured creativity and diversity from the first iteration to the last.} 
\label{creativity} 
\end{figure*}

\subsection{Network Experiments on Collective Creativity}
We conducted large-scale online experiments on collective creativity, where participants (either human or AI) were embedded in a 5$\times$5 social network and engaged in a creative storytelling task. Participants selected and modified stories from their neighbours in the netowrk, and their creations were presented to other participants over 25 iterations (Figure \ref{story_example}A). The same prompt was used for both human and AI agents: \textit{Please creatively elaborate on the story, adding your own details and ideas}''. Participants were randomly assigned to one location (node) in the network and only contributed once to the experiment. All networks were initialized with the same story:
\begin{quote}
        ``\textit{As John reached for his front door, he realized his key was missing. Panic set in as he searched his pockets, but the key was nowhere to be found. Feeling defeated, he slumped against the door, only to hear a jingle from inside—his cat had been playing with the key all along.}''
\end{quote}

We compared three experimental conditions (Figure \ref{story_example}B): (1) \textit{human-only}, where all nodes were occupied by human participants (N=625), (2) \textit{AI-only}, where all nodes were simulated using GPT-4o (625 calls to the OpenAI API, and (3) \textit{human-AI}, consisting of an equal distribution of human participants (N=254, 50\%) and GPT-4o agents (50\%).  

All experiments were conducted using PsyNet\footnote{\url{www.psynet.dev}}, a Python-based framework for advanced online psychological experiments~\cite{harrison2020gibbs}. 




\subsection{Measures of Creativity}
To asses the quality of creations across conditions, we conducted a validation study with a separate group of 100 human participants. Each participant was presented with a randomized selection of stories from all experimental conditions and asked to rate their creativity on a 5-point scale, ranging from 1 (not creative at all) to 5 (extremely creative). Each participant evaluated 20 different stories. Crucially, participants were not informed whether stories were created by humans or AI. 

In addition to subjective creativity, we measured the diversity of stories by computing their semantic similarity. Specifically, we embedded each story using a TF-IDF vectorization approach and calculated the pairwise cosine similarity between all stories within predefined iteration groups. Diversity was operationalized as the inverse of the mean cosine similarity, with lower similarity indicating greater diversity. 


\section{Results}
\subsection{Creativity and Diversity}
We begin by examining the dynamics of collective creativity across the three experimental conditions. Figure~\ref{creativity}A shows the average creativity ratings from the validation study across the three conditions over time. The \textit{AI-only} condition exhibited the highest creativity rating ($M = 3.571,\, SD = 1.026$, 95\% CI: [3.491, 3.652]), significantly higher than both \textit{Human-only} and \textit{Human-AI} conditions ($p < .001$). The average creativity ratings in the \textit{Human-only} condition ($M = 2.482,\, SD = 1.026$, 95\% CI: [2.389, 2.576]) were similar to the \textit{Human-AI} condition ($M = 2.327,\, SD = 1.159$, 95\% CI: [2.184, 2.576]; $p < .001$). This result demostrates that GPT easily surpasses humans in simple creative writing tasks, even when evaluated by human raters. Interestingly, AI-only and Human-AI networks consistently improved over time, showing a significantly positive gain by the end of the experiment (GPT: $M = 0.464$, $SD = 0.154$, $p < 0.001$, Human-AI: $M = 0.264$, $SD = 0.175$, $p < 0.001$), but Human-only networks did not improve over time ($M = -0.133$, $SD = 0.067$, $p = 1.000$) (Figure \ref{creativity}C).

Next, we looked at the diversity of collective creations (Figure~\ref{creativity}B and D). Here, the \textit{AI-only} condition exhibited the highest diversity ($M = 0.880, SD = 0.017$, 95\% CI: [0.859, 0.900]), followed by \textit{Human-AI} ($M = 0.860, SD = 0.043$, 95\% CI: [0.806, 0.913]), and \textit{Human-only}, which showed the lowest diversity ($M = 0.823, SD = 0.019$, 95\% CI: [0.800, 0.900]). 

However, the evolution of collective creativity revealed an intriguing finding. Initially (iteration 1-5), stories in the \textit{AI-only} network were the highest in creativity and diversity, but over iterations, diversity steadily declined, with a drop of $M = -0.034$,\, $SD =0.17$, 95\% CI: [-0.047, -0.021] (Figure \ref{creativity}D). In contrast, the \textit{Human-AI} network started with lower collective diversity (similar levels to \textit{Human-only}) but exhibited the largest increase over time ($M = 0.098$, $SD =0.039$, 95\% CI: [0.064, 0.131]), ultimately achieving the highest overall diversity score in the final iterations.


\begin{figure}[ht]
\includegraphics[width=\columnwidth]{./figures/embedding.png}
\caption{UMAP projection of the shared semantic embedding space, highlighting word clouds for specific clusters.}
\label{umap}
\end{figure} 

\begin{figure*}[t]
\centering
\includegraphics[width=1.03\textwidth]{./figures/terms.png}

\caption{Term dynamics by condition: Words are plotted along the horizontal axis, and generations are plotted along the vertical axis. A circle at position $(x, y)$ indicates that the word $x$ was used in a story at iteration $y$. A line denotes that the corresponding word was used by successive iterations. The size of the circle represents the frequency of the word’s appearance in the same iteration.}
\label{term}
\end{figure*}

\subsection{Semantic Analysis of Stories}

To visualize the difference between human and AI-generated stories, we created a semantic embedding space based on all written stories. Figure~\ref{umap} shows the UMAP embedding of the stories, visualizing the dynamics between the three conditions. Each point represents a single story, and the proximity of points reflects their semantic similarity in the original high-dimensional space. To compute the high-dimensional space, we first generated semantic embeddings for each story using a pre-trained model (all-MiniLM-L6-v2; \citeNP{wang2020minilm}). We then applied UMAP to reduce these embeddings to two dimensions, allowing us to visualize the semantic similarities among the stories.

Three key insights emerge from this analysis. First, the \textit{Human-only} and \textit{AI-only} conditions exhibit distinct clusters, indicating a marked difference in the language and semantics employed in their stories. The word cloud on the bottom right of Figure \ref{umap} shows that space-related words such as ``universe'' and ``cosmic'' are created when AI are involved in story generation. The word clouds on the left of Figure~\ref{umap} (largely composed from human data), on the other hand, suggest that story themes remain close to the original seed story (e.g., they share many of the same keywords, such as ``John'' and ``Key''). Second, the \textit{Human-only} condition exhibited additional human names such as “Amanda”, ``David'', and ``Tom'' suggesting potential shifts in the protagonist or narrative content, and indicating a distinct subgroup within the generated stories.
Third, in the \textit{Human-AI} condition, humans adopted a compromise in vocabulary and semantics, resulting in narratives that interpolate between the twe other conditions, suggesting that humans can be influenced by new ideas generated by AI. 
These clusters represent emergent ``niches'' in storytelling styles, characterized by unique interactions between human creativity and AI-driven semantic expansion.

Finally, to understand the shifts in narrative dynamics, we computed the frequency of dominant words in the story chracterized by TF-IDF scores. We combined all stories across conditions, calculated the TF-IDF for each term, and sorted them so that the most frequent terms are identified.
Figure~\ref{term} shows the dynamics of change in the narrative. Each  chain shows specific term prevalence over iterations, with circle size indicating the frequency of the term in the iteration. We can see that the longevity of specific keywords vary significantly depending on the condition. For example, certain words such as ``dreams'', ``danced'' and ``celestial'' only emerge and persist under the \textit{AI-only} condition. Conversely, words from the original story, including ``John'',  ``cat'', and ``keys'' persist until the end of the experiment only in the \textit{Human-only} condition. This suggests that humans tend to create new narratives that remain closely aligned with the original storyline, while AI outputs exhibited a unique tendency to converge on certain creative themes, such as space-related narratives, which were consistent across iterations. This convergence, while creative, can potentially indicate  difference in how AI agents interpert the task compared with humans.

\section{Discussion}
This study explored how the interplay between human and AI creativity in a storytelling task influences collective creative in experimental social networks. We examined three distinct network configurations -- human-only, AI-only, and human–AI -- to understand whether human-AI collaboration led people towards greater creativity. 

Our findings reveal that, from the outset, AI-only networks exhibited the highest levels of creativity and diversity compared to human-only and mixed networks. Over successive iterations, the creativity advantage of AI-only networks remained robust, suggesting that GPT’s ability to generate novel and divergent narratives was particularly well-suited to this task. However, while AI-generated stories initially displayed high diversity, this gradually declined over time. This suggests that although GPT can introduce novel ideas, it also exhibits a form of thematic convergence over time, leading to a reduction in overall diversity. This result complements previous evidence showing that while AI can enhance individual creativity, it may simultaneously reduce collective diversity \cite{doshi2024generative}.

In contrast, human-AI networks, which initially demonstrated lower diversity, ended up surpassing the diversity generated by AI-only networks. This shift was primarily driven by the distinct ways in which humans and AI approached the task. While AI frequently disregarded core narrative elements in favor of novel inventions, human participants tended to retain key story components, such as character identities (e.g., maintaining the protagonist, John) and objects (e.g., `keys'). The interplay between humans and AI in mixed networks enabled a dynamic balance between stability and novelty, enabling them to produce increasingly diverse outputs over time. This suggests that collaboration between humans and AI can harness the strengths of both, leading to richer and more diverse creative outcomes.

A crucial consideration in interpreting our results is the nature of the creative task itself. The storytelling task used in this study aligns with those traditionally employed in human creativity research \cite{kaufman2010cambridge, beaty2023associative}. However, the task proved to be relatively easy for a large language models like GPT, which consistently outperformed humans alone both in creativity and diversity. This does not necessarily imply that AI is intrinsically more creative than humans; rather, it highlights the limitations of using tasks designed for human cognition as benchmarks for AI creativity. AI’s advantage may stem from its ability to rapidly generate highly novel yet semantically coherent text, a skill optimized by its training on vast datasets \cite{burton2024large, brinkmann2023machine}. Conversely, human creativity and creative writing is influenced by memory constraints, cognitive biases, and adherence to implicit narrative conventions \cite{hayes2012modeling}. 

Moving forward, creativity research should move beyond simple tasks that may be well-suited for assessing individual human creativity but fall short in evaluating AI capabilities or capturing the dynamics of human–AI synergy. For example, using multimodal creative tasks that do not only rely on language, such as music creation \cite{anglada2023large} and drawings \cite{kumar2024comparing, hart2017creative, hart2018creative}. Moreover, future studies should focus on designing complex tasks that challenge both humans and AI in meaningful ways, allowing for a more nuanced understanding of collective creativity and underlying mechanisms. 


\section{Limitations and conclusion}
Our study aimed to simulate social-naturalistic dynamics within experimental societies. However, our approach diverges from how ecologically valid social interactions unfold in the real world. Unlike our experiments, where participants engaged only once, individuals in real-world settings continuously interact with each other over time. Additionally, real-world exchanges are far more complex than the constrained task of creating simple stories used in our experiment. Another key limitation is the static structure of our simulated social network, which used a grid-based topology. Real social networks, such as groups of friends or work relationships, tend to have a modular structure with irregular patterns and evolving connections, allowing individuals to actively shape their interactions by forming and adjusting their social ties rather than being confined to static connections. Finally, our paradigm avoids any direct communication between participants and masks agent information, such as whether your partner is a human or an AI. 

Despite these limitations, none of these constraints are inherent to our methodological approach. Our framework can be extended to incorporate more ecologically valid dynamics, including persistent interactions, evolving social structures, and greater participant agency. Our approach can also be extended to non-verbal, open-ended creative task, such as music and visual art. While our study represents only an initial exploration of hybrid experimental social networks, it highlights the vast potential of this approach for future research in cognitive and computer science.


\bibliographystyle{apacite}

\setlength{\bibleftmargin}{.125in}
\setlength{\bibindent}{-\bibleftmargin}

\bibliography{CogSci_Template}


\end{document}
