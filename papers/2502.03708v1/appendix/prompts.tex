\section{Steering details: prompts, datasets, and parameters}
\label{app: prompts}

We now describe the parameters and prompts used for steering Llama-3.1-8B-it and Gemma-2-9B-it toward different concepts.

\subsection{Our prompting method}

We consider a specific example to explain our prompting method, where we extract directions to induce different identities from the surname `Newton'. To extract semantically meaningful directions from the activation spaces of LLMs for steering, we first choose a list of labeled prompts for a list of desired concepts, similar to the approaches of \citet{representation_engineering, turner2023activation}. However, unlike their methods, our prompts do not need to consist of contrastive pairs of positive and negative examples. Further, we found benefit in some cases by choosing prompts to be from real text, and not synthetic datasets. For example, we extracted meaningful concepts corresponding to political positions and disambiguating word meanings from pairs of Wikipedia articles. 

Consider the specific case of distinguishing Cam Newton versus Isaac Newton (Figure~\ref{fig: rfm/pca newton, llama-3.1-8B}). We obtain sentences from the Isaac and Cam Newton wikipedia articles. 
Suppose we want to learn the vector for `Isaac' Newton. Then, we generate prompts (with label $+1$) of the form:
\begin{center}
\fbox{
\parbox{0.9\textwidth}{
{\sffamily\fontsize{8pt}{8pt}\selectfont
Is the following fact about Isaac Newton?\\
Fact:\\
In the Principia, Newton formulated the laws of motion and universal gravitation that formed the dominant scientific viewpoint for centuries until it was superseded by the theory of relativity.}
}
}
\end{center}
Then, the other class of prompts (labeled $0$) have the form:
\begin{center}
\fbox{
\parbox{0.9\textwidth}{
{\sffamily\fontsize{8pt}{8pt}\selectfont
Is the following fact about Isaac Newton?\\
Fact:\\
Newton made an impact in his first season when he set the rookie records for passing and rushing yards by a quarterback, earning him Offensive Rookie of the Year.}
}
}
\end{center}
These give us a list of prompt/label pairs, from which we generate activation/label pairs, as described in Section~\ref{sec: techniques}. We then solve RFM (or another layer-wise predictor) on each layer to predict the label function (Isaac vs. Cam Newton). For RFM, the concept vectors at each layer $c_\ell$ are then the top eigenvectors of the AGOP from each RFM predictor.

\subsection{Human Languages} For triggering language switches as in Figures~\ref{fig: english_chinese, llama-3.1-8B} and \ref{fig: english_spanish, llama-3.1-8B}, we used examples generated from the following prompt template.

\begin{center}
\fbox{\parbox{0.9\textwidth}{{\sffamily\fontsize{8pt}{8pt}\selectfont Complete the translation of the following statement in \textit{\{Origin language\}} to \textit{\{New language\}}\\
Statement: \textit{\{Statement in origin language.\}}\\ Translation: \textit{\{Partial translation in new language.\}} }
}
}
\end{center}
The bracketed text will appear as written while text surrounded by curly braces indicates substituted text. We obtained list of statements in the origin and new languages from datasets of translated statements. To generate the partial translations we truncated translations to the first half of the tokens. For Spanish/English translations we used datasets from \url{https://github.com/jatinmandav/Neural-Machine-Translation/tree/master}. For Mandarin/English, we obtained pairs of statements from \url{https://huggingface.co/datasets/swaption2009/20k-en-zh-translation-pinyin-hsk}. 

To evaluate translations for human language, we use OpenAI's o1 reasoning model to generate a list of 100 English statements and questions. We then evaluate the translation from steering of each sentence.

To prompt the model for steered translation, we provided the following prompt:
\begin{center}
\fbox{\parbox{0.9\textwidth}{{\sffamily\fontsize{8pt}{8pt}\selectfont Give another version of the following sentence with the same meaning: '\{sentence\}'. Write the version in quotes.}
}
}
\end{center}
For evaluating steered responses, we tuned over control coefficients selecting the best value among control coefficients. We steer the outputs of all blocks of the transformer. For Llama-3.1-8B-it, we tuned over coefficients: 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, and for Gemma-2-9B-it: 4.0, 5.0, 6.0, 7.0, 8.0, 9.0. Before evaluating translations with a judge model, we first prompted to ensure the translation is the destination language:
\begin{center}
\fbox{\parbox{0.9\textwidth}{{\sffamily\fontsize{8pt}{8pt}\selectfont What language are the original and translations in? Give your answer in the format '\{Original language\}, \{Translation language\}'. If the translation is empty, assume Language 2 is English."}
}
}
\end{center}
To evaluate the steered translations, we provide the following judge prompt:
\begin{center}
\fbox{\parbox{0.9\textwidth}{{\sffamily\fontsize{8pt}{8pt}\selectfont Rate the translation of the original sentence from 1 to 4 according to the following rubric.\\\\
Score of 1: The translation is mostly inaccurate or unrelated.\\
Score of 2: The translation is slightly unrelated to the original.\\
Score of 3: The translation has mostly the same meaning as the original.\\
Score of 4: The translation has the same meaning as the original.\\\\
Give your response in the format '{score}/4.' Do not penalize awkward or excessive wording. If the translation is empty, give a score of 0.\\
----------------------------------------\\
ORIGINAL: \{original\}\\
----------------------------------------\\
TRANSLATION: \{translation\}"}
}
}
\end{center}

\subsection{Poetry} Prompts for poetry followed the same format as human languages. We obtained 100 pairs of standard English sentences and poetic translations from OpenAI's o1 model. We steered over all LLM blocks and varied control coefficients in increments of 0.1 over 0.4 to 0.8. Figure~\ref{fig: steered poetry style} uses coefficient 0.6. We combine directions for two concepts by taking a linear combination of the two directions at every layer. For poetry and dishonesty (Figure~\ref{fig: main figure}), we use $a=1.2,b=1.0$ as the multiple for each concept, respectively, then use coefficient $0.4$ on the combined vector across all blocks. 

\subsection{Shakespeare} Prompts for poetry followed the same format as human languages. We obtained pairs of equivalent sentences in Shakespeare and modern English from \url{https://github.com/harsh19/Shakespearizing-Modern-English/tree/master}. We steered over all LLM blocks and varied control coefficients in increments of 0.1 over 0.4 to 0.8. For Shakespeare and harmful (Figure~\ref{fig: main figure}), we use $a=1.0,b=0.5$ as the multiple for each concept, respectively, then use coefficient $0.5$ on the combined vector across all blocks. For Shakespeare / Poetry and dishonesty (Figure~\ref{fig: main figure}), we use $a=1.2,b=1.0$ as the multiple for each concept, respectively, then use coefficient $0.4$ on the combined vector across all blocks.

\subsection{Programming Languages}

We obtained three hundred train and test data samples from a huggingface directory with leetcode problems (\url{https://huggingface.co/datasets/greengerong/leetcode}). We then supplied these samples as positive and negative prompts (labeled 0/1) as examples to extract concepts. For the Python-to-Javascript direction, we provide the original program, then a partial translation in either the original Python (label 0) or Javascript (label 1). The partial translation was truncated to half the original length. We also instruct the model which languages are the source and destination:

\begin{center}
\fbox{
   \parbox{0.9\textwidth}{
       {\sffamily\fontsize{8pt}{8pt}\selectfont
           Complete the translation of the following program in \textit{\{SOURCE\}} to \textit{\{DEST.\}}.\\
           Program:\\
           \textit{\{Code in origin language.\}}\\
           Translation:\\
           \textit{\{Partially translated code in dest. language.\}}
       }
   }
}
\end{center}


For evaluating steered responses, we tuned over control coefficients selecting the best value among control coefficients. We steer the outputs of all blocks of the transformer. For Llama-3.1-8B-it, we tuned over coefficients: 0.4, 0.5, 0.6, 0.7, 0.8, and for Gemma-2-9B-it: 4.0, 5.0, 6.0, 7.0, 8.0, 9.0. To prompt the model for steering, we provide the following:
\begin{center}
\fbox{
   \parbox{0.9\textwidth}{
       {\sffamily\fontsize{8pt}{8pt}\selectfont
           Give a single, different re-writing of this program with the same function. The output will be judged by an expert in all programming languages. Do not include an explanation.\\\\\{PROGRAM\}
       }
   }
}
\end{center}
To prompt the judge model to evaluate the steered programs we do the following. 
\begin{center}
\fbox{
   \parbox{0.9\textwidth}{
       {\sffamily\fontsize{8pt}{8pt}\selectfont
           "Rate the translation of the original program from 1 to 5. Do not reduce score for name changes. Give your response in the format '\{score\}/5. \{Reason\}'.\\
           ------------------------------------------------------------\\
           ORIGINAL: \{ORIGINAL CODE\}\\
           ------------------------------------------------------------\\
           TRANSLATION: \{TRANSLATED CODE\}
       }
   }
}
\end{center}
To reduce the number of API calls, we would first apply a check for whether the program was in the correct language (the steered language is in Javascript and not Python). To detect language, we used Python indicators = [``def ", ``print(", ``elif ", ``self.", ``len(", ``range(", ``elif"] and 
Javascript indicators = [``function", ``console.log(", ``var ", ``let ", ``const ", ``=>", ``.has(", ``document.", ``||", ``\&\&", ``null", ``===", ``if (", ``else if", ``while ("]. The predicted language is whichever has more indicators. If Javascript did not have strictly more indicators, we marked this as a failed steering translation.

\subsection{Hallucinations}

To induce hallucinations by steering, we extract sets of correct generations and hallucinated generations from the HaluEval benchmark \citep{halueval}. Then, we generate prompts of the form:
\begin{center}
\fbox{\parbox{0.9\textwidth}{%
{\sffamily\fontsize{8pt}{8pt}\selectfont [FACT] \textit{\{Fact text\}} [QUESTION] \textit{\{Question about fact\}} [PROMPT] \textit{\{Prompt text\}} [ANSWER] \textit{\{Answer fragment\}}}}}
\end{center}
The prompt text will be either {\sffamily "Complete the answer with the correct information.''}, or {\sffamily "Make up an answer to the question that seems correct.''} for correct and hallucinated generations, respectively. Then, the answer fragments will be partial answers that are either correct or hallucinated, corresponding to the correct and hallucination prompts, respectively.

\subsection{Science subjects}

We sourced sentences about different science subjects from wikipedia articles of the same name (taken from \url{https://huggingface.co/datasets/legacy-datasets/wikipedia}). Then, we trained predictors on the following prompts:

\begin{center}
\fbox{
\parbox{0.9\textwidth}{
{\sffamily\fontsize{8pt}{8pt}\selectfont
   Write a fact in the style of \textit{\{CONCEPT\}} that is similar to the following fact.\\
   Fact:\\
   \textit{\{FACT\}}
   }
   }
}
\end{center}

\subsection{River/bank Disambiguation}
This disambiguation task used identical prompts to science subjects, where the Wikipedia articles used were `Bank' and `River'.

\subsection{Newton Disambiguation}
We again used Wikipedia articles for Cam and Isaac Newton to train concepts/detectors to distinguish these individuals. The prompt was as follows:
\begin{center}
\fbox{
\parbox{0.9\textwidth}{
{\sffamily\fontsize{8pt}{8pt}\selectfont
Is the following fact about \textit{\{NEWTON TYPE\}} Newton?\\
Fact:\\
\textit{\{FACT\}}
}
}
}
\end{center}


\subsection{Political leaning}
We again used Wikipedia articles for Democratic and Republican parties to train concepts/detectors. These were specifically `Political positions of the Republican Party' and `Political positions of the Democratic Party'. The prompt was as follows:
\begin{center}
\fbox{
\parbox{0.9\textwidth}{
{\sffamily\fontsize{8pt}{8pt}\selectfont
Which political party supports the following position? \\ 
Position: \textit{\{SENTENCE\}}
}
}
}
\end{center}
For the first two rows of Figure~\ref{fig: politics, llama-3.1-8B}, we steered over blocks $-8$ through $-31$ with steering coefficient 0.8. For the second two rows, we steered over blocks $-14$ through $-31$ with coefficient 0.8.  

\subsection{Harmful content}

We used the dataset and prompting from \url{https://github.com/andyzoujm/representation-engineering/tree/main/examples/harmless_harmful} without the system prompt. Specifically these utilize the prompts from \url{https://huggingface.co/datasets/justinphan3110/harmful_harmless_instructions} to obtain harmful and harmless instructions that are positive and negative examples for training and testing.

\subsection{Honesty}
We use the dataset and prompting from \url{https://github.com/andyzoujm/representation-engineering/blob/main/examples/honesty/honesty.ipynb} \citep{representation_engineering}. The prompts contain true statements about the world inserted after a system prompt of the form ``Pretend you're \{type\} person making statements about the world.'' 
\begin{center}
\fbox{
\parbox{0.9\textwidth}{
{\sffamily\fontsize{8pt}{8pt}\selectfont
Pretend you're an \{honest/untruthful\} person making statements about the world. \textit{\{Partial truthful statement\}}.
}
}
}
\end{center}