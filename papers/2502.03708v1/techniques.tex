\section{Detection and steering by aggregating nonlinear predictors}
\label{sec: techniques}

Below, we describe our framework for detecting concepts and steering LLMs by aggregating multiple concept vectors from the layer-wise activations. Our approach combines two key technical innovations: (1) detecting concepts by aggregating layer-wise concept predictors, and (2) learning concept vectors through  nonlinear feature-learning models (e.g., Recursive Feature Machines (RFMs) \citep{rfm_science}). We begin by mathematically describing the general framework for how we detect concepts from LLM activations.

In this work, we consider standard decoder-only transformers, such as Llama and Gemma series models \citep{brown2020language, llama, gemma}, which are trained to predict the next token auto-regressively. Inference with these models occurs as follows. A prompt or a context window is first converted into a sequence of $T$ input tokens that are one-hot encoded, i.e. each token is mapped to a vector in $\Real^V$, where $V$ is the vocabulary size. The input is formed by stacking these tokens into a single matrix $X \in \Real^{T \times V}$. For any input $X$, LLMs implement next-token prediction functions $f: \mathbb{R}^{T \times V} \to \mathbb{R}^{V}$ of the form: 
\begin{align*}
\label{eq: LLM forward pass}
    \tag{Embedding layer} A_1(X) &= E(X), \\
    \tag{Activations of the $\ell$-th block} A_{\ell}(X) &= B_{\ell}(A_{{\ell-1}}(X)) ~ \text{for $\ell \in \{2, \ldots, L\}$}, \\
    \tag{Final output} f(X) &= R(A_L(X)),
\end{align*}
where $E: \mathbb{R}^{T \times V} \to \mathbb{R}^{T \times k}$ is called an \textit{embedding} layer, each of the $A_{\ell}(X) \in \mathbb{R}^{T \times k}$ is a matrix of \textit{activations},  each of the functions $B_{\ell}: \mathbb{R}^{T \times k} \to \mathbb{R}^{T \times k}$ is a \textit{block}, and $R : \mathbb{R}^{T \times k} \rightarrow \mathbb{R}^{V}$ is a \textit{readout} layer. The final output token is obtained by sampling the from the output of the readout layer treated as a probability distribution. In transformer-based LLMs, blocks typically consist of self-attention layers followed by fully-connected layers, each with skip connections and a normalization step \citep{brown2020language}, however our approach relies only on the outputs of the blocks.  
 Given this setup, we describe how we detect concepts and steer LLMs below.  

\paragraph{Detection.}  To train predictors to detect a specified concept, we first curate a training dataset of prompt-label pairs $\{X^{(i)}, y^{(i)}\}_{i=1}^{n}$ where $X^{(i)} \in \mathbb{R}^{T \times d}$ and $y^{(i)} \in \{0, 1\}$, with $1$ indicating that the prompt belongs to the concept and $0$ indicating that it does not.\footnote{Our approach extends to multi-class concept detection by letting $y^{(i)}$ be a one-hot vector in $\mathbb{R}^{c}$.} See Appendix~\ref{app: prompts} for an example of our approach to generating labeled prompts. We next train layer-wise predictors, $\{f_{\ell}\}_{\ell = 1}^{L}$, to predict the concept labels from activations on these prompts.  In particular, letting $a_{\ell}^{(i)} \in \mathbb{R}^{k}$ denote the $T$\textsuperscript{th} row of $A_{\ell}(X^{(i)})$, we train $f_{\ell}: \mathbb{R}^{k} \to \mathbb{R}$ to map $a_{\ell}^{(i)}$ to $y^{(i)}$.  From each trained predictor, we next extract a set of $m \leq k$ features $\{c_{\ell, j}\}_{j=1}^{m}$ with $\|c_{\ell, j}\|_2 = 1$, which we refer to as \textit{concept vectors} (when $m = 1$, we indicate the concept vector as $c_{\ell}$).  For each layer, we then project the activations $a_{\ell}^{(i)}$ onto each of the $c_{\ell, j}$ to produce a vector $b_{\ell}^{(i)} \in \mathbb{R}^{m}$.  We then aggregate these projected activations across layers by concatenating these $L$ projected vectors into a vector $b^{(i)} = \left[ b_{1}^{(i)}, \ldots b_{L}^{(i)}\right] \in \mathbb{R}^{Lm}$.  To detect concepts, we finally train a predictor $f: \mathbb{R}^{Lm} \to \mathbb{R}$ that maps $b^{(i)}$ to label $y^{(i)}$.      

We are now faced with a choice of predictor and feature extraction method. In addition to standard linear or logistic regression, we consider Recursive Feature Machines (RFMs)~\cite{rfm_science} used with kernel machines. RFMs are an algorithm for enabling feature learning in any nonlinear predictive model such as a kernel machine (See Appendix~\ref{app: rfms} for a review of kernel machines and RFM).  Namely, after training a predictor $f: \mathbb{R}^{k} \to \mathbb{R}$, an RFM computes the Average Gradient Outer Product (AGOP) of the trained predictor to extract features in the form of a $k \times k$ feature matrix, $M$.  We select our $m$ concept vectors by computing the top $m$ eigenvectors of $M$.  


Below, we outline the specific form of RFM that we use in this work.   Let $X = [x^{(1)}, \ldots x^{(n)} ]^\top \in \mathbb{R}^{n \times d}$ and $y = [y^{(1)}, \ldots, y^{(n)}]^\top \in \mathbb{R}^{n}$ denote training data.  For any $x, z \in \mathbb{R}^{d}$, the (Mahalanobis) Laplace kernel with bandwidth parameter $L$ and symmetric, positive-semi-definite matrix $M$ takes the form 
\begin{align}
K_M(x, z) = \exp\left(-\frac{1}{L}\sqrt{ (x-z)^\top M (x-z)} \right).   
\end{align}  
Abusing notation, we write $K_M(A,B) \in \Real^{n \times m}$ for matrices $A \in \Real^{n \times d}, B \in \Real^{m \times d}$ to indicate the matrix of pairwise evaluations between all rows of $A$ and $B$. Letting $M_0 = I$, RFM iterates the following two steps for $\tau$ iterations:
\begin{align}
    &\text{Step 1:}~~ \hat{f}_t(z) = K_{M_t}(z, X) \alpha_t  ~\text{where}~ \alpha_t = [K_{M_t}(X, X)]^{-1} y \in \Real^{n}~, \tag{Kernel Ridge Regression}\\
    & \text{Step 2:}~~ M_{t+1} = \frac{1}{n}\sum_{i=1}^{n} \nabla_x \hat{f}_t(x^{(i)}) \nabla_x \hat{f}_t(x^{(i)})^\top \in \Real^{d \times d} \label{eq: agop} \tag{AGOP matrix}~.
\end{align}
\noindent Note the gradient in the AGOP computation is of the predictor with respect to its inputs (and not, e.g., its parameters). Hence, the AGOP matrix extracts the directions in input space that most influence predictions at iteration $t$, as changes in the inputs in these relevant directions will have greater influence on the classifier's prediction. In our case, the predictor is usually a classifier for a particular concept, hence the top eigenvectors of the AGOP are orthogonal directions that are relevant to this concept.

RFM is useful for detecting concepts that are nonlinear functions of activations and may depend on a subspace in activation space, not just a single direction, as the AGOP matrix provides multiple eigenvectors. This is in contrast to typical approaches for concept extraction, which rely on the use of linear methods such as linear / logistic regression, Principal Component Analysis (PCA), or Difference-in-means (See Appendix~\ref{app: pca} for an overview of these methods). 


\paragraph{Steering.}  Given a set of concept vectors $\{c_{\ell}\}_{\ell=1 }^{L}$ (1 concept vector per layer), we steer LLMs toward a concept by replacing activations $A_{\ell}(X)$ during the forward pass with $\tilde{A}_{\ell}(X)$ defined as follows.  Letting $A_{\ell, i}$ denote the $i$\textsuperscript{th} row of $A_{\ell}$, 
\begin{align}
    \tilde{A}_{\ell, i}(X) := A_{\ell, i}(X) + \eps c_{\ell}  ~ \text{for $\ell \in [L]$, $i \in [T]$},
\end{align} 
where $\eps \in \mathbb{R}$ is a constant parameter termed the \textit{control coefficient}. Values of $\eps$ vary per concept and per model. To steer for multiple concepts simultaneously, we simply let $c_{\ell}$ be a linear combination of the layer-wise concept vectors for each concept.  This steering approach is similar to other activation intervention methods~\citep{turner2023activation, representation_engineering, refusal_mediated, panickssery2023steering} with the differences that (1) concept vectors can be learned from nonlinear predictors, (2) we steer linear combinations of concepts, and (3) we learn steering vectors from gradated outputs. 
\\
\\
\noindent Our method extracts concept vectors given a list of labeled prompts, in contrast to certain contrastive approaches, such as PCA, which require pairs of positive and negative examples. Our approaches are described algorithmically in Appendix~\ref{app: method details}. We next demonstrate the generality and effectiveness of these algorithms by applying them to detect concepts and steer LLMs toward desired concepts.