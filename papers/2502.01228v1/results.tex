\section{Results and Discussion}\label{sec:results}

\begin{figure}[b!]
	\centering
	\includegraphics[width=0.98\columnwidth]{pointcloud_rev.png}
	\caption{The model point cloud $\hat{X}$ is shown with gray dots and over-imposed on the real cuboid used for the localization task. The red point cloud $X_k$, was obtained by merging $k=50$ random point cloud samples recorded by the robot in different poses reached when commanded with $k$ pressure sequences. An exemplification of the soft robot in three different configurations is also shown. }
	\label{fig:reco}
\end{figure}

In order to show the quality of the point clouds obtained with these \gls{tof} sensors, we reported in \cref{fig:reco} a point cloud $X_k$ collected with $k = 50$ samples acquired with the robot in different poses. The figure also shows the ground truth map of the environment. As visible, measurements of the sensors are noisy, and despite the simple geometry of the surroundings, in some areas, it is not possible to reconstruct precisely the local shape. As an example, sharp features, such as corners, appear to be smoothed in the collected point clouds. This is due to the fact that ToF measurements are affected by environmental factors such as the multiple-ways reflections that can be induced by sharp edges and the reflectance of the scene~\cite{gudmundsson2007environmental, may2009robust} which in our case consists of metallic parts as well. Furthermore, the noise on the output readings also depends on the distance of the sensor from the target and their respective orientation which further complicates the success of the task.
% 

\begin{figure}[t]
	\centering
	\subfigure[][] {\label{fig:results_knn}\includegraphics[width=0.9\columnwidth]{knn.png}} 
	%%%%
	\subfigure[][]
	{\label{fig:results_opti}\includegraphics[width=0.9\columnwidth]{gt.png}} 
	%%%%
	\caption{The bar plot shows the mean linear and rotational error along with their relative standard deviation ranges with a growing number of point cloud samples in two cases: (a) when point cloud samples are merged using the $k$-NN model for the transformation with respect to a common base frame; (b) when point cloud samples are merged using OptiTrack data for the transformation with respect to a common base frame. }
	\label{fig:results}
\end{figure}  
%

The performance on the localization task was evaluated by computing (i) the position error $e_x$ as the norm of the difference between the true and estimated position, and (ii) orientation error $e_{\gamma}$, i.e., the absolute value of the difference between the true and estimated in-plane angle of the robot base. 

Results are reported in~\cref{fig:results} for both point clouds merged using the tip poses estimated with the $k$-NN model (\cref{fig:results_knn}), and measured with the \gls{mocap} system (\cref{fig:results_opti}). 
The bars report the mean error across all trials for both position and orientation and the relative standard deviation.
It is visible from the plots that there is no significant difference between the two cases. This is further highlighted in~\cref{tab:table_errors}, where the average and the standard deviation across all the trials are given for the two considered approaches. Consequently, we can conclude that in this scenario, the localization accuracy is not affected by the approximate estimation of the robot tip position given by the $k$-NN model.

It is worth also noting that in both cases, increasing the point cloud samples does not lead to any improvements, as the localization error is always similar, with small oscillation in the average due to the noise of the measurements. We argue that this is because having a single actuator limits the motions of the robot, thus reducing the area explored. Additionally, the cuboidal shape of the environment does not have many discriminative features (only the corners), hence when the robot moves, it collects redundant information.

%

From \cref{fig:results} and \cref{tab:table_errors} it can be also seen that the mean error converges at approximately \SI{0.03}{\meter} and less than \SI{4.5}{\degree} for orientation. 
These results are in line with the information provided in the datasheet of the sensors used in this paper\cite{st_vl53l5cx_datasheet}. As previously mentioned in the introduction, one of the drawbacks of these sensors is the uncertainty of the measurement increasing with the distance between the sensor's origin and the environment. The size of the cuboid containing the robot is $0.7$ $\times$ $0.7$ $\times$ \SI{0.6}{\meter}. The robot is placed at the center of the frame, thus being distant approximately \SI{0.35}{\meter} from the cuboid vertical faces when not actuated. According to the sensor's datasheet, the uncertainty of the measurement in this range corresponds to 11\% of the real distance. %
Therefore, we should expect an uncertainty in the \gls{tof} measurements in the order of \SI{0.03}{\meter}, which is in line with our localization error.
% 

For what concerns the distorted corners of the frame in some point clouds, we argue that the adopted updating policy for the particles is playing a major role in filtering them out. As a matter of fact, outliers are discarded in the ICP score; hence unreliable measures induced by multiple-ways reflections are not considered in the weighing process and do not hinder the success of the localization task.

\begin{table}[t!]
\label{tab:table_errors}
\caption{Mean and standard deviation of the linear and angular error when considering $k$-NN model and OptiTrack data to merge point cloud samples.}
\begin{tabular}{|cc|cc|}
\hline
\multicolumn{2}{|c|}{$k$-NN}                                       & \multicolumn{2}{c|}{OptiTrack}                                 \\ \hline
\multicolumn{1}{|c|}{$e_x$ (m)}           & $e_\gamma$ ($\degree$) & \multicolumn{1}{c|}{$e_x$ (m)}           & $e_\gamma$ ($\degree$) \\ \hline
\multicolumn{1}{|c|}{0.0300 ± 0.0076} & 4.438 ± 0.181            & \multicolumn{1}{c|}{0.0305 ± 0.0076} & 4.428 ± 0.182            \\ \hline
\end{tabular}
\label{tab:table_errors}
\end{table}


We argue that to improve the performance of the \gls{pf} a probabilistic model, such as the beam model \cite{thrun2002probabilistic}, may be adapted to work on these specific types of \gls{tof} sensors, thus modeling the uncertainty on the measurements.
In addition to this, it is also important to note that, although the environment has a simple shape, the localization can be challenging - a cuboid presents symmetries and large flat areas, making it hard to find distinguishing features that can be used to match the point clouds, especially when only a partial representation of the environment is available. Adding more links to the robot and additional \gls{tof} sensors can represent a solution to increase its range of motion and capture additional areas of the environment. Furthermore, another aspect worth investigating is to consider more complex environments. Indeed, they may be composed of more discriminative features that can make it easier to match the reconstructed point cloud with the known map of the environment. These aspects will be investigated in a future extension of the paper.
