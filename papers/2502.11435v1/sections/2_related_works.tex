\section{Related Work}

\paragraph{LM Knowledge Boundary.}
Recent studies highlight that while LMs excel at standard tasks, they struggle to recognize and acknowledge the limits of their knowledge~\cite{yin2023large, kadavath2022language}. To address this gap, the concept of knowledge boundary has been introduced to define the limits of knowledge in LLMs~\cite{li2024knowledge, amayuelas2023knowledge}.
Building on this, some research evaluates LMs' self-awareness of their knowledge boundary through verbal probing~\citep{kadavath2022language} and fine-grained benchmarks~\citep{yin2024benchmarking}, enabling LMs to determine whether a question is answerable.
Other work focuses on mitigating hallucinations arising from the model’s unawareness of its limits through data augmentation~\cite{chen2023gotta,chen-etal-2024-minprompt}, retrieval augmentation~\cite{ren2023investigating}, and confidence calibration~\citep{xue2024ualign}. Additionally, \citet{chen2024teaching} and \citet{zhang2024r} trained LLMs to express their knowledge boundaries, enabling them to answer known questions and admit ignorance for unknown ones.
Our work aligns with these studies but focuses on enhancing agents' awareness of their knowledge boundaries to enable wiser tool use and more efficient task handling.

\paragraph{LM Tool Use.}
Integrating tool use into LLMs has gained significant attention as a way to complement parametric knowledge and enhance decision-making~\cite{qin2023tool, qu2025tool}. Some research focuses on enabling LLMs to access external tools to overcome knowledge limitations~\citep{qin2023toolllm, qian2024toolink}, including up-to-date information~\citep{vu2023freshllms, wang2024uniretriever} and domain-specific expertise~\citep{ling2023domain, wang2024appbench}. Others explore tool creation~\citep{qian2023creator, cai2023large} and external module integration~\citep{qian2024investigate} to improve tool learning robustness. Despite these, a key challenge lies in evaluating and enhancing LLMs’ ability to determine when and which tools to use. Benchmarks like MetaTool~\cite{huang2023metatool} and WTU-EVAL~\cite{ning2024wtu} highlight LLMs' struggles with unnecessary or incorrect tool usage, while dynamic frameworks~\cite{wang2024selfdc, shen2024smartcal} propose adaptively invoking tools based on internal uncertainty thresholds. Unlike prior works, SMART rigorously defines and measures \textit{tool overuse}, addressing overreliance on tools despite intrinsic reasoning capabilities. We optimize the balance between parametric knowledge and tool use, reducing overuse while enhancing performance.
