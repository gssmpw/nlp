\section{Preliminaries}

\begin{figure}[!t]
    \centering
    \subfigure{\includegraphics[width=\linewidth]{figures/preliminary_model.png}}
    \caption{Statistics on Llama and Mistral's tool overuse.}
    \label{fig:preliminary_model}
\end{figure}

To investigate how models decide between invoking tools and relying on their own knowledge, we conduct a preliminary study on both LLMs and LM-driven agent systems. Our findings reveal both LLMs and agent systems' strong tendency for excessive tool use, which we define as \textbf{Tool Overuse}, leading to unnecessary resource overhead.

\label{sec:tool_overuse}
\paragraph{Definition of Tool Overuse.}
Tool overuse refers to the excessive reliance on external tools when an agent model could have successfully completed the task using its parametric knowledge alone.
Formally, let \( Q \) be the total set of questions, and let \( P \) be the subset of questions that the model can correctly answer without using any tools. The model's intrinsic reasoning capability is then given by \( \alpha = \frac{|P|}{|Q|} \). Now, suppose that when provided with access to tools, the model chooses to invoke at least one tool on a fraction \( \beta \) of these questions in \( P \). The \textbf{Tool Overuse Rate} is then defined as:
\[
\mathcal{O} = \alpha \cdot \beta
\]
which quantifies the proportion of all questions where tool use is unnecessary, highlighting inefficiencies in the model's decision-making process.


\begin{table}[!t]
    \centering
    \subfigure{\includegraphics[width=\linewidth]{figures/preliminary_agent_table.png}}
    \caption{Statistics on XAgent and AgentGPT's tool overuse. Both agents invoke tools multiple times across 50 samples, despite \textit{ideally} requiring \textit{zero} tool usage.}
    \label{tab:preliminary_agent_table}
\end{table}

\begin{figure}[!t]
    \centering
    \subfigure{\includegraphics[width=\linewidth]{figures/preliminary_agent.png}}
    \caption{Example cases respectively demonstrating tool overuse in XAgent and AgentGPT.}
    \label{fig:preliminary_agent}
\end{figure}


\label{sec:preliminary_llm}
\paragraph{Experiments on LLMs.}
We first experiment with Llama-3.1-8B~\citep{dubey2024llama} and Mistral-7B~\citep{jiang2023mistral} on the GSM8K test set~\citep{cobbe2021training}. Each test question is presented under two conditions: i) the model reasons through the question normally and provides a final answer without using tools, and ii) the model has access to tools and independently decides whether to use them (see \Cref{apdx:prelim_model}). The statistics in \Cref{fig:preliminary_model} reveal two key insights. First, both models exhibit significant tool overuse, with Llama's rate exceeding 50\%. Second, in some cases, tool use leads to incorrect answers, even for questions the model could have solved correctly without external assistance. This highlights how excessive reliance on tools can introduce unnecessary complexity and degrade performance.

\paragraph{Experiments on LM-driven Agents.} 
In addition to LLMs, we also experiment with two agent systems: XAgent~\citep{xagent2023} and AgentGPT~\citep{2024agentgpt}, both designed for complex problem-solving and driven by closed-source GPT models. We sampled 50 queries from the GSM8K test set that can be answered correctly without tools (see \Cref{apdx:prelim_agent}) and instructed the models to use tools only when necessary. The results in \Cref{tab:preliminary_agent_table} show that, despite being equipped with various tools, both agent systems still tend to use them unnecessarily, significantly slowing down problem-solving (about 10x slower than using GPT alone). In the case study shown in \Cref{fig:preliminary_agent}, we identify issues like XAgent redundantly saving results and AgentGPT unnecessarily invoking a code-writing tool after generating answers. These observations underscore the need to address our core research question: \textbf{How can we calibrate agent models to balance tool use and parametric reasoning, mitigating tool overuse while preserving utility?}
