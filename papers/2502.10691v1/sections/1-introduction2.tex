\section{Introduction}
\label{sec:intro}

\input{figures/front_fig}

Out-of-distribution (OOD) detection and OOD generalization are two fundamental challenges in deep learning. OOD detection enables deep neural networks (DNNs) to reject unfamiliar inputs, preventing overconfident mispredictions, while OOD generalization allows DNNs to transfer their knowledge to new distributions. For applications like open-world learning, where a DNN continuously encounters new concepts, both capabilities are essential: OOD detection enables new concepts to be detected, while OOD generalization facilitates forward transfer to improve learning of these new concepts. Despite their importance, these tasks have primarily been studied in isolation. Here, we empirically and theoretically demonstrate a link between both tasks and neural collapse (NC), as illustrated in Fig.~\ref{fig:vis_abstract}.


NC is a phenomenon where DNNs develop compact and structured class representations~\cite{papyan2020prevalence}. While NC was first identified in the final hidden layer, later work has found that it occurs to varying degrees in the last $K$ DNN layers~\cite{rangamani2023feature,harun2024what,sukenikneural2024}. NC has a major impact on both OOD detection and generalization. Strong NC improves OOD detection by forming tightly clustered class features that enhance separation between in-distribution (ID) and OOD data~\cite{haas2023linking, wu2024pursuing, ming2022poem}. Conversely, NC impairs OOD generalization by reducing feature diversity, making it harder to transfer knowledge to novel distributions~\cite{kothapalli2023neural, masarczyk2023tunnel,harun2024what}. However, past work has considered NC in the context of either OOD detection or OOD generalization \textit{individually}, leaving open the question of how NC affects both tasks \textit{simultaneously}. To the best of our knowledge, no prior work has theoretically or empirically examined this relationship.

Here, we establish that the NC exhibited by a DNN layer has an \textbf{inverse relationship} with OOD detection and OOD generalization: \textit{stronger NC improves OOD detection but degrades generalization, while weaker NC enhances generalization at the cost of detection performance}. This trade-off suggests that a single feature space cannot effectively optimize both tasks, motivating the need for a novel approach. %Furthermore, we extend prior work by analyzing NC across \textit{multiple layers} rather than just the final hidden layer, providing new insights into how its extent varies throughout a DNN and how it affects OOD performance.

We propose a framework that strategically controls NC at different DNN layers to optimize both OOD detection and OOD generalization. We introduce entropy regularization to mitigate NC in the encoder, improving feature diversity and enhancing generalization. Simultaneously, we leverage a fixed Simplex Equiangular Tight Frame (ETF) projector to induce NC in the classification layer, improving feature compactness and enhancing detection. This design enables our DNNs to \textit{decouple representations} for detection and generalization, optimizing both objectives simultaneously.

\textbf{Our key contributions are as follows:}
\begin{enumerate}[noitemsep, nolistsep, leftmargin=*]
    \item We present the first unified study linking \textit{Neural Collapse} to both OOD detection and OOD generalization, empirically demonstrating their inverse relationship and extending analyses of NC beyond the final hidden layer.
    \item We develop a theoretical framework explaining how \textbf{entropy regularization mitigates NC} for OOD generalization and how a \textbf{fixed Simplex ETF projector enforces NC} for OOD detection.

    \item In extensive experiments on diverse OOD datasets and DNN architectures, we demonstrate the efficacy of our method compared to baselines. 
\end{enumerate}


