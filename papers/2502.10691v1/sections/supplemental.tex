\clearpage
\setcounter{page}{1}
%\maketitlesupplementary

\appendix

\begin{center}
    {\Large{\textbf{Appendix}}}
\end{center}

%\section{Rationale}
%\label{sec:rationale}
% 
%Having the supplementary compiled together with the main paper means that:
% 
%\begin{itemize}
%\item The supplementary can back-reference sections of the main paper, for example, we can refer to \cref{sec:intro};
%\item The main paper can forward reference sub-sections within the supplementary explicitly (e.g. referring to a particular experiment); 
%\item When submitted to arXiv, the supplementary will already included at the end of the paper.
%\end{itemize}
% 
%To split the supplementary pages from the main paper, you can use \href{https://support.apple.com/en-ca/guide/preview/prvw11793/mac#:~:text=Delete%20a%20page%20from%20a,or%20choose%20Edit%20%3E%20Delete).}{Preview (on macOS)}, \href{https://www.adobe.com/acrobat/how-to/delete-pages-from-pdf.html#:~:text=Choose%20%E2%80%9CTools%E2%80%9D%20%3E%20%E2%80%9COrganize,or%20pages%20from%20the%20file.}{Adobe Acrobat} (on all OSs), as well as \href{https://superuser.com/questions/517986/is-it-possible-to-delete-some-pages-of-a-pdf-document}{command line tools}.




We organize the Appendix as follows: 
\begin{itemize}
    \item Appendix~\ref{sec:implementation} describes the implementation details. It describes the DNN architectures (VGG, ResNet, and ViT), feature extraction for linear probing, training, and evaluation details of both pre-training and linear probing in various experiments.
    
    \item Appendix~\ref{sec:datasets} provides details on the datasets used in this paper. In total, we use 9 datasets.

    \item Appendix~\ref{sec:nc_metrics} describes four neural collapse metrics ($\mathcal{NC}1 - \mathcal{NC}4$) used in this paper.

    \item Appendix~\ref{sec:mse_ce_supp} presents a comprehensive comparison between MSE and CE.

    \item Appendix~\ref{sec:details_proposition} contains proof on the implication of NC on entropy.

    \item Appendix~\ref{sec:comprehensive_results} provides a comprehensive comparison between the encoder and projector across different architectures. %It includes comprehensive results on 8 OOD datasets for different DNNs including VGG17, ResNet18, ResNet34, ViT-T, and ViT-S.

    \item Appendix~\ref{sec:analysis_entropy_reg} provides detailed analyses on entropy regularization and neural collapse.

    \item Additional experiments and analyses are summarized in Appendix~\ref{sec:additional_exp_supp}. The mechanisms of controlling NC have been examined.
    
    \item Appendix~\ref{sec:imagenet_100_classes} includes the list of 100 classes in the imageNet-100 dataset. %and confirms there is no overlap between ID and OOD datasets.
\end{itemize}




\section{Implementation Details}
\label{sec:implementation}

In this paper, we use several acronyms such as
\textbf{NC} : Neural Collapse, 
\textbf{ETF} : Equiangular Tight Frame,
\textbf{ID} : In-Distribution, 
\textbf{OOD} : Out-of-Distribution,
\textbf{LR} : Learning Rate, 
\textbf{WD} : Weight Decay,
\textbf{GAP} : Global Average Pooling,
\textbf{GN} : Group Normalization, 
\textbf{BN} : Batch Normalization, 
\textbf{WS} : Weight Standardization,  
\textbf{CE} : Cross Entropy, 
\textbf{MSE} : Mean Squared Error,
\textbf{FPR} : False Positive Rate.

We use the terms OOD generalization and OOD transfer interchangeably.


%We implemented our code in Python using PyTorch.


\subsection{Architectures}
\label{sec:arch_details}

\textbf{VGG.}
We modified the VGG-19 architecture to create our VGG-17 encoder. Additionally, we removed two fully connected (FC) layers before the final classifier head. And, we added an adaptive average pooling layer (nn.AdaptiveAvgPool2d), which allows the network to accept any input size while keeping the output dimensions the same. After VGG-17 encoder, we attached a projector consisting of two MLP layers ($512 \rightarrow 2048 \rightarrow 512$) and finally added a classifier head. 
We use ReLU activation between projector layers.
We replace BN with GN+WS in all layers. For GN, we use 32 groups in all layers.

\noindent
\textbf{ResNet.}
We used the entire ResNet-18 or ResNet-34 as the encoder and attached a projector ($512 \rightarrow 2048 \rightarrow 512$) similar to the VGG networks mentioned above. 
We replace BN with GN+WS in all layers. For GN, we use 32 groups in all layers.

\noindent
\textbf{ViT.}
We consider ViT-Tiny/Small (5.73M/21.85M parameters) as the encoder for our experiments. %We use embedding dimension of 192, depth of 18 (i.e., 18 ViT blocks) and 3 heads. 
The projector comprising two MLP layers configured as fixed ETF Simplex and added after the encoder.
%($192 \rightarrow 768 \rightarrow 192$) is added after the encoder.
Following~\cite{beyer2022better}, we omit the learnable position embeddings and instead use the fixed 2D sin-cos position embeddings. Other details adhere to the original ViT paper~\cite{dosovitskiy2020image}. 
\begin{enumerate} %[noitemsep, nolistsep, leftmargin=*]
    \item \textbf{ViT-Tiny Configuration:} patch size=16, embedding dimension=192, \# heads=3, depth=12. Projector has
    output dimension=192 and hidden dimension=768,
    ($192 \rightarrow 768 \rightarrow 192$). We use ReLU activation between projector layers.
    The number of parameters in ViT-Tiny $+$ projector is 6.02M.
    \item \textbf{ViT-Small Configuration:} patch size=16, embedding dimension=384, \# heads=6, depth=12. Projector has
    output dimension=384 and hidden dimension=1536,
    ($384 \rightarrow 1536 \rightarrow 384$). We use ReLU activation between projector layers.
    The number of parameters in ViT-Small $+$ projector is 23.03M.
\end{enumerate}


\subsection{Feature Extraction For Linear Probing}
\label{sec:feat_extract_details}
In experiments with CNNs, at each layer $l$, for each sample, we extract features of dimension $H_{l}\times W_{l}\times C_{l}$, where $H_{l}$, $W_{l}$, and $C_{l}$ denote the height, width and channel dimensions respectively. Next, following~\cite{sarfi2023simulated}, we apply $2\times 2$ adaptive average pooling on each spatial tensor ($H_{l}\times W_{l}$). After average pooling, features of dimension $2\times 2 \times C_{l}$ are flattened and converted into a vector of dimension $4C_{l}$. Finally, a linear probe is trained on the flattened vectors. 
In experiments with ViTs, 
following~\cite{raghu2021vision}, we apply global average-pooling (GAP) to aggregate image tokens excluding the class token and train a linear probe on top of GAP tokens.
We report the best error ($\%$) on the test dataset for linear probing at each layer.


\subsection{VGG Experiments}

\textbf{VGG ID Training:} For training VGG on ImageNet-100, we employ the AdamW optimizer with a LR of $6\times10^{-3}$ and WD of $5\times10^{-2}$ for batch size 512. The model is trained for 100 epochs using the Cosine Annealing LR scheduler with a linear warmup of 5 epochs. 
In all experiments, we use CE and entropy regularization ($\alpha=0.05$) losses. 
However, in some particular experiments comparing CE and MSE, we use MSE loss ($\kappa$=15, M=60) and entropy regularization loss ($\alpha=0.05$). 

\noindent
\textbf{VGG Linear Probing:} We use the AdamW optimizer with a flat LR of $1\times 10^{-3}$ and WD of $0$ for batch size 128. The linear probes are trained for 30 epochs. We use label smoothing of 0.1 with the cross-entropy loss. 


\subsection{ResNet Experiments}

\textbf{ResNet ID Training:} 
For training ResNet-18/34, we employ the AdamW optimizer with an LR of 0.01 and a WD of 0.05 for batch size 512. The model is trained for 100 epochs using the Cosine Annealing LR scheduler with a linear warmup of 5 epochs. 
We use CE and entropy regularization ($\alpha=0.05$) losses. 
%We use MSE ($\kappa$=15, M=60) and regularization losses. 

\noindent
\textbf{ResNet Linear Probing:} In the linear probing experiment, we use the AdamW optimizer with an LR of $1\times 10^{-3}$ and WD of $0$ for batch size 128. The linear probes are trained for 30 epochs. We use label smoothing of 0.1 with cross-entropy loss.


\subsection{ViT Experiments}

\textbf{ViT ID Training:} 
For training ViT-Tiny, we employ the AdamW optimizer with LR of $8\times10^{-4}$ and WD of $5\times10^{-2}$ for batch size 256. The LR is scaled for $n$ GPUs according to: $LR \times n \times \frac{batch size}{512}$. We use an LR of $4\times10^{-4}$ for ViT-Small when the batch size is 256.
We use the Cosine Annealing LR scheduler with warm-up (5 epochs). 
We train the ViT-Tiny/Small for 100 epochs using CE and entropy regularization ($\alpha=0.05$) losses.
%We train the ViT-Tiny/Small for 100 epochs using CE or MSE ($\kappa$=5, M=10 for MSE) and regularization losses.
Following~\cite{raghu2021vision, beyer2022better}, we omit class token and instead use GAP token by global average-pooling image tokens and feed GAP embeddings to the projector. 


\noindent
\textbf{ViT Linear Probing:} We use the AdamW optimizer with LR of $0.01$ and WD of $1\times 10^{-4}$ for batch size 512. The linear probes are trained for 30 epochs. We use label smoothing of 0.1 with cross-entropy loss.

\noindent
\textbf{Augmentation.}
We use random resized crop and random flip augmentations and $224 \times 224$ images as inputs to the DNNs.

In experiments with CE loss, we use label smoothing of $0.1$.


\subsection{Evaluation Criteria}

\textbf{\textit{FPR95.}}
The OOD detection performance is evaluated by the FPR (False Positive Rate) metric. In particular, we use FPR95 (FPR at 95\% True Positive Rate) that evaluates OOD detection performance by measuring the fraction of OOD samples misclassified as ID where threshold, $\lambda$ is chosen when the true positive rate is 95\%. 
Both OOD detection and OOD generalization tasks are evaluated on the \emph{same} OOD test set.



%$\mathbf{\Delta_{E \rightarrow P}}$.
\textbf{\textit{Percentage Change.}}
To capture percentage increase or decrease when switching from the encoder ($E$) to the projector ($P$), we use 
\[
\Delta_{E \rightarrow P} = \frac{(P - E)} {|E|} \times 100.
\]


\textbf{\textit{Normalization for different OOD datasets.}}
In our correlation analysis between NC and OOD detection/generalization (Fig.~\ref{fig:vis_abstract} and~\ref{fig:nc_resnet}), we use min-max normalization for layer-wise OOD detection errors and OOD generalization errors which enables comparison using different OOD datasets. For a given OOD dataset and a DNN consisting of total $L$ layers, let the OOD detection/ generalization error for a layer $l$ be $E_l$. For $L$ layers we have error vector $\mathbf{E} = [E_1, E_2, \cdots E_L]$ which is then normalized by
\[
\mathbf{E}_N = \frac{\mathbf{E} - \mathrm{min}(\mathbf{E})} {\mathrm{max}(\mathbf{E}) - \mathrm{min}(\mathbf{E})}.
\]


\textbf{\textit{Effective Rank.}}
We use RankMe~\cite{garrido2023rankme} to measure the effective rank of the embeddings.



\section{Datasets}
\label{sec:datasets}

\textbf{ImageNet-100.} 
ImageNet-100~\cite{tian2020contrastive} is a subset of ImageNet-1K~\cite{deng2009imagenet} and contains 100 ImageNet classes. It consists of 126689 training images ($224\times 224$) and 5000 test images.
The object categories present in ImageNet-100 are listed in Appendix~\ref{sec:imagenet_100_classes}.

\textbf{CIFAR-100.} 
CIFAR-100~\cite{krizhevsky2014cifar} is a dataset widely used in computer vision. It contains $60,000$ RGB images and $100$ classes, each containing $600$ images. The
dataset is split into $50,000$ training samples and $10,000$ test samples. The images in CIFAR-100 have a
resolution of $32\times 32$ pixels. 
Unlike CIFAR-10, CIFAR-100 has a higher level of granularity, with
more fine-grained classes such as flowers, insects, household items, and a variety of animals and vehicles.
%CIFAR-100~\cite{krizhevsky2014cifar} dataset is similar with CIFAR-10 but with 100 classes. And each class has 600 images. %The out-of-distribution accuracy will be computed with randomly selected 10 classes from CIFAR-100, which is the same protocol used in~\cite{masarczyk2023tunnel}. Note that the classes in CIFAR-100 are mutually exclusive with those in CIFAR-10. 
For linear probing, all samples from both the training and validation datasets were used.


\textbf{NINCO (No ImageNet Class Objects).} NINCO ~\cite{bitterwolf2023ninco} is a dataset with 64 classes. The dataset is curated to eliminate semantic overlap with ImageNet-1K dataset and is used to evaluate the OOD performance of the models pre-trained on imagenet-1K. The NINCO dataset has 5878 samples, and we split it into 4702 samples for training and 1176 samples for evaluation. We do not have a fixed number of samples per class for training and evaluation datasets.

\textbf{ImageNet-Rendition (ImageNet-R).} ImageNet-R incorporates distribution shifts using different artistic renditions of object classes from the original ImageNet dataset~\citep{hendrycks2021many}.
We use a variant of ImageNet-R dataset from~\cite{wang2022dualprompt}.
ImageNet-R is a challenging benchmark for continual learning, transfer learning, and OOD detection. It consists of classes with different styles and intra-class diversity and thereby poses significant distribution shifts for ImageNet-1K pre-trained models~\citep{wang2022dualprompt}.
It contains 200 classes, 24000 training images, and 6000 test images.

\textbf{CUB-200.} CUB-200 is composed of 200 different bird species~\cite{wah2011caltech}. The CUB-200 dataset comprises a total of 11,788 images, with 5,994 images allocated for training and 5,794 images for testing.

\textbf{Aircrafts-100.} Aircrafts or FGVCAircrafts dataset~\cite{maji2013fine} consists of 100 different aircraft categories and 10000 high-resolution images with 100 images per category. The training and test sets contain 6667 and 3333 images respectively.

\textbf{Oxford Pets-37.} The Oxford Pets dataset includes a total of 37 various pet categories, with an approximately equal number of images for dogs and cats, totaling around 200 images for each category~\cite{parkhi2012cats}.

\textbf{Flowers-102.} The Flowers-102 dataset contains 102 flower categories that can be easily found in the UK. Each category of the dataset contains 40 to 258 images.~\cite{nilsback2008automated}

\textbf{STL-10.} STL-10 has 10 classes with 500 training images and 800 test images per class~\cite{coates2011analysis}.


For all datasets, images are resized to $224 \times 224$ to train and evaluate DNNs.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Neural Collapse Metrics}
\label{sec:nc_metrics}

Neural Collapse (NC) describes a structured organization of representations in DNNs~\cite{papyan2020prevalence, kothapalli2023neural, zhu2021geometric, rangamani2023feature}.
%\begin{tcolorbox}[boxsep=1pt,left=2pt,right=2pt,top=0pt,bottom=0pt]
The following four criteria characterize Neural Collapse:
\begin{enumerate}
    \item \textbf{Feature Collapse} ($\mathcal{NC}1$): Features within each class concentrate around a single mean, with almost no variability within classes.
    \item \textbf{Simplex ETF Structure} ($\mathcal{NC}2$): Class means, when centered at the global mean, are linearly separable, maximally distant, and form a symmetrical structure on a hypersphere known as a Simplex Equiangular Tight Frame (Simplex ETF).
    \item \textbf{Self-Duality} ($\mathcal{NC}3$): The last-layer classifiers align closely with their corresponding class means, forming a self-dual configuration.
    \item \textbf{Nearest Class Mean Decision} ($\mathcal{NC}4$): The classifier operates similarly to the nearest class-center (NCC) decision rule, assigning classes based on proximity to the class means. 
\end{enumerate}
%\end{tcolorbox}


Here, we describe each NC metric used in our results. Let \( \mu_G \) denote the global mean and \( \mu_c \) the \( c \)-th class mean of the features, \( \{z_{c,i}\} \) at layer \( l \), defined as follows:
\[
\mu_G = \frac{1}{nC} \sum_{c=1}^C \sum_{i=1}^n z_{c,i}, \quad \mu_c = \frac{1}{n} \sum_{i=1}^n z_{c,i} \quad (1 \leq c \leq C).
\]
We drop the layer index \( l \) from notation for simplicity.

\noindent
\textbf{Within-Class Variability Collapse ($\mathcal{NC}1$):}  
It measures the relative size of the within-class covariance \( \Sigma_W \) with respect to the between-class covariance \( \Sigma_B \) of the DNN features:
\[
\Sigma_W = \frac{1}{nC} \sum_{c=1}^C \sum_{i=1}^n \left( z_{c,i} - \mu_c \right) \left( z_{c,i} - \mu_c \right)^\top \in \mathbb{R}^{d \times d},
\]
\[
\Sigma_B = \frac{1}{C} \sum_{c=1}^C \left( \mu_c - \mu_G \right) \left( \mu_c - \mu_G \right)^\top \in \mathbb{R}^{d \times d}.
\]

The $\mathcal{NC}1$ metric is defined as:

\[
\mathcal{NC}1 = \frac{1}{C} \operatorname{trace} \left( \Sigma_W \Sigma_B^{\dagger} \right),
\]
where \( \Sigma_B^{\dagger} \) is the pseudo-inverse of \( \Sigma_B \). Note that $\mathcal{NC}1$ is the most dominant indicator of neural collapse.

\noindent
\textbf{Convergence to Simplex ETF ($\mathcal{NC}2$):}  
It quantifies the \( \ell_2 \) distance between the normalized simplex ETF and the normalized \( WW^\top \), as follows:
\[
\mathcal{NC}2 := \left\| \frac{WW^\top}{\| WW^\top \|_F} - \frac{1}{\sqrt{C-1}} \left( I_C - \frac{1}{C} \mathbf{1}_C \mathbf{1}_C^\top \right) \right\|_F,
\]
where \( W \in \mathbb{R}^{C \times d} \) is the weight matrix of the learned classifier.

\noindent
\textbf{Convergence to Self-Duality ($\mathcal{NC}3$):}  
It measures the \( \ell_2 \) distance between the normalized simplex ETF and the normalized \( WZ \):
\[
\mathcal{NC}3 := \left\| \frac{WZ}{\| WZ \|_F} - \frac{1}{\sqrt{C-1}} \left( I_C - \frac{1}{C} \mathbf{1}_C \mathbf{1}_C^\top \right) \right\|_F,
\]
where \( Z = \left[ z_1 - \mu_G \; \cdots \; z_C - \mu_G \right] \in \mathbb{R}^{d \times C} \) is the centered class-mean matrix.


\textbf{Simplification to NCC ($\mathcal{NC}4$):} It measures the collapse of bias \( b \):
\[
\mathcal{NC}4 := \left\| b + W \mu_G   \right\|_2.
\]






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Mean Squared Error vs. Cross-Entropy}
\label{sec:mse_ce_supp}

Prior work~\cite{kornblith2021better} finds that MSE rivals CE in ID classification task but underperforms CE in OOD transfer. However, the comparison between CE and MSE in OOD detection task remains unexplored.
In this work, we find that CE significantly outperforms MSE in both OOD transfer and OOD detection tasks.
As shown in Table~\ref{tab:mse_ce_comp}, MSE underperforms CE by 6.74\% (absolute) in OOD detection and by 17.71\% (absolute) in OOD generalization. Our OOD generalization results are consistent with~\citet{kornblith2021better}.
CE also obtains lower ID error than MSE, thereby showing good overall performance.

In terms of inducing neural collapse, both MSE and CE are effective and achieve lower NC values (i.e., stronger NC). However, our results suggest that CE does a better job than MSE in enhancing NC without sacrificing OOD transfer. We find MSE to be sensitive to the hyperparameters.
The comparison on all OOD datasets is shown in Table~\ref{tab:main_results}.





\begin{table}[t]
\centering
  \caption{\textbf{Comparison between MSE and CE.} VGG17 networks are trained on \textbf{ImageNet-100} dataset (ID) and evaluated on 8 OOD datasets. For OOD generalization we report $\boldsymbol{\mathcal{E}}_{\text{GEN}}$ (\%) whereas for OOD detection we report $\boldsymbol{\mathcal{E}}_{\text{DET}}$ (\%), both are averaged over 8 OOD datasets. %$\downarrow$ indicates smaller values are better. 
  \textbf{A lower $\mathcal{NC}$ indicates stronger neural collapse.} $+\Delta_{E \rightarrow P}$ and $-\Delta_{E \rightarrow P}$ indicate \% increase and \% decrease respectively, when changing from the encoder ($E$) to projector ($P$). %\textcolor{brown}{CE outperforms MSE in both OOD transfer and OOD detection evaluations.}
  }
  \label{tab:mse_ce_comp}
  \centering
  \resizebox{\linewidth}{!}{
     \begin{tabular}{c|c|cccc|c|c}
     \hline %\hline
     \multicolumn{1}{c|}{\textbf{Method}} &
     \multicolumn{1}{c|}{$\boldsymbol{\mathcal{E}}_{\text{ID}}$} &
     \multicolumn{4}{c|}{\textbf{Neural Collapse}} &
     \multicolumn{1}{c|}{$\boldsymbol{\mathcal{E}}_{\text{GEN}}$} &
     \multicolumn{1}{c}{$\boldsymbol{\mathcal{E}}_{\text{DET}}$} \\
     & $\downarrow$ & $\mathcal{NC}1$ & $\mathcal{NC}2$ & $\mathcal{NC}3$ & $\mathcal{NC}4$ & Avg. $\downarrow$ & Avg. $\downarrow$ \\
     %\hline
     \toprule
     \rowcolor[gray]{0.9}
     \textbf{CE Loss} \\
     Projector & \textbf{12.62} & 0.393 & 0.490 & 0.468 & 0.316 & 66.36 & \textbf{65.10} \\
     Encoder & 15.52 & 2.175 & 0.603 & 0.616 & 5.364 & \textbf{41.85} & 87.62 \\
     \rowcolor{yellow!50}
     $\Delta_{E \rightarrow P}$ & -18.69 & -81.93 & -18.74 & -24.03 & -94.11 & +58.57 & -25.70 \\
    %\hline \hline
    \toprule
    \rowcolor[gray]{0.9}
    \textbf{MSE Loss} \\
    Projector & \textbf{14.04} & 0.469 & 0.743 & 0.279 & 0.382 & 70.87 & \textbf{71.84} \\
    %\hline
    Encoder & 14.74 & 2.267 & 0.843 & 0.673 & 10.773 & \textbf{59.56} & 88.88 \\
    %\hline
    \rowcolor{yellow!50}
    $\Delta_{E \rightarrow P}$ & -4.75 & -79.31 & -11.86 & -58.54 & -96.45 & +18.99 & -19.17 \\
    %\hline %\hline
    \bottomrule
    \end{tabular}}
\end{table}



%\input{tables/plastic_proj}


\section{Formal Proposition: Collapsing Implies Entropy $-\infty$}
\label{sec:details_proposition}

\begin{proposition}[Entropy under Class-Conditional Collapse]
Consider a mixture of $K$ class-conditional densities $\{p_{\ell,k}\}_{k=1}^K$ in $\mathbb{R}^{d_\ell}$, with mixture weights $\{\pi_k\}$. Suppose that for each $k$, there exists a family of densities $\{p_{\ell,k}(\epsilon) : \epsilon > 0\}$ such that
\[
\lim_{\epsilon \to 0} p_{\ell,k}(\epsilon) = \delta(z - \mu_{\ell,k})
\]
in the weak topology (i.e., they converge to a Dirac delta). Then
\[
\lim_{\epsilon \to 0} H\left(\sum_{k=1}^K \pi_k \, p_{\ell,k}(\epsilon)\right) = -\infty.
\]
\end{proposition}

\paragraph{Proof (Sketch).}
For each fixed $k$,
\[
\lim_{\epsilon \to 0} H(p_{\ell,k}(\epsilon)) = -\infty,
\]
because each $p_{\ell,k}(\epsilon)$ ``collapses'' its support around $\mu_{\ell,k}$. This is analogous to reducing variance to $0$ for a parametric family (e.g., a Gaussian with covariance $\epsilon I$).

The mixture’s differential entropy can be bounded above as
\[
H\left(\sum_{k} \pi_k \, p_{\ell,k}(\epsilon)\right) \leq \sum_{k} \pi_k H(p_{\ell,k}(\epsilon)) + \text{const},
\]
where the constant term arises from mixture overlap considerations (or the standard inequality $H(\sum_i q_i) \leq \sum_i \alpha_i H(q_i) + \log K$ for simpler forms).

Hence, if each $H(p_{\ell,k}(\epsilon)) \to -\infty$, the sum also diverges to $-\infty$. This demonstrates that if each class distribution collapses around its mean, the overall mixture’s differential entropy approaches $-\infty$.



%%%%%%%%%%%%%%%%%%%

\section{Comprehensive Results (Encoder Vs. Projector)}
\label{sec:comprehensive_results}

\input{tables/main_results} % VGG


\input{figures/umap_id_ood}


\input{figures/id_ood_energy}


\subsection{VGG Experiments}

The detailed VGG17 results are given in Table~\ref{tab:main_results}. VGG results demonstrate that the encoder effectively mitigates NC for OOD generalization and the projector builds collapsed features and excels at the OOD detection task. The results also confirm that NC properties can be built using both CE and MSE loss functions.

\textbf{Qualitative Comparison.} 
We compare and visualize encoder embeddings and projector embeddings using UMAP. We also visualize the energy score distribution of ID and OOD data. The analysis is based on the VGG17 model pre-trained on the ImageNet-100 (ID) dataset and evaluated on OOD datasets: NINCO-64, Flowers-102, and STL-10. We observe the following:
\begin{itemize}[noitemsep, nolistsep, leftmargin=*]
    \item In Fig.~\ref{fig:umap_id_ood}, the UMAP shows that projector embeddings nicely separate ID and OOD sets whereas encoder embeddings exhibit substantial overlap between ID and OOD sets. This demonstrates that, unlike the encoder, the projector can intensify NC and is adept at OOD detection.

    \item We show the energy distribution of ID and OOD sets in Fig.~\ref{fig:eng_id_ood} and~\ref{fig:more_eng_id_ood}. In all comparisons, we observe that the projector outperforms the encoder in separating ID and OOD sets based on energy scores.
    
\end{itemize}




\subsection{ResNet Experiments}

\input{tables/resnet_results} % ResNet

\begin{figure}[t]
    \centering
    \includegraphics[width = 0.99\linewidth]{images/nc_ood_detect_transfer_corr_resnet_updated.png}
  \caption{Lower NC1 values (indicating stronger neural collapse) correlate with lower OOD detection error but higher OOD transfer error, and vice versa. This suggests that stronger neural collapse improves OOD detection, while weaker neural collapse enhances OOD generalization. We analyze various layers of \textbf{ResNet18}, pre-trained on ImageNet-100 (ID), and evaluate them on four OOD datasets. $R$ denotes the Pearson correlation coefficient.
  %NC exhibits a positive correlation with OOD detection error and a negative correlation with OOD transfer error when we analyze different layers of ResNet18 models that are pre-trained on ImageNet-100 (ID) and evaluated on four OOD datasets. $R$ denotes the Pearson correlation coefficient.
  } 
  \label{fig:nc_resnet}
\end{figure}



The detailed ResNet18/34 results are given in Table~\ref{tab:resnet_results}. Our findings validate that NC can be controlled in various ResNet architectures for improving OOD detection and OOD generalization performance.
Additionally, NC shows a strong correlation with OOD detection and OOD generalization as illustrated in Fig.~\ref{fig:nc_resnet}.

\input{figures/umap_resnet}


We also visualize embeddings extracted from the encoder and projector of the ResNet18 model. As depicted in Fig.~\ref{fig:umap_vis_resnet}, projector embeddings exhibit much greater neural collapse than encoder embeddings.



\subsection{ViT Experiments} 

\input{tables/vit_results} %% ViT

As shown in Table~\ref{tab:vit_results}, the projector outperforms the encoder in OOD detection by absolute 7.73\% (ViT-Tiny) and 9.23\% (ViT-Small). Whereas the encoder outperforms the projector in OOD transfer by absolute 10.90\% (ViT-Tiny) and 11.56\% (ViT-Small). This demonstrates that controlling NC improves OOD detection and generalization in ViTs. 



\section{Analysis on Entropy Regularization}
\label{sec:analysis_entropy_reg}

\input{tables/ent_reg_vs_no_ent_reg}

Table~\ref{tab:reg_vs_no_reg} presents the detailed comparison between a model using the entropy regularization vs another model omitting it. We observe that using entropy penalty enhances OOD transfer by 2.71\% (absolute), OOD detection by 2.36\% (absolute), and ID performance by 0.84\% (absolute).

Additionally, we analyze the impact of the entropy regularization loss coefficient on the ID and OOD transfer. Table~\ref{tab:entropy_loss_coeff} shows that increasing coefficient increases OOD transfer and rank of embeddings. This suggests that entropy regularization helps encode diverse features and reduce redundant features, encouraging utilization of all dimensions. Although entropy regularization is not sensitive to coefficient, over-regularization may hurt ID performance. Thereby, any non-aggressive coefficient can maintain good performance in both ID and OOD tasks. %Typically, a coefficient of $0.1$ or less works fine.


% \textbf{Training Dynamics.}
We also analyze the impact of entropy regularization on encoder embeddings during the training phase. During each training epoch, we measure the NC1 criterion, entropy, and effective rank of encoder embeddings. These experiments are computationally intensive for large-scale datasets. Therefore, we perform small-scale experiments where we train VGG17 models on the ImageNet-10 (10 ImageNet classes) subset for 100 epochs. We evaluate two cases: one with entropy regularization and another without entropy regularization.


The results are illustrated in Fig.~\ref{fig:nc_dynamics}.
%The impact of entropy regularization on NC1 is exhibited in Fig.~\ref{fig:nc_dynamics}. 
We find that entropy regularization achieves higher NC1 values during training compared to the model without any regularization. Thus, it helps mitigate NC during training, thereby contributing to OOD generalization. These findings align with our theoretical analysis showing entropy as an effective mechanism to prevent NC in the encoder.


Entropy regularization also increases the entropy and effective rank of the encoder embeddings. 
This demonstrates that entropy regularization helps encode diverse features, ensuring the features remain sufficiently ``spread out.''


Without the entropy regularization, the entropy of encoder embeddings does not improve. Also, the effective rank ends up at a low value (as low as the number of ID classes). The low rank is a sign of strong neural collapse and suggests that the encoder uses a few feature dimensions to encode information with huge redundancy in other dimensions. This degeneracy of embeddings impairs OOD transfer.
Entropy regularization counteracts this and improves OOD transfer.




\input{tables/ent_reg_coeff}


\input{figures/dynamics}




\section{Additional Experimental Results}
\label{sec:additional_exp_supp}

%%%%%%%%%%%%%%%%%%%%%

\subsection{Fixed ETF Projector Vs. Learnable Projector}

In Table~\ref{tab:plastic_proj}, we observe that the fixed ETF projector shows a higher transfer error (2.47\% absolute) than the plastic projector but outperforms the plastic projector in ID error (2.48\% absolute) and OOD detection error (8.9\% absolute). A fixed ETF projector should intensify NC and hinder OOD transfer and our fixed ETF projector fulfills this goal.


\input{tables/plastic_proj}


%%%%%%%%%%%%%%%%%%%%%

\subsection{Impact of $\mathbf{L_2}$ Normalization on NC}

\input{tables/l2_norm}

We verify whether $L_2$ normalization effectively induces more neural collapse and improves OOD detection.
We analyze two VGG17 models pre-trained on ImageNet-100 dataset where one model uses $L_2$ normalization and the other omits it.
The results are summarized in Table~\ref{tab:l2_norm_nc}.
We find that $L_2$ normalization induces more NC as evidenced by the lower NC1 value than its counterpart.
Consequently, $L_2$ normalization improves OOD detection by 3.83\% (absolute). Also, it achieves lower ID error than the compared model without $L_2$ normalization.

Next, we analyze how $L_2$ normalization impacts NC during training. We perform small-scale experiments since large-scale experiments are compute-intensive.
We train two VGG17 models on the ImageNet-10 (10 ImageNet classes) subset where one model uses $L_2$ normalization and another does not. During training, we measure the NC1 metric for the encoder embeddings.
The impact of $L_2$ normalization on NC1 is exhibited in Fig.~\ref{fig:l2_norm}. We find that $L_2$ normalization helps intensify NC during training. Consequently, it promotes better OOD detection.


%%%%%%%%%%%%%%%%%%%%%

\subsection{Batch Normalization Vs. Group Normalization}

\input{tables/bn_vs_gn}

We find that group normalization (combined with weight standardization) outperforms batch normalization by 10.11\% (absolute) in OOD transfer and by 4.37\% (absolute) in OOD detection (see Table~\ref{tab:bn_vs_gn}).
Group normalization achieves a higher $\mathcal{NC}1$ value than batch normalization, thereby mitigating NC and enhancing OOD generalization. Group normalization also achieves ID performance similar to that of batch normalization.
Our results demonstrate that group normalization achieves competitive performance and plays a crucial role in OOD generalization.


%%%%%%%%%%%%%%%%%%%%%

\subsection{Comparison with Baseline}

\input{tables/base_model}

Our experimental results show that our method significantly improves OOD detection and OOD transfer performance across all DNN architectures. We summarize the results in Table~\ref{tab:base_model}. We evaluate VGG17, ResNet18, and ViT-T baselines on 8 OOD datasets and compare them with our models.
The absolute improvements over VGG17 baseline are 7.69\% (OOD generalization) and 
29.82\% (OOD detection). Similarly, our method outperforms other DNNs in all criteria.
Our results corroborate our argument that \emph{controlling NC enables good OOD detection and OOD generalization performance}. It is also evident that a single feature space cannot simultaneously achieve both OOD detection and OOD generalization abilities.



%%%%%%%%%%%%%%%%%%%%%

\subsection{Projector Design Criteria}

Here we study the design choices of the projector network. We want to know how depth and width impact the performance. For this, we examine projectors consisting of a single layer (\textit{depth=1}, $512d$), two layers (\textit{depth=2}, $512d \rightarrow 2048d \rightarrow 512d$), three layers (\textit{depth=3}, $512d \rightarrow 2048d \rightarrow 2048d \rightarrow 512d$),
and a wider variant (\textit{width=2}, $512d \rightarrow 4096d \rightarrow 512d$). All of these variants are trained in identical settings and only the projector is changed. We train VGG17 networks on ImageNet-100 dataset (ID) and evaluate OOD detection/generalization on 8 OOD datasets.
The results are shown in Table~\ref{tab:proj_design}. The projector with depth 2 outperforms other variants across all evaluations.


\input{tables/proj_design_choices}


%\subsection{Additional ID dataset}
%% TBA


%%%%%%%%%%%%%%%%%%%%%

\subsection{Fixed ETF Classifier Vs. Plastic Classifier}

\input{tables/fixed_classifier_details}
%\input{tables/etf_clf_summary}

We investigate how using a fixed ETF classifier head impacts NC and OOD detection/generalization performance.
We train two identical models consisting of our proposed mechanisms to control NC, the only thing we vary is the classifier head. One model consists of a plastic (learnable) classifier head which is our proposed model and the other consists of an ETF classifier head. The ETF classifier head is configured with Simplex ETF and frozen during training. We train VGG17 networks on ImageNet-100 (ID) and evaluate them on 8 OOD datasets.

%Table~\ref{tab:etf_clf_results} 
Table~\ref{tab:fixed_vs_plastic_head} shows results across all OOD datasets, where the plastic classifier outperforms the fixed ETF classifier by 4.39\% (absolute) in OOD detection and by 15.6\% in OOD generalization. The plastic classifier also outperforms ETF classifier in the ID task. 
%Table~\ref{tab:fixed_vs_plastic_head} shows detailed results for each OOD dataset. 
Our results suggest that imposing NC in the classifier head is sub-optimal for enhancing OOD detection and generalization.


%%%%%%%%%%%%%%%%%%%%%


%\section{Some Research Questions}
%\begin{enumerate}
%    \item Does a fixed classifier become a better OOD detector and classifier than a learned one?
%\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%
%\newpage

\section{Classes of ImageNet-100 ID Dataset}
\label{sec:imagenet_100_classes}

We list the 100 classes in the ID dataset, ImageNet-100~\cite{tian2020contrastive}. 
This list can also be found at: \url{https://github.com/HobbitLong/CMC/blob/master/imagenet100.txt}


\textit{Rocking chair, pirate, computer keyboard, Rottweiler, Great Dane, tile roof, harmonica, langur, Gila monster, hognose snake, vacuum, Doberman, laptop, gasmask, mixing bowl, robin, throne, chime, bonnet, komondor, jean, moped, tub, rotisserie, African hunting dog, kuvasz, stretcher, garden spider, theater curtain, honeycomb, garter snake, wild boar, pedestal, bassinet, pickup, American lobster, sarong, mousetrap, coyote, hard disc, chocolate sauce, slide rule, wing, cauliflower, American Staffordshire terrier, meerkat, Chihuahua, lorikeet, bannister, tripod, head cabbage, stinkhorn, rock crab, papillon, park bench, reel, toy terrier, obelisk, walking stick, cocktail shaker, standard poodle, cinema, carbonara, red fox, little blue heron, gyromitra, Dutch oven, hare, dung beetle, iron, bottlecap, lampshade, mortarboard, purse, boathouse, ambulance, milk can, Mexican hairless, goose, boxer, gibbon, football helmet, car wheel, Shih-Tzu, Saluki, window screen, English foxhound, American coot, Walker hound, modem, vizsla, green mamba, pineapple, safety pin, borzoi, tabby, fiddler crab, leafhopper, Chesapeake Bay retriever, and ski mask.}


\begin{comment}

\textbf{Is there any semantic class overlap between ID and OOD datasets?}
There is no semantic class overlap between ImageNet-100 (ID dataset) and 8 other OOD datasets e.g., CIFAR-10, CIFAR-100, NINCO-64, CUB-200, Aircrafts-100, Oxford Pets-37, Flowers-102, and STL-10. 

Only ImageNet-R (consisting of 200 classes) has 19 classes that overlap with ImageNet-100. 
This is expected and we know that ImageNet-R includes classes from ImageNet-1K dataset but incorporates significant distribution shifts using artistic renditions.
The overlapping classes are:
\textit{Gasmask, American lobster, Standard poodle, Red fox, Head cabbage, Harmonica, Ambulance, Gibbon, Pineapple, Chihuahua, Tabby, Pirate, Rottweiler, Lorikeet, Boxer, Pickup, Goose, Shih-Tzu, and Meerkat.}

\end{comment}

