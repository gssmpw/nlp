\begin{table}[t]
\centering
  \caption{\textbf{Impact of Entropy Regularization.} VGG17 models are trained on ImageNet-100 dataset (ID) and evaluated on 8 OOD datasets. NC metrics are measured with encoder embeddings where entropy regularization is applied or omitted. Reported $\mathcal{E}_{\text{GEN}}$ (\%) and $\mathcal{E}_{\text{DET}}$ (\%) correspond to the encoder and projector respectively. OOD performance is averaged over 8 OOD datasets.
  %All metrics except NC are in percentage.
  %\textcolor{brown}{Entropy regularization reduces NC1 and increases performance across all criteria.}
  }
  \label{tab:entropy_results_summary}
  \centering
  \resizebox{\linewidth}{!}{
     \begin{tabular}{c|c|cccc|c|c}
     \hline %\hline
     \multicolumn{1}{c|}{\textbf{Method}} &
     \multicolumn{1}{c|}{$\boldsymbol{\mathcal{E}}_{\text{ID}}$} &
     \multicolumn{4}{c|}{\textbf{Neural Collapse} $\uparrow$} &
     \multicolumn{1}{c|}{$\boldsymbol{\mathcal{E}}_{\text{GEN}}$} &
     \multicolumn{1}{c}{$\boldsymbol{\mathcal{E}}_{\text{DET}}$} \\
     & $\downarrow$ & $\mathcal{NC}1$ & $\mathcal{NC}2$ & $\mathcal{NC}3$ & $\mathcal{NC}4$ & Avg. $\downarrow$ & Avg. $\downarrow$ \\
     
    %\hline \hline
    \toprule
    No Reg. & 13.46 & 1.31 & 0.72 & 0.62 & 5.18 & 44.56 & 67.46 \\
    
    %\hline
    \rowcolor{yellow!50}
    \textbf{Reg.} & \textbf{12.62} & \textbf{2.18} & 0.61 & 0.62 & 5.36 & \textbf{41.85} & \textbf{65.10} \\
    %\hline \hline
    \bottomrule
    \end{tabular}}
\end{table}