\begin{table*}[t]
\centering
  \caption{\textbf{NC Analysis (ImageNet-100).} In this setting, VGGm-17 models are trained on ImageNet-100 dataset (ID) for 200 epochs using MSE loss (k=15 and M=30) and evaluated on the same ID dataset using neural collapse metrics. Reported is the top-1 accuracy (\%). $\mathbf{W}$ and $\mathbf{W_{LS}}$ denote learned weights and least square weights (analytical, no training) of the final classifier layer, respectively. \textbf{A lower $\mathcal{NC}$ indicates higher neural collapse.} Here $\mathbf{h_E}$ and $\mathbf{h_p}$ denote embeddings extracted from the encoder or backbone (before projector) and projector (before output layer), respectively.}
  \label{tab:nc_results_100c}
  \centering
  %\resizebox{\linewidth}{!}{
     \begin{tabular}{ccc|cccc}
     \hline %\hline
     \multicolumn{1}{c}{\textbf{Configuration}} &
     \multicolumn{1}{c}{\textbf{ID Accuracy} $\uparrow$} &
     \multicolumn{1}{c|}{\textbf{ID Accuracy} $\uparrow$} &
     \multicolumn{4}{c}{\textbf{Neural Collapse} $\downarrow$} \\
    & $\mathbf{W}$ & $\mathbf{W_{LS}}$ & $\mathcal{NC}1$ &  $\mathcal{NC}2$ &  $\mathcal{NC}3$ &  $\mathcal{NC}4$ \\
    %\hline
    %No Projector & 89.60 & 89.40 & 0.075 & 0.219 & 0.030 & 0.316 \\
    %\hline
    %Plastic Projector (1 layer) & 89.20 & 89.40 & 0.074 & 0.304 & 0.043 & 0.316 \\
    %ETF Fixed Projector (1 layer) & 89.00 & 88.80 & \textbf{0.069} & \textbf{0.254} & \textbf{0.035} & 0.316 \\
    %\hline
    %Plastic Projector (2 layers) & 89.20 & 89.00 & 0.101 & 0.378 & 0.051 & 0.316 \\
    %ETF Fixed Projector (2 layers) & 89.40 & 89.40 & \textbf{0.080} & \textbf{0.311} & \textbf{0.041} & 0.316 \\
    \hline \hline
    ETF Fixed Proj (L=2) + KoLeo ($\mathbf{h_E}$) & \textbf{85.88} & 85.66 & 2.267 & 0.743 & 0.342 & 64.63 \\
    ETF Fixed Proj (L=2) + KoLeo ($\mathbf{h_P}$) & \textbf{85.88} & \textbf{85.82} & \textbf{0.469} & \textbf{0.743} & \textbf{0.279} & \textbf{6.195} \\
    \hline \hline
    %\vspace{-2em}
    \end{tabular} %}
\end{table*}