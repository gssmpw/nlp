\begin{table*}[t]
\centering
  \caption{\textbf{Entropy Regularization Loss Coefficient.} VGG17 models are pre-trained on the ImageNet-10 (10 ImageNet classes) ID dataset and evaluated on 8 OOD datasets. %via linear probing. %Reported is the top-1 error (\%). %Increasing the entropy regularization loss coefficient increases embedding rank and decreases OOD transfer error. 
  $\alpha$ denotes the entropy regularization loss coefficient. We use a regular VGG17 network without the projector to focus on entropy regularization. Effective rank corresponds to penultimate embeddings. For OOD generalization, we report $\boldsymbol{\mathcal{E}}_{\text{GEN}}$ (\%).
  } 
  \label{tab:entropy_loss_coeff}
  \centering
  \resizebox{\linewidth}{!}{
     \begin{tabular}{ccc|ccccccccc}
     \hline %\hline
     \multicolumn{1}{c}{\textbf{Reg. Coeff.}} &
     \multicolumn{1}{c}{$\boldsymbol{\mathcal{E}}_{\text{ID}} \downarrow$} &
     \multicolumn{1}{c|}{\textbf{Rank} $\uparrow$} &
     \multicolumn{9}{c}{$\boldsymbol{\mathcal{E}}_{\text{GEN}} \downarrow$} \\
    $\mathbf{\alpha}$ & IN & IN & IN-R & CIFAR & Flowers & NINCO & CUB & Aircrafts & Pets & STL & Avg. \\
    % \hline %\hline
    & 10 & 10 & 200 & 100 & 102 & 64 & 200 & 100 & 37 & 10 & \\ 
    \hline
    %0 & \textbf{90.80} & 2211.99 & 5.38 & 16.23 & 27.55 & 34.44 & 13.24 & 10.68 & 19.68 & 50.56 & 22.22 \\
    0 & \textbf{9.20} & 2211.99 & 94.62 & 83.77 & 72.45 & 65.56 & 86.76 & 89.32 & 80.32 & 49.44 & 77.78 \\
    %0.1 & 90.20 & 2964.39 & 9.28 & 24.42 & 42.06 & 49.91 & 20.04 & 15.87 & 27.28 & 60.21 & 31.13 \\
    0.1 & 9.80 & 2964.39 & 90.72 & 75.58 & 57.94 & 50.09 & 79.96 & 84.13 & 72.72 & 39.79 & 68.87 \\
    %0.2 & 89.80 & 3170.92 & 9.75 & 27.23 & 42.16 & 49.15 & 20.52 & 15.84 & 29.57 & \textbf{62.29} & 32.06 \\
    0.2 & 10.20 & 3170.92 & 90.25 & 72.77 & 57.84 & 50.85 & 79.48 & 84.16 & 70.43 & \textbf{37.71} & 67.94 \\
    %%0.3 & 89.20 & -- & 10.23 & 28.70 & 46.08 & 50.51 & 21.56 & 16.74 & 30.34 & 61.61 & 33.22 \\
    %0.6 & 88.00 & 3761.33 & \textbf{11.67} & 31.27 & \textbf{49.71} & 52.55 & \textbf{22.90} & 17.43 & \textbf{32.27} & 61.00 & 34.85 \\
    0.6 & 12.00 & 3761.33 & \textbf{88.33} & 68.73 & \textbf{50.29} & 47.45 & \textbf{77.10} & 82.57 & \textbf{67.73} & 39.00 & 65.15 \\
    %1.0 & 87.20 & \textbf{4815.32} & 11.62 & \textbf{32.19} & \textbf{49.71} & \textbf{52.89} & 22.52 & \textbf{18.36} & 31.73 & 61.26 & \textbf{35.04} \\
    1.0 & 12.80 & \textbf{4815.32} & 88.38 & \textbf{67.81} & \textbf{50.29} & \textbf{47.11} & 77.48 & \textbf{81.64} & 68.27 & 38.74 & \textbf{64.96} \\
    \hline %\hline
    %\vspace{-2em}
    \end{tabular}
    }
\end{table*}
