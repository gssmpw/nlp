\begin{figure*}[t]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/umap_enc_proj_10c_IN_ninco_64_vgg17.png}
        \caption{UMAP of Embeddings}
        \label{fig:umap_id_ood}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/energy_ood_ninco.png}
        \caption{Energy Score Distribution}
        \label{fig:eng_id_ood}
    \end{subfigure}
    \caption{\textbf{ID \& OOD Data Visualization.} In \textbf{(a)}, The projector exhibits a greater separation between ID and OOD embeddings than the encoder. For clarity, we show 10 ImageNet classes as ID data and 64 classes from the NINCO dataset as OOD data. 
    In \textbf{(b)}, The projector achieves higher energy scores (and lower FPR95) for ID data.
    For ID and OOD datasets, we show ImageNet-100 and NINCO-64 respectively.
    }
    \label{fig:umap_eng_id_ood}
\end{figure*}






%\begin{figure}[t]
%    \centering
%    \includegraphics[width = 0.99\linewidth]{images/umap_enc_proj_10c_IN_ninco_64_vgg17.png}
%  \caption{\textbf{UMAP of ID and OOD Embeddings.} The projector exhibits a greater separation between ID and OOD embeddings. In contrast, the encoder shows a lot of overlap between ID and OOD embeddings. The embeddings are extracted from ImageNet-100 pre-trained VGG17. For clarity, we show 10 ImageNet classes as ID data and 64 classes from the NINCO dataset as OOD data.} 
%  \label{fig:umap_id_ood}
%\end{figure}