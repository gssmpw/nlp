\section{Conclusion} \label{sec:conclusion}

This survey provides a comprehensive overview of discrete tokenizers, which leverage vector quantization (VQ) techniques to transform continuous multimodal features into discrete semantic representations. 
By evolving from vanilla VQ methods to modern approaches, discrete tokenizers have become fundamental components for bridging different modalities with foundation models. 
Their applications span from enhancing recommendation systems' efficiency to enabling high-quality multimodal generation.
By summarizing the challenges faced by discrete tokenizers, we aim to contribute to the understanding and advancement of this field, 
identifying promising directions in the era of foundation models and multimodal AI.
