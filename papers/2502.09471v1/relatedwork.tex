\section{Related work}
\label{sec:work}

Beyond horizontal detection \cite{Zhao2019Object, liu2020deep,zheng2024zone}, oriented object detection (OOD) \cite{wen2023comprehensive} has received extensive attention. Here, approaches related to oriented detection and studies related to HBox/Point supervision are discussed.

\textbf{Fully-supervised oriented detection.} Representative works include anchor-based detector Rotated RetinaNet \cite{Lin2017Focal}, anchor-free detector Rotated FCOS \cite{Tian2019FCOS}, and two-stage solutions, e.g. RoI Transformer \cite{Ding2018Learning}, Oriented R-CNN \cite{Xie2021Oriented}, and ReDet \cite{Han2021Redet}. Some research enhances the detector by exploiting alignment features, e.g. R$^3$Det \cite{Yang2021R3Det} and S$^2$A-Net \cite{Han2022Align}. The angle regression may face boundary discontinuity and remedies are developed, including modulated losses \cite{Yang2019SCRDet, Qian2021RSDet} that alleviate loss jumps, angle coders \cite{Yang2020Arbitrary, Yang2021Dense, yu2024boundary} that convert the angle into boundary-free coded data, and Gaussian-based losses \cite{Yang2021Rethinking, Yang2021Learning, yang2023detecting, yang2023kfiou} transforming RBoxes into Gaussian distributions. RepPoint-based methods \cite{Yang2019Reppoints, hou2022grep, li2022oriented} provide alternatives that predict a set of sample points that bounds the spatial extent of an object. LMMRotate \cite{li2025simple} is a new paradigm of OOD based on multimodal language model and performs object localization through autoregressive prediction.

\textbf{HBox-to-RBox.} 
Before our studies, some methods use HBoxes with additional annotated data for training: \textbf{1)} OAOD \cite{iqbal2021leveraging} is proposed for weakly-supervised OOD. But in fact, it uses HBox along with an object angle as annotation, which is just ``slightly weaker" than RBox supervision. Such an annotation manner is not common, and OAOD is only verified on their self-collected ITU Firearm dataset. 
\textbf{2)} Sun et al. \cite{sun2021oriented} propose a two-stage framework: i) training detector with the annotated horizontal and vertical objects, and ii) mining the rotation objects by rotating the training image to align the oriented objects as horizontally or vertically as possible.
\textbf{3)} KCR \cite{zhu2023knowledge} combines a RBox-annotated source dataset with a HBox-annotated target dataset, and achieves HBox-to-RBox on the target dataset via transfer learning.

Some studies focus on a similar task, HBox-to-Mask: \textbf{1)} SDI \cite{khoreva2017simple} refines the segmentation through an iterative training process; \textbf{2)} BBTP \cite{hsu2019weakly} formulates the HBox-supervised instance segmentation into a multiple-instance learning problem based on Mask R-CNN \cite{he2017mask}; \textbf{3)} BoxInst \cite{tian2021boxinst} uses the color-pairwise affinity with box constraint under an efficient RoI-free CondInst \cite{tian2020conditional}; \textbf{4)} BoxLevelSet \cite{li2022box} introduces an energy function to predict the instance-aware mask as the level set; \textbf{5)} SAM (Segment Anything Model) \cite{kirillov2023segany} produces object masks from input Point/HBox prompts. Though RBoxes can be obtained from the segmentation mask by finding the minimum circumscribed rectangle, we show that such a cascade pipeline can be less cost-efficient (see Sec. \ref{sec:exp}). 

To fill the blank of HBox-to-RBox, we have proposed H2RBox \cite{yang2023h2rbox} and H2RBox-v2 \cite{yu2023h2rboxv2}. H2RBox directly achieves RBox detection from HBox annotations, bypassing segmentation. With HBox labels for the same object in various orientations, the geometric constraint limits candidate angles. Supplemented with a self-supervised branch eliminating the undesired results, an HBox-to-RBox paradigm is established. An enhanced version H2RBox-v2 \cite{yu2023h2rboxv2} is proposed to leverage the reflection symmetry of objects to estimate their angle, further boosting the HBox-to-RBox performance. Inspired by our work, EIE-Det \cite{wang2024explicit} uses an explicit equivariance branch for learning rotation consistency, and an implicit equivariance branch for learning position, aspect ratio, and scale consistency. AFWS \cite{lu2024afws} simplifies the model training process by decoupling horizontal and rotating parameters.

Particularly, our H2RBox-v2 \cite{yu2023h2rboxv2} has bridged the gap between HBox- and RBox-supervised OOD. In this paper, we employ a similar theoretical foundation in the HBox-to-RBox part of Wholly-WOOD, with a more concise architecture and significantly reduced RAM usage.

\textbf{Point-to-RBox.} Compared to Point-to-RBox, the Point-to-HBox setting has been better studied: \textbf{1)} P2BNet \cite{chen2022pointtobox} samples box proposals of different ratios and sizes around the labeled point and classifies them via multiple instance learning to achieve point-supervised horizontal object detection. \textbf{2)} PSOD \cite{gao2022weakly} achieves point-supervised salient object detection using an edge detector and adaptive masked flood fill. \textbf{3)} LESPS \cite{ying2023mapping} proposes a label evolution framework to progressively expand the point label by leveraging the intermediate predictions of CNNs for infrared small target detection.

Some methods accept partial point annotations (e.g. 80\% points and 20\% HBoxes), usually termed semi-supervision: 
\textbf{1)} Point DETR \cite{chen2021points} extends DETR \cite{carion2020detr} by adding a point encoder for point annotations. 
\textbf{2)} Group-RCNN \cite{zhang2022grouprcnn} generates a group of proposals for each point annotation.
\textbf{3)} CPR \cite{yu2022object} produces center points from coarse point annotations, relaxing the supervision from accurate points to freely spotted points.

Besides the Point-to-HBox methods, Point-to-Mask has also been an active area: Point2Mask \cite{li2023point2mask} is proposed to achieve panoptic segmentation using only a single point annotation per target for training. SAM (Segment Anything Model) \cite{kirillov2023segany} produces object masks from input Point/HBox prompts.

These Point-to-HBox/Mask methods are potentially applicable to our Point-to-RBox task setting -- by using a subsequent HBox/Mask-to-RBox to build a cascade solution. 

Recently, several approaches directly aimed at Point-to-RBox have been proposed: \textbf{1)} PointOBB \cite{luo2024pointobb} achieves point annotation based RBox generation method for oriented object detection through scale-sensitive consistency and multiple instance learning. \textbf{2)} P2RBox \cite{cao2023p2rbox} proposes oriented object detection with point prompts by employing the zero-shot Point-to-Mask ability of SAM \cite{kirillov2023segany}.

Our conference paper Point2RBox \cite{yu2024point2rbox} has also introduced a novel approach based on knowledge combination in this domain. While achieving competitive accuracy compared to state-of-the-art methods, it still has room for improvement, particularly in handling FPN/anchor assignments. In Wholly-WOOD, we incorporate the concept of knowledge combination and address the assignment issue, resulting in a substantially enhanced Point-to-RBox performance, about 22.36\%.

For comprehensive evaluation, our experiments will compare Wholly-WOOD with Point-to-RBox approaches such as PointOBB series \cite{luo2024pointobb,ren2025pointobbv2}, P2RBox \cite{cao2023p2rbox}, and Point2RBox \cite{yu2024point2rbox}, as well as cascade solutions driven by leading methodologies like P2BNet \cite{chen2022pointtobox} and Point2Mask \cite{li2023point2mask} (see Sec. \ref{sec:exp}).