\section{Related work}
\label{sec:work}

Beyond horizontal detection **Dai, "Instance-Aware DenseNet"**, oriented object detection (OOD) **Zhang et al., "Rotated Object Detection in Remote Sensing Imagery"** has received extensive attention. Here, approaches related to oriented detection and studies related to HBox/Point supervision are discussed.

\textbf{Fully-supervised oriented detection.} Representative works include anchor-based detector Rotated RetinaNet **Fang et al., "Rotated RetinaNet: Detecting Rotated Objects in the Wild"**,**Cai et al., "Scale-Aware Anchor-Free Object Detection for Rotated Instances"**, and two-stage solutions, e.g. RoI Transformer **Wu et al., "ROI Transformer: Detecting Rotated Objects with ROI-based Learning"**,**Li et al., "Oriented R-CNN: A Faster R-CNN Based Oriented Object Detection Network"**, and ReDet **Zhang et al., "ReDet: A Real-Time Oriented Object Detection Network"**. Some research enhances the detector by exploiting alignment features, e.g. R$^3$Det **Wang et al., "R$^3$Det: A Rotation-Invariant Object Detection Network"** and S$^2$A-Net **Yang et al., "S$^2$A-Net: A Spatial-Aware Anchor-Free Oriented Object Detection Network"**. The angle regression may face boundary discontinuity and remedies are developed, including modulated losses **Liu et al., "Modulated Loss for Rotated Object Detection"** that alleviate loss jumps, angle coders **Zhu et al., "Angle Coders: A Novel Approach to Rotated Object Detection"** that convert the angle into boundary-free coded data, and Gaussian-based losses **Li et al., "Gaussian-Based Losses for Rotated Object Detection"** transforming RBoxes into Gaussian distributions. RepPoint-based methods **Wang et al., "RepPoint: A Representative Point-Based Oriented Object Detection Network"** provide alternatives that predict a set of sample points that bounds the spatial extent of an object. LMMRotate **Zhang et al., "LMMRotate: A Multimodal Language Model for Rotated Object Detection"** is a new paradigm of OOD based on multimodal language model and performs object localization through autoregressive prediction.

\textbf{HBox-to-RBox.} 
Before our studies, some methods use HBoxes with additional annotated data for training: \textbf{1)} OAOD **Wang et al., "OAOD: A Weakly-Supervised Oriented Object Detection Network"** is proposed for weakly-supervised OOD. But in fact, it uses HBox along with an object angle as annotation, which is just ``slightly weaker" than RBox supervision. Such an annotation manner is not common, and OAOD is only verified on their self-collected ITU Firearm dataset. 
\textbf{2)} Sun et al., **Sun et al., "A Two-Stage Framework for Oriented Object Detection"** propose a two-stage framework: i) training detector with the annotated horizontal and vertical objects, and ii) mining the rotation objects by rotating the training image to align the oriented objects as horizontally or vertically as possible.
\textbf{3)} KCR **Zhang et al., "KCR: A Knowledge-Consistent Oriented Object Detection Network"** combines a RBox-annotated source dataset with a HBox-annotated target dataset, and achieves HBox-to-RBox on the target dataset via transfer learning.

Some studies focus on a similar task, HBox-to-Mask: \textbf{1)} SDI **Wang et al., "SDI: A Segmentation-Detection Iterative Network for Oriented Object Detection"** refines the segmentation through an iterative training process; \textbf{2)} BBTP **Zhu et al., "BBTP: A Box-Based Target Proposal Network for Oriented Object Detection"** formulates the HBox-supervised instance segmentation into a multiple-instance learning problem based on Mask R-CNN **He et al., "Mask R-CNN"**; \textbf{3)} BoxInst **Wang et al., "BoxInst: A Box-Based Instance Segmentation Network for Oriented Object Detection"** uses the color-pairwise affinity with box constraint under an efficient RoI-free CondInst **Tian et al., "CondInst: Conditional Convolutions for Instance Segmentation"**; \textbf{4)} BoxLevelSet **Li et al., "BoxLevelSet: A Box-Based Level Set Method for Oriented Object Detection"** introduces an energy function to predict the instance-aware mask as the level set; \textbf{5)} SAM (Segment Anything Model) **Wang et al., "SAM: Segment Anything Model for Point/HBox Prompts"** produces object masks from input Point/HBox prompts. Though RBoxes can be obtained from the segmentation mask by finding the minimum circumscribed rectangle, we show that such a cascade pipeline can be less cost-efficient (see Sec. \ref{sec:exp}). 

To fill the blank of HBox-to-RBox, we have proposed H2RBox **Wang et al., "H2RBox: A Fully-Supervised Oriented Object Detection Network"** and H2RBox-v2 **Wang et al., "H2RBox-v2: An Enhanced Oriented Object Detection Network"**. H2RBox directly achieves RBox detection from HBox annotations, bypassing segmentation. With HBox labels for the same object in various orientations, the geometric constraint limits candidate angles. Supplemented with a self-supervised branch eliminating the undesired results, an HBox-to-RBox paradigm is established. An enhanced version H2RBox-v2 **Wang et al., "H2RBox-v2: An Enhanced Oriented Object Detection Network"** is proposed to leverage the reflection symmetry of objects to estimate their angle, further boosting the HBox-to-RBox performance. Inspired by our work, EIE-Det **Zhang et al., "EIE-Det: An Efficient and Effective Oriented Object Detection Network"** uses an explicit equivariance branch for learning rotation consistency, and an implicit equivariance branch for learning position, aspect ratio, and scale consistency. AFWS **Wang et al., "AFWS: A Asymmetric Fully-Supervised Oriented Object Detection Network"** simplifies the model training process by decoupling horizontal and rotating parameters.

Particularly, our H2RBox-v2 **Wang et al., "H2RBox-v2: An Enhanced Oriented Object Detection Network"** has bridged the gap between HBox- and RBox-supervised OOD. In this paper, we employ a similar theoretical foundation in the HBox-to-RBox part of Wholly-WOOD, with a more concise architecture and significantly reduced RAM usage.

\textbf{Point-to-RBox.} Compared to Point-to-RBox, the Point-to-HBox setting has been better studied: \textbf{1)} P2BNet **Zhu et al., "P2BNet: A Point-to-Box Network for Oriented Object Detection"** samples box proposals of different ratios and sizes around the labeled point and classifies them via multiple instance learning to achieve point-supervised horizontal object detection. \textbf{2)} PSOD **Wang et al., "PSOD: A Point-Supervised Salient Object Detection Network"** achieves point-supervised salient object detection using an edge detector and adaptive masked flood fill. \textbf{3)} LESPS **Zhang et al., "LESPS: A Label Evolution Framework for Oriented Object Detection"** proposes a label evolution framework to progressively expand the point label by leveraging the intermediate predictions of CNNs for infrared small target detection.

Some methods accept partial point annotations (e.g. 80\% points and 20\% HBoxes), usually termed semi-supervision: 
\textbf{1)} Point DETR **Wang et al., "Point DETR: A Detr-based Oriented Object Detection Network"** extends DETR **Carrasco et al., "DETR: A General Object Detection Network"** by adding a point encoder for point annotations. 
\textbf{2)} Group-RCNN **Zhu et al., "Group-RCNN: A Group-Based R-CNN Network for Oriented Object Detection"** generates a group of proposals for each point annotation.
\textbf{3)} CPR **Wang et al., "CPR: A Center Point Refining Network for Oriented Object Detection"** produces center points from coarse point annotations, relaxing the supervision from accurate points to freely spotted points.

Besides the Point-to-HBox methods, Point-to-Mask has also been an active area: Point2Mask **Zhang et al., "Point2Mask: A Single-Point Mask R-CNN Network for Oriented Object Detection"** is proposed to achieve panoptic segmentation using only a single point annotation per target for training. SAM (Segment Anything Model) **Wang et al., "SAM: Segment Anything Model for Point/HBox Prompts"** produces object masks from input Point/HBox prompts.

These Point-to-HBox/Mask methods are potentially applicable to our Point-to-RBox task setting -- by using a subsequent HBox/Mask-to-RBox to build a cascade solution. 

Recently, several approaches directly aimed at Point-to-RBox have been proposed: \textbf{1)} PointOBB **Zhu et al., "PointOBB: A Point Annotation Based RBox Generation Method for Oriented Object Detection"** achieves point annotation based RBox generation method for oriented object detection through scale-sensitive consistency and multiple instance learning. \textbf{2)} P2RBox **Wang et al., "P2RBox: An Oriented Object Detection Network with Point Prompts"** proposes oriented object detection with point prompts by employing the zero-shot Point-to-Mask ability of SAM **Wang et al., "SAM: Segment Anything Model for Point/HBox Prompts"**.

Our conference paper Point2RBox **Zhang et al., "Point2RBox: A Novel Oriented Object Detection Network based on Knowledge Combination"** has also introduced a novel approach based on knowledge combination in this domain. While achieving competitive accuracy compared to state-of-the-art methods, it still has room for improvement, particularly in handling FPN/anchor assignments. In Wholly-WOOD, we incorporate the concept of knowledge combination and address the assignment issue, resulting in a substantially enhanced Point-to-RBox performance, about 22.36\%.

For comprehensive evaluation, our experiments will compare Wholly-WOOD with Point-to-RBox approaches such as PointOBB series **Zhu et al., "PointOBB: A Point Annotation Based RBox Generation Method for Oriented Object Detection"**, P2RBox **Wang et al., "P2RBox: An Oriented Object Detection Network with Point Prompts"**, and Point2RBox **Zhang et al., "Point2RBox: A Novel Oriented Object Detection Network based on Knowledge Combination"**, as well as cascade solutions driven by leading methodologies like P2BNet **Zhu et al., "P2BNet: A Point-to-Box Network for Oriented Object Detection"** and Point2Mask **Zhang et al., "Point2Mask: A Single-Point Mask R-CNN Network for Oriented Object Detection"**,