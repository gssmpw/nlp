\section{Related Work}
\label{sec:related_work_task_repr}
Here, we discuss studies that specifically focus on learning task representations in ICL. A more comprehensive review of related works is available in Appendix \ref{app:related_work}.

Initial studies on developing task representations for transformers are documented in ____. These works proposed methods to create compositional task encodings through model perturbations in the parameter space: ``soft'' prompts, codebooks, and meta-mappings. Notably, the term \emph{task vectors} was first introduced in ____. In contrast, through the application of causal mediation analysis ____, \textit{function vectors} were discovered to exist inherently within the transformer architecture and to exhibit strong causal effects ____. This finding aligns with research on RNNs, where it was demonstrated that RNN hidden states can be grouped based on task similarities ____.

Efforts to represent ICL tasks often derive a task vector from the layer activations associated with the dummy token following the input query ____. This approach was later refined by averaging the layer activations of dummy tokens across a few-shot prompt and optimizing them ____. However, these methods were primarily designed for language tasks, where input-output pairs are explicitly separated by specific tokens (e.g., ``\(\rightarrow\)''). This limitation restricts their applicability to broader domains, such as regression tasks. Another approach leverages the first principal component of the difference in layer activations to guide the ICL task, resulting in \textit{In-Context Vectors} (ICVs) ____. Notably, attention heads have been argued to play a critical role in transferring information between token positions ____. Building on this insight, the \textit{Function Vector} (FV) ____ is computed as the sum of activations from a specific subset of attention heads, selected based on an \emph{indirect metric} derived from causal inference literature ____. In this study, we aim to develop a structured and automated method for extracting function vectors from transformer architectures, expanding on the approach of Todd et al. ____.