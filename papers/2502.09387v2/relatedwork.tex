\section{Related Work}
\label{sec:related_work}

A significant challenge in contemporary Artificial Intelligence (AI) research concerns the development of methodologies to optimize LLMs for factual accuracy and veracity in their outputs. %
Improving factual consistency and reducing hallucinations would help to increase trust in LLMs thereby increasing their application across various domains. Apart from the popular TruthfulQA, already introduced in Section \ref{sec:data}, other approaches include SimpleQA \cite{wei2024measuring},
and VeritasQA \cite{aula-blasco-etal-2025-veritasqa}.

SimpleQA is a benchmark dataset designed for evaluating the abilities of LLMs to answer factual questions, specifically targeting short, fact-seeking queries. The dataset %
features dual-source verification for answer validation, %
and shows an increased difficulty compared to legacy benchmarks (e.g., \citet{joshi-etal-2017-triviaqa} or \citet{kwiatkowski-etal-2019-natural}), where current LLMs show performance saturation. 

VeritasQA is a multilingual dataset to evaluate truthfulness in LLMs, currently available in English, Spanish, Catalan, and Galician. It consists of 353 questions (288 from the 817 available in the original TruthfulQA plus 65 added from scratch). The dataset is designed to be transferable across languages, context-independent, and temporally stable. The empirical evidence presented in Figure \ref{fig:contextual} indicates that LLMs are approaching performance saturation on datasets such as VeritasQA that exclusively test universal knowledge. %