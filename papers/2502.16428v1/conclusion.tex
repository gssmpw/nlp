\section{Conclusion} \label{sec:conclusion}


This study provides a comprehensive evaluation of multimodal LLMs, revealing significant differences in reasoning stability, bias susceptibility, and uncertainty handling. ChatGPT-o1 and ChatGPT-4o consistently outperformed other models, demonstrating superior consistency, balanced rejection reasoning, and effective uncertainty calibration. These results highlight the advantages of extensive fine-tuning and high-quality training data in proprietary models.

Grok 3, despite its massive parameter count of 2.7 trillion, failed to meet expectations, showcasing inconsistent reasoning stability, excessive rejection behavior, and moderate overall accuracy. Its high abstention rate (0.375) indicates an overly conservative approach, emphasizing that scale alone does not guarantee better performance. Similarly, Janus 7B and Janus 1B displayed the lowest rejection accuracy and reluctance to abstain, reflecting a bias towards overcommitting to answers, likely due to insufficient exposure to rejection-based reasoning.

This study also highlights the impact of reordered answer variations in detecting positional biases. Models with high entropy scores, such as Janus 7B (0.8392) and Janus 1B (0.787), exhibited greater variability and susceptibility to positional heuristics, whereas ChatGPT-o1 (0.1352) and ChatGPT-4o (0.216) maintained consistent reasoning patterns. The introduction of entropy as a reasoning consistency metric provides a novel, quantitative measure of stability across reordered variants, revealing limitations in traditional VQA metrics that focus solely on correctness.

Rejection accuracy and abstention rates further exposed weaknesses in uncertainty calibration. QVQ-72B-Preview displayed the highest rejection accuracy but also over-rejected, exceeding the 0.33 threshold, reflecting risk-averse decision-making. Conversely, Janus models consistently avoided rejection, highlighting poor uncertainty recognition. The balanced rejection strategies of ChatGPT-o1 and ChatGPT-4o illustrate the importance of strategic abstention for reliable decision-making.

Overall, this study underscores the need for advanced benchmarks that incorporate reordered answers, entropy-based consistency metrics, and rejection accuracy to more effectively evaluate reasoning stability and uncertainty calibration. Addressing positional biases, refining rejection strategies, and enhancing generalization are crucial for advancing multimodal LLMs' real-world applicability.