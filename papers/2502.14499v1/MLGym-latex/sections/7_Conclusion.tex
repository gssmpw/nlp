\section{Discussion and Limitations}
\label{sec:discussion}
Our findings highlight both the opportunities and ongoing challenges in leveraging large language models (LLMs) as agents for scientific workflows. The proposed \mlgym framework and accompanying \mlgym-Bench tasks demonstrate that modern LLM agents can successfully tackle a diverse array of quantitative experiments, reflecting advanced skills and domain adaptability. At the same time, our results reveal notable capability gaps, which point to several avenues for improvement:

\begin{itemize}
\item \textbf{Scaling beyond ML tasks}
To further evaluate the agent's AI Research capabilities, it is essential to scale up the evaluation framework to accommodate large-scale domain-specific datasets, more complex tasks, as well as domains outside AI. This will enable the community to assess the robustness and generalizability of different methods, as well as identify potential limitations and areas for improvement.

\item \textbf{Interdisciplinary Ablations and Generalization}
Within the stage of method evaluation, one approach is to test the solutions for generalization: 
\begin{itemize}
    \item automatically evaluating the applicability of a new method on different domains .
    % conducting method evaluation on different domains of data to evaluate applicability automatically, mechanically validating and finding the limits of applicability of methods. 
    For example, new LLM architectures like Mamba \citep{gu2024mambalineartimesequencemodeling} could be automatically applied to data on DNA, chemical molecules, music generation, etc.
    \item automatically running interdisciplinary and multidisciplinary ablations, where we systematically remove or modify specific components of the proposed ML system to assess their impact on performance. This will enable the community to more quickly identify the most critical factors contributing to generalization across different domains.
  % for more complex agentic pipelines, 
\end{itemize}


\item \textbf{Addressing Scientific Novelty}
While the agentic benchmarks have demonstrated their effectiveness in evaluating complex tasks in different areas, it is essential to acknowledge that proposed interdisciplinary extrapolation of methods is just one aspect of the broader scientific understanding of "novelty" and "discovery"~\citep{popper2005logic, langley1987scientific}. It is not yet clear if the notion of scientific novelty can be successfully automated or even formally defined in a form suitable for agents.
% To address this, we propose the gradual leveling of the scientific agent autonomy \ref{sec:intro}.
%\todo[inline]{@tatiana: add link in the above line}
For many scientific disciplines, development may be uneven and depend on the availability of open data, the development of the methods, metrics and definitions used. 
% It is worth explicitly taking into account the degree of automation in each individual scientific discipline, focus on increasing reproducibility, explainability, fairness.

\item \textbf{Data Openness Imperative}
Finally, we emphasize the importance of data openness in driving scientific progress. By making our representative 'corpus of the world' widely accessible, including scientific artifacts, reproducible code, and domain-specific data for modeling, we can facilitate collaboration and accelerate discovery. This imperative is crucial for advancing our understanding of complex systems and developing more effective solutions to real-world problems. Removing once accessible resources that have entered LLM training from public access can have an irreparable impact on the acceleration of scientific progress, as it becomes impossible to identify sources of facts, and it is impossible to attribute the out-of-distribution result from a scientific work from a hallucination or a completely new result.
\end{itemize}

\section{Ethical Considerations}
\label{sec:ethics}

AI agents proficient in tackling open research challenges like those in our benchmark could catalyze a remarkable acceleration in scientific advancement. This prospect is exhilarating yet demands a meticulous comprehension of model progress to ensure responsible and controlled deployment of such breakthroughs. \mlgym-Bench, for instance, can serve as a metric for model autonomy within OpenAI's Preparedness Framework, autonomous capabilities in Anthropic's Responsible Scaling Policy, and ML R\&D in Google DeepMind's Frontier Safety Framework.

Should AI agents become adept at autonomously conducting AI research, the positive impacts could be multifaceted, encompassing accelerated scientific progress in healthcare, climate science, and other domains, expedited safety and alignment research for models, and economic growth spurred by the development of novel products. The ability of agents to deliver high-quality research could signify a transformative stride in the economy.

Nonetheless, agents capable of executing open-ended AI research tasks, such as enhancing their own training code, could augment the capabilities of cutting-edge models at a pace outstripping human researchers. If innovations outpace our ability to comprehend their ramifications, we risk developing models with catastrophic harm or misuse potential without parallel advancements in securing, aligning, and controlling such models. We believe a model proficient in solving a substantial portion of \mlgym-Bench likely possesses the capacity to execute numerous open-ended AI tasks. We are open-sourcing \mlgym and \mlgym-Bench to foster understanding and research into the agentic capabilities of AI Research Agents and promote transparency regarding acceleration risks in frontier AI labs. In doing so, we acknowledge the limitations of \mlgym-Bench and strongly encourage the development of additional evaluations of automated AI research capabilities, particularly those tailored to the workflow of researchers training frontier models.


\section{Conclusions}
\label{sec:conclusion}

This paper presents \textsc{\mlgym} and \mlgym-Bench as initial steps toward building robust, flexible, and transparent LLM agents for AI research. As the field continues to evolve, improvements in long-context reasoning, better agent architectures, training and inference algorithms, as well as richer evaluation methodologies will be essential to fully harness LLMsâ€™ potential for scientific discovery, in general and for AI research in particular. By fostering collaboration among researchers in machine learning, scientific computing, and diverse application domains, we can move closer to a future where AI-driven agents meaningfully accelerate scientific research, all while maintaining verifiability, reproducibility, and integrity in scientific discovery.

% \section{Limitations}
% \label{sec:limitations}
% Generalization

% Lack of data

% Absence of baseline for some real scientific tasks

% Levelling of agents and the current state of thigs

% Contamination/Data leakage 


\section{Acknowledgments}
\label{sec:ack}
We thank Sten Sootla, Mikayel Samvelyan, Sharath Chandra Raparthy, Mike Plekhanov, and Rishi Hazra for many insightful discussions about evaluating and developing AI Research Agents.
