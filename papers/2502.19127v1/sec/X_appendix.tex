\newpage

\section{More Details of FactualBench}
In this section, we will introduce more details of our dataset, FactualBench, including prompts used for generation and evaluation, more examples of data in FactualBench, LLMs performance on FactualBench and related analyses.

\subsection{Prompts in Construction}
\label{cha:generation prompts}
Figure \ref{fig:generation prompt} shows the complete prompt we use in \textit{Question Generation} stage, and Figure \ref{fig:generation prompt english} shows an English translation version. We include two manually written examples as few-shots and insert the target object with its description in the position marked in \textcolor{orange}{orange}.

Figure \ref{fig:filter prompt} shows the complete prompt we use in \textit{Question Filtering} stage, and Figure \ref{fig:filter prompt english} shows an English translation version. We list four types of low-quality cases and required GPT4 to judge whether the question falls into one. The question under judgment should be placed in the position marked in \textcolor{red}{red}.

\subsection{Prompt in Evaluation}
\label{cha:evaluation prompts}
Figure \ref{fig:eval prompt} shows the complete prompt we use when evaluating the correctness of a response, and Figure \ref{fig:eval prompt english} shows an English translation version. We include five judging examples that cover the situations of answering correctly, answering incorrectly, and refusing to answer. The verifier is supposed to show its analysis before providing the judgment. The question, standard answer, and model's candidate answer should be placed in the position marked in \textcolor{green}{green}.

\subsection{More Examples in FactualBench}
\label{cha:more examples}
We list one example of each domain (exclude \textit{others}) in FactualBench in Table \ref{tab:more example1}, \ref{tab:more example2}, \ref{tab:more example3}. We provide English translations for reference only, and the questions are highlighted in \textcolor{blue!90}{blue}.

\subsection{Detailed Benchmark Results}
\label{cha:detailed result}
We benchmark 14 LLMs on our FactualBench dataset: Baichuan1 (closed), Baichuan2 (closed), Qwen1.5-7B-Chat (open), Qwen2-7B-Instruct (open), Llama-3-8B-Instruct (open), Baichuan3 (closed), Yi-34B-Chat (open), Command-R-35B (open), Llama-3-70B-Instruct (open), Qwen2-72B-Instuct (open), Baichuan4 (closed), Command-R-plus-104B (open), DeepSeek-v2-0628 MoE-236B (open), GPT4-0125-preview (closed), among which DeepSeek and GPT4 are queried from API and others are run locally. We use the recommended generation configuration and code on huggingface\footnote{\url{https://huggingface.co/}} to generate responses, and we set max-new-tokens and max-length configuration large enough to ensure that models can complete all their responses to questions.

We present the performance of 14 LLMs on our FactualBench at a domain level using a heatmap in Figure \ref{fig:heatmap benchmark}. The first column presents the overall accuracy of the model, and the last line shows the average accuracy of all 14 models. We arrange domains from left to right in descending order of the average accuracy. Each domain is represented by its first five letters.

It is evident from the figure that as the number of model parameters increases, there is a corresponding upward trend in accuracy, while models with proficiency in Chinese demonstrate superior performance compared to those primarily proficient in English with approximate parameter numbers, which are aligned with our expectations. Additionally, we have identified two key findings: 
\textbf{1) The performance of the same model can vary significantly across various domains}; 
\textbf{2) Different models share a consistency in relative ability on different domains}. Specifically, models tend to share similar domains where they achieve higher (or lower) accuracy, and there is no domain where one model excels (ranking in the top five accuracy domains) while another performs poorly (ranking in the bottom five accuracy domains). Interestingly, the film\&entertainment domain constitutes the largest portion of all data, but models exhibit the lowest accuracy among all domains.

We attribute the phenomenon to two possible primary factors. Firstly, the type of knowledge required varies across different domains. Secondly, the distribution of training data across these domains is uneven. These two factors contribute to the varying difficulty of tasks in different domains, and the differing levels of mastery that LLMs have over the knowledge pertinent to each domain, respectively.

\subsection{LLMs Responses in High Temp.}
\label{cha:BO8 cases}
We present illustrative examples of model responses, including one instance from Baichuan1 on a test case (Table \ref{tab:bo1vsbo8 example bc}) and two examples from Qwen2-7B-Instruct on training cases (Table \ref{tab:bo8 example qwen}). For clarity, we provide English translations of key response details within square brackets ([]). The examples reveal that while Baichuan1 produces incorrect answers to questions under a low-temperature configuration, it can sometimes generate more correct responses to them under a high-temperature configuration. Similarly, Qwen2 exhibits substantial variation in its responses under the high-temperature setting.

\begin{CJK*}{UTF8}{gbsn}
\begin{figure*}
\centering
\begin{tcolorbox}[title=Question generation, width=\textwidth]
我将提供给你一个对象和相关的参考文档，请针对对象提出最多\{提问个数：3\}个事实性问题。要求每个问题都具有唯一且准确的答案，避免答案模糊或存在争议，避免涉及主观判断的问题和时效性问题，要求答案可以在参考文档中直接找到。要求提问的问题表达清晰，问题中的名词指代明确，不需要依赖参考文档即可理解问题内容。对每个问题，给出 1 个标准答案和 3 个具有干扰性的错误答案。

下面是两个例子：

\vspace{1em}

【对象】：\{示例对象1\}

【参考文档】：\{关于示例对象1的百科内容简介\}

【问题1】：\{针对示例对象1提出的示例问题1\}

【标准答案】：\{示例问题1标准答案\}

【错误答案1】：\{示例问题1错误答案1\}

【错误答案2】：\{示例问题1错误答案2\}

【错误答案3】：\{示例问题1错误答案3\}

\vspace{1em}

【对象】：\{示例对象2\}

【参考文档】：\{关于示例对象2的百科内容简介\}

【问题1】：\{针对示例对象2提出的示例问题2\}

【标准答案】：\{示例问题2标准答案\}

【错误答案1】：\{示例问题2错误答案1\}

【错误答案2】：\{示例问题2错误答案2\}

【错误答案3】：\{示例问题2错误答案3\}

\vspace{1em}

对于以下的对象和参考文档，使用同样的格式生成问题、答案。

【对象】：\textcolor{orange}{\{对象：百科词条对象\}}

【参考文档】：\textcolor{orange}{\{文档：百科简介\}}

\vspace{1em}
\end{tcolorbox}
\caption {Prompt used to generate questions.}
\label{fig:generation prompt}
\end{figure*}
\end{CJK*}

\begin{figure*}
\centering
\begin{tcolorbox}[title=Question generation, width=\textwidth]
I will provide you with an object and its related reference description. Please generate up to \{Question number: 3\} factual questions about the object. Each question should have a unique and accurate answer, avoiding vague or contentious answers, subjective judgments, and time-sensitive. The answer should be directly found in the reference description. The question should be clearly expressed, with unambiguous noun references, and should not rely on the reference description for understanding. For each question, provide one standard answer and three misleading wrong answers.

Here are two examples:

\vspace{1em}

[Object]: \{Example Object 1\}

[Reference Description]: \{Brief introduction to Example Object 1\}

[Question 1]: \{Example question 1 related to Example Object 1\}

[Standard Answer]: \{Standard answer to Example question 1\}

[Wrong Answer 1]: \{Wrong answer 1 to Example question 1\}

[Wrong Answer 2]: \{Wrong answer 2 to Example question 1\}

[Wrong Answer 3]: \{Wrong answer 3 to Example question 1\}

\vspace{1em}

[Object]: \{Example Object 2\}

[Reference Description]: \{Brief introduction to Example Object 2\}

[Question 1]: \{Example question 2 related to Example Object 2\}

[Standard Answer]: \{Standard answer to Example question 2\}

[Wrong Answer 1]: \{Wrong answer 1 to Example question 2\}

[Wrong Answer 2]: \{Wrong answer 2 to Example question 2\}

[Wrong Answer 3]: \{Wrong answer 3 to Example question 2\}

\vspace{1em}

For the following object and reference description, generate questions and answers in the same format. 

[Object]: \textcolor{orange}{\{Object: Encyclopedia Entry Object\}}

[Reference Description]: \textcolor{orange}{\{Description: Encyclopedia Description\}}

\vspace{1em}
\end{tcolorbox}
\caption {Prompt used to generate questions (English translation).}
\label{fig:generation prompt english}
\end{figure*}

\begin{CJK*}{UTF8}{gbsn}
\begin{figure*}[ht]
\centering
\begin{tcolorbox}[title=Question filtering, width=\textwidth]
\textbf{User:}你是一个评估专家，下面需要你对一个问题的质量进行判断。

我会给你一个事实性知识问答问题, 你需要从以下几个方面分析这个问题，最终回答问题是【优质】还是【非优质】。

如果这个问题内存在代词指代不清，或无法明确理解问题含义，请回复【非优质】。

如果问题的答案不唯一，请回复【非优质】。

如果问题是时效性问题，且没有给出具体的背景时间点，请回复【非优质】。

如果问题没有以上情况，请回复【优质】。

请一步步思考，并在最后给出你的判断：【优质】或【非优质】。注意将你的最终判断写在中括号【】中！

\vspace{1em}

\textbf{Assistant:}明白了，我会按照你的要求和规则进行判断。

\vspace{1em}

\textbf{User:}问题是：

\textcolor{red}{\{待评价问题\}}

请给出你的判断：

\vspace{1em}
\end{tcolorbox}
\caption {Prompt used to filter out low-quality questions.}
\label{fig:filter prompt}
\end{figure*}
\end{CJK*}

\begin{figure*}[ht]
\centering
\begin{tcolorbox}[title=Question filtering, width=\textwidth]
\textbf{User: }You are an evaluation expert, and you need to assess the quality of a question.

I will provide you with a factual knowledge question, and you need to analyze the question from the following aspects to determine whether the question is of [High Quality] or [Low Quality].

If the question contains unclear pronoun references or cannot be clearly understood, please respond with [Low Quality].

If the answer to the question is not unique, please respond with [Low Quality].

If the question is time-sensitive and does not provide a specific time limitation, please respond with [Low Quality].

If none of the above situations apply, please respond with [High Quality].

Please think through the question step by step and give your final judgment as [High Quality] or [Low Quality]. Be sure to put your final judgment in square brackets []!

\vspace{1em}

\textbf{Assistant: }Understood. I will follow your requirements and rules for evaluation.

\vspace{1em}

\textbf{User: }The question is:

\textcolor{red}{\{Question to be evaluated\}}

Please provide your judgment:

\vspace{1em}
\end{tcolorbox}
\caption {Prompt used to filter out low-quality questions (English translation).}
\label{fig:filter prompt english}
\end{figure*}

\begin{CJK*}{UTF8}{gbsn}
\begin{figure*}[ht]
\centering
\begin{tcolorbox}[title=Answer evaluation, width=\textwidth]
给定一个问题以及对应的参考答案，根据参考答案和你掌握的知识，对候选答案是否回答正确进行评价。请注意，问题可能不具有唯一答案，此时只要候选答案言之成理即可。如果候选答案符合参考答案或言之成理，请回答【正确】；如果候选答案与参考答案矛盾或没有回答问题，请回答【错误】，并给出你的分析过程。下面是五个例子：

\vspace{1em}

【问题】：百川智能创始人王小川在什么时间与茹立云联合创立了该公司？

【参考答案】：百川智能创始人王小川于2023年4月10日与茹立云联合创立了该公司。

【候选答案】：王小川与茹立云于2023年4月共同创立了百川智能公司。

【评价】：根据参考答案，百川智能于2023年4月10日创立，候选答案认为是2023年4月创立，符合参考答案。【正确】

\vspace{1em}

【问题】：《采桑子·清明后三日作》是哪位诗人创作的？

【参考答案】：《采桑子·清明后三日作》是诗人龙榆生创作的。

【候选答案】：《采桑子·清明后三日作》是清代词人蒋春霖创作的一首词。

【评价】：根据参考答案，《采桑子·清明后三日作》是由诗人龙榆生创作，候选答案认为是蒋春霖创作，与参考答案矛盾。【错误】

\vspace{1em}

【问题】：李白的代表作有哪些？

【参考答案】：李白的代表作有《望庐山瀑布》《行路难》《蜀道难》《将进酒》《早发白帝城》《黄鹤楼送孟浩然之广陵》等。

【候选答案】：李白的代表作有《将进酒》《静夜思》《庐山谣》《早发白帝城》《赠汪伦》《望庐山瀑布》《行路难》《夜泊牛渚怀古》《登金陵凤凰台》《送友人》等。

【评价】：李白有许多代表作，答案不唯一，候选答案中的诗的确均为李白所写，言之成理。【正确】

\vspace{1em}

【问题】：哈蒂·温斯顿的主要作品有哪些？

【参考答案】：哈蒂·温斯顿的主要作品有《灵书妙探 第一季》。

【候选答案】：哈蒂·温斯顿（Hedy Lamarr）的主要作品有《Ecstasy》（1933年）， 《Algiers》（1938年）， 《Samson and Delilah》（1949年）等。

【评价】：哈蒂·温斯顿有许多作品，答案不唯一，但候选答案中的作品不是哈蒂·温斯顿的作品。【错误】

\vspace{1em}

【问题】：吴之番在哪次战斗中牺牲的？

【参考答案】：吴之番在清顺治二年八月二十六日的战斗中牺牲，这是嘉定三屠的一部分。

【候选答案】：对不起，我找不到关于“吴之番”的相关牺牲信息。这可能是因为您提供的信息有误或者该人物并不存在。

【评价】：根据参考答案，吴之番在顺治二年八月二十六日的战斗中牺牲，候选答案没有回答问题。【错误】

\vspace{1em}

下面是你需要评价的内容，请使用同样的格式给出评价。

【问题】：\textcolor{green}{\{问题\}}

【参考答案】：\textcolor{green}{\{参考答案\}}

【候选答案】：\textcolor{green}{\{候选答案\}}

【评价】：
\end{tcolorbox}
\caption {Prompt used to evaluate candidate answers to questions.}
\label{fig:eval prompt}
\end{figure*}
\end{CJK*}

\begin{figure*}[ht]
\centering
\small
\begin{tcolorbox}[title=Answer evaluation, width=\textwidth]
Given a question and its corresponding standard answer, evaluate whether the candidate answer correctly addresses the question based on the standard answer and your knowledge. Please note that the question may not have only one unique answer; in such cases, as long as the candidate answer is reasonable, it is acceptable. If the candidate answer aligns with the reference answer or is reasonable, please respond with [Correct]; if the candidate answer contradicts the reference answer or does not answer the question, please respond with [Incorrect], and provide your analysis. Here are five examples:

\vspace{1em}

[Question]: When did Wang Xiaochuan, the founder of Baichuan Inc., co-found the company with Ru Liyun?

[Standard Answer]: Wang Xiaochuan co-founded Baichuan Inc. with Ru Liyun on April 10, 2023.

[Candidate Answer]: Wang Xiaochuan and Ru Liyun co-founded Baichuan Inc. in April 2023.

[Evaluation]: According to the standard answer, Baichuan Inc. was founded on April 10, 2023. The candidate answer states it was founded in April 2023, which aligns with the reference answer. [Correct]

\vspace{1em}

[Question]: Which poet created "Cai Sang Zi · Qing Ming Hou San Ri Zuo"?

[Standard Answer]: "Cai Sang Zi · Qing Ming Hou San Ri Zuo" was created by the poet Long Yusheng.

[Candidate Answer]: "Cai Sang Zi · Qing Ming Hou San Ri Zuo" was created by the Qing Dynasty poet Jiang Chunlin.

[Evaluation]: According to the reference answer, "Cai Sang Zi · Qing Ming Hou San Ri Zuo" was created by Long Yusheng, while the candidate answer claims it was created by Jiang Chunlin, which contradicts the reference answer. [Incorrect]

\vspace{1em}

[Question]: What are the representative works of Li Bai?

[Standard Answer]: Li Bai's representative works include "Wang Lu Shan Pu Bu", "Xing Lu Nan", "Shu Dao Nan", "Qiang Jin Jiu", "Zao Fa Bai Di Cheng", and "Huang He Lou Song Meng Hao Ran Zhi Guang Ling", etc.

[Candidate Answer]: Li Bai's representative works include "Qiang Jin Jiu", "Jing Ye Si", "Lu Shan Yao", "Zao Fa Bai Di Cheng", "Zeng Wang Lun", "Wang Lu Shan Pu Bu", "Xing Lu Nan", "Ye Bo Niu Zhu Huai Gu", "Deng Jin Ling Feng Huang Tai", and "Song You Ren", etc.

[Evaluation]: Li Bai has many representative works, and the answer is not unique. The poems listed in the candidate answer are indeed all written by Li Bai, which is reasonable. [Correct]

\vspace{1em}

[Question]: What are the main works of Hattie Winston?

[Standard Answer]: Hattie Winston's main work is "Castle" (Season one).

[Candidate Answer]: Hedy Lamarr's main works include "Ecstasy" (1933), "Algiers" (1938), and "Samson and Delilah" (1949), etc.

[Evaluation]: Hattie Winston has many works, and the answer is not unique. However, the works listed in the candidate answer are not by Hattie Winston. [Incorrect]

\vspace{1em}

[Question]: In which battle did Wu Zhifan sacrifice?

[Standard Answer]: Wu Zhifan was sacrificed in the battle on August 26, the second year of the Shunzhi reign, which was part of the Jiadin Santu.

[Candidate Answer]: Sorry, I cannot find any information related to Wu Zhifan's sacrifice. This may be due to incorrect information you provided or because this person does not exist.

[Evaluation]: According to the standard answer, Wu Zhifan was sacrificed in the battle on August 26,  the second year of the Shunzhi reign, but the candidate answer did not answer the question. [Incorrect]

\vspace{1em}

Here is the content you need to evaluate, and please use the same format to provide your evaluation.

[Question]: \textcolor{green}{\{Question\}}

[Standard Answer]: \textcolor{green}{\{Standard Answer\}}

[Candidate Answer]: \textcolor{green}{\{Candidate Answer\}}

[Evaluation]: 

\end{tcolorbox}
\caption {Prompt used to evaluate candidate answers to questions (English translation).}
\label{fig:eval prompt english}
\end{figure*}

\begin{CJK*}{UTF8}{gbsn}
\begin{table*}[ht]
  \centering
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{c|p{10cm}|p{10cm}}
    \toprule[1.5pt]
    \rowcolor{blue!10} Question & 韩国电影《人狼》是由哪位导演执导的？ & 河北师范大学最早起源于哪两所学校？ \\
    \rowcolor{blue!10} & Who directed the Korean movie 'Inrang'? & Which two schools did Hebei Normal University first originate from? \\ 
    \midrule
    Standard Answer & 电影《人狼》是由金知云执导的。 & 河北师范大学最早起源于顺天府学堂和北洋女师范学堂。 \\
    & The movie 'Inrang' is directed by Kim Jee-woon. & Hebei Normal University originated from Shuntianfu Official School and Beiyang Women's Normal School.  \\
    \midrule
    Wrong Answer1 & 电影《人狼》是由姜栋元执导的。 & 河北师范大学最早起源于河北师范学院和河北教育学院。\\
    & The movie 'Inrang' is directed by Kang Dong Won. & Hebei Normal University originated from Hebei Normal Institute and Hebei Institute of Education. \\
    \midrule
    Wrong Answer2 & 电影《人狼》是由韩孝周执导的。& 河北师范大学最早起源于河北职业技术师范学院和汇华学院。 \\
    & The movie 'Inrang' is directed by Han Hyo Joo. & Hebei Normal University originated from Hebei Vocational and Technical Normal College and Huihua College. \\
    \midrule
    Wrong Answer3 & 电影《人狼》是由郑雨盛执导的。 & 河北师范大学最早起源于北京大学和清华大学。\\
    & The movie 'Inrang' is directed by Jung Woo Sung. & Hebei Normal University originated from Peking University and Tsinghua University. \\ 
    \midrule
    Domain & 影视娱乐 & 教育培养 \\
    & film\&entertainment & education\&training \\
    \midrule[1.5pt]
    \rowcolor{blue!10} Question & 苯丙氨酸的化学式是什么？ & 谥号是在什么时期开始的？ \\
    \rowcolor{blue!10} & What is the chemical formula for phenylalanine? & When did posthumous titles begin? \\ 
    \midrule
    Standard Answer & 苯丙氨酸的化学式是C9H11NO2。 & 谥号始于西周。 \\
    & The chemical formula for phenylalanine is C9H11NO2. & The posthumous title began in the Western Zhou Dynasty.  \\
    \midrule
    Wrong Answer1 & 苯丙氨酸的化学式是C8H11NO2。 & 谥号始于东周。\\
    & The chemical formula for phenylalanine is C8H11NO2. & The posthumous title began in the Eastern Zhou Dynasty. \\
    \midrule
    Wrong Answer2 & 苯丙氨酸的化学式是C9H10NO2。& 谥号始于秦朝。 \\
    & The chemical formula for phenylalanine is C9H10NO2. & The posthumous title began in the Qin Dynasty. \\
    \midrule
    Wrong Answer3 & 苯丙氨酸的化学式是C9H11NO3。 & 谥号始于汉朝。\\
    & The chemical formula for phenylalanine is C9H11NO3. & The posthumous title began in the Han Dynasty. \\ 
    \midrule
    Domain & 数理化生 & 历史国学 \\
    &physics, chemistry, mathematics\&biology & history\&traditional culture \\
    \midrule[1.5pt]
    \rowcolor{blue!10} Question & 中国电影“第六代导演”之一王小帅的电影处女作是什么？ & 法律关系的构成要素有哪些？ \\
    \rowcolor{blue!10} & What is the debut film of Wang Xiaoshuai, one of the "sixth generation directors" of Chinese cinema? & What are the constituent elements of legal relationships?  \\ 
    \midrule
    Standard Answer & 王小帅的电影处女作是《冬春的日子》。 & 法律关系的构成要素有三项：法律关系主体，法律关系内容，法律关系客体。 \\
    & Wang Xiaoshuai's debut film is 'THE DAYS'. & There are three elements that make up a legal relationship: the subject of the legal relationship, the content of the legal relationship, and the object of the legal relationship.  \\
    \midrule
    Wrong Answer1 & 王小帅的电影处女作是《扁担姑娘》。 & 法律关系的构成要素有三项：法律关系主体，法律关系形式，法律关系客体。\\
    & Wang Xiaoshuai's debut film is 'So Close to Paradise'. & There are three elements that make up a legal relationship: the subject of the legal relationship, the form of the legal relationship, and the object of the legal relationship. \\
    \midrule
    Wrong Answer2 & 王小帅的电影处女作是《十七岁的单车》。& 法律关系的构成要素有三项：法律关系主体，法律关系内容，法律关系方式。 \\
    & Wang Xiaoshuai's debut film is 'Beijing Bicycle'. & There are three elements that make up a legal relationship: the subject of the legal relationship, the content of the legal relationship, and the method of the legal relationship. \\
    \midrule
    Wrong Answer3 & 王小帅的电影处女作是《青红》。 & 法律关系的构成要素有三项：法律关系主体，法律关系内容，法律关系目标。\\
    & Wang Xiaoshuai's debut film is 'Shanghai Dreams'. &  There are three elements that make up a legal relationship: the subject of the legal relationship, the content of the legal relationship, and the objective of the legal relationship. \\ 
    \midrule
    Domain & 人物百科 & 政治法律 \\
    & biography & politics\&law \\
    \bottomrule[1.5pt]
    \end{tabular}%
    }
  \caption{More examples in FactualBench (part 1).}
  \label{tab:more example1}
\end{table*}
\end{CJK*}

\begin{CJK*}{UTF8}{gbsn}
\begin{table*}[ht]
  \centering
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{c|p{10cm}|p{10cm}}
    \toprule[1.5pt]
    \rowcolor{blue!10} Question & 国家金融监督管理总局是在哪一年揭牌的？ & MemCache是由谁开发的？ \\
    \rowcolor{blue!10} & In which year was the Chinese National Financial Supervisory Administration unveiled? & Who developed MemCache?  \\ 
    \midrule
    Standard Answer & 国家金融监督管理总局是在2023年揭牌的。 &  MemCache是由LiveJournal的Brad Fitzpatrick开发的。 \\
    & The Chinese National Financial Supervisory Administration was unveiled in 2023.& MemCache was developed by Brad Fitzpatrick from LiveJournal.  \\
    \midrule
    Wrong Answer1 & 国家金融监督管理总局是在2022年揭牌的。 & MemCache是由Facebook的Mark Zuckerberg开发的。\\
    & The Chinese National Financial Supervisory Administration was unveiled in 2022. & MemCache was developed by Mark Zuckerberg from Facebook. \\
    \midrule
    Wrong Answer2 & 国家金融监督管理总局是在2021年揭牌的。& MemCache是由Google的Larry Page开发的。 \\
    & The Chinese National Financial Supervisory Administration was unveiled in 2021. & MemCache was developed by Larry Page from Google. \\
    \midrule
    Wrong Answer3 & 国家金融监督管理总局是在2020年揭牌的。 & MemCache是由Microsoft的Bill Gates开发的。\\
    & The Chinese National Financial Supervisory Administration was unveiled in 2020. &  MemCache was developed by Bill Gates from Microsoft. \\ 
    \midrule
    Domain & 经济管理 & 计算机科学 \\
    & economics\&management & computer science \\
    \midrule[1.5pt]
    \rowcolor{blue!10} Question & 瑞舒伐他汀的主要作用部位是哪里？ & “枫丹白露”这个名字的原义是什么？ \\
    \rowcolor{blue!10} & What is the main site of action of rosuvastatin? & What is the original meaning of 'Fontainebleau'?  \\ 
    \midrule
    Standard Answer & 瑞舒伐他汀的主要作用部位是肝。 &  “枫丹白露”的法文原义为“美丽的泉水”。 \\
    & The main site of action of rosuvastatin is the liver. & The original French meaning of "Fontainebleau" is "beautiful spring water".  \\
    \midrule
    Wrong Answer1 & 瑞舒伐他汀的主要作用部位是心脏。 &“枫丹白露”的法文原义为“宏伟的宫殿”。\\
    & The main site of action of rosuvastatin is the heart. & The original French meaning of "Fontainebleau" is "magnificent palace". \\
    \midrule
    Wrong Answer2 & 瑞舒伐他汀的主要作用部位是肾脏。 & “枫丹白露”的法文原义为“狩猎的行宫”。 \\
    & The main site of action of rosuvastatin is the kidney. & The original French meaning of "Fontainebleau" is "hunting palace".  \\
    \midrule
    Wrong Answer3 & 瑞舒伐他汀的主要作用部位是胃。 & “枫丹白露”的法文原义为“古老的城堡”。\\
    & The main site of action of rosuvastatin is the stomache. &  The original French meaning of "Fontainebleau" is "ancient castle". \\ 
    \midrule
    Domain & 医学 & 社会人文 \\
    & medical & sociology\&humanity \\
    \midrule[1.5pt]
    \rowcolor{blue!10} Question & 竹笋原产于哪里？ & 更新世是由哪位地质学家创用的？ \\
    \rowcolor{blue!10} & Where do bamboo shoots originate from? & Which geologist named the Pleistocene epoch?  \\ 
    \midrule
    Standard Answer & 竹笋原产于中国。 &  更新世是由英国地质学家莱伊尔创用的。 \\
    & Bamboo shoots originate from China.  & The Pleistocene was named by British geologist Lyell.   \\
    \midrule
    Wrong Answer1 & 竹笋原产于日本。 &更新世是由英国地质学家福布斯创用的。\\
    & Bamboo shoots originate from Japan. & The Pleistocene was named by British geologist Forbes.  \\
    \midrule
    Wrong Answer2 & 竹笋原产于印度。 & 更新世是由美国地质学家莱伊尔创用的。 \\
    & Bamboo shoots originate from India. & The Pleistocene was named by American geologist Lyell. \\
    \midrule
    Wrong Answer3 & 竹笋原产于泰国。 & 更新世是由中国地质学家莱伊尔创用的。\\
    & Bamboo shoots originate from Thailand. & The Pleistocene was named by Chinese geologist Lyell. \\ 
    \midrule
    Domain & 农林牧渔 & 天文地理  \\
    & agriculture, forestry, fisheries\&allied industries & astronomy\&geography \\
    \bottomrule[1.5pt]
    \end{tabular}%
    }
  \caption{More examples in FactualBench (part 2).}
  \label{tab:more example2}
\end{table*}
\end{CJK*}

\begin{CJK*}{UTF8}{gbsn}
\begin{table*}[ht]
  \centering
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{c|p{10cm}|p{10cm}}
    \toprule[1.5pt]
    \rowcolor{blue!10} Question & 新奥尔良鹈鹕队在哪一年正式宣布球队改名为鹈鹕队？ & 宾利汽车公司是在哪一年创办的？ \\
    \rowcolor{blue!10} & In which year did the New Orleans Pelicans officially announce their name change to the Pelicans? & In which year was BentleyMotors Limited founded?  \\ 
    \midrule
    Standard Answer & 新奥尔良鹈鹕队在2013年正式宣布球队改名为鹈鹕队。 &  宾利汽车公司是在1919年创办的。 \\
    & The New Orleans Pelicans officially announced their name change to the Pelicans in 2013.& BentleyMotors Limited was founded in 1919.  \\
    \midrule
    Wrong Answer1 & 新奥尔良鹈鹕队在2012年正式宣布球队改名为鹈鹕队。 & 宾利汽车公司是在1920年创办的。\\
    & The New Orleans Pelicans officially announced their name change to the Pelicans in 2012. & BentleyMotors Limited was founded in 1920. \\
    \midrule
    Wrong Answer2 & 新奥尔良鹈鹕队在2014年正式宣布球队改名为鹈鹕队。&宾利汽车公司是在1918年创办的。 \\
    & The New Orleans Pelicans officially announced their name change to the Pelicans in 2014. & BentleyMotors Limited was founded in 1918. \\
    \midrule
    Wrong Answer3 & 新奥尔良鹈鹕队在2015年正式宣布球队改名为鹈鹕队。 & 宾利汽车公司是在1921年创办的。\\
    & The New Orleans Pelicans officially announced their name change to the Pelicans in 2015. & BentleyMotors Limited was founded in 1921. \\ 
    \midrule
    Domain & 运动旅游 & 数码汽车 \\
    & sports\&tourism  & digital\&automotive \\
    \midrule[1.5pt]
    \rowcolor{blue!10} Question & 隔离开关主要用于什么？ & 鸦片战争是在哪一年开始的？ \\
    \rowcolor{blue!10} & What is the main use of disconnectors? & In which year did the Opium War begin?  \\ 
    \midrule
    Standard Answer & 隔离开关主要用于隔离电源、倒闸操作、用以连通和切断小电流电路。 &  鸦片战争是在1840年开始的。 \\
    & Disconnectors are mainly used for isolating power sources, switching operations, and connecting and disconnecting small current circuits. & The Opium War begin in 1840.  \\
    \midrule
    Wrong Answer1 & 隔离开关主要用于调节电压。 &鸦片战争是在1842年开始的。\\
    & Disconnectors are mainly used to regulate voltage. & The Opium War begin in 1842. \\
    \midrule
    Wrong Answer2 & 隔离开关主要用于转换电流。 & 鸦片战争是在1839年开始的。 \\
    & Disconnectors are mainly used to convert current. & The Opium War begin in 1839.  \\
    \midrule
    Wrong Answer3 & 隔离开关主要用于存储电能。 & 鸦片战争是在1841年开始的。\\
    & Disconnectors are mainly used for storing electrical energy. &  The Opium War begin in 1841. \\ 
    \midrule
    Domain & 工业工程  & 军武战争 \\
    & industrial engineering & military\&war \\
    \midrule[1.5pt]
    \rowcolor{blue!10} Question & 买了佛冷这个词是来源于哪首歌曲？ & 苏荷酒吧是在哪一年诞生的？ \\
    \rowcolor{blue!10} & What song does the meme 'Mai Le Fo Leng' come from? & In which year was Soho Bar founded?  \\ 
    \midrule
    Standard Answer & 买了佛冷这个词是来源于歌曲《I Love Poland》。 & 苏荷酒吧是在2003年诞生的。 \\
    & The meme 'Mai Le Fo Leng' comes from "I love Poland"  & Soho Bar was founded in 2003. \\
    \midrule
    Wrong Answer1 & 买了佛冷这个词是来源于歌曲《I Love China》。 &苏荷酒吧是在2000年诞生的。\\
    & The meme 'Mai Le Fo Leng' comes from "I love China" & Soho Bar was founded in 2000. \\
    \midrule
    Wrong Answer2 & 买了佛冷这个词是来源于歌曲《I Love America》。 & 苏荷酒吧是在2005年诞生的。 \\
    & The meme 'Mai Le Fo Leng' comes from "I love America" &Soho Bar was founded in 2005. \\
    \midrule
    Wrong Answer3 & 买了佛冷这个词是来源于歌曲《I Love England》。 &  苏荷酒吧是在2010年诞生的。\\
    & The meme 'Mai Le Fo Leng' comes from "I love England" &  Soho Bar was founded in 2010. \\ 
    \midrule
    Domain & 网词网梗 & 工作生活  \\
    & slang\&memes &  work\&life \\
    \midrule[1.5pt]
    \rowcolor{blue!10} Question & 视觉识别系统VI是什么的缩写？ & 风水业内公认的"龙脉之源"是哪里？ \\
    \rowcolor{blue!10} & What words is VI (a Vision System) abbreviation for? & Where is the recognized "source of dragon veins" in chinese feng shui?  \\ 
    \midrule
    Standard Answer & 视觉识别系统是Visual Identity的缩写。 &  风水业内公认的"龙脉之源"是昆仑山。 \\
    & VI abbreviation for Visual Identity. & The "source of dragon veins" in chinese feng shui is Kunlun Mountain.  \\
    \midrule
    Wrong Answer1 & 视觉识别系统是Visual Information的缩写。 & 风水业内公认的"龙脉之源"是长江。\\
    & VI abbreviation for Visual Information. & The "source of dragon veins" in chinese feng shui is Yangtze River. \\
    \midrule
    Wrong Answer2 & 视觉识别系统是Visual Interface的缩写。&风水业内公认的"龙脉之源"是黄河。 \\
    & VI abbreviation for Visual Interface. & The "source of dragon veins" in chinese feng shui is the Yellow River. \\
    \midrule
    Wrong Answer3 & 视觉识别系统是Visual Interaction的缩写。 & 风水业内公认的"龙脉之源"是太湖。\\
    & VI abbreviation for Visual Interface. &  The "source of dragon veins" in chinese feng shui is the Taihu Lake. \\ 
    \midrule
    Domain & 高新科技 & 信仰文化 \\
    & high technology  & religion\&culture \\
    \bottomrule[1.5pt]
    \end{tabular}%
    }
  \caption{More examples in FactualBench (part 3).}
  \label{tab:more example3}
\end{table*}
\end{CJK*}

\begin{figure*}[ht]
  \includegraphics[width=\textwidth]{latex/img/heatmap_benchmark.pdf} 
  \caption {Performance on FactualBench at domain level. We prioritize the chat/instruct version of these models.}
  \label{fig:heatmap benchmark}
\end{figure*}

\clearpage

\begin{CJK*}{UTF8}{gbsn}
\begin{table*}[ht]
  \centering
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{c|p{20cm}|c}
    \toprule[1.5pt]
    \multicolumn{3}{c}{\sc Baichuan1-Chat} \\
    \midrule
    \rowcolor{blue!10} \multicolumn{3}{c}{Test split: 黄眉大王在《西游记》中最后是被谁降伏的？[标准答案：弥勒佛]} \\
    \rowcolor{blue!10} \multicolumn{3}{c}{Who ultimately subdued King Huangmei in \textit{Journey to the West?} [Standard Answer: \textbf{Maitreya Buddha}]} \\
    \midrule
    \small low temp. & 孙悟空 \textcolor{red}{[Sun WuKong]}。 & \ding{55} \\
    \midrule
    \small \multirow{3}{*}{high temp.} & 哪吒 \textcolor{red}{[Ne Zha]}$\backslash$n黄眉大王,第七十四回“长庚传报魔头狠 小圣战败母夜叉”中,红孩儿的叔叔被孙悟空、沙僧和护法伽蓝保着唐僧战败 & \ding{55} \\
    \cmidrule{2-3}
     & 孙悟空 \textcolor{red}{[Sun WuKong]}。第十九回$\backslash$n云栈洞悟空收八戒$\backslash$n浮屠山玄奘受心经 & \ding{55} \\
     \cmidrule{2-3}
     & 弥勒佛祖 \textcolor{green}{[Maitreya Buddha]}。黄眉大王是头目级妖怪,手下也有不少妖将,他趁孙悟空不在的时候捉了唐僧(其实是假冒的),后来弥勒佛祖亲自来了之后黄眉大王现出了原形。& \ding{51} \\
    \bottomrule[1.5pt]
    \end{tabular}%
    }
  \caption{Baichuan1 responses to a test case under low temperature and high temperature.}
  \label{tab:bo1vsbo8 example bc}
\end{table*}
\end{CJK*}

\begin{CJK*}{UTF8}{gbsn}
\begin{table*}[ht]
  \centering
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{c|p{20cm}|c}
    \toprule[1.5pt]
    \multicolumn{3}{c}{\sc Qwen2-7B-Instruct} \\
    \midrule
    \rowcolor{blue!10} \multicolumn{3}{c}{Training split: 在《魔兽世界》中，牛头人在英语环境下被称为什么？[标准答案：Tauren]} \\
    \rowcolor{blue!10} \multicolumn{3}{c}{What is the shu'halo referred to as in English in \textit{World of Warcraft?} [Standard Answer: \textbf{Tauren}]} \\
    \midrule
    \small \multirow{3}{*}{high temp.} & 在《魔兽世界》这个虚构的系列游戏设定下，牛头人这一种族在其英语环境下被称为 \textcolor{green}{Tauren}。在该游戏背景故事中，牛头人们以他们的力量、荣耀概念的坚持和原生氏族形式的生活方式而著称，并被认为是艾泽拉斯这个主世界上的坚韧守护者之一。 & \ding{51} \\
    \cmidrule{2-3}
     & 在《魔兽世界》这个游戏中，牛头人种族在英语环境下被称为"\textcolor{red}{Ogres}"。但通常提到的牛头人应该指的是魔兽系列中的半神牛头人阵营，他们的正式名字叫作"High Hill Ogres"（山顶族）和"Grim Guor'gan Orges"（灰烬游侠），但也经常用"orcs"（食人魔）的统称来指代。这可能产生了一些混淆。正确而且具体的称呼应该是“Ogres”还是依据特定的情境下更加复杂的名称描述如 "Hill Gazelle" 或 "Mountain Goliaths" （具体根据《魔兽世界》的不同版本与时间而有所不同）。但在普通讨论或玩家交流中，“Ogres”是最常见的称呼方法。 & \ding{55} \\
     \cmidrule{2-3}
     & 在《魔兽世界》这个虚构的世界里，牛头人在这个英文环境下被称为\textcolor{red}{Trolls}。但在另一个文化背景中，特别是指真实生活中的非洲塞米诺尔人族裔时，他们被称为Touaregs或者Berbers，但这并不是《魔兽世界》中所使用的名称。在该游戏中，牛头人们属于暗夜 elves 的一种原住民，有自己的文化、语言和领袖，并在游戏的剧情中有很重要的地位。& \ding{55} \\
     \midrule
     \rowcolor{blue!10} \multicolumn{3}{c}{Training split: 哪个法甲球队在1992/93赛季获得了法甲球队历史上首个欧洲冠军联赛冠军？[标准答案：马赛]} \\
    \rowcolor{blue!10} \multicolumn{3}{c}{Which \textit{Ligue 1} football club won the first \textit{UEFA} Champions League championship} \\
     \rowcolor{blue!10} \multicolumn{3}{c}{in \textit{Ligue 1} history in the 1992/93 season? [Standard Answer: \textbf{Olympique de Marseille (OM)}]} \\
    \midrule
    \small \multirow{3}{*}{high temp.} & 在1992/93赛季获得法甲球队历史上首个欧洲冠军联赛（当时称为欧洲冠军杯）冠军的球队是马赛 \textcolor{green}{[OM]} 足球俱乐部。 & \ding{51} \\
    \cmidrule{2-3}
     & 在1992/93赛季，意大利的AC米兰队 \textcolor{red}{[A.C. Milan from Italy]} 在当年的欧洲冠军联赛中获得了历史性的首个欧洲冠军，而不是法甲球队。不过，有一支法甲球队在后来成功夺得了欧洲冠军联赛冠军，那便是法国球队马赛足球俱乐部，在1993/94赛季获得了其历史上首个也是至今唯一的欧洲冠军联赛冠军（以及后来所谓的"五冠王"）。 & \ding{55} \\
     \cmidrule{2-3}
     & 1992/93赛季获得欧洲冠军联赛（当时的赛事名称为欧洲冠军杯）冠军的是荷兰的阿贾克斯队 \textcolor{red}{[AFC Ajax from the Netherlands]} ，并非任何法甲球队。所以答案是：没有法甲球队在这个赛季获得过这个荣誉。& \ding{55} \\
    \bottomrule[1.5pt]
    \end{tabular}%
    }
  \caption{Qwen2-7B-Instruct responses to training cases under high temperature.}
  \label{tab:bo8 example qwen}
\end{table*}
\end{CJK*}

\FloatBarrier

\section{Training Details}
\label{sec:training details}
We complete all our training based on OpenRLHF \citep{hu2024openrlhf} framework, on 8 H800-80G NVIDIA GPUs, using AdamW optimizer \citep{loshchilov2017decoupled} and cosine scheduler. Learning rate is set to be $2e-6$ for SFT training, $1e-6$ for DPO training, and $1e-6$ DPO $+$ $1e-7$ SFT when fusing two loss functions together. Only $1$ epoch is trained on tuning set, the batch size is set $128$, the DPO $\beta$ is set $0.1$, the weight decay is set $1e-4$ in all conditions. We list sizes of all our tuning data in main experiments and ablation studies in Table \ref{tab:training data construction}. For SFT loss, a question is considered to be valid if the model correctly answers at least one time; While for DPO loss, a question is considered to be valid if it receives both correct and incorrect answers from the model. As for baselines, we reproduce their methods following settings in their papers.

\begin{table*}[ht]
  \centering
  \resizebox{0.8\textwidth}{!}{%
  \begin{tabular}{cccccc}
    \toprule[1.5pt]
    Loss & Split & Chosen & Rejected & \# Valid Questions & \# Labels/Pairs \\
    \midrule
    \multicolumn{6}{c}{\sc Qwen2-7B-Instruct} \\ 
    \midrule
    SFT & small & self & - & 16,845 & 16,845 \\
    SFT & small & Baichuan & - & 15,489 & 15,489 \\
    SFT & small & dataset & - & 24,000 & 24,000 \\
    DPO & small & self & self & 11,485 & 85,041 \\
    DPO\textsuperscript{1} & small & Baichuan & Baichuan & 12,949 & 96,737 \\
    DPO & small & dataset & dataset & 72,000 & 72,000 \\
    \midrule
    \multicolumn{6}{c}{\sc Baichuan1-Chat} \\ 
    \midrule
    SFT (single label) & full & self & - & 115,798 & 115,798 \\
    SFT (all labels) & full & self & - & 115,798 & 489,357 \\
    SFT & full & w/ desc. & - & 177,714 & 177,714 \\
    SFT & full & dataset & - & 177,714 & 177,714 \\
    DPO (small)\textsuperscript{1} & small & self & self & 12,949 & 96,737 \\
    DPO (full)\textsuperscript{2} & full & self & self & 98,805 & 743,333 \\
    DPO & full & w/ desc. & self & 177,714 & 881,932 \\
    DPO & full & dataset & self & 177,714 & 881,932 \\
    DPO & full & dataset & dataset & 177,714 & 533,142 \\
    SFT then DPO\textsuperscript{2} & full & self & self & 98,805 & 743,333 \\
    SFT + DPO\textsuperscript{2}  & full & self & self & 98,805 & 743,333 \\ 
    \bottomrule[1.5pt]
  \end{tabular}
  }
  \caption{Sizes of all our tuning data. Data with the same superscript \textsuperscript{1,2} are exactly the same.}
  \label{tab:training data construction}
\end{table*}

\section{Evaluation Details}
\label{cha:benchmark detail}
We choose 6 other open-source benchmarks to evaluate model's enhancement comprehensively. Models are required to respond to the questions or instructions in zero-shot condition and under default generation configuration. Official metrics are reported for all, and for model-based evaluation processes, we all choose GPT4 as evaluator.

\textbf{TruthfulQA} \cite{lin2022truthfulqa} is an English benchmark to measure whether a language model is truthful in generating answers. It contains 817 questions covering 38 domains. The questions are designed to cause imitative falsehoods which are due to a false belief or misconception. We use the generative part of TruthfulQA and adopt GPT4 to evaluate the response correctness.

\textbf{HalluQA} \citep{cheng2023evaluating} is a benchmark to measure hallucination in Chinese LLM. It contains 450 meticulously designed adversarial questions covering various domains to test imitative falsehoods of the model and factual knowledge. Still, we use the generative part and its official prompt to evaluate the answer.

\textbf{CMMLU} \citep{li2023cmmlu} is a Chinese multiple-choice benchmark similar to MMLU \cite{MMLU}, comprising 67 topics with massive questions. We use the official script and code to evaluate the model's accuracy on the task.

\textbf{HaluEval} \citep{li2023halueval} is a large collection of generated and human-annotated English hallucinated samples to evaluate the performance of LLM on recognizing hallucinations. It is a discriminative task that requires the model to judge whether a response contains hallucination or not. We use the official prompt and only test on 10,000 samples from the QA part. The evaluation is based on string matching (e.g. "Yes" or "No") and if the model's judgment does not match any pattern, it will be considered as a wrong judgment.

\textbf{AlignBench} \citep{liu2023alignbench} is a Chinese benchmark for evaluating LLMs’ alignment skills. It contains 683 instructions on 8 different tasks, including professional knowledge, mathematics, fundamental language ability, logical reasoning, advanced Chinese understanding, writing ability, task-oriented role play, and open-ended question. We use its official prompt format to evaluate answers in a model-based way.

\textbf{AlpacaEval} \citep{alpaca_eval} is a benchmark based on the AlpacaFarm \citep{dubois2023alpacafarm} evaluation set, which tests the model's instruction following ability. It contains 805 samples on different instructions, and calculates the winning rate against a base model. It has been used to indicate model's helpfulness in previous work \citep{flame}. In our experiments, the model before training is selected as the base model.

\section{Detailed Experiment Results}
In this section, we will provide more detailed results of the main experiments and ablation studies. Domain-level accuracy on FactualBench is presented in heatmaps, and performance on other benchmarks and sub-tasks of AlignBench is listed in tables.

\subsection{Main Experiments}
\label{cha:detailed main experiment result}
We present the performance of Qwen2-7B-Instruct and Baichuan1-Chat after training through our method and the other three baselines on FactualBench at domain-level in Figure \ref{fig:heatmap qwen methods} and Figure \ref{fig:heatmap bc methods}, respectively. The first column presents the overall accuracy of the model and we arrange domains from left to right in the same order as Figure \ref{fig:heatmap benchmark}. Each domain is represented by its first 5 letters.

\begin{figure*}[ht]
  \includegraphics[width=\textwidth]{latex/img/heatmap_qwen_methods.pdf} 
  \caption {Qwen2-7B-Instruct performance on FactualBench after different training methods.}
  \label{fig:heatmap qwen methods}
\end{figure*}

\begin{figure*}[ht]
  \includegraphics[width=\textwidth]{latex/img/heatmap_bc_methods.pdf} 
  \caption {Baichuan1-Chat performance on FactualBench after different training methods.}
  \label{fig:heatmap bc methods}
\end{figure*}

\subsection{Ablation Studies}
\label{cha:detailed ablation experiment result}
For the ablation study on data sources, we present models performance on 7 benchmarks in Table \ref{tab:data source ablation result}, on 8 sub-tasks of AlignBench in Table \ref{tab:data source ablation result Alignbench}, and domain-level accuracy on FactualBench in Figure \ref{fig:heatmap qwen source}, Figure \ref{fig:heatmap bc source}. 

For the ablation study on loss functions, we present Baichuan performance on 7 benchmarks in Table \ref{tab:loss ablation result}, on 8 sub-tasks of AlignBench in Table \ref{tab:loss ablation result Alignbench}, and domain-level accuracy on FactualBench in Figure \ref{fig:heatmap bc loss}. 

\begin{table*}[ht]
  \centering
   \resizebox{\textwidth}{!}{%
    \begin{tabular}{c|cc|ccccc|c|c|c}
    \toprule[1.5pt]
     Loss & Chosen & Rejected & FactualBench & TruthfulQA & HalluQA & CMMLU & HaluEval & AlignBench & AlpacaEval & $\Delta$Avg.\\ 
     \midrule
     \multicolumn{11}{c}{\sc Qwen2-7B-Instruct} \\ 
    \midrule
     SFT & self & - & 55.43 & 50.31 & 45.56 & 80.22 & 53.70 & 6.63 & 44.22 & -0.66  \\ 
     SFT & Baichuan & - & 49.97 & 29.87 & 24.67 & 77.49 & 42.05 & 4.98 & 15.03 & -13.61 \\
     SFT & dataset & - & 50.38 & 19.58 & 21.11 & 79.85 & 9.69 & 3.56 & 7.20 & -23.22  \\
     \midrule
     DPO & self & self & \bf 58.81 & \bf 54.47 & \bf 49.78 & \bf 82.15 & \bf 54.00 & \bf 6.96 & \bf 58.26 & \bf +2.22 \\ 
     DPO & Baichuan & Baichuan & 58.17 & 53.86 & 46.67 & 80.14 & 52.26 & 6.71 & 39.19 & +0.45  \\ 
     DPO & dataset & dataset & 55.75 & 52.14 & 46.22 & 80.77 & 51.70 & 6.50 & 36.06 & -0.65 \\ 
     \midrule
    \multicolumn{11}{c}{\sc Baichuan1-Chat} \\ 
    \midrule
     SFT & self & - & 51.33 & 31.46 & 30.00 & 48.78 & \bf 55.73 & 5.04 & 37.58 & +1.29  \\ 
     SFT & w/ desc. & -  & 55.63 & \bf 36.60 & 27.11 & 51.39 & 10.40 & 4.47 & 36.96 & -5.69  \\
     SFT & dataset & -  & 55.86 & 21.30 & 22.44 & 49.58 & 12.40 & 3.73 & 26.65 & -10.18  \\
     \midrule
     DPO & self & self & \bf 58.29 & 35.86 & \bf 38.89 & \bf 50.92 & 52.05 & \bf 5.38 & \bf 63.99 & \bf +4.97 \\ 
     DPO & w/ desc. & self & 18.17 & 13.10 & 9.33 & 48.05 & 48.57 & 4.07 & 32.80 & -13.67  \\ 
     DPO & dataset & self & 5.40 & 3.92 & 1.56 & 46.85 & 40.10 & 3.28 & 19.07 & -21.56  \\ 
     DPO & dataset & dataset & 49.08 & 28.89 & 19.78 & 50.70 & 54.89 & 4.82 & 39.07 & -1.40 \\ 
     \bottomrule[1.5pt]
    \end{tabular}
    }
  \caption{\label{tab:data source ablation result}
    Performance on 7 benchmarks in data sources ablation study. We mark the best results in \textbf{bold}.
  }
\end{table*}

\begin{table*}[ht]
  \centering
   \resizebox{\textwidth}{!}{%
    \begin{tabular}{c|cc|cccccccc}
    \toprule[1.5pt]
     \multirow{2}{*}{Loss} & \multirow{2}{*}{Chosen} & \multirow{2}{*}{Rejected} & Professional & Mathe- & Fundamental & Logical & Advanced Chinese & Writing & Task-oriented & Open-ended \\ 
      & & & Knowledge & matics & Language Ability & Reasoning & Understanding & Ability & Role Play & Question \\
     \midrule
     \multicolumn{11}{c}{\sc Qwen2-7B-Instruct} \\ 
    \midrule
     SFT & self & - & \bf 6.74 & 6.40 & \bf 7.04 & 4.90 & 6.50 & 7.09 & 7.35 & 7.50  \\ 
     SFT & Baichuan & - & 5.26 & 3.72 & 5.88 & 3.41 & 5.31 & 5.60 & 5.59 & 6.42 \\
     SFT & dataset & - & 4.47 & 3.29 & 4.50 & 3.37 & 5.29 & 1.92 & 2.73 & 3.32 \\
     \midrule
     DPO & self & self & 6.63 & \bf 6.94 & 6.94 & \bf 5.56 & \bf 6.93 & \bf 7.43 & \bf 7.84 & \bf 7.92 \\ 
     DPO & Baichuan & Baichuan & 6.44 & 6.37 & 6.85 & 5.29 & 7.26 & 7.21 & 7.45 & 7.74 \\ 
     DPO & dataset & dataset & 6.10 & 6.36 & 6.76 & 4.70 & 6.59 & 7.23 & 7.64 & 7.07 \\ 
     \midrule
    \multicolumn{11}{c}{\sc Baichuan1-Chat} \\ 
    \midrule
     SFT & self & - & 5.78 & 2.59 & 5.47 & 3.30 & 5.66 & 6.11 & 6.25 & 6.58  \\ 
     SFT & w/ desc. & -  & 5.02 & 2.68 & 4.96 & 2.92 & 5.67 & 5.32 & 5.00 & 5.74  \\
     SFT & dataset & -  & 4.48 & 2.62 & 4.79 & 2.75 & 5.08 & 3.24 & 3.77 & 3.76 \\
     \midrule
     DPO & self & self & \bf 6.25 & \bf 3.03 & \bf 5.76 & \bf 3.55 & \bf 6.12 & \bf 6.52 & \bf 6.36 & \bf 6.79 \\ 
     DPO & w/ desc. & self & 3.62 & 1.93 & 4.88 & 2.63 & 4.47 & 5.81 & 5.53 & 5.34 \\ 
     DPO & dataset & self & 1.77 & 1.95 & 4.13 & 2.58 & 3.71 & 5.04 & 5.14 & 2.55  \\ 
     DPO & dataset & dataset & 4.67 & 2.60 & 5.53 & 3.30 & 5.50 & 6.40 & 6.17 & 6.00  \\ 
    \bottomrule[1.5pt]
    \end{tabular}
    }
  \caption{\label{tab:data source ablation result Alignbench}
    Performance on 8 sub-tasks of AlignBench in data sources ablation study. We mark the best results in \textbf{bold}.
  }
\end{table*}

\begin{figure*}[ht]
  \includegraphics[width=\textwidth]{latex/img/heatmap_qwen_source.pdf} 
  \caption {Qwen2-7B-Instruct performance on FactualBench after training on different data sources.}
  \label{fig:heatmap qwen source}
\end{figure*}

\begin{figure*}[ht]
  \includegraphics[width=\textwidth]{latex/img/heatmap_bc_source.pdf} 
  \caption {Baichuan1-Chat performance on FactualBench after training on different data sources.}
  \label{fig:heatmap bc source}
\end{figure*}

\begin{table*}[ht]
  \centering
   \resizebox{\textwidth}{!}{%
    \begin{tabular}{c|ccccc|c|c|c}
    \toprule[1.5pt]
     Loss & FactualBench & TruthfulQA & HalluQA & CMMLU & HaluEval & AlignBench & AlpacaEval & $\Delta$Avg.\\ 
     \midrule
    \multicolumn{9}{c}{\sc Baichuan1-Chat} \\ 
    \midrule
     SFT (single label)  & 51.33 & 31.46 & 30.00 & 48.78 & \bf 55.73 & 5.04 & 37.58 & +1.29  \\ 
     SFT (all labels)  & 52.37 & 28.76 & 26.44 & 50.15 & 53.90 & 5.03 & 31.06 & +0.32 \\ 
     \midrule
     DPO (small)  & 57.37 & 33.78 & 38.44 & 50.13 & 50.63 & 5.30 & 54.84 & +3.90 \\ 
     DPO (full)  & \bf 58.29 & 35.86 & \bf 38.89 & \bf 50.92 & 52.05 & \bf 5.38 & \bf 63.99 & \bf +4.97 \\ 
     \midrule
     SFT then DPO & 54.74 & \bf 37.33 & 36.67 & 50.72 & 54.02 & 5.07 & 54.53 & +4.03  \\ 
     SFT + DPO  & 57.16 & 34.76 & 38.22 & 50.78 & 52.31 & 5.13 & 63.91 & +4.09  \\ 
     \bottomrule[1.5pt]
    \end{tabular}
    }
  \caption{\label{tab:loss ablation result}
    Performance on 7 benchmarks in loss functions ablation study. We mark the best results in \textbf{bold}.
  }
\end{table*}

\begin{table*}[ht]
  \centering
   \resizebox{\textwidth}{!}{%
    \begin{tabular}{c|cccccccc}
    \toprule[1.5pt]
     \multirow{2}{*}{Loss} & Professional & Mathe- & Fundamental & Logical & Advanced Chinese & Writing & Task-oriented & Open-ended \\ 
      & Knowledge & matics & Language Ability & Reasoning & Understanding & Ability & Role Play & Question \\
    \midrule
    \multicolumn{9}{c}{\sc Baichuan1-Chat} \\ 
    \midrule
     SFT (single label)  & 5.78 & 2.59 & 5.47 & 3.30 & 5.66 & 6.11 & 6.25 & 6.58  \\ 
     SFT (all labels)  & 5.46 & 2.88 & 5.60 & 3.25 & 5.57 & 6.19 & 6.17 & 6.63  \\ 
     \midrule
     DPO (small)  & 5.92 & 3.02 & 5.66 & 3.37 & 5.97 & \bf 6.53 & \bf 6.55 & 6.79  \\ 
     DPO (full)  & \bf 6.25 & \bf 3.03 & \bf 5.76 & \bf 3.55 & \bf 6.12 & 6.52 & 6.36 & 6.79  \\ 
     \midrule
     SFT then DPO & 5.57 & 2.66 & 5.53 & 3.01 & 6.00 & 6.33 & 6.32 & 6.92  \\ 
     SFT + DPO  & 5.60 & 2.79 & 5.57 & 3.16 & 6.05 & 6.17 & 6.41 & \bf 7.16 \\ 
     \bottomrule[1.5pt]
    \end{tabular}
    }
  \caption{\label{tab:loss ablation result Alignbench}
    Performance on 8 sub-tasks of AlignBench in loss functions ablation study. We mark the best results in \textbf{bold}.
  }
\end{table*}

\begin{figure*}[ht]
  \includegraphics[width=\textwidth]{latex/img/heatmap_bc_loss.pdf} 
  \caption {Baichuan1-Chat performance on FactualBench after training using different loss functions.}
  \label{fig:heatmap bc loss}
\end{figure*}

\section{Mutual Nearest-Neighbor Metric}
\label{cha:metric}
For two models with representations $f$, $g$, the mutual $k$-nearest neighbor metric measures the average overlap of their respective nearest neighbor sets \citep{huh2024platonic}. According to the original definition, define $x_i \sim \mathcal{X}$ as a sample from the data distribution $\mathcal{X}$. $\{x_i\}_{i=1}^b$ is a mini-batch sampled from this data distribution. Two models $f$ and $g$ extract features $\phi_i = f(x_i)$ and $\psi_i = g(x_i)$. The collections of these features are denoted as $\Phi = \{\phi_1, \phi_2,...,\phi_b\}$ and $\Psi = \{\psi_1,\psi_2,...,\psi_b\}$. Then we compute the respective nearest neighbor sets $S(\phi_i)$ and $S(\psi_i)$ for each $x_i$ under the representations $f$ and $g$:
\begin{align}
    d_{knn}(\phi_i, \Phi \backslash \phi_i) = S(\phi_i); \\
    d_{knn}(\psi_i, \Psi \backslash \psi_i) = S(\psi_i),
\end{align}
where $d_{knn}$ returns the set of indices of its $k$-nearest neighbors. Then we measure its average intersection via 
\begin{equation}
    m_{\text{NN}}(\phi_i, \psi_i) = \frac{1}{k} \lvert S(\phi_i) \cap S(\psi_i) \rvert,
\end{equation}
where $\lvert \cdot \rvert$ denotes the size of the intersection. We use the hidden state of the last layer to represent the extracted feature of a prompt, and following the original paper \citep{huh2024platonic}, we set $k=10$ and $b=1,000$ (we take all data points if the total size of the data is less than $1,000$). We apply $l_2$ normalization to the features, then use the inner product kernel to measure the distance between two features. The alignment of two models is measured by $\frac{1}{b} \Sigma_{i=1}^b m_{\text{NN}}(\phi_i, \psi_i)$.
