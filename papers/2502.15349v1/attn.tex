\section{A Unified Attention Abstraction}
\label{sec:attn}
Attention mechanisms exhibit significant diversity at the implementation level. For example, standard attention utilizes matrix multiplication to compute attention scores between $Q$ and $K$, followed by a weighted aggregation of $V$ to produce the output representation. In contrast, linear attention compresses $K$ and $V$ using a recurrent loop before applying $Q$ to compute the output. Despite these implementation differences, these variants adhere to the same underlying principles of attention semantics.

By examining the native implementation of attention as a loop-based operation, we identify two fundamental components common to all attention mechanisms:

\begin{itemize}[noitemsep,topsep=0pt, left=0pt]
    \item \textit{Relevance Scoring:} This operation forms the core of attention mechanisms, capturing pairwise similarities or interactions between input tokens. It is typically realized through inner products or other similarity measures to determine token relationships.
    \item \textit{Aggregation:} Using the relevance scores, this operation consolidates contextual information into a representation for each token. 
\end{itemize}

Building on these two fundamental operations, we propose a unified template that encapsulates the diverse spectrum of attention variants. This template abstracts the core semantics of relevance scoring and aggregation while offering customizable components, striking a balance between broad applicability and development flexibility. By providing a consistent framework, this approach streamlines the design and implementation of new attention mechanisms while enabling efficient adaptation to evolving computational demands. The next section introduces \oursys{}, a unified framework that brings this abstraction to life, facilitating efficient and scalable attention mechanism design across diverse hardware platforms.


