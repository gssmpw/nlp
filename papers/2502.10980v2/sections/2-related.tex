\begin{figure*}[!t]
    \centering
    % \vspace{10pt}
    \includegraphics[width=\linewidth]{figures/fig2.pdf}
    \caption{The expressive dance motion learning system is composed of four key components: motion design, motion representation, motion learning, and hardware inference. In the motion design phase, artists create motion references using specialized design software. The representation of these diverse motions is then learned using a \ac{pae}. Reinforcement learning (\ac{rl}) is employed to enable the robot to perform auxiliary tasks, such as walking and head orientation control, while accurately tracking the designed dance references. During inference, the learned policy is deployed on the actual hardware, allowing for real-time execution of dance motions and dynamic and interactive motions by tracking the auxiliary task commands.}
    \label{fig:system_overview}
    \vspace{-2ex}
\end{figure*}

\section{RELATED WORK}
\subsection{Robotic Dance}
The development of dancing for entertainment robots has seen significant progress~\cite{dance_robot_god}.
Nakaoka et al. employed a motion capture system to teach the HRP-2~\cite{HRP2} a traditional Japanese folk dance~\cite{dancing_humanoid}.
While this approach showcased impressive dancing capabilities, the sequences and timings of all movements were meticulously pre-programmed to align with a specific music.
For quadruped robots, a notable example is a dancing robot capable of detecting tempo and adjusting its motions in real-time~\cite{anymal_dance}.
Similarly, certain entertainment robots, such as Sony's aibo, incorporate the ability to adjust their dancing tempo~\cite{aibo_dance}.
However, these systems rely mostly on replaying predefined motion sequences and lack the capability to perform additional task operations during motion execution, which is a key focus of this paper.

\subsection{Learning from Demonstrations}
Reinforcement learning (\ac{rl}) has been extensively utilized to generate robust locomotion policies for quadrupedal robots~\cite{anymal_terrain, anymal_perceptive, Choi2023-cf}.
Despite these advances, achieving stylized motions that appear natural to human observers remains challenging.
To address the need for natural motion learning, Peng et al.\cite{deepmimic} proposed a method that enhances \ac{rl} by incorporating rewards to imitate reference trajectories within a physics-based simulator.
Recently, Ruben et al.\cite{disney_learning} applied this approach to real robots.
However, these methods are constrained by their reliance on a single trajectory, making it difficult to transition between reference motions without intricate motion design.

To handle transitions between multiple reference motions, various methods based on \ac{gan} have been developed~\cite{amp_org, amp_quadruped_robot}.
Nevertheless, these approaches are often plagued by mode collapse, a phenomenon resulting from insufficient motion distinction without intrinsic diversity rewards.
Although recent works~\cite{peng2022ase, li2023versatile, luo2023perpetual, tessler2023calm} have made efforts to mitigate mode collapse, they still struggle to handle the switching of specific motions at arbitrary timings, a critical requirement for entertainment robots.

In contrast, self-supervised representation methods using physics simulators have emerged as another promising research direction~\cite{motion_representation}.
While some previous studies have specifically focused on learning dancing motions~\cite{ai_choreographer, transflower}, the \ac{pae}~\cite{periodic_autoencoder} has proven effective in producing smoother and more stable movements for periodic motions, such as locomotion and dancing, with a special treatment of the spatial-temporal relationships inherent in the motions.
The \ac{fld} approach\cite{fld} further extends \ac{pae} by introducing latent dynamics with a quasi-constant representation of motions that greatly reduces the parameterization effort in motion representation and facilitates downstream learning with \ac{rl}.
These methods automatically align and represent motions within a structured latent space, allowing for conditioning desired motion trajectories during policy inference without suffering from mode collapse.
However, both the representation and policy learning in \ac{fld} impose strong periodic assumptions, which can lead to over-smoothed motions that lack expressiveness, a significant drawback for entertainment robots that aim to replicate the nuanced motions of real animals.
