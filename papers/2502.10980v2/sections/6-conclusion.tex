\section{CONCLUSION}
We introduce \ac{dfm}, a novel approach that combines motion representation with \ac{rl} to achieve high tracking accuracy, smooth transitions, and the capability to perform additional tasks during dancing.
By relaxing the strong periodic assumptions presented in previous works, our method demonstrates superior motion expressiveness compared to the baselines.
Our motion representation technique enables continuous frequency changes for unseen reference datasets and facilitates smooth transitions between different motion types through latent space interpolation.
Additionally, \ac{dfm} demonstrates extended multi-task capabilities, such as locomotion and gaze control during dancing, leading to more interactive motions beyond simple motion replay.
These findings have significant implications for advancing research in human-robot interaction for expressive entertainment robots.

% While our method shows considerable improvement in both tracking accuracy and transition smoothness, it is currently optimized for periodic motions.
% Although it can be extended to non-periodic reference motions, the resulting latent space may not be well-structured, which could lead to jerky transitions or suboptimal interpolation when dealing with unseen datasets.

% Our work is the first to demonstrate the successful deployment of motion representation and policy learning on a real entertainment robot.

