\section{Problem Definition}
\label{sec:problem_definition}

% \yy{I feel the connection of the 1st paragraph and the following two is not quite smooth? Also, I feel it not good that we refer to operators/predicates before defining them.}

% We focus on long-horizon tasks that chain skill policies trained through imitation learning using image inputs, assuming a robust planner generates the skill sequence. The primary concern is ensuring these skill policies can adapt to skill-irrelevant changes in predicates within their preconditions.

We focus on long-horizon tasks that chain skill policies trained through imitation learning using visual inputs, assuming a robust planner generates the skill sequence based on a high-level task goal.

We first model the environment as a Partially Observable Markov Decision Process (POMDP), defined as $\mathcal{M} = \langle \mathcal{S}, \mathcal{O}, \mathcal{A}, \mathcal{T}, \mathcal{Z}, r, \gamma \rangle$. Here, $\mathcal{S}$, $\mathcal{O}$, and $\mathcal{A}$ represent the state, observation, and action spaces, respectively. The transition and observation probabilities are $\mathcal{T}(s_{t+1} \mid s_t, a_t)$ and $\mathcal{Z}(o_t \mid s_t)$. The reward function $r(s_t, a_t, s_{t+1})$ and discount factor $\gamma$ guide the trade-off between immediate and future rewards. In our setup, the observation space $\mathcal{O}$ includes both third-person camera views and proprioceptive states. The objective is, for each skill, to learn a policy $\pi : \mathcal{O} \rightarrow \Delta(\mathcal{A})$ that replicates demonstrated behavior from observation-action pairs $\tau = (o_0, a_0, \cdots, o_t, a_t)$, without explicit access to $\mathcal{S}$.

% A significant problem arises during deployment when chaining skill policies, which we define as the \textbf{Observation Space Shift (\pb)}. We adopt the framework of Task and Motion Planning (TAMP) to formalize this problem~\cite{garrett2021integrated, guo2023recent}. We define predicates $\Psi = \{\psi_1, \psi_2, \ldots, \psi_n\}$ as properties or relationships within the state space, where each predicate $\psi_i$ maps a state $s \in \mathcal{S}$ to a truth value, $\psi_i(s) \in \{0, 1\}$. Essentially, each predicate acts as a binary classifier over the state space, identifying a subset of $\mathcal{S}$ where the predicate evaluates to true. As the example shown in Figure~\ref{fig:osm_illustration}, the predicate \texttt{In(potato, bowl)} evaluates to 1 if the potato is inside the bowl, and 0 otherwise. Operator is defined as $\texttt{op} = \langle \texttt{Pre}, \texttt{Eff}, c \rangle$ that comprises three components: preconditions $\texttt{Pre} \subseteq \Psi$, effects $\texttt{Eff} \subseteq \Psi$, and a cost $c$. Intuitively, an operator specifies when a skill can execute (i.e., $\texttt{Pre}$) and what is expected after execution (i.e., $\texttt{Eff}$). Symbolic operators use preconditions (e.g., \texttt{On(bowl, table)}) and effects (e.g., \texttt{On(bowl, cabinet)}) to represent only the elements (e.g., bowl instead of potato) necessary for feasibility of a skill (e.g., \texttt{MoveContainer(bowl, cabinet)}), abstracting away irrelevant ones (e.g., \texttt{In(potato, bowl)}). However, these skill-irrelevant elements often appear in visual observations and can be unintentionally modified by preceding skills' effects. Such changes disrupt visuomotor policies, causing failures in skill execution. This problem, where changes in irrelevant predicates within the visual observation space hinder visuomotor performance, is defined as \pb. 

A significant problem arises during deployment when chaining skill policies, which we define as the \textbf{Observation Space Shift (\pb)}. We adopt the framework of Task and Motion Planning (TAMP) to formalize this problem~\cite{garrett2021integrated, guo2023recent}. We define predicates $\Psi = \{\psi_1, \psi_2, \ldots, \psi_n\}$ as properties or relationships within the state space, where each predicate $\psi_i$ maps a state $s \in \mathcal{S}$ to a truth value, $\psi_i(s) \in \{0, 1\}$. Essentially, each predicate acts as a binary classifier over the state space, identifying a subset of $\mathcal{S}$ where the predicate evaluates to true. As the example shown in Figure~\ref{fig:osm_illustration}, the predicate \texttt{In(potato, bowl)} evaluates to 1 if the potato is inside the bowl, and 0 otherwise. Operator is defined as $\texttt{op} = \langle \texttt{Pre}, \texttt{Eff}, c \rangle$ that comprises three components: preconditions $\texttt{Pre} \subseteq \Psi$, effects $\texttt{Eff} \subseteq \Psi$, and a cost $c$. Intuitively, an operator specifies when a skill can execute (i.e., $\texttt{Pre}$) and what is expected after execution (i.e., $\texttt{Eff}$). Symbolic operators use preconditions (e.g., \texttt{On(bowl, table)}) and effects (e.g., \texttt{On(bowl, cabinet)}) to represent only the elements (e.g., bowl instead of potato) necessary for feasibility of a skill (e.g., \texttt{MoveContainer(bowl, cabinet)}), abstracting away irrelevant ones (e.g., \texttt{In(potato, bowl)}). Formally, a predicate $\psi_i \in \Psi$ is irrelevant for an operator $\texttt{op}$ if $\psi_i \notin \texttt{Pre} \cup \texttt{Eff}$, meaning it does not influence the feasibility or expected outcome of the skill execution. However, these skill-irrelevant elements often appear in visual observations and can be unintentionally modified by preceding skills' effects. Such changes disrupt visuomotor policies, causing failures in skill execution. This problem, where changes in irrelevant predicates within the visual observation space $\mathcal{O}$ hinder visuomotor performance, is defined as \pb.



% \gb{This section is not intuitive and difficult for me to follow. There's lots of terminology and few intuitive examples. Some of them are also not that intuitive to me. I also don't understand why you need all these formalisms to define your problem since they are not used anywhere else in the draft? I feel like the problem is pretty easy to define and understand without these complicated terms/variables, etc. Why would you want to make it harder to follow? I'd understand this if these variables/terms were used later, but it doesn't seem like they are used anywhere else in the draft. I'd consider rewriting using more intuitive/easy-to-follow language/examples}

% Symbolic operators rely on preconditions and effects that abstract away elements irrelevant to a skill's completeness, only ensuring the skill remains feasible despite excluding these elements from symbolic reasoning. However, such skill-irrelevant elements often appear in visual observations and may be inadvertently altered by the effects of preceding skills. These unintended changes can confuse visuomotor policies, leading to failures in skill execution. This problem, where irrelevant predicate changes in the observation space disrupt visuomotor execution, is the \pb.



% zlf: I think one major source is that Pre and Eff doesn't describe unrelated objects (which may be caused by other skills, or just other reasons), so they may change, but in the training data of IL policies, we won't consider deployment time that the skills that can be chained with each other. So a primary point of this paper is that we consider how skills can be chained during data generation stage and add possible variations to training data (?).

% \gb{The second paragraph in this section was very confusing to me. I didn't understand almost any of the formal definitions and how they relate to the OSS problem. I also feel like there's a disconnect between your verbal and formal descriptions. I don't see how they are connected. I'd recommend rewriting the formal descriptions to make them more intuitive and more clear. If you have to, connect them with some intuitive examples. I also feel like you don't need to include lengthy verbal descriptions since technically you already spent a lot of time introducing/verbally defining the problem in the introduction}



% A significant challenge arises during inference when chaining skill policies. Symbolic skill policies (operators) rely on preconditions and effects that often overlook skill-irrelevant environmental elements present in the observation space. These ignored elements, although excluded from symbolic preconditions, can disrupt visuomotor policy execution. To formalize this, we define predicates $\Psi = \{\psi_1, \psi_2, \ldots, \psi_n\}$, which represent properties or relationships within the state space. Each predicate $\psi_i$ maps a state $s \in \mathcal{S}$ to a truth value, $\psi_i(s) \in \{0, 1\}$. An operator $\texttt{op} = \langle \texttt{Pre}, \texttt{Eff}, c \rangle$ comprises three components: preconditions $\texttt{Pre} \subseteq \Psi$, effects $\texttt{Eff} \subseteq \Psi$, and a cost $c$. While some predicates are skill-relevant, others are irrelevant but still appear in visual observations and can be inadvertently modified by the effects of preceding skills. This problem, where skill-irrelevant predicates changes in the observation space disrupt skill execution, is what we define as the \textbf{Observation Space Shift (\pb)}.

% A significant challenge arises during inference when chaining these skill policies, where symbolic skills (operators) have preconditions and effects that may not account for irrelevant elements visible in the observation space. These elements, ignored in symbolic preconditions, can disrupt visuomotor policy execution. We define predicates $\Psi = \{\psi_1, \psi_2, \ldots, \psi_n\}$ that describe properties or relationships in the state space. Each predicate $\psi_i$ maps a state $s \in \mathcal{S}$ to a truth value, $\psi_i(s) \in \{0, 1\}$. An operator $\texttt{op} = \langle \texttt{Pre}, \texttt{Eff}, c \rangle$ consists of preconditions $\texttt{Pre} \subseteq \Psi$, effects $\texttt{Eff} \subseteq \Psi$, and a cost $c$. Some predicates are irrelevant to the task but present in visual observations and potentially altered by previous skills' effects. This is the problem we defined as \textbf{Observation Space Shift (\pb)}.





% In this work, we benchmark the OSM problem, and explore the features of it. We also investigate the  a straightforward solution to this problem.

% The problem is to ensure that the learned policy $\pi$ is robust to observation space modifications, maintaining task success across different conditions. This requires developing methods that generalize across a wide range of observation conditions, ensuring that the policy can handle unexpected changes in the environment that do not affect the task's dynamic feasibility but alter its visual preconditions.

% Mathematically, the goal is to optimize the policy $\pi$ such that for any sequence of observations $\tau = (o_0, a_0, \cdots, o_t, a_t)$, the policy can successfully map observations to actions, $\pi(o_t) \rightarrow a_t$, even when $\mathcal{O}$ is modified by irrelevant elements. This involves minimizing the imitation loss under shifted observation input.



% To address this, we propose a method to ablate irrelevant elements during training, ensuring the policy remains robust to variations in observations.




%%%% Keep original version below:

% For each skill in a long-horizon task, we represent the environment as a Partially Observable Markov Decision 
% Process (POMDP)~\cite{kaelbling1998planning}, $\mathcal{P}=\langle\mathcal{S}, \mathcal{A}, \mathcal{O}, T, 
% \rho_0\rangle$. $\mathcal{S}$ and $\mathcal{A}$ represent the state and action spaces, respectively, while 
% $\mathcal{O}$ is the observation space, which in our work includes a third-person camera view and proprioceptive 
% states. $T : \mathcal{S} \times \mathcal{A} \rightarrow \mathcal{S}$ denotes the transition function, and \rho_0 
% : \mathcal{S} \rightarrow \mathbb{R}$ defines the initial state distribution. In most visual-servoing IL, 
% demonstrations are provided as observation-action pairs, $\tau = (o_0, a_0, \cdots, o_t, a_t)$, without explicit 
% access to $\mathcal{S}$. The objective is to learn a policy $\pi : \mathcal{O} \rightarrow \Delta(\mathcal{A})$ 
% that replicates the demonstrated behavior.

% Math descriptions for OSM problem under the TAMP framework $=>$ pre-condition allows much flexible space for 
% (1) non-interest object positions (e.g., another egg put on the open space) (2) object state (e.g., bottom drawer 
% is opened) (3) non-interest object relationship with interest object (egg in the bowl when the task is ``moving 
% bowl onto the cabinet''). This flexibility is the main reason causing OSM. ...