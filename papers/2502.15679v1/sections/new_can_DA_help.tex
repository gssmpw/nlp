\section{Can Data Augmentation Mitigate \pb?}
\label{sec:da}


\subsection{Data Augmentation}
\label{subsec:our_bl}
% We propose a simple baseline, \bl, which additionally provides a corresponding dataset as a valuable byproduct. As defined in Section~\ref{sec:problem_definition}, the \pb problem arises when visual changes occur due to previous skills. A straightforward solution is to collect a larger set of demonstrations, allowing algorithms to learn from a diverse observation space and become robust to novel visual modifications. To explore the effectiveness of this potential solution to \pb, we augments demonstrations and train all the aforementioned baselines based on it to provide guidance for future research on the \pb problem. 

% \gb{Subsection title is not very informative and just generally sounds weird. It also doesn't fit well with the benchmark section. Lastly, I think it hurts your paper to first introduce the benchmark and then suggest/imply that some simple approach can provide a solution to your benchmark. It defeats the purpose of your benchmark. I would formulate this as some additional baselines rather than the solution}


% \gb{You can just call this Baselines with Data Augmentation or something like that. This is essentially just data augmentation. Not sure why we need to use vague terminology such as "potential solution" to a technique that's already widely used in other fields} %, offering valuable insights for future research on addressing the \pb problem. 

% For each skill-level task, we scalably generate modified tasks with \pb problem using a \textbf{Rule-based Automatic Modification Generator (RAMG)}.\gb{To me the flow of this is not great, i.e., that you start talking about this 2 sections ago, don't conclude it, then have a separate completely unrelated subsection, and then go back to this again.} RAMG is a systematic algorithm designed to enhance diversity in pre-defined environments through structured, rule-based modifications. Operating on PDDL files, RAMG iteratively alters object positions, introduces new objects, or modifies object states within the environment. It supports three types of modifications: (1) repositioning or adding external objects to specific regions, (2) changing the states of fixtures (e.g., opening or closing cabinets), and (3) placing small objects into designated containers. These modifications follow dynamic constraints (e.g., newly added objects do not create obstacles) and maintain logical consistency (e.g., a drawer cannot be simultaneously open and closed) to ensure they do not hinder the agent from achieving the task goal. By utilizing deterministic yet flexible rules, RAMG offers a scalable approach to generating task variations, creating up to 1,727 modified tasks from the 44 tasks in \taskoriginal.


As defined in Section~\ref{sec:problem_definition}, the \pb problem occurs when visual changes caused by preceding skills disrupt the execution of the current skill. A straightforward solution is to collect demonstrations with more diverse visual content, allowing algorithms to learn from varied observation spaces and become more robust to novel visual modifications. To simulate this approach, we augment the demonstrations and train all the baselines on an expanded dataset.

Using RAMG, we generate diverse modified tasks, creating a total of 1,727 new tasks from the 44 selected tasks with a single modification applied to each. For each modified task, we replay demonstrations in the corresponding environment, filtering out failed replays to produce new demonstrations where the trajectory remains unchanged, yet with varied visual observations. This method produces a significantly larger dataset, totaling 57,000 demonstrationsâ€”nearly 30 times the size of the original Libero dataset for the 44 selected tasks (2,000 demonstrations). Notably, this figure corresponds to cases with a single modification applied; an even much larger dataset can be generated by iteratively using RAMG to apply multiple modifications. We then pre-train (BCs) or fine-tune (OpenVLA) all baselines using this expanded dataset.




\input{tables/da_table}

\subsection{Results}
\label{subsec:results_bl}


% \begin{table}[]
% \caption{Your table description here.}
% \centering
% \begin{tabular}{|c|c|c|}
% \hline
% \diagbox{Training}{Evaluation}                                 & \begin{tabular}[c]{@{}c@{}}Demonstrations \\ for Skill-X\end{tabular} & \begin{tabular}[c]{@{}c@{}}Augmented Demonstrations \\ for Skill-X\end{tabular} \\ \hline
% Skill-X                                                            & A                                                                     & B                                                                                        \\ \hline
% \begin{tabular}[c]{@{}c@{}}Skill-X \\ Affected by OSS\end{tabular} & C                                                                     & D                                                                                        \\ \hline
% \end{tabular}
% \end{table}

To investigate whether the data augmentation method mitigates the \pb problem, we compare performance between two setups to assess whether improvements exist on skills affected by \pb. Setup A: baselines are trained on original demonstrations for a skill and evaluated on the skill affected by \pb. Setup B: baselines are trained on augmented demonstrations and evaluated on the same skill affected by \pb. Table~\ref{tb:da_results} presents the performance values for both setups across all baselines, with averaged results reported for all 44 tasks. A comparison between the setups reveals that BC-RESNET-RNN shows a slight improvement under Setup B. However, other baselines, including BC-RESNET-T, BC-VIT-T, and OpenVLA, perform equivalently or worse, suggesting that data augmentation alone is limited in mitigating \pb. While larger and more diverse datasets generally improve performance, they may not fully address \pb. One possible reason is that some baselines struggle to generalize across the diverse visual distributions of demonstrations, leading to even worse performance. Another challenge is the combinatorial explosion of scene and task variations, making it impractical to cover all relevant cases through data augmentation alone. This limitation persists even with RAMG, which is constrained to simulated data generation and cannot scale to real-world data. These findings underscore the need for tailored algorithmic solutions to effectively address \pb.

% A comparison between the setups reveals that BC-RESNET-RNN shows slight improvement under Setup B. However, other baselines, including BC-RESNET-T, BC-VIT-T, and OpenVLA, perform equivalently or worse\gb{Why would the results for Setup B be worse? Can you provide an intuitive explanation of what's happening?}, highlighting the limited effectiveness of data augmentation in mitigating \pb. These findings demonstrate that simply training on larger and more diverse datasets is insufficient to address \pb effectively, underscoring the need for tailored algorithmic solutions.\gb{For me this is a very counterintuitive statement/explanation. I would actually disagree with this. We know that as long as there's sufficiently diverse/large data deep learning algorithms will learn those cases. The main issue is generalization. Therefore, for me the question after reading this statement, is whether you mean that we cannot generate all kinds of combinations of the data that might contribute to OSS? If so, maybe you should explicitly discuss this, i.e., combinatorial space explosion, and the difficulty to generate data for all possible combinations. Otherwise, if that's not an issue, I disagree with your statement, i.e., if you had sufficiently diverse+large dataset, I believe you would be able to solve this problem as evidenced by everything that's happening in deep learning in the last 5-10 years.}

