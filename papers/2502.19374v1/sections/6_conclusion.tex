\section{Conclusion}

In this study, we demonstrated that features extracted from DINOv2 using surround-view image data can be reliably utilized to establish correspondences between point clouds. Through extensive experimentation, we showed that integrating these DINOv2-based point descriptors with traditional registration methods, such as RANSAC or ICP, substantially enhances scan-to-map registration, outperforming various handcrafted and learning-based baselines. We also verified the robustness of the descriptor against seasonal variations and long-term environmental changes.
Future research will explore the potential application of visual foundation models directly to point cloud projections, eliminating the need for surround-view cameras and addressing challenges related to insufficient illumination and inaccuracies in point-to-pixel projection. Additionally, another direction for further research is explicitly combining the semantic richness of DINOv2 features with geometric features.
