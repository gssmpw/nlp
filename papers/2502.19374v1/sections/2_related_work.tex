\section{Related Work}

Point cloud registration has been extensively studied by the research community across a diverse range of applications. Previous works have addressed alignment of relatively small 3D objects~\cite{breitenreicher2010robust}, mid-size indoor scenes~\cite{poiesi2021dip, zeng20173dmatch}, LiDAR odometry~\cite{cui2024sageicp, vizzo2023kissicp}, and scan registration to 3D maps~\cite{hroob2024generalizable}. Particularly the latter introduces further challenges, such as geometric and semantic discrepancies between the source and the target point clouds, arising from temporal changes in the environment since the creation of the reference map. While the majority of studies focus on object alignment or LiDAR odometry, only a few works~\cite{hroob2024generalizable, kim2019scancontextimage} explicitly target long-term scenarios. Typically, the point cloud registration problem is addressed in two stages: first, identifying point-to-point correspondences using point descriptors and, second, determining the six degrees of freedom (6DoF) transformation required to align the two point clouds. In the following paragraphs, we provide an overview of each of these steps. \looseness=-1

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/overview.png}
    \vspace*{-.6cm}
    \caption{Overview of our proposed approach for 6DoF point cloud registration. First, we extract DINOv2~\cite{oquab2024dinov2} features from surround-view image data. These features are then attached to the point cloud as point descriptors via point-to-pixel projection. Second, we perform a point-wise similarity search using cosine similarity between the descriptors of the LiDAR scan and the descriptors of the voxelized 3D map. Finally, we use a traditional coarse-to-fine registration scheme with RANSAC~\cite{fischler1987ransac} and point-to-point ICP~\cite{vizzo2023kissicp} for obtaining a highly accurate pose estimate within the provided map frame.}
    \label{fig:overview}
    \vspace*{-.5cm}
\end{figure*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\parskip=3pt
\noindent\textit{Point Descriptors:}
Point descriptors refer to an abstract representation of a 3D point that can be used to search for point-to-point correspondences between two point clouds. In contrast to a naive nearest-neighbor search in the Euclidean space, e.g., performed by the iterative closest point (ICP) algorithm~\cite{besl1992icp}, point descriptors allow finding global correspondences.
A classical, yet still commonly used~\cite{bai2021pointdsc, yang2021teaser} descriptor is the FPFH~\cite{rusu2009fpfh} descriptor that captures the geometry around a point by computing local feature histograms based on the angles to its neighboring points. FPFH is designed to provide both translational and rotational invariance.
In more recent years, many learning-based approaches have been proposed that employ deep neural networks for extracting point descriptors. These methods can generally be categorized into patch-based networks and fully convolutional networks.
3DMatch~\cite{zeng20173dmatch} pioneered the first category by learning local geometric patterns from volumetric patches around a point. While 3DMatch computes truncated distance function values from the patch, 3DSmoothNet~\cite{gojcic2019perfectmatch} uses a smoothed density value representation to achieve rotation invariance. Both DIP~\cite{poiesi2021dip} and GeDi~\cite{poiesi2023gedi} propose to follow a Siamese approach to train two neural networks with shared parameters and a contrastive loss on the patches. 
Unlike patch-based approaches, fully convolutional networks employ such a contrastive loss directly on the point level as first proposed by FCGF~\cite{choy2019fcgf}, which is commonly used by many registration algorithms~\cite{bai2021pointdsc}. While early convolutional descriptors were either computed for all points of a point cloud or a randomly sampled subset, later works such as D3Feat~\cite{bai2020d3feat} include keypoint detection schemes. A particular challenge of operating on individual points instead of patches is to achieve density invariance. Therefore, GCL~\cite{Liu2023gcl} focuses on low-overlap scenarios, e.g., required for early loop closure registration in LiDAR SLAM.
Although learning-based descriptors have shown impressive performance, a substantial drawback is their poor generalization between different training and testing domains, e.g., \mbox{RGB-D} data versus LiDAR scans or aligning individual objects versus large-scale outdoor scenes.

The majority of point descriptors focus on encoding only geometric information neglecting semantic hints. Especially in the context of autonomous driving, a few works have proposed to include information from semantic segmentation. For instance, SAGE-ICP~\cite{cui2024sageicp} extends the point correspondence search of ICP with a hard rejection scheme if the candidate points belong to different semantic classes. The transformer-based PADLoC~\cite{arce2023padloc} exploits panoptic information during the training phase to avoid wrong matches. Nonetheless, a major barrier to including semantic information is the lack of 3D segmentation networks that generalize well across domains requiring cost-intense retraining. In this work, we exploit the recent advances in the vision domain by proposing to extract point descriptors using a visual foundation model~\cite{oquab2024dinov2}. In contrast to the hard matching of discrete semantic classes, our method enables searching more soft correspondences while considering the scene semantics.
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\parskip=3pt
\noindent\textit{Point Cloud Registration:}
Algorithms for point cloud registration can be categorized into local and global registration schemes. Whereas local methods require an accurate initial guess, global registration often assumes given point correspondences based on the aforementioned point descriptors. Often, both types are combined in a coarse-to-fine manner to achieve global registration with the high performance of local approaches such as ICP~\cite{besl1992icp} or NDT~\cite{biber2003ndt}.
To obtain a sufficient coarse registration, a main requirement for global registration schemes is outlier rejection. The most popular traditional method for this task is still RANSAC~\cite{fischler1987ransac}, including its more recent variants~\cite{barath2022magsac}. However, the major drawbacks of RANSAC are slow convergence and low accuracy in the presence of large outlier rates, which are commonly faced in point cloud registration. Fast global registration (FGR)~\cite{zhou2016fgr} aims to overcome these problems by optimizing a robust objective function that is defined densely over the surfaces. TEASER~\cite{yang2021teaser} proposes a certifiable algorithm that decouples scale, rotation, and translation estimation.
Similar to other fields, recent outlier rejection schemes attempt to improve their performance via deep learning. Both deep global registration (DGR)~\cite{choy2020dgr} and 3DRegNet~\cite{pais20203dregnet} formulate outlier rejection as a point-based classification problem. PointDSC~\cite{bai2021pointdsc} extends this idea by including the spatial consistency between inlier correspondences when applying rigid Euclidean transformations.
In this work, we demonstrate that coupling our proposed point descriptors with traditional registration algorithms, such as RANSAC or ICP, enables robust point cloud registration.
}
