\section{Discussion of the Limitations}

In this section, we outline some limitations of our approach. As discussed in \cref{sec:intro}, LiDAR-camera sensor configurations are a common setup on mobile robots. We further show in \cref{ssec:exp-scan-to-map} that the additional vision modality enables our method to substantially outperform LiDAR-only baselines. Nonetheless, fusing these modalities introduces new challenges such as accurate extrinsic calibration and time synchronization. A primary source of error arises from incorrect projection of DINOv2 features from image pixels to the wrong LiDAR points, which can lead to misalignments, such as a \textit{tree} pixel being projected onto a building in the point cloud. Eventually, this results in an incorrect semantic description of a point. Other factors contributing to such errors include the presence of moving objects and varying fields of view of the sensors. Furthermore, limitations inherent to DINOv2, such as dependence on adequate illumination, may also affect performance. Lastly, we anticipate reduced performance when dealing with out-of-domain data, e.g., deployment in extraterrestrial environments like Mars. In most relevant scenarios though, this limitation is mitigated by the robust generalization capabilities of DINOv2.
