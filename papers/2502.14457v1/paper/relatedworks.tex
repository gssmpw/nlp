\section{Related work}
\label{sec:relatedworks}
% all approaches / affordacne + RL add 2+3 from intro to introduce here
\subsection{Articulated object manipulation}
Manipulating articulated objects is highly challenging due to the wide variety of object geometries and physical properties. Recent works on articulated object manipulation can be broadly categorized into affordance-based and RL-based methods. Affordance-based approaches rely on visual affordance heatmaps~\cite{theory} where each point corresponds to the success rate of manipulation to choose contact points and predict actions~\cite{vatmart,where2act,umpnet,roboabc}.   However, this approach often neglects physical interaction and suffers from large sim-to-real gap \cite{where2act, where2explore, coarse}, which limits their generalizable capability to novel scenes. On the other hand, RL-based methods~\cite{partmanip,rlafford, li2024unidoormanip} with closed-loop feedback have shown better generalization capability. Nevertheless, they utilize point-cloud features as an input to the policy, which makes the exploration space vast and complicates the task. These pipelines also leverage visual input for each inference step which inherently introduces more sim-to-real gap. Our work only leverages low-dimensional vision information captured in the first frame and incorporates history observation during the manipulation stage for better object motion understanding with RL.
 
% Recent articulated object manipulation works rely on first-frame vision input or closed-loop feedback. In manipulation tasks, affordance~\cite{theory} refers to the potential ways a robot can interact with objects. Specifically, visual affordance leverages visual information from both objects and robots to predict the likelihood of successfully executing each contact pose. Recent works have heavily focused on learning grasping affordance~\cite{redmon2015real,qin2020s4g,jiang2021synergies,kokic2020learning,mandikal2021learning,roboabc} and manipulation affordance~\cite{fang2018demo2vec,fang2020learning,nagarajan2020learning,xu2021deep} to enhance robot-object interaction. For tasks involving articulated objects, AdaAfford~\cite{adaafford}, Where2Act~\cite{where2act}, RL-Afford~\cite{rlafford} and Where2Explore~\cite{where2explore} use dense affordance maps as actionable visual representations, indicating the success rate of manipulation at each point on the 3D articulated object. VAT-MART~\cite{vatmart} introduces visual priors as representations for estimating actionable grasp poses while considering the geometrical constraints of articulated objects. Our work only leverages low-dimensional vision information captured in the first frame and incorporates history observation during the manipulation stage for better object motion understanding.

\subsection{Impedance control for learning-based methods}

Impedance control belongs to the position-force control family where position and force are not decoupled but simultaneously processed, thus enhancing tolerance to feedback force while maintaining a good tracking state. Many contact-rich robotic tasks such as object placement~\cite{industreal} or tool assembly~\cite{admitlearn,atla,factory,fmb,genchip} have successfully demonstrated the compatibility of this type of controller for tasks that consider both position setpoint tracking and object-robot force constraints. For learning-based methods, many works~\cite{manipllm,rgbmanip,imagemanip} introduce impedance control as an off-the-shelf low-level controller for downstream command execution guided by a policy. Some directly incorporate impedance control parameters as learnable variables for RL~\cite{admitlearn,variable}, inverse RL~\cite{impedance_irl}, or analytical optimization methods~\cite{compliancetuning}. These works also showcase that variable impedance control can be more generalizable to different task settings and less labor-expensive than manually tuned impedance control. In this work, we extend the application of impedance control for articulated object manipulation by learning control gain in the simulation and directly transfer to the real world.