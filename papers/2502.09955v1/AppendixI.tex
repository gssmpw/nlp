\section{IMO Combinatorics Agent Architecture}
\label{appendix:I}

\paragraph{Reinforcement learning for bounding or solution search.}
If the problem \(\mathcal{P}\) requires finding an \emph{optimal bound} or solution, we use RL to learn a policy \(\pi^\star\colon \Omega \to \mathcal{A}\) that maximizes expected return. Formally, we solve:
\[
\pi^\star \;=\; \underset{\pi}{\mathrm{argmax}} \;
\mathbb{E}_{\tau \sim \pi}\Bigl[\sum_{t} \gamma^t\, R\bigl(s_t,\, a_t\bigr)\Bigr],
\]
where \(\gamma \in [0,1]\) is a discount factor. The policy \(\pi^\star\) discovered through RL (e.g.\ via PPO or policy gradient) may guide us to improved or optimal solutions for \(\mathcal{P}\). 

\paragraph{Deriving an answer or proof in English.}
Using the relevant data (books, proof guides, etc), simulation results or learned policy \(\pi^\star\), the model \(\mathcal{M}\) proposes an answer or proof $X_{\mathrm{EN}}$ in English
that explains the reasoning steps, the final answer, or a bound that addresses the problem.


\begin{figure*}[htb]
  \centering
   \includegraphics[width=0.7\linewidth]{imocomblean.png}
   \caption{Our approach to solving IMO combinatorics problems has three stages: (i) Encoding: The problem is encoded as a game in python, including a state space, action space, and reward function. This is done by representing the problem as a programmatic game with an agent and policy, generated by a large language model. (ii) Reinforcement Learning: We simulate the game and if required we find the optimal policy, then record multiple episodes as data and videos. This process is repeated for different dimensions. (iii) Decoding: We use the data in Appendix N along with the simulation data to generate a proof. We autoformalize this proof in Lean, verify its correctness, translate back to English and repeat this process until the proof is correct. Appendix I describes this agent graph in detail.}

   \label{fig:combinatorics_pipeline}
   \vspace{-5pt}
\end{figure*}

\begin{figure*}[htb]
  \centering
   \includegraphics[width=1.0\linewidth]{Team_of_Agents.png}
   \caption{A multi-stage automated reasoning pipeline for problem solving and proof generation. The pipeline begins with user inputs specifying a competition and a problem identifier. The Select Problem node retrieves the corresponding data, feeding it to the Problem Analysis Agent, which detects the problem type and dispatches it via a Router to domain-specific modules. The Game Environment Agent and Simulation Agent combine reinforcement learning-based exploration with simulation to inform the Proof Synthesis Agent, which generates an English proof. This proof is then autoformalized into a Lean-compatible format and verified by the Lean Environment Agent. A conditional node checks validity before producing the final proof output, ensuring correctness throughout the entire automated pipeline.}

   \label{fig:Team_of_Agents}
   \vspace{-5pt}
\end{figure*}


\begin{figure*}[htb]
  \centering
   \includegraphics[width=1.0\linewidth]{Select_Problem.png}
   \caption{A sub-graph that retrieves a specific data record from a user-specified dataset and output the extracted information. The agent begins with two Graph Input nodes, which accept a dataset ID and a row ID. These inputs feed into a Get Dataset Row node, which queries the dataset to retrieve the corresponding row. The resulting data is then passed to a Destructure node that extracts the first element of the returned array. Next, the extracted field is routed to the Problem Selected text node, where it is formatted for output. Finally, the Graph Output node presents the processed result.}

   \label{fig:Select_Problem}
   \vspace{-5pt}
\end{figure*}

\begin{figure*}[htb]
  \centering
   \includegraphics[width=1.0\linewidth]{Problem_Analysis_Agent.png}
   \caption{The Problem Analysis Agent classify an International Mathematical Olympiad (IMO) problem into one of four categories: (i) Algebra, (ii) Geometry, (iii) Number Theory, or (iv) Combinatorics. A single Graph Input node supplies the problem statement. Four text nodes house representative examples of each problem type and are merged via a join node to form a comprehensive set of classification references. Alongside a separate node listing the four possible types, these references feed into a Prompt node, which composes a unified request for classification. A Chat node then processes this prompt, leveraging both the user's input and curated examples to generate the most suitable category. The final classification is delivered to the Graph Output node.}

   \label{fig:Problem_Analysis_Agent}
   \vspace{-5pt}
\end{figure*}

\begin{figure*}[htb]
  \centering
   \includegraphics[width=1.0\linewidth]{Game_Environment_Agent.png}
   \caption{An Agent graph used to generate a Pygame Gymnasium environment for an IMO combinatorics problem. Text nodes supply training materials, problem descriptions, and notes on combinatorics. Join nodes merge these textual inputs, combining them with a specialized encoding template. Arrows indicate the data flow from user inputs through intermediate prompts, leading to nodes that formulate game representations and environment specifications. Conditional branches and joins coordinate the transformation of input text into structured prompts. In the final step, a code-generation module produces a complete environment implementation.}

   \label{fig:Game_Environment_Agent}
   \vspace{-5pt}
\end{figure*}


\begin{figure*}[htb]
  \centering
   \includegraphics[width=1.0\linewidth]{Simulation_Agent.png}
   \caption{A multi-step agent workflow for creating and running a custom reinforcement learning simulation. The process begins by gathering text inputs-problem definitions, reference material, and existing code before assembling them into a prompt (left portion). The agent then parses code blocks, installs dependencies, and iteratively checks and fixes errors through loop controllers (Evaluate Dependencies, Evaluate Training Code, and Evaluate Simulation Code). Key subgraphs such as Fix Dependencies, Train RL Game, and Run Simulation encapsulate targeted repair and execution logic. Upon successful completion of each stage, the results are coalesced into a unified output pipeline, ultimately returning game simulations.}
   \label{fig:Simulation_Agent}
   \vspace{-5pt}
\end{figure*}

\begin{figure*}[htb]
  \centering
   \includegraphics[width=1.0\linewidth]{Simulation_Dependencies.png}
   \caption{An agent for automated Python dependency installation. The agent reads a list of dependencies from the Graph Input node and writes them to a requirements file via the Write Requirements File node. The Context node provides the project path, which is used as the working directory and base directory for file operations. The Install Dependencies Command node creates a virtual environment, upgrades pip, and installs dependencies from the generated requirements file. Its output is routed to one Graph Output (labeled Code), while its exit code updates a Boolean node to signal errors, exposed through the second Graph Output (Has Errors?). This workflow provides a standardized environment configuration and verifies the success of installations.}

   \label{fig:Simulation_Dependencies}
   \vspace{-5pt}
\end{figure*}

\begin{figure*}[htb]
  \centering
   \includegraphics[width=1.0\linewidth]{Simulation_Fix_Dependencies.png}
   \caption{An agent graph for automatically repairing Python dependencies. The agent receives an error message through a Graph Input node and retrieves the current requirements via a Read File node. These inputs are merged in a prompt node (Fix Dependencies Code Prompt) before being processed by a language model (Fix Dependencies Code Chat), which produces a corrected version of the requirements. An Extract Markdown Code Blocks node parses the model's output to extract the fixed dependency list. Finally, the agent delivers this updated set of dependencies to the Graph Output node, and an optional (disabled) Write Requirements File node demonstrates how the new requirements could be written back to a file. This setup streamlines dependency fixes by automating error analysis and requirements updates.}

   \label{fig:Simulation_Fix_Dependencies}
   \vspace{-5pt}
\end{figure*}

\begin{figure*}[htb]
  \centering
   \includegraphics[width=1.0\linewidth]{Simulation_Training.png}
   \caption{This figure depicts an agent that orchestrates a reinforcement learning training pipeline. Two input nodes, labeled Graph Input, supply code or project data, while context nodes store the project and model paths. The Model File Exists? subgraph checks if a trained model is already present. If not, the agent writes a new training file (Write Training File) and invokes the Train RL GAME Command shell command. Conditional logic in Already Trained? ensures unnecessary training steps are bypassed. The results of each step are merged using Coalesce nodes, ultimately producing two graph outputs: the generated code and a Has Errors? status.}

   \label{fig:Simulation_Training}
   \vspace{-5pt}
\end{figure*}

\begin{figure*}[htb]
  \centering
   \includegraphics[width=1.0\linewidth]{Simulation_Fix_Training.png}
   \caption{This figure presents a pipeline agent designed to automatically correct errors in a Python training script for reinforcement learning. The flow begins with two input nodes providing the script content (via direct file read and user input) and the associated error message. A prompt node compiles these inputs into a structured query passed to a chat-based language model node, which analyzes the error context and suggests modifications. The agent then extracts the corrected code block from the model's response and outputs the fully revised script. The agent performs error analysis, targeted code updates, and convenient code retrieval from the model's response.}

   \label{fig:Simulation_Fix_Training}
   \vspace{-5pt}
\end{figure*}

\begin{figure*}[htb]
  \centering
   \includegraphics[width=1.0\linewidth]{Simulation_Build.png}
   \caption{This figure presents an agent graph designed to transform an existing reinforcement learning training script into a standalone simulation script. The graph begins with two input nodes: one providing the original script text (Graph Input) and another specifying the project path (Context). These inputs feed into a Prompt node, which constructs detailed instructions for modifying the script. A Chat node then processes the prompt with a language model to generate the updated code. The Extract Markdown Code Blocks node retrieves the code snippets from the model's response, and the Write File node saves them to a new file, run\_simulation.py. Finally, the Graph Output node provides the finalized simulation script, which loads a trained model and outputs simulation traces.}

   \label{fig:Simulation_Build}
   \vspace{-5pt}
\end{figure*}

\begin{figure*}[htb]
  \centering
   \includegraphics[width=1.0\linewidth]{Simulation_Run.png}
   \caption{This figure shows an agent that orchestrates the process of verifying and generating simulation files, running simulations, and writing trace outputs. The agent is triggered by two user-defined inputs (Code and input) and references two context variables (project\_path, simulations\_path). First, the agent checks whether a required simulation file exists using a sub-graph node. If the file is absent, a new one is created, and a shell command is executed to run the simulation. Then, trace outputs are optionally written based on a Boolean condition. Key decision points are handled via If-nodes, while coalesce nodes merge outputs for final logging. The Has Errors? output is derived from the simulation's exit code, providing robust error handling.}
   \label{fig:Simulation_Run}
   \vspace{-5pt}
\end{figure*}


\begin{figure*}[htb]
  \centering
   \includegraphics[width=1.0\linewidth]{Simulation_Fix_Simulation.png}
   \caption{This graph illustrates an automated code-repair pipeline implemented as an agent. The process begins with two input nodes providing an error message and references to the simulation script. A file-reading node retrieves the original code, which is combined with the error details in a Prompt node. The integrated prompt is then passed to a Chat node, where a language model proposes corrections. An intermediate node extracts the revised code from the model's response, and the final Graph Output node delivers the fixed script. With the orchestration of these steps, the agent systematically diagnoses the reported error, leverages the language model for targeted fixes, and outputs a clean, corrected version of the code.}

   \label{fig:Simulation_Fix_Simulation}
   \vspace{-5pt}
\end{figure*}

\begin{figure*}[htb]
  \centering
   \includegraphics[width=1.0\linewidth]{Proof_Synthesis_Agent.png}
   \caption{A multi-stage Proof Synthesis Agent pipeline for generating and refining an IMO-style combinatorics proof. The four input nodes provide the problem statement, Lean encoding, game representation, and simulation data. File-reading nodes import style guidelines and reference materials, which are merged into a unified Proof Writing Book resource. The Infer Numeric Answer Prompt node processes the simulation data to propose a numeric solution, while the WRITE PROOF Prompt composes the initial LaTeX proof. Subsequently, the REVIEW PROOF Prompt refines the draft by integrating style recommendations and reference proofs. Finally, the pipeline's concluding Chat node synthesizes a polished proof, producing a GENERATED\_PROOF output that aligns with IMO standards}

   \label{fig:Proof_Synthesis_Agent}
   \vspace{-5pt}
\end{figure*}

\begin{figure*}[htb]
  \centering
   \includegraphics[width=1.0\linewidth]{Autoformalization_Agent.png}
   \caption{An Autoformalization Agent graph that orchestrates the conversion of IMO-style combinatorics problems between Lean formal language and English statements. Each colored node corresponds to a distinct role in the workflow: text nodes store sample problem statements (both Lean and English), prompt nodes guide the translation process, and chat nodes handle iterative refinement. The graph begins with an English Problem Graph Input node, which provides the source problem text. From there, edges connect to dedicated prompt nodes (Eng2Lean\_Prompt or Lean2Eng\_Prompt) that facilitate the translation and verification steps. Multiple text nodes containing examples serve as references, feeding contextual information into these transformations. Finally, the "Graph Output" node aggregates the translated or verified results. This structure enables the agent to systematically retrieve examples, apply specialized translation prompts, and deliver a coherent final output, thus streamlining the end-to-end autoformalization of mathematical problems.}

   \label{fig:Autoformalization_Agent}
   \vspace{-5pt}
\end{figure*}

\begin{figure*}[htb]
  \centering
   \includegraphics[width=1.0\linewidth]{Lean_Environment_Agent.png}
   \caption{An agent for creating and running a Lean 4 environment. Three context nodes (project\_path, lean\_env, lean\_file\_path) supply directory paths and environment settings, which are joined into a working directory. A text node provides Lean code, which is written to a file (test.lean) using the Write Lean4 File node. The Setup Lake Env Command node initializes a new Lake project, while the subsequent Shell Command node executes the Lean file in the configured environment. The string output from the final command is captured by one Graph Output node, and a second Graph Output node emits a boolean flag indicating the validity of the process. The agent thus automates the creation, configuration, and execution of a Lean script.}

   \label{fig:Lean_Environment_Agent}
   \vspace{-5pt}
\end{figure*}