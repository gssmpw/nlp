@inproceedings{alayrac2022flamingo,
author = {Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millicah, Katie and Reynolds, Malcolm and others},
title = {Flamingo: a visual language model for few-shot learning},
year = {2022},
isbn = {9781713871088},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proc. of the 36th Int. Conf. on Neural Information Processing Systems},
articleno = {1723},
numpages = {21},
location = {New Orleans, LA, USA},
series = {NIPS '22}
}

@misc{belkhale2024minivla,
      title={MiniVLA: A Better VLA with a Smaller Footprint}, 
      author={Suneel Belkhale and Dorsa Sadigh},
      url={https://github.com/Stanford-ILIAD/openvla-mini},
      year={2024},
}

@InProceedings{bensadoun2024meta,
  title={Meta 3d gen},
  author={Bensadoun, Raphael and Monnier, Tom and Kleiman, Yanir and Kokkinos, Filippos and Siddiqui, Yawar and Kariya, Mahendra and Harosh, Omri and Shapovalov, Roman and Graham, Benjamin and Garreau, Emilien and others},
  Eprint ={arXiv:2407.02599.},
  note = {arxiv:2407.02599.},
  year={2024}
}

@inproceedings{brohan2022rt,
  title={Rt-1: Robotics transformer for real-world control at scale},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Dabis, Joseph and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and Hsu, Jasmine and others},
  eprint={arXiv:2212.06817.},
  note={arxiv:2212.06817.},
  year={2022}
}

@article{brohan2023rt,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  eprint={arXiv:2307.15818.},
  note={arxiv:2307.15818.},
  year={2023}
}

@InProceedings{chen2019text2shape,
author="Chen, Kevin
and Choy, Christopher B.
and Savva, Manolis
and Chang, Angel X.
and Funkhouser, Thomas
and Savarese, Silvio",
title="Text2Shape: Generating Shapes from Natural Language by Learning Joint Embeddings",
booktitle="Proc. of the 14th Asian Conf. on Computer Vision (ACCV 2018), Perth, Australia, December 2--6",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="100--116",
isbn="978-3-030-20893-6"
}

@InProceedings{deitke2024molmo,
  title={Molmo and pixmo: Open weights and open data for state-of-the-art multimodal models},
  author={Deitke, Matt and Clark, Christopher and Lee, Sangho and Tripathi, Rohun and Yang, Yue and Park, Jae Sung and Salehi, Mohammadreza and Muennighoff, Niklas and Lo, Kyle and Soldaini, Luca and others},
  eprint={arXiv:2409.17146.},
  note = {arxiv:2409.17146.},
  year={2024}
}

@inproceedings{driess2023palm,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  eprint={arXiv:2303.03378.},
  note={arxiv:2303.03378.},
  year={2023}
}

@inproceedings{fu2022shapecrafter,
author = {Fu, Rao and Zhan, Xiao and Chen, Yiwen and Ritchie, Daniel and Sridhar, Srinath},
title = {ShapeCrafter: a recursive text-conditioned 3D shape generation model},
year = {2022},
isbn = {9781713871088},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proc. of the 36th Int. Conf. on Neural Information Processing Systems},
articleno = {646},
numpages = {14},
location = {New Orleans, LA, USA},
series = {NIPS '22}
}

@InProceedings{gbagbe2024bi,
  title={Bi-VLA: Vision-Language-Action Model-Based System for Bimanual Robotic Dexterous Manipulations},
  author={Gbagbe, Koffivi Fid{\`e}le and Altamirano Cabrera, Miguel  and Alabbas, Ali and Alyunes, Oussama and Lykov, Artem and Tsetserukou, Dzmitry},
  eprint={arXiv:2405.06039},
  note = {arxiv:2405.06039.},
  year={2024}
}

@INPROCEEDINGS{jain2022zero,
  author={Jain, Ajay and Mildenhall, Ben and Barron, Jonathan T. and Abbeel, Pieter and Poole, Ben},
  booktitle={Proc. of the IEEE/CVF Conf. on Computer Vision and Pattern Recognition (CVPR 2022)}, 
  title={Zero-Shot Text-Guided Object Generation with Dream Fields}, 
  year={2022},
  volume={},
  number={},
  pages={857-866},
  doi={10.1109/CVPR52688.2022.00094}}

@InProceedings{khan2025shake,
  title={Shake-VLA: Vision-Language-Action Model-Based System for Bimanual Robotic Manipulations and Liquid Mixing},
  author={Khan, Muhamamd Haris and Asfaw, Selamawit and Iarchuk, Dmitrii and Altamirano Cabrera, Miguel and Moreno, Luis and Tokmurziyev, Issatay and Tsetserukou, Dzmitry},
  Eprint = {arXiv:2501.06919},
  note = {arXiv:2501.06919.},
  year={2025}
}

@inproceedings{kim2024openvla,
  title={OpenVLA: An Open-Source Vision-Language-Action Model},
  author={Kim, Moo Jin and Pertsch, Karl and Karamcheti, Siddharth and Xiao, Ted and Balakrishna, Ashwin and Nair, Suraj and Rafailov, Rafael and Foster, Ethan and Lam, Grace and Sanketi, Pannag and others},
  eprint={arXiv:2406.09246},
  note={arxiv:2406.09246.},
  year={2024}
}

@inproceedings{li2023blip,
author = {Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
title = {BLIP-2: bootstrapping language-image pre-training with frozen image encoders and large language models},
year = {2023},
publisher = {JMLR.org},
booktitle = {Proc. of the 40th Int. Conf. on Machine Learning},
articleno = {814},
numpages = {13},
location = {Honolulu, Hawaii, USA},
series = {ICML'23}
}

@INPROCEEDINGS{liu2022towards,
  author={Liu, Zhengzhe and Wang, Yi and Qi, Xiaojuan and Fu, Chi-Wing},
  booktitle={Proc. of the 2022 IEEE/CVF Conf. on Computer Vision and Pattern Recognition (CVPR 2022)}, 
  title={Towards Implicit Text-Guided 3D Shape Generation}, 
  year={2022},
  volume={},
  number={},
  pages={17875-17885},
  doi={10.1109/CVPR52688.2022.01737}}

@INPROCEEDINGS{liu2024sherpa3d,
  author={Liu, Fangfu and Wu, Diankun and Wei, Yi and Rao, Yongming and Duan, Yueqi},
  booktitle={Proc. of the IEEE/CVF Conf. on Computer Vision and Pattern Recognition (CVPR 2024)}, 
  title={Sherpa3D: Boosting High-Fidelity Text-to-3D Generation via Coarse 3D Prior}, 
  year={2024},
  volume={},
  number={},
  pages={20763-20774},
  doi={10.1109/CVPR52733.2024.01962}}

@inproceedings{o2023open,
  title={Open x-embodiment: Robotic learning datasets and rt-x models},
  author={O'Neill, Abby and Rehman, Abdul and Gupta, Abhinav and Maddukuri, Abhiram and Gupta, Abhishek and Padalkar, Abhishek and Lee, Abraham and Pooley, Acorn and Gupta, Agrim and Mandlekar, Ajay and others},
  eprint={arXiv:2310.08864.},
  note={arxiv:2310.08864.},
  year={2023}
}

@inproceedings{openai2024gpt4technicalreport,
      title={GPT-4 Technical Report}, 
      author={OpenAI and others},
      eprint={arXiv:2303.08774.},
      note={arxiv:2303.08774.},
       year={2024}
}

@article{osher2004level,
  title={Level set methods and dynamic implicit surfaces},
  author={Osher, Stanley and Fedkiw, Ronald and Piechor, K},
  journal={Appl. Mech. Rev.},
  volume={57},
  number={3},
  pages={B15--B15},
  year={2004}
}

@InProceedings{peng2023kosmos,
  title={Kosmos-2: Grounding multimodal large language models to the world},
  author={Peng, Zhiliang and Wang, Wenhui and Dong, Li and Hao, Yaru and Huang, Shaohan and Ma, Shuming and Wei, Furu},
  eprint={arXiv:2306.14824.},
  note = {arxiv:2306.14824.},
  year={2023}
}

@inproceedings{siddiqui2024meshgpt,
  title={Meshgpt: Generating triangle meshes with decoder-only transformers},
  author={Siddiqui, Yawar and Alliegro, Antonio and Artemov, Alexey and Tommasi, Tatiana and Sirigatti, Daniele and Rosov, Vladislav and Dai, Angela and Nie{\ss}ner, Matthias},
  booktitle={Proc. of the IEEE/CVF Conf. on Computer Vision and Pattern Recognition (CVPR 2024)},
  pages={19615--19625},
  year={2024},
 doi={10.1109/CVPR52733.2024.01855}
}

@InProceedings{wang2024llama,
      title={LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models}, 
      author={Zhengyi Wang and Jonathan Lorraine and Yikai Wang and Hang Su and Jun Zhu and Sanja Fidler and Xiaohui Zeng},
      year={2024},
      eprint={arXiv:2411.09595.},
      note={arxiv:2411.0959.}
}

@InProceedings{wang2024qwen2,
      title={Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution}, 
      author={Peng Wang and Shuai Bai and Sinan Tan and Shijie Wang and Zhihao Fan and Jinze Bai and Keqin Chen and Xuejing Liu and Jialin Wang and Wenbin Ge and Yang Fan and Kai Dang and Mengfei Du and Xuancheng Ren and Rui Men and Dayiheng Liu and Chang Zhou and Jingren Zhou and Junyang Lin},
      year={2024},
      eprint={arXiv:2409.12191.},
      note = {arxiv:2409.12191.}
}

@inproceedings{yu2023text,
      title={Text-to-3D with Classifier Score Distillation}, 
      author={Xin Yu and Yuan-Chen Guo and Yangguang Li and Ding Liang and Song-Hai Zhang and Xiaojuan Qi},
      year={2023},
      eprint={arXiv:2310.19415.},
      note = {arxiv:2310.19415.}
}

