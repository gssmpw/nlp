\section{Near-Optimal LDDs in Near-Linear Time} \label{sec:ldd-fast}
In this section we show that near-optimal LDDs can even be computed in near-linear (i.e., near-optimal) running time. Formally, the goal of this section is to prove the last of our main theorems:

\thmMainFast*

We structure this section as follows: In \cref{sec:ldd-fast:sec:cutting} we first prove an important cutting lemma (\cref{lem:cut-light}), which we then apply in \cref{sec:ldd-fast:sec:algo} to prove \cref{thm:main-fast}.

\subsection{Cutting Lemma} \label{sec:ldd-fast:sec:cutting}
We rely on the following result due to Cohen that we can approximate efficiently the sizes of out-balls $\Bout(v, r)$ simultaneously for all nodes $v$. Note that we can equally approximate the size of the in-balls $\Bin(v, r)$ by applying \cref{lem:cohen} on the reverse graph.

\begin{lemma}[Cohen's Algorithm~{{\cite[Theorem~5.1]{Cohen97}}}] \label{lem:cohen}
Let $G$ be a directed weighted graph, let $r \geq 0$ and~\makebox{$\epsilon > 0$}. There is an algorithm that runs in time $\Order(m \epsilon^{-2} \log^3 n)$ and computes approximations~$b(v)$ satisfying with high probability that
\begin{equation*}
    (1 - \epsilon) |\Bout(v, r)| \leq b(v) \leq (1 + \epsilon) |\Bout(v, r)|.
\end{equation*}
\end{lemma}

The goal of this subsection is to establish the following lemma:

\begin{lemma}[Cutting Light Nodes] \label{lem:cut-light}
Let $G = (V, E)$ be a directed weighted graph, and consider the parameters $\delta > 0$, $0 \leq r_0 < r_1$, $1 \leq s_1 < s_0 \leq m$. There is an algorithm that computes a set of cut edges $S \subseteq E$ and sets of remaining vertices $R \subseteq V$ such that:
\begin{enumerate}[label=(\roman*)]
    \item Each strongly connected component in $G \setminus S$ either only contains nodes from $R$ or only nodes from $V \setminus R$. In the latter case it contains at most $\frac32 \cdot \frac{m}{s_1}$ edges.
    \item For every node $v \in R$ with $|\Bout_G(v, r_1)| \leq \frac{m}{s_1}$, it holds that $|\Bout_{G[R]}(v, r_0)| \leq \frac{m}{s_0}$.
    \item None of the edges in $S$ has its source in $R$ (i.e., $S \subseteq (V \setminus R) \times V$). Moreover, for each edge $e = (x, y) \in E$ it holds that:
    \begin{equation*}
        \Pr(e \in S \mid x \not\in R) \leq \frac{w_e \ln(2s_0 / \delta)}{r_1 - r_0}.
    \end{equation*}
\end{enumerate}
With probability at most $\delta$ the algorithm instead returns ``fail'', and with probability at most~$\frac{1}{\poly(n)}$ the algorithm returns an arbitrary answer. The running time is~\smash{$\Order(m \log^4 n)$}.
\end{lemma}

\begin{proof}
Consider the pseudocode in \cref{alg:cut-light}. Throughout we maintain a set of cut edges~\makebox{$S \subseteq E$} that is initially empty. We classify nodes as \emph{good} or \emph{bad} depending on whether their out-balls~$\Bout(v, r_0)$ and~$\Bout(v, r_1)$ satisfy certain size requirements. Then, in several iterations the algorithm samples a good node $v$ and attempts to \emph{cut} around $v$ in the sense that we sample a radius~\smash{$r_0 \leq r \leq r_1$}, include the boundary edges $\delta^+(\Bout(v, r))$ into $S$, and then remove $\Bout(v, r)$ from the graph.

\begin{algorithm}[t]
\caption{Implements the cutting procedure from \cref{lem:cut-light}.} \label{alg:cut-light}
\begin{enumerate}[label=\arabic*.]
    \item Run Cohen's algorithm (\cref{lem:cohen} with parameter $\epsilon = \frac18$) on $G$ to compute approximations~$b_1(v)$ satisfying that $\tfrac78 \cdot |\Bout(v, r_1)| \leq b_1(v) \leq \tfrac98 \cdot |\Bout(v, r_1)|$. Mark all nodes $v$ satisfying that $b_1(v) \leq \frac98 \cdot \frac{m}{s_1}$ as \emph{good} and all other nodes as \emph{bad.}
    \item Repeat the following steps $\log n + 1$ times:
    \begin{enumerate}[label=2.\arabic*.]
        \item Repeat the following steps $s_0 \cdot 100 \log n$ times:
        \begin{enumerate}[label=2.1.\arabic*.]
            \item Among the nodes that are marked good, pick a uniformly random node $v$.
            \item Test whether $|\Bout(v, r_0)| \geq \frac{1}{2} \cdot \frac{m}{s_0}$, and otherwise continue with the next iteration of step (b).
            \item Sample $r \sim r_0 + \geom(p)$ (where~\smash{$p = \frac{\ln(2s_0 / \delta)}{r_1 - r_0}$}) and compute $B^+(v, r)$.
            \item If $r > r_1$, then return ``fail''.
            \item Update $S \gets S \cup \delta^+(B^+(v, r))$, mark the nodes in $B^+(v, r)$ as bad, and remove these nodes from $G$.
        \end{enumerate}
        \item Run Cohen's algorithm (\cref{lem:cohen} with parameter $\epsilon = \frac18$) on $G$ to compute approximations $b_0(v)$ satisfying that $\tfrac78 \cdot |\Bout(v, r_0)| \leq b_0(v) \leq \tfrac98 \cdot |\Bout(v, r_0)|$. Mark all nodes $v$ satisfying that $b_0(v) < \frac78 \cdot \frac{m}{s_0}$ as bad.
    \end{enumerate}
    \item Let $R$ denote the set of remaining nodes in $G$, and return $(S, R)$.
\end{enumerate}
\end{algorithm}

In the following we formally analyze \cref{alg:cut-light}. Throughout we often condition on the event that Cohen's algorithm is correct as this happens with high probability. (Note however that we cannot necessarily detect that Cohen's algorithm has erred, and thus the algorithm may return an arbitrary answer in this rare case.)

\paragraph{Correctness of (i).}
Note that whenever the algorithm cuts a ball $\Bout(v, r)$ from the graph~$G$ and adds the boundary edges $\delta^+(\Bout(v, r))$ to $S$, it makes sure that the nodes inside and outside~$\Bout(v, r)$ lie in different strongly connected components in $G \setminus S$. As $R$ is defined to be the left-over nodes that are never cut, and as we only cut around \emph{good} nodes $v$, it suffices to prove the following claim: With high probability, at any time during the execution of the algorithm it holds that $|\Bout_G(v, r_1)| \leq \frac32 \cdot \frac{m}{s_1}$ for all good nodes $v$.

To this end, observe that we only mark nodes as good in the first step, and in this step we only mark nodes as good when $b_1(v) \leq \frac98 \cdot \frac{m}{s_1}$. By the guarantee of \cref{lem:cohen}, we therefore initially have that
\begin{equation*}
    |\Bout_G(v, r_1)| \leq \frac98 \cdot b_1(v) \leq \frac{9^2}{8^2} \cdot \frac{m}{s_1} \leq \frac{3}{2} \cdot \frac{m}{s_1}.
\end{equation*}
Finally, as we only remove nodes and edges from $G$, the size of $|\Bout_G(v, r_1)|$ can only decrease throughout the remaining execution.

\paragraph{Correctness of (ii).}
In order to prove the correctness of (ii), we crucially rely on the following claim:

\begin{claim}
When the algorithm terminates (without returning ``fail''), with high probability all nodes are marked bad.
\end{claim}
\begin{proof}
The idea is to prove that with each iteration of step 2 the number of good nodes halves. As the algorithm runs $\log n + 1$ iterations of step 2, the claim then follows.

Focus on any iteration of step 2. Let $M_0$ denote the initial set of good nodes, let $M_1, \dots, M_k$ denote the subsets of nodes that are still marked good after the respective $k = s_0 \cdot 100 \log n$ iterations of step~2.1, and let $M^*$ denote the good nodes after executing step~2.2. We clearly have that~\makebox{$M_0 \supseteq M_1 \supseteq \dots \supseteq M_k \supseteq M^*$}. Our goal is to show that $|M^*| \leq \frac12 \cdot |M_0|$. The claim is clear if~\makebox{$|M_k| \leq \frac12 \cdot |M_0|$}, so assume otherwise. We argue that after completing step~2.1, with high probability at least half of the nodes $v \in M_k$ satisfy that $|\Bout_G(v, r_0)| < \tfrac12 \cdot \tfrac{m}{s_0}$. This implies the claim as then we will mark at least half of the nodes in $M_k$ as bad while executing step 2.2. To prove this, suppose that instead more than half of the nodes $v \in M_k$ satisfy that~\smash{$|\Bout_G(v, r_0)| \geq \tfrac12 \cdot \tfrac{m}{s_0}$}. In particular, there are least $\frac{|M_k|}{2} \geq \frac{|M_0|}{4}$ such nodes. But this means that every iteration of step 2.1 \emph{succeeds} (in the sense that the algorithm samples a node $v$ passing the condition in 2.1.2) with probability at least $\frac14$. As there are $k = s_0 \cdot 100 \log n$ repetitions, with high probability at least, say,~$10 s_0$ repetitions succeed. However, every time this happens the algorithm either removes at least $\frac12 \cdot \frac{m}{s_0}$ edges from the graph or fails and stops. Thus, the total number of repetitions can be at most $2 s_0$, leading to a contradiction.
\end{proof}

With this claim in mind, we return to the correctness of Property (ii). Each node $v \in R$ has been classified as bad at some point during the execution. This could have happened in step 1 (if~\makebox{$b_1(v) > \frac98 \cdot \frac{m}{s_1}$}), or in step 2.2 (if $b_0 < \frac78 \cdot \frac{m}{s_0}$), but not in step 2.1.5 as otherwise $v$ would not have ended up in $R$. Conditioning on the correctness of Cohen's algorithm, in the former case we have that
\begin{equation*}
    |\Bout_G(v, r_1)| \geq \frac89 \cdot b_1(v) > \frac89 \cdot \frac98 \cdot \frac{m}{s_1} = \frac{m}{s_1} 
\end{equation*}
(where $G$ is the initial graph). In the latter case we have that
\begin{equation*}
    |\Bout_G(v, r_0)| \leq \frac87 \cdot b_0(v) < \frac87 \cdot \frac78 \cdot \frac{m}{s_0} = \frac{m}{s_0}
\end{equation*}
(where $G$ is the current graph), and thus also~\smash{$|\Bout_{G[R]}(v, r_0)| < \frac{m}{s_0}$} for the set $R$ returned by the algorithm. The statement~(ii) follows.

\paragraph{Correctness of (iii).}
It is clear that the source nodes of all cut edges in $S$ cannot be in~$R$. Let $e = (x, y) \in E$ denote an arbitrary edge; we show that the probability~\makebox{$\Pr(e \in S \mid x \not\in R)$} is as claimed. Note that we can only have~\makebox{$x \not\in R$} if there is some iteration of step 2 that selects a node~$v$ and samples radius $r \sim r_0 + \geom(p)$ such that~\makebox{$x \in \Bout(v, r)$}. In this iteration we might include~$e$ into $S$ if it happens that~\makebox{$e \in \delta^+(\Bout(v, r))$}. After this iteration, however, we remove the edge~$e$ from the graph and the algorithm will never attempt to include $e$ into $S$ later on. Therefore, we can upper bound the desired probability by
\begin{flalign*}
    &\Pr(e \in S \mid x \not\in R) \\
    &\qquad\qquad\leq \max_{G, v} \Pr_{r \sim r_0 + \geom(p)}(e \in \delta^+_G(\Bout_G(v, r)) \mid x \in \Bout_G(v, r)) \\
    &\qquad\qquad= \max_{G, v} \Pr_{r \sim \geom(p)}(d_G(v, y) > r_0 + r \mid d_G(v, x) \leq r_0 + r) \\
    &\qquad\qquad \leq \max_{G, v} \Pr_{r \sim \geom(p)}(d_G(v, x) + w_e > r_0 + r \mid d_G(v, x) \leq r_0 + r)
\intertext{We will now exploit the memorylessness of the geometric distribution: Conditioning on the event that $r \geq d_G(v, x) - r_0$, the random variable $r - (d_G(v, x) - r_0)$ behaves like a geometric random variable from the same original distribution (assuming that $d_G(v, x) - r_0 \geq 0$; otherwise we can simply drop the condition). Therefore:}
    &\qquad\qquad \leq \Pr_{r \sim \geom(p)}(r < w_e) \\
    &\qquad\qquad \leq p \cdot w_e.
\end{flalign*}
Recall that~\smash{$p = \frac{\ln(2s_0 / \delta)}{r_1 - r_0}$}, so the correctness follows.

\paragraph{Failure Probability.}
Next, we analyze that the algorithm returns ``fail''. Recall that this only happens if in steps 2.1.3 and 2.1.4 we sample a radius $r \sim r_0 + \geom(p)$ that satisfies~$r > r_1$. This event happens with probability
\begin{align*}
    \Pr_{r \sim r_0 + \geom(p)}(r > r_1) &= \Pr_{r \sim \geom(p)}(r > r_1 - r_0) \\
    &\leq (1 - p)^{r_1 - r_0} \\
    &\leq \exp(-p(r_1 - r_0)) \\
    &= \exp(-\ln(2s_0) / \delta) \\
    &= \frac{\delta}{2s_0}.
\end{align*}
Whenever the algorithm does not return ``fail'' in step 2.1.4, we are guaranteed to remove at least~$\frac{1}{2} \cdot \frac{m}{s_0}$ edges from the graph $G$ in step~2.1.5. In particular, there can be at most $2s_0$ repetitions of step~2.1.5 and thus at most trials of step 2.1.4. By a union bound it follows that the algorithm indeed returns ``fail'' with probability at most $\delta$.

\paragraph{Running Time.}
Finally, we analyze the running time. We run \cref{lem:cohen} once in step~1, and $\Order(\log n)$ times in step 2.2. Each call runs in time $\Order(m \log^3 n)$, so the total time spent for \cref{lem:cohen} is~$\Order(m \log^4 n)$. There are $\Order(s_0 \log^2 n)$ iterations of step 2.1. In each iteration, we spend time $\Order(1)$ for steps 2.1.1 and 2.1.4. For step 2.1.2 we spend time $\Order(\frac{m}{s_0} \log n)$---indeed, we can test whether~\smash{$|\Bout(v, r_0)| \geq \frac{1}{2} \cdot \frac{m}{s_0}$} by Dijkstra's algorithm, and if the time budget is exceeded it is clear that the bound holds. In steps 2.1.3 and 2.1.5 we spend time proportional to the size of $\Bout(v, r)$, but since we remove the nodes and edges in $\Bout(v, r)$ from $G$ afterwards in total we spend only time $\Order(m \log n)$ in these steps. Therefore, the total running time spend in step~2.1 is~\smash{$\Order(s_0 \log^2 n \cdot \frac{m}{s_0} \log n + m \log n) = \Order(m \log^3 n)$}.
\end{proof}

\subsection{Near-Linear-Time LDD} \label{sec:ldd-fast:sec:algo}
We are ready to state the LDD algorithm. Throughout this section, we fix the following parameters:
\begin{itemize}
    \item $L = \ceil{\log\log m} + 1$,
    \item \smash{$\delta = \frac{1}{\log^{10} m}$},
    \item $r_0 := 0$ and \smash{$r_\ell := r_{\ell-1} + \frac{D}{2^{L-\ell+3}} + \frac{D}{4 L}$} (for $1 \leq \ell \leq L$),
    \item \smash{$s_\ell := \min(2^{2^{L-\ell}}, m+1)$} (for $0 \leq \ell \leq L$).
\end{itemize}
With these parameters in mind, consider \cref{alg:ldd-fast}. The algorithm first deletes all edges with sufficiently large weight. Then it proceeds in $L$ iterations where in each iteration we apply \cref{lem:cut-light} to cut some edges in the graph (or reverse graph). If any of these calls returns ``fail'', then the entire algorithm restarts. In the following \cref{lem:ldd-fast-correctness,lem:ldd-fast-prob,lem:ldd-fast-time} we will show that this procedure correctly implements the algorithm claimed in \cref{thm:main-fast}.

\begin{algorithm}[t]
\caption{The near-linear-time near-optimal LDD, see \cref{thm:main-fast}.} \label{alg:ldd-fast}
\begin{enumerate}
    \item Initially let $S \subseteq E$ be the set of edges of weight at least $\frac{D}{4L}$, and remove these edges from $G$
    \item For $\ell \gets L, \dots, 1$:
    \begin{enumerate}
        \item[2.1.] Run \cref{lem:cut-light} on $G$ with parameters $\delta, r_{\ell-1}, r_\ell, s_{\ell-1}, s_{\ell}$, and let $S^+_\ell, R^+_\ell$ denote the resulting sets.
        \item[2.2.] Compute the strongly connected components in $(G \setminus S^+_\ell)[V \setminus R^+_\ell]$. Recur on each such component and add the recursively computed cut edges to $S$.
        \item[2.3.] Update $G \gets G[R^+_\ell]$ and $S \gets S \cup S^+_\ell$.
        \item[2.4.] Run \cref{lem:cut-light} on $\rev(G)$ with parameters $\delta, r_{\ell-1}, r_\ell, s_{\ell-1}, s_{\ell}$, and let $S^-_\ell, R^-_\ell$ denote the resulting sets.
        \item[2.5.] Compute the strongly connected components in $(G \setminus S^-_\ell)[V \setminus R^-_\ell]$. Recur on each such component and add the recursively computed cut edges to $S$.
        \item[2.6.] Update $G \gets G[R^-_\ell]$ and $S \gets S \cup S^-_\ell$.
    \end{enumerate}
    \item If any of the $2L$ previous calls to \cref{lem:cut-light} returns ``fail'', then we restart the entire algorithm (i.e., we reset $G$ to be the given graph, we reset $S \gets \emptyset$, and we start the execution from step~1).
\end{enumerate}
\end{algorithm}

\begin{lemma}[Correctness of \cref{alg:ldd-fast}] \label{lem:ldd-fast-correctness}
Let $u, v$ be two nodes lying in the same strongly connected component in $G \setminus S$. Then $d_G(u, v) \leq D$.
\end{lemma}
\begin{proof}
For clarity, let us denote the original (given) graph $G$ by $G_0$, and let $G$ denote the graph that is being manipulated by the algorithm. We prove the claim by induction. In the base case (when the graph has constant size) the statement can easily be enforced, so focus on the inductive case. Let $u, v$ be two arbitrary nodes.

For any iteration $\ell$, by \cref{lem:cut-light}~(i) it is clear that if $u \in R^+_\ell$ and $v \not\in R^+_\ell$ (or similarly for~$R^-_\ell$), then $u$ and $v$ cannot end up in the same strongly connected component in $G \setminus S$. If both $u, v \not\in R^+_\ell$ (or similarly for $R^-_\ell$) then the claim follows by induction since we recur on $(G \setminus S^+_\ell)[V \setminus R^+_\ell]$. This leaves as the only remaining case that $u, v \in R^+_\ell$. In particular, after completing all $L$ iterations, the only nodes left to consider are the nodes that are still contained in $G$ when the algorithm terminates. Let us call a node $v$ \emph{heavy} if
\begin{equation*}
    |\Bout_{G_0}(v, \tfrac D2)| \geq \frac{m}{2} \qquad\text{and}\qquad |\Bin_{G_0}(v, \tfrac D2)| \geq \frac{m}{2}.
\end{equation*}
In the following paragraph we prove that the only nodes $v$ remaining in $G$ are either (i) heavy or (ii) have no out- or no in-neighbors. In case (ii) clearly $v$ forms a strongly connected component in~$G \setminus S$ on its own. For (i), we claim that for any pair $u, v$ of heavy nodes it holds that $d_{G_0}(u, v) \leq D$---indeed, the out-ball~\smash{$\Bout_{G_0}(u, \frac D2)$} and the in-ball~\smash{$\Bin_{G_0}(v, \frac D2)$} necessarily intersect. It similarly holds that $d_{G_0}(v, u) \leq D$.

To prove the missing claim, let $v$ be a non-heavy node; we show that if $v$ remains in the graph~$G$ then it has no out- or no in-neighbors. By induction we show that
\begin{equation*}
    |\Bout_G(v, r_\ell)| \leq \frac{m}{s_\ell} \qquad\text{or}\qquad |\Bin_G(v, r_\ell)| \leq \frac{m}{s_\ell}.
\end{equation*}
Initially, for $\ell = L$, this is clearly true using that $v$ is not heavy, that $s_L = 2$, and that
\begin{equation*}
    r_L = \sum_{\ell=1}^L \parens*{\frac{D}{2^{L-\ell+3}} + \frac{D}{4L}} \leq \frac{D}{8} \cdot \sum_{k=0}^\infty \frac{1}{2^k} + \frac{D}{4} = \frac{D}{4} + \frac{D}{4} = \frac{D}{2}.
\end{equation*}
So now assume inductively that the claim holds for some $\ell \leq L$. Then \cref{lem:cut-light}~(ii) guarantees that
\begin{equation*}
    |\Bout_{G[R^+_\ell]}(v, r_{\ell-1})| \leq \frac{m}{s_{\ell-1}} \qquad\text{or}\qquad |\Bin_{G[R^-_\ell]}(v, r_{\ell-1})| \leq \frac{m}{s_{\ell-1}}.
\end{equation*}
Since we update $G \gets G[R^+_\ell]$ and $G \gets G[R^-_\ell]$, this is exactly as desired. In iteration $\ell = 1$ we thus have that 
\begin{equation*}
    |\Bout_G(v, r_1)| \leq \frac{m}{s_1} < 1 \qquad\text{or}\qquad |\Bin_G(v, r_1)| \leq \frac{m}{s_1} < 1,
\end{equation*}
that is, $v$ has no outgoing or incoming edges of weight less than $r_1$. Recall that initially we remove all edges of weight larger than $\frac{D}{4L} \leq r_1$, and therefore $v$ truly has no outgoing or incoming edges. This completes the proof.
\end{proof}

\begin{lemma}[Edge Cutting Probability of \cref{alg:ldd-fast}] \label{lem:ldd-fast-prob}
For any edge $e \in E$, we have
\begin{equation*}
    \Pr(e \in S) \leq \Order\parens*{\frac{w_e}{D} \cdot \log n \log\log n + \frac{1}{\poly(n)}}.
\end{equation*}
\end{lemma}
\begin{proof}
Let $e = (x, y) \in E$ be an arbitrary edge. The algorithm certainly cuts $e$ if it has weight at least $\frac{D}{4L}$, but in this case the right-hand side exceeds $1$. Otherwise, it only cuts edges via \cref{lem:cut-light} or via recursive calls. Since \cref{lem:cut-light} never cuts edges whose source lies in the returned set~$R$, each edge becomes relevant only in the first iteration $\ell$ when $x \in R_\ell^+$, or~$x \not\in R_\ell^+$ and~\makebox{$x \in R_\ell^-$}. Let us focus on the former case; the latter is analogous. Conditioning on the event that $x \in R_\ell^+$, the edge~$e$ can be cut in three ways:
\begin{enumerate}
    \item $e$ is cut by the call to \cref{lem:cut-light} (i.e., $e \in S^+_\ell$),
    \item $e$ is cut in the recursive call, or
    \item the algorithm fails and cuts $e$ during the restart.
\end{enumerate}
In particular, note that the edge cannot be cut in later iterations $\ell' < \ell$, as then we have already removed $x$ from the current graph $G$.

The probability of the first event is at most as follows, using \cref{lem:cut-light}~(iii):
\begin{align*}
    \Pr(e \in S^+_\ell \mid x \not\in R^+_\ell)
    &\leq \frac{w_e \ln(2s_{\ell-1} / \delta)}{r_\ell - r_{\ell-1}} \\
    &\leq \frac{w_e \ln(2^{2^{L - \ell + 1}} \cdot (\log m)^{10})}{\frac{D}{2^{L-\ell+3}} + \frac{D}{4L}} \\
    &\leq \frac{w_e}{D} \cdot \frac{2^{L - \ell + 1} + 10L}{\max\set*{\frac{1}{2^{L-\ell+3}}, \frac{1}{4L}}} \\
    &\leq \frac{w_e}{D} \cdot (2^{L-\ell+3} + 10L) \cdot \min\set*{2^{L-\ell+3}, 10L} \\
    &\leq \frac{w_e}{D} \cdot 2^{L-\ell} \cdot 160L.
\end{align*}
In the last step we used that $(a + b) \min\set{a, b} \leq 2 \max\set{a, b} \min\set{a, b} = 2ab$.

To analyze the events 2 and 3, let us write $p(m) = \Pr(e \in S)$ (where $m$ is the number of edges in the input). Note that each recursive call in the $\ell$-th iteration is on a graph with at most~\smash{$\frac{3}{2} \cdot \frac{m}{s_\ell} \leq \frac32 \cdot \frac{m}{2^{2^{L-\ell}}}$} edges by \cref{lem:cut-light}~(i). Therefore, the probability of event 2 is at most~\smash{$p(\frac32 \cdot \frac{m}{2^{2^{L-\ell}}})$}.

Next, focus on event 3. Each call to \cref{lem:cut-light} returns ``fail'' with probability at most~$\delta$, and by a union bound over the at most $2L$ calls the algorithm restarts with probability at most $2L\delta$. If the algorithm restarts, then clearly its randomness is independent of the previous iterations and thus it cuts $e$ with probability $p(m)$. Hence, the probability of the event 3 is at most $p(m) \cdot 2L\delta$.

By a union bound over these three probabilities we obtain that
\begin{flalign*}
    p(m) &\leq \max_\ell \parens*{\frac{w_e}{D} \cdot 2^{L-\ell} \cdot 160L + p\parens*{\frac32 \cdot \frac{m}{2^{2^{L-\ell}}}} + p(m) \cdot 2L \delta},
\end{flalign*}
or equivalently,
\begin{flalign*}
    p(m) &\leq \frac{1}{1 - 2L\delta} \cdot \max_\ell \parens*{\frac{w_e}{D} \cdot 2^{L-\ell} \cdot 160L + p\parens*{\frac32 \cdot \frac{m}{2^{2^{L-\ell}}}}} \\
    &\leq \parens*{1 + 4L\delta} \cdot \max_\ell \parens*{\frac{w_e}{D} \cdot 2^{L-\ell} \cdot 160L + p\parens*{\frac32 \cdot \frac{m}{2^{2^{L-\ell}}}}}.
\end{flalign*}
This recurrence solves to
\begin{flalign*}
    p(m) &\leq (1 + 4L\delta)^{\log_{4/3}(m)} \cdot \frac{w_e}{D} \cdot 320L \cdot \log m,
\end{flalign*}
as can easily be verified as follows; here we will bound~\smash{$\frac32 \cdot \frac{m}{2^{2^{L-\ell}}}$} on the one hand by $\leq \frac34 m$ and on the other hand by~\smash{$\leq \frac{m}{2^{2^{L-\ell-1}}}$}:
\begin{flalign*}
    p(m) &\leq \parens*{1 + 4L\delta} \cdot \max_\ell \parens*{\frac{w_e}{D} \cdot 2^{L-\ell} \cdot 160L + p\parens*{\frac32 \cdot \frac{m}{2^{2^{L-\ell}}}}} \\
    &\leq \parens*{1 + 4L\delta} \cdot \max_\ell \parens*{\frac{w_e}{D} \cdot 2^{L-\ell} \cdot 160L + (1 + 4L\delta)^{\log_{4/3}(m)-1} \cdot \frac{w_e}{D} \cdot 320L \cdot \log \frac{m}{2^{2^{L-\ell-1}}}} \\
    &\leq \parens*{1 + 4L\delta}^{\log_{4/3}(m)} \cdot \max_\ell \parens*{\frac{w_e}{D} \cdot 2^{L-\ell} \cdot 160L + \frac{w_e}{D} \cdot 320L \cdot \parens*{\log m - 2^{L-\ell-1}}} \vphantom{\parens*{\frac{m}{2^{2^{L-\ell-1}}}}} \\
    &= \parens*{1 + 4L\delta}^{\log_{4/3}(m)} \cdot \frac{w_e}{D} \cdot 320L \cdot \log m. \vphantom{\parens*{\frac{m}{2^{2^{L-\ell-1}}}}}
\end{flalign*}
Finally, we plug in the chosen values for $L \leq \Order(\log\log m)$ and $\delta = (\log m)^{-10}$ to obtain that
\begin{align*}
    p(m) &\leq \parens*{1 + \frac{\Order(\log\log m)}{(\log m)^{10}}}^{\log_{4/3}(m)} \cdot \Order\parens*{\frac{w_e}{D} \cdot \log m \log\log m} \\
    &\leq \exp\parens*{\frac{\Order(\log\log m)}{(\log m)^{10}} \cdot \log_{4/3}(m)} \cdot \Order\parens*{\frac{w_e}{D} \cdot \log m \log\log m} \\
    &\leq \Order\parens*{\frac{w_e}{D} \cdot \log m \log\log m},
\end{align*}
as claimed. A final detail is that all previous bounds condition on the high-probability event that none of the calls to \cref{lem:cut-light} returns an invalid answer (but not ``fail''). To take this into account, the edge cutting probability increases additively by $\frac{1}{\poly(n)}$ (for an arbitrarily large polynomial).
\end{proof}

\begin{lemma}[Running Time of \cref{alg:ldd-fast}] \label{lem:ldd-fast-time}
The expected running time is $\Order(m \log^5 n \log\log n)$.
\end{lemma}
\begin{proof}
Ignoring the cost of recursive calls, one execution of \cref{alg:ldd-fast} involves $\Order(L)$ calls to \cref{lem:cut-light} each of which runs in time $\Order(m \log^4 n)$. (The additional computations such as computing strongly connected components runs in linear time.) To take the recursive calls and restarts into account, let~$T(m)$ denote the running time given $m$ edges. We recurse on subgraphs with, say,~$m_1, \dots, m_r$ edges where $m_i \leq \frac34 m$ and $\sum_{i=1}^r m_i \leq m$. Moreover, the probability that the algorithm restarts is at most $2L \delta \leq (\log m)^{-9}$. Thus, we can bound
\begin{equation*}
    T(m) = \sum_{i=1}^r T(m_i) + 2L\delta T(m) + \Order(m \log^4 n \log\log n),
\end{equation*}
which, similarly to the analysis in \cref{lem:ldd-fast-prob}, can be solved to $T(m) \leq \Order(m \log^5 n \log\log n)$.
\end{proof}

We remark that we have not attempted to optimize the log-factors in the running time here and it is likely that the overhead can be reduced. An obvious improvement to shave one log-factor from the running time is to employ a faster priority queue in Dijkstra's algorithm, e.g.\ as developed by Thorup~\cite{Thorup03}.