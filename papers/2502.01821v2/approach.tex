\section{Approaches}
\label{sec:approach}

\begin{figure*}[htbp] %
  \centering

  \begin{subfigure}[b]{\textwidth}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/LIBRO_approach.pdf}
    \caption{\libro Adaptation: The input comprises the bug report (\gits issue) accompanied by the list of buggy files and the relevant test file. \libro  prompts the \codeeditingllm to generates a candidate \brt\Space{ for the given issue}.}
    \label{fig:libro}
  \end{subfigure}

  \vspace{1em} %

  \begin{subfigure}[b]{\textwidth}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/BRT_Agent_approach.pdf}
    \caption{BRT Agent (Ours): Given the bug report (GITS issue) and buggy file content as initial input, our \llm-agent-based approach leverages a set of actions, including code editing via the \codeeditingllm, to generate a candidate BRT.}
    \label{fig:brtagent}
  \end{subfigure}

  \caption{Bug Reproduction Test (BRT) generation techniques explored in our work.}
  \label{fig:main_figure}
\end{figure*}


In this section, we first describe our adaptation of \libro to Google's internal development environment.
We then detail the design and implementation of our agent-based approach for \brt generation, which we will refer to as \textbf{\tool}.
Figure~\ref{fig:main_figure} illustrates both our adaptation of \libro (\ref{fig:libro}) and \tool (\ref{fig:brtagent}).\Comment{This section details the design and implementation of our approach for automated BRT generation within Google's internal infrastructure. 
We first describe our adaptation of the baseline technique, LIBRO, to function effectively in this unique environment. 
Subsequently, we introduce our enhanced BRT agent, designed to overcome the limitations of existing methods by leveraging a fine-tuned LLM for code editing.}



\subsection{Adaptation of \libro}
\label{sec:approach:libro}



\libro was originally built on open-source projects. 
We make changes to \libro's \llm, input data, and prompt to make it compatible with \google's internal development environment.

\myparagraph{\llm}
We replaced the open-source \llm that \libro uses with a Gemini model fine-tuned on \google's internal code. 
This \llm is exposed to the specific coding styles, libraries, and patterns prevalent within \google's codebase, and can improve \libro's ability to generate relevant and syntactically correct code. 
Note that we also use this fine-tuned \gemini model as the \codeeditingllm for our agent-based \brt generation approach (\S\ref{sec:approach:agent}). 

\myparagraph{Input Data}
\libro finds a relevant test file to inject a \brt into and resolves dependencies after the \brt has been generated (\S\ref{sec:relatedwork:brt:libro}). 
We find this workflow error-prone and impractical within \google's complex and interconnected codebase. 
Thus, we adapt \libro to accept a pre-identified test file as input, which can provide useful test code context (e.g., libraries and attributes used by existing tests) to the \llm, to generate a more robust and relevant \brt.\Comment{substantially simplifies the generation process and ensures that the generated \brt is compatible with existing testing infrastructure.} 
In practice, the input test file(s) will be identified as the test file most related to the buggy file(s), e.g., via code search or coverage analysis.


\myparagraph{Prompt}
We carefully crafted the input prompt for the internal \llm used by our adapted \libro through small-scale experiments on different prompt structures, paraphrases, and input.
The final prompt includes the bug report description, buggy file content, and a pre-identified test file.
\Comment{commented out because original \libro has this too. \textbf{Multiple Sample Generation}: We modified LIBRO to enable it to generate multiple sample BRTs by calling the LLM multiple times, using a non-zero temperature. This allows us to explore the diversity of generated tests and potentially identify more effective BRTs.}





\subsection{Our Approach: \tool}
\label{sec:approach:agent}

Recent research on \llm agents for \autopr have shown promising results~\cite{zhang2024autocoderover,yang2024swe,chen2024coder,hou2024large,rondon2025passerine}\Space{, and is actively investigated in industrial settings~\cite{rondon2025passerine,OTHER_STUDIES}}, while \llm agents for \brt generation remained rather under-explored.
Moreover,\Space{ in our experience,} we find that state-of-the-art technique using standalone \llm, i.e., \libro, faces performance challenges\Space{ on large-scale, proprietary codebase} even after adaptation (\S\ref{sec:results}).
Thusly motivated, we develop an agent-based approach for \brt generation: \tool.\Space{\tool iteratively improves the generated \brt via reasoning and performing actions according to its observed environments \react~\cite{yao2022react,yang2024swe}.}
We now describe \tool's workflow and components.


\subsubsection{Initialization}

\tool receives a bug report and identified buggy file content\Comment{\sam{no test file}, and the path to the chosen test file} as initial input.\Comment{we should mention it in experiment setup instead \textit{In our evaluation, an oracle provides the buggy code files and test file path. In practice, a user may provide this information.}} These files can be provided by users or upstream fault localization services~\cite{wong2016survey,kang2023preliminary,yang2024large,qin2024agentfl}.

\subsubsection{Reasoning}
\label{sec:approach:agent:reasoning}
A \gemini model serves as the primary reasoning \llm, responsible for understanding the bug report, planning overall execution of the \brt generation task, and making decisions about which action to take in each \react step~\cite{yao2022react}.
At each step, it analyzes the current agent state, which includes the bug report, the displayed code context, and the history of past actions and observations, to eventually determine the next action.

\subsubsection{Action Selection and Execution}
\label{sec:approach:agent:action}


\input{tables/actions}

Table~\ref{tab:actions} shows a list of possible actions \tool can select and execute. For action \actioncat, \actioncodesearch, \actiontest, and \actionfinish, the agent executes the action directly.
For action \actionedit, the agent initiates a specialized code editing process that will be handled by a \codeeditingllm. Specifically:

\myparagraph{Change Description}
As part of the \actionedit action invocation, \tool, via its reasoning \llm, generates a natural language description of the desired code change to a test file the agent specifies.
The agent often chooses a test file from results of \actioncodesearch action(s) from prior steps (\S\ref{sec:results:brt:behave}). 
The description captures the intent of the edit; one example description can be: ``Add a test case that asserts the function returns \CodeIn{null} when given an empty input.''

\myparagraph{Prompt Construction}
The action \actionedit constructs a prompt for the \codeeditingllm, which includes (1) the bug report description; (2) the content of the specified test file; and (3) a clear task description composed of two parts: a \textit{meta} task description fixed to ``Write a bug reproduction test for the following bug report.'', and a \textit{step-specific} change description, which describes the desired change in natural language, generated by the reasoning \llm for this \actionedit invocation.


\myparagraph{Code Generation}
The \codeeditingllm receives the prompt and generates a code patch that implements the described change. 
The generated patch will then be applied to the specified test file.

The \codeeditingllm, given it is fine-tuned on \google's internal codebase, offers the following key advantages. 
First, by being exposed to a vast amount of internal code, the \codeeditingllm possesses a deep understanding of the nuances and context specific to the production environment, making it more effective in understanding and thus reproducing a bug.
Second, the \codeeditingllm can generate code that seamlessly integrates with \google's production infrastructure while adhering internal coding standards, ensuring the generated test to be functional and align with established best practices and conventions.
Employing the \codeeditingllm can thus improve the agent's ability to generate syntactically- and semantically-correct \brt{}s.

Moreover, this design of combining generic \llm (which demonstrated reasoning proficiency) with fine-tuned \codeeditingllm could be generally applicable and efficient to cases where the software engineering agent is deployed to a codebase with new APIs and conventions outside the generic \llm's training distribution.

Note that the \codeeditingllm's training data excludes all bugs, code changes, and \brt{}s used in our empirical evaluation (\S\ref{sec:empiricalstudy})---its training data cutoff predates the reporting of all bugs analyzed in this study, preventing any potential data leakage.



\subsubsection{Observation}
\label{sec:approach:agent:observe}
\tool observes the result of its previous executed action. 
Action \actiontest produces one of these test results, accompanied with test logs: 
    \begin{itemize}
        \item \textbf{Pass}: All specified tests executed successfully and passed.
        \item \textbf{Fail}: All specified tests executed but at least one test failed, indicating a potential bug reproduction.
        \item \textbf{Broken/Error}: The specified tests could not be executed successfully due to compilation errors, runtime errors before test execution, or other issues in the setup. This state often signifies that the code edits require further refinement.
    \end{itemize}


\subsubsection{Iteration}
\label{sec:approach:agent:iterate}
The agent repetitively attempts \S\ref{sec:approach:agent:reasoning}-\ref{sec:approach:agent:observe} until it finishes (see Table~\ref{tab:actions}) or exhausts the total number of allowed steps.

\subsubsection{Termination}
\label{sec:approach:agent:terminate}
\tool terminates gracefully by invoking the action \actionfinish, or reaching the total step limit. 
The final output will be the generated test code, if any, within a test file.





































