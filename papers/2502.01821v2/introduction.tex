\section{Introduction}
\label{sec:intro}
Bug reproduction is a critical part of the software debugging process~\cite{chaparro2019assessing,kang2023large,koyuncu2019ifixr,Ernst2014Defects4J,le2012systematic,xiong2017precise,li2019deepfl,yang2024swe}.
\Space{To enable effective and efficient debugging and repairing, b}The bug reproduction steps of a reported bug can often be encapsulated into test(s), which automatically reproduce the bug by demonstrating test failure(s).
Such a test is referred to as a \brtfull (\brt).
More formally, a \brt\Space{ is a test case\samcheng{do we use both 'test case' and 'test' in the paper? if not, can just call test.}} should (1) fail in the presence of the bug, demonstrating the faulty behavior; and (2) pass once the bug has been resolved, confirming the effectiveness of the applied fix patch.
For both human users and \autoprfull (\autopr) systems, \brt{}s can offer insights on the root cause of the bug~\cite{ko2008debugging,kang2023large,nayrolles2015jcharming,just2018comparing}, \Space{plays a crucial role in guiding}guide the development of a fix patch~\cite{rondon2025passerine,yang2024swe,mundler2024swt}, and is essential for validating the effectiveness of the proposed fix patch~\cite{ko2008debugging,Ernst2014Defects4J,saha2017elixir,le2012systematic}.



However, despite their importance, \brt{}s are often absent\Space{ from bug reports} when the debugging or repairing process starts.
Bug reports from human users/developers, written in natural language, are often vague, ambiguous, and lacking crucial details for reproducing and subsequently addressing the reported software defects~\cite{bettenburg2008duplicate,zimmermann2009cross,anvik2006should}.
Studies show that bug reports in open-source projects often do not have \brt{}s, e.g., \citet{koyuncu2019ifixr} found that only 4\% of the bug reports in \defectsfj~\cite{Ernst2014Defects4J} include a \brt; \citet{kang2023large} found that 28\% of the tests among the 300 most-starred \github projects are added due to bug reports;
more recently, \citet{mundler2024swt} found that there are no corresponding \brt{}s for bug-reporting pull requests prior to the creation of those pull requests in \swebench projects.


In industrial setting, similarly, \brt{}s are commonly expected to be developed \textit{alongside} the fix patch, after the bug is reported.
Through our exploration of \brt creation and \brt availability in \google's internal issue tracking system\Space{ (\gits)}, we observed that \brt development can be deferred to fix development stage because developers often do not prioritize the task of, or possess enough information of, developing a \brt at the time of bug reporting (\S\ref{sec:motivation}).
For example, developers may not attend to \brt development when actively dealing with issues reported by production monitoring.
Moreover, developing a \brt requires knowledge of the bug's root cause, and effort to craft a precise, bug-reproducing test failure~\cite{grottke2007fighting,just2018comparing,beller2018dichotomy}, which may not be available\Space{ immediately} as soon as the bug is reported. 

In this paper, we tackle the challenge of automated \brt generation in an industrial\Space{ production} environment, specifically at \google.
Automated \brt generation facilitates \brt development at scale, which could provide crucial benefits to industrial settings where a large number of bug reports are handled per day.

To develop automated \brt generation for \google's\Space{ internal} development environment, we first make nontrivial effort to adapt a state-of-the-art \llm-based approach, \libro~\cite{kang2023large} (\S\ref{sec:approach:libro}).
After finding limitations from the adapted \libro, we developed our \llm-agent-based approach for \brt generation, \tool (\S\ref{sec:approach:agent})\Space{, independently and concurrently to a recently proposed \llm-based \brt generation agent~\cite{mundler2024swt} (\S\ref{sec:relatedwork:compare})}.
Our approach, \tool, goes beyond being a straightforward adaptation of the existing\Space{ open-source} \llm-agent-based \autopr systems into \brt generation task via \llm prompt engineering (\S\ref{sec:relatedwork}).
Specifically, we introduce and focus on agent components that overcome challenges unique to our industrial context. 
For example, to address the challenge of generating proprietary code with idiosyncratic APIs and coding practices, \tool incorporates a specialized \codeeditingllm fine-tuned on \google's codebase, to generate high-quality test code (\S\ref{sec:approach:agent:action}).
We implemented both \libro and our \tool to work with \google's development infrastructure, and evaluate them on a set of 80 production bugs reported and fixed by human developers from a wide array of \google projects~\cite{rondon2025passerine} (\S\ref{sec:empiricalstudy:datasetandconfig}).

Moreover, while prior work focuses on evaluating the performance of \brt generation techniques in isolation (\S\ref{sec:relatedwork}), we further investigate the practical impact of the generated \brt{}s for\Space{ the end-to-end performance of automated} bug-fixing.
Given \brt{}s can provide additional context for understanding the bug, we study how generated \brt{}s can improve the performance of \passerine~\cite{rondon2025passerine}, an industrial-scale \autopr system at \google, to generate plausible fixes for more bugs more efficiently. 
Given\Space{ recent} \autopr systems can generate many fixes per bug and \brt{}s can help validate a fix through Fail-to-Pass behavior (\S\ref{sec:motivation}), we explore whether generated \brt{}s can be used to effectively indicate the plausible fixes from all fixes generated by \passerine\Space{, for bugs where no existing tests had failed}. 
To this aim, we propose a novel metric, \enpassratefull (\enpassrate), which evaluates each generated fix by calculating its pass rate over a suite of generated \brt{}s, to select promising fixes from \autopr systems. 

This paper makes the following key contributions:
\begin{itemize}
    \item We adapt state-of-the-art approach, \libro, and develop our \llm-agent-based approach for \brt generation, \tool, in \google's environment (\S\ref{sec:approach}).
    \tool substantially outperforms \libro by generating plausible \brt{}s on 28\% of the evaluated \google production bugs across six programming languages, compared to that of 10\% by \libro.
    Our manual inspection find that 67\% of the plausible \brt{}s generated by \tool are semantically equivalent or identical to the oracle \brt in the ground truth fixes; we also provide insights to the agent behaviors during \brt generation (\S\ref{sec:results:brt}).
    \item We assess the practical impact of generated plausible \brt{}s on improving \passerine's fix generation performance.
    When generated \brt{}s are provided as part of the bug report, \passerine fixes 30\% more bugs, and fewer agent steps were taken to generate a fix (\S\ref{sec:results:generation}).
    \item We propose \enpassratefull (\enpassrate), a metric using generated \brt{}s to help select the more promising fixes from all \autopr-generated fixes for bugs where no existing test had failed. Our evaluation of \enpassrate on Top-K fix selection and threshold-based fix selection shows promising results and reveals trade-offs (\S\ref{sec:results:selection}). 
\end{itemize}




