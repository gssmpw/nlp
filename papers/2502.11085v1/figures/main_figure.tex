\begin{figure*}
\centering
\includegraphics[width=\linewidth]{images/pipeline.png}
\vspace{-0.8cm}
\caption{\textbf{Pipeline Overview}. Our paradigm for pretraining and finetuning consists of two new components: (1) \textit{Dataset Selection Stage}, where a distance metric \(\delta\) is employed to identify the dataset that is most similar to our downstream task dataset \(\mathcal{D}_d\), in this case \(\mathcal{D}_u^{(1)}\). This selected dataset is then used for pretraining the model. (2) \textit{Limited Budget Pretraining}, where we impose a training budget by subsampling \(\mathcal{N}\) random samples from \(\mathcal{D}_u^{(1)}\) and training the model for \(\mathcal{E}\) epochs. This results in a computational budget of \(\mathcal{C} = \mathcal{E} \times \mathcal{N}\). The pretrained backbone \(\theta_b^{(1)*}\) is subsequently finetuned on the downstream task dataset \(\mathcal{D}_d\) to obtain the final model parameters \(\theta_d^*\). }
\label{fig:main_figure}
\vspace{-0.3cm}
\end{figure*}
