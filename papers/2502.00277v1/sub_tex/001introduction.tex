Combinatorial Optimization (CO) problems are central challenges in computer science and operations research \citep{papadimitriou1998combinatorial}, with diverse real-world applications such as supply chain management, logistics optimization \citep{chopra2001strategy}, workforce scheduling \citep{ernst2004staff}, financial portfolio management \citep{rubinstein2002markowitz,lobo2007portfolio}, compiler optimization \citep{trofin2021mlgo,zheng2022alpa}, and bioinformatics \citep{gusfield1997algorithms}. Despite their wide-ranging utility, CO problems are inherently difficult due to their non-convex nature and often NP-hard complexity, making them intractable in polynomial time by exact solvers.  Traditional CO algorithms often rely on hand-crafted, domain-specific heuristics, which are costly and difficult to design, posing significant challenges in solving novel or complex CO problems.

Recent advancements in neural network (NN)-based learning \citep{bengio2020machine} and simulated annealing (SA) \citep{kirkpatrick1983SA} algorithms  have redefined approaches to combinatorial optimization by minimizing dependence on manual heuristics:
\begin{itemize}
    \item \textbf{Neural Network Models}: NN-based methods leverage reinforcement learning \citep{Khalil2017DQNCO, qiu2022dimes}, unsupervised learning \citep{Karalias2020ErdosGN, wang2022unsupervised, wang2023unsupervised, SanokowskiHL24} or generative models \citep{kool2018attention, zhang2023let, sun2023difusco, li2023from, li2024fast} to learn optimization strategies directly from data. By automating the process, these models replace handcrafted heuristics with learned representations and decision-making processes, enabling tailored solutions refined through training rather than manual adjustment.
    \item \textbf{Simulated Annealing}: SA is a general-purpose optimization algorithm that explores the solution space probabilistically, avoiding dependence on problem-specific heuristics. Although its cooling schedule and acceptance criteria require some design decisions, SA is highly adaptable across diverse problems free from detailed domain knowledge \citep{Johnson1991opsa}.
\end{itemize}

%Recent examples of NN-based CO solvers highlight the remarkable progress in the field. DIMES \citep{qiu2022dimes} scales reinforcement learning from graphs with up to 100 nodes to 10,000 nodes without sacrificing prediction accuracy.
Discrete Langevin dynamics (LD) \citep{zhang2022langevinlike, sun2022path} and the corresponding diffusion models \citep{chen2023analog, austin2021structured} have greatly advanced the recent development of both NN and SA solvers. The key idea of LD is to guide the iterative sampling via the gradient, for a more efficient searching/generation process. For instance, DIFUSCO \citep{sun2023difusco} adopts continuous diffusion models from computer vision to address the discrete nature of CO problems, outperforming previous end-to-end neural models in both accuracy and computational efficiency. Additionally, DiffUCO \citep{SanokowskiHL24} generalizes DIFUSCO by eliminating the need for labeled training data, using unsupervised learning for CO problems.
Meanwhile, advanced SA-based CO solvers  have demonstrated performance on par with state-of-the-art NN-based approaches.  \citet{sun2023revisiting} underscore the advantages of LD-based SA method, including their simplicity, superior speed-quality trade-offs, and generalizability to new CO problems, as they require no training or problem-specific customization.
However, existing discrete LD/diffusion methods are all adapted from the methods \citep{Welling2011LD, dickstein2015nonequ, song2019generative, Ho2020denoising, song2020improved} in the continuous domain, this raises important questions:  Is there any difference between CO and continuous optimization? Do these adapted methods sufficiently consider the nature of discrete data? Exploring these questions is the central focus of this paper.



Our key observation is that the optimization process is more prone to local optima in a discrete domain than in a continuous one.  That is, local optima in a continuous domain typically has a zero gradient (under the smoothness condition)
but this is often not true in a discrete domain, where the gradients may be very large in magnitude but pointing to an infeasible region. Such a difference makes the escaping of local optima more difficult in a discrete domain than in a continuous one, with the common strategy of  adding a random noise as in LD.  We propose  
to address this issue by enforcing a constant norm of the expected distance between the sampled solution and the current solution during the searching process. In other words, we control the magnitude of the update in LD, encouraging the search to explore more promising areas. We name this sampling method \textit{Regularized Langevin Dynamics (RLD)}. We apply RLD on both SA and NN-based CO solvers, leading to Regularized Langevin Simulated Annealing (RLSA) and Regularized Langevin Neural Network (RLNN).  Our empirical evaluation on three CO problems demonstrate thes significant improvement of RLSA and RLNN over both SA and NN baselines. Notably, RLSA only needs 20\% running time to outperform the previous  SOTA SA baselines. It shows a clear efficiency advantage with either less or more searching steps.

To summarize, we propose a new variant of discrete Langevin dynamics for CO by regularizing the expected update magnitude on the current solution at each step. Our method is featured by its simplicity, effectiveness, and wide applicability to both SA and NN-based solvers, indicating its strong potential in addressing CO problems.





