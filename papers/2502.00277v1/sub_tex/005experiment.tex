\begin{table*}[ht!]
\small
    \centering
        \caption{Comparative results on the \textit{Mximum independent Set (MIS)} problem. On each dataset, we bold the best result and color the second-best one in green. By "best" or "second best", we exclude the OR solvers (Gurobi and KaMIS) as their running times are excessively large, preventing a fair comparison with the methods in other categories.}
            \vspace{5pt}
    \begin{tabular}{cc|cccccccc}

     \multicolumn{2}{c}{\textbf{MIS}}  &  \multicolumn{2}{c}{RB-[$200$--$300$]} &  \multicolumn{2}{c}{RB-[$800$--$1200$]}   & \multicolumn{2}{c}{ER-[$700$--$800$]} &  \multicolumn{2}{c}{ER-[$9000$--$11000$]} \\%&  \multicolumn{2}{c}{SATLIB}  \\
         %\toprule
             \toprule
        \textsc{Method}  &       \textsc{Type}     & \textsc{Size} $\uparrow$ & \textsc{Time} $\downarrow$  & \textsc{Size} $\uparrow$ & \textsc{Time} $\downarrow$ & \textsc{Size} $\uparrow$ & \textsc{Time} $\downarrow$ & \textsc{Size} $\uparrow$ & \textsc{Time} $\downarrow$ \\%& \textsc{Size} $\uparrow$ &\\ \textsc{Time} $\downarrow$     \\
    \midrule
 Gurobi & OR & $19.98$ & 47.57m & $40.90$ &  2.17h & $41.38$ & 50.00m & --- & --- \\%& $425.95$ & 26.00m  

     KaMIS    & OR & $20.10$  & 1.40h & $43.15$ & 2.05h & $44.87$ &  52.13m & $381.31$ & 7.60h \\%& $425.96$ & 37.58m\\
     \midrule
     PPO & RL &  $19.01$ & 1.28m &  $32.32$ &  7.55m & --- & --- & --- & --- \\%& $421.49$ & 13.20m\\
     INTEL & SL & $18.47$ & 13.07m &  $34.47$  &  20.28m & $34.86$ & 6.06m & $284.63$ & 5.02m \\%& $420.66$ & 23.05m \\
     DGL & SL & $17.36$ & 12.78m & $34.50$ & 23.90m & $37.26$ & 22.71m & --- & --- \\%& --- & --- \\
     DIMES & RL  & --- & --- & --- & --- &  $42.06$ & 12.01m & $332.80$ &  12.72m \\%& $421.24$ & 24.17m \\
     DIFUSCO & SL & $18.52$ & 16.05m & --- & --- & $41.12$ & 26.67m &  --- & --- \\%& 424.50 & 8.75m \\
     LTFT & UL & $19.18$ & 32s & $37.48$ & 4.37m & --- & --- & --- & --- \\%& $423.54$ & 23.22m \\
     DiffUCO  & UL & $19.24$ & 54s & \textcolor{mygreen}{$38.87$} & 4.95m & --- & --- & --- & --- \\%& --- & --- \\
    iSCO & H & $19.29$ & 2.71m & $36.96$ & 11.26m &$42.18$ & 1.45m &  \textcolor{mygreen}{$365.37$} & 1.10h  \\%& $420.30$ & 52.33m \\
   %\rowcolor{lightgray} iSCO ($10\times$) & H & $20.01$ & 26.25m & $40.47$ & 1.87h  & $44.41$ & 7.21m & $378.56$ & 11.03h\\
     \midrule 
    RLNN & RL & \textcolor{mygreen}{$19.52$} & 1.64m & $38.46$  & 6.24m & \textcolor{mygreen}{$43.34$} & 1.37m & $363.34$ & 11.76m \\
    RLSA & H & $\textbf{19.97}$ & 35s & $\textbf{40.19}$ & 1.85m & $\textbf{44.10}$ & 20s &  $\textbf{375.31}$ & 1.66m \\%& $\textbf{424.61}$ & 14.91m  \\
    % \rowcolor{lightgray}  RLSA ($10\times$) & H &$20.10$ & 6.98m & $41.83$ & 10.65m & $45.05$ & 2.92m & $379.19$ & 17.63m \\     
    \bottomrule
    \end{tabular}
    

    \label{tab:mis}
\end{table*}
\begin{table*}[ht!]
\small
    \centering
        
    \caption{Comparative results on the \textit{Max Clique (MCl)} and \textit{Max Cut (MCut)} problems. On each dataset, we bold the best result and color the second-best one in green. By "best" or "second best", we exclude the OR solvers (Gurobi and KaMIS) as their running times are excessively large, preventing a fair comparison with the methods in other categories. } %\underline{The rows highlighted in gray are excluded from comparison.}}
        \vspace{5pt}
    \begin{tabular}{cc|cccc|cc|cccc}

       \multicolumn{2}{c}{\textbf{MCl}} &  \multicolumn{2}{c}{RB-[$200$--$300$]} & \multicolumn{2}{c}{RB-[$800$--$1200$]} &      
       \multicolumn{2}{c}{\textbf{MCut}} &  \multicolumn{2}{c}{BA-[$200$--$300$]} & \multicolumn{2}{c}{BA-[$800$--$1200$]}    \\
           \toprule   % \toprule
       \textsc{Method}  &       \textsc{Type}     & \textsc{Size} $\uparrow$  & \textsc{Time} $\downarrow$  & \textsc{Size} $\uparrow$  & \textsc{Time} $\downarrow$ &\textsc{Method}  &       \textsc{Type}     & \textsc{Size} $\uparrow$  & \textsc{Time} $\downarrow$  & \textsc{Size} $\uparrow$  & \textsc{Time} $\downarrow$   \\
    \midrule
    Gurobi & OR & $19.05$ & 1m55s & $33.89$ & 19.67m & Gurobi & OR & $730.87$ & 8.50m & $2944.38$ & 1.28h \\
    SDP & OR &  --- & --- & --- & --- & SDP & OR & $700.36$  & 35.78m & $2786.00$ & 10.00h \\
    \midrule
    Greedy & H & $13.53$ & 25s & $26.71$ & 25s  & Greedy & H & $688.31$ & 13s & $2786.00$ & 3.12m \\
    MFA    & H & $14.82$ & 27s & $27.94$ & 2.32m & MFA & H & $704.03$ & 1.60m & $2833.86$ & 7.27m \\
    ERDOES & UL & $12.02$ & 41s & $25.43$ & 2.27m & ERDOES & UL & $693.45$ & 46s & $2870.34$ & 2.82m \\
   %ANNEAL & UL & $14.10$ & 41s & $27.46$ & 2.77m &  ANNEAL & UL & $696.73$ & 45s & $2863.23$ & 2.80m\\
    LTFT &  UL & $16.24$ & 42s & $31.42$ & 4.83m & LTFT & UL & $704.30$ & 2.95m & $2864.61$ & 21.33m \\
    DiffUCO & UL & $16.22$ & 1.00m & --- & --- & DiffUCO & UL & $727.32$ & 1.00m & \textcolor{mygreen}{$2947.53$} & 3.78m \\
     iSCO & H & \textcolor{mygreen}{$18.96$} & 54s & \textcolor{mygreen}{$40.35$} & 11.37m & iSCO & H & $728.24$ &  1.67m & $2919.97$ &  4.18m \\
     %\rowcolor{lightgray} iSCO ($10\times$) & H & $18.97$ & 8.81m & $40.41$ &  1.83h %& iSCO ($10\times$) & H &  $734.62$ & 1.20h &$2960.23$ & 43.98m\\  
     \midrule 
     RLNN & RL & $18.13$ & 1.36m & $35.23$ & 7.83m & RLNN & RL &\textcolor{mygreen}{$729.00$} & 1.58m & $2907.18$ & 3.67m\\ 
    RLSA & H & $\textbf{18.97}$ & 23s &  $\textbf{40.53}$ & 1.27m & RLSA & H  & $\textbf{733.54}$ & 27s &  $\textbf{2955.81}$ & 1.45m \\
    %\rowcolor{lightgray}     RLD ($10\times$) & H & $18.97$ & 3.14m & 40.63 & 8.67m & RLD ($10\times$) & H & $734.62$ & 4.07m & $2968.59$ & 10.25m\\ 
    \bottomrule
    \end{tabular}

    \label{tab:mc}
\end{table*}

\subsection{Experimental Setup}

\paragraph{Benchmark datasets.} Following \citet{zhang2023let}, we use the Revised Model B (RB) graphs \citep{Xu2000ExactPT} for the evaluation of MIS and MCl problems, and use the Barabasi-Albert (BA) graphs \citep{doi:10.1126/science.286.5439.509} for the evaluation of MCut problem. In addition, we also include Erdős-Rényi (ER) graphs \citep{Erdos1984OnTE} used by \citet{qiu2022dimes} on the MIS problem. We follow the above works to generate RB, BA and ER graphs at two different scales. On RB and BA graphs, the small scale contains 200 to 300 nodes and the large scale contains 800 to 1200 nodes. While the ER graphs have a small scale of 700 to 800 nodes and a large scale  of 9,000 to 11,000 nodes. The large-scale ER graphs are used for transfer testing on the models trained on the small-scale ER graph. A suffix of `-[$n$--$N$]' is used to differentiate the graphs with different scales, implying that the graphs contain $n$ to $N$ nodes. The test set size is 500 for RB and BA graphs, 128 for ER-[$700$--$800$] and 16 for ER-[$9000$--$11000$]. A training set of size 1000 and validation set of 500 graphs is used for all datasets except for ER-[$9000$--$11000$]. The node weight in MIS and MCl is set as $1$ for all nodes.

\paragraph{Baselines.}  Following \citet{qiu2022dimes} and \citet{zhang2023let}, we categorize our baselines as the classical operation research methods (OR), heuristic methods (H), reinforcement learning-based  solvers (RL), supervised learning-based solvers (SL) and unsupervised learning-based solvers (UL). For MIS, we have the integer linear programming solver Gurobi \citep{gurobi} and MIS-specific solver KAMIS \citep{kamis} as the OR baselines, and the recent SA method iSCO \citep{sun2023revisiting} as a heuristic baseline. In the RL category, we include PPO \citep{10.5555/3524938.3524952} and DIMES \citep{qiu2022dimes}.  In the SL category, we have  
INTEL \citep{NEURIPS2018_8d3bba74}, DGL \citep{bother2022whats}, and DIFUSCO \citep{sun2023difusco}. In the UL category, we use LTFT \citep{zhang2023let} and DiffUCO \citep{SanokowskiHL24}. For the non-MIS problems, the baselines include two OR methods, which are Gurobi and a semi-definite programming method (SDP); three heuristic methods, which are greedy, mean-filed annealing (MFA) \citep{NIPS1988_ec5decca} and iSCO \citep{sun2023revisiting}; and three UL methods, which are ERDOES \citep{Erdos1984OnTE}, LTFT \citep{zhang2023let} and DiffUCO \citep{SanokowskiHL24}, respectively. For most of those methods, we report their published results in \citet{qiu2022dimes, zhang2023let, sun2023difusco, SanokowskiHL24, li2024fast}. If a NN-based method has multiple variants, we only compare with the version with the longest running time (typically corresponding to the best result). For method iSCO, we run its code on our datasets as the time measurement in this work is inconsistent with others.  For a fair comparison, we run iSCO with the same number of steps and trials as we did for RLSA. 

\paragraph{Implementation Details.} We used two servers for the training of RLNN, one with 8 NVIDIA RTX A6000 GPUs, and the other one with 10 NVIDIA RTX 2080 Ti GPUs. All the time measurement is conducted on a single A6000 GPU. We find the efficiency of RLNN highly susceptible to the inductive bias of the NN architecture, e.g., a two-parameter linear model is enough to fit the gradient of MIS in Equation \ref{eq:mis}. Therefore, we mainly focus on verifying the effectiveness of RLNN algorithm, without optimizing the neural network architecture. In our experiment, we parameterized RLNN with a five-layer GCN \citep{kipf2017semisupervised} with 128 hidden dimensions. Due to the increasing computational complexity at each step, we also accordingly reduce the number of sampling steps and trials of RLNN compared to RLSA, with other hyperparameters kept the same. We include more details, such as the hyperparameters, in Appendix \ref{sec:detail}
\begin{figure*}[ht!]
    \centering
    \includegraphics[width=.95\linewidth]{plots/ablate.png}
    \caption{Comparison between RLD and standard discrete LD for SA. RLD/RLSA is in the \underline{red color}. The man value of the primal gap in the test set is plotted, while the shaded area indicates the standard deviation.}
    \label{fig:ablation}
\end{figure*}


\subsection{Main Results}
%For a better interpretability, 
In performance evaluation, we compare the mean value of the achieved problem-specific objective (larger is better) of each method on each problem, including the set size for MIS, clique size for MCl and cut size for MCut. In addition, we compare the \textit{total running time} (lower is better) of each method on the entire test set by sequentially evaluating each instance. Since the OR solvers are guaranteed to find the optimal solution with enough running time, we do not include them for comparison.
%their performance in comparison but just take it for reference. 

Table \ref{tab:mis} presents the results on the MIS problem. It can be seen that with a similar or even less running time, RLSA shows a significant improvement against the SOTA NN-based methods on RB and ER graphs. Besides, RLSA also consistently outperforms another gradient-guided SA method iSCO, with the same number of steps and trials. Due to the simplicity of RLSA, it only take around  5-20\% running time of iSCO, but with a better objective value. The performance of RLNN is also competitive, taking the second-best result on 2 out of 4 datasets. It also achieves the similar performance on ER-[$900$--$11000$] to iSCO, using less than 20\% running time. Due to the significant increase in computational overhead at each step, RLNN only uses 10\% number of trails and a shorter sampling chain compared to RLSA. We observe that RLNN could sometimes outperform RLSA with the same number of running steps and trials, which indicates the potential of NN in learning the problem distribution. But how to balance the computational resources between the per-step computation and searching efforts would an interesting topic.

The comparative results on the MCl and MCut problems are summarized in Table \ref{tab:mc}. Generally, RLSA still maintains a clear efficiency advantage against iSCO.  We observe that iSCO has a similar performance with RLSA on MCl at both scales, but RLSA and RLNN are still clearly better than other baselines. RLSA takes a consistent lead on MCut, while RLNN, DiffUCO and iSCO have a similar performance, with a significant improvement against other baselines. 

Besides, we also include the comparative results between iSCO and RLSA with $10\times$ running steps in Appendix \ref{ref:longer}, and the observation is consistent. In general, we find both RLSA and RLNN competitive on our evaluation benchmarks, and RLSA shows an impressive performance on all datasets with only a limited computational cost.

\begin{table*}[ht!]
\small
    \centering
        \caption{Ablation Study on regularization in RLNN. The numbers correspond to the set size (larger is better).}
            \vspace{5pt}
    \begin{tabular}{c|cc|c|c}

    & \multicolumn{2}{c|}{\textbf{MIS}}& \textbf{MCl} & \textbf{MCut} \\
        \toprule
    \textsc{Method} & RB-[$200$--$300$] &  ER-[$700$--$800$]  & RB-[$200$--$300$]   & BA-[$200$--$300$]  \\
    \midrule
   % RLD & $19.97$ \\
     RLNN w/o regularization & $18.64$    & $37.73$  & $16.62$ & $\textbf{730.20}$ \\
    RLNN w/ regularization & $\textbf{19.52}$  & 
$\textbf{43.34}$ & $\textbf{18.13}$ & $729.00$\\
    \bottomrule
    \end{tabular}

    \label{tab:ablate}
\end{table*}
\subsection{Ablation Study}
To verify the effectiveness of regularization in RLD, we conduct the ablation study on RLSA and RLNN, respectively. We first compare RLD with the standard discrete LD  \citep{zhang2022langevinlike} for SA, searching the step size $\alpha$ over the set $\{ 0.1, 0.01, 0.001\}$. All other hyperparameters are kept the same as in RLSA. Figure \ref{fig:ablation} compares the dynamics of the primal gap \citep{Berthold2014HeuristicAI} across the sampling process. Here, the primal gap on each instance is defined as
\begin{equation}
\begin{cases}
        \frac{|H(\mathbf{x})-H(\mathbf{x}^*)|}{\max\{|H(\mathbf{x})|,|H(\mathbf{x}^*)|\}}, & \text{if} \ H(\mathbf{x})H(\mathbf{x}^*)\geq0; \\
        1, & \text{otherwise},
    \end{cases}
\end{equation}
where $\mathbf{x}$ corresponds to the best solution found so far and $\mathbf{x}^*$ is a pre-computed optimal (or best known) solution. 

It can be seen that the standard discrete LD always ends up at a sub-optimal solution except on MCl. The searching could easily get stuck in a local optima, indicated by the flat stage. In contrast, RLSA usually converges in just a few steps (less than 100) without getting stuck in any local optima. Note that our searching set has already covered the most common choices of the gradient descent step size for continuous data, and a smaller step size, e.g., 0.001, shows an even worse performance. Contrast to the optimization in the continuous domain, CO clearly presents a different challenge and we address it by RLD.


We then examine the regularization term in Equation \ref{eq:obj} for training RLNN. We perform the ablation study on  small-scale graphs by training RLNN without regularization, and present the comparative results in Table \ref{tab:ablate}. The regularization brings a significant improvement on RLNN in most cases, except on MCut. We hypothesize this is because MCut has no constraint and suffers less from the local optima. But on other benchmarks, we find it almost impossible to effectively train RLNN without regularization. Here we visualize training dynamics on MIS and MCl by plotting the set/clique size on the validation set (larger is better) in Figure \ref{fig:training}.  
\begin{figure}
    \centering
    \includegraphics[width=0.95\linewidth]{plots/training_curve.png}
    \caption{Training curves of  RLNN with or without regularization. Validation performance  (set/clique size) is shown.}
    \label{fig:training}
    \vspace{-5pt}
\end{figure}
It can be seen that the performance of the orange curve (no regularization) remains unchanged (on MIS) or even drops after more training epochs (on MCl). The usage of a local optimization loss function makes the diversity of training samples a huge concern. While the regularization would enforce RLNN to collect different training samples and encourage the search during inference time. The similar spirit is also used in some well-known reinforcement learning algorithms to encourage the exploration, such as the  curiosity \citep{pathakICMl17curiosity} and soft policies \citep{haarnoja2017reinforcement, pmlr-v80-haarnoja18b}. 