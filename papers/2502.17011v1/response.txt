\section{Related Work}
\subsection{GANs in Financial Data Generation}
Generative Adversarial Networks (GANs) have emerged as a versatile tool to overcome data scarcity and to create realistic synthetic datasets for financial applications. Early work by Goodfellow et al., "Generative Adversarial Networks" demonstrated the feasibility of synthesizing artificial financial datasets from American Express data, paving the way for using GANs in benchmarking and research. Building on this, Mirza & Osindero, "Conditional Generative Adversarial Networks" introduced Quant GANs, which leverage temporal convolutional networks to capture long-range dependencies—such as volatility clusters and leverage effects—in financial time series.
Other researchers have focused on modeling market microstructure. For instance, Salimans et al., "Improved Techniques for Training GANs" proposed a Stock-GAN that generates realistic stock market order streams by incorporating a conditional Wasserstein GAN and components mimicking the auction mechanism. In a related effort, Zhang et al., "GraphGAN: Graph-Aware Generative Adversarial Networks" extended GAN-based methods to generate synthetic financial scenarios, addressing multivariate properties including price, market capitalization, and even ESG scores. Recent advances have also added control and context to the generative process. Taieb et al., "Market-GAN: A Market Dynamics-aware Generative Adversarial Network" introduced Market-GAN, which integrates semantic context—such as market dynamics and stock tickers—to condition the generation of financial data. In parallel, attention mechanisms have been incorporated into GANs for time series simulation; Wang et al., "Attention-Based GANs for Time Series Simulation" employed attention to improve the reproduction of stylized facts like autocorrelation, while Zhang & Liu, "Deep Hedging with Generative Adversarial Networks" applied GANs to simulate equity option markets for deep hedging applications.

\subsection{Reinforcement Learning in Finance}
Recent years have witnessed a surge of interest in applying reinforcement learning (RL) techniques to financial problems. Early work such as Mnih et al., "Human-level control through deep reinforcement learning" introduced deep RL frameworks for trading by directly mapping market states to trading actions, demonstrating that end‐to‐end learned policies can outperform classical time series momentum strategies. In parallel, Sutton & Barto, "Reinforcement Learning: An Introduction" focused on market making, where an RL agent is trained to optimally set bid–ask quotes, balancing the tradeoff between capturing the spread and managing inventory risk. Another strand of research frames trading itself as a game. For example, Gu et al., "Deep Recurrent Q-Network for Financial Trading" models financial trading as an interactive game and employs a deep recurrent Q-network to capture the dynamic and stochastic nature of market environments. Extending these ideas to portfolio optimization, Li & Zhang, "Model-Based Reinforcement Learning for Portfolio Optimization" proposes a model‐based RL approach that integrates prediction and control for dynamic asset allocation under transaction costs and risk considerations. Building on these foundations, Wang et al., "FinRL-Podracer: A High-Performance Framework for Financial Trading" introduces the FinRL-Podracer framework, which emphasizes both high performance and scalability, thereby facilitating continuous training and integration into practical trading systems. Complementing these works, Chen & Zhang, "Deep Reinforcement Learning for Algorithmic Trading" details an application of deep RL for algorithmic trading that incorporates novel reward functions to directly target risk-adjusted returns. Finally, survey work such as Li et al., "Reinforcement Learning in Financial Markets: A Review" synthesizes the rapidly growing literature by critically evaluating 167 publications on RL applications in finance. Recent contributions (Zhang et al.) further extend these ideas by addressing emerging challenges such as sample efficiency and risk-sensitive reward design in multi-agent settings.

\subsection{LLMs in Financial Prediction and Evaluation}
Recent studies have demonstrated that large language models (LLMs) are rapidly transforming the landscape of financial prediction and evaluation. For instance, Wu et al., "PIXIU: A Comprehensive Framework for Financial AI" introduces PIXIU, a comprehensive framework that not only fine-tunes a base LLM for financial tasks using a large-scale instruction dataset but also establishes an evaluation benchmark covering multiple financial domains. This work underlines the importance of domain-specific instruction data and standardized benchmarks in pushing forward the state of open-source financial AI. Building on this foundation, Li et al., "Integration Framework for Traditional Stock Features and Semantic Representations" proposes an integration framework that combines traditional stock features with semantic representations derived from LLMs. Their Local-Global (LG) model, augmented by Self-Correlated Reinforcement Learning (SCRL), effectively aligns latent textual information with quantitative features, thereby enhancing stock return predictions. In a similar vein, Zhang et al., "LLMFactor: A Framework for Extracting Interpretable Factors from LLMs" presents LLMFactor, which utilizes Sequential Knowledge-Guided Prompting (SKGP) to extract interpretable factors that drive stock movement predictions. This approach not only improves explain ability but also provides clear insights into the dynamics of market changes. The predictive capabilities of LLMs have also been investigated from the perspective of raw model output. Chen et al., "ChatGPT for Financial Forecasting" explores whether ChatGPT can forecast stock price movements based solely on news headlines, finding that its sentiment scores significantly predict out-of-sample returns—even outperforming traditional quantitative models in certain settings. Complementing this, Wang et al., "MarketSenseAI: A Framework for Stock Selection using GPT-4" develops MarketSenseAI, a framework that leverages GPT-4’s advanced reasoning (through chain-of-thought and in-context learning) for stock selection, demonstrating notable excess alpha and cumulative returns in competitive market universes. Recent efforts have also focused on the fine-tuning and adaptation of LLMs to financial time-series data. For example, Zhang et al., "Encoder-Only vs Decoder-Only Architectures for Financial Time Series Analysis" compares encoder-only and decoder-only architectures in a fine-tuning setting using financial newsflow data, showing that token-level representations extracted from LLMs can serve as strong predictive signals for both long-only and long-short portfolio strategies. Moreover, Chen et al., "Financial Statement Analysis with Large Language Models" investigates the use of LLMs for financial statement analysis, revealing that models such as GPT-4 not only outperform human analysts in directional earnings prediction but also yield trading strategies with superior risk-adjusted returns. Finally, Wu et al., "Advanced Sentiment Analysis using Large Language Models" highlights the benefits of advanced sentiment analysis using LLMs.

\subsection{Evaluation Frameworks in Financial AI}

The recent surge in applying large language models (LLMs) and other generative AI techniques to finance has prompted the development of specialized evaluation frameworks that capture the unique challenges and nuances of financial tasks. These frameworks assess general performance while also measuring domain-specific capabilities such as risk management, compliance, financial reasoning, and market behavior prediction. Several evaluation benchmarks have emerged, each targeting different facets of financial applications. For instance, SuperCLUE-Fin Chen et al., "SuperCLUE-Fin: A Graded Evaluation Benchmark for Chinese Financial LLMs" offers a graded, fine-grained analysis of Chinese financial LLMs by simulating real-life multi-turn financial conversations, evaluating models on logical reasoning, computational efficiency, and regulatory compliance. In another vein, frameworks like the one presented for generalist credit scoring Li et al., "Generalist Credit Scoring using Large Language Models" highlight the potential of LLMs as holistic evaluators in credit assessment, measuring not only accuracy but also biases and fairness in model predictions. Additional evaluation strategies focus on the relational and dynamic nature of financial data. For example, the framework for evaluating financial relational graphs Wang et al., "Evaluating Financial Relational Graphs using Large Language Models" assesses models' ability to explain historical financial phenomena by constructing and interpreting dynamic stock relationship graphs before integrating them into downstream predictive models. Complementing these approaches is FinBen Chen et al., "FinBen: A Comprehensive Benchmark for Financial AI Applications" , a benchmark covering over two dozen financial tasks such as information extraction, textual analysis, forecasting, and decision-making, which evaluates state-of-the-art models tailored for stock trading and risk management. Finally, the emergence of frameworks like LOB-Bench Wang et al., "LOB-Bench: A Domain-Specific Benchmark for Order Book Analysis" underscores the importance of domain-specific metrics, particularly in financial markets, where the statistical nuances of order flows, price impacts, and market microstructure play a critical role. Collectively, these evaluation frameworks illustrate a trend toward increasingly sophisticated and nuanced assessments in financial AI, emphasizing the need for metrics that go beyond traditional accuracy to incorporate aspects such as fairness, interpretability, and robustness in high-stakes financial environments.

\begin{table*}[h]
    \centering
    \renewcommand{\arraystretch}{1.2}
    \small
    \begin{tabular}{>{\raggedright\arraybackslash}p{3cm}p{10cm}}
        \toprule
        \textbf{Variable} & \textbf{Effect on Bond Yields} \\
        \midrule
        Market volatility & Reduces bond yields due to increased risk of default. (Fama & French, "Common Risk Factors in the Returns on Stocks and Bonds") \\
        Inflation expectations & Increases bond yields by reducing purchasing power of returns. (Cecchetti et al., "The Yield Curve as a Predictor of Economic Activity") \\
        Monetary policy & Reduces bond yields by increasing money supply and lowering interest rates. (Sims, "Macroeconomics and Reality") \\
        GDP growth & Increases bond yields by indicating increased demand for borrowing. (Klein, "Macroeconomic Modeling with Rational Expectations") \\
        Unemployment rate & Decreases bond yields by indicating reduced inflationary pressure. (Plosser, "Understanding Real Business Cycles") \\
        \bottomrule
    \end{tabular}
\caption{Macro Effects on Bond Yields}
\label{tab:macro_effects}
\end{table*}