\begin{figure*}[!th]
\centering
\begin{minipage}{0.32\textwidth}
    \includegraphics[width=\linewidth]{images/llama_reasoning.pdf}
\end{minipage}
\hfill
\begin{minipage}{0.32\textwidth}
    \includegraphics[width=\linewidth]{images/llama_understanding.pdf}
\end{minipage}
\hfill
\begin{minipage}{0.32\textwidth}
    \includegraphics[width=\linewidth]{images/llama_generation.pdf}
\end{minipage}

\medskip

\begin{minipage}{0.32\textwidth}
    \includegraphics[width=\linewidth]{images/qwen_reasoning.pdf}
\end{minipage}
\hfill
\begin{minipage}{0.32\textwidth}
    \includegraphics[width=\linewidth]{images/qwen_understanding.pdf}
\end{minipage}
\hfill
\begin{minipage}{0.32\textwidth}
    \includegraphics[width=\linewidth]{images/qwen_generation.pdf}
\end{minipage}
\caption{\label{fig:main_res}
Performance comparison of \jola{} and baseline methods across commonsense reasoning~\cite{hu-etal-2023-llm}, natural language understanding (MMLU-Pro benchmark;~\citealp{wang2024mmlu}), and natural language generation tasks (GEM benchmark;~\citealp{gehrmann-etal-2022-gemv2}) for LLaMA-3~\cite{dubey2024llama} and Qwen-2.5~\cite{yang2024qwen2}. Please refer to Appendix~\ref{appendix:full_res} for full results.
}
\end{figure*}