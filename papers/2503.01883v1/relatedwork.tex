\section{Related Work}
\label{sec:related}
\noindent Black-box optimization problems were studied using derivative-free methods, such as random gradient estimation~\citep{WangAISTATS18} or Bayesian optimization~\citep{Snoek12,Wang13,eriksson2019scalable}. These methods require online evaluation of the target function to approximate its derivative or learn its surrogate model. In many practical applications, this can be very expensive (e.g., testing new protein or drug design), or even dangerous (e.g., test-driving autonomous vehicles in a real physical environment). To avoid this, \textit{offline optimization} approaches tackle this problem via utilizing an existing dataset that records target function evaluations for a fixed set of inputs. These approaches can be categorized into two main families:

\noindent {\bf Conditioning Search Model.}
Existing approaches in this direction are grounded in the framework of density estimation, which aims to learn a probabilistic prior over the input space. The search model is treated as a probability distribution conditioned on the rare event of achieving a high target function score, and is estimated using different approaches, such as adaptive trust-region based strategies~\citep{BrookeICML19}, adaptive step-size in gradient update via reinforcement learning~\citep{YassineAAAI24} or zero-sum game~\citep{ClaraNeurIPs20}, or autoregressive modeling \cite{krishnamoorthy2023generative}, \cite{krishnamoorthy2023diffusion}. \citet{kumar2020model}~learns an inverse mapping of the target function evaluations to inputs and uses it as a search model that predicts which regions will most likely have high-performing designs.
These approaches are often sensitive to the accuracy of the conditioning at out-of-distribution input regimes and/or require learning a computationally expensive generative model of the input space. The robustness of these conditioning algorithms has neither been defined, nor investigated.

\noindent {\bf Conditioning Surrogate Model.} Approaches in this direction tend to fix the search methodology and focus on conditioning the surrogate model to improve the likelihood of finding a good design. This is generally achieved via adopting different forms of regularization on the predicted values of OOD inputs based on the learned surrogate. For example, \citet{YuNeurIPs21}~uses robust model pre-training and adaptation to ensure local smoothness, whereas \citet{FuICLR21}~maximizes data likelihood to reduce the uncertainty in OOD prediction. Alternatively, \citet{TrabuccoICML21}~penalizes high-value predictions for OOD examples, and \citet{NghiaICML24}~penalizes surrogate candidates with high prediction sensitivity over the offline data to avoid overestimation. These approaches are only justified empirically through practical demonstrations. From a theoretical perspective, the extent of effectiveness of these algorithms, as well as the fundamental question regarding when to trust a surrogate function both remain unclear. 

\vspace{-1.0ex}