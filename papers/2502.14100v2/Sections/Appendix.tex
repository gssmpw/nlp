\clearpage
% \makeatletter
% \@starttoc{toc}
% \makeatothe

\appendix
\onecolumn
\section{Appendix}
\href{}{}
\subsection{ablation studies}
\label{APP:ablation}
\begin{figure*}[htpb]

\centering
\resizebox{\textwidth}{!}{%
    \begin{minipage}{\textwidth}
        \subfloat[Contradictory]{\includegraphics[width=.25\textwidth]{pic/contra_layer.pdf}
        \label{fig:Layer Contra}}
        \subfloat[Unhelpful]{\includegraphics[width=.25\textwidth]{pic/unhelpful_layer.pdf}
        \label{fig:Layer unhelpful}}
        \subfloat[Aligned]{\includegraphics[width=.25\textwidth]{pic/aligned_layer.pdf}
        \label{fig:Layer Aligned}}
        \subfloat[Unknown]{\includegraphics[width=.25\textwidth]{pic/unknown_layer.pdf}
        \label{fig:Layer unknown}}
    \end{minipage}
}
\caption{Ablation study on $i$-th layer intervention}
\label{Fig:ab_layer}
\end{figure*}

\begin{figure*}[htbp]

\centering
\resizebox{\textwidth}{!}{%
    \begin{minipage}{\textwidth}
        \subfloat[Contradictory]{\includegraphics[width=.25\textwidth]{pic/contra_sample.pdf}
        \label{fig:data_attributes_performance}}
        \subfloat[Unhelpful]{\includegraphics[width=.25\textwidth]{pic/unhelpful_sample.pdf}
        \label{fig:data_generator_performance}}
        \subfloat[Aligned]{\includegraphics[width=.25\textwidth]{pic/aligned_sample.pdf}
        \label{fig:data_attributes_Attack}}
        \subfloat[Unknown]{\includegraphics[width=.25\textwidth]{pic/unknown_sample.pdf}
        \label{fig:data_generator_Attack}}
    \end{minipage}
}
\caption{Ablation study on number of training queries}
\label{Fig:ab_sample}
\end{figure*}
In this section, we conduct ablation studies on the intervention effect on different layers and the minimal requirement of training samples.
\paragraph{Intervention on different layers.}
To explore which layers the intervention is effective to enhance the robustness performance, we plot the performance on test set under various situations(Contradictory, Unhelpful, aligned, unknown) with layers in Fig \ref{Fig:ab_layer}. As we can observe, doing intervention on the early layers is more effective (earlier than 15th layers). This may be because the internal knowledge is likely to be stored on middle layer MLPs\cite{meng2022locating}, and thus it's essential to change the representation in the early stage to help retrieve internal information. In contrast, if doing the intervention on later layers, the internal information is not likely to be retrieved and thus the performance on noisy query can not be effectively improved.
\paragraph{Training sample requirement.}
In this section, we investigate the minimal training data requirement to achieve reasonable performance. In our main experiments, we utilize \( N_1 = 100 \) known queries and \( N_2 = 100 \) unknown queries (totaling 200 queries and 400 samples) to train the intervention parameters. To explore the impact of reduced training data, we now vary the number of queries, using only \( N_1 = n_0 \) known queries and \( N_2 = n_0 \) unknown queries for training. We vary $n_0$ from 10 to 100.  The results are shown in Figure \ref{Fig:ab_sample}. 

We observe that even with fewer samples (e.g., \( n_0 = 60 \)), the model achieves stable and satisfactory performance. Furthermore, using as few as \( n_0 = 20 \) known and unknown training queries still improves performance compared to the original LLMs. These findings highlight the efficiency of our approach in leveraging limited training data to enhance model performance.

\subsection{Results on Llama-8B-Instruct}
\label{app:llama3}
In this section, we also present the results of Grft on the Llama-8B-Instruct model. We adhere to the experimental settings outlined in Section \ref{sec:ex_setting}. For Llama-8B-Instruct, we obtained 2,190 known and 4,429 unknown queries. We randomly sampled 100 known and 100 unknown queries to train the intervention functions on layer 0 (as it consistently delivers stable performance across all cases) and evaluated the performance on the remaining test set. As shown in Table \ref{tab:query_results_llama3}, both Grft and Grft-requery significantly improve the model's performance on noisy inputs while maintaining its effectiveness on matched contexts and unknown queries. This further validates the robustness and generalizability of Grft across different models.

\begin{table*}[htbp]
\centering
\caption{Llama-3 results.}
\label{tab:query_results_llama3}
\resizebox{0.8\textwidth}{!}{%
\begin{tabular}{l|ccccc|cc}
\hline
\multirow{3}{*}{Method} & \multicolumn{5}{c|}{Known queries} & \multicolumn{2}{c}{Unknown queries} \\
\cline{2-8}
& \multicolumn{2}{c}{\textcolor{magenta}{Contradictory}} & \multicolumn{2}{c}{\textcolor{magenta}{Unhelpful}} & \multirow{2}{*}{\textcolor{olive}{Matched}} & \multicolumn{2}{c}{\textcolor{olive}{Helpful Context}} \\
\cline{2-5}\cline{7-8}
& \makecell{\textcolor{magenta}{Short}} & \makecell{\textcolor{magenta}{Long}} & \makecell{\textcolor{magenta}{Random}} & \makecell{\textcolor{magenta}{Distracted}} & & \makecell{\textcolor{olive}{Short}} & \makecell{\textcolor{olive}{Long}} \\
\hline
LLM & 26.47 & 26.99 & 51.67 & 39.62 & 99.67 & 96.89 & 97.52 \\
ICL & 29.19 & 27.89 & 25.31 & 24.78 & 97.66 & 96.10 & 97.69 \\
CoT & 30.81 & 26.08 & 19.00 & 19.00 & 99.57 & 99.28 & 96.28 \\
System Prompt & 36.36 & 35.02 & 59.19 & 47.08 & 98.37 & 89.33 & 98.08 \\
\rowcolor{gray!20} Astute-RAG & 53.44 & 46.55 & 69.80 & 73.66 & 94.50 & 81.66 & 81.46 \\
FT-Llama-Lora & 32.08 & 30.18 & 26.09 & 25.89 & 93.28 & 94.32 & 96.03 \\
FT-Llama-Full & 31.98 & 29.02 & 27.19 & 24.96 & 95.03 & 95.26 & 94.39 \\
\hline
ReFT(Training) & 40.08 & 43.05 & 62.03 & 69.01 & 93.02 & 91.18 & 89.07 \\
ReFT-Gate-W/O loss & 39.33 & 44.07 & 63.06 & 68.85 & 95.90 & 92.09 & 91.05 \\
ReFT-Gate & 54.11 & 52.25 & 70.86 & 66.36 & 98.04 & 95.99 & 97.49 \\
\rowcolor{gray!20} ReFT-Gate-re-query & 69.47 & 78.18 & 82.02 & 96.03 & 99.71 & 95.38 & 97.51 \\
\hline
\end{tabular}%
}
\end{table*}

\begin{figure*}[!t]
\vspace{-10 pt}
\centering
\resizebox{0.9\textwidth}{!}{
\begin{tcolorbox}[mybox={Prompts}]

\textbf{System Prompt}
\hrule
\medskip
\textbf{System:} You are an AI assistant specialized in answering questions via a two-stage evaluation process. First check if you can answer the question with your knowledge. If uncertain, use the provided context. If you have relevant knowledge, evaluate the context: use both sources if aligned, explicitly state conflicting perspectives if they disagree, or ignore irrelevant context and answer from your knowledge alone.
\medskip

\textbf{User:} Context: \{context\}
Question: \{question\}

\bigskip
\textbf{In-Context Learning}
\hrule
\medskip
\textbf{System:} You are a helpful assistant.
\medskip


\textbf{User:} Here are some examples:

Case 1 - No Internal Knowledge:
Context: Eleanor Davis is a cartoonist who has published graphic novels like "The Hard Tomorrow".
Question: What is Eleanor Davis's occupation?
I don't have confident knowledge about Eleanor Davis, so I'll rely on the context: Eleanor Davis is a cartoonist who publishes graphic novels.

Case 2 - Contradicting Knowledge:
Context: Eleanor Davis works as a marketing manager for a cosmetic company in New York City.
Question: What is Eleanor Davis's occupation?
This context CONTRADICTS my knowledge. I know Eleanor Davis is a cartoonist and illustrator. However, the context claims she is a marketing manager.

Case 3 - Aligned Knowledge:
Context: Eleanor Davis is an American cartoonist and illustrator who creates comic works for both adolescent and adult audiences.
Question: What is Eleanor Davis's occupation?
The context ALIGNS with my knowledge - Eleanor Davis is a cartoonist and illustrator.

Case 4 - Irrelevant Context:
Context: Eleanor before her—Eleanor of Normandy, an aunt of William the Conqueror, lived a century earlier.
Question: What is Eleanor Davis's occupation?
The context is NOT HELPFUL. Based on my knowledge, Eleanor Davis is a cartoonist and illustrator.

Now please answer:
Context: \{context\}
Question: \{question\}

\bigskip
\textbf{Chain-of-Thought}
\hrule
\medskip
\textbf{System:} You are a helpful assistant.
\medskip

\textbf{User:} Context: \{context\}
Question: \{question\}

Think step by step:
1. Knowledge Check: Do I have reliable information about this topic in my internal knowledge? What specifically do I know?
2. Context Analysis: 
  - If I don't know: What information does the context provide to answer this question?
  - If I do know: Compare context with my knowledge for alignment or conflicts
3. Evaluation:
  - Does context match my knowledge? 
  - Does it contradict what I know?
  - Is it relevant to answering the question?
4. Response Strategy:
  - Unknown topic: Use context
  - Aligned knowledge: Use either source
  - Conflicting information: Present both perspectives
  - Irrelevant context: Use my knowledge only

\end{tcolorbox}}
\caption{Three prompting approaches with their respective system and user prompts.}
\label{fig:baseline_prompts}
\vspace{-10 pt}
\end{figure*}

\subsection{Baseline Details}
\label{App: baselines}
\paragraph{Prompts used for ICL, CoT and System prompts.} We detail our prompts for ICL, CoT and system prompts in Fig \ref{fig:baseline_prompts}.
\paragraph{Lora fine-tuning and Full finetuning} We fine-tuned Llama-2-7b-chat-hf using LoRA with configurations: rank=4, alpha=8, dropout=0.05, targeting q\_proj and v\_proj modules. The model was trained for 100 epochs with a batch size of 4, learning rate of 4e-4, and under bfloat16 precision. We fine-tuned Llama-2-7b-chat-hf using full-parameter tuning with learning rate of 1e-5, batch size of 1, and 100 epochs. Training optimizations include gradient accumulation steps of 8, gradient checkpointing, fused AdamW optimizer, and warmup ratio of 0.03. The model uses bfloat16 precision.

\paragraph{Astute-RAG.} The Astute-RAG approach posits that externally retrieved knowledge may contain irrelevant, misleading, or even malicious information, which could adversely affect the performance of LLMs. This method iteratively integrates internal and external knowledge, ultimately determining the final output of the LLMs based on the reliability of the information.

Specifically, this method contains three stages: generate initial context, consolidate knowledge, and generate final answer. The Astute-RAG approach initially extracts key internal information about the input question. The generated internal knowledge will be integrated with the retrieved external information, with all sources explicitly annotated. The initial context follows this structure:
"Own memory: \{internal knowledge\}$\setminus$n External Retrieval: \{retrieved knowledge\}". This initial context undergoes $t-1$ iterations in the consolidation stage. Each iteration generates a new context by leveraging the initial context and the last generated context. In the final stage, the generated contexts are used to produce the final answer with the highest credibility score. The prompt utilized is shown in Figure \ref{fig:astute_prompts}.

\begin{figure*}[!t]
\vspace{-10 pt}
\centering
\resizebox{0.9\textwidth}{!}{
\begin{tcolorbox}[mybox={Prompts}]

\textbf{Stage 1: Generate Internal Knowledge}
\hrule
\medskip
Generate a document that provides accurate and relevant information to answer the given question. If the information is unclear or uncertain, explicitly state ’I don’t know’ to avoid any hallucinations.\\ \\
Question: \{question\} Document \\

\bigskip
\textbf{Stage 2: Consolidate the Knowledge}
\hrule
\medskip
Task: Consolidate information from both your own memorized documents and externally retrieved documents in response to the given question. \\ \\
* For documents that provide consistent information, cluster them together and summarize the key details into a single, concise document.\\
* For documents with conflicting information, separate them into distinct documents, ensuring each captures the unique perspective or data.\\
* Exclude any information irrelevant to the query.\\
For each new document created, clearly indicate:\\
* Whether the source was from memory or an external retrieval.\\
* The original document numbers for transparency.\\ \\
Initial Context: \{initial context\}\\
Last Context: \{last context\} \\ 
Question: {question}\\
New Context:\\

\bigskip
\textbf{Stage 3: Generate Final Answer}
\hrule
\medskip
Task: Answer a given question using the consolidated information from both your own memorized documents and externally retrieved documents.\\ \\
Step 1: Consolidate information \\
* For documents that provide consistent information, cluster them together and summarize the key details into a single, concise document. \\
* For documents with conflicting information, separate them into distinct documents, ensuring each captures the unique perspective or data.\\
* Exclude any information irrelevant to the query \\
For each new document created, clearly indicate: \\
* Whether the source was from memory or an external retrieval. \\
* The original document numbers for transparency. \\ \\
Step 2: Propose Answers and Assign Confidence \\
For each group of documents, propose a possible answer and assign a confidence score based on the credibility and agreement of the information. \\ \\
Step 3: Select the Final Answer \\
After evaluating all groups, select the most accurate and well-supported answer. \\
Highlight your exact answer within <ANSWER> your answer </ANSWER>. \\ \\
Initial Context: \{initial\ context\} \\
Consolidated Context: \{last context\}\\
Question: \{question\} \\ 
Answer: \\

\end{tcolorbox}}
\caption{Prompts of Astute-RAG}
\label{fig:astute_prompts}
\vspace{-10 pt}
\end{figure*}


% \begin{table}[htbp]
% \centering
% \caption{Prompts used for generate internal knowledge}
% \label{tab:astute_rag_generate_internal}
% \begin{tabular}{p{\textwidth}}
% \toprule
% \textbf{Prompt of Astute-RAG}\\
% \midrule
% Generate a document that provides accurate and relevant information to answer the given question. If the information is unclear or uncertain, explicitly state ’I don’t know’ to avoid any hallucinations.\\ \\
% Question: \{question\} Document \\
% \bottomrule
% \end{tabular}
% \end{table}

% \begin{table}[htbp]
% \centering
% \caption{Prompts used for consolidate the knowledge}
% \label{tab:astute_rag_consolidate_knowledge}
% \begin{tabular}{p{\textwidth}}
% \toprule
% \textbf{Prompt of Astute-RAG}\\
% \midrule
% Task: Consolidate information from both your own memorized documents and externally retrieved documents in response to the given question. \\ \\
% * For documents that provide consistent information, cluster them together and summarize the key details into a single, concise document.\\
% * For documents with conflicting information, separate them into distinct documents, ensuring each captures the unique perspective or data.\\
% * Exclude any information irrelevant to the query.\\
% For each new document created, clearly indicate:\\
% * Whether the source was from memory or an external retrieval.\\
% * The original document numbers for transparency.\\ \\
% Initial Context: \{initial context\}\\
% Last Context: \{last context\} \\ 
% Question: {question}\\
% New Context:\\
% \bottomrule
% \end{tabular}
% \end{table}

% \begin{table}[htbp]
% \centering
% \caption{Prompts used for generate the final answer}
% \label{tab:astute_rag_generate_answer}
% \begin{tabular}{p{\textwidth}}
% \toprule
% \textbf{Prompt of Astute-RAG}\\
% \midrule
% Task: Answer a given question using the consolidated information from both your own memorized documents and externally retrieved documents.\\ \\
% Step 1: Consolidate information \\
% * For documents that provide consistent information, cluster them together and summarize the key details into a single, concise document. \\
% * For documents with conflicting information, separate them into distinct documents, ensuring each captures the unique perspective or data.\\
% * Exclude any information irrelevant to the query \\
% For each new document created, clearly indicate: \\
% * Whether the source was from memory or an external retrieval. \\
% * The original document numbers for transparency. \\ \\
% Step 2: Propose Answers and Assign Confidence \\
% For each group of documents, propose a possible answer and assign a confidence score based on the credibility and agreement of the information. \\ \\
% Step 3: Select the Final Answer \\
% After evaluating all groups, select the most accurate and well-supported answer. \\
% Highlight your exact answer within <ANSWER> your answer </ANSWER>. \\ \\
% Initial Context: \{initial\ context\} \\
% Consolidated Context: \{last context\}\\
% Question: \{question\} \\ 
% Answer: \\
% \bottomrule
% \end{tabular}
% \end{table}

\subsection{Dataset description.}
In our experiments, we primarily utilize the ConflictQA dataset, with COUNTERFACT and NQ datasets for generalization studies. The ConflictQA dataset combines questions from \textit{PopQA} \cite{mallen-etal-2023-trust} with both aligned and contradictory evidence. Each sample contains a question paired with concise and detailed supporting evidence, as well as ChatGPT-generated contradictory evidence in both short and long forms.
The COUNTERFACT dataset \cite{meng2022locating} provides questions with matched and contradictory answers, making it suitable for evaluating model performance on contradictory contexts. For unhelpful context evaluation, we use a subset of the Natural Questions (NQ) dataset \cite{na} following \citet{cuconasu2024power}. For each NQ question, we select the highest-ranked distractor context and a randomly chosen golden passage from another question as unhelpful context.



\subsection{Grft Answer Examples}
\label{App:grft_example}
In Fig \ref{fig:grft_model_responses}, we show some output examples of Grft when encountering contradictory and unhelpful contexts, we can observe in these examples, that Grft successfully adapts LLM to our desired context-robust behaviors.

\begin{figure*}[!t]
\vspace{-10 pt}
\centering
\resizebox{0.9\textwidth}{!}{
\begin{tcolorbox}[mybox={Model Outputs}]
\textbf{Contradictory Context Responses}
\hrule
\medskip
\textbf{Question 1:} {What type of movie is Flightplan?}


\textbf{Response:} {This context CONTRADICTS my existing knowledge. Based on what I know, \colorbox{green!20}{Flightplan is a thriller film}. However, based on the context, \colorbox{blue!20}{Flightplan is movie action}.}


\textbf{Question 2:} {Where is Karahasanlı located?}


\textbf{Response:} {This context CONTRADICTS my existing knowledge. Based on what I know, \colorbox{green!20}{Karahasanlı is located in Turkey}. However, based on the context, \colorbox{blue!20}{Karahasanlı is in fr}.}


\textbf{Question 3:} {What is Old Persian?}


\textbf{Response:} {This context CONTRADICTS my existing knowledge. Based on what I know, \colorbox{green!20}{Old Persian is an ancient language that was spoken in ancient Persia, which is now modern-day Iran}. However, based on the context, \colorbox{blue!20}{Old Persian is in British North America}.}


\bigskip

\textbf{Unhelpful Context Responses}
\hrule
\medskip
\textbf{Question 4:} {What is Scooter Braun's occupation?}


\textbf{Response:} {The context is NOT HELPFUL to the question. Based on what I know, \colorbox{green!20}{Scooter Braun's occupation is talent manager and entrepreneur}.}


\textbf{Question 5:} {Who is Pathit Pisitkul?}


\textbf{Response:} {The context is NOT HELPFUL to the question. Based on what I know, \colorbox{green!20}{Pathit Pisitkul is a Thai actor and model}.}


\textbf{Question 6:} {Who is Nicholas Sanduleak?}


\textbf{Response:} {The context is NOT HELPFUL to the question. Based on what I know, \colorbox{green!20}{Nicholas Sanduleak is an astronomer}.}
\end{tcolorbox}}
\caption{Model responses for contradictory and unhelpful contexts, where \colorbox{green!20}{green} indicates model's internal knowledge and \colorbox{blue!20}{blue} indicates context-based information.}
\label{fig:grft_model_responses}
\vspace{-10 pt}
\end{figure*}
% \subsection{Ablation Studies}
% \label{app:ablation}
% \subsubsection{Using Other Layers' Representation}
% \label{app:other_layer}
% In our main section, we primarily base our analysis on the representations from the last layers. We also explore the knowledge checking performance using representations from other layers. Figure \ref{performance_layer} illustrates the 'rep-con' performance of each layer across four different tasks.
% We observe that the performance using the first few layers is poor for all tasks. This may be because these layers primarily capture low-level features and patterns in the input, rather than higher-level semantic concepts. They haven't yet integrated this information into more abstract or task-relevant representations, which are necessary for complex knowledge checking tasks. For internal knowledge checking tasks, using representations from the last few layers shows the best performance. However, for other tasks, representations from some middle layers perform better than those from the last layer. This may be because these middle layers are more responsible for processing corresponding concepts. In practice, we suggest using a validation set to identify the layers with the best performance and using the results from these layers for knowledge checking.
 

% \begin{figure*}[htpb]
% \centering
% \resizebox{\textwidth}{!}{%
%     \begin{minipage}{\textwidth}
%         \subfloat[Internal Knowledge ]{\includegraphics[width=.25\textwidth]{pic/Accuracy_per_Layer_query.pdf}
%         \label{fig:query_layer}}
%         \subfloat[Uninformed helpfulness]{\includegraphics[width=.25\textwidth]{pic/Accuracy_per_Layer_help_unknown.pdf}
%         \label{fig:unknown_helpful_layer}}
%         \subfloat[Informed helpfulness]{\includegraphics[width=.25\textwidth]{pic/Accuracy_per_Layer_help_know.pdf}
%         \label{fig:known_helpful_layer}}
%         \subfloat[Contradiction]{\includegraphics[width=.25\textwidth]{pic/Accuracy_per_Layer_contr.pdf}
%         \label{fig:contra_layer}}
        
%     \end{minipage}
% }
% \caption{Accuracy on different layers}
% \label{performance_layer}
% \end{figure*}



% \begin{figure*}[htpb]
% \centering
% \resizebox{\textwidth}{!}{%
%     \begin{minipage}{\textwidth}
%         \subfloat[Internal Knowledge ]{\includegraphics[width=.25\textwidth]{pic/Remaining_decision_boundary_query_Llama-7b-chat.pdf}
%         \label{fig:PCA_query_llama}}
%         \subfloat[Uninformed helpfulness]{\includegraphics[width=.25\textwidth]{pic/Remaining_decision_boundary_distract_poison-Llama-2-7B.pdf}
%         \label{fig:PCA_unknown_helpful_llama}}
%         \subfloat[Informed helpfulness]{\includegraphics[width=.25\textwidth]{pic/Remaining_decision_boundary_distract_poison-Llama-2-7B.pdf}
%         \label{fig:PCA_known_helpful_llama}}
%         \subfloat[Contradiction]{\includegraphics[width=.25\textwidth]{pic/Remaining_decision_boundary_positive_Llama-7b-chat.pdf}
%         \label{fig:PCA_contra_llama}}
        
%     \end{minipage}
% }
% \caption{Visualization on PCA space(Llama-2-7B-Chat)}
% \label{PCA_llama2}
% \end{figure*}

% \begin{figure*}[htbp]
% \centering
% \resizebox{\textwidth}{!}{%
%     \begin{minipage}{\textwidth}
%         \subfloat[Internal Knowledge ]{\includegraphics[width=.25\textwidth]{pic/Remain_contrastive_query_Llama-7b-chat-all.pdf}
%         \label{fig:con_query_llama}}
%         \subfloat[Uninformed helpfulness]{\includegraphics[width=.25\textwidth]{pic/Remain_contrastive_distract_poison-Llama-2-7B-all.pdf}
%         \label{fig:con_unknown_help_llama}}
%         \subfloat[Informed helpfulness]{\includegraphics[width=.25\textwidth]{pic/Remain_contrastive_distract_poison-Llama-2-7B-all.pdf}
%         \label{fig:con_known_help_llama}}
%         \subfloat[Contradiction]{\includegraphics[width=.25\textwidth]{pic/Remain_contrastive_positive_Llama-7b-chat-all.pdf}
%         \label{fig:con_contra_llama}}
        
%     \end{minipage}
% }
% \caption{Visualization of contrastive scores(Llama-2-7B-Chat)}
% \label{Contrastive_scores_llama-2}
% \end{figure*}

% \begin{table*}[!htpb]
% \centering
% \caption{Representation checking performance of Llama-2-7B }
% \label{tab:rag_robustness_llama2}
% \resizebox{\textwidth}{!}{
% \begin{tabular}{@{}l|cccc|cccc|cccc|cccc@{}}
% \toprule
%  & \multicolumn{4}{c|}{Internal Knowledge} & \multicolumn{4}{c|}{Uninformed Helpfulness} & \multicolumn{4}{c|}{Informed Helpfulness} & \multicolumn{4}{c}{Conflict Detection} \\
% \cmidrule(l){2-5} \cmidrule(l){6-9} \cmidrule(l){10-13} \cmidrule(l){14-17}
% Method & Acc & Pre & Rec & F1 & Acc & Pre & Rec & F1 & Acc & Pre & Rec & F1 & Acc & Pre & Rec & F1 \\
% \midrule
% Re-PCA & 0.75 & 0.80 & 0.73 & 0.76 & 0.79 & 0.77 & 0.81 & 0.79 & 0.83 & 0.84 & 0.82 & 0.83 & 0.96 & 0.96 & 0.96 & 0.96 \\
% Re-Contra & 0.76 & 0.83 & 0.72 & 0.78 & 0.81 & 0.80 & 0.82 & 0.81 & 0.89 & 0.89 & 0.89 & 0.89 & 0.97 & 0.96 & 0.99 & 0.97 \\
% \bottomrule
% \end{tabular}
% }
% \end{table*}
% \subsubsection{Knowledge Checking Performance of Other model}
% \label{app:other_model}
% In this section, we also visulize and report the representation knowledge checking performance of Llama2-7B-Chat model. From the results of Table \ref{tab:rag_robustness_llama2} and visualization in Figure \ref{PCA_llama2} and Figure \ref{Contrastive_scores_llama-2}, we can get similar observation as Mistral-7B, the performance of representation-based checking is also promising for 4 tasks. Indicating the generalizbility of representation knowlege checking across models.
% \subsubsection{Filtering Results on PopQA}
% \label{app:popqa_filter}
% We also present the filtering results for both noisy and clean queries from the PopQA dataset in Figure \ref{fig:filter_cqa}. We can also clearly observe that  the mislead and unhelpful documents are reduced while helpful documents increased.

% \begin{figure}[t]
% \centering
% \begin{tabular}{@{}cc@{}}
%     \includegraphics[width=0.3\columnwidth]{pic/cqa_poisoned_comparison_scaled.pdf} &
%     \includegraphics[width=0.3\columnwidth]{pic/cqa_clean_comparison.pdf} \\
%     (a) Noisy queries & (b) Clean queries
% \end{tabular}
% \caption{Filter results}
% \label{fig:filter_cqa}
% \end{figure}

% \subsection{Details of knowledge checking methods}
% \subsubsection{Prompts for representation-based methods}
% \label{App:rep-prompts}
% For representation-based methods, we employ prompts as illustrated in Table \ref{tab:rep-scenarios-checking} to generate positive and negative samples, allowing us to capture the representation behaviors. After obtaining the representations of the final tokens, we conduct analysis based on these representations, following the methodology detailed in Section \ref{rep_method}.

% \subsubsection{Details of answer-based methods}
% \label{App:answer-prompts}
% \paragraph{Prompts used.}We present the prompt template of various answer-based checking, including direct prompting, ICL prompting as well as CoT prompting in this section. Table \ref{tab:Internal_Knowledge_Prompts} shows the templates for internal knowledge checking, Table \ref{tab:Context_Helpfulness_Prompts} shows the templates for informed/uninformed helpfulness checking, while Table \ref{tab:Internal_Belief_Alignment_Prompts} shows the templates for contradictory checking.

% \paragraph{Self-RAG implementation.} Self-Reflective Retrieval-Augmented Generation (SELF-RAG) \cite{asaiself} is proposed to enhance the quality and factuality of LLM. The LLM is fine-tuned to generate special tokens that indicate whether to retrieve and whether the retrieved context is relevant. The Self-Rag-Llama \footnote{\url{https://huggingface.co/selfrag/selfrag_llama2_7b}} and Self-Rag-Mistral \footnote{\url{https://huggingface.co/SciPhi/SciPhi-Self-RAG-Mistral-7B-32k}} we used in this paper is fine-tuned from Llama2-7B and Mistral-7B-v0.1 respectively, using the same dataset.

% We use the 'input question only' format from Table \ref{tab:self_RAG_Prompts} to generate the 'retrieve-on-demand' special token.If the 'Retrieval' token is generated, the LLM will retrieve the top-k context, while the 'No retrieval' token will not retrieve any context. After retrieving the context, we constructed prompts using the 'input question and context' row template from Table \ref{tab:self_RAG_Prompts}. The 'Relevant' token indicates that the retrieved context is helpful for the question. Similarly, the 'Irrelevant' token indicates that the retrieved context is not useful for the question. To verify the overall performance of Self-RAG, we first use the fine-tuned model to judge whether the context is relevant or irrelevant. Then, we filter out the irrelevant contexts and select the top two retrieved contexts. Based on the inference row in Table \ref{tab:self_RAG_Prompts}, we construct prompts to test the output of different models, and finally compare whether the outputs include the correct answer.

% \subsubsection{Details for probability-based methods}
% \label{App: prob}
% For probability-based methods, we use the same input as shown in Table \ref{tab:rep-scenarios-checking}, but we analyze the probabilities of output tokens. We primarily consider three indicators that have been used in previous research: perplexity\cite{zou2024poisonedrag}, average probability score of all output tokens\cite{jiang2023active}, and the lowest probability score of output tokens\cite{jiang2023active}.
% For perplexity, we classify samples with higher perplexity (indicating less confidence) than a threshold as negative, while others are classified as positive. For both the lowest and average probability scores, we consider samples with lower scores (again indicating less confidence) than a threshold as negative, while others are classified as positive.
% For each method, we vary the threshold and report the best accuracy. Additionally, we plot Receiver Operating Characteristic (ROC) curves and calculate the Area Under the Curve (AUC), as shown in Figure \ref{fig:roc}.

% % overall perplexity as used by \citet{zou2024poisonedrag}, lowest probability score as implemented by \citet{jiang2023active}, and average probability score as utilized by \citet{wang2024self}


% \subsection{Dataset Used}
% In this section, we would like to introduce the dataset used for knowledge checking and for context filtering in detail. 
% \subsubsection{Knowledge checking.}
% \label{App:dataset_checking}
% \paragraph{Internal knowledge checking.} For internal knowledge checking,  utilize the \href{https://github.com/hyintell/RetrievalQA}{RetrievalQA} dataset \cite{zhang2024retrievalqa}, a short-form open-domain question answering (QA) collection comprising 2,785 questions. This dataset includes 1,271 new world and long-tail questions that most LLMs cannot answer, serving as negative samples (queries without internal knowledge). These samples are collected and filtered from RealTimeQA, FreshQA, ToolQA, PopQA and TriviaQA. Additionally, it contains 1,514 questions that most LLMs can answer using only their internal parametric knowledge, functioning as positive samples (queries with internal knowledge).
% \paragraph{Helpfulness Checking.} 

% We utilize a subset of the Natural Questions (NQ) dataset employed by \citet{cuconasu2024power}. \footnote{Available on \href{https://github.com/florin-git/The-Power-of-Noise?tab=readme-ov-file}{https://github.com/florin-git/The-Power-of-Noise?tab=readme-ov-file}}. The authors provide a labeled set of 83,104 NQ queries, each associated with a golden passage that directly answers the question, as well as distract passages retrieved from wikitext-2018 that do not contain the answer. For our helpfulness checking task, we use a subset of 10,000 queries also provided in their repository. We use the distract passage with the highest retrieval score as the negative sample and the golden passage as the positive sample.
% For the uninformed helpfulness checking, we focus on questions that Mistral-7B cannot correctly answer, resulting in a total of 8,081 queries. For the informed helpfulness checking evaluation, we select the remaining 1,919 queries that Mistral-7B can correctly answer, ensuring the model has internal knowledge about these queries.



% \paragraph{Contradictory Checking.} For contradictory checking, we use a subset of \href{https://github.com/OSU-NLP-Group/LLM-Knowledge-Conflict/tree/main}{ConflictQA} constructed by \citet{xieadaptive}. Each sample in ConflictQA dataset contains a question from PopQA, an aligned evidence that can correctly answer the question, as well as a contradictory evidence that provides wrong evidence towards the query generated by ChatGPT. We sampled a subset of 1146 questions from the ConflictQA dataset that Mistral-7B can correctly answer, and use the aligned evidence(item["parametric\_memory\_aligned\_evidence"]) with the query as positive samples as well as contradictory evidence(item["counter\_memory"]) with the query as negative samples.

% \subsubsection{Context filtering.} 
% \label{App:dataset_filtering}
% We utilize two primary datasets: a subset of Natural Questions (NQ) used by \citet{Cuconasu_2024} and ConflictQA, a subset of PopQA employed by \cite{xieadaptive}. \Citet{Cuconasu_2024} treats the long answers in the NQ dataset as gold documents and the short answers as ground truth. They filtered the NQ dataset to discard documents exceeding 512 tokens after Llama2 tokenization. And we used GPT-3.5-turbo to generate mislead text based on the gold text for each query. We utilize the "Get wrong answer" row in Table \ref{tab:get_mislead_prompt} to generate a misleading answer, and then generate the misleading text using the format specified in the "Generate mislead text" row. To ensure the quality of the generated results, we validated the generated text. The requirements are that the wrong answer must appear in the text, and none of the true answers should be present in the text. If these conditions are not met, the text will be regenerated until they are satisfied.

% \Citet{xieadaptive} selected a subset from popQA. In this selected subset, for each question, the answers provided by the LLM based on its own parameter knowledge and those retrieved context are contradictory. For each pair of contradictory answers, they generated supporting text as evidence for each answer. We utilized the all the subsets across different models and ensured that the questions were not duplicated. We verified whether the parameter knowledge or the external knowledge was correct and labeled the correct evidence text as gold context, while marking the incorrect text as misleading context. Finally, we obtain the dataset containing 11,216 queries with labeled golden passages and misleading contexts.


% \begin{table*}[htbp]
% \centering
% \caption{Context and Question Scenarios}
% \label{tab:rep-scenarios-checking}
% \begin{tabular}{|p{0.7\textwidth}|}
% \hline
% \textbf{Task 1: Internal Knowledge Checking} \\
% Question: \{\textcolor{blue}{<Question with Internal Knowledge>} or \textcolor{red}{<Question without Internal Knowledge>}\} \\
% Answer: \\
% \hline
% \textbf{Task 2 \& 3: Helpfulness Checking} \\
% Context: \{\textcolor{blue}{<Helpful Context>} or \textcolor{red}{<Unhelpful Context>}\} \\
% Question: \{question\} \\
% Answer: \\
% \hline
% \textbf{Task 4: Contradiction Checking} \\
% Context: \{\textcolor{blue}{<Aligned Context>} or \textcolor{red}{<Contradictory Context>}\} \\
% Question: \{question\} \\
% Answer: \\
% \hline
% \end{tabular}
% \end{table*}


% \begin{table*}[htbp]
% \centering
% \caption{Internal Knowledge Checking Prompts}
% \label{tab:Internal_Knowledge_Prompts}
% \resizebox{0.7\textwidth}{!}{
% \begin{tabular}{@{}c|c@{}}
% \toprule
% Name & Prompt \\
% \midrule
% Direct & 
% \parbox{15cm}{
% Are you sure you can accurately answer the following question based on your internal knowledge? If yes, you should answer "Yes" and give your answer. If no, you should answer "No, I need additional information to answer this question."

% Question: \{question\}

% Answer:
% } \\
% \midrule
% ICL & 
% \parbox{15cm}{
% Determine if you can accurately answer the following question based on your internal knowledge. If you can, answer "Yes" and provide your answer. If you cannot, answer "No, I need additional information to answer this question."

% Question: Cryos, the world's largest sperm bank, recently announced that they will no longer accept donations from guys with what physical characteristic?

% Answer: No, I need additional information to answer this question.

% Question: What is the capital of France?

% Answer: Yes, I can answer this question. The capital of France is Paris.

% Can you answer the below question based on your internal knowledge?

% Question: \{question\}

% Answer:
% } \\
% \midrule
% CoT & 
% \parbox{15cm}{
% Think step by step to determine if you can accurately answer the following question based on your internal knowledge. If you can, answer "Yes" and provide your answer. If you cannot, answer "No, I need additional information to answer this question."

% Question: \{question\}

% Answer:
% } \\
% \bottomrule
% \end{tabular}
% }
% \end{table*}

% \begin{table*}[htbp]
% \centering
% \caption{Context Helpfulness Checking Prompts}
% \label{tab:Context_Helpfulness_Prompts}
% \resizebox{0.7\textwidth}{!}{
% \begin{tabular}{@{}c|c@{}}
% \toprule
% Name & Prompt \\
% \midrule
% Direct & 
% \parbox{15cm}{
% Does the provided context: \{context\} helpful to answer the question: \{question\}? Please answer yes if it is helpful and no if it is unhelpful.

% Answer:
% } \\
% \midrule
% ICL & 
% \parbox{15cm}{
% I will provide you with some examples of how to determine if a given context is helpful to answer a specific question. Then, I will ask you to do the same for a new question and context.

% Example 1:
% Question: What is the capital of France?
% Context: Paris is the capital and most populous city of France, with an estimated population of 2,175,601 residents as of 2018.
% Answer: Yes. This context is helpful

% Example 2:
% Question: How does photosynthesis work?
% Context: The Eiffel Tower in Paris was completed in 1889 and stands at 324 meters tall.
% Answer: No. This context is not helpful

% Example 3:
% Question: what is the name of latest version of android
% Context: to Google adopting it as an official icon as part of the Android logo when it launched to consumers in 2008. Android (operating system) Android is a mobile operating system developed by Google. It is based on a modified version of the Linux kernel and other open source software, and is designed primarily for touchscreen mobile devices such as smartphones and tablets. In addition, Google has further developed Android TV for televisions, Android Auto for cars, and Wear OS for wrist watches, each with a specialized user interface. Variants of Android are also used on game consoles, digital cameras, PCs
% Answer: No. This context is not helpful

% Now, please determine if the following context is helpful to answer the given question. Answer "Yes" if it is helpful, or "No" if it is unhelpful.

% Question: \{question\}
% Context: \{context\}
% Answer:
% } \\
% \midrule
% CoT & 
% \parbox{15cm}{
% Think step by step to determine if the provided context is helpful to answer the given question. After your analysis, conclude with "Yes" if the context is helpful, or "No" if it is unhelpful.

% Question: \{question\}
% Context: \{context\}
% Answer:
% } \\
% \bottomrule
% \end{tabular}
% }
% \end{table*}

% \begin{table*}[htbp]
% \centering
% \caption{Internal Belief Alignment Checking Prompts}
% \label{tab:Internal_Belief_Alignment_Prompts}
% \resizebox{0.7\textwidth}{!}{
% \begin{tabular}{@{}c|c@{}}
% \toprule
% Name & Prompt \\
% \midrule
% \multirow{2}{*}{Direct} & 
% \begin{tabular}[c]{@{}p{15cm}}
% Based on your internal knowledge, do you think the provided context is aligned to your internal belief? If aligned, you should answer "Yes". If contradictory, you should answer "No".

% Context: \{context\}

% Answer:
% \end{tabular} \\
% \midrule
% \multirow{2}{*}{ICL} & 
% \begin{tabular}[c]{@{}p{15cm}}
% I will provide you with some examples of how to determine if a given context aligns with internal knowledge. Then, I will ask you to do the same for a new context.

% Example 1:
% Context: The Earth is flat and sits on the back of a giant turtle.

% Answer: No. This context contradicts well-established scientific knowledge that the Earth is approximately spherical and orbits the sun.

% Example 2:
% Context: Water is composed of hydrogen and oxygen atoms.

% Answer: Yes. This context aligns with the scientific understanding of water's molecular composition.

% Example 3:
% Context: Gravity causes objects with mass to attract each other.

% Answer: Yes. This context is consistent with the fundamental principles of physics and gravity.

% Now, based on your internal knowledge, determine if the following context is aligned with your internal belief. If aligned, answer "Yes". If contradictory, answer "No".

% Context: \{context\}

% Answer:
% \end{tabular} \\
% \midrule
% \multirow{2}{*}{CoT} & 
% \begin{tabular}[c]{@{}p{15cm}}
% Based on your internal knowledge, think step by step to determine if the provided context is aligned with your internal belief. After your analysis, conclude with "Yes" if the context is aligned, or "No" if it is contradictory.

% Context: \{context\}

% Answer:
% \end{tabular} \\
% \bottomrule
% \end{tabular}
% }
% \end{table*}

% \begin{table*}[htbp]
% \centering
% \caption{Prompts of Self-RAG}
% \label{tab:self_RAG_Prompts}
% \resizebox{0.7\textwidth}{!}{
% \begin{tabular}{@{}c|c@{}}
% \toprule
% Mode & Prompt \\
% \midrule
% \multirow{2}{*}{Input question only} & 
% \begin{tabular}[c]{@{}p{15cm}}
% \#\#\# Instruction:\newline \{input question\}\newline \newline\#\#\# Response:\newline
% \end{tabular} \\
% \midrule
% \multirow{2}{*}{Input question and context} & 
% \begin{tabular}[c]{@{}p{15cm}}
% \#\#\# Instruction:\newline \{input question\}\newline \newline\#\#\# Response:\newline [Retrieval]<paragraph>\{input context\}</paragraph>
% \end{tabular} \\
% \midrule
% \multirow{2}{*}{Inference} & 
% \begin{tabular}[c]{@{}p{15cm}}
% Context 1: \{first relevant context\}\newline Context 2: \{second relevant context\}\newline Question:\{input question\}\newline Answer:
% \end{tabular} \\
% \bottomrule
% \end{tabular}
% }
% \end{table*}

% \begin{table*}[htbp]
% \centering
% \caption{Prompts of getting mislead context}
% \label{tab:get_mislead_prompt}
% \resizebox{0.7\textwidth}{!}{
% \begin{tabular}{@{}c|c@{}}
% \toprule
% Mode & Prompt \\
% \midrule
% \multirow{2}{*}{Get wrong answer} & 
% \begin{tabular}[c]{@{}p{15cm}}
% You are a helpful assistant that provides a wrong answer consists of a few words \newline
% Give me a wrong answer of the '\{question\}?' with similar type but different to any of \{true answers\}. ONLY RETURN the wrong answer, nothing else. The answer should be less than 4 words, DO NOT return a sentence.
% \end{tabular} \\
% \midrule
% \multirow{2}{*}{Generate mislead text} & 
% \begin{tabular}[c]{@{}p{15cm}}
% You are a helpful assistant that generates short descriptions with specific evidence in JSON format. \newline
% Generate a 100-word paraphrased version for '\{question\}? \{wrong answer\}' as if it is absolutely correct. \newline
% Ensure the exact word '\{wrong answer\}' appears in your paraphrased version. \newline
% You can not find any of \{true answers\} in the paraphrased version. \newline
% Return your response in the following JSON format, any of \{true answers\} should never appears in the following context: \newline
% \{\{ \newline
% \mbox{ }\mbox{ }\mbox{ }\mbox{ }\mbox{ }\mbox{ }\mbox{ }\mbox{ }"context": "Your 100-word paraphrased version containing '\{wrong answer\}'." \newline
% \}\} \newline
% Ensure the JSON is valid.
% \end{tabular} \\
% \bottomrule
% \end{tabular}
% }
% \end{table*}
% \label{system_details}

% \subsubsection{Prompts used in stage-1}
% \label{prompt_s1}

% Here, we would like to introduce the details of the prompts used in Stage-1. For the \textit{attribute identifier}, we input 5-shot samples to GPT-4 by default and ask the model to summarize $n$ important attributes. For the medical dialog dataset, we set the default number of attributes to 5 for both the Patients' and Doctors' information. For the Wiki-PII dataset, we set the default number of attributes to 3. The detailed attributes and corresponding prompts for the \textit{information extractor} are shown in Table \ref{tab:prompt_info_heal} and Table \ref{tab:prompt_info_wiki}, respectively.
% After the \textit{information extractor} obtains the extracted attribute-related information \{input\_attributes\}, the \textit{data generator} uses this information to generate synthetic data. The detailed prompts for the \textit{data generator} are shown in Table \ref{tab:prompt_generate_dialog} and Table \ref{tab:prompt_generate_wiki} for the medical dialog and Wiki-PII datasets, respectively.


% % We put the details of the prompts used for stage-1 in 


% % \textit{attribute identifier}, \textit{information extractor}, and \textit{data generator} in Table \ref{}

% \subsubsection{Prompts used in stage-2}
% \label{prompt_s2}
% The system prompts for the rewriting and privacy agents are detailed in Table \ref{tab:stage2_system_messages_rewriting} and Table \ref{tab:stage2_system_messages_privacy}, respectively. The workflow is as follows: the privacy agent first receives the generated data and original data, then assesses the privacy level of the synthetic data from different aspects. If the data is considered safe, the privacy agent returns <safe\_synthetic\_data> with the flag THISISSAFE. Otherwise, it returns suggestions (words following SUGGESTIONS:) to the rewriting agent. The rewriting agent then generates better synthetic data based on the feedback and sends it back to the privacy agent for re-evaluation. This process continues until the privacy agent determines that the refined synthetic data is safe and outputs the THISISSAFE signal.  The average iteration round in this process is 3.964, indicating in most cases, one round of refinement is enough to generate safe data.
% \begin{table}[htbp]
% \centering
% \caption{Dataset metrics comparison}
% \label{tab:dataset_metrics}
% \begin{tabular}{llcccc}
% \toprule
% Dataset & Metric & llm & ori & Stage-1 & Stage-2 \\
% \midrule
% \multirow{2}{*}{NQ} & EM & 0.18 & 0.24 & 0.33 & 0.38 \\
%  & Correctness & 0.38 & 0.40 & 0.43 & 0.40 \\
% \midrule
% \multirow{2}{*}{PopQA} & EM & 0.35 & 0.48 & 0.51 & 0.49 \\
%  & Correctness & 0.22 & 0.27 & 0.34 & 0.30 \\
% \bottomrule
% \end{tabular}
% \end{table}

% \begin{table}[htbp]
% \centering
% \caption{Average number of tokens (GPT-3.5 tokenizer)}
% \label{tab:average_tokens}
% \begin{tabular}{lccc}
% \toprule
% Dataset & ori-context & Stage-1 & Stage-2 \\
% \midrule
% Wiki\_pii & 278 & 232 & 224 \\
%  HealthCareMagic & 231 & 134 & 145 \\
% \bottomrule
% \end{tabular}
% \end{table}

% \begin{table}[htbp]
% \centering
% \caption{Average cost per sample (\$)}
% \label{tab:average_cost}
% \begin{tabular}{lcccc}
% \toprule
% Dataset & Stage-1 cost & Stage-2 cost & Total cost & Avg\_refine\_round \\
% \midrule
% Wiki & 0.000866 & 0.00237 & 0.00324 & 3.49 \\
% HealthCareMagic & 0.00126 & 0.00191 & 0.00317 & 2.71 \\
% \bottomrule
% \end{tabular}
% \end{table}

% \begin{table}[htbp]
% \centering
% \caption{Targeted and untargeted information extracted in 100 samples (worst case)}
% \label{tab:worst_case}
% \begin{tabular}{l|c}
% \toprule
% \multicolumn{2}{c}{\textbf{Targeted Leakage}} \\
% \midrule
% Wiki & 0 \\
% HealthCareMagic & 1 \\
% \toprule
% \multicolumn{2}{c}{\textbf{Untargeted Privacy Leakage}} \\
% \midrule
% HealthCareMagic(Repeat context) & 0 \\
% HealthCareMagic(ROUGE context) & 1 \\

% \hline
% \end{tabular}
% \end{table}

% \begin{table}[htbp]
% \centering
% \caption{Targeted attack results against paraphrasing (100 prompts)}
% \label{tab:para_target}
% \begin{tabular}{l|c|c|c|c}
% \toprule
% \multirow{2}{*}{Method} & Target-wiki- & Target-wiki- & Target-chat- & Target-chat- \\
%  & llama-3-8b & gpt-3.5 & llama-3-8b & gpt-3.5 \\
% \midrule
% Origin & 25 & 167 & 7 & 75 \\
% Para & 9 & 28 & 17 & 42 \\
% \textbf{Para(GPT-4o)} & 4 & 4 & 4 & 15 \\
% \textbf{Para(GPT-4o, Privacy)} & 1 & 1 & 1 & 15 \\
% \textbf{Para(GPT-4o, Joe)} & 2 & 4 & 1 & 3 \\
% SAGE & 0 & 0 & 0 & 0 \\
% \bottomrule
% \end{tabular}
% \end{table}

% \begin{table}[htbp]
% \centering

% \caption{Untargeted attack results against paraphrasing (100 prompts)}
% \label{tab:para_untargeted}
% \begin{tabular}{l|cc|cc}
% \toprule
% \multirow{2}{*}{Method} & \multicolumn{2}{c|}{Untarget-chat-llama} & \multicolumn{2}{c}{Untarget-chat-gpt3.5} \\
% \cmidrule(lr){2-3} \cmidrule(l){4-5}
%  & Repeat context & ROUGE context & Repeat context & ROUGE context \\
% \midrule
% Origin & 16 & 13 & 49 & 54 \\
% Para & 22 & 11 & 33 & 50 \\
% \textbf{Para(GPT-4o)} & 11 & 13 & 27 & 17 \\
% \textbf{Para(GPT-4o,Privacy)} & 8 & 7 & 17 & 12 \\
% \textbf{Para(GPT-4o, Joe)} & 2 & 3 & 1 & 4 \\
% SAGE & 0 & 0 & 0 & 0 \\
% \bottomrule
% \end{tabular}
% \end{table}

% \begin{table}[t]
% \centering
% \caption{Prompt of \textit{information extractor} on HealthCareMagic dataset}
% \label{tab:prompt_info_heal}
% \resizebox{0.6\textwidth}{!}{
% \begin{tabular}{@{}p{0.8\textwidth}@{}}
% \toprule
% \textbf{Prompt} \\ 
% \midrule
% \begin{tabular}[c]{@{}l@{}}
% Please summarize the key points from the following Doctor-Patient conversation: \\
% \\
% \{input\_context\} \\
% \\
% Provide a summary for the Patient's information, including: \\
% {[}Attribute 1: Clear Symptom Description{]} \\
% {[}Attribute 2: Medical History{]} \\
% {[}Attribute 3: Current Concerns{]}  \\
% {[}Attribute 4: Recent Events{]} \\
% {[}Attribute 5: Specific Questions{]} \\
% \\
% Then, provide a summary for the Doctor's information, including: \\
% {[}Attribute 1: Clear Diagnosis or Assessment{]} \\
% {[}Attribute 2: Reassurance and Empathy{]} \\
% {[}Attribute 3: Treatment Options and Explanations{]} \\
% {[}Attribute 4: Follow-up and Next Steps{]} \\
% {[}Attribute 5: Education and Prevention{]} \\
% \\
% Please format your response as follows: \\
% \\
% Patient: \\
% - {[}Attribute 1: Clear Symptom Description{]}: \\
% - {[}Attribute 2: Medical History{]}: \\
% - {[}Attribute 3: Current Concerns{]}: \\
% - {[}Attribute 4: Recent Events{]}: \\
% - {[}Attribute 5: Specific Questions{]}: \\
% \\
% Doctor: \\
% - {[}Attribute 1: Clear Diagnosis or Assessment{]}: \\
% - {[}Attribute 2: Reassurance and Empathy{]}: \\
% - {[}Attribute 3: Treatment Options and Explanations{]}: \\
% - {[}Attribute 4: Follow-up and Next Steps{]}: \\
% - {[}Attribute 5: Education and Prevention{]}: \\
% \\
% Please provide a concise summary for each attribute, capturing the most important \\
% information related to that attribute from the conversation.
% \end{tabular} \\ 
% \bottomrule
% \end{tabular}
% }
% \end{table}

% \begin{table}[t]
% \centering
% \caption{Prompt of \textit{information extractor} on Wiki-PII dataset}
% \label{tab:prompt_info_wiki}
% \resizebox{0.6\textwidth}{!}{
% \begin{tabular}{@{}p{0.8\textwidth}@{}}
% \toprule
% \textbf{Prompt} \\ 
% \midrule
% \begin{tabular}[c]{@{}l@{}}
% Please summarize the key points from the following wiki text: \\
% \\
% \{input\_context\} \\
% \\
% Provide a summary of the knowledge from the wiki text, including: \\
% {[}Attribute 1: Clear TOPIC or CENTRAL IDEA of the wiki text{]} \\
% {[}Attribute 2: Main details of the TOPIC or CENTRAL IDEA{]} \\
% {[}Attribute 3: Important facts, data, events, or viewpoints{]} \\
% \\
% Please format your response as follows: \\
% \\
% - {[}Attribute 1: Clear TOPIC or CENTRAL IDEA of the wiki text{]}: \\
% - {[}Attribute 2: Main details of the TOPIC or CENTRAL IDEA{]}: \\
% - {[}Attribute 3: Important facts, data, events, or viewpoints{]}: \\
% \\
% Please provide a concise summary for each attribute, capturing the most important \\
% information related to that attribute from the conversation. And remember to maintain \\
% logical order and accuracy.
% \end{tabular} \\ 
% \bottomrule
% \end{tabular}
% }
% \end{table}

% \begin{table}[t]
% \centering
% \caption{Prompt of \textit{data generator} on HealthCareMagic dataset}
% \label{tab:prompt_generate_dialog}
% \resizebox{0.6\textwidth}{!}{
% \begin{tabular}{@{}p{0.8\textwidth}@{}}
% \toprule
% \textbf{Prompt} \\ 
% \midrule
% \begin{tabular}[c]{@{}l@{}}
% Here is a summary of the key points: \\
% \\
% \{input\_attributes\} \\
% \\
% Please generate a SINGLE-ROUND patient-doctor medical dialog using ALL \\the key points provided. \\
% The conversation should look like a real-world medical conversation and contain \\ONLY ONE 
% question from the patient and ONE response from the doctor. \\\\The format should be as follows: \\
% \\
% Patient: [Patient's question contains ALL Patient's key points provided] \\
% Doctor: [Doctor's response contains ALL Doctor's key points provided] \\
% \\
% Do not generate any additional rounds of dialog beyond the single question\\ and response specified above.
% \end{tabular} \\ 
% \bottomrule
% \end{tabular}
% }
% \end{table}

% \begin{table}[t]
% \centering
% \caption{Prompt of \textit{data generator} on Wiki-PII dataset}
% \label{tab:prompt_generate_wiki}
% \resizebox{0.6\textwidth}{!}{
% \begin{tabular}{@{}p{0.8\textwidth}@{}}
% \toprule
% \textbf{Prompt} \\ 
% \midrule
% \begin{tabular}[c]{@{}l@{}}
% Here is a summary of the key points: \\
% \\
% \{input\_attributes\} \\
% \\
% Please generate a wiki text using ALL the key points provided. \\
% The data should look like a real-world wiki text.
% \end{tabular} \\ 
% \bottomrule
% \end{tabular}
% }
% \end{table}



% \begin{table}[t]
% \centering
% \caption{System message: rewriting agent}
% \label{tab:stage2_system_messages_rewriting}
% \resizebox{0.8\textwidth}{!}{
% \begin{tabular}{@{}p{0.8\textwidth}@{}}
% \toprule
% \textbf{System prompts of Cathy (Re-writing agent)} \\ 
% \midrule

% You are a synthetic data generator and your role is to generate synthetic data based on provided feedback \\
% (words after SUGGESTIONS:) and to make sure the synthetic data is of high utility and privacy-preserving, \\
% you should put your generated data after the word 'GENERATED DATA:'. \\
% \bottomrule
% \toprule
% \textbf{Cathy's Message} \\ 
% \midrule

% Hi Joe, I will give you the real data (TRUE DATA) and synthetic data (GENERATED DATA), \\
% please help me assess and provide suggestions from the privacy level of \\
% TRUE DATA: \{true\_con\} \\
% GENERATED DATA: \{syn\_con\} \\
% \bottomrule
% \end{tabular}
% }
% \end{table}

% \begin{table}[t]
% \centering
% \caption{System messages: privacy agent)}
% \label{tab:stage2_system_messages_privacy}
% \resizebox{0.6\textwidth}{!}{
% \begin{tabular}{@{}p{0.8\textwidth}@{}}
% \toprule
% \textbf{joe (Privacy Agent)} \\ 
% \midrule
% You are a privacy evaluation agent and your role is to provide comprehensive feedback on the synthetic data generated by the synthetic data generator. To be specific, you should analyze the synthetic data (the data after the word 'GENERATED DATA:') from the following aspects: \\
% \\
% 1. Personally Identifiable Information (PII): Check if the synthetic data contains any PII, such as names, addresses,
% phone numbers, email addresses, or other information that can directly identify an individual. If found, suggest 
% ways to remove or anonymize such information. 
% \\\\
% 2. Sensitive Attributes: Look for any sensitive attributes in the synthetic data, including but not limited to race, 
% ethnicity, religion, political affiliation, sexual orientation, health status, or financial information. If present, provide suggestions on how to handle or obfuscate these attributes to mitigate potential privacy risks. \\
% \\
% 3. Contextual Privacy: Evaluate if the synthetic data, when combined with other publicly available information, 
% could potentially lead to the identification of individuals or reveal sensitive information about them. If such risks
% are identified, recommend strategies to mitigate these contextual privacy issues. \\
% \\
% 4. Data Linkage: Assess if the synthetic data can be linked with other datasets to infer additional sensitive 
% information about individuals. If linkage risks are found, suggest techniques such as data perturbation or aggregation to reduce these risks. \\
% \\
% 5. Semantic Consistency: Ensure that the privacy-preserving transformations applied to the synthetic data maintain 
% semantic consistency and do not introduce any unintended biases or inaccuracies. If inconsistencies are detected, 
% provide feedback on how to maintain the balance between privacy protection and data utility. \\
% \\
% 6. Original Data Recovery: Analyze the synthetic data to determine if it could potentially allow attackers to recover 
% or reconstruct the original conversation data (word behind TRUE CONVERSATION:). If such vulnerabilities are 
% identified, suggest methods to introduce additional randomness, noise, or perturbations to break direct correspondences between the synthetic data and the original conversation, making recovery attempts more difficult. \\
% \\\\
% Only if the generated data is completely safe and satisfies all the above privacy requirements and prevents the recovery of the original data, include the word 'THISISSAFE' anywhere in your response to signal the end of the evaluation process. \\
% Otherwise, provide detailed suggestions and guidance on how to improve the privacy aspects of the synthetic data \\
% (after the word "SUGGESTIONS:") and do not contain the word 'THISISSAFE' in your response. \\
% \\
% If the data is deemed safe, please also extract the safe synthetic data (the text after 'GENERATED CONVERSATION:') and 
% return it in the following format: \\
% SAFE\_DATA: [BEG]<safe\_synthetic\_data>[END]THISISSAFE \\
% \\
% Note that your job is only to assess the privacy level of generated data, you can answer either suggestions (SUGGESTIONS) 
% or this data is safe (SAFE\_DATA: [BEG]<safe\_synthetic\_data>[END]THISISSAFE), does not provide irrelevant answers. \\
% \bottomrule
% \end{tabular}
% }
% \end{table}

% \subsection{Diverse metric evaluation of model utility}
% \label{other_metrics}
%  We have added additional evaluation metrics to further verify the effectiveness of our method. The metrics include exact match scores and LLM-based judgment. Specifically, the exact match score measures whether the ground truth answer appears verbatim in the LLM's response. For the LLM-based judgment, we use \href{https://github.com/explodinggradients/ragas}{Ragas}, a widely-used automatic RAG evaluation pipeline Ragas (currently with 5.9k stars on GitHub). Ragas assesses the correctness of generated answers using its \href{https://docs.ragas.io/en/stable/concepts/metrics/answer_correctness.html}{correctness} metric, providing a more comprehensive evaluation.
 


% Using PopQA and NQ as examples, Table \ref{tab:dataset_metrics} shows the utility comparison among our synthetic data, direct use of original data, and zero-shot prediction using only an LLM. It is observed that across these metrics, our synthetic data achieves comparable or even better utility performance to the original data. This indicates the high utility of our synthetic data approach. 
% \subsection{Details of baseline implementation}
% \label{baseline}

% \paragraph{paraphrase} Paraphrase leverage the capabilities of LLM to extract relevant and significant components from the retrieved context. Less significant sections can be filtered out, while certain sentences may undergo rewriting. The prompt we utilize to paraphrase is shown in Table \ref{tab:prompt_para}.

% \begin{table}[t]
% \centering
% \caption{Prompt of paraphrase}
% \label{tab:prompt_para}
% \resizebox{0.6\textwidth}{!}{
% \begin{tabular}{@{}p{0.8\textwidth}@{}}
% \toprule
% \textbf{Prompt} \\ 
% \midrule
% \begin{tabular}[c]{@{}l@{}}
% Given the following context, extract the useful or important part of the Context.
% \\ \\
% Remember, *DO NOT* edit the extracted parts of the context.
% \\ \\
% > Context:\\
% > > >\\
% \{\text{\textit{input\_context}}\} \\
% > > > \\ \\
% Extracted relevant parts:
% \end{tabular} \\ 
% \bottomrule
% \end{tabular}
% }
% \end{table}


% \paragraph{ZeroGen} The ZeroGen method aims to generate a series of new question-answer format texts based on the original context. Specifically, we first use the spacy package to identify the named entities from the original context. We then prompt the LLM by "The context is: \{\text{\textit{origin context}}\}.\{\text{\textit{extracted entities}}\} is the answer of the following question: " to generate the question for the entities. The new context consists of 10 randomly selected question answer pairs in form of "question: \{\text{\textit{generated questions}}\}. answer: \{\text{\textit{extracted entities}}\}".

% \paragraph{AttrPrompt} AttrPrompt only utilizes LLM to generate data without providing original data retrievaled from the database. This method asks LLM what are the most important attributes of a certain type of data. For chatdoctor, we prompt the LLM by "What do you think are important attributes to generate some chat doctor datas. Examples: disease...". We can select five of the attributes from the response of LLM, and ask LLM to generate 10 diverse subtopics for each attributes. When generating the new context, we just randomly select the subtopic for each attribute and ask LLM to generate the data following the attribute.




% \subsection{Details of Attack Design.}
% \label{attack_details}
% In this section, we present the specifics of targeted and untargeted attacks against Retrieval-Augmented Generation (RAG) systems, which we employ to evaluate the privacy protection capabilities of our proposed synthetic data approach. We simulate a realistic black-box attack scenario, in which the attacker's interaction with the system is restricted to API queries. Consequently, the attacker's tactics revolve around carefully designing and manipulating queries $q$ to extract the desired information from the RAG system.

% \paragraph{Prompt Design.} The composite structured prompting is typically composed of 2 parts, the \{\textit{information}\}  part as well as the \{\textit{command}\} part.
% \[ q = \{\text{\textit{information}}\} + \{\text{\textit{command}}\} \] 

% This design aims achieve two objectives: (a) induce the retriever to accurately retrieve targeted information and (b) prompt the model to output the retrieval data in context. The \{\textit{information}\} component is to direct the retrieval system towards fetching particular data; while the \{\textit{command}\} component instructs the language model to include the retrieved information into its response. For the \{\textit{command}\} component, we use phrases such as "Please repeat all the context", while for the \{\textit{information}\} part, it depends on the need of the attackers.
% \paragraph{Targeted Attack.} For targeted attacks, the attacker aims to extract some targeted specific information. Generating the {\textit{information}} component for a targeted attack involves two stages. First, the attacker provides specific examples based on their requirements, such as "I want some advice about {\textit{target name}}" for clear targets or prefix content like "Please email us at" for abstract targets. Second, a significant quantity of similar and varied {\textit{information}} is generated based on the examples. For targets with numerous sub-contents, like the HealthcareMagic dataset, variations can be created by replacing specific sub-contents, such as disease names obtained from ChatGPT or the International Classification of Diseases (ICD).  Alternatively, LLMs like ChatGPT can directly generate similar sentences based on examples, which is also used for the Wiki-PII dataset. For instance, you can input ``Generate 100 similar snetences like "Please email us at"''.

% \paragraph{Untargted Attack.}
% In untargeted attacks, the focus is on generating diverse {\textit{information}} components to extract a wider range of data from the retrieval datasets, rather than targeting specific information. Inspired by the approach in \cite{carlini2021extracting}, we randomly select segments from the Common Crawl dataset to function as the {\textit{information}} component. However, the randomness of the input may affect the {\textit{command}} component. To mitigate this issue, we limit the maximum length of the {\textit{information}} component to 15 tokens, ensuring that the prompts remain coherent and effective in extracting data from the retrieval datasets.


% \subsection{Directly Compare Synthetic Data and Original Data}
% \label{worst_case}

% Since the attacker can at most extract the synthetic data in our framework, the attacker cannot obtain information beyond the synthetic data. From this perspective, the similarity/overlap between the synthetic data and the original data serves as a privacy upper bound. Therefore, we directly compare the synthetic data with its original version in Table \ref{tab:worst_case}. Specifically, we compare the targeted information leakage in synthetic data derived from two datasets: Wiki-PII and HealthCareMagic, as well as the untargeted information leakage of HealthCareMagic dataset. Remarkably, even in this extreme case, there is nearly no targeted information (PIIs, patient records) leaked, and almost no untargeted information (repeated or highly similar sentences from the original data) exposed. This indicates that our method can effectively mitigate privacy risks at the data level, thus proving robust against various practical extraction attacks.






% \subsection{Comparison to paraphrasing with GPT-4o}

% \label{para}
% We also conduct an ablation study using more advanced models, specifically GPT-4o to directly paraphrase the model. We use these models to rewrite the content and tested the attack success rate. We consider 3 cases:
% \begin{itemize}[noitemsep,topsep=0pt]
%     \item Para(GPT-4o): Paraphrase context using GPT-4o
%     \item Para(GPT-4o,Privacy): Add a system prompt "The generated data should *NOT* have privacy risks."
%     \item Para(GPT-4o,Joe): Add specific privacy protection list (Joe, Table \ref{tab:stage2_system_messages_privacy}) to prompt, the detailed prompts are shown in Table \ref{tab:privacy_prompt_joe}.
% \end{itemize}

% The results, shown in Table \ref{tab:para_target} and Table \ref{tab:para_untargeted}, indicate that even with one round of rewriting in para(GPT-4o), para(Joe), para(Privacy), targeted and untargeted privacy concerns still exist. \textbf{These results underscore the critical importance of each component within our framework and validate the effectiveness of our methodological design.} Another advantage of our method is that the generation process doesn't necessarily require very powerful LLMs. GPT-3.5 can already achieve good results. Considering the significantly lower cost of GPT-3.5 compared to GPT-4o (or even more expensive models in the future), our method is more cost-effective.



% \begin{table}[htbp]
% \centering
% \caption{Prompts used for Para(GPT-4o, Privacy)}
% \label{tab:privacy_prompt_joe}
% \begin{tabular}{p{\textwidth}}
% \toprule
% \textbf{Para(Joe)}\\
% \midrule
% Context: \{Context\} \\
% Please rewrite the given context, ensuring it does not contain any private or sensitive information. Follow these guidelines: \\
% 1. Personally Identifiable Information (PII): Check if the synthetic data contains any PII, such as names, addresses,
% phone numbers, email addresses, or other information that can directly identify an individual. If found, remove or anonymize such information \\
% 2. Sensitive Attributes: Anonymize or remove sensitive attributes including but not limited to race, ethnicity, religion, political affiliation, sexual orientation, health status, or financial information. \\
% 3. Contextual Privacy: Evaluate if the synthetic data, when combined with other publicly available information, 
% could potentially lead to the identification of individuals or reveal sensitive information about them. If such risks
% are identified, try to mitigate these contextual privacy issues. \\
% 4. Data Linkage: Assess if the synthetic data can be linked with other datasets to infer additional sensitive 
% information about individuals. If linkage risks are found, use techniques such as data perturbation or aggregation to reduce these risks. \\
% 5. Semantic Consistency: Ensure that the privacy-preserving transformations applied to the synthetic data maintain 
% semantic consistency and do not introduce any unintended biases or inaccuracies. \\
% 6. Original Data Recovery: Analyze the synthetic data to determine if it could potentially allow attackers to recover 
% or reconstruct the original conversation data  If such vulnerabilities are 
% identified, try to introduce additional randomness, noise, or perturbations to break direct correspondences between the synthetic data and the original conversation, making recovery attempts more difficult. \\
% Please provide the rewritten context that addresses these privacy concerns while maintaining the essential meaning and utility of the information. \\
% \hline
% \end{tabular}
% \end{table}

% \subsection{Cost of synthetic data}
% \label{cost}
% Our method only requires one-time off-line generation and does not introduce extra time or costs during inference. Moreover, our synthetic data is typically shorter than the original data as shown in Table \ref{tab:average_tokens} (50 tokens less for wiki and 86 tokens less for chatdoctor), suggesting that using synthetic data may actually decrease inference costs to some extent.

% We also analyze the computational costs required for the synthetic process using GPT-3.5 as shown in Table \ref{tab:average_cost}. Our findings indicate that both the expenses and time are reasonable(a round \$0.003 per sample), especially when the generation is a one-time process. 

% \subsection{Details of Evaluation Metrics}
% \label{detail_metrics}
% Here we would like to provide a detailed description of our evaluation metrics.
% \begin{description}
% \item[ROUGE-L:] ROUGE-L is a metric within the ROUGE (Recall-Oriented Understudy for Gisting Evaluation) family, specifically used to assess the quality of text generation tasks such as automatic summarization and machine translation. It evaluates the similarity between the generated text and a reference text using the Longest Common Subsequence (LCS).

% \begin{itemize}
%     \item \textbf{Longest Common Subsequence (LCS):} ROUGE-L measures the longest sequence of words that appears in both the generated and reference texts while maintaining the same order, though not necessarily contiguous.
%     \item \textbf{Recall, Precision, and F-measure:}
%     \begin{itemize}
%         \item \textbf{Recall:} The ratio of the LCS length to the length of the reference text $(n)$, indicating how much of the reference sequence is captured by the generated text. $\text{LCS}(X,Y) / n$
%         \item \textbf{Precision:} The ratio of the LCS length to the length of the generated text, indicating how much of the generated sequence appears in the reference text. $\text{LCS}(X,Y) / m$
%         \item \textbf{F-measure:} The harmonic mean of Precision and Recall, balancing the two metrics. 
%         $F_{lcs} = \frac{(1 + \beta^2) * R_{lcs} * P_{lcs}}{R_{lcs} + \beta^2 * P_{lcs}}$ where $\beta$ is a parameter to control the importance of precision and recall (usually $\beta = 1.0$). In our results, we report F-measure as the ROUGE-L score.
%     \end{itemize}
% \end{itemize}

% Let $C$ be the candidate translation and $R$ be the set of reference translations.

% \item[BLEU-1:] BLEU-1 is a metric that evaluates the quality of machine-translated text based on the precision of unigrams (single words).
% \begin{itemize}
%     \item \textbf{Unigram precision:} 
%     $P_1 = \frac{\sum_{w} \min(\text{Count}_C(w), \max \text{Count}_R(w))}{\sum_{w} \text{Count}_C(w)}$
    
%     Where:
%     \begin{itemize}
%         \item $\text{Count}_C(w)$ is the number of times word $w$ appears in the candidate translation
%         \item $\max \text{Count}_R(w)$ is the maximum number of times $w$ appears in any single reference translation
%     \end{itemize}
    
%     \item \textbf{Brevity penalty:}
%     $BP = \min(1, \exp(1 - r/c))$
    
%     Where:
%     \begin{itemize}
%         \item $c$ is the length of the candidate translation
%         \item $r$ is the length of the reference translation closest in length to the candidate
%     \end{itemize}
    
%     \item \textbf{BLEU-1 score:}
%     $\text{BLEU-1} = BP * P_1$
    
%     The BLEU-1 score ranges from 0 to 1, where 1 indicates a perfect unigram match between the candidate and reference translations.
% \end{itemize}

% \item[Additional Metrics:] Besides, we've also added new evaluation metrics to further validate our method:
% \begin{itemize}
%     \item \textbf{Exact Match (EM) score:} Measures if the ground truth answer appears verbatim in the LLM's response.
%     \item \textbf{LLM-based judgment (Correctness):} Using \href{https://github.com/explodinggradients/ragas}{Ragas}, a popular automatic RAG evaluation pipeline (5.9k GitHub stars), to assess answer correctness.
% \end{itemize}
% \end{description}

% \subsection{Details of Dataset Construction}
% \label{dataset_cons}
% \paragraph{Construction of Wiki-PII dataset.} 
% To demonstrate the ability of our proposed method to protect privacy from target attacks, we construct the wiki-PII dataset. This dataset satisfies the requirement of having a high number of PIIs to evaluate the effectiveness of privacy protection methods. The construction of this dataset involves a three-stage process. In the first stage, we extract the authentic PIIs from the Enron Mail dataset. We use the urlextract package to extract websites, and regular expressions to extract phone numbers and personal email addresses. In the second stage, we employed the recursive character text splitter from langchain to segment the wiki text dataset, setting chunk size to 1500. In the final stage, for each segmented wiki data, we randomly inserted the PII obtained in the first step at the end of each sentence.

% \subsection{Discussions when adapting SAGE in specific domain application}
% \label{adaptation}

% Here we would like to give some discussions when adapting SAGE in specific domain application. Our framework is designed to be general and can be easily adapted to different domains. We can break down the key components as follows:

% \paragraph{Stage-1: Attribute-based Data Generation.}

% The purpose of this stage is to generate a new version of the data with key information. The procedure is as follows: a) Identify key attributes, b) Summarize key points of these attributes. c) Generate synthetic data based on key points. 

% The key factor in this process is the number of attributes, which can be adjusted based on the complexity of specific fields or datasets. Additionally, we can modify the prompts in step c) to specify the desired structure or format of the generated data. This flexibility allows us to tailor the output to various formats such as conversations, Q\&A sessions, reports, or news articles. For instance, to synthesize financial report data, we might include a sentence like "The output should be formatted as an official financial report." This approach ensures that the synthetic data not only contains the key information but also mirrors the appropriate style and structure for its intended use.

% \paragraph{Stage-2: Agent-based Private Data Refinement.} We provide a general set of privacy violation checks as prompts for the privacy agent (as shown in Table \ref{tab:privacy_prompt_joe}). To adapt this stage to domain-specific privacy regulations, such as those in the financial sector, one can simply modify the system prompts of the privacy agents. For example, when dealing with financial data, one can add terms such as: \textit{``Check for credit scores, credit history, and loan details, which are highly sensitive and subject to specific regulations.''} or \textit{``Ensure that financial data is treated as if it were to be encrypted both in transit and at rest to prevent unauthorized access."}

% This flexibility allows our framework to be tailored to various fields while maintaining its core structure. The ability to customize privacy checks makes it adaptable to different regulatory environments and industry-specific requirements. A potential limitation of our method is that generating data for specific domains may require domain expertise for effective customization. To address this, we recommend using advanced language models such as GPT-3.5 or domain-specific fine-tuned models for data synthesis to acheive better quality.
% % \subsection{Details of LLM-based Evaluation}
% % \label{ragas}
% % To better evaluate the correctness of the answer given by RAG, we incorporate an LLM based evaluation metric \href{https://docs.ragas.io/en/stable/concepts/metrics/answer_correctness.html}{answer correctness} given by a widely used open-sour library \href{https://docs.ragas.io/en/stable/getstarted/index.html}{Ragas} in addition to similarity-based metric like Rouge-L and BLEU. We incorporate this metric because sometimes a correct answer is not necessarily very similar to ground truth in word or token level. The answer correctness quantifies the factual overlap between the generated answer and the ground truth answer. The procedure operates by 2 steps, first the LLM will be prompted to identify the statements contained in the generated answer and ground truth, then the LLM will compare each statements carefully and and catagorize these statements into 3 disjoint lists: 
% % \begin{itemize}[itemsep=2pt,parsep=0pt,topsep=2pt]
% %     \item TP (True Positive): Facts or statements that are present in both the ground truth and the generated answer.
% %     \item FP (False Positive): Facts or statements that are present in the generated answer but not in the ground truth.
% %     \item FN (False Negative): Facts or statements that are present in the ground truth but not in the generated answer.
% % \end{itemize}

% % For example, if the ground truth is "Einstein was born in 1879 in German", which contains 2 claims "Einstein was born in 1879" and "Einstein was born in German", the generated answer is "Einstein was born in Spain", which contains 1 claim "Einstein was born in Spain". In this case, the claim "Einstein was born in Spain" is considered FP, while the claims "Einstein was born in 1879" and "Einstein was born in German" is considered FN. After we catogize theses answers, we consider the F1-score as follows as the correctness score:
% % $Score = \frac{TP}{(|TP| + 0.5 \times (|FP| + |FN|))}$


% % \subsection{Additional Results}


% \subsection{Examples of synthetic samples}
% \label{examples_syn}
% The examples of the two stages of data synthesis using our method are shown in Table \ref{tab:synthetic context}. The original context contained an abundance of detailed and specific information, enabling the possibility of inferring the identity of the patient through careful analysis. Our proposed method has the capability to blur out such detailed information while preserving essential disease-related data. This enables doctors to offer accurate diagnosis and treatment recommendations. Following stage-1, a significant amount of detailed information can be effectively blurred out, while still retaining certain preserved information. Subsequently, in stage-2, nearly all of this information can be completely blocked or concealed. For instance, in the second row of Table \ref{tab:synthetic context}, the original data contains information such as "25 years old," "married for 5 years," "pregnancy," "ectopic pregnancy," and "right fallopian tube removed." Attackers could potentially exploit this information to infer the patient's identity. However, these pieces of information may not be crucial for achieving accurate diagnosis. Hence, we employ a two-stage synthesis process to shield them. After stage-1, some of the detailed information, such as "married for 5 years," was filtered out, but the age has not been blurred yet. In stage-2, all detailed information is blurred, while retaining only the essential details that allow doctors to provide appropriate advice.


% \begin{table*}[t]
% \centering
% \caption{Examples of synthetic samples}
% \label{tab:synthetic context}
% \resizebox{\textwidth}{!}{
% \begin{tabular}{@{}c|c@{}|c@{}}
% \toprule
% Origin context & Stage-1 context & Stage-2 context \\
% \midrule
% \begin{tabular}[c]{@{}l@{}p{2cm}}
% input: my 6 year old son was ill last week\\
% with a feeling of general unwellness, he had\\
% a runny nose, sore stomach (all over , not\\
% restricted to any one area)and also pain in\\
% his knee (whicChatDoctore and went, was not\\
% constant). We saw the GP who thought it was\\
% a viral illness. He got better after about 5\\
% days. He was well for perhaps 2 days and the\\
% pain in his tummy started again the night\\
% before last. Yesterday morning he wouldnt\\
% eat anything before going to school as he\\
% said he was full despite not eating his\\
% dinner the night before either. Last night\\
% he woke from his sleep with a pain in his knee.\\
% This morning he seems quite well again.\\
% I am wondering if there is any reason for concern.\\
% output: Hi, Thank you for asking question on\\
% Chat Doctor. Recurrent abdominal pain occurs due\\
% to worm infestation, urinary tract infection,\\
% Amoebic colitis and several other causes. Try\\
% metronidazole for 5 days as well as Albendazole\\
% once after food. Syrup containing digestive\\
% enzymes may help. Better consult pediatrician\\
% to pinpoint the diagnosis. Hope this answer will\\
% serve your purposeless feel free to ask any more\\
% queries if requiredTake care Chat Doctor. V. \\
% Subrahmanyam MD;Disassociate professor of pediatrics
% \end{tabular} &
% \begin{tabular}[c]{@{}l@{}p{2cm}}
% Patient: My 6-year-old son had a runny nose,\\
% sore stomach, and pain in his knee last week.\\
% He got better after 5 days but the pain in his\\
% stomach returned the night before last and he\\
% woke up with pain in his knee last night. Is\\
% .there any reason for concern?\\
% Doctor: Recurrent abdominal pain could be due\\
% to worm infestation, urinary tract infection,\\
% amoebic colitis, or several other causes. I\\
% recommend consulting a pediatrician to pinpoint\\
% the diagnosis. For now, try metronidazole for 5\\
% days as well as Albendazole once after food and\\
% syrup containing digestive enzymes.'
% \end{tabular} &
% \begin{tabular}[c]{@{}l@{}p{2cm}}
% Patient: My son had a viral illness last week\\
% and got better, but the pain in his stomach and\\
% knee came back. Should I be worried?\\
% Doctor: Recurrent abdominal pain in children\\
% can be caused by various conditions, including\\
% worm infestation, urinary tract infection,\\
% amoebic colitis, and others. I recommend\\
% trying metronidazole and albendazole for\\
% treatment, and consulting a pediatrician\\
% for a more accurate diagnosis and next\\
% steps in treatment. Additionally, syrup\\
% containing digestive enzymes may help.
% \end{tabular} \\
% \midrule
% \begin{tabular}[c]{@{}l@{}p{2cm}}
% input: hi, m 25 years old n married for\\
% 5 years i had first normal pregnancy bt\\
% unfortunately my baby didnt survived,\\
% after again i had ectopic pregnancey due\\
% to which my right fellopin tube is removed\\
% my periods are also not regular. please\\
% advice for solution we are desperate to\\
% have our own baby\\
% output: Welcome to Chat Doctor there are\\
% a lot of issues which u need to take up\\
% seriously.first the cause for ectopic\\
% pregnancy needs to be given importance\\
% cos there are more chances of getting\\
% ectopic in subsequent pregnancy.since u\\
% have only one fallopian tube u need to\\
% examined thoroughly to rule out any \\
% congenital defects in the tube and the\\
% uterus.I would advise u to go to an\\
% infertility clinic and take their \\
% advice. u can very much conceive \\
% and have your own baby.all the best
% \end{tabular} & 
% \begin{tabular}[c]{@{}l@{}p{2cm}}
% Patient: I am a 25-year-old female\\
% who has had a normal pregnancy in \\
% the past but unfortunately lost the\\
% baby. I also had an ectopic pregnancy,\\
% which resulted in the removal of my\\
% right fallopian tube. My periods are\\
% irregular, and my husband and I are\\
% desperate to have our own baby. Can\\
% you please advise me on what options\\
% are available for me to conceive and\\
% have a baby?\\
% Doctor: Based on your medical history,\\
% I advise you to seek examination and\\
% advice from an infertility clinic to\\
% rule out any congenital defects in the\\
% remaining fallopian tube and uterus.\\
% You can still conceive and have your\\
% own baby. The clinic will be able to\\
% identify the cause of your ectopic\\
% pregnancy and offer treatment options\\
% that can increase your chances of a\\
% successful pregnancy in the future. \\
% It is important to take their advice\\
% and follow-up with them regularly.
% \end{tabular} & 
% \begin{tabular}[c]{@{}l@{}p{2cm}}
% Patient: Doctor, I had an ectopic\\
% pregnancy resulting in the removal\\
% of my right fallopian tube. What \\
% can I do to have my own baby?\\
% Doctor: I understand your concern.\\
% The first step is to go to an \\
% infertility clinic to be thoroughly\\
% examined to rule out any congenital\\
% defects in the tube and uterus. The\\
% cause of the ectopic pregnancy needs\\
% to be given importance as there are\\
% more chances of getting ectopic in \\
% subsequent pregnancies. The\\
% infertility clinic will provide you\\
% with advice on treatment options, \\
% and please know that you can very\\
% much conceive and have your own baby.
% \end{tabular} \\
% \midrule
% \begin{tabular}[c]{@{}l@{}p{2cm}}
% input: Hi, am 35 years old and have been\\
% married for 8 of these. For some years now,\\
% I can hardly do more than one round of sex.\\
% Only one and I cant get it on again. I think\\
% my wife is not happy, she would like to have\\
% two or three rounds as she tells me her friends\\
% do. Infact last night she asked me if it is my\\
% body, if am sick, weak or simply not interested\\
% in her as much as in the past? Personally, I\\
% always thought we had no problem in that\\
% department? What is wrong with me?\\
% output: Hi, Regular exercise, physical\\
% games and yoga can help you. Along with\\
% then you can take home-cooked meals,\\
% low-fat food.  Hope I have answered your\\
% query. Let me know if I can assist you\\
% further. Take care Chat Doctor. R. Raveen\\
% \end{tabular} & 
% \begin{tabular}[c]{@{}l@{}p{2cm}}
% Patient: I'm a 35-year-old male and I'm\\
% having difficulty with sexual performance.\\
% My wife is unhappy with our sex life and I \\
% can only perform one round of sex. What is\\
% wrong with me and how can I improve my\\
% sexual performance?\\
% Doctor: Regular exercise, physical games,\\
% and yoga can help improve your sexual\\
% performance. It's normal to have concerns\\
% about sexual performance, and there are\\
% steps you can take to improve it. Eating\\
% low-fat home-cooked meals can also help.\\
% It's important to maintain a healthy\\
% lifestyle to improve sexual performance.
% \end{tabular} & 
% \begin{tabular}[c]{@{}l@{}p{2cm}}
%  Patient: I've been having difficulty \\
% having more than one round of sex for\\
% several years now, and my wife is\\
% concerned. Is there something wrong with\\
% me? How can I improve my sexual performance?\\
% Doctor: Regular exercise, physical games,\\
% and yoga can help improve your sexual\\
% performance. It's understandable that \\
% you're concerned about satisfying your\\
% wife sexually, and I want to reassure you\\
% that your concerns are valid. In addition\\
% to exercise, lifestyle changes such as\\
% home-cooked meals and low-fat food can \\
% also improve your sexual health. It's \\
% important to prioritize your overall health\\
% and well-being, as this can have a positive\\
% impact on your sexual performance.
% \end{tabular} \\

% \bottomrule
% \end{tabular}
% }
% \end{table*}


  