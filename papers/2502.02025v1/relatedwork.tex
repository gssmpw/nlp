\section{Related Work}
\label{sec:re_work}
% \subsection{Scenario-based ADS Testing}

In 2019, AC3R~\cite{gambi2019generating} introduced an innovative approach to scenario-based testing using crash reports. Unlike methods that rely on traffic regulations as scenario sources~\cite{sun2022lawbreaker,deng2021rmt}, AC3R constructs more challenging scenarios by leveraging detailed descriptions within crash reports. However, its limitation lies in only utilizing crash summaries, overlooking the additional map and vehicle trajectory data available in crash sketches, which reduces the realism of its scenarios. Building on this, ADEPT~\cite{wang2022adept} enhanced the process by adopting Scenic as a domain-specific language (DSL) for scenario descriptions, improving scalability. However, it also did not take full advantage of the rich details in crash sketches. Subsequently, M-CPS~\cite{zhang2023building} acknowledged the potential of multimodal models and developed an LLM-based information extraction framework to capture scene data from CCTV accident videos and reconstruct these scenes in a simulator. However, this approach focused more on analyzing video keyframes rather than using LLMs for text-based information extraction, and it struggled with the common issue of LLM hallucinations. Most relevantly, LCTGen~\cite{tan2023language} utilized LLMs as the core model for information extraction. While this approach streamlined the task, but it  failed to address LLM hallucination issues and did not incorporate crash sketches in its workflow.
\vspace{-2mm}
% In 2019, AC3R~\cite{gambi2019generating} innovatively proposed scenario-based testing using crash reports. Compared to approaches that rely on traffic regulations as scenario resources~\cite{sun2022lawbreaker,deng2021rmt}, AC3R is able to construct more challenging scenarios due to the detailed descriptions found in crash reports. However, its limitation lies in only using crash summaries while ignoring the additional map and vehicle trajectory information contained in crash sketches, which reduces the realism of the constructed scenarios. Following this, ADEPT~\cite{wang2022adept} introduced an improved workflow by adopting Scenic as the domain-specific language (DSL) for scenarios, enhancing the scalability of scenario description files, but it still failed to leverage the rich information in crash sketches. Later, M-CPS~\cite{zhang2023building} recognized the potential of multimodal large models and developed an information extraction framework based on large language models (LLMs) to extract scene information from CCTV-recorded accident videos and reconstruct the scenes in a simulator. However, the focus of this work was more on understanding video keyframes rather than utilizing LLMs for information extraction, and a major flaw in the process was the failure to address the hallucination problem common to LLMs. Similarly, in the same year, LCTGen~\cite{tan2023language} also employed LLMs as the backbone model for information extraction. Although the involvement of large models greatly simplified the task flow, LCTGen failed to tackle the hallucination issue of LLMs and did not utilize crash sketches.