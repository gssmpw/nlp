\section{Motivation}
\label{sec:motivation}

The motivation for this work can be put into two parts.
%: (1) utilizing multimodal data, including crash summaries, sketches and vehicle trajectories, to reconstruct more realistic scenes, and (2) addressing LLM hallucinations, as seen in tools like LCTGen and ADEPT, by integrating prompt engineering and self-verification to enhance accuracy in scene information extraction.

\textbf{Motivation 1: Enhancing Realism in Scene Reconstruction through Multimodal Data Integration.} Current methods that rely on crash reports often depend primarily on crash summaries, overlooking the more detailed information available in crash sketches. This reliance tends to oversimplify information extraction for test scenarios, leading to omissions in key spatial and trajectory details and consequently yielding unrealistic scene reconstructions. 
% For example, while tools such as LCTGen~\cite{tan2023language} and ADEPT~\cite{wang2022adept} are more advanced than the earlier AC3R tool~\cite{gambi2019generating}, which initially used stem dependency analysis, they still face limitations. Although these advanced tools leverage GPT models to improve data extraction efficiency, they lack access to critical map and vehicle trajectory data contained within crash sketches. As a result, these methods frequently misrepresent vehicle positioning and fail to interpret complex road interactions, creating significant gaps in scene accuracy. To illustrate this limitation, Figure ~\ref{fig:NHTSA_LCTGen} presents a crash report (Case 100343) from the NHTSA dataset, along with the scenario construction results generated by LCTGen. It's obvious that the crash summaries include only basic situational and driver behavior descriptions. In contrast, corresponding crash sketches provide precise vehicle position and directional details. Due to the lack of integrated map and trajectory data, LCTGenâ€™s vehicle behavior prediction, based solely on crash summaries, frequently misrepresents relative vehicle positioning, resulting in inaccurate scene reconstructions.
To address this gap, our research aims to extract and integrate detailed information from both crash summaries and sketches to construct a more accurate road network. Additionally, we incorporate map data(from sketches) and vehicle trajectories to develop a customized GPT model for precise trajectory planning, enabling a more concrete scene construction.


% \begin{figure}[!t]
%   \centering
%   \includegraphics[width=\linewidth]{Graphs/NHTSA_Preview.pdf}
%   \caption{Preview of NHTSA dataset and scenario replay from LCTGen}
%   \label{fig:NHTSA_LCTGen}
% \end{figure}
% % https://drive.google.com/file/d/1oyCHrmNEbhETTJ28-et3bwhOFTinPGo0/view?usp=sharing

\textbf{Motivation 2: Reducing LLM Hallucination for Precise Scene Parameter Extraction.} LLMs have demonstrated considerable potential across text generation and image recognition tasks, powered by their extensive and diverse training datasets. Their adaptability and generalization capabilities have made them foundational for numerous downstream tasks. For instance, both LCTGen and ADEPT employ GPT models for information extraction. However, it is worth noting that hallucination issues in LLMs are common, and these can substantially impact downstream task performance. 
% Unfortunately, both LCTGen and ADEPT fully trust the responses generated by these models, without strategies for mitigating hallucination, contributing to inaccuracies in scene parameter extraction and scene reconstruction. Recent techniques such as chain-of-thought prompting guide LLMs through structured, sequential tasks, showing promise for reducing hallucination. Furthermore, SELFCHECKGPT~\cite{manakul2023selfcheckgpt} demonstrates how prompt engineering, through iterative self-verification, can help models revalidate their outputs, thus mitigating hallucinations. 
Inspired by this trend, our approach incorporates prompt engineering and self-verification processes alongside multimodal large models for information extraction, reducing hallucination-related inaccuracies and enhancing the realism of scene reconstruction. Specifically, we leverage the advanced GPT-4o model to extract road networks and environmental context from crash summaries and sketches. The TrackMate model, based on ChatGPT, is enhanced with map and trajectory data to identify participant paths and is able to give realistic way point predictions. Our method not only mitigates hallucination but also bridges the existing gap in concrete information extraction and realistic vehicle trajectory prediction, thus improving the fidelity of generated scenes.
%revised by Yang: I have generated 2 motivations however I believe the discussion for each motivation can be more succinct.