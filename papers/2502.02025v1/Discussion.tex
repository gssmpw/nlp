
\section{Discussion}
\label{sec:discuss}
% In this study, we selected LCTGen as the sole baseline for comparison due to its use of the MetaDrive simulator and the same ADS policies as those in our experiments. This alignment allowed for a more equitable comparison of test generation and bug detection performance between TRACE and an existing methodology under consistent simulation conditions. While ADEPT could have been another potential baseline, we opted not to include it for several reasons. Firstly, ADEPT relies on adversarial attack techniques to expand the number of generated scenarios, which diverges from our approach focused on scenario realism and criticality rather than quantity expansion through adversarial methods. Secondly, ADEPT’s testing was conducted in the Carla simulator, which differs significantly from MetaDrive in terms of environment and scenario representation. Thus, incorporating ADEPT would introduce variables unrelated to scenario generation methodology, complicating a direct comparison. By focusing on LCTGen, we ensured a controlled, comparable environment that highlighted TRACE’s strengths in realistic scenario generation and ADS vulnerability detection.
%In this study, we select LCTGen as the baseline due to its use of the MetaDrive simulator and shared ADS policies, ensuring a fair comparison of test generation and bug detection performance between TRACE and existing methods under consistent simulation conditions. Although ADEPT was a potential alternative, we excluded it for two main reasons: first, ADEPT’s adversarial approach expands scenario quantity, diverging from our focus on scenario realism and criticality; second, ADEPT’s use of the Carla simulator would introduce environment-based variables, complicating direct comparisons. Concentrating on LCTGen allowed us to maintain a controlled environment, highlighting TRACE’s strengths in realistic scenario generation and ADS vulnerability detection.
In this study, we select LCTGen as the baseline due to its strong relevance to our work. LCTGen not only uses an LLM as a knowledge extractor but also employs the MetaDrive simulator and the same ADS system for evaluation, enabling a fair comparison of knowledge extraction accuracy from crash reports and bug detection performance. While ADEPT is another potential alternative, its focus on scenario generation quality rather than criticality, and its use of CARLA instead of MetaDrive, makes it less directly comparable. Our qualitative analysis in this study is conducted using MetaDrive and BeamNG, with plans to expand to CARLA.
\vspace{-2mm}
