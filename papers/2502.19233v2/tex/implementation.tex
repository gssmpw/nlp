


% \todo{modify the table, make it not so similar to neomem (for example, learn from PoM)}

% \todo{modify the description and table, make it not so similar to neomem}

% We build HeteroBox emulation platform on a real CXL memory system, detailed in Table \ref{table:system_config}. 
% The system setup includes a single-socket Intel$^\circledR$ Sapphire-Rapids$^\texttt{TM}$ CPU and a CXL-enabled Intel$^\circledR$ Agilex$^\texttt{TM}$-7 I-Series FPGA acting as CXL memory (CXL 1.1, Type-3 device). 
% The FPGA has dual-channel DDR4-2666 memory with 16GB capacity. 
% The host CPU is equipped with 32GB $\times 2$ dual-channel DDR5-4800 memory.
% We implement HeteroMem based on Linux kernel v6.3. 
% The CXL memory on FPGA are exposed to the software as a CPU-less NUMA node.
% In order to compare the performance of HeteroMem with other baseline memory tiering system, we hack the numa nodes enumeration code and split the CXL memory NUMA node into two fake NUMA nodes, corresponding to the fast memory and slow memory emulated by HeteroBox.
% We use Intel$^\circledR$ FPGA CXL IP (Memory Expander Type 3) and add about 7000 lines of Verilog RTL custom logic code to build HeteroMem, coupled with about 1000 lines C++ simulation environment code and about 1000 lines modification in Linux kernel for HeteroMem driver and fake numa nodes logic.
%For different fast-slow memory ratios, we adjust host memory size by reserving a specific amount of physical memory within the Linux kernel~\cite{memmap}. The default fast-slow ratio is 1:2. We disable CPU's SMT, fix the CPU clock frequency and clear the page cache before running workloads to ensure consistent performance across trials.

% Our FPGA protype of HeteroMem consumes 234.7k ALMs (25.7\%) and 1913 BRAMs (M20K, 14.4\%), no DSPs. The layout of our HeteroMem FPAG prototype is shown in Figure~\ref{fig:implementation}-(a). The red part in the layout is our HeteroMem logic, acting as an abstract layer between Intel CXL hard IP and memory controller. Figure~\ref{fig:implementation}-(b) shows a photo of our implementation platform.

% We build the HeteroBox emulation platform on a real CXL memory system, detailed in Table \ref{table:system_config}. The system setup includes a single-socket Intel$^\circledR$ Sapphire-Rapids$^\texttt{TM}$ CPU and a CXL-enabled Intel$^\circledR$ Agilex$^\texttt{TM}$-7 I-Series FPGA acting as CXL memory (CXL 1.1, Type-3 device). The FPGA is equipped with dual-channel DDR4-2666 memory with a 16GB capacity, while the host CPU has 32GB $\times$ 2 dual-channel DDR5-4800 memory.

\input{table_tex/system_config.tex}
\input{table_tex/parameters.tex}
\input{fig_tex/implementation.tex}

We build our HeteroBox emulation platform on a real CXL system, as detailed in Table \ref{table:system_config}. The system setup includes a single-socket Intel$^\circledR$ Sapphire-Rapids$^\texttt{TM}$ CPU paired with a CXL-enabled Intel$^\circledR$ Agilex$^\texttt{TM}$-7 I-Series FPGA that acts as CXL memory (CXL 1.1, Type-3 device). The FPGA is equipped with dual-channel DDR4-2666 memory with a capacity of 16GB, while the host CPU is equipped with 32GB $\times$ 2 dual-channel DDR5-4800 memory.

We implement HeteroMem based on the Linux kernel v6.3. The CXL memory on the FPGA is exposed to the software as a CPU-less NUMA node. To compare the performance of HeteroMem with other baseline memory tiering systems, we modified the NUMA nodes enumeration code and split the CXL memory NUMA node into two fake NUMA nodes, corresponding to the fast memory and slow memory emulated by HeteroBox.
We use Intel$^\circledR$ FPGA CXL IP (Memory Expander Type 3) and add about 7000 lines of Verilog RTL custom logic code to build HeteroBox and HeteroMem, along with approximately 1000 lines of C++ simulation environment code and about 1000 lines of modifications in the Linux kernel for HeteroBox and HeteroMem driver and fake NUMA nodes logic. 
We will open-source all the hardware and software codes after publication.

\input{fig_tex/mlc_bandwidth_latency.tex}

% Our FPGA prototype of HeteroMem consumes \textcolor{blue}{234.7k ALMs (25.7\%) and 1913 BRAMs (M20K, 14.4\%), with no DSPs.}\xp{remember to change if large cache is avialiable} The layout of our HeteroMem FPGA prototype is shown in Figure~\ref{fig:implementation}-(a). The red part in the layout represents our HeteroMem logic, acting as an abstraction layer between the Intel CXL hard IP and the memory controller. Figure~\ref{fig:implementation}-(b) shows a photo of our implementation platform.
% Our FPGA prototype of HeteroMem consumes 224.4k ALMs (24.6\%) and 3615 BRAMs (M20K, 27.2\%), with no DSPs. The layout of our HeteroMem FPGA prototype is shown in Figure~\ref{fig:implementation}-(a). The red part in the layout represents our HeteroMem logic, acting as an abstraction layer between the Intel CXL hard IP and the memory controller. 
% Figure~\ref{fig:implementation}-(b) shows a photo of our implementation platform. 
% Figure~\ref{fig:implementation}-(c) shows the overview of the system emulated by HeteroBox in the following evaluation. We configure the HeteroBox to emulate two memory regions in the CXL-extended memory space. We allocate the memory of applications in CXL-extended memory, while the OS memory resides in the host memory.
Our FPGA prototype of HeteroMem consumes 224.4k ALMs (24.6\%) and 3615 BRAMs (M20K, 27.2\%), with no usage of DSPs. The layout of our HeteroMem FPGA prototype is illustrated in Figure~\ref{fig:implementation}-(a), where the red part represents our HeteroMem logic. This logic acts as an abstraction layer between Intel CXL hard IP and memory controller. Figure~\ref{fig:implementation}-(b) provides a photo of our implementation platform. Finally, Figure~\ref{fig:implementation}-(c) presents an overview of the system emulated by HeteroBox for the subsequent evaluation. 
We configure HeteroBox to emulate two memory regions in CXL-extended memory space: one fast memory region and one slow memory region. Application memory is allocated in CXL-extended memory space, while OS memory remains in the host memory.




