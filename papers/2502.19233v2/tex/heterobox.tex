% To overcome these limits, we first build an emulation platform to emulate a multi-tier CXL heterogeneous memory system. Based on this emulation platform, we propose HeteroMem, a CXL-native hardware based memory tiering system. The key design philosophy of HeteroMem is to build an abstraction layer between the host CPU and memory controller located in CXL device. The hardware based abstraction layer is responsible for detecting hot data in slow memory and moving hot data to fast memory. The whole process is totally transparent to host CPU. In this section, we outline the full-stack system design of HeteroBox emulation platform and HeteroMem memory tiering system. 
% We build an emulation platform based on real-world CXL device to evaluate the performance improvement of HeteroBox compared to software method. 
% As shown in Figure \ref{fig:heterobox_system_overview}, the enumeration platform is built upon an intel Agilex 7 FPGA, which consists four main components: \textbf{Remap Table}, \textbf{Profile Unit}, \textbf{Migrate Unit} and \textbf{Latency module}. Besides, we implement software interface support for the enumeration platform, including software driver in the kernel and BAR regs in the device for configuration and debugging.

% In this section, we present the comprehensive system design of the HeteroBox emulation platform.


\subsection{Overview of HeteroBox Emulation Platform}

% \input{fig_tex/emulation_platform.tex}

% \input{table_tex/heterobox_config.tex}

% Due to the lack of commercial CXL memory device, previous memory tiering works use zero numa node to emulate the CXL memory\cite{tpp_asplos23, memtis_sosp23}. However, there exists  gap between zero numa node and CXL memory which can not be neglected. According to \cite{caption_micro23}, both the latency and bandwidth of CXL memory are different from remote NUMA node. Besides, CXL moves the memory controller to the device side, which allows more complicated modification at the device side. However, considering current available CXL supported CPU only support CXL 1.1, which still can not support CXL switch, the real CXL-based complicated heterogenous memory system are still unavailable. To emulate the performance of a complicated CXL based heterogeneous memory system, we build an emulation platform based on a system with an Intel 4$^{th}$-generation Xeon scalable CPU (Sapphire Rapids) and an Intel$^\circledR$ Agilex$^\texttt{TM}$-7 I-Series FPGA.

% As shown in Figure~\ref{fig:emulation_platform_overview}-(a), we add a latency module between the DRAM of FPGA board and the CPU host. The latency module can be configured to divide the homogeneous DRAM into several regions, each with configurable latency attribute. As shown in Figure~\ref{fig:emulation_platform_overview}-(b), the latency module is transparent to CPU host. In CPU host's view, the CXL expanded memory space is consisted of several regions with different latency attributes, which forms a complicated heterogeneous memory system.

% \textcolor{blue}{Due to the lack of commercial CXL memory devices, previous memory tiering efforts have used zero NUMA nodes to emulate CXL memory\cite{tpp_asplos23, memtis_sosp23}. However, there is a significant gap between zero NUMA nodes and CXL memory that cannot be ignored. 
% According to \cite{caption_micro23}, both the latency and bandwidth of CXL memory differ from those of remote NUMA nodes.}\xp{already declare} 
% Additionally, CXL relocates the memory controller to the device side, enabling more complex modifications at the device level. 

% However, given that currently commercially available CXL-supported CPUs only support CXL 1.1, which does not yet support CXL switches, a true CXL-based heterogeneous memory system remains unavailable. 

% However, since commercially available CXL-supported CPUs currently only support CXL 1.1, which does not include support for CXL switches, a true CXL-based heterogeneous memory system remains unavailable.

% To emulate the performance of a complex CXL-based heterogeneous memory system, we propose HeteroBox, an emulation platform to evaluate the performance of CXL-based heterogeneous memory systems, and build it on a system with an Intel 4$^{th}$-generation Xeon scalable CPU (Sapphire Rapids) and an Intel$^\circledR$ Agilex$^\texttt{TM}$-7 I-Series FPGA.


% To address this challenge, we propose HeteroBox, an emulation platform designed to evaluate the performance of CXL-based heterogeneous memory systems. HeteroBox is built on a system featuring an Intel 4$^{th}$-generation Xeon scalable CPU (Sapphire Rapids) and an Intel$^\circledR$ Agilex$^\texttt{TM}$-7 I-Series FPGA.

% As illustrated in Figure~\ref{fig:emulation_platform_overview}-(a), the main part of HeteroBox is a latency module between the DRAM of the FPGA board and the CPU host. 

% \input{table_tex/heterobox_config.tex}

Figure~\ref{fig:heterobox_overview} illustrates the overview of HeteroBox emulation platform, where a CXL-enabled host processor (e.g., Intel 4$^{th}$-generation Xeon Sapphire Rapids CPU) connects to a CXL FPGA board that manages the device memory. 
We implement the emulation logic of HeteroBox between the memory controller and CXL controller, intercepting and processing all memory read requests. 
In the following description, we refer to the request address in the host address space as hPA and the address sent to the memory controller in the device as dPA. Typically, hPA equals dPA when no additional translation logic is involved.
The requests are assigned different latency and bandwidth characteristics according to their dPA.
% We implement a set of configuration registers of HeteroBox, which control the behavior of HeteroBox, and map them to the PCIe BAR space. We build software interface at the host side, allowing users to runtime configure the behavior in HeteroBox.
% Meanwhile, users can implement their custom hardware logic in the HeteroBox emulation platform.
% Building on CXL-enabled CPU and FPGA, HeteroBox is able to accurately emulate the performance characteristics of the CXL link.
Besides, we implement configuration registers for HeteroBox, mapping them to the PCIe BAR space to control the behavior of HeteroBox. A host-side software interface allows users to configure HeteroBox at runtime.
Meanwhile, users can implement custom hardware logic (e.g., hardware-based tiered memory management unit) on the HeteroBox emulation platform. 
% Utilizing a CXL-enabled CPU and FPGA, HeteroBox accurately emulates the performance characteristics of the CXL link, while the emulation logic of HeteroBox allows it to emulate various latency and bandwidth characteristics, thus enabling HeteroBox to accurately emulating a wide range of CXL-extended heterogeneous memory system.
% Utilizing a CXL-enabled CPU and FPGA, HeteroBox accurately emulates the performance characteristics of the CXL link, while its emulation logic allows HeteroBox to emulate various latency and bandwidth characteristics.
% As a result, HeteroBox is able to accurately emulate a wide range of CXL-extended heterogeneous memory systems.
% Utilizing a CXL-enabled CPU and FPGA, HeteroBox effectively emulates the performance characteristics of the CXL link. Its emulation logic replicates various latency and bandwidth characteristics, enabling HeteroBox to accurately mimic a diverse range of CXL-extended heterogeneous memory systems.

Using a CXL-enabled CPU and FPGA, HeteroBox accurately emulates the performance characteristics of the CXL link, and its emulation logic replicates various latency and bandwidth characteristics. These capabilities allow HeteroBox to precisely model a wide range of CXL-extended heterogeneous memory systems.
% In the following section, we will detail the design of HeteroBox's emulation logic and its configuration process.
In the subsequent part of this section, we will detail the design of HeteroBox's emulation logic and its configuration process.


% The key of HeteroBox is a \textbf{Latency Unit} situated at the FPGA board, between the CXL controlling IP and the memory controller. Such a latency unit enables a heterogeneous memory space. To be specific, users could split the device memory into multiple memory regions, and each region is configured with a latency attribute that emulates a memory module.  
% As shown in Figure~\ref{fig:emulation_platform_overview}-(b), the latency unit is transparent to the CPU host. 
% From the CPU host's perspective, the CXL-expanded memory space consists of several regions with different latency attributes, forming a flattened heterogeneous memory space.


% can be configured to divide the homogeneous DRAM into several regions, each with configurable latency attributes. 
% where a consists of an CXL-enabled host processor, e.g. Intel 4$^{th}$-generation Xeon scalable CPU in Sapphire Rapids, and an 
% Intel$^\circledR$ Agilex$^\texttt{TM}$-7 I-Series FPGA.


% As illustrated in Figure~\ref{fig:emulation_platform_overview}-(a), the key of HeteroBox is a \textbf{Latency Unit} situated between the DRAM of the FPGA board and the CPU host.
% This latency module can be configured to divide the homogeneous DRAM into several regions, each with configurable latency attributes. 


\subsection{Emulation Logic Design}
% \input{fig_tex/latency_unit.tex}

% The Latency Unit create an illusion that the homogeneous DDR memory on the FPGA is devided into two heterogeneous part of memory with different latency attribute. As shown in Figure \ref{fig:latency_unit}, the Latency Unit contains a time stamp reg and a latency reg. The time stamp reg is added by one every cycle, while the latency reg can be configured by the user through CXL.io request. When a read request goes into the Latency Unit, we will first judge if its target address is located in the fast memory region. The fast memory boundary can also be configured by user through CXL.io request. If the read request is not located in the fast memory region, the latency unit will attach the time stamp, added with the latency reg, on the request as a tag. If the read request locate in the fast memory region, the latency unit will just attach a zero tag on the request. 
% In practice, the latency unit will not sent the tag to memory controller, instead, it push the tag into a fifo and maintain the correspondence of each tag and request's response. 
% When the read response is returned from memory, the latency unit first push them into a response fifo. In every cycle, the latency unit checks the tag of the first element of the response fifo to see if the value of time stamp reg is larger than it. If larger, then the latency unit pops the response out and return it as a response. 
% The design of latency unit will add a fixed latency to slow memory, thus creating an illusion that a part of memory has lower latency while the other part has higher latency. When the added latency cycles is smaller than the depth of the response fifo, the bandwidth of the slow memory is equal to fast memory, otherwise it will also showcase lower bandwidth.
The emulation logic of HeteroBox creates an illusion that the homogeneous DDR memory on the FPGA is divided into several heterogeneous parts, each with distinct latency and bandwidth characteristics. 
% As shown in Figure \ref{fig:latency_unit}, the Latency Unit contains a timestamp register and for each abstract region there is a latency register. 
% The timestamp register increments by one each cycle, while the latency registers can be configured by the user through CXL.io requests. 
As shown in the right part of Figure \ref{fig:heterobox_overview} (\textcolor{red}{\bone}), the emulation logic contains a timestamp register, and for each abstract region, there is a latency register, a bandwidth configuration register and a bandwidth counter register. The timestamp register increments by one each cycle, while the latency registers and bandwidth configuration registers can be configured by users through \texttt{CXL.io} requests.
% We consider read requests since they are on the critical path of program executing.
We focus on read requests since they are on the critical path of program execution.
% If the ready signal is high, a read request can enter the emulation logic.
% HeteroBox first checks which region the target address of this read request is located in. 
% Then it attaches the timestamp, incremented by the latency register of the memory region corresponding to the read request, to the request as a tag. 
When the ready signal is high, a read request can enter the emulation logic. HeteroBox first identifies the memory region of the dPA for the read request. It then attaches a timestamp, incremented by the latency register of the corresponding memory region, to the request as a tag. 
In practice, HeteroBox does not send the tag to the memory controller; instead, it pushes the tag into a FIFO and maintains the correspondence between each tag and the request's response.
% When the read response is returned from memory, HeteroBox first pushes it into a response FIFO. 
When the read response is returned from memory, it is first pushed into a response FIFO. 
% Every cycle, HeteroBox checks the tag of the first element in the response FIFO to see if the value of the timestamp register is larger than the tag. If it is, the Latency Unit pops the response out and returns it. 
% This design of the emulation logic adds a configurable latency to a memory region.
HeteroBox then checks the tag of the first element in response FIFO every cycle to determine if the value of the timestamp register exceeds the tag. If it does, HeteroBox pops the response out and returns it, adding a configurable latency to the region.
% For bandwidth characteristics, HeteroBox set the ready signal low when the elements number in the response FIFO is larger than the bandwidth register corresponding to the region of the incoming read request.
% For bandwidth characteristics, HeteroBox sets the ready signal low when the number of elements in the response FIFO exceeds the bandwidth register corresponding to the memory region of the incoming read request, thus blocking the incoming read request until the elements number in response FIFO is small than the bandwidth register.
% For bandwidth characteristics, HeteroBox sets ready signal low when the number of elements in response FIFO exceeds the bandwidth register for memory region of the incoming read request, blocking the incoming read request until the number of elements in response FIFO is less than the bandwidth register.


% This design changes the effective FIFO depth of the response FIFO for different memory regions, thus enabling HeteroBox to scale down the bandwidth of different memory regions proportionally.
% This approach adjusts the effective FIFO depth of the response FIFO for different memory regions, enabling HeteroBox to scale down the bandwidth of different memory regions proportionally.
% Consequently, HeteroBox can create memory regions with distinct latency and bandwidth characteristics.
% thus creating the illusion that part of the memory has lower latency while another part has higher latency. 
% When the added latency cycles are smaller than the depth of the response FIFO, the bandwidth of the slow memory is equal to that of the fast memory; otherwise, it also exhibits lower bandwidth.

% For bandwidth characteristics, HeteroBox sets the ready signal low when the number of elements in the response FIFO exceeds the bandwidth register, blocking the read request until the count drops below the bandwidth register.
% This approach adjusts the effective depth of the response FIFO for different memory regions, allowing HeteroBox to scale down bandwidth proportionally. Consequently, HeteroBox can create memory regions with distinct latency and bandwidth characteristics.

For bandwidth characteristics, HeteroBox maintains a bandwidth configuration register and a bandwidth counter register for each region. 
The bandwidth configuration register is user-configurable, while the bandwidth counter register increments by one whenever a response is returned from the corresponding region, and it resets at a user-defined interval. 
When the bandwidth counter register reaches the value set in the bandwidth configuration register for that region, HeteroBox blocks further responses from that region until the bandwidth counter register is reset in the next interval.


\subsection{Configuration Process}

% As shown in the left part of Figure~\ref{fig:heterobox_overview}, we implement a set of configuration registers in the HeteroBox emulation platform.
% These registers can control the number of memory regions, the memory address range of each memory region and the latency and bandwidth characteristics of each memory region.
% These configuration registers are mapped to PCIe BAR space at host side, allowing host to modify these configuration registers.
% The HeteroBox emulation platform supports up to 512 regions with distinct latency and bandwidth characteristics.
% We futher implement drivers in kernel space and interpreter in user space for HeteroBox configuration.
% Users can configure the HeteroBox using JSON files, of which the left part of Figure~\ref{fig:heterobox_overview} gives an example. 
% The JSON files contains the information of the number of memory regions, the region ID of each region, the start address and end address of each region, and the latency attribute in cycles (in a 200MHz clock domain) and the bandwidth attribute (effective FIFO depth of response FIFO). Users can input the JSON file to user space interpreter, and then the interpreter will phase the information in the JSON file and send it to kernel space driver. Then, the driver will write the memory in PCIe BAR space, thus finally controlling the value of configuration registers in HeteroBox.

% The HeteroBox supports up to 512 regions with different latency and bandwidth. The latency attribute of a region can be controlled by setting its latency register, while the bandwidth attribute can be controlled by setting the effective depth of response FIFO. We implement drivers for HeteroBox in kernel space and the corresponding software interface in the user space. As shown in Figure~\ref{fig:emulation_platform_overview}, the HeteroBox emulation platform can be configured using JSON configuration. 


% As shown in the left part of Figure~\ref{fig:heterobox_overview} (\textcolor{red}{\bone}), the configuration registers for HeteroBox is mapped to the PCIe BAR space of the host. 
% These registers control the number of memory regions, the address range of each region, and their latency and bandwidth characteristics. 
% The host CPU can read or write these registers through MMIO.
% The HeteroBox platform supports up to 512 regions with distinct latency and bandwidth characteristics.
% We further implement drivers in kernel space and an interpreter in user space for HeteroBox configuration. Users can configure HeteroBox using JSON files, an example of which is shown in the left part of Figure~\ref{fig:heterobox_overview} (\textcolor{red}{\bone}). These files specify the number of memory regions, region IDs, start and end addresses, latency (in clock cycles at 200MHz), and bandwidth (effective FIFO depth). The JSON file is processed by the user space interpreter, which sends the information to the kernel space driver. The driver then writes to the PCIe BAR space, thus updating the configuration registers in HeteroBox.

As shown in the left part of Figure~\ref{fig:heterobox_overview} (\textcolor{red}{\btwo}), the configuration registers for HeteroBox are mapped to the PCIe BAR space of the host. These registers control the number of memory regions, the dPA range of each region, and their latency and bandwidth characteristics. The host CPU can read or write these registers through MMIO.

The HeteroBox platform supports multiple regions with distinct latency and bandwidth characteristics. To configure HeteroBox, we implement drivers in kernel space and an interpreter in user space. Users can configure HeteroBox using JSON files, as illustrated in the left part of Figure~\ref{fig:heterobox_overview} (\textcolor{red}{\bthree}). These files specify the number of memory regions, region IDs, start and end dPAs, latency (cycles at 200MHz), and bandwidth (bandwidth configuration register). The JSON file is processed by user space interpreter, which sends the information to the kernel space driver. The driver then writes to PCIe BAR space to update configuration registers in HeteroBox.