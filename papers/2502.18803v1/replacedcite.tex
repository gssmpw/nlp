\section{Related Work}
\label{sec:relwork}
\subsection{Approximation Query Processing}

Approximate Query Processing (AQP) methods aim to return approximate answers to Online Analytical Processing (OLAP) queries with high accuracy and low computational overhead. AQNNs differ from OLAP queries fundamentally in both scope and operation. 

AQP techniques can generally be categorized into two types: online and offline. Online methods dynamically sample data at query time to compute approximate answers ____. Offline methods, on the other hand, rely on precomputed synopses such as wavelets to answer queries efficiently ____. Our method adopts a probabilistic top-k framework that distinguishes itself from these categories, which does not rely on precomputation nor does it dynamically sample data during query execution. 

\subsection{Nearest Neighbor Search}
Nearest neighbor (NN) search methods can be categorized into exact and approximate approaches. Common methods, such as brute force, k-d trees, and cell techniques, are conceptually straightforward ____. However, these methods are impractical due to their high computational cost. Exact NN search typically relies on accurate embeddings generated by expensive oracle models and builds indexes over the entire database, leading to significant computational overhead ____. 
%\laks{NN search has a long history with a lot of work, some pretty sophisticated. not sure about conceptually straighforward. let me see what we can add here.}

As databases and data dimensionality grow, approximation algorithms are used to strike a balance between accuracy and efficiency. These approaches include hashing-based ____, tree-based ____, and index-based methods ____. Additionally, ____ proposes a locality-sensitive hashing based approach and delivers sublinear query times and polynomial time processing costs, while ____ proposes space-efficient data structures guaranteeing compactness for Euclidean distances under specific accuracy constraints. FLANN ____ is a library leveraging randomized kd-trees and priority search k-means trees for scalable approximate NN finding over large datasets. Unlike our work, these approaches assume that the ground-truth representation of data objects is precomputed and can be efficiently accessed. The challenge in our problem is that the ground-truth representation needs to be computed on demand using expensive models. Recently, there has been a line of works relying cheap proxy models to approximate ground truth oracle labels and find accurate approximations of NN ____. For instance, Lai et al. propose probabilistic Top-K to train proxy models to generate oracle label distribution and output approximate Top-K solutions for video analytics ____. In ____, the authors introduce statistical accuracy guarantees, such as meeting a minimum precision or recall target with high probability, for approximate selection queries. Recently, Ding et al. introduce a  framework for approximate queries that leverages proxy models to minimize the reliance on expensive oracle models ____. They propose four algorithms to find high-quality answers for both precision-target and recall-target queries. However, these methods prioritize either precision or recall. 

Notice that while \sprintv and \sprintc build upon PQE-PT, one of the algorithms proposed in ____, for selecting nearest neighbors, our work is substantially differentiated by two key aspects. First, PQE-PT assumes a \textit{given} recall target as input and identifies neighbors that satisfy this target. In contrast, our algorithms \textit{dynamically optimize both recall and precision targets}. Second, while PQE-PT focuses on maximizing recall given a precision target, \sprintv is designed to maximize the \(\text{F}{\beta}\) score, and \sprintc aims to equalize recall and precision, which enable more accurate approximation of aggregates. Specifically, none of the algorithms in prior work including PQE-PT can achieve either of these objectives -- max \(\text{F}{\beta}\) score or equal precision and recall.

% \subsection{Hypothesis Testing}
% Hypothesis testing is an established method of statistical analysis, widely applied in many areas, including behavioral sciences and medical research ____. Existing studies focus on designing statistical tests that account for dependencies, distributions, and other characteristics of the data ____. Additionally, hypothesis testing has been applied to evaluate relationships between variables, determine causal effects, and validate assumptions in different scenarios____. For instance, Talwar et al. test hypotheses about the factors influencing the sharing of fake news on social media ____. In ____, the authors examine the relationship between students' interest in learning and their academic outcomes in natural sciences. Wang et al. extend hypothesis testing to graph data, proposing methods to test graph hypotheses based on nodes, edges, and path patterns ____. However, little attention has been given to hypothesis testing in the context of modern predictive models.

\subsection{Post-ML-Inference Processing}
General-purpose embeddings generated by machine learning models are typically trained on broader objectives, such as feature extraction or representation learning. These embeddings can be reused across various post-inference querying tasks, including anomaly detection ____, aggregation ____, and nearest neighbor search ____. Our work leverages these embeddings as proxy models to facilitate a distinct task: the approximate answering of AQNNs.