\noindent\textbf{\large{Accelerating WSI processing with Trident}} \label{sec4}

We introduce Trident\footnote{\url{https://github.com/mahmoodlab/trident/}}, a Python package for processing WSIs using pretrained foundation models for pathology. Building on the widely adopted CLAM toolbox\cite{luDataefficientWeaklySupervised2021a}, Trident addresses key limitations of its predecessor, including limited error handling, lack of support for recent foundation models at both patch and slide levels, and challenges in scaling to large repositories. To bridge this gap, Trident offers: (i) support for most WSI formats across multiple stains, (ii) a robust tissue-vs-background segmentation pipeline, (iii) access to 18 popular foundation models via a unified API, and (iv) scalable batch processing modules capable of handling thousands of WSIs.

% As most publicly available models do not follow a unified standard, users need to parse through the documentation to determine the necessary dependencies, model access, and input/output format. This issue is especially relevant for slide-level encoders\cite{wang2024chief,xu2024whole,ding2024titan}, whose usage may require metadata, such as patch coordinates and patch size.

% Trident builds on the success of the CLAM toolbox\cite{luDataefficientWeaklySupervised2021a}, which has been widely used by the computational pathology community since its release in 2021. Building on its predecessor, Trident provides a robust and modular processing pipeline, an expanded set of pretrained patch-level FMs, and access to slide encoders. Although other packages \cite{pocockTIAToolboxEndtoendLibrary2022, elnahhasWholeslideImageBiomarker2025} offer resources for  WSI processing and model training, the simplicity, scalability and modularity of Trident make it a unique tool highly optimized for large-scale slide processing.
% how to adapt it?
% we saw an opportunity to create a tool that is optimized for foundation model development. We recognize that research groups working at the frontier of FM development are likely to be accustomed to highly customized codebases, and it is impossible to develop a universal end-to-end pipeline. As a result, Trident was designed to focus on just three highly repetitive and self-contained tasks, while optimizing for code modularity, ease of use, and extensibility.

\subsection{Tissue vs. background segmentation.}
Tissue segmentation removes background regions to minimize unnecessary downstream processing. Existing packages often use image processing techniques such as binary or Otsu thresholding of pixel intensity, which typically require manual tuning. Moreover, these methods struggle to generalize beyond H\&E staining and fail to effectively separate tissue from noise and artifacts, such as penmarks or bubbles. Instead, Trident uses a segmentation model based on DeepLabV3 pretrained on the COCO dataset\cite{jaumeHEST1kDatasetSpatial2024}. The tissue segmentation can also be edited in QuPath\cite{bankheadQuPathOpenSource2017} to correct mistakes or restrict slide processing to a region-of-interest.

% The segmentation model is far more robust than naive thresholding and requires no manual tuning aside from choosing a segmentation resolution (higher resolutions are slower but may be more accurate).
% Trident has been trained on and tested with both haematoxylin and eosin (H\&E)-stained slides and immunohistochemistry slides.
% In the future, additional segmentation model checkpoints may be added for specialized stain types.

\subsection{Tissue patching.}
Post-tissue segmentation, the patching step divides the tissue-containing regions into individual image patches for later processing by a patch encoder. For efficiency, only patch coordinates are extracted, with patch images being loaded on demand during the feature extraction step. The patching step is specified using two parameters: patch size and magnification (i.e., 256 $\times$ 256-pixel patches at 20$\times$ magnification).
As retrieving metadata about the image resolution and magnification may be complex, Trident uses several heuristics to determine the raw magnification level. If all methods fail, users can manually provide the pixel resolution.

% Although patching may appear to be a relatively straightforward operation, it is complicated by the difficulty of retrieving magnification metadata from WSI files (which may have been scanned at 20x, 40x, or another magnification and stored in a wide variety of formats).

\subsection{Feature extraction.}
Trident provides model factories for easily loading pretrained patch and slide encoders and unifying inference. Trident provides off-the-shelf support for 13 publicly released patch encoders, including UNI\cite{chen2024towards}, CONCH\cite{luVisuallanguageFoundationModel2024}, Virchow\cite{vorontsov2024foundation}, among others (\Cref{tab:foundation_models}). We also support five slide encoder FMs, including Threads\cite{vaidya2024amolecular}, Titan\cite{ding2024titan}, PRISM\cite{shaikovski2024prism}, Prov-GigaPath\cite{xu2024whole} and CHIEF\cite{wang2024chief} (\Cref{tab:foundation_models}). As new models are released, they can easily be integrated into Trident with minimal effort. These pretrained FMs can either be used to extract patch and slide-level features using the provided scripts or imported into custom pipelines for inference or finetuning.

\begin{table}[t]
    \centering
    \caption{\textbf{Publicly available patch-level and slide-level foundation models supported by Trident.}
    % Trident also supports naive meanpooling of patch features as a baseline slide encoding strategy.
    }
    \begin{tabular}{cc}
    \toprule
    \textbf{Patch encoders} & \textbf{Slide encoders} \\
    \midrule
    UNI \cite{chen2024towards}                   & Threads \cite{vaidya2024amolecular}                \\
    UNIv2 \cite{chen2024towards}                   & Titan \cite{ding2024titan}                 \\
    CONCH \cite{luVisuallanguageFoundationModel2024}                  &  PRISM \cite{shaikovski2024prism}                \\
    CONCHv1.5 \cite{luVisuallanguageFoundationModel2024}              &  CHIEF \cite{wang2024chief}                 \\
    Virchow \cite{vorontsov2024foundation}                &  Prov-Gigapath \cite{xu2024whole}                 \\
    Virchow2 \cite{zimmermannVirchow2ScalingSelfSupervised2024}              &  Mean pooling         \\
    Phikon \cite{filiotScalingSelfSupervisedLearning2023}                 &                        \\
    Phikon-v2 \cite{filiotPhikonv2LargePublic2024}              &                        \\
    Prov-GigaPath \cite{xu2024whole}          &                        \\
    H-Optimus-0 \cite{saillardHOptimus02024}           &                        \\
    MUSK \cite{xiangVisionLanguageFoundation2025}                   &                        \\
    CTransPath \cite{wangTransformerbasedUnsupervisedContrastive2022}             &                        \\
    ResNet50-ImageNet \cite{heDeepResidualLearning2015}      &                        \\
    \bottomrule
    \end{tabular}
    \label{tab:foundation_models}
\end{table}

% In developing Trident, we aim to provide a scalable solution for the core part of every computational pathology workflow.
% Trident is installable via \texttt{pip}, making it convenient to import into custom workflows. 
% By standardizing and open-sourcing these components, we hope to improve interoperability and cooperation between new and existing research groups working in this field.
