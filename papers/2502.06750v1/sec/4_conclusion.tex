
\noindent\textbf{\Large{Conclusion}} 

Trident and Patho-Bench are a significant step toward better transparency and reproducibility in computational pathology.
% By open-sourcing these tools, we also aim to make the field more accessible to new researchers.
% % this has been said already. 
% Advances in foundation models now make up a significant fraction of progress in computational pathology. Recent works show that the choice of FM encoder (whether at the patch or slide level) has a substantial impact on downstream task performance. However, new model releases are typically accompanied by a relatively small collection of benchmarking tasks and datasets, which may not be representative of the breadth of diagnostic and prognostic workflows in real-world pathology. Moreover, because different labs tend to use their own custom processing and benchmarking pipelines, a fair comparison between existing FMs usually requires re-implementing and rerunning all relevant evaluations manually.
Compared with existing offerings, our codebases are optimized for FM development and conform to the principle that code simplicity and reusability are more important than handling the entire experiment lifecycle end-to-end. Moving forward, our hope is that both new and existing labs working on pathology foundation models will find these resources valuable as a common starting ground. We believe that collaboration is important for accelerating scientific progress, and therefore welcome contributions to these open-source repositories from the research community.

% We hope that this diverse set of pathology tasks, along with standardized fold assignments and test sets, is a step towards encouraging reproducible and standardized evaluations for pathology foundation models moving forward.
