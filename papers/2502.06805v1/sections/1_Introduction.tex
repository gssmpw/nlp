

\section{Introduction}

Diffusion models kickstart a new era in the field of artificial intelligence generative content (AIGC), garnering unprecedented attention~\citep{yang2023diffusionsurvey, croitoru2023diffusionvision}. Especially in the context of image synthesis tasks, diffusion models have demonstrated impressive and diverse generative capabilities. The powerful cross-modal capabilities of diffusion models have also further fueled the vigorous development of downstream tasks~\citep{chen2023diffusiondet}. Despite the increasing maturity of diffusion model variants after numerous iterations~\citep{zhang2023controlnet, xu2023versatile}, generating high-resolution complex natural scenes remains both time-consuming and computationally intensive, whether the initial pixel-level approach~\citep{ho2020denoising} or the latent space variant~\citep{rombach2022high}. Therefore, in order to optimize user-level deployment of diffusion models, researchers have never ceased their pursuit of efficient diffusion models.

% Although diffusion models are leading the next wave of AIGC, their remarkable capabilities come at substantial resource demands.
% There are two figures follow Efficient LLM need to be added.



% Due to the complex noise addition and iterative denoising sampling processes required by diffusion models~\citep{ho2020denoising}, as well as the intricate model architectures, efficient diffusion models can be approached from multiple perspectives. For the model training, efficient noise scheduling~\citep{nichol2021improved} and score matching~\citep{song2020sliced} can significantly improve the training efficiency of diffusion models. For the model inference, efficient solvers~\citep{song2020score, guo2024gaussian} and sampling schedules~\citep{pokle2022deep, song2020denoising} have been widely studied. In terms of model architecture, efficiency techniques such as quantization~\citep{he2023efficientdm, so2024temporal}, pruning~\citep{castells2024ld, zhang2024laptop}, and knowledge distillation~\citep{salimans2022progressive, luhman2021knowledge} can also enhance the efficiency of diffusion models. Additionally, efficient hardware-software co-design~\citep{chen2023speed, yang2024sda} and specialized parallelization techniques~\citep{li2024distrifusion, zhao2024dspdynamicsequenceparallelism} can further improve the efficiency of diffusion models.


%\subsection{Motivation}
Despite the growing popularity of diffusion models in recent years, one of the significant issues with diffusion model is that its multi-step denoising procedure requires numerous timesteps to reconstruct a high-quality sample from noise. This multi-step process is not only time-consuming but also computationally intensive, resulting in a heavy workload. Therefore, improving the efficiency of diffusion models is crucial. In recent years, various studies have been presented to address this problem, such as controlling the noise added during training~\citep{hang2024improved, chen2023cheaper} and selecting appropriate sampling timesteps~\citep{watson2021learning, sabour2024align}, among others.

% Therefore, the purpose of this survey is to summarize the different approaches that have been proposed to enhance the efficiency of diffusion models. We categorize these methods primarily into several strategies, such as algorithms, systems, applications, and frameworks,  providing a comprehensive overview of them.

While there are numerous comprehensive surveys on diffusion models~\citep{yang2023diffusionsurvey,chen2024overview,10081412,10419041} and those focused on specific fields and tasks~\citep{ulhaq2022efficient,lin2024diffusion,KAZEROUNI2023102846,lin2024survey,peng2024diffusion,daras2024surveydiffusionmodelsinverse}, discussions on the efficiency of diffusion models are notably scarce. The only existing survey addressing efficiency~\citep{ma2024efficient} serves as an initial exploration in this area. In our work, we provide a more comprehensive and detailed taxonomy of efficient techniques, covering a broader and more recent collection of research papers.

The overarching goal of this survey is to provide a holistic view of the technological advances in efficient diffusion models from \textbf{algorithm-level}, \textbf{system-level}, \textbf{application}, and \textbf{framework} perspectives, as illustrated in Figure~\ref{fig:efficient_diffusion_structure}. These four categories cover distinct yet interconnected research topics, collectively providing a systematic and comprehensive review of efficient diffusion models research. Specifically,

\begin{itemize}
\item \textbf{Algorithm-Level Methods:} Algorithm-level methods are critical for improving the computational efficiency and scalability of diffusion models, as their training and inference processes are often resource-intensive. In §\ref{sec:algorithm}, we survey efficient techniques that cover research directions related to efficient training, efficient fine-tuning, efficient sampling, and model compression.
%
\item \textbf{System-Level Methods:} System-level methods aim to optimize the infrastructure and computational resources required for training and deploying diffusion models. In §\ref{sec:system}, we survey efficient techniques that cover research directions related to optimized hardware-software co-design, parallel computing, and caching techniques.
%
\item \textbf{Applications:} Applications of diffusion models span various domains, where efficiency directly impacts their practical usability. Tailored techniques are required to optimize the performance of diffusion models for these specific tasks without sacrificing quality. In §\ref{sec:application}, we survey efficient techniques that focus on image generation, video generation, text generation, audio generation, and 3D generation.
%
\item \textbf{Frameworks:} The advent of diffusion models necessitates the development of specialized frameworks to efficiently handle their training, fine-tuning, inference, and serving. While mainstream AI frameworks such as TensorFlow and PyTorch provide the foundations, they lack built-in support for specific optimizations and features crucial for diffusion models. In §\ref{sec:framework}, we survey existing frameworks specifically designed for efficient diffusion models, covering their unique features, underlying libraries, and specializations.
\end{itemize}

In addition to the survey, we have established a GitHub repository where we compile the papers featured in this survey at \href{https://github.com/AIoT-MLSys-Lab/Efficient-Diffusion-Model-Survey}{https://github.com/AIoT-MLSys-Lab/Efficient-Diffusion-Model-Survey}. We will actively maintain it and incorporate new research as it emerges.


%In the second section of our survey, we investigate efficient diffusion models from the algorithm perspective, covering efficient training, efficient sampling, and compression. The third section explores the system perspective, focusing on hardware-software co-design, parallelization, and cache optimization. In the fourth section, we review representative applications of diffusion models. Finally, in the fifth section, we investigate the widely used implementation frameworks for efficient diffusion models.




\begin{figure*}[t!]
	\centering
	\resizebox{\textwidth}{!}{
		\begin{forest}
			forked edges,
			for tree={
				grow=east,
				reversed=true,
				anchor=base west,
				parent anchor=east,
				child anchor=west,
				base=center,
				font=\large,
				rectangle,
				draw=hidden-draw,
				rounded corners,
				align=left,
				text centered,
				minimum width=4em,
				edge+={darkgray, line width=1pt},
				s sep=3pt,
				inner xsep=2pt,
				inner ysep=3pt,
				line width=0.8pt,
				ver/.style={rotate=90, child anchor=north, parent anchor=south, anchor=center},
			},
			where level=1{text width=12em, font=\normalsize}{},
			where level=2{text width=18em, font=\normalsize}{},
			where level=3{text width=16em, font=\normalsize}{},
			where level=4{text width=18em, font=\normalsize}{},
			where level=5{text width=18em, font=\normalsize}{},
			[
				\textbf{Efficient Diffusion}, ver
                    [
					\textbf{Application (§\ref{sec:application})} , fill=green!10
     				[
						\textbf{Image Generation (§\ref{sec:image_generation})}, fill=green!10
					]
					[
						\textbf{Video Generation (§\ref{sec:video_generation})}, fill=green!10
					]
					[
						\textbf{Text Generation (§\ref{sec:text_generation})}, fill=green!10
					]
     				[
						\textbf{Audio Generation (§\ref{sec:audio_generation})}, fill=green!10
					]
     				[
						  \textbf{3D Generation (§\ref{sec:3d_generation})}, fill=green!10
					]
				]
				[
					\textbf{Algorithm (§\ref{sec:algorithm})}, fill=blue!10
					[
						\textbf{Efficient Training (§\ref{sec:efficient_training})}, fill=blue!10
						[
							\textbf{Noise Schedule}, fill=blue!10
						]
						[
							\textbf{Score Matching}, fill=blue!10
						]
						[
							\scalebox{0.9}{\textbf{Data-Dependent Adaptive Priors}}, fill=blue!10
						]
						[
							\textbf{Rectified Flow}, fill=blue!10
						]
					]
					[
						\textbf{Efficient Fine-tuning (§\ref{sec:efficient_finetuning})}, fill=blue!10
						[
							\textbf{LoRA}, fill=blue!10
						]
						[
							\textbf{Adapter}, fill=blue!10
						]
						[
							\textbf{ControlNet}, fill=blue!10
						]
					]
					[
						\textbf{Efficient Sampling (§\ref{sec:efficient_sampling})}, fill=blue!10
						[
							\textbf{Efficient Solver}, fill=blue!10
							[
								\textbf{SDE Solver}, fill=blue!10
							]
							[
								\textbf{ODE Solver}, fill=blue!10
							]
						]
						[
							\textbf{Sampling Scheduling}, fill=blue!10
							[
								\textbf{Parallel Sampling}, fill=blue!10
							]
							[
								\textbf{Timestep Schedule}, fill=blue!10
							]
						]
						[
							\textbf{Partial Sampling}, fill=blue!10
							[
								\textbf{Early Exit}, fill=blue!10
							]
							[
								\textbf{Retrieval-Based Diffusion}, fill=blue!10
							]
						]
					]
					[
						\textbf{Compression (§\ref{sec:compression})}, fill=blue!10
						[
							\textbf{Quantization}, fill=blue!10
           						[
    								\textbf{Post-Training Quantization}, fill=blue!10
    							]
    							[
    								\textbf{Quantization-Aware Training}, fill=blue!10
    							]
						]
						[
							\textbf{Pruning}, fill=blue!10
						]
						[
							\textbf{Knowledge Distillation}, fill=blue!10
           						[
    								\textbf{Vector Field Distillation}, fill=blue!10
    							]
    							[
    								\textbf{Generator Distillation}, fill=blue!10
    							]
						]
					]
				]
				[
					\textbf{System (§\ref{sec:system})}, fill=orange!10
					[
						\textbf{Hardware-Software Co-Design (§\ref{sec:codesign})} , fill=orange!10
					]
					[
						\textbf{Parallel Computing (§\ref{sec:parallel_computing})} , fill=orange!10
					]
					[
						\textbf{Caching Technique (§\ref{sec:caching_technique})} , fill=orange!10
					]
				]
                    [
                        \textbf{Frameworks (§\ref{sec:framework})}, fill=lime!10
                        [
                            Diffusers{,}
                            DALL-E{,}
                            OneDiff{,}
                            LiteGen{,}
                            InvokeAI{,}
                            Comfy UI-Docker{,}
                            Grate{,}
                            DifFUSER{,}
                            \\Versatile Diffusion{,}
                            UniDiffuser, text width=43em, fill=lime!10
                        ]
                    ]
			]
		\end{forest}
	}
	\caption{Taxonomy of efficient diffusion model literature.}
	\label{fig:efficient_diffusion_structure}
\end{figure*}
