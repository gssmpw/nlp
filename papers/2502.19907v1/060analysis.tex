\input{tau} 
\subsection{Condition Augmentation with Varying Shuffling Degrees}
To investigate the effects of premise order transformations, we divide the Kendall tau distance \( \tau \) between different premise orders and the original order into 10 groups, each spanning a 0.2 range within [-1,1). A \( \tau \) value of 1 indicates forward order, -1 indicates a complete reversal, and 0 represents  a more uniform shuffling. Additionally, random shuffle means that \( \tau \) values from the entire range may be included. We conduct experiments on RuleTaker using different \( \tau \) values for condition-based data augmentation.

As shown in Tab. \ref{tab:tau}, random shuffling provides the best performance across all \( \tau \) values. The level of perturbation in premise order significantly affects model accuracy,  with differences exceeding 10\%. LLaMA3-8B-Instruct excels with negative \( \tau \) values, while LLaMA2-13B-Chat and Mistral-7B-Instruct-v0.3 do better with positive \( \tau \) values. Random shuffled in training data achieves the best overall performance, emphasizing the value of diverse data augmentation for more flexible and robust models.


\input{DAG_or_not}
\subsection{The Importance of DAG-based Step Dependency}
\label{sec:non_DAG}
To explore the importance of using DAG for step dependencies in step augmentation, we use the Answer Step Shuffled data from Tab. \ref{tab:Data_statistics} as a baseline. We randomly shuffle the steps in the original COT process and assess its performance to evaluate the impact of random step reordering without DAG dependencies.

As shown in Tab. \ref{tab:DAG_or_not}, not utilizing DAG dependencies leads to a performance drop compared to DAG-based augmentation. The decline is particularly severe on FOLIO, where LLaMA3-8B-Instruct and LLaMA2-13B-Chat show a drop of 7.64\% and 4.68\% in the shuffled test. In contrast, Ruletaker and LogicNLI experience a smaller decline. 

To explore the underlying cause of this phenomenon, we investigate the degree of dependency between steps in the step dependency DAG. We introduce the \textbf{Topological Freedom Index (TFI)}. This metric measures how loosely or tightly connected a DAG is, and it is calculated as follows:
\begin{equation}
TFI = \frac{\text{Number of valid sequences}}{\text{Factorial of the number of steps}}
\end{equation}

Number of valid sequences represents the number of valid topological orderings that respect the dependency constraints within the DAG. Factorial of the number of steps corresponds the number of possible orderings if no dependencies were present.
The closer the TFI value is to 1, the looser the DAG structure, indicating higher reordering flexibility and greater step independence. Conversely, the closer the TFI value is to 0, the stronger the step dependencies, meaning the sequence must follow a strict order with little to no flexibility. Fig. \ref{fig:pie_TFI} presents the TFI distribution across three datasets, illustrating the degree of step dependency in different reasoning tasks.

\input{pie_TFI}
In FOLIO, the majority of samples (49.9\%) fall within the 0.0–0.1 range, indicating strong dependency constraints and minimal reordering flexibility. In contrast, RuleTaker and LogicNLI exhibit a significantly higher proportion of high-TFI samples (e.g., 44.0\% and 27.0\% in the 0.9–1.0 range, respectively), suggesting that these datasets contain more loosely connected reasoning structures. These trends highlight that FOLIO imposes stricter logical dependencies. In contrast, the latter datasets have weaker step dependencies, offering greater reordering flexibility. However, this may also imply that the quality of the generated COT needs improvement.

The difference in TFI across datasets aligns with the conclusions we obtained from the Random Step Shuffled experiment. Specifically, stronger step dependencies result in greater performance loss from random shuffling. Therefore, when performing answer order augmentation, it is important to maintain the integrity of these dependencies.

\subsection{Combined Condition and Step Shuffling Leads to Performance Degradation}
\label{sec:both_ran}
To investigate the combined effect of condition and step order augmentation, we apply an additional premise shuffle to Answer Steps Shuffled data, adjusting premise references in the answers accordingly. As shown in Tab. \ref{tab:DAG_or_not}, \textbf{Condition\&Answer Shuffled} results in lower performance compared to Answer Steps Shuffled alone.

We believe the key reason is that premise and step shuffling serve different learning purposes. Premise shuffling enables the model to recognize that independent conditions with commutativity can lead to the same answer, while step shuffling allows it to understand that different reasoning paths under the same condition can yield consistent conclusions. When applied separately, each augmentation enhances the model's understanding of logical equivalence, thereby improving its overall reasoning ability. However, when condition and step shuffling are applied together, the logical structure is perturbed in two ways, requiring the model to simultaneously align different orders of both conditions and steps, increasing learning difficulty and reducing generalization. This suggests that excessive augmentation may introduce noise, making it harder for models to establish logical equivalence.

\subsection{Effect of Augmentation Frequency}
In the main experiment, we set \( |D_C'| = |D_C| \), meaning that the parameter \( k = 1 \).
To investigate the impact of augmentation quantity, we increase \( k \) and generate \( k = 5 \) augmented instances for each original training sample in RuleTaker. 
This leads to an augmented dataset \( D_C' \) containing \( 5 \times |D_C| \) instances. 
As shown in Tab. \ref{tab:condition_variants}, adding a few shuffled instances improves model accuracy, but excessive augmentation results in performance degradation. This highlights the need to control the augmentation frequency. The increase in \( k \) can lead to a certain degree of performance improvement, indicating that our order-centric data augmentation method has room for further enhancement.

\input{condition_variants}