\input{method}

\subsection{Order Effect of Language Models}
Large language models are sensitive to reasoning order. While word order variations in natural language have little impact~\cite{cao2023unnatural,abdou2022word}, disrupting the order in reasoning tasks significantly degrades performance. \citet{chen2024premise} show that models perform optimally only when the premise order matches the sequence required for the reasoning process. To address this, \citet{liu2024conciseorganizedperceptionfacilitates} propose reorganizing premise order to reduce order sensitivity. However, this approach is task-specific and lacks generalizability.
Furthermore, the Reversal Curse reveals that models fail to grasp logical equivalence when trained with a fixed linguistic order~\cite{berglund2023reversal}. \citet{golovneva2024reverse} mitigate this by proposing reverse training, where LLMs learn both forward and reverse reasoning by randomly shuffling words or segments within a sentence. This highlights the need for diverse training data with varied orderings.

Compared to the above works, we extend to more complex logical reasoning scenarios, building upon this concept by leveraging commutativity for data augmentation in logical reasoning, which helps models generalize across different reasoning structures and enhances robustness.

\subsection{Logical Reasoning Enhancing}
Existing methods to enhance LLMs' logical reasoning ability mainly fall into three categories: integrating symbolic reasoning, training and inference strategies, and leveraging data augmentation.

Symbolic reasoning enhances LLMs by transforming natural language into formal logic, providing a symbolic approach that helps models understand logic~\cite{olausson2023linc,xu2024faithful,zhang2023improved}. Training and inference strategies use adversarial pre-training, contrastive learning, and multi-step explicit planning to improve training efficiency and reasoning effectiveness~\cite{pi2022logiganlearninglogicalreasoning,jiao2022merit,zhao2023explicitplanninghelpslanguage}. 
% Data augmentation creates diverse training and testing data, aiding models in generalizing better across logical tasks~\cite{han2022folio,tafjord2021proofwritergeneratingimplicationsproofs,clark2020transformerssoftreasonerslanguage}. Benchmarks like LogiGLUE~\cite{luo2023towards} and LogicBench~\cite{parmar2024logicbench} evaluate LLMs on various reasoning patterns, highlighting their limitations in handling complex reasoning and negation.
ata augmentation creates diverse training and testing data, aiding models in generalizing better across logical tasks~\cite{han2022folio,tafjord2021proofwritergeneratingimplicationsproofs,clark2020transformerssoftreasonerslanguage}. 
LogiGLUE~\cite{luo2023towards} builds a large-scale logical benchmark through instruction fine-tuning across deductive, abductive, and inductive tasks.
LogicBench~\cite{parmar2024logicbench} focuses on single-rule inference, evaluating LLMs on 25 reasoning patterns and exposing their weaknesses in complex reasoning and negation handling.

Our work falls into the last category. Unlike the previous approaches, we perform order-centric data augmentation on existing logical reasoning datasets, leveraging logical commutativity to enhance the model's understanding of logical equivalence and improve overall logical reasoning ability.