% 1. 逻辑推理对大模型很重要
% 2. LLM对于逻辑等价变换很敏感。
% 3. 然而，现有增强LLM逻辑的方法都并没有关注到等价性 a. evaluation b. symbolic-NL映射/translation c. 避免额外的信息干扰
% 4. 逻辑推理的核心特质是independency + commutativity。independency—


% 提出逻辑推理对大模型的重要性
Large language models (LLMs) have demonstrated exceptional performance across various real-world applications~\cite{jaech2024openai,dubey2024llama,liu2024deepseek}. Logic reasoning~\cite{Cummins1991-CUMCRA-2} is essential for LLMs. It allows models to draw valid conclusions, maintain coherence, and make reliable decisions across tasks~\cite{pan2023logic,liu2023evaluating}.

% LLMs 对逻辑序列极为敏感，难以灵活适应等价的逻辑结构。当前的 LLMs 更多依赖模式记忆和惯性进行推理，而非掌握逻辑推理的结构性特征。
% 下降了多少，用数据
However, LLMs are sensitive to reasoning order and struggle with logically equivalent transformations~\cite{chen2024premise,berglund2023reversal,tarski1956logic}. First, the models are highly sensitive to the order of premises, with perturbing the order leading to up to a 40\% performance drop~\cite{chen2024premise,liu2024conciseorganizedperceptionfacilitates}. Additionally, if the testing order is reversed compared to the training order, accuracy drops drastically. For example, in the case of data involving two entities within a single factual statement, accuracy drops from 96.7\% to 0.1\% when training is left-to-right and testing is right-to-left.~\cite{berglund2023reversal,berglund2023taken,allen2023physics}. This suggests that LLMs follow a rigid logical reasoning order driven by learned patterns rather than true logical understanding.


\input{order_intro}
% 然而，现有增强LLM逻辑的方法都并没有解决等价变化很敏感的问题 a. evaluation b. symbolic-NL映射/translation c. 避免额外的信息干扰
Existing LLM logical data augmentation methods do not effectively address the sensitivity to equivalent transformations. First, many logical datasets are specifically designed for certain domains, such as specialized fields or exam questions, primarily to broaden the scope of logical reasoning data collection and application~\cite{han2022folio,liu2020logiqa,yu2020reclor}. Second, a line of work aims to enhance the model's reasoning by mapping natural language to symbolic reasoning~\cite{olausson2023linc,xu2024faithful,pan2023logic}, but it primarily provides symbolic tools for understanding logical language rather than enhancing the logical structure itself. Lastly, another augmentation method creates a ``vacuum'' world to block interference from real-world logic~\cite{saparov2022language}, but it focuses on the impact of the model’s prior experience on reasoning, without addressing the design of logical equivalence.


In fact, \textbf{commutativity} is a crucial property of logical reasoning. As established by Gödel’s completeness theorem~\cite{godel1930completeness} and Tarski’s model theory~\cite{tarski1956logic}, commutativity means that independent logical units can be freely reordered without changing the essence of the logical structure. Therefore, in logical reasoning, first, independent premises are commutative. As shown in the upper half of Fig. \ref{fig:order_intro}, different orders of premises represent equivalent problem structures. Furthermore, as demonstrated by Gentzen’s proof theory~\cite{gentzen1935proof}, reasoning steps are also commutative, provided their dependencies are intact. As shown in the lower half of Fig. \ref{fig:order_intro}, changing the order of steps without disrupting the dependencies results in an equivalent reasoning process. However, altering the order of dependent steps disrupts inference and prevents a coherent path to the correct conclusion.


% 我们提出了一种基于逻辑乱序的数据增强框架。对于条件/回答步骤进行乱序。
% order-centric亦谓之为中心的
% teach-enable……
% 所有的说法都要统一，先给一个定义
In this work, we propose an order-centric data augmentation framework that explicitly incorporates logical commutativity into LLM training. For condition order, we randomly shuffle all independent premises. For reasoning steps, we construct a structured, step-by-step reasoning process, identify step dependencies using a directed acyclic graph (DAG), and apply topological sorting to reorder reasoning steps while preserving logical dependencies. Order-centric data augmentation allows models to learn logical equivalence through commutativity, leading to a deeper understanding of logic, rather than relying solely on fixed patterns to solve problems. Our experiments show that order-centric augmentation outperforms training on datasets with a fixed logical structure, enhancing the model's overall reasoning ability and improving its performance in complex shuffled testing scenarios.

% 贡献：提出了一种基于条件乱序和回答步骤乱序的逻辑推理数据增强方法/构建了逻辑推理过程中条件与推理步骤之间的依赖关系建模机制/系统性实验，验证了所提出方法的有效性
Our contributions are summarized as follows:
(1) We propose an order-centric logic data augmentation method based on commutativity, which permutes both condition order and reasoning step order, helping models gain a deeper understanding of logical equivalence.
(2) We introduce a method that uses DAGs to model the dependencies between reasoning steps, helping to identify valid step reorderings.
(3) We conduct extensive experiments to prove the effectiveness of our approach in enhancing logical reasoning.
