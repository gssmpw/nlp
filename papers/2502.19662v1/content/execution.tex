%{\bf Peh: So far, there's no mention of how you set DVFS for the different weights, and granularity. I presume it'll be mentioned here? With DVFS assumptions for TPU and GPU in Section VA? Some discussion on overclocking}
\subsection{Adaptive DVFS Strategy}
\label{section:execution}

\subsubsection{DVFS for Outliers and Salient features}
\noindent \textbf{Packaging of Salient and Outlier Weights:}
\begin{comment}
Salient and outlier weights exhibit extreme sparsity and are packaged for efficient computation using a Sparse Matrix-Vector Multiplication (SpMV) engine. Given this hypersparsity, the weight matrix is represented using a compact format: a value vector $val$ containing all non-zero elements and an index vector $idx$ indicating their column positions. This approach minimizes memory usage and accelerates operations. The matrix-vector multiplication $A \times b$ for a dense vector $b \in \mathbb{R}^k$ is computed as:
\end{comment}
Salient and outlier weights, exhibiting extreme sparsity, are packaged for efficient computation using a Sparse Matrix-Vector Multiplication (SpMV) engine. The hypersparse weight matrix is compactly stored with a value vector $val$ for non-zero elements and an index vector $idx$ for column positions, reducing memory usage and accelerating computations. The matrix-vector multiplication $A \times b$ for a dense vector $b \in \mathbb{R}^k$ is performed as:
\[\text{res}[i] = \text{val}[i] \times b[\text{idx}[i]], \quad \text{for } i = 0, 1, \ldots, m - 1,\]
where $res$ is the result vector, efficiently leveraging the matrix’s sparsity.

\noindent \textbf{DVFS Configuration Selection:}
These uniformly quantized hypersparse weights span the entire 8-bit range, necessitating DVFS settings that respect the critical-path delay for all possible weight values. Guided by MAC characteristic trends, the optimal voltage-frequency \( (V, f) \) point is selected to minimize energy consumption while ensuring timing constraints are met:
\[(V, f) = \arg\min_{(V_i, f_i)} \left[ E(V_i, f_i) \right] \quad\text{given} (1/f_i) \geq \text{Critical Path}\]
This approach ensures efficient system performance without sacrificing model fidelity.

\subsubsection{DVFS for High- and Low-Sensitivity Weights}
\begin{table}[h!]
\centering
%\renewcommand{\arraystretch}{0.9} % Adjust row height
%\setlength{\tabcolsep}{4pt}       % Adjust column separation
\resizebox{\columnwidth}{!}{
\begin{tabular}{c|c}
\hline
\textbf{Hardware}       & \textbf{DVFS Levels (Voltage, Frequency)} \\ \hline
GPU                     & (0.9 V, 1.5 GHz), (1.0 V, 2.0 GHz), (1.1 V, 2.8 GHz) \\
Systolic Array (TPU)    & (1.0 V, 1.9 GHz), (1.1 V, 2.4 GHz), (1.2 V, 3.7 GHz)\\ \hline
\end{tabular}
}
\caption{Assumed DVFS levels for GPUs and Systolic Arrays.}
\label{tab:dvfs_levels}
\end{table}

For non-uniformly quantized weights on the systolic array, weight tensors are divided into $128\times128$ tiles, with DVFS settings determined by the tile sensitivity mapping strategy as outlined in Sec.\ref{section:crit_quant}. This tile size aligns with the architecture of modern systolic arrays in TPUs and is critical for balancing the tradeoff between accuracy and performance, optimizing energy efficiency while preserving precision.
The assumed DVFS levels for both GPUs and systolic arrays are summarized in Table~\ref{tab:dvfs_levels}. We base our DVFS levels on practical hardware parameters: for GPUs, using NVIDIA's publicly available maximum clock frequency of 2.8 GHz~\cite{gpu_max_frequency}, and for systolic arrays (similar to those present in TPUs), deriving levels from MAC characteristics (see Sec.\ref{section:motivation}).
%We base our DVFS assumptions on practical hardware parameters: for GPUs, using NVIDIA's publicly available maximum clock frequency of 2.8 GHz~\cite{gpu_max_frequency}, with DVFS levels at (0.9 V, 1.5 GHz), (1.0 V, 2.0 GHz), and (1.1 V, 2.8 GHz). For systolic arrays, similar to those present in TPUs, we derive DVFS levels from MAC characteristics, assuming (1.0 V, 1.8 GHz), (1.1 V, 2.4 GHz), and (1.2 V, 3.7 GHz).

\begin{comment}
\noindent \textbf{High-Sensitivity Tiles:} These tiles are optimized for accuracy, with DVFS settings ($V_i$,$f_i$) chosen to minimize accuracy loss, where $V_i$ is the supply voltage and $f_i$ the operating frequency. The selection formula is:
\[(V_i, f_i) = \arg\min_{(V_j, f_j)} \left[ \Delta \text{Accuracy}(V_j, f_j) \right]\]
These settings ensure precision, even at higher energy costs.
\end{comment}

\noindent \textbf{High-Sensitivity Tiles:} These tiles are composed of critical weights that are crucial for maintaining model accuracy. As discussed in Sec.\ref{section:motivation}, the \texttt{DW02\_MAC} unit handles 16 high-sensitivity weights, operating at a frequency of 2.4 GHz. These tiles are exclusively made up of these 16 values to ensure precision. The execution is performed at specific DVFS settings ($V_i$,$f_i$), where $1/f_i \ge$ the critical delay associated with these weights. While this configuration may lead to higher energy consumption, it significantly boosts tile performance by overclocking the accelerator's global clock to meet the precise timing requirements of these weights.%{\bf Peh: Sounds like u now do DVFS and not just DFS. Do have a table of the Vi, Fi assumed for the TPU and GPU targets, or at least mention the number of levels, and range. This is to counter reviewers claiming that assumptions of DVFS settings are impractical}

\begin{comment}
\noindent \textbf{Low-Sensitivity Tiles:} Optimized for performance and energy efficiency, selecting configurations that maximize speed and minimize energy:
\[(V_i, f_i) = \arg\min_{(V_j, f_j)} \left[ \frac{E(V_j, f_j)}{\text{Performance}(V_j, f_j)} \right]\]
This approach leverages MAC characteristics to balance efficiency and computational speed.
\end{comment}
\noindent \textbf{Low-Sensitivity Tiles:} These tiles are subjected to aggressive overclocking to maximize performance. As detailed in Sec.\ref{section:motivation}, they contain only 9 weights, each capable of operating at frequencies up to 3.7 GHz. The DVFS settings are fine-tuned to respect the critical-path delay only for these 9 weights. Despite the high overclocking, the energy increase remains incremental, as switching occurs primarily along the shortest paths in the circuit.

By leveraging MAC characteristics, this approach achieves an efficient trade-off between processing speed and energy consumption, optimizing the use of the accelerator’s resources.
