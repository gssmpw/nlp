\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%Template version as of 6/27/2024

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
%\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\include{config}
\begin{document}

%\title{Systolic Xtreme: Selecting Low-Critical-Delay Weights for Accelerating LLM Inference}
\title{HALO: \underline{H}ardware-\underline{a}ware quantization with \underline{lo}w critical-path-delay weights for LLM acceleration}

\begin{comment}
\author{\IEEEauthorblockN{Rohan Juneja}
\IEEEauthorblockA{\textit{School of Computing} \\
\textit{National University of Singapore}\\
rohan@comp.nus.edu.sg}
\and
\IEEEauthorblockN{Shivam Aggarwal}
\IEEEauthorblockA{\textit{School of Computing} \\
\textit{National University of Singapore}\\
shivam@comp.nus.edu.sg}
\and
\IEEEauthorblockN{Safeen Huda}
\IEEEauthorblockA{\textit{Google}\\
safeen@google.com}
\and
\IEEEauthorblockN{Tulika Mitra}
\IEEEauthorblockA{\textit{School of Computing} \\
\textit{National University of Singapore}\\
tulika@comp.nus.edu.sg}
\and
\IEEEauthorblockN{Li-Shiuan Peh}
\IEEEauthorblockA{\textit{School of Computing} \\
\textit{National University of Singapore}\\
peh@comp.nus.edu.sg}
}
\end{comment}

\author{
    \IEEEauthorblockN{
        Rohan Juneja\IEEEauthorrefmark{1},
        Shivam Aggarwal\IEEEauthorrefmark{1},
        Safeen Huda\IEEEauthorrefmark{2}
        Tulika Mitra\IEEEauthorrefmark{1},
        Li-Shiuan Peh\IEEEauthorrefmark{1},
    }
    \\
    \IEEEauthorblockA{\IEEEauthorrefmark{1}School of Computing, National University of Singapore, \IEEEauthorrefmark{2}Google\\ 
    \{rohan, shivam, tulika, peh\}@comp.nus.edu.sg, 
    safeen@google.com}
}

\maketitle

\begin{comment}
\begin{abstract}
The rapid expansion of Transformer-based models has significantly outpaced advancements in hardware, leading to increased inference costs.
To address the gap between growing model sizes and hardware limitations, model quantization presents a promising solution. 
However, current quantization techniques do not account for the critical path variations in Multiply-Accumulate (MAC) operations, which differ significantly with each weight value due to the iterative shift-add architecture of MAC units.
This paper introduces Systolic Xtreme (SystolicX), a novel hardware-software co-design aimed at accelerating models on Systolic Arrays by leveraging unique frequency scaling opportunities.

SystolicX capitalizes on the relationship between weight values and their effective critical path timing at runtime. 
It proposes a Hardware-Aware Post-Training quantization framework that incorporates hardware accelerator timing and power analysis. 
This framework strategically quantizes model weights, prioritizing those with lower critical delay, thereby reducing the circuit's overall critical delay. 
This reduction enables dynamic frequency adjustment to higher clock frequencies, achieving significant performance and energy improvements.
SystolicX demonstrates the potential to deliver up to ?? times speedup and ?? power savings, all without compromising accuracy and with minimal area overhead.
\end{abstract}
\end{comment}

\begin{abstract}
%Cambrian explosion of accelerators for LLMs has fragmented the hardware landscape, highlighting the need to optimize existing platforms over developing bespoke solutions. 
Quantization is critical for realizing efficient inference of LLMs.
Traditional quantization methods are hardware-agnostic, limited to bit-width constraints, and lacking circuit-level insights, such as timing and energy characteristics of Multiply-Accumulate (MAC) units. We introduce \textit{HALO}, a versatile framework that adapts to various hardware through a Hardware-Aware Post-Training Quantization (PTQ) approach. By leveraging MAC unit properties, \textit{HALO} minimizes critical-path delays and enables dynamic frequency scaling. Deployed on LLM accelerators like TPUs and GPUs, \textit{HALO} achieves on average 270\% performance gains and 51\% energy savings, all with minimal accuracy drop.
%{\bf Peh: Why is there area overhead?}
\end{abstract}
\begin{IEEEkeywords}
LLMs, Quantization, DVFS, TPUs, GPUs
\end{IEEEkeywords}

\input{content/introduction}
\input{content/background}
%\input{content/motivation}
\input{content/quantization}
\input{content/execution}
%\clearpage
\input{content/evaluation}
%\clearpage
\input{content/relatedworks}
\input{content/conclusion}

\clearpage
\sloppy  % Enable relaxed line breaking
\bibliographystyle{IEEEtran}
\bibliography{refs}

\end{document}
