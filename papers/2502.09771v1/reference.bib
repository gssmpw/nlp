@misc{homepage,
year={https://github.com/ShuyinOuyang/DSrepair}
}

@misc{gptmodel,
year={https://platform.openai.com/docs/models}
}

@misc{codestral,
year={https://mistral.ai/news/codestral/}
}

@misc{promptcompetition,
year={https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41}
}

@misc{numpy,
year={https://numpy.org/doc/stable/index.html}
}

@misc{pandas,
year={https://pandas.pydata.org/docs/index.html}
}

@misc{scipy,
year={https://docs.scipy.org/doc/scipy/index.html}
}

@misc{sklearn,
year={https://scikit-learn.org/stable/}
}


@misc{matplotlib,
year={https://matplotlib.org/}
}

@misc{pytorch,
year={https://PyTorch.org/}
}

@misc{tensorflow,
year={https://www.tensorflow.org/}
}

@misc{lucene,
year={https://lucene.apache.org/}
}

@misc{upsetplot,
year={https://en.wikipedia.org/wiki/UpSet\_plot}
}

@misc{fuseki,
year={https://jena.apache.org/documentation/fuseki2/}
}

@misc{sparql,
year={https://www.w3.org/TR/sparql11-query/}
}

@misc{exact_match,
year={https://huggingface.co/spaces/evaluate-metric/exact\_match}
}

@article{prudhommeaux2008sparql,
  title={SPARQL query language for RDF},
  author={Prudhommeaux, Eric},
  journal={http://www. w3. org/TR/rdf-sparql-query/},
  year={2008}
}

@inproceedings{liang2022misusehint,
  title={MisuseHint: A Service for API Misuse Detection Based on Building Knowledge Graph from Documentation and Codebase},
  author={Liang, Qingmi and Kuai, Zhirui and Zhang, Yangqi and Zhang, Zhiyang and Kuang, Li and Zhang, Lingyan},
  booktitle={2022 IEEE International Conference on Web Services (ICWS)},
  pages={246--255},
  year={2022},
  organization={IEEE}
}

@inproceedings{abdelaziz2021toolkit,
  title={A toolkit for generating code knowledge graphs},
  author={Abdelaziz, Ibrahim and Dolby, Julian and McCusker, Jamie and Srinivas, Kavitha},
  booktitle={Proceedings of the 11th Knowledge Capture Conference},
  pages={137--144},
  year={2021}
}

@article{agashe2019juice,
  title={JuICe: A large scale distantly supervised dataset for open domain context-based code generation},
  author={Agashe, Rajas and Iyer, Srinivasan and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1910.02216},
  year={2019}
}

@article{post2018call,
  title={A call for clarity in reporting BLEU scores},
  author={Post, Matt},
  journal={arXiv preprint arXiv:1804.08771},
  year={2018}
}

@incollection{suarez2011neon,
  title={The NeOn methodology for ontology engineering},
  author={Su{\'a}rez-Figueroa, Mari Carmen and G{\'o}mez-P{\'e}rez, Asunci{\'o}n and Fern{\'a}ndez-L{\'o}pez, Mariano},
  booktitle={Ontology engineering in a networked world},
  pages={9--34},
  year={2011},
  publisher={Springer}
}

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}


@article{simperl2014collaborative,
  title={Collaborative ontology engineering: a survey},
  author={Simperl, Elena and Luczak-R{\"o}sch, Markus},
  journal={The Knowledge Engineering Review},
  volume={29},
  number={1},
  pages={101--131},
  year={2014},
  publisher={Cambridge University Press}
}


@article{chandel2022training,
  title={Training and evaluating a jupyter notebook data science assistant},
  author={Chandel, Shubham and Clement, Colin B and Serrato, Guillermo and Sundaresan, Neel},
  journal={arXiv preprint arXiv:2201.12901},
  year={2022}
}

@article{olausson2023demystifying,
  title={Demystifying gpt self-repair for code generation},
  author={Olausson, Theo X and Inala, Jeevana Priya and Wang, Chenglong and Gao, Jianfeng and Solar-Lezama, Armando},
  journal={arXiv preprint arXiv:2306.09896},
  year={2023}
}

@article{yin2022natural,
  title={Natural language to code generation in interactive data science notebooks},
  author={Yin, Pengcheng and Li, Wen-Ding and Xiao, Kefan and Rao, Abhishek and Wen, Yeming and Shi, Kensen and Howland, Joshua and Bailey, Paige and Catasta, Michele and Michalewski, Henryk and others},
  journal={arXiv preprint arXiv:2212.09248},
  year={2022}
}

@article{nielebock2024asap,
  title={ASAP-Repair: API-Specific Automated Program Repair Based on API Usage Graphs},
  author={Nielebock, Sebastian and Blockhaus, Paul and Kr{\"u}ger, Jacob and Ortmeier, Frank},
  journal={arXiv preprint arXiv:2402.07542},
  year={2024}
}

@inproceedings{yin2018learning,
  title={Learning to mine aligned code and natural language pairs from stack overflow},
  author={Yin, Pengcheng and Deng, Bowen and Chen, Edgar and Vasilescu, Bogdan and Neubig, Graham},
  booktitle={Proceedings of the 15th international conference on mining software repositories},
  pages={476--486},
  year={2018}
}

@inproceedings{ouyang2021api,
  title={API Misuse Detection based on Stacked LSTM},
  author={OuYang, Shuyin and Ge, Fan and Kuang, Li and Yin, Yuyu},
  booktitle={Collaborative Computing: Networking, Applications and Worksharing: 16th EAI International Conference, CollaborateCom 2020, Shanghai, China, October 16--18, 2020, Proceedings, Part I 16},
  pages={421--438},
  year={2021},
  organization={Springer}
}

@article{papadakis2015metallaxis,
  title={Metallaxis-FL: mutation-based fault localization},
  author={Papadakis, Mike and Le Traon, Yves},
  journal={Software Testing, Verification and Reliability},
  volume={25},
  number={5-7},
  pages={605--628},
  year={2015},
  publisher={Wiley Online Library}
}

@inproceedings{abreu2007accuracy,
  title={On the accuracy of spectrum-based fault localization},
  author={Abreu, Rui and Zoeteweij, Peter and Van Gemund, Arjan JC},
  booktitle={Testing: Academic and industrial conference practice and research techniques-MUTATION (TAICPART-MUTATION 2007)},
  pages={89--98},
  year={2007},
  organization={IEEE}
}

@article{zhang2023critical,
  title={A critical review of large language model on software engineering: An example from chatgpt and automated program repair},
  author={Zhang, Quanjun and Zhang, Tongke and Zhai, Juan and Fang, Chunrong and Yu, Bowen and Sun, Weisong and Chen, Zhenyu},
  journal={arXiv preprint arXiv:2310.08879},
  year={2023}
}

@inproceedings{fu2023chatgpt,
  title={Chatgpt for vulnerability detection, classification, and repair: How far are we?},
  author={Fu, Michael and Tantithamthavorn, Chakkrit Kla and Nguyen, Van and Le, Trung},
  booktitle={2023 30th Asia-Pacific Software Engineering Conference (APSEC)},
  pages={632--636},
  year={2023},
  organization={IEEE}
}

@article{nejjar2023llms,
  title={Llms for science: Usage for code generation and data analysis},
  author={Nejjar, Mohamed and Zacharias, Luca and Stiehle, Fabian and Weber, Ingo},
  journal={arXiv preprint arXiv:2311.16733},
  year={2023}
}

@article{hong2024data,
  title={Data interpreter: An LLM agent for data science},
  author={Hong, Sirui and Lin, Yizhang and Liu, Bangbang and Wu, Binhao and Li, Danyang and Chen, Jiaqi and Zhang, Jiayi and Wang, Jinlin and Zhang, Lingyao and Zhuge, Mingchen and others},
  journal={arXiv preprint arXiv:2402.18679},
  year={2024}
}

@inproceedings{ahmed2024automatic,
  title={Automatic semantic augmentation of language model prompts (for code summarization)},
  author={Ahmed, Toufique and Pai, Kunal Suresh and Devanbu, Premkumar and Barr, Earl},
  booktitle={Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
  pages={1--13},
  year={2024}
}

@article{hendrycks2021measuring,
  title={Measuring coding challenge competence with apps},
  author={Hendrycks, Dan and Basart, Steven and Kadavath, Saurav and Mazeika, Mantas and Arora, Akul and Guo, Ethan and Burns, Collin and Puranik, Samir and He, Horace and Song, Dawn and others},
  journal={arXiv preprint arXiv:2105.09938},
  year={2021}
}

@article{izacard2023atlas,
  title={Atlas: Few-shot learning with retrieval augmented language models},
  author={Izacard, Gautier and Lewis, Patrick and Lomeli, Maria and Hosseini, Lucas and Petroni, Fabio and Schick, Timo and Dwivedi-Yu, Jane and Joulin, Armand and Riedel, Sebastian and Grave, Edouard},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={251},
  pages={1--43},
  year={2023}
}

@article{he2023rest,
  title={Rest: Retrieval-based speculative decoding},
  author={He, Zhenyu and Zhong, Zexuan and Cai, Tianle and Lee, Jason D and He, Di},
  journal={arXiv preprint arXiv:2311.08252},
  year={2023}
}

@inproceedings{carlini2021extracting,
  title={Extracting training data from large language models},
  author={Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Ulfar and others},
  booktitle={30th USENIX Security Symposium (USENIX Security 21)},
  pages={2633--2650},
  year={2021}
}

@article{mallen2022not,
  title={When not to trust language models: Investigating effectiveness of parametric and non-parametric memories},
  author={Mallen, Alex and Asai, Akari and Zhong, Victor and Das, Rajarshi and Khashabi, Daniel and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2212.10511},
  year={2022}
}

@inproceedings{lai2023ds,
  title={DS-1000: A natural and reliable benchmark for data science code generation},
  author={Lai, Yuhang and Li, Chengxi and Wang, Yiming and Zhang, Tianyi and Zhong, Ruiqi and Zettlemoyer, Luke and Yih, Wen-tau and Fried, Daniel and Wang, Sida and Yu, Tao},
  booktitle={International Conference on Machine Learning},
  pages={18319--18345},
  year={2023},
  organization={PMLR}
}

@article{roziere2023code,
  title={Code llama: Open foundation models for code},
  author={Roziere, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Remez, Tal and Rapin, J{\'e}r{\'e}my and others},
  journal={arXiv preprint arXiv:2308.12950},
  year={2023}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{pan2024vector,
  title={Vector Database Management Techniques and Systems},
  author={Pan, James Jie and Wang, Jianguo and Li, Guoliang},
  booktitle={Companion of the 2024 International Conference on Management of Data},
  pages={597--604},
  year={2024}
}

@book{harrington2016relational,
  title={Relational database design and implementation},
  author={Harrington, Jan L},
  year={2016},
  publisher={Morgan Kaufmann}
}

@article{bahrami2021pytorrent,
  title={Pytorrent: A python library corpus for large-scale language models},
  author={Bahrami, Mehdi and Shrikanth, NC and Ruangwan, Shade and Liu, Lei and Mizobuchi, Yuji and Fukuyori, Masahiro and Chen, Wei-Peng and Munakata, Kazuki and Menzies, Tim},
  journal={arXiv preprint arXiv:2110.01710},
  year={2021}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{li2022competition,
  title={Competition-level code generation with alphacode},
  author={Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, R{\'e}mi and Eccles, Tom and Keeling, James and Gimeno, Felix and Dal Lago, Agustin and others},
  journal={Science},
  volume={378},
  number={6624},
  pages={1092--1097},
  year={2022},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{gao2020switch,
  title={Switch code generation using program synthesis},
  author={Gao, Xiangyu and Kim, Taegyun and Wong, Michael D and Raghunathan, Divya and Varma, Aatish Kishan and Kannan, Pravein Govindan and Sivaraman, Anirudh and Narayana, Srinivas and Gupta, Aarti},
  booktitle={Proceedings of the Annual conference of the ACM Special Interest Group on Data Communication on the applications, technologies, architectures, and protocols for computer communication},
  pages={44--61},
  year={2020}
}

@article{durai2022novel,
  title={A novel approach with an extensive case study and experiment for automatic code generation from the XMI schema Of UML models},
  author={Durai, Anand Deva and Ganesh, Mythily and Mathew, Rincy Merlin and Anguraj, Dinesh Kumar},
  journal={The Journal of Supercomputing},
  pages={1--23},
  year={2022},
  publisher={Springer}
}

@article{jurgelaitis2022solidity,
  title={Solidity code generation from UML state machines in model-driven smart contract development},
  author={Jurgelaitis, Mantas and Butkien{\.e}, Rita and others},
  journal={IEEE Access},
  volume={10},
  pages={33465--33481},
  year={2022},
  publisher={IEEE}
}

@article{smith2003compiling,
  title={Compiling for template-based run-time code generation},
  author={Smith, Frederick and Grossman, Dan and Morrisett, Greg and Hornof, Luke and Jim, Trevor},
  journal={Journal of Functional Programming},
  volume={13},
  number={3},
  pages={677--708},
  year={2003},
  publisher={Cambridge University Press}
}

@article{syriani2018systematic,
  title={Systematic mapping study of template-based code generation},
  author={Syriani, Eugene and Luhunu, Lechanceux and Sahraoui, Houari},
  journal={Computer Languages, Systems \& Structures},
  volume={52},
  pages={43--62},
  year={2018},
  publisher={Elsevier}
}

@article{ryan2024code,
  title={Code-aware prompting: A study of coverage guided test generation in regression setting using llm},
  author={Ryan, Gabriel and Jain, Siddhartha and Shang, Mingyue and Wang, Shiqi and Ma, Xiaofei and Ramanathan, Murali Krishna and Ray, Baishakhi},
  journal={arXiv preprint arXiv:2402.00097},
  year={2024}
}

@article{hassani2023role,
  title={The role of ChatGPT in data science: how ai-assisted conversational interfaces are revolutionizing the field},
  author={Hassani, Hossein and Silva, Emmanuel Sirmal},
  journal={Big data and cognitive computing},
  volume={7},
  number={2},
  pages={62},
  year={2023},
  publisher={MDPI}
}

@article{guo2024deepseek,
  title={DeepSeek-Coder: When the Large Language Model Meets Programming--The Rise of Code Intelligence},
  author={Guo, Daya and Zhu, Qihao and Yang, Dejian and Xie, Zhenda and Dong, Kai and Zhang, Wentao and Chen, Guanting and Bi, Xiao and Wu, Yu and Li, YK and others},
  journal={arXiv preprint arXiv:2401.14196},
  year={2024}
}

@article{bolyen2019reproducible,
  title={Reproducible, interactive, scalable and extensible microbiome data science using QIIME 2},
  author={Bolyen, Evan and Rideout, Jai Ram and Dillon, Matthew R and Bokulich, Nicholas A and Abnet, Christian C and Al-Ghalith, Gabriel A and Alexander, Harriet and Alm, Eric J and Arumugam, Manimozhiyan and Asnicar, Francesco and others},
  journal={Nature biotechnology},
  volume={37},
  number={8},
  pages={852--857},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{ji2023survey,
  title={Survey of hallucination in natural language generation},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  journal={ACM Computing Surveys},
  volume={55},
  number={12},
  pages={1--38},
  year={2023},
  publisher={ACM New York, NY}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{qi2024can,
  title={Can We Catch the Elephant? The Evolvement of Hallucination Evaluation on Natural Language Generation: A Survey},
  author={Qi, Siya and He, Yulan and Yuan, Zheng},
  journal={arXiv preprint arXiv:2404.12041},
  year={2024}
}

@article{tian2024codehalu,
  title={CodeHalu: Code Hallucinations in LLMs Driven by Execution-based Verification},
  author={Tian, Yuchen and Yan, Weixiang and Yang, Qian and Chen, Qian and Wang, Wen and Luo, Ziyang and Ma, Lei},
  journal={arXiv preprint arXiv:2405.00253},
  year={2024}
}

@article{ouyang2023llm,
  title={LLM is Like a Box of Chocolates: the Non-determinism of ChatGPT in Code Generation},
  author={Ouyang, Shuyin and Zhang, Jie M and Harman, Mark and Wang, Meng},
  journal={arXiv preprint arXiv:2308.02828},
  year={2023}
}

@article{zhang2023siren,
  title={Siren's song in the AI ocean: a survey on hallucination in large language models},
  author={Zhang, Yue and Li, Yafu and Cui, Leyang and Cai, Deng and Liu, Lemao and Fu, Tingchen and Huang, Xinting and Zhao, Enbo and Zhang, Yu and Chen, Yulong and others},
  journal={arXiv preprint arXiv:2309.01219},
  year={2023}
}

@article{xia2023keep,
  title={Keep the Conversation Going: Fixing 162 out of 337 bugs for \$0.42 each using ChatGPT},
  author={Xia, Chunqiu Steven and Zhang, Lingming},
  journal={arXiv preprint arXiv:2304.00385},
  year={2023}
}

@article{zhou2022large,
  title={Large language models are human-level prompt engineers},
  author={Zhou, Yongchao and Muresanu, Andrei Ioan and Han, Ziwen and Paster, Keiran and Pitis, Silviu and Chan, Harris and Ba, Jimmy},
  journal={arXiv preprint arXiv:2211.01910},
  year={2022}
}

@article{borji2023categorical,
  title={A categorical archive of chatgpt failures},
  author={Borji, Ali},
  journal={arXiv preprint arXiv:2302.03494},
  year={2023}
}



@article{maddigan2023chat2vis,
  title={Chat2vis: Generating data visualisations via natural language using chatgpt, codex and gpt-3 large language models},
  author={Maddigan, Paula and Susnjak, Teo},
  journal={IEEE Access},
  year={2023},
  publisher={IEEE}
}

@article{white2023chatgpt,
  title={Chatgpt prompt patterns for improving code quality, refactoring, requirements elicitation, and software design},
  author={White, Jules and Hays, Sam and Fu, Quchen and Spencer-Smith, Jesse and Schmidt, Douglas C},
  journal={arXiv preprint arXiv:2303.07839},
  year={2023}
}

@article{abukhalaf2023codex,
  title={On Codex Prompt Engineering for OCL Generation: An Empirical Study},
  author={Abukhalaf, Seif and Hamdaqa, Mohammad and Khomh, Foutse},
  journal={arXiv preprint arXiv:2303.16244},
  year={2023}
}

@inproceedings{liu2022design,
  title={Design guidelines for prompt engineering text-to-image generative models},
  author={Liu, Vivian and Chilton, Lydia B},
  booktitle={Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
  pages={1--23},
  year={2022}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@inproceedings{reynolds2021prompt,
  title={Prompt programming for large language models: Beyond the few-shot paradigm},
  author={Reynolds, Laria and McDonell, Kyle},
  booktitle={Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--7},
  year={2021}
}

@book{gamma1995design,
  title={Design patterns: elements of reusable object-oriented software},
  author={Gamma, Erich and Helm, Richard and Johnson, Ralph and Vlissides, John},
  year={1995},
  publisher={Pearson Deutschland GmbH}
}

@article{white2023prompt,
  title={A prompt pattern catalog to enhance prompt engineering with chatgpt},
  author={White, Jules and Fu, Quchen and Hays, Sam and Sandborn, Michael and Olea, Carlos and Gilbert, Henry and Elnashar, Ashraf and Spencer-Smith, Jesse and Schmidt, Douglas C},
  journal={arXiv preprint arXiv:2302.11382},
  year={2023}
}

@article{chen2023teaching,
  title={Teaching large language models to self-debug},
  author={Chen, Xinyun and Lin, Maxwell and Sch{\"a}rli, Nathanael and Zhou, Denny},
  journal={arXiv preprint arXiv:2304.05128},
  year={2023}
}


@article{gupta2020synthesize,
  title={Synthesize, execute and debug: Learning to repair for neural program synthesis},
  author={Gupta, Kavi and Christensen, Peter Ebert and Chen, Xinyun and Song, Dawn},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={17685--17695},
  year={2020}
}

@article{hong2023metagpt,
  title={Metagpt: Meta programming for multi-agent collaborative framework},
  author={Hong, Sirui and Zheng, Xiawu and Chen, Jonathan and Cheng, Yuheng and Wang, Jinlin and Zhang, Ceyao and Wang, Zili and Yau, Steven Ka Shing and Lin, Zijuan and Zhou, Liyang and others},
  journal={arXiv preprint arXiv:2308.00352},
  year={2023}
}

@article{su2024arks,
  title={ARKS: Active Retrieval in Knowledge Soup for Code Generation},
  author={Su, Hongjin and Jiang, Shuyang and Lai, Yuhang and Wu, Haoyuan and Shi, Boao and Liu, Che and Liu, Qian and Yu, Tao},
  journal={arXiv preprint arXiv:2402.12317},
  year={2024}
}

@article{zhang2024codeagent,
  title={Codeagent: Enhancing code generation with tool-integrated agent systems for real-world repo-level coding challenges},
  author={Zhang, Kechi and Li, Jia and Li, Ge and Shi, Xianjie and Jin, Zhi},
  journal={arXiv preprint arXiv:2401.07339},
  year={2024}
}

@article{gou2024rrgcode,
  title={RRGcode: Deep hierarchical search-based code generation},
  author={Gou, Qianwen and Dong, Yunwei and Wu, Yujiao and Ke, Qiao},
  journal={Journal of Systems and Software},
  volume={211},
  pages={111982},
  year={2024},
  publisher={Elsevier}
}

@inproceedings{li2023skcoder,
  title={Skcoder: A sketch-based approach for automatic code generation},
  author={Li, Jia and Li, Yongmin and Li, Ge and Jin, Zhi and Hao, Yiyang and Hu, Xing},
  booktitle={2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)},
  pages={2124--2135},
  year={2023},
  organization={IEEE}
}

@article{parvez2021retrieval,
  title={Retrieval augmented code generation and summarization},
  author={Parvez, Md Rizwan and Ahmad, Wasi Uddin and Chakraborty, Saikat and Ray, Baishakhi and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:2108.11601},
  year={2021}
}

@inproceedings{liu2023codegen4libs,
  title={Codegen4libs: A two-stage approach for library-oriented code generation},
  author={Liu, Mingwei and Yang, Tianyong and Lou, Yiling and Du, Xueying and Wang, Ying and Peng, Xin},
  booktitle={2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  pages={434--445},
  year={2023},
  organization={IEEE}
}

@article{zhou2022docprompting,
  title={Docprompting: Generating code by retrieving the docs},
  author={Zhou, Shuyan and Alon, Uri and Xu, Frank F and Wang, Zhiruo and Jiang, Zhengbao and Neubig, Graham},
  journal={arXiv preprint arXiv:2207.05987},
  year={2022}
}

@article{zan2023private,
  title={Private-library-oriented code generation with large language models},
  author={Zan, Daoguang and Chen, Bei and Gong, Yongshun and Cao, Junzhi and Zhang, Fengji and Wu, Bingchao and Guan, Bei and Yin, Yilong and Wang, Yongji},
  journal={arXiv preprint arXiv:2307.15370},
  year={2023}
}

@inproceedings{blinov2020semantic,
  title={Semantic triples verbalization with generative pre-training model},
  author={Blinov, Pavel},
  booktitle={Proceedings of the 3rd International Workshop on Natural Language Generation from the Semantic Web (WebNLG+)},
  pages={154--158},
  year={2020}
}

@article{zan2022language,
  title={When language model meets private library},
  author={Zan, Daoguang and Chen, Bei and Lin, Zeqi and Guan, Bei and Wang, Yongji and Lou, Jian-Guang},
  journal={arXiv preprint arXiv:2210.17236},
  year={2022}
}

@article{li2023acecoder,
  title={Acecoder: Utilizing existing code to enhance code generation},
  author={Li, Jia and Zhao, Yunfei and Li, Yongmin and Li, Ge and Jin, Zhi},
  journal={arXiv preprint arXiv:2303.17780},
  year={2023}
}

@article{liu2023repobench,
  title={Repobench: Benchmarking repository-level code auto-completion systems},
  author={Liu, Tianyang and Xu, Canwen and McAuley, Julian},
  journal={arXiv preprint arXiv:2306.03091},
  year={2023}
}

@inproceedings{brate2022improving,
  title={Improving Language Model Predictions via Prompts Enriched with Knowledge Graphs},
  author={Brate, Ryan and Dang, Minh-Hoang and Hoppe, Fabian and He, Yuan and Mero{\~n}o-Pe{\~n}uela, Albert and Sadashivaiah, Vijay},
  booktitle={DL4KG@ ISWC2022},
  year={2022}
}

@article{ding2024crosscodeeval,
  title={Crosscodeeval: A diverse and multilingual benchmark for cross-file code completion},
  author={Ding, Yangruibo and Wang, Zijian and Ahmad, Wasi and Ding, Hantian and Tan, Ming and Jain, Nihal and Ramanathan, Murali Krishna and Nallapati, Ramesh and Bhatia, Parminder and Roth, Dan and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{chu2011contextual,
  title={Contextual bandits with linear payoff functions},
  author={Chu, Wei and Li, Lihong and Reyzin, Lev and Schapire, Robert},
  booktitle={Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  pages={208--214},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{zhang2023repocoder,
  title={Repocoder: Repository-level code completion through iterative retrieval and generation},
  author={Zhang, Fengji and Chen, Bei and Zhang, Yue and Keung, Jacky and Liu, Jin and Zan, Daoguang and Mao, Yi and Lou, Jian-Guang and Chen, Weizhu},
  journal={arXiv preprint arXiv:2303.12570},
  year={2023}
}

@inproceedings{tang2023domain,
  title={Domain adaptive code completion via language models and decoupled domain databases},
  author={Tang, Ze and Ge, Jidong and Liu, Shangqing and Zhu, Tingwei and Xu, Tongtong and Huang, Liguo and Luo, Bin},
  booktitle={2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  pages={421--433},
  year={2023},
  organization={IEEE}
}

@inproceedings{denny2023conversing,
  title={Conversing with copilot: Exploring prompt engineering for solving cs1 problems using natural language},
  author={Denny, Paul and Kumar, Viraj and Giacaman, Nasser},
  booktitle={Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
  pages={1136--1142},
  year={2023}
}

@article{lu2022reacc,
  title={Reacc: A retrieval-augmented code completion framework},
  author={Lu, Shuai and Duan, Nan and Han, Hojae and Guo, Daya and Hwang, Seung-won and Svyatkovskiy, Alexey},
  journal={arXiv preprint arXiv:2203.07722},
  year={2022}
}

@article{karpukhin2020dense,
  title={Dense passage retrieval for open-domain question answering},
  author={Karpukhin, Vladimir and O{\u{g}}uz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau},
  journal={arXiv preprint arXiv:2004.04906},
  year={2020}
}

@article{gao2021simcse,
  title={Simcse: Simple contrastive learning of sentence embeddings},
  author={Gao, Tianyu and Yao, Xingcheng and Chen, Danqi},
  journal={arXiv preprint arXiv:2104.08821},
  year={2021}
}

@article{jiang2023self,
  title={Self-planning Code Generation with Large Language Models},
  author={Jiang, Xue and Dong, Yihong and Wang, Lecheng and Zheng, Fang and Shang, Qiwei and Li, Ge and Jin, Zhi and Jiao, Wenpin},
  journal={ACM Transactions on Software Engineering and Methodology},
  year={2023},
  publisher={ACM New York, NY}
}

@article{ge2024openagi,
  title={Openagi: When llm meets domain experts},
  author={Ge, Yingqiang and Hua, Wenyue and Mei, Kai and Tan, Juntao and Xu, Shuyuan and Li, Zelong and Zhang, Yongfeng and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{qian2023communicative,
  title={Communicative agents for software development},
  author={Qian, Chen and Cong, Xin and Yang, Cheng and Chen, Weize and Su, Yusheng and Xu, Juyuan and Liu, Zhiyuan and Sun, Maosong},
  journal={arXiv preprint arXiv:2307.07924},
  year={2023}
}


@article{huang2023agentcoder,
  title={Agentcoder: Multi-agent-based code generation with iterative testing and optimisation},
  author={Huang, Dong and Bu, Qingwen and Zhang, Jie M and Luck, Michael and Cui, Heming},
  journal={arXiv preprint arXiv:2312.13010},
  year={2023}
}

@inproceedings{joshi2023repair,
  title={Repair is nearly generation: Multilingual program repair with llms},
  author={Joshi, Harshit and Sanchez, Jos{\'e} Cambronero and Gulwani, Sumit and Le, Vu and Verbruggen, Gust and Radi{\v{c}}ek, Ivan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={4},
  pages={5131--5140},
  year={2023}
}

@inproceedings{chen2024code,
  title={Code Search Is All You Need? Improving Code Suggestions with Code Search},
  author={Chen, Junkai and Hu, Xing and Li, Zhenhao and Gao, Cuiyun and Xia, Xin and Lo, David},
  booktitle={Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
  pages={1--13},
  year={2024}
}

@article{liu2024exploring,
  title={Exploring and evaluating hallucinations in llm-powered code generation},
  author={Liu, Fang and Liu, Yang and Shi, Lin and Huang, Houkun and Wang, Ruifeng and Yang, Zhen and Zhang, Li},
  journal={arXiv preprint arXiv:2404.00971},
  year={2024}
}

@article{yao2023llm,
  title={Llm lies: Hallucinations are not bugs, but features as adversarial examples},
  author={Yao, Jia-Yu and Ning, Kun-Peng and Liu, Zhen-Hui and Ning, Mu-Nan and Yuan, Li},
  journal={arXiv preprint arXiv:2310.01469},
  year={2023}
}

@misc{qi2024catchelephantsurveyevolvement,
      title={Can We Catch the Elephant? A Survey of the Evolvement of Hallucination Evaluation on Natural Language Generation}, 
      author={Siya Qi and Yulan He and Zheng Yuan},
      year={2024},
      eprint={2404.12041},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.12041}, 
}



@article{deng2023large,
  title={Large language models are edge-case fuzzers: Testing deep learning libraries via fuzzgpt},
  author={Deng, Yinlin and Xia, Chunqiu Steven and Yang, Chenyuan and Zhang, Shizhuo Dylan and Yang, Shujing and Zhang, Lingming},
  journal={arXiv preprint arXiv:2304.02014},
  year={2023}
}

@article{puigcerver2023sparse,
  title={From Sparse to Soft Mixtures of Experts},
  author={Puigcerver, Joan and Riquelme, Carlos and Mustafa, Basil and Houlsby, Neil},
  journal={arXiv preprint arXiv:2308.00951},
  year={2023}
}

@misc{gptrandomness,
year={https://152334h.github.io/blog/non-determinism-in-gpt-4/}
}

@article{la2023arrt,
  title={The ARRT of Language-Models-as-a-Service: Overview of a New Paradigm and its Challenges},
  author={La Malfa, Emanuele and Petrov, Aleksandar and Frieder, Simon and Weinhuber, Christoph and Burnell, Ryan and Cohn, Anthony G and Shadbolt, Nigel and Wooldridge, Michael},
  journal={arXiv preprint arXiv:2309.16573},
  year={2023}
}

@misc{OpenAI2022gpt3.5,
    title={GPT-3.5},
    author={OpenAI},
    year={2022},
    url={https://platform.openai.com/docs/models/gpt-3-5}
}

@inproceedings{liang2023code,
  title={Code as policies: Language model programs for embodied control},
  author={Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={9493--9500},
  year={2023},
  organization={IEEE}
}

@article{bhavya2022analogy,
  title={Analogy generation by prompting large language models: A case study of instructgpt},
  author={Bhavya, Bhavya and Xiong, Jinjun and Zhai, Chengxiang},
  journal={arXiv preprint arXiv:2210.04186},
  year={2022}
}

@misc{Github2023copilot,
    title={Github copilot},
    author={Github},
    year={2023},
    url={https://github.com/features/copilot/}
}

@article{li2023starcoder,
  title={Starcoder: may the source be with you!},
  author={Li, Raymond and Allal, Loubna Ben and Zi, Yangtian and Muennighoff, Niklas and Kocetkov, Denis and Mou, Chenghao and Marone, Marc and Akiki, Christopher and Li, Jia and Chim, Jenny and others},
  journal={arXiv preprint arXiv:2305.06161},
  year={2023}
}

@misc{hou2024large,
      title={Large Language Models for Software Engineering: A Systematic Literature Review}, 
      author={Xinyi Hou and Yanjie Zhao and Yue Liu and Zhou Yang and Kailong Wang and Li Li and Xiapu Luo and David Lo and John Grundy and Haoyu Wang},
      year={2024},
      eprint={2308.10620},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@article{yang2022survey,
  title={A survey on deep learning for software engineering},
  author={Yang, Yanming and Xia, Xin and Lo, David and Grundy, John},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={10s},
  pages={1--73},
  year={2022},
  publisher={ACM New York, NY}
}

@article{xu2020incorporating,
  title={Incorporating external knowledge through pre-training for natural language to code generation},
  author={Xu, Frank F and Jiang, Zhengbao and Yin, Pengcheng and Vasilescu, Bogdan and Neubig, Graham},
  journal={arXiv preprint arXiv:2004.09015},
  year={2020}
}

@article{yang2024stealthy,
  title={Stealthy backdoor attack for code models},
  author={Yang, Zhou and Xu, Bowen and Zhang, Jie M and Kang, Hong Jin and Shi, Jieke and He, Junda and Lo, David},
  journal={IEEE Transactions on Software Engineering},
  year={2024},
  publisher={IEEE}
}

@inproceedings{wu2023effective,
  title={How effective are neural networks for fixing security vulnerabilities},
  author={Wu, Yi and Jiang, Nan and Pham, Hung Viet and Lutellier, Thibaud and Davis, Jordan and Tan, Lin and Babkin, Petr and Shah, Sameena},
  booktitle={Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
  pages={1282--1294},
  year={2023}
}

@inproceedings{yang2022natural,
  title={Natural attack for pre-trained models of code},
  author={Yang, Zhou and Shi, Jieke and He, Junda and Lo, David},
  booktitle={Proceedings of the 44th International Conference on Software Engineering},
  pages={1482--1493},
  year={2022}
}

@inproceedings{lajko2022towards,
  title={Towards javascript program repair with generative pre-trained transformer (gpt-2)},
  author={Lajk{\'o}, M{\'a}rk and Csuvik, Viktor and Vid{\'a}cs, L{\'a}szl{\'o}},
  booktitle={Proceedings of the Third International Workshop on Automated Program Repair},
  pages={61--68},
  year={2022}
}

@inproceedings{sobania2023analysis,
  title={An analysis of the automatic bug fixing performance of chatgpt},
  author={Sobania, Dominik and Briesch, Martin and Hanna, Carol and Petke, Justyna},
  booktitle={2023 IEEE/ACM International Workshop on Automated Program Repair (APR)},
  pages={23--30},
  year={2023},
  organization={IEEE}
}

@article{xia2023conversational,
  title={Conversational automated program repair},
  author={Xia, Chunqiu Steven and Zhang, Lingming},
  journal={arXiv preprint arXiv:2301.13246},
  year={2023}
}

@inproceedings{jin2023inferfix,
  title={Inferfix: End-to-end program repair with llms},
  author={Jin, Matthew and Shahriar, Syed and Tufano, Michele and Shi, Xin and Lu, Shuai and Sundaresan, Neel and Svyatkovskiy, Alexey},
  booktitle={Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages={1646--1656},
  year={2023}
}

@inproceedings{fan2023automated,
  title={Automated repair of programs from large language models},
  author={Fan, Zhiyu and Gao, Xiang and Mirchev, Martin and Roychoudhury, Abhik and Tan, Shin Hwei},
  booktitle={2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)},
  pages={1469--1481},
  year={2023},
  organization={IEEE}
}


@article{le2023invalidator,
  title={Invalidator: Automated patch correctness assessment via semantic and syntactic reasoning},
  author={Le-Cong, Thanh and Luong, Duc-Minh and Le, Xuan Bach D and Lo, David and Tran, Nhat-Hoa and Quang-Huy, Bui and Huynh, Quyet-Thang},
  journal={IEEE Transactions on Software Engineering},
  year={2023},
  publisher={IEEE}
}

@article{zhang2024appt,
  title={APPT: Boosting Automated Patch Correctness Prediction via Fine-tuning Pre-trained Models},
  author={Zhang, Quanjun and Fang, Chunrong and Sun, Weisong and Liu, Yan and He, Tieke and Hao, Xiaodong and Chen, Zhenyu},
  journal={IEEE Transactions on Software Engineering},
  year={2024},
  publisher={IEEE}
}

@inproceedings{shen2022incorporating,
  title={Incorporating domain knowledge through task augmentation for front-end JavaScript code generation},
  author={Shen, Sijie and Zhu, Xiang and Dong, Yihong and Guo, Qizhi and Zhen, Yankun and Li, Ge},
  booktitle={Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages={1533--1543},
  year={2022}
}

@article{xu2020incorporating,
  title={Incorporating external knowledge through pre-training for natural language to code generation},
  author={Xu, Frank F and Jiang, Zhengbao and Yin, Pengcheng and Vasilescu, Bogdan and Neubig, Graham},
  journal={arXiv preprint arXiv:2004.09015},
  year={2020}
}


@misc{GPTCC2021GPTCC,
    title={gpt-code-clippy},
    author={gpt-code-clippy},
    year={2021},
    url={https://huggingface.co/codeparrot/codeparrot}
}

@article{wang2021codet5,
  title={Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation},
  author={Wang, Yue and Wang, Weishi and Joty, Shafiq and Hoi, Steven CH},
  journal={arXiv preprint arXiv:2109.00859},
  year={2021}
}

@inproceedings{xu2022systematic,
  title={A systematic evaluation of large language models of code},
  author={Xu, Frank F and Alon, Uri and Neubig, Graham and Hellendoorn, Vincent Josua},
  booktitle={Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming},
  pages={1--10},
  year={2022}
}

@inproceedings{ochs2023evaluating,
  title={Evaluating and improving transformers pre-trained on ASTs for Code Completion},
  author={Ochs, Marcel and Narasimhan, Krishna and Mezini, Mira},
  booktitle={2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  pages={834--844},
  year={2023},
  organization={IEEE}
}

@inproceedings{pearce2023examining,
  title={Examining zero-shot vulnerability repair with large language models},
  author={Pearce, Hammond and Tan, Benjamin and Ahmad, Baleegh and Karri, Ramesh and Dolan-Gavitt, Brendan},
  booktitle={2023 IEEE Symposium on Security and Privacy (SP)},
  pages={2339--2356},
  year={2023},
  organization={IEEE}
}

@inproceedings{khan2022automatic,
  title={Automatic detection and analysis of technical debts in peer-review documentation of r packages},
  author={Khan, Junaed Younus and Uddin, Gias},
  booktitle={2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  pages={765--776},
  year={2022},
  organization={IEEE}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@misc{CodeParrot2022CodeParrot,
    title={CodeParrot},
    author={CodeParrot},
    year={2022},
    url={https://github.com/CodedotAl/gpt-code-clippy}
}

@misc{wang2021gpt,
  title={GPT-J-6B: A 6 billion parameter autoregressive language model},
  author={Wang, Ben and Komatsuzaki, Aran},
  year={2021}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{liu2024your,
  title={Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation},
  author={Liu, Jiawei and Xia, Chunqiu Steven and Wang, Yuyao and Zhang, Lingming},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{dong2023self,
  title={Self-collaboration code generation via chatgpt},
  author={Dong, Yihong and Jiang, Xue and Jin, Zhi and Li, Ge},
  journal={arXiv preprint arXiv:2304.07590},
  year={2023}
}


@inproceedings{gulwani2010dimensions,
  title={Dimensions in program synthesis},
  author={Gulwani, Sumit},
  booktitle={Proceedings of the 12th international ACM SIGPLAN symposium on Principles and practice of declarative programming},
  pages={13--24},
  year={2010}
}

@article{david2017program,
  title={Program synthesis: challenges and opportunities},
  author={David, Cristina and Kroening, Daniel},
  journal={Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume={375},
  number={2104},
  pages={20150403},
  year={2017},
  publisher={The Royal Society Publishing}
}

@article{black2022gpt,
  title={Gpt-neox-20b: An open-source autoregressive language model},
  author={Black, Sid and Biderman, Stella and Hallahan, Eric and Anthony, Quentin and Gao, Leo and Golding, Laurence and He, Horace and Leahy, Connor and McDonell, Kyle and Phang, Jason and others},
  journal={arXiv preprint arXiv:2204.06745},
  year={2022}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{black2021gpt,
  title={Gpt-neo: Large scale autoregressive language modeling with mesh-tensorflow},
  author={Black, Sid and Gao, Leo and Wang, Phil and Leahy, Connor and Biderman, Stella},
  journal={If you use this software, please cite it using these metadata},
  volume={58},
  pages={2},
  year={2021}
}

@article{zan2022cert,
  title={CERT: Continual Pre-training on Sketches for Library-oriented Code Generation},
  author={Zan, Daoguang and Chen, Bei and Yang, Dejian and Lin, Zeqi and Kim, Minsu and Guan, Bei and Wang, Yongji and Chen, Weizhu and Lou, Jian-Guang},
  journal={arXiv preprint arXiv:2206.06888},
  year={2022}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@misc{keele2007guidelines,
  title={Guidelines for performing systematic literature reviews in software engineering},
  author={Keele, Staffs and others},
  year={2007},
  publisher={Technical report, ver. 2.3 ebse technical report. ebse}
}

@article{kitchenham2022segress,
  title={SEGRESS: Software engineering guidelines for reporting secondary studies},
  author={Kitchenham, Barbara and Madeyski, Lech and Budgen, David},
  journal={IEEE Transactions on Software Engineering},
  volume={49},
  number={3},
  pages={1273--1298},
  year={2022},
  publisher={IEEE}
}

@article{lu2021codexglue,
  title={Codexglue: A machine learning benchmark dataset for code understanding and generation},
  author={Lu, Shuai and Guo, Daya and Ren, Shuo and Huang, Junjie and Svyatkovskiy, Alexey and Blanco, Ambrosio and Clement, Colin and Drain, Dawn and Jiang, Daxin and Tang, Duyu and others},
  journal={arXiv preprint arXiv:2102.04664},
  year={2021}
}


@inproceedings{amann2016study,
  title={A study of visual studio usage in practice},
  author={Amann, Sven and Proksch, Sebastian and Nadi, Sarah and Mezini, Mira},
  booktitle={2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER)},
  volume={1},
  pages={124--134},
  year={2016},
  organization={IEEE}
}

@article{fan2023large,
  title={Large language models for software engineering: Survey and open problems},
  author={Fan, Angela and Gokkaya, Beliz and Harman, Mark and Lyubarskiy, Mitya and Sengupta, Shubho and Yoo, Shin and Zhang, Jie M},
  journal={arXiv preprint arXiv:2310.03533},
  year={2023}
}

@article{wang2021codet5,
  title={Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation},
  author={Wang, Yue and Wang, Weishi and Joty, Shafiq and Hoi, Steven CH},
  journal={arXiv preprint arXiv:2109.00859},
  year={2021}
}

@article{wang2023codet5+,
  title={Codet5+: Open code large language models for code understanding and generation},
  author={Wang, Yue and Le, Hung and Gotmare, Akhilesh Deepak and Bui, Nghi DQ and Li, Junnan and Hoi, Steven CH},
  journal={arXiv preprint arXiv:2305.07922},
  year={2023}
}

@article{li2022competition,
  title={Competition-level code generation with alphacode},
  author={Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, R{\'e}mi and Eccles, Tom and Keeling, James and Gimeno, Felix and Dal Lago, Agustin and others},
  journal={Science},
  volume={378},
  number={6624},
  pages={1092--1097},
  year={2022},
  publisher={American Association for the Advancement of Science}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}

@misc{openai2024gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{ahmad2021unified,
  title={Unified pre-training for program understanding and generation},
  author={Ahmad, Wasi Uddin and Chakraborty, Saikat and Ray, Baishakhi and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:2103.06333},
  year={2021}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{ciniselli2021empirical,
  title={An empirical study on the usage of bert models for code completion},
  author={Ciniselli, Matteo and Cooper, Nathan and Pascarella, Luca and Poshyvanyk, Denys and Di Penta, Massimiliano and Bavota, Gabriele},
  booktitle={2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR)},
  pages={108--119},
  year={2021},
  organization={IEEE}
}

@inproceedings{wang2022bridging,
  title={Bridging pre-trained models and downstream tasks for source code understanding},
  author={Wang, Deze and Jia, Zhouyang and Li, Shanshan and Yu, Yue and Xiong, Yun and Dong, Wei and Liao, Xiangke},
  booktitle={Proceedings of the 44th International Conference on Software Engineering},
  pages={287--298},
  year={2022}
}

@inproceedings{ciniselli2021empirical,
  title={An empirical study on the usage of bert models for code completion},
  author={Ciniselli, Matteo and Cooper, Nathan and Pascarella, Luca and Poshyvanyk, Denys and Di Penta, Massimiliano and Bavota, Gabriele},
  booktitle={2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR)},
  pages={108--119},
  year={2021},
  organization={IEEE}
}

@article{Hou2023LargeLM,
  title={Large Language Models for Software Engineering: A Systematic Literature Review},
  author={Xinying Hou and Yanjie Zhao and Yue Liu and Zhou Yang and Kailong Wang and Li Li and Xiapu Luo and David Lo and John C. Grundy and Haoyu Wang},
  journal={ArXiv},
  year={2023},
  volume={abs/2308.10620},
  url={https://api.semanticscholar.org/CorpusID:261048648}
}

@article{wang2024software,
  title={Software testing with large language models: Survey, landscape, and vision},
  author={Wang, Junjie and Huang, Yuchao and Chen, Chunyang and Liu, Zhe and Wang, Song and Wang, Qing},
  journal={IEEE Transactions on Software Engineering},
  year={2024},
  publisher={IEEE}
}

@article{pan2024unifying,
  title={Unifying large language models and knowledge graphs: A roadmap},
  author={Pan, Shirui and Luo, Linhao and Wang, Yufei and Chen, Chen and Wang, Jiapu and Wu, Xindong},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2024},
  publisher={IEEE}
}

@article{feng2020codebert,
  title={Codebert: A pre-trained model for programming and natural languages},
  author={Feng, Zhangyin and Guo, Daya and Tang, Duyu and Duan, Nan and Feng, Xiaocheng and Gong, Ming and Shou, Linjun and Qin, Bing and Liu, Ting and Jiang, Daxin and others},
  journal={arXiv preprint arXiv:2002.08155},
  year={2020}
}

@article{guo2020graphcodebert,
  title={Graphcodebert: Pre-training code representations with data flow},
  author={Guo, Daya and Ren, Shuo and Lu, Shuai and Feng, Zhangyin and Tang, Duyu and Liu, Shujie and Zhou, Long and Duan, Nan and Svyatkovskiy, Alexey and Fu, Shengyu and others},
  journal={arXiv preprint arXiv:2009.08366},
  year={2020}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}


@article{shanahan2024talking,
  title={Talking about large language models},
  author={Shanahan, Murray},
  journal={Communications of the ACM},
  volume={67},
  number={2},
  pages={68--79},
  year={2024},
  publisher={ACM New York, NY, USA}
}

@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}



@inproceedings{li2023skcoder,
  title={Skcoder: A sketch-based approach for automatic code generation},
  author={Li, Jia and Li, Yongmin and Li, Ge and Jin, Zhi and Hao, Yiyang and Hu, Xing},
  booktitle={2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)},
  pages={2124--2135},
  year={2023},
  organization={IEEE}
}

@inproceedings{wu2020deep,
  title={How are deep learning models similar? an empirical study on clone analysis of deep learning software},
  author={Wu, Xiongfei and Qin, Liangyu and Yu, Bing and Xie, Xiaofei and Ma, Lei and Xue, Yinxing and Liu, Yang and Zhao, Jianjun},
  booktitle={Proceedings of the 28th International Conference on Program Comprehension},
  pages={172--183},
  year={2020}
}

@inproceedings{li2023cctest,
  title={Cctest: Testing and repairing code completion systems},
  author={Li, Zongjie and Wang, Chaozheng and Liu, Zhibo and Wang, Haoxuan and Chen, Dong and Wang, Shuai and Gao, Cuiyun},
  booktitle={2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)},
  pages={1238--1250},
  year={2023},
  organization={IEEE}
}

@article{bubeck2023sparks,
  title={Sparks of artificial general intelligence: Early experiments with gpt-4},
  author={Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and others},
  journal={arXiv preprint arXiv:2303.12712},
  year={2023}
}

@article{liu2023your,
  title={Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation},
  author={Liu, Jiawei and Xia, Chunqiu Steven and Wang, Yuyao and Zhang, Lingming},
  journal={arXiv preprint arXiv:2305.01210},
  year={2023}
}

@article{hendrycks2020aligning,
  title={Aligning ai with shared human values},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Critch, Andrew and Li, Jerry and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2008.02275},
  year={2020}
}


@inproceedings{feng2023investigating,
  title={Investigating Code Generation Performance of Chat-GPT with Crowdsourcing Social Data},
  author={Feng, Yunhe and Vanam, Sreecharan and Cherukupally, Manasa and Zheng, Weijian and Qiu, Meikang and Chen, Haihua},
  booktitle={Proceedings of the 47th IEEE Computer Software and Applications Conference},
  pages={1--10},
  year={2023}
}

@article{hendrycks2021measuring,
  title={Measuring coding challenge competence with apps},
  author={Hendrycks, Dan and Basart, Steven and Kadavath, Saurav and Mazeika, Mantas and Arora, Akul and Guo, Ethan and Burns, Collin and Puranik, Samir and He, Horace and Song, Dawn and others},
  journal={arXiv preprint arXiv:2105.09938},
  year={2021}
}

@article{li2023codeeditor,
  title={Codeeditor: Learning to edit source code with pre-trained models},
  author={Li, Jia and Li, Ge and Li, Zhuo and Jin, Zhi and Hu, Xing and Zhang, Kechi and Fu, Zhiyi},
  journal={ACM Transactions on Software Engineering and Methodology},
  volume={32},
  number={6},
  pages={1--22},
  year={2023},
  publisher={ACM New York, NY}
}

@article{wang2022machine,
  title={Machine/deep learning for software engineering: A systematic literature review},
  author={Wang, Simin and Huang, Liguo and Gao, Amiao and Ge, Jidong and Zhang, Tengfei and Feng, Haitao and Satyarth, Ishna and Li, Ming and Zhang, He and Ng, Vincent},
  journal={IEEE Transactions on Software Engineering},
  volume={49},
  number={3},
  pages={1188--1231},
  year={2022},
  publisher={IEEE}
}

@article{ramirez2018systematic,
  title={A systematic review of interaction in search-based software engineering},
  author={Ramirez, Aurora and Romero, Jose Raul and Simons, Christopher L},
  journal={IEEE Transactions on Software Engineering},
  volume={45},
  number={8},
  pages={760--781},
  year={2018},
  publisher={IEEE}
}