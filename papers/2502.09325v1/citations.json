[
  {
    "index": 0,
    "papers": [
      {
        "key": "BN-WVAD",
        "author": "Zhou, Yixuan and Qu, Yi and Xu, Xing and Shen, Fumin and Song, Jingkuan and Shen, Heng Tao",
        "title": "Batchnorm-based weakly supervised video anomaly detection"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "I3D",
        "author": "Carreira, Joao and Zisserman, Andrew",
        "title": "Quo vadis, action recognition? a new model and the kinetics dataset"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "PDVC",
        "author": "Wang, Teng and Zhang, Ruimao and Lu, Zhichao and Zheng, Feng and Cheng, Ran and Luo, Ping",
        "title": "End-to-end dense video captioning with parallel decoding"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "C3D",
        "author": "Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar",
        "title": "Learning spatiotemporal features with 3d convolutional networks"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "MMN",
        "author": "Wang, Zhenzhi and Wang, Limin and Wu, Tao and Li, Tianhao and Wu, Gangshan",
        "title": "Negative sample matters: A renaissance of metric learning for temporal grounding"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "DistilBERT",
        "author": "Sanh, V",
        "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "UCFCrime",
        "author": " Sultani, Waqas  and  Chen, Chen  and  Shah, Mubarak ",
        "title": "Real-World Anomaly Detection in Surveillance Videos"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "UCA",
        "author": "Yuan, Tongtong and Zhang, Xuange and Liu, Kun and Liu, Bo and Chen, Chen and Jin, Jian and Jiao, Zhenzhen",
        "title": "Towards Surveillance Video-and-Language Understanding: New Dataset Baselines and Challenges"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "BLEU",
        "author": "Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing",
        "title": "Bleu: a method for automatic evaluation of machine translation"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "llava-onevision",
        "author": "Li, Bo and Zhang, Yuanhan and Guo, Dong and Zhang, Renrui and Li, Feng and Zhang, Hao and Zhang, Kaichen and Zhang, Peiyuan and Li, Yanwei and Liu, Ziwei and others",
        "title": "Llava-onevision: Easy visual task transfer"
      },
      {
        "key": "internvl",
        "author": "Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Zhong, Muyan and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and others",
        "title": "Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "llava-onevision",
        "author": "Li, Bo and Zhang, Yuanhan and Guo, Dong and Zhang, Renrui and Li, Feng and Zhang, Hao and Zhang, Kaichen and Zhang, Peiyuan and Li, Yanwei and Liu, Ziwei and others",
        "title": "Llava-onevision: Easy visual task transfer"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "internvl",
        "author": "Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Zhong, Muyan and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and others",
        "title": "Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "qwen2VL",
        "author": "Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and others",
        "title": "Qwen2-vl: Enhancing vision-language model's perception of the world at any resolution"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "VQAv2",
        "author": "Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi",
        "title": "Making the v in vqa matter: Elevating the role of image understanding in visual question answering"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "video-mme",
        "author": "Fu, Chaoyou and Dai, Yuhan and Luo, Yongdong and Li, Lei and Ren, Shuhuai and Zhang, Renrui and Wang, Zihan and Zhou, Chenyu and Shen, Yunhang and Zhang, Mengdan and others",
        "title": "Video-mme: The first-ever comprehensive evaluation benchmark of multi-modal llms in video analysis"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "mm-vet",
        "author": "Yu, Weihao and Yang, Zhengyuan and Li, Linjie and Wang, Jianfeng and Lin, Kevin and Liu, Zicheng and Wang, Xinchao and Wang, Lijuan",
        "title": "Mm-vet: Evaluating large multimodal models for integrated capabilities"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "mmbench-video",
        "author": "Fang, Xinyu and Mao, Kangrui and Duan, Haodong and Zhao, Xiangyu and Li, Yining and Lin, Dahua and Chen, Kai",
        "title": "MMBench-Video: A Long-Form Multi-Shot Benchmark for Holistic Video Understanding"
      }
    ]
  }
]