

\subsection{Matrix Rigidity}

\begin{definition}[Matrix rigidity]
    The \defn{rigidity} of a matrix $A \in \F^{N \times N}$ of rank $r$ over a field $\F$, denoted by $\R_{A}^{\F}(r)$, is defined as the minimum $s$, such that there is a rank-$r$ matrix $L \in \F^{N \times N}$ that agree with $A$ in at least $N^2 - s$ entries, i.e., there is subset of indices $I \subset [N]^2$ with $|I| \ge N^2 - s$, satisfying
    \begin{align*}
        A[i,j] = L[i,j], \quad \forall (i,j) \in I.
    \end{align*}
\end{definition}


\begin{definition}[Razborov rigidity]
    We say a matrix family $\BK{A_n}_{n \in \mathbb{N}}$ is \defn{Razborov rigid} over some field $\F$, if there is a constant $\delta > 0$, such that for any $2^n \times 2^n$ matrix $A_n$, we have \[\R_{A_n}^{\F} \bk*{2^{\log^{\omega(1)} n}} \ge \delta \cdot 4^n.\]
\end{definition}

\subsection{Rigidity Variants}

\begin{definition}[Boolean rigidity]
    For any $x \in \F_p$, we define its \defn{Booleanization} as 
    \begin{align*}
        \bool(x) \defeq \begin{cases}
            1 & \text{if } x \equiv 1 \pmod p,\\
            -1 & \text{otherwise.}
        \end{cases}
    \end{align*}
    The \defn{Boolean rigidity} of a matrix $A \in \F_p^{N \times N}$ of rank $r$ over $\F_p$, denoted by $\boolRigidity{A}{r}$ is defined as the minimum $s$, such that there is a matrix $L \in \F_p^{N \times N}$ with $\rank(L) \le r$ and a subset of indices $I \subset [N]^2$ with $|I| \ge N^2 - s$, satisfying
    \begin{align*}
        \bool(A[i,j]) = \bool(L[i,j]), \quad \forall (i,j) \in I.
    \end{align*}
\end{definition}

\begin{remark}
\label{rmk:boolean_close_to_regular}
    For any rank $r$, we have $\R_{A}^{\F_p} (O(r^{p-1})) \le \boolRigidity{A}{r} \le \R_{A}^{\F_p} (r)$.
\end{remark}

\begin{proofof}{the first inequality}
    Let $L \in \F_p^{N \times N}$ be the rank-$r$ matrix that approximates $A$ in the boolean sense, then $\tilde{L} \in \F_p^{N \times N}$ defined by $\tilde{L}[i,j] \defeq \bool\bk{L[i,j]}$ for any $(i,j) \in [N]^2$ approximates $A$ in the regular sense with the same error rate. Moreover, we prove that $\rank\bk{\tilde{L}} \le O(r^{p-1})$ below, using a standard technique called the \emph{polynomial method}.

    Let $L \eqdef U^{\top} V$ be the low-rank decomposition of $L$, where $U,V$ are matrices in $\F_p^{r \times N}$. Then, the $(i,j)$-entry of $L$ can be represented as 
    $L[i,j] = \vec{u_i}^\top \vec{v_j} = \sum_{k=1}^{r} \vec{u_i}[k] \vec{v_j}[k]$, where $\vec{u_i}$ is the $i$-th column vector of $U$ and $\vec{v_j}$ is defined similarly.
    By Fermart's little theorem, each entry of $\tilde{L}$ can be represented as 
    \begin{align*}
        \label{eq:low-rank_from_Fermart}
        \tilde{L}[i,j] = \bool\bk{L[i,j]}
        = 1 - 2 \cdot \bk{L[i,j] - 1}^{p-1}
        = 1 - 2 \cdot \bk*{\sum_{k=1}^{r} \vec{u_i}[k] \vec{v_j}[k] - 1}^{p-1}. \numberthis
    \end{align*}
    By expanding the $(p-1)$-th power in \eqref{eq:low-rank_from_Fermart}, we can further write the RHS of \eqref{eq:low-rank_from_Fermart} as 
    \begin{align*}
        \label{eq:expand_power}
        \tilde{L}[i,j] = \sum_{\vec{\alpha} \in \BK{0,1}^r,\, |\vec{\alpha}|\le p-1} C_{\vec{\alpha}} \vec{u_i}^{\vec{\alpha}} \vec{v_j}^{\vec{\alpha}}, \numberthis
    \end{align*}
    where $C_{\vec{\alpha}}$ are constant coefficients,  and we use the notation that, for an exponent vector $\vec{\alpha}$ and a vector $\vec{u}_i$, we write $\vec{u}_i^{\vec{\alpha}}$ to denote $u_{i1}^{\alpha_1} u_{i2}^{\alpha_2} \cdots u_{ir}^{\alpha_r}$. As there are at most $O(r^{p-1})$ different terms in the sum in \eqref{eq:expand_power}, one can conclude that $\rank\bk{\tilde{L}} \le O(r^{p-1})$ and $\R_{A}^{\F_p} (O(r^{p-1})) \le \boolRigidity{A}{r}$. 
\end{proofof}


We also consider the notion of \emph{probabilistic} Boolean rank, which combines Boolean rank with the notion of probabilistic rank from prior work~\cite{alman2017probabilistic}:

\begin{definition}[Probabilistic Boolean rank]
    For a matrix $A \in \F^{N \times N}$, The \defn{probabilistic Boolean rank} of an error rate $\delta \in (0,1)$ is defined as the minimum rank $r$, such that there is a distribution $\mathcal{L}$ of $N \times N$ rank-$r$ matrices, satisfying
    \begin{align*}
        \Pr_{L \sim \mathcal{L}}\Bk*{\bool\bk{A[i,j]} \neq \bool\bk{L[i,j]}} \le \delta, \quad \forall (i,j) \in [N]^2.
    \end{align*}
\end{definition}



\subsection{Matrix Power Families}


\begin{definition}[Kronecker power]
    For any matrix $A \in \BK{-1,1}^{q \times q}$, its Kronecker $n$-th power $\kro{A}$ is a matrix in $\BK{-1, 1}^{q^n \times q^n}$, with its columns and rows being indexed by vectors from $[q]^n$, and entries being
    \begin{align*}
        \kro{A}[x, y] \defeq \prod_{i=1}^n A[x_i, y_i],
    \end{align*}
    for any $x = (x_1, \ldots, x_n) \in [q]^n$ and $y = (y_1, \ldots, y_n) \in [q]^n$.
\end{definition}

\begin{definition}[Majority power]
    For any matrix $A \in \BK{-1,1}^{q \times q}$, its $n$-th power $\maj{A}$ is a matrix in $\BK{-1, 1}^{q^n \times q^n}$, with its columns and rows being indexed by vectors from $[q]^n$, and entries being
    \begin{align*}
        \maj{A}[x, y] \defeq \Maj\bk{ A[x_1, y_1], \ldots, A[x_n, y_n]},
    \end{align*}
    for any $x = (x_1, \ldots, x_n) \in [q]^n$ and $y = (y_1, \ldots, y_n) \in [q]^n$, where $\Maj: \BK{-1, 1}^n \to \BK{-1, 1}$ is the majority function defined as 
    \begin{align*}
        \Maj(a_1, \ldots, a_n) = \begin{cases}
            1 & \text{if } a_1 + \cdots + a_n \ge 0\\
            -1 & \text{otherwise}.
        \end{cases}
    \end{align*}
\end{definition}

\begin{definition}[Walsh-Hadamard matrix]
    We define the $n$-th \defn{Walsh-Hadamard matrix} $H_n \defeq \kro{H_1}$ as the $n$-th Kronecker power of the matrix $H_1 \defeq \bk*{\begin{matrix}
        1 & 1\\
        1 & -1
        \end{matrix}} $.
\end{definition}

\begin{definition}[Distance matrix]
    We define the $n$-th \defn{distance matrix} $M_n$ as the $n$-th Majority power of $M_1 \defeq \bk*{\begin{matrix}
        1 & -1\\
        -1 & 1
        \end{matrix}} $. 
    Equivalently, the distance matrix $M_n$ can be defined entry-wisely by 
    \begin{align*}
        M_n[x,y] = 2\indicator{|{x-y}| \le n/2}-1, \quad \forall x,y \in \BK{-1,1}^n.
    \end{align*}

\end{definition}
