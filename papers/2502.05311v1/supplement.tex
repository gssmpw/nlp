\documentclass{article}

\usepackage{arxiv}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[T1]{fontenc}
\usepackage{pgfplots}
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{cleveref}       % smart cross-referencing
\usepackage{lipsum}         % Can be removed after putting your text content
\usepackage{graphicx}
\usepackage{subcaption} % for captions below each image
\usepackage{caption}
\usepackage{dirtree}
\usepackage[english]{babel}
\usepackage{listings}
\usepackage{etoolbox}
\usepackage{csvsimple-l3}
\usepackage{tabularray,siunitx,xfp}
\usepackage{booktabs}
\usepackage{array} % For the centering control
\usepackage{tabularray}
\usepackage{enumitem}
\usepackage{tcolorbox}
\usepackage{csquotes}
\usepackage{adjustbox}


\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
\pgfplotsset{compat=1.18}
\pdfminorversion=6

\tolerance=1000

\DeclareGraphicsExtensions{.pdf,.png,.jpg,.svg}

\hbadness=99999  % or any number >=10000


\definecolor{lightyellow}{rgb}{1.0, 0.97, 0.86} % Light yellow color
\definecolor{mangotango}{rgb}{1.0, 0.51, 0.26}
\definecolor{bluebell}{rgb}{0.64, 0.64, 0.82}


% Define the style for our inline code box
\tcbuselibrary{most}
\tcbset{
    codestyle/.style={
        enhanced,
        fontupper=\normalsize\ttfamily\bfseries,
        nobeforeafter,
        tcbox raise base,
        boxrule=0.1pt,
        top=0pt,
        bottom=0pt,
        right=0pt,
        left=0pt,
        arc=3pt,
        boxsep=1.2pt,
        colback=gray!10,
        colframe=gray!50,
        breakable,
       hbox,
        on line,
        valign=center
    }
}

\newcounter{subsubsubsection}[subsubsection] % Reset when subsubsection changes
\renewcommand{\thesubsubsubsection}{\arabic{subsubsubsection}} % Use simple numbering: 1, 2, 3...



\newcommand{\code}[1]{\tcbox[codestyle]{\lstinline!#1!}}

\lstset{
  language=Python,
  showstringspaces=false
  columns=fullflexible,      % Ensure proper alignment
  keepspaces=true,           % Preserve space
%   basicstyle=\ttfamily\tiny, % Font size
%   basicstyle=\ttfamily\footnotesize, % Font size
  basicstyle=\ttfamily\scriptsize, % Font size
%   basicstyle=\ttfamily\small, % Font size
  keywordstyle=\color{blue},         % Keywords in blue
  commentstyle=\color{green},        % Comments in green
  stringstyle=\color{red},           % Strings in red
  numbers=left,                      % Line numbers on the left
  numberstyle=\tiny\color{gray},     % Line numbers style
  breaklines=true,                   % Line breaks
  frame=single,                      % Frame around code
  backgroundcolor=\color{lightyellow} % Set background color
}



\newcommand{\aldo} [1] 
{\todo[inline,backgroundcolor=green,size=\small ,bordercolor=white]{{\bf Aldo:} #1}}
\newcommand{\logan} [1] 
{\todo[inline,backgroundcolor=cyan,size=\small ,bordercolor=white]{{\bf Logan:} #1}}
\newcommand{\eduardo} [1] 
{\todo[inline,backgroundcolor=bluebell,size=\small ,bordercolor=white]{{\bf Zac:} #1}}
\newcommand{\kamal} [1] 
{\todo[inline,backgroundcolor=red,size=\small ,bordercolor=white]{{\bf Zac:} #1}}


\usepackage{authblk}
\renewcommand\Authfont{\bfseries}
\setlength{\affilsep}{0em}

\newbox{\orcid}\sbox{\orcid}{\includegraphics[scale=0.06]{orcid.pdf}}
\author[1]{\href{https://orcid.org/0000-0003-2867-1706}{\usebox{\orcid}\hspace{1mm}Logan Lang}\thanks{Corresponding author: \texttt{lllang@mix.wvu.edu}}}

\author[2]{\href{https://orcid.org/0000-0002-1164-2856}{\usebox{\orcid}\hspace{1mm}Eduardo Hernandez}\thanks{\texttt{Eduardo.Hernandez@csic.es}}}
\author[3]{\href{https://orcid.org/0000-0001-9737-8074}{\usebox{\orcid}\hspace{1mm}Kamal Choudhary}\thanks{\texttt{kamal.choudhary@nist.gov}}}
\author[1]{\href{https://orcid.org/0000-0001-5968-0571}{\usebox{\orcid}\hspace{1mm}Aldo H. Romero}\thanks{\texttt{Aldo.Romero@mail.wvu.edu}}}

\affil[1]{Department of Physics, West Virginia University, Morgantown, WV 26506, United States}
\affil[2]{Instituto de Ciencia de Materiales de Madrid, Campus de Cantoblanco, C. Sor Juana In√©s de la Cruz, 3, Fuencarral-El Pardo, Madrid 28049, Spain}
\affil[3]{National Institute of Standards and Technology, 100 Bureau Dr, Gaithersburg, MD 20899, United States}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{ParquetDB: A Lightweight Python Parquet-Based Database}


\begin{document}

\maketitle


\section{Parquet File Layout}

The Parquet file structure is engineered for optimal performance (refer to Figure Y for an overview of the Parquet file layout). Parquet files are partitioned into row groups, which serve as the horizontal segmentation of the dataset. Each row group is further divided into column chunks, and each column chunk comprises pages, representing the smallest storage unit in Parquet. At the conclusion of each Parquet file, a footer is appended, containing essential metadata, including the schema, field-level information, and row group metadata such as the minimum and maximum values for each column within a row group. This footer is fundamental for enabling efficient data access and is integral to the self-descriptive nature of Parquet files. The hierarchical organization of row groups, column chunks, and pages facilitates efficient data compression and retrieval, while also supporting advanced features like predicate pushdown and columnar projection. Parquet files also include metadata at various hierarchical levels: file-level metadata, which details the overarching structure, and row group metadata, which encompasses statistics such as minimum and maximum values that are crucial for query optimization.


\subsection{Pages}

Pages in Parquet files are responsible for storing the actual data, and each page is composed of two principal components: the page header and the data pages. The page header encapsulates metadata pertaining to the page, such as the data type, uncompressed and compressed page sizes, the codec utilized, the data page header, and optionally, the dictionary page header. The data page header conveys details including the number of values, the encoding type, and the definition and repetition level encodings, which facilitate the representation of nested structures. In scenarios employing dictionary encoding, the dictionary page header specifies the count of values within the dictionary. Subsequent to the page header is the dictionary page, if applicable, which contains the dictionary-encoded values. This dictionary page substantially reduces storage requirements by maintaining unique values that are referenced by the data pages. In the absence of dictionary encoding, the data pages directly store the encoded values.

\subsection{Bloom Filter}
This is located before the column index and offset index

\subsection{Page Index}

The Page Index in a Parquet file is located in the footer and provides critical statistics for column data pages, enabling more efficient data scanning. The Page Index contains two main structures: the ColumnIndex, which helps locate data pages containing specific values for a given scan predicate, and the OffsetIndex, which helps navigate by row index to retrieve matching values across different columns within a row group.

These index structures are specifically designed to make data retrieval operations, such as range scans and point lookups, I/O efficient. They allow a reader to access only the data pages necessary for a particular operation, thereby significantly reducing the overhead of reading irrelevant pages. For example, in range scans on sorted columns, the Page Index helps the reader skip non-relevant pages and directly access those with the desired values.

The index structures are stored separately from the row group metadata, right before the footer of the file, ensuring they do not add I/O overhead unless explicitly needed. This separation ensures that readers not requiring selective scans can avoid unnecessary index deserialization costs. The boundaries between pages are recorded using minimum and maximum values for each page, and these boundaries are used by readers to perform efficient searches, such as binary searches for ordered columns or sequential scans for unordered columns.

\subsection{Footer}
The footer in a Parquet file serves as a critical component that consolidates metadata necessary for efficient data operations. It contains comprehensive metadata for the entire file, providing essential information to support efficient data access and processing. The footer includes:

\subsubsection{FileMetaData}
The \texttt{FileMetaData} is the top-level metadata structure in a Parquet file. It encapsulates essential information about the file's schema, version, row groups, and other properties. This metadata enables readers to understand how to interpret and process the data stored within the file. Below is a detailed explanation of each component within the metadata:

\begin{itemize}[label=-]
    \item \textbf{Schema} - The schema describes each column in detail, specifying attributes such as column names, data types, repetition levels, number of child elements, and converted (logical) types.
    \item \textbf{Version} - The version of the Parquet format used to write the file.
    \item \textbf{Number of Rows} - The total number of rows in the file.
    \item \textbf{Key Value Metadata} - Optional user-defined key-value metadata.
    \item \textbf{Created by} - The writer version that created the file. Indicates the name and version of the software that wrote the Parquet file, such as "Apache Parquet-MR version 1.10.1" or "pyarrow 3.0.0".
    \item \textbf{Column Order} - A list of the column orders. Specifies the ordering of columns in the file, which can impact how data is read and optimized during query execution.
    \item \textbf{Encryption Algorithm} - Specifies the algorithm used to encrypt the file.
    \item \textbf{Footer Signing Key Metadata} - Metadata related to the key used to sign the footer, for encryption purposes.
\end{itemize}

\subsubsection{Schema}
The schema describes each column in detail, specifying attributes such as column names, data types, repetition levels, number of child elements, and converted (logical) types. The order of columns is important as it affects how data is read and optimized during query execution. The schema provides a detailed blueprint of the data structure within the Parquet file. It includes:

\begin{itemize}[label=-]
    \item \textbf{Column Names} - Identifiers for each field or column in the dataset.
    \item \textbf{Data Types} - Physical data types like \texttt{INT32}, \texttt{FLOAT}, \texttt{BYTE\_ARRAY}, etc.
    \item \textbf{Logical Types (Converted Types)} - Higher-level data types like \texttt{DECIMAL}, \texttt{DATE}, \texttt{TIMESTAMP}, which provide semantic meaning over physical types.
    \item \textbf{Repetition Levels} - Indicate whether fields are required, optional, or repeated (allowing for lists or arrays).
    \item \textbf{Nested Structures} - Information about complex types such as structs, maps, and lists, including the number of child elements and their respective schemas.
\end{itemize}


\subsubsection{Row Group MetaData}
Each row group in a Parquet file represents a horizontal partition of the data, containing a subset of rows for all columns. The metadata for each row group provides crucial information that enables efficient data access, storage optimization, and query execution. Below is a detailed explanation of each component within the row group metadata:

\begin{itemize}[label=-]
    \item \textbf{Column Chunks} - A list of Column Chunk Metadata for each column in the row group. Each column chunk corresponds to the data of a single column within the row group. The column chunk metadata includes information such as the data type, encoding schemes, compression codec, file offsets, and statistics like min and max values. This metadata is essential for readers to locate and interpret the column data correctly, allowing for efficient columnar access and operations like predicate pushdown and data skipping.
    \item \textbf{Total uncompressed byte size} - The total size in bytes of the row group before compression. This value represents the sum of the uncompressed sizes of all column chunks within the row group. It provides an estimate of the raw data size, which can be useful for understanding the level of compression achieved and for planning memory allocation during data processing.
    \item \textbf{Total compressed byte size} - The total size in bytes of the row group after compression. This is the actual size of the row group as stored on disk, after applying compression algorithms. It reflects the storage space utilized by the row group and is critical for I/O operations, as it influences the amount of data that needs to be read from or written to disk.
    \item \textbf{Number of rows} - The total number of rows contained in the row group. This indicates how many rows are present in the row group, which helps in dividing the dataset into manageable chunks for parallel processing. Knowing the number of rows is also important for query planning and optimization, as it affects operations like joins, aggregations, and limit clauses.
    \item \textbf{Sorting columns} - The columns by which the rows in the row group are sorted, including sorting order (ascending or descending). If the data within the row group is sorted based on one or more columns, this metadata specifies those columns and the sort order. Sorted data can significantly enhance query performance by enabling faster data retrieval, efficient range scans, and improved compression ratios. Query engines can leverage this information to optimize execution plans, especially for queries involving order-dependent operations or filters on sorted columns.
    \item \textbf{File Offset} - The byte offset in the file where the row group starts. This offset points to the exact location in the Parquet file where the row group's data begins. It allows readers to seek directly to the row group without scanning the entire file, facilitating random access and efficient data retrieval. This is particularly important in distributed storage systems or when dealing with large files.
    \item \textbf{Ordinal} - The position or index of the row group within the file. The ordinal is a zero-based index indicating the sequence of the row group in the file. It helps in identifying the order of row groups, which can be useful for certain operations like consistent data shuffling, partitioning, or when reconstructing the dataset's original sequence. The ordinal can also assist in correlating row groups across different files or datasets when performing distributed processing.
\end{itemize}

\subsubsection{ColumnChunk MetaData}
Contains metadata specific to the column chunk, such as encoding types, compression codec, data type, number of values, and statistics like min and max values. This is essential for reading and interpreting the column data correctly.

\begin{itemize}[label=-]
    \item \textbf{File Path} - Specifies the relative path to the file where the column chunk is stored. If the column chunk is in the same file as the metadata (which is common), this field may be null or omitted.
    \item \textbf{File Offset} - The byte offset within the file where the column chunk data begins. This allows readers to locate the exact position of the column data in the file.
    \item \textbf{Offset Index Offset} - The byte offset to the offset index for the column chunk. The offset index contains information about the locations of individual pages within the column chunk, which can be used for efficient data access.
    \item \textbf{Offset Index Length} - The length in bytes of the offset index. This tells readers how much data to read starting from the Offset Index Offset to obtain the full offset index.
    \item \textbf{Column Index Offset} - The byte offset to the column index for the column chunk. The column index provides min and max statistics for each page within the column chunk, facilitating faster queries by enabling data skipping.
    \item \textbf{Column Index Length} - The length in bytes of the column index. This indicates how much data to read from the Column Index Offset to retrieve the entire column index.
    \item \textbf{Crypto MetaData} - Contains information related to encryption, such as the encryption algorithm used and key metadata. This is crucial for decrypting the column chunk if encryption is applied.
    \item \textbf{Encrypted Metadata} - If the column metadata itself is encrypted, this field contains the encrypted bytes. This ensures that sensitive metadata is protected, and only authorized readers with the correct decryption keys can access it.
\end{itemize}

\subsubsection{Column MetaData}
The metadata for a column chunk provides detailed information about how the column's data is stored, encoded, and compressed within a Parquet file. This metadata is crucial for correctly reading and interpreting the column data, optimizing query performance, and managing resources efficiently. Below is an in-depth explanation of each component within the

\begin{itemize}[label=-]
    \item \textbf{Type} - The data type of the column. Specifies the physical data type used to store the column's values in the Parquet file.
    \item \textbf{Encodings} - A list of the encoding types used for the column data. Lists all encoding mechanisms applied to the column's data pages. Encodings optimize storage and speed up data processing by reducing data size and enabling efficient decompression.
    \item \textbf{Path in the schema} - The hierarchical path of the column in the schema. Represents the nested path to the column within the Parquet schema, especially important for complex data structures like nested records or arrays. For example, a path might be \texttt{["customer", "address", "city"]} for a nested field. This helps map the column data to the correct field in the application's data model.
    \item \textbf{Codec} - The compression codec used to compress the column data. Specifies the compression algorithm applied to the column's data pages. Compression reduces disk space usage and I/O costs.
    \item \textbf{Number of values} - The total number of values in the column chunk, including nulls. Represents the total count of logical values stored in the column chunk. This includes both null and non-null values.
    \item \textbf{Total uncompressed size} - The total size in bytes of the column chunk data before compression. Indicates the amount of data before any compression is applied.
    \item \textbf{Total compressed size} - The total size in bytes of the column chunk data after compression. The actual size of the data stored on disk. This impacts storage and retrieval performance.
    \item \textbf{Key\_value\_metadata} - Optional key-value metadata specific to the column. Allows for custom metadata to be attached to the column.
    \item \textbf{Data page offset} - The byte offset in the file to the first data page of the column chunk. Specifies where the column's data pages begin in the file. Data pages contain the actual encoded and compressed data.
    \item \textbf{Index page offset} - The byte offset in the file to the index page for the column chunk. If present, the index page contains information that allows for faster data access.
    \item \textbf{Dictionary\_page\_offset} - The byte offset in the file to the dictionary page of the column chunk. Relevant when dictionary encoding is used. The dictionary page contains the unique values (dictionary) that data pages reference.
    \item \textbf{Statistics} - Statistical information for the column, including min and max values. Provides aggregate statistics about the column data, such as:
    \begin{itemize}
        \item \textbf{Minimum Value}: The smallest value in the column chunk.
        \item \textbf{Maximum Value}: The largest value in the column chunk.
        \item \textbf{Null Count}: The number of null values.
        \item \textbf{Distinct Count}: The number of distinct values (optional).
        \item \textbf{Sum}: The total sum of all values (optional).
    \end{itemize}
    \item \textbf{Encoding\_stats} - Statistics about the encodings used in the column chunk, including counts of pages encoded with each encoding type. Details how different encoding methods are applied across the data pages in the column chunk.
    \item \textbf{Bloom\_filter\_offset} - The byte offset in the file to the Bloom filter data for the column. Points to the location of the Bloom filter, a probabilistic data structure used to test whether an element is a member of a set.
    \item \textbf{Bloom\_filter\_length} - The length in bytes of the Bloom filter data for the column. Indicates the size of the Bloom filter.
\end{itemize}

\section{How Parquet Files are written}
% https://cloudsqale.com/2020/05/29/how-parquet-files-are-written-row-groups-pages-required-memory-and-flush-operations/
To gain a deeper understanding of how pages are formed within Parquet files, we must explore the underlying mechanisms involved in the process of writing Parquet files (for more detailed information, refer to this article). Although Parquet is a columnar format, its internal representation necessitates writing data row by row. Each row is decomposed into individual columns, and the values of these columns are subsequently added to their respective in-memory column stores. During this phase, metadata such as minimum and maximum value statistics, as well as the count of NULL values, is also updated for each column. At this stage, all data remains in memory.

Once the initial 100 values for a column have been written (equivalent to 100 rows), the Parquet writer evaluates whether the column content exceeds the specified page size threshold, which is typically set at 1 MB. If the raw data size remains below this threshold, subsequent page size checks are dynamically adjusted based on the actual size of the column, rather than occurring after each value or strictly every 100 values. Consequently, the page size limit is not rigidly enforced. Should the raw data size exceed the page size threshold, the column content is compressed (if compression is enabled for the Parquet file) and then flushed into the page store. Each page also contains metadata, referred to as the page header, which includes the uncompressed and compressed sizes, the number of values, and statistics such as the minimum and maximum values for the column, along with the count of NULL values.

After writing the first 100 rows to memory, the Parquet writer checks whether the data size exceeds the specified row group size (block size), which by default is 128 MB. This size includes both the uncompressed size of the data in the column store (not yet flushed to the page store) and the compressed data already held in the page store for each column.

If the data size does not exceed the specified row group size, the Parquet writer estimates the next size check based on the average row size. This next check may occur after 100 rows or even after 10,000 rows, indicating that the row group size limit is not strictly enforced.

If the data size exceeds the specified row group size, the Parquet writer flushes the content of all column stores into their respective page stores and subsequently flushes all page stores to the output stream, column by column. This is the first instance where data is written to an external stream (HadoopPositionOutputStream), thereby making it potentially visible to external components, such as S3 Multipart Upload transfer threads, which may start uploading data to S3 in the background.

Once the row group has been flushed, the memory occupied by the current column and page stores is freed, although garbage collection cycles may be required to fully reclaim this memory.

It is important to note that the row group content itself does not include metadata (e.g., statistics or offsets). Instead, row group metadata is appended to the Parquet file footer.

After all row groups have been written and before the file is closed, the Parquet writer appends a footer to the end of the file. This footer includes the file schema (column names and their respective data types), along with detailed information for each row group, such as the total size, number of rows, and column-specific statistics (e.g., minimum and maximum values, and the count of NULL values). These statistics are provided for each row group individually, rather than for the entire file.

Storing metadata in the footer allows the Parquet writer to avoid keeping the entire file in memory or on local disk, thereby allowing row groups to be safely flushed once they are completed.

\end{document}
