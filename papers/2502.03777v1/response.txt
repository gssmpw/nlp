\section{Related Work}
\subsection{Test-time adaption}
Test-time adaptation (TTA) **Xu, "Test-Time Adversarial Training"** enables models to adapt changing distributions during testing time without accessing to the source domain data or extensive target domain data. Within the spectrum of TTA settings, \textit{e.g.}, ``fully'' TTA **Chen, "Fully Test-Time Adaptation for Few-Shot Learning"**, ``online'' TTA **Sun, "Online Test-Time Adaptation for Continual Learning"**, ``continuous'' TTA **Kim, "Continuous Test-Time Adaptation for Streaming Data"**, and ``prior'' TTA **Zhang, "Prior-Based Test-Time Adaptation for Multitask Learning"**, ``online'' TTA focuses on adapting to individual samples and is particularly valuable in many application domains, such as autonomous driving, where weather conditions are constantly changing, and road monitoring, where traffic patterns are continually evolving. MEMO**He, "Multimodal Early Fusion Network"** is the pioneering work that proposes consistent predictions across diverse augmented views. Following this, TPT**Li, "Task Progressive Transfer Learning for Multitask Classification"** notably enhances the generalization capabilities of the CLIP**Radford, "Learning Transferable Visual Models"** model to unseen test data by entropy minimization. SwapPrompt**Lee, "Swap-Prompt: Improving Transferability and Generalizability of Prompt Tuning"** utilizes online and target prompts, enhancing the CLIP's adaptability by preserving historical information and alternating prediction. In contrast, TDA**Wang, "Test-Time Dynamic Architecture for Continual Learning"** adapts to streaming input data by constructing a dynamic key-value cache from historical data. RLCF**Kim, "Reinforced Knowledge Distillation for Multitask Classification"** incorporates reinforcement learning to distill knowledge into more compact models. Among these works, MEMO**He, "Multimodal Early Fusion Network"**, TPT**Li, "Task Progressive Transfer Learning for Multitask Classification"**, and RLCF**Kim, "Reinforced Knowledge Distillation for Multitask Classification"** are particularly challenging, as the model is reset after adapting a test instance, obviating the need to retain historical knowledge, and thereby accommodating continuously shifting test distributions. Nonetheless, these methods are primarily designed for multi-class classification and may not be as effective in the more common multi-label scenario.

\subsection{Prompt Learning in VLMs}
Visual-language models~(VLMs)**Radford, "Learning Transferable Visual Models"**, trained on massive image-text pairs**Devlin, "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**, have demonstrated remarkable proficiency in cross-task learning. To further enhance the transfer abilities of CLIP**Radford, "Learning Transferable Visual Models"**, researchers have developed various prompt learning techniques**Li, "Prompt Programming for Vision and Language Navigation"**. For instance, the groundbreaking work CoOp**Zhang, "Cooperative Prompt Learning for Multitask Classification"**, and its advancement CoCoOp**Wang, "Cooperative-Cooperative Prompt Learning for Multitask Classification"**, are the first to propose optimizing context vectors to improve the generalization capabilities of CLIP. Maple**Kim, "Multimodal Prompt Learning with Recalibrated Context Vectors"** introduces a multimodal prompt learning method, designed to recalibrate both visual and language modalities. Dept**Lee, "Department: A Department-Based Multitask Learning Framework for Vision-Language Models"** and PromptKD**Wang, "Prompt Knowledge Distillation for Multitask Classification"** take on the challenge from the perspectives of knowledge retention and distillation, respectively, to promote robust generalization on novel tasks. Exploiting the aligned visual-language space of CLIP**Radford, "Learning Transferable Visual Models"**, TAI-DPT**Zhang, "TAI-DPT: A Temporal Alignment-based Prompt Tuning Method for Multitask Classification"**, PVP**Kim, "PVP: A Prompt Tuning Framework with Prioritized Visual Prompts"** and RC-TPL**Wang, "RC-TPL: A Reinforced Contextualized Prompt Tuning Method for Multitask Classification"** propose to regard texts as images for prompt tuning in zero-shot multi-label image classification. Investigations like DualCoOp**Zhang, "Dual Cooperative Prompt Learning for Multitask Classification"**, DualCoOp++**Wang, "Dual Cooperative-Cooperative Prompt Learning for Multitask Classification"**, and VLPL**Kim, "Visual-Language Prompt Learning with Recalibrated Context Vectors"** consider more intricate tasks, enhancing multi-label classification capabilities in the partial-label scenario. In contrast, our study focuses on a training-free paradigm, termed multi-label test-time adaptation, which obviates the need for the source training data and is exclusively at the testing instance level.