\section{Related Work}
\subsection{Test-time adaption}
Test-time adaptation (TTA)____ enables models to adapt changing distributions during testing time without accessing to the source domain data or extensive target domain data. Within the spectrum of TTA settings, \textit{e.g.}, ``fully'' TTA____, ``online'' TTA____, ``continuous'' TTA____, and ``prior'' TTA____, ``online'' TTA____ focuses on adapting to individual samples and is particularly valuable in many application domains, such as autonomous driving, where weather conditions are constantly changing, and road monitoring, where traffic patterns are continually evolving. MEMO____ is the pioneering work that proposes consistent predictions across diverse augmented views. Following this, TPT____ notably enhances the generalization capabilities of the CLIP____ model to unseen test data by entropy minimization. SwapPrompt____ utilizes online and target prompts, enhancing the CLIP's adaptability by preserving historical information and alternating prediction. In contrast, TDA____ adapts to streaming input data by constructing a dynamic key-value cache from historical data. RLCF____ incorporates reinforcement learning to distill knowledge into more compact models. Among these works, MEMO____, TPT____, and RLCF____ are particularly challenging, as the model is reset after adapting a test instance, obviating the need to retain historical knowledge, and thereby accommodating continuously shifting test distributions. Nonetheless, these methods are primarily designed for multi-class classification and may not be as effective in the more common multi-label scenario.

\subsection{Prompt Learning in VLMs}
Visual-language models~(VLMs)____, trained on massive image-text pairs____, have demonstrated remarkable proficiency in cross-task learning. To further enhance the transfer abilities of CLIP____, researchers have developed various prompt learning techniques____. For instance, the groundbreaking work CoOp____, and its advancement CoCoOp____, are the first to propose optimizing context vectors to improve the generalization capabilities of CLIP. Maple____ introduces a multimodal prompt learning method, designed to recalibrate both visual and language modalities. Dept____ and PromptKD____ take on the challenge from the perspectives of knowledge retention and distillation, respectively, to promote robust generalization on novel tasks. Exploiting the aligned visual-language space of CLIP____, TAI-DPT____, PVP____ and RC-TPL____ propose to regard texts as images for prompt tuning in zero-shot multi-label image classification. Investigations like DualCoOp____, DualCoOp++____, and VLPL____ consider more intricate tasks, enhancing multi-label classification capabilities in the partial-label scenario. In contrast, our study focuses on a training-free paradigm, termed multi-label test-time adaptation, which obviates the need for the source training data and is exclusively at the testing instance level.