\begin{figure*}[t!]
    \centering
    \renewcommand{\thesubfigure}{}
    \setlength{\tabcolsep}{0pt} % Remove extra spacing between columns
    \begin{tabular}{@{}cccc@{}}
        \subfigure{\includegraphics[width=0.24\textwidth]{figures/speaker_level_ei/emotion_diversity.pdf}} &
        \subfigure{\includegraphics[width=0.24\textwidth]{figures/speaker_level_ei/empathy.pdf}} &
        \subfigure{\includegraphics[width=0.24\textwidth]{figures/speaker_level_ei/grounding_frequency.pdf}} &
        \subfigure{\includegraphics[width=0.24\textwidth]{figures/speaker_level_ei/linear_intimacy_progression.pdf}} \\
    \end{tabular}
    \vspace{-0.3cm}
    \caption{\textbf{Speaker-Level EI Comparison between \dataset{} and \textsc{LoCoMo}~\cite{maharana-etal-2024-evaluating}.} 
    Each bar represents the distribution of EI attributes for individual speakers in the conversation. 
    For a comprehensive evaluation, refer to Appendix~\ref{appendix:speaker-ei}.}
    \label{fig:speaker-level-ei}
    \vspace{-0.3cm}
\end{figure*}

\section{Data Statistics and Analysis}
\label{sec:analysis}
This section analyzes the collected data, starting with general observations and statistics (\secref{ssec:analysis-data}).  
Next, we compare our dataset with LLM-generated dialogues, focusing on speaker-level emotional intelligence (EI) metrics (\secref{ssec:analysis-speaker-level-ei}).  
Finally, we examine persona consistency in real-world conversations, leveraging the fact that each speaker participates in at least two conversations (\secref{ssec:analysis-persona}).  

\subsection{Data Statistics \& General Observations}  
\label{ssec:analysis-data}  
The dataset comprises 10 participant pairs engaging in 16–21 days of conversation, with daily word counts ranging from 691 to 861.
Participants share 23–46 images per pair and revisit topics 6–8 times, showcasing sustained and rich interactions.
Detailed statistics are provided in Appendix~\ref{appendix:chat-statistics}.
Three key characteristics distinguish real-world human dialogues from LLM-generated dialogues:
First, Human dialogues are inherently noisy, featuring typos, abbreviations, acronyms, and slang (\textit{e.g.}, ``imo'' for ``in my opinion'' and ``dunno'' for ``don’t know''), reflecting the informal and natural flow of communication.
Second, human conversations exhibit noticeable gaps between messages unlike LLM-generated dialogues, reflecting asynchronous and flexible communication.
On average, participants take 20.98 minutes to respond, with a median gap of 2.22 minutes.
Some gaps extend up to 27.90 hours, highlighting the non-linear nature of real-world interactions (Appendix~\ref{appendix:temporal-gap}).
Third, human dialogues often include varying lengths of consecutive messages (\textit{i.e.,} chat bubbles) by the same speaker, reflecting diverse communication patterns.
On average, participants send 2.31 consecutive messages per turn, with a median of 2.00 and a maximum of 68, showcasing occasional extended monologues (Appendix~\ref{appendix:chat-bubbles}).

\subsection{vs. LLM-generated Dialogues}  
\label{ssec:analysis-speaker-level-ei}  
We evaluate speaker-level EI (\secref{ssec:speaker-level-ei}) in real-world and LLM-generated dialogues using the \textsc{LoCoMo} dataset~\cite{maharana-etal-2024-evaluating}.
Speaker-level EI is derived from message-level EI: reflectiveness, grounding acts, and empathy are computed using \texttt{gpt-4o-mini}, while sentiment, emotion, and intimacy are classified using task-specific fine-tuned RoBERTa models trained on labeled Twitter data~\cite{antypas2023supertweeteval}.  
Each speaker in each conversation receives an independent EI score.  
Figure~\ref{fig:speaker-level-ei} illustrates key differences between human (\dataset{}) and LLM-generated (\textsc{LoCoMo}) dialogues by showing the distribution of speaker EI scores (full comparison in Appendix~\ref{appendix:speaker-ei}):
(1) Humans exhibit greater emotion and sentiment diversity, while LLMs remain constrained;
(2) LLMs display excessive empathy; and
(3) Humans show high variance in EI attributes, whereas LLMs are more uniform, aligning with prior research~\cite{lee2024language}.  

High emotional intelligence—characterized by strong grounding, emotional alignment, and intimacy progression—enhances engagement and relationship-building~\cite{altman1973social, hatfield1993emotional, derks2008role, huang2017doesn, niederhoffer2002linguistic}.  
However, since human EI naturally varies across individuals and interactions, enforcing uniformly high EI in LLMs does not make them more human-like.  
Instead, tailoring LLMs to specific individuals better reflects the diverse dynamics of real human interactions.  


\subsection{Persona Consistency Analysis}  
\label{ssec:analysis-persona}  
We examine how speakers adapt their emotional intelligence (EI) based on their conversational partners.  
Figure~\ref{fig:persona-consistency} shows absolute differences in EI attributes per participant, capturing persona variability across interactions:
(1) Some participants maintain a stable persona, while others dynamically adapt their EI; and
(2) Intimacy progression shows the most variation, suggesting that rapport-building is highly influenced by the specific conversational partner.
These findings indicate that a speaker's persona is flexible and adjusts according to social dynamics, reflecting adaptive emotional behavior.

\begin{figure}[t!]
    \centering
    \setlength{\tabcolsep}{0pt} % Remove extra spacing between columns
    \includegraphics[width=\columnwidth]{figures/persona_consistency.pdf}
    \vspace{-0.5cm}
    \caption{\textbf{Persona Consistency.} Each value represents the absolute difference in EI attributes for individual speakers across two conversations, capturing how their EI varies depending on their conversational partners.}
    \label{fig:persona-consistency}
    \vspace{-0.5cm}
\end{figure}