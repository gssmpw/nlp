\begin{table*}[!th]
    \begin{minipage}{\textwidth}
    \centering
    \small
    \resizebox{\textwidth}{!}{
        \begin{tabular}{lcccccc}
            \toprule
            Dataset & Dialogue Participants & \# Turns / $\mathcal{C}$ & \# Session / $\mathcal{C}$ & \# Tokens / $\mathcal{C}$ & Multimodal & Collection \\
            \midrule
            MemoryBank~\cite{zhong2024memorybank} & Human-AI & 3.7 & 10 & 257.8 & \ding{55} & LLM-simulated \\
            LongMemEval~\cite{wu2024longmemeval} & Human-AI & 9.8 & 50.2 & 1,572.3 & \ding{55} & LLM-simulated \\

            \midrule
            SODA~\cite{kim-etal-2023-soda} & Human-Human & 7.6 & 1 & 122.4 & \ding{55} & LLM-simulated \\
            Conversation Chronicles~\cite{jang2023conversation} & Human-Human & 58.5 & 5 & 1,054.7 & \ding{55} & LLM-simulated \\
            LoCoMo~\cite{maharana-etal-2024-evaluating} & Human-Human & 588.2 & 27.2 & 13,377.2 & \ding{51} & LLM-simulated \\
            \midrule
            MPChat~\cite{ahn2023mpchat} & Human-Human & 2.8 & 1 & 53.3 & \ding{51} & Reddit \\
            MMDialog~\cite{feng2022mmdialog} & Human-Human & 4.6 & 1 & 72.5 & \ding{51} & Social media \\
            Daily Dialog~\cite{li2017dailydialog} & Human-Human & 7.9 & 1 & 114.7 & \ding{55} & Crowdsourcing \\
            MSC~\cite{xu2022beyond} & Human-Human & 53.3 & 4 & 1,225.9 & \ding{55} & Crowdsourcing \\
            \textbf{\dataset} & Human-Human & 894.4 & 21.9 & 17,109.8 & \ding{51} & Crowdsourcing \\
            \bottomrule
        \end{tabular}
    }
    \end{minipage}
    \vspace{-0.3cm}
    \caption{\textbf{Comparison of data statistics across various datasets.} \underline{Human-AI} dialogues primarily address task-oriented interactions where humans aim to achieve specific goals through the dialogue. 
    In contrast, \underline{Human-Human} dialogues involve conversational exchanges such as chit-chat or other forms of social interaction. 
    Unlike other works that simulate dialogues using models, \dataset{} is entirely derived from real-world human interactions.}
    \vspace{-0.5cm}
    \label{tab:data-statistics}
\end{table*}

\section{Related Work}
\paragraph{Long-term dialogues.}
Recent studies in long-term dialogue aim to improve model coherence and empathy through better memory recall of past interactions (See Table~\ref{tab:data-statistics} for more details).
Early work focused on collecting \textit{human-human} dialogues from online sources (\textit{e.g.,} Reddit) or via crowd-sourcing to evaluate model in multi-session, open-domain conversations~\cite{xu2022beyond, feng2022mmdialog, ahn2023mpchat, li2017dailydialog}, and collecting \textit{human-AI} dialogues to analyze user interactions and align models with user expectations~\cite{zheng2023lmsys, kopf2024openassistant, zhao2024wildchat}.
With LLMs now capable of processing longer contexts, recent studies simulate extensive \textit{human-human} dialogues~\cite{kim-etal-2023-soda, jang2023conversation, maharana-etal-2024-evaluating} and \textit{human-AI} dialogues~\cite{zhong2024memorybank, du2024perltqa, wu2024longmemeval} to improve model evaluation, addressing the difficulty of obtaining naturally long conversations.
While LLM simulations show some human-like traits, notable differences may remain compared to actual human interactions~\cite{hu-etal-2023-fine, kim-etal-2023-fantom, zhou2024real, mahowald2024dissociating, ivey2024real}.

In contrast to prior works, our work examines memory recalling capability of LLMs within real-world long-term \textit{human-human} dialogues, where informal cues may often challenge retention.

\paragraph{Emotional Intelligence.}
Prior research on emotional intelligence before the emergence of large language models (LLMs) primarily focused on affective understanding, where models were trained to recognize and interpret human emotions and sentiments based on text and its surrounding context~\cite{hu2004mining, pang-lee-2004-sentimental, hutto2014vader, rosenthal-etal-2017-semeval, mohammad-etal-2018-semeval, yin-etal-2020-sentibert, antypas2023supertweeteval}
With the advent of LLMs, researchers have adapted or fine-tuned these models for affective tasks, such as predicting emotion intensity and classifying emotions in human text~\cite{lei2023instructerc, liu2024emollms, zhang2023dialoguellm}.
Additionally, LLMs have been evaluated for their ability to infer how individuals might feel in specific scenarios~\cite{wang2023emotional, paech2023eq, huang2023emotionally, zhao2024both}.
However, existing studies remain limited to sentiment and emotion analysis at the message or context level, without assessing the overall emotional intelligence of a specific speaker across extended conversations.

In contrast, our work investigates long-term, real-world human dialogues, analyzing both genuine human interactions and LLM-simulated conversations through a comprehensive taxonomy of EI attributes. 
Beyond sentiment and emotion, we examine factors such as empathy, grounding acts, reflectiveness, and intimacy. Additionally, we use these EI attributes as metrics to evaluate how effectively a model simulates a specific persona over time.