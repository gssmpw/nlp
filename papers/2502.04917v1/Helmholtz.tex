The Helmholtz equation describes wave and diffusion phenomena, addressing variations over time within a spatial or combined spatial-temporal domain. We consider the following 2D Helmholtz equation
\begin{align}
    &u_{xx}+u_{yy} + k^2u - q(x,y) = 0, \quad (x,y) \in \Omega, \\
    &u(x,y) = 0, \quad (x,y)\in\partial\Omega, 
\end{align}
where
\begin{align}
    q(x,y) = (k^2-2(a\pi)^2)\sin(a\pi x)\sin(a\pi y).
\end{align}

We set $k = 1$ and $\Omega = [-1, 1]\times [-1,1]$ and the exact solution to the equation is
\begin{align}
    u(x,y) = \sin(a\pi x)\sin(a\pi y).
\end{align}

In this study, we focus on two different settings for parameter $a \in \{3,6\}$ in the forcing term $q(x,y)$, where the corresponding exact solution can be viewed in Fig.~\ref{Helm exact}. For both cases, we compare the compleX-PINN with the traditional PINN and RBA. 

All PINN-based models employ a 5-layer network architecture, each layer consisting of 60 neurons. The compleX-PINN uses a Cauchy layer with 1000 neurons. Training is conducted using the Adam optimizer for 10k iterations with a learning rate of $1 \times 10^{-4}$. Furthermore, we set $N_f = 5000$ for each model. Boundary conditions are implemented using a hard constraint formulated as $\hat{u} = (x^2-1)(y^2-1)\hat{u}_{NN}$~\cite{lu2021physics, sukumar2022exact,RRef4}. As a result, only the residual loss~\eqref{(4)} is enforced, and no boundary training points are included.

\begin{figure}[!htb]
    \centering
    % % Second and third images on the same line
    \begin{minipage}{0.45\textwidth}
    \centering
    \includegraphics[width=0.98\linewidth, height=0.65\textwidth]{Helm-Exact-3-3.png}    
    \end{minipage}
    \begin{minipage}{0.45\textwidth}
   \centering
    \includegraphics[width=0.98\linewidth, height=0.65\textwidth]{Helm-Exact-6-6.png}
    \end{minipage}
    \vspace{1em} % Add some vertical space between the images
   \caption{The exact solutions for the 2D Helmholtz equation when $a = 3$ (left) and $a = 6$ (right).}\label{Helm exact}
\end{figure}

The results for each model can be visualized in Fig.~\ref{Helm Point-wise Error}. For $a = 3$, both PINN and RBA exhibit significant errors spread across the domain, while compleX-PINN accurately predicts the solution across nearly the entire domain, with only small localized errors. Moreover, the maximum error for compleX-PINN ($2.11 \times 10^{-3}$) is substantially lower than those of PINN ($9.02 \times 10^{-2}$) and RBA ($3.01 \times 10^{-2}$).



Moreover, for the $a = 6$ case, point-wise error comparisons across PINN, RBA, and compleX-PINN highlight the better accuracy of compleX-PINN. The PINN prediction exhibits regions of significant error, particularly near the boundaries and in specific interior areas, with a maximum error of $0.383$. The RBA method reduces these errors but still shows localized high-error regions, achieving a maximum error of $0.146$. In contrast, compleX-PINN demonstrates substantially improved performance with a significantly lower maximum error of $1.97\times 10^{-2}$.


The relative $L^2$ error history is shown in Fig.~\ref{Helm-HIST}. We can see the relative $L^2$ errors for compleX-PINN decrease faster to lower values, compared with PINN and RBA. These results underscore the effectiveness of compleX-PINN in achieving higher accuracy and better error control compared to the baseline methods.


\begin{figure}[!htb]
    \centering
    \begin{minipage}{0.45\textwidth}
    \centering
    \includegraphics[width=\linewidth]{Helm-PINN-Error-3-3.png}  
    \small PINN ($a=3$): $9.02\times 10^{-2} (L^\infty)$
    \end{minipage}
    \begin{minipage}{0.45\textwidth}
    \centering
    \includegraphics[width=\linewidth]{Helm-PINN-Error-6-6.png}
    \small PINN ($a=6$): $3.83\times 10^{-1} (L^\infty)$
    \end{minipage}


    
    \begin{minipage}{0.45\textwidth}
    \centering
    \includegraphics[width=\linewidth]{Helm-RBA-Error-3-3.png}
    \small RBA ($a=3$): $3.01\times 10^{-2} (L^\infty)$
    \end{minipage}
    \begin{minipage}{0.45\textwidth}
    \centering
    \includegraphics[width=\linewidth]{Helm-RBA-Error-6-6.png}  
    \small RBA ($a=6$): $1.46\times 10^{-1} (L^\infty)$
    \end{minipage}

    
    \begin{minipage}{0.45\textwidth}
    \centering
    \includegraphics[width=\linewidth]{Helm-XNet-Error-3-3.png}  
    \small compleX-PINN ($a=3$): $\bm{2.11\times 10^{-3}} (L^\infty)$
    \end{minipage}
    \begin{minipage}{0.45\textwidth}
    \centering
    \includegraphics[width=\linewidth]{Helm-XNet-Error-6-6.png}
    \small compleX-PINN ($a=6$): $\bm{1.97\times 10^{-2}} (L^\infty)$
    \end{minipage}
    \caption{Point-wise errors for traditional PINN (first row), RBA (second row), and compleX-PINN (third row), respectively. The first column stands for the results for $a = 3$ and the second is for $a = 6$. compleX-PINN receives a lower $L^{\infty}$ error for both cases, compared with PINN and RBA.
    }\label{Helm Point-wise Error}
\end{figure}

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.5\textwidth]{Helm-L2-HIST.png}    
    \vspace{1em}
    \caption{Relative \( L^2 \) error history of PINN, RBA, and compleX-PINN for the 2D Helmholtz equation for $a = 3$ and $6$. CompleX-PINN converges faster to a lower value. E.g., when $a = 3$, the $L^2$ error is reduced to below $0.01$ for about 20k iterations, while the errors for the other two models can only archive the lowest value around $0.03$.}\label{Helm-HIST}
\end{figure}