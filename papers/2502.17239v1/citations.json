[
  {
    "index": 0,
    "papers": [
      {
        "key": "hsu2021hubert",
        "author": "Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman",
        "title": "Hubert: Self-supervised speech representation learning by masked prediction of hidden units"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "chen2022wavlm",
        "author": "Chen, Sanyuan and Wang, Chengyi and Chen, Zhengyang and Wu, Yu and Liu, Shujie and Chen, Zhuo and Li, Jinyu and Kanda, Naoyuki and Yoshioka, Takuya and Xiao, Xiong and others",
        "title": "Wavlm: Large-scale self-supervised pre-training for full stack speech processing"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "zeghidour2021soundstream",
        "author": "Zeghidour, Neil and Luebs, Alejandro and Omran, Ahmed and Skoglund, Jan and Tagliasacchi, Marco",
        "title": "Soundstream: An end-to-end neural audio codec"
      },
      {
        "key": "defossez2022high",
        "author": "D{\\'e}fossez, Alexandre and Copet, Jade and Synnaeve, Gabriel and Adi, Yossi",
        "title": "High fidelity neural audio compression"
      },
      {
        "key": "kumar2024high",
        "author": "Kumar, Rithesh and Seetharaman, Prem and Luebs, Alejandro and Kumar, Ishaan and Kumar, Kundan",
        "title": "High-fidelity audio compression with improved rvqgan"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "zhang2024speechtokenizer",
        "author": "Zhang, Xin and Zhang, Dong and Li, Shimin and Zhou, Yaqian and Qiu, Xipeng",
        "title": "Speechtokenizer: Unified speech tokenizer for speech language models"
      },
      {
        "key": "defossez2024moshi",
        "author": "D{\\'e}fossez, Alexandre and Mazar{\\'e}, Laurent and Orsini, Manu and Royer, Am{\\'e}lie and P{\\'e}rez, Patrick and J{\\'e}gou, Herv{\\'e} and Grave, Edouard and Zeghidour, Neil",
        "title": "Moshi: a speech-text foundation model for real-time dialogue"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "chu2023qwen",
        "author": "Chu, Yunfei and Xu, Jin and Zhou, Xiaohuan and Yang, Qian and Zhang, Shiliang and Yan, Zhijie and Zhou, Chang and Zhou, Jingren",
        "title": "Qwen-audio: Advancing universal audio understanding via unified large-scale audio-language models"
      },
      {
        "key": "chu2024qwen2",
        "author": "Chu, Yunfei and Xu, Jin and Yang, Qian and Wei, Haojie and Wei, Xipin and Guo, Zhifang and Leng, Yichong and Lv, Yuanjun and He, Jinzheng and Lin, Junyang and others",
        "title": "Qwen2-audio technical report"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "hu2024wavllm",
        "author": "Hu, Shujie and Zhou, Long and Liu, Shujie and Chen, Sanyuan and Meng, Lingwei and Hao, Hongkun and Pan, Jing and Liu, Xunying and Li, Jinyu and Sivasankaran, Sunit and others",
        "title": "Wavllm: Towards robust and adaptive speech large language model"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "deshmukh2023pengi",
        "author": "Deshmukh, Soham and Elizalde, Benjamin and Singh, Rita and Wang, Huaming",
        "title": "Pengi: An audio language model for audio tasks"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "radford2023robust",
        "author": "Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya",
        "title": "Robust speech recognition via large-scale weak supervision"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "wang2023neural",
        "author": "Wang, Chengyi and Chen, Sanyuan and Wu, Yu and Zhang, Ziqiang and Zhou, Long and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and others",
        "title": "Neural codec language models are zero-shot text to speech synthesizers"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "du2024cosyvoice",
        "author": "Du, Zhihao and Chen, Qian and Zhang, Shiliang and Hu, Kai and Lu, Heng and Yang, Yexin and Hu, Hangrui and Zheng, Siqi and Gu, Yue and Ma, Ziyang and others",
        "title": "Cosyvoice: A scalable multilingual zero-shot text-to-speech synthesizer based on supervised semantic tokens"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "mehta2024matcha",
        "author": "Mehta, Shivam and Tu, Ruibo and Beskow, Jonas and Sz{\\'e}kely, {\\'E}va and Henter, Gustav Eje",
        "title": "Matcha-TTS: A fast TTS architecture with conditional flow matching"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "HelloGPT4o",
        "author": "OpenAI ",
        "title": "Hello GPT-4o"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "defossez2024moshi",
        "author": "D{\\'e}fossez, Alexandre and Mazar{\\'e}, Laurent and Orsini, Manu and Royer, Am{\\'e}lie and P{\\'e}rez, Patrick and J{\\'e}gou, Herv{\\'e} and Grave, Edouard and Zeghidour, Neil",
        "title": "Moshi: a speech-text foundation model for real-time dialogue"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "zeng2024glm",
        "author": "Zeng, Aohan and Du, Zhengxiao and Liu, Mingdao and Wang, Kedong and Jiang, Shengmin and Zhao, Lei and Dong, Yuxiao and Tang, Jie",
        "title": "GLM-4-Voice: Towards Intelligent and Human-Like End-to-End Spoken Chatbot"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "wang2024freeze",
        "author": "Wang, Xiong and Li, Yangze and Fu, Chaoyou and Xie, Lei and Li, Ke and Sun, Xing and Ma, Long",
        "title": "Freeze-omni: A smart and low latency speech-to-speech dialogue model with frozen llm"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "fu2025vita",
        "author": "Fu, Chaoyou and Lin, Haojia and Wang, Xiong and Zhang, Yi-Fan and Shen, Yunhang and Liu, Xiaoyu and Li, Yangze and Long, Zuwei and Gao, Heting and Li, Ke and others",
        "title": "VITA-1.5: Towards GPT-4o Level Real-Time Vision and Speech Interaction"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "yu2024salmonn",
        "author": "Yu, Wenyi and Wang, Siyin and Yang, Xiaoyu and Chen, Xianzhao and Tian, Xiaohai and Zhang, Jun and Sun, Guangzhi and Lu, Lu and Wang, Yuxuan and Zhang, Chao",
        "title": "SALMONN-omni: A Codec-free LLM for Full-duplex Speech Understanding and Generation"
      }
    ]
  }
]