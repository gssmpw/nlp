\section{Related Work}
\label{sec:related}

\subsection{3D Visual Grounding}
3D visual grounding aims to locate a target object within a 3D scene based on natural language descriptions~\citep{liu2024surveytextguided3dvisual}. Existing methods are typically categorized into two-stage and single-stage approaches.
Two-stage methods follow a detect-then-match paradigm. In the first stage, they independently extract features from the language query using pre-trained language models~\citep{devlin2018bert,pennington2014glove,chung2014empirical} and predict candidate 3D objects using pre-trained 3D detectors~\citep{qi2019deep,liu2021group} or segmenters~\citep{chen2021hierarchical,jiang2020pointgroup,vu2022softgroup}. In the second stage, they focus on aligning the vision and text features to identify the target object. Techniques for feature fusion include attention mechanisms with Transformers~\citep{he2021transrefer3d,zhao20213dvg}, contrastive learning~\citep{abdelreheem20223dreftransformer}, and graph-based matching~\citep{feng2021free,huang2021text,yuan2021instancerefer}. 
% However, these methods suffer from a detection bottleneck: objects missed in the first stage cannot be recovered later, and they often have high computational overhead.
In contrast, single-stage methods integrate object detection and feature extraction, allowing for direct identification of the target object. Methods in this category include guiding keypoint selection using textual features~\citep{luo20223d}, and measuring similarity between words and objects inspired by 2D image-language pre-trained models like GLIP~\citep{li2022grounded}, as in BUTD-DETR~\citep{jain2022bottom}. And methods like EDA~\citep{wu2023eda} and G$^3$-LQ~\citep{wang2024g} advance single-stage 3D visual grounding by enhancing multimodal feature discriminability through explicit text-decoupling, dense alignment, and semantic-geometric modeling. MCLN~\citep{qian2025multi} uses the 3D referring expression segmentation task to assist 3DVG in improving performance.
% Despite their advantages, existing single-stage methods often have limitations such as reliance on ground-truth annotations for object names, which restricts generalizability, and focusing on sparse alignment of main object words, neglecting dense alignment of all object-related textual components [11].

However, existing two-stage and single-stage methods generally have high computational costs, hindering real-time applications. Our work aims to address these efficiency challenges by proposing an efficient single-stage method with multi-level sparse convolutional architecture.

\subsection{Multi-Level Convolutional Architectures}
Recently, sparse convolutional architecture has achieved great success in the field of 3D object detection. Built on the voxel-based representation~\citep{wang2022cagroup3d,chen2023voxelnext,deng2021voxel} and sparse convolution operation~\citep{choy20194d,graham20183d,xu2023binarizing}, this kind of methods show great efficiency and accuracy when processing scene-level data. GSDN~\citep{gwak2020generative} first adopts multi-level sparse convolution with generative feature upsampling in 3D object detection. FCAF3D~\citep{rukhovich2022fcaf3d} simplifies the multi-level architecture with anchor-free design, achieving leading accuracy and speed. TR3D~\citep{rukhovich2023tr3d} further accelerates FCAF3D by removing unnecessary layers and introducing category-aware proposal assignment method. Moreover, DSPDet3D~\cite{xu2023dsp} introduces the multi-level architecture to 3D small object detection.
% and demonstrates great accuracy and efficiency, even being able to process building-level 3D scenes.

Our proposed method draws inspiration from these approaches, utilizing a sparse multi-level architecture with sparse convolutions and an anchor-free design. This allows for efficient processing of 3D data, enabling real-time performance in 3D visual grounding tasks.

% Anchor-free approaches have demonstrated that voxel-based methods can achieve competitive accuracy without relying on anchors, improving efficiency. FCAF3D [4] is one such method that processes voxelized point clouds through a fully convolutional architecture and employs multi-level feature fusion to enhance detection performance. Similarly, TR3D [25] builds upon FCAF3D and demonstrates that anchor-free, voxel-based methods can achieve competitive results in 3D object detection.

% Our proposed method draws inspiration from these approaches, utilizing a 3DCNN-based multi-level architecture with sparse convolutions and an anchor-free design. This allows for efficient processing of 3D data, enabling real-time performance in 3D visual grounding tasks.