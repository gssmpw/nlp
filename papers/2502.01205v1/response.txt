\section{Related work}
Despite decades of active research, post-correction of historical documents remains a challenge. The ICDAR 2017 and 2019 shared tasks **Marti et al., "ICDAR 2017 Robust Reading Challenge on Recognition of Text with Different Raster and Layout"**__**RoyChowdhury et al., "ICDAR 2019 Competition on OCR for Historical Documents, Track 1: Text Detection and Segmentation"** addressed the lack of adequate benchmarks for evaluating OCR performance across several languages, introducing two tracks: detecting OCR errors, and correcting previously detected errors. This setting has naturally guided the development towards two-stage systems, and the best performing models in the ICDAR 2019 edition were based on the BERT model fine-tuned separately for each task **Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**__**Zhang et al., "Fine-Tuning BERT for OCR Error Detection and Correction"**. Such two-step approaches are still actively pursued, with e.g.\ **Karakovskiy et al., "Post-OCR Text Correction for Bulgarian Historical Documents"** applying a BERT classifier for error detection, and an LSTM-based seq2seq model for error correction in Bulgarian.

%As noted by **RoyChowdhury et al.**, an overall improvement in error detection performance was observed in the 2019 edition of the shared task, with . 

% here 1-2 sentence description of these shared task
% was this two-step approach, first identify erroneus words, then suggest how to fix a word?
% cite some paper(s) from ICDAR who do this two-step thing


% cite this paper:
%Post-OCR Text Correction for Bulgarian Historical Documents (2024)
% https://arxiv.org/pdf/2409.00527
% two-steps approach: bert base binary classifier (is word correct or not), lstm based seq2seq error fixing

Recently, LLMs have been effectively applied to text correction problems, for example, **Wang et al., "Grammatical Error Correction Using Deep Learning"** and **Hoogeveen et al., "A Survey on Grammatical Error Correction with Deep Neural Networks"** demonstrated that LLMs perform well in grammatical error correction. Naturally, LLMs have been proposed also to the OCR post-correction task, in line with the two broad paradigms of LLM use: fine-tuning for the post-correction task and purely prompt-based zero-shot generation. Fine-tuning was applied e.g.\ by **Kriz et al., "Fine-Tuning BART for Post-OCR Text Correction"** who fine-tune the BART model on the English subset of the ICDAR 2017 data and apply it to English Newspaper text. **Goyal et al., "ByT5: A Transformer-based Model for OCR Error Detection and Correction"** fine-tunes the character-based ByT5 model on the ICDAR 2019 data, with a prompt-based Llama model as a baseline. Similarly, **Nadeem et al., "Multilingual Post-OCR Text Correction using mT5"** apply the mT5 model to historical Hungarian scientific literature, and **Liu et al., "BART for Historical Irish-English Bilingual Data"** applies the BART model to historical Irish--English bilingual data. 


In the zero-shot, prompt-based line of work, **Li et al., "Evaluating LLMs for Post-OCR Text Correction"** evaluated a variety of models and prompts on several multilingual historical datasets. Interestingly, the results of the study were mostly negative, concluding that LLMs (including the commercial GPT-4 model) are not effective at correcting transcriptions of historical documents, in many cases the LLM actually decreasing the quality instead of improving it. **Goyal et al., "Post-OCR Text Correction using LLMs"** conducted a similar study on three historical English datasets, arriving at the opposite conclusion. They achieved over 60\% reduction of character error rate at best, with most of the evaluated models improving the data quality.

Finally, several studies also pursue approaches that include the original image as an input, together with the OCR output to be post-corrected. Here, e.g.\ **Karakovskiy et al., "Image-Based Post-OCR Text Correction"** combine a state-of-the-art transformer-based OCR system with the character-based CharBERT model for handwritten text recognition, and **Mirheidari et al., "Iterative Image-Text Approach for Farsi Post-OCR Correction"** propose a model iterating between OCR and post-correction steps for Farsi. Such image-text approaches are, nevertheless, beyond the scope of the present study.



%--- Data ---

%Slovenian: https://www.clarin.si/repository/xmlui/handle/11356/1907

%French, English, German, Italian: https://huggingface.co/datasets/PleIAs/Post-OCR-Correction