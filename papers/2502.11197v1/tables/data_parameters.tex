\begin{tabular}{|l|c|}
\hline
\textbf{Parameter} & \textbf{Value(s)} \\
\hline
\textbf{Number of agents} & 4 or 5 \\
\hline
Rounds & 30 \\
\hline
Round by Round & True \\
\hline
Queries & 30 queries selected from TREC \\
\hline
\textbf{Rankers} & intfloat/e5-large-unsupervised, facebook/contriever, Okapi BM25 \\
\hline
\textbf{LLM models of agents} & 
\begin{tabular}[t]{@{}l@{}}
\small{meta-llama/Meta-Llama-3.1-8B-Instruct, google/gemma-2-9b-it,} \\
\small{Qwen/Qwen2.5-7B-Instruct, mlx-community/Ministral-8B-Instruct-2410-bf16}
\end{tabular} \\
\hline
LLM parameters & $top_p = 0.9 ; Temperature = 0.5$ \\
\hline
Characters & BSc student, professional writer, professional editor, \\
& English student, data science professor \\
\hline
Max Tokens & 256 \\
\hline
\textbf{Feedback Mechanism} & Pairwise prompt, listwise prompt\footnote{XX ref to niv} \\
\hline
\textbf{System Prompt} & The system prompt in Bardas et al. \cite{niv} or The the system prompt with addition instruction to not copy. Figures \ref{prompt_system} and \ref{prompt_system_no_copy}\\
\hline
\end{tabular}