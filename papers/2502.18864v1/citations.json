[
  {
    "index": 0,
    "papers": [
      {
        "key": "bommasani2021opportunities",
        "author": "Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others",
        "title": "On the opportunities and risks of foundation models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "erhan2010does",
        "author": "Erhan, Dumitru and Courville, Aaron and Bengio, Yoshua and Vincent, Pascal",
        "title": "Why does unsupervised pre-training help deep learning?"
      },
      {
        "key": "radford2018improving",
        "author": "Radford, Alec",
        "title": "Improving language understanding by generative pre-training"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "team2023gemini",
        "author": "Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others",
        "title": "Gemini: a family of highly capable multimodal models"
      },
      {
        "key": "achiam2023gpt",
        "author": "Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others",
        "title": "{GPT}-4 technical report"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "chowdhery2022palm",
        "author": "Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others",
        "title": "{PaLM}: Scaling language modeling with pathways"
      },
      {
        "key": "google2023palm2",
        "author": "Google",
        "title": "PaLM 2 Technical Report"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "wei2022chain",
        "author": "Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others",
        "title": "Chain-of-thought prompting elicits reasoning in large language models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "kahneman2011thinking",
        "author": "Kahneman, Daniel",
        "title": "Thinking, fast and slow"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "silver2016mastering",
        "author": "Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others",
        "title": "Mastering the game of Go with deep neural networks and tree search"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "brown2019superhuman",
        "author": "Brown, Noam and Sandholm, Tuomas",
        "title": "Superhuman AI for multiplayer poker"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "wei2022chain",
        "author": "Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others",
        "title": "Chain-of-thought prompting elicits reasoning in large language models"
      },
      {
        "key": "yao2024tree",
        "author": "Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik",
        "title": "Tree of thoughts: Deliberate problem solving with large language models"
      },
      {
        "key": "zelikman2022star",
        "author": "Zelikman, Eric and Wu, Yuhuai and Mu, Jesse and Goodman, Noah",
        "title": "Star: Bootstrapping reasoning with reasoning"
      },
      {
        "key": "chen2024more",
        "author": "Chen, Lingjiao and Davis, Jared Quincy and Hanin, Boris and Bailis, Peter and Stoica, Ion and Zaharia, Matei and Zou, James",
        "title": "Are More LLM Calls All You Need? Towards the Scaling Properties of Compound AI Systems"
      },
      {
        "key": "snell2024scaling",
        "author": "Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral",
        "title": "Scaling llm test-time compute optimally can be more effective than scaling model parameters"
      },
      {
        "key": "4928",
        "author": "Tamara Williams and Marilyn Szekendi and Stephen Pavkovic and Wanda Clevenger and Julie Cerese",
        "title": "The reliability of AHRQ Common Format Harm Scales in rating patient safety events."
      },
      {
        "key": "muennighoff2025s1",
        "author": "Muennighoff, Niklas and Yang, Zitong and Shi, Weijia and Li, Xiang Lisa and Fei-Fei, Li and Hajishirzi, Hannaneh and Zettlemoyer, Luke and Liang, Percy and Cand{\\'e}s, Emmanuel and Hashimoto, Tatsunori",
        "title": "s1: Simple test-time scaling"
      },
      {
        "key": "tu2024towards",
        "author": "Tu, Tao and Palepu, Anil and Schaekermann, Mike and Saab, Khaled and Freyberg, Jan and Tanno, Ryutaro and Wang, Amy and Li, Brenna and Amin, Mohamed and Tomasev, Nenad and others",
        "title": "Towards conversational diagnostic {AI}"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "guo2025deepseek",
        "author": "Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others",
        "title": "Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "jumper2021highly",
        "author": "Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\\v{Z}}{\\'i}dek, Augustin and Potapenko, Anna and others",
        "title": "Highly accurate protein structure prediction with AlphaFold"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "wong2024discovery",
        "author": "Wong, Felix and Zheng, Erica J and Valeri, Jacqueline A and Donghia, Nina M and Anahtar, Melis N and Omori, Satotaka and Li, Alicia and Cubillos-Ruiz, Andres and Krishnan, Aarti and Jin, Wengong and others",
        "title": "Discovery of a structural class of antibiotics with explainable deep learning"
      },
      {
        "key": "zambaldi2024novo",
        "author": "Zambaldi, Vinicius and La, David and Chu, Alexander E and Patani, Harshnira and Danson, Amy E and Kwan, Tristan OC and Frerix, Thomas and Schneider, Rosalia G and Saxton, David and Thillaisundaram, Ashok and others",
        "title": "De novo design of high-affinity protein binders with AlphaProteo"
      },
      {
        "key": "merchant2023scaling",
        "author": "Merchant, Amil and Batzner, Simon and Schoenholz, Samuel S and Aykol, Muratahan and Cheon, Gowoon and Cubuk, Ekin Dogus",
        "title": "Scaling deep learning for materials discovery"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "lu2024ai",
        "author": "Lu, Chris and Lu, Cong and Lange, Robert Tjarko and Foerster, Jakob and Clune, Jeff and Ha, David",
        "title": "The {AI} scientist: Towards fully automated open-ended scientific discovery"
      },
      {
        "key": "schmidgall2025agent",
        "author": "Schmidgall, Samuel and Su, Yusheng and Wang, Ze and Sun, Ximeng and Wu, Jialian and Yu, Xiaodong and Liu, Jiang and Liu, Zicheng and Barsoum, Emad",
        "title": "Agent laboratory: Using llm agents as research assistants"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "liang2024can",
        "author": "Liang, Weixin and Zhang, Yuhui and Cao, Hancheng and Wang, Binglu and Ding, Daisy Yi and Yang, Xinyu and Vodrahalli, Kailas and He, Siyu and Smith, Daniel Scott and Yin, Yian and others",
        "title": "Can large language models provide useful feedback on research papers? A large-scale empirical analysis"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "openai2023gpt4",
        "author": "OpenAI",
        "title": "GPT-4 Technical Report"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "skarlinski2024language",
        "author": "Skarlinski, Michael D and Cox, Sam and Laurent, Jon M and Braza, James D and Hinks, Michaela and Hammerling, Michael J and Ponnapati, Manvitha and Rodriques, Samuel G and White, Andrew D",
        "title": "Language agents achieve superhuman synthesis of scientific knowledge"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "zhou2022least",
        "author": "Zhou, Denny and Sch{\\\"a}rli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Bousquet, Olivier and Le, Quoc and Chi, Ed",
        "title": "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "ifargan2025autonomous",
        "author": "Ifargan, Tal and Hafner, Lukas and Kern, Maor and Alcalay, Ori and Kishony, Roy",
        "title": "Autonomous LLM-Driven Research\u2014from Data to Human-Verifiable Research Papers"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "swanson2024virtual",
        "author": "Swanson, Kyle and Wu, Wesley and Bulaong, Nash L and Pak, John E and Zou, James",
        "title": "The virtual lab: {AI} agents design new {SARS}-{CoV}-2 nanobodies with experimental validation"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "boiko2023autonomous",
        "author": "Boiko, Daniil A and MacKnight, Robert and Kline, Ben and Gomes, Gabe",
        "title": "Autonomous chemical research with large language models"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "lu2024ai",
        "author": "Lu, Chris and Lu, Cong and Lange, Robert Tjarko and Foerster, Jakob and Clune, Jeff and Ha, David",
        "title": "The {AI} scientist: Towards fully automated open-ended scientific discovery"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "team2023gemini",
        "author": "Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others",
        "title": "Gemini: a family of highly capable multimodal models"
      },
      {
        "key": "achiam2023gpt",
        "author": "Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others",
        "title": "{GPT}-4 technical report"
      },
      {
        "key": "singhal2022large",
        "author": "Singhal, Karan and Azizi, Shekoofeh and Tu, Tao and Mahdavi, S Sara and Wei, Jason and Chung, Hyung Won and Scales, Nathan and Tanwani, Ajay and Cole-Lewis, Heather and Pfohl, Stephen and others",
        "title": "Large Language Models Encode Clinical Knowledge"
      },
      {
        "key": "saab2024capabilities",
        "author": "Saab, Khaled and Tu, Tao and Weng, Wei-Hung and Tanno, Ryutaro and Stutz, David and Wulczyn, Ellery and Zhang, Fan and Strother, Tim and Park, Chunjong and Vedadi, Elahe and others",
        "title": "Capabilities of gemini models in medicine"
      },
      {
        "key": "taylor2022galactica",
        "author": "Taylor, Ross and Kardas, Marcin and Cucurull, Guillem and Scialom, Thomas and Hartshorn, Anthony and Saravia, Elvis and Poulton, Andrew and Kerkez, Viktor and Stojnic, Robert",
        "title": "{Galactica}: A Large Language Model for Science"
      },
      {
        "key": "chaves2024tx",
        "author": "Chaves, Juan Manuel Zambrano and Wang, Eric and Tu, Tao and Vaishnav, Eeshit Dhaval and Lee, Byron and Mahdavi, S Sara and Semturs, Christopher and Fleet, David and Natarajan, Vivek and Azizi, Shekoofeh",
        "title": "Tx-LLM: A Large Language Model for Therapeutics"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "tu2023genetic",
        "author": "Tu, Tao and Fang, Zhouqing and Cheng, Zhuanfen and Spasic, Svetolik and Palepu, Anil and Stankovic, Konstantina M and Natarajan, Vivek and Peltz, Gary",
        "title": "Genetic Discovery Enabled by A Large Language Model"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "nguyen2024sequence",
        "author": "Nguyen, Eric and Poli, Michael and Durrant, Matthew G and Kang, Brian and Katrekar, Dhruva and Li, David B and Bartie, Liam J and Thomas, Armin W and King, Samuel H and Brixi, Garyk and others",
        "title": "Sequence modeling and design from molecular to genome scale with {Evo}"
      },
      {
        "key": "lin2023evolutionary",
        "author": "Lin, Zeming and Akin, Halil and Rao, Roshan and Hie, Brian and Zhu, Zhongkai and Lu, Wenting and Smetanin, Nikita and Verkuil, Robert and Kabeli, Ori and Shmueli, Yaniv and others",
        "title": "Evolutionary-scale prediction of atomic-level protein structure with a language model"
      },
      {
        "key": "ruffolo2024design",
        "author": "Ruffolo, Jeffrey A and Nayfach, Stephen and Gallagher, Joseph and Bhatnagar, Aadyot and Beazer, Joel and Hussain, Riffat and Russ, Jordan and Yip, Jennifer and Hill, Emily and Pacesa, Martin and others",
        "title": "Design of highly functional genome editors by modeling the universe of CRISPR-Cas sequences"
      },
      {
        "key": "shaw2024protex",
        "author": "Shaw, Peter and Gurram, Bhaskar and Belanger, David and Gane, Andreea and Bileschi, Maxwell L and Colwell, Lucy J and Toutanova, Kristina and Parikh, Ankur P",
        "title": "ProtEx: A Retrieval-Augmented Approach for Protein Function Prediction"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "pushpakom2019drug",
        "author": "Pushpakom, Sudeep and Iorio, Francesco and Eyers, Patrick A and Escott, K Jane and Hopper, Shirley and Wells, Andrew and Doig, Andrew and Guilliams, Tim and Latimer, Joanna and McNamee, Christine and others",
        "title": "Drug repurposing: progress, challenges and recommendations"
      },
      {
        "key": "krishnamurthy2022drug",
        "author": "Krishnamurthy, Nithya and Grimshaw, Alyssa A and Axson, Sydney A and Choe, Sung Hee and Miller, Jennifer E",
        "title": "Drug repurposing: a systematic review on root causes, barriers and facilitators"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "zitnik2018modeling",
        "author": "Zitnik, Marinka and Agrawal, Monica and Leskovec, Jure",
        "title": "Modeling polypharmacy side effects with graph convolutional networks"
      },
      {
        "key": "morselli2021network",
        "author": "Morselli Gysi, Deisy and Do Valle, {\\'I}talo and Zitnik, Marinka and Ameli, Asher and Gan, Xiao and Varol, Onur and Ghiassian, Susan Dina and Patten, JJ and Davey, Robert A and Loscalzo, Joseph and others",
        "title": "Network medicine framework for identifying drug-repurposing opportunities for COVID-19"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "huang2024foundation",
        "author": "Huang, Kexin and Chandak, Payal and Wang, Qianwen and Havaldar, Shreyas and Vaid, Akhil and Leskovec, Jure and Nadkarni, Girish and Glicksberg, Benjamin S and Gehlenborg, Nils and Zitnik, Marinka",
        "title": "A foundation model for clinician-centered drug repurposing"
      }
    ]
  }
]