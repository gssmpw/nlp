\section{Omitted Proofs}
\label{sec:proofs}

This section contains the proofs omitted from the main body. 

\subsection{Existence of $\Phi$-EVI solutions}

We begin with~\Cref{theorem:existence}.

\mainexistence*

\begin{proof}
    We define a function $\hatF_\delta  : \cX \to \R^d$ as
    \[
        \hatF_\delta: \vx \mapsto \frac{1}{|\cB_{\delta}(\vx) \cap \cX|} \int_{\cB_{\delta}(\vx) \cap \cX} F(\hatvx) d\nu(\hatvx);
    \]
    this is a rescaled Lebesgue integral, which represents a multivariate local average. Above,
    \begin{itemize}[noitemsep,topsep=0pt]
        \item $\delta > 0$ is a sufficiently small parameter, to be defined shortly;
        \item $\cB_{\delta}(\vx) \subseteq \R^d$ is the (closed) Euclidean ball of radius $\delta$ centered at $\vx$; and
        \item $|\cdot|$ denotes the set's Borel measure.
    \end{itemize}
    Given that $F$ is assumed to be bounded, we can define $B \in \R$ such that $\max_{\vx \in \cX} \| F(\vx) \| \leq B$. For the proof below, it will suffice to set $\delta := \nicefrac{\eps}{(L+1) B}$. 

    We first observe that $\hatF_\delta$ is continuous.

    \begin{claim}
        \label{lemma:cont}
        $\hatF_\delta$ is continuous.
    \end{claim}

    \begin{proof}
        We will show that for any $\vx \in \cX$ and $\epsilon' > 0$, we can choose $\delta' = \delta'(\epsilon')$ such that for any $\vx' \in \cX$ with $\|\vx - \vx'\| < \delta'$,
        \begin{equation*}
            \| \hatF_\delta(\vx) - \hatF_\delta(\vx') \| \leq \epsilon'.
        \end{equation*}
    By the triangle inequality, the difference $\| \hatF_\delta(\vx) - \hatF_\delta(\vx') \|$ can be decomposed as the sum of 
    \begin{equation*}
        \tcircle{A} \defeq \left| \frac{1}{|\cB_{\delta}(\vx) \cap \cX|} - \frac{1}{|\cB_{\delta}(\vx') \cap \cX|} \right|  \int_{\cB_{\delta}(\vx) \cap \cX} \| F(\hatvx) \| d\nu(\hatvx)
    \end{equation*}
    and
    \begin{equation*}
        \tcircle{B} \defeq \frac{1}{|\cB_{\delta}(\vx') \cap \cX|} \left\| \int_{\cB_{\delta}(\vx) \cap \cX} F(\hatvx) d\nu(\hatvx) - \int_{\cB_{\delta}(\vx') \cap \cX} F(\hatvx) d\nu(\hatvx) \right\|.
    \end{equation*}
    Now, $\tcircle{A}$ can be bounded as
    \begin{equation*}
        \tcircle{A} \leq B \left| 1 - \frac{ | \cB_\delta(\vx) \cap \cX| }{| \cB_\delta(\vx') \cap \cX|} \right| \leq \frac{1}{2} \epsilon',
    \end{equation*}
    where we selected $\delta'$ small enough so that 
    \begin{equation*}
         \left(1 - \frac{\epsilon'}{B} \right) | \cB_\delta(\vx') \cap \cX| \leq | \cB_\delta(\vx) \cap \cX| \leq  \left(1 + \frac{\epsilon'}{B} \right) | \cB_\delta(\vx') \cap \cX|.
    \end{equation*}
    Moreover, by selecting $\delta'$ small enough so that
    \begin{equation}
        \label{eq:smalldelta}
        | (\cB_\delta(\vx) \cap \cX ) \setminus (\cB_\delta(\vx') \cap \cX) | + | (\cB_\delta(\vx') \cap \cX) \setminus (\cB_\delta(\vx) \cap \cX) | \leq \frac{1}{2B} \epsilon' | \cB_\delta(\vx') \cap \cX |,
    \end{equation}
    we have
    \begin{align*}
        \Bigg\| \int_{\cB_{\delta}(\vx) \cap \cX} F(\hatvx) d\nu(\hatvx) &- \int_{\cB_{\delta}(\vx') \cap \cX} F(\hatvx) d\nu(\hatvx) \Bigg\| \\
        &\leq  \int_{ (\cB_{\delta}(\vx) \cap \cX) \setminus (\cB_{\delta}(\vx') \cap \cX) } \| F(\hatvx) \| d\nu(\hatvx)  + \int_{(\cB_{\delta}(\vx') \cap \cX) \setminus (\cB_{\delta}(\vx) \cap \cX)} \| F(\hatvx) \| d\nu(\hatvx) \\
        &\leq B | (\cB_\delta(\vx) \cap \cX ) \setminus (\cB_\delta(\vx') \cap \cX) | + B | (\cB_\delta(\vx') \cap \cX) \setminus (\cB_\delta(\vx) \cap \cX) | \\
        &\leq \frac{1}{2} \epsilon' | \cB_\delta(\vx') \cap \cX|,
    \end{align*}
    where the last inequality uses~\eqref{eq:smalldelta}. As a result, we have shown that $\tcircle{A} + \tcircle{B} \leq \epsilon'$, thereby implying that $\| \hatF_\delta(\vx) - \hatF_\delta(\vx') \| \leq \epsilon'$. This completes the proof.
    \end{proof}
    \iffalse
    First, we observe that $\hatF_\delta$ is indeed continuous: For any $\vx \in \cX$ and any $\eps' >0$, we can choose $\delta'>0$ small enough such that for any $\vx' \in \cX$ with $||\vx - \vx'|| < \delta'$ we have
    \begin{align}
        &\Big|\Big| \hatF_\delta(\vx) - \hatF_\delta(\vx') \Big|\Big|
        \\
        &= \Big|\Big| \frac{1}{|\cB_{\delta}(\vx) \cap \cX|} \int_{\cB_{\delta}(\vx) \cap \cX} F(\hatvx) d\nu(\hatvx) - \frac{1}{|\cB_{\delta}(\vx') \cap \cX|} \int_{\cB_{\delta}(\vx) \cap \cX} F(\hatvx) d\nu(\hatvx) 
        \\
        &\, \quad \quad + \frac{1}{|\cB_{\delta}(\vx') \cap \cX|} \int_{\cB_{\delta}(\vx) \cap \cX} F(\hatvx) d\nu(\hatvx) - \frac{1}{|\cB_{\delta}(\vx') \cap \cX|} \int_{\cB_{\delta}(\vx') \cap \cX} F(\hatvx) d\nu(\hatvx) \Big|\Big|
        \\
        &\leq \Bigg| \frac{1}{|\cB_{\delta}(\vx) \cap \cX|} - \frac{1}{|\cB_{\delta}(\vx') \cap \cX|} \Bigg| \cdot \int_{\cB_{\delta}(\vx) \cap \cX} \Big|\Big| F(\hatvx) \Big|\Big| d\nu(\hatvx)
        \\
        &\, \quad \quad + \frac{1}{|\cB_{\delta}(\vx') \cap \cX|} \Big|\Big| \int_{\cB_{\delta}(\vx) \cap \cX} F(\hatvx) d\nu(\hatvx) - \int_{\cB_{\delta}(\vx') \cap \cX} F(\hatvx) d\nu(\hatvx) \Big|\Big|
        \\
        &= \frac{ \big| |\cB_{\delta}(\vx') \cap \cX| - |\cB_{\delta}(\vx) \cap \cX| \big|}{|\cB_{\delta}(\vx) \cap \cX| \cdot |\cB_{\delta}(\vx') \cap \cX|} \cdot \int_{\cB_{\delta}(\vx) \cap \cX} || F(\hatvx) || d\nu(\hatvx) 
        \\
        &\, \quad \quad + \frac{1}{|\cB_{\delta}(\vx') \cap \cX|} \Big|\Big| \int_{(\cB_{\delta}(\vx) \setminus \cB_{\delta}(\vx')) \cap \cX} F(\hatvx) d\nu(\hatvx) - \int_{(\cB_{\delta}(\vx') \setminus \cB_{\delta}(\vx)) \cap \cX} F(\hatvx) d\nu(\hatvx) \Big|\Big|
        \\
        &\leq \frac{ \big| | \qty( \cB_{\delta}(\vx') \setminus \cB_{\delta}(\vx) ) \cap \cX| - | \qty( \cB_{\delta}(\vx') \setminus \cB_{\delta}(\vx) ) \cap \cX| \big| }{|\cB_{\delta}(\vx) \cap \cX| \cdot |\cB_{\delta}(\vx') \cap \cX|} \cdot \int_{\cB_{\delta}(\vx) \cap \cX} M d\nu(\hatvx)
        \\
        &\, \quad \quad + \frac{1}{|\cB_{\delta}(\vx') \cap \cX|} \qty( \Big|\Big| \int_{(\cB_{\delta}(\vx) \setminus \cB_{\delta}(\vx')) \cap \cX} F(\hatvx) d\nu(\hatvx) \Big|\Big| + \Big|\Big| \int_{(\cB_{\delta}(\vx') \setminus \cB_{\delta}(\vx)) \cap \cX} F(\hatvx) d\nu(\hatvx) \Big|\Big| )
        \\
        &\overset{(*)}{\leq} \frac{| \qty( \cB_{\delta}(\vx') \setminus \cB_{\delta}(\vx) ) \cap \cX| + | \qty( \cB_{\delta}(\vx') \setminus \cB_{\delta}(\vx) ) \cap \cX|}{ \frac{3}{2}|\cB_{\delta}(\vx) \cap \cX|} \cdot  M \cdot  |\cB_{\delta}(\vx) \cap \cX|
        \\
        &\, \quad \quad + \frac{1}{\frac{1}{2}|\cB_{\delta}(\vx) \cap \cX|} \cdot M \cdot \Big( |(\cB_{\delta}(\vx) \setminus \cB_{\delta}(\vx')) \cap \cX| + |(\cB_{\delta}(\vx') \setminus \cB_{\delta}(\vx)) \cap \cX| \Big)
        \\
        &= \frac{M}{|\cB_{\delta}(\vx) \cap \cX|} \cdot \Big( |(\cB_{\delta}(\vx) \setminus \cB_{\delta}(\vx')) \cap \cX| + |(\cB_{\delta}(\vx') \setminus \cB_{\delta}(\vx)) \cap \cX| \Big)
        \\
        &\overset{(**)}{\leq} \frac{M}{|\cB_{\delta}(\vx) \cap \cX|} \cdot \frac{\eps' \cdot |\cB_{\delta}(\vx) \cap \cX|}{M} = \eps'.
    \end{align}
    In $(*)$ and $(**)$, we use that $\delta'$ was chosen sufficiently small such that for any $\delta'$-close $\vx'$ to $\vx$ we have that $|\cB_{\delta}(\vx') \cap \cX| \geq \frac{1}{2}|\cB_{\delta}(\vx) \cap \cX|$ and (respectively) that
    \[
        |(\cB_{\delta}(\vx) \setminus \cB_{\delta}(\vx')) \cap \cX| + |(\cB_{\delta}(\vx') \setminus \cB_{\delta}(\vx)) \cap \cX| \leq \frac{\eps' \cdot |\cB_{\delta}(\vx) \cap \cX|}{M}.
    \]
    \fi
    Having established that $\hatF_\delta$ is continuous, we can now apply Brouwer's fixed point theorem on the map $\vx \mapsto \proj_\cX ( \vx - \hatF_{\delta}(\vx))$, where we recall that $\proj_\cX$ denotes the Euclidean projection onto $\cX$. This implies that there is a point $\vx \in \cX$ such that $\vx = \proj_\cX ( \vx - \hatF_{\delta}(\vx))$. Moreover, such a point satisfies the VI constraint with respect to $\hatF_\delta$:
    \begin{equation*}
        \langle \hatF_\delta(\vx), \vx' - \vx \rangle \geq 0 \quad \vx' \in \cX;
    \end{equation*}
    for example, see~\citet[Section 3]{Kinderlehrer00:Introduction} for the derivation. Finally, we define $\mu \in \Delta(\cX)$ to be the uniform distribution over $\cB_{\delta}(\vx) \cap \cX$. Then, for any $\phi \in \Phi$,
    %Next, we need a solution $\vx^* \in \cX$ to the variational inequality $\ip{\hatF_{\delta}(\vx), \vx' - \vx} \geq 0 \quad \forall \vx' \in \cX$. And indeed, by using the Brouwer fixed point theorem on the map $\vx \mapsto \proj_\cX ( \vx - \hatF_{\delta}(\vx) )$, we can guarantee that such a solution must exist since $\cX$ is convex and compact and $\hatF_{\delta}: \cX \to \R^n$ is continuous (see, \eg, \citealp{KinderlehrerS00} Section 3 for such a derivation). Last but not least, define $\mu \in \Delta(\cX)$ as the uniform distribution over $\cB_{\delta}(\vx^*) \cap \cX$. Then, we have for any $\phi \in \Phi$ that
    \begin{align}
        \langle \hatF_\delta(\vx), \phi(\vx) - \vx \rangle &= \E_{\hatvx \sim \mu} \langle F(\hatvx), \phi(\vx) - \vx \rangle \notag \\
        &= \E_{\hatvx \sim \mu} \ip{F(\hatvx), \hatvx - \vx} + \E_{\hatvx \sim \mu} \ip{F(\hatvx),  \phi(\vx) - \phi(\hatvx)}  + \E_{\hatvx \sim \mu} \ip{F(\hatvx), \phi(\hatvx) - \hatvx}. \label{align:interm}
    \end{align}
    The first term in~\eqref{align:interm} can be bounded as
    \begin{equation}
        \label{eq:firstineq}
        \E_{\hatvx \sim \mu} \ip{F(\hatvx), \hatvx - \vx} \leq \sqrt{\E_{\hatvx \sim \mu} \| F(\hatvx) \|^2} \sqrt{\E_{\hatvx \sim \mu} \| \hatvx - \vx \|^2} \leq \delta B,
    \end{equation}
    where we used the Cauchy-Schwarz inequality, the fact that $\| F(\hatvx) \| \leq B$ for all $\hatvx \in \cX$, and $\| \hatvx - \vx \| \leq \delta$ for all $\hatvx$ in the support of $\mu$. Similarly, the second term in~\eqref{align:interm} can be bounded as
    \begin{align}
        \E_{\hatvx \sim \mu} \ip{F(\hatvx), \phi(\vx) - \phi(\hatvx) } &\leq \sqrt{\E_{\hatvx \sim \mu} \| F(\hatvx) \|^2} \sqrt{\E_{\hatvx \sim \mu} \| \phi(\hatvx) - \phi(\vx) \|^2} \notag \\
        &\leq L \sqrt{\E_{\hatvx \sim \mu} \| F(\hatvx) \|^2} \sqrt{\E_{\hatvx \sim \mu} \| \hatvx - \vx \|^2} \leq \delta B L, \label{eq:secondineq}
    \end{align}
    where we additionally used the assumption that $\phi$ is $L$-Lipschitz continuous. Combining~\eqref{eq:firstineq} and~\eqref{eq:secondineq} with~\eqref{align:interm}, we have
    \begin{equation}
        \E_{\hatvx \sim \mu} \ip{F(\hatvx), \phi(\hatvx) - \hatvx} \geq - \delta (L+1) B + \langle \hatF_\delta(\vx), \phi(\vx) - \vx \rangle \geq - \delta (L+1) B,
    \end{equation}
    and this holds for any $\phi \in \Phi$. Setting $\delta \defeq \nicefrac{\epsilon}{(L+1)B}$ completes the proof.
    \iffalse
    \begin{align}
        \E_{\vx\sim\mu} &\ip{F(\vx), \phi(\vx) - \vx} = \E_{\vx\sim\mu} \ip{F(\vx), \phi(\vx) - \vx - \phi(\vx^*) + \phi(\vx^*) + \vx^* - \vx^*} 
        \\
        &= \E_{\vx\sim\mu} \ip{F(\vx), \phi(\vx) - \phi(\vx^*)} + \E_{\vx\sim\mu} \ip{F(\vx), - \vx + \vx^*} + \E_{\vx\sim\mu} \ip{F(\vx), \phi(\vx^*) - \vx^*} 
        \\
        &\overset{(\dagger)}{\geq} - \sqrt{\E_{\vx\sim\mu} ||F(\vx)||^2} \sqrt{\E_{\vx\sim\mu} ||\phi(\vx) - \phi(\vx^*)||^2} - \sqrt{\E_{\vx\sim\mu} ||F(\vx)||^2} \sqrt{\E_{\vx\sim\mu} ||\vx^* - \vx||^2} + \E_{\vx\sim\mu} \ip{F(\vx), \phi(\vx^*) - \vx^*} 
        \\
        &\overset{(\star)}{\geq} - M L \delta - M \delta + \int_X \sum_{i=1}^n F_i(\vx) \cdot \qty( \phi_i(\vx^*) - \vx_i^* ) d\mu(\vx) = - M (L+1) \delta + \sum_{i=1}^n \qty( \phi_i(\vx^*) - \vx_i^* ) \int_X F_i(\vx) d\mu(\vx)
        \\
        &= - M (L+1) \delta + \ip{\int_X F_i(\vx) d\mu(\vx) \, \, , \, \, \phi(\vx^*) - \vx^*} 
        \\
        &= - M (L+1) \delta + \ip{\frac{1}{|\cB_{\delta}(\vx^*) \cap \cX|} \int_{\cB_{\delta}(\vx^*) \cap \cX} F(\vx) d\nu(\vx) \, \, , \, \, \phi(\vx^*) - \vx^*} = - M (L+1) \delta + \ip{\hatF_\delta(\vx^*), \phi(\vx^*) - \vx^*}
        \\
        &\geq - M (L+1) \delta + 0 = -\eps.
    \end{align}
    Here, we used the Cauchy-Schwarz inequality for integrals in $(\dagger)$, and the uniform Lipschitz continuity of $\Phi$ in $(\star)$ together with that $||F(\vx)|| \leq M$ because $F(\vx) \in \cX$. Therefore, $\mu$ forms an $\epsilon$-approximate solution to the $\Phi$-EVI problem.
    \fi
\end{proof}

We next proceed with~\Cref{prop:VI-vs-EVIs} and \Cref{prop:notexact}, which are restated below.

\VIsvsEVIs*

\notexact*

We provide an example that will establish both of those claims.

\begin{example}[Discontinuous $F$; \emph{cf.} \Cref{prop:VI-vs-EVIs} and \Cref{prop:notexact}]
    \label{ex:sign-evi}
    Let $F(x)$ be the sign function, 
    $$F(x) = \sgn(x) := 
    \begin{cases} 
        -1 &\qif x < 0, \\ 
        1 &\qq{otherwise,} 
    \end{cases}$$ 
    and $\cX=[-1,1]$. We first claim that there is no $\epsilon$-approximate VI solution for $\epsilon <1$. Indeed, 
    \begin{itemize}%[noitemsep,topsep=0pt]
        \item for any $x<0$, picking $x'=1$ ensures $\ip{F(x), x' - x}=x-1<-1$;
        \item for any  $x \geq 0$, picking $x'=-1$ ensures $\ip{F(x), x' - x}=-1-x \leq -1$.
    \end{itemize}
    There is also no \emph{exact} EVI solution to this problem. Indeed, consider any $\mu \in \Delta(\cX)$. 
    \begin{itemize}%[noitemsep,topsep=0pt]
        \item If $\pr_{x \sim \mu}[x = 0]= 1$, then taking $x'=-1$ ensures $\E_{x\sim\mu} \ip{F(x), x' - x} = \langle F(0), x' \rangle = -1$.
        \item Otherwise, taking $x'=0$, we have
    \begin{align*}
         \E_{x\sim\mu} \ip{F(x), x' - x}  =  \E_{x\sim\mu} [-|x|] < 0.
    \end{align*}
    \end{itemize}
    On the other hand, for any $\epsilon>0$, there exists an $\epsilon$-approximate EVI solution (as promised by~\Cref{theorem:existence}). In particular, suppose that $\mu$ uniformly picks between $-\eps$ and $\eps$. Then, for any $x' \in \cX$,
    \begin{align*}
         \E_{x\sim\mu} \ip{F(x), x' - x}  = - \frac{1}{2} \left(x' + \epsilon \right) + \frac{1}{2} \left(x' -\epsilon \right)= -\epsilon.
    \end{align*}
\end{example}

It is worth pointing out that the above example can be slightly modified so that exact EVI solutions do exist, as we explain below.

\begin{example}[Modification of~\Cref{ex:sign-evi} with exact VI]
    We define $F(x)$ identically to \Cref{ex:sign-evi}, except $F\left(\nicefrac{1}{2}\right)=-1$. We claim that there is no VI solution for $\epsilon < \nicefrac{1}{2}$: any $x \neq \nicefrac{1}{2}$ can be treated as in~\Cref{ex:sign-evi}, and $x = \nicefrac{1}{2}$ is not a solution since $y= 1$ ensures $\ip{F(x), x' - x}= - \nicefrac{1}{2}$.

    However, there is an exact EVI solution: fix any $\xstar \in [0,\nicefrac{1}{2} )$ and consider $\mu$ that uniformly mixes between $x=\xstar$ and $x = \nicefrac{1}{2}$. Then, for any $x' \in \cX$,
    \begin{align*}
        \E_{x\sim\mu} \ip{F(x), x' - x}  =  \frac{1}{2} \left(x' -\xstar \right) - \frac{1}{2} \left(x' -\frac{1}{2} \right)= \frac{1}{2} \left(\frac{1}{2} -\xstar \right) > 0.
    \end{align*}
\end{example}

Our next result reveals that the precondition of~\Cref{theorem:existence} with respect to $\Phi$ cannot be relaxed to continuity.

\countercont*

\begin{proof}
    As before, let $F(x)$ be the sign function, $$F(x) = \sgn(x) := \begin{cases} -1 &\qif x < 0, \\ 1 &\qq{otherwise,} \end{cases}$$ and $\mu \in \Delta([-1, 1])$ be any distribution. For $\delta > 0$, let $\phi_\delta : [-1, 1] \to [-1, 1]$ be given by 
    \begin{align*}
        \phi_\delta(x) = \begin{cases}
            1 &\qif x < -2\delta, \\
            - (x+\delta)/\delta &\qif -2\delta \le x \le 0, \\
            -1 &\qif x > 0.
        \end{cases}
    \end{align*}
    Further, let $\phi_0(x) := -\sgn(x)$. Every $\phi_\delta$ (with $\delta > 0$) is continuous, by construction. Now, note that $\phi_\delta \to \phi_0$ pointwise when $\delta \downarrow 0$, and every $\phi_\delta$ is bounded. As a result, by the dominated convergence theorem, we have
    \begin{align*}
        \lim_{\delta \to 0} \E_{\vx\sim\mu}[F(x) (\phi_\delta(x) - x)] &= \E_{\vx\sim\mu}[F(x) (\phi_0(x) - x)]
        \\&= \E_{\vx\sim\mu}[-1 - F(x) \cdot x] \le -1,
    \end{align*}
    where the last line uses the fact that $F(x) \phi_0(x) = -\sgn(x)^2 = -1$ and $F(x) \cdot x = \sgn(x)\cdot x = |x|$ for all $x$. Thus, for any $\eps < 1$, there must be some $\delta > 0$ for which $\E[F(x) (\phi_\delta(x) - x)] < -\eps$, so $\mu$ cannot be an $\eps$-approximate EVI solution.
\end{proof}

Continuing on~\Cref{sec:existence}, we next provide the proof of~\Cref{theorem:finitedim}.

\finitedim*

\begin{proof}
We assume, without loss of generality, that (as functions) the coordinates $m_i : \cX \to \R$ for $1 \le i \le k$ are linearly independent. We further assume that $m$ is bounded, again without loss of generality. (Indeed, if for example $m_i$ is unbounded, then column $i$ of $\mK$ must contain all zeros, or else $\phi_\mK(\vx) := \mK m(\vx)$ would be unbounded; we can thus freely remove such coordinates $m_i$.)

Now, let $\cK := \co\{ \mK : \phi_\mK \in \Phi\}$ be the set of matrices corresponding to maps in $\Phi$; we can assume that $\cK$ is closed. We can now rewrite the $\Phi$-EVI problem as
    \begin{align*}
        \qq{find} \mu\in \Delta(\cX) \qq{s.t.} \E_{\vx\sim\mu}\ip{F(\vx) m(\vx)^\top, \mK - \mI} \ge 0
    \end{align*}
    for all $\mK \in \cK$, where above $\mat{I}$ is the identity matrix and the inner product is the usual Frobenius inner product of matrices.\footnote{To avoid measurability issues, it is enough to consider here only distributions $\mu$ with finite support.} Further, let $\cA := \co \{ F(\vx) m(\vx)^\top : \vx \in \cX\}$. Then, the $\Phi$-EVI problem can be in turn expressed as
    \begin{align*}
        \qq{find} \mA \in \cA \qq{s.t.} \ip{\mA, \mK - \mI} \ge 0
    \end{align*}
    for all $\mK \in \cK$. Since $F$ and $m$ are bounded, by assumption, so is $\cA$. Moreover, since the coordinates $m_i$ are linearly independent, $\cK$ is also bounded. Thus, letting $\bar\cA$ denote the closure of $\cA$, the max-min problem
    \begin{align}\label{eq:existence-game}
        \max_{\mA \in \bar\cA} \min_{\mK \in \cK} \ip{\mA, \mK - \mI}
    \end{align}
    satisfies the conditions of the minimax theorem. Moreover, for any $\mK\in\cK$, the fixed point $\vx := \fix(\phi_\mK)$ satisfies 
    \begin{align*}
        \ip{F(\vx) m(\vx)^\top, \mK - \mI} = \ip{F(\vx), \phi_\mK(\vx) - \vx} = 0,
    \end{align*}
    so the zero-sum game \eqref{eq:existence-game} has a nonnegative value; that is, there exists $\mA \in \bar\cA$ such that $\min_{\mK \in \cK} \ip{\mA, \mK - \mI} \ge 0$. Thus, for every $\eps > 0$, there exists $\mA \in \cA$ such that $\min_{\mK \in \cK} \ip{\mA, \mK - \mI} \ge -\eps$. Moreover, by Carath\'eodory's theorem, $\mA$ can be expressed as a convex combination of at most $1+dk$ matrices of the form $F(\vx) m(\vx)^\top$. This convex combination is thus an $\eps$-approximate EVI solution.
\end{proof}

The only reason the above proof breaks when $\eps = 0$ is that $\cA$ may not be closed. Indeed, this issue is fundamental: there are instances where no exact EVI solutions exist even when $\phi$ contains only constant functions (\Cref{prop:notexact}).

\subsection{Complexity of $\Phi$-EVIs}

With regard to the complexity of computing $\Phi$-EVI solutions, the key observation is that, when $\Phi$ contains all (measurable) maps, $\Phi$-EVIs are essentially equivalent to VIs; this immediately implies a number of hardness results, which were covered earlier in~\Cref{sec:existence}. We provide the formal proof of~\Cref{prop:EVI-VI} below.

\EVIequiv*

\begin{proof}
    We can define a measurable map $\phi : \cX \to \cX$ such that $\phi(\vx)$ is an element selected from $\argmin_{\vx' \in \cX} \ip{F(\vx), \vx' - \vx}$ by utilizing the measurable maximum theorem \citep[Theorem 18.19]{AliprantisB06:Infinite}. To satisfy the conditions of this theorem, we need to define---using \citeauthor{AliprantisB06:Infinite}'s notation--- the weakly measurable set-valued function $\psi : \cX \twoheadrightarrow \cX$ as $\psi(\vx) = \cX$ and the (Carath\'eodory) function $f : \cX \times \cX \to \R$ as $f(\vx,\vx') = - \ip{F(\vx), \vx' - \vx}$. Due to this map $\phi$, a $\Phi$-EVI solution $\mu \in \Delta(\cX)$ must then, in particular, satisfy
    \begin{align*}
        \E_{\vx\sim\mu} \ip{F(\vx), \phi(\vx) - \vx} = \E_{\vx\sim\mu} \argmin_{\vx' \in \cX} \ip{F(\vx), \vx' - \vx} \ge 0.
    \end{align*}
    Therefore, there must exist $\vxstar \in \cX$ with $\argmin_{\vx' \in \cX} \ip{F(\vxstar), \vx' - \vxstar} \ge 0$, that is, a VI solution $\vxstar$. If $\mu$ has finite support, then such a $\vxstar$ exists within that support. The $\eps$-approximation case follows analogously.
\end{proof}


\iffalse
One may have hoped that expected fixed points would save us from the above hardness result. Clearly that cannot be the case, since we have already established that the EVI problem is hard in general. But what goes wrong? The answer is the following. We need a separation oracle, that is, given $\phi \in \Phi$ we need to find $\mu$ such that $\ip{F(\vx), \phi(\vx) - \vx}$. \et{(The mathematical statement needs to be completed here.)} An expected fixed point, that is, a solution to $\E_{\vx\sim\mu}[\phi(\vx) - \vx] = 0$, does not satisfy this, because in general it is not the case that
    \begin{align}
        \E_{\vx\sim\mu}\ip{F(\vx), \phi(\vx) - \vx} = \big\langle\E_{\vx\sim\mu}F(\vx), \E_{\vx\sim\mu}[\phi(\vx) - \vx]\big\rangle
    \end{align}
because $F(\vx)$ and $\phi(\vx) - \vx$ may not be independent.
\fi


\subsection{Proof of Theorem~\ref{th:elvi}}
\label{sec:mainproof}

To establish~\Cref{th:elvi}, we will use the recent framework of~\citet{Daskalakis24:Efficient}, which refines~\Cref{theorem:eah} in the context of~\Cref{sec:eah}, ultimately summarized in~\Cref{th:eahrelax}. Coupled with the ``semi-separation oracle'' of~\Cref{lemma:semiseparation}, we will thus arrive at~\Cref{th:elvi}.

Let $\cX \subseteq \R^d$ and $\cY \subseteq \R^m$ be convex and compact sets. The goal is to solve the convex program
\begin{equation}
    \label{eq:init-prog}
    \qq{find} \mu \in \Delta(\cX) \qq{s.t.} \min_{\vy \in \cY} \langle \mu, \mat{A} \vy \rangle \geq 0,
\end{equation}
where $\Delta(\cX) \subseteq \R^M$ and $\mat{A} \in \R^{M \times m}$; we think of $M$ as being potentially exponentially large, so $\mat{A}$ is not given explicitly; $\Philin$-EVIs can be expressed as~\eqref{eq:init-prog}, assuming that $\mu$ has finite support (\emph{cf.}~\Cref{theorem:finitedim}). The target is to solve~\eqref{eq:init-prog} with complexity polynomial in $d$ and $m$ (and other parameters of the problem, except $M$). As we saw earlier in~\Cref{sec:eah}, the $\eah$ algorithm accomplishes that given access to a $\ger$ oracle, which, for any $\vy \in \cY$, returns $\vx \in \cX$ such that $\langle \mu(\vx), \mat{A} \vy \rangle \geq 0$, where $\Delta(\cX) \ni \mu(\vx)$ places all probability on $\vx$. Assuming that such an oracle exists, the convex program
\begin{equation}
    \label{eq:dual-prog}
    \qq{find} \vy \in \R_{> 0} \cY \qq{s.t.} \max_{\mu \in \Delta(\cX)} \langle \mu, \mat{A} \vy \rangle \leq -1
\end{equation}
is infeasible, where $\R_{> 0} \cY \defeq \{ c \vy : \vy \in \cY, c > 0 \}$ is the conic hull of $\cY$. Despite its infeasibility, $\eah$ proceeds by applying the ellipsoid algorithm on~\eqref{eq:dual-prog}---this is where the name ``ellipsoid against hope'' comes from. In doing so, the ellipsoid will eventually shrink to an area with negligible volume (denoted by $\vol$), at which point one can extract a certificate of infeasibility for~\eqref{eq:dual-prog} as follows. The execution of the ellipsoid will have produced a sequence of $T \in \N$ good-enough-responses, $\vx^{(1)}, \dots, \vx^{(T)}$, such that for any $\vy \in \cY$, it holds that $\langle \mu(\vx^{(t)}), \mat{A} \vy \rangle \geq 0 $ for some $t \in [T]$ (up to numerical imprecision). In turn, this implies that there is a mixture $\mu$ over $\{ \vx^{(1)}, \dots, \vx^{(T)} \}$ that guarantees $\langle \mu, \mat{A} \vy \rangle \geq 0$ for every $\vy \in \cY$. Such a $\mu$ can be computed in polynomial time by solving a smaller program, which simply searches over the mixing coefficients.

So far, we have elaborated on the framework presented in~\Cref{sec:eah}. To solve $\Philin$-EVIs, it is necessary to relax the oracle assumed above. In particular, the $\either$ oracle, introduced by~\citet{Daskalakis24:Lower}, proceeds as follows. It takes as input a point $\vy \in \R^m$ (not necessarily in $\cY$), and must \emph{either} return a good-enough-response $\vx \in \cX$, or a hyperplane separating $\vy$ from $\cY$. The idea now is to again run ellipsoid on~\eqref{eq:dual-prog}, but by replacing $\cY$ with a convex ``shell set''; every time the $\either$ oracle returns a separating hyperplane, the shell set restricts further. At the end of this process, once the ellipsoid has shrank enough, one can work with the induced shell set $\widetilde{\cY}$ and proceed by identifying a mixture among the good-enough-responses $\{\vx^{(1)}, \dots, \vx^{(T)} \}$ that approximately solves~\eqref{eq:init-prog}. The overall scheme is given in~\Cref{alg:eah}.

\begin{algorithm}[!ht]
\caption{Ellipsoid against hope ($\eah$) under $\either$ oracle~\citep{Daskalakis24:Efficient}}
\label{alg:eah}
\begin{algorithmic}[1]
\INPUT 
\begin{minipage}[t]{\linewidth} % Use a minipage to control alignment
\begin{itemize}[noitemsep,topsep=0pt,leftmargin=*]
    \item Parameters $R_y, r_y > 0$ such that $\cB_{r_y}(\cdot) \subseteq \cY \subseteq \cB_{R_y}(\vec{0})$
    \item precision parameter $\epsilon > 0$
    \item constant $B \geq 1$ such that $\| \mu^\top \mat{A} \| \leq B$ for all $\mu \in \Delta(\cX)$
    \item a $\either$ oracle
\end{itemize}
\end{minipage}
\OUTPUT A sparse, $\epsilon$-approximate solution $\mu \in \Delta(\cX)$ of~\eqref{eq:init-prog}
\STATE Initialize the ellipsoid $\cE \defeq \cB_{R_y}(\vec{0})$
\STATE Initialize $\widetilde{\cY} \defeq \cB_{R_y}(\vec{0})$
\WHILE{$\vol(\cE) \geq \vol(\cB_{\epsilon/B}(\cdot))$}
    \STATE Query the $\either$ oracle on the center of $\cE$
    \IF{it returns a good-enough-response $\vx \in \cX$}
        \STATE Update $\cE$ to the minimum volume ellipsoid containing $\cE \cap \{ \vy \in \R^m : \langle \vy, \mat{A}^\top \mu(\vx) \rangle \leq 0 \} $
    \ELSE
        \STATE Let $H$ be the halfspace that separates $\vy$ from $\cY$
        \STATE Update $\cE$ to the minimum volume ellipsoid containing $\cE \cap H$
        \STATE Update $\widetilde{\cY} \defeq \widetilde{\cY} \cap H$
    \ENDIF
\ENDWHILE
\STATE Let $\vx^{(1)}, \dots, \vx^{(T)}$ be the $\ger$ oracle responses produced in the process above
\STATE Define $\mat{X} \defeq [\mu(\vx^{(1)}) \mid \hdots \mid \mu(\vx^{(T)})]$ and compute $\mat{X}^\top \mat{A} \in \R^{T \times m} $
\STATE Compute a solution $\vec{\lambda}$ to the convex program
\begin{equation*}
    \qq{find} \vec{\lambda} \in \Delta^T \qq{s.t.} \min_{\vy \in \widetilde{\cY}} \vec{\lambda}^\top ( \mat{X}^\top \mat{A}) \vy \geq - \epsilon
\end{equation*}
\STATE \textbf{return} $\Delta(\cX) \ni \mu \defeq \sum_{t=1}^T \lambda^{(t)} \mu(\vx^{(t)})$
\end{algorithmic}
\end{algorithm}

Below, we state the main guarantee of~\Cref{alg:eah} shown by~\citet{Daskalakis24:Efficient}; in its statement, we have made certain slight adjustments in accordance with our setting.

\begin{theorem}[\citealp{Daskalakis24:Efficient}]
    \label{th:eahrelax}
    Suppose that the following conditions hold.
    \begin{enumerate}
        \item $\mat{A} \in \R^{M \times m}$ such that for any $\mu \in \Delta(\cX)$, $\| \mu^\top \mat{A} \| \leq B$ for some $B \geq 1$;
        \item $\cY$ is convex and compact, and satisfies $\cB_{r_y}(\cdot) \subseteq \cY \subseteq \cB_{R_y}(\vec{0})$; \label{item:niceness-Y} and
        \item there exists a $\either$ oracle: for every point $\vy \in \cB_{R_y}(\vec{0})$, it runs in $\poly(d, m)$ time, and either returns a hyperplane separating $\vy$ from $\cY$ or a good-enough-response $\vx \in \cX$.\label{item:oracle}
    \end{enumerate}
    Then, \Cref{alg:eah} runs in $\poly(d, m, \log(B/\epsilon))$ time and computes $\mu \in \Delta(\cX)$ such that
    \begin{equation*}
        \min_{\vy \in \cY} \langle \mu, \mat{A} \vy \rangle \geq - \epsilon.
    \end{equation*}
\end{theorem}

That the second precondition (\Cref{item:niceness-Y}) is satisfied follows from~\citet[Lemma 2.3]{Daskalakis24:Efficient}. The third precondition, \Cref{item:oracle}, is satisfied by virtue of~\Cref{lemma:semiseparation}. Consequently, \Cref{th:elvi} follows from~\Cref{th:eahrelax}.

\begin{remark}[Weak oracles and finite precision]
    Since we are working with general convex sets, the oracles posited in~\Cref{sec:prel} (namely, membership, separation, and linear optimization) can return irrational outputs. This can be addressed by employing \emph{weak} versions of those oracles, which relax the output by allowing some small slackness $\epsilon$~\citep{Grotschel93:Geometric}. \Cref{th:elvi} can be readily extended under those weaker oracles; see~\citet[Appendices E and F]{Daskalakis24:Efficient}.
\end{remark}

\section{Characterizing Linear Endomorphisms for Polytopes}
\label{sec:repre}

In this section, we answer the following question. Given a nonempty polytope $\cX = \{ \vx \in \R^d : \mA \vx \le \vb\}$ where $\mA\in\R^{m\times d}$ and $\vb\in\R^m$, we wish to characterize the set of (affine) linear maps $\phi : \cX \to \cX$. That is, we wish to understand the set of pairs $(\mK, \vc) \in \R^{d\times d} \times \R^d$ such that $\mK \vx + \vc\in \cX$ for all $\vx\in\cX$. The following result provides an explicit polynomial representation for that set, establishing~\Cref{theorem:regret}.

\begin{theorem}
    \label{theorem:explicit-repres}
    $\mK \vx + \vc \in \cX$ for all $\vx\in\cX$ if and only if there is a matrix $\mV \in \R^{m \times m}$ satisfying the constraints
    \begin{align}
        \mV\mA = \mA\mK, \quad \mV\vb \le \vb - \mA \vc, \quad \mV \ge \vec 0.
    \end{align}
\end{theorem}
\begin{proof}
    Let $\mK \in \R^{d\times d}$ and $\vc \in \R^d$, and let $\va_i^\top  \vx \le b_i$ be the $i$th constraint that defines $\cX$. Then, the claim that $\va_i^\top (\mK \vx + \vc) \le b_i$ for every $\vx\in\cX$ is equivalent to the claim that the linear program
    \begin{align}
        \max_{\vx} \quad \va_i^\top \mK \vx \qq{s.t.} \mA\vx\le \vb\label{eq:lp primal}
    \end{align}
    has value at most $b_i - \va_i^\top \vc$. By strong duality, \eqref{eq:lp primal} has the same value as
    \begin{align*}
        \min_{\vv_i} \quad \vb^\top\vv_i \qq{s.t.} \mA^\top \vv_i = \mK^\top \va_i, \quad \vv \ge \vec 0.
    \end{align*}
    The theorem follows now by setting $\mV = \mqty[\vv_1 & \dots & \vv_k]^\top$.
\end{proof}

Furthermore, assuming that $\cB_1(\vec{0}) \subseteq \cX \subseteq \cB_R(\vec{0})$ with $R \leq \poly(d)$, it follows that $\| \mat{K} \|_2, \|\mat{V} \|_2 \leq \poly(d)$, where $\|\cdot\|_2$ denotes the spectral norm. Indeed, to begin with, $\| \vc \|_2 \leq R$ since $\mK \cdot \vec{0} + \vc \in \cX \subseteq \cB_r(\vec{0})$. For $\| \mat{K} \|_2$, take any $\vx \in \R^d$ with $\|\vx\| = 1$. Since $\cB_1(\vec{0}) \subseteq \cX$, we have $\vx \in \cX$, in turn implying that $\mat{K} \vx + \vc \in \cX$. As a result, $\|\mat{K} \vx \| - \|\vc\| \leq \| \mat{K} \vx + \vc \| \leq \poly(d)$, from which it follows that $\| \mat{K} \|_2 \leq \poly(d)$. Further, one can take each $\vec{a}_i$ and $b_i$ to be such that $1 \leq b_i \leq \poly(d)$ and $\| \vec{a}_i \| = 1$, and so the bound $\| \mat{V} \|_2 \leq \poly(d)$ follows from the fact that $\mat{V} \vec{b} \leq \vec{b} - \mat{A} \vc$ and $\mat{V} \geq 0$.

Combining these bounds with~\Cref{theorem:explicit-repres}, and as we saw earlier in~\Cref{cor:regret}, we are able to use standard techniques for minimizing regret over $\Philin$---such as projected gradient descent.

For comparison, let us point out the approach of~\citet{Daskalakis24:Efficient} for the case where $\cX$ is given explicitly. To do so, we recall the following definition.

\begin{definition}
    \label{def:repr}
We say that a polytope $\cX$ has an \emph{H-representation} of size $m$ if it is given as the intersection of $m$ halfspaces: $\cX = \{  \vx \in \R^d : 
\mat{A} \vx \leq \vec{b} \}$ for some $\mat{A} \in \Q^{m \times d}$ and $\vec{b} \in \Q^m$. It has a \emph{$V$-representation} of size $m$ if it is given as the convex hull of $m$ vertices: $\cX = \conv( \{ \vec{v}_1, \dots, \vec{v}_m \} )$ for $\vec{v}_1, \dots, \vec{v}_m \in \Q^d$.    
\end{definition}

In this context, they make the following crucial observation~\citep[Lemmas 3.1 and 3.2]{Daskalakis24:Efficient}.

\begin{lemma}[\citealp{Daskalakis24:Efficient}]
    \label{lemma:H-V}
    If $\cX$ has either an $H$-representation of size $m$ or a $V$-representation of size $m$, there is a $\poly(d, m)$-time membership oracle for $\Philin$.
\end{lemma}

Using a membership oracle for $\Philin$, it is also possible to construct a linear optimization oracle~\citep{Grotschel12:Geometric}. As a result, coupled with~\Cref{lemma:H-V}, standard algorithms---such as \emph{follow-the-perturbed-leader}~\citep{Hazan16:Introduction}---can be applied to minimize regret over $\Philin$. However, the main limitation is that constructing a linear optimization oracle using a membership oracle relies on the ellipsoid algorithm, which is impractical. In contrast, \Cref{theorem:explicit-repres} allows us to bypass using the ellipsoid algorithm, resulting in a more practical approach.

It is also worth noting that one can extend~\Cref{theorem:regret} using only a membership oracle for $\cX$ (even when $\cX$ is not an explicitly represented polytope) using techniques from~\citet{Daskalakis24:Efficient}, although the resulting algorithm is more elaborate and requires running the ellipsoid algorithm on every iteration to compute the next strategies.

\section{An Illustrative Example of Definition~\ref{def:smooth-fun}}
\label{sec:appendix-smooth}

In \Cref{sec:smoothness}, we introduced a generalized notion of smoothness (\Cref{def:smoothness}) that captures Roughgarden's notion in the context of multi-player games. As a result, there are numerous interesting examples that fall under~\Cref{def:smoothness}; for example, \citet{Roughgarden17:Price} provide a survey in the context of auctions. Our goal here is to provide a single function that satisfies~\Cref{def:smooth-fun}, but without being quasar-concave (in the sense of~\Cref{def:quasar}).

\begin{example}
    We consider the polynomial function
    \begin{equation}
        \label{eq:u-smooth}
        u : x \mapsto - \frac{3}{4} p x^4 + p x^3 + 1,
    \end{equation}
    where $p \in (0, 8]$. $u$ has a global maximum at $x = 1$, with value $1 + \nicefrac{p}{4}$. It also admits a VI solution (in fact, a saddle point) at $x = 0$. This implies that $u$ is not $\gamma$-quasar-concave for any $\gamma \in (0, 1]$. On the other hand, it is not hard to verify the following claim.

    \begin{claim}
        \label{claim:u}
        $u$ is $(1, \nicefrac{p}{4})$-smooth (\Cref{def:smooth-fun}) for any $p \in (0, 8]$.
    \end{claim}
    A graphical illustration of $u$ for various values of $p$ is given in~\Cref{fig:smooth_polynomial}. Coupled with~\Cref{theorem:smoothness}, \Cref{claim:u} implies that any solution $\mu$ to the induced EVI problem satisfies
    \begin{equation}
        \E_{ x \sim \mu} u(x) \geq \frac{1}{ 1 + \frac{p}{4}} \max u(x)=1.
    \end{equation}
    This guarantee is tight, since $x = 0$, with $u(0) = 1$, is a solution to the (E)VI problem.

    \begin{figure}[!ht]
        \centering
        \includegraphics[scale=.6]{figs/smooth_polynomial.pdf}
        \caption{Function $u$, defined in~\eqref{eq:u-smooth}, for $p \in \{1, 2, 4, 8\}$.}
        \label{fig:smooth_polynomial}
    \end{figure}
\end{example}

\begin{remark}
    \Cref{def:smoothness}, to which~\Cref{def:smooth-fun} is a special case, is a generalization of smoothness in the sense of~\citet{Roughgarden15:Local}. While our bound applies to any EVI solution (\Cref{theorem:smoothness}), \citet{Roughgarden15:Local} gave a counter-example that excludes CCEs; this is not a contradiction because they define CCEs \emph{without} linearizing the utilities (as in~\Cref{example:CCE}), while EVIs always operate over the linearized utilities. 
\end{remark}

\section{Omitted Details from \Cref{sec:games}}\label{sec:appendix-joint}
In this section and the next, we will use the notation $\Philin(\cX, \cY)$ to denote the set of linear maps $\phi : \cX \to \cY$. %When $\cX = \cX_1 \times \dots \times \cX_n$, we will sometimes abuse notation and also use $\Philin(\cX_i, \cY)$ to denote the set of linear maps $\phi : \cX \to \cY$ that only depend on $\vx_i$.

In this section, let $\Gamma$ be a concave game. For each player $i$ let $\cX_i \subset \R^{d_i}$ be its (convex, compact) strategy set, and let $\Phi_i \subseteq \cX_i^{\cX}$. We assume $u_i(\cdot, \vx_{-i})$ is differentiable in $\vx_i$ for all $i$.\footnote{By ``$f : \cC \to \R$ is differentiable'' when $\cC$ is closed, we mean that $f$ is defined and differentiable on an open set $\hat \cC \supset \cC$.} Without loss of generality we assume that the projection function $\pi_i(\vx) = \vx_i$ is in $\Phi_i$, and that $\Phi_i$ is convex. Crucially for this section and departing to our knowledge from all  prior work on $\Phi$-equilibria in games, functions $\phi_i \in \Phi_i$ are allowed to depend not just on $\vx_i$ but also on $\vx_{-i}$. We first generalize the examples in \Cref{sec:games} to arbitrary $\Phi$.
\begin{definition}
    An {\em $\eps$-approximate $\Phipl$-equilibrium} of $\Gamma$ is a distribution $\mu \in \Delta(\cX)$ such that 
    \begin{align*}
        \E_{ \vx \sim \mu } \qty[u_i(\phi_i(\vx_i), \vx_{-i}) - u_i(\vx)] \leq \epsilon
    \end{align*}
    for all players $i$ and deviations $\phi_i\in \Phi_i$.
\end{definition}
As discussed in \Cref{sec:games}, several special cases of $\Phi_i$ are well-studied and interesting:
\begin{itemize}
    \item When $\Phi_i$ contains the set of constant endomorphisms and the projection $\pi_i$, the set of $\Phipl$-equilibria are the CCEs.
    \item When $\Phi_i$ consists of linear endomorphisms depending only on $\vx_i$, \ie, functions of the form $\vx \mapsto \mA \vx_i$ for matrices $\mA$, $\Phipl$-equilibria are LCEs, which correspond to CEs in the special case of  normal-form games.
    \item When $\Phi_i$ consists of all functions $\cX \to  \cX_i$, $\Phipl$-equilibria are Nash equilibria.
\end{itemize}

Now let $\cX = \cX_1 \times \dots \times \cX_n \subset \R^d$ where $d = \sum_i d_i$, and define $\Phi \subseteq \cX^\cX$ to be the set of all functions of the form 
    \begin{align*}
        \vx \mapsto (\vx_1, \dots, \phi_i(\vx), \dots, \vx_n)
    \end{align*}
for players $i$ and functions $\phi_i \in \Phi_i$. We will abuse notation and also call these functions $\phi_i : \cX \to \cX$. Moreover, let $F : \cX \to \R^{\sum_i d_i}$ be given by $F(\vx) = -\qty(\grad_{\vx_1} u_1(\vx), \dots, \grad_{\vx_n} u_n(\vx))$.
\begin{proposition}\label{prop:evi phi equivalence convex}
    If $\mu$ is an $\eps$-approximate $\Phi$-EVI solution of $F$, then $\mu$ is an $\eps$-approximate $\Phipl$-equilibrium $\Gamma$. The converse holds for $\eps = 0$. 
\end{proposition}
\begin{proof}
    Suppose first that $\mu \in \Delta(\cX)$ is an $\eps$-approximate $\Phi$-EVI solution of $F$. Then, for any player $i$ and deviation $\phi_i \in \Phi_i$, we have
    \begin{align*}
        \E_{ \vx \sim \mu } \qty[u_i(\phi_i(\vx), \vx_{-i}) - u_i(\vx)] \leq \E_{\vx\sim\mu} \ip{\grad_{\vx_i} u_i(\vx), \phi_i(\vx) - \vx_i} = \E_{\vx\sim\mu} \ip{-F(\vx), \phi_i(\vx) - \vx} \le \eps,
    \end{align*}
    where the first inequality is concavity and the second is the definition of $\Phi$-EVI. Conversely, suppose that $\mu$ is an (exact) $\Phipl$-equilibrium of $\Gamma$. For $\lambda \in \R$ let $\phi_i^\lambda = \lambda \phi_i + (1 - \lambda) \pi_i$. Let $g : [0, 1] \times \cX \to \R$ be defined by
    \begin{align*}
        g(\lambda, \vx) = u_i(\phi_i^\lambda(\vx), \vx_{-i}) - u_i(\vx).
    \end{align*}
    Then, $g$ is differentiable in $\lambda$ for any fixed $\vx$, and $g$ is bounded. Let $G(\lambda) = \E_{\vx\sim\mu} g(\lambda, \vx)$. Then $G(0) = 0$, and by the Leibniz rule, $G$ is differentiable with derivative
    \begin{align*}
        G'(0) &= \E_{\vx\sim\mu} \grad_\lambda g(0, \vx) 
        \\&=  \E_{ \vx \sim \mu }  \ip{\grad_{\vx_i} u_i(\vx), \lim_{\lambda \to 0} \frac{1}{\lambda} \qty( \phi_i^\lambda(\vx) - \vx_i)}
       \\&= \E_{ \vx \sim \mu } \ip{\grad_{\vx_i} u_i(\vx), \phi_i(\vx) - \vx_i} 
       \\&= \E_{\vx\sim\mu}\ip{-F(\vx), \phi_i(\vx) - \vx},
    \end{align*}
    where we use the chain rule, then the definition of $\phi_i^\lambda$, and finally the definition of $F$.    But if $\E_{\vx\sim\mu}\ip{-F(\vx), \phi_i(\vx) - \vx} > 0$, then by definition of derivative, there is some $\lambda > 0$ for which $G(\lambda) > 0$, contradicting the definition of $\Phipl$-equilibrium.
\end{proof}

We now prove the following generalization of \Cref{prop:joint lce symmetric}.
\begin{proposition}\label{prop:symmetry equivalence}
    For a given distribution $\mu \in \Delta(\cX)$, define the distribution $\mu^n \in \Delta(\cX^n)$ by sampling $\vx\sim\mu$ and outputting $(\vx, \dots, \vx) \in \cX^n$. Then the $(\Phi_1, \dots, \Phi_n)$-equilibria of $\Gamma$ are precisely the $(\Phi, \dots, \Phi)$-equilibria of $\Gamma^\textup{sym}$.  
\end{proposition}
\begin{proof}
    $\mu^n$ is an $\eps$-approximate $(\Phi, \dots, \Phi)$-equilibria of $\Gamma^\text{sym}$ if and only if, for every player $i$ and linear map $\phi : \cX \to \cX$, we have
    \begin{align*}
        0 &\ge \frac{1}{n!} \sum_{\sigma \in \Sym_n } \E_{\vx\sim\mu} \qty[u_{\sigma(i)}(\vx_1, \dots, \phi(\vx)_{\sigma(i)}, \dots, \vx_n) - u_{\sigma^{-1}(i)}(\vx)] 
        \\&= \frac{1}{n} \sum_{j \in [n]} \E_{\vx\sim\mu} \qty[u_{j}(\vx_1, \dots, \phi(\vx)_j, \dots, \vx_n) - u_{j}(\vx)] .
    \end{align*}
    But this holds if and only if 
    \begin{align*}
        \E_{\vx\sim\mu} \qty[u_{j}(\vx_1, \dots, \phi_j(\vx), \dots, \vx_n) - u_{j}(\vx)] \le 0
    \end{align*}
    for every player $j$ and every $\phi_j \in \Phi_j$, which is precisely the definition of an $(\Phi_1, \dots, \Phi_n)$-equilibria of $\Gamma$.
\end{proof}
\Cref{prop:joint lce symmetric} follows by combining \Cref{prop:symmetry equivalence} and \Cref{prop:evi phi equivalence convex} in the special case when $\Phi_i = \Philin(\cX, \cX_i)$.

\subsection{Anonymous linear correlated equilibria}

For the special case where $\Phi_i = \Philin(\cX, \cX_i)$, we have coined the resulting $\Phipl$-equilibrium notion an {\em anonymous linear correlated equilibrium} (\jlce). We now compare \jlces and LCEs in concave games. We now point out some intriguing properties of \jlces, especially compared to LCEs and CEs.

In normal-form games $\Gamma$, LCEs and CEs coincide, and \jlces lie strictly between LCEs and Nash equilibria, as can be seen in \Cref{fig:bach or stravinsky}. We now elaborate on the normal-form specific game-theoretic interpretation of \jlces by giving an augmented game-based definition. For any fixed $\mu \in \Delta(\cX)$, consider the augmented game $\Gamma^\mu$ that proceeds as follows.
\begin{enumerate}
    \item A correlation device samples $\vx\sim\mu$. 
    \item Each player $i$ chooses a player $j$ (possibly not itself) and observes a sample $a_j \sim \vx_j$, {\em independently from the samples of other players}. (In particular, if multiple players choose the same player $j$, then they get independent samples from $\vx_j$.)
    \item Each player selects an action $a_i \in \cA_i$ and gets utility $u_i(a_1, \dots, a_n)$.
\end{enumerate}
\begin{proposition}\label{prop:joint lce augmented}
    A distribution $\mu \in \Delta(\cX)$ is a \jlce of $\Gamma$ if and only if the strategy profile in which every player requests an action for itself and then plays that action is a Nash equilibrium of $\Gamma^\mu$. 
\end{proposition}
The proof will use critically the following characterization of linear maps. 
\begin{lemma}[\citealp{Fujii23:Bayes}]\label{lem:fujii}
    Let $\cX = \cX_1 \times \dots\times \cX_n$ where each $\cX_i$ is a simplex $\cX_i = \Delta([m_i])$. Then every linear map $\phi : \cX \to \cX_i$ is a convex combination of linear maps $\phi_j : \cX \to \cX_i$ that only depend on a single $\vx_j$.
\end{lemma}
\begin{proof}[Proof of \Cref{prop:joint lce augmented}]
Fix some $\mu \in \Delta(\cX)$ and suppose that it is not a \jlce, that is, there is some profitable deviation $\phi : \cX \to \cX_i$ for some player $i$. By \Cref{lem:fujii}, it suffices to assume that $\phi$ only depends on one player's strategy $\vx_j$. Moreover, a linear map $\phi : \cX_j \to \cX_i$ can be represented as $\vx_j \mapsto \mA \vx_i$, where $\mA \in \R^{m_i \times m_j}$ is column-stochastic. Again, it suffices to assume that $\phi$ is a vertex of the set of column-stochastic matrices, that is, $\mA$ has exactly one $1$ in each column. Now player $i$'s deviation benefit under deviation $\phi$ is given by
\begin{align*}
    \E_{\vx\sim\mu} [u_i(\phi_j(\vx_j), \vx_{-i}) - u_i(\vx)] =  \E_{\substack{\vx\sim\mu\\a\sim\vx}}\qty[\E_{a_j'\sim\vx_j}u_i(\phi_j(a_j'), a_{-i}) - u_i(a)],
\end{align*}
where the equality uses multilinearity of $a$. This is precisely the deviation benefit of the strategy in $\Gamma^\mu$ for player $i$ in which player $i$ chooses to sample $a_j'$ and then plays an action according to $\phi_j : [m_j] \to [m_i]$. The proposition now follows by observing that these are precisely the possible pure strategy deviations of player $i$ in $\Gamma^\mu$.
\end{proof}

We make several more observations about the relationship between \jlces and other notions of equilibrium in games.
\begin{itemize}
    \item \Cref{prop:joint lce augmented} generalizes beyond normal-form games, but needs to be modified. For example, for (single-step) Bayesian games where each $\cX_i$ is itself a product of simplices, it follows from a similar proof that, in the augmented game $\Gamma^\mu$, player $i$ should be allowed to observe its own type first, and then select both another player $j$ and a type $\theta_j$ of that player at which to ask for a recommendation. (Another way to see this is that the EVI formulation does not distinguish Bayesian games from their {\em agent form}~\citep{Kuhn53:Extensive}, where each player-type pair is treated as a separate player.)
    
    Even more generally, for extensive-form games, we can generalize \jlces using a characterization of the linear maps $\cX\to\cX_i$ due to \citet{Zhang24:Mediator}: in $\Gamma^\mu$, player $i$ first may  observe its first recommendation at any time of its choosing, and may delay its choice of which player $j$ to observe until that point.
    
    \item In normal-form games, CEs can be without loss of generality defined as distributions over {\em pure} action profiles $\cA = \cA_1 \times \dots \times \cA_n$ instead of distributions over mixed strategy profiles $\cX=  \cX_1 \times \dots \times \cX_n$~\citep{Aumann74:Subjectivity}. By ``without loss of generality,'' we mean the following: given any $\mu\in\Delta(\cX)$, define $\mu'\in\Delta(\cA)$ by sampling $\vx\sim\mu$, then $a_i\sim\vx_i$ for each $i$. Then $\mu$ is a correlated equilibrium if and only if $\mu'$ is.

    This phenomenon is {\em not} true for \jlces. Indeed, for two-player games, if $\mu'\in\Delta(\cA)$ is a \jlce, then in fact $\mu'$ is a distribution over pure Nash equilibria, which in general may not even exist! It is thus critical in our definition that $\mu$ be allowed to be a distribution over {\em mixed} strategy profiles, not just {\em pure} strategy profiles.

    \item We have shown that there is an efficient algorithm for computing {\em one} (approximate) \jlce. We leave as an open question the complexity of computing an {\em optimal} (\eg, welfare-maximizing) \jlce (when the number of players $n$ is a constant). Optimal CEs can be computed efficiently in this setting, because the set of CEs $\mu\in\Delta(\cA)$ is bounded by a small number of linear constraints; however, this fails for \jlces because, as above, we need to optimize over $\mu\in\Delta(\cX)$.
\end{itemize}




\section{Local \texorpdfstring{$\Phipl$}{Phi}-Equilibria in Nonconcave Games}
\label{sec:localPhi}

This section connects $\Phi$-EVIs with a solution concept recently put forward by~\citet{Cai24:Tractable} (see also~\citet{Ahunbay25:First}) in the context of nonconcave games (\Cref{prop:localPhi}).

\paragraph{Nonconcave games} Consider an $n$-player game in which each player $i \in [n]$ has a convex and compact strategy set $\cX_i$, and a differentiable utility function $u_i : \cX_1 \times \dots \times \cX_n \to \R$. Crucially, there is now no assumption that $u_i$ is concave. In this setting, our framework suggests the following definition.
\begin{definition}
    \label{def:localPhi}
    Given sets of functions $\Phi \subseteq  \cX_i^{\cX_i}$, an {\em $\eps$-approximate local $\Phipl$-equilibrium} in an $n$-player nonconcave game is a distribution $\mu \in \Delta(\cX_1 \times \dots \times \cX_n)$ such that for any player $i \in [n]$ and deviation $\phi_i \in \Phi_i$,
    \begin{align*}
        \E_{\vx\sim\mu} \ip{\grad_{\vx_i} u_i(\vx), \phi_i(\vx_i) - \vx} \le \eps.
    \end{align*}
\end{definition}
\Cref{th:elvi} immediately implies the following result when $\Phi_i = \Philin(\cX_i, \cX_i)$; as before, in what follows, we assume a membership oracle for each $\cX_i$.

\begin{corollary}\label{cor:nonconcave ellipsoid}
Suppose $\norm{\grad u_i(\vx)} \le B$ for every player $i \in [n]$ and profile $\vx \in \cX_1 \times \dots \times \cX_n$. Then, there is a $\poly(d, \log(B/\eps))$-time algorithm that outputs an $\eps$-approximate local $\Phipl$-equilibrium.
\end{corollary}
Similarly, the existence of linear swap-regret minimizers for arbitrary polytopes $\cX_i$~\citep{Daskalakis24:Efficient} immediately implies the following.

\begin{corollary}
    There is an independent no-regret learning algorithm that computes $\eps$-approximate local $\Phipl$-equilibria in $\poly(d, 1/\eps)$ rounds and $\poly(d, 1/\eps)$ per-round runtime.
\end{corollary}

\citet{Cai24:Tractable} also studied the problem of computing local $\Phipl$-equilibria in nonconcave games. They defined $\eps$-local $\Phipl$-equilibria instead by restricting the magnitudes of the deviations to the ``first-order'' regime where local deviations cannot change the gradients by too much. In particular, they assume that utility functions $u_i$ are smooth, in the sense that
\begin{align*}
    \norm{\grad_{\vx_i} u_i(\vx_i, \vx_{-i}) - \grad_{\vx_i} u_i(\vx_i', \vx_{-i})}_2 \le L \norm{\vx_i - \vx_i'} \quad \forall \vx_i, \vx_i' \in \cX_i, \forall \vx_{-i} \in \bigtimes_{i' \neq i} \cX_{i'},
\end{align*}
where $L > 0$ is a constant. Then, they restrict deviations to only slightly perturb the strategies, that is, for a given set $\Phi_i \subseteq \cX_i^{\cX_i}$, they define a set $$\Phi_{i}(\delta) := \{ \lambda \phi_i + (1 - \lambda) \Id : \phi_i \in \Phi_i, \lambda \le \delta / D_i \},$$ where $\Id : \cX \to \cX$ is the identity function and $D_i$ is the $\ell_2$-diameter of $\cX_i$, \ie, $\norm{\vx - \vx'}_2 \le D_i$ for all $\vx, \vx' \in \cX_i$. With this restriction, they show \citep[Lemma~1 and Theorem~10]{Cai24:Tractable} that $\Phi$-regret minimizers converge to $\Phi(\delta)$-equilibria, in the sense that
\begin{align*}
    \E_{\vx\sim\mu}[u_i(\phi_i(\vx_i), \vx_{-i}) - u_i(\vx)] \le \frac{\delta}{D_i}\frac{\phireg_i^{(T)}}{T}+\frac{\delta^2 L}{2},
\end{align*}
where $\phireg_i$ is the $\Phi_i$-regret of Player $i \in [n]$, for all players $i$ and deviations $\phi_i \in \Phi_i(\delta)$. Our results imply theirs, in the following sense.

\begin{proposition}
    \label{prop:localPhi}
    Any $\eps$-approximate local $\Phipl$-equilibrium $\mu$ (per~\Cref{def:localPhi}) satisfies
    $$\E_{\vx\sim\mu}[u_i(\phi_i(\vx_i), \vx_{-i}) - u_i(\vx)] \le \frac{\delta\eps}{D_i}+\frac{\delta^2 L}{2}$$
    for any player $i \in [n]$ and deviation $\phi_i \in \Phi_i(\delta)$.
\end{proposition}
\begin{proof}
Write $\phi_i = \lambda \phi_i^* + (1 - \lambda) \Id$ for some $\phi_i^* \in \Phi_i$. Then,
    \begin{align*}
        u_i(\phi_i(\vx_i), \vx_{-i}) - u_i(\vx) &\le \ip{\grad_{\vx_i} u_i(\vx), \phi_i(\vx_i) - \vx_i} + \frac{L}{2} \norm{\phi_i(\vx_i) - \vx_i}_2^2 \\
        &\le \frac{\delta}{D_i} \ip{\grad_{\vx_i} u_i(\vx), \phi_i^*(\vx_i) - \vx_i} + \frac{\delta^2 L}{2},
    \end{align*}
    where the last inequality uses the fact that $\lambda \le \delta/D_i$ and therefore $\norm{\phi_i(\vx_i) - \vx_i}_2 \le \lambda \norm{\phi_i^*(\vx_i) - \vx_i}_2 \le \lambda D_i \le \delta$.
    Taking expectations over $\mu$ and applying the definition of $\eps$-approximate local $\Phipl$-equilibrium completes the proof.
\end{proof}

However, our results improve on theirs in several ways:
\begin{itemize}
    \item We believe that the formulation of local $\Phipl$-equilibria using gradients directly instead of restricting to small perturbations is more natural and more directly conveys what it means for a distribution to be a local $\Phipl$-equilibrium without introducing too many hyperparameters; one of the notions proposed by \citet[Definition 6]{Ahunbay25:First} also shares this advantage.
    \item Our results do not require the smoothness of the utility functions $u_i$.
    \item We have an ellipsoid-based algorithm that computes local $\Phipl$-equilibria with convergence rate depending on $\log(1/\eps)$, whereas no-regret algorithms only achieve $\poly(1/\eps)$ convergence rate.
    \item Although we do not explicitly state it here, \Cref{def:localPhi} and \Cref{cor:nonconcave ellipsoid} extend directly to the case where $\Phi_i = \Philin(\cX, \cX_i)$ (instead of $\Philin(\cX_i, \cX_i)$). Per \Cref{sec:appendix-joint}, this can yield an even smaller set of equilibria.
\end{itemize}
