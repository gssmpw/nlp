\section{Related Work}
\label{sec:related}

The Vendiscope offers a range of capabilities, including the detection of outliers, duplicates, samples prone to memorization, and samples that models may struggle to predict---prior to any training. It also ranks data points according to their rarity. Related works only tackle a subset of these tasks, typically in specific domains, and we discuss them below.

\parhead{Near-duplicate detection.} Several methods have been developed to detect duplicates in specific domains, e.g. proteins and text~\citep{kocetkov2022stack, lee2021deduplicating, steinegger2018clustering, zhang2023retsim}. MMSeqs2 is a highly-parallelizable method for detecting duplicates in protein sequences using an approximate matching of k-mers across sequences~\citep{steinegger2018clustering}. While MMSeqs2 is fast in practice, it can be inaccurate~\citep{schutze2022nearest, ou2023recent}. We observed this inaccuracy on the UniProtKB dataset in our experiments, as discussed earlier. This limitation of MMSeqs2 is partially because proteins with matched k-mers do not necessarily describe homologs or functions~\citep{schutze2022nearest, villegas2021unsupervised}. As a result, the duplicate sequences identified by MMSeqs2 are less informative. knnProtT5 is an alternative method that relies on k-nearest neighbor search on protein embeddings~\citep{schutze2022nearest}. However, this has a higher complexity of $\mathcal{O}(N\log N)$ compared to the Vendiscope and MMSeqs2, which have linear complexity. 

A popular approach for detecting duplicates in text data is the MinHash-based Locally Sensitive Hashing (LSH) algorithm~\citep{lee2021deduplicating, kocetkov2022stack}. This method estimates the Jaccard similarity between two documents using a series of hashing functions, which makes it scalable and amenable to various streaming optimizations. However, MinHash does not account for semantic similarity and is thus sensitive to typos and other adversarial attacks on text. Another duplication detection method for text is RETSim, which trains a lightweight encoder model for near-duplicate detection~\citep{zhang2023retsim}. While the results are quite encouraging, it is not feasible for researchers to train a specialized model for each potential use-case. 

The Vendiscope can detect near duplicates at scale (see \Cref{table:DupMethods}) and applies to any domain where similarity can be defined, which makes it more general. Furthermore, the Vendiscope offers additional capabilities for analyzing data collections beyond duplication detection. 

\parhead{Detecting memorization in generative models.} Significant efforts have been made to identify the causes of memorization in generative models ~\citep{jagielski2022measuring, kandpal2022deduplicating, lee2021deduplicating, somepalli2023diffusion, tirumala2022memorization}, and this topic continues to attract considerable attention from the ML community. \citet{kandpal2022deduplicating} and \citet{lee2021deduplicating} found that the presence of duplicates can be a potential cause of model memorization. However, memorization can occur even in the absence of duplicates~\citep{somepalli2023diffusion}. Overfitting has also been thought to contribute to memorization; however, \citet{tirumala2022memorization} found examples of memorized training samples from models that had not yet overfit. Moreover, \citet{jagielski2022measuring} attributed memorization to the order in which data is presented to a model, with samples presented last being more prone to memorization. The Vendiscope provides a new framework for reasoning about memorization in ML: memorization is closely linked to the contribution of samples to diversity. Our analysis of $13$ different image generative models shows that samples contributing more to diversity are less likely to be memorized, while those prone to memorization contribute the least to diversity. Moreover, by identifying a correlation between memorization and diversity, the Vendiscope adds an extra capability: it can detect data points likely to be memorized by models even before training. This is possible because the Vendiscope can be applied to any collection, whether it's the training set or outputs from a generative model.

An additional challenge in studying model memorization is the lack of reliable metrics. Existing metrics, such as \(C_T\), calibrated \(l_2\) distance, and label memorization, often require significant tuning or can only detect specific forms of memorization \citep{meehan2020non, stein2023exposing, pondenkandath2018leveraging}. Alternatives include manually feeding prompts from the training data to the model in an attempt to identify memorized samples \citep{carlini2022quantifying}. However, selecting which prompts to feed is largely ad-hoc and relies on heuristics such as prompt length. The Vendiscope can guide such a prompting strategy by identifying clusters of data that are likely to be memorized.

\parhead{Characterizing large-scale datasets.} Certain datasets, such as The Stack, FineWeb, C4, and RedPajama, have become staples for training large language models \citep{kocetkov2022stack, penedo2024fineweb, webster2021person}. However, the contents of these datasets are not well understood, and very few works have attempted to address this gap. \citet{penedo2024fineweb} conducted extensive ablation studies to justify the curation strategies behind FineWeb, yet the dataset itself remains largely opaque beyond a high-level topic analysis and a word-association bias study. \citet{elazar2023s} analyzed numerous benchmark text datasets, revealing statistics such as the most common $n$-grams, the diversity of text sources, and the number of exact duplicate documents within each dataset. The overall pipeline enables searches for the amount of personally identifiable information (PII) present in each dataset. \citet{zhong2024explaining} also aimed to improve vision and language dataset interpretation by identifying common topics present in the dataset. The Vendiscope provides a more comprehensive analysis of the composition of a data collection and is applicable beyond documents and images.

\parhead{Vendi scoring.} 
The Vendi Score (VS) and the probability-weighted Vendi Score (pVS) were introduced by \cite{friedman2023vendi} and quantify the diversity of a collection of elements. \citet{pasarkar2023vendi} demonstrated the utility of optimizing the VS in molecular dynamics simulations, finding that jointly optimizing the VS and the energy of a molecule significantly speeds up and diversifies the exploration of complex energy landscapes. \cite{berns2023towards} optimized the sum of the pVS and the Shannon entropy of the probabilities involved in the computation of the pVS to balance the modes of generative models, enhancing their ability to produce diverse outputs in artistic domains. The VS has been extended and applied in multiple ways, owing to its flexibility~\citep{askari2024improving, kannen2024beyond,liu2024diversity,nguyen2024quality, mousavi2024vsi, pasarkar2024cousins, rezaei2025alpha, bhardwaj2025robust}. The Vendiscope maximizes the pVS and enables scalable detection of outliers, duplicates, samples prone to memorization, and samples that models may struggle to predict, even before training. It also ranks the data points in a given dataset according to their rarity and provides per-data-point weights that can aid in data processing, model training, and evaluation.


\begin{table}[]
\def\arraystretch{1.1}
\centering
\begin{NiceTabular}{@{}m{0.22\linewidth}m{0.24\linewidth}m{0.22\linewidth}m{0.17\linewidth}@{}}[colortbl-like]
\multirow[b]{2}{*}{\textbf{Method}} & \multirow[b]{2}{*}{\textbf{Input}}  & \multicolumn{2}{l}{\textbf{\ \ \ \ \ \ \ \ \ \ \ \ Complexity}} \\ \cline{3-4}
                                   &                         & \multicolumn{1}{l}{\textbf{Time}} & \multicolumn{1}{l}{\textbf{Space}}  \\ \hline
\rowcolor{gray!50}
MMSeqs2                 & Protein Sequences                        & O(N)  &  O(NL)\\ 
knnProtT5 & Protein Embeddings                        & O(N$\log$N) & O(ND) \\                                  
\rowcolor{gray!50}
MinHash                            & Raw Text & 
O(KT$^2$N)                       & O(NK) \\ 
RETSim                  & Text Embeddings                        &  O(ND)    &  O(ND)                                       \\
\rowcolor{gray!50}
The Vendiscope                  &  Any Embedding                      &  O(Nm+ND$^2$)    & O(ND)               
\end{NiceTabular}
\caption{A comparison of the complexity of various de-duplication methods for a dataset with $N$ samples. For protein sequence databases, we denote by $L$ the maximum protein sequence length. For embedding-based methods, we denote by $D$ the dimensionality of each sample's embedding. For MinHash, we denote by $K$ the number of hashing functions used, and by $T$ the maximum number of tokens in a document. For the Vendiscope, we denote by $m$ the search-range used in Algorithm \ref{alg:duplicate}. The Vendiscope has linear time and space complexity and is more general.}
\label{table:DupMethods}
\end{table}