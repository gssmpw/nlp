\section{Related Work}
\subsection{Factor Model}
Factor models are widely utilized in stock investments. The original factor model, the capital asset pricing model (CAPM) ____, attributes differences in stock returns to varying exposures to a single market factor. Later, in a seminal work ____, it was observed that firm value and size also contribute to explaining expected stock returns, and proposed the Fama-French three-factor model.
With the advancement of machine learning, some machine learning-based factor models have emerged. ____ proposed a nonlinear factor model based on neural networks to model possible interactions between different factors. ____ proposed a latent dynamic factor model using a conditional autoencoder network to capture non-linearity in return dynamics, demonstrating that the nonlinear factor model outperforms other leading linear methods. Furthermore, ____ introduced a probabilistic factor model based on variational autoencoders to better extract effective factors from the market data with high noise levels.

\subsection{Hypergraph Neural Network}
Hypergraphs have proven to be an efficient approach for modeling high-order correlations among data. ____ first introduced hypergraph learning as a propagation process on hypergraph structures. ____ further advanced this concept by developing the hypergraph convolutional neural network using deep learning methods for data representation learning. Hypergraphs have also been widely applied in the field of stock return prediction____, ____ initially applied the hypergraph neural network to learn stock price evolution based on stock relationships. Subsequently, ____ improved hypergraph neural network for stock trend prediction by incorporating ranking loss. ____ designed a concept-oriented graph framework to mine hidden concepts for stock trend forecasting. Additionally, ____ developed a dynamic hypergraph for stock selection problem using a transformer-based pretraining mechanism.

\subsection{Contrastive Learning}
This work is also related to contrastive learning , a promising class of self-supervised methods that leverage the semantic dependencies of sample pairs to capture the essence of data ____. Contrastive learning has been widely used in various applications. For instance, ____ introduced Contrastive Predictive Coding to learn useful representations for predicting future data. ____ proposed a unsupervised deep graph structure learning method based on contrastive learning. In the financial domain, ____ introduced a contrastive learning method for multi-granularity stock data and used it as a regularization term to improve stock trend prediction tasks.