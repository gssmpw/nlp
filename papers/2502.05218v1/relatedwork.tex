\section{Related Work}
\subsection{Factor Model}
Factor models are widely utilized in stock investments. The original factor model, the capital asset pricing model (CAPM) \cite{treynor1961toward, sharpe1964capital, lintner1975valuation}, attributes differences in stock returns to varying exposures to a single market factor. Later, in a seminal work \cite{eugene1992cross}, it was observed that firm value and size also contribute to explaining expected stock returns, and proposed the Fama-French three-factor model.
With the advancement of machine learning, some machine learning-based factor models have emerged. \cite{levin1995stock} proposed a nonlinear factor model based on neural networks to model possible interactions between different factors. \cite{gu2021autoencoder} proposed a latent dynamic factor model using a conditional autoencoder network to capture non-linearity in return dynamics, demonstrating that the nonlinear factor model outperforms other leading linear methods. Furthermore, \cite{duan2022factorvae} introduced a probabilistic factor model based on variational autoencoders to better extract effective factors from the market data with high noise levels.

\subsection{Hypergraph Neural Network}
Hypergraphs have proven to be an efficient approach for modeling high-order correlations among data. \cite{zhou2006learning} first introduced hypergraph learning as a propagation process on hypergraph structures. \cite{feng2019hypergraph} further advanced this concept by developing the hypergraph convolutional neural network using deep learning methods for data representation learning. Hypergraphs have also been widely applied in the field of stock return prediction\cite{li2022hypergraph, han2023stock, su2024attention}, \cite{sawhney2020spatiotemporal} initially applied the hypergraph neural network to learn stock price evolution based on stock relationships. Subsequently, \cite{sawhney2021stock} improved hypergraph neural network for stock trend prediction by incorporating ranking loss. \cite{xu2021hist} designed a concept-oriented graph framework to mine hidden concepts for stock trend forecasting. Additionally, \cite{xia2024ci} developed a dynamic hypergraph for stock selection problem using a transformer-based pretraining mechanism.

\subsection{Contrastive Learning}
This work is also related to contrastive learning , a promising class of self-supervised methods that leverage the semantic dependencies of sample pairs to capture the essence of data \cite{chen2021exploring, lin2022prototypical, li2020prototypical, caron2020unsupervised}. Contrastive learning has been widely used in various applications. For instance, \cite{oord2018representation} introduced Contrastive Predictive Coding to learn useful representations for predicting future data. \cite{liu2022towards} proposed a unsupervised deep graph structure learning method based on contrastive learning. In the financial domain, \cite{hou2021stock} introduced a contrastive learning method for multi-granularity stock data and used it as a regularization term to improve stock trend prediction tasks.