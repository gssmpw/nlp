[
  {
    "index": 0,
    "papers": [
      {
        "key": "wang2022self",
        "author": "Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny",
        "title": "Self-consistency improves chain of thought reasoning in language models"
      },
      {
        "key": "zhang2023multimodal",
        "author": "Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Zhao, Hai and Karypis, George and Smola, Alex",
        "title": "Multimodal chain-of-thought reasoning in language models"
      },
      {
        "key": "yao2023tree",
        "author": "Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik",
        "title": "Tree of thoughts: Deliberate problem solving with large language models"
      },
      {
        "key": "plaat2024reasoning",
        "author": "Plaat, Aske and Wong, Annie and Verberne, Suzan and Broekens, Joost and van Stein, Niki and Back, Thomas",
        "title": "Reasoning with large language models, a survey"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "minaee2024large",
        "author": "Minaee, Shervin and Mikolov, Tomas and Nikzad, Narjes and Chenaghlu, Meysam and Socher, Richard and Amatriain, Xavier and Gao, Jianfeng",
        "title": "Large language models: A survey"
      },
      {
        "key": "xu2024survey",
        "author": "Xu, Mengwei and Yin, Wangsong and Cai, Dongqi and Yi, Rongjie and Xu, Daliang and Wang, Qipeng and Wu, Bingyang and Zhao, Yihao and Yang, Chen and Wang, Shihe and others",
        "title": "A survey of resource-efficient llm and multimodal foundation models"
      },
      {
        "key": "morris2023levels",
        "author": "Morris, Meredith Ringel and Sohl-Dickstein, Jascha and Fiedel, Noah and Warkentin, Tris and Dafoe, Allan and Faust, Aleksandra and Farabet, Clement and Legg, Shane",
        "title": "Levels of AGI: Operationalizing Progress on the Path to AGI"
      },
      {
        "key": "feng2024far",
        "author": "Feng, Tao and Jin, Chuanyang and Liu, Jingyu and Zhu, Kunlun and Tu, Haoqin and Cheng, Zirui and Lin, Guanyu and You, Jiaxuan",
        "title": "How Far Are We From AGI"
      },
      {
        "key": "krishnan2025artificial",
        "author": "Krishnan, Vinod",
        "title": "From Artificial intelligence (AI) to Artificial General Intelligence (AGI)--the road ahead"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "jaech2024openai",
        "author": "Jaech, Aaron and Kalai, Adam and Lerer, Adam and Richardson, Adam and El-Kishky, Ahmed and Low, Aiden and Helyar, Alec and Madry, Aleksander and Beutel, Alex and Carney, Alex and others",
        "title": "Openai o1 system card"
      },
      {
        "key": "arrieta2025o3",
        "author": "Arrieta, Aitor and Ugarte, Miriam and Valle, Pablo and Parejo, Jos{\\'e} Antonio and Segura, Sergio",
        "title": "o3-mini vs DeepSeek-R1: Which One is Safer?"
      },
      {
        "key": "hurst2024gpt",
        "author": "Hurst, Aaron and Lerer, Adam and Goucher, Adam P and Perelman, Adam and Ramesh, Aditya and Clark, Aidan and Ostrow, AJ and Welihinda, Akila and Hayes, Alan and Radford, Alec and others",
        "title": "Gpt-4o system card"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "qwen2.5",
        "author": "An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu",
        "title": "Qwen2.5 Technical Report"
      },
      {
        "key": "bai2023qwen",
        "author": "Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and others",
        "title": "Qwen technical report"
      },
      {
        "key": "bai2023qwens",
        "author": "Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren",
        "title": "Qwen-vl: A frontier large vision-language model with versatile abilities"
      },
      {
        "key": "chu2024qwen2",
        "author": "Chu, Yunfei and Xu, Jin and Yang, Qian and Wei, Haojie and Wei, Xipin and Guo, Zhifang and Leng, Yichong and Lv, Yuanjun and He, Jinzheng and Lin, Junyang and others",
        "title": "Qwen2-audio technical report"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "li2024process",
        "author": "Li, Wendi and Li, Yixuan",
        "title": "Process reward model with q-value rankings"
      },
      {
        "key": "ma2023let",
        "author": "Ma, Qianli and Zhou, Haotian and Liu, Tingkai and Yuan, Jianbo and Liu, Pengfei and You, Yang and Yang, Hongxia",
        "title": "Let's reward step by step: Step-Level reward model as the Navigators for Reasoning"
      },
      {
        "key": "zhang2025lessons",
        "author": "Zhang, Zhenru and Zheng, Chujie and Wu, Yangzhen and Zhang, Beichen and Lin, Runji and Yu, Bowen and Liu, Dayiheng and Zhou, Jingren and Lin, Junyang",
        "title": "The lessons of developing process reward models in mathematical reasoning"
      },
      {
        "key": "lambert2024rewardbench",
        "author": "Lambert, Nathan and Pyatkin, Valentina and Morrison, Jacob and Miranda, LJ and Lin, Bill Yuchen and Chandu, Khyathi and Dziri, Nouha and Kumar, Sachin and Zick, Tom and Choi, Yejin and others",
        "title": "Rewardbench: Evaluating reward models for language modeling"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "deepseekai2025deepseekr1incentivizingreasoningcapability",
        "author": "DeepSeek-AI and Daya Guo and Dejian Yang and Haowei Zhang and Junxiao Song and Ruoyu Zhang and Runxin Xu and Qihao Zhu and Shirong Ma and Peiyi Wang and Xiao Bi and Xiaokang Zhang and Xingkai Yu and Yu Wu and Z. F. Wu and Zhibin Gou and Zhihong Shao and Zhuoshu Li and Ziyi Gao and Aixin Liu and Bing Xue and Bingxuan Wang and Bochao Wu and Bei Feng and Chengda Lu and Chenggang Zhao and Chengqi Deng and Chenyu Zhang and Chong Ruan and Damai Dai and Deli Chen and Dongjie Ji and Erhang Li and Fangyun Lin and Fucong Dai and Fuli Luo and Guangbo Hao and Guanting Chen and Guowei Li and H. Zhang and Han Bao and Hanwei Xu and Haocheng Wang and Honghui Ding and Huajian Xin and Huazuo Gao and Hui Qu and Hui Li and Jianzhong Guo and Jiashi Li and Jiawei Wang and Jingchang Chen and Jingyang Yuan and Junjie Qiu and Junlong Li and J. L. Cai and Jiaqi Ni and Jian Liang and Jin Chen and Kai Dong and Kai Hu and Kaige Gao and Kang Guan and Kexin Huang and Kuai Yu and Lean Wang and Lecong Zhang and Liang Zhao and Litong Wang and Liyue Zhang and Lei Xu and Leyi Xia and Mingchuan Zhang and Minghua Zhang and Minghui Tang and Meng Li and Miaojun Wang and Mingming Li and Ning Tian and Panpan Huang and Peng Zhang and Qiancheng Wang and Qinyu Chen and Qiushi Du and Ruiqi Ge and Ruisong Zhang and Ruizhe Pan and Runji Wang and R. J. Chen and R. L. Jin and Ruyi Chen and Shanghao Lu and Shangyan Zhou and Shanhuang Chen and Shengfeng Ye and Shiyu Wang and Shuiping Yu and Shunfeng Zhou and Shuting Pan and S. S. Li and Shuang Zhou and Shaoqing Wu and Shengfeng Ye and Tao Yun and Tian Pei and Tianyu Sun and T. Wang and Wangding Zeng and Wanjia Zhao and Wen Liu and Wenfeng Liang and Wenjun Gao and Wenqin Yu and Wentao Zhang and W. L. Xiao and Wei An and Xiaodong Liu and Xiaohan Wang and Xiaokang Chen and Xiaotao Nie and Xin Cheng and Xin Liu and Xin Xie and Xingchao Liu and Xinyu Yang and Xinyuan Li and Xuecheng Su and Xuheng Lin and X. Q. Li and Xiangyue Jin and Xiaojin Shen and Xiaosha Chen and Xiaowen Sun and Xiaoxiang Wang and Xinnan Song and Xinyi Zhou and Xianzu Wang and Xinxia Shan and Y. K. Li and Y. Q. Wang and Y. X. Wei and Yang Zhang and Yanhong Xu and Yao Li and Yao Zhao and Yaofeng Sun and Yaohui Wang and Yi Yu and Yichao Zhang and Yifan Shi and Yiliang Xiong and Ying He and Yishi Piao and Yisong Wang and Yixuan Tan and Yiyang Ma and Yiyuan Liu and Yongqiang Guo and Yuan Ou and Yuduan Wang and Yue Gong and Yuheng Zou and Yujia He and Yunfan Xiong and Yuxiang Luo and Yuxiang You and Yuxuan Liu and Yuyang Zhou and Y. X. Zhu and Yanhong Xu and Yanping Huang and Yaohui Li and Yi Zheng and Yuchen Zhu and Yunxian Ma and Ying Tang and Yukun Zha and Yuting Yan and Z. Z. Ren and Zehui Ren and Zhangli Sha and Zhe Fu and Zhean Xu and Zhenda Xie and Zhengyan Zhang and Zhewen Hao and Zhicheng Ma and Zhigang Yan and Zhiyu Wu and Zihui Gu and Zijia Zhu and Zijun Liu and Zilin Li and Ziwei Xie and Ziyang Song and Zizheng Pan and Zhen Huang and Zhipeng Xu and Zhongyu Zhang and Zhen Zhang",
        "title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "kimiteam2025kimik15scalingreinforcement",
        "author": "Kimi Team and Angang Du and Bofei Gao and Bowei Xing and Changjiu Jiang and Cheng Chen and Cheng Li and Chenjun Xiao and Chenzhuang Du and Chonghua Liao and Chuning Tang and Congcong Wang and Dehao Zhang and Enming Yuan and Enzhe Lu and Fengxiang Tang and Flood Sung and Guangda Wei and Guokun Lai and Haiqing Guo and Han Zhu and Hao Ding and Hao Hu and Hao Yang and Hao Zhang and Haotian Yao and Haotian Zhao and Haoyu Lu and Haoze Li and Haozhen Yu and Hongcheng Gao and Huabin Zheng and Huan Yuan and Jia Chen and Jianhang Guo and Jianlin Su and Jianzhou Wang and Jie Zhao and Jin Zhang and Jingyuan Liu and Junjie Yan and Junyan Wu and Lidong Shi and Ling Ye and Longhui Yu and Mengnan Dong and Neo Zhang and Ningchen Ma and Qiwei Pan and Qucheng Gong and Shaowei Liu and Shengling Ma and Shupeng Wei and Sihan Cao and Siying Huang and Tao Jiang and Weihao Gao and Weimin Xiong and Weiran He and Weixiao Huang and Wenhao Wu and Wenyang He and Xianghui Wei and Xianqing Jia and Xingzhe Wu and Xinran Xu and Xinxing Zu and Xinyu Zhou and Xuehai Pan and Y. Charles and Yang Li and Yangyang Hu and Yangyang Liu and Yanru Chen and Yejie Wang and Yibo Liu and Yidao Qin and Yifeng Liu and Ying Yang and Yiping Bao and Yulun Du and Yuxin Wu and Yuzhi Wang and Zaida Zhou and Zhaoji Wang and Zhaowei Li and Zhen Zhu and Zheng Zhang and Zhexu Wang and Zhilin Yang and Zhiqi Huang and Zihao Huang and Ziyao Xu and Zonghan Yang",
        "title": "Kimi k1.5: Scaling Reinforcement Learning with LLMs"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "ramesh2024group",
        "author": "Ramesh, Shyam Sundhar and Hu, Yifan and Chaimalas, Iason and Mehta, Viraj and Sessa, Pier Giuseppe and Ammar, Haitham Bou and Bogunovic, Ilija",
        "title": "Group Robust Preference Optimization in Reward-free RLHF"
      },
      {
        "key": "hu2025reinforce++",
        "author": "Hu, Jian",
        "title": "REINFORCE++: A Simple and Efficient Approach for Aligning Large Language Models"
      },
      {
        "key": "shao2024deepseekmath",
        "author": "Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Bi, Xiao and Zhang, Haowei and Zhang, Mingchuan and Li, YK and Wu, Y and others",
        "title": "Deepseekmath: Pushing the limits of mathematical reasoning in open language models"
      },
      {
        "key": "alonso2025mathematics",
        "author": "Alonso, Noguer I and others",
        "title": "The Mathematics of Group Relative Policy Optimization: A Multi-Agent Reinforcement Learning Approach"
      },
      {
        "key": "kirk2023understanding",
        "author": "Kirk, Robert and Mediratta, Ishita and Nalmpantis, Christoforos and Luketina, Jelena and Hambro, Eric and Grefenstette, Edward and Raileanu, Roberta",
        "title": "Understanding the effects of rlhf on llm generalisation and diversity"
      },
      {
        "key": "yang2024bayesian",
        "author": "Yang, Adam X and Robeyns, Maxime and Coste, Thomas and Shi, Zhengyan and Wang, Jun and Bou-Ammar, Haitham and Aitchison, Laurence",
        "title": "Bayesian reward models for LLM alignment"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "sky_t1_2025",
        "author": "NovaSky Team",
        "title": "Sky-T1: Train your own O1 preview model within \\$450"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "bespoke_stratos",
        "author": "Bespoke Labs",
        "title": "Bespoke-Stratos: The unreasonable effectiveness of reasoning distillation"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "muennighoff2025s1simpletesttimescaling",
        "author": "Niklas Muennighoff and Zitong Yang and Weijia Shi and Xiang Lisa Li and Li Fei-Fei and Hannaneh Hajishirzi and Luke Zettlemoyer and Percy Liang and Emmanuel Cand\u00e8s and Tatsunori Hashimoto",
        "title": "s1: Simple test-time scaling"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "ye2025limoreasoning",
        "author": "Yixin Ye and Zhen Huang and Yang Xiao and Ethan Chern and Shijie Xia and Pengfei Liu",
        "title": "LIMO: Less is More for Reasoning"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "chaudhari2024rlhf",
        "author": "Chaudhari, Shreyas and Aggarwal, Pranjal and Murahari, Vishvak and Rajpurohit, Tanmay and Kalyan, Ashwin and Narasimhan, Karthik and Deshpande, Ameet and da Silva, Bruno Castro",
        "title": "RLHF Deciphered: A Critical Analysis of Reinforcement Learning from Human Feedback for LLMs"
      },
      {
        "key": "kirk2023understanding",
        "author": "Kirk, Robert and Mediratta, Ishita and Nalmpantis, Christoforos and Luketina, Jelena and Hambro, Eric and Grefenstette, Edward and Raileanu, Roberta",
        "title": "Understanding the effects of rlhf on llm generalisation and diversity"
      },
      {
        "key": "kaufmann2023survey",
        "author": "Kaufmann, Timo and Weng, Paul and Bengs, Viktor and H{\\\"u}llermeier, Eyke",
        "title": "A survey of reinforcement learning from human feedback"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "engstrom2019implementation",
        "author": "Engstrom, Logan and Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Janoos, Firdaus and Rudolph, Larry and Madry, Aleksander",
        "title": "Implementation matters in deep rl: A case study on ppo and trpo"
      },
      {
        "key": "huang2022a2c",
        "author": "Huang, Shengyi and Kanervisto, Anssi and Raffin, Antonin and Wang, Weixun and Onta{\\~n}{\\'o}n, Santiago and Dossa, Rousslan Fernand Julien",
        "title": "A2C is a special case of PPO"
      },
      {
        "key": "wijmans2019dd",
        "author": "Wijmans, Erik and Kadian, Abhishek and Morcos, Ari and Lee, Stefan and Essa, Irfan and Parikh, Devi and Savva, Manolis and Batra, Dhruv",
        "title": "Dd-ppo: Learning near-perfect pointgoal navigators from 2.5 billion frames"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "wu2024beta",
        "author": "Wu, Junkang and Xie, Yuexiang and Yang, Zhengyi and Wu, Jiancan and Gao, Jinyang and Ding, Bolin and Wang, Xiang and He, Xiangnan",
        "title": "$\\beta$-DPO: Direct Preference Optimization with Dynamic $\\beta$"
      },
      {
        "key": "wu2024alpha",
        "author": "Wu, Junkang and Wang, Xue and Yang, Zhengyi and Wu, Jiancan and Gao, Jinyang and Ding, Bolin and Wang, Xiang and He, Xiangnan",
        "title": "$\\alpha$-DPO: Adaptive Reward Margin is What Direct Preference Optimization Needs"
      },
      {
        "key": "qi2024online",
        "author": "Qi, Biqing and Li, Pengfei and Li, Fangyuan and Gao, Junqi and Zhang, Kaiyan and Zhou, Bowen",
        "title": "Online DPO: Online Direct Preference Optimization with Fast-Slow Chasing"
      },
      {
        "key": "zhong2024dpo",
        "author": "Zhong, Han and Feng, Guhao and Xiong, Wei and Cheng, Xinle and Zhao, Li and He, Di and Bian, Jiang and Wang, Liwei",
        "title": "Dpo meets ppo: Reinforced token optimization for rlhf"
      },
      {
        "key": "su2025reveal",
        "author": "Su, Xuerui and Wang, Yue and Zhu, Jinhua and Yi, Mingyang and Xu, Feng and Ma, Zhiming and Liu, Yuting",
        "title": "Reveal the Mystery of DPO: The Connection between DPO and RL Algorithms"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "lai2024step",
        "author": "Lai, Xin and Tian, Zhuotao and Chen, Yukang and Yang, Senqiao and Peng, Xiangru and Jia, Jiaya",
        "title": "Step-dpo: Step-wise preference optimization for long-chain reasoning of llms"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "ethayarajh2024kto",
        "author": "Ethayarajh, Kawin and Xu, Winnie and Muennighoff, Niklas and Jurafsky, Dan and Kiela, Douwe",
        "title": "Kto: Model alignment as prospect theoretic optimization"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "meng2024simpo",
        "author": "Meng, Yu and Xia, Mengzhou and Chen, Danqi",
        "title": "Simpo: Simple preference optimization with a reference-free reward"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "ping2025longdpo",
        "author": "Ping, Bowen and Zeng, Jiali and Meng, Fandong and Wang, Shuo and Zhou, Jie and Zhang, Shanghang",
        "title": "LongDPO: Unlock Better Long-form Generation Abilities for LLMs via Critique-augmented Stepwise Information"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "li2025testtimepreferenceoptimizationonthefly",
        "author": "Yafu Li and Xuyang Hu and Xiaoye Qu and Linjie Li and Yu Cheng",
        "title": "Test-Time Preference Optimization: On-the-Fly Alignment via Iterative Textual Feedback"
      }
    ]
  }
]