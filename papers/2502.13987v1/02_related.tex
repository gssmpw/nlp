\section{Related Work}
\label{sec:related}

\paragraph{Age transformation.}
Many studies have explored controlling various facial attributes, including age, by manipulating latent variables in GANs~\cite{shen2020interpreting,wu2021stylespace,patashnik2021styleclip,parihar2022everything,huang2023adaptive,nitzan2022large,harkonen2020ganspace}.
For example, Shen et al.~\cite{shen2020interpreting} demonstrated that facial age could be edited by shifting latent variables along the normal directions of hyperplanes that separate attributes.
Huang et al.~\cite{huang2023adaptive} improved upon this by moving latent variables in multiple directions for a single attribute, enabling more natural age editing.
However, these methods allow for increasing or decreasing age but do not support specifying a precise target age.
Conversely, target age editing has been achieved within GAN-based image-to-image translation frameworks~\cite{or2020lifespan,alaluf2021only,gomez2022custom,yao2021high,DBLP:journals/vc/ItoEK23}.
Nevertheless, these GAN-based methods often struggle to preserve identity during age transformations.

Recently, diffusion models have gained significant attention, leading to the development of attribute editing methods~\cite{baumann2024continuous,kwon2022diffusion,li2023pluralistic,chen2023face}.
FADING~\cite{chen2023face} is an age editing method based on a pretrained LDM~\cite{rombach2022high}.
Specifically, it fine-tunes LDM on an age-labeled dataset to specialize the model for age editing.
During inference, the input image is embedded into the model's latent space using Null-text Inversion~\cite{mokady2023null}, and Prompt-to-Prompt~\cite{hertz2022prompt} is applied to modify only age-related regions.
However, these existing methods do not sufficiently consider individual variations in age progression and regression.

\paragraph{Personalized image synthesis.}

The task of adapting an image generative model to a specific concept is known as personalization.
Personalized image synthesis has been explored with
both GAN-based methods~\cite{roich2022pivotal,nitzan2022mystyle,qi2024my3dgen,zeng2023mystyle++} and diffusion-based methods~\cite{gal2022textual,ruiz2022dreambooth,kumari2023multi}.
Many of these approaches fine-tune pretrained models so that generated images become close to a small set of reference images.
IDP~\cite{banerjee2023identity} is a personalized age transformation method fine-tuned using self-reference images and diverse facial images~\cite{jiang2021talk}. 
However, because IDP is for generating new images but not for editing them, the composition and facial expression of the generated face image differ from those of the target person. Moreover, IDP restricts age input to predefined coarse categories (i.e., age groups). In contrast, our method can edit an existing image of the target person with integer target ages.

Concurrently, Qi et al.~\cite{DBLP:journals/corr/abs-2411-14521} proposed a personalized facial aging method. Their method is GAN-based, whereas our method is diffusion-based. Their work is a preprint at the time of our submission, and the source code is not publicly available. Direct comparison is left as future work. 