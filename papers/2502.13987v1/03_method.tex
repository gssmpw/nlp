\section{Method}
\label{chap:method}

\begin{figure*}[t]
  \centering
  \includegraphics[width=\linewidth]{fig/our_method_en2-eps-converted-to.pdf}
  \caption{
Overview of our method. In the training phase, we fine-tune a pretrained diffusion model~\cite{rombach2022high} using a refined regularization set (see Section~\ref{sec:int_age}) and self-reference images labeled with integer ages. We employ LoRA~\cite{hu2021lora} to avoid overfitting on these images (see Section~\ref{sec:lora}). In the inference phase, from input image $x$, we first obtain a latent representation $x_T$ using Null-text Inversion~\cite{mokady2023null} and apply Prompt-to-prompt~\cite{hertz2022prompt} with original age $\alpha_\mathit{in}$ and target age $\alpha_\mathit{tar}$ to generate age-edited image $y$. We carefully design the text prompts $\mathcal{P}_\mathit{ref}$, $\mathcal{P}_\mathit{reg}$, $\mathcal{P}_\mathit{in}$, and $\mathcal{P}_\mathit{tar}$ for more accurate age transformation (see Section~\ref{sec:prompt_design} and Table~\ref{tab:prompt}).
  }
  \label{fig:our_method}
\end{figure*}

Our method aims to edit a given facial image $x$ to a target age $\alpha_\mathit{tar} \in \mathbb{Z}$. 
To capture personalized characteristics and enable identity-preserving age editing, our method incorporates additional information in the form of a few (3-5) self-reference images $\mathcal{X}=\{x_1,x_2,\ldots,x_M\}$ (where $M$ is the number of images) of the same individual, which differ from $x$.

Figure~\ref{fig:our_method} illustrates an overview of our method.
Our method is based on IDP~\cite{banerjee2023identity} and fine-tunes a pretrained LDM using self-reference images and prompts $\mathcal{P}_\mathit{ref}$.
This process embeds the target individual into the generative manifold by associating it with a unique token \texttt{$\langle$token$\rangle$}.
Simultaneously, it learns human age progression and regression from a regularization set, which consists of age-labeled facial images and prompts $\mathcal{P}_\mathit{reg}$.
For fine-tuning, we employ the same loss functions as IDP~\cite{banerjee2023identity}, which are the normalized temperature-scaled cross-entropy (NT-Xent) loss and the reconstruction losses for self-reference and regularization images. 
During inference, the input image is embedded into the diffusion model's latent space using Null-text Inversion~\cite{mokady2023null}.
Subsequently, age editing is performed using Prompt-to-Prompt~\cite{hertz2022prompt}, where a pair of prompts $\mathcal{P}_\mathit{in}$ and $\mathcal{P}_\mathit{tar}$ is provided to guide the transformation.
While our method is inspired by IDP and FADING, we found that a na\"ive combination of them does not show sufficient performance, and thus we introduce further improvements into our framework. 

\begin{table*}[t]
\small
  \centering
  \caption{
Comparison of input prompts used in IDP~\cite{banerjee2023identity}, FADING~\cite{chen2023face}, and our method. 
\texttt{$\langle$token$\rangle$} represents a token associated with an individual, and \texttt{$\langle$age group$\rangle$} denotes an age category.
$\alpha_\mathit{in}$, $\alpha_\mathit{tar}$, $\alpha_\mathit{ref}$, and $\alpha_\mathit{reg}$ are integer ages of the input image, target, self-reference image, and regularization image, respectively.
Additionally, \texttt{\{person\}} is dynamically replaced based on gender, input image age, and target age to ensure proper semantic alignment.
  }
  \label{tab:prompt}
  \begin{tabular}{llll}
    \hline
    \multicolumn{1}{c}{Prompt}
    & \multicolumn{1}{c}{IDP~\cite{banerjee2023identity}}
    & \multicolumn{1}{c}{FADING~\cite{chen2023face}}
    & \multicolumn{1}{c}{Ours} \\
    \hline
    $\mathcal{P}_\mathit{ref}$ & 
    \texttt{\begin{tabular}{l}
      photo of a $\langle$token$\rangle$ person
    \end{tabular}}
    &
    \texttt{\begin{tabular}{l}
      photo of $\alpha_\mathit{ref}$ year old person
    \end{tabular}}
    &
    \texttt{\begin{tabular}{l}
      photo of $\langle$token$\rangle$ person \\ as $\alpha_\mathit{ref}$-year-old
    \end{tabular}}
    \\
    \midrule
    $\mathcal{P}_\mathit{reg}$
    & 
    \texttt{\begin{tabular}{l}
      photo of a $\langle$age group$\rangle$
    \end{tabular}}
    &
    \texttt{\begin{tabular}{l}
      (N/A)
    \end{tabular}}
    &
    \texttt{\begin{tabular}{l}
      photo of person \\ as $\alpha_\mathit{reg}$-year-old
    \end{tabular}}
    \\
    \midrule
    $\mathcal{P}_\mathit{in/tar}$
    & 
    \texttt{\begin{tabular}{l}
      photo of a $\langle$token$\rangle$ person \\ as $\langle$age group$\rangle$
    \end{tabular}}
    &
    \texttt{\begin{tabular}{l}
      photo of $\alpha_\mathit{in/tar}$ year old \{person\}
    \end{tabular}}
    &
    \texttt{\begin{tabular}{l}
      photo of $\langle$token$\rangle$ \{person\} \\ as $\alpha_\mathit{in/tar}$-year-old
    \end{tabular}}
    \\
    \hline
  \end{tabular}
\end{table*}

\subsection{Regularization Set Refinement
}
\label{sec:int_age}

IDP~\cite{banerjee2023identity} only allows age editing within predefined age groups, such as teenager or elderly, and does not support integer age specification.
This limitation arises from the regularization set used in training.
The existing regularization set consists of 612 facial images sampled from the CelebA-Dialog dataset~\cite{jiang2021talk}.
CelebA-Dialog provides age group labels, categorizing each image into six groups (\texttt{child}, \texttt{teenager}, \texttt{young adults}, \texttt{middle-aged}, \texttt{elderly}, \texttt{old}) with 102 images per group.
To overcome this limitation, our method reassigns integer age labels to the IDP regularization set using a pretrained age estimator, DEX~\cite{rothe2015dex}.
DEX is a neural network that predicts integer ages from 0 to 100 based on facial images.
By incorporating these integer labels, our method learns age transformations explicitly linked to numerical ages, enabling precise and flexible age editing for any target integer age.

Similarly to our method, FADING~\cite{chen2023face} fine-tunes a diffusion model using integer ages as supervision. Specifically, it assigns the median age of the corresponding age group as a label to 150 images sampled from the FFHQ-Aging dataset~\cite{or2020lifespan}.
In contrast, our method fine-tunes the model using a larger and more diverse set of images sampled evenly from existing age groups, with estimated integer ages as labels.
This enables our model to learn a broader and more detailed representation of age transformations.

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{fig/yearold2-eps-converted-to.pdf}
  \caption{
  Difference in cross-attention value replacement between our method and FADING~\cite{chen2023face}. Our method represents age information as ``\texttt{$\alpha$-year-old}" and replaces cross-attention values corresponding to the person-describing noun (e.g., ``\texttt{man}'' or ``\texttt{boy}'') as well as the tokens ``\texttt{$\alpha$}", ``\texttt{-}", ``\texttt{year}", ``\texttt{-}", and ``\texttt{old}". In contrast, FADING represents age information as ``\texttt{$\alpha$ year old}" and replaces cross-attention values only for the person-describing noun and the token ``\texttt{$\alpha$}".
  }
  \label{fig:yearold}
\end{figure}


\subsection{Overfitting Avoidance with LoRA
}
\label{sec:lora}
Fine-tuning the entire U-Net, as done in IDP~\cite{banerjee2023identity} and FADING~\cite{chen2023face}, can lead to overfitting on self-reference images, resulting in unnatural age transformations.
To solve this problem, our method introduces Low-Rank Adaptation (LoRA)~\cite{hu2021lora}, which trains additional adapter layers instead of fine-tuning the entire model. 
Specifically, the pretrained weight matrix $W$ of U-Net is updated as $W' = W + \Delta W$, where $\Delta W\in \mathbb{R}^{d\times d}$ represents the learned adaptation.
Here, $\Delta W$ is approximated as a low-rank decomposition, $\Delta W=AB$, where $A\in \mathbb{R}^{d\times r}$ and $B\in \mathbb{R}^{r\times d}$, with natural integers $r \ll d$.

\subsection{Prompt Design
}\label{sec:prompt_design}

\begin{table}[t]
  \centering
  \caption{
  Word replacement in the prompts for our method. The placeholder \texttt{\{person\}} is replaced based on age $\alpha$ and gender, where it is substituted with ``\texttt{man}", ``\texttt{woman}", ``\texttt{boy}", ``\texttt{girl}", ``\texttt{baby}", or ``\texttt{elderly}", as appropriate.
  }
  \label{tab:person}
  \begin{tabular}{ccc}
    \toprule
    \multirow{2}{*}{Age} & \multicolumn{2}{c}{Gender} \\
    \cmidrule(lr){2-3}
    & Male & Female \\
    \midrule
    $\alpha<5$ & \multicolumn{2}{c}{\texttt{baby}} \\
    $5\le\alpha<15$ & \texttt{boy} & \texttt{girl} \\
    $15\le\alpha<65$ & \texttt{man} & \texttt{woman} \\
    $65\le\alpha$ & \multicolumn{2}{c}{\texttt{elderly}} \\
    \bottomrule
  \end{tabular}
\end{table}

\paragraph{Modification of age representation.
}
Our method utilizes a different prompt design from IDP~\cite{banerjee2023identity} and FADING~\cite{chen2023face} to effectively incorporate the personal identity token \texttt{$\langle$token$\rangle$} learned from fine-tuning with self-reference images. 
Table~\ref{tab:prompt} compares the input prompts used in each method.
Given these formulations, a na\"ive adaptation would combine elements from both approaches.
Specifically, \texttt{$\langle$token$\rangle$} is placed before the noun phrase, and the age expression follows, connected with ``\texttt{as}''. Thus, the prompts are structured as:
$\mathcal{P}_\mathit{ref}$: ``\texttt{photo of $\langle$token$\rangle$ person}'',
$\mathcal{P}_\mathit{reg}$: ``\texttt{photo of person as $\alpha_\mathit{ref}$ year old}'', and
$\mathcal{P}_\mathit{in/tar}$: ``\texttt{photo of $\langle$token$\rangle$ \{person\} as $\alpha_\mathit{in/tar}$ year old.}''

However, we found this na\"ive approach does not achieve sufficient performance because of the inappropriate age representation in a prompt (see Section~\ref{sec:eval_yearold}). 
In IDP, the model learns age information by associating facial images with a single word token \texttt{$\langle$age group$\rangle$} during regularization.
In contrast, FADING and our method specify integer ages using a three-word phrase, ``\texttt{$\alpha$ year old.}''
Additionally, in FADING, when applying Prompt-to-Prompt during inference, only the cross-attention values corresponding to ``\texttt{$\alpha$}'' are replaced.
However, because ``\texttt{year}'' and ``\texttt{old}'' also contribute to age representation, the cross-attention replacement may not correctly perform age editing. 
To address this issue, our method modifies the age expression to ``\texttt{$\alpha$-year-old}'', connecting the words with hyphens to ensure the model interprets the entire phrase as a single cohesive token.
Furthermore, we replace the cross-attention values corresponding to ``\texttt{$\alpha$}'', ``\texttt{-}'', ``\texttt{year}'', ``\texttt{-}'', and ``\texttt{old}'' to ensure proper age modification.
Figure~\ref{fig:yearold} illustrates the difference in cross-attention value replacement between our method and FADING. Our final prompts are shown in Table~\ref{tab:prompt}. 

\paragraph{Use of self-reference image age.}
As shown in $\mathcal{P}_\mathit{ref}$ in Table~\ref{tab:prompt}, IDP~\cite{banerjee2023identity} embeds identity information into the model using self-reference images but does not utilize any age-related information from those images.
In contrast, our method explicitly incorporates the age $\alpha_\mathit{ref}$ of self-reference images into the input prompt during training.
This encourages the model to disentangle identity features and age features.
Specifically, we modify the training prompt $\mathcal{P}_\mathit{ref}$ for self-reference images as 
``\texttt{photo of $\langle$token$\rangle$ person as $\alpha_\mathit{ref}$-year-old.}''
Here, \texttt{$\langle$token$\rangle$} corresponds to identity information, while $\alpha_\mathit{ref}$-year-old explicitly encodes age information.

\paragraph{Token replacement for extreme age.
}


To provide more precise guidance for inference, FADING~\cite{chen2023face} modifies the word \texttt{\{person\}} in the inference prompt based on the input image's gender and age, replacing it with ``\texttt{man}", ``\texttt{woman}", ``\texttt{boy}", or ``\texttt{girl}" as appropriate.
Our method further refines this approach to enhance performance, particularly for extreme age transformations, such as very young or very old ages. Specifically, as shown in Table~\ref{tab:person}, we modify the editing prompt $\mathcal{P}_\mathit{in/tar}$ by changing {person} based on the target age. When the target age is below 5, {person} is replaced with ``\texttt{baby}", and when the target age is 65 or older, it is replaced with ``\texttt{elderly}".
