\begin{figure}[!t]

\centering
\includegraphics[width=\linewidth]{imgs/motivating_ex_newnewnew.png}
%\vspace{-0.7cm}
\caption{Self-attention alteration from  order-invariant models.
(a) PCW by elimination (b)
PINE by
re-assignment of position IDs 
based on
query-based pairwise ordering. In contrast, (c) RoToR minimizes the distribution mismatch by global ordering with circular assignment.}

%(1) Previous order-invariant models suffer from excessive re-assignment of positional ids of segments (S1, ... S5) with attention-based ordering. Instead, we propose to use global ordering with circular assignment. (2) Listwise inputs may contain \textbf{order-sensitive} examples on practical scenarios (MMLU), motivating the need and effectivness of MoV (Sec.~\ref{sec:mov}).}
\label{fig:intro_example}
%\vspace{0.2cm}
\end{figure}

%\begin{table}[!t]
%\centering
\begin{comment}
\resizebox{\linewidth}{!}
{
\begin{tabular}{@{}l|c|c@{}}
\toprule
 & \begin{tabular}[c]{@{}c@{}}Original\\ model\end{tabular} & \begin{tabular}[c]{@{}c@{}}Invariant \\ model\end{tabular} \\ \midrule
%1. All listwise inputs                & \textbf{68.3\%} & 64.8\%          \\
%2. On subsets without serial information & 74.3\%          & 72.2\%          \\
1. Exchangeable inputs     & 68.2\%          & \textbf{68.7\%} \\ 
2. Non-exchangeable inputs & \textbf{64.6\%}          & 60.3\%          \\
\bottomrule
\end{tabular}
}
\captionof{table}{
Initial motivating experiments at MMLU, with examples at Fig.~\ref{fig:intro_example}. Exchangeable inputs (inputs with index bias removed and doesn't have serial information) should be handled with the invariant model (PINE), while non-exchangeable inputs should be handled with the original model. %excels at exchangeable inputs (3), but naively applying them without considering confounding factors (1, 2) can lead to misinterpretations of the behavior of original and invariant models.
}
\label{table/intro_example_table}
%\end{table}
\vspace{-0.5cm}
%\end{figure}


    \begin{tabular}{@{}lcccc@{}}
\toprule
& \texttt{\#1} & \texttt{\#2} & \texttt{\#3} & \texttt{\#4} \\ \midrule
($a$) No index bias & $\times$ & $\bigcirc$ & $\times$ & $\times$ \\ \midrule
($b$) No serial dependency between contexts & $\bigcirc$ & $\bigcirc$ & $\times$ & $\times$ \\ \midrule
Ordering-invariant input? ($a$ \& $b$) & $\bigtriangleup$ & $\bigcirc$ & $\times$ & $\times$ \\ \midrule
Ordering-invariant models can be \textbf{effective} & $\bigtriangleup$ & $\bigcirc$ & $\times$ & $\times$ \\ \bottomrule
\end{tabular}

\captionof{table}{Comparing inputs \texttt{\#1-\#4} in Fig.~\ref{fig:intro_example}. We argue that a \textbf{finer definition of ordering-invariant inputs} is essential, excluding interference without ($a$) serial dependency and ($b$) index bias, for effective application of ordering-invariant models.}%(which only accounts for \texttt{\#2} in this case)
\label{table/intro_example_table}
%\end{table}
\vspace{-0.5cm}
\end{comment}