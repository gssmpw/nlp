
\begin{table}[h]
\centering
\resizebox{0.6\linewidth}{!}
{
\begin{tabular}{@{}l|cccc|cccccc@{}}
\toprule
ndoc = & \multicolumn{4}{c|}{10} & \multicolumn{6}{c}{20} \\ \midrule
gold idx = & 0 & 4 & 9 & avg. & 0 & 4 & 9 & 14 & 19 & avg. \\ \midrule
Orig. & 66.2 & 65.7 & 65.7 & 65.9 & 65.2 & 64.3 & 65.0 & 66.2 & 64.8 & 65.2 \\
PINE & 67.9 & 67.8 & 67.5 & 67.7 & 65.9 & 65.7 & 65.9 & 65.8 & 65.5 & 66.1 \\
RoToR-reranking & 68.9 & 69.0 & 68.8 & 68.9 & 67.5 & 67.5 & 67.7 & 67.5 & 67.6 & 67.8 \\
RoToR-lexical & \textbf{69.6} & \textbf{69.5} & \textbf{69.3} & \textbf{69.5} & \textbf{67.6} & \textbf{67.8} & \textbf{67.8} & \textbf{67.7} & \textbf{67.9} & \textbf{68.0} \\
\bottomrule
\end{tabular}
}
\caption{Reporting the performance with the \textbf{Llama-3.1-70B-Instruct} model on a subset of lost-in-the middle benchmark (without index bias) performance. We see that the gains are consistant with the models we mainly investigated (Llama-3.1-8B-Instruct)}
\label{table/70bresult}

\end{table}
