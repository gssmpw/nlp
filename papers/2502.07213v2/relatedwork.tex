\section{Related Works}
\label{sec:related}
Regression analyses have always been overlooked in Machine Learning field, not to mention the contempt for the streaming scenario.
Novel research on regression and prediction intervals is limited in the recent literature. 
We choose some new and commonly used algorithms as demonstration tools in this work.

One of the most famous streaming regression models is the Fast Incremental Model Tree with Drift Detection (FIMT-DD)~\cite{ref_fimtdd}. FIMT-DD incrementally constructs regression trees by splitting nodes based on variance reduction, using adaptive sliding windows to detect and respond to concept drift, ensuring timely updates to the model structure.
% The ORTO (Option-enhanced Regression Tree for Online learning)~\cite{ref_orto} algorithm is a Hoeffding-based regression tree method that incorporates decision options to improve predictive performance. By exploring multiple potential splits at decision nodes, ORTO balances accuracy and computational efficiency, enabling faster adaptation to evolving data streams.
The Adaptive Random Forest for Regression (ARF-Reg)~\cite{ref_arfreg} algorithm builds an ensemble of regression trees, leveraging online bagging with weighted resampling and drift detection mechanisms to dynamically adapt individual trees or the entire ensemble to changes in data streams. Noticeably, the based learner of ARF-Reg is typically FIRT-DD, a variant of FIMT-DD. FIRT-DD utilizes mean target values from the leaf as the final prediction instead of a model output to avoid overflow problems.
The Self-Optimising k-Nearest Leaves (SOKNL)~\cite{ref_soknl} algorithm integrates k-nearest neighbors with ARF-Reg, dynamically selecting optimal leaf nodes based on a dissimilarity measurement between centroids in the leaf and the incoming instances. It also adjusts k-values to enhance prediction accuracy on evolving data streams.
Furthermore, a sliding-window k nearest neighbours algorithm is also involved in this work due to its universal usage and surprising effectiveness. 

Recently, there are some developments in the streaming Prediction Interval aspect. Sun et al. implemented a streaming version of Mean and Variance Estimation (MVE) method and proposed a novel Adaptive Prediction Interval (AdaPI)~\cite{ref_adapi} algorithm. The Mean and Variance Estimation (MVE) algorithm is a straightforward method for constructing prediction intervals in regression tasks, operating under the assumption that predictive errors follow a Gaussian distribution. It calculates intervals centered around the predicted value, extending by a factor determined by the inverse Gaussian distribution and the standard deviation of errors. Building upon MVE, the Adaptive Prediction Interval (AdaPI) algorithm introduces a dynamic scaling coefficient that adjusts the interval width based on historical coverage. This adaptive mechanism ensures that the prediction intervals converge towards a user-defined confidence level over time, making AdaPI particularly suitable for streaming data where the underlying data distribution may evolve.