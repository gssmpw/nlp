\section{Related Work}
% Academic interest in AI risk spans multiple angles. On one end, conceptual frameworks explore high-level concerns such as alignment, emergent misalignment, and existential risks \cite{bostrom2014superintelligence, russell2019human}. On the other end, technical research addresses issues like adversarial examples \cite{goodfellow2014explaining}, interpretability \cite{lipton2018mythos}, and data distribution shift \cite{quinonero2009dataset}. Yet these efforts typically remain model-centric, focusing on the AI algorithm or dataset.

% Extensive literature exists on \emph{operational risk modelling} in finance and insurance, featuring scenario-based analyses, advanced statistical tools for heavy-tailed distributions, and the interplay of correlated events \cite{mcneil2015quantitative,embrechts2002correlation}.Reliability models are also a hallmark of risk assessment for multi-component systems, where technical methods such Markov chains and renewal processes are used to analyse risk propagation across sequential and distributed systems in order to estimate risk metrics such as time-to-failure \cite{rossstochastic}.

% We can trace attempts to unify the idea of multi-event or multi-factor risk with AI. For instance, some frameworks for AI safety mention the importance of \emph{contextual} embedding \cite{amodei2016concrete} or \emph{operational} considerations \cite{varshney2019risk}. However, these treatments often remain qualitative or do not detail the mathematics of multi-stage scenario modelling. Meanwhile, certain research in supply-chain analytics uses predictive models plus discrete-event simulation but does not focus specifically on \emph{AI risk}. 
% Despite these realities, few AI risk studies systematically incorporate established statistical risk analyses, such as Markov processes, copula-based dependence, or extreme value theory (EVT). These approaches are deeply entrenched in finance, actuarial science, and engineering reliability \cite{mcneil2015quantitative, romeijnders2014multivariate, coles2001introduction}, yet remain relatively unexplored in mainstream AI risk literature.