@misc{brown_language_2020,
	title = {Language {Models} are {Few}-{Shot} {Learners}},
	url = {http://arxiv.org/abs/2005.14165},
	abstract = {Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by ﬁne-tuning on a speciﬁc task. While typically task-agnostic in architecture, this method still requires task-speciﬁc ﬁne-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions – something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art ﬁnetuning approaches. Speciﬁcally, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or ﬁne-tuning, with tasks and few-shot demonstrations speciﬁed purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-ﬂy reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3’s few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we ﬁnd that GPT-3 can generate samples of news articles which human evaluators have difﬁculty distinguishing from articles written by humans. We discuss broader societal impacts of this ﬁnding and of GPT-3 in general.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	month = {July},
	year = {2020},
	note = {arXiv:2005.14165 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: 40+32 pages},
	file = {Brown et al. - 2020 - Language Models are Few-Shot Learners.pdf:/Users/yosephineyosephine/Zotero/storage/P2NSBE2P/Brown et al. - 2020 - Language Models are Few-Shot Learners.pdf:application/pdf},
}

@inproceedings{kabra-etal-2023-multi,
    title = {Multi-lingual and Multi-cultural Figurative Language Understanding},
    author = {Kabra, Anubha and Liu, Emmy and Khanuja, Simran and Aji, Alham Fikri and Winata, Genta and Cahyawijaya, Samuel and Aremu, Anuoluwapo and Ogayo, Perez and Neubig, Graham},
    editor = {Rogers, Anna and Boyd-Graber, Jordan and Okazaki, Naoaki},
    booktitle = {Findings of the Association for Computational Linguistics: ACL 2023},
    month = {July},
    year = {2023},
    address = {Toronto, Canada},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/2023.findings-acl.525/},
    doi = {10.18653/v1/2023.findings-acl.525},
    pages = {8269--8284}
}

@book{fujita_advances_2021,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Advances and {Trends} in {Artificial} {Intelligence}. {Artificial} {Intelligence} {Practices}: 34th {International} {Conference} on {Industrial}, {Engineering} and {Other} {Applications} of {Applied} {Intelligent} {Systems}, {IEA}/{AIE} 2021, {Kuala} {Lumpur}, {Malaysia}, {July} 26–29, 2021, {Proceedings}, {Part} {I}},
	volume = {12798},
	isbn = {978-3-030-79456-9 978-3-030-79457-6},
	shorttitle = {Advances and {Trends} in {Artificial} {Intelligence}. {Artificial} {Intelligence} {Practices}},
	url = {https://link.springer.com/10.1007/978-3-030-79457-6},
	language = {en},
	urldate = {2023-09-10},
	publisher = {Springer International Publishing},
	editor = {Fujita, Hamido and Selamat, Ali and Lin, Jerry Chun-Wei and Ali, Moonis},
	year = {2021},
	doi = {10.1007/978-3-030-79457-6},
	file = {Fujita et al. - 2021 - Advances and Trends in Artificial Intelligence. Ar.pdf:/Users/yosephineyosephine/Zotero/storage/QUWP3IWU/Fujita et al. - 2021 - Advances and Trends in Artificial Intelligence. Ar.pdf:application/pdf},
}

@misc{bang_multitask_2023,
	title = {A {Multitask}, {Multilingual}, {Multimodal} {Evaluation} of {ChatGPT} on {Reasoning}, {Hallucination}, and {Interactivity}},
	url = {http://arxiv.org/abs/2302.04023},
	abstract = {This paper proposes a framework for quantitatively evaluating interactive LLMs such as ChatGPT using publicly available data sets. We carry out an extensive technical evaluation of ChatGPT using 23 data sets covering 8 different common NLP application tasks. We evaluate the multitask, multilingual and multi-modal aspects of ChatGPT based on these data sets and a newly designed multimodal dataset. We find that ChatGPT outperforms LLMs with zero-shot learning on most tasks and even outperforms fine-tuned models on some tasks. We find that it is better at understanding non-Latin script languages than generating them. It is able to generate multimodal content from textual prompts, via an intermediate code generation step. Moreover, we find that ChatGPT is 63.41\% accurate on average in 10 different reasoning categories under logical reasoning, non-textual reasoning, and commonsense reasoning, hence making it an unreliable reasoner. It is, for example, better at deductive than inductive reasoning. ChatGPT suffers from hallucination problems like other LLMs and it generates more extrinsic hallucinations from its parametric memory as it does not have access to an external knowledge base. Finally, the interactive feature of ChatGPT enables human collaboration with the underlying LLM to improve its performance, i.e, 8\% ROUGE-1 on summarization and 2\% ChrF++ on machine translation, in a multi-turn "prompt engineering" fashion. We also release codebase for evaluation set extraction.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Bang, Yejin and Cahyawijaya, Samuel and Lee, Nayeon and Dai, Wenliang and Su, Dan and Wilie, Bryan and Lovenia, Holy and Ji, Ziwei and Yu, Tiezheng and Chung, Willy and Do, Quyet V. and Xu, Yan and Fung, Pascale},
	month = {February},
	year = {2023},
	note = {arXiv:2302.04023 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	annote = {Comment: 52 pages},
	file = {Bang et al. - 2023 - A Multitask, Multilingual, Multimodal Evaluation o.pdf:/Users/yosephineyosephine/Zotero/storage/2R4G2DZX/Bang et al. - 2023 - A Multitask, Multilingual, Multimodal Evaluation o.pdf:application/pdf},
}

@article{sai_survey_2023,
	title = {A {Survey} of {Evaluation} {Metrics} {Used} for {NLG} {Systems}},
	volume = {55},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3485766},
	doi = {10.1145/3485766},
	abstract = {In the last few years, a large number of automatic evaluation metrics have been proposed for evaluating Natural Language Generation (NLG) systems. The rapid development and adoption of such automatic evaluation metrics in a relatively short time has created the need for a survey of these metrics. In this survey, we (i) highlight the challenges in automatically evaluating NLG systems, (ii) propose a coherent taxonomy for organising existing evaluation metrics, (iii) briefly describe different existing metrics, and finally (iv) discuss studies criticising the use of automatic evaluation metrics. We then conclude the article highlighting promising future directions of research.},
	language = {en},
	number = {2},
	urldate = {2023-09-10},
	journal = {ACM Computing Surveys},
	author = {Sai, Ananya B. and Mohankumar, Akash Kumar and Khapra, Mitesh M.},
	month = {feb},
	year = {2023},
	pages = {1--39},
	file = {Sai et al. - 2023 - A Survey of Evaluation Metrics Used for NLG System.pdf:/Users/yosephineyosephine/Zotero/storage/A56JK6D8/Sai et al. - 2023 - A Survey of Evaluation Metrics Used for NLG System.pdf:application/pdf},
}

@inproceedings{poliak_survey_2020,
	address = {Online},
	title = {A {Survey} on {Recognizing} {Textual} {Entailment} as an {NLP} {Evaluation}},
	url = {https://www.aclweb.org/anthology/2020.eval4nlp-1.10},
	doi = {10.18653/v1/2020.eval4nlp-1.10},
	abstract = {Recognizing Textual Entailment (RTE) was proposed as a uniﬁed evaluation framework to compare semantic understanding of different NLP systems. In this survey paper, we provide an overview of different approaches for evaluating and understanding the reasoning capabilities of NLP systems. We then focus our discussion on RTE by highlighting prominent RTE datasets as well as advances in RTE dataset that focus on speciﬁc linguistic phenomena that can be used to evaluate NLP systems on a ﬁne-grained level. We conclude by arguing that when evaluating NLP systems, the community should utilize newly introduced RTE datasets that focus on speciﬁc linguistic phenomena.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the {First} {Workshop} on {Evaluation} and {Comparison} of {NLP} {Systems}},
	publisher = {Association for Computational Linguistics},
	author = {Poliak, Adam},
	year = {2020},
	pages = {92--109},
	file = {Poliak - 2020 - A survey on Recognizing Textual Entailment as an N.pdf:/Users/yosephineyosephine/Zotero/storage/WAMSFA75/Poliak - 2020 - A survey on Recognizing Textual Entailment as an N.pdf:application/pdf},
}

@inproceedings{zhang_active_2022,
	address = {Abu Dhabi, United Arab Emirates},
	title = {Active {Example} {Selection} for {In}-{Context} {Learning}},
	url = {https://aclanthology.org/2022.emnlp-main.622},
	doi = {10.18653/v1/2022.emnlp-main.622},
	abstract = {With a handful of demonstration examples, large-scale language models show strong capability to perform various tasks by in-context learning from these examples, without any finetuning. We demonstrate that in-context learning performance can be highly unstable across samples of examples, indicating the idiosyncrasies of how language models acquire information. We formulate example selection for in-context learning as a sequential decision problem, and propose a reinforcement learning algorithm for identifying generalizable policies to select demonstration examples. For GPT-2, our learned policies demonstrate strong abilities of generalizing to unseen tasks in training, with a 5.8\% improvement on average. Examples selected from our learned policies can even achieve a small improvement on GPT-3 Ada. However, the improvement diminishes on larger GPT-3 models, suggesting emerging capabilities of large language models.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 2022 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Zhang, Yiming and Feng, Shi and Tan, Chenhao},
	year = {2022},
	pages = {9134--9148},
	file = {Zhang et al. - 2022 - Active Example Selection for In-Context Learning.pdf:/Users/yosephineyosephine/Zotero/storage/6UBC7U6S/Zhang et al. - 2022 - Active Example Selection for In-Context Learning.pdf:application/pdf},
}

@misc{ahuja_mega_2023,
	title = {{MEGA}: {Multilingual} {Evaluation} of {Generative} {AI}},
	shorttitle = {{MEGA}},
	url = {http://arxiv.org/abs/2303.12528},
	abstract = {Generative AI models have shown impressive performance on many Natural Language Processing tasks such as language understanding, reasoning and language generation. An important question being asked by the AI community today is about the capabilities and limits of these models, and it is clear that evaluating generative AI is very challenging. Most studies on generative LLMs have been restricted to English and it is unclear how capable these models are at understanding and generating text in other languages. We present the ﬁrst comprehensive benchmarking of generative LLMs - MEGA, which evaluates models on standard NLP benchmarks, covering 16 NLP datasets across 70 typologically diverse languages. We compare the performance of generative LLMs including Chat-GPT and GPT4 to State of the Art (SOTA) non-autoregressive models on these tasks to determine how well generative models perform compared to the previous generation of LLMs. We present a thorough analysis of the performance of models across languages and tasks and discuss challenges in improving the performance of generative LLMs on low-resource languages. We create a framework for evaluating generative LLMs in the multilingual setting and provide directions for future progress in the ﬁeld.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Ahuja, Kabir and Diddee, Harshita and Hada, Rishav and Ochieng, Millicent and Ramesh, Krithika and Jain, Prachi and Nambi, Akshay and Ganu, Tanuja and Segal, Sameer and Axmed, Maxamed and Bali, Kalika and Sitaram, Sunayana},
	month = {May},
	year = {2023},
	note = {arXiv:2303.12528 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Ahuja et al. - 2023 - MEGA Multilingual Evaluation of Generative AI.pdf:/Users/yosephineyosephine/Zotero/storage/AFKBYLVC/Ahuja et al. - 2023 - MEGA Multilingual Evaluation of Generative AI.pdf:application/pdf},
}

@misc{ahuja_mega_2023-1,
	title = {{MEGA}: {Multilingual} {Evaluation} of {Generative} {AI}},
	shorttitle = {{MEGA}},
	url = {http://arxiv.org/abs/2303.12528},
	abstract = {Generative AI models have impressive performance on many Natural Language Processing tasks such as language understanding, reasoning and language generation. One of the most important questions that is being asked by the AI community today is about the capabilities and limits of these models, and it is clear that evaluating generative AI is very challenging. Most studies on generative LLMs are restricted to English and it is unclear how capable these models are at understanding and generating other languages. We present the ﬁrst comprehensive benchmarking of generative LLMs - MEGA, which evaluates models on standard NLP benchmarks, covering 8 diverse tasks and 33 typologically diverse languages. We also compare the performance of generative LLMs to State of the Art (SOTA) non-autoregressive models on these tasks to determine how well generative models perform compared to the previous generation of LLMs. We present a thorough analysis of the performance of models across languages and discuss some of the reasons why generative LLMs are currently not optimal for all languages. We create a framework for evaluating generative LLMs in the multilingual setting and provide directions for future progress in the ﬁeld.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Ahuja, Kabir and Diddee, Harshita and Hada, Rishav and Ochieng, Millicent and Ramesh, Krithika and Jain, Prachi and Nambi, Akshay and Ganu, Tanuja and Segal, Sameer and Axmed, Maxamed and Bali, Kalika and Sitaram, Sunayana},
	month = {may},
	year = {2023},
	note = {arXiv:2303.12528 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Ahuja et al. - 2023 - MEGA Multilingual Evaluation of Generative AI.pdf:/Users/yosephineyosephine/Zotero/storage/Z67WTRM5/Ahuja et al. - 2023 - MEGA Multilingual Evaluation of Generative AI.pdf:application/pdf},
}

@misc{steever_dravidian_nodate,
	title = {The {Dravidian} {Languages}},
	language = {en},
    year ={2019},
	author = {Steever, Sanford B},
	file = {Steever - The Dravidian Languages.pdf:/Users/yosephineyosephine/Zotero/storage/VPREEKWB/Steever - The Dravidian Languages.pdf:application/pdf},
}

@inproceedings{sirihattasak2018annotation,
  title={Annotation and {Classification} of {Toxicity} for {Thai} {Twitter}},
  author={Sirihattasak, Sugan and Komachi, Mamoru and Ishikawa, Hiroshi},
  booktitle={TA-COS 2018: 2nd Workshop on Text Analytics for Cybersecurity and Online Safety},
  pages={1--7},
  year={2018}
}
@article{nllb2022,
  author = {NLLB Team and Costa-juss{\`a}, Marta R and Cross, James and {\c{C}}elebi, Onur and Elbayad, Maha and Heafield, Kenneth and Heffernan, Kevin and Kalbassi, Elahe and Lam, Janice and Licht, Daniel and Maillard, Jean and Sun, Anna  and  Wang, Skyler and Wenzek, Guillaume  and Youngblood, Al  and Akula, Bapi  and  Barrault,Loic and Gonzalez, Gabriel Mejia  and Hansanti, Prangthip  and  Hoffman, John and  Jarrett, Semarley and Sadagopan, Kaushik Ram  and Rowe, Dirk  and  Spruit,Shannon and Tran, Chau  and  Andrews, Pierre and Ayan, Necip Fazil  and Bhosale, Shruti and Edunov, Sergey and Fan, Angela and Gao, Cynthia and Goswami, Vedanuj  and Guzmán, Francisco and Koehn, Philipp and Mourachko, Alexandre and Ropers, Christophe and Saleem, Safiyyah andSchwenk, Holger and Wang, Jeff},
  title = {No {Language} {Left} {Behind}: {Scaling} {Human-Centered} {Machine} {Translation}},
  journal = {-},
  year = {2022},
}


@article{manning2006local,
  title={Local {Textual} {Inference}: {It’s} {Hard} to {Circumscribe}, {But} {You} {Know} {It} {When} {You} {See} {It} -- {And} {NLP} {Needs} {It}},
  author={Manning, Christopher D},
  journal={-},
  year={2006},
}
@book{nasution70tradisi,
  title={70 Tradisi Unik Suku Bangsa di Indonesia},
  author={Nasution, Fitri Haryani},
  publisher ={Bhuana Ilmu Populer},
    address={Jakarta},
  year={2019},
}
@book{Chomsky1981-CHOLOG,
	author = {Noam Chomsky},
	editor = {},
	publisher = {Foris},
	title = {Lectures on Government and Binding},
	year = {1981}
}


@book{arka1998voice,
  title={Voice and {Grammatical} {Relations} in {Indonesian}: {A} {New} {Perspective}},
  author={Arka, I Wayan and Manning, Christopher and others},
  year={1998},
  publisher={CSLI Stanford}
}

@misc{asai_buffet_2023,
	title = {{BUFFET}: {Benchmarking} {Large} {Language} {Models} for {Few}-shot {Cross}-lingual {Transfer}},
	shorttitle = {{BUFFET}},
	url = {http://arxiv.org/abs/2305.14857},
	abstract = {Despite remarkable advancements in few-shot generalization in natural language processing, most models are developed and evaluated primarily in English. To facilitate research on few-shot cross-lingual transfer, we introduce a new benchmark, called BUFFET, which unifies 15 diverse tasks across 54 languages in a sequence-to-sequence format and provides a fixed set of few-shot examples and instructions. BUFFET is designed to establish a rigorous and equitable evaluation framework for fewshot cross-lingual transfer across a broad range of tasks and languages. Using BUFFET, we perform thorough evaluations of state-of-theart multilingual large language models with different transfer methods, namely in-context learning and fine-tuning. Our findings reveal significant room for improvement in few-shot in-context cross-lingual transfer. In particular, ChatGPT with in-context learning often performs worse than much smaller mT5-base models fine-tuned on English task data and few-shot in-language examples. Our analysis suggests various avenues for future research in few-shot cross-lingual transfer, such as improved pretraining, understanding, and future evaluations.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Asai, Akari and Kudugunta, Sneha and Yu, Xinyan Velocity and Blevins, Terra and Gonen, Hila and Reid, Machel and Tsvetkov, Yulia and Ruder, Sebastian and Hajishirzi, Hannaneh},
	month = {May},
	year = {2023},
	note = {arXiv:2305.14857 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: The data and code is available at https://buffetfs.github.io/},
	file = {Asai et al. - 2023 - BUFFET Benchmarking Large Language Models for Few.pdf:/Users/yosephineyosephine/Zotero/storage/NQT7S8UU/Asai et al. - 2023 - BUFFET Benchmarking Large Language Models for Few.pdf:application/pdf},
}

@article{linzen_assessing_2016,
	title = {Assessing the {Ability} of {LSTMs} to {Learn} {Syntax}-{Sensitive} {Dependencies}},
	volume = {4},
	issn = {2307-387X},
	url = {https://direct.mit.edu/tacl/article/43378},
	doi = {10.1162/tacl_a_00115},
	abstract = {The success of long short-term memory (LSTM) neural networks in language processing is typically attributed to their ability to capture long-distance statistical regularities. Linguistic regularities are often sensitive to syntactic structure; can such dependencies be captured by LSTMs, which do not have explicit structural representations? We begin addressing this question using number agreement in English subject-verb dependencies. We probe the architecture’s grammatical competence both using training objectives with an explicit grammatical target (number prediction, grammaticality judgments) and using language models. In the strongly supervised settings, the LSTM achieved very high overall accuracy (less than 1\% errors), but errors increased when sequential and structural information conﬂicted. The frequency of such errors rose sharply in the language-modeling setting. We conclude that LSTMs can capture a non-trivial amount of grammatical structure given targeted supervision, but stronger architectures may be required to further reduce errors; furthermore, the language modeling signal is insufﬁcient for capturing syntax-sensitive dependencies, and should be supplemented with more direct supervision if such dependencies need to be captured.},
	language = {en},
	urldate = {2023-09-10},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Linzen, Tal and Dupoux, Emmanuel and Goldberg, Yoav},
	month = {dec},
	year = {2016},
	pages = {521--535},
	file = {Linzen et al. - 2016 - Assessing the Ability of LSTMs to Learn Syntax-Sen.pdf:/Users/yosephineyosephine/Zotero/storage/WYGII4EM/Linzen et al. - 2016 - Assessing the Ability of LSTMs to Learn Syntax-Sen.pdf:application/pdf},
}

@incollection{asudeh_three_nodate,
    author ={Asudeh, Ash},
    title = {{Local} {Grammaticality} in {Syntactic} {Production}},
    booktitle = {{Language} from a {Cognitive} {Perspective} {Grammar}, {Usage}, and {Processing} {Studies} in honor of {Tom} {Wasow}},
    publisher = {CSLI publications},
    year = {2011},
}


@inproceedings{vaswani_attention_NIPS2017_3f5ee243,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {{Advances} in {Neural} {Information} {Processing} {Systems}},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is {All} {You} {Need}},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017},
}


@misc{vaswani_attention_nodate,
	title = {Attention is {All} you {Need}},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
	language = {en},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
    year={2017},
	file = {Vaswani et al. - Attention is All you Need.pdf:/Users/yosephineyosephine/Zotero/storage/KZ9J6KJE/Vaswani et al. - Attention is All you Need.pdf:application/pdf},
}
@misc{asudeh2007,
  author        = {Asudeh, Ash},
  title         = {{Three} {Kinds} of {Resumption}},
  month         = {June},
  year          = {2007},
  publisher={Carleton University},
}
@misc{nguyen_attentive_2019,
	title = {Attentive {Neural} {Network} for {Named} {Entity} {Recognition} in {Vietnamese}},
	url = {http://arxiv.org/abs/1810.13097},
	abstract = {We propose an attentive neural network for the task of named entity recognition in Vietnamese. The proposed attentive neural model makes use of character-based language models and word embeddings to encode words as vector representations. A neural network architecture of encoder, attention, and decoder layers is then utilized to encode knowledge of input sentences and to label entity tags. The experimental results show that the proposed attentive neural network achieves the state-of-the-art results on the benchmark named entity recognition datasets in Vietnamese in comparison to both hand-crafted features based models and neural models.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Nguyen, Kim Anh and Dong, Ngan and Nguyen, Cam-Tu},
	month = {June},
	year = {2019},
	note = {arXiv:1810.13097 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Nguyen et al. - 2019 - Attentive Neural Network for Named Entity Recognit.pdf:/Users/yosephineyosephine/Zotero/storage/Y68MMZ4T/Nguyen et al. - 2019 - Attentive Neural Network for Named Entity Recognit.pdf:application/pdf},
}

@misc{begus2023large,
      title={{Large} {Linguistic} {Models}: {Analyzing} {Theoretical} {Linguistic} {Abilities} of {LLMs}}, 
      author={Gasper Begus and Maksymilian Dabkowski and Ryan Rhodes},
      year={2023},
      eprint={2305.00948},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      publisher={arXiv},
      note={arXiv:2305.00948 [cs]}
}

@misc{begusa_large_nodate,
	title = {Large {Linguistic} {Models}: {Analyzing} theoretical linguistic abilities of {LLMs}},
	abstract = {The performance of large language models (LLMs) has recently improved to the point where the models can generate valid and coherent meta-linguistic analyses of data. This paper illustrates a vast potential for analyses of the meta-linguistic abilities of large language models. LLMs are primarily trained on language data in the form of text; analyzing their meta-linguistic abilities is informative both for our understanding of the general capabilities of LLMs as well as for models of linguistics. In this paper, we propose several types of experiments and prompt designs that allow us to analyze the ability of GPT-4 to generate meta-linguistic analyses. We focus on three linguistics subfields with formalisms that allow for a detailed analysis of GPT-4’s theoretical capabilities: theoretical syntax, phonology, and semantics. We identify types of experiments, provide general guidelines, discuss limitations, and offer future directions for this research program.},
	language = {en},
    year={2023},
	author = {Begu\v{s}a, Gašper and Dąbkowskia, Maksymilian and Rhodesb, Ryan},
	file = {Beguša et al. - Large Linguistic Models Analyzing theoretical lin.pdf:/Users/yosephineyosephine/Zotero/storage/X5WNDVLY/Beguša et al. - Large Linguistic Models Analyzing theoretical lin.pdf:application/pdf},
}

@misc{bai_benchmarking_2023,
	title = {Benchmarking {Foundation} {Models} with {Language}-{Model}-as-an-{Examiner}},
	url = {http://arxiv.org/abs/2306.04181},
	abstract = {Numerous benchmarks have been established to assess the performance of foundation models on open-ended question answering, which serves as a comprehensive test of a model’s ability to understand and generate language in a manner similar to humans. Most of these works focus on proposing new datasets, however, we see two main issues within previous benchmarking pipelines, namely testing leakage and evaluation automation. In this paper, we propose a novel benchmarking framework, Language-Model-as-an-Examiner, where the LM serves as a knowledgeable examiner that formulates questions based on its knowledge and evaluates responses in a reference-free manner. Our framework allows for effortless extensibility as various LMs can be adopted as the examiner, and the questions can be constantly updated given more diverse trigger topics. For a more comprehensive and equitable evaluation, we devise three strategies: (1) We instruct the LM examiner to generate questions across a multitude of domains to probe for a broad acquisition, and raise follow-up questions to engage in a more in-depth assessment. (2) Upon evaluation, the examiner combines both scoring and ranking measurements, providing a reliable result as it aligns closely with human annotations. (3) We additionally propose a decentralized Peer-examination method to address the biases in a single examiner. Our data and benchmarking results are available at: https://lmexam.com.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Bai, Yushi and Ying, Jiahao and Cao, Yixin and Lv, Xin and He, Yuze and Wang, Xiaozhi and Yu, Jifan and Zeng, Kaisheng and Xiao, Yijia and Lyu, Haozhe and Zhang, Jiayin and Li, Juanzi and Hou, Lei},
	month = {June},
	year = {2023},
	note = {arXiv:2306.04181 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: 23 pages, 8 figures},
	file = {Bai et al. - 2023 - Benchmarking Foundation Models with Language-Model.pdf:/Users/yosephineyosephine/Zotero/storage/7B6GEMSQ/Bai et al. - 2023 - Benchmarking Foundation Models with Language-Model.pdf:application/pdf},
}

@misc{zhang_benchmarking_2023,
	title = {Benchmarking {Large} {Language} {Models} for {News} {Summarization}},
	url = {http://arxiv.org/abs/2301.13848},
	abstract = {Large language models (LLMs) have shown promise for automatic summarization but the reasons behind their successes are poorly understood. By conducting a human evaluation on ten LLMs across different pretraining methods, prompts, and model scales, we make two important observations. First, we ﬁnd instruction tuning, and not model size, is the key to the LLM’s zero-shot summarization capability. Second, existing studies have been limited by low-quality references, leading to underestimates of human performance and lower few-shot and ﬁnetuning performance. To better evaluate LLMs, we perform human evaluation over high-quality summaries we collect from freelance writers. Despite major stylistic differences such as the amount of paraphrasing, we ﬁnd that LMM summaries are judged to be on par with human written summaries.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Zhang, Tianyi and Ladhak, Faisal and Durmus, Esin and Liang, Percy and McKeown, Kathleen and Hashimoto, Tatsunori B.},
	month = {Jan},
	year = {2023},
	note = {arXiv:2301.13848 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Zhang et al. - 2023 - Benchmarking Large Language Models for News Summar.pdf:/Users/yosephineyosephine/Zotero/storage/G68CRQN3/Zhang et al. - 2023 - Benchmarking Large Language Models for News Summar.pdf:application/pdf},
}

@inproceedings{devlin-etal-2019-bert,
    title = {BERT: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
    author = {Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina},
    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
    month = {June},
    year = {2019},
    address = {Minneapolis, Minnesota},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/N19-1423},
    doi = {10.18653/v1/N19-1423},
    pages = {4171--4186},
    abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
}


@misc{devlin_bert_nodate,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be ﬁnetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial taskspeciﬁc architecture modiﬁcations.},
	language = {en},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
    year={2019},
	file = {Devlin et al. - BERT Pre-training of Deep Bidirectional Transform.pdf:/Users/yosephineyosephine/Zotero/storage/X9E24LW7/Devlin et al. - BERT Pre-training of Deep Bidirectional Transform.pdf:application/pdf},
}

@article{warstadt_blimp_2020,
	title = {{BLiMP}: {The} {Benchmark} of {Linguistic} {Minimal} {Pairs} for {English}},
	volume = {8},
	issn = {2307-387X},
	shorttitle = {{BLiMP}},
	url = {https://direct.mit.edu/tacl/article/96452},
	doi = {10.1162/tacl_a_00321},
	abstract = {We introduce The Benchmark of Linguistic Minimal Pairs (BLiMP),1 a challenge set for evaluating the linguistic knowledge of language models (LMs) on major grammatical phenomena in English. BLiMP consists of 67 individual datasets, each containing 1,000 minimal pairs—that is, pairs of minimally different sentences that contrast in grammatical acceptability and isolate specific phenomenon in syntax, morphology, or semantics. We generate the data according to linguist-crafted grammar templates, and human aggregate agreement with the labels is 96.4\%. We evaluate n-gram, LSTM, and Transformer (GPT-2 and Transformer-XL) LMs by observing whether they assign a higher probability to the acceptable sentence in each minimal pair. We find that state-of-the-art models identify morphological contrasts related to agreement reliably, but they struggle with some subtle semantic and syntactic phenomena, such as negative polarity items and extraction islands.},
	language = {en},
	urldate = {2023-09-10},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Warstadt, Alex and Parrish, Alicia and Liu, Haokun and Mohananey, Anhad and Peng, Wei and Wang, Sheng-Fu and Bowman, Samuel R.},
	month = {December},
	year = {2020},
	pages = {377--392},
	file = {Warstadt et al. - 2020 - BLiMP The Benchmark of Linguistic Minimal Pairs f.pdf:/Users/yosephineyosephine/Zotero/storage/ND8JZZNR/Warstadt et al. - 2020 - BLiMP The Benchmark of Linguistic Minimal Pairs f.pdf:application/pdf},
}
@inproceedings{zhao2021calibrate,
  title={Calibrate {Before} {Use}: {Improving} {Few-shot} {Performance} of {Language} {Models}},
  author={Zhao, Zihao and Wallace, Eric and Feng, Shi and Klein, Dan and Singh, Sameer},
  booktitle={International Conference on Machine Learning},
  pages={12697--12706},
  year={2021},
  organization={PMLR}
}

@inproceedings{chiang-lee-2023-large,
    title = {Can {Large} {Language} {Models} {Be} an {Alternative} to {Human} {Evaluations?}},
    author = {Chiang, Cheng-Han  and
      Lee, Hung-yi},
    booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
    month = {July},
    year = {2023},
    address = {Toronto, Canada},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/2023.acl-long.870},
    doi = {10.18653/v1/2023.acl-long.870},
    pages = {15607--15631},
    abstract = {Human evaluation is indispensable and inevitable for assessing the quality of texts generated by machine learning models or written by humans. However, human evaluation is very difficult to reproduce and its quality is notoriously unstable, hindering fair comparisons among different natural language processing (NLP) models and algorithms.Recently, large language models (LLMs) have demonstrated exceptional performance on unseen tasks when only the task instructions are provided.In this paper, we explore if such an ability of the LLMs can be used as an alternative to human evaluation.We present the LLMs with the exact same instructions, samples to be evaluated, and questions used to conduct human evaluation, and then ask the LLMs to generate responses to those questions; we dub this LLM evaluation.We use human evaluation and LLM evaluation to evaluate the texts in two NLP tasks: open-ended story generation and adversarial attacks.We show that the result of LLM evaluation is consistent with the results obtained by expert human evaluation: the texts rated higher by human experts are also rated higher by the LLMs.We also find that the results of LLM evaluation are stable over different formatting of the task instructions and the sampling algorithm used to generate the answer.We are the first to show the potential of using LLMs to assess the quality of texts and discuss the limitations and ethical considerations of LLM evaluation.},
}


@misc{chiang_can_nodate,
	title = {Can Large Language Models Be an Alternative to Human Evaluation?},
	abstract = {Human evaluation is indispensable and inevitable for assessing the quality of texts generated by machine learning models or written by humans. However, human evaluation is very difficult to reproduce and its quality is notoriously unstable, hindering fair comparisons among different natural language processing (NLP) models and algorithms. Recently, large language models (LLMs) have demonstrated exceptional performance on unseen tasks when only the task instructions are provided. In this paper, we explore if such an ability of the LLMs can be used as an alternative to human evaluation. We present the LLMs with the exact same instructions, samples to be evaluated, and questions used to conduct human evaluation, and then ask the LLMs to generate responses to those questions; we dub this LLM evaluation. We use human evaluation and LLM evaluation to evaluate the texts in two NLP tasks: openended story generation and adversarial attacks. We show that the result of LLM evaluation is consistent with the results obtained by expert human evaluation: the texts rated higher by human experts are also rated higher by the LLMs. We also find that the results of LLM evaluation are stable over different formatting of the task instructions and the sampling algorithm used to generate the answer. We are the first to show the potential of using LLMs to assess the quality of texts and discuss the limitations and ethical considerations of LLM evaluation.},
	language = {en},
    year = {2023},
	author = {Chiang, Cheng-Han and Lee, Hung-yi},
	file = {Chiang and Lee - Can Large Language Models Be an Alternative to Hum.pdf:/Users/yosephineyosephine/Zotero/storage/9WFGJE7B/Chiang and Lee - Can Large Language Models Be an Alternative to Hum.pdf:application/pdf},
}

@inproceedings{chao_interpretation_1983,
    author = {Chao, Wynn and Sells, Peter},
    title = {On the {Interpretation} of {Resumptive} {Pronouns}},
    booktitle = {North East Linguistics Society Vol. 13},
    year = {1983}
}

@misc{lai_chatgpt_2023,
	title = {{ChatGPT} {Beyond} {English}: {Towards} a {Comprehensive} {Evaluation} of {Large} {Language} {Models} in {Multilingual} {Learning}},
	shorttitle = {{ChatGPT} {Beyond} {English}},
	url = {http://arxiv.org/abs/2304.05613},
	abstract = {Over the last few years, large language models (LLMs) have emerged as the most important breakthroughs in natural language processing (NLP) that fundamentally transform research and developments in the field. ChatGPT represents one of the most exciting LLM systems developed recently to showcase impressive skills for language generation and highly attract public attention. Among various exciting applications discovered for ChatGPT in English, the model can process and generate texts for multiple languages due to its multilingual training data. Given the broad adoption of ChatGPT for English in different problems and areas, a natural question is whether ChatGPT can also be applied effectively for other languages or it is necessary to develop more language-specific technologies. The answer to this question requires a thorough evaluation of ChatGPT over multiple tasks with diverse languages and large datasets (i.e., beyond reported anecdotes), which is still missing or limited in current research. Our work aims to fill this gap for the evaluation of ChatGPT and similar LLMs to provide more comprehensive information for multilingual NLP applications. While this work will be an ongoing effort to include additional experiments in the future, our current paper evaluates ChatGPT on 7 different tasks, covering 37 diverse languages with high, medium, low, and extremely low resources. We also focus on the zero-shot learning setting for ChatGPT to improve reproducibility and better simulate the interactions of general users. Compared to the performance of previous models, our extensive experimental results demonstrate a worse performance of ChatGPT for different NLP tasks and languages, calling for further research to develop better models and understanding for multilingual learning.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Lai, Viet Dac and Ngo, Nghia Trung and Veyseh, Amir Pouran Ben and Man, Hieu and Dernoncourt, Franck and Bui, Trung and Nguyen, Thien Huu},
	month = {April},
	year = {2023},
	note = {arXiv:2304.05613 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Lai et al. - 2023 - ChatGPT Beyond English Towards a Comprehensive Ev.pdf:/Users/yosephineyosephine/Zotero/storage/MK7WQ97F/Lai et al. - 2023 - ChatGPT Beyond English Towards a Comprehensive Ev.pdf:application/pdf},
}

@inproceedings{roemmele2011choice,
  title={Choice of {Plausible} {Alternatives}: {An} {Evaluation} of {Commonsense} {Causal} {Reasoning}},
  author={Roemmele, Melissa and Bejan, Cosmin Adrian and Gordon, Andrew S},
  booktitle={2011 AAAI Spring Symposium Series},
  year={2011},
  url={https://people.ict.usc.edu/~gordon/publications/AAAI-SPRING11A.PDF},
}

@misc{roemmele_choice_nodate,
	title = {Choice of {Plausible} {Alternatives}: {An} {Evaluation} of {Commonsense} {Causal} {Reasoning}},
	abstract = {Research in open-domain commonsense reasoning has been hindered by the lack of evaluation metrics for judging progress and comparing alternative approaches. Taking inspiration from large-scale question sets used in natural language processing research, we authored one thousand English-language questions that directly assess commonsense causal reasoning, called the Choice Of Plausible Alternatives (COPA) evaluation. Using a forcedchoice format, each question gives a premise and two plausible causes or effects, where the correct choice is the alternative that is more plausible than the other. This paper describes the authoring methodology that we used to develop a validated question set with sufficient breadth to advance open-domain commonsense reasoning research. We discuss the design decisions made during the authoring process, and explain how these decisions will affect the design of high-scoring systems. We also present the performance of multiple baseline approaches that use statistical natural language processing techniques, establishing initial benchmarks for future systems.},
	language = {en},
    year = {2011},
	author = {Roemmele, Melissa and Bejan, Cosmin Adrian and Gordon, Andrew S},
	file = {Roemmele et al. - Choice of Plausible Alternatives An Evaluation of.pdf:/Users/yosephineyosephine/Zotero/storage/W8CDQXMC/Roemmele et al. - Choice of Plausible Alternatives An Evaluation of.pdf:application/pdf},
}
@inproceedings{popovic-2017-chrf,
    title = {{ChrF}++: {Words} {Helping} {Character} n-grams},
    author = {Popovi{\'c}, Maja},
    booktitle = {Proceedings of the Second Conference on Machine Translation},
    month = {September},
    year = {2017},
    address = {Copenhagen, Denmark},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/W17-4770},
    doi = {10.18653/v1/W17-4770},
    pages = {612--618}
}

@inproceedings{popovic-2015-chrf,
    title = {{ChrF}: {Character} {n-gram} {F-score} for {Automatic} {MT} {Evaluation}},
    author = {Popovi\'c, Maja},
    booktitle = {Proceedings of the Tenth Workshop on Statistical Machine Translation},
    month = {September},
    year = {2015},
    address = {Lisbon, Portugal},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/W15-3049},
    doi = {10.18653/v1/W15-3049},
    pages = {392--395},
}

@inproceedings{rei2022comet,
  title={COMET-22: {Unbabel-IST} 2022 {Submission} for the {Metrics} {Shared} {Task}},
  author={Rei, Ricardo and De Souza, Jos{\'e} GC and Alves, Duarte and Zerva, Chrysoula and Farinha, Ana C and Glushkova, Taisiya and Lavie, Alon and Coheur, Luisa and Martins, Andr{\'e} FT},
  booktitle={Proceedings of the Seventh Conference on Machine Translation (WMT)},
  pages={578--585},
  year={2022},
}


@inproceedings{rei-etal-2022-cometkiwi,
    title = {CometKiwi: {IST-Unbabel} 2022 {Submission} for the {Quality} {Estimation} {Shared} {Task}},
    author = {Rei, Ricardo  and
      Treviso, Marcos  and
      Guerreiro, Nuno M.  and
      Zerva, Chrysoula  and
      Farinha, Ana C  and
      Maroti, Christine  and
      C. de Souza, Jos{\'e} G.  and
      Glushkova, Taisiya  and
      Alves, Duarte  and
      Coheur, Luisa  and
      Lavie, Alon  and
      Martins, Andr{\'e} F. T.},
    booktitle = {Proceedings of the Seventh Conference on Machine Translation (WMT)},
    month = {December},
    year = {2022},
    address = {Abu Dhabi, United Arab Emirates (Hybrid)},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/2022.wmt-1.60},
    pages = {634--645},
    abstract = {We present the joint contribution of IST and Unbabel to the WMT 2022 Shared Task on Quality Estimation (QE). Our team participated in all three subtasks: (i) Sentence and Word-level Quality Prediction; (ii) Explainable QE; and (iii) Critical Error Detection. For all tasks we build on top of the COMET framework, connecting it with the predictor-estimator architecture of OpenKiwi, and equipping it with a word-level sequence tagger and an explanation extractor. Our results suggest that incorporating references during pretraining improves performance across several language pairs on downstream tasks, and that jointly training with sentence and word-level objectives yields a further boost. Furthermore, combining attention and gradient information proved to be the top strategy for extracting good explanations of sentence-level QE models. Overall, our submissions achieved the best results for all three tasks for almost all language pairs by a considerable margin.},
}

@article{gellerstam1986translationese,
  title={Translationese in {Swedish} {Novels} {Translated} from {English}},
  author={Gellerstam, Martin},
  journal={Translation studies in Scandinavia},
  volume={1},
  pages={88--95},
  year={1986},
}

@misc{phatthiyaphaibun_2022_7761354,
  author       = {Wannaphong Phatthiyaphaibun},
  title        = {Thai {NER} 2.0},
  month        = {Sep},
  year         = {2022},
  publisher    = {Zenodo},
  version      = {2.0},
  doi          = {10.5281/zenodo.7761354},
  url          = {https://doi.org/10.5281/zenodo.7761354},
}
@inproceedings{luu2021large,
  title={A {Large-scale} {Dataset} for {Hate} {Speech} {Detection} on {Vietnamese} {Social} {Media} {Texts}},
  author={Luu, Son T and Nguyen, Kiet Van and Nguyen, Ngan Luu-Thuy},
  booktitle={Advances and Trends in Artificial Intelligence. Artificial Intelligence Practices: 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2021, Kuala Lumpur, Malaysia, July 26--29, 2021, Proceedings, Part I 34},
  pages={415--426},
  year={2021},
  organization={Springer},
}
@misc{bact_2019_3457447,
  author       = {Bact' and
                  Pattarawat Chormai and
                  Charin and
                  ekapolc},
  title        = {PyThaiNLP/wisesight-sentiment: First release},
  month        = {sep},
  year         = {2019},
  publisher    = {Zenodo},
  version      = {v1.0},
  doi          = {10.5281/zenodo.3457447},
  url          = {https://doi.org/10.5281/zenodo.3457447},
}
@article{cole_voice_2008,
	title = {Voice in {Malay}/{Indonesian}},
	volume = {118},
	issn = {00243841},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0024384107001490},
	doi = {10.1016/j.lingua.2007.08.008},
	language = {en},
	number = {10},
	urldate = {2023-09-10},
	journal = {Lingua},
	author = {Cole, Peter and Hermon, Gabriella and {Yanti}},
	month = {October},
	year = {2008},
	pages = {1500--1553},
	file = {Cole et al. - 2008 - Voice in MalayIndonesian.pdf:/Users/yosephineyosephine/Zotero/storage/6R8FCBLI/Cole et al. - 2008 - Voice in MalayIndonesian.pdf:application/pdf},
}

@article{cole_argument_2004,
	title = {The {Argument} {Structure} of {Verbs} with the {Suffix} - kan in {Indonesian}},
	volume = {43},
	issn = {1527-9421},
	url = {http://muse.jhu.edu/content/crossref/journals/oceanic_linguistics/v043/43.2cole.pdf},
	doi = {10.1353/ol.2005.0003},
	language = {en},
	number = {2},
	urldate = {2023-09-10},
	journal = {Oceanic Linguistics},
	author = {Cole, Peter and Son, Min-Jeong},
	year = {2004},
	pages = {339--364},
	file = {Cole and Son - 2004 - The Argument Structure of Verbs with the Suffix - .pdf:/Users/yosephineyosephine/Zotero/storage/ZUEAWQWE/Cole and Son - 2004 - The Argument Structure of Verbs with the Suffix - .pdf:application/pdf},
}

@misc{noauthor_principles_2023,
	title = {Principles and {Parameters} of {Long-Distance} {Reflexives}},
    author={},
	language = {en},
	year = {2023},
	file = {2023 - Principles and Parameters of Long-Distance Reflexi.pdf:/Users/yosephineyosephine/Zotero/storage/EASLMCKA/2023 - Principles and Parameters of Long-Distance Reflexi.pdf:application/pdf},
}

@inproceedings{rei_comet_2020,
	address = {Online},
	title = {{COMET}: {A} {Neural} {Framework} for {MT} {Evaluation}},
	shorttitle = {COMET},
	url = {https://www.aclweb.org/anthology/2020.emnlp-main.213},
	doi = {10.18653/v1/2020.emnlp-main.213},
	abstract = {We present COMET, a neural framework for training multilingual machine translation evaluation models which obtains new state-of-theart levels of correlation with human judgements. Our framework leverages recent breakthroughs in cross-lingual pretrained language modeling resulting in highly multilingual and adaptable MT evaluation models that exploit information from both the source input and a target-language reference translation in order to more accurately predict MT quality. To showcase our framework, we train three models with different types of human judgements: Direct Assessments, Human-mediated Translation Edit Rate and Multidimensional Quality Metrics. Our models achieve new state-ofthe-art performance on the WMT 2019 Metrics shared task and demonstrate robustness to high-performing systems.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 2020 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Rei, Ricardo and Stewart, Craig and Farinha, Ana C and Lavie, Alon},
	year = {2020},
	pages = {2685--2702},
	file = {Rei et al. - 2020 - COMET A Neural Framework for MT Evaluation.pdf:/Users/yosephineyosephine/Zotero/storage/QDFQ5BJ9/Rei et al. - 2020 - COMET A Neural Framework for MT Evaluation.pdf:application/pdf},
}

@misc{rei_unbabel-ist_nodate,
	title = {Unbabel-IST 2022 Submission for the Metrics Shared Task},
	abstract = {In this paper, we present the joint contribution of Unbabel and IST to the WMT 2022 Metrics Shared Task. Our primary submission –dubbed COMET-22 – is an ensemble between a COMET estimator model trained with Direct Assessments and a newly proposed multitask model trained to predict sentence-level scores along with OK/BAD word-level tags derived from Multidimensional Quality Metrics error annotations. These models are ensembled together using a hyper-parameter search that weights different features extracted from both evaluation models and combines them into a single score. For the reference-free evaluation we present COMETKIWI. Similarly to our primary submission, COMETKIWI is an ensemble between two models. A traditional predictorestimator model inspired by OPENKIWI and our new multitask model trained on Multidimensional Quality Metrics which can also be used without references. Both our submissions show improved correlations compared to stateof-the-art metrics from last year as well as increased robustness to critical errors.},
	language = {en},
    year = {2022},
	author = {Rei, Ricardo and Zerva, Chrysoula and Farinha, Ana C and Glushkova, Taisiya and Lavie, Alon and Coheur, Luisa and Martins, André F T},
	file = {Rei et al. - Unbabel-IST 2022 Submission for the Metrics Shared.pdf:/Users/yosephineyosephine/Zotero/storage/TG729S7J/Rei et al. - Unbabel-IST 2022 Submission for the Metrics Shared.pdf:application/pdf},
}

@incollection{baker_corpus_1993,
	address = {Amsterdam},
	title = {Corpus {Linguistics} and {Translation} {Studies} —- {Implications} and {Applications}},
	isbn = {978-90-272-2138-4 978-1-55619-494-8 978-90-272-8587-4},
	url = {https://benjamins.com/catalog/z.64.15bak},
	abstract = {The rise of corpus linguistics has serious implications for any discipline in which language plays a major role. This paper explores the impact that the availability of corpora is likely to have on the study of translation as an empirical phenomenon. It argues that the techniques and methodology developed in the field of corpus linguistics will have a direct impact on the emerging discipline of translation studies, particularly with respect to its theoretical and descriptive branches. The nature of this impact is discussed in some detail and brief reference is made to some of the applications of corpus techniques in the applied branch of the discipline.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Text and {Technology}},
	publisher = {John Benjamins Publishing Company},
	author = {Baker, Mona},
	editor = {Baker, Mona and Francis, Gill and Tognini-Bonelli, Elena},
	year = {1993},
	doi = {10.1075/z.64.15bak},
	pages = {233},
	file = {Baker - 1993 - Corpus Linguistics and Translation Studies — Impli.pdf:/Users/yosephineyosephine/Zotero/storage/SXTE4SLP/Baker - 1993 - Corpus Linguistics and Translation Studies — Impli.pdf:application/pdf},
}

@misc{wei_chain--thought_2023,
	title = {Chain-of-{Thought} {Prompting} {Elicits} {Reasoning} in {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2201.11903},
	abstract = {We explore how generating a chain of thought—a series of intermediate reasoning steps—signiﬁcantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufﬁciently large language models via a simple method called chain-ofthought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain-of-thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a PaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art accuracy on the GSM8K benchmark of math word problems, surpassing even ﬁnetuned GPT-3 with a veriﬁer.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
	month = {January},
	year = {2023},
	note = {arXiv:2201.11903 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in La.pdf:/Users/yosephineyosephine/Zotero/storage/7BL44IXG/Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in La.pdf:application/pdf},
}

@inproceedings{pan_cross-lingual_2017,
	address = {Vancouver, Canada},
	title = {Cross-lingual {Name} {Tagging} and {Linking} for 282 {Languages}},
	url = {http://aclweb.org/anthology/P17-1178},
	doi = {10.18653/v1/P17-1178},
	abstract = {The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able to identify name mentions, assign a coarse-grained or ﬁne-grained type to each mention, and link it to an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of new KB mining methods: generating “silver-standard” annotations by transferring annotations from English to other languages through crosslingual links and KB properties, reﬁning annotations through self-training and topic selection, deriving language-speciﬁc morphology features from anchor links, and mining word translation pairs from crosslingual links. Both name tagging and linking results for 282 languages are promising on Wikipedia data and on-Wikipedia data. All the data sets, resources and systems for 282 languages are made publicly available as a new benchmark 1.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 55th {Annual} {Meeting} of the {Association} for           {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Pan, Xiaoman and Zhang, Boliang and May, Jonathan and Nothman, Joel and Knight, Kevin and Ji, Heng},
	year = {2017},
	pages = {1946--1958},
	file = {Pan et al. - 2017 - Cross-lingual Name Tagging and Linking for 282 Lan.pdf:/Users/yosephineyosephine/Zotero/storage/8PN4S9RP/Pan et al. - 2017 - Cross-lingual Name Tagging and Linking for 282 Lan.pdf:application/pdf},
}

@inproceedings{muennighoff_crosslingual_2023,
	address = {Toronto, Canada},
	title = {Crosslingual {Generalization} through {Multitask} {Finetuning}},
	url = {https://aclanthology.org/2023.acl-long.891},
	doi = {10.18653/v1/2023.acl-long.891},
	abstract = {Multitask prompted finetuning (MTF) has been shown to help large language models generalize to new tasks in a zero-shot setting, but so far explorations of MTF have focused on English data and models. We apply MTF to the pretrained multilingual BLOOM and mT5 model families to produce finetuned variants called BLOOMZ and mT0. We find finetuning large multilingual language models on English tasks with English prompts allows for task generalization to non-English languages that appear only in the pretraining corpus. Finetuning on multilingual tasks with English prompts further improves performance on English and non-English tasks leading to various state-ofthe-art zero-shot results. We also investigate finetuning on multilingual tasks with prompts that have been machine-translated from English to match the language of each dataset. We find training on these machine-translated prompts leads to better performance on humanwritten prompts in the respective languages. Surprisingly, we find models are capable of zero-shot generalization to tasks in languages they have never intentionally seen. We conjecture that the models are learning higher-level capabilities that are both task- and languageagnostic. In addition, we introduce xP3, a composite of supervised datasets in 46 languages with English and machine-translated prompts. Our code, datasets and models are freely available at https://github.com/ bigscience-workshop/xmtf.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 61st {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Muennighoff, Niklas and Wang, Thomas and Sutawika, Lintang and Roberts, Adam and Biderman, Stella and Le Scao, Teven and Bari, M Saiful and Shen, Sheng and Yong, Zheng Xin and Schoelkopf, Hailey and Tang, Xiangru and Radev, Dragomir and Aji, Alham Fikri and Almubarak, Khalid and Albanie, Samuel and Alyafeai, Zaid and Webson, Albert and Raff, Edward and Raffel, Colin},
	year = {2022},
	pages = {15991--16111},
	file = {Muennighoff et al. - 2023 - Crosslingual Generalization through Multitask Fine.pdf:/Users/yosephineyosephine/Zotero/storage/HVMNQN93/Muennighoff et al. - 2023 - Crosslingual Generalization through Multitask Fine.pdf:application/pdf},
}

@misc{dabkowski2023large,
      title={Large {Language} {Models} and {(Non-)linguistic} {Recursion}}, 
      author={Maksymilian Dabkowski and Gasper Begus},
      year={2023},
      eprint={2306.07195},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      publisher={arXiv},
      note={arXiv:2306.07195 [cs]}
}

@misc{dabkowski_large_nodate,
	title = {Large language models and (non-)linguistic recursion},
	abstract = {Recursion is one of the hallmarks of human language. While many design features of language have been shown to exist in animal communication systems, recursion has not. Previous research shows that GPT-4 is the first large language model (LLM) to exhibit metalinguistic abilities (Beguš, Dąbkowski, and Rhodes, 2023). Here, we propose several prompt designs aimed at eliciting and analyzing recursive behavior in LLMs, both linguistic and non-linguistic. We demonstrate that when explicitly prompted, GPT-4 can both produce and analyze recursive structures. Thus, we present one of the first studies investigating whether meta-linguistic awareness of recursion—a uniquely human cognitive property—can emerge in transformers with a high number of parameters such as GPT-4.},
	language = {en},
    Year={2023},
	author = {Dąbkowski, Maksymilian and Begu\v{s}, Gašper},
	file = {Dąbkowski and Beguš - Large language models and (non-)linguistic recursi.pdf:/Users/yosephineyosephine/Zotero/storage/WMNYHNAW/Dąbkowski and Beguš - Large language models and (non-)linguistic recursi.pdf:application/pdf},
}

@misc{deshpande_toxicity_2023,
	title = {Toxicity in {ChatGPT}: {Analyzing} {Persona}-assigned {Language} {Models}},
	shorttitle = {Toxicity in {ChatGPT}},
	url = {http://arxiv.org/abs/2304.05335},
	abstract = {Large language models (LLMs) have shown incredible capabilities and transcended the natural language processing (NLP) community, with adoption throughout many services like healthcare, therapy, education, and customer service. Since users include people with critical information needs like students or patients engaging with chatbots, the safety of these systems is of prime importance. Therefore, a clear understanding of the capabilities and limitations of LLMs is necessary. To this end, we systematically evaluate toxicity in over half a million generations of CHATGPT, a popular dialogue-based LLM. We ﬁnd that setting the system parameter of CHATGPT by assigning it a persona, say that of the boxer Muhammad Ali, signiﬁcantly increases the toxicity of generations. Depending on the persona assigned to CHATGPT, its toxicity can increase up to 6×, with outputs engaging in incorrect stereo- 
    types, harmful dialogue, and hurtful opinions. This may be potentially defamatory to the persona and harmful to an unsuspecting user. Furthermore, we ﬁnd concerning patterns where speciﬁc entities (e.g., certain races) are targeted more than others (3× more) irrespective of the assigned persona, that reﬂect inherent discriminatory biases in the model. We hope that our ﬁndings inspire the broader AI community to rethink the efﬁcacy of current safety guardrails and develop better techniques that lead to robust, safe, and trustworthy AI systems.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Deshpande, Ameet and Murahari, Vishvak and Rajpurohit, Tanmay and Kalyan, Ashwin and Narasimhan, Karthik},
	month = {April},
	year = {2023},
	note = {arXiv:2304.05335 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Deshpande et al. - 2023 - Toxicity in ChatGPT Analyzing Persona-assigned La.pdf:/Users/yosephineyosephine/Zotero/storage/MX7XEPA6/Deshpande et al. - 2023 - Toxicity in ChatGPT Analyzing Persona-assigned La.pdf:application/pdf},
}

@misc{durmus_towards_2023,
	title = {Towards {Measuring} the {Representation} of {Subjective} {Global} {Opinions} in {Language} {Models}},
	url = {http://arxiv.org/abs/2306.16388},
	abstract = {Large language models (LLMs) may not equitably represent diverse global perspectives on societal issues. In this paper, we develop a quantitative framework to evaluate whose opinions model-generated responses are more similar to. We first build a dataset, GlobalOpinionQA, comprised of questions and answers from cross-national surveys designed to capture diverse opinions on global issues across different countries. Next, we define a metric that quantifies the similarity between LLM-generated survey responses and human responses, conditioned on country. With our framework, we run three experiments on an LLM trained to be helpful, honest, and harmless with Constitutional AI. By default, LLM responses tend to be more similar to the opinions of certain populations, such as those from the USA, and some European and South American countries, highlighting the potential for biases. When we prompt the model to consider a particular country’s perspective, responses shift to be more similar to the opinions of the prompted populations, but can reflect harmful cultural stereotypes. When we translate GlobalOpinionQA questions to a target language, the model’s responses do not necessarily become the most similar to the opinions of speakers of those languages. We release our dataset for others to use and build on.2 We also provide an interactive visualization at https://llmglobalvalues.anthropic.com.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Durmus, Esin and Nyugen, Karina and Liao, Thomas I. and Schiefer, Nicholas and Askell, Amanda and Bakhtin, Anton and Chen, Carol and Hatfield-Dodds, Zac and Hernandez, Danny and Joseph, Nicholas and Lovitt, Liane and McCandlish, Sam and Sikder, Orowa and Tamkin, Alex and Thamkul, Janel and Kaplan, Jared and Clark, Jack and Ganguli, Deep},
	month = {June},
	year = {2023},
	note = {arXiv:2306.16388 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Durmus et al. - 2023 - Towards Measuring the Representation of Subjective.pdf:/Users/yosephineyosephine/Zotero/storage/DIV6M4H2/Durmus et al. - 2023 - Towards Measuring the Representation of Subjective.pdf:application/pdf},
}

@misc{hoe_syntax_nodate,
	title = {{THE} {SYNTAX} {OF} {TAMIL} {PERIPHRASTIC} {CAUSATIVES}: {A} {MORPHOSEMANTIC} {EXPONENCE}},
	language = {en},
    year ={2022},
	author = {Hoe, Benjamin Pong Wai},
	file = {Hoe - THE SYNTAX OF TAMIL PERIPHRASTIC CAUSATIVES A MOR.pdf:/Users/yosephineyosephine/Zotero/storage/IRWHMQHQ/Hoe - THE SYNTAX OF TAMIL PERIPHRASTIC CAUSATIVES A MOR.pdf:application/pdf},
}

@article{engdahl_parasitic_1985,
	title = {Parasitic {Gaps}, {Resumptive} {Pronouns}, and {Subject} {Extractions}},
	volume = {23},
	issn = {0024-3949, 1613-396X},
	url = {https://www.degruyter.com/document/doi/10.1515/ling.1985.23.1.3/html},
	doi = {10.1515/ling.1985.23.1.3},
	abstract = {In this paper, two interesting predictions concerning the nature of parasitic gaps made by Chomsky (1982) are investigated. Although the exact predictions are not borne out in Scandinavian languages, the results in each case confirm Chomsky's claim that there are no specific rules in the grammar dealing with parasitic gaps but that their distribution follows from the interaction of principles of universal grammar and language-particular rules. It is proposed in the paper that resumptive pronouns license parasitic gaps in a language only if they behave syntactically as variables. The existence of parasitic subject gaps in Norwegian turns out to be a natural consequence, given that empty categories in subject position don't show standard ECP effects in this language. In the final section, it is shown how a modified version ofKayne's (1983) connectedness condition can account for the distribution of empty categories in Swedish.},
	language = {en},
	number = {1},
	urldate = {2023-09-10},
	journal = {Linguistics},
	author = {Engdahl, Elisabet},
	year = {1985},
	pages = {3--44},
	file = {Engdahl - 1985 - Parasitic gaps, resumptive pronouns, and subject e.pdf:/Users/yosephineyosephine/Zotero/storage/QR7MD2CJ/Engdahl - 1985 - Parasitic gaps, resumptive pronouns, and subject e.pdf:application/pdf},
}

@misc{espejel2023gpt35,
      title={{GPT-3.5} vs {GPT-4}: {Evaluating} {ChatGPT's} {Reasoning} {Performance} in {Zero-shot} {Learning}}, 
      author={Jessica López Espejel and El Hassane Ettifouri and Mahaman Sanoussi Yahaya Alassan and El Mehdi Chouham and Walid Dahhane},
      year={2023},
      eprint={2305.12477},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      publisher={arXiv},
      note={arXiv:2305.12477 [cs]}
}

@misc{espejel_gpt-35_nodate,
	title = {{GPT}-3.5 vs {GPT}-4: {Evaluating} {ChatGPT}'s {Reasoning} {Performance} in {Zero}-shot {Learning}},
	abstract = {Large Language Models (LLMs) have exhibited remarkable performance on various Natural Language Processing (NLP) tasks. However, there is a current hot debate regarding their reasoning capacity. In this paper, we examine the performance of GPT-3.5 and GPT-4 models, by performing a thorough technical evaluation on diﬀerent reasoning tasks across eleven distinct datasets. Our ﬁndings show that GPT-4 outperforms GPT-3.5 in zero-shot learning throughout almost all evaluated tasks. In addition, we note that both models exhibit limited performance in Inductive, Mathematical, and Multi-hop Reasoning Tasks. While it may seem intuitive that the GPT-4 model would outperform GPT-3.5 given its size and eﬃciency in various NLP tasks, our paper oﬀers empirical evidence to support this claim. We provide a detailed and comprehensive analysis of the results from both models to further support our ﬁndings. In addition, we propose a set of engineered prompts that improves performance of both models on zero-shot learning.},
	language = {en},
    year={2023},
	author = {Espejel, Jessica López and Ettifouri, El Hassane and Alassan, Mahaman Sanoussi Yahaya and Chouham, El Mehdi and Dahhane, Walid},
	file = {Espejel et al. - GPT-3.5 vs GPT-4 Evaluating ChatGPT's Reasoning P.pdf:/Users/yosephineyosephine/Zotero/storage/PVEPIQFL/Espejel et al. - GPT-3.5 vs GPT-4 Evaluating ChatGPT's Reasoning P.pdf:application/pdf},
}

@inproceedings{kryscinski_evaluating_2020,
	address = {Online},
	title = {Evaluating the {Factual} {Consistency} of {Abstractive} {Text} {Summarization}},
	url = {https://www.aclweb.org/anthology/2020.emnlp-main.750},
	doi = {10.18653/v1/2020.emnlp-main.750},
	abstract = {The most common metrics for assessing summarization algorithms do not account for whether summaries are factually consistent with source documents. We propose a weakly-supervised, model-based approach for verifying factual consistency and identifying conﬂicts between source documents and generated summaries. Training data is generated by applying a series of rule-based transformations to the sentences of source documents. The factual consistency model is then trained jointly for three tasks: 1) predict whether each summary sentence is factually consistent or not, 2) in either case, extract a span in the source document to support this consistency prediction, 3) for each summary sentence that is deemed inconsistent, extract the inconsistent span from it. Transferring this model to summaries generated by several neural models reveals that this highly scalable approach outperforms previous models, including those trained with strong supervision using datasets from related domains, such as natural language inference and fact checking. Additionally, human evaluation shows that the auxiliary span extraction tasks provide useful assistance in the process of verifying factual consistency. We also release a manually annotated dataset for factual consistency veriﬁcation, code for training data generation, and trained model weights at https://github.com/salesforce/factCC.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 2020 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Kryscinski, Wojciech and McCann, Bryan and Xiong, Caiming and Socher, Richard},
	year = {2020},
	pages = {9332--9346},
	file = {Kryscinski et al. - 2020 - Evaluating the Factual Consistency of Abstractive .pdf:/Users/yosephineyosephine/Zotero/storage/F5GU9WZ5/Kryscinski et al. - 2020 - Evaluating the Factual Consistency of Abstractive .pdf:application/pdf},
}

@misc{liu_evaluating_2023,
	title = {Evaluating the {Logical} {Reasoning} {Ability} of {ChatGPT} and {GPT}-4},
	url = {http://arxiv.org/abs/2304.03439},
	abstract = {Harnessing logical reasoning ability is a comprehensive natural language understanding endeavor. With the release of Generative Pretrained Transformer 4 (GPT-4), highlighted as "advanced" at reasoning tasks, we are eager to learn the GPT-4 performance on various logical reasoning tasks. This report analyses multiple logical reasoning datasets, with popular benchmarks like LogiQA and ReClor, and newly-released datasets like AR-LSAT. We test the multi-choice reading comprehension and natural language inference tasks with benchmarks requiring logical reasoning. We further construct a logical reasoning out-ofdistribution dataset to investigate the robustness of ChatGPT and GPT-4. We also make a performance comparison between ChatGPT and GPT-4. Experiment results show that ChatGPT performs signiﬁcantly better than the RoBERTa ﬁne-tuning method on most logical reasoning benchmarks. With early access to the GPT-4 API we are able to conduct intense experiments on the GPT-4 model. The results show GPT-4 yields even higher performance on most logical reasoning datasets. Among benchmarks, ChatGPT and GPT-4 do relatively well on well-known datasets like LogiQA and ReClor. However, the performance drops signiﬁcantly when handling newly released and out-of-distribution datasets. Logical reasoning remains challenging for ChatGPT and GPT-4, especially on outof-distribution and natural language inference datasets. We release the prompt-style logical reasoning datasets as a benchmark suite and name it LogiEval.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Liu, Hanmeng and Ning, Ruoxi and Teng, Zhiyang and Liu, Jian and Zhou, Qiji and Zhang, Yue},
	month = {May},
	year = {2023},
	note = {arXiv:2304.03439 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Liu et al. - 2023 - Evaluating the Logical Reasoning Ability of ChatGP.pdf:/Users/yosephineyosephine/Zotero/storage/55YR4QSH/Liu et al. - 2023 - Evaluating the Logical Reasoning Ability of ChatGP.pdf:application/pdf},
}

@article{freitag2021experts,
  title={Experts, {Errors}, and {Context}: {A} {Large-scale} {Study} of {Human} {Evaluation} for {Machine} {Translation}},
  author={Freitag, Markus and Foster, George and Grangier, David and Ratnakar, Viresh and Tan, Qijun and Macherey, Wolfgang},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={1460--1474},
  year={2021},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@misc{ji_exploring_2023,
	title = {Exploring {ChatGPT}'s {Ability} to {Rank} {Content}: {A} {Preliminary} {Study} on {Consistency} with {Human} {Preferences}},
	shorttitle = {Exploring {ChatGPT}'s {Ability} to {Rank} {Content}},
	url = {http://arxiv.org/abs/2303.07610},
	abstract = {As a natural language assistant, ChatGPT is capable of performing various tasks, including but not limited to article generation, code completion, and data analysis. Furthermore, ChatGPT has consistently demonstrated a remarkable level of accuracy and reliability in terms of content evaluation, exhibiting the capability of mimicking human preferences. To further explore ChatGPT’s potential in this regard, a study is conducted to assess its ability to rank content. In order to do so, a test set consisting of prompts is created, covering a wide range of use cases, and ﬁve models are utilized to generate corresponding responses. ChatGPT is then instructed to rank the responses generated by these models. The results on the test set show that ChatGPT’s ranking preferences are consistent with human to a certain extent. This preliminary experimental ﬁnding implies that ChatGPT’s zero-shot ranking capability could be used to reduce annotation pressure in a number of ranking tasks.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Ji, Yunjie and Gong, Yan and Peng, Yiping and Ni, Chao and Sun, Peiyan and Pan, Dongyu and Ma, Baochang and Li, Xiangang},
	month = {March},
	year = {2023},
	note = {arXiv:2303.07610 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Ji et al. - 2023 - Exploring ChatGPT's Ability to Rank Content A Pre.pdf:/Users/yosephineyosephine/Zotero/storage/FFMJPUR9/Ji et al. - 2023 - Exploring ChatGPT's Ability to Rank Content A Pre.pdf:application/pdf},
}

@misc{chen_exploring_2023,
	title = {Exploring the {Use} of {Large} {Language} {Models} for {Reference}-{Free} {Text} {Quality} {Evaluation}: {A} {Preliminary} {Empirical} {Study}},
	shorttitle = {Exploring the {Use} of {Large} {Language} {Models} for {Reference}-{Free} {Text} {Quality} {Evaluation}},
	url = {http://arxiv.org/abs/2304.00723},
	abstract = {Evaluating the quality of generated text is a challenging task in natural language processing. This difﬁculty arises from the inherent complexity and diversity of text. Recently, OpenAI’s ChatGPT, a powerful large language model (LLM), has garnered signiﬁcant attention due to its impressive performance in various tasks. Therefore, we present this report to investigate the effectiveness of LLMs, especially ChatGPT, and explore ways to optimize their use in assessing text quality. We compared three kinds of reference-free evaluation methods based on ChatGPT or similar LLMs. The experimental results prove that ChatGPT is capable to evaluate text quality effectively from various perspectives without reference and demonstrates superior performance than most existing automatic metrics. In particular, the Explicit Score, which utilizes ChatGPT to generate a numeric score measuring text quality, is the most effective and reliable method among the three exploited approaches. However, directly comparing the quality of two texts using ChatGPT may lead to suboptimal results. We hope this report will provide valuable insights into selecting appropriate methods for evaluating text quality with LLMs such as ChatGPT. We have released the used data1.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Chen, Yi and Wang, Rui and Jiang, Haiyun and Shi, Shuming and Xu, Ruifeng},
	month = {April},
	year = {2023},
	note = {arXiv:2304.00723 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Technical Report, 13 pages},
	file = {Chen et al. - 2023 - Exploring the Use of Large Language Models for Ref.pdf:/Users/yosephineyosephine/Zotero/storage/CC5BVL6W/Chen et al. - 2023 - Exploring the Use of Large Language Models for Ref.pdf:application/pdf},
}

@inproceedings{ramesh-etal-2023-fairness,
    title = {Fairness in {Language} {Models} {Beyond} {English}: {Gaps} and {Challenges}},
    author = {Ramesh, Krithika  and
      Sitaram, Sunayana  and
      Choudhury, Monojit},
    booktitle = {Findings of the Association for Computational Linguistics: EACL 2023},
    month = {May},
    year = {2023},
    address = {Dubrovnik, Croatia},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/2023.findings-eacl.157},
    pages = {2106--2119},
    abstract = {With language models becoming increasingly ubiquitous, it has become essential to address their inequitable treatment of diverse demographic groups and factors. Most research on evaluating and mitigating fairness harms has been concentrated on English, while multilingual models and non-English languages have received comparatively little attention. In this paper, we survey different aspects of fairness in languages beyond English and multilingual contexts. This paper presents a survey of fairness in multilingual and non-English contexts, highlighting the shortcomings of current research and the difficulties faced by methods designed for English. We contend that the multitude of diverse cultures and languages across the world makes it infeasible to achieve comprehensive coverage in terms of constructing fairness datasets. Thus, the measurement and mitigation of biases must evolve beyond the current dataset-driven practices that are narrowly focused on specific dimensions and types of biases and, therefore, impossible to scale across languages and cultures.},
}


@misc{ramesh_fairness_nodate,
	title = {Fairness in {Language} {Models} {Beyond} {English}: {Gaps} and {Challenges}},
	abstract = {With language models becoming increasingly ubiquitous, it has become essential to address their inequitable treatment of diverse demographic groups and factors. Most research on evaluating and mitigating fairness harms has been concentrated on English, while multilingual models and non-English languages have received comparatively little attention. In this paper, we survey different aspects of fairness in languages beyond English and multilingual contexts. This paper presents a survey of fairness in multilingual and non-English contexts, highlighting the shortcomings of current research and the difficulties faced by methods designed for English. We contend that the multitude of diverse cultures and languages across the world makes it infeasible to achieve comprehensive coverage in terms of constructing fairness datasets. Thus, the measurement and mitigation of biases must evolve beyond the current dataset-driven practices that are narrowly focused on specific dimensions and types of biases and, therefore, impossible to scale across languages and cultures.},
	language = {en},
	author = {Ramesh, Krithika and Sitaram, Sunayana and Choudhury, Monojit},
    year ={2023},
	file = {Ramesh et al. - Fairness in Language Models Beyond English Gaps a.pdf:/Users/yosephineyosephine/Zotero/storage/ZQM4ZKV9/Ramesh et al. - Fairness in Language Models Beyond English Gaps a.pdf:application/pdf},
}

@inproceedings{lu_fantastically_2022,
	address = {Dublin, Ireland},
	title = {Fantastically {Ordered} {Prompts} and {Where} to {Find} {Them}: {Overcoming} {Few}-{Shot} {Prompt} {Order} {Sensitivity}},
	shorttitle = {Fantastically {Ordered} {Prompts} and {Where} to {Find} {Them}},
	url = {https://aclanthology.org/2022.acl-long.556},
	doi = {10.18653/v1/2022.acl-long.556},
	abstract = {When primed with only a handful of training samples, very large, pretrained language models such as GPT-3 have shown competitive results when compared to fully-supervised, ﬁnetuned, large, pretrained language models. We demonstrate that the order in which the samples are provided can make the difference between near state-of-the-art and random guess performance: essentially some permutations are “fantastic” and some not. We analyse this phenomenon in detail, establishing that: it is present across model sizes (even for the largest current models), it is not related to a speciﬁc subset of samples, and that a given good permutation for one model is not transferable to another. While one could use a development set to determine which permutations are performant, this would deviate from the true fewshot setting as it requires additional annotated data. Instead, we use the generative nature of language models to construct an artiﬁcial development set and based on entropy statistics of the candidate permutations on this set, we identify performant prompts. Our method yields a 13\% relative improvement for GPTfamily models across eleven different established text classiﬁcation tasks.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Lu, Yao and Bartolo, Max and Moore, Alastair and Riedel, Sebastian and Stenetorp, Pontus},
	year = {2022},
	pages = {8086--8098},
	file = {Lu et al. - 2022 - Fantastically Ordered Prompts and Where to Find Th.pdf:/Users/yosephineyosephine/Zotero/storage/HQEIM2SA/Lu et al. - 2022 - Fantastically Ordered Prompts and Where to Find Th.pdf:application/pdf},
}
@article{sneddon2010indonesian,
  title={Indonesian {Reference} {Grammar}},
  author={Sneddon, James Neil and Adelaar, Alexander and Djenar, Dwi Noverini and Ewing, Michael C},
  journal={New South Wales: Allen and Unwin},
  year={2010}
}

@article{ferreira_production_2005,
    author = {Ferreira, Fernanda and Swets, Benjamin},
    year = {2005},
    month = {January},
    pages = {},
    title = {The {Production} and {Comprehension} of {Resumptive} {Pronouns} in {Relative} {Clause} ``{Island}'' {Contexts}},
    journal = {Twenty-First Century Psycholinguistics: Four Cornerstones}
}

@misc{ferreira_production_nodate,
	title = {The {Production} and {Comprehension} of {Resumptive} {Pronouns} in {Relative} {Clause} "{Island}" {Contexts}},
	language = {en},
    year = {2005},
	author = {Ferreira, Fernanda and Swets, Benjamin},
	file = {Ferreira and Swets - The Production and Comprehension of Resumptive Pro.pdf:/Users/yosephineyosephine/Zotero/storage/F7WBT482/Ferreira and Swets - The Production and Comprehension of Resumptive Pro.pdf:application/pdf},
}

@misc{kocmi_findings_nodate,
	title = {Findings of the 2022 {Conference} on {Machine} {Translation} ({WMT22})},
	abstract = {This paper presents the results of the General Machine Translation Task organised as part of the Conference on Machine Translation (WMT) 2022. In the general MT task, participants were asked to build machine translation systems for any of 11 language pairs, to be evaluated on test sets consisting of four different domains. We evaluate system outputs with human annotators using two different techniques: reference-based direct assessment and (DA) and a combination of DA and scalar quality metric (DA+SQM).},
	language = {en},
    year = {2022},
	author = {Kocmi, Tom and Bawden, Rachel and Bojar, Ondrˇej and Dvorkovich, Anton and Federmann, Christian and Fishel, Mark and Gowda, Thamme and Graham, Yvette and Grundkiewicz, Roman and Haddow, Barry and Knowles, Rebecca and Koehn, Philipp and Monz, Christof and Morishita, Makoto and Nagata, Masaaki and Nakazawa, Toshiaki and Novák, Michal and Popel, Martin and Popovic, Maja and Shmatova, Mariya},
	file = {Kocmi et al. - Findings of the 2022 Conference on Machine Transla.pdf:/Users/yosephineyosephine/Zotero/storage/GIXDX9GY/Kocmi et al. - Findings of the 2022 Conference on Machine Transla.pdf:application/pdf},
}

@inproceedings{kocmi-etal-2022-findings,
    title = {Findings of the 2022 {Conference} on {Machine} {Translation} ({WMT}22)},
    author = {Kocmi, Tom  and
      Bawden, Rachel  and
      Bojar, Ond{\v{r}}ej  and
      Dvorkovich, Anton  and
      Federmann, Christian  and
      Fishel, Mark  and
      Gowda, Thamme  and
      Graham, Yvette  and
      Grundkiewicz, Roman  and
      Haddow, Barry  and
      Knowles, Rebecca  and
      Koehn, Philipp  and
      Monz, Christof  and
      Morishita, Makoto  and
      Nagata, Masaaki  and
      Nakazawa, Toshiaki  and
      Nov{\'a}k, Michal  and
      Popel, Martin  and
      Popovi{\'c}, Maja},
    booktitle = {Proceedings of the Seventh Conference on Machine Translation (WMT)},
    month = {December},
    year = {2022},
    address = {Abu Dhabi, United Arab Emirates (Hybrid)},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/2022.wmt-1.1},
    pages = {1--45},
    abstract = {This paper presents the results of the General Machine Translation Task organised as part of the Conference on Machine Translation (WMT) 2022. In the general MT task, participants were asked to build machine translation systems for any of 11 language pairs, to be evaluated on test sets consisting of four different domains. We evaluate system outputs with human annotators using two different techniques: reference-based direct assessment and (DA) and a combination of DA and scalar quality metric (DA+SQM).},
}


@inproceedings{fortin2011we,
  title={We {Need} {LF} {Copying}: {A} {Few} {Good} {Reasons} {Why}},
  author={Fortin, Catherine Rose},
  booktitle={Proceedings of the 28th West Coast Conference on Formal Linguistics},
  pages = {87--95},
  year={2011},
  
}

@misc{liu_g-eval_2023,
	title = {G-{Eval}: {NLG} {Evaluation} {Using} {GPT}-4 with {Better} {Human} {Alignment}},
	shorttitle = {G-{Eval}},
	url = {http://arxiv.org/abs/2303.16634},
	abstract = {The quality of texts generated by natural language generation (NLG) systems is hard to measure automatically. Conventional reference-based metrics, such as BLEU and ROUGE, have been shown to have relatively low correlation with human judgments, especially for tasks that require creativity and diversity. Recent studies suggest using large language models (LLMs) as reference-free metrics for NLG evaluation, which have the beneﬁt of being applicable to new tasks that lack human references. However, these LLM-based evaluators still have lower human correspondence than medium-size neural evaluators. In this work, we present G-EVAL, a framework of using large language models with chain-ofthoughts (CoT) and a form-ﬁlling paradigm, to assess the quality of NLG outputs. We experiment with two generation tasks, text summarization and dialogue generation. We show that G-EVAL with GPT-4 as the backbone model achieves a Spearman correlation of 0.514 with human on summarization task, outperforming all previous methods by a large margin. We also propose analysis on the behavior of LLM-based evaluators, and highlight the potential concern of LLM-based evaluators having a bias towards the LLM-generated texts.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Liu, Yang and Iter, Dan and Xu, Yichong and Wang, Shuohang and Xu, Ruochen and Zhu, Chenguang},
	month = {May},
	year = {2023},
	note = {arXiv:2303.16634 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Liu et al. - 2023 - G-Eval NLG Evaluation using GPT-4 with Better Hum.pdf:/Users/yosephineyosephine/Zotero/storage/BW6BVPTY/Liu et al. - 2023 - G-Eval NLG Evaluation using GPT-4 with Better Hum.pdf:application/pdf},
}

@inproceedings{gauthier_syntaxgym_2020,
	address = {Online},
	title = {{SyntaxGym}: {An} {Online} {Platform} for {Targeted} {Evaluation} of {Language} {Models}},
	shorttitle = {{SyntaxGym}},
	url = {https://www.aclweb.org/anthology/2020.acl-demos.10},
	doi = {10.18653/v1/2020.acl-demos.10},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}: {System} {Demonstrations}},
	publisher = {Association for Computational Linguistics},
	author = {Gauthier, Jon and Hu, Jennifer and Wilcox, Ethan and Qian, Peng and Levy, Roger},
	year = {2020},
	pages = {70--76},
	file = {Gauthier et al. - 2020 - SyntaxGym An Online Platform for Targeted Evaluat.pdf:/Users/yosephineyosephine/Zotero/storage/NA3GTRTT/Gauthier et al. - 2020 - SyntaxGym An Online Platform for Targeted Evaluat.pdf:application/pdf},
}

@inproceedings{gehrmann_gem_2021,
	address = {Online},
	title = {The {GEM} {Benchmark}: {Natural} {Language} {Generation}, its {Evaluation} and {Metrics}},
	shorttitle = {The {GEM} {Benchmark}},
	url = {https://aclanthology.org/2021.gem-1.10},
	doi = {10.18653/v1/2021.gem-1.10},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 1st {Workshop} on {Natural} {Language} {Generation}, {Evaluation}, and {Metrics} ({GEM} 2021)},
	publisher = {Association for Computational Linguistics},
	author = {Gehrmann, Sebastian and Adewumi, Tosin and Aggarwal, Karmanya and Ammanamanchi, Pawan Sasanka and Aremu, Anuoluwapo and Bosselut, Antoine and Chandu, Khyathi Raghavi and Clinciu, Miruna-Adriana and Das, Dipanjan and Dhole, Kaustubh and Du, Wanyu and Durmus, Esin and Dušek, Ondřej and Emezue, Chris Chinenye and Gangal, Varun and Garbacea, Cristina and Hashimoto, Tatsunori and Hou, Yufang and Jernite, Yacine and Jhamtani, Harsh and Ji, Yangfeng and Jolly, Shailza and Kale, Mihir and Kumar, Dhruv and Ladhak, Faisal and Madaan, Aman and Maddela, Mounica and Mahajan, Khyati and Mahamood, Saad and Majumder, Bodhisattwa Prasad and Martins, Pedro Henrique and McMillan-Major, Angelina and Mille, Simon and Van Miltenburg, Emiel and Nadeem, Moin and Narayan, Shashi and Nikolaev, Vitaly and Niyongabo Rubungo, Andre and Osei, Salomey and Parikh, Ankur and Perez-Beltrachini, Laura and Rao, Niranjan Ramesh and Raunak, Vikas and Rodriguez, Juan Diego and Santhanam, Sashank and Sedoc, João and Sellam, Thibault and Shaikh, Samira and Shimorina, Anastasia and Sobrevilla Cabezudo, Marco Antonio and Strobelt, Hendrik and Subramani, Nishant and Xu, Wei and Yang, Diyi and Yerukola, Akhila and Zhou, Jiawei},
	year = {2021},
	pages = {96--120},
	file = {Gehrmann et al. - 2021 - The GEM Benchmark Natural Language Generation, it.pdf:/Users/yosephineyosephine/Zotero/storage/VUNL49LJ/Gehrmann et al. - 2021 - The GEM Benchmark Natural Language Generation, it.pdf:application/pdf},
}

@misc{openai_gpt-4_2023,
	title = {{GPT}-4 {Technical} {Report}},
	url = {http://arxiv.org/abs/2303.08774},
	abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. GPT-4 is a Transformerbased model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4’s performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {OpenAI},
	month = {March},
	year = {2023},
	note = {arXiv:2303.08774 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	annote = {Comment: 100 pages},
	file = {OpenAI - 2023 - GPT-4 Technical Report.pdf:/Users/yosephineyosephine/Zotero/storage/YEIC2DWA/OpenAI - 2023 - GPT-4 Technical Report.pdf:application/pdf},
}

@misc{wang_gpt-ner_2023,
	title = {{GPT}-{NER}: {Named} {Entity} {Recognition} via {Large} {Language} {Models}},
	shorttitle = {{GPT}-{NER}},
	url = {http://arxiv.org/abs/2304.10428},
	abstract = {Despite the fact that large-scale Language Models (LLM) have achieved SOTA performances on a variety of NLP tasks, its performance on NER is still significantly below supervised baselines. This is due to the gap between the two tasks the NER and LLMs: the former is a sequence labeling task in nature while the latter is a text-generation model. In this paper, we propose GPT-NER to resolve this issue. GPT-NER bridges the gap by transforming the sequence labeling task to a generation task that can be easily adapted by LLMs e.g., the task of finding location entities in the input text "Columbus is a city" is transformed to generate the text sequence "@@Columbus\#\# is a city", where special tokens @@\#\# marks the entity to extract. To efficiently address the "hallucination" issue of LLMs, where LLMs have a strong inclination to over-confidently label NULL inputs as entities, we propose a self-verification strategy by prompting LLMs to ask itself whether the extracted entities belong to a labeled entity tag. We conduct experiments on five widely adopted NER datasets, and GPT-NER achieves comparable performances to fully supervised baselines, which is the first time as far as we are concerned. More importantly, we find that GPT-NER exhibits a greater ability in the low-resource and few-shot setups, when the amount of training data is extremely scarce, GPT-NER performs significantly better than supervised models. This demonstrates the capabilities of GPT-NER in real-world NER applications where the number of labeled examples is limited.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Wang, Shuhe and Sun, Xiaofei and Li, Xiaoya and Ouyang, Rongbin and Wu, Fei and Zhang, Tianwei and Li, Jiwei and Wang, Guoyin},
	month = {May},
	year = {2023},
	note = {arXiv:2304.10428 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Wang et al. - 2023 - GPT-NER Named Entity Recognition via Large Langua.pdf:/Users/yosephineyosephine/Zotero/storage/NVFMMEFV/Wang et al. - 2023 - GPT-NER Named Entity Recognition via Large Langua.pdf:application/pdf},
}

@misc{naous_having_2023,
	title = {Having {Beer} after {Prayer}? {Measuring} {Cultural} {Bias} in {Large} {Language} {Models}},
	shorttitle = {Having {Beer} after {Prayer}?},
	url = {http://arxiv.org/abs/2305.14456},
	abstract = {Are language models culturally biased? It is important that language models conform to the cultural aspects of the communities they serve. However, we show in this paper that language models suffer from a significant bias towards Western culture when handling and generating text in Arabic, often preferring, and producing Western-fitting content as opposed to the relevant Arab content. We quantify this bias through a likelihood scoring-based metric using naturally occurring contexts that we collect from online social media. Our experiments reveal that both Arabic monolingual and multilingual models exhibit bias towards Western culture in eight different cultural aspects: person names, food, clothing, location, literature, beverage, religion, and sports. Models also tend to exhibit more bias when prompted with Arabic sentences that are more linguistically aligned with English. These findings raise concerns about the cultural relevance of current language models. Our analyses show that providing culture-indicating tokens or culturallyrelevant demonstrations to the model can help in debiasing.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Naous, Tarek and Ryan, Michael J. and Xu, Wei},
	month = {May},
	year = {2023},
	note = {arXiv:2305.14456 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Naous et al. - 2023 - Having Beer after Prayer Measuring Cultural Bias .pdf:/Users/yosephineyosephine/Zotero/storage/5CNS9GF9/Naous et al. - 2023 - Having Beer after Prayer Measuring Cultural Bias .pdf:application/pdf},
}

@misc{hendrycks_measuring_2021,
	title = {Measuring {Massive} {Multitask} {Language} {Understanding}},
	url = {http://arxiv.org/abs/2009.03300},
	abstract = {We propose a new test to measure a text model’s multitask accuracy. The test covers 57 tasks including elementary mathematics, US history, computer science, law, and more. To attain high accuracy on this test, models must possess extensive world knowledge and problem solving ability. We ﬁnd that while most recent models have near random-chance accuracy, the very largest GPT-3 model improves over random chance by almost 20 percentage points on average. However, on every one of the 57 tasks, the best models still need substantial improvements before they can reach expert-level accuracy. Models also have lopsided performance and frequently do not know when they are wrong. Worse, they still have nearrandom accuracy on some socially important subjects such as morality and law. By comprehensively evaluating the breadth and depth of a model’s academic and professional understanding, our test can be used to analyze models across many tasks and to identify important shortcomings.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
	month = {January},
	year = {2021},
	note = {arXiv:2009.03300 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society, Computer Science - Machine Learning},
	annote = {Comment: ICLR 2021; the test and code is available at https://github.com/hendrycks/test},
	file = {Hendrycks et al. - 2021 - Measuring Massive Multitask Language Understanding.pdf:/Users/yosephineyosephine/Zotero/storage/SFCQ5LG6/Hendrycks et al. - 2021 - Measuring Massive Multitask Language Understanding.pdf:application/pdf},
}

@inproceedings{hershcovich_challenges_2022,
	address = {Dublin, Ireland},
	title = {Challenges and {Strategies} in {Cross}-{Cultural} {NLP}},
	url = {https://aclanthology.org/2022.acl-long.482},
	doi = {10.18653/v1/2022.acl-long.482},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Hershcovich, Daniel and Frank, Stella and Lent, Heather and De Lhoneux, Miryam and Abdou, Mostafa and Brandl, Stephanie and Bugliarello, Emanuele and Cabello Piqueras, Laura and Chalkidis, Ilias and Cui, Ruixiang and Fierro, Constanza and Margatina, Katerina and Rust, Phillip and Søgaard, Anders},
	year = {2022},
	pages = {6997--7013},
	file = {Hershcovich et al. - 2022 - Challenges and Strategies in Cross-Cultural NLP.pdf:/Users/yosephineyosephine/Zotero/storage/JV9UKFA5/Hershcovich et al. - 2022 - Challenges and Strategies in Cross-Cultural NLP.pdf:application/pdf},
}

@misc{hendy_how_2023,
	title = {How {Good} {Are} {GPT} {Models} at {Machine} {Translation}? {A} {Comprehensive} {Evaluation}},
	shorttitle = {How {Good} {Are} {GPT} {Models} at {Machine} {Translation}?},
	url = {http://arxiv.org/abs/2302.09210},
	abstract = {Generative Pre-trained Transformer (GPT) models have shown remarkable capabilities for natural language generation, but their performance for machine translation has not been thoroughly investigated. In this paper, we present a comprehensive evaluation of GPT models for machine translation, covering various aspects such as quality of different GPT models in comparison with stateof-the-art research and commercial systems, effect of prompting strategies, robustness towards domain shifts and document-level translation. We experiment with eighteen different translation directions involving high and low resource languages, as well as non English-centric translations, and evaluate the performance of three GPT models: ChatGPT, GPT3.5 (text-davinci-003), and text-davinci002. Our results show that GPT models achieve very competitive translation quality for high resource languages, while having limited capabilities for low resource languages. We also show that hybrid approaches, which combine GPT models with other translation systems, can further enhance the translation quality. We perform comprehensive analysis and human evaluation to further understand the characteristics of GPT translations. We hope that our paper provides valuable insights for researchers and practitioners in the ﬁeld and helps to better understand the potential and limitations of GPT models for translation.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Hendy, Amr and Abdelrehim, Mohamed and Sharaf, Amr and Raunak, Vikas and Gabr, Mohamed and Matsushita, Hitokazu and Kim, Young Jin and Afify, Mohamed and Awadalla, Hany Hassan},
	month = {February},
	year = {2023},
	note = {arXiv:2302.09210 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Hendy et al. - 2023 - How Good Are GPT Models at Machine Translation A .pdf:/Users/yosephineyosephine/Zotero/storage/P48D5SJB/Hendy et al. - 2023 - How Good Are GPT Models at Machine Translation A .pdf:application/pdf},
}

@misc{hu_prompt-based_2023,
	title = {Prompt-based {Methods} {May} {Underestimate} {Large} {Language} {Models'} {Linguistic} {Generalizations}},
	url = {http://arxiv.org/abs/2305.13264},
	abstract = {Prompting is now a dominant method for evaluating the linguistic knowledge of large language models (LLMs). While other methods directly read out models’ probability distributions over strings, prompting requires models to access this internal information by processing linguistic input, thereby implicitly testing a new type of emergent ability: metalinguistic judgment. In this study, we compare metalinguistic prompting and direct probability measurements as ways of measuring models’ knowledge of English. Broadly, we ﬁnd that LLMs’ metalinguistic judgments are inferior to quantities directly derived from representations. Furthermore, consistency gets worse as the prompt diverges from direct measurements of next-word probabilities. Our ﬁndings suggest that negative results relying on metalinguistic prompts cannot be taken as conclusive evidence that an LLM lacks a particular linguistic competence. Our results also highlight the lost value with the move to closed APIs where access to probability distributions is limited.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Hu, Jennifer and Levy, Roger},
	month = {May},
	year = {2023},
	note = {arXiv:2305.13264 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Hu and Levy - 2023 - Prompt-based methods may underestimate large langu.pdf:/Users/yosephineyosephine/Zotero/storage/UE9Q8BD2/Hu and Levy - 2023 - Prompt-based methods may underestimate large langu.pdf:application/pdf},
}

@inproceedings{hu_systematic_2020,
	address = {Online},
	title = {A {Systematic} {Assessment} of {Syntactic} {Generalization} in {Neural} {Language} {Models}},
	url = {https://www.aclweb.org/anthology/2020.acl-main.158},
	doi = {10.18653/v1/2020.acl-main.158},
	abstract = {While state-of-the-art neural network models continue to achieve lower perplexity scores on language modeling benchmarks, it remains unknown whether optimizing for broad-coverage predictive performance leads to human-like syntactic knowledge. Furthermore, existing work has not provided a clear picture about the model properties required to produce proper syntactic generalizations. We present a systematic evaluation of the syntactic knowledge of neural language models, testing 20 combinations of model types and data sizes on a set of 34 English-language syntactic test suites. We ﬁnd substantial differences in syntactic generalization performance by model architecture, with sequential models underperforming other architectures. Factorially manipulating model architecture and training dataset size (1M–40M words), we ﬁnd that variability in syntactic generalization performance is substantially greater by architecture than by dataset size for the corpora tested in our experiments. Our results also reveal a dissociation between perplexity and syntactic generalization performance.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Hu, Jennifer and Gauthier, Jon and Qian, Peng and Wilcox, Ethan and Levy, Roger},
	year = {2020},
	pages = {1725--1744},
	file = {Hu et al. - 2020 - A Systematic Assessment of Syntactic Generalizatio.pdf:/Users/yosephineyosephine/Zotero/storage/TBP73B66/Hu et al. - 2020 - A Systematic Assessment of Syntactic Generalizatio.pdf:application/pdf},
}

@misc{hu_expectations_2023,
	title = {Expectations over {Unspoken} {Alternatives} {Predict} {Pragmatic} {Inferences}},
	url = {http://arxiv.org/abs/2304.04758},
	abstract = {Scalar inferences (SI) are a signature example of how humans interpret language based on unspoken alternatives. While empirical studies have demonstrated that human SI rates are highly variable – both within instances of a single scale, and across different scales – there have been few proposals that quantitatively explain both crossand within-scale variation. Furthermore, while it is generally assumed that SIs arise through reasoning about unspoken alternatives, it remains debated whether humans reason about alternatives as linguistic forms, or at the level of concepts. Here, we test a shared mechanism explaining SI rates within and across scales: context-driven expectations about the unspoken alternatives. Using neural language models to approximate human predictive distributions, we ﬁnd that SI rates are captured by the expectedness of the strong scalemate as an alternative. Crucially, however, expectedness robustly predicts cross-scale variation only under a meaning-based view of alternatives. Our results suggest that pragmatic inferences arise from context-driven expectations over alternatives, and these expectations operate at the level of concepts.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Hu, Jennifer and Levy, Roger and Degen, Judith and Schuster, Sebastian},
	month = {April},
	year = {2023},
	note = {arXiv:2304.04758 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: To appear in TACL (pre-MIT Press publication version)},
	file = {Hu et al. - 2023 - Expectations over Unspoken Alternatives Predict Pr.pdf:/Users/yosephineyosephine/Zotero/storage/DQVHPLZE/Hu et al. - 2023 - Expectations over Unspoken Alternatives Predict Pr.pdf:application/pdf},
}

@misc{shen_hugginggpt_2023,
	title = {{HuggingGPT}: {Solving} {AI} {Tasks} with {ChatGPT} and its {Friends} in {Hugging} {Face}},
	shorttitle = {HuggingGPT},
	url = {http://arxiv.org/abs/2303.17580},
	abstract = {Solving complicated AI tasks with different domains and modalities is a key step toward advanced artiﬁcial intelligence. While there are abundant AI models available for different domains and modalities, they cannot handle complicated AI tasks. Considering large language models (LLMs) have exhibited exceptional ability in language understanding, generation, interaction, and reasoning, we advocate that LLMs could act as a controller to manage existing AI models to solve complicated AI tasks and language could be a generic interface to empower this. Based on this philosophy, we present HuggingGPT, a framework that leverages LLMs (e.g., ChatGPT) to connect various AI models in machine learning communities (e.g., Hugging Face) to solve AI tasks. Speciﬁcally, we use ChatGPT to conduct task planning when receiving a user request, select models according to their function descriptions available in Hugging Face, execute each subtask with the selected AI model, and summarize the response according to the execution results. By leveraging the strong language capability of ChatGPT and abundant AI models in Hugging Face, HuggingGPT is able to cover numerous sophisticated AI tasks in different modalities and domains and achieve impressive results in language, vision, speech, and other challenging tasks, which paves a new way towards advanced artiﬁcial intelligence 2.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Shen, Yongliang and Song, Kaitao and Tan, Xu and Li, Dongsheng and Lu, Weiming and Zhuang, Yueting},
	month = may,
	year = {2023},
	note = {arXiv:2303.17580 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {Shen et al. - 2023 - HuggingGPT Solving AI Tasks with ChatGPT and its .pdf:/Users/yosephineyosephine/Zotero/storage/ESQNQ948/Shen et al. - 2023 - HuggingGPT Solving AI Tasks with ChatGPT and its .pdf:application/pdf},
}

@inproceedings{aggarwal-etal-2022-indicxnli,
    title = {Indic {XNLI}: {Evaluating} {Multilingual} {Inference} for {Indian} {Languages}},
    author = {Aggarwal, Divyanshu  and
      Gupta, Vivek  and
      Kunchukuttan, Anoop},
    booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
    month = {December},
    year = {2022},
    address = {Abu Dhabi, United Arab Emirate},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/2022.emnlp-main.755},
    doi = {10.18653/v1/2022.emnlp-main.755},
    pages = {10994--11006},
    abstract = {While Indic NLP has made rapid advances recently in terms of the availability of corpora and pre-trained models, benchmark datasets on standard NLU tasks are limited. To this end, we introduce INDICXNLI, an NLI dataset for 11 Indic languages. It has been created by high-quality machine translation of the original English XNLI dataset and our analysis attests to the quality of INDICXNLI. By finetuning different pre-trained LMs on this INDICXNLI, we analyze various cross-lingual transfer techniques with respect to the impact of the choice of language models, languages, multi-linguality, mix-language input, etc. These experiments provide us with useful insights into the behaviour of pre-trained models for a diverse set of languages.},
}


@misc{aggarwal_indicxnli_nodate,
	title = {{INDICXNLI}: {Evaluating} {Multilingual} {Inference} for {Indian} {Languages}},
	abstract = {While Indic NLP has made rapid advances recently in terms of the availability of corpora and pre-trained models, benchmark datasets on standard NLU tasks are limited. To this end, we introduce INDICXNLI, an NLI dataset for 11 Indic languages. It has been created by high-quality machine translation of the original English XNLI dataset and our analysis attests to the quality of INDICXNLI. By finetuning different pre-trained LMs on this INDICXNLI, we analyze various cross-lingual transfer techniques with respect to the impact of the choice of language models, languages, multi-linguality, mix-language input, etc. These experiments provide us with useful insights into the behaviour of pre-trained models for a diverse set of languages.},
	language = {en},
    year = {2022},
	author = {Aggarwal, Divyanshu and Gupta, Vivek and Kunchukuttan, Anoop},
	file = {Aggarwal et al. - INDICXNLI Evaluating Multilingual Inference for I.pdf:/Users/yosephineyosephine/Zotero/storage/ZD584HQR/Aggarwal et al. - INDICXNLI Evaluating Multilingual Inference for I.pdf:application/pdf}
}

@inproceedings{mahendra_indonli_2021,
	address = {Online and Punta Cana, Dominican Republic},
	title = {{IndoNLI}: {A} {Natural} {Language} {Inference} {Dataset} for {Indonesian}},
	shorttitle = {{IndoNLI}},
	url = {https://aclanthology.org/2021.emnlp-main.821},
	doi = {10.18653/v1/2021.emnlp-main.821},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 2021 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Mahendra, Rahmad and Aji, Alham Fikri and Louvan, Samuel and Rahman, Fahrurrozi and Vania, Clara},
	year = {2021},
	pages = {10511--10527},
	file = {Mahendra et al. - 2021 - IndoNLI A Natural Language Inference Dataset for .pdf:/Users/yosephineyosephine/Zotero/storage/YAEVF254/Mahendra et al. - 2021 - IndoNLI A Natural Language Inference Dataset for .pdf:application/pdf},
}

@inproceedings{wilie-etal-2020-indonlu,
    title = {{IndoNLU}: {Benchmark} and {Resources} for {Evaluating} {Indonesian} {Natural} {Language} {Understanding}},
    author = {Wilie, Bryan  and
      Vincentio, Karissa  and
      Winata, Genta Indra  and
      Cahyawijaya, Samuel  and
      Li, Xiaohong  and
      Lim, Zhi Yuan  and
      Soleman, Sidik  and
      Mahendra, Rahmad  and
      Fung, Pascale  and
      Bahar, Syafri  and
      Purwarianti, Ayu},
    booktitle = {Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},
    month = {dec},
    year = {2020},
    address = {Suzhou, China},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/2020.aacl-main.85},
    pages = {843--857},
    abstract = {Although Indonesian is known to be the fourth most frequently used language over the internet, the research progress on this language in natural language processing (NLP) is slow-moving due to a lack of available resources. In response, we introduce the first-ever vast resource for training, evaluation, and benchmarking on Indonesian natural language understanding (IndoNLU) tasks. IndoNLU includes twelve tasks, ranging from single sentence classification to pair-sentences sequence labeling with different levels of complexity. The datasets for the tasks lie in different domains and styles to ensure task diversity. We also provide a set of Indonesian pre-trained models (IndoBERT) trained from a large and clean Indonesian dataset (Indo4B) collected from publicly available sources such as social media texts, blogs, news, and websites. We release baseline models for all twelve tasks, as well as the framework for benchmark evaluation, thus enabling everyone to benchmark their system performances.},
}


@misc{wilie_indonlu_nodate,
	title = {{IndoNLU}: {Benchmark} and {Resources} for {Evaluating} {Indonesian} {Natural} {Language} {Understanding}},
	abstract = {Although Indonesian is known to be the fourth most frequently used language over the internet, the research progress on this language in natural language processing (NLP) is slowmoving due to a lack of available resources. In response, we introduce the ﬁrst-ever vast resource for training, evaluation, and benchmarking on Indonesian natural language understanding (IndoNLU) tasks. IndoNLU includes twelve tasks, ranging from single sentence classiﬁcation to pair-sentences sequence labeling with different levels of complexity. The datasets for the tasks lie in different domains and styles to ensure task diversity. We also provide a set of Indonesian pre-trained models (IndoBERT) trained from a large and clean Indonesian dataset (Indo4B) collected from publicly available sources such as social media texts, blogs, news, and websites. We release baseline models for all twelve tasks, as well as the framework for benchmark evaluation, thus enabling everyone to benchmark their system performances.},
	language = {en},
    year ={2020},
	author = {Wilie, Bryan and Vincentio, Karissa and Winata, Genta Indra and Cahyawijaya, Samuel and Li, Xiaohong and Lim, Zhi Yuan and Soleman, Sidik and Mahendra, Rahmad and Fung, Pascale and Bahar, Syafri and Purwarianti, Ayu},
	file = {Wilie et al. - IndoNLU Benchmark and Resources for Evaluating In.pdf:/Users/yosephineyosephine/Zotero/storage/8VELZ5W3/Wilie et al. - IndoNLU Benchmark and Resources for Evaluating In.pdf:application/pdf},
}

@misc{wang_is_2023,
	title = {Is {ChatGPT} a {Good} {NLG} {Evaluator}? {A} {Preliminary} {Study}},
	shorttitle = {Is {ChatGPT} a {Good} {NLG} {Evaluator}?},
	url = {http://arxiv.org/abs/2303.04048},
	abstract = {Recently, the emergence of ChatGPT has attracted wide attention from the computational linguistics community. Many prior studies have shown that ChatGPT achieves remarkable performance on various NLP tasks in terms of automatic evaluation metrics. However, the ability of ChatGPT to serve as an evaluation metric is still underexplored. Considering assessing the quality of natural language generation (NLG) models is an arduous task and NLG metrics notoriously show their poor correlation with human judgments, we wonder whether ChatGPT is a good NLG evaluation metric. In this report, we provide a preliminary meta-evaluation on ChatGPT to show its reliability as an NLG metric. In detail, we regard ChatGPT as a human evaluator and give task-specific (e.g., summarization) and aspect-specific (e.g., relevance) instruction to prompt ChatGPT to evaluate the generated results of NLG models. We conduct experiments on five NLG meta-evaluation datasets (including summarization, story generation and data-to-text tasks). Experimental results show that compared with previous automatic metrics, ChatGPT achieves state-of-the-art or competitive correlation with human judgments in most cases. In addition, we find that the effectiveness of the ChatGPT evaluator might be influenced by the creation method of the meta-evaluation datasets. For the meta-evaluation datasets which are created greatly depending on the reference and thus are biased, the ChatGPT evaluator might lose its effectiveness. We hope our preliminary study could prompt the emergence of a general-purposed reliable NLG metric.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Wang, Jiaan and Liang, Yunlong and Meng, Fandong and Sun, Zengkui and Shi, Haoxiang and Li, Zhixu and Xu, Jinan and Qu, Jianfeng and Zhou, Jie},
	month = apr,
	year = {2023},
	note = {arXiv:2303.04048 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	annote = {Comment: Technical Report, 11 pages},
	file = {Wang et al. - 2023 - Is ChatGPT a Good NLG Evaluator A Preliminary Stu.pdf:/Users/yosephineyosephine/Zotero/storage/9VM5LUHT/Wang et al. - 2023 - Is ChatGPT a Good NLG Evaluator A Preliminary Stu.pdf:application/pdf},
}

@inproceedings{jeretic_are_2020,
	address = {Online},
	title = {Are {Natural} {Language} {Inference} {Models} {IMPPRESsive}? {Learning} {IMPlicature} and {PRESupposition}},
	shorttitle = {Are {Natural} {Language} {Inference} {Models} {IMPPRESsive}?},
	url = {https://www.aclweb.org/anthology/2020.acl-main.768},
	doi = {10.18653/v1/2020.acl-main.768},
	abstract = {Natural language inference (NLI) is an increasingly important task for natural language understanding, which requires one to infer whether a sentence entails another. However, the ability of NLI models to make pragmatic inferences remains understudied. We create an IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of {\textgreater}25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types. We use IMPPRES to evaluate whether BERT, InferSent, and BOW NLI models trained on MultiNLI (Williams et al., 2018) learn to make pragmatic inferences. Although MultiNLI appears to contain very few pairs illustrating these inference types, we ﬁnd that BERT learns to draw pragmatic inferences. It reliably treats scalar implicatures triggered by “some” as entailments. For some presupposition triggers like only, BERT reliably recognizes the presupposition as an entailment, even when the trigger is embedded under an entailment canceling operator like negation. BOW and InferSent show weaker evidence of pragmatic reasoning. We conclude that NLI training encourages models to learn some, but not all, pragmatic inferences.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Jereti\v{c}, Paloma and Warstadt, Alex and Bhooshan, Suvrat and Williams, Adina},
	year = {2020},
	pages = {8690--8705},
	file = {Jeretic et al. - 2020 - Are Natural Language Inference Models IMPPRESsive.pdf:/Users/yosephineyosephine/Zotero/storage/AFLBGK5B/Jeretic et al. - 2020 - Are Natural Language Inference Models IMPPRESsive.pdf:application/pdf},
}

@misc{zheng_judging_2023,
	title = {Judging {LLM}-as-a-judge with {MT}-{Bench} and {Chatbot} {Arena}},
	url = {http://arxiv.org/abs/2306.05685},
	abstract = {Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80\% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA and Vicuna. We will publicly release MT-bench questions, 3K expert votes, and 30K conversations with human preferences from Chatbot Arena 2.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric P. and Zhang, Hao and Gonzalez, Joseph E. and Stoica, Ion},
	month = jul,
	year = {2023},
	note = {arXiv:2306.05685 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Zheng et al. - 2023 - Judging LLM-as-a-judge with MT-Bench and Chatbot A.pdf:/Users/yosephineyosephine/Zotero/storage/G842FC8V/Zheng et al. - 2023 - Judging LLM-as-a-judge with MT-Bench and Chatbot A.pdf:application/pdf},
}

@inproceedings{ramezani_knowledge_2023,
	address = {Toronto, Canada},
	title = {Knowledge of {Cultural} {Moral} {Norms} in {Large} {Language} {Models}},
	url = {https://aclanthology.org/2023.acl-long.26},
	doi = {10.18653/v1/2023.acl-long.26},
	abstract = {Moral norms vary across cultures. A recent line of work suggests that English large language models contain human-like moral biases, but these studies typically do not examine moral variation in a diverse cultural setting. We investigate the extent to which monolingual English language models contain knowledge about moral norms in different countries. We consider two levels of analysis: 1) whether language models capture ﬁne-grained moral variation across countries over a variety of topics such as “homosexuality” and “divorce”; 2) whether language models capture cultural diversity and shared tendencies in which topics people around the globe tend to diverge or agree on in their moral judgment. We perform our analyses with two public datasets from the World Values Survey (across 55 countries) and PEW global surveys (across 40 countries) on morality. We ﬁnd that pre-trained English language models predict empirical moral norms across countries worse than the English moral norms reported previously. However, ﬁne-tuning language models on the survey data improves inference across countries at the expense of a less accurate estimate of the English moral norms. We discuss the relevance and challenges of incorporating cultural knowledge into the automated inference of moral norms.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 61st {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Ramezani, Aida and Xu, Yang},
	year = {2023},
	pages = {428--446},
	file = {Ramezani and Xu - 2023 - Knowledge of cultural moral norms in large languag.pdf:/Users/yosephineyosephine/Zotero/storage/4A7HTAK4/Ramezani and Xu - 2023 - Knowledge of cultural moral norms in large languag.pdf:application/pdf},
}

@misc{kodner_why_2023,
	title = {Why {Linguistics} {Will} {Thrive} in the 21st {Century}: {A} {Reply} to {Piantadosi} (2023)},
	shorttitle = {Why {Linguistics} {Will} {Thrive} in the 21st {Century}},
	url = {http://arxiv.org/abs/2308.03228},
	abstract = {We present a critical assessment of Piantadosi's (2023) claim that "Modern language models refute Chomsky's approach to language," focusing on four main points. First, despite the impressive performance and utility of large language models (LLMs), humans achieve their capacity for language after exposure to several orders of magnitude less data. The fact that young children become competent, fluent speakers of their native languages with relatively little exposure to them is the central mystery of language learning to which Chomsky initially drew attention, and LLMs currently show little promise of solving this mystery. Second, what can the artificial reveal about the natural? Put simply, the implications of LLMs for our understanding of the cognitive structures and mechanisms underlying language and its acquisition are like the implications of airplanes for understanding how birds fly. Third, LLMs cannot constitute scientific theories of language for several reasons, not least of which is that scientific theories must provide interpretable explanations, not just predictions. This leads to our final point: to even determine whether the linguistic and cognitive capabilities of LLMs rival those of humans requires explicating what humans' capacities actually are. In other words, it requires a separate theory of language and cognition; generative linguistics provides precisely such a theory. As such, we conclude that generative linguistics as a scientific discipline will remain indispensable throughout the 21st century and beyond.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Kodner, Jordan and Payne, Sarah and Heinz, Jeffrey},
	month = aug,
	year = {2023},
	note = {arXiv:2308.03228 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Kodner et al. - 2023 - Why Linguistics Will Thrive in the 21st Century A.pdf:/Users/yosephineyosephine/Zotero/storage/PURZMJDD/Kodner et al. - 2023 - Why Linguistics Will Thrive in the 21st Century A.pdf:application/pdf},
}

@misc{yu_kola_2023,
	title = {{KoLA}: {Carefully} {Benchmarking} {World} {Knowledge} of {Large} {Language} {Models}},
	shorttitle = {{KoLA}},
	url = {http://arxiv.org/abs/2306.09296},
	abstract = {The unprecedented performance of large language models (LLMs) necessitates improvements in evaluations. Rather than merely exploring the breadth of LLM abilities, we believe meticulous and thoughtful designs are essential to thorough, unbiased, and applicable evaluations. Given the importance of world knowledge to LLMs, we construct a Knowledge-oriented LLM Assessment benchmark (KoLA), in which we carefully design three crucial factors: (1) For ability modeling, we mimic human cognition to form a four-level taxonomy of knowledge-related abilities, covering 19 tasks. (2) For data, to ensure fair comparisons, we use both Wikipedia, a corpus prevalently pre-trained by LLMs, along with continuously collected emerging corpora, aiming to evaluate the capacity to handle unseen data and evolving knowledge. (3) For evaluation criteria, we adopt a contrastive system, including overall standard scores for better numerical comparability across tasks and models and a unique self-contrast metric for automatically evaluating knowledge hallucination. We evaluate 21 open-source and commercial LLMs and obtain some intriguing findings. The KoLA dataset and open-participation leaderboard are publicly released at https://kola.xlore.cn and will be continuously updated to provide references for developing LLMs and knowledge-related systems.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Yu, Jifan and Wang, Xiaozhi and Tu, Shangqing and Cao, Shulin and Zhang-Li, Daniel and Lv, Xin and Peng, Hao and Yao, Zijun and Zhang, Xiaohan and Li, Hanming and Li, Chunyang and Zhang, Zheyuan and Bai, Yushi and Liu, Yantao and Xin, Amy and Lin, Nianyi and Yun, Kaifeng and Gong, Linlu and Chen, Jianhui and Wu, Zhili and Qi, Yunjia and Li, Weikai and Guan, Yong and Zeng, Kaisheng and Qi, Ji and Jin, Hailong and Liu, Jinxin and Gu, Yu and Yao, Yuan and Ding, Ning and Hou, Lei and Liu, Zhiyuan and Xu, Bin and Tang, Jie and Li, Juanzi},
	month = jul,
	year = {2023},
	note = {arXiv:2306.09296 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Yu et al. - 2023 - KoLA Carefully Benchmarking World Knowledge of La.pdf:/Users/yosephineyosephine/Zotero/storage/ESJKNI5I/Yu et al. - 2023 - KoLA Carefully Benchmarking World Knowledge of La.pdf:application/pdf},
}

@article{lembersky_language_2012,
	title = {Language {Models} for {Machine} {Translation}: {Original} vs. {Translated} {Texts}},
	volume = {38},
	issn = {0891-2017, 1530-9312},
	shorttitle = {Language {Models} for {Machine} {Translation}},
	url = {https://direct.mit.edu/coli/article/38/4/799-825/2154},
	doi = {10.1162/COLI_a_00111},
	abstract = {We investigate the differences between language models compiled from original target-language texts and those compiled from texts manually translated to the target language. Corroborating established observations of Translation Studies, we demonstrate that the latter are significantly better predictors of translated sentences than the former, and hence fit the reference set better. Furthermore, translated texts yield better language models for statistical machine translation than original texts.},
	language = {en},
	number = {4},
	urldate = {2023-09-10},
	journal = {Computational Linguistics},
	author = {Lembersky, Gennadi and Ordan, Noam and Wintner, Shuly},
	month = dec,
	year = {2012},
	pages = {799--825},
	file = {Lembersky et al. - 2012 - Language Models for Machine Translation Original .pdf:/Users/yosephineyosephine/Zotero/storage/VP2H8TII/Lembersky et al. - 2012 - Language Models for Machine Translation Original .pdf:application/pdf},
}

@article{leung_syntax_2018,
	title = {The {Syntax} of {Two} {Types} of {Sluicing} in {Tamil}},
	volume = {35},
	issn = {0167-6318, 1613-3676},
	url = {https://www.degruyter.com/document/doi/10.1515/tlr-2017-0017/html},
	doi = {10.1515/tlr-2017-0017},
	abstract = {Abstract
            
              Recent analyses of sluicing focus on the underlying structure of the sluiced clause, i.e. sluicing as deriving from full-fledged wh-questions, or from reduced clefts (Ross 1969, Guess who? In Robert I. Binnick, Alice Davison, Georgia M. Green \& Jerry L. Morgan (eds.),
              Proceedings of the Fifth Regional Meeting of the Chicago Linguistic Society
              , 252–286. Chicago, IL: Chicago Linguistic Society, University of Chicago; Merchant 2001,
              The syntax of silence
              . Oxford, NY: Oxford University Press; Craenenbroeck, Jeroen van. 2010b.
              The syntax of ellipsis: Evidence from Dutch dialects
              . Oxford, NY: Oxford University Press., inter alia). In this paper, we investigate two sluicing strategies in Spoken Tamil, namely
              case-marked
              (CM) and
              non-case-marked
              (NCM) sluicing. In addition to the morphological distinction with respect to the presence/absence of grammatical case on the wh-sluice, we argue that the two types of sluicing differ in the configuration of the underlying embedded CP. For CM sluicing, the sluiced clause is derived from a full-fledged interrogative CP at the underlying level, whereas the bare wh-sluice undergoes leftward wh-scrambling to the CP-initial position followed by TP-domain deletion at PF. While we contend that most A/A’-diagnostics are uninformative of the type of operation wh-scrambling in Tamil involves (contra Sarma 2003, Non-Canonical word order: Topic and focus in adult and child tamil. In Karimi Simin (eds.),
              Word order and scrambling
              , 238–272. Malden, Oxford: Blackwell), various properties of the CM wh-sluice (e.g. scope, negation, adverb placement, multiple sluicing) can still be described by postulating that the wh-sluice involves A’-scrambling. For the second type of sluicing (NCM sluicing), the sluiced clause involves a biclausal structure formed by a normal sentence and a null copular question. We claim that the NCM wh-sluice is derived from
              Spad
              (
              Sluicing Plus A Demonstrative
              ), since the null copular question can be accompanied by a demonstrative, cf. English ‘John met someone, who is that?’ and Dutch spading (Van Craenenbroeck 2010b). Spad is not derived from a full-fledged interrogative CP, and therefore its wh-sluice does not involve any scrambling operation. The present analysis of Tamil sluicing refutes the claim that reduced clefts are one underlying sluicing source in Dravidian languages, and moreover invites an inquiry of whether Dravidian as a language family in the historical sense always receives a homogeneous analysis, given the immense parametric variation among branch languages. In the same vein, we contend that any claim about the ‘principles’ of Dravidian syntax must be supported by strong cross-linguistic evidence at the microscopic level.},
	language = {en},
	number = {1},
	urldate = {2023-09-10},
	journal = {The Linguistic Review},
	author = {Leung, Tommi},
	month = jan,
	year = {2018},
	pages = {35--82},
	file = {Leung - 2018 - The syntax of two types of sluicing in Tamil.pdf:/Users/yosephineyosephine/Zotero/storage/2IZG883D/Leung - 2018 - The syntax of two types of sluicing in Tamil.pdf:application/pdf},
}

@misc{li_translate_2023,
	title = {Translate {Meanings}, {Not} {Just} {Words}: {IdiomKB}'s {Role} in {Optimizing} {Idiomatic} {Translation} with {Language} {Models}},
	shorttitle = {Translate {Meanings}, {Not} {Just} {Words}},
	url = {http://arxiv.org/abs/2308.13961},
	abstract = {To translate well, machine translation (MT) systems and general-purposed language models (LMs) need a deep understanding of both source and target languages and cultures. Therefore, idioms, with their non-compositional nature, pose particular challenges for Transformer-based systems, as literal translations often miss the intended meaning. Traditional methods, which replace idioms using existing knowledge bases (KBs), often lack scale and context awareness. Addressing these challenges, our approach prioritizes context awareness and scalability, allowing for offline storage of idioms in a manageable KB size. This ensures efficient serving with smaller models and provides a more comprehensive understanding of idiomatic expressions. We introduce a multilingual idiom KB (IDIOMKB) developed using large LMs to address this. This KB facilitates better translation by smaller models, such as BLOOMZ (7.1B), Alpaca (7B), and InstructGPT (6.7B), by retrieving idioms’ figurative meanings. We present a novel, GPT-4-powered metric for human-aligned evaluation, demonstrating that IDIOMKB considerably boosts model performance. Human evaluations further validate our KB’s quality. Resources of this work can be found at https://github.com/lishuang-w/IdiomKB.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Li, Shuang and Chen, Jiangjie and Yuan, Siyu and Wu, Xinyi and Yang, Hao and Tao, Shimin and Xiao, Yanghua},
	month = aug,
	year = {2023},
	note = {arXiv:2308.13961 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Work in progress},
	file = {Li et al. - 2023 - Translate Meanings, Not Just Words IdiomKB's Role.pdf:/Users/yosephineyosephine/Zotero/storage/UK4VPN6Z/Li et al. - 2023 - Translate Meanings, Not Just Words IdiomKB's Role.pdf:application/pdf},
}

@misc{liang_holistic_2022,
	title = {Holistic {Evaluation} of {Language} {Models}},
	url = {http://arxiv.org/abs/2211.09110},
	abstract = {Language models (LMs) are becoming the foundation for almost all major language technologies, but their capabilities, limitations, and risks are not well understood. We present Holistic Evaluation of Language Models (HELM) to improve the transparency of language models. First, we taxonomize the vast space of potential scenarios (i.e. use cases) and metrics (i.e. desiderata) that are of interest for LMs. Then we select a broad subset based on coverage and feasibility, noting what's missing or underrepresented (e.g. question answering for neglected English dialects, metrics for trustworthiness). Second, we adopt a multi-metric approach: We measure 7 metrics (accuracy, calibration, robustness, fairness, bias, toxicity, and efficiency) for each of 16 core scenarios when possible (87.5\% of the time). This ensures metrics beyond accuracy don't fall to the wayside, and that trade-offs are clearly exposed. We also perform 7 targeted evaluations, based on 26 targeted scenarios, to analyze specific aspects (e.g. reasoning, disinformation). Third, we conduct a large-scale evaluation of 30 prominent language models (spanning open, limited-access, and closed models) on all 42 scenarios, 21 of which were not previously used in mainstream LM evaluation. Prior to HELM, models on average were evaluated on just 17.9\% of the core HELM scenarios, with some prominent models not sharing a single scenario in common. We improve this to 96.0\%: now all 30 models have been densely benchmarked on the same core scenarios and metrics under standardized conditions. Our evaluation surfaces 25 top-level findings. For full transparency, we release all raw model prompts and completions publicly for further analysis, as well as a general modular toolkit. We intend for HELM to be a living benchmark for the community, continuously updated with new scenarios, metrics, and models.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and Newman, Benjamin and Yuan, Binhang and Yan, Bobby and Zhang, Ce and Cosgrove, Christian and Manning, Christopher D. and Ré, Christopher and Acosta-Navas, Diana and Hudson, Drew A. and Zelikman, Eric and Durmus, Esin and Ladhak, Faisal and Rong, Frieda and Ren, Hongyu and Yao, Huaxiu and Wang, Jue and Santhanam, Keshav and Orr, Laurel and Zheng, Lucia and Yuksekgonul, Mert and Suzgun, Mirac and Kim, Nathan and Guha, Neel and Chatterji, Niladri and Khattab, Omar and Henderson, Peter and Huang, Qian and Chi, Ryan and Xie, Sang Michael and Santurkar, Shibani and Ganguli, Surya and Hashimoto, Tatsunori and Icard, Thomas and Zhang, Tianyi and Chaudhary, Vishrav and Wang, William and Li, Xuechen and Mai, Yifan and Zhang, Yuhui and Koreeda, Yuta},
	month = nov,
	year = {2022},
	note = {arXiv:2211.09110 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: Authored by the Center for Research on Foundation Models (CRFM) at the Stanford Institute for Human-Centered Artificial Intelligence (HAI). Project page: https://crfm.stanford.edu/helm/v1.0},
	file = {Liang et al. - 2022 - Holistic Evaluation of Language Models.pdf:/Users/yosephineyosephine/Zotero/storage/L79KNNR8/Liang et al. - 2022 - Holistic Evaluation of Language Models.pdf:application/pdf},
}

@article{liu_adjective_2023,
	title = {Adjective {Scale} {Probe}: {Can} {Language} {Models} {Encode} {Formal} {Semantics} {Information}?},
	volume = {37},
	issn = {2374-3468, 2159-5399},
	shorttitle = {Adjective {Scale} {Probe}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/26559},
	doi = {10.1609/aaai.v37i11.26559},
	abstract = {It is an open question what semantic representations transformer-based language models can encode and whether they have access to more abstract aspects of semantic meaning. Here, we propose a diagnostic dataset to investigate how well language models understand the degree semantics of adjectives. In the dataset, referred as the Adjective Scale Probe (ASP), we semi-automatically generate 8 tests of Natural Language Inference (NLI) questions to test 8 key capabilities of adjective interpretation. We apply the ASP dataset to evaluate the performance of 3 language models, i.e., BERT, DeBERTa, and T0. It is found that language models perform below the majority baseline for most tests of the ASP, even when the models have been fine-tuned to achieve high performance on the large-scale MNLI dataset. But after we fine-tune the pre-trained models on a subset of the ASP, DeBERTa can achieve high performance on the untrained adjectives and untrained tests, suggesting that DeBERTa may have captured degree semantic information of adjectives through pre-training but it needs specific training data to learn how to apply such information to the current tasks. In sum, the ASP provides an easy-to-use method to test fine-grained formal semantic properties of adjectives, and reveals language models’ abilities to access formal semantic information.},
	language = {en},
	number = {11},
	urldate = {2023-09-10},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Liu, Wei and Xiang, Ming and Ding, Nai},
	month = jun,
	year = {2023},
	pages = {13282--13290},
	file = {Liu et al. - 2023 - Adjective Scale Probe Can Language Models Encode .pdf:/Users/yosephineyosephine/Zotero/storage/TJBNN9RI/Liu et al. - 2023 - Adjective Scale Probe Can Language Models Encode .pdf:application/pdf},
}

@misc{liu_were_2023,
	title = {We're {Afraid} {Language} {Models} {Aren}'t {Modeling} {Ambiguity}},
	url = {http://arxiv.org/abs/2304.14399},
	abstract = {Ambiguity is an intrinsic feature of natural language. Managing ambiguity is a key part of human language understanding, allowing us to anticipate misunderstanding as communicators and revise our interpretations as listeners. As language models (LMs) are increasingly employed as dialogue interfaces and writing aids, handling ambiguous language is critical to their success. We characterize ambiguity in a sentence by its effect on entailment relations with another sentence, and collect AMBIENT,1 a linguist-annotated benchmark of 1,645 examples with diverse kinds of ambiguity. We design a suite of tests based on AMBIENT, presenting the ﬁrst evaluation of pretrained LMs to recognize ambiguity and disentangle possible meanings. We ﬁnd that the task remains extremely challenging, including for the recent GPT-4, whose generated disambiguations are considered correct only 32\% of the time in human evaluation, compared to 90\% for disambiguations in our dataset. Finally, to illustrate the value of ambiguity-sensitive tools, we show that a multilabel NLI model can ﬂag political claims in the wild that are misleading due to ambiguity. We encourage the ﬁeld to rediscover the importance of ambiguity for NLP.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Liu, Alisa and Wu, Zhaofeng and Michael, Julian and Suhr, Alane and West, Peter and Koller, Alexander and Swayamdipta, Swabha and Smith, Noah A. and Choi, Yejin},
	month = apr,
	year = {2023},
	note = {arXiv:2304.14399 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: 9 pages, 3 figures},
	file = {Liu et al. - 2023 - We're Afraid Language Models Aren't Modeling Ambig.pdf:/Users/yosephineyosephine/Zotero/storage/BYQGJEPE/Liu et al. - 2023 - We're Afraid Language Models Aren't Modeling Ambig.pdf:application/pdf},
}

@misc{long_large_2023,
	title = {Large {Language} {Model} {Guided} {Tree}-of-{Thought}},
	url = {http://arxiv.org/abs/2305.08291},
	abstract = {In this paper, we introduce the Tree-of-Thought (ToT) framework, a novel approach aimed at improving the problem-solving capabilities of auto-regressive large language models (LLMs). The ToT technique is inspired by the human mind’s approach for solving complex reasoning tasks through trial and error. In this process, the human mind explores the solution space through a tree-like thought process, allowing for backtracking when necessary. To implement ToT as a software system, we augment an LLM with additional modules including a prompter agent, a checker module, a memory module, and a ToT controller. In order to solve a given problem, these modules engage in a multi-round conversation with the LLM. The memory module records the conversation and state history of the problem solving process, which allows the system to backtrack to the previous steps of the thought-process and explore other directions from there. To verify the effectiveness of the proposed technique, we implemented a ToT-based solver for the Sudoku Puzzle. Experimental results show that the ToT framework can signiﬁcantly increase the success rate of Sudoku puzzle solving. Our implementation of the ToT-based Sudoku solver is available on GitHub: https://github.com/jieyilong/tree-of-thought-puzzle-solver.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Long, Jieyi},
	month = may,
	year = {2023},
	note = {arXiv:2305.08291 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {Long - 2023 - Large Language Model Guided Tree-of-Thought.pdf:/Users/yosephineyosephine/Zotero/storage/GI2AGD2H/Long - 2023 - Large Language Model Guided Tree-of-Thought.pdf:application/pdf},
}

@misc{zhou_large_2023,
	title = {Large {Language} {Models} {Are} {Human}-{Level} {Prompt} {Engineers}},
	url = {http://arxiv.org/abs/2211.01910},
	abstract = {By conditioning on natural language instructions, large language models (LLMs) have displayed impressive capabilities as general-purpose computers. However, task performance depends significantly on the quality of the prompt used to steer the model, and most effective prompts have been handcrafted by humans. Inspired by classical program synthesis and the human approach to prompt engineering, we propose Automatic Prompt Engineer (APE) for automatic instruction generation and selection. In our method, we treat the instruction as the "program," optimized by searching over a pool of instruction candidates proposed by an LLM in order to maximize a chosen score function. To evaluate the quality of the selected instruction, we evaluate the zero-shot performance of another LLM following the selected instruction. Experiments on 24 NLP tasks show that our automatically generated instructions outperform the prior LLM baseline by a large margin and achieve better or comparable performance to the instructions generated by human annotators on 19/24 tasks. We conduct extensive qualitative and quantitative analyses to explore the performance of APE. We show that APE-engineered prompts can be applied to steer models toward truthfulness and/or informativeness, as well as to improve few-shot learning performance by simply prepending them to standard in-context learning prompts. Please check out our webpage at https://sites.google.com/view/automatic-prompt-engineer.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Zhou, Yongchao and Muresanu, Andrei Ioan and Han, Ziwen and Paster, Keiran and Pitis, Silviu and Chan, Harris and Ba, Jimmy},
	month = mar,
	year = {2023},
	note = {arXiv:2211.01910 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Zhou et al. - 2023 - Large Language Models Are Human-Level Prompt Engin.pdf:/Users/yosephineyosephine/Zotero/storage/CN7MARB9/Zhou et al. - 2023 - Large Language Models Are Human-Level Prompt Engin.pdf:application/pdf},
}

@misc{wang_large_2023,
	title = {Large {Language} {Models} are {Not} {Fair} {Evaluators}},
	url = {http://arxiv.org/abs/2305.17926},
	abstract = {In this paper, we uncover a systematic bias in the evaluation paradigm of adopting large language models{\textasciitilde}(LLMs), e.g., GPT-4, as a referee to score and compare the quality of responses generated by candidate models. We find that the quality ranking of candidate responses can be easily hacked by simply altering their order of appearance in the context. This manipulation allows us to skew the evaluation result, making one model appear considerably superior to the other, e.g., Vicuna-13B could beat ChatGPT on 66 over 80 tested queries with ChatGPT as an evaluator. To address this issue, we propose a calibration framework with three simple yet effective strategies: 1) Multiple Evidence Calibration, which requires the evaluator model to generate multiple evaluation evidence before assigning ratings; 2) Balanced Position Calibration, which aggregates results across various orders to determine the final score; 3) Human-in-the-Loop Calibration, which introduces a balanced position diversity entropy to measure the difficulty of each example and seeks human assistance when needed. We also manually annotate the "win/tie/lose" outcomes of responses from ChatGPT and Vicuna-13B in the Vicuna Benchmark's question prompt, and extensive experiments demonstrate that our approach successfully mitigates evaluation bias, resulting in closer alignment with human judgments. We release our code and human annotation at {\textbackslash}url\{https://github.com/i-Eval/FairEval\} to facilitate future research.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Wang, Peiyi and Li, Lei and Chen, Liang and Cai, Zefan and Zhu, Dawei and Lin, Binghuai and Cao, Yunbo and Liu, Qi and Liu, Tianyu and Sui, Zhifang},
	month = aug,
	year = {2023},
	note = {arXiv:2305.17926 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Information Retrieval},
	file = {Wang et al. - 2023 - Large Language Models are not Fair Evaluators.pdf:/Users/yosephineyosephine/Zotero/storage/5VCMN98V/Wang et al. - 2023 - Large Language Models are not Fair Evaluators.pdf:application/pdf},
}

@misc{kocmi_large_2023,
	title = {Large {Language} {Models} {Are} {State}-of-the-{Art} {Evaluators} of {Translation} {Quality}},
	url = {http://arxiv.org/abs/2302.14520},
	abstract = {We describe GEMBA, a GPT-based metric for assessment of translation quality, which works both with a reference translation and without. In our evaluation, we focus on zero-shot prompting, comparing four prompt variants in two modes, based on the availability of the reference. We investigate nine versions of GPT models, including ChatGPT and GPT-4. We show that our method for translation quality assessment only works with GPT{\textasciitilde}3.5 and larger models. Comparing to results from WMT22's Metrics shared task, our method achieves state-of-the-art accuracy in both modes when compared to MQM-based human labels. Our results are valid on the system level for all three WMT22 Metrics shared task language pairs, namely English into German, English into Russian, and Chinese into English. This provides a first glimpse into the usefulness of pre-trained, generative large language models for quality assessment of translations. We publicly release all our code and prompt templates used for the experiments described in this work, as well as all corresponding scoring results, to allow for external validation and reproducibility.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Kocmi, Tom and Federmann, Christian},
	month = may,
	year = {2023},
	note = {arXiv:2302.14520 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Accepted in EAMT, 10 pages, 8 tables, one figure},
	file = {Kocmi and Federmann - 2023 - Large Language Models Are State-of-the-Art Evaluat.pdf:/Users/yosephineyosephine/Zotero/storage/7SWR2RBG/Kocmi and Federmann - 2023 - Large Language Models Are State-of-the-Art Evaluat.pdf:application/pdf},
}

@misc{kojima2023large,
      title={Large {Language} {Models} are {Zero-Shot} {Reasoners}}, 
      author={Takeshi Kojima and Shixiang Shane Gu and Machel Reid and Yutaka Matsuo and Yusuke Iwasawa},
      year={2023},
      eprint={2205.11916},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      publisher={arXiv},
      note={arXiv:2205.11916 [cs]}
}



@misc{mao_gpteval_2023,
	title = {{GPTEval}: {A} {Survey} on {Assessments} of {ChatGPT} and {GPT}-4},
	shorttitle = {{GPTEval}},
	url = {http://arxiv.org/abs/2308.12488},
	abstract = {The emergence of ChatGPT has generated much speculation in the press about its potential to disrupt social and economic systems. Its astonishing language ability has aroused strong curiosity among scholars about its performance in different domains. There have been many studies evaluating the ability of ChatGPT and GPT-4 in different tasks and disciplines. However, a comprehensive review summarizing the collective assessment findings is lacking. The objective of this survey is to thoroughly analyze prior assessments of ChatGPT and GPT-4, focusing on its language and reasoning abilities, scientific knowledge, and ethical considerations. Furthermore, an examination of the existing evaluation methods is conducted, offering several recommendations for future research in evaluating large language models.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Mao, Rui and Chen, Guanyi and Zhang, Xulang and Guerin, Frank and Cambria, Erik},
	month = aug,
	year = {2023},
	note = {arXiv:2308.12488 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Mao et al. - 2023 - GPTEval A Survey on Assessments of ChatGPT and GP.pdf:/Users/yosephineyosephine/Zotero/storage/MW8EKI79/Mao et al. - 2023 - GPTEval A Survey on Assessments of ChatGPT and GP.pdf:application/pdf},
}

@incollection{epstein_resumption_2002,
	edition = {1},
	title = {Resumption, {Successive} {Cyclicity}, and the {Locality} of {Operations}},
	isbn = {978-0-631-22732-8 978-0-470-75566-2},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/9780470755662.ch9},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Derivation and {Explanation} in the {Minimalist} {Program}},
	publisher = {Wiley},
	author = {Mccloskey, James},
	editor = {Epstein, Samuel David and Seely, T. Daniel},
	month = jan,
	year = {2002},
	doi = {10.1002/9780470755662.ch9},
	pages = {184--226},
	file = {Mccloskey - 2002 - Resumption, Successive Cyclicity, and the Locality.pdf:/Users/yosephineyosephine/Zotero/storage/M7PIK2C4/Mccloskey - 2002 - Resumption, Successive Cyclicity, and the Locality.pdf:application/pdf},
}

@incollection{everaert_resumption_2006,
	edition = {1},
	title = {Resumption},
	isbn = {978-1-4051-1485-1 978-0-470-99659-1},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/9780470996591.ch55},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {The {Blackwell} {Companion} to {Syntax}},
	publisher = {Wiley},
	author = {McCloskey, James},
	editor = {Everaert, Martin and Van Riemsdijk, Henk},
	month = jan,
	year = {2006},
	doi = {10.1002/9780470996591.ch55},
	pages = {94--117},
	file = {McCloskey - 2006 - Resumption.pdf:/Users/yosephineyosephine/Zotero/storage/A4XCNXEZ/McCloskey - 2006 - Resumption.pdf:application/pdf},
}

@article{morgan_english_2018,
	title = {English {Resumptive} {Pronouns} {Are} {More} {Common} {Where} {Gaps} {Are} {Less} {Acceptable}},
	volume = {49},
	issn = {0024-3892, 1530-9150},
	url = {https://direct.mit.edu/ling/article/49/4/861-876/693},
	doi = {10.1162/ling_a_00293},
	language = {en},
	number = {4},
	urldate = {2023-09-10},
	journal = {Linguistic Inquiry},
	author = {Morgan, Adam Milton and Wagers, Matthew W.},
	month = oct,
	year = {2018},
	pages = {861--876},
	file = {Morgan and Wagers - 2018 - English Resumptive Pronouns Are More Common Where .pdf:/Users/yosephineyosephine/Zotero/storage/CJ8LMVE6/Morgan and Wagers - 2018 - English Resumptive Pronouns Are More Common Where .pdf:application/pdf},
}

@inproceedings{ibrohim_multi-label_2019,
	address = {Florence, Italy},
	title = {Multi-label {Hate} {Speech} and {Abusive} {Language} {Detection} in {Indonesian} {Twitter}},
	url = {https://www.aclweb.org/anthology/W19-3506},
	doi = {10.18653/v1/W19-3506},
	abstract = {Hate speech and abusive language spreading on social media need to be detected automatically to avoid conﬂicts between citizens. Moreover, hate speech has a target, category, and level that also need to be detected to help the authority in prioritizing which hate speech must be addressed immediately. This research discusses multi-label text classiﬁcation for abusive language and hate speech detection including detecting the target, category, and level of hate speech in Indonesian Twitter using machine learning approaches with Support Vector Machine (SVM), Naive Bayes (NB), and Random Forest Decision Tree (RFDT) classiﬁer and Binary Relevance (BR), Label Power-set (LP), and Classiﬁer Chains (CC) as the data transformation method. We used several kinds of feature extractions which are term frequency, orthography, and lexicon features. Our experiment results show that in general the RFDT classiﬁer using LP as the transformation method gives the best accuracy with fast computational time.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the {Third} {Workshop} on {Abusive} {Language} {Online}},
	publisher = {Association for Computational Linguistics},
	author = {Ibrohim, Muhammad Okky and Budi, Indra},
	year = {2019},
	pages = {46--57},
	file = {Ibrohim and Budi - 2019 - Multi-label Hate Speech and Abusive Language Detec.pdf:/Users/yosephineyosephine/Zotero/storage/PMMBUY6F/Ibrohim and Budi - 2019 - Multi-label Hate Speech and Abusive Language Detec.pdf:application/pdf},
}

@inproceedings{lommel-2013-multidimensional,
    title = {Multidimensional {Quality} {Metrics}: {A} {Flexible} {System} for {Assessing} {Translation} {Quality}},
    author = {Lommel, Arle Richard and Burchardt, Aljoscha and Uszkoreit, Hans},
    booktitle = {Proceedings of Translating and the Computer 35},
    month = {November},
    year = {2013},
    address = {London, UK},
    publisher = {Aslib},
    url = {https://aclanthology.org/2013.tc-1.6},
}


@misc{lommel_multidimensional_nodate,
	title = {Multidimensional quality metrics: a flexible system for assessing translation quality},
	language = {en},
    year ={2013},
	author = {Lommel, Arle Richard and Burchardt, Aljoscha and Uszkoreit, Hans},
	file = {Lommel et al. - Multidimensional quality metrics a flexible syste.pdf:/Users/yosephineyosephine/Zotero/storage/U93E3Y42/Lommel et al. - Multidimensional quality metrics a flexible syste.pdf:application/pdf},

}

@inproceedings{sundaresan2011plea,
  title={A {Plea} for {Syntax} and a {Return} to {First} {Principles}: {Monstrous} {Agreement} in {Tamil}},
  author={Sundaresan, Sandhya},
  booktitle={Semantics and Linguistic Theory},
  volume={21},
  pages={674--693},
  year={2011}
}

@misc{zhu_multilingual_2023,
	title = {Multilingual {Machine} {Translation} with {Large} {Language} {Models}: {Empirical} {Results} and {Analysis}},
	shorttitle = {Multilingual {Machine} {Translation} with {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2304.04675},
	abstract = {Large language models (LLMs) have demonstrated remarkable potential in handling multilingual machine translation (MMT). In this paper, we systematically investigate the advantages and challenges of LLMs for MMT by answering two questions: 1) How well do LLMs perform in translating a massive number of languages? 2) Which factors affect LLMs' performance in translation? We evaluate popular LLMs, including XGLM, OPT, BLOOMZ, and ChatGPT, on 102 languages. Our empirical results show that even the best model ChatGPT still lags behind the supervised baseline NLLB in 83.33\% of translation directions. Through further analysis, we discover that LLMs exhibit new working patterns when used for MMT. First, prompt semantics can surprisingly be ignored when given in-context exemplars, where LLMs still show strong performance even with unreasonable prompts. Second, cross-lingual exemplars can provide better task instruction for low-resource translation than exemplars in the same language pairs. Third, we observe the overestimated performance of BLOOMZ on dataset Flores-101, indicating the potential risk when using public datasets for evaluation.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Zhu, Wenhao and Liu, Hongyi and Dong, Qingxiu and Xu, Jingjing and Huang, Shujian and Kong, Lingpeng and Chen, Jiajun and Li, Lei},
	month = may,
	year = {2023},
	note = {arXiv:2304.04675 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Zhu et al. - 2023 - Multilingual Machine Translation with Large Langua.pdf:/Users/yosephineyosephine/Zotero/storage/NH2E4SUD/Zhu et al. - 2023 - Multilingual Machine Translation with Large Langua.pdf:application/pdf},
}

@inproceedings{mhaske_naamapadam_2023,
	address = {Toronto, Canada},
	title = {Naamapadam: {A} {Large}-{Scale} {Named} {Entity} {Annotated} {Data} for {Indic} {Languages}},
	shorttitle = {Naamapadam},
	url = {https://aclanthology.org/2023.acl-long.582},
	doi = {10.18653/v1/2023.acl-long.582},
	abstract = {We present, Naamapadam, the largest publicly available Named Entity Recognition (NER) dataset for the 11 major Indian languages from two language families. The dataset contains more than 400k sentences annotated with a total of at least 100k entities from three standard entity categories (Person, Location, and, Organization) for 9 out of the 11 languages. The training dataset has been automatically created from the Samanantar parallel corpus by projecting automatically tagged entities from an English sentence to the corresponding Indian language translation. We also create manually annotated testsets for 9 languages. We demonstrate the utility of the obtained dataset on the Naamapadam-test dataset. We also release IndicNER, a multilingual IndicBERT model finetuned on Naamapadam training set. IndicNER achieves an F1 score of more than 80 for 7 out of 9 test languages. The dataset and models are available under open-source licences at https: //ai4bharat.iitm.ac.in/naamapadam.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 61st {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Mhaske, Arnav and Kedia, Harshit and Doddapaneni, Sumanth and Khapra, Mitesh M. and Kumar, Pratyush and Murthy, Rudra and Kunchukuttan, Anoop},
	year = {2023},
	pages = {10441--10456},
	file = {Mhaske et al. - 2023 - Naamapadam A Large-Scale Named Entity Annotated D.pdf:/Users/yosephineyosephine/Zotero/storage/API6TEZE/Mhaske et al. - 2023 - Naamapadam A Large-Scale Named Entity Annotated D.pdf:application/pdf},
}

@misc{yu_natural_2023,
	title = {Natural {Language} {Reasoning}, {A} {Survey}},
	url = {http://arxiv.org/abs/2303.14725},
	abstract = {This survey paper proposes a clearer view of natural language reasoning in the field of Natural Language Processing (NLP), both conceptually and practically. Conceptually, we provide a distinct definition for natural language reasoning in NLP, based on both philosophy and NLP scenarios, discuss what types of tasks require reasoning, and introduce a taxonomy of reasoning. Practically, we conduct a comprehensive literature review on natural language reasoning in NLP, mainly covering classical logical reasoning, natural language inference, multi-hop question answering, and commonsense reasoning. The paper also identifies and views backward reasoning, a powerful paradigm for multi-step reasoning, and introduces defeasible reasoning as one of the most important future directions in natural language reasoning research. We focus on single-modality unstructured natural language text, excluding neuro-symbolic techniques and mathematical reasoning.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Yu, Fei and Zhang, Hongbo and Tiwari, Prayag and Wang, Benyou},
	month = may,
	year = {2023},
	note = {arXiv:2303.14725 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: https://github.com/FreedomIntelligence/ReasoningNLP},
	file = {Yu et al. - 2023 - Natural Language Reasoning, A Survey.pdf:/Users/yosephineyosephine/Zotero/storage/G6SLP6TD/Yu et al. - 2023 - Natural Language Reasoning, A Survey.pdf:application/pdf},
}

@article{navigli_biases_2023,
	title = {Biases in {Large} {Language} {Models}: {Origins}, {Inventory}, and {Discussion}},
	volume = {15},
	issn = {1936-1955, 1936-1963},
	shorttitle = {Biases in {Large} {Language} {Models}},
	url = {https://dl.acm.org/doi/10.1145/3597307},
	doi = {10.1145/3597307},
	abstract = {In this article, we introduce and discuss the pervasive issue of bias in the large language models that are currently at the core of mainstream approaches to Natural Language Processing (NLP). We first introduce data selection bias, that is, the bias caused by the choice of texts that make up a training corpus. Then, we survey the different types of social bias evidenced in the text generated by language models trained on such corpora, ranging from gender to age, from sexual orientation to ethnicity, and from religion to culture. We conclude with directions focused on measuring, reducing, and tackling the aforementioned types of bias.},
	language = {en},
	number = {2},
	urldate = {2023-09-10},
	journal = {Journal of Data and Information Quality},
	author = {Navigli, Roberto and Conia, Simone and Ross, Björn},
	month = jun,
	year = {2023},
	pages = {1--21},
	file = {Navigli et al. - 2023 - Biases in Large Language Models Origins, Inventor.pdf:/Users/yosephineyosephine/Zotero/storage/T2LFGEGP/Navigli et al. - 2023 - Biases in Large Language Models Origins, Inventor.pdf:application/pdf},
}



@inproceedings{winata-etal-2023-nusax,
    title = {{NusaX}: {Multilingual} {Parallel} {Sentiment} {Dataset} for 10 {Indonesian} {Local} {Languages}},
    author = {Winata, Genta Indra  and
      Aji, Alham Fikri  and
      Cahyawijaya, Samuel  and
      Mahendra, Rahmad  and
      Koto, Fajri  and
      Romadhony, Ade  and
      Kurniawan, Kemal  and
      Moeljadi, David  and
      Prasojo, Radityo Eko  and
      Fung, Pascale  and
      Baldwin, Timothy  and
      Lau, Jey Han  and
      Sennrich, Rico  and
      Ruder, Sebastian},
    booktitle = {Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics},
    month = {May},
    year = {2023},
    address = {Dubrovnik, Croatia},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/2023.eacl-main.57},
    pages = {815--834},
    abstract = {Natural language processing (NLP) has a significant impact on society via technologies such as machine translation and search engines. Despite its success, NLP technology is only widely available for high-resource languages such as English and Chinese, while it remains inaccessible to many languages due to the unavailability of data resources and benchmarks. In this work, we focus on developing resources for languages in Indonesia. Despite being the second most linguistically diverse country, most languages in Indonesia are categorized as endangered and some are even extinct. We develop the first-ever parallel resource for 10 low-resource languages in Indonesia. Our resource includes sentiment and machine translation datasets, and bilingual lexicons. We provide extensive analyses and describe challenges for creating such resources. We hope this work can spark NLP research on Indonesian and other underrepresented languages.},
}


@misc{winata_nusax_nodate,
	title = {{NusaX}: {Multilingual} {Parallel} {Sentiment} {Dataset} for 10 {Indonesian} {Local} {Languages}},
	abstract = {Natural language processing (NLP) has significant impact on society via technologies such as machine translation and search engines. Despite its success, NLP technology is only widely available for high-resource languages such as English and Mandarin Chinese, and remains inaccessible to many languages due to the unavailability of data resources and benchmarks. In this work, we focus on developing resources for languages of Indonesia. Despite being the second most linguistically-diverse country, most languages in Indonesia are categorized as endangered and some are even extinct. We develop the first-ever parallel resource for 10 low-resource languages in Indonesia. Our resource includes sentiment and machine translation datasets, and bilingual lexicons. We provide extensive analysis, and describe challenges for creating such resources. Our hope is that this work will spark more NLP research on Indonesian and other underrepresented languages.},
    year ={2023},
	language = {en},
	author = {Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya, Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony, Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo, Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau, Jey Han and Sennrich, Rico and Ruder, Sebastian},
	file = {Winata et al. - NusaX Multilingual Parallel Sentiment Dataset for.pdf:/Users/yosephineyosephine/Zotero/storage/EHIXQQFM/Winata et al. - NusaX Multilingual Parallel Sentiment Dataset for.pdf:application/pdf},
}

@inproceedings{arka2011modality,
  title={On {Modality} and {Finiteness} in {Indonesian}: {Complexities} of \textit{=nya} {Nominalisation}},
  author={Arka, I Wayan and others},
  booktitle={Workshop on TAM markers and evidentiality in Indonesian Languages, Tokyo University of Foreign Studies},
  pages={17--18},
  year={2011}
}

@inproceedings{artetxe_cross-lingual_2020,
	address = {Online},
	title = {On the {Cross}-lingual {Transferability} of {Monolingual} {Representations}},
	url = {https://www.aclweb.org/anthology/2020.acl-main.421},
	doi = {10.18653/v1/2020.acl-main.421},
	abstract = {State-of-the-art unsupervised multilingual models (e.g., multilingual BERT) have been shown to generalize in a zero-shot crosslingual setting. This generalization ability has been attributed to the use of a shared subword vocabulary and joint training across multiple languages giving rise to deep multilingual abstractions. We evaluate this hypothesis by designing an alternative approach that transfers a monolingual model to new languages at the lexical level. More concretely, we ﬁrst train a transformer-based masked language model on one language, and transfer it to a new language by learning a new embedding matrix with the same masked language modeling objective—freezing parameters of all other layers. This approach does not rely on a shared vocabulary or joint training. However, we show that it is competitive with multilingual BERT on standard cross-lingual classiﬁcation benchmarks and on a new Cross-lingual Question Answering Dataset (XQuAD). Our results contradict common beliefs of the basis of the generalization ability of multilingual models and suggest that deep monolingual models learn some abstractions that generalize across languages. We also release XQuAD as a more comprehensive cross-lingual benchmark, which comprises 240 paragraphs and 1190 question-answer pairs from SQuAD v1.1 translated into ten languages by professional translators.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Artetxe, Mikel and Ruder, Sebastian and Yogatama, Dani},
	year = {2020},
	pages = {4623--4637},
	file = {Artetxe et al. - 2020 - On the Cross-lingual Transferability of Monolingua.pdf:/Users/yosephineyosephine/Zotero/storage/PWYCTRRM/Artetxe et al. - 2020 - On the Cross-lingual Transferability of Monolingua.pdf:application/pdf},
}

@article{volansky_features_2015,
	title = {On the {Features} of {Translationese}},
	volume = {30},
	issn = {2055-7671, 2055-768X},
	url = {https://academic.oup.com/dsh/article-lookup/doi/10.1093/llc/fqt031},
	doi = {10.1093/llc/fqt031},
	language = {en},
	number = {1},
	urldate = {2023-09-10},
	journal = {Digital Scholarship in the Humanities},
	author = {Volansky, V. and Ordan, N. and Wintner, S.},
	month = apr,
	year = {2015},
	pages = {98--118},
	file = {Volansky et al. - 2015 - On the features of translationese.pdf:/Users/yosephineyosephine/Zotero/storage/642IW5XB/Volansky et al. - 2015 - On the features of translationese.pdf:application/pdf},
}

@misc{zhang_opt_2022,
	title = {{OPT}: {Open} {Pre}-trained {Transformer} {Language} {Models}},
	shorttitle = {{OPT}},
	url = {http://arxiv.org/abs/2205.01068},
	abstract = {Large language models, which are often trained for hundreds of thousands of compute days, have shown remarkable capabilities for zero- and few-shot learning. Given their computational cost, these models are difﬁcult to replicate without signiﬁcant capital. For the few that are available through APIs, no access is granted to the full model weights, making them difﬁcult to study. We present Open Pre-trained Transformers (OPT), a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, which we aim to fully and responsibly share with interested researchers. We show that OPT-175B is comparable to GPT-3,1 while requiring only 1/7th the carbon footprint to develop. We are also releasing our logbook detailing the infrastructure challenges we faced, along with code for experimenting with all of the released models.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and Mihaylov, Todor and Ott, Myle and Shleifer, Sam and Shuster, Kurt and Simig, Daniel and Koura, Punit Singh and Sridhar, Anjali and Wang, Tianlu and Zettlemoyer, Luke},
	month = jun,
	year = {2022},
	note = {arXiv:2205.01068 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Zhang et al. - 2022 - OPT Open Pre-trained Transformer Language Models.pdf:/Users/yosephineyosephine/Zotero/storage/2AYAPWI3/Zhang et al. - 2022 - OPT Open Pre-trained Transformer Language Models.pdf:application/pdf},
}

@misc{chowdhery_palm_2022,
	title = {{PaLM}: {Scaling} {Language} {Modeling} with {Pathways}},
	shorttitle = {{PaLM}},
	url = {http://arxiv.org/abs/2204.02311},
	abstract = {Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-speciﬁc training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540-billion parameter, densely activated, Transformer language model, which we call Pathways Language Model (PaLM).},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sasha and Maynez, Joshua and Rao, Abhishek and Barnes, Parker and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin, Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Toju and Levskaya, Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and Garcia, Xavier and Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and Luan, David and Lim, Hyeontaek and Zoph, Barret and Spiridonov, Alexander and Sepassi, Ryan and Dohan, David and Agrawal, Shivani and Omernick, Mark and Dai, Andrew M. and Pillai, Thanumalayan Sankaranarayana and Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and Child, Rewon and Polozov, Oleksandr and Lee, Katherine and Zhou, Zongwei and Wang, Xuezhi and Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and Meier-Hellstern, Kathy and Eck, Douglas and Dean, Jeff and Petrov, Slav and Fiedel, Noah},
	month = oct,
	year = {2022},
	note = {arXiv:2204.02311 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Chowdhery et al. - 2022 - PaLM Scaling Language Modeling with Pathways.pdf:/Users/yosephineyosephine/Zotero/storage/NM9QEWVF/Chowdhery et al. - 2022 - PaLM Scaling Language Modeling with Pathways.pdf:application/pdf},
}

@misc{pandia_pragmatic_2021,
	title = {Pragmatic {Competence} of {Pre-trained} {Language} {Models} through the {Lens} of {Discourse} {Connectives}},
	url = {http://arxiv.org/abs/2109.12951},
	abstract = {As pre-trained language models (LMs) continue to dominate NLP, it is increasingly important that we understand the depth of language capabilities in these models. In this paper, we target pre-trained LMs’ competence in pragmatics, with a focus on pragmatics relating to discourse connectives. We formulate cloze-style tests using a combination of naturally-occurring data and controlled inputs drawn from psycholinguistics. We focus on testing models’ ability to use pragmatic cues to predict discourse connectives, models’ ability to understand implicatures relating to connectives, and the extent to which models show humanlike preferences regarding temporal dynamics of connectives. We ﬁnd that although models predict connectives reasonably well in the context of naturally-occurring data, when we control contexts to isolate high-level pragmatic cues, model sensitivity is much lower. Models also do not show substantial humanlike temporal preferences. Overall, the ﬁndings suggest that at present, dominant pretraining paradigms do not result in substantial pragmatic competence in our models.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Pandia, Lalchand and Cong, Yan and Ettinger, Allyson},
	month = sep,
	year = {2021},
	note = {arXiv:2109.12951 [cs]},
	keywords = {68T50, Computer Science - Computation and Language, I.2.7},
	annote = {Comment: Accepted at CoNLL 2021},
	file = {Pandia et al. - 2021 - Pragmatic competence of pre-trained language model.pdf:/Users/yosephineyosephine/Zotero/storage/HKRTFS2U/Pandia et al. - 2021 - Pragmatic competence of pre-trained language model.pdf:application/pdf},
}

@misc{parrish_nope_2021,
	title = {{NOPE}: {A} {Corpus} of {Naturally}-{Occurring} {Presuppositions} in {English}},
	shorttitle = {{NOPE}},
	url = {http://arxiv.org/abs/2109.06987},
	abstract = {Understanding language requires grasping not only the overtly stated content, but also making inferences about things that were left unsaid. These inferences include presuppositions, a phenomenon by which a listener learns about new information through reasoning about what a speaker takes as given. Presuppositions require complex understanding of the lexical and syntactic properties that trigger them as well as the broader conversational context. In this work, we introduce the Naturally-Occurring Presuppositions in English (NOPE) Corpus to investigate the context-sensitivity of 10 different types of presupposition triggers and to evaluate machine learning models’ ability to predict human inferences. We ﬁnd that most of the triggers we investigate exhibit moderate variability. We further ﬁnd that transformer-based models draw correct inferences in simple cases involving presuppositions, but they fail to capture the minority of exceptional cases in which human judgments reveal complex interactions between context and triggers.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Parrish, Alicia and Schuster, Sebastian and Warstadt, Alex and Agha, Omar and Lee, Soo-Hwan and Zhao, Zhuoye and Bowman, Samuel R. and Linzen, Tal},
	month = sep,
	year = {2021},
	note = {arXiv:2109.06987 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: CoNLL 2021. Data and code available at https://github.com/nyu-mll/nope},
	file = {Parrish et al. - 2021 - NOPE A Corpus of Naturally-Occurring Presuppositi.pdf:/Users/yosephineyosephine/Zotero/storage/23V7VBT5/Parrish et al. - 2021 - NOPE A Corpus of Naturally-Occurring Presuppositi.pdf:application/pdf},
}

@inproceedings{parrish_bbq_2022,
	address = {Dublin, Ireland},
	title = {{BBQ}: {A} hand-built bias benchmark for question answering},
	shorttitle = {{BBQ}},
	url = {https://aclanthology.org/2022.findings-acl.165},
	doi = {10.18653/v1/2022.findings-acl.165},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL} 2022},
	publisher = {Association for Computational Linguistics},
	author = {Parrish, Alicia and Chen, Angelica and Nangia, Nikita and Padmakumar, Vishakh and Phang, Jason and Thompson, Jana and Htut, Phu Mon and Bowman, Samuel},
	year = {2022},
	pages = {2086--2105},
	file = {Parrish et al. - 2022 - BBQ A hand-built bias benchmark for question answ.pdf:/Users/yosephineyosephine/Zotero/storage/6VQ6GB8V/Parrish et al. - 2022 - BBQ A hand-built bias benchmark for question answ.pdf:application/pdf},
}

@article{rogers_qa_2023,
	title = {{QA} {Dataset} {Explosion}: {A} {Taxonomy} of {NLP} {Resources} for {Question} {Answering} and {Reading} {Comprehension}},
	volume = {55},
	issn = {0360-0300, 1557-7341},
	shorttitle = {{QA} {Dataset} {Explosion}},
	url = {http://arxiv.org/abs/2107.12708},
	doi = {10.1145/3560260},
	abstract = {Alongside huge volumes of research on deep learning models in NLP in the recent years, there has been also much work on benchmark datasets needed to track modeling progress. Question answering and reading comprehension have been particularly prolific in this regard, with over 80 new datasets appearing in the past two years. This study is the largest survey of the field to date. We provide an overview of the various formats and domains of the current resources, highlighting the current lacunae for future work. We further discuss the current classifications of "skills" that question answering/reading comprehension systems are supposed to acquire, and propose a new taxonomy. The supplementary materials survey the current multilingual resources and monolingual resources for languages other than English, and we discuss the implications of over-focusing on English. The study is aimed at both practitioners looking for pointers to the wealth of existing data, and at researchers working on new resources.},
	language = {en},
	number = {10},
	urldate = {2023-09-10},
	journal = {ACM Computing Surveys},
	author = {Rogers, Anna and Gardner, Matt and Augenstein, Isabelle},
	month = oct,
	year = {2023},
	note = {arXiv:2107.12708 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	pages = {1--45},
	annote = {Comment: Published in ACM Comput. Surv (2022). This version differs from the final version in that section 7 ("Languages") is not in the main paper rather than the supplementary materials},
	file = {Rogers et al. - 2023 - QA Dataset Explosion A Taxonomy of NLP Resources .pdf:/Users/yosephineyosephine/Zotero/storage/E26QD8HL/Rogers et al. - 2023 - QA Dataset Explosion A Taxonomy of NLP Resources .pdf:application/pdf},
}

@inproceedings{qiao_reasoning_2023,
	address = {Toronto, Canada},
	title = {Reasoning with {Language} {Model} {Prompting}: {A} {Survey}},
	shorttitle = {Reasoning with {Language} {Model} {Prompting}},
	url = {https://aclanthology.org/2023.acl-long.294},
	doi = {10.18653/v1/2023.acl-long.294},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 61st {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Qiao, Shuofei and Ou, Yixin and Zhang, Ningyu and Chen, Xiang and Yao, Yunzhi and Deng, Shumin and Tan, Chuanqi and Huang, Fei and Chen, Huajun},
	year = {2023},
	pages = {5368--5393},
	file = {Qiao et al. - 2023 - Reasoning with Language Model Prompting A Survey.pdf:/Users/yosephineyosephine/Zotero/storage/VRERAEPK/Qiao et al. - 2023 - Reasoning with Language Model Prompting A Survey.pdf:application/pdf},
}

@misc{wu_recursively_2021,
	title = {Recursively {Summarizing} {Books} with {Human} {Feedback}},
	url = {http://arxiv.org/abs/2109.10862},
	abstract = {A major challenge for scaling machine learning is training models to perform tasks that are very difficult or time-consuming for humans to evaluate. We present progress on this problem on the task of abstractive summarization of entire fiction novels. Our method combines learning from human feedback with recursive task decomposition: we use models trained on smaller parts of the task to assist humans in giving feedback on the broader task. We collect a large volume of demonstrations and comparisons from human labelers, and fine-tune GPT-3 using behavioral cloning and reward modeling to do summarization recursively. At inference time, the model first summarizes small sections of the book and then recursively summarizes these summaries to produce a summary of the entire book. Our human labelers are able to supervise and evaluate the models quickly, despite not having read the entire books themselves. Our resulting model generates sensible summaries of entire books, even matching the quality of human-written summaries in a few cases (\${\textbackslash}sim5{\textbackslash}\%\$ of books). We achieve state-of-the-art results on the recent BookSum dataset for book-length summarization. A zero-shot question-answering model using these summaries achieves state-of-the-art results on the challenging NarrativeQA benchmark for answering questions about books and movie scripts. We release datasets of samples from our model.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Wu, Jeff and Ouyang, Long and Ziegler, Daniel M. and Stiennon, Nisan and Lowe, Ryan and Leike, Jan and Christiano, Paul},
	month = {September},
	year = {2021},
	note = {arXiv:2109.10862 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Wu et al. - 2021 - Recursively Summarizing Books with Human Feedback.pdf:/Users/yosephineyosephine/Zotero/storage/2LAKYXYF/Wu et al. - 2021 - Recursively Summarizing Books with Human Feedback.pdf:application/pdf},
}
@phdthesis{ross1967constraints,
    author = {Ross, John Robert},
    title = {Constraints on {Variables} in {Syntax}.},
    school = {Massachusetts Institute of Technology},
    year = {1967}
}
@incollection{Annamalai2019,
  author={Annamalai, Elay},
  year = {2019}, 
  title = {Modern {Tamil}}, 
  editor = {Sanford B, Steever}, 
  booktitle = {The Dravidian Languages}, 
  publisher= {Routledge}, address={London}, 
}
@incollection{Fortin2019,
  author = {Fortin, Catherine Rose},
  year= {2019}, 
  title = {Indonesian}, 
  editor = {Jeroen, van Craenenbroeck and Tanja, Temmerman}, 
  booktitle = {The Oxford Handbook of Elipsis}, 
  publisher= {Oxford University Press}, 
    address={New York}, 
}
@incollection{vonfintel2004,
    author = {von Fintel, Kai},
    title = {Would {You} {Believe} {It?} {The} {King} of {France} {Is} {Back!} ({Presuppositions} and {Truth-value} {Intuitions})},
    booktitle = {Descriptions and Beyond},
    publisher = {Oxford}, 
    address = {New York},
    year = {2004}
}
@article{cole2008voice,
  title={Voice in Malay/Indonesian},
  author={Cole, Peter and Hermon, Gabriella and others},
  journal={Lingua},
  volume={118},
  number={10},
  pages={1500--1553},
  year={2008},
  publisher={Elsevier}
}
@article{purwo1988voice,
  title={Voice in {Indonesian}: A {Discourse} {Study}},
  author={Purwo, Bambang},
  journal={Passive and voice},
  volume={16},
  pages={195},
  year={1988},
  publisher={John Benjamins Publishing Company}
}

@inproceedings{freitag2022results,
  title={Results of {WMT22} {Metrics} {Shared} {Task}: {Stop} {Using} {BLEU} -- {Neural} {Metrics} are {Better} and {More} {Robust}},
  author={Freitag, Markus and Rei, Ricardo and Mathur, Nitika and Lo, Chi-kiu and Stewart, Craig and Avramidis, Eleftherios and Kocmi, Tom and Foster, George and Lavie, Alon and Martins, Andr{\'e} FT},
  booktitle={Proceedings of the Seventh Conference on Machine Translation (WMT)},
  pages={46--68},
  year={2022}
}

@inproceedings{lin2004rouge,
  title={Rouge: A {Package} for {Automatic} {Evaluation} of {Summaries}},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}

@article{sato_p-stranding_2011,
	title = {P-stranding under {Sluicing} and {Repair} {By} {Ellipsis}: {Why} {Is} {Indonesian} {(Not)} {Special?}},
	volume = {20},
	issn = {0925-8558, 1572-8560},
	shorttitle = {P-stranding under sluicing and repair by ellipsis},
	url = {http://link.springer.com/10.1007/s10831-011-9082-3},
	doi = {10.1007/s10831-011-9082-3},
	abstract = {This paper presents novel evidence that P-stranding in Indonesian contradicts Merchant’s (The syntax of silence: sluicing, islands, and the theory of ellipsis, 2001) generalization that P-stranding under sluicing is possible only in those languages that allow this option under regular wh-movement. It is proposed that this apparently special pattern is accounted for by the recent idea of repair by ellipsis (Ross, in Binnick et al. (eds.) Papers from the 5th Regional Meeting of the Chicago Linguistic Society, 1969; Merchant, The syntax of silence: sluicing, islands, and the theory of ellipsis; Lasnik, M: Kim and Strauss (eds.) Proceedings of NELS 31, 2001). Speciﬁcally, the failure of percolation of the wh-feature is repaired by PF deletion. P-stranding in French and German cannot be so repaired since the violation in question is a strictly computational violation caused by D-to-P incorporation. Our cross-linguistic examination of P-stranding suggests a bifurcated view of violations (Boeckx and Lasnik in Linguistic Inquiry 37: 150–155, 2006); violations pertaining to the syntax-phonology interface in principle can be repaired whereas violations incurred within the syntactic computation cannot. This contrast in ‘‘reparability’’ naturally falls out from a minimalist architecture of the syntaxphonology interface. A broader implication of the present analysis is that syntax is itself not a crash-proof system in the sense of Frampton and Gutmann (Syntax 2:1–27, 1999; Derivation and explanation in the minimalist program. Blackwell, Oxford, 2002); it could produce certain operational failures, but language-particular parameters afford a bit of leeway for PF to remedy them at the syntax-phonology interface.},
	language = {en},
	number = {4},
	urldate = {2023-09-10},
	journal = {Journal of East Asian Linguistics},
	author = {Sato, Yosuke},
	month = {November},
	year = {2011},
	pages = {339--382},
	file = {Sato - 2011 - P-stranding under sluicing and repair by ellipsis.pdf:/Users/yosephineyosephine/Zotero/storage/XPBQZTKT/Sato - 2011 - P-stranding under sluicing and repair by ellipsis.pdf:application/pdf},
}
@incollection{grice1975logic,
  title={Logic and {Conversation}},
  author={Grice, Herbert P},
  booktitle={Speech Acts},
  pages={41--58},
  year={1975},
  publisher={Brill}
}
@article{potts2015presupposition,
  title={Presupposition and {Implicature}},
  author={Potts, Christopher},
  journal={The Handbook of Contemporary Semantic Theory},
  pages={168--202},
  year={2015},
  publisher={Wiley Online Library}
}

@book{austronesian2016afla,
  title={AFLA 23: the Proceedings of the 23rd meeting of the Austronesian Formal Linguistics Association},
  author={Austronesian Formal Linguistics Association and others},
  year={2016},
  publisher={Asia-Pacific Linguistics, School of Culture, History and Language, College~…}

}

@article{sato_actionresult_2021,
	title = {Action/{Result} in {Indonesian} {Accomplishment} {Verbs} and the {Agent} {Control} {Hypothesis}},
	volume = {60},
	issn = {1527-9421},
	url = {https://muse.jhu.edu/article/836175},
	doi = {10.1353/ol.2021.0017},
	language = {en},
	number = {2},
	urldate = {2023-09-10},
	journal = {Oceanic Linguistics},
	author = {Sato, Yosuke},
	year = {2021},
	pages = {263--301},
	file = {Sato - 2021 - ActionResult in Indonesian Accomplishment Verbs a.pdf:/Users/yosephineyosephine/Zotero/storage/AH7IMIJJ/Sato - 2021 - ActionResult in Indonesian Accomplishment Verbs a.pdf:application/pdf},
}

@incollection{chevillard_tamil_2004,
	title = {The {Tamil} {Case} {System}},
	isbn = {978-81-8470-116-6 979-10-365-5621-0},
	url = {http://books.openedition.org/ifp/7736},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {South-{Indian} {Horizons}},
	publisher = {Institut Français de Pondichéry},
	author = {Schiffman, Harold F.},
	editor = {Chevillard, Jean-Luc and Wilden, Eva},
	year = {2004},
	doi = {10.4000/books.ifp.7736},
	pages = {293--305},
	file = {Schiffman - 2004 - The Tamil Case System.pdf:/Users/yosephineyosephine/Zotero/storage/PUDYY4BI/Schiffman - 2004 - The Tamil Case System.pdf:application/pdf},
}

@inproceedings{wu_self-adaptive_2023,
	address = {Toronto, Canada},
	title = {Self-{Adaptive} {In}-{Context} {Learning}: {An} {Information} {Compression} {Perspective} for {In}-{Context} {Example} {Selection} and {Ordering}},
	shorttitle = {Self-{Adaptive} {In}-{Context} {Learning}},
	url = {https://aclanthology.org/2023.acl-long.79},
	doi = {10.18653/v1/2023.acl-long.79},
	abstract = {Despite the impressive few-shot performance of in-context learning (ICL), it remains a common practice to randomly select examples to serve as the context. In this paper, we advocate self-adaptive in-context learning, a new principle for ICL, in which the self-adaption mechanism is introduced to help each input ﬁnd an in-context example organization (i.e., selection and permutation) that can derive the correct output, thus maximizing performance. To validate the effectiveness of self-adaptive ICL, we propose a general select-then-rank framework and a set of novel selection and ranking algorithms. Upon extensive evaluation on eight different NLP datasets, our self-adaptive ICL method achieves a 40\% relative improvement over the common practice setting. Further analysis reveals the great potential of selfadaptive ICL as a promising method to close the gap between ICL and ﬁnetuning. Our code will be released to facilitate future research.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 61st {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Wu, Zhiyong and Wang, Yaoxiang and Ye, Jiacheng and Kong, Lingpeng},
	year = {2023},
	pages = {1423--1436},
	file = {Wu et al. - 2023 - Self-Adaptive In-Context Learning An Information .pdf:/Users/yosephineyosephine/Zotero/storage/WJ7QVAJY/Wu et al. - 2023 - Self-Adaptive In-Context Learning An Information .pdf:application/pdf},

}
@inproceedings{simons2010projects,
  title={What {Projects} and {Why}},
  author={Simons, Mandy and Tonhauser, Judith and Beaver, David and Roberts, Craige},
  booktitle={Semantics and Linguistic Theory},
  volume={20},
  pages={309--327},
  year={2010}
}

@misc{solaiman_evaluating_2023,
	title = {Evaluating the {Social} {Impact} of {Generative} {AI} {Systems} in {Systems} and {Society}},
	url = {http://arxiv.org/abs/2306.05949},
	abstract = {Generative AI systems across modalities, ranging from text, image, audio, and video, have broad social impacts, but there exists no official standard for means of evaluating those impacts and which impacts should be evaluated. We move toward a standard approach in evaluating a generative AI system for any modality, in two overarching categories: what is able to be evaluated in a base system that has no predetermined application and what is able to be evaluated in society. We describe specific social impact categories and how to approach and conduct evaluations in the base technical system, then in people and society. Our framework for a base system defines seven categories of social impact: bias, stereotypes, and representational harms; cultural values and sensitive content; disparate performance; privacy and data protection; financial costs; environmental costs; and data and content moderation labor costs. Suggested methods for evaluation apply to all modalities and analyses of the limitations of existing evaluations serve as a starting point for necessary investment in future evaluations. We offer five overarching categories for what is able to be evaluated in society, each with their own subcategories: trustworthiness and autonomy; inequality, marginalization, and violence; concentration of authority; labor and creativity; and ecosystem and environment. Each subcategory includes recommendations for mitigating harm. We are concurrently crafting an evaluation repository for the AI research community to contribute existing evaluations along the given categories. This version will be updated following a CRAFT session at ACM FAccT 2023.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Solaiman, Irene and Talat, Zeerak and Agnew, William and Ahmad, Lama and Baker, Dylan and Blodgett, Su Lin and Daumé III, Hal and Dodge, Jesse and Evans, Ellie and Hooker, Sara and Jernite, Yacine and Luccioni, Alexandra Sasha and Lusoli, Alberto and Mitchell, Margaret and Newman, Jessica and Png, Marie-Therese and Strait, Andrew and Vassilev, Apostol},
	month = {June},
	year = {2023},
	note = {arXiv:2306.05949 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society},
	file = {Solaiman et al. - 2023 - Evaluating the Social Impact of Generative AI Syst.pdf:/Users/yosephineyosephine/Zotero/storage/FKCT9A7D/Solaiman et al. - 2023 - Evaluating the Social Impact of Generative AI Syst.pdf:application/pdf},
}

@inproceedings{someya-oseki-2023-jblimp,
    title = {{JBLiMP}: {Japanese} {Benchmark} of {Linguistic} {Minimal} {Pairs}},
    author = {Someya, Taiga  and
      Oseki, Yohei},
    booktitle = {Findings of the Association for Computational Linguistics: EACL 2023},
    month = {May},
    year = {2023},
    address = {Dubrovnik, Croatia},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/2023.findings-eacl.117},
    pages = {1581--1594},
    abstract = {In this paper, we introduce JBLiMP (Japanese Benchmark of Linguistic Minimal Pairs), a novel dataset for targeted syntactic evaluations of language models in Japanese. JBLiMP consists of 331 minimal pairs, which are created based on acceptability judgments extracted from journal articles in theoretical linguistics. These minimal pairs are grouped into 11 categories, each covering a different linguistic phenomenon. JBLiMP is unique in that it successfully combines two important features independently observed in existing datasets: (i) coverage of complex linguistic phenomena (cf. CoLA) and (ii) presentation of sentences as minimal pairs (cf. BLiMP). In addition, JBLiMP is the first dataset for targeted syntactic evaluations of language models in Japanese, thus allowing the comparison of syntactic knowledge of language models across different languages. We then evaluate the syntactic knowledge of several language models on JBLiMP: GPT-2, LSTM, and n-gram language models. The results demonstrated that all the architectures achieved comparable overall accuracies around 75{\%}. Error analyses by linguistic phenomenon further revealed that these language models successfully captured local dependencies like nominal structures, but not long-distance dependencies such as verbal agreement and binding.},
}




@misc{chang_speak_2023,
	title = {Speak, {Memory}: {An} {Archaeology} of {Books} {Known} to {ChatGPT}/{GPT}-4},
	shorttitle = {Speak, {Memory}},
	url = {http://arxiv.org/abs/2305.00118},
	abstract = {In this work, we carry out a data archaeology to infer books that are known to ChatGPT and GPT-4 using a name cloze membership inference query. We ﬁnd that OpenAI models have memorized a wide collection of copyrighted materials, and that the degree of memorization is tied to the frequency with which passages of those books appear on the web. The ability of these models to memorize an unknown set of books complicates assessments of measurement validity for cultural analytics by contaminating test data; we show that models perform much better on memorized books than on nonmemorized books for downstream tasks. We argue that this supports a case for open models whose training data is known.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Chang, Kent K. and Cramer, Mackenzie and Soni, Sandeep and Bamman, David},
	month = {April},
	year = {2023},
	note = {arXiv:2305.00118 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Chang et al. - 2023 - Speak, Memory An Archaeology of Books Known to Ch.pdf:/Users/yosephineyosephine/Zotero/storage/BKYR89QX/Chang et al. - 2023 - Speak, Memory An Archaeology of Books Known to Ch.pdf:application/pdf},
}

@misc{srivastava_beyond_2023,
	title = {Beyond the {Imitation} {Game}: {Quantifying} and {Extrapolating} the {Capabilities} of {Language} {Models}},
	shorttitle = {Beyond the {Imitation} {Game}},
	url = {http://arxiv.org/abs/2206.04615},
	abstract = {Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R. and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adrià and Kluska, Agnieszka and Lewkowycz, Aitor and Agarwal, Akshat and Power, Alethea and Ray, Alex and Warstadt, Alex and Kocurek, Alexander W. and Safaya, Ali and Tazarv, Ali and Xiang, Alice and Parrish, Alicia and Nie, Allen and Hussain, Aman and Askell, Amanda and Dsouza, Amanda and Slone, Ambrose and Rahane, Ameet and Iyer, Anantharaman S. and Andreassen, Anders and Madotto, Andrea and Santilli, Andrea and Stuhlmüller, Andreas and Dai, Andrew and La, Andrew and Lampinen, Andrew and Zou, Andy and Jiang, Angela and Chen, Angelica and Vuong, Anh and Gupta, Animesh and Gottardi, Anna and Norelli, Antonio and Venkatesh, Anu and Gholamidavoodi, Arash and Tabassum, Arfa and Menezes, Arul and Kirubarajan, Arun and Mullokandov, Asher and Sabharwal, Ashish and Herrick, Austin and Efrat, Avia and Erdem, Aykut and Karakaş, Ayla and Roberts, B. Ryan and Loe, Bao Sheng and Zoph, Barret and Bojanowski, Bartłomiej and Özyurt, Batuhan and Hedayatnia, Behnam and Neyshabur, Behnam and Inden, Benjamin and Stein, Benno and Ekmekci, Berk and Lin, Bill Yuchen and Howald, Blake and Orinion, Bryan and Diao, Cameron and Dour, Cameron and Stinson, Catherine and Argueta, Cedrick and Ramírez, César Ferri and Singh, Chandan and Rathkopf, Charles and Meng, Chenlin and Baral, Chitta and Wu, Chiyu and Callison-Burch, Chris and Waites, Chris and Voigt, Christian and Manning, Christopher D. and Potts, Christopher and Ramirez, Cindy and Rivera, Clara E. and Siro, Clemencia and Raffel, Colin and Ashcraft, Courtney and Garbacea, Cristina and Sileo, Damien and Garrette, Dan and Hendrycks, Dan and Kilman, Dan and Roth, Dan and Freeman, Daniel and Khashabi, Daniel and Levy, Daniel and González, Daniel Moseguí and Perszyk, Danielle and Hernandez, Danny and Chen, Danqi and Ippolito, Daphne and Gilboa, Dar and Dohan, David and Drakard, David and Jurgens, David and Datta, Debajyoti and Ganguli, Deep and Emelin, Denis and Kleyko, Denis and Yuret, Deniz and Chen, Derek and Tam, Derek and Hupkes, Dieuwke and Misra, Diganta and Buzan, Dilyar and Mollo, Dimitri Coelho and Yang, Diyi and Lee, Dong-Ho and Schrader, Dylan and Shutova, Ekaterina and Cubuk, Ekin Dogus and Segal, Elad and Hagerman, Eleanor and Barnes, Elizabeth and Donoway, Elizabeth and Pavlick, Ellie and Rodola, Emanuele and Lam, Emma and Chu, Eric and Tang, Eric and Erdem, Erkut and Chang, Ernie and Chi, Ethan A. and Dyer, Ethan and Jerzak, Ethan and Kim, Ethan and Manyasi, Eunice Engefu and Zheltonozhskii, Evgenii and Xia, Fanyue and Siar, Fatemeh and Martínez-Plumed, Fernando and Happé, Francesca and Chollet, Francois and Rong, Frieda and Mishra, Gaurav and Winata, Genta Indra and de Melo, Gerard and Kruszewski, Germán and Parascandolo, Giambattista and Mariani, Giorgio and Wang, Gloria and Jaimovitch-López, Gonzalo and Betz, Gregor and Gur-Ari, Guy and Galijasevic, Hana and Kim, Hannah and Rashkin, Hannah and Hajishirzi, Hannaneh and Mehta, Harsh and Bogar, Hayden and Shevlin, Henry and Schütze, Hinrich and Yakura, Hiromu and Zhang, Hongming and Wong, Hugh Mee and Ng, Ian and Noble, Isaac and Jumelet, Jaap and Geissinger, Jack and Kernion, Jackson and Hilton, Jacob and Lee, Jaehoon and Fisac, Jaime Fernández and Simon, James B. and Koppel, James and Zheng, James and Zou, James and Kocoń, Jan and Thompson, Jana and Wingfield, Janelle and Kaplan, Jared and Radom, Jarema and Sohl-Dickstein, Jascha and Phang, Jason and Wei, Jason and Yosinski, Jason and Novikova, Jekaterina and Bosscher, Jelle and Marsh, Jennifer and Kim, Jeremy and Taal, Jeroen and Engel, Jesse and Alabi, Jesujoba and Xu, Jiacheng and Song, Jiaming and Tang, Jillian and Waweru, Joan and Burden, John and Miller, John and Balis, John U. and Batchelder, Jonathan and Berant, Jonathan and Frohberg, Jörg and Rozen, Jos and Hernandez-Orallo, Jose and Boudeman, Joseph and Guerr, Joseph and Jones, Joseph and Tenenbaum, Joshua B. and Rule, Joshua S. and Chua, Joyce and Kanclerz, Kamil and Livescu, Karen and Krauth, Karl and Gopalakrishnan, Karthik and Ignatyeva, Katerina and Markert, Katja and Dhole, Kaustubh D. and Gimpel, Kevin and Omondi, Kevin and Mathewson, Kory and Chiafullo, Kristen and Shkaruta, Ksenia and Shridhar, Kumar and McDonell, Kyle and Richardson, Kyle and Reynolds, Laria and Gao, Leo and Zhang, Li and Dugan, Liam and Qin, Lianhui and Contreras-Ochando, Lidia and Morency, Louis-Philippe and Moschella, Luca and Lam, Lucas and Noble, Lucy and Schmidt, Ludwig and He, Luheng and Colón, Luis Oliveros and Metz, Luke and Şenel, Lütfi Kerem and Bosma, Maarten and Sap, Maarten and ter Hoeve, Maartje and Farooqi, Maheen and Faruqui, Manaal and Mazeika, Mantas and Baturan, Marco and Marelli, Marco and Maru, Marco and Quintana, Maria Jose Ramírez and Tolkiehn, Marie and Giulianelli, Mario and Lewis, Martha and Potthast, Martin and Leavitt, Matthew L. and Hagen, Matthias and Schubert, Mátyás and Baitemirova, Medina Orduna and Arnaud, Melody and McElrath, Melvin and Yee, Michael A. and Cohen, Michael and Gu, Michael and Ivanitskiy, Michael and Starritt, Michael and Strube, Michael and Swędrowski, Michał and Bevilacqua, Michele and Yasunaga, Michihiro and Kale, Mihir and Cain, Mike and Xu, Mimee and Suzgun, Mirac and Walker, Mitch and Tiwari, Mo and Bansal, Mohit and Aminnaseri, Moin and Geva, Mor and Gheini, Mozhdeh and T, Mukund Varma and Peng, Nanyun and Chi, Nathan A. and Lee, Nayeon and Krakover, Neta Gur-Ari and Cameron, Nicholas and Roberts, Nicholas and Doiron, Nick and Martinez, Nicole and Nangia, Nikita and Deckers, Niklas and Muennighoff, Niklas and Keskar, Nitish Shirish and Iyer, Niveditha S. and Constant, Noah and Fiedel, Noah and Wen, Nuan and Zhang, Oliver and Agha, Omar and Elbaghdadi, Omar and Levy, Omer and Evans, Owain and Casares, Pablo Antonio Moreno and Doshi, Parth and Fung, Pascale and Liang, Paul Pu and Vicol, Paul and Alipoormolabashi, Pegah and Liao, Peiyuan and Liang, Percy and Chang, Peter and Eckersley, Peter and Htut, Phu Mon and Hwang, Pinyu and Miłkowski, Piotr and Patil, Piyush and Pezeshkpour, Pouya and Oli, Priti and Mei, Qiaozhu and Lyu, Qing and Chen, Qinlang and Banjade, Rabin and Rudolph, Rachel Etta and Gabriel, Raefer and Habacker, Rahel and Risco, Ramon and Millière, Raphaël and Garg, Rhythm and Barnes, Richard and Saurous, Rif A. and Arakawa, Riku and Raymaekers, Robbe and Frank, Robert and Sikand, Rohan and Novak, Roman and Sitelew, Roman and LeBras, Ronan and Liu, Rosanne and Jacobs, Rowan and Zhang, Rui and Salakhutdinov, Ruslan and Chi, Ryan and Lee, Ryan and Stovall, Ryan and Teehan, Ryan and Yang, Rylan and Singh, Sahib and Mohammad, Saif M. and Anand, Sajant and Dillavou, Sam and Shleifer, Sam and Wiseman, Sam and Gruetter, Samuel and Bowman, Samuel R. and Schoenholz, Samuel S. and Han, Sanghyun and Kwatra, Sanjeev and Rous, Sarah A. and Ghazarian, Sarik and Ghosh, Sayan and Casey, Sean and Bischoff, Sebastian and Gehrmann, Sebastian and Schuster, Sebastian and Sadeghi, Sepideh and Hamdan, Shadi and Zhou, Sharon and Srivastava, Shashank and Shi, Sherry and Singh, Shikhar and Asaadi, Shima and Gu, Shixiang Shane and Pachchigar, Shubh and Toshniwal, Shubham and Upadhyay, Shyam and Shyamolima and Debnath and Shakeri, Siamak and Thormeyer, Simon and Melzi, Simone and Reddy, Siva and Makini, Sneha Priscilla and Lee, Soo-Hwan and Torene, Spencer and Hatwar, Sriharsha and Dehaene, Stanislas and Divic, Stefan and Ermon, Stefano and Biderman, Stella and Lin, Stephanie and Prasad, Stephen and Piantadosi, Steven T. and Shieber, Stuart M. and Misherghi, Summer and Kiritchenko, Svetlana and Mishra, Swaroop and Linzen, Tal and Schuster, Tal and Li, Tao and Yu, Tao and Ali, Tariq and Hashimoto, Tatsu and Wu, Te-Lin and Desbordes, Théo and Rothschild, Theodore and Phan, Thomas and Wang, Tianle and Nkinyili, Tiberius and Schick, Timo and Kornev, Timofei and Tunduny, Titus and Gerstenberg, Tobias and Chang, Trenton and Neeraj, Trishala and Khot, Tushar and Shultz, Tyler and Shaham, Uri and Misra, Vedant and Demberg, Vera and Nyamai, Victoria and Raunak, Vikas and Ramasesh, Vinay and Prabhu, Vinay Uday and Padmakumar, Vishakh and Srikumar, Vivek and Fedus, William and Saunders, William and Zhang, William and Vossen, Wout and Ren, Xiang and Tong, Xiaoyu and Zhao, Xinran and Wu, Xinyi and Shen, Xudong and Yaghoobzadeh, Yadollah and Lakretz, Yair and Song, Yangqiu and Bahri, Yasaman and Choi, Yejin and Yang, Yichi and Hao, Yiding and Chen, Yifu and Belinkov, Yonatan and Hou, Yu and Hou, Yufang and Bai, Yuntao and Seid, Zachary and Zhao, Zhuoye and Wang, Zijian and Wang, Zijie J. and Wang, Zirui and Wu, Ziyi},
	month = {June},
	year = {2023},
	note = {arXiv:2206.04615 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 27 pages, 17 figures + references and appendices, repo: https://github.com/google/BIG-bench},
	file = {Srivastava et al. - 2023 - Beyond the Imitation Game Quantifying and extrapo.pdf:/Users/yosephineyosephine/Zotero/storage/CHUA4BVL/Srivastava et al. - 2023 - Beyond the Imitation Game Quantifying and extrapo.pdf:application/pdf},
}

@misc{fabbri_summeval_2021,
	title = {{SummEval}: {Re}-evaluating {Summarization} {Evaluation}},
	shorttitle = {{SummEval}},
	url = {http://arxiv.org/abs/2007.12626},
	abstract = {The scarcity of comprehensive up-to-date studies on evaluation metrics for text summarization and the lack of consensus regarding evaluation protocols continue to inhibit progress. We address the existing shortcomings of summarization evaluation methods along ﬁve dimensions: 1) we reevaluate 14 automatic evaluation metrics in a comprehensive and consistent fashion using neural summarization model outputs along with expert and crowd-sourced human annotations, 2) we consistently benchmark 23 recent summarization models using the aforementioned automatic evaluation metrics, 3) we assemble the largest collection of summaries generated by models trained on the CNN/DailyMail news dataset and share it in a uniﬁed format, 4) we implement and share a toolkit that provides an extensible and uniﬁed API for evaluating summarization models across a broad range of automatic metrics, 5) we assemble and share the largest and most diverse, in terms of model types, collection of human judgments of model-generated summaries on the CNN/Daily Mail dataset annotated by both expert judges and crowd-source workers. We hope that this work will help promote a more complete evaluation protocol for text summarization as well as advance research in developing evaluation metrics that better correlate with human judgments.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Fabbri, Alexander R. and Kryściński, Wojciech and McCann, Bryan and Xiong, Caiming and Socher, Richard and Radev, Dragomir},
	month = {February},
	year = {2021},
	note = {arXiv:2007.12626 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: 11 pages, 4 tables, 2 figures; pre-MIT Press publication version},
	file = {Fabbri et al. - 2021 - SummEval Re-evaluating Summarization Evaluation.pdf:/Users/yosephineyosephine/Zotero/storage/46MDN6YW/Fabbri et al. - 2021 - SummEval Re-evaluating Summarization Evaluation.pdf:application/pdf},
}

@inproceedings{wang_superglue_NEURIPS2019_4496bf24,
 author = {Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {{SuperGLUE}: {A} {Stickier} {Benchmark} for {General-Purpose} {Language} {Understanding} {Systems}},
 url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/4496bf24afe7fab6f046bf4923da8de6-Paper.pdf},
 volume = {32},
 year = {2019}
}


@misc{wang_superglue_2019,
	title = {{SuperGLUE}: {A} {Stickier} {Benchmark} for {General}-{Purpose} {Language} {Understanding} {Systems}},
	abstract = {In the last year, new models and methods for pretraining and transfer learning have driven striking performance improvements across a range of language understanding tasks. The GLUE benchmark, introduced a little over one year ago, offers a single-number metric that summarizes progress on a diverse set of such tasks, but performance on the benchmark has recently surpassed the level of non-expert humans, suggesting limited headroom for further research. In this paper we present SuperGLUE, a new benchmark styled after GLUE with a new set of more difﬁcult language understanding tasks, a software toolkit, and a public leaderboard. SuperGLUE is available at super.gluebenchmark.com.},
	language = {en},
	author = {Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
    year = {2019},
	file = {Wang et al. - SuperGLUE A Stickier Benchmark for General-Purpos.pdf:/Users/yosephineyosephine/Zotero/storage/U849EETB/Wang et al. - SuperGLUE A Stickier Benchmark for General-Purpos.pdf:application/pdf},
}

@book{lehmann_grammar_1993,
	address = {Pondicherry},
	edition = {second},
	series = {Pondicherry {Institute} of {Linguistics} and {Culture} publication},
	title = {A {Grammar} of {Modern} {Tamil}},
	isbn = {978-81-85452-03-6},
	language = {en},
	
	publisher = {Pondicherry Institute of Linguistics and Culture},
	author = {Lehmann, Thomas},
	year = {1993},
	file = {Lehmann - 1993 - A grammar of modern Tamil.pdf:/Users/yosephineyosephine/Zotero/storage/LUT3AZ5R/Lehmann - 1993 - A grammar of modern Tamil.pdf:application/pdf},
}

@misc{tang_large_2023,
	title = {Large {Language} {Models} are {In}-{Context} {Semantic} {Reasoners} rather than {Symbolic} {Reasoners}},
	url = {http://arxiv.org/abs/2305.14825},
	abstract = {The emergent few-shot reasoning capabilities of Large Language Models (LLMs) have excited the natural language and machine learning community over recent years. Despite of numerous successful applications, the underlying mechanism of such in-context capabilities still remains unclear. In this work, we hypothesize that the learned semantics of language tokens do the most heavy lifting during the reasoning process. Different from human’s symbolic reasoning process, the semantic representations of LLMs could create strong connections among tokens, thus composing a superficial logical chain. To test our hypothesis, we decouple semantics from the language reasoning process and evaluate three kinds of reasoning abilities, i.e., deduction, induction and abduction. Our findings reveal that semantics play a vital role in LLMs’ in-context reasoning—LLMs perform significantly better when semantics are consistent with commonsense but struggle to solve symbolic or counter-commonsense reasoning tasks by leveraging in-context new knowledge. The surprising observations question whether modern LLMs have mastered the inductive, deductive and abductive reasoning abilities as in human intelligence, and motivate research on unveiling the magic existing within the black-box LLMs. On the whole, our analysis provides a novel perspective on the role of semantics in developing and evaluating language models’ reasoning abilities. Code is available at https://github.com/XiaojuanTang/ICSR.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Tang, Xiaojuan and Zheng, Zilong and Li, Jiaqi and Meng, Fanxu and Zhu, Song-Chun and Liang, Yitao and Zhang, Muhan},
	month = jun,
	year = {2023},
	note = {arXiv:2305.14825 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Tang et al. - 2023 - Large Language Models are In-Context Semantic Reas.pdf:/Users/yosephineyosephine/Zotero/storage/3REJV5P3/Tang et al. - 2023 - Large Language Models are In-Context Semantic Reas.pdf:application/pdf},
}

@inproceedings{marvin_targeted_2018,
	address = {Brussels, Belgium},
	title = {Targeted {Syntactic} {Evaluation} of {Language} {Models}},
	url = {http://aclweb.org/anthology/D18-1151},
	doi = {10.18653/v1/D18-1151},
	abstract = {We present a dataset for evaluating the grammaticality of the predictions of a language model. We automatically construct a large number of minimally different pairs of English sentences, each consisting of a grammatical and an ungrammatical sentence. The sentence pairs represent different variations of structure-sensitive phenomena: subject-verb agreement, reﬂexive anaphora and negative polarity items. We expect a language model to assign a higher probability to the grammatical sentence than the ungrammatical one. In an experiment using this data set, an LSTM language model performed poorly on many of the constructions. Multi-task training with a syntactic objective (CCG supertagging) improved the LSTM’s accuracy, but a large gap remained between its performance and the accuracy of human participants recruited online. This suggests that there is considerable room for improvement over LSTMs in capturing syntax in a language model.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 2018 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Marvin, Rebecca and Linzen, Tal},
	year = {2018},
	pages = {1192--1202},
	file = {Marvin and Linzen - 2018 - Targeted Syntactic Evaluation of Language Models.pdf:/Users/yosephineyosephine/Zotero/storage/WMUGWH8U/Marvin and Linzen - 2018 - Targeted Syntactic Evaluation of Language Models.pdf:application/pdf},
}

@article{grange_indonesian_2015,
	title = {The {Indonesian} {Verbal} {Suffix} \textit{-nya} -- {Nominalization} or {Subordination?}},
	volume = {16},
	issn = {2407-6899, 1411-2272},
	url = {https://scholarhub.ui.ac.id/wacana/vol16/iss1/7},
	doi = {10.17510/wjhi.v16i1.370},
	abstract = {The suffix ‑nya is one of the most frequent and polysemic suffixes in Indonesian. It can provide definite determination and topicalization. The “Verb‑nya“, which often appears in a topicalized subject Noun Phrase (NP), is generally labelled as a deverbal noun. Nevertheless, many syntactic constraints set it apart from Indonesian deverbal nouns. “Verb‑nya“ must be complemented by a NP, which can easily be reconstructed as a former subject: a sentence is topicalized and thus becomes a noun clause, generally the subject of the main clause Verb Phrase (VP). I argue that “Verb‑nya“ is a subordinate noun clause, almost always conveying causality. This causal noun clause, an innovation in formal written Indonesian (especially in the media), seems to fill a “gap“: the impossibility of beginning a sentence with a subordinating morpheme (‘that’, ‘because’).},
	language = {en},
	number = {1},
	urldate = {2023-09-10},
	journal = {Wacana, Journal of the Humanities of Indonesia},
	author = {Grangé, Philippe},
	month = apr,
	year = {2015},
	pages = {133},
	file = {Grangé - 2015 - The Indonesian verbal suffix –nya Nominalization o.pdf:/Users/yosephineyosephine/Zotero/storage/LE97V39H/Grangé - 2015 - The Indonesian verbal suffix –nya Nominalization o.pdf:application/pdf},
}

@inproceedings{joshi_state_2020,
	address = {Online},
	title = {The {State} and {Fate} of {Linguistic} {Diversity} and {Inclusion} in the {NLP} {World}},
	url = {https://www.aclweb.org/anthology/2020.acl-main.560},
	doi = {10.18653/v1/2020.acl-main.560},
	abstract = {Language technologies contribute to promoting multilingualism and linguistic diversity around the world. However, only a very small number of the over 7000 languages of the world are represented in the rapidly evolving language technologies and applications. In this paper we look at the relation between the types of languages, resources, and their representation in NLP conferences to understand the trajectory that different languages have followed over time. Our quantitative investigation underlines the disparity between languages, especially in terms of their resources, and calls into question the “language agnostic” status of current models and systems. Through this paper, we attempt to convince the ACL community to prioritise the resolution of the predicaments highlighted here, so that no language is left behind.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Joshi, Pratik and Santy, Sebastin and Budhiraja, Amar and Bali, Kalika and Choudhury, Monojit},
	year = {2020},
	pages = {6282--6293},
	file = {Joshi et al. - 2020 - The State and Fate of Linguistic Diversity and Inc.pdf:/Users/yosephineyosephine/Zotero/storage/LLZ5QQ6J/Joshi et al. - 2020 - The State and Fate of Linguistic Diversity and Inc.pdf:application/pdf},
}

@inproceedings{lignos_toward_2022,
	address = {Dublin, Ireland},
	title = {Toward {More} {Meaningful} {Resources} for {Lower}-resourced {Languages}},
	url = {https://aclanthology.org/2022.findings-acl.44},
	doi = {10.18653/v1/2022.findings-acl.44},
	abstract = {In this position paper, we describe our perspective on how meaningful resources for lowerresourced languages should be developed in connection with the speakers of those languages. Before advancing that position, we first examine two massively multilingual resources used in language technology development, identifying shortcomings that limit their usefulness. We explore the contents of the names stored in Wikidata for a few lowerresourced languages and find that many of them are not in fact in the languages they claim to be, requiring non-trivial effort to correct. We discuss quality issues present in WikiAnn and evaluate whether it is a useful supplement to handannotated data. We then discuss the importance of creating annotations for lower-resourced languages in a thoughtful and ethical way that includes the language speakers as part of the development process. We conclude with recommended guidelines for resource development.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL} 2022},
	publisher = {Association for Computational Linguistics},
	author = {Lignos, Constantine and Holley, Nolan and Palen-Michel, Chester and Sälevä, Jonne},
	year = {2022},
	pages = {523--532},
	file = {Lignos et al. - 2022 - Toward More Meaningful Resources for Lower-resourc.pdf:/Users/yosephineyosephine/Zotero/storage/24EEN797/Lignos et al. - 2022 - Toward More Meaningful Resources for Lower-resourc.pdf:application/pdf},
}

@inproceedings{doddapaneni-etal-2023-towards,
    title = {Towards {Leaving} {No} {Indic} {Language} {Behind}: {Building} {Monolingual} {Corpora}, {Benchmark} and {Models} for {Indic} {Languages}},
    author = {Doddapaneni, Sumanth  and
      Aralikatte, Rahul  and
      Ramesh, Gowtham  and
      Goyal, Shreya  and
      Khapra, Mitesh M.  and
      Kunchukuttan, Anoop  and
      Kumar, Pratyush},
    booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
    month = {July},
    year = {2023},
    address = {Toronto, Canada},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/2023.acl-long.693},
    doi = {10.18653/v1/2023.acl-long.693},
    pages = {12402--12426},
    abstract = {Building Natural Language Understanding (NLU) capabilities for Indic languages, which have a collective speaker base of more than one billion speakers is absolutely crucial. In this work, we aim to improve the NLU capabilities of Indic languages by making contributions along 3 important axes (i) monolingual corpora (ii) NLU testsets (iii) multilingual LLMs focusing on Indic languages. Specifically, we curate the largest monolingual corpora, IndicCorp, with 20.9B tokens covering 24 languages from 4 language families - a 2.3x increase over prior work, while supporting 12 additional languages. Next, we create a human-supervised benchmark, IndicXTREME, consisting of nine diverse NLU tasks covering 20 languages. Across languages and tasks, IndicXTREME contains a total of 105 evaluation sets, of which 52 are new contributions to the literature. To the best of our knowledge, this is the first effort towards creating a standard benchmark for Indic languages that aims to test the multilingual zero-shot capabilities of pretrained language models. Finally, we train IndicBERT v2, a state-of-the-art model supporting all the languages. Averaged across languages and tasks, the model achieves an absolute improvement of 2 points over a strong baseline. The data and models are available at https://github.com/AI4Bharat/IndicBERT.},
}


@misc{doddapaneni_towards_nodate,
	title = {Towards Leaving No Indic Language Behind: Building Monolingual Corpora, Benchmark and Models for Indic Languages},
	abstract = {Building Natural Language Understanding (NLU) capabilities for Indic languages, which have a collective speaker base of more than one billion speakers is absolutely crucial. In this work, we aim to improve the NLU capabilities of Indic languages by making contributions along 3 important axes (i) monolingual corpora (ii) NLU testsets (iii) multilingual LLMs focusing on Indic languages. Specifically, we curate the largest monolingual corpora, IndicCorp, with 20.9B tokens covering 24 languages from 4 language families - a 2.3x increase over prior work, while supporting 12 additional languages. Next, we create a humansupervised benchmark, IndicXTREME, consisting of nine diverse NLU tasks covering 20 languages. Across languages and tasks, IndicXTREME contains a total of 105 evaluation sets, of which 52 are new contributions to the literature. To the best of our knowledge, this is the first effort towards creating a standard benchmark for Indic languages that aims to test the multilingual zero-shot capabilities of pretrained language models. Finally, we train IndicBERT v2, a state-of-the-art model supporting all the languages. Averaged across languages and tasks, the model achieves an absolute improvement of 2 points over a strong baseline. The data and models are available at https:// github.com/AI4Bharat/IndicBERT.},
	language = {en},
    year = {2023},
	author = {Doddapaneni, Sumanth and Aralikatte, Rahul and Ramesh, Gowtham and Goyal, Shreya and Khapra, Mitesh M and Kunchukuttan, Anoop and Kumar, Pratyush},
	file = {Doddapaneni et al. - Towards Leaving No Indic Language Behind Building.pdf:/Users/yosephineyosephine/Zotero/storage/DHIF2YM5/Doddapaneni et al. - Towards Leaving No Indic Language Behind Building.pdf:application/pdf},
}

@misc{peng_towards_2023,
	title = {Towards {Making} the {Most} of {ChatGPT} for {Machine} {Translation}},
	url = {http://arxiv.org/abs/2303.13780},
	abstract = {ChatGPT shows remarkable capabilities for machine translation (MT). Several prior studies have shown that it achieves comparable results to commercial systems for high-resource languages, but lags behind in complex tasks, e.g, low-resource and distant-language-pairs translation. However, they usually adopt simple prompts which can not fully elicit the capability of ChatGPT. In this report, we aim to further mine ChatGPT’s translation ability by revisiting several aspects: temperature, task information, and domain information, and correspondingly propose two (simple but effective) prompts: Task-Speciﬁc Prompts (TSP) and Domain-Speciﬁc Prompts (DSP). We show that: The performance of ChatGPT depends largely on temperature, and a lower temperature usually can achieve better performance;  Emphasizing the task information further improves ChatGPT’s performance, particularly in complex MT tasks; Introducing domain information can elicit ChatGPT’s generalization ability and improve its performance in the speciﬁc domain;  ChatGPT tends to generate hallucinations for nonEnglish-centric MT tasks, which can be partially addressed by our proposed prompts but still need to be highlighted for the MT/NLP community. We also explore the effects of advanced in-context learning strategies and ﬁnd a (negative but interesting) observation: the powerful chain-of-thought prompt leads to wordby-word translation behavior, thus bringing signiﬁcant translation degradation.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Peng, Keqin and Ding, Liang and Zhong, Qihuang and Shen, Li and Liu, Xuebo and Zhang, Min and Ouyang, Yuanxin and Tao, Dacheng},
	month = mar,
	year = {2023},
	note = {arXiv:2303.13780 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Work in progress, 9 pages},
	file = {Peng et al. - 2023 - Towards Making the Most of ChatGPT for Machine Tra.pdf:/Users/yosephineyosephine/Zotero/storage/JPI2BKM8/Peng et al. - 2023 - Towards Making the Most of ChatGPT for Machine Tra.pdf:application/pdf},
}

@misc{huang_towards_2023,
	title = {Towards {Reasoning} in {Large} {Language} {Models}: {A} {Survey}},
	shorttitle = {Towards {Reasoning} in {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2212.10403},
	abstract = {Reasoning is a fundamental aspect of human intelligence that plays a crucial role in activities such as problem solving, decision making, and critical thinking. In recent years, large language models (LLMs) have made significant progress in natural language processing, and there is observation that these models may exhibit reasoning abilities when they are sufficiently large. However, it is not yet clear to what extent LLMs are capable of reasoning. This paper provides a comprehensive overview of the current state of knowledge on reasoning in LLMs, including techniques for improving and eliciting reasoning in these models, methods and benchmarks for evaluating reasoning abilities, findings and implications of previous research in this field, and suggestions on future directions. Our aim is to provide a detailed and up-to-date review of this topic and stimulate meaningful discussion and future work.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Huang, Jie and Chang, Kevin Chen-Chuan},
	month = may,
	year = {2023},
	note = {arXiv:2212.10403 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	annote = {Comment: ACL 2023 Findings, 15 pages},
	file = {Huang and Chang - 2023 - Towards Reasoning in Large Language Models A Surv.pdf:/Users/yosephineyosephine/Zotero/storage/CEG4MID4/Huang and Chang - 2023 - Towards Reasoning in Large Language Models A Surv.pdf:application/pdf},
}

@misc{bai_training_2022,
	title = {Training a {Helpful} and {Harmless} {Assistant} with {Reinforcement} {Learning} from {Human} {Feedback}},
	url = {http://arxiv.org/abs/2204.05862},
	abstract = {We apply preference modeling and reinforcement learning from human feedback (RLHF) to ﬁnetune language models to act as helpful and harmless assistants. We ﬁnd this alignment training improves performance on almost all NLP evaluations, and is fully compatible with training for specialized skills such as python coding and summarization. We explore an iterated online mode of training, where preference models and RL policies are updated on a weekly cadence with fresh human feedback data, efﬁciently improving our datasets and models. Finally, we investigate the robustness of RLHF training, and identify a roughly linear relation between the RL reward and the square root of the KL divergence between the policy and its initialization. Alongside our main results, we perform peripheral analyses on calibration, competing objectives, and the use of OOD detection, compare our models with human writers, and provide samples from our models using prompts appearing in recent related work.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and Joseph, Nicholas and Kadavath, Saurav and Kernion, Jackson and Conerly, Tom and El-Showk, Sheer and Elhage, Nelson and Hatfield-Dodds, Zac and Hernandez, Danny and Hume, Tristan and Johnston, Scott and Kravec, Shauna and Lovitt, Liane and Nanda, Neel and Olsson, Catherine and Amodei, Dario and Brown, Tom and Clark, Jack and McCandlish, Sam and Olah, Chris and Mann, Ben and Kaplan, Jared},
	month = apr,
	year = {2022},
	note = {arXiv:2204.05862 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: Data available at https://github.com/anthropics/hh-rlhf},
	file = {Bai et al. - 2022 - Training a Helpful and Harmless Assistant with Rei.pdf:/Users/yosephineyosephine/Zotero/storage/MM8SZ4EB/Bai et al. - 2022 - Training a Helpful and Harmless Assistant with Rei.pdf:application/pdf},
}

@misc{ouyang_training_2022,
	title = {Training {Language} {Models} to {Follow} {Instructions} with {Human} {Feedback}},
	url = {http://arxiv.org/abs/2203.02155},
	abstract = {Making language models bigger does not inherently make them better at following a user’s intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by ﬁne-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through the OpenAI API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to ﬁne-tune GPT-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further ﬁne-tune this supervised model using reinforcement learning from human feedback. We call the resulting models InstructGPT. In human evaluations on our prompt distribution, outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters. Moreover, InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets. Even though InstructGPT still makes simple mistakes, our results show that ﬁne-tuning with human feedback is a promising direction for aligning language models with human intent.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L. and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul and Leike, Jan and Lowe, Ryan},
	month = mar,
	year = {2022},
	note = {arXiv:2203.02155 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Ouyang et al. - 2022 - Training language models to follow instructions wi.pdf:/Users/yosephineyosephine/Zotero/storage/PU53I3VK/Ouyang et al. - 2022 - Training language models to follow instructions wi.pdf:application/pdf},
}

@inproceedings{riley_translationese_2020,
	address = {Online},
	title = {Translationese as a {Language} in “{Multilingual}” {NMT}},
	url = {https://www.aclweb.org/anthology/2020.acl-main.691},
	doi = {10.18653/v1/2020.acl-main.691},
	abstract = {Machine translation has an undesirable propensity to produce “translationese” artifacts, which can lead to higher BLEU scores while being liked less by human raters. Motivated by this, we model translationese and original (i.e. natural) text as separate languages in a multilingual model, and pose the question: can we perform zero-shot translation between original source text and original target text? There is no data with original source and original target, so we train a sentence-level classiﬁer to distinguish translationese from original target text, and use this classiﬁer to tag the training data for an NMT model. Using this technique we bias the model to produce more natural outputs at test time, yielding gains in human evaluation scores on both adequacy and ﬂuency. Additionally, we demonstrate that it is possible to bias the model to produce translationese and game the BLEU score, increasing it while decreasing human-rated quality. We analyze these outputs using metrics measuring the degree of translationese, and present an analysis of the volatility of heuristic-based train-data tagging.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Riley, Parker and Caswell, Isaac and Freitag, Markus and Grangier, David},
	year = {2020},
	pages = {7737--7746},
	file = {Riley et al. - 2020 - Translationese as a Language in “Multilingual” NMT.pdf:/Users/yosephineyosephine/Zotero/storage/XRV3LLQ4/Riley et al. - 2020 - Translationese as a Language in “Multilingual” NMT.pdf:application/pdf},
}

@misc{yao_tree_2023,
	title = {Tree of {Thoughts}: {Deliberate} {Problem} {Solving} with {Large} {Language} {Models}},
	shorttitle = {Tree of {Thoughts}},
	url = {http://arxiv.org/abs/2305.10601},
	abstract = {Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still conﬁned to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, “Tree of Thoughts” (ToT), which generalizes over the popular “Chain of Thought” approach to prompting language models, and enables exploration over coherent units of text (“thoughts”) that serve as intermediate steps toward problem solving. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices. Our experiments show that ToT signiﬁcantly enhances language models’ problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4\% of tasks, our method achieved a success rate of 74\%. Code repo with all prompts: https://github.com/ysymyth/tree-of-thought-llm.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L. and Cao, Yuan and Narasimhan, Karthik},
	month = may,
	year = {2023},
	note = {arXiv:2305.10601 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: Code repo with all prompts: https://github.com/ysymyth/tree-of-thought-llm},
	file = {Yao et al. - 2023 - Tree of Thoughts Deliberate Problem Solving with .pdf:/Users/yosephineyosephine/Zotero/storage/WXJ987NC/Yao et al. - 2023 - Tree of Thoughts Deliberate Problem Solving with .pdf:application/pdf},
}

@article{clark-etal-2020-tydi,
    title = {{TyDi} {QA}: {A} {Benchmark} for {Information-Seeking} {Question} {Answering} in {Typologically} {Diverse} {Languages}},
    author = {Clark, Jonathan H.  and
      Choi, Eunsol  and
      Collins, Michael  and
      Garrette, Dan  and
      Kwiatkowski, Tom  and
      Nikolaev, Vitaly  and
      Palomaki, Jennimaria},
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {8},
    year = {2020},
    address = {Cambridge, MA},
    publisher = {MIT Press},
    url = {https://aclanthology.org/2020.tacl-1.30},
    doi = {10.1162/tacl_a_00317},
    pages = {454--470},
    abstract = {Confidently making progress on multilingual modeling requires challenging, trustworthy evaluations. We present TyDi QA{---}a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs. The languages of TyDi QA are diverse with regard to their typology{---}the set of linguistic features each language expresses{---}such that we expect models performing well on this set to generalize across a large number of the world{'}s languages. We present a quantitative analysis of the data quality and example-level qualitative linguistic analyses of observed language phenomena that would not be found in English-only corpora. To provide a realistic information-seeking task and avoid priming effects, questions are written by people who want to know the answer, but don{'}t know the answer yet, and the data is collected directly in each language without the use of translation.},
}




@inproceedings{nguyen_uit-vsfc_2018,
	address = {Ho Chi Minh City},
	title = {{UIT-VSFC}: {Vietnamese} {Students’} {Feedback} {Corpus} for {Sentiment} {Analysis}},
	isbn = {978-1-5386-6113-0},
	shorttitle = {{UIT}-{VSFC}},
	url = {https://ieeexplore.ieee.org/document/8573337/},
	doi = {10.1109/KSE.2018.8573337},
	abstract = {Students’ feedback is a vital resource for the interdisciplinary research combining of two ﬁelds: sentiment analysis and education. To strengthen the sentiment analysis of the Vietnamese language which is a low-resource language, we build a Vietnamese Students’ Feedback Corpus (UIT-VSFC), a free and high-quality corpus for research on two different tasks: sentiment-based and topic-based classiﬁcations. In this paper, we present the methods of building annotation guidelines and ensure the annotation accuracy and consistency of this corpus. The resource consists of over 16,000 sentences which are humanannotated on the two tasks. To assess the quality of our corpus, we measure the inter-annotator agreements and classiﬁcation accuracies on our UIT-VSFC. As a result, we achieved 91.20\% of the inter-annotator agreement for the sentiment-based task and 71.07\% of that for the topic-based task. In addition, the best results are of baseline model as the Maximum Entropy classiﬁer with 87.94\% and 84.03\% of the overall F1-score of the sentimentbased and topic-based tasks respectively. These results illustrate that the corpus is reliable and helpful resource for research.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {2018 10th {International} {Conference} on {Knowledge} and {Systems} {Engineering} ({KSE})},
	publisher = {IEEE},
	author = {Nguyen, Kiet Van and Nguyen, Vu Duc and Nguyen, Phu X. V. and Truong, Tham T. H. and Nguyen, Ngan Luu-Thuy},
	month = {November},
	year = {2018},
	pages = {19--24},
	file = {Nguyen et al. - 2018 - UIT-VSFC Vietnamese Students’ Feedback Corpus for.pdf:/Users/yosephineyosephine/Zotero/storage/2E55BKQG/Nguyen et al. - 2018 - UIT-VSFC Vietnamese Students’ Feedback Corpus for.pdf:application/pdf},
}

@article{chong_understanding_2022,
	title = {Understanding {Toxicity} {Triggers} on {Reddit} in the {Context} of {Singapore}},
	volume = {16},
	issn = {2334-0770, 2162-3449},
	url = {https://ojs.aaai.org/index.php/ICWSM/article/view/19392},
	doi = {10.1609/icwsm.v16i1.19392},
	abstract = {While the contagious nature of online toxicity sparked increasing interest in its early detection and prevention, most of the literature focuses on the Western world. In this work, we demonstrate that 1) it is possible to detect toxicity triggers in an Asian online community, and 2) toxicity triggers can be strikingly different between Western and Eastern contexts.},
	language = {en},
	urldate = {2023-09-10},
	journal = {Proceedings of the International AAAI Conference on Web and Social Media},
	author = {Chong, Yun Yu and Kwak, Haewoon},
	month = may,
	year = {2022},
	pages = {1383--1387},
	file = {Chong and Kwak - 2022 - Understanding Toxicity Triggers on Reddit in the C.pdf:/Users/yosephineyosephine/Zotero/storage/H7DKNEXY/Chong and Kwak - 2022 - Understanding Toxicity Triggers on Reddit in the C.pdf:application/pdf},
}

@article{nguyen_vlsp_2019,
	title = {{VLSP} {Shared} {Task}: {Named} {Entity} {Recognition}},
	volume = {34},
	issn = {1813-9663, 1813-9663},
	shorttitle = {{VLSP} {Shared} {Task}},
	url = {https://vjs.ac.vn/index.php/jcc/article/view/13161},
	doi = {10.15625/1813-9663/34/4/13161},
	abstract = {Named Entities (NE) are phrases that contain the names of persons, organizations, locations, times and quantities, monetary values, percentages, etc. Named Entity Recognition (NER) is the task of recognizing named entities in documents. NER is an important subtask of Information Extraction, which has attracted researchers all over the world since 1990s. For Vietnamese language, although there exist some research projects and publications on NER task before 2016, no systematic comparison of the performance of NER systems has been done. In 2016, the organizing committee of the VLSP workshop decided to launch the ﬁrst NER shared task, in order to get an objective evaluation of Vietnamese NER systems and to promote the development of high quality systems. As a result, the ﬁrst dataset with morpho-syntactic and NE annotations has been released for benchmarking NER systems. At VLSP 2018, the NER shared task has been organized for the second time, providing a bigger dataset containing texts from various domains, but without morpho-syntactic annotation. These resources are available for research purpose via the VLSP website vlsp.org.vn/resources. In this paper, we describe the datasets as well as the evaluation results obtained from these two campaigns.},
	language = {en},
	number = {4},
	urldate = {2023-09-10},
	journal = {Journal of Computer Science and Cybernetics},
	author = {Nguyen, Huyen T M and Ngo, Quyen T and Vu, Luong X and Tran, Vu M and Nguyen, Hien T T},
	month = jan,
	year = {2019},
	pages = {283--294},
	file = {Nguyen et al. - 2019 - VLSP Shared Task Named Entity Recognition.pdf:/Users/yosephineyosephine/Zotero/storage/IZGFH9HQ/Nguyen et al. - 2019 - VLSP Shared Task Named Entity Recognition.pdf:application/pdf},
}

@inproceedings{wang_glue_2018,
	address = {Brussels, Belgium},
	title = {{GLUE}: {A} {Multi}-{Task} {Benchmark} and {Analysis} {Platform} for {Natural} {Language} {Understanding}},
	shorttitle = {{GLUE}},
	url = {http://aclweb.org/anthology/W18-5446},
	doi = {10.18653/v1/W18-5446},
	abstract = {For natural language understanding (NLU) technology to be maximally useful, it must be able to process language in a way that is not exclusive to a single task, genre, or dataset. In pursuit of this objective, we introduce the General Language Understanding Evaluation (GLUE) benchmark, a collection of tools for evaluating the performance of models across a diverse set of existing NLU tasks. By including tasks with limited training data, GLUE is designed to favor and encourage models that share general linguistic knowledge across tasks. GLUE also includes a hand-crafted diagnostic test suite that enables detailed linguistic analysis of models. We evaluate baselines based on current methods for transfer and representation learning and ﬁnd that multi-task training on all tasks performs better than training a separate model per task. However, the low absolute performance of our best model indicates the need for improved general NLU systems.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 2018 {EMNLP} {Workshop} {BlackboxNLP}: {Analyzing} and {Interpreting} {Neural} {Networks} for {NLP}},
	publisher = {Association for Computational Linguistics},
	author = {Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel},
	year = {2018},
	pages = {353--355},
	file = {Wang et al. - 2018 - GLUE A Multi-Task Benchmark and Analysis Platform.pdf:/Users/yosephineyosephine/Zotero/storage/GTBCBITM/Wang et al. - 2018 - GLUE A Multi-Task Benchmark and Analysis Platform.pdf:application/pdf},
}

@misc{wang_unleashing_2023,
	title = {Unleashing {Cognitive} {Synergy} in {Large} {Language} {Models}: {A} {Task}-{Solving} {Agent} through {Multi}-{Persona} {Self}-{Collaboration}},
	shorttitle = {Unleashing {Cognitive} {Synergy} in {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2307.05300},
	abstract = {Human intelligence thrives on the concept of cognitive synergy, where collaboration and information integration among different cognitive processes yield superior outcomes compared to individual cognitive processes in isolation. Although Large Language Models (LLMs) have demonstrated promising performance as general task-solving agents, they still struggle with tasks that require intensive domain knowledge and complex reasoning. In this work, we propose Solo Performance Prompting (SPP), which transforms a single LLM into a cognitive synergist by engaging in multi-turn self-collaboration with multiple personas. A cognitive synergist refers to an intelligent agent that collaborates with multiple minds, combining their individual strengths and knowledge, to enhance problem-solving and overall performance in complex tasks. By dynamically identifying and simulating different personas based on task inputs, SPP unleashes the potential of cognitive synergy in LLMs. We have discovered that assigning multiple, fine-grained personas in LLMs elicits better problem-solving abilities compared to using a single or fixed number of personas. We evaluate SPP on three challenging tasks: Trivia Creative Writing, Codenames Collaborative, and Logic Grid Puzzle, encompassing both knowledgeintensive and reasoning-intensive types. Unlike previous works, such as Chainof-Thought, that solely enhance the reasoning abilities in LLMs, SPP effectively elicits internal knowledge acquisition abilities, reduces hallucination, and maintains strong reasoning capabilities. Code, data, and prompts can be found at: https: //github.com/MikeWangWZHL/Solo-Performance-Prompting.git.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Wang, Zhenhailong and Mao, Shaoguang and Wu, Wenshan and Ge, Tao and Wei, Furu and Ji, Heng},
	month = jul,
	year = {2023},
	note = {arXiv:2307.05300 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	annote = {Comment: work in progress},
	file = {Wang et al. - 2023 - Unleashing Cognitive Synergy in Large Language Mod.pdf:/Users/yosephineyosephine/Zotero/storage/5HH7BCI2/Wang et al. - 2023 - Unleashing Cognitive Synergy in Large Language Mod.pdf:application/pdf},
}

@misc{lowphansirikul_wangchanberta_2021,
	title = {{WangchanBERTa}: {Pretraining} {Transformer-based} {Thai} {Language} {Models}},
	shorttitle = {{WangchanBERTa}},
	url = {http://arxiv.org/abs/2101.09635},
	abstract = {Transformer-based language models, more speciﬁcally BERT-based architectures have achieved state-of-the-art performance in many downstream tasks. However, for a relatively low-resource language such as Thai, the choices of models are limited to training a BERT-based model based on a much smaller dataset or ﬁnetuning multi-lingual models, both of which yield suboptimal downstream performance. Moreover, large-scale multi-lingual pretraining does not take into account language-speciﬁc features for Thai. To overcome these limitations, we pretrain a language model based on RoBERTa-base architecture on a large, deduplicated, cleaned training set (78GB in total size), curated from diverse domains of social media posts, news articles and other publicly available datasets. We apply text processing rules that are speciﬁc to Thai most importantly preserving spaces, which are important chunk and sentence boundaries in Thai before subword tokenization. We also experiment with word-level, syllable-level and SentencePiece tokenization with a smaller dataset to explore the effects on tokenization on downstream performance. Our model wangchanberta-baseatt-spm-uncased trained on the 78.5GB dataset outperforms strong baselines (NBSVM, CRF and ULMFit) and multi-lingual models (XLMR and mBERT) on both sequence classiﬁcation and token classiﬁcation tasks in human-annotated, mono-lingual contexts.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Lowphansirikul, Lalita and Polpanumas, Charin and Jantrakulchai, Nawat and Nutanong, Sarana},
	month = mar,
	year = {2021},
	note = {arXiv:2101.09635 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: 24 pages, edited the citation of the syllable-level tokenizer from [Chormai et al., 2020] to [Phatthiyaphaibun et al., 2020] as the authors used the syllable-level tokenizer from PyThaiNLP [Phatthiyaphaibun et al., 2020] in the experiments},
	file = {Lowphansirikul et al. - 2021 - WangchanBERTa Pretraining transformer-based Thai .pdf:/Users/yosephineyosephine/Zotero/storage/NVTX7U4J/Lowphansirikul et al. - 2021 - WangchanBERTa Pretraining transformer-based Thai .pdf:application/pdf},
}

@inproceedings{liu_what_2022,
	address = {Dublin, Ireland and Online},
	title = {What {Makes} {Good} {In}-{Context} {Examples} for {GPT}-3?},
	url = {https://aclanthology.org/2022.deelio-1.10},
	doi = {10.18653/v1/2022.deelio-1.10},
	abstract = {GPT-3 has attracted lots of attention due to its superior performance across a wide range of NLP tasks, especially with its in-context learning abilities. Despite its success, we found that the empirical results of GPT-3 depend heavily on the choice of in-context examples. In this work, we investigate whether there are more effective strategies for judiciously selecting incontext examples (relative to random sampling) that better leverage GPT-3’s in-context learning capabilities. Inspired by the recent success of leveraging a retrieval module to augment neural networks, we propose to retrieve examples that are semantically-similar to a test query sample to formulate its corresponding prompt. Intuitively, the examples selected with such a strategy may serve as more informative inputs to unleash GPT-3’s power of text generation. We evaluate the proposed approach on several natural language understanding and generation benchmarks, where the retrieval-based prompt selection approach consistently outperforms the random selection baseline. Moreover, it is observed that the sentence encoders finetuned on task-related datasets yield even more helpful retrieval results. Notably, significant gains are observed on tasks such as table-totext generation (44.3\% on the ToTTo dataset) and open-domain question answering (45.5\% on the NQ dataset).},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of {Deep} {Learning} {Inside} {Out} ({DeeLIO} 2022): {The} 3rd {Workshop} on {Knowledge} {Extraction} and {Integration} for {Deep} {Learning} {Architectures}},
	publisher = {Association for Computational Linguistics},
	author = {Liu, Jiachang and Shen, Dinghan and Zhang, Yizhe and Dolan, Bill and Carin, Lawrence and Chen, Weizhu},
	year = {2022},
	pages = {100--114},
	file = {Liu et al. - 2022 - What Makes Good In-Context Examples for GPT-3.pdf:/Users/yosephineyosephine/Zotero/storage/HA78VJF8/Liu et al. - 2022 - What Makes Good In-Context Examples for GPT-3.pdf:application/pdf},
}

@misc{tedeschi_whats_2023,
	title = {What's the {Meaning} of {Superhuman} {Performance} in {Today}'s {NLU}?},
	url = {http://arxiv.org/abs/2305.08414},
	abstract = {In the last ﬁve years, there has been a significant focus in Natural Language Processing (NLP) on developing larger Pretrained Language Models (PLMs) and introducing benchmarks such as SuperGLUE and SQuAD to measure their abilities in language understanding, reasoning, and reading comprehension. These PLMs have achieved impressive results on these benchmarks, even surpassing human performance in some cases. This has led to claims of superhuman capabilities and the provocative idea that certain tasks have been solved. In this position paper, we take a critical look at these claims and ask whether PLMs truly have superhuman abilities and what the current benchmarks are really evaluating. We show that these benchmarks have serious limitations affecting the comparison between humans and PLMs and provide recommendations for fairer and more transparent benchmarks.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Tedeschi, Simone and Bos, Johan and Declerck, Thierry and Hajic, Jan and Hershcovich, Daniel and Hovy, Eduard H. and Koller, Alexander and Krek, Simon and Schockaert, Steven and Sennrich, Rico and Shutova, Ekaterina and Navigli, Roberto},
	month = may,
	year = {2023},
	note = {arXiv:2305.08414 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	annote = {Comment: 9 pages, long paper at ACL 2023 proceedings},
	file = {Tedeschi et al. - 2023 - What's the Meaning of Superhuman Performance in To.pdf:/Users/yosephineyosephine/Zotero/storage/T89KIKAC/Tedeschi et al. - 2023 - What's the Meaning of Superhuman Performance in To.pdf:application/pdf},
}

@misc{whitehouse_llm-powered_2023,
	title = {{LLM}-powered {Data} {Augmentation} for {Enhanced} {Crosslingual} {Performance}},
	url = {http://arxiv.org/abs/2305.14288},
	abstract = {This paper aims to explore the potential of leveraging Large Language Models (LLMs) for data augmentation in crosslingual commonsense reasoning datasets, where the available training data is extremely limited. To achieve this, we employ several LLMs including Dolly-v2, StableVicuna, ChatGPT, and GPT-4 to augment three datasets: XCOPA, XWinograd, and XStoryCloze. Subsequently, we assess the effectiveness of fine-tuning smaller crosslingual models, mBERT and XLMR, using the synthesised data. We compare the performance of training with data generated in English and target languages, as well as translating the English-generated data into the target languages. Our experiments reveal the overall advantages of incorporating data generated by LLMs. Training on synthetic data generated by GPT-4, whether English or multilingual, improves performance consistently compared to the baseline. Other models also exhibit an overall increase in performance, however, their effectiveness decreases in some settings. We also ask native speakers to evaluate the naturalness and logical soundness of the generated examples for different languages. Human evaluation reveals that LLMs like ChatGPT and GPT-4 excel at generating natural text in most languages, except a few such as Tamil. Moreover, ChatGPT trails behind in generating plausible alternatives in comparison to the original dataset, while GPT-4 demonstrates competitive logic consistency in the synthesised data1.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Whitehouse, Chenxi and Choudhury, Monojit and Aji, Alham Fikri},
	month = may,
	year = {2023},
	note = {arXiv:2305.14288 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Whitehouse et al. - 2023 - LLM-powered Data Augmentation for Enhanced Crossli.pdf:/Users/yosephineyosephine/Zotero/storage/K2HCVNM4/Whitehouse et al. - 2023 - LLM-powered Data Augmentation for Enhanced Crossli.pdf:application/pdf},
}

@inproceedings{ponti_xcopa_2020,
	address = {Online},
	title = {{XCOPA}: {A} {Multilingual} {Dataset} for {Causal} {Commonsense} {Reasoning}},
	shorttitle = {{XCOPA}},
	url = {https://www.aclweb.org/anthology/2020.emnlp-main.185},
	doi = {10.18653/v1/2020.emnlp-main.185},
	abstract = {In order to simulate human language capacity, natural language processing systems must be able to reason about the dynamics of everyday situations, including their possible causes and effects. Moreover, they should be able to generalise the acquired world knowledge to new languages, modulo cultural differences. Advances in machine reasoning and cross-lingual transfer depend on the availability of challenging evaluation benchmarks. Motivated by both demands, we introduce Cross-lingual Choice of Plausible Alternatives (XCOPA), a typologically diverse multilingual dataset for causal commonsense reasoning in 11 languages, which includes resource-poor languages like Eastern Apur´ımac Quechua and Haitian Creole. We evaluate a range of state-of-the-art models on this novel dataset, revealing that the performance of current methods based on multilingual pretraining and zero-shot ﬁne-tuning falls short compared to translation-based transfer. Finally, we propose strategies to adapt multilingual models to out-of-sample resource-lean languages where only a small corpus or a bilingual dictionary is available, and report substantial improvements over the random baseline. The XCOPA dataset is freely available at github.com/cambridgeltl/xcopa.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 2020 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Ponti, Edoardo Maria and Glavaš, Goran and Majewska, Olga and Liu, Qianchu and Vulić, Ivan and Korhonen, Anna},
	year = {2020},
	pages = {2362--2376},
	file = {Ponti et al. - 2020 - XCOPA A Multilingual Dataset for Causal Commonsen.pdf:/Users/yosephineyosephine/Zotero/storage/QTB2STMD/Ponti et al. - 2020 - XCOPA A Multilingual Dataset for Causal Commonsen.pdf:application/pdf},
}

@inproceedings{xiang_climp_2021,
	address = {Online},
	title = {{CLiMP}: {A} {Benchmark} for {Chinese} {Language} {Model} {Evaluation}},
	shorttitle = {{CLiMP}},
	url = {https://aclanthology.org/2021.eacl-main.242},
	doi = {10.18653/v1/2021.eacl-main.242},
	abstract = {Linguistically informed analyses of language models (LMs) contribute to the understanding and improvement of these models. Here, we introduce the corpus of Chinese linguistic minimal pairs (CLiMP), which can be used to investigate what knowledge Chinese LMs acquire. CLiMP consists of sets of 1,000 minimal pairs (MPs) for 16 syntactic contrasts in Mandarin, covering 9 major Mandarin linguistic phenomena. The MPs are semiautomatically generated, and human agreement with the labels in CLiMP is 95.8\%. We evaluate 11 different LMs on CLiMP, covering n-grams, LSTMs, and Chinese BERT. We ﬁnd that classiﬁer–noun agreement and verb complement selection are the phenomena that models generally perform best at. However, models struggle the most with the baˇ construction, binding, and ﬁller-gap dependencies. Overall, Chinese BERT achieves an 81.8\% average accuracy, while the performances of LSTMs and 5-grams are only moderately above chance level.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 16th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}: {Main} {Volume}},
	publisher = {Association for Computational Linguistics},
	author = {Xiang, Beilei and Yang, Changbing and Li, Yu and Warstadt, Alex and Kann, Katharina},
	year = {2021},
	pages = {2784--2790},
	file = {Xiang et al. - 2021 - CLiMP A Benchmark for Chinese Language Model Eval.pdf:/Users/yosephineyosephine/Zotero/storage/58KIGQ32/Xiang et al. - 2021 - CLiMP A Benchmark for Chinese Language Model Eval.pdf:application/pdf},
}

@inproceedings{hasan_xl-sum_2021,
	address = {Online},
	title = {{XL}-{Sum}: {Large}-{Scale} {Multilingual} {Abstractive} {Summarization} for 44 {Languages}},
	shorttitle = {{XL}-{Sum}},
	url = {https://aclanthology.org/2021.findings-acl.413},
	doi = {10.18653/v1/2021.findings-acl.413},
	abstract = {Contemporary works on abstractive text summarization have focused primarily on highresource languages like English, mostly due to the limited availability of datasets for low/midresource ones. In this work, we present XLSum, a comprehensive and diverse dataset comprising 1 million professionally annotated article-summary pairs from BBC, extracted using a set of carefully designed heuristics. The dataset covers 44 languages ranging from low to high-resource, for many of which no public dataset is currently available. XL-Sum is highly abstractive, concise, and of high quality, as indicated by human and intrinsic evaluation. We ﬁne-tune mT5, a state-of-theart pretrained multilingual model, with XLSum and experiment on multilingual and lowresource summarization tasks. XL-Sum induces competitive results compared to the ones obtained using similar monolingual datasets: we show higher than 11 ROUGE-2 scores on 10 languages we benchmark on, with some of them exceeding 15, as obtained by multilingual training. Additionally, training on low-resource languages individually also provides competitive performance. To the best of our knowledge, XL-Sum is the largest abstractive summarization dataset in terms of the number of samples collected from a single source and the number of languages covered. We are releasing our dataset and models to encourage future research on multilingual abstractive summarization. The resources can be found at https://github. com/csebuetnlp/xl-sum.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL}-{IJCNLP} 2021},
	publisher = {Association for Computational Linguistics},
	author = {Hasan, Tahmid and Bhattacharjee, Abhik and Islam, Md. Saiful and Mubasshir, Kazi and Li, Yuan-Fang and Kang, Yong-Bin and Rahman, M. Sohel and Shahriyar, Rifat},
	year = {2021},
	pages = {4693--4703},
	file = {Hasan et al. - 2021 - XL-Sum Large-Scale Multilingual Abstractive Summa.pdf:/Users/yosephineyosephine/Zotero/storage/UAELAD8M/Hasan et al. - 2021 - XL-Sum Large-Scale Multilingual Abstractive Summa.pdf:application/pdf},
}

@inproceedings{conneau_xnli_2018,
	address = {Brussels, Belgium},
	title = {{XNLI}: {Evaluating} {Cross}-lingual {Sentence} {Representations}},
	shorttitle = {{XNLI}},
	url = {http://aclweb.org/anthology/D18-1269},
	doi = {10.18653/v1/D18-1269},
	abstract = {State-of-the-art natural language processing systems rely on supervision in the form of annotated data to learn competent models. These models are generally trained on data in a single language (usually English), and cannot be directly used beyond that language. Since collecting data in every language is not realistic, there has been a growing interest in crosslingual language understanding (XLU) and low-resource cross-language transfer. In this work, we construct an evaluation set for XLU by extending the development and test sets of the Multi-Genre Natural Language Inference Corpus (MultiNLI) to 15 languages, including low-resource languages such as Swahili and Urdu. We hope that our dataset, dubbed XNLI, will catalyze research in cross-lingual sentence understanding by providing an informative standard evaluation task. In addition, we provide several baselines for multilingual sentence understanding, including two based on machine translation systems, and two that use parallel data to train aligned multilingual bag-of-words and LSTM encoders. We ﬁnd that XNLI represents a practical and challenging evaluation suite, and that directly translating the test data yields the best performance among available baselines.},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 2018 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Conneau, Alexis and Rinott, Ruty and Lample, Guillaume and Williams, Adina and Bowman, Samuel and Schwenk, Holger and Stoyanov, Veselin},
	year = {2018},
	pages = {2475--2485},
	file = {Conneau et al. - 2018 - XNLI Evaluating Cross-lingual Sentence Representa.pdf:/Users/yosephineyosephine/Zotero/storage/2SZ58IKD/Conneau et al. - 2018 - XNLI Evaluating Cross-lingual Sentence Representa.pdf:application/pdf},
}

@misc{hu_xtreme_2020,
	title = {{XTREME}: {A} {Massively} {Multilingual} {Multi}-task {Benchmark} for {Evaluating} {Cross}-lingual {Generalization}},
	shorttitle = {{XTREME}},
	url = {http://arxiv.org/abs/2003.11080},
	abstract = {Much recent progress in applications of machine learning models to NLP has been driven by benchmarks that evaluate models across a wide variety of tasks. However, these broad-coverage benchmarks have been mostly limited to English, and despite an increasing interest in multilingual models, a benchmark that enables the comprehensive evaluation of such methods on a diverse range of languages and tasks is still missing. To this end, we introduce the Cross-lingual TRansfer Evaluation of Multilingual Encoders (XTREME) benchmark, a multi-task benchmark for evaluating the cross-lingual generalization capabilities of multilingual representations across 40 languages and 9 tasks. We demonstrate that while models tested on English reach human performance on many tasks, there is still a sizable gap in the performance of cross-lingually transferred models, particularly on syntactic and sentence retrieval tasks. There is also a wide spread of results across languages. We release the benchmark1 to encourage research on cross-lingual learning methods that transfer linguistic knowledge across a diverse and representative set of languages and tasks.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Hu, Junjie and Ruder, Sebastian and Siddhant, Aditya and Neubig, Graham and Firat, Orhan and Johnson, Melvin},
	month = sep,
	year = {2020},
	note = {arXiv:2003.11080 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: In Proceedings of the 37th International Conference on Machine Learning (ICML). July 2020},
	file = {Hu et al. - 2020 - XTREME A Massively Multilingual Multi-task Benchm.pdf:/Users/yosephineyosephine/Zotero/storage/MHZWUALX/Hu et al. - 2020 - XTREME A Massively Multilingual Multi-task Benchm.pdf:application/pdf},
}

@misc{xu_are_2023,
	title = {Are {Large} {Language} {Models} {Really} {Good} {Logical} {Reasoners}? {A} {Comprehensive} {Evaluation} and {Beyond}},
	shorttitle = {Are {Large} {Language} {Models} {Really} {Good} {Logical} {Reasoners}?},
	url = {http://arxiv.org/abs/2306.09841},
	abstract = {Large Language Models (LLMs) have achieved great success in various natural language tasks. It has aroused much interest in evaluating the specific reasoning capability of LLMs, such as multilingual reasoning and mathematical reasoning. However, as one of the key reasoning perspectives, logical reasoning capability has not yet been thoroughly evaluated. In this work, we aim to bridge those gaps and provide comprehensive evaluations. Firstly, to offer systematic evaluations, this paper selects fifteen typical logical reasoning datasets and organizes them into deductive, inductive, abductive and mixedform reasoning settings. Considering the comprehensiveness of evaluations, we include three representative LLMs (i.e., text-davinci-003, ChatGPT and BARD) and evaluate them on all selected datasets under zero-shot, one-shot and threeshot settings. Secondly, different from previous evaluations relying only on simple metrics (e.g., accuracy), we propose fine-level evaluations from objective and subjective manners, covering both answers and explanations. Also, to uncover the logical flaws of LLMs, bad cases will be attributed to five error types from two dimensions Evidence Selection Process and Reasoning Process. The former one includes evidence selection error and hallucination, while the latter one includes no reasoning, mistakes of reasoning perspectives and mistakes during reasoning process. Thirdly, to avoid the influences of knowledge bias and purely focus on benchmarking the logical reasoning capability of LLMs, we propose a new dataset with neutral content. It contains 3K samples and covers deductive, inductive and abductive reasoning settings. Based on the in-depth evaluations, this paper finally concludes the ability maps of logical reasoning capability from six dimensions (i.e., correct, rigorous, self-aware, active, oriented and no hallucination). It reflects the pros and cons of LLMs and gives guiding directions for future works.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Xu, Fangzhi and Lin, Qika and Han, Jiawei and Zhao, Tianzhe and Liu, Jun and Cambria, Erik},
	month = aug,
	year = {2023},
	note = {arXiv:2306.09841 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	annote = {Comment: 14 pages, 11 figures},
	file = {Xu et al. - 2023 - Are Large Language Models Really Good Logical Reas.pdf:/Users/yosephineyosephine/Zotero/storage/FCCDT3LL/Xu et al. - 2023 - Are Large Language Models Really Good Logical Reas.pdf:application/pdf},
}

@misc{xu_expertprompting_2023,
	title = {{ExpertPrompting}: {Instructing} {Large} {Language} {Models} to be {Distinguished} {Experts}},
	shorttitle = {{ExpertPrompting}},
	url = {http://arxiv.org/abs/2305.14688},
	abstract = {The answering quality of an aligned large language model (LLM) can be drastically improved if treated with proper crafting of prompts. In this paper, we propose ExpertPrompting to elicit the potential of LLMs to answer as distinguished experts. We first utilize In-Context Learning to automatically synthesize detailed and customized descriptions of the expert identity for each specific instruction, and then ask LLMs to provide answer conditioned on such agent background. Based on this augmented prompting strategy, we produce a new set of instruction-following data using GPT-3.5, and train a competitive open-source chat assistant called ExpertLLaMA. We employ GPT4-based evaluation to show that 1) the expert data is of significantly higher quality than vanilla answers, and 2) ExpertLLaMA outperforms existing open-source opponents and achieves 96\% of the original ChatGPT’s capability. All data and the ExpertLLaMA model will be made publicly available at https:// github.com/OFA-Sys/ExpertLLaMA.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Xu, Benfeng and Yang, An and Lin, Junyang and Wang, Quan and Zhou, Chang and Zhang, Yongdong and Mao, Zhendong},
	month = may,
	year = {2023},
	note = {arXiv:2305.14688 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Xu et al. - 2023 - ExpertPrompting Instructing Large Language Models.pdf:/Users/yosephineyosephine/Zotero/storage/PPGW8K6G/Xu et al. - 2023 - ExpertPrompting Instructing Large Language Models.pdf:application/pdf},
}

@misc{ye_comprehensive_nodate,
	title = {A {Comprehensive} {Capability} {Analysis} of {GPT}-3 and {GPT}-3.5 {Series} {Models}},
	abstract = {GPT series models, such as GPT-3, CodeX, InstructGPT, ChatGPT, and so on, have gained considerable attention due to their exceptional natural language processing capabilities. However, despite the abundance of research on the difference in capabilities between GPT series models and ﬁne-tuned models, there has been limited attention given to the evolution of GPT series models’ capabilities over time. To conduct a comprehensive analysis of the capabilities of GPT series models, we select six representative models, comprising two GPT-3 series models (i.e., davinci and text-davinci-001) and four GPT-3.5 series models (i.e., code-davinci-002, text-davinci-002, text-davinci-003, and gpt-3.5-turbo). We evaluate their performance on nine natural language understanding (NLU) tasks using 21 datasets. In particular, we compare the performance and robustness of different models for each task under zero-shot and few-shot scenarios. Our extensive experiments reveal that the overall ability of GPT series models on NLU tasks does not increase gradually as the models evolve, especially with the introduction of the RLHF training strategy. While this strategy enhances the models’ ability to generate humanlike responses, it also compromises their ability to solve some tasks. Furthermore, our ﬁndings indicate that there is still room for improvement in areas such as model robustness.},
	language = {en},
	author = {Ye, Junjie and Chen, Xuanting and Xu, Nuo and Liu, Shichun and Cui, Yuhan and Zhou, Zeyang and Gong, Chao and Shen, Yang and Zhou, Jie and Chen, Siming and Gui, Tao and Zhang, Qi and Huang, Xuanjing},
    year ={2023},
	file = {Ye et al. - A Comprehensive Capability Analysis of GPT-3 and G.pdf:/Users/yosephineyosephine/Zotero/storage/3HSTN9R2/Ye et al. - A Comprehensive Capability Analysis of GPT-3 and G.pdf:application/pdf},
}

@misc{ye2023comprehensive,
      title={A {Comprehensive} {Capability} {Analysis} of {GPT-3} and {GPT-3.5} {Series} {Models}}, 
      author={Junjie Ye and Xuanting Chen and Nuo Xu and Can Zu and Zekai Shao and Shichun Liu and Yuhan Cui and Zeyang Zhou and Chao Gong and Yang Shen and Jie Zhou and Siming Chen and Tao Gui and Qi Zhang and Xuanjing Huang},
      year={2023},
      eprint={2303.10420},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      publisher={arXiv},
      note={arXiv:2303.10420 [cs]}
}

@misc{zhang_m3exam_2023,
	title = {{M3Exam}: {A} {Multilingual}, {Multimodal}, {Multilevel} {Benchmark} for {Examining} {Large} {Language} {Models}},
	shorttitle = {{M3Exam}},
	url = {http://arxiv.org/abs/2306.05179},
	abstract = {Despite the existence of various benchmarks for evaluating natural language processing models, we argue that human exams are a more suitable means of evaluating general intelligence for large language models (LLMs), as they inherently demand a much wider range of abilities such as language understanding, domain knowledge, and problem-solving skills. To this end, we introduce M3Exam, a novel benchmark sourced from real and official human exam questions for evaluating LLMs in a multilingual, multimodal, and multilevel context. M3Exam exhibits three unique characteristics: (1) multilingualism, encompassing questions from multiple countries that require strong multilingual proficiency and cultural knowledge; (2) multimodality, accounting for the multimodal nature of many exam questions to test the model’s multimodal understanding capability; and (3) multilevel structure, featuring exams from three critical educational periods to comprehensively assess a model’s proficiency at different levels. In total, M3Exam contains 12,317 questions in 9 diverse languages with three educational levels, where about 23\% of the questions require processing images for successful solving. We assess the performance of top-performing LLMs on M3Exam and find that current models, including GPT-4, still struggle with multilingual text, particularly in low-resource and non-Latin script languages. Multimodal LLMs also perform poorly with complex multimodal questions. We believe that M3Exam can be a valuable resource for comprehensively evaluating LLMs by examining their multilingual and multimodal abilities and tracking their development. Data and evaluation code is available at https://github.com/DAMO-NLP-SG/M3Exam.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Zhang, Wenxuan and Aljunied, Sharifah Mahani and Gao, Chang and Chia, Yew Ken and Bing, Lidong},
	month = {June},
	year = {2023},
	note = {arXiv:2306.05179 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition},
	file = {Zhang et al. - 2023 - M3Exam A Multilingual, Multimodal, Multilevel Ben.pdf:/Users/yosephineyosephine/Zotero/storage/PM2AW6NL/Zhang et al. - 2023 - M3Exam A Multilingual, Multimodal, Multilevel Ben.pdf:application/pdf},
}

@inproceedings{zhao_pretrained_2021,
	address = {Online},
	title = {Do {Pretrained} {Transformers} {Infer} {Telicity} {Like} {Humans?}},
	url = {https://aclanthology.org/2021.conll-1.6},
	doi = {10.18653/v1/2021.conll-1.6},
	language = {en},
	urldate = {2023-09-10},
	booktitle = {Proceedings of the 25th {Conference} on {Computational} {Natural} {Language} {Learning}},
	publisher = {Association for Computational Linguistics},
	author = {Zhao, Yiyun and Ngui, Jian Gang and Hall Hartley, Lucy and Bethard, Steven},
	year = {2021},
	pages = {72--81},
	file = {Zhao et al. - 2021 - Do pretrained transformers infer telicity like hum.pdf:/Users/yosephineyosephine/Zotero/storage/2BPRDHCG/Zhao et al. - 2021 - Do pretrained transformers infer telicity like hum.pdf:application/pdf},
}

@misc{zhong_agieval_2023,
	title = {{AGIEval}: {A} {Human}-{Centric} {Benchmark} for {Evaluating} {Foundation} {Models}},
	shorttitle = {{AGIEval}},
	url = {http://arxiv.org/abs/2304.06364},
	abstract = {Evaluating the general abilities of foundation models to tackle human-level tasks is a vital aspect of their development and application in the pursuit of Artiﬁcial General Intelligence (AGI). Traditional benchmarks, which rely on artiﬁcial datasets, may not accurately represent human-level capabilities. In this paper, we introduce AGIEval, a novel benchmark speciﬁcally designed to assess foundation model in the context of human-centric standardized exams, such as college entrance exams, law school admission tests, math competitions, and lawyer qualiﬁcation tests. We evaluate several state-of-the-art foundation models, including GPT-4, ChatGPT, and Text-Davinci-003, using this benchmark. Impressively, GPT-4 surpasses average human performance on SAT, LSAT, and math competitions, attaining a 95\% accuracy rate on the SAT Math test and a 92.5\% accuracy on the English test of the Chinese national college entrance exam. This demonstrates the extraordinary performance of contemporary foundation models. In contrast, we also ﬁnd that GPT-4 is less proﬁcient in tasks that require complex reasoning or speciﬁc domain knowledge. Our comprehensive analyses of model capabilities (understanding, knowledge, reasoning, and calculation) reveal these models’ strengths and limitations, providing valuable insights into future directions for enhancing their general capabilities. By concentrating on tasks pertinent to human cognition and decision-making, our benchmark delivers a more meaningful and robust evaluation of foundation models’ performance in real-world scenarios2.},
	language = {en},
	urldate = {2023-09-10},
	publisher = {arXiv},
	author = {Zhong, Wanjun and Cui, Ruixiang and Guo, Yiduo and Liang, Yaobo and Lu, Shuai and Wang, Yanlin and Saied, Amin and Chen, Weizhu and Duan, Nan},
	month = {April},
	year = {2023},
	note = {arXiv:2304.06364 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	annote = {Comment: 19 pages},
	file = {Zhong et al. - 2023 - AGIEval A Human-Centric Benchmark for Evaluating .pdf:/Users/yosephineyosephine/Zotero/storage/36U4SYUL/Zhong et al. - 2023 - AGIEval A Human-Centric Benchmark for Evaluating .pdf:application/pdf},
}

@article{cole1990principles,
  title={Principles and {Parameters} of {Long-distance} {Reflexives}},
  author={Cole, Peter and Hermon, Gabriella and Sung, Li-May},
  journal={Linguistic inquiry},
  pages={1--22},
  year={1990},
  publisher={JSTOR}
}

@book{cole2000long,
  title={Long {Distance} {Reflexives}},
  author={Cole, Peter and Hermon, Gabriella and Huang, C-T James},
  volume={33},
  year={2000},
  publisher={Brill}
}

@article{mccloskey2006resumption,
  title={Resumption},
  author={McCloskey, James},
  journal={The Blackwell companion to syntax},
  pages={94--117},
  year={2006},
  publisher={Wiley Online Library}
}

@article{mccloskey2002resumption,
  title={Resumption, {Successive} {Cyclicity}, and the {Locality} of {Operations}},
  author={McCloskey, James},
  journal={Derivation and explanation in the minimalist program},
  pages={184--226},
  year={2002},
  publisher={Wiley Online Library}
}

@inproceedings{grusky2023rogue,
  title={Rogue {Scores}},
  author={Grusky, Max},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1914--1934},
  year={2023}
}

@book{tenali_selected_2008,
	title = {Selected Stories of Tenali Raman},
        author = {Jude, Brian},
	isbn = {978-81-88759-46-0},
	url = {https://books.google.com.sg/books?id=tUFNPgAACAAJ},
	publisher = {Spider Books},
	year = {2008},
}

@book{tenali_bestof_2005,
	title = {The Best of Tenali Raman},
        author = {Jude, Brian},
	isbn = {978-81-88759-07-1},
	url = {https://www.abebooks.com/9788188759071/Best-Tenali-Raman-Spider-Books-8188759074/plp},
	publisher = {Spider Books},
	year = {2005},
}

@book{tenali_famous_2007,
	title = {Famous Stories of Tenali Raman},
        author = {Jude, Brian},
	isbn = {978-81-88759-43-9},
	url = {https://books.google.com.sg/books/about/Famous_Stories_Of_Tenali_Raman.html?id=BIpVPgAACAAJ&redir_esc=y},
	publisher = {Spider Books},
	year = {2007},
}

@book{tenali_favourite_2008,
	title = {Favourite Stories of Tenali Raman},
        author = {Jude, Brian},
	isbn = {978-81-88759-44-6},
	url = {https://books.google.com.sg/books/about/Favourite_Stories_Of_Tenali_Raman.html?id=e4lJPgAACAAJ&redir_esc=y},
	publisher = {Spider Books},
	year = {2008},
}

@book{tenali_popular_2008,
	title = {Popular Stories of Tenali Raman},
        author = {Jude, Brian},
	isbn = {978-81-88759-45-3},
	url = {https://www.amazon.com/Popular-Stories-Tenali-Raman-Spider/dp/8188759457},
	publisher = {Spider Books},
	year = {2008},
}

@article{jeoung2020whagree,
  title={{WH-agreement} {Across} {Three} {Domains} in {Indonesian}},
  author={Jeoung, Helen},
  journal={University of Pennsylvania Working Papers in Linguistics},
  volume={26},
  number={1},
  pages={14},
  year={2020}
}

@article{jeoung2020mauandsuka,
  title={Categorial {Ambiguity} in \textit{mau}, \textit{suka}, and {Other} {Indonesian} {Predicates}},
  author={Jeoung, Helen},
  journal={Language},
  volume={96},
  number={3},
  pages={157--172},
  year={2020},
  publisher={Linguistic Society of America}
}

@article{schiffman2004tamil,
  title={The {Tamil} {Case} {System}},
  author={Schiffman, Harold F},
  journal={South Indian Horizons: Felicitation Volume for Francois Gros on the Occasion of his 70th Birthday},
  pages={293--322},
  year={2004}
}

@incollection{lehmann2019old,
  title={Old {Tamil}},
  author={Lehmann, Thomas},
  booktitle={The Dravidian Languages},
  pages={81--103},
  year={2019},
  publisher={Routledge}
}

@inproceedings{sato2016situ,
  title={An {In-situ} {Syntax} of {Sluicing} in {Indonesian}},
  author={Sato, Yosuke},
  booktitle={The proceedings of AFLA},
  volume={23},
  pages={243--57},
  year={2016}
}

@book{legate2014voice,
  title={Voice and v: {Lessons} from {Acehnese}},
  author={Legate, Julie Anne},
  volume={69},
  year={2014},
  publisher={MIT Press}
}

@inproceedings{annamalai2013variable,
  title={The {Variable} {Relation} of {Verbs} in {Sequence} in {Tamil}},
  author={Annamalai, Elai},
  booktitle={NINJAL International Symposium},
  year={2013}
}

@mastersthesis{pong2022syntax,
    author = {Pong, Benjamin Wai Hoe},
    type = {Bachelor's Thesis},
    title = {The {Syntax} of {Tamil} {Periphrastic} {Causatives}: {A} {Morphosemantic} {Exponence}},
    school = {The National University of Singapore},
    year = {2022}
}

@article{annamalai2003constituent,
  title={The {Constituent} {Structure} of {Tamil}},
  author={Annamalai, Elai},
  journal={The Yearbook of South Asian Languages and Linguistics},
  pages={3--46},
  year={2003},
  publisher={Sage Publications}
}


@inproceedings{fortin2009leftper,
  title={On the {Left} {Periphery} in {Indonesian}},
  author={Fortin, Catherine Rose},
  booktitle={Proceedings of the Sixteenth Meeting of the Austronesian Formal Linguistics Association (AFLA), ed. Sandy Chung, Daniel Finer, Ileana Paul, and Eric Postdam},
  pages={29--43},
  publisher={University of California, Santa Cruz},
  year={2009}
  
}

@book{schiffman1999reference,
  title={A {Reference} {Grammar} of {Spoken} {Tamil}},
  author={Schiffman, Harold F},
  year={1999},
  publisher={Cambridge University Press}
}

@misc{anil2023palm,
      title={{PaLM} 2 {Technical} {Report}}, 
      author={Rohan Anil and Andrew M. Dai and Orhan Firat and Melvin Johnson and Dmitry Lepikhin and Alexandre Passos and Siamak Shakeri and Emanuel Taropa and Paige Bailey and Zhifeng Chen and Eric Chu and Jonathan H. Clark and Laurent El Shafey and Yanping Huang and Kathy Meier-Hellstern and Gaurav Mishra and Erica Moreira and Mark Omernick and Kevin Robinson and Sebastian Ruder and Yi Tay and Kefan Xiao and Yuanzhong Xu and Yujing Zhang and Gustavo Hernandez Abrego and Junwhan Ahn and Jacob Austin and Paul Barham and Jan Botha and James Bradbury and Siddhartha Brahma and Kevin Brooks and Michele Catasta and Yong Cheng and Colin Cherry and Christopher A. Choquette-Choo and Aakanksha Chowdhery and Clément Crepy and Shachi Dave and Mostafa Dehghani and Sunipa Dev and Jacob Devlin and Mark Díaz and Nan Du and Ethan Dyer and Vlad Feinberg and Fangxiaoyu Feng and Vlad Fienber and Markus Freitag and Xavier Garcia and Sebastian Gehrmann and Lucas Gonzalez and Guy Gur-Ari and Steven Hand and Hadi Hashemi and Le Hou and Joshua Howland and Andrea Hu and Jeffrey Hui and Jeremy Hurwitz and Michael Isard and Abe Ittycheriah and Matthew Jagielski and Wenhao Jia and Kathleen Kenealy and Maxim Krikun and Sneha Kudugunta and Chang Lan and Katherine Lee and Benjamin Lee and Eric Li and Music Li and Wei Li and YaGuang Li and Jian Li and Hyeontaek Lim and Hanzhao Lin and Zhongtao Liu and Frederick Liu and Marcello Maggioni and Aroma Mahendru and Joshua Maynez and Vedant Misra and Maysam Moussalem and Zachary Nado and John Nham and Eric Ni and Andrew Nystrom and Alicia Parrish and Marie Pellat and Martin Polacek and Alex Polozov and Reiner Pope and Siyuan Qiao and Emily Reif and Bryan Richter and Parker Riley and Alex Castro Ros and Aurko Roy and Brennan Saeta and Rajkumar Samuel and Renee Shelby and Ambrose Slone and Daniel Smilkov and David R. So and Daniel Sohn and Simon Tokumine and Dasha Valter and Vijay Vasudevan and Kiran Vodrahalli and Xuezhi Wang and Pidong Wang and Zirui Wang and Tao Wang and John Wieting and Yuhuai Wu and Kelvin Xu and Yunhan Xu and Linting Xue and Pengcheng Yin and Jiahui Yu and Qiao Zhang and Steven Zheng and Ce Zheng and Weikang Zhou and Denny Zhou and Slav Petrov and Yonghui Wu},
      year={2023},
      eprint={2305.10403},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      publisher={arXiv},
      note={arXiv:2305.10403 [cs]}
}

@book{poesponegoro1984sejarah,
  title={Sejarah Nasional Indonesia},
  author={Poesponegoro, Marwati Djoened and Notosusanto, Nugroho},
  volume={2},
  year={2019},
  publisher={Balai Pustaka},
  address={Jakarta, Indonesia}
}
@misc{leong2023bhasa,
  title = {BHASA: A Holistic Southeast Asian Linguistic and Cultural Evaluation Suite for Large Language Models},
  author = {Leong, Wei Qi and Ngui, Jian Gang and Susanto, Yosephine and Rengarajan, Hamsawardhini and Sarveswaran, Kengatharaiyer and Tjhi, William Chandra},
  year = {2023},
  eprint = {2309.06085},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  publisher = {arXiv},
  note = {arXiv:2309.06085 [cs.CL]}
}
@article{zhang2024seallms,
  title={Seallms 3: Open foundation and chat multilingual large language models for southeast asian languages},
  author={Zhang, Wenxuan and Chan, Hou Pong and Zhao, Yiran and Aljunied, Mahani and Wang, Jianyu and Liu, Chaoqun and Deng, Yue and Hu, Zhiqiang and Xu, Weiwen and Chia, Yew Ken and others},
  journal={arXiv preprint arXiv:2407.19672},
  year={2024}
}
@misc{sailor2report,
  title={Sailor2: Sailing in South-East Asia with Inclusive Multilingual LLM},
  author={{Sailor2 Team}},
  year={2024}
}
@article{bai2023qwen,
  title={Qwen technical report},
  author={Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and others},
  journal={arXiv preprint arXiv:2309.16609},
  year={2023}
}
@article{dang2024aya,
  title={Aya expanse: Combining research breakthroughs for a new multilingual frontier},
  author={Dang, John and Singh, Shivalika and D'souza, Daniel and Ahmadian, Arash and Salamanca, Alejandro and Smith, Madeline and Peppin, Aidan and Hong, Sungjin and Govindassamy, Manoj and Zhao, Terrence and others},
  journal={arXiv preprint arXiv:2412.04261},
  year={2024}
}
@misc{damonlp2024seallm3,
  author = {Zhang, Wenxuan and Chan, Hou Pong and Zhao, Yiran and Aljunied, Mahani and Wang, Jianyu and Liu, Chaoqun and Deng, Yue and Hu, Zhiqiang and Xu, Weiwen and Chia, Yew Ken and Li, Xin and Bing, Lidong},
  title = {SeaLLMs 3: Open Foundation and Chat Multilingual Large Language Models for Southeast Asian Languages},
  year = {2024},
  url = {https://arxiv.org/abs/2407.19672}
}
@misc{damonlpsg2023seallm,
  author = {Nguyen, Xuan-Phi and Zhang, Wenxuan and Li, Xin and Aljunied, Mahani and Hu, Zhiqiang and Shen, Chenhui and Chia, Yew Ken and Li, Xingxuan and Wang, Jianyu and Tan, Qingyu and Cheng, Liying and Chen, Guanzheng and Deng, Yue and Yang, Sen and Liu, Chaoqun and Zhang, Hang and Bing, Lidong},
  title = {SeaLLMs - Large Language Models for Southeast Asia},
  year = {2024},
  booktitle = {ACL 2024 System Demonstrations},
  url = {https://arxiv.org/pdf/2312.00738}
}
@article{wang2023seaeval,
  title={SeaEval for multilingual foundation models: From cross-lingual alignment to cultural reasoning},
  author={Wang, Bin and Liu, Zhengyuan and Huang, Xin and Jiao, Fangkai and Ding, Yang and Aw, AiTi and Chen, Nancy F},
  journal={arXiv preprint arXiv:2309.04766},
  year={2023}
}
@article{singh2024global,
  title={Global mmlu: Understanding and addressing cultural and linguistic biases in multilingual evaluation},
  author={Singh, Shivalika and Romanou, Angelika and Fourrier, Cl{\'e}mentine and Adelani, David I and Ngui, Jian Gang and Vila-Suero, Daniel and Limkonchotiwat, Peerat and Marchisio, Kelly and Leong, Wei Qi and Susanto, Yosephine and others},
  journal={arXiv preprint arXiv:2412.03304},
  year={2024}
}
@article{zhou2023instruction,
  title={Instruction-following evaluation for large language models},
  author={Zhou, Jeffrey and Lu, Tianjian and Mishra, Swaroop and Brahma, Siddhartha and Basu, Sujoy and Luan, Yi and Zhou, Denny and Hou, Le},
  journal={arXiv preprint arXiv:2311.07911},
  year={2023}
}
@article{zheng2023judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46595--46623},
  year={2023}
}
@misc{SeaExam2023,
  author       = {DAMO-NLP-SG},
  title        = {SeaExam},
  year         = {2024},
  url          = {https://github.com/DAMO-NLP-SG/SeaExam},
  note         = {Accessed: 2025-02-04},
}
@misc{CohereForAI_mArenaHard,
  author       = {CohereForAI},
  title        = {m-ArenaHard},
  year         = {2024},
  url          = {https://huggingface.co/datasets/CohereForAI/m-ArenaHard},
  note         = {Accessed: 2025-02-04},
}
@misc{MTBench_Thai,
  author       = {ThaiLLM-Leaderboard},
  title        = {MT-Bench Thai},
  year         = {2024},
  url          = {https://huggingface.co/datasets/ThaiLLM-Leaderboard/mt-bench-thai},
  note         = {Accessed: 2025-02-04},
}
@misc{montalan2024kalahihandcraftedgrassrootscultural,
      title={Kalahi: A handcrafted, grassroots cultural LLM evaluation suite for Filipino}, 
      author={Jann Railey Montalan and Jian Gang Ngui and Wei Qi Leong and Yosephine Susanto and Hamsawardhini Rengarajan and Alham Fikri Aji and William Chandra Tjhi},
      year={2024},
      eprint={2409.15380},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.15380}, 
}

@article{causadias2020culture,
  title={What is culture? {S}ystems of people, places, and practices},
  author={Causadias, Jos{\'e} M},
  journal={Applied Developmental Science},
  volume={24},
  number={4},
  pages={310--322},
  year={2020},
  publisher={Taylor \& Francis}
}

@article{swidler1986culture,
  title={{C}ulture in action: {S}ymbols and strategies},
  author={Swidler, Ann},
  journal={American Sociological Review},
  pages={273--286},
  year={1986},
  publisher={JSTOR},
}
@article{romero2024cvqa,
  title={Cvqa: Culturally-diverse multilingual visual question answering benchmark},
  author={Romero, David and Lyu, Chenyang and Wibowo, Haryo Akbarianto and Lynn, Teresa and Hamed, Injy and Kishore, Aditya Nanda and Mandal, Aishik and Dragonetti, Alina and Abzaliev, Artem and Tonja, Atnafu Lambebo and others},
  journal={arXiv preprint arXiv:2406.05967},
  year={2024},
}
@misc{atari2023humans,
  title={Which humans?},
  author={Atari, Mohammad and Xue, Mona J and Park, Peter S and Blasi, Dami{\'a}n and Henrich, Joseph},
  year={2023},
  publisher={PsyArXiv}
}
@article{koto2024indoculture,
  title={IndoCulture: Exploring Geographically-Influenced Cultural Commonsense Reasoning Across Eleven Indonesian Provinces},
  author={Koto, Fajri and Mahendra, Rahmad and Aisyah, Nurul and Baldwin, Timothy},
  journal={arXiv preprint arXiv:2404.01854},
  year={2024}
}
@article{song2024multilingual,
  title={Multilingual blending: Llm safety alignment evaluation with language mixture},
  author={Song, Jiayang and Huang, Yuheng and Zhou, Zhehua and Ma, Lei},
  journal={arXiv preprint arXiv:2407.07342},
  year={2024}
}
@article{shen2024language,
  title={The language barrier: Dissecting safety challenges of llms in multilingual contexts},
  author={Shen, Lingfeng and Tan, Weiting and Chen, Sihao and Chen, Yunmo and Zhang, Jingyu and Xu, Haoran and Zheng, Boyuan and Koehn, Philipp and Khashabi, Daniel},
  journal={arXiv preprint arXiv:2401.13136},
  year={2024}
}
@inproceedings{birhane2022power,
  title={Power to the people? Opportunities and challenges for participatory AI},
  author={Birhane, Abeba and Isaac, William and Prabhakaran, Vinodkumar and Diaz, Mark and Elish, Madeleine Clare and Gabriel, Iason and Mohamed, Shakir},
  booktitle={Proceedings of the 2nd ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization},
  pages={1--8},
  year={2022}
}
@article{smart2024socially,
  title={Socially Responsible Data for Large Multilingual Language Models},
  author={Smart, Andrew and Hutchinson, Ben and Amugongo, Lameck Mbangula and Dikker, Suzanne and Zito, Alex and Ebinama, Amber and Wudiri, Zara and Wang, Ding and van Liemt, Erin and Sedoc, Jo{\~a}o and others},
  journal={arXiv preprint arXiv:2409.05247},
  year={2024}
}

@article{haimes2024benchmark,
  title={Benchmark inflation: Revealing llm performance gaps using retro-holdouts},
  author={Haimes, Jacob and Wenner, Cenny and Thaman, Kunvar and Tashev, Vassil and Neo, Clement and Kran, Esben and Schreiber, Jason},
  journal={arXiv preprint arXiv:2410.09247},
  year={2024}
}

@misc{li2024languagerankermetricquantifying,
      title={Language Ranker: A Metric for Quantifying LLM Performance Across High and Low-Resource Languages}, 
      author={Zihao Li and Yucheng Shi and Zirui Liu and Fan Yang and Ali Payani and Ninghao Liu and Mengnan Du},
      year={2024},
      eprint={2404.11553},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.11553}, 
}

@misc{liu2024benchmarkinggenerationevaluationcapabilities,
      title={Benchmarking Generation and Evaluation Capabilities of Large Language Models for Instruction Controllable Summarization}, 
      author={Yixin Liu and Alexander R. Fabbri and Jiawen Chen and Yilun Zhao and Simeng Han and Shafiq Joty and Pengfei Liu and Dragomir Radev and Chien-Sheng Wu and Arman Cohan},
      year={2024},
      eprint={2311.09184},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.09184}, 
}

@misc{qadri2025risksculturalerasurelarge,
      title={Risks of Cultural Erasure in Large Language Models}, 
      author={Rida Qadri and Aida M. Davani and Kevin Robinson and Vinodkumar Prabhakaran},
      year={2025},
      eprint={2501.01056},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.01056}, 
}
@article{ColeHermon2005,
	title = {Subject and {Non-subject} {Relativisation} in {Indonesian}},
	volume = {14},
	doi = {https://doi.org/10.1007/s10831-004-2703-3},
	journal = {Journal of East Asian Linguistics},
	author = {Cole, Peter and Hermon, Gabriella},
	month = {January},
	year = {2005},
	pages = {59-88},
}
@misc{cohere2025towards,
  author = {Adithya Venkatadri Hulagadri and Julia Kreutzer and Jian Gang Ngui and Xian Bin Yong},
  title = {Towards Fair and Comprehensive Multilingual and Multicultural LLM Benchmarking},
  year = {2025},
  url = {https://cohere.com/blog/towards-fair-and-comprehensive-multilingual-and-multicultural-llm-benchmarking},
  note = {Accessed: 2025-02-11}
}

@article{cabasag2019hate,
  title={Hate speech in {P}hilippine election-related tweets: {A}utomatic detection and classification using natural language processing},
  author={Cabasag, Neil Vicente and Chan, Vicente Raphael and Lim, Sean Christian and Gonzales, Mark Edward and Cheng, Charibeth},
  journal={Philippine Computing Journal, XIV},
  volume={1},
  year={2019}
}

@inproceedings{kavumba-etal-2019-choosing,
    title = "When {C}hoosing {P}lausible {A}lternatives, {C}lever {H}ans can be {C}lever",
    author = "Kavumba, Pride  and
      Inoue, Naoya  and
      Heinzerling, Benjamin  and
      Singh, Keshav  and
      Reisert, Paul  and
      Inui, Kentaro",
    booktitle = "Proceedings of the First Workshop on Commonsense Inference in Natural Language Processing",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-6004",
    doi = "10.18653/v1/D19-6004",
    pages = "33--42",
    abstract = "Pretrained language models, such as BERT and RoBERTa, have shown large improvements in the commonsense reasoning benchmark COPA. However, recent work found that many improvements in benchmarks of natural language understanding are not due to models learning the task, but due to their increasing ability to exploit superficial cues, such as tokens that occur more often in the correct answer than the wrong one. Are BERT{'}s and RoBERTa{'}s good performance on COPA also caused by this? We find superficial cues in COPA, as well as evidence that BERT exploits these cues.To remedy this problem, we introduce Balanced COPA, an extension of COPA that does not suffer from easy-to-exploit single token cues. We analyze BERT{'}s and RoBERTa{'}s performance on original and Balanced COPA, finding that BERT relies on superficial cues when they are present, but still achieves comparable performance once they are made ineffective, suggesting that BERT learns the task to a certain degree when forced to. In contrast, RoBERTa does not appear to rely on superficial cues.",
}

@misc{ali2024tokenizerchoicellmtraining,
      title={Tokenizer Choice For LLM Training: Negligible or Crucial?}, 
      author={Mehdi Ali and Michael Fromm and Klaudia Thellmann and Richard Rutmann and Max Lübbering and Johannes Leveling and Katrin Klug and Jan Ebert and Niclas Doll and Jasper Schulze Buschhoff and Charvi Jain and Alexander Arno Weber and Lena Jurkschat and Hammam Abdelwahab and Chelsea John and Pedro Ortiz Suarez and Malte Ostendorff and Samuel Weinbach and Rafet Sifa and Stefan Kesselheim and Nicolas Flores-Herr},
      year={2024},
      eprint={2310.08754},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.08754}, 
}
@misc{liu2025seaexamseabenchbenchmarkingllms,
      title={SeaExam and SeaBench: Benchmarking LLMs with Local Multilingual Questions in Southeast Asia}, 
      author={Chaoqun Liu and Wenxuan Zhang and Jiahao Ying and Mahani Aljunied and Anh Tuan Luu and Lidong Bing},
      year={2025},
      eprint={2502.06298},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.06298}, 
}

@inproceedings{bandarkar-etal-2024-belebele,
    title = "The Belebele Benchmark: a Parallel Reading Comprehension Dataset in 122 Language Variants",
    author = "Bandarkar, Lucas  and
      Liang, Davis  and
      Muller, Benjamin  and
      Artetxe, Mikel  and
      Shukla, Satya Narayan  and
      Husa, Donald  and
      Goyal, Naman  and
      Krishnan, Abhinandan  and
      Zettlemoyer, Luke  and
      Khabsa, Madian",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand and virtual meeting",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.44",
    pages = "749--775",
}

@inproceedings{hasan-etal-2021-xl,
    title = "{XL}-{S}um: {L}arge-Scale {M}ultilingual {A}bstractive {S}ummarization for 44 {L}anguages",
    author = "Hasan, Tahmid  and
      Bhattacharjee, Abhik  and
      Islam, Md. Saiful  and
      Mubasshir, Kazi  and
      Li, Yuan-Fang  and
      Kang, Yong-Bin  and
      Rahman, M. Sohel  and
      Shahriyar, Rifat",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.413",
    doi = "10.18653/v1/2021.findings-acl.413",
    pages = "4693--4703",
}


@inproceedings{juraska-etal-2024-metricx,
    title = "{M}etric{X}-24: The {G}oogle Submission to the {WMT} 2024 Metrics Shared Task",
    author = "Juraska, Juraj  and
      Deutsch, Daniel  and
      Finkelstein, Mara  and
      Freitag, Markus",
    editor = "Haddow, Barry  and
      Kocmi, Tom  and
      Koehn, Philipp  and
      Monz, Christof",
    booktitle = "Proceedings of the Ninth Conference on Machine Translation",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.wmt-1.35/",
    doi = "10.18653/v1/2024.wmt-1.35",
    pages = "492--504",
    abstract = "In this paper, we present the MetricX-24 submissions to the WMT24 Metrics Shared Task and provide details on the improvements we made over the previous version of MetricX. Our primary submission is a hybrid reference-based/-free metric, which can score a translation irrespective of whether it is given the source segment, the reference, or both. The metric is trained on previous WMT data in a two-stage fashion, first on the DA ratings only, then on a mixture of MQM and DA ratings. The training set in both stages is augmented with synthetic examples that we created to make the metric more robust to several common failure modes, such as fluent but unrelated translation, or undertranslation. We demonstrate the benefits of the individual modifications via an ablation study, and show a significant performance increase over MetricX-23 on the WMT23 MQM ratings, as well as our new synthetic challenge set."
}
@misc{deepseekai2025deepseekr1incentivizingreasoningcapability,
      title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning}, 
      author={DeepSeek-AI and Daya Guo and Dejian Yang and Haowei Zhang and Junxiao Song and Ruoyu Zhang and Runxin Xu and Qihao Zhu and Shirong Ma and Peiyi Wang and Xiao Bi and Xiaokang Zhang and Xingkai Yu and Yu Wu and Z. F. Wu and Zhibin Gou and Zhihong Shao and Zhuoshu Li and Ziyi Gao and Aixin Liu and Bing Xue and Bingxuan Wang and Bochao Wu and Bei Feng and Chengda Lu and Chenggang Zhao and Chengqi Deng and Chenyu Zhang and Chong Ruan and Damai Dai and Deli Chen and Dongjie Ji and Erhang Li and Fangyun Lin and Fucong Dai and Fuli Luo and Guangbo Hao and Guanting Chen and Guowei Li and H. Zhang and Han Bao and Hanwei Xu and Haocheng Wang and Honghui Ding and Huajian Xin and Huazuo Gao and Hui Qu and Hui Li and Jianzhong Guo and Jiashi Li and Jiawei Wang and Jingchang Chen and Jingyang Yuan and Junjie Qiu and Junlong Li and J. L. Cai and Jiaqi Ni and Jian Liang and Jin Chen and Kai Dong and Kai Hu and Kaige Gao and Kang Guan and Kexin Huang and Kuai Yu and Lean Wang and Lecong Zhang and Liang Zhao and Litong Wang and Liyue Zhang and Lei Xu and Leyi Xia and Mingchuan Zhang and Minghua Zhang and Minghui Tang and Meng Li and Miaojun Wang and Mingming Li and Ning Tian and Panpan Huang and Peng Zhang and Qiancheng Wang and Qinyu Chen and Qiushi Du and Ruiqi Ge and Ruisong Zhang and Ruizhe Pan and Runji Wang and R. J. Chen and R. L. Jin and Ruyi Chen and Shanghao Lu and Shangyan Zhou and Shanhuang Chen and Shengfeng Ye and Shiyu Wang and Shuiping Yu and Shunfeng Zhou and Shuting Pan and S. S. Li and Shuang Zhou and Shaoqing Wu and Shengfeng Ye and Tao Yun and Tian Pei and Tianyu Sun and T. Wang and Wangding Zeng and Wanjia Zhao and Wen Liu and Wenfeng Liang and Wenjun Gao and Wenqin Yu and Wentao Zhang and W. L. Xiao and Wei An and Xiaodong Liu and Xiaohan Wang and Xiaokang Chen and Xiaotao Nie and Xin Cheng and Xin Liu and Xin Xie and Xingchao Liu and Xinyu Yang and Xinyuan Li and Xuecheng Su and Xuheng Lin and X. Q. Li and Xiangyue Jin and Xiaojin Shen and Xiaosha Chen and Xiaowen Sun and Xiaoxiang Wang and Xinnan Song and Xinyi Zhou and Xianzu Wang and Xinxia Shan and Y. K. Li and Y. Q. Wang and Y. X. Wei and Yang Zhang and Yanhong Xu and Yao Li and Yao Zhao and Yaofeng Sun and Yaohui Wang and Yi Yu and Yichao Zhang and Yifan Shi and Yiliang Xiong and Ying He and Yishi Piao and Yisong Wang and Yixuan Tan and Yiyang Ma and Yiyuan Liu and Yongqiang Guo and Yuan Ou and Yuduan Wang and Yue Gong and Yuheng Zou and Yujia He and Yunfan Xiong and Yuxiang Luo and Yuxiang You and Yuxuan Liu and Yuyang Zhou and Y. X. Zhu and Yanhong Xu and Yanping Huang and Yaohui Li and Yi Zheng and Yuchen Zhu and Yunxian Ma and Ying Tang and Yukun Zha and Yuting Yan and Z. Z. Ren and Zehui Ren and Zhangli Sha and Zhe Fu and Zhean Xu and Zhenda Xie and Zhengyan Zhang and Zhewen Hao and Zhicheng Ma and Zhigang Yan and Zhiyu Wu and Zihui Gu and Zijia Zhu and Zijun Liu and Zilin Li and Ziwei Xie and Ziyang Song and Zizheng Pan and Zhen Huang and Zhipeng Xu and Zhongyu Zhang and Zhen Zhang},
      year={2025},
      eprint={2501.12948},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.12948}, 
}
@misc{dang2024ayaexpansecombiningresearch,
      title={Aya Expanse: Combining Research Breakthroughs for a New Multilingual Frontier}, 
      author={John Dang and Shivalika Singh and Daniel D'souza and Arash Ahmadian and Alejandro Salamanca and Madeline Smith and Aidan Peppin and Sungjin Hong and Manoj Govindassamy and Terrence Zhao and Sandra Kublik and Meor Amer and Viraat Aryabumi and Jon Ander Campos and Yi-Chern Tan and Tom Kocmi and Florian Strub and Nathan Grinsztajn and Yannis Flet-Berliac and Acyr Locatelli and Hangyu Lin and Dwarak Talupuru and Bharat Venkitesh and David Cairuz and Bowen Yang and Tim Chung and Wei-Yin Ko and Sylvie Shang Shi and Amir Shukayev and Sammie Bae and Aleksandra Piktus and Roman Castagné and Felipe Cruz-Salinas and Eddie Kim and Lucas Crawhall-Stein and Adrien Morisot and Sudip Roy and Phil Blunsom and Ivan Zhang and Aidan Gomez and Nick Frosst and Marzieh Fadaee and Beyza Ermis and Ahmet Üstün and Sara Hooker},
      year={2024},
      eprint={2412.04261},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.04261}, 

}
@misc{qwen2.5,
    title = {Qwen2.5: A Party of Foundation Models},
    url = {https://qwenlm.github.io/blog/qwen2.5/},
    author = {Qwen Team,Qwen Team},
    month = {September},
    year = {2024}
}

@article{qwen2,
      title={Qwen2 Technical Report}, 
      author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhihao Fan},
      journal={arXiv preprint arXiv:2407.10671},
      year={2024}
}
@misc{gemma_2024,
    title={Gemma},
    url={https://www.kaggle.com/m/3301},
    DOI={10.34740/KAGGLE/M/3301},
    publisher={Kaggle},
    author={Gemma Team,Gemma Team},
    year={2024}
}
@misc{llama_3_1_8b_instruct,
  author = {AI@Meta},
  title = {Llama-3.1-8B-Instruct},
  year = {2024},
  url = {https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct}
}
@misc{llama3modelcard,
    title={Llama 3 Model Card},
    author={AI@Meta},
    year={2024},
    url = {https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md}
}
@misc{openai_gpt4,
  author = {OpenAI},
  title = {GPT-4 Technical Report},
  year = {2023},
  url = {https://cdn.openai.com/papers/gpt-4.pdf}
}
@misc{aisingapore_gemma2_9b_cpt_sealionv3_instruct,
  author = {AI Singapore,AI Singapore},
  title = {Gemma2 9B CPT SEA-LIONv3 Instruct},
  year = {2024},
  url = {https://huggingface.co/aisingapore/gemma2-9b-cpt-sea-lionv3-instruct}
}
@misc{aisingapore_llama3_1_8b_cpt_sealionv3_instruct,
  author = {AI Singapore,AI Singapore},
  title = {Llama3.1 8B CPT SEA-LIONv3 Instruct},
  year = {2024},
  url = {https://huggingface.co/aisingapore/llama3.1-8b-cpt-sea-lionv3-instruct}
}
@misc{anthropic2023claude,
  author       = {Anthropic},
  title        = {Claude: A family of language models},
  year         = {2023},
  url          = {https://www.anthropic.com},
  note         = {Accessed: 2025-02-15}
}
@misc{mistral2023,
  author       = {Mistral AI,Mistral AI},
  title        = {Mistral 7B: Open-weight dense language model},
  year         = {2023},
  url          = {https://mistral.ai},
  note         = {Accessed: 2025-02-15}
}

@article{dam2024complete,
  title={A complete survey on llm-based ai chatbots},
  author={Dam, Sumit Kumar and Hong, Choong Seon and Qiao, Yu and Zhang, Chaoning},
  journal={arXiv preprint arXiv:2406.16937},
  year={2024}
}
@inproceedings{yeo2024selftraining,
  author    = {Wei Jie Yeo and Teddy Ferdinan and Przemyslaw Kazienko and Ranjan Satapathy and Erik Cambria},
  title     = {Self-training Large Language Models through Knowledge Detection},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2024},
  pages     = {15033--15045},
  year      = {2024},
  address   = {November 12-16, 2024},
  publisher = {Association for Computational Linguistics}
}
@misc{lovenia2024seacrowdmultilingualmultimodaldata,
      title={SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages}, 
      author={Holy Lovenia and Rahmad Mahendra and Salsabil Maulana Akbar and Lester James V. Miranda and Jennifer Santoso and Elyanah Aco and Akhdan Fadhilah and Jonibek Mansurov and Joseph Marvin Imperial and Onno P. Kampman and Joel Ruben Antony Moniz and Muhammad Ravi Shulthan Habibi and Frederikus Hudi and Railey Montalan and Ryan Ignatius and Joanito Agili Lopo and William Nixon and Börje F. Karlsson and James Jaya and Ryandito Diandaru and Yuze Gao and Patrick Amadeus and Bin Wang and Jan Christian Blaise Cruz and Chenxi Whitehouse and Ivan Halim Parmonangan and Maria Khelli and Wenyu Zhang and Lucky Susanto and Reynard Adha Ryanda and Sonny Lazuardi Hermawan and Dan John Velasco and Muhammad Dehan Al Kautsar and Willy Fitra Hendria and Yasmin Moslem and Noah Flynn and Muhammad Farid Adilazuarda and Haochen Li and Johanes Lee and R. Damanhuri and Shuo Sun and Muhammad Reza Qorib and Amirbek Djanibekov and Wei Qi Leong and Quyet V. Do and Niklas Muennighoff and Tanrada Pansuwan and Ilham Firdausi Putra and Yan Xu and Ngee Chia Tai and Ayu Purwarianti and Sebastian Ruder and William Tjhi and Peerat Limkonchotiwat and Alham Fikri Aji and Sedrick Keh and Genta Indra Winata and Ruochen Zhang and Fajri Koto and Zheng-Xin Yong and Samuel Cahyawijaya},
      year={2024},
      eprint={2406.10118},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.10118}, 
}






