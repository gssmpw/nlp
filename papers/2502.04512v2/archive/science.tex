\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{url}
\usepackage{hyperref}
\title{AI safety in LLM4Science}

\begin{document}

\maketitle

% \section{Introduction}

% https://www.youtube.com/watch?v=yqKJ9pUQ6Q8 - Judea Pearl about learning causality by 1 level - experimenting, 2 level - imagination, hypothesis.

% \subsection{Control of the hallucinations}

% - Temperature parameter

% \subsection{Evaluation}


\begin{enumerate}
    \item 3 years ago where the field was, 3 years from now where to? reliability governance
    \item consider different concerns and impacts
    \item molecules can be used for warfare (popular argument) 
    \item Philosophy - what is science?
    \item Advocating
    \item ai ethics board
    \item politics in science
    \item history of science
    \item checklist 
    \item red flags/risk level/ decision maps
    
\end{enumerate}

https://podcasters.spotify.com/pod/show/machinelearningstreettalk/episodes/Open-Ended-AI-The-Key-to-Superhuman-Intelligence----Prof--Tim-Rocktschel-e2p8drk


Relevant references - pls upload if you have some others too. These are good overview papers I think.

\begin{enumerate}
    \item Open Questions in Creating Safe Open-ended AI: Tensions Between Control and Creativity - \url{https://arxiv.org/pdf/2006.07495}

    \item Open-Endedness is Essential for Artificial Superhuman Intelligence - \url{https://arxiv.org/abs/2406.04268}

    \item From Text to Life: On the Reciprocal Relationship between Artificial Life and Large Language Models \cite{nisioti2024text}

    \item - \url{https://www.reddit.com/r/singularity/comments/1dacsaq/deepmind_openendedness_is_essential_for/}

    \item - Building Machines that Learn and Think with People
 \url{https://arxiv.org/abs/2408.03943}

    \item - Future Trends for Human-AI Collaboration: A Comprehensive Taxonomy of AI/AGI Using Multiple Intelligences and Learning Styles \url{https://onlinelibrary.wiley.com/doi/pdf/10.1155/2021/8893795}

    \item - Foundational Challenges in Assuring Alignment and Safety of Large Language Models \url{https://arxiv.org/pdf/2404.09932}

    \item The structure of scientific revolutions~\cite{kuhn1997structure} - one of the most influential scientific history books

    \item relevant article: Science in the age of large language models~\cite{birhane2023science}

    \item \url{https://arxiv.org/pdf/2406.06769} DISCOVERYWORLD: A Virtual Environment for Developing and Evaluating Automated Scientific Discovery Agents

    \item Open-endedness in synthetic biology: A route to continual innovation for biological design \cite{stock2024open}
    

    \item The ethics of advanced ai assistants-for human-ai collaboration and ethics reading \cite{gabriel2024ethics}

    \item \url{https://scholar.google.com/citations?hl=en&user=GcvxHWQAAAAJ&view_op=list_works&sortby=pubdate}

    \item \url{https://scholar.google.com/citations?hl=en&user=FczrreMAAAAJ&view_op=list_works&sortby=pubdate}

    \item \url{https://alife.org/} Conference on Artificial Life
    
\end{enumerate}



\section{Introduction}

\subsection{Definition of Open-endedness}
Open-ended AI refers to artificial intelligence systems designed to continuously explore, learn, and evolve without predefined limits or specific goals. The main characteristic defining open-ended system is novelty that is human-learnable.
Does it have to be autonomous? Does it have to be self-improving? Can it have a implicit goal (like when it is uses for security and meant to generate attacks). From the application examples, it seems that there is a broad goal, so it is not completely un-bounded.
\subsection{Examples of Open-Endedness}

\begin{itemize}
    \item Open-endedness for security
    \item Open-endedness for science: a) with physical experiments b) without physical experiments
    \item Open-ended agents
    \item AI-driven evolutionary simulations
    \item Open-ended AI learning environments
    \item Gaming
    \item AI companions
    \item Robotics and embodied AI
    \item Education
    \item Ecosystem Simulations
    \item Creative AI, AI for art
\end{itemize}










\subsection{Examples of Science Gone Wrong: Unethical, Dangerous and Absurd}
\textbf{Tuskegee Syphilis Study} was a study conducted between $1932$ and $1972$ by the United States Public Health Service (PHS) and the Centers for Disease Control and Prevention (CDC) on a group of nearly 400 African American men with syphilis.The purpose of the study was to observe the effects of the disease when untreated, though by the end of the study medical advancements meant it was entirely treatable. The men were not informed of the nature of the experiment, and more than $100$ died as a result.(\href{$https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study$}{Wikipedia}) One can argue that strictly from the scientific point of view, the experiment required the to not inform and/or treat the patients, however unethical this is. In this sense, open-endedness, or science without ethical boundaries can lead to similar outcomes.

\textbf{Discovery of Hyper-toxic Molecules with AI}
ML model used to generate drugs modified to generate toxic molecules. "In less than 6 hours after starting on our
in-house server, our model generated 40,000
molecules that scored within our desired
threshold. In the process, the AI designed
not only VX, but also many other known
chemical warfare agents that we identified
through visual confirmation with structures
in public chemistry databases. Many new
molecules were also designed that looked
equally plausible. These new molecules
were predicted to be more toxic, based on
the predicted LD50 values, than publicly
known chemical warfare agents"~(\cite{urbina2022dual}). The discovery of the agent of unprecedented toxicity is undoubtedly scientifically significant. However, what are the practical use cases for this discovery? And given the climate impact of extended computing hours, would it be ethical to dedicate such resources to this task?

\textbf{Absurd Science} The IG Nobel prize is a parody award to the most useless and weird scientific discoveries of the year. For example, in 1993  Robert W. Faid of Greenville, South Carolina, were awarede the IG Nobel prize in mathematics, for calculating the exact odds (710,609,175,188,282,000 to 1) that Mikhail Gorbachev is the Antichrist. One can argue, that this is a humorous intellectual exercise that is rewarding for the authors and for the observers. Some of the weirdest inventions even proved to be useful later. For example, in 2006, a laureate in biology revealed that the malaria mosquito Anopheles gambiae is attracted to the scent of Limburger cheese. Following this discovery, traps baited with Limburger cheese have been strategically placed to help combat malaria outbreaks in Africa. However, when a discovery of this kind is produced at the expense of limited resources the benefits do not outweigh the cost.

\textbf{Unsolvable Scientific Problems} "Some things are inherently unpredictable or chaotic and even the most powerful AI cannot predict or untangle them substantially better than a human or a computer today. For example, even incredibly powerful AI could predict only marginally further ahead in a chaotic system (such as the three-body problem) in the general case,9 as compared to todayâ€™s humans and computers." "In physics, specifically classical mechanics, the three-body problem is to take the initial positions and velocities (or momenta) of three point masses that orbit each other in space and calculate their subsequent trajectories using Newton's laws of motion and Newton's law of universal gravitation."~\hyperlink{https://darioamodei.com/machines-of-loving-grace}{Machines Of Loving Grace}

Unlike the two-body problem, the three-body problem has no general closed-form solution, meaning there is no equation that always solves it.[1] When three bodies orbit each other, the resulting dynamical system is chaotic for most initial conditions. Because there are no solvable equations for most three-body systems, the only way to predict the motions of the bodies is to estimate them using numerical methods. " ~\hyperlink{https://en.wikipedia.org/wiki/Three-body_problem}{Wikipedia}


\section{Possible Domains}

-biology and medicine

-social sciences

- physics 

\section{Existing Human in the Loop Frameworks}

- to be done

The science can be viewed from two perspectives - epistemic and pragmatic. In pragmatic sense the AI-driven science is justifiable. From the epistemic point of view, it is unclear what knowledge humanity would gain. Even if humans were able to understand the scientific process, one might argue, that human in the loop would slow down the process.

\bibliography{main}
\bibliographystyle{abbrv}
\end{document}
