\section{Introduction}

The integration of retrieval-augmented generation (RAG) with large language models (LLMs)~\cite{lewis2020retrieval} has emerged as a pivotal advancement in mitigating the issue of factual hallucination~\cite{ji2023survey}—an inherent limitation of LLMs when generating knowledge-intensive responses. By leveraging external knowledge sources, %which generally consist of several retrieved documents, 
RAG enables LLMs to utilize relevant knowledge dynamically, enhancing both the accuracy and reliability of their outputs. 

RAG is especially crucial in the context of specialized domains, where precision is paramount and errors can be costly. Also, in RAG, LLMs must not only incorporate the relevant external information as the input, but also contextualize the information within the nuances of the target domain. To optimize the RAG-LLM for a specific domain, recently domain-specific RAG~\cite{RAFT} has been developed where LLMs can early access the target domain through finetuning. The practicality of the domain-specific RAG is more noteworthy when computational resources are limited such as edge devices since with only a small-scaled LLM some tasks should be performed reliably.
%small-scale LLMs may need to be specialized to some selected tasks.
\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/intro2.png}
    \caption{\textbf{Performance for domain-specific RAG on HotPotQA dataset on LLaMA3-8B with LoRA adapter.} The marginal effect of CoT (59.2\% $\rightarrow$ 60.6\%) is because of the generated incorrect reasoning which severely degrades the performance.}
    \label{fig:intro}
    \vspace{-0.2cm}
\end{figure}

Despite the promise of the domain-specific RAG, the input external knowledge (generally retrieved information dubbed contexts) may consist of both irrelevant and relevant contexts. 
Hence, reasoning process such as chain-of-thought (CoT)~\cite{wei2022chain} is useful for understanding and focusing on the relevant context. To this end, in RAFT~\cite{RAFT}, LLM learns the reasoning as well as answering in finetuning. Also, in~\cite{con}, the reasoning is prompted to generate a summary of all the contexts. Elaborated reasoning is beneficial, and yet obtaining this kind of reasoning dataset for domain-specific learning is time-consuming and costful, and also it incurs a large testing cost. 

\begin{figure*}[t]
    \centering
    %\includegraphics[width=\linewidth]{figure/main.png}
    \includegraphics[width=\linewidth]{figure/main2.png}
    \vspace{-0.5cm}
    \caption{\textbf{Illustration of the proposed chain-of-rank for domain-specific RAG.} CoR streamlines the reasoning step, which is easier to be learned.}
    \label{fig:main}
    \vspace{-0.3cm}
\end{figure*}

Unreliability of reasoning is also a critical issue, especially when the parameter-efficient fine-tuning (PEFT) like LoRA adapters~\cite{hu2021lora,huang2023lorahub,bang2024crayon} are used to reduce the computational burden in training resource constraint environment. Namely, the PEFT adapters are efficient but lack enough learning capacities, and then struggle to learn the intricate reasoning process. As shown in Fig.~\ref{fig:intro}, LLaMA3-8B~\cite{dubey2024llama} with LoRA exhibits marginal gains when learned with CoT. It means that the intricate reasoning can become a hindrance~\cite{shi2023large} in resource-constrained domain-specific RAG.
% reasoning 자체가 hallucination, retrieved context에 정확한 정보가 이미 포함.


Instead of focusing the intricate reasoning processes, we narrow the focus to the ranking of the contexts' relevance, then the LLM can streamline its reasoning and reduce the cognitive load required to generate accurate final answers. Building on this insight, we propose the Chain-of-Rank (CoR) approach. In this method, the model is learned to output just the ID of the contexts which are relevant to the query, and the answer. Then, CoR not only reduces computational complexity but also enables the LLM to concentrate more fully on the critical information, leading to more accurate and domain-specific outputs. This focus on relevance rather than elaborate reasoning aligns well with the resource limitations of small-scale LLMs and edge devices.
