@article{asai2023self,
  title={Self-rag: Learning to retrieve, generate, and critique through self-reflection},
  author={Asai, Akari and Wu, Zeqiu and Wang, Yizhong and Sil, Avirup and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2310.11511},
  year={2023}
}

@article{con,
      title={Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models}, 
      author={Wenhao Yu and Hongming Zhang and Xiaoman Pan and Kaixin Ma and Hongwei Wang and Dong Yu},
      year={2023},
      journal={ArXiv:2311.09210}, 
}

@inproceedings{linra,
  title={RA-DIT: Retrieval-Augmented Dual Instruction Tuning},
  author={Lin, Xi Victoria and Chen, Xilun and Chen, Mingda and Shi, Weijia and Lomeli, Maria and James, Richard and Rodriguez, Pedro and Kahn, Jacob and Szilvasy, Gergely and Lewis, Mike and others},
  booktitle={Proceedings on International Conference on Learning Representations},
  year={2024}
}

@inproceedings{shi2023large,
  title={Large language models can be easily distracted by irrelevant context},
  author={Shi, Freda and Chen, Xinyun and Misra, Kanishka and Scales, Nathan and Dohan, David and Chi, Ed H and Sch{\"a}rli, Nathanael and Zhou, Denny},
  booktitle={International Conference on Machine Learning},
  year={2023}
}

@inproceedings{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}

@article{wang2024chain,
  title={Chain-of-thought reasoning without prompting},
  author={Wang, Xuezhi and Zhou, Denny},
  journal={arXiv preprint arXiv:2402.10200},
  year={2024}
}

@inproceedings{wanginstructretro,
  title={InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining},
  author={Wang, Boxin and Ping, Wei and McAfee, Lawrence and Xu, Peng and Li, Bo and Shoeybi, Mohammad and Catanzaro, Bryan},
  booktitle={Proceedings on International Conference on Machine Learning},
  year={2024}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@inproceedings{yasunaga2023large,
  title={Large language models as analogical reasoners},
  author={Yasunaga, Michihiro and Chen, Xinyun and Li, Yujia and Pasupat, Panupong and Leskovec, Jure and Liang, Percy and Chi, Ed H and Zhou, Denny},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

