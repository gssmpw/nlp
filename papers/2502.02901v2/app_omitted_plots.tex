\subsection{Average Empirical Game Size over TE-PSRO Epochs}\label{app:game_size}

\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{0.5\textwidth}
    \caption{\barg}
    \includegraphics[width=\textwidth]{figs/game_size_plots/empirical_game_mem_6_27.png}
    \label{fig:mem_barg}
    \end{subfigure}~
    \begin{subfigure}[b]{0.5\textwidth}
    \caption{\gengoofK{4}}
    \includegraphics[width=\textwidth]{figs/empirical_game_mem_4rounds_822.png}
     \label{fig:memory_gengoof}
    \end{subfigure}
    \caption{Memory in megabytes (MB) required by empirical game $\hat{G}$ over the course of TE-PSRO's runtime, averaged over all combinations of all parameters (except $M$) and seeds.}
    \label{fig:game_size_app}
\end{figure}
Fig.~\ref{fig:game_size} in \S\ref{sec:exp_results} and 
Fig.~\ref{fig:game_size_app} above together underscore the effectiveness of our heuristic of a choosing a subset of $M$ information sets to augment with outgoing edges based on the latest best response in keeping the empirical game tree growth tractable for both \barg and \gengoofK{4}. However, there is one stark difference between the results for these two games that merits elaboration: for \gengoofK{4}, the game size is significantly more consistent over time with a lower variance than for \barg as indicated by the smaller error bars for \gengoofK{4}. 

The likely reason for the above observation is that \gengoofK{4} by design consists of fewer rounds of player action ($3$ per player) than \barg ($5$ per player), which means that fewer epochs of TE-PSRO passed before a complete empirical history was included in the game of \gengoofK{4} instead of a default policy being assumed for the remainder of a history, as described in Section~\ref{sec:expand_game_tree}. For \barg, depending on the choice of $M$ and where the new best response policy was added, this results in higher variability in the lengths of these histories, hence higher variability in the number of information sets that comprised $\hat{G}$. Additionally, despite the size of $\hat{G}$ being more consistent, \gengoofK{4} did result in a larger empirical game tree than \barg (compare the vertical axes of Figs.~\ref{fig:mem_barg} and~\ref{fig:memory_gengoof}). This is not particularly surprising since \barg by design began with two stochastic rounds, each containing a binary event, while \gengoofK{4} included three stochastic rounds with a decreasing number of possible outcomes per event (four, then three, then two); this led to significantly more player information sets for \gengoofK{4} once these events were publically realized.


\subsection{Average Regret Over Time Given $M$ For Different Choices of MSS}

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{figs/true_regret_plots_by_num_br/true_regret_7_4_M1_no_NF.png}
    \caption{$M = 1$}
    \label{fig:app_regret_M1_no_NF}
    \end{subfigure}~
    \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{figs/true_regret_plots_by_num_br/true_regret_7_4_M2_no_NF.png}
    \caption{$M = 2$}
    \label{fig:app_regret_M2_no_NF}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{figs/true_regret_plots_by_num_br/true_regret_7_4_M4_no_NF.png}
    \caption{$M = 4$}
    \label{fig:app_regret_M4_no_NF}
    \end{subfigure}~
    \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{figs/true_regret_plots_by_num_br/true_regret_7_3_M8_no_NF.png}
    \caption{$M = 8$}
    \label{fig:app_regret_M8_no_NF}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{figs/true_regret_plots_by_num_br/true_regret_7_4_M16_no_NF.png}
    \caption{$M = 16$}
    \label{fig:app_regret_M16_no_NF}
    \end{subfigure}
    \caption{Average regret of evaluated solution from empirical game $\hat{G}$ in true game over the course of TE-PSRO's runtime, using different MSS's for exploration and different values of $M$.}
    \label{fig:app_true_regret_no_NF_by_M}
\end{figure}
\newpage

\subsection{Average Regret Over Time Given $M$ For Different Choices of MSS Compared to Normal-Form}

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{figs/true_regret_plots_by_num_br/true_regret_6_16_M1.png}
    \caption{$M = 1$}
    \label{fig:app_regret_M1}
    \end{subfigure}~
    \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{figs/true_regret_plots_by_num_br/true_regret_6_16_M2.png}
    \caption{$M = 2$}
    \label{fig:app_regret_M2}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{figs/true_regret_plots_by_num_br/true_regret_6_16_M4.png}
    \caption{$M = 4$}
    \label{fig:app_regret_M4}
    \end{subfigure}~
    \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{figs/true_regret_plots_by_num_br/true_regret_6_22_M8.png}
    \caption{$M = 8$}
    \label{fig:app_regret_M8}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{figs/true_regret_plots_by_num_br/true_regret_7_2_M16.png}
    \caption{$M = 16$}
    \label{fig:app_regret_M16}
    \end{subfigure}
    \caption{Average regret of evaluated solution from empirical game $\hat{G}$ in true game over the course of TE-PSRO's runtime, using different MSS's for exploration and different values of $M$. Regret over time for PSRO using a normal-form model included as baseline.}
    \label{fig:app_true_regret}
\end{figure}
\newpage
\subsection{Average Regret Over Time Given MSS and Evaluation Strategy For Different Choices of $M$}

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{figs/true_regret_plots_by_mss/true_regret_ne_mss_ne_eval_7_4.png}
    \caption{NE for true regret evaluation and for MSS}
    \label{fig:app_regret_ne_mss_ne_eval}
    \end{subfigure}~
    \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{figs/true_regret_plots_by_mss/true_regret_spe_mss_ne_eval_7_3.png}
    \caption{NE for true regret evaluation, SPE for MSS}
    \label{fig:app_regret_spe_mss_ne_eval}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{figs/true_regret_plots_by_mss/true_regret_ne_mss_spe_eval_7_4.png}
    \caption{SPE for true regret evaluation, NE for MSS}
    \label{fig:app_regret_ne_mss_spe_eval}
    \end{subfigure}~
    \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{figs/true_regret_plots_by_mss/true_regret_spe_mss_spe_eval_7_4.png}
    \caption{SPE for true regret evaluation and for MSS}
    \label{fig:app_regret_spe_mss_spe_eval}
    \end{subfigure}
    \caption{Average regret of evaluated solution from empirical game $\hat{G}$ in true game over the course of TE-PSRO's runtime, using different MSS's for exploration and different values of $M$.}
    \label{fig:app_true_regret_no_NF}
\end{figure}

\newpage
\subsection{Permutation Test Results for All $M$ and Choices of Evaluation Strategy}
\label{app:p-values}

\begin{table}[ht!]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        $D_{\textsc{obs}}$ & $M$ & EVAL & p-value \\
    \hline
        0.210 & 1 & SPE & 0.286 \\
        -0.587 & 1 & NE & 0.862 \\
        -0.453 & 2 & SPE & 0.823 \\
        -0.152 & 2 & NE & 0.600 \\
        0.787 & 4 & SPE & 0.105 \\
        \textbf{0.124} & \textbf{4} & \textbf{NE} & \textbf{0.007} \\
        \textbf{0.938} & \textbf{8} & \textbf{SPE} & \textbf{0.021} \\
        \textbf{0.908} & \textbf{8} & \textbf{NE} & \textbf{0.006} \\
        0.488 & 16 & SPE & 0.086 \\
        -0.209 & 16 & NE & 0.636 \\
    \hline
    \end{tabular}
    \vspace{1em}
    \caption{Statistically significant p-values are highlighted in boldface. In these cases, we reject the null hypothesis and conclude that the using SPE as the MSS results in a statistically significant improvement in convergence to zero regret over using NE as the MSS, measured using the area under the curve. The area under the curve captures the number of TE-PSRO epochs until convergence as well as the distance on the y-axis from zero regret.}
    \label{tab:regret_perm_k5}
\end{table}

\subsection{Impact of $IR$-based coarsening of \gengoof empirical model on TE-PSRO performance.}
\label{app:IR_gengoof}

Recall that in Fig.~\ref{fig:abstract_spe_mss_chap8}, we see that $IR = [0]$ and $IR = [0, 1]$ yield the best performance regardless of MSS. This is a surprising result since intuition suggests that the more tree structure from the underlying game is incorporated into $\hat{G}$, the better TE-PSRO should perform, converging faster and to a tighter regret. 

A natural explanation for this observation is the complex interaction of $IR$ with the parameter $M$ that we imposed as a strict limit on the growth of $\hat{G}$ when adding best responses (Section~\ref{sec:best_response_augment}). The action edges of $\hat{G}$ either matched the actions of the underlying game in the rounds whose stochastic events were included or represented abstract DRL policies in the rounds of the game whose stochastic events were excluded. Additionally, the policies were learned as best responses for the \textit{entire underlying game} and then added to specific information sets as best responses, while in the rounds containing stochastic events, only the single actions at those information sets which yielded the best performance (i.e., had the maximum learned Q-value of the four available actions) were added as best responses. In this way, including the abstract policies without the stochastic event is a better option for exploiting the tree structure of the underlying game even though less tree structure is technically incorporated into $\hat{G}$. However, if we could add new best responses to all the information sets of $\hat{G}$ in each iteration of TE-PSRO without any limitation on the tree's growth, even for larger games, then it seems likely that including more stochastic rounds in $\hat{G}$ would be beneficial.

