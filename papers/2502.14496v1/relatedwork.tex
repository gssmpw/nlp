\section{Related Work}
\label{gen_inst}
\noindent\textbf{Agents on Interactive Environments} \quad Before the advent of LLMs, agents relied on traditional RL to perform interactions such as clicking and typing~\citep{liu2018learning,humphreys2022data}. However, recent advancements have shifted towards leveraging foundation models with in-context learning or fine-tuning across various interfaces, including mobile~\citep{wang2023enabling,hong2024cogagent}, web~\citep{lai2024autowebglm, deng-etal-2024-multi}, and computer using environments~\citep{xu2024crab, wu2024copilot}. Recently, there are emerging methods designing process rewards~\citep{he2024webvoyager, pan2024autonomous} or language RL~\citep{bai2024digirl} for better performing single agents. 

\noindent\textbf{Interactive Environments for Agents} \quad To effectively evaluate language agents, it is essential to create environments that replicate real-world conditions and deliver accurate rewards~\citep{rawles2024androidinthewild,deng2024mind2web}. MiniWoB++~\citep{shi2017world} is a lightweight framework that features small, synthetic HTML pages with parameterized tasks. WebArena~\citep{zhou2023webarena} and its visual counterpart, VisualWebArena~\citep{koh2024visualwebarena}, simulate websites spanning up to distinct domains, while WorkArena~\citep{drouin2024workarena} focuses on enterprise software. For more specialized environments, WebShop~\citep{yao2022webshop} simulates an e-commerce platform for online shopping. For computer using environment, OSWorld~\citep{xie2024osworld} provides both a user interface and programmatically generated rewards across different apps.

\noindent\textbf{Prompt-Based Multi-agent Learning} \quad Collaboration among multiple LLM agents has shown effective for various tasks~\citep{hong2024metagpt,wu2024autogen,qian-etal-2024-chatdev,wang2025mobileagenteselfevolvingmobileassistant}. However, employing a static architecture without team optimization may restrict the performance and generalization. \citet{chen2024agentverse} selects a fixed number of agents from a set of manual prompt candidates via an additional LLM during each round of discussion. %\citet{zhang2023cumulative} adapt a dynamic directed acyclic graph structure with three LLM roles—the proposer, verifier, and reporter—to iteratively propose, validate, and compile reasoning steps into a comprehensive solution. 
\citet{zhuge2024gptswarm} unify language agent systems by describing them as optimizable computational graphs and develop optimization methods for nodes and edges, enabling automatic improvements of agent prompts and inter-agent orchestration. \citet{liu2024a} employ a layered network to formulate the process of LLM-agent collaboration for arbitrary tasks and introduce an unsupervised algorithm to optimize the team of agents by the individual contributions of agent.