\section{Literature Review}
\vspace{-0.1cm}

\subsection{Text-based Forecasting}

Text-based forecasting explores the predictive power of textual data such as news articles ____, social media ____, or corporate reports ____. By extracting linguistic features such as keywords ____, sentiment ____, raw embedding representations ____ or high-density embedding clusters ____, researchers have shown that it is possible to enhance traditional forecasting models using text-derived information. The findings of these papers imply there is some causal interaction between textual data and the economy. Yet to our knowledge, no papers have explored the bidirectional nature of this relationship; understanding the effect that markets have on news discourse. 
\vspace{-0.1cm}

\subsection{Diachronic Shifts}
\label{sec:diachronic}

Diachronic analysis ____ examines how linguistic phenomena change over time. The process begins by aggregating time-stamped information to create time-specific representations. The aggregation process can be done using averaging ____ or clustering ____, and is considered a design choice dependent on what one is measuring; with averaging suiting cases which aim to detect the dominant shifts. Diachronic shifts tend to be measured using a distance metric between the point-in-time representations. There are several distance metrics that are used in the literature: Cosine Distance (CD) ____, Average Pairwise Distance (APD) ____, Hausdorf Distance (HD) ____ etc. The standard distance metric is CD -- which we use in this paper -- since APD is more commonly used for polysemy detection ____ and HD is sensitive to outliers ____. The reciprocal of CD, Cosine Similarity, is widely used in other NLP applications as a robust and efficient similarity metric ____. 
\vspace{-0.1cm}

\subsection{Causality}
\label{sec:causality}
% \vspace{-0.1cm}

\subsubsection{Causality in Time-series}
\label{sec:caus_in_TS}

Causality in time-series can be inferred using methods like transfer entropy ____, convergent cross mapping ____ and dynamic Bayesian networks ____; these techniques model non-linear effects but are poor at isolating individual lag contributions. Granger causality ____ tests whether past values of one variable can help to predict the future value of another, enabling analysis of individual lag contributions. It does not imply “causation” in a philosophical sense but identifies temporal precedence and predictability. If the inclusion of past values of variable $X$ significantly improves the prediction of variable $Y$, then $X$ is said to "Granger cause" $Y$. Non-linear regression models can be used in a Granger causality test to model non-linear relationships ____.
\vspace{-0.1cm}

\subsubsection{Causality in Text}
\label{sec:cause_in_text}

There are three main research areas that explore "causal" interactions in NLP. Firstly, autoregressive generation which underpins modern generative LLMs is sometimes referred to as "causal language modelling" ____, but this area is not related to the identification of causal relationships with exogenous data. Secondly, causal relation extraction ____ identifies causal relationships between clauses. The final causal NLP research area which is of interest to this paper creates a link between text and observable phenomena in the real world. Text-derived features can be used in causal inference where text is the treatment variable - what causes the outcome - for a temporally static outcome. Past work has found success in medical records ____, politics ____, and mental health ____. This research direction is mature and has developed solutions that encode text with topic models ____ as well as text embeddings ____. However, there has been little work exploring the predictive causal relationship between text and time-series information. Existing methods do not link changes in an LLM-derived semantic space with observable time-series, instead focusing on keywords ____, lexicons, and LDA topics ____, making our framework novel. Further to this, no techniques measure the temporal causality of observable time-series on text.
\vspace{-0.1cm}