% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@inproceedings{litterer-etal-2023-rains,
    title = "When it Rains, it Pours: Modeling Media Storms and the News Ecosystem",
    author = "Litterer, Benjamin  and
      Jurgens, David  and
      Card, Dallas",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.420",
    doi = "10.18653/v1/2023.findings-emnlp.420",
    pages = "6346--6361",
    abstract = "Most events in the world receive at most brief coverage by the news media. Occasionally, however, an event will trigger a media storm, with voluminous and widespread coverage lasting for weeks instead of days. In this work, we develop and apply a pairwise article similarity model, allowing us to identify story clusters in corpora covering local and national online news, and thereby create a comprehensive corpus of media storms over a nearly two year period. Using this corpus, we investigate media storms at a new level of granularity, allowing us to validate claims about storm evolution and topical distribution, and provide empirical support for previously hypothesized patterns of influence of storms on media coverage and intermedia agenda setting.",
}

@article{fry2011sign,
  title={{Sign Restrictions in Structural Vector Autoregressions: A Critical Review}},
  author={Fry, Renee and Pagan, Adrian},
  journal={{Journal of Economic Literature}},
  volume={49},
  number={4},
  pages={938--960},
  year={2011},
  publisher={American Economic Association},
  url={https://www.aeaweb.org/articles?id=10.1257/jel.49.4.938}
}

@article{10.1145/2542182.2542190,
author = {Arias, Marta and Arratia, Argimiro and Xuriguera, Ramon},
title = {{Forecasting with Twitter Data}},
year = {2014},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {1},
issn = {2157-6904},
url = {https://doi.org/10.1145/2542182.2542190},
doi = {10.1145/2542182.2542190},
abstract = {The dramatic rise in the use of social network platforms such as Facebook or Twitter has resulted in the availability of vast and growing user-contributed repositories of data. Exploiting this data by extracting useful information from it has become a great challenge in data mining and knowledge discovery. A recently popular way of extracting useful information from social network platforms is to build indicators, often in the form of a time series, of general public mood by means of sentiment analysis. Such indicators have been shown to correlate with a diverse variety of phenomena.In this article we follow this line of work and set out to assess, in a rigorous manner, whether a public sentiment indicator extracted from daily Twitter messages can indeed improve the forecasting of social, economic, or commercial indicators. To this end we have collected and processed a large amount of Twitter posts from March 2011 to the present date for two very different domains: stock market and movie box office revenue. For each of these domains, we build and evaluate forecasting models for several target time series both using and ignoring the Twitter-related data. If Twitter does help, then this should be reflected in the fact that the predictions of models that use Twitter-related data are better than the models that do not use this data. By systematically varying the models that we use and their parameters, together with other tuning factors such as lag or the way in which we build our Twitter sentiment index, we obtain a large dataset that allows us to test our hypothesis under different experimental conditions. Using a novel decision-tree-based technique that we call summary tree we are able to mine this large dataset and obtain automatically those configurations that lead to an improvement in the prediction power of our forecasting models. As a general result, we have seen that nonlinear models do take advantage of Twitter data when forecasting trends in volatility indices, while linear ones fail systematically when forecasting any kind of financial time series. In the case of predicting box office revenue trend, it is support vector machines that make best use of Twitter data. In addition, we conduct statistical tests to determine the relation between our Twitter time series and the different target time series.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jan,
articleno = {8},
numpages = {24},
keywords = {Box office, Twitter, forecasting, sentiment index, stock market}
}

@inproceedings{drinkall2021predicting,
  title={{Predicting COVID-19 Cases using Reddit Posts and other Online Resources}},
  year={2021},
  author={Felix Drinkall and Janet B. Pierrehumbert},
  booktitle={SwissText},
  url={https://ceur-ws.org/Vol-2957/paper4.pdf},
  organization={CEUR Workshop Proceedings}
}

@article{rahimikia2024r,
  title={{Re (Visiting) Large Language Models in Finance}},
  author={Rahimikia, Eghbal and Drinkall, Felix and others},
  journal={Available at SSRN},
  year={2024},
  url={https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4963618}
}

@inproceedings{wang2024newsforecast,
   title={{From News to Forecast: Integrating Event Analysis in LLM-Based Time Series Forecasting with Reflection}},
   author={Wang, Xinlei and Feng, Maike and Qiu, Jing and Gu, Jinjin and Zhao, Junhua},
   booktitle={Neural Information Processing Systems},
   year={2024},
   url={https://neurips.cc/virtual/2024/poster/93316}
}

@article{HOBOLT_LAWALL_TILLEY_2024, 
    title={{The Polarizing Effect of Partisan Echo Chambers}}, 
    volume={118}, 
    DOI={10.1017/S0003055423001211}, 
    number={3}, 
    journal={American Political Science Review}, 
    author={Hobolt, Sara B. and Lawall, Katharina and Tilley, James}, 
    year={2024}, 
    pages={1464–1479}
}

@article{einav2014economics,
  title={{Economics in the Age of Big Data}},
  author={Einav, Liran and Levin, Jonathan},
  journal={Science},
  volume={346},
  number={6210},
  pages={1243089},
  year={2014},
  publisher={American Association for the Advancement of Science},
  url={https://www.science.org/doi/pdf/10.1126/science.1243089}
}

@article{
doi:10.1073/pnas.2013464118,
author = {Andrew M. Guess  and Pablo Barberá  and Simon Munzert  and JungHwan Yang },
title = {{The Consequences of Online Partisan Media}},
journal = {Proceedings of the National Academy of Sciences},
volume = {118},
number = {14},
pages = {e2013464118},
year = {2021},
doi = {10.1073/pnas.2013464118},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.2013464118},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.2013464118},
abstract = {Popular wisdom suggests that the internet plays a major role in influencing people’s attitudes and behaviors related to politics, such as by providing slanted sources of information. Yet evidence for this proposition is elusive due to methodological difficulties and the multifaceted nature of online media effects. This study breaks ground by demonstrating a nudge-like approach for exploring these effects through a combination of real-world experimentation and computational social science techniques. The results confirm that it is difficult for people to be persuaded by competing media accounts during a contentious election campaign. At the same time, data from a longer time span suggest that the real consequence of online partisan media may be an erosion of trust in mainstream news. What role do ideologically extreme media play in the polarization of society? Here we report results from a randomized longitudinal field experiment embedded in a nationally representative online panel survey (N = 1,037) in which participants were incentivized to change their browser default settings and social media following patterns, boosting the likelihood of encountering news with either a left-leaning (HuffPost) or right-leaning (Fox News) slant during the 2018 US midterm election campaign. Data on ≈ 19 million web visits by respondents indicate that resulting changes in news consumption persisted for at least 8 wk. Greater exposure to partisan news can cause immediate but short-lived increases in website visits and knowledge of recent events. After adjusting for multiple comparisons, however, we find little evidence of a direct impact on opinions or affect. Still, results from later survey waves suggest that both treatments produce a lasting and meaningful decrease in trust in the mainstream media up to 1 y later. Consistent with the minimal-effects tradition, direct consequences of online partisan media are limited, although our findings raise questions about the possibility of subtle, cumulative dynamics. The combination of experimentation and computational social science techniques illustrates a powerful approach for studying the long-term consequences of exposure to partisan news.}}


@article{Epstude2022,
  author    = {Kai Epstude and Daniel A. Effron and Neal J. Roese},
  title     = {{Polarized Imagination: Partisanship Influences the Direction and Consequences of Counterfactual Thinking}},
  journal   = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume    = {377},
  number    = {1866},
  pages     = {20210342},
  year      = {2022},
  month     = {December},
  doi       = {10.1098/rstb.2021.0342},
  pmid      = {36314153},
  pmcid     = {PMC9619232},
  issn      = {1471-2970},
  publisher = {The Royal Society},
  url       = {https://doi.org/10.1098/rstb.2021.0342},
  abstract  = {Four studies examine how political partisanship qualifies previously documented regularities in people's counterfactual thinking (n = 1186 Democrats and Republicans). First, whereas prior work finds that people generally prefer to think about how things could have been better instead of worse (i.e. entertain counterfactuals in an upward versus downward direction), studies 1a-2 find that partisans are more likely to generate and endorse counterfactuals in whichever direction best aligns with their political views. Second, previous research finds that the closer someone comes to causing a negative event, the more blame that person receives; study 3 finds that this effect is more pronounced among partisans who oppose (versus support) a leader who 'almost' caused a negative event. Thus, partisan reasoning may influence which alternatives to reality people will find most plausible, will be most likely to imagine spontaneously, and will view as sufficient grounds for blame.},
  keywords  = {counterfactual thinking, mental simulation, moral judgement, motivated reasoning, political partisanship}
}

@InProceedings{10.1007/978-3-031-41682-8_4,
author="Doshi, Chinesh
and Shrotiya, Himani
and Bhiogade, Rohit
and Bhatt, Himanshu S.
and Jha, Abhishek",
editor="Fink, Gernot A.
and Jain, Rajiv
and Kise, Koichi
and Zanibbi, Richard",
title={Analyzing Textual Information from Financial Statements for Default Prediction},
booktitle="Document Analysis and Recognition - ICDAR 2023",
year="2023",
publisher="Springer Nature Switzerland",
address="Cham",
pages="48--65",
abstract="Financial statements provide a view of company's financial status at a specific point in time including the quantitative as well as qualitative view. Besides the quantitative information, the paper asserts that the qualitative information present in the form of textual disclosures have high discriminating power to predict the financial default. Towards this, the paper presents a technique to capture comprehensive 360-{\$}{\$}^{\{}{\backslash}circ {\}}{\$}{\$}∘features from qualitative textual data at multiple granularities. The paper proposes a new sentence embedding (SE) from large language models specifically built for financial domain to encode the textual data and presents three deep learning models built on SE for financial default prediction. To accommodate unstructured and non-standard financial statements from small and unlisted companies, the paper also presents a document processing pipeline to be inclusive of such companies in the financial text modelling. Finally, the paper presents comprehensive experimental results on two datasets demonstrating the discriminating power of textual features to predict financial defaults.",
isbn="978-3-031-41682-8"
}



@inproceedings{kogan-etal-2009-predicting,
    title = "{Predicting Risk from Financial Reports with Regression}",
    author = "Kogan, Shimon  and
      Levin, Dimitry  and
      Routledge, Bryan R.  and
      Sagi, Jacob S.  and
      Smith, Noah A.",
    editor = "Ostendorf, Mari  and
      Collins, Michael  and
      Narayanan, Shri  and
      Oard, Douglas W.  and
      Vanderwende, Lucy",
    booktitle = "Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics",
    month = jun,
    year = "2009",
    address = "Boulder, Colorado",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N09-1031/",
    pages = "272--280"
}

@misc{drinkall2025financialregression,
      title={{When Dimensionality Hurts: The Role of LLM Embedding Compression for Noisy Regression Tasks}}, 
      author={Felix Drinkall and Janet B. Pierrehumbert and Stefan Zohren},
      year={2025},
      eprint={2502.02199},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.02199}, 
}

@inproceedings{peng-jiang-2016-leverage,
    title = "{Leverage Financial News to Predict Stock Price Movements Using Word Embeddings and Deep Neural Networks}",
    author = "Peng, Yangtuo  and
      Jiang, Hui",
    editor = "Knight, Kevin  and
      Nenkova, Ani  and
      Rambow, Owen",
    booktitle = "Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N16-1041/",
    doi = "10.18653/v1/N16-1041",
    pages = "374--379"
}

@inproceedings{thongtan-phienthrakul-2019-sentiment,
    title = "{Sentiment Classification Using Document Embeddings Trained with Cosine Similarity}",
    author = "Thongtan, Tan  and
      Phienthrakul, Tanasanee",
    editor = "Alva-Manchego, Fernando  and
      Choi, Eunsol  and
      Khashabi, Daniel",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-2057/",
    doi = "10.18653/v1/P19-2057",
    pages = "407--414",
    abstract = "In document-level sentiment classification, each document must be mapped to a fixed length vector. Document embedding models map each document to a dense, low-dimensional vector in continuous vector space. This paper proposes training document embeddings using cosine similarity instead of dot product. Experiments on the IMDB dataset show that accuracy is improved when using cosine similarity compared to using dot product, while using feature combination with Naive Bayes weighted bag of n-grams achieves a competitive accuracy of 93.68{\%}. Code to reproduce all experiments is available at \url{https://github.com/tanthongtan/dv-cosine}."
}

@article{10.1145/3672393,
author = {Periti, Francesco and Montanelli, Stefano},
title = {{Lexical Semantic Change through Large Language Models: a Survey}},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {11},
issn = {0360-0300},
url = {https://doi.org/10.1145/3672393},
doi = {10.1145/3672393},
abstract = {Lexical Semantic Change (LSC) is the task of identifying, interpreting, and assessing the possible change over time in the meanings of a target word. Traditionally, LSC has been addressed by linguists and social scientists through manual and time-consuming analyses, which have thus been limited in terms of the volume, genres, and time-frame that can be considered. In recent years, computational approaches based on Natural Language Processing have gained increasing attention to automate LSC as much as possible. Significant advancements have been made by relying on Large Language Models (LLMs), which can handle the multiple usages of the words and better capture the related semantic change. In this article, we survey the approaches based on LLMs for LSC, and we propose a classification framework characterized by three dimensions: meaning representation, time-awareness, and learning modality. The framework is exploited to (i) review the measures for change assessment, (ii) compare the approaches on performance, and (iii) discuss the current issues in terms of scalability, interpretability, and robustness. Open challenges and future research directions about the use of LLMs for LSC are finally outlined.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {282},
numpages = {38},
keywords = {Lexical semantics, lexical semantic change, semantic shift detection, large language models}
}


@inproceedings{kudisov-arefyev-2022-black,
    title = "{BOS at LSCDiscovery: Lexical Substitution for Interpretable Lexical Semantic Change Detection}",
    author = "Kudisov, Artem  and
      Arefyev, Nikolay",
    editor = "Tahmasebi, Nina  and
      Montariol, Syrielle  and
      Kutuzov, Andrey  and
      Hengchen, Simon  and
      Dubossarsky, Haim  and
      Borin, Lars",
    booktitle = "Proceedings of the 3rd Workshop on Computational Approaches to Historical Language Change",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.lchange-1.17/",
    doi = "10.18653/v1/2022.lchange-1.17",
    pages = "165--172",
    abstract = "We propose a solution for the LSCDiscovery shared task on Lexical Semantic Change Detection in Spanish. Our approach is based on generating lexical substitutes that describe old and new senses of a given word. This approach achieves the second best result in sense loss and sense gain detection subtasks. By observing those substitutes that are specific for only one time period, one can understand which senses were obtained or lost. This allows providing more detailed information about semantic change to the user and makes our method interpretable."
}

@inproceedings{keidar-etal-2022-slangvolution,
    title = "{Slangvolution: A Causal Analysis of Semantic Change and Frequency Dynamics in Slang}",
    author = "Keidar, Daphna  and
      Opedal, Andreas  and
      Jin, Zhijing  and
      Sachan, Mrinmaya",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.101/",
    doi = "10.18653/v1/2022.acl-long.101",
    pages = "1422--1442",
    abstract = "Languages are continuously undergoing changes, and the mechanisms that underlie these changes are still a matter of debate. In this work, we approach language evolution through the lens of causality in order to model not only how various distributional factors associate with language change, but how they causally affect it. In particular, we study slang, which is an informal language that is typically restricted to a specific group or social setting. We analyze the semantic change and frequency shift of slang words and compare them to those of standard, nonslang words. With causal discovery and causal inference techniques, we measure the effect that word type (slang/nonslang) has on both semantic change and frequency shift, as well as its relationship to frequency, polysemy and part of speech. Our analysis provides some new insights in the study of language change, e.g., we show that slang words undergo less semantic change but tend to have larger frequency shifts over time."
}

@inproceedings{10.1145/3366424.3382186,
author = {Martinc, Matej and Montariol, Syrielle and Zosa, Elaine and Pivovarova, Lidia},
title = {{Capturing Evolution in Word Usage: Just Add More Clusters?}},
year = {2020},
isbn = {9781450370240},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366424.3382186},
doi = {10.1145/3366424.3382186},
abstract = {The way the words are used evolves through time, mirroring cultural or technological evolution of society. Semantic change detection is the task of detecting and analysing word evolution in textual data, even in short periods of time. In this paper we focus on a new set of methods relying on contextualised embeddings, a type of semantic modelling that revolutionised the NLP field recently. We leverage the ability of the transformer-based BERT model to generate contextualised embeddings capable of detecting semantic change of words across time. Several approaches are compared in a common setting in order to establish strengths and weaknesses for each of them. We also propose several ideas for improvements, managing to drastically improve the performance of existing approaches.},
booktitle = {Companion Proceedings of the Web Conference 2020},
pages = {343–349},
numpages = {7},
keywords = {Semantic Change, Contextualised Embeddings, Clustering},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@article{Zeng2021UncoveringIP,
  title={{Uncovering Interpretable Potential Confounders in Electronic Medical Records}},
  author={Jiaming Zeng and Michael Francis Gensheimer and Daniel L. Rubin and Susan Athey and Ross D. Shachter},
  journal={Nature Communications},
  year={2021},
  volume={13},
  url={https://api.semanticscholar.org/CorpusID:231821119}
}

@inproceedings{10.5555/3495724.3497138,
author = {Song, Kaitao and Tan, Xu and Qin, Tao and Lu, Jianfeng and Liu, Tie-Yan},
title = {{MPNet: Masked and Permuted Pre-training for Language Understanding}},
year = {2020},
isbn = {9781713829546},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {BERT adopts masked language modeling (MLM) for pre-training and is one of the most successful pre-training models. Since BERT neglects dependency among predicted tokens, XLNet introduces permuted language modeling (PLM) for pre-training to address this problem. However, XLNet does not leverage the full position information of a sentence and thus suffers from position discrepancy between pre-training and fine-tuning. In this paper, we propose MPNet, a novel pre-training method that inherits the advantages of BERT and XLNet and avoids their limitations. MPNet leverages the dependency among predicted tokens through permuted language modeling (vs. MLM in BERT), and takes auxiliary position information as input to make the model see a full sentence and thus reducing the position discrepancy (vs. PLM in XLNet). We pre-train MPNet on a large-scale dataset (over 160GB text corpora) and fine-tune on a variety of down-streaming tasks (GLUE, SQuAD, etc). Experimental results show that MPNet outperforms MLM and PLM by a large margin, and achieves better results on these tasks compared with previous state-of-the-art pre-trained methods (e.g., BERT, XLNet, RoBERTa) under the same model setting.},
booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
articleno = {1414},
numpages = {11},
location = {Vancouver, BC, Canada},
series = {NIPS '20},
url = {https://dl.acm.org/doi/10.5555/3495724.3497138}
}

@article{VanderWeele2019,
  author    = {VanderWeele, Tyler J.},
  title     = {{Principles of Confounder Selection}},
  journal   = {European Journal of Epidemiology},
  volume    = {34},
  pages     = {211--219},
  year      = {2019},
  month     = {March},
  doi       = {10.1007/s10654-019-00494-6},
  url       = {https://doi.org/10.1007/s10654-019-00494-6}
}

@misc{lee2025nvembedimprovedtechniquestraining,
      title={{NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models}}, 
      author={Chankyu Lee and Rajarshi Roy and Mengyao Xu and Jonathan Raiman and Mohammad Shoeybi and Bryan Catanzaro and Wei Ping},
      year={2025},
      eprint={2405.17428},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.17428}, 
}

@inproceedings{muennighoff-etal-2023-mteb,
    title = "{MTEB: Massive Text Embedding Benchmark}",
    author = "Muennighoff, Niklas  and
      Tazi, Nouamane  and
      Magne, Loic  and
      Reimers, Nils",
    editor = "Vlachos, Andreas  and
      Augenstein, Isabelle",
    booktitle = "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.eacl-main.148/",
    doi = "10.18653/v1/2023.eacl-main.148",
    pages = "2014--2037",
    abstract = "Text embeddings are commonly evaluated on a small set of datasets from a single task not covering their possible applications to other tasks. It is unclear whether state-of-the-art embeddings on semantic textual similarity (STS) can be equally well applied to other tasks like clustering or reranking. This makes progress in the field difficult to track, as various models are constantly being proposed without proper evaluation. To solve this problem, we introduce the Massive Text Embedding Benchmark (MTEB). MTEB spans 8 embedding tasks covering a total of 58 datasets and 112 languages. Through the benchmarking of 33 models on MTEB, we establish the most comprehensive benchmark of text embeddings todate. We find that no particular text embedding method dominates across all tasks. This suggests that the field has yet to converge on a universal text embedding method and scale it up sufficiently to provide state-of-theart results on all embedding tasks. MTEB comes with open-source code and a public leaderboard at \url{https://github.com/embeddings-benchmark/mteb}."
}

@inproceedings{kang-etal-2017-detecting,
    title = "{Detecting and Explaining Causes From Text For a Time Series Event}",
    author = "Kang, Dongyeop  and
      Gangal, Varun  and
      Lu, Ang  and
      Chen, Zheng  and
      Hovy, Eduard",
    editor = "Palmer, Martha  and
      Hwa, Rebecca  and
      Riedel, Sebastian",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D17-1292/",
    doi = "10.18653/v1/D17-1292",
    pages = "2758--2767",
    abstract = "Explaining underlying causes or effects about events is a challenging but valuable task. We define a novel problem of generating explanations of a time series event by (1) searching cause and effect relationships of the time series with textual data and (2) constructing a connecting chain between them to generate an explanation. To detect causal features from text, we propose a novel method based on the Granger causality of time series between features extracted from text such as N-grams, topics, sentiments, and their composition. The generation of the sequence of causal entities requires a commonsense causative knowledge base with efficient reasoning. To ensure good interpretability and appropriate lexical usage we combine symbolic and neural representations, using a neural reasoning algorithm trained on commonsense causal tuples to predict the next cause step. Our quantitative and human analysis show empirical evidence that our method successfully extracts meaningful causality relationships between time series with textual features and generates appropriate explanation between them."
}

@article{MetzlerGarcia2024,
  author    = {Metzler, H. and Garcia, D.},
  title     = {{Social Drivers and Algorithmic Mechanisms on Digital Media}},
  journal   = {Perspectives on Psychological Science},
  year      = {2024},
  volume    = {19},
  number    = {5},
  pages     = {735-748},
  doi       = {10.1177/17456916231185057}
}

@article{NGUYEN201939,
title = {Making new products go viral and succeed},
journal = {International Journal of Research in Marketing},
volume = {36},
number = {1},
pages = {39-62},
year = {2019},
issn = {0167-8116},
doi = {https://doi.org/10.1016/j.ijresmar.2018.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S0167811618300521},
author = {Hang T. Nguyen and Malika Chaudhuri},
keywords = {Social media, Word of mouth, Diffusion, Innovation, Field experiment, Brand strategy},
abstract = {Why are some new product introductions more viral and successful than others? This research integrates theories of interpersonal communication and consumer learning to explore this question. Analyzing a unique data set of millions of consumer word-of-mouth transmissions (eWOM) on social media regarding 345 new automobile products introduced during 2008–2015, we find that more innovative products generate more eWOM volume but surprisingly less positive sentiment. These effects vary in magnitude across eWOM channels. However, the use of rich-content communication, pre-announcement, and cobranding strengthens (weakens) the positive (negative) effect of product innovativeness on eWOM volume (sentiment). The results further indicate that eWOM sentiment is a stronger predictor of new product success than eWOM volume. Experimental results reveal more insights into how product innovativeness influences eWOM metrics in several product categories and shed light on the role of excitement and perceived risk as mechanisms underlying these effects. The research offers useful implications for firms to design effective viral marketing campaigns to enhance new product success.}
}

@article{semenova2024wisdom,
  title={{Wisdom of the Crowds or Ignorance of the Masses? A Data-Driven Guide to WallStreetBets}},
  author={Semenova, Valentina and Gorduza, Dragos and Wildi, William and Dong, Xiaowen and Zohren, Stefan},
  journal={Journal of Portfolio Management},
  volume={50},
  number={4},
  year={2024},
  url={https://openurl.ebsco.com/EPDB%3Agcd%3A16%3A13677488/detailv2?sid=ebsco%3Aplink%3Ascholar&id=ebsco%3Agcd%3A175592193&crl=c&link_origin=scholar.google.com}
}

@article{MURRAY1997513,
title = {{Exploring the Dialectics of Route-based Tourism: The Camino de Santiago}},
journal = {Tourism Management},
volume = {18},
number = {8},
pages = {513-524},
year = {1997},
issn = {0261-5177},
doi = {https://doi.org/10.1016/S0261-5177(97)00075-7},
url = {https://www.sciencedirect.com/science/article/pii/S0261517797000757},
author = {Michael Murray and Brian Graham},
keywords = {route-based tourism, pilgrimage, heritage, spatial development, green tourism, Camino de Santiago, Spain},
abstract = {In its specific concern with route-based itineraries, this paper examines the complex tensions and conflicts that ensue from the marketing of cultural artefacts as tourism commodities. The paper analyses the characteristics and trends of the contemporary utilization of the medieval pilgrimage routes to the Galician shrine of Santiago de Compostela and distinguishes between the differing tourist sub-markets and their contrasting motivations in consuming this heritage complex. This discussion is linked with an assessment of the more subtle modifications of religious meaning by tourism activity, which pose particular problems in formulating strategies to promote this form of cultural itinerary. In proposing a synthetic model that combines the conflicting motivations and demands of pilgrims and tourists, the paper points to the need for critical awareness among those whose brief and interest lie in sustaining the integrity of route-based cultural tourism.}
}

@inproceedings{balashankar-etal-2019-identifying,
    title = "{Identifying Predictive Causal Factors from News Streams}",
    author = "Balashankar, Ananth  and
      Chakraborty, Sunandan  and
      Fraiberger, Samuel  and
      Subramanian, Lakshminarayanan",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1238/",
    doi = "10.18653/v1/D19-1238",
    pages = "2338--2348",
    abstract = "We propose a new framework to uncover the relationship between news events and real world phenomena. We present the Predictive Causal Graph (PCG) which allows to detect latent relationships between events mentioned in news streams. This graph is constructed by measuring how the occurrence of a word in the news influences the occurrence of another (set of) word(s) in the future. We show that PCG can be used to extract latent features from news streams, outperforming other graph-based methods in prediction error of 10 stock price time series for 12 months. We then extended PCG to be applicable for longer time windows by allowing time-varying factors, leading to stock price prediction error rates between 1.5{\%} and 5{\%} for about 4 years. We then manually validated PCG, finding that 67{\%} of the causation semantic frame arguments present in the news corpus were directly connected in the PCG, the remaining being connected through a semantically relevant intermediate node."
}

@book{akerlof2010animal,
  author    = {Akerlof, George A. and Shiller, Robert J.},
  title     = {{Animal Spirits: How Human Psychology Drives the Economy, and Why It Matters for Global Capitalism}},
  year      = {2010},
  publisher = {Princeton University Press},
  url       = {https://psycnet.apa.org/record/2009-01285-000}
}

@article{marinazzo2008kernel,
  title={{Kernel Method for Nonlinear Granger Causality}},
  author={Marinazzo, Daniele and Pellicoro, Mario and Stramaglia, Sebastiano},
  journal={Physical review letters},
  volume={100},
  number={14},
  pages={144103},
  year={2008},
  publisher={APS},
  url={https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.100.144103}
}

@article{Maisonnave2022CausalGE,
  title={{Causal Graph Extraction from News: A Comparative Study of Time-series Causality Learning Techniques}},
  author={Mariano, Maisonnave and Fernando, Delbianco and Fernando, A. Tohm{\'e} and Evangelos, E. Milios and Ana, Gabriela Maguitman},
  journal={PeerJ Computer Science},
  year={2022},
  volume={8},
  url={https://api.semanticscholar.org/CorpusID:251329598}
}

@article{barnett2009granger,
  title={{Granger Causality and Transfer Entropy are Equivalent for Gaussian Variables}},
  author={Barnett, Lionel and Barrett, Adam B and Seth, Anil K},
  journal={Physical review letters},
  volume={103},
  number={23},
  pages={238701},
  year={2009},
  publisher={APS},
  url={https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.103.238701}
}

@article{ghahramani1997learning,
  title={{Learning Dynamic Bayesian Networks}},
  author={Ghahramani, Zoubin},
  journal={International School on Neural Networks, Initiated by IIASS and EMFCSC},
  pages={168--197},
  year={1997},
  publisher={Springer},
  url={https://link.springer.com/chapter/10.1007/BFb0053999}
}

@article{ye2015distinguishing,
  title={{Distinguishing Time-delayed Causal Interactions Using Convergent Cross Mapping}},
  author={Ye, Hao and Deyle, Ethan R and Gilarranz, Luis J and Sugihara, George},
  journal={Scientific Reports},
  volume={5},
  pages={14750},
  year={2015},
  publisher={Nature Publishing Group},
  doi={10.1038/srep14750},
  url={https://doi.org/10.1038/srep14750}
}


@inproceedings{fong-grimmer-2016-discovery,
    title = "Discovery of Treatments from Text Corpora",
    author = "Fong, Christian  and
      Grimmer, Justin",
    editor = "Erk, Katrin  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P16-1151/",
    doi = "10.18653/v1/P16-1151",
    pages = "1600--1609"
}

@article{zhang2020quantifying,
  title={{Quantifying the Causal Effects of Conversational Tendencies}},
  author={Zhang, Justine and Mullainathan, Sendhil and Danescu-Niculescu-Mizil, Cristian},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={4},
  number={CSCW2},
  pages={1--24},
  year={2020},
  publisher={ACM New York, NY, USA},
  url={https://dl.acm.org/doi/abs/10.1145/3415202}
}

@article{roberts2020adjusting,
  title={{Adjusting for Confounding with Text Matching}},
  author={Roberts, Margaret E and Stewart, Brandon M and Nielsen, Richard A},
  journal={American Journal of Political Science},
  volume={64},
  number={4},
  pages={887--903},
  year={2020},
  publisher={Wiley Online Library},
  url={https://onlinelibrary.wiley.com/doi/full/10.1111/ajps.12526}
}

@inproceedings{Veitch2019AdaptingTE,
  title={{Adapting Text Embeddings for Causal Inference}},
  author={Victor Veitch and Dhanya Sridhar and David M. Blei},
  booktitle={Conference on Uncertainty in Artificial Intelligence},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:220793347}
}

@article{Radford2019,
  author    = {Alec Radford and Jeffrey Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  title     = {{Language Models are Unsupervised Multitask Learners}},
  journal   = {OpenAI Blog},
  volume    = {1},
  number    = {8},
  pages     = {9},
  year      = {2019},
  url       = {https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf},
  note      = {OpenAI Technical Report}
}

@inproceedings{Brown2020,
  author    = {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  title     = {{Language Models are Few-Shot Learners}},
  booktitle = {Advances in Neural Information Processing Systems 33 (NeurIPS 2020)},
  year      = {2020},
  url       = {https://papers.nips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html},
  note      = {NeurIPS 2020, December 6--12, Virtual Conference}
}


@techreport{Radford2018,
  author    = {Alec Radford and Karthik Narasimhan and Tim Salimans and Ilya Sutskever},
  title     = {{Improving Language Understanding by Generative Pre-Training}},
  year      = {2018},
  institution = {OpenAI},
  url       = {https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf},
  note      = {OpenAI Technical Report}
}


@inproceedings{dasgupta-etal-2018-automatic-extraction,
    title = "{Automatic Extraction of Causal Relations from Text using Linguistically Informed Deep Neural Networks}",
    author = "Dasgupta, Tirthankar  and
      Saha, Rupsa  and
      Dey, Lipika  and
      Naskar, Abir",
    editor = "Komatani, Kazunori  and
      Litman, Diane  and
      Yu, Kai  and
      Papangelis, Alex  and
      Cavedon, Lawrence  and
      Nakano, Mikio",
    booktitle = "Proceedings of the 19th Annual {SIG}dial Meeting on Discourse and Dialogue",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W18-5035/",
    doi = "10.18653/v1/W18-5035",
    pages = "306--316",
    abstract = "In this paper we have proposed a linguistically informed recursive neural network architecture for automatic extraction of cause-effect relations from text. These relations can be expressed in arbitrarily complex ways. The architecture uses word level embeddings and other linguistic features to detect causal events and their effects mentioned within a sentence. The extracted events and their relations are used to build a causal-graph after clustering and appropriate generalization, which is then used for predictive purposes. We have evaluated the performance of the proposed extraction model with respect to two baseline systems,one a rule-based classifier, and the other a conditional random field (CRF) based supervised model. We have also compared our results with related work reported in the past by other authors on SEMEVAL data set, and found that the proposed bi-directional LSTM model enhanced with an additional linguistic layer performs better. We have also worked extensively on creating new annotated datasets from publicly available data, which we are willing to share with the community."
}

@inproceedings{ning-etal-2018-joint,
    title = "{Joint Reasoning for Temporal and Causal Relations}",
    author = "Ning, Qiang  and
      Feng, Zhili  and
      Wu, Hao  and
      Roth, Dan",
    editor = "Gurevych, Iryna  and
      Miyao, Yusuke",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1212/",
    doi = "10.18653/v1/P18-1212",
    pages = "2278--2288",
    abstract = "Understanding temporal and causal relations between events is a fundamental natural language understanding task. Because a cause must occur earlier than its effect, temporal and causal relations are closely related and one relation often dictates the value of the other. However, limited attention has been paid to studying these two relations jointly. This paper presents a joint inference framework for them using constrained conditional models (CCMs). Specifically, we formulate the joint problem as an integer linear programming (ILP) problem, enforcing constraints that are inherent in the nature of time and causality. We show that the joint inference framework results in statistically significant improvement in the extraction of both temporal and causal relations from text."
}

@inproceedings{horn-2021-exploring,
    title = "{Exploring Word Usage Change with Continuously Evolving Embeddings}",
    author = "Horn, Franziska",
    editor = "Ji, Heng  and
      Park, Jong C.  and
      Xia, Rui",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-demo.35/",
    doi = "10.18653/v1/2021.acl-demo.35",
    pages = "290--297",
    abstract = "The usage of individual words can change over time, for example, when words experience a semantic shift. As text datasets generally comprise documents that were collected over a longer period of time, examining word usage changes in a corpus can often reveal interesting patterns. In this paper, we introduce a simple and intuitive way to track word usage changes via continuously evolving embeddings, computed as a weighted running average of transformer-based contextualized embeddings. We demonstrate our approach on a corpus of recent New York Times article snippets and provide code for an easy to use web app to conveniently explore semantic shifts with interactive plots."
}

@article{Yang2021ASO,
  title={{A Survey on Extraction of Causal Relations from Natural Language Text}},
  author={Jie Yang and Soyeon Caren Han and Josiah Poon},
  journal={Knowledge and Information Systems},
  year={2021},
  volume={64},
  pages={1161 - 1186},
  url={https://api.semanticscholar.org/CorpusID:231632837}
}

@inproceedings{martinc-etal-2020-leveraging,
    title = "{Leveraging Contextual Embeddings for Detecting Diachronic Semantic Shift}",
    author = "Martinc, Matej  and
      Kralj Novak, Petra  and
      Pollak, Senja",
    editor = "Calzolari, Nicoletta  and
      B{\'e}chet, Fr{\'e}d{\'e}ric  and
      Blache, Philippe  and
      Choukri, Khalid  and
      Cieri, Christopher  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Isahara, Hitoshi  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, H{\'e}l{\`e}ne  and
      Moreno, Asuncion  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "Proceedings of the Twelfth Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2020.lrec-1.592/",
    pages = "4811--4819",
    language = "eng",
    ISBN = "979-10-95546-34-4",
    abstract = "We propose a new method that leverages contextual embeddings for the task of diachronic semantic shift detection by generating time specific word representations from BERT embeddings. The results of our experiments in the domain specific LiverpoolFC corpus suggest that the proposed method has performance comparable to the current state-of-the-art without requiring any time consuming domain adaptation on large corpora. The results on the newly created Brexit news corpus suggest that the method can be successfully used for the detection of a short-term yearly semantic shift. And lastly, the model also shows promising results in a multilingual settings, where the task was to detect differences and similarities between diachronic semantic shifts in different languages."
}

@InProceedings{10.1007/978-3-030-72610-2_13,
author="Rodina, Julia
and Trofimova, Yuliya
and Kutuzov, Andrey
and Artemova, Ekaterina",
editor="van der Aalst, Wil M. P.
and Batagelj, Vladimir
and Ignatov, Dmitry I.
and Khachay, Michael
and Koltsova, Olessia
and Kutuzov, Andrey
and Kuznetsov, Sergei O.
and Lomazova, Irina A.
and Loukachevitch, Natalia
and Napoli, Amedeo
and Panchenko, Alexander
and Pardalos, Panos M.
and Pelillo, Marcello
and Savchenko, Andrey V.
and Tutubalina, Elena",
title="{ELMo and BERT in Semantic Change Detection for Russian}",
booktitle="Analysis of Images, Social Networks and Texts",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="175--186",
url={https://arxiv.org/abs/2010.03481},
abstract="We study the effectiveness of contextualized embeddings for the task of diachronic semantic change detection for Russian language data. Evaluation test sets consist of Russian nouns and adjectives annotated based on their occurrences in texts created in pre-Soviet, Soviet and post-Soviet time periods. ELMo and BERT architectures are compared on the task of ranking Russian words according to the degree of their semantic change over time. We use several methods for aggregation of contextualized embeddings from these architectures and evaluate their performance. Finally, we compare unsupervised and supervised techniques in this task.",
isbn="978-3-030-72610-2"
}



@inproceedings{yamagiwa-etal-2025-revisiting,
    title = "{Revisiting Cosine Similarity via Normalized ICA-transformed Embeddings}",
    author = "Yamagiwa, Hiroaki  and
      Oyama, Momose  and
      Shimodaira, Hidetoshi",
    editor = "Rambow, Owen  and
      Wanner, Leo  and
      Apidianaki, Marianna  and
      Al-Khalifa, Hend  and
      Eugenio, Barbara Di  and
      Schockaert, Steven",
    booktitle = "Proceedings of the 31st International Conference on Computational Linguistics",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.coling-main.497/",
    pages = "7423--7452",
    abstract = "Cosine similarity is widely used to measure the similarity between two embeddings, while interpretations based on angle and correlation coefficient are common. In this study, we focus on the interpretable axes of embeddings transformed by Independent Component Analysis (ICA), and propose a novel interpretation of cosine similarity as the sum of semantic similarities over axes. The normalized ICA-transformed embeddings exhibit sparsity, enhancing the interpretability of each axis, and the semantic similarity defined by the product of the components represents the shared meaning between the two embeddings along each axis. The effectiveness of this approach is demonstrated through intuitive numerical examples and thorough numerical experiments. By deriving the probability distributions that govern each component and the product of components, we propose a method for selecting statistically significant axes."
}

@inproceedings{reimers-gurevych-2019-sentence,
    title = "{Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks}",
    author = "Reimers, Nils  and
      Gurevych, Iryna",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1410/",
    doi = "10.18653/v1/D19-1410",
    pages = "3982--3992",
    abstract = "BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations ({\textasciitilde}65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods."
}

@inproceedings{Wang2020,
  author    = {Benyou Wang and Emanuele Di Buccio and Massimo Melucci},
  title     = {{University of Padova @ DIACR-Ita}},
  booktitle = {{Proceedings of the Evaluation Campaign of Natural Language Processing and Speech Tools for Italian (EVALITA 2020)}},
  year      = {2020},
  address   = {Marrakech, Morocco},
  month     = {December},
  publisher = {CEUR-WS},
  note      = {CEUR Workshop Proceedings},
  url={https://core.ac.uk/download/430176515.pdf}
}

@inproceedings{giulianelli-etal-2020-analysing,
    title = "{Analysing Lexical Semantic Change with Contextualised Word Representations}",
    author = "Giulianelli, Mario  and
      Del Tredici, Marco  and
      Fern{\'a}ndez, Raquel",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.365/",
    doi = "10.18653/v1/2020.acl-main.365",
    pages = "3960--3973",
    abstract = "This paper presents the first unsupervised approach to lexical semantic change that makes use of contextualised word representations. We propose a novel method that exploits the BERT neural language model to obtain representations of word usages, clusters these representations into usage types, and measures change along time with three proposed metrics. We create a new evaluation dataset and show that the model representations and the detected semantic shifts are positively correlated with human judgements. Our extensive qualitative analysis demonstrates that our method captures a variety of synchronic and diachronic linguistic phenomena. We expect our work to inspire further research in this direction."
}

@article{Tangherlini2020,
  author    = {Timothy R. Tangherlini and Shadi Shahsavari and Behnam Shahbazi and Ehsan Ebrahimzadeh and Vwani Roychowdhury},
  title     = {{An Automated Pipeline for the Discovery of Conspiracy and Conspiracy Theory Narrative Frameworks: Bridgegate, Pizzagate, and Storytelling on the Web}},
  journal   = {PLoS ONE},
  volume    = {15},
  number    = {6},
  pages     = {e0233879},
  year      = {2020},
  doi       = {10.1371/journal.pone.0233879},
  url       = {https://doi.org/10.1371/journal.pone.0233879},
  publisher = {Public Library of Science},
  editor    = {Yu-Ru Lin},
  note      = {Published: June 16, 2020}
}

@article{10.1145/3533018,
author = {Zhai, Shuang (Sophie) and Zhang, Zhu (Drew)},
title = {{Read the News, Not the Books: Forecasting Firms’ Long-term Financial Performance via Deep Text Mining}},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {1},
issn = {2158-656X},
url = {https://doi.org/10.1145/3533018},
doi = {10.1145/3533018},
abstract = {In this paper, we show textual data from firm-related events in news articles can effectively predict various firm financial ratios, with or without historical financial ratios. We exploit state-of-the-art neural architectures, including pseudo-event embeddings, Long Short-Term Memory Networks, and attention mechanisms. Our news-powered deep learning models are shown to outperform standard econometric models operating on precise accounting historical data. We also observe forecasting quality improvement when integrating textual and numerical data streams. In addition, we provide in-depth case studies for model explainability and transparency. Our forecasting models, model attention maps, and firm embeddings benefit various stakeholders with quality predictions and explainable insights. Our proposed models can be applied both when numerically historical data is or is not available.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = jan,
articleno = {3},
numpages = {37},
keywords = {forecasting, deep learning, Natural language processing}
}

@inproceedings{sawhney-etal-2020-deep,
    title = "{Deep Attentive Learning for Stock Movement Prediction From Social Media Text and Company Correlations}",
    author = "Sawhney, Ramit  and
      Agarwal, Shivam  and
      Wadhwa, Arnav  and
      Shah, Rajiv Ratn",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.676/",
    doi = "10.18653/v1/2020.emnlp-main.676",
    pages = "8415--8426",
    abstract = "In the financial domain, risk modeling and profit generation heavily rely on the sophisticated and intricate stock movement prediction task. Stock forecasting is complex, given the stochastic dynamics and non-stationary behavior of the market. Stock movements are influenced by varied factors beyond the conventionally studied historical prices, such as social media and correlations among stocks. The rising ubiquity of online content and knowledge mandates an exploration of models that factor in such multimodal signals for accurate stock forecasting. We introduce an architecture that achieves a potent blend of chaotic temporal signals from financial data, social media, and inter-stock relationships via a graph neural network in a hierarchical temporal fashion. Through experiments on real-world S{\&}P 500 index data and English tweets, we show the practical applicability of our model as a tool for investment decision making and trading."
}

@inproceedings{drinkall-etal-2022-forecasting,
    title = {{Forecasting COVID-19 Caseloads Using Unsupervised Embedding Clusters of Social Media Posts}},
    author = "Drinkall, Felix  and
      Zohren, Stefan  and
      Pierrehumbert, Janet",
    editor = "Carpuat, Marine  and
      de Marneffe, Marie-Catherine  and
      Meza Ruiz, Ivan Vladimir",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.105/",
    doi = "10.18653/v1/2022.naacl-main.105",
    pages = "1471--1484",
    abstract = "We present a novel approach incorporating transformer-based language models into infectious disease modelling. Text-derived features are quantified by tracking high-density clusters of sentence-level representations of Reddit posts within specific US states' COVID-19 subreddits. We benchmark these clustered embedding features against features extracted from other high-quality datasets. In a threshold-classification task, we show that they outperform all other feature types at predicting upward trend signals, a significant result for infectious disease modelling in areas where epidemiological data is unreliable. Subsequently, in a time-series forecasting task, we fully utilise the predictive power of the caseload and compare the relative strengths of using different supplementary datasets as covariate feature sets in a transformer-based time-series model."
}

@inproceedings{iso-etal-2016-forecasting,
    title = "{Forecasting Word Model: Twitter-based Influenza Surveillance and Prediction}",
    author = "Iso, Hayate  and
      Wakamiya, Shoko  and
      Aramaki, Eiji",
    editor = "Matsumoto, Yuji  and
      Prasad, Rashmi",
    booktitle = "Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",
    month = dec,
    year = "2016",
    address = "Osaka, Japan",
    publisher = "The COLING 2016 Organizing Committee",
    url = "https://aclanthology.org/C16-1008/",
    pages = "76--86",
    abstract = "Because of the increasing popularity of social media, much information has been shared on the internet, enabling social media users to understand various real world events. Particularly, social media-based infectious disease surveillance has attracted increasing attention. In this work, we specifically examine influenza: a common topic of communication on social media. The fundamental theory of this work is that several words, such as symptom words (fever, headache, etc.), appear in advance of flu epidemic occurrence. Consequently, past word occurrence can contribute to estimation of the number of current patients. To employ such forecasting words, one can first estimate the optimal time lag for each word based on their cross correlation. Then one can build a linear model consisting of word frequencies at different time points for nowcasting and for forecasting influenza epidemics. Experimentally obtained results (using 7.7 million tweets of August 2012 {--} January 2016), the proposed model achieved the best nowcasting performance to date (correlation ratio 0.93) and practically sufficient forecasting performance (correlation ratio 0.91 in 1-week future prediction, and correlation ratio 0.77 in 3-weeks future prediction). This report is the first of the relevant literature to describe a model enabling prediction of future epidemics using Twitter."
}

@inproceedings{drinkall-etal-2025-forecasting,
    title = "{Forecasting Credit Ratings: A Case Study where Traditional Methods Outperform Generative LLMs}",
    author = "Drinkall, Felix  and
      Pierrehumbert, Janet B.  and
      Zohren, Stefan",
    editor = "Chen, Chung-Chi  and
      Moreno-Sandoval, Antonio  and
      Huang, Jimin  and
      Xie, Qianqian  and
      Ananiadou, Sophia  and
      Chen, Hsin-Hsi",
    booktitle = "Proceedings of the Joint Workshop of the 9th Financial Technology and Natural Language Processing (FinNLP), the 6th Financial Narrative Processing (FNP), and the 1st Workshop on Large Language Models for Finance and Legal (LLMFinLegal)",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.finnlp-1.11/",
    pages = "118--133",
    abstract = "Large Language Models (LLMs) have been shown to perform well for many downstream tasks. Transfer learning can enable LLMs to acquire skills that were not targeted during pre-training. In financial contexts, LLMs can sometimes beat well-established benchmarks. This paper investigates how well LLMs perform at forecasting corporate credit ratings. We show that while LLMs are very good at encoding textual information, traditional methods are still very competitive when it comes to encoding numeric and multimodal data. For our task, current LLMs perform worse than a more traditional XGBoost architecture that combines fundamental and macroeconomic data with high-density text-based embedding features. We investigate the degree to which the text encoding methodology affects performance and interpretability."
}

@Article{math10132156,
AUTHOR = {Fazlija, Bledar and Harder, Pedro},
TITLE = {{Using Financial News Sentiment for Stock Price Direction Prediction}},
JOURNAL = {Mathematics},
VOLUME = {10},
YEAR = {2022},
NUMBER = {13},
ARTICLE-NUMBER = {2156},
URL = {https://www.mdpi.com/2227-7390/10/13/2156},
ISSN = {2227-7390},
ABSTRACT = {Using sentiment information in the analysis of financial markets has attracted much attention. Natural language processing methods can be used to extract market sentiment information from texts such as news articles. The objective of this paper is to extract financial market sentiment information from news articles and use the estimated sentiment scores to predict the price direction of the stock market index Standard & Poor’s 500. To achieve the best possible performance in sentiment classification, state-of-the-art bidirectional encoder representations from transformers (BERT) models are used. The pretrained transformer networks are fine-tuned on a labeled financial text dataset and applied to news articles from known providers of financial news content to predict their sentiment scores. The generated sentiment scores for the titles of the given news articles, for the (text) content of said news articles, and for the combined title-content consideration are posited against past time series information of the stock market index. To forecast the price direction of the stock market index, the predicted sentiment scores are used in a simple strategy and as features for a random forest classifier. The results show that sentiment scores based on news content are particularly useful for stock price direction prediction.},
DOI = {10.3390/math10132156}
}

@inproceedings{piper2021narrative,
    title = "{Narrative Theory for Computational Narrative Understanding}",
    author = "Piper, Andrew  and
      So, Richard Jean  and
      Bamman, David",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.26/",
    doi = "10.18653/v1/2021.emnlp-main.26",
    pages = "298--311",
    abstract = "Over the past decade, the field of natural language processing has developed a wide array of computational methods for reasoning about narrative, including summarization, commonsense inference, and event detection. While this work has brought an important empirical lens for examining narrative, it is by and large divorced from the large body of theoretical work on narrative within the humanities, social and cognitive sciences. In this position paper, we introduce the dominant theoretical frameworks to the NLP community, situate current research in NLP within distinct narratological traditions, and argue that linking computational work in NLP to theory opens up a range of new empirical questions that would both help advance our understanding of narrative and open up new practical applications."
}

@article{loughran2011liability,
  title={{When is a Liability not a Liability? Textual Analysis, Dictionaries, and 10-Ks}},
  author={Loughran, Tim and McDonald, Bill},
  journal={The Journal of finance},
  volume={66},
  number={1},
  pages={35--65},
  year={2011},
  publisher={Wiley Online Library},
  url={https://onlinelibrary.wiley.com/doi/10.1111/j.1540-6261.2010.01625.x}
}

@article{Klüver_Spoon_2016, 
    title={{Who Responds? Voters, Parties and Issue Attention}}, 
    volume={46}, 
    DOI={10.1017/S0007123414000313}, 
    number={3}, 
    journal={British Journal of Political Science}, 
    author={Klüver, Heike and Spoon, Jae-Jae}, 
    year={2016}, 
    pages={633–654}
}

@article{choi2012predicting,
  title={{Predicting the Present with Google Trends}},
  author={Choi, Hyunyoung and Varian, Hal},
  journal={Economic Record},
  year={2012},
  doi={10.1111/j.1475-4932.2012.00809.x},
  note={First published: 27 June 2012},
  publisher={Wiley},
  author_email={hal@google.com}
}

@article{margalit2019political,
  title={{Political Responses to Economic Shocks}},
  author={Margalit, Yotam},
  journal={Annual Review of Political Science},
  volume={22},
  pages={277--295},
  year={2019},
  doi={10.1146/annurev-polisci-050517-110713},
  publisher={Annual Reviews},
  note={First published as a Review in Advance on January 23, 2019}
}

@article{shiller2017narrative,
  title={{Narrative Economics}},
  author={Shiller, Robert J},
  journal={{American Economic Review}},
  volume={107},
  number={4},
  pages={967--1004},
  year={2017},
  url={https://www.aeaweb.org/articles?id=10.1257/aer.107.4.967},
  publisher={American Economic Association 2014 Broadway, Suite 305, Nashville, TN 37203}
}

@article{Ash_Gauthier_Widmer_2024, 
    title={{Relatio: Text Semantics Capture Political and Economic Narratives}}, 
    volume={32}, 
    DOI={10.1017/pan.2023.8}, 
    number={1}, 
    journal={Political Analysis}, 
    author={Ash, Elliott and Gauthier, Germain and Widmer, Philine}, 
    year={2024}, 
    pages={115–132}
}

@misc{sutton2019bitter,
  title = {{The Bitter Lesson}},
  author = {Sutton, Rich},
  year = {2019},
  month = {March},
  day = {13},
  url = {http://www.incompleteideas.net/IncIdeas/BitterLesson.html},
  note = {Acc.: 03/02/25}
}

@article{702ab909-8cb1-3c30-a5f1-ab4517d6cf1c,
 ISSN = {00129682, 14680262},
 URL = {http://www.jstor.org/stable/1912791},
 abstract = {There occurs on some occasions a difficulty in deciding the direction of causality between two related variables and also whether or not feedback is occurring. Testable definitions of causality and feedback are proposed and illustrated by use of simple two-variable models. The important problem of apparent instantaneous causality is discussed and it is suggested that the problem often arises due to slowness in recording information or because a sufficiently wide class of possible causal variables has not been used. It can be shown that the cross spectrum between two variables can be decomposed into two parts, each relating to a single causal arm of a feedback situation. Measures of causal lag and causal strength can then be constructed. A generalisation of this result with the partial cross spectrum is suggested.},
 author = {C. W. J. Granger},
 journal = {Econometrica},
 number = {3},
 pages = {424--438},
 publisher = {[Wiley, Econometric Society]},
 title = {{Investigating Causal Relations by Econometric Models and Cross-spectral Methods}},
 urldate = {2025-01-30},
 volume = {37},
 year = {1969}
}


@book{bonferroni1936teoria,
  title={{Teoria Statistica Delle Classi e Calcolo Delle Probabilit{\`a}}},
  author={Bonferroni, C.E.},
  series={{Pubblicazioni del R. Istituto Superiore di Scienze Economiche e Commerciali di Firenze}},
  url={https://books.google.co.uk/books?id=3CY-HQAACAAJ},
  year={1936},
  publisher={Seeber}
}

@inproceedings{10.1145/2531602.2531623,
author = {Castillo, Carlos and El-Haddad, Mohammed and Pfeffer, J\"{u}rgen and Stempeck, Matt},
title = {{Characterizing the Life Cycle of Online News Stories Using Social Media Reactions}},
year = {2014},
isbn = {9781450325400},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2531602.2531623},
doi = {10.1145/2531602.2531623},
abstract = {This paper presents a study of the life cycle of news articles posted online. We describe the interplay between website visitation patterns and social media reactions to news content. We show that we can use this hybrid observation method to characterize distinct classes of articles. We also find that social media reactions can help predict future visitation patterns early and accurately. We validate our methods using qualitative analysis as well as quantitative analysis on data from a large international news network, for a set of articles generating more than 3,000,000 visits and 200,000 social media reactions. We show that it is possible to model accurately the overall traffic articles will ultimately receive by observing the first ten to twenty minutes of social media reactions. Achieving the same prediction accuracy with visits alone would require to wait for three hours of data. We also describe significant improvements on the accuracy of the early prediction of shelf-life for news stories.},
booktitle = {Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work \& Social Computing},
pages = {211–223},
numpages = {13},
keywords = {web analytics, predictive web analytics, online news},
location = {Baltimore, Maryland, USA},
series = {CSCW '14}
}

@article{chen2015granularity,
  title={{Granularity in Economic Decision Making: An Interdisciplinary Review}},
  author={Chen, Shu-Heng and Du, Ye-Rong},
  journal={{Granular Computing and Decision-making: Interactive and Iterative Approaches}},
  pages={47--71},
  year={2015},
  publisher={Springer},
  url={https://doi.org/10.1007/978-3-319-16829-6_3}
}

@InProceedings{spliethoever2022,
  address =                  {Abu Dhabi, United Arab Emirates},
  author =                   {Maximilian Splieth{\"o}ver and Maximilian Keiff and Henning Wachsmuth},
  booktitle =                {Findings of the Association for Computational Linguistics: EMNLP 2022},
  month =                    dec,
  publisher =                {Association for Computational Linguistics},
  title =                    {{No Word Embedding Model Is Perfect: Evaluating the Representation Accuracy for Social Bias in the Media}},
  url =                      {https://aclanthology.org/2022.findings-emnlp.152/},
  year =                     2022
}

@article{nakagawa2004farewell,
  title={{A Farewell to Bonferroni: The Problems of Low Statistical Power and Publication Bias}},
  author={Nakagawa, Shinichi},
  journal={Behavioral ecology},
  volume={15},
  number={6},
  pages={1044--1045},
  year={2004},
  publisher={Oxford University Press},
  url={https://doi.org/10.1093/beheco/arh107}
}

@article{anderson2000null,
  title={{Null Hypothesis Testing: Problems, Prevalence, and an Alternative}},
  author={Anderson, David R and Burnham, Kenneth P and Thompson, William L},
  journal={{The Journal of Wildlife Management}},
  pages={912--923},
  year={2000},
  publisher={JSTOR},
  url={https://doi.org/10.2307/3803199}
}

@article{perneger1998s,
  title={{What's Wrong with Bonferroni Adjustments}},
  author={Perneger, Thomas V},
  journal={{BMJ}},
  volume={316},
  number={7139},
  pages={1236--1238},
  year={1998},
  publisher={British Medical Journal Publishing Group},
  url={https://www.bmj.com/content/316/7139/1236}
}

@article{cieslak2021common,
  title={{Common Shocks in Stocks and Bonds}},
  author={Cieslak, Anna and Pang, Hao},
  journal={Journal of Financial Economics},
  volume={142},
  number={2},
  pages={880--904},
  year={2021},
  publisher={Elsevier},
  url={http://www.sciencedirect.com/science/article/pii/S0304405X21002749}
}