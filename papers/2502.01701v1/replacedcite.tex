\section{Related Work}
%In this subsection, we highlight the most closely related concurrent contributions to contextualize our work.
%\paragraph{Differential privacy and Statistics / Learning.}
%The task of estimating various quantities under differential privacy has garnered growing interest over the past decade. A selection of references includes, but is not limited to 
%____. Notably, it is possible to perform advanced private learning tasks such as deep learning with a technique called DP-SDG for \emph{differentially private stochastic gradient descent} ____. The method that we will present in this article is typically aimed at being a \emph{data-dependent} regulizer for this framework penalizing with discrepencies of prescribed empirical measures.
\paragraph{Differential Privacy and Optimal Transport}
Our analysis aligns with the work of ____, which extends the ideas from ____—originally applied to the Maximum Mean Discrepancy (MMD)—to the sliced Wasserstein loss. This work establishes privacy guarantees for the value of the sliced Wasserstein distance. However, the privacy guarantees are insufficient for training models privately, except in simple scenarios such as the generative model proposed in ____. In contrast, our work is significantly broader in scope, and adapts to a wider range of problems, as discussed in \cref{remark:comparison}. ____ follow the same line of ____, extending their methodology to an alternative definition of the sliced Wasserstein distance.  In a different vein, other existing works develop task-specific private methodologies leveraging optimal transport. The sliced Wasserstein distance has been applied in data generation by ____ from a different approach based on gradient flows. ____ tackled differentially private domain adaptation with optimal transport by perturbing the optimal coupling between noisy data. Recently, ____ proposed a post-processing method based on the Wasserstein barycenter of private histogram estimators of conditional densities to obtain a fair and private regressor. Beyond these approaches, optimal transport has also been explored in novel privacy paradigms unrelated to our work ____.
\paragraph{Fairness in Machine Learning.}
Fairness in machine learning has emerged as a critical area of research, driven  by the growing recognition of its societal impact and the ethical implications of algorithmic decision-making. Additionally, regulatory frameworks such as the General Data Protection Regulation (GDPR) and the recent European AI Act\footnote{\url{https://artificialintelligenceact.eu/}} mandate stringent measures to identify and mitigate bias in AI systems, emphasizing the need for fair and private methodologies in machine learning. Unfairness arises when certain variables, often referred to as sensible variable, systematically bias the behavior of an algorithm against specific groups of individuals, leading to disparate outcomes. This field of research has received a growing attention over the last few years as pointed out in the following papers and references therein ____.

The Wasserstein distance offers a compelling framework for addressing fairness, as it provides a principled way to quantify discrepancies between the distributions of different subgroups. Moreover, as stated first in ____, then in ____ or ____, Wasserstein distance between the conditional distributions of the algorithm  for each group, is the natural  measure to quantify the cost of ensuring fairness of the algorithm, defined as algorithms exhibiting the same behavior for each group. Hence optimal transport based methods are commonly used to  assess and mitigate distributional biases, paving the way for more equitable algorithmic decision-making. We refer, for instance, to the previously mentioned references ____ and references therein.


\paragraph{Differential Privacy and Fair Learning.}

The interplay between fairness and differential privacy has received significant attention in recent years. A comprehensive review of this topic in decision and learning problems is provided in ____. Within the learning framework, research has progressed in various directions. From a theoretical standpoint, despite the early work of ____ demonstrating inherent incompatibilities between exact fairness and differential privacy, ____ recently presented promising theoretical results indicating that fairness is not severely compromised by privacy in classification tasks. Another research direction has focused on studying the disparate impacts on model accuracy introduced by private training of algorithms. This phenomenon was first observed in ____ and has been extensively studied in subsequent works ____. A third line of research aims to develop models that are both private and fair. Private and fair classification models have been proposed using in-processing and post-processing techniques across various scenarios in ____. A recent comparison of these works can be found in ____. 
In the topic of fair and private regression, the only available work is the aforementioned post-processing method of ____, which is limited to one-dimensional case.