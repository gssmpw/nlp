\section{Related Work}
\label{sec:related_work}
% \vspace{-0.5em}
\paragraph{Camera Modeling and Lens Distortion.}
Lens distortion is an inherent property of all cameras. In general, nonlinear distortion can be formulated as:
\begin{equation}
\textbf{x}_d = \textbf{K} \cdot D\left(\pi\left(\textbf{R}\cdot\textbf{X} + \textbf{t}\right)\right),
\end{equation}
where $\textbf{K}$ and $[\textbf{R}|\textbf{t}]$ represent the intrinsic and extrinsic parameters, respectively. $\textbf{X}$ is a 3D point in world coordinates. $\pi(\cdot)$ denotes the pinhole projection, including dehomogenization to obtain 2D points $\textbf{x}_n$ on the image plane. The distortion model $D(r(\textbf{x}_n))$ is parameterized as a polynomial function of the radial distance:
\begin{equation} \label{eq:radial}
D(r(\textbf{x}_n)) = 1 + k_1r^2 + k_2r^4 + k_3r^6 + \ldots
\end{equation}
where $k_1$, $k_2$, $k_3$, $\ldots$ are the parameters of the Brown–Conrady model~\cite{conrady1919decentred,brown1996decentering}, derived from calibration, and $r = \sqrt{x_n^2 + y_n^2}$.
Scaramuzza \textit{et al.}\cite{scaramuzza2006toolbox} first proposed a unified model for large-FOV fisheye lenses, which has been adopted in several works\cite{bujnak2010new,kukelova2015efficient}. The most widely used fisheye model~\cite{itseez2015opencv} describes distortion as a function of the angular distance from the projection center:
\begin{equation} \label{eq:fisheye}
D(r(\textbf{x}_n)) = \frac{\theta}{r} \left(1 + k_1\theta^2 + k_2\theta^4 + k_3\theta^6 + \ldots\right),
\end{equation}
where $\theta = \arctan\left(\frac{r}{1}\right)$, and the distances of projected points to the image plane are normalized to 1.
The 3D Gaussian Splatting method~\cite{kerbl20233d} assumes a standard perfect pinhole camera model and typically relies on COLMAP~\cite{schoenberger2016sfm} to undistort images before reconstruction. To remove this constraint, recent methods~\cite{liao2024fisheye,moenne20243d} adopt parametric models like~\cref{eq:fisheye} to extend 3D Gaussian Splatting techniques to fisheye images. However, these methods still depend heavily on camera calibration for accurate estimation and fix the projection in rasterization, limiting their generalizability to various camera types.
Some works~\cite{moenne20243d} introduce ray tracing into the rasterization pipeline and approximate Gaussian bounding using an icosahedron, which can potentially compromise rasterization efficiency. Other approaches~\cite{li2024omnigs,bai2024360,huang2025sc} explore reconstruction from omnidirectional 360° panoramas, but the key difference is that panoramas require calibration to stitch two fisheye images together, which does not preserve raw geometric consistency at the stitching boundary.
We address these limitations by introducing a hybrid distortion field that is compatible with the 3D Gaussian Splatting pipeline. Our experiments demonstrate that existing methods, such as Fisheye-GS~\cite{liao2024fisheye} and ADOP~\cite{ruckert2022adop}, which incorporate traditional camera distortion models from~\cref{eq:radial,eq:fisheye} into the rasterization process, are not expressive enough to handle the severe distortions present in large-FOV cameras.


\input{images/method}
% \vspace{-1.2em}
\paragraph{Self-Calibrating Reconstruction.}
The bundle adjustment process can be extended to optimize camera lens parameters alongside poses, a process known as self-calibration~\cite{zhang1999flexible,pollefeys1999self,devernay2001straight,hartley2003multiple}. Camera calibration without a known calibration target is particularly challenging, as it relies on strong assumptions about scene structure and geometric priors to establish reliable correspondences~\cite{barreto2005geometric,carroll2009optimizing,aleman2014automatic}. Camera auto-calibration methods~\cite{zhang1999flexible,pollefeys1999self,devernay2001straight} extend this idea by deriving camera intrinsics from multi-view observations of unstructured scenes, an approach further advanced in recent studies~\cite{fang2022self,engel2016photometrically,ha2016high,deng2024physics}.
Several non-parametric models have been developed to ensure broad applicability across different camera and lens combinations~\cite{grossberg2001general,camposeco2015non,hartley2007parameter,li2006plane}, while additional regularization is often required to maintain smooth underlying distortion~\cite{pan2022camera}. With advances in differentiable rendering and rasterization pipelines~\cite{kopanas2021point,yifan2019differentiable}, recent works~\cite{ruckert2022adop,xian2023neural,jeong2021self} have demonstrated that camera lens distortion can be optimized jointly with other parameters through a differentiable projection module.
Prior works have also adapted NeRF for panoramic and fisheye-distorted inputs~\cite{gu2022omni,huang2022360roam,xu2023vr,kulkarni2023360fusionnerf}. These solutions typically rely on parametric models tailored for specific lenses, limiting their generalizability to a broader range of lens types. SCNeRF~\cite{jeong2021self} models a residual projection matrix and residual raxel parameters~\cite{grossberg2005raxel}, which are interpolated on a sub-sampled pixel grid. NeuroLens~\cite{xian2023neural} optimizes lens parameters through an invertible neural network, while SC-OmniGS~\cite{huang2025sc} optimizes camera parameters jointly with reconstruction but relies on calibrated captures.
Building on insights from prior self-calibration methods, this work introduces a novel and efficient approach to modeling lens distortion, fully integrated with 3DGS~\cite{kerbl20233d}.