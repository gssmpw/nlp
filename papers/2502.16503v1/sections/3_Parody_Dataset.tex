\section{FanChuan}

\begin{figure*}[htbp]
\centering
  \includegraphics[width=1\linewidth]{images/illustrations/dataset_construction.pdf}
  \caption{The pipeline for the construction of FanChuan, which includes three key steps: data collection (left), annotation (middle), and preprocessing (right).}\vspace{-0.48cm}
  \label{fig:data_construction}
\end{figure*}


In this section, we will introduce the details about FanChuan. Specifically, in Section \ref{sec:datast_construction}, we introduce the dataset construction process, including data collection, annotation and preprocessing. These steps ensure high diversity, precise annotations, and rich contexts within our dataset. In Section \ref{sec:problem_definition}, we propose three parody-related tasks for model evaluations.

\subsection{Dataset Construction}\label{sec:datast_construction}

As illustrated in Figure \ref{fig:data_construction}, the data construction process for FanChuan involves three steps: data collection, annotation, and preprocessing. Then we introduce the details of each step as follows.

\paragraph{Data collection} To ensure a comprehensive evaluation, we ensure \textbf{high diversity} in our benchmark by selecting a wide range of topics from both Chinese and English corpora. Given that parody often emerges around controversial issues, we begin by focusing on topics or recent events that have sparked intense debates on social media. To select the post that includes adequate parody comments, we randomly sample a subset of its comments to determine the proportion of parody content. If more than $3\%$ of the comments are identified as parody, we classify it as suitable for further collection. To capture the most relevant content, we use keyword search to identify prominent posts, then collect their comments, replies, and associated content.

\paragraph{Data Annotation} Labeling parody presents a significant challenge, not only because it requires a high familiarity with the content and culture \citep{banziger2005role}, but also due to potential disagreements of understanding among annotators from diverse backgrounds \citep{dress2008regional}. To ensure \textbf{precise annotations} in FanChuan, the annotation process includes five steps: 
\textbf{(1)} To provide accurate and culturally relevant insights, we assign native speakers to annotate Chinese and English datasets, respectively. Annotators are then asked to review relevant materials to enhance their understanding before starting the annotation process.
\textbf{(2) Sentiment Annotation.} Annotators classify the sentiment of a given comment or user by answering the question: \textit{``Does this comment or user support, oppose, or remain neutral regarding to this statement?''}
\textbf{(3) Parody Annotation.} After sentiment classification, annotators are asked to determine whether a comment is a parody by answering the question: \textit{``Is this comment a parody or not?''} During both sentiment and parody annotation stages, annotators are provided with relevant comments and context to ensure accurate labeling.
\textbf{(4) Resolving Discrepancies.} Each comment receives a final label based on the majority vote of three annotators. If consensus is not reached, the most knowledgeable annotator on the relevant topic or event reassesses the labels.
\textbf{(5) Verification.} To minimize errors in parody annotations, an experienced annotator reviews all comments labeled as parody. Note that this annotator will also double-check the comments that are labeled as parody by LLMs but not labeled by human annotators. 
% This final step ensures \textbf{precise and high-quality} parody annotations.

\paragraph{Data preprocessing} To ensure data quality, we first delete any content or comments that contain irrelevant, sensitive, personal, or hazardous information. We provide three types of embeddings: Bag of Words (BoW) \citep{BoW}, Skip-gram \citep{Skip-gram}, and RoBERTa \citep{RoBERTa}. Given that the context of parody forms a network structure, we store the data as heterogeneous graphs as shown in Figure \ref{fig:ORP_graph}, where the nodes represent users and posts, and there are two types of edges to represent two types of relations: user-comments-post, and user-comments-user. Compared with existing datasets \citep{dialogue_bamman, ptaek2014sarcasm} that focus solely on content or dialogue, such graph-structured data enables deeper understanding of parody with \textbf{richer contexts}, including 2-hop neighbors and higher-order relationships.

Finally, as shown in Table \ref{tab:dataset_statistics}, we constructed seven datasets from both Chinese and English corpora, encompassing multiple topics, with a total of 14,755 annotated users and 21,210 annotated comments. Our analysis reveals that parody comments constitute only a small proportion of the total comments across all datasets. For detailed description and background information of each dataset, please refer to Appendix \ref{apd:dataset_details}.

\input{tables/dataset_statistics}

\subsection{Problem Definition}\label{sec:problem_definition}

As shown in Figure \ref{fig:ORP_graph}, we utilize Heterogeneous Information Networks (HINs) to structure our datasets, representing the relational information in content and comments. Each HIN comprises two types of nodes: user nodes and post nodes, along with two types of edges: user comments to posts and user comments to users\footnote{A comment on another comment inherently forms an edge linking to another edge, which cannot be directly represented in a graph. Instead, we connect such comments to the target user, as they reflect that user's traits or viewpoints.}. Each edge is directed, with the source being the user and the target either a post or another user. As shown by the \textcolor{orange}{orange} edges on the right in Figure \ref{fig:ORP_graph}, multiple edges may exist between two nodes due to several rounds of replies among these users. This results in a directed multigraph \citep{gross2003handbook}. Each edge or node is associated with text as features. We then introduce three tasks as follows.

\paragraph{P1. Parody Detection} Parody detection aims to identify whether a comment is \textcolor{orp}{parody} or \textcolor{neu}{normal}. In HINs, this can be framed as a binary classification task on edges. Given that parody comments represent a small fraction of all comments, this task can also be considered as outlier detection.

\paragraph{P2. Comment Sentiment Classification} Like parody detection, comment sentiment classification aims to categorize comments into three sentiment labels: \textcolor{pos}{positive}, \textcolor{neg}{negative}, and \textcolor{neu}{neutral}.

\paragraph{P3. User Sentiment Classification} This task focuses on classifying users' sentiment as either a \textcolor{pos}{supporter}, \textcolor{neg}{opponent}, or \textcolor{neu}{neutral}. Unlike the edge classification tasks discussed earlier, this is a node classification task in HINs.

\begin{figure*}[htbp]
\centering
  \includegraphics[width=1\linewidth]{images/illustrations/ORP_graph.pdf}
  \caption{Examples of a parody dataset as a heterogeneous graph.}\vspace{-0.4cm}
  \label{fig:ORP_graph}
\end{figure*}

\paragraph{Remarks} We introduce sentiment classification tasks due to the complexity of the scenarios that include parody comments \cite{bull2010automatic}. In the context of parody, these tasks serve as a comprehensive measure to assess the effectiveness of current models in handling parody-related tasks, which will be introduced in the next section.

% Specifically, our HIN comprises two distinct node sets: a user set $\mathcal{U}=\{u_i|1\le i\le N_U\}$ and a poster set $\mathcal{P}=\{p_j|1\le j\le N_P\}$. Furthermore, it encompasses two types of edge sets: comments on posters, denoted as $\mathcal{C}^P=\{u_i \xrightarrow{c_k^P} p_j | 1\le k\le N_C^P\}$, and comments on users, represented as $\mathcal{C}^U=\{u_i \xrightarrow{c_q^U} u_j | 1\le q\le N_C^U\}$\footnote{Given that a comment on another comment inherently forms an edge linking to another edge, which cannot be directly represented in a graph, we instead connect such comments to the target user, as they reflect that user's traits or viewpoints.}. Due to potential multiple rounds of replies, our network may contain numerous edges between any two nodes, forming a directed multigraph \citep{gross2003handbook}. Each edge and node is associated with feature vectors $\mathbf{X}$ and $\bar{\mathbf{X}}$, respectively. Then, we introduce three tasks as follows.

% predict the label $Y$ for all comments $\mathcal{C} = \mathcal{C}^P \cup \mathcal{C}^U$. This can be formulated as a binary classification task for edges in graphs. Each comment (edge) $c_k \in \mathcal{C}$ is associated with a label $Y \in \{0, 1\}$, where $1$ indicates that $c_k$ is a parody comment, and $0$ otherwise.