\section{Experiments}
\label{sec:Experiments}

% In this section, we present the experimental results of current methods applied to FanChuan. We begin by outlining the experimental settings in Section \ref{sec:exp_settings}. Next, we provide a performance comparison in Section \ref{sec:exp_performance}. Following that, we analyze the impact of context on parody detection and the influence of parody on sentiment analysis in Sections \ref{sec:exp_context_impact} and \ref{sec:exp_parody_senti}, respectively. Finally, we explore how reasoning with large language models (LLMs) affects performance in parody detection.

\subsection{Settings}\label{sec:exp_settings}

We split all the comment data into training, validation, and test sets with a ratio of 40\%/30\%/30\%. We consider parody detection as a binary classification problem use F1 score for the evaluation. We model the comment and user sentiment classification with parody as multi-class classification problems, and use Macro-F1 to measure the model performance.
%Since parody only account for around 5\%-10\% of the comments, 
% \paragraph{Methods}
For comprehensive evaluation and analysis, we test five types of approach in our experiments:

\textbf{(1) Embedding-based methods.} This category includes Bag-of-Words (BoW) \citep{BoW}, Skip-gram \citep{Skip-gram}, and RoBERTa \citep{RoBERTa}, all of which utilize Multi-Layer Perceptron (MLP) classifiers. These methods are widely used and can provide general text representations to capture linguistic patterns and semantics.

\textbf{(2) Inconsistency-based methods.} These methods are commonly used for irony detection and we assess BNS-Net \citep{BNS-Net}, DC-Net \citep{DC-Net}, QUIET \citep{QUIET}, and SarcPrompt \citep{SarcPrompt}. Similar to irony or sarcasm, parody usually contains inconsistencies between literal and intended meaning, and thus, the evaluation of these methods are necessary.

\textbf{(3) Outlier detection methods.} This category includes Isolation Forest \citep{IsolationForest}, the Z-Score Method \citep{Z-Score}, and One-Class SVM \citep{OneclassSVM}. Similar to outlier detection tasks, where data is highly imbalanced, parody only accounts for around 5\%-10\% of all comments and tremendously deviates from the normal comment patterns, which makes outlier detection methods quite relevant.

\textbf{(4) Graph-based methods.} Since (graph-structured) context information is highly important for parody understanding, and to capture complex structural information in user interaction graphs, Graph Neural Networks (GNNs) could be used for user sentiment classification. Three types of classical GNNs are used: Graph Convolutional Networks (GCN) \citep{GCN}, Graph Attention Networks (GAT) \citep{GAT}, and GraphSAGE \citep{GraphSAGE}.

\textbf{(5) Large Language Models (LLMs).} We evaluate models such as ChatGPT-4o (and 4o-mini) \citep{GPT4} from OpenAI, Claude 3.5 \citep{Claude} from Anthropic, Qwen 2.5 \citep{Qwen2.5} from Alibaba, and DeepSeek-V3 \citep{DeepSeek} from DeepSeek. Given the strong reasoning capabilities and contextual understanding of LLMs in NLP-related tasks, we assess their performance in parody detection under a zero-shot setting.


\subsection{Performance Comparison}\label{sec:exp_performance}
The evaluation results on the three parody-related tasks are shown in Table \ref{tab:ORP_detection_new}, \ref{tab:sentiment_detection_new},  \ref{tab:user_sentiment_detection_new}. The best and runner-up methods for each dataset are highlighted in \textbf{bold} and \underline{underlined}, respectively. Then, the detailed comparison and analysis are as follows.

\input{tables/fanchuan_new}
\paragraph{Parody Detection.} The results in Table \ref{tab:ORP_detection_new} indicate that: (1) Parody detection is challenging for all models, with most achieving only $10\%\sim40\%$ F1 scores. Even the best-performing methods for \textit{Alibaba.} and \textit{Drink.} reach only $16.17\%$ and $17.39\%$, respectively, highlighting the difficulty of the task. (2) LLMs generally rank higher but struggle with Chinese datasets. Specifically, both of ChatGPT-4o and Deepseek-V3 achieve $3.86$ average rank across all datasets, outperforming other methods. However, traditional methods perform better on Chinese datasets. For instance, SarcPrompt achieves an F1 score of $22.22\%$ on \textit{Bride.} and $21.39\%$ on \textit{CS2}, outperforming the best LLM by a large margin. In addition to the performance comparison, we conduct a case study to further investigate how well LLMs understand parody detection in Appendix \ref{apd:sec_case_study}.

\input{tables/sentiment_new}
\input{tables/user_sentiment_new}
\paragraph{Sentiment Classification.} Tables \ref{tab:sentiment_detection_new} and \ref{tab:user_sentiment_detection_new} present the model performance in comment and user sentiment classification, respectively. Our findings are as follows: (1) Sentiment classification in the context of parody presents significant challenges. The top-performing models across each dataset achieve F1 scores ranging from 40\% to 50\%, which are notably lower than the performance on traditional sentiment classification benchmarks without parody\citep{senti_benchmark1,senti_benchmark2}. (2) Although LLMs show their superiority over other methods in terms of average rank, they still underperform some traditional approaches on certain datasets. For example, although ChatGPT-4o-mini attains the highest average rank of 4.29 in comment sentiment classification, it performs much worse than BoW+MLP on \textit{Bride.} and DC-Net on \textit{Campus.} (3) Graph-based methods demonstrate strong performance on certain datasets. For example, GCN achieves the best results on \textit{Bride.}, suggesting that the relational context information in user-interaction networks is informative and beneficial for some tasks in sentiment classification.
%These results underscore the effectiveness of inconsistency-based and embedding-based methods in sentiment classification within the parody context. Further analysis of why LLMs cannot perform well on these datasets are needed

In general, all the parody-related tasks are challenging for current models and no model can take dominant advantage over others cross all datasets. These observations underscore the need for further study and model development on parody-related tasks.

\subsection{Influence of Context on Parody Detection}\label{sec:exp_context_impact}
\input{tables/ORP_context_table}

Since parody detection requires a deep understanding of the background information of a topic, intuitively, the context information should have a strong impact on model performance. Therefore, we introduce relevant background details and target comments (when available), and conduct ablation study to investigate its impact on model performance. In Table \ref{tab:impact_context}, we report the average F1 score across seven datasets, both with and without context. Performance improvements and declines are highlighted in \textcolor{increase}{green} and \textcolor{decrease}{red}, respectively.

Overall, most models benefit from contextual information, with ChatGPT-4o improving significantly from $24.04$ to $28.53$ and RoBERTa+MLP increasing from $16.43$ to $21.23$. Our results are consistent with the observations in \citep{dialogue_bamman,dialogue_wang} that context improves model performance on sarcasm and irony detection. However, Qwen2.5 is the only model that performs worse with added context, suggesting potential limitations in how it processes additional information. These results highlight that while context generally enhances parody detection, its effectiveness varies across models. Please refer to Appendix \ref{apd:impact_context} for more details of the impact of context on each dataset.

\subsection{Influence of Parody to Sentiment Classification}\label{sec:exp_parody_senti}
\input{tables/ORP_senti_table}

To confirm that parody adds challenges to sentiment classification, we evaluate model performance using Macro F1 score averaged over seven datasets on comment sentiment classification, and compare the results of parody and non-parody comments. As shown in Table \ref{tab:impact_parody_senti}, the average Macro F1 scores decrease by $5\%$ to $15\%$ across all models, indicating that parody significantly increases the difficulty of sentiment classification. Additionally, we observe that while LLMs outperform embedding-based methods on non-parody comments, their performance deteriorates on parody comments, falling a lot behind embedding-based methods. We speculate that this degradation occurs because these topics are relatively new and LLMs have not encountered such data before, whereas the training process in embedding-based methods allows them to better adapt to the updated knowledge. For more details of the impact of context on each dataset, please refer to Appendix \ref{apd:impact_parody}.

\subsection{Reasoning LLMs in Parody Detection}
\label{sec:exp_reasoning_llms}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.9\columnwidth]{images/LLMCompare/Average_LLMCompare.pdf}
  \vspace{-0.4cm}
  \caption{Performance comparison between reasoning LLMs and non-reasoning LLMs using average F1 Score (\%) over six datasets.}\vspace{-0.4cm}
  \label{fig:reasoning_llms}
\end{figure}

Recently, there has been a surge in reasoning LLMs \citep{ChatGPT-o1}, which enhance performance by introducing inference-time scaling in the Chain-of-Thought (CoT) \citep{CoT} reasoning process. To assess the impact of reasoning on LLM performance in parody detection, we compared the performance of reasoning LLMs with that of non-reasoning LLMs. Figure \ref{fig:reasoning_llms} presents the average F1 scores of reasoning LLMs, including ChatGPTo1-mini \citep{ChatGPT-o1}, ChatGPTo3-mini \citep{ChatGPT-o3}, and DeepSeek-R1 \citep{DeepSeek-R1}, and non-reasoning LLMs, including ChatGPT4o, ChatGPT4o-mini, and DeepSeek-V3. Surprisingly, unlike math, coding \citep{o1_math} and medical applications \citep{o1_medical}, where reasoning LLMs significantly improve performance, our results show that reasoning LLMs underperform their non-reasoning counterparts. This finding aligns with the conclusion in \citep{yao2024sarcasm}, which suggests that tasks like sarcasm detection do not follow a step-by-step reasoning process. This can explain why CoT does not enhance LLM performance. It indicates that the complexities of parody detection may require alternative strategies beyond reasoning, highlighting the need for further research in this area. Please see Appendix \ref{apd:reasoning_llms} for detailed results on the performance of reasoning LLMs in parody detection.