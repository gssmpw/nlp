\vspace{-0.2cm}
\section{Conclusions}
\vspace{-0.2cm}
In this paper, we introduce FanChuan, a multilingual benchmark for parody detection and analysis, encompassing seven datasets characterized by high diversity, rich contextual information, and precise annotations. Our findings reveal that parody detection remains highly challenging for both LLMs and traditional methods, with particularly poor performance on Chinese datasets. We also observe that contextual information significantly enhances model performance, while parody itself increases the difficulty of sentiment classification. Additionally, our results indicate that reasoning fails to improve LLM performance in parody detection. By filling a critical gap in the study of emerging online phenomena, FanChuan provides valuable insights into cultural values and the role of parody in digital discourse. These findings highlight the limitations of current LLMs, presenting an opportunity for future research to enhance model capabilities in parody detection and analysis.
