\begin{table*}[h]
\centering
\resizebox{1\textwidth}{!}{
\begin{tabular}{ll|ccccccc|c}
\toprule
\textbf{Paradigm} & \textbf{Method} & \textbf{Alibaba.} & \textbf{Bride.} & \textbf{Drink.} & \textbf{CS2} & \textbf{Campus.} & \textbf{Tiktok.} & \textbf{Reddit.} & \textbf{Ave. Rank} \\
\midrule
\multirow{3}{*}{\makecell[l]{Embedding\\-based}} 
& BoW+MLP & 35.30 & \textbf{40.43} & \underline{48.78} & 27.56 & 32.35 & 33.74 & 37.13 & 8.14  \\
& Skip-gram+MLP & 39.62 & \underline{39.50} & 47.46 & 31.09 & 30.80 & 35.42 & 37.71 & 6.29  \\
& RoBERTa+MLP & 36.91 & 34.48 & 44.17 & 26.02 & \underline{38.87} & 47.56 & 51.66 & 8.00  \\
\midrule
\multirow{4}{*}{\makecell[l]{Inconsistency\\-based}} 
& BNS-Net & 35.48 & 29.40 & 45.66 & 21.13 & 29.71 & 26.47 & 22.08 & 7.29  \\
& DC-Net & 16.07 & 28.87 & 48.66 & 18.89 & \textbf{38.90} & 45.21 & 37.18 & 7.29  \\
& QUIET & 24.34 & 30.26 & 35.52 & 17.65 & 30.05 & 29.51 & 23.95 & 7.00  \\
& SarcPrompt & 28.77 & 28.85 & 33.91 & 19.18 & 35.21 & 40.06 & 22.69 & 5.43  \\
\midrule
\multirow{5}{*}{LLMs} 
& ChatGPT4o & 40.00 & 32.28 & 47.75 & \textbf{37.82} & 32.10 & 51.02 & 51.89 & \underline{4.86}  \\
& ChatGPT4o-mini & \underline{40.01} & 34.27 & \textbf{49.95} & 34.33 & 33.19 & \underline{51.56} & \underline{52.42} & \textbf{4.29}  \\
& Claude3.5 & \textbf{40.53} & 29.89 & 42.99 & 30.70 & 28.31 & 46.03 & 51.92 & 5.71  \\
& Qwen2.5 & 38.46 & 31.83 & 46.14 & \underline{34.78} & 28.38 & 47.55 & 51.93 & 6.86  \\
& DeepSeek-V3 & 35.88 & 28.15 & 43.05 & 32.62 & 36.36 & \textbf{56.26} & \textbf{54.83} & 6.86  \\
\bottomrule
\end{tabular}
}
\caption{Comparison of model performance in comment sentiment classification with parody using Macro-F1 score (\%)}\vspace{-0.4cm}
\label{tab:sentiment_detection_new}
\end{table*}