\begin{table*}[h]
\centering
\resizebox{1\textwidth}{!}{
\begin{tabular}{ll|ccccccc|c}
\toprule
\textbf{Paradigm} & \textbf{Method} & \textbf{Alibaba.} & \textbf{Bride.} & \textbf{Drink.} & \textbf{CS2} & \textbf{Campus.} & \textbf{Tiktok.} & \textbf{Reddit.} & \textbf{Ave. Rank} \\
\midrule
\multirow{3}{*}{\makecell[l]{Embedding\\-based}} 
& BoW+MLP & \underline{46.54} & 37.60 & 46.65 & 29.22 & 32.35 & 35.05 & 31.97 & 7.57 \\
& Skip-gram+MLP & \textbf{46.99} & 38.28 & \underline{50.45} & 31.92 & 32.02 & 38.46 & 32.69 & 6.42 \\
& RoBERTa+MLP & 43.11 & 36.94 & 44.20 & 27.09 & 35.49 & \underline{50.82} & \underline{52.79} & \underline{5.00} \\
\midrule
\multirow{3}{*}{\makecell[l]{Inconsistency\\-based}} 
& BNS-Net & 34.32 & 27.21 & 41.91 & 23.38 & 28.67 & 23.61 & 22.98 & 13.00 \\
& DC-Net & 16.51 & 33.56 & 48.65 & 17.17 & 35.60 & 34.62 & 39.54 & 9.57 \\
& SarcPrompt & 27.72 & \underline{38.54} & 29.51 & 15.62 & 31.45 & 24.48 & 39.10 & 11.29 \\
\midrule
\multirow{3}{*}{\makecell[l]{Graph\\-based}} 
& GCN & 37.69 & \textbf{40.00} & 43.67 & 23.64 & 36.45 & 42.94 & 48.06 & 7.00 \\
& GAT & 38.30 & 38.53 & 43.44 & 23.72 & \underline{37.20} & 42.12 & 50.57 & 6.71 \\
& GraphSAGE & 39.92 & 37.63 & 42.79 & 25.98 & 32.94 & 40.66 & 52.08 & 7.71 \\
\midrule
\multirow{5}{*}{LLMs} 
& ChatGPT-4o & 41.71 & 35.02 & \textbf{51.54} & \textbf{39.19} & 35.89 & 45.87 & 49.01 & \textbf{4.14} \\
& ChatGPT-4o-mini & 40.55 & 30.25 & 45.88 & 34.03 & 31.95 & 45.29 & 51.20 & 6.71 \\
& Claude3.5 & 41.47 & 29.96 & 43.78 & 32.81 & 31.07 & 41.85 & 46.92 & 8.57 \\
& Qwen2.5 & 40.89 & 33.08 & 49.52 & \underline{36.51} & 33.34 & 46.18 & 50.13 & 5.29 \\
& DeepSeek-V3 & 40.00 & 26.37 & 41.55 & 33.61 & \textbf{40.49} & \textbf{54.04} & \textbf{53.22} & 6.00 \\
\bottomrule
\end{tabular}
}
\caption{Comparison of model performance in user sentiment classification with parody using Macro-F1 score (\%).}\vspace{-0.4cm}
\label{tab:user_sentiment_detection_new}
\end{table*}