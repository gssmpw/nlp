% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
% \documentclass[runningheads]{llncs}
\documentclass{article}
%
\usepackage[T1]{fontenc}
\usepackage{microtype}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{graphicx}
\usepackage{makecell}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{float}
\usepackage{amsfonts}
\usepackage{bm}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algorithmic}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
\usepackage{color}
\usepackage{hyperref}
\usepackage{xcolor}
% \setcitestyle{maxnames=3}
\renewcommand\UrlFont{\color{blue}\rmfamily}

\definecolor{darkblue}{RGB}{0,0,139}  % Define dark blue color
\urlstyle{rm}

% \input{squenze}

\def\vbeta{{\bm{\beta}}}
% \input{macros.tex}

\usepackage{amssymb}
\usepackage{bbm}

\newcommand{\sR}{\mathbb{R}}
\newcommand{\AYA}{\tiny\texttt{AYA}}
\newcommand{\CARE}{\tiny\texttt{CARE}}
\newcommand{\EDGE}{\tiny\texttt{REL}}

\DeclareMathOperator*{\argmax}{arg\,max}

\def\Sleep{{\texttt{Sleep}}}
\def\Stress{{\texttt{Stress}}}
\def\Rel{{\texttt{Relatsh}}}
\def\Mood{{\texttt{Mood}}}
\def\SqrtStep{{\texttt{SqrtStep}}}
\def\ADH{{\texttt{ADH}}}
\def\Treat{\tiny{\texttt{Treat}}}

\def\AM{{\texttt{AM}}}
\def\PM{{\texttt{PM}}}

%

% Comments
% \usepackage{xcolor}
\newcount\comments  % 0 suppresses notes to selves in text
\comments=1  % TODO: change to 0 for final version
\newcommand{\genComment}[2]{\ifnum\comments=1{\textcolor{#1}{\textsf{\footnotesize #2}}}\fi}
\newcommand{\ziping}[1]{\genComment{green}{[Ziping:#1]}}
\newcommand{\sam}[1]{\genComment{blue}{[SAM:#1]}}
\newcommand{\hinal}[1]{\genComment{brown}{[Hinal:#1]}}

\usepackage{silence}
\WarningFilter{latexfont}{Command \tiny invalid in math mode}
\WarningFilter{latexfont}{Overfull}
\hbadness=10000  % Add this line to suppress overfull hbox warnings

\newcommand{\coloneq}{\mathrel{\mathop:}=}

\definecolor{redorange}{RGB}{255,69,0}  % A reddish-orange color
\definecolor{grassgreen}{RGB}{76, 153, 0}
\begin{document}
%
\title{Reinforcement Learning on AYA Dyads to Enhance Medication Adherence}

\date{}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
% \author{Ziping Xu\inst{1} \and
% Hinal Jajal\inst{1} \and
% Sung Won Choi\inst{2} \and
% Inbal Nahum-Shani\inst{2} \and
% Guy Shani\inst{2} \and
% Alexandra M. Psihogios \inst{3} \and
% Pei-Yao Hung \inst{2} \and
% Susan Murphy\inst{1}}
%
% \authorrunning{Xu et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\author{Ziping Xu\thanks{Harvard University, Cambridge, MA, USA} \and
Hinal Jajal\footnotemark[1] \and
Sung Won Choi\thanks{University of Michigan, Ann Arbor, MI, USA} \and
Inbal Nahum-Shani\footnotemark[3] \and
Guy Shani\footnotemark[3] \and
Alexandra M. Psihogios\thanks{Northwestern University, Feinberg School of Medicine, Chicago, IL, USA} \and
Pei-Yao Hung\footnotemark[3] \and
Susan Murphy\footnotemark[1]}
\maketitle              % typeset the header of the contribution
%
\begin{abstract}

% \ziping{Alternative title: Enhancing Medication Adherence on AYA Dyads with Reinforcement Learning Powered Digital Interventions}

% \ziping{Should we include multi-agent? For example, Multi-agent Reinforcement Learning on Dyads to Enhance Medication Adherence}

Medication adherence is critical for the recovery of adolescents and young adults (AYAs) who have undergone hematopoietic cell transplantation (HCT). However, maintaining adherence is challenging for AYAs after hospital discharge, who experience both individual (e.g. physical and emotional symptoms) and interpersonal barriers (e.g., relational difficulties with their care partner, who is often involved in medication management).
To optimize the effectiveness of a three-component digital intervention targeting both members of the dyad as well as their relationship, we propose a novel Multi-Agent Reinforcement Learning (MARL) approach to personalize the delivery of interventions.
By incorporating the domain knowledge, the  MARL framework, where each agent is responsible for the delivery of one intervention component, allows for faster learning compared with a flattened agent. Evaluation using a dyadic simulator environment, based on real clinical data, shows a significant improvement in medication adherence (approximately 3\%) compared to purely random intervention delivery. The effectiveness of this approach will be further evaluated in an upcoming trial.

% of optimizing deliveries across different time scales for each intervention component and accelerating learning in the noisy envioronment induced by the complex dynamics of human behavior are addressed by proposing a multi-agent RL framework that personalizes intervention delivery. We evaluate the proposed framework in a dyadic simulator environment, which is shown to significantly improve medication adherence over baseline algorithms.

% The intervention package combines both positive psychology messages for individual outcomes and collaborative games for relational outcomes to support AYAs and their care partners over a 100-day period following hematopoietic cell transplantation (HCT). 

% By integrating personalized positive psychology messages and collaborative activities, the intervention aims to improve both individual and relational outcomes. We address key challenges in multi-agent reinforcement learning, including managing interventions across different time scales and accelerating learning in noisy, data-limited environments. Our results demonstrate the effectiveness of the proposed framework in fostering collaboration among agents and optimizing intervention delivery, ultimately contributing to improved medication adherence in dyadic contexts.


% \keywords{Reinforcement Learning \and Dyadic Relationships \and Medication Adherence \and Digital Health}
\end{abstract}

\input{Sections/0_Introduction.tex}
\input{Sections/1_Methods.tex}
% \input{Sections/2_Testbed.tex}
\input{Sections/3_Results.tex}
% \input{Sections/4_Conclusion.tex}



\bibliographystyle{plain}   
\bibliography{main.bib}

\newpage

\appendix
\input{Sections/5_Appendix.tex}
\end{document}