\section{Spurious Biases and their Impact on Generalizability}\label{sec:bias}
\vspace{0.1in}
Deep neural networks tend to learn and rely on correlations between partly predictive spurious features that are causally unrelated to ground truth labels in the training data. For example, assume one wants to train a deep neural network to be able to correctly classify pictures of animals as Cows or Camels~\cite{Arjovsky2019}. Due to selection bias, most samples that have Cows in them are present in green backgrounds in the training set while most Camels are present in brown backgrounds. In such a setting, deep networks are shown to learn the correlation between the background color and the ground truth labels. Such correlations are referred to as spurious correlations. In practice, deep networks often prefer spurious correlations over correlations between fully predictive, general features (features of Cows or Camels) and ground truth labels. The learning of and reliance on these correlations is undesirable because these features may disappear or become correlated with a different label or task during testing, causing these networks to malfunction.

\vspace{0.1in}
\subsection{Why do Deep Neural Networks Learn and Rely on Spurious Correlations?} Deep networks learn and rely on spurious correlations due to a preference for simpler features over those that are more complex in nature~\cite{geirhos2020shortcut,Kirichenko2023ICLR}. \cite{Shah2020Neurips} show that such simplicity bias is extreme in practice. They consider a binary classification task, where every sample of each class contains two sets of features. One of these features is simpler than the other. They show that when a network is trained on this task, the network will fully ignore the more complex feature and rely only on the simpler feature when making predictions. In settings where the simpler feature does not exist in all samples, deep networks learn both sets of features but exhibit strong reliance on the simpler feature~\cite{Kirichenko2023ICLR}. All existing works that study spurious correlations generally assume the same set-up, where spurious features are only partly predictive of the task while general, invariant features exist in every sample within their respective class.

\vspace{0.1in}
\subsection{Mitigating Spurious Correlations: Existing Practice}

Existing solutions that enable a network to mitigate spurious correlations operate under the implicit assumption that a network trained using Empirical Risk Minimization (ERM)~\cite{Vapnik98} will learn and rely on spurious correlations due to a preference for simpler features. Based on this assumption, promising solutions generally fall into the following categories:


\paragraph{Altering the Training Distribution. } The degree to which a trained network relies on spurious correlations depends on various factors. Of these factors, the most extensively studied is the proportion of samples within the train set that contain the spurious feature. The greater the proportion of samples containing the spurious feature, the greater the reliance on spurious correlations. To reduce the proportion of samples containing spurious features, existing works aim to either up-weight samples that do not contain spurious features, down-weight samples that contain spurious features, or remove samples containing spurious features. Most works that attain state-of-the-art results on popular benchmarks rely on the availability of sample-environment membership information.~\cite{Liu2021ICML} up-weight samples that do not contain spurious features while~\cite{Yang2024AISTATS} down-weight samples containing spurious features in conjunction with a similar up-weighting step.~\cite{Kirichenko2023ICLR,Deng2023Neurips} simply balance the number of samples belonging to each environment when proposing mitigation strategies. However, they make use of the assumption that environments that are overrepresented force networks to rely on spurious correlations. Attaining such sample-environment information is expensive due to the need for human intervention and annotation. To overcome this problem, some works aim to infer such sample-wise environment labels.~\cite{Liu2021ICML} train a network with heavy regularization to identify samples with and without spurious features based on whether these samples were correctly classified during training.~\cite{Ahmed2021ICLR} aim to maximize the Invariant Risk Minimization penalty (IRM)~\cite{Arjovsky2019} during training to obtain environment-labels.~\cite{Zhang2022ICML} cluster a biased network's representations to obtain these labels.~\cite{pezeshki2024ICML} attain these labels by utilizing a twin-network setting where networks are encouraged to learn environmental cues, thereby aiding in sample-environment discovery.


\paragraph{Altering a Network's Learned Representations.   } These works either align the representation of samples within a class that contains spurious features and those that do not, or simply block parts of a network's representation that encodes spurious information.~\cite{Ahmed2021ICLR} aim to align the predicted distributions for samples belonging to the same class but different environments using a KL-divergence term in the optimization function.~\cite{Zhang2022ICML} make use of a contrastive loss function which brings representations of samples within the same class but different environments closer while distancing representations of samples belonging to the same environment but different classes.~\cite{gandelsman2024ICLR} identify the role of individual attention heads in CLIP-ViT and remove those heads associated with spurious cues.


\paragraph{Prioritizing Worst-Group Accuracy During Training.  } \cite{sagawa2020ICLR} optimize a network using an objective that minimizes the risk for the group of samples belonging to the environment with the maximum risk within a class.


\paragraph{Fine-tuning on an Unbiased Dataset. } \cite{Kirichenko2023ICLR} re-train the last layer of a trained (biased) network on a dataset where the proportion of samples containing the spurious feature is significantly lower than the original training set.~\cite{moayeri2023Neurips} follow similar retraining, where they fine-tune a trained network on a small dataset with minimal spurious features, where such a set is obtained using human supervision.


\begin{figure*}[t]
\centering     %%% not \center
\includegraphics[width=0.67\linewidth]{figs/R50-O-MTA.pdf}
\caption{Excluding only a handful of training samples with spurious features and hard core features mitigates spurious correlations. This is indicated by high Worst Group Accuracies (Female test samples with glasses.) Excluding up to 97\% of all training samples with spurious features and easy core features shows no improvements in worst group accuracy. This figure is excerpted from~\protect\cite{Mulchandani2025ICLR}.}
%\vspace{-0.3cm}
%\label{fig:Exclusion}
\label{fig:keyplayers}
\end{figure*}


\subsection{Limitations of Existing Techniques}

\paragraph{Heavy Dependence on Sample-Environment Membership Information.}

Promising solutions that overcome spurious correlations hinge on the availability or identifiability of sample-environment membership information. In other words, these solutions work with the assumption that it is possible to determine which groups of samples were drawn from which environments. Additionally, recent works that aim to infer this information are unable to attain competitive performances with techniques that directly use this information.

\paragraph{Assuming Over-Represented Environment Groups as Contributors to Learning of Spurious Correlations.}

All existing studies that aim to overcome spurious correlations work with the assumption that environments/groups that are overrepresented are the groups that contribute to the learning of spurious correlations. Reliance on this assumption makes it easy to identify which samples contain the spurious features causing problems, which allows for further representational alignment or changes to the training distribution.~\cite{Mulchandani2025ICLR} show that this assumption does not always hold in practice and that minority groups can contain spurious features that can mislead a network significantly.

\paragraph{Representational Collapse.}

Works by~\cite{Ahmed2021ICLR,Zhang2022ICML} align representations of samples belonging to different environments within the same class. While effective at overcoming spurious correlations, these techniques reduce overall testing accuracies due to the loss of representational richness.

\paragraph{Extensive Hyperparameter Tuning.}

Most works depend heavily on hyperparameter tuning, where they optimize for the best worst-group accuracy. Optimization is done with the help of a validation split that mimics the distribution of shifted testing environments. Such access to a validation split that mimics test-time distribution is unrealistic.~\cite{gulrajani2021ICLR} show that without access to such a validation set, standard Empirical Risk Minimization outperforms seemingly promising solutions.

\subsection{Creating Robust Solutions: Next Steps}

\paragraph{Moving Past Egalitarian Approaches.}

Most standard and state-of-the-art techniques assume an equal contribution to the learning and reliance of spurious correlations. In other words, every training sample belonging to the environment known to cause reliance on spurious correlations is treated the same way.~\cite{Mulchandani2025ICLR} show that samples within an environment contribute differently to learning of spurious correlations and show that these differences are extreme in practice. They train a network to learn gender classification, where a fraction of the male samples contain eyeglasses. In their work, the degree of spurious feature reliance is measured by observing the test accuracy of female samples containing eyeglasses (Worst-Group Accuracy). They observe that removing 97\% of easy-to-understand male samples with eyeglasses has almost no improvement on the testing accuracy of female samples with eyeglasses. However, removing 10\% of hard-to-understand male samples with eyeglasses doubles the testing accuracy of female samples with eyeglasses, as shown in Fig.~\ref{fig:keyplayers}. They show that such pruning has minimal impact on testing accuracy of the male class.


\paragraph{Overcoming Reliance on Unbiased Validation Sets.}

Access to unbiased, environment-balanced datasets for fine-tuning or environment-based hyperparameter tuning is unrealistic. The results presented in Fig.~\ref{fig:keyplayers} by pruning samples with hard-to-understand male features do not make use of any hyperparameter tuning.

% architecture; data;
% efficiency and bias

\subsection{Intersection of Spurious Correlations with Other Areas of Study}
% \subsubsection{Model Capacity and Spurious Correlations. } {Sagawa} show that increasing the number of parameters of a network increases the degree to which the network relies on spurious correlations.

\paragraph{Reasoning and Spurious Correlations. } Recent work has shown that deep neural networks have a tendency to rely on short-cut solutions or heuristics when learning to solve reasoning tasks, instead of robust rules that actually cover the solution to the problem~\cite{Zhang2023IJCAI,nikankin2025ICLR}. This makes it difficult for networks to generalize to different or more challenging domains. A good example of this is the length generalization problem, where a network is unable to solve simple arithmetic operations on numbers of length different from those observed during training, despite these operations requiring the same set of rules~\cite{Zhou2024ICLR,lee2024ICLR}.

\paragraph{Privacy and Spurious Correlations.   } \cite{yang2022} show that neural networks pick up on spurious features present in only a handful of training samples, which can lead to privacy leaks.
