\documentclass{article}

\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}		% Can be removed after putting your text content
\usepackage{graphicx}
%\usepackage{natbib}
\usepackage{doi}
\usepackage{caption}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{fancyhdr}       % header
\usepackage{graphicx}       % graphics
\usepackage{fancyvrb}        % Enhances verbatim capabilities, which may be used within tcolorbox
\usepackage{pdfpages}
\usepackage{hyperref} 
\usepackage{caption} 

\usepackage{setspace} % Ensure you include this package

\usepackage{soul}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{caption}

\usepackage{multirow}
%\captionsetup{font=tiny}  % Sets the font size for captions to small
\captionsetup[table, figure]{font=scriptsize} % Change "small" to "footnotesize" or "scriptsize" if needed

\usepackage{helvet} % Use Arial font
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows, arrows.meta, positioning,fit,backgrounds, shadows}
\usepackage{enumitem}

\captionsetup{
    labelfont=bf, % Makes "Figure 1:" and "Table 1:" bold
    textfont=small % Keeps the rest of the text normal
}
% Arrow command to draw downwards arrows between boxes
\newcommand{\downarrowbetweenboxes}{
    \vspace{-0.4cm}
    \begin{center}
        \tikz \draw[-{Latex[length=3mm,width=2mm]}, thick] (0,-0) -- (0,-0.5);
    \end{center}
    \vspace{-.5cm}
}
 
\usetikzlibrary{decorations.pathreplacing}


\newcounter{textbox}
\setcounter{textbox}{0}
\renewcommand{\thetextbox}{\arabic{textbox}} % Adjust according to where you reset this

\newcommand{\textboxcaption}[1]{
  \refstepcounter{textbox}
  % Use the figure environment's captioning system but style it manually
  \noindent\small\textbf{Text Box \thetextbox:} #1\par\medskip
  %\noindent Text Box \thetextbox: #1\par\medskip
}


\usepackage{sansmath} % To ensure math is also sans-serif inside flowchart

\tikzstyle{process} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=orange!30]
\tikzstyle{start} = [ellipse, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=yellow!30]
\tikzstyle{decision} = [diamond, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=green!30]
\tikzstyle{arrow} = [thick,->,>=stealth]

\tikzstyle{phase} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=orange!30]
\tikzstyle{result} = [ellipse, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=green!30]

\tikzstyle{dataset} = [rectangle, rounded corners, minimum width=2cm, minimum height=1cm, text centered, draw=black, fill=blue!30]
\tikzstyle{masking} = [rectangle, rounded corners, minimum width=2cm, minimum height=1cm, text centered, draw=black, fill=red!30]

\usepackage[skins,breakable]{tcolorbox}

\definecolor{aigold}{RGB}{244,210, 1} 
\definecolor{aigreen}{RGB}{210,244,211} 
\newcommand{\lightgreen}[1]{\fcolorbox{aigreen}{aigreen}{\parbox{\linewidth}{#1}}}
\sethlcolor{aigreen}

\definecolor{aired}{RGB}{255,180,181} 
\newcommand{\lightred}[1]{\colorbox{aired}{\parbox{\linewidth}{#1}}}

\definecolor{aigold}{RGB}{255,180,181} 
\newcommand{\hlgold}[1]{\colorbox{aired}{\parbox{\linewidth}{#1}}}

\definecolor{aiblue}{RGB}{173,216,230} % Light blue color (you can adjust the RGB values for a different shade)
 
% Define a custom highlighting color
\definecolor{lightred}{rgb}{1,0.9,0.9} % Light red color
% Define the LLMbox environment with minimal style

% Define a command for red highlighting
\newcommand{\hlred}[1]{{%
  \sethlcolor{lightred}% Set the highlight color to light red
  \hl{#1}% Highlight the argument text
}}

% Define a command for red highlighting
\newcommand{\hllightgreen}[1]{{%
  \sethlcolor{aigreen}% Set the highlight color to light red
  \hl{#1}% Highlight the argument text
}}
% Define a command for red highlighting
\newcommand{\hlblue}[1]{{%
  \sethlcolor{aiblue}% Set the highlight color to light red
  \hl{#1}% Highlight the argument text
}}

\tcbset{
  customboxsmalll/.style={
    width=0.95\textwidth,  % 95% of page width
    fonttitle=\ttfamily\scriptsize, % Title font style
    colback=white,  % Box background color
    colframe=black,  % Box border color
    colbacktitle=blue!75!black, % Title background color
    coltitle=white,  % Title text color
    boxrule=0.5pt,  % Border thickness
    rounded corners,  % Rounded corners
    %attach boxed title to top left={yshift=2mm}, % Title attached to top left
    boxed title style={
        colback=blue!75!black, % Title background color
        colframe=black, % Title frame color
        boxrule=0.5pt  % Title border thickness
            before={\setlength{\parskip}{0pt} \setlength{\parindent}{-6pt}},  % Remove paragraph spacing
    after={\setlength{\parskip}{0pt} \setlength{\parindent}{-6pt}},   % Remove paragraph spacing
    halign=center,  % Center alignment
    before skip=-5pt,  % Space before the box
    after skip=-5pt,   % Space after the box
    innertop=-3pt,     % Inner top padding
    innerbottom=-3pt,  % Inner bottom padding
    valign=center,    % Center vertical alignment of content
    }
    
  }
}


\lstset{
  basicstyle=\ttfamily\scriptsize\setstretch{0.1}\selectfont, % Adjust line spacing here
  breaklines=true,
  breakatwhitespace=true,
  breakindent=0pt,
  columns=fullflexible,
  keepspaces=true,
  linewidth=\linewidth,
  xleftmargin=0pt,
  showstringspaces=false,
  escapeinside={(*@}{@*)},
  aboveskip=3pt,
  belowskip=0pt,
}
 
\tcbset{
  custombox/.style={
    width=512.18663pt,
    top=3pt,
    fonttitle=\bfseries\scriptsize\sffamily, % Bold, larger, and sans serif title font
    colback=white,
    colframe=black,
    colbacktitle=black,
    boxrule=0.5pt, % Border thickness
    colback=white, % Background color
    enhanced,
    rounded corners, % Rounded corners
    center,
    boxed title style={
            sharp corners,
            size=small,
            colframe=blue!75!black, % Title frame color
        },
    attach boxed title to top left={yshift=-0.1in,xshift=0.15in},
    boxed title style={boxrule=0pt,colframe=white,},
    before=\setlength{\baselineskip}{2pt}, % Tighter line spacing
    before upper=\setlength{\baselineskip}{2pt}, % Tighter line spacing inside the box
    after=\setlength{\baselineskip}{2pt}, % Tighter line spacing after the box
  }
} 

\newtcolorbox{LLMbox}[2][]{custombox, title=#2,#1}
% Define the LLMbox environment with a title
\newtcolorbox{LLMboxSmall}[2][]{customboxsmalll, title=#2,#1}



% Verbatim coloring with fancyvrb and fvextra
\DefineVerbatimEnvironment{thinkingcolor}{Verbatim}{
  formatcom=\color{blue}, % Set color of the verbatim text
  fontsize=\scriptsize  % Optional: adjust font size if needed
}
% Verbatim coloring with fancyvrb and fvextra
\DefineVerbatimEnvironment{reflectcolor}{Verbatim}{
  formatcom=\color{orange}, % Set color of the verbatim text
  fontsize=\scriptsize  % Optional: adjust font size if needed
}

\renewcommand{\rmdefault}{cmr} % Ensure Computer Modern Roman

\title{\textbf{Agentic Deep Graph Reasoning Yields Self-Organizing Knowledge Networks}
}

%\date{September 9, 1985}	% Here you can change the date presented in the paper title
%\date{} 					% Or removing it

\author{ \href{https://orcid.org/0000-0002-4173-9659}{\includegraphics[scale=0.06]{orcid.pdf}\hspace{1mm}Markus J. Buehler}\thanks{Corresponding author.} \\
	Laboratory for Atomistic and Molecular Mechanics\\Center for Computational Science and Engineering \\
        Schwarzman College of Computing \\
	Massachusetts Institute of Technology\\
	Cambridge, MA 02139, USA \\
        \\
	\texttt{mbuehler@MIT.EDU} \\
	%% examples of more authors
	%\And
	 %...
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
}



\newtcbox{\mybox}[1][green]{on line,
arc=0pt,outer arc=0pt,colback=#1!10!white,colframe=#1!50!black,
boxsep=0pt,left=0pt,right=0pt,top=0pt,bottom=0pt,
boxrule=0pt,bottomrule=0pt,toprule=0pt}


\tcbset{
  customboxmultipage/.style={
    width=512.18663pt,
    top=3pt,
    fonttitle=\ttfamily\scriptsize, % Title font style
    %fonttitle=\bfseries\small\sffamily,
    colback=white,
    breakable,
    colframe=black,
    colbacktitle=black,
    boxrule=0.5pt,
    rounded corners,
    center,
    boxed title style={
        sharp corners,
        size=small,
        colframe=blue!75!black,
    },
    attach boxed title to top left={yshift=-0.1in,xshift=0.15in},
    boxed title style={boxrule=0pt,colframe=white,},
    before={\par\noindent},
    after={\par},
    %before upper={\nointerlineskip},
    before upper={\setstretch{0.3}}, % Adjust line spacing inside the box
    after lower={\nointerlineskip},
    every page on break/.style={
      % Remove bottom and top rules during breaks
      interior style={top color=white, bottom color=white},
    },
  }
}

\newtcolorbox{LLMboxmultipage}[2][]{customboxmultipage,title=#2,#1}


% Uncomment to remove the date
%\date{}

% Uncomment to override  the `A preprint' in the header
\renewcommand{\headeright}{}
%\renewcommand{\undertitle}{Technical Report}
\renewcommand{\shorttitle}{Agentic Deep Graph Reasoning }

%%% Add PDF metadata to help others organize their library
%%% Once the PDF is generated, you can check the metadata with
%%% $ pdfinfo template.pdf
\hypersetup{
pdftitle={%Graph-Aware Isomorphic Attention 
Autonomous Knowledge Gardening at Scale},
pdfsubject={q-bio.NC, q-bio.QM},
pdfauthor={Markus J. Buehler, MIT, mbuehler@MIT.EDU},
pdfkeywords={Language Modeling, Graph Theory, Category Theory, Materials Science, Materiomics, Symbolic Reasoning},
}


\begin{document}
\maketitle

\begin{abstract} 

%We present an agentic, autonomous graph expansion framework that iteratively structures and refines knowledge in situ. Unlike conventional knowledge graph construction methods relying on static extraction or single-pass learning, our approach couples a reasoning-native large language model with a continually updated graph representation. At each step, the system actively generates new concepts and relationships, merges them into a global graph, and formulates subsequent prompts based on its evolving structure. Through this feedback-driven loop, the model organizes information into a scale-free network characterized by hub formation, stable modularity, and bridging nodes that link disparate knowledge clusters. Over hundreds of iterations, new nodes and edges continue to appear without saturating, while centrality measures and shortest path distributions evolve to yield increasingly distributed connectivity.  Applied to materials design problems, we present compositional reasoning experiments to foster knowledge synthesis, yielding cross-domain ideas that transcend rote summarization.   

We present an agentic, autonomous graph expansion framework that iteratively structures and refines knowledge \textit{in situ}. Unlike conventional knowledge graph construction methods relying on static extraction or single-pass learning, our approach couples a reasoning-native large language model with a continually updated graph representation. At each step, the system actively generates new concepts and relationships, merges them into a global graph, and formulates subsequent prompts based on its evolving structure. Through this feedback-driven loop, the model organizes information into a scale-free network characterized by hub formation, stable modularity, and bridging nodes that link disparate knowledge clusters. Over hundreds of iterations, new nodes and edges continue to appear without saturating, while centrality measures and shortest path distributions evolve to yield increasingly distributed connectivity. Our analysis reveals emergent patterns—such as the rise of highly connected ``hub'' concepts and the shifting influence of ``bridge'' nodes—indicating that agentic, self-reinforcing graph construction can yield open-ended, coherent knowledge structures. Applied to materials design problems, we present compositional reasoning experiments by extracting node-specific and synergy-level principles to foster genuinely novel knowledge synthesis, yielding cross-domain ideas that transcend rote summarization and strengthen the framework’s potential for open-ended scientific discovery. We discuss other applications in scientific discovery and outline future directions for enhancing scalability and interpretability.
\end{abstract}


% keywords can be removed
\keywords{Artificial Intelligence \and Science \and Graph Theory \and Category Theory \and Materials Science \and Materiomics \and Language Modeling \and Reasoning \and Isomorphisms \and Engineering}




\section{Introduction}

Scientific inquiry often proceeds through an interplay of incremental refinement and transformative leaps, evoking broader questions of how knowledge evolves under continual reflection and questioning. In many accounts of discovery, sustained progress arises not from isolated insights but from an iterative process in which prior conclusions are revisited, expressed as generalizable ideas, refined, or even reorganized as new evidence and perspectives emerge~\cite{kuhn1962structure}. Foundational work in category theory has formalized aspects of this recursive structuring, showing how hierarchical representations can unify diverse knowledge domains and enable higher-level abstractions in both the natural and social sciences \cite{Spivak2011CategoryNetworks,Giesa2011ReoccurringAnalogies,Giesa2012CategoryDesign}. Across engineering disciplines including materials science, such iterative integration of information has proven essential in synthesizing deeply interlinked concepts. 

Recent AI methods, however, often emphasize predictive accuracy and single-step outputs over the layered, self-reflective processes that characterize human problem-solving. Impressive gains in natural language processing, multimodal reasoning \cite{Vaswani2017AttentionNeed,AlecRadfordImprovingPre-Training,Xue2021ByT5:Models,Jiang2023Mistral7Bb,Phi-2:Research,dubey2024llama3herdmodels,Brown2020LanguageLearners,salinas2025exoplanettransitcandidateidentification}, and materials science \cite{Schmidt2019MLMaterials,Buehler2024X-LoRA:Design,Arevalo2023LearningMaterials,Hu2023DeepScience,D1MH00495F}, including breakthroughs in molecular biology \cite{Vamathevan2019ApplicationsDevelopment} and protein folding \cite{Jumper2021HighlyAlphaFold,ProteinTrRosetta,Wu2022High-resolutionSequencelocal}, showcase the prowess of large-scale models trained on vast datasets. Yet most of the early systems generate answers in a single pass, sidestepping the symbolic, stepwise reasoning that often underpins scientific exploration. This gap has prompted a line of research into modeling that explicitly incorporates relational modeling, reflection or multi-step inferences \cite{Spivak2011CategoryNetworks,Giesa2011ReoccurringAnalogies,Giesa2012CategoryDesign,abbott2024flashattentionnapkindiagrammaticapproach,Buehler2025GraphAwareGPT,Miconi2025,o1-model-card-2024,buehler2024preflexorpreferencebasedrecursivelanguage,buehler2025insitugraphreasoningknowledge,reddy2024towards}, hinting at a transition from single-shot pattern recognition to more adaptive synthesis of answers from first principles in ways that more closely resemble compositional mechanisms. Thus, a fundamental challenge now is how can we build scientific AI systems that synthesize information rather than memorizing it. 

Graphs offer a natural substrate for this kind of iterative knowledge building. By representing concepts and their relationships as a network, it becomes possible to capture higher-order structure—such as hubs, bridging nodes, or densely interconnected communities—that might otherwise remain implicit. This explicit relational format also facilitates systematic expansion: each newly added node or edge can be linked back to existing concepts, reshaping the network and enabling new paths of inference~\cite{BuehlerGraphReasoning2024,Buehler2025GraphAwareGPT,buehler2025insitugraphreasoningknowledge}. Moreover, graph-based abstractions can help large language models move beyond memorizing discrete facts; as nodes accumulate and form clusters, emergent properties may reveal cross-domain synergies or overlooked gaps in the knowledge space.

Recent work suggests that standard Transformer architectures can be viewed as a form of Graph Isomorphism Network (GIN), where attention operates over relational structures rather than raw token sequences~\cite{Buehler2025GraphAwareGPT}. Under this lens, each attention head effectively tests for isomorphisms in local neighborhoods of the graph, offering a principled way to capture both global and local dependencies. A category-theoretic perspective further bolsters this approach by providing a unified framework for compositional abstractions: nodes and edges can be treated as objects and morphisms, respectively, while higher-level concepts emerge from functorial mappings that preserve relational structure \cite{Spivak2011CategoryNetworks,Giesa2011ReoccurringAnalogies,Giesa2012CategoryDesign}. Taken together, these insights hint at the potential for compositional capabilities in AI systems, where simpler building blocks can be combined and reconfigured to form increasingly sophisticated representations, rather than relying on one-pass computations or static ontologies. By using graph-native modeling and viewing nodes and edges as composable abstractions, such a model may be able to recognize and reapply learned configurations in new contexts—akin to rearranging building blocks to form unanticipated solutions. This compositional approach, strengthened by category-theoretic insights, allows the system to not only interpolate among known scenarios but to extrapolate to genuinely novel configurations. In effect, graph-native attention mechanisms treat interconnected concepts as first-class entities, enabling the discovery of new behaviors or interactions that purely sequence-based methods might otherwise overlook.


A fundamental challenge remains: How can we design AI systems that, rather than merely retrieving or matching existing patterns, build and refine their own knowledge structures across iterations. Recent work proposes that graphs can be useful strategies to endow AI models with relational capabilities\cite{BuehlerGraphReasoning2024,Buehler2025GraphAwareGPT,buehler2025insitugraphreasoningknowledge} both within the framework of creating graph-native attention mechanisms and by training models to use graphs as native abstractions during learned reasoning phases. Addressing this challenge requires not only methods for extracting concepts but also mechanisms for dynamically organizing them so that new information reshapes what is already known. By endowing large language models with recursively expanding knowledge graph capabilities, we aim to show how stepwise reasoning can support open-ended discovery and conceptual reorganization. The work presented here explores how such feedback-driven graph construction may lead to emergent, self-organizing behaviors, shedding light on the potential for truly iterative AI approaches that align more closely with the evolving, integrative nature of human scientific inquiry. Earlier work on graph-native reasoning has demonstrated that models explicitly taught how to reason in graphs and abstractions can lead to systems that generalize better and are more interpretable~\cite{buehler2025insitugraphreasoningknowledge}. 

Here we explore whether we can push this approach toward ever-larger graphs, creating extensive \textit{in situ} graph reasoning loops where models spend hours or days developing complex relational structures before responding to a task. Within such a vision, several key issues arise: Will repeated expansions naturally preserve the network’s relational cohesion, or risk splintering into disconnected clusters? Does the continuous addition of new concepts and edges maintain meaningful structure, or lead to saturation and redundancy? And to what extent do bridging nodes, which may initially spark interdisciplinary links, remain influential over hundreds of iterations? In the sections ahead, we investigate these questions by analyzing how our recursively expanded knowledge graphs grow and reorganize at scale—quantifying hub formation, modular stability, and the persistence of cross-domain connectors. Our findings suggest that, rather than collapsing under its own complexity, the system retains coherent, open-ended development, pointing to new possibilities for large-scale knowledge formation in AI-driven research for scientific exploration.

\begin{figure}
\centering


\sffamily% Switch to sans-serif font
\scriptsize

%\sansmath % Ensure math in flowchart is also sans-serif

\begin{tikzpicture}[
    node distance=0.6cm and 1cm, auto,
    task/.style={rectangle, draw, fill=blue!20, text width=5cm, text centered, rounded corners, minimum height=1.2cm},
    generation/.style={rectangle, draw, fill=cyan!30, text width=5cm, text centered, rounded corners, minimum height=1.2cm},
    extraction/.style={rectangle, draw, fill=violet!40, text width=5cm, text centered, rounded corners, minimum height=1.2cm},
    merge_graph/.style={rectangle, draw, fill=violet!20, text width=5cm, text centered, rounded corners, minimum height=1.5cm},
    question/.style={rectangle, draw, fill=green!20, text width=5cm, text centered, rounded corners, minimum height=1.5cm},
    visualization/.style={rectangle, draw, fill=yellow!30, text width=5cm, text centered, rounded corners, minimum height=1.2cm},
    final_output/.style={rectangle, draw, fill=orange!30, text width=5cm, text centered, rounded corners, minimum height=1.2cm},
    line/.style={draw, -stealth', shorten >=1pt},
    dashed line/.style={draw, dashed, shorten >=1pt}]

    % Define nodes
    \node [task] (start) {\textbf{Define Initial Question} \\ (Broad question or specific topic, e.g., "Impact-Resistant Materials")};
    \node [generation, below=of start] (generate) {\textbf{Generate Graph-native \\ Reasoning Tokens} \\ \texttt{<|thinking|> ... <|/thinking|>}};
    \node [extraction, below=of generate] (extract_graph) {\textbf{Parse Graph} \( \mathcal{G}_{\text{local}}^i \) \\ (Extract Nodes and Relations)};
    \node [merge_graph, below=of extract_graph] (merge_graph) {\textbf{Merge Extracted Graph with \\ Larger Graph} \\ (Append Newly Added Nodes/Edges) \\  $\mathcal{G} \leftarrow \mathcal{G} \cup \mathcal{G}_{\text{local}}^i$};
    \node [visualization, below=of merge_graph] (save_graph) {\textbf{Save and Visualize}} ;
    \node [final_output, below=of save_graph] (final_result) {\textbf{Final Integrated Graph} $\mathcal{G}$} ;

    % Sequential Flow
    \path [line] (start) -- (generate);
    \path [line] (generate) -- (extract_graph);
    \path [line] (extract_graph) -- (merge_graph);
    \path [line] (merge_graph) -- (save_graph);
    \path [line] (save_graph) -- (final_result);

    % Generate new questions
    \node [question, right=of extract_graph, xshift=3cm] (new_question) {\textbf{Generate New Question} \\ 
    Based on Last Extracted Added Nodes/Edges as captured in $\mathcal{G}_{\text{local}}^i$ };
    \path [line] (merge_graph.east) -| (new_question.south);
    \path [line] (new_question.north) |- (generate.east);

    % Iterative Learning Box
    \begin{pgfonlayer}{background}
        \node [draw=orange, thick, dashed, fit=(generate) (extract_graph) (merge_graph) (save_graph) (new_question), 
               inner sep=0.4cm, label={[text=orange]above: \textbf{Iterative Reasoning} $i<N$}] (iteration_box) {};
    \end{pgfonlayer}

\end{tikzpicture}
%\sansmath % Ensure math in flowchart is also sans-serif

\rmfamily
%\sffamily % Restore default font
\caption{Algorithm used for iterative knowledge extraction and graph refinement. 
At each iteration \( i \), the model generates reasoning tokens (blue). 
From the response, a local graph \( \mathcal{G}_{\text{local}}^i \) is extracted (violet) and merged with the global knowledge graph \( \mathcal{G} \) (light violet). 
The evolving graph is stored in multiple formats for visualization and analysis (yellow). 
Instead of letting the model respond to the task, a follow-up task is generated based on the latest extracted nodes and edges in \( \mathcal{G}_{\text{local}}^i \) (green), ensuring iterative refinement (orange), so that the model generates yet more reasoning tokens, and as part of that process, new nodes and edges. 
The process continues until the stopping condition \( i < N \) is met, yielding a final structured knowledge graph \( \mathcal{G} \) (orange).}
\label{fig:fig_01}
\end{figure}
 


%%%%%%%%%%%%%%%%


\subsection{Knowledge Graph Expansion Approaches}
Knowledge graphs are one way to organize relational understanding of the world. They have grown from manually curated ontologies decades ago into massive automatically constructed repositories of facts. A variety of methodologies have been developed for expanding knowledge graphs. Early approaches focused on information extraction from text using pattern-based or open-domain extractors. For example, the DIPRE algorithm \cite{brin1998dipre} bootstrapped relational patterns from a few seed examples to extract new facts in a self-reinforcing loop. Similarly, the KnowItAll system \cite{etzioni2004knowitall} introduced an open-ended, autonomous ``generate-and-test'' paradigm to extract entity facts from the web with minimal supervision. Open Information Extraction methods like TextRunner \cite{banko2007openIE} and ReVerb \cite{etzioni2011reverb} further enabled unsupervised extraction of subject–predicate–object triples from large text corpora without requiring a predefined schema. These unsupervised techniques expanded knowledge graphs by harvesting new entities and relations from unstructured data, although they often required subsequent mapping of raw extractions to a coherent ontology.

In parallel, research on knowledge graph completion has aimed to expand graphs by inferring missing links and attributes. Statistical relational learning and embedding-based models (e.g., translational embeddings like TransE \cite{bordes2013translating}) predict new relationships by generalizing from known graph structures. Such approaches, while not fully unsupervised (they rely on an existing core of facts for training), can autonomously suggest plausible new edges to add to a knowledge graph. Complementary to embeddings, logical rule-mining systems such as AMIE \cite{galarraga2013amie} showed that high-confidence Horn rules can be extracted from an existing knowledge base and applied to infer new facts recursively. Traditional link prediction heuristics from network science – for example, preferential attachment and other graph connectivity measures – have also been used as simple unsupervised methods to propose new connections in knowledge networks. Together, these techniques form a broad toolkit for knowledge graph expansion, combining text-derived new content with graph-internal inference to improve a graph’s coverage and completeness.

\subsection{Recursive and Autonomous Expansion Techniques}
\label{sec:rec_review}

A notable line of work seeks to make knowledge graphs growth continuous and self-sustaining – essentially achieving never-ending expansion. The NELL project (Never-Ending Language Learner) \cite{carlson2010nell} pioneered this paradigm, with a system that runs 24/7, iteratively extracting new beliefs from the web, integrating them into its knowledge base, and retraining itself to improve extraction competence each day. Over years of operation, NELL has autonomously accumulated millions of facts by coupling multiple learners (for parsing, classification, relation extraction, etc.) in a semi-supervised bootstrapping loop. This recursive approach uses the knowledge learned so far to guide future extractions, gradually expanding coverage while self-correcting errors; notably, NELL can even propose extensions to its ontology as new concepts emerge.

Another milestone in autonomous knowledge graph construction was Knowledge Vault~\cite{dong2014knowledgevault}, which demonstrated web-scale automatic knowledge base population by fusing facts from diverse extractors with probabilistic inference. Knowledge Vault combined extractions from text, tables, page structure, and human annotations with prior knowledge from existing knowledge graphs, yielding a vast collection of candidate facts (on the order of 300 million) each accompanied by a calibrated probability of correctness. This approach showed that an ensemble of extractors, coupled with statistical fusion, can populate a knowledge graph at scales far beyond what manual curation or single-source extraction can achieve. Both NELL and Knowledge Vault illustrate the power of autonomous or weakly-supervised systems that grow a knowledge graph with minimal human intervention, using recursive learning and data fusion to continually expand and refine the knowledge repository.

More recent research has explored agent-based and reinforcement learning (RL) frameworks for knowledge graph expansion and reasoning. Instead of one-shot predictions, these methods allow an agent to make multi-hop queries or sequential decisions to discover new facts or paths in the graph. For example, some work~\cite{xiong2017deeppath} employ an agent that learns to navigate a knowledge graph and find multi-step relational paths, effectively learning to reason over the graph to answer queries. Such techniques highlight the potential of autonomous reasoning agents that expand knowledge by exploring connections in a guided manner (using a reward signal for finding correct or novel information). This idea of exploratory graph expansion aligns with concepts in network science, where traversing a network can reveal undiscovered links or communities. It also foreshadowed approaches like Graph-PReFLexOR~\cite{buehler2025insitugraphreasoningknowledge} that treat reasoning as a sequential decision process, marked by special tokens, that can iteratively build and refine a task-specific knowledge graph.

% \subsection{Applications in Science and Engineering}
Applications of these expansion techniques in science and engineering domains underscore their value for discovery~\cite{BuehlerGraphReasoning2024}. Automatically constructed knowledge graphs have been used to integrate and navigate scientific literature, enabling hypothesis generation by linking disparate findings. A classic example is Swanson’s manual discovery of a connection between dietary fish oil and Raynaud’s disease, which emerged by linking two disjoint bodies of literature through intermediate concepts \cite{swanson1986undiscovered,Cameron2013GraphSwanson}. Modern approaches attempt to replicate such cross-domain discovery in an automated way: for instance, mining biomedical literature to propose new drug–disease links, or building materials science knowledge graphs that connect material properties, processes, and applications to suggest novel materials, engineering concepts, or designs~\cite{nickel2016review,BuehlerGraphReasoning2024}.



\subsection{Relation to Earlier Work and Key Hypothesis}
\label{sec:rel_work}

The prior work discussed in Section~\ref{sec:rec_review} provides a foundation for our approach, which draws on the never-ending learning spirit of NELL~\cite{carlson2010nell} and the web-scale automation of Knowledge Vault~\cite{dong2014knowledgevault} to dynamically grow a knowledge graph \textit{in situ} as it reasons. Like those systems, it integrates information from diverse sources and uses iterative self-improvement. However, rather than relying on passive extraction or purely probabilistic link prediction, our method pairs on-the-fly logical reasoning with graph expansion within the construct of a graph-native reasoning LLM. This means each newly added node or edge is both informed by and used for the model’s next step of reasoning. Inspired in part by category theory and hierarchical inference, we move beyond static curation by introducing a principled, recursive reasoning loop that helps maintain transparency in how the knowledge graph evolves. In this sense, the work can be seen as a synthesis of existing ideas—continuous learning, flexible extraction, and structured reasoning—geared toward autonomous problem-solving in scientific domains.

Despite substantial progress in knowledge graph expansion, many existing methods still depend on predefined ontologies, extensive post-processing, or reinforce only a fixed set of relations. NELL and Knowledge Vault, for instance, demonstrated how large-scale extraction and integration of facts can be automated, but they rely on established schemas or require manual oversight to refine extracted knowledge~\cite{carlson2010nell,dong2014knowledgevault}. Reinforcement learning approaches such as DeepPath~\cite{xiong2017deeppath} can efficiently navigate existing graphs but do not grow them by generating new concepts or hypotheses.

By contrast, the work reported here treats reasoning as an active, recursive process that expands a knowledge graph while simultaneously refining its structure. This aligns with scientific and biological discovery processes, where knowledge is not just passively accumulated but also reorganized in light of new insights. Another key distinction is the integration of preference-based objectives, enabling more explicit interpretability of each expansion step. Methods like TransE~\cite{bordes2013translating} excel at capturing statistical regularities but lack an internal record of reasoning paths; our approach, in contrast, tracks and justifies each newly added node or relation. This design allows for a transparent, evolving representation that is readily applied to interdisciplinary exploration—such as in biomedicine~\cite{swanson1986undiscovered} and materials science~\cite{nickel2016review}—without depending on rigid taxonomies.

Hence, this work goes beyond conventional graph expansion by embedding recursive reasoning directly into the construction process, bridging the gap between passive knowledge extraction and active discovery. As we show in subsequent sections, this self-expanding paradigm yields scale-free knowledge graphs in which emergent hubs and bridge nodes enable continuous reorganization, allowing the system to evolve its understanding without exhaustive supervision and paving the way for scalable hypothesis generation and autonomous reasoning.

\paragraph{Hypothesis.} We hypothesize that recursive graph expansion enables self-organizing knowledge formation, allowing intelligence-like behavior to emerge without predefined ontologies, external supervision, or centralized control. Using a pre-trained model, Graph-PReFLexOR (an autonomous graph-reasoning model trained on a corpus of biological and biologically inspired materials principles) we demonstrate that knowledge graphs can continuously expand in a structured yet open-ended manner, forming scale-free networks with emergent conceptual hubs and interdisciplinary bridge nodes. Our findings suggest that intelligence-like reasoning can arise from recursive self-organization, challenging conventional paradigms and advancing possibilities for autonomous scientific discovery and scalable epistemic reasoning.

%%%%%%%%%%%%%%%%%

\section{Results and Discussion}


We present the results of experiments in which the graph-native reasoning model engages in a continuous, recursive process of graph-based reasoning, expanding its knowledge graph representation autonomously over 1,000 iterations. Unlike prior approaches that rely on a small number of just a few recursive reasoning steps, the experiments reported in this paper explore how knowledge formation unfolds in an open-ended manner, generating a dynamically evolving graph. As the system iterates, it formulates new tasks, refines reasoning pathways, and integrates emerging concepts, progressively structuring its own knowledge representation following the simple algorithmic paradigm delineated in Figure~\ref{fig:fig_01}. The resulting graphs from all iterations form a final integrated knowledge graph, which we analyze for structural and conceptual insights. Figure~\ref{fig:fig_2000} depicts the final state of the graph, referred to as graph $\mathcal{G}_1$, after the full reasoning process. 

The recursive graph reasoning process can be conducted in either an open-ended setting or develoepd into a more tailored manner to address a specific domain or flavor in which reasoning steps are carried out (details, see Materials and Methods). In the example explored here, we focus on designing impact-resistant materials. In this specialized scenario, we initiate the model with a concise, topic-specific prompt -- e.g., \texttt{Describe a way to design impact resistant materials}, and maintain the iterative process of extracting structured knowledge from the model’s reasoning. We refer to the resulting graph as $\mathcal{G}_2$. Despite the narrower focus, the same core principles apply: each new piece of information from the language model is parsed into nodes and edges, appended to a global graph, and informs the next iteration’s query. In this way, $\mathcal{G}_2$ captures a highly directed and domain-specific knowledge space while still exhibiting many of the emergent structural traits—such as hub formation, stable modularity, and growing connectivity—previously seen in the more general graph $\mathcal{G}_1$. Figure~\ref{fig:fig_2001} shows the final snapshot for $\mathcal{G}_2$. To further examine the emergent structural organization of both graphs, Figures~\ref{fig:fig_2000_C} and \ref{fig:fig_2001_C} display the same graphs with nodes and edges colored according to cluster identification, revealing the conceptual groupings that emerge during recursive knowledge expansion. 
 
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{fig_2000.pdf}
    \caption{Knowledge graph  $\mathcal{G_1}$ after around 1,000 iterations, under a flexible self-exploration scheme initiated with the prompt \texttt{Discuss an interesting idea in bio-inspired materials science.} We observe the formation of a highly connected graph with multiple hubs and centers. }
    \label{fig:fig_2000}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{fig_2001.pdf}
    \caption{Visualizatrion of the knowledge graph \textbf{Graph 2} after around 500 iterations, under a topic-specific self-exploration scheme initiated with the prompt \texttt{Describe a way to design impact resistant materials.} The graph structure features a complex interwoven but highly connected network with multiple centers.}
    \label{fig:fig_2001}
\end{figure}
 
Table~\ref{tab:graph_comparison} shows a comparison of network properties for two graphs (graph $\mathcal{G_1}$, see Figure~\ref{fig:fig_2000} and graph $\mathcal{G_2}$, see Figure~\ref{fig:fig_2001}), each computed at the end of their iterations.  The scale-free nature of each graph is determined by fitting the degree distribution to a power-law model using the maximum likelihood estimation method. The analysis involves estimating the power-law exponent (\(\alpha\)) and the lower bound (\(x_{\min}\)), followed by a statistical comparison against an alternative exponential distribution. A log-likelihood ratio (LR) greater than zero and a $p$-value below 0.05 indicate that the power-law distribution better explains the degree distribution than an exponential fit, suggesting that the network exhibits scale-free behavior. In both graphs, these criteria are met, supporting a scale-free classification.
%
We observe that $\mathcal{G_1}$ has a power-law exponent of \(\alpha = 3.0055\), whereas $\mathcal{G_2}$ has a lower \(\alpha = 2.6455\), indicating that Graph 2 has a heavier-tailed degree distribution with a greater presence of high-degree nodes (hubs). The lower bound \(x_{\min}\) is smaller in $\mathcal{G_2}$  (\(x_{\min} = 10.0\)) compared to $\mathcal{G_1}$ (\(x_{\min} = 24.0\)), suggesting that the power-law regime starts at a lower degree value, reinforcing its stronger scale-free characteristics.

Other structural properties provide additional insights into the connectivity and organization of these graphs. The average clustering coefficients (0.1363 and 0.1434) indicate moderate levels of local connectivity, with $\mathcal{G_2}$ exhibiting slightly higher clustering. The average shortest path lengths (5.1596 and 4.8984) and diameters (17 and 13) suggest that both graphs maintain small-world characteristics, where any node can be reached within a relatively short number of steps. The modularity values (0.6970 and 0.6932) indicate strong community structures in both graphs, implying the presence of well-defined clusters of interconnected nodes. These findings collectively suggest that both graphs exhibit small-world and scale-free properties, with $\mathcal{G_2}$ demonstrating a stronger tendency towards scale-free behavior due to its lower exponent and smaller \(x_{\min}\).

Beyond scale-free characteristics, we note that the two graphs exhibit differences in structural properties that influence their connectivity and community organization. We find that $\mathcal{G_1}$, with 3,835 nodes and 11,910 edges, is much larger and more densely connected than $\mathcal{G_2}$, which has 2,180 nodes and 6,290 edges. However, both graphs have similar average degrees (6.2112 and 5.7706), suggesting comparable overall connectivity per node. The number of self-loops is slightly higher in Graph 1 (70 vs. 33), though this does not significantly impact global structure. The clustering coefficients (0.1363 and 0.1434) indicate moderate levels of local connectivity, with Graph 2 exhibiting slightly more pronounced local clustering. The small-world nature of both graphs is evident from their average shortest path lengths (5.1596 and 4.8984) and diameters (17 and 13), implying efficient information flow. Modularity values (0.6970 and 0.6932) suggest both graphs have well-defined community structures, with Graph 1 showing marginally stronger modularity, possibly due to its larger size. Overall, while both graphs display small-world and scale-free properties, $\mathcal{G_2}$ appears to have a more cohesive structure with shorter paths and higher clustering, whereas $\mathcal{G_1}$ is larger with a slightly stronger community division.

\begin{table}[h!]
\centering
\begin{tabular}{|l|p{3cm}|p{3cm}|}
\hline
\textbf{Metric} & \textbf{Graph} $\mathcal{G_1}$ & \textbf{Graph}  $\mathcal{G_2}$ \\ \hline
Number of nodes & 3835 & 2180 \\ \hline
Number of edges & 11910 & 6290 \\ \hline
Average degree & 6.2112 & 5.7706 \\ \hline
Number of self-loops & 70 & 33 \\ \hline
Average clustering coefficient & 0.1363 & 0.1434 \\ \hline
Average shortest path length (LCC) & 5.1596 & 4.8984 \\ \hline
Diameter (LCC) & 17 & 13 \\ \hline
Modularity (Louvain) & 0.6970 & 0.6932 \\ \hline
Log-likelihood ratio (LR) & 15.6952 & 39.6937 \\ \hline
p-value & 0.0250 & 0.0118 \\ \hline
Power-law exponent (\(\alpha\)) & 3.0055 & 2.6455 \\ \hline
Lower bound (\(x_{\min}\)) & 24.0 & 10.0 \\ \hline
Scale-free classification & Yes & Yes \\ \hline
\end{tabular}
\caption{Comparison of network properties for two graphs (graph $\mathcal{G_1}$, see Figure~\ref{fig:fig_2000} and \ref{fig:fig_2000_C} and graph $\mathcal{G_2}$, see Figure~\ref{fig:fig_2001} and \ref{fig:fig_2001_C}), each computed at the end of their iterations. Both graphs exhibit scale-free characteristics, as indicated by the statistically significant preference for a power-law degree distribution over an exponential fit (log-likelihood ratio \(LR > 0\) and \(p < 0.05\)). The power-law exponent (\(\alpha\)) for $\mathcal{G_1}$ is 3.0055, while $\mathcal{G_2}$ has a lower exponent of 2.6455, suggesting a heavier-tailed degree distribution. The clustering coefficients (0.1363 and 0.1434) indicate the presence of local connectivity, while the shortest path lengths (5.1596 and 4.8984) and diameters (17 and 13) suggest efficient global reachability. The high modularity values (0.6970 and 0.6932) indicate strong community structure in both graphs. Overall, both networks exhibit hallmark properties of scale-free networks, with $\mathcal{G_2}$ showing a more pronounced scale-free behavior due to its lower \(\alpha\) and lower \(x_{\min}\).}
\label{tab:graph_comparison}
\end{table}

\subsection{Basic Analysis of Recursive Graph Growth}
We now move on to a detailed analysis of the evolution of the graph as the reasoning process unfolds over thinking iterations. This sheds light into how the iterative process dynamically changes the nature of the graph. The analysis is largely focused on $\mathcal{G_1}$, albeit a few key results are also included for  $\mathcal{G_2}$. Detailed methods about how the various quantities are computed are included in Materials and Methods. 


Figure~\ref{fig:graph_analysis} illustrates the evolution of key structural properties of the recursively generated knowledge graph. The number of nodes and edges both exhibit linear growth with iterations, indicating that the reasoning process systematically expands the graph without saturation. The increase in edges is slightly steeper than that of nodes, suggesting that each new concept introduced is integrated into an increasingly dense network of relationships rather than remaining isolated. This continuous expansion supports the hypothesis that the model enables open-ended knowledge discovery through recursive self-organization.

The average degree of the graph steadily increases, stabilizing around six edges per node. This trend signifies that the knowledge graph maintains a balance between exploration and connectivity, ensuring that newly introduced concepts remain well-integrated within the broader structure. Simultaneously, the maximum degree follows a non-linear trajectory, demonstrating that certain nodes become significantly more connected over time. This emergent hub formation is characteristic of scale-free networks and aligns with patterns observed in human knowledge organization, where certain concepts act as central abstractions that facilitate higher-order reasoning.

The size of the largest connected component (LCC) grows proportionally with the total number of nodes, reinforcing the observation that the graph remains a unified, traversable structure rather than fragmenting into disconnected subgraphs. This property is crucial for recursive reasoning, as it ensures that the system retains coherence while expanding. The average clustering coefficient initially fluctuates but stabilizes around 0.16, indicating that while localized connections are formed, the graph does not devolve into tightly clustered sub-networks. Instead, it maintains a relatively open structure that enables adaptive reasoning pathways.

These findings highlight the self-organizing nature of the recursive reasoning process, wherein hierarchical knowledge formation emerges without the need for predefined ontologies or supervised corrections. The presence of conceptual hubs, increasing relational connectivity, and sustained network coherence suggest that the model autonomously structures knowledge in a manner that mirrors epistemic intelligence. This emergent organization enables the system to navigate complex knowledge spaces efficiently, reinforcing the premise that intelligence-like behavior can arise through recursive, feedback-driven information processing. Further analysis of degree distribution and centrality metrics would provide deeper insights into the exact nature of this evolving graph topology.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\textwidth]{fig_400.pdf}
    \caption{Evolution of basic graph properties over recursive iterations, highlighting the emergence of hierarchical structure, hub formation, and adaptive connectivity, for $\mathcal{G_1}$.}
    \label{fig:graph_analysis}
\end{figure}


Figure~\ref{fig:graph_analysis_V7} illustrates the same analysis of the evolution of key structural properties of the recursively generated knowledge graph for graph $\mathcal{G_2}$, as a comparison.
 


\textbf{Structural Evolution of the Recursive Knowledge Graph}

Figure~\ref{fig:graph_modularity} presents the evolution of three key structural properties, including Louvain modularity, average shortest path length, and graph diameter, over iterations. These metrics provide deeper insights into the self-organizing behavior of the graph as it expands through iterative reasoning. 
The Louvain modularity, depicted in Figure~\ref{fig:graph_modularity}(a), measures the strength of community structure within the graph. Initially, modularity increases sharply, reaching a peak around 0.75 within the first few iterations. This indicates that the early phases of reasoning lead to the rapid formation of well-defined conceptual clusters. As the graph expands, modularity stabilizes at approximately 0.70, suggesting that the system maintains distinct knowledge domains while allowing new interconnections to form. This behavior implies that the model preserves structural coherence, ensuring that the recursive expansion does not collapse existing conceptual groupings.

The evolution of the average shortest path length (SPL), shown in Figure~\ref{fig:graph_modularity}(b), provides further evidence of structured self-organization. Initially, the SPL increases sharply before stabilizing around 4.5–5.0. The initial rise reflects the introduction of new nodes that temporarily extend shortest paths before they are effectively integrated into the existing structure. The subsequent stabilization suggests that the recursive process maintains an efficient knowledge representation, ensuring that information remains accessible despite continuous expansion. This property is crucial for reasoning, as it implies that the system does not suffer from runaway growth in path lengths, preserving navigability.

The graph diameter, illustrated in Figure~\ref{fig:graph_modularity}(c), exhibits a stepwise increase, eventually stabilizing around 16–18. The staircase-like behavior suggests that the recursive expansion occurs in structured phases, where certain iterations introduce concepts that temporarily extend the longest shortest path before subsequent refinements integrate them more effectively. This bounded expansion indicates that the system autonomously regulates its hierarchical growth, maintaining a balance between depth and connectivity.

These findings reveal several emergent properties of the recursive reasoning model. The stabilization of modularity demonstrates the ability to autonomously maintain structured conceptual groupings, resembling human-like hierarchical knowledge formation. The controlled growth of the shortest path length highlights the system’s capacity for efficient information propagation, preventing fragmentation. We note that the bounded expansion of graph diameter suggests that reasoning-driven recursive self-organization is capable of structuring knowledge in a way that mirrors epistemic intelligence, reinforcing the hypothesis that certain forms of intelligent-like behavior can emerge without predefined ontologies.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\textwidth]{fig_401.pdf}
    \caption{Evolution of key structural properties in the recursively generated knowledge graph $\mathcal{G_1}$: (a) Louvain modularity, showing stable community formation; (b) average shortest path length, highlighting efficient information propagation; and (c) graph diameter, demonstrating bounded hierarchical expansion.}
    \label{fig:graph_modularity}
\end{figure}

For comparison, Figure~\ref{fig:graph_modularity_V7} presents the evolution of three key structural properties—Louvain modularity, average shortest path length, and graph diameter—over recursive iterations for graph $\mathcal{G_2}$.





\subsection{Analysis of Advanced Graph Evolution Metrics}

Figure~\ref{fig:advanced_graph_analysis} presents the evolution of six advanced structural metrics over recursive iterations, capturing higher-order properties of the self-expanding knowledge graph. These measures provide insights into network organization, resilience, and connectivity patterns emerging during recursive reasoning.

Degree assortativity coefficient is a measure of the tendency of nodes to connect to others with similar degrees. A negative value indicates disassortativity (high-degree nodes connect to low-degree nodes), while a positive value suggests assortativity (nodes prefer connections to similarly connected nodes). The degree assortativity coefficient (Figure~\ref{fig:advanced_graph_analysis}(a)) begins with a strongly negative value near \(-0.25\), indicating a disassortative structure where high-degree nodes preferentially connect to low-degree nodes. Over time, assortativity increases and stabilizes around \(-0.05\), suggesting a gradual shift toward a more balanced connectivity structure without fully transitioning to an assortative regime. This trend is consistent with the emergence of hub-like structures, characteristic of scale-free networks, where a few nodes accumulate a disproportionately high number of connections.

The global transitivity (Figure~\ref{fig:advanced_graph_analysis}(b)), measuring the fraction of closed triplets in the network, exhibits an initial peak near 0.35 before rapidly declining and stabilizing towards 0.10, albeit still decreasing. This suggests that early in the recursive reasoning process, the graph forms tightly clustered regions, likely due to localized conceptual groupings. As iterations progress, interconnections between distant parts of the graph increase, reducing local clustering and favoring long-range connectivity, a hallmark of expanding knowledge networks.

The $k$-core Index defines the largest integer $k$ for which a subgraph exists where all nodes have at least 
$k$ connections. A higher maximum $k$-core index suggests a more densely interconnected core. The maximum $k$-core index (Figure~\ref{fig:advanced_graph_analysis}(c)), representing the deepest level of connectivity, increases in discrete steps, reaching a maximum value of 11. This indicates that as the graph expands, an increasingly dense core emerges, reinforcing the formation of highly interconnected substructures. The stepwise progression suggests that specific iterations introduce structural reorganizations that significantly enhance connectivity rather than continuous incremental growth.

We observe that the size of the largest $k$-core (Figure~\ref{fig:advanced_graph_analysis}(d)) follows a similar pattern, growing in discrete steps and experiencing a sudden drop around iteration 700 before stabilizing again. This behavior suggests that the graph undergoes structural realignments, possibly due to the introduction of new reasoning pathways that temporarily reduce the dominance of the most connected core before further stabilization.

Betweenness Centrality is a measure of how often a node appears on the shortest paths between other nodes. High betweenness suggests a critical role in information flow, while a decrease indicates decentralization and redundancy in pathways. The average betweenness centrality (Figure~\ref{fig:advanced_graph_analysis}(e)) initially exhibits high values, indicating that early reasoning iterations rely heavily on specific nodes to mediate information flow. Over time, betweenness declines and stabilizes a bit below 0.01, suggesting that the graph becomes more navigable and distributed, reducing reliance on key bottleneck nodes over more iterations. This trend aligns with the emergence of redundant reasoning pathways, making the system more robust to localized disruptions.

Articulation points are nodes whose removal would increase the number of disconnected components in the graph, meaning they serve as key bridges between different knowledge clusters. The number of articulation points (Figure~\ref{fig:advanced_graph_analysis}(f)) steadily increases throughout iterations, reaching over 800. This suggests that as the knowledge graph expands, an increasing number of bridging nodes emerge, reflecting a hierarchical structure where key nodes maintain connectivity between distinct regions. Despite this increase, the network remains well connected, indicating that redundant pathways mitigate the risk of fragmentation.

A network where the degree distribution follows a power-law, meaning most nodes have few connections, but a small number (hubs) have many (supporting the notion of a scale-free network). Our findings provide evidence that the recursive graph reasoning process spontaneously organizes into a hierarchical, scale-free structure, balancing local clustering, global connectivity, and efficient navigability. The noted trends in assortativity, core connectivity, and betweenness centrality confirm that the system optimally structures its knowledge representation over iterations, reinforcing the hypothesis that self-organized reasoning processes naturally form efficient and resilient knowledge networks.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\textwidth]{fig_402.pdf}
    \caption{Evolution of advanced structural properties in the recursively generated knowledge graph $\mathcal{G_1}$: (a) degree assortativity, (b) global transitivity, (c) maximum k-core index, (d) size of the largest k-core, (e) average betweenness centrality, and (f) number of articulation points. These metrics reveal the emergence of hierarchical organization, hub formation, and increased navigability over recursive iterations.}
    \label{fig:advanced_graph_analysis}
\end{figure}


 


\subsection{Evolution of Newly Connected Pairs}

Figure~\ref{fig:newly_connected_pairs} presents the evolution of newly connected node pairs as a function of iteration, illustrating how the recursive reasoning process expands the knowledge graph over time. This metric captures the rate at which new relationships are established between nodes, providing insights into the self-organizing nature of the network.

In the early iterations (0–100), the number of newly connected pairs exhibits high variance, fluctuating between 0 and 400 connections per iteration. This suggests that the initial phase of recursive reasoning leads to significant structural reorganization, where large bursts of new edges are formed as the network establishes its fundamental connectivity patterns. The high variability in this region indicates an exploratory phase, where the graph undergoes rapid adjustments to define its core structure.

Beyond approximately 200 iterations, the number of newly connected pairs stabilizes around 500–600 per iteration, with only minor fluctuations. This plateau suggests that the knowledge graph has transitioned into a steady-state expansion phase, where new nodes and edges are integrated into an increasingly structured and predictable manner. Unlike random growth, this behavior indicates that the system follows a self-organized expansion process, reinforcing existing structures rather than disrupting them.

The stabilization at a high connection rate suggests the emergence of hierarchical organization, where newly introduced nodes preferentially attach to well-established structures. This pattern aligns with the scale-free properties observed in other experimentally acquired knowledge networks, where central concepts continuously accumulate new links, strengthening core reasoning pathways. The overall trend highlights how recursive self-organization leads to sustained, structured knowledge expansion, rather than arbitrary or saturation-driven growth.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.4\textwidth]{fig_410.pdf}
    \caption{Evolution of newly connected node pairs over recursive iterations, $\mathcal{G_1}$. Early iterations exhibit high variability, reflecting an exploratory phase of rapid structural reorganization. Beyond 200 iterations, the process stabilizes, suggesting a steady-state expansion phase with sustained connectivity formation.}
    \label{fig:newly_connected_pairs}
\end{figure}


The observed transition from high-variance, exploratory graph expansion to a stable, structured growth phase suggests that recursive self-organization follows a process similar to human cognitive learning and scientific discovery. We believe that this indicates that in early iterations, the system explores diverse reasoning pathways, mirroring how scientific fields establish foundational concepts through broad exploration before refining them into structured disciplines~\cite{kuhn1962structure}. The stabilization of connectivity beyond 200 iterations reflects preferential attachment dynamics, a hallmark of scale-free networks where highly connected nodes continue to accumulate new links, much like citation networks in academia~\cite{barabasi1999emergence}. This mechanism ensures that core concepts serve as attractors for further knowledge integration, reinforcing structured reasoning while maintaining adaptability. Importantly, the system does not exhibit saturation or stagnation, suggesting that open-ended knowledge discovery is possible through recursive reasoning alone, without requiring predefined ontologies or externally imposed constraints. This aligns with findings in AI-driven scientific hypothesis generation, where graph-based models dynamically infer new connections by iterating over expanding knowledge structures~\cite{swanson1986undiscovered, nickel2016review}. The ability of the system to self-organize, expand, and refine its knowledge base autonomously underscores its potential as a scalable framework for automated scientific discovery and epistemic reasoning.





\subsection{Analysis of Node Centrality Distributions at Final Stage of Reasoning}

Next, Figure~\ref{fig:centrality_analysis} presents histograms for three key centrality measures—betweenness centrality, closeness centrality, and eigenvector centrality—computed for the recursively generated knowledge graph, at the final iteration. These metrics provide insights into the role of different nodes in maintaining connectivity, network efficiency, and global influence.

Figure~\ref{fig:centrality_analysis}(a) shows the distribution of betweenness centrality. We find the distribution of betweenness centrality to be highly skewed, with the majority of nodes exhibiting values close to zero. Only a small fraction of nodes attain significantly higher centrality values, indicating that very few nodes serve as critical intermediaries for shortest paths. This pattern is characteristic of hierarchical or scale-free networks, where a small number of hub nodes facilitate global connectivity, while most nodes remain peripheral. The presence of a few high-betweenness outliers suggests that key nodes emerge as crucial mediators of information flow, reinforcing the hypothesis that self-organizing structures lead to the formation of highly connected bridging nodes.

Figure~\ref{fig:centrality_analysis}(b) depicts the closeness centrality distribution. It follows an approximately normal distribution centered around 0.20, suggesting that most nodes remain well-connected within the network. This result implies that the network maintains a compact structure, allowing for efficient navigation between nodes despite continuous expansion. The relatively low spread indicates that the recursive reasoning process prevents excessive distance growth, ensuring that newly introduced nodes do not become isolated. This reinforces the observation that the graph remains navigable as it evolves, an essential property for maintaining coherent reasoning pathways.

Next, Figure~\ref{fig:centrality_analysis}(c) shows the eigenvector centrality distribution, identified to be also highly skewed, with most nodes having values close to zero. However, a few nodes attain substantially higher eigenvector centrality scores, indicating that only a select few nodes dominate the network in terms of global influence. This suggests that the network naturally organizes into a hierarchical structure, where dominant hubs accumulate influence over time, while the majority of nodes play a more peripheral role. The emergence of high-eigenvector hubs aligns with scale-free network behavior, further supporting the idea that reasoning-driven recursive self-organization leads to structured knowledge representation.

These findings indicate that the recursive knowledge graph balances global connectivity and local modularity, self-organizing into a structured yet efficient system. The few high-betweenness nodes act as key mediators, while the closeness centrality distribution suggests that the network remains efficiently connected. The eigenvector centrality pattern highlights the formation of dominant conceptual hubs, reinforcing the presence of hierarchical knowledge organization within the evolving reasoning framework.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\textwidth]{fig_405.pdf}
    \caption{Distribution of node centrality measures in the recursively generated knowledge graph, for $\mathcal{G_1}$: (a) Betweenness centrality, showing that only a few nodes serve as major intermediaries; (b) Closeness centrality, indicating that the majority of nodes remain well-connected; (c) Eigenvector centrality, revealing the emergence of dominant hub nodes. These distributions highlight the hierarchical and scale-free nature of the evolving knowledge graph.}
    \label{fig:centrality_analysis}
\end{figure}

Figure~\ref{fig:shortest_path_distribution} presents the distribution of sampled shortest path lengths. This distribution provides insights into the overall compactness, navigability, and structural efficiency of the  network.

The histogram reveals that the most frequent shortest path length is centered around 5–6 steps, indicating that the majority of node pairs are relatively close in the network. The distribution follows a bell-shaped pattern, suggesting a typical range of distances between nodes, with a slight right skew where some paths extend beyond 10 steps. The presence of longer paths implies that certain nodes remain in the periphery or are indirectly connected to the core reasoning structure.

The relatively narrow range of shortest path lengths affirms that the network remains well-integrated, ensuring efficient knowledge propagation and retrieval. The absence of extreme outliers suggests that the recursive expansion process does not lead to fragmented or sparsely connected regions. This structure contrasts with purely random graphs, where shortest path lengths typically exhibit a narrower peak at lower values. The broader peak observed here suggests that the model does not generate arbitrary connections but instead organizes knowledge in a structured manner, balancing global integration with local modularity.

The observed path length distribution supports the hypothesis that recursive graph reasoning constructs an efficiently connected knowledge framework, where most concepts can be accessed within a small number of steps. The presence of some longer paths further suggests that the network exhibits hierarchical expansion, with certain areas developing as specialized subdomains that extend outward from the core structure.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\textwidth]{fig_406.pdf}
    \caption{Distribution of sampled shortest path lengths in the recursively generated knowledge graphs (panel (a), for graph $\mathcal{G_2}$, panel (b), graph $\mathcal{G_2}$). The peak around 5–6 steps suggests that the network remains compact and navigable, while the slight right skew especially in panel (a) indicates the presence of peripheral nodes or specialized subdomains.}
    \label{fig:shortest_path_distribution}
\end{figure}



\subsection{Knowledge Graph Evolution and Conceptual Breakthroughs}


The evolution of the knowledge graph over iterative expansions discussed so far reveals distinct patterns in knowledge accumulation, conceptual breakthroughs, and interdisciplinary integration. To analyze these processes, we now examine (i) the growth trajectories of major conceptual hubs, (ii) the emergence of new highly connected nodes, and (iii) overall network connectivity trends across iterations. The results of these analyses are presented in Figure~\ref{fig:knowledge_graph_evolution}, which consists of three sub-components.

\begin{figure}[h]
    \centering
     \includegraphics[width=.9\textwidth]{fig_100.pdf}
    \caption{Evolution of knowledge graph structure across iterations, for $\mathcal{G_1}$. (a) Degree growth of the top conceptual hubs, showing both steady accumulation and sudden breakthroughs. (b) Histogram of newly emerging high-degree nodes across iterations, indicating phases of conceptual expansion. (c) Plot of the mean node degree over time, illustrating the system’s progressive integration of new knowledge.}
    \label{fig:knowledge_graph_evolution_100}
\end{figure}

The trajectory of hub development (Figure~\ref{fig:knowledge_graph_evolution_100}(a)) suggests two primary modes of knowledge accumulation: steady growth and conceptual breakthroughs. Certain concepts, such as \texttt{Artificial Intelligence (AI)} and \texttt{Knowledge Graphs}, exhibit continuous incremental expansion, reflecting their persistent relevance in structuring knowledge. In contrast, hubs like \texttt{Bioluminescent Technology} and \texttt{Urban Ecosystems} experience extended periods of low connectivity followed by sudden increases in node degree, suggesting moments when these concepts became structurally significant in the knowledge graph. These results indicate that the system does not expand knowledge in a purely linear fashion but undergoes phases of conceptual restructuring, akin to punctuated equilibrium in scientific development.

The emergence of new hubs (Figure~\ref{fig:knowledge_graph_evolution_100}(b)) further supports this interpretation. Instead of a continuous influx of new central concepts, we observe discrete bursts of hub formation occurring at specific iteration milestones. These bursts likely correspond to the accumulation of contextual knowledge reaching a critical threshold, after which the system autonomously generates new organizing principles to structure its expanding knowledge base. This finding suggests that the system’s reasoning process undergoes alternating cycles of consolidation and discovery, where previously formed knowledge stabilizes before new abstract concepts emerge.

The overall network connectivity trends (Figure~\ref{fig:knowledge_graph_evolution_100}(c)) demonstrate a steady increase in average node degree, indicating that the graph maintains a structurally stable expansion while integrating additional knowledge. The absence of abrupt drops in connectivity suggests that previously introduced concepts remain relevant and continue to influence reasoning rather than become obsolete. This trend supports the hypothesis that the system exhibits self-organizing knowledge structures, continuously refining its conceptual hierarchy as it expands.

These observations lead to several overarching conclusions. First, the results indicate that the system follows a hybrid knowledge expansion model, combining gradual accumulation with disruptive conceptual breakthroughs. This behavior closely mirrors the dynamics of human knowledge formation, where foundational ideas develop progressively, but major paradigm shifts occur when conceptual thresholds are crossed. Second, the persistence of high-degree hubs suggests that knowledge graphs generated in this manner do not suffer from catastrophic forgetting; instead, they maintain and reinforce previously established structures while integrating new insights. Third, the formation of new hubs in discrete bursts implies that knowledge expansion is not driven by uniform growth but by self-reinforcing epistemic structures, where accumulated reasoning reaches a tipping point that necessitates new abstract representations.

Additionally, the system demonstrates a structured directionality in knowledge formation, as evidenced by the smooth increase in average node degree without fragmentation. This suggests that new concepts do not disrupt existing structures but are incrementally woven into the broader network. Such behavior is characteristic of self-organizing knowledge systems, where conceptual evolution follows a dynamic yet cohesive trajectory. The model also exhibits potential for cross-domain knowledge synthesis, as indicated by the presence of nodes that transition into highly connected hubs later in the process. These nodes likely act as bridges between previously distinct knowledge clusters, fostering interdisciplinary connections.

These analyses provide strong evidence that the recursive graph expansion model is capable of simulating key characteristics of scientific knowledge formation. The presence of alternating stability and breakthrough phases, the hierarchical organization of concepts, and the increasing connectivity across knowledge domains all highlight the potential for autonomous reasoning systems to construct, refine, and reorganize knowledge representations dynamically. Future research could potentially focus on exploring the role of interdisciplinary bridge nodes, analyzing the hierarchical depth of reasoning paths, and examining whether the system can autonomously infer meta-theoretical insights from its evolving knowledge graph.




\subsection{Structural Evolution of the Knowledge Graph}

The expansion of the knowledge graph over iterative refinements reveals emergent structural patterns that highlight how knowledge communities form, how interdisciplinary connections evolve, and how reasoning complexity changes over time. These dynamics provide insight into how autonomous knowledge expansion follows systematic self-organization rather than random accumulation. Figure~\ref{fig:knowledge_graph_evolution} presents three key trends: (a) the formation and growth of knowledge sub-networks, (b) the number of bridge nodes that connect different knowledge domains, and (c) the depth of multi-hop reasoning over iterations.

\begin{figure}[h]
    \centering
     \includegraphics[width=.9\textwidth]{fig_102.pdf}
    \caption{Structural evolution of the knowledge graph across iterations. (a) The number of distinct knowledge communities over time, showing an increasing trend with some fluctuations, for graph $\mathcal{G_1}$. (b) The growth of bridge nodes that connect multiple knowledge domains, following a steady linear increase. (c) The average shortest path length over iterations, indicating shifts in reasoning complexity as the graph expands.}
    \label{fig:knowledge_graph_evolution}
\end{figure}

Figure~\ref{fig:knowledge_graph_evolution}(a) illustrates the formation of knowledge sub-networks over time. The number of distinct communities increases as iterations progress, reflecting the system's ability to differentiate between specialized fields of knowledge. The trend suggests two key observations: (i) an early rapid formation of new communities as novel knowledge domains emerge and (ii) a later stage where the number of communities stabilizes with occasional fluctuations. The latter behavior indicates that rather than indefinitely forming new disconnected knowledge clusters, the system reaches a regime where previously distinct domains remain relatively stable while undergoing minor structural reorganizations. The fluctuations in the later stages may correspond to moments where knowledge clusters merge or when new abstractions cause domain shifts.

Figure~\ref{fig:knowledge_graph_evolution}(b) tracks the number of bridge nodes (concepts that serve as interdisciplinary connectors) over iterative expansions. The steady, almost linear increase in bridge nodes suggests that as knowledge expands, more concepts naturally emerge as crucial links between different domains. This behavior reflects the self-reinforcing nature of knowledge integration, where new ideas not only expand within their respective fields but also introduce new ways to connect previously unrelated disciplines. Interestingly, there is no evidence of saturation in the number of bridge nodes, implying that the graph remains highly adaptive, continuously uncovering interdisciplinary relationships without premature convergence. This property is reminiscent of human knowledge structures, where interdisciplinary connections become more prevalent as scientific inquiry deepens.

Figure~\ref{fig:knowledge_graph_evolution}(c) examines the depth of multi-hop reasoning over iterations by measuring the average shortest path length in the graph. Initially, reasoning depth fluctuates significantly, which corresponds to the early phase of knowledge graph formation when structural organization is still emergent. As iterations progress, the average path length stabilizes, indicating that the system achieves a balance between hierarchical depth and accessibility of information. The early fluctuations may be attributed to the rapid reorganization of knowledge, where some paths temporarily become longer as new concepts emerge before stabilizing into more efficient reasoning structures. The eventual stabilization suggests that the graph reaches an equilibrium in how information propagates through interconnected domains, maintaining reasoning efficiency while still allowing for complex inferential pathways.

Taken together, these findings suggest that the autonomous knowledge expansion model exhibits structured self-organization, balancing specialization and integration. The interplay between distinct community formation, interdisciplinary connectivity, and reasoning depth highlights the emergence of a dynamically evolving but structurally coherent knowledge network. The continuous increase in bridge nodes reinforces the idea that interdisciplinary reasoning remains a central feature throughout the system’s expansion, which may have significant implications for autonomous discovery processes. Future analyses will explore whether certain bridge nodes exhibit long-term persistence as central knowledge connectors or if interdisciplinary pathways evolve dynamically based on newly introduced concepts.


\subsection{Persistence of Bridge Nodes in Knowledge Evolution}

To understand the structural stability of interdisciplinary connections, we further analyze the persistence of bridge nodes—concepts that act as connectors between distinct knowledge domains, over multiple iterations. Figure~\ref{fig:bridge_persistence} presents a histogram of bridge node lifespans, showing how long each node remained an active bridge in the knowledge graph.

\begin{figure}[h]
    \centering
     \includegraphics[width=0.7\textwidth]{fig_103.pdf}
    \caption{Histogram of bridge node persistence over iterations, for $\mathcal{G_1}$. The distribution follows a long-tail pattern, indicating that while most bridge nodes exist only briefly, a subset remains active across hundreds of iterations.}
    \label{fig:bridge_persistence}
\end{figure}

The distribution in Figure~\ref{fig:bridge_persistence} suggests that knowledge graph connectivity follows a hybrid model of structural evolution. The majority of bridge nodes appear only for a limited number of iterations, reinforcing the hypothesis that interdisciplinary pathways frequently evolve as new concepts emerge and replace older ones. This aligns with earlier observations that the knowledge system exhibits a high degree of conceptual dynamism.

However, a subset of bridge nodes remains persistent for hundreds of iterations. These nodes likely correspond to fundamental concepts that sustain long-term interdisciplinary connectivity. Their extended presence suggests that the system does not solely undergo continuous restructuring; rather, it maintains a set of core concepts that act as stable anchors in the evolving knowledge landscape.

These results refine our earlier observations by distinguishing between transient interdisciplinary connections and long-term structural stability. While knowledge graph expansion is dynamic, certain foundational concepts maintain their bridging role, structuring the broader knowledge network over extended periods. This hybrid model suggests that autonomous knowledge expansion does not operate under complete conceptual turnover but instead converges toward the emergence of stable, high-impact concepts that persist across iterations.

Related questions that could be explored in future research is whether these persistent bridge nodes correspond to widely used theoretical frameworks, methodological paradigms, or cross-domain knowledge principles. Additionally, further analysis is needed to examine whether long-term bridge nodes exhibit distinct topological properties, such as higher degree centrality or clustering coefficients, compared to short-lived connectors.



\subsection {Early Evolution of Bridge Nodes in Knowledge Expansion}

To examine the mechanics of the formation of interdisciplinary connections in the early stages of knowledge graph evolution, we pay close attention to the process. In the analysis discussed here, we identify the first occurrences of bridge nodes over the initial 200 iterations. Figure~\ref{fig:sorted_bridge_heatmap} presents a binary heatmap, where each row represents a bridge node, and each column corresponds to an iteration. The bridge nodes are sorted by the iteration in which they first appeared, providing a clearer view of how interdisciplinary connectors emerge over time.

\begin{figure}[h]
    \centering
    \includegraphics[width=1.\textwidth]{fig_105.pdf}
    \caption{Emergence of bridge nodes over the first 200 iterations, sorted by first appearance, for $\mathcal{G_1}$. White regions indicate the absence of a node as a bridge, while dark blue regions denote its presence. Nodes that appear earlier in the graph evolution are positioned at the top. The structured emergence pattern suggests phases of knowledge expansion and stabilization.}
    \label{fig:sorted_bridge_heatmap}
\end{figure}

The heatmap in Figure~\ref{fig:sorted_bridge_heatmap} reveals several key trends in the evolution of bridge nodes. Notably, the earliest iterations feature a rapid influx of bridge nodes, reflecting the initial structuring phase of the knowledge graph. Many nodes appear and remain active for extended periods, suggesting that certain concepts establish themselves as core interdisciplinary connectors early in the process. These nodes likely play a foundational role in structuring knowledge integration across domains.

A second notable pattern is the episodic emergence of new bridge nodes, rather than a continuous accumulation. The visualization shows distinct clusters of newly appearing bridge nodes, interspersed with periods of relative stability. These bursts suggest that knowledge integration occurs in structured phases rather than through gradual accumulation. Such phases may represent moments when the system reaches a threshold where newly integrated concepts allow for the creation of previously infeasible interdisciplinary links.

In contrast to the early-established bridge nodes, a subset of nodes appears only in later iterations. These late-emerging bridge nodes indicate that interdisciplinary roles are notably not static; rather, the system continuously restructures itself, incorporating new ideas as they gain relevance. This supports the hypothesis that certain bridge nodes emerge not from initial structuring but from later stages of conceptual refinement, possibly as higher-order abstractions connecting previously developed knowledge clusters.

The distribution of bridge node activity also suggests a mix of persistent and transient connectors. While some nodes appear briefly and disappear, others remain active over long stretches. This behavior reinforces the idea that knowledge expansion is both dynamic and structured, balancing exploration (where new connections are tested) and stabilization (where key interdisciplinary links persist).

We note that the structured emergence of bridge nodes may indicate that interdisciplinary pathways do not form randomly but are shaped by systematic phases of knowledge integration and refinement. Future analyses could explore the long-term impact of early bridge nodes, assessing whether they remain influential throughout the knowledge graph’s evolution, and whether the structure of interdisciplinary connectivity stabilizes or continues to reorganize over extended iterations.






\subsection{Evolution of Key Bridge Nodes Over Iterations}

To investigate how interdisciplinary pathways evolve in the knowledge graph, we analyzed the betweenness centrality of the most influential bridge nodes across 1,000 iterations. Figure~\ref{fig:bridge_node_evolution} presents the trajectory of the top 10 bridge nodes, highlighting their shifting roles in facilitating interdisciplinary connections.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{fig_110.pdf}
    \caption{Evolution of the top 10 bridge nodes over iterations, for $\mathcal{G_1}$. Each curve represents the betweenness centrality of a bridge node, indicating its role in facilitating knowledge integration. Nodes that initially had high centrality later declined, while some concepts maintained their influence throughout the graph’s evolution.}
    \label{fig:bridge_node_evolution}
\end{figure}

The trends in Figure~\ref{fig:bridge_node_evolution} reveal distinct patterns in how bridge nodes emerge, peak in influence, and decline over time. Notably, nodes such as \texttt{Closed-Loop Life Cycle Design} and \texttt{Human Well-being} exhibit high betweenness centrality in the early iterations, suggesting that they played a fundamental role in structuring the initial interdisciplinary landscape. However, as the knowledge graph expanded, these nodes saw a gradual decline in their centrality, indicating that their role as primary connectors was replaced by alternative pathways.

A second class of bridge nodes, including \texttt{Adaptability and Resilience of Cities} and \texttt{Artificial Intelligence (AI)}, maintained high centrality values for a longer duration, suggesting that certain concepts remain essential to interdisciplinary knowledge integration even as the graph evolves. These nodes acted as long-term knowledge stabilizers, facilitating interactions between different research domains throughout a significant portion of the knowledge expansion process.

Interestingly, a subset of nodes, such as \texttt{Feedback Mechanism} and \texttt{Outcome}, gradually gained importance over time. Unlike early bridge nodes that peaked and declined, these nodes started with lower centrality but increased in influence in later iterations. This suggests that some interdisciplinary pathways only become critical after sufficient knowledge accumulation, reinforcing the idea that interdisciplinary roles are not static but continuously reorganize as the knowledge graph matures.

Furthermore, we observe that by approximately iteration 400-600, most bridge nodes' betweenness centrality values begin converging toward lower values, indicating that knowledge transfer is no longer reliant on a small set of nodes. This suggests that, as the graph expands, alternative pathways develop, leading to a more distributed and decentralized knowledge structure where connectivity is no longer dominated by a few highly influential nodes.

These findings support the hypothesis that interdisciplinary pathways evolve dynamically, with early-stage knowledge formation relying on a few key concepts, followed by a transition to a more robust and distributed network where multiple redundant pathways exist. Future analyses will focus on:
\begin{itemize}
    \item Identifying which nodes replaced early bridge nodes as major interdisciplinary connectors in later iterations.
    \item Comparing early vs. late-stage bridge nodes to assess whether earlier nodes tend to be general concepts, while later bridge nodes represent more specialized interdisciplinary knowledge.
    \item Analyzing the resilience of the knowledge graph by simulating the removal of early bridge nodes to determine their structural significance.
\end{itemize}

These results provide a perspective on how interdisciplinary linkages emerge, stabilize, and reorganize over time, offering insights into the self-organizing properties of large-scale knowledge systems.




\subsection{Evolution of Betweenness Centrality Distribution}

To analyze the structural evolution of the knowledge graph, we next examine the distribution of betweenness centrality at different iterations. Betweenness centrality is a measure of a node’s importance in facilitating knowledge transfer between different parts of the network. Formally, the betweenness centrality of a node $v$ is given by:

\begin{equation}
    C_B(v) = \sum_{s \neq v \neq t} \frac{\sigma_{st}(v)}{\sigma_{st}},
\end{equation}

where $\sigma_{st}$ is the total number of shortest paths between nodes $s$ and $t$, and $\sigma_{st}(v)$ is the number of those paths that pass through $v$. A higher betweenness centrality indicates that a node serves as a critical intermediary in connecting disparate knowledge domains.

Figure~\ref{fig:betweenness_distribution} presents histograms of betweenness centrality distribution at four key iterations (2, 100, 510, and 1024), illustrating the shifting role of bridge nodes over time.

Initially, at Iteration 2, the network is highly centralized, with a small number of nodes exhibiting extremely high betweenness centrality (above 0.6), while the majority of nodes have near-zero values. This indicates that only a few nodes act as critical interdisciplinary connectors, facilitating nearly all knowledge transfer.

By Iteration 100, the distribution has broadened, meaning that more nodes participate in knowledge transfer. The highest betweenness values have decreased compared to Iteration 2, and more nodes exhibit low but nonzero centrality, suggesting an increase in redundant pathways and reduced dependency on a few dominant bridge nodes.

At Iteration 510, the distribution becomes more skewed again, with fewer nodes having high betweenness centrality and a stronger concentration at low values. This suggests that the network has undergone a phase of structural consolidation, where interdisciplinary pathways reorganize around fewer, more stable bridges.

Finally, at Iteration 1024, the histogram shows that most nodes have low betweenness centrality, and only a few retain moderate values. This suggests that the network has matured into a more distributed structure, where no single node dominates knowledge transfer. The observed trend indicates that as the knowledge graph expands, the burden of interdisciplinary connectivity is increasingly shared among many nodes rather than concentrated in a few.

These results suggest that the system undergoes a dynamic reorganization process, shifting from an initial hub-dominated structure to a more distributed and resilient network. Future work could potentially explore whether these trends continue as the graph scales further and whether the eventual network state remains stable or undergoes additional restructuring.

%%%%%%
To examine the overall structural properties of the knowledge graph, we analyzed the distribution of betweenness centrality across all iterations. Figure~\ref{fig:betweenness_distribution_across_all} presents a histogram of betweenness centrality values collected from all iterations of the knowledge graph. The distribution was generated by computing betweenness centrality for each iteration and aggregating all node values overall iterations.

\begin{figure}[h]
    \centering
    \includegraphics[width=.7\textwidth]{fig_115.pdf}
    \caption{Distribution of betweenness centrality across all iterations, $\mathcal{G_1}$. The y-axis is log-scaled, showing the frequency of nodes with different centrality values. A small number of nodes dominate knowledge transfer, while most nodes exhibit near-zero centrality.}
    \label{fig:betweenness_distribution_across_all}
\end{figure}

The histogram in Figure~\ref{fig:betweenness_distribution_across_all} reveals a highly skewed distribution, where the majority of nodes exhibit near-zero betweenness centrality, while a small subset maintains significantly higher values. This pattern suggests that knowledge transfer within the network is primarily governed by a few dominant bridge nodes, which facilitate interdisciplinary connections. The presence of a long tail in the distribution indicates that these high-betweenness nodes persist throughout multiple iterations.

Interestingly, the distribution also exhibits multiple peaks, suggesting that the network consists of different classes of bridge nodes. Some nodes act as long-term stable interdisciplinary connectors, while others emerge as transient bridges that facilitate knowledge transfer only for limited iterations.

The log scale on the $y$-axis reveals that while most nodes contribute little to betweenness centrality, a significant number of nodes still exhibit low but nonzero values indicating that knowledge flow is distributed across many minor pathways. Over multiple iterations, it is expected that betweenness centrality values redistribute, reducing dependency on early dominant nodes and leading to a more decentralized knowledge structure.

These findings highlight that the knowledge graph maintains a core-periphery structure, where a few key nodes play a disproportionate role in bridging knowledge across disciplines. Future work will explore how the distribution evolves over time, identifying whether the network transitions toward a more evenly distributed structure or remains reliant on a small number of high-centrality nodes.



\subsection{Evolution of Betweenness Centrality in the Knowledge Graph}

To analyze the structural evolution of the knowledge graph, we tracked the changes in betweenness centrality over 1,000 iterations. Betweenness centrality quantifies the extent to which a node serves as a bridge between other nodes by appearing on shortest paths. A node with high betweenness centrality facilitates interdisciplinary knowledge transfer by linking otherwise disconnected regions of the network. Figures~\ref{fig:betweenness_evolution}(a) and \ref{fig:betweenness_evolution}(b) illustrate how mean and maximum betweenness centrality evolve over time. The first plot captures the average importance of nodes in knowledge transfer, while the second identifies the most dominant bridge nodes at each iteration.

\begin{figure}[h]
    \centering
    \includegraphics[width=.9\textwidth]{fig_120.pdf} 
    \caption{Evolution of betweenness centrality in the knowledge graph, $\mathcal{G_1}$. Panel (a): Mean betweenness centrality over time, showing a transition from early high centralization to a more distributed state. Panel (b):  Maximum betweenness centrality per iteration, highlighting how the most dominant bridge nodes shift and decline in influence.}
    \label{fig:betweenness_evolution}
\end{figure}

%\subsubsection*{Evolution of Betweenness Centrality Over Iterations}
Figure~\ref{fig:betweenness_evolution}(a) tracks the mean betweenness centrality, providing insight into how the overall distribution of knowledge transfer roles evolves. In the earliest iterations, the mean betweenness is extremely high, indicating that only a few nodes dominate knowledge exchange. However, as the graph expands and alternative pathways form, the mean betweenness declines rapidly within the first 100 iterations.

Between iterations 100 and 500, we observe a continued decline, but at a slower rate. This suggests that knowledge transfer is being shared across more nodes, reducing reliance on a small set of dominant bridges. After iteration 500, the values stabilize near zero, indicating that the network has reached a decentralized state, where multiple nodes contribute to knowledge integration instead of a few key intermediaries.

These trends suggest a self-organizing process, where the knowledge graph transitions from a highly centralized system into a more distributed and resilient network. The final structure is more robust, with many small bridges collectively supporting interdisciplinary connectivity instead of a few dominant hubs.

Figure~\ref{fig:betweenness_evolution}(b) examines the highest betweenness centrality recorded in each iteration, tracking the most dominant knowledge bridge at each stage. In the earliest iterations, a single node reaches an extreme betweenness value of around 0.7, indicating that knowledge transfer is highly bottlenecked through one or very few key nodes.

Between iterations 50 and 300, the maximum betweenness remains high, fluctuating between 0.3 and 0.5. This suggests that while the network becomes less dependent on a single node, a small number of highly central nodes still dominate knowledge flow. This phase represents a transition period, where the network starts distributing knowledge transfer across multiple nodes.

After iteration 500, the maximum betweenness exhibits a gradual decline, eventually stabilizing around 0.2. This suggests that the network has successfully decentralized, and knowledge transfer is no longer dominated by a single key node. The presence of multiple lower-betweenness bridge nodes implies that redundant pathways have developed, making the system more resilient to disruptions. This is in general agreement with earlier observations. 

The combined results from Figures~\ref{fig:betweenness_evolution}(a) and \ref{fig:betweenness_evolution}(b) suggest that the knowledge graph undergoes a fundamental structural transformation over time:
\begin{itemize}
    \item Initially, a few dominant nodes control knowledge flow, leading to high mean and maximum betweenness centrality.
    \item As the graph expands, new pathways emerge, and betweenness is distributed across more nodes.
    \item By the later iterations, no single node dominates, and knowledge transfer occurs through a decentralized structure.
\end{itemize}

This evolution suggests that the knowledge graph self-organizes into a more distributed state, where interdisciplinary connectivity is no longer constrained by a few central hubs. Future studies can explore whether this trend continues at larger scales and analyze which specific nodes maintained high betweenness longest and which replaced them in later iterations.





\subsection{Analysis of longest shortest path in $\mathcal{G}_2$ and analysis using agentic reasoning}

While the primary focus of this study is targeting a detailed analysis of graph dynamic experiments during reasoning, we also explore how graph reasoning based on the \textit{in-situ} generated graph can be used to improve responses through in-context learning~\cite{Brown2020LanguageLearners} (here, we use \url{meta-llama/Llama-3.2-3B-Instruct}). The methodology employs a graph-based reasoning framework to enhance LLM responses through structured knowledge extraction obtained through the method described above.  
Figure~\ref{fig:shortest_longest_G2}(b) depicts additional analysis, showing a correlation heatmap of path-level metrics, computed for the first 30 longest shortest paths. 

\begin{figure}[h]
    \centering
    \includegraphics[width=1.\textwidth]{fig_872.pdf}
    \caption{Longest shortest path analysis. Panel (a): Visualization of the longest shortest path (diameter path) in $\mathcal{G}_2$, presenting a fascinating chain of interdisciplinary relationships across medicine, data science and AI, materials science, sustainability, and infrastructure. Panel (b): Correlation heatmap of path-level metrics, computed for the first 30 longest shortest paths. Degree and betweenness centrality are highly correlated, indicating that high-degree nodes frequently serve as key connectors. Eigenvector centrality and PageRank also show strong correlation, highlighting their shared role in capturing node influence. Path density exhibits a weak or negative correlation with centrality measures, suggesting that highly connected nodes often form less dense structures. The metrics were computed for each path by extracting node-level properties (degree, betweenness, closeness, eigenvector centrality, PageRank, clustering coefficient) from the original graph and averaging them over all nodes in the path. Path density was calculated as the ratio of actual edges to possible edges within the path subgraph. Correlations were then derived from these aggregated values across multiple paths.
     }
    \label{fig:shortest_longest_G2}
\end{figure}

The extracted longest shortest path depicted in Figure~\ref{fig:shortest_longest_G2}(a) presents a compelling sequence of relationships spanning biotechnology, artificial intelligence, materials science, and sustainability, illustrating how advancements in one domain influence others. The overall logical flow is well-structured, with clear and expected progressions, such as \texttt{Rare Genetic Disorders} leading to \texttt{Personalized Medicine} and \texttt{Knowledge Discovery}, reflecting that the model captures the increasing role of AI in medical research. The sequence from \texttt{AI Techniques} to \texttt{Predictive Modeling} and \texttt{Machine Learning (ML) Algorithms} is similarly intuitive, as computational models underpin predictive simulations across disciplines (details on methods, see Section~\ref{methods:agentic_longest_shortest}).

However, some unexpected connections emerge, suggesting areas for further exploration. The link from \texttt{Machine Learning (ML) Algorithms} to \texttt{Impact-Resistant Materials} stands out -- not as a weak connection, but as an intriguing suggestion of AI-driven materials design rather than mere discovery. Computational techniques, such as reinforcement learning and generative modeling, could optimize material structures for durability, opening new pathways in materials engineering. Another unconventional relationship is the transition from \texttt{Biodegradable Microplastic Materials} to \texttt{Infrastructure Design}. These two areas typically operate separately, yet this link may hint at the emergence of biodegradable composites for construction or sustainable materials engineering. Further investigation into the practical applications of biodegradable materials in structural design could strengthen this connection.

A notable redundancy appears in the presence of \texttt{Pollution Mitigation} twice, spelled differently, which results from a lack of node merging rather than a distinct conceptual relationship. This duplication suggests that similar concepts are being represented as separate nodes, potentially affecting graph-based reasoning. Similarly, \texttt{Self-Healing Materials in Infrastructure Design} loops back to \texttt{Pollution Mitigation}, reinforcing an already established sustainability link. While valid, this repetition could be streamlined for clarity.

We find that the logical progression effectively captures key interdisciplinary relationships while revealing areas for refinement. The structure underscores the increasing role of AI in materials science, the integration of sustainability into materials design, and the interplay between predictive modeling and physical sciences. Addressing node duplication and refining transitions between traditionally separate fields—such as biodegradable materials in construction—would enhance the clarity and coherence of the path, making it an even more insightful representation of scientific knowledge.

\paragraph{Agentic Reasoning over the Path}  We apply an agentic model to analyze the longest shortest path. For this analysis, an agentic system first analyzes each node in the subgraph, then each of the relationships, and then synthesizes them into a ``Final Synthesized Discovery'' (in blue font for clarity). The analysis identifies key concepts such as biodegradable microplastics, self-healing materials, pollution mitigation, and AI-driven predictive modeling, ultimately synthesizing the \texttt{Bio-Inspired, Adaptive Materials for Resilient Ecosystems (BAMES)} paradigm. The resulting document, \hyperlink{supporting_text_1}{Supporting Text 1}, presents the results.

The proposed discovery proposes self-healing, bio-inspired materials that integrate microbial, plant, and animal-derived mechanisms with AI-driven optimization to create adaptive, environmentally responsive materials. By embedding microorganisms for pollutant degradation and leveraging machine learning for real-time optimization, the model suggests that \texttt{BAMES} extends conventional self-healing materials beyond infrastructure applications into active environmental remediation~\cite{white2001autonomic}. The concept of temporal memory, where materials learn from past environmental conditions and adjust accordingly, introduces a novel paradigm in smart materials~\cite{complex_systems_review}. Additionally, the hypothesis that interconnected materials could develop emergent, collective behavior akin to biological ecosystems presents an interesting perspective on material intelligence and sustainability~\cite{bioinspired_design,Nepal2022HierarchicallyNanocomposites}.

%%% Compositional Reasoning

\paragraph{Agentic Compositional Reasoning} We can formalize this approach further and induce agentic strategy to develop compositional reasoning (see, Section~\ref{methods:agentic_compositional} for details). In this experiment, implement a systematic development of hierarchical reasoning over concepts, pairs of concepts, and so on. The resulting document is shown in \hyperlink{supporting_text_2}{Supporting Text 2}, and Figure~\ref{fig:compositional_analysis} shows a flowchart of the reasoning process. 

\begin{figure}[h]
    \centering
    \includegraphics[width=.8\textwidth]{fig_876.pdf}
    \caption{Compositional framework applied to the longest shortest path. The flowchart illustrates the hierarchical process of compositional reasoning, beginning with atomic components (fundamental scientific concepts, left, as identified in the longest shortest path (Figure~\ref{fig:shortest_longest_G2}(a))) and progressing through pairwise fusions, bridge synergies, and a final expanded discovery. Each stage (Steps A, B, C and D) integrates concepts systematically, ensuring interoperability, generativity, and hierarchical refinement, culminating in the \texttt{EcoCycle} framework for sustainable infrastructure development.     }
    \label{fig:compositional_analysis}
\end{figure}

The example ultimately presents a structured approach to compositional scientific discovery, integrating principles from infrastructure materials science, environmental sustainability, and artificial intelligence to develop a novel framework for sustainable infrastructure, termed \texttt{EcoCycle}. As can be seen in \hyperlink{supporting_text_2}{Supporting Text 2} and in Figure~\ref{fig:compositional_analysis}, the compositional reasoning process proceeded through multiple hierarchical steps, ensuring the systematic combination of concepts with well-defined relationships. 

At the foundational level, atomic components were identified, each representing an independent domain concept, such as biodegradable microplastic materials, self-healing materials, predictive modeling, and knowledge discovery. These fundamental elements were then combined into pairwise fusions, leveraging shared properties to generate novel synergies. For instance, the fusion of self-healing materials with pollution mitigation led to \texttt{environmental self-healing systems}, integrating autonomous repair mechanisms with pollution reduction strategies. Similarly, combining impact-resistant materials with machine learning algorithms enabled \texttt{damage forecasting systems}, enhancing predictive maintenance in infrastructure.

The validity of this compositional reasoning was established by ensuring that each fusion preserved the integrity of its constituent concepts while generating emergent functionalities. The process adhered to key compositionality principles: (1) \texttt{Interoperability}, ensuring that combined components interacted meaningfully rather than arbitrarily; (2) \texttt{Generativity}, whereby new properties emerged that were not present in the individual components; and (3) \texttt{Hierarchical Refinement}, wherein smaller-scale synergies were recursively integrated into higher-order bridge synergies. This led to overarching themes such as \texttt{the intersection of environmental sustainability and technological innovation} and \texttt{the holistic understanding of complex systems}, demonstrating the robustness of the approach.

Ultimately, these synergies converged into the \texttt{EcoCycle} framework, encapsulating self-healing, eco-responsive, and AI-optimized infrastructure solutions. The structured composition ensured that emergent discoveries were not mere aggregations but cohesive, context-aware innovations, validating the methodological rigor of the compositional approach. Using a strategy of adhering to systematic composition principles, the method used here demonstrates how interdisciplinary insights can be synthesized into scientific concepts.

For comparison, \hyperlink{supporting_text_3}{Supporting Text 3} shows the same experiment but where we use \texttt{o1-pro} in the final step of synthesis. 

Putting this into context, earlier work~\cite{fodor1988connectionism,zhao2024compositional,shi2025cryptox,xu2024largelanguagemodelscompositional} have highlighted significant limitations in large language models (LLMs) concerning their ability to perform systematic compositional reasoning, particularly in domains requiring logical integration and generalization. Our approach directly addresses these deficiencies by structuring reasoning processes in a progressive and interpretable manner. Despite possessing individual components of knowledge, LLMs often struggle to integrate these dynamically to detect inconsistencies or solve problems requiring novel reasoning paths. We mitigate this by explicitly encoding relationships between concepts within a graph structure. Unlike conventional LLMs that rely on associative pattern recognition or statistical co-occurrence~\cite{fodor1988connectionism}, our structured approach mitigates the concerns of mere connectionist representations by enforcing rule-based, interpretable generalization mechanisms that allow for dynamic recombination of learned knowledge in novel contexts. Further, our approach ensures that each reasoning step builds upon prior knowledge in a structured hierarchy. Steps A-D in our framework progressively construct solutions by leveraging explicit connections between concepts, enforcing compositionality rather than assuming it. For example, our approach connects biodegradable microplastic materials with self-healing materials, not merely through surface-level similarities but through defined mechanisms such as thermoreversible gelation and environmental interactions. Instead of expecting an LLM to infer relationships in a single step, our agentic model progressively traverses reasoning graphs, ensuring that the final outcome emerges through logically justified intermediary steps. This not only reduces reliance on pattern memorization but also enhances interpretability and robustness in novel scenarios.  

Our model further enhances compositional reasoning through three key mechanisms: 
\begin{enumerate}
    \item \textbf{Explicit Pathway Construction:} By mapping dependencies between concepts in a structured graph, our model ensures that each step in the reasoning process is explicitly defined and logically connected.
    \item \textbf{Adaptive Contextual Integration:} Instead of treating reasoning steps as isolated tasks, the model dynamically integrates intermediate results to refine its conclusions, ensuring that errors or inconsistencies in earlier stages are corrected before final predictions.
    \item \textbf{Hierarchical Synergy Identification:} Our model analyzes multi-domain interactions through graph traversal and thereby identify emergent patterns that standard LLMs would overlook, enabling more robust and flexible reasoning. These mechanisms collectively establish a reasoning framework that mitigates compositional deficiencies and facilitates the structured synthesis of knowledge.
\end{enumerate}
Table \ref{tab:comparison} summarizes how our approach directly addresses key LLM limitations identified in earlier work.

\begin{table}[h]
    \centering
    \begin{tabular}{|p{5cm}|p{10cm}|}
        \hline
        \textbf{Conventional LLM} & \textbf{How Our Model Addresses It} \\
        \hline
        Fails to compose multiple reasoning steps into a coherent process & Uses hierarchical reasoning with Steps A-D, ensuring progressive knowledge integration through structured dependencies. \\
        \hline
        Struggles to generalize beyond memorized patterns & Uses explicit graph structures to enforce systematic knowledge composition, allowing for novel reasoning paths. \\
        \hline
        Overfits to reasoning templates, failing on unseen reformulations & Introduces pairwise and bridge synergies to enable dynamic recombination of knowledge through structured traversal and adaptive reasoning. \\
        \hline
        Does not simulate "slow thinking" or iterative reasoning well & Implements an agentic model that explicitly traverses a reasoning graph rather than relying on a single forward pass, ensuring each step refines and validates prior knowledge. \\
        \hline
    \end{tabular}
    \caption{Comparison of limitations of conventional LLMs, and our approach addresses these. By explicitly structuring relationships between concepts, breaking down reasoning into progressive steps, and incorporating dynamic knowledge recombination, our approach achieves a higher level of structured compositionality that conventional LLMs struggle with. Future work could further refine this approach by introducing adaptive feedback loops, reinforcing causal reasoning, and incorporating quantitative constraints to strengthen knowledge synergies.}
    \label{tab:comparison}
\end{table}

Further analysis of these is left to future work, as they would exceed the scope of the present paper. The experiments show that principled approaches to expand knowledge can indeed be implemented using the methodologies described above, complementing other recent work that has explored related topics~\cite{BuehlerGraphReasoning2024,shi2025cryptox,Buehler2025GraphAwareGPT,xu2024largelanguagemodelscompositional,fodor1988connectionism}. 

\subsection{Utilization of Graph Reasoning over Key Hubs and Influencer Nodes in Response Generation}


In this example, we analyze the knowledge graph $\mathcal{G}_2$ using \texttt{NetworkX} to compute node centralities (betweenness and eigenvector centrality), identifying key hubs and influencers. Community detection via the Louvain method partitions the graph into conceptual clusters, extracting representative nodes per community. 

Key relationships are identified by examining high-centrality nodes and their strongest edges. These insights are formatted into a structured context and integrated into a task-specific prompt for LLM reasoning on impact-resistant materials, the same prompt that was used to construct the original graph. 

The model's response is generated both with and without graph data, followed by a comparative evaluation based on graph utilization, depth of reasoning, scientific rigor, and innovativeness. Raw responses for both models are shown in Text Boxes~\ref{TexBox:graph-response} and \ref{TexBox:base-response}. Table~\ref{tab:response_comparison} provides a detailed comparison, and Figure~\ref{fig:response_analysis_graph} compares responses based on four
key evaluation metrics (Graph Utilization, Depth of Reasoning, Scientific Rigor, and Innovativeness, along with the overall score).


\begin{figure}[h]
    \centering
     \includegraphics[width=.9\textwidth]{fig_85.pdf}
    \caption{Comparison of Responses on Impact-Resistant Material Design. This  plot compares two responses based on four key evaluation metrics: Graph Utilization, Depth of Reasoning, Scientific Rigor, and Innovativeness, along with the overall score. Response 1, which incorporates graph-based insights, AI/ML techniques, and interdisciplinary approaches, outperforms Response 2 in all categories. Response 2 follows a more conventional materials science approach without leveraging computational methods. The higher overall score of Response 1 highlights the benefits of integrating advanced data-driven methodologies in material design. }
    \label{fig:response_analysis_graph}
\end{figure}


\subsection{Use of an Agentic Deep Reasoning Model to Generate new Hypotheses and Anticipated Material Behavior}

Next, we use the SciAgents model~\cite{ghafarollahi2024sciagentsautomatingscientificdiscovery} with the \texttt{o3-mini} reasoning model~\cite{o3-mini-model-card-2025} as the back-end, and graph $\mathcal{G_2}$to answer this question: \texttt{Create a research idea around impact resistant materials and resilience. Rate the novelty and feasibility in the end.}  

The path-finding algorithm that integrates node embeddings and a degree of randomness to enhance exploration sampling strategy~\cite{ghafarollahi2024sciagentsautomatingscientificdiscovery} extracts this sub-graph from the larger graph:

\begin{LLMbox}{}
\begin{lstlisting}
Impact Resistant Materials -- IS-A -- Materials -- IS-A -- Impact-Resistant Materials -- INFLUENCES -- Modular Infrastructure Systems -- RELATES-TO -- Self-Healing Materials -- RELATES-TO -- Long-term Sustainability and Environmental Footprint of Infrastructure -- RELATES-TO -- Self-Healing Materials -- RELATES-TO -- Infrastructure -- IS-A -- Infrastructure Resilience -- RELATES-TO -- Smart Infrastructure -- RELATES-TO -- Impact-Resistant Materials -- RELATES-TO -- Machine Learning Algorithms -- RELATES-TO -- Impact-Resistant Materials -- RELATES-TO -- Resilience
\end{lstlisting}
\end{LLMbox}

As described in~\cite{ghafarollahi2024sciagentsautomatingscientificdiscovery} paths are sampled using a path-finding algorithm that utilizes both node embeddings and a degree of randomness to enhance exploration as a path is identified between distinct concepts. Critically, instead of simply identifying the shortest path, the algorithm introduces stochastic elements by selecting waypoints and modifying priority queues in a modified version of Dijkstra’s algorithm. This allows for the discovery of richer and more diverse paths in a knowledge graph. The resulting paths serve as the foundation for graph-based reasoning specifically geared towards research hypothesis generation, ensuring a more extensive and insightful exploration of scientific concepts.

Visualizations of the subgraph are shown in Figure~\ref{fig:fig_500}, depicting the subgraph alone (Figure~\ref{fig:fig_500}(a)) and the subgraph with second hops (Figure~\ref{fig:fig_500}(b), showing the deep interconnectness that can be extracted). 

\begin{figure}[h]
    \centering
     \includegraphics[width=.85\textwidth]{fig_500.pdf}
    \caption{Visualization of subgraphs extracted from $\mathcal{G}_2$ by SciAgents, for use in graph reasoning. The left panel (a) represents the primary subgraph containing only nodes from the specified reasoning path. Node size is proportional to the original degree in the full network, highlighting key entities with high connectivity. The structure is sparse, with key nodes acting as central hubs in the reasoning framework. The right panel (b) represents an expanded subgraph that includes second-hop neighbors. Nodes from the original subgraph are colored orange, while newly introduced second-hop nodes are green. The increased connectivity and density indicate the broader network relationships captured through second-hop expansion. Larger orange nodes remain dominant in connectivity, while green nodes form supporting structures, emphasizing peripheral interactions and their contribution to knowledge propagation. This visualization highlights how expanding reasoning pathways in a graph framework integrates additional contextual information, enriching the overall structure..}
    \label{fig:fig_500}
\end{figure}


The resulting document \hyperlink{supporting_text_4}{Supporting Text 4} presents the results of applying SciAgents to $\mathcal{G}_2$  in the context of impact-resistant materials and infrastructure resilience. The graph representation serves as a structured framework for reasoning about the relationships between key concepts—impact-resistant materials, self-healing mechanisms, machine learning optimization, and modular infrastructure—by encoding dependencies and influences between them. Graph 2 specifically captures these interconnected domains as nodes, with edges representing logical or causal links, enabling a systematic exploration of pathways that lead to optimal material design strategies. The path traversal within the graph identifies key dependencies, such as how impact-resistant materials influence infrastructure resilience or how machine learning refines self-healing efficiency. This structured pathway-based reasoning allows SciAgents to generate research hypotheses that maximize cross-domain synergies, ensuring that material properties are not optimized in isolation but rather in concert with their broader applications in engineering and sustainability. Furthermore, graph traversal reveals emergent relationships—such as how integrating real-time sensor feedback into modular infrastructure could create self-improving materials—that might not be immediately evident through conventional linear analysis. Thus, the use of graph-based reasoning is pivotal in formulating a research framework that is not only interdisciplinary but also systematically optimized for long-term infrastructure resilience and material adaptability.


In terms of specific content, the proposed research explores an advanced composite material that integrates carbon nanotube (CNT)-reinforced polymer matrices with self-healing microcapsules, embedded sensor networks, and closed-loop ML optimization. The goal is to create a dynamically self-improving material system that enhances impact resistance and longevity in modular infrastructure. The material design is structured around several key components: (1) CNT reinforcement (1–2 wt\%) to improve tensile strength and fracture toughness, (2) self-healing microcapsules (50–200 $\mu$m) filled with polymerizable agents, (3) embedded graphene-based or PVDF strain sensors for real-time monitoring, and (4) adaptive ML algorithms that regulate stress distributions and healing responses.

The proposal establishes interconnections between several domains, highlighting the interdisciplinary nature of the research: impact-resistant materials are a subset of general materials with enhanced energy dissipation properties, modular infrastructure benefits from these materials due to increased durability, self-healing materials reduce maintenance cycles, and machine learning optimizes real-time responses to structural stress. This holistic framework aims to advance infrastructure resilience and sustainability. The research hypothesizes that embedding self-healing microcapsules within a CNT-reinforced polymer matrix will yield a composite with superior impact resistance and adaptive repair capabilities. Expected performance gains include a 50\% increase in impact energy absorption (surpassing 200 J/m²), up to 80\% recovery of mechanical properties after micro-damage, an estimated 30\% improvement in yield strain, a 50\% extension in structural lifetime, and a 30\% reduction in required maintenance interventions.

The composite operates via a multi-scale integration strategy where nanoscale CNTs form a stress-bridging network, microscale healing agents autonomously restore structural integrity, and macroscale sensors collect real-time strain data to inform machine learning-based optimizations. The closed-loop ML system refines material responses dynamically, preemptively addressing stress concentrations before catastrophic failure occurs. This iterative self-optimization process is represented in the  flowchart shown in Figure~\ref{fig:composite_flowchart}. 
\begin{figure}
\centering
\sffamily
\scriptsize
\sansmath

\begin{tikzpicture}[
    node distance=0.5cm and .5cm, auto,
    event/.style={rectangle, draw, fill=blue!20, text width=5cm, text centered, rounded corners, minimum height=1.2cm},
    sensing/.style={rectangle, draw, fill=cyan!30, text width=5cm, text centered, rounded corners, minimum height=1.2cm},
    ml_analysis/.style={rectangle, draw, fill=violet!40, text width=5cm, text centered, rounded corners, minimum height=1.2cm},
    adjustment/.style={rectangle, draw, fill=violet!20, text width=5cm, text centered, rounded corners, minimum height=1.5cm},
    healing/.style={rectangle, draw, fill=green!30, text width=5cm, text centered, rounded corners, minimum height=1.5cm},
    feedback/.style={rectangle, draw, fill=yellow!30, text width=5cm, text centered, rounded corners, minimum height=1.2cm},
    line/.style={draw, -stealth', shorten >=1pt},
    dashed line/.style={draw, dashed, shorten >=1pt}]

    % Define nodes
    \node [event] (impact) {\textbf{Impact Event} \\ (Material undergoes structural stress or damage)};
    \node [sensing, below=of impact] (sensors) {\textbf{Sensor Detection} \\ (Real-time strain monitoring via embedded graphene/PVDF sensors)};
    \node [ml_analysis, below=of sensors] (ml) {\textbf{Machine Learning Analysis} \\ (Prediction of stress distribution, micro-damage evolution)};
    \node [adjustment, below=of ml] (adjustment) {\textbf{Healing Response Adjustment} \\ (ML-optimized activation of microcapsules based on sensor data)};
    \node [healing, below=of adjustment] (repair) {\textbf{Microcapsule Rupture and Repair} \\ (Self-healing agent polymerization to restore mechanical integrity)};
    \node [feedback, below=of repair] (performance) {\textbf{Material Performance Feedback} \\ (Updated data informs next optimization cycle)};

    % Sequential Flow
    \path [line] (impact) -- (sensors);
    \path [line] (sensors) -- (ml);
    \path [line] (ml) -- (adjustment);
    \path [line] (adjustment) -- (repair);
    \path [line] (repair) -- (performance);

    % Feedback loop
    \path [dashed line] (performance.east) to[out=0, in=0] node[right, text width=4.5cm, align=center] {\textbf{Adaptive Learning Cycle:} \\ Sensors collect new data, \\ ML refines healing response} (ml.east);

\end{tikzpicture}
\sffamily
\caption{Flowchart of the Self-Optimizing Composite System proposed by SciAgents after reasoning over $\mathcal{G}_2$. 
Upon an impact event, embedded sensors (cyan) detect strain changes and transmit real-time data to a machine learning system (violet). 
This system predicts stress evolution and dynamically adjusts healing response thresholds (light violet). 
Microcapsules containing polymerizable agents (green) rupture at critical points, autonomously restoring material integrity. 
A feedback mechanism (yellow) continuously refines the process, ensuring adaptive optimization over multiple impact cycles. 
The dashed feedback loop signifies that each iteration improves the material’s ability to predict and mitigate future stress events, making the system progressively more efficient.}
\label{fig:composite_flowchart}
\end{figure}

Compared to conventional high-performance composites such as ultra-high molecular weight polyethylene (UHMWPE) and standard carbon fiber-reinforced polymers, the proposed material demonstrates superior mechanical performance and autonomous damage remediation. Traditional impact-resistant materials typically absorb 120–150 J/m² of energy, whereas this system is designed to exceed 200 J/m². Additionally, existing self-healing materials recover only 50–60\% of their mechanical properties, while this composite targets an 80\% restoration rate. The modular design ensures seamless integration into existing infrastructure, supporting scalability and standardization.

Beyond its core functions, the composite exhibits several emergent properties: (1) localized reinforcement zones where healing chemistry alters stress distributions, (2) increased energy dissipation efficiency over repeated impact cycles, (3) long-term self-improving feedback where ML-driven adjustments refine material performance, and (4) potential microstructural evolution, such as crystalline phase formation, that enhances impact resistance. These unexpected yet beneficial attributes highlight the adaptive nature of the material system.

The broader implications of this research include significant economic and environmental benefits. By reducing maintenance frequency by 30\%, the composite lowers infrastructure downtime and lifecycle costs. The extended service life translates to a 25–30\% reduction in resource consumption and associated carbon emissions. While the upfront processing cost is higher due to advanced material fabrication and sensor integration, the long-term cost per operational year is projected to be competitive with, or superior to, existing alternatives.

This interdisciplinary fusion of nanomaterials, self-healing chemistry, real-time sensor feedback, and machine learning-based control represents a fundamental shift from passive materials to smart, self-optimizing systems. The proposed research not only addresses impact resistance and self-repair but also pioneers an adaptable, continuously improving infrastructure material. The combination of rigorous experimental validation (e.g., ASTM mechanical testing, finite element modeling, and real-world simulations) ensures that the material’s theoretical advantages translate into practical performance gains. This research positions itself as a transformative solution for infrastructure resilience, bridging the gap between static engineering materials and dynamically intelligent, self-regulating composites.



\section{Conclusion}

This work introduced a framework for recursive graph expansion, demonstrating that self-organizing intelligence-like behavior can emerge through iterative reasoning without predefined ontologies, external supervision, or centralized control. Unlike conventional knowledge graph expansion techniques that rely on static extractions, probabilistic link predictions, or reinforcement learning-based traversal, extensive test-time compute Graph-PReFLexOR graph reasoning actively restructures its own knowledge representation as it evolves, allowing for dynamic adaptation and autonomous knowledge synthesis. These findings are generally in line with other recent results that elucidated the importance of inference scaling methods~\cite{o1-model-card-2024,o3-mini-model-card-2025,geiping2025scalingtesttimecomputelatent,buehler2024preflexorpreferencebasedrecursivelanguage}. 

Through extensive graph-theoretic analysis, we found that the recursively generated knowledge structures exhibit scale-free properties, hierarchical modularity, and sustained interdisciplinary connectivity, aligning with patterns observed in human knowledge systems. The formation of conceptual hubs (Figures~\ref{fig:graph_analysis}-\ref{fig:graph_modularity}) and the emergence of bridge nodes (Figures~\ref{fig:bridge_persistence}) demonstrate that the system autonomously organizes information into a structured yet flexible network, facilitating both local coherence and global knowledge integration. Importantly, the model does not appear to saturate or stagnate; instead, it continuously reorganizes relationships between concepts by reinforcing key conceptual linkages while allowing new hypotheses to emerge through iterative reasoning (Figures~\ref{fig:knowledge_graph_evolution} and \ref{fig:bridge_node_evolution}).

One of the most striking findings is the self-regulation of knowledge propagation pathways. The early stages of graph expansion relied heavily on a few dominant nodes (high betweenness centrality), but over successive iterations, knowledge transfer became increasingly distributed and decentralized (Figure~\ref{fig:betweenness_distribution}). This structural transformation suggests that recursive self-organization naturally reduces bottlenecks, enabling a more resilient and scalable knowledge framework. Additionally, we observed alternating phases of conceptual stability and breakthrough, indicating that knowledge formation follows a punctuated equilibrium model, rather than purely incremental accumulation.

More broadly, the recursive self‐organization process produces emergent, fractal‐like knowledge structures, suggesting that similar principles may underlie both human cognition and the design of intelligent systems~\cite{barabasi1999emergence}. Moreover, the potential role of bridge nodes—as connectors and as natural intervention points—is underscored by their persistent yet shifting influence, implying they could be strategically targeted for system updates or error correction in a self‐organizing network. Additionally, the observed alternating phases of stable community formation punctuated by sudden breakthroughs appear to mirror the concept of punctuated equilibrium in scientific discovery~\cite{kuhn1962structure}, offering a promising framework for understanding the natural emergence of innovation. These insights extend the implications of our work beyond scientific discovery, hinting at broader applications in autonomous reasoning, such as adaptive natural language understanding and real‐time decision‐making in complex environments. We demonstrated a few initial use cases where we used graph structures in attempts towards compositional reasoning, as shown in Figure~\ref{fig:compositional_analysis}.


\subsection{Graph Evolution Dynamics: Interplay of Network Measures}
The evolution of the knowledge graph reveals a complex interplay between growth, connectivity, centralization, and structural reorganization, with different network-theoretic measures exhibiting distinct yet interdependent behaviors over iterations. Initially, the system undergoes rapid expansion, as seen in the near-linear increase in the number of nodes and edges (Figure~\ref{fig:graph_analysis}). However, despite this outward growth, the clustering coefficient stabilizes early (around 0.16), suggesting that the graph maintains a balance between connectivity and modularity rather than devolving into isolated clusters. This stabilization indicates that the system does not expand chaotically but instead integrates new knowledge in a structured and preferentially attached manner, reinforcing key concepts while allowing for exploration.

One of the most informative trends is the evolution of betweenness centrality (Figure~\ref{fig:betweenness_evolution}), which starts highly concentrated in a few key nodes but then redistributes over time, reflecting a transition from hub-dominated information flow to a more decentralized and resilient network. This shift aligns with the gradual stabilization of average shortest path length (around 4.5, see Figure~\ref{fig:shortest_path_distribution}) and the graph diameter (around 16–18 steps, see Figure~\ref{fig:graph_modularity}), implying that while knowledge expands, it remains navigable and does not suffer from excessive fragmentation. Meanwhile, the maximum $k$-core index (Figure~\ref{fig:advanced_graph_analysis}) exhibits a stepwise increase, reflecting structured phases of densification where core knowledge regions consolidate before expanding further. This suggests that the system undergoes punctuated reorganization, where newly introduced concepts occasionally necessitate internal restructuring before further outward growth.

Interestingly, the degree assortativity starts strongly negative (around -0.25) and trends toward neutrality (-0.05), indicating that high-degree nodes initially dominate connections but later distribute their influence, allowing mid-degree nodes to contribute to network connectivity. This effect is reinforced by the persistence of bridge nodes (Figures~\ref{fig:advanced_graph_analysis}-\ref{fig:betweenness_evolution}), where we see a long-tail distribution of interdisciplinary connectors—some nodes serve as transient links that appear briefly, while others persist across hundreds of iterations, indicating stable, high-impact conceptual connectors.

Taken together, these experimentally observed trends suggest that the system self-regulates its expansion, dynamically shifting between growth, consolidation, and reorganization phases. The absence of saturation in key structural properties (such as new edge formation and bridge node emergence) indicates that the model supports continuous knowledge discovery, rather than converging to a fixed-state representation. This emergent behavior, where network-wide connectivity stabilizes while conceptual expansion remains open-ended, suggests that recursive graph reasoning could serve as a scalable foundation for autonomous scientific exploration, adaptive learning, and self-organizing knowledge systems.



\subsection{Relevance in the Context of Materials Science}
The framework introduced in this work offers a novel paradigm for accelerating discovery in materials science by systematically structuring and expanding knowledge networks. Unlike traditional approaches that rely on static databases or predefined ontologies~\cite{buehler2023biomateriomics,tshitoyan2019unsupervised,Buehler2022GeneratingCues,Buehler2023PredictingCapacityb,Brinson2023CommunityResearchb}, our self-organizing method enables dynamic hypothesis generation, uncovering hidden relationships between material properties, synthesis pathways, and functional behaviors. The emergent scale-free networks observed in our experiments reflect the underlying modularity and hierarchical organization often seen in biological and engineered materials, suggesting that recursive graph-based reasoning could serve as a computational analogue to self-assembling and adaptive materials. 
%
Applied to materials design, the  approach developed in this paper could reveal unexpected synergies between molecular architectures and macroscale performance, leading to new pathways for bioinspired, multifunctional, and self-healing materials. Future work can integrate experimental data directly into these reasoning loops, allowing AI-driven materials discovery to move beyond retrieval-focused recognition toward novel inference and innovation. We believe it is essential to bridge the gap between autonomous reasoning and materials informatics to ultimately create self-improving knowledge systems that can adaptively guide materials engineering efforts in real-time~\cite{Stach2021AutonomousPerspective}.

\subsection{Broader Implications}
The observations put forth in this paper have potential implications for AI-driven scientific reasoning, autonomous hypothesis generation, and scientific inquiry. As our results demonstrate, complex knowledge structures can self-organize without explicit goal-setting. This work challenges a prevailing assumption that intelligence requires externally imposed constraints or supervision. Instead, it suggests that intelligent reasoning may emerge as a fundamental property of recursive, feedback-driven information processing, mirroring cognitive processes observed in scientific discovery and human learning. Our experiments that directed the evolution of the thinking mechanisms towards a certain goal were provided with relational modeling that incorporated these concepts in a more pronounced manner, as expected, provisioning a powerful substrate for deeper reasoning. 

Future work could potentially explore extending this framework to multi-agent reasoning environments, cross-domain knowledge synthesis, and real-world applications in AI-driven research discovery. Additionally, refining interpretability mechanisms will be crucial for ensuring that autonomously generated insights align with human epistemic standards, minimizing risks related to misinformation propagation and reasoning biases. Bridging graph-theoretic modeling, AI reasoning, and self-organizing knowledge dynamics, allowed us to provide a step toward building AI systems capable of autonomous, scalable, and transparent knowledge formation on their own.

We note that wile our agentic deep graph reasoning framework demonstrates promise in achieving self-organizing knowledge formation, several challenges remain. In particular, the computational scalability of recursive graph expansions and the sensitivity of emergent structures to parameter choices warrant further investigation. Future work should explore robust error-correction strategies, enhanced interpretability of evolving networks, and ethical guidelines to ensure transparency in autonomous reasoning systems, especially if deployed in commercial or public settings beyond academic research. Addressing these issues will not only refine the current model but also paves the way for its application in real-world autonomous decision-making and adaptive learning environments.


\section{Materials and Methods}

We describe key materials and methods developed and used in the course of this study in this section. 

\subsection{Graph-PReFLexOR model development} 

A detailed account of the Graph-PReFLexOR is provided in \cite{buehler2025insitugraphreasoningknowledge}. Graph-PReFLexOR (Graph-based Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning) is an AI model integrating \textit{in-situ} graph reasoning, symbolic abstraction, and recursive reflection into generative modeling. The model was trained on a set of around 1,000 scientific papers in the biological materials and bio-inspired materials domain, as discussed in \cite{buehler2025insitugraphreasoningknowledge}. We refer readers to the original paper for implementation details, but provide a high-level summary here. The method defines reasoning as a structured mapping:
\begin{equation}
M: T \rightarrow (G, P, A),
\end{equation}
where a given task $T$ generates a knowledge graph $G = (V, E)$ with nodes $V$ representing key concepts and edges $E$ denoting relationships, abstract patterns $P$ capturing structural dependencies, and final answers $A$. Inspired by category theory, the approach encodes knowledge through hierarchical inference, leveraging isomorphisms to generalize across domains. The model autonomously constructs symbolic representations via a reasoning phase marked by \texttt{<|thinking|>} ... \texttt{<|/thinking|>} tokens, refining understanding before generating outputs. Recursive optimization can further improve logical coherence, aligning responses with generalizable principles, a particular feature that will be expanded on in this paper.

To enhance the adaptability of structured reasoning, Graph-PReFLexOR employs an iterative feedback mechanism:
\begin{equation}
R_{i+1} = f_{\text{eval}}(R_i, F_i),
\end{equation}
where $R_i$ denotes the intermediate reasoning at step $i$, $F_i$ is the feedback applied to improve logical structure, and $f_{\text{eval}}$ evaluates alignment with domain principles. The final answer $A$ is derived after $N$ refinements as:
\begin{equation}
A = g(R_N).
\end{equation}
Through the idea to explicitly model knowledge graphs and symbolic representations, this method attempts to bridge connectionist and symbolic paradigms, facilitating multi-step reasoning, hypothesis generation, and interdisciplinary knowledge expansion. Empirical evaluations in~\cite{buehler2025insitugraphreasoningknowledge} demonstrated its capability to generalize beyond training data. In this study, we take advantage of the capability of Graph-PReFLexOR to generate graph representations on the fly over a great number of iterations during which the model continues to expand its reasoning tokens.  

\subsection{Iterative Unconstrained Graph Reasoning on General Topic }

We develop an iterative knowledge extraction pipeline to construct a structured knowledge graph using a LLM, following the flowchart shown in Figure~\ref{fig:fig_01}. The method systematically expands a graph representation of relationships by extracting structured knowledge from model-generated reasoning sequences and generating follow-up queries to refine exploration. We use this method to construct $\mathcal{G_1}$. 

At the start of each run, the algorithm initializes an initial question or prompt. This can be very general or focus on a particular topic that defines the area of scientific inquiry. In the example, the topic is set as:

\begin{LLMbox}{}
\begin{lstlisting}
prompt = "Discuss an interesting idea in bio-inspired materials science."  
\end{lstlisting}
\end{LLMbox}

The LLM then generates structured reasoning responses within the \texttt{<|thinking|>} ... \texttt{<|/thinking|>} tokens. The response is processed to extract structured knowledge by isolating the graph.

To convert the extracted knowledge into a structured representation, the model is queried with an additional instruction to transform the resulting raw text that contains the reasoning graph (denoted by \texttt{\{raw graph\}}) into a Python dictionary formatted for graph representation:

\begin{LLMbox}{}
\begin{lstlisting}
You are an AI that extracts information from structured text and outputs a graph in Python dictionary format compatible with NetworkX. 
Given the following structured text: 
(*@\bf\hlred{\{raw graph\}}@*)
Output the graph as a Python dictionary without any additional text or explanations. Ensure the dictionary is properly formatted for immediate evaluation in Python.
\end{lstlisting}
\end{LLMbox}

The output is parsed and structured using \texttt{ast.literal\_eval()} to construct a directed graph $\mathcal{G}_{\text{local}}^i$ in \texttt{NetworkX}, where nodes represent entities such as materials, properties, and scientific concepts, while edges encode relationships such as \texttt{HAS}, \texttt{INFLUENCES}, and \texttt{SIMILAR-TO}.

At each iteration $i$, the newly extracted knowledge graph is appended to an evolving global graph:
\begin{equation}
\mathcal{G} \leftarrow \mathcal{G} \cup \mathcal{G}_{\text{local}}^i.
\label{eq:graph_rek}
\end{equation}

The extracted structure is parsed using:
\begin{quote}
\texttt{graph\_code, graph\_dict = extract\_graph\_from\_text(graph)}
\end{quote}
The graph is progressively expanded by adding newly introduced nodes and edges, ensuring that redundant relationships are not duplicated. The final knowledge graph is stored in multiple formats, including GraphML for structural analysis and PNG for visualization.

To facilitate continued exploration, a follow-up question is generated at each iteration. The LLM is queried to produce a question that introduces a new aspect of the domain, ensuring an iterative, self-refining process that utilizes the previously generated entities and relations:

\begin{LLMbox}{}
\begin{lstlisting}
Consider this list of topics/keywords. Formulate a creative follow-up question to ask about a totally new concept. 
Your question should include at least one of the original topics/keywords.
Original list of topics/keywords:
(*@\bf\hlred{\{latest extracted entities and relations\}}@*)
Reply only with the new question. The new question is:
\end{lstlisting}
\end{LLMbox}


This ensures that subsequent queries remain contextually grounded in the domain while promoting scientific discovery. The generated question is appended to the reasoning token structure and fed back into the LLM, thereby continuing the iterative learning process.

The algorithm runs for a total of $N$ iterations, progressively refining the knowledge graph. At each step, we track the growth of the graph by recording the number of nodes and edges over time. The final knowledge graph provides a structured and extensible representation of insights extracted from the LLM, enabling downstream analysis of emerging concepts. The reasoning process (Figure~\ref{fig:fig_01}) unfolds sequentially over a period of several days (using a consumer GPU, like NVIDIA A6000 Ada).  


\subsection{Iterative Graph Reasoning on a Particular Topic}

As an alternative to the approach above, we can tailor the reasoning process to focus more strongly on a particular topic. We use this method to construct $\mathcal{G_2}$. For instance, at the beginning of each run, the algorithm is initialized with a user-defined topic:

\begin{LLMbox}{}
\begin{lstlisting}
topic = "impact resistant materials"
\end{lstlisting}
\end{LLMbox}



This variable defines the area of exploration and is dynamically incorporated into the model prompts. The LLM is then queried with a topic-conditioned instruction to generate structured reasoning tokens:

\begin{LLMbox}{}
\begin{lstlisting}
Describe a way to design (*@\bf\hlred{\{topic\}}@*).
\end{lstlisting}
\end{LLMbox}

The model generates textual responses that include explicit reasoning within the \texttt{<|thinking|>} ... \texttt{<|/thinking|>} markers. As before, from this output, we extract structured knowledge by isolating the section labeled graph, to extract entity-relationship pairs. A follow-up question is generated at each iteration to drive the discovery process forward. This prompt ensures that new queries focus on underexplored aspects of the knowledge graph while maintaining the topic-conditioned structure:
 
\begin{LLMbox}{}
\begin{lstlisting}
Consider this list of keywords. Considering the broad topic of (*@\bf\hlred{\{topic\}}@*), formulate a creative follow-up question to ask about a totally new aspect. Your question should include at least one of the original keywords. 
Original list of keywords:
(*@\bf\hlred{\{latest extracted entities and relations\}}@*)
Reply only with the new question. The new question is:
\end{lstlisting}
\end{LLMbox}



This ensures that each iteration remains contextually grounded in the specified domain while continuously expanding the knowledge graph.

The process continues for $N$ steps, progressively refining the knowledge graph. At each iteration, we track the growth of the graph by recording the number of nodes and edges. The resulting knowledge graph serves as a structured repository of insights extracted from the LLM, enabling downstream analysis of materials properties and design principles. 

Naturally, other variants of these strategies could easily be devised, for instance to create other generalist graphs (akin to $\mathcal{G}_1$) or specialized graphs (akin to $\mathcal{G}_2$). Prompt engineering can be human-tailored or developed agentically by other AI systems. 


\subsection{Graph Analysis and Visualization}

Graph analysis and visualizations are conducted using \texttt{NetworkX}~\cite{Networkx/networkx:Python}, Gephi~\cite{ICWSM09154}, Cytoscope~\cite{shannon2003cytoscape}, Mermaid~\url{https://mermaid.js.org/}, and various plugins within these packages. 




\subsubsection{Basic Analysis of Recursive Graph Growth over Reasoning Iterations}

To analyze the recursive expansion of the knowledge graph, we computed a set of graph-theoretic properties at each iteration using the \texttt{NetworkX} Python library. Graph data was stored in GraphML format, with filenames encoded to reflect the iteration number, allowing for chronological tracking of structural changes. Each graph was sequentially loaded and processed to extract key metrics that characterize its connectivity, topology, and hierarchical organization.

The fundamental properties of the graph, including the number of nodes and edges, were directly retrieved from the graph structure. The degree distribution was computed across all nodes to derive the average degree, representing the mean connectivity per node, and the maximum degree, which highlights the most connected node at each iteration. To assess network cohesion, the largest connected component (LCC) was extracted by identifying the largest strongly connected component in directed graphs and the largest connected subgraph in undirected cases. The clustering coefficient was computed using the standard local clustering metric, which quantifies the likelihood that a node’s neighbors are also connected to each other. The average clustering coefficient was obtained by averaging over all nodes in the graph, providing insight into the tendency of local structures to form tightly connected clusters.

To assess global connectivity and efficiency, we computed the average shortest path length (SPL) and the graph diameter within the largest connected component. The SPL was obtained by calculating the mean shortest path distance between all pairs of nodes in the LCC, while the diameter was determined as the longest shortest path observed in the component. Since these calculations are computationally expensive for large graphs, they were conditionally executed only when the LCC was sufficiently small or explicitly enabled in the analysis. For community detection, we applied the Louvain modularity algorithm using the \texttt{community-louvain} package. The graph was treated as undirected for this step, and the modularity score was computed by partitioning the graph into communities that maximize the modularity function. This metric captures the extent to which the graph naturally organizes into distinct clusters over iterations. 

The entire analysis pipeline iterated over a series of GraphML files, extracting the iteration number from each filename and systematically computing these metrics. The results were stored as time series arrays and visualized through multi-panel plots, capturing trends in network evolution. To optimize performance, computationally intensive operations, such as shortest path calculations and modularity detection, were executed conditionally based on graph size and software availability. To further examine the structural evolution of the recursively generated knowledge graph, we computed a set of advanced graph-theoretic metrics over iterative expansions. As before, the analysis was conducted over a series of iterations, allowing for the study of emergent network behaviors.

The degree assortativity coefficient was computed to measure the correlation between node degrees, assessing whether high-degree nodes preferentially connect to similar nodes. This metric provides insight into the network's structural organization and whether its expansion follows a preferential attachment mechanism. The global transitivity, defined as the fraction of closed triplets among all possible triplets, was calculated to quantify the overall clustering tendency of the graph and detect the emergence of tightly interconnected regions. To assess the hierarchical connectivity structure, we performed $k$-core decomposition, which identifies the maximal subgraph where all nodes have at least \( k \) neighbors. We extracted the maximum $k$-core index, representing the deepest level of connectivity within the network, and computed the size of the largest $k$-core, indicating the robustness of highly connected core regions.

For understanding the importance of individual nodes in information flow, we computed average betweenness centrality over the largest connected component. Betweenness centrality quantifies the extent to which nodes serve as intermediaries in shortest paths, highlighting critical nodes that facilitate efficient navigation of the knowledge graph. Since exact computation of betweenness centrality can be computationally expensive for large graphs, it was performed only within the largest component to ensure feasibility. Additionally, we identified articulation points, which are nodes whose removal increases the number of connected components in the network. The presence and distribution of articulation points reveal structural vulnerabilities, highlighting nodes that serve as key bridges between different knowledge regions.


\subsubsection{Prediction of Newly Connected Pairs}

To track the evolution of connectivity in the recursively expanding knowledge graph, we employed a random sampling approach to estimate the number of newly connected node pairs at each iteration. Given the computational cost of computing all-pairs shortest paths in large graphs, we instead sampled a fixed number of node pairs per iteration and measured changes in their shortest path distances over time.

\textbf{Sampling Strategy.} At each iteration, we randomly selected 1,000 node pairs from the current set of nodes in the global knowledge graph. For each sampled pair \((u, v)\), we computed the shortest path length in the graph using Breadth-First Search (BFS), implemented via \texttt{nx.single\_source\_shortest\_path\_length(G, src)}. If a path existed, its length was recorded; otherwise, it was marked as unreachable.

\textbf{Tracking Newly Connected Pairs.} To detect the formation of new connections, we maintained a record of shortest path distances from the previous iteration and compared them with the current distances. A pair \((u, v)\) was classified as:
\begin{itemize}
    \item \textbf{Newly connected} if it was previously unreachable (\(\text{dist}_\text{before} = \text{None}\)) but became connected (\(\text{dist}_\text{now} \neq \text{None}\)).
    \item \textbf{Having a shorter path} if its shortest path length decreased between iterations (\(\text{dist}_\text{now} < \text{dist}_\text{before}\)).
\end{itemize}
The number of newly connected pairs and the number of pairs with shortened paths were recorded for each iteration.

\textbf{Graph Integration and Visualization.} At each iteration, the newly processed graph was merged into a global knowledge graph, ensuring cumulative analysis over time. The number of newly connected pairs per iteration was plotted as a time series, revealing patterns in connectivity evolution. This method effectively captures structural transitions, particularly the initial burst of connectivity formation followed by a steady-state expansion phase, as observed in the results.

By employing this approach, we achieved a computationally efficient yet statistically robust estimate of network connectivity evolution, allowing us to analyze the self-organizing dynamics of the reasoning process over large iterative expansions.



\subsubsection{Graph Structure and Community Analysis}

To examine the structural properties of the recursively generated knowledge graph, we performed a comprehensive analysis of node connectivity, degree distribution, clustering behavior, shortest-path efficiency, and community structure. The graph was loaded from a \texttt{GraphML} file using the \texttt{NetworkX} library, and various metrics were computed to assess both local and global network properties.

\textbf{Basic Graph Properties.} The fundamental characteristics of the graph, including the number of nodes, edges, and average degree, were extracted. Additionally, the number of self-loops was recorded to identify redundant connections that may influence network dynamics.

\textbf{Graph Component Analysis.} To ensure robust connectivity analysis, the largest connected component (LCC) was extracted for undirected graphs, while the largest strongly connected component (SCC) was used for directed graphs. This ensured that further structural computations were performed on a fully connected subgraph, avoiding artifacts from disconnected nodes.

\textbf{Degree Distribution Analysis.} The degree distribution was computed and visualized using both a linear-scale histogram and a log-log scatter plot. The latter was used to assess whether the network exhibits a power-law degree distribution, characteristic of scale-free networks.

\textbf{Clustering Coefficient Analysis.} The local clustering coefficient, which quantifies the tendency of nodes to form tightly connected triads, was computed for each node. The distribution of clustering coefficients was plotted, and the average clustering coefficient was recorded to evaluate the extent of modular organization within the network.

\textbf{Centrality Measures.} Three centrality metrics were computed to identify influential nodes:
(i) \textit{Betweenness centrality}, which measures the extent to which nodes act as intermediaries in shortest paths, highlighting key connectors in the knowledge graph;
(ii) \textit{Closeness centrality}, which quantifies the efficiency of information propagation from a given node;
(iii) \textit{Eigenvector centrality}, which identifies nodes that are highly influential due to their connections to other high-importance nodes.

\textbf{Shortest Path Analysis.} The average shortest path length (SPL) and graph diameter were computed to evaluate the network’s navigability. Additionally, a histogram of sampled shortest path lengths was generated to analyze the distribution of distances between randomly selected node pairs (2,000 samples used).

\textbf{Community Detection and Modularity.} The Louvain modularity algorithm was applied (if available) to partition the network into communities and assess its hierarchical structure. The modularity score was computed to quantify the strength of the detected community structure, and the resulting partitions were visualized using a force-directed layout.

\subsubsection{Analysis of Conceptual Breakthroughs}

The evolution of knowledge graphs is analyzed by processing a sequence of graph snapshots stored in \texttt{GraphML} format. Each graph is indexed by an iteration number, extracted using a regular expression from filenames of the form \texttt{graph\_iteration\_\#.graphml}. The graphs are sequentially loaded and processed to ensure consistency across iterations. If the graph is directed, it is converted to an undirected format using the \texttt{networkx.to\_undirected()} function. To ensure structural integrity, we extract the largest connected component using the \texttt{networkx.connected\_components()} function, selecting the subgraph with the maximum number of nodes.

For each iteration \( t \), we compute the degree distribution of all nodes in the largest connected component. The degree of a node \( v \) in graph \( G_t = (V_t, E_t) \) is given by:
\begin{equation}
d_t(v) = \sum_{u \in V_t} A_t(v, u)
\end{equation}
%
where \( A_t \) is the adjacency matrix of \( G_t \). The computed degree distributions are stored in a dictionary and later aggregated into a pandas \texttt{DataFrame} for further analysis.

To track the emergence of top hubs, we define a node \( v \) as a hub if it attains a high degree at any iteration. The set of top hubs is determined by selecting the nodes with the highest maximum degree across all iterations:
\[
H = \{ v \mid \max_t d_t(v) \geq d_{\text{top}, 10} \}
\]
where \( d_{\text{top}, 10} \) is the degree of the 10th highest-ranked node in terms of maximum degree. The degree growth trajectory of each hub is then extracted by recording \( d_t(v) \) for all \( t \) where \( v \in V_t \).

To quantify the emergence of new hubs, we define an emergence threshold \( d_{\text{emerge}} = 5 \), considering a node as a hub when its degree first surpasses this threshold. The first significant appearance of a node \( v \) is computed as:
\[
t_{\text{emerge}}(v) = \min \{ t \mid d_t(v) > d_{\text{emerge}} \}
\]
for all \( v \) where such \( t \) exists. The histogram of \( t_{\text{emerge}}(v) \) across all nodes provides a temporal distribution of hub emergence.

To evaluate global network connectivity, we compute the mean degree at each iteration:
\begin{equation}
\bar{d}_t = \frac{1}{|V_t|} \sum_{v \in V_t} d_t(v)
\end{equation}
capturing the overall trend in node connectivity as the knowledge graph evolves.

Three key visualizations are generated: (1) the degree growth trajectories of top hubs, plotted as \( d_t(v) \) over time for \( v \in H \); (2) the emergence of new hubs, represented as a histogram of \( t_{\text{emerge}}(v) \); and (3) the overall network connectivity, visualized as \( \bar{d}_t \) over iterations.  



\subsubsection{Structural Evolution of the Graphs: Knowledge Communities, Bridge Nodes and Multi-hop Reasoning}

We analyze the structural evolution of knowledge graphs by computing three key metrics: (1) the number of distinct knowledge communities over time, (2) the emergence of bridge nodes that connect different knowledge domains, and (3) the depth of multi-hop reasoning based on shortest path lengths. These metrics are computed for each iteration \( t \) of the evolving graph and visualized as follows.

The evolution of knowledge communities is measured using the Louvain modularity optimization algorithm, implemented via \texttt{community.best\_partition()}, which partitions the graph into distinct communities. For each iteration, the number of detected communities \( |C_t| \) is computed as:
\[
|C_t| = |\{ c \mid c = P_t(v), v \in V_t \}|
\]
where \( P_t(v) \) maps node \( v \) to its assigned community at iteration \( t \). The values of \( |C_t| \) are plotted over iterations to track the subdivision and merging of knowledge domains over time.

The emergence of bridge nodes, nodes that connect multiple communities, is determined by examining the community affiliations of each node's neighbors. A node \( v \) is classified as a bridge node if:
\[
|\mathcal{C}(v)| > 1, \quad \text{where} \quad \mathcal{C}(v) = \{ P_t(u) \mid u \in N(v) \}
\]
and \( N(v) \) represents the set of neighbors of \( v \). The number of bridge nodes is computed per iteration and plotted to analyze how interdisciplinary connections emerge over time.

The depth of multi-hop reasoning is quantified by computing the average shortest path length for the largest connected component at each iteration:
\[
L_t = \frac{1}{|V_t| (|V_t| - 1)} \sum_{v,u \in V_t, v \neq u} d_{\text{sp}}(v, u)
\]
where \( d_{\text{sp}}(v, u) \) is the shortest path distance between nodes \( v \) and \( u \), computed using \texttt{networkx.average\_shortest\_path\_length()}. This metric captures the evolving complexity of conceptual reasoning chains in the knowledge graph.

We generate three plots: (1) the evolution of knowledge communities, visualizing \( |C_t| \) over time; (2) the emergence of bridge nodes, displaying the number of inter-community connectors per iteration; and (3) the depth of multi-hop reasoning, tracking \( L_t \) as a function of iteration number.  


To analyze the temporal stability of bridge nodes in the evolving knowledge graph, we compute the persistence of bridge nodes, which quantifies how long individual nodes function as bridges across multiple iterations. Given the bridge node set \( B_t \) at iteration \( t \), the persistence count for a node \( v \) is defined as:
\[
P(v) = \sum_{t} \mathbb{1} (v \in B_t)
\]
where \( \mathbb{1}(\cdot) \) is the indicator function that equals 1 if \( v \) appears as a bridge node at iteration \( t \), and 0 otherwise. This metric captures the frequency with which each node serves as a conceptual connector between different knowledge domains.

To visualize the distribution of bridge node persistence, we construct a histogram of \( P(v) \) across all detected bridge nodes, with kernel density estimation (KDE) applied for smoother visualization. The histogram provides insight into whether bridge nodes are transient or persist over multiple iterations.

The persistence values are computed and stored in a structured dataset, which is then used to generate a plot of the histogram of bridge node persistence.  


%\subsubsection{Methods}
\noindent To analyze the temporal dynamics of bridge node emergence, we construct a binary presence matrix that tracks when individual nodes first appear as bridges. The matrix is used to visualize the earliest bridge nodes over time, capturing the structural formation of key conceptual connectors.

The binary presence matrix is defined as follows. Given a set of bridge node lists \( B_t \) for each iteration \( t \), we construct a matrix \( M \) where each row corresponds to an iteration and each column corresponds to a unique bridge node. The matrix entries are:
\[
M_{t,v} =
\begin{cases}
1, & v \in B_t \\
0, & \text{otherwise}
\end{cases}
\]
where \( M_{t,v} \) indicates whether node \( v \) appears as a bridge at iteration \( t \). The full set of unique bridge nodes across all iterations is extracted to define the columns of \( M \).

To identify the earliest appearing bridge nodes we compute the first iteration in which each node appears:
\[
t_{\text{first}}(v) = \min \{ t \mid M_{t,v} = 1 \}
\]
The top 100 earliest appearing bridge nodes are selected by ranking nodes based on \( t_{\text{first}}(v) \), keeping those with the smallest values. The binary matrix is then restricted to these nodes.

To capture early-stage network formation, the analysis is limited to the first 200 iterations, ensuring that the onset of key bridge nodes is clearly visible. The final presence matrix \( M' \) is reordered so that nodes are sorted by their first appearance, emphasizing the sequential nature of bridge formation.

The matrix is visualized as a heatmap (Figure~\ref{fig:sorted_bridge_heatmap}), where rows correspond to the top 100 earliest appearing bridge nodes and columns represent iterations. A blue-scale colormap is used to indicate presence (darker shades for active nodes).  

To analyze the evolution of key bridge nodes in the knowledge graph, we compute and track the betweenness centrality of all nodes across multiple iterations. Betweenness centrality quantifies the importance of a node as an intermediary in shortest paths and is defined as:
\[
C_B(v) = \sum_{s \neq v \neq t} \frac{\sigma_{st}(v)}{\sigma_{st}}
\]
where \( \sigma_{st} \) is the total number of shortest paths between nodes \( s \) and \( t \), and \( \sigma_{st}(v) \) is the number of those paths that pass through \( v \). This measure is recalculated at each iteration to observe structural changes in the network.

The computational procedure is as follows:  
\begin{enumerate}
    \item Graph Loading: Graph snapshots are loaded from GraphML files, indexed by iteration number. If a graph is directed, it is converted to an undirected format using \texttt{networkx.to\_undirected()} to ensure consistent betweenness computations.
    \item Betweenness Centrality Calculation: For each graph \( G_t \) at iteration \( t \), the betweenness centrality for all nodes is computed using \texttt{networkx.betweenness\_centrality()}.
    \item Time Series Construction: The computed centrality values are stored in a time-series matrix \( B \), where rows correspond to iterations and columns correspond to nodes:
     \[
     B_{t,v} = C_B(v) \quad \forall v \in V_t
     \]
     Missing values (nodes absent in certain iterations) are set to zero to maintain a consistent matrix structure.
\end{enumerate}

To identify key bridge nodes, we extract the top ten nodes with the highest peak betweenness at any iteration:
\[
H = \{ v \mid \max_t B_{t,v} \geq B_{\text{top}, 10} \}
\]
where \( B_{\text{top}, 10} \) represents the 10th highest betweenness value recorded across all iterations. The time-series data is filtered to retain only these nodes.

To visualize the dynamic role of key bridge nodes, we generate a line plot of betweenness centrality evolution where each curve represents the changing centrality of a top bridge node over iterations. This graph captures how structural importance fluctuates over time.  





\subsection{Agentic Approach to Reason over Longest Shortest Paths}
\label{methods:agentic_longest_shortest}

We employ an agentic approach to analyze structured knowledge representations in the form of a graph \( G = (V, E) \), where \( V \) represents the set of nodes (concepts) and \( E \) represents the set of edges (relationships). The methodology consists of four primary steps: (i) extraction of the longest knowledge path, (ii) decentralized node and relationship reasoning, (iii) multi-agent synthesis, and (iv) structured report generation.

\textbf{Path Extraction.} The input knowledge graph \( G \) is first converted into an undirected graph \( G' = (V, E') \) where \( E' \) contains bidirectional edges to ensure reachability across all nodes. We extract the largest connected component \( G_c \) by computing:
\[
G_c = \arg\max_{S \in \mathcal{C}(G')} |S|
\]
where \( \mathcal{C}(G') \) is the set of all connected components in \( G' \). The longest shortest path, or \textit{diameter path}, is determined by computing the eccentricity:
\[
\epsilon(v) = \max_{u \in V} d(v, u),
\]
where \( d(v, u) \) is the shortest path length between nodes \( v \) and \( u \). The source node is selected as \( v^* = \arg\max_{v \in V} \epsilon(v) \), and the farthest reachable node from \( v^* \) determines the longest path.

Numerically, the longest paths are determined by computing node eccentricities using \texttt{networkx.eccentricity()}, which identifies the most distant node pairs in terms of shortest paths. The five longest shortest paths are extracted with \texttt{networkx.shortest\_path()}. For each extracted path, we assign node-level structural metrics computed from the original graph. The node degree is obtained using \texttt{networkx.degree()}, betweenness centrality is computed with \texttt{networkx.betweenness\_centrality()}, and closeness centrality is determined via \texttt{networkx.closeness\_centrality()}. Each identified path is saved as a GraphML file using \texttt{networkx.write\_graphml()} with these computed node attributes for further analysis.

\textbf{Decentralized Node and Relationship Reasoning.} Each node \( v_i \in V \) and each relationship \( e_{ij} \in E \) along the longest path is analyzed separately. A language model \( f_{\theta} \) is prompted with:
\[
\text{LLM}(v_i) = f_{\theta}(\text{``Analyze concept } v_i \text{ in a novel scientific context."})
\]
for nodes, and
\[
\text{LLM}(e_{ij}) = f_{\theta}(\text{``Analyze relationship } e_{ij} \text{ and hypothesize new implications."})
\]
for relationships. This enables independent hypothesis generation at the atomic level.

\textbf{Multi-Agent Synthesis.} The set of independent insights \( \mathcal{I} = \{ I_1, I_2, \dots \} \) is aggregated, and a final inference step is performed using:
\[
I_{\text{final}} = f_{\theta}(\text{``Synthesize a novel discovery from } \mathcal{I} \text{."})
\]
This allows the model to infer higher-order patterns beyond individual node-relationship reasoning.

\textbf{Structured Report Generation.} The final response, along with intermediate insights, is formatted into a structured markdown report containing:
\begin{itemize}
    \item The extracted longest path
    \item Individual insights per node and relationship
    \item The final synthesized discovery
\end{itemize}
This approach leverages multi-step reasoning and recursive inference, allowing for emergent discoveries beyond explicit graph-encoded knowledge.


\subsubsection{Agent-driven Compositional Reasoning}
\label{methods:agentic_compositional}
We employ a multi-step agentic approach that couples LLMs with graph-based compositional reasoning. To develop such an approach, we load the graph and locate its largest connected component. We compute eccentricities to identify two far-apart nodes, then extract the longest shortest path between them. Each node in that path becomes a ``building block,'' for which the LLM provides a concise definition, principles, and a property conducive to synergy (Step A). Next, we prompt the LLM to create pairwise synergies by merging adjacent building blocks, encouraging a short, compositional statement that unifies the nodes' respective features (Step B). To deepen the layering of ideas, we consolidate multiple synergy statements into bridge synergies that capture cross-cutting themes (Step C). Finally, we issue a more elaborate prompt asking the LLM to integrate all building blocks and synergies into an expanded, coherent ``final discovery,'' referencing both prior statements and each node's defining traits (Step D). This process yields a multi-step compositional approach, wherein each synergy can build on earlier results to reveal increasingly sophisticated connections. The initial steps A-C are carried out using \url{meta-llama/Llama-3.2-3B-Instruct}, whereas the final integration of the response in Step D is conducted using \url{meta-llama/Llama-3.3-70B-Instruct}. We also experimented with other models, such as \texttt{o1-pro} as discussed in the main text. 


 


\subsection{Scale free analysis}

To determine whether a given network exhibits scale-free properties, we analyze its degree distribution using the power-law fitting method implemented in the \texttt{powerlaw} Python package. The algorithm extracts the degree sequence from the input graph and fits a power-law distribution, estimating the exponent \(\alpha\) and lower bound \(x_{\min}\). To assess whether the power-law is a preferable fit, we compute the log-likelihood ratio (LR) between the power-law and an exponential distribution, along with the corresponding $p$-value. A network is classified as scale-free if LR is positive and \(p < 0.05\), indicating statistical support for the power-law hypothesis. The method accounts for discrete degree values and excludes zero-degree nodes from the fitting process.


\subsection{Audio Summary in the Form of a Podcast}
Supplementary Audio A1 presents an audio summary of this paper in the style of a podcast, created using PDF2Audio (\url{https://huggingface.co/spaces/lamm-mit/PDF2Audio}~\cite{ghafarollahi2024sciagentsautomatingscientificdiscovery}). The audio format in the form a conversation enables reader to gain a broader understanding of the results of this paper, including expanding the broader impact of the work. The transcript was generated using the \texttt{o3-mini} model~\cite{o3-mini-model-card-2025} from the final draft of the paper.



\section*{Code, data and model weights availability}

Codes, model weights and additional materials are available at \url{https://huggingface.co/lamm-mit} and \url{https://github.com/lamm-mit/PRefLexOR}. The model used for the experiments is available at~\url{lamm-mit/Graph-Preflexor_01062025}. 

\section*{Conflicts of Interest}

The author declares no conflicts of interest of any kind. 

\section*{Acknowledgments}

The author acknowledges support from the MIT Generative AI initiative. 

%\bibliographystyle{unsrtnat}
\bibliographystyle{naturemag}

\bibliography{references,references-Mendeley}  



\clearpage
% Start the appendix
\appendix
\renewcommand{\thesection}{S\arabic{section}}
\renewcommand{\thefigure}{S\arabic{figure}}
\renewcommand{\thetable}{S\arabic{table}}
\renewcommand{\thetextbox}{S\arabic{textbox}}

% Reset counters for the appendix
\setcounter{section}{0}
\setcounter{figure}{0}
\setcounter{table}{0}
\setcounter{textbox}{0}

\newpage
%\vspace{4cm}

\section*{\vspace{1cm} \centering \Large  \sffamily \\ \textbf{Supplementary Information}}
\vspace{4cm}


\begin{center}
    {\LARGE\sffamily  \textbf{Agentic Deep Graph Reasoning Yields Self-Organizing Knowledge Networks }} \\[1em] 
    
\end{center}

\vspace{3cm}


\begin{center}
    {\large Markus J. Buehler} \\[1.em]  

    Laboratory for Atomistic and Molecular Mechanics\\Center for Computational Science and Engineering \\
        Schwarzman College of Computing \\
	Massachusetts Institute of Technology\\
	Cambridge, MA 02139, USA \\
[0.5em]
    
    {\normalsize mbuehler@MIT.EDU}
\end{center}



\clearpage


\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{fig_2000_C.pdf}
    \caption{Knowledge graph $\mathcal{G_1}$ after around 1,000 iterations, under a flexible self-exploration scheme initiated with the prompt \texttt{Discuss an interesting idea in bio-inspired materials science.}. In this visualization, nodes/edges are colored according to cluster ID.}
    \label{fig:fig_2000_C}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{fig_2001_C.pdf}
    \caption{Knowledge graph $\mathcal{G_2}$ after around 500 iterations, under a topic-specific self-exploration scheme initiated with the prompt \texttt{Describe a way to design impact resistant materials}. Nodes/edges are colored according to cluster ID.} 
    \label{fig:fig_2001_C}
\end{figure}



\clearpage
 

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{fig_113.pdf}
    \caption{Distribution of betweenness centrality across four iterations, $\mathcal{G_1}$. The $y$-axis is in log scale, indicating the number of nodes with a given centrality value. The evolution suggests a transition from an early centralized state to a more distributed knowledge structure in later iterations.}
    \label{fig:betweenness_distribution}
\end{figure}

\clearpage

\begin{table}[h!]
\centering
\begin{tabular}{|p{3cm}|p{6cm}|p{6cm}|}
\hline
\textbf{Metric} & \textbf{Response 1 (reasoning wit graph data)} & \textbf{Response 2 (reasoning without graph data)} \\ \hline
Graph Utilization & 5/5 (Explicit use of graph-based insights for material selection and optimization) & 0/5 (No reference to graph data) \\ \hline
Depth of Reasoning & 4/5 (Multi-step reasoning including AI/ML integration, degradation adaptability, and bioinspiration) & 3/5 (Structured approach but mostly standard materials science reasoning) \\ \hline
Scientific Rigor & 4/5 (Logical relationships between material properties, AI/ML, and impact resistance) & 4/5 (Follows well-established materials science principles with clear reasoning) \\ \hline
Innovativeness & 5/5 (Proposes unique ideas such as AI/ML-driven discovery, urban ecosystems, and adaptive materials) & 3/5 (Uses conventional material design strategies without novel insights) \\ \hline
\textbf{Overall Score} & \textbf{18/20} (Superior interdisciplinary and computational approach) & \textbf{10/20} (Limited to conventional material design strategies) \\ \hline
\end{tabular}
\caption{Comparison of Responses on Impact-Resistant Material Design with Annotated Scores. Response 1 achieves a higher score due to its interdisciplinary approach, explicit graph-based insights, and innovative integration of AI/ML.}
\label{tab:response_comparison}
\end{table}

\clearpage
 
\textboxcaption{Answer of the graph-reasoning model to the task \texttt{Describe a way to design impact resistant materials.} In this case, we extract key insights from a knowledge graph using centrality measures, Louvain community detection, and key relationship identification, integrating structured graph-based context into LLM prompts to enhance reasoning and evaluate response quality.}
\label{TexBox:graph-response}

\begin{LLMbox}{Answer of the graph-reasoning model}
\begin{lstlisting}
Based on the knowledge graph insights, I will outline a design strategy for impact-resistant materials.

**Design Strategy:**

1. **Material Selection and Optimization**: Utilize advanced materials science and machine learning algorithms to identify and optimize materials with inherent impact resistance properties. This can be achieved by analyzing the relationships between materials, their properties, and impact resistance.

2. **Self-Healing Materials**: Incorporate self-healing materials into the design, which can repair cracks and damages autonomously. This can be achieved through the use of microcapsules, polymers, or other materials that can release healing agents in response to impact.

3. **Adaptive Materials**: Design materials that can adapt to changing environmental conditions, such as temperature, humidity, or pressure. This can be achieved through the use of shape-memory alloys, polymers, or other materials that can change their properties in response to external stimuli.

4. **Urban Ecosystems Integration**: Incorporate urban ecosystems into the design, which can provide a natural source of inspiration for impact-resistant materials. For example, studying the properties of urban algae farms or the self-healing properties of certain plants can inform the design of impact-resistant materials.

5. **Artificial Intelligence (AI) and Machine Learning (ML) Integration**: Utilize AI and ML algorithms to analyze data from various sources, such as sensor data, material properties, and environmental conditions. This can help identify patterns and trends that can inform the design of impact-resistant materials.

6. **Material Degradation and Adaptability**: Design materials that can adapt to material degradation over time. This can be achieved through the use of materials that can self-heal, self-repair, or self-renew.

**Key Materials and Technologies:**

1. **Shape-Memory Alloys (SMAs)**: SMAs can be used to create adaptive materials that can change their properties in response to external stimuli.
2. **Polymers**: Polymers can be used to create self-healing materials that can repair cracks and damages autonomously.
3. **Graphene**: Graphene can be used to create ultra-strong and lightweight materials with high impact resistance.
4. **Nanomaterials**: Nanomaterials can be used to create materials with enhanced impact resistance and self-healing properties.

**Design Considerations:**

1. **Material Properties**: Consider the material properties, such as strength, stiffness, and toughness, when designing impact-resistant materials.
2. **Environmental Conditions**: Consider the environmental conditions, such as temperature, humidity, and pressure, when designing impact-resistant materials.
3. **Scalability**: Consider the scalability of the design, including the ability to manufacture and deploy the material at large scales.
4. **Cost-Effectiveness**: Consider the cost-effectiveness of the design, including the cost of materials, manufacturing, and deployment.

By following this design strategy, impact-resistant materials can be designed that are optimized for performance, scalability, and cost-effectiveness.
\end{lstlisting}
\end{LLMbox}



\clearpage
 
\textboxcaption{Answer of the base model to the task \texttt{Describe a way to design impact resistant materials.}}
\label{TexBox:base-response}

\begin{LLMbox}{Answer of the base model}
\begin{lstlisting}
Designing impact-resistant materials involves creating materials that can absorb and distribute the energy of an impact, reducing the likelihood of damage or failure. Here's a step-by-step approach to designing impact-resistant materials:

1. **Material Selection**: Choose a material with inherent properties that can absorb and dissipate energy, such as:
	* High-density materials (e.g., metals, ceramics)
	* Viscoelastic materials (e.g., rubber, polymers)
	* Energy-absorbing materials (e.g., foam, composites)
2. **Microstructure Optimization**: Design the material's microstructure to optimize energy absorption:
	* Create a hierarchical structure with multiple scales (e.g., nanoparticles, microparticles, macroscopic particles)
	* Incorporate defects or irregularities to increase the material's energy-absorbing capacity
	* Use phase transformations or phase changes to absorb energy
3. **Material Properties Engineering**: Engineer the material's properties to enhance its impact resistance:
	* Increase the material's stiffness and strength to resist deformation
	* Improve the material's toughness by increasing its energy-absorbing capacity
	* Enhance the material's viscoelastic properties to absorb and dissipate energy
4. **Composite Materials**: Design composite materials that combine different materials to achieve enhanced impact resistance:
	* Use a matrix material (e.g., polymer, metal) to bind together reinforcement materials (e.g., fibers, particles)
	* Incorporate energy-absorbing materials (e.g., foam, rubber) into the composite
	* Use a hierarchical structure to optimize energy absorption
5. **Testing and Validation**: Test and validate the material's impact resistance using standardized tests (e.g., Charpy impact test, Izod impact test):
	* Measure the material's energy absorption capacity
	* Evaluate the material's ability to withstand different types of impacts (e.g., drop, impact, penetration)
6. **Scaling and Optimization**: Scale up the material design and optimize it for specific applications:
	* Use computational models (e.g., finite element analysis, molecular dynamics) to simulate the material's behavior under impact
	* Optimize the material's design for specific applications (e.g., aerospace, automotive, sports equipment)

Some examples of impact-resistant materials include:

* Kevlar-reinforced polymers
* Carbon fiber-reinforced polymers
* High-density polyethylene (HDPE) foam
* Rubber-based composites
* Ceramic matrix composites

By following these steps, designers can create impact-resistant materials that can withstand various types of impacts and reduce the risk of damage or failure.
\end{lstlisting}
\end{LLMbox}



\clearpage
 
\begin{figure}[h]
    \centering
    \includegraphics[width=.9\textwidth]{fig_401_V7.pdf}
    \caption{Evolution of key structural properties in the recursively generated knowledge graph ($\mathcal{G_2}$, focused on \texttt{Describe a way to design impact resistant materials.}): (a) Louvain modularity, showing stable community formation; (b) average shortest path length, highlighting efficient information propagation; and (c) graph diameter, demonstrating bounded hierarchical expansion.}
    \label{fig:graph_modularity_V7}
\end{figure}

\clearpage

\begin{figure}[h]
    \centering
    \includegraphics[width=.9\textwidth]{fig_400_V7.pdf}
    \caption{Evolution of graph properties over recursive iterations, highlighting the emergence of hierarchical structure, hub formation, and adaptive connectivity (Graph $\mathcal{G_2}$, focused on \texttt{Describe a way to design impact resistant materials.}).}
    \label{fig:graph_analysis_V7}
\end{figure}

\clearpage
\hypertarget{supporting_text_1}{\includepdf[pages=-]{discovery_sample.pdf}}

\clearpage
\hypertarget{supporting_text_2}{\includepdf[pages=-]{compositional_1_20250217_140156.pdf}}


\clearpage
\hypertarget{supporting_text_3}{\includepdf[pages=-]{compositional_2_20250217_140156_o1-pro.pdf}}

\clearpage
\hypertarget{supporting_text_4}{\includepdf[pages=-]{proposal_1.pdf}}



\end{document}
