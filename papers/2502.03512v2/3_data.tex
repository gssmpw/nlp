


\section{YinYangAlign: Dataset and Annotation}

The development of YinYangAlign employs a carefully designed annotation pipeline to enable a comprehensive evaluation of T2I systems. To overcome the inherent stochasticity of T2I models and the subjective complexities of visual alignment, we propose a hybrid annotation pipeline. This pipeline leverages advanced vision-language models (VLMs) for automated identification of misalignments, augmented by meticulous human validation to ensure scalability and reliability. This hybrid strategy ensures scalability while maintaining high annotation reliability, resulting in a robust and reliable benchmark. The subsequent sections outline the models, data sources, and annotation methodology utilized in the creation of YinYangAlign.






\textbf{T2I Models Utilized}: For our data creation, we utilize state-of-the-art T2I models such as
%Stable Diffusion 2.1 \cite{rombach2022high}, Stable Diffusion 3 \cite{esser2024scaling}, 
Stable Diffusion XL \cite{podell2023sdxl}, %DALL-E 3 \cite{betker2023improving}, 
and Midjourney 6 \cite{Midjourney2024}. 

\textbf{Prompt Sources}: To construct the YinYang dataset, we strategically selected diverse datasets to cover  the six contradictory alignment axioms. For the first three axioms—\textit{Faithfulness to Prompt vs. Artistic Freedom}, \textit{Emotional Impact vs. Neutrality}, and \textit{Visual Realism vs. Artistic Freedom}—we utilized the MS COCO dataset~\cite{lin2014microsoft}. The \textit{Originality vs. Referentiality} axiom drew upon Google's Conceptual Captions dataset~\cite{sharma2018conceptual}, while the \textit{Verifiability vs. Artistic Freedom} axiom relied on the FACTIFY 3M dataset~\cite{chakraborty-etal-2023-factify3m}. Finally, for \textit{Cultural Sensitivity vs. Artistic Freedom}, we employed the Facebook Hate Meme Challenge~\cite{DBLP:journals/corr/abs-2005-04790} and Memotion datasets~\cite{sharma-etal-2020-semeval}, with careful filtering to ensure inclusion of culturally sensitive data points.
 



\subsection{Annotation Pipeline}
Annotation process involves the following steps:

\begin{enumerate}
    \item \textbf{Multiple Outputs per Prompt:}  To account for the stochastic nature of T2I systems, we generate 10 distinct outputs for each prompt to capture the variability in the generated visuals. 
    \cref{fig:stochastic_generation} illustrates an example of how the same prompt can produce diverse images due to this inherent randomness.

    
    \item \textbf{Automated Annotation Using VLMs:}  
    We employ two VLMs: \textbf{GPT-4o} \cite{openai2023gpt4} and \textbf{LLaVA} \cite{liu2023visualinstruction}, to annotate the generated images. The annotation is guided by the following prompt. See more examples of prompts in \cref{sec:appendix:dataset}.  

\begin{lstlisting}[
    basicstyle=\scriptsize\ttfamily,
    xleftmargin=0.05\columnwidth,
    xrightmargin=0.05\columnwidth
]
Faithfulness to Prompt vs. Artistic Freedom and Given the textual description (prompt) 
and an image, evaluate the alignment of the image.

Instructions:
1. Faithfulness to Prompt: Evaluate how well the image adheres to the user's prompt. 
2. Artistic Freedom: Assess if the image introduces creative or artistic elements 
   that deviate from, enhance, or reinterpret the original prompt. 
3. Identify if artistic freedom significantly compromises faithfulness to the prompt.

Output Format: Faithfulness Score (1-5), Artistic Freedom Score (1-5), Observations (Text).
\end{lstlisting}


% \begin{lstlisting}[basicstyle=\scriptsize\ttfamily]
% Faithfulness to Prompt vs. Artistic Freedom and Given the textual description (prompt) and an image, evaluate the alignment of the image.

% Instructions:
% 1. Faithfulness to Prompt: Evaluate how well the image adheres to the user's prompt. 
% 2. Artistic Freedom: Assess if the image introduces creative or artistic elements that deviate from, enhance, or reinterpret the original prompt. 
% 3. Identify if artistic freedom significantly compromises faithfulness to the prompt. 

% Output Format: Faithfulness Score (1-5), Artistic Freedom Score (1-5), Observations (Text).
% \end{lstlisting}
\vspace{-2mm}
    
   \item \textbf{Consensus Filtering:} To improve annotation reliability, we utilized LLaVA-Critic \cite{xiong2024llavacriticlearningevaluatemultimodal} and Prometheus-Vision \cite{lee2024prometheusvisionvisionlanguagemodeljudge}, for independently scoring of each generated image. Since these models are fine-tuned on pointwise and/or pairwise ranking data, they are specialized for grading tasks. This fine-tuning enables them to consistently and effectively assess the quality and relevance of generated content. Images were selected for human verification only when both VLMs produced consistent annotations, specifically when the scores for a given axiom were $\geq 3$. This approach ensured higher confidence in the automated annotation process before proceeding to manual review.  

    \item \textbf{Human Verification:}  
    Ten human annotators evaluated approximately 50,000 images flagged by the VLMs. To measure inter-annotator agreement, a subset of 5,000 images was annotated by all 10 annotators, achieving a kappa score of 0.83, demonstrating high consistency and reliability in the annotation process. During the manual review, approximately 10,000 images were discarded due to quality issues, resulting in the final YinYangAlign benchmark consisting of 40,000 high-quality images. \cref{fig:annotation_agreement_heatmap} presents the kappa scores comparing agreement levels between human annotators and machine (VLM) evaluations across six contradictory alignment axioms, highlighting areas of alignment and divergence. The entire annotation process, including model-based tagging and human verification, spanned 11 weeks. cf \cref{sec:appendix:dataset}. 


\end{enumerate}

\vspace{-4mm}

\begin{figure*}[h!]
    \centering
    \includegraphics[width=\textwidth]{img/heatmap.pdf}
    \vspace{-6mm}
    \caption{\textit{Annotation Agreement Heatmap}: The VLM column represents the kappa score indicating the average agreement between GPT-4o and LLaVA across all axioms. Columns (H1--H10) correspond to the kappa scores measuring the agreement between each specific human annotator and the consolidated VLM annotations. Higher scores (darker blue) signify stronger agreement, while lower scores (lighter shades) highlight areas of disagreement.}
    \label{fig:annotation_agreement_heatmap}
    \vspace{-4mm}
\end{figure*}




