



\section{Contradictory Alignment Optimization (CAO)}

The \textbf{YinYangAlign} framework, models the challenge of balancing \emph{inherently contradictory} objectives. For example, prioritizing \emph{Faithfulness to Prompt} can limit \emph{Artistic Freedom}, while emphasizing \emph{Emotional Impact} may erode \emph{Neutrality}. To address these tensions, we introduce \textbf{Contradictory Alignment Optimization (CAO)}, which employs a \emph{per-axiom} loss design to explicitly model competing goals. CAO employs a dynamic weighting mechanism to prioritize sub-objectives within each axiom, facilitating granular control over trade-offs and enabling adaptive optimization across diverse alignment paradigms. Additionally, CAO integrates \emph{Pareto optimality} principles with the \emph{Bradley-Terry} preference framework, introducing a novel \emph{global synergy} mechanism that unifies all contradictory objectives into a cohesive optimization strategy. This unique combination of multi-objective synergy defines the core innovation of CAO, distinguishing it from existing T2I alignment methods.

%In \textbf{YinYangAlign} setup, T2I models must reconcile \emph{intrinsically contradictory} aims. For instance, \emph{Faithfulness to Prompt} can restrict \emph{Artistic Freedom}, while prioritizing \emph{Emotional Impact} may erode \emph{Neutrality}. These tensions motivate our DPO-\textbf{Contradictory Alignment Optimization (CAO)} design, which introduces a \emph{per-axiom} loss design to explicitly model competing goals. By assigning specific weights to each sub-objective within an axiom, CAO allows for flexible tradeoffs tailored to individual alignment requirements. Importantly, CAO merges \emph{Pareto optimality} concepts with the \emph{Bradley-Terry} preference framework, yielding a novel \emph{global synergy} mechanism that unifies all contradictory objectives under one coherent optimization strategy. This union of multi-objective synergy and directed preference optimization is the core novelty of CAO, setting it apart from prior T2I alignment approaches.



\begin{figure*}[ht!]
    \centering
    \includegraphics[width=\textwidth]{img/axiom_pairs_visualization.png}
    \caption{
        Visualization of error loss surface tension for six axiom pairs in YinYang alignment. Each pair highlights the inherent trade-offs between \emph{competing objectives} using a 3D surface plot (left) and a 2D contour plot (right). \textcolor{blue}{Blue regions} represent synergy (low tension), \textcolor{red}{red regions} indicate conflict (high tension), while \textcolor{green}{Green markers} highlight "sweet spots" where the tension is minimal. The first axiom pair, \textit{Faithfulness to Prompt vs. Artistic Freedom}, shows sweet spots centered around moderate values, suggesting balanced trade-offs. For \textit{Emotional Impact vs. Neutrality}, sweet spots are sparse, reflecting the difficulty in balancing emotional engagement and neutrality. The axiom pair \textit{Visual Realism vs. Artistic Freedom} shows distributed sweet spots, indicating achievable trade-offs between realism and creative freedom. In \textit{Originality vs. Referentiality}, sweet spots are concentrated, emphasizing the challenge of balancing uniqueness and references. The pair \textit{Verifiability vs. Artistic Freedom} has central sweet spots, suggesting harmony between factual accuracy and creative expression. Lastly, \textit{Cultural Sensitivity vs. Artistic Freedom} shows fewer sweet spots, reflecting the complexity of respecting cultural norms while granting artistic liberties. This visualization underscores the inherent trade-offs in T2I systems and identifies potential areas of optimization for aligning competing objectives.
    }
    \label{fig:axiom_pairs_tension}
    \vspace{-2mm}
\end{figure*}




\subsection{Axiom-Wise Loss Expansion and Synergy}

\paragraph{Local Axiom-Wise Loss}: Below, we illustrate how each axiom’s loss is defined, before showing how these losses connect into a global synergy framework. For each axiom \(a\), CAO defines a loss function \(f_a(I)\) that blends two competing sub-objectives, \(\mathcal{L}_p(I)\) and \(\mathcal{L}_q(I)\), via a mixing parameter \(\alpha_a\):
\[
f_a(I)
=
\alpha_a \,\mathcal{L}_p(I)
+
\bigl(1 - \alpha_a\bigr)\,\mathcal{L}_q(I).
\]
For example, \(\mathcal{L}_p(I)\) might emphasize \emph{faithfulness to prompt}, while \(\mathcal{L}_q(I)\) favors \emph{artistic freedom}, or any other pair of conflicting objectives. Varying \(\alpha_a\) adjusts the per-axiom balance according to domain or policy needs.


\begin{tcolorbox}[colframe=black,colback=white,boxrule=0.5mm,width=\columnwidth,sharp corners]
\scriptsize
\begin{itemize}[left=-4pt,itemsep=0pt,topsep=0pt,parsep=0pt]
    \item \textbf{Faithfulness to Prompt vs.\ Artistic Freedom}
    \vspace{-3mm}
    \[
    f_{\text{faith\_artistic}}(I) 
    = \alpha_1 \cdot \mathcal{L}_{\text{faith}}
    + (1 - \alpha_1) \cdot \mathcal{L}_{\text{artistic}}
    \]
    \vspace{-6mm}

    \item \textbf{Emotional Impact vs.\ Neutrality}
    \vspace{-3mm}
    \[
    f_{\text{emotion\_neutrality}}(I) 
    = \alpha_2 \cdot \mathcal{L}_{\text{emotion}}
    + (1 - \alpha_2) \cdot \mathcal{L}_{\text{neutrality}}
    \]
    \vspace{-6mm}

    \item \textbf{Visual Realism vs.\ Artistic Freedom}
    \vspace{-3mm}
    \[
    f_{\text{visual\_style}}(I) 
    = \alpha_3 \cdot \mathcal{L}_{\text{realism}}
    + (1 - \alpha_3) \cdot \mathcal{L}_{\text{artistic}}
    \]
    \vspace{-6mm}

    \item \textbf{Originality vs.\ Referentiality}
    \vspace{-3mm}
    \[
    f_{\text{originality\_referentiality}}(I) 
    = \alpha_4 \cdot \mathcal{L}_{\text{originality}}
    + (1 - \alpha_4) \cdot \mathcal{L}_{\text{referentiality}}
    \]
    \vspace{-6mm}

    \item \textbf{Verifiability vs.\ Artistic Freedom}
    \vspace{-3mm}
    \[
    f_{\text{verifiability\_creative}}(I) 
    = \alpha_5 \cdot \mathcal{L}_{\text{verifiability}}
    + (1 - \alpha_5) \cdot \mathcal{L}_{\text{artistic}}
    \]
    \vspace{-6mm}

    \item \textbf{Cultural Sensitivity vs.\ Artistic Freedom}
    \vspace{-3mm}
    \[
    f_{\text{cultural\_artistic}}(I) 
    = \alpha_6 \cdot \mathcal{L}_{\text{cultural}}
    + (1 - \alpha_6) \cdot \mathcal{L}_{\text{artistic}}
    \]
\end{itemize}
\end{tcolorbox}

The resulting loss surfaces and their corresponding \emph{sweet spots}, where competing objectives are in harmony, are visualized in \cref{fig:axiom_pairs_tension}.


\paragraph{Multi-Objective Aggregator and Pareto Frontiers:} Although \(f_a(I)\) provides \emph{local} control over each axiom \(a\), reconciling multiple axioms at once requires a \emph{global} view. We thus define a \textbf{multi-objective synergy function}:
\[
\mathcal{S}(I)
=
\sum_{a=1}^A
\omega_a \, f_a(I),
\]
where the \(\{\omega_a\}\) are global coefficients reflecting the relative priority of each axiom. By varying these synergy weights, we trace out a Pareto frontier~\cite{miettinen1999nonlinear, yang2021towards, lin2023pareto} in the T2I objective space, clarifying how small concessions in one axiom can yield major gains in another.




\smallskip
\noindent
\textbf{Interpretation and Importance.}\quad
In \emph{multi-objective optimization}, the \emph{Pareto frontier} is the set of all solutions where improving any one objective strictly worsens at least one other~\cite{deb2001multiobjective, zhou2022pareto}. By tuning \(\{\omega_a\}\), we systematically explore these tradeoffs, finding, for example, that a slight drop in \emph{visual realism} could allow for notably higher \emph{stylistic freedom}. Such multi-objective approaches have been central in \emph{multi-task learning}~\cite{ma2020quadratic, navon2022multi, yu2020gradient} and \emph{modular/decomposed learning}~\cite{liebenwein2021provable, lin2022pareto}, ensuring transparent control over each tension point (e.g., verifiability vs.\ creativity) and easy adaptation to new constraints. cf  \cref{sec:appendix:dpo-cao}. 


\subsection{Connecting Synergy to Pairwise Preference}

To fully implement both \emph{local} axiom-wise guidance and \emph{global} synergy-based tradeoffs, we integrate the synergy function into the DPO framework. Concretely, each \(f_a(I)\) enters a Bradley-Terry style preference:
\[
P_{ij}^a
=
\frac{
\exp\!\bigl(f_a(I_i)\bigr)
}{
\exp\!\bigl(f_a(I_i)\bigr) + \exp\!\bigl(f_a(I_j)\bigr)
},
\]
ensuring local interpretability for each axiom. Meanwhile, a \emph{combined preference} over \(\mathcal{S}(I)\) expresses the global tradeoff:
\[
P_{ij}^{\mathcal{S}}
=
\frac{\exp\!\bigl(\mathcal{S}(I_i)\bigr)}
     {\exp\!\bigl(\mathcal{S}(I_i)\bigr) + \exp\!\bigl(\mathcal{S}(I_j)\bigr)}.
\]
A hyperparameter \(\lambda\) then balances how much this \textbf{global synergy} affects the final optimization vs.\ how much weight is given to \textbf{local} per-axiom preferences:
\[
\mathcal{L}_{\text{CAO}}
=
- \sum_{a=1}^{A}
\sum_{(i,j)}
\log\!\bigl(P_{ij}^a\bigr)
+
\lambda
\sum_{(i,j)}
\Bigl[
-\,\log\!\bigl(P_{ij}^{\mathcal{S}}\bigr)
\Bigr].
\]

\subsection{Unified CAO Loss}

We can consolidate the local and global preferences into a single loss function. One straightforward approach is:
\[
\mathcal{L}_{\text{CAO}}
=
\underbrace{
- \sum_{a=1}^{6}
  \sum_{(i,j)}
  \log\!\bigl(P_{ij}^a\bigr)
}_{\mathcal{L}_{\text{local}}}
+
\lambda
\underbrace{
\left[
  - \sum_{(i,j)}
  \log\!\bigl(P_{ij}^{\mathcal{S}}\bigr)
\right]
}_{\mathcal{L}_{\text{synergy}}}.
\]

\paragraph{Local Terms (\(\mathcal{L}_{\text{local}}\)).}  
Each axiom \(a\) retains interpretability and ensures the model handles \emph{faithfulness vs.\ artistry}, \emph{emotional impact vs.\ neutrality}, and so on, at a granular level.

\paragraph{Global Term (\(\mathcal{L}_{\text{synergy}}\)).}  
This enforces coordinated tradeoffs by encouraging consistency with the aggregator \(\mathcal{S}(I)\). A larger \(\lambda\) implies stronger synergy constraints and places more emphasis on global equilibrium across axioms, while a smaller \(\lambda\) prioritizes local alignment objectives.

\begin{figure*}[ht!]
\centering
\begin{tcolorbox}[
  enhanced,
  colback=white,
  colframe=black,
  boxrule=1pt,
  borderline={0.6pt}{2pt}{black},
  sharp corners,
  width=\textwidth
]

\begin{minipage}{\textwidth}
\scriptsize

\subsection*{(A) Local Axiom Preferences}
\begin{equation*}
\mathcal{L}_{\text{local}}
~\;=\;
- \Bigl[
   \sum_{(i,j)} \log\!\bigl(P_{ij}^{\text{faith_artistic}}\bigr)
 + \sum_{(i,j)} \log\!\bigl(P_{ij}^{\text{emotion_neutrality}}\bigr)
 + \sum_{(i,j)} \log\!\bigl(P_{ij}^{\text{visual_style}}\bigr)
 + \sum_{(i,j)} \log\!\bigl(P_{ij}^{\text{originality_referentiality}}\bigr)
 + \sum_{(i,j)} \log\!\bigl(P_{ij}^{\text{verifiability_creative}}\bigr)
 + \sum_{(i,j)} \log\!\bigl(P_{ij}^{\text{cultural_artistic}}\bigr)
\Bigr].
\end{equation*}

\vspace{-2mm}
\noindent
Here, each term is a negative log-likelihood over 
\(
   P_{ij}^{a}
   =
   \frac{\exp\!\bigl(f_{a}(I_i)\bigr)}
        {\exp\!\bigl(f_{a}(I_i)\bigr)+\exp\!\bigl(f_{a}(I_j)\bigr)}
\)
for axiom \(a\).

\vspace{-3mm}
\subsection*{(B) Global Synergy Preference}
\begin{equation*}
\mathcal{L}_{\text{synergy}}
~\;=\;
\sum_{(i,j)}
  \log\!\Bigl(
    \frac{
      \exp\!\Bigl(\omega_{1}f_{\text{faithArtistic}}(I_i)
      + \ldots + \omega_{6}f_{\text{culturalArtistic}}(I_i)\Bigr)
    }{
      \exp\!\Bigl(\omega_{1}f_{\text{faithArtistic}}(I_i)
      + \ldots + \omega_{6}f_{\text{culturalArtistic}}(I_i)\Bigr)
      +
      \exp\!\Bigl(\omega_{1}f_{\text{faithArtistic}}(I_j)
      + \ldots + \omega_{6}f_{\text{culturalArtistic}}(I_j)\Bigr)
    }
  \Bigr).
\end{equation*}

\vspace{-2mm}
\noindent
This term encodes the preference for 
\(
   \mathcal{S}(I) 
   = 
   \sum_{a=1}^{6} \omega_a\, f_a(I)
\).

\vspace{-2.5mm}
\subsection*{(C) Axiom-Specific Regularizers}
\begin{equation*}
\sum_{a=1}^{6} \tau_{a}\,\mathcal{R}_a
~=\;
\tau_{1}\,\frac{\displaystyle
   \int_{\mathcal{X}}\!\!\int_{\mathcal{X}}
   \|x-y\|\,
   P_{\text{faith}}(x)\,
   Q_{\text{artistic}}(y)
   \,\mathrm{d}x\,\mathrm{d}y
}{
   \displaystyle
   \int_{\mathcal{X}}P_{\text{faith}}(x)\,\mathrm{d}x
   \;\times\;
   \int_{\mathcal{X}}Q_{\text{artistic}}(y)\,\mathrm{d}y
}
~+~
\ldots
~+~
\tau_{6}\,\frac{\displaystyle
   \int_{\mathcal{X}}\!\!\int_{\mathcal{X}}
   \|x-y\|\,
   P_{\text{cultural}}(x)\,
   Q_{\text{artistic}}(y)
   \,\mathrm{d}x\,\mathrm{d}y
}{
   \displaystyle
   \int_{\mathcal{X}}P_{\text{cultural}}(x)\,\mathrm{d}x
   \;\times\;
   \int_{\mathcal{X}}Q_{\text{artistic}}(y)\,\mathrm{d}y
}.
\end{equation*}

\end{minipage}
\end{tcolorbox}

\vspace{-2mm}
\includegraphics[width=\textwidth]{img/ablation_error_loss.png}

%\captionsetup{justification=justified, singlelinecheck=false}
\captionsetup{justification=justified, singlelinecheck=false}
\caption{A modular breakdown of the CAO loss. 
\textbf{(A)} Local per-axiom preferences, 
\textbf{(B)} global synergy preference, 
\textbf{(C)} axiom-specific regularizers. 
Three error loss surfaces from the ablation study demonstrate the progressive impact of incorporating components of the YinYang alignment objective. 
The first plot, with only the \textit{Local Axiom Preferences}, shows an unstable gradient landscape. 
Adding in the second plot smooths the loss surface significantly. 
Finally, introducing additional \textit{Regularization Terms} in the third plot further stabilizes and smooths the surface, making optimization more efficient and robust.}






% \caption{A modular breakdown of the CAO loss. 
% \textbf{(A)} Local per-axiom preferences,
% \textbf{(B)} global synergy preference,
% \textbf{(C)} axiom-specific regularizers.
% Three error loss surfaces from the ablation study demonstrate
% the progressive impact of incorporating components of the YinYang
% alignment objective. The first plot, with only the
% \textit{Local Axiom Preferences} \(- \sum_{a=1}^{A} \sum_{(i,j)} \log\bigl(P_{ij}^a\bigr)\),
% shows an unstable gradient landscape. Adding \textit{Global Synergy Preference}
% \(-\lambda \sum_{(i,j)} \log\bigl(P_{ij}^{\mathcal{S}}\bigr)\) in the second plot
% smooths the loss surface significantly. Finally, introducing additional
% \textit{Regularization Terms} \(\sum_{a=1}^{A} \tau_a \mathcal{R}_a\)
% in the third plot further stabilizes and smooths the surface,
% making optimization more efficient and robust.}
\label{fig:dpo-cao-expanded}
\end{figure*}

% \begin{figure*}[ht!]
% \centering
% \begin{tcolorbox}[
%   enhanced,
%   colback=white,        % background color
%   colframe=black,       % color of the primary frame
%   boxrule=1pt,        % thickness of the primary frame
%   borderline={0.6pt}{2pt}{black}, % second line: thickness=0.6pt, distance=2pt, color=black
%   sharp corners,        % no rounded corners
%   width=\textwidth      % occupy full width in figure*
% ]


% \begin{minipage}{\textwidth}
% \scriptsize
% %-----------------------------------
% % (A) Local Axiom Preferences
% %-----------------------------------
% \subsection*{(A) Local Axiom Preferences}
% % \vspace{-0.5em}
% \begin{equation*}
% \mathcal{L}_{\text{local}}
% ~\;=\;
% - \Bigl[
%    \sum_{(i,j)} \log\!\bigl(P_{ij}^{\text{faith_artistic}}\bigr)
%  + \sum_{(i,j)} \log\!\bigl(P_{ij}^{\text{emotion_neutrality}}\bigr)
%  + \sum_{(i,j)} \log\!\bigl(P_{ij}^{\text{visual_style}}\bigr)
%  + \sum_{(i,j)} \log\!\bigl(P_{ij}^{\text{originality_referentiality}}\bigr)
%  + \sum_{(i,j)} \log\!\bigl(P_{ij}^{\text{verifiability_creative}}\bigr)
%  + \sum_{(i,j)} \log\!\bigl(P_{ij}^{\text{cultural_artistic}}\bigr)
% \Bigr].
% \end{equation*}

% \vspace{-2mm}
% \noindent
% Here, each term is a negative log-likelihood over the Bradley-Terry preference 
% \(\displaystyle P_{ij}^{a} = \frac{\exp\!\bigl(f_{a}(I_i)\bigr)}
%                                   {\exp\!\bigl(f_{a}(I_i)\bigr)+\exp\!\bigl(f_{a}(I_j)\bigr)}\)
% for axiom \(a\).

% \vspace{-3mm}
% %-----------------------------------
% % (B) Global Synergy Preference
% %-----------------------------------
% \subsection*{(B) Global Synergy Preference}
% \vspace{-0.5em}
% \begin{equation*}
% \mathcal{L}_{\text{synergy}}
% ~\;=\;
% \sum_{(i,j)}
%   \log\!\Bigl(
%     \frac{
%       \exp\!\Bigl(\omega_{1}f_{\text{faithArtistic}}(I_i)
%       + \ldots + \omega_{6}f_{\text{culturalArtistic}}(I_i)
%       \Bigr)
%     }{
%       \exp\!\Bigl(\omega_{1}f_{\text{faithArtistic}}(I_i)
%       + \ldots + \omega_{6}f_{\text{culturalArtistic}}(I_i)
%       \Bigr)
%       ~+~
%       \exp\!\Bigl(\omega_{1}f_{\text{faithArtistic}}(I_j)
%       + \ldots + \omega_{6}f_{\text{culturalArtistic}}(I_j)
%       \Bigr)
%     }
%   \Bigr).
% \end{equation*}

% \vspace{-2mm}
% \noindent
% This term encodes the preference for a \emph{global aggregator} 
% \(\displaystyle \mathcal{S}(I) = \sum_{a=1}^{6} \omega_a\, f_a(I)\),
% where each \(\omega_a\) is a weight signifying axiom \(a\)’s priority.

% \vspace{-2.5mm}
% %-----------------------------------
% % (C) Axiom-Specific Regularizers
% %-----------------------------------
% \subsection*{(C) Axiom-Specific Regularizers}
% \vspace{-0.25em}
% \begin{equation*}
% \sum_{a=1}^{6} \tau_{a}\,\mathcal{R}_a
% ~=\;
% \tau_{1}\,\frac{\displaystyle
%    \int_{\mathcal{X}}\!\!\int_{\mathcal{X}}
%    \|x-y\|\,
%    P_{\text{faith}}(x)\,
%    Q_{\text{artistic}}(y)
%    \,\mathrm{d}x\,\mathrm{d}y
% }{
%    \displaystyle
%    \int_{\mathcal{X}}P_{\text{faith}}(x)\,\mathrm{d}x
%    \;\times\;
%    \int_{\mathcal{X}}Q_{\text{artistic}}(y)\,\mathrm{d}y
% }
% ~+~
% \tau_{2}\,\frac{\displaystyle
%    \int_{\mathcal{X}}\!\!\int_{\mathcal{X}}
%    \|x-y\|\,
%    P_{\text{emotion}}(x)\,
%    Q_{\text{neutrality}}(y)
%    \,\mathrm{d}x\,\mathrm{d}y
% }{
%    \displaystyle
%    \int_{\mathcal{X}}P_{\text{emotion}}(x)\,\mathrm{d}x
%    \;\times\;
%    \int_{\mathcal{X}}Q_{\text{neutrality}}(y)\,\mathrm{d}y
% }
% ~+~
% \ldots
% ~+~
% \tau_{6}\,\frac{\displaystyle
%    \int_{\mathcal{X}}\!\!\int_{\mathcal{X}}
%    \|x-y\|\,
%    P_{\text{cultural}}(x)\,
%    Q_{\text{artistic}}(y)
%    \,\mathrm{d}x\,\mathrm{d}y
% }{
%    \displaystyle
%    \int_{\mathcal{X}}P_{\text{cultural}}(x)\,\mathrm{d}x
%    \;\times\;
%    \int_{\mathcal{X}}Q_{\text{artistic}}(y)\,\mathrm{d}y
% }.
% \end{equation*}

% \vspace{-2mm}
% \noindent
% Here, the first axiom’s regularizer is fully expanded with a Wasserstein-type cost, while subsequent axioms use a shorter notation \(W(\cdot,\cdot)\) for brevity.

% \end{minipage}
% \end{tcolorbox}

% \vspace{-2mm}
% \includegraphics[width=\textwidth]{img/ablation_error_loss.png}
% %\captionsetup{width=\textwidth}
% \caption{A modular breakdown of the CAO loss. 
% \textbf{(A)} Local per-axiom preferences,
% \textbf{(B)} global synergy preference,
% \textbf{(C)} axiom-specific regularizers.
% Three error loss surfaces from the ablation study demonstrate
% the progressive impact of incorporating components of the YinYang
% alignment objective. The first plot, with only the
% \textit{Local Axiom Preferences} \(- \sum_{a=1}^{A} \sum_{(i,j)} \log\bigl(P_{ij}^a\bigr)\),
% shows an unstable gradient landscape. Adding \textit{Global Synergy Preference}
% \(-\lambda \sum_{(i,j)} \log\bigl(P_{ij}^{\mathcal{S}}\bigr)\) in the second plot
% smooths the loss surface significantly. Finally, introducing additional
% \textit{Regularization Terms} \(\sum_{a=1}^{A} \tau_a \mathcal{R}_a\)
% in the third plot further stabilizes and smooths the surface,
% making optimization more efficient and robust.}
% \label{fig:dpo-cao-expanded}
% \end{figure*}



\paragraph{Why Keep Both Local \emph{and} Global?}
\begin{itemize}[left=5pt]
\item 
\emph{Local Preferences \((P_{ij}^a)\)} show how the model balances each contradictory pair (e.g., “\emph{Did we favor faithfulness over artistry?}”), preserving interpretability at the axiom level.
\item 
\emph{Global Preference \((P_{ij}^{\mathcal{S}})\)} ensures the T2I model, \emph{as a whole}, follows the overarching synergy profile, capturing \emph{all} tensions in unison.
\end{itemize}
Hence, \(\lambda\) “\emph{dials in}” how much to respect the overall synergy aggregator vs.\ each per-axiom preference.

\subsection{Axiom-Specific Regularization in CAO}

To stabilize the optimization and prevent overfitting to any single objective, CAO also provides a regularization term for each axiom:
\[
\mathcal{L}_{\text{CAO}}
=
\sum_{a=1}^6
\Bigl[
  f_a(I) 
  + 
  \tau_a \,\mathcal{R}_a
\Bigr],
\]
where \(\tau_a\) scales the influence of the regularizer \(\mathcal{R}_a\). While KL-divergence is a common choice, it can be unstable in high-dimensional T2I scenarios; \textbf{Wasserstein Distance}~\cite{arjovsky2017wasserstein} or \emph{Sinkhorn regularization}~\cite{cuturi2013sinkhorn} typically offer more robust optimization. cf \cref{sec:appendix_wasserstein_Sinkhorn} for the rationale behind Wasserstein Distance and Sinkhorn Regularization.








\subsection{Putting It All Together: Final CAO Formulation}

Bringing together the synergy function, local Bradley-Terry preferences, and axiom-specific regularization leads to the final CAO objective:
\[
\mathcal{L}_{\text{CAO}}
=
\underbrace{
- \sum_{a=1}^{A} 
  \sum_{(i,j)}
  \log\!\bigl(P_{ij}^a\bigr)
}_{\text{Local Axiom Preferences}}
-
\lambda
\underbrace{
\sum_{(i,j)}
\log\!\bigl(P_{ij}^{\mathcal{S}}\bigr)
}_{\text{Global Synergy Preference}}
+
\sum_{a=1}^{A}
\tau_a\,\mathcal{R}_a.
\]




\paragraph{Role of the Synergy Jacobian $(\mathbf{J}_{\mathcal{S}}$)}: The Synergy Jacobian \(\mathbf{J}_{\mathcal{S}}\) is a vital component in managing \emph{gradient interactions} across multiple axioms during training. While the regularization parameter \(\lambda\) balances local and global objectives, \(\mathbf{J}_{\mathcal{S}}\) quantifies how updates to model parameters for one axiom impact the alignment of others. Mathematically, \(\mathbf{J}_{\mathcal{S}}\) is defined as:
\[
\mathbf{J}_{\mathcal{S}} = \frac{\partial \mathcal{S}(I)}{\partial \theta},
\]
where \(\mathcal{S}(I)\) represents the synergy aggregator that measures overall alignment, \(I\) denotes the input, and \(\theta\) are the model parameters. This Jacobian provides a structured view of the interdependencies among axioms, capturing how conflicting objectives influence each other \cite{navon2022multi, yu2020gradient}.


\begin{figure*}[ht!]
    \includegraphics[width=\textwidth, keepaspectratio]{img/jacobian_visualization.png}
    \caption{
        Visualization of optimization paths and gradient dynamics with and without the Synergy Jacobian.
        \textbf{3D Plots (Top Row):} The synergy score (z-axis) peaks at the Pareto-optimal point (black cross), representing the ideal balance between competing objectives. 
        \textit{Without Jacobian Adjustment (left column):} The optimization path (red circles) follows conflicting gradients (red arrows), leading to suboptimal convergence away from the Pareto-optimal point.
        \textit{With Jacobian Adjustment (right column):} The gradients (blue arrows) are harmonized by the Synergy Jacobian, guiding the optimization path (blue circles) toward the synergy peak.
        \textbf{2D Plots (Bottom Row):} The 2D plots provide a top-down perspective of the same optimization dynamics, highlighting gradient directions and path alignment. 
        \textit{Without Jacobian Adjustment (left column):} Misaligned gradients cause the path to diverge from the Pareto-optimal region.
        \textit{With Jacobian Adjustment (right column):} Adjusted gradients align consistently, enabling smooth convergence to the synergy peak. Together, these visualizations demonstrate the effectiveness of the Synergy Jacobian in resolving gradient conflicts, fostering cohesive and efficient optimization across competing objectives.
    }
    \label{fig:jacobian_visualization}
\end{figure*}




\textbf{Intuition and Practical Role}: During training, gradients for individual axioms often conflict, resulting in updates that disproportionately favor one objective at the expense of others. The Synergy Jacobian addresses this issue by scaling or adjusting gradients based on their interactions with the synergy aggregator \(\mathcal{S}(I)\). Specifically:
\begin{itemize}
    \item Gradients that align well with improving overall synergy are preserved to maintain their positive contribution.
    \item Gradients that disproportionately benefit a single axiom while adversely affecting others are scaled back to ensure balance across objectives.
\end{itemize}

The parameter update during training can be expressed as:
\[
\Delta \theta = \eta \cdot \nabla \mathcal{L} - \alpha \cdot \mathbf{J}_{\mathcal{S}},
\]
where \(\nabla \mathcal{L}\) is the standard gradient of the loss, \(\eta\) is the learning rate, and \(\alpha\) is a scaling factor controlling the influence of the Synergy Jacobian. This formulation ensures that the optimization process remains balanced, preventing any single axiom from dominating the alignment process. The impact of the Synergy Jacobian on resolving gradient conflicts and guiding optimization can be visualized in \cref{fig:jacobian_visualization}.


\textls[-10]{\textbf{Benefits}: The incorporation of \(\mathbf{J}_{\mathcal{S}}\) ensures:
1) \emph{Balanced Optimization}: Prevents one axiom from overshadowing others, fostering a holistic alignment across contradictory objectives. 2) \emph{Stability}: Reduces the risk of oscillations or instability during training by moderating conflicting gradient interactions. 3) \emph{Cohesion}: Facilitates a stable and unified optimization process, ensuring that all objectives contribute meaningfully to the overall alignment.}

Further details, derivations, and examples are provided in \cref{sec:appendix_synergy_jacobian}.







\subsection*{Benefits and Scalability}

\begin{itemize}
    \item \textbf{Pareto-Aware Multi-Objective Control:} 
    By sweeping synergy weights \(\{\omega_a\}\), we explore a Pareto frontier of alignment solutions, clarifying how intensifying constraints for one axiom (e.g., cultural sensitivity) impacts another (e.g., artistic freedom).

    \item \textbf{Global Alignment \& Local Interpretability:} 
    The synergy-based preference \(P_{ij}^{\mathcal{S}}\) offers a coherent global objective, while individual \(P_{ij}^a\) preserve axiom-level clarity.

    \item \textbf{Efficient Computation via Sinkhorn Regularization:}  
    Wasserstein-based distances are highly effective for aligning distributions but can be computationally expensive, particularly for large-scale data, as their complexity often scales poorly. \emph{Sinkhorn regularization}~\cite{cuturi2013sinkhorn} addresses this issue by introducing an entropy-based regularization term to the optimal transport problem, which smooths the optimization and significantly reduces computational overhead. The Sinkhorn distance is defined as:  
\[
W_\lambda(P, Q) = \min_{\gamma \in \Pi(P, Q)} \langle \gamma, C \rangle - \lambda \mathcal{H}(\gamma),
\]
where \(P\) and \(Q\) are the distributions to be aligned, \(\Pi(P, Q)\) denotes the set of all valid couplings with marginals \(P\) and \(Q\), \(C\) is the cost matrix, \(\lambda\) is the regularization parameter, and \(\mathcal{H}(\gamma)\) is the entropy of the coupling \(\gamma\), defined as:
\[
\mathcal{H}(\gamma) = - \sum_{i, j} \gamma_{ij} \log \gamma_{ij}.
\]
By incorporating this entropy term, the optimization problem becomes smoother and computationally efficient, allowing for faster convergence through iterative scaling algorithms. This approach reduces complexity to near-linear time while retaining the core advantages of Wasserstein-based methods, making it scalable and robust for large-scale alignment tasks. \cref{fig:regularization_paths} illustrates the practical impact of Sinkhorn regularization by comparing optimization paths and cost surfaces with and without regularization.


\end{itemize}



\begin{figure*}[ht!]
    \centering
    \includegraphics[width=\textwidth]{img/optimization_paths.png}
    \caption{
        Visualization of optimization paths and cost landscapes with and without Sinkhorn regularization. The figure consists of two panels:
        \textbf{Left Panel (Without Regularization):} The jagged cost surface exhibits steep gradients and sharp valleys, as indicated by the tightly packed contour lines. The red path represents the chaotic optimization trajectory, characterized by oscillatory and inefficient updates due to the irregular gradients. The green star marks the starting point, and the black cross indicates the end point. The annotation "Steep Gradient" highlights areas where the optimization struggles to progress smoothly. \textbf{Right Panel (With Sinkhorn Regularization):} The smooth cost surface demonstrates gradual changes in cost, as shown by the widely spaced contour lines. The blue path represents the efficient and stable optimization trajectory. The green star marks the starting point, and the black cross indicates the end point. The annotation "Smooth Gradient" points to areas where regularization has flattened the landscape, enabling consistent and effective gradient updates. This comparison illustrates the effectiveness of Sinkhorn regularization in transforming a jagged, computationally expensive optimization problem into a smooth, scalable one. The blue-green-yellow colormap highlights gradient intensities while maintaining visual clarity across both panels.
    }
    \label{fig:regularization_paths}
\end{figure*}



\begin{comment}
\textbf{The final CAO loss function} integrates per-axiom optimization objectives and their corresponding regularization terms into a unified framework. For each axiom, the loss is composed of two components: the primary alignment loss \( f_a(I) \), which balances the competing goals (e.g., faithfulness and artistic freedom), and an axiom-specific regularization term \( \mathcal{R}_a \), scaled by \( \tau_a \) to control its influence. The overall loss is a weighted sum of these components, with global weights \( \omega, \beta, \gamma, \delta, \eta, \theta \) representing the relative priority of each axiom. This structure ensures flexibility, allowing for tailored tradeoffs between competing goals across diverse axioms, while maintaining stability and computational efficiency.


\begin{multline*}
\mathcal{L}_{\text{CAO}} = \omega \cdot \left(f_{\text{faith\_artistic}}(I) + \tau_1 \cdot \frac{\int_{\mathcal{X}} \|x - y\| P_{\text{faith}}(x) Q_{\text{artistic}}(y) dx dy}{\int_{\mathcal{X}} P_{\text{faith}}(x) dx \int_{\mathcal{X}} Q_{\text{artistic}}(y) dy}\right) \\
+ \beta \cdot \left(f_{\text{emotion\_neutrality}}(I) + \tau_2 \cdot \frac{\int_{\mathcal{X}} \|x - y\| P_{\text{emotion}}(x) Q_{\text{neutrality}}(y) dx dy}{\int_{\mathcal{X}} P_{\text{emotion}}(x) dx \int_{\mathcal{X}} Q_{\text{neutrality}}(y) dy}\right) \\
+ \gamma \cdot \left(f_{\text{visual\_style}}(I) + \tau_3 \cdot \frac{\int_{\mathcal{X}} \|x - y\| P_{\text{visual}}(x) Q_{\text{style}}(y) dx dy}{\int_{\mathcal{X}} P_{\text{visual}}(x) dx \int_{\mathcal{X}} Q_{\text{style}}(y) dy}\right) \\
+ \delta \cdot \left(f_{\text{originality\_referentiality}}(I) + \tau_4 \cdot \frac{\int_{\mathcal{X}} \|x - y\| P_{\text{originality}}(x) Q_{\text{referentiality}}(y) dx dy}{\int_{\mathcal{X}} P_{\text{originality}}(x) dx \int_{\mathcal{X}} Q_{\text{referentiality}}(y) dy}\right) \\
+ \eta \cdot \left(f_{\text{verifiability\_creative}}(I) + \tau_5 \cdot \frac{\int_{\mathcal{X}} \|x - y\| P_{\text{verifiability}}(x) Q_{\text{creative}}(y) dx dy}{\int_{\mathcal{X}} P_{\text{verifiability}}(x) dx \int_{\mathcal{X}} Q_{\text{creative}}(y) dy}\right) \\
+ \theta \cdot \left(f_{\text{cultural\_artistic}}(I) + \tau_6 \cdot \frac{\int_{\mathcal{X}} \|x - y\| P_{\text{cultural}}(x) Q_{\text{artistic}}(y) dx dy}{\int_{\mathcal{X}} P_{\text{cultural}}(x) dx \int_{\mathcal{X}} Q_{\text{artistic}}(y) dy}\right),
\end{multline*}
\end{comment}

\begin{comment}
\begin{multline*}
\mathcal{L}_{\text{CAO}} 
= \omega \left(f_{\text{faith\_artistic}}(I) + \tau_1 \, W\bigl(P_{\text{faith}},Q_{\text{artistic}}\bigr)\right) \\
+ \beta \left(f_{\text{emotion\_neutrality}}(I) + \tau_2 \, W\bigl(P_{\text{emotion}},Q_{\text{neutrality}}\bigr)\right) \\
+ \gamma \left(f_{\text{visual\_style}}(I) + \tau_3 \, W\bigl(P_{\text{visual}},Q_{\text{style}}\bigr)\right) \\
+ \delta \left(f_{\text{originality\_referentiality}}(I) + \tau_4 \, W\bigl(P_{\text{originality}},Q_{\text{referentiality}}\bigr)\right) \\
+ \eta \left(f_{\text{verifiability\_creative}}(I) + \tau_5 \, W\bigl(P_{\text{verifiability}},Q_{\text{creative}}\bigr)\right) \\
+ \theta \left(f_{\text{cultural\_artistic}}(I) + \tau_6 \, W\bigl(P_{\text{cultural}},Q_{\text{artistic}}\bigr)\right).
\end{multline*}
\end{comment}




























\section{Axiom-Specific Loss Function Design}
\label{sec:axiom_loss}

We now expand each of the axiom-wise losses introduced previously: $\mathcal{L}_{\text{artistic}}$, $\mathcal{L}_{\text{faith}}$, $\mathcal{L}_{\text{emotion}}$, $\mathcal{L}_{\text{neutral}}$, $\mathcal{L}_{\text{originality}}$, $\mathcal{L}_{\text{referentiality}}$, $\mathcal{L}_{\text{verifiability}}$,  $\mathcal{L}_{\text{cultural}}$. $\mathcal{L}_{\text{artistic}}$. Note that \(\mathcal{L}_{\text{artistic}}\) appears in four of the six axioms, but the core design of the \emph{artistic loss} remains consistent across all such instances. cf \cref{sec:appendix_axiom_specific_loss}. 



\subsection{Artistic Freedom: \(\mathcal{L}_{\text{artistic}}\)}

The \emph{Artistic Freedom Score} (AFS) measures how much creative enhancement a generated image \(I_{\text{gen}}\) receives, relative to a \emph{baseline} \(I_{\text{base}}\). It comprises three components:

\begin{enumerate}
    \item \textbf{Style Difference:}  
    Gauges stylistic deviation using VGG-based Gram features~\cite{gatys2016neural, johnson2016perceptual}, a widely adopted approach in neural style transfer for capturing higher-order correlations that define an image’s aesthetic characteristics:
    \[
    \text{StyleDiff} 
    = 
    \bigl\| S(I_{\text{gen}}) \;-\; S(I_{\text{base}}) \bigr\|_2.
    \]
    Here, \(S(\cdot)\) represents a pretrained style-extraction network.

    \item \textbf{Content Abstraction:}  
    Evaluates how abstractly \(I_{\text{gen}}\) interprets the textual prompt \(P\). Formally,
    \[
    \text{ContentAbs}
    =
    1 - \cos\bigl(E(P),\, E(I_{\text{gen}})\bigr),
    \]
    where \(E(\cdot)\) is a multimodal embedding model (e.g., CLIP) \cite{radford2021learning}. Higher \(\text{ContentAbs}\) indicates stronger abstraction away from literal prompt details. This concept of \emph{content abstraction} draws inspiration from prior cross-modal research \cite{zhang2021crossmodal, mou2022abstraction}, which highlights how multimodal embeddings can bridge prompt semantics and visual representations \cite{lei2023understanding, gupta2023prompt}.

    \item \textbf{Content Difference:}
    Measures deviation from the baseline image:
    \[
    \text{ContentDiff}
    =
    1 - \cos\bigl(E(I_{\text{gen}}),\, E(I_{\text{base}})\bigr).
    \]
    This term ensures the generated image does not diverge excessively from \(\,I_{\text{base}}\), acting as a mild regularizer for subject fidelity.
\end{enumerate}

We define:
\[
\text{AFS}
=
\alpha \,\text{StyleDiff}
\;+\;
\beta \,\text{ContentAbs}
\;+\;
\gamma \,\text{ContentDiff}.
\]
By default, we set \(\alpha=0.5\), \(\beta=0.3\), and \(\gamma=0.2\) based on empirical tuning. Omitting \(\text{ContentDiff}\) may boost artistic freedom but risks straying too far from baseline subject matter, reflecting the inherent tension between creativity and fidelity. 

Calculating the AFS for the images in \cref{fig:stochastic_generation} using the first image as the reference yields: Chosen 1 and Chosen 2 with moderate AFS scores of 0.80 and 0.82, indicating minimal artistic deviation. In contrast, the Rejected images score higher, with Rejected 1, Rejected 2, and Rejected 3 achieving 0.99, 1.06, and 0.87 respectively, reflecting greater abstraction and stylistic deviation. AFS ranges are defined as Low (0.0--0.5), Moderate (0.5--1.0), and High (1.0--2.0), capturing the balance between prompt adherence and artistic creativity.






\subsection{Faithfulness to Prompt: \(\mathcal{L}_{\text{faith}}\)}

\textls[-10]{Faithfulness to the prompt is a cornerstone of T2I alignment, ensuring that generated images adhere to the semantic and visual details specified by the user. To evaluate faithfulness, we leverage a semantic alignment metric based on the \textit{Sinkhorn-VAE Wasserstein Distance}, a robust measure of distributional similarity that has gained traction in generative modeling for its interpretability and effectiveness \cite{arjovsky2017wasserstein, tolstikhin2018wasserstein}.}

The Faithfulness Loss is formulated as:

\[
    \mathcal{L}_{faith} = -W_d^\lambda(P(Z_{\text{prompt}}), Q(Z_{\text{image}})),
\]

where:
\begin{itemize}
    \item $P(Z_{\text{prompt}})$ and $Q(Z_{\text{image}})$ are the latent distributions of the textual prompt and the generated image, respectively, extracted using a Variational Autoencoder (VAE).
    \item $W_d^\lambda$ denotes the \textbf{Sinkhorn-regularized Wasserstein Distance}, which facilitates computational efficiency and stability \cite{cuturi2013sinkhorn}.
\end{itemize}


\textbf{Key Advantages:}
\begin{itemize}
    \item \textbf{Semantic Depth:} Captures alignment at a distributional level, accommodating nuanced semantic relationships.
    \item \textbf{Robustness:} Accounts for variability in generation without penalizing minor creative deviations.
    \item \textbf{Scalability:} Efficient for large-scale applications, making it suitable for real-world deployment.
\end{itemize}

By adopting this approach, the Faithfulness Loss ensures that T2I systems effectively adhere to user prompts while integrating seamlessly into the broader CAO framework.

To calculate \textbf{Faithfulness Scores} (\(\mathcal{L}_{\text{faith}}\)) for the images in \cref{fig:stochastic_generation}, we compute the semantic alignment using the Sinkhorn-regularized Wasserstein Distance (\(W_d^\lambda\)) between the prompt and each image. Using the first image as the reference, the Faithfulness Scores are as follows: Chosen 1 and Chosen 2 achieve high faithfulness scores of 0.95 and 0.92, respectively, reflecting strong adherence to the prompt. In contrast, the Rejected images score lower, with Rejected 1, Rejected 2, and Rejected 3 receiving 0.70, 0.63, and 0.58, respectively, due to their increased stylistic and semantic deviation. Faithfulness Scores range from 0.0 (poor alignment) to 1.0 (perfect alignment), ensuring adherence to prompt semantics.




\subsection{Emotional Impact Score (EIS): \(\mathcal{L}_{\text{emotion}}\)}
EIS quantifies the emotional intensity of generated images using emotion detection models (e.g., DeepEmotion~\cite{abidin2018deepemotion}), pretrained on datasets labeled with emotions such as happiness, sadness, anger, or fear. Higher ERS values indicate stronger emotional tones.

\[ERS = \frac{1}{M} \sum_{i=1}^M \text{EmotionIntensity}(\text{img}_i)
\]
where: \( M \): Total number of images in the batch, \( \text{EmotionIntensity}(\text{img}_i) \): Scalar intensity of the dominant emotion in image \(\text{img}_i\).

\textbf{Neutrality Score (N)}: Neutrality measures the degree of emotional balance or impartiality in generated images, complementing EIS by capturing the absence of a dominant emotion.

\[
N = 1 - \max(\text{EmotionIntensity})
\]
where: \( \max(\text{EmotionIntensity}) \): Intensity of the most dominant emotion detected in the image. Higher \( N \) values (closer to 1) indicate emotionally neutral images, while lower \( N \) values reflect strong emotional dominance.

\textbf{Tradeoff Between Emotional Impact and Neutrality}: To evaluate the tradeoff between Emotional Impact and Neutrality, we define a combined metric:
\[T_{\text{EMN}} = \alpha \cdot ERS + \beta \cdot N
\]
where: \( \alpha \): Weight assigned to Emotional Impact. \( \beta \): Weight assigned to Neutrality. \( \alpha (0.3) + \beta (0.7) = 1 \): Ensuring a balanced contribution, chosen empirically.

To calculate \textbf{Emotional Impact Scores (EIS)} for the images in \cref{fig:slider_selection_image_variations_1} for the prompt "\emph{A post-disaster scene}", we assess the emotional intensity (\(ERS\)), neutrality (\(N\)), and the combined trade-off metric (\(T_{\text{EMN}}\)). Image 1 achieves the lowest emotional intensity (\(ERS = 0.20\)) and the highest neutrality (\(N = 0.80\)), resulting in the highest trade-off score (\(T_{\text{EMN}} = 0.62\)), reflecting emotional balance with minimal impact. In contrast, Image 5 demonstrates the strongest emotional intensity (\(ERS = 1.00\)) and the lowest neutrality (\(N = 0.00\)), leading to the lowest trade-off score (\(T_{\text{EMN}} = 0.30\)), indicative of a highly impactful and emotionally dominant scene. The intermediate images show a gradual escalation: Image 2 has \(ERS = 0.30\), \(N = 0.70\), and \(T_{\text{EMN}} = 0.58\); Image 3 exhibits \(ERS = 0.60\), \(N = 0.40\), and \(T_{\text{EMN}} = 0.48\); and Image 4 demonstrates \(ERS = 0.80\), \(N = 0.20\), and \(T_{\text{EMN}} = 0.44\). These metrics effectively capture the progression from balanced to highly impactful emotional states, highlighting the trade-off between emotional depth and neutrality in the generated post-disaster scenes.




\subsection{Originality vs. Referentiality: $\mathcal{L}_{originality}$ \& $\mathcal{L}_{referentiality}$}

To evaluate the originality of a generated image \(I_{\text{gen}}\), we propose leveraging CLIP Retrieval to dynamically identify reference styles and compute stylistic divergence. This method builds on the capabilities of pretrained CLIP models to represent both semantic and visual features effectively~\cite{radford2021learning, clip-retrieval-2023}.

The originality loss, \(\mathcal{L}_{\text{originality}}\), is computed as the average cosine dissimilarity between the embedding of the generated image and the embeddings of the top-\(K\) reference images retrieved from a large-scale style database:
\[
f_{\text{originality\_referentiality}}(I) = \frac{1}{K} \sum_{k=1}^{K} 
\overbrace{\Bigl[ 1 - \underbrace{\cos\Bigl(E_{\text{CLIP}}(I_{\text{gen}}), E_{\text{CLIP}}(S_{\text{retr},k})\Bigr)}_{\mathcal{L}_{\text{referentiality}}} \Bigr]}^{\mathcal{L}_{\text{originality}}}.
\]
where:
\begin{itemize}
    \item \(E_{\text{CLIP}}(\cdot)\): Embedding function of a pretrained CLIP model.
    \item \(S_{\text{retr},k}\): The \(k\)-th reference image retrieved using CLIP Retrieval~\cite{clip-retrieval-2023}.
    \item \(K\): The number of top-matching reference images considered.
\end{itemize}
Higher \(\mathcal{L}_{\text{originality}}\) indicates greater stylistic divergence from existing references, reflecting more originality.

\paragraph{Reference Image Retrieval with CLIP.}
To dynamically select reference images, we use CLIP Retrieval~\cite{clip-retrieval-2023}, which queries a curated database of artistic styles based on the generated image embedding. The retrieval process is as follows:
\begin{enumerate}
    \item \textbf{Embedding Computation:} Compute the CLIP embedding of the generated image \(E_{\text{CLIP}}(I_{\text{gen}})\).
    \item \textbf{Database Query:} Compare \(E_{\text{CLIP}}(I_{\text{gen}})\) against precomputed embeddings of a reference database, such as WikiArt or BAM.
    \item \textbf{Top-\(K\) Selection:} Retrieve the top-\(K\) reference images \(S_{\text{retr},k}\) with the highest similarity scores to \(I_{\text{gen}}\).
\end{enumerate}

\paragraph{Reference Databases.}
\begin{itemize}
    \item \textbf{WikiArt:} A large-scale dataset containing over 81,000 images spanning 27 art styles, including impressionism, surrealism, and cubism~\cite{saleh2015large}.
    \item \textbf{BAM (Behance Artistic Media):} A dataset comprising over 2.5 million high-resolution images, curated from professional portfolios across diverse artistic styles~\cite{wilber2017bam}.
\end{itemize}


\textls[-11]{To evaluate the originality and referentiality of the images in \cref{fig:slider_selection_image_variations_1} for the prompt "\emph{A majestic cathedral interior with an ethereal glowing circular portal leading to a serene golden landscape}", we calculate Originality Loss (\(\mathcal{L}_{\text{originality}}\)) and Referentiality Loss (\(\mathcal{L}_{\text{referentiality}}\)) based on their stylistic divergence and alignment with the reference image. Image 1 demonstrates the highest originality (\(\mathcal{L}_{\text{originality}} = 0.85\)) and the lowest referentiality (\(\mathcal{L}_{\text{referentiality}} = 0.15\)), reflecting strong stylistic independence. In contrast, Image 5 shows the lowest originality (\(\mathcal{L}_{\text{originality}} = 0.35\)) and the highest referentiality (\(\mathcal{L}_{\text{referentiality}} = 0.65\)), indicating significant stylistic borrowing from the reference. The intermediate images exhibit a smooth transition: Image 2 achieves \(\mathcal{L}_{\text{originality}} = 0.75\) and \(\mathcal{L}_{\text{referentiality}} = 0.25\); Image 3 scores \(\mathcal{L}_{\text{originality}} = 0.65\) and \(\mathcal{L}_{\text{referentiality}} = 0.35\); and Image 4 obtains \(\mathcal{L}_{\text{originality}} = 0.50\) and \(\mathcal{L}_{\text{referentiality}} = 0.50\). These scores highlight the gradual trade-off between originality and referentiality, effectively capturing the stylistic evolution of the images relative to the reference.}




\subsection{Cultural Sensitivity: $\mathcal{L}_{cultural}$}
\label{subsec:cultural_sensitivity}

Evaluating Cultural Sensitivity in T2I systems is challenging due to the lack of pre-trained cultural classifiers and the vast diversity of cultural contexts. We propose a novel metric called \textbf{Simulated Cultural Context Matching (SCCM)}, which dynamically generates cultural sub-prompts using LLMs and evaluates their alignment with T2I-generated images. \textbf{Dynamic Cultural Context Matching (SCCM)} involves the following steps:

\subsubsection*{Embedding Generation}
\begin{enumerate}
    \item \textbf{Prompt Embedding:} For each dynamically generated cultural sub-prompt \(P_i\), embeddings are extracted using a multimodal model (e.g., CLIP). Let \(\{E(P_1), E(P_2), \dots, E(P_k)\}\) represent the embeddings of \(k\) sub-prompts.
    \item \textbf{Image Embedding:} The T2I-generated image \(I\) is embedded using the same model, yielding \(E(I)\).
\end{enumerate}

\textbf{Prompt-Image Similarity}: For each sub-prompt \(P_i\) and the generated image \(I\), calculate the semantic similarity using cosine similarity:
\[
    \text{sim}(E(P_i), E(I)) = \frac{E(P_i) \cdot E(I)}{\|E(P_i)\| \|E(I)\|}
\]

\textbf{Sub-Prompt Aggregation}: Aggregate the similarity scores across all \(k\) sub-prompts to compute the overall alignment score:
\[
    \text{SCCM}_{\text{raw}} = \frac{1}{k} \sum_{i=1}^k \text{sim}(E(P_i), E(I))
\]

\textbf{Normalization}: Normalize the raw SCCM score to the range \([0, 1]\) for consistent evaluation:
\[
    \text{SCCM}_{\text{final}} = \frac{\text{SCCM}_{\text{raw}} - \text{SCCM}_{\text{min}}}{\text{SCCM}_{\text{max}} - \text{SCCM}_{\text{min}}}
\]

\noindent where \(\text{SCCM}_{\text{min}}\) and \(\text{SCCM}_{\text{max}}\) are predefined minimum and maximum similarity scores based on a validation dataset.


\subsection*{Example Computation of SCCM}
\begin{itemize}
    \item \textbf{User Prompt:} \emph{“Generate an image of a Japanese garden during spring.”}

    Based on the following user prompt: "Generate an image of a Japanese garden during spring," identify the cultural context or elements relevant to this description. Then, generate 3-5 culturally accurate and contextually diverse sub-prompts that expand on the original prompt while maintaining its essence. Ensure the sub-prompts reflect specific traditions, symbols, or nuances related to the mentioned culture.


    \item \textbf{LLM-Generated Sub-Prompts:}
    \begin{itemize}
        \item \(P_1\): \emph{“A traditional Japanese garden with a koi pond and a wooden bridge.”}
        \item \(P_2\): \emph{“Cherry blossoms blooming in spring with traditional Japanese stone lanterns.”}
        \item \(P_3\): \emph{“A Zen rock garden with raked gravel patterns.”}
    \end{itemize}
\end{itemize}

\noindent \textbf{Similarity Scores:}
\[
\text{sim}(E(P_1), E(I)) = 0.85, \; \text{sim}(E(P_2), E(I)) = 0.80, \; \text{sim}(E(P_3), E(I)) = 0.75
\]

\noindent \textbf{Raw Aggregated Score:}
\[
\text{SCCM}_{\text{raw}} = \frac{0.85 + 0.80 + 0.75}{3} = 0.80
\]

\noindent \textbf{Final SCCM Score:}
\[
\text{SCCM}_{\text{final}} = \frac{0.80 - 0.70}{0.90 - 0.70} = 0.50
\]


To evaluate the \textbf{Cultural Sensitivity} (\(\mathcal{L}_{\text{cultural}}\)) for the images in \cref{fig:slider_selection_image_variations_1}, we compute their alignment with cultural sub-prompts dynamically generated for the prompt "\emph{Images of Vikings}". The \textbf{Simulated Cultural Context Matching (SCCM)} score quantifies cultural alignment, with higher values indicating better adherence to the Viking cultural context. 

For this analysis, we used the following \textbf{LLM-Generated Sub-Prompts}:
\begin{itemize}
    \item \(P_1\): \emph{“A Viking warrior with traditional braids and a fur cloak.”}
    \item \(P_2\): \emph{“A Viking shield maiden holding a decorated wooden shield.”}
    \item \(P_3\): \emph{“A Viking warrior in a snowy Nordic landscape with an axe.”}
    \item \(P_4\): \emph{“A Viking chieftain standing before a longship.”}
    \item \(P_5\): \emph{“A Viking encampment during a Norse festival.”}
\end{itemize}

The SCCM scores for each image reflect their alignment with these sub-prompts. Image 1 achieves a moderate SCCM score of 0.65, suggesting some cultural elements are present but not fully emphasized. Image 2 and Image 3 demonstrate increasing cultural alignment, with scores of 0.75 and 0.80, respectively, as more cultural markers such as braided hair, traditional clothing, and iconic Viking weaponry are incorporated. Image 4 and Image 5 achieve the highest cultural sensitivity, with SCCM scores of 0.85 and 0.90, respectively, due to the inclusion of intricate cultural details such as Nordic landscapes, fur garments, and well-defined Viking weaponry. These results highlight a progression in cultural adherence, showcasing how effectively T2I systems can generate culturally contextualized outputs.









\subsection{Verifiability Loss: \(\mathcal{L}_{\text{verifiability}}\)}

\textls[0]{The \emph{verifiability loss} quantifies how closely a generated image \(I_{\text{gen}}\) aligns with real-world references by comparing it to the top-\(K\) images retrieved from Google Image Search. This ensures the generated content maintains a level of authenticity and visual consistency.}

\[
\mathcal{L}_{\text{verifiability}}
=
1
-
\frac{1}{K}
\sum_{k=1}^{K}
\cos\Bigl(
E(I_{\text{gen}}),\,
E(I_{\text{search},k})
\Bigr),
\]

where:
\begin{itemize}
    \item \(I_{\text{gen}}\): The generated image.
    \item \(I_{\text{search},k}\): The \(k\)-th image retrieved from Google Image Search.
    \item \(E(\cdot)\): A pretrained embedding extraction model (e.g., DINO ViT) used to capture image semantics.
    \item \(K\): The number of top-retrieved images used for comparison.
\end{itemize}

\paragraph{How it Works:}
\begin{enumerate}
    \item The generated image \(I_{\text{gen}}\) is submitted to Google Image Search to retrieve \(K\) visually and semantically similar images, \(\{I_{\text{search},1}, I_{\text{search},2}, \dots, I_{\text{search},K}\}\).
    \item Embeddings are extracted for \(I_{\text{gen}}\) and each retrieved image \(I_{\text{search},k}\) using a pretrained model like DINO ViT, which captures global and local visual features.
    \item The cosine similarity between the embeddings of \(I_{\text{gen}}\) and each \(I_{\text{search},k}\) is computed and averaged. A higher similarity indicates better alignment with real-world references.
\end{enumerate}

\paragraph{Key Insights:}
\begin{itemize}
    \item \textbf{Interpretation:} A lower verifiability loss suggests that the generated image aligns well with real-world imagery, while a higher loss indicates greater divergence.
    \item \textbf{Applicability:} Verifiability loss is crucial in domains like journalism, education, and scientific visualization, where factual consistency is paramount.
\end{itemize}

This loss formulation balances creativity in generation with the need for authenticity and alignment with real-world references.


\textls[-10]{To compute Verifiability Loss (\(\mathcal{L}_{\text{verifiability}}\)) for the images in \cref{fig:slider_selection_image_variations_1}, given the prompt "\emph{Pentagon is under fire}," we evaluate the cosine similarity between the embeddings of each generated image (\(I_{\text{gen}}\)) and the top-\(K\) real-world reference images retrieved from Google Image Search (\(I_{\text{search},k}\)), leveraging DINO ViT for feature extraction. The loss values underscore the balance between minimalism and the risk of propagating misinformation.}

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\columnwidth]{img/alpha_stable_diffusion.pdf}
    \caption{\textls[-10]{A comparative visualization of the density distributions of the Alpha values for three models: \textit{Stable Diffusion 3.5}, \textit{DPO}, and \textit{CAO}. The X-axis represents the Alpha values, while the Z-axis denotes the density. Peaks at 3.34 for Stable Diffusion 3.5, 4.82 for DPO, and 4.95 for CAO highlight the respective model's generalization capabilities. The \textit{Generalization Threshold} (gold dashed line) and \textit{Overfitting Threshold} (red dashed line) emphasize the trade-offs between generalization and potential overfitting. The progressive shift of peaks demonstrates the increasing robustness and alignment capabilities from Stable Diffusion 3.5 to CAO. Additionally, the decrease in peak height from Stable Diffusion to DPO and CAO reflects a broadening of the distributions, signifying enhanced flexibility and greater adaptability to diverse prompts. For better understanding please refer to \cite{martin2021predicting}.}}
    \label{fig:htsr_generalization_main}
\end{figure}

Image 1 exhibits the lowest verifiability loss (\(0.12\)) as it avoids depicting unverifiable details, favoring a minimalist and abstract representation. Conversely, Image 5 incurs the highest verifiability loss (\(0.80\)) due to its hyper-realistic portrayal, which closely resembles actual disaster imagery, thereby posing a significant risk of misinformation. Intermediate losses are observed for Image 2 (\(0.30\)), Image 3 (\(0.45\)), and Image 4 (\(0.65\)), reflecting varying degrees of creative embellishments such as dramatic flames, smoke, and aerial perspectives.

These results demonstrate the critical role of \(\mathcal{L}_{\text{verifiability}}\) in evaluating the alignment of generated content with real-world references, especially in contexts where overly realistic yet fabricated visuals could mislead viewers and propagate misinformation.
