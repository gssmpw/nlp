\documentclass[final]{eptcs}


\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
% \usepackage{iftex}
\bibliographystyle{eptcs} 
\usepackage{amsmath,latexsym}
% \usepackage{graphicx}
\usepackage{amsthm,amssymb}
%\usepackage[english]{babel}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{proposition}[theorem]{Proposition}
% \usepackage{multirow}
% \usepackage{times}
% \usepackage{helvet,courier}
% \usepackage{courier,txfonts,palatino}
%\renewcommand{cite}{citep}
%\usepackage{fullpage}
%\usepackage[margin=45pt]{geometry}
\DeclareMathAlphabet{\mathitbf}{OML}{cmm}{b}{it}   
%\let\citep\cite
%\bibliographystyle{eptcs}



%\lefttitle{Vaishak Belle}

\newcommand{\titlerunning}{Counterfactual Explanations as Plans}
\newcommand{\authorrunning}{Vaishak Belle}

% \jnlPage{1}{8}
% \jnlDoiYr{2021}
% \doival{10.1017/xxxxx}

\title{Counterfactual Explanations as Plans}

\author{Vaishak Belle 
\institute{University of Edinburgh \& Alan Turing Institute, UK}
\email{vaishak@ed.ac.uk}}

% \begin{authgrp}
% \author{\sn{Vaishak} \gn{Belle}}
% \affiliation{University of Edinburgh \& Alan Turing Institute, UK}
% % \author{\sn{Cambridge} \gn{Author2}}
% % \affiliation{Cambridge University Press}
% \end{authgrp}
%
% \history{\sub{xx xx xxxx;} \rev{xx xx xxxx;} \acc{xx xx xxxx}}

\input defn

\begin{document}
	
\maketitle



\begin{abstract} There has been considerable recent interest in explainability in AI, especially with black-box machine learning models.  As correctly observed by the planning community, when the application at hand is not a single-shot decision or prediction, but a sequence of actions that depend on observations, a richer notion of explanations are desirable. 

In this paper, we look to provide a formal account of ``counterfactual explanations," based in terms of action sequences. We then show that this naturally leads to an account of model reconciliation, which might take the form of the user correcting the agent's model, or suggesting actions to the agent's plan. For this, we will need to articulate what is true versus what is known, and we appeal to a modal fragment of the situation calculus to formalise these intuitions. We consider various settings: the agent knowing partial truths, weakened truths and having false beliefs, and show that our definitions easily generalize to these different settings. 

\end{abstract}

% \begin{keywords}
% Counterfactuals, Explanations, Situation Calculus, Knowledge, Action
% \end{keywords}

\input matter



% \begin{thebibliography}{10}
% \footnotesize  
% \bibitem{baral_et_al:DR:2017:8285}
% C.~Baral, T.~Bolander, H.~van Ditmarsch, and S.~McIlrath.
% \newblock {Epistemic Planning}.
% \newblock {\em Dagstuhl Reports}, 7(6):1--47, 2017.

% \bibitem{baral2005logic}
% C.~Baral and M.~Gelfond.
% \newblock Logic programming and reasoning about actions.
% \newblock In {\em Handbook of Temporal Reasoning in Artificial Intelligence},
%   pages 389--426. Elsevier, 2005.

% \bibitem{Belle:2014aa}
% V.~Belle and G.~Lakemeyer.
% \newblock Multiagent only knowing in dynamic systems.
% \newblock {\em JAIR}, 49, 2014.

% \bibitem{bertossi2021declarative}
% L.~Bertossi.
% \newblock Declarative approaches to counterfactual explanations for
%   classification.
% \newblock {\em TPLP}, pages 1--35, 2021.

% \bibitem{bogatarkan2020explanation}
% A.~Bogatarkan and E.~Erdem.
% \newblock Explanation generation for multi-modal multi-agent path finding with
%   optimal resource utilization using answer set programming.
% \newblock {\em TPLP}, 20(6):974--989, 2020.

% \bibitem{borgo2018towards}
% R.~Borgo, M.~Cashmore, and D.~Magazzeni.
% \newblock Towards providing explanations for ai planner decisions.
% \newblock {\em arXiv preprint arXiv:1810.06338}, 2018.

% \bibitem{cashmore2019towards}
% M.~Cashmore, A.~Collins, B.~Krarup, S.~Krivic, D.~Magazzeni, and D.~Smith.
% \newblock Towards explainable ai planning as a service.
% \newblock {\em arXiv preprint arXiv:1908.05059}, 2019.

% \bibitem{classen2007towards}
% J.~Classen, P.~Eyerich, G.~Lakemeyer, and B.~Nebel.
% \newblock Towards an integration of golog and planning.
% \newblock In {\em IJCAI},  2007.

% \bibitem{Clasen:2007vn}
% J.~Classen, P.~Eyerich, G.~Lakemeyer, and B.~Nebel.
% \newblock Towards an integration of golog and planning.
% \newblock In {\em Proc. IJCAI}, pages 1846--1851, 2007.

% \bibitem{dai2022counterfactual}
% X.~Dai, M.~T. Keane, L.~Shalloo, E.~Ruelle, and R.~M. Byrne.
% \newblock Counterfactual explanations for prediction and diagnosis in xai.
% \newblock In {\em Proc. AAAI/ACM AIES}, pages 215--226, 2022.

% \bibitem{Delgrande:2012fk}
% J.~P. Delgrande and H.~J. Levesque.
% \newblock Belief revision with sensing and fallible actions.
% \newblock In {\em Proc. KR}, 2012.

% \bibitem{fan2015contingency}
% J.~Fan, Y.~Wang, and H.~Van~Ditmarsch.
% \newblock Contingency and knowing whether.
% \newblock {\em The Review of Symbolic Logic}, 8(1):75--107, 2015.

% \bibitem{fandinno2022thirty}
% J.~Fandinno, W.~Faber, and M.~Gelfond.
% \newblock Thirty years of epistemic specifications.
% \newblock {\em TPLP}, 22(6):1043--1083,
%   2022.

% \bibitem{fox2017explainable}
% M.~Fox, D.~Long, and D.~Magazzeni.
% \newblock Explainable planning.
% \newblock {\em arXiv preprint arXiv:1709.10256}, 2017.

% \bibitem{Fritz:2008uq}
% C.~Fritz, J.~A. Baier, and S.~A. McIlraith.
% \newblock Congolog, sin trans: Compiling congolog into basic action theories
%   for planning and beyond.
% \newblock In {\em KR}, pages 600--610, 2008.

% \bibitem{gelfond1993representing}
% M.~Gelfond and V.~Lifschitz.
% \newblock Representing action and change by logic programs.
% \newblock {\em J. Logic Prog.}, 17(2-4):301--321, 1993.

% \bibitem{ginsberg1986counterfactuals}
% M.~L. Ginsberg.
% \newblock Counterfactuals.
% \newblock {\em Artificial intelligence}, 30(1):35--79, 1986.

% \bibitem{DBLP:journals/jacm/HalpernM90}
% J.~Y. Halpern and Y.~Moses.
% \newblock Knowledge and common knowledge in a distributed environment.
% \newblock {\em J. {ACM}},  1990.

% \bibitem{kambhampati2020challenges}
% S.~Kambhampati.
% \newblock Challenges of human-aware ai systems.
% \newblock {\em AI Magazine}, 41(3), 2020.

% \bibitem{DBLP:conf/kr/KellyP08}
% R.~F. Kelly and A.~R. Pearce.
% \newblock Complex epistemic modalities in the situation calculus.
% \newblock In {\em KR}, 2008.

% \bibitem{krarup2019model}
% B.~Krarup, M.~Cashmore, D.~Magazzeni, and T.~Miller.
% \newblock Model-based contrastive explanations for explainable planning.
% \newblock 2019.

% \bibitem{LakemeyerLevesque2004}
% G.~Lakemeyer and H.~J. Levesque.
% \newblock Situations, {S}i! situation terms, {N}o!
% \newblock In {\em Proc. KR}, pages 516--526, 2004.

% \bibitem{Lakemeyer:2011:SCU:1897346.1897552}
% G.~Lakemeyer and H.~J. Levesque.
% \newblock A semantic characterization of a useful fragment of the situation
%   calculus with knowledge.
% \newblock {\em Artificial Intelligence}, 175:142--164, 2011.

% \bibitem{DBLP:journals/sLogica/LesperanceLLS00}
% Y.~Lesp{\'e}rance, H.~J. Levesque, F.~Lin, and R.~B. Scherl.
% \newblock Ability and knowing how in the situation calculus.
% \newblock {\em Studia Logica}, 66(1):165--186, 2000.

% \bibitem{Levesque97-Golog}
% H.~Levesque, R.~Reiter, Y.~Lesp\'erance, F.~Lin, and R.~Scherl.
% \newblock Golog: A logic programming language for dynamic domains.
% \newblock {\em Journal of Logic Programming}, 31:59--84, 1997.

% \bibitem{77758}
% H.~J. Levesque.
% \newblock All {I} know: a study in autoepistemic logic.
% \newblock {\em Artificial Intelligence}, 42(2-3):263--309, 1990.

% \bibitem{DBLP:conf/aaai/Levesque96}
% H.~J. Levesque.
% \newblock What is planning in the presence of sensing?
% \newblock In {\em Proc. AAAI / IAAI}, pages 1139--1146, 1996.

% \bibitem{lin1994forget}
% F.~Lin and R.~Reiter.
% \newblock {Forget it}.
% \newblock In {\em Working Notes of AAAI Fall Symposium on Relevance}, pages
%   154--159, 1994.

% \bibitem{mothilal2020explaining}
% R.~K. Mothilal, A.~Sharma, and C.~Tan.
% \newblock Explaining machine learning classifiers through diverse
%   counterfactual explanations.
% \newblock In {\em Proceedings of the 2020 conference on fairness,
%   accountability, and transparency}, pages 607--617, 2020.

% \bibitem{muise-aaai-15}
% C.~Muise, V.~Belle, P.~Felli, S.~McIlraith, T.~Miller, A.~Pearce, and
%   L.~Sonenberg.
% \newblock Planning over multi-agent epistemic states: A classical planning
%   approach.
% \newblock In {\em Proc. AAAI}, 2015.

% \bibitem{pearl2009causality}
% J.~Pearl.
% \newblock {\em Causality}.
% \newblock Cambridge university press, 2009.

% \bibitem{pednault1989adl}
% E.~Pednault.
% \newblock {ADL}: Exploring the middle ground between {STRIPS} and the situation
%   calculus.
% \newblock In {\em Proc. KR}, 1989.

% \bibitem{reifsteck2019epistemic}
% D.~Reifsteck, T.~Engesser, R.~Mattm{\"u}ller, and B.~Nebel.
% \newblock Epistemic multi-agent planning using monte-carlo tree search.
% \newblock In {\em Joint German/Austrian Conference on Artificial Intelligence
%   (K{\"u}nstliche Intelligenz)}, pages 277--289. Springer, 2019.

% \bibitem{reiter2001knowledge}
% R.~Reiter.
% \newblock {\em {Knowledge in action: logical foundations for specifying and
%   implementing dynamical systems}}.
% \newblock {MIT} Press, 2001.

% \bibitem{citeulike:528170}
% R.~B. Scherl and H.~J. Levesque.
% \newblock Knowledge, action, and the frame problem.
% \newblock {\em Artificial Intelligence}, 144(1-2):1--39, 2003.

% \bibitem{shapiro2002cognitive}
% S.~Shapiro, Y.~Lesp{\'e}rance, and H.~Levesque.
% \newblock The cognitive agents specification language and verification
%   environment for multiagent systems.
% \newblock In {\em Proc. AAMAS}, pages 19--26, 2002.

% \bibitem{shvo2022resolving}
% M.~Shvo, T.~Q. Klassen, and S.~A. McIlraith.
% \newblock Resolving misconceptions about the plans of agents via theory of
%   mind.
% \newblock In {\em Proc. ICAPS}, volume~32, pages 719--729, 2022.

% \bibitem{sohrabi2010diagnosis}
% S.~Sohrabi, J.~A. Baier, and S.~A. McIlraith.
% \newblock Diagnosis as planning revisited.
% \newblock In {\em Proc. KR}, 2010.

% \bibitem{son2001formalizing}
% T.~Son and C.~Baral.
% \newblock Formalizing sensing actions--a transition function based approach.
% \newblock {\em Artificial Intelligence}, 125(1-2):19--91, 2001.

% \bibitem{sreedharan2018handling}
% S.~Sreedharan, S.~Kambhampati, et~al.
% \newblock Handling model uncertainty and multiplicity in explanations via model
%   reconciliation.
% \newblock In {\em Proc. ICAPS}, volume~28, pages 518--526, 2018.

% \bibitem{siddthesis}
% S.~Srivastava.
% \newblock {\em Foundations and Applications of Generalized Planning}.
% \newblock PhD thesis, Univ. 
%   Mass. Amherst, 2010.

% \bibitem{DBLP:journals/logcom/DitmarschHL11}
% H.~P. van Ditmarsch, A.~Herzig, and T.~D. Lima.
% \newblock From situation calculus to dynamic epistemic logic.
% \newblock {\em J. Log. Comput.}, 21(2):179--204, 2011.

% \bibitem{vasileiou2022logic}
% S.~L. Vasileiou, W.~Yeoh, T.~C. Son, A.~Kumar, M.~Cashmore, and D.~Magazzeni.
% \newblock A logic-based explanation generation framework for classical and
%   hybrid planning problems.
% \newblock {\em JAIR}, 73:1473--1534,
%   2022.

% \bibitem{wachter2017counterfactual}
% S.~Wachter, B.~Mittelstadt, and C.~Russell.
% \newblock Counterfactual explanations without opening the black box: Automated
%   decisions and the gdpr.
% \newblock {\em Harv. JL \& Tech.}, 31:841, 2017.

% \end{thebibliography}
%\tiny


\bibliography{iclp}

\end{document}