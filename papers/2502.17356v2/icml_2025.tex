
\documentclass{article}

\usepackage{microtype}
\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage{subcaption}  %
\usepackage{float}
\usepackage{booktabs}
\usepackage{hyperref}


\newcommand{\theHalgorithm}{\arabic{algorithm}}


\usepackage[accepted]{icml2025}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

\usepackage[capitalize,noabbrev]{cleveref}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\usepackage[textsize=tiny]{todonotes}

\input{math_commands.tex}

\newcommand{\rosie}[1]{{\color{orange}[#1 -- Rosie]}}
\newcommand{\ns}[1]{{\color{magenta}[#1 -- Naomi]}}
\newcommand{\wm}[1]{{\color{green}[#1 -- Will]}}
\newcommand{\dam}[1]{{\color{orange}[#1 -- DAM]}}
\newcommand{\sqin}[1]{{\color{purple}[#1 -- Sunny]}}

\icmltitlerunning{Distributional Scaling Laws for Emergent Capabilities}

\begin{document}

\twocolumn[
\icmltitle{Distributional Scaling Laws for Emergent Capabilities}




\begin{icmlauthorlist}
\icmlauthor{Rosie Zhao}{kempner,harvard}
\icmlauthor{Tian Qin}{harvard}
\icmlauthor{David Alvarez-Melis}{kempner,harvard}
\icmlauthor{Sham Kakade}{kempner,harvard}
\icmlauthor{Naomi Saphra}{kempner,harvard}

\end{icmlauthorlist}

\icmlaffiliation{harvard}{Harvard University}
\icmlaffiliation{kempner}{Kempner Institute for the Study of Natural and Artificial Intelligence at Harvard University
}

\icmlcorrespondingauthor{Rosie Zhao}{rosiezhao@g.harvard.edu}

\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]



\printAffiliationsAndNotice{}  %

\begin{abstract}
In this paper, we explore the nature of sudden breakthroughs in language model performance at scale, which stands in contrast to smooth improvements governed by scaling laws. While advocates of ``emergence" view abrupt performance gains as capabilities unlocking at specific scales, others have suggested that they are produced by thresholding effects and alleviated by continuous metrics. We propose that breakthroughs are instead driven by continuous changes in the \textit{probability distribution} of training outcomes, particularly when performance is bimodally distributed across random seeds. In synthetic length generalization tasks, we show that different random seeds can produce either highly linear or emergent scaling trends. We reveal that sharp breakthroughs in metrics are produced by underlying continuous changes in their  distribution across seeds. Furthermore, we provide a case study of inverse scaling and show that even as the probability of a successful run declines, the average performance of a successful run continues to increase monotonically.
We validate our distributional scaling framework on realistic settings by measuring MMLU performance in LLM populations. These insights emphasize the role of random variation in the effect of scale on LLM capabilities.
\end{abstract}

\section{Introduction}

On most benchmarks, language model (LM) performance is determined by a scaling law \citep{hestness2017deeplearningscalingpredictable,rosenfeld2019constructivepredictiongeneralizationerror,kaplan2020scaling} that varies smoothly with parameter size and overall training compute. There are, however, a number of celebrated exceptions in which performance abruptly improves on specific benchmarks \citep{srivastava2023beyond}.

These sudden breakthroughs fuel one of the most heated debates in modern machine learning. On one side, advocates of \textbf{emergence} claim that performance abruptly improves at particular scales because those scales allow the LLM to acquire specific concepts that permit out-of-distribution generalization \citep{wei2022emergent}. On the other side, skeptics argue that these sudden improvements are a \textit{mirage} driven by thresholding effects and alleviated by more appropriate continuous metrics---though a few \textbf{breakthrough capabilities} remain stubbornly emergent \citep{schaeffer2024emergent}. Here, we argue that such discontinuities are driven by continuous changes in the \textit{probability} of a breakthrough at each scale.

We posit that a breakthrough capability is often distinguished not by direct responses to scale, but by \textit{multimodal} random variation---in other words, independent training runs form multiple clusters in their performance metrics. Such effects are currently undetected because scaling laws are usually determined by measuring a single training run at each scale, and resources are rarely committed to correct for random variation by reusing the same hyperparameter settings with different random seeds. Although random variation may be benign when model performance is measured in-distribution~\citep{jordanvariance}, previous work suggests that out-of-distribution performance may vary widely across training runs~\citep{zhoualgorithms, zhou2024transformers}, even at larger scales~\citep{madaan2024quantifying}. Since training numerous seeds becomes prohibitively expensive at large scales, we first study length generalization in small models trained on synthetic tasks. In similar settings, existing publications consider only a few training runs and report their summary statistics. By contrast, we characterize their full distribution, demonstrating that these breakthrough tasks exhibit multimodal variation. Our findings can be summarized as follows: 

\begin{figure*}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/figure_1_actual_new.png}
    \vspace{-1mm}
    \caption{\textbf{Different random seeds produce different scaling trends.} Scaling trends can be emergent or continuous for different seeds, even if all models train on the same data with the same hyperparameters. On the counting task, we show trends for random seeds with the highest breakthroughness (seed 93; top left) and linearity (seed 205; top right). We mark parameter counts immediately before and after seed 93's emergence respectively as (a) and (b). Histograms illustrate the bimodal distribution of performance across all random seeds at scales (a) and (b), marking the positions of seeds 93 and 205. Breakthroughs occur when consecutive points represent different clusters; linear trends occur when each point is sampled from the same gradually shifting cluster.}
    \label{fig:emergence}
\end{figure*}

\begin{itemize}
\item \textbf{Breakthrough scaling results from bimodal performance distributions.} Using length generalization as a case study, we demonstrate that different random seeds can exhibit either highly linear or highly emergent scale behavior. We connect these differences to the bimodal distribution of this compositional skill across random seeds, a property that materializes at many parameter scales. At these scales, ``emergence'' is a stochastic property.  \textbf{We observe these bimodal distributions around breakthrough scales both in small synthetic tasks and in LLM performance on MMLU.}
\item \textbf{When a scale curve exhibits sudden, \textit{discontinuous} improvement in a skill, the \textit{probability} of a model learning that skill may be responding \textit{continuously} to scale}. By modeling the bimodal distribution as a mix of failure and success distributions, we illustrate that improvements with scale can come from changes in the probability of success or in the average performance of a successful model (Section~\ref{subsec:bimodality}). In response to the distributional nature of model performances, we propose to use Wassterstein distance to measure changes in performance distribution across model scale (Section~\ref{subsec:emergence_of_bimodality}). Using this metric, we show that the unlocking of model capacity at some small threshold in fact leads to a sudden emergence of bimodality in performance distribution from a unimodal one.  

\item \textbf{Competing solutions can lead to either monotonic or U-shaped trends in emergence likelihood.} We provide two synthetic tasks in which one has well-behaved scaling behavior and another exhibits U-shaped trends when increasing the width of the network (Section~\ref{subsec:inverse_scaling}), a phenomenon also observed in LLM scaling \citep{mckenzie2022inverse}. We note that the performance of successful runs remain monotonic during ranges of inverse scaling, confirming that U-shaped curves in performance distributions are an artifact of success probability; conventional scaling describes the performance of successful runs.

\item \textbf{In realistic settings, multimodal performance clusters emerge based on data composition and model scale.} In Section~\ref{sec:natural_language}, we extend our analysis to the task of multiple choice question answering by continually pretraining LLMs. Our findings confirm that random variation in LLMs is also bimodal on established emergent capabilities.
\end{itemize}
\begin{figure*}
    \centering
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/histograms/addition_depth_acc.pdf} %
        \caption{Fixing network depth to 6 layers.}
        \label{fig:rev_add_fix_depth_hist}
    \end{subfigure}
    
    \vspace{0.2cm}  %
    
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/histograms/addition_width_acc.pdf} %
        \caption{Fixing network width to 8 heads per layer.}
        \label{fig:rev_add_fix_width_hist}
    \end{subfigure}
    \caption{Histograms of exact match accuracy when generalizing to length $40$ sequences on the reverse order addition task when independently scaling width (above) and depth (below).
    }
    \label{fig:rev_add_histograms}
\end{figure*}

\section{Methodology}
\label{sec:methodology}

\subsection{Synthetic Tasks}
\label{sec:methodology_synthetic}

Breakthrough capabilities often require compositional reasoning \citep{srivastava2023beyond,löwe2024abruptspontaneousstrategyswitches,chen_sudden_2024}; we consider the compositional property of length generalization~\citep{graves2016hybrid, kaiser2015neural, lake2018generalization, hupkes2020compositionality}. Below we outline our experimental setup, with further details in Appendix~\ref{app:exp_details}.

\textbf{Architecture:} In our synthetic experiments, we train decoder-only Transformer models from scratch  using rotary position embeddings (RoPE)~\citep{su2024roformer}. To observe the random performance distribution at each scale, we train our models from hundreds of seeds. We choose model sizes by separately increasing the width and depth  hyperparameters, fixing the other hyperparameter. We scale  width by increasing the number of 64-parameter heads per layer.

\textbf{Task: } We consider two algorithmic tasks previously studied in \citet{zhoualgorithms}: counting and reverse-order addition. Performance on these task ranges widely across random seeds. At each  scale, we train models from 250 seeds for learning to count and 200 seeds for reverse-order addition.

\begin{itemize}
    \item \textbf{Count}: Given two numbers in increasing order, the model is trained to generate a sequence which counts consecutively from the first number to the second number. Examples are given in the form \texttt{"5, 9 >, 5, 6, 7, 8, 9"}, while limiting the length of the counting sequence during training. \citet{zhoualgorithms} showed that models trained to count can generalize to more than twice this training length; however, we will reveal a more nuanced view of length generalization based on its distribution across independent model runs.
    \item \textbf{Reverse-Order Addition with Index Hints}: \citet{zhou2024transformers} show that Transformers can generalize to 10-15 digits past their training length with two modifications made to the original addition task: generating the digits of the answer in reverse order and using index hints. Examples are given in the form \texttt{"a0, 3, a1, 4, +, a0, 2, a1, 8, >, a1, 2, a0, 6"}, where the index hints are a consecutive sequence of the max number of digits sampled randomly from 0 to the max evaluation length. 
\end{itemize}

\textbf{Dataset:} During training, we sample sequences i.i.d from the train set and invoke in-context learning by adding examples to the context, following previous work~\citep{jelassirepeat, zhou2024transformers}. The length of examples are sampled uniformly from 1 to the maximum training length, set to 30 for count and 35 for reverse-order addition. 

\subsection{Natural Language Tasks}
\label{sec:mmlu_method}
We extend our investigation to LLMs by testing an emergent natural language understanding task, multiple choice question answering. We test whether the performance clusters observed in emergent synthetic tasks also manifest in LLMs. Specifically, we hypothesize that emergent scaling curves in LLMs express underlying bimodal (or multimodal) performance distributions. During training, the large and diverse pretraining corpus encourages models to acquire various capabilities. While sufficiently large models may learn all such capabilities, smaller models have limited capacity, requiring these capabilities to compete~\citep{merrill2023tale}. This competition, influenced by initialization and data order, leads to varying outcomes across random seeds, forming performance clusters for specific benchmarks.


We train 
LLMs to answer multiple-choice questions,  an established breakthrough capability \citep{srivastava2023beyond,snell2024predicting}. Our procedure can be regarded as continued pretraining, as we mimic the model's original pretraining objective with a dataset of English language sequences. We hypothesize that at the emergence point for this task, performance distributions will also be bimodal across random seeds. 


\textbf{Task}: We consider finetuning LLMs for the MMLU benchmark \cite{hendrycks2021measuring}, a multiple-choice question-answering task. Achieving strong performance on MMLU requires two key abilities: (1) natural language understanding and reasoning with domain-specific knowledge and (2) producing correct answers in the required format. It is this latter auxiliary ability which  leads to emergent trends \citep{srivastava2023beyond,hu2024auxiliary}.


\textbf{Model}: We use the Qwen2.5 family of base models \cite{qwen2.5}. To introduce randomness during continued pretraining, we reinitialize the final attention layer and the subsequent LLM head. We perform full-parameter continued pretraining on these reinitialized models.


\textbf{Data}: To ensure that the multiple choice formatting circuits compete with other tasks during continued pretraining, we create a diverse dataset by mixing the English news subset of C4 \cite{raffel2023exploring} with the official MMLU auxiliary training data. The C4 news data reinforces general language modeling ability, while the MMLU data focuses on multiple-choice question answering.  We vary the proportion of MMLU in this mixture to control the target task's data size in addition to model size, as both are common control variables in the scaling laws literature.

\textbf{Training}: We continue pretraining the Qwen2.5-0.5B and Qwen2.5-1.5B models on our C4-MMLU mixes, training 20 reinitializations on each data mixture ratio. We train Qwen2.5-0.5B models for 2 epochs and Qwen2.5-1.5B models for 5 epochs to ensure convergence on the MMLU validation set. We use a learning rate of 1e-5 with linear decay scheduler.


\section{Synthetic Experiment Results}


\label{subsec:bimodality}
Existing studies on performance breakthroughs across scales typically report results for a single model or, at most, the average of a few runs. The literature suggests that these emergent behaviors are unlocked at certain model scales~\citep{wei2022emergent}, implying that scaling curves for different model runs would generally perform similarly to within a margin of noise. Contrary to this belief, we demonstrate that breakthroughs in  compositional tasks are the result of a stochastic distribution which changes gradually even as individual scaling curves jump abruptly. We will introduce these concepts and our framework through a case study of the reverse order addition task from Section \ref{sec:methodology_synthetic}.

\subsection{Emergence is a Sign of Bimodal Variation}

First, we report benchmark performance across scales on our synthetic tasks by emulating the conventional approach in reporting results for single seeds. Following \citet{srivastava2023beyond}, we take the vector of model performances for the count task given a fixed seed at test length 60 across different scales and calculate their \emph{breakthroughness} and \emph{linearity} metrics. As defined in Appendix~\ref{app:breakthrough}, the former metric measures emergence, whereas the latter measures a smooth response to scale. We plot the performance across scale for the seeds with the highest breakthrough and highest linearity in Figure \ref{fig:emergence}, fixing the random initialization and data order seed across scales.\footnote{Although the fixed seed is standard practice for reporting LLM benchmark performance across scales, the initializations produced by a single seed have no meaningful relation across different scales.} As seen in Figure~\ref{fig:emergence} and Appendix Figure~\ref{fig:breakthrough_seeds}, we can easily find fixed seeds that show varying levels of emergence and linearity, due to random variation in breakthroughs. 

This variation is explained by the bimodality of model performance distributions when varying seed. The histograms shown in Figure~\ref{fig:rev_add_histograms} illustrate that, for a population of models independently trained on the reverse-order addition task, performance clusters into high and low component modes at many parameter sizes. In other words, these scales exhibit distinctly bimodal distributions in length generalization capabilities. This variability is precisely what causes some model runs to appear as breakthroughs while others follow a more linear progression. Specifically, when different runs are clustered into very high or very low performance due to their bimodality, a model might exhibit linear scaling if sampled from the same cluster as the previous scale \emph{or} emergent scaling when switching from the low cluster to the high cluster. These differences ultimately lead to high variability in the timing and degree of emergence.

\subsection{Sudden Jumps From Gradual Distribution Shifts}

When experiments report a performance metric from only one seed or a scalar value summarizing a few seeds, the  outcome is likely to be close to the \emph{mode} performance of the underlying model population. As shown in Figure~\ref{fig:rev_add_quantiles} (top left), the mode of the performance distribution shows a massive spike in improvement mirroring an  emergent benchmark's scaling trend. However, we claim that this discontinuous improvement is only an artifact of sampling the \emph{mode} performance, although this artifact which will also produce discontinuity in many single-seed scaling curves.  Underlying this \textit{discontinuous} performance jump are \textit{continuous} changes in other distributional statistics. In Figure~\ref{fig:rev_add_quantiles} (top right), the mean exhibits a smoother trend in accuracy. Mode and mean diverge thus because the underlying distribution is bimodal, expressing a mixture of ``successful'' and ``failing'' runs. 

Treating the distribution as a mixture of successes and failures, we can separately analyze the \textit{probability} of a successful run and the \textit{performance distribution} of successful runs. Both of these properties are changing continuously and gradually when the mode increases abruptly. If we restrict our analysis to the runs achieving nontrivial 20\% accuracy, we see that the probability (Figure~\ref{fig:rev_add_quantiles} (bottom left) and mean  (bottom right) of such ``successful'' runs both exhibit continuous improvement, with the exception of increasing from depth 2 to 3 (discussed further in Section~\ref{subsec:emergence_of_bimodality}). Even at the mode breakthrough,these underlying distributional properties are only changing gradually. We conclude that when tasks exhibit bimodal 
distributions across random seeds, there are statistics exhibiting continuous improvements underlying the seemingly abrupt improvements across scale.


\begin{figure}[t!]
    \begin{subfigure}[t]{\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/quantiles/rev_add_quantiles_combined_no_li.pdf}
    \end{subfigure}
    \caption{\label{fig:rev_add_quantiles} Summary statistics for models generalizing to test length 40 on the reverse-order addition task. We track overall mode (top left) and overall mean (top right). While the mode exhibits a sharp increase in accuracy at a certain model scale whether scaling width or depth, the mean evolves more continuously as a result of the bimodal nature of the random variation distribution. We also take note of the part of the distribution corresponding to successful runs by plotting the fraction of runs reaching above 20\% accuracy (bottom left) and the mean of such runs (bottom right). The plots for mean include 95\% confidence intervals with 1000 bootstrapped samples.}
\end{figure}

    
    
    
    

\begin{figure}[t!]
    \begin{subfigure}[t]{\linewidth}
        \centering
        \includegraphics[width=0.9\linewidth]{figures/wasserstein/addition_wasserstein_2.pdf}
    \end{subfigure}
    \caption{\label{fig:rev_add_wasserstein} Scaling depth and width independently for the reverse-order addition models, we show Wasserstein-L2 distance from the performance distribution of the final, largest model. We mark  the emergence of bimodality based on the last scale before multiple peaks appear in Figure~\ref{fig:rev_add_histograms}. We mark the mode breakthrough  at the point where  the mode in Figure~\ref{fig:rev_add_quantiles} (top left) sharply increases because successful length generalization becomes marginally more likely than failure. Note that the sharp decrease in W2 distance---corresponding to the appearance of bimodality at depth 3 in Figure~\ref{fig:rev_add_histograms}---occurs before the mode breakthrough. During the apparent breakthrough in the mode, the distributions shift more gradually and continuously with increases in scale.}
\end{figure}



\begin{figure*}[h]
    \centering
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/histograms/count_depth_acc.pdf} %
        \caption{Fixing network depth to 4 layers.}
        
    \end{subfigure}
    
    \vspace{0.2cm}  %
    
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/histograms/count_width_acc.pdf} %
        \caption{Fixing network width to 4 heads per layer.}
        
    \end{subfigure}
    \caption{Histograms for EM accuracy for test length $60$ on the count task, across 8 different scales for independently scaling depth (above) and 10 different scales for scaling width (below).}
    \label{fig:count_histograms}
\end{figure*}

\subsection{Bimodality Emerges Abruptly}
\label{subsec:emergence_of_bimodality}

In the previous section, we found that bimodal random distributions cause performance breakthroughs when scaling up a single training run. We also wish to analyze how the \emph{distribution itself} evolves across scales; as shown in Figure~\ref{fig:rev_add_histograms}, the performance distribution starts as unimodal at the smallest scale, where all models are unable to length generalize. Larger scales yield a bimodal distribution where most of the probability mass is ultimately placed on successful length generalizing runs. A priori, there could be a smooth evolution between these two distributions in which probability mass from failing runs gradually shifts towards higher performance metrics, eventually splitting into a clear separate cluster. We now show, to the contrary, that the shift from unimodal to bimodal is abrupt and instantly polarized into low and high clusters.

To track the evolution of the performance distribution across scales, we plot the Wasserstein-L2 distance of each distribution relative to that of the final, largest model scale when separately fixing width and depth. In Figure~\ref{fig:rev_add_wasserstein} we see that there is a sharp decrease in the W2 distance for scaling with a fixed width, quantifying the sudden appearance of highly successful runs when model depth reaches 3 layers or model width reaches 2 heads. 
These sudden changes identify the moment when a new capability is unlocked, as the distribution transitions abruptly from unimodal on one extreme to bimodal at both extremes. We posit that this transition marks the \textbf{minimum capacity} required to learn the task. We also mark the point in each trend where the mode in Figure~\ref{fig:rev_add_quantiles} (top left) increases sharply. We posit that it may be misleading to draw conclusions about minimal model capacity on a specific task using single runs at each scale, whereas distributional metrics correctly predict the sudden appearance of probability mass placed on successful runs.

\subsection{Count: An Instance of U-shaped Scaling}
\label{subsec:inverse_scaling}

We next consider the counting task (Section \ref{sec:methodology_synthetic}), which also exhibits bimodally-distributed performance (see Figure~\ref{fig:count_histograms}) but ultimately yields a very different scaling effect: a U-shaped curve.
The summary statistics in Figure~\ref{fig:count_quantiles} reveal this peculiar phenomenon, particularly in the fixed-depth trendline. This U-shaped trend in mean accuracy is similar to that observed on certain natural language tasks~\citep{wei2023inverse}. Furthermore, this phenomenon is not simply a result of the choice of summary statistic, as the same curve describes the evolution of the distributions as a whole when measuring their W2 distance in Figure~\ref{fig:count_wasserstein}. 

U-shaped scaling has been observed in LLMs, but its causes are not currently well-understood. When the Inverse Scaling Prize~\citep{mckenzie2022inverse} solicited tasks which exhibit inverse scaling trends---performance decreases at scale---for large models,  \citet{wei2023inverse} revealed that the majority of awarded tasks actually exhibit U-shaped scaling after considering even larger models.
Treating the counting task as a concrete instance of U-shaped scaling at small model scales, we find that this unusual trend is still underscored by monotonic continuous changes in the performance distribution. Indeed, Figure~\ref{fig:count_quantiles} (bottom right) shows that although the trend in the mean across all runs is U-shaped curve, the mean of the ``successful'' runs---those achieving at least 50\% accuracy---still improves monotonically when increasing width. The observation of inverse scaling is, instead, due to changes in the \textit{probability} of success (bottom left). Even when inverse scaling is in effect across a performance distribution, the performance of  successful runs may exhibit more conventional responses to scale.




\begin{figure}[t!]
    \begin{subfigure}[t]{\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/quantiles/count_quantiles_combined_no_lim.pdf}
    \end{subfigure}
    \caption{\label{fig:count_quantiles} As in Figure~\ref{fig:rev_add_quantiles}, we capture various summary statistics for test length 60 on the count task. For fixed width (scaling depth), the trends across overall mode, overall mean, fraction, and mean of successful (above 50\% accuracy) runs are similar to the reverse order addition case. The trend for fixed depth (scaling width) exhibits a U-shaped curve emerge for the mean across \textit{all} runs; however, the mean of  \textit{successful} runs still exhibits continuous improvement.
    }
    \vspace{-0.1cm}
\end{figure}
\begin{figure}[t!]\includegraphics[width=0.9\linewidth]{figures/wasserstein/count_wasserstein_2.pdf}
\caption{\label{fig:count_wasserstein} Wasserstein-L2 distance relative to final model scale when scaling depth and width for the count task. When fixing depth and scaling width, we observe that the W2 metric has an upside-down U-shape at an intermediate range of model scales.
    }
\end{figure}

\subsection{Is Bimodality a Mirage?}
\label{subsec:bimodality_mirage}

Metrics with hard thresholds and discontinuities can artificially induce breakthrough behavior \citep{schaeffer2024emergent}; conversely, continuous metrics can make apparently emergent curves into smooth curves \citep{srivastava2023beyond}. We must be particularly cautious about claiming emergence when requiring model outputs to exactly match a target string, as we do for both synthetic tasks. Are our case studies artifacts of thresholding effects? In other words, do their bimodal distributions become unimodal under continuous metrics? To assess the role of the exact match metric in creating apparent bimodality, we instead consider a continuous equivalent to the exact match metric: the minimum probability assigned to any individual token. If the model fails to assign its highest probability to the correct token for any position in the sequence, it receives a score of zero under the exact match metric, even if the correct token was still highly ranked. Likewise, if the model successfully assigns maximum probability to the correct token, exact match considers it to be accurate whether that probability was high or low. Our continuous metric reports the worst mistake made by the model, i.e., the minimum probability of any correct token in the sequence.

In Figure~\ref{fig:count_histograms_probability}, we plot a histogram for this continuous metric averaged across all samples. The distribution of this  metric across random seeds is often still clustered; its bimodality is not due to thresholding alone. We therefore confirm that emergent capabilities exhibit bimodal performance distributions even when using a continuous performance metric.

\begin{figure*}
    \centering
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/histograms/count_depth_probability.pdf} %
        \caption{Fixing network depth to 4 layers.}
        
    \end{subfigure}
    
    \vspace{0.2cm}  %
    
    \begin{subfigure}{0.7\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/histograms/count_width_probability.pdf} %
        \caption{Fixing network width to 256 hidden dimension.}
        
    \end{subfigure}
    \caption{Histograms of the probabilities assigned to the correct token, calculated by taking the minimum probability within each sequence and averaging across all samples. These histograms are generated for a test length of $60$ on the count task, scaling the parameter count by increasing width with a fixed model depth (top) and by increasing depth with a fixed model width (bottom). Random variation still leads to bimodal performance distributions, even  using this continuous performance metric.}
    \label{fig:count_histograms_probability}

\end{figure*}


\begin{figure*}[h]
    \centering
    \includegraphics[width=0.42\textwidth]{figures/mmlu/qwen0.5B_mmlu_ratio_vs_avg_violin_3000.pdf}
    \hspace{15px}
    \includegraphics[width=0.4\textwidth]{figures/mmlu/qwen_comparison_violin.pdf}
    \caption{
    Violin plots of last-layer reinitialized Qwen2.5 models on the MMLU benchmark.
    \textit{Left} Models are trained on different mixtures of the C4 news subset and the MMLU auxiliary training set. With insufficient MMLU training data, Qwen2.5-0.5B fails to follow the multiple-choice format, resulting in trivial performance. As the MMLU data ratio increases, models trained on different seeds exhibit a bimodal distribution in performance. With enough MMLU examples, all models score above the random baseline.
    \textit{Right}: For a fixed data mix, the smaller model (Qwen2.5-0.5B) is constrained by its capacity and shows a bimodal distribution in MMLU performance. In contrast, the larger model (Qwen2.5-1.5B) consistently learns to answer multiple-choice questions requiring natural language understanding.
    However, our training data for continued pretraining lacks diversity and therefore, models trained on them do not fully recover the multiple choice capability of the original model.
    }
    \label{fig:qwen_emergence}
\end{figure*}





\section{Natural Language Results}
\label{sec:natural_language}

Having documented the bimodal variation of emergent capabilities in small synthetic settings, we turn to large language models (LLMs). We focus on the MMLU dataset, where high performance emerges after the LLM learns the multiple choice format \citep{srivastava2023beyond, hu2024auxiliary}. To avoid the expense of repeatedly training large-scale models from scratch, we simulate independent runs by reinitializing the upper layer of pretrained LLMs before continuing to train them.



\subsection{Emergence Across Data Compositions}

We first examine how data composition influences the emergence of bimodal behavior in Qwen2.5-0.5B.  Specifically, as the training data contains more examples of a target breakthrough task, it changes the task's bimodal performance distribution in ways that mirror the effect of scale.

In Figure \ref{fig:qwen_emergence} (left), when trained on a data mix containing only 5\% MMLU examples and 95\% random sequences from C4 \cite{raffel2023exploring}, most models (out of 20 seeds) achieve near 0\% performance on the MMLU test set. According to the existing literature, this failure stems from a failure to process the multiple-choice format \cite{hu2024auxiliary}. As the proportion of MMLU samples increases, bimodality emerges when MMLU composes 10\% of the training data, where models form two distinct performance clusters. In one cluster, continually pretrained models still fail to follow the correct format, while in the other, models achieve performance at or above the random guess baseline of 25\%. This second cluster contains models that consistently respond with valid multiple choice options; those that outperform the random baseline have even learned to compose the multiple choice format with their world knowledge when selecting an answer. Finally, with sufficient data ($>20\%$ MMLU), models across all 20 seeds consistently outperform the 25\% random baseline.\footnote{Note that Qwen2.5-0.5B base model can already following instructions 0-shot without further finetuning, achieving 39.5\% performance on MMLU. By re-intializing the last layer, we removed the base model's MMLU ability. Our continued training dataset, a mix of C4 news data and the MMLU auxiliary training data, is insufficient to recover the full capability of the the base model. Appendix \ref{app:llm_results} speculates further on the effect of continued training with this pre-existing capability.}


\subsection{Emergence Across Model Scales}

Next, we show that, as in the synthetic setting, LLM model size affects the formation of performance clusters. Fixing the dataset to a mixture with 10\% MMLU auxiliary training samples, we continually pretrain Qwen2.5-1.5B on the same 20 seeds and report MMLU test accuracy in Figure \ref{fig:qwen_emergence} (right). While models built on the smaller Qwen2.5-0.5B form two distinct performance clusters, those built on the larger Qwen2.5-1.5B consistently outperform the random baseline. We conclude that larger scale models can reliably acquire MMLU capability when trained on the same dataset that produces highly bimodal variation at smaller scales. This conclusion recalls the literature on scaling laws, which argues that smaller models require more training examples to match the performance of larger models \citep{rosenfeld2019constructivepredictiongeneralizationerror,kaplan2020scaling}.









\section{Related Works}
\textbf{Random variation:} Even after controlling for critical hyperparameters such as learning rate, model performance remains sensitive to stochastic aspects of the training process---specifically, random initialization and the order of training examples. Prior studies have documented consistent performance differences across various stress test sets~\citep{d2022underspecification, naik2018stress} and observed that these differences persist throughout training, not just at the final checkpoint~\citep{zhou2020curse}. \citet{dodge2020fine} compared the impacts of weight initialization and data ordering, concluding that both contribute equally to variations in out-of-sample performance. 
Additionally, \citet{sellammultiberts} demonstrated that different BERT models independently pre-training  from scratch can differ in downstream task performance and social biases. Existing work has also found model runs can cluster in out-of-distribution behavior \citep{juneja_linear_2023} and in training dynamics \citep{qin2024itree,hu_latent_2023}, hinting at multimodal variation. Our work connects known these random clustering effects to the phenomenon of emergence at scale.

\textbf{Length generalization and compositionality with transformers:} Several studies have highlighted the challenge of length generalization in transformers~\citep{anil2022exploring, deletangneural, gontier2020measuring, hupkes2020compositionality, schwarzschild2021can, zhang2022unveiling}. Various remedies have been proposed to address length generalization failures. Some methods focus on alternative positional encodings~\citep{shaw2018self, presstrain, su2024roformer, kazemnejad2024impact, jelassirepeat}. Others modify the dataset format, either adding scratchpad or Chain-of-Thought formats~\citep{anil2022exploring} or incorporating padding and index hints for specific arithmetic tasks~\citep{jelassi2023length, zhoualgorithms}. Regarding random variation, \citet{zhoualgorithms} and \citet{zhou2024transformers} provide evidence of variability in length generalization across random seeds, which we further investigate and analyze across a range of model scales.

\textbf{Emergent abilities of LLMs:} In large language models, emergent abilities are behaviors that arise unexpectedly as models are scaled up in size or trained on larger datasets~\citep{hestness2017deeplearningscalingpredictable,rosenfeld2019constructivepredictiongeneralizationerror,brown2020language,kaplan2020scaling}. These abilities are characterized by unpredictable and abrupt performance improvements on specific benchmarks at certain scales~\citep{wei2022emergent, ganguli2022predictability, srivastava2023beyond}. Understanding the conditions and mechanisms underlying emergence is a key area of research. Recent studies suggest that emergent abilities may stem from the choice of evaluation metrics rather than fundamental changes in model behavior with increased scale~\citep{schaeffer2024emergent}. Nonetheless, some breakthrough capabilities remain emergent. One direction to better understand the mechanisms underlying emergence is through studying language models trained on algorithmic tasks exhibiting similar behavior; for instance, \citet{gopalaniabrupt} show that BERT models learn the low-rank matrix completion problem with a sudden drop in the loss before interpreting components of the model before and after this transition.  \citet{snell2024predicting} found that some scales exhibit earlier emergence if finetuned explicitly on an emergent task, suggesting that smaller models may have the capacity for that task but are limited by its scarcity in the training corpus.  In a similar vein, we show that emergent capabilities can arise from multimodal random variation using synthetic length generalization tasks as a case study.

\textbf{Depth versus Width Scaling:} Despite scaling laws offering a smooth extrapolation for model performance, downstream performance can vary depending on architecture shape and not just model size~\citep{tayscale}. For compositional tasks, deeper models often generalize better up to a certain point, but for a fixed compute budget, it may be more advantageous to train a shallower, wider model~\citep{petty2024impact}. Various works have proposed explanations for the role of width versus depth in scaling behavior; for instance, \citet{edelman2024pareto} show that increasing network width offers more `parallel queries' over randomized subnetworks which learn sparse features more efficiently.  \citet{levine2020limits} use a border rank argument to establish a width-dependent depth threshold, beyond which additional depth yields diminishing returns. In this work, we specifically investigate how independently scaling width and depth influences the random variation distribution in compositional tasks.

\section{Discussion and Conclusions}
Our work explores the evolution of random variation in model performance across scales, bringing a more nuanced perspective on emergent capabilities than the conventional approach of plotting a single model run per scale. Previous work has already documented the variability of length generalization across random seeds~\citep{zhou2024transformers, zhoualgorithms}; in general, out-of-distribution behavior like compositional rules \citep{mccoy_berts_2019} or associative biases  \citep{sellammultiberts} often exhibit extreme variation compared to in-distribution performance. We attribute a capability's emergence to its underlying bimodal random distribution, which is also documented in text classifier performance metrics \citep{juneja_linear_2023} and even in the timing of generalization breakthroughs during training \citep{hu_latent_2023}. The mode of these performance distributions displays a sharp improvement at a certain model scale, similar to emergent capabilities in the literature, but we attribute these sudden jumps to gradual improvements in the random distribution. Furthermore, we show that bimodality can emerge \emph{before} the mode---or most seeds---exhibit a breakthrough (Section~\ref{subsec:emergence_of_bimodality}); the transition from the initial unimodal distribution to a bimodal one is sudden.

In the wider scaling laws literature, which often focuses on aggregated loss, parameters added by increasing depth and width are often treated interchangeably in their contribution to total compute. By separately considering depth and width, our results suggest that emergent phenomena may be sensitive to tradeoffs between architectural hyperparameters. In particular, we document a regime in which increasing width damages model performance but increasing depth improves model performance. In a research environment increasingly concerned with compositional and breakthrough capabilities, our findings should inspire further study of how these tasks respond to architectural hyperparameter tradeoffs. Our synthetic case study on U-shaped scaling can also enable future research into the origins of inverse scaling trends.

Future work should rigorously verify these findings at larger scales and across more diverse tasks. We especially hope future research can confirm that emergent benchmarks are bimodal when pretraining from scratch across different seeds. 



\section*{Impact Statement}

This work challenges conventional views on emergent capabilities in large language models by demonstrating that performance breakthroughs can be explained by multimodal distributions across training seeds rather than sharp phase transitions. By highlighting the role of random variation in scaling laws, our findings provide a new perspective on model evaluation and reproducibility, emphasizing the need for robust statistical analysis in benchmarking. This research has broad implications for interpreting model capabilities and the responsible development of AI systems.

\section*{Acknowledgments}

This work has been made possible in part by a gift from the Chan Zuckerberg Initiative Foundation to establish the Kempner Institute for the Study of Natural and Artificial Intelligence. RZ, TQ, and SK acknowledge support from the Office of Naval Research under award N00014-22-1-2377 and the National Science Foundation Grant under award \#IIS 2229881. RZ is supported by a Kempner Institute Graduate Research Fellowship, Simons Investigator Fellowship, NSF grant DMS-2134157, DARPA grant W911NF2010021,and DOE grant DE-SC0022199. TQ and DAM are partially supported by the Kempner Institute, the Aramont Fellowship Fund, and the FAS Dean’s Competitive Fund for Promising Scholarship. Our work has been improved by invaluable discussion with Will Merrill and David Chiang.


\bibliography{references}
\bibliographystyle{icml2025}


\newpage
\appendix
\onecolumn

\section{Additional Experimental Details}
\label{app:exp_details}

\subsection{Synthetic Tasks} 

Below we provide more details when training decoder-only language models on the count and reverse order addition---with index hints--- tasks. Hyperparameters are largely adapted from~\citep{zhoualgorithms}. We train all of our models to convergence on the train distribution. 

\textbf{Count task: }For all of our training runs, we fix the vocabulary size to 150. For evaluation, we compute the exact match (EM) accuracy across all consecutive subsequences of the test length. 

\begin{itemize}
\item \textbf{Model scales:} As mentioned in Section~\ref{sec:methodology}, we scale up our models by fixing width and scaling depth and fixing depth and scaling width. The precise parameters for each variation are as follows. For our \textbf{fixed depth experiments}, we fix the network depth to 4 layers and vary width by taking hidden dimensions $\{64, 128, 256, 384, 512, 640, 768, 1024\}$. The head dimension is fixed to 64. For our \textbf{fixed width experiments}, we fix the hidden dimension to be 512 and vary the depth from $\{1, 2, 4, 6, 8\}$ layers.
\item \textbf{Hyperparameters:}  We use a learning rate of $1e-3$ with a cosine decay scheduler and weight decay 0.1. We set the maximum training duration to be 10000 steps, with batch size 128 and context length 256. 
\end{itemize}


\textbf{Reverse Order Addition with Index Hints:} For evaluation, we compute the exact match (EM) accuracy across 500 batches of 128 examples each.

\begin{itemize}
\item \textbf{Model scales:} For our \textbf{fixed depth experiments}, we fix the network depth to 6 layers and vary width by taking hidden dimensions $\{64, 128, 256, 384, 512, 640, 768\}$. For our \textbf{fixed width experiments}, we fix the hidden dimension to be 512 and vary the depth from $\{1, 2, 3, 4, 6, 8, 10, 12\}$ layers.
\item \textbf{Hyperparameters:}  We use a learning rate of $1e-4$ with a cosine decay scheduler and weight decay 0. We set the maximum training duration to be 30000 steps, with batch size 64 and context length 512. 
\end{itemize}



\section{Breakthroughness and Linearity}
\label{app:breakthrough}

\citet{srivastava2023beyond} introduced \emph{breakthroughness} and \emph{linearity} metrics to capture model performance improving suddenly or reliably with scale. Given a model's performances $y_i$ at model scales $x_i$ sorted by ascending model scale, the linearity metric $L$ and breakthroughness metric $B$ are respectively calculated as
\begin{align*}
    &L = \frac{I(y)}{\mathrm{RootMeanSquare}(\{y_{i + 1} - y_i\}_i)}, \\
    &B = \frac{I(y)}{\mathrm{RootMedianSquare}(\{y_{i + 1} - y_i\}_i)}
\end{align*}
where $I(y) = \mathrm{sign}(\arg\max_i y_i - \arg\min_i y_i) (\max_i y_i - \min_i y_i)$.

\section{Additional Figures and Experimental Results}

In Figure~\ref{fig:breakthrough_seeds} we sample the five top seeds for the breakthroughness and linearity metric respectively for count (above) and reverse order addition (below).

Our plots in the main paper use a fixed test length 60 for count and fixed test length 40 for reverse order addition. In Figure~\ref{fig:count_violins} and Figure~\ref{fig:addition_violins} we show violin plots to view the random variation distribution at each model scale across multiple test lengths for count and reverse order addition respectively.

In Section~\ref{subsec:emergence_of_bimodality}, we posit that the performance distribution becomes bimodal at the \textbf{minimum capacity} required by the task. For example, Figure~\ref{fig:count_fix_depth_1} shows that, regardless of width, models with a fixed depth of 1 layer are unable to length generalize on the count task, despite achieving near-perfect accuracy in-distribution.

In Figure~\ref{fig:count_histograms_probability}, we saw that for the count task, the bimodal random variation distribution persists when viewing a continuous performance metric: the minimum probability averaged across all test sequences. We show in Figure~\ref{fig:rev_add_histograms_probability} that a similar outcome holds for the reverse order addition task.

\begin{figure*}
    \centering
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=0.7\textwidth]{figures/scaling_curves/breakthrough_count.png} %
        \caption{Count.}
        
    \end{subfigure}
    
    \vspace{0.2cm}  %
    
    \begin{subfigure}{0.7\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/scaling_curves/breakthrough_rev_add.png} %
        \caption{Reverse order addition.}
        
    \end{subfigure}
    \caption{Top five seeds corresponding to calculations in breakthroughness and linearity given in Appendix~\ref{app:breakthrough} for both the count task (top) and reverse order addition task (bottom).}
    \label{fig:breakthrough_seeds}
\end{figure*}


\begin{figure*}
    \centering
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/violin/count_violin_fix_depth.png} %
        \caption{Fixing network depth to 4 layers.}
        \label{fig:count_10_fix_depth_violin}
    \end{subfigure}
    
    \vspace{0.2cm}  %
    
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/violin/count_violin_fix_width.png} %
        \caption{Fixing network width to 256 hidden dimension.}
        \label{fig:count_10_fix_width_violin}
    \end{subfigure}
    \caption{Violin plots for the same histograms from Figure~\ref{fig:count_histograms}, i.e. for EM accuracy for test length $60$ on the count task, across 8 different scales for independently scaling depth (above) and 10 different scales for scaling width (below).}
    \label{fig:count_violins}
\end{figure*}




\begin{figure*}
    \centering
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/violin/addition_violin_fix_depth.png} %
        \caption{Fixing network depth to 4 layers.}
        \label{fig:addition_10_fix_depth_violin}
    \end{subfigure}
    
    \vspace{0.2cm}  %
    
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/violin/addition_violin_fix_width.png} %
        \caption{Fixing network width to 256 hidden dimension.}
        \label{fig:addition_10_fix_width_violin}
    \end{subfigure}
    \caption{Violin plots for the same histograms from Figure~\ref{fig:rev_add_histograms}, i.e. for EM accuracy for test length $40$ on the reverse order addition task, across 5 different scales for independently scaling depth (above) and 5 different scales for scaling width (below).}
    \label{fig:addition_violins}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{figures/histograms/count_fix_depth_1.pdf}
    \caption{
    Histogram for EM accuracy for test length 30 (blue, i.e. in-distribution) and test length 60 (orange, i.e. out-of-distribution) on the count task when fixing depth to be one layer. While all model seeds obtain near perfect accuracy in-distribution, all model seeds fail to length generalize at this depth.
    }
    \label{fig:count_fix_depth_1}
\end{figure*}

\begin{figure*}
    \centering
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/histograms/rev_add_depth_probability.pdf} %
        \caption{Fixing network depth to 6 layers.}
        
    \end{subfigure}
    
    \vspace{0.2cm}  %
    
    \begin{subfigure}{0.6\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/histograms/rev_add_width_probability.pdf} %
        \caption{Fixing network width to 8 heads per layer.}
        
    \end{subfigure}
    \caption{Histograms of the probabilities assigned to the correct token, calculated by taking the minimum probability within each sequence and averaging across all samples. These histograms are generated for a test length of $40$ on the reverse order addition task task, considering 5 different scaling factors for depth (top) and 3 different scaling factors for width (bottom). As we saw in Figure~\ref{fig:count_histograms_probability},  the bimodal nature of the random variation distribution persists even when measuring probability.}
    \label{fig:rev_add_histograms_probability}

\end{figure*}

\section{Additional LLM Results}
\label{app:llm_results}
We repeat the same data mix experiment detailed in Section \ref{sec:mmlu_method} on Qwen2.5-1.5B and report results in Figure \ref{fig:qwen1.5_emergence}. In contrast to Figure \ref{fig:qwen_emergence} \textit{left}, a larger model can learn to perform well on the MMLU task with fewer samples in the training data. For example, Qwen2.5-1.5B can consistently achieve non-trivial performance when the continually pretrained on a data mix that only contains 5\% of MMLU auxiliary training samples. In contrast, to achieve a similar performance distribution across 20 runs, Qwen2.5-0.5B requires a data mix that contains 20\% of MMLU auxiliary training samples. Interestingly, while the emergence of MMLU capability for Qwen2.5-0.5B showcase bimodal behavior, such a phenomenon is not observed in Qwen2.5-1.5B. As we increase the MMLU ratio in the training data from 0.01\% to 0.5\%, we instead see a more continuous transition from 0\% MMLU performance to non-trivial performance. We qualitatively observe that even with a very small amount of MMLU samples, the last-layer reinitialized Qwen2.5-1.5B model can sometimes learn to output multiple-choice answers but not consistently across all the MMLU test questions. The inconsistent format following behaviors leads to a more continous transition that we observe in Figure \ref{fig:qwen1.5_emergence}. 


Given that the even the performance distributions with the highest variability in Qwen2.5-1.5B are not clearly bimodal, it appears that bimodality depends on model capacity, at least in our continual pretraining setup. We speculate that even a small number of MMLU examples may draw out a latent ability to handle multiple choice formats in the 1.5B model. There is  support for the notion that a model might encode some useful latent structure without yet being able to use it; masked language models learn to  represent linguistic structure before they learn to use it for complex grammaticality judgments \citep{chen_sudden_2024}.


\begin{figure*}
    \centering
    \includegraphics[width=0.6\textwidth]{figures/mmlu/qwen1.5B_mmlu_ratio_vs_avg_violin_3000.pdf}
    \caption{
    Violin plots for last-layer reinitialized Qwen2.5-1.5B models on the MMLU benchmark. The emergence of MMLU capability on Qwen2.5-1.5B shows a more continuous transition. 
    }
    \label{fig:qwen1.5_emergence}
\end{figure*}



\end{document}
