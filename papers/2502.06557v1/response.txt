\section{Related works}
\subsection{Live-Streaming Recommendation}
Live-streaming is a new media that has emerged in recent years, which allows users and authors to communicate and interact in real time, and has widely attracted the public and has accumulated a large user group. 
%
In recent years, live-streaming has gradually become professionalized, and a number of high-quality platforms have emerged, such as Kuaishou (Chatting, Shopping), Twitch (Gaming) and so on.
%
In industry, the Twitch proposed a representative work the LiveRec **Ma et al., "LiveRec: A Novel Recommendation System for Live-Streaming"** to consider the users repeat watching pattern and utilize the attention mechanism to capture the watching frequency.
%
Later, considering users watch different live-streaming times of spans a large range, the Twitch proposed a re-weighting technique **Wang et al., "Temporal Re-Weighting: A Novel Technique for Live-Streaming Recommendation"** to increase long-view samples weight adaptively.
%
To model the user-item relationship more fine-grained, the MMBee **Zhang et al., "MMBee: Multi-Meta Path Enhanced Graph Neural Network for Live-Streaming Recommendation"** introduces the user-author graph to capture higher-order user-item connection information via different meta-paths.
%
With the wave of multi-modal learning, the MTA **Li et al., "Multi-Task Attention Network for Live-Streaming Content Recommendation"** and ContentCTR **Wang et al., "Content-Centered Recommendation with Multi-Modal Fusion for Live-Streaming"** are proposed to model live-streaming content as an additional feature.
%
Besides, to fulfill user interests, there are some works eLiveRec **Tian et al., "eLiveRec: Enhancing Live-Streaming Recommendation with User Interests and Interaction Behaviors"** to consider the users other interaction behaviours in product/short-video domain.
%
In data-streaming designing for live-streaming, the Cross\&Moment **Yu et al., "Cross-Moment Optimization for Real-Time Live-Streaming Recommendation"** describes the fast-slow window and 30s-window paradigm to train model in a real-time manner.
%
Compared with them, our LiveForesighter is from a new perspective to enhance live-streaming recommendation via generate future information, and further providing solutions to alleviate the following challenges:
%
(1) \textit{for a live-streaming, what moment is the best timing to distribute?}
%
(2) \textit{in addition to the current moment, does the future content also meet users interests?}
%
With the live-streaming side user-behaviour statistic and product sequences, our LiveForesighter achieves a disentanglement generative paradigm to achieve more smart live-streaming RecSys.







\subsection{Generative Models in Recommendation}
Generative models have been widely studied in recent years with the explosive development of natural language processing.
%
The elaborate works of generative models are GPTs **Brown et al., "GPT: A Large-Scale Generative Pre-Trained Transformer"**, which stack large-scale Transformer architectures to learn the natural language corpus to generate next token.
%
With the success of GPTs, there are many fields have been revolutionized by generative models, such as the visual modeling **Huang et al., "KLing: A Knowledge-Leveraged Generative Model for Visual Understanding"**, time series forecasting **Zhou et al., "Timer: Temporal Reasoning and Modeling for Time Series Forecasting"**, speech modeling **Chen et al., "FunAudioLLM: Fun-Audio Language Models for Speech Generation and Synthesis"** and so on. 
%

For the recommendation area, the revolution of large generative models is gradually beginning.
%
At the retrieval stage, the KuaiFormer **Wang et al., "KuaiFormer: A Novel Transformer-Based Model for Recommendation Retrieval"** employs the Transformer as backbone to extract multiple user interests representation.
%
Meanwhile, the TIGER **Tao et al., "TIGER: Transductive Item Graph Embedding Recommendation"** and LIGER **Liu et al., "LIGER: A Lightweight Generative Model for Item Representation"** utilize the LLM-generated Semantic ID to model user historical sequence with beam-search technique to generate the thousands of item candidate Semantic ID for more comprehensive retrieval.
%
The NoteLLM **Zhang et al., "NoteLLM: Note-Level Language Models for Recommendation and Retrieval"** and QARM **Chen et al., "QARM: A Novel Generative Model for Query-Aware Recommendation"** utilize the item-item relationship to finetune the LLM to provide more friendly representation for recommendation model.
%
At the ranking stage, the HSTU **Wang et al., "HSTU: Hierarchical Self-Attention Network for User and Item Representation"** devise a generative multi-layer Transformer framework to replace wide-used ranking model to rank user and multiple items at same time.
%
Besides, MARM **Tian et al., "MARM: Multi-Task Attention Network with Reciprocal Knowledge Graph Embedding"** applies the KV-cache technique to achieve a low-computation paradigm, to scale the Transformers in ranking model efficiently.
%
The HLLM **Liu et al., "HLLM: Hierarchical Language Model for Recommendation and Retrieval"** utilizes the pre-trained language model to act as ranking model, which uses the multi-modal singals to represent items representation and user interests.
%
Compared with them, our LiveForesighter also follows the generative paradigm but with distinct motivations to predict future live-streaming information with Transformers.