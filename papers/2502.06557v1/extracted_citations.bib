@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={Arxiv},
  year={2023}
}

@article{an2024funaudiollm,
  title={Funaudiollm: Voice understanding and generation foundation models for natural interaction between humans and llms},
  author={An, Keyu and Chen, Qian and Deng, Chong and Du, Zhihao and Gao, Changfeng and Gao, Zhifu and Gu, Yue and He, Ting and Hu, Hangrui and Hu, Kai and others},
  journal={Arxiv},
  year={2024}
}

@article{bai2023qwen,
  title={Qwen technical report},
  author={Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and others},
  journal={Arxiv},
  year={2023}
}

@article{cao2024moment,
  title={Moment\&Cross: Next-Generation Real-Time Cross-Domain CTR Prediction for Live-Streaming Recommendation at Kuaishou},
  author={Cao, Jiangxia and Wang, Shen and Li, Yue and Wang, Shenghui and Tang, Jian and Wang, Shiyao and Yang, Shuang and Liu, Zhaojie and Zhou, Guorui},
  journal={Arxiv},
  year={2024}
}

@article{chen2022weighing,
  title={Weighing dynamic availability and consumption for Twitch recommendations},
  author={Chen, Edgar and Ally, Mark and Santana, Eder and Ali, Saad},
journal={Arxiv},
  year={2022}
}

@article{chen2024hllm,
  title={Hllm: Enhancing sequential recommendations via hierarchical large language models for item and user modeling},
  author={Chen, Junyi and Chi, Lu and Peng, Bingyue and Yuan, Zehuan},
  journal={Arxiv},
  year={2024}
}

@article{contentctr,
  title={ContentCTR: Frame-level Live Streaming Click-Through Rate Prediction with Multimodal Transformer},
  author={Deng, Jiaxin and Shen, Dong and Wang, Shiyao and Wu, Xiangyu and Yang, Fan and Zhou, Guorui and Meng, Gaofeng},
  journal={Arxiv},
  year={2023}
}

@inproceedings{deng2024mmbee,
  title={MMBee: Live Streaming Gift-Sending Recommendations via Multi-Modal Fusion and Behaviour Expansion},
  author={Deng, Jiaxin and Wang, Shiyao and Wang, Yuchen and Qi, Jiansong and Zhao, Liqin and Zhou, Guorui and Meng, Gaofeng},
  booktitle={ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)},
  year={2024}
}

@inproceedings{eliverec,
  title={Cross-domain disentangled learning for e-commerce live streaming recommendation},
  author={Zhang, Yixin and Liu, Yong and Xiong, Hao and Liu, Yi and Yu, Fuqiang and He, Wei and Xu, Yonghui and Cui, Lizhen and Miao, Chunyan},
  booktitle={IEEE International Conference on Data Engineering (ICDE)},
  year={2023},
}

@article{kuaiformer,
  title={KuaiFormer: Transformer-Based Retrieval at Kuaishou},
  author={Liu, Chi and Cao, Jiangxia and Huang, Rui and Zheng, Kai and Luo, Qiang and Gai, Kun and Zhou, Guorui},
  journal={Arxiv},
  year={2024}
}

@inproceedings{liutimer,
  title={Timer: Generative Pre-trained Transformers Are Large Time Series Models},
  author={Liu, Yong and Zhang, Haoran and Li, Chenyu and Huang, Xiangdong and Wang, Jianmin and Long, Mingsheng},
  booktitle={International Conference on Machine Learning (ICML)},
    year={2024},
}

@inproceedings{liverec,
  title={Recommendation on live-streaming platforms: Dynamic availability and repeat consumption},
  author={Rappaz, J{\'e}r{\'e}mie and McAuley, Julian and Aberer, Karl},
  booktitle={ACM Conference on Recommender Systems (RecSys)},
  year={2021}
}

@article{luo2024qarm,
  title={QARM: Quantitative Alignment Multi-Modal Recommendation at Kuaishou},
  author={Luo, Xinchen and Cao, Jiangxia and Sun, Tianyu and Yu, Jinkai and Huang, Rui and Yuan, Wei and Lin, Hezheng and Zheng, Yichen and Wang, Shiyao and Hu, Qigen and others},
  journal={Arxiv},
  year={2024}
}

@article{lv2024marm,
  title={MARM: Unlocking the Future of Recommendation Systems through Memory Augmentation and Scalable Complexity},
  author={Lv, Xiao and Cao, Jiangxia and Guan, Shijie and Zhou, Xiaoyou and Qi, Zhiguang and Zang, Yaqiang and Li, Ming and Wang, Ben and Gai, Kun and Zhou, Guorui},
  journal={Arxiv},
  year={2024}
}

@article{tian2024videotetris,
  title={VideoTetris: Towards Compositional Text-to-Video Generation},
  author={Tian, Ye and Yang, Ling and Yang, Haotian and Gao, Yuan and Deng, Yufan and Chen, Jingmin and Wang, Xintao and Yu, Zhaochen and Tao, Xin and Wan, Pengfei and others},
  journal={Arxiv},
  year={2024}
}

@inproceedings{tiger,
  title={Recommender systems with generative retrieval},
  author={Rajput, Shashank and Mehta, Nikhil and Singh, Anima and Hulikal Keshavan, Raghunandan and Vu, Trung and Heldt, Lukasz and Hong, Lichan and Tay, Yi and Tran, Vinh and Samost, Jonah and others},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)}, 
  year={2023}
}

@article{xi2023multimodal,
  title={A multimodal time-series method for gifting prediction in live streaming platforms},
  author={Xi, Dinghao and Tang, Liumin and Chen, Runyu and Xu, Wei},
  journal={Information Processing \& Management (IPM)},
  year={2023},
}

@article{yang2024unifying,
  title={Unifying Generative and Dense Retrieval for Sequential Recommendation},
  author={Yang, Liu and Paischer, Fabian and Hassani, Kaveh and Li, Jiacheng and Shao, Shuai and Li, Zhang Gabriel and He, Yun and Feng, Xue and Noorshams, Nima and Park, Sem and others},
  journal={Arxiv},
  year={2024}
}

@article{zhai2024actions,
  title={Actions speak louder than words: Trillion-parameter sequential transducers for generative recommendations},
  author={Zhai, Jiaqi and Liao, Lucy and Liu, Xing and Wang, Yueming and Li, Rui and Cao, Xuan and Gao, Leon and Gong, Zhaojie and Gu, Fangda and He, Michael and others},
  journal={Arxiv},
  year={2024}
}

@inproceedings{zhang2024notellm,
  title={NoteLLM: A Retrievable Large Language Model for Note Recommendation},
  author={Zhang, Chao and Wu, Shiwei and Zhang, Haoxin and Xu, Tong and Gao, Yan and Hu, Yao and Chen, Enhong},
  booktitle={Companion Proceedings of the ACM on Web Conference},
  year={2024}
}

