%\label{08Tab_random}
\input{08Tab_random}

\subsection{Experimental Setup}
\textbf{Problem Settings}. We adopt the standard data generation process from the previous work~\cite{kool2018attention}. 
The training set consists of 8192 instances, each with 1000 nodes randomly sampled from a uniform distribution. 
The test set includes both synthetic data and real-world data from TSPLIB~\cite{reinelt1991tsplib}. 
The synthetic data includes instances with three problem sizes: 1000, 5000, and 10000 nodes, referred to as TSP-1000, TSP-5000, and TSP-10000, respectively.  
The TSP-1000 and TSP-10000 test sets use the same instances as in \citet{fu2021generalize}, with 128 and 16 instances, respectively. The TSP-5000 test set is generated similarly, with 16 instances. 
For subsequence reconstruction problems, each subsequence length is set to $m=100$. For regional reconstruction problems, the center point $c$ is sampled from the $[0,1]^2$ space, and the number of removed edges is set to $k=60$. 

\textbf{Model Settings}. The constructive model $\boldsymbol{\theta}$ consists of  $L=6$ decoding layers with $A = 5 \times 5$ anchor nodes. Both the subsequence reconstruction model $\boldsymbol{\psi}$ and the regional reconstruction model $\boldsymbol{\phi}$ have 6 encoding layers.  
We evaluate LocalEscaper in three modes: 
(1) \textbf{LocalEscaper greedy}: A greedy construction using the constructive model; 
(2) \textbf{LocalEscaper Rec100}: After greedy construction, the solution is refined with 100 improvement iterations by our improver; 
(3) \textbf{LocalEscaper Rec500}: Similar to Rec100, but with up to 500 improvement iterations. 

\textbf{Training}. We follow a curriculum learning approach~\cite{wang2021survey}, starting with shorter subsequences and progressively increasing their length as training progresses.  Specifically, the subsequence length $|\boldsymbol{\tau}^{\prime}|$ is sampled from the range $[30,130]$ for each batch. 
After each epoch, the bounds of the sampling range are increased by 5, continuing until the upper bound reaches 1000 nodes. 
The optimizer is Adam~\cite{kingma2014adam}, with an initial learning rate of 1e-4 and a decay rate of 0.99 per epoch. Both the reconstruction models $\boldsymbol{\psi}$ and $\boldsymbol{\phi}$ are trained with the same optimizer and learning rate. 

\textbf{Baselines}. We compare our method with 
(1) \textbf{Classical solvers}: Concorde~\cite{applegate2009certification} and LKH-3~\cite{helsgaun2017extension}; 
(2) \textbf{Constructive solver}s: POMO~\cite{kwon2020pomo}, Pointerformer~\cite{jin2023pointerformer}, H-TSP~\cite{pan2023h}, INViT-3V\cite{fang2024invit} and LEHD greedy~\cite{luo2023neural}; (3) \textbf{Search-based solvers}: Att-GCN~\cite{fu2021generalize}, DIFUSCO~\cite{sun2023difusco}, GLOP~\cite{ye2024glop} and LEHD RRC100~\cite{luo2023neural}. 

\textbf{Metrics and Inference}.
We evaluate the methods based on three metrics: average tour length (Obj.), average optimality gap (Gap) and total run-time (Time). 
Since classical solvers are run on a single CPU, their run-time should not be directly compared with methods running on a GPU. 
All neural solvers are run on an RTX 3090 GPU for inference. We set a maximum inference time of 6 hours per problem size, and any method exceeding this time limit is marked as "N/A". 


\input{08Tab_TSPLIB}

\begin{figure}[t]
\centering
\includegraphics[width=60mm]{Z_Decomposition.pdf}
\caption{Ablation study on the three steps of improver. %for TSP-1000.
}
\label{fig:Decomposition}
% \vspace{-2em}
\end{figure}

\subsection{Results and Analysis}
The main experimental results on the uniform distribution instances are presented in Table \ref{Table: TSP random}. 
% We report the total time taken to solve all instances. 
In comparison with constructive solvers, LocalEscaper demonstrates  fast inference speed under greedy decoding and achieves the lowest gap across all three instance sizes. Our constructive model $\boldsymbol{\theta}$, based on LEHD, performs similarly to LEHD on TSP-1000 but outperforms it on instances with more than 1000 nodes. % Due to LEHD is trained on small-scale instances with 100 nodes, while our model employs a lightweight linear attention mechanism that reduces computational overhead, enabling training on instances with up to 1000 nodes. As a result, it performs better  generalization on large-scale instances. 
While LEHD is trained on small-scale instances (with 100 nodes), our model uses a lightweight linear attention mechanism that reduces computational overhead, enabling training on larger instances (up to 1000 nodes), resulting in better generalization to large-scale instances.

Compared to search-based solvers, LocalEscaper also achieves the lowest gap across all instance sizes. LocalEscaper Rec100 delivers  competitive solutions in a short amount of time, while LocalEscaper Rec500 further improves the solution quality by reducing the gap for TSP-1000 to $0.74\%$, and for TSP-5000 and TSP-10000 to $1.29\%$ and $1.69\%$. 


Experimental results on TSPLIB are shown in Table \ref{Table: TSPLIB}. We categorize instances into three groups based on their size: $1\sim1000$ nodes, $1001\sim5000$ nodes, and over 5000 nodes. For each group, we solve all instances sequentially. 
Emphasizing the optimality gap, we compare LocalEscaper with other search-based methods. LocalEscaper Rec500 achieves the lowest gap across all instance categories. LocalEscaper Rec100 outperforms Att-GCN, LEHD RRC100, and DIFUSCO in inference speed, while achieving similar or lower gaps compared to other methods. 



\input{08Tab_WSL_vs_SL}
% \input{{Table/08Tab_RR}
\input{08Tab_TSP-5W}

\subsection{Ablation Study} 
\textbf{Weakly-supervised Learning vs. Supervised Learning}.  
To assess the difference between weakly-supervised learning and fully-supervised learning for training the constructive model, we present a comparison in Table \ref{Table: weakly SL vs. SL}. 
Both methods were trained on the same dataset of 1000-node instances, with LKH-3 generating the labels for SL.  
Although weakly-supervised learning slightly outperforms supervised learning on TSP-1000, the difference is only $0.05\%$, indicating that the performance is %essentially comparable.
nearly identical.  For instances with more than 1000 nodes, supervised learning exhibits better generalization.

\textbf{Effect of the Improver's Components}. 
We conducted an ablation study on TSP-1000 to investigate the impact of each component of the improver.  
Figure \ref{fig:Decomposition} shows the solution improvement process over 500 iterations, with one or two components of the improver removed. Removing either regional reconstruction or both regional reconstruction and 2-opt significantly reduces performance, indicating that relying solely on subsequence reconstruction leads to a fast convergence to low-quality local optima.

\subsection{Performance on Larger Scale Instances} 
Table \ref{Table: TSP-5W} presents the evaluation results of LocalEscaper on TSP-20000 and TSP-50000, each with 16 instances. We removed the 2-opt step from the improver in TSP-50000 to adapt to the scale of these instances. The results show that while the generalization of the constructive model decreases on TSP-50000,  the improver still efficiently enhances solution quality. 


