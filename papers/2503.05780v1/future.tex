

\documentclass{article}
\usepackage{graphicx} % Required for inserting images

% \documentclass[a4paper,12pt]{article}  % Standard article class with A4 paper size

% Essential packages
\usepackage[a4paper, margin=1in]{geometry}  % Set margins
\usepackage{graphicx}  % For including images
\usepackage{titlesec}  % For section formatting
\usepackage{fancyhdr}  % Custom headers and footers
\usepackage{hyperref}  % Clickable links
\usepackage{amsmath, amssymb}  % Math symbols if needed
\usepackage{todonotes}  % For comments (optional)

\usepackage[edges]{forest}
\usepackage{xcolor}
\usepackage[skins]{tcolorbox}%
\usepackage{tcolorbox}
\usepackage{hyperref}
\newtcolorbox[auto counter, number within=section]{definitionbox}[2][]{%
colframe=black!50,
colback=black!5,
coltitle=white,
fonttitle=\bfseries,
title={#2},
sharp corners=south,
enhanced,
before upper={\noindent},
}

% Title and author
%\title{\textbf{AI Risk Atlas (Nexus? open to either) - Taxonomy and Tooling for Navigating AI Risks and Resources}}
\title{\textbf{AI Risk Atlas:\\
Taxonomy and Tooling for\\Navigating AI Risks and Resources}}

\author{Frank Bagehorn, Kristina Brimijoin, Elizabeth M. Daly, Jessica He,\\Michael Hind, Luis Garc√©s-Erice, Christopher Giblin, Ioana Giurgiu,\\Jacquelyn Martino, Rahul Nair, David Piorkowski, Ambrish Rawat, John Richards,\\Sean Rooney, Dhaval Salwala, Seshu Tirupathi, Peter Urbanetz,\\Kush R. Varshney, Inge Vejsbjerg, Mira L. Wolf-Bauwens}
%\date{\today}

\begin{document}

\maketitle  % Generate title

\section{Potential for the future} \label{sec-potential}
There is immense potential of automation of various aspects of compliance and risk management processes. While human oversight and manual verification are still essential requirements for compliance, auditing and regulatory purposes, automation can help to bring an efficient execution of intermediate stages in the compliance workflow. AutoML strategies have been employed to automate model training pipelines excelling at tasks such as feature selection,  hyper parameter optimization, model generation and evaluation \cite{he2021automl,wang2020autoai}. In a similar manner AI governance pipelines could be employed to detect and mitigate risks. By starting with identifying the most relevant risks, running the most relevant benchmarks and then assessing the impact of employing real-time mitigation strategies, concrete recommendations can be made to improve safety of AI solutions.

In the context of complex systems LLMs are increasingly being used as part of the validation process, from software testing and assisting in tasks such as test case preparation \cite{wang2024software} to assessing the output of an LLM \cite{van2024field,shankar2024validates, ashktorab2024aligning}. With the increasing capabilities of LLMs their applications have gone beyond single function tasks to being used to address complex problems acting as autonomous-agents \cite{wang2024survey}. ToolLLaMA learns how to call appropriate API based tools \cite{schick2023toolformer} meaning LLMs can orchestrate tasks that leverage existing functionality embedded in other tooling. The research community has begun to use agent flows to design, plan and execute scientific experiments  \cite{boiko2023emergent} and even write papers \cite{lu2024ai}.

%\begin{itemize}
%    \item AutoML opportunities for CI/CD pipelines
%    \item Agentic solutions for lifecycle governance
%    \item Potential links to policy and regulations
%    \item Open questions and challenges. How can practisioners use the information in the risk atlas to communicate to stake holders
%\end{itemize}

Given these evolving capabilities agentic frameworks\cite{lang-graph,crewai,autogen,bee-ai-framework} have the potential to create real-time governance pipelines, from identifying relevant risks and benchmarks to identifying mitigating actions to online monitoring capabilities. To reliably build such pipelines a method to organise and connect these functional components together must be created to curate appropriate meta-data. 
%\todo{Elizabeth: We really need some related work here on LLM Agentic frameworks. Mike: I added 4 citations to frameworks. I'm not sure if you wanted more than that. Elizabeth: Thank you!}



%Further, to ensure adaptive realtime governance of LLMs, an agentic framework can be established. This can enable monitoring of LLM models in production for drift, enhanced risk exposure or security attacks. The agent systems should inherently possess the capacity for self-improvement through mechanisms such as continuous learning from experience, data, and feedback, ensuring refinement of AI governance performance and adaptability. This is essential for maintaining reliability, and overall effectiveness of AI governance systems over time.

% \begin{itemize}
%     \item Potential for Automation and Scaling 
%     \item Intent to Governance for AI Lifecycle pipelines [Seshu]
%         \todo{MH: Here are 2 citations\cite{watsonx-gov-dec-2024,lee2023qb4airaquestionbankai} that can be used as examples for risk identification questionnaires. The first is the best we have for what was shipped in x.gov (Marc will create a blog post in the near future) and the 2nd is an external group.}
%     \item Agentic workflows for real-time dynamic governance [Seshu]
% \end{itemize}

\section{Conclusion and call to action} \label{sec-conc}

Curating the Risk Atlas is just the first step in providing a reference framework for researchers and practitioners navigating the rapidly evolving AI landscape. By positioning our risk taxonomy in relation to existing definitions and taxonomies, we aim to encourage the community to map new risk definitions, datasets, benchmarks, research papers, and crucially mitigation and detection strategies into a structured framework. This approach will enhance accessibility and facilitate the operationalisation of AI governance processes.

The initial tools released as part of the Risk Atlas Nexus toolkit represent only the beginning of what is possible. We are committed to ongoing development, enabling the developer community to contribute and expand this initiative. By fostering a community-driven approach, we can lower the barrier to entry for all. We invite the open-source community to enrich the knowledge graph by linking benchmarks, datasets, and research papers to identified risks. Additionally, contributors can request new functionality through GitHub enhancement requests or develop and integrate their own algorithms.





\bibliographystyle{plain}
\bibliography{refs}

\appendix
\input{ibm-ai-risk-atlas-risks-formatted}

\end{document}
