\section{Related Work}
\label{sec:related_work}

\myparagraph{Dataset Search}
To better understand the behavior of users seeking structured data, Koesten et al~\cite{koesten2017trials} carried out a mixed-methods study, which encompasses interviews with users and analysis of search engine logs. One of the main findings of the interviews was that people often cannot find the data they need. The study also uncovered common strategies people use while searching for datasets, as well as \emph{dataset attributes} that occur frequently in queries, including the category/topic of the dataset (e.g., transportation, business), geographic region covered by the data records, data granularity (e.g., spatial and temporal resolution); and how users determine the relevance of datasets, e.g., looking at summary statistics, understanding the semantics of data. \citet{papenmeier2021genuine} conducted a survey with social science
researchers who expressed their individual information needs for research data. They also found that ``current systems fail to sufficiently support scientists in their data-seeking process'' and mention that a key reason is that the metadata associated with datasets do not cover information that is sought by scientists. This underscores both the disconnect between the datasets a user needs and what datasets a user can actually find, as well as the importance of descriptions that properly describe the data and match users' information needs~\cite{chapman2020dataset}.
%
\citet{Sostek2024Discovering} carried out a study that focused on the user experience with Google Dataset Search. They confirmed the metadata shortcomings identified in previous studies and acknowledge that there is a wide variability on metadata (description) quality, which depends on dataset provides and authors. They also identified an additional challenge: the inconsistency in how datasets are described leads to a higher mental load as users assess relevance and compare different datasets. 
%
We use the findings from these studies to guide the design of the data-driven and semantic profiles in \SystemName. The automatic generation of descriptions can help address these challenges. By using the actual contents of the dataset to generate summaries and augmenting them with semantic information, we can derive high-quality descriptions. While it may not be possible to derive completely uniform descriptions as datasets contain different information, an automated process can be applied to all datasets and enforce a structure that makes the descriptions more uniform. For example, it is not possible to summarize the spatial extent of a dataset that does not contain spatial data, but for all spatial datasets, that information will be made available and represented in a similar fashion.

Discovery queries that go beyond keyword search have been proposed in which a dataset $D$ is the query, and the results include datasets that are related to $D$, e.g., can be joined or concatenated, or are correlated~\cite{lazo@icde2019,josie@sigmod2019,santos23,santos2021correlation}. These queries are orthogonal to and  can be combined with keyword search.
%
The descriptions derived by \SystemName have the potential to improve findability for both existing inverted-index based systems that are widely used, as well as for emerging dataset search engines like Auctus~\cite{castelo2021auctus} that also support keyword-based search.
% 

\myparagraph{Table Understanding and Representation}
Many models have been developed to enhance table understanding and facilitate various downstream tasks by semantically representing table content \cite{hulsebos2019sherlock, wang2021tcn, zhang2019sato, deng2022turl, archetype@vldb2024, herzig2020tapas, chorus@vldb2024, korini2023columnGPT, liu2021tapex, suhara2022doduo, yin2020tabert, wang2021tuta, iida2021tabbie}. 
% 
These areas include but not limited to table question answering, column type analysis and table type classification.
% 
For exmaple, TAPAS \cite{herzig2020tapas} proposes a weakly supervised table parsing model for question answering over tables.
% 
TURL \cite{deng2022turl} presents a novel framework for table understanding and representation learning, which can be fine-tuned for various tasks like entity linking and relation extraction.
% 
DODUO \cite{suhara2022doduo} introduces a column annotation framework based on pre-trained Transformer.
% 
Recently, large language models (LLMs) have begun to play a significant role in various data-related tasks.
% 
Korini and Bizer \cite{korini2023columnGPT} use ChatGPT to address column type annotation with a two-step annotation pipeline, optimizing annotation efficiency. Chorus \cite{chorus@vldb2024} focuses on data exploration tasks, such as table-class detection and column type annotation (CTA). ArcheType \cite{ archetype@vldb2024} establishes a new state-of-the-art for zero-shot CTA performance using LLMs.
% 
These studies demonstrate the growing application of foundation models to achieve state-of-the-art results in these areas.
% 
While these models advance semantic understanding in tables, they do not directly address the problem of generating dataset descriptions. Instead, these models focus on enhancing table comprehension and annotation, providing a foundation that could support enriched dataset descriptions but without the specific goal of generating comprehensive, human-readable summaries of entire datasets.

\myparagraph{Text Generation from Table}
Table-to-text generation models have attained significant attention due to their ability to transform structured data into coherent natural language text \cite{chen2019d2t_lm_switch, puduppully2019d2t_ncp, gong2020tablegpt, chen2020kgpt, liu2021d2t_augplan, su2021d2t_p2g, wang2021d2t_sketch, puduppully2021d2t_macro, zhao2022reastap, tang2023mvp, seo2024unveiling}. 
% 
Among recent advancements, ReasTAP \cite{zhao2022reastap} introduces a novel table pre-training approach, which enhances models' reasoning capabilities through synthetic question-answering examples and demonstrates notable performance gains in producing logically faithful text in various downstream tasks. Additionally, the Multi-task Supervised Pre-training for Natural Language Generation (MVP) model \cite{tang2023mvp} leverages multi-task supervised pre-training to excel in a broad range of natural language generation tasks, including knowledge-graph-to-text and data-to-text generation. 
% 
However, these models are trained on datasets like Rotowire \cite{wiseman2017rotowire}, WikiBio \cite{lebret2016wikibio}, and LogicNLG \cite{chen2020logicNLG}. These datasets are designed for generating narrative text tailored to specific tasks such as sports game summaries and biographical sentences.
% 
While effective for generating natural language text from structured data, these models lack the ability to: (1) create descriptions for keyword-based search and high-level overviews; (2) handle large and heterogeneous datasets with complex structures.
% 
Moreover, they require training for a specific objective. In our scenario, however, we need to generate summaries that are general enough to accommodate a wide range of datasets and cater to different information needs, without requiring specific training for each dataset.

