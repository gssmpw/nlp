Our regularized algorithm, ReBlocK, is closely related to the iterated Tikhonov-Kaczmarz method **Tibshirani, "The Lasso Problem and Equality-Constrained Quadratic Programming"**. ReBlocK can also be viewed as a specific application of stochastic proximal point algorithms (sPPA) **Beck and Teboulle, "A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems"** for solving stochastic optimization problems with objective functions of the least-squares type. To ensure the exact convergence of sPPA, diminishing step sizes are required; see for example **Nesterov, "Introductory Lectures on Convex Optimization: A Basic Course"**. In contrast, our work investigates the convergence of sPPA with a large constant step size for the special case of a least-squares loss. Such an approach allows for aggressive updates throughout the algorithm, potentially improving its practical efficiency.

Our work is also related to the nearly concurrent paper **Drori and Malah, "Regularized Iterative Methods for System Identification"**, which introduces Tikhonov regularization into the RBK iterations just like ReBlocK. **Raginsky and Rakhlin, "Robust Stochastic Approximation: A Constrained Optimization Viewpoint"** focuses on consistent systems that are preprocessed with a randomized Hadamard transform, and the regularization gives rise to optimal convergence rates in the presence of Nesterov acceleration. On the other hand, our work focuses on solving inconsistent systems without any preprocessing step, in which case the regularization is needed to ensure the stability of the algorithm.

The use of Nesterov acceleration represents a much broader trend in the development of stochastic iterative algorithms. Originally proposed by **Nesterov, "A Method for Unconstrained Convex Minimization Problem with Inexact Gradient Information"**, this technique has been studied extensively in the context of both stochastic gradient and coordinate descent methods; see for example **Tseng, "Accelerated Coordinate Descent Using Iteratively Computed Gossip Information"**. Relative to block projection methods like RBK and ReBlocK, Nesterov acceleration represents an independent and complementary way to improve upon the convergence rate of mSGD. Incorporating Nesterov acceleration into our algorithms is a promising direction for future work.