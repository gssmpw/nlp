\section{Related Works}
\label{sec:relatedworks}
In the recent literature~\cite{boob2023stochastic, ma2020quadratically,jia2022first,huang2023oracle,liu2025single}, subgradient-based methods have been developed for non-smooth continuous optimization problems with convex or weakly convex inequality constraints and achieved the oracle complexity of $O(\epsilon^{-4})$ for finding a nearly $\epsilon$-KKT point. Although those methods can be applied to \eqref{eq:gco_general}, their analysis does not utilize the smoothness of the functions and thus has a complexity higher than the one in this work when the constraints are convex. 

The iMELa method we study is closely related to the classical  augmented Lagrangian method (ALM), which has a long history of study~\cite{hestenes1969multiplier,powell1969method,rockafellar1973multiplier,rockafellar1973dual,rockafellar1974augmented,rockafellar1976augmented} and is still one of the most effective approaches for constrained optimization. Below, we review the recent studies on ALM and its variants, including the penalty methods, for the following general problem
\begin{align}
\label{eq:gco_general_new}
    \min_{\bx}f(\bx)+r(\bx) \; \text{s.t.} \; \bg(\bx)=(g_1(\bx),\dots,g_m(\bx))^\top\leq \bzero, \;  
    \bh(\bx)=(h_1(\bx),\dots,h_l(\bx))^\top= \bzero, 
\end{align}
where $f$, $g_i$, $i=1,\dots,m$, and $h_j$, $j=1,\dots,l$, are smooth and have Lipschitz continuous gradients, and $r$ is a proper convex lower semi-continuous function that allows a computationally easy proximal mapping.  When \eqref{eq:gco_general_new} is convex, the oracle complexity of the ALM for finding an $\epsilon$-optimal solution is well studied. See, e.g.~\cite{lan2016iteration,xu2021iteration,xu2021first,he2010acceleration,liu2019nonergodic} for the results under different settings. We next focus on the works that are applicable to \eqref{eq:gco_general_new} or its special cases when the problem is non-convex.  

In several studies on ALM (e.g.~\cite{hong2016decomposing,hajinezhad2019perturbed,zeng2022moreau}), the efficiency of an algorithm is characterized by its \emph{iteration complexity}, defined as the number of main iterations needed for computing an $\epsilon$-KKT point. Since a (proximal) augmented Lagrangian subproblem must be solved in each main iteration of ALM—typically using a separate FOM—the oracle complexity is generally higher than the iteration complexity.  

\textbf{Methods for linear constraints.} Suppose $g_i$'s are not present and $h_j$'s are linear in \eqref{eq:gco_general_new}. When $r\equiv 0$, Hong~\cite{hong2016decomposing} introduced a proximal primal-dual algorithm (prox-PDA) that finds an $\epsilon$-KKT point of \eqref{eq:gco_general_new} with an iteration complexity of $O(\epsilon^{-2})$. When $r$ in \eqref{eq:gco_general_new} is the characteristic function of a box or a bounded polytope, it has been shown in~\cite{zhang2020proximal,zhang2022global} that a smoothed proximal ALM (SP-ALM), which generalizes the classical proximal ALM~\cite{rockafellar1976augmented}, can achieve an $\epsilon$-KKT point with an oracle complexity of $O(\epsilon^{-2})$. When $r$ is the characteristic function of a compact set defined by convex inequalities, it has been shown that SP-ALM also achieves an $O(\epsilon^{-2})$ oracle complexity under CRCQ~\cite{zhang2022iteration}. 

Suppose no additional structural assumption is made on $r$. Hajinezhad and Hong~\cite{hajinezhad2019perturbed} developed a variant of prox-PDA with an iteration complexity of $O(\epsilon^{-4})$. Zeng et al.~\cite{zeng2022moreau} proposed the Moreau envelope ALM (MEAL), a type of proximal ALM, which achieves an iteration complexity of $o(\epsilon^{-2})$ when $f$ satisfies an implicit Lipschitz subgradient property and $O(\epsilon^{-2})$ when $f$ satisfies an implicit bounded subgradient property. The convergence property of MEAL is also established  when the augmented Lagrangian function satisfies the Kurdyka-{\L}ojasiewicz property~\cite{zeng2022moreau}. Kong et al.~\cite{kong2019complexity,kong2020efficient} proposed a quadratic penalty accelerated inexact proximal point (QP-AIPP) method, which finds an $\epsilon$-KKT point with an oracle complexity of $\tilde O(\epsilon^{-3})$. Under additional mildly strong assumptions, a reduced oracle complexity of $\tilde O(\epsilon^{-2.5})$ is achieved by an inexact ALM (iALM) by Li et al.~\cite{li2021rate},  an inexact proximal accelerated augmented Lagrangian (IPAAL) by Melo et al.~\cite{melo2020iteration}, and an inner accelerated inexact proximal augmented Lagrangian (IAIPAL) method  by Kong et al.~\cite{kong2023iteration-SIOPT}. 

\textbf{Methods for nonlinear convex constraints.} Suppose $g_i$'s are convex and $h_j$'s are linear in \eqref{eq:gco_general_new}. Lin et al.~\cite{lin2022complexity} proposed an inexact proximal point penalty (iPPP) method that achieves an oracle complexity of $\tilde{O}(\epsilon^{-2.5})$ under a Slater's condition. Under the similar assumptions, Li and Xu~\cite{li2021augmented} extended this approach to a hybrid method combining ALM and the penalty method with the same complexity. Dahal et al.~\cite{dahal2023damped} provided a damped proximal ALM that achieves the same order of oracle complexity. The iALM by Li et al.~\cite{li2021rate} can also achieve the same complexity but requires an additional regularity assumption (see \eqref{eq:PLconstraint} below). The IAIPAL introduced in~\cite{kong2023iteration-SIOPT} was also extended by Kong et al.~\cite{kong2023iteration-MathOR} to handle nonlinear convex constraints and obtains an $\tilde{O}(\epsilon^{-3})$ oracle complexity. 

When $r$ is the characteristic function of a compact set defined by convex inequalities, Pu et al.~\cite{pu2024smoothed} developed a smoothed proximal Lagrangian method (SP-LM), which finds an $\epsilon$-KKT point with an oracle complexity of $O(\epsilon^{-2})$. In contrast, our method assumes $r$ is the characteristic function of a compact polytope and requires a complexity of $\tilde O(\epsilon^{-2})$. Besides the assumption on $r$, there are two key differences between their method and ours in the updating schemes. First, their method projects the dual variables onto a compact, artificially constructed set,  whereas our method only needs to project the dual variables onto $\mathbb{R}^m_+$. Second, their method only uses a single loop but ours employs a double-loop structure. More importantly, their method relies on a Slater-like condition and a local LICQ condition at all KKT points, whereas we assume a Slater's condition and a local error bound condition on each active subset of the constraint set (see Assumption~\ref{assume:draft_regular_cond_lm}). We will show (see Proposition~\ref{thm:LICQ_implies_regular_cond_lm}) that, if the local LICQ condition in~\cite{pu2024smoothed} holds over all KKT points, our local error bound assumption also holds. However, the converse is not true. Thus, our work extends the complexity analysis of SP-LM to the case not covered in~\cite{pu2024smoothed}.  

\textbf{Methods for nonconvex constraints.} Suppose $g_i$'s are non-convex or $h_j$'s are nonlinear in \eqref{eq:gco_general_new}. In this case, even finding a feasible solution for \eqref{eq:gco_general_new} is generally intractable. When $r$ is the characteristic function of a box and $\bg\equiv\bzero$,~\cite{curtis2015adaptive,curtis2016adaptive} proposed an augmented Lagrangian trust-region method with the global asymptotic convergence guarantee. Their methods may produce an infeasible stationary point due to the non-convex constraints. In general, additional assumptions are needed to obtain a feasible stationary point. For example, assuming a (nearly) feasible solution can be easily obtained, the iPPP method~\cite{lin2022complexity} and a scaled dual descent alternating direction method of multipliers (SDD-ADMM) proposed by Sun and Sun~\cite{sun2024dual} can find an $\epsilon$-KKT point with an oracle complexity of $O(\epsilon^{-4})$. Another common assumption made in literature is the regularity condition, which assumes that there exists $\zeta>0$ such that
\begin{align}
\label{eq:PLconstraint}
    \zeta\sqrt{\|[\bg(\bx)]_+\|^2+\|\bh(\bx)\|^2}\leq \text{dist}\left(-\nabla\bg(\bx)[\bg(\bx)]_+-\nabla\bh(\bx)\bh(\bx),\partial r(\bx)\right)
\end{align}
for any $\bx\in\text{dom}(r)$. When \eqref{eq:PLconstraint} holds and $g_i$'s are not present, Sahin et al. \cite{sahin2019inexact} showed that iALM can find an $\epsilon$-KKT point with a complexity of $\tilde O(\epsilon^{-4})$.  This complexity is reduced to $\tilde O(\epsilon^{-3})$ by the iALM~\cite{li2021rate}\footnote{Although the problem considered in~\cite{li2021rate} involves only equality constraints, their results can be extended to the general problem \eqref{eq:gco_general_new}, as noted in~\cite[Remark 6]{li2021rate}.} and the iPPP method~\cite{lin2022complexity} with the inequality constraints, and to $O(\epsilon^{-3})$ by the SDD-ADMM method~\cite{sun2024dual} without the inequality constraints when there is only one block in $\bx$. Moreover, the SDD-ADMM method~\cite{sun2024dual} can achieve a complexity of $O(\epsilon^{-2})$ under stronger assumptions. Investigating whether an oracle complexity of $O(\epsilon^{-2})$ can be achieved by the iMELa method, SP-LM or SP-ALM under weaker assumptions than those in~\cite{li2021rate} is a topic for future study.