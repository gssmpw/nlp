\documentclass[journal,twoside]{IEEEtran}

\usepackage{etoolbox}
\makeatletter
\@ifundefined{color@begingroup}%
{\let\color@begingroup\relax
\let\color@endgroup\relax}{}%
\def\fix@ieeecolor@hbox#1{%
\hbox{\color@begingroup#1\color@endgroup}}
\patchcmd\@makecaption{\hbox}{\fix@ieeecolor@hbox}{}{\FAILED}
\patchcmd\@makecaption{\hbox}{\fix@ieeecolor@hbox}{}{\FAILED}

% \usepackage{generic}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
% \usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{textcomp}
% \usepackage[justification=centering]{caption}
\usepackage{multirow}
\usepackage{tabularx}
% \usepackage{caption}
% \captionsetup{justification=justified}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
% \markboth{\journalname, VOL. XX, NO. XX, XXXX 2017}
% {Author \MakeLowercase{\textit{et al.}}: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS (February 2017)}

\begin{document}
\title{Enhancing Subject-Independent Accuracy in fNIRS-based Brain-Computer Interfaces with Optimized Channel Selection}




% \author{
%     Yuxin Li\textsuperscript{1,2}, 
%     Hao Fang\textsuperscript{3}, 
%     Wen Liu\textsuperscript{1},
%     Chuantong Cheng\textsuperscript{2,4},
%     and Hongda Chen\textsuperscript{2,4}
%     \thanks{\textsuperscript{1} Affiliation for Yuxin Li and Wen Liu.}
%     \thanks{\textsuperscript{2} Affiliation for Yuxin Li, Chuantong Cheng, and Hongda Chen.}
%     \thanks{\textsuperscript{3} Affiliation for Hao Fang.}
%     \thanks{\textsuperscript{4} Affiliation for Chuantong Cheng and Hongda Chen.}
% }
\author{
    Yuxin Li, Hao Fang, Wen Liu, Chuantong Cheng, Hongda Chen
    \thanks{Yuxin Li is with the School of Mechanical Engineering, Xi’an Jiaotong University, Xi'an, China.}
    \thanks{Hao Fang is with the SMART Group, Institute for Imaging, Data and Communications, School of Engineering, The University of Edinburgh, Edinburgh, UK.}
    \thanks{Wen Liu is with the Department of Electrical and Electronic Engineering, Xi'an Jiaotong-Liverpool University, Suzhou, China.}
    \thanks{Chuantong Cheng and Hongda Chen are with the State Key Laboratory on Integrated Optoelectronics, Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China.}
    \thanks{This work was supported by the National Key R\&D Program of China (Grant Nos. 2021YFB3601201). Correspondence author: Wen Liu and Chuantong Cheng; Email: Wen.Liu@xjtlu.edu.cn; chengchuantong@semi.ac.cn}
}




% \author{
%   \IEEEauthorblockN{Yuxin Li\textsuperscript{1,2}, Hao Fang\textsuperscript{3}, Wen Liu\textsuperscript{1},Chuantong Cheng\textsuperscript{2,4},Hongda Chen\textsuperscript{2,4}}\\


% \IEEEauthorblockA{\textsuperscript{1}School of Advanced Technology, Xi’an Jiaotong-Liverpool University, Suzhou 215123, China\\
%     \textsuperscript{2}Affiliation 2\\
%     \textsuperscript{3}Brain Machine Fusion Intelligence Institute, Jiangsu Industrial Technology Research Institute, Suzhou 215008, China\\
%     \textsuperscript{4}State Key Laboratory on Integrated Optoelectronics, Institute of Semiconductors, Chinese Academy of Sciences, Beijing 100083, China\\
    
%   \thanks{Corresponding author(Email: author4@example.com)}
%   \thanks{This research was supported by Project 123 (Grant No. 456).}
% }

% \thanks{This work was supported by the National KeyR&D Program of China (Grant Nos.2021YFB3601201). }
\maketitle
% \thanks{S. B. Author, Jr., was with Rice University, Houston, TX 77005 USA. He is now with the Department of Physics, Colorado State University, Fort Collins, CO 80523 USA (e-mail: author@lamar.colostate.edu).}
% \thanks{T. C. Author is with the Electrical Engineering Department, University of Colorado, Boulder, CO 80309 USA, on leave from the National Research Institute for Metals, 
% Tsukuba, Japan (e-mail: author@nrim.go.jp).}}

% \maketitle

\begin{abstract}
%In the realm of functional near-infrared spectroscopy (fNIRS) based Brain-Computer Interface (BCI) devices, achieving high subject-independent accuracy in online classification, especially with a reduced number of channels, is a pressing concern. 

% Achieving high subject-independent accuracy in online classification is an important part in the field of functional near-infrared spectroscopy (fNIRS) based Brain-computer Interface (BCI), especially with a reduced number of channels. However, it is often not possible to achieve both of them. This paper proposed a novel feature extraction scheme for fNIRS dataset to improve the subject-independent accuracy. Additionally, we proposed a channel selection algorithm to locate the ROI (Region of Interest) channels, reducing the number of channels required for such classification tasks. We applied scheme on a open access fNIRS dataset. The results show that, under the same classifier, the introduction of our feature extraction scheme resulted in a 28.09\% improvement in average accuracy. Furthermore, the scheme for channel selection achieve a peak subject-independent accuracy of 95.98\% using only two channels: channel 26 in the anterior prefrontal cortex (aPFC) and channel 43 in the right dorsolateral prefrontal cortex (r.DLPFC) on the same dataset. In conclusion, our work is of great significance for the future development of efficient fNIRS-based BCI devices.
Achieving high subject-independent accuracy in functional near-infrared spectroscopy (fNIRS)-based brain-computer interfaces (BCIs) remains a challenge, particularly when minimizing the number of channels. This study proposes a novel feature extraction scheme and a Pearson correlation-based channel selection algorithm to enhance classification accuracy while reducing hardware complexity. Using an open-access fNIRS dataset, our method improved average accuracy by 28.09\% compared to existing approaches, achieving a peak subject-independent accuracy of 95.98\% with only two channels. These results demonstrate the potential of our optimized feature extraction and channel selection methods for developing efficient, subject-independent fNIRS-based BCI systems.

% and complete the channel selection. The model pinpoint the regions of interest channels, streamlining the number of channels needed for such classifications. 
%Current methodologies often fall short in optimizing hardware configurations and maximizing classification accuracy. 
%In this work, we improved subject-independent classification accuracy and proposed channel selection to optimize fNIRS-based BCI devices. We proposed a feature extraction model to improve the classification accuracy. Additionally, we have devised a channel selection algorithm tailored specifically to pinpoint the regions of interest (ROI) channels, streamlining the number of channels needed for such classifications. 
%To be more specific, delving into the intricacies of multi-channel fNIRS raw data, we have crafted a feature extraction scheme capable of simultaneously extracting statistical features, time-domain characteristics, frequency-domain attributes, and principal component statistical features from the raw fNIRS data. We also introduced Pearson correlation into our channel selection algorithm. By constructing adjacency matrices, we strategically select channel pairs that exhibit low correlation yet possess high mutual information, reducing redundant information and ensuring optimal data representation. 
%To validate the effectiveness of our model, 

% Our innovative scheme guides the strategic reduction and optimal positioning of transmitters and receivers, targeting superior binary classification outcomes with reduced hardware dependencies. This feature extraction method we introduce, specifically designed for machine learning, that captures unique fNIRS signal attributes. Validated on a 52-channel binary classification fNIRS dataset, our approach showcased a remarkable 28.09\% surge in classification accuracy over traditional techniques. Additionally, utilizing the same dataset, we constructed adjacency matrices based on Pearson correlation, identifying channel combinations with small interrelations. Applying our feature extraction to both individual and dual-channel combinations, and integrating machine learning-driven binary classification, we discerned the optimal configurations for peak accuracy. Our conclusions pave the way for pinpointing the ideal locations of transmitters and receivers in fNIRS-BCI systems designed for binary tasks. Fundamentally, our approach significantly enhances classification accuracy of fNIRS-based BCI systems, optimizing hardware placement and negating superfluous channels. 
\end{abstract}

\begin{IEEEkeywords}
fNIRS, machine learning, BCI, adjacency matrix, online binary
classification
\end{IEEEkeywords}

\section{Introduction}
\label{sec:introduction}
\IEEEPARstart{T}he advancements in the field of brain-computer interfaces (BCI) have fueled scholarly enthusiasm for the study of cerebral activities. Studying cerebral activity enables interaction between the human cerebral and external devices, with significant contributions to fields such as rehabilitation medicine, psychology, and military. Commonly employed methodologies for evaluating cerebral activity across distinct task states encompass functional near-infrared spectroscopy (fNIRS), functional magnetic resonance imaging (fMRI), and electroencephalography(EEG)\cite{ref36}. Notably, fNIRS boasts distinct advantages over alternative neuroimaging modalities, primarily manifesting in its inherent portability, safety profile, and capacity to withstand environmental electrical noise. Additionally, fNIRS exhibits heightened resilience to motion artifacts and electromyographic (EMG) interferences when juxtaposed with methodologies such as EEG \cite{ref1}. Conversely, while fMRI has been prolific in elucidating the blood oxygenation level-dependent (BOLD) signal, particularly during visual stimuli, fNIRS has unequivocally established correlations between alterations in blood hemoglobin concentration and the presence or absence of external stimulation\cite{ref1,ref8,ref9}. This positioning of fNIRS as a compelling choice for scrutinizing diverse task states within the intricacies of the human brain is thus underscored.
%{F}unctional near-infrared spectroscopy (fNIRS) stands as a noninvasive neuroimaging technique employed for the detection of cerebral activity. 

fNIRS devices have a simple structure, and the measurement principle is not overly complex. An fNIRS device typically includes multiple light sources and detectors, placed on the scalp. The emitted near-infrared light passes through the scalp and brain tissue before being captured by the detectors. By examining how light is absorbed and scattered, it becomes possible to deduce alterations in oxygen levels in different brain regions, thus enabling the study of brain function. fNIRS employs near-infrared light, situated between visible and infrared wavelengths, to measure changes in the concentration of hemoglobin and oxyhemoglobin in brain tissue\cite{ref31}. When specific brain regions are active, blood flow increases, leading to variations in oxygen levels\cite{ref35}. fNIRS calculates these oxygenation changes by analyzing differences in the intensity of incoming and outgoing light. 

The pivotal pursuit of discerning neural activation patterns in the human brain during diverse task states constitutes a fundamental thrust in the practical advancement of BCIs. By measuring hemoglobin concentration changes, fNIRS provides insights into neural activities, positioning it as a promising tool for various BCI tasks, including cognitive, motor, visual, and visuo-motor functions. \cite{ref2,ref3,ref4,ref5,ref6,ref7,ref15}. In 2009, Huppert, T. J., et al\cite{ref16}, utilized Support Vector Machines to classify brain activity during the execution of working memory tasks, achieving an accuracy rate of approximately 85\%. In 2017, Hong, K. S. \cite{ref17}, employed Convolutional Neural Networks (CNN) for classifying experiments that involved controlling external devices through brain activity, achieving an accuracy rate exceeding 90\%. In 2018, Santosa, H. \cite{ref18}, used Linear Discriminant Analysis to classify subjects based on different emotional states, achieving an accuracy rate of over 80\%. While numerous studies\cite{ref13} have delved into enhancing the performance of fNIRS-based BCIs, the dual challenge of subject-independent accuracy and online classification remains largely unaddressed. Most existing methodologies either focus on one aspect, sacrificing the other, or require a large number of subjects and extensive individual calibration sessions, which are not feasible for real-world applications\cite{ref10,ref11,ref14}.

Depending on specific research questions and interests, different types of tasks and classifiers can be selected for fNIRS users. However, there are still some challenges in this field: One of the paramount challenges in the development and deployment of fNIRS-based BCI devices is achieving high subject-independent accuracy. This refers to the algorithm's ability to maintain consistent classification accuracy across different individuals, ensuring that its recognition capabilities are not confined to subjects-dependent but can be generalized across a diverse population\cite{ref25}. Such generalization is crucial, as individual differences in brain anatomy, physiology, and cognitive strategies can introduce variability in neural signals. Moreover, the demand for online classification, which involves real-time processing and interpretation of neural data, further complicates the BCI design.

%To address these challenges, many scholars have proposed creative algorithms to be applied to the fNIRS dataset to improve classification accuracy. %Commonly employed classification methods include, but are not limited to, Support Vector Machines, k-Nearest Neighbors, Linear Discriminant Analysis, and Bayesian classifiers. 

Our study pioneers a novel optimization scheme specifically tailored for binary classification tasks to improve the accuracy of classification. This scheme aims to discover the characteristics of fNIRS data and develop a feature extraction scheme that aligns with hemodynamics for training machine learning classifiers. These features include statistical features, time-domain features, frequency-domain features, and principal component features. Extracting statistical features for different brain regions can construct more accurate classification models. 
%Time-domain features can capture instantaneous changes in brain activity and respond to dynamic changes in brain activity signals over time. When extracting frequency-domain features, Fourier transform is used to explore the relationship between specific frequency fluctuations and the task state, thus improving the classification performance. The introduction of principal component features, on the other hand, preserves data information and improves the feasibility of the algorithm. 
The strength of our scheme lies in its holistic approach, amalgamating diverse feature sets that collectively offer a rich, multi-faceted view of the data. This ensures that our models are informed by  temporal, statistical, and spectral variations of the signals, positioning them for superior performance in classification tasks.
%\item[2)] 

%Harnessing the synergy of adjacency matrices and state-of-the-art machine learning techniques, we endeavor to revolutionize the paradigms of transmitter and receiver placement, feature extraction, and real-time classification.
When conducting channel selection, confronted with the complexity of a vast number of channels, we employ a Pearson correlation-based approach to construct an adjacency matrix. This enables us to quantify the information content within each channel, with the objective of minimizing information loss while reducing the number of channels. This reduction is aimed at enhancing classification accuracy across distinct task states. Central to our approach is a strategic reduction in hardware components, ensuring their optimal positioning, coupled with an innovative feature extraction methodology that adeptly captures the unique attributes of fNIRS signals.
%\end{enumerate}



% To validate the efficacy of our approach, we tested our scheme on a 52-channel fNIRS dataset from a mental arithmetic task done by G. Bauernfe et al.\cite{ref12}. It is worth noting that, when employing the Linear Discriminant Analysis (LDA) machine learning classification method consistent with G. Bauernfe et al, we extract a feature matrix comprising several features, including slope and the maximum, minimum, mean, and variance of Fourier Transform. These features are used to comprehensively describe both the statistical and frequency domain characteristics of the data. Simultaneously, by introducing principal components analysis (PCA) to eliminate redundant information while preserving data integrity, our approach enhances the average accuracy of individual subjects by 28.09\%. Furthermore, our optimization scheme proved its mettle by achieving an astounding subject-independent accuracy of up to 95.98\% with the deployment of merely 1 to 2 sets of transmitters and receivers.

To validate the effectiveness of our scheme, we conducted experiments on a 52-channel binary classification fNIRS dataset related to mental arithmetic. It's noteworthy that our experimental setup maintained consistency with G. Bauernfe et al.\cite{ref12} in terms of utilizing the Linear Discriminant Analysis (LDA) algorithm and the same dataset. With this setup, the introduction of our feature extraction scheme led to a notable 28.09\% improvement in average accuracy. This improvement is the mean value derived from three sets of experiments using oxy-Hb data from three ROIs. Specifically, for ROI$_1$, ROI$_2$, and ROI$_3$, the accuracy enhancements were 25.44\%, 29.56\%, and 29.28\%, respectively. Furthermore, our channel selection algorithm enabled us to achieve a peak subject-independent accuracy of 95.98\% using only two channels: channel 26 in the anterior prefrontal cortex (aPFC) and channel 43 in the right dorsolateral prefrontal cortex (r.DLPFC) on the same dataset.

The rest of this paper is organized as follows. The second section presents the methods used in our scheme. The third section describes the experimental setup of our research, including the introduction of the dataset used, experimental parameter settings, and evaluation metrics. The fourth section presents the experimental results. The fifth section is the conclusion, summarizing the advantages of our scheme and future prospects.

\section{Methods}
\subsection{Feature Extraction}
Feature extraction stands as a cornerstone in the domain of machine learning and signal processing, particularly for complex datasets like those derived from fNIRS\cite{ref30}. %Its primary objective is to transform and reduce the high-dimensional raw data into a more manageable and informative representation, ensuring that the most salient and discriminative features are retained while discarding extraneous noise and redundancies
fNIRS dataset can be noisy due to instruments and the environment. To make sense of this data, researchers extract useful features and use machine learning to classify different brain states \cite{ref26}. This process not only aids in enhancing the interpretability of the data but also plays a pivotal role in improving the efficiency and performance of subsequent analytical tasks.

\begin{figure*}[htbp]
	\centerline{\includegraphics[scale=0.65]{Drawing1.pdf}}
	\caption{Flow chart of our  methods.} %It Includes data segments, feature extraction, construct adjacency matrix. From this flow chart, our me  }
	\label{flowchart}
\end{figure*}

\subsubsection{Statistical Features}
By computing the mean, maximum, minimum, and variance of the data, we succinctly capture its central tendency, range, and variability. The mean reflects the average blood oxygen level over time, while the maximum and minimum values help identify peaks and valleys in brain blood flow, indicating brain activity. Variance measures the instability in the hemodynamic response.
\subsubsection{Frequency-domain Features}
%Through the Fourier transform, we obtain the amplitude spectrum of the data.
The Fourier Transform converts the time-domain data from fNIRS measurements into frequency-domain data, providing information about the different frequency components. It helps to detect changes in blood oxygen at different frequencies.
\subsubsection{Temporal Rate-of-change Features}
By calculating the slope and its associated mean, maximum, minimum, and variance, we gauge the dynamic changes and trends in the time domain. This reveals the rate at which neural activities change over time, highlighting rapid fluctuations or steady states. The slope measures the rate of change in the blood oxygen response, which is important for capturing dynamic changes in brain activity.
\subsubsection{Principal Component Statistical Features}
By leveraging Principal Component Analysis (PCA), we distill the data into its primary modes of variation. This helps to understand the relationships between brain activity characteristics and which characteristics are most important for a particular task or condition.

\begin{equation}	
	\begin{split}
    feature\_matrix(raw\_data\_segment) = \\
    \left[ \begin{array}{cccc}
    mean & max & min & var\\
    pca_{\text{mean}} & pca_{\text{max}} & pca_{\text{min}} & pca_{\text{var}}\\
    slope_{\text{mean}} & slope_{\text{max}} & slope_{\text{min}} & slope_{\text{var}}\\
    fft_{\text{mean}} & fft_{\text{max}} & fft_{\text{min}} & fft_{\text{var}}\\
    \end{array}
    \right ],
    \end{split}
\end{equation}

The equation provided offers a structured representation of a feature matrix derived from a segment of single-channel raw fNIRS data, denoted as $raw\_data\_segment$.This segment captures a specific temporal window of neural activity. Collectively, this feature matrix ensures that subsequent analyses, especially machine learning models, have access to a rich set of features that comprehensively capture the nuances of the underlying neural activity.

%The $mean$ represents the arithmetic average of the values within the segment, offering a measure of the central tendency of the signal. The $max$ and $min$ parameters highlight the peak and lowest intensities of the signal during that segment, respectively, while $var$ quantifies the dispersion of the signal values around their mean. Features derived from the PCA transformation of the segment, such as $pca_{\text{mean}}$, $pca_{\text{max}}$, $pca_{\text{min}}$,and $pca_{\text{var}}$, encapsulate the dominant patterns in the data, with PCA being a technique that captures the primary modes of variance. The slope-related features,including $slope_{\text{mean}}$, $slope_{\text{max}}$, $slope_{\text{min}}$, and $slope_{\text{var}}$, provide insights into the rapidity and directionality of changes in neural activity. Lastly, the features derived from the FFT of the segment, namely $fft_{\text{mean}}$, $fft_{\text{max}}$, $fft_{\text{min}}$, and $fft_{\text{var}}$ capture the spectral characteristics of the signal, offering insights into the dominant frequency components and their intensities.



%The strength of our scheme lies in its holistic approach, amalgamating diverse feature sets that collectively offer a rich, multi-faceted view of the data. This ensures that our models are informed by  temporal, statistical and spectral variations of the signals, positioning them for superior performance in classification tasks.

%Overall, utilizing our meticulously crafted feature extraction scheme for multi-channel fNIRS data to construct feature matrices holds profound significance in the realm of machine learning. Our feature extraction contains comprehensive feature information that matches the data characteristics of the fNIRS dataset, and is a set of feature extraction schemes tailored for fNIRS data.

\subsection{Normalization}
%Normalization is a foundational preprocessing step in machine learning, designed to standardize the range of independent variables or features within the data. The essence of normalization lies in its ability to bring all features to a consistent scale. This uniformity is especially crucial for algorithms that are sensitive to feature scales, such as those that rely on distance computations like k-means clustering or k-nearest neighbors. Without normalization, features with larger scales can disproportionately influence the model's behavior, potentially overshadowing the intrinsic relationships between features.


%Moreover, normalization plays a pivotal role in enhancing the efficiency of optimization-based algorithms. For instance, in methods that employ gradient descent, such as neural networks and linear regression, a consistent feature scale ensures a more regular optimization landscape. This regularity can lead to faster and more stable convergence to the optimal solution, mitigating potential numerical instability issues that might arise in algorithms involving intricate matrix operations.


%In our approach, we employ the Min-Max normalization technique, which linearly scales every feature to lie within a given range, typically [0, 1]. 
After the feature extraction process, the importance of normalization becomes even more pronounced. The fNIRS data usually have different sizes and magnitudes, which if not normalized may lead to some features being overweighted in classification, affecting the classification results. Scaling the data into [0, 1] ensures that all features have similar scales. The formula for Min-Max normalization is:

\begin{equation}
X_{\text{norm}} = \frac{X - X_{\text{min}}}{X_{\text{max}} - X_{\text{min}}}
\end{equation}

Where $X_{\text{norm}}$ is the normalized value, $X$ is the original value, and $X_{\text{max}}$ and $X_{\text{min}}$ are the minimum and maximum values of the feature, respectively.

%Extracted features, whether they be statistical measures like mean and variance, Fourier coefficients, or other derived metrics, can span vastly different scales.
By applying normalization post-feature extraction, we ensure that these diverse features are harmonized in scale, setting the stage for machine learning models to discern and capitalize on the underlying patterns in the data more effectively.

\subsection{Machine Learning}
%Machine learning, a branch of artificial intelligence, focuses on the design of algorithms that allow computers to learn from and make decisions based on data. Instead of being explicitly programmed to carry out a task, these algorithms use statistical techniques to learn patterns in data, enabling them to improve their performance over time.

When tackling binary classification problems using fNIRS data, the selection of the analytical approach is crucial. While deep learning has achieved remarkable success in various areas, especially where large datasets are available, there are compelling reasons to choose traditional machine learning techniques for fNIRS:

\subsubsection{Data Volume Requirements}
Given the complexity and cost associated with many fNIRS experiments, the available data might be limited. Traditional machine learning methods, such as Support Vector Machines (SVM) or Random Forests, often perform well with smaller datasets.

\subsubsection{Computational Complexity}
Machine learning methods are generally more efficient and don't require specialized hardware like GPUs, More responsive to the needs of fNIRS online categorization.

\subsubsection{Model Interpretability}
Models like decision trees or linear regression in machine learning offer better interpretability. This is vital in fields like medicine or biology, where understanding the decision-making process of a model can be crucial. Deep learning models, in contrast, often act as "black boxes."

\subsubsection{Feature Engineering}
In machine learning, researchers can use domain knowledge for feature engineering, potentially improving model performance. For instance, We can use our well-designed feature extraction scheme suitable for fNIRS data classification in machine learning methods. Deep learning models, on the other hand, typically learn features automatically, which might not always be optimal.

In summary, the specific challenges and needs of fNIRS-based binary classification make traditional machine learning methods a more appropriate choice\cite{ref33}. In our experiments, we explored a diverse set of machine learning algorithms, including Support Vector Machine (SVM), Logistic Regression, Decision Tree, K-Nearest Neighbors (KNeighbors), Gaussian Naive Bayes (GaussianNB), Linear Discriminant Analysis (LDA), Multi-layer Perceptron Classifier (MLPClassifier), and Stochastic Gradient Descent (SGD).

Through rigorous testing and comparison, we identified that the MLP, LDA, and SVM consistently outperformed the others, emerging as the top three algorithms best suited for our fNIRS-based binary classification tasks. The architecture and principles of the above machine learning algorithm are:


\textbf{Multilayer Perceptron Classifier (MLP Classifier):}
The MLP Classifier constructs a multilayer neural network after extracting the fNIRS data features, which usually includes an input layer, one or more hidden layers, and an output layer\cite{ref27}. Each neuron receives inputs from the previous layer, weights and sums the inputs, and introduces a nonlinear transformation through an activation function. The weights and bias parameters of the neural network need to be initialized and adjusted to minimize the loss function by the backpropagation algorithm during the training process. The training process is designed to enable the neural network to automatically learn complex relationships between features from fNIRS data in order to accurately classify different task states or brain activity patterns. In this way, the MLP Classifier can help researchers mine useful information from fNIRS data for efficient brain activity classification.

\textbf{Linear Discriminant Analysis (LDA):}
LDA operates by linearly transforming data into a lower-dimensional space, often along a single line or hyperplane. Its primary goal is to maximize inter-class distinctions while minimizing intra-class variations. This approach significantly improves classifier performance\cite{ref28}. In the context of fNIRS data, which often results in high-dimensional, multi-channel time-series datasets, LDA is employed to project this data into a lower-dimensional space. This, in turn, facilitates a more accurate classification of distinct task states.
Furthermore, LDA aims to optimize differences between different categories, making it particularly valuable for investigating disparities among various regions of the brain.

\textbf{Support Vector Machine (SVM):}
Since SVM works well in solving multidimensional small sample sizes and nonlinear classification problems, it is suitable for fNIRS signal classification. SVM tries to find an optimal hyperplane to separate different classes of features, which should be perturbed by the training set as little as possible.
Given a training set of n samples {(x$_i$,y$_i$)},i=1,2,... ,y$_i$ are the sample labels, and find an optimal hyperplane that satisfies the requirements by constructing an objective function, which is described by a linear equation as  :

\begin{equation}
    w^Tx+b=0
\end{equation}
$w$ is a nonzero normal vector perpendicular to the separating hyperplane, and $b$ is the intercept. $d=\frac{2}{||w||_2}$ is the interval we inscribed.
%\end{enumerate}

%Training samples that are linearly classifiable can be classified directly using the above principles and formulas. However, for nonlinearly classifiable problems, a kernel function can be introduced to learn nonlinear support vector machines, which is equivalent to implicitly learning linear support vector machines in a high-dimensional feature space. 
The kernel function used in this study is a Gaussian kernel function, which can be mapped with no linear dimension and more diverse decision boundaries\cite{ref19}.

\subsection{Channel Selection}
\begin{algorithm} 
    
	\caption{Channel Selection} 
	\label{alg4} 
	\begin{algorithmic}
  
		\REQUIRE N-channel fNIRS raw data
		\ENSURE Optimal channel combinations and their accuracies
		\STATE Construct Pearson correlation for N channels
		\STATE Build NxN adjacency matrix based on correlations
		\STATE Sort matrix elements in descending order
        \STATE Select channel combinations with Pearson correlations less than \(0.4\) (indicating weak or very weak correlations) and record their indices
        \STATE Split data based on trials
		\FOR{each channel}
		    \STATE Construct feature matrix using the feature selection scheme
		    \STATE Normalize the feature matrix
		    \STATE Obtain normalized dataset for the channel
		\ENDFOR
		\FOR{each normalized channel dataset}
		    \STATE Apply machine learning algorithm with 5-fold cross-validation
		    \STATE Record accuracy for the channel
		\ENDFOR
		\STATE Sort all accuracies in ascending order
		\STATE Record top 20\% channel indices and their accuracies
		\STATE Scan the recorded single channel indices and previously selected channel combinations
		\STATE Identify channel combinations present in both lists
		\FOR{each identified channel combination}
		    \STATE Apply machine learning algorithm with 5-fold cross-validation on the dataset corresponding to the channel combination
		    \STATE Record accuracy for the channel combination
		\ENDFOR
		\STATE Sort all combination accuracies in ascending order
		\STATE Output all channel combinations and their accuracies that meet the criteria
	\end{algorithmic} 
\end{algorithm}

Channel selection is a pivotal step in the processing and analysis of multi-channel fNIRS data. In the realm of brain-computer interfaces (BCIs), where the data is often high-dimensional due to the multitude of channels, selecting the most informative channels becomes imperative. By focusing on channels that capture the most discriminative information, the accuracy of subsequent classification tasks can be significantly improved. Redundant or noisy channels can introduce variability that might confound the classifiers, leading to sub-optimal performance.

Moreover, in BCIs, real-time response is often crucial, especially for applications like prosthetic control or real-time neurofeedback. Processing data from fewer, but more informative channels can expedite the classification process, ensuring timely responses. From a hardware perspective, every channel in a BCI system corresponds to sensors, transmitters, and associated electronics. By narrowing down to essential channels, the overall cost of the BCI device can be reduced. Additionally, fewer channels mean less data to process, store, and transmit, leading to computational savings and more efficient power utilization.

Given the importance of channel selection, a channel selection algorithm is meticulously designed to identify the most informative and distinct channel combinations from raw data derived from N channels of fNIRS. Our method employs Pearson's correlation coefficient, a statistical measure that quantifies the linear relationship between two variables. The formula for Pearson correlation coefficient, $r$, is given by:

\begin{equation}
r=\frac{\sum_{i=1}^{n}\left(x_{i}-\overline{x}\right)\left(y_{i}-\overline{y}\right)}{\sqrt{\sum_{i=1}^{n}\left(x_{i}-\overline{x}\right)^{2} \sum_{i=1}^{n}\left(y_{i} - \overline{y}\right)^{2}}}
\end{equation}

where $r$ is the Pearson correlation coefficient, quantifies the linear relationship between two samples of data. $x_{i}$ and $y_{i}$ represent individual data points of samples $x$ and $y$, while $\overline{x}$ and $\overline{y}$ denote their respective means. The total number of data points is represented by n. The value of $r$ can range from -1 to 1, with 1 indicating a perfect positive linear relationship, -1 indicating a perfect negative linear relationship, and 0 suggesting no linear relationship.

\begin{table}[h]
\centering
\caption{An Typical Interpretation of Pearson Correlation Coefficient}
\begin{tabular}{|c|c|}
\hline
\textbf{Absolute value of $r$} & \textbf{Interpretation} \\
\hline
0.8 - 1.0 & Extremely Strong Correlation \\
\hline
0.6 - 0.8 & Strong Correlation \\
\hline
0.4 - 0.6 & Moderate Correlation \\
\hline
0.2 - 0.4 & Weak Correlation \\
\hline
0.0 - 0.2 & Very Weak or No Correlation \\
\hline
\end{tabular}
\end{table}


% In the context of this algorithm, it evaluates the linear relationship between signals from different channels. Channels with values close to 1 share similar information, indicating a strong positive correlation. Conversely, a value close to -1 suggests the channels capture inversely related information. 
In our algorithm, we retain only those channel combinations with an absolute value of Pearson correlation below 0.4. This threshold indicates weak or very weak correlations, ensuring that the chosen channels are relatively independent and offer diverse information. To gain a more intuitive understanding of the correlation between different channels, we constructed visual 2D and 3D adjacency matrices based on the absolute values of the computed Pearson correlation, as illustrated in Fig.~\ref{mutual_pearson}.

At the same time, we also employed machine learning algorithms to obtain classification accuracies of models trained using the normalized feature matrices corresponding to each channel. We retained the channel identifiers for the top 20\% of channels based on their performance. After that, we sequentially retrieved channel combinations from those derived based on Pearson correlation that contained the aforementioned channel identifiers with high classification accuracy. We then used machine learning techniques to obtain the classification accuracies corresponding to these channel combinations. Ultimately, we ranked these channel combinations based on their classification accuracy from high to low. The combinations at the forefront are the dual-channel combinations selected by our channel selection algorithm.

% With this understanding, the algorithm constructs an $N \times N$ adjacency matrix based on the calculated correlations, offering a comprehensive view of how each channel relates to every other channel. Prioritizing channels with stronger correlations, the elements of this matrix are sorted in descending order. However, the algorithm's focus is on channels with weak or very weak correlations, ensuring the selected channels' independence.

% Once the channels of interest are identified, the raw data undergoes a splitting process based on trials. This ensures that each trial's data is treated distinctly. For every channel, a feature matrix is then constructed using a predefined feature selection scheme. 
% This matrix undergoes normalization, a crucial step to ensure all features have a consistent scale, which is pivotal for the effective application of many machine learning algorithms.

% The algorithm then embarks on the task of evaluating the performance of each normalized channel dataset. By applying a machine learning algorithm with 5-fold cross-validation, the accuracy for each channel is ascertained and recorded. Post this evaluation, the channels showcasing the highest accuracies, specifically the top 20\%, are earmarked for further analysis.

% In the subsequent phase, the algorithm identifies combinations from the top-performing channels and the previously selected channel combinations. Each of these combinations is then subjected to the machine learning algorithm, and their accuracies are recorded.

% Concluding its operations, the algorithm sorts all the combination accuracies and outputs the channel combinations and their respective accuracies that meet the predefined criteria. Through this intricate process, the algorithm ensures that the selected channels are not just high-performing but also independent, setting the stage for a comprehensive and diverse set of signals for subsequent analysis.

\section{Experimental Setup}
\subsection{Dataset}
In this study, we utilized the 52-channel dataset constructed by Günther Bauernfeind et al. in 2014 for our experiments. This dataset encompasses recordings from eight subjects (three males, five females, with an average age of 26 and a standard deviation of 2.8 years) who exhibited contrasting hemodynamic response patterns during a mental arithmetic (MA) task. In this task, subjects were instructed to perform visually cued arithmetic calculations. For instance, they were tasked with continuously subtracting a single-digit number from a two-digit number (e.g., 97 - 4 = 93, 93 - 4 = 89, …) as swiftly as possible for a duration of 12 seconds, followed by a rest period of 28 seconds.

% The goal is to better explore on single trial classification of these responses. This dataset includes 8 subjects(three male, five female, mean age 26 years). We tested the different classifier on this dataset to achieve the high accuracy of subject-independent.

The data was recorded using a continuous-wave system (ETG-4000, Hitachi Medical Co., Japan) that measures changes in cerebral oxygenation and comprises 16 photodetectors and 17 photo emitters, resulting in a total of 52 channels. The sampling rate was set at 10Hz. The distance between the source and the detector was maintained at 3 cm. The lowest row of channels was aligned along the FP1–FP2 line of the international EEG 10–20 system, with channel 48 precisely positioned at FP1\cite{ref12}.


\begin{figure}[htbp]
	\centerline{\includegraphics[scale=0.30]{raw_data_example1.png}}
	\caption{Temporal variations in the concentration changes of oxy-hemoglobin across our selected 9 channels during a MA task for a single subject. Each channel's data is represented by a distinct color, with colors cycling through a predefined set for clarity. Vertical red lines indicate the start or end of an experimental trial, serving as markers to differentiate between rest periods and active MA phases. The x-axis denotes the sample number, serving as a proxy for time, while the y-axis indicates the amplitude of the oxy-hemoglobin concentration changes. Considering the time delay of the hemodynamic response, there are data rounding operations. The observed fluctuations provide insights into the cerebral hemodynamic responses associated with the cognitive demands of the task. }
	\label{raw_data_example}
\end{figure}

The MA dataset primarily consists of fNIRS raw data, positions of the trials, and labels. The fNIRS raw data reflects the changes in the concentrations of various substances (oxygen-hemoglobin, deoxygen-hemoglobin, total-Hb) in the brain during the experimental process. The positions of the trials, on the other hand, correspond to the start and end of the MA task. The labels illustrate the composition of the entire experimental process, where '1' indicates the MA task is in progress, and '2' signifies a resting state. For instance, Fig.~\ref{raw_data_example} depicts the variation in oxygen-hemoglobin concentration over time in nine channels for a participant throughout the experimental procedure. Within the figure, each curve corresponds to the concentration variation of the substance within a channel, while each vertical red line represents the position of a trial. To make the dataset suitable for machine learning classification, we preprocessed the data. This primarily involved segmenting the data based on the positions of the trials and aligning it with the labels.

% Considering that there is a time delay in the hemodynamic response\cite{ref20}, we divide the task interval from the moment when the MA task starts executing, and round off the data before that point. 
% The data structure of this MA dataset is shown in Fig. 1. Typically, each curve reflects the change of oxygen-hemoglobin concentration over time during the course of the experiment, using data from 9 selected channels of subject 1 as an example. We partitioned the dataset based on the positions of the trials. We divided the dataset based on the  by a vertical red line at the beginning of the experiment (when the mental arithmetic task is about to be performed) and at the end of the experiment (when the rest phase is about to be entered). The experimental data of the remaining seven subjects were also divided in the same way, with the aim of distinguishing between the two different state of the subjects in the task-performing phase and the resting phase. 

% This dataset encompasses recordings from eight subjects (three males, five females, with an average age of 26 and a standard deviation of 2.8 years) who exhibited contrasting hemodynamic response patterns during a mental arithmetic (MA) task. In this task, subjects were instructed to perform visually cued arithmetic calculations. For instance, they were tasked with continuously subtracting a single-digit number from a two-digit number (e.g., 97 - 4 = 93, 93 - 4 = 89, …) as swiftly as possible for a duration of 12 seconds, followed by a rest period of 28 seconds.

\subsection{Experimental Setting}
After preprocessing the dataset, we first employed our feature extraction scheme to construct feature matrices. Then, these matrices undergo normalization, a crucial step to ensure all features have a consistent scale, which is pivotal for the effective application of many machine learning algorithms. Subsequently, we partitioned the dataset into 80\% for training and 20\% for testing. Finally, for training datasets generated based on different single channels or channel combinations, we trained and tested using various machine learning algorithms. %including Support Vector Machine (SVM), Logistic Regression, Decision Tree, K-Nearest Neighbors (KNeighbors), Gaussian Naive Bayes (GaussianNB), Linear Discriminant Analysis (LDA), Multi-layer Perceptron Classifier (MLPClassifier), and Stochastic Gradient Descent (SGD).

Throughout the process, we set all random seeds to 56 to ensure the reproducibility of the experiments. Additionally, the kernel for our SVM classifier was set to 'linear'. For the MLP classifier, the size of the hidden layers was set to (10, 10, 10, 10), with a maximum iteration count of 3000.
% We divided this dataset into 80\% training set and 20\% testing set, a fundamental practice in machine learning to ensure models generalize well to unseen data. To rigorously evaluate our approach, we employed various machine learning algorithms. This provided a comprehensive assessment of our models' performance.

% Once the channels of interest are identified, the raw data undergoes a splitting process based on trials. This ensures that each trial's data is treated distinctly. For every channel, a feature matrix is then constructed using a predefined feature selection scheme. 
% This matrix undergoes normalization, a crucial step to ensure all features have a consistent scale, which is pivotal for the effective application of many machine learning algorithms.

% The algorithm then embarks on the task of evaluating the performance of each normalized channel dataset. By applying a machine learning algorithm with 5-fold cross-validation, the accuracy for each channel is ascertained and recorded. Post this evaluation, the channels showcasing the highest accuracies, specifically the top 20\%, are earmarked for further analysis.

% In the subsequent phase, the algorithm identifies combinations from the top-performing channels and the previously selected channel combinations. Each of these combinations is then subjected to the machine learning algorithm, and their accuracies are recorded.

% Concluding its operations, the algorithm sorts all the combination accuracies and outputs the channel combinations and their respective accuracies that meet the predefined criteria. Through this intricate process, the algorithm ensures that the selected channels are not just high-performing but also independent, setting the stage for a comprehensive and diverse set of signals for subsequent analysis.

\subsection{Evaluation Metrics}
We adopted various evaluation metrics to assess the performance of our scheme. These metrics include classification accuracy, sensitivity, specificity, Cohen's Kappa, F1 score, and ROC curve. Additionally, we employed 5-fold cross-validation as our training assessment strategy. 

\section{Experimental Evaluation and Results}
% \subsection{fNIRS Raw Data}
%To validate the efficacy of our proposed feature extraction scheme and channel selection algorithm, we conducted experiments and analyses on a set of fNIRS - BCI mental arithmetic multi-channel datasets provided by Günther Bauernfeind et al. 2014\cite{ref6}. This dataset encompasses recordings from eight subjects (three males, five females, with an average age of 26 and a standard deviation of 2.8 years) who exhibited contrasting hemodynamic response patterns during a mental arithmetic (MA) task. In this task, subjects were instructed to perform visually cued arithmetic calculations. For instance, they were tasked with continuously subtracting a single-digit number from a two-digit number (e.g., 97 - 4 = 93, 93 - 4 = 89, …) as swiftly as possible for a duration of 12 seconds, followed by a rest period of 28 seconds.

% \begin{figure}[htbp]
% 	\centerline{\includegraphics[scale=0.30]{raw_data_example1.png}}
% 	\caption{Temporal variations in the concentration changes of oxy-hemoglobin across our selected 9 channels during a mental arithmetic (MA) task for a single subject. Each channel's data is represented by a distinct color, with colors cycling through a predefined set for clarity. Vertical red lines indicate the start or end of an experimental trial, serving as markers to differentiate between rest periods and active MA phases. The x-axis denotes the sample number, serving as a proxy for time, while the y-axis indicates the amplitude of the oxy-hemoglobin concentration changes. Considering the time delay of the hemodynamic response, there are data rounding operations. The observed fluctuations provide insights into the cerebral hemodynamic responses associated with the cognitive demands of the task. }
% 	\label{raw_data_example}
% \end{figure}




% Considering that there is a time delay in the hemodynamic response\cite{ref20}, we divide the task interval from the moment when the task starts executing, and round off the data before that point. Fig. 1 is a schematic representation of the oxygen-hemoglobin concentration over time during the course of the experiment, using data from 9 channels of Subject 1 as an example. It is divided by a vertical red line at the beginning of the experiment (when the mental arithmetic task is about to be performed) and at the end of the experiment (when the rest phase is about to be entered). The experimental data of the remaining seven subjects were also divided in the same way, with the aim of distinguishing between the two different state of the subjects in the task-performing phase and the resting phase.


\subsection{Adjacency Matrix from Pearson correlation}
At the outset of our experiment, we extracted data from each of the 52 channels within the fNIRS dataset. This was followed by the computation of the Pearson correlation for every channel pairing, leading to the creation of a 52x52 Pearson correlation matrix. To further refine this matrix, we derived its absolute values, thereby constructing an adjacency matrix. Utilizing a sorting algorithm, we pinpointed channel combinations with absolute correlation values between 0 and 0.4, signifying weak or very weak correlations. %This methodology ensured the selection of channels that were relatively independent, offering diverse and non-redundant information for subsequent stages of our analysis.

In a bid to validate the relationship between Pearson correlation and the amount of shared information between two channels, we also constructed an adjacency matrix using mutual information. Upon visual inspection of the resulting data visualizations, we observed a striking similarity in the color distributions between the Pearson-based correlation map (c-map) and the mutual information-based c-map. Notably, even though the average values of mutual information were relatively smaller compared to the Pearson correlation values, the patterns of light and dark regions aligned well, suggesting a consistent relationship. Specifically, regions with low Pearson correlation corresponded seamlessly with areas of low mutual information, underscoring the reliability of our initial Pearson-based approach.

\begin{figure}[htbp]
	\centerline{\includegraphics[scale=0.35]{histogram.png}}
	\caption{Histogram comparison of values derived from adjacency matrices based on mutual information (left) and Pearson correlation (right). While the average values from the mutual information are notably smaller than those from the Pearson correlation, both histograms exhibit a congruent trend in counts as the values increase, underscoring the parallelism in their distribution patterns.}
	\label{histogram}
\end{figure}

\begin{figure}[htbp]
	\centerline{\includegraphics[scale=0.6]{mutual_pearson.png}}
	\caption{Comparative visualization of adjacency matrices constructed using mutual information (top) and Pearson correlation (bottom). While the mutual information-based matrix exhibits a generally lighter colormap, the alignment of its bright and dark regions with those of the Pearson-based matrix is evident. Specifically, regions of low Pearson correlation align well with areas of low mutual information, and vice versa for high values, highlighting the consistency between the two methods.}
	\label{mutual_pearson}
\end{figure}



% \begin{figure*}[htbp]
% 	\centerline{\includegraphics[scale=0.52]{pearson_matrix_example.png}}
% 	\caption{Temporal variations in the concentration changes of oxy-hemoglobin across 52 channels during a mental arithmetic (MA) task for a single participant. Each channel's data is represented by a distinct color, with colors cycling through a predefined set for clarity. Vertical red lines indicate the start or end of an experimental trial, serving as markers to differentiate between rest periods and active MA phases. The x-axis denotes the sample number, serving as a proxy for time, while the y-axis indicates the amplitude of the oxy-hemoglobin concentration changes. The observed fluctuations provide insights into the cerebral hemodynamic responses associated with the cognitive demands of the task. }
% 	\label{pearson_matrix_example}
% \end{figure*}


\subsection{Feature Extraction, Normalization and Machine Learning}
%, we embarked on the construction and evaluation of our dataset. For each channel's raw data, we began by segmenting the data based on trial markers. These segments were then labeled accordingly: periods of rest were designated as $0$, while the MA phases were labeled as $1$.

Following the initial steps of our experiment, having segmented and labeled the raw data from each channel, the subsequent pivotal step was feature extraction. Using our crafted scheme, the raw data is transformed into feature data that can be used in a classifier.
%we transformed the raw data into a compact and informative representation, making it more amenable for machine learning applications. This extracted data was then normalized to ensure comparability across different channels, setting the stage for consistent and reliable machine learning outcomes.

%With the processed dataset in hand, We divided it into 80\% training set and 20\% testing set, a fundamental practice in machine learning to ensure models generalize well to unseen data. To rigorously evaluate our approach, we employed various machine learning algorithms, each subjected to five-fold cross-validation. This provided a comprehensive assessment of our models' performance.

Furthermore, we adopted two distinct evaluation strategies. In the "Subject-dependent classifications" machine learning algorithms were trained and tested independently on each subject's dataset, yielding individualized accuracy. Conversely, for "Subject-independent classifications," we amalgamated and shuffled the datasets of all subjects, aiming to assess the model's broader generalizability. 
This dual approach offered a holistic view of our model's performance, reinforcing the robustness and versatility of our experimental design.

Table~\ref{tab:Different alg result} shows the results of applying our model to nine machine learning algorithms. These include the classification correctness of oxy-­Hb, dexoy-­Hb, total-­Hb, and all metrics. Oxy-­Hb, a commonly used observable for fNIRS-based brain-computer interfaces\cite{ref34}, is represented by our feature extraction and normalization model on the Support Vector Machine (SVM) algorithm with the highest correct rate of 99.14\%. This is followed by applying our model to the Multi-Layer Perception (MLP) algorithm with a correct rate of 97.98\%. For most of the algorithms, the accuracy of our model is very high, which can also confirm the effectiveness of the model we designed. The same classifier as G.Bauernfein et al. is used is LDA and the accuracy of our model is improved by 28.09\% as compared to their model. The confusion matrix of SVM and LDA algorithms is shown in Fig.~\ref{confusion_matrix} and correspondingly, the ROC curve is shown in Fig.~\ref{ROC-curve}.

\begin{table}[htbp]
\centering
\caption{Subject-independent classification accuracies using various machine learning algorithms and our feature extraction method. }
\begin{tabular}{lllll}
\multicolumn{1}{l|}{\multirow{2}{*}{Algorithm}} & oxy-­Hb & deoxy-­Hb & total-­Hb & all   \\
\multicolumn{1}{l|}{}                           & \multicolumn{4}{l}{Acc.(\%)}            \\ \hline
\multicolumn{1}{l|}{SVM}                        & 99.14   & 99.14     & 98.00     & 99.43 \\
\multicolumn{1}{l|}{LR}                         & 96.84   & 98.00     & 95.97     & 99.13 \\
\multicolumn{1}{l|}{DT}                         & 79.91   & 88.50     & 83.93     & 86.20 \\
\multicolumn{1}{l|}{RF}                         & 95.13   & 96.84     & 92.52     & 96.85 \\
\multicolumn{1}{l|}{KN}                         & 83.06   & 74.41     & 78.14     & 80.77 \\
\multicolumn{1}{l|}{GNB}                        & 69.25   & 72.97     & 68.07     & 71.81 \\
\multicolumn{1}{l|}{LDA}                        & 95.69   & 96.55     & 93.67     & 98.00 \\
\multicolumn{1}{l|}{MLP}                        & 97.98   & 97.71     & 97.99     & 99.13 \\
\multicolumn{1}{l|}{SGD}                        & 96.56   & 94.85     & 88.77     & 96.56 \\ \hline
\multicolumn{5}{l}{\begin{tabular}[c]{@{}l@{}}$SVM$ Support Vector Machine, $LR$ Logistic Regression,\\ $DF$ Decision Tree, $RF$ Random Forst, $KN$ K Neighbors,\\ $GNB$ Gaussian NB, $LDA$ Linear Discriminant Analysis,\\ $MLP$ Multilayer Perceptron, $SGD$ Schotastic Gradient Descent\end{tabular}}
\end{tabular}
\label{tab:Different alg result}
\end{table}

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table*}[htbp]
\centering
\caption{Performance metrics of the SVM and LDA algorithms trained on different types of fNIRS data: oxy-Hb, deoxy-Hb, total-Hb, and the combined dataset. The table enumerates Sensitivity (true positive rate), Specificity (true negative rate), Cohen's Kappa (a measure of classification accuracy corrected for chance), and the F1 Score (the harmonic mean of precision and recall) for both algorithms across the various data types. From the reported metrics, it can be observed how each algorithm's performance varies depending on the utilized fNIRS data. The comprehensive metrics provide insights into not only the models' correctness but also their reliability in differentiating between the classes, especially when it comes to unbalanced datasets.}

\label{tab:my-table}
\begin{tabular}{l|llll|llll|llll|llll}
\multirow{2}{*}{} & \multicolumn{4}{l|}{oxy-Hb}   & \multicolumn{4}{l|}{deoxy-Hb} & \multicolumn{4}{l|}{total-Hb} & \multicolumn{4}{l}{all}       \\ \cline{2-17} 
                  & TPR   & TNR   & K     & F1 (\%)    & TPR   & TNR   & K     & F1 (\%)   & TPR   & TNR   & K     & F1 (\%)   & TPR   & TNR   & K     & F1 (\%)    \\ \hline
SVM               & 98.85 & 98.28 & 97.13 & 98.56 & 99.43 & 98.85 & 98.28 & 99.14 & 99.43 & 98.28 & 97.70 & 98.84 & 99.43 & 99.43 & 98.85 & 99.43 \\
LDA               & 93.10 & 97.13 & 90.23 & 95.21 & 93.10 & 97.70 & 90.80 & 95.51 & 91.38 & 96.55 & 87.93 & 94.12 & 98.28 & 97.70 & 95.98 & 97.98
\end{tabular}
\end{table*}


\begin{figure*}[htbp]
	\centerline{\includegraphics[scale=0.62]{confusion_matrix.png}}

 
 
 
 
 
 
 
 
 
 \caption{This figure illustrates the 4x2 set of confusion matrices representing the performance of SVM and LDA models trained with various types of fNIRS data: oxy-Hb, deoxy-Hb, total-Hb, and a combination of all. The first row displays the confusion matrices of the SVM models: from left to right, the models are trained using oxy-Hb, deoxy-Hb, total-Hb, and a combination of all types of fNIRS data respectively. Similarly, the second row represents the LDA models trained with the same sequence of data types. Each matrix provides insights into the model's ability to correctly classify the instances, offering a visualization of true positive, true negative, false positive, and false negative counts.}
	\label{confusion_matrix}
\end{figure*}

\begin{figure*}[htbp]
	\centerline{\includegraphics[scale=0.62]{ROC-curve.png}}
	\caption{This figure presents a 4x2 array of Receiver Operating Characteristic (ROC) curves, showcasing the discriminative ability of both SVM and LDA models when trained with different types of fNIRS data: oxy-Hb, deoxy-Hb, total-Hb, and a combination of all. In the first row, from left to right, the ROC curves represent SVM models trained respectively with oxy-Hb, deoxy-Hb, total-Hb, and combined data. The second row, with a similar arrangement, displays the ROC curves for LDA models. Each curve in the figure depicts the trade-off between the true positive rate (sensitivity) and false positive rate (1-specificity) at various thresholds, providing a comprehensive visualization of model performance across different data types. The area under each curve (AUC) serves as a single scalar value to summarize the model's ability to distinguish between the classes, with 1.0 representing perfect classification and 0.5 representing a model no better than random chance.}

	\label{ROC-curve}
\end{figure*}

In G. Bauernfeind's study, the Linear Discriminant Analysis (LDA) classification method was applied to eight subjects to compare the accuracy of the classification results, as shown in Table~\ref{tab:comparative_results}. The average accuracy of discrimination for the eight subjects was 63.28\% for Region of Interest 1 (ROI$_1$)and Region of Interest 2 (ROI$_2$), and 59.38\% for Region of Interest 3 (ROI$_3$). Obviously this is not a more desirable discrimination accuracy rate. This result is related to a number of factors, more than its failure to accurately extract data features. %This is a strategy known as "subject-dependent accuracy", where experiments are conducted and evaluated on a specific subject to assess the performance of the algorithm on that subject. 
Although this approach cannot rule out individual differences between subjects, which may lead to salient experimental results for a particular subject, it can be used to validate the effectiveness of the research protocol.
\begin{table*}[htbp]
\centering
\caption{Comparative analysis of classification accuracies and [oxy-­Hb] patterns across three regions of interest (ROI$_1$, ROI$_2$, and ROI$_3$) between the experiments conducted by G. Bauernfeind et al. and our experiments. The table details the accuracy percentages, channel positions, Brodmann areas, and anatomical regions for each subject in both studies.}

\label{tab:comparative_results}
\begin{tabular}{llllllllllllll}
\multirow{3}{*}{Exp.} &
  \multirow{3}{*}{Sub.} &
  \multicolumn{4}{l}{ROI$_1$ {[}oxy-Hb{]}} &
  \multicolumn{4}{l}{ROI$_2$ {[}oxy-Hb{]}} &
  \multicolumn{4}{l}{ROI$_3$ {[}oxy-Hb{]}} \\ \cline{3-14} 
 &
   &
  \multirow{2}{*}{Acc.(\%)} &
  \multicolumn{3}{l}{Pos.} &
  \multirow{2}{*}{Acc.(\%)} &
  \multicolumn{3}{l}{Pos.} &
  \multirow{2}{*}{Acc.(\%)} &
  \multicolumn{3}{l}{Pos.} \\ \cline{4-6} \cline{8-10} \cline{12-14} 
 &      &       & Ch.    & BA & Anat. &       & Ch.    & BA & Anat. &       & Ch.    & BA & Anat. \\ \hline
\multirow{10}{*}{\begin{tabular}[c]{@{}l@{}}Experiments by G. Bauernfeind et al. \\ using LDA\cite{ref12}.\end{tabular}} &
  S1 &
  62.50 &
  46$^a$ &
  10 &
  SFG &
  56.25 &
  18$^c$ &
  9 &
  MFG &
  56.25 &
  24$^b$ &
  46 &
  MFG \\
 & S2   & 62.50 & 47$^a$ & 10 & MeFG  & 50.00 & 28$^c$ & 46 & MFG   & 62.50 & 24$^b$ & 46 & MFG   \\
 & S3   & 62.50 & 46$^a$ & 10 & SFG   & 50.00 & 29$^c$ & 9  & IFG   & 68.75 & 24$^b$ & 46 & MFG   \\
 & S4   & 81.25 & 48$^a$ & 10 & MFG   & 50.00 & 29$^c$ & 9  & IFG   & 62.50 & 24$^b$ & 46 & MFG   \\
 & S5   & 50.00 & 47$^a$ & 10 & MeFG  & 68.75 & 28$^c$ & 46 & MFG   & 56.25 & 24$^b$ & 46 & MFG   \\
 & S6   & 62.50 & 46$^a$ & 10 & SFG   & 50.00 & 28$^c$ & 46 & MFG   & 62.50 & 24$^b$ & 46 & MFG   \\
 & S7   & 62.50 & 47$^a$ & 10 & SFG   & 81.25 & 18$^c$ & 9  & MFG   & 62.50 & 23$^b$ & 46 & MFG   \\
 & S8   & 62.50 & 48$^a$ & 10 & MFG   & 68.75 & 28$^c$ & 46 & MFG   & 75.00 & 23$^b$ & 46 & MFG   \\
 & Mean & 63.28 &        &    &       & 59.38 &        &    &       & 63.28 &        &    &       \\
 & SD   & 8.48  &        &    &       & 12.05 &        &    &       & 6.19  &        &    &       \\ \hline
\multirow{10}{*}{\begin{tabular}[c]{@{}l@{}@{}}Our Experiments using LDA and our\\  feature extraction method\end{tabular}} &
  S1 & 94.25
   &
  46$^a$ &
  10 &
  SFG &
  89.00 &
  18$^c$ &
  9 &
  MFG &
  97.50 &
  24$^b$ &
  46 &
  MFG \\
 & S2   & 91.25 & 47$^a$ & 10 & MeFG  & 88.50 & 28$^c$ & 46 & MFG   & 94.75 & 24$^b$ & 46 & MFG   \\
 & S3   & 82.75 & 46$^a$ & 10 & SFG   & 86.00 & 29$^c$ & 9  & IFG   & 94.50 & 24$^b$ & 46 & MFG   \\
 & S4   & 98.00 & 48$^a$ & 10 & MFG   & 81.75 & 29$^c$ & 9  & IFG   & 100.00 & 24$^b$ & 46 & MFG   \\
 & S5   & 91.75 & 47$^a$ & 10 & MeFG  & 89.25 & 28$^c$ & 46 & MFG   & 87.50 & 24$^b$ & 46 & MFG   \\
 & S6   & 87.25 & 46$^a$ & 10 & SFG   & 87.50 & 28$^c$ & 46 & MFG   & 85.50 & 24$^b$ & 46 & MFG   \\
 & S7   & 83.25 & 47$^a$ & 10 & SFG   & 91.50 & 18$^c$ & 9  & MFG   & 91.50 & 23$^b$ & 46 & MFG   \\
 & S8   & 81.25 & 48$^a$ & 10 & MFG   & 98.00 & 28$^c$ & 46 & MFG   & 89.25 & 23$^b$ & 46 & MFG   \\
 & Mean & 88.72 &        &    &       & 88.94 &        &    &       & 92.56 &        &    &       \\
 & SD   & 6.05  &        &    &       & 4.65 &        &    &       & 5.01  &        &    &       \\  
  & SIA   & 90.23  &  46$^a$ & 10   &  SFG     & 86.20 &   18$^c$     &  9  &       MFG & 89.35  &  24$^b$      &  46  &   MFG    \\
 & SIA   & 87.64  &  47$^a$ & 10   &  MEFG     & 88.50 &   28$^c$     &  46  &       MFG & 89.10  &  23$^b$      &  46  &   MFG    \\
 & SIA   & 91.38  &  48$^a$ & 10   &  MFG     & 86.23 &   29$^c$     &  9  &  IFG &   &        &    &       \\ \hline
\multicolumn{14}{l}{$^a$ APFC, $^b$ r. DLPFC, $^c$ l. DLPFC}                                      \\
\multicolumn{14}{l}{$BA$ Brodmann area, $SFG$ superior frontal gyrus, $MFG$ middle frontal gyrus, $IFG$ inferior frontal gyrus, $MeFG$ medial frontal gyrus} \\
\multicolumn{14}{l}{$SIA$ Subject-independent Classification Accuracy}                        
\end{tabular}
\end{table*}

To further demonstrate the effectiveness of our model, we also used Linear Discriminant Analysis (LDA) for the same channels, ROI, and Brodmann areas as in G. Bauernfeind's study for eight subjects, and the classification accuracies obtained are shown in Table~\ref{tab:comparative_results}. The results show that the accuracy of the experimental results was significantly improved to varying degrees across subjects. The average discrimination accuracy for ROI$_1$ increased to 88.72\%, the average discrimination accuracy for ROI$_2$ increased to 88.84\%, and the average discrimination accuracy for ROI$_3$ incredibly increased to 92.56\%. This very well demonstrates the effectiveness of our well-designed feature extraction scheme. 

Furthermore, we conducted a statistical significance test based on Table IV. We employed the t-statistic to compare the mean accuracies of the two methods: ours and that proposed by G. Bauernfeind et al. A larger t-statistic implies a more distinct difference between the two groups. The p-value, on the other hand, denotes the probability of observing the given results, or more extreme results, assuming that no real difference exists between the two techniques. By convention, a p-value less than 0.05 is considered evidence of statistical significance.

It's worth noting that, for this analysis, we opted for Welch's t-test over the standard t-test. This decision was driven by our intent to make the test more robust to potential inequalities in the variances of the accuracies between the two methods. Welch's t-test is particularly recommended when there's a suspicion or evidence that the two data samples might have unequal variances, making it a more appropriate choice here.

\begin{table}[htbp]
\centering
\caption{Statistical significance analysis of differences in accuracy between the proposed method and the one by G. Bauernfeind et al. for ROIs.}
\label{tab:stat_results}
\begin{tabular}{l|ll}
ROI     & t-statistic & p-value \\ \hline
ROI$_1$ {[}oxy-Hb{]} & 6.91        & 0.00001 \\
ROI$_2$ {[}oxy-Hb{]} & 6.48        & 0.00011 \\
ROI$_3$ {[}oxy-Hb{]} & 10.39        & 8.58e-8 \\ \hline
\multicolumn{3}{l}{Note: p-value$<$0.5 represents statistically  } \\
\multicolumn{3}{l}{ significant difference. } 
\end{tabular}
\end{table}

From Table~\ref{tab:stat_results}, the observed t-statistics for ROI$_1$, ROI$_2$, and ROI$_3$ using Welch's t-test were 6.91, 6.48, and 10.39 respectively. The corresponding p-values were 0.00001, 0.00011, and 8.58e-8, all of which are substantially below the 0.05 threshold. These results offer compelling evidence of a significant accuracy enhancement when using our method in comparison to the approach of G. Bauernfeind et al.

In summation, our approach exhibits marked superiority in accuracy across all assessed ROIs, underscoring the merits of our model.

\subsection{New channel selection for fNIRS-based Online binary classification}
Using the data for machine learning after our proprietary feature extraction and normalization is valuable for fNIRS-based online binary classification. Previous fNIRS-based binary classification studies had a large number of channels to study\cite{ref21,ref22,ref23,ref24}, many redundant channels, and low accuracy. These large numbers of channels are not all channels that can be used to improve classification accuracy, and if higher accuracy can be achieved with fewer channels, this is certainly a study with applications. In order to improve the classification capability as well as the accuracy, and also to provide a more elaborate channel distribution scheme for fNIRS-based BCI device research.

% \begin{figure*}[htbp]
% 	\centerline{\includegraphics[scale=0.4]{acc1.png}}
% 	\caption{Visualization of the subject-independent accuracy across fNIRs data channels (ranging from 1 to 52) for various machine learning methods employing our feature extraction and normalization processing. Each colored line corresponds to a distinct machine learning method, effectively showcasing the comparative performance across channels.}
% 	\label{acc1}
% \end{figure*}

\begin{figure*}[htbp]
	\centerline{\includegraphics[scale=0.55]{acc2.png}}
	\caption{Visualization of the subject-independent accuracy for various machine learning methods applied to fNIRS data channels, employing our feature extraction and normalization processing. In this heatmap, each column corresponds to one of the fNIRS data channels (ranging from 1 to 52), and each row represents a distinct machine learning method. The color intensity within the heatmap signifies the accuracy level, providing a comparative insight into the performance of different machine learning algorithms across various channels.}
	\label{acc1}
\end{figure*}


First, our model was used for different machine learning algorithms, and the accuracy was calculated for each of the 52 channels, and the results are shown in Fig.~\ref{acc1}. The horizontal coordinates are 1-52 channels, with different shades of color representing the correctness of different machine learning classifications. The results of the performance of the different algorithms can be visualized, and the multilayer perception algorithm shows a high and stable correct rate in each channel. This step serves to quickly eliminate some redundant channels with low correct rates, such as eight channels. The correct rate of single-channel classification can also be provided as a reference for comparison with multi-channel classification.

Then, based on the adjacency matrix constructed by the Pearson correlation coefficient, the 10 sets of two-by-two correlated channels with the lowest correlation were found. The correlation coefficients of the selected channels are lower than 0.4, which indicates that these key channels contain information that is more independent of each other and improves the accuracy of classification.

In Table~\ref{tab:top 10 channels}, we list the 10 channels with the highest accuracy single-channel classification result and their respective accuracy value. The highest accuracy is for channel 25, with a 92.76\% accuracy. Critically, we give the channels and their accuracy after channel combination. It is encouraging to find that there is a very significant improvement in the classification accuracy. Only for channel 26 and channel 43, the accuracy reaches 95.98\%. Compared with previous studies, the higher accuracy is obtained with a more compact number of channels, which reduces the complexity of data processing and algorithms, and greatly reduces the difficulty of device development.

\begin{table}[htbp]
\centering
\caption{Comparison of the top 10 individual channels and channel combinations in terms of their subject-independent accuracy. Each channel or combination is associated with a region (either APFC, r. DLPFC, or l. DLPFC) and for channel combinations, the Pearson correlation is provided to indicate the relationship between channels. This information serves to identify and understand the most influential channels and combinations in the fNIRS data.}
\begin{tabular}{l|ll|lll}
\multirow{2}{*}{No.} & \multicolumn{2}{l|}{Single Channel} & \multicolumn{3}{l}{Channel Combination} \\
                     & Ch.            & Acc.(\%)           & Ch.  & Acc.(\%)  & Pearson correlation  \\ \hline
1  & 25$^a$ & 92.76 & 26$^a$, 43$^b$ & 95.98 & 0.08118 \\
2  & 15$^a$ & 90.94 & 20$^c$, 26$^a$ & 95.40 & 0.16684 \\
3  & 16$^a$ & 90.16 & 23$^b$, 26$^a$ & 95.40 & 0.28594 \\
4  & 46$^a$ & 89.87 & 37$^a$, 43$^b$ & 95.12 & 0.03323 \\
5  & 36$^a$ & 89.63 & 26$^a$, 34$^b$ & 95.11 & 0.33568 \\
6  & 27$^a$ & 89.55 & 26$^a$, 51$^c$ & 94.84 & 0.20525 \\
7  & 26$^a$ & 88.98 & 26$^a$, 52$^c$ & 94.84 & 0.00340 \\
8  & 48$^a$ & 88.98 & 25$^a$, 52$^b$ & 94.84 & 0.33150 \\
9  & 12$^b$ & 88.67 & 37$^a$, 51$^b$ & 94.83 & 0.07331 \\
10 & 34$^b$ & 88.64 & 37$^a$, 52$^b$ & 94.55 & 0.10958\\ \hline
\multicolumn{6}{l}{$^a$ APFC, $^b$ r. DLPFC, $^c$ l. DLPFC}                                      \\
\end{tabular}
\label{tab:top 10 channels}
\end{table}

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \begin{table*}[htbp]
% \centering
% \caption{Comparison of classification accuracies and antagonistic [oxy-Hb] patterns between the experiments conducted by G. Bauernfeind et al. and our experiments. The table presents the accuracy percentages, channel positions, Brodmann areas, and anatomical regions for each subject in both studies.}

% \begin{tabular}{lllllllll}
% \multirow{3}{*}{Exp.} &
%   \multirow{3}{*}{Sub.} &
%   \multicolumn{7}{l}{Antagonistic {[}oxy-Hb{]} pattern} \\ \cline{3-9} 
%  &
%    &
%   \multirow{2}{*}{Acc.(\%)} &
%   \multicolumn{3}{l}{Pos$._1$} &
%   \multicolumn{3}{l}{Pos$._2$} \\ \cline{4-9} 
%  &      &       & Ch. & BA & Anat. & Ch. & BA & Anat. \\ \hline
% \multirow{10}{*}{\begin{tabular}[c]{@{}l@{}}Experiments by G. Bauernfeind et al. using LDA.\end{tabular}} &
%   S1 &
%   68.75 &
%   $46^a$ &
%   10 &
%   SFG &
%   24b &
%   46 &
%   MFG \\
%  & S2   & 87.50 & $47^a$ & 10 & MEFG  & $24^b$ & 46 & MFG   \\
%  & S3   & 75.00 &  $48^a$ & 10 & MFG   & $29^c$ & 9  & IFG   \\
%  & S4   & 87.50 & $48^a$ & 10 & MFG   & $29^c$ & 9  & IFG   \\
%  & S5   & 81.25 & $47^a$ & 10 & MEFG  & $28^c$ & 46 & MFG   \\
%  & S6   & 68.75 & $46^a$ & 10 & SFG   & $28^c$ & 46 & MFG   \\
%  & S7   & 87.50 & $47^a$ & 10 & MEFG  & $18^c$ & 9  & MFG   \\
%  & S8   & 81.25 & $47^a$ & 10 & MEFG  & $28^c$ & 46 & MFG   \\
%  & Mean & 79.69 &     &    &       &     &    &       \\
%  & SD   & 8.01  &     &    &       &     &    &       \\ \hline
% \multirow{10}{*}{\begin{tabular}[c]{@{}l@{}}Our Experiments using LDA and our feature extraction method.\end{tabular}} &
%   S1 &
%   90.00 &
%   $46^a$ &
%   10 &
%   SFG &
%   24b &
%   46 &
%   MFG \\
%  & S2   & 0.50 & $47^a$ & 10 & MEFG  & $24^b$ & 46 & MFG   \\
%  & S3   & 0.00 &  $48^a$ & 10 & MFG   & $29^c$ & 9  & IFG   \\
%  & S4   & 0.50 & $48^a$ & 10 & MFG   & $29^c$ & 9  & IFG   \\
%  & S5   & 0.25 & $47^a$ & 10 & MEFG  & $28^c$ & 46 & MFG   \\
%  & S6   & 0.75 & $46^a$ & 10 & SFG   & $28^c$ & 46 & MFG   \\
%  & S7   & 0.50 & $47^a$ & 10 & MEFG  & $18^c$ & 9  & MFG   \\
%  & S8   & 0.25 & $47^a$ & 10 & MEFG  & $28^c$ & 46 & MFG   \\
%  & Mean & 00.00 &     &    &       &     &    &       \\
%  & SD   & 0     &     &    &       &     &    &       \\ \hline
% \multicolumn{9}{l}{$^a$ APFC, $^b$ r. DLPFC, $^c$ l. DLPFC}    \\
% \multicolumn{9}{l}{$BA$ Brodmann area, $SFG$ superior frontal gyrus, $MFG$ middle frontal gyrus, $IFG$ inferior frontal gyrus, $MeFG$ medial frontal gyrus}
% \end{tabular}
% \end{table*}




% \begin{table}[htbp]
% \centering
% \caption{Top 10 Channel combinations}
% \begin{tabular}{|l|l|l|l|}
% \hline
% No. & Channels & Pearson correlation & Acc.(\%) \\ \hline
% 1   & 26, 43   & 0.08118             & 95.98    \\
% 2   & 20, 26   & 0.16684             & 95.40    \\
% 3   & 23, 26   & 0.28594             & 95.40    \\
% 4   & 37, 43   & 0.03323             & 95.12    \\
% 5   & 26, 34   & 0.33568             & 95.11    \\
% 6   & 26, 51   & 0.20525             & 94.84    \\
% 7   & 26, 52   & 0.00340             & 94.84    \\
% 8   & 25, 52   & 0.33150             & 94.84    \\
% 9   & 37, 51   & 0.07331             & 94.83    \\
% 10  & 37, 52   & 0.10958             & 94.55    \\ \hline
% \end{tabular}
% \end{table}

% Please add the following required packages to your document preamble:
% \usepackage{multirow}

\begin{figure}[htbp]
	\centerline{\includegraphics[scale=0.32]{107.jpg}}
	\caption{The combination of channels that have been selected by our scheme is highlighted in green in the diagram, while the other channels are shown in gray to highlight their positional information.}
	\label{ccf}
\end{figure}

\section{Discussion and Future Work}
In this work, we aim to address the dual challenges associated with online classification of fNIRS data and achieving subject-independent accuracy. To tackle these challenges, we propose a feature extraction scheme that is hemodynamically compliant for fNIRS data. This scheme involves constructing feature matrices comprising statistical features, time-domain, frequency-domain, and principal component features.

%We applied the designed feature matrix to various machine learning algorithms to validate its classification accuracy. This validation was performed on a 52-channel fNIRS dataset containing data from eight subjects while they were engaged in a mental arithmetic task. In addition to presenting the classification accuracies achieved by different machine learning algorithms, we also provide subject-independent classification accuracies and compare them with the results obtained by Bauernfeind et al. Our findings demonstrate significant improvements in classification results across different ROI for various subjects.

%A further innovation is to apply our proposed scheme to all channels to get the classification correct rate for each channel, this step can also quickly exclude some channels with lower accuracies. Then using the Pearson correlation coefficient, the Pearson correlation coefficient matrix between channels is constructed to find the top 10 channel combinations with low correlation. Low correlation means that they contain less overlapping information, and higher classification results are obtained with a smaller number of channels. The results show that our selected channel combinations improve the classification accuracies. This result, as well as our proposed scheme, is promising and applicable for online classification of fNIRS data and subject-independent classification accuracy studies and promotes fNIRS-based BCI device development

Our approach presents a paradigm for the preliminary development process of fNIRS-based BCIs tailored for binary classification tasks, maintaining high subject-independent accuracy while reducing the number of transmitters and receivers. Theoretically, our methodology holds potential for extension to any binary classification challenge within fNIRS-based frameworks. This investigation presents a foundational blueprint for binary classification in fNIRS-based BCI platforms, holding promise for addressing diverse binary classification dilemmas within fNIRS-centric frameworks.

% Be aware of the different meanings of the homophones ``affect'' (usually a 
% verb) and ``effect'' (usually a noun), ``complement'' and ``compliment,'' 
% ``discreet'' and ``discrete,'' ``principal'' (e.g., ``principal 
% investigator'') and ``principle'' (e.g., ``principle of measurement''). Do 
% not confuse ``imply'' and ``infer.'' 

% Prefixes such as ``non,'' ``sub,'' ``micro,'' ``multi,'' and ``ultra'' are 
% not independent words; they should be joined to the words they modify, 
% usually without a hyphen. There is no period after the ``et'' in the Latin 
% abbreviation ``\emph{et al.}'' (it is also italicized). The abbreviation ``i.e.,'' means 
% ``that is,'' and the abbreviation ``e.g.,'' means ``for example'' (these 
% abbreviations are not italicized).

% A general IEEE styleguide is available at \underline{http://www.ieee.org/authortools}.

% \section{Guidelines for Graphics Preparation and Submission}
% \label{sec:guidelines}

% \subsection{Types of Graphics}
% The following list outlines the different types of graphics published in 
% IEEE journals. They are categorized based on their construction, and use of 
% color/shades of gray:

% \subsubsection{Color/Grayscale figures}
% {Figures that are meant to appear in color, or shades of black/gray. Such 
% figures may include photographs, illustrations, multicolor graphs, and 
% flowcharts.}

% \subsubsection{Line Art figures}
% {Figures that are composed of only black lines and shapes. These figures 
% should have no shades or half-tones of gray, only black and white.}

% \subsubsection{Author photos}
% {Head and shoulders shots of authors that appear at the end of our papers. }

% \subsubsection{Tables}
% {Data charts which are typically black and white, but sometimes include 
% color.}

% \begin{table}
% \caption{Units for Magnetic Properties}
% \label{table}
% \setlength{\tabcolsep}{3pt}
% \begin{tabular}{|p{25pt}|p{75pt}|p{115pt}|}
% \hline
% Symbol& 
% Quantity& 
% Conversion from Gaussian and \par CGS EMU to SI $^{\mathrm{a}}$ \\
% \hline
% $\Phi $& 
% magnetic flux& 
% 1 Mx $\to  10^{-8}$ Wb $= 10^{-8}$ V$\cdot $s \\
% $B$& 
% magnetic flux density, \par magnetic induction& 
% 1 G $\to  10^{-4}$ T $= 10^{-4}$ Wb/m$^{2}$ \\
% $H$& 
% magnetic field strength& 
% 1 Oe $\to  10^{3}/(4\pi )$ A/m \\
% $m$& 
% magnetic moment& 
% 1 erg/G $=$ 1 emu \par $\to 10^{-3}$ A$\cdot $m$^{2} = 10^{-3}$ J/T \\
% $M$& 
% magnetization& 
% 1 erg/(G$\cdot $cm$^{3}) =$ 1 emu/cm$^{3}$ \par $\to 10^{3}$ A/m \\
% 4$\pi M$& 
% magnetization& 
% 1 G $\to  10^{3}/(4\pi )$ A/m \\
% $\sigma $& 
% specific magnetization& 
% 1 erg/(G$\cdot $g) $=$ 1 emu/g $\to $ 1 A$\cdot $m$^{2}$/kg \\
% $j$& 
% magnetic dipole \par moment& 
% 1 erg/G $=$ 1 emu \par $\to 4\pi \times  10^{-10}$ Wb$\cdot $m \\
% $J$& 
% magnetic polarization& 
% 1 erg/(G$\cdot $cm$^{3}) =$ 1 emu/cm$^{3}$ \par $\to 4\pi \times  10^{-4}$ T \\
% $\chi , \kappa $& 
% susceptibility& 
% 1 $\to  4\pi $ \\
% $\chi_{\rho }$& 
% mass susceptibility& 
% 1 cm$^{3}$/g $\to  4\pi \times  10^{-3}$ m$^{3}$/kg \\
% $\mu $& 
% permeability& 
% 1 $\to  4\pi \times  10^{-7}$ H/m \par $= 4\pi \times  10^{-7}$ Wb/(A$\cdot $m) \\
% $\mu_{r}$& 
% relative permeability& 
% $\mu \to \mu_{r}$ \\
% $w, W$& 
% energy density& 
% 1 erg/cm$^{3} \to  10^{-1}$ J/m$^{3}$ \\
% $N, D$& 
% demagnetizing factor& 
% 1 $\to  1/(4\pi )$ \\
% \hline
% \multicolumn{3}{p{251pt}}{Vertical lines are optional in tables. Statements that serve as captions for 
% the entire table do not need footnote letters. }\\
% \multicolumn{3}{p{251pt}}{$^{\mathrm{a}}$Gaussian units are the same as cg emu for magnetostatics; Mx 
% $=$ maxwell, G $=$ gauss, Oe $=$ oersted; Wb $=$ weber, V $=$ volt, s $=$ 
% second, T $=$ tesla, m $=$ meter, A $=$ ampere, J $=$ joule, kg $=$ 
% kilogram, H $=$ henry.}
% \end{tabular}
% \label{tab1}
% \end{table}

% \subsection{Multipart figures}
% Figures compiled of more than one sub-figure presented side-by-side, or 
% stacked. If a multipart figure is made up of multiple figure
% types (one part is lineart, and another is grayscale or color) the figure 
% should meet the stricter guidelines.

% \subsection{File Formats For Graphics}\label{formats}
% Format and save your graphics using a suitable graphics processing program 
% that will allow you to create the images as PostScript (PS), Encapsulated 
% PostScript (.EPS), Tagged Image File Format (.TIFF), Portable Document 
% Format (.PDF), Portable Network Graphics (.PNG), or Metapost (.MPS), sizes them, and adjusts 
% the resolution settings. When 
% submitting your final paper, your graphics should all be submitted 
% individually in one of these formats along with the manuscript.

% \subsection{Sizing of Graphics}
% Most charts, graphs, and tables are one column wide (3.5 inches/88 
% millimeters/21 picas) or page wide (7.16 inches/181 millimeters/43 
% picas). The maximum depth a graphic can be is 8.5 inches (216 millimeters/54
% picas). When choosing the depth of a graphic, please allow space for a 
% caption. Figures can be sized between column and page widths if the author 
% chooses, however it is recommended that figures are not sized less than 
% column width unless when necessary. 

% There is currently one publication with column measurements that do not 
% coincide with those listed above. Proceedings of the IEEE has a column 
% measurement of 3.25 inches (82.5 millimeters/19.5 picas). 

% The final printed size of author photographs is exactly
% 1 inch wide by 1.25 inches tall (25.4 millimeters$\,\times\,$31.75 millimeters/6 
% picas$\,\times\,$7.5 picas). Author photos printed in editorials measure 1.59 inches 
% wide by 2 inches tall (40 millimeters$\,\times\,$50 millimeters/9.5 picas$\,\times\,$12 
% picas).

% \subsection{Resolution }
% The proper resolution of your figures will depend on the type of figure it 
% is as defined in the ``Types of Figures'' section. Author photographs, 
% color, and grayscale figures should be at least 300dpi. Line art, including 
% tables should be a minimum of 600dpi.

% \subsection{Vector Art}
% In order to preserve the figures' integrity across multiple computer 
% platforms, we accept files in the following formats: .EPS/.PDF/.PS. All 
% fonts must be embedded or text converted to outlines in order to achieve the 
% best-quality results.

% \subsection{Color Space}
% The term color space refers to the entire sum of colors that can be 
% represented within the said medium. For our purposes, the three main color 
% spaces are Grayscale, RGB (red/green/blue) and CMYK 
% (cyan/magenta/yellow/black). RGB is generally used with on-screen graphics, 
% whereas CMYK is used for printing purposes.

% All color figures should be generated in RGB or CMYK color space. Grayscale 
% images should be submitted in Grayscale color space. Line art may be 
% provided in grayscale OR bitmap colorspace. Note that ``bitmap colorspace'' 
% and ``bitmap file format'' are not the same thing. When bitmap color space 
% is selected, .TIF/.TIFF/.PNG are the recommended file formats.

% \subsection{Accepted Fonts Within Figures}
% When preparing your graphics IEEE suggests that you use of one of the 
% following Open Type fonts: Times New Roman, Helvetica, Arial, Cambria, and 
% Symbol. If you are supplying EPS, PS, or PDF files all fonts must be 
% embedded. Some fonts may only be native to your operating system; without 
% the fonts embedded, parts of the graphic may be distorted or missing.

% A safe option when finalizing your figures is to strip out the fonts before 
% you save the files, creating ``outline'' type. This converts fonts to 
% artwork what will appear uniformly on any screen.

% \subsection{Using Labels Within Figures}

% \subsubsection{Figure Axis labels }
% Figure axis labels are often a source of confusion. Use words rather than 
% symbols. As an example, write the quantity ``Magnetization,'' or 
% ``Magnetization M,'' not just ``M.'' Put units in parentheses. Do not label 
% axes only with units. As in Fig. 1, for example, write ``Magnetization 
% (A/m)'' or ``Magnetization (A$\cdot$m$^{-1}$),'' not just ``A/m.'' Do not label axes with a ratio of quantities and 
% units. For example, write ``Temperature (K),'' not ``Temperature/K.'' 

% Multipliers can be especially confusing. Write ``Magnetization (kA/m)'' or 
% ``Magnetization (10$^{3}$ A/m).'' Do not write ``Magnetization 
% (A/m)$\,\times\,$1000'' because the reader would not know whether the top 
% axis label in Fig. 1 meant 16000 A/m or 0.016 A/m. Figure labels should be 
% legible, approximately 8 to 10 point type.

% \subsubsection{Subfigure Labels in Multipart Figures and Tables}
% Multipart figures should be combined and labeled before final submission. 
% Labels should appear centered below each subfigure in 8 point Times New 
% Roman font in the format of (a) (b) (c). 

% \subsection{File Naming}
% Figures (line artwork or photographs) should be named starting with the 
% first 5 letters of the author's last name. The next characters in the 
% filename should be the number that represents the sequential 
% location of this image in your article. For example, in author 
% ``Anderson's'' paper, the first three figures would be named ander1.tif, 
% ander2.tif, and ander3.ps.

% Tables should contain only the body of the table (not the caption) and 
% should be named similarly to figures, except that `.t' is inserted 
% in-between the author's name and the table number. For example, author 
% Anderson's first three tables would be named ander.t1.tif, ander.t2.ps, 
% ander.t3.eps.

% Author photographs should be named using the first five characters of the 
% pictured author's last name. For example, four author photographs for a 
% paper may be named: oppen.ps, moshc.tif, chen.eps, and duran.pdf.

% If two authors or more have the same last name, their first initial(s) can 
% be substituted for the fifth, fourth, third$\ldots$ letters of their surname 
% until the degree where there is differentiation. For example, two authors 
% Michael and Monica Oppenheimer's photos would be named oppmi.tif, and 
% oppmo.eps.

% \subsection{Referencing a Figure or Table Within Your Paper}
% When referencing your figures and tables within your paper, use the 
% abbreviation ``Fig.'' even at the beginning of a sentence. Do not abbreviate 
% ``Table.'' Tables should be numbered with Roman Numerals.

% \subsection{Checking Your Figures: The IEEE Graphics Analyzer}
% The IEEE Graphics Analyzer enables authors to pre-screen their graphics for 
% compliance with IEEE Transactions and Journals standards before submission. 
% The online tool, located at
% \underline{http://graphicsqc.ieee.org/}, allows authors to 
% upload their graphics in order to check that each file is the correct file 
% format, resolution, size and colorspace; that no fonts are missing or 
% corrupt; that figures are not compiled in layers or have transparency, and 
% that they are named according to the IEEE Transactions and Journals naming 
% convention. At the end of this automated process, authors are provided with 
% a detailed report on each graphic within the web applet, as well as by 
% email.

% For more information on using the Graphics Analyzer or any other graphics 
% related topic, contact the IEEE Graphics Help Desk by e-mail at 
% graphics@ieee.org.

% \subsection{Submitting Your Graphics}
% Because IEEE will do the final formatting of your paper,
% you do not need to position figures and tables at the top and bottom of each 
% column. In fact, all figures, figure captions, and tables can be placed at 
% the end of your paper. In addition to, or even in lieu of submitting figures 
% within your final manuscript, figures should be submitted individually, 
% separate from the manuscript in one of the file formats listed above in 
% Section \ref{formats}. Place figure captions below the figures; place table titles 
% above the tables. Please do not include captions as part of the figures, or 
% put them in ``text boxes'' linked to the figures. Also, do not place borders 
% around the outside of your figures.

% \subsection{Color Processing/Printing in IEEE Journals}
% All IEEE Transactions, Journals, and Letters allow an author to publish 
% color figures on IEEE Xplore\textregistered\ at no charge, and automatically 
% convert them to grayscale for print versions. In most journals, figures and 
% tables may alternatively be printed in color if an author chooses to do so. 
% Please note that this service comes at an extra expense to the author. If 
% you intend to have print color graphics, include a note with your final 
% paper indicating which figures or tables you would like to be handled that 
% way, and stating that you are willing to pay the additional fee.

% \section{Conclusion}
% A conclusion section is not required. Although a conclusion may review the 
% main points of the paper, do not replicate the abstract as the conclusion. A 
% conclusion might elaborate on the importance of the work or suggest 
% applications and extensions. 

% \appendices

% Appendixes, if needed, appear before the acknowledgment.


\bibliographystyle{IEEEtran}
\bibliography{reference}



%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{a1.png}}]{First A. Author} (M'76--SM'81--F'87) and all authors may include 
%biographies. Biographies are often not included in conference-related
%papers. This author became a Member (M) of IEEE in 1976, a Senior
%Member (SM) in 1981, and a Fellow (F) in 1987. The first paragraph may
%contain a place and/or date of birth (list place, then date). Next,
%the author's educational background is listed. The degrees should be
%listed with type of degree in what field, which institution, city,
%state, and country, and year the degree was earned. The author's major
%field of study should be lower-cased. 

%The second paragraph uses the pronoun of the person (he or she) and not the author's last name. It lists military and work experience, including summer and fellowship jobs. Job titles are capitalized. The current job must have a location; previous positions may be listed without one. Information concerning previous publications may be included. Try not to list more than three books or published articles. The format for listing publishers of a book within the biography is: title of book (publisher name, year) similar to a reference. Current and previous research interests end the paragraph. The third paragraph begins with the author's title and last name (e.g., Dr.\ Smith, Prof.\ Jones, Mr.\ Kajor, Ms.\ Hunter). List any memberships in professional societies other than the IEEE. Finally, list any awards and work for IEEE committees and publications. If a photograph is provided, it should be of good quality, and professional-looking. Following are two examples of an author's biography.\end{IEEEbiography}

%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{a2.png}}]{Second B. Author} was born in Greenwich Village, New York, NY, USA in 1977. He received the B.S. and M.S. degrees in aerospace engineering from the University of Virginia, Charlottesville, in 2001 and the Ph.D. degree in mechanical engineering from Drexel University, Philadelphia, PA, in 2008.

%From 2001 to 2004, he was a Research Assistant with the Princeton Plasma Physics Laboratory. Since 2009, he has been an Assistant Professor with the Mechanical Engineering Department, Texas A{\&}M University, College Station.He is the author of three books, more than 150 articles, and more than 70 inventions. His research interests include high-pressure and high-density nonthermal plasma discharge processes and applications, microscale plasma discharges, discharges in liquids, spectroscopic diagnostics, plasma propulsion, and innovation plasma applications. He is an Associate Editor of the journal \emph{Earth, Moon, Planets}, and holds two patents. 

%Dr. Author was a recipient of the International Association of Geomagnetism and Aeronomy Young Scientist Award for Excellence in 2008, and the IEEE Electromagnetic Compatibility Society Best Symposium Paper Award in 2011. \end{IEEEbiography}

%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{a3.png}}]{Third C. Author, Jr.} (M'87) received the B.S. degree in mechanical engineering from National Chung Cheng University, Chiayi, Taiwan, in 2004 and the M.S. degree in mechanical engineering from National Tsing Hua University, Hsinchu, Taiwan, in 2006. He is currently pursuing the Ph.D. degree in mechanical engineering at Texas A{\&}M University, College Station, TX, USA.

%From 2008 to 2009, he was a Research Assistant with the Institute of Physics, Academia Sinica, Tapei, Taiwan. His research interest includes the development of surface processing and biological/medical treatment techniques using nonthermal atmospheric pressure plasmas, fundamental study of plasma sources, and fabrication of micro- or nanostructured surfaces. 

%Mr. Author's awards and honors include the Frew Fellowship (Australian Academy of Science), the I. I. Rabi Prize (APS), the European Frequency and Time Forum Award, the Carl Zeiss Research Award, the William F. Meggers Award and the Adolph Lomb Medal (OSA).\end{IEEEbiography}

\end{document}
