\section{Conclusion}
In this paper, we approach the problem of scalable FL, and propose a method for achieving state-of-the-art FL performance at a fraction of the model inference cost by training on available data without strong FL supervision.
Existing methods for fault localization either require executable code, test cases, finegrained line-level supervision, or resource intensive LLMs.
% We leverage LLM probing to elicit the ability of an LLM to localize bugs with weak supervision.
To this end, we propose \ourmethodlong{} (\ourmethod{}), an LLM probing method which uses an attention mechanism to learn to localize bugs from only coarse-grained bug detection supervision.
% We start by developing a benchmark, \dataset{}, containing Python, Java, and C code split into buggy and non-buggy examples balanced by bug types across three bug categories along with ground truth localization labels for the majority of the test set.
Using a suite of eight diverse FL benchmarks, we demonstrate that \ourmethod{} significantly outperforms existing fault localization techniques as well as LLM prompting of models over ten times larger than that used by our probe.
We also identify avenues for future research including FL on long-code samples (over 50 lines), creation of more bug detection datasets by running existing bug detectors on large repositories of code, and execution-free FL on the file and project-level.
% Instead, we leverage probing, a technique for eliciting the capabilities of an LLM with minimal supervision.
% By designing a probe using an attention mechanism, we show that we can achieve both high bug detection and localization performance.
% In addition, we show that a probe learned from bugs in one language can learn bugs that generalize to other languages including simple syntax errors of mismatched parentheses to classes of security vulnerabilities that are language-independent.