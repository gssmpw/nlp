\section{Related Work}
% Outline:
% \begin{itemize}
%     \item Bug detection: neural **Devlin et al., "BERT"**, evaluating code LLMs **Hewlett et al., "Control and Strategy in Natural Language Processing"**, prompting **Lewis et al., "BART: Denoising Sequence-to-Sequence Pre-training for Genomic NLP"**
%     \item Probing: code properties **Liu et al., "LXMERT: Learning Cross-Modality Encoder Representations from Vision to Language"**, using attention **Hudson and Manning, "PANGu Alpha: Large-Scale Self-Supervised Text Understanding"**. The method from **Kovaleva et al., "Reevaluating the Foundations of Neural Machine Translation with Limited Data"** is most similar to ours but it uses an RNN to learn the attention weights rather than a linear probe and it is applied to classic NLP tasks such as constituency parsing.
%     \item Alignment: code understanding capabilities **Srivastava et al., "AutoAugment: Online Overfit Reduction with No Need for Human Expertise"**
% \end{itemize}

We survey related work in FL techniques and LLM probing.

\textbf{Automated Fault Localization.}
% Symbolic reasoning approaches for bug detection include static approaches such as CodeQL **Spreitzenbarth et al., "Magellan: 10K-Functions, 1000-KLines of Code, Java Malware Analysis at Scale"**, dynamic approaches such as fuzzing **Godefroid et al., "DART: Directed Automated Random Testing"**) and hybrid approaches such as dynamic symbolic execution **Godefroid et al., "DART: Directed Automated Random Testing"**. These approaches all require customization including tests, formal specifications, and compilable code.
% % All of these approaches formulate bug detection as a {\em decision problem}, which often requires customization in the form of formal correctness specifications, and programs that compile (for static) and run (for dynamic).
% % The undecidability of this decision problem leads these approaches to strike tradeoffs between scalability and accuracy.
% The requirement on customization for symbolic reasoning approaches has spurred a large body of deep learning approaches.
% % that formulate bug detection as a {\em classification problem}.
% %The idea of applying language models for **Devlin et al., "BERT"** introduced the idea of applying language models for modeling real-world code and laid the foundation for a line of work on neural bug detectors.
% Due to the lack of large real-world supervised training datasets, these methods often rely on synthetic data, causing overfitting **Sung et al., "Learning to Compare Image Patches via CNN and Spiral Matching"**.
% To overcome the overfitting, there are methods for better synthetic data generation **Kiros et al., "Using Deep Learning to Improve Word Representations for Language Translation"**, more generalizable architecture design **Vaswani et al., "Attention Is All You Need"**, unsupervised pretraining on code **Liu et al., "LXMERT: Learning Cross-Modality Encoder Representations from Vision to Language"**, and recently prompting-based methods which utilize the knowledge of LLMs **Raffel et al., "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"**.
% Our approach allows for scaling FL by training on the available bug detection data and using larger models for improved performance.
% % Our approach in this paper differs from existing works since we rely on small supervised datasets to learn a lightweight probe on top of an LLM, allowing us to elicit its knowledge of bugs without severe overfitting.
Methods for FL include the traditional spectrum-based (SBFL) and mutation-based (MBFL) methods which require executable code and deep-learning based approaches **Srivastava et al., "AutoAugment: Online Overfit Reduction with No Need for Human Expertise"**. SBFL methods are simple but have low accuracy while MBFL and deep learning approaches have higher accuracy at larger computational cost **Zhang et al., "DART: Directed Automated Random Testing"**. Various deep learning approaches combine SBFL and MBFL with semantic features from deep models **Srivastava et al., "AutoAugment: Online Overfit Reduction with No Need for Human Expertise"**. Recently, LLMs have significantly outperformed SBFL and MBFL approaches on FL on the method level **Raffel et al., "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"**. Prompting and agent-based systems can even perform repository-level FL **Touretsky et al., "Learning to Compare Image Patches via CNN and Spiral Matching"**, but they must reduce the problem to method-level FL **Vaswani et al., "Attention Is All You Need"**. LLMAO **Kovaleva et al., "Reevaluating the Foundations of Neural Machine Translation with Limited Data"** trains an adapter on an LLM from strong FL supervision to perform FL without executable tests, and WELL **Spreitzenbarth et al., "Magellan: 10K-Functions, 1000-KLines of Code, Java Malware Analysis at Scale"** finetunes an LLM on bug detection supervision and interprets the attention for FL.
Unlike these approaches, our method uses LLM probing, and we leverage bug detection supervision to scale to more available data.
% Our method is an LLM probing approach which combines the power of LLMs with supervised datasets in a lightweight manner for strong FL performance.


\textbf{Probing LLMs.}
Probing is useful tool in LLM interpretability.
% , although probing results can be nuanced **Hewlett et al., "Control and Strategy in Natural Language Processing"**.
There is extensive work on probing LLMs, most notably BERT **Devlin et al., "BERT"**, to understand what linguistic knowledge it encodes. **Kovaleva et al., "Reevaluating the Foundations of Neural Machine Translation with Limited Data"** design a probe for eliciting natural language syntax parse trees from BERT, and **Liu et al., "LXMERT: Learning Cross-Modality Encoder Representations from Vision to Language"** probe for the code abstract syntax trees.
These probes are usually trained on a fixed size input **Srivastava et al., "AutoAugment: Online Overfit Reduction with No Need for Human Expertise"**, but pooling sequence representations using global weights **Vaswani et al., "Attention Is All You Need"** and sample-conditional weights **Touretsky et al., "Learning to Compare Image Patches via CNN and Spiral Matching"** have been studied. Unlike these approaches, we adopt a traditional Transformer layer as our probe where the attention module learns to pool the input tokens.
% Finally, probing is traditionally known to be outperformed by full-model finetuning, but recent work has shown that probing often performs better out-of-distribution **Hewlett et al., "Control and Strategy in Natural Language Processing"**. We build on such work and show that \ourmethod{} outperforms finetuning on bug generalization across languages.

% \textbf{LLM alignment}
% Recently, probing has also been used to leverage the knowledge of an LLM for improved truth classification, and even unsupervised probing methods can outperform few-shot prompting **Touretsky et al., "Learning to Compare Image Patches via CNN and Spiral Matching"**.