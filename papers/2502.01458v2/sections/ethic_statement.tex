\section*{Broader Impact and Ethics Statement}

This work on weak-to-strong generalization aims to improve the alignment of superhuman models with human values. 
While our theoretical and empirical insights highlight the potential of this approach, we acknowledge the risks of propagating biases or errors from the weak model to the strong model. 
To address these concerns, we emphasize the importance of ensuring the weak model's generalization and calibration, as well as carefully balancing the strong model's optimization to avoid over-reliance on weak supervision. 
We encourage rigorous testing, transparency, and ongoing monitoring in real-world applications to ensure the safe and ethical deployment of such systems. 
Our work contributes to the broader effort of aligning advanced AI with human values, but its implementation must prioritize fairness, accountability, and safety.



\section*{Acknowledgements}
We are deeply grateful to Shaojie Li, Chenyu Zheng, Gengze Xu for their  constructive suggestions.




