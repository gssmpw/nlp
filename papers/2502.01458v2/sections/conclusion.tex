\section{Conclusion}

This paper provides a comprehensive theoretical framework for understanding the capability and limitation of weak-to-strong generalization. 
In the classification setting, we establish upper and lower bounds for both the generalization and calibration errors of the strong model, revealing that the primary limitations arise from the weak model and the optimization objective. 
These bounds emphasize two critical insights: (1) the weak model must demonstrate strong generalization and calibration performance, and (2) the strong model should avoid excessive training to prevent overfitting on weak supervision.
In the regression setting, we extended prior work to output distribution divergence loss, proving that a strong model can outperform its weak teacher by at least their disagreement under certain assumptions. 
Our theoretical findings were validated through experiments with language models and MLP, providing practical insights and some interesting observations for the WTSG paradigm.
% To broaden the applicability of the theoretical framework presented in this paper, we also provide some theoretical extension in~\cref{appendix:further_discusion}.
% in~\cref{appendix:further_discusion}, we demonstrate how some of the results from~\cref{section:universal_result} can be extended to the regression setting.
% Additionally, we show how certain findings from~\cref{subsec:recover_quantify} can be adapted to the classification setting.
% The proof technique follows a similar methodology to that employed in the main theoretical results of our paper.
% Overall, we hope this work deepens the understanding of WTSG and inspires future research on its foundations.
Overall, we hope this work enhances the understanding of weak-to-strong generalization and encourages future research to unlock its promise for human-aligned AI systems.











