%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

\title{\LARGE \bf
Graph Contrastive Learning for Connectome Classification
}


\author{Mart\'in Schmidt$^{1}$, Sara Silva$^{1}$, Federico Larroca$^{1}$, Gonzalo Mateos$^{2}$ and Pablo Mus\'e$^{1}$% <-this % stops a space
\thanks{*This work was partially funded by CSIC (I+D project 22520220100076UD) and ANII (FCE-1-2023-1-176172)}% <-this % stops a space
\thanks{$^{1}$Mart\'in Schmidt, Sara Silva, Federico Larroca and Pablo Mus\'e are with the  Facultad de Ingenier\'ia, Universidad de la Rep\'ublica, Montevideo 11300, Uruguay (e-mail: {\tt\small mschmidt@fing.edu.uy; 
ssilva@fing.edu.uy;
flarroca@fing.edu.uy; pmuse@fing.edu.uy}). Both Schmidt and Silva contributed equally to this work and share first authorship. }%
\thanks{$^{2}$Gonzalo Mateos is with the Department of Electrical and Computer Engineering, University of Rochester, Rochester, NY 14627 USA (e-mail: {\tt\small gmateosb@ece.rochester.edu}).}%
}

\def\etal{\textit{et al.}}
%\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\def\sectionautorefname{Sec.\ }
\def\figureautorefname{Fig.}
\usepackage{caption}
\usepackage{multirow}
\usepackage{amssymb}% http://ctan.org/pkg/amssymb
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\usepackage[style=numeric, sorting=none]{biblatex}
\addbibresource{referencias.bib}

\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

% The brain has been the subject of extensive research due to its critical role in cognitive and emotional processes, as well as its contribution to understanding human behavior. Much of this research focuses on the connections between different regions of interest (ROIs), encompassing both anatomical (structural) connections and regions exhibiting similar activity patterns (functional). 
% leading to the development of numerous analytical methods. 
% In particular, these connections between ROIs are represented as graphs in the literature, commonly referred to as connectomes.

With recent advancements in non-invasive techniques for measuring brain activity, such as magnetic resonance imaging (MRI), the study of structural and functional brain networks through graph signal processing (GSP) has gained notable prominence. GSP stands as a key tool in unraveling the interplay between the brain’s function and structure, enabling the analysis of graphs defined by the connections between regions of interest—referred to as connectomes in this context. Our work represents a further step in this direction by exploring supervised contrastive learning methods within the realm of graph representation learning. The main objective of this approach is to generate subject-level (i.e., graph-level) vector representations that bring together subjects sharing the same label while separating those with different labels. These connectome embeddings are derived from a graph neural network Encoder-Decoder architecture, which jointly considers structural and functional connectivity. By leveraging data augmentation techniques, the proposed framework achieves state-of-the-art performance in a gender classification task using Human Connectome Project data. More broadly, our connectome-centric methodological advances support the promising prospect of using GSP to discover more about brain function, with potential impact to understanding heterogeneity in the neurodegeneration for precision medicine and diagnosis.

%The GNN is trained in two stages: in the pre-training phase, it learns to minimize a similarity-preserving loss, whereas in the fine-tuning phase, a classifier is incorporated into the pipeline for an additional training step.

% With advancements in non-invasive techniques for measuring brain activity and structural connectivity, such as magnetic resonance imaging, studying brain networks (structural and functional) through graph signal processing (GSP) has gained prominence. 
% GSP is a key tool in understanding the interplay between the brain's function and structure that permits the analysis of graphs defined by connections between regions of interest, known in this context as connectomes.  
% Our work represents a further step in this direction. In particular, we explore supervised contrastive learning methods in the context of graph representation learning. The objective of this technique is to produce vector representations at the graph level (i.e., subject level) that are close to each other for subjects sharing the same label and far apart for those with different labels. These application-dependent vectors are computed through a graph neural network (GNN) encoder-decoder architecture, coupling both structural connectivity (SC) and functional connectivity (FC) networks. The GNN is trained in two stages: in the pre-training phase, it learns to minimize a similarity-preserving loss, whereas in the fine-tuning phase, a classifier is incorporated into the pipeline, and the complete system is trained further.
% The proposed framework, enhanced with data augmentation techniques, achieves state-of-the-art performance in gender classification tasks based on connectomes, demonstrating its efficacy.
% State-of-the-art results were achieved, with an accuracy of $94\%$, leveraging contrastive learning techniques and classical data augmentation methods. Additionally, the relationship between the functional and structural graphs was examined, utilizing both an encoder architecture and an encoder-decoder one. The latter with a dual loss function: reconstruction of the functional graph from the structural graph and classification. This aims to highlight each connectivity's relative importance in classification tasks.
% \newline
% \indent \textit{Clinical relevance}— This is a brief additional statement on why this might be of interest to practicing clinicians. Example: This establishes the anesthetic efficacy of 10\% intraosseous injections with epinephrine to positively influence cardiovascular function. {\color{red} [FL] Por lo que vi en papers de ediciones anteriores, no es necesario poner esto.}
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% Algunos comentarios de Gonchi %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% 3 de Enero, 2025

% * Sobrevolando el paper (lo que sigue es un tema de gustos, pero en fin), para mi hay mucha itemizacion que lo hace ver mas como una presentacion que un paper. Mas alla del estilo, no es el mejor uso del espacio. Por ejemplo, me parece bien itemizar las contribuciones en la Introduccion (para enfatizarlas), pero despues por ejemplo en Section II-A prefiero hacer algo asi como \noindent\textbf{Inputs.} The model.... \noindent\textbf{GCN Encoder.} The enconder... en vez de enumerar. Misma cosa en Section II-C con Pre-training y Fine-tuning, y en algun otra instancia en Section III. Yo reformateo despues cuando haga mi pasada, si les parece bien.

% * Introduction, primera frase del segundo parrafo: El "This work focuses on gender classification using..." yo lo venderia como "This work focuses on subject-level classification using..." y despues sin duda mencionaria gender classification como un ejemplo que usamos para ilustrar/demostrar la utilidad de un metodo que tiene varias propiedades/atributos interesantes (contrastive learning y data augmentation y su importancia en neuroimaging data analysis, donde los datos tienen a ser limitados, graph representation learning y graph signal processing como un mecanismo natural para integrar structural y functional information, trabajar con grafos se alinea con las tendencias prevalentes en network neuroscience, etc etc) y un alcance bastante mas general. Como esta ahora, da una impresion de alcance "narrow". Sin sobrevender or vender humo, me parece que podemos posicionar la innovacion un poco mejor. De nuevo, yo puedo ayudar a re-escribir esto cuando le de mi pasada.

% * Estan muy bien los diagramas en Fig. 1 y 2. Porque el caption de la Fig. 1 esta formateado tip flushed left? Esto es un poco raro.

% * Despues sigo...

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

The study of human brain connectivity, both structural and functional, is essential to decipher the brain's pivotal role in regulating behavior and cognitive processes. Neuroimaging advances, such as functional magnetic resonance imaging (fMRI) and positron emission tomography (PET), enable real-time visualization of brain activity, offering valuable insights into functional connectivity (FC)~\cite{van2010exploring}. Furthermore, structural mapping through techniques such as diffusion magnetic resonance imaging (dMRI) facilitates the construction of macroscopic maps of the physical connections of the brain~\cite{fornito2016fundamentals}. These tools have been instrumental in the diagnosis and treatment of neurological and psychiatric conditions, including epilepsy, autism, and schizophrenia \cite{esquizofrenia, epilepsia, autismo}.

This work focuses on Contrastive Learning (CL) techniques applied to Graph Neural Networks (GNNs), which excel in processing data structured as graphs; see e.g.,~\cite{gama2020graphs}. CL is a widely used machine learning technique that learns robust representations by enforcing similarity between related data points while separating unrelated ones. CL approaches, e.g., the SimCLR framework~\cite{SimCLR}, have achieved significant success in fields such as computer vision. However, only a few CL studies including~\cite{GCLAugmentations, empiricalGCL, fairCL} have focused on graph-structured data, leaving this area underexplored in the literature. In particular, we employ these techniques for subject-level (gender) classification using FC and structural connectomes (SC) extracted from fMRI and dMRI data, respectively. Connectomes are naturally modeled as graphs, where each node corresponds to a region of interest (ROI) and each edge represents the neural connections between ROIs, thereby capturing their intricate and complex relationships~\cite{sporns2010networks}. Beyond the specific gender classification task, we aim to contribute in the pathway to advance our understanding of brain networks and develop tools with broader applications in neuroscience. \vspace{2pt}

% By performing convolutions directly on graph structures, GNNs are suited to analyzing brain connectivity. 
\noindent \textbf{Methodological innovation.} A GNN may be understood as a concatenation of several layers, each consisting of a graph convolution followed by a point-wise non-linearity~\cite{gama2020graphs}. Graph convolutions are fundamental tools of Graph Signal Processing (GSP)~\cite{ortega2018graph}, a framework that has recently gained prominence for the analysis of brain networks and associated signals~\cite{huang2016graph,huang2018graph}. 
% By performing convolutions directly on graph structures, GNNs are suited to analyzing brain connectivity. 
The rationale behind applying the CL technique to our problem is inspired by Li \etal ~\cite{li2022learning}, who initially implemented the GNN architecture used in this study for connectome classification and later proposed a framework incorporating concepts akin to CL~\cite{li2022similarity}. Building on this foundation, our aim is to structure the latent space such that learned representations capture meaningful relationships within the data, ultimately enhancing classification performance. Different from~\cite{li2022learning,li2022similarity}, we propose a novel two-stage GNN training scheme. In the first stage, the pre-training phase, the model learns
to minimize a supervised similarity-preserving loss, whereas in the fine-tuning phase, a classifier is incorporated into the pipeline for
an additional training step. Furthermore, we integrate data augmentation techniques to generate diverse views of the same subject, ensuring that the model achieves a closer alignment between these augmented versions during the pre-training phase.\vspace{2pt} %This approach not only enhances the representation capacity and robustness of the model but also improves classification performance by structuring the latent space to capture meaningful relationships within the data.

%(Differently), we advocate a new two-stage GNN training scheme. In the first, a pre-training phase, the model learns to minimize a similarity-preserving loss between embeddings of the same subject. (We also propose) that these embeddings are generated from augmented versions... .  In the fine-tuning phase, a classifier is incorporated into the pipeline for an additional training step, allowing the model to leverage the refined representations for accurate connectome classification.


%Different from ~\cite{li2022similarity}, we advocate a new two-stage GNN training scheme: in the pre-training phase, it learns to minimize a similarity-preserving loss, (la loss busca) the closer alignment between the augmented versions of the same subject, [se puede agregar algo de esto: Building on this foundation, our aim is to structure the latent space such that learned representations capture meaningful relationships within the data, ultimately enhancing classification performance.] improving representation capacity and the robustness of the model. Whereas in the fine-tuning phase, a classifier is incorporated into the pipeline for an additional training step. 

%Besides, we implement ... DA.
%parafrasear: the closer alignment between the augmented versions of the same subject, improving representation capacity and the robustness of the model. 

% (Particularly), we employ this techniques on gender classification using functional and structural connectomes (referred to as FC and SC, respectively)

% connectome classification due to their naturally modeled as graphs, capturing the intricate neural connections and their complex relationships. By performing convolutions directly on graph structures, GNNs are particularly suited to analyzing brain connectivity. 


% This work focuses on gender classification using functional and structural connectomes (referred to as FC and SC, respectively) built based on MRI as a pathway for advancing our understanding of brain networks and developing tools with broader applications in neuroscience. For this task, we employ Graph Neural Networks (GNNs), which excel in processing data structured as graphs~\cite{gama2020graphs}. Connectomes are naturally modeled as graphs, capturing the intricate neural connections and their complex relationships. By performing convolutions directly on graph structures, GNNs are particularly suited to analyzing brain connectivity. 
% %Through graph-based modeling, this work contributes to state-of-the-art methods in connectome analysis while exploring the broader applicability of GNNs in neuroscience.
% This work contributes to state-of-the-art methods in connectome analysis while extending the applicability of GNNs in neuroscience.

% % In this paper, we investigate the implementation of contrastive learning, a popular technique in machine learning designed to learn useful representations by enforcing similarity between related data points while distinguishing them from unrelated ones. 
% To achieve this, we apply contrastive learning, a widely used machine learning technique that learns robust representations by enforcing similarity between related data points while separating unrelated ones.
% This approach has seen significant success in fields like computer vision, exemplified by the well-known SimCLR framework~\cite{SimCLR}, but its application to graph-structured data remains under-explored in the literature. The intuition behind applying this technique to our problem is inspired by~\cite{li2022learning}, who initially implemented the GNN architecture used in this study for connectome classification and later proposed a framework with concepts akin to contrastive learning~\cite{li2022similarity}. Building on this foundation, our aim is to structure the latent space such that learned representations capture meaningful relationships within the data, ultimately enhancing classification performance.

\noindent \textbf{Evaluation protocol.} To evaluate the effectiveness of this approach, we compare against a more conventional graph classification framework, where a GNN is trained directly for the  task without the additional CL step. This comparison provides insights into the potential advantages of CL in graph-based modeling and its impact on connectome classification performance. Through this study, our work contributes to the growing exploration of advanced representation learning techniques in network neuroscience~\cite{ktena2018metric,sihag2023explainable,neurograph}.

Moreover, to assess the robustness of the CL framework and to evaluate the impact of data quantity on the performance of each proposed model, we conducted experiments using reduced versions of the training dataset. This investigation is particularly pertinent in the medical domain, where acquiring large-scale datasets is often challenging due to patient privacy concerns, high data collection costs, and the inherent rarity of certain neurological conditions. Consequently, researchers often face the need to develop effective models under data scarcity. \vspace{2pt}

\noindent \textbf{Data.} The dataset used in the present work is part of the Human Connectome Project (HCP)~\cite{HCP, HCP_DC}, a large-scale initiative aimed at mapping the human connectome with advanced MRI techniques. Specifically, we utilized the HCP Young Adults 1200 release, which includes data from 1200 healthy adults.\footnote{Visit the project website \url{https://www.humanconnectome.org/study/hcp-young-adult} and the repository
\url{https://www.humanconnectome.org/study/hcp-young-adult/document/1200-subjects-data-release} for details.} This release provides comprehensive MRI data, along with demographic and behavioral information. For this study, we derived FC matrices from functional MRI (fMRI) timecourses and SC from diffusion MRI (dMRI) data using the Desikan-Killiany atlas~\cite{DESIKAN2006968}. After preprocessing, the dataset includes 1048 subjects with complete data, as not all participants underwent both imaging modalities. This rich dataset enables a robust exploration of brain connectivity and its relationship to individual characteristics.

All in all, our main contributions are the following:\vspace{2pt}  

    \noindent $\bullet$ \textbf{Evaluation of contrastive learning methods}: We evaluate the impact of applying CL techniques to improve the quality of learned representations for connectome classification, including experiments with reduced training sets to emulate the common scenario of limited data in medical applications. 
    
    \noindent $\bullet$  \textbf{Effect of data augmentation}: We analyze the role of data augmentation strategies within the CL framework and their influence on model performance.  
    
    \noindent $\bullet$  \textbf{Integration with Encoder-Decoder architectures}: We explore the combination of CL with the Encoder-Decoder approach for SC and FC in~\cite{li2022learning}, building on the architecture therein to enhance representation learning.  
    
    \noindent $\bullet$ \textbf{State-of-the-art classification}: We demonstrate competitive or superior classification performance relative to state-of-the-art methods, benchmarking against a key study~\cite{neurograph}.\vspace{2pt}   
% \end{enumerate}

\noindent \emph{Notation:} In what follows, matrices are represented by bold uppercase letters (\(\mathbf{X}\)), column vectors by bold lowercase letters (\(\mathbf{x}\)) and plain letters ($x$) denote scalars or indices. The Frobenius norm of a matrix \(\mathbf{M} \in \mathbb{R}^{N \times N}\) is defined as $\|\mathbf{M}\|_F^2:= \sum_{i=1}^N\sum_{j=1}^N  M_{ij}^2.$ The remaining notation is explicitly defined when introduced.  


\section{Methods}

This section presents an overview of the proposed methodology. We begin by describing the Encoder-Decoder baseline model in Section \ref{sec:ed}, and then we introduce two useful data augmentation techniques (Section \ref{sec:da}). Finally, Section \ref{sec:cl} outlines how we integrate these techniques into a supervised CL framework rooted in the Encoder-Decoder architecture.

\subsection{Encoder-decoder architecture}
\label{sec:ed}

The multi-task Encoder-Decoder architecture used in this work is illustrated in \autoref{fig:encoder-decoder}. This model consists of two main components: the top branch performs a regression task to reconstruct the FC matrix from the SC matrix, while the bottom branch predicts the gender of the subject using a graph classification module. 
These components are tightly integrated to facilitate learning of latent representations with inductive biases beneficial to both tasks.
% These two components are not decoupled since the leverage of integrating both is learning latent representations with inductive biases for both tasks.

The following are key components of the architecture. %{\color{red} Me parece que lo de abajo necesita introducir algunas cosas antes. Por lo pronto, seguro el 87, que no está dicho en ningún lado de dónde salió. Quizá incluso convenga dar la notación antes, por lo menos que las mayúsculas negrita son matrices y las minúsculas negritas son vectores. }

\begin{figure*}
\centering
\includegraphics[width=\textwidth]{figures/encoder_decoder.pdf}
\caption{
The Encoder-Decoder architecture used in this work processes structural connectivity matrix \(\mathbf{A}\) as input, along with nodal attributes \(\mathbf{X}^{(0)} = \mathbf{I}_{N}\). The GCN encoder performs graph convolutions and associated information propagation through $L$ layers, producing low-dimensional node embeddings \(\mathbf{X}^{(l)}\) at layer $l$. Intermediate representations from all layers are concatenated into one final embedding \(\mathbf{X}_C\). The decoder uses an outer-product operation to predict the reconstructed functional connectivity matrix \(\hat{\mathbf{\Sigma}}:=\text{ReLU}(\mathbf{X}_C\mathbf{X}_C^\top)\), effectively modeling the SC-FC mapping. Graph-level representations \(\mathbf{z}\) are obtained via a pooling operation applied to \(\mathbf{X}_C\), summarizing the node embeddings into a single vector, from which a logistic regression classifier predicts the binary label \(\hat{y}\).\vspace{2pt} %The model is referred to as the ``encoder" when the architecture excludes the reconstruction branch. Additionally, within the contrastive learning framework, the logistic regression classifier is omitted, and the graph-level embedding \(\mathbf{z}\) is trained directly to learn meaningful representations. 
}
\label{fig:encoder-decoder}
\end{figure*}

% \begin{enumerate}
    \noindent \textbf{Inputs.}  
    The model takes as input the SC matrix \(\mathbf{A} \in \mathbb{R}^{N \times N}\), the FC matrix \(\mathbf{\Sigma} \in [0, 1]^{N \times N}\), and an initial nodal feature matrix \(\mathbf{X}^{(0)} = \mathbf{I}_{N}\) (the identity matrix; i.e., a one-hot encoding vector per ROI), where $N$ is the number of ROIs (with $N=87$, as per the Desikan-Killiany atlas). \vspace{2pt}

    \noindent \textbf{GCN encoder.}  
    The encoder uses a multi-layer graph convolutional network (GCN) to generate low-dimensional node embeddings. At each layer \(l\), the GCN applies a graph convolution followed by a $\textrm{ReLU}(\cdot)=\max(\cdot,0)$ non-linearity:  
    \[
    \mathbf{X}^{(l+1)} = \text{ReLU}(\tilde{\mathbf{A}}\mathbf{X}^{(l)}\mathbf{\Theta}^{(l)}),
    \]
    where \(\tilde{\mathbf{A}}\) is the normalized SC adjacency matrix, as defined in~\cite{primer_GCN}, \(\mathbf{X}^{(l)} \in \mathbb{R}^{N \times d_{l-1}}\) is the feature matrix at layer \(l\), \(\mathbf{\Theta}^{(l)} \in \mathbb{R}^{d_{l-1} \times d_l}\) are the trainable weights and \( d_l \) denotes the dimensionality of the node embeddings at layer \( l \). The decoder output is a concatenated embedding \(\mathbf{X}_C \in \mathbb{R}^{N \times \sum_l d_l}\), combining the representations from all layers $l=1,\ldots,L$.\vspace{2pt}

    \noindent \textbf{Decoder.}  
    The decoder reconstructs the FC matrix from \(\mathbf{X}_C\) as \(\hat{\mathbf{\Sigma}} :   = \text{ReLU}(\mathbf{X}_C \mathbf{X}_C^\top)\). This step ensures that \(\hat{\mathbf{\Sigma}} \in \mathbb{R}^{N \times N}\) has positive entries, aligning with the FC reconstruction objective. The reconstruction error is measured using the Mean Squared Error (MSE) between the entries of \(\hat{\mathbf{\Sigma}}\) and the ground truth FC matrix \(\mathbf{\Sigma}\).\vspace{2pt}

    \noindent \textbf{Pooling and classification.}  
    For the classification branch, a pooling layer aggregates \(\mathbf{X}_C\) across nodes by averaging, resulting in a graph-level embedding \(\mathbf{z}\in \mathbb{R}^{\sum_l d_l}\). This embedding is then fed to a logistic regression classifier to predict the subject's gender, using a binary cross-entropy (CE) loss.\vspace{2pt} %The pooling method used is the mean. {\color{red} creo que esto no hace falta decirlo de nuevo.}

    %\item \textbf{Loss Function:}  
    % The model is trained using a combination of reconstruction and classification loss:  
    % \[
    % \mathcal{L} = \mathcal{L}_{MSE}\left(\hat{\mathbf{\Sigma}}, \mathbf{\Sigma}\right) + \lambda \times \mathcal{L}_{CLA}(\hat{y}, y),
    % \]
    % where \(\mathbf{\Sigma}\) is the ground truth FC matrix, \(y\) is the ground truth gender label, and \(\hat{\mathbf{\Sigma}}\) and \(\hat{y}\) are their respective predictions. The hyperparameter \(\lambda\) balances the importance of the reconstruction and classification objectives. {\color{red} Yo acá sería más preciso y pondría una ecuación como la \eqref{eq:l_sup_loss}. Y ojo con el segundo término de la loss porque el diagrama dice CE de cross-entropy, no CLA.\color{blue}{mejor como esta abajo? quedo tambien la norma de frobenius en 'notation'}}
    \noindent \textbf{Loss function.}  
    The model is trained using a joint reconstruction and classification loss:  
\[
\mathcal{L}
\;=\;
\underbrace{\mathcal{L}_{\mathrm{MSE}}\bigl(\hat{\mathbf{\Sigma}}, \mathbf{\Sigma}\bigr)}_{\text{reconstruction loss}}
\;+\;
\lambda
\,\times\,
\underbrace{\mathcal{L}_{\mathrm{CE}}\bigl(\hat{y}, y\bigr)}_{\text{classification loss}},
\]
where \(\mathbf{\Sigma}\) is the ground truth FC matrix, \(y\) is the ground truth gender label, and \(\hat{\mathbf{\Sigma}}\) and \(\hat{y}\) are their respective predictions. The hyperparameter \(\lambda\) balances the importance of the reconstruction and classification objectives.
% \begin{itemize}
%     \item \textbf{Reconstruction Loss.} 
    The reconstruction MSE is computed as:
    \begin{equation}
    \begin{aligned}
    \mathcal{L}_{\mathrm{MSE}}\bigl(\hat{\mathbf{\Sigma}}, \mathbf{\Sigma}\bigr)
    \;=\;
    \frac{1}{N^2} \,\bigl\|\hat{\mathbf{\Sigma}} - \mathbf{\Sigma}\bigr\|_{F}^{2}.
    \end{aligned}
    \label{eq:l_mse}
    \end{equation}
    % \item \textbf{Classification Loss.}
    On the other hand, minimizing the classification loss aims at predicting the binary label \(y\) given \(\hat{y}\). We adopt the binary CE loss, which for a single sample amounts to:
    \begin{equation}
    \begin{aligned}
    \mathcal{L}_{\mathrm{CE}}\bigl(\hat{y}, y\bigr)
    \;=\;
    -\,\Bigl[y\,\log\!\bigl(\hat{y}\bigr)
    \;+\;(1-y)\,\log\!\bigl(1-\hat{y}\bigr)\Bigr].
    \end{aligned}
    \label{eq:l_ce}
    \end{equation}
% \end{itemize}
When training on a batch, both loss functions are averaged across all samples.

% \end{enumerate}

This dual-task pipeline enables the model to learn robust graph representations that are effective for reconstructing FC matrices and predicting gender (or other subject-level binary attributes). Even if the end goal is purely discriminative, the regression branch implicitly infuses the embeddings $\mathbf{X}_C$ with valuable information about the SC-FC coupling~\cite{li2022learning}.


\subsection{Data augmentation for graphs} \label{sec:da}

Data augmentation is widely used in deep learning to address the challenge of limited data availability and improve generalization. Two graph augmentation strategies were considered in this work, which we now briefly discuss, noting that other strategies are possible~\cite{DAGraphs, GCLAugmentations}.

% \begin{itemize}
In \emph{attribute masking} certain node attributes (i.e., the columns of $\mathbf{X}^{(0)}$) are masked by setting them to zero. Recall that the one-hot encoding we are using as input signal acts as an identifier for the ROI.
    % In our implementation, the one-hot encoding vectors 
    By setting the corresponding signal vector to zero, 
    % of selected ROIs are entirely set to zero, 
    we are challenging the model to infer informative representations 
    ignoring some nodes' identities. 
    % using incomplete attribute information. 

\emph{Edge dropping} may be regarded as the dual of attribute masking, where now edges $A_{ij}$ of the SC graph are randomly dropped based on a probability \(p\). This forces the model to remain robust to missing links and generate consistent representations despite an incomplete graph structure.
% \end{itemize}

In the CL framework, augmented versions of the data are incorporated to encourage the model to produce meaningful representations, even when the input data is perturbed. These augmentations aim to preserve the overall structure of the data while introducing variations that can aid generalization.

\subsection{Supervised contrastive learning}\label{sec:cl}

As illustrated in \autoref{fig:contrastive_learning}, the goal of CL is to train models to learn vector representations that are interpretable or useful for downstream tasks. The core principle is to ensure that similar data points are mapped to similar representations. Supervised CL, introduced in~\cite{supervisedCL}, extends this approach to a fully supervised framework. In this setting, not only are augmented versions of the same data point pulled closer together and distinct data points pushed apart, but this process is also guided by class labels: data points of the same class are attracted to each other, while those from different classes are repelled.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figures/data_augmentation.pdf}
    \caption{A schematic view of the constrastive learning approach. For each input datum $\{\mathbf{A}_k,y_k\}$ we generate two augmented versions $\{\mathbf{A}'_{2k},y_k\}$ and $\{\mathbf{A}'_{2k+1},y_k\}$ using edge dropping and attribute masking. The corresponding graph embeddings $\mathbf{z}_i$ are produced as in Fig.\ \ref{fig:encoder-decoder}. Whereas unsupervised CL only pulls together the representations stemming from the same original graph (represented by green arrows), supervised CL optimizes the contrastive loss $\mathcal{L}^{\mathrm{sup}}$ in \eqref{eq:l_sup_loss}, which also takes into account the class labels of the subjects. This approach attracts augmented versions originating from subjects with the same label and repels those associated with different ones (represented by green but also red arrows).}
    % Whereas unsupervised contrastive learning only pulls together the representations stemming from the same original graph, its supervised counterpart pulls together representations with the same label (represented by a green arrow) and pushes apart those with a different label (red arrow).

    
    \label{fig:contrastive_learning}
\end{figure}

Given a batch of \(B\) data points and their corresponding labels \(\{\mathbf{A}_k, y_k\}_{k=1}^{B}\), the training batch consists of \(2B\) pairs \(\{\mathbf{A}'_k, y'_k\}_{k=1}^{2B}\). Here, \(\mathbf{A}'_{2k-1}\) and \(\mathbf{A}'_{2k}\) are two augmented versions of the original SC sample \(\mathbf{A}_k\), generated with attribute masking and edge dropping respectively (see Section \ref{sec:da}), and \(y'_{2k-1} = y'_{2k} = y_k\).
We propose a training process consisting of two steps: pre-training and fine-tuning.\vspace{2pt}

\noindent \textbf{Pre-training.} During the pre-training phase, the architecture is the one presented in Section \ref{sec:ed}, albeit without the logistic regressor (i.e., no classification is performed). In this step, the objective is to minimize the contrastive loss:
%
\small\begin{gather}
    \mathcal{L}^{\mathrm{sup}}\bigl(\{\mathbf{z}_k, y_k\}_{k=1}^{2B}\bigr) = \sum_{i \in I} \frac{-1}{|P(i)|} \sum_{p \in P(i)} \log \frac{\exp\bigl(\frac{\mathbf{z}_i^\top \mathbf{z}_p}{\tau}\bigr)}{\sum_{q \in Q(i)} \exp\bigl(\frac{\mathbf{z}_i^\top \mathbf{z}_q}{\tau}\bigr)},
   \label{eq:l_sup_loss}
\end{gather}\normalsize
%
    %{\color{red}[FL] chequear porque en el denominador decía $z_a$ y yo puse $z_q$ que entiendo que es lo que va. Si, god}
where \(\mathbf{z}_i\) is the vector representation of matrix \(\mathbf{A}'_i\) (cf.\ after pooling in the lower branch in \autoref{fig:encoder-decoder}),  \(I = \{1, \ldots, 2B\}\) represents the set of indices in the augmented batch, \(Q(i) = I \setminus \{i\}\) is the set of indices excluding \(i\), \(P(i) = \{p \in Q(i) : y'_p = y'_i\}\) is the set of positive indices distinct from \(i\) that share the same label, and \(\tau \in (0,1]\) is a temperature hyperparameter for the model.

When the decoder branch is integrated to this framework, the model is trained using a combination of $\mathcal{L}^{\text{sup}}$ in \eqref{eq:l_sup_loss} and the reconstruction loss $\mathcal{L}_{\mathrm{MSE}}$ in~\eqref{eq:l_mse}. In this case, the reconstructed FC matrix $\hat{\mathbf{\Sigma}}_k$ is generated from the non-augmented SC matrix $\mathbf{A}_k$. The overall loss function in pre-training is therefore defined as follows:
\[
\mathcal{L}
\;=\;
\frac{1}{B} \sum_{k=1}^{B} \mathcal{L}_{\mathrm{MSE}}\bigl(\hat{\mathbf{\Sigma}}_k, \mathbf{\Sigma}_k\bigr)
\;+\;
\lambda
\,\times\,
\mathcal{L}^{\mathrm{sup}}\bigl(\{\mathbf{z}_k, y_k\}_{k=1}^{2B}\bigr).
\]
%
Note that in this step, we only adapt the parameters of the GCN encoder since the pooling that produces $\mathbf{z}$ from $\mathbf{X}_C$ and the decoder branch do not have trainable parameters. \vspace{2pt}

\noindent \textbf{Fine-tuning.} After the pre-training step, we turn to the fine-tuning phase, where the logistic regression classifier is incorporated into the pipeline and trained along with the encoder (cf.\ the lower branch in \autoref{fig:encoder-decoder}). In this step, the model is trained during \(K\) epochs using the classification loss function $\mathcal{L}_\mathrm{CE}$ in \eqref{eq:l_ce}, omitting the reconstruction loss $\mathcal{L}_{\mathrm{MSE}}$. During the first \(M < K\) epochs, only the classifier is trained (the encoder remains frozen). In the subsequent \(K - M\) epochs, the entire network (i.e., the GCN and the classifier) is trained  using a lower learning rate. This step refines the embeddings generated by the encoder so that they are more suitable for the specific classification task.
% \end{enumerate}

\section{Experiments}

\subsection{Implementation details}

For the gender classification task, we tested two architectures: Encoder-only and Encoder-Decoder. The latter is the one depicted in \autoref{fig:encoder-decoder}, whereas the former does not include the decoder branch (thus ignoring the FC). These architectures are evaluated on the classification task, both in a baseline setting (i.e., without a pre-training CL step) and in a supervised CL one. In addition, each framework was trained both with and without data augmentation, resulting in four final configurations:
\begin{itemize}
    \item Baseline setup without any modifications, model and loss as described in Section \ref{sec:ed}.
    \item Baseline setup with data augmentation, in which the model described in Section \ref{sec:ed} is trained on augmented versions of the SC matrix; see Section \ref{sec:da}.
    \item Contrastive learning with data augmentation, where the model is as described in Section \ref{sec:cl}. %where pre-training with data augmentation and fine-tuning steps are implemented.
    \item Contrastive learning without data augmentation, where the model is as described in Section \ref{sec:cl}, but no data augmentation is applied.  
    % in which the embeddings used on Lsup loss are generated based on the original version of the subject.
\end{itemize}

As described in Section \ref{sec:da}, the data augmentation techniques used were attribute masking and edge dropping, where between 0 and 87 nodes were masked and edges were removed with a probability of $p= 0.2$. In the non-CL framework, we randomly sampled one type of data augmentation method in each batch.

We performed a hyperparameter search, resulting in $L=3$ layers and encoder layer widths of $[32, 16, 8]$ for both architectures and frameworks. The learning rate used in the baseline classification was set to $0.001$, the batch size $B=64$, and the trade-off parameter $\lambda=0.4$. For the CL framework we set $\lambda= 0.25$, while the rest of the setup is as follows:
\begin{enumerate}
    \item During pre-training, a batch size of $B=128$, 3000 epochs, a learning rate of $1 \times 10^{-3}$, and $\tau=1$. 
    \item During fine-tuning, the encoder was frozen for the first set of $M=100$ epochs, and the learning rate was set to $1 \times 10^{-3}$. For the additional $K-M=100$ epochs, the complete model was further trained with a learning rate of $1 \times 10^{-4}$. This step is trained with a batch size of $B=16$.
\end{enumerate}

In all cases, the data was split into 80\% for training, 10\% for validation, and 10\% for testing. The reported results are based on the test set metrics. 

The complete code is available at \url{https://github.com/sara-silvaad/Connectome_GCL}.

\subsection{Results}
% {\color{red} A esta torta le falta mucho relleno. Redactar y hacer una ``real discussion''. Por ejemplo, la figura 3 apenas si está mencionada, y se podría hablar de tareas de visualización por ejemplo, o tratar de entender qué características tienen los sujetos más fáciles de clasificar}. \textcolor{blue}{entre results y conclusiones agregamos las ideas que fuimos comentando que faltaban, quizas haya que cambiar el punteo por parrafos y tirar todo para Results; excepto trabajo futuro y alguna linea general que le de forma a las conclusiones} 
% The results are presented in \autoref{tab:encoder}. The key conclusions derived from these results are as follows:
% \begin{itemize}
% \item The Decoder branch significantly enhances performance in most cases. \textcolor{blue}{decir algo de por que: actua como regularizador e incorpora la info de FC (o aca o en las conclusiones)}
% \item Data augmentation plays a crucial role in the contrastive learning framework, yielding notable performance improvements. 
% \item Contrastive learning, combined with data augmentation, achieved the best performance in both scenarios. \autoref{fig:pca} illustrates the evolution of the first two dimensions of the PCA of the learned representations throughout the epochs in the best case: Encoder-Decoder with contrastive learning and data augmentation. 
% \end{itemize}

% The results are presented in \autoref{tab:encoder}. The key conclusions derived from these results are as follows:

% \begin{itemize} \item \textbf{The Decoder branch improves performance:} In most cases, using an encoder-decoder scheme significantly outperforms the encoder-only approach. Notably, this improvement could be justified by the incorporation of the FC matrix, which provides richer information, and by the fact that the decoder acts as a form of ``regularizer'' for the latent representation used for the classification task.

% \item \textbf{Data augmentation plays a crucial role in the contrastive learning framework:} In the baseline setup, the use of data augmentation did not yield a significant performance improvement; however, when applied within the contrastive learning framework, it had a notable impact.

% \item 

% As suggested in~\cite{supervisedCL}, the supervised contrastive learning framework outperforms the baseline. In particular, the inclusion of data augmentation---as highlighted in~\cite{GCLAugmentations}---strengthens the method’s performance. Although it is not entirely clear why the contrastive learning approach achieves such a pronounced benefit over the baseline, one possible explanation resides in the closer alignment between the augmented versions of the same subject, improving representation capacity and the robustness of the model. This observation might also elucidate the significance of data augmentation, since the method explicitly depends on the augmented versions of the same subject to strengthen the model.

% \item \textbf{The combination of contrastive learning and data augmentation achieves the best performance:} Under this scheme, the best results were obtained. Furthermore, the model proposed achieves state-of-the-art performance, surpassing~\cite{neurograph}, which to the best of our knowledge is the only work benchmarking the gender classification task using HCP subjects. Moreover, \autoref{fig:pca} illustrates the evolution of the first two dimensions of the PCA of the learned representations throughout the epochs in the best case (Encoder-Decoder with contrastive learning and data augmentation). Notably, after the pre-training stage, a clear separation between embeddings of different classes can already be observed.
%\end{itemize}

Results are displayed in \autoref{tab:encoder}. The first key observation is that the decoder branch improves performance. Specifically, using an Encoder-Decoder scheme outperforms the encoder-only approach in most cases. This improvement could be justified by the incorporation of the FC matrix, which provides richer information, and by the fact that the decoder acts as a form of ``regularizer” for the latent representation used for the classification task.

\begin{table}
\caption{Performance of the Encoder and Encoder-Decoder architectures under different frameworks: Baseline classification and contrastive learning (CL), both trained with and without data augmentation. The Decoder branch is beneficial in most cases. Data augmentation proves crucial within the CL framework, achieving the best performance overall. }
\label{tab:encoder}
\begin{center}
\renewcommand{\arraystretch}{1.5} % Aumenta el espacio vertical entre las filas
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{\multirow{2}{*}{Framework}} & \textbf{\multirow{2}{*}{Data Augmentation}} & \multicolumn{2}{c|}{\textbf{Architecture}} \\ \cline{3-4} 
                           &                                    & \textbf{Encoder} & \textbf{Encoder-Decoder} \\ \hline
Baseline class.                &  \xmark
                                  & 0.88                      & 0.90 \\ \hline
Baseline class.                &  \checkmark \par
                                  & 0.88                      & 0.90 \\ \hline
CL                       &  \xmark
                                  & 0.86                      & 0.86      \\ \hline
CL                        &  \checkmark \par
                                  & 0.93                      & 0.94 \\ \hline
\end{tabular}
\end{center}
\end{table}

Moreover, data augmentation plays a crucial role in the CL framework, and when applied within this context, it yields a notable impact compared to its marginal effect in the baseline setup. As suggested in~\cite{supervisedCL}, the supervised CL framework outperforms the baseline, and the inclusion of data augmentation---as highlighted in~\cite{GCLAugmentations}---strengthens the method’s performance. Although it is not entirely clear why the CL approach achieves such a pronounced benefit over the baseline, one possible explanation resides in the closer alignment between the augmented versions of the same subject, improving representation capacity and the robustness of the model. This observation might also elucidate the significance of data augmentation, since the method explictly relies on augmented versions of the same subject to strengthen the model. 

In any case, it is important to highlight that the combination of CL and data augmentation achieves the best performance: the best results were obtained using this scheme, surpassing~\cite{neurograph}, which, to the best of our knowledge, is the only work benchmarking the gender classification task using HCP subjects. Furthermore, \autoref{fig:pca} illustrates the evolution of the first two PCA dimensions of the learned representations throughout the epochs, for the most performant approach (Encoder-Decoder with CL and data augmentation). Notably, after the pre-training stage, a clear separation between embeddings of different classes can already be observed.\vspace{2pt}



% \begin{table}
% \caption{.}
% \label{tab:encoder}
% \begin{center}
% \renewcommand{\arraystretch}{1.5}
% \begin{tabular}{|l|c|c|}
% \hline
% \textbf{Framework} & \textbf{Encoder} & \textbf{Encoder-Decoder} \\ \hline
% Baseline                & 0.77            & 0.78             \\ \hline
% CL                      & 0.83            & 0.84             \\ \hline
% Fully Connected SC      & \multicolumn{2}{c|}{0.79}          \\ \hline
% Fully Connected SC+FC   & \multicolumn{2}{c|}{0.80}          \\ \hline
% \end{tabular}
% \end{center}
% \end{table}

% \begin{table}[]
%     \centering
%     \begin{tabular}{|c|c|}
%     \hline
%     Fully Connected SC   &  0.90\\
%     \hline
%     Fully Connected SC+FC  & 0.92\\
%     \hline
%     \end{tabular}
%     \caption{Caption}
%     \label{tab:nn}
% \end{table}



% \begin{table}
% \caption{10\%}
% \label{tab:encoder}
% \begin{center}
% \renewcommand{\arraystretch}{1.5}
% \begin{tabular}{|l|c|c|}
% \hline
% \textbf{Framework} & \textbf{Encoder} & \textbf{Encoder-Decoder} \\ \hline
% Baseline                & 0.76            & 0.77             \\ \hline
% Baseline + DA                      & 0.77            & 0.76             \\ \hline
% CL                      & 0.78            & 0.79             \\ \hline
% Fully Connected SC      & \multicolumn{2}{c|}{0.74}          \\ \hline
% Fully Connected SC+FC   & \multicolumn{2}{c|}{0.77}          \\ \hline
% \end{tabular}
% \end{center}
% \end{table}

% \begin{table}
% \caption{30\%}
% \label{tab:encoder}
% \begin{center}
% \renewcommand{\arraystretch}{1.5}
% \begin{tabular}{|l|c|c|}
% \hline
% \textbf{Framework} & \textbf{Encoder} & \textbf{Encoder-Decoder} \\ \hline
% Baseline                & 0.83            & 0.79             \\ \hline
% Baseline + DA                      & 0.84            & 0.83             \\ \hline
% CL                      & 0.83            & 0.85            \\ \hline
% Fully Connected SC      & \multicolumn{2}{c|}{0.84}          \\ \hline
% Fully Connected SC+FC   & \multicolumn{2}{c|}{0.84}          \\ \hline
% \end{tabular}
% \end{center}
% \end{table}

% \begin{table}
% \caption{50\%}
% \label{tab:encoder}
% \begin{center}
% \renewcommand{\arraystretch}{1.5}
% \begin{tabular}{|l|c|c|}
% \hline
% \textbf{Framework} & \textbf{Encoder} & \textbf{Encoder-Decoder} \\ \hline
% Baseline                & 0.84            & 0.84             \\ \hline
% Baseline + DA                      & 0.82            & 0.84             \\ \hline
% CL                      & 0.90            & 0.92             \\ \hline
% Fully Connected SC      & \multicolumn{2}{c|}{0.87}          \\ \hline
% Fully Connected SC+FC   & \multicolumn{2}{c|}{0.89}          \\ \hline
% \end{tabular}
% \end{center}
% \end{table}

% \begin{table}
% \caption{70\%}
% \label{tab:encoder}
% \begin{center}
% \renewcommand{\arraystretch}{1.5}
% \begin{tabular}{|l|c|c|}
% \hline
% \textbf{Framework} & \textbf{Encoder} & \textbf{Encoder-Decoder} \\ \hline
% Baseline                & 0.84            & 0.89             \\ \hline
% Baseline + DA                      & 0.            & 0.             \\ \hline
% CL                      & 0.92            & 0.93             \\ \hline
% Fully Connected SC      & \multicolumn{2}{c|}{0.89}          \\ \hline
% Fully Connected SC+FC   & \multicolumn{2}{c|}{0.90}          \\ \hline
% \end{tabular}
% \end{center}
% \end{table}

% \begin{table}
% \caption{80\%}
% \label{tab:encoder}
% \begin{center}
% \renewcommand{\arraystretch}{1.5}
% \begin{tabular}{|l|c|c|}
% \hline
% \textbf{Framework} & \textbf{Encoder} & \textbf{Encoder-Decoder} \\ \hline
% Baseline                & 0.85            & 0.87             \\ \hline
% Baseline + DA           & 0.            & 0.             \\ \hline
% CL                      & 0.            & 0.             \\ \hline
% Fully Connected SC      & \multicolumn{2}{c|}{0.91}          \\ \hline
% Fully Connected SC+FC   & \multicolumn{2}{c|}{0.91}          \\ \hline
% \end{tabular}
% \end{center}
% \end{table}





\begin{figure}
% \captionsetup{justification=raggedright, singlelinecheck=false}
    \centering
    % \begin{minipage}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=0.99\linewidth]{figures/pca_ejes_grandes.png}
    % \end{minipage}
    % \begin{minipage}[b]{0.49\textwidth}
        % \centering
        % \includegraphics[width=0.48\linewidth]{figures/500.png}
    % \end{minipage}
    \caption{Evolution of the learned embeddings in the validation set for the contrastive learning setup and the Encoder-Decoder architecture, shown after the pre-training step. The first two PCA principal components are visualized. At epoch 500, in the first principal component, a clear separation between embeddings of different genders can be observed. During the fine-tuning step, these learned embeddings are utilized to classify with a logistic regression classifier.%{\color{red} Esto es sólo usando el fine-tuning? Si es así, comentarlo. \color{blue}{es after pre-training , before fine-tuning , creo que ahi quedo mejor}} %{\color{red} Creo que queda mejor ocupando una sola fila y más chiquito. Si se pudiera agrandar la letra (y dejar sólo el eje y) sería genial. }
    % {\color{green} Así? }
    }
    \label{fig:pca}
\end{figure}

\noindent \textbf{Robustness.} To analyze the impact of the sample size on the performance of the model, an evaluation was carried out using different proportions of the training set. The test set was kept invariant, while the training set was reduced to 10\%, 30\%, 50\% and 70\% of its original size to assess the robustness of the different frameworks. The batch size in the baseline setting was set to $B=8, 16, 32, 64$ respectively, while in CL: $B=16, 32, 64, 128$ for the pre-training step, and $B=4, 8, 16, 16$ for the fine-tuning. The rest of the hyperparameters kept the same values from the previous test case.

\autoref{fig:prop} shows the training results when using different proportions of the training set, comparing the performance between the different frameworks under varying data quantities. In all cases, across both architectures and all proportions of the training set, we find that the CL framework consistently outperforms all other frameworks, demonstrating its robustness even when the amount of available training data is limited. Interestingly, the CL framework starts to show strong performance with fewer subjects, attaining near-optimal accuracies with as few as half of the original data. On the other hand, competing alternatives require (almost) the full training set to reach their peak performance.


\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figures/training_encoder_encoder_decoder_DA.png}
    \caption{Comparison of contrastive learning (CL) and baseline classification (Baseline), for encoder and Encoder-Decoder architectures with or without data augmentation (DA), under varying training set proportions. The CL approach consistently outperforms the others and reaches near-optimal results with as little as half of the data, whereas the other frameworks require the full dataset to achieve near-peak performance.}
    \label{fig:prop}
\end{figure}


\section{Conclusion}

% As suggested in~\cite{supervisedCL}, supervised contrastive learning framework outperforms the vanilla approach. In particular, the inclusion of \emph{data augmentation}—as highlighted in~\cite{GCLAugmentations}— strengthens the method’s performance. Although it is not entirely clear why the contrastive learning approach achieves such a pronounced benefit over the vanilla approach, one possible explanation resides in the closer alignment between the augmented versions of the same subject, improving representation capacity and the robustness of the model.  

% Despite these findings, there remains a need to explore other data augmentation strategies, especially domain-specific, for instance, considering brain regions when dropping edges or masking attributes. Furthermore, we have shown that combining contrastive learning with the \emph{Encoder-Decoder} model proposed in~\cite{li2022learning} achieves state-of-the-art performance, surpassing~\cite{neurograph}, which to the best of our knowledge is the only work benchmarking the gender classification task using HCP subjects.

% As suggested in~\cite{supervisedCL}, the supervised contrastive learning framework outperforms the vanilla approach. In particular, the inclusion of \emph{data augmentation}—as highlighted in~\cite{GCLAugmentations}—strengthens the method’s performance. Although it is not entirely clear why the contrastive learning approach achieves such a pronounced benefit over the vanilla approach, one possible explanation resides in the closer alignment between the augmented versions of the same subject, improving representation capacity and the robustness of the model. This observation might also elucidate the significance of data augmentation, since the method explicitly depends on the augmented versions of the same subject to strengthen the model.  Despite these findings, there remains a need to explore other data augmentation strategies, especially domain-specific ones, for instance, considering brain regions when dropping edges or masking attributes. Moreover, the clear separation seen in \autoref{fig:pca} after the pre-training step suggests the possibility of conducting a more thorough analysis of the characteristics that distinguish subjects that are easier or harder to classify based on their distance in the embedded space, which may include demographic characteristics (e.g., age) or topological properties of the structural and functional matrices of the respective subjects.

We have presented a CL methodology that not only obtains state-of-the-art results in subject classification, but also does so with markedly less data than competing alternatives.
%
Despite these promising preliminary findings, there remains a need to explore other data augmentation strategies, especially domain-specific ones (for instance, considering brain ROIs when dropping edges or masking attributes). It is important to acknowledge that current data augmentation strategies (i.e., attribute masking and edge dropping) can be detrimental, potentially removing critical information from the connectomes. Therefore, developing augmentation techniques that preserve vital brain connectivity patterns while introducing meaningful variability is a promising direction we will explore in the near future. 

Furthermore, as shown in \autoref{fig:pca}, the proposed methodology learns subject-level representations that are clearly separated after the pre-training step (when the subjects belong to different classes, naturally). 
This motivates conducting a more thorough analysis of the characteristics that distinguish subjects who are easier or harder to classify based on their distance in the embedding space. These characteristics may include demographic factors (e.g., age) or topological properties of the respective subjects' SC and FC matrices.

Overall, combining CL, data augmentation, and the Encoder-Decoder model is a promising approach to achieve robust and interpretable representations, especially for network neuroscience tasks.

\addtolength{\textheight}{-6cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \section*{APPENDIX}

% Appendixes should appear before the acknowledgment.

% \section*{ACKNOWLEDGMENT}

% The preferred spelling of the word ÒacknowledgmentÓ in America is without an ÒeÓ after the ÒgÓ. Avoid the stilted expression, ÒOne of us (R. B. G.) thanks . . .Ó  Instead, try ÒR. B. G. thanksÓ. Put sponsor acknowledgments in the unnumbered footnote on the first page.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{thebibliography}{99}

\printbibliography%[heading=none]


% \bibitem{c8} Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, ÒElectron spectroscopy studies on magneto-optical media and plastic substrate interfaces(Translation Journals style),Ó IEEE Transl. J. Magn.Jpn., vol. 2, Aug. 1987, pp. 740Ð741 [Dig. 9th Annu. Conf. Magnetics Japan, 1982, p. 301].
% \bibitem{c9} M. Young, The Techincal Writers Handbook.  Mill Valley, CA: University Science, 1989.
% \bibitem{c10} J. U. Duncombe, ÒInfrared navigationÑPart I: An assessment of feasibility (Periodical style),Ó IEEE Trans. Electron Devices, vol. ED-11, pp. 34Ð39, Jan. 1959.
% \bibitem{c11} S. Chen, B. Mulgrew, and P. M. Grant, ÒA clustering technique for digital communications channel equalization using radial basis function networks,Ó IEEE Trans. Neural Networks, vol. 4, pp. 570Ð578, July 1993.
% \bibitem{c12} R. W. Lucky, ÒAutomatic equalization for digital communication,Ó Bell Syst. Tech. J., vol. 44, no. 4, pp. 547Ð588, Apr. 1965.
% \bibitem{c13} S. P. Bingulac, ÒOn the compatibility of adaptive controllers (Published Conference Proceedings style),Ó in Proc. 4th Annu. Allerton Conf. Circuits and Systems Theory, New York, 1994, pp. 8Ð16.
% \bibitem{c14} G. R. Faulhaber, ÒDesign of service systems with priority reservation,Ó in Conf. Rec. 1995 IEEE Int. Conf. Communications, pp. 3Ð8.
% \bibitem{c15} W. D. Doyle, ÒMagnetization reversal in films with biaxial anisotropy,Ó in 1987 Proc. INTERMAG Conf., pp. 2.2-1Ð2.2-6.
% \bibitem{c16} G. W. Juette and L. E. Zeffanella, ÒRadio noise currents n short sections on bundle conductors (Presented Conference Paper style),Ó presented at the IEEE Summer power Meeting, Dallas, TX, June 22Ð27, 1990, Paper 90 SM 690-0 PWRS.
% \bibitem{c17} J. G. Kreifeldt, ÒAn analysis of surface-detected EMG as an amplitude-modulated noise,Ó presented at the 1989 Int. Conf. Medicine and Biological Engineering, Chicago, IL.
% \bibitem{c18} J. Williams, ÒNarrow-band analyzer (Thesis or Dissertation style),Ó Ph.D. dissertation, Dept. Elect. Eng., Harvard Univ., Cambridge, MA, 1993. 
% \bibitem{c19} N. Kawasaki, ÒParametric study of thermal and chemical nonequilibrium nozzle flow,Ó M.S. thesis, Dept. Electron. Eng., Osaka Univ., Osaka, Japan, 1993.
% \bibitem{c20} J. P. Wilkinson, ÒNonlinear resonant circuit devices (Patent style),Ó U.S. Patent 3 624 12, July 16, 1990. 


% \end{thebibliography}




\end{document}
