

\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{multirow}
\usepackage{amssymb}% http://ctan.org/pkg/amssymb
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\addto\extrasenglish{%
  \renewcommand{\figureautorefname}{figure}
  \renewcommand{\sectionautorefname}{section}
  \renewcommand{\subsectionautorefname}{section}
  \renewcommand{\subsubsectionautorefname}{section}
  \renewcommand{\chapterautorefname}{chapter}
  \renewcommand{\tableautorefname}{table}
  \renewcommand{\appendixautorefname}{appendix}
}

\usepackage[style=numeric, sorting=none]{biblatex}
\addbibresource{referencias.bib}

\def\etal{\textit{et al.}}


\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Graph Constrastive Learning for Connectome Classification
}

\author{\IEEEauthorblockN{
Sara Silva\IEEEauthorrefmark{1},
Mart\'in Schmidt\IEEEauthorrefmark{1},
Gonzalo Mateos\IEEEauthorrefmark{2}, 
Federico Larroca\IEEEauthorrefmark{1}
and
Pablo Mus\'e\IEEEauthorrefmark{1}}
\IEEEauthorblockA{\IEEEauthorrefmark{1}Facultad de Ingenier\'ia, Universidad de la Rep\'ublica, Uruguay
}
\IEEEauthorblockA{\IEEEauthorrefmark{2}Dept. of Electrical and Computer Engineering, University of Rochester, Rochester, NY, USA.\\
Emails: \{ssilva,mschmidt,flarroca,pmuse\}@fing.edu.uy and gmateosb@ur.rochester.edu}
}

% \author{\IEEEauthorblockN{Sara Silva}
% \IEEEauthorblockA{\textit{Facultad de Ingeier\'ia} \\
% \textit{Universidad de la Rep\'ublica}\\
% Montevideo, Uruguay \\
% ssilva@fing.edu.uy}
% \and
% \IEEEauthorblockN{Martín Schmidt}
% \IEEEauthorblockA{\textit{Facultad de Ingeier\'ia} \\
% \textit{Universidad de la Rep\'ublica}\\
% Montevideo, Uruguay \\
% mschmidt@fing.edu.uy}
% \and
% \IEEEauthorblockN{Gonzalo Mateos}
% \IEEEauthorblockA{\textit{Electrical and Computer Engineering} \\
% \textit{University of Rochester}\\
% Rochester, NY, USA \\
% gmateosb@ur.rochester.edu}
% \and
% \IEEEauthorblockN{Federico Larroca}
% \IEEEauthorblockA{\textit{Facultad de Ingeier\'ia} \\
% \textit{Universidad de la Rep\'ublica}\\
% Montevideo, Uruguay \\
% flarroca@fing.edu.uy}
% \and
% \IEEEauthorblockN{Pablo Musé}
% \IEEEauthorblockA{\textit{Facultad de Ingeier\'ia} \\
% \textit{Universidad de la Rep\'ublica}\\
% Montevideo, Uruguay \\
% pmuse@fing.edu.uy}
% }

\maketitle

\begin{abstract}


The brain has been the subject of extensive research due to its critical role in cognitive and emotional processes, as well as its contribution to understanding human behavior. Much of this research focuses on the connections between different regions of interest (ROIs), encompassing both anatomical (structural) connections and regions exhibiting similar activity patterns (functional). With advancements in non-invasive techniques for measuring brain activity and structural connectivity, such as magnetic resonance imaging, the study of brain networks has gained prominence, leading to the development of numerous analytical methods. In particular, these connections between ROIs are represented as graphs in the literature, commonly referred to as connectomes. This study emphasizes the problem of gender classification using connectomes. State-of-the-art results were achieved, with an accuracy of $94\%$, leveraging contrastive learning techniques and classical data augmentation methods. Additionally, the relationship between the functional and structural graphs was examined, utilizing both an encoder architecture and an encoder-decoder one. The latter with a dual loss function: reconstruction of the functional graph from the structural graph and classification. This aims to highlight each connectivity's relative importance in classification tasks.


\end{abstract}

\begin{IEEEkeywords}

Connectomes, Graph Neural Networks, Encoder-Decoder, Contrastive Learning, ... 
\end{IEEEkeywords}

\section{Introduction}

The study of human brain connectivity, both structural and functional, is essential due to the brain's pivotal role in regulating behavior and cognitive processes. Advances in neuroimaging techniques, such as functional magnetic resonance imaging (fMRI) and positron emission tomography (PET), enable real-time visualization of brain activity, offering valuable insights into functional connectivity. Additionally, structural mapping through techniques like diffusion magnetic resonance imaging (dMRI) facilitates the construction of macroscopic maps of the brain's physical connections. These tools have been instrumental in diagnosing and treating neurological and psychiatric conditions, including epilepsy, autism, and schizophrenia \cite{esquizofrenia, epilepsia, autismo}.

This work focuses on gender classification using functional and structural connectomes (referred to as FC and SC respectively) built based on MRI as a pathway to advancing our understanding of brain networks and developing tools with broader applications in neuroscience. For this task, we employ Graph Neural Networks (GNNs), which excel in processing data structured as graphs. Connectomes are naturally modeled as graphs, capturing the intricate neural connections and their complex relationships. By performing convolutions directly on graph structures, GNNs are particularly suited to analyzing brain connectivity. Through graph-based modeling, this work contributes to state-of-the-art methods in connectome analysis while exploring the broader applicability of GNNs in neuroscience.

In this paper, we explore the implementation of contrastive learning, a popular technique in machine learning designed to learn useful representations by enforcing similarity between related data points while distinguishing them from unrelated ones. This approach has seen significant success in fields like computer vision, exemplified by the well-known SimCLR framework \cite{SimCLR}, but its application to graph-structured data remains underexplored in the literature. The intuition behind applying this technique to our problem is inspired by Li et al. \cite{li2022learning}, who initially implemented the GCN architecture used in this study for connectome classification and later proposed a framework with concepts akin to contrastive learning. Building on this foundation, we aim to structure the latent space such that learned representations capture meaningful relationships within the data, ultimately enhancing classification performance.

To assess the effectiveness of this approach, we compare it against a more conventional graph classification framework, where a Graph Convolutional Network (GCN) is trained directly for the classification task without the additional step of contrastive learning. This comparison will provide insights into the potential advantages of contrastive learning in graph-based modeling and its impact on performance in functional and structural connectome classification. By focusing on this comparison, our work contributes to the growing exploration of advanced representation learning techniques in neuroscience.

The dataset used for this research is part of the Human Connectome Project (HCP) \cite{HCP, HCP_DC}, a large-scale initiative aimed at mapping the human connectome with advanced MRI techniques. Specifically, we utilize the HCP Young Adults 1200 release \cite{HCP_YA, HCP_YA_DR}, which includes data from 1200 healthy adults. This release provides comprehensive structural (dMRI) and functional (fMRI) connectivity matrices, alongside demographic and behavioral data. For this study, we derived functional and structural connectivity matrices using the Desikan-Killiany atlas \cite{DESIKAN2006968}. After preprocessing, the dataset includes 1048 subjects with complete data, as not all participants underwent all imaging modalities. This rich dataset enables a robust exploration of brain connectivity and its relationship to individual characteristics.

The main contributions of this work are as follows:  

\begin{enumerate}
    \item \textbf{Evaluation of Contrastive Methods}: We assess the impact of applying contrastive learning techniques to improve the quality of learned representations for the classification of connectomes.  
    \item \textbf{Effect of Data Augmentation}: We analyze the role of data augmentation strategies within the contrastive learning framework and their influence on model performance.  
    \item \textbf{Integration with Encoder-Decoder Architectures}: We explore the combination of contrastive learning with the encoder-decoder approach for SC and FC proposed by Li et al. \cite{li2022learning}, leveraging their method to enhance representation learning.  
    \item \textbf{State-of-the-Art Classification}: We demonstrate competitive or superior classification performance compared to state-of-the-art methods, benchmarking against a key reference study \cite{neurograph}.  
\end{enumerate}

% \section{Previous work and proposed method}

% In this section, we review the background on supervised contrastive learning see also [16], [28] for further details. ... y data augmentation/ Then we formally
%  introduce the proposed models: primero el encoder y luego el encoder-decoder.

% In this section, we review the background on supervised contrastive learning 

\section{Method}

\subsection{Encoder-Decoder}

The Encoder-Decoder architecture used in this work is based on the framework proposed by Li \etal~\cite{li2022learning}, as illustrated in \autoref{fig:encoder-decoder}. This architecture consists of two main components: the top branch performs a regression task to reconstruct the FC matrix from the SC matrix, while the bottom branch predicts the gender of the subject using a graph classification module. Below, are summarize the key components of the architecture:

\begin{enumerate}
    \item \textbf{Inputs:}  
    The model takes as input the structural connectivity matrix \(\mathbf{A} \in [0, 1]^{87 \times 87}\), the functional connectivity matrix \(\mathbf{\Sigma} \in [0, 1]^{87 \times 87}\), and an initial feature matrix \(\mathbf{X}^{(0)} = \mathbf{I}_{87}\) (the identity matrix).

    \item \textbf{GCN Encoder:}  
    The encoder uses a multi-layer Graph Convolutional Network (GCN) to generate low-dimensional node embeddings. At each layer \(l\), the GCN applies a graph convolution followed by a ReLU non-linearity:  
    \[
    \mathbf{X}^{(l+1)} = \text{ReLU}(\tilde{\mathbf{A}}\mathbf{X}^{(l)}\mathbf{\Theta}^{(l)}),
    \]
    where \(\tilde{\mathbf{A}}\) is the normalized adjacency matrix, as defined in Thomas N. Kipf \etal~\cite{primer_GCN}, \(\mathbf{X}^{(l)} \in \mathbb{R}^{N \times d_{l-1}}\) is the feature matrix at layer \(l\), and \(\mathbf{\Theta}^{(l)} \in \mathbb{R}^{d_{l-1} \times d_l}\) are the trainable weights. The final output is a concatenated embedding \(\mathbf{X}_C \in \mathbb{R}^{N \times \sum_l d_l}\), combining intermediate representations from all layers.

    \item \textbf{Decoder:}  
    The decoder reconstructs the FC matrix from \(\mathbf{X}_C\) as \(\hat{\mathbf{\small \sum}} = \text{ReLU}(\mathbf{X}_C \mathbf{X}_C^T)\). This step ensures that \(\hat{\mathbf{\Sigma}} \in \mathbb{R}^{87 \times 87}\) has positive entries, aligning with the FC reconstruction objective. The reconstruction error is measured using the Mean Squared Error (MSE) between \(\hat{\mathbf{\small \sum}}\) and the ground truth \(\mathbf{\small \sum}\).

    \item \textbf{Pooling and Classification:}  
    For the classification branch, a pooling layer aggregates \(\mathbf{X}_C\) across nodes by averaging, resulting in a graph-level embedding \(\mathbf{z}\in \mathbb{R}^{\sum_l d_l}\). This embedding is then passed through a logistic regression classifier to predict the gender of the subject. The pooling method used is the mean.

    \item \textbf{Loss Function:}  
    The model is trained using a combination of reconstruction and classification loss:  
    \[
    \mathcal{L} = \mathcal{L}_{MSE}\left(\hat{\mathbf{\Sigma}}, \mathbf{\Sigma}\right) + \lambda \times \mathcal{L}_{CLA}(\hat{y}, y),
    \]
    where \(\mathbf{\Sigma}\) is the ground truth FC matrix, \(y\) is the ground truth gender label, and \(\hat{\mathbf{\small \sum}}\) and \(\hat{y}\) are their respective predictions. The hyperparameter \(\lambda\) balances the importance of the reconstruction and classification objectives.
\end{enumerate}

This dual-task architecture enables the model to learn robust graph representations that are effective for reconstructing FC matrices and predicting gender.

\begin{figure*}
\centering
\captionsetup{justification=raggedright, singlelinecheck=false}
\includegraphics[width=\textwidth]{figures/encoder_decoder.pdf}
\caption{
The encoder-decoder architecture used in this work processes structural connectivity (SC) networks \(\mathbf{A}\) as input, along with nodal attributes \(\mathbf{X}^{(0)} = \mathbf{I}_{87}\). The GCN encoder performs graph convolution and information propagation through multiple layers, producing low-dimensional node embeddings \(\mathbf{X}^{(l)}\) at layer $l$. Combining intermediate representations from all layers, they are all concatenated into one embedding \(\mathbf{X}_C\). The decoder uses an outer-product operation to predict the reconstructed functional connectivity (FC) matrix \(\hat{\mathbf{\Sigma}}\), effectively modeling the SC-to-FC mapping. Graph-level representations \(\mathbf{z}\) are obtained via a pooling operation applied to \(\mathbf{X}_C\), summarizing the node embeddings into a single vector, which a logistic regression classifier predicts the binary label \(\hat{y}\). The model is referred to as the ``encoder" when the architecture excludes the reconstruction branch. Additionally, within the contrastive learning framework, the logistic regression classifier is omitted, and the graph-level representation \(\mathbf{z}\) is trained directly to learn meaningful embeddings. 
}
\label{fig:encoder-decoder}
\end{figure*}

\subsection{Data Augmentation for Graphs}

Data augmentation is a widely used technique in deep learning to address the challenge of limited data availability and improve a model’s generalization performance. In this use case, augmented versions of the data are incorporated into the contrastive learning framework to encourage the model to produce meaningful representations, even when the input data is perturbed. These augmentations aim to preserve the overall structure of the data while introducing variations. Only augmentation methods that have been experimentally tested will be described. For more details, refer to \cite{DAGraphs} \cite{GCLAugmentations}.

\begin{itemize}
    \item Attribute masking: Certain node attributes are masked by setting them to zero, challenging the model to infer meaningful representations using incomplete attribute information. 
    \item Edge Dropping: Edges are removed with a probability \(p\), requiring the model to remain robust to missing links and generate consistent representations despite an incomplete graph structure.
\end{itemize}

\subsection{Supervised Contrastive Learning}

The goal of contrastive learning is to train algorithms to learn meaningful representations that are interpretable or useful for other tasks. The core principle is to ensure that similar data points are mapped to similar representations. Supervised contrastive learning, introduced by Khosla \etal ~\cite{supervisedCL}, extends this approach to a fully supervised framework. In this setting, not only are augmented versions of the same data point pulled closer together and distinct data points pushed apart, but this process is also guided by class labels: data points of the same class are attracted to each other, while those from different classes are repelled.

Given a batch of \(N\) data points and their corresponding labels \(\{A_k, y_k\}_{k=1,\ldots,N}\), the training batch consists of \(2N\) pairs \(\{A'_k, y'_k\}_{k=1,\ldots,2N}\). Here, \(A'_{2k-1}\) and \(A'_{2k}\) are two augmented versions of the original sample \(A_k\), and \(y'_{2k-1} = y'_{2k} = y_k\).

The training process consists of two steps: Pre-training and Fine-tuning.

\begin{enumerate}
    \item \textbf{Pre-training:} In this step, the objective is to minimize the following cost function:
    \[
    \mathcal{L}^{\text{sup}} = \sum_{i \in I} \frac{-1}{|P(i)|} \sum_{p \in P(i)} \log \frac{\exp\left(\frac{z_i \cdot z_p}{\tau}\right)}{\sum_{q \in Q(i)} \exp\left(\frac{z_i \cdot z_a}{\tau}\right)},
    \]
    where:
    \begin{itemize}
        \item \(z_i\) is the encoded version of element \(A'_i\).
        \item \(I = \{1, \ldots, 2N\}\) represents the set of indices in the augmented batch.
        \item \(Q(i) = I \setminus \{i\}\) is the set of indices excluding \(i\).
        \item \(P(i) = \{p \in Q(i) : y'_p = y'_i\}\) is the set of positive indices distinct from \(i\) that share the same label.
        \item \(\tau \in (0,1]\) is a temperature hyperparameter for the model.
    \end{itemize}

    \item \textbf{Fine-tuning:} After the pre-training step, a single-layer classifier is trained on top of the encoder to evaluate if the latent representation generated by the encoder is suitable for the specific classification task. The model is trained for \(K\) epochs. During the first \(M < K\) epochs, only the classifier is trained (the encoder remains frozen). In the subsequent \(K - M\) epochs, the entire network is trained using a lower learning rate.
\end{enumerate}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figures/data_augmentation.pdf}
    \caption{A schematic view of the constrastive learning approach. For each input data $\{\mathbf{A}_k,y_k\}$ we generate two augmented versions $\{\mathbf{A}'_{2k},y_k\}$ and $\{\mathbf{A}'_{2k+1},y_k\}$ using edge dropping and attribute masking as data augmentation techniques. The corresponding graph embeddings $\mathbf{z}_i$ are produced as in Fig.\ \ref{fig:encoder-decoder}. Whereas unsupervised constrastive learning only pulls together the representations stemming from the same original graph (green arrow), its supervised counterpart pulls together representations with the same label and pushes apart those with a different label (red arrow).}
    \label{fig:contrastive_learning}
\end{figure}

\section{Experiments}

\subsection{Implementation}

For the gender classification task, we tested two model architectures—Encoder and Encoder-Decoder—under two different frameworks: vanilla classification (i.e., no pretraining contrastive learning step) and supervised contrastive learning. In addition, each framework was trained both with and without data augmentation, resulting in four final configurations.
\begin{itemize}
    \item Vanilla set-up without any modifications.
    \item Vanilla set-up with data augmentation.
    \item Contrastive learning without data augmentation.
    \item Contrastive learning with data augmentation.
\end{itemize}

The data augmentation techniques used were attribute masking and edge dropping, as described above. In the non-contrastive learning framework we randomly sampled one type of data augmentation method in each batch.

We performed a light hyperparameter search. Consequently, the sizes of the encoder layers, for both architectures and frameworks, were [32, 16, 8]. The learning rate used in the vanilla classification is set to 0.001, the batch size 64, and the balancing parameter $\lambda$ was set to 0.4. For the contrastive learning framework, $\lambda$ was set to 0.25, while the rest of the set-up is as follows:

\begin{enumerate}
    \item During pre-training, a batch size of 128, a learning rate of $1 \times 10^{-3}$ and $\tau$ was set to 1. 
    \item During fine-tuning, the Encoder was frozen for the first set of epochs, and the learning rate was set to $1 \times 10^{-3}$. For the second set, the complete model was further trained with a learning rate of $1 \times 10^{-4}$.
\end{enumerate}

In all cases, the data was split into 80\% for training, 10\% for validation, and 10\% for testing. The reported results are based on the test set metrics.

\subsection{Results}

The results are presented in \autoref{tab:encoder}. The key conclusions derived from these results are as follows:
\begin{itemize}
\item The Decoder branch significantly enhances performance in most cases. 
\item Data augmentation plays a crucial role in the contrastive learning framework, yielding notable performance improvements. 
\item Contrastive learning, combined with data augmentation, achieved the best performance in both scenarios. \autoref{fig:pca} illustrates the evolution of the first two dimensions of the PCA of the learned representations throughout the epochs in the best case: Encoder-Decoder with contrastive learning and data augmentation. 
\end{itemize}

% \begin{table}
% \centering
% \renewcommand{\arraystretch}{1.5} % Aumenta el espacio vertical entre las filas
% \begin{tabular}{|l|l|l|}
% \hline
% %\multicolumn{2}{|c|}{\textbf{\textit{Encoder}}} \\ \hline
% & \textbf{\textit{Encoder}} & \textbf{\textit{Encoder-Decoder}} \\ \hline
% Base model - no DA & 0.88 & 0.90\\ \hline
% Base model - DA & 0.88 & 0.90\\ \hline
% CL - no DA & 0.86 &\\ \hline
% CL - DA & 0.93 & 0.94\\ \hline
% \end{tabular}
% \caption{Performance of the Encoder and Encoder-Decoder architecture in different (): base model, with and without data augmentation, and the same model in the contrastive learning framework with (CL and DA) and without (CL - no DA) data augmentation.}
% \label{tab:encoder}
% \end{table}

% \begin{table}
% \centering
% \renewcommand{\arraystretch}{1.5} % Aumenta el espacio vertical entre las filas
% \begin{tabular}{|l|l|l|l|}
% \hline
% %\multicolumn{2}{|c|}{\textbf{\textit{Encoder}}} \\ \hline
% Framework & Data Augmentation & \textbf{\textit{Encoder}} & \textbf{\textit{Encoder-Decoder}} \\ \hline
% Base model & no  & 0.88 & 0.90\\ \hline
% Base model & yes & 0.88 & 0.90\\ \hline
% CL & no  & 0.86 &\\ \hline
% CL & yes & 0.93 & 0.94\\ \hline
% \end{tabular}
% \caption{Performance of the Encoder and Encoder-Decoder architecture in different (): base model, with and without data augmentation, and the same model in the contrastive learning framework with (CL and DA) and without (CL - no DA) data augmentation.}
% \label{tab:encoder}
% \end{table}

\begin{table}
\centering
\renewcommand{\arraystretch}{1.5} % Aumenta el espacio vertical entre las filas
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{\multirow{2}{*}{Framework}} & \textbf{\multirow{2}{*}{Data Augmentation}} & \multicolumn{2}{c|}{\textbf{Architecture}} \\ \cline{3-4} 
                           &                                    & \textbf{\textit{Encoder}} & \textbf{\textit{Encoder-Decoder}} \\ \hline
Vanilla class.                &  \xmark
                                  & 0.88                      & 0.90 \\ \hline
Vanilla class.                &  \checkmark \par
                                  & 0.88                      & 0.90 \\ \hline
CL                       &  \xmark
                                  & 0.86                      & 0.86      \\ \hline
CL                        &  \checkmark \par
                                  & 0.93                      & 0.94 \\ \hline
\end{tabular}
\caption{Performance of the Encoder and Encoder-Decoder architectures under different frameworks: Vanilla classification and the contrastive learning (CL), both trained with and without data augmentation. The Decoder branch significantly improves performance in most cases. Data augmentation proves crucial within the contrastive learning framework. When combined with data augmentation, contrastive learning achieves the highest performance in both scenarios}
\label{tab:encoder}
\end{table}



\begin{figure}
\captionsetup{justification=raggedright, singlelinecheck=false}
    \centering
    \begin{minipage}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/60.png}
    \end{minipage}
    \begin{minipage}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/500.png}
    \end{minipage}
    \caption{Evolution of the learned representations in the validation set for the contrastive learning setup and the Encoder-Decoder architecture. The first two PCA principal components are visualized. In the first principal component at epoch 500, a clear separation between embeddings of different genders can be observed.}
    \label{fig:pca}
\end{figure}

\section{Conclusions}

% Como sugiere \cite{supervisedCL} , este framework muestra mejoras respecto del enfoque vanilla. Especialmente, utilizando data augmentation , como se ve en \cite{GCLAugmentations}. Si bien no es evidente,...

% While it remains unclear why the contrastive learning framework achieves such a significant improvement over the vanilla one, the effects of data augmentation suggest that this improvement arises from aligning augmented versions of the same subject more closely. Queda por explorar otro tipo de data augementation , en particular parece prometedor utilizar data augmentation domain-specific por ejemplo que tenga en cuenta las regiones del cerebro. 

% Por otro lado, se muestra como la combinacion de contrastive learning con el modelo encoder decoder propesta en li et al alcanza performance estado del arte,  benchmarking against neurograph. 


% As suggested in \cite{supervisedCL}, the proposed framework outperforms the vanilla approach, particularly when data augmentation is employed \cite{GCLAugmentations}. Although it remains unclear why the contrastive learning framework achieves such a substantial improvement, one possible explanation is that data augmentation brings the augmented versions of the same subject closer.

% Exploring other types of data augmentation, especially domain-specific methods that consider specific brain regions, remains an important direction for future work. Furthermore, our results show that combining contrastive learning with the encoder-decoder model (as proposed by Li et al.) achieves state-of-the-art performance when benchmarked against Neurograph and other reference methods.

As suggested in Khosla \etal \cite{supervisedCL}, supervised contrastive learning framework outperforms the vanilla approach. In particular, the inclusion of \emph{data augmentation}—as highlighted in Yuning You \etal \cite{GCLAugmentations}— strengthens the method’s performance. Although it is not entirely clear why the contrastive learning approach achieves such a pronounced benefit over the vanilla approach, one possible explanation is that improvement may stem from closer alignment between the augmented versions of the same subject, improving representation capacity and the robustness of the model. 

Despite these findings, there remains a need to explore other data augmentation strategies, especially domain-specific, for instance, considering brain regions when dropping edges or masking attributes. Furthermore, we have shown that combining contrastive learning with the \emph{Encoder-Decoder} model proposed in Yang Li \etal \cite{li2022learning} achieves state-of-the-art performance compared to Said \etal \cite{neurograph}, which, to our knowledge, is the only work benchmarking the gender classification task using HCP subjects.


\printbibliography

\end{document}
