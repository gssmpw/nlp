\section{Main results for local rates}


In this section, we first provide the precise version of \lemmaref{lem:main/asymptotic-newton-properties} in \lemmaref{lem:gradient-decay-of-newton-step,lem:asymptotic-newton-step}, and then prove the main result of the local convergence order. The proofs for technical lemmas are deferred to \Cref{sec:properties-of-newton-step,sec:appendix/local-rate-boosting}.

\begin{assumption}[Positive definiteness]
    \label{assumption:local-strong-convexity}
    There exists $\alpha > 0$ such that $\nabla^2 \varphi(x^*) \succeq \alpha \Id$.
\end{assumption}


Let $C(\alpha, a, b, U)$ be the constant defined in \lemmaref{lem:capped-cg},
$\alpha$ be defined in Assumption~\ref{assumption:local-strong-convexity}, 
and $\gamma, \mu, M_0, \eta$ be the inputs of \Cref{alg:adap-newton-cg},
and $\theta$ be defined in \theoremref{thm:newton-local-rate-boosted}.
We define the following constants which will be subsequently used in \lemmaref{lem:gradient-decay-of-newton-step,lem:asymptotic-newton-step}:
\begin{align*}
    U_M &= \max(M_0, \tilde C_5 \gamma L_H), 
    \delta_0 = \frac{\alpha}{2L_H}, 
    L_g = \| \nabla^2 \varphi(x^*) \| + L_H \delta_0,   \\
    \tilde c &= 
    C\left (\frac{\alpha}{2},
    (1 + 2\theta)^{-1},
    \tau U_\varphi^{-\theta(1 + 2\theta)^{-1}},
    U_M^{\frac{1 - \theta(1 + 2\theta)^{-1}}{2}},
    L_g
    \right ),
    \\
    \delta_1^{\frac{1}{2}} &= \min \Big ( 
        \delta_0^{\frac{1}{2}}, 
        \min(\eta, \tilde c) (U_ML_g)^{-\frac{1}{2}}
    \Big ), \\
    c_1 &= \frac{4}{\alpha} \max \left ( 
        L_H \delta_1^{\frac{1}{2}},
        2(U_M L_g)^{\frac{1}{2}}(1 + L_g) 
        \right ), \\
    \delta_2^{\frac{1}{2}} &= \min\left ( 
        \delta_1^{\frac{1}{2}},
        \frac{1}{2c_1},
        \frac{(1 - 2\mu) \alpha}{
            8L_g c_1\big(c_1 \delta_1^{\frac{1}{2}} + 1 \big) 
            + 32L_H \delta_1^{\frac{1}{2}}
            } 
        \right ), \\
    c_2 &=
    4\alpha^{-2} \max\left( 
        2\alpha^{-1}L_gL_H,
        (2 + \alpha)L_gU_M^{\frac{1}{2}}
     \right), \\
    \delta_3 &= 
    \min\left( \delta_2, 
    c_2^{-2} L_g^{-1} \big ( \delta_2^{\frac{1}{2}} + 1 \big )^{-2},
    \frac{\alpha^2}{4} (L_H + 2U_M^{\frac{1}{2}}L_g^{\frac{1}{2}}(1 + L_g))^{-2}
     \right)
    .
\end{align*}

\begin{lemma}[Newton direction yields superlinear convergence]
    \label{lem:gradient-decay-of-newton-step}
    Let $x, d, M$ and $\omega$ be those in the subroutine \texttt{NewtonStep} of \Cref{alg:adap-newton-cg} with $\text{d\_type} = \texttt{SOL}$.
    Let $x^*$ be such that $\nabla \varphi(x^*) = 0$ and $\nabla^2\varphi(x^*) \succeq \alpha\Id$, 
    then for $x \in B_{\delta_0}(x^*)$, 
    we have the following inequalities 
    \begin{align}
        \label{eqn:distance-decay-of-newton-step}
        \| x^* - (x + d) \|
        &\leq \frac{2}{\alpha}\left( L_H \| x - x^* \|^2 + 2M^{\frac{1}{2}}\omega (1 + L_g) \| x - x^* \| \right)
        ,
        \\
        \label{eqn:gradient-decay-of-newton-step}
        \| \nabla \varphi(x + d) \|
        &\leq \frac{8L_gL_H}{\alpha^3} \| \nabla \varphi(x) \|^2
        + \frac{4L_g(2 + \alpha)}{\alpha^2} M^{\frac{1}{2}} \omega \| \nabla \varphi(x) \|.
    \end{align}
\end{lemma}

The lemma below shows that the Newton direction will be taken when iterates are close enough to the solution.
\begin{lemma}[Newton direction is eventually taken]
    \label{lem:asymptotic-newton-step}
    Let $x^* \in \R^n$ be such that $\nabla \varphi(x^*) = 0$ and Assumption~\ref{assumption:local-strong-convexity} holds. 
    If $\max(\omega_k^{\supsucc}, \omega_k^{\supfallback}) \leq \sqrt{g_k}$, then $\text{d\_type}_k = \texttt{SOL}$ and $m_k = 0$ exists for $x_k \in B_{\delta_2}(x^*)$.
    Moreover, the trial step using $\omega_k^{\supsucc}$ is accepted for $x_k \in B_{\delta_3}(x^*)$.
\end{lemma}

\subsection{Proof of local rates in Theorem~\ref{thm:newton-local-rate-boosted}} \label{sec:appendix/proof-boosted-local-rates-theorem}

\begin{proposition}
    \label{prop:mixed-newton-nonconvex-phase-local-rates}
    Let $\{ x_k \}_{k \ge 0}$ be the points generated by \Cref{alg:adap-newton-cg} with the regularizer choices in \theoremref{thm:newton-local-rate-boosted} and $\theta \geq 0$;
    and $x^*, \{x_{k_j}\}_{j \geq 0}$ be those in \theoremref{thm:appendix/global-newton-complexity} such that $\lim_{j \to \infty} x_{k_j} = x^*$ and $\nabla\varphi(x^*) = 0$ and suppose Assumption~\ref{assumption:local-strong-convexity} holds, i.e., $\nabla^2\varphi(x^*) \succeq \alpha \Id$.

    Then, there exists $j_0$ such that $\epsilon_{j_0} = g_{j_0} < \min(1, (2c_2)^{-2})$ and $x_{j_0} \in B_{\delta_3}(x^*)$, and
    \begin{enumerate}
        \item  $\lim_{k \to \infty} x_k = x^*$.
        \item When $\theta \in (0, 1]$ and $j \geq 1$, we have
        \begin{equation*}
            \| \nabla \varphi(x_{j_0+j+1}) \| \leq 
            (2c_2)^3 \| \nabla \varphi(x_{j_0+j}) \|^{1 + \nu_\infty - (4\theta/9)^k},
        \end{equation*}
        where $\nu_\infty \in \left [\frac{1}{2}, 1\right ]$ is defined in \lemmaref{lem:appendix/superlinear-rate-boosting-generalized} and illustrated in \figureref{fig:local-rate-for-nu1}.
        \item When $\theta > 1$ and $j \geq \log_2\frac{2\theta - 1}{2\theta - 2} + 1$, we have
        \begin{equation*}
            \| \nabla \varphi(x_{j_0+j+1}) \| \leq 
            (2c_2)^{2\theta + 2} \| \nabla \varphi(x_{j_0+j}) \|^{2}.
        \end{equation*}
    \end{enumerate}
\end{proposition}
\begin{proof}
    Since $\lim_{j \to \infty} x_{k_j} = x^*$ and $\nabla\varphi(x^*) = 0$, we know $j_0$ exists.
We define the set
    \begin{equation}
        \cI = 
        \{
            j \in \N : 
    g_j = \epsilon_j
    \text{ and } x_j \in B_{\delta_3}(x^*)
        \}.
    \end{equation}

    By the existence of $j_0$, we know $j_0 \in \cI$. 
    Suppose $k \in \cI$, then we will show that $k + 1 \in \cI$.
    Since the choices of $\omega_{k}^{\supfallback}$ and $\omega_k^{\supsucc}$ in \theoremref{thm:newton-local-rate-boosted} fulfill the condition of \lemmaref{lem:asymptotic-newton-step}, 
    we know the trial step is taken and $x_{{k}+1} = x_{k} + d_{k}$,
    where $d_{k}$ is the direction in \texttt{NewtonStep} with $\omega = \omega_k^{\supsucc}$.

    From \lemmaref{lem:gradient-decay-of-newton-step} and \corollaryref{cor:perturbation-lemma},
    we have $g_{k} \leq L_g \| x_{k} - x^* \| \leq L_g \delta_3$, $\omega_k^{\supsucc} \leq \sqrt{g_k}$ and 
    \begin{align}
    g_{{k}+1} 
    \overset{\eqref{eqn:gradient-decay-of-newton-step}}{\leq} 
    c_2 g_{k}^2 + c_2 \omega^{\supsucc}_{k} g_{k}
    \leq c_2 \big ( L_g \delta_3 + (L_g \delta_3)^{\frac{1}{2}} \big ) g_{k} 
    \leq c_2 \big ( L_g \delta_2^{\frac{1}{2}} + L_g^{\frac{1}{2}} \big )\delta_3^{\frac{1}{2}} g_{k} 
    \leq g_{k}.
    \label{eqn:appendix/proof/basic-gradient-descent-of-newton}
    \end{align}
    Hence, $\epsilon_{{k}+1} = \min(\epsilon_{k}, g_{{k}+1}) = g_{{k}+1}$.
    Moreover, since $M_k \leq U_M$, then
    \begin{align*}
        \|x_{k+1} - x^* \|
        \overset{\eqref{eqn:distance-decay-of-newton-step}}&{\leq}
        \frac{2}{\alpha}\left( L_H \delta_3^2 + 2U_M^{\frac{1}{2}} (L_g \delta_3)^{\frac{1}{2}} (1 + L_g) \delta_3\right)   \\
        &\leq \frac{2}{\alpha}\left( L_H  + 2U_M^{\frac{1}{2}} L_g^{\frac{1}{2}} (1 + L_g) \right) \delta_3^{\frac{3}{2}}
        \leq \delta_3.
    \end{align*}
    Thus, we know $k + 1 \in \cI$.
    By induction, $k \in \cI$ for every $k \geq j_0$, 
    which also gives the convergence of the whole sequence $\{x_k\}$ since \lemmaref{lem:gradient-decay-of-newton-step} provides a superlinear convergence with order $\frac{3}{2}$ of the sequence $\{ \|x_k - x^*\| \}_{k \geq j_0}$.

    Furthermore, the regularizer $\omega_{k}^{\supsucc}$ reduces to $g_{k}^{\frac{1}{2} + \theta} g_{{k}-1}^{-\theta}$ for $k \geq j_0 + 1$
    and the premises of \lemmaref{lem:appendix/superlinear-rate-boosting-generalized} and \corollaryref{cor:appendix/quadratic-rate-boosting} are satisfied, 
    with the constants $c_0, c$, and $\nu$ therein chosen as $c_2, c_2$, and $1$, respectively.
    Then, the conclusion follows from \lemmaref{lem:appendix/superlinear-rate-boosting-generalized} and \corollaryref{cor:appendix/quadratic-rate-boosting}.
\end{proof}
