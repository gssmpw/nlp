
\section{Introduction} \label{sec:main/intro}
We focus on the nonconvex optimization problem
\begin{equation}
    \min_{x \in \R^n} \varphi(x),
\end{equation}
where $\varphi: \R^n \to \R$ is twice differentiable function with globally Lipschitz continuous Hessian.
Since finding a global minimum is generally difficult, 
 the typical goal is to instead find an $\epsilon$-stationary point $x^*$ such that $\| \nabla \varphi(x^*) \| \leq \epsilon$ for arbitrary $\epsilon>0$. 

The Newton-type method is one of the most powerful tools for solving such problems, 
known for 
its quadratic local convergence near a solution with positive definite Hessian. 
The classical Newton method uses the second-order information at the current iterate $x_k$ 
to construct the following local model $m_k(d)$ and generate the next iterate $x_{k+1} = x_k + d_k$ by minimizing this model:
\begin{equation}
   \min_{d \in \R^n} \left\{ 
        m_k(d) := 
        d^\top \nabla \varphi(x_k)
        + \frac{1}{2} d^\top \nabla^2\varphi(x_k) d
     \right\}, 
     \text{ where }
     k\ge0.
     \label{eqn:basic-newton-direction}
\end{equation}
Although this method enjoys a quadratic local rate,
it is well-known that it may fail to converge globally (i.e., converge from any initial point) even for a strongly convex function. %
Various globalization techniques have been developed to ensure global convergence by introducing regularization or constraints in \eqref{eqn:basic-newton-direction} to adjust the %
direction $d_k$,
including 
Levenberg-Marquardt regularization~\citep{levenberg1944method,marquardt1963algorithm}, trust-region methods~\citep{conn2000trust},
and damped Newton methods with a linesearch procedure~\citep{nocedal1999numerical}. 

However, the original versions of these approaches exhibit a slow 
$O(\epsilon^{-2})$ worst-case performance~\citep{conn2000trust,cartis2010complexity},
leading to extensive efforts to improve the global complexity of second-order methods.
Among these, 
the cubic regularization method~\citep{nesterov2006cubic} overcomes this issue and achieves an iteration complexity of $O(\epsilon^{-\frac{3}{2}})$, 
which has been shown to be optimal~\citep{carmon2020lower}, while retaining the quadratic local rate.
Meanwhile, Levenberg-Marquardt regularization, also known as quadratic regularization,
with gradient norms as the regularization coefficients $\rho_k$,
has also received several attentions due to its simplicity and computational efficiency~\citep{li2004regularized,polyak2009regularized}.
This method approximately solves the regularized subproblem 
$\min_{d} \left \{ m_k(d) + \frac{\rho_k}{2}\| d \|^2 \right \}$ to generate $d_k$ and the next iterate $x_{k+1} = x_k + \alpha_k d_k$, where $\alpha_k$ is either fixed or one selected through a linesearch.
When the regularized subproblem is strongly convex, it is equivalent to solving the linear equation %
$(\nabla^2 \varphi(x_k) + \rho_k \Id)d_k = -\nabla \varphi(x_k)$,
which is simpler than the cubic-regularized subproblem and can be efficiently implemented using %
iterative methods such as the \emph{conjugate gradient} (CG).
Furthermore, each CG iteration only requires a
Hessian-vector product, 
facilitating large-scale problem-solving~\citep{yang2015sdpnal+,li2018highly,li2018efficiently,sun2020sdpnal+,zhang2020efficient}.

While such gradient regularization can preserve the superlinear local rate,
the fast global rate has remained unclear for some time. 
Recent studies have achieved such iteration complexity for convex problems~\citep{mishchenko2023regularized,doikov2024gradient}.
Nevertheless, the regularized subproblem may become ill-defined for nonconvex functions.
Consequently, modifications to these methods are necessary to address cases involving indefinite Hessians.
A possible solution is to apply CG as if the Hessian is positive definite, and choose a first-order direction if evidence of indefiniteness is found~\citep{nocedal1999numerical}, 
although this may result in a deterioration of the global rate.
In contrast, 
\citet{gratton2024yet} introduced a method with a near-optimal global rate of $O(\epsilon^{-\frac{3}{2}}\log \frac{1}{\epsilon})$ and a superlinear local rate.
Instead of relying on a first-order direction, 
their method switches to a direction constructed from the \emph{minimal eigenvalue} and the corresponding eigenvector when indefiniteness is encountered.

On the other hand, \citet{royer2020newton} 
proposed the \emph{capped CG} by modifying the standard CG method to monitor whether a negative curvature direction is encountered during the iterations, 
and switching to such a direction if it exists.
It is worth noting that this modification introduces only one additional Hessian-vector product throughout the entire CG iteration process,
avoiding the need for the minimal eigenvalue computation used in \citet{gratton2024yet}.
Furthermore, when the regularizer is \emph{fixed}, 
an $O(\epsilon^{-\frac{3}{2}})$ global rate can be proved~\citep{royer2020newton}.
Building on this method, \citet{he2023newton-hessian,he2023newton} improved the dependency of the Lipschitz constant by adjusting the linesearch rule, 
and generalized it to achieve an optimal global rate for H\"older continuous Hessian, without requiring prior knowledge of problem parameters.
Despite the appealing global performance, it is unclear whether the superlinear local rate can be preserved using these regularizers.
Along similar lines, \citet{zhu2024hybrid} 
combined the gradient regularizer with capped CG and established a superlinear local convergence rate,
assuming either the error bound condition or global strong convexity. 
\emph{However, it remains unclear whether this holds for nonconvex problems that exhibit local strong convexity.} 

Motivated by the discussions above,
our goal is to \emph{figure out whether the optimal global order can be achieved by the quadratic regularized Newton method without incurring the logarithmic factor, 
while also improving the local rate to a quadratic one.}
Since the Hessian Lipschitz constant $L_H$ is typically unknown and large for many problems, in our algorithmic design, we aim to avoid both the minimal eigenvalue computation and the prior knowledge of $L_H$, while achieving the optimal dependence on $L_H$ in the global rate. %

The remaining parts of this article are organized as follows:
We list the notations used throughout the paper below.
Some background, our main results and related works are provided in \Cref{sec:main/background}.
The ideas and techniques underlying our method are presented in \Cref{sec:main/techniques-overview}, 
and the detailed proofs are deferred to the appendix.
Finally, 
we present some preliminary numerical results to illustrate the performance of our algorithm in \Cref{sec:main/numerical},
and discuss potential directions in \Cref{sec:main/conclusion}.

















\paragraph{Notations}
We use $\N$, $[i]$, and $I_{i,j}$ to denote the set of non-negative integers, $\{1,\ldots,i\}$, and $\{i, .., j-1\}$, respectively, and $\log$ to represent the natural logarithm, unless the base is explicitly specified.
The constant $\ce$ is $\exp(1)$.
For a set $S$, $|S|$ denotes its cardinality, and $\bone_{\{j \in S\}} = 1$ if $j \in S$, and $0$ otherwise. For a symmetric matrix $X$, $X\succ (\succeq)\,0$ denote the positive (semi-)definiteness, respectively. $\lambda_{\min}(X)$ and $\|X\|$ denote the minimum eigenvalue and spectral norm of matrix $X$, respectively. 
The $n$-dimensional identity matrix is denoted by $\Id$.
The notations $O$, $\tilde O$, $\tilde \Omega$, and $\Omega$ are used in their standard sense to represent asymptotic behavior.
$\|x\|$ is the Euclidean norm of $x\in\R^n$.
For a sequence $\{x_k\}_{k \geq 0}$ generated by the algorithm,
we define $g_k = \| \nabla \varphi(x_k) \|$, $\epsilon_k = \min_{j \leq k} g_j$, %
and $\Delta_\varphi = \varphi(x_0) - \inf \varphi$, $U_\varphi = \sup_{\varphi(x) \leq \varphi(x_0)} \| \nabla \varphi(x) \|$.

