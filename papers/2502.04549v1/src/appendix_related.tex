\section{Additional Related Works}
\label{app:related}


\textbf{Structured compositional generative models.} Structured generative models leverage architectural inductive biases in an encoder-decoder framework, such as recurrent attention mechanisms \cite{gregor2015drawrecurrentneuralnetwork} or slot-attention \cite{Wang2023SlotVAEOS}. These models decompose scenes into background and parts-based representations in an unsupervised manner guided by modeling priors. While these approaches can flexibly generate scenes with single or multiple objects, they are not explicitly controllable, and require specific model pre-training on datasets containing compositions of interest.

\textbf{Controllable generation.} Composition at inference-time is one potential mechanism for exerting control over the generation process. Another way to modify compositions of style and/or content attributes is through spatial conditioning a pre-trained diffusion model on a structural attribute (e.g., pose or depth) as in  \citet{zhang2023adding}, or on multiple attributes of style and/or content as in \citet{conditional-loradapter}. Another option is control through resampling, as in \citet{liu2024correcting}. These methods are complementary to single or multiple model conditioning mechanisms based on score composition that we study in the current work.

\textbf{Single model conditioning.} We distinguish the kind of composition we study in this paper from approaches that rely on a single model but use OOD conditioners to achieve novel combinations of concepts never seen together during training; for example, passing OOD text prompts to text-to-image models \citep{nichol2021glide, podell2023sdxl}, or works like \citet{okawa2024compositional, park2024emergence} where a single model conditions simultaneously on multiple attributes like shape and color, with some combinations held out during training.
In contrast, the compositions we study recombine the outputs of multiple separate models at inference time.
Though less powerful, this can still be surprisingly effective, and is more amenable to theoretical study since it disentangles the potential role of conditional embeddings.

\textbf{Multiple model composition.} Among compositions involving multiple separate models, many different variants have been explored with different goals and applications.
Some definitions of composition are inspired by logical operators like AND and OR, usually taken to mean that the composed distribution should have high probability under all of the conditional distributions to be composed, or at least one of them, respectively.
Given two conditional probabilities $p_0(x), p_1(x)$, AND is typically implemented as the product $p_0(x)p_1(x)$ and OR as sum $p_0(x) + p_1(x)$
(though these only loosely correspond to the logical operators and other implementations are also possible).
Some composition methods are based on diffusion models and use the learned scores (mainly for product compositions), others use energy-based models (which allows for OR-inspired sum compositions, as well as more sophisticated samplers, in particular sampling at $t=0$ \citep{du2020visualenergy, du2023reduce, liu2021learning}, and still others work directly with the densities \cite{skreta2024superposition} (enabling an even greater variety of compositions, including a different style of AND, taken to mean $p_0(x) = p_1(x)$). \citet{mcallister2025decentralized} explore another type of OR composition. \cite{wiedemer2024compositional} take a different approach of taking the final rendered images generated by separate diffusion models and ``adding them up'' in pixel-space, as part of a study on generalization of data-generating processes. Task-arithmetic \cite{zhang2023composing, ilharco2022editing}, often using LoRAs \cite{hu2021lora}, is a kind of composition in weight-space that has had significant practical impact.

\textbf{Product compositions.} In this work, we focus specifically on product compositions (broadly defined to allow for a ``background'' distribution, i.e. compositions of the form $\hat{p}(x) = p_b(x) \prod_i \frac{p_i(x)}{p_b(x)}$) implemented with diffusion models, which allows the composition to be implemented via a linear combinations of scores as in \citet{du2023reduce, liu2022compositional}. Our goal is not to propose
a wholly new method of composition but rather to improve theoretical understanding of existing methods.

\textbf{Learning and Generalization.}
Recently, \citet{kamb2024analytic}
demonstrated how a type of compositional generalization
arises from inductive bias in the learning procedure (equivariance
and locality).
Their findings are relevant to our broader motivation,
but complementary to the focus of this work.
Specifically, we focus only on mathematical aspects
of defining and sampling from compositional distributions,
and we do not consider any learning-theoretic aspects
such as inductive bias or sample complexity.
This allows us to study the behavior of
compositional sampling methods
even assuming perfect knowledge of the underlying distributions.
