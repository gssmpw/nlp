\section{CLEVR Experimental Details}
\label{app:clevr_extra}

All of our CLEVR experiments use raw conditional diffusion
scores, without applying any guidance/CFG \citep{ho2022classifier}.
Details below.

\subsection{Dataset, models, and training details}
\subsubsection{CLEVR dataset}
We used the CLEVR \cite{johnson2017clevr} dataset generation procedure\footnote{\url{https://github.com/facebookresearch/clevr-dataset-gen}} to generate datasets customized to the needs of the present work.
All default objects, shapes, sizes, colors were kept unchanged.
Images were generated in their original resolution of $320\times240$ and down-sampled to a lower resolution of $128\times128$ to facilitate experimentation and to be more GPU resources friendly.
The various datasets we generated from this procedure include:
\begin{itemize}
    \item A background dataset ($0$ objects) with 50,000 samples
    \item Single object dataset with 1,550,000 samples
    \item A dataset having 1 to 5 objects, with 500,000 samples for each object count, for a total of 2,500,000 samples.
\end{itemize}

\subsubsection{Model architecture}
We used our own PyTorch re-implementation of the EDM2 \cite{karras2024analyzing} U-net architecture.
Our re-implementation is functionally equivalent, and only differs in optimizations introduced to save memory and GPU cycles.
We used the smallest model architecture, e.g. $\texttt{edm2-img64-xs}$ from \url{https://github.com/NVlabs/edm2}.
This model has a base channel width of $128$, resulting in a total of $124\texttt{M}$ trainable weights.
Two versions of this model were used:
\begin{itemize}
    \item An unmodified version for background and class-conditioned experiments.
    \item A modified version for $(x,y)$ conditioning in which we simply replaced Fourier embeddings for the class with concatenated Fourier embeddings for $x$ and $y$.
\end{itemize}

\subsubsection{Training and inference}
In all experiments, the model is trained with a batch size of $2048$ over $128\times2^{20}$ samples by looping over the dataset as often as needed to reach that number.
In practice, training takes around $16$ hours to complete on $32$ A100 GPUs.
We used almost the same training procedure as in EDM2 \cite{karras2024analyzing}, which is basically a standard training loop with gradient accumulation.
The only difference is that we do weight renormalization after the weights are updated rather than before as the authors originally did.

For simplicity, we did not use posthoc-EMA to obtain the final weights used in inference.
Instead we took the average of weights over the last $4096$ training updates.
The denoising procedure for inference is exactly the same as in EDM2 \cite{karras2024analyzing}, e.g. $65$ model calls using a $32$-step Heun sampler.

\subsection{Factorized Conditionals in CLEVR.}
\label{app:clevr-details}

\subsubsection{Single object distributions with empty background}
Let us explicitly describe how
our definition of Factorized Conditionals
captures the CLEVR setting of Figures~\ref{fig:len_gen} and~\ref{fig:len_gen_monster}a.
Recall, the background distribution $p_b$ 
over $n$ pixels is images of an empty scene with no objects.
For each $i \in \{1,\ldots,L\}$ (where $L = 4$ in \cref{fig:len_gen} and $L=9$ in \cref{fig:len_gen_monster}(a)) define the set $M_i \in [n]$ 
as the set of pixel indices surrounding location $i$.
Each $M_i$ should be thought of as a ``mask'' that
that masks out objects at location $i$.
Then, let $M_b := (\cup_i M_i)^c$ be the remaining
pixels in the image, excluding all the masks.
Now we claim the distributions $(p_b, p_1, \ldots, p_L)$
are approximately Factorized Conditionals, with corresponding
coordinate partition $(M_b, M_1, \ldots, M_L)$.
We can confirm each criterion in Definition~\ref{def:factorized}
individually:
\begin{enumerate}
    \setlength{\itemsep}{1pt}
    \item In each distribution $p_i$, the pixels inside the
    mask $M_i$ are approximately independent from the pixels outside the mask,
    since the outside pixels always describe an empty scene.
    \item In the background $p_b$,
    the set of masks $\{M_i\}$ specify approximately
    mutually-independent sets of pixels,
    since all pixels are roughly constant.
    \item The distribution of $p_i$ and $p_b$ approximately agree 
    along all pixels outside mask $M_i$, since they both
    describe an empty scene outside this mask.
\end{enumerate}
Thus, the set of distributions approximately form
Factorized Conditionals. However the conditions of Definition~\ref{def:factorized} do not \emph{exactly} hold, since objects can cast shadows on each other and may even occlude each other. Empirically, this can significantly affect the results when composing many objects, as explored in Figure \ref{fig:len_gen_monster}(a).

\subsubsection{Cluttered distributed with unconditional background}
\begin{figure}[hb]
\vskip 0.2in
\begin{center}
\centerline{
\includegraphics[width=0.8\columnwidth]{figures/clutter_uncond_6.png}
}
\caption{Samples from unconditional model trained on images containing 1-5 objects. The sampled images sometimes contain 6 objects (circled in orange).}
\label{fig:clutter_uncond_6}
\end{center}
\vskip -0.2in
\end{figure}

Next, we discuss the setting of \cref{fig:len_gen_monster}c, which is a Bayes composition based on an unconditional distribution where each scene contains 1-5 objects (with the number of objects sampled uniformly). The locations and all other attributes of the objects are sampled independently. The conditions label the location of one randomly-chosen object. Just as in the previous case, for each $i \in \{1,2, \ldots, L\}$ ($L=9$ in \cref{fig:len_gen_monster}c), we define the set $M_i \in [n]$  as the set of pixel indices surrounding location $i$, and let $M_b := (\cup_i M_i)^c$ be the remaining pixels in the image, excluding all the masks. Again, we claim that the distributions $(p_b, p_1, \ldots, p_L)$
are approximately Factorized Conditionals, with corresponding
coordinate partition $(M_b, M_1,\ldots, M_L)$. We examine the criteria in Definition~\ref{def:factorized}:
\begin{enumerate}
    \setlength{\itemsep}{1pt}
    \item In each distribution $p_i$, the pixels inside the
    mask $M_i$ are approximately independent from the pixels outside the mask,
    since the outside pixels approximately describe a distribution containing 0-4 objects, and the locations and other attributes of all objects are independent.
    \item In the unconditional background distribution $p_b$, we argue that in practice, the set of masks $\{M_i\}$ are approximately
    mutually-independent. By assumption, the locations and other attributes of all shapes are all independent, and the masks $M_i$ are chosen in these experiment to minimize interaction/overlap. The main difficulty is the restriction to 1-5 total objects, which we discuss below.
    \item The distribution of $p_i$ and $p_b$ approximately agree 
    along all pixels outside mask $M_i$, since $p_i|_{M_i^c}$ contains 0-4 objects, while $p_b|_{M_i^c}$ contains 0-5 objects (since one object could be `hidden' in ${M_i^c}$).
\end{enumerate}
There are, however, two important caveats to the points above. First, overlap or other interaction (shadows, etc.) between objects can clearly violate all three criteria. In our experiment, this is mitigated by the fact that the masks $M_i$ are chosen to minimize interaction/overlap (though interactions start to occur as we compose more objects, leading to some image degradation). Second, since the number of objects is sampled uniformly from 1-5, the presence of one object affects the probability that another will be present. Thus, the masks $\{M_i\}$ are not perfectly independent under the background distribution, nor do $p_i$ and $p_b$ perfectly agree on $M_i^c$. Ideally, each $p_i$ would place an object in mask $M_i$ and independently follow $p_b$ on $M_i^c$, and $p_b$ would be such that the probability that an object appears in mask $M_i$ is independently Bernoulli (c.f. \cref{app:clutter}). In particular, this would imply that the distribution of the total number of objects is Binomial (which allows the total object-count to range from zero to the total-number-of-locations, as well as placing specific probabilities on each object-count), which clearly differs from the uniform distribution over 1-5 objects. However, a few factors mitigate this discrepancy:
\vspace{-1em}
\begin{itemize}
\item A Binomial with sufficiently small probability-of-success places very little probability on large $k$. For example, under $\text{Binomial}(9, 0.3)$, $\mathbb{P}(k=0:5) = 0.04, 0.156, 0.27, 0.27, 0.17, 0.07$ and $\mathbb{P}(k>5) = 0.026$.
\vspace{-0.5em}
\item Empirically, the \emph{learned} unconditional distribution does not actually enforce $k<5$; we sometimes see samples with $k=6$ for example, as seen in \cref{fig:clutter_uncond_6}.
\end{itemize}
\vspace{-1em}
Intuitively, the train distribution is ``close to Bernoulli'' and the \emph{learned} distribution seems to be even closer.

With these considerations in mind, we see that the set of distributions approximately -- though imperfectly -- form
Factorized Conditionals. One advantage of this setting compared to the single-object setting is that the models can learn how multiple objects should interact and even overlap correctly, potentially making it easier compose nearby locations. We explore the length-generalization of this composition empirically in Figure \ref{fig:len_gen_monster}c (note, however, that only compositions of more than 5 objects are actually OOD w.r.t. the distributions $p_i$ in this case).


\subsection{Additional CLEVR samples}
In this section we provide additional non-cherrypicked samples of the experiments shown in the main text.

\begin{figure}[ht]
\vskip 0.2in
\begin{center}
\centerline{
\includegraphics[width=1.0\columnwidth]{figures/len-gen-extra.png}
}
\caption{Additional non-cherrypicked samples for CLEVR experiment of Figure \ref{fig:len_gen}.}
\label{fig:len_gen_extra}
\end{center}
\vskip -0.2in
\end{figure}



\begin{figure}[hb]
\vskip 0.2in
\begin{center}
\centerline{
\includegraphics[width=1.0\columnwidth]{figures/clevr_color_comp_extra.png}
}
\caption{Additional non-cherrypicked samples for CLEVR experiment of Figure \ref{fig:clevr_color_comp}. Top left grid shows conditional samples for each color. Top right grid shows compositions of red-colored objects ($p_6$) with objects of other colors (8 samples of each), which only succeeds for cyan-colored objects. Bottom grid shows compositions of yellow-colored objects ($p_7$) with objects of other colors (16 samples of each): these are additional samples of the exact experiment shown in Figure \ref{fig:clevr_color_comp}.}
\label{fig:clever_color_comp_extra}
\end{center}
\vskip -0.2in
\end{figure}
