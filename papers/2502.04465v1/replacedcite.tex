\section{Related Work}
\label{sec:related_work}

\paragraph{Acoustic Codecs.} Acoustic codecs, built on the VQ-VAE____ framework, aim for high-fidelity reconstruction. Notable advancements include hierarchical RVQ____, lightweight architectures____, improved RVQ techniques____, and efficiency-driven designs____. Recent methods explore scalar quantization____, Mel-spectrogram discretization____, and novel paradigms like diffusion- and flow-based decoding____.
To reduce bitrate without compromising performance, multi-scale RVQ____ achieves improved compression by varying frame rates in deeper quantizers. However, its hierarchical design adds complexity to downstream applications, as it requires flattening the token sequences.
Single-codebook designs____ have emerged as a simpler, efficient alternative, delivering robust performance at low bitrates. Our codec aligns with this trend, leveraging a novel focal modulation architecture and a pretrained self-supervised encoder to efficiently unify semantic and acoustic representation learning.


\paragraph{Semantic Codecs.} Semantic codecs leverage self-supervised features from large models trained with contrastive objectives____ and k-means clustering____ for quantization, either from a single layer____ or multiple layers____.
Improvements upon this paradigm include replacing k-means with RVQ____, noise-aware____ and speaker-invariant tokenization____. 
While these approaches effectively capture linguistic and content-related information, they often discard much of the acoustic detail, resulting in low speaker fidelity when a vocoder is trained to resynthesize speech from these representations.
Our codec adopts a self-supervised architecture similar to semantic codecs but retains acoustic detail through its novel compressor-quantizer-decompressor architecture and decoupled training strategy, ensuring high-quality reconstruction while preserving the advantages of semantic representations.


\paragraph{Hybrid Codecs.}
Hybrid codecs combine semantic and acoustic features to balance reconstruction quality and content representation. Some methods____ employ multiple codebooks to disentangle speech into distinct subspaces, such as content, prosody, and timbre, while others____ utilize dual encoders to separately capture content and fine-grained acoustic information. Semantic distillation____ has also been explored to enrich the first RVQ codebook with semantic information from HuBERT____ and WavLM____. More recently, ____ trained a large-scale transformer-based VQ-VAE, achieving exceptional reconstruction quality at ultra-low bitrates. To enhance semantic content, they employed supervised fine-tuning on force-aligned phoneme data.
Our codec also belongs to this category but instead of relying on complex multi-codebook designs with explicit disentanglement, distillation losses, or supervised fine-tuning, it is purely based on self-supervised learning. It compresses both semantic and acoustic information into a single codebook, pushing the boundaries of hybrid codec design at low bitrates.