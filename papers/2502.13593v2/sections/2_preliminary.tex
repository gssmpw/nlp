\section{Preliminary}
\label{sec:Preliminary}

\subsection{Problem Setup}

In NTL, we generally consider a source domain and a target domain, where we want to keep the performance on the source domain (similar to supervised learning (SL) performance) and degrade performance on the target domain, thus implementing the resistance of generalization from the source domain to the target domain.

According to whether the target domain is known in the training stage, NTL could be divided into two settings~\cite{wang2021non}: \textbf{(i)} \textit{target-speciﬁed NTL}, which assumes the target domain is known and aims to restrict the model generalization toward the pre-known target domain, and \textbf{(ii)} \textit{source-only NTL}, which assumes the target domain is unknown and aims to restrict the generalization toward all other domains except the source domain. The comparison between SL and the two NTLs is shown in~\Cref{fig:NTL}.


\subsection{General Framework of NTL}
\label{sec:definition}

We use a classification task for illustration, as most existing NTL methods aim at image classification tasks. 
Let $\mathcal{D}_s=\{(\boldsymbol{x}_i,y_i)\}_{i=1}^{N_s}$ and $\mathcal{D}_t=\{(\boldsymbol{x}_i,y_i)\}_{i=1}^{N_t}$ represent the source domain and the target domain, respectively. Note that we here assume $\mathcal{D}_s$ and $\mathcal{D}_t$ share the same label space, as considered in \cite{wang2021non}.
Considering a neural network $f_{\theta}$ with parameters $\theta$, NTL aims to train the $f_{\theta}$ to maximize the risk on the target domain $\mathcal{D}_t$ and simultaneously minimize the risk on the source domain $\mathcal{D}_s$. 
To reach this goal, a basic NTL framework is to impose a regularization term on the SL to maximize the target domain error:
\vspace{-1.5mm}
\begin{equation}
    \begin{aligned}
 {\underset{\theta}{\min}}\ \Big\{ \mathcal{L}_{\text{ntl}} := & \underbrace{\mathbb{E}_{(\boldsymbol{x}_s,y_s)\sim \mathcal{D}_s}\left[ \mathcal{L}_{\text{src}}(f_{\theta}(\boldsymbol{x}_s), y_s)\right]}_{\mathcal{T}_{\text{src}}} \\
 \noalign{\vskip -5pt}
 - & \lambda\ \underbrace{\mathbb{E}_{(\boldsymbol{x}_t,y_t)\sim \mathcal{D}_t}\left[ \mathcal{L}_{\text{tgt}}(f_{\theta}(\boldsymbol{x}_t), y_t)\right]}_{\mathcal{T}_{\text{tgt}}} \Big\}, \\
    \noalign{\vskip -3pt}
    \end{aligned}
    \label{eq:ntlframe}
\end{equation}
where $\lambda$ is a trade-off weight, $\mathcal{L}_{\text{src}}$ and $\mathcal{L}_{\text{tgt}}$ represent the loss function (e.g., Kullback-Leible divergence) for the source and target domain, respectively. 
The learning objective contains two tasks: (i) a source domain learning task $\mathcal{T}_{\text{src}}$ to maintain the source domain performance, and (ii) a non-transferable task $\mathcal{T}_{\text{tgt}}$ to degrade the target domain performance.


Existing works generally can be seen as variants to \Cref{eq:ntlframe}, where they may focus on different fields (modal, task), data assumptions (label space, target supervision, source data dependent), and use different approaches to conduct $\mathcal{T}_{\text{tgt}}$. The statistics of these aspects considered in existing works are shown in \Cref{tab:summary}. More details for each NTL approach are illustrated in \Cref{sec:immeNTL}.



\newcommand{\twoline}[2]{\begin{tabular}[c]{@{}c@{}}#1\\#2\end{tabular}}

\newcommand{\true}{\textcolor{teal}{\usym{2714}}}
\newcommand{\false}{\textcolor{purple}{\usym{2717}}}


\begin{table*}
    % \scriptsize
    \tiny
    \centering
    \begin{tabular}{@{\hspace{4pt}}c@{\hspace{4pt}}|@{\hspace{4pt}}c@{\hspace{4pt}}|@{\hspace{4pt}}c@{\hspace{4pt}}c|c@{\hspace{6pt}}c@{\hspace{6pt}}c|c@{\hspace{4pt}}c|c@{\hspace{4pt}}c@{\hspace{4pt}}}
    \toprule
    
    \multirow{2.5}{*}{\textbf{Method}}
    &
    \multirow{2.5}{*}{\textbf{Venue}}
    &
    \multicolumn{2}{c|}{\textbf{Field} \textbf{\ding{172}}}
    &
    \multicolumn{3}{c|}{\textbf{Data} \textbf{\ding{173}}}
    &
    \multicolumn{2}{c|}{\textbf{Non-Transferable Approach} \textbf{\ding{174}}}
    &
    \multicolumn{2}{c}{\textbf{Robustness} \textbf{\ding{175}}}
    \\\cmidrule{3-11}
    &
    & \textbf{Modal} & \textbf{Task} & \textbf{Label Space} & \textbf{Target Data} & \textbf{Source Data} & \textbf{Feature Space} & \textbf{Output Space} & \textbf{Source} & \textbf{Target} \\
    \midrule
    \midrule
    
    NTL \cite{wang2021non}
    & ICLR'22
    & CV & CLS & Close-Set & Labeled & 
    Dependent
    & $\max \text{MMD}(\Phi(\boldsymbol{x}_s), \Phi(\boldsymbol{x}_t))$  
    & $\max \text{KL}(f(\boldsymbol{x}_t), y_t)$
    & \true & \false \\\cmidrule{1-11}
    
    UNTL \cite{zeng2022unsupervised}
    & EMNLP'22
    & NLP & CLS & Close-Set & Unlabeled & 
    Dependent
    & \begin{tabular}[c]{@{}l@{}}$\max \text{MMD}(\Phi(\boldsymbol{x}_s), \Phi(\boldsymbol{x}_t))$\\ $ + \min \text{CE}(\Omega_d(\Phi(\boldsymbol{x})),y_d)$\end{tabular}
    & --- & \false & \false \\\cmidrule{1-11}
    
    CUTI-domain \cite{wang2023model}
    & CVPR'23
    & CV & CLS & Close-Set & Labeled & 
    Dependent
    & --- 
    & $\max \text{KL}(f(\boldsymbol{x}_t), y_t)$
    & \true & \false \\\cmidrule{1-11}
    
    DSO \cite{wang2023domain}
    & ICCV'23
    & CV & CLS & Close-Set & Unlabeled & 
    Dependent
    & --- 
    & $\min \text{KL}(f(\boldsymbol{x}_t), y_s+1)$
    & \false & \false\\\cmidrule{1-11}
    
    H-NTL \cite{hong2024improving}
    & ICLR'24
    & CV & CLS & Close-Set & Labeled & 
    Dependent
    & --- 
    & $\min \text{KL}(f(\boldsymbol{x}_t), f_{\text{sty}}(\boldsymbol{x}_t))$ 
    & \false & \false \\\cmidrule{1-11}
    
    ArchLock \cite{zhou2024archlock}
    & ICLR'24
    & CV & Cross & Open-Set & Labeled & 
    Dependent
    & --- 
    & $\max \text{CE}(f(\boldsymbol{x}_t), y_t)$ 
    & \false & \true \\\cmidrule{1-11}

    TransNTL \cite{hong2024your}
    & CVPR'24
    & CV & CLS & Close-Set & Labeled & 
    Dependent
    & --- 
    & --- 
    & \true & \false \\\cmidrule{1-11}
    
    MAP \cite{peng2024map}
    & CVPR'24
    & CV & CLS & Close-Set & Unlabeled & 
    Free
    & --- 
    & $\max \text{KL}(f(\boldsymbol{x}_t), \hat{y}_t)$
    & \false & \false \\\cmidrule{1-11}
    

    \multirow{2.6}{*}{SOPHON \cite{deng2024sophon}}
    & \multirow{2.6}{*}{
        \begin{tabular}[c]{@{}c@{}}    
            IEEE\\S\&P'24
        \end{tabular} 
        }
    & CV & CLS
    & Open-Set & Labeled & 
    Dependent
    & ---
    & \begin{tabular}[c]{@{}c@{}}
        $\min \text{CE}(f(\boldsymbol{x}_t),1-y_t)$
        \\
        or $\min \text{KL}(f(\boldsymbol{x}_t),\mathcal{U})$
    \end{tabular} 
    & \multirow{2.6}{*}{\false} & \multirow{2.6}{*}{\true}
    \\\cmidrule{3-9}
    &
    & CV & GEN
    & Open-Set & Labeled & 
    Dependent
    & --- 
    & $\min \text{MSE}(f(\boldsymbol{x}_t),\boldsymbol{0})$
    & &
    \\\cmidrule{1-11}
    
    CUPI-domain \cite{wang2024say}
    & TPAMI'24
    & CV & CLS & Close-Set & Labeled & 
    Dependent
    & --- 
    & $\max \text{KL}(f(\boldsymbol{x}_t), y_t)$ 
    & \true & \false \\\cmidrule{1-11}
    
    NTP \cite{ding2024non}
    & ECCV'24
    & CV & CLS & Close-Set & Labeled &  
    Dependent
    & $\min \text{FDA}(\Phi(\boldsymbol{x}_t), y_t)$
    & $\max \text{KL}(f(\boldsymbol{x}_t), y_t)$ 
    & \false & \true \\
    
    \bottomrule
    \end{tabular}
    \vspace{-2mm}
    \begin{flushleft}
        \scriptsize 
        \textbf{\ding{172}} In \textbf{Field} column, ``CV'': computer vision. ``NLP'': natural language processing. ``CLS'': classification task. ``GEN'': generation task. ``Cross'': cross task. 

        \hangindent=1em
        \hangafter=1
        \textbf{\ding{173}} In \textbf{Data} column: ``Close-Set'': source and target domain share the same label space. ``Open-Set'': source and target domain have different label space. ``Labeled'': using labeled targeted data. ``Unlabeled'': do not need labeled targeted data. ``Dependent'': using source data. ``Free'': without source data. 

        \textbf{\ding{174}} In \textbf{Non-Transferable Approach}, we split the model $f$ into a feature extractor $\Phi$ and a classifier $\Omega$, i.e., $f(\boldsymbol{x})=\Omega(\Phi(\boldsymbol{x}))$. $\Omega_d$ means an additional domain classifer. $\boldsymbol{x}_s$ and $y_s$: source-domain data and label. $\boldsymbol{x}_t$ and $y_t$: target-domain data and label. $y_d$: domain label.
        %  ($0$/$1$ indicates source/target domain). 
         $\hat{y}_t$: target-domain pesudo label predicted by the model. $f_{\text{sty}}(\cdot)$: the style mapping function trained in H-NTL~\cite{hong2024improving}. $\mathcal{U}$: uniform distribution.
        $\boldsymbol{0}$: zero vector. 
        $\text{KL}(\cdot,\cdot)$: Kullback-Leible divergence. $\text{CE}(\cdot,\cdot)$: Cross-Entropy loss. $\text{MMD}(\cdot,\cdot)$: Maximum Mean Discrepancy. $\text{MSE}(\cdot,\cdot)$: Mean Squared Error. $\text{FDA}(\cdot,\cdot)$: Fisher Discriminant Analysis (larger value indicates better feature clustering~\cite{shao2022not}).

        \textbf{\ding{175}} In \textbf{Robustness} column, \true (or \false) represent the robustness have (or haven't) been evaluated in their original paper.
    \end{flushleft}
    \vspace{-3mm}
    \caption{Summary of NTL methods according to \textbf{Field} (modal, task), \textbf{Data} (label space, target supervision, source data dependent), \textbf{Non-Transferable Approach} (feature or output space), and \textbf{Robustness} (whether source and target domain robustness have been evaluated). 
    }
    \vspace{-1mm}
    \label{tab:summary}
  \end{table*}
  



\subsection{NTL Criteria}
\label{sec:criteria}

\paragraph{Non-transferability performance.} 
NTL models are usually evaluated in two aspects \cite{wang2021non}:
\begin{itemize}[leftmargin=*, topsep=0pt]\setlength{\parskip}{0pt}
    \item \textit{Source domain maintainance}: Whether the NTL model is able to achieve normal performance (i.e., the same level as the SL model) on the source domain.
    \item \textit{Target domain degradation}: The extent to which the NTL model can reduce performance on the target domain.
\end{itemize}
We review how existing methods achieve both the \textit{source domain maintainance} and the \textit{target domain degradation} in \Cref{sec:immeNTL}. Speciﬁcally, we focus on the setting that the target domain is known (i.e., target-specified NTL) in \Cref{sec:target-specified} and unknown (i.e., source-only NTL) in \Cref{sec:source-only}.


\paragraph{Post-training robustness.} 
NTL models are expected to keep the non-transferability after malicious attacks,
while not all existing works consider or evaluate the comprehensive robustness of their proposed method. 
We summarize the robustness considered in existing works into the following two parts, based on which domain is accessible to attackers.
The statistics on which aspects have been evaluated for each NTL method are shown in \Cref{tab:summary} (\textbf{Robustness} column).
\begin{itemize}[leftmargin=*, topsep=0pt]\setlength{\parskip}{0pt}
    \item \textit{Robustness against source domain attack}: 
    It has been verified that fine-tuning the white-box NTL model with a small amount of source domain data is a potential risk to break non-transferability~\cite{hong2024your,wang2021non,wang2024say}. Thus, the \textit{robustness against source domain attacks} measures how well an NTL model can resist fine-tuning attacks on the source domain.
    \item \textit{Robustness against target domain attack}: If malicious attackers have access to a small amount of labeled target domain data and the white-box NTL model, they can fine-tune the NTL model to re-activate target domain performance~\cite{deng2024sophon,ding2024non}.
    The \textit{robustness against target domain attack} evaluates how well an NTL model can defend against attack from the target domain, such as fine-tuning using target domain data.
\end{itemize}
The \text{post-training robustness} of existing methods is reviewed in \Cref{sec:robustness}, where the \textit{robustness against source domain attack} is illustrated in \Cref{sec:robustness_src}, and the \textit{robustness against target domain attack} is illustrated in \Cref{sec:robustness_tgt}.
 
