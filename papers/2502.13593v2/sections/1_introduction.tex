

\vspace{-1mm}
\section{Introduction}\label{sec:introduction}

Throughout much of deep learning (DL) history, researchers have primarily focused on improving generalization abilities \cite{neyshabur2017exploring,liu2021towards,zhuang2020comprehensive,yuan2025instance,yang2020rethinking,foret2020sharpness}. 
With advancements in novel techniques, the availability of high-quality data, and the expansion of model sizes and computational resources, DL models have demonstrated increasingly strong generalization, extending from in-distribution to out-of-distribution (OOD) scenarios \cite{wang2022generalizing,radford2021learning,ye2022ood,kaplan2020scaling,hendrycks2021many,li2022out,huang2023winning,zou2024towards,guo2024investigating}. 
This facilitates the application of DL in complex real-world scenarios.
However, limited attention has been given to regulating models' generalization abilities, while strong-enough yet unconstrained generalization abilities may pose misuse risks. Specifically, the generalization of deep models to unintended data (e.g., unauthorized or harmful data) can be exploited by malicious adversaries in unexpected ways. 
This raises concerns regarding the regulating of powerful DL models, including issues related to model ethic \cite{li2023trustworthy,jiao2024navigating}, safety alignment \cite{ouyang2022training,huang2024harmful,ji2024beavertails,yin2025safeworld}, model privacy and intellectual property \cite{sun2023deep,wang2024training,chen2024watermark,wuresilient,wangdefense,jiang2024intellectual}, among others.


Non-transferable learning (NTL)~\cite{wang2021non}, a task aimed at reshaping the generalization abilities of DL models, was proposed to address these challenges. 
Its goal is to prevent the model's generalization to specific target domains or tasks (such as harmful \cite{rosati2024representation,huang2024harmful} or unauthorized domains \cite{wang2021non,si2024iclguard}) while preserving its normal functionality on a source domain. Although numerous NTL methods have been proposed recently~\cite{zeng2022unsupervised,wang2023model,wang2023domain,hong2024improving,peng2024map,zhou2024archlock,hong2024your,deng2024sophon,si2024iclguard,rosati2024representation,wang2024say,ding2024non,xiang2025jailbreaking}, a comprehensive summary of existing progress in this field and an thorough analysis of current limitations is still lacking.

In this paper, we bridge this gap by presenting the first comprehensive survey of NTL.  We first introduce the task settings, general framework and criteria of NTL (\Cref{sec:Preliminary}), followed by a summary of existing NTL approaches according to their strategies to implement non-transferability in two settings (\Cref{sec:immeNTL}). 
Then, we highlight the often-overlooked robustness against diverse attacks that can destroy the non-transferable mechanism established by NTL (\Cref{sec:robustness}).

In addition, we propose the first benchmark (\texttt{NTLBench}) to integrate 5 state-of-the-art (SOTA) and open-source NTL methods and 3 types of post-training attacks (15 attack methods) in a unified framework, as illustrated in \Cref{fig:opening}. Our \texttt{NTLBench} supports running NTL and attacks on 9 datasets (more than 116 domain pairs), 5 network architecture families,
providing overall at least 40,000 experimental configurations for comprehensive evaluation. 
Main results obtained from \texttt{NTLBench} verify the unsatisfactory robustness of existing NTL methods in dealing with various post-training attacks (\Cref{sec:exp}). 
Finally, we discuss applications, related work and future directions and challenges (\Cref{sec:applications,sec:related,sec:future}). 


We believe that our survey and \texttt{NTLBench} can drive the development of robust NTL methods and facilitate their applications in trustworthy model deployment scenarios. 
Our major contributions are summarized as three folds:
\begin{itemize}[leftmargin=*, topsep=0pt]\setlength{\parskip}{0pt}
    \item \textbf{Comprehensive review:} We conduct a systematic review of existing NTL works, including settings, framework, criteria, approaches, and applications. We emphasize the robustness challenges of NTL from three aspects, according to the data accessibility of different attackers.
    \item \textbf{Codebase:} We propose \texttt{NTLBench} to benchmark 5 SOTA and open-source NTL methods, covering standard assessments (5 networks and 9 datasets) and examining robustness against 15 attacks from 3 attack settings. 
    \item \textbf{Evaluation and analysis:} We use our \texttt{NTLBench} to fairly evaluate 5 SOTA NTL methods, covering the performance and robustness against diversity attacks. Our results identify the limitation of existing NTL methods in dealing with complex datasets and diverse attacks.
\end{itemize}


\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{figs/NTL.pdf}
    \vspace{-6mm}
    \caption{Comparison of (a) supervised learning (SL), (b) target-specified non-transferable learning (NTL), and (c) source-only NTL.}
    \vspace{-2mm}
    \label{fig:NTL}
\end{figure}

