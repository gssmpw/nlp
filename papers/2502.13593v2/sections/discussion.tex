\section{Future Directions and Challenges}
\label{sec:future}

\paragraph{Improving robustness.} We highlight the shortcoming of NTL on post-training robustness.
Existing defense attempts (e.g., SOPHON~\cite{deng2024sophon}) require extensive resources, such as an extremely high number of training epochs, yet they may still fail to remain robust against unseen fine-tuning. This raises an open challenge: how to effectively enhance the robustness of NTL against various attacks.
\paragraph{Identifying more threat.}
There are other potential attacks that could pose risks to NTL under weaker assumptions. For example, if an attacker is unable to re-train the NTL model \cite{hu2023learning,guo2023scale}, can they still bypass the non-transferability constraints? Moreover, attackers may have access to a large amount of data from the wild \cite{chen2021learning}, distinct from both the source and target domains. Can they leverage these unseen data to break non-transferability? We believe identifying these threats can further promote the robustness of NTL.
\paragraph{Cross-modal non-transferability.} Existing NTL works primarily focus on single modality, while the cross-modal non-transferability remains an important yet underexplored challenge. A related finding in large models suggests that the safety alignment of LLMs can be compromised through visual instruction tuning~\cite{zong2024safety,liu2023visual}. 
However, a deep investigation of robust cross-modal non-transferability mechanisms remains lacking.
Advancing cross-modal non-transferability not only addresses this gap but also broadens the application scope of NTL.



\section{Conclusion}
In this paper, we conduct the first systematic review of NTL by summarizing existing approaches and highlighting the often overlooked robustness challenges. 
In addition, we propose \texttt{NTLBench} to benchmark 5 SOTA NTL methods, covering standard assessments and examining robustness against 15 attacks. 
Main results from \texttt{NTLBench} verify the limitation of existing NTLs on robustness.
We believe \texttt{NTLBench} can drive the development of robust NTL and facilitate their applications in practical scenarios. 
