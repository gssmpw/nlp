[
  {
    "index": 0,
    "papers": [
      {
        "key": "jonathan2020ddpm",
        "author": "Ho, Jonathan and Jain, Ajay and Abbeel, Pieter",
        "title": "Denoising Diffusion Probabilistic Models"
      },
      {
        "key": "song2021ddim",
        "author": "Jiaming Song and Chenlin Meng and Stefano Ermon",
        "title": "Denoising Diffusion Implicit Models"
      },
      {
        "key": "karras2022edm",
        "author": "Karras, Tero and Aittala, Miika and Aila, Timo and Laine, Samuli",
        "title": "Elucidating the design space of diffusion-based generative models"
      },
      {
        "key": "song2020score",
        "author": "Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben",
        "title": "Score-based generative modeling through stochastic differential equations"
      },
      {
        "key": "liu2022reflow",
        "author": "Xingchao Liu and Chengyue Gong and Qiang Liu",
        "title": "Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "sd3",
        "author": "Esser, Patrick and Kulal, Sumith and Blattmann, Andreas and Entezari, Rahim and M{\\\"u}ller, Jonas and Saini, Harry and Levi, Yam and Lorenz, Dominik and Sauer, Axel and Boesel, Frederic and others",
        "title": "Scaling rectified flow transformers for high-resolution image synthesis"
      },
      {
        "key": "chen2024pixartdelta",
        "author": "Junsong Chen and Yue Wu and Simian Luo and Enze Xie and Sayak Paul and Ping Luo and Hang Zhao and Zhenguo Li",
        "title": "PIXART-Delta: Fast and Controllable Image Generation with Latent Consistency Models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "zhou2022magicvideo",
        "author": "Zhou, Daquan and Wang, Weimin and Yan, Hanshu and Lv, Weiwei and Zhu, Yizhe and Feng, Jiashi",
        "title": "Magicvideo: Efficient video generation with latent diffusion models"
      },
      {
        "key": "zeng2024pxldance",
        "author": "Zeng, Yan and Wei, Guoqiang and Zheng, Jiani and Zou, Jiaxin and Wei, Yang and Zhang, Yuchen and Li, Hang",
        "title": "Make pixels dance: High-dynamic video generation"
      },
      {
        "key": "hong2022cogvideo",
        "author": "Hong, Wenyi and Ding, Ming and Zheng, Wendi and Liu, Xinghan and Tang, Jie",
        "title": "CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers"
      },
      {
        "key": "yang2024cogvideox",
        "author": "Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others",
        "title": "CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer"
      },
      {
        "key": "openai2024sora",
        "author": "Tim, Brooks and Bill, Peebles and Connorm Holmes and Will, DePue and Yufeim Guo and Li, Jing and David, Schnurr and Joe, Taylor and Troy, Luhman and Eric, Luhman and Clarence, Ng and Ricky, Wang and Aditya, Ramesh",
        "title": "Video generation models as world simulators"
      },
      {
        "key": "kong2024hunyuanvideo",
        "author": "Kong, Weijie and Tian, Qi and Zhang, Zijian and Min, Rox and Dai, Zuozhuo and Zhou, Jin and Xiong, Jiangfeng and Li, Xin and Wu, Bo and Zhang, Jianwei and others",
        "title": "HunyuanVideo: A Systematic Framework For Large Video Generative Models"
      },
      {
        "key": "polyak2024moviegen",
        "author": "Polyak, Adam and Zohar, Amit and Brown, Andrew and Tjandra, Andros and Sinha, Animesh and Lee, Ann and Vyas, Apoorv and Shi, Bowen and Ma, Chih-Yao and Chuang, Ching-Yao and others",
        "title": "Movie gen: A cast of media foundation models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "singer2022make",
        "author": "Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and others",
        "title": "Make-a-video: Text-to-video generation without text-video data"
      },
      {
        "key": "wu2023tune",
        "author": "Wu, Jay Zhangjie and Ge, Yixiao and Wang, Xintao and Lei, Stan Weixian and Gu, Yuchao and Shi, Yufei and Hsu, Wynne and Shan, Ying and Qie, Xiaohu and Shou, Mike Zheng",
        "title": "Tune-a-video: One-shot tuning of image diffusion models for text-to-video generation"
      },
      {
        "key": "qi2023fatezero",
        "author": "Chenyang Qi and Xiaodong Cun and Yong Zhang and Chenyang Lei and Xintao Wang and Ying Shan and Qifeng Chen",
        "title": "FateZero: Fusing Attentions for Zero-shot Text-based Video Editing"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "guo2023animatediff",
        "author": "Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Liang, Zhengyang and Wang, Yaohui and Qiao, Yu and Agrawala, Maneesh and Lin, Dahua and Dai, Bo",
        "title": "Animatediff: Animate your personalized text-to-image diffusion models without specific tuning"
      },
      {
        "key": "zhou2022magicvideo",
        "author": "Zhou, Daquan and Wang, Weimin and Yan, Hanshu and Lv, Weiwei and Zhu, Yizhe and Feng, Jiashi",
        "title": "Magicvideo: Efficient video generation with latent diffusion models"
      },
      {
        "key": "wang2023modelscope",
        "author": "Wang, Jiuniu and Yuan, Hangjie and Chen, Dayou and Zhang, Yingya and Wang, Xiang and Zhang, Shiwei",
        "title": "Modelscope text-to-video technical report"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "openai2024sora",
        "author": "Tim, Brooks and Bill, Peebles and Connorm Holmes and Will, DePue and Yufeim Guo and Li, Jing and David, Schnurr and Joe, Taylor and Troy, Luhman and Eric, Luhman and Clarence, Ng and Ricky, Wang and Aditya, Ramesh",
        "title": "Video generation models as world simulators"
      },
      {
        "key": "yang2024cogvideox",
        "author": "Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others",
        "title": "CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer"
      },
      {
        "key": "kong2024hunyuanvideo",
        "author": "Kong, Weijie and Tian, Qi and Zhang, Zijian and Min, Rox and Dai, Zuozhuo and Zhou, Jin and Xiong, Jiangfeng and Li, Xin and Wu, Bo and Zhang, Jianwei and others",
        "title": "HunyuanVideo: A Systematic Framework For Large Video Generative Models"
      },
      {
        "key": "polyak2024moviegen",
        "author": "Polyak, Adam and Zohar, Amit and Brown, Andrew and Tjandra, Andros and Sinha, Animesh and Lee, Ann and Vyas, Apoorv and Shi, Bowen and Ma, Chih-Yao and Chuang, Ching-Yao and others",
        "title": "Movie gen: A cast of media foundation models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "yu20233DVAE",
        "author": "Yu, Lijun and Lezama, Jos and Gundavarapu, Nitesh B and Versari, Luca and Sohn, Kihyuk and Minnen, David and Cheng, Yong and Birodkar, Vighnesh and Gupta, Agrim and Gu, Xiuye and others",
        "title": "Language Model Beats Diffusion--Tokenizer is Key to Visual Generation"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "polyak2024moviegen",
        "author": "Polyak, Adam and Zohar, Amit and Brown, Andrew and Tjandra, Andros and Sinha, Animesh and Lee, Ann and Vyas, Apoorv and Shi, Bowen and Ma, Chih-Yao and Chuang, Ching-Yao and others",
        "title": "Movie gen: A cast of media foundation models"
      },
      {
        "key": "kong2024hunyuanvideo",
        "author": "Kong, Weijie and Tian, Qi and Zhang, Zijian and Min, Rox and Dai, Zuozhuo and Zhou, Jin and Xiong, Jiangfeng and Li, Xin and Wu, Bo and Zhang, Jianwei and others",
        "title": "HunyuanVideo: A Systematic Framework For Large Video Generative Models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "siarohin2019fomm",
        "author": "Siarohin, Aliaksandr and Lathuili{\\`e}re, St{\\'e}phane and Tulyakov, Sergey and Ricci, Elisa and Sebe, Nicu",
        "title": "First order motion model for image animation"
      },
      {
        "key": "zhao2022tps",
        "author": "Zhao, Jian and Zhang, Hui",
        "title": "Thin-plate spline motion model for image animation"
      },
      {
        "key": "siarohin2021mraa",
        "author": "Siarohin, Aliaksandr and Woodford, Oliver J and Ren, Jian and Chai, Menglei and Tulyakov, Sergey",
        "title": "Motion representations for articulated animation"
      },
      {
        "key": "jiang2024mobileportrait",
        "author": "Jiang, Jianwen and Lin, Gaojie and Rong, Zhengkun and Liang, Chao and Zhu, Yongming and Yang, Jiaqi and Zhong, Tianyun",
        "title": "Mobileportrait: Real-time one-shot neural head avatars on mobile devices"
      },
      {
        "key": "wang2021facev2v",
        "author": "Wang, Ting-Chun and Mallya, Arun and Liu, Ming-Yu",
        "title": "One-shot free-view neural talking-head synthesis for video conferencing"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "nagrani2017voxceleb",
        "author": "Nagrani, A and Chung, J and Zisserman, A",
        "title": "VoxCeleb: a large-scale speaker identification dataset"
      },
      {
        "key": "siarohin2019fomm",
        "author": "Siarohin, Aliaksandr and Lathuili{\\`e}re, St{\\'e}phane and Tulyakov, Sergey and Ricci, Elisa and Sebe, Nicu",
        "title": "First order motion model for image animation"
      },
      {
        "key": "xie2022vfhq",
        "author": "Xie, Liangbin and Wang, Xintao and Zhang, Honglun and Dong, Chao and Shan, Ying",
        "title": "Vfhq: A high-quality dataset and benchmark for video face super-resolution"
      },
      {
        "key": "zhu2022celebv",
        "author": "Zhu, Hao and Wu, Wayne and Zhu, Wentao and Jiang, Liming and Tang, Siwei and Zhang, Li and Liu, Ziwei and Loy, Chen Change",
        "title": "CelebV-HQ: A large-scale video facial attributes dataset"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "Disco",
        "author": "Wang, Tan and Li, Linjie and Lin, Kevin and Zhai, Yuanhao and Lin, Chung-Ching and Yang, Zhengyuan and Zhang, Hanwang and Liu, Zicheng and Wang, Lijuan",
        "title": "Disco: Disentangled control for realistic human dance generation"
      },
      {
        "key": "aa",
        "author": "Hu, Li",
        "title": "Animate anyone: Consistent and controllable image-to-video synthesis for character animation"
      },
      {
        "key": "champ",
        "author": "Zhu, Shenhao and Chen, Junming Leo and Dai, Zuozhuo and Dong, Zilong and Xu, Yinghui and Cao, Xun and Yao, Yao and Zhu, Hao and Zhu, Siyu",
        "title": "Champ: Controllable and consistent human image animation with 3d parametric guidance"
      },
      {
        "key": "shao2024human4dit",
        "author": "Shao, Ruizhi and Pang, Youxin and Zheng, Zerong and Sun, Jingxiang and Liu, Yebin",
        "title": "Human4DiT: Free-view Human Video Generation with 4D Diffusion Transformer"
      },
      {
        "key": "zhang2024mimicmotion",
        "author": "Zhang, Yuang and Gu, Jiaxi and Wang, Li-Wen and Wang, Han and Cheng, Junqi and Zhu, Yuefeng and Zou, Fangyuan",
        "title": "Mimicmotion: High-quality human motion video generation with confidence-aware pose guidance"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "adnerf",
        "author": "Guo, Yudong and Chen, Keyu and Liang, Sen and Liu, Yong-Jin and Bao, Hujun and Zhang, Juyong",
        "title": "Ad-nerf: Audio driven neural radiance fields for talking head synthesis"
      },
      {
        "key": "GeneFace",
        "author": "Unknown",
        "title": "Unknown"
      },
      {
        "key": "zhang2023sadtalker",
        "author": "Zhang, Wenxuan and Cun, Xiaodong and Wang, Xuan and Zhang, Yong and Shen, Xi and Guo, Yu and Shan, Ying and Wang, Fei",
        "title": "Sadtalker: Learning realistic 3d motion coefficients for stylized audio-driven single image talking face animation"
      },
      {
        "key": "EMO",
        "author": "Unknown",
        "title": "Unknown"
      },
      {
        "key": "jiang2024loopy",
        "author": "Jiang, Jianwen and Liang, Chao and Yang, Jiaqi and Lin, Gaojie and Zhong, Tianyun and Zheng, Yanbo",
        "title": "Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency"
      },
      {
        "key": "hallo3",
        "author": "Cui, Jiahao and Li, Hui and Zhan, Yun and Shang, Hanlin and Cheng, Kaihui and Ma, Yuqi and Mu, Shan and Zhou, Hang and Wang, Jingdong and Zhu, Siyu",
        "title": "Hallo3: Highly Dynamic and Realistic Portrait Image Animation with Diffusion Transformer Networks"
      },
      {
        "key": "fada",
        "author": "Zhong, Tianyun and Liang, Chao and Jiang, Jianwen and Lin, Gaojie and Yang, Jiaqi and Zhao, Zhou",
        "title": "FADA: Fast Diffusion Avatar Synthesis with Mixed-Supervised Multi-CFG Distillation"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "VLogger",
        "author": "Unknown",
        "title": "Unknown"
      },
      {
        "key": "lin2024cyberhost",
        "author": "Lin, Gaojie and Jiang, Jianwen and Liang, Chao and Zhong, Tianyun and Yang, Jiaqi and Zheng, Yanbo",
        "title": "CyberHost: Taming Audio-driven Avatar Diffusion Model with Region Codebook Attention"
      },
      {
        "key": "EchomimicV2",
        "author": "Unknown",
        "title": "Unknown"
      },
      {
        "key": "EMO2",
        "author": "Unknown",
        "title": "Unknown"
      },
      {
        "key": "diffted",
        "author": "Hogue, Steven and Zhang, Chenxu and Daruger, Hamza and Tian, Yapeng and Guo, Xiaohu",
        "title": "DiffTED: One-shot Audio-driven TED Talk Video Generation with Diffusion-based Co-speech Gestures"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "VLogger",
        "author": "Unknown",
        "title": "Unknown"
      },
      {
        "key": "EchomimicV2",
        "author": "Unknown",
        "title": "Unknown"
      },
      {
        "key": "EMO2",
        "author": "Unknown",
        "title": "Unknown"
      },
      {
        "key": "diffted",
        "author": "Hogue, Steven and Zhang, Chenxu and Daruger, Hamza and Tian, Yapeng and Guo, Xiaohu",
        "title": "DiffTED: One-shot Audio-driven TED Talk Video Generation with Diffusion-based Co-speech Gestures"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "lin2024cyberhost",
        "author": "Lin, Gaojie and Jiang, Jianwen and Liang, Chao and Zhong, Tianyun and Yang, Jiaqi and Zheng, Yanbo",
        "title": "CyberHost: Taming Audio-driven Avatar Diffusion Model with Region Codebook Attention"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "fada",
        "author": "Zhong, Tianyun and Liang, Chao and Jiang, Jianwen and Lin, Gaojie and Yang, Jiaqi and Zhao, Zhou",
        "title": "FADA: Fast Diffusion Avatar Synthesis with Mixed-Supervised Multi-CFG Distillation"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "VLogger",
        "author": "Unknown",
        "title": "Unknown"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "hallo3",
        "author": "Cui, Jiahao and Li, Hui and Zhan, Yun and Shang, Hanlin and Cheng, Kaihui and Ma, Yuqi and Mu, Shan and Zhou, Hang and Wang, Jingdong and Zhu, Siyu",
        "title": "Hallo3: Highly Dynamic and Realistic Portrait Image Animation with Diffusion Transformer Networks"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "cogvideox",
        "author": "Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others",
        "title": "Cogvideox: Text-to-video diffusion models with an expert transformer"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "ouyang2022training",
        "author": "Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others",
        "title": "Training language models to follow instructions with human feedback"
      },
      {
        "key": "touvron2023llama",
        "author": "Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others",
        "title": "Llama 2: Open foundation and fine-tuned chat models"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "liu2024improved",
        "author": "Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae",
        "title": "Improved baselines with visual instruction tuning"
      },
      {
        "key": "bai2023qwen",
        "author": "Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren",
        "title": "Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "esser2024scaling",
        "author": "Esser, Patrick and Kulal, Sumith and Blattmann, Andreas and Entezari, Rahim and M{\\\"u}ller, Jonas and Saini, Harry and Levi, Yam and Lorenz, Dominik and Sauer, Axel and Boesel, Frederic and others",
        "title": "Scaling rectified flow transformers for high-resolution image synthesis"
      },
      {
        "key": "flux2023",
        "author": "Black Forest Labs",
        "title": "FLUX"
      },
      {
        "key": "kondratyuk2023videopoet",
        "author": "Kondratyuk, Dan and Yu, Lijun and Gu, Xiuye and Lezama, Jos{\\'e} and Huang, Jonathan and Schindler, Grant and Hornung, Rachel and Birodkar, Vighnesh and Yan, Jimmy and Chiu, Ming-Chang and others",
        "title": "Videopoet: A large language model for zero-shot video generation"
      }
    ]
  }
]