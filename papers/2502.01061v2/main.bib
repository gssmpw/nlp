@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})


% Long form of conference & journal abbreviations -- especially for camera ready
@String(PAMI  = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV  = {Int. J. Comput. Vis.})
@String(CVPR  = {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV  = {Int. Conf. Comput. Vis.})
@String(ECCV  = {Eur. Conf. Comput. Vis.})
@String(NeurIPS = {Adv. Neural Inform. Process. Syst.})
@String(ICML  = {Int. Conf. Mach. Learn.})
@String(ICLR  = {Int. Conf. Learn. Represent.})
@String(ACCV  = {Asian Conf. Comput. Vis.})
@String(BMVC  = {Brit. Mach. Vis. Conf.})
@String(CVPRW = {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(AAAI  = {AAAI})
@String(IJCAI = {IJCAI})
@String(ICIP  = {IEEE Int. Conf. Image Process.})
@String(ICPR  = {Int. Conf. Pattern Recog.})
@String(ICASSP=	{ICASSP})
@String(ICME  = {Int. Conf. Multimedia and Expo})
@String(JMLR  = {J. Mach. Learn. Res.})
@String(TMLR  = {Trans. Mach. Learn Res.})
@String(TOG   = {ACM Trans. Graph.})
@String(TIP   = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TCSVT = {IEEE Trans. Circuit Syst. Video Technol.})
@String(TMM   = {IEEE Trans. Multimedia})
@String(ACMMM = {ACM Int. Conf. Multimedia})
@String(PR    = {Pattern Recognition})

@String(MNI	  = {Nature Mach. Intell.})
@String(SPL	  = {IEEE Sign. Process. Letters})
@String(VR    = {Vis. Res.})
@String(JOV	  = {J. Vis.})
@String(TVC   = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF   = {Comput. Graph. Forum})
@String(CVM   = {Computational Visual Media})


% Short form of conference & journal abbreviations -- especially for submission version
% if desired, remove these macros in favor of the above ones
@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NeurIPS = {NeurIPS})
@String(ICML  = {ICML})
@String(ICLR  = {ICLR})
@String(ACCV  = {ACCV})
@String(BMVC  =	{BMVC})
@String(CVPRW = {CVPRW})
@String(AAAI  = {AAAI})
@String(IJCAI = {IJCAI})
@String(ICIP  = {ICIP})
@String(ICPR  = {ICPR})
@String(ICASSP=	{ICASSP})
@String(ICME  =	{ICME})
@String(JMLR  = {JMLR})
@String(TMLR  = {TMLR})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(PR    = {PR})
@article{zhong2024fada,
  title={FADA: Fast Diffusion Avatar Synthesis with Mixed-Supervised Multi-CFG Distillation},
  author={Zhong, Tianyun and Liang, Chao and Jiang, Jianwen and Lin, Gaojie and Yang, Jiaqi and Zhao, Zhou},
  journal={arXiv preprint arXiv:2412.16915},
  year={2024}
}

@article{nan2024openvid,
  title={Openvid-1m: A large-scale high-quality dataset for text-to-video generation},
  author={Nan, Kepan and Xie, Rui and Zhou, Penghao and Fan, Tiehan and Yang, Zhenheng and Chen, Zhijie and Li, Xiang and Yang, Jian and Tai, Ying},
  journal={arXiv preprint arXiv:2407.02371},
  year={2024}
}

@inproceedings{chen2024panda,
  title={Panda-70m: Captioning 70m videos with multiple cross-modality teachers},
  author={Chen, Tsai-Shien and Siarohin, Aliaksandr and Menapace, Willi and Deyneka, Ekaterina and Chao, Hsiang-wei and Jeon, Byung Eun and Fang, Yuwei and Lee, Hsin-Ying and Ren, Jian and Yang, Ming-Hsuan and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13320--13331},
  year={2024}
}

@article{rope,
  title={Roformer: Enhanced transformer with rotary position embedding},
  author={Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  journal={Neurocomputing},
  volume={568},
  pages={127063},
  year={2024},
  publisher={Elsevier}
}

@article{lipman2022flow,
  title={Flow matching for generative modeling},
  author={Lipman, Yaron and Chen, Ricky TQ and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt},
  journal={arXiv preprint arXiv:2210.02747},
  year={2022}
}

@article{navit,
  title={Patch nâ€™pack: Navit, a vision transformer for any aspect ratio and resolution},
  author={Dehghani, Mostafa and Mustafa, Basil and Djolonga, Josip and Heek, Jonathan and Minderer, Matthias and Caron, Mathilde and Steiner, Andreas and Puigcerver, Joan and Geirhos, Robert and Alabdulmohsin, Ibrahim M and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{dit,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4195--4205},
  year={2023}
}

@inproceedings{zhao2022thin,
  title={Thin-plate spline motion model for image animation},
  author={Zhao, Jian and Zhang, Hui},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3657--3666},
  year={2022}
}
@article{nagrani2017voxceleb,
  title={VoxCeleb: a large-scale speaker identification dataset},
  author={Nagrani, A and Chung, J and Zisserman, A},
  journal={Interspeech 2017},
  year={2017},
  publisher={ISCA}
}
@inproceedings{mraa,
  title={Motion representations for articulated animation},
  author={Siarohin, Aliaksandr and Woodford, Oliver J and Ren, Jian and Chai, Menglei and Tulyakov, Sergey},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13653--13662},
  year={2021}
}
@inproceedings{vfhq,
  title={Vfhq: A high-quality dataset and benchmark for video face super-resolution},
  author={Xie, Liangbin and Wang, Xintao and Zhang, Honglun and Dong, Chao and Shan, Ying},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={657--666},
  year={2022}
}
@inproceedings{facev2v,
  title={One-shot free-view neural talking-head synthesis for video conferencing},
  author={Wang, Ting-Chun and Mallya, Arun and Liu, Ming-Yu},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10039--10049},
  year={2021}
}
@inproceedings{Disco,
  title={Disco: Disentangled control for realistic human dance generation},
  author={Wang, Tan and Li, Linjie and Lin, Kevin and Zhai, Yuanhao and Lin, Chung-Ching and Yang, Zhengyuan and Zhang, Hanwang and Liu, Zicheng and Wang, Lijuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9326--9336},
  year={2024}
}
@article{shao2024human4dit,
  title={Human4DiT: Free-view Human Video Generation with 4D Diffusion Transformer},
  author={Shao, Ruizhi and Pang, Youxin and Zheng, Zerong and Sun, Jingxiang and Liu, Yebin},
  journal={arXiv preprint arXiv:2405.17405},
  year={2024}
}
@inproceedings{champ,
  title={Champ: Controllable and consistent human image animation with 3d parametric guidance},
  author={Zhu, Shenhao and Chen, Junming Leo and Dai, Zuozhuo and Dong, Zilong and Xu, Yinghui and Cao, Xun and Yao, Yao and Zhu, Hao and Zhu, Siyu},
  booktitle={European Conference on Computer Vision},
  pages={145--162},
  year={2025},
  organization={Springer}
}
@inproceedings{adnerf,
  title={Ad-nerf: Audio driven neural radiance fields for talking head synthesis},
  author={Guo, Yudong and Chen, Keyu and Liang, Sen and Liu, Yong-Jin and Bao, Hujun and Zhang, Juyong},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={5784--5794},
  year={2021}
}
@inproceedings{geneface,
  title={GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis},
  author={Ye, Zhenhui and Jiang, Ziyue and Ren, Yi and Liu, Jinglin and He, Jinzheng and Zhao, Zhou},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}


@article{fada,
  title={FADA: Fast Diffusion Avatar Synthesis with Mixed-Supervised Multi-CFG Distillation},
  author={Zhong, Tianyun and Liang, Chao and Jiang, Jianwen and Lin, Gaojie and Yang, Jiaqi and Zhao, Zhou},
  journal={arXiv preprint arXiv:2412.16915},
  year={2024}
}
@inproceedings{emo,
  title={EMO: Emote Portrait Alive Generating Expressive Portrait Videos with Audio2Video Diffusion Model Under Weak Conditions},
  author={Tian, Linrui and Wang, Qi and Zhang, Bang and Bo, Liefeng},
  booktitle={European Conference on Computer Vision},
  pages={244--260},
  year={2025},
  organization={Springer}
}
@article{hallo3,
  title={Hallo3: Highly Dynamic and Realistic Portrait Image Animation with Diffusion Transformer Networks},
  author={Cui, Jiahao and Li, Hui and Zhan, Yun and Shang, Hanlin and Cheng, Kaihui and Ma, Yuqi and Mu, Shan and Zhou, Hang and Wang, Jingdong and Zhu, Siyu},
  journal={arXiv preprint arXiv:2412.00733},
  year={2024}
}
@article{vlogger,
  title={VLOGGER: Multimodal diffusion for embodied avatar synthesis},
  author={Corona, Enric and Zanfir, Andrei and Bazavan, Eduard Gabriel and Kolotouros, Nikos and Alldieck, Thiemo and Sminchisescu, Cristian},
  journal={arXiv preprint arXiv:2403.08764},
  year={2024}
}
@article{echomimicv2,
  title={EchoMimicV2: Towards Striking, Simplified, and Semi-Body Human Animation},
  author={Meng, Rang and Zhang, Xingyu and Li, Yuming and Ma, Chenguang},
  journal={arXiv preprint arXiv:2411.10061},
  year={2024}
}
@article{emo2,
  title={EMO2: End-Effector Guided Audio-Driven Avatar Video Generation},
  author={Tian, Linrui and Hu, Siqi and Wang, Qi and Zhang, Bang and Bo, Liefeng},
  journal={arXiv preprint arXiv:2501.10687},
  year={2025}
}
@inproceedings{diffted,
  title={DiffTED: One-shot Audio-driven TED Talk Video Generation with Diffusion-based Co-speech Gestures},
  author={Hogue, Steven and Zhang, Chenxu and Daruger, Hamza and Tian, Yapeng and Guo, Xiaohu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1922--1931},
  year={2024}
}
@article{cogvideox,
  title={Cogvideox: Text-to-video diffusion models with an expert transformer},
  author={Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others},
  journal={arXiv preprint arXiv:2408.06072},
  year={2024}
}
@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}
@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}
@inproceedings{liu2024improved,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26296--26306},
  year={2024}
}
@article{bai2023qwen,
  title={Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.12966},
  volume={1},
  number={2},
  pages={3},
  year={2023}
}
@inproceedings{esser2024scaling,
  title={Scaling rectified flow transformers for high-resolution image synthesis},
  author={Esser, Patrick and Kulal, Sumith and Blattmann, Andreas and Entezari, Rahim and M{\"u}ller, Jonas and Saini, Harry and Levi, Yam and Lorenz, Dominik and Sauer, Axel and Boesel, Frederic and others},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}
@misc{flux2023,
    author={Black Forest Labs},
    title={FLUX},
    year={2023},
    howpublished={\url{https://github.com/black-forest-labs/flux}},
}
@article{kondratyuk2023videopoet,
  title={Videopoet: A large language model for zero-shot video generation},
  author={Kondratyuk, Dan and Yu, Lijun and Gu, Xiuye and Lezama, Jos{\'e} and Huang, Jonathan and Schindler, Grant and Hornung, Rachel and Birodkar, Vighnesh and Yan, Jimmy and Chiu, Ming-Chang and others},
  journal={arXiv preprint arXiv:2312.14125},
  year={2023}
}
@inproceedings{zhu2022celebv,
  title={CelebV-HQ: A large-scale video facial attributes dataset},
  author={Zhu, Hao and Wu, Wayne and Zhu, Wentao and Jiang, Liming and Tang, Siwei and Zhang, Li and Liu, Ziwei and Loy, Chen Change},
  booktitle={European conference on computer vision},
  pages={650--667},
  year={2022},
  organization={Springer}
}
@article{chen2024echomimic,
  title={Echomimic: Lifelike audio-driven portrait animations through editable landmark conditions},
  author={Chen, Zhiyuan and Cao, Jiajiong and Chen, Zhiquan and Li, Yuming and Ma, Chenguang},
  journal={arXiv preprint arXiv:2407.08136},
  year={2024}
}
@article{zhang2024mimicmotion,
  title={Mimicmotion: High-quality human motion video generation with confidence-aware pose guidance},
  author={Zhang, Yuang and Gu, Jiaxi and Wang, Li-Wen and Wang, Han and Cheng, Junqi and Zhu, Yuefeng and Zou, Fangyuan},
  journal={arXiv preprint arXiv:2406.19680},
  year={2024}
}
@article{unterthiner2019fvd,
  title={FVD: A new metric for video generation},
  author={Unterthiner, Thomas and van Steenkiste, Sjoerd and Kurach, Karol and Marinier, Rapha{\"e}l and Michalski, Marcin and Gelly, Sylvain}
}
@article{wu2023q,
  title={Q-align: Teaching lmms for visual scoring via discrete text-defined levels},
  author={Wu, Haoning and Zhang, Zicheng and Zhang, Weixia and Chen, Chaofeng and Liao, Liang and Li, Chunyi and Gao, Yixuan and Wang, Annan and Zhang, Erli and Sun, Wenxiu and others},
  journal={arXiv preprint arXiv:2312.17090},
  year={2023}
}
@article{heusel2017gans,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{sd3,
  title={Scaling rectified flow transformers for high-resolution image synthesis},
  author={Esser, Patrick and Kulal, Sumith and Blattmann, Andreas and Entezari, Rahim and M{\"u}ller, Jonas and Saini, Harry and Levi, Yam and Lorenz, Dominik and Sauer, Axel and Boesel, Frederic and others},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}
 @article{jiang2024loopy,
            title={Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency},
            author={Jiang, Jianwen and Liang, Chao and Yang, Jiaqi and Lin, Gaojie and Zhong, Tianyun and Zheng, Yanbo},
            journal={arXiv preprint arXiv:2409.02634},
            year={2024}
          }

          @article{lin2024cyberhost,
            title={CyberHost: Taming Audio-driven Avatar Diffusion Model with Region Codebook Attention},
            author={Lin, Gaojie and Jiang, Jianwen and Liang, Chao and Zhong, Tianyun and Yang, Jiaqi and Zheng, Yanbo},
            journal={arXiv preprint arXiv:2409.01876},
            year={2024}
          }

@article{jiang2024mobileportrait,
  title={Mobileportrait: Real-time one-shot neural head avatars on mobile devices},
  author={Jiang, Jianwen and Lin, Gaojie and Rong, Zhengkun and Liang, Chao and Zhu, Yongming and Yang, Jiaqi and Zhong, Tianyun},
  journal={arXiv preprint arXiv:2407.05712},
  year={2024}
}
@article{emoji,
title={Follow-Your-Emoji: Fine-Controllable and Expressive Freestyle Portrait Animation},
author={Ma, Yue and Liu, Hongyu and Wang, Hongfa and Pan, Heng and He, Yingqing and Yuan, Junkun and Zeng, Ailing and Cai, Chengfei and Shum, Heung-Yeung and Liu, Wei and others},
journal={arXiv preprint arXiv:2406.01900},
year={2024}
}
@inproceedings{syncnet,
  title={Out of time: automated lip sync in the wild},
  author={Chung, Joon Son and Zisserman, Andrew},
  booktitle={Computer Vision--ACCV 2016 Workshops: ACCV 2016 International Workshops, Taipei, Taiwan, November 20-24, 2016, Revised Selected Papers, Part II 13},
  pages={251--263},
  year={2017},
  organization={Springer}
}

@article{ye2024real3d,
  title={Real3d-portrait: One-shot realistic 3d talking portrait synthesis},
  author={Ye, Zhenhui and Zhong, Tianyun and Ren, Yi and Yang, Jiaqi and Li, Weichuang and Huang, Jiawei and Jiang, Ziyue and He, Jinzheng and Huang, Rongjie and Liu, Jinglin and others},
  journal={arXiv preprint arXiv:2401.08503},
  year={2024}
}

@inproceedings{jonathan2020ddpm,
    author      = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
    booktitle   = {Advances in Neural Information Processing Systems},
    editor      = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
    pages       = {6840--6851},
    publisher   = {Curran Associates, Inc.},
    title       = {Denoising Diffusion Probabilistic Models},
    url         = {https://proceedings.neurips.cc/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf},
    volume      = {33},
    year        = {2020}
}

@inproceedings{song2021ddim,
title={Denoising Diffusion Implicit Models},
author={Jiaming Song and Chenlin Meng and Stefano Ermon},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=St1giarCHLP}
}

@article{karras2022edm,
  title={Elucidating the design space of diffusion-based generative models},
  author={Karras, Tero and Aittala, Miika and Aila, Timo and Laine, Samuli},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={26565--26577},
  year={2022}
}

@article{song2020score,
  title={Score-based generative modeling through stochastic differential equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  journal={arXiv preprint arXiv:2011.13456},
  year={2020}
}

@article{liu2022reflow,
    title   = {Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow},
    author  = {Xingchao Liu and Chengyue Gong and Qiang Liu},
    journal = {ArXiv},
    year    = {2022},
    volume  = {abs/2209.03003},
    url     = {https://api.semanticscholar.org/CorpusID:252111177}
}


@article{yu20233DVAE,
  title={Language Model Beats Diffusion--Tokenizer is Key to Visual Generation},
  author={Yu, Lijun and Lezama, Jos and Gundavarapu, Nitesh B and Versari, Luca and Sohn, Kihyuk and Minnen, David and Cheng, Yong and Birodkar, Vighnesh and Gupta, Agrim and Gu, Xiuye and others},
  journal={arXiv preprint arXiv:2310.05737},
  year={2023}
}

@article{singer2022make,
  title={Make-a-video: Text-to-video generation without text-video data},
  author={Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and others},
  journal={arXiv preprint arXiv:2209.14792},
  year={2022}
}

@article{qi2023fatezero,
        title={FateZero: Fusing Attentions for Zero-shot Text-based Video Editing}, 
        author={Chenyang Qi and Xiaodong Cun and Yong Zhang and Chenyang Lei and Xintao Wang and Ying Shan and Qifeng Chen},
        year={2023},
        journal={arXiv:2303.09535},
}
  

@inproceedings{wu2023tune,
    title={Tune-a-video: One-shot tuning of image diffusion models for text-to-video generation},
    author={Wu, Jay Zhangjie and Ge, Yixiao and Wang, Xintao and Lei, Stan Weixian and Gu, Yuchao and Shi, Yufei and Hsu, Wynne and Shan, Ying and Qie, Xiaohu and Shou, Mike Zheng},
    booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
    pages={7623--7633},
    year={2023}
}       

@misc{chen2024videocrafter2,
      title={VideoCrafter2: Overcoming Data Limitations for High-Quality Video Diffusion Models}, 
      author={Haoxin Chen and Yong Zhang and Xiaodong Cun and Menghan Xia and Xintao Wang and Chao Weng and Ying Shan},
      year={2024},
      eprint={2401.09047},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

   
@misc{rombach2021sd1,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and BjÃ¶rn Ommer},
      year={2021},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{chen2024pixartdelta,
      title={PIXART-Delta: Fast and Controllable Image Generation with Latent Consistency Models}, 
      author={Junsong Chen and Yue Wu and Simian Luo and Enze Xie and Sayak Paul and Ping Luo and Hang Zhao and Zhenguo Li},
      year={2024},
      eprint={2401.05252},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{esser2024sd3,
  title={Scaling rectified flow transformers for high-resolution image synthesis},
  author={Esser, Patrick and Kulal, Sumith and Blattmann, Andreas and Entezari, Rahim and M{\"u}ller, Jonas and Saini, Harry and Levi, Yam and Lorenz, Dominik and Sauer, Axel and Boesel, Frederic and others},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@article{zhou2022magicvideo,
  title={Magicvideo: Efficient video generation with latent diffusion models},
  author={Zhou, Daquan and Wang, Weimin and Yan, Hanshu and Lv, Weiwei and Zhu, Yizhe and Feng, Jiashi},
  journal={arXiv preprint arXiv:2211.11018},
  year={2022}
}

@article{blattmann2023svd,
  title={Stable video diffusion: Scaling latent video diffusion models to large datasets},
  author={Blattmann, Andreas and Dockhorn, Tim and Kulal, Sumith and Mendelevitch, Daniel and Kilian, Maciej and Lorenz, Dominik and Levi, Yam and English, Zion and Voleti, Vikram and Letts, Adam and others},
  journal={arXiv preprint arXiv:2311.15127},
  year={2023}
}


@article{openai2024sora,
  author = {Tim, Brooks and Bill, Peebles and Connorm Holmes and Will, DePue and Yufeim Guo and Li, Jing and David, Schnurr and Joe, Taylor and Troy, Luhman and Eric, Luhman and Clarence, Ng and Ricky, Wang and Aditya, Ramesh},
  title = {Video generation models as world simulators},
  year = {2024},
  note = {Accessed: 2024-02-15},
  url = {https://openai.com/index/sora/}
}

@software{opensora,
  author = {Zangwei Zheng and Xiangyu Peng and Tianji Yang and Chenhui Shen and Shenggui Li and Hongxin Liu and Yukun Zhou and Tianyi Li and Yang You},
  title = {Open-Sora: Democratizing Efficient Video Production for All},
  month = {March},
  year = {2024},
  url = {https://github.com/hpcaitech/Open-Sora}
}

@article{lin2024open,
  title={Open-Sora Plan: Open-Source Large Video Generation Model},
  author={Lin, Bin and Ge, Yunyang and Cheng, Xinhua and Li, Zongjian and Zhu, Bin and Wang, Shaodong and He, Xianyi and Ye, Yang and Yuan, Shenghai and Chen, Liuhan and others},
  journal={arXiv preprint arXiv:2412.00131},
  year={2024}
}


@article{hong2022cogvideo,
  title={CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers},
  author={Hong, Wenyi and Ding, Ming and Zheng, Wendi and Liu, Xinghan and Tang, Jie},
  journal={arXiv preprint arXiv:2205.15868},
  year={2022}
}

@article{yang2024cogvideox,
  title={CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer},
  author={Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others},
  journal={arXiv preprint arXiv:2408.06072},
  year={2024}
}

@article{lin2025apt,
  title={Diffusion Adversarial Post-Training for One-Step Video Generation},
  author={Lin, Shanchuan and Xia, Xin and Ren, Yuxi and Yang, Ceyuan and Xiao, Xuefeng and Jiang, Lu},
  journal={arXiv preprint arXiv:2501.08316},
  year={2025}
}

@inproceedings{zeng2024pxldance,
  title={Make pixels dance: High-dynamic video generation},
  author={Zeng, Yan and Wei, Guoqiang and Zheng, Jiani and Zou, Jiaxin and Wei, Yang and Zhang, Yuchen and Li, Hang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8850--8860},
  year={2024}
}

@article{polyak2024moviegen,
  title={Movie gen: A cast of media foundation models},
  author={Polyak, Adam and Zohar, Amit and Brown, Andrew and Tjandra, Andros and Sinha, Animesh and Lee, Ann and Vyas, Apoorv and Shi, Bowen and Ma, Chih-Yao and Chuang, Ching-Yao and others},
  journal={arXiv preprint arXiv:2410.13720},
  year={2024}
}

@article{kong2024hunyuanvideo,
  title={HunyuanVideo: A Systematic Framework For Large Video Generative Models},
  author={Kong, Weijie and Tian, Qi and Zhang, Zijian and Min, Rox and Dai, Zuozhuo and Zhou, Jin and Xiong, Jiangfeng and Li, Xin and Wu, Bo and Zhang, Jianwei and others},
  journal={arXiv preprint arXiv:2412.03603},
  year={2024}
}

@article{ho2022video,
      title={Video diffusion models},
      author={Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J},
      journal={Advances in Neural Information Processing Systems (NeurIPS)},
      volume={35},
      pages={8633--8646},
      year={2022}
}

@article{wang2023videocomposer,
      title={Videocomposer: Compositional video synthesis with motion controllability},
      author={Wang, Xiang and Yuan, Hangjie and Zhang, Shiwei and Chen, Dayou and Wang, Jiuniu and Zhang, Yingya and Shen, Yujun and Zhao, Deli and Zhou, Jingren},
      journal={Advances in Neural Information Processing Systems (NeurIPS)},
      volume={36},
      year={2024}
}

@inproceedings{guo2024animatediff,
      title={AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning},
      author={Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Liang, Zhengyang and Wang, Yaohui and Qiao, Yu and Agrawala, Maneesh and Lin, Dahua and Dai, Bo},
      booktitle={International Conference on Learning Representations (ICLR)},
      year={2023}
}


@inproceedings{mraa,
  title={Motion representations for articulated animation},
  author={Siarohin, Aliaksandr and Woodford, Oliver J and Ren, Jian and Chai, Menglei and Tulyakov, Sergey},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13653--13662},
  year={2021}
}


@article{fomm,
  title={First order motion model for image animation},
  author={Siarohin, Aliaksandr and Lathuili{\`e}re, St{\'e}phane and Tulyakov, Sergey and Ricci, Elisa and Sebe, Nicu},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}


@inproceedings{text2video,
  title={Video generation from text},
  author={Li, Yitong and Min, Martin and Shen, Dinghan and Carlson, David and Carin, Lawrence},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{villegas2022phenaki,
  title={Phenaki: Variable length video generation from open domain textual descriptions},
  author={Villegas, Ruben and Babaeizadeh, Mohammad and Kindermans, Pieter-Jan and Moraldo, Hernan and Zhang, Han and Saffar, Mohammad Taghi and Castro, Santiago and Kunze, Julius and Erhan, Dumitru},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@inproceedings{cvideogan,
  title={Imaginator: Conditional spatio-temporal gan for video generation},
  author={Wang, Yaohui and Bilinski, Piotr and Bremond, Francois and Dantcheva, Antitza},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={1160--1169},
  year={2020}
}

@article{videogan,
  title={Generating long videos of dynamic scenes},
  author={Brooks, Tim and Hellsten, Janne and Aittala, Miika and Wang, Ting-Chun and Aila, Timo and Lehtinen, Jaakko and Liu, Ming-Yu and Efros, Alexei and Karras, Tero},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={31769--31781},
  year={2022}
}


@inproceedings{huang2024vbench,
  title={Vbench: Comprehensive benchmark suite for video generative models},
  author={Huang, Ziqi and He, Yinan and Yu, Jiashuo and Zhang, Fan and Si, Chenyang and Jiang, Yuming and Zhang, Yuanhan and Wu, Tianxing and Jin, Qingyang and Chanpaisit, Nattapol and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={21807--21818},
  year={2024}
}

@article{qalign,
  title={Q-align: Teaching lmms for visual scoring via discrete text-defined levels},
  author={Wu, Haoning and Zhang, Zicheng and Zhang, Weixia and Chen, Chaofeng and Liao, Liang and Li, Chunyi and Gao, Yixuan and Wang, Annan and Zhang, Erli and Sun, Wenxiu and others},
  journal={arXiv preprint arXiv:2312.17090},
  year={2023}
}

@inproceedings{dwpose,
  title={Effective whole-body pose estimation with two-stages distillation},
  author={Yang, Zhendong and Zeng, Ailing and Yuan, Chun and Li, Yu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4210--4220},
  year={2023}
}

@article{adamw,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@article{cfg,
  title={Classifier-free diffusion guidance},
  author={Ho, Jonathan and Salimans, Tim},
  journal={arXiv preprint arXiv:2207.12598},
  year={2022}
}

@article{wang2022latent,
  title={Latent image animator: Learning to animate images via latent space navigation},
  author={Wang, Yaohui and Yang, Di and Bremond, Francois and Dantcheva, Antitza},
  journal={arXiv preprint arXiv:2203.09043},
  year={2022}
}

@misc{ravdess_dataset,
  author       = {Kaggle},
  title        = {RAVDESS Emotional Speech Audio},
  howpublished = {\url{https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio}},
}

@inproceedings{wang2020mead,
  title={Mead: A large-scale audio-visual dataset for emotional talking-face generation},
  author={Wang, Kaisiyuan and Wu, Qianyi and Song, Linsen and Yang, Zhuoqian and Wu, Wayne and Qian, Chen and He, Ran and Qiao, Yu and Loy, Chen Change},
  booktitle={European Conference on Computer Vision},
  pages={700--717},
  year={2020},
  organization={Springer}
}

@inproceedings{hdtf,
  title={Flow-Guided One-Shot Talking Face Generation With a High-Resolution Audio-Visual Dataset},
  author={Zhang, Zhimeng and Li, Lincheng and Ding, Yu and Fan, Changjie},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3661--3670},
  year={2021}
}



@inproceedings{zhu2023tryondiffusion,
  title={Tryondiffusion: A tale of two unets},
  author={Zhu, Luyang and Yang, Dawei and Zhu, Tyler and Reda, Fitsum and Chan, William and Saharia, Chitwan and Norouzi, Mohammad and Kemelmacher-Shlizerman, Ira},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4606--4615},
  year={2023}
}

@article{baevski2020wav2vec2,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}

@article{schneider2019wav2vec,
  title={wav2vec: Unsupervised pre-training for speech recognition},
  author={Schneider, Steffen and Baevski, Alexei and Collobert, Ronan and Auli, Michael},
  journal={arXiv preprint arXiv:1904.05862},
  year={2019}
}


@article{ddim,
  title={Denoising diffusion implicit models},
  author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  journal={arXiv preprint arXiv:2010.02502},
  year={2020}
}

@article{ddpm,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@article{vae,
  title={Auto-Encoding Variational Bayes},
  author={Kingma, DP},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{vqvae,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@inproceedings{ldm,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}
@inproceedings{drobyshev2022megaportraits,
  title={Megaportraits: One-shot megapixel neural head avatars},
  author={Drobyshev, Nikita and Chelishev, Jenya and Khakhulin, Taras and Ivakhnenko, Aleksei and Lempitsky, Victor and Zakharov, Egor},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={2663--2671},
  year={2022}
}

@inproceedings{ren2021pirenderer,
  title={Pirenderer: Controllable portrait image generation via semantic neural rendering},
  author={Ren, Yurui and Li, Ge and Chen, Yuanqi and Li, Thomas H and Liu, Shan},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={13759--13768},
  year={2021}
}

@article{zhang2023dream,
  title={Dream-talk: diffusion-based realistic emotional audio-driven method for single image talking face generation},
  author={Zhang, Chenxu and Wang, Chao and Zhang, Jianfeng and Xu, Hongyi and Song, Guoxian and Xie, You and Luo, Linjie and Tian, Yapeng and Guo, Xiaohu and Feng, Jiashi},
  journal={arXiv preprint arXiv:2312.13578},
  year={2023}
}

@article{ma2023dreamtalk,
  title={Dreamtalk: When expressive talking head generation meets diffusion probabilistic models},
  author={Ma, Yifeng and Zhang, Shiwei and Wang, Jiayu and Wang, Xiang and Zhang, Yingya and Deng, Zhidong},
  journal={arXiv preprint arXiv:2312.09767},
  year={2023}
}

@inproceedings{wang2021facevid2vid,
title={One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing},
author={Ting-Chun Wang and Arun Mallya and Ming-Yu Liu},
booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
year={2021}
}

@InProceedings{gcavt,
    author    = {Liang, Borong and Pan, Yan and Guo, Zhizhi and Zhou, Hang and Hong, Zhibin and Han, Xiaoguang and Han, Junyu and Liu, Jingtuo and Ding, Errui and Wang, Jingdong},
    title     = {Expressive Talking Head Generation With Granular Audio-Visual Control},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {3387-3396}
}

@article{zhou2020makelttalk,
  title={Makelttalk: speaker-aware talking-head animation},
  author={Zhou, Yang and Han, Xintong and Shechtman, Eli and Echevarria, Jose and Kalogerakis, Evangelos and Li, Dingzeyu},
  journal={ACM Transactions On Graphics (TOG)},
  volume={39},
  number={6},
  pages={1--15},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@inproceedings{zhang2023sadtalker,
  title={Sadtalker: Learning realistic 3d motion coefficients for stylized audio-driven single image talking face animation},
  author={Zhang, Wenxuan and Cun, Xiaodong and Wang, Xuan and Zhang, Yong and Shen, Xi and Guo, Yu and Shan, Ying and Wang, Fei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8652--8661},
  year={2023}
}

@inproceedings{prajwal2020wav2lip,
  title={A lip sync expert is all you need for speech to lip generation in the wild},
  author={Prajwal, KR and Mukhopadhyay, Rudrabha and Namboodiri, Vinay P and Jawahar, CV},
  booktitle={Proceedings of the 28th ACM international conference on multimedia},
  pages={484--492},
  year={2020}
}

@inproceedings{zhu2023taming,
  title={Taming diffusion models for audio-driven co-speech gesture generation},
  author={Zhu, Lingting and Liu, Xian and Liu, Xuanyu and Qian, Rui and Liu, Ziwei and Yu, Lequan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10544--10553},
  year={2023}
}

@article{corona2024vlogger,
  title={VLOGGER: Multimodal diffusion for embodied avatar synthesis},
  author={Corona, Enric and Zanfir, Andrei and Bazavan, Eduard Gabriel and Kolotouros, Nikos and Alldieck, Thiemo and Sminchisescu, Cristian},
  journal={arXiv preprint arXiv:2403.08764},
  year={2024}
}
@inproceedings{aa,
  title={Animate anyone: Consistent and controllable image-to-video synthesis for character animation},
  author={Hu, Li},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8153--8163},
  year={2024}
}
@inproceedings{stypulkowski2024diffused,
  title={Diffused heads: Diffusion models beat gans on talking-face generation},
  author={Stypulkowski, Michal and Vougioukas, Konstantinos and He, Sen and Zieba, Maciej and Petridis, Stavros and Pantic, Maja},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={5091--5100},
  year={2024}
}
@article{xu2024vasa,
  title={Vasa-1: Lifelike audio-driven talking faces generated in real time},
  author={Xu, Sicheng and Chen, Guojun and Guo, Yu-Xiao and Yang, Jiaolong and Li, Chong and Zang, Zhenyu and Zhang, Yizhong and Tong, Xin and Guo, Baining},
  journal={arXiv preprint arXiv:2404.10667},
  year={2024}
}

@article{he2023gaia,
  title={Gaia: Zero-shot talking avatar generation},
  author={He, Tianyu and Guo, Junliang and Yu, Runyi and Wang, Yuchi and Zhu, Jialiang and An, Kaikai and Li, Leyi and Tan, Xu and Wang, Chunyu and Hu, Han and others},
  journal={arXiv preprint arXiv:2311.15230},
  year={2023}
}


@article{wang2024vexpress,
  title={V-Express: Conditional Dropout for Progressive Training of Portrait Video Generation},
  author={Wang, Cong and Tian, Kuan and Zhang, Jun and Guan, Yonghang and Luo, Feng and Shen, Fei and Jiang, Zhiwei and Gu, Qing and Han, Xiao and Yang, Wei},
  journal={arXiv preprint arXiv:2406.02511},
  year={2024}
}

@article{xu2024hallo,
  title={Hallo: Hierarchical Audio-Driven Visual Synthesis for Portrait Image Animation},
  author={Xu, Mingwang and Li, Hui and Su, Qingkun and Shang, Hanlin and Zhang, Liwei and Liu, Ce and Wang, Jingdong and Van Gool, Luc and Yao, Yao and Zhu, Siyu},
  journal={arXiv preprint arXiv:2406.08801},
  year={2024}
}

@article{tian2024emo,
  title={Emo: Emote portrait alive-generating expressive portrait videos with audio2video diffusion model under weak conditions},
  author={Tian, Linrui and Wang, Qi and Zhang, Bang and Bo, Liefeng},
  journal={arXiv preprint arXiv:2402.17485},
  year={2024}
}

@article{vdm,
  title={Video diffusion models},
  author={Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={8633--8646},
  year={2022}
}


@article{wang2023modelscope,
  title={Modelscope text-to-video technical report},
  author={Wang, Jiuniu and Yuan, Hangjie and Chen, Dayou and Zhang, Yingya and Wang, Xiang and Zhang, Shiwei},
  journal={arXiv preprint arXiv:2308.06571},
  year={2023}
}

@article{bar2024lumiere,
  title={Lumiere: A space-time diffusion model for video generation},
  author={Bar-Tal, Omer and Chefer, Hila and Tov, Omer and Herrmann, Charles and Paiss, Roni and Zada, Shiran and Ephrat, Ariel and Hur, Junhwa and Li, Yuanzhen and Michaeli, Tomer and others},
  journal={arXiv preprint arXiv:2401.12945},
  year={2024}
}

@article{guo2023animatediff,
  title={Animatediff: Animate your personalized text-to-image diffusion models without specific tuning},
  author={Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Liang, Zhengyang and Wang, Yaohui and Qiao, Yu and Agrawala, Maneesh and Lin, Dahua and Dai, Bo},
  journal={arXiv preprint arXiv:2307.04725},
  year={2023}
}

@inproceedings{ayl,
  title={Align your latents: High-resolution video synthesis with latent diffusion models},
  author={Blattmann, Andreas and Rombach, Robin and Ling, Huan and Dockhorn, Tim and Kim, Seung Wook and Fidler, Sanja and Kreis, Karsten},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22563--22575},
  year={2023}
}

@article{svd,
  title={Stable video diffusion: Scaling latent video diffusion models to large datasets},
  author={Blattmann, Andreas and Dockhorn, Tim and Kulal, Sumith and Mendelevitch, Daniel and Kilian, Maciej and Lorenz, Dominik and Levi, Yam and English, Zion and Voleti, Vikram and Letts, Adam and others},
  journal={arXiv preprint arXiv:2311.15127},
  year={2023}
}

@article{walt,
  title={Photorealistic video generation with diffusion models},
  author={Gupta, Agrim and Yu, Lijun and Sohn, Kihyuk and Gu, Xiuye and Hahn, Meera and Fei-Fei, Li and Essa, Irfan and Jiang, Lu and Lezama, Jos{\'e}},
  journal={arXiv preprint arXiv:2312.06662},
  year={2023}
}

@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}


@inproceedings{su2020blindly,
  title={Blindly assess image quality in the wild guided by a self-adaptive hyper network},
  author={Su, Shaolin and Yan, Qingsen and Zhu, Yu and Zhang, Cheng and Ge, Xin and Sun, Jinqiu and Zhang, Yanning},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={3667--3676},
  year={2020}
}

@misc{EasyOCR,
  author = {JaidedAI},
  title = {EasyOCR},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://https://github.com/JaidedAI/EasyOCR}},
  commit = {c4f3cd7225efd4f85451bd8b4a7646ae9a092420}
}

@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@inproceedings{deng2024portrait4d,
  title={Portrait4D: Learning One-Shot 4D Head Avatar Synthesis using Synthetic Data},
  author={Deng, Yu and Wang, Duomin and Ren, Xiaohang and Chen, Xingyu and Wang, Baoyuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7119--7130},
  year={2024}
}

@inproceedings{pechead,
  title={High-fidelity and freely controllable talking head video generation},
  author={Gao, Yue and Zhou, Yuan and Wang, Jinglu and Li, Xiao and Ming, Xiang and Lu, Yan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5609--5619},
  year={2023}
}

@inproceedings{bilayer,
  title={Fast bi-layer neural synthesis of one-shot realistic head avatars},
  author={Zakharov, Egor and Ivakhnenko, Aleksei and Shysheya, Aliaksandra and Lempitsky, Victor},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XII 16},
  pages={524--540},
  year={2020},
  organization={Springer}
}

@article{followemoji,
  title={COVE: Unleashing the Diffusion Feature Correspondence for Consistent Video Editing},
  author={Wang, Jiangshan and Ma, Yue and Guo, Jiayi and Xiao, Yicheng and Huang, Gao and Li, Xiu},
  journal={arXiv preprint arXiv:2406.08850},
  year={2024}
}
@inproceedings{xportrait,
  title={X-portrait: Expressive portrait animation with hierarchical motion attention},
  author={Xie, You and Xu, Hongyi and Song, Guoxian and Wang, Chao and Shi, Yichun and Luo, Linjie},
  booktitle={ACM SIGGRAPH 2024 Conference Papers},
  pages={1--11},
  year={2024}
}

@article{shi2023mvdream,
  title={Mvdream: Multi-view diffusion for 3d generation},
  author={Shi, Yichun and Wang, Peng and Ye, Jianglong and Long, Mai and Li, Kejie and Yang, Xiao},
  journal={arXiv preprint arXiv:2308.16512},
  year={2023}
}
@inproceedings{chen2017multi,
  title={Multi-view 3d object detection network for autonomous driving},
  author={Chen, Xiaozhi and Ma, Huimin and Wan, Ji and Li, Bo and Xia, Tian},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={1907--1915},
  year={2017}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{mallya2022implicit,
  title={Implicit warping for animation with image sets},
  author={Mallya, Arun and Wang, Ting-Chun and Liu, Ming-Yu},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={22438--22450},
  year={2022}
}

@inproceedings{park2019SPADE,
  title={Semantic Image Synthesis with Spatially-Adaptive Normalization},
  author={Park, Taesung and Liu, Ming-Yu and Wang, Ting-Chun and Zhu, Jun-Yan},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year={2019}
}

@inproceedings{morf,
author = {Wang, Daoye and Chandran, Prashanth and Zoss, Gaspard and Bradley, Derek and Gotardo, Paulo},
title = {MoRF: Morphable Radiance Fields for Multiview Neural Head Modeling},
year = {2022},
isbn = {9781450393379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
booktitle = {ACM SIGGRAPH 2022 Conference Proceedings},
articleno = {55},
numpages = {9},
location = {Vancouver, BC, Canada},
series = {SIGGRAPH '22}
}
@inproceedings{su2015multi,
  title={Multi-view convolutional neural networks for 3d shape recognition},
  author={Su, Hang and Maji, Subhransu and Kalogerakis, Evangelos and Learned-Miller, Erik},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={945--953},
  year={2015}
}
 @InProceedings{huang2024vbench,
     title={{VBench}: Comprehensive Benchmark Suite for Video Generative Models},
     author={Huang, Ziqi and He, Yinan and Yu, Jiashuo and Zhang, Fan and Si, Chenyang and Jiang, Yuming and Zhang, Yuanhan and Wu, Tianxing and Jin, Qingyang and Chanpaisit, Nattapol and Wang, Yaohui and Chen, Xinyuan and Wang, Limin and Lin, Dahua and Qiao, Yu and Liu, Ziwei},
     booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
     year={2024}
 }
@inproceedings{feichtenhofer2019slowfast,
  title={Slowfast networks for video recognition},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Malik, Jitendra and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={6202--6211},
  year={2019}
}

@inproceedings{tsn,
  title={Temporal segment networks: Towards good practices for deep action recognition},
  author={Wang, Limin and Xiong, Yuanjun and Wang, Zhe and Qiao, Yu and Lin, Dahua and Tang, Xiaoou and Van Gool, Luc},
  booktitle={European conference on computer vision},
  pages={20--36},
  year={2016},
  organization={Springer}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{jiang2019mlvcnn,
  title={MLVCNN: Multi-loop-view convolutional neural network for 3D shape retrieval},
  author={Jiang, Jianwen and Bao, Di and Chen, Ziqiang and Zhao, Xibin and Gao, Yue},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  pages={8513--8520},
  year={2019}
}

@article{zhou2020makelttalk,
  title={Makelttalk: speaker-aware talking-head animation},
  author={Zhou, Yang and Han, Xintong and Shechtman, Eli and Echevarria, Jose and Kalogerakis, Evangelos and Li, Dingzeyu},
  journal={TOG},
  volume={39},
  number={6},
  pages={1--15},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@inproceedings{lama,
  title={Resolution-robust large mask inpainting with fourier convolutions},
  author={Suvorov, Roman and Logacheva, Elizaveta and Mashikhin, Anton and Remizova, Anastasia and Ashukha, Arsenii and Silvestrov, Aleksei and Kong, Naejin and Goka, Harshith and Park, Kiwoong and Lempitsky, Victor},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={2149--2159},
  year={2022}
}

@inproceedings{cheng2021mask2former,
  title={Masked-attention Mask Transformer for Universal Image Segmentation},
  author={Bowen Cheng and Ishan Misra and Alexander G. Schwing and Alexander Kirillov and Rohit Girdhar},
  booktitle={CVPR},
  year={2022}
}

@InProceedings{vox,
              author       = "Chung, J.~S. and Nagrani, A. and Zisserman, A.",
              title        = "VoxCeleb2: Deep Speaker Recognition",
              booktitle    = "INTERSPEECH",
              year         = "2018",
            }

@article{ccv2,
  title={Towards measuring fairness in ai: the casual conversations dataset},
  author={Hazirbas, Caner and Bitton, Joanna and Dolhansky, Brian and Pan, Jacqueline and Gordo, Albert and Ferrer, Cristian Canton},
  journal={IEEE Transactions on Biometrics, Behavior, and Identity Science},
  volume={4},
  number={3},
  pages={324--332},
  year={2021},
  publisher={IEEE}
}

@inproceedings{hdtf,
  title={Flow-guided one-shot talking face generation with a high-resolution audio-visual dataset},
  author={Zhang, Zhimeng and Li, Lincheng and Ding, Yu and Fan, Changjie},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3661--3670},
  year={2021}
}


@inproceedings{xie2022vfhq,
  title={Vfhq: A high-quality dataset and benchmark for video face super-resolution},
  author={Xie, Liangbin and Wang, Xintao and Zhang, Honglun and Dong, Chao and Shan, Ying},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={657--666},
  year={2022}
}



@book{ECCV2022,
    editor = {Shai Avidan and Gabriel Brostow and Moustapha CissÃ© and Giovanni Maria Farinella and Tal Hassner},
    title = {Computer Vision -- ECCV 2022},
    year = {2022},
    publisher = {Springer},
    doi = {10.1007/978-3-031-19769-7}
}

# v2v 

@article{siarohin2019fomm,
  title={First order motion model for image animation},
  author={Siarohin, Aliaksandr and Lathuili{\`e}re, St{\'e}phane and Tulyakov, Sergey and Ricci, Elisa and Sebe, Nicu},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{siarohin2021mraa,
  title={Motion representations for articulated animation},
  author={Siarohin, Aliaksandr and Woodford, Oliver J and Ren, Jian and Chai, Menglei and Tulyakov, Sergey},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13653--13662},
  year={2021}
}

@inproceedings{zhao2022tps,
  title={Thin-plate spline motion model for image animation},
  author={Zhao, Jian and Zhang, Hui},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3657--3666},
  year={2022}
}

@inproceedings{hong2023mcn,
  title={Implicit identity representation conditioned memory compensation network for talking head video generation},
  author={Hong, Fa-Ting and Xu, Dan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={23062--23072},
  year={2023}
}

@inproceedings{wang2022lia,
  title={Latent Image Animator: Learning to Animate Images via Latent Space Navigation},
  author={Yaohui Wang and Di Yang and Francois Bremond and Antitza Dantcheva},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@inproceedings{wang2021facev2v,
  title={One-shot free-view neural talking-head synthesis for video conferencing},
  author={Wang, Ting-Chun and Mallya, Arun and Liu, Ming-Yu},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10039--10049},
  year={2021}
}

@inproceedings{zhang2023metaportrait,
  title={Metaportrait: Identity-preserving talking head generation with fast personalized adaptation},
  author={Zhang, Bowen and Qi, Chenyang and Zhang, Pan and Zhang, Bo and Wu, HsiangTao and Chen, Dong and Chen, Qifeng and Wang, Yong and Wen, Fang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22096--22105},
  year={2023}
}

@inproceedings{yin2022styleheat,
  title={Styleheat: One-shot high-resolution editable talking face generation via pre-trained stylegan},
  author={Yin, Fei and Zhang, Yong and Cun, Xiaodong and Cao, Mingdeng and Fan, Yanbo and Wang, Xuan and Bai, Qingyan and Wu, Baoyuan and Wang, Jue and Yang, Yujiu},
  booktitle={European conference on computer vision},
  pages={85--101},
  year={2022},
  organization={Springer}
}

@inproceedings{ren2021pirenderer,
  title={Pirenderer: Controllable portrait image generation via semantic neural rendering},
  author={Ren, Yurui and Li, Ge and Chen, Yuanqi and Li, Thomas H and Liu, Shan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={13759--13768},
  year={2021}
}

@inproceedings{ye2024real3d,
    author    = {Ye, Zhenhui and Zhong, Tianyun and Ren, Yi and Yang, Jiaqi and Li, Weichuang and Huang, Jiangwei and Jiang, Ziyue and He, Jinzheng and Huang, Rongjie and Liu, Jinglin and Zhang, Chen and Yin, Xiang and Ma, Zejun and Zhao, Zhou},
    title     = {Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis},
    booktitle   = {ICLR},
    year      = {2024},
  }


# a2v 


@article{sun2023vividtalk,
  title={VividTalk: One-Shot Audio-Driven Talking Head Generation Based on 3D Hybrid Prior},
  author={Sun, Xusen and Zhang, Longhao and Zhu, Hao and Zhang, Peng and Zhang, Bang and Ji, Xinya and Zhou, Kangneng and Gao, Daiheng and Bo, Liefeng and Cao, Xun},
  journal={arXiv preprint arXiv:2312.01841},
  year={2023}
}

@article{ma2023dreamtalk,
  title={DreamTalk: When Expressive Talking Head Generation Meets Diffusion Probabilistic Models},
  author={Ma, Yifeng and Zhang, Shiwei and Wang, Jiayu and Wang, Xiang and Zhang, Yingya and Deng, Zhidong},
  journal={arXiv preprint arXiv:2312.09767},
  year={2023}
}

@article{zhang2023dream,
  title={DREAM-Talk: Diffusion-based Realistic Emotional Audio-driven Method for Single Image Talking Face Generation},
  author={Zhang, Chenxu and Wang, Chao and Zhang, Jianfeng and Xu, Hongyi and Song, Guoxian and Xie, You and Luo, Linjie and Tian, Yapeng and Guo, Xiaohu and Feng, Jiashi},
  journal={arXiv preprint arXiv:2312.13578},
  year={2023}
}

@inproceedings{drobyshev2022megaportraits,
  title={Megaportraits: One-shot megapixel neural head avatars},
  author={Drobyshev, Nikita and Chelishev, Jenya and Khakhulin, Taras and Ivakhnenko, Aleksei and Lempitsky, Victor and Zakharov, Egor},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={2663--2671},
  year={2022}
}

@inproceedings{prajwal2020wav2lip,
  title={A lip sync expert is all you need for speech to lip generation in the wild},
  author={Prajwal, KR and Mukhopadhyay, Rudrabha and Namboodiri, Vinay P and Jawahar, CV},
  booktitle={Proceedings of the 28th ACM international conference on multimedia},
  pages={484--492},
  year={2020}
}

@inproceedings{unet,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={Medical Image Computing and Computer-Assisted Intervention--MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18},
  pages={234--241},
  year={2015},
  organization={Springer}
}


@inproceedings{shen2023difftalk,
  title={DiffTalk: Crafting Diffusion Models for Generalized Audio-Driven Portraits Animation},
  author={Shen, Shuai and Zhao, Wenliang and Meng, Zibin and Li, Wanhua and Zhu, Zheng and Zhou, Jie and Lu, Jiwen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1982--1991},
  year={2023}
}

# gan related

@inproceedings{karras2019stylegan,
  title={A style-based generator architecture for generative adversarial networks},
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4401--4410},
  year={2019}
}

# face related

@article{song20093dmm,
  title={On Parameterizing of Human Expression Using ICA},
  author={Song, Ji-Hey and Shin, Hyun-Joon},
  journal={Journal of the Korea Computer Graphics Society},
  volume={15},
  number={1},
  pages={7--15},
  year={2009},
  publisher={Korea Computer Graphics Society}
}

# lite related

@article{zhao2023mobilediffusion,
  title={MobileDiffusion: Subsecond Text-to-Image Generation on Mobile Devices},
  author={Zhao, Yang and Xu, Yanwu and Xiao, Zhisheng and Hou, Tingbo},
  journal={arXiv preprint arXiv:2311.16567},
  year={2023}
}

@article{li2024snapfusion,
  title={Snapfusion: Text-to-image diffusion model on mobile devices within two seconds},
  author={Li, Yanyu and Wang, Huan and Jin, Qing and Hu, Ju and Chemerys, Pavlo and Fu, Yun and Wang, Yanzhi and Tulyakov, Sergey and Ren, Jian},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{jia2023blazestylegan,
  title={BlazeStyleGAN: A Real-Time On-Device StyleGAN},
  author={Jia, Haolin and Wang, Qifei and Tov, Omer and Zhao, Yang and Deng, Fei and Wang, Lu and Chang, Chuo-Ling and Hou, Tingbo and Grundmann, Matthias},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4689--4693},
  year={2023}
}


@inproceedings{prajwal2020lip,
  title={A lip sync expert is all you need for speech to lip generation in the wild},
  author={Prajwal, KR and Mukhopadhyay, Rudrabha and Namboodiri, Vinay P and Jawahar, CV},
  booktitle={ACM MM},
  pages={484--492},
  year={2020}
}

@article{siarohin2019first,
  title={First order motion model for image animation},
  author={Siarohin, Aliaksandr and Lathuili{\`e}re, St{\'e}phane and Tulyakov, Sergey and Ricci, Elisa and Sebe, Nicu},
  journal={NeurIPS},
  volume={32},
  year={2019}
}


@inproceedings{wang2021one,
  title={One-shot free-view neural talking-head synthesis for video conferencing},
  author={Wang, Ting-Chun and Mallya, Arun and Liu, Ming-Yu},
  booktitle={CVPR},
  pages={10039--10049},
  year={2021}
}

@inproceedings{Zhou2021Pose,
  title = {Pose-Controllable Talking Face Generation by Implicitly Modularized Audio-Visual Representation},
  author = {Zhou, Hang and Sun, Yasheng and Wu, Wayne and Loy, Chen Change and Wang, Xiaogang and Liu, Ziwei},
  booktitle = {CVPR},
  year = {2021}
}


@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}


@inproceedings{guo2021ad,
  title={Ad-nerf: Audio driven neural radiance fields for talking head synthesis},
  author={Guo, Yudong and Chen, Keyu and Liang, Sen and Liu, Yong-Jin and Bao, Hujun and Zhang, Juyong},
  booktitle={ICCV},
  pages={5784--5794},
  year={2021}
}


@inproceedings{wang2021towards,
  title={Towards real-world blind face restoration with generative facial prior},
  author={Wang, Xintao and Li, Yu and Zhang, Honglun and Shan, Ying},
  booktitle={CVPR},
  pages={9168--9178},
  year={2021}
}


@InProceedings{Zhao_2022_CVPR,
    author    = {Zhao, Jian and Zhang, Hui},
    title     = {Thin-Plate Spline Motion Model for Image Animation},
    booktitle = {CVPR},
    year      = {2022},
    pages     = {3657-3666}
}


@InProceedings{Zhang_2023_CVPR,
    author    = {Zhang, Bowen and Qi, Chenyang and Zhang, Pan and Zhang, Bo and Wu, HsiangTao and Chen, Dong and Chen, Qifeng and Wang, Yong and Wen, Fang},
    title     = {MetaPortrait: Identity-Preserving Talking Head Generation With Fast Personalized Adaptation},
    booktitle = {CVPR},
    year      = {2023},
    pages     = {22096-22105}
}


@InProceedings{Wang_2023_CVPR,
    author    = {Wang, Jiadong and Qian, Xinyuan and Zhang, Malu and Tan, Robby T. and Li, Haizhou},
    title     = {Seeing What You Said: Talking Face Generation Guided by a Lip Reading Expert},
    booktitle = {CVPR},
    year      = {2023},
    pages     = {14653-14662}
}


@inproceedings{yin2022styleheat,
  title={Styleheat: One-shot high-resolution editable talking face generation via pre-trained stylegan},
  author={Yin, Fei and Zhang, Yong and Cun, Xiaodong and Cao, Mingdeng and Fan, Yanbo and Wang, Xuan and Bai, Qingyan and Wu, Baoyuan and Wang, Jue and Yang, Yujiu},
  booktitle={ECCV},
  pages={85--101},
  year={2022},
  organization={Springer}
}

@inproceedings{mildenhall2020nerf,
 title={NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis},
 author={Ben Mildenhall and Pratul P. Srinivasan and Matthew Tancik and Jonathan T. Barron and Ravi Ramamoorthi and Ren Ng},
 year={2020},
 booktitle={ECCV},
}

@article{zhou2020makelttalk,
  title={Makelttalk: speaker-aware talking-head animation},
  author={Zhou, Yang and Han, Xintong and Shechtman, Eli and Echevarria, Jose and Kalogerakis, Evangelos and Li, Dingzeyu},
  journal={TOG},
  volume={39},
  number={6},
  pages={1--15},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{fried2019text,
  title={Text-based editing of talking-head video},
  author={Fried, Ohad and Tewari, Ayush and Zollh{\"o}fer, Michael and Finkelstein, Adam and Shechtman, Eli and Goldman, Dan B and Genova, Kyle and Jin, Zeyu and Theobalt, Christian and Agrawala, Maneesh},
  journal={TOG},
  volume={38},
  number={4},
  pages={1--14},
  year={2019},
  publisher={ACM New York, NY, USA}
}


@inproceedings{li2021write,
  title={Write-a-speaker: Text-based emotional and rhythmic talking-head generation},
  author={Li, Lincheng and Wang, Suzhen and Zhang, Zhimeng and Ding, Yu and Zheng, Yixing and Yu, Xin and Fan, Changjie},
  booktitle={AAAI},
  volume={35},
  number={3},
  pages={1911--1920},
  year={2021}
}

@inproceedings{zhang2022text2video,
  title={Text2video: Text-driven talking-head video synthesis with personalized phoneme-pose dictionary},
  author={Zhang, Sibo and Yuan, Jiahong and Liao, Miao and Zhang, Liangjun},
  booktitle={ICASSP},
  pages={2659--2663},
  year={2022},
  organization={IEEE}
}


@article{zhang2023dinet,
  title={DINet: Deformation Inpainting Network for Realistic Face Visually Dubbing on High Resolution Video},
  author={Zhang, Zhimeng and Hu, Zhipeng and Deng, Wenjin and Fan, Changjie and Lv, Tangjie and Ding, Yu},
  booktitle={AAAI},
  year={2023}
}

@InProceedings{Ma_2023_CVPR,
    author    = {Ma, Zhiyuan and Zhu, Xiangyu and Qi, Guo-Jun and Lei, Zhen and Zhang, Lei},
    title     = {OTAvatar: One-Shot Talking Face Avatar With Controllable Tri-Plane Rendering},
    booktitle = {CVPR},
    year      = {2023},
    pages     = {16901-16910}
}



@InProceedings{Shen_2023_CVPR,
    author    = {Shen, Shuai and Zhao, Wenliang and Meng, Zibin and Li, Wanhua and Zhu, Zheng and Zhou, Jie and Lu, Jiwen},
    title     = {DiffTalk: Crafting Diffusion Models for Generalized Audio-Driven Portraits Animation},
    booktitle = {CVPR},
    month     = {June},
    year      = {2023},
    pages     = {1982-1991}
}


@InProceedings{Mukhopadhyay_2024_WACV,
    author    = {Mukhopadhyay, Soumik and Suri, Saksham and Gadde, Ravi Teja and Shrivastava, Abhinav},
    title     = {Diff2Lip: Audio Conditioned Diffusion Models for Lip-Synchronization},
    booktitle = {WACV},
    month     = {January},
    year      = {2024},
    pages     = {5292-5302}
}


@inproceedings{liu2023opt,
  title={OPT: One-shot Pose-Controllable Talking Head Generation},
  author={Liu, Jin and Wang, Xi and Fu, Xiaomeng and Chai, Yesheng and Yu, Cai and Dai, Jiao and Han, Jizhong},
  booktitle={ICASSP},
  pages={1--5},
  year={2023},
  organization={IEEE}
}


@article{mallyaimplicit,
  title={Implicit warping for animation with image sets},
  author={Mallya, Arun and Wang, Ting-Chun and Liu, Ming-Yu},
  journal={NeurIPS},
  volume={35},
  pages={22438--22450},
  year={2022}
}

@inproceedings{blanz1999morphable,
  title={A morphable model for the synthesis of 3D faces},
  author={Blanz, Volker and Vetter, Thomas},
  booktitle={SIGGRAPH},
  pages={187--194},
  year={1999}
}


@inproceedings{paysan20093d,
  title={A 3D face model for pose and illumination invariant face recognition},
  author={Paysan, Pascal and Knothe, Reinhard and Amberg, Brian and Romdhani, Sami and Vetter, Thomas},
  booktitle={AVSS},
  pages={296--301},
  year={2009},
  organization={Ieee}
}


@inproceedings{zhong2023identity,
  title={Identity-Preserving Talking Face Generation with Landmark and Appearance Priors},
  author={Zhong, Weizhi and Fang, Chaowei and Cai, Yinqi and Wei, Pengxu and Zhao, Gangming and Lin, Liang and Li, Guanbin},
  booktitle={CVPR},
  pages={9729--9738},
  year={2023}
}


@article{kim2018deep,
  title={Deep video portraits},
  author={Kim, Hyeongwoo and Garrido, Pablo and Tewari, Ayush and Xu, Weipeng and Thies, Justus and Niessner, Matthias and P{\'e}rez, Patrick and Richardt, Christian and Zollh{\"o}fer, Michael and Theobalt, Christian},
  journal={TOG},
  volume={37},
  number={4},
  pages={1--14},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@article{kim2019neural,
  title={Neural style-preserving visual dubbing},
  author={Kim, Hyeongwoo and Elgharib, Mohamed and Zollh{\"o}fer, Michael and Seidel, Hans-Peter and Beeler, Thabo and Richardt, Christian and Theobalt, Christian},
  journal={TOG},
  volume={38},
  number={6},
  pages={1--13},
  year={2019},
  publisher={ACM New York, NY, USA}
}


@inproceedings{ren2021pirenderer,
  title={Pirenderer: Controllable portrait image generation via semantic neural rendering},
  author={Ren, Yurui and Li, Ge and Chen, Yuanqi and Li, Thomas H and Liu, Shan},
  booktitle={ICCV},
  pages={13759--13768},
  year={2021}
}

@InProceedings{Liang_2022_CVPR,
    author    = {Liang, Borong and Pan, Yan and Guo, Zhizhi and Zhou, Hang and Hong, Zhibin and Han, Xiaoguang and Han, Junyu and Liu, Jingtuo and Ding, Errui and Wang, Jingdong},
    title     = {Expressive Talking Head Generation With Granular Audio-Visual Control},
    booktitle = {CVPR},
    month     = {June},
    year      = {2022},
    pages     = {3387-3396}
}


@inproceedings{zhang2021facial,
  title={Facial: Synthesizing dynamic talking face with implicit attribute learning},
  author={Zhang, Chenxu and Zhao, Yifan and Huang, Yifei and Zeng, Ming and Ni, Saifeng and Budagavi, Madhukar and Guo, Xiaohu},
  booktitle={ICCV},
  pages={3867--3876},
  year={2021}
}


@inproceedings{du2023dae,
  title={Dae-talker: High fidelity speech-driven talking face generation with diffusion autoencoder},
  author={Du, Chenpeng and Chen, Qi and He, Tianyu and Tan, Xu and Chen, Xie and Yu, Kai and Zhao, Sheng and Bian, Jiang},
  booktitle={ACM MM},
  pages={4281--4289},
  year={2023}
}

@inproceedings{kowalski2017deep,
  title={Deep alignment network: A convolutional neural network for robust face alignment},
  author={Kowalski, Marek and Naruniec, Jacek and Trzcinski, Tomasz},
  booktitle={CVPRW},
  pages={88--97},
  year={2017}
}

@article{guo2019pfld,
  title={PFLD: A practical facial landmark detector},
  author={Guo, Xiaojie and Li, Siyuan and Yu, Jinke and Zhang, Jiawan and Ma, Jiayi and Ma, Lin and Liu, Wei and Ling, Haibin},
  journal={arXiv preprint arXiv:1902.10859},
  year={2019}
}


@inproceedings{wang2021real,
  title={Real-esrgan: Training real-world blind super-resolution with pure synthetic data},
  author={Wang, Xintao and Xie, Liangbin and Dong, Chao and Shan, Ying},
  booktitle={ICCV},
  pages={1905--1914},
  year={2021}
}


@inproceedings{yang2021gan,
  title={Gan prior embedded network for blind face restoration in the wild},
  author={Yang, Tao and Ren, Peiran and Xie, Xuansong and Zhang, Lei},
  booktitle={CVPR},
  pages={672--681},
  year={2021}
}

@inproceedings{gu2022vqfr,
  title={VQFR: Blind face restoration with vector-quantized dictionary and parallel decoder},
  author={Gu, Yuchao and Wang, Xintao and Xie, Liangbin and Dong, Chao and Li, Gen and Shan, Ying and Cheng, Ming-Ming},
  booktitle={ECCV},
  pages={126--143},
  year={2022},
  organization={Springer}
}

@article{yao2022dfa,
  title={DFA-NeRF: Personalized talking head generation via disentangled face attributes neural rendering},
  author={Yao, Shunyu and Zhong, RuiZhe and Yan, Yichao and Zhai, Guangtao and Yang, Xiaokang},
  journal={arXiv preprint arXiv:2201.00791},
  year={2022}
}


@inproceedings{hong2023implicit,
  title={Implicit identity representation conditioned memory compensation network for talking head video generation},
  author={Hong, Fa-Ting and Xu, Dan},
  booktitle={ICCV},
  pages={23062--23072},
  year={2023}
}

@article{ye2024real3d,
  title={Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis},
  author={Ye, Zhenhui and Zhong, Tianyun and Ren, Yi and Yang, Jiaqi and Li, Weichuang and Huang, Jiawei and Jiang, Ziyue and He, Jinzheng and Huang, Rongjie and Liu, Jinglin and others},
  booktitle={ICLR},
  year={2024}
}


@inproceedings{karras2019style,
  title={A style-based generator architecture for generative adversarial networks},
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle={CVPR},
  pages={4401--4410},
  year={2019}
}


@inproceedings{karras2020analyzing,
  title={Analyzing and improving the image quality of stylegan},
  author={Karras, Tero and Laine, Samuli and Aittala, Miika and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
  booktitle={CVPR},
  pages={8110--8119},
  year={2020}
}

@article{karras2021alias,
  title={Alias-free generative adversarial networks},
  author={Karras, Tero and Aittala, Miika and Laine, Samuli and H{\"a}rk{\"o}nen, Erik and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
  journal={NeurIPS},
  volume={34},
  pages={852--863},
  year={2021}
}


@inproceedings{burkov2020neural,
  title={Neural head reenactment with latent pose descriptors},
  author={Burkov, Egor and Pasechnik, Igor and Grigorev, Artur and Lempitsky, Victor},
  booktitle={CVPR},
  pages={13786--13795},
  year={2020}
}

@article{sun2022ide,
  title={Ide-3d: Interactive disentangled editing for high-resolution 3d-aware portrait synthesis},
  author={Sun, Jingxiang and Wang, Xuan and Shi, Yichun and Wang, Lizhen and Wang, Jue and Liu, Yebin},
  journal={TOG},
  volume={41},
  number={6},
  pages={1--10},
  year={2022},
  publisher={ACM New York, NY, USA}
}

@inproceedings{zhang2021flow,
  title={Flow-guided one-shot talking face generation with a high-resolution audio-visual dataset},
  author={Zhang, Zhimeng and Li, Lincheng and Ding, Yu and Fan, Changjie},
  booktitle={CVPR},
  pages={3661--3670},
  year={2021}
}

@inproceedings{kinga2015method,
  title={A method for stochastic optimization},
  author={Kinga, D and Adam, Jimmy Ba and others},
  booktitle={ICLR},
  volume={5},
  pages={6},
  year={2015},
  organization={San Diego, California;}
}

@inproceedings{deng2019arcface,
  title={Arcface: Additive angular margin loss for deep face recognition},
  author={Deng, Jiankang and Guo, Jia and Xue, Niannan and Zafeiriou, Stefanos},
  booktitle={CVPR},
  pages={4690--4699},
  year={2019}
}

@inproceedings{chen2018lip,
  title={Lip movements generation at a glance},
  author={Chen, Lele and Li, Zhiheng and Maddox, Ross K and Duan, Zhiyao and Xu, Chenliang},
  booktitle={ECCV},
  pages={520--535},
  year={2018}
}

@article{radford2015unsupervised,
  title={Unsupervised representation learning with deep convolutional generative adversarial networks},
  author={Radford, Alec and Metz, Luke and Chintala, Soumith},
  journal={arXiv preprint arXiv:1511.06434},
  year={2015}
}

@article{hazirbas2021towards,
  title={Towards measuring fairness in ai: the casual conversations dataset},
  author={Hazirbas, Caner and Bitton, Joanna and Dolhansky, Brian and Pan, Jacqueline and Gordo, Albert and Ferrer, Cristian Canton},
  journal={IEEE Transactions on Biometrics, Behavior, and Identity Science},
  volume={4},
  number={3},
  pages={324--332},
  year={2021},
  publisher={IEEE}
}

@article{howard2017mobilenets,
  title={Mobilenets: Efficient convolutional neural networks for mobile vision applications},
  author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  journal={arXiv preprint arXiv:1704.04861},
  year={2017}
}

@inproceedings{zhang2018shufflenet,
  title={Shufflenet: An extremely efficient convolutional neural network for mobile devices},
  author={Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},
  booktitle={CVPR},
  pages={6848--6856},
  year={2018}
}

@inproceedings{buciluÇŽ2006model,
  title={Model compression},
  author={BuciluÇŽ, Cristian and Caruana, Rich and Niculescu-Mizil, Alexandru},
  booktitle={ACM SIGKDD},
  pages={535--541},
  year={2006}
}

@article{lecun1989optimal,
  title={Optimal brain damage},
  author={LeCun, Yann and Denker, John and Solla, Sara},
  journal={NeurIPS},
  volume={2},
  year={1989}
}

@article{courbariaux2015binaryconnect,
  title={Binaryconnect: Training deep neural networks with binary weights during propagations},
  author={Courbariaux, Matthieu and Bengio, Yoshua and David, Jean-Pierre},
  journal={NeurIPS},
  volume={28},
  year={2015}
}

@article{gong2014compressing,
  title={Compressing deep convolutional networks using vector quantization},
  author={Gong, Yunchao and Liu, Liu and Yang, Ming and Bourdev, Lubomir},
  journal={arXiv preprint arXiv:1412.6115},
  year={2014}
}

@article{wen2016learning,
  title={Learning structured sparsity in deep neural networks},
  author={Wen, Wei and Wu, Chunpeng and Wang, Yandan and Chen, Yiran and Li, Hai},
  journal={NeurIPS},
  volume={29},
  year={2016}
}

@inproceedings{johnson2016perceptual,
  title={Perceptual losses for real-time style transfer and super-resolution},
  author={Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part II 14},
  pages={694--711},
  year={2016},
  organization={Springer}
}

@inproceedings{wang2018high,
  title={High-resolution image synthesis and semantic manipulation with conditional gans},
  author={Wang, Ting-Chun and Liu, Ming-Yu and Zhu, Jun-Yan and Tao, Andrew and Kautz, Jan and Catanzaro, Bryan},
  booktitle={CVPR},
  pages={8798--8807},
  year={2018}
}

% 65 headpose
@inproceedings{ruiz2018fine,
  title={Fine-grained head pose estimation without keypoints},
  author={Ruiz, Nataniel and Chong, Eunji and Rehg, James M},
  booktitle={CVPRW},
  pages={2074--2083},
  year={2018}
}

@article{lugaresi2019mediapipe,
  title={Mediapipe: A framework for building perception pipelines},
  author={Lugaresi, Camillo and Tang, Jiuqiang and Nash, Hadon and McClanahan, Chris and Uboweja, Esha and Hays, Michael and Zhang, Fan and Chang, Chuo-Ling and Yong, Ming Guang and Lee, Juhyun and others},
  journal={arXiv preprint arXiv:1906.08172},
  year={2019}
}


@inproceedings{su2020blindly,
  title={Blindly assess image quality in the wild guided by a self-adaptive hyper network},
  author={Su, Shaolin and Yan, Qingsen and Zhu, Yu and Zhang, Cheng and Ge, Xin and Sun, Jinqiu and Zhang, Yanning},
  booktitle={CVPR},
  pages={3667--3676},
  year={2020}
}


@inproceedings{park2019semantic,
  title={Semantic image synthesis with spatially-adaptive normalization},
  author={Park, Taesung and Liu, Ming-Yu and Wang, Ting-Chun and Zhu, Jun-Yan},
  booktitle={CVPR},
  pages={2337--2346},
  year={2019}
}


@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}


@article{wang2024v,
  title={V-Express: Conditional Dropout for Progressive Training of Portrait Video Generation},
  author={Wang, Cong and Tian, Kuan and Zhang, Jun and Guan, Yonghang and Luo, Feng and Shen, Fei and Jiang, Zhiwei and Gu, Qing and Han, Xiao and Yang, Wei},
  journal={arXiv preprint arXiv:2406.02511},
  year={2024}
}

