\section{Extensions}
\label{sec:ext}
In this section, we extend BARBAT to various corrupted bandit settings discussed earlier and introduce necessary modifications to accommodate the relevant environment configurations. %These extensions demonstrate that our framework is scalable and parallelizable.

\subsection{Strongly Observable Graph Bandits}
\label{sec:sog}

% In strongly observable graph bandits, the feedback structure of $K$ arms is formalized as a directed graph $G = (K, E)$. When an agent pulls an arm $k_i$, it can observe the rewards of arms $k_j$ for which $(k_i, k_j) \in E$. In a strongly observable graph, each arm either has a self-loop or receives edges from all other arms, implying that pulling a single arm may yield observations for multiple arms. Such auxiliary information is commonly found in real-world applications~\citep{alon2017nonstochastic}. For instance, in online advertising, if two ads promote comparable products, they may be linked by an edge in the feedback graph. When a user clicks on one ad, it is probable that the user will also show interest in the other ad.

% However, the previous works~\citep{ito2022nearly,dann2023blackbox,eldowa2024minimax} require prior knowledge of the independence number $\alpha$, which is a well-known NP-hard problem. \cite{ito2024adaptive} addresses this issue using an adaptive method, but this approach only applies to undirected bandits and each arm has a self-loop. Additionally, most of these works assume that the optimal arm is unique.

% Motivated by these problems, we extend BARBAT to SOG-BARBAT, which is presented in Algorithm~\ref{algs:SOG-BARBAT}. Based on the feedback structure, our goal is to pull as few arms as possible while ensuring that each arm is observed enough times. Furthermore, SOG-BARBAT is specifically designed to optimize the actual expected pulling times, $\widetilde{n}_k^m$, for all arms $k \in [K]$. Intuitively, we continuously seek a dominating set for the graph, ensuring that pulling each arm in the dominating set once allows all arms to be observed at least once. To accomplish this, SOG-BARBAT initializes a \emph{pulling arm set} $Z^m[k] = 0$ for each arm $k \in [K]$, which tracks the number of times each arm is pulled, and an \emph{observation arm set} $H^m[k] = 0$, which records the number of times each arm is observed. For analytical convenience, we assume that each arm has a self-loop; we show in Appendix~\ref{ape:sog} that this assumption does not affect the regret bound. To minimize the number of arm pulls, we design a novel algorithm, \textsc{OODS} (Algorithm~\ref{algs:OODS}), which outputs an out-dominating set $D$ for any strongly observable directed graph $G$.

% A ``no-root vertex'' is defined as a vertex with no incoming edges other than its self-loop. To ensure that the rewards for no-root vertices are observed, \textsc{OODS} pulls these vertices directly. However, in graphs containing cycles, there may be no no-root vertices. In such cases, \textsc{OODS} applies a greedy strategy: it selects the vertex with the highest out-degree and adds it to $D$. The procedure proceeds as follows: if a cycle is detected in $G$, the greedy strategy is employed; otherwise, all no-root vertices are added to $D$. The vertices in $D$ and their out-degree neighbors are then removed from $G$, and the process repeats until $G$ is empty, ensuring that $D$ forms an out-dominating set covering $G$.
% The theoretical analysis shows that for any strongly observable directed graph $G = (K, E)$ with independence number $\alpha$, the set $D$ constructed by \textsc{OODS} satisfies $|D| \leq \alpha(1+2\ln(K/\alpha)$. Moreover, for acyclic graphs---including undirected graphs---we have $|D| \le \alpha$. To reduce computational overhead, \textsc{OODS} only needs to verify whether $G$ is acyclic once, while still achieving the same theoretical guarantee on $|D|$.

% Returning to Algorithm~\ref{algs:SOG-BARBAT}, we initialize a counter $s = 1$ and copy $G$ to a new graph $G_s$. The algorithm enters a loop under the condition $H_k^m \ge n_k^m$ for all arms $k \in [K]$, ensuring each arm is observed sufficiently. First, SOG-BARBAT invokes \textsc{OODS} on $G_s^m$ to obtain an out-dominating set $D_s^m$. Then, it computes $\mathcal{H}_s^m = \min_{k \in [K]} \Bigl( n_k^m - H_k^m \Bigr).$
% For each arm $k_i \in D_s^m$, SOG-BARBAT increments $Z_{k_i}^m$ by $\mathcal{H}_s^m$, and for all arms $k_j$ with $(k_i, k_j) \in E$, it updates $H_{k_j}^m$ accordingly. This guarantees that at least one arm satisfies $H_k^m \ge n_k^m$, allowing that arm to be removed from the graph. The loop continues until $G_s^m$ is empty.
% Lastly, SOG-BARBAT uses $Z^m$ to construct the actual expected number of pulls. Importantly, the observable number of pulls is defined as $\hat{n}_{k_j}^m = \sum_{\substack{(k_i, k_j) \in E}} \widetilde{n}_{k_i}^m,$
% rather than being derived from $H^m$. 

% The SOG-BARBAT algorithm achieves the following regret bound, with the proof provided in Appendix \ref{ape:sog}:
% \begin{theorem}\label{the:sog-erb}
% Without loss of generality, let $\mu_1 \geq \mu_2 \geq \cdots \geq \mu_K$ be the ordering of mean rewards for the $K$ arms. 
% For any strongly observable directed graph $G = (K,E)$ with independence number $\alpha$, the expected regret of SOG-BARBAT satisfies
% \[
%     R(T) = O\left(C + 
%       \sum_{k = 2}^{\lceil \alpha(1 + 2\ln(K / \alpha)) + 1\rceil}
%         \frac{\log(T)\log(KT)}{\Delta_k}
%       +
%       \frac{K\log(1/\Delta)\log\!\bigl(K/\Delta\bigr)}{\Delta}
%     \right).
% \]
% \end{theorem}
% \begin{remark}
%     For any strongly observable directed graph $G = (K,E)$ with independence number $\alpha$, the regret upper bound of SOG-BARBAT depends on $\alpha\left(1 + 2\ln(K/\alpha)\right) = O(\alpha\ln(K/\alpha + 1))$,
%     which matches the lower bound established by \cite{chen2023interpolating}. In particular, when $G$ is an acyclic graph (including undirected graphs), we have the regret upper bound of SOG-BARBAT depends on $\alpha$, indicating that SOG-BARBAT can achieve better performance under this favorable condition.
% \end{remark}
% \begin{remark}
%     Compared to the recent works~\citep{ito2022nearly,dann2023blackbox}, whose regret bounds depend on the smallest suboptimality gap $1/\Delta$, note that our regret can be represented in a summation form, which is also controlled by $1/\Delta$. It is worth highlighting that these works require prior knowledge of the independence number $\alpha$, which is a well-known NP-hard problem, whereas SOG-BARBAT does not need any such prior knowledge of $\alpha$. 
%     In the undirected setting, the previous works~\citep{eldowa2024minimax,ito2024adaptive} achieve regret bounds on the order of $O\!\bigl(\alpha \ln(K/\alpha + 1)\bigr)$, which is significantly larger than our $\alpha$-dependent regret bounds.
% \end{remark}

In strongly observable graph bandits, the feedback structure is defined by a directed graph $G=(K,E)$, where pulling arm $k_i$ reveals rewards for all arms $k_j$ such that $(k_i,k_j)\in E$. The \emph{independence number} $\alpha$ is the size of the largest independent set in $G$. For the strongly observable graphs, each arm has either a self-loop or incoming edges from all other arms, revealing multiple rewards in a single pull~\citep{alon2017nonstochastic}.

Most previous works~\citep{ito2022nearly,dann2023blackbox,eldowa2024minimax} rely on the knowledge of independence number $\alpha$, which is NP-hard to compute. \cite{ito2024adaptive} addresses this in undirected graph bandits with self-loops but assumes a unique optimal arm.

To overcome these issues, we extend BARBAT to SOG-BARBAT (Algorithm~\ref{algs:SOG-BARBAT}). In epoch $m$, we observe $\lambda_m (\Delta_k^{m-1})^{-2}$ times for arm $k$ in expected. SOG-BARBAT aims to pull the fewest arms while ensuring sufficient observations. It defines expected pulling times array $Z^m[K]$ and expected observable times array $H^m[K]$. For ease of analysis, we assume that each arm is equipped with a self-loop. From a theoretical standpoint, this assumption does not alter the resulting regret.
We design the \textbf{OODS} algorithm (Algorithm~\ref{algs:OODS}), which ensures that the out-dominating set $D_s^m$ satisfies $|D_s^m| \leq \alpha(1+2\ln(K/\alpha))$. For acyclic graphs, we always have $D_s^m \leq \alpha$. We compute $\cH_s^m = \min_{k \in [K]}$ for each $k_i \in D_s^m$, set $Z_{k_i}^m = Z_{k_i}^m + \cH_s^m$, and update $H^m$. Repeating these steps ensures that all arms are observed sufficiently during epoch $m$.
\begin{algorithm}[t]
    \LinesNumbered
    \SetAlgoLined
    \caption{SOG-BARBAT: Strongly Observable Graph-BARBAT}
    \label{algs:SOG-BARBAT}

    \KwIn{A Strongly Observable Directed Graph $G$}

    \textbf{Initialization:} 
    Set the initial round \( T_0 = 0 \), \( \Delta_k^0 = 1 \), and \( r_k^0 = 0 \) for all \( k \in [K] \).

    \For{epochs $m = 1,2,...$}{
        Set $\zeta_m \leftarrow (m + 4)2^{2(m+4)}\ln (K)$, and $\delta_m \leftarrow 1/(K\zeta_m)$
        
        Set $\lambda_m \leftarrow 2^8 \ln{\left(4K / \delta_m\right)}$ and $\beta_m \leftarrow \delta_m / K$.
        
        Set $n_k^m = \lambda_m (\Delta_k^{m-1})^{-2}$ for all arms $k \in [K]$.
        
        Set $N_m \leftarrow \lceil K \lambda_m 2^{2(m-1)} \rceil$ and $T_m \leftarrow T_{m-1} + N_m$.

        Select the arm \( k_m = \mathop{\arg\max}_{k \in [K]} r_k^{m-1} \).

        Build two arrays $Z_k^m \leftarrow 0$ and $H_k^m \leftarrow 0$ for all arms $k \in [K]$.

        Set $s = 1$, Copy graph $G$ to obtain a new graph $G_s^m$.
        
        \While{$H_k^m \geq n_k^m$ holds for all arms $k \in [K]$}{
        
            Run Algorithm \ref{algs:OODS} with parameter $G_s^m$ to obtain an out-dominating set $D_s^m$.
            
            Set $\cH_s^m = \min_{k \in [K]} (n_k^m - H_k^m)$.

            For each arm $k_i \in D_s^m$, set $Z_{k_i}^m = Z_{k_i}^m + \cH_s^m$, and $H_{k_j}^m = H_{k_j}^m + \cH_s^m$ for all arms $(k_i,k_j) \in E$ and self $k_i$, set $s \leftarrow s + 1$.

            Remove all arms which satisfies $H_k^m \geq n_k^m$ to obtain a new graph $G_s^m$.
        }

        Set
        $   
            \widetilde{n}_k^m = \begin{cases}
                Z_k^m & k \neq k_m \\
                N_m - \sum_{k \neq k_m}Z_k^m & k = k_m
            \end{cases}
        $,
        and
        $\hat{n}_{k_j}^m = \sum_{(k_i,k_j) \in E}\widetilde{n}_{k_i}^m$.
        
        \For{$t = T_{m-1} + 1$ to $T_m$}{
            Choose arm $I_t\sim p_m$ where $p_m(k)= \widetilde{n}_k^m / N_m$.

            Observe the corrupted reward $\widetilde{r}_{t,I_t}$ and update the total reward $S_{I_t}^m = S_{I_t}^m + \widetilde{r}_{t,I_t}$.
        }

        Set $r_k^m \leftarrow \min \{S_k^m / \hat{n}_k^m, 1\}$.
        Set $r_*^m \leftarrow \max_{k \in [K]}\left\{r_k^m - \sqrt{\frac{4\ln(4/\beta_m)}{\hat{n}_k^m}}\right\}$
        
        Set $\Delta_k^m \leftarrow \max\{2^{-m}, r_*^m - r_k^m\}$.
    }
\end{algorithm}
\begin{algorithm}[t]
    \LinesNumbered
    \SetAlgoLined
    \caption{OODS: Obtain an Out-Dominating Set}
    \label{algs:OODS}
    \KwIn{A Strongly Observable Directed Graph $G$}
    \KwOut{An Out-Dominating Set $D$}
    \While{the graph $G$ is empty}{
        \eIf{there exist cycles in graph $G$}{
            Select the vertex with the largest out-degree in the graph $G$ and add it to the set $D$.

            Remove the vertex and its out-degree neighbors from graph $G$.
        }{
            Find all no-root vertices and add them to the set $D$.

            Remove all no-root vertices and their out-degree neighbors from graph $G$.
        }
    }
\end{algorithm}
The regret bound for SOG-BARBAT as follows, the proof is given in Appendix~\ref{ape:sog}.
\begin{theorem}\label{the:sog-erb}
For any strongly observable directed graph $G = (K, E)$ with independence number $\alpha$, the expected regret of SOG-BARBAT satisfies
\[
    \BE\left[R(T)\right] = O\left(C + 
      \sum_{k\in \cI^*}
        \frac{\log(T)\log(KT)}{\Delta_k}
      +
      \frac{K\log\left(1/\Delta\right)\log\left(K/\Delta\right)}{\Delta}
    \right).
\]
For general strongly observable graphs, $\cI^*$ is the set of at most $\lfloor \alpha(1 + 2\ln(K/\alpha)) \rfloor$ arms with the smallest gaps. Specially, for acyclic graphs (include undirected graphs), $\cI^*$ is the set of at most $\alpha$ arms with the smallest gaps.
\end{theorem}
\begin{remark}
    The regret upper bound of SOG-BARBAT depends on $|\cI^*| = O(\alpha\ln(K/\alpha + 1))$, which matches the lower bound established by \cite{chen2023interpolating}. When $G$ is an acyclic graph, we can get $|\cI^*| \leq \alpha$, indicating that SOG-BARBAT performs better under this  condition.
    
    Compared to recent works~\citep{ito2022nearly,dann2023blackbox}, whose regret bounds depend on the smallest suboptimality gap $1/\Delta$, our bound reveals the relationship between the regret and the suboptimality gap of all arms. Notably, these works require prior knowledge of the independence number $\alpha$ which is NP-hard to compute, whereas SOG-BARBAT does not need such prior knowledge. %In the undirected setting, previous works~\citep{ito2024adaptive} achieve regret bounds on the factor of $O\!\bigl(\alpha \ln(K/\alpha + 1)\bigr)$, which is larger than our  regret bounds.
\end{remark}
