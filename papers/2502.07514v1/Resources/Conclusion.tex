\section{Conclusion}
\label{sec:con}
Building on the work of \citet{gupta2019better}, we propose the BARBAT framework by elaborately choosing epoch lengths $N_m$ and the parameters $\delta_m$. we also extend BARBAT to various corrupted bandit settings including strongly observable graph bandits, $d$-set semi-bandits, multi-agent bandits and batched bandits. The analysis shows that our algorithms can achieve near-optimal regret bounds for the adversarial corruption environments. Compared with FTRL-based methods, BARBAT and its extensions are more efficient and do not require the assumption of unique optimal action. Also, FTRL-based methods are intractable to parallelize so that it is not applicable to the multi-agent bandits and batched bandits. These advantages make the BARBAT framework an appealing alternative to FTRL algorithms for many corrupted bandits settings.

One future work is to improve the $\log^2(T)$ dependence in our regret bound to $\log(T)$. Investigating extensions in other bandits settings such as linear bandits is also a interesting future direction.
%Our work still leaves a gap that the term dependent on $T$ may carry an additional factor of $\log(T)$ compared to the theoretically optimal bound, likely owing to the epoch-based nature of our algorithms. %Another drawback is an additive $O(K/\Delta)$ term in the regret, which could potentially be further improved.
