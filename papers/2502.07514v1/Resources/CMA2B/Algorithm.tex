\subsection{Multi-Agent Multi-Armed Bandits}
\label{sec:cma2b}

In CMA2B, each agent can broadcast messages in one round to all $V$ agents. For simplicity, we define the total communication cost as:
\begin{align*}
\textrm{Cost}(T)\triangleq \sum_{i\in \cV}\sum_{t = 1}^{T}\mathbb{I}\{&\mathrm{agent~}i\text{ broadcasts a message to other agents in round } t\},   
\end{align*} and we aim to keep communication costs sub-linear in $T$.
%Given growing interest in distributed systems, multi-agent bandit algorithms are increasingly important: collaboration often reduces single-agent regret by a factor of $V$~\citep{liu2021cooperative,wang2022achieving,ghaffari2024multi}.

We extend BARBAT to MA-BARBAT (Algorithm~\ref{algs:MA-BARBAT}) with only minor adjustments. %In BARBAT, the agent updates the total reward during each epoch and estimates values at the epochâ€™s end. 
In MA-BARBAT, we split the epoch into $V$ parts, allowing each agent to pull arms with identical probabilities and then broadcast the total rewards at the end. This ensures the combined reward is equivalent to that in a (unsplit) epoch by a single agent. Each agent $v$ broadcasts $\{S_{v,k}^m\}_{k=1}^K$ at the end of an epoch, enabling all agents to compute $\Delta_k^{m-1}$ from others' observations.
\begin{algorithm}[t]
    \LinesNumbered
    \SetAlgoLined
    \caption{MA-BARBAT: Multi-Agent-BARBAT}
    \label{algs:MA-BARBAT}

    \SetKwInOut{Input}{Input}
    \SetKwInOut{Output}{Output}
    
    \textbf{Initialization:} 
    Set the initial round \( T_0 = 0 \), \( \Delta_k^0 = 1 \), and \( r_k^0 = 0 \) for all \( k \in [K] \).

    \For{epoch \( m = 1, 2, \dots \)}{
        Each agent sets \( \zeta_m \leftarrow (m + 4) 2^{2(m+4)} \ln(VK) \) and \( \delta_m \leftarrow 1 / VK \zeta_m \). 
        
        Each agent sets \( \lambda_m \leftarrow 2^8 \ln\left( 4K / \delta_m \right) / V \), \( \beta_m \leftarrow \delta_m / VK \).
        
        Each agent sets \( n_k^m \leftarrow \lambda_m (\Delta_k^{m-1})^{-2} \) for all $k \in [K]$.
        
        Each agent sets \( N_m \leftarrow \lceil K \lambda_m 2^{2(m-1)} \rceil\) and \( T_m \leftarrow T_{m-1} + N_m \).

        Each agent selects the arm \( k_m = \mathop{\arg\max}_{k \in [K]} r_k^{m-1} \). In case of ties (multiple arms with the same \( r_k^{m-1} \)), select the arm with the smallest index as \( k_m \).

        Each agent sets:
        \[
        \widetilde{n}_k^m = 
        \begin{cases}
            n_k^m & \text{if } k \neq k_m \\
            N_m - \sum_{k \neq k_m} n_k^m & \text{if } k = k_m
        \end{cases}
        \]
        
        \For{$t = T_{m-1} + 1$ \textbf{to} \( T_m \)}{
            Each agent chooses arm \( I_t \sim p_m \), where \( p_m(k) = \widetilde{n}_k^m / N_m \).
            
            Each agent observes the corrupted reward \( \widetilde{r}_{t,I_t} \) and updates the total reward:
            $S_{I_t}^m = S_{I_t}^m + \widetilde{r}_{t,I_t}.$
        }
        
        Each agent $v$ broadcasts the messages $\{S_{v,k}^m\}_{k \in [K]}$ to other agents.
        
        Each agent sets $r_k^m \leftarrow \min \{\sum_{v \in [V]}S_{v,k}^m / (V\widetilde{n}_k^m), 1\}$.
        
        Each agent sets $r_*^m \leftarrow \max_{k \in [K]}\left\{r_k^m - \sqrt{\frac{4\ln(4/\beta_m)}{V\widetilde{n}_k^m}}\right\}$.
        
        Each agent set $\Delta_k^m \leftarrow \max\{2^{-m}, r_*^m - r_k^m\}$.
    }
\end{algorithm}

%Using the same approach, we can also transform other algorithms designed for single-agent settings into algorithms that can operate in a multi-agent setting.
We show that our MA-BARBAT algorithm have the following regret bound. The proof is given in Appendix \ref{ape:cma2b}.
\begin{theorem}
\label{the:ma-erb}    % The expected regret of Algorithm MA-BARBAT
    With only $V\log(VT)$ communication cost, we can guarantee the expected individual regret of each agent $i$ as follows:
    \[\BE\left[R(T)\right] = O\left(\frac{C}{V} + \sum_{\Delta_k > 0}\frac{\log(VT)\log(KVT)}{V\Delta_k} + \frac{K\log\left(1/\Delta\right)\log\left(KV / \Delta\right)}{V\Delta}\right).\]
\end{theorem}
Compared with previous works~\citep{liu2021cooperative} which achieves $O(VC + \frac{K\log^2(T)}{\Delta})$ regret and the concurrent work~\citep{ghaffari2024multi} which achieve $O(C/V + \frac{K\log^2(T)}{V\Delta})$, our regret bound is better.
    %Furthermore, the work by \cite{liu2021cooperative} does not achieve near-optimal individual regret, with the worst-case performance being as large as the group regret. %Finally, MA-BARBAT does not require prior knowledge of the time horizon $T$.

\begin{remark}
Our regret bound shows that collaboration can reduce the individual regret of each agent by a factor of $V$. Notice that some previous works~\cite{wang2022achieving} for CMA2B without corruptions only require $o(\log(T))$ communication cost, but these methods significantly depends on the assumption of unique best arm. For the case with multiple best arms, it is still unknown whether $o(\log(T))$  communication cost is enough.  
    %
\end{remark}