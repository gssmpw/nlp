\section{Proof of Theorem \ref{the:ma-erb}}
\label{ape:cma2b}

\subsection{Notations}
We define $C_k^m$ as the sum of corruptions to arm $k$ in epoch $m$ for all agents $v \in [V]$, and let $C_m \triangleq \max_{k \in [K]}C_k^m$.

\subsection{Lemmas for Proving Theorem \ref{the:ma-erb}}

\begin{lemma}
\label{lem:tnem} % The number of epochs (Multi-Agent)
    For the MA-BARBAT algorithm time horizon $T$, the number of epochs $M$ is at most $\log(VT)$. In the $m$-th epoch, the selected arm $k_m$ must satisfy $\Delta_{k_m}^{m-1} = 2^{-(m-1)}$ for all agents $v \in [V]$.
\end{lemma}
\begin{proof}
    The length of epoch $m$ is given by $N_m = \lceil K \lambda_m 2^{2(m-1)} \rceil \geq 2^{2(m-1)} / V$. From the lower bound of $N_m$, we can complete the first statement. Since $\Delta_k^{m-1} \leftarrow \max\{2^{-(m-1)}, r_*^m - r_k^m\}$, there exists at least one arm that satisfies $\Delta_k^{m-1} = 2^{-(m-1)}$ and all arms satisfy $\Delta_k^{m-1} \leq 2^{-(m-1)}$. Since $r_{k_m}^{m-1} > r_{*}^{m-1}$, the equality $\Delta_{k_m}^{m-1} = 2^{-(m-1)}$ must hold.
\end{proof}
Since the length $N_m$ still satisfies $N_m = \lceil K \lambda_m 2^{2(m-1)} \rceil \geq \sum_{k \in [K]}n_k^m$, Lemma \ref{lem:rkc} still holds for this setting.
\begin{lemma}
\label{lem:trlm}    % The ratio of lambda (Multi-Agent)
    For epoch $s$ and $m$ with $1\le s \leq m$, the following inequality holds:
    \[\frac{\lambda_m}{\lambda_s} \leq \left(\frac{7}{6}\right)^{m-s}.\]
\end{lemma}
\begin{proof}
    We first show that the function $f(x)=\frac{(x+1.7)\ln(4)+\ln(x)}{(7/6)^x}$
    is strictly decreasing for $x\ge 5$.
    Notice that the derivative function \[f'(x)=\frac{(\ln(4)+1/x)-((x+1.7)\ln(4)+\ln(x))\ln\left(\frac{7}{6}\right)}{\left(\frac{7}{6}\right)^{x}}\]
    is monotonically decreasing and $f'(5)<0$, thus we have $f'(x)<0$ for $x\ge 5$, which indicates that $f(x)$ is strictly decreasing.
    Since $K\ge 2$ and $V\ge 1$, we can get
    \begin{align*}
    \frac{\lambda_m}{\lambda_s}=&\, \frac{\ln(4VK^2\ln(VK)(m+4)2^{2(m+4)})}{\ln(4VK^2\ln(VK)(s+4)2^{2(s+4)})}\\
    =& \,\frac{\ln(4VK^2\ln(VK))+\ln(m+4)+(m+4)\ln(4)}{\ln(4VK^2\ln(VK))+\ln(s+4)+(s+4)\ln(4)}\\
    <& \,\frac{1.7\cdot\ln(4)+\ln(m+4)+(m+4)\ln(4)}{1.7\cdot\ln(4)+\ln(s+4)+(s+4)\ln(4)}\\
    =&\,\frac{f(m+4)}{f(s+4)}\left(\frac{7}{6}\right)^{m-s}<\left(\frac{7}{6}\right)^{m-s}
    \end{align*}
where we use the monotonicity of $f(x)$ and the fact that $K\ge 2$ and $V\ge 1$.
\end{proof}

\begin{lemma}
\label{lem:tslm}     % The sum of lambda (Multi-Agent)
    For any epoch $m$, the following inequality holds:
    \[\sum_{s=1}^{m} \lambda_s \leq 2^8(m^2 + m(10+\ln(VK))).\]
\end{lemma}
\begin{proof}
    Given the function $f(x) = 2x(1-\ln(2)) - \ln(x+4) + 7 - 8\ln(2)$. Notice that the derivative function as $f'(x) = 2 - 2\ln(2) - \frac{1}{x+4} > 0$ for all $x \geq 1$, which means that $f(x)$ is strictly increasing for $x \geq 1$. Since $f(x) \geq f(1) \geq 0$, we can get the inequality as $2x + 7 \geq 2(x+4)\ln(2) + \ln(x+4)$ for all $x \geq 1$, then have
    \begin{align*}
        \sum_{s=1}^{m} \lambda_s &= \sum_{s=1}^{m} 2^8(\ln(4VK^2\ln(VK)(s+4)2^{2(s+4)})) \\
        &= \sum_{s=1}^{m} 2^8(2(s+4)\ln(2) + \ln(s+4) + \ln(4VK^2\ln(VK)) \\
        &\leq \sum_{s=1}^{m} 2^8(2s + 7 + \ln(4V^2K^3)) \\
        &= 2^8(m^2 + 8m + m\ln(4V^2K^3)) \\
        &\leq 2^8(m^2 + m(10+3\ln(VK))).
    \end{align*}
\end{proof}

\begin{lemma}
\label{lem:berm} % Bound the experimental reward (Multi-Agent)
    For any fixed $k,m$ and any $\beta_m \geq 4e^{-V\lambda_m/16}$, Algorithm \ref{algs:MA-BARBAT} satisfies
    \[\Pr\left[|r_k^m - \mu_k| \geq \sqrt{\frac{4\ln(4/\beta_m)}{V \widetilde{n}_k^m}} + \frac{2C_m}{V N_m}\right] \leq \beta_m.\]
\end{lemma}
\begin{proof}
    Since in each epoch $m$, all agents have the same probability $p_m(k)$ of pulling each arm $k$. Using the method as Lemma \ref{lem:ber}, we set an indicator variable $Y_{v,k}^t$, which determines whether the agent $v$ updates the corrupted reward $\widetilde{r}_{v,I_t}$ into the total reward $S_{v,I_t}^m$ at step $t$. We define the corruption at step $t$ on arm $k$ for agent $v$ as $C_{v,k}^t := \widetilde{r}_{v,k}^t - r_{v,k}^t$. Let $E_m := [T_{m-1} + 1,...,T_m]$ represent the $N_m$ time-steps for epoch $m$. Since $r_k^m = \min\{\sum_{v\in [V]}S_{v,k}^m / (V \widetilde{n}_k^m), 1\}$, we can obtain
    \[r_k^m \leq \sum_{v\in [V]}\frac{S_{v,k}^m}{V \widetilde{n}_k^m} = \frac{1}{V \widetilde{n}_k^m}\sum_{t \in E_m}\sum_{v\in [V]}Y_{v,k}^t (r_{v,k}^t + C_{v,k}^t).\]
    We can divide the sum to two components:
    \[A_k^m = \sum_{t \in E_m}\sum_{v\in [V]}Y_{v,k}^t r_{v,k}^t, \quad B_k^m = \sum_{t \in E_m}\sum_{v\in [V]}Y_{v,k}^t C_{v,k}^t.\]
    For the previous component $A_k^m$, notice that $r_k^t$ is dependently drawn from an unknown distribution with mean $\mu_k$, and $Y_{v,k}^t$ is dependently drawn from a Bernoullvdistribution with mean $q_k^m := \widetilde{n}_k^m / N_m$. Therefore, we have
    \[\mathbb{E}[A_k^m] = V N_m q_k^m \mathbb{E}[r_k^t] = V \widetilde{n}_k^m \mu_k \leq V \widetilde{n}_k^m.\]
    By applying the Chernoff-Hoeffding inequality (Theorem 1.1 in \cite{dubhashi2009concentration}), we can get
    \begin{equation}
    \label{eqs:Akmm}
        \Pr\left[\left|\frac{A_k^m}{V \widetilde{n}_k^m} - \mu_k\right|\geq \sqrt{\frac{3\ln(4/\beta_m)}{V \widetilde{n}_k^m}}\right] \leq \frac{\beta_m}{2}.
    \end{equation}
    For the latter component $B_k^m$, we need to define a martingale difference sequence $X_i^1,...,X_i^T$, where $X_i^t = (Y_{v,k}^t - q_k^m) C_{v,k}^t$ for all $t$, with respect to the historical information $\{\mathcal{F}\}_{t=1}^T$. Since the corruption $C_{v,k}^t$ becomes a deterministic value when conditioned on $\mathcal{F}_{t-1}$ and $\mathbb{E}[Y_{v,k}^t | \mathcal{F}_{t-1}] = q_k^m$, we can get
    \[\mathbb{E}[X_i^t|\mathcal{F}_{t-1}] = \mathbb{E}[Y_{v,k}^t - q_k^m|\mathcal{F}_{t-1}] C_{v,k}^t = 0.\]
    Additionally, we have $|X_i^t| \leq 1$ for all $t$ and all $v \in [V]$, and the predictable quadratic variation of this martingale can be bounded as follows:
    \[\Var = \sum_{t \in E_m} \sum_{v\in [V]} \mathbb{E}[(X_i^t)^2|\mathcal{F}_{t-1}] \leq \sum_{t \in E_m}\sum_{v\in [V]}|C_{v,k}^t|\Var(Y_{v,k}^t) \leq q_k^m \sum_{t \in E_m}\sum_{v\in [V]}|C_{v,k}^t|.\]
    By applying the concentration inequality for martingales (Theorem 1 in \cite{beygelzimer2011contextual}), with probability at least $1-\frac{\beta_m}{4}$, we have
    \[B_k^m \leq q_k^m \sum_{t \in E_m}\sum_{v\in [V]} C_{v,k}^t + \Var + \ln(4/\beta_m) \leq 2q_k^m \sum_{t \in E_m}\sum_{v\in [V]}|C_{v,k}^t| + \ln(4/\beta_m).\]
    Since $q_k^m = \widetilde{n}_k^m / N_m$, $\sum_{t \in E_m}\sum_{v\in [V]}|C_{v,k}^t| \leq C_m$ and $n_k^m \geq \lambda_m \geq 16\ln(4/\beta_m) / V$, with probability at least least $1-\frac{\beta_m}{4}$, we can get the following inequality:
    \[\frac{B_k^m}{V \widetilde{n}_k^m} \leq \sqrt{\frac{\ln(4 /\beta_m)}{16V \widetilde{n}_k^m}} + \frac{2C_m}{V \widetilde{n}_k^m}.\]
    Similarly, $-\frac{B_k^m}{V \widetilde{n}_k^m}$ also meets this bound with probability $1 - \beta / 4$. Therefore, we have
    \begin{equation}
    \label{eqs:Bkmm}
        \Pr\left[\left|\frac{B_k^m}{V \widetilde{n}_k^m}\right| \geq \sqrt{\frac{\ln(4 /\beta_m)}{16V \widetilde{n}_k^m}} + \frac{2C_m}{V N_m}\right] \leq \frac{\beta_m}{2}.
    \end{equation}
    Combine Eq. \ref{eqs:Akmm} and Eq. \ref{eqs:Bkmm}, we complete the proof. 
\end{proof}

We also define an event $\cE_m$ for epoch $m$ as follows:
\begin{equation*}
    \cE_m \triangleq \left\{ \forall\ k: |r_k^m - \mu_k| \leq \sqrt{\frac{4\ln(4/\beta_m)}{V \widetilde{n}_k^m}} + \frac{2C_m}{VN_m} \right\}.
\end{equation*}

\begin{lemma}
\label{lem:pemm} % The probability of cE_m (Multi-Agent)
     For any epoch $m$, event $\cE_m$ holds with probability at least $1 - \delta_m$. And after rigorous calculation, we have $1 / \delta_m \geq V N_m$.
\end{lemma}
\begin{proof}
    By Lemma \ref{lem:berm}, we can get
    \[\Pr\left[|r_k^m - \mu_k| \leq \sqrt{\frac{4\ln(4/\beta_m)}{V \widetilde{n}_k^m}} + \frac{2C_m}{V N_m}\right] \leq 2\beta_m = \frac{\delta_m}{VK}.\]
    A union bound over the $V$ agents and the $K$ arms conclude the proof.

    Since $m \geq 1$, $V \geq 1$ and $K \geq 2$, then we can get
    \begin{align*}
        V N_m &= KV 2^{2(m-1)} \lambda_m \\
        &= K 2^{2(m+3)}\ln((m+4) 2^{2(m+5)} VK^2 \ln(K))  \\
        &\leq K 2^{2(m+3)} (\ln(m+4) + 2(m+5)\ln(2) + \ln(VK^3)) \\
        &\leq K 2^{2(m+4)} ((m + 4)\ln (VK)) \\
        &\leq 1 / \delta_m.
    \end{align*}
\end{proof}

As mentioned before, for each epoch $m$, to unify the varying bounds depending on the occurrence of event $\cE_m$, we also define the offset level
\[D_m = \begin{cases}
    2C_m & \textit{when $\cE_m$ occurs} \\
    V N_m & \textit{when $\cE_m$ dose not occur}
\end{cases}.\]
This way we can always guarantee the following inequality:
\[|r_k^m - \mu_k| \leq \sqrt{\frac{4\ln(4/\beta_m)}{V \widetilde{n}_k^m}} + \frac{D_m}{V N_m}.\]
By the definition of $D_m$, we have 
\[\Pr[D_m = 2C_m] \geq 1 - \delta_m \quad \text{ and } \quad \Pr[D_m = N_m] \leq \delta_m.\]
Next, we will bound the estimated gap $\Delta_k^m$. To start, we define the discounted offset rate as
\[\rho_m := \sum_{s=1}^m \frac{D_s}{8^{m-s}VN_s}.\]
Then we have the following lemma.
\begin{lemma}
\label{lem:bsgm} %   Bound the suboptimality-gap (Multi-Agent)
    For all epochs $m$ and arms $k$, we can have
    \[\frac{4}{7}\Delta_k - \frac{3}{4}2^{-m} - 6 \rho_m \leq \Delta_k^{m} \leq \frac{8 \Delta_k}{7} + 2^{-(m-1)} + 2\rho_m.\]
\end{lemma}
\begin{proof}
    Since $|r_k^m - \mu_k| \leq \sqrt{\frac{4\ln(4 /\beta_m)}{V\widetilde{n}_k^m}} + \frac{D_m}{VN_m}$, we have
    \[-\frac{D_m}{VN_m} - \sqrt{\frac{4\ln(4 /\beta_m)}{V\widetilde{n}_k^m}} \leq r_{k}^m - \mu_{k} \leq \frac{D_m}{VN_m} + \sqrt{\frac{4\ln(4 /\beta_m)}{V\widetilde{n}_k^m}}.\]
    Additionally, since
    \[r_{*}^m \leq \max_k \left\{\mu_{k} + \frac{D_m}{VN_m} + \sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{Vn}_k^m}} - \sqrt{\frac{4\ln(4 /\beta_m)}{V\widetilde{n}_k^m}}\right\} \leq \mu_{k^*} + \frac{D_m}{VN_m},\]
    \[r_{*}^m = \max_k \left\{r_k^m - \sqrt{\frac{4\ln(4 /\beta_m)}{V\widetilde{n}_k^m}}\right\} \geq r_{k^*}^m - \sqrt{\frac{4\ln(4 /\beta_m)}{V\widetilde{n}_{k^*}^m}} \geq \mu_{k^*} - 2\sqrt{\frac{4\ln(4 /\beta_m)}{V\widetilde{n}_{k^*}^m}} - \frac{D_m}{VN_m},\]
    we can get
    \[-\frac{D_m}{VN_m} - 2\sqrt{\frac{4\ln(4 /\beta_m)}{V\widetilde{n}_{k^*}^m}} \leq r_{*}^m - \mu_{k^*} \leq \frac{D_m}{VN_m}.\]
    According to Algorithm \ref{algs:BARBAT} and Lemma \ref{lem:rkc}, we have $\widetilde{n}_k^m \geq n_k^m$ for all arms $k$. Then we have the following inequality for all $k\in [K]$:
    \[\sqrt{\frac{4\ln(4 /\beta_m)}{V\widetilde{n}_k^m}} \leq \sqrt{\frac{4\ln(4 /\beta_m)}{Vn_k^m}} = \frac{\Delta_k^{m-1}}{8}.\]

    We now establish the upper bound for $\Delta_k^m$ by induction on $m$.
    
    For the base case $m = 1$, the statement is trivial as $\Delta_k^1 = 1$ for all $k \in [K]$.
    
    Assuming the statement is true for the case of $m-1$, we have
    \begin{equation*}
    \begin{split}
        \Delta_k^m = r_*^m - r_k^m
        &= (r_*^m - \mu_{k^*}) + (\mu_{k^*} - \mu_k) + (\mu_k - r_k^m) \\
        &\leq \frac{D_m}{VN_m}+ \Delta_k + \frac{D_m}{VN_m} + \frac{1}{8}\Delta_k^{m-1} \\
        &\leq \frac{2D_m}{VN_m} + \Delta_k + \frac{1}{8}\left(\frac{8 \Delta_k}{7} + 2^{-(m-2)} + 2\rho_{m-1}\right) \\
        &\leq \frac{8 \Delta_k}{7} + 2^{-(m-1)} + 2\rho_m,
    \end{split}
    \end{equation*}
    Where the second inequality follows from the induction hypothesis.
     
    Next, we provide the lower bound of $\Delta_k^m$. We can get
    \begin{equation*}
    \begin{split}
        \Delta_k^m =  r_*^m - r_k^m
        &= (r_*^m - \mu_{k^*}) + (\mu_{k^*} - \mu_k) + (\mu_k - r_k^m) \\
        &\geq -\frac{D_m}{VN_m} - \frac{1}{4}\Delta_{k^*}^{m-1} + \Delta_k -\frac{D_m}{VN_m} - \frac{1}{8}\Delta_k^{m-1} \\
        &\geq -\frac{2D_m}{VN_m} + \Delta_k - \frac{3}{8}\left(\frac{8 \Delta_k}{7} + 2^{-(m-2)} + 2\rho_{m-1}\right) \\
        &\geq \frac{4}{7}\Delta_k - \frac{3}{2}2^{-m} - 6\rho_m.
    \end{split}
    \end{equation*}
    where the third inequality comes from the upper bound of $\Delta_k^{m-1}$.
\end{proof}

We only introduces a small change into the parameter $\lambda_m$, by simple calculation, Lemma \ref{lem:trl} still holds.

\subsection{Proof for Theorem \ref{the:ma-erb}}

We first define the regret $R_k^m$ generated by arm $k$ in epoch $m$ for agent $v$ as 
\[R_{v,k}^m\triangleq\Delta_k\widetilde{n}_{v,k}^m=\begin{cases}
    \Delta_kn_{k}^m & k\neq k_m\\
    \Delta_k\widetilde{n}_{k}^m & k=k_m
\end{cases}.\]
Then we analyze the regret in following three cases:

\paragraph{Case 1:} $0<\Delta_k\le 64\rho_{m-1}$.\\ %$k\in\cA^m$.
If $k \neq k_m$, then we have \[R_{v,k}^m=\Delta_k n_{k}^m\le 64\rho_{m-1}n_{k}^m .\] 
If $k=k_m$, then we have \[R_{v,k}^m=\Delta_k\widetilde{n}_{k_m}^m\le 64\rho_{m-1}N_m.\]

\paragraph{Case 2:} $\Delta_k \leq 8 \cdot 2^{-m}$ and $\rho_{m-1} \leq \frac{\Delta_k}{64}$.\\
If $k \neq k_m$, then we have \[R_{v,k}^m=n_{k}^m\Delta_k =\lambda_m(\Delta_k^{m-1})^{-2} \Delta_k \leq \lambda_m 2^{2(m-1)} \Delta_k  \leq \frac{16 \lambda_m}{\Delta_k}.\] 
If $k=k_m$, since $\Delta_{k_m}^{m-1} = 2^{-(m-1)}$, we can get:
\begin{align*}
    R_{v,k}^m=\widetilde{n}_{k_m}^m \Delta_{k_m} \leq 
    N_m\Delta_{k_m} = \lceil K \lambda_m 2^{2(m-1)} \rceil \Delta_{k_m} \leq \frac{16K\lambda_m}{\Delta_{k_m}} + \Delta_{k_m} \leq \frac{16K\lambda_m}{\Delta} + 1.
\end{align*}

\paragraph{Case 3:} $\Delta_k > 8 \cdot 2^{-m}$ and $\rho_{m-1} \leq \frac{\Delta_k}{64}$.\\
By Lemma \ref{lem:bsg} we have
\[\Delta_k^{m-1} \geq \frac{4}{7}\Delta_k - \frac{3}{2}2^{-m} - \frac{6}{64}\Delta_k \geq \Delta_k\left(\frac{4}{7} - \frac{3}{16} - \frac{6}{64}\right) \geq 0.29 \Delta_k.\]
In this case, it is impossible that $k=k_m$ because $\Delta_{k_m}^{m-1} = 2^{-(m-1)}<0.29\cdot 8\cdot 2^{-m}<0.29\Delta_k$.
So we can obtain
\begin{align*}
   R_{v,k}^m= n_k^m \Delta_k = \lambda_m(\Delta_k^{m-1})^{-2} \Delta_k
    \leq \frac{\lambda_m}{0.29^2 \Delta_k} 
    \leq \frac{16\lambda_m}{\Delta_k}.
\end{align*}

We define $\cA^m\triangleq\left\{ k\in[K]\,\big|\,0<\Delta_k\le 64\rho_{m-1} \right\}$ for epoch $m$. By combining all three cases, we can upper bound the regret for agent $v$ as
\begin{equation}\label{eq:cma2b-regret}
\begin{split}
R(T)=&\sum_{m=1}^M\Bigg(\sum_{k \in \mathcal{A}^m} R_k^m + \sum_{k \notin \mathcal{A}^m} R_k^m\Bigg)\\    
\le& \sum_{m=1}^M\Bigg( 64\rho_{m-1}N_m+\sum_{k \in \mathcal{A}^m,k\neq k_m} 64\rho_{m-1}n_k^m + \sum_{k \notin \mathcal{A}^m, \Delta_k>0} \frac{16\lambda_m}{\Delta_k}\\
&+ \left(\frac{16K\lambda_m}{\Delta} + 1\right)\BI(0<\Delta_{k_m} \le 8 \cdot 2^{-m}) \Bigg)\\ 
\le& \sum_{m=1}^M\Bigg( 64\rho_{m-1}N_m+\sum_{\Delta_k>0} 64\rho_{m-1}n_k^m + \sum_{\Delta_k>0} \frac{16\lambda_m}{\Delta_k} \\
&+ \left(\frac{16K\lambda_m}{\Delta} + 1\right)\BI\left(m\le \log_2\left(8/\Delta\right)\right)\Bigg)\\ 
\le& \sum_{m=1}^M\Bigg( 128\rho_{m-1}N_m + \sum_{\Delta_k>0} \frac{16\lambda_m}{\Delta_k}\Bigg) 
+ \sum_{m=1}^{\log_2(8/\Delta)}\left(\frac{16K\lambda_m}{\Delta} + 1\right)
\end{split}
\end{equation}
where the last inequality uses the fact that $\sum_{\Delta_k>0} n_k^m\le N_m$. Notice that we can bound the expectation of the offset level as
\[\mathbb{E}[D_m] = 2(1-\delta_m)C_m + \delta_m N_m \leq 2C_m + 1\]
and we can bound $\sum_{m=1}^M \rho_{m-1} N_m$ as
\begin{equation}\label{eq:cma2b-rho}
    \begin{split}
        %\sum_{m=1}^M \sum_{k \in \mathcal{A}^m} \rho_{m-1}n_k^m
        \sum_{m=1}^M \rho_{m-1} N_m
        &\leq \sum_{m=1}^M \left(\sum_{s=1}^{m-1}\frac{D_s}{8^{m-1-s}VN_s}\right)N_m \\
        &= \frac{4}{V}\sum_{m=1}^M \left(\sum_{s=1}^{m-1}\frac{(4^{m-1-s} + 1)\lambda_m}{8^{m-1-s}\lambda_s}D_s\right) \\
        &= \frac{4}{V}\sum_{m=1}^M \left(\sum_{s=1}^{m-1}\left((7/12)^{m-1-s} + (7/48)^{m-1-s}\right)D_s\right) \\
        &= \frac{4}{V}\sum_{s=1}^{M-1} D_s \sum_{m=s+1}^M (7/12)^{m-1-s} + (7/48)^{m-1-s}\\
        &\leq \frac{4}{V}\left(\sum_{m=1}^{M-1} D_m\right)\sum_{j=0}^{\infty} \left(7/12\right)^{j} + (7/48)^{j} 
        \leq \frac{11}{V}\sum_{m=1}^{M-1} D_m.
    \end{split}
\end{equation}
Combining Eq.~\eqref{eq:cma2b-regret} and Eq.~\eqref{eq:cma2b-rho}, by Lemma \ref{lem:tslm}, we can get
\begin{equation*}
    \begin{split}
        \BE[R_i(T)]
        &\leq \sum_{m=1}^{M-1} 1440 \BE[D_m] + \sum_{m=1}^M \sum_{\Delta_k > 0}\frac{16\lambda_m}{\Delta_k} + \sum_{m=1}^{\log_2(8/\Delta)}\left(\frac{16K\lambda_m}{\Delta} + 1\right)\\
        &\leq \sum_{m=1}^{M-1} 1440 \BE[D_m] + \sum_{\Delta_k > 0}\frac{2^{12}(\log^2(VT) + 3\log(VT)\log(30VK))}{V\Delta_k} \\
        &\quad + \frac{2^{12}K(\log^2(8/\Delta) + 3\log(8/\Delta)\log(30VK)))}{V\Delta} + \log(8/\Delta) \\
        &\leq \sum_{m=1}^{M-1} 2880 \frac{C_m}{V} + 1440 + \sum_{\Delta_k > 0}\frac{2^{14}\log(VT)\log(30VKT)}{V\Delta_k} \\
        &\quad+ \frac{2^{14}K\log(8/\Delta)\log(240VK / \Delta)}{V\Delta} + \log(8/\Delta)\\ 
        &= O\left(\frac{C}{V} + \sum_{\Delta_k > 0}\frac{\log(T)\log(VKT)}{V\Delta_k} + \frac{K\log(1 / \Delta)\log(VK / \Delta)}{V\Delta}\right).
    \end{split}
\end{equation*}
So the cumulative regret for all agents as
\[\BE[R(T)] = O\left(C + \sum_{\Delta_k > 0}\frac{\log(VT)\log(VKT)}{\Delta_k} + \frac{K\log(1 / \Delta)\log(VK / \Delta)}{\Delta}\right).\]
And each agent only broadcast messages in the end of each epoch, so the communication cost of MA-BARBAT as follows:
\[\textrm{Cost}(T) = \sum_{v \in [V]} M = O(V\log(VT)).\]