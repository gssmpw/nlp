 \section{Proof of Theorem \ref{the:bb-erb}}
\label{ape:bb}

\subsection{Notations}
We define $C_k^m$ as the sum of corruptions to arm $k$ in epoch $m$, and let $C_m \triangleq \max_{k \in [K]}C_k^m$.

\subsection{Lemmas for Proving Theorem \ref{the:bb-erb}}

\begin{lemma}
\label{lem:tnebb} % The number of epochs (Batched Bandits)
    For the BB-BARBAT algorithm time horizon $T$, the number of epochs $M$ is at most $\min \{\cM, \log(T)\}$. In the $m$-th epoch, the selected arm $k_m$ must satisfy $\Delta_{k_m}^{m-1} = a^{-(m-1)}$.
\end{lemma}
\begin{proof}
    The length of epoch $m$ is given by $N_m = K \lambda_m a^{2(m-1)} \geq a^{2(m-1)}$. From the lower bound of $N_m$ and $a = \max \{T^{\frac{1}{2(\cM + 1)}}, 2\}$, we can complete the first statement. Since $\Delta_k^{m-1} \leftarrow \max\{a^{-(m-1)}, r_*^m - r_k^m\}$, there exists at least one arm that satisfies $\Delta_k^{m-1} = a^{-(m-1)}$ and all arms satisfy $\Delta_k^{m-1} \leq a^{-(m-1)}$. Since $r_{k_m}^{m-1} > r_{*}^{m-1}$, the equality $\Delta_{k_m}^{m-1} = 2^{-(m-1)}$ must hold.
\end{proof}

\begin{lemma}
\label{lem:bb-rkc} % The reason of k_m (Batched Bandits)
    For any epoch $m$, the length $N_m$ satisfies $N_m \geq \sum_{k \in [K]} n_k^m$.
\end{lemma}
\begin{proof}
    Since $\Delta_k^m = \max \{a^{-m}, r_*^m - r_k^m\} \geq a^{-m}$, we can get
    $n_k^m = \lambda_m (\Delta_k^{m-1})^{-2} \leq \lambda_m a^{2(m-1)}.$
    Therefore, we have
    $\sum_{k \in [K]}n_k^m \leq K \lambda_m a^{2(m-1)} = N_m.$
\end{proof}

\begin{lemma}
\label{lem:bb-trl}    % The ratio of lambda (Batched Bandits)
    For epoch $s$ and $m$ with $1\le s \leq m$, the following inequality holds:
    \[\frac{\lambda_m}{\lambda_s} \leq \left(\frac{7}{5}\right)^{m-s}.\]
\end{lemma}
\begin{proof}
    We first show that the function $f(x)=\frac{x\ln(a^2)+\ln(x)}{(7/5)^x}$
    is strictly decreasing for $x\ge 5$, where $a = \max \{T^{\frac{1}{2(\cM + 1)}}, 2\} \ge 2$.
    Notice that the derivative function \[f'(x)=\frac{(\ln(a^2)+1/x)-(x\ln(a^2)+\ln(x))\ln\left(\frac{7}{5}\right)}{\left(\frac{7}{5}\right)^{x}}\]
    is monotonically decreasing and $f'(5)<0$, thus we have $f'(x)<0$ for $x\ge 5$, which indicates that $f(x)$ is strictly decreasing.
    Since $K\ge 2$, we can get
    \begin{align*}
    \frac{\lambda_m}{\lambda_s}=&\, \frac{\ln(4K^2\ln(K)(m+4)a^{2(m+4)})}{\ln(4K^2\ln(K)(s+4)a^{2(s+4)})}\\
    =& \,\frac{\ln(4K^2\ln(K))+\ln(m+4)+(m+4)\ln(a^2)}{\ln(4K^2\ln(K))+\ln(s+4)+(s+4)\ln(a^2)}\\
    <& \,\frac{\ln(m+4)+(m+4)\ln(a^2)}{\ln(s+4)+(s+4)\ln(a^2)}\\
    =&\,\frac{f(m+4)}{f(s+4)}\left(\frac{7}{5}\right)^{m-s}<\left(\frac{7}{5}\right)^{m-s}
    \end{align*}
where we use the monotonicity of $f(x)$ and the fact that $K\ge 2$.
\end{proof}

\begin{lemma}
\label{lem:bb-tsl}     % The sum of lambda (Batched Bandits)
    For any epoch $m$, the following inequality holds:
    \[\sum_{s=1}^{m} \lambda_s \leq 2a^8\ln(a)(m^2 + 3m(2 + \ln(K))).\]
\end{lemma}
\begin{proof}
    Since $a \ge 2$ and $K \geq 2$, we can have
    \begin{align*}
        \sum_{s=1}^{m} \lambda_s &= \sum_{s=1}^{m} a^8(\ln(4K^2\ln(aK)(s+4)a^{2(s+4)})) \\
        &= \sum_{s=1}^{m} a^8(2(s+4)\ln(a) + \ln(s+4) + \ln(4K^2\ln(aK)) \\
        &\leq \sum_{s=1}^{m} a^8(2(s+4)\ln(a) + 2(s+1)\ln(a) + 6\ln(K)\ln(a)) \\
        &\leq \sum_{s=1}^{m} a^8\ln(a)(4s + 10 + 6\ln(K)) \\
        &= 2a^8\ln(a)(m^2 + 3m(2 + \ln(K))).
    \end{align*}
\end{proof}

We can also guarantee Lemma \ref{lem:ber} still holds. As mentioned before, given the definition of an event $\cE_m$ as follows:
\begin{equation*}
    \cE_m \triangleq \left\{ \forall\ k: |r_k^m - \mu_k| \leq \sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_k^m}} + \frac{2C_m}{N_m} \right\}.
\end{equation*}
Then we can establish a lower bound on the probability of the event $\cE_m$ occurring by the following lemma.
\begin{lemma}
\label{lem:bb-pem} % The probability of cE_m (Batched Bandits)
     For any epoch $m$, event $\cE_m$ holds with probability at least $1 - \delta_m$. We also have $1 / \delta_m \geq N_m$.
\end{lemma}
\begin{proof}
    By Lemma \ref{lem:ber}, we can get
    \[\Pr\left[|r_k^m - \mu_k| \leq \sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_k^m}} + \frac{2C_m}{N_m}\right] \leq 2\beta_m = \frac{\delta_m}{K}.\]
    A union bound over the $K$ arms conclude the proof.

    Since $m \geq 1$, $K \geq 2$ and $a \geq 2$, then we can get
    \begin{align*}
        N_m &= K \lambda_m a^{2(m-1)} \\
        &= K a^{2(m+3)}\ln(4K^2(m+4) a^{2(m+4)}\ln(aK))  \\
        &\leq K a^{2(m+3)} (2(m+4)\ln(a) + \ln(m+4) + \ln(K^2\ln(aK)) + \ln(4)) \\
        &\leq K a^{2(m+3)}(2(m+4)\ln(aK)+ (m+4)\ln(aK) + 3\ln (aK) + 2\ln(aK)) \\
        &\leq K a^{2(m+3)} ((4m + 16)\ln(aK)) \\
        &= K a^{2(m+4)} ((m+4)\ln(aK)) \\
        &= 1 / \delta_m.
    \end{align*}
\end{proof}
As mentioned before, for each epoch $m$, to unify the varying bounds depending on the occurrence of event $\cE_m$, we define the offset level
\[D_m = \begin{cases}
    2C_m & \textit{when $\cE_m$ occurs} \\
    N_m & \textit{when $\cE_m$ dose not occur}
\end{cases}.\]
This way we can always guarantee the following inequality:
\[|r_k^m - \mu_k| \leq \sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_k^m}} + \frac{D_m}{N_m}.\]
It is worth noting that $\Pr[D_m = 2C_m] \geq 1 - \delta_m$ and $\Pr[D_m = N_m] \leq \delta_m$.

Next, we will bound $\Delta_k^m$. To start, we define the discounted offset rate as
\[\rho_m := \sum_{s=1}^m \frac{2^{m-s}D_s}{a^{4(m-s)}N_s}.\]
\begin{lemma}
\label{lem:bsgbb}
    For all epochs $m$ and arms $k$, we can have
     \[\frac{a^4 - 8}{a^4 - 2}\Delta_k - \frac{3}{2a^2}a^{-m} - 6\rho_m \leq \Delta_k^{m} \leq \frac{a^4 - 2}{a^4}\Delta_k + a^{-(m-1)} + 2\rho_m.\]
\end{lemma}
\begin{proof}
    Since $|r_k^m - \mu_k| \leq \sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_k^m}} + \frac{D_m}{N_m}$, we have
    \[-\frac{D_m}{N_m} - \sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_k^m}} \leq r_{k}^m - \mu_{k} \leq \frac{D_m}{N_m} + \sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_k^m}}.\]
    Additionally, since
    \[r_{*}^m \leq \max_k \left\{\mu_{k} + \frac{D_m}{N_m} + \sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_k^m}} - \sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_k^m}}\right\} \leq \mu_{k^*} + \frac{D_m}{N_m},\]
    \[r_{*}^m = \max_k \left\{r_k^m - \sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_k^m}}\right\} \geq r_{k^*}^m - \sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_{k^*}^m}} \geq \mu_{k^*} - 2\sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_{k^*}^m}} - \frac{D_m}{N_m},\]
    we can get
    \[-\frac{D_m}{N_m} - \sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_{k^*}^m}} \leq r_{*}^m - \mu_{k^*} \leq \frac{D_m}{N_m}.\]
    According to Algorithm \ref{algs:BARBAT} and Lemma \ref{lem:rkc}, we have $\widetilde{n}_k^m \geq n_k^m$ for all arms $k$. Then we have the following inequality for all $k\in [K]$:
    \[\sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_k^m}} \leq \sqrt{\frac{4\ln(4 /\beta_m)}{n_k^m}} = \frac{2\Delta_k^{m-1}}{a^4}.\]

    We now establish the upper bound for $\Delta_k^m$ by induction on $m$.
    
    For the base case $m = 1$, the statement is trivial as $\Delta_k^1 = 1$ for all $k \in [K]$.
    
    Assuming the statement is true for the case of $m-1$, we have
    \begin{equation*}
    \begin{split}
        \Delta_k^m = r_*^m - r_k^m
        &= (r_*^m - \mu_{k^*}) + (\mu_{k^*} - \mu_k) + (\mu_k - r_k^m) \\
        &\leq \frac{D_m}{N_m}+ \Delta_k + \frac{D_m}{N_m} + \frac{2}{a^4}\Delta_k^{m-1} \\
        &\leq \frac{2D_m}{N_m} + \Delta_k + \frac{2}{a^4}\left(\frac{a^4 \Delta_k}{a^4 - 2} + a^{-(m-2)} + 2\rho_{m-1}\right) \\
        &\leq \frac{a^4 \Delta_k}{a^4 - 2} + a^{-(m-1)} + 2\rho_m,
    \end{split}
    \end{equation*}
    Where the second inequality follows from the induction hypothesis.
     
    Next, we provide the lower bound of $\Delta_k^m$. We can get
    \begin{equation*}
    \begin{split}
        \Delta_k^m =  r_*^m - r_k^m
        &= (r_*^m - \mu_{k^*}) + (\mu_{k^*} - \mu_k) + (\mu_k - r_k^m) \\
        &\geq -\frac{D_m}{N_m} - \frac{4}{a^4}\Delta_{k^*}^{m-1} + \Delta_k -\frac{D_m}{N_m} - \frac{2}{a^4}\Delta_k^{m-1} \\
        &\geq -\frac{2D_m}{N_m} + \Delta_k - \frac{6}{a^4}\left(\frac{a^4 \Delta_k}{a^4 - 2} + a^{-(m-2)} + 2\rho_{m-1}\right) \\
        &\geq \frac{a^4 - 8}{a^4 - 2}\Delta_k - \frac{3}{2a^2}a^{-m} - 6\rho_m.
    \end{split}
    \end{equation*}
    where the third inequality comes from the upper bound of $\Delta_k^{m-1}$.
\end{proof}

\subsection{Proving Theorem \ref{the:bb-erb}}

We first define the regret $R_k^m$ generated by arm $k$ in epoch $m$ as 
\[R_k^m\triangleq\Delta_k\widetilde{n}_{k}^m=\begin{cases}
    \Delta_kn_{k}^m & k\neq k_m\\
    \Delta_k\widetilde{n}_{k}^m & k=k_m
\end{cases}.\]
Then we analyze the regret in following three cases:

\paragraph{Case 1:} $0<\Delta_k\le 64\rho_{m-1}$.\\ %$k\in\cA^m$.
If $k \neq k_m$, then we have \[R_k^m=\Delta_k n_{k}^m\le 64\rho_{m-1}n_k^m .\] 
If $k=k_m$, then we have \[R_k^m=\Delta_k\widetilde{n}_{k_m}^m\le 64\rho_{m-1}N_m.\]

\paragraph{Case 2:} $\Delta_k \leq 4 \cdot a^{-(m-1)}$ and $\rho_{m-1} \leq \frac{\Delta_k}{64}$.\\
If $k \neq k_m$, then we have \[R_k^m=n_{k}^m\Delta_k =\lambda_m(\Delta_k^{m-1})^{-2} \Delta_k \leq \lambda_m a^{2(m-1)} \Delta_k  \leq \frac{\lambda_m}{\Delta_k}.\] 
If $k=k_m$, since $\Delta_{k_m}^{m-1} = 2^{-(m-1)}$, we can get:
\begin{align*}
    R_k^m=\widetilde{n}_{k_m}^m \Delta_{k_m} \leq 
    N_m\Delta_{k_m} = \lceil K\lambda_m a^{2(m-1)}\rceil \Delta_{k_m} \leq \frac{16K\lambda_m}{\Delta_{k_m}} + \Delta_{k_m} \leq \frac{16K\lambda_m}{\Delta} + 1.
\end{align*}

\paragraph{Case 3:} $\Delta_k > 4 \cdot a^{-(m-1)}$ and $\rho_{m-1} \leq \frac{\Delta_k}{64}$.\\
By Lemma \ref{lem:bsg} we have
\[\Delta_k^{m-1} \geq \frac{a^4 - 8}{a^4 - 2}\Delta_k - \frac{3}{2a^2}a^{-m} - \frac{6}{64}\Delta_k \geq \Delta_k\left(1 - \frac{6}{a^4 - 2} - \frac{3}{8a} - \frac{6}{64}\right) \geq 0.29 \Delta_k.\]
In this case, it is impossible that $k=k_m$ because $\Delta_{k_m}^{m-1} = a^{-(m-1)} < 0.29\cdot 4\cdot a^{-(m-1)}<0.29\Delta_k$.
So we can obtain
\begin{align*}
   R_k^m= n_k^m \Delta_k = \lambda_m(\Delta_k^{m-1})^{-2} \Delta_k
    \leq \frac{\lambda_m}{0.29^2 \Delta_k} 
    \leq \frac{16\lambda_m}{\Delta_k}.
\end{align*}
We define $\cA^m\triangleq\left\{ k\in[K]\,\big|\,0<\Delta_k\le 64\rho_{m-1} \right\}$ for epoch $m$. By combining all three cases, we can upper bound the regret as
\begin{equation}\label{eq:bb-regret}
\begin{split}
R(T)=&\sum_{m=1}^M\Bigg(\sum_{k \in \mathcal{A}^m} R_k^m + \sum_{k \notin \mathcal{A}^m} R_k^m\Bigg)\\    
\le& \sum_{m=1}^M\Bigg( 64\rho_{m-1}N_m+\sum_{k \in \mathcal{A}^m,k\neq k_m} 64\rho_{m-1}n_k^m + \sum_{k \notin \mathcal{A}^m, \Delta_k>0} \frac{16\lambda_m}{\Delta_k}\\
&+ \left(\frac{16K\lambda_m}{\Delta} + 1\right)\BI(0<\Delta_{k_m} \le 4 \cdot a^{-(m-1)}) \Bigg)\\
\le& \sum_{m=1}^M\Bigg( 64\rho_{m-1}N_m+\sum_{\Delta_k>0} 64\rho_{m-1}n_k^m + \sum_{\Delta_k>0} \frac{16\lambda_m}{\Delta_k} \\
&+ \left(\frac{16K\lambda_m}{\Delta} + 1\right)\BI\left(m\le \log_a(4/\Delta) + 1\right)\Bigg)\\ 
\le& \sum_{m=1}^M\Bigg( 64\rho_{m-1}N_m+\sum_{\Delta_k>0} 64\rho_{m-1}n_k^m + \sum_{\Delta_k>0} \frac{16\lambda_m}{\Delta_k}\\
&+ \left(\frac{16K\lambda_m}{\Delta} + 1\right)\BI\left(m\le \log_2\left(8/\Delta\right)\right)\Bigg)\\ 
\le& \sum_{m=1}^M\Bigg( 128\rho_{m-1}N_m + \sum_{\Delta_k>0} \frac{16\lambda_m}{\Delta_k}\Bigg)+ \sum_{m=1}^{\log_2(8/\Delta)}\left(\frac{16K\lambda_m}{\Delta} + 1\right)
\end{split}
\end{equation}
where the last inequality uses the fact that $\sum_{\Delta_k>0} n_k^m\le N_m$. Notice that we can bound the expectation of the offset level as
\[\mathbb{E}[D_m] = 2(1-\delta_m)C_m + \delta_m N_m \leq 2C_m + 1\]
and we can bound $\sum_{m=1}^M \rho_{m-1} N_m$ as
\begin{equation}\label{eq:bb-rho}
    \begin{split}
        %\sum_{m=1}^M \sum_{k \in \mathcal{A}^m} \rho_{m-1}n_k^m
        \sum_{m=1}^M \rho_{m-1} N_m
        &\leq \sum_{m=1}^M \left(\sum_{s=1}^{m-1}\frac{2^{m-1-s}D_s}{a^{4(m-1-s)}N_s}\right)N_m \\
        &= a^2\sum_{m=1}^M \left(\sum_{s=1}^{m-1}\frac{((2a^2)^{m-1-s} + 1)\lambda_m}{a^{4(m-1-s)}\lambda_s}D_s\right)\\
        &= a^2\sum_{m=1}^M \left(\sum_{s=1}^{m-1}\left(\left(\frac{14}{5a^2}\right)^{m-1-s} + \left(\frac{1}{a^4}\right)^{m-1-s}\right)D_s\right) \\
        &= a^2\sum_{s=1}^{M-1} D_s \sum_{m=s+1}^M \left(\frac{14}{5a^2}\right)^{m-1-s} + \left(\frac{1}{a^4}\right)^{m-1-s}\\
        &\leq a^2\left(\sum_{m=1}^{M-1} D_m\right)\sum_{j=0}^{\infty} \left(\frac{14}{5a^2}\right)^{j} + \left(\frac{1}{a^4}\right)^{j}\\
        &\leq a^2\left(\frac{5a^2}{5a^2-14} + \frac{a^4}{a^4 - 1}\right)\sum_{m=1}^{M-1} D_m
        \leq \frac{22a^2}{5}\sum_{m=1}^{M-1} D_m.
    \end{split}
\end{equation}
Combining Eq.~\eqref{eq:bb-regret} and Eq.~\eqref{eq:bb-rho}, by Lemma \ref{lem:bb-tsl}, since $a = \max\{T^{\frac{1}{2(M+3)}},2\}$ and $M = \min\{\cM, \log_2(T)\}$, we can get
\begin{equation*}
    \begin{split}
        \BE[R(T)]
        &\leq \sum_{m=1}^{M-1}570a^2 \BE[D_m] + \sum_{m=1}^M \sum_{\Delta_k > 0}\frac{16\lambda_m}{\Delta_k} + \sum_{m=1}^{\log_2(8/\Delta)}\left(\frac{16K\lambda_m}{\Delta} + 1\right) \\
        &\leq \sum_{m=1}^{M-1} \sum_{m=1}^{M-1} 1140a^2 C_m + 570a^2 + 2^{5}a^{8}\ln(a)\left(\sum_{\Delta_k > 0}\frac{M^2 + 3M(2 + \log(K))}{\Delta_k}\right. \\
        &\quad \left.+ \frac{K(\log^2(8/\Delta) + 3\log(8/\Delta)(2 + \log(K))}{\Delta}\right) + \log_2(8/\Delta) \\
        &= O\left(CT^{\frac{1}{M+3}} + T^{\frac{4}{M+3}}\left(\sum_{\Delta_k > 0}\frac{M\log(KT)}{\Delta_k} + \frac{K\log(T)\log(1 / \Delta)\log(K/\Delta)}{M\Delta}\right)\right).
    \end{split}
\end{equation*}
\subsection{Proving for Theorem~\ref{the:bb-lb}}
\begin{proof}
    In the context of batched bandits, let the static grids be defined as \( 0 = t_0 < t_1 < \cdots < t_{\cM} = T \). According to Lemma 2 in~\cite{gao2019batched}, the lower bounds for stochastic batched bandits are given by:
    \begin{equation}
    \label{eqs:sbb}
        R(C = 0, \cM) = O\left(K \cdot \max_{j \in [\cM]}\frac{t_j}{t_{j-1} + 1}\right).
    \end{equation}
    For adversarial corruption, we define an adversary who starts attacking at round \(0\) and continues until the end of a batch, denoted by \( t_s \) for \( 0 < s < \cM \). The attack strategy involves setting the rewards of all arms to zero, forcing any algorithm to pull all arms evenly in round \( s+1 \), which leads to a regret of approximately \( t_s - t_{s-1} \). Therefore, under adversarial corruption, the lower bound can be expressed as:
    \begin{equation}
    \label{eqs:cbb}
        \begin{split}
        R(C, \cM) 
        &= O\left(K \cdot \max_{j \in [\cM]}\frac{t_j}{t_{j-1} + 1} + C \cdot \max_{j \in [\cM-1]}\frac{t_{j+1} - t_{j}}{t_{j}}\right) \\
        &= O\left(Kt_1 + (K+C)\max_{j \in [\cM-1]}\frac{t_{j+1} - t_{j}}{t_{j}}\right) \\
        &= O\left(Kt_1 + (K+C)\left(\frac{T}{t_j}\right)^{\frac{1}{\cM - 1}}\right).
        \end{split}
    \end{equation}
    According the formula, we can get the optimal value of $t_1 = T^{\frac{1}{\cM}} \left(\frac{K(\cM - 1)}{K + C}\right)^{\frac{\cM - 1}{\cM}}$. Combine equation~\ref{eqs:cbb}, we can get
    \[R(C,\cM) \geq \Omega \left(T^{\frac{1}{\cM}}\left(K + C^{1 - \frac{1}{\cM}}\right)\right).\]
\end{proof}
