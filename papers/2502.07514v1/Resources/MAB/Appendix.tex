\section{Proof of Theorem \ref{the:erb}}
\label{ape:mab}

\subsection{Notations}
We define $C_k^m$ as the sum of corruptions to arm $k$ in epoch $m$, and let $C_m \triangleq \max_{k \in [K]}C_k^m$.

\subsection{Lemmas for Proving Theorem \ref{the:erb}}

\begin{lemma}
\label{lem:tne} % The number of epochs
    For the BARBAT algorithm time horizon $T$, the number of epochs $M$ is at most $\log_2(T)$. In the $m$-th epoch, the selected arm $k_m$ must satisfy $\Delta_{k_m}^{m-1} = 2^{-(m-1)}$.
\end{lemma}
\begin{proof}
    The length of epoch $m$ is given by $ N_m = \lceil K \lambda_m 2^{2(m-1)} \rceil \geq 2^{2(m-1)}$. From the lower bound of $N_m$, we can complete the first statement. Since $\Delta_k^{m-1} \leftarrow \max\{2^{-(m-1)}, r_*^m - r_k^m\}$, there exists at least one arm that satisfies $\Delta_k^{m-1} = 2^{-(m-1)}$ and all arms satisfy $\Delta_k^{m-1} \leq 2^{-(m-1)}$. Since $r_{k_m}^{m-1} > r_{*}^{m-1}$, the equality $\Delta_{k_m}^{m-1} = 2^{-(m-1)}$ must hold.
\end{proof}

\begin{lemma}
\label{lem:rkc} % The reason of k_m
    For any epoch $m$, the length $N_m$ satisfies $N_m \geq \sum_{k \in [K]} n_k^m$.
\end{lemma}
\begin{proof}
    Since $\Delta_k^m = \max \{2^{-m}, r_*^m - r_k^m\} \geq 2^{-m}$, we can get
    $n_k^m = \lambda_m (\Delta_k^{m-1})^{-2} \leq \lambda_m 2^{2(m-1)}.$
    Therefore, we have
    $\sum_{k \in [K]}n_k^m \leq K \lambda_m 2^{2(m-1)} \leq N_m.$
\end{proof}

\begin{lemma}
\label{lem:trl}    % The ratio of lambda
    For epoch $s$ and $m$ with $1\le s \leq m$, the following inequality holds:
    \[\frac{\lambda_m}{\lambda_s} \leq \left(\frac{7}{6}\right)^{m-s}.\]
\end{lemma}
\begin{proof}
    We first show that the function $f(x)=\frac{(x+1.7)\ln(4)+\ln(x)}{(7/6)^x}$
    is strictly decreasing for $x\ge 5$.
    Notice that the derivative function \[f'(x)=\frac{(\ln(4)+1/x)-((x+1.7)\ln(4)+\ln(x))\ln\left(\frac{7}{6}\right)}{\left(\frac{7}{6}\right)^{x}}\]
    is monotonically decreasing and $f'(5)<0$, thus we have $f'(x)<0$ for $x\ge 5$, which indicates that $f(x)$ is strictly decreasing.
    Since $K\ge 2$, we can get
    \begin{align*}
    \frac{\lambda_m}{\lambda_s}=&\, \frac{\ln(4K^2\ln(K)(m+4)2^{2(m+4)})}{\ln(4K^2\ln(K)(s+4)2^{2(s+4)})}\\
    =& \,\frac{\ln(4K^2\ln(K))+\ln(m+4)+(m+4)\ln(4)}{\ln(4K^2\ln(K))+\ln(s+4)+(s+4)\ln(4)}\\
    <& \,\frac{1.7\cdot\ln(4)+\ln(m+4)+(m+4)\ln(4)}{1.7\cdot\ln(4)+\ln(s+4)+(s+4)\ln(4)}\\
    =&\,\frac{f(m+4)}{f(s+4)}\left(\frac{7}{6}\right)^{m-s}<\left(\frac{7}{6}\right)^{m-s}
    \end{align*}
where we use the monotonicity of $f(x)$ and the fact that $K\ge 2$.
\end{proof}

\begin{lemma}
\label{lem:tsl}     % The sum of lambda
    For any epoch $m$, the following inequality holds:
    \[\sum_{s=1}^{m} \lambda_s \leq 2^8(m^2 + m(10+3\ln(K))).\]
\end{lemma}
\begin{proof}
    Given the function $f(x) = 2x(1-\ln(2)) - \ln(x+4) + 7 - 8\ln(2)$. Notice that the derivative function as $f'(x) = 2 - 2\ln(2) - \frac{1}{x+4} > 0$ for all $x \geq 1$, which means that $f(x)$ is strictly increasing for $x \geq 1$. Since $f(x) \geq f(1) \geq 0$, we can get the inequality as $2x + 7 \geq 2(x+4)\ln(2) + \ln(x+4)$ for all $x \geq 1$, then have
    \begin{align*}
        \sum_{s=1}^{m} \lambda_s &= \sum_{s=1}^{m} 2^8(\ln(4K^2\ln(K)(s+4)2^{2(s+4)})) \\
        &= \sum_{s=1}^{m} 2^8(2(s+4)\ln(2) + \ln(s+4) + \ln(4K^2\ln(K)) \\
        &\leq \sum_{s=1}^{m} 2^8(2s + 7 + \ln(4K^3)) \\
        &= 2^8(m^2 + 8m + m\ln(4K^3)) \\
        &\leq 2^8(m^2 + m(10+3\ln(K))).
    \end{align*}
\end{proof}


\begin{lemma}
\label{lem:ber} % Bound the experimental reward
    For any fixed $k, m$ and $\beta_m$, Algorithm \ref{algs:BARBAT} satisfies
    \[\Pr\left[|r_k^m - \mu_k| \geq \sqrt{\frac{4\ln(4 / \beta_m)}{\widetilde{n}_k^m}} + \frac{2C_m}{N_m}\right] \leq \beta_m.\]
\end{lemma}
\begin{proof}
    The proof of Lemma \ref{lem:ber} mainly follows the proof of Lemma 4 in \cite{gupta2019better}.
    We only consider the randomness in epoch $m$ and condition on all random variables before epoch $m$. In epoch $m$, the agent pulls arm $k$ with probability $p_m(k) = \widetilde{n}_k^m / N_m$.

    For ease of analysis, we set an indicator variable $Y_{k}^t$, which determines whether the agent updates the corrupted reward $\widetilde{r}_{I_t}$ into the total reward $S_{I_t}^m$ at step $t$. We define the corruption at step $t$ on arm $k$ as $C_k^t := \widetilde{r}_k^t - r_k^t$. Let $E_m := \left[T_{m-1} + 1,..., T_m\right]$ represent the $N_m$ time-steps for epoch $m$. Since $r_k^m = \min \left\{S_k^m / \widetilde{n}_k^m, 1\right\}$, we can obtain
    \[r_k^m \leq \frac{S_k^m}{\widetilde{n}_k^m} = \frac{1}{\widetilde{n}_k^m}\sum_{t \in E_m}Y_k^t(r_k^t + C_k^t).\]
    We can divide the sum into two components:
    \[A_k^m = \sum_{t \in E_m} Y_k^t r_k^t, \quad B_k^m = \sum_{t \in E_m} Y_k^t C_k^t.\]
    For the previous component $A_k^m$, notice that $r_k^t$ is independently drawn from a $[0,1]$-valued distribution with mean $\mu_k$, and $Y_k^t$ is independently drawn from a Bernoulli distribution with mean $q_k^m := \widetilde{n}_k^m / N_m$. Therefore, we have
    \[\mathbb{E}[A_k^m] = N_m q_k^m \mathbb{E}[r_k^t] = \widetilde{n}_k^m \mu_k \leq \widetilde{n}_k^m.\]
    By applying the Chernoff-Hoeffding inequality (Theorem 1.1 in \cite{dubhashi2009concentration}, 
    we can get
    \begin{equation}
    \label{eqs:Akm}
        \Pr\left[\left|\frac{A_k^m}{\widetilde{n}_k^m} - \mu_k \right| \geq \sqrt{\frac{3\ln(4/\beta_m)}{\widetilde{n}_k^m}}\right] \leq \frac{\beta_m}{2}.
    \end{equation}
    For analyzing the latter component $B_k^m$, we define a martingale difference sequence $X_1,...,X_T$, where $X_t = (Y_k^t - q_k^m) C_k^t$ for all $t$, with respect to the historical information $\{\mathcal{F}\}_{t=1}^T$. Since the corruption $C_k^t$ is deterministic when conditioned on $\mathcal{F}_{t-1}$ and since $\mathbb{E}[Y_k^t | \mathcal{F}_{t-1}] = q_k^m$, we can get
    \[\mathbb{E}[X_t|\mathcal{F}_{t-1}] = \mathbb{E}[Y_k^t - q_k^m|\mathcal{F}_{t-1}] C_k^t = 0.\]
    Additionally, we have $|X_t| \leq 1$ for all $t$, and the predictable quadratic variation of this martingale can be bounded as follows:
    \[\sum_{t \in E_m} \mathbb{E}[(X_t)^2|\mathcal{F}_{t-1}] \leq \sum_{t \in E_m}|C_k^t|\Var(Y_k^t) \leq q_k^m \sum_{t \in E_m}|C_k^t|.\]
    By Freedman concentration inequality (Theorem 1 in \cite{beygelzimer2011contextual}), with probability at least $1 - \beta_m / 4$ we have
    \[B_k^m \leq q_k^m \sum_{t \in E_m} C_k^t + \sum_{t \in E_m} \mathbb{E}[(X_t)^2|\mathcal{F}_{t-1}] + \ln(4/\beta_m) \leq 2q_k^m \sum_{t \in E_m}|C_k^t| + \ln(4/\beta_m).\]
    Since $q_k^m = \widetilde{n}_k^m / N_m$, $\sum_{t \in E_m}|C_k^t| \leq C_m$ and $n_k^m \geq \lambda_m \geq 16\ln(4/\beta_m)$, with probability at least $1 - \beta_m / 4$ the following inequality holds:
    \[\frac{B_k^m}{\widetilde{n}_k^m} \leq \sqrt{\frac{\ln(4 /\beta_m)}{16\widetilde{n}_k^m}} + \frac{2C_m}{N_m}.\]
    Similarly, with probability at least $1 - \beta_m / 4$ the following inequality holds:
     \[-\frac{B_k^m}{\widetilde{n}_k^m} \leq \sqrt{\frac{\ln(4 /\beta_m)}{16\widetilde{n}_k^m}} + \frac{2C_m}{N_m}.\]
    Thus we have
    \begin{equation}
    \label{eqs:Bkm}
        \Pr\left[\left|\frac{B_k^m}{\widetilde{n}_k^m}\right| \geq \sqrt{\frac{\ln(4 /\beta_m)}{16\widetilde{n}_k^m}} + \frac{2C_m}{N_m}\right] \leq \frac{\beta_m}{2}.
    \end{equation}
    Combine Eq. \eqref{eqs:Akm} and Eq. \eqref{eqs:Bkm}, we complete the proof. 
\end{proof}

We define an event $\cE_m$ for epoch $m$ as follows:
\begin{equation*}
    \cE_m \triangleq \left\{ \forall\ k: |r_k^m - \mu_k| \leq \sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_k^m}} + \frac{2C_m}{N_m} \right\}.
\end{equation*}
Then we can establish a lower bound on the probability of the event $\cE_m$ occurring by the following lemma.
\begin{lemma}
\label{lem:pem} % The probability of cE_m
     For any epoch $m$, event $\cE_m$ holds with probability at least $1 - \delta_m$. We also have $1 / \delta_m \geq N_m$.
\end{lemma}
\begin{proof}
    By Lemma \ref{lem:ber}, we can get
    \[\Pr\left[|r_k^m - \mu_k| \leq \sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_k^m}} + \frac{2C_m}{N_m}\right] \leq \beta_m = \frac{\delta_m}{K}.\]
    A union bound over the $K$ arms indicates that the success probability of event $\cE_m$ is at least $1 - \delta_m$.

    Since $m \geq 1$ and $K \geq 2$, then we can get
    \begin{align*}
        N_m &= K 2^{2(m-1)} \lambda_m \\
        &= K 2^{2(m+3)}\ln((m+4) 2^{2(m+5)} K^2 \ln(K))  \\
        &\leq  K 2^{2(m+3)}(\ln(m+4)+2(m+5)\ln(2)+ \ln(K^3))  \\
        &\leq K 2^{2(m+3)}((m+4)\ln(K)+ 2(m+5)\ln(K) + 3\ln (K)) \\
        &\leq K 2^{2(m+3)}(4m+16)\ln(K) \\
        &= K 2^{2(m+4)} ((m + 4)\ln (K)) = 1 / \delta_m.
    \end{align*}
\end{proof}
Now we can we define the offset level $D_m$ for each epoch $m$:
\[D_m = \begin{cases}
    2C_m & \textit{when $\cE_m$ occurs} \\
    N_m & \textit{when $\cE_m$ does not occur}
\end{cases}.\]
Since we always have $|r_k^m - \mu_k| \leq 1$, thus the following inequality always holds, regardless of whether event $\cE_m$ happens:
\[|r_k^m - \mu_k| \leq \sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_k^m}} + \frac{D_m}{N_m}.\]
By the definition of $D_m$, we have 
\[\Pr[D_m = 2C_m] \geq 1 - \delta_m \quad \text{ and } \quad \Pr[D_m = N_m] \leq \delta_m.\]
Next, we will bound the estimated gap $\Delta_k^m$. To start, we define the discounted offset rate as
\[\rho_m := \sum_{s=1}^m \frac{D_s}{8^{m-s}N_s}.\]
Then we have the following lemma.
\begin{lemma}
\label{lem:bsg} %   Bound the suboptimality-gap
    For all epochs $m$ and arms $k$, we can have
    \[\frac{4\Delta_k}{7} - \frac{3}{2}2^{-m} - 6 \rho_m \leq \Delta_k^{m} \leq \frac{8 \Delta_k}{7} + 2^{-(m-1)} + 2\rho_m.\]
\end{lemma}
\begin{proof}
    Since $|r_k^m - \mu_k| \leq \sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_k^m}} + \frac{D_m}{N_m}$, we have
    \[-\frac{D_m}{N_m} - \sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_k^m}} \leq r_{k}^m - \mu_{k} \leq \frac{D_m}{N_m} + \sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_k^m}}.\]
    Additionally, since
    \[r_{*}^m \leq \max_k \left\{\mu_{k} + \frac{D_m}{N_m} + \sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_k^m}} - \sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_k^m}}\right\} \leq \mu_{k^*} + \frac{D_m}{N_m},\]
    \[r_{*}^m = \max_k \left\{r_k^m - \sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_k^m}}\right\} \geq r_{k^*}^m - \sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_{k^*}^m}} \geq \mu_{k^*} - 2\sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_{k^*}^m}} - \frac{D_m}{N_m},\]
    we can get
    \[-\frac{D_m}{N_m} - 2\sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_{k^*}^m}} \leq r_{*}^m - \mu_{k^*} \leq \frac{D_m}{N_m}.\]
    According to Algorithm \ref{algs:BARBAT} and Lemma \ref{lem:rkc}, we have $\widetilde{n}_k^m \geq n_k^m$ for all arms $k$. Then we have the following inequality for all $k\in [K]$:
    \[\sqrt{\frac{4\ln(4 /\beta_m)}{\widetilde{n}_k^m}} \leq \sqrt{\frac{4\ln(4 /\beta_m)}{n_k^m}} = \frac{\Delta_k^{m-1}}{8}.\]

    We now establish the upper bound for $\Delta_k^m$ by induction on $m$.
    
    For the base case $m = 1$, the statement is trivial as $\Delta_k^1 = 1$ for all $k \in [K]$.
    
    Assuming the statement is true for the case of $m-1$, we have
    \begin{equation*}
    \begin{split}
        \Delta_k^m = r_*^m - r_k^m
        &= (r_*^m - \mu_{k^*}) + (\mu_{k^*} - \mu_k) + (\mu_k - r_k^m) \\
        &\leq \frac{D_m}{N_m}+ \Delta_k + \frac{D_m}{N_m} + \frac{1}{8}\Delta_k^{m-1} \\
        &\leq \frac{2D_m}{N_m} + \Delta_k + \frac{1}{8}\left(\frac{8 \Delta_k}{7} + 2^{-(m-2)} + 2\rho_{m-1}\right) \\
        &\leq \frac{8 \Delta_k}{7} + 2^{-(m-1)} + 2\rho_m,
    \end{split}
    \end{equation*}
    Where the second inequality follows from the induction hypothesis.
     
    Next, we provide the lower bound of $\Delta_k^m$. We can get
    \begin{equation*}
    \begin{split}
        \Delta_k^m =  r_*^m - r_k^m
        &= (r_*^m - \mu_{k^*}) + (\mu_{k^*} - \mu_k) + (\mu_k - r_k^m) \\
        &\geq -\frac{D_m}{N_m} - \frac{1}{4}\Delta_{k^*}^{m-1} + \Delta_k -\frac{D_m}{N_m} - \frac{1}{8}\Delta_k^{m-1} \\
        &\geq -\frac{2D_m}{N_m} + \Delta_k - \frac{3}{8}\left(\frac{8 \Delta_k}{7} + 2^{-(m-2)} + 2\rho_{m-1}\right) \\
        &\geq \frac{4}{7}\Delta_k - \frac{3}{2}2^{-m} - 6\rho_m.
    \end{split}
    \end{equation*}
    where the third inequality comes from the upper bound of $\Delta_k^{m-1}$.
\end{proof}

\subsection{Proof for Theorem \ref{the:erb}}

We first define the regret $R_k^m$ generated by arm $k$ in epoch $m$ as 
\[R_k^m\triangleq\Delta_k\widetilde{n}_{k}^m=\begin{cases}
    \Delta_kn_{k}^m & k\neq k_m\\
    \Delta_k\widetilde{n}_{k}^m & k=k_m
\end{cases}.\]
Then we analyze the regret in following three cases:

\paragraph{Case 1:} $0<\Delta_k\le 64\rho_{m-1}$.\\ %$k\in\cA^m$.
If $k \neq k_m$, then we have \[R_k^m=\Delta_k n_{k}^m\le 64\rho_{m-1}n_k^m .\] 
If $k=k_m$, then we have \[R_k^m=\Delta_k\widetilde{n}_{k_m}^m\le 64\rho_{m-1}N_m.\]

\paragraph{Case 2:} $\Delta_k \leq 8 \cdot 2^{-m}$ and $\rho_{m-1} \leq \frac{\Delta_k}{64}$.\\
If $k \neq k_m$, then we have \[R_k^m=n_{k}^m\Delta_k =\lambda_m(\Delta_k^{m-1})^{-2} \Delta_k \leq \lambda_m 2^{2(m-1)} \Delta_k  \leq \frac{16 \lambda_m}{\Delta_k}.\] 
If $k=k_m$, since $\Delta_{k_m}^{m-1} = 2^{-(m-1)}$, we can get:
\begin{align*}
    R_k^m=\widetilde{n}_{k_m}^m \Delta_{k_m} \leq 
    N_m\Delta_{k_m} = \lceil K\lambda_m 2^{2(m-1)}\rceil \Delta_{k_m} \leq \frac{16K\lambda_m}{\Delta_{k_m}} + \Delta_{k_m} \leq \frac{16K\lambda_m}{\Delta} + 1.
\end{align*}

\paragraph{Case 3:} $\Delta_k > 8 \cdot 2^{-m}$ and $\rho_{m-1} \leq \frac{\Delta_k}{64}$.\\
By Lemma \ref{lem:bsg} we have
\[\Delta_k^{m-1} \geq \frac{4}{7}\Delta_k - \frac{3}{2}2^{-m} - \frac{6}{64}\Delta_k \geq \Delta_k\left(\frac{4}{7} - \frac{3}{16} - \frac{6}{64}\right) \geq 0.29 \Delta_k.\]
In this case, it is impossible that $k=k_m$ because $\Delta_{k_m}^{m-1} = 2^{-(m-1)}<0.29\cdot 8\cdot 2^{-m}<0.29\Delta_k$.
So we can obtain
\begin{align*}
   R_k^m= n_k^m \Delta_k = \lambda_m(\Delta_k^{m-1})^{-2} \Delta_k
    \leq \frac{\lambda_m}{0.29^2 \Delta_k} 
    \leq \frac{16\lambda_m}{\Delta_k}.
\end{align*}

We define $\cA^m\triangleq\left\{ k\in[K]\,\big|\,0<\Delta_k\le 64\rho_{m-1} \right\}$ for epoch $m$. By combining all three cases, we can upper bound the regret as
\begin{equation}\label{eq:mab-regret}
\begin{split}
R(T)=&\sum_{m=1}^M\Bigg(\sum_{k \in \mathcal{A}^m} R_k^m + \sum_{k \notin \mathcal{A}^m} R_k^m\Bigg)\\    
\le& \sum_{m=1}^M\Bigg( 64\rho_{m-1}N_m+\sum_{k \in \mathcal{A}^m,k\neq k_m} 64\rho_{m-1}n_k^m + \sum_{k \notin \mathcal{A}^m, \Delta_k>0} \frac{16\lambda_m}{\Delta_k}\\
&+ \left(\frac{16K\lambda_m}{\Delta} + 1\right)\BI(0<\Delta_{k_m} \le 8 \cdot 2^{-m}) \Bigg)\\ 
\le& \sum_{m=1}^M\Bigg( 64\rho_{m-1}N_m+\sum_{\Delta_k>0} 64\rho_{m-1}n_k^m + \sum_{\Delta_k>0} \frac{16\lambda_m}{\Delta_k} \\
&+ \left(\frac{16K\lambda_m}{\Delta} + 1\right)\BI\left(m\le \log_2\left(8/\Delta\right)\right)\Bigg)\\ 
\le& \sum_{m=1}^M\Bigg( 128\rho_{m-1}N_m + \sum_{\Delta_k>0} \frac{16\lambda_m}{\Delta_k}\Bigg) 
+ \sum_{m=1}^{\log_2(8/\Delta)}\left(\frac{16K\lambda_m}{\Delta} + 1\right)
\end{split}
\end{equation}
where the last inequality uses the fact that $\sum_{\Delta_k>0} n_k^m\le N_m$. Notice that we can bound the expectation of the offset level as
\[\mathbb{E}[D_m] = 2(1-\delta_m)C_m + \delta_m N_m \leq 2C_m + 1\]
and we can bound $\sum_{m=1}^M \rho_{m-1} N_m$ as
\begin{equation}\label{eq:mab-rho}
    \begin{split}
        \sum_{m=1}^M \rho_{m-1} N_m
        &\leq \sum_{m=1}^M \left(\sum_{s=1}^{m-1}\frac{D_s}{8^{m-1-s}N_s}\right)N_m \\
        &\leq 4\sum_{m=1}^M \left(\sum_{s=1}^{m-1}\frac{(4^{m-1-s} + 1)\lambda_m}{8^{m-1-s}\lambda_s}D_s\right) \\
        &= 4\sum_{m=1}^M \left(\sum_{s=1}^{m-1}((7/12)^{m-1-s} + (7/48)^{m-1-s})D_s\right) \\
        &= 4\sum_{s=1}^{M-1} D_s \sum_{m=s+1}^M (7/12)^{m-1-s} + (7/48)^{m-1-s}\\
        &\leq 4\left(\sum_{m=1}^{M-1} D_m\right)\sum_{j=0}^{\infty} \left(7/12\right)^{j} + \left(7/48\right)^{j} 
        \leq 11\sum_{m=1}^{M-1} D_m.
    \end{split}
\end{equation}
Combining Eq.~\eqref{eq:mab-regret} and Eq.~\eqref{eq:mab-rho}, by Lemma \ref{lem:tsl}, we can get
\begin{equation*}
    \begin{split}
        \BE[R(T)]
        &\leq \sum_{m=1}^{M-1} 1440 \BE[D_m] + \sum_{m=1}^M \sum_{\Delta_k > 0}\frac{16\lambda_m}{\Delta_k} + \sum_{m=1}^{\log_2(8/\Delta)}\left(\frac{16K\lambda_m}{\Delta} + 1\right) \\
        &\leq \sum_{m=1}^{M-1} 1440 \BE[D_m] + \sum_{\Delta_k > 0}\frac{2^{12}(\log^2(T) + 3\log(T)\log(30K))}{\Delta_k} \\
        &\quad + \frac{2^{12}K(\log^2(8/\Delta) + 3\log(8/\Delta)\log(30K)))}{\Delta} + \log(8/\Delta) \\
        &\leq \sum_{m=1}^{M-1} 2880 C_m + 1440 + \sum_{\Delta_k > 0}\frac{2^{14}\log(T)\log(30KT)}{\Delta_k} \\
        &\quad+ \frac{2^{14}K\log(8/\Delta)\log(240K / \Delta)}{\Delta}  + \log(8/\Delta)\\ 
        &= O\left(C + \sum_{\Delta_k > 0}\frac{\log(T)\log(KT)}{\Delta_k} + \frac{K\log(1/\Delta)\log(K / \Delta)}{\Delta}\right).
    \end{split}
\end{equation*}
