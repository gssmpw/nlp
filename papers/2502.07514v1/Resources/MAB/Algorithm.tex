\section{Stochastic Multi-Armed Bandits Robust to Adversarial Corruptions}
\label{sec:mab}

\begin{algorithm}[t]
    \LinesNumbered
    \SetAlgoLined
    \caption{BARBAT: Bad Arms get Recourse, Best Arm gets Trust}
    \label{algs:BARBAT}
    
    \textbf{Initialization:} 
    Set the initial round \( T_0 = 0 \), \( \Delta_k^0 = 1 \), and \( r_k^0 = 0 \) for all \( k \in [K] \).

    \For{epochs $m = 1,2,\cdots$}{
        Set $\zeta_m \leftarrow (m + 4)2^{2(m+4)}\ln (K)$, and $\delta_m \leftarrow 1/(K\zeta_m)$
        
        Set $\lambda_m \leftarrow 2^8 \ln{\left(4K / \delta_m\right)}$ and $\beta_m \leftarrow \delta_m / K$.
        
        Set $n_k^m = \lambda_m (\Delta_k^{m-1})^{-2}$ for all arms $k \in [K]$.
        
        Set $N_m \leftarrow \lceil K \lambda_m 2^{2(m-1)} \rceil$ and $T_m \leftarrow T_{m-1} + N_m$.

        Select the arm \( k_m = \mathop{\arg\max}_{k \in [K]} r_k^{m-1} \). 

        Set
        $   
            \widetilde{n}_k^m = \begin{cases}
                n_k^m & k \neq k_m \\
                N_m - \sum_{k \neq k_m}n_k^m & k = k_m
            \end{cases}
        $.

        \For{$t = T_{m-1} + 1$ to $T_m$}{
            Choose arm $I_t\sim p_m$ where $p_m(k)= \widetilde{n}_k^m / N_m$.

            Observe the corrupted reward $\widetilde{r}_{t,I_t}$ and update the total reward $S_{I_t}^m = S_{I_t}^m + \widetilde{r}_{t,I_t}$.
        }

        Set $r_k^m \leftarrow \min \{S_k^m / \widetilde{n}_k^m, 1\}$
        
        Set$r_*^m \leftarrow \max_{k \in [K]}\left\{r_k^m - \sqrt{\frac{4\ln(4/\beta_m)}{\widetilde{n}_k^m}}\right\}$
        
        Set $\Delta_k^m \leftarrow \max\{2^{-m}, r_*^m - r_k^m\}$.
    }
\end{algorithm}

%The BARBAR~\citep{gupta2019better} algorithm employs an epoch-based strategy that is robust to adversarial corruptions; however, \citet{gupta2019better} left an open problem of removing the multiplicative factor $K$ from the corruption-dependent term. BARBAR also requires prior knowledge of the horizon $T$, which can be impractical in real scenarios. Nonetheless, it only updates pulling probabilities and value estimates at epoch boundaries, making it substantially more compute efficient than FTRL-based algorithms~\citep{bubeck2012best,seldin2014one,auer2016algorithm,seldin2017improved,wei2018more,zimmert2021tsallis,ito2021parameter,jin2024improved,tsuchiya2024stability}, which compute the arm-selection probability every round. Moreover, its epoch-based nature is highly suitable for a multi-agent collaborative extension, yielding low communication cost and near-optimal regret for each agent.

We introduce our BARBAT framework for stochastic bandits with adversarial corruptions in Algorithm~\ref{algs:BARBAT}. In each epoch $m$, BARBAT sets
$\delta_m = 1/(K \zeta_m)$ where $\zeta_m$ is chosen to make $\delta_m \le 1/N_m$. From $\delta_m$, BARBAT set parameters  
 $\lambda_m$ and $\beta_m$ based on $\delta_m$. It then assigns
$n_k^m = \lambda_m \bigl(\Delta_k^{m-1}\bigr)^{-2}$, where $\Delta_k^0 = 1$.
Unlike BARBAR, which defines $N_m=\sum_{k \in [K]}\lambda_m n_k^m$, BARBAT employs
$N_m=\bigl\lceil K\lambda_m 2^{2(m-1)}\bigr\rceil \ge \sum_{k \in [K]}n_k^m.$
It selects the arm with the highest empirical reward in the previous epoch $k_m=\arg\max_{k\in[K]}r_k^{m-1}$ (if multiple arms has the same mean rewards, we select the arm with the smallest index)
and sets
\[
\widetilde{n}_k^m =
\begin{cases}
n_k^m, & k \neq k_m, \\
N_m - \sum_{k \neq k_m} n_k^m, & k = k_m.
\end{cases}
\]
During epoch $m$, the agent pulls arm $I_t$ with probability $p_m(I_t)=\widetilde{n}_{I_t}^m/N_m$, observes the corrupted reward $\widetilde{r}_{t,I_t}$, and accumulates $S_{I_t}^m$. At the end of each epoch $m$, BARBAT sets
$r_k^m=\min\{S_k^m/\widetilde{n}_k^m,1\}$, ensuring $r_k^m \le 1$ and addressing the BARBAR issue noted by \citet{lu2021stochastic}. The algorithm estimates $r_*^m$
and updates the estimated suboptimality gap $\Delta_k^m$.


% We illustrate how BARBAT eliminates the multiplicative factor $K$ in the regret of BARBAR by a toy example, where
% $[\mu_1,\mu_2,\dots,\mu_K]=[1,0,\dots,0]$.
% Without corruptions, for epoch $m\ge1$, BARBAR and BARBAT share $\Delta_1^m=2^{-m}$ and $\Delta_k^m=r_*^m\in[14/15,15/16]$. Let $N_m'=\sum_{k\in[K]}\lambda'n_k^m$ be the epoch lengths of BARBAR. Suppose all corruptions occur in the epoch $c>2\log_2(K)$, with corruption level $C'=N_c'=\lambda' \bigl(2^{2(c-1)} + O(K))$. If the adversary sets the observed rewards of every arm to zero until $C'$ is exhausted, In BARBAR, as a result of this attack, we have $r_* \le 0$ and $\Delta_k^c = 2^{-c}$ for all $k \in [K]$, so that any prior information is effectively erased. BARBARâ€™s next epoch length will become $N_{c+1}'\approx 2KC'$, yielding $O(KC')$ regret in epoch $c+1$. In BARBAT, causing the same effect requires $C=N_c=K\lambda_m2^{2(c-1)}$, but subsequent epochs grow in length by at most a factor of $14/3$, limiting the regret in epoch $c+1$ to $O(C)$ rather than $O(KC)$.

The key difference between BARBAT and BARBAR is that epoch length of BARBAR heavily depends on the empirical rewards, so that adversary may manipulate the epoch length and potentially increase the chance of pulling suboptimal arms (see Appendix B of \cite{gupta2019better}). On the other hand, our BARBAT algorithm always guarantees that $N_{m+1}/N_m\in[4,14/3]$ and makes the algorithm more robust. By our choice of $N_m$  and $\delta_m$, we can reduce the regret bound from $O(KC)$ to $O(C)$ with the cost of an extra term $O\bigl(K\log^2(1/\Delta)/\Delta\bigr)$, which is independent of $T$. Moreover, BARBAT is an anytime algorithm, i.e., it does not require prior knowledge of $T$.
BARBAT achieves the following regret bound, with the proof provided in Appendix \ref{ape:mab}:
\begin{theorem}
    \label{the:erb}
    The expected regret of BARBAT satisfies
    \[
    \BE[R(T)] = O\left(C + \sum_{\Delta_k > 0}\frac{\log(T)\log(KT)}{\Delta_k} + \frac{K\log\left(1 / \Delta\right)\log\left(K / \Delta\right)}{\Delta}\right).
    \]
\end{theorem}
\begin{remark}
    BARBAT removes the multiplicative factor $K$ in the corruption-dependent term, addressing the open problem of \citet{gupta2019better}. Our method also outperform the concurrent work~\citep{ghaffari2024multi}, which incur $O\bigl(C+K\log^2(T)/\Delta\bigr)$ regret. %In real-world scenarios with $1 / \Delta\ll T$, $\Delta\ll\Delta_k$, and $K\ll T$, BARBAT has a clear advantage and does not require knowledge of $T$, allowing termination at any time.

    %Compared to best-of-both-worlds algorithms~\citep{zimmert2021tsallis,ito2021parameter,jin2024improved,tsuchiya2024stability}, BARBAT avoids solving complex optimization problems. Its computational cost is $O(K)$ at epoch boundaries, and its phase-based design enables a multi-agent extension with low communication cost and near-optimal regret reduction per agent. Additionally, BARBAT does not require the optimal arm to be unique, unlike some prior works.
\end{remark}
