\section{Proof of Theorem \ref{the:wog-erm}}
\label{ape:wog}

\subsection{Lemmas for Proving Theorem \ref{the:wog-erm}}

Using the methods mentioned before, all lemmas in appendix \ref{ape:sog} still holds. The only difference is the only case where $\hat{n}_k^m \leq n_k^m$ be changed as:

The arm must be selected as $k_c$, is weakly observable vertex and $\forall k \neq k_c:\hat{n}_{k_c}^m \geq n_k^m$.

\subsection{Proof for Theorem \ref{the:wog-erm}}

By Lemma \ref{lem:bsgsog}, for all arms $k \neq k^*$, we have
\[\frac{4}{7}\Delta_k - \frac{3}{4}2^{-m} - 6\rho_m \leq \Delta_k^m \leq \frac{8}{7}\Delta_k + 2^{-(m-1)} + 2\rho_m.\]

We partition the proof into three distinct cases. It is important to observe that the actual expected pulling times for any arm $ k \neq k_c $ is given by $\widetilde{n}_k^m \leq n_k^m$. Conversely, the actual expected pulling times for arm $ k_c $ is $\widetilde{n}_{k_c}^m = N_m - \sum_{k \neq k_c}n_k^m \leq N_m$. We need to consider the relationship between arm $k_c$ and the domain arm $k'$. We first discuss the case where $k_c = k$, and discuss the case where $k_c \neq k'$ in the end.

\textbf{Case 1:} $\rho_{m-1} \geq \frac{\Delta_k}{64}.$

We define  $\mathcal{A}^m$ as the set consisting of all arms that satisfy $\rho_{m-1} \geq \frac{\Delta_k}{64}$ at epoch $m$. For $k \neq k_c$, we have
\begin{equation*}
    \begin{split}
        \sum_{m=1}^M \sum_{k \in \mathcal{A}^m} \rho_{m-1}n_k^m
        \leq \sum_{m=1}^M \rho_{m-1} N_m
        \leq \sum_{m=1}^M (\sum_{s=1}^{m-1}\frac{D_s}{8^{m-1-s}N_s})N_m
        = 4\sum_{m=1}^M (\sum_{s=1}^{m-1}\frac{4^{m-1-s}\lambda_m}{8^{m-1-s}\lambda_s}D_s) \\
        = 4\sum_{m=1}^M (\sum_{s=1}^{m-1}(4/5)^{m-1-s}D_s)
        = 4\sum_{s=1}^{M-1} D_s \sum_{m=s+1}^M (4/5)^{m-1-s}
        \leq 4(\sum_{m=1}^M D_m)\sum_{j=1}^{\infty} (4/5)^{j} 
        \leq 16\sum_{m=1}^M D_m.
    \end{split}
\end{equation*}
But if the arm $k$ is weakly observable vertex, Algorithm \ref{algs:WOG-BARBAC} will pull the domain arm $k'$ as $n_k^m$ times. Therefore, we obtain
\[\sum_{m=1}^M \sum_{k \in \mathcal{A}^m} n_k^m \Delta_{k'} \leq 64\sum_{m=1}^M \sum_{k \in \mathcal{A}^m} \frac{n_k^m \rho_m}{\Delta_k} = O\left(\sum_{m=1}^M \sum_{k \in \mathcal{T}^*} \frac{D_m}{\delta(\mathcal{G})\Delta_k} \right).\]

For arm $k_c = k'$, we can get
\begin{align*}
    \widetilde{n}_{k_c}^m \Delta_{k_c} \leq N_m\Delta_{k_c} = O(\sum_{m=1}^M D_m).
\end{align*}

\textbf{Case 2:} $\Delta_k \leq 2^{-(m-3)}$ and $\rho_{m-1} \leq \frac{\Delta_k}{64}.$

\[n_k^m = \lambda_m(\Delta_k^{m-1})^{-2} \leq \lambda_m 2^{2(m-1)} = \frac{4 \lambda_m}{(2^{-(m-3)})^2} \leq \frac{16 \lambda_m}{\Delta_k^2}.\]

For arm $k_c = k'$, since $\Delta_{k_c}^{m-1} = 2^{-(m-1)}$, we can establish the upper bound as:
\begin{align*}
    \widetilde{n}_{k_c}^m \Delta_{k_c} \leq 
    N_m\Delta_{k_c} = \delta(\mathcal{G}) \lambda_m \Delta_{k_c}2^{2(m-1)} \leq \frac{16\delta(\mathcal{G})\lambda_m}{\Delta_{k_c}} \leq \frac{16\delta(\mathcal{G})\lambda_m}{\Delta}.
\end{align*}

This epoch, which satisfies the given conditions $\Delta_k \leq 2^{-(m-3)}$, is bounded by $\log(1 / \Delta)$ which can be considered as a constant. At the same time, under the conditions, the parameter $\lambda_m$ also can be considered as a constant.

\textbf{Case 3:} $\Delta_k > 2^{-(m-3)}$ and $\rho_{m-1} \leq \frac{\Delta_k}{64}$.

In this case, by Lemma \ref{lem:bsg} we have
\[\Delta_k^{m-1} \geq \frac{4}{7}\Delta_k - \frac{3}{4}2^{-m} - \frac{6\Delta_k}{64} \geq \Delta_k(\frac{4}{7} - \frac{3}{32} - \frac{6}{64}) \geq 0.38 \Delta_k.\]

So we can obtain
\begin{align*}
    n_k^m = \lambda_m(\Delta_k^{m-1})^{-2}
    \leq \frac{\lambda_m}{0.38^2 \Delta_k^2} 
    \leq \frac{7\lambda_m}{\Delta_k^2}.
\end{align*}

In this case, it is impossible for $\Delta_{k_c} > 2^{-(m-3)}$ and $\rho_{m-1} \leq \frac{\Delta_{k_c}}{64}$ to occur simultaneously. Since $\Delta_{k_c}^{m-1} \geq 0.38 \Delta_{k_c} > 2^{-(m-1)}$, this does not align with the algorithm's selection criterion $\Delta_{k_c}^{m-1} = 2^{-(m-1)}$. Therefore, arm $k_c$ must be the optimal arm.

Based on the cases mentioned above, if $k_c \neq k'$, we have
\begin{align*}
    \widetilde{n}_{k'}^m \Delta_{k'} + \widetilde{n}_k^m \Delta_{k_c} 
    \leq \max_{k \neq k_c} n_k^m \Delta_{k'} + N_m \Delta_{k_c} 
    = O\left(\sum_{m=1}^M \sum_{k \in \mathcal{T}^*} \left(\frac{D_m}{\delta(\mathcal{G})\Delta_k} + \frac{\lambda_m}{\Delta_k^2}\right) + \frac{\delta(\mathcal{G})}{\Delta}\right).
\end{align*}

Based on the cases mentioned above, we will obtain the expected regret. Firstly, we bound the offset level as
\[\mathbb{E}[D_m] = (1-\delta_m)C_m + \delta_m N_m \leq C_m + 1.\]
Since we only pull arms $k \in Z^m$, by the definition of $\mathcal{I}^*$, we can get the expected regret as follows:
\begin{equation*}
    \begin{split}
        R(T) &\leq \sum_{m=1}^M\sum_{k \in \mathcal{T}^*,\Delta_k > 0}\left(1024\frac{D_m}{\delta(\mathcal{G})\Delta_k} + frac{\lambda_m}{\Delta_k^2}\right) + \frac{256\alpha}{\Delta} \\
        &\leq \sum_{k \in \mathcal{T}^*,\Delta_k > 0}\left(1024\frac{C + M}{\delta(\mathcal{G})\Delta_k} + \frac{4096\log^2(T)}{\Delta_k^2}\right) + \frac{256\widetilde{\alpha}}{\Delta} \\
        &= O\left(\sum_{k \in \mathcal{T}^*}\frac{C}{\delta(\mathcal{G})\Delta_k} + \sum_{k \in \mathcal{T}^*}\frac{\log^2(T)}{\Delta_{k}^2} + \frac{\delta(\mathcal{G})}{\Delta}\right).
    \end{split}
\end{equation*}