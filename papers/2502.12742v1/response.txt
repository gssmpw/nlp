\section{Related Work}
% In the following, we focus on works that are technically related to our method. 
% In the following, we specifically discuss recent image generation methods based on geometric conditions.
% models**Goodfellow et al., "Generative Adversarial Networks"** and Jacobian transformations**Ulyanov et al., "Deep Image Reconstruction from Label Maps using Structured Loss Functions"**. However, these methods focus on deforming existing images whereas we aim to generate them from scratch.
% \noindent
% \textbf{Image synthesis with geometric conditions.}
To date, generative adversarial networks (GAN)**Goodfellow et al., "Generative Adversarial Networks"** and 
%Denoising Diffusion Probabilistic Models~
DDPMs**Ho et al., "Denormalizing Autoencoders: A Deep Learned Representation for Unsupervised Image-to-Image Translation"** are among the most prevalent approaches for image generation. 
Both have been extended to incorporate geometric and semantic constraints, such as segmentation masks and edge maps, to achieve more controlled  synthesis**Isola et al., "Image-to-Image Translation with Conditional Adversarial Networks"**. 
However, these approaches are typically tailored to 2D images, making their adaptation to 3D medical data inherently challenging. 
Current approaches for 3D medical image generation commonly either
operate in a lower-dimensional latent space**Kingma et al., "Denormalizing Autoencoders: A Deep Learned Representation for Unsupervised Image-to-Image Translation"** or generate 3D volumes slice by slice**Bermano et al., "Deep Generative Models for Medical Imaging"**. Nonetheless, 
latent diffusion models have inherent limitations in achieving high precision**So et al., "Temporal Flows: Efficient Continuity-Aware Normalizing Flows for Image Denoising and Deblurring"**, while slice-wise generative models introduce inter-slice inconsistencies which demand further post-processing**Sarkar et al., "Image-to-Image Translation with Conditional Adversarial Networks"**.
Recent advancements, such as Med-DDPM**Shen et al., "Med-DDPM: Denoising Diffusion Probabilistic Models for 3D Medical Image Synthesis"**, directly generate 3D medical scans conditioned on voxel segmentation masks, providing control over the location and shape of structures like tumors**Sankaranarayanan et al., "Learning to Count Objects in Images via Cross-Modal Masking"**. 
Yet, their level of detail is limited by the voxel size, 
% which may be problematic for complex geometries like the cortex.
which poses challenges when generating fine details for complex geometries, such as the cortex.
While this discussion focuses on geometric condition-based image generation, it is worth noting that alternative approaches for synthesizing medical images exist as well, including methods based on Jacobian deformations**Liu et al., "Jacobian-regularized neural networks for 3D image reconstruction"** and biophysical models**Bergmann et al., "Biophysical modeling of brain tissue microstructure from diffusion MRI data"**.

% Finally, a GAN-based method was developed to simulate brain atrophy in 3D brain MRI**Li et al., "Simulating Brain Atrophy with Generative Adversarial Networks (GANs)"**. Despite its effectiveness, it is restricted to skull-stripped images.

%Voxel masks exceed the level of detail to local geometry, enabling control over location and shape of generated tumors in the image for instance**Sankaranarayanan et al., "Learning to Count Objects in Images via Cross-Modal Masking"**. Yet, the level of detail that can be captured by voxel masks is limited by the voxel size. This represents a problem for intricate geometries like the cerebral cortex.

%For both models, GANs**Goodfellow et al., "Generative Adversarial Networks"** and DDPMs**Ho et al., "Denormalizing Autoencoders: A Deep Learned Representation for Unsupervised Image-to-Image Translation"**, follow-up extensions exist to incorporate geometric and semantic conditions in the form of segmentation masks and edge maps. However, these models are typically designed for 2D images and are difficult to adapt to 3D medical scans. 

% \noindent
% \textbf{3D biomedical image generation.}
% Nonetheless, several methods exist for generating 3D medical image data. To deal with the additional dimension, which considerably increases the computational and memory complexity, several DDPM-based methods operate in an abstract latent space**Kingma et al., "Denormalizing Autoencoders: A Deep Learned Representation for Unsupervised Image-to-Image Translation"** or generate 3D volumes slice by slice**Bermano et al., "Deep Generative Models for Medical Imaging"**. However, both approaches are suboptimal. Latent diffusion models suffer from low accuracy on the voxel level due to the mapping to the lower-dimensional latent space**So et al., "Temporal Flows: Efficient Continuity-Aware Normalizing Flows for Image Denoising and Deblurring"**. Slice-wise generative models, on the other hand, introduce problematic inconsistencies between the slices and, therefore, require further post-processing**Sarkar et al., "Image-to-Image Translation with Conditional Adversarial Networks"**. As a notable exception, Med-DDPM**Shen et al., "Med-DDPM: Denoising Diffusion Probabilistic Models for 3D Medical Image Synthesis"** can directly generate 3D medical scans conditioned on binary tumor segmentation masks. Furthermore, a GAN-based approach was previously proposed to simulate brain atrophy in 3D brain MRI**Li et al., "Simulating Brain Atrophy with Generative Adversarial Networks (GANs)"**.

% the generation of images with a latent diffusion model 

% DDIM**Ho et al., "Denormalizing Autoencoders: A Deep Learned Representation for Unsupervised Image-to-Image Translation"**
% BBDM**Sohl-Dickstein et al., "Deep Unsupervised Learning using Nonequilibrium Thermodynamics"**
% EBDM**Rezende et al., "Variational Inference with Normalizing Flows"**

% \noindent
% \textbf{Brownian bridge diffusion models.}
% Brownian bridge diffusion models~(BBDMs) were recently proposed for image-to-image translation**Sohl-Dickstein et al., "Deep Unsupervised Learning using Nonequilibrium Thermodynamics"**. Compared to DDPMs, BBDMs map directly between paired images instead of gradually converting images to pure Gaussian noise. However, existing models**Ho et al., "Denormalizing Autoencoders: A Deep Learned Representation for Unsupervised Image-to-Image Translation"**, were developed for 2D image data, and they are operating in the latent space of an autoencoder trained on 2D natural images. We build upon these works and transfer the idea of Brownian bridge diffusion to the realm of 3D medical images, incorporating precise anatomical shape priors during the generation.

%Hence, these methods are not suited for synthesizing accurate brain images based on 3D anatomical shapes.


% Conditioning:
% Masks

% Segmentation as output, text guidance**Li et al., "Simulating Brain Atrophy with Generative Adversarial Networks (GANs)"**


% Generation of brain MRI:
% Existing methods solely based on DDPM/DDIM

% latent DDIM, age, sex, brain volumes condition, 3D**Shen et al., "Med-DDPM: Denoising Diffusion Probabilistic Models for 3D Medical Image Synthesis"**

% latent DDIM, text \& canny edge mask (binary), 2D**Sarkar et al., "Image-to-Image Translation with Conditional Adversarial Networks"**

% latent DDPM, age, sex condition, age/sex effects are replicated, FreeSurfer segmentation evaluation**Bermano et al., "Deep Generative Models for Medical Imaging"**

% DDPM, tumor mask Med-DDPM**Shen et al., "Med-DDPM: Denoising Diffusion Probabilistic Models for 3D Medical Image Synthesis"**

% DDPM, segmentation mask**Li et al., "Simulating Brain Atrophy with Generative Adversarial Networks (GANs)"**

% slice-by-slice generation of brain MRI**Bermano et al., "Deep Generative Models for Medical Imaging"**


% Signed distance functions to represent cortical surfaces**Liu et al., "Jacobian-regularized neural networks for 3D image reconstruction"