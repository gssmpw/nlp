% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
%\usepackage{subfigure}
%\usepackage{subcaption}
\usepackage{tabularx}
\usepackage{booktabs} % for professional tables
% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Some new commands
\newcommand{\shrink}[1]{}
\newcommand{\la}{\langle}
\newcommand{\ra}{\rangle}
%\newcommand{\todo}[1]{\textcolor{red}{todo: #1}}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}

% These are the \argmax and \argmin operators
\DeclareMathOperator*{\argmax}{\arg\!\max}
\DeclareMathOperator*{\argmin}{\arg\!\min}

% spacing commands----------------------
%\renewcommand{\tabcolsep}{3pt}
\addtolength{\textfloatsep}{-13pt}


% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{\textsc{FactReasoner}: A Probabilistic Approach to Long-Form Factuality Assessment for Large Language Models}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

% \author{First Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\\And
%   Second Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\}

\author{
 \textbf{Radu Marinescu\textsuperscript{1}},
 \textbf{Debarun Bhattacharjya\textsuperscript{1}},
 \textbf{Junkyu Lee\textsuperscript{1}},
 \textbf{Tigran Tchrakian\textsuperscript{1}},
\\
 \textbf{Javier Carnerero Cano\textsuperscript{1}},
 \textbf{Yufang Hou\textsuperscript{1,2}},
 \textbf{Elizabeth Daly\textsuperscript{1}},
 \textbf{Alessandra Pascale\textsuperscript{1}},
\\
 \textsuperscript{1}IBM Research,
 \textsuperscript{2}IT:U - Interdisciplinary Transformation University Austria
 % \textsuperscript{3}Affiliation 3,
 % \textsuperscript{4}Affiliation 4,
 % \textsuperscript{5}Affiliation 5
\\
 \small{
   \textbf{Correspondence:} \href{mailto:radu.marinescu@ie.ibm.com}{radu.marinescu@ie.ibm.com}
 }
}

\begin{document}
\include{macros}
\maketitle
\begin{abstract}
    Large language models (LLMs) have demonstrated vast capabilities on generative tasks in recent years, yet they struggle with guaranteeing the factual correctness of the generated content. This makes these models unreliable in realistic situations where factually accurate responses are expected. In this paper, we propose FactReasoner, a new factuality assessor that relies on probabilistic reasoning to assess the factuality of a long-form generated response. Specifically, FactReasoner decomposes the response into atomic units, retrieves relevant contexts for them from an external knowledge source, and constructs a joint probability distribution over the atoms and contexts using probabilistic encodings of the logical relationships (entailment, contradiction) between the textual utterances corresponding to the atoms and contexts. FactReasoner then computes the posterior probability of whether atomic units in the response are supported by the retrieved contexts. Our experiments on labeled and unlabeled benchmark datasets demonstrate clearly that FactReasoner improves considerably over state-of-the-art prompt-based approaches in terms of both factual precision and recall.
\end{abstract}

\section{Introduction}
\label{sec-intro}
Large language models (LLMs) have achieved impressive improvements and demonstrated vast capabilities in recent years \cite{LLMFewShortLearner,chowdhery2022palm}, however they still struggle to guarantee the factual accuracy of the generated content. Specifically, LLMs often \emph{hallucinate}, namely they produce factual errors in which a claim contradicts well-established ground-truth knowledge \cite{zhang2023siren,sahoo2024hallu,huang2025hallu}. This makes the models unreliable in realistic situations that require factually accurate LLM-generated responses \cite{tonmoy2024hallu}.

% Despite recent advances in retrieval-augmented generation (RAG) that couple LLMs generation capability with traditional information retrieval paradigms in order to reduce hallucinations \cite{rag1,guu2020retrieval}, ensuring factuality remains challenging due to conflicting information between the model's internal knowledge and conflicting information within the retrieved context itself.  

Most modern approaches for assessing the factuality of LLM-generated long-form responses such as FactScore \cite{factscore2023emnlp}, VeriScore \cite{song2024veriscore} and others \cite{wei2024longform,bayat2025factbench} are prompt-based approaches and consist of three main stages: 1) the response is decomposed into a set of atomic units (facts or claims) which are subsequently revised or decontextualized to make them self-contained; 2) relevant evidence (or context) is retrieved for each atomic unit from an external knowledge source such as Wikipedia, and 3) each atomic unit is evaluated against the retrieved context to determine whether it is supported (factually correct) or not and a factuality score is calculated for the response. These approaches sometimes struggle due to conflicting information between the model's internal knowledge and conflicting information within the retrieved contexts themselves. Therefore, they typically assume that the pieces of information retrieved do not conflict or overlap with each other \cite{factscore2023emnlp}. %This assumption however is not realistic especially in situations when multiple sources of knowledge need to be combined to assess long-form factuality. 

\paragraph{Contributions:} In this paper, we provide a new perspective on long-form factuality assessment that departs from the prompt-based approach, especially in the evaluation stage of the assessment. Specifically, we propose a novel factuality assessor called FactReasoner that also decomposes the response into atomic units and retrieves the relevant contexts for them from an external knowledge source. However, instead of prompting another LLM to evaluate the atoms against the retrieved evidence, FactReasoner computes the probability of each atom being supported by reasoning over a graphical model that represents a joint probability distribution over the atoms and the retrieved contexts. The graphical model is constructed using probabilistic encodings of the entailment and contradiction relationships between the natural language utterances corresponding to the atoms and contexts. Furthermore, FactReasoner makes no assumptions regarding the existence of any conflicting information within the retrieved contexts.

We conduct an extensive empirical evaluation on labeled and unlabeled benchmark datasets for long-form factuality and compare against several state-of-the-art prompt-based approaches using open-source LLMs. Our results demonstrate clearly that FactReasoner improves significantly over its competitors in terms of factual precision and recall. We show that exploiting the logical relationships between atoms and all retrieved contexts, as well as between the contexts themselves, allows FactReasoner to identify correctly considerably more supported atoms than the competing approaches.



% We also show that using the logical relationships between an atom and all retrieved contexts as well as between the contexts themselves typically leads to improved performance as FactReasoner is able to correctly label atoms as supported/contradicted that were otherwise labeled undecided by the previous methods. 

%Following background on probabilistic graphical models and on long-form factuality assessment (Section \ref{sec-background}), Section \ref{sec-factreasoner} presents our proposed probabilistic inference based factuality assessor called FactReasoner. Section \ref{sec-experiments} describes our experimental evaluation. In Section \ref{sec-related} we overview the related work while Section \ref{sec-conclusion} provides concluding remarks and outlines directions of future work. 

The Appendix contains additional examples, experimental results and implementation details.

% LLMs have demonstrated vast capabilities in tasks such as text generation and summarization. While the researcher and industry community alike saw the impressive potential these capabilities offer, the community also quickly recognised the challenges when guaranteeing the factual accuracy of generated content. Retrieval-augmented generation (RAG) overcomes this problem by coupling LLMs generation capabilities with traditional information retrieval paradigms \cite{rag1, guu2020retrieval}. While this dramatically reduced hallucinations, ensuring factuality remains challenging due to conflicting information between the model's internal knowledge and conflicting information within the retrieved context itself. 

% {
% \color{red}
% LLM has an issue with factuality guarntee [reference?]. 
% RAG is well-known solution. 
% RAG reduced hallucinations [need reference?]

% [hallucinations has many meanings. 
% \cite{huang2023hallucination,sun2024trustllm}
% will put references and what it is and how it was reduced;
% there's no consensus, hallucination was used for long time even before LLM era.
% %
% In UQ hallucination is connected to inherent uncertainty (aleatoric) that we cannot overcome by better model (epsitemic) \cite{shorinwa2024survey}. 
% providing more precise prompt is the way to resolve hallucinations.
% RAG exactly offer more information.
% ]
% Earlier works utilized self-consistency.
% \cite{wang2023selfconsistency,dohan2022language,mitchell2022enhancing}
% % a few impactful consistency papers
% % [Dohan  Murphy Charles Sutton 2022] Language Model Casades
% % [Mitchell Finn Manning 2022] Enhancing Self-Consistency and Performance of Pre-Trained LM through Natural Language Interface
% %
% issue 1. Self-consistency is not enough.
% [In empirical research \cite{huang2024large}, correction (factuality) cannot be done by LLM itself, and external information must be given.]
% %
% issue 2. the conflict between external and internal knowledge cannot be resolved by information retrieval.
% [
% this is due to uncertainty in knowledge or statement; 
% probabilistic reasoning will infer the most probable theory/statement out of retrieved and generated statements.
% FactReasoner provide such an external signal for correction
% ]
% %
% contribution summary
% }



\section{Background} % Radu
\label{sec-background}
In this section, we provide preliminaries on probabilistic graphical models and long-form factuality assessment for large language models. 

\paragraph{Graphical Models.}
A \emph{graphical model} is a tuple $\cM = \langle \bX,\bD,\bF \rangle$, where $\bX = \{X_1, \ldots, X_n\}$ is a set of variables, $\bD = \{D_1, \ldots, D_n\}$ is the set of their finite domains of values and $\bF =\{f_1, \ldots, f_m\}$ is a set of discrete positive real-valued functions. Each function $f_i$ (also called \emph{factor}) is defined on a subset of variables $\bS_i \subseteq \bX$ called its \emph{scope} and denoted by $vars(f_i)$. The model $\cM$ defines a factorized probability distribution on $\bX$: $P(\bx) = \frac{1}{Z}\prod_{j=1}^{m} f_j(\bx)$ where $Z = \sum_{\bx \in \Omega(\bX)} \prod_{j=1}^{m} f_j(\bx)$ is the normalization constant $Z$ is known as the \emph{partition function} and $\Omega(\bX)$ denotes the Cartesian product of the variables domains \cite{koller2009probabilistic}.

%The function scopes of a model $\cM$ define a \emph{primal graph} whose vertices are the variables and its edges connect any two variables that appear in the scope of the same function.

A common inference task over graphical models is to compute the posterior marginal distributions over all variables. Namely, for each variable $X_i \in \bX$ and domain value $x_i \in D_i$, compute:
$P(x_i) = \sum_{\bx \in \Omega(\bX)} \delta_{x_i}(\bx)\cdot P(\bx)$, where $\delta_{x_i}(\bx)$ is $1$ if $X_i$ is assigned $x_i$ in $\bx$ and $0$ otherwise.


\paragraph{Long-Form Factuality.}
Let $y$ be the long-form response generated by an LLM to a query $x$. Following prior work \cite{factscore2023emnlp,song2024veriscore,wei2024longform}, we assume that $y$ can be decomposed into a set of $n$ \emph{atomic units} (or \emph{atoms}) that can be either true or false, denoted by $\cA_y = \{a_1, a_2, \ldots a_n\}$. An atomic unit $a_i \in \cA_y$ is defined as a short sentence conveying one piece of information. Furthermore, given an external knowledge source $\cC$\footnote{For example, $\cC$ could be Wikipedia, Google Search, or a collection of documents embedded into a vector database.}, we say that an atomic unit $a_i\in \cA_y$ is \emph{supported} by $\cC$ if there exists at least one piece of information in $\cC$ (e.g., a passage) called a \emph{context} that undebatably supports $a_i$. Otherwise, we say that the atomic unit is \emph{not supported}. The \emph{factual precision} $Pr(y)$ of the response $y$ with respect to a knowledge source $\cC$ is defined as: $Pr(y) = \frac{S(y)}{|\cA_y|}$, 
where $S(y) = \sum_{i=1}^{n} \mathbb{I}[a_i \textrm{ is supported by } \cC]$ is the number of supported atomic units. Furthermore, the notion of \emph{factual recall} up to the $K$-th supported atomic unit denoted by $R_K(y)$ is given by: $R_K(y) = \min(\frac{S(y)}{K}, 1)$. Finally, an $F_1$ measure for long-form factuality denoted by $F1@K$ can be defined as: $F_1@K(y) = \frac{2\cdot Pr(y) \cdot R_K(y)}{Pr(y) + R_K(y)}$ if $S(y) > 0$, and $0$ otherwise \cite{wei2024longform}.
%
% \begin{align*}
%     F_1@K(y) &= \left\{
%     \begin {aligned}
%          & \frac{2\cdot Pr(y) \cdot R_K(y)}{Pr(y) + R_K(y)} ,& S(y) > 0 \\
%          & 0 ,& S(y) = 0                  
%     \end{aligned}
% \right.
% \end{align*}

%The precision and recall definitions however assume that the pieces of information in $\cC$ do not conflict or overlap with each other \cite{factscore2023emnlp}.


\section{The FactReasoner Assessor} % Radu
\label{sec-factreasoner}

In this section, we present FactReasoner, a novel long-form factuality assessor that uses probabilistic reasoning to assess the factuality of the generated response with respect to an external knowledge source $\cC$. Specifically, FactReasoner builds a graphical model that represents a joint probability distribution over the atoms of the response and their relevant contexts in $\cC$, and subsequently computes for each atom $a_i$ the posterior marginal probability distribution $P(a_i)$ representing the probability of $a_i$ being true (or supported) with respect to the information available in $\cC$.

% This definition assumes that (i) whether or not an atomic unit is supported by $\cC$ is undebatable, (ii) every atomic unit in $\cA_y$ has an equal weight of importance \cite{krishna2023longeval} and (iii) pieces of information in $\cK$ do not conflict or overlap with each other \cite{factscore2023emnlp}. 

% Therefore, the framework proposed in Section \ref{sec-factreasoner} aims to relax these assumptions thus allowing for varying levels of support for the atomic units, conflicts and overlaps in the external knowledge source as well as atomic units with different degrees of importance, which is more realistic in practice.

% {
% \color{red}
% In LLM consisteny literature, the most common target is semantic consistency \cite{elazar2021measuring,kuhn2023semantic}.
% logical consistency is adding semantic consistency and NLI \cite{jang2022becel}.
% the graphical model enforces logical (NLI) consistency.
% consistency are evalauted with dataset and evaluation sets are used for tuning the model.
% it is not directly comparable but a common approach. Here, it's like external reasoning, RAG, or test-time compute.
% }
\subsection{A Graphical Models Based Approach}

Let $y$ be the long-form response generated by an LLM for the input query $x$, and let $\cA_y = \{a_1, \ldots, a_n\}$ be the set of $n$ atomic units corresponding to $y$. For simplicity, but without loss of generality, we restrict ourselves to atomic units that are either \emph{facts} or \emph{claims} \cite{song2024veriscore}. In addition, let $\cC_y = \{c_1, \ldots, c_m\}$ be a set of $m$ contexts relevant to $y$'s atoms that were retrieved from an external knowledge source $\cC$. We make no assumptions about these contexts, namely they may be overlapping and/or contradicting each other, which is often the case in realistic situations. 

We next define the graphical model $\langle \bX, \bD, \bF \rangle$ that represents a joint probability distribution over the atoms and their corresponding contexts.

\paragraph{Variables.} We associate each atom $a_i \in \cA_y$ and context $c_j \in \cC_y$ with a bi-valued variable denoted by either $A_i$ (for atoms) or $C_j$ (for contexts). Therefore, we have that $\bX=\bX_a \cup \bX_c$ where $\bX_a = \{A_1, \ldots, A_n\}$ and $\bX_c = \{C_1, \ldots, C_m\}$, respectively. The domains of the variables contain the values \emph{true} and \emph{false} indicating whether the corresponding atom or context is true or false. For simplicity, we use $a_i$ and $\neg a_i$ (resp. $c_j$ and $\neg c_j$) to denote the value assignments $A_i = true$ and $A_i = false$ (resp. $C_j=true$ and $C_j=false$).

\paragraph{Priors.} For each variable $A_i \in \bX_a$ (resp. $C_j \in \bX_c$) we consider a unary factor denoted by $f(A_i)$ (resp. $f(C_j)$) representing the prior belief about the truthfulness of the corresponding atom (resp. context). Since we make no assumptions about the response, we set $f(a_i) = 0.5$ and $f(\neg a_i) = 0.5$, respectively. In contrast, the external knowledge source $\cC$ is assumed to be reliable and therefore the retrieved contexts have high probability of being true (e.g., $f(c_j) = 0.99$). Note that if a context is retrieved from a less reliable source then its prior probability can be set to a smaller value. 

\paragraph{Relationships.} In addition, we also consider binary factors denoted by $f(A_i,C_j)$ and $f(C_j, C_k)$, defined on atom-context variable pairs as well as pairs of context variables. These factors are probabilistic representations of the logical relationships between the natural language utterances corresponding to the context and atom variables. For our purpose, we use a \emph{relation model} $p_{\theta}(\cdot | t,t')$ to predict the most likely logical relationship between an ordered pair of natural language utterances from
the choices \{none, entail, contradict, equivalence\}\footnote{The ``equivalence" relationship is formed if entailment is predicted for both orderings of the utterances. The ``none" relationship corresponds to neutrality meaning that the two utterances are not related to each other.}. The relation model can be any pre-trained BERT or LLM \cite{liu2019roberta,touvron2023llama}.

Specifically, let $X$ and $Y$ be two variables in $\bX$ and let $t_X$ and $t_Y$ be their corresponding textual utterances. Let also $r^* = \argmax_{r} p_\theta(r|t_X,t_Y)$ be the predicted relationship between the ordered pair $(t_X,t_Y)$ and let $p^*$ be its probability. Table \ref{tab:factors} shows the binary factor $f(X,Y)$ corresponding to $r^*\in$ \{entailment, contradiction, equivalence\}.  

\begin{table}[t!]
\begin{center}
\resizebox{\linewidth}{!}{%
\begin{tabular}{cc|c|c|c}
        &     & entailment & contradiction & equivalence \\
    $X$ & $Y$ & $f(X,Y)$ & $f(X,Y)$ & $f(X,Y)$ \\
    \toprule
    $x$ & $y$ & $p^*$  &  $1-p^*$ &  $p^*$ \\
    $x$ & $\neg y$ & $1 - p^*$ &  $p^*$  & $1 - p^*$ \\
    $\neg x$ & $y$ & $p^*$  &  $p^*$  & $1 - p^*$ \\
    $\neg x$ & $\neg y$ & $p^*$  & $p^*$  &  $p^*$ \\
\end{tabular}}
\end{center}
\caption{Factors corresponding to logical relationships.}
\label{tab:factors}
\end{table}

For instance, if $r^*$ corresponds to entailment and $(X, Y)$ is a context-atom pair then the context supports the atom. Alternatively, if $r^*$ is a contradiction for the same $(X,Y)$ pair then the context contradicts the atom. Finally, for BERT-based relation models, the probability $p^*$ is given together with the predicted relationship $r^*$, whereas for instructed LLM-based relation models we can obtain $p^*$ by applying any uncertainty quantification method \cite{lin2024generating,spuq}. We use a simple white-box method that calculates $p^*$ as the probability of the ``entailment" or ``contradiction" tokens produced by the model.


Therefore, the set of factors $\bF$ is:
\begin{align*}
    \bF &= \{f(C_j,A_i)~|~ A_i\in \bX_a, C_j \in \bX_c\} \\
        & \cup \{f(C_j,C_k)~|~ C_j\in \bX_c, C_k\in \bX_c\} \\
        & \cup \{f(A_i~|~ \forall A_i\in \bX_a)\} \\
        & \cup \{f(C_j~|~ \forall C_j \in \bX_c)\}
\end{align*}
\noindent where we consider $r^*\in$ $\{\textrm{entail}$, $\textrm{contradict}\}$ for the context-atom pairs, and $r^*\in$ $\{\textrm{entail}$, $\textrm{contradict}$, $\textrm{equivalence}\}$ for the context pairs, respectively.


\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{figs/fig-fr-a.png}
    \caption{FactReasoner: the graphical model corresponding to one atom $A_1$ and two contexts $C_1$ and $C_2$ such that $C_1$ entails $A_1$ and $C_2$ contradicts $A_1$.}
    \label{fig:fr-a}
\end{figure}


\begin{example}
    Figure \ref{fig:fr-a} shows a simple example with one atomic unit $a_1$ and two contexts $c_1$ and $c_2$ retrieved from Wikipedia together with their corresponding natural language utterances. In this case, context $c_1$ entails the atom with probability $p_e=0.8$ while context $c_2$ contradicts it with probability $p_c = 0.9$. The corresponding graphical model has 3 variables $\{A_1, C_1, C_2\}$, 3 unary factors $\{f(A_1)$, $f(C_1)$, $f(C_2)\}$ as well as 2 binary factors $\{f(C_1,A_1)$, $f(C_2,A_2)\}$ encoding the two entailment and contradiction relationships.
\end{example}

\subsection{Inference and Factuality Assessment}

The graphical model $\cM =\langle \bX,\bD,\bF \rangle$ we just defined in the previous section represents a joint probability distribution over the set of atoms and relevant externally retrieved contexts. Therefore, we can use any probabilistic inference algorithm to compute the posterior marginal distribution $P(A_i)$ for each atom $A_i \in \cA_y$ \cite{pearl88,koller2009probabilistic}. Specifically, in our experiments, we use an approximate variational inference algorithm called Weighted Mini-Buckets \cite{liu2011} to compute the marginals.

\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{figs/fig-fr-b.png}
    \caption{FactReasoner: the graphical model corresponding to one atom $A_1$ and three contexts $C_1$, $C_2$ and $C_3$ such that $C_3$ contradicts $C_2$.}
    \label{fig:fr-b}
\end{figure}


The number of supported atomic units $S(y)$ in a response $y$ can be computed in this case as: $S(y) = \sum_{i=1}^{n} \mathbb{I}[P(a_i) > P(\neg a_i)]$, namely it is the number of atoms for which the probability of being true is larger than the probability of being false.

\begin{example}
    Looking again at Figure \ref{fig:fr-a}, we can see that in this case the posterior probability of the atom is $P(a_1) = 0.32$ and $P(\neg a_1) = 0.68$, which means that the atom is most likely false. Figure \ref{fig:fr-b} continues the example and shows a third context $c_3$, possibly retrieved from another external knowledge source, that contradicts context $c_2$ and is neutral to atom $a_1$. As expected, the contradiction between $c_2$ and $a_1$ is much weaker now and therefore the posterior marginal probabilities are $P(a_1) = 0.59$ and $P(\neg a_1) = 0.41$, meaning that in light of the newly retrieved information, atom $a_1$ in more likely to be true than false. This example illustrates the kinds of conflicts that may exist between atoms and contexts and how they affect the factuality assessment.
\end{example}

In addition to the factual precision $Pr(y)$ and $F_1@K$ measures, we define a new \emph{entropy}-based factuality measure called $\cE(y)$ that leverages the posterior probabilities of response $y$'s atoms:
\begin{equation}\label{eq:entropy}
    \cE = \frac{1}{n} \sum_{i=1}^{n} -P(a_i) \cdot \log P(a_i)
\end{equation}
\noindent where $n$ is the number of atomic units in $y$.

Clearly, if all atoms in $\cA_y$ have posterior probability $P(a_i) = 0.5$, there is virtually no external information to support or contradict the atoms (we refer to these atoms as \emph{undecided atoms}) then $\cE(y) = 0.150515$. On the other hand, if all atoms are true with absolute certainty ($P(a_i) = 1$), then $\cE(y) = 0$ and if all atoms are false with absolute certainty then $\cE(y) = \infty$. Therefore, when $\cE(y)$ is closer to $0$ the response is more truthful.

\subsection{The FactReasoner Pipeline and Variants}

\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{figs/fig-fr-pipeline.png}
    \caption{The FactReasoner pipeline.}
    \label{fig:fr-pipeline}
\end{figure}

The proposed FactReasoner pipeline for long-form factuality assessment is shown in Figure \ref{fig:fr-pipeline} and consists of four main stages called Atomizer, Reviser, Retriever and Evaluator, respectively. It takes as input a response $y$ and outputs the marginal posterior probabilities $P(a_i)$ of $y$'s atomic units together with the factuality measures described earlier, such as $Pr(y)$, $F_1@K(y)$ and $\cE(y)$, respectively.

The \textbf{Atomizer} prompts an LLM to decompose the response $y$ into a set of $n$ atomic units $\cA_y$ by applying any of the decomposition strategies proposed recently \cite{factscore2023emnlp,bayat2025factbench}. Subsequently, the \textbf{Reviser} also uses an LLM to revise the atoms such that the pronouns, unknown entities, or incomplete names are replaced with their corresponding named entities in the response \cite{wei2024longform}. Next, the \textbf{Retriever} is responsible for querying an external knowledge source to retrieve the contexts relevant to the response's atoms. At this stage, we can simply use the atoms' utterances as queries or prompt an LLM to generate them \cite{song2024veriscore}. Finally, the \textbf{Evaluator} constructs the probabilistic graphical model representing the logical relationships between the atoms and contexts, and assess $y$'s factuality via probabilistic reasoning, as described previously.

Depending on what relationships between atoms and contexts are considered, we define three versions of the FactReasoner pipeline, as follows:

\paragraph{FactReasoner 1 (FR1).} In this case, for each atom variable $A_i$ up to $k$ most relevant contexts $\{C_1^i, ..., C_k^i\}$ are retrieved and only the relationships between atom $A_i$ and its corresponding contexts are considered, namely only the factors $f(A_i,C_j^i)$ are created (where $j=1..k$).

\paragraph{FactReasoner 2 (FR2).} This version also retrieves up to $k$ contexts for each atom $A_i$, but it subsequently removes any duplicated contexts, thus resulting in $m$ unique contexts denoted by $\{C_1, ..., C_m\}$. It then considers the relationships between atom $A_i$ and all $m$ contexts, creating the factors $f(A_i, C_j)$, where $j=1..m$.

\paragraph{FactReasoner 3 (FR3).} In this version, we consider the same contexts $\{C_1, ..., C_m\}$ as in FR2, but in addition to the atom-context relationships we also consider the context-context relationships. Thus, we create the factors $f(A_i,C_j)$ as well as the factors $f(C_j,C_k)$, where $j=1..m$ and $k=1..m$ and $j\neq k$, respectively.



\section{Experiments} %Radu, Javier, Tigran
\label{sec-experiments}
In this section, we empirically evaluate our proposed FactReasoner assessor for long-form factuality and compare it against state-of-the-art approaches on labeled and unlabeled datasets. Although the FactReasoner pipeline stages can be instantiated with different LLMs, in our implementation we use the same LLM throughout the entire pipeline and focus our empirical evaluation on the Evaluator stage (i.e., factuality assessment).


\paragraph{Baseline Assessors.} 
For our purpose, we consider the following state-of-the-art prompt-based long-form factuality assessors: FactScore (FS) \cite{factscore2023emnlp}, FactVerify (FV) \cite{bayat2025factbench} and VeriScore (VS) \cite{song2024veriscore}. FactScore is one of the first assessor that prompts an LLM to assess whether an atomic unit of the response is supported or not by a set of contexts relevant to the atom which are retrieved from an external knowledge source such as Wikipedia. FactVerify and VeriScore are more recent refinements of FactScore's original prompt that can accommodate other external knowledge sources such as Google Search results and enable the LLM's reasoning capabilities to evaluate the relationships between an atom and its relevant contexts. Unlike FactScore, the latter can label the atoms as supported, contradicted and undecided, respectively. In our experiments, we instantiated the competing assessors including the FactReasoner variants with open-source LLMs belonging to the IBM Granite\footnote{\texttt{https://huggingface.co/ibm-granite}}, Meta LLama\footnote{\texttt{https://huggingface.co/meta-llama}} and MistralAI Mixtral\footnote{\texttt{https://huggingface.co/mistralai}} families, namely: granite-3.0-8b-instruct, llama-3.1-70b-instruct, and mixtral-8x22b-instruct, respectively. All our LLMs are hosted remotely on compute nodes with A100 80GB GPUs and accessed via \texttt{litellm} APIs.


\paragraph{Datasets.} 
We experimented with the following benchmark datasets: Biographies (Bio) \cite{factscore2023emnlp}, AskHistorians (AskH) \cite{xu2023}, ELI5 \cite{xu2023}, FreshBooks (Books) \cite{song2024veriscore} and LongFact-Objects (LFObj) \cite{wei2024longform}. 

The Biographies is a \emph{labeled} dataset that contains 157 biographies generated by ChatGPT for various person entities that have a Wikipedia page. Each biographic passage is also associated with a set of human generated atomic units (facts) that are labeled as \emph{supported} (S) or \emph{not-supported} (NS) by human annotators. We assume that this annotation is the ground truth.

The other four datasets are unlabeled and consist of collections of prompts (or questions). Specifically, the AskH and ELI5 datasets contain 200 questions each that were scraped from the reddit/AskHistorians and reddit/explainlikeimfive online forums, while the Books dataset consists of 10 paragraphs sampled from 20 non-fictional books that were published between 2023 and 2024, for a total of 200 paragraphs. Our version of the LFObj dataset is a subset of the original dataset \cite{wei2024longform} and contains 10 prompts sampled randomly from the original ones about objects spreading 38 different topics. For each prompt in these datasets, we generated a long-form response spanning up to two paragraphs using the llama-3.3-70b-instruct model \cite{touvron2023llama}.



\paragraph{Measures of Performance.} 
For each dataset $\cD$ and each competing assessor, we report the factual precision $Pr$ and $F_1@K$ measure, averaged over the number of prompts in $\cD$. If $\cD$ contains annotated atomic units (i.e., ground truth) then we also report the standard $F_1$ measure and the mean absolute error (MAE) given by:
\begin{equation}
    \textrm{MAE} = \frac{1}{|\cD|}\sum_{j=1}^{|\cD|} |Pr_j - Pr^*_j|
\end{equation}
\noindent where $Pr_j$ and $Pr^*_j$ are the precision and respectively the true factual precision of the $j$-th instance. Since the FactReasoner assessors calculate the posterior marginal distributions of the atoms, we also compute the $\cE$-measure. Finally, we also report the mean number of supported (\#S), contradicted (\#C) and undecided atoms (\#U), respectively.

% \begin{table}[t!]
%     \centering
%     \resizebox{\linewidth}{!}{%
%     \begin{tabular}{l|r|r|r|r|r}
%        Dataset & \# prompts & \# atoms & \# S$^*$ & Pr$^*$ & $K$\\
%        \toprule
%        %\multicolumn{6}{c}{labeled}\\
%        %\midrule
%        Biographies  & 157 & 31$\pm$8 & 20$\pm$10 & 0.62$\pm$0.26 & 32 \\
%        % Claims       & 330 & 1 & 1 & 1 \\
%        %\midrule
%        % \multicolumn{6}{c}{unlabeled}\\
%        \midrule
%        AskH         & 200 & 22$\pm$5 & & & 22\\
%        Books        & 200 & 23$\pm$7 & & & 23\\
%        ELI5         & 200 & 22$\pm$5 & & & 21\\
%        LFObj        & 380 & 26$\pm$9 & & & 25\\
%     \end{tabular}
%     }
%     \caption{Properties of the datasets used for evaluation.}
%     \label{tab:datasets}    
% \end{table}

\begin{table}[t!]
    \centering
    \resizebox{0.9\linewidth}{!}{%
    \begin{tabular}{l|r|r|r|r|r}
       Dataset & \# prompts & \# atoms & \# S$^*$ & Pr$^*$ & $K$\\
       \toprule
       %\multicolumn{6}{c}{labeled}\\
       %\midrule
       Biographies  & 157 & 31 & 20 & 0.62 & 32 \\
       % Claims       & 330 & 1 & 1 & 1 \\
       %\midrule
       % \multicolumn{6}{c}{unlabeled}\\
       \midrule
       AskH         & 200 & 22 & & & 22\\
       Books        & 200 & 23 & & & 23\\
       ELI5         & 200 & 22 & & & 21\\
       LFObj        & 380 & 26 & & & 25\\
    \end{tabular}
    }
    \caption{Properties of the datasets used for evaluation.}
    \label{tab:datasets}    
\end{table}

\paragraph{External Knowledge Sources.} We consider two external knowledge sources: Wikipedia and Google Search results. For a given atom, the top $k$ results are retrieved as contexts either from wikipedia.org using the Wikipedia retriever available from LangChain\footnote{\texttt{https://python.langchain.com}}, or from google.com using the Serper API\footnote{\texttt{https://serper.dev}}. In both cases, a context is a tuple $(t,l,s,d)$, where $t$ is the title of the wiki/web-page, $l$ is the link, $s$ is a short text snippet or summary and $d$ is the content retrieved from $l$ (but capped at max 4000 characters). We used $k=3$ for the Wikipedia retriever and $k=5$ for the Google Search results \cite{factscore2023emnlp,wei2024longform}.

In order to ensure a consistent evaluation, we decompose each response in the datasets into the corresponding atomic units (and subsequently revise them) using the same llama-3.3-70b-instruct model. Furthermore, we also retrieve and cache the relevant contexts for atoms from the two knowledge sources. This way, all competing assessors could be evaluated on the same sets of atoms and contexts. Table \ref{tab:datasets} summarizes the properties of the datasets, showing the number of prompts, the mean number of atoms and the median number of atoms ($K$). The latter is used for calculating the $F_1@K$ measure. In addition, for the labeled dataset, we also indicate the true number of supported atoms ($S^*$) and the true precision (Pr$^*$).

% \begin{figure}
%     \centering
%     \includegraphics[width=0.49\linewidth]{figs/expert_contradiction_logprobs_vitc_llama-3.1-70b-instruct_rits.png}
%     \includegraphics[width=0.49\linewidth]{figs/expert_entailment_logprobs_vitc_llama-3.1-70b-instruct_rits.png}
%     \caption{ROC curves for the \texttt{vitc}- and \texttt{llama}-based relation models predicting contradiction and entailment.}
%     \label{fig:nli-llama}
% \end{figure}


\begin{table}[t!]
    \centering
    \resizebox{\linewidth}{!}{%
    \begin{tabular}{l|r|r|r|r|r|r|r|r}
       Assessor & \# S & \# C & \# U & Pr$\uparrow$ & $F_1$ $\uparrow$ & $F_1@K$ $\uparrow$ & MAE$\downarrow$ & $\cE$ $\downarrow$ \\
       \toprule
       \multicolumn{9}{c}{BERT-based relation model: \texttt{albert-xlarge-vitaminc-mnli}}\\
       \midrule
       FR1  & 12 &  5 & 12 & 0.40 & 0.66 & 0.39 & 0.25 & 0.11 \\
       FR2  & 10 & 16 &  4 & 0.32 & 0.53 & 0.31 & 0.34 & 0.09 \\
       FR3  & 10 & 16 &  4 & 0.32 & 0.53 & 0.31 & 0.33 & 0.09 \\       
       \toprule
       \multicolumn{9}{c}{LLM-based relation model: \texttt{llama-3.1-70b-instruct}}\\
       \midrule
       FR1  & 13 & 1 & 16  & 0.41 & 0.70 & 0.41 & 0.23 & 0.10 \\
       FR2  & {\bf 19} & 2 &  9  & {\bf 0.60} & {\bf 0.83} & {\bf 0.59} & {\bf 0.11} & {\bf 0.06} \\
       FR3  & {\bf 19} & 2 &  9  & {\bf 0.60} & {\bf 0.83} & {\bf 0.59} & {\bf 0.11} & {\bf 0.06} \\
    \end{tabular}}
    \caption{Results for the \texttt{vitc}- and \texttt{llama}-based relation models used by FactReasoner's Evaluator stage.}
    \label{tab:nli}
\end{table}


\subsection{Evaluating the Relation Model}
We first evaluate the relation model used by the Evaluator stage of the FactReasoner assessor to extract the atom-context and context-context relationships required to construct the graphical model. Specifically, we consider two relation models based on a standard BERT-based model such as \texttt{vitc} \cite{schuster2021vitc} and on a larger LLM such as \texttt{llama-3.1-70b-instruct} \cite{touvron2023llama} with a suitable few-shots prompt. 

Table \ref{tab:nli} shows the results obtained for the FR1, FR2 and FR3 assessors employing the two types of relation models on the Biographies dataset using Wikipedia retrieved contexts. We observe that using the LLM-based relation model which predicts entailments much more accurately than the BERT-based one leads to significant improvements in performance, especially for the FR2 and FR3 variants. For example, the \texttt{llama}-based FR2 achieves an $F_1$ score nearly twice as high compared with the \texttt{vitc}-based one (i.e., 0.83 versus 0.53). For this reason, we only employ LLM-based relation models for now on (see also the Appendix for more details).



\subsection{Results on Labeled Datasets}

\begin{table}[t!]
    \centering
    \resizebox{\linewidth}{!}{%
    \begin{tabular}{l|r|r|r|r|r|r|r|r}
       Assessor & \# S & \# C & \# U & Pr $\uparrow$ & $F_1$ $\uparrow$ & $F_1@K$ $\uparrow$ & MAE $\downarrow$ & $\cE$ $\downarrow$ \\
       \toprule
       \multicolumn{9}{c}{\texttt{granite-3.0-8b-instruct}}\\
       \midrule
       FS   & 18 & 12  &     & 0.59  & 0.70  & 0.57  & 0.17 &   \\
       FV   & 14 &  2  & 14  & 0.45  & 0.67  & 0.44  & 0.21 &  \\
       VS   & 15 &  8  &  6  & 0.49  & 0.64  & 0.48  &  0.21 &  \\
       FR1 (ours)  & 14 &  2  & 14  & 0.43  & 0.70  & 0.43  & 0.22  &  0.12 \\
       FR2 (ours)  & 20 &  4  &  6  & {\bf 0.62} & {\bf 0.78}  & {\bf 0.61} & {\bf 0.12}  & {\bf 0.06} \\
       FR3 (ours)  & 19 &  4  &  6  & 0.60  & 0.78  & 0.59  & 0.13  &  {\bf 0.06} \\
       \midrule
       \multicolumn{9}{c}{\texttt{llama-3.1-70b-instruct}}\\
       \midrule
       FS   & 19 & 12  &     & 0.59  & 0.73  & 0.58  & 0.16 &  \\
       FV   & 15 & 1   & 14  & 0.47  & 0.73  & 0.47  & 0.19 &  \\
       VS   & 12 & 0   & 18  & 0.38  & 0.64  & 0.38  & 0.27 &  \\
       FR1 (ours)  & 13 & 1   & 16  & 0.42  & 0.71  & 0.42  & 0.23 & 0.10 \\
       FR2 (ours) & 19 & 2   &  9  & {\bf 0.60}  & {\bf 0.83}  & {\bf 0.59}  & {\bf 0.11} & {\bf 0.06} \\
       FR3 (ours) & 19 & 2 &  9  & {\bf 0.60}  & {\bf 0.83}  & {\bf 0.59}  & {\bf 0.11} & {\bf 0.06} \\
       \midrule
       \multicolumn{9}{c}{\texttt{mixtral-8x22b-instruct}}\\
       \midrule
       FS   & 19 & 12 &    & 0.59  & 0.74  & 0.58  & 0.16 &  \\
       FV   & 15 & 1 & 13  & 0.49  & 0.72  & 0.48  & 0.19 &  \\
       VS   & 13 & 1 & 15  & 0.42  & 0.65  & 0.42  & 0.25 &  \\
       FR1 (ours) & 14 & 0 & 15  & 0.44  & 0.72  & 0.44  & 0.21  & 0.10 \\
       FR2 (ours) & 20 & 1 &  8 & {\bf 0.63}  & {\bf 0.83}  & {\bf 0.62}  & {\bf 0.11}  & {\bf 0.07} \\
       FR3 (ours) & 20 & 1 &  9 & {\bf 0.64}  & {\bf 0.83}  & {\bf 0.62}  & {\bf 0.11}  & {\bf 0.07} \\

    \end{tabular}}
    \caption{Results on the labeled Biographies dataset using Wikipedia contexts (mean number of supported (\#S), contradicted (\#C) and undecided (\#U) atoms).}
    \label{tab:bio-wikipedia}
\end{table}

Table \ref{tab:bio-wikipedia} shows the results obtained on the labeled Biographies dataset using Wikipedia retrieved contexts (the best performance is highlighted). We see that in terms or mean absolute error (MAE), precision and $F_1$ scores, the FR2 and FR3 assessors powered by stronger LLMs like llama-3.1-70b-instruct and mixtral-8x22b-instruct achieve the best performance compared to the other assessors. This is because both FR2 and FR3 can exploit the relationships between the atoms and all the retrieved contexts (as well as between the contexts themselves for FR3), not just the ones between an atom and its corresponding top $k$ contexts. Therefore, it is often the case that a context retrieved for atom $A_i$ may support or contradict another atom $A_j$ for which it wasn't retrieved. This leads to a higher number of true positives and consequently larger $F_1$ scores. We also observe that the numbers of undecided atoms is also smaller for FR2/FR3 compared with the other assessors. The performance of FR3 is similar to that of FR2 because most of the context-context relationships are equivalence.

When looking at the prompt-based assessors, especially FV and VS, we see that they are more conservative in terms of number of supported atoms found. This can be explained by the relatively strict instructions specified in their prompts for identifying supported/contradicted atoms. Hence the number of undecided atoms is much larger than that of FR2/FR3. The  simple prompt used by FS leads to finding a relatively large number supported atoms, across all the backend LLMs considered. However, many of these supported atoms are actually false positives which in fact is explained by the relatively smaller $F_1$ score compared with the best performing assessors FR2 and FR3, respectively. 

We notice that the lightweight FR1 assessor performs on par with FV and VS in terms of precision, error and $F_1$ score. This shows that using only the top $k$ contexts to determine whether an atom is supported or not is fairly limited. Furthermore, in situations when an atom is supported by several contexts but is contradicted by another context (which might as well be a spurious contradiction), the FR2/FR3 assessors are able to correctly label the atom as supported based on the strengths of the respective relationships (i.e., probabilities of entailment and contradiction) whereas the other assessors struggle and often label the atom as contradicted or undecided. This demonstrates clearly the power of the probabilistic approach to factuality as employed by the proposed assessors.



%%%% AskHistorians with Wikipedia
\begin{table}[t!]
    \centering
    \resizebox{0.8\linewidth}{!}{%
    \begin{tabular}{l|r|r|r|r|r|r}
       Assessor & \# S & \# C & \# U & Pr $\uparrow$ & $F_1@K$ $\uparrow$ & $\cE$ $\downarrow$ \\
       \toprule
       \multicolumn{7}{c}{\texttt{granite-3.0-8b-instruct}}\\
       \midrule
       FS   & 17 & 5  &   & 0.76  & 0.74  &    \\
       FB   &  8 & 0  & 13  & 0.35  & 0.36  &    \\
       FV   & 12 & 4  &  5  & 0.55  & 0.55   &    \\
       FR1 (ours)  &  4 & 1 & 16 & 0.19  & 0.19  & 0.14  \\
       FR2 (ours) & 10 & 9 & 2  & 0.46  & 0.47  & 0.09  \\
       FR3 (ours) & 11 & 8 & 2  & 0.47  & 0.48  & 0.10   \\
       \midrule
       \multicolumn{7}{c}{\texttt{llama-3.1-70b-instruct}}\\
       \midrule
       FS   &  15  & 7  &  & 0.69  & 0.68  &    \\
       FB   &   8  &  0 & 13  & 0.37  & 0.38   &  \\
       FV   &   5  &  0 & 16  & 0.25  & 0.25   &  \\
       FR1 (ours) &  5 & 0  & 17  & 0.21  & 0.22  & 0.13 \\
       FR2 (ours) & 10 & 1  & 10  & 0.45  & 0.46  & 0.09 \\
       FR3 (ours)  & 10 & 1  & 10  & 0.44 & 0.45  & 0.09 \\
       \midrule
       \multicolumn{7}{c}{\texttt{mixtral-8x22b-instruct}}\\
       \midrule
       FS   & 16  & 6  &   &  0.71  & 0.70  &  \\
       FB   &  9  & 0  & 12  & 0.43  & 0.43  &  \\
       FV   &  7  & 0  & 14  & 0.34  & 0.34  &  \\
       FR1 (ours) &  5 & 0  & 17  & 0.22  & 0.23 & 0.12 \\
       FR2 (ours) & 11 & 0  & 11  & 0.46  & 0.47  & 0.09 \\
       FR3 (ours) & 11 & 0  & 11  & 0.46  & 0.47  & 0.09 \\
       \toprule
       DeepSeek-v3 & 9 &  1  & 12   &  0.43   &  0.43    & \\

    \end{tabular}}
    \caption{Results on the unlabeled AskH dataset using Wikipedia contexts (mean number of supported (\#S), contradicted (\#C) and undecided (\#U) atoms).}
    \label{tab:askh-wikipedia}
\end{table}


%%%% AskHistorians with Google Search
\begin{table}[t!]
    \centering
    \resizebox{0.8\linewidth}{!}{%
    \begin{tabular}{l|r|r|r|r|r|r}
       Assessor & \# S & \# C & \# U & Pr $\uparrow$ & $F_1@K$ $\uparrow$ & $\cE$ $\downarrow$ \\
       \toprule
       \multicolumn{7}{c}{\texttt{granite-3.0-8b-instruct}}\\
       \midrule
       FS   & 18  & 3  &   & 0.82  & 0.81  &     \\
       FV   & 14  & 1  & 7  & 0.62  & 0.62   &    \\
       VS   & 14  & 3  & 3  & 0.65  & 0.65   &    \\
       FR1 (ours)  & 13 & 4 & 4  & 0.60  & 0.60  &  0.08  \\
       FR2 (ours) & 14 & 7 & 0  & 0.63  & 0.62  &  0.04  \\
       FR3 (ours) & 15 & 7  & 0  & 0.67  & 0.66 &  0.06  \\
       \midrule
       \multicolumn{7}{c}{\texttt{llama-3.1-70b-instruct}}\\
       \midrule
       FS   & 18 & 3  &   & 0.82  & 0.80  &  \\
       FV   & 16 & 1  & 5  & 0.71  & 0.70   &  \\
       VS   & 15 & 0  & 7  & 0.66  & 0.65   &  \\
       FR1 (ours) & 12 & 1  & 8  & 0.53  & 0.54  & 0.08 \\
       FR2 (ours) & 17 & 1  & 3  & 0.76  & 0.74  & 0.04 \\
       FR3 (ours) & 17 & 2  & 3  & 0.75  & 0.74  & 0.04 \\
       \midrule
       \multicolumn{7}{c}{\texttt{mixtral-8x22b-instruct}}\\
       \midrule
       FS   & 18 & 3  &   & 0.82   & 0.80  &  \\
       FV   & 15 & 0  & 6  &  0.67  & 0.67  &  \\
       VS   & 15 & 0  & 6  &  0.68  & 0.67  &  \\
       FR1 (ours) & 14 & 0  & 8  & 0.60  & 0.60  & 0.07 \\
       FR2 (ours) & 18 & 0  & 3  & 0.80  & 0.79  & 0.04 \\
       FR3 (ours) & 18 & 0  & 3  & 0.80  & 0.79  & 0.04 \\
       \toprule
       DeepSeek-v3   &  15  &  2  &  5   &  0.69   &   0.69    & \\

    \end{tabular}}
    \caption{Results on the unlabeled AskH dataset using Google Search contexts (mean number of supported (\#S), contradicted (\#C) and undecided (\#U) atoms).}
    \label{tab:askh-google}
\end{table}

\subsection{Results on Unlabeled Datasets}
Tables \ref{tab:askh-wikipedia} and \ref{tab:askh-google} show the results obtained on the unlabeled AskH dataset using Wikipedia and Google Search retrieved contexts, respectively (we include in the the Appendix the experiments with the remaining  datasets: Books, ELI5 and LFObj). Since there is no ground truth for this dataset, we only report the precision, $F_1@K$ (for $K=22$) and the $\cE$ measure. However, for reference, we also experimented with DeepSeek-v3, perhaps one of the strongest open models at the moment, using a suitable prompt \cite{deepseek2024}.

We note that the AskH dataset covers a wider range of topics compared with the Biographies dataset and, therefore, the Wikipedia based contexts have a much smaller coverage in this case compared with the Google search results. This is reflected by the relatively smaller number of atoms supported by Wikipedia only contexts (Table \ref{tab:askh-wikipedia}) compared with those supported by Google Search results (Table \ref{tab:askh-google}), across all competing assessors. A similar pattern can be observed for the precision, $F_1@K$ and $\cE$ measures reported in Table \ref{tab:askh-wikipedia}, as they are typically inferior to those shown in Table \ref{tab:askh-google}. 

The prompt-based assessors FV and VS are fairly conservative in this case as well and find relatively fewer supported atoms compared with the FR2 and FR3 assessors. The latter two benefit from considering the relationships between an atom and all of the retrieved contexts and, therefore, find more supported atoms. The corresponding precision and $F_1@K$ values are also higher for FR2/FR3. We also observe that the $\cE$-measure specific to the FR assessors correlates well with the number of supported atoms, namely as the number of supported atoms increases $\cE$ gets closer to $0$ . 

When looking at the FS assessor, we notice again that it tends to find more supported atoms than the other assessors. However, we hypothesise that some of these atoms are false positive as before, but acknowledge that without any ground truth information it is difficult to verify this hypothesis.

Comparing the results obtained with DeepSeek-v3, we see that FV and VS come very close, especially for Google Search contexts. This is likely because the prompts used are fairly similar. In contrast, FR2/FR3 find slightly more supported atoms, although the results are very close for Wikipedia only contexts. We believe that this is caused by spurious context-atom entailment relationships which indicates that a better relation model is required.

In summary, our proposed FactReasoner assessor achieved the best performance on the labeled dataset, nearly matching the ground truth. However, on the unlabeled datasets, its performance was comparable with that of its competitors including DeepSeek-v3, a very powerful open model. 

\section{Related Work} 
\label{sec-related}

The assessment of LLMs' adherence to factual knowledge has gained significant attention in recent years due to their widespread adoption. Several well-established benchmarks, including TruthfulQA \cite{lin2022truthfulqa}, FreshQA \cite{vu2023freshllms}, HaluEval \cite{li2023halueval}, HalluQA \cite{cheng2023evaluating}, and FELM \cite{chen2023felm}, focus on short-form response evaluation, where an LLM’s knowledge is tested through individual factoids classified as either true or false. More recent studies \cite{factscore2023emnlp,wei2024longform,bayat2025factbench,song2024veriscore} have extended this approach to long-form generations by decomposing responses into distinct factual elements, which are then evaluated separately against relevant evidence retrieved from an external source of knowledge. These previous works typically assume that the retrieved pieces of information do not overlap or conflict with each other. 

Conflicting information is prevalent in external knowledge sources \cite{xu2024knowledge} and it typically impacts modern retrieval augmented-generation systems that aim to reduce hallucinations in LLMs \cite{lewis2021retrievalaugmented}. Other works have developed new benchmarks for capturing knowledge conflicts in realistic situations \cite{hou2024wiki,marjanovic2024dynamicqa,su2024conflictbank,pham2024s}. 

Our work is closely related with recent studies on self-consistency that aim at improving the logical consistency of the LLM's response with respect to the input query by leveraging various methods including formal reasoning
\cite{wang2023selfconsistency,dohan2022language,mitchell2022concord}.

\section{Conclusion}
\label{sec-conclusion}

The paper provides a new perspective on long-form factuality assessment and proposes FactReasoner, a new factuality assessor that employs probabilistic reasoning to assess the factuality of an LLM-generated long-form response. FactReasoner proceeds in a manner similar to existing prompt-based assessors by decomposing the response into atomic units and retrieving contexts relevant to them from an external knowledge source. However, unlike those methods, FactReasoner evaluates the factuality of the atoms by probabilistic reasoning over a graphical model that represents the logical relationships between the textual utterances corresponding to the atoms and contexts. We experiment with labeled and unlabeled benchmark datasets and demonstrate conclusively that FactReasoner improves significantly over the state-of-the-art prompt based approaches for long-form factuality evaluation. For future work, we plan to leverage the new FactReasoner assessor as part of a self-reflection loop to facilitate correction of the response.



\section*{Limitations}
We acknowledge further limitations of the proposed FactReasoner approach. 

First, the Atomizer stage is sensitive to the quality of the prompt and few shot examples used as well as the LLM employed to perform the atomic unit decomposition of the response. In our work we only consider open-source models from the LLaMA family (i.e., \texttt{llama-3.3-70b-instruct}). Furthermore, the decomposition of the response can be done at different granularities such as sentence level, paragraph level and the entire response level. Our implementation is limited to decomposing the entire response in one shot.

Second, the Reviser stage is also sensitive to how well the prompt is crafted as well as the quality of the few shot examples included in the prompt. Again, at this stage we only used the \texttt{llama-3.3-70b-instruct} model.

Third, the quality of the contexts retrieved for each atomic unit depends on the implementation of the retriever used as well as the structure of the query string that it receives. Our implementation is limited to off-the-shelf retrievers such as the one available from LangChain and we used the atomic unit's utterance as query. It is possible to prompt an LLM to generate better quality queries as suggested in previous work \cite{song2024veriscore}. Therefore, employing a more advanced retriever will lead to better quality retrieved contexts and consequently will improve the overall performance of the proposed FactReasoner assessors.

Fourth, extracting the logical relationships between atoms and contexts as well as between the contexts themselves also depends on the quality of the prompt and the LLM. As before, for our relation model we only used open-source models such as granite-3.0-8b-instruct, llama-3.1-70b-instruct, and mixtral-8x22b-instruct with a fairly straightforward prompt. It is possible to craft better prompts that could lead to a better extraction of the relationships. Fine-tuning is another option to obtain a stronger relation model.

Finally, from a computational overhead perspective, the FR3 version requires $O(n\cdot m + m^2)$ prompts to extract the relationships between atoms and context, the FR2 version requires $O(n\cdot m)$ prompts while FR1 requires $O(k\cdot n)$ prompts, where $n$ is the number of atomic units, $m$ is the total number of non-duplicated contexts retrieved for the atoms, and $k$ is maximum number of contexts retrieved per atom. In contrast, the prompt-based factuality assessor only require $O(n)$ prompts.

\section*{Ethical Statement}
We recognize the positive and negative societal impacts of LLMs in general, including potential misuse of our work around uncertainty quantification for LLM generated output. We note that the datasets considered are public and peer reviewed, there are no human subjects involved, and as far as we know, there are no obvious harmful consequences from our work. All creators and original owners of assets have been properly credited and licenses and terms of use have been respected. We have not conducted crowd-sourcing experiments or research with human subjects.

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{ref}

\appendix

\section{Details on Graphical Models}
\label{apx:pgm}
Graphical models such as Bayesian or Markov networks provide a powerful framework for reasoning about conditional dependency structures over many variables \cite{pearl88,koller2009probabilistic}. 

A \emph{graphical model} is a tuple $\cM = \langle \bX,\bD,\bF \rangle$, where $\bX = \{X_1, \ldots, X_n\}$ is a set of variables, $\bD = \{D_1, \ldots, D_n\}$ is the set of their finite domains of values and $\bF =\{f_1, \ldots, f_m\}$ is a set of discrete positive real-valued functions. Each function $f_i$ (also called \emph{factor}) is defined on a subset of variables $\bS_i \subseteq \bX$ called its \emph{scope} and denoted by $vars(f_i)$. The model $\cM$ defines a factorized probability distribution on $\bX$: 
%
\begin{align}\label{eq:pgm}
P(\bx) = \frac{1}{Z}\prod_{j=1}^{m} f_j(\bx) ~\textrm{s.t.}~ & Z = \sum_{\bx \in \Omega(\bX)} \prod_{j=1}^{m} f_j(\bx)
\end{align}
%
\noindent where the normalization constant $Z$ is known as the \emph{partition function} and $\Omega(\bX)$ denotes the Cartesian product of the variables domains.

The function scopes of a model $\cM$ define a \emph{primal graph} whose vertices are the variables and its edges connect any two variables that appear in the scope of the same function.

A common inference task over graphical models is to compute the posterior marginal distributions over all variables. Namely, for each variable $X_i \in \bX$ and domain value $x_i \in D_i$, compute:
%
\begin{align}\label{eq:marginal}
P(x_i) &= \sum_{\bx \in \Omega(\bX)} \delta_{x_i}(\bx)\cdot P(\bx)
\end{align}
%
\noindent where $\delta_{x_i}(\bx)$ is $1$ if $X_i$ is assigned $x_i$ in $\bx$ and $0$ otherwise \cite{koller2009probabilistic}.

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{figs/fig-pgm.png}
    \caption{A graphical model with three bi-valued variables $X_1$, $X_2$ and $X_3$, and three binary functions.}
    \label{fig:pgm}
\end{figure}

\begin{example}
 Figure \ref{fig:pgm} shows a graphical model with 3 bi-valued variables $X_1$, $X_2$ and $X_3$ and 3 binary functions $f_1(X_1,X_2)$, $f_2(X_1,X_3)$ and $f_3(X_2,X_3)$. The joint probability distribution is given by $P(X_1,X_2,X_3)=\frac{1}{Z} \cdot f_1(X_1,X_2)\cdot f_2(X_1,X_3)\cdot f_3(X_2,X_3)$. In this case, the posterior marginal distribution of $X_1$ is: $P(X_1=0) = 0.46$ and $P(X_1=1) = 0.54$, respectively. %0.456140 0.543860
\end{example}

Solving Equation \ref{eq:marginal} can be done using any probabilistic inference algorithm for graphical models such as variable elimination \cite{dechter-book}, belief propagation \cite{pearl88} or variational inference \cite{liu2011}. In our implementation we used the Weighted Mini-Buckets (WMB) algorithm \cite{liu2011}. Specifically, WMB is parameterized by a so called i-bound which controls the complexity of inference. In our experiments we selected an i-bound of 6 which allowed us to solve all inference problems relatively efficiently.

\section{Details on Long-Form Factuality Assessment}
Assessing the factuality of long form text generations is a challenging problem because these kinds of generations may contain a large number of informative statements and validating each piece of information against one or more reliable sources may be time-consuming, costly and often prone to errors \cite{factscore2023emnlp,wei2024longform}.

Formally, let $y$ be the long form text generated by a large language model $\cL$ in response to a query $x$. Following prior work \cite{factscore2023emnlp,song2024veriscore}, we assume that $y$ consists of $n$ \emph{atomic units} (or \emph{atoms}) that can be either true or false, denoted by $\cA_y = \{a_1, a_2, \ldots a_n\}$. An atomic unit $a_i \in \cA_y$ is defined as a short sentence conveying one piece of information. Furthermore, given an external knowledge source $\cC$\footnote{For example, $\cC$ could be Wikipedia, the Web, or a collection of documents embedded into a vector database.}, we say that an atomic unit $a_i\in \cA_y$ is \emph{supported} by $\cC$ if there exists at least one piece of information in $\cC$ (e.g., a passage) called a \emph{context} that undebatably supports $a_i$. Otherwise, we say that the atomic unit is \emph{not supported} \cite{factscore2023emnlp,song2024veriscore}.

% {
% \color{red}
% metrics are for measuring factually or assessment. above defines factually in long-form generation.
% Some transition 1 paragraph; notations above, and metrics below. they are taken from existing works.
% }
Therefore, the \emph{factual precision} $Pr(y)$ of the response $y$ with respect to a knowledge source $\cC$ is defined as:
%
\begin{align}\label{eq:precision}
Pr(y) &= \frac{S(y)}{|\cA_y|}
\end{align}
%
\noindent where $S(y) = \sum_{i=1}^{n} \mathbb{I}[a_i \textrm{ is supported by } \cC]$ is the number of supported atomic units.
% {\color{red} $\delta$ function vs Indicator function; }
Similarly, the notion of \emph{factual recall\footnote{Measuring recall is quite challenging because it is almost impossible to come up with a definite set of atomic units that should be included in a long form response \cite{wei2024longform}} up to the $K$-th supported atomic unit} denoted by $R_K(y)$ can be defined as follows:
%
\begin{align}\label{eq:recall}
R_K(y) &= \min(\frac{S(y)}{K}, 1)
\end{align}
%

Combining Equations \ref{eq:precision} and \ref{eq:recall} yields an $F_1$ measure for factuality denoted $F1@K$ as follows:
%
\begin{align}\label{eq:f1k}
    F_1@K(y) &= \left\{
    \begin {aligned}
         & \frac{2\cdot Pr(y) \cdot R_K(y)}{Pr(y) + R_K(y)} ,& S(y) > 0 \\
         & 0 ,& S(y) = 0                  
    \end{aligned}
\right.
\end{align}

Intuitively, $F_1@K(y)$ measures the long-form factuality of a model response $y$ given the numbers of supported and not-supported atomic units in $y$. The parameter $K$ indicates the number of supported atomic units required for a response to achieve full recall \cite{wei2024longform}.

The precision and recall definitions however assume that the pieces of information in $\cC$ do not conflict or overlap with each other \cite{factscore2023emnlp}.

% {
% \color{red}
% Do we need to use 1/4 page for defining metrics, Eq. 3 to 5?,
% if it is well-known in ARR?}

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{figs/fig-atoms.png}
    \caption{An example user prompt and the corresponding long form response together with its supported (green) and not supported (red) atomic units.}
    \label{fig:flaherty}
\end{figure}

\begin{example}
    In Figure \ref{fig:flaherty} we show an example of a long form generated text for a user prompt/query. In this case, the response $y$ contains 14 atomic units $\cA_y = \{a_1, a_2, \ldots, a_{14}\}$. Furthermore, considering Wikipedia as our reliable knowledge source, we depict in green the supported atomic units, while the ones in red are not supported. The factual precision and $F_1@K$ of the response are $Pr(y)= 0.43$ and $F_1@K(y) = 0.57$ for $K=7$, respectively.
\end{example}


\section{Additional Experiments}
\label{apx:experiments}


\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{figs/expert_contradiction_logprobs_vitc_llama-3.1-70b-instruct_rits.png}
    \includegraphics[width=\linewidth]{figs/expert_entailment_logprobs_vitc_llama-3.1-70b-instruct_rits.png}
    \caption{ROC curves for the \texttt{vitc}- and \texttt{llama}-based relation models predicting contradiction and entailment.}
    \label{fig:nli-llama2}
\end{figure}

\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{figs/expert_contradiction_logprobs_llama-3.1-70b-instruct_rits.png}
    \includegraphics[width=\linewidth]{figs/expert_contradiction_vitc.png}
    \caption{ROC curves for the \texttt{llama}- (top) \texttt{vitc}-based (bottom) relation models predicting contradiction on the Expert FACTOR dataset.}
    \label{fig:nli-contr-expert}
\end{figure}
\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{figs/expert_entailment_logprobs_llama-3.1-70b-instruct_rits.png}
    \includegraphics[width=\linewidth]{figs/expert_entailment_vitc.png}
    \caption{ROC curves for the \texttt{llama}- (top) \texttt{vitc}-based (bottom) relation models predicting entailment on the Expert FACTOR dataset.}
    \label{fig:nli-entail-expert}
\end{figure}
\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{figs/news_contradiction_logprobs_llama-3.1-70b-instruct_rits.png}
    \includegraphics[width=\linewidth]{figs/news_contradiction_vitc.png}
    \caption{ROC curves for the \texttt{llama}- (top) \texttt{vitc}-based (bottom) relation models predicting contradiction on the News FACTOR dataset.}
    \label{fig:nli-contr-news}
\end{figure}
\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{figs/news_entailment_logprobs_llama-3.1-70b-instruct_rits.png}
    \includegraphics[width=\linewidth]{figs/news_entailment_vitc.png}
    \caption{ROC curves for the \texttt{llama}- (top) \texttt{vitc}-based (bottom) relation models predicting entailment on the News FACTOR dataset.}
    \label{fig:nli-entail-news}
\end{figure}

Figure \ref{fig:nli-llama2} plots the ROC curves for predicting contradiction and entailment relationships on the Expert FACTOR dataset \cite{factor2024ecacl}. We see that the \texttt{vitc}-based model predicts contradictions fairly accurately compared with the \texttt{llama}-based one, but performs rather poorly on predicting the entailment relations. 

Figures \ref{fig:nli-contr-expert} and \ref{fig:nli-entail-expert} plot the ROC curves for predicting the contradiction and entailment relationships by the \texttt{llama}- and \texttt{vitc}-based relation models on the Expert FACTOR dataset \cite{factor2024ecacl}. Figures \ref{fig:nli-contr-news} and \ref{fig:nli-entail-news} plot the ROC curves for predicting the contradiction and entailment relationships by the same relation models on the News FACTOR dataset \cite{factor2024ecacl}

In Table \ref{tab:bio-google} we show the results obtained on the same Biographies dataset but using Google Search results as contexts. We observe a similar pattern of the results compared with the previous case, namely FV and VS being more conservative than the FR assessors. However, we notice that in this case there are many more atoms labeled as supported (\#S) and consequently more false positives which is reflected in the slightly higher MAE values for all competing assessors. We believe that this is most likely caused by the slightly noisier contexts compared with the Wikipedia only based ones which eventually leads to more spurious entailment relationships than in the previous case. As before, we note that the relatively simple prompt employed by FS leads to large numbers of atoms labeled as supported.

Tables \ref{tab:bio-wikipedia2} and \ref{tab:bio-google2} contain the detailed results obtained on the labeled Biographies dataset including the standard deviations for each of the reported performance measures.

Tables \ref{tab:askh-wikipedia2}, \ref{tab:books-wikipedia}, \ref{tab:eli5-wikipedia} and \ref{tab:lfobj-wikipedia} report the detailed results obtained on the unlabeled datasets AskH, Books, ELI5 and LFObj using Wikipedia retrieved contexts. Tables \ref{tab:askh-google2}, \ref{tab:books-google}, \ref{tab:eli5-google} and \ref{tab:lfobj-google} show the detailed results obtained on the unlabeled datasets Books, ELI5 and LFObj using Google Search results based contexts. All these additional results show a similar pattern to those reported for the AskH dataset in the main paper.

\begin{table}[t!]
    \centering
    \resizebox{\linewidth}{!}{%
    \begin{tabular}{l|r|r|r|r|r|r|r|r}
       Method & \# S & \# C & \# U & Pr & $F_1$ & $F_1@K$ & MAE & $\cE$ \\
       \toprule
       \multicolumn{9}{c}{\texttt{granite-3.0-8b-instruct}}\\
       \midrule
       FS   & 24 & 6  &    & 0.76  & 0.80   & 0.73  & 0.15 &   \\
       FV   & 20 & 2  & 8  & 0.64  & 0.74   & 0.62  & 0.14 &  \\
       VS   & 21 & 1  & 8  & 0.67  & 0.74   & 0.65  & 0.14 &  \\
       FR1  & 23 & 3  & 4  & 0.73  & 0.79   & 0.70  & 0.14 & 0.08 \\
       FR2  & 24 & 5  & 0  & 0.78 & 0.80  & 0.75  & 0.19 & 0.04 \\
       FR3  & 24 & 5  & 0  & 0.78 & 0.79  & 0.74  & 0.18 & 0.04 \\
       \midrule
       \multicolumn{9}{c}{\texttt{llama-3.1-70b-instruct}}\\
       \midrule
       FS   & 23 & 7  &   & 0.73  &  0.82  & 0.71  & 0.14 &  \\
       FV   & 23 & 3  & 4  & 0.72  & 0.82   & 0.70   & 0.13 &  \\
       VS   & 23 & 1  & 6 & 0.72  & 0.81   & 0.70  & 0.13 &  \\
       FR1  & 21 & 2  & 7 & 0.66  & 0.81  & 0.64  & 0.11 & 0.06 \\
       FR2  & 24 & 2 & 3  & 0.77  & 0.83  & 0.74  & 0.16 & 0.03 \\
       FR3  & 24 & 2 & 3  & 0.77  & 0.83  & 0.74  & 0.16 & 0.03 \\
       \midrule
       \multicolumn{9}{c}{\texttt{mixtral-8x22b-instruct}}\\
       \midrule
       FS   & 24 & 6  &   & 0.75 & 0.83  & 0.72  & 0.15 &  \\
       FV   & 22 & 2  & 5  & 0.71  & 0.82  & 0.69 & 0.12 &  \\
       VS   & 23 & 1  & 5  & 0.73  & 0.81  & 0.71 & 0.13 &  \\
       FR1  & 22 & 1  & 6  & 0.71  & 0.81  & 0.69 & 0.13 & 0.05 \\
       FR2  & 25 & 1 & 3  & 0.81  & 0.82  & 0.77  & 0.19 & 0.03 \\
       FR3  & 25 & 2 & 3  & 0.80  & 0.82  & 0.77  & 0.19 & 0.03 \\

    \end{tabular}}
    \caption{Results obtained on the labeled Biographies dataset using Google Search retrieved contexts.}
    \label{tab:bio-google}
\end{table}


\begin{table}[t!]
    \centering
    \resizebox{\linewidth}{!}{%
    \begin{tabular}{l|r|r|r|r|r|r|r|r}
       Assessor & \# S & \# C & \# U & Pr & $F_1$ & $F_1@K$ & MAE & $\cE$ \\
       \toprule
       \multicolumn{9}{c}{\texttt{granite-3.0-8b-instruct}}\\
       \midrule
       FS   & 18$\pm$8 & 12$\pm$5  &     & 0.59$\pm$0.17  & 0.70$\pm$0.17  & 0.57$\pm$0.20  & 0.17$\pm$0.14 &   \\
       FV   & 14$\pm$7 & 2$\pm$1  & 14$\pm$6  & 0.45$\pm$0.19  & 0.67$\pm$0.15  & 0.44$\pm$0.21  & 0.21$\pm$0.14 &  \\
       VS   &  15$\pm$8  & 8$\pm$4  &  6$\pm$3  & 0.49$\pm$0.20  &  0.64$\pm$0.19 &  0.48$\pm$0.22  &  0.21$\pm$0.14   &  \\
       FR1  & 14$\pm$6 & 2$\pm$2 & 14$\pm$6  & 0.43$\pm$0.20 & 0.70$\pm$0.15  & 0.43$\pm$0.21 & 0.22$\pm$0.13  &  0.12$\pm$0.01 \\
       FR2  & 20$\pm$6 & 4$\pm$3 &  6$\pm$3  & {\bf 0.62$\pm$0.21} & {\bf 0.78$\pm$0.15}  & {\bf 0.61$\pm$0.23} & {\bf 0.12$\pm$0.13}  & 0.06$\pm$0.01 \\
       FR3  & 19$\pm$6 & 4$\pm$3 &  6$\pm$3  & 0.60$\pm$0.19 & 0.78$\pm$0.14  & 0.59$\pm$0.22 & 0.13$\pm$0.13  &  0.06$\pm$0.01 \\
       \midrule
       \multicolumn{9}{c}{\texttt{llama-3.1-70b-instruct}}\\
       \midrule
       FS   & 19$\pm$8 & 12$\pm$5  &     & 0.59$\pm$0.20  & 0.73$\pm$0.16  & 0.58$\pm$0.20  & 0.16$\pm$0.14 &  \\
       FV   & 15$\pm$8 & 1$\pm$1  & 14$\pm$6  & 0.47$\pm$0.20  & 0.73$\pm$0.15  & 0.47$\pm$0.22  & 0.19$\pm$0.12 &  \\
       VS   & 12$\pm$8   & 0  &  18$\pm$7 & 0.38$\pm$0.21  &  0.64$\pm$0.18 &  0.38$\pm$0.23  &  0.27$\pm$0.15 &  \\
       FR1  & 13$\pm$8 & 1$\pm$2 & 16$\pm$6  & 0.42$\pm$0.20  & 0.71$\pm$0.15  & 0.42$\pm$0.21  & 0.23$\pm$0.13 & 0.10$\pm$0.02 \\
       FR2  & 19$\pm$9 & 2$\pm$2 &  9$\pm$5  & {\bf 0.60$\pm$0.20}  & {\bf 0.83$\pm$0.13}  & {\bf 0.59$\pm$0.24}  & {\bf 0.11$\pm$0.11} & {\bf 0.06$\pm$0.02} \\
       FR3  & 19$\pm$9 & 2$\pm$2 &  9$\pm$5  & {\bf 0.60$\pm$0.20}  & {\bf 0.83$\pm$0.14}  & {\bf 0.59$\pm$0.24}  & {\bf 0.11$\pm$0.12} & {\bf 0.06$\pm$0.02} \\
       \midrule
       \multicolumn{9}{c}{\texttt{mixtral-8x22b-instruct}}\\
       \midrule
       FS   & 19$\pm$8 & 12$\pm$5 &    & 0.59$\pm$0.18  & 0.74$\pm$0.16  & 0.58$\pm$0.20  & 0.16$\pm$0.13 &  \\
       FV   & 15$\pm$7 & 1$\pm$1 & 13$\pm$5  & 0.49$\pm$0.18  & 0.72$\pm$0.14  & 0.48$\pm$0.21  & 0.19$\pm$0.12 &  \\
       VS   & 13$\pm$7  & 1$\pm$1 & 15$\pm$6  & 0.42$\pm$0.18  & 0.65$\pm$0.16 &  0.42$\pm$0.20  &  0.25$\pm$0.14    &  \\
       FR1  & 14$\pm$8 & 0$\pm$1 & 15$\pm$6 & 0.44$\pm$0.20  & 0.72$\pm$0.15  & 0.44$\pm$0.22  & 0.21$\pm$0.13  & 0.10$\pm$0.02 \\
       FR2  & 20$\pm$9 & 1$\pm$1 &  8$\pm$5 & {\bf 0.63$\pm$0.20}  & {\bf 0.83$\pm$0.14}  & {\bf 0.62$\pm$0.24}  & {\bf 0.11$\pm$0.11}  & {\bf 0.07$\pm$0.01} \\
       FR3  & 20$\pm$9 & 1$\pm$1 &  9$\pm$5 & {\bf 0.64$\pm$0.21}  & {\bf 0.83$\pm$0.14}  & {\bf 0.62$\pm$0.24}  & {\bf 0.11$\pm$0.12}  & {\bf 0.07$\pm$0.01} \\

    \end{tabular}}
    \caption{Results obtained on the labeled Biographies dataset using Wikipedia retrieved contexts.}
    \label{tab:bio-wikipedia2}
\end{table}

\begin{table}[t!]
    \centering
    \resizebox{\linewidth}{!}{%
    \begin{tabular}{l|r|r|r|r|r|r|r|r}
       Method & \# S & \# C & \# U & Pr & $F_1$ & $F_1@K$ & MAE & $\cE$ \\
       \toprule
       \multicolumn{9}{c}{\texttt{granite-3.0-8b-instruct}}\\
       \midrule
       FS   & 24$\pm$10 & 6$\pm$5  &   & 0.76$\pm$0.20  & 0.80$\pm$0.17   & 0.73$\pm$0.23  & 0.15$\pm$0.14 &   \\
       FV   & 20$\pm$8 & 2$\pm$2  & 8$\pm$4  & 0.64$\pm$0.18  & 0.74$\pm$0.16   & 0.62$\pm$0.21  & 0.14$\pm$0.12 &  \\
       VS   & 21$\pm$9 & 1$\pm$1  & 8$\pm$4  & 0.67$\pm$0.18  & 0.74$\pm$0.17   & 0.65$\pm$0.21  & 0.14$\pm$0.12 &  \\
       FR1  & 23$\pm$9  &  3$\pm$2 & 4$\pm$3  & 0.73$\pm$0.19  & 0.79$\pm$0.15  & 0.70$\pm$0.22  & 0.14$\pm$0.14 & 0.08$\pm$0.01 \\
       FR2  & 24$\pm$10 & 5$\pm$5 & 0$\pm$1  & 0.78$\pm$0.20 & 0.80$\pm$0.18  & 0.75$\pm$0.23  & 0.19$\pm$0.16 & 0.04$\pm$0.01 \\
       FR3  & 24$\pm$10 & 5$\pm$6 & 0$\pm$1  & 0.78$\pm$0.21 & 0.79$\pm$0.18  & 0.74$\pm$0.24  & 0.18$\pm$0.16 & 0.04$\pm$0.01 \\
       \midrule
       \multicolumn{9}{c}{\texttt{llama-3.1-70b-instruct}}\\
       \midrule
       FS   & 23$\pm$10 & 7$\pm$5  &   & 0.73$\pm$0.20  &  0.82$\pm$0.15  & 0.71$\pm$0.23  & 0.14$\pm$0.13 &  \\
       FV   & 23$\pm$10 & 3$\pm$2 & 4$\pm$3  & 0.72$\pm$0.20  & 0.82$\pm$0.16   & 0.70$\pm$0.23  & 0.13$\pm$0.12 &  \\
       VS   & 23$\pm$10 & 1$\pm$1  & 6$\pm$5 & 0.72$\pm$0.21  & 0.81$\pm$0.15   & 0.70$\pm$0.24  & 0.13$\pm$0.12 &  \\
       FR1  & 21$\pm$9 & 2$\pm$1 & 7$\pm$4  & 0.66$\pm$0.22  & 0.81$\pm$0.15  & 0.64$\pm$0.22  & 0.11$\pm$0.12 & 0.06$\pm$0.01 \\
       FR2  & 24$\pm$10 & 2$\pm$2 & 3$\pm$3  & 0.77$\pm$0.20  & 0.83$\pm$0.17  & 0.74$\pm$0.23  & 0.16$\pm$0.14 & 0.03$\pm$0.01 \\
       FR3  & 24$\pm$10 & 2$\pm$2 & 3$\pm$3  & 0.77$\pm$0.20  & 0.83$\pm$0.17  & 0.74$\pm$0.23  & 0.16$\pm$0.14 & 0.03$\pm$0.01 \\
       \midrule
       \multicolumn{9}{c}{\texttt{mixtral-8x22b-instruct}}\\
       \midrule
       FS   & 24$\pm$10 & 6$\pm$5  &   & 0.75$\pm$0.20  & 0.83$\pm$0.16  & 0.72$\pm$0.23  & 0.15$\pm$0.14 &  \\
       FV   & 22$\pm$9 & 2$\pm$2  & 5$\pm$4  & 0.71$\pm$0.20  & 0.82$\pm$0.15  & 0.69$\pm$0.23  & 0.12$\pm$0.12 &  \\
       VS   & 23$\pm$10 & 1$\pm$1  & 5$\pm$4  & 0.73$\pm$0.21  & 0.81$\pm$0.16  & 0.71$\pm$0.24  & 0.13$\pm$0.13 &  \\
       FR1  & 22$\pm$9 & 1$\pm$1 & 6$\pm$4  & 0.71$\pm$0.20  & 0.81$\pm$0.15  & 0.69$\pm$0.23  & 0.13$\pm$0.13 & 0.05$\pm$0.01 \\
       FR2  & 25$\pm$10 & 1$\pm$2 & 3$\pm$3  & 0.81$\pm$0.18  & 0.82$\pm$0.17  & 0.77$\pm$0.22  & 0.19$\pm$0.16 & 0.03$\pm$0.01 \\
       FR3  & 25$\pm$10 & 2$\pm$4 & 3$\pm$3  & 0.80$\pm$0.19  & 0.82$\pm$0.17  & 0.77$\pm$0.22  & 0.19$\pm$0.17 & 0.03$\pm$0.01 \\

    \end{tabular}}
    \caption{Results obtained on the labeled Biographies dataset using Google Search retrieved contexts.}
    \label{tab:bio-google2}
\end{table}


%%%% AskHistorians with Wikipedia
\begin{table}[t!]
    \centering
    \resizebox{\linewidth}{!}{%
    \begin{tabular}{l|r|r|r|r|r|r}
       Assessor & \# S & \# C & \# U & Pr $\uparrow$ & $F_1@K$ $\uparrow$ & $\cE$ $\downarrow$ \\
       \toprule
       \multicolumn{7}{c}{\texttt{granite-3.0-8b-instruct}}\\
       \midrule
       FS   & 17$\pm$6 & 5$\pm$3  &   & 0.76$\pm$0.15  & 0.74$\pm$0.17  &    \\
       FB   &  8$\pm$4 & 0$\pm$1  & 13$\pm$4  & 0.35$\pm$0.15  & 0.36$\pm$0.17  &    \\
       FV   & 12$\pm$5 & 4$\pm$2  &  5$\pm$2 & 0.55$\pm$0.16  & 0.55$\pm$0.18   &    \\
       FR1 (ours)  &  4$\pm$3 & 1$\pm$1 & 16$\pm$4 & 0.19$\pm$0.14  & 0.19$\pm$0.13  & 0.14$\pm$0.01  \\
       FR2 (ours) & 10$\pm$6 & 9$\pm$5 & 2$\pm$2  & 0.46$\pm$0.22  & 0.47$\pm$0.24  & 0.09$\pm$0.03  \\
       FR3 (ours) & 11$\pm$6 & 8$\pm$4 & 2$\pm$2  & 0.47$\pm$0.22  & 0.48$\pm$0.24  & 0.10$\pm$0.03   \\
       \midrule
       \multicolumn{7}{c}{\texttt{llama-3.1-70b-instruct}}\\
       \midrule
       FS   &  15$\pm$5  & 7$\pm$3  &  & 0.69$\pm$0.15  & 0.68$\pm$0.16  &    \\
       FB   &   8$\pm$5 &  0 & 13$\pm$4  & 0.37$\pm$0.19  & 0.38$\pm$0.21   &  \\
       FV   &   5$\pm$4 &  0 & 16$\pm$5  & 0.25$\pm$0.16  & 0.25$\pm$0.18   &  \\
       FR1 (ours) &  5$\pm$4 & 0  & 17$\pm$4  & 0.21$\pm$0.16  & 0.22$\pm$0.18  & 0.13$\pm$0.02 \\
       FR2 (ours) & 10$\pm$7 & 1$\pm$1  & 10$\pm$5  & 0.45$\pm$0.26  & 0.46$\pm$0.28  & 0.09$\pm$0.04 \\
       FR3 (ours)  & 10$\pm$7 & 1$\pm$1  & 10$\pm$5  & 0.44$\pm$0.25  & 0.45$\pm$0.27  & 0.09$\pm$0.04 \\
       \midrule
       \multicolumn{7}{c}{\texttt{mixtral-8x22b-instruct}}\\
       \midrule
       FS   & 16$\pm$5  & 6$\pm$3  &   &  0.71$\pm$0.15  & 0.70$\pm$0.16  &  \\
       FB   &  9$\pm$5 & 0  & 12$\pm$4  & 0.43$\pm$0.17  & 0.43$\pm$0.19  &  \\
       FV   &  7$\pm$4 & 0  & 14$\pm$5  & 0.34$\pm$0.17  & 0.34$\pm$0.19  &  \\
       FR1 (ours) &  5$\pm$4 & 0  & 17$\pm$4  & 0.22$\pm$0.18  & 0.23$\pm$0.20  & 0.12$\pm$0.02 \\
       FR2 (ours) & 11$\pm$5 & 0  & 11$\pm$5  & 0.46$\pm$0.28  & 0.47$\pm$0.30  & 0.09$\pm$0.04 \\
       FR3 (ours) & 11$\pm$8 & 0  & 11$\pm$5  & 0.46$\pm$0.30  & 0.47$\pm$0.30  & 0.09$\pm$0.04 \\

    \end{tabular}}
    \caption{Results obtained on the unlabeled AskH dataset using Wikipedia retrieved contexts.}
    \label{tab:askh-wikipedia2}
\end{table}


%%%% AskHistorians with Google Search
\begin{table}[t!]
    \centering
    \resizebox{\linewidth}{!}{%
    \begin{tabular}{l|r|r|r|r|r|r}
       Assessor & \# S & \# C & \# U & Pr $\uparrow$ & $F_1@K$ $\uparrow$ & $\cE$ $\downarrow$ \\
       \toprule
       \multicolumn{7}{c}{\texttt{granite-3.0-8b-instruct}}\\
       \midrule
       FS   & 18$\pm$6  & 3$\pm$2  &   & 0.82$\pm$0.13  & 0.81$\pm$0.15  &     \\
       FV   &  14$\pm$5 & 1$\pm$1  & 7$\pm$3  & 0.62$\pm$0.16  & 0.62$\pm$0.19   &    \\
       VS   &  14$\pm$5 & 3$\pm$2  & 3$\pm$2  & 0.65$\pm$0.15  & 0.65$\pm$0.15   &    \\
       FR1 (ours)  & 13$\pm$5 & 4$\pm$2  & 4$\pm$2  & 0.60$\pm$0.17  & 0.60$\pm$0.20  &  0.08$\pm$0.02  \\
       FR2 (ours) & 14$\pm$8 & 7$\pm$5  & 0  & 0.63$\pm$0.27  & 0.62$\pm$0.28  &  0.04$\pm$0.03  \\
       FR3 (ours) & 15$\pm$7 & 7$\pm$5  & 0  & 0.67$\pm$0.24  & 0.66$\pm$0.25  &  0.06$\pm$0.03  \\
       \midrule
       \multicolumn{7}{c}{\texttt{llama-3.1-70b-instruct}}\\
       \midrule
       FS   & 18$\pm$5 & 3$\pm$2  &   & 0.82$\pm$0.12  & 0.80$\pm$0.14  &  \\
       FV   & 16$\pm$6 & 1$\pm$1  & 5$\pm$3  & 0.71$\pm$0.18  & 0.70$\pm$0.20   &  \\
       VS   & 15$\pm$6 & 0  & 7$\pm$3  & 0.66$\pm$0.18  & 0.65$\pm$0.20   &  \\
       FR1 (ours) & 12$\pm$6 & 1$\pm$1  & 8$\pm$4  & 0.53$\pm$0.19  & 0.54$\pm$0.22  & 0.08$\pm$0.03 \\
       FR2 (ours) & 17$\pm$6 & 1$\pm$1  & 3$\pm$3  & 0.76$\pm$0.18  & 0.74$\pm$0.20  & 0.04$\pm$0.03 \\
       FR3 (ours) & 17$\pm$6 & 2$\pm$1  & 3$\pm$3  & 0.75$\pm$0.18  & 0.74$\pm$0.20  & 0.04$\pm$0.03 \\
       \midrule
       \multicolumn{7}{c}{\texttt{mixtral-8x22b-instruct}}\\
       \midrule
       FS   & 18$\pm$6 & 3$\pm$2  &   & 0.82$\pm$0.13   & 0.80$\pm$0.15  &  \\
       FV   & 15$\pm$6 & 0$\pm$1  & 6$\pm$3  &  0.67$\pm$0.18  & 0.67$\pm$0.21  &  \\
       VS   & 15$\pm$6 & 0$\pm$1  & 6$\pm$3  &  0.68$\pm$0.18  & 0.67$\pm$0.20  &  \\
       FR1 (ours) & 14$\pm$6 & 0  & 8$\pm$4  & 0.60$\pm$0.20  & 0.60$\pm$0.22  & 0.07$\pm$0.03 \\
       FR2 (ours) & 18$\pm$7 & 0  & 3$\pm$3  & 0.80$\pm$0.17  & 0.79$\pm$0.19  & 0.04$\pm$0.03 \\
       FR3 (ours) & 18$\pm$7 & 0  & 3$\pm$3  & 0.80$\pm$0.17  & 0.79$\pm$0.19  & 0.04$\pm$0.03 \\

    \end{tabular}}
    \caption{Results obtained on the unlabeled AskH dataset using Google Search retrieved contexts.}
    \label{tab:askh-google2}
\end{table}


%%%% Books with Wikipedia
\begin{table}[t!]
    \centering
    \resizebox{\linewidth}{!}{%
    \begin{tabular}{l|r|r|r|r|r|r}
       Method & \# S & \# C & \# U & Pr & $F_1@K$ & $\cE$ \\
       \toprule
       \multicolumn{7}{c}{\texttt{granite-3.0-8b-instruct}}\\
       \midrule
       FS   & 17$\pm$6 & 6$\pm$4  &   & 0.72$\pm$0.19  & 0.71$\pm$20   &    \\
       FV   & 9$\pm$5 & 0  & 13$\pm$5  & 0.38$\pm$0.18  & 0.38$\pm$0.18   &    \\
       VS   & 15$\pm$6 & 3$\pm$2  & 4$\pm$2  & 0.63$\pm$0.16  & 0.63$\pm$0.18  &    \\
       FR1  & 8$\pm$6 & 0$\pm$0  & 14$\pm$6  & 0.34$\pm$0.23  & 0.34$\pm$0.24  & 0.11$\pm$0.03   \\
       FR2  & 15$\pm$9 & 0$\pm$1  & 7$\pm$6  & 0.64$\pm$0.29  & 0.63$\pm$0.29  & 0.06$\pm$0.04   \\
       FR3  & 13$\pm$8 & 7$\pm$6  & 2$\pm$3  & 0.55$\pm$0.27  & 0.54$\pm$0.28  & 0.09$\pm$0.03   \\
       \midrule
       \multicolumn{7}{c}{\texttt{llama-3.1-70b-instruct}}\\
       \midrule
       FS   & 16$\pm$6 & 7$\pm$4  & & 0.69$\pm$0.18  & 0.68$\pm$0.19   &  \\
       FV   & 10$\pm$6 & 0  & 12$\pm$5  & 0.43$\pm$0.22  & 0.43$\pm$0.23   &  \\
       VS   &  5$\pm$4 & 0  & 17$\pm$4  & 0.24$\pm$0.18  & 0.24$\pm$0.18   &  \\
       FR1  & 5$\pm$5 & 0$\pm$0  & 17$\pm$6  & 0.24$\pm$0.18  & 0.24$\pm$0.19  & 0.12$\pm$0.02 \\
       FR2  & 11$\pm$8 & 1$\pm$1  & 10$\pm$6  & 0.49$\pm$0.29  & 0.49$\pm$0.29  & 0.09$\pm$0.04 \\
       FR3  & 12$\pm$8 & 2$\pm$2  & 9$\pm$6  & 0.49$\pm$0.28  & 0.50$\pm$0.29  & 0.09$\pm$0.04 \\
       \midrule
       \multicolumn{7}{c}{\texttt{mixtral-8x22b-instruct}}\\
       \midrule
       FS   & 17$\pm$6 & 6$\pm$4  &   &  0.72$\pm$0.19  & 0.71$\pm$0.20  &  \\
       FV   & 11$\pm$6 & 0  & 11$\pm$5  & 0.50$\pm$0.21   & 0.50$\pm$0.21  &  \\
       VS   & 10$\pm$6 & 0  & 12$\pm$6  & 0.43$\pm$0.22   & 0.43$\pm$0.22  &  \\
       FR1  & 6$\pm$5 & 0$\pm$0  & 17$\pm$6  & 0.25$\pm$0.20  & 0.25$\pm$0.21  & 0.12$\pm$0.03 \\
       FR2  & 12$\pm$8 & 0$\pm$0  & 10$\pm$6  & 0.51$\pm$0.29  & 0.51$\pm$0.30  & 0.08$\pm$0.04 \\
       FR3  & 12$\pm$8 & 0$\pm$0  & 10$\pm$6  & 0.51$\pm$0.30  & 0.51$\pm$0.30  & 0.08$\pm$0.04 \\

    \end{tabular}}
    \caption{Results obtained on the unlabeled Books dataset using Wikipedia retrieved contexts.}
    \label{tab:books-wikipedia}
\end{table}

%%%% Books with Google Search
\begin{table}[t!]
    \centering
    \resizebox{\linewidth}{!}{%
    \begin{tabular}{l|r|r|r|r|r|r}
       Method & \# S & \# C & \# U & Pr & $F_1@K$ & $\cE$ \\
       \toprule
       \multicolumn{7}{c}{\texttt{granite-3.0-8b-instruct}}\\
       \midrule
       FS   & 20$\pm$7 & 2$\pm$2  &   & 0.87$\pm$0.13  & 0.84$\pm$0.15   &    \\
       FV   & 16$\pm$6 & 0$\pm$1  & 6$\pm$3  & 0.71$\pm$0.17  & 0.70$\pm$0.18   &    \\
       VS   & 18$\pm$7 & 2$\pm$2  & 3$\pm$2  & 0.76$\pm$0.17  & 0.75$\pm$0.19   &    \\
       FR1  & 18$\pm$8 & 0$\pm$1  & 3$\pm$3  & 0.79$\pm$0.19  & 0.77$\pm$0.20  &  0.04$\pm$0.03  \\
       FR2  & 21$\pm$7 & 1$\pm$1  & 0$\pm$1  & 0.90$\pm$0.14  & 0.86$\pm$0.15  &  0.02$\pm$0.02  \\
       FR3  & 17$\pm$8 & 5$\pm$5  & 0  & 0.74$\pm$0.27  & 0.72$\pm$0.27  &  0.04$\pm$0.03  \\
       \midrule
       \multicolumn{7}{c}{\texttt{llama-3.1-70b-instruct}}\\
       \midrule
       FS   & 20$\pm$7 & 3$\pm$3  &   & 0.84$\pm$0.15  &  0.82$\pm$0.17  &  \\
       FV   & 18$\pm$8 & 0$\pm$1  & 4$\pm$4  & 0.78$\pm$0.20  & 0.76$\pm$0.21   &  \\
       VS   & 17$\pm$8 & 0  & 5$\pm$5  & 0.72$\pm$0.23  & 0.71$\pm$0.23   &  \\
       FR1  & 14$\pm$7 & 1$\pm$1  & 7$\pm$5  & 0.62$\pm$0.23  & 0.62$\pm$0.24  & 0.07$\pm$0.03 \\
       FR2  & 19$\pm$8 & 1$\pm$1  & 3$\pm$3  & 0.80$\pm$0.21  & 0.78$\pm$0.21  & 0.04$\pm$0.03 \\
       FR3  & 18$\pm$7 & 2$\pm$6  & 2$\pm$2  & 0.80$\pm$0.20  & 0.78$\pm$0.21  & 0.04$\pm$0.03 \\
       \midrule
       \multicolumn{7}{c}{\texttt{mixtral-8x22b-instruct}}\\
       \midrule
       FS   & 20$\pm$7 & 3$\pm$3  &   & 0.84$\pm$0.16 & 0.82$\pm$0.18  &  \\
       FV   & 18$\pm$7 & 0  & 4$\pm$4  & 0.76$\pm$0.20   & 0.74$\pm$0.21  &  \\
       VS   & 18$\pm$8 & 0  & 4$\pm$4  & 0.79$\pm$0.20   & 0.77$\pm$0.21  &  \\
       FR1  & 16$\pm$7 & 0$\pm$0  & 6$\pm$4  & 0.69$\pm$0.22  & 0.68$\pm$0.23  & 0.06$\pm$0.03 \\
       FR2  & 20$\pm$7 & 0$\pm$0  & 2$\pm$3  & 0.86$\pm$0.17  & 0.83$\pm$0.18  & 0.03$\pm$0.03 \\
       FR3  & 20$\pm$7 & 0$\pm$0  & 2$\pm$3  & 0.86$\pm$0.17  & 0.83$\pm$0.18  & 0.03$\pm$0.03 \\

    \end{tabular}}
    \caption{Results obtained on the unlabeled Books dataset using Google Search retrieved contexts.}
    \label{tab:books-google}
\end{table}

%%%% ELI5 with Wikipedia
\begin{table}[t!]
    \centering
    \resizebox{\linewidth}{!}{%
    \begin{tabular}{l|r|r|r|r|r|r}
       Method & \# S & \# C & \# U & Pr & $F_1@K$ & $\cE$ \\
       \toprule
       \multicolumn{7}{c}{\texttt{granite-3.0-8b-instruct}}\\
       \midrule
       FS   & 17$\pm$5 & 4$\pm$3  &   & 0.77$\pm$0.15  & 0.77$\pm$0.17   &    \\
       FV   &  8$\pm$3 & 0  & 12$\pm$4 & 0.39$\pm$0.15 & 0.40$\pm$0.16   &    \\
       VS   & 13$\pm$5 & 4$\pm$2  & 4$\pm$2  & 0.59$\pm$0.17  & 0.60$\pm$0.18   &    \\
       FR1  & 5$\pm$4 & 1$\pm$1  & 15$\pm$4  & 0.23$\pm$0.15  & 0.24$\pm$0.16  &  0.13$\pm$0.01  \\
       FR2  & 14$\pm$6 & 4$\pm$3  & 3$\pm$2  & 0.63$\pm$0.22  & 0.63$\pm$0.24  &  0.08$\pm$0.03  \\
       FR3  & 14$\pm$6 & 4$\pm$3  & 3$\pm$2  & 0.64$\pm$0.21  & 0.64$\pm$0.23  &  0.08$\pm$0.03  \\
       \midrule
       \multicolumn{7}{c}{\texttt{llama-3.1-70b-instruct}}\\
       \midrule
       FS   & 16$\pm$5 & 5$\pm$3  &   & 0.74$\pm$0.14  & 0.74$\pm$0.16  &  \\
       FV   & 10$\pm$5 & 0  & 10$\pm$4  & 0.47$\pm$0.21  &  0.47$\pm$0.22  &  \\
       VS   &  6$\pm$4 & 0  & 15$\pm$5  & 0.29$\pm$0.18  &  0.30$\pm$0.19  &  \\
       FR1  & 5$\pm$4 & 0  & 15$\pm$4  & 0.25$\pm$0.19 & 0.26$\pm$0.20  & 0.12$\pm$0.02 \\
       FR2  & 12$\pm$7 & 1$\pm$1  & 8$\pm$5  & 0.54$\pm$0.28  & 0.55$\pm$0.28  & 0.08$\pm$0.04 \\
       FR3  & 12$\pm$7 & 1$\pm$1  & 8$\pm$5  & 0.54$\pm$0.27  & 0.55$\pm$0.28  & 0.08$\pm$0.04 \\
       \midrule
       \multicolumn{7}{c}{\texttt{mixtral-8x22b-instruct}}\\
       \midrule
       FS   & 17$\pm$5 & 4$\pm$3  &   &  0.78$\pm$0.14  & 0.77$\pm$0.15  &  \\
       FV   & 12$\pm$5  & 0  & 9$\pm$4  & 0.55$\pm$0.18  & 0.55$\pm$0.19  &  \\
       VS   & 9$\pm$5 & 0  & 11$\pm$4  &  0.44$\pm$0.19  & 0.44$\pm$0.21  &  \\
       FR1  & 6$\pm$5 & 0  & 15$\pm$4  & 0.27$\pm$0.20  & 0.28$\pm$0.21  & 0.12$\pm$0.03 \\
       FR2  & 12$\pm$7 & 0  & 8$\pm$6  & 0.55$\pm$0.29  & 0.56$\pm$0.30  & 0.08$\pm$0.04 \\
       FR3  & 12$\pm$7 & 0  & 9$\pm$6  & 0.55$\pm$0.31  & 0.56$\pm$0.31  & 0.08$\pm$0.04 \\

    \end{tabular}}
    \caption{Results obtained on the unlabeled ELI5 dataset using Wikipedia retrieved contexts.}
    \label{tab:eli5-wikipedia}
\end{table}

%%%% ELI5 with Google Search
\begin{table}[t!]
    \centering
    \resizebox{\linewidth}{!}{%
    \begin{tabular}{l|r|r|r|r|r|r}
       Method & \# S & \# C & \# U & Pr & $F_1@K$ & $\cE$ \\
       \toprule
       \multicolumn{7}{c}{\texttt{granite-3.0-8b-instruct}}\\
       \midrule
       FS   & 18$\pm$5 & 3$\pm$2  &   & 0.85$\pm$0.11  & 0.84$\pm$0.13   &    \\
       FV   & 15$\pm$5 & 0$\pm$1  & 5$\pm$2  & 0.69$\pm$0.14  & 0.70$\pm$0.16   &    \\
       VS   & 16$\pm$5 & 2$\pm$2  & 3$\pm$1  & 0.71$\pm$0.14  & 0.72$\pm$0.17   &    \\
       FR1  & 14$\pm$5 & 3$\pm$2  &  3$\pm$2 & 0.66$\pm$0.17  & 0.67$\pm$0.19  & 0.08$\pm$0.02   \\
       FR2  & 18$\pm$6 & 3$\pm$4  & 0  & 0.82$\pm$0.21  & 0.80$\pm$0.21  & 0.03$\pm$0.02   \\
       FR3  & 16$\pm$6 & 3$\pm$3  & 0  & 0.83$\pm$0.18  & 0.82$\pm$0.18  & 0.03$\pm$0.03   \\
       \midrule
       \multicolumn{7}{c}{\texttt{llama-3.1-70b-instruct}}\\
       \midrule
       FS   & 19$\pm$5 & 3$\pm$2  &   & 0.86$\pm$0.12  & 0.84$\pm$0.13   &  \\
       FV   & 18$\pm$5 & 1$\pm$1  & 3$\pm$2  & 0.81$\pm$0.16  & 0.80$\pm$0.17   &  \\
       VS   & 17$\pm$5 & 0  & 4$\pm$3  & 0.78$\pm$0.16  & 0.77$\pm$0.17  &  \\
       FR1  & 14$\pm$6 & 1$\pm$1  & 6$\pm$4  & 0.65$\pm$0.20  & 0.66$\pm$0.21  & 0.07$\pm$0.03 \\
       FR2  & 19$\pm$5 & 1$\pm$1  & 1$\pm$1  & 0.86$\pm$0.14  & 0.85$\pm$0.16  & 0.03$\pm$0.03 \\
       FR3  & 19$\pm$6 & 1$\pm$1  & 1$\pm$1  & 0.86$\pm$0.15  & 0.84$\pm$0.16  & 0.03$\pm$0.03 \\
       \midrule
       \multicolumn{7}{c}{\texttt{mixtral-8x22b-instruct}}\\
       \midrule
       FS   & 19$\pm$5 & 2$\pm$2  &   & 0.87$\pm$0.11   & 0.86$\pm$0.13  &  \\
       FV   & 17$\pm$5 & 0  & 3$\pm$2  & 0.79$\pm$0.15   & 0.79$\pm$0.17  &  \\
       VS   & 17$\pm$5 & 0$\pm$1  & 3$\pm$2  & 0.79$\pm$0.15   & 0.78$\pm$0.17  &  \\
       FR1  & 16$\pm$5 & 0  & 5$\pm$3  & 0.74$\pm$0.18  & 0.74$\pm$0.19  & 0.05$\pm$0.03 \\
       FR2  & 20$\pm$5 & 0  & 1$\pm$2  & 0.90$\pm$0.12  & 0.88$\pm$0.13  & 0.02$\pm$0.02 \\
       FR3  & 20$\pm$5 & 0  & 1$\pm$2  & 0.90$\pm$0.12  & 0.88$\pm$0.13  & 0.02$\pm$0.02 \\

    \end{tabular}}
    \caption{Results obtained on the unlabeled ELI5 dataset using Google Search retrieved contexts.}
    \label{tab:eli5-google}
\end{table}

%%%% LFObj with Wikipedia
\begin{table}[t!]
    \centering
    \resizebox{\linewidth}{!}{%
    \begin{tabular}{l|r|r|r|r|r|r}
       Method & \# S & \# C & \# U & Pr & $F_1@K$ & $\cE$ \\
       \toprule
       \multicolumn{7}{c}{\texttt{granite-3.0-8b-instruct}}\\
       \midrule
       FS   & 22$\pm$9 & 4$\pm$2  &   & 0.83$\pm$0.10  & 0.82$\pm$0.12   &    \\
       FV   & 13$\pm$6 & 0$\pm$1  & 12$\pm$5  & 0.50$\pm$0.15  & 0.50$\pm$0.16   &    \\
       VS   & 18$\pm$8 & 4$\pm$3  & 4$\pm$2 & 0.69$\pm$0.14  & 0.69$\pm$0.16   &    \\
       FR1  & 12$\pm$8 & 0$\pm$0  & 13$\pm$7  & 0.46$\pm$0.23  & 0.47$\pm$0.24  & 0.09$\pm$0.03   \\
       FR2  & 20$\pm$11 & 0$\pm$1  & 4$\pm$6  & 0.79$\pm$0.24  & 0.78$\pm$0.25  & 0.04$\pm$0.04   \\
       FR3  & 15$\pm$11 & 8$\pm$6  & 2$\pm$6  & 0.58$\pm$0.28  & 0.58$\pm$0.28  & 0.08$\pm$0.04   \\
       \midrule
       \multicolumn{7}{c}{\texttt{llama-3.1-70b-instruct}}\\
       \midrule
       FS   & 18$\pm$9 & 7$\pm$4  &   & 0.71$\pm$0.16  & 0.71$\pm$0.17   &  \\
       FV   & 14$\pm$9 & 0  & 11$\pm$6  & 0.53$\pm$0.21  & 0.54$\pm$0.21   &  \\
       VS   & 10$\pm$7 & 0  & 15$\pm$7 & 0.41$\pm$0.21  & 0.41$\pm$0.22 &  \\
       FR1  & 10$\pm$8 & 0$\pm$1  & 15$\pm$6  & 0.39$\pm$0.21  & 0.39$\pm$0.22  & 0.11$\pm$0.02 \\
       FR2  & 18$\pm$10 & 1$\pm$1  & 5$\pm$6  & 0.70$\pm$0.26  & 0.70$\pm$0.26  & 0.06$\pm$0.04 \\
       FR3  & 18$\pm$10 & 1$\pm$1  & 5$\pm$6  & 0.71$\pm$0.26  & 0.70$\pm$0.26  & 0.06$\pm$0.04 \\
       \midrule
       \multicolumn{7}{c}{\texttt{mixtral-8x22b-instruct}}\\
       \midrule
       FS   & 20$\pm$9 & 6$\pm$4  &   & 0.76$\pm$0.16   & 0.75$\pm$0.17  &  \\
       FV   & 15$\pm$8 & 0  & 10$\pm$5  &  0.59$\pm$0.18  & 0.59$\pm$0.18  &  \\
       VS   & 15$\pm$8 & 0 &  10$\pm$5 &  0.57$\pm$0.19  & 0.57$\pm$0.20  &  \\
       FR1  & 11$\pm$8 & 0$\pm$0  & 14$\pm$7  & 0.41$\pm$0.22  & 0.42$\pm$0.23  & 0.10$\pm$0.03 \\
       FR2  & 19$\pm$10 & 0$\pm$0  & 6$\pm$6  & 0.74$\pm$0.26  & 0.74$\pm$0.26  & 0.05$\pm$0.04 \\
       FR3  & 19$\pm$10 & 0$\pm$0  & 6$\pm$7  & 0.74$\pm$0.26  & 0.74$\pm$0.26  & 0.05$\pm$0.04 \\

    \end{tabular}}
    \caption{Results obtained on the unlabeled LFObj dataset using Wikipedia retrieved contexts.}
    \label{tab:lfobj-wikipedia}
\end{table}

%%%% LFObj with Google Search
\begin{table}[t!]
    \centering
    \resizebox{\linewidth}{!}{%
    \begin{tabular}{l|r|r|r|r|r|r}
       Method & \# S & \# C & \# U & Pr & $F_1@K$ & $\cE$ \\
       \toprule
       \multicolumn{7}{c}{\texttt{granite-3.0-8b-instruct}}\\
       \midrule
       FS   & 24$\pm$9 & 1$\pm$1  &   & 0.93$\pm$0.07  & 0.91$\pm$0.09   &    \\
       FV   & 20$\pm$8 & 0  & 4$\pm$2  & 0.79$\pm$0.10  & 0.79$\pm$0.12   &    \\
       VS   & 18$\pm$8 & 3$\pm$2  & 4$\pm$2  & 0.68$\pm$0.14  & 0.69$\pm$0.15   &    \\
       FR1  & 24$\pm$9 & 0$\pm$0  & 1$\pm$2  & 0.93$\pm$0.09  & 0.91$\pm$0.10  & 0.02$\pm$0.02   \\
       FR2  & 25$\pm$5 & 1$\pm$9  & 0$\pm$0  & 0.97$\pm$0.07  & 0.94$\pm$0.09  & 0.00$\pm$0.01   \\
       FR3  & 23$\pm$7 & 4$\pm$16 & 0  & 0.89$\pm$0.22  & 0.86$\pm$0.22  & 0.02$\pm$0.02   \\
       \midrule
       \multicolumn{7}{c}{\texttt{llama-3.1-70b-instruct}}\\
       \midrule
       FS   & 23$\pm$9 & 2$\pm$2  &   & 0.91$\pm$0.09  & 0.89$\pm$0.10   &  \\
       FV   & 23$\pm$9 & 0$\pm$1  & 1$\pm$2  & 0.91$\pm$0.10  & 0.89$\pm$0.12   &  \\
       VS   & 10$\pm$7 & 0  & 15$\pm$7  & 0.40$\pm$0.21  & 0.40$\pm$0.22   &  \\
       FR1  & 22$\pm$9 & 0$\pm$1  & 2$\pm$3  & 0.85$\pm$0.13  & 0.84$\pm$0.14  & 0.03$\pm$0.02 \\
       FR2  & 24$\pm$5 & 1$\pm$9  &  0$\pm$1  & 0.94$\pm$0.10  & 0.92$\pm$0.11  & 0.01$\pm$0.01 \\
       FR3  & 24$\pm$5 & 1$\pm$10  & 0  & 0.93$\pm$0.13  & 0.91$\pm$0.14  & 0.01$\pm$0.01 \\
       \midrule
       \multicolumn{7}{c}{\texttt{mixtral-8x22b-instruct}}\\
       \midrule
       FS   & 24$\pm$9 & 1$\pm$2  &   & 0.93$\pm$0.08   & 0.91$\pm$0.10  &  \\
       FV   & 23$\pm$9 & 0$\pm$1  & 2$\pm$2  & 0.90$\pm$0.10   & 0.88$\pm$0.11  &  \\
       VS   & 23$\pm$9 & 0  & 2$\pm$4  &  0.88$\pm$0.16  & 0.86$\pm$0.16  &  \\
       FR1  & 23$\pm$9 & 0$\pm$0  & 2$\pm$2  & 0.90$\pm$0.10  & 0.88$\pm$0.12  & 0.03$\pm$0.02 \\
       FR2  & 24$\pm$5 & 0$\pm$9  & 0$\pm$1  & 0.96$\pm$0.09  & 0.93$\pm$0.10  & 0.01$\pm$0.01 \\
       FR3  & 24$\pm$5 & 0$\pm$9  & 0$\pm$1  & 0.96$\pm$0.09  & 0.94$\pm$0.10  & 0.01$\pm$0.01 \\

    \end{tabular}}
    \caption{Results obtained on the LFObj dataset using Google Search retrieved contexts.}
    \label{tab:lfobj-google}
\end{table}



\section{Prompts}
\label{apx:prompts}

Tables \ref{tab:prompt-atomizer}, \ref{tab:prompt-reviser} and \ref{tab:prompt-nli} show the prompt templates we used for the Atomizer, Reviser and Evaluator stages of the FactReasoner pipeline. Tables \ref{tab:prompt-fs}, \ref{tab:prompt-fb} and \ref{tab:prompt-fv} show the prompts used by the prompt-based assessors: FactScore (FS), FactVerify (FV) and VeriScore (VS), respectively.


\begin{table*}[h!]
\centering
\caption{Prompt template for few-shot atomic unit decomposition - Atomizer stage}, 
\label{tab:prompt-atomizer}
\begin{footnotesize}
\begin{tabularx}{\textwidth}{X}
\toprule
\textbf{Atomic unit decomposition (Few-Shot)} \\

\textbf{Instructions:} \\
1. You are given a paragraph. Your task is to break the sentence down into a list of atomic statements without adding any new information. \\
2. An atomic statement is a sentence containing a singular piece of information directly extracted from the provided paragraph. \\
3. Atomic statements may contradict one another. \\
4. The paragraph may contain information that is factually incorrect. Even in such cases, you are not to alter any information contained in the paragraph and must produce atomic statements that are completely faithful to the information in the paragraph. \\
5. Each atomic statement in the outputted list should check a different piece of information found explicitly in the paragraph. \\
6. Each atomic statement is standalone in that any actual nouns or proper nouns should be used in place of pronouns or anaphoras. \\
7. Each atomic statement must not include any information beyond what is explicitly stated in the provided paragraph. \\
8. Where possible, avoid paraphrasing and instead try to only use language used in the paragraph without introducing new words. \\ 
9. Use the previous examples to learn how to do this. \\
10. You should only output the atomic statement as a list, with each item starting with "- ". Do not include other formatting. \\
11. Your task is to do this for the last paragraph that is given. \\


\textbf{Few-Shot Examples:} \\

Please breakdown the following paragraph into independent statements: Glenn Allen Anzalone (born June 23, 1955), better known by his stage name Glenn Danzig, is an American singer, songwriter, musician, and record producer. He is the founder of the rock bands Misfits, Samhain, and Danzig. He owns the Evilive record label as well as Verotik, an adult-oriented comic book publishing company. \\[0.5em]
- Glenn Allen Anzalone was born on June 23, 1955. \\
- Glenn Allen Anzalone is better known by his stage name Glenn Danzig. \\
- Glenn Danzig is an American singer, songwriter, musician, and record producer. \\
- Glenn Danzig is the founder of several rock bands, including Misfits, Samhain, and Danzig. \\
- Glenn Danzig owns the Evilive record label. \\
- Glenn Danzig owns Verotik, which is an adult-oriented comic book publishing company. \\

Please breakdown the following paragraph into independent statements: Luiz Inácio Lula da Silva (born 27 October 1945), also known as Lula da Silva or simply Lula, is a Brazilian politician who is the 39th and current president of Brazil since 2023. A member of the Workers' Party, Lula was also the 35th president from 2003 to 2010. He also holds the presidency of the G20 since 2023. Lula quit school after second grade to work, and did not learn to read until he was ten years old. As a teenager, he worked as a metalworker and became a trade unionist.\\
- Luiz Inácio Lula da Silva was born on October 27, 1945. \\
- Luiz Inácio Lula da Silva is also known as Lula da Silva or simply Lula. \\
- Lula is a Brazilian politician.\\
- Lula is the 39th and current president of Brazil since 2023. \\
- Lula is a member of the Workers' Party. \\
- Lula served as the 35th president of Brazil from 2003 to 2010. \\
- Lula holds the presidency of the G20 since 2023. \\
- Lula quit school after the second grade to work. \\
- Lula did not learn to read until he was ten years old. \\
- As a teenager, Lula worked as a metalworker. \\
- Lula became a trade unionist. \\

Please breakdown the following paragraph into independent statements: \{\}\\
\bottomrule
\end{tabularx}
\end{footnotesize}
\end{table*}

\begin{table*}[h!]
\centering
\caption{Prompt template for few-shot decontextualization - Reviser stage}
\label{tab:prompt-reviser}
\begin{footnotesize}    
\begin{tabularx}{\textwidth}{X}
\toprule
\textbf{Decontextualization (Few-Shot)} \\[0.5em]


\textbf{Instructions:} \\
1. You are given a statement and a context that the statement belongs to. Your task is to modify the statement so that any pronouns or anaphora (words like "it," "they," "this") are replaced with the noun or proper noun that they refer to, such that the sentence remains clear without referring to the original context. \\
2. Return only the revised, standalone version of the statement without adding any information that is not already contained within the original statement.
3. If the statement requires no changes, return the original statement as-is without any explanation.   \\
4. The statement that you return must start with \#\#\#\# and finish with \#\#\#\# as follows: \#\#\#\#<statement>\#\#\#\# \\
5. Do not include any explanation or any additional formatting including any lead-in or sign-off text. \\
6. Learn from the provided examples below and use that knowledge to amend the last example yourself. \\
\\
\textbf{Few-Shot Examples:} \\[0.5em]

Example 1:
Context: John went to the store. \\
Statement: He bought some apples. \\
Standalone: \#\#\#\#John bought some apples.\#\#\#\# \\[0.5em]

Example 2:
Context: The presentation covered various aspects of climate change, including sea level rise. \\
Statement: This was a key part of the discussion. \\
Standalone: \#\#\#\#Sea level rise was a key part of the discussion.\#\#\#\# \\[0.5em]

Example 3:
Context: Maria Sanchez is a renowned marine biologist known for her groundbreaking research on coral reef ecosystems. Her work has contributed to the preservation of many endangered coral species, and she is often invited to speak at international conferences on environmental conservation. \\
Statement: She presented her findings at the conference last year. \\
Standalone: \#\#\#\#Maria Sanchez presented her findings at the conference last year.\#\#\#\# \\[0.5em]

Example 4:
Context: Nathan Carter is a best-selling science fiction author famous for his dystopian novels that explore the intersection of technology and society. His latest book, The Edge of Something, received widespread critical acclaim for its imaginative world-building and its poignant commentary on artificial cacti. \\
Statement: It was praised for its thought-provoking themes. \\
Standalone: \#\#\#\#The Edge of Tomorrow was praised for its thought-provoking themes.\#\#\#\# \\[0.5em]

Now perform the task for the following example:
Context: \{\} \\
Statement: \{\} \\
Standalone: \\[0.5em]

\bottomrule
\end{tabularx}
\end{footnotesize}
\end{table*}


\begin{table*}[h!]
\centering
\caption{Prompt template for few-shot NLI relation extraction.}
\label{tab:prompt-nli}
\begin{footnotesize}
\begin{tabularx}{\textwidth}{X}
\toprule
\textbf{NLI relation prompting (Few-Shot)} \\[0.5em]


\textbf{Instructions:} \\
1. You are given a premise and a hypothesis and a context. Your task is to identify the relationship between them: does the premise entail, contradict, or remain neutral toward the hypothesis? \\
2. Your only output must be one of: (entailment | contradiction | neutral) without any lead-in, sign-off, new lines or any other formatting. \\
3. Do not provide any explanation or rationale to your output. \\
4. Use the following examples to learn how to do this, and provide your output for the last example given. \\[0.5em]

\textbf{Few-Shot Examples:} \\[0.5em]

Premise: Contrary to popular belief, the Great Wall is not visible from space without aid. \\
Hypothesis: Astronauts have managed to see the wall from Space unaided.  \\
Context: The Great Wall of China is one of the most famous landmarks in the world. It stretches over 13,000 miles and was primarily built during the Ming Dynasty. Contrary to popular belief, the Great Wall is not visible from space without aid. The primary purpose of the Great Wall was to protect against invasions from nomadic tribes. The wall is a UNESCO World Heritage site and attracts millions of tourists each year. Astronauts have managed to see the wall from Space unaided.  \\
Output: Contradiction \\[0.5em]

Premise: It is estimated that around 20 percent of the world's oxygen is produced by the Amazon. \\
Hypothesis: However, the Amazon Rainforest produces no significant amount of oxygen as the plants consume almost all of it through respiration. \\
Context: The Amazon Rainforest is often referred to as the lungs of the Earth due to its vast capacity to produce oxygen. This immense rainforest spans nine countries in South America. It is estimated that around 20 percent of the world's oxygen is produced by the Amazon. However, the Amazon Rainforest produces no significant amount of oxygen as the plants consume almost all of it through respiration. The biodiversity of the Amazon is unparalleled, hosting millions of species of plants and animals. \\
Output: Contradiction \\[0.5em]

Premise: It is estimated that around 20 percent of the world's oxygen is produced by the Amazon. \\
Hypothesis: This immense rainforest spans nine countries in South America. \\
Context: The Amazon Rainforest is often referred to as the lungs of the Earth due to its vast capacity to produce oxygen. This immense rainforest spans nine countries in South America. It is estimated that around 20 percent of the world's oxygen is produced by the Amazon. However, the Amazon Rainforest produces no significant amount of oxygen as the plants consume almost all of it through respiration. The biodiversity of the Amazon is unparalleled, hosting millions of species of plants and animals. \\
Output: Neutral \\[0.5em]

Premise: It is estimated that around 20 percent of the world's oxygen is produced by the Amazon. \\
Hypothesis: The Amazon Rainforest is often referred to as the lungs of the Earth due to its vast capacity to produce oxygen. \\
Context: The Amazon Rainforest is often referred to as the lungs of the Earth due to its vast capacity to produce oxygen. This immense rainforest spans nine countries in South America. It is estimated that around 20 percent of the world's oxygen is produced by the Amazon. However, the Amazon Rainforest produces no significant amount of oxygen as the plants consume almost all of it through respiration. The biodiversity of the Amazon is unparalleled, hosting millions of species of plants and animals. \\
Output: Entailment \\[0.5em]

Premise: \{\} \\
Hypothesis: \{\} \\
Context: \{\} \\
Output:\\
\bottomrule
\end{tabularx}
\end{footnotesize}
\end{table*}

\begin{table*}[h!]
\centering
\caption{Prompt template used by the FactScore (FS) assessor.}
\label{tab:prompt-fs}
\begin{tabularx}{\textwidth}{X}
\toprule


Answer the input question based on the given context. \\
 
\{CONTEXTS\} \\

Input: \{ATOM\} True or False? \\
Output:\\

\bottomrule
\end{tabularx}
\end{table*}

\begin{table*}[h!]
\centering
\caption{Prompt template used by the FactVerify (FV) assessor.}
\label{tab:prompt-fb}
\begin{tabularx}{\textwidth}{X}
\toprule

\textbf{Instructions:}\\
You are provided with a STATEMENT and several KNOWLEDGE points. \\
Your task is to evaluate the relationship between the STATEMENT and the \\
KNOWLEDGE, following the steps outlined below: \\

1. Summarize KNOWLEDGE Points: Carefully analyze the KNOWLEDGE points one by one and assess their relevance to the STATEMENT. \\
Summarize the main points of the KNOWLEDGE.\\
2. Evaluate Evidence: Based on your reasoning: \\
- If the KNOWLEDGE strongly implies or directly supports the STATEMENT, explain the supporting evidence. \\
- If the KNOWLEDGE contradicts the STATEMENT, identify and explain the conflicting evidence. \\
- If the KNOWLEDGE is insufficient to confirm or deny the STATEMENT, explain why the evidence is inconclusive. \\
3. Restate the STATEMENT: After considering the evidence, restate the STATEMENT to maintain clarity.\\
4. Final Answer: Based on your reasoning and the STATEMENT, determine your final answer. \\
Your final answer must be one of the following, wrapped in square brackets: \\
- [Supported] if the STATEMENT is supported by the KNOWLEDGE. \\
- [Contradicted] if the STATEMENT is contradicted by the KNOWLEDGE. \\
- [Undecided] if the KNOWLEDGE is insufficient to verify the STATEMENT. \\

Your task:\\

KNOWLEDGE: \\
\{\}\\

STATEMENT:\\
\{\}\\
\bottomrule
\end{tabularx}
\end{table*}

\begin{table*}[h!]
\centering
\caption{Prompt template used by the VeriScore (VS) assessor.}
\label{tab:prompt-fv}
\begin{footnotesize}
\begin{tabularx}{\textwidth}{X}
\toprule

\textbf{Instructions}\\

You need to judge whether a claim is supported or contradicted by Google search results, or whether there is no enough information to make the judgement. When doing the task, take into consideration whether the link of the search result is of a trustworthy source. Mark your answer with \#\#\# signs.\\

Below are the definitions of the three categories:\\

Supported: A claim is supported by the search results if everything in the claim is supported and nothing is contradicted by the search results. There can be some search results that are not fully related to the claim.\\
Contradicted: A claim is contradicted by the search results if something in the claim is contradicted by some search results. There should be no search result that supports the same part.\\
Undecided: A claim is inconclusive based on the search results if:\\
- a part of a claim cannot be verified by the search results,\\
- a part of a claim is supported and contradicted by different pieces of evidence,\\
- the entity/person mentioned in the claim has no clear referent (e.g., "the approach", "Emily", "a book").\\

Here are some examples:\\

Claim: Characters Lenny and Carl on The Simpsons are hearing but are depicted as close friends of the Simpsons family.\\

Search result 1\\
Title: Character Spotlight: Lenny Leonard and Carl Carlson\\
Content: Their friendship is a pretty singular aspect on the show -- save Bart and Milhouse (or to some degree, Mr. Burns and Smithers) -- they always ...\\
Link: https://nohomers.net/forums/index.php?threads/character-spotlight-lenny-leonard-and-carl-carlson-barflies.23798/

Search result 2\\
Title: The Simpsons: Lenny and Carl's History, Explained - CBR\\
Content: Introduced in the show's first season, the pair were portrayed as background characters at Homer's work, usually appearing together in minor ...\\
Link: https://www.cbr.com/the-simpsons-lenny-carl-history-explained/\\

Search result 3\\
Title: Are Lennie and Carl Homer Simpson's real or fake friends? - Quora\\
Content: Lenni is a pal, Carl doesn't consider any of them to be 'friends' they're just shallow guys he hangs out with. Lenny and Carl have a special ...\\
Link: https://www.quora.com/Are-Lennie-and-Carl-Homer-Simpson-s-real-or-fake-friends\\

Your decision: \#\#\#Undecided\#\#\#\\

Claim: The championship match of the FIFA World Cup 2026 will be hosted by the United States.\\

Search result 1\\
Title: World Cup 2026 | New York New Jersey to host final - FIFA\\
Content: New York New Jersey Stadium has been confirmed as the location for the FIFA World Cup 26 final on Sunday, 19 July 2026. The full match schedule for the ...\\
Link:https://www.fifa.com/fifaplus/en/tournaments/mens/worldcup/canadamexicousa2026/articles/new-york-new-jersey-stadium-host-world-cup-2026-final\\

Search result 2\\
Title: 2026 FIFA World Cup - Wikipedia\\
Content: The tournament will take place from June 11 to July 19, 2026. It will be jointly hosted by 16 cities in three North American countries: Canada, Mexico, and the ...\\
Link: https://en.wikipedia.org/wiki/2026\_FIFA\_World\_Cup\\

Search result 3\\
Title: World Cup 2026 | Dallas to host nine matches - FIFA\\
Content: Dallas Stadium will host nine matches from the FIFA World Cup 26, including four knockout games in the latter stages of the tournament.\\
Link:https://www.fifa.com/fifaplus/en/tournaments/mens/worldcup/canadamexicousa2026/articles/dallas-stadium-host-nine-world-cup-matches\\

Your decision: \#\#\#Supported\#\#\#\\

Claim: Vikings used their longships to transport livestock.\\

Search result 1\\
Title: How did the Vikings transport animals on their ships? - Quora\\
Content: The Vikings transported horses overseas in boats very similar to Viking longships, but with flat flooring built within the hulls, which allowed ...\\
Link: https://www.quora.com/How-did-the-Vikings-transport-animals-on-their-ships\\

Search result 2\\
Title: The Truth Behind Vikings Ships\\
Content: They could land on any beach, permitting lightning-quick embarking and attacks. Great loads could be carried, including horses and livestock.\\
Link: https://www.vikings.com/news/the-truth-behind-vikings-ships-18274806\\

Search result 3\\
Title: Viking ships | Royal Museums Greenwich\\
Content: Cargo vessels were used to carry trade goods and possessions. They were wider than the longships and travelled more slowly.\\
Link: https://www.rmg.co.uk/stories/topics/viking-ships\\

Your decision: \#\#\#Contradicted\#\#\#\\

Your task:\\
Claim: \{\}\\

\{\}\\

Your decision:\\
\bottomrule
\end{tabularx}
\end{footnotesize}

\end{table*}


\begin{table*}[h!]
\centering
\caption{Prompt template used by DeepSeek-v3.}
\label{tab:prompt-ds}
\begin{tabularx}{\textwidth}{X}
\toprule

\textbf{Instructions:}\\
You are provided with a STATEMENT and several external EVIDENCE points. \\
Your task is to use your internal knowledge as well as the provided EVIDENCE to \\
reason about the relationship between the STATEMENT and the EVIDENCE.\\
\\[0.2em]

1. Carefully analyze the EVIDENCE points one by one and assess their relevance to the STATEMENT. \\
2. Use your reasoning and your internal knowledge, evaluate the EVIDENCE as follows:\\
- If the EVIDENCE strongly implies or directly supports the STATEMENT, explain the supporting evidence.\\
- If the EVIDENCE contradicts the STATEMENT, identify and explain the conflicting evidence.\\
- If the EVIDENCE is insufficient to confirm or deny the STATEMENT, explain why the evidence is inconclusive.\\
3. Based on your reasoning and your explanations, determine your final answer. \\
Your final answer must be one of the following, wrapped in square brackets:\\
- [Supported] if the EVIDENCE supports the STATEMENT.\\
- [Contradicted] if the EVIDENCE contradicts the STATEMENT.\\
- [Undecided] if the EVIDENCE is insufficient to assess the STATEMENT.\\

\\ [0.3em]
Your task: \\

EVIDENCE: \{\} \\

STATEMENT:\\

\bottomrule
\end{tabularx}
\end{table*}

\end{document}
