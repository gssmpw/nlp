%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%
\PassOptionsToPackage{dvipsnames}{xcolor}
\documentclass{article}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage{hyperref}
\newcommand{\theHalgorithm}{\arabic{algorithm}}
\usepackage[accepted]{icml2025}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{multirow}
\usepackage[capitalize,noabbrev]{cleveref}
\usepackage{enumitem}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\usepackage[disable,textsize=tiny]{todonotes}
\newcommand{\lele}{\textcolor{blue}}
\icmltitlerunning{\raisebox{-0.1\height}{\includegraphics[height=0.77em]{icon.png}} SimMark: A Robust Sentence-Level Similarity-Based Watermarking Algorithm for LLMs}
\begin{document}
\allowdisplaybreaks
\raggedbottom
\twocolumn[
\icmltitle{\raisebox{-0.1\height}{\includegraphics[height=0.77em]{icon.png}} \textit{\textbf{SimMark}}: A Robust Sentence-Level Similarity-Based \\ Watermarking Algorithm for Large Language Models}
\begin{icmlauthorlist}
\icmlauthor{Amirhossein Dabiriaghdam}{UBC}
\icmlauthor{Lele Wang}{UBC}
\end{icmlauthorlist}
\icmlaffiliation{UBC}{Department of ECE, University of British Columbia, Vancouver, BC, Canada}
\icmlcorrespondingauthor{Amirhossein Dabiriaghdam}{amirhossein@ece.ubc.ca}
% \icmlcorrespondingauthor{Lele Wang}{lele.wang@ece.ubc.ca}
\icmlkeywords{Large Language Models,Watermarking LLMs,Posthoc Watermarking,Sentence-Level Watermarking,Similarity-Based Watermarking, Machine Learning, ICML}
\vskip 0.3in
]
\printAffiliationsAndNotice{} 
\begin{abstract}
\renewcommand*{\thefootnote}{\fnsymbol{footnote}}
The rapid proliferation of large language models (LLMs) has created an urgent need for reliable methods to detect whether a text is generated by such models. In this paper, we propose \textbf{\textit{SimMark}}, a posthoc watermarking algorithm that makes LLMs' outputs traceable without requiring access to the model's internal logits, enabling compatibility with a wide range of LLMs, including API-only models. By leveraging the similarity of semantic sentence embeddings and rejection sampling to impose detectable statistical patterns imperceptible to humans, and employing a \textit{soft} counting mechanism, \textit{SimMark} achieves robustness against paraphrasing attacks. Experimental results demonstrate that \textit{SimMark} sets a new benchmark for robust watermarking of LLM-generated content, surpassing prior sentence-level watermarking techniques in robustness, sampling efficiency, and applicability across diverse domains, all while preserving the text quality.\footnote{The source code of our algorithm can be found at \href{https://github.com/DabiriAghdam/SimMark}{https://github.com/DabiriAghdam/SimMark}.}
\end{abstract}

\section{Introduction} \label{intro}
\renewcommand*{\thefootnote}{\arabic{footnote}}

\begin{figure}[t]
    \centering
    \includegraphics[page=1,width=\linewidth]{figures_cropped.pdf}
    \vspace{-10pt} 
    \caption{A high-level overview of \textit{SimMark} detection algorithm. The input text is divided into individual sentences $X_1$ to $X_N$, which are embedded using a semantic embedding model, with optional PCA for dimensionality reduction. The similarity between consecutive sentence embeddings is computed. Sentences with similarities within a predefined interval $[a, b]$ are considered \textcolor{ForestGreen}{\textbf{valid}}, while those outside are \textcolor{BrickRed}{\textbf{invalid}}. 
    A \textit{\textbf{soft}}-$z$-test is performed using the \textit{soft} count of \textcolor{BrickRed}{invalid/partially valid} sentences to determine whether the text is watermarked.}
    \vspace{-5pt} 
    \label{fig:Detection}
\end{figure}
The advent of deep generative AIs has made it increasingly important to detect whether a given text is generated by a large language model (LLM). Advanced LLMs, such as GPT-3.5 \cite{openai2022chatgpt}, GPT-4 \cite{gpt4}, and Claude 3 \cite{anthropic2024claude}, can produce human-like text at scale and low cost, enabling transformative applications across industries. However, these capabilities also present significant risks, including but not limited to misuse for academic plagiarism, disinformation campaigns and propaganda aimed at manipulating public opinion.  For example, the use of AI-generated content in news articles has raised concerns about transparency, accountability, and the potential spread of misinformation \cite{futurism2023cnet}. Furthermore, the ability to reliably identify LLM-generated content is essential for enforcing copyright protections and ensuring accountability for such content \cite{weidinger2021ethical}.

Detecting LLM-generated text poses a unique challenge. These models are explicitly trained to emulate human writing styles, often rendering their outputs indistinguishable from human-authored text. As demonstrated by \citet{kumarage-etal-2023-reliable} and \citet{reliable}, reliably differentiating between human-written and machine-generated text remains an open problem.

One promising approach to addressing this, is the use of imperceptible statistical signatures, or \textit{watermarks}, embedded within a text. Watermarking imperceptibly alters text such that it remains natural to human readers but enables subsequent detection of its origin \cite{atallah2001natural}. Effective watermarking methods must balance the preservation of LLM output quality with robustness against adversarial \textit{paraphrasing}, where attackers modify the text to evade detection \cite{krishna2024paraphrasing}. Additionally, watermarks must be resistant to \textit{spoofing} attacks, wherein adversaries craft non-machine-generated text (often malicious) to falsely trigger watermark detectors \cite{reliable}.

In this paper, we introduce \textbf{\textit{SimMark}}, a robust \textit{posthoc} sentence-level watermarking algorithm for LLMs based on sentence embedding similarity. The term posthoc here refers to the fact that the watermarking process operates on text \textbf{after} it has been generated by the LLM, rather than modifying the text generation process itself. This approach makes \textit{SimMark} compatible with a wide range of models, including open-weight LLMs and closed-source proprietary models accessible only via APIs, as it does not require fine-tuning or access to the model's internal logits. Access to logits is often restricted by API providers due to their potential use in distilling LLMs and leaking proprietary information \cite{finlayson2024logits}. \textit{SimMark} leverages embedding representations from text embedding models to capture semantic relationships between sentences and imposes detectable statistical patterns on sentence similarity through rejection sampling. Specifically, rejection sampling involves querying the LLM multiple times until the similarity between embeddings of consecutive sentences falls within a certain predefined interval. At detection time, these patterns are analyzed using one-proportion \textit{soft}-$z$-test, a statistical test, to differentiate between human-written and LLM-generated text, as illustrated in Figure~\ref{fig:Detection}.



In summary, our contributions are as follows:
\begin{itemize}[itemsep=0pt, topsep=0pt]
    \item We introduce a novel watermarking algorithm that achieves state-of-the-art detection performance while maintaining low false positive rates for human-written text.
    \item Our approach demonstrates robustness against paraphrasing attacks through semantic-level watermarking and a soft counting mechanism for statistical testing.
    \item Compared to existing watermarking methods, \textit{SimMark} provides a more practical solution that operates without access to LLM logits or fine-tuning, offering efficient and high-quality watermark injection and detection.
\end{itemize}

The remainder of this paper is organized as follows. Section~\ref{background} reviews the background and related work on watermarking techniques for LLMs. Section~\ref{approach} outlines our methodology. Section~\ref{experiments} describes our experimental setup and presents comparative results, while Section~\ref{conclusion} concludes the paper. In the end, we also discuss the potential ethical considerations and societal impacts.

\section{Background} \label{background}
In this section, we provide an overview of the foundational concepts related to text generation with LLMs and discuss related works on watermarking techniques for LLMs.

\subsection{Autoregressive Decoding of LLMs}  
An LLM operates over a vocabulary \( V \), a set of words or subwords termed as \textit{tokens}. Let \( f: V \rightarrow V \) be an LLM that takes a sequence of tokens \( T_i = \{t_1, t_2, \ldots, t_i\} \) as input and generates the next token \( t_{i+1} \) as its output.  

To generate \( t_{i+1} \), the LLM samples it from the conditional probability distribution \( P(t_{i+1} | T_i) \) over the vocabulary \( V \). After generating \( t_{i+1} \), the updated sequence \( T_{i+1} = \{t_1, t_2, \ldots, t_i, t_{i+1}\} \) is fed back into the model \( f \), and the process is repeated iteratively to generate the subsequent token \( t_{i+2} \). This continues until an end-of-sequence token is generated or the generation reaches a predefined token limit. This sequential process of generating one token at a time based on the previously generated tokens is known as \textit{autoregressive decoding}.  

\subsection{Token-Level Watermarking}  
Token-level watermarking methods embed a statistical signal in the text by manipulating the token generation process \cite{kgw, unigram, fu2024watermarking}. These methods typically alter the probability distribution over \( V \) during decoding, subtly biasing the selection of certain tokens to form detectable patterns.

For instance, the KGW algorithm introduced by \citet*{kgw}, groups \( V \) into \textit{green} and \textit{red} subsets \textit{pseudo-randomly} seeded on the previous token before generating each new token.
A predefined positive constant \( \delta\) is added to the logits of each token in the green list, increasing their probability of being selected during the sampling step.

At detection, a one-proportion \( z \)-test is applied to the number of tokens from the green list in the text to determine whether the text contains a watermark. This test compares the observed proportion of green tokens to the expected proportion under the null hypothesis of no watermark, providing a statistical measure to detect even subtle biases introduced by the watermark \cite{kgw}.

\citet{unigram}'s UNIGRAM-WATERMARK builds upon KGW by fixing the red and green lists instead of pseudo-randomly selecting them, proving that compared to KGW their method is more robust to paraphrasing and editing \cite{unigram}. However, as outlined by \citet{k-semstamp}, this algorithm can be reverse-engineered, rendering it impractical for high-stakes, real-world applications.

The Semantic Invariant Robust (SIR) watermark in \citet{sir} is also similar to KGW but is designed to be less sensitive to attacks involving synonym replacement or advanced paraphrasing. SIR achieves this by altering the LLM logits based on the semantics of previously generated tokens, using an embedding model to compute semantic representations and training a model that adjusts LLM's logits based on the semantic embeddings of prior tokens \cite{sir}.  

Detection of such watermarks involves analyzing token sequences for statistical signatures that deviate from typical human-generated text. However, token-level watermarks can still be vulnerable to paraphrasing attacks, as rephrasing may disrupt the green and red token lists without altering the overall meaning \cite{krishna2024paraphrasing}. Moreover, since these methods modify the logits, they directly impact the conditional probability distribution over \( V \), potentially affecting the quality of the generated text \cite{fu2024watermarking}.  

\subsection{Sentence-Level Watermarking}  
One approach to mitigate the previously mentioned problems is to inject the watermark signal at the sentence-level semantics, making it less vulnerable to paraphrasing attacks. Consider a similar notation for sentence generation using model \( f \) (i.e., the LLM) with autoregressive decoding that takes a sequence of sentences \( M_i = \{X_1, X_2, \ldots, X_i\} \) and generates the next sentence \( X_{i+1} \). The updated sequence of sentences \( M_{i+1} = M_i \cup \{X_{i+1}\} \) is then used to generate subsequent sentences iteratively.

SemStamp~\cite{semstamp} employs Locality-Sensitive Hashing (LSH)~\cite{lsh} to pseudo-randomly partition the semantic space of the embedding model into a set of \textit{valid} and \textit{blocked} regions, analogous to the green and red subsets in KGW. During rejection sampling, if the representation of a newly generated sentence lies within the valid regions (determined based on the LSH signature of the previous sentence), the sentence is accepted. Otherwise, a new sentence is generated until a valid sentence is produced or the retry limit is reached. Similar to KGW, a one-proportion \( z \)-test is applied to the number of valid sentences (analogous to green tokens) to determine whether the text contains a watermark.  

To improve robustness against paraphrasing, SemStamp used a contrastive learning approach \cite{1640964}, fine-tuning a semantic embedding model such that the embeddings of paraphrased sentences remain as close as possible to the original sentences. This was achieved by minimizing the distance between paraphrased and original embeddings while ensuring unrelated sentences remained distinct. Additionally, they introduce a margin constraint in the rejection sampling process to reject sentences whose representations lie near the region boundaries. Their results demonstrate that this sentence-level approach improves robustness against paraphrasing.

$k$-SemStamp~\cite{k-semstamp} builds upon SemStamp and aims to enhance robustness by partitioning the semantic space using \( k \)-means clustering~\cite{kmeans} instead of random partitioning. They claim that in this way, sentences with similar semantics are more likely to fall within the same partition, unlike random partitioning, which may place semantically similar sentences into different partitions, reducing robustness \cite{k-semstamp}. However, $k$-SemStamp assumes that the LLM generates text within a specific domain to apply \( k \)-means clustering effectively \cite{k-semstamp}, limiting its applicability in real-world, open-domain scenarios. The generation and detection procedures of $k$-SemStamp remain largely similar to the original SemStamp. In contrast to token-level algorithms, these sentence-level methods do not alter the logits of the LLM, therefore it is expected for their resulting text to be of higher quality \cite{semstamp}.

Our work, like SemStamp and $k$-SemStamp, is a sentence-level watermarking algorithm; however, it embeds its watermark signature in the semantic similarity of consecutive sentences. It achieves greater generalizability across domains by leveraging an off-the-shelf, general-purpose sentence embedding model without fine-tuning. At the same time, it outperforms state-of-the-art token-level and sentence-level watermarking methods in robustness against paraphrasing while preserving text quality.

\section{\textit{SimMark}: A Similarity-Based Watermark} \label{approach}
In this section, we present our proposed framework for watermarking LLMs, detailing both the process of generating watermarked text and its subsequent detection.

\begin{figure*}[t]
    \centering
    \includegraphics[page=2,width=\linewidth]{figures_cropped.pdf}
    \vspace{-10pt} 
    \caption{Overview of \textit{\textbf{SimMark}} algorithm. \textbf{Top:} \textit{\textbf{Generation}}. For each newly generated sentence ($X_{i+1}$), its embedding ($e_{i+1}$) is computed using the Instructor-Large model, optionally applying PCA for dimensionality reduction. The cosine similarity (or Euclidean distance) between $e_{i+1}$ and the embedding of the previous sentence ($e_i$), denoted as $s_{i+1}$, is calculated. If $s_{i+1}$ lies within the predefined interval $[a, b]$, the sentence is marked \textcolor{ForestGreen}{valid} and accepted. Otherwise, rejection sampling generates a new candidate sentence until validity is achieved or the iteration limit is reached. Once a sentence is accepted, the process repeats for subsequent sentences. \textbf{Bottom:} \textit{\textbf{Detection (+ Paraphrase attack)}}. Paraphrased versions of watermarked sentences are generated ($Y_{i}$), and their embeddings ($e'_{i}$) are computed. The similarity (or distance) between consecutive sentences in the paraphrased text is evaluated. If paraphrasing causes the similarity ($s'_{i+1}$) to fall outside $[a, b]$, it is mismarked as \textcolor{BrickRed}{invalid}. A \textit{soft counting} mechanism (via function $c(s_{i+1})$ instead of a regular counting with a step function in the interval $[a,b]$) quantifies partial validity based on proximity to the interval bounds, enabling detection of watermarked text via the \textit{\textbf{soft}}-$z$-test even under paraphrase attacks. It should be emphasized that soft counting is always applied during detection, regardless of whether paraphrasing is present or not, as we cannot assume prior knowledge of paraphrasing.}
    \vspace{-5pt} 
    \label{fig:Overview}
\end{figure*}

\subsection{Watermarked Text Generation}
Similar to SemStamp and $k$-SemStamp \cite{semstamp, k-semstamp}, \textit{SimMark} utilizes the embedding representations of the sentences. To compute the embeddings, in contrast with \citet{semstamp, k-semstamp} that fine-tuned their embedder model (which could make it biased toward a specific paraphrasing model or domain), we employ Instructor-Large~\cite{instructor}, a general-purpose instruction-tuned embedding model. The use of a general-purpose embedding model enables our approach to be more easily adaptable to different domains, and since the generated embeddings are conditioned on a specific instruction, even if a third party knows what embedder model we used, it is still not trivial to reverse-engineer our algorithm without knowing the exact instruction used during generation (the user can also change this instruction frequently), resulting in more robustness against spoofing attacks. 

\begin{algorithm}[t]
    \caption{Generation Pseudo-Code for \textit{\textbf{SimMark}}}
    \label{alg:generation}
    \begin{algorithmic}[1]
        \REQUIRE LLM, embedding model, predefined interval $[a, b]$, maximum iterations $N_\mathrm{max}$, optional PCA model 
        \FOR{each generated sentence $i$ ($X_i$)}
            \STATE Compute embedding $e_i$ for $X_i$ using the embedding model.
            \STATE $n \gets 0$ 
            \STATE \textbf{do}
            \STATE \hspace{1em} Generate sentence $i+1$ ($X_{i+1}$) using the LLM.
            \STATE \hspace{1em} Compute embedding $e_{i+1}$ for $X_{i+1}$ using the embedding model.
            \STATE \hspace{1em} \textit{Optional:} Reduce the dimension of $e_i$ and $e_{i+1}$ using the PCA model.
            \STATE \hspace{1em} Compute similarity $s_{i+1}\gets sim(e_i, e_{i+1})$:
             {\[
             \small
            s_{i+1} \gets 
            \begin{cases}
                \tfrac{e_i\cdot e_{i+1}}{\Vert e_{i}\Vert_2 \cdot \Vert e_{i+1}\Vert_2} &  \text{ if cosine similarity}, \\
                \Vert e_i - e_{i+1}\Vert_2 & \text{ if Euclidean distance,}
            \end{cases}
            \]}
            \STATE \hspace{1em} $n \gets n + 1$
            \STATE \textbf{while} $s_{i+1} \textcolor{BrickRed}{\notin [a, b]}$ \textbf{and} $n < N_\mathrm{max}$
            \STATE Accept $X_{i+1}$ as valid and continue generating the next sentence. \COMMENT{\textit{Here we either reached the $N_\mathrm{max}$ or $s_{i+1} \textcolor{ForestGreen}{\in [a, b]}$}}
        \ENDFOR
    \end{algorithmic}
\end{algorithm}

Using Instructor-Large, we compute embeddings for a sentence by passing both the sentence and an instruction (e.g., \textit{``Represent the sentence for cosine similarity:''} or \textit{``Represent the sentence for Euclidean distance:''}) to the Instructor model. Then, we calculate the cosine similarity (or Euclidean distance) between the embedding of sentence $i+1$ (denoted as $e_{i+1}$ in Algorithm~\ref{alg:generation}) and the embedding of sentence $i$ (denoted as $e_i$). If the computed value lies within the user-defined predefined interval, sentence $i+1$ is considered \textbf{\textit{\textcolor{ForestGreen}{valid}}} (analogous to the green subset in KGW). Otherwise, we prompt the LLM to generate a new sentence and repeat this procedure until a valid sentence is found or the maximum number of iterations is reached (in this case we accept the last generated sentence, and continue to generating sentence $i+2$), as shown in Algorithm~\ref{alg:generation}. Optionally, we may apply Principal Component Analysis (PCA) method to the embeddings to reduce their dimensionality before calculating the similarity or distance (this is the instruction in this case: \textit{``Represent the sentence for PCA:''}). The reason for applying PCA is provided in Subsection \ref{sub:detection}. An overview of \textit{SimMark} generation algorithm is depicted in the top part of Figure~\ref{fig:Overview}.

The predefined interval is a hyperparameter chosen a priori by the user based on the distribution of similarities (or distances) between consecutive sentences' embeddings generated by an unwatermarked LLM and human-written text. The choice of this hyperparameter is critical for the performance of \textit{SimMark}. 

First, if the interval's width is too small or its position is far from the mean of the similarity distribution, generating sentences within this interval can be challenging or even infeasible for the LLM. Conversely, if the interval's width is large and centered around the mean of the similarity distribution, generating sentences becomes easier, but the false positive (FP) rate (i.e., human-written text misclassified as machine-generated) increases.

Furthermore, the choice of interval affects the robustness of \textit{SimMark} against paraphrasing attacks. When an attacker paraphrases sentences, the similarities (or distances) may change and fall outside the interval. A larger interval provides greater robustness, as the watermark is less likely to be disrupted by paraphrasing. Therefore, the selection of the interval involves balancing several factors: it must not be too narrow to impede sentence generation while maintaining a low FP rate and adequate robustness against paraphrasing.

Finding an optimal interval, or ``sweet spot,'' depends on the distribution of similarities between consecutive sentences, which varies across different embedding models. However, identifying such sweet spots is feasible when the user analyzes the similarity distributions of both LLM-generated and human-written text (See Appendix \ref{appendix:optimal_interval} for an example of finding the sweet spot).

\subsection{Watermarked Text Detection} \label{sub:detection}

The detection of \textit{SimMark} follows a similar methodology to KGW by employing a one-proportion $z$-test for hypothesis testing. However, akin to \citet{semstamp, k-semstamp}, the detection operates at the \textit{sentence level} rather than the token level. To perform detection, we first divide the input text into sentences\footnote{Using \textit{sent\_tokenize} method of NLTK \cite{bird2009natural}.} and use the same Instructor-Large embedding model with identical instruction to compute the embeddings for each sentence. If PCA was used during the watermark generation process, it must also be applied here to ensure consistency.

\begin{algorithm}[t]
    \caption{Detection Pseudo-Code for \textit{\textbf{SimMark}}}
    \label{alg:detection}
    \begin{algorithmic}[1]
        \REQUIRE input text, embedding model, predefined interval $[a, b]$, decay factor $K$, threshold $\beta$, optional PCA model
        \STATE Split the input text into sentences excluding the first sentence (i.e, the prompt): $M=\{X_2, \dots, X_{N_\mathrm{total}}\}$.
        \FOR{each sentence pair $(X_i, X_{i+1})$}
            \STATE Compute embeddings $e_i$ for $X_i$ and $e_{i+1}$ for $X_{i+1}$ using the embedding model.
            \STATE \textit{Optional}: Reduce the dimensionality of $e_i$ and $e_{i+1}$ using the PCA model.
            \STATE Compute $s_{i+1}\gets sim(e_i, e_{i+1})$.
            \STATE Compute $c_{i+1}$ according to Eq. \eqref{eq:count_formula}.
        \ENDFOR
        \STATE $N \gets |M|$
        \STATE Soft count of valid sentences: $N_\mathrm{valid\_soft} \gets \sum_{i=2}^{N+1} c_i$. 
        \STATE Estimate $p_0$ as the area under the human-written text embeddings similarity distribution curve within $[a, b]$.
        \STATE Compute $z_\mathrm{soft}$  (i.e., the \textit{\textbf{soft}}-$z$-score) using Eq. \eqref{eq:z_formula2}.
        \IF{\textcolor{ForestGreen}{$z_\mathrm{soft} > \beta$}} 
            \STATE Reject $H_0$, i.e., the input text is likely generated by an LLM watermarked by \textit{SimMark}. 
            ~\raisebox{-0.3\height}{\includegraphics[width=0.033\textwidth]{watermarked.png}}
            
        \ELSE  
            \STATE Accept $H_0$, i.e., the input text is likely written by a human.
            ~\raisebox{-0.3\height}{\reflectbox{\includegraphics[width=0.03\textwidth]{human.png}}} 
        \ENDIF
    \end{algorithmic}
\end{algorithm}

Next, we compute the similarity (or distance) between consecutive sentences and count the number of \textcolor{ForestGreen}{valid} sentences, denoted as $N_\mathrm{valid\_soft}$. A sentence $X_{i+1}$ is deemed valid if $s_{i+1}$ the similarity (or distance) between $X_{i+1}$ and $X_i$ lies within the predefined user interval $[a, b]$. However, paraphrasing attacks may alter embeddings significantly, causing the similarity (or distance) to deviate from the desired interval. To mitigate this, we adopt a \textbf{soft counting} approach, where a sentence is considered partially valid if its similarity is near the interval boundaries. Specifically, the soft count of $X_{i+1}$, denoted as $c_{i+1}$, is defined as follows:
\begin{equation}
\vspace{-0.5em}
\scalebox{0.9}{$
\begin{aligned}
c_{i+1} = c(s_{i+1}) = 
\begin{cases} 
1 & \text{if } s_{i+1} \; \textcolor{ForestGreen}{\in [a, b]}, \\
e^{-K \min\{|a - s_{i+1}|, |b - s_{i+1}|\}} & \textcolor{BrickRed}{\text{otherwise.}}
\end{cases}
\end{aligned}
$}
\label{eq:count_formula}
\end{equation}

Here, \( s_{i+1} = sim(e_i,e_{i+1}) \) represents the similarity (or distance) between consecutive sentence embeddings, and \( K >0\) is a decay factor controlling the smoothness of the soft counting mechanism. A higher \( K \) makes the function behave closer to a step function, while a lower \( K \) allows for smoother transitions, tolerating minor deviations outside the interval \([a, b]\). The total number of valid sentences is then computed as $N_\mathrm{valid\_soft} = \sum c_i$.

Refer to Appendix \ref{appendix:K} for experimental results demonstrating how this soft counting mechanism improves robustness against paraphrasing, with only a minimal impact on performance in non-paraphrased scenarios. Allowing for some degree of error through soft counting enables better detection under adversarial conditions while maintaining high accuracy in non-paraphrased cases.

During our initial experiments, we observed that contrary to cosine similarity, Euclidean distance is very sensitive to paraphrasing and even a subtle change in the sentences would result in a huge difference in the distances of embeddings. We hypothesize that Euclidean distance is sensitive to noise in high-dimensional spaces such as the semantic space of the embedder. To mitigate this, we propose using PCA: We first train a PCA model on a dataset of human-written texts, to find the principal components of the sentence embeddings, i.e., the components that contribute the most to the semantical representation of the sentences. Then, we apply PCA to the embeddings to reduce their dimension. More details on the dimensionality reduction are provided in Section \ref{experiments} and Appendix \ref{appendix:ablation_pca}.

With this approach reverse-engineering the watermark algorithm becomes even harder as the third party who tries to reverse-engineer the algorithm, not only requires to know the embedder model and the instruction used for it, but it also needs to know the specifics of PCA setting (such as the number of principal components) and needs access to the dataset for training the PCA; 
otherwise, the similarity distribution of sentence embeddings would be different, making reverse engineering challenging. We found that this approach improved the robustness against paraphrasing when Euclidean distance is used. However, it would decrease the performance when cosine similarity is used.

Returning to the detection, the null hypothesis $H_0$ is defined as follows:
\begin{quote}
\vspace{-10pt} 
\textit{$H_0$: The sentences are written by humans, i.e., the text sequence is written (or generated) without knowledge of the valid interval in the similarity distribution of sentence embeddings.}
\end{quote}
\vspace{-5pt} 
We calculate the $z$-statistic for the one-proportion $z$-test using the sample proportion $p = \frac{N_\mathrm{valid\_soft}}{N}$, where $N$ is the total number of samples (sentences). Since $N_\mathrm{valid\_soft}$ is a soft count of valid sentences, we refer to it as \textit{soft}-$z$-score, which is given by $z_\mathrm{soft}  = \frac{p - p_0}{\sqrt{\frac{p_0(1 - p_0)}{N}}}$.
Here, $p_0$ is the population proportion and represents the ratio of valid sentences to all sentences in human-written text (i.e., in a text with no watermark), which is estimated as the area under the similarity distribution curve of consecutive human-written sentences within the interval $[a, b]$ (Like the one in Figure~\ref{fig:dist_of_distances}). Alternatively, the \textit{soft}-$z$-score can be expressed as:
\begin{equation}
z_\mathrm{soft} = \tfrac{N_\mathrm{valid\_soft} - p_0 N}{\sqrt{p_0(1 - p_0)N}}.
\label{eq:z_formula2}
\end{equation}
In this form, the value of $z_\mathrm{soft}$ can be interpreted as a normalized deviation of the number of valid sentences $N_\mathrm{valid\_soft}$ from its expectation $p_0 N$.
As highlighted in Algorithm~\ref{alg:detection}, the null hypothesis $H_0$ is rejected if \textcolor{ForestGreen}{$z_{soft} > \beta$}, where $\beta$ is a threshold determined empirically by running the detection algorithm on human-written text. The threshold $\beta$ is selected to maintain a desired FP rate (i.e., minimizing the misclassification of human-written text as LLM-generated). Details on the computation of $\beta$ are provided in the Appendix \ref{appendix:estimate-AUC}.

\section{Experiments} \label{experiments}
\renewcommand*{\thefootnote}{\fnsymbol{footnote}}
\begin{table*}[t] 
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{@{}clcccccccc@{}}
\toprule
Dataset & Algorithm & No Paraphrase & Pegasus & Pegasus-bigram & Parrot & Parrot-bigram & GPT3.5 & GPT3.5-bigram & Avg. Paraphrased \\ 
\midrule
\multirow{6}{*}{\rotatebox{90}{RealNews}} 
& KGW (\citeauthor{kgw})        & 99.6 / 98.4 / 98.9 & 95.9 / 82.1 / 91.0 & 92.1 / 42.7 / 72.9 & 88.5 / 31.5 / 55.4 & 83.0 / 15.0 / 39.9 & 82.8 / 17.4 / 46.7 & 75.1 / 5.9 / 26.3 & 86.2 / 32.4 / 55.4 \\
& SIR (\citeauthor{sir})       & \textbf{99.9} / \textbf{99.4} / \textbf{99.9} & 94.4 / 79.2 / 85.4 & 94.1 / 72.6 / 82.6 & 93.2 / 62.8 / 75.9 & 95.2 / 66.4 / 80.2 & 80.2 / 24.7 / 42.7 & 77.7 / 20.9 / 36.4 & 89.1 / 54.4 / 67.2 \\
& SemStamp (\citeauthor{semstamp}) & 99.2 / 93.9 / 97.1 & 97.8 / 83.7 / 92.0 & 96.5 / 76.7 / 86.8 & 93.3 / 56.2 / 75.5 & 93.1 / 54.4 / 74.0 & 83.3 / 33.9 / 52.9 & 82.2 / 31.3 / 48.7 & 91.0 / 56.0 / 71.6 \\
& $k$-SemStamp (\citeauthor{k-semstamp}) & 99.6 / 98.1 / 98.7 & \textbf{99.5} / \textbf{92.7} / \underline{96.5} & \underline{99.0} / \underline{88.4} / \underline{94.3} & \underline{97.8} / \underline{78.7} / \underline{89.4} & \underline{97.5} / \underline{78.3} / \underline{87.3} & 90.8 / \underline{55.5} / 71.8 & \underline{88.9} / \textbf{50.2} / \underline{66.1}  & \underline{95.6} / \underline{74.0} / \underline{84.2}   \\ 
& Cosine-\textit{SimMark} (Ours) & 99.6 / 96.8 / 98.8 & \underline{99.2} / \underline{90.3} / \textbf{98.2} & \textbf{99.1} / \textbf{90.3} /\textbf{ 97.9} & \textbf{98.7} / \textbf{88.1} / \textbf{97.2} & \textbf{98.8} / \textbf{87.3} / \textbf{97.6} & \textbf{95.7} / \textbf{59.7} / \textbf{86.7} & \textbf{92.0} / \underline{38.8} / \textbf{73.7}  & \textbf{97.2} / \textbf{75.8} / \textbf{91.9} \\ 
& Euclidean-\textit{SimMark}\footnotemark[7] (Ours) & \underline{99.8} / \underline{98.5} / \underline{99.3} & 97.2 / 72.3 / 89.1 & 96.9 / 70.0 / 87.4 & 95.7 / 60.2 / 82.5 & 95.7 / 59.1 / 81.5 & \underline{94.1} / 51.6 / \underline{76.2} & 88.2 / 29.7 / 53.5  & 94.6 / 57.2 / 78.4 \\ 
\midrule
\multirow{6}{*}{\rotatebox{90}{BookSum}} 
& KGW   & 99.6 / 99.0 / 99.2 & 97.3 / 89.7 / 95.3 & 96.5 / 56.6 / 85.3 & 94.6 / 42.0 / 75.8 & 93.1 / 37.4 / 71.2 & 87.6 / 17.2 / 52.1 & 77.1 / 4.4 / 27.1  & 91.0 / 41.2 / 67.8 \\
& SIR         & \textbf{100} / \underline{99.8} / \textbf{100}   & 93.1 / 79.3 / 85.9 & 93.7 / 69.9 / 81.5 & 96.5 / 72.9 / 85.1 & 97.2 / 76.5 / 88.0 & 80.9 / 39.9 / 23.6 & 75.8 / 19.9 / 35.4  & 89.5 / 59.7 / 66.6 \\
& SemStamp    & 99.6 / 98.3 / 98.8 & 99.0 / \textbf{94.3} / 97.0 & 98.6 / 90.6 / 95.5 & 98.3 / 83.0 / 91.5 & 98.4 / 85.7 / 92.5 & 89.6 / 45.6 / 62.4 & 86.2 / 37.4 / 53.8  & 95.0 / 72.8 / 82.1 \\
& $k$-SemStamp & \underline{99.9} / 99.1 / 99.4 & \underline{99.3} / \underline{94.1} / \underline{97.3} & \underline{99.1} / \underline{92.5} / \underline{96.9} & \underline{98.4} / \underline{86.3} / \underline{93.9} & \underline{98.8} / \textbf{88.9} / \underline{94.9} & 95.6 / \underline{65.7} / 83.0 & \underline{95.7} / \underline{64.5} / \underline{81.4}  & 97.8 / \underline{81.5} / 91.2 \\ 
& Cosine-\textit{SimMark} (Ours) & 99.8 / 98.8 / \underline{99.5} & \textbf{99.5} / 93.3 / \textbf{98.5} & \textbf{99.6} / \textbf{94.1} / \textbf{98.5} & \textbf{99.3} / \textbf{88.5} / \textbf{98.0} & \textbf{99.3} / \underline{87.0} / \textbf{98.2} & \underline{97.1} / 62.5 / \underline{86.9} & 94.5 / 41.6 / 74.2  & \underline{98.2} / 77.8 / \underline{92.4} \\ 
& Euclidean-\textit{SimMark} (Ours) & \textbf{100} / \textbf{100} / \textbf{100} & 98.8 / 82.6 / 94.9 & 98.6 / 80.4 / 93.4 & 97.9 / 75.3 / 91.1 &  97.9 / 73.3 / 91.6 & \textbf{99.7} / \textbf{94.4} / \textbf{98.8} & \textbf{99.5} / \textbf{91.9} / \textbf{97.6}  & \textbf{98.7} / \textbf{83.0} / \textbf{94.6} \\ 
\midrule
\multirow{4}{*}{\rotatebox{90}{\small Reddit-TIFU}} 
& KGW & 99.3 / 97.5 / 98.1 & 94.1 / 87.2 / 87.2 & 91.7 / 67.2 / 67.6 & 79.5 / 22.8 / 43.3 & 82.8 / 27.6 / 49.7 & 84.1 / 27.3 / 50.9 & 79.8 / 19.3 / 41.3  & 85.3 / 41.9 / 56.7 \\
& SemStamp & \underline{99.7} / \underline{97.7} / \underline{98.2} & 98.4 / 92.8 / 95.4 & 98.0 / 89.0 / 92.9 & 90.2 / 56.2 / 70.5 & 93.9 / 71.8 / 82.3 & 87.7 / 47.5 / 58.2 & 87.4 / 43.8 / 55.9  & 92.6 / 66.9 / 75.9 \\
& Cosine-\textit{SimMark} (Ours) & 99.1 / 96.3 / 97.6 & \underline{98.9} / \underline{94.5} / \underline{96.4} & \underline{98.7} / \textbf{93.6} / \underline{96.1} & \textbf{98.5} / \textbf{91.6} / \textbf{96.0} & \textbf{98.5} / \textbf{91.7} / \textbf{95.5} & \underline{97.8} / \textbf{88.4} / \underline{94.7} & \underline{96.3} / \textbf{72.9} / \textbf{88.4}  & \underline{98.1} / \textbf{88.8} / \textbf{94.5} \\ 
& Euclidean-\textit{SimMark}\footnotemark[7] (Ours) & \textbf{99.8} / \textbf{98.7} / \textbf{99.2} & \textbf{99.0} / \textbf{94.7} / \textbf{97.6} & \textbf{99.0} / \underline{91.9} / \textbf{96.2} & \underline{97.8} / \underline{75.9} / \underline{89.5} & \underline{97.7} / \underline{76.4} / \underline{90.4} & \textbf{98.7} / \underline{83.7} / \textbf{95.2} & \textbf{96.8} / \underline{65.8} / \underline{87.3}  & \textbf{98.2} / \underline{81.4} / \underline{92.7} \\ 
\bottomrule
\end{tabular}
}
\vspace{-5pt} 
\caption{Performance of different algorithms across datasets and paraphrasers, evaluated using ROC-AUC$\uparrow$, TP@FP=1\%$\uparrow$ and TP@FP=5\%$\uparrow$, respectively, reported from left to right. Higher values indicate better performance across all metrics.  In each column, \textbf{bold} values indicate the best performance for a given dataset and metric, while \underline{underlined} values denote the second-best. \textit{SimMark} consistently outperforms or is on par with other state-of-the-art methods across datasets, paraphrasers, and it is the best on average.
}
\label{tab:performance}
\end{table*}

\begin{table}[t]
\small
\centering
\resizebox{0.46\textwidth}{!}{
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Algorithm} & \textbf{PPL$\downarrow$} & \textbf{Ent-3$\uparrow$} & \textbf{Sem-Ent$\uparrow$} \\ \midrule
No watermark       & 11.89                    & 11.43                    & 3.10                      \\
SemStamp           & 12.89                   & \textbf{11.51}                   & 3.17                      \\
$k$-SemStamp       & \underline{11.82}                    & 11.48                    & 3.11                      \\
Cosine-\textit{SimMark} (Ours) & 12.69                    & \underline{11.50}                    & \textbf{3.39}                      \\
Euclidean-\textit{SimMark}\footnotemark[7] (Ours) & \textbf{9.67}                       &   \underline{11.50}                      &  \underline{3.28}
\\ \bottomrule
\end{tabular}
}
\vspace{-5pt} 
\caption{Comparison of the quality of text generated using different watermarking algorithms on the BookSum dataset. For PPL metric, lower values indicate better quality, while higher values are better for  Ent-3 and Sem-Ent. \textit{SimMark} watermarking achieves quality comparable to no watermarking, demonstrating minimal impact on text quality.
}
\vspace{-5pt} 
\label{tab:quality}
\end{table}
\renewcommand*{\thefootnote}{\arabic{footnote}}
In this section, we evaluate the performance of our watermarking algorithm, \textit{SimMark}, across different datasets. Performance is assessed using the area under the receiver operating characteristic curve (ROC-AUC) and true positive rate (TP) at fixed false positive rates (FP) of 1\% and 5\%, (TP@1\%FP and TP@5\%FP). Higher values indicate better performance across all metrics. 

For dimensionality reduction, we trained a PCA model on 8000 samples from the RealNews subset of the C4 dataset \cite{c4}, reducing embedding dimensions from 768 to 16. After testing various principal component counts (ranging from 512 to 16), we found 16 to yield the best results. PCA improved robustness against paraphrasing attacks when Euclidean distance was used (except on the BookSum dataset) but consistently degraded performance when cosine similarity was employed across all datasets. During our experiments, we applied PCA wherever it enhanced performance. More details and the results of these experiments are summarized in Table~\ref{tab:pca} in Appendix \ref{appendix:ablation_pca}.

Across all experiments, the decay factor was set to $K=250$, as this value provided an optimal trade-off between performance under both non-paraphrased and paraphrased conditions (See Appendix \ref{appendix:K}). The threshold $\beta$ was determined programmatically during the detection (See Appendix \ref{appendix:estimate-AUC}) to achieve the specified FP rates (1\% or 5\%). The predefined intervals $[0.68, 0.76]$ for cosine similarity and $[0.28, 0.36]$ for Euclidean distance with PCA and $[0.4, 0.55]$ for Euclidean distance without PCA were found to be near-optimal.
While the intervals could have been further optimized for each dataset individually, we chose not to do so to demonstrate the general performance of our method. For additional details on the experimental environment refer to Appendix~\ref{appendix:eval-setting}.

\subsection{Models and Datasets}

To ensure comparability with prior works by \citet{semstamp, k-semstamp}, we also employed the same fine-tuned version of OPT-1.3B \cite{zhang2022opt}, that they used as our LLM\footnote{Used \href{https://huggingface.co/AbeHou/opt-1.3b-semstamp}{AbeHou/opt-1.3b-semstamp} model.}. For semantic embedding, we utilized the Instructor-Large model\footnote{Used \href{https://huggingface.co/hkunlp/instructor-large}{hkunlp/instructor-large} embedding model.} \cite{instructor}, as mentioned earlier. Following \citet{kgw}, sampling from the LLM was performed with a temperature of 0.7 and a repetition penalty of 1.05, while the minimum and the maximum number of generated tokens were set to 195 and 205, respectively. The maximum number of iterations for rejection sampling is set to 100, following \citet{semstamp, k-semstamp}.

In our experiments, we used the RealNews subset of the C4, the BookSum \cite{booksum}, and Reddit-TIFU \cite{tifu} datasets, as in \citet{semstamp}. 1000 samples from each dataset were chosen to analyze the detection results and the text quality. Each sample was segmented into sentences, with the first sentence serving as the \textit{prompt} to the LLM. 

We evaluated text quality after applying \textit{SimMark} using the following metrics:
\begin{itemize}[noitemsep, topsep=0pt]
    \item \textbf{Perplexity (PPL)}: Measures how surprising the text is to a larger LLM (OPT-2.7B \cite{zhang2022opt}). Lower values indicate higher quality.
    \item \textbf{Tri-gram Entropy (Ent-3)} \cite{ent-3}: To assess textual diversity via the entropy of the tri-grams distribution.
    \item \textbf{Semantic Entropy (Sem-Ent)} \cite{sem-ent}: Used to measure semantic informativeness and diversity of the text.
\end{itemize}
\renewcommand*{\thefootnote}{\fnsymbol{footnote}}
\footnotetext[7]{PCA is applied.}
\renewcommand*{\thefootnote}{\arabic{footnote}}
\subsection{Paraphrasing Attack}
To evaluate the robustness of \textit{SimMark}, we tested it against paraphrasing attacks using three models: Pegasus paraphraser\footnote{Used \href{https://huggingface.co/tuner007/pegasus_paraphrase}{tuner007/pegasus\_paraphrase} paraphrasing model.} \cite{pegasus}, Parrot paraphraser \cite{parrot}, and GPT-3.5-Turbo \cite{openai2022chatgpt}. \citet{kirchenbauerreliability} observed that prompting models to paraphrase entire texts often results in summarized outputs, with the summarization ratio worsening for longer inputs. To prevent such summarization, we adopted a sentence-by-sentence paraphrasing scheme, which also ensures our results are comparable to prior works such as \citet{semstamp, k-semstamp}. The quality of paraphrases was assessed using BertScore\footnote{Used \href{https://huggingface.co/microsoft/deberta-xlarge-mnli}{microsoft/deberta-xlarge-mnli} \cite{he2021deberta} model.} \cite{bertscore}, with all settings consistent with prior works of \citet{semstamp, k-semstamp}. The bottom part of Figure~\ref{fig:Overview} demonstrates the paraphrase attack and detection phase in more detail. Refer to Appendix \ref{appendix:prompt} to find the prompts used with GPT-3.5-Turbo.

We also included the results for the \textit{bigram} paraphrase attacks introduced by \citet{semstamp}, with identical settings (25 rephrases for each sentence, etc.). This type of attack involves generating multiple paraphrases for each sentence, and choosing the one that increases the likelihood of disrupting statistical signatures embedded in the text, especially for token-level watermarking algorithms \cite{semstamp}. While this type of attack significantly impacts most other models, \textit{SimMark} demonstrates greater robustness against it. We must highlight that direct comparisons to $k$-SemStamp are not entirely fair, as $k$-SemStamp relies on domain-specific clustering of semantic spaces, making it domain-dependent. In contrast, \textit{SimMark}, similar to SemStamp, is domain-independent. Still, \textit{SimMark} outperforms $k$-SemStamp in most cases across various datasets and metrics, further underscoring its universality and robustness.  

\subsection{Paraphrase+Drop Attack}
\begin{figure}[t]
    \centering
    \includegraphics[width=0.48\textwidth]{para_delete_results.pdf}
    \vspace{-15pt} 
    \caption{Detection results (ROC-AUC) under the Paraphrase+Drop Attack. Pegasus is used as the paraphraser. Here, 0 probability means no sentence is dropped, i.e., sentences are only paraphrased. \textit{SimMark} is more robust than SemStamp and $k$-SemStamp across varying sentence drop probabilities.}
    \vspace{-5pt}  
    \label{fig:auc_plot}
\end{figure}
To further evaluate the robustness of our method and its real-world applicability, we introduce a more challenging attack scenario, termed the \textit{Paraphrase+Drop Attack}. We argue that an adversary not only paraphrases the text but also drops sentences deemed redundant. This reflects common editing practices since LLMs are known for their tendency to generate lengthy outputs with redundancy, likely due to their imperfect reward modelling \cite{chiang2024over}.

To simulate this scenario, we first paraphrase the text using the method described in the previous subsection and then randomly drop sentences from the paraphrased text. This combined attack tests the resilience of \textit{SimMark} under more aggressive transformations that mimic real-world adversarial editing.

\subsection{Results \& Discussion}
We compared the performance of \textit{SimMark} against state-of-the-art watermarking algorithms through extensive experiments. Our primary baseline was SemStamp, a sentence-level semantic watermarking method. We also included $k$-SemStamp, an improvement over SemStamp tailored to specific text domains. Results for SemStamp, $k$-SemStamp, and other methods, including KGW and SIR, were extracted directly from \citet{k-semstamp}. 

Table~\ref{tab:performance} presents detection performance before and after paraphrasing attacks, while Table~\ref{tab:quality} provides text quality evaluation results. Our algorithm (the last two rows in each section) does not affect the text quality while being effective and consistently outperforming or matching other state-of-the-art methods, achieving the highest average performance across all paraphrasers and datasets. Notably, domain-independent \textit{SimMark} surpasses our primary baseline, SemStamp, and matches or exceeds the domain-dependent $k$-SemStamp. Refer to Appendix \ref{appendix:examples} for qualitative examples of \textit{SimMark}. 

A key aspect to consider is that the fine-tuning of SemStamp and $k$-SemStamp’s embedding model on text paraphrased by Pegasus likely contributes to its improved robustness against this specific paraphraser but may introduce bias. Additionally, the results for the Reddit-TIFU dataset were only available for SemStamp and not $k$-SemStamp, likely due to the dataset’s informal diverse text style and $k$-SemStamp's limitation for text to belong to a specific domain such as news articles or scientific writings~\cite{k-semstamp}.


Figure~\ref{fig:auc_plot} presents the detection performance (in terms of ROC-AUC) of \textit{SimMark}, $k$-SemStamp, and SemStamp against Paraphrase+Delete Attack under varying sentence drop probabilities, evaluated on the RealNews and BookSum datasets. The results demonstrate that \textit{SimMark} consistently achieves higher performance compared to other methods, even as the sentence drop probability increases. These findings underscore the robustness of \textit{SimMark} in handling more challenging real-world adversarial scenarios. 

Despite \citet{semstamp, k-semstamp} releasing their code and data, we were unable to reproduce their reported results fully. Consequently, there are minor discrepancies between our reproduction results (shown in Figure~\ref{fig:auc_plot} for the case with zero probability) and those presented in Table~\ref{tab:performance}, which were extracted directly from their paper. Notably, the results for $k$-SemStamp on the BookSum dataset differed substantially, leading us to exclude them from Figure~\ref{fig:auc_plot}. Additionally, the results reported in Table~\ref{tab:quality} (our reproduction) also show slight differences from their paper, likely due to hyperparameter details that were not explicitly documented.


Regarding sampling efficiency, for BookSum dataset for instance, cosine-\textit{SimMark} required an average of 7.1 samples per sentence from the LLM, compared to $k$-SemStamp and SemStamp, which averaged 13.3 and 20.9 samples, respectively \cite{k-semstamp}. This demonstrates that our method not only outperforms these baselines but is also significantly (about 2-3 times) more efficient. Further analysis of this, including theoretical estimates is provided in Appendix~\ref{appendix:sampling-efficiency}.

\section{Conclusion} \label{conclusion}
In this paper, we introduced {\textit{SimMark}}, a similarity-based, sentence-level posthoc watermarking algorithm. Unlike existing approaches, \textit{SimMark} operates without requiring access to the internal logits or architecture of the model, ensuring compatibility with a wide range of LLMs, including API-only models. By utilizing a general-purpose sentence embedding model and integrating a \textit{soft} counting mechanism, \textit{SimMark} combines robustness against paraphrasing with applicability to diverse domains. Furthermore, its resistance to reverse engineering ensures resilience against spoofing attacks. Experimental results show that \textit{SimMark} outperforms state-of-the-art watermarking algorithms, such as SemStamp, in both efficiency and robustness to adversarial paraphrasing, representing a significant step forward in practical watermarking techniques for LLM-generated content.
Due to space constraints, the discussion of the future directions is deferred to Appendix \ref{appendix:future}.


% Acknowledgements should only appear in the accepted version.
\section*{Acknowledgements}
This work was supported by the NSERC Discovery Grant No. RGPIN-2019-05448.
% \textbf{Do not} include acknowledgements in the initial version of
% the paper submitted for blind review.

% If a paper is accepted, the final camera-ready version can (and
% usually should) include acknowledgements.  Such acknowledgements
% should be placed at the end of the section, in an unnumbered section
% that does not count towards the paper page limit. Typically, this will 
% include thanks to reviewers who gave useful comments, to colleagues 
% who contributed to the ideas, and to funding agencies and corporate 
% sponsors that provided financial support.

\section*{Impact Statement\footnote{Generative AI tools, such as ChatGPT \cite{openai2022chatgpt}, were used to refine this manuscript. The authors retain full responsibility for all content presented in the paper, ensuring adherence to academic integrity and ethical research practices.}}
By enabling robust detection of LLM-generated text, particularly under paraphrasing attacks, \textit{SimMark} addresses ethical concerns surrounding the transparency and accountability of AI-generated content. However, like any watermarking method, there are potential risks, such as falsely implicating human authors or adversaries developing more advanced techniques for spoofing attacks or bypassing detection. 

We acknowledge these limitations and advocate for the responsible deployment of such tools in combination with other verification mechanisms to mitigate these risks and ensure ethical, fair deployment. The primary goal of this work is to advance research in watermarking techniques to support the responsible use of LLMs. We believe that the societal impacts and ethical considerations of our work align with those outlined in \citet{weidinger2021ethical}.

\newpage

\bibliographystyle{icml2025}
\bibliography{anthology}

\newpage
\appendix
\section{Future Work}   \label{appendix:future}
While \textit{SimMark} demonstrates outstanding performance, there are still some areas that warrant further exploration:

\textbf{Reduce Rejection Sampling Overhead.} The rejection sampling process requires generating multiple candidate sentences until a valid sentence is accepted. Although our method is 2-3 times more efficient than prior approaches such as SemStamp and $k$-SemStamp, there is still a notable decrease in generation speed due to rejection sampling. Techniques like batch sampling or parallel sampling could potentially mitigate this issue, though at the expense of higher computational resource usage. Future research should focus on optimizing these methods to balance efficiency and resource requirements.

\textbf{Improve Resistance to More Advanced Attacks.} Although \textit{SimMark} is robust against paraphrasing attacks to some extent, more advanced text transformations (e.g., sentence splitting and merging, semantic reordering) may still pose challenges. Additionally, our detection algorithm may struggle when watermarked text is mixed into a larger body of human-written content. Further research is needed to enhance resilience against a broader range of adversarial transformations.

\textbf{Setting the Interval Dynamically.} In our experiments, we used consistent predefined intervals across all datasets and observed consistently strong performance.
Notably, we did not observe any degradation in text quality due to this interval constraint during rejection sampling (as shown in Table~\ref{tab:quality}), likely because the constraint applies only to consecutive sentences. Nonetheless, slight variations in the embeddings similarity distribution of LLM-generated text across different models and domains may impact watermarking effectiveness. Adaptive strategies for setting these intervals dynamically (or pseudo-randomly) could not only improve performance but also make reverse-engineering the algorithm even more difficult.

\section{Examples of Watermarked Text} \label{appendix:examples}
Figures~\ref{fig:ex1} and~\ref{fig:ex2} provide examples of text generated with and without the \textit{SimMark} watermark. These examples illustrate the imperceptibility of the watermark to human readers while enabling robust detection through our proposed algorithm. They also highlight \textit{SimMark}'s robustness to paraphrasing while maintaining quality comparable to non-watermarked text.  

\begin{figure*}[!h]
    \centering
    \includegraphics[page=3, width=0.97\linewidth]{figures_cropped.pdf}
    \caption{Example of text generated with and without cosine-\textit{SimMark} using the RealNews dataset. The first sentence (in black) is the prompt for the model, the \textcolor{ForestGreen}{green} sentences are \textcolor{ForestGreen}{valid}, and \textcolor{Red}{red} sentences are \textcolor{Red}{invalid/partially valid}. Numbers in parentheses represent the \textit{soft count} for partially valid sentences. The top panel shows non-watermarked text, which fails to produce a significant detection signal (\( z_{\text{soft}} = 0.14 \; \textcolor{Red}{<} \; 5.033 \), false negative). The middle panel demonstrates text generated using \textit{SimMark} with cosine similarity-based watermarking, producing a strong detection signal (\( z_{\text{soft}} = 9.48 \; \textcolor{ForestGreen}{>} \; 5.033 \)). The bottom panel shows paraphrased watermarked text using GPT-3.5-Turbo, where the embedded watermark remains detectable despite semantic alterations (\( z_{\text{soft}} = 6.94 \; \textcolor{ForestGreen}{>} \; 5.033 \)).}
    \label{fig:ex1}
\end{figure*}

\begin{figure*}[h]
    \centering
    \includegraphics[page=4, width=0.97\linewidth]{figures_cropped.pdf}
    \caption{Example of text generated with and without Euclidean-\textit{SimMark} using the BookSum dataset. The first sentence (in black) is the prompt for the model, the \textcolor{ForestGreen}{green} sentences are \textcolor{ForestGreen}{valid}, and \textcolor{Red}{red} sentences are \textcolor{Red}{invalid/partially valid}. Numbers in parentheses represent the \textit{soft count} for partially valid sentences. The top panel shows the non-watermarked text, which fails to produce a significant detection signal (\( z_{\text{soft}} = -1.07 \; \textcolor{Red}{<} \; 4.13 \), false negative). The middle panel demonstrates text generated using \textit{SimMark} with Euclidean distance-based watermarking, producing a strong detection signal (\( z_{\text{soft}} = 13.07 \; \textcolor{ForestGreen}{>} \; 4.13 \)). The bottom panel shows paraphrased watermarked text using GPT-3.5-Turbo, where the embedded watermark remains detectable despite semantic alterations (\( z_{\text{soft}} = 11.99 \; \textcolor{ForestGreen}{>} 
\; 4.13 \)).}
    \label{fig:ex2}
\end{figure*}


\section{Ablation Study on Soft Count Smoothness Factor $K$} \label{appendix:K}
\begin{table*}[h]
\centering
 \resizebox{0.98\textwidth}{!}{
\begin{tabular}{llcc|cc} 
\toprule 
\textbf{Count Method} & \textbf{K} & \textbf{cosine-\textit{SimMark}} & \textbf{Paraphrased cosine-\textit{SimMark}} & \textbf{Euclidean-\textit{SimMark}} & \textbf{Paraphrased Euclidean-\textit{SimMark}} \\
\midrule 
\multirow{4}{*}{Soft Count} & 50 & 99.0 / 89.2 / 97.2 & \underline{98.6} / 78.5 / 96.5 & \underline{99.4} / 91.2 / 98.1 & 96.9 / 49.3 / 87.9 \\
& 150 & \underline{99.6} / \underline{95.7} / \underline{98.8} & \textbf{99.2} / 88.7 / \textbf{98.2} & \textbf{99.8} / \underline{97.6} / \underline{99.3} & \textbf{97.3} / 67.8 / \textbf{90.4} \\
& 250 & \textbf{99.7} / \textbf{96.9} / \underline{98.8} & \textbf{99.2} / \underline{90.3} / \textbf{98.2} & \textbf{99.8} / \textbf{98.5} / 99.2 & \underline{97.2} / \textbf{72.3} / \underline{88.9} \\
& 350 & \textbf{99.7} / \textbf{96.9} / \textbf{98.9} & \textbf{99.2} / \textbf{90.4} / \underline{98.1} & \textbf{99.8} / \textbf{98.5} / \textbf{99.4} & \underline{97.2} / \underline{71.1} / \underline{88.9} \\ 
\midrule
\multirow{1}{*}{Regular Count}
& $\infty$ & 99.7 / 97.2 / 99.1 & 99.1 / 88.7 / 97.6 & 99.8 / 98.5 / 99.7 & 97.0 / 70.0 / 88.2 \\ 
\bottomrule 
\end{tabular}
}
\caption{Ablation study on the smoothness factor \( K \) in soft counting (Eq.~\eqref{eq:count_formula}) using the RealNews dataset, with Pegasus as the paraphraser. Metrics reported include ROC-AUC$\uparrow$, TP@FP=1\%$\uparrow$, and TP@FP=5\%$\uparrow$, from left to right. The last row (\( K = \infty \)) corresponds to regular counting with a step function in the interval \([a, b]\). A smoothness factor of \( K=250 \) provides a good balance between performance before and after paraphrase attacks for both cosine-\textit{SimMark} and Euclidean-\textit{SimMark}. Notably, while soft counting slightly reduces performance in the absence of paraphrasing, it demonstrates enhanced robustness against paraphrasing, yielding an increase across all metrics for Pegasus paraphraser and potentially larger gains against more advanced paraphrasers.}
\label{tab:K}
\end{table*}
In this section, we analyze the impact of the smoothness factor \( K \) on the performance of \textit{SimMark}. Recall that \( K \) controls the degree of smoothness in the soft counting mechanism as defined in Eq.~\eqref{eq:count_formula}. A larger \( K \) makes the soft counting function behave more like a step function, while smaller values provide smoother transitions between valid and invalid sentences.

Table~\ref{tab:K} presents the results of this ablation study, conducted on the RealNews dataset with Pegasus as the paraphraser. Metrics include ROC-AUC, TP@FP=1\%, and TP@FP=5\%. Higher values indicate better performance across all metrics. The results demonstrate the following trends:
\begin{itemize}[noitemsep, topsep=0pt]
    \item A smoothness factor of \( K=250 \) provides a good trade-off, achieving strong performance both before and after paraphrasing attacks for both cosine-\textit{SimMark} and Euclidean-\textit{SimMark}.
    \item For \( K=\infty \), corresponding to regular counting with a step function, the performance is slightly higher in the absence of paraphrasing but significantly degrades under paraphrasing attacks, highlighting the benefits of soft counting in adversarial scenarios.
\end{itemize}

These findings confirm that soft counting loses a small amount of performance when no paraphrasing is applied, but it gains substantial robustness under paraphrasing. For example, TP@FP=1\% improves by 1.6–2.3\% for Pegasus-paraphrased text when \( K=250 \), and the improvement is likely to be even more significant for stronger paraphrasers.

\section{Ablation Study on Impact of PCA} \label{appendix:ablation_pca}
Table \ref{tab:pca} presents the results of an ablation study investigating the impact of applying PCA to reduce the dimensionality of sentence embeddings across the RealNews, BookSum, and Reddit-TIFU datasets. Metrics include ROC-AUC, and TP at fixed FP rates (FP=1\% and FP=5\%). Higher values indicate better performance across all metrics, with PCA applied to embeddings to explore its effect on detection accuracy and robustness. 

The results reveal that the effect of PCA depends on the choice of similarity measure. For \textit{Euclidean distance-based SimMark}, applying PCA generally improves robustness against paraphrasing attacks across most datasets, except for the BookSum dataset. This improvement likely arises because reducing dimensionality helps mitigate noise in the embeddings, especially after paraphrase attack. 

On the other hand, for \textit{cosine similarity-based SimMark}, applying PCA reduces performance across all datasets. This reduction may be due to PCA altering the embeddings in a way that disrupts the angular relationships critical for cosine similarity calculations. These findings highlight the importance of adapting PCA usage based on the similarity measure employed to achieve optimal watermarking performance.
\begin{table}[t]
\small
\centering
\resizebox{0.48\textwidth}{!}{
\begin{tabular}{@{}clcc@{}}
\toprule
\textbf{Dataset} & \textbf{Configuration}   & \textbf{No paraphrase} & \textbf{Pegasus} \\ 
\midrule
\multirow{4.5}{*}{\rotatebox{90}{RealNews}} 
& Cosine-\textit{SimMark} (No PCA)                 & \textbf{99.7} / 96.9 / 98.8                      & \textbf{99.2} / \textbf{90.3} / \textbf{98.2}                                             \\
& Cosine-\textit{SimMark} (PCA)                     & 99.6 / 96.9 / \textbf{99.1}                      & 92.1 / 33.8 / 71.2                                             \\
\cmidrule{2-4}
& Euclidean-\textit{SimMark} (No PCA)               & 99.4 / 92.6 / 98.4                      & 90.5 / 19.7 / 58.0                                              \\
& Euclidean-\textit{SimMark} (PCA)                 & \textbf{99.8} / \textbf{98.5} / \textbf{99.2}                      & \textbf{97.2} / \textbf{72.3} / \textbf{88.9}                                             \\ 
\midrule 
\multirow{4.5}{*}{\rotatebox{90}{BookSum}} 
& Cosine-\textit{SimMark} (No PCA)            & 99.8 / 98.8 / 99.5                      & \textbf{99.5} / \textbf{93.3} / \textbf{98.5}                                              \\
& Cosine-\textit{SimMark} (PCA)               & \textbf{100} / \textbf{99.9} / \textbf{99.9}                     & 98.7 / 87.3 / 95.1                                              \\ 
\cmidrule{2-4}
& Euclidean-\textit{SimMark} (No PCA)         & \textbf{100} / \textbf{100} / \textbf{100}                      & \textbf{98.8} / \textbf{82.6} / \textbf{94.9}                                             \\
& Euclidean-\textit{SimMark} (PCA)            & 99.9 / 99.3 / 99.5                     & 97.4 / 69.8 / 88.6                                              \\ 
\midrule 
\multirow{4.5}{*}{\rotatebox{90}{\small Reddit-TIFU}} 
& Cosine-\textit{SimMark} (No PCA)              & 99.1 / 96.3 / 97.6          & \textbf{98.9} / \textbf{94.5} / \textbf{96.4} \\
& Cosine-\textit{SimMark} (PCA)              & \textbf{99.7} / \textbf{98.8 }/ \textbf{99.3}                      & 96.6 / 78.9 / 89.3  \\
\cmidrule{2-4}
& Euclidean-\textit{SimMark} (No PCA)              & 99.6 / 98.1 / 99.1                      & 96.7 / 72.6 / 90.0 \\
& Euclidean-\textit{SimMark} (PCA)              & \textbf{99.8} / \textbf{98.7} / \textbf{99.2}                      & \textbf{99.0} / \textbf{94.7} / \textbf{97.6} \\
\bottomrule
\end{tabular}
 }
\caption{Ablation study on the impact of applying PCA to embeddings across three datasets. Metrics reported include ROC-AUC$\uparrow$, TP@FP=1\%$\uparrow$, and TP@FP=5\%$\uparrow$, respectively, from left to right. Higher values indicate better performance across all metrics. For cosine-\textit{SimMark}, not applying PCA yields better results, while for Euclidean-\textit{SimMark}, applying PCA improves performance except on the BookSum dataset.}
\label{tab:pca}
\end{table}

\section{Finding an Optimal Interval} \label{appendix:optimal_interval}
Figure~\ref{fig:dist_of_distances} shows the distribution of distances between embeddings of consecutive sentences for both human and LLM-generated text, calculated on a sample of size 1000 from the BookSum dataset (no PCA applied to the embeddings in this case). A small but noticeable distribution shift between the two can be observed. Based on this, the interval \([0.4, 0.55]\) appears to be a reasonable choice for \textit{SimMark} watermarking in this case.  

It is important to note that changes to the embedding representations, such as applying PCA or using a different embedding model, will lead to altered distance distributions. Consequently, the interval must be adjusted accordingly to maintain optimal performance. For instance, if PCA is applied, the interval \([0.28, 0.36]\) is suitable. Similarly, if we plot the figure for when cosine similarity is used instead of Euclidean distance, intervals \([0.81, 0.94]\)  and \([0.68, 0.76]\) are good candidates for cases with and without PCA, respectively. This variability in the distance distributions also strengthens the algorithm's resistance to reverse engineering.

Selecting the optimal interval \([a, b]\) is a critical step in achieving a robust and reliable watermarking with \textit{SimMark}. In general, selecting an optimal interval involves balancing low FP rates, high TP rates, and robustness against paraphrasing attacks. It is often beneficial to choose intervals toward the tails of the distribution rather than around the mean. Finally, further exploration of dynamic interval selection mechanisms could enhance \textit{SimMark}'s robustness.

\begin{figure}[H]
    \centering
\includegraphics[width=0.99\linewidth]{dist_of_distances.pdf}
    \caption{Distribution of Euclidean distances between embeddings of consecutive sentences for \textcolor{Salmon}{human-written} and \textcolor{SeaGreen}{LLM-generated} text on the BookSum dataset, generated using OPT-1.3B. The figure demonstrates that the interval $[0.4, 0.55]$ is a reasonable choice for Euclidean-\textit{SimMark} in this case, though it is not necessarily the only viable option.}
    \label{fig:dist_of_distances}
\end{figure}
\section{Computing Threshold \( \beta \) for \textit{soft}-$z$-test} \label{appendix:estimate-AUC}
Recall that a text is classified as LLM-generated when \textcolor{ForestGreen}{$z_\mathrm{soft} > \beta,$} and as human-written otherwise. $z_\mathrm{soft}$ is the statistic used in the statistical test described in Eq. \eqref{eq:z_formula2}. To determine the threshold \( \beta \) that limits the FP rate to 1\% or 5\%, we first need to estimate \( p_0 \), the probability that the consecutive embeddings' similarity or distance falls within the predefined interval \([a, b]\). This value of \( p_0 \) is a key component in calculating the $z_\mathrm{soft}$, as it represents the proportion of valid sentences in human-written text under the given interval. \( p_0 \) serves as an indicator of how frequently valid sentences are expected to occur in human-written text.

To compute \( p_0 \), we analyze the distribution of similarities (or distances) using a histogram approach, such as the one depicted in Figure~\ref{fig:dist_of_distances}. Specifically, we employ a binning technique to approximate the area under the curve of distribution in the interval \([a, b]\). The process involves dividing the entire range of distances or similarities into a fixed number of bins—1000 bins in our implementation. Each bin represents a small segment of the range, and the histogram is used to calculate the proportion of samples that fall within the interval \([a, b]\).

Mathematically, \( p_0 \) is estimated as:
\[
\small
p_0 = \frac{\text{Number of samples in bins corresponding to } [a, b]}{\text{Size of the dataset}},
\]

Once \( p_0 \) is estimated, the detection threshold \( \beta \) is determined by iterating over a range of possible values, typically from -10 to 10, to find the one that results in the desired false positive rate. Specifically, the threshold is chosen such that the proportion of human-written texts misclassified as LLM-generated matches the target FP rate (e.g., 1\% or 5\%). 


It is worth noting that the distribution of similarities or distances may vary depending on different factors such as embedding model, and similarity measure (e.g., cosine or Euclidean). As a result, \( p_0 \) and therefore \( \beta \) are determined programmatically during the detection to ensure reliable performance of the watermarking algorithm.


\section{Analysis of Sampling Efficiency} \label{appendix:sampling-efficiency}

The average number of samples required to generate a valid sentence is influenced by the chosen interval \([a, b]\). To provide further insights into this relationship, we estimated the area under the curve (AUC) of the embedding similarity distribution for an unwatermarked LLM. Specifically, for the interval \([0.68, 0.76]\) (for cosine-\textit{SimMark}), the estimated AUC is approximately \( 0.194 \). 

Using the mean of the geometric distribution, which is given by \( \frac{1}{p} \), where \( p \) is the probability of success (in this case, the probability of falling within the interval), this translates to an expected average of $\frac{1}{0.194} \approx 5.1$ samples per valid sentence. This estimate is on par with the experimental results observed in our study. The AUC estimates were computed using the binning technique, as described in Appendix \ref{appendix:estimate-AUC}.

This analysis underscores the importance of carefully selecting the interval \([a, b]\), as narrower intervals may increase the number of required samples, leading to reduced sampling efficiency but better performance, while broader intervals may compromise the effectiveness of the watermark. By understanding the interplay between the interval choice and sampling efficiency, we can better optimize \textit{SimMark}'s performance for different embedding models.


\section{Experimental Environment} \label{appendix:eval-setting}
The majority of the experiments, including text generation and detection tasks, were conducted on a workstation equipped with an Intel Core i9 processor, 64GB of RAM, and an Nvidia RTX 3090 GPU with 24GB of VRAM. Some of the experiments involving bigram paraphrasing were performed on compute nodes with Nvidia V100 GPU with 32GB of VRAM.

\section{Prompts Used with GPT-3.5-Turbo} \label{appendix:prompt}
 Table \ref{tab:prompts} presents the prompts we used to obtain paraphrases using GPT-3.5-Turbo (accessed via OpenAI API\footnote{\href{https://platform.openai.com/docs/api-reference}{https://platform.openai.com/docs/api-reference}}) for both regular paraphrasing and more aggressive bigram paraphrasing attacks. By using the same prompts as \citet{semstamp}, we ensured that our results were directly comparable to those extracted from their paper, maintaining consistency in evaluation methodology.
\begin{table}[h]
    \centering
    \small
    \begin{tabular}{p{7cm}}
    \hline
    \multicolumn{1}{c}{\textbf{Prompt for Regular Attack}} \\
    \hline
    \texttt{Previous context: \{context\} \textbackslash n Current sentence to paraphrase: \{sent\}} \\
    \hline
    \multicolumn{1}{c}{\textbf{Prompt for Bigram Attack}} \\
    \hline
    \texttt{Previous context: \{context\} \textbackslash n Paraphrase in \{num\_beams\} different ways and return a numbered list: \{sent\}} \\
    \hline
    \end{tabular}
    \caption{Prompts used to generate paraphrases with GPT-3.5-Turbo for regular and bigram attacks. These are the same prompts used by \citet{semstamp} for consistent and comparable evaluation. Here, \texttt{sent} represents the target sentence to rephrase, \texttt{context} includes all preceding sentences, and \texttt{num\_beams} specifies the number of paraphrases generated for the bigram attack. A higher \texttt{num\_beams} value indicates a more aggressive attack.}
    \label{tab:prompts}
\end{table}
\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
