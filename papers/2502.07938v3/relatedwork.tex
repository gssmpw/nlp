\section{Related Work}
This section reviews relevant embedding models that support Luxembourgish semantic search, including monolingual Luxembourgish models and multilingual embeddings.


\citet{reimers-gurevych-2020-making} use knowledge distillation through a strong paraphrase-trained English embedding model and parallel data to create cross-lingually aligned models. Multiple instances of such models have been open sourced and a particularly powerful and popular one is \textit{paraphrase-multilingual-mpnet-base-v2} (\textbf{M-MPNet}) which was trained on over 50 languages. Later within this work, we will explain how we extend this model to also support Luxembourgish.

The multilingual bitext mining model \textbf{LaBSE} \citep{feng-etal-2022-language} is trained with translation ranking loss and negative samples.  It has been trained roughly on less than 100 Luxembourgish-English sentence pairs and specializes in zero-shot bitext mining. 

A recent model is GTE Multilingual (\textbf{M-GTE}) \citep{zhang-etal-2024-mgte}, a multilingual embedding model designed for long context text representation and reranking.  \textit{M-GTE} has been trained with hard negatives and has included 50,000 Luxembourgish pairs within its contrastive pre-training.

Specific model adaptations to Luxembourgish have also been developed. One example is \textbf{LuxemBERT} \citep{lothritz-etal-2022-luxembert}, a monolingual BERT model pre-trained for Luxembourgish using augmented data, partially generated by translating texts from closely related languages and incorporating relevant text sources. 

Closely related to our work, \textbf{LuxEmbedder} \citep{philippy-etal-2025-luxembedder} used OpenAI's \textit{text-embedding-3-small} and \textit{LaBSE} to mine a set of parallel sentences for each pair of languages between Luxembourgish, English, and French. These parallel sentences (up to 20,000 per pair) were then used to further fine-tune \textit{LaBSE}, improving performance on modern Luxembourgish evaluation sets. However, its ability to handle Luxembourgish texts from different historical periods---potentially affected by digitization errors common in large-scale historical text collections, remains unclear.

Our work aims to extend existing embedding models to better perform cross-lingual semantic search within a collection of historical, OCR-noisy Luxembourgish texts. The conditions of these texts combined with the different spelling variations\footnote{Luxembourgish had no standardized spelling until 1946 and underwent multiple further reformations (eg. in 1999)} poses an interesting generalization challenge to the models.