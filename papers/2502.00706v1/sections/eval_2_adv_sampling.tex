\subsection{Reducing Query Complexity}
\label{sec:eval:online}

%
Certain pre-trained models from \bencho and \bencht exhibit a high degree of similarity when comparing their output tokens generated from random prompts.
Table~\ref{tab:eval:similarity_pre_train} of Appendix~\ref{sec:appendix:tables} presents the top $5$ most similar model pairs from \bencht, measured by the percentage of matching output tokens when tested on 1,000 random prompts (column $k=1$).

To reduce the online complexity, we implement an advanced rejection prompt sampling strategy as detailed in Section~\ref{sec:query}. 
%
%
We evaluate this strategy using different parameter values $k=4,16,$ and $64$ (recall, $k$ defines how many random samples are used to produce one selected sample), comparing it to the standard provenance testing without rejection ($k=1$).

Table~\ref{tab:eval:similarity_pre_train} demonstrates how the percentage of matching tokens changes with rejection sampling (columns $k=4,16,$ and $64$). For example, the most similar pair of models shows a reduction in matching output tokens from $64\%$ ($k=1$) to merely $16\%$ ($k=64$), indicating that rejection sampling significantly reduces token overlap between models. This improvement directly enhances the efficiency of provenance testing by reducing the tester's online complexity.



\begin{figure}[t]
  \includegraphics[width=8cm]{plots/recall_online_small.png}
  \caption{Recall for \bencht with different values of advanced prompt sampling defined with $k$.}
  \label{fig:eval:online_recall}
\end{figure}
Figure~\ref{fig:eval:online_recall} compares the tester's recall across different values of $k$. Notable improvements are visible even at $k=4$, with higher values of $k$ showing better results (though with diminishing returns). Specifically, the recall achieved with $1,000$ prompts at $k=1$ can be matched using only about $250$ prompts at $k=64$, representing a four-fold reduction in online complexity. %
Figure~\ref{fig:eval:online_full} provides
a comprehensive comparison between $k=1$ and $k=64$ for both precision and recall across both benchmarks, using $4-5$ times fewer queries for $k=64$ 
(note, in Figure~\ref{fig:eval:online_full} the number of prompts for $k=64$ are given at the top of the plots). 
The results demonstrate that the tester maintains its effectiveness despite the significant reduction in queries to the tested models. 
For example, advanced prompt sampling achieves high levels of $90-95$\% precision and $80-90$\% recall while reducing the required number of prompts from $3,000$ to just $500$ per model.
\begin{figure}[t]
    \centering
    \subfigure
    {
        \includegraphics[width=8cm]{plots/online_full_large.png}
    }
    \subfigure
    {
        \includegraphics[width=8cm]{plots/online_full_small.png}
    }
    \caption{Comparison of precision/recall for \bencht (top) and \bencht (bottom) when advanced online prompt sampling with $k=64$  uses four times less prompts than no advanced sampling ($k=1$). }
    \label{fig:eval:online_full}
\end{figure}


