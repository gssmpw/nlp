\section{Related Work}
\paragraph{LGT and HGT Detection.}
Past efforts to identify LLM-generated texts (LGTs) often relied on binary classification systems that distinguish human-generated texts (HGTs) from LGTs using surface-level features. While these methods were initially effective, they are prone to errors when encountering adversarial attacks or domain shifts, which limit their overall robustness____. To address these limitations, researchers have explored strategies that integrate external knowledge, such as combining internal and external factual structures, to boost detection against diverse content and styles____. Recent studies also highlight the promise of using the LLMs themselves for text detection: approaches like self-detection and mutual detection can outperform traditional classifiers, as illustrated by GPT-4's success in tasks like plagiarism detection____. Notably, smaller models sometimes excel in zero-shot scenarios, offering adaptable solutions across varying architectures____. Furthermore, ____ demonstrated that LLMs can reliably identify their own outputs, providing a more nuanced framework for content verification. Despite these advances, the continuing challenges of domain adaptation and adversarial resistance underscore the need for more versatile and robust detection systems.



\textbf{Explainability in Detection Models.}
Recent work on LGT detection has focused on improving explainability. ____ proposed to incorporate factual consistency into detection models to enhance their interpretability, while____ explored mixed-initiative approaches that combine human expertise with automated models for better detection. These studies have made significant contributions to the field; however, they either depend heavily on expert input____ or lack integration of explanation generation within the model itself____. Our approach, in contrast, enables LLMs to autonomously generate both predictions and detailed explanations, making it a more scalable and transparent solution for detecting machine-generated content.

\textbf{Ternary Classification.}
Traditional binary classification methods, distinguishing between LGTs and HGTs, face limitations when texts exhibit characteristics that are ambiguous or could plausibly originate from either source. In such cases, adding an ``Undecided'' category provides a more nuanced framework for detection. This approach has several advantages over previous methods, which typically focus on mixed human-machine texts and fail to account for uncertainties in text origin. For instance, the work by____ revealed that current detectors struggle to identify ``mixed text'', particularly in cases where subtle modifications and style adaptability blur the distinction. Similarly, the Turing test conducted on online reviews____ showed that even humans often cannot reliably distinguish between human-written and AI-generated content, pointing to the inherent difficulties in binary classification. Moreover, studies such as____ and ____ further underscore the complexity in distinguishing between the two, suggesting that an ``Undecided'' class could allow for better handling of such ambiguity. Incorporating this third category not only enhances detection accuracy but also improves explainability, offering clearer insights into the decision-making process.