\section{Introduction}

The rapid advancement of large language models (LLMs) in multi-turn dialogue systems has elevated instruction-following capabilities to a pivotal research frontier in human-AI interaction~\cite{chang2024survey}.
Current evaluation methodologies bifurcate into two streams: multi-turn dialogue evaluations focusing on capability evaluation~\cite{zheng2023judging,bai-etal-2024-mt,kwan-etal-2024-mt} and instruction-following analyses emphasizing fine-grained constraint compliance~\cite{jiang-etal-2024-followbench,he2024can,zhang2024cfbench}. 
More recent research has started to model the composition of intra-turn constraints~\cite{wen2024benchmarking}.

However, current evaluation methodologies treat multi-turn dialogues as simple concatenations of single-turn interactions, neglecting users' planning and intentionality in extended conversations.
This leads to three critical limitations: (1) Failure to model complex scenarios: Multi-turn dialogue data constructed with simplistic linear thinking cannot accurately capture key characteristics of real-world complex conversations, such as logical coherence, user goal clarity, and natural transitions.
(2) Methodological bias: Single-turn evaluation strategies fragment inter-turn structural connections, overlooking multi-turn structural constraints.
(3) Analytical deficiency: Existing approaches overemphasize intra-turn-level constraint compliance while lacking a systematic framework to characterize dialogue structural flow.

\begin{figure}[t!]
    \captionsetup{skip=0pt}
	\centering
	\includegraphics[width=\linewidth]{figures/structural_flow_revised.pdf}
	\caption{The Structural Flow Taxonomy includes six fundamental structures, each used to describe the inter-turn relationships in multi-turn dialogues. It can be applied to analyze any dialogue and generate specific structural flows.}
	\label{fig:intro}
\end{figure}

To bridge these gaps, we introduce \textbf{StructFlowBench}, a novel instruction-following benchmark integrating a multi-turn structural flow framework. 
It consists of two key components: 1) \textbf{Dual-constraint evaluation system}, which combines 8 intra-turn instruction constraints with 5 newly proposed structural constraints, enabling a more comprehensive assessment of multi-turn dialogue instruction following capabilities of LLMs. 
These structural constraints account for inter-turn dependencies, ensuring that models are evaluated not only on their ability to satisfy individual constraints but also on their capacity to maintain logical coherence across multiple turns.
2) \textbf{Six-category structural flow taxonomy}, encompassing six fundamental inter-turn relationships: \textit{Follow-up, Refinement, Recall, Summary, Expansion, Unrelatedness}.
The illustration of the structural flow taxonomy and an example of the structural flow are presented in Figure~\ref{fig:intro}.
This taxonomy serves a tripartite function: (a) \textbf{Diagnostic evaluation:} It enables a structured analysis of cross-turn structural rationality, helping to identify inconsistencies in dialogue flow and ensuring that model responses align with the expected discourse structure.
(b) \textbf{Intent inference:} By analyzing structural patterns, this taxonomy facilitates the extraction of implicit user intent, offering a deeper understanding of how instructions evolve over multiple turns.
(c) \textbf{Controlled generation:} The taxonomy provides configurable structural parameters that guide task-specific dialogue simulation, allowing for the tailored generation of multi-turn conversations with predefined structural patterns.
This not only enhances dataset diversity but also supports the development of more robust instruction-following models adaptable to varied real-world applications.

We summarize our contributions as follows: 
\vspace{-.1in}
\begin{itemize}
    \setlength{\itemsep}{0pt}
    \setlength{\parskip}{0pt}
    \item \textbf{Structural Flow Taxonomy}: We propose a six-category structured taxonomy for multi-turn instruction-following evaluation, offering an interpretable framework for analyzing dialogue structural flow.
    \item \textbf{StructFlowBench}: We introduce StructFlowBench, a structurally annotated multi-turn benchmark that leverages a structure-driven generation paradigm to enhance the simulation of complex dialogue scenarios.
    \item \textbf{Comprehensive LLM evaluation}: We systematically evaluate 13 state-of-the-art LLMs (3 closed-source and 10 open-source), unveiling disparities in structural processing capabilities and providing empirical insights for optimizing dialogue systems.
\end{itemize}
