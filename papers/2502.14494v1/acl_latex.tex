% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{booktabs}  % 让表格更美观
\usepackage{pifont}    % 提供 \xmark (×)
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\usepackage{array}     % 控制表格列格式
\usepackage{boldline}  % 额外的加粗线条


% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{StructFlowBench: A Structured Flow Benchmark for Multi-turn Instruction Following}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{
        Jinnan Li$^{1,5}$ \quad Jinzhe Li$^{2}$ \quad Yue Wang$^{3}$ \quad  Yi Chang$^{1,4,5}$\footnotemark[1] \quad Yuan Wu$^{1}$\footnotemark[1] \\
        $^{1}$School of Artificial Intelligence, Jilin University \\
        $^{2}$College of Computer Science and Technology, Jilin University \\ 
        $^{3}$School of Information and Library Science, University of North Carolina at Chapel Hill \\
        $^{4}$Engineering Research Center of Knowledge-Driven Human-Machine Intelligence, MOE, China \\
        $^{5}$International Center of Future Science, Jilin University\\
        \{jnli23, lijz2121\}@mails.jlu.edu.cn, wangyue@email.unc.edu, \\
        yichang@jlu.edu.cn, yuanwu@jlu.edu.cn \\   
}

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\footnotetext[1]{Corresponding authors}


\begin{abstract}
Multi-turn instruction following capability constitutes a core competency of large language models (LLMs) in real-world applications.
Existing evaluation benchmarks predominantly focus on fine-grained constraint satisfaction and domain-specific capability assessment, yet overlook the crucial structural dependency between dialogue turns that distinguishes multi-turn from single-turn interactions.
This structural dependency not only reflects user intent but also establishes a second dimension for instruction following evaluation beyond constraint satisfaction.
To address this gap, we propose StructFlowBench, a multi-turn instruction following benchmark with structural flow modeling.
The benchmark innovatively defines a structural flow framework comprising six fundamental inter-turn relationships, which not only introduces novel structural constraints for model evaluation but also serves as generation parameters for creating customized dialogue flows tailored to specific scenarios.
Adopting established LLM-based automatic evaluation methodologies, we conduct systematic evaluations of 13 leading open-source and closed-source LLMs. 
Experimental results reveal significant deficiencies in current models' comprehension of multi-turn dialogue structures.
The code is available at \url{https://github.com/MLGroupJLU/StructFlowBench}.
\end{abstract}

\input{tex/introduction}
\input{tex/related_work}
\input{tex/benchmark}
\input{tex/experiments}
\input{tex/conclusion}



\section*{Limitations}
Currently, the structural flow in StructFlowBench is designed with a single linear relationship to facilitate analysis and data generation. 
For instance, if the third turn dialogue serves as both a recall structure to the first turn and a follow-up structure to the second turn, the current approach retains only the recall relationship while disregarding other structural dependencies. 
This simplification may limit the comprehensive modeling of hierarchical dialogue structures. 
Future work should extend the structural flow framework to simultaneously capture multiple coexisting dialogue relationships, thereby providing a more holistic representation of multi-turn dialogue complexity.

\section*{Ethics Statement}
This study utilizes GPT-4o to generate multi-turn dialogue data and annotate constraints, with manual review to filter out inappropriate content. 
However, unintended biases in GPT-4o's generation process, as well as potential oversight during human review, may result in residual errors or biases in the dataset. 
While we have made every effort to ensure data quality and mitigate these issues, completely eliminating them remains challenging. 
Additionally, since this dataset is publicly available, there is a risk of misuse for model training, which may compromise the validity of our benchmark. 
Therefore, we encourage the research community to exercise caution when using this dataset and to complement it with other evaluation methods to ensure comprehensive and fair model assessment.


%\section*{Acknowledgments}



% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom}

\clearpage
\appendix

\section{Details of Topics and Tasks}
\label{sec:topic-task}
\begin{itemize}
    \item \textbf{Topic:} Our dataset is generated across a diverse range of 22 topics, including health, history, science, technology, digital media, automotive, astronomy, geography, lifestyle, literature, physics, finance, stocks, law, humanities, entertainment, music, fashion, art, environment, psychology, and a mixed category that incorporates multiple topics. This broad coverage ensures that our data spans multiple domains, capturing a wide array of fields and areas of interest.
    \item \textbf{Task:} StructFlowBench comprises seven NLP tasks and one mixed-category task, with their exact distribution detailed in Table~\ref{tab:task-distribution}.
\end{itemize}

\begin{table}[htbp]
\centering
\begin{tabular}{l|r}
\toprule
\textbf{Category} & \textbf{\#Dialogues} \\
\midrule
Fact-based Questions & 25 \\
Open-ended Questions & 20 \\
Practical Writing & 26 \\
Creative Writing & 21 \\
Professional Writing & 21 \\
Casual Chat & 15 \\
Task-oriented Role Play & 17 \\
Mixture & 10 \\
\midrule
Total & 155 \\
\bottomrule
\end{tabular}
\caption{Task distribution of \textsc{StructFlowBench} dataset.}
\label{tab:task-distribution}
\end{table}


\section{Details of Constraints}
\label{sec:constraint}
The distribution of all constraints is detailed in Table~\ref{tab:constraint-distribution}, with the definitions of intra-turn constraints as follows: 

\textbf{Content Constraint:} The response must strictly focus on the specified content scope and avoid any deviation from the topic.

\textbf{Keyword/Element Constraint:} The response must include specific words or elements as required.

\textbf{Style Constraint:} The response must be generated in a specific writing style, such as formal, humorous, poetic, etc.

\textbf{Basic Format Constraint:} The output must adhere to a specified basic format, such as JSON, XML, CSV, Table, Markdown, etc.

\textbf{Quantity Format Constraint:} The response must meet a precise requirement for the number of characters, words, sentences, or paragraphs as specified.

\textbf{Template Format Constraint:} The response must follow a predefined template structure, such as starting with a specific phrase, ending with a certain statement, or using a custom template provided by the user.

\textbf{Situation Constraint:} The response must be tailored to a given scenario or perspective, such as responding from a specific identity or context.

\textbf{Inverse Constraint:} The response must deliberately exclude or avoid certain constraints, such as not containing a specific keyword, not involving a particular element, or not using a certain language style.

\begin{table*}[htbp]
    \centering
    \resizebox{\textwidth}{!}{
        \begin{tabular}{ccccc|cccccccc}
            \toprule
            \textbf{Follow-up} & \textbf{Refinement} & \textbf{Expansion} & \textbf{Summary} & \textbf{Recall} & \textbf{C1} & \textbf{C2} & \textbf{C3} & \textbf{C4} & \textbf{C5} & \textbf{C6} & \textbf{C7} & \textbf{C8}\\
            \midrule
            95 & 32 & 156 & 63 & 118 & 505 & 153 & 140 & 105 & 175 & 98 & 83 & 52 \\
            \bottomrule
        \end{tabular}
    }
    \caption{The constraints distribution of \textsc{StructFlowBench}. \textit{Follow-up}, \textit{Refinement}, \textit{Expansion}, \textit{Summary}, \textit{Recall} denote the structural constraints. The designations C1 - C8 denote the Constraint types of \textit{Content Constraint, Keyword/Element Constraint, Style Constraint, Basic Format Constraint, Quantity Format Constraint, Template Format Constraint, Situation Constraint, Inverse Constraint}}
    \label{tab:constraint-distribution}
\end{table*}


\section{Detailed Results Categorized by Intra-turn Constraints and Task Types}
\label{sec:detailed results}
Table~\ref{tab:intra-turn-results} presents the intra-turn constraints performance of various models on StructFlowBench, while Table~\ref{tab:task-results} illustrates the task-categorized performance. 
Additionally, Figure~\ref{fig:radar} provides a radar chart comparing both perspectives.

\begin{table*}[htbp]
    \centering
    \resizebox{\textwidth}{!}{
        \begin{tabular}{l>{\centering\arraybackslash}p{2.5cm}>{\centering\arraybackslash}p{2.5cm}>{\centering\arraybackslash}p{2.5cm}>{\centering\arraybackslash}p{2.5cm}>{\centering\arraybackslash}p{3.5cm}>{\centering\arraybackslash}p{3cm}>{\centering\arraybackslash}p{3cm}>{\centering\arraybackslash}p{2.5cm}}
            \toprule
            \multirow{2}{*}{\textbf{Model Name}} & \textbf{Inverse Constraint} & \textbf{Keyword/Element Constraint} & \textbf{Style Constraint} & \textbf{Situation Constraint} & \textbf{Basic Format Constraint} & \textbf{Quantity Format Constraint} & \textbf{Template Format Constraint} & \textbf{Content Constraint} \\
            \midrule
            Deepseek-v3 & \textbf{\underline{1.0}}& \textbf{\underline{1.0}}& \textbf{\underline{1.0}}& \textbf{\underline{1.0}} & \textbf{\underline{0.99}} & \textbf{\underline{1.0}} & \textbf{\underline{0.99}}& \textbf{\underline{1.0}} \\
            Gemini-1.5-Pro & \textbf{\underline{1.0}}& 0.99& 0.99& \textbf{\underline{1.0}} & \textbf{\underline{0.99}}& 0.99 & \textbf{\underline{0.99}}& 0.99 \\
            GPT-4o & \textbf{\underline{1.0}} & \textbf{\underline{1.0}}& \textbf{\underline{1.0}}& \textbf{\underline{1.0}}& \textbf{\underline{0.99}}& 0.98& \textbf{\underline{0.99}} & \textbf{\underline{1.0}}\\
            Claude-3.5-Sonnet & 0.98 & 0.97& 0.99& \textbf{\underline{1.0}} & 0.95& 0.99 & 0.94& 0.97\\
            GLM-4-9B-Chat & 0.98 & 0.98& 0.99& 0.96& 0.97& 0.95 & 0.95 & 0.99 \\
            Qwen2.5-14B-Instruct & 0.96& 0.99& 0.99& 0.95& 0.9& 0.93 & 0.92& 0.97 \\
            Qwen2.5-7B-Instruct & 0.96& 0.97& 0.99& 0.99& 0.95& 0.91 & 0.88& 0.96 \\
            Deepseek-R1-Distill-Qwen-7B & 0.9& 0.89& 0.91& 0.84& 0.82& 0.7 & 0.8 & 0.83 \\
            DeepSeek-R1-Distill-Llama-8B & 0.88& 0.95& 0.9& 0.9& 0.9& 0.84& 0.84& 0.88\\
            Llama-3.1-Instruct-8B & 0.98& 0.87& 0.92& 0.94& 0.73& 0.79 & 0.7& 0.88\\
            Phi-3.5-mini-instruct & 0.94& 0.93& 0.96& 0.96& 0.82& 0.81 & 0.8& 0.9\\
            Yi-6B-Chat & 0.83 & 0.92& 0.91 & 0.9& 0.87& 0.65 & 0.91& 0.9 \\
            Mistral-7B-Instruct-v0.3 & 0.88& 0.82& 0.84& 0.9& 0.65& 0.59 & 0.56 & 0.8 \\
            \bottomrule
        \end{tabular}
    }
    \caption{The intra-turn constraints performance of various models on \textsc{StructFlowBench}.}
    \label{tab:intra-turn-results}
\end{table*}

\begin{table*}[htbp]
    \centering
    \resizebox{\textwidth}{!}{
        \begin{tabular}{l>{\centering\arraybackslash}p{2.5cm}>{\centering\arraybackslash}p{2.5cm}>{\centering\arraybackslash}p{2.5cm}>{\centering\arraybackslash}p{2.5cm}>{\centering\arraybackslash}p{2.5cm}c>{\centering\arraybackslash}p{3cm}c}
            \toprule
            \multirow{2}{*}{\textbf{Model Name}} & \textbf{Fact-based Questions} & \textbf{Open-ended Questions} & \textbf{Professional Writing} & \textbf{Practical Writing} & \textbf{Creative Writing} & \multirow{2}{*}{\textbf{Casual Chat}} & \textbf{Task-oriented Role-playing} & \multirow{2}{*}{\textbf{Mixture}} \\
            \midrule
            Deepseek-v3 & \textbf{\underline{0.93}}& 0.96& \textbf{\underline{0.99}}& \textbf{\underline{0.96}} & 0.97 & \textbf{\underline{0.98}} & 0.95& 0.97 \\
            Gemini-1.5-Pro & 0.91& \textbf{\underline{0.97}}& 0.96& 0.91 & \textbf{\underline{0.98}}& 0.96 & 0.95& 0.97 \\
            GPT-4o & 0.92 & 0.96& 0.96& 0.95& 0.97& 0.94& 0.92 & \textbf{\underline{0.98}}\\
            Claude-3.5-Sonnet & \textbf{\underline{0.93}} & 0.95& 0.97& 0.88 & 0.94& 0.92 & \textbf{\underline{0.97}}& 0.95\\
            GLM-4-9B-Chat & 0.89 & 0.93& 0.96& 0.92& 0.94& 0.95 & 0.93 & 0.97 \\
            Qwen2.5-14B-Instruct & 0.9& 0.94& 0.93& 0.9& 0.94& 0.91 & 0.91& 0.93 \\
            Qwen2.5-7B-Instruct & 0.9& 0.92& 0.89& 0.91& 0.93& 0.93 & 0.94& 0.95 \\
            Deepseek-R1-Distill-Qwen-7B & 0.77& 0.85& 0.86& 0.82& 0.74& 0.79 & 0.8 & 0.77 \\
            DeepSeek-R1-Distill-Llama-8B & 0.79& 0.9& 0.9& 0.87& 0.86& 0.88& 0.86& 0.83\\
            Llama-3.1-Instruct-8B & 0.81& 0.88& 0.8& 0.83& 0.84& 0.76 & 0.88& 0.88\\
            Phi-3.5-mini-instruct & 0.86& 0.88& 0.86& 0.84& 0.94& 0.86 & 0.86& 0.86\\
            Yi-6B-Chat & 0.84 & 0.9& 0.87 & 0.82& 0.82& 0.77 & 0.86& 0.8 \\
            Mistral-7B-Instruct-v0.3 & 0.71& 0.82& 0.72& 0.76& 0.75& 0.73 & 0.79 & 0.78 \\
            \bottomrule
        \end{tabular}
    }
    \caption{Task-categorized performance of various models on \textsc{StructFlowBench}.}
    \label{tab:task-results}
\end{table*}

\begin{figure*}[htbp]
	\centering
	\includegraphics[width=\textwidth]{figures/radar.pdf}
	\caption{The radar chart of intra-turn-constraint-categorized performance (a) and task-categorized performance (b).}
	\label{fig:radar}
\end{figure*}


\section{Details of Prompts}
\label{sec:prompt}
Figure~\ref{fig:imtermediate-prompt} to Figure~\ref{fig:evaluation-prompt} respectively illustrate the intermediate dialogue plan generation template, complete dialogue generation prompt template, constraint extraction prompt template, and GPT-4o evaluation prompt template used in our study.

\begin{figure*}[htbp]
	\centering
	\includegraphics[width=\textwidth]{figures/Intermediate_Dialogue_Plan_Generation_Template.pdf}
	\caption{Intermediate Dialogue Plan Generation Template}
    \label{fig:imtermediate-prompt}
\end{figure*}

\begin{figure*}[htbp]
	\centering
	\includegraphics[width=\textwidth]{figures/Complete_Dialogue_Generation_Prompt_Template.pdf}
	\caption{Complete Dialogue Generation Prompt Template}
    \label{fig:complete-prompt}
\end{figure*}

\begin{figure*}[htbp]
	\centering
	\includegraphics[width=\textwidth]{figures/Constraint_Extraction_Prompt_Template.pdf}
	\caption{Constraint Extraction Prompt Template}
    \label{fig:extraction-prompt}
\end{figure*}

\begin{figure*}[htbp]
	\centering
	\includegraphics[width=\textwidth]{figures/GPT-4o_Evaluation_Prompt_Template.pdf}
	\caption{GPT-4o Evaluation Prompt Template}
    \label{fig:evaluation-prompt}
\end{figure*}


\section{Case of Data}
\label{sec:case}
Table~\ref{tab:data-case} presents a sample case from StructFlowBench.

\begin{table*}[htbp]
    \centering
    \begin{tabular}{p{0.2\linewidth} p{0.8\linewidth}}
        \toprule
        \textbf{User purpose} 
        & The user aims to develop a financial plan for a fictional character by interacting with the assistant as a financial advisor.The user wants to learn about different music genres and styles to enhance their personal music knowledge and broaden their music listening experience. \\
        \midrule
        \textbf{Structure} 
        & "source": "c1","target": "c2","relation": "follow-up" \\
        & "source": "c1","target": "c3","relation": "recall" \\
        & "source": "c3","target": "c4","relation": "unrelatedness" \\
        & "source": "c4","target": "c5","relation": "refinement" \\
        \midrule
        \textbf{Summarized Prompts} 
        & "c1" : "The user asks the assistant, role-playing as a financial advisor, to provide a general strategy for a young professional who wants to start saving for retirement." \\
        & ... \\
        & "c5": "The user modify the detail level in last round's prompt to request a deeper dive into the unique instruments used in each genre for better understanding of their sounds." \\
        \midrule
        \textbf{Complete Dialogue}
        & "name": "c1", \\
        & "user prompt": "Imagine I am a young professional entering the workforce. As my financial advisor, could you...", \\
        & "assistant answer": "Certainly! Here's a comprehensive strategy for..." \\
        &...\\
        & "name": "c5", \\
        & "user prompt": "In order to delve deeper into the musical intricacies ... Please format the response as a table and ..." \\
        & "assistant answer": "Certainly! Here is a detailed examination of the unique instruments associated with each genre in a table format:..." \\
        \midrule
        \textbf{Check Lists} 
        & "name":"c1" \\
        & "Situation Constraint":"Is the response given from the perspective of a financial advisor?" \\
        & "Keyword/Element Constraint":"Does the response include specific keywords such as... ?" \\
        & ... \\
        & "name":"c5" \\
        & "Basic Format Constraint":"Is the response formatted as a table?" \\
        & "Refinement Constraint":"Is the c5 conversation a refinement of c4 conversation?" \\
        \bottomrule
    \end{tabular}
    \caption{An example of synthetic data.}
    \label{tab:data-case}
\end{table*}


\section{Details of Models}
\label{sec:model-link}
All the details about the evaluated models are provided in Table~\ref{tab:model-link}.

\begin{table*}[htbp]
    \centering
    \begin{tabular}{l l p{8cm}}
        \toprule
        \textbf{Model} & & \textbf{Model Link} \\
        \midrule
        GPT & GPT-4o & \href{https://platform.openai.com/docs/models#gpt-4o}{https://platform.openai.com/docs/models\#gpt-4o} \\
        \midrule
        Claude & Claude-3.5-Sonnet & \href{https://docs.anthropic.com/en/docs/about-claude/models}{https://docs.anthropic.com/en/docs/about-claude/models} \\
        \midrule
        Gemini & Gemini-1.5-Pro & \href{https://ai.google.dev/gemini-api/docs/models/gemini?hl=en#gemini-1.5-pro}{https://ai.google.dev/gemini-api/docs/models/gemini?hl=en\#gemini-1.5-pro} \\
        \midrule
        \multirow{3}{*}{Deepseek} 
        & DeepSeek-v3 & \href{https://huggingface.co/deepseek-ai/DeepSeek-V3}{https://huggingface.co/deepseek-ai/DeepSeek-V3} \\
        & DeepSeek-R1-Distill-Qwen-7B & \href{https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B}{https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B} \\
        & DeepSeek-R1-Distill-Llama-8B & \href{https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B}{https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B} \\
        \midrule
        \multirow{2}{*}{Qwen} 
        & Qwen2.5-14B-Instruct & \href{https://huggingface.co/Qwen/Qwen2.5-14B-Instruct}{https://huggingface.co/Qwen/Qwen2.5-14B-Instruct} \\
        & Qwen2.5-7B-Instruct & \href{https://huggingface.co/Qwen/Qwen2.5-7B-Instruct}{https://huggingface.co/Qwen/Qwen2.5-7B-Instruct} \\
        \midrule
        GLM & GLM-4-9B-Chat & \href{https://huggingface.co/THUDM/glm-4-9b-chat}{https://huggingface.co/THUDM/glm-4-9b-chat} \\
        \midrule
        Yi & Yi-6B-Chat & \href{https://huggingface.co/01-ai/Yi-6B-Chat}{https://huggingface.co/01-ai/Yi-6B-Chat} \\
        \midrule
        LLAMA & Llama-3.1-8B-Instruct & \href{https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct}{https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct} \\
        \midrule
        Mistral & Mistral-7B-Instruct-v0.3 & \href{https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3}{https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3} \\
        \midrule
        Phi & Phi-3.5-mini-instruct & \href{https://huggingface.co/microsoft/Phi-3.5-mini-instruct}{https://huggingface.co/microsoft/Phi-3.5-mini-instruct} \\
        \bottomrule
    \end{tabular}
    \caption{Model Links.}
    \label{tab:model-link}
\end{table*}


\end{document}