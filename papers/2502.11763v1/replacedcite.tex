\section{Related Works}
\label{sec:impact}

Deepfakes have emerged as a critical challenge, prompting extensive research into detection techniques. The DL-based methods have shown the most advancement, leading to efficient detection systems. While various approaches have been proposed, they primarily rely on similar underlying principles____. 
Most of the detection methods use CNN-based models to classify images as fake or real, but state-of-the-art deepfake detectors (e.g., N. Bonettini____) still rely on complex neural networks, struggle with generalization to unseen deepfake techniques, and lack robustness under real-world distortions____.

Several deepfake detection approaches depend on various modalities and feature fusion to improve accuracy. Prior research has shown that integrating spatial and frequency domain features, as well as combining spatial, temporal, and spatiotemporal features, significantly improves detection accuracy compared to single-modality approaches____. For instance, Almestekawy et~al.____ fused Facial Region Feature Descriptor (FFR-FD) with random forest classifier and texture features (standard deviation, gradient domain, and GLCM) fed into an SVM classifier. Raza et~al.____ proposed a three-stream network utilizing temporal, spatial, and spatiotemporal features for deepfake detection. Moreover, security techniques for deepfake detection on untrusted servers were introduced by Chen B. et~al.____; their method enables distant servers to detect deepfake videos without understanding the~\mbox{content}.

Proper methods are essential for extracting valuable information from large unprocessed visual data, with feature-based techniques like LBP and KAZE offering computational efficiency as an alternative to resource-intensive CNNs____. Recent studies have suggested that combining extracted features with advanced ML classifiers can develop hybrid models for deepfake detection while maintaining robustness across diverse datasets____. 

Alternatively, texture can be encoded by comparing each pixel with its neighbors, creating a binary pattern that serves as a robust feature descriptor across various lighting conditions. Feature extraction techniques are divided into global and local descriptor approaches____. Global methods analyze the entire image to generate a feature vector and are considered fast processing but have some limitations, such as Principle Component Analysis (PCA)____, Linear Discriminant Analysis (LDA)____, and Global Gabor generic features____. Local descriptors, like LBP____ and Histogram of Oriented Gradients (HOG)____, provide a more effective representation of images. LBP is widely used in face recognition____, while HOG is used for human detection by dividing the image into fixed-size blocks and computing HOG features for each block. Likewise, the selection of custom features (Local Binary Patterns (LBP) based on texture and a customized High-Resolution Network (HRNet)) proposed by Khalil et~al.____ and fed to the SVM classifier. %please check if meaning is retained
This efficiency makes LBP a popular choice in tasks where texture details are important, such as facial recognition and expression analysis, while also reducing processing time and computational costs____. Deepfake artifacts regularly change gradient orientations and edge patterns, which are essential for lightweight detection on resource-constrained devices. Compared to CNN-based approaches, it is less successful in detecting higher-level semantic discrepancies____. KAZE, on the other hand, can detect unique key points that are invariant to noise and transformations, which is essential for applications requiring high-fidelity feature matching under variable conditions. By detecting and characterizing two-dimensional features in nonlinear scale space, the KAZE features____ resist Gaussian blurring. KAZEâ€™s reliance on nonlinear diffusion allows it to capture image structures that are often missed by traditional linear approaches, enhancing performance in complex environments____.

More recent deepfake methods, particularly diffusion models, have introduced high-quality synthetic images that closely resemble natural visuals, evading common detection markers such as GAN-related grid artifacts____. Chen Y et~al.~and Yuan et~al.____ developed a model that uses a reference image and text prompt to generate deepfake images as human identity. These developments initiate a shift in detection strategies, where integrating extracted features with classifiers holds significant potential for improving accuracy and reducing computational load____. 

As a result, detecting deepfake images/videos contributes to the struggle against spreading false information and encourages preserving the validity of visual content and privacy. Our methodology differs from previous approaches in numerous important ways, including the use of multi-feature-level fusion (HOG, LBP, and KAZE features) prior to classification. Focus on characteristics that are computationally efficient. For validation, supervised ML classifiers (such as support vector machines (SVMs), random forest (RF), and gradient boosting classifiers) were used, and their performance in deepfake detection has been evaluated.