
    \section{Degrees of the RBG Graph}
In this section, we consider some basic properties of the RBG graph $\mathcal{G}(\Phi,\Psi, f)$. Let $\Phi^o\triangleq \Phi\mid o\in\Phi.$ We focus on the typical agent at the origin and the Palm distribution of $\Phi$
\begin{equation}
 \mathrm{P}_{}^{o}(\cdot) \triangleq \Pr(\Phi\in\cdot \mid o\in\Phi),\nonumber
\end{equation}
and the reduced Palm distribution
\begin{equation}
 \mathrm{P}_{}^{!o}(\cdot) \triangleq \Pr(\Phi\setminus\{o\}\in\cdot\mid o\in\Phi).\nonumber
\end{equation}
We denote by $\Ex_{}^{{o}}$ the  expectation with respect to the Palm measure of $\Phi$
   and by $\Ex_{}^{!o}$ the  expectation with respect to the reduced Palm measure of $\Phi$ \cite[Chapter 8]{haenggi2012stochastic}.
   %of $\Phi$, i.e., $\Ex^{!}_{{o}}f(\Phi) \triangleq \Ex (f(\Phi\setminus\{o\})\mid o\in\Phi).$
    




%There are several quantities of interest and connection functions: the degree (the number of edges) of the typical node/hub, the number of connections of the typical node, and the number of connected nodes of the typical node.
\subsection{General Point Processes}
%To simplify the notation, let $\Ex^{!o}$ denote the (total) expectation where the expectation with respect to $\Phi$ is its reduced Palm expectation.

Let $c_d$ denote the volume of unit ball in $\mathbb{R}^d$.
The mean degree of the typical agent in a general point process is 
%  $\sum_{y\in\Psi} \ind(o\to y)$ with mean 
    \begin{align}
  \Ex^{o} \sum_{y\in\Psi}I(o,y)
       &\peq{a} \Ex \sum_{y\in\Psi}f(\|y\|)\nonumber
      \\
      &\peq{b} \mu c_d d \int_{0}^{\infty}f(r) r^{d-1} \dd r,\label{eq: EN_hub}
    \end{align}
    where step (a) follows from the independence of $\Phi$ and $\Psi$, and step (b) follows from Campbell's theorem. 
    By the mass transport principle \cite{baccelli:hal-02460214}, the mean degree of the typical hub (defined through the Palm expectation of $\Psi$) is $\lambda c_d d \int_{0}^{\infty}f(r) r^{d-1} \dd r.$ %Similarly, the sum length of the edges of the typical node is given by $ \Ex \sum_{y\in\Psi} \|y\|I(o, y)= \mu c_d d \int_{0}^{\infty}f(r) r^{d} \dd r.$
    For example, consider $d=2$, a general connection function $f$, and its dispersed version $f_{p}$. While the mean degree remains constant for any $p\in(0,1]$,
%, i.e., \[\int_{0}^{\infty}f_p(r)2\pi r \dd r \equiv \int_{0}^{\infty}f(r)2\pi r \dd r.\]
 the edges spreads out in space as $p\to 0$. To see this, consider the mean distance
 \begin{align}
 \Ex^{o} \sum_{y\in\Psi}I(o,y)\|y\| &=\int_{0}^{\infty}f_p(r)2\pi r^2 \dd r\nonumber \\
 & = \frac{1}{\sqrt{p}}\int_{0}^{\infty}f(r)2\pi r^2 \dd r,\nonumber
 \end{align}
which increases as the connection function becomes more dispersed.


    
 Let $M\triangleq\sum_{x\in\Phi^o\setminus\{o\}}\max_{y\in\Psi} I(o,y)I(x,y)$ denote the number of agents connected to $o$.  We have
    \begin{align}
        \Ex M &= \Ex\sum_{x\in\Phi^o\setminus\{o\} } 1-\prod_{y\in\Psi} \left(1-I(o,y)I(x,y)\right) \nonumber\\
        &= \Ex^{!o} \sum_{x\in\Phi} 1-\prod_{y\in\Psi} (1-f(\|y\|)f(\|x-y\|)).\nonumber
        \end{align}
    This follows from the fact that the edge indicator functions are independent Bernoulli random variables given $\Phi$ and $\Psi$.
    
    Let $N\triangleq\sum_{y\in\Psi}\sum_{x \in\Phi^o\setminus\{o\}} I(o,y)I(x,y)$ denote the total number of direct (two-edge) paths between $o$ and its connected agents. We have
    \begin{align}
       \Ex N  &= \Ex \sum_{y\in\Psi}\sum_{x \in\Phi^o\setminus\{o\}} I(o,y)I(x,y) \nonumber\\
       &= \Ex^{!o}\sum_{y\in\Psi}\sum_{x \in\Phi}f(\|y\|)f(\|x-y\|).\nonumber
       %\\ \nonumber & =  \Ex_{\Psi} \sum_{y\in\Psi}f(\|y\|) \Ex^{!}_{{o}}\sum_{x \in\Phi} f(\|x-y\|),
    \end{align}  
    

 
    
By definition, $N\geq M$, and the equality is achieved when $o$ and $x$ are connected through at most one hub, $\forall x\in\Phi$. The difference between $N$ and $M$ reflects how likely two agents connect through multiple hubs. The variance of $M$ is $\mathbb{V} M \triangleq \Ex M^2 - (\Ex M)^2$, which characterizes the heterogeneity of the number of connected agents.
   
   
    
    % \subsection{The Basic Reproduction Number}
    %   The basic reproduction number $R_0$ is widely used in epidemiology to predict whether an infectious disease will spread. However, it is difficult to calculate in general and its effectiveness and interpretation rely on the model \cite{Li2011TheFO}. While $R_0$ captures the initial state of the disease propagation, it may not predict the spread in a global level. For instance, consider a model where each node always connects with its nearest hub and $\alpha=1$. Then $R_0=N-1$ assuming each hub on average connects to $N$ nodes. However, due to the locality of connections, the disease only spreads within nodes connected to the same hub and always dies out for an arbitrarily large $N$. 
       
%      \begin{definition}[The basic reproduction number ]
%   \end{definition}


%Without loss of generality we assume that the single infected node is at the origin.
   


%   \begin{remark}
%         For given $\Phi$ and $\Psi$, denote the expected number of secondary infections generated by the typical infected node by $R(\Phi,\Psi)$. $R(\Phi,\Psi)$ is the conditional basic reproduction number given node and hub locations.      Given $\Phi,\Psi$, the number of secondary infections caused by $o$ is 
%      \begin{align}
%         R(\Phi,\Psi)&= \Ex \left[\sum_{x\in\Phi}\max_{1\leq k\leq K} \ind (Z_x^{k} = \mathrm{I}\mid Z_x^{0}=\mathrm{S},Z_o^{0} = \mathrm{I})\mid \Phi,\Psi\right]\\
%          &= \Ex \left[\sum_{x\in\Phi}  1- (1-\alpha)^{K  N_x}\mid\Phi,\Psi\right]\\
%          & = \Ex \left[\sum_{x\in\Phi}  1- \prod_{y\in\Psi} (1-\alpha)^{K \ind(o\to y)\ind(x\to y)}\mid\Phi,\Psi\right]\\
%          & \peq{a} \sum_{x\in\Phi}  1- \prod_{y\in\Psi}\left[ (1-\alpha)^{K}f(\|y\|)f(\|x-y\|)+1-f(\|y\|)f(\|x-y\|)\right]
%     %  \\& = 1- \prod_{\Psi} \left(1-t\gamma^2\exp\big(-\theta (\|y\|+\|x-y\|)\big)\right)^K.
%         \end{align}
% where step (a) follows from the independence of $\{I(x,y):x\in\Phi\}$ given $\Psi$ and $\Phi$. 
%     %  \\
%     %  & = 1-\exp\left(-\int_{\|x\|}^{\infty} \lambda_{x}(r) \Big(1-\big(1-t\gamma^2\exp(-\theta r)\big)^K\Big)\dd r\right),\label{eq: bessel}
%      By Definition 1, \begin{equation}
%          R_0 \triangleq \Ex R_{0}(\Phi,\Psi) = \Ex_{\Psi}\Ex_{o}^{!} R_{0}(\Phi,\Psi).
%      \end{equation}   
%   \end{remark}
    
    
  
    
    % and prove its existence for the static model. Two observations:\\
    % - the dynamic RBG graph's threshold is lower-bounded by the static one.\\
    % - the percolation threshold should decrease with the dispersiveness of $f$ using the idea in \cite{Franceschetti05continuumpercolation}

    
% \input{analysis}
   

%     $R_0>1$ alone is not sufficient for the disease spread. 
%     \begin{conjecture}
%     A necessary condition for the disease spread is that the Poisson random connection model of $\Psi$ with connection function $g$ percolates.
%     \end{conjecture}
% If $\Phi$ percolate, then $\Psi$ percolate? 
%We say that two hubs are connected if they connect to a common node... This leads to a connection function $g(r)$. Does the percolation of $\Psi$ with $g(r)$ indicate the percolation of $\Phi$ with $f$? 
% tThe probability that infinite nodes get infected is 0 if the largest connected component of the random connection model of $\Psi$ associated with $g$ is finite (to be proved).


\subsection{Poisson Point Processes}
\begin{figure*}[t]
\normalsize
\setcounter{MYtempeqncnt}{\value{equation}}
\setcounter{equation}{\value{equation}+2}
 \begin{align}
       \mathbb{V} N
       & = \Ex N+\lambda^2\mu\left(\int_{0}^{\infty}f(r)dc_d r^{d-1} \dd r\right)^3 \nonumber%\int_{\mathbb{R}^2}\int_{\mathbb{R}^2}\int_{\mathbb{R}^2}f(\|y\|)f(\|x_1-y\|)f(\|x_2-y\|) \dd y\dd x_1 \dd x_2\nonumber\\
       \\
       &\quad+\lambda\mu^2 \int_{\mathbb{R}^d}\int_{\mathbb{R}^d}\int_{\mathbb{R}^d}f(\|y_1\|)f(\|y_2\|) f(\|x-y_1\|)f(\|x-y_2\|) \dd y_1\dd y_2\dd x.\label{eq: E_N_o^2}
      % &\quad+\lambda^2\mu^2 \int_{\mathbb{R}^2}\int_{\mathbb{R}^2}\int_{\mathbb{R}^2}\int_{\mathbb{R}^2}f(\|y_1\|)f(\|y_2\|) f(\|x_1-y_1\|)f(\|x_2-y_2\|) \dd x_1 \dd x_2 \dd y_1\dd y_2
    \end{align}
    \setcounter{equation}{\value{MYtempeqncnt}}
\hrulefill
\vspace*{4pt}
\end{figure*}
Here we focus on the case where $\Psi$ and $\Phi$ are two independent PPPs in $\mathbb{R}^d$, defined on the same probability space. We derive the mean and variance of $N$ and $M$. For the PPP,
\[
{\rm P}_{\Phi}^{!o} = \rm P_{\Phi}.
\]
This is known as Slivnyak's Theorem  \cite{haenggi2012stochastic} and leads to  the result below.

%With a slight abuse of notation, we write $\Phi$ instead of $\Phi_o^{!}$ in this section for simplicity. 
   
% For simplicity, we assume $K\equiv1$, $i.e.,$ an infected node is infectious for one slot and is removed afterwards. 
% The relevant parameters are the densities $\lambda,~\mu$, the rate(s) of visiting a hub $(\gamma,\theta)$, and the rate of infection $\alpha$. We first analyze the distribution of the number of connections. Then we derive the basic reproduction number of the model.

%     \end{equation}
%   Its expectation is 
% The moment-generating function of $N_o$ is 
%           \begin{align}
%          \mathcal{G}_{N_o}(s) & = \Ex s^ {N_o}\\
%          & = \Ex s^{\sum_{y\in\Psi}\sum_{x \in\Phi} I(o,y)I(x,y)}\\
%          & = \Ex \prod_{y\in\Psi}\prod_{x \in\Phi} s^{I(o,y)I(x,y)}\\
%          & \peq{a} \Ex\prod_{y\in\Psi}\prod_{x\in\Phi} \gamma^2 s\exp(-\theta\|y\|-\theta\|x-y\|)+1-\gamma^2 \exp(-\theta\|y\|-\theta\|x-y\|)\\
%          & \peq{b} \Ex \prod_{y\in\Psi} \exp\bigg(-\int_{0}^{\infty}2\pi\lambda  r  (1-s)\gamma^2 \exp(-\theta\|y\|)\exp(-\theta r)\dd r\bigg)\\
%          & = \Ex \prod_{y\in\Psi} \exp\big(-2\pi\lambda (1-s)\gamma^2\theta^{-2} \exp(-\theta \|y\|)\big)\\
%          & \peq{c} \exp\bigg(-\int_{0}^{\infty}2\pi\mu r \Big(1-\exp\big(-2\pi\lambda (1-s) \gamma^2\theta^{-2} \exp(-\theta r)\big)\Big)\dd r\bigg)\label{eq: LaplaceN}
%      \end{align}
%   where  step (a) follows from the distribution of the binary random variable $I(o,y)I(x,y)$. Step (b)  and (c) follow from the PGFL of the PPP. One can obtain $\Ex N_o = (\mathrm{d}/\mathrm{d}s)\mathcal{G}(s)|_{s=1}$, Or directly b
%Recall that $N_o = \sum_{y\in\Psi}\sum_{x \in\Phi_o^!} I(o,y)I(x,y)$ and $M_o =\sum_{x \in\Phi_o^!} \max_{y\in\Psi}I(o,y)I(x,y)$.     
    \begin{theorem}
    \label{thm: N,M}
For the PPP, the means of $M,~N$ are
\begin{equation}
  \Ex N = \lambda\mu \left(\int_{0}^{\infty}f(r)dc_d r^{d-1} \dd r\right)^2,        \label{eq: EN}
\end{equation}
and
 \begin{equation}
     \Ex M = \lambda\int_{\mathbb{R}^d}  1-\exp\left(-\mu\int_{\mathbb{R}^d}f(\|y\|)f(\|x-y\|)\dd y\right)\dd x.\label{eq: EM}
 \end{equation}
 Further, the variance of $N$ is given in (\ref{eq: E_N_o^2}),
 and the variance of $M$ satisfies $\mathbb{V} M \geq \Ex M$.
\end{theorem}
% \begin{figure*}[t]
% \normalsize
% \setcounter{MYtempeqncnt}{\value{equation}}
% \setcounter{equation}{\value{equation}}
%      \begin{align}
%             \Ex M_o^2 
%             & = \Ex M_o +2\lambda^2  \int_{\mathbb{R}^2}\int_{\mathbb{R}^2} 1- \exp\left(-\mu\int_{\mathbb{R}^2}f(\|y\|)f(\|x_1-y\|)\right)-\exp\left(-\mu\int_{\mathbb{R}^2}f(\|y\|)f(\|x_2-y\|)\dd y\right)\nonumber\\   &\quad+\exp\left(-\mu\int_{\mathbb{R}^2}f(\|y\|)(f(\|x_1-y\|)+f(\|x_2-y\|))-f(\|y\|)^2f(\|x_1-y\|)f(\|x_2-y\|)\dd y\right)\dd x_1 \dd x_2.
%               \label{eq: E_M_o^2}
%             \end{align} 
%             \setcounter{equation}{\value{MYtempeqncnt}+1}
% \hrulefill
% \vspace*{4pt}
% \end{figure*}
\begin{proof}
See Appendix \ref{appendix: N,M}.
   \end{proof}
   \begin{remark} 
       $\Ex M = {\Theta}(\mu)$\footnote{We use $f(x)=\Theta(g(x))$ as $x\to a$ to denote that $f(x)=O\left(g(x)\right)$ and $ g(x)=O(f(x))$ as $x\to a$.} as $\mu\to0$, since $1-\exp(-\mu) = {\Theta}(\mu)$ as $\mu\to0$.
   \end{remark}
 \begin{remark}
Eq. (\ref{eq: EN}) holds for general hub point process $\Psi$. The other equations in Theorem 1 rely on the fact that $\Psi$ is a PPP.  In (\ref{eq: EM}), $\int_{\mathbb{R}^d}f(\|y\|)f(\|x-y\|)\dd y$ only depends on $\|x\|$, as the rotation of $x$ is equivalent to rotating $y$, which has no effect on the integral. This observation is used in the next subsection.
 \end{remark} 
 \begin{remark}
  Both $N$ and $M$ are super-Poisson since $\Var N\geq \Ex N$, and $\Var M\geq \Ex M$. In (\ref{eq: E_N_o^2}), note that in the second term the integral to the power of 3 is larger than the triple integral in the third term. Hence, for fixed $\lambda\mu$, there exists a threshold of $\lambda$ above which increasing $\lambda/\mu$ increases the variance of $N$.
  %When $\gamma\theta^2$ is fixed, increasing $\theta$ increases the variance of $\M_o$ but decreases the variance of $N_o$.
 \end{remark}


 





 
   
%   \begin{corollary}
% The probability that an arbitrary location $x$ is connected with $o$ averaged over $\Psi$ is 
% \begin{equation}
% \Pr(\max_{y\in\Psi} I(o,y)I(x,y) = 1)  = 1-\exp\left(-\frac{\mu\pi}{4}\gamma^2 \|x\|^2\left(\frac{2K_1(\theta  \|x\|)}{\theta \|x\|}+K_0\big(\theta  \|x\|\big)\right)\right).
% \label{eq: p_x_connect}
% \end{equation}
%   \end{corollary}
%      The moment generating function of $M_o$ is 
%           \begin{align}
%          \mathcal{G}_{M_o}(s) & = \Ex s^{M_o}\\
%          & = \Ex s^{\sum_{x\in\Phi} \max_{y\in\Psi} I(o,y)I(x,y)}\\
%          & = \Ex \prod_{x \in\Phi} s^{\max_{y\in\Psi} I(o,y)I(x,y)}\\
%       %  & \peq{a} \Ex\prod_{x\in\Phi} \left(s (1- \prod_{y\in\Psi}(1- \gamma^2 \exp(-\theta\|y\|-\theta\|x-y\|)))+\prod_{y\in\Psi}(1-\gamma^2 \exp(-\theta\|y\|-\theta\|x-y\|))\right)\\
%       & = \Ex \prod_{x\in\Phi} s\Pr(o \leftrightarrow x\mid\Psi) + 1-\Pr(o \leftrightarrow x\mid\Psi)\\
%       & = \Ex \prod_{x\in\Phi} s +(1-s)\prod_{y\in\Psi}\left(1-\gamma^2\exp(-\theta\|y\|-\theta\|x-y\|)\right)\\
%          & \peq{a} \Ex\prod_{x\in\Phi}  s+(1-s)\exp\left(-\frac{\mu\pi}{4}\gamma^2 \|x\|^2\left(\frac{2K_1(\theta  \|x\|)}{\theta \|x\|}+K_0\big(\theta  \|x\|\big)\right)\right)\\
%      %    & = \exp\left(-\int_0^{\infty} 2\pi\lambda v(1-s)\exp(-\int_0^{\infty}\lambda \gamma^2\exp(-\theta r)\dd r)\right)\\
%          & \peq{b}\exp\left(-\int_0^{\infty} 2\pi\lambda v(1-s)\left(1-\exp\left(-\frac{\mu\pi}{4}\gamma^2 v^2\left(\frac{2K_1(\theta v)}{\theta v}+K_0\big(\theta  v\big)\right)\right)\right)\right).
%          \label{eq: gf_M}
%      \end{align}
%     Step (a) follows from Corollary 1. Step (b) follows from the PGFL of the PPP.
 
%          So $M_o$ is Poisson distributed with mean
    
    
    
     %  \hl{Note the relation between $M_o$ and $R_0$}
%   \begin{corollary}
%   The basic reproduction number of the proposed model is 
%   \begin{equation}
%       R_0 =\int_{0}^{\infty} \frac{2\pi\lambda v}{\theta^2} \left(1-\exp\left(-\frac{\mu\pi}{4\theta^2}\alpha \gamma^2 v^2\left(\frac{2K_1( v)}{v}+K_0\big( v\big)\right)\right)\right) \dd v.
%       \label{eq: R_0}
%   \end{equation}
% %   where $\lambda_x(r)$ is given in Lemma 1.
%   \end{corollary}
%   \begin{proof}

%      We denote the probability of a node $x$ of distance $r=\|x\|$ getting infected from $o$ as $g(r)$.  First, we observe that $g(r)  = \Ex \ind(Z_x^1=\mathrm{I})$ can be obtained by changing the connection function $f(r)$ to $\sqrt{\alpha}f(r)$ in $\Ex M_o= \Ex \max_{y\in\Psi} I(o,y)I(x,y)$. This changes $\gamma^2$ to $\alpha\gamma^2$  in (\ref{eq: p_x_connect}). Thus 
%      \begin{equation}
%      g(r) = 1-\exp\left(-\frac{\mu\pi}{4}\alpha\gamma^2 r^2\left(\frac{2K_1(\theta r)}{\theta r}+K_0\big(\theta  r\big)\right)\right),\quad r>0.
%      \label{eq: g_r_exp}
%      \end{equation}
%   Using the reduced Palm expectation, Campbell's theorem, and substituting $\theta r$ by $v$ lead to (\ref{eq: R_0}).
%       \end{proof}


%       \begin{remark}
%          \begin{equation}
% \begin{split}
%   R(\Phi,\Psi) 
%      & =\sum_{x\in\Phi}  1- \prod_{y\in\Psi} \left(1-\alpha\gamma^2\exp\big(-\theta (\|y\|+\|x-y\|)\big)\right). \nonumber
% \end{split}
%     \end{equation}
%     Comment on its distribution
%       \end{remark}
      
     
            

      
%Fig. \ref{fig: pdf_R_0} shows the distribution of $R_0(\Phi,\Psi)$. Fig. \ref{fig: g_r_exp} shows the probability of infection at distance $r$.




%       \begin{corollary}
% For $K>0$, fix $\Ex N_o = K$.   Let $\rho\triangleq(2\pi)^2\lambda/\mu$.  $\Ex M_o$ depends on $\lambda$ and $\mu$ only through $\rho$. Further, $\Ex M_o$ monotonically increases with $\rho$, $\gamma$, and $K$.
%       \end{corollary}
%       \begin{proof}
%       $\Ex N_o = K$ implies  \begin{equation}
%       \theta^4 = K/(\gamma^2\mu^2{\rho}).
%       \label{eq: ratio}
%       \end{equation}
%       Here, the factor $1/(2\pi)^2$ is added to simplify the expressions below. Substituting $\theta$ by (\ref{eq: ratio})  and substituting $\sqrt{\mu} v$ by $v$ in Eq (\ref{eq: E M_0 exp}), we have
%       \begin{equation}
%           \Ex M_o =  \int_{0}^{\infty} \frac{\sqrt{\rho K}v}{2\pi\gamma} \left[1-\exp\left(-\frac{\pi\sqrt{K}}{4\sqrt{\rho}} \gamma v^2\left(\frac{2K_1( v)}{ v}+K_0\big( v \big)\right)\right)\right] \dd v,        \label{eq: R_0_simple}
%           %\int_{0}^{\infty} \frac{\rho v}{2\pi} \left[1-\exp\left(\frac{\pi}{4}\sum_{m=1}^{K}{K \choose m}(-t \gamma^2)^m v^2\left(\frac{2K_1( mv \sqrt{\gamma} \sqrt[\leftroot{-2}\uproot{2}4]{\rho/M})}{ mv\sqrt{\gamma} \sqrt[\leftroot{-2}\uproot{2}4]{\rho/M}}+K_0\big(m v \sqrt{\gamma} \sqrt[\leftroot{-2}\uproot{2}4]{\rho/M} \big)\right)\right)\right] \dd v,        \label{eq: R_0_simple}
%       \end{equation}
%       which does not depend on $\mu$. The monotonicity of $R_0$ wrt $K$ is trivial once we observe that the exponent is negative.  The monotonicity of $\Ex M_o$ wrt $\gamma,\rho$ is to be proved.
%       \end{proof}

      
      
      
      
%       \begin{corollary} 
%           For $\Ex N_o =K$, we have $\Ex M_o\leq K$.  The equality is achieved when $\rho\to\infty$ or $\gamma\to0$. $\int_{0}^{\infty}x^{n-1}K_m(x)\dd x = 2^{n-2}\Gamma(\frac{n-m}{2})\Gamma(\frac{n+m}{2}),~n> m.$
%           \end{corollary}
%           \begin{proof}
%           Taking the limit of (\ref{eq: R_0_simple}) when $\rho\to\infty$ or $\gamma\to0$ yields the upper bound. 
%           \end{proof}
          
    %   For a given set of $\lambda,\mu,\alpha$, let  $\gamma\to0$ while \begin{equation}\frac{\gamma}{\theta^2}=\frac{1}{2\pi}\sqrt{\frac{M}{\lambda\mu}}
    %   \label{eq: ratio}
    %   \end{equation}
    %   such that $\Ex N =M$, we have $
    %       \lim_{\gamma\to0}R_0 = C.$
    %   For a given set of $\lambda,\alpha,\gamma$, let  $\mu\to0$ while $\Ex N =M$ as in (\ref{eq: ratio}), we have $ \lim_{\gamma\to0} R_0 = C.$
       
    %  \begin{remark}
    %  From Corollary 2, when fixing the average number of hubs visited for the typical user, removing the location-dependence is equivalent to decreasing the hub density. The limiting case is where all nodes are uniformly mixed. On the other hand, when $\rho\to0$, $\Ex M_o\to 0$ because the number of distinct nodes decrease.
    %  \end{remark} 
      
     % Fig. \ref{fig: R_0} plots $R_0$ versus $\gamma$ for a set of $\bar\rho\triangleq\rho/(2\pi)^2$. As the density ratio $\lambda/\rho$ increases or the preference for nearby connections $\gamma$ decreases, $\Ex M_o$ increases. The upper bound $tM$ is achieved when $\gamma=0$ or $\bar\rho\to\infty$.
%   \begin{figure}
%       \centering
%       \includegraphics[width=0.5\textwidth]{R0vsmu2.eps}
%       \caption{Simulation results of $R_0$ using \eqref{eq: R_0}. }
%       \label{fig: R_0}
%   \end{figure}
 
% \begin{equation}
%       R_0\approx p(1-\mathcal{L}_\alpha(N))/(1-p)(1-\exp(-\beta))
%       \end{equation}
    
    %  \subsection{Speed of spread}
%       \begin{figure}
%     \begin{subfigure}[b]{0.45\textwidth}
%       \includegraphics[width=\textwidth]{var_R_0.eps}
%       \caption{$f_1$.}
%       \end{subfigure}
%       \hfill
%     \begin{subfigure}[b]{0.45\textwidth}
%       \includegraphics[width=\textwidth]{var_R_0.eps}       \caption{$f_2$.}
%       \end{subfigure}
%       \caption{Mean and variance of $M_o$.}
%       \label{fig: mean_var_M_o}
%   \end{figure}   
   
  

%The probability that the disease dies out is lower-bounded by 
%\begin{equation}
%    \Ex \prod_{x\in\Phi}(1-p_x)
%\end{equation}
%    \subsection{Clustering (tentative)}
%    \hl{Need the definition of clustering. Assuming the disease spreads from a single infected user, this seems a straightforward result as the result of the monotonicity of $f$... Connection with $g(r)$?}
%    
%If at the beginning of the spread, nodes are infected iid with probability $p$, $i.e.,$ both susceptible and infected nodes are PPPs with intensity $(1-p)\lambda$ and $p\lambda$, respectively. The probability of the typical susceptible node getting infected at the end of the first slot immediately follows from Eq (\ref{eq: LaplaceN}) by replacing $\lambda$ with $p\lambda$.   The probability of the typical (susceptible) node getting infected is 
%     \begin{align}
%         \Pr(Z^{1} = \mathrm{I} \mid Z^{0} = \mathrm{S}) &= \Ex [1-\exp(-\alpha N)] \\
%         & = 1-\mathcal{L}_{N}(\alpha).\label{eq: StoI-PPP}
%     \end{align}
%By ergodicity, it is equivalent to the fraction of susceptible nodes infected in a single realization.
%  
%    If the locations of infected nodes followed a PPP throughout the disease spread, then the system is fully characterized by Eq (\ref{eq: StoI-PPP}). In other words, given the parameters and starting condition, the transition probability between compartments are known. However, given the geometric dependence, infections likely cause a clustering effect around higher-density hubs and infected nodes. As a result, there are fewer infected nodes around susceptible ones, leading to a slow down of spread. 
%    


  \begin{figure*}[t]
       \centering
       \subfigure[Mean and the standard deviation of $N$. ]{           \psfrag{EN}{$\mathbb{E}N$}
       \psfrag{VN, lambda = 5, mu=50}{$\sqrt{\mathbb{V}N},\lambda=5,\mu=50$}
              \psfrag{VN, lambda = 50, mu=5}{$\sqrt{\mathbb{V}N},\lambda=50,\mu=5$}

\includegraphics[width=.42\textwidth]{fig/N_o_disk_2.eps}
       %  \caption{$f(r) = \exp(-9.426r)$}
         \label{fig: N_o}}
     \hfill
     \subfigure[Mean and the standard deviation of $M$. ]{ 
     \psfrag{EM, rho = 01}{$\mathbb{E}M,\lambda=5,\mu=50$}
          \psfrag{EM}{$\mathbb{E}M,\lambda=50,\mu=5$}
          \psfrag{sqrt{{V}M}, rho = 0111}{$\sqrt{\mathbb{V}M},\lambda=5,\mu=50$}
  \psfrag{sqrt{{V}M}, rho = 10102}{$\sqrt{\mathbb{V}M},\lambda=50,\mu=5$}
\includegraphics[width=.42\textwidth]{fig/M_o_disk_3.eps}
         \label{fig: illu-g}}
           \caption{Mean and standard deviation of $N$ and $M$ for $f =\ind{(r\leq 0.2122)}$. We compare $(\lambda,\mu) = (5,50), (50,5)$ respectively. $\Ex N=5$. $\sqrt{\Var{M}}$ is obtained via simulation whereas the rest via Corollary 2.}
         \label{fig: N_oM_o_disk}
   \end{figure*} 



%Observe that for $p\in(0,1]$ replacing $\mu$ by  $\mu/p^2$ and $f(r)$ by $pf(r)$ does not change $\Ex M_o$. In contrast, replacing $\lambda$ by  $\lambda/p^2$ and $f(r)$ by $pf(r)$ increases $\Ex M_o$.
  \begin{corollary}
  \label{cor: dispersed-mean-degree}
   For all $f$, $\Ex^{} M$ for $f_p$ monotonically decreases with $p$. For all $f$, $\Ex^{} M$ monotonically increases with $\lambda/\mu$ for fixed $\lambda\mu$. Further,
   
 \setcounter{equation}{\value{MYtempeqncnt}+3}
  \begin{equation}
 \lim_{p\to 0} \Ex^{} M = \Ex^{} N.
  \end{equation}
  \begin{equation}
 \lim_{\frac{\lambda}{\mu}\to \infty} \Ex^{} M = \Ex^{} N.
  \end{equation}
 \end{corollary}
 \begin{proof}
Let us write $\Ex^{} M$ for $f_p$  as
 \begin{equation}
\begin{split}\nonumber
   &\Ex^{} M\\
   & = \lambda\int_{\mathbb{R}^d}  1-\exp\left(-\mu p^2\int_{\mathbb{R}^d}f(\sqrt[d]{p}\|y\|)f(\sqrt[d]{p}\|x-y\|)\dd y\right)\dd x\\
   &  \peq{a} \frac{\lambda}{p}\int_{\mathbb{R}^d}   1-\exp\left(-\mu p\int_{\mathbb{R}^d}f(\|v\|)f(\|u-v\|)\dd v\right)\dd u.
   %\\
   %& = \lambda\int_{\mathbb{R}^2}  1-\exp\left(-\mu p\int_{\mathbb{R}^2}f(\|y\|)f(\|\sqrt{p}x-y\|)\dd y\right)\dd x
 %& = \int_{\mathbb{R}^2} \frac{\lambda}{p} \left( 1-\exp\left(-\mu p\int_{\mathbb{R}^2}f(\|y\|)f(\|x-y\|)\dd y\right)\right) \dd x
 \end{split}
 \end{equation}
% Taking the derivative of the last equation with respect to $p$,
% \begin{equation}
%     \frac{\dd \Ex M_o}{\dd p}  = \lambda \int_{\mathbb{R}^2}  \mu\sqrt{p} \int_{\mathbb{R}^2}f(\|y\|)f'(\|\sqrt{p}x-y\|)\dd y \exp\left(-\mu p\int_{\mathbb{R}^2}f(\|y\|)f(\|\sqrt{p}x-y\|)\dd y\right)\dd x,
% \end{equation}
% is negative by the monotonicity of $f$. 
Step (a) follows from change of variables $u=\sqrt{p}x,~v=\sqrt{p}y$.
The last equation monotonically decreases with the increase of $p$ since $(1-\exp(-C x))/x$ monotonically decreases with $x$.
Further, this shows that for $\Ex M$, stretching $f$ to $f_p$ is equivalent to scaling the network by $\lambda' = \lambda/p$ and $\mu'=\mu p$.
As $p\to0$, all terms in the series expression of the integrand containing $p$ go to 0, hence the convergence to $\Ex N$.
 \end{proof}

\begin{remark}Recall that $N=M$ when each pair of agents are connected through at most one hub. 
 For fixed $\lambda\mu$, as $\lambda/\mu\to\infty$, the number of hubs for the typical agent decreases per (\ref{eq: EN_hub}). Intuitively, most agents only have an edge to their closest hub. 
 On the other hand, as $p\to0$, two agents in proximity are less unlikely to be connected through common hubs, and geometry has a diminishing impact on connections. The graph eventually becomes an arbitrarily large abstract random graph.  Since $N-M$ is a non-negative integer, Corollary 1 also implies the convergence of $M$ to $N$ in probability.
\end{remark}
% \begin{remark}
%     A similar result can be derived when considering the mean number of hubs connected with hubs and letting $\mu/\lambda\to\infty$. We omit its discussion due to its symmetry to the described result as well as its lack of physical relevance.
% \end{remark}
 
 
 \subsection{Examples}
   In this subsection, we consider an example with $d=2$ and two special connection functions. 
    
    The first is\begin{equation}
  \nonumber  f_1(r) = \ind{(r\leq \theta)},\quad r\geq 0,\label{eq: disk}
      \end{equation} 
      where $\theta>0$ is the cut-off radius for drawing an edge between a agent and a hub. Two agents potentially have common hubs only if the intersection of their disks of radius $\theta$ are nonempty regardless of $\Psi$.
      
The second is
   \begin{equation}
\nonumber        f_2(r) =\frac{1}{2}\exp(-r/\theta),\quad r\geq 0.
\label{eq: exp dist}
\end{equation}
which has infinite support.
 


For both connection functions, the degree of the typical agent is Poisson distributed with mean 
    \begin{align}
      \Ex \sum_{y\in\Psi}I(o,y)&= \int_{0}^{\infty}\exp(- r/\theta)\pi\mu r \dd r\nonumber\\
      &=\int_{0}^{\infty} 2\pi\mu r \ind{(r\leq \theta)} \dd r\nonumber\\
      &= {\pi\mu}{\theta^2}.\nonumber\label{eq: EN_hub}
    \end{align}
%  The mean total length of the edge of the typical agent is
% \begin{align}
%       \Ex D_o = \int_{0}^{\infty} \exp(-r/\theta ) 2\pi\mu r^2 \dd r= {2\pi\mu}{\theta^3}.\label{eq: EN_hub}
%     \end{align}
    % and
    % \begin{align}
    %   \Ex D_o = \int_{0}^{\infty} \ind{(r\leq \theta)}2\pi\mu r^2 \dd r= \frac{2\pi\mu \theta^3}{3}.
    % \end{align}

   
\begin{corollary}
\label{cor: examples-N-M}
 For $f_1(r)= \ind{(r\leq \theta)}$, $\Ex N = \lambda\mu\pi^2\theta^4$, and 
 \begin{equation}
        \Ex M 
         = \int_{0}^{2\theta}2\pi\lambda v\left(1-e^{-\mu (2\theta^2\arccos(v/2\theta)-v\sqrt{\theta^2-v^2/4})}\right)\dd v.
        \label{eq: E M_0 disk}
\end{equation}
For $f_2(r)= \exp(-r/\theta)/2$,  $\Ex N = {\lambda\mu\pi^2}{\theta^4},$
and
\begin{align}
        \Ex M = \int_{0}^{\infty}2\pi\lambda v\left(1-e^{-\frac{\mu\pi v}{16}{({2\theta K_1(v/\theta)}+vK_0(v/\theta)})}\right)\dd v.\label{eq: E M_0 exp}
        \end{align}
% \begin{figure*}[t]
% \normalsize
% \setcounter{MYtempeqncnt}{\value{equation}}
% \setcounter{equation}{\value{equation}}
% \begin{align}
%         \Ex M_o 
%         & = \int_{0}^{\infty}2\pi\lambda v\left(1-\exp\left(-\frac{\mu\pi}{16} v^2\left(\frac{2\theta K_1(v/\theta)}{v}+K_0(v/\theta  \big)\right)\right)\right)\dd v.\label{eq: E M_0 exp}
%         \end{align}
%         \setcounter{equation}{\value{MYtempeqncnt}+1}
% \hrulefill
% \vspace*{4pt}
% \end{figure*}
where $K_n(\cdot)$ is the modified Bessel function of the second kind.



 
% \begin{figure*}[t]
% \normalsize
% \setcounter{MYtempeqncnt}{\value{equation}}
% \setcounter{equation}{\value{equation}}
% \begin{align}
%         \Ex M_o 
%         & = \int_{0}^{2\theta}2\pi\lambda v\left(1-\exp\left(-\mu \big(2\theta^2\arccos(v/2\theta)-v\sqrt{\theta^2-v^2/4}\big)\right)\right)\dd v.
%         \label{eq: E M_0 disk}
% \end{align}
% \setcounter{equation}{\value{MYtempeqncnt}+1}
% \hrulefill
% \vspace*{4pt}
% \end{figure*}
\end{corollary}    
\begin{proof}
For $f_1$, note that only agents within radius $2\theta$ can be connected to the typical agent $o$. Then the expression follows from the area of the intersection of two disks with radius $\theta$. For $f_2$, see Appendix \ref{appendix: examples-N-M}. 
\end{proof}
\begin{remark}
The integrand in $\Ex M$ has bounded support if and only if the connection function $f$ has bounded support, in which case its support is twice the support of $f$. 
\end{remark}

The numerical evaluations of (\ref{eq: E M_0 disk})  and (\ref{eq: E M_0 exp}) take a few millisecond using Matlab. $\Ex M$ increases linearly with $\lambda$ and sublinearly with $\mu$. As $\mu\to0$, $\Ex M$ is a linear function of $\mu$ asymptotically (see Remark 1). 
Fig. \ref{fig: N_oM_o_disk} plots the mean and variance of $N,~M$ for a fixed $\Ex N$ and $f_p(r)= pf(\sqrt{p}r)$, $p\in(0,1]$. 


      