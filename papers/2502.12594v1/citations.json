[
  {
    "index": 0,
    "papers": [
      {
        "key": "sparsegpt2023elias",
        "author": "Elias Frantar and\nDan Alistarh",
        "title": "SparseGPT: Massive Language Models Can be Accurately Pruned in One-Shot"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "wanda2024mingjie",
        "author": "Mingjie Sun and\nZhuang Liu and\nAnna Bair and\nJ. Zico Kolter",
        "title": "A Simple and Effective Pruning Approach for Large Language Models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "besa2024peng",
        "author": "Peng Xu and\nWenqi Shao and\nMengzhao Chen and\nShitao Tang and\nKaipeng Zhang and\nPeng Gao and\nFengwei An and\nYu Qiao and\nPing Luo",
        "title": "{BESA:} Pruning Large Language Models with Blockwise Parameter-Efficient\nSparsity Allocation"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "owl2024lu",
        "author": "Lu Yin and\nYou Wu and\nZhenyu Zhang and\nCheng{-}Yu Hsieh and\nYaqing Wang and\nYiling Jia and\nGen Li and\nAjay Kumar Jaiswal and\nMykola Pechenizkiy and\nYi Liang and\nMichael Bendersky and\nZhangyang Wang and\nShiwei Liu",
        "title": "Outlier Weighed Layerwise Sparsity {(OWL):} {A} Missing Secret Sauce\nfor Pruning LLMs to High Sparsity"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "zhi2024dass",
        "author": "Zhiyu Guo and\nHidetaka Kamigaito and\nTaro Wanatnabe",
        "title": "Dependency-Aware Semi-Structured Sparsity of {GLU} Variants in Large\nLanguage Models"
      },
      {
        "key": "copal2024srikanth",
        "author": "Srikanth Malla and\nJoon Hee Choi and\nChiho Choi",
        "title": "{COPAL:} Continual Pruning in Large Language Generative Models"
      },
      {
        "key": "sparsegpt2023elias",
        "author": "Elias Frantar and\nDan Alistarh",
        "title": "SparseGPT: Massive Language Models Can be Accurately Pruned in One-Shot"
      },
      {
        "key": "wanda2024mingjie",
        "author": "Mingjie Sun and\nZhuang Liu and\nAnna Bair and\nJ. Zico Kolter",
        "title": "A Simple and Effective Pruning Approach for Large Language Models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "ma2023llm",
        "author": "Ma, Xinyin and Fang, Gongfan and Wang, Xinchao",
        "title": "Llm-pruner: On the structural pruning of large language models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "slidegpt2024saleh",
        "author": "Saleh Ashkboos and\nMaximilian L. Croci and\nMarcelo Gennari Do Nascimento and\nTorsten Hoefler and\nJames Hensman",
        "title": "SliceGPT: Compress Large Language Models by Deleting Rows and Columns"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "nash2023jongwoo",
        "author": "Jongwoo Ko and\nSeungjoon Park and\nYujin Kim and\nSumyeong Ahn and\nDu{-}Seong Chang and\nEuijai Ahn and\nSe{-}Young Yun",
        "title": "{NASH:} {A} Simple Unified Framework of Structured Pruning for Accelerating\nEncoder-Decoder Language Models"
      },
      {
        "key": "flap2024yongqi",
        "author": "Yongqi An and\nXu Zhao and\nTao Yu and\nMing Tang and\nJinqiao Wang",
        "title": "Fluctuation-Based Adaptive Structured Pruning for Large Language Models"
      },
      {
        "key": "sleb2024jiwon",
        "author": "Jiwon Song and\nKyungseok Oh and\nTaesu Kim and\nHyungjun Kim and\nYulhwa Kim and\nJae{-}Joon Kim",
        "title": "{SLEB:} Streamlining LLMs through Redundancy Verification and Elimination\nof Transformer Blocks"
      },
      {
        "key": "sheared2024mengzhou",
        "author": "Mengzhou Xia and\nTianyu Gao and\nZhiyuan Zeng and\nDanqi Chen",
        "title": "Sheared LLaMA: Accelerating Language Model Pre-training via Structured\nPruning"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "weifinetuned",
        "author": "Wei, Jason and Bosma, Maarten and Zhao, Vincent and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V",
        "title": "Finetuned Language Models are Zero-Shot Learners"
      },
      {
        "key": "wang2023self",
        "author": "Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A and Khashabi, Daniel and Hajishirzi, Hannaneh",
        "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "sanhmultitask",
        "author": "Sanh, Victor and Webson, Albert and Raffel, Colin and Bach, Stephen and Sutawika, Lintang and Alyafeai, Zaid and Chaffin, Antoine and Stiegler, Arnaud and Raja, Arun and Dey, Manan and others",
        "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization"
      },
      {
        "key": "liangexploring",
        "author": "Liang, Shihao and Tian, Runchu and Zhu, Kunlun and Qin, Yujia and Wang, Huadong and Cong, Xin and Liu, Zhiyuan and Liu, Xiaojiang and Sun, Maosong",
        "title": "Exploring Format Consistency for Instruction Tuning"
      },
      {
        "key": "zhou2024lima",
        "author": "Zhou, Chunting and Liu, Pengfei and Xu, Puxin and Iyer, Srinivasan and Sun, Jiao and Mao, Yuning and Ma, Xuezhe and Efrat, Avia and Yu, Ping and Yu, Lili and others",
        "title": "Lima: Less is more for alignment"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "zhaolora",
        "author": "Zhao, Weilin and Huang, Yuxiang and Han, Xu and Liu, Zhiyuan and Zhang, Zhengyan and Li, Kuai and Chen, Chen and Yang, Tao and Sun, Maosong",
        "title": "CA-LoRA: Adapting Existing LoRA for Compressed LLMs to Enable Efficient Multi-Tasking on Personal Devices"
      },
      {
        "key": "ma2023llm",
        "author": "Ma, Xinyin and Fang, Gongfan and Wang, Xinchao",
        "title": "Llm-pruner: On the structural pruning of large language models"
      }
    ]
  }
]