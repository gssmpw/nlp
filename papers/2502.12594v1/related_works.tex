\section{Related Works}
\textbf{Large Language Model Pruning} can be generally divided into three categories: unstructured pruning, semi-structured pruning, and structured pruning. Unstructured pruning removes individual weights without structural constraints, with representative works including SparseGPT~\citep{sparsegpt2023elias}, Wanda~\citep{wanda2024mingjie}, BESA~\citep{besa2024peng}, and OWL~\citep{owl2024lu}. This technique allows for maximum flexibility in weight selection and can achieve high compression rates while maintaining model performance. However, the resulting irregular sparsity patterns limits the practical acceleration. 
%While achieving high compression rates, it often results in irregular patterns limiting practical speedups.
Semi-structured pruning~\citep{zhi2024dass, copal2024srikanth, sparsegpt2023elias, wanda2024mingjie} targets specific patterns like N:M sparsity, balancing flexibility and hardware efficiency. Structured pruning approaches like LLM-Pruner~\citep{ma2023llm} and SliceGPT~\citep{slidegpt2024saleh} remove entire structural components, offering better hardware compatibility and attracting industry attention~\citep{nash2023jongwoo, flap2024yongqi, sleb2024jiwon, sheared2024mengzhou}. However, structured pruning faces more severe performance degradation, highlighting the importance of recovery post-training.

\textbf{Instruction Tuning} has emerged as a crucial technique for enhancing LLMs~\citep{weifinetuned, wang2023self}, improving their adaptability to novel tasks~\citep{sanhmultitask, liangexploring, zhou2024lima}. Recent works have explored instruction tuning as a post-compression recovery mechanism~\citep{zhaolora, ma2023llm}. While promising, this combination faces challenges from reduced model capacity and computational costs. Most current approaches use general instruction datasets without considering compressed model's characteristics or disproportionately affected capabilities. Our work addresses these gaps by proposing a novel framework for post-training data selection in pruned LLM recovery.