@article{Fang2023BiasOA,
  title={Bias of AI-generated content: an examination of news produced by large language models},
  author={Xiao Fang and Shangkun Che and Minjia Mao and Hongzhe Zhang and Ming Zhao and Xiaohang Zhao},
  journal={Scientific Reports},
  year={2023},
  volume={14},
  url={https://api.semanticscholar.org/CorpusID:261898112}
}

@inproceedings{Liang2021TowardsUA,
  title={Towards Understanding and Mitigating Social Biases in Language Models},
  author={Paul Pu Liang and Chiyu Wu and Louis-Philippe Morency and Ruslan Salakhutdinov},
  booktitle={International Conference on Machine Learning},
  year={2021},
  url={https://api.semanticscholar.org/CorpusID:235623756}
}

@article{Munoz-Ortiz2024,
  title={Contrasting Linguistic Patterns in Human and LLM-Generated News Text},
  author={Alberto Muñoz-Ortiz and Carlos Gómez-Rodríguez and David Vilares},
  journal={Artificial Intelligence Review},
  volume={57},
  pages={265},
  year={2024},
  doi={10.1007/s10462-024-10903-2}
}

@article{bai2024measuring,
  title={Measuring implicit bias in explicitly unbiased large language models},
  author={Bai, Xuechunzi and Wang, Angelina and Sucholutsky, Ilia and Griffiths, Thomas L},
  journal={arXiv preprint arXiv:2402.04105},
  year={2024}
}

@article{beatty2024revealing,
  title={Revealing Hidden Bias in AI: Lessons from Large Language Models},
  author={Beatty, Django and Masanthia, Kritsada and Kaphol, Teepakorn and Sethi, Niphan},
  journal={arXiv preprint arXiv:2410.16927},
  year={2024}
}

@inproceedings{chen2024slight,
  title={Slight Corruption in Pre-training Data Makes Better Diffusion Models},
  author={Chen, Hao and Han, Yujin and Misra, Diganta and Li, Xiang and Hu, Kai and Zou, Difan and Sugiyama, Masashi and Wang, Jindong and Raj, Bhiksha},
  booktitle={Thirty-Eighth Annual Conference on Neural Information Processing Systems (NeurIPS)},
  year={2024}
}

@inproceedings{chenself,
  title={Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models},
  author={Chen, Zixiang and Deng, Yihe and Yuan, Huizhuo and Ji, Kaixuan and Gu, Quanquan},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@article{eloundou2024first,
  title={First-Person Fairness in Chatbots},
  author={Eloundou, Tyna and Beutel, Alex and Robinson, David G and Gu-Lemberg, Keren and Brakman, Anna-Luisa and Mishkin, Pamela and Shah, Meghan and Heidecke, Johannes and Weng, Lilian and Kalai, Adam Tauman},
  journal={arXiv preprint arXiv:2410.19803},
  year={2024}
}

@article{fisher2024biased,
  title={Biased ai can influence political decision-making},
  author={Fisher, Jillian and Feng, Shangbin and Aron, Robert and Richardson, Thomas and Choi, Yejin and Fisher, Daniel W and Pan, Jennifer and Tsvetkov, Yulia and Reinecke, Katharina},
  journal={arXiv preprint arXiv:2410.06415},
  year={2024}
}

@article{gallegos2024bias,
  title={Bias and fairness in large language models: A survey},
  author={Gallegos, Isabel O and Rossi, Ryan A and Barrow, Joe and Tanjim, Md Mehrab and Kim, Sungchul and Dernoncourt, Franck and Yu, Tong and Zhang, Ruiyi and Ahmed, Nesreen K},
  journal={Computational Linguistics},
  pages={1--79},
  year={2024},
  publisher={MIT Press 255 Main Street, 9th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{giorgi2024explicit,
  title={Explicit and Implicit Large Language Model Personas Generate Opinions but Fail to Replicate Deeper Perceptions and Biases},
  author={Giorgi, Salvatore and Liu, Tingting and Aich, Ankit and Isman, Kelsey and Sherman, Garrick and Fried, Zachary and Sedoc, Jo{\~a}o and Ungar, Lyle H and Curtis, Brenda},
  journal={arXiv preprint arXiv:2406.14462},
  year={2024}
}

@article{guo2024hey,
  title={Hey GPT, Can You be More Racist? Analysis from Crowdsourced Attempts to Elicit Biased Content from Generative AI},
  author={Guo, Hangzhi and Venkit, Pranav Narayanan and Jang, Eunchae and Srinath, Mukund and Zhang, Wenbo and Mingole, Bonam and Gupta, Vipul and Varshney, Kush R and Sundar, S Shyam and Yadav, Amulya},
  journal={arXiv preprint arXiv:2410.15467},
  year={2024}
}

@article{hu2024generative,
  author = {Hu, T. and Kyrychenko, Y. and Rathje, S. and others},
  title = {Generative language models exhibit social identity biases},
  journal = {Nature Computational Science},
  year = {2024},
  doi = {10.1038/s43588-024-00741-1}
}

@inproceedings{kotek2023gender,
  title={Gender bias and stereotypes in large language models},
  author={Kotek, Hadas and Dockum, Rikker and Sun, David},
  booktitle={Proceedings of the ACM collective intelligence conference},
  pages={12--24},
  year={2023}
}

@inproceedings{li2024culturepark,
  title={CulturePark: Boosting Cross-cultural Understanding in Large Language Models},
  author={Li, Cheng and Teney, Damien and Yang, Linyi and Wen, Qingsong and Xie, Xing and Wang, Jindong},
  booktitle={Thirty-Eighth Annual Conference on Neural Information Processing Systems (NeurIPS)},
  year={2024}
}

@inproceedings{longpre-etal-2024-pretrainers,
    title = "A Pretrainer`s Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, {\&} Toxicity",
    author = "Longpre, Shayne  and
      Yauney, Gregory  and
      Reif, Emily  and
      Lee, Katherine  and
      Roberts, Adam  and
      Zoph, Barret  and
      Zhou, Denny  and
      Wei, Jason  and
      Robinson, Kevin  and
      Mimno, David  and
      Ippolito, Daphne",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    pages = "3245--3276",
}

@inproceedings{lyu2023pathway,
  title={A pathway towards responsible AI generated content},
  author={Lyu, Lingjuan},
  booktitle={Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence},
  pages={7033--7038},
  year={2023}
}

@article{maheshwari2024efficacy,
  title={Efficacy of synthetic data as a benchmark},
  author={Maheshwari, Gaurav and Ivanov, Dmitry and Haddad, Kevin El},
  journal={arXiv preprint arXiv:2409.11968},
  year={2024}
}

@inproceedings{naous-etal-2024-beer,
    title = "Having Beer after Prayer? Measuring Cultural Bias in Large Language Models",
    author = "Naous, Tarek  and
      Ryan, Michael J  and
      Ritter, Alan  and
      Xu, Wei",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    publisher = "Association for Computational Linguistics",
    pages = "16366--16393",
}

@article{navigli2023biases,
  title={Biases in large language models: origins, inventory, and discussion},
  author={Navigli, Roberto and Conia, Simone and Ross, Bj{\"o}rn},
  journal={ACM Journal of Data and Information Quality},
  volume={15},
  number={2},
  pages={1--21},
  year={2023},
  publisher={ACM New York, NY}
}

@inproceedings{nghiem-etal-2024-gotta,
    title = "{\textquotedblleft}You Gotta be a Doctor, Lin{\textquotedblright} : An Investigation of Name-Based Bias of Large Language Models in Employment Recommendations",
    author = "Nghiem, Huy  and
      Prindle, John  and
      Zhao, Jieyu  and
      Daum{\'e} Iii, Hal",

    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    pages = "7268--7287",
}

@article{rogulsky2024effects,
  title={The Effects of Hallucinations in Synthetic Training Data for Relation Extraction},
  author={Rogulsky, Steven and Popovic, Nicholas and F{\"a}rber, Michael},
  journal={arXiv preprint arXiv:2410.08393},
  year={2024}
}

@inproceedings{seshadri2024bias,
  title={The Bias Amplification Paradox in Text-to-Image Generation},
  author={Seshadri, Preethi and Singh, Sameer and Elazar, Yanai},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages={6367--6384},
  year={2024}
}

@inproceedings{shaib-etal-2024-detection,
    title = "Detection and Measurement of Syntactic Templates in Generated Text",
    author = "Shaib, Chantal  and
      Elazar, Yanai  and
      Li, Junyi Jessy  and
      Wallace, Byron C",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    pages = "6416--6431"
}

@article{tao2024cultural,
  title={Cultural bias and cultural alignment of large language models},
  author={Tao, Yan and Viberg, Olga and Baker, Ryan S and Kizilcec, Ren{\'e} F},
  journal={PNAS nexus},
  volume={3},
  number={9},
  pages={346},
  year={2024},
}

@article{wang2024bias,
  title={Bias Amplification: Language Models as Increasingly Biased Media},
  author={Wang, Ze and Wu, Zekun and Zhang, Jeremy and Jain, Navya and Guan, Xin and Koshiyama, Adriano},
  journal={arXiv preprint arXiv:2410.15234},
  year={2024}
}

@article{zhang2024will,
  title={Will the Inclusion of Generated Data Amplify Bias Across Generations in Future Image Classification Models?},
  author={Zhang, Zeliang and Liang, Xin and Feng, Mingqian and Liang, Susan and Xu, Chenliang},
  journal={arXiv preprint arXiv:2410.10160},
  year={2024}
}

@article{zhu2024synthesize,
  title={How to Synthesize Text Data without Model Collapse?},
  author={Zhu, Xuekai and Cheng, Daixuan and Li, Hengli and Zhang, Kaiyan and Hua, Ermo and Lv, Xingtai and Ding, Ning and Lin, Zhouhan and Zheng, Zilong and Zhou, Bowen},
  journal={arXiv preprint arXiv:2412.14689},
  year={2024}
}

