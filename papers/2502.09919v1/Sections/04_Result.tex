
\section{Results \& Discussion}
In this section, we first introduce the AI-READI dataset used to train AttenGluco. We then compare its performance against a baseline model consisting if a 1D-CNN and LSTM for blood glucose forecasting to highlight the significance of our model for providing accurate forecasting. The baseline model, a multimodal LSTM, is commonly employed in state-of-the-art blood glucose prediction. The comparison is conducted using error metrics, including Root Mean Square Error (RMSE) and Mean Absolute Error (MAE), as well as correlation analysis. We investigate various training and testing scenarios to comprehensively evaluate the performance of AttenGluco.

\subsection{Dataset Description}
\label{section:dataset}
The dataset used in this study is the publicly available AI-READI Flagship Dataset. This dataset is designed to advance AI and machine learning research on Type 2 Diabetes Mellitus (T2DM). Collected from 1,067 participants across three U.S. sites. It includes individuals with and without T2DM, balanced across sex, race, and diabetes severity. The dataset consists of four categories: healthy individuals, individuals with prediabetes, individuals with T2DM on oral medication, and individuals with T2DM on insulin.

A key feature of the dataset is its multi-modal structure, where participants were monitored over ten days using a Dexcom G6 CGM for real-time blood glucose, a Garmin Vivosmart 5 for physical activity and heart rate variability, and a LeeLab Anura sensor for environmental factors such as air quality and temperature. The dataset also includes survey data, clinical assessments, and retinal imaging. Daily step counts are recorded via an accelerometer, with occasional gaps due to device recharging. The heart rate sensor also computed a stress index (0-100) based on heart rate variability.

For this study, CGM data and walking activity (steps and intervals) are extracted as key features. After filtering out subjects with missing data, 896 participants are included in the final analysis, distributed as follows: 323 healthy individuals, 207 pre T2DM, 258 with T2DM on oral medication, and 108 with T2DM on insulin.


\subsection{Experimental Setup}
The baseline model follows a 1D-CNN architecture coupled with an LSTM. The 1D-CNN consists of two convolutional layers with 64 and 128 filters, each using a kernel size of 3. This is followed by a two-layer LSTM with 128 and 64 output features. The LSTM output is then passed through an MLP composed of three fully connected layers. 

Both AttenGluco and the baseline model receive a sliding window of historical data covering 6.66 hours (400 minutes) as input. Training is conducted for 300 epochs with a learning rate of 0.001, optimizing the Mean Squared Error (MSE) using the Adam optimizer. Forecasting performance is assessed across three prediction horizons (PHs): 5 minutes, 30 minutes, and 60 minutes. To ensure consistency, each model undergoes five independent training runs. Model performance is assessed across all subjects, with comparisons based on RMSE~\cite{arefeen2023glysim}, MAE~\cite{arefeen2023glysim}, and Correlation~\cite{zhang2023joint}.

As mentioned in section~\ref{section:dataset}, the AI-READI dataset categorizes subjects into four cohorts (healthy, pre-T2DM, oral, and insulin) based on diabetes severity. To evaluate AttenGluco’s performance across these cohorts, we conducted three distinct experiments under different scenarios (subject training, cohort-wise fine-tuning, and forgetting analysis) and compared the results with the baseline model. The details of each scenario will be discussed in the following sections.

\subsubsection{Isolated Subject Training}
In this scenario, the CGM and activity data of AI-READI participants are first grouped according to their respective cohorts. The proposed model is then applied to each subject individually, with 85\% of their data used for training and the remaining 15\% reserved for testing. After evaluating one subject, the model is reinitialized before being trained and tested on the next. Table~\ref{tab:performance Person} presents the average error metrics for AI-READI participants across each cohort separately.
\vspace{-2mm}
\begin{table}[h]
\captionsetup{font=small} % Center caption
\caption{Comparison of baseline and AttenGluco performance across different cohorts in the isolated subject scenario. The best results are highlighted in bold.}
    \centering
    \renewcommand{\arraystretch}{1} % Adjust row height
    \setlength{\tabcolsep}{2pt} % Adjust column spacing
    \begin{adjustbox}{max width=\columnwidth}
    \begin{tabular}{|c|cc|cc|cc|}
        \hline
        \multirow{2}{*}{\textbf{Cohort}} & \multicolumn{2}{c|}{\textbf{RMSE}} & \multicolumn{2}{c|}{\textbf{MAE}} & \multicolumn{2}{c|}{\textbf{Correlation}} \\
        & Baseline & AttenGluco & Baseline & AttenGluco & Baseline & AttenGluco \\
        \hline
        Healthy     & 18.04 & \textbf{16.05} & 13.02  & \textbf{11.12} & 0.38 & \textbf{0.49} \\
        Pre-T2DM & 19.95 & \textbf{18.27} & 15.12  & \textbf{13.65} & 0.49 & \textbf{0.57} \\
        Oral        & 25.01  & \textbf{22.56} & 17.9   & \textbf{15.74} & 0.55 & \textbf{0.64} \\
        Insulin      & 29.9  & \textbf{27.18} & 22.28  & \textbf{19.93} & 0.59 & \textbf{0.67} \\
        \hline
    \end{tabular}
    \label{tab:performance Person}
    \end{adjustbox}
\end{table}

Table~\ref{tab:performance Person} depicts that our proposed method surpassed the baseline model in all performance metrics. For instance, compared to the baseline model, AttenGluco improves the RMSE metric by 11.03\%, 8.42\%, 9.79\%, and 9.09\% for the healthy, pre-T2DM, oral, and insulin cohorts, respectively.
\subsubsection{Cohort-Wise Fine-Tuning}
In the  cohort-wise fine-tuning scenario, the model is trained progressively within each participant category, unlike the isolated subject scenario where it is reset for each subject. Here, the model is first trained on one subject and then fine-tuned sequentially across the other subjects in the same category, with each subject serving as both training and testing data. This process continues until all subjects in a category have been used. Once a category is completed, the model is reinitialized before moving on to the next cohort. The average performance metrics for each category are presented in Table~\ref{tab:performance}. This approach enables the model to gradually adapt to variations within each cohort; therefore, it achieves better performance than the previous scenario.

\begin{table}[h]
    \centering
    \renewcommand{\arraystretch}{1.2} % Adjust row height
    \setlength{\tabcolsep}{6pt} % Adjust column spacing
    \captionsetup{justification=centering, font=small} % Center caption
    \caption{Performance comparison between the baseline model and AttenGluco across different cohorts in the cohort-wise fine-tuning scenario. The best scores are highlighted in bold.}
    \label{tab:performance}
    
    \begin{adjustbox}{max width=\columnwidth}
    \begin{tabular}{|l|cc|cc|cc|}
        \hline
        \multirow{2}{*}{\textbf{Cohort}} & \multicolumn{2}{c|}{\textbf{RMSE}} & \multicolumn{2}{c|}{\textbf{MAE}} & \multicolumn{2}{c|}{\textbf{Correlation}} \\
        & \textbf{Baseline} & \textbf{AttenGluco} & \textbf{Baseline} & \textbf{AttenGluco} & \textbf{Baseline} & \textbf{AttenGluco} \\
        \hline
        Healthy      & 17.79  & \textbf{15.45}   & 12.79  & \textbf{10.96}  & 0.44  & \textbf{0.53} \\
        Pre-T2DM & 19.77  & \textbf{17.47}   & 14.41  & \textbf{12.46}  & 0.51  & \textbf{0.6} \\
        Oral         & 23.37  & \textbf{20.45}   & 16.93  & \textbf{14.71}  & 0.57  & \textbf{0.67} \\
        Insulin      & 28.22  & \textbf{25.04}   & 20.51  & \textbf{18.03}  & 0.68  & \textbf{0.75} \\

        \hline
    \end{tabular}
    \end{adjustbox}
\end{table}
Referring to Table~\ref{tab:performance}, we conclude that AttenGluco outperforms the baseline model across all performance metrics. It improves RMSE by 13.15\%, 11.63\%, 12.49\%, and 11.27\% for the healthy, pre-T2DM, oral, and insulin cohorts, respectively.

% In this scenario, we also hypothesize that  Meaning that the newer subjects will yield lower error when used as the test subject. To test our hypothesis, we present
Fig.~\ref{fig:trendline} demonstrates that as more subjects are added into each cohort, the model's performance progressively improves in this scenario. This results in lower errors for newer subjects when used for testing. Notably, the reduction in test error is more significant in AttenGluco, indicating that its performance could further improve with a larger training dataset. For improved clarity and better visibility, we illustrate only 80 subjects of each cohort in Fig.~\ref{fig:trendline} while maintaining the overall distribution and trends of the complete dataset.

Moreover, we evaluate the AttenGluco's forecasting RMSE at different PH values of $5$, $30$, and $60$ minutes. Since CGM data is recorded at 5-minute intervals, a PH of 5 minutes corresponds to \( m = 1 \) sample, a PH of 30 minutes corresponds to \( m = 6 \) samples, and a PH of 60 minutes corresponds to \( m = 12 \) samples. Table~\ref{tab:rmse_comparison} presents a comparison of AttenGluco and the baseline model across different PHs. As shown, increasing the PH leads to a higher RMSE for both models. However, while the baseline model experiences a significant drop in performance, AttenGluco maintains a relatively stable RMSE. This demonstrates AttenGluco's robustness in long-term forecasting.
\begin{table}[h]
\vspace{-1.5mm}
    \centering
    \renewcommand{\arraystretch}{1.2} % Adjust row height
    \setlength{\tabcolsep}{8pt} % Adjust column spacing
    \caption{\small RMSE Comparison of Baseline and AttenGluco Models Across Different PHs}
    \label{tab:rmse_comparison}
     \begin{adjustbox}{max width=\columnwidth}
    \begin{tabular}{|l|ccc|ccc|}
        \hline
        \multirow{2}{*}{\textbf{Cohort}} & \multicolumn{3}{c|}{\textbf{Baseline RMSE}} & \multicolumn{3}{c|}{\textbf{AttenGluco RMSE}} \\
        & \textbf{5 min} & \textbf{30 min} & \textbf{60 min} & \textbf{5 min} & \textbf{30 min} & \textbf{60 min} \\
        \hline
        Healthy        & 7.35  & 14.37  & 17.79  & 7.63  & 12.38  & 15.45 \\
        Pre-T2DM   & 7.94  & 15.43  & 19.77  & 8.70  & 13.50  & 17.47 \\
        Oral           & 9.15  & 17.73  & 23.37  & 9.33  & 15.21  & 20.45 \\
        Insulin        & 12.11 & 21.00  & 28.22  & 11.94 & 18.55  & 25.04 \\
        \hline
    \end{tabular}
    \end{adjustbox}
\end{table}
% \subsection{Group fine-tuning}
% In the Group fine-tuning scenario, we combined all category participants and ignore their belonging category. Then, the model are trained on one subject and fine-tuned on the other subjects. Note that for a fair comparison, we consider the same percentage of train and test data for each subject. The error metrics average for all participants of dataset are reported in Table~\ref{tab:performance}.
% \begin{table}[h]
%     \centering
%     \renewcommand{\arraystretch}{1.2} % Adjust row height
%     \setlength{\tabcolsep}{6pt} % Adjust column spacing
%     \captionsetup{justification=centering} % Center caption
%     \caption{Comparison of RMSE, MAE, and Correlation for LSTM and Transformer models across different subject categories.}
%     \label{tab:performance}
%     \begin{adjustbox}{max width=\columnwidth}
%     \begin{tabular}{|l|cc|cc|cc|}
%         \hline
%         \textbf{Category} & \multicolumn{2}{c|}{\textbf{RMSE}} & \multicolumn{2}{c|}{\textbf{MAE}} & \multicolumn{2}{c|}{\textbf{Correlation}} \\
%         & \textbf{LSTM} & \textbf{Transformer} & \textbf{LSTM} & \textbf{Transformer} & \textbf{LSTM} & \textbf{Transformer} \\
%         \hline
%         Healthy      & 20.65  & 24.95   & 15.34  & 20.35  & 0.36  & 0.47 \\
%         Pre-diabetes & 27.99  & 28.09   & 21.44  & 22.50  & 0.49  & 0.42 \\
%         Oral         & 36.43  & 28.56   & 30.28  & 22.81  & 0.32  & 0.73 \\
%         Insulin      & 81.91  & 76.55   & 61.89  & 58.64  & 0.39  & 0.45 \\
%         \hline
%          Average & 41.75  & 39.54   & 32.24  & 31.08  & 0.39  & 0.52 \\
%         \hline
%     \end{tabular}
%     \end{adjustbox}
% \end{table}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{Figures/trendline.pdf}
    \caption{\small The RMSE of each subject in (a) the baseline model and (b) AttenGluco under the cohort-wise scenario. As observed, AttenGluco's RMSE decreases significantly within each cohort as more subjects are incorporated into the fine-tuning process.}
    \label{fig:trendline}
\end{figure}
\subsubsection{Continual Learning and Forgetting Analysis}
Even though transferring the model to and fine-tuning it on new subjects enhances the model's performance on new data, it simultaneously leads to the loss of previously learned knowledge. This phenomenon, known as catastrophic forgetting~\cite{kirkpatrick2017overcoming}, is a well-known issue that happens with model retraining. The problem becomes more pronounced when there is a significant distribution shift between the old and new data, which causes the model to prioritize recent patterns while disregarding past ones.

We hypothesize that a distribution shift exists among the four cohorts, which potentially causes the model to forget previously learned information as new cohorts are introduced. To measure forgetting in both models, we evaluate their performance on prior cohorts after completing training on new ones. In this scenario, the model continues training on all subjects of the cohorts without reinitialization. The results are presented in Fig.~\ref{fig:cl_results}, where the x-axis represents the training cohorts, and each grouped bar chart illustrates the model’s performance after training on the respective cohort. As shown, the introduction of new cohorts degrades both model’s retention of previous knowledge.
\begin{figure}
\vspace{-2mm}
    \centering
    \includegraphics[width=\linewidth]{Figures/cl_results.pdf}
    \caption{Fine-tuning the model on new cohorts leads to the loss of knowledge from previous ones.}
    \label{fig:cl_results}
    \vspace{-2mm}
\end{figure}