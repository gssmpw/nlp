


\section{Model Architecture and Training Details}
\label{app:model_details}

\Cref{tab:model_details} provides details of the model architecture and training hyperparameters that were used to train the COMET models in this paper.

Unless otherwise specified, the configuration of \href{https://github.com/Unbabel/COMET/blob/master/configs/models/referenceless_model.yaml}{referenceless COMET} is used.
Our models are largely compatible with the upstream COMET repository and can be reproduced based on our code.
We run all our experiments on Nvidia A100 (40GB) GPUs, taking about 8 hours to train a single model (2.2GB) for 5 epochs.
For each setting, we train a single model and report its performance.
In total, all experiments, including preliminary ones, amounted to approximately 20$\times$8 hours = 160 hours of compute on the aforementioned GPU.
We base our experiments on a modified COMET v2.2.4 codebase with other package versions listed as dependencies in this version.

\begin{table}[htbp]
\small
\centering
\begin{tabular}{ll}
\toprule
Encoder & xlm-roberta-large (24 layers) \\
Embeddings & Layerwise attention \& CLS \\
Encoder frozen & 30\% of first epoch \\
Regression head & $(4{\times}768)\times 2048{\times}1024 \times (1$ or $2)$\\
Optimizer & AdamW \\
Learning rate & $1.5\times10^{-5}$, encoder $10^{-6}$ \\
Batch size &  256 (simulated) \\
Loss & MSE for both targets \\
Training epochs & 5 \\
\bottomrule
\end{tabular}
\caption{Model architecture and training details. 
}
\label{tab:model_details}
\end{table}

\section{Replicating HTS model}
\label{sec:fail_hts}
\citet{zerva-etal-2022-disentangling} propose a quality estimation model that outputs a distribution by predicting its mean and variance.
Loosely, this can be interpreted as the score and confidence prediction.
However, no public model is available and we have been unable to reproduce the model based on the \href{https://github.com/deep-spin/uncertainties_MT_eval}{publicly available code}.
Upon making the changes in the code that make the codebase compatible with up-to-date packages we did train a model with the \texttt{hts} loss, though the resulting human and error correlations were only 0.247 and 0.206, respectively.
Because this strays far from the original reported results, we attribute this to reproducibility failure as opposed to failure of the method.
\citet{zouhar-etal-2024-pitfalls} already show that the differences in COMET codebase versions can cause large discrepancies in COMET model behavior.
While our work uses the latest COMET v2.2.4, the work of \citet{zerva-etal-2022-disentangling} used COMET v1.0.0rc4.


\section{Additional Plots for Instant Confidence COMET}
\label{app:confidence_add_plots}

We provide additional plots showing the quality of the Instant Confidence COMET error predictions. In \Cref{fig:13-plot_conf} we plot the average predicted error versus the true error to indicate average alignment. We also include correlation scores for selected layers showing the correlation between the predicted and true errors, e.g., $0.44$ for layer $9$ scores.
In \Cref{fig:15c-expected_calibration_error} we plot the average error for different confidence bins based on Instant Confidence. We see that the true error decreases as the predicted confidence increases. The plot also indicates that the score predictions with the highest and lowest true errors are reliably identified by the predicted instant confidence values.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{generated/13-plot_conf_last.pdf}
    \caption{Correspondence of true and instant self-confidence. Correlations in brackets are Pearson correlation for each layer.}
    \label{fig:13-plot_conf}
\end{figure}


\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{generated/15c-expected_calibration_error.pdf}
    \caption{Calibration of predicted quality estimation model confidence based on 100 confidence bins (x-axis) and mean true absolute error of the prediction in each bin (y-axis).
    }
    \label{fig:15c-expected_calibration_error}
\end{figure}

\section{Baseline Early Exit Algorithms}
\label{app:early_exit_algorithms}

Below we provide pseudocode for the early-exit algorithms that we use as baselines to compare with Confidence-Exit. These baselines do not use the confidence scores of Early-Exit COMET.

\Cref{alg:constant_algorithm} exits the COMET evaluation after a fixed, predefined layer, exit layer $k$. 

\Cref{alg:variance_algorithm} exits the COMET evaluation when Early-Exit COMET scores from three consecutive layers are close to each other, or more precisely, have variance below a chosen threshold $\tau$.


\begin{figure}[ht!]
{
\small
\hrule
\vspace{1mm}
\textbf{Inputs}: Source $s$, translation $t$, exit layer $k$ \\
\textbf{Output}: Quality estimation $\hat{y}$ 
\vspace{1mm}
\hrule
\vspace{1mm}
\begin{algorithmic}[1]

\State Compute $L_0(s, t)$
\For{$i \in 1\ldots k$}
    \State {Compute }$L_i(s,t)$ from $L_{i-1}(s,t)$ \Comment{next layer}
\EndFor    
\State $\hat{y}_k, \hat{e}_k \gets R(L_k)$ \Comment{apply regressor head}
\State \Return  $\hat{y}_{k}$ 
\end{algorithmic}
}
\vspace{1mm}
\hrule
\vspace{1mm}

\captionof{algorithm}{Constant-Exit with Early-Exit COMET.}
\label{alg:constant_algorithm}

\end{figure}


\begin{figure}[ht!]
{
\small
\hrule
\vspace{1mm}
\textbf{Inputs}: Source $s$, translation $t$, threshold $\tau$ \\
\textbf{Output}: Quality estimation $\hat{y}$ 
\vspace{1mm}
\hrule
\vspace{1mm}
\begin{algorithmic}[1]

\State Compute $L_0(s, t)$
\For{$i \in 1\ldots |L|$}
    \State {Compute }$L_i(s,t)$ from $L_{i-1}(s,t)$ \Comment{next layer}
    \State $\hat{y}_i, \hat{e}_i \gets R(L_i)$ \Comment{apply regressor head}
    \State \textbf{if} $\mathrm{Var}[\hat{y}_{i-2:i}]{<} \tau$ \textbf{then return} $\hat{y}_i$
    \Comment{early-exit}
\EndFor
\State \Return  $\hat{y}_{|L|}$ 
\end{algorithmic}
}
\vspace{1mm}
\hrule
\vspace{1mm}


\captionof{algorithm}{Variance-Exit with Early-Exit COMET.}
\label{alg:variance_algorithm}

\end{figure}






\section{Upper Confidence Bound Bandit Ablations}
\label{sec:bandit_ablations}

We now describe two variations to the Upper Confidence Bound Bandit algorithm described in \Cref{sec:goal_earlyexit2}: (1) starting at later layers, and (2) balancing exploration and exploitation.

\paragraph{Starting at Different Layers.}
Given the significant jump in COMET score accuracy within the first few layers of the COMET model (\Cref{10-eval_oxygen_hydrogen}), we decided to explore initializing the algorithm with different starting layers. This carries a higher initial cost as we have to run the first few layers of the COMET model for all candidates but could lead to better-informed exploration with the remaining budget.
The results in \Cref{fig:bandit_ablation_start} show that this leads to only marginal improvements.
\paragraph{Exploration-Exploitation Tradeoff.}
The heart of the multi-armed bandit problem is the exploration-exploitation trade-off.
In our algorithm this trade-off is controlled by the hyperparameter $\gamma$.
The higher one chooses $\gamma$, the higher the Upper Confidence Bound scores for uncertain candidates will be, and therefore the more likely the algorithm will be to explore many candidates.
On the other hand, a low $\gamma$ will lead the algorithm to go deep with the most promising candidates, i.e., those with the highest estimated scores. 
We provide results for two different values for $\gamma$ in \Cref{fig:bandit_ablation_gamma}, which shows that the default choice is likely the most apt.

\paragraph{Distribution of Max. Layers Calculated.}
We analyze the order in which the layers were calculated by the UCB bandit algorithm by taking snapshots of the max. layer calculated across all candidates at $5\%$ budget increments, from $5\%$ to $100\%$. We provide plots for the default UCB bandit hyperparameter values (start layer = 1, $\gamma = 1.0$) on the test set with the candidates generated via sampling. 

At the start (budget, $B=5\%$), only the first layer COMET scores are explored for (almost) all candidates, and by the end (budget, $B=100\%$) the full COMET scores are calculated for all candidates.
However, the distributions in between reveal that the bandit often explores the candidates up until certain modal layers. These can be clearly seen (e.g. for budget $B=50\%$) to be layers $3$, $4$, $11$, $18$, and $24$. Looking at \Cref{fig:13-plot_conf}, it can be seen that these values correspond to layers where the predicted error rates (uncertainties) drop significantly, meaning that the evaluation model is now more certain about these scores relative to scores for other candidates. This explains why the UCB bandit algorithm would then prefer to explore less certain candidates with higher UCB scores.













\begin{figure*}[t]
    \centering
    Beam-Search\\
    \includegraphics[width=0.49\linewidth]{generated/53-bandit_ablation_start_win_rate_beam.pdf}
    \hfill
    \includegraphics[width=0.49\linewidth]{generated/53-bandit_ablation_start_avg_score_beam.pdf}
    
    Sampling\\
    \includegraphics[width=0.49\linewidth]{generated/53-bandit_ablation_start_win_rate_sample.pdf}
    \hfill
    \includegraphics[width=0.49\linewidth]{generated/53-bandit_ablation_start_avg_score_sample.pdf}
    
    \caption{
    Ablation for the Upper Confidence Bound bandit by forcefully computing the first few layers. Quality is measured in terms of the average final candidate score and the proportion to top-1 candidates selected. We plot these measures for various evaluation budgets. Cost (or budget) is given relative to calculating the full COMET scores for all candidates ($100\%$).
    }
    \label{fig:bandit_ablation_start}
\end{figure*}

\begin{figure*}[t]
    \centering
    Beam-Search\\
    \includegraphics[width=0.49\linewidth]{generated/54-bandit_ablation_gamma_win_rate_beam.pdf}
    \hfill
    \includegraphics[width=0.49\linewidth]{generated/54-bandit_ablation_gamma_avg_score_beam.pdf}
    
    Sampling\\
    \includegraphics[width=0.49\linewidth]{generated/54-bandit_ablation_gamma_win_rate_sample.pdf}
    \hfill
    \includegraphics[width=0.49\linewidth]{generated/54-bandit_ablation_gamma_avg_score_sample.pdf}
    
    \caption{
    Ablation for the Upper Confidence Bound bandit with changing $\gamma$ (exploitation-exploration trade-off). With higher $\gamma$, the algorithm explores even otherwise low-scoring candidates. Quality is measured in terms of the average final candidate score and the proportion to top-1 candidates selected. We plot these measures for various evaluation budgets. Cost (or budget) is given relative to calculating the full COMET scores for all candidates ($100\%$).
    }
    \label{fig:bandit_ablation_gamma}
\end{figure*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{generated/models-oxygen_bandit_ucb_ablation_16000_norm_start0sample_viewed.pdf}
    \caption{
    Distributions of the highest COMET layer scores calculated by UCB bandit (start layer = 1, $\gamma = 1.0$) across different budgets. 
    The distributions are plotted for $5\%$ budget increments, from $5\%$ to $100\%$, on the test set with the candidates generated via sampling. 
    }
    \label{fig:bandit_layers_viewed}
\end{figure*}




\section{Reranking Results in Tabular Format}
\label{app:reranking_results_table}

\Cref{tab:bandit} provides the results from \Cref{fig:bandit} in tabular format.

\begin{table*}
\newcolumntype{Y}{p{6mm}}
\small
\centering
\begin{minipage}{0.2\linewidth}
\centering
\vspace{1em}
Beam-Search\\
Final candidate is top-1
\end{minipage}
\input{generated/52-bandit_win_rate_beam.tab.tex}

\begin{minipage}{0.2\linewidth}
\centering
Beam-Search\\
Final candidate score
\end{minipage}
\input{generated/52-bandit_avg_score_beam.tab.tex}

\begin{minipage}{0.2\linewidth}
\centering
Sampling\\
Final candidate is top-1
\end{minipage}
\input{generated/52-bandit_win_rate_sample.tab.tex}

\begin{minipage}{0.2\linewidth}
\centering
Sampling\\
Final candidate score
\end{minipage}
\input{generated/52-bandit_avg_score_sample.tab.tex}

\caption{
    Quality of the candidates returned by the Upper Confidence Bound bandit. Quality is measured in terms of the average final candidate score and the proportion to top-1 candidates selected. We plot these measures for various evaluation budgets. Cost (or budget) is given relative to calculating the full COMET scores for all candidates ($100\%$).
    Visualized in \Cref{fig:bandit}.
}
\label{tab:bandit}
\end{table*}




\begin{table*}[ht]
\newcolumntype{V}{>{\raggedleft\arraybackslash}p{6.8mm}}
\newcolumntype{Z}{>{\raggedleft\arraybackslash}p{8.3mm}}
\small
\setlength{\tabcolsep}{3pt}


\centering
\begin{tabular}{llVVVVVVVVVVVVVZ}
\parbox[t]{2mm}{\multirow{18}{*}{\rotatebox[origin=c]{90}{\bf Layer}}}
& \multicolumn{13}{c}{\bf \color{green!40!black} Layers} 
& \multicolumn{2}{r}{\bf \color{purple!80!black} Human} \\
\input{generated/10-eval_helium2hydrogen_big.tex}
\end{tabular} \\
Baseline COMET
\vspace{10mm}

\begin{tabular}{llVVVVVVVVVVVVVZ}
\parbox[t]{2mm}{\multirow{18}{*}{\rotatebox[origin=c]{90}{\bf Layer}}}
& \multicolumn{13}{c}{\bf \color{green!40!black} Layers} 
& \multicolumn{2}{r}{\bf \color{purple!80!black} Human} \\
\input{generated/10-eval_oxygen_big.tex}
\end{tabular} \\
Early-Exit COMET
\vspace{10mm}

\begin{tabular}{llVVVVVVVVVVVVVZ}
\parbox[t]{2mm}{\multirow{18}{*}{\rotatebox[origin=c]{90}{\bf Layer}}}
& \multicolumn{13}{c}{\bf \color{green!40!black} Layers} 
& \multicolumn{2}{r}{\bf \color{purple!80!black} Human} \\
\input{generated/10-eval_nitrogen_big.tex}
\end{tabular}\\
Early-Exit COMET (separate heads)






\caption{Pearson correlations between intermediate layer outputs (green) and between intermediate layer outputs and humans (purple) for unsupervised Early-Exit based on standard COMET, supervised Early-Exit with a single regression head, and supervised Early-Exit with separate regression head for each layer.}
\label{10-eval_all_big}
\end{table*}






\clearpage
\clearpage


\section{Partial COMET}
\label{sec:goal_partial}

Most quality estimation models, such as COMET, struggle with partial generations and other non-standard inputs \citep{zouhar-etal-2024-pitfalls}.
This is also crucial in applications like speech translation, where the input is often segmented into smaller chunks \citep{sperber-etal-2024-evaluating}, potentially resulting in partial sentences or incomplete translations that current quality estimation models struggle to handle effectively \citep[][Appendix D1]{amrhein-haddow-2022-dont}.

In this section, we introduce \textit{Partial COMET} (addressing non-standard input obstacle), ensuring reliable quality assessments for incomplete outputs. We show that also beyond evaluation, partial quality estimation can assess translation quality early in the translation generation process, and help discard unpromising candidates from beam search or sampling-based methods, allowing only the most promising candidates to be further expanded.
(\Cref{sec:goal_partial})



Machine translation quality estimation systems provide an assessment of model output quality.
However, in many cases, we wish to know the quality estimation even before a full translation is produced, for example in setups with unclear segmentations, such as simultaneous speech translation, or in the middle of the generation process.
Using a quality estimation system trained on full translation candidates on partial generations will lead to lower scores because the translation is technically not correct.
In this section, we propose a model that is able to score even partial generations, which are prefixes of the original translations.
This can be then used during beam search or batch sampling to discard unpromising candidates.





\subsection{Modeling}

For partial generations, we do not yet know the full translation, but only its prefix: $t_{<i}$.
Using this as an input to a quality estimation model that expects a full translation would result in a unfairly low scores.
Therefore, we explicitly train a function for partial generations $f_p$, which sees partial generations during training:
\begin{align}
\mathcal{L}_2(y, f(s, t_{<p}))
\end{align}
This way, the quality estimation model predicts final translation scores based on just the translation prefix.
See \Cref{ex:partial_generation}.

\begin{table}[ht]
\centering
\small
\begin{tabular}{lll}
\toprule
\parbox[t]{2mm}{\multirow{2}{*}{\rotatebox[origin=c]{90}{Orig.}}}
& Hi there! Let's go eat, no? & \multirow{2}{*}{$\rightarrow$ 65}\\
& Hallo du! Lass uns essen gehen, oder? & \\[0.5em]
\parbox[t]{2mm}{\multirow{2}{*}{\rotatebox[origin=c]{90}{Part.}}}
& Hi there! Let's go eat, no? & \multirow{2}{*}{$\rightarrow$ 65}\\
& Hallo du! Lass--- \\
\bottomrule
\end{tabular}
\captionof{example}{Setup for partial translation quality estimation. The quality estimation model sees only half the translation but predicts the original human score for the whole translation.}
\label{ex:partial_generation}
\end{table}

To make this applicable for generation in MT models, we need to know when to stop in the middle of the translation.
For this, we use a heuristic based on 25\%, 50\%, and 75\% of the source segment length.
To account for different language verbosities, we multiply the portion of the source length with fertility for each language pair, such as 1.1 for English$\rightarrow$German.
So for 50\%, the model sees $t_{<1.1\times |s| \times 50\%}$.
For each training segment we randomly choose whether 25\%, 50\%, 75\%, or 100\% is revealed.

\subsection{Results}


\paragraph{Full COMET falls short.}
We show the results, as measured by Pearson correlation across WMT23 in \Cref{tab:results_partial}.
The full COMET strongly underperforms on partial generations.
Therefore, this quality estimation model is not suitable for evaluating incomplete segments during generation.
In contrast, the partial quality estimation model correlates much more.
This can also be due to human annotators overfocusing on the beginning of the translations when providing assessment scores \citep{magooda2020attendbeginningstudyusing}, or the quality estimation system picking up spurious correlations that give away the score \citep{zouhar-etal-2024-pitfalls}.


\begin{table}[ht]
\small
\centering
\begin{tabular}{lcc}
\toprule
\bf Segments & \bf Full COMET & \bf Partial COMET \\
\midrule
Partial 25\% & 0.097 & 0.210 \\
Partial 50\% & 0.108 & 0.250 \\
Partial 75\% & 0.155 & 0.283 \\
Original 100\% & 0.327 & 0.318 \\
\bottomrule
\end{tabular}

\caption{Pearson correlation in original and partial (half length) translation evaluation setups. The models are either trained on full or partial generations.}
\label{tab:results_partial}
\end{table}


\paragraph{Partial COMET prunes generations.}

To show that the partial COMET is useful also in practice, we consider a generative model, such as for machine translation.
In this case, the model produces multiple generations at the same time either using parallel sampling or beam-search.
Higher beam count or parallel samples generally lead to better performance, but also take much more compute.
In this setup, partial COMET is useful because it can prune unpromising generations.

We use the the \href{https://huggingface.co/facebook/nllb-200-distilled-600M}{600M-parameter distilled NLLB model} \citep{nllb2022} with beam search and parallel sampling of 200\footnote{For computational tractability, we  run this evaluation on a subset of WMT 2023 data, sampling 2000 examples for each language pair.}.
However, instead of generating all 200 candidates until the end, we perform reranking with partial COMET when only 25\% of the candidate's output has been generated.
Then, we take only a fraction to continue in the generation of the main model.
At 50\%, we again perform the intermediate reranking, and once again at 75\%.


We try all combinations of pruning bottom 0\%, 25\%, 50\%, or 75\% at each of 25\%, 50\%, and 75\% target lengths.
The results in \Cref{fig:31-partial_candidates_top1_beam} show that by using Partial COMET, we are more likely to prune lower-quality candidates than with the original COMET, which itself performs better than random pruning.

\paragraph{Limitations.}
For Partial COMET, in some cases, the human score is not aligned with the translation substring, such as when the error which cause a lower human score is not present in the substring.
This can be further remedied by word-level quality estimation, where considering only a substring to evaluation also automatically select only the present word-level errors.


\subsection{Works on Segmentation-Robust QE}
Learned automated metrics, such as COMET or MetricX \citep{juraska-etal-2024-metricx} inherit all problems of statistical machine learning, by expecting the input to come from a particular distribution \citep{zouhar-etal-2024-pitfalls}.
\citet{amrhein-haddow-2022-dont} hint, and we confirm, that using a quality estimation model trained on full translations on incomplete segments leads to poor correlations.
Justifiably so, because from the perspective of the quality estimation model, the translation is thus incorrect.
This is problematic during decoding or in cases where the translation segmentation is unclear, such as for speech translation \citep{akhbardeh-etal-2021-findings-FIXED,salesky-etal-2023-evaluating,han-etal-2024-speechqe,sperber-etal-2024-evaluating}.




\begin{figure*}[ht]
    \centering
    Beam-Search\\
    \includegraphics[width=0.49\linewidth]{generated/31-partial_candidates_top1_beam.pdf}
    \includegraphics[width=0.49\linewidth]{generated/31-partial_candidates_topS_beam.pdf}
    Sampling\\
    \includegraphics[width=0.49\linewidth]{generated/31-partial_candidates_top1_sample.pdf}
    \includegraphics[width=0.49\linewidth]{generated/31-partial_candidates_topS_sample.pdf}

    \caption{
    Proportion of the pruning process leading to the top candidate being chosen (left) or final candidate score (right) with respect to the computation cost of the generative model.
    }
    \label{fig:31-partial_candidates_top1_beam}
\end{figure*}


