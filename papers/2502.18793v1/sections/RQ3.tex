% \vspace{-0.4cm}
\subsection{Empirical Lessons}
\label{sec:Findings}


\paragraph{RAG and Context Information improve LLMs' performance in Solidity smart contract generation.}
As shown in Table~\ref{tab:ablation}, both Pass@1 and Compile@1 are higher when using RAG and context information.
This suggests that LLMs benefit from RAG and relevant contextual dependencies in generating more accurate and functional contracts. 
However, no significant correlation was observed between gas fee or vulnerability rate and the presence of context or RAG, indicating that while context and RAG enhance correctness, they do not necessarily influence efficiency or security.


\paragraph{While LLMs can generate pretty nice contracts with challenging requirements, they can fail in some really easy cases.} 
Fig.~\ref{fig:LLMs can generate pretty nice contracts} illustrates an example of GPT-4o solving a difficult requirement. 
On the other hand, Fig.~\ref{fig:LLMs can generate really dumb contracts} is an instance of DeepSeek-R1-Distill-Qwen-7B failing an easy problem. 
The detailed prompts and generated solutions are also provided in Fig.~\ref{fig:LLMs can generate pretty nice contracts} and Fig.~\ref{fig:LLMs can generate really dumb contracts}.


\paragraph{Larger language models do not necessarily improve the gas fee of the generated code.} 
In Table~\ref{tab:rq1}, DeepSeek-V3 (671B) ranks first in Pass@k but generates the most gas-inefficient contracts among the 32B-to-671B LLMs. 
Furthermore, GPT-4o-mini is outperformed by GPT-4o in Pass@k but excels in crafting contracts that cost less gas fee.