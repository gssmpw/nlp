\section{Background}
\noindent\textbf{Problem Formulation.} Operator learning seeks to approximate an operator that maps input parameters and/or functions to corresponding output functions.  
%Operator learning, an emergent field in machine learning, focuses on learning mappings between infinite-dimensional spaces, primarily aiming to discover and approximate unknown operators. 
In many cases, operator learning rises in the context of solving partial differential equations (PDEs), where the operator corresponds to the solution operator of the PDE.
Consider a PDE system:
\begin{equation}
	\label{eq:pde}
	% \mathcal{N}u(\x) = f(\x), \quad \x \in \Omega
	% \mathcal{N}[u](\mathbf{x}, t) = f(\mathbf{x}, t), \quad \mathbf{x} \in \Omega \times [0,\infty) 
	\mathcal{N}[u](\mathbf{x}) = f(\mathbf{x}), \quad \mathbf{x} \in \Omega \times [0,\infty), 
\end{equation}
where $\x$ is a compact notation for the spatial and temporal coordinates, $\Omega$ is the spatial domain, $[0,\infty)$ is the temporal domain, $\mathcal{N}$ is a nonlinear differential operator, $u(\mathbf{x})$ is the solution function, and $f(\mathbf{x})$ is the source term. %Solving the PDE system is to find the solution function $u(\mathbf{x})$ that satisfies the PDE system equation \eqref{eq:pde} as well as the initial and boundary conditions. %This task often necessitates the use of computationally expensive numerical solvers such as finite element method (FEM) or finite difference method (FDM). To alleviate the computational challenge, 
We aim to learn the solution operator of the PDE system, \({\psi}: \mathbb{F} \rightarrow \mathbb{U}\) where $\mathbb{F}$ and $\mathbb{U}$ are two functional spaces,  using a training dataset \(\mathcal{D} = \{(\f_n,\u_n)\}_{n=1}^N\), which includes different instances of  $u(\cdot)$ and $f(\cdot)$ sampled/discretized at a set of locations. Once the model is trained, it can be used to directly predict the solution function $u$ for new instances of the input $f$,   offering a much more efficient alternative to running numerical solvers from scratch. However, the training dataset still needs to be generated offline using numerical solvers.


\cmt{
Our objective is to learn a function-to-function mapping \({\psi}: \mathbb{F} \rightarrow \mathbb{U}\), where \(\mathbb{F}\) and \(\mathbb{U}\) represent two function spaces (e.g., Banach spaces) using a training dataset \(\mathcal{D} = \{(\f_n,\u_n)\}_{n=1}^N\) that consists of discretized $u(\x)$ and $f(\x)$ at a set of collocations points. % $\{\x_1, \x_2, \cdots, \x_{m}\}$. 
% and $\{\x'_1, \x'_2, \cdots, \x'_{m'} \}$, respectively.
Directly working with the functional space is often infeasible. Thus, classic operator learning learns a mapping between the discretized input and output functions, %$\psi: \mathbb{R}^m \rightarrow \mathbb{R}^{m'}$, i.e., 
\ie $\psi(\f) = \u$, where $\f$ and $\u$ are the values of $f$ and $u$ sampled at the collocation points, respectively.  
%$\f = [f(\x_1), f(\x_2), \cdots, f(\x_m)]^\top$ and $\u = [u(\x'_1), u(\x'_2), \cdots, u(\x'_{m'})]^\top$.
}


\noindent\textbf{Fourier Neural Operator (FNO)}
~\citep{li2020fourier} is a popular  neural network architecture for operator learning, especially in solving PDEs. For a given discretized input function \(\f\), FNO first employs a linear layer on each component of \(\f\) at its respective sampling location, thereby lifting the input into a higher-dimensional channel space. The core of FNO is the Fourier layer, which performs a linear transformation followed by a nonlinear activation within the functional space,  
$ h(\mathbf{x}) \leftarrow \sigma \left( \mathcal{W}h(\mathbf{x}) + \int \kappa(\mathbf{x} - \mathbf{x}')h(\mathbf{x}')d\mathbf{x}' \right)$, where \(h(\mathbf{x})\) is the input to the Fourier layer, \(\kappa(\cdot)\) the integration kernel, and \(\sigma(\cdot)\) the activation function. The functional convolution is computed using the convolution theorem:
$ \int \kappa(\mathbf{x} - \mathbf{x}')h(\mathbf{x}')d\mathbf{x}' = \mathcal{F}^{-1} [\mathcal{F}[\kappa] \cdot \mathcal{F}[h]](\mathbf{x})$, 
where \(\mathcal{F}\) and \(\mathcal{F}^{-1}\) denote the Fourier and inverse Fourier transforms, respectively. %To be computationally efficient, 
FNO performs Fast Fourier Transform (FFT) on \(h\), multiplies it with the discretized kernel in the frequency domain, and then applies the inverse FFT. %The local linear transformation, \(\mathcal{W}h(\mathbf{x})\), is executed through standard convolution. 
After multiple Fourier layers, FNO employs another linear layer to project the latent channels to the original space for prediction. 
%the final output is obtained by projecting the latent channels tthe channel-wise application of another FFN, projecting the representation back to the original space.

\noindent\textbf{Deep Operator Network (DONet)}~\citep{lu2021learning} is another prominent work in operator learning. %Conceptualized on the universal approximation theorem for operators, DONets are capable of approximating any continuous linear or nonlinear operator under certain conditions. 
The architecture of a DONet is  structured into two components: a branch net and a trunk net, learning representations for the input functions and querying locations, respectively. 
Consider an input function \(f(\x) \in \mathbb{F}\) sampled at \(m\) locations \(\{\x_1, \x_2, \cdots, \x_m\}\) and an output function \(u \in \mathbb{U}\).
The branch net receives the values \([f(\x_1), f(\x_2), \cdots, f(\x_m)]\) and outputs a feature representation \([b_1, b_2, \cdots, b_p]^\top \in \mathbb{R}^p\). Concurrently, the trunk network processes a querying location $\x$
and outputs another feature vector \([t_1, t_2, \cdots, t_p]^\top \in \mathbb{R}^p\).
The output function value at $\x$ is predicted as a sum of products of the corresponding elements from the branch and trunk nets, $\mathcal{G}[f](\x) \approx \sum_{k=1}^p b_k t_k$,
 % \begin{equation}
 % 	\label{eq:deeponet}
 % 	\mathcal{G}[f](\x) \approx \sum\nolimits_{k=1}^p b_k t_k,
 % \end{equation} 
where \(\mathcal{G}\) is the learned operator mapping \(f\) to \(u\).
% where \(G\) is the operator mapping input function \(f\) to the corresponding output function \(G(f)\).
% Here, \(G\) denotes the DeepONet operator that takes an input function \(f\) and produces an output function \(G(f)\), approximated at the points \(\y\).

%This architecture allows DONet to learn complex mappings between infinite-dimensional spaces. However, similar to other frameworks, DONet faces challenges in data acquisition, especially in scenarios where training data is scarce and costly to obtain.

\textbf{Physics-Informed Neural Operator (PINO)}~\citep{wang2021learning,li2021physics}  has recently emerged as a promising approach to address the data scarcity issue in operator learning.
% In recent years, physics-informed neural operators (PINO) have emerged as a promising approach to address the data scarcity issue in operator learning. PINO leverages the governing physical equations as soft constraints during the training process to guide the learning of the neural operator.
%In an effort to mitigate these challenges, the concept of Physics-Informed Neural Operators (PINO)~\citep{wang2021learning,li2021physics} has been introduced. 
PINO embeds physical laws --- typically governing equations --- into the learning process. The incorporation of physics not only enhances the model's adherence to ground-truth phenomena but also reduces its dependency on extensive training data. 
%PINO operates by assimilating physical equations, typically in the form of partial differential equations (PDEs), into the neural network's architecture. This approach ensures that the learned operator not only fits the training data but also respects the underlying physical laws governing the system. For example, in a PINO model designed for fluid dynamics, the Navier-Stokes equations might be integrated into the training process to enforce the alignment of the fluid behavior with established physical principles.
Mathematically, the integration of physics into the learning process can be viewed as adding a regularization term in the loss function. Let \(\mathcal{L}_\text{data}\) represent the standard data-fitting loss term (\eg the mean squared error between the predicted and actual outputs), and the physics-informed term \(\mathcal{L}_\text{physics}\) be the residual of the governing PDEs evaluated at the neural network's outputs. The loss function \(\mathcal{L}\) for a PINO model is expressed as
\[ \mathcal{L} = \mathcal{L}_\text{data} + \lambda \mathcal{L}_\text{physics}, \]
where \(\lambda\) is a weighting factor that balances the importance of data-fitting versus physics compliance. This approach encourages the model to learn solutions not only consistent with the provided data but also physically plausible.



\section{Methodology}
In the absence of physics knowledge (\ie PDE system~\eqref{eq:pde}), %(\ie the PDE system \eqref{eq:pde} is not available), 
it is impossible to construct the physics loss term as in PINO.
To address this challenge, we propose a ``pseudo'' physics-informed operator learning framework that extracts useful physics representation from data so as to enhance operator learning. 
%motivated by the need to uncover the underlying physical laws  using available data. 
This framework is motivated by relatively complex applications, where data is often costly and/or limited while the underlying physics is hard to fully understand. %Our model architecture is depicted in Figure \ref{fig:model}.

% In the second step, we learn the mapping $\psi: f \rightarrow u$ with initial sparse data. Then we sample many new $f'$ data from a given distribution, and utilize the mapping learned with sparse data to predict corresponding $u'$ such that $\psi(f')=u'$. After that, based on the mapping $\phi: u \rightarrow f$ learned in the first step, we use $u'$ to reconstruct $f'$. Then we use the reconstruction loss w.r.t $f'$ and training data loss to fine tune the mapping $\psi: f \rightarrow u$ so that the performance of operator learning with sparse data could improve.

% 
% \subsection{Motivation}

% There are many implict physics laws in the system, and it is significant to use the data available to find the underlying physical laws so that people can have an access to learn, understand, and create in the system.

% Existing operator learning methods often suppose that the data used to train the model is sufficient which means that the physical laws are learned fully from data. However, in the real world such as power system, autonomous driving, the data is always costly or sparse which results in the difficulty of operator learning in many cases. Therefore there exists a question:

% \textbf{Given sparse data, can we firstly discover some underlying physical laws and then improve the performance of operator learning?}
% Based on this question, we propose a two-step framework to improve the operator learning with sparse data.

% \subsection{Overall Framework}
\subsection{Pseudo Physics System Learning}\label{sect:phi}
As the first step, we propose a novel approach to learn the physics system using scarce training data. 
Our key observation is that, \textit{although the mapping from $f$ to $u$ can be intricate and may necessitate information across the entire domain (\eg in linear PDEs, $u$ is an integration of the Green's function multiplied with $f$ over the domain), the underlying PDE system \eqref{eq:pde} simplifies to a local combination of $u$ and its derivatives.} We therefore design a neural network $\phi$ to approximate the general form of $\N$, 
\begin{align}
    \N[u](\x) \approx \phi\left(\x, u(\x), S_1(u)(\x), \ldots, S_Q(u)(\x)\right), \label{eq:pde-learn}
\end{align}
where  $\{S_j\}_{j=1}^Q$ are $Q$  derivative operators that we believe should be present in the system, such as $\partial_t u$, $\partial_{tt} u$, $\partial_{x_1} u$, $\partial_{x_2} u$,  
$\partial_{x_1x_1} u$, $\partial_{x_1x_2} u$, $\partial_{x_2x_2}u$, and more. 

%The local combination nature of the PDE representation decouples the values of $u$ and its derivatives across different sampling locations, and thereby dramatically increase the number of training data points. For example, suppose the input function $f$ and output function $u$ are sampled at a $128 \times 128$ grid. A single pair of the discretized input and output functions, $(\f, \u)$ is typically far from sufficient for a neural operator to learn the mapping $f\rightarrow u$. However, this sample can be decoupled into $128\times 128 = 16,384$ training data points to learn $\phi$ as in \eqref{eq:pde-learn}. Hence we can expect that even with sparse training examples for operator learning, the learning of the PDE system $\Ncal$ via our formulation \eqref{eq:pde-learn}
%can still be accurate, due to a relatively much larger number of training data points can be decoupled from these training examples.


The inherent local combinatorial nature of the PDE representation decouples the values of $u$ and its derivatives across different sampling locations, thereby significantly reducing the learning complexity and the amount of training data required.
%thereby significantly increasing the number of available training data points. 
For instance, consider sampling the input function $f$ and output function $u$ on a $128 \times 128$ grid. A single pair of discretized input and output functions, denoted as $(\f, \u)$, is typically insufficient for a neural operator to effectively learn the mapping $f \rightarrow u$. However, this pair can be decomposed into $128 \times 128 = 16,384$ training data points across various (spatial and temporal) locations, which can be used  to train $\phi$ as outlined in \eqref{eq:pde-learn}. This decomposition provides rich information that reveals the local relationships between those derivatives. Therefore, even with a small number of $(\f, \u)$ pairs, we hypothesize that the learning of the PDE system $\mathcal{N}$ through our formulation in \eqref{eq:pde-learn} can still yield high accuracy in predicting $f(\cdot)$ as in~\eqref{eq:pde}.


\cmt{
\begin{figure*}[t]
    \centering
    \setlength\tabcolsep{0pt}
    \includegraphics[width=0.8\textwidth]{./model.pdf}
    %\vspace{-0.1in}
    \caption{\small The illustration of the Pseudo Physics-Informed Neural Operator (PPI-NO). At the top, a black-box PDE representation is learned through the neural network $\phi$. At the bottom, the acquired ``pseudo'' physics laws are utilized to form a reconstruction loss, thereby regulating the NO training.
    %Step 1 learns a black-box PDE representation via the neural network $\phi$. In Step 2, the learned ``pseudo'' physics laws is used to construct a reconstruction loss, regularizing the NO training. 
    } \label{fig:model}
\end{figure*}
}
\begin{figure*}[t]
    \centering
    \setlength\tabcolsep{0pt}
    \includegraphics[width=0.8\textwidth]{figs-model/model_figure1-trim.pdf}
    %\vspace{-0.1in}
    \caption{\small The illustration of ``pseudo'' physics representation network $\phi$. The input consists of $u$ and its finite difference derivative approximations ($\{\hat{S}_1(u), \ldots, \hat{S}_Q(u)\}$) across different sampling locations. The top row shows a convolution layer that aggregates local neighborhood to compensate the information loss caused by finite difference. The bottom row shows that $\phi$ uses fully connected layers at each sampling location to combine $u$ and its derivatives locally to predict $f$ at the same location.
    } \label{fig:phi}
\end{figure*}

\begin{figure}[t]
    \centering
    \setlength\tabcolsep{0pt}
    \includegraphics[width=0.45\textwidth]{figs-model/model_figure2-trim.pdf}
    %\vspace{-0.1in}
    \caption{\small PPI-NO learning framework.
    } \label{fig:model}
\end{figure}

\cmt{
\begin{figure*}
    \centering
    \setlength\tabcolsep{0pt}
	\begin{tabular}[c]{c}
    \begin{subfigure}[b]{0.8\textwidth}
        \centering
\includegraphics[width=\textwidth]{figs-model/model_figure1-trim.pdf}
        \caption{\small PDE representation network $\Phi$}\label{fig:phi}
    \end{subfigure} \\ 
    \begin{subfigure}[b]{0.8\textwidth}
        \centering
\includegraphics[width=\textwidth]{figs-model/model_figure2-trim.pdf}
        \caption{\small PPI-NO}\label{fig:donet-learning}
    \end{subfigure} 
    \end{tabular}
    \caption{\small The illustration of the Pseudo Physics-Informed Neural Operator (PPI-NO). At the top, a black-box PDE representation is learned through the neural network $\phi$. At the bottom, the acquired ``pseudo'' physics laws are utilized to form a reconstruction loss, thereby regulating the NO training. }
    \label{fig:model}
\end{figure*}
}



We use an $L_2$ loss to estimate the parameters of $\phi$, which is defined as 
\begin{align}
	\Lcal_\phi =  \sum_{n=1}^{N}\sum_{j=1}^M &\Big[\phi(\x_{j}, u_n(\x_{j}), S_1(u_n)(\x_{j}), \ldots, S_Q(u_n)(\x_{j})) \notag \\
    &- f_n(\x_{j})\Big]^2, \label{eq:pde-learn}
\end{align}
where $f_n(\cdot)$ and $u_n(\cdot)$ are the input and output functions in $n$-th training example, and $\{\x_1, \ldots \x_M\}$ are the locations at which we sample $f_n$ and $u_n$. 

% For a dynamic system, we could use the steady state data to learn the mapping $\phi: u \rightarrow f$ and then use the learned mapping to predict the dynamic data generated by the pseudo system using simulations with initial condition $u_0(\x)$ and boundary condition $\mathcal{B}(\x)$.
% The training loss function is defined as:
% \begin{align}
% 	\label{eq:loss}
% 	\mathcal{L}(\pmb{\upsilon}) = 
% \frac{1}{N} \sum_{n=1}^{N} \left| \phi\left(\pmb{\upsilon}, \u, {\u_x}_n, {\u_{xx}}_n, {\u_t}_n, {\u_{tt}}_n \right)- \f_n \right|^2,
% \end{align}
% where  $N$ is the number of training data, $\u$ is the discretized representation of function $u(\x)$ at collocation point , ${\u_x}_n$, ${\u_{xx}}_n$, ${\u_t}_n$, ${\u_{tt}}_n$ are the discretized representation of function $u_x$, $u_{xx}$, $u_t$, $u_{tt}$ at collocation point, $\f_n$ is the discretized representation of function $f(\x)$ at collocation points.

We use finite difference to obtain the derivatives of each $u_n$, namely, $S_k(u_n)$ ($1 \le k \le Q$), and then pass these inputs to the  network $\phi$ to compute the prediction. Since finite difference introduces numerical errors, the computed derivatives are not exact. To compensate for such information loss, we propose incorporating a convolution layer to integrate and leverage the neighborhood information (see Fig.~\ref{fig:phi} top). Specifically, let $\hat{S}_k(u_n)$ represents the finite difference approximation of $S_k(u_n)$ ($1 \le k \le Q)$; for $k=0$, we define $\hat{S}_k(u_n) = u_n$. Each $\hat{S}_k(u_n)$ is treated as an input channel. After applying the convolution,  the output at each sampling location $\x_j$ for channel $k$ is given by
\begin{align}
    \overline{S}_k(\x_j) = \sum_{c=0}^{Q} \sum_{\x_i \in \text{nei}(\x_j)} w_c(\Delta_{ij}) \hat{S}_c(\x_j),
\end{align}
where $\text{nei}(\cdot)$ denotes the neighborhood sampling locations defined in the convolution filter, $\Delta_{ij}$ is the relative distance between $\x_i$ and $\x_j$, and $w_c(\Delta_{ij})$ is the corresponding filter weight. We view $\overline{S}_k(\x_j)$ as an interpolation, providing a new approximation of $S_k(\x_j)$ by incorporating all neighborhood values of $u_n(\x_j)$ and their finite difference derivative approximations. The convolution results are then passed into subsequent layers. The interpolation (filter) weights are jointly learned from data. This design allows us to integrate additional information into the inputs to facilitate the learning of $\phi$. Empirical results confirm that incorporating this convolution layer improves the prediction accuracy; refer to the ablation study in Section~\ref{sect:exp-res} and Appendix Table~\ref{tb:phi-pred-f}. Next, at each sampling location $\x_j$, we employ fully connected layers (i.e., MLP) to combine all $\{\overline{S}_k(\x_j)\}_{k=0}^Q$ in an arbitrarily flexible way to predict $f(\x_j)$; see Fig. \ref{fig:phi} bottom. In this way, the learned neural network mapping $\phi: u \rightarrow f$, although black-box in nature, is expressive enough to encapsulate valuable physics knowledge inherent in the data employed for operator learning. 




%As the numerical difference method may introduce errors when calculating derivatives, we incorporate a convolution layer in $\phi$ to collect and integrate neighborhood information about $u$ and its numerical derivatives, aiming to compensate for these errors. After that, we use feed-forward layers to sequentially perform linear transform and nonlinear activation to obtain the prediction at each sampling location; see Fig. \ref{fig:model} top. The learned neural network mapping $\phi: u \rightarrow f$, although black-box in nature, can encapsulate valuable physics knowledge inherent in the data employed for operator learning. 

Our method can be readily adapted to other numerical approaches for derivative approximation. For instance, when functions are irregularly sampled, smooth function estimators such as kernel interpolation~\citep{long2024equation}, the RBF-FD method~\citep{fornberg2013stable,fornberg2015solving}, or Bayesian B-splines~\citep{sun2022bayesian} can be used to estimate gradient information directly from data. These estimated gradients are then provided as inputs to our PDE neural network $\phi$ for further training.


%Our method can be easily adapted to other numerical approximations of derivatives. For example,  when the functions are irregularly sampled, one can employ smooth function estimators, such as kernel interpolation~\citep{long2024equation}, RBF-FD method, or Bayesian B-splines~\citep{sun2022bayesian}, to estimate the gradient information from  data. These gradient estimations are then passed into our PDE neural network $\phi$ for further learning.

%scenarios where the input and output functions are irregularly sampled, and numerical differentiation is no longer applicable. In such cases, we can employ smooth function estimators, such as kernel interpolation~\citep{long2024equation} or Bayesian B-splines~\citep{sun2022bayesian}, to estimate the gradient information from  data. These gradient estimations are then fed into our PDE neural network $\phi$ for further learning.


%In some complex systems, we might only have steady-state data despite the system is dynamic. In such cases, we can instead model $u_t$ using the neural network $\phi$. Since at the steady state, we have $u_t = 0$, we fit each $\phi(\x_j, u_n(\x_j), S_1(u_n)(\x_j), \ldots, S_Q(u_n)(\x_j))$ to zero in \eqref{eq:eq-loss}.





\subsection{Coupling Neural Operator with Pseudo Physics}
Next, we leverage the pseudo physics laws embedded in the learned mapping \(\phi: u \rightarrow f\) to enhance neural operator learning. Specifically, we use \(\phi\) to reconstruct \(f\) from the \(u\) predicted by the neural operator. % that learns to maps from $f$ to $u$. 
In this way, our approach goes beyond relying solely on the training data; it uses the physics learned in the previous step to incorporate a reconstruction error into the learning  of the neural operator parameters; see Fig.~\ref{fig:model} for an illustration. 
 
%which is obtained using the mapping \(\psi: f \rightarrow u\) trained with sparse data. This approach goes beyond relying solely on sparse data; instead, it uses the physics laws learned in the previous step for reconstructing \(f\) from \(u\) and incorporates the reconstruction error into optimizing the mapping \(\psi: f \rightarrow u\).

Initially, we train the neural operator \(\psi: f \rightarrow u\) using the available training data, creating a preliminary model. This model is developed using FNO or DONet or other neural operators. The focus is to first establish a basic understanding of the relationship between \(f\) and \(u\) from the limited data. Next, the loss function for \(\psi\) is augmented using the physics laws learned in the first step, %$\mathcal{L}=  \sum_{n=1}^{N} \mathcal{L}_2(\psi(f_n),u_n) + \lambda \cdot  \EE_{p(f')} \left[\mathcal{L}_2(f', \phi(\psi(f')))\right]$,
\begin{align}
 	\mathcal{L}=  \sum_{n=1}^{N} \mathcal{L}_2(\psi(f_n),u_n) + \lambda \cdot  \EE_{p(f')} \left[\mathcal{L}_2(f', \phi(\psi(f')))\right], \notag %\label{eq:ppi-loss}
 \end{align}
where the first term is the \(\mathcal{L}_2\) loss for data fitting (as in the standard neural operator training), and the second term is the expected reconstruction error for the input function.  %newly sampled data related to the physics-informed loss. 
The second term incorporates the physics laws embedded in $\phi(\cdot)$, and \(\lambda\) is a weighting factor that balances the training data loss against the reconstruction error.

%In practice, \(f'\) denotes data sampled from the distribution of \(f\), and \(\phi(\psi(f'))\) is the reconstruction of \(f'\) using the learned mappings \(\phi\) and \(\psi\). These samples can be generated using Gaussian processes with a radial basis function kernel. The computation of the integral in the loss function is approximated using Monte Carlo sampling:
In practice, the expected reconstruction error does not have a closed form. One can sample a collection of $f'$ from the underlying distribution of the input function $p(\cdot)$, \eg a Gauss random field or Gaussian process, and then employ a Monte-Carlo approximation, 
\begin{align}
	\mathcal{L}=  \sum_{n=1}^{N} \mathcal{L}_2(\psi(f_n),u_n) + \lambda  \frac{1}{N'} \sum_{n=1}^{N'} \mathcal{L}_2(f'_n, \phi(\psi(f'_n))), \label{eq:fine-tune-loss}
\end{align}
where \(N'\) is the number of input function samples. % from the distribution of \(f\).



% **Iterative Refinement and Fine-Tuning:**
%\todo{@shandian: need to clarify.}

To enhance the operator learning process, the model is iteratively refined. In each iteration, we first fine-tune the neural operator $\psi$ with the pseudo physics $\phi$ fixed, and then fix $\psi$,  fine-tune  $\phi$ to refine the physics representation. This fine-tuning loop is carried out for multiple iterations, allowing for continuous improvement of the neural operator based on the refined physics representation. Our method is summarized in Algorithm~\ref{alg:ppino}.


\begin{algorithm}[H]
  \caption{Pseudo-Physics-Informed NO}
  \begin{algorithmic}[1]\label{alg:train}
        \STATE Train a preliminary NO $\psi$ with standard NO loss.
        \STATE Train a preliminary psuedo physics network $\phi$ with loss $\Lcal_\phi$ in~\eqref{eq:pde-learn}.
        \REPEAT
        \STATE Sample $N'$ instances from the input function space.
        \STATE Fix pseudo physics network $\phi$, fine tune NO $\psi$ with the loss~\eqref{eq:fine-tune-loss}. %for $T$ epochs.
        \STATE Fix NO $\psi$, fine tune the pseudo physics network $\phi$ with the loss~\eqref{eq:fine-tune-loss}.  %for $M$ epochs.
    \UNTIL{Maximum iterations are done or convergence}
  \end{algorithmic}\label{alg:ppino}
\end{algorithm}

\cmt{
\begin{algorithm}[H]
  \caption{Training($\Zcal_1, \ldots, \Zcal_M, p(\Hcal)$)}
  \begin{algorithmic}[1]\label{alg:train}
    \REPEAT
        \STATE Sample $N'$ instances from the input function space.
        \STATE Fix PDE network $\phi$, continue training NO $\psi$ for XX epochs.
        \STATE Fix NO $\psi$, continue training PDE network $\phi$ for XX epochs
    \UNTIL{Maximum iterations are done or convergence}
  \end{algorithmic}
\end{algorithm}
}
This methodology mirrors  human experts' approach to physics system modeling, where a limited amount of data is available and used to investigate the physics laws inspired by simple differential operations,  
and then these laws are utilized to generalize the system for further applications, \eg forward simulation and solving inverse problems. In our method, the  reconstruction loss term augments the operator learning with additional information, leading to potential improvement upon only training with limited data.
%(up to the 2nd order to imitate human experts), 


% \Keyan{
% \subsection{Alternative training with Pseudo Physics Regularization}
% In this step, we propose an alternative training method to help enhance our neural operator performance. Generally, it uses a similar method to improve \(\phi: u \rightarrow f\) and then improve the neural operator \(\psi: f \rightarrow u\) by using the enhanced \(\phi: u \rightarrow f\). We can cycle-enhance both models to improve their performance.

% We first follow a similar procedure in section 3.2 to enhance the learned mapping  \(\phi: u \rightarrow f\). Particularly, we reuse the expected reconstruction error for the input function, but we use the $\phi(\cdot)$ in section 3.2 to define our first term in the loss function,
% \begin{align}
% 	\mathcal{L}=  \sum_{n=1}^{N} \mathcal{L}_2(\phi(u_n),f_n) + \lambda  \frac{1}{N'} \sum_{n=1}^{N'} \mathcal{L}_2(f'_n, \phi(\psi(f'_n))), \label{eq:fine-tune-loss}
% \end{align}
% where the first term is the \(\mathcal{L}_2\) loss for physics laws learned in section 3.1, and the second term is the reused expected reconstruction error for the input function in section 3.2. 

% We then use the improved mapping \(\phi: u \rightarrow f\) to reprocess section 3.2 again. We produce the modeling as an alternative training method and try to make the neural operator, and the physics laws we learned can enhance each other.
% }


% In order to accelerate the process of operator learning, after fine tuning the networks for $\psi: f \rightarrow u$ in specific epochs, we can use the updated preliminary model to predict the corresponding $u'$ which are more precise than the values the initial preliminary model predicts. We continue this fine tuning loop for 10 episodes. (\todo{not sure what paragraph means.})

% Augmented operator learning here aims to accelerate and improve the performance of operator learning with sparse data based on the physics learned in the first step. With the physics learned in our framework, operator learning with sparse data could achieve similar performance compared with operator learning with sufficient training data.  (\todo{not sure what paragraph means.})

% \todo{rewrite this section}
% \subsection{Neural Operator with Physics Regularization}
% Once we learn the pseudo physics laws thorough the implicit mapping $\phi: u \rightarrow f$, we use the learned mapping $\phi$ to reconstruct $f$ from $u$ which is leaning using the mapping $\psi: f \rightarrow u$ trained with sparse data.
% In stead on solely relying on the sparse data, we use the physics laws learned in the first step to reconstruct $f$ from $u$ and use the reconstruction error as a part of optimizing the mapping $\psi: f \rightarrow u$.

% % Then we use the reconstruction loss w.r.t $f'$ and training data loss to fine tune the mapping $\psi: f \rightarrow u$ so that the performance of operator learning with sparse data could improve.

% % More specifically, we firstly train a neural operator $\psi: f \rightarrow u$ using the initial sparse data and get a preliminary model. The mapping $\psi: f \rightarrow u$ is trained by FNO and modified DeepONet in this article.
% % When training branch networks, we introduce only one branch network. Regardless of the specific positions of input function $f$, we flatten the grid coordinates and make the predictions of embedding vectors $[b_1, b_2, \cdots, b_k]$ for each sample.



% % In order to perform operator learning with sparse data, it is natural to think that we try to generate more data pairs based on the physics laws we have learned in the first step and the distribution information of source terms. 
% More specifically, we firstly train a mapping $\psi: f \rightarrow u$ using the original sparse data and get a preliminary model. The mapping $\psi: f \rightarrow u$ is trained by FNO and modified DeepONet in this article.
% % 

% Similar to the PINN, the loss function $\psi$ is augmented using the physics laws learned in the first step. The loss function is defined as:
% % \begin{align}
% % 	\mathcal{L}=  \mathcal{L}_2(\psi(f),u) + \lambda  \mathcal{L}_2(f', \phi(\psi(f'))),
% % \end{align}
% \begin{align}
% 	\label{eq:loss}
% 	\mathcal{L}=  \sum_{n=1}^{N} \mathcal{L}_2(\psi(f_n),u_n) + \lambda  \int_{f'} \mathcal{L}_2(f', \phi(\psi(f'))) p(f') \d f',
% \end{align}
% where the first term in R.H.S is the $\mathcal{L}_2$ loss corresponding to sparse data, the second term in R.H.S is the error for reconstruction of sampled new data related to physics informed loss. In this second term, it includes the physics laws we learned in the first step of our framework. $\lambda$ determines the weights of reconstruction error from new generated data compared with sparse training data loss.
% In this equation, $f'$ denoted collection data sampled from the distribution of $f$ and $\phi(\psi(f'))$ is the reconstruction of $f'$ using the learned mapping $\phi$ and $\psi$. Such samples can be generated using Gaussian process with radial basis function kernel \citep{rasmussen2006gaussian} combined with the physics laws learned in the first step. 
% In practice, the computation of the integral in the second term of the loss function is approximated using Monte Carlo sampling. i.e.,
% \begin{equation}
% 	\label{eq:loss}
% 	\mathcal{L}=  \sum_{n=1}^{N} \mathcal{L}_2(\psi(f_n),u_n) + \lambda  \frac{1}{N} \sum_{n=1}^{N'} \mathcal{L}_2(f'_n, \phi(\psi(f'_n))),
% \end{equation}
% where $N'$ is the number of samples from the distribution of $f$.


% % sampled from a given distribution and $\phi(\psi(f'))$ is the reconstruction of $f'$ using the learned mapping $\phi$ and $\psi$.


% % When training branch networks, we introduce only one branch network.
% % Regardless of the specific positions of input function $f$, we flatten the grid coordinates and make the predictions of embedding vectors $[b_1, b_2, \cdots, b_k]$ for each sample. 
% % Then we replicate the embedding vectors for each grid points and let the output of branch network multiply with the output of trunk network to get the final prediction of $u$ at search points.

% % After training a preliminary model, we sample $f'$ which follows the same distribution of $f$ in the dataset from radial-basis function kernel using gaussian process, and feed $f'$ to the preliminary trained model to predict $u'$, then use implicit physics model trained in the first step to reconstruct $f'$. 
% % 

% % Since the preliminary model mapping $\psi: f \rightarrow u$ is trained only with sparse data, the reconstruction of $f'$ here is not so accurate. 
% % We use this error as a part of optimizing the preliminary model which maps from $f$ to $u$. 

% The idea here is similar to auto-encoder where the target is to learn two models such that given an input, it can automatically produce the input without labels. 
% This process imitate the process of physics system modeling by human experts where the sparse data is used to learn the physics laws that is described by a concise PDE system. 
% Then the learned physics laws are then extracted to generalize the physics system to generate more data.
% Considering the model inadquacy, we introduce the weights $\lambda$ to balance the reconstruction error and the sparse data loss.
% This can be interpreted as a kind of data augmentation where prior knowledge of physics laws learned from sparse data is used to generate more data to improve the performance of operator learning while keeping our data fitting task as the primary goal.


% The difference in our model is that we only optimize parameters of $\psi: f \rightarrow u$ and set the parameters of $\psi: f \rightarrow u$ freeze since in the first step with the information from neighbors and their estimations of derivative values for $u$, the physics behind $u \rightarrow f$ have been well-learned. The loss function to fine tune mapping $\psi: f \rightarrow u$ in Augmented Operator learning is defined as 
% \begin{align}
	% \mathcal{L}=  \mathcal{L}_2(\psi(f),u) + \lambda  \mathcal{L}_2(f', \phi(\psi(f')))
% \end{align}
% where the first term in R.H.S is the $\mathcal{L}_2$ loss corresponding to sparse data, the second term in R.H.S is the error for reconstruction of sampled new data related to physics informed loss. In this second term, it includes the physics laws we learned in the first step of our framework. $\lambda$ determines the weights of reconstruction error from new generated data compared with sparse training data loss. 





% \subsection*{PINN}
% In the context of PINNs, the solution \(u(\mathbf{x}, t)\) is approximated by a neural network \(\hat{u}(\mathbf{x}, t; \boldsymbol{\theta})\). The goal is to train this network such that it satisfies the PDE, along with the boundary and initial conditions. The loss function for this task typically includes three parts:

% 1. PDE Residual Loss:
% \[ \mathcal{L}_{PDE}(\boldsymbol{\theta}) = \frac{1}{N_p} \sum_{i=1}^{N_p} \left|\mathcal{N}[\hat{u}](\mathbf{x}_i, t_i; \boldsymbol{\theta}) - f(\mathbf{x}_i, t_i)\right|^2 \]
% 2. Boundary Condition Loss:
%    \[ \mathcal{L}_{BC}(\boldsymbol{\theta}) = \frac{1}{N_b} \sum_{j=1}^{N_b} \left|\mathcal{B}[\hat{u}](\mathbf{x}_j, t_j; \boldsymbol{\theta}) - g(\mathbf{x}_j, t_j)\right|^2 \]
% 3. Initial Condition Loss:
%    \[ \mathcal{L}_{IC}(\boldsymbol{\theta}) = \frac{1}{N_i} \sum_{k=1}^{N_i} \left|\hat{u}(\mathbf{x}_k, 0; \boldsymbol{\theta}) - u_0(\mathbf{x}_k)\right|^2 \]

% where \(N_p\), \(N_b\), and \(N_i\) are the number of collocation points used for enforcing the PDE, boundary conditions, and initial conditions, respectively.

% % **Optimization:**
% The training process involves adjusting the neural network parameters \(\boldsymbol{\theta}\) to minimize the combined loss:
% \[ \mathcal{L}(\boldsymbol{\theta}) = \mathcal{L}_{PDE}(\boldsymbol{\theta}) + \mathcal{L}_{BC}(\boldsymbol{\theta}) + \mathcal{L}_{IC}(\boldsymbol{\theta}). \]
% This optimization ensures that the network \(\hat{u}(\mathbf{x}, t; \boldsymbol{\theta})\) not only approximates the solution of the PDE but also satisfies the specified boundary and initial conditions, effectively embedding the physics of the problem into the neural network model.
