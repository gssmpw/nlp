\section{Introduction}
%Operator learning, a dynamic and rapidly evolving domain, has seen remarkable advancements with the advent of neural operators. Rooted in the express power of neural networks, neural operators have transformed computational problem-solving methods. 
Operator learning, an important area for data-driven surrogate modeling,  has made significant strides with the emergence of neural operators, which leverage the expressive power of neural networks. 
Notable examples include 
Fourier Neural Operators (FNO)~\citep{li2020fourier}, Deep Operator Net (DONet)~\citep{lu2021learning} and other frameworks such as~\citep{cao2021choose,hao2023gnot}. FNO employs Fourier transform for global convolution and function transformation, while DONet introduces two sub-networks, the branch net and trunk net, to extract representations from the functional space and query locations, respectively, enabling predictions akin to attention mechanisms~\citep{vaswani2017attention}. 
%the Low-Rank Neural Operator (LNO) \citep{} and Fourier Neural Operators (FNO) \citep{li2020fourier}, which utilize low-rank structures and Fourier transformations to effectively represent operators' kernels. This innovation is further expanded upon with the Graph Neural Operator (GNO) \citep{li2020neural} and Multipole Graph Neural Operator (MGNO) \citep{li2020multipole} employing multiscale kernel decomposition for efficient convolution computations.

For trading for model capacity and performance, neural operators typically require a substantial amount of training data to perform optimally. This demand poses challenges, particularly in complex problems, where training data is limited and costly to acquire. In response, the field of physics-informed machine learning, including physics-informed neural networks (PINN)~\citep{raissi2019physics}, has shown promise by incorporating physical laws as soft constraints during training. This approach serves as a regularization technique, embedding a fundamental understanding of physics into the model to lessen its reliance on extensive data. Building on this idea, the concept of physics-informed neural operators (PINO) has emerged, which integrates physical laws as soft constraints to enhance operator learning while reducing data quantity. It has been used in~\citep{wang2021learning,li2021physics} for FNO and DONet training.


Despite the success of PINO, the necessity for a thorough understanding of the underlying physics can pose a significant hurdle, especially in complex applications such as in fracture mechanics and climate modeling. In those scenarios, the detailed physical knowledge is often unavailable or difficult to identify, and it is often prohibitively expensive to collect extensive data. %These challenges can render the current methods unavailable or impractical. 
To navigate these challenges while retaining the benefits of physics-informed learning, we propose  the Pseudo Physics-Informed Neural Operator (PPI-NO). This  framework bypasses the need for exhaustive physical comprehension by constructing  a neural-network-based partial differential equation (PDE) that characterizes the target system directly from data. The neural PDE is then coupled with the neural operator for alternating updates and training,  enabling iterative extraction, refinement and integration of physics knowledge to enhance operator learning. %The major contributions are as follows:
The contribution mainly lies in the following aspects:
\begin{itemize}
\item To our knowledge, PPI-NO is the first work to enhance a standard operator learning pipeline using physics directly learned from \textit{limited data}, delivering superior accuracy without the need for in-depth physical understanding or extensive data collection.
\item PPI-NO opens up a new paradigm of physics-informed machine learning where only rudimentary physics assumptions (in this case, the basic differential operations) are required rather than in-depth or rigorous expert knowledge, extending the spectrum of the physics-informed learning for experts of different levels.
\item The effectiveness of PPI-NO is validated through extensive evaluations on five commonly used benchmark operator learning tasks in literature~\citep{li2020fourier,lu2022comprehensive}, including  Darcy flow, nonlinear diffusion, Eikonal, Poisson and advection equations, as well as one application in fatigue modeling in fracture mechanics, where the ground-truth holistic PDE system is unknown. 
\end{itemize}