\section{Background}
\noindent\textbf{Problem Formulation.} Operator learning seeks to approximate an operator that maps input parameters and/or functions to corresponding output functions.  
%Operator learning, an emergent field in machine learning, focuses on learning mappings between infinite-dimensional spaces, primarily aiming to discover and approximate unknown operators. 
In most practical cases, operator learning rises in the context of solving partial differential equations (PDEs), where the operator corresponds to the solution operator of the PDE.
Assume a PDE system:
\begin{equation}
	\label{eq:pde}
	% \mathcal{N}u(\x) = f(\x), \quad \x \in \Omega
	% \mathcal{N}[u](\mathbf{x}, t) = f(\mathbf{x}, t), \quad \mathbf{x} \in \Omega \times [0,\infty) 
	\mathcal{N}[u](\mathbf{x}) = f(\mathbf{x}), \quad \mathbf{x} \in \Omega \times [0,\infty), 
\end{equation}
where $\x$ is a compact notation for the spatial and temporal coordinates, $\Omega$ is the spatial domain, $[0,\infty)$ is the temporal domain, $\mathcal{N}$ is a nonlinear differential operator, $u(\mathbf{x})$ is the solution function, and $f(\mathbf{x})$ is the source term. Solving the PDE system is to find the solution function $u(\mathbf{x})$ that satisfies the PDE system equation \eqref{eq:pde} as well as the initial and boundary conditions. This task often necessitates the use of computationally expensive numerical solvers such as finite element method (FEM) or finite difference method (FDM). To alleviate the computational challenge, we aim to learn the solution operator of the PDE system, \({\psi}: \mathbb{F} \rightarrow \mathbb{U}\) using a training dataset \(\mathcal{D} = \{(\f_n,\u_n)\}_{n=1}^N\), which consists of discretized functions $u(\x)$ and $f(\x)$ at a set of collocations points. Once the operator model is trained, it can be used to directly predict the solution function $u$ for new instances of the input $f$,   offering a much more efficient alternative to running numerical solvers from scratch. However, the training dataset still needs to be generated offline using numerical solvers.


\cmt{
Our objective is to learn a function-to-function mapping \({\psi}: \mathbb{F} \rightarrow \mathbb{U}\), where \(\mathbb{F}\) and \(\mathbb{U}\) represent two function spaces (e.g., Banach spaces) using a training dataset \(\mathcal{D} = \{(\f_n,\u_n)\}_{n=1}^N\) that consists of discretized $u(\x)$ and $f(\x)$ at a set of collocations points. % $\{\x_1, \x_2, \cdots, \x_{m}\}$. 
% and $\{\x'_1, \x'_2, \cdots, \x'_{m'} \}$, respectively.
Directly working with the functional space is often infeasible. Thus, classic operator learning learns a mapping between the discretized input and output functions, %$\psi: \mathbb{R}^m \rightarrow \mathbb{R}^{m'}$, i.e., 
\ie $\psi(\f) = \u$, where $\f$ and $\u$ are the values of $f$ and $u$ sampled at the collocation points, respectively.  
%$\f = [f(\x_1), f(\x_2), \cdots, f(\x_m)]^\top$ and $\u = [u(\x'_1), u(\x'_2), \cdots, u(\x'_{m'})]^\top$.
}


\noindent\textbf{Fourier Neural Operator (FNO)}
~\citep{li2020fourier} represents a significant leap in neural network architecture for operator learning, especially in solving PDEs. For a given discretized input function \(\f\), FNO first employs a feed-forward network (FFN) on each component of \(\f\) at its respective sampling location, thereby lifting the input into a higher-dimensional channel space. The core of FNO is the Fourier layer, which performs a linear transformation followed by a nonlinear activation within the functional space,  
$ h(\mathbf{x}) \leftarrow \sigma \left( \mathcal{W}h(\mathbf{x}) + \int \kappa(\mathbf{x} - \mathbf{x}')h(\mathbf{x}')d\mathbf{x}' \right)$, where \(h(\mathbf{x})\) is the input to the Fourier layer, \(\kappa(\cdot)\) the integration kernel, and \(\sigma(\cdot)\) the activation function. The convolution operation in this context is efficiently computed using the convolution theorem:
$ \int \kappa(\mathbf{x} - \mathbf{x}')h(\mathbf{x}')d\mathbf{x}' = \mathcal{F}^{-1} [\mathcal{F}[\kappa] \cdot \mathcal{F}[h]](\mathbf{x})$, 
where \(\mathcal{F}\) and \(\mathcal{F}^{-1}\) denote the Fourier and inverse Fourier transforms, respectively. The Fourier layer's efficiency stems from performing the Fast Fourier Transform (FFT) on \(h\), multiplying it with the discretized kernel in the frequency domain, and then applying the inverse FFT. The local linear transformation, \(\mathcal{W}h(\mathbf{x})\), is executed through conventional convolution operations. After multiple Fourier layers, the final output is obtained by the channel-wise application of another FFN, projecting the representation back to the original space.

\noindent\textbf{Deep Operator Network (DONet)}~\citep{lu2021learning}, is another prominent work in operator learning. %Conceptualized on the universal approximation theorem for operators, DONets are capable of approximating any continuous linear or nonlinear operator under certain conditions. 
The architecture of a DONet is  structured into two primary components: the branch network and the trunk network, learning representations for the input functions and querying locations, respectively. 
Consider an input function \(f(\x) \in \mathbb{F}\) evaluated at \(m\) sensor locations \(\{\x_1, \x_2, \cdots, \x_m\}\) and an output function \(u \in \mathbb{U}\).
The branch network receives the values \([f(\x_1), f(\x_2), \cdots, f(\x_m)]\) and outputs a feature representation \([b_1, b_2, \cdots, b_p]^\top \in \mathbb{R}^p\). Concurrently, the trunk network processes a querying location $\x$
and outputs another feature vector \([t_1, t_2, \cdots, t_p]^\top \in \mathbb{R}^p\).
The approximation of the output function \(u(\x)\) is then computed as a sum of products of the corresponding elements from the branch and trunk networks, $\mathcal{G}[f](\x) \approx \sum_{k=1}^p b_k t_k$,
 % \begin{equation}
 % 	\label{eq:deeponet}
 % 	\mathcal{G}[f](\x) \approx \sum\nolimits_{k=1}^p b_k t_k,
 % \end{equation} 
where \(\mathcal{G}\) is the learned operator mapping input function \(f\) to the corresponding output function  \(u\).
% where \(G\) is the operator mapping input function \(f\) to the corresponding output function \(G(f)\).
% Here, \(G\) denotes the DeepONet operator that takes an input function \(f\) and produces an output function \(G(f)\), approximated at the points \(\y\).

%This architecture allows DONet to learn complex mappings between infinite-dimensional spaces. However, similar to other frameworks, DONet faces challenges in data acquisition, especially in scenarios where training data is scarce and costly to obtain.

\textbf{Physics-Informed Neural Operator (PINO)}~\citep{wang2021learning,li2021physics}  has recently emerged as a promising approach to address the data scarcity issue in operator learning.
% In recent years, physics-informed neural operators (PINO) have emerged as a promising approach to address the data scarcity issue in operator learning. PINO leverages the governing physical equations as soft constraints during the training process to guide the learning of the neural operator.
%In an effort to mitigate these challenges, the concept of Physics-Informed Neural Operators (PINO)~\citep{wang2021learning,li2021physics} has been introduced. 
PINO embeds physical laws, \eg governing equations, directly into the learning process, serving as soft constraints that guide the training of the model. The incorporation of physical principles not only enhances the model's adherence to ground-truth phenomena but also reduces its dependency on extensive training data. 
%PINO operates by assimilating physical equations, typically in the form of partial differential equations (PDEs), into the neural network's architecture. This approach ensures that the learned operator not only fits the training data but also respects the underlying physical laws governing the system. For example, in a PINO model designed for fluid dynamics, the Navier-Stokes equations might be integrated into the training process to enforce the alignment of the fluid behavior with established physical principles.
Mathematically, the integration of physics into the learning process can be viewed as an additional regularization term in the loss function. Let \(\mathcal{L}_\text{data}\) represent the traditional data-fitting loss term (\eg the mean squared error between predicted and actual outputs), the physics-informed term \(\mathcal{L}_\text{physics}\) can be the residual of the governing PDEs evaluated at the neural network's outputs. The total loss function \(\mathcal{L}\) for a PINO model is then expressed as
\[ \mathcal{L} = \mathcal{L}_\text{data} + \lambda \mathcal{L}_\text{physics}, \]
where \(\lambda\) is a weighting factor that balances the importance of data-fitting versus physics compliance. This approach encourages the model to learn solutions that are not only consistent with the provided data but also physically plausible.



\section{Methodology}
In the absence of the underlying physics knowledge (\ie the PDE system \eqref{eq:pde} is not available), it is impossible to construct the physics loss term in the PINO framework.
To address this challenge, we propose a ``pseudo'' physics-informed operator learning framework motivated by the need to uncover the underlying physical laws using available data. This approach is particularly useful in complex, challenging applications, where data is often costly or sparse while the underlying physics is hard to fully understand. 	
%To address the challenge of operator learning with sparse data in real-world scenarios, 
%we propose a framework motivated by the need to uncover the underlying physical laws using available data. This approach is particularly relevant in fields like climate modeling, where data is often costly or sparse while the underlying physics is hard to fully understand. 	
Our model architecture is depicted in Figure \ref{fig:model}.

% In the second step, we learn the mapping $\psi: f \rightarrow u$ with initial sparse data. Then we sample many new $f'$ data from a given distribution, and utilize the mapping learned with sparse data to predict corresponding $u'$ such that $\psi(f')=u'$. After that, based on the mapping $\phi: u \rightarrow f$ learned in the first step, we use $u'$ to reconstruct $f'$. Then we use the reconstruction loss w.r.t $f'$ and training data loss to fine tune the mapping $\psi: f \rightarrow u$ so that the performance of operator learning with sparse data could improve.

% 
% \subsection{Motivation}

% There are many implict physics laws in the system, and it is significant to use the data available to find the underlying physical laws so that people can have an access to learn, understand, and create in the system.

% Existing operator learning methods often suppose that the data used to train the model is sufficient which means that the physical laws are learned fully from data. However, in the real world such as power system, autonomous driving, the data is always costly or sparse which results in the difficulty of operator learning in many cases. Therefore there exists a question:

% \textbf{Given sparse data, can we firstly discover some underlying physical laws and then improve the performance of operator learning?}
% Based on this question, we propose a two-step framework to improve the operator learning with sparse data.

% \subsection{Overall Framework}
\subsection{Pseudo Physics System Learning}\label{sect:phi}
As the first step, we propose a novel approach to learn the physics system using sparse training data. 
Our key observation is that, \textit{although the mapping from $f$ to $u$ can be intricate and may necessitate information across the entire domain (in theory, $u$ is an integration of the Green's function multiplied with $f$ over the domain), the underlying PDE system \eqref{eq:pde} simplifies to a local combination of $u$ and its derivatives.} We therefore use a neural network $\phi$ to approximate the general form of $\N$, 
\begin{align}
    \N[u](\x) \approx \phi\left(\x, u(\x), S_1(u)(\x), \ldots, S_Q(u)(\x)\right), \label{eq:pde-learn}
\end{align}
where  $\{S_j\}_{j=1}^Q$ are $Q$  derivative operators that we believe should be present in the system, such as $\partial_t u$, $\partial_{tt} u$, $\partial_{x_1} u$, $\partial_{x_2} u$,  
$\partial_{x_1x_1} u$, $\partial_{x_1x_2} u$, $\partial_{x_2x_2}u$, and more. 

%The local combination nature of the PDE representation decouples the values of $u$ and its derivatives across different sampling locations, and thereby dramatically increase the number of training data points. For example, suppose the input function $f$ and output function $u$ are sampled at a $128 \times 128$ grid. A single pair of the discretized input and output functions, $(\f, \u)$ is typically far from sufficient for a neural operator to learn the mapping $f\rightarrow u$. However, this sample can be decoupled into $128\times 128 = 16,384$ training data points to learn $\phi$ as in \eqref{eq:pde-learn}. Hence we can expect that even with sparse training examples for operator learning, the learning of the PDE system $\Ncal$ via our formulation \eqref{eq:pde-learn}
%can still be accurate, due to a relatively much larger number of training data points can be decoupled from these training examples.


The inherent local combination nature of the PDE representation decouples the values of $u$ and its derivatives across various sampling locations, thereby significantly increasing the number of available training data points. For instance, consider sampling the input function $f$ and output function $u$ on a $128 \times 128$ grid. A single pair of discretized input and output functions, denoted as $(\f, \u)$, is typically insufficient for a neural operator to effectively learn the mapping $f \rightarrow u$. However, this sample can be decomposed into $128 \times 128 = 16,384$ training data points to train $\phi$ as outlined in \eqref{eq:pde-learn}. Consequently, even with sparse training examples for operator learning, the learning of the PDE system $\mathcal{N}$ via our formulation in \eqref{eq:pde-learn} can still achieve accuracy, thanks to the much greater number of training data points that can be derived from these examples.

\begin{figure*}[t]
    \centering
    \setlength\tabcolsep{0pt}
    \includegraphics[width=0.8\textwidth]{./model.pdf}
    %\vspace{-0.1in}
    \caption{\small The illustration of the Pseudo Physics-Informed Neural Operator (PPI-NO). At the top, a black-box PDE representation is learned through the neural network $\phi$. At the bottom, the acquired ``pseudo'' physics laws are utilized to construct a reconstruction loss, thereby regulating the NO training.
    %Step 1 learns a black-box PDE representation via the neural network $\phi$. In Step 2, the learned ``pseudo'' physics laws is used to construct a reconstruction loss, regularizing the NO training. 
    } \label{fig:model}
\end{figure*}

We use an $L_2$ loss to estimate the parameters of $\phi$, which is defined as 
\begin{align}
	\Lcal_\phi =  \sum\nolimits_{n=1}^{N}\sum\nolimits_{j=1}^M &\left[\phi(\x_{j}, u_n(\x_{j}), S_1(u_n)(\x_{j}), \ldots, S_Q(u_n)(\x_{j})) - f_n(\x_{j})\right]^2, \label{eq:eq-loss}
\end{align}
where $f_n(\cdot)$ and $u_n(\cdot)$ are the input and output functions in $n$-th training example, and $\{\x_1, \ldots \x_M\}$ are the  locations at which we discretize $f_n$ and $u_n$. 

% For a dynamic system, we could use the steady state data to learn the mapping $\phi: u \rightarrow f$ and then use the learned mapping to predict the dynamic data generated by the pseudo system using simulations with initial condition $u_0(\x)$ and boundary condition $\mathcal{B}(\x)$.
% The training loss function is defined as:
% \begin{align}
% 	\label{eq:loss}
% 	\mathcal{L}(\pmb{\upsilon}) = 
% \frac{1}{N} \sum_{n=1}^{N} \left| \phi\left(\pmb{\upsilon}, \u, {\u_x}_n, {\u_{xx}}_n, {\u_t}_n, {\u_{tt}}_n \right)- \f_n \right|^2,
% \end{align}
% where  $N$ is the number of training data, $\u$ is the discretized representation of function $u(\x)$ at collocation point , ${\u_x}_n$, ${\u_{xx}}_n$, ${\u_t}_n$, ${\u_{tt}}_n$ are the discretized representation of function $u_x$, $u_{xx}$, $u_t$, $u_{tt}$ at collocation point, $\f_n$ is the discretized representation of function $f(\x)$ at collocation points.

We use numerical difference to obtain the derivatives of each $u_n$, namely, $S_k(u_n)$ ($1 \le k \le Q$), and then feed these inputs to the neural network $\phi$ to compute the prediction. 
As the numerical difference method may introduce errors when calculating derivatives, we incorporate a convolution layer in $\phi$ to collect and integrate neighborhood information about $u$ and its numerical derivatives, aiming to compensate for these errors. After that, we use feed-forward layers to sequentially perform linear transforms and nonlinear activation to obtain the prediction at each sampling location; see Fig. \ref{fig:model} top. The learned neural network mapping $\phi: u \rightarrow f$, although black-box in nature,
encapsulates crucial physics knowledge inherent in the data employed for operator learning. %(even such data can be sparse)

%In some complex systems, we might only have steady-state data despite the system is dynamic. In such cases, we can instead model $u_t$ using the neural network $\phi$. Since at the steady state, we have $u_t = 0$, we fit each $\phi(\x_j, u_n(\x_j), S_1(u_n)(\x_j), \ldots, S_Q(u_n)(\x_j))$ to zero in \eqref{eq:eq-loss}.




% To solve this PDE, boundary conditions (BCs) and initial conditions (ICs) are necessary. These can be expressed as:
% Boundary Conditions: \( \mathcal{B}[u](\mathbf{x}, t) = g(\mathbf{x}, t), \quad \mathbf{x} \in \partial\Omega \)
% ; Initial Conditions: \( u(\mathbf{x}, 0) = u_0(\mathbf{x}), \quad \mathbf{x} \in \Omega \),
% where \(\mathcal{B}\) is an operator defining the boundary conditions on the boundary \(\partial\Omega\) of the domain, \(g(\mathbf{x}, t)\) specifies the boundary values, and \(u_0(\mathbf{x})\) is the initial state of the system.





% Implicit Physics Learning here aims to learn the underlying physical laws from sparse data based on the estimation of derivatives for $u$.


\subsection{Coupling Neural Operator with Pseudo Physics}
Next, we leverage the pseudo physics laws embedded in the learned mapping \(\phi: u \rightarrow f\) to enhance the neural operator learning process. Specifically, we use \(\phi\) to reconstruct \(f\) from the \(u\) predicted by the neural operator. % that learns to maps from $f$ to $u$. 
In this way, our approach goes beyond relying solely on the training data; it uses the physics laws learned in the previous step to incorporate a reconstruction error into optimizing the neural operator parameters. %mapping \(\psi: f \rightarrow u\).

%which is obtained using the mapping \(\psi: f \rightarrow u\) trained with sparse data. This approach goes beyond relying solely on sparse data; instead, it uses the physics laws learned in the previous step for reconstructing \(f\) from \(u\) and incorporates the reconstruction error into optimizing the mapping \(\psi: f \rightarrow u\).

Initially, we train the neural operator \(\psi: f \rightarrow u\) using the available training data, creating a preliminary model. This model is developed using FNO or DONet or their variants. The focus is to first establish a fundamental understanding of the relationship between \(f\) and \(u\), based on the limited data. Next, the loss function for \(\psi\) is augmented using the physics laws learned in the first step, %$\mathcal{L}=  \sum_{n=1}^{N} \mathcal{L}_2(\psi(f_n),u_n) + \lambda \cdot  \EE_{p(f')} \left[\mathcal{L}_2(f', \phi(\psi(f')))\right]$,
\begin{align}
 	\mathcal{L}=  \sum\nolimits_{n=1}^{N} \mathcal{L}_2(\psi(f_n),u_n) + \lambda \cdot  \EE_{p(f')} \left[\mathcal{L}_2(f', \phi(\psi(f')))\right], \label{eq:ppi-loss}
 \end{align}
where the first term is the \(\mathcal{L}_2\) loss for data fitting (as in the standard neural operator training), and the second term is the expected reconstruction error for the input function.  %newly sampled data related to the physics-informed loss. 
The second term incorporates the physics laws embedded in $\phi(\cdot)$, and \(\lambda\) is a weight factor that balances the training data loss against the reconstruction error.

%In practice, \(f'\) denotes data sampled from the distribution of \(f\), and \(\phi(\psi(f'))\) is the reconstruction of \(f'\) using the learned mappings \(\phi\) and \(\psi\). These samples can be generated using Gaussian processes with a radial basis function kernel. The computation of the integral in the loss function is approximated using Monte Carlo sampling:
In practice, the expected reconstruction error does not have a closed form. One can sample a collection of $f'$ from the underlying distribution of the input function $p(\cdot)$, \eg a Gauss random field or Gaussian process, and then employ a Monte-Carlo approximation, 
\begin{align}
	\mathcal{L}=  \sum_{n=1}^{N} \mathcal{L}_2(\psi(f_n),u_n) + \lambda  \frac{1}{N'} \sum_{n=1}^{N'} \mathcal{L}_2(f'_n, \phi(\psi(f'_n))), \label{eq:fine-tune-loss}
\end{align}
where \(N'\) is the number of input function samples. % from the distribution of \(f\).



% **Iterative Refinement and Fine-Tuning:**
%\todo{@shandian: need to clarify.}

To enhance the operator learning process, the model is iteratively refined. In each iteration, we first fine-tune the neural operator $\psi$ with the pseudo physics $\phi$ fixed, and then fix $\psi$,  fine-tune  $\phi$ to refine the physics representation. This fine-tuning loop is carried out for multiple iterations, allowing for continuous improvement of the neural operator based on the refined physics.
%After fine-tuning the \(\psi: f \rightarrow u\) model for specific epochs, we use the updated model to make more precise predictions of \(u'\) than initially possible.
%This fine-tuning loop continues for multiple iterations, allowing for the continuous improvement of the neural operator based on the refined physics.


This methodology mirrors  human experts' approach to physics system modeling, where sparse data is used to learn the physics laws inspired by simple differential operation (up to the 2nd order to imitate human experts), and then these laws are utilized to generalize the system for data generation. The  reconstruction loss term augments the operator learning with additional information, leading to potential improvement upon only training with sparse data. 
% \Keyan{
% \subsection{Alternative training with Pseudo Physics Regularization}
% In this step, we propose an alternative training method to help enhance our neural operator performance. Generally, it uses a similar method to improve \(\phi: u \rightarrow f\) and then improve the neural operator \(\psi: f \rightarrow u\) by using the enhanced \(\phi: u \rightarrow f\). We can cycle-enhance both models to improve their performance.

% We first follow a similar procedure in section 3.2 to enhance the learned mapping  \(\phi: u \rightarrow f\). Particularly, we reuse the expected reconstruction error for the input function, but we use the $\phi(\cdot)$ in section 3.2 to define our first term in the loss function,
% \begin{align}
% 	\mathcal{L}=  \sum_{n=1}^{N} \mathcal{L}_2(\phi(u_n),f_n) + \lambda  \frac{1}{N'} \sum_{n=1}^{N'} \mathcal{L}_2(f'_n, \phi(\psi(f'_n))), \label{eq:fine-tune-loss}
% \end{align}
% where the first term is the \(\mathcal{L}_2\) loss for physics laws learned in section 3.1, and the second term is the reused expected reconstruction error for the input function in section 3.2. 

% We then use the improved mapping \(\phi: u \rightarrow f\) to reprocess section 3.2 again. We produce the modeling as an alternative training method and try to make the neural operator, and the physics laws we learned can enhance each other.
% }


% In order to accelerate the process of operator learning, after fine tuning the networks for $\psi: f \rightarrow u$ in specific epochs, we can use the updated preliminary model to predict the corresponding $u'$ which are more precise than the values the initial preliminary model predicts. We continue this fine tuning loop for 10 episodes. (\todo{not sure what paragraph means.})

% Augmented operator learning here aims to accelerate and improve the performance of operator learning with sparse data based on the physics learned in the first step. With the physics learned in our framework, operator learning with sparse data could achieve similar performance compared with operator learning with sufficient training data.  (\todo{not sure what paragraph means.})

% \todo{rewrite this section}
% \subsection{Neural Operator with Physics Regularization}
% Once we learn the pseudo physics laws thorough the implicit mapping $\phi: u \rightarrow f$, we use the learned mapping $\phi$ to reconstruct $f$ from $u$ which is leaning using the mapping $\psi: f \rightarrow u$ trained with sparse data.
% In stead on solely relying on the sparse data, we use the physics laws learned in the first step to reconstruct $f$ from $u$ and use the reconstruction error as a part of optimizing the mapping $\psi: f \rightarrow u$.

% % Then we use the reconstruction loss w.r.t $f'$ and training data loss to fine tune the mapping $\psi: f \rightarrow u$ so that the performance of operator learning with sparse data could improve.

% % More specifically, we firstly train a neural operator $\psi: f \rightarrow u$ using the initial sparse data and get a preliminary model. The mapping $\psi: f \rightarrow u$ is trained by FNO and modified DeepONet in this article.
% % When training branch networks, we introduce only one branch network. Regardless of the specific positions of input function $f$, we flatten the grid coordinates and make the predictions of embedding vectors $[b_1, b_2, \cdots, b_k]$ for each sample.



% % In order to perform operator learning with sparse data, it is natural to think that we try to generate more data pairs based on the physics laws we have learned in the first step and the distribution information of source terms. 
% More specifically, we firstly train a mapping $\psi: f \rightarrow u$ using the original sparse data and get a preliminary model. The mapping $\psi: f \rightarrow u$ is trained by FNO and modified DeepONet in this article.
% % 

% Similar to the PINN, the loss function $\psi$ is augmented using the physics laws learned in the first step. The loss function is defined as:
% % \begin{align}
% % 	\mathcal{L}=  \mathcal{L}_2(\psi(f),u) + \lambda  \mathcal{L}_2(f', \phi(\psi(f'))),
% % \end{align}
% \begin{align}
% 	\label{eq:loss}
% 	\mathcal{L}=  \sum_{n=1}^{N} \mathcal{L}_2(\psi(f_n),u_n) + \lambda  \int_{f'} \mathcal{L}_2(f', \phi(\psi(f'))) p(f') \d f',
% \end{align}
% where the first term in R.H.S is the $\mathcal{L}_2$ loss corresponding to sparse data, the second term in R.H.S is the error for reconstruction of sampled new data related to physics informed loss. In this second term, it includes the physics laws we learned in the first step of our framework. $\lambda$ determines the weights of reconstruction error from new generated data compared with sparse training data loss.
% In this equation, $f'$ denoted collection data sampled from the distribution of $f$ and $\phi(\psi(f'))$ is the reconstruction of $f'$ using the learned mapping $\phi$ and $\psi$. Such samples can be generated using Gaussian process with radial basis function kernel \citep{rasmussen2006gaussian} combined with the physics laws learned in the first step. 
% In practice, the computation of the integral in the second term of the loss function is approximated using Monte Carlo sampling. i.e.,
% \begin{equation}
% 	\label{eq:loss}
% 	\mathcal{L}=  \sum_{n=1}^{N} \mathcal{L}_2(\psi(f_n),u_n) + \lambda  \frac{1}{N} \sum_{n=1}^{N'} \mathcal{L}_2(f'_n, \phi(\psi(f'_n))),
% \end{equation}
% where $N'$ is the number of samples from the distribution of $f$.


% % sampled from a given distribution and $\phi(\psi(f'))$ is the reconstruction of $f'$ using the learned mapping $\phi$ and $\psi$.


% % When training branch networks, we introduce only one branch network.
% % Regardless of the specific positions of input function $f$, we flatten the grid coordinates and make the predictions of embedding vectors $[b_1, b_2, \cdots, b_k]$ for each sample. 
% % Then we replicate the embedding vectors for each grid points and let the output of branch network multiply with the output of trunk network to get the final prediction of $u$ at search points.

% % After training a preliminary model, we sample $f'$ which follows the same distribution of $f$ in the dataset from radial-basis function kernel using gaussian process, and feed $f'$ to the preliminary trained model to predict $u'$, then use implicit physics model trained in the first step to reconstruct $f'$. 
% % 

% % Since the preliminary model mapping $\psi: f \rightarrow u$ is trained only with sparse data, the reconstruction of $f'$ here is not so accurate. 
% % We use this error as a part of optimizing the preliminary model which maps from $f$ to $u$. 

% The idea here is similar to auto-encoder where the target is to learn two models such that given an input, it can automatically produce the input without labels. 
% This process imitate the process of physics system modeling by human experts where the sparse data is used to learn the physics laws that is described by a concise PDE system. 
% Then the learned physics laws are then extracted to generalize the physics system to generate more data.
% Considering the model inadquacy, we introduce the weights $\lambda$ to balance the reconstruction error and the sparse data loss.
% This can be interpreted as a kind of data augmentation where prior knowledge of physics laws learned from sparse data is used to generate more data to improve the performance of operator learning while keeping our data fitting task as the primary goal.


% The difference in our model is that we only optimize parameters of $\psi: f \rightarrow u$ and set the parameters of $\psi: f \rightarrow u$ freeze since in the first step with the information from neighbors and their estimations of derivative values for $u$, the physics behind $u \rightarrow f$ have been well-learned. The loss function to fine tune mapping $\psi: f \rightarrow u$ in Augmented Operator learning is defined as 
% \begin{align}
	% \mathcal{L}=  \mathcal{L}_2(\psi(f),u) + \lambda  \mathcal{L}_2(f', \phi(\psi(f')))
% \end{align}
% where the first term in R.H.S is the $\mathcal{L}_2$ loss corresponding to sparse data, the second term in R.H.S is the error for reconstruction of sampled new data related to physics informed loss. In this second term, it includes the physics laws we learned in the first step of our framework. $\lambda$ determines the weights of reconstruction error from new generated data compared with sparse training data loss. 





% \subsection*{PINN}
% In the context of PINNs, the solution \(u(\mathbf{x}, t)\) is approximated by a neural network \(\hat{u}(\mathbf{x}, t; \boldsymbol{\theta})\). The goal is to train this network such that it satisfies the PDE, along with the boundary and initial conditions. The loss function for this task typically includes three parts:

% 1. PDE Residual Loss:
% \[ \mathcal{L}_{PDE}(\boldsymbol{\theta}) = \frac{1}{N_p} \sum_{i=1}^{N_p} \left|\mathcal{N}[\hat{u}](\mathbf{x}_i, t_i; \boldsymbol{\theta}) - f(\mathbf{x}_i, t_i)\right|^2 \]
% 2. Boundary Condition Loss:
%    \[ \mathcal{L}_{BC}(\boldsymbol{\theta}) = \frac{1}{N_b} \sum_{j=1}^{N_b} \left|\mathcal{B}[\hat{u}](\mathbf{x}_j, t_j; \boldsymbol{\theta}) - g(\mathbf{x}_j, t_j)\right|^2 \]
% 3. Initial Condition Loss:
%    \[ \mathcal{L}_{IC}(\boldsymbol{\theta}) = \frac{1}{N_i} \sum_{k=1}^{N_i} \left|\hat{u}(\mathbf{x}_k, 0; \boldsymbol{\theta}) - u_0(\mathbf{x}_k)\right|^2 \]

% where \(N_p\), \(N_b\), and \(N_i\) are the number of collocation points used for enforcing the PDE, boundary conditions, and initial conditions, respectively.

% % **Optimization:**
% The training process involves adjusting the neural network parameters \(\boldsymbol{\theta}\) to minimize the combined loss:
% \[ \mathcal{L}(\boldsymbol{\theta}) = \mathcal{L}_{PDE}(\boldsymbol{\theta}) + \mathcal{L}_{BC}(\boldsymbol{\theta}) + \mathcal{L}_{IC}(\boldsymbol{\theta}). \]
% This optimization ensures that the network \(\hat{u}(\mathbf{x}, t; \boldsymbol{\theta})\) not only approximates the solution of the PDE but also satisfies the specified boundary and initial conditions, effectively embedding the physics of the problem into the neural network model.
