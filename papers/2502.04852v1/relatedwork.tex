\section{Related Work}
Facial age estimation is inherently complex due to significant variations in
aging characteristics across ethnicities, genders, and
lifestyles~\cite{han2013age}. Buolamwini and Gebru~\cite{Gebru} demonstrated
the significance of ethnicity and gender in face analysis and recognition. Guo
and Mu~\cite{guo2010human} introduced a hierarchical approach wherein facial
images are first classified by gender and ethnicity, followed by age
estimation within each subgroup to enhance prediction accuracy. Earlier
approaches relied on local image features to embed facial images, followed by
statistical inference. Balmaseda et al.~\cite{ramon2012gender} used Local
Binary Pattern (LBP) features and SVM classifiers to analyze multiscale
normalized face images and their local context. Zheng and
Sun~\cite{ZhengSun2012} employed a ranking SVM to estimate age by learning
ranking relationships, which were then applied to a reference set for age
estimation. A gender and age classification scheme was introduced by Eidinger
et al.~\cite{eidinger2014age} for non-frontal facial images captured under
uncontrolled conditions. Regression-based approaches reformulate age
estimation as a scalar regression problem using high-dimensional image
embeddings. Thus, a regression model for unbalanced and sparse data was
proposed by Chen and Gong~\cite{ChenGong2013}, enabling accurate age and crowd
density estimation. Low-level visual features extracted from unbalanced and
sparse images were mapped onto a cumulative attribute space, where each
dimension corresponds to a semantic interpretation.

While early methods relied on handcrafted features and statistical models, the
advent of deep learning has significantly transformed facial age estimation,
enabling more robust and data-driven approaches. A hierarchical unsupervised
neural network model was introduced by Wang and Kamikaze~\cite{wang2015age} to
extract robust facial representations. These features were subsequently
processed by Recursive Neural Networks (RNNs) to capture age progression
patterns. Manifold learning was applied to capture the underlying facial aging
manifold by projecting the feature vector into a lower-dimensional, more
discriminative subspace. Hasner and Levi~\cite{leviage} improved the accuracy
of age estimation by formulating it as a classification problem and leveraging
Convolutional Neural Networks (CNNs), while Sendik and Keller~\cite{deepage}
applied deep metric learning to CNN-computed facial features and employed a
Support Vector Regressor (SVR) for age estimation. Deep metric-learning was
also used by Lieu et al.~\cite{8099569} who introduced a hard quadruplet
mining scheme to enhance embeddings, applying a regression-based loss for age
estimation. Rote et al.~\cite{7406390} developed a classification scheme in
which the class probability distribution from the Softmax function was used to
compute the empirical expectancy of the estimated age. Pan et
al.~\cite{Mean-Variance} proposed a multitask approach, where the empirical
probability of each age was computed using the Softmax activation function.
They minimized both the $L_{2}$ loss and the empirical variance of the age
estimation error. A set of CNN-based classification models was suggested by
Malli et al.~\cite{7406402}. Each model was trained to classify within a
specific age range. The final age estimate was obtained by averaging the
outputs of these models.

Shen et al.~\cite{8578343} proposed a hybrid Deep Regression Forests approach
that combines Regression Forests and deep learning inference. In this method,
the forest nodes, which learn adaptive data partitions from the input, are
connected to fully connected layers of a Convolutional Neural Network (CNN).
The Random Forests and CNN are optimized jointly in an end-to-end manner. a
tree-based structure was introduced by Li et al.~\cite{8954134} where adjacent
tree leaves in close branches were connected to create a continuous
transition. Additionally, they employed an ensemble of local regressors, with
each leaf linked to a specific local regressor. The age labels in this
approach were encoded using an ordinal-preserving
representation~\cite{8099569,7780901,9145576,coral} to exploit the inherent
order of age labels. This encoding ensures that each model outputs signals
indicating whether an estimated age exceeds a given threshold. These methods
have been shown to improve the accuracy of age classification.

Niu et al.~\cite{7780901} employed an ordinal regression Convolutional Neural
Network (CNN) to address non-stationarity in aging patterns and develop the
Asian Face Age Dataset (AFAD), which contains more than 160,000 images with
accurately labeled ages. The Deep Cross-Population (DC) domain adaptation
approach by Li et al.~\cite{8578147} for age estimation trains a CNN on a
large source dataset to enhance the accuracy of age estimation on a smaller
target dataset. In the DC approach, transferable aging features are learned
from the source dataset and then transferred to the target dataset.
Additionally, an order-preserving pairwise loss function is utilized to align
the aging features of the two populations. Tain et al.~\cite{TianCCY19}
proposed a correlation learning method to represent and utilize inter- and
intra-cumulative attribute relationships, which was further extended to
perform gender-aware age estimations by leveraging correlations both between
and within gender groups.

Attention-based learning has revolutionized NLP-related tasks and was also
adapted for computer vision. Hiba and Keller \cite{deepage2} introduced a Deep
Learning framework for age estimation, featuring an attention-based image
augmentation-aggregation approach and a hierarchical probabilistic regression
model. While this approach used attention on top of the augmentations, Wang et
al. \cite{9673115} used attention to identify image patches that should be
focused on for age estimation, creating a framework of two CNNs: Attention and
Fusionist. Attention employs a novel OMAHA (Ranking-guided Multi-Head Hybrid
Attention) mechanism to dynamically locate and rank age-specific patches,
which Fusionist integrates with facial images to predict subject age. Line et
al. \cite{lin2021fpage} presented an age estimation method for in-the-wild
scenarios, incorporating facial semantics through a face parsing-based network
and attention module. Considering related tasks in video processing, Deformer,
a video-based model for age classification was proposed by Ali et al.
\cite{Ali_2024_WACV}, that categorizes individuals into four age groups.
Addressing challenges like occlusions and low resolution, the method employs a
two-stream architecture with the Transformer and EfficientNet architectures.

Sun et al. \cite{9541205} addressed age estimation challenges such as
illumination, pose, expression, and the ambiguity of the age labels between
demographic groups. They proposed a general label distribution learning (DLL)
formulation that unifies various age estimation methods. Introducing a deep
conditional distribution learning (DL) method within this framework, the
authors utilized auxiliary face attributes to learn age-related features. From
another perspective, considering the inherent imbalance prevalent across
datasets, Boa et al. \cite{bao2023general} proposed a unified framework for
facial age estimation, addressing challenges in both general and long-tailed
age estimation. They introduced feature rearrangement, pixel-level adjunct
learning, and adaptive routing to enhance performance across diverse age
classes. Siamese graph learning (SGD) was introduced by Lieu et al.
\cite{10068268} to address aging dataset bias. SGD aligns sparse and dense
distributions, preserving the smoothness of aging. The approach employs a
blending strategy for plausible hallucinatory sample generation using
unlabeled data and introduces graph contrastive regularization to mitigate
noise from auxiliary samples. Generative AI as in Delta Age AGAIN (DAA), was
proposed by Chen et al. \cite{chen2023daa} for age recognition using transfer
learning. The DAA operation based on mean and standard deviation values of
style maps employs binary code mapping and a FaceEncoder-AgeDecoder framework.

Several image datasets have been used in face-based age estimation. Some older
datasets, such as FERET \cite{PHILLIPS1998295} (14K images), FG-NET
\cite{cootes2008fg} (1K images), Chalearn LAP 2015
\cite{agustsson2017appareal} (7.5K images), and UTKFace \cite{zhifei2017cvpr}
(16K images), are too small for CNN-based approaches, while others, like
IMDB-Wiki \cite{7406390}, are based on web scraping and human age annotators
without objective groundtruth age labels. As the accuracy of computational age
estimation improves (MAE $\approx$ 2.5 years), it becomes comparable to human
annotations, limiting their effectiveness for future work. The MORPH Album II
\cite{RicanekJr.:2006:MLI:1126250.1126361} is notable as it provides accurate
age and identity labels, while other datasets, including AFAD \cite{7780901},
do not provide identity labels. This has led some works to use only the
Random-Split (RS) test protocol, where the image set is randomly split into
train and test subsets. As most datasets have 25 images of each subject, this
inevitably results in significant train-to-test leakage, making their age
estimation results less reliable. In this work, we focus on datasets equipped
with identity labels, and use the Subject-Exclusive (SE) protocol, where all
of a particular subject's face images are used just in either the train or
test sets.\begin{figure}[tbh]
\begin{center}
\centering\includegraphics[width=0.5\textwidth]{figures/differential_based_age_est_elaborated.pdf}
\end{center}
\caption{\textbf{Differential age estimation in the training and test phases.}
In training time, the groundtruth age $a_{q}$ of the input face image
$\mathbf{x}_{q}$, is augmented using Eq. \ref{equ:train sampling} and used to
retrieve the reference set of images $\{\boldsymbol{x_{r}}\}_{1}^{R}$. In the
test phase, a Baseline Age Regressor (BAR) estimates $\hat{a}_{q}$, the age of
$\mathbf{x}_{q}$ that is used to retrieve $\{\boldsymbol{x_{r}}\}_{1}^{R}$.}%
\label{fig:differential_based_age_est_elaborated}%
\end{figure}\begin{figure*}[tbh]
\begin{center}
\centering\includegraphics[width=0.8\textwidth]{figures/network_arch_general.pdf}
\end{center}
\par
.\caption{\textbf{The Differential Age Regressor (DAR) network.} The
embeddings of the query image $\boldsymbol{x_{q}}$ and the reference images
$\{\boldsymbol{x_{r}}\}_{1}^{R}$ are computed by a CNN, while the initial age
estimate of the query image $\hat{a}_{q}$ and reference ages
$\{\boldsymbol{a_{r}}\}_{1}^{R}$ are encoded by an embedding layer. The
embeddings are concatenated to $\boldsymbol{{\hat{x}}_{q}}$ and
$\{\boldsymbol{{\hat{x}}_{r}}\}_{1}^{R}$. The DAR network uses the embeddings
to estimate the age differences $\{{d}_{r}\}_{1}^{R}$ and the weights per
reference $\{{w}_{r}\}_{1}^{R}$. The resulting difference estimate
$\hat{\Delta}$ is the weighted average $\hat{\Delta}=\sum_{r}{w}_{r}{d}_{r}$
added to $\hat{a}_{q}$ to compute the age estimate.}%
\label{fig:network_arch_general}%
\end{figure*}