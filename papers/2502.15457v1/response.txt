\section{Related Works}
\subsection{Temporal Understanding in Videos}
Understanding temporal ques in videos is challenging and MLLM-based methods draw great attention. A wide range of work **Dosovitskiy, "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"**, **Parmar et al., "Image Transformer"** leverages the reasoning ability of MLLMs and presents great performance in understanding holistic videos.

\subsection{Memory as Contexts in LLMs} Implementing memories has been a big topic. Due to the emergent abilities of LLMs **Brown et al., "Language Models play DOTA: Winning at DotA 2 with Combined Online Learning"** to understand and leverage context, using contexts as memory has been one mainstream approach for NLP tasks **Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**, and also multimodal tasks **Radford et al., "Improving Language Understanding by Generative Multi-Task Learning"**.