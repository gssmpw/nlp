\section{Experiments}
\label{sec:experiment}
\subsection{Experimental Setup}
\textbf{Dataset.} To validate the performance of the proposed model in diverse environments, both a public dataset and a custom dataset are utilized. For the public dataset, the widely-adopted \textbf{KITTI} 3D Benchmark \cite{geiger2012we} is selected. Following standard practice \cite{chen20153d, chen2016monocular}, the dataset is splited into 3,712 samples for training and 3,769 samples for validation.

Most M3OD models in academia are primarily evaluated on public datasets like KITTI, which consist of flat roads with minimal elevation changes. To assess the model's performance in a high-bank environment, such as a race track, we constructed a \textbf{custom dataset} from a racing scenario. Image and LiDAR data were collected using our race car platform, as shown in Figure \ref{fig:Indy car platform}, during a head-to-head race with an opponent vehicle at the Kentucky Speedway, where each car took turns overtaking the other in a parallel line while progressively increasing the target speed.

First, we collected time-synchronized image and LiDAR data to create paired image-LiDAR samples. Ground-truth 3D bounding boxes were generated using a pseudo-labeling approach with the PointPillars model \cite{lang2019pointpillars}, a LiDAR-based detection method. The resulting data was then post-processed and filtered to obtain 1,171 training samples and 293 validation samples, each containing paired images and 3D bounding box labels in the KITTI format.

\textbf{Evaluation metrics.}  We report the detection results for three levels of difficulty-easy, moderate, and hard-on the KITTI validation dataset.
The evaluation is conducted using the average precision of bounding boxes in 3D space, $AP_{3D}$, and the bird's-eye view, $AP_{BEV}$, both calculated at 40 recall positions.

\textbf{Implementation details.} For training, we used 4 NVIDIA TITAN RTX GPUs for 195 epochs with a batch size of 8 and a learning rate of 0.0002. The AdamW \cite{loshchilov2017decoupled} optimizer with a weight decay of 0.0001 was employed. The learning rate was reduced by a factor of 0.1 at 125 and 165. For the foreground depth map, the depth range $[d_{min}, d_{max}]$ was set to $[0m, 60m]$ for the KITTI dataset, and $[0m, 120m]$ for the custom dataset. The number of bins $k$ was set to 80 and 160, respectively.

\begin{table*}[h]
\caption[Comparison of our model with state-of-the-art models on KITTI \textit{val.}]{\textbf{Comparison of our model with state-of-the-art models on KITTI \textit{val.} set for the car class.} `Mod.' indicates the moderate difficulty level. Bold numbers highlight the best results, underlined numbers indicate the second-best results, and blue numbers represent the improvement over them. {\small *Since CaDDN uses a substantial amount of GPU memory, the batch size is set to 2 per GPU across 4 GPUs for CaDDN, and 8 for other models.}}
\centering
\small
\begin{tabular}{l|c|ccc|ccc|c}
	\toprule
\multirow{2}{*}{Method} & \multirow{2}{*}{Extra data} & \multicolumn{3}{c|}{Val,\ $AP_{3D}$} & \multicolumn{3}{c|}{Val,\ $AP_{BEV}$} & Time \\ 
% \cline{3-11}
& & Easy & Mod. & Hard & Easy & Mod. & Hard & (ms) \\
\midrule
CaDDN* (CVPR 2021) \cite{reading2021categorical} & \multirow{2}{*}{LiDAR} & 21.91 & 15.28 & 13.66 & 29.96 & 21.61 & 18.95  & - \\
MonoDTR (CVPR 2022) \cite{huang2022monodtr} &  & 23.92 & \underline{18.76} & \underline{15.81} & \underline{32.24} & \underline{24.66} & \underline{21.21}  & - \\
\midrule
MonoGround (CVPR 2022) \cite{qin2022monoground} & \multirow{2}{*}{None} & 19.78 & 14.46 & 12.42 & 28.11 & 21.21 & 19.00  & 42 \\
MonoDETR (ICCV 2023)\cite{zhang2023monodetr} &  & \underline{24.29} & 17.52 & 15.28 & 32.16 & 23.54 & 20.12 & 23 \\
\midrule
MonoCD (CVPR 2024) \cite{yan2024monocd} & Planes & 21.39 & 15.86 & 13.09 & 29.60 & 22.73  & 13.09 & 35 \\
\midrule
\textbf{MonoDINO-DETR} & \multirow{2}{*}{None} & 26.72 & 19.19 & 15.92 & 37.65 & \textbf{26.70} & 21.79 & 66 \\
\textbf{MonoDINO-DETR + DAB} &  & \textbf{27.93} & \textbf{19.39} & \textbf{15.97} & \textbf{38.51} & 26.15 & \textbf{22.00} & 74 \\
\textit{Improvement} & \textit{v.s. second-best} & \color{blue}{+3.64} & \color{blue}{+0.63} & \color{blue}{+0.16} & \color{blue}{+6.27} & \color{blue}{+1.49} & \color{blue}{+0.79} & \\
\bottomrule
\end{tabular}
\label{tab:KITTI_valid}
\end{table*}

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/indy_platform.jpg}
    \caption[Indy Race Car Platform]{\textbf{Indy Race Car Platform.} Synchronized camera image data and LiDAR data were acquired during the race using a front-mounted Luminar Iris LiDAR sensor and a front-left Mako G-319C camera.
    } \label{fig:Indy car platform}
\end{figure}

\begin{table*}[h]
\caption[Comparison of our model with state-of-the-art models on our custom dataset]{Comparison of our model with state-of-the-art models on our custom dataset for the car class.}
\centering
\small
\begin{tabular}{l|c|cc|cc|c}
	\toprule
\multirow{2}{*}{Method} & \multirow{2}{*}{Extra data} & \multicolumn{2}{c|}{Val,\ (IoU = 0.7)} & \multicolumn{2}{c|}{Val,\ (IoU = 0.5)} & Time \\ 
% \cline{3-11}
& & $AP_{3D}$ & $AP_{BEV}$  & $AP_{3D}$ & $AP_{BEV}$ & (ms) \\
\midrule
MonoGround (CVPR 2022) \cite{qin2022monoground} & \multirow{2}{*}{None} & 1.49 & 10.14 & 21.66 & \underline{71.87} & 110 \\
MonoDETR (ICCV 2023)\cite{zhang2023monodetr} &  & \underline{9.86} & \underline{21.59} & \underline{36.35} & 44.09 & 23 \\
\midrule
\textbf{MonoDINO-DETR {\small (small)}} & \multirow{2}{*}{None} & 22.47 & 41.44 & 62.11 & 69.92 & 41 \\
\textbf{MonoDINO-DETR {\small (base)}} &  & \textbf{26.23} & \textbf{59.68} & \textbf{80.30} & \textbf{88.80} & 70 \\
\textit{Improvement} & \textit{v.s. second-best} & \color{blue}{+16.37} & \color{blue}{+38.09} & \color{blue}{+43.95} & \color{blue}{+16.93} & \\
\bottomrule
\end{tabular}
\label{tab:Cusom_valid}
\end{table*}

\subsection{Main Results}
\textbf{KITTI validation set.} Table \ref{tab:KITTI_valid} presents the validation result of state-of-the-art models and our model on the KITTI dataset. The proposed model, MonoDINO-DETR, outperforms all recent models in the table in terms of both $AP_{3D}$ and  $AP_{BEV}$. Even without requiring any additional data, it surpasses models that utilize extra data, such as LiDAR or ground information.
%Specifically, for objects in the ``easy" difficulty level, our model with DAB achieves an  $AP_{3D}$ score that is 3.64\% higher than the second-best model.
Furthermore, even without DAB, it still demonstrates the second-best performance. Visualized results for the KITTI dataset are shown in Figure \ref{fig:KITTI visualized}.

\textbf{Custom Dataset.} Table \ref{tab:Cusom_valid} presents the validation results for the custom dataset.
We tested other M3OD models, such as MonoGround and MonoDETR, which do not require extra data.
As shown, our model significantly outperforms the others on the custom dataset, demonstrating the superior generalizability of foundation models.
Notably, MonoGround performs very poorly in 3D object detection, likely due to its assumption that the ground is flat.
In contrast, our model makes no such assumptions, allowing it to achieve the best performance across diverse environments, whether on flat ground or high-bank tracks. Visualized results of the custom dataset are shown in Figure \ref{fig:custom_result_visualized}.

\subsection{Ablation Studies}
\textbf{Effect of the Foundation Model.}
%We also conducted an ablation study to verify the effectiveness of each component in our model.
To evaluate the impact of the foundation model for depth estimation and object localization, we compared the MonoDETR model with MonoDETR enhanced by our depth feature extraction module.
%In the MonoDETR model, we replaced its original depth feature extraction module with our proposed module.
In other words, we replaced the visual feature extraction module in our models with an alternative ResNet backbone, instead of using the HFFB.

Table \ref{tab:Ablation1_KITTI} presents the results of the first ablation study on the KITTI dataset. The MonoDETR model enhanced with our depth feature extraction module outperforms the original MonoDETR model. This demonstrates that, with the help of the foundation model, it can better estimate the depth value of each pixel in the image, resulting in improved performance in predicting 3D bounding boxes.
Additionally, by comparing this variant model with our model—which relies solely on DINOv2 as the backbone without an additional ResNet backbone—it can be inferred that foundation models are more effective at capturing visual features than ResNet \cite{he2016deep}. This enhanced feature extraction capability translates to improved performance in predicting 3D bounding boxes.

\begin{table}[h]
\caption[Comparison of models with or without DINOv2 + DPT Head result on the KITTI \textit{val.} set]{Comparison of models with or without DINOv2 + DPT Head result on the KITTI \textit{val.} set for the car class.}
\centering
\small
\begin{tabular}{l|ccc}
\toprule
\multirow{2}{*}{Method} & \multicolumn{3}{c}{Val,\ $AP_{3D}$} \\
& Easy & Mod. & Hard \\
\midrule
MonoDETR\cite{zhang2023monodetr} & 24.29 & 17.52 & 15.28 \\
MonoDETR {\small +DINOv2+DPT Head} & \underline{25.44} & \underline{18.69} & \underline{15.57} \\
\textbf{MonoDINO-DETR} & \textbf{26.72} & \textbf{19.19} & \textbf{15.92} \\
\bottomrule
\end{tabular}
\label{tab:Ablation1_KITTI}
\end{table}

\textbf{Effect of the Hierarchical Feature Fusion Block.} To evaluate the impact of the Hierarchical Feature Fusion Block (HFFB), we tested the following variants of HFFB as shown in Figure \ref{fig:HFB Ablation}.

\begin{table*}[h]
\caption[Comparison of models with HFFB variants result on the KITTI \textit{val.} set]{Comparison of models with HFFB variants result on the KITTI \textit{val.} set for the car class.}
\centering
\small
\begin{tabular}{l|ccc|ccc|ccc|c}
	\toprule
\multirow{2}{*}{Method} & \multicolumn{3}{c|}{Val,\ $AP_{3D}$} & \multicolumn{3}{c|}{Val,\ $AP_{BEV}$} & \multicolumn{3}{c|}{Val,\ $AP_{BBOX}$} & Time \\ 
% \cline{3-11}
& Easy & Mod. & Hard & Easy & Mod. & Hard & Easy & Mod. & Hard & (ms) \\
\midrule
(1) Last layer only & 23.20 & 16.08 & 12.86 & \underline{34.36} & 23.15 & 19.18 & 92.74 & 77.78 & 70.36 & 49 \\
(2) Last layer with 3 dif. DeConvs & \underline{23.61} & 16.51 & \underline{13.71} & 34.06 & 23.00 & 19.35 & 92.94 & 78.93 & 73.76 & 71 \\
(3) 3 Layers without DeConvs & 21.90 & \underline{16.66} & 13.64 & 33.50 & \underline{23.94} & \underline{20.09} & \underline{95.03} & \underline{83.69} & \underline{76.37} &  51 \\
\midrule
\textbf{3 layers with DeConvs(=HFFB)}  & \textbf{26.72} & \textbf{19.19} & \textbf{15.92} & \textbf{37.65} & \textbf{26.70} & \textbf{21.79} & \textbf{96.00} & \textbf{87.09} & \textbf{79.84} & 66 \\
\textit{Improvement v.s. second-best} & \color{blue}{+3.11} & \color{blue}{+2.53} & \color{blue}{+2.21} & \color{blue}{+3.29} & \color{blue}{+2.76} & \color{blue}{+1.70} & \color{blue}{+0.97} & \color{blue}{+3.40} & \color{blue}{+3.47} & \\
\bottomrule
\end{tabular}
\label{tab:Ablation2_KITTI}
\end{table*}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\linewidth]{figures/HFB_Ablation3.png}
    \caption[Ablation Study 2: Effect of the HFFB]{\textbf{Ablation Study 2: Effect of the Hierarchical Feature Fusion Block.} We evaluated the effect of HFFB by testing 3 HFFB variants.
    } \label{fig:HFB Ablation}
\end{figure}

The first variant uses only the last layer features from the intermediate layers to extract visual features. It does not incorporate any hierarchical architecture to obtain features at diverse resolutions.
The second variant module generates multi-scale features using only the last layer feature.
%It differs from the original HFB in that the original module uses features from the 6th, 9th, and 12th layers to generate multi-scale features.
This architecture resembles a simple feature pyramid of VitDet \cite{li2022exploring}.
The last variant module uses the three layer features from DINOv2 but does not employ transposed convolution to generate different resolutions.
%Instead, it extracts visual features with the same resolution but from different layers.

As shown in Table \ref{tab:Ablation2_KITTI}, the HFFB is a key component for localizing objects in 2D space and providing rich visual features to estimate 3D bounding boxes in the decoder module.
%(1) Using only the last layer feature appears to result in the lowest performance for both 3D bounding box estimation and 2D bounding box localization. When examining the result of $AP_{BBOX}$, which measures the average precision for 2D bounding box localization, (3) utilizing features from three different layers shows some improvement, likely due to the inclusion of multi-level features. This approach also outperforms (2), which uses features from the last layer combined with three different transposed convolutions, similar to VitDet.
Only by combining features from three layers with transposed convolution to generate multi-scale hierarchical features does the model achieve the best performance.
This demonstrates the effectiveness of the HFFB in extracting meaningful local features from DINOv2’s backbone, leading to improved 3D object detection performance.

\textbf{Effect of 6D Dynamic Anchor Boxes.} The final ablation study was conducted to evaluate the effect of 6 dimensional dynamic anchor boxes. We configured the decoder queries as learnable dynamic anchors with six dimensions to accurately estimate bounding boxes. As shown in Table \ref{tab:Ablation3_KITTI}, the model with DAB outperforms the one without it across most metrics and difficulty levels. This demonstrates that 6D DAB effectively incorporates the spatial information of bounding boxes and refines object queries layer by layer, leading to improved performance in 3D object detection.

\begin{table}[h]
\caption[Comparison of models with or without DAB result on the KITTI \textit{val.} set]{Comparison of models with or without DAB result on the KITTI \textit{val.} set for the car class.}
\centering
\small
\begin{tabular}{l|ccc}
\toprule
\multirow{2}{*}{Method} &  \multicolumn{3}{c}{Val,\ $AP_{3D}$} \\
& Easy & Mod. & Hard \\
\midrule
MonoDINO-DETR & 26.72 & 19.19 & 15.92\\
\textbf{MonoDINO-DETR {\small + DAB}} & \textbf{27.93} & \textbf{19.39} & \textbf{15.97} \\
\bottomrule
\end{tabular}
\label{tab:Ablation3_KITTI}
\end{table}