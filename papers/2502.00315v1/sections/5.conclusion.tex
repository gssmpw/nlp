\begin{figure*}[h]
    \centering
    \includegraphics[width=14cm]{figures/visualized_kitti5.jpg}
    \caption[Qualitative Results on KITTI \textit{val.} set]{\textbf{Qualitative results on the KITTI \textit{val} set for the car class.} The proposed method (green) and ground truth (red).
    } \label{fig:KITTI visualized}
\end{figure*}

\begin{figure*}[t]
    \centering
     \includegraphics[width=14cm]{figures/custom_result_monodetr_monoground3.jpg}
    \caption{\textbf{Qualitative results on the custom dataset.} Comparison of detection results between the proposed model (blue), the state-of-the-art models (green), and ground truth (red) in ego-view (left) and bird's-eye view (right); MonoDETR (left) and MonoGround (right).}
    \label{fig:custom_result_visualized}
\end{figure*}

\section{Conclusion}
\label{sec:conclusion}
This paper presents a novel approach to monocular 3D object detection by integrating a Vision Foundation Model as the backbone with the DETR architecture, enabling enhanced depth estimation and feature extraction within a single-stage, real-time framework. By incorporating a Hierarchical Feature Fusion Block for multi-scale detection and 6D Dynamic Anchor Boxes for iterative bounding box refinement, the proposed model achieves improved performance without relying on additional data sources, such as LiDAR. Future work will focus on extending the model's capabilities to detect 3D bounding boxes while accounting for rolling and pitching angles.