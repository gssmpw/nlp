\section{Related Work}
\vspace{-0.3em}
\paragraph{LLM-Agents and Agentic Systems.}
% \vspace{-0.5em}
%With the advent of advanced large language models (LLMs)~\citep{openai2023gpt4,team2023gemini}, significant efforts have been made to develop autonomous agents~\citep{autogpt,babyagi} by equipping LLMs with high-level features, such as persona, tool, planning and memory~\citep{shen2024hugginggpt,zhu2024knowagent,zhong2024memorybank}. 
Building on the success of single agents~\citep{shen2024hugginggpt,zhu2024knowagent,zhong2024memorybank}, studies have shown that grouping multiple LLM-based agents into multi-agent systems (MAS) can substantially enhance individual model capabilities~\citep{FCS2024_Survey-Agent}, as demonstrated in early attempts such as AutoGen~\citep{autogen}, LLM-Debate~\citep{arXiv2023_MultiAgent-Debate}, and AgentVerse~\citep{chen2023agentverse}. 
However, they heavily relied on manually crafted designs, which constrained the adaptability and flexibility of agents in addressing unforeseen challenges~\citep{he2023lego,chen2023agentverse}. As a result, automated agentic system design has gained increasing attention in the academic community.




\vspace{-0.6em}
\paragraph{Automating Agentic Systems.}
% \vspace{-0.5em}
Efforts to automate the design of agent-based systems can be broadly classified into the following categories: \textbf{(I) Prompt Optimization}, such as PromptBreeder~\citep{fernando2023promptbreeder}, DsPy~\citep{khattab2023dspy}, and EvoPrompt~\citep{guo2023evoprompt}; \textbf{(II) Inter-agent Communication}, which focuses on orchestrating interactions between agents, including GPTSwarm~\citep{zhuge2024gptswarm}, DyLAN~\citep{arXiv2023_Dynamic-LLM-Agent}, EvoMAC~\citep{hu2024evomac}, AgentPrune~\citep{zhang2024cut} and G-Designer~\citep{zhang2024gdesigner}; and \textbf{(III) Agent Profiling}, represented by AgentVerse~\citep{chen2023agentverse}, EvoAgent~\citep{yuan2024evoagent}, and AutoAgents~\citep{chen2023autoagents}. 
Further, ADAS~\citep{hu2024adas} and AgentSquare~\citep{shang2024agentsquare} provide more comprehensive automation for single-agent design, while AFlow~\citep{zhang2024aflow} achieves multi-agent workflow automation using Monte Carlo tree search (MCTS). However, these high-performing methods still follow the paradigm of searching for a single final system, whereas \ourmethod searches for distribution of architectures with lower average inference costs (LLM calls, token cost, \textit{etc.}).


\vspace{-0.6em}
\paragraph{AutoML.} Automating the design of agentic systems is an emerging topic, yet the history of AutoML~\citep{he2021automl} provides clear precedents. Notably, the progression of agentic automation mirrors that of neural architecture search (NAS)~\citep{ren2021comprehensivenas}. Core NAS techniques, such as reinforcement learning~\citep{zoph2016rl-nas}, evolutionary algorithms~\citep{liu2021evo-nas}, Bayesian optimization (BO)~\citep{white2021bananas}, and MCTS~\citep{wang2021mcts-nas}, have inspired analogous approaches in agentic automation, from policy gradient in \citep{zhuge2024gptswarm} to evolutionary search in \citep{yuan2024evoagent}, BO in \citep{shang2024agentsquare}, and MCTS in \citep{zhang2024aflow}. In NAS, however, these black-box methods were eventually eclipsed by efficient supernet training~\citep{white2023nas1k}, culminating in seminal works like DARTS~\citep{liu2018darts} and SNAS~\citep{xie2018snas}. Inspired by this, we introduce the first MAS searching framework leveraging an \textit{\textbf{agentic supernet}}, posing new paradigms and challenges for agentic automation.



\vspace{-0.4em}