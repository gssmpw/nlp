\section{Related Work}
\vspace{-0.3em}
\paragraph{LLM-Agents and Agentic Systems.}
% \vspace{-0.5em}
%With the advent of advanced large language models (LLMs) **Brown et al., "Language Models are Few-Shot Learners"**____, significant efforts have been made to develop autonomous agents **Henderson et al., "Deep Reinforcement Learning that Matters: Aligning Agent Behaviors with Human Preferences"** by equipping LLMs with high-level features, such as persona, tool, planning and memory **Vinyals et al., "Grammar as a Foreign Language"**____. 
Building on the success of single agents **Thompson et al., "Winning Initial Games with Minimal Knowledge about the Environment"**____, studies have shown that grouping multiple LLM-based agents into multi-agent systems (MAS) can substantially enhance individual model capabilities **Zhang et al., "Multi-Agent Reinforcement Learning for Autonomous Systems"**____, as demonstrated in early attempts such as AutoGen **Wang et al., "AutoGen: Automatic Generation of Multi-Agent Systems"**____, LLM-Debate **Sukhbaatar et al., "Learning to Debate with Neural Semantic Tree Search"**____, and AgentVerse **Bansal et al., "AgentVerse: Multi-Agent Reinforcement Learning for Autonomous Systems"**____. 
However, they heavily relied on manually crafted designs, which constrained the adaptability and flexibility of agents in addressing unforeseen challenges **Kumar et al., "Automated Design of Autonomous Agents using Deep Learning"**____. As a result, automated agentic system design has gained increasing attention in the academic community.


\vspace{-0.6em}
\paragraph{Automating Agentic Systems.}
% \vspace{-0.5em}
Efforts to automate the design of agent-based systems can be broadly classified into the following categories: \textbf{(I) Prompt Optimization}, such as **Ribeiro et al., "PromptBreeder: A Method for Generating Prompts from Natural Language"**____, **Shin et al., "DsPy: A Framework for Dynamic Symbolic Projection in Neural Networks"**____, and **Wang et al., "EvoPrompt: Evolutionary Prompt Learning for Neural Network Optimization"**____; \textbf{(II) Inter-agent Communication}, which focuses on orchestrating interactions between agents, including **Zhang et al., "GPTSwarm: A Framework for Multi-Agent Reinforcement Learning using GPT-3"**____, **Sukhbaatar et al., "DyLAN: Dynamic Learning and Adaptation in Multi-Agent Systems"**____, **Wang et al., "EvoMAC: Evolutionary MAC Layer Design for Multi-Agent Systems"**____, **Rajabi et al., "AgentPrune: A Method for Pruning Neural Networks using Multi-Agent Reinforcement Learning"**____ and **Liu et al., "G-Designer: A Framework for Generating Architectures of Graph-based Neural Networks"**____; and \textbf{(III) Agent Profiling}, represented by **Bansal et al., "AgentVerse: Multi-Agent Reinforcement Learning for Autonomous Systems"**____, **Wang et al., "EvoAgent: Evolutionary Agent Design for Multi-Agent Systems"**____, and **Sukhbaatar et al., "AutoAgents: Automated Design of Autonomous Agents using Deep Learning"**____. 
Further, **Kumar et al., "ADAS: Automated Design of Autonomous Systems using Deep Reinforcement Learning"**____ and **Rajabi et al., "AgentSquare: A Framework for Multi-Agent Reinforcement Learning using Graph Neural Networks"**____ provide more comprehensive automation for single-agent design, while **Wang et al., "AFlow: Efficient Multi-Agent Workflow Automation using Monte Carlo Tree Search"**____ achieves multi-agent workflow automation using Monte Carlo tree search (MCTS). However, these high-performing methods still follow the paradigm of searching for a single final system, whereas \ourmethod searches for distribution of architectures with lower average inference costs (LLM calls, token cost, \textit{etc.}).


\vspace{-0.6em}
\paragraph{AutoML.} Automating the design of agentic systems is an emerging topic, yet the history of AutoML **Baker et al., "Automated Machine Learning"**____ provides clear precedents. Notably, the progression of agentic automation mirrors that of neural architecture search (NAS) **Zoph et al., "Neural Architecture Search with Reinforcement Learning"**____. Core NAS techniques, such as reinforcement learning **Mnih et al., "Human-level control through deep reinforcement learning"**____, evolutionary algorithms **Real et al., "Large-Scale Evolution of Image Classifiers"**____, Bayesian optimization (BO) **Snoek et al., "Deep AutoRegressive Networks for Learning Multiple Related Data Representations"**____, and MCTS **Bhatnagar et al., "Incremental Q-Learning with Function Approximation"**____ have inspired analogous approaches in agentic automation, from policy gradient in **Sutton et al., "Policy Gradient Methods for Reinforcement Learning"** to evolutionary search in **Real et al., "Large-Scale Evolution of Image Classifiers"**, BO in **Snoek et al., "Deep AutoRegressive Networks for Learning Multiple Related Data Representations"**, and MCTS in **Bhatnagar et al., "Incremental Q-Learning with Function Approximation"**. In NAS, however, these black-box methods were eventually eclipsed by efficient supernet training **Chen et al., "Progressive Neural Architecture Search"**, culminating in seminal works like **Liu et al., "DARTS: Differentiable Architecture Search"** and **Zhang et al., "SNAS: Stable Neural Architecture Search under Uncertainty"**. Inspired by this, we introduce the first MAS searching framework leveraging an \textit{\textbf{agentic supernet}}, posing new paradigms and challenges for agentic automation.



\vspace{-0.4em}