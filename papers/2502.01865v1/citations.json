[
  {
    "index": 0,
    "papers": [
      {
        "key": "sinha2017review",
        "author": "Sinha, Ankur and Malo, Pekka and Deb, Kalyanmoy",
        "title": "A review on bilevel optimization: From classical to evolutionary approaches and applications"
      },
      {
        "key": "zhang2024introduction",
        "author": "Zhang, Yihua and Khanduri, Prashant and Tsaknakis, Ioannis and Yao, Yuguang and Hong, Mingyi and Liu, Sijia",
        "title": "An Introduction to Bilevel Optimization: Foundations and applications in signal processing and machine learning"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "lorraine2020optimizing",
        "author": "Lorraine, Jonathan and Vicol, Paul and Duvenaud, David",
        "title": "Optimizing millions of hyperparameters by implicit differentiation"
      },
      {
        "key": "maclaurin2015gradient",
        "author": "Maclaurin, Dougal and Duvenaud, David and Adams, Ryan",
        "title": "Gradient-based hyperparameter optimization through reversible learning"
      },
      {
        "key": "mackay2019self",
        "author": "MacKay, Matthew and Vicol, Paul and Lorraine, Jon and Duvenaud, David and Grosse, Roger",
        "title": "Self-tuning networks: Bilevel optimization of hyperparameters using structured best-response functions"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "finn2017model",
        "author": "Finn, Chelsea and Abbeel, Pieter and Levine, Sergey",
        "title": "Model-agnostic meta-learning for fast adaptation of deep networks"
      },
      {
        "key": "gao2022loss",
        "author": "Gao, Boyan and Gouk, Henry and Yang, Yongxin and Hospedales, Timothy",
        "title": "Loss function learning for domain generalization by implicit gradient"
      },
      {
        "key": "rajeswaran2019meta",
        "author": "Rajeswaran, Aravind and Finn, Chelsea and Kakade, Sham M and Levine, Sergey",
        "title": "Meta-learning with implicit gradients"
      },
      {
        "key": "gao2021searching",
        "author": "Gao, Boyan and Gouk, Henry and Hospedales, Timothy M",
        "title": "Searching for robustness: Loss learning for noisy classification tasks"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "wang2018dataset",
        "author": "Wang, Tongzhou and Zhu, Jun-Yan and Torralba, Antonio and Efros, Alexei A",
        "title": "Dataset distillation"
      },
      {
        "key": "dc2021",
        "author": "Zhao, Bo and Mopuri, Konda Reddy and Bilen, Hakan",
        "title": "Dataset Condensation with Gradient Matching."
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "mtt",
        "author": "Cazenavette, George and Wang, Tongzhou and Torralba, Antonio and Efros, Alexei A and Zhu, Jun-Yan",
        "title": "Dataset distillation by matching training trajectories"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "mtt",
        "author": "Cazenavette, George and Wang, Tongzhou and Torralba, Antonio and Efros, Alexei A and Zhu, Jun-Yan",
        "title": "Dataset distillation by matching training trajectories"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "mtt",
        "author": "Cazenavette, George and Wang, Tongzhou and Torralba, Antonio and Efros, Alexei A and Zhu, Jun-Yan",
        "title": "Dataset distillation by matching training trajectories"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "gou2021knowledge",
        "author": "Gou, Jianping and Yu, Baosheng and Maybank, Stephen J and Tao, Dacheng",
        "title": "Knowledge distillation: A survey"
      },
      {
        "key": "yang2020distilling",
        "author": "Yang, Yiding and Qiu, Jiayan and Song, Mingli and Tao, Dacheng and Wang, Xinchao",
        "title": "Distilling knowledge from graph convolutional networks"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "lorraine2020optimizing",
        "author": "Lorraine, Jonathan and Vicol, Paul and Duvenaud, David",
        "title": "Optimizing millions of hyperparameters by implicit differentiation"
      },
      {
        "key": "maclaurin2015gradient",
        "author": "Maclaurin, Dougal and Duvenaud, David and Adams, Ryan",
        "title": "Gradient-based hyperparameter optimization through reversible learning"
      },
      {
        "key": "mackay2019self",
        "author": "MacKay, Matthew and Vicol, Paul and Lorraine, Jon and Duvenaud, David and Grosse, Roger",
        "title": "Self-tuning networks: Bilevel optimization of hyperparameters using structured best-response functions"
      },
      {
        "key": "finn2017model",
        "author": "Finn, Chelsea and Abbeel, Pieter and Levine, Sergey",
        "title": "Model-agnostic meta-learning for fast adaptation of deep networks"
      },
      {
        "key": "gao2022loss",
        "author": "Gao, Boyan and Gouk, Henry and Yang, Yongxin and Hospedales, Timothy",
        "title": "Loss function learning for domain generalization by implicit gradient"
      },
      {
        "key": "rajeswaran2019meta",
        "author": "Rajeswaran, Aravind and Finn, Chelsea and Kakade, Sham M and Levine, Sergey",
        "title": "Meta-learning with implicit gradients"
      },
      {
        "key": "gao2021searching",
        "author": "Gao, Boyan and Gouk, Henry and Hospedales, Timothy M",
        "title": "Searching for robustness: Loss learning for noisy classification tasks"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "wang2018dataset",
        "author": "Wang, Tongzhou and Zhu, Jun-Yan and Torralba, Antonio and Efros, Alexei A",
        "title": "Dataset distillation"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "dsa2021",
        "author": "Zhao, Bo and Bilen, Hakan",
        "title": "Dataset condensation with differentiable siamese augmentation"
      },
      {
        "key": "dc2021",
        "author": "Zhao, Bo and Mopuri, Konda Reddy and Bilen, Hakan",
        "title": "Dataset Condensation with Gradient Matching."
      },
      {
        "key": "lee2022dataset",
        "author": "Lee, Saehyung and Chun, Sanghyuk and Jung, Sangwon and Yun, Sangdoo and Yoon, Sungroh",
        "title": "Dataset condensation with contrastive signals"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "wang2022cafe",
        "author": "Wang, Kai and Zhao, Bo and Peng, Xiangyu and Zhu, Zheng and Yang, Shuo and Wang, Shuo and Huang, Guan and Bilen, Hakan and Wang, Xinchao and You, Yang",
        "title": "Cafe: Learning to condense dataset by aligning features"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "dm",
        "author": "Zhao, Bo and Bilen, Hakan",
        "title": "Dataset condensation with distribution matching"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "rded",
        "author": "Sun, Peng and Shi, Bei and Yu, Daiwei and Lin, Tao",
        "title": "On the diversity and realism of distilled dataset: An efficient dataset distillation paradigm"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "nguyen2021dataset",
        "author": "Nguyen, Timothy and Novak, Roman and Xiao, Lechao and Lee, Jaehoon",
        "title": "Dataset distillation with infinitely wide convolutional networks"
      },
      {
        "key": "nguyen2022dataset",
        "author": "Timothy Nguyen and Zhourong Chen and Jaehoon Lee",
        "title": "Dataset Meta-Learning from Kernel Ridge-Regression"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "mtt",
        "author": "Cazenavette, George and Wang, Tongzhou and Torralba, Antonio and Efros, Alexei A and Zhu, Jun-Yan",
        "title": "Dataset distillation by matching training trajectories"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "ftd",
        "author": "Du, Jiawei and Jiang, Yidi and Tan, Vincent YF and Zhou, Joey Tianyi and Li, Haizhou",
        "title": "Minimizing the accumulated trajectory error to improve dataset distillation"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "TESLA",
        "author": "Cui, Justin and Wang, Ruochen and Si, Si and Hsieh, Cho-Jui",
        "title": "Scaling up dataset distillation to imagenet-1k with constant memory"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "datm",
        "author": "Ziyao Guo and Kai Wang and George Cazenavette and HUI LI and Kaipeng Zhang and Yang You",
        "title": "Towards Lossless Dataset Distillation via Difficulty-Aligned Trajectory Matching"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "dinh2017sharp",
        "author": "Dinh, Laurent and Pascanu, Razvan and Bengio, Samy and Bengio, Yoshua",
        "title": "Sharp minima can generalize for deep nets"
      },
      {
        "key": "keskar2016large",
        "author": "Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter",
        "title": "On large-batch training for deep learning: Generalization gap and sharp minima"
      },
      {
        "key": "neyshabur2017exploring",
        "author": "Neyshabur, Behnam and Bhojanapalli, Srinadh and McAllester, David and Srebro, Nati",
        "title": "Exploring generalization in deep learning"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "sam",
        "author": "Foret, Pierre and Kleiner, Ariel and Mobahi, Hossein and Neyshabur, Behnam",
        "title": "Sharpness-aware minimization for efficiently improving generalization"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "esam",
        "author": "Jiawei Du and Hanshu Yan and Jiashi Feng and Joey Tianyi Zhou and Liangli Zhen and Rick Siow Mong Goh and Vincent Tan",
        "title": "Efficient Sharpness-aware Minimization for Improved Training of Neural Networks"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "gsam",
        "author": "Zhuang, Juntang and Gong, Boqing and Yuan, Liangzhe and Cui, Yin and Adam, Hartwig and Dvornek, Nicha C and s Duncan, James and Liu, Ting and others",
        "title": "Surrogate Gap Minimization Improves Sharpness-Aware Training"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "vasso",
        "author": "Li, Bingcong and Giannakis, Georgios",
        "title": "Enhancing sharpness-aware optimization through variance suppression"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "asam",
        "author": "Kwon, Jungmin and Kim, Jeongseop and Park, Hyunseo and Choi, In Kwon",
        "title": "Asam: Adaptive sharpness-aware minimization for scale-invariant learning of deep neural networks"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "sharpmaml",
        "author": "Abbas, Momin and Xiao, Quan and Chen, Lisha and Chen, Pin-Yu and Chen, Tianyi",
        "title": "Sharp-maml: Sharpness-aware model-agnostic meta learning"
      }
    ]
  }
]