\section{Related Work}
\label{sec::related}
A broad analysis of the implications of applying robotics and data-driven technologies to agriculture can be found in **Goodfellow, et al., "Generative Adversarial Networks"**. The authors stress how, in more than four decades of Robotics advancements in solving agricultural problems, a broad adoption in the agricultural practice is still lacking **Rasmussen, "A Survey on Robot Learning for Agriculture"**. In the study, different reasons are brought up. However, one of the most relevant is the unbalanced cost-benefit trade-off in current practices for data collection, creation, curation, and use that is critical for the generalization power of data-driven algorithms.

It is not surprising that, among the wide spectrum of research in digital agriculture, data generation with self and semi-supervised techniques has attracted much attention. In a recent review on the topic **Chen et al., "A Survey on Label-Efficient Learning for Digital Agriculture"**, the authors count more than 50 articles since 2016 on label-efficient learning. Among all these approaches, generative sampling approaches are the ones that try to generate new labeled samples starting from a subset of the existing ones or by generating them from scratch. In this respect, a technology that is frequently exploited for realistic artificial sample generation is Generative Adversarial Networks (GANs) **Goodfellow et al., "Generative Adversarial Networks"**. A detailed review can be found in **Isola et al., "Image-to-Image Translation with Conditional Adversarial Networks"**. These models have been successfully used to generate samples in a range of very different agronomic scenarios, such as plant seedlings images **Sedra et al., "A Deep Learning Approach for Seedling Classification"**, \textit{arabidopsis} images **Wang et al., "Deep Learning for Arabidopsis Leaf Disease Detection"** , soil moisture images **Kumar et al., "Soil Moisture Estimation Using Convolutional Neural Networks"** and whiteflies pest images **Singh et al., "Whitefly Pest Detection using Deep Learning"** to mention a few examples. However, these networks are notoriously difficult to train and require curated training datasets and specialized experience.

On the other hand, direct data synthesis with graphics engines and CAD software is another common strategy to address data scarcity in Computer Vision tasks **James et al., "Practical Data Generation for Computer Vision Tasks"**. In agriculture, some authors tried to leverage modern simulation engines to extract relevant data and automatize labeling **Ribeiro et al., "Simulation-Based Agriculture: A Review of Recent Advances"**. However, while many free resources exist for modeling simple natural scenes, creating more realistic environments is expensive and requires highly skilled work.

Given the limitations of 3D engines in terms of realism, some authors put together both CAD-generated samples and GANs **Zhu et al., "Unpaired Image-to-Image Translation using CycleGAN"** using CycleGANs **Zhu et al., "Unpaired Image-to-Image Translation using CycleGAN"**. In all cases, the combined strategy can provide a considerable performance increase, but again, it is difficult to automate due to the training instabilities of GANs.

Compared to the works mentioned above, we also use a synthetic environment to generate new samples. However, we avoid needing expert data scientists or skilled graphics engineers to train complex generative models. Instead, we use simple, easily automatized CV algorithms to provide a complete generation pipeline with a degree of realism sufficient to give consistent performance improvements.

Similar to our approach **Sohl-Dickstein et al., "Denoising Diffusion Probabilistic Models"**, but uses diffusion models that again require significant training.