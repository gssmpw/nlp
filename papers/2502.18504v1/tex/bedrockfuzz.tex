\section{Method: \bedrockfuzz}
\label{sec:bedrockfuzz}
Figure~\ref{fig:workflow} presents an overview of \bedrockfuzz. Except of a collection of functional (\S\ref{sec:functional}), efficiency-focused (\S\ref{sec:efficiency}), and engineering upgrades (Appendix~\ref{sec:engineering}), the overall workflow of \bedrockfuzz is the same as GPTFuzzer.

Given a set of original templates $O = \{ o_1, o_2, \dots, o_{|O|} \}$, a set of harmful questions $Q = \{ q_1, q_2, \dots, q_{|Q|} \}$, and a target model $T$, \bedrockfuzz performs black-box mutation-based fuzzing to iteratively generate new jailbreaking templates $G = \{ g_1, g_2, \dots, g_{|G|} \}$.
In each fuzzing iteration, \bedrockfuzz selects a template $t$ from the current population $P = O \cup G$ (initially $G = \emptyset$) and a mutation $m$ from the set of all mutations $M$ to generate a new mutant $m(t)$.
Next, the effectiveness of this new template $m(t)$ is evaluated by attacking the target model $T$ using $Q$, i.e., $m(t)$ is combined with questions $q_i \in Q$ to formulate attack prompts $A_{m(t)} = \{ a_{q_1}, a_{q_2}, \dots, a_{q_{|Q|}} \}$, which are queried to $T$ to get a set of responses $R_{m(t)} = \{ r_{q_1}, r_{q_2}, \dots, r_{q_{|Q|}} \}$.
Each response $r_{q_i}$ from $T$ is sent to a judge model to evaluate whether or not $r_{q_i}$ represents a successful jailbreak for question $q_i$, to get the subset of successful jailbreak responses $R_{m(t)}^{success} \subseteq R_{m(t)}$.
If $m(t)$ jailbreaks at least one question (i.e., $R_{m(t)}^{success} \neq \emptyset$), then $m(t)$ is added to $G$, or else, $m(t)$ is discarded.
Fuzzing iterations end when a stopping criteria, such as all questions got jailbroken or the target model query budget, is reached.

\subsection{Functional Upgrades}
\label{sec:functional}
\bedrockfuzz implements two groups of functional upgrades over GPTFuzzer: i) new mutations, and ii) new selection policies to improve the mutant space explored during the search.

\subsubsection{New Mutations}
\label{sec:mutations}
In addition to the 5 mutations from GPTFuzzer~\cite{yu2023gptfuzzer}, we added 2 syntactic and 3 LLM-based new mutations to \bedrockfuzz. 
 
\begin{itemize}
    \item \textit{Refusal Suppression}. This is a static mutation, inspired from~\cite{wei2024jailbroken}, that instructs the model to respond under constraints that rule out common refusal responses, thus making unsafe responses more likely. Figure~\ref{fig:refusal} in Appendix~\ref{app:mutations} details the mutant template generated on applying refusal suppression mutation to a given template.
    
    \item \textit{Inject Prefix}. This is a static mutation, inspired from~\cite{wei2024jailbroken,jiang2024chatbug}, that appends the fixed string ``Sure, here is'' to a given template. This can make the model to heavily penalize refusing and continue answering the unsafe prompt with a jailbreaking response.
    
    \item \textit{Expand After}. This is a LLM-based mutation, inspired from the \textit{Expand} mutation from GPTFuzzer~\cite{yu2023gptfuzzer}, designed to append the new content at the end of the given template (instead of adding new content to the beginning as in \textit{Expand}).

    \item \textit{Transfer Mutation}. This is a LLM-based mutation that transforms a given template $y$ using another template-mutant pair $\left( x, m^*(x) \right)$ as an example, instructing the LLM to infer the (compounded) mutation $m^*$ and return $m^*(y)$. The example mutant $m^*(x)$ is selected randomly from among the top 10 jailbreaking mutants generated so far during fuzzing and $x$ is its corresponding root parent template, i.e., $x \in O$ and $m^*(x) = m_k(\dots m_2(m_1(x))\dots)$. The key idea here is to apply in-context learning to transfer the series of mutations $m_1, m_2, \dots, m_k$ applied to an original template $x$ to derive one of the top ranking mutants $m^*(x)$ identified so far to the given template $y$ in a single fuzzing iteration. Figure~\ref{fig:transfer_mutation} in Appendix~\ref{app:mutations} details the prompt used to apply this mutation to a given template.
    
    \item \textit{Few Shots}. This is a LLM-based mutation that transforms a given template $y$ using a fixed set of mutants $[g_1, g_2, \dots, g_k]$ as in-context examples. These few-shot examples are selected as the top 3 jailbreaking mutants generated so far from the same sub tree as $y$ (i.e., $root(y) = root(g_i)$ for 1 $\leq$ $i$ $\leq$ $k$). The key idea here is to apply few-shot in-context learning to transfer to the given template $y$ a hybrid combination of top ranking mutants identified so far and originating from the same original template as $y$. Figure~\ref{fig:few_shots} in Appendix~\ref{app:mutations} details the prompt used to apply this mutation to a given template.
\end{itemize}

\subsubsection{New Selection Policies}
\label{sec:selection}
\bedrockfuzz introduces new template and mutation selection policies based on reinforcement learning to learn from previous fuzzing iterations which template or mutation could work better than the others in a given fuzzing iteration.

\begin{itemize}
    \item \textit{Mutation selection using Q-learning}.
    \bedrockfuzz utilizes a Q-learning based technique to learn over time which mutation works the best for a given template $t$.
    \bedrockfuzz maintains a Q-table $\mathcal{Q} : \mathit{S} \times \mathit{A} \rightarrow \mathbb{R}$ where $\mathit{S}$ represents the current state of the environment and $\mathit{A}$ represents the possible actions to take at a given state.
    Given a template $t$ selected in a fuzzing iteration, \bedrockfuzz tracks the original root parent $root(t) \in O$ corresponding to $t$ and uses it as the state for Q-learning. The set of possible mutations $M$ are used as the actions set $\mathit{A}$ for any given state. The selected mutation $m$ is rewarded based on the attack success rate of the mutant $m(t)$. Algorithm~\ref{alg:mutation_selection_ql} in Appendix~\ref{app:mutation_selection} provides the pseudo code of Q-learning based mutation selection.
    
    \item \textit{Template selection using multi-arm bandits}. This template selection method is basically the same as Q-learning based mutation selection, except that there is no environment state that is tracked, making it similar to a multi-arm bandits selection~\cite{slivkins2019introduction}.
    Algorithm~\ref{alg:template_selection_ql} in Appendix~\ref{app:template_selection} provides the pseudo code in detail.
    \end{itemize}

\subsection{Efficiency Upgrades}
\label{sec:efficiency}
\bedrockfuzz implements two efficiency-focused upgrades with the objective of jailbreaking more harmful questions with fewer queries to the target model.


\subsubsection{Early-exit Fruitless Templates}
\label{sec:early_exit}
Given a mutant $m(t)$ generated in a fuzzing iteration, \bedrockfuzz exits the fuzzing iteration early before all questions $Q$ are combined with $m(t)$ if $m(t)$ is determined as fruitless. To determine whether or not $m(t)$ is fruitless without making $|Q|$ queries to the target model, \bedrockfuzz utilizes a simple heuristic that iterates over $Q$ in a random order and if any 10\% of the corresponding attack prompts serially evaluated do not result in a jailbreak, $m(t)$ is classified as fruitless. In such a scenario, the remaining questions are skipped, i.e., not combined with $m(t)$ into attack prompts, and the fuzzing iteration is terminated prematurely.

Using such a heuristic significantly reducing the number of queries sent to the target model that are likely futile. However, this leaves the possibility that a mutant $m(t)$ is never combined with a question $q_k \in Q$, even though it might result in a jailbreak. To avoid such a case, we added a new identity/noop mutation such that $m_{identity}(t) = t$. Thus, even if a mutant $m(t)$ is determined as fruitless in a fuzzing iteration $k$, questions skipped in iteration $k$ can still be combined with $m(t)$ in a possible future iteration $l$ ($l > k$) that applies identity mutation on $m(t)$.

\subsubsection{Warmup Stage}
\label{sec:warmup}
\bedrockfuzz adds an initial warmup stage that uses original templates $O$ directly to attack the target model, before beginning the fuzzing stage. The benefits of warmup stage are two-fold: i) it identifies questions that can be jailbroken with original templates directly, and ii) it warms up the Q-table for mutation/template selectors (\S\ref{sec:selection}). Note that the early-exit fruitless templates heuristic (\S\ref{sec:early_exit}) ensures that only a limited number of queries are spent in the warmup stage if the original templates as is are ineffective/fruitless. 







