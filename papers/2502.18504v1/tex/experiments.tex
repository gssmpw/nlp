\section{Experiments}
\label{sec:experiments}
We conducted a detailed experimental evaluation to answer the following research questions:
\begin{shaded1}
\begin{enumerate}[leftmargin=0pt, topsep=0pt,itemsep=1pt]
    \item[] \textit{RQ1}: Does \bedrockfuzz outperform GPTFuzzer in terms of attack performance?
    \item[] \textit{RQ2}: How does \bedrockfuzz compare against other jailbreaking methods in terms of attack success rate?
    \item[] \textit{RQ3}: How generalizable are templates generated with \bedrockfuzz when applied to unseen harmful questions?
    \item[] \textit{RQ4}: Which upgrades significantly influence the attack performance of \bedrockfuzz?
\end{enumerate}
\end{shaded1}

Additionally, \S\ref{sec:defense} presents how to improve in-built defenses by performing supervised adversarial training using red-teaming data generated with \bedrockfuzz.

\subsection{Implementation}
\label{sec:implement}
We implemented \bedrockfuzz in $\sim$3K lines of code in Python. We utilize Mistral Large 2 (24.07) as the mutator model to power LLM-based mutations. For all experiments, we utilize the fine-tuned Llama 2 13B model introduced in HarmBench~\cite{mazeika2024harmbench} as the judge model to classify whether or not the target model response adequately answers the question meanwhile harmful.
Appendix~\ref{app:implement} provides additional implementation details, including values used for key hyperparameters.

For a fair comparison against GPTFuzzer, we utilize the same mutator and judge model, and implemented all engineering upgrades (Appendix~\ref{sec:engineering}) in GPTFuzzer as well.

\subsection{Setup}
\label{sec:setup}

\begin{table*}[tp]
\resizebox{\linewidth}{!}{%
\centering
\small
\begin{tabular}{l|rrrrrrrrrrrrrrrr|r}\toprule
\multirow{2}{*}{Model} &\multicolumn{16}{c|}{Baseline} &\multirow{2}{*}{Ours} \\\cmidrule{2-17}
&GCG &GCG-M &GCG-T &PEZ &GBDA &UAT &AP &SFS &ZS &PAIR &TAP &TAP-T &AutoDAN &PAP-top5 &Human &DR \\\midrule
Zephyr 7B &90.5 &82.7 &78.6 &79.6 &80.0 &82.5 &79.5 &77.0 &79.3 &70.0 &83.0 &88.4 &97.5 &31.1 &83.4 &83.0 &\textbf{100.0} \\
R2D2 &0.0 &0.5 &0.0 &0.1 &0.0 &0.0 &0.0 &47.0 &1.6 &57.5 &76.5 &66.8 &10.5 &20.7 &5.2 &1.0 &\textbf{99.5} \\ \midrule
GPT-3.5 Turbo 1106 &- &- &55.8 &- &- &- &- &- &32.7 &41.0 &46.7 &60.3 &- &12.3 &2.7 &35.0 &\textbf{100.0} \\
GPT-4 0613 &- &- &14.0 &- &- &- &- &- &11.1 &38.5 &43.7 &66.8 &- &10.8 &3.9 &10.0 &\textbf{80.0} \\
GPT-4 Turbo 1106 &- &- &21.0 &- &- &- &- &- &10.2 &39.0 &41.7 &81.9 &- &11.1 &1.5 &7.0 &\textbf{97.0} \\
\bottomrule
\end{tabular}
}
\caption{Comparison of attack success rates of \bedrockfuzz (column ``Ours'') versus different baselines from~\cite{mazeika2024harmbench} on 200 harmful behaviors from HarmBench~\cite{mazeika2024harmbench} text standard dataset. A target model query budget of 4,000 is used for \bedrockfuzz.}
\label{tab:rq2}
\end{table*}

\noindent \paragraph{\textbf{Datasets}.} We utilize all 200 harmful questions from HarmBench~\cite{mazeika2024harmbench} text standard dataset for evaluating \textit{RQ1}, \textit{RQ2}, and \textit{RQ4}. For \textit{RQ3}, we use all 100 harmful questions from JailBreakBench~\cite{chao2024jailbreakbench} to evaluate generalizability to new unseen questions.

\noindent \paragraph{\textbf{Metrics}.} We compute the attack success rate (ASR) as detailed in HarmBench~\cite{mazeika2024harmbench}, and use it as the primary metric, that indicates the percentage of questions jailbroken.
With a substantial query budget, a higher ASR translates to more difficult harmful questions were jailbroken.
For \textit{RQ2}, we use Top-1 and Top-5 Template ASR, as defined in~\cite{yu2023gptfuzzer} as additional metrics. For \textit{RQ1} and \textit{RQ4}, we use the average queries per jailbreak (computed as total queries to the target model / number of questions jailbroken) and number of jailbreaking templates (i.e., count of templates that broke at least one question) as additional metrics to compare attack performance.

\noindent \paragraph{\textbf{Target Models}.} For \textit{RQ1}, \textit{RQ3}, \& \textit{RQ4}, we present the evaluation with GPT models from OpenAI and Gemma models from Google, as target models. For \textit{RQ2}, we use a subset of target models compared in~\cite{mazeika2024harmbench}, including Zephyr 7B from HuggingFace, and R2D2 model from~\cite{mazeika2024harmbench} that is adversarially trained against the GCG~\cite{zou2023universal} attack.\footnote{While we conducted experiments with many more models from different LLM providers, the results are omitted from this paper due to business constraints and because they added no additional insights. Importantly, all key takeaways remain the same and extend analogously to leading LLMs beyond this representative set.}


\begin{table*}[tp]
\centering
\small
\begin{tabular}{l|rrrr|rr}\toprule
\multirow{2}{*}{Metric (\%)} &\multicolumn{6}{c}{Model} \\\cmidrule{2-7}
&GPT-4o &GPT-4o Mini &GPT-4 Turbo &GPT-3.5 Turbo &Gemma 7B &Gemma 2B \\\midrule
ASR &97 &95 &99 &100 &100 &99 \\\midrule
Top-1 Template ASR &69 &76 &82 &91 &75 &84 \\
Top-5 Template ASR &92 &93 &98 &100 &98 &99 \\
\bottomrule
\end{tabular}
\caption{Templates learnt with \bedrockfuzz in \textit{RQ1} (Table~\ref{tab:rq1}) evaluated on 100 new unseen harmful questions from JailBreakBench~\cite{chao2024jailbreakbench}. The learned templates generalize and achieve $\geq 95\%$ ASR.}
\label{tab:rq3}
\end{table*}

\subsection{Evaluation}
\label{sec:eval}

\subsubsection*{\textit{RQ1}: Does \bedrockfuzz outperform GPTFuzzer in terms of attack performance?}
Table~\ref{tab:rq1} summarizes the comparison of \bedrockfuzz versus GPTFuzzer on HarmBench text standard dataset, with a target model query budget of 4,000 (4000 queries / 200 questions = 20 queries per question on average). Overall, \bedrockfuzz shows 2-3x better attack performance on all evaluation metrics. Functional and efficiency upgrades added exclusively to \bedrockfuzz (\S\ref{sec:functional} \&~\S\ref{sec:efficiency}) results in \bedrockfuzz achieving near-perfect attack success rates (98-100\%), while requiring fewer queries (average 3.15x better) and producing more jailbreaking templates (average 2.69x better).

Additionally, Table~\ref{tab:rq1} also indicates how different target models compare based on native defenses against jailbreaking attacks. GPT-4o showed the best performance, reaching a relatively lower ASR while consistently requiring many more queries per jailbreak on an average. As shown in~\cite{huang2024trustllm}, a larger model does not always mean better defenses against jailbreaking attacks, as evident from comparing Gemma 7B versus Gemma 2B.

\subsubsection*{\textit{RQ2}: How does \bedrockfuzz compare against other jailbreaking methods in terms of attack success rate?}

Table~\ref{tab:rq2} summarizes attack success rates of \bedrockfuzz against a variety of white- and black-box jailbreaking methods taken from~\cite{mazeika2024harmbench}. \bedrockfuzz consistently outperformed these baselines, reaching near-perfect attack success rates for Zephyr 7B, R2D2, and GPT-3.5 Turbo (1106) models. For GPT-4 (0613) and GPT-4 Turbo (1106), \bedrockfuzz required more than 4,000 queries to reach a 100\% ASR, requiring $\sim$8K queries for GPT-4 (0613) and $\sim$5K queries for GPT-4 Turbo (1106).

\subsubsection*{\textit{RQ3}: How generalizable are templates generated with \bedrockfuzz when applied to unseen harmful questions?}
Table~\ref{tab:rq3} summarizes how effective are templates learnt with \bedrockfuzz in \textit{RQ1} (Table~\ref{tab:rq1}) when evaluated as is (i.e., without any fuzzing) on all 100 unseen harmful questions from JailBreakBench~\cite{chao2024jailbreakbench} dataset. Overall, these templates showed impressive generalizability to unseen questions, reaching $\geq 95\%$ ASR consistently for each target model. The top-1 template individually achieved $69-91\%$ ASR, while the top-5 templates collectively were able to jailbreak $\geq 92\%$ unseen harmful questions.


\subsubsection*{\textit{RQ4}: Which upgrades significantly influence the attack performance of \bedrockfuzz?}

\begin{table*}[bp]
\resizebox{\linewidth}{!}{%
\centering
\small
\begin{tabular}{c|l|r|r|r}\toprule
Group &Configuration &ASR (\%) &Average Queries Per Jailbreak &Number of Jailbreaking Templates \\\midrule
G0 &\bedrockfuzz &98 &\textbf{20.31} &38 \\ \midrule
\multirow{6}{*}{G1} &a. $(-)$ Refusal Suppression &69 &28.78 &18 \\
& b. $(-)$ Inject Prefix &83 &24.17 &23 \\
& c. $(-)$ Expand After &95 &21.05 &38 \\
& d. $(-)$ Transfer Mutation &61 &32.78 &17 \\
& e. $(-)$ Few Shots &93 &21.50 &35 \\
& f. No New Mutations &54 &37.06 &17 \\ \midrule
\multirow{3}{*}{G2} &a. $(-)$ Template Selection with MAB (MCTS instead) &72 &27.59 &14 \\
& b. $(-)$ Mutation Selection with Q-learning (random instead) &75 &26.49 &22 \\
& c. No New Selection Policies &76 &26.14 &20 \\ \midrule
\multirow{3}{*}{G3} &a. $(-)$ Early Exit &31 &65.59 &5 \\
& b. $(-)$ Warmup &93 &21.39 &43 \\
& c. No Efficiency Upgrades &42 &47.89 &7 \\ \midrule
\multirow{2}{*}{G4} &GPTFuzzer (no new mutations, no new selection policies, & & & \\& no efficiency upgrades) &28 &73.32 &8 \\ \midrule
\multirow{2}{*}{G5} &a. \bedrockfuzz with 5X query budget (20,000 queries) &\textbf{100} &29.31 &\textbf{50} \\
&b. GPTFuzzer with 5X query budget (20,000 queries) &69 &143.95 &22 \\
\bottomrule
\end{tabular}
}
\caption{
Ablation studies using GPT-4o as the target model on 200 harmful behaviors from HarmBench~\cite{mazeika2024harmbench} text standard dataset. Group G1 shows the effect of excluding new mutations (\S\ref{sec:mutations}), G2 compares the effect of excluding new selection policies (\S\ref{sec:selection}), G3 summarizes the effect of excluding efficiency upgrades (\S\ref{sec:efficiency}), G4 summarizes excluding both functional and efficiency upgrades (\S\ref{sec:functional}, \S\ref{sec:efficiency}), and G5 shows the effect of increasing the target model query budget.}
\label{tab:rq4}
\end{table*}
Table~\ref{tab:rq4} summarizes ablation studies we conducted using GPT-4o as the target model to understand the influence of each upgrade we added in \bedrockfuzz (groups G1 to G4) as well as the effect of increasing the target model query budget (G5). Key observations include:
\begin{itemize}
    \item Among new mutations (\S\ref{sec:mutations}), refusal suppression and transfer mutation significantly impact the attack performance, while expand after and few shots only influence marginally (G1.a-e vs G0).
    \item New selection policies (\S\ref{sec:selection}) show a relatively lower influence compared to new mutations (G2.c vs G1.f) or efficiency upgrades (G2.c vs G3.c).
    \item The early-exit fruitless templates heuristic (\S\ref{sec:early_exit}) impacts the attack performance of \bedrockfuzz the most (G3.a vs G0). On the other hand, warmup stage (\S\ref{sec:warmup}) only marginally impacts the attack performance (G3.b vs G0).
    \item Increasing the query budget helps both \bedrockfuzz and GPTFuzzer to achieve better ASR at the cost of increasing the average queries required per jailbreak (G5.a-b vs G0/G4).
\end{itemize}
