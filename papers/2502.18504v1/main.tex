\pdfoutput=1

\documentclass[11pt]{article}




\usepackage[preprint]{acl}

\usepackage{times}
\usepackage{latexsym}

\usepackage[T1]{fontenc}

\usepackage[utf8]{inputenc}

\usepackage{microtype}

\usepackage{inconsolata}

\usepackage{graphicx}
\graphicspath{{./figs/}{./}}

\usepackage{amsfonts}
\usepackage{multirow} 
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{amsmath}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{xspace}
\usepackage{stfloats}
\usepackage{xcolor} %
\usepackage{mdframed}
\newmdenv[
backgroundcolor=hlcolor,
topline=false,
bottomline=false,
leftline=false,
rightline=false,
]{shaded}


\newcommand{\qnote}[1]{[\textcolor{blue}{Q-note: #1}]}




\definecolor{color1}{HTML}{f3f3f3}
\definecolor{color2}{HTML}{000000}
\newmdenv[
backgroundcolor=color1,
fontcolor=color2,
topline=true,
bottomline=true,
leftline=true,
rightline=true,
]{shaded1}

\newcommand{\oldalglinenumber}{}%
\NewDocumentCommand{\NoLNElse}{ m }{%
  \RenewCommandCopy{\oldalglinenumber}{\alglinenumber}%
  \RenewDocumentCommand{\alglinenumber}{ m }{}%
  \Else #1%
  \addtocounter{ALG@line}{-1}%
  \RenewCommandCopy{\alglinenumber}{\oldalglinenumber}%
}
\NewDocumentCommand{\NoLNState}{}{%
  \RenewCommandCopy{\oldalglinenumber}{\alglinenumber}%
  \RenewDocumentCommand{\alglinenumber}{ m }{}%
  \State%
  \addtocounter{ALG@line}{-1}%
  \RenewCommandCopy{\alglinenumber}{\oldalglinenumber}%
}

\newcommand{\todo}{\textcolor{red}{TODO}}
\newcommand{\aman}[1]{\textcolor{orange}{Aman: #1}}



\newcommand{\bedrockfuzz}{{\sc TurboFuzzLLM}\xspace}





















\title{\bedrockfuzz: Turbocharging Mutation-based Fuzzing for Effectively Jailbreaking Large Language Models in Practice}


\author{Aman Goel$^*$, Xian Carrie Wu, Zhe Wang, Dmitriy Bespalov, Yanjun Qi$^*$  \\
  Amazon Web Services, USA \\
  \texttt{\{goelaman, xianwwu, zhebeta, dbespal, yanjunqi\}@amazon.com} \\}


\begin{document}
\maketitle
\begingroup\def\thefootnote{*}\footnotetext{Corresponding authors}\endgroup
\begin{abstract}
Jailbreaking large-language models (LLMs) involves testing their robustness against adversarial prompts and evaluating their ability to withstand prompt attacks that could elicit unauthorized or malicious responses. In this paper, we present \bedrockfuzz, a mutation-based fuzzing technique for efficiently finding a collection of effective jailbreaking templates that, when combined with harmful questions, can lead a target LLM to produce harmful responses through black-box access via user prompts. We describe the limitations of directly applying existing template-based attacking techniques in practice, and present functional and efficiency-focused upgrades we added to mutation-based fuzzing to generate effective jailbreaking templates automatically. \bedrockfuzz achieves $\geq$ 95\% attack success rates (ASR) on public datasets for leading LLMs (including GPT-4o \& GPT-4 Turbo), shows impressive generalizability to unseen harmful questions, and helps in improving model defenses to prompt attacks.\footnote{\textcolor{red}{Warning: This paper contains techniques to generate unfiltered content by LLMs that may be offensive to readers.}}
\end{abstract}

\input{tex/introduction}
\input{tex/bedrockfuzz}
\input{tex/experiments}
\input{tex/mitigation}
\input{tex/conclusion}
\input{tex/acknowledgements}
\input{tex/ethics}


\bibliography{main}

\vspace*{\fill} \pagebreak
\appendix
\input{tex/appendices}

\end{document}
