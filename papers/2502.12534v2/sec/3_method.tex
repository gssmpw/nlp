\section{Method}
\label{sec:formatting}
The overview of our method is illustrated in~\Cref{fig:overview}. 
Given a point cloud $\points {\in} \real^{N\times 3}$ of N points in 3-dimensional space, we compute hierarchical point features $\features$ with $S$ levels using a point-based transformer $\backbone$ parameterized via $\param_{\backbone}$ as
\begin{align}
\{(\points_s, \features_s)\}^{S}_{s=1} = \backbone(\points; \param_{\backbone})
\end{align}
where with the $s$ subscript we denote the point cloud and learned features at $s$-th level.  
For a given query $\query \in \real^{3}$, we employ the features from the feature hierarchy to predict its distance field value $\distance$:
\begin{align}
\distance = \distancefield(\query ~|~ \{(\points_s, \features_s )\} ; \param_\distancefield)
\end{align}
where $\distancefield$ has learnable parameters~$\param_{\distancefield}$.

\subsection{Distance field\texorpdfstring{ -- $\distancefield$}{}}
For each query $\query$, we calculate a per-level feature from the feature hierarchy through an \textit{aggregation} module $\aggregation$, and then sum the features of all levels as the query's feature, which is then mapped to an SDF value by $\mlp$:
\begin{align}
\distancefield(\query) = \mlp\left(\sum_{s=1}^{S} \aggregation\left(\query| \points_s, \features_s\right) \right)
\end{align}
Following~\citet{huang2023neural}, $\mlp$ is simply an MLP with a single hidden layer followed by a \textit{tanh} activation, and its parameters are included in the set~$\param_\distancefield$. 
We now describe the aggregation module $\aggregation$ in more details.

\subsection{Aggregation module -- \texorpdfstring{$\aggregation$}{}}
\label{sec:aggregation}
At the $s$-th level, we retrieve the local neighborhood at the query location and use a PointNet-style network to map the local point cloud into the per-level feature:
\begin{align}    
\aggregation(\query | \points_s, \features_s) = 
\frac{
\sum_{\point \in \neighbor(\query | \points_s)} w(\point, \query) \cdot \pointnet(\point - \query, \feature_\point)  
}{
\epsilon + \sum_{\point \in \neighbor(\query | \points_s)} w(\point, \query) 
}
\end{align}
where  $w(\point, \query)$ is the inverse spatial distance, 
$\epsilon{=}1e{-}8$ avoids division by zero, $\pointnet$ is a small MLP whose parameters are included in the set $\param_\distancefield$, $\feature_\point$ is the feature in $\features$ at $\point$, $\neighbor(\query | \point)$ is a function that retrieves the local neighborhood of $\query$ from $\points_s$. 

\input{figs/neighborhood/item}

\subsubsection{Neighborhood function \texorpdfstring{ -- $\neighbor$}{}}
\label{sec:neighbor_func}
Retrieving neighbors via k-nearest neighbor (KNN) or ball-query methods would be optimal, but these are difficult to implement efficiently on GPU hardware.
As the reconstruction pipeline is sensitive to the computational cost of this operation, we choose to leverage a more efficient strategy.
In particular, we implement our approximate neighborhood lookup $\neighbor$ on the locality-preserving \textit{serialization} encoding proposed by~\cite{wang2023octformer, wu2024point}. 
A serialization encoding is a hash function ($\gamma: \real^3 \hookrightarrow \mathbb{Z} $) that maps a point to a integer.
Given a point $point \in \real^{3}$, we calculate the integer as 
\begin{align} 
\gamma = \phi(\lfloor{ p/g }\rfloor))
\end{align}
where $\lfloor{ p/g }\rfloor$ is a floor function that quantizes a point with real-valued coordinates to the integral coordinates of cells in a 3-dimensional grid with size $g$, and $\phi$ is a bijective function that maps 3D coordinates $\mathbb{Z}^3$ to 1D values $\mathbb{Z}$. 
We define the bijective $\phi$ as a space filling curve, which traverses 3D space in a \textit{locality-preserving} order. 
We utilize Hilbert curves~\cite{hilbert1935stetige}, and to avoid collisions in the quantization of point coordinates to grid cells, we use a very fine grid resolution across all levels, as there is no cost associated with increasing the resolution of this \textit{virtual} grid.
As illustrated in \Cref{fig:neighbor_func}, to retrieve the local neighborhood of a query from a point cloud, we first encode the point cloud into a set of sorted integers using $\gamma$.
We then apply $\gamma$ to the query coordinate and search through its neighbors on the 1D line to identify close-by points in Euclidean space.

\subsection{Training}
To train our networks, we optimize the loss:
\begin{align}    
\argmin_{\param_\backbone, \param_\distancefield, \param_{\mathcal{C}}}  \:\: \lambda_{\text{SDF}} \loss{SDF} + \lambda_{\text{Eikonal}} \loss{Eikonal} + \lambda_{\text{mask}} \loss{mask}
\end{align}
where $\lambda_{\text{SDF}}$ , $\lambda_{\text{eikonal}}$ and $\lambda_{\text{mask}}$ are the coefficients for loss terms, which we will detail below. 

\paragraph{Signed distance function supervision -- $\loss{SDF}$}
We define $\loss{SDF}$ to reproduce the ground truth SDF value $\distance_q$ at $\query$:
\begin{align*}
\loss{SDF} = \expect_{\query\sim\mathcal{Q}} 
\:
[|| \distance_\query - \distancefield(\query) ||_1]    
\end{align*}
where $\mathcal{Q}$ is the distribution from~\citet{huang2023neural}.

\paragraph{Surface regularizer -- $\loss{Eikonal}$}
We regularize the field $\distancefield$ with an Eikonal loss to encourage this function to be a signed distance field away from the surface: 
\begin{align}
    \loss{Eikonal} = \expect_{\x \sim \mathcal{Q}} [(||\nabla_\x \distancefield(\x)\|_2 - 1)^2 ]
\end{align}

\paragraph{Auxiliary loss -- $\loss{mask}$}  
\at{Following~\cite{huang2023neural}, the classification branch $\mathcal{C}$ with learnable parameters $\param_{\mathcal{C}}$ classifies queries as near/far from the surface as supervised by the loss:}
\begin{align*}
\loss{mask} = \expect_{\query\sim\mathcal{Q}} [\textbf{CE}(\mathbf{c}_\query, \mathcal{C}(\query)
)] 
\end{align*}
where \textbf{CE} is the cross entropy function, $\mathbf{c}_\query$ is ground-truth binary label calculated by thresholding the ground-truth SDF with empirically chosen values of 0.015 meters for indoor scenes, and 0.1 meters for outdoor.
\at{At inference time, the output of this classifier helps avoid reconstructing surfaces that are far from the input point cloud~(i.e. not supported by input point-cloud data).}

