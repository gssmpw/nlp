\begin{table*}
\centering
\resizebox{\linewidth}{!}{
\setlength{\tabcolsep}{3pt}
\begin{tabular}{LccccccccccccC}
\toprule
Methods & & \multicolumn{3}{c}{\ws{{\bf \synthetic}}}  &  \multicolumn{3}{c}{{\bf \scannet}} & \multicolumn{3}{c}{\ws{{\bf \carla(Original)}}} & \multicolumn{3}{c}{\ws{{\bf \carla(Novel)}}} \\ 
 \cmidrule(lr){3-5} \cmidrule(lr){6-8} \cmidrule(lr){9-11} \cmidrule(lr){12-14} 
&Primitive& CD ($10^{-2}$) $\downarrow$ & F-Score  $\uparrow$ & Latency (s) $\downarrow$  & CD ($10^{-2}$) $\downarrow$ & F-Score  $\uparrow$ & Latency (s) $\downarrow$  & CD (cm) $\downarrow$ & F-Score  $\uparrow$ & Latency (s) $\downarrow$ & CD (cm) $\downarrow$ & F-Score  $\uparrow$ & Latency (s) $\downarrow$ \\        
\midrule
SA-CONet~\cite{tang2021SACon} & Voxels & {0.496} & {93.60} & - & - & - & - & - & - & - & - & - & -\\
ConvOcc~\cite{peng2020convoccnet} & Voxels & {0.420} & {96.40} & - & - & - & - & - & - & - & - & - & -\\
NDF~\cite{chibane2020ndf} & Voxels & {0.408} & {95.20} & - & 0.385  & 96.40  & -  & - & - & - & - & - & -\\
RangeUDF~\cite{wang2022rangeudf} & Voxels & {0.348} & {97.80} & {-} & 0.286 & 98.80 & - & - & - & - & - & - & -\\
\ws{TSDF-Fusion~\cite{zeng20163dmatch}} & -  & - & - & - & - & - & - & 8.1 & 80.2 & - & 7.6 & 80.7 & - \\
\ws{POCO~\cite{boulch2022poco}} & - & - & - & - & - & - & - & 7.0 & 90.1 & - & 12.0 & 92.4 & - \\
\ws{SPSR~\cite{kazhdan2013screened}} & - & - & - & - & - & - & - & 13.3 & 86.5 & - & 11.3 & 88.3 & - \\
\nksr & Voxels &  \underline{0.346} &  \underline{97.41} & \underline{0.40} & \underline{0.246} & \underline{99.51} & \underline{1.54} &  \underline{3.9} &  \underline{93.9} &  \underline{2.0} &  \underline{2.9} &  \underline{96.0} &  \underline{1.8} \\
\nksr (more data) & Voxels & - & - & - & - & - & - & {3.6} & {94.0} & {2.0} & {3.0} & {96.0} & {1.8}\\
Ours~(Minkowski)~\cite{choy20194d} \scriptsize{(w/ KNN)} & Voxels & - & \todo{} & \todo{} & 0.254 & 99.41 & 0.46 & 3.4 & 97.2 &1.9 & 2.7 & 98.1 & 2.0 \\
Ours~(Minkowski)~\cite{choy20194d} & Voxels & - & \todo{} & \todo{} & 0.301 & 98.48 & 0.31 & 3.8 & 96.2 & 1.5 & 3.0 & 97.4 & 1.5\\
\rowcolor{1st} Ours \scriptsize{(w/ KNN)} & Points &{0.321} & {98.34} & {0.13} & {0.243} & {99.61} & {0.48} &{3.2} & {97.5} & {3.2} &{2.6} & {98.3} & {3.4}\\
\rowcolor{1st}Ours & Points & {0.360} & {96.32} & 0.14 & 0.257 & 99.33 & 0.49 & {3.3} & {97.4} & 1.7 & {2.7} & {98.2} & 1.7 \\

\bottomrule
\end{tabular}
}
\caption{\textbf{In-domain evaluation} -- We show that our method achieves the best accuracy (CD and F-score) with significantly improved time efficiency~(inference latency).
Note we retrain \nksr (numbers are underlined) for fairer comparison, \ws{as the training data for \nksr is different from ours -- i.e., they reported some models trained on a ``mix'' of datasets, which is impossible to reproduce.
}
}
\label{tab:indomain}
\end{table*}
