\begin{table}
\centering
\resizebox{.8\columnwidth}{!}{
\begin{tabular}{@{}lcccc@{}}
\toprule
\bf Fusion method & CD (10\textsuperscript{-2}) $\downarrow$ & F-score $\uparrow$ & Latency (s) $\downarrow$ \\ \midrule
\rowcolor{1st}Sum & 0.257 & 99.33 & 152 \\
Average & 0.257 & 99.33 & 151 \\
Concatenation & 0.256 & 99.37 & 151 \\
Learnable Gate & 0.257 & 99.33 & 152 \\
Attentive Pooling & 0.255 & 99.36 & 156 \\
\bottomrule
\end{tabular}
}
\caption{
{\bf Scales fusion} -- we investigate different ways to fuse per-scale features. Attentive pooling achieves marginal improvement at the cost of noticeable increased latency.}

\label{tab:multi_level_agg}
\end{table}
