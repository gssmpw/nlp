\begin{table}[]
\centering
\resizebox{.95\columnwidth}{!}{
\begin{tabular}{@{}lcccccc@{}}
\toprule
\makecell{\bf Num. of segments\\\bf in training and reconstruction} & CD (10\textsuperscript{-2}) $\downarrow$ & F-score $\uparrow$ & Latency (s) $\downarrow$ & Peak memory (GB) $\downarrow$\\ \midrule
\rowcolor{1st} 1 & 3.3 & 97.4 & 1.7 & 20.4 \\
 10 & 3.4 & 96.7 & 3.0 & 7.1 \\
 50 & 3.4 & 96.6 & 6.2 & 5.0 \\
\bottomrule
\end{tabular}
}
\caption{
{\bf Handling large scenes via partition -- } Simply with serialization codes, we partition a large scene into smaller segmentation to avoid GPU memory. We show that our method reduce the peak memory with a negligible decrease in reconstruction quality.}

\label{tab:segment_supp}
\end{table}
