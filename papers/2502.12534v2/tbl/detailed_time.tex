\begin{table}
\centering
\resizebox{\columnwidth}{!}{
\begin{tabular}{@{}lccccc@{}}
\toprule
\makecell{\bf Methods} & \makecell{Feature \\ Backbone(s)} & Decoder(s) & \makecell{Dual Marching \\ Cube(s)} & Total (s) & CD (10\textsuperscript{-2}) $\downarrow$ \\ \midrule
\nksr & 83 & 313 & 78 & 480 & 0.246\\
\rowcolor{1st}Ours & 10 & 70 & 68 & 152 & 0.243\\
Ours (w/ KNN) & 10 & 72 & 68 & 151 & 0.257\\
Ours (Minkowski) & 6 & 30 & 56 & 97 & 0.301\\
\bottomrule
\end{tabular}
}
\caption{
{\bf Latency distribution.} 
We report the latency distribution during inference steps for the feature backbone $\backbone$, decoder and marching cubes. Our method outperforms the SOTA~\cite{huang2023neural} in all steps, particularly in the decoder step where~\cite{huang2023neural} needs to solve a large differentiable linear system.
}
\label{tab:detailed_time}
\end{table}
