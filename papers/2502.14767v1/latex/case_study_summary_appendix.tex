\section{Qualitative Case Study: TreeInstruct vs. BRIDGE}
\label{appendix:summary}
\begin{table*}[]
    \centering
    \caption{Summaries from two methods: ToD (No Tree) -- the \textsc{Tree-of-Debate} ablation -- and the Two-Stage baseline. The papers being compared are TreeInstruct and BRIDGE: they develop LLM-based instructors that guide students towards the answers to their questions rather than give away the answers. The rest of the table follows in \ref{table: qualitative_study_appendix_part2}.}
    \begin{tabular}{|p{8cm}|p{8cm}|}
        \toprule
        \textbf{Two-Stage} & \textbf{ToD (No Tree)} \\
        \midrule
        Both papers focus on enhancing educational experiences through innovative technological approaches. Both utilize novel methodologies to address specific learning challenges (code debugging for Paper 0 and math remediation for Paper 1). Both papers emphasize the importance of real-world validation and case studies to assess the effectiveness of their proposed solutions. Topic Focus: Paper 0 focuses on code debugging with TreeInstruct, while Paper 1 addresses math mistake remediation with the Bridge method. \textcolor{red}{Methodological Approach: Paper 0 employs state space estimation and dynamic tree-based questioning, whereas Paper 1 utilizes cognitive task analysis and decision-making models.} Evaluation Metrics: Paper 0 measures performance on debugging datasets and student engagement, whereas Paper 1 assesses the preference for LLM responses with expert decisions and conducts lexical analysis. Target Audience: Paper 0's work is geared towards students of varying skill levels in code debugging, whereas Paper 1 focuses on 1st-5th grade students in Title I schools for math tutoring. While both papers contribute to the educational technology landscape, Paper 0's TreeInstruct offers a novel approach to code debugging through adaptive Socratic questioning, and Paper 1's Bridge method innovatively embeds expert thought processes into LLMs for math remediation. \textcolor{red}{Despite overlapping in their pursuit of enhancing educational experiences, the papers diverge significantly in their topics, methodologies, and target audiences, indicating a broad and diverse landscape in educational technology research.} & Papers on adaptive guidance systems debate similarities and differences for effective Socratic questioning. While both papers aim to enhance adaptive guidance, they differ in approach: \textcolor{red}{TreeInstruct (Paper 0) emphasizes adaptive, expert-agnostic planning, leveraging dynamic question trees and state space-based planning to address interdependent errors, whereas Bridge (Paper 1) focuses on expert-informed decision-making, incorporating domain-specific expert knowledge for more effective Socratic questioning.} A key difference lies in their handling of unforeseen errors, with TreeInstruct relying on dynamic adaptation and \textcolor{red}{Bridge on continuous expert annotation and model fine-tuning. }Another distinction is their applicability: \textcolor{red}{TreeInstruct is designed for diverse educational domains}, while Bridge initially focused on math education, later expanding to other domains. Both authors eventually converge on a hybrid approach, combining expert guidance with adaptive planning for a more comprehensive solution. Despite this, their initial differences in methodology and error handling strategies remain a focal point of the debate. The debate highlights the importance of both adaptive planning and expert guidance in effective adaptive guidance systems. Ultimately, the synthesis of both approaches offers a more robust solution for personalizing student learning experiences. \\
\bottomrule
    \end{tabular}
    \label{table: qualitative_study_appendix_part1}
\end{table*}

\begin{table*}[]
    \centering
    \caption{Summaries from two methods: ToD (No SD) -- the \textsc{Tree-of-Debate} ablation -- and \textsc{Tree-of-Debate}. The papers being compared are TreeInstruct and BRIDGE: they develop LLM-based instructors that guide students towards the answers to their questions rather than give away the answers. The rest of the table follows in \ref{table: qualitative_study_appendix_part1}.}
    \begin{tabular}{|p{8cm}|p{8cm}|}
        \toprule
        \textbf{ToD (No SD)} & \textbf{ToD (Final)} \\
        \midrule
        The papers share similarities in their focus on adaptive, student-centered approaches for mistake correction, leveraging AI-driven tools to enhance personalized learning experiences. Both papers emphasize the importance of context-aware feedback and expert guidance in promoting deeper understanding. However, the papers diverge in their novelties. Paper 0's paper, 'Instruct, Not Assist,' uniquely integrates adaptive, multi-turn Socratic questioning with state space estimation, \textcolor{red}{providing a more holistic and adaptable learning experience}. In contrast, Paper 1's paper, 'Bridging the Novice-Expert Gap,' focuses on modular, expert-guided decision-making, offering a more explicit and scalable approach to addressing complex, interdependent mistakes. \textcolor{ForestGreen}{While Paper 0's approach excels in handling ambiguous student responses, Paper 1's method provides more nuanced, human-centric guidance.} The papers also differ in their evaluation metrics, with Paper 0 emphasizing robust state space estimation and Paper 1 highlighting the importance of contextual relevance. Ultimately, \textcolor{red}{the papers present complementary approaches, with Paper 0's work prioritizing adaptability and Paper 1's work emphasizing expert-driven contextualization}. & The papers by Paper 0 and Paper 1 share similarities in their focus on adaptive error resolution strategies, emphasizing the importance of context-sensitive decision-making and expert knowledge in enhancing student learning outcomes. \textcolor{ForestGreen}{Both papers also highlight the limitations of current LLMs in educational settings} and propose novel methodologies to address these challenges. However, the papers diverge in their approaches to achieving these goals. \textcolor{ForestGreen}{Paper 0's paper, 'Instruct, Not Assist,' uniquely integrates dynamic planning and hierarchical questioning to provide a more nuanced understanding of student thought processes}, scaling to accommodate diverse student populations. In contrast, \textcolor{ForestGreen}{Paper 1's paper, 'Bridging the Novice-Expert Gap,' leverages expert decision-making models to inform adaptive error resolution strategies, offering a more domain-agnostic framework}. The papers also differ in their evaluation frameworks, with Paper 0's approach utilizing a state space-based planning algorithm and Paper 1's method incorporating transfer learning and domain-specific expert annotations. Furthermore, \textcolor{ForestGreen}{Paper 0 emphasizes the importance of adaptive Socratic questioning, while Paper 1 highlights the value of expert-guided decision-making in enhancing educational support.} Ultimately, the papers present distinct novelties in addressing the novice-expert gap, with \textcolor{ForestGreen}{Paper 0 focusing on adaptive structured planning and Paper 1 on context-aware expert decision embedding}. \\
\bottomrule
    \end{tabular}
    \label{table: qualitative_study_appendix_part2}
\end{table*}

Tables \ref{table: qualitative_study_appendix_part1} and \ref{table: qualitative_study_appendix_part2} contain comparative summaries from the baseline, ablations, and our final method on the papers, TreeInstruct \cite{kargupta2024instructassistllmbasedmultiturn} and BRIDGE \cite{bridge}--- Papers 0 and 1, respectively. Below, we qualitatively compare each summary, pointing out the weaknesses and strengths, and show how our method is able to address all the issues brought up in the baseline summaries.

The top left contains the Two-Stage baseline. The Two-Stage baseline tends to contain near-copy phrases from the paper, resulting in \textbf{an overly specific, extractive and unnatural summary} (an example is the first line highlighted in red: ``Methodological Approach: Paper 0 employs...''). As a result, the differences that are extracted are not explained very well, requiring more work to understand the terminology-heavy summary. It also makes vague claims near the end of summaries (example is the second line highlighted in red: ``Despite overlapping in their pursuit of enhancing educational experiences...''). \textbf{The overall structure results in a suboptimal summary}.

Next, the top right box contains the summary for ToD (No Tree). The use of the debate format improves the quality of the generated claims. Unlike in the Two-Stage summary, it does not contain many extractive phrases, however \textbf{the structure of the debate is still fine-grained to coarse-grained}. Intuitively, the summaries should develop coarse-grained claims into fine-grained arguments. Moreover, there are \textbf{slight hallucinations} (examples are in the second and third lines highlighted in red: ``Bridge on continuous expert...'' and ``TreeInstruct is designed...''). Still, the conclusion (last sentence) of the summary is not as vague as the conclusion from Two-Stage, but it still does not capture the intricacies of the two methods well enough.

Subsequently, the summary for ToD (No SD) is on the bottom left. The benefits of the tree are drastic, as the summary starts by discussing the high-level summaries, and breaks down the individual fine-grained differences. This is much less extractive and more abstractive. \textbf{Using the tree structure along with the debate allows each argument to be explored further}-- this is evident as after each claim, an explanation of why it matters follows (example is the line highlighted in green: ``While Paper 0's approach excels in...''). Still, a few of these explanations are vague and \textbf{do not reveal the true underlying motivation of the claims} (highlighted in red).

Finally, the summary for ToD (our final method) is in the bottom right box. With the self-deliberation, it was able to extract a short phrase of the motivation behind both works (the ``limitations of current LLMs in educational settings''). The arguments are developed from \textbf{high-level claims to low-level}, technical concepts. The \textbf{facts are correctly identified} and do not contain any hallucinations. Moreover, the explanations preceding the claims also \textbf{reveal the underlying motivation} behind the specific novelty. Finally, the concluding sentence explains the exact difference between the two works.