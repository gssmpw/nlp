\par Navigating and identifying new and relevant research findings has become non-trivial with the popularity of open-access repositories. For example, arXiv received over 24,000 submissions in October 2024 \cite{arxiv_monthly_submissions}, inundating researchers with an overwhelming volume of information. This astronomical surge in scholarly articles makes it difficult to identify novel findings and discern the distinctions between related papers, especially those presenting similar ideas from different angles (e.g., papers from different research communities).

\par Automatically generating comparative summaries of research papers has proven valuable for addressing these challenges \cite{whats_new}. Existing comparative summarization works \cite{Strhle2023} typically follow a two-step pipeline: (1) construct extractive summaries for each document to (2) identify their similarities and differences \cite{lerman2009contrastive,gunel2024strum}. However, despite using large language models (LLMs), these methods often focus on surface-level semantic differences, which may not capture the most relevant distinctions. For example, when comparing pre-trained models like ``BERT'' \cite{devlin-etal-2019-bert} and ``RoBERTa'' \cite{Liu2019RoBERTaAR}, it is crucial to note that RoBERTa omits next-sentence prediction, trains on ten times more data, and achieves superior performance. These insights require complex, comparative reasoning beyond basic semantics, as they rely on understanding BERT's contributions \textit{in the context} of RoBERTa's. Thus, we propose the following principles:

% need for debate
\par{\textbf{Multi-persona debates elicit complex, comparative reasoning.}} We explore the use of multi-agent debates for inducing fine-grained, comparative reasoning. These debates simulate group discussions where agents suggest diverse answers, critique one another, and refine responses to produce better outputs \cite{chan2023chateval, liang2023encouraging}. Recent work has also introduced defining LLM agents as personas with distinct characteristics or values, enabling them to generate outputs that reflect the diverse perspectives needed to solve multi-faceted problems \cite{tseng2024two,wang-etal-2024-unleashing}. Inspired by this, we propose \textit{converting scientific \underline{papers into personas} that debate} each other to foster critical analysis. For instance, while the papers debate their respective contributions to a topic, they critically evaluate each other's novelty and significance \textit{relative to their own claims}.

    \begin{figure}
        \centering
        \includegraphics[width=1.0\linewidth]{example_hierarchy.pdf}
        \caption{A hierarchy of contributions made by Papers $A$ and $B$, specific to the root topic. Green check mark: a single paper makes a unique contribution; red X: an overlapping contribution.}
        \label{fig:hierarchy}
        \vspace{-0.6cm}
    \end{figure}

% need for structured debate
\par{\textbf{Tree-structured debates allow for independent assessments of different contributions at varying depths.}} A scientific paper often makes contributions (e.g., methodology, dataset, evaluation metric) that can be deconstructed into multiple ``sub-ideas.'' Some sub-ideas may or may not be novel (e.g., uses an existing architecture, but proposes novel fine-tuning and evaluation mechanisms) and consequently, should be independently evaluated for their \textit{degree} of novelty. Hence, an unstructured debate combining all ideas is insufficient for handling the complexity of scientific comparative analysis. We instead propose a \textit{tree-structured} debate, where each \textit{node} represents a specific contribution topic being debated, and an \textit{edge} indicates unresolved points or interesting questions from the parent debate node which warrant further exploration in a child node. Figure \ref{fig:hierarchy} illustrates these topical relationships.

\par{\textbf{Iterative retrieval throughout a debate improves fine-grained reasoning.}} Due to their lengthy nature, providing an entire paper in-context is ineffective, as details specific to the debate node topic may be overshadowed \cite{li-etal-2024-loogle}. Conversely, using only the title and abstract results in high-level comparisons based on surface-level semantic differences. To address these long-context challenges, we propose an \textit{iterative retrieval} process, where retrieval queries are dynamically determined by the debate's content. This ensures the retrieved content is targeted to the specific contribution in question, enabling personas to generate more compelling affirmative or opposing arguments. For instance, as the debate progresses from ``reasoning evaluation'' to ``domain-expert evaluation'' in Figure \ref{fig:hierarchy}, the evidence pool is updated to be more fine-grained and relevant to the subtopic.

% multiple contributions -> need for STRUCTURED debate


\par We integrate these proposed principles into \textbf{Tree-of-Debate}, a framework which dynamically structures a debate between paper personas, conducted by a moderator. First, each persona prepares (\textbf{self-deliberation}) by retrieving topic-relevant segments from their paper, identifying their novel contributions, and updating their evidence pool based on the opposition's claimed contributions (Section \ref{sec:self-deliberate}). Based on this, the moderator determines the most valuable subtopics to explore (e.g., second level of Figure \ref{fig:hierarchy}). For each subtopic, a \textbf{child debate node is formed}, where each persona presents their initial arguments, responds to one another (e.g., clarifying questions, doubts), and revises their argument based on the interaction. Based on the debate, the moderator determines if the \textbf{debate node is worth expanding} and exploring deeper into (Section \ref{sec:expansion}). If so, a more fine-grained set of subtopics are determined for the next level of debate children (Section \ref{sec:debate_round_format}). Our contributions can be summarized as: 
\begin{itemize}
    \itemsep-0.1em
    \item We introduce \textbf{Tree-of-Debate}, a structured multi-persona debate framework, to generate fine-grained contrastive summaries.  
    \item Tree-of-Debate can \textbf{dynamically construct a debate tree} to reason about fine-grained arguments discussed in scholarly articles. 
    \item Through experiments on \textbf{real-world scientific literature}, we show that Tree-of-Debates elicits informative arguments and contrasts papers, aiding researchers in their work. 
\end{itemize}

\textbf{Reproducibility:} We provide our dataset and source code\footnote{\url{https://github.com/pkargupta/tree-of-debate}} to facilitate further studies.