\section{Methodology}

\textsc{Tree-of-Debate} aims to determine and compare the fine-grained scientific claims of two papers through a methodology inspired by formal debate. Our overall framework is presented in Figure \ref{fig:tree}.
\subsection{Preliminaries}

\subsubsection{\textbf{Problem Formulation}} 
We assume two papers, $p_1$ and $p_2$, and a topic $n_0$ (e.g., ``inference-time LLM reasoning methods'') are provided as input by the user. Our goal is to determine the specific novelties, incremental additions, and equivalent contributions relevant to $n_0$ between $p_1$ and $p_2$, producing a \textbf{debate tree $T$} with a corresponding \textbf{comparative summary} $S$. In $T$, each node $n_i$ represents a topic (with $n_0$ as the root), where topic $n_i$ guides the specific debate occurring at that node. Topics may pertain to both papers or only one (e.g., in Figure \ref{fig:hierarchy}, only $p_i=B$ includes ``Backtracking''). An edge from $n_i$ to $n^i_j$ indicates that $n_j$ is a subtopic of $n_i$ that merits further exploration.

\subsubsection{\textbf{Segment-level Retrieval}}
\label{sec:retrieval}
An effective debate is contingent on an individual's preparation \textit{before} the debate and their ability to retrieve knowledge dynamically \textit{during} the debate. We employ a retrieval embedding model \cite{bge_embedding} and cosine-similarity to compute and rank segment-level embeddings. We chunk each paper into roughly three-sentence segments such that it is easily comprehensible during the debate.

\subsection{\textsc{Tree-of-Debate} Setup}

\par We conduct a multi-persona debate between two paper personas, $p_1$ and $p_2$, based on the high-level claim, \textit{\underline{$p_1$ is better than the $p_2$ for topic $n_i$}}. Our goal is not to determine a final debate ``winner'' but to capture the \textbf{specific reasoning} \textbf{\textit{induced}} by the debate format, reflected in the progression of arguments and the degree of novelty in each paper’s claims. While we explored novelty-specific claims (e.g., ``$p_1$’s contribution towards $n_i$ is more novel than $p_2$’s''), this led to more surface-level arguments. Moreover, a paper often features a breadth of claims/ideas, motivating a debate structure that is flexible to explore these different angles independently. Thus, we propose a \textbf{\textsc{Tree-of-Debate}} (ToD), $T$, where each node represents a round of debate (Section \ref{sec:debate_round_format}). A directed edge from parent node $n_p$ to child node $n^p_c$ indicates the debate progressing into one of $n_p$'s subtopics $n^p_c$ (out of potentially $k$ subtopics). Leaf nodes indicate no further progression in argumentation is evident.

\subsubsection{Constructing the Personas} We leverage an LLM agent to embody each debate persona, allowing for retrieved information from the papers and the debate history to be easily integrated into its context:
\begin{itemize}[leftmargin=*]
    \item \textbf{Papers:} Each paper persona is given the title, abstract, and retrieved segments relevant to the starting topic $n_0$ (updated at each self-deliberation stage (Section \ref{sec:self-deliberate})). Each paper persona's $p_i$ role is to argue that their contributions towards the topic $n_i$ are better than persona $p_j$'s.
    \item \textbf{Moderator:} Using the same underlying model as the paper personas, the moderator (i) identifies key debate subtopics for determining the papers' similarities and differences, (ii) judges the progression of the debate based on the authors' arguments, and (iii) synthesizes the debate tree into a comparative summary.
\end{itemize}

\subsubsection{\textbf{Tree Node Format}}
\label{sec:debate_round_format}
Each tree node with topic $n_i$ undergoes a three-stage debate (pre-, during, and post-debate). The format is as follows:
\begin{enumerate}[leftmargin=*]
    \item \textbf{Self-Deliberation (\textit{Section \ref{sec:self-deliberate}})}: Each persona $p_a$ retrieves segments $S^a_i$ relevant to $n_i$, generates $k$ claims $C^a_i$ for their novel contributions, cites corresponding evidence $E^a_i \subseteq S^a_i$, and collects counter-evidence from their own paper $\widetilde{E}^a_i$. The moderator then selects $k$ new subtopics for the next level of $k$ children, $n_j^i \in N^i$.
    
    \item \textbf{Debate (Prompts \ref{prompt_persona: present_arguments}, \ref{prompt_persona: respond_to_argument}, and \ref{prompt_persona: revise_argument})}: For each child debate node $n_j^i$, each persona $p_a$ (i) presents an argument that $p_a$ is \underline{better} than $p_b$ on $n_j$, (ii) responds to the opposing argument, and (iii) revises their argument accordingly.
    
    \item \textbf{Determine Expansion \textit{(Section \ref{sec:expansion})}}: Based on the debate at $n_j^i$, the moderator determines whether the arguments progressed or introduced any unresolved questions meriting another round. If so, the moderator triggers self-deliberation for $n_i \rightarrow n^i_j$.
\end{enumerate}

\subsection{Self-Deliberation}
\label{sec:self-deliberate}
\par Self-deliberation is an argumentative strategy \cite{tindale2020self} that enables one to ``argue with oneself'' by considering alternative views, aiming to arrive at the best, most well-justified conclusion. We integrate self-deliberation into our multi-persona debate for a given topic node $n_i$ and paper $p_{a\in\{1,2\}}$:
\begin{enumerate}[leftmargin=*]
    \itemsep=0em
    \item Retrieve relevant segments $S_a^i$ from $p_a$ that are closely related to $n_i$.
    \item Generate $k$ claims $c_j \in C^a_i$ on the \textit{novel contributions} of $p_a$ toward $n_i$. Each claim includes a title, description, and a set of mapped evidence $E^a_{(i, j)}\subseteq S_i^a$ (see Prompt \ref{prompt_persona: generate_arguments}).
    \item Preempt $p_b$'s contributions, where $C^b_i$ is exposed in-context to $p_a$ and $p_a$ retrieves another round of evidence $\widetilde{E}^a_i$ aimed at targeting $p_b$'s claims.
    \item The moderator then uses $E_i$, $\widetilde{E}_i$, and $C_i$ to generate a list of \textbf{subtopics} for further exploration.
\end{enumerate}

\par{\textbf{Retrieving relevant segments.}} For each paper $p_{a\in\{1,2\}}$, we retrieve the top $\delta$ segments $S^i_{a\in\{1,2\}}$ conditioned on node topic $n_i$ using the retrieval embedding model \cite{bge_embedding} (Section \ref{sec:retrieval}). We embed $n_i$ using the query format: ``[\texttt{topic name}] : [\texttt{topic description}]'' (the moderator generates a description for each non-root node). These segments form two separate pools of evidence per paper to compose their novelty claims.

\par{\textbf{Preemption.}} For each of paper $p_b$'s novelty claims $c^b_{(i,j)} \in C^b_i$ with its corresponding evidence $E^b_i$, we retrieve additional segments $\widetilde{E}^a_{(i,j)}$ from $p_a$ using the concatenated title and description of $c^b_{(i,j)}$ as the query. Each retrieved segment $e$ is then filtered using an LLM-based step (Prompt \ref{prompt_persona: is_irrelevant_evidences}) that evaluates whether $e$ (1) \underline{\textit{supports}}, (2) \underline{\textit{refutes}}, (3) \underline{\textit{clarifies}} $p_b$'s claim, or (4) is \underline{\textit{irrelevant}}. While redundant, we notice that explicitly including (4) as an option helps with filtration performance. If either (1-3) are true or (4) is false, then $e$ is filtered out. If $|\widetilde{E}^i_{(a, j)}| = 0$, we indicate that $p_a$ does not address $p_b$'s claim, $c^b_{(i,j)}$. Overall, preemption allows the paper personas to be better prepared for their opposition's arguments ahead of the debate.

\par{\textbf{Subtopic Generation.}} Using each paper's title, abstract, $C_i$, $E_i$, and $\widetilde{E}_i$, the moderator generates $k$ \textbf{subtopics} $n^i_j \in N^i$ that should be further explored (Prompt \ref{prompt_mod: generate_topics}). The moderator maps each subtopic to at least one claim $c_i$ from either $p_1$ and/or $p_2$, forming child debate nodes that explore overlapping topics (e.g., ``Reasoning Evaluation'' in Figure \ref{fig:hierarchy}) or topics potentially unique to one paper (e.g., ``Multiple Paths'').

\subsection{Debate Tree Expansion \& Synthesis}
\label{sec:expansion}

\par While we motivate the personas to examine and debate whether their work proposes a \textit{better} idea than their opposition, this mechanism is intended to (1) emphasize the \textbf{\textit{reasoning behind the idea}} and (2) provoke debate on the \textbf{\textit{novelty behind the ideas}}, relative to each other. In other words, we hypothesize that two very similar ideas (e.g., ``Reasoning Evaluation'' in Figure \ref{fig:hierarchy}) will typically lead to a \textit{longer} debate subtree on which approach is better. Conversely, a uniquely novel approach or task proposed in $p_1$, relative to $p_2$, may result in a \textit{shorter} debate as the moderator will ideally determine that $p_2$ does not address $p_1$'s claim in their work and thus has a weak argument (e.g., ``Backtracking'' in Figure \ref{fig:hierarchy}). To facilitate this process, the moderator's core tasks are detailed below.

\subsubsection{\textbf{Determining Round Depth Expansion}}
\par For debate node $n_i$, the moderator assesses the following (Prompt \ref{prompt_mod: is_expand}):
\begin{enumerate}[leftmargin=*]
    \item \textbf{Argument Progression}: Is there sufficient evolution in the arguments or new, deeper concepts being introduced to justify further debate?
    \item \textbf{Meaningful Questions}: Have clarifying questions been raised that remain unanswered and merit further discussion? If no questions are raised, the moderator returns False.
    \item \textbf{Clear Winner}: Is it clear that one paper has won the debate, as their contributions are truly better and do not warrant deconstruction (to determine which \textit{subcomponents} are truly better)?
\end{enumerate}
If either (1) or (2) holds true, or if (3) does not indicate a clear winner, the moderator proceeds to the self-deliberation stage (Section \ref{sec:self-deliberate}) to identify new subtopics and expand $n_i$ to $n^i_j \in N^i$. Otherwise, expansion stops for that debate path. A maximum tree depth is also enforced.

\subsubsection{\textbf{Debate Synthesis}}
\par Once ToD has converged (i.e., all debate paths have been adequately expanded), the moderator synthesizes the entire debate tree into a paragraph-long comparative summary. The debate tree is provided in-context, with each node $n_i \in T$ containing the following information: node topic \textbf{title}, node topic \textbf{description}, persona $p_1$'s \textbf{revised argument} (at the end of the debate round), and persona $p_2$'s \textbf{revised argument}. The synthesis should first explain the papers' novelty similarities and then detail their differences, with greater emphasis on the latter. We provide the prompt in Prompt \ref{prompt_mod: summarize_debate} and an example subtree in Appendix \ref{sec:tree_example}.