% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.


\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}
\usepackage{longtable}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{booktabs} % for professional tables
\usepackage{multirow}
\usepackage{arydshln}
\newcommand{\ccol}[1]{\multicolumn{1}{c}{#1}}
\usepackage{hyperref}
\newcommand{\theHalgorithm}{\arabic{algorithm}}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{color}
% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{EPO: Explicit Policy Optimization for Strategic Reasoning in LLMs via Reinforcement Learning}
% Enhancing Strategic Reasoning in LLMs for Long-term Goal Alignment via Reinforcement Learning
% Collaborative Strategic Reasoning Elicits Goal-Oriented Behavior from Large Language Models
% Collaborative Strategic Reasoning Enhances Decision-Making of Large Language Models
% Cooperative Strategic Reasoning Enhances Long-term Planning of Large Language Model Agents
% Inference-Time Policy Steering through Strategic Reasoning Models
% Steering Large Language Model Agents with Strategic Reasoning Models


% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

%\author{Xiaoqian Liu \\
%   University of Chinese Academy of Sciences\\
%  Insititute of Automation, Chinese Academy of Sciences \\
%  \texttt{email@domain} \\\And
%  Ke Wang \\
%  Tongyi Lab \\
%  \texttt{email@domain} \\}

\author{
  \textbf{Xiaoqian Liu\textsuperscript{1,3}},
  \textbf{Ke Wang\textsuperscript{2}},
\textbf{Yongbin Li\textsuperscript{2}$^{*}$},
  \textbf{Yuchuan Wu\textsuperscript{2}},
  \textbf{Wentao Ma\textsuperscript{2}},\\
  \textbf{Aobo Kong\textsuperscript{2}},
  \textbf{Fei Huang\textsuperscript{2}},
  \textbf{Jianbin Jiao \textsuperscript{1}},
  \textbf{Junge Zhang\textsuperscript{3}\thanks{Corresponding authors}}
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
\\
  \textsuperscript{1}University of Chinese Academy of Sciences,
 \textsuperscript{2}Tongyi Lab\\
  \textsuperscript{3}Insititute of Automation, Chinese Academy of Sciences
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence to:} \href{mailto:email@domain}{email@domain}
%  }
}

\begin{document}
\maketitle

\input{0-abstract}

\input{1-intro}

\input{2-related}

\input{3-method}

\input{4-experiment}

\input{5-conclusion}

\section*{Limitations}
Despite \textit{EPO} shows promise in advancing strategic reasoning in LLMs, this work has several limitations that provide avenues for future work.
First, the social and physical environments tested in this paper involve maximumly two agents, and \textit{EPO}'s performance on more complex multi-agent settings such as Diplomacy and Hanabi is also interesting.
Second, due to the computational constraints, we focus on 8B/7B models and do not scale up the multi-turn RL training to a large scale.
It would be an important direction for future work to train our strategic reasoning model with larger base models on more domains.
Third, we employ an off-the-shelf LLM as the process reward model for RL training, while a more reliable process-supervised reward model can be learned in the future work.
Finally, we rely on the final goal completion score to evaluate the reasoning model's performance.
Future research could design evaluation metrics tailored to assess the quality and diversity of strategies devised by this model.


% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix


\section{Strategic Reasoning vs. Static Problem-Solving}
\label{append:challenge}

The differences between strategic reasoning and static problem-solving are summarized in Table~\ref{tab:challenge}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table*}[ht]
    \centering
    \begin{tabular}{lll}
    \toprule
   \textbf{Aspect} & \textbf{Static Problem-Solving}  &  \textbf{Strategic Reasoning}\\
    \midrule
    \textbf{Environment} & Fixed rules, known variables  & Dynamic, evolving conditions\\
    \midrule
    \textbf{Solutions} & Single correct answer & Multiple viable paths with trade-offs\\
    \midrule
    \textbf{Information} & Complete and observable & Partial, ambiguous, or delayed\\
    \midrule
    \textbf{Interactions} & None (isolated problem-solving) & Multi-agent or environmental dynamics\\
    \midrule
    \textbf{Feedback} & Immediate and deterministic & Delayed, probabilistic, or indirect\\
    \midrule
    \textbf{Goals} & Short-term, well-defined & Long-term, abstract\\
    \midrule
    \textbf{Risk} & Predictable & High-stakes, irreversible consequences\\
    \bottomrule
    \end{tabular}
    \caption{Challenges of Strategic Reasoning vs. Static Problem-Solving.}
    \label{tab:challenge}
\end{table*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






\section{Environments and Datasets}
\label{append:dataset}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table*}[ht]
\begin{center}
\begin{tabular}{lccc}
\toprule
\textbf{Dataset} & Train & Test & Max Turns \\
\midrule
SOTOPIA & 2050  &450/50 & 20 \\
WebShop &1938 & 200 & 10\\
ALFWorld &3321  &140/134 & 40\\
\bottomrule
\end{tabular}
\caption{\textbf{Dataset Statistics.} ``Train'' and ``Test'' denote the number of scenarios for training and evaluation, respectively. Test scenarios in SOTOPIA (left) and SOTOPIA-hard (right) as well as test sets with seen (left) and unseen (right) scenarios in ALFWorld are separated. ``Max Turns'' is the maximum turns in an interaction.}
\label{tab:data}
\end{center}
\end{table*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\paragraph{\textbf{SOTOPIA}.}
SOTOPIA~\cite{zhou2024sotopia} is an open-ended, general-domain platform designed to simulate goal-oriented social interactions between artificial agents. A social task in this environment involves a scenario, two role profiles, and private social goals to be achieved through interaction. Scenarios in SOTOPIA cover a wide variety of social interation types, including negotiation, exchange, collaboration, competition, accommodation and persuation. Each agent is characterized by detailed profiles, including aspects like name, gender, personality, and occupation. At the end of each episode, agents are assessed based on seven dimensions: Goal Completion, Believability, Knowledge, Secret, Relationship, Social Rules, and Financial and Material Benefits. These scores are then averaged to produce an overall score for the agents. 
SOTOPIA-$\pi$~\cite{Wang2024SOTOPIAIL} is a follow-up work that leverages GPT-4 to automatically construct an entirely new set of scenarios. The social tasks (a combination of scenarios, characters’ profiles, and social goals) in SOTOPIA-$\pi$ are guaranteed to not overlap with the ones in SOTOPIA.

For training data collection, we employ GPT-4-Turbo as the agent for self-chat in scenarios of SOTOPIA-$\pi$ and prompt it to generate reasoning and strategy before response at each dialogue turn. We show the prompt in Table~\ref{tab:data_collect_prompt}. We only use the strategy and response data for training our reasoning model.
For iterative self-play RL training, before each iteration, we employ our RL-trained reasoning model to collect strategy data and GPT-4-Turbo to collect dialogue history data. The RL-trained reasoning model is plugged into GPT-4-Turbo for self-chat.



\paragraph{\textbf{WebShop}.}
WebShop~\cite{yao2022webshop} is a large-scale interactive online shopping environment on an e-commerce website. Agents in this environment aim to purchase a product to match the specifications provided by human user instructions. Once the agent selects the ``buy'' action, the environment provides a final reward, which is calculated using programmatic matching functions that consider the attributes, type, options, and price of the chosen product.

We use the training data collected by~\cite{song-etal-2024-trial} where GPT-4 is employed as the agent to explore in the WebShop environment and trajectories with a reward greater than 0.7 are selected. GPT-4 is used to generate corresponing rationales for each action step within a trajectory. We consider the rationale as a strategy for training our reasoning model.

\paragraph{\textbf{ALFWorld}~\cite{shridhar2021alfworld}.}
ALFWorld~\cite{shridhar2021alfworld} features interactive TextWorld environments that correspond to the embodied worlds found in the ALFRED~\cite{9156851} dataset. In ALFWorld, agents are tasked with exploring these text-based environments and completing high-level household instructions, assessing their abstract reasoning abilities and concrete execution skills.

Training data in the ALFWorld environment consists of two parts: (1) a few successful trajectories collected by~\cite{song-etal-2024-trial} where each trajectory contains CoT information generated by GPT-4 for each action step; (2) failed trajectories generated by GPT-4 that contain both rationales and action information via CoT prompting.


\section{Additional Results}
\label{append:add_res}

To validate the effectivess of explicit policy optimization for strategic reasoning, we conduct comparative experiments which involve fine-tuning a single LLM (Llama3-8B-Instruct) via SFT on training data collected from three environments, respectively. This single model is trained to output strategy and behavior simuteneously for each interaction turn. The results are shown in Table~\ref{tab:single_res}.

From the results, it can be observed that training a single LLM via SFT underperforms our reasoning model trained with SFT plugged into LLM agents (GPT-4o) for navigating in SOTOPIA and WebShop, despite that the LLM agents remain frozen without additional training. However, our method underperforms the single model fined-tuned on ALFWorld, since the frozen LLM agent (GPT-4o) has poor performance in this environment. Under the guidance of our reasoning model in \textit{EPO}, this agent improves performance in achieving long-term goals but still struggles with challenging scenarios in ALFWorld.

\begin{table*}[ht]
    \centering
    \begin{tabular}{llccccc}
    \toprule
     \multirow{2}{*}{Backbone} & \multirow{2}{*}{Method}  &  \multicolumn{2}{c}{\textbf{SOTOPIA}} & \multirow{2}{*}{\textbf{WebShop}} & \multicolumn{2}{c}{\textbf{ALFWorld}}\\
     & & Hard & All &  & Seen & Unseen\\
     \midrule
     Llama3-8B & SFT & 6.65 & 8.20 & 62.6 & \textbf{61.4}& \textbf{60.4} \\
     Llama3-8B & EPO-SFT & \textbf{6.76} & \textbf{8.28} & \textbf{67.1} & 45.9 & 44.1 \\
     \bottomrule
    \end{tabular}
    \caption{\textbf{Comparative performance between training a single LLM with SFT and explicitly optimizing a strategic reasoning model via SFT.}
    The evaluation metric for SOTOPIA is the final goal completion score, and average reward for WebShop and ALFWorld. Our strategic reasoning model trained with SFT is plugged into GPT-4o.}
    \label{tab:single_res}
\end{table*}


\section{Additional Implementation Details}
\label{append:imple} 
For SFT or RL training of our reasoning model, we use a fixed budget of gradient updates without altering hyperparameters. Final model checkpoints are selected for each run, although a small held-out validation set can be used.
Due to computational costs, we only report results in a single run. All experiments are conducted on 6 NVIDIA A100 80G GPUs.
GPT-4o refers to GPT-4o-2024-0806 and Claude-3.5-Sonnet refers to Claude-3-5-Sonnet-20241022.


\paragraph{\textbf{Baseline Implementations:}} (1) ReAct: During ReAct prompting, the two parties in a conversation from SOTOPIA cannot see each other's reasoning and strategies. During evaluation, reasoning and strategies are excluded from dialogue histories for GPT-4o to assess the agents from seven dimensions; (2) PPDPP: We adopt RoBERTa~\cite{Liu2019RoBERTaAR} as the base model for dialogue policy planner to predict five action types in SOTOPIA: ``none'', ``speak'', ``non-verbal communication'', ``action'', and ``leave''. We train the policy planner via RL with supervised initialization using same hyperparameters as in~\cite{deng2023plug}.
(3) DAT: We adopt a small multi-layer perceptron (MLP) as the planner model to predict a continuous action vector. We first train the planner and an up-mapping matrix with supervised fine-tuning and then optimize the planner using the RL method TD3-BC~\cite{fujimoto2021minimalist} with same hyperparameters as in~\cite{li2024dialogue}. Note that in the original paper, DAT is trained on scenarios from SOTOPIA and only 50 evaluations are conducted, while in this work, we train DAT on scenarios from SOTOPIA-$\pi$ and evaluate it on all the scenarios in SOTOPIA.

\onecolumn

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
\begin{longtable}{p{0.95\columnwidth}}
\toprule
    \texttt{Imagine you are <Agent>, your task is to act/speak as <Agent> would, keeping in mind <Agent>'s goal.} \\
    \texttt{You can find <Agent>'s goal (or background) in the ``Here is the context of the interaction'' field.} \\
    \texttt{Note that <Agent>'s goal is only visible to you.}\\
    \texttt{You should try your best to achieve <Agent>'s goal in a way that align with their character traits.}\\
    \texttt{While trying to achieve <Agent>'s goal, you should also follow the following principles as much as possible:}\\
    \texttt{1. Maintain the conversation's naturalness and realism is essential (e.g., do not repeat what other people has already said before).}\\
    \texttt{2. Preserve or enhance <Agent>'s personal relations with the other agent(s) during the interaction. The relations may encompass family ties, friendships, romantic associations and etc.}\\
    \texttt{3. Attempt to gain more new and important information during the interaction.}\\
    \texttt{4. Try to keep <Agent>'s secrets, private information, or secretive intentions.}\\
    \texttt{5. Do not violate any moral rules or laws in the interactions.}\\
    \texttt{6. Attempt to contribute towards financial and material benefits during the interaction. The financial and material benefits include short-term ones, such as monetary rewards and food, and long-term ones, such as employment opportunities and stock.}\\
    \texttt{You are at Turn <turn number>.}\\
    \texttt{The dialogue history until now is: <history>.}\\
    \texttt{You should first provide a reasoning for your action and argument to align with <Agent>'s social goal based on the dialogue history.}\\
    \texttt{The reasoning process for the action should be logical, considering the context of the conversation, <Agent>'s goal, and <Agent>'s character traits.}\\
    \texttt{You can reason step by step, starting from the current dialogue turn, and then consider the long-term effects of the dialogue turn.}\\
    \texttt{Remember that the reasoning should mainly focus on how <Agent>'s argument can help to achieve <Agent>'s goal in the long term.}\\
    \texttt{Note that the reasoning should not be redundant or too long and it is only visible to you.}\\
    \texttt{Based on the reasoning process and dialogue history, you should then generate a corresponding dialogue policy for current dialogue turn to steer the conversation towards <Agent>'s goal.}\\
    \texttt{You can use different types of dialogue, communication or social strategies.}\\
    \texttt{For example, given a scenario where a persuader attempts to persuade a persuadee to donate to a charity, you can generate dialogue policies for the persuader such as ``elicit empathy by telling personal stories'' and ``provide social proof to show the benefits of donating'', etc.}\\
    \texttt{The types of dialogue policies are not restricted to examples above.}\\
    \texttt{You can even generate new policies as long as the policies can help you to achieve <Agent>'s goal smoothly and quickly.}\\
    \texttt{But remember to keep the dialogue policy concise and strictly limit it to be a single phrase or sentence within 10 words.}\\
    \texttt{Note that the dialogue policy is only visible to you.}\\
    \texttt{Then based on the reasoning, dialogue policy and dialogue history, you should select the action type.}
    \texttt{Your available action types are <action list>.}\\
    \texttt{Note: You can ``leave'' this conversation if 1. you have achieved your social goals, 2. this conversation makes you uncomfortable, 3. you find it uninteresting/you lose your patience, 4. or for other reasons you want to leave.}\\
    \texttt{Finally, you should generate the argument following the action type.}\\
    \texttt{The argument should be generated based on the dialogue history and aligned with the dialogue policy you have generated.}\\
    \texttt{Remember that the argument should not be too short, and one or two sentences are recommended.}\\
    \texttt{Please only generate a JSON string including the reasoning, the dialogue policy, the action type and the argument.}\\
    \texttt{Your response should follow the given format:} \\
    \texttt{<format instructions>}\\
\bottomrule
\caption{\textbf{Prompts for training data collection from SOTOPIA-$\pi$.} ``<Agent>'', ``<turn number>'', ``<history>'', ``<action list>'' and ``<format instructions>'' can be replaced by the participant's name, the index of interaction turn, the full dialogue history with the participant's strategies, action types and output format instructions in SOTOPIA-$\pi$.}
\label{tab:data_collect_prompt}
\end{longtable}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%







\section{Prompts}
\label{append:prompt}

\subsection{\textbf{Evaluation Prompts}}
\label{append:task-prompt}

\begin{center}
\begin{longtable}{lp{0.85\columnwidth}}
    \toprule
    \textbf{SOTOPIA} & \texttt{You are a social expert with exceptional communication skills known for helping individuals achieve their interpersonal goals through nuanced strategies.}
	 \\ & \texttt{Your current objective is to assist <Agent1> in reaching their goal in an interaction with <Agent2>.}
	 \\ & \texttt{You will be given the context of their interaction and can find <Agent1>'s goal in the 'Here is the context of this interaction' field, keeping in mind <Agent1>'s goal.}
	 \\ & \texttt{You will also have access to the conversation between <Agent1> and <Agent2>.}
	 \\ & \texttt{Before proposing any strategies, reason step by step to reflect on the current state of the dialogue and consider what strategies might be most effective for helping <Agent1> achieve their goal.}
	 \\ & \texttt{Additionally, maintaining the diversity of strategies is essential (e.g., do not repeat strategies that have already proposed before).}
	 \\ & \texttt{And the strategy should not be aggressive, offensive, or violate any moral rules or laws.}
	 \\ & \texttt{You must generate a strategy at each dialogue turn except that any participant has left the conversation.}
	 \\ & \texttt{Finally, provide a well-thought-out communication and social strategy based on your reflection and the conversation history.}
	 \\ & \texttt{Your output should STRICTLY follow the format: Strategy: content (e.g, Strategy: Elicit emphathy by telling personal stories).}
	 \\ & \texttt{Your output should ONLY contain the strategy. DO NOT include any reasoning or argument. DO NOT generate any argument on behalf of any participant as the strategy.}
	 \\ & \texttt{Your output should be in a natural language form.}
	 \\ & \texttt{Keep the strategy concise and limit it to be a single phrase or sentence within 10 words.}\\
\midrule
    \textbf{WebShop} & \texttt{You are a skilled buyer in an online shopping environment. Your task is to assist Agent in navigating the platform to make purchases based on instructions. Your primary role is to provide strategic and insightful guidance to Agent, ensuring it successfully identifies and purchases products based on the instruction.}
	 \\ & \texttt{- At the beginning of the interaction, you will receive an instruction that includes the desired product's attributes and price, which serves as the shopping goal for Agent.}
	 \\ & \texttt{- You can find the instruction in the 'Instruction' field, keeping in mind the instruction.}
	 \\ & \texttt{- For each turn, you will be given an action performed by Agent and the resulting observation from the environment.}
	 \\ & \texttt{- In each turn, your task is to analyze the given scenario and provide thoughts that can guide Agent in its next action, ensuring it meets the shopping goal.}
	 \\ & \texttt{Your thoughts should be based on:}
	 \\ & \texttt{1. Understanding and following the instructions for shopping.}
	 \\ & \texttt{2. Evaluating the current state of the environment.}
	 \\ & \texttt{3. Assessing the effectiveness of Agent's last action.}
	 \\ & \texttt{4. Anticipating future actions that will lead Agent closer to achieving the shopping goal.}
	 \\ & \texttt{The available actions for Agent are:}
	 \\ & \texttt{1. search[keywords]}
	 \\ & \texttt{2. click[value]}
	 \\ & \texttt{where [keywords] in search are up to Agent, and the [value] in click is a value in the list of available actions given by the environment.}
	 \\ & \texttt{Note that you must generate a thought at each turn except that the task has been finished.}
	 \\ & \texttt{Keep your thoughts focused and concise, leveraging your understanding of online shopping dynamics to maximize the efficiency and correctness of Agent's actions. Use your reasoning skills to project possible scenarios and potential obstacles Agent might face, offering solutions or alternatives when necessary.}
	 \\ & \texttt{**Output Format:**}
	 \\ & \texttt{Keep your response to one or two sentences each turn.}
	 \\ & \texttt{Your response must strictly follow this format:}
	 \\ & \texttt{Thought: <your thoughts>} \\
    
\midrule
    \textbf{ALFWorld}
    & \texttt{You are an intelligent guide in an interactive household environment. Your task is to assist Agent in accomplishing household tasks within the environment. Your primary role is to provide strategic and insightful guidance to Agent, ensuring that Agent can achieve each task goal efficiently.}
	 \\ & \texttt{- At the beginning of your interactions, you will be given the detailed description of the current environment and the task goal to accomplish.}
	 \\ & \texttt{- You can find the task goal in the 'Your task is to' field, keeping in mind the task goal.}
	 \\ & \texttt{- For each of your turn, you will receive Agent's actions and the corresponding environment observations. If the environment observation is ``Nothing happens'', that means the previous action by Agent is invalid.}
	 \\ & \texttt{- In each turn, your task is to analyze the current situation and provide clear, logical thoughts that will help direct Agent's subsequent actions toward achieving the task goal.}
	 \\ & \texttt{Your thoughts should be based on:}
	 \\ & \texttt{1. Understanding the goal of household task.}
	 \\ & \texttt{2. Breaking down a high-level house-holding instruction into manageable sub-goals.}
	 \\ & \texttt{3. Evaluating the current state of the environment.}
	 \\ & \texttt{4. Assessing the effectiveness of Agent's last action.}
	 \\ & \texttt{5. Anticipating future actions that will lead Agent closer to achieving the task goal.}
	 \\ & \texttt{The available actions for Agent are:}
	 \\ & \texttt{1. go to \{recep\}}
	 \\ & \texttt{2. take \{obj\} from \{recep\}}
	 \\ & \texttt{3. put \{obj\} in/on \{recep\}}
	 \\ & \texttt{4. open \{recep\}}
	 \\ & \texttt{5. close \{recep\}}
	 \\ & \texttt{6. toggle \{obj\} \{recep\}}
	 \\ & \texttt{7. clean \{obj\} with \{recep\}}
	 \\ & \texttt{8. heat \{obj\} with \{recep\}}
	 \\ & \texttt{9. cool \{obj\} with \{recep\}}
	 \\ & \texttt{where \{obj\} and \{recep\} correspond to objects and receptacles.}
	 \\ & \texttt{Note that you must generate a thought at each turn except that the task has been finished.}
	 \\ & \texttt{Keep your thoughts focused and concise, leveraging your understanding of household dynamics to maximize the efficiency and correctness of Agent's actions. Use your reasoning skills to project possible scenarios and potential obstacles Agent might face, offering solutions or alternatives when necessary.}
	 \\ & \texttt{**Output Format:**}
	 \\ & \texttt{Keep your response to one or two sentences each turn.}
	 \\ & \texttt{Your response must strictly follow this format:}
	 \\ & \texttt{Thought: <your thoughts>}
     \\
         \bottomrule
    \caption{\textbf{Evaluation prompts for strategic reasoning model}. "<Agent1>" and "<Agent2>" can be replaced by the participant's name in SOTOPIA.}

\end{longtable}
\end{center}





\subsection{\textbf{PRM Prompts}}
\label{append:strategy-prompt}

\begin{center}
\begin{longtable}{lp{0.85\columnwidth}}
    \toprule
     \textbf{SOTOPIA} & \texttt{Here's a conversation in JSON format between <Agent1> and <Agent2>:}
	 \\ & \texttt{In the first response from ``human'', you can find the context of the conversation and <Agent1>'s goal in the ``Here is the context of this interaction'' field.}
	 \\ & \texttt{In the other responses from ``human'', you can find the conversation history between <Agent1> and <Agent2>.}
	 \\ & \texttt{In the responses from ``gpt'', you can find communication and social strategies that <Agent1> used for achieving <Agent1>'s goal.}
	 \\ & \texttt{In the ``score'' field, you can find a score for evaluating <Agent1>'s goal achievement. The score ranges from 0 and 10. 0 represents minimal goals achievement, 10 represents complete goal achievement, and a higher score indicates that <Agent1> is making progress towards the goal.}
     \\ &
	 \\ & \texttt{<history>}
     \\ &
	 \\ & \texttt{Your task is to select top strategies <Agent1> used that were critically important for achieving <Agent1>'s goal.}
          \\ &
	 \\ & \texttt{Please output the selected round indexes and the reasoning process that led you to the selection in JSON format like this: {``indexes'': , ``reasoning'': `` ''}.}
	 \\ & \texttt{Here is the output schema: {``properties": {``indexes": {``description": ``the selected top strategies that are critically important for achieving <Agent1>'s goal", ``title": ``indexes", ``type": ``list(integer)"}, ``reasoning": {``description": ``the reasoning process why you select these strategies", ``title": ``reasoning", ``type": ``string"}}, ``required": [``indexes", ``reasoning"]}.}
    \\
\midrule
    \textbf{WebShop} & \texttt{Here's a conversation in JSON format between human and gpt.}
     \\ & \texttt{In the first response from ``human'', you can find the instructions for gpt to help Agent interact in an online shopping environment.}
     \\ & \texttt{In the second response from ``human'', you can find the shopping goal for gpt and Agent to achieve.}
     \\ & \texttt{In the responses from ``gpt'', you can find thoughts that gpt provides for helping Agent to achieve the shopping goal.}
     \\ & \texttt{In the other responses from ``human'', you can find the trajectories of Agent's actions and the resulting observations from the environment.}
     \\ & \texttt{}
     \\ & \texttt{In the ``score'' field, you can find a score evaluating the goal achievement. The score ranges from 0 and 1. 0 represents minimal goals achievement, 10 represents complete goal achievement, and a higher score indicates making progress towards the goal.}
     \\ & \texttt{}
     \\ & \texttt{<history>}
     \\ & \texttt{}
     \\ & \texttt{Your task is to select top thoughts gpt produced that were critically important for achieving the shopping goal.}
     \\ & \texttt{}
     \\ & \texttt{Please output the selected round indexes and the reasoning process that led you to the selection in JSON format like this: {``indexes": , ``reasoning": `` "}.}
     \\ & \texttt{Here is the output schema: {``properties": {``indexes": {``description": ``the selected top thoughts that are critically important for achieving the shopping goal", ``title": ``indexes", ``type": ``list(integer)"}, ``reasoning": {``description": ``the reasoning process why you select these thoughts", ``title": ``reasoning", ``type": ``string"}}, ``required": [``indexes", ``reasoning"]}.}

\\
\midrule
    \textbf{ALFWorld} & \texttt{Here's a conversation in JSON format between human and gpt.}
	 \\ & \texttt{In the first response from 'human', you can find the instructions for gpt to help Agent interact in a household environment.}
	 \\ & \texttt{In the second response from ``human'', you can find the initial environment observation and a household task for gpt and Agent to accomplish.}
	 \\ & \texttt{In the responses from ``gpt'', you can find thoughts that gpt provides for helping Agent to accomplish the household task.}
	 \\ & \texttt{In the other responses from ``human'', you can find the trajectories of Agent's actions and the resulting observations from the environment.}
	 \\ & \texttt{}
	 \\ & \texttt{In the 'score' field, you can find a score specifying whether gpt has helped Agent to successfully accomplish the household task. The score is either 0.0 or 1.0. 0.0 represents that the task was not completed and 1.0 represents that the task was successfully accomplished.}
	 \\ & \texttt{}
	 \\ & \texttt{<history>}
	 \\ & \texttt{}
	 \\ & \texttt{Your task is to select top thoughts gpt produced that were critically important for accomplishing the household task.}
	 \\ & \texttt{}
	 \\ & \texttt{Please output the selected round indexes and the reasoning process that led you to the selection in JSON format like this: {``indexes": , ``reasoning": `` "}.}
	 \\ & \texttt{Here is the output schema: {``properties": {``indexes": {``description": ``the selected top thoughts that are critically important for accomplishing the household task", ``title": ``indexes", ``type": ``list(integer)"}, ``reasoning": {``description": ``the reasoning process why you select these thoughts", ``title": ``reasoning", ``type": ``string"}}, ``required": [``indexes", ``reasoning"]}.}
\\  
         \bottomrule
        \caption{\textbf{Prompts for the process reward model.} "<history>" can be replaced by the full interaction history with strategies private to corresponding agents.}
\end{longtable}
\end{center}















\section{Case Studies}
\label{append:case}

\begin{center}
\begin{longtable}{lp{0.83\columnwidth}}
    \toprule
    \textbf{Scenario} &  One person is offering a BMW Z3 for \$5000, while another individual is interested in  purchasing it. The BMW Z3 is in need of a good home. It operates smoothly without any problems and is known for its fuel efficiency and sporty appearance. The mileage is relatively low for its age. It's an opportunity not to be missed, so come and get it before it's gone. A smog certificate is readily available. \\
    \midrule
    \textbf{Person1} & Lily Greenberg, a 45-year-old female lawyer (she/her), is a hard-working and successful professional who values authority, loyalty, rules, and schedules. She makes rational, practical decisions and secretly donates to charity anonymously. \\
    & \textbf{Goal:} You are the buyer for this item with a target price of \$4600. You aim to avoid penalties for exceeding the target and seeks bonuses for securing it below that price.\\
    \midrule
    \textbf{Person2} &  Hendrick Heinz, a 54-year-old male chef (he/him), hosts monthly wine tasting nights. Though impulsive, he values hedonism and conformity, blending practicality with decisiveness. Secretly, he faked his culinary credentials to secure prestigious jobs. \\
    & \textbf{Goal:} You are the seller to achieve a target price of \$3260 for this item. Selling significantly below may incur a penalty, while selling above could earn a bonus.\\
    \midrule
    \textbf{ReAct}  & \textbf{Strategy:} Express interest and hint at budget constraints. \\
    & Lily Greenberg said: "The BMW Z3 sounds great! Would you consider \$4600?" \\
    & \textbf{Strategy:} Highlight car's unique features and value.\\
    & Hendrick Heinz said: "The BMW Z3 is not only sporty but also fuel-efficient, a rare find!"\\
    & \textbf{Strategy:} Highlight budget limits and car appeal.\\
    & Lily Greenberg said: "That's impressive! But my budget is tight. Can we negotiate?"\\
    & \textbf{Strategy:} Emphasize long-term value and low maintenance costs.\\
    & Hendrick Heinz said: "While I understand budget constraints, consider the car's long-term value and low maintenance costs. It truly is a worthwhile investment."\\
    & \textbf{Strategy:} Acknowledge value but reiterate budget constraints.\\
    & Lily Greenberg said: "I completely see the long-term value, but \$4600 is my max. Could we find a middle ground?"\\
    & \textbf{Strategy:} Offer smog certificate as a bonus.\\
    & Hendrick Heinz said: "How about I throw in the smog certificate for \$4800?"\\
    \midrule
    \textbf{EPO-SFT}  & \textbf{Strategy:} Express interests and offer a lower price.\\
    (Llama3-8B)& Lily Greenberg said: "Hello Hendrick, I'm very interested in the BMW Z3 you're offering. However, after considering the market and the car's age, I feel more comfortable with a price of \$4600. Would that work for you?"\\
    & \textbf{Strategy:} Emphasize vehicle’s condition and counter with a higher price.\\
    & Hendrick Heinz said: "Hello Lily, it's great to hear from you. I appreciate your offer, but considering the condition and the low mileage of the BMW, I was hoping to get a bit more for it. Would you consider \$4800? The car really is in fantastic shape and I think it's worth it."\\
    & \textbf{Strategy:} Cite budget constraints and propose a compromise price.\\
    & Lily Greenberg said: "I understand your point, Hendrick, and I appreciate the quality of the car. However, my budget is quite tight at the moment. Would you be able to meet me in the  middle at \$4700? I'm ready to proceed with the purchase quickly if we can agree on that price."\\
    & \textbf{Strategy:} Offer a near-middle compromise.\\
    & Hendrick Heinz said: "Lily, I truly value your quick decision-making and readiness to proceed. Given the car's excellent condition and your eagerness, let's settle at \$4750. I believe it's a fair compromise and it ensures the car goes to someone who appreciates its value. \\
    & \textbf{Strategy:} Accepts compromise and finalize the sale.\\
    & Lily Greenberg said: "Hendrick, I appreciate your willingness to negotiate. \$4750 is a bit above what I initially planned, but considering the car's excellent condition, I'll accept your offer. Let's proceed with the paperwork!"\\
    & \textbf{Strategy:} Confirm agreement and outline next steps.\\
    & Hendrick Heinz said: "Fantastic, Lily! I'll prepare the necessary paperwork and we can finalize everything. I'm glad the BMW Z3 will be in good hands."\\
    \midrule
    \textbf{EPO-RL}  & \textbf{Strategy:} Negotiation initiation highlighting positive factors with a concern.\\
    (Llama3-8B)& Lily Greenberg said: "The BMW Z3 sounds great, especially with low mileage and good fuel efficiency. I am interested, but I noticed it's a bit older. Is there any room for negotiation on the price given its age?"\\
    & \textbf{Strategy:} Highlight the car's unique aspects to justify pricing.\\
    & Hendrick Heinz said: "The BMW Z3 is indeed a classic, and its sporty appearance combined with its low mileage makes it quite a rare find. It's maintained its performance quality over the years, making it a great investment. I believe the price reflects its unique value, but I'm open to hearing your offer."\\
    & \textbf{Strategy:} Offer lower price citing the car's age.\\
    & Lily Greenberg said: "I appreciate the value of a classic car like this, but given its age, my offer would be \$4300. Would that be something you'd consider?"\\
    & \textbf{Strategy:} Mention recent maintenance as value justification and counteroffer.\\
    & Hendrick Heinz said: "I totally understand your point, Lily. Just to highlight, the car recently underwent a thorough maintenance check, ensuring everything is in top-notch condition. Considering that, I would be comfortable with \$4700. What do you think?"\\
    & \textbf{Strategy:} Express budget constraints while proposing a middle-ground offer.\\
    & Lily Greenberg said: "I really like the car, Hendrick, and I see its value after the maintenance. However, I have a strict budget I'm working with. Could we possibly meet in the middle at \$4500? That would really help me out."\\
    & \textbf{Strategy:} Create urgency and offer slight flexibility for the deal.\\
    & Hendrick Heinz said: "I completely understand, Lily. The car has attracted some interest from other potential buyers, so I do need to finalize a deal soon. However, I want to work with you on this. How about we settle at \$4600? That way, you get a great deal, and I can ensure the car goes to someone who truly appreciates it."\\
    \bottomrule
    \caption{\textbf{A negotiation example from SOTOPIA.} GPT-4o serves as the dialogue agent for self-chat. ``ReAct'' means the two parties in a dialogue employ the ReAct prompting method to generate strategy before response at each turn. ``EPO-SFT'' refers to a strategic reasoning model trained via SFT that plugged into both dialogue agents, while ``EPO-RL'' represents an RL-trained reasoning model that assists both dialogue parties to incentivize goal-directed behavior.}
    \label{tab:case}
\end{longtable}
\end{center}




\end{document}
