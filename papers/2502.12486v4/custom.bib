% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@inproceedings{
yao2023react,
title={ReAct: Synergizing Reasoning and Acting in Language Models},
author={Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik R Narasimhan and Yuan Cao},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=WE_vluYUL-X}
}
@inproceedings{deng2023plug,
  title={Plug-and-play policy planner for large language model powered dialogue agents},
  author={Deng, Yang and Zhang, Wenxuan and Lam, Wai and Ng, See-Kiong and Chua, Tat-Seng},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}
@article{li2024dialogue,
  title={Dialogue Action Tokens: Steering Language Models in Goal-Directed Dialogue with a Multi-Turn Planner},
  author={Li, Kenneth and Wang, Yiming and Vi{\'e}gas, Fernanda and Wattenberg, Martin},
  journal={arXiv preprint arXiv:2406.11978},
  year={2024}
}
@inproceedings{
zhou2024sotopia,
title={{SOTOPIA}: Interactive Evaluation for Social Intelligence in Language Agents},
author={Xuhui Zhou and Hao Zhu and Leena Mathur and Ruohong Zhang and Haofei Yu and Zhengyang Qi and Louis-Philippe Morency and Yonatan Bisk and Daniel Fried and Graham Neubig and Maarten Sap},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=mM7VurbA4r}
}
@article{yao2022webshop,
  title={Webshop: Towards scalable real-world web interaction with grounded language agents},
  author={Yao, Shunyu and Chen, Howard and Yang, John and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={20744--20757},
  year={2022}
}
@inproceedings{
shridhar2021alfworld,
title={{\{}ALFW{\}}orld: Aligning Text and Embodied Environments for Interactive Learning},
author={Mohit Shridhar and Xingdi Yuan and Marc-Alexandre Cote and Yonatan Bisk and Adam Trischler and Matthew Hausknecht},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=0IOX0YcCdTn}
}
@inproceedings{Wang2024SOTOPIAIL,
  title={SOTOPIA-$\pi$: Interactive Learning of Socially Intelligent Language Agents},
  author={Ruiyi Wang and Haofei Yu and Wenxin Sharon Zhang and Zhengyang Qi and Maarten Sap and Graham Neubig and Yonatan Bisk and Hao Zhu},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:268379635}
}
@inproceedings{song-etal-2024-trial,
    title = "Trial and Error: Exploration-Based Trajectory Optimization of {LLM} Agents",
    author = "Song, Yifan  and
      Yin, Da  and
      Yue, Xiang  and
      Huang, Jie  and
      Li, Sujian  and
      Lin, Bill Yuchen",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.409/",
    doi = "10.18653/v1/2024.acl-long.409",
    pages = "7584--7600",
}
@inproceedings{ahmadian-etal-2024-back,
    title = "Back to Basics: Revisiting {REINFORCE}-Style Optimization for Learning from Human Feedback in {LLM}s",
    author = {Ahmadian, Arash  and
      Cremer, Chris  and
      Gall{\'e}, Matthias  and
      Fadaee, Marzieh  and
      Kreutzer, Julia  and
      Pietquin, Olivier  and
      {\"U}st{\"u}n, Ahmet  and
      Hooker, Sara},
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.662/",
    doi = "10.18653/v1/2024.acl-long.662",
    pages = "12248--12267",
}
@article{Peng2019AdvantageWeightedRS,
  title={Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning},
  author={Xue Bin Peng and Aviral Kumar and Grace Zhang and Sergey Levine},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.00177},
  url={https://api.semanticscholar.org/CorpusID:203610423}
}
@article{sutton1999policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
  journal={Advances in neural information processing systems},
  volume={12},
  year={1999}
}
@article{Deng2024FromNT,
  title={From Novice to Expert: LLM Agent Policy Optimization via Step-wise Reinforcement Learning},
  author={Zhirui Deng and Zhicheng Dou and Yutao Zhu and Ji-Rong Wen and Ruibin Xiong and Mang Wang and Weipeng Chen},
  journal={ArXiv},
  year={2024},
  volume={abs/2411.03817},
  url={https://api.semanticscholar.org/CorpusID:273850657}
}
@article{Hua2024GametheoreticLA,
  title={Game-theoretic LLM: Agent Workflow for Negotiation Games},
  author={Wenyue Hua and Ollie Liu and Lingyao Li and Alfonso Amayuelas and Julie Chen and Lucas Jiang and Mingyu Jin and Lizhou Fan and Fei Sun and William Yang Wang and Xintong Wang and Yongfeng Zhang},
  journal={ArXiv},
  year={2024},
  volume={abs/2411.05990},
  url={https://api.semanticscholar.org/CorpusID:273963514}
}
@article{Bakhtin2022HumanlevelPI,
  title={Human-level play in the game of Diplomacy by combining language models with strategic reasoning},
  author={Anton Bakhtin and Noam Brown and Emily Dinan and Gabriele Farina and Colin Flaherty and Daniel Fried and Andrew Goff and Jonathan Gray and Hengyuan Hu and Athul Paul Jacob and Mojtaba Komeili and Karthik Konath and Minae Kwon and Adam Lerer and Mike Lewis and Alexander H. Miller and Sandra Mitts and Adithya Renduchintala and Stephen Roller and Dirk Rowe and Weiyan Shi and Joe Spisak and Alexander Wei and David J. Wu and Hugh Zhang and Markus Zijlstra},
  journal={Science},
  year={2022},
  volume={378},
  pages={1067 - 1074},
  url={https://api.semanticscholar.org/CorpusID:253759631}
}
@inproceedings{
bakhtin2023mastering,
title={Mastering the Game of No-Press Diplomacy via Human-Regularized Reinforcement Learning and Planning},
author={Anton Bakhtin and David J Wu and Adam Lerer and Jonathan Gray and Athul Paul Jacob and Gabriele Farina and Alexander H Miller and Noam Brown},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=F61FwJTZhb}
}
@article{gemp2024states,
  title={States as strings as strategies: Steering language models with game-theoretic solvers},
  author={Gemp, Ian and Bachrach, Yoram and Lanctot, Marc and Patel, Roma and Dasagi, Vibhavari and Marris, Luke and Piliouras, Georgios and Liu, Siqi and Tuyls, Karl},
  journal={arXiv preprint arXiv:2402.01704},
  year={2024}
}
@article{gandhi2023strategic,
  title={Strategic reasoning with language models},
  author={Gandhi, Kanishk and Sadigh, Dorsa and Goodman, Noah D},
  journal={arXiv preprint arXiv:2305.19165},
  year={2023}
}
@inproceedings{duan-etal-2024-reta,
    title = "{R}e{TA}: Recursively Thinking Ahead to Improve the Strategic Reasoning of Large Language Models",
    author = "Duan, Jinhao  and
      Wang, Shiqi  and
      Diffenderfer, James  and
      Sun, Lichao  and
      Chen, Tianlong  and
      Kailkhura, Bhavya  and
      Xu, Kaidi",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-long.123/",
    doi = "10.18653/v1/2024.naacl-long.123",
    pages = "2232--2246",
    abstract = "Current logical reasoning evaluations of Large Language Models (LLMs) primarily focus on single-turn and static environments, such as arithmetic problems. The crucial problem of multi-turn, strategic reasoning is under-explored. In this work, we analyze the multi-turn strategic reasoning of LLMs through text-driven complete- and incomplete-information gaming, e.g., board games (Tic-Tac-Toe, Connect-4) and poker games (Texas Hold`em Poker). Specifically, we consider two distinct scenarios: 1) Online Racing, featuring multiple LLMs/agents to facilitate direct competition and comparison; 2) Offline Probing, constructing targeted questions with verified ground truth to evaluate LLMs' strategic behaviors. Experimental results demonstrate that existing state-of-the-art LLMs and reasoning schemes are largely ineffective for strategic reasoning tasks. To mitigate these limitations, we propose a simple yet effective Recursively Thinking-Ahead (ReTA) agent, incorporating a recursive prompting mechanism that automatically analyzes the opponents' future moves/actions and assigns reward signals for these situations, to strengthen the strategic reasoning of LLMs. We hope our work could spur further research and exploration in the multi-turn strategic reasoning of LLMs. The code is available at https://github.com/jinhaoduan/ReTA."
}
@inproceedings{zhang-etal-2023-ask,
    title = "Ask an Expert: Leveraging Language Models to Improve Strategic Reasoning in Goal-Oriented Dialogue Models",
    author = "Zhang, Qiang  and
      Naradowsky, Jason  and
      Miyao, Yusuke",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.417/",
    doi = "10.18653/v1/2023.findings-acl.417",
    pages = "6665--6694",
}
@inproceedings{
zhang2024llm,
title={{LLM} as a Mastermind: A Survey of Strategic Reasoning with Large Language Models},
author={Yadong Zhang and Shaoguang Mao and Tao Ge and Xun Wang and Yan Xia and Wenshan Wu and Ting Song and Man Lan and Furu Wei},
booktitle={First Conference on Language Modeling},
year={2024},
url={https://openreview.net/forum?id=iMqJsQ4evS}
}
@inproceedings{
wei2022chain,
title={Chain of Thought Prompting Elicits Reasoning in Large Language Models},
author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and brian ichter and Fei Xia and Ed H. Chi and Quoc V Le and Denny Zhou},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=_VjQlMeSB_J}
}
@inproceedings{
yao2023tree,
title={Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
author={Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik R Narasimhan},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=5Xc1ecxO1h}
}
@inproceedings{Besta2023GraphOT,
  title={Graph of Thoughts: Solving Elaborate Problems with Large Language Models},
  author={Maciej Besta and Nils Blach and Ale{\vs} Kub{\'i}{\vc}ek and Robert Gerstenberger and Lukas Gianinazzi and Joanna Gajda and Tomasz Lehmann and Michal Podstawski and Hubert Niewiadomski and Piotr Nyczyk and Torsten Hoefler},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:261030303}
}
@inproceedings{wilf-etal-2024-think,
    title = "Think Twice: Perspective-Taking Improves Large Language Models' Theory-of-Mind Capabilities",
    author = "Wilf, Alex  and
      Lee, Sihyun  and
      Liang, Paul Pu  and
      Morency, Louis-Philippe",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.451/",
    doi = "10.18653/v1/2024.acl-long.451",
    pages = "8292--8308",
}
@article{xu2023exploring,
  title={Exploring large language models for communication games: An empirical study on werewolf},
  author={Xu, Yuzhuang and Wang, Shuo and Li, Peng and Luo, Fuwen and Wang, Xiaolong and Liu, Weidong and Liu, Yang},
  journal={arXiv preprint arXiv:2309.04658},
  year={2023}
}
@article{fu2023improving,
  title={Improving language model negotiation with self-play and in-context learning from ai feedback},
  author={Fu, Yao and Peng, Hao and Khot, Tushar and Lapata, Mirella},
  journal={arXiv preprint arXiv:2305.10142},
  year={2023}
}
@article{shinn2024reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{turpin2024language,
  title={Language models don't always say what they think: unfaithful explanations in chain-of-thought prompting},
  author={Turpin, Miles and Michael, Julian and Perez, Ethan and Bowman, Samuel},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{zeng2023agenttuning,
  title={Agenttuning: Enabling generalized agent abilities for llms},
  author={Zeng, Aohan and Liu, Mingdao and Lu, Rui and Wang, Bowen and Liu, Xiao and Dong, Yuxiao and Tang, Jie},
  journal={arXiv preprint arXiv:2310.12823},
  year={2023}
}
@article{chen2023fireact,
  title={Fireact: Toward language agent fine-tuning},
  author={Chen, Baian and Shu, Chang and Shareghi, Ehsan and Collier, Nigel and Narasimhan, Karthik and Yao, Shunyu},
  journal={arXiv preprint arXiv:2310.05915},
  year={2023}
}
@inproceedings{he-etal-2024-planning,
    title = "Planning Like Human: A Dual-process Framework for Dialogue Planning",
    author = "He, Tao  and
      Liao, Lizi  and
      Cao, Yixin  and
      Liu, Yuanxing  and
      Liu, Ming  and
      Chen, Zerui  and
      Qin, Bing",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.262/",
    doi = "10.18653/v1/2024.acl-long.262",
    pages = "4768--4791",
}
@article{
wang2024voyager,
title={Voyager: An Open-Ended Embodied Agent with Large Language Models},
author={Guanzhi Wang and Yuqi Xie and Yunfan Jiang and Ajay Mandlekar and Chaowei Xiao and Yuke Zhu and Linxi Fan and Anima Anandkumar},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2024},
url={https://openreview.net/forum?id=ehfRiF0R3a},
note={}
}

@InProceedings{pmlr-v235-zhou24t,
  title = 	 {{A}r{CH}er: Training Language Model Agents via Hierarchical Multi-Turn {RL}},
  author =       {Zhou, Yifei and Zanette, Andrea and Pan, Jiayi and Levine, Sergey and Kumar, Aviral},
  booktitle = 	 {Proceedings of the 41st International Conference on Machine Learning},
  pages = 	 {62178--62209},
  year = 	 {2024},
  editor = 	 {Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix},
  volume = 	 {235},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {21--27 Jul},
  publisher =    {PMLR},
}
@inproceedings{
shani2024multiturn,
title={Multi-turn Reinforcement Learning with Preference Human Feedback},
author={Lior Shani and Aviv Rosenberg and Asaf Cassel and Oran Lang and Daniele Calandriello and Avital Zipori and Hila Noga and Orgad Keller and Bilal Piot and Idan Szpektor and Avinatan Hassidim and Yossi Matias and Remi Munos},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=rVSc3HIZS4}
}
@article{zhu2023ghost,
  title={Ghost in the minecraft: Generally capable agents for open-world environments via large language models with text-based knowledge and memory},
  author={Zhu, Xizhou and Chen, Yuntao and Tian, Hao and Tao, Chenxin and Su, Weijie and Yang, Chenyu and Huang, Gao and Li, Bin and Lu, Lewei and Wang, Xiaogang and others},
  journal={arXiv preprint arXiv:2305.17144},
  year={2023}
}
@article{ge2023openagi,
  title={Openagi: When llm meets domain experts},
  author={Ge, Yingqiang and Hua, Wenyue and Mei, Kai and Tan, Juntao and Xu, Shuyuan and Li, Zelong and Zhang, Yongfeng and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={5539--5568},
  year={2023}
}
@article{putta2024agent,
  title={Agent q: Advanced reasoning and learning for autonomous ai agents},
  author={Putta, Pranav and Mills, Edmund and Garg, Naman and Motwani, Sumeet and Finn, Chelsea and Garg, Divyansh and Rafailov, Rafael},
  journal={arXiv preprint arXiv:2408.07199},
  year={2024}
}
@article{xu2023language,
  title={Language agents with reinforcement learning for strategic play in the werewolf game},
  author={Xu, Zelai and Yu, Chao and Fang, Fei and Wang, Yu and Wu, Yi},
  journal={arXiv preprint arXiv:2310.18940},
  year={2023}
}
@article{wang2024cooperative,
  title={Cooperative Strategic Planning Enhances Reasoning Capabilities in Large Language Models},
  author={Wang, Danqing and Ye, Zhuorui and Fang, Fei and Li, Lei},
  journal={arXiv preprint arXiv:2410.20007},
  year={2024}
}
@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}
@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{gulcehre2023reinforced,
  title={Reinforced self-training (rest) for language modeling},
  author={Gulcehre, Caglar and Paine, Tom Le and Srinivasan, Srivatsan and Konyushkova, Ksenia and Weerts, Lotte and Sharma, Abhishek and Siddhant, Aditya and Ahern, Alex and Wang, Miaosen and Gu, Chenjie and others},
  journal={arXiv preprint arXiv:2308.08998},
  year={2023}
}
@article{guan2024deliberative,
  title={Deliberative alignment: Reasoning enables safer language models},
  author={Guan, Melody Y and Joglekar, Manas and Wallace, Eric and Jain, Saachi and Barak, Boaz and Heylar, Alec and Dias, Rachel and Vallone, Andrea and Ren, Hongyu and Wei, Jason and others},
  journal={arXiv preprint arXiv:2412.16339},
  year={2024}
}
@article{kumar2024training,
  title={Training language models to self-correct via reinforcement learning},
  author={Kumar, Aviral and Zhuang, Vincent and Agarwal, Rishabh and Su, Yi and Co-Reyes, John D and Singh, Avi and Baumli, Kate and Iqbal, Shariq and Bishop, Colton and Roelofs, Rebecca and others},
  journal={arXiv preprint arXiv:2409.12917},
  year={2024}
}
@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@inproceedings{suzgun-etal-2023-challenging,
    title = "Challenging {BIG}-Bench Tasks and Whether Chain-of-Thought Can Solve Them",
    author = {Suzgun, Mirac  and
      Scales, Nathan  and
      Sch{\"a}rli, Nathanael  and
      Gehrmann, Sebastian  and
      Tay, Yi  and
      Chung, Hyung Won  and
      Chowdhery, Aakanksha  and
      Le, Quoc  and
      Chi, Ed  and
      Zhou, Denny  and
      Wei, Jason},
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.824/",
    doi = "10.18653/v1/2023.findings-acl.824",
    pages = "13003--13051",
}
@inproceedings{10.5555/3491440.3491941,
author = {Liu, Jian and Cui, Leyang and Liu, Hanmeng and Huang, Dandan and Wang, Yile and Zhang, Yue},
title = {LogiQA: a challenge dataset for machine reading comprehension with logical reasoning},
year = {2021},
isbn = {9780999241165},
booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence},
articleno = {501},
numpages = {7},
location = {Yokohama, Yokohama, Japan},
series = {IJCAI'20}
}
@inproceedings{
lightman2024lets,
title={Let's Verify Step by Step},
author={Hunter Lightman and Vineet Kosaraju and Yuri Burda and Harrison Edwards and Bowen Baker and Teddy Lee and Jan Leike and John Schulman and Ilya Sutskever and Karl Cobbe},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=v8L0pN6EOi}
}
@inproceedings{
bianchi2024how,
title={How Well Can {LLM}s Negotiate? NegotiationArena Platform and Analysis},
author={Federico Bianchi and Patrick John Chia and Mert Yuksekgonul and Jacopo Tagliabue and Dan Jurafsky and James Zou},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=CmOmaxkt8p}
}
@inproceedings{
zhou2024webarena,
title={WebArena: A Realistic Web Environment for Building Autonomous Agents},
author={Shuyan Zhou and Frank F. Xu and Hao Zhu and Xuhui Zhou and Robert Lo and Abishek Sridhar and Xianyi Cheng and Tianyue Ou and Yonatan Bisk and Daniel Fried and Uri Alon and Graham Neubig},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=oKn9c6ytLx}
}
@inproceedings{lewis-etal-2017-deal,
    title = "Deal or No Deal? End-to-End Learning of Negotiation Dialogues",
    author = "Lewis, Mike  and
      Yarats, Denis  and
      Dauphin, Yann  and
      Parikh, Devi  and
      Batra, Dhruv",
    editor = "Palmer, Martha  and
      Hwa, Rebecca  and
      Riedel, Sebastian",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D17-1259/",
    doi = "10.18653/v1/D17-1259",
    pages = "2443--2453",
    abstract = "Much of human dialogue occurs in semi-cooperative settings, where agents with different goals attempt to agree on common decisions. Negotiations require complex communication and reasoning skills, but success is easy to measure, making this an interesting task for AI. We gather a large dataset of human-human negotiations on a multi-issue bargaining task, where agents who cannot observe each other`s reward functions must reach an agreement (or a deal) via natural language dialogue. For the first time, we show it is possible to train end-to-end models for negotiation, which must learn both linguistic and reasoning skills with no annotated dialogue states. We also introduce dialogue rollouts, in which the model plans ahead by simulating possible complete continuations of the conversation, and find that this technique dramatically improves performance. Our code and dataset are publicly available."
}
@inproceedings{
ma2024large,
title={Large Language Models Play StarCraft {II}:Benchmarks and A Chain of Summarization Approach},
author={Weiyu Ma and Qirui Mi and Yongcheng Zeng and Xue Yan and Runji Lin and Yuqiao Wu and Jun Wang and Haifeng Zhang},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=kEPpD7yETM}
}

@article{o2023open,
  title={Open x-embodiment: Robotic learning datasets and rt-x models},
  author={O'Neill, Abby and Rehman, Abdul and Gupta, Abhinav and Maddukuri, Abhiram and Gupta, Abhishek and Padalkar, Abhishek and Lee, Abraham and Pooley, Acorn and Gupta, Agrim and Mandlekar, Ajay and others},
  journal={arXiv preprint arXiv:2310.08864},
  year={2023}
}
@techreport{o1,
    author = {OpenAI},
    title = {Learning to reason with llms},
    institution = {OpenAI},
    year = {2024},
    url= {https://openai.com/index/learning-to-reason-with-llms/}
}
@techreport{qwq,
    author = {Qwen},
    title = {Qwq: Reflect deeply on the boundaries of the unknown},
    institution = {Qwen},
    year = {2024},
    url= {https://qwenlm.github.io/blog/qwq-32b-preview/}
}
@techreport{claude,
    author = {Anthropic},
    title = {Claude 3.5 sonnet},
    institution = {Anthropic},
    year = {2024},
    url= {https://www.anthropic.com/news/claude-3-5-sonnet}
}
@techreport{gemini,
    author = {Google},
    title = {Introducing Gemini 2.0: our new AI model for the agentic era},
    institution = {Google},
    year = {2024},
    url= {https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/?utm_source=deepmind.google&utm_medium=referral&utm_campaign=gdm&utm_content=#ceo-message}
}
@article{guo2025deepseek,
  title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}
@inproceedings{
hu2024uncertainty,
title={Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information Seeking in {LLM}s},
author={Zhiyuan Hu and Chumin Liu and Xidong Feng and Yilun Zhao and See-Kiong Ng and Anh Tuan Luu and Junxian He and Pang Wei Koh and Bryan Hooi},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=CVpuVe1N22}
}
@inproceedings{han-etal-2024-towards,
    title = "Towards Uncertainty-Aware Language Agent",
    author = "Han, Jiuzhou  and
      Buntine, Wray  and
      Shareghi, Ehsan",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.398/",
    doi = "10.18653/v1/2024.findings-acl.398",
    pages = "6662--6685",
}
@article{huyuk2024reasoning,
  title={Reasoning Elicitation in Language Models via Counterfactual Feedback},
  author={H{\"u}y{\"u}k, Alihan and Xu, Xinnuo and Maasch, Jacqueline and Nori, Aditya V and Gonz{\'a}lez, Javier},
  journal={arXiv preprint arXiv:2410.03767},
  year={2024}
}
@article{sun2024enhancing,
  title={Enhancing agent learning through world dynamics modeling},
  author={Sun, Zhiyuan and Shi, Haochen and C{\^o}t{\'e}, Marc-Alexandre and Berseth, Glen and Yuan, Xingdi and Liu, Bang},
  journal={arXiv preprint arXiv:2407.17695},
  year={2024}
}
@inproceedings{
hao2023reasoning,
title={Reasoning with Language Model is Planning with World Model},
author={Shibo Hao and Yi Gu and Haodi Ma and Joshua Jiahua Hong and Zhen Wang and Daisy Zhe Wang and Zhiting Hu},
booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
year={2023},
url={https://openreview.net/forum?id=VTWWvYtF1R}
}
@inproceedings{
madaan2023selfrefine,
title={Self-Refine: Iterative Refinement with Self-Feedback},
author={Aman Madaan and Niket Tandon and Prakhar Gupta and Skyler Hallinan and Luyu Gao and Sarah Wiegreffe and Uri Alon and Nouha Dziri and Shrimai Prabhumoye and Yiming Yang and Shashank Gupta and Bodhisattwa Prasad Majumder and Katherine Hermann and Sean Welleck and Amir Yazdanbakhsh and Peter Clark},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=S37hOerQLB}
}
@inproceedings{yu-etal-2023-prompt,
    title = "Prompt-Based {M}onte-{C}arlo Tree Search for Goal-oriented Dialogue Policy Planning",
    author = "Yu, Xiao  and
      Chen, Maximillian  and
      Yu, Zhou",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.439/",
    doi = "10.18653/v1/2023.emnlp-main.439",
    pages = "7101--7125",
    abstract = "Planning for goal-oriented dialogue often requires simulating future dialogue interactions and estimating task progress. Many approaches thus consider training neural networks to perform look-ahead search algorithms such as A* search and Monte Carlo Tree Search (MCTS). However, this training often require abundant annotated data, which creates challenges when faced with noisy annotations or low-resource settings. We introduce GDP-Zero, an approach using Open-Loop MCTS to perform goal-oriented dialogue policy planning without any model training. GDP-Zero prompts a large language model to act as a policy prior, value function, user simulator, and system model during the tree search. We evaluate GDP-Zero on the goal-oriented task PersuasionForGood, and find that its responses are preferred over ChatGPT up to 59.32{\%} of the time, and are rated more persuasive than ChatGPT during interactive evaluations."
}
@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}
@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}
@techreport{4o,
    author = {OpenAI},
    title = {Hello GPT-4o},
    institution = {OpenAI},
    year = {2024},
    url = {URL https://openai.com/index/hello-gpt-4o/.}
}
@techreport{llama-3.1,
    author = {Meta},
    title = {Introducing Llama 3.1: Our most capable models to date},
    institution = {Meta},
    year = {2024},
    url = {https://ai.meta.com/blog/meta-llama-3-1/}
}
@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}
@article{zhang2024k,
  title={K-Level Reasoning with Large Language Models},
  author={Zhang, Yadong and Mao, Shaoguang and Ge, Tao and Wang, Xun and Xia, Yan and Lan, Man and Wei, Furu},
  journal={arXiv preprint arXiv:2402.01521},
  year={2024}
}
@inproceedings{
liu2024position,
title={Position: Foundation Agents as the Paradigm Shift for Decision Making},
author={Xiaoqian Liu and Xingzhou Lou and Jianbin Jiao and Junge Zhang},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=jzHmElqpPe}
}
@inproceedings{
snell2025scaling,
title={Scaling Test-Time Compute Optimally Can be More Effective than Scaling {LLM} Parameters},
author={Charlie Victor Snell and Jaehoon Lee and Kelvin Xu and Aviral Kumar},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=4FWAwZtd2n}
}
@article{patil2025advancing,
  title={Advancing Reasoning in Large Language Models: Promising Methods and Approaches},
  author={Patil, Avinash},
  journal={arXiv preprint arXiv:2502.03671},
  year={2025}
}
@INPROCEEDINGS{9156851,
  author={Shridhar, Mohit and Thomason, Jesse and Gordon, Daniel and Bisk, Yonatan and Han, Winson and Mottaghi, Roozbeh and Zettlemoyer, Luke and Fox, Dieter},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks}, 
  year={2020},
  volume={},
  number={},
  pages={10737-10746},
  keywords={Task analysis;Visualization;Navigation;Benchmark testing;Natural languages;Robots;Videos},
  doi={10.1109/CVPR42600.2020.01075}}
@article{Liu2019RoBERTaAR,
  title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
  journal={ArXiv},
  year={2019},
  volume={abs/1907.11692},
  url={https://api.semanticscholar.org/CorpusID:198953378}
}
@article{fujimoto2021minimalist,
  title={A minimalist approach to offline reinforcement learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={20132--20145},
  year={2021}
}
@article{Williams2004SimpleSG,
  title={Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
  author={Ronald J. Williams},
  journal={Machine Learning},
  year={2004},
  volume={8},
  pages={229-256},
  url={https://api.semanticscholar.org/CorpusID:2332513}
}
@book{75b5cec4-4f40-3f36-9492-860b8376add8,
 ISBN = {9780691130613},
 URL = {http://www.jstor.org/stable/j.ctt1r2gkx},
 abstract = {This is the classic work upon which modern-day game theory is based. What began more than sixty years ago as a modest proposal that a mathematician and an economist write a short paper together blossomed, in 1944, when Princeton University Press publishedTheory of Games and Economic Behavior. In it, John von Neumann and Oskar Morgenstern conceived a groundbreaking mathematical theory of economic and social organization, based on a theory of games of strategy. Not only would this revolutionize economics, but the entirely new field of scientific inquiry it yielded--game theory--has since been widely used to analyze a host of real-world phenomena from arms races to optimal policy choices of presidential candidates, from vaccination policy to major league baseball salary negotiations. And it is today established throughout both the social sciences and a wide range of other sciences.This sixtieth anniversary edition includes not only the original text but also an introduction by Harold Kuhn, an afterword by Ariel Rubinstein, and reviews and articles on the book that appeared at the time of its original publication in theNew York Times, ttheAmerican Economic Review, and a variety of other publications. Together, these writings provide readers a matchless opportunity to more fully appreciate a work whose influence will yet resound for generations to come.},
 author = {John von Neumann and Oskar Morgenstern and Ariel Rubinstein},
 publisher = {Princeton University Press},
 title = {Theory of Games and Economic Behavior (60th Anniversary Commemorative Edition)},
 urldate = {2025-03-14},
 year = {1944}
}
@article{Shao2024DeepSeekMathPT,
  title={DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models},
  author={Zhihong Shao and Peiyi Wang and Qihao Zhu and Runxin Xu and Jun-Mei Song and Mingchuan Zhang and Y. K. Li and Yu Wu and Daya Guo},
  journal={ArXiv},
  year={2024},
  volume={abs/2402.03300},
  url={https://api.semanticscholar.org/CorpusID:267412607}
}
@article{Patil2025AdvancingRI,
  title={Advancing Reasoning in Large Language Models: Promising Methods and Approaches},
  author={Avinash Patil},
  journal={ArXiv},
  year={2025},
  volume={abs/2502.03671},
  url={https://api.semanticscholar.org/CorpusID:276161258}
}
