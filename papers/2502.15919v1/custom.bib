@inproceedings{owsm,
  title={Reproducing whisper-style training using an open-source toolkit and publicly available data},
  author={Peng, Yifan and Tian, Jinchuan and Yan, Brian and Berrebbi, Dan and Chang, Xuankai and Li, Xinjian and Shi, Jiatong and Arora, Siddhant and Chen, William and Sharma, Roshan and others},
  booktitle={2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={1--8},
  year={2023},
  organization={IEEE}
}

@misc{clark2018thinksolvedquestionanswering,
      title={Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge}, 
      author={Peter Clark and Isaac Cowhey and Oren Etzioni and Tushar Khot and Ashish Sabharwal and Carissa Schoenick and Oyvind Tafjord},
      year={2018},
      eprint={1803.05457},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1803.05457}, 
}

@article{baevski2020wav2vec2,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}

@article{babu2021xls,
  title={XLS-R: Self-supervised cross-lingual speech representation learning at scale},
  author={Babu, Arun and Wang, Changhan and Tjandra, Andros and Lakhotia, Kushal and Xu, Qiantong and Goyal, Naman and Singh, Kritika and Von Platen, Patrick and Saraf, Yatharth and Pino, Juan and others},
  journal={arXiv preprint arXiv:2111.09296},
  year={2021}
}

@inproceedings{few_shot,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
 volume = {33},
 year = {2020}
}

@article{murata1994intrusive,
  title={Intrusive or co-operative? A cross-cultural study of interruption},
  author={Murata, Kumiko},
  journal={Journal of pragmatics},
  volume={21},
  number={4},
  pages={385--400},
  year={1994},
  publisher={Elsevier}
}

@inproceedings{sutton2019voice,
  title={Voice as a design material: Sociophonetic inspired design strategies in human-computer interaction},
  author={Sutton, Selina Jeanne and Foulkes, Paul and Kirk, David and Lawson, Shaun},
  booktitle={Proceedings of the 2019 CHI conference on human factors in computing systems},
  pages={1--14},
  year={2019}
}

@ARTICLE{ubiq_jl,
  author={Wei, Zhuxiaona and Landay, James A.},
  journal={IEEE Pervasive Computing}, 
  title={Evaluating Speech-Based Smart Devices Using New Usability Heuristics}, 
  year={2018},
  volume={17},
  number={2},
  pages={84-96},
  keywords={Ubiquitous computing;Task analysis;Smart devices;Speech recognition;User interfaces;pervasive computing;ubiquitous computing;heuristics;speech user interface;SUI;Spotlight;Internet of Things;IoT},
  doi={10.1109/MPRV.2018.022511249}}


@misc{molmo,
      title={Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Vision-Language Models}, 
      author={Matt Deitke and Christopher Clark and Sangho Lee and Rohun Tripathi and Yue Yang and Jae Sung Park and Mohammadreza Salehi and Niklas Muennighoff and Kyle Lo and Luca Soldaini and Jiasen Lu and Taira Anderson and Erin Bransom and Kiana Ehsani and Huong Ngo and YenSung Chen and Ajay Patel and Mark Yatskar and Chris Callison-Burch and Andrew Head and Rose Hendrix and Favyen Bastani and Eli VanderBilt and Nathan Lambert and Yvonne Chou and Arnavi Chheda and Jenna Sparks and Sam Skjonsberg and Michael Schmitz and Aaron Sarnat and Byron Bischoff and Pete Walsh and Chris Newell and Piper Wolters and Tanmay Gupta and Kuo-Hao Zeng and Jon Borchardt and Dirk Groeneveld and Crystal Nam and Sophie Lebrecht and Caitlin Wittlif and Carissa Schoenick and Oscar Michel and Ranjay Krishna and Luca Weihs and Noah A. Smith and Hannaneh Hajishirzi and Ross Girshick and Ali Farhadi and Aniruddha Kembhavi},
      year={2024},
      eprint={2409.17146},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.17146}, 
}

% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").
@article{ruan2016speech,
  title={Speech is 3x faster than typing for english and mandarin text entry on mobile devices},
  author={Ruan, Sherry and Wobbrock, Jacob O and Liou, Kenny and Ng, Andrew and Landay, James},
  journal={arXiv preprint arXiv:1608.07323},
  year={2016}
}
@article{cavalier1996talking,
  title={Talking instead of typing: Alternate access to computers via speech recognition technology},
  author={Cavalier, Albert R and Ferretti, Ralph P},
  journal={Focus on Autism and Other Developmental Disabilities},
  volume={11},
  number={2},
  pages={79--85},
  year={1996},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@article{chafe1987relation,
  title={The relation between written and spoken language},
  author={Chafe, Wallace and Tannen, Deborah},
  journal={Annual review of anthropology},
  volume={16},
  pages={383--407},
  year={1987},
  publisher={JSTOR}
}
@article{wu2023next,
  title={Next-gpt: Any-to-any multimodal llm},
  author={Wu, Shengqiong and Fei, Hao and Qu, Leigang and Ji, Wei and Chua, Tat-Seng},
  journal={arXiv preprint arXiv:2309.05519},
  year={2023}
}
@article{su2023pandagpt,
  title={Pandagpt: One model to instruction-follow them all},
  author={Su, Yixuan and Lan, Tian and Li, Huayang and Xu, Jialu and Wang, Yan and Cai, Deng},
  journal={arXiv preprint arXiv:2305.16355},
  year={2023}
}
@incollection{tomasello2023having,
  title={Having intentions, understanding intentions, and understanding communicative intentions},
  author={Tomasello, Michael},
  booktitle={Developing theories of intention},
  pages={63--76},
  year={2023},
  publisher={Psychology Press}
}
@inproceedings{hasan-etal-2019-ur,
    title = "{UR}-{FUNNY}: A Multimodal Language Dataset for Understanding Humor",
    author = "Hasan, Md Kamrul  and
      Rahman, Wasifur  and
      Bagher Zadeh, AmirAli  and
      Zhong, Jianyuan  and
      Tanveer, Md Iftekhar  and
      Morency, Louis-Philippe  and
      Hoque, Mohammed (Ehsan)",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1211/",
    doi = "10.18653/v1/D19-1211",
    pages = "2046--2056",
    abstract = "Humor is a unique and creative communicative behavior often displayed during social interactions. It is produced in a multimodal manner, through the usage of words (text), gestures (visual) and prosodic cues (acoustic). Understanding humor from these three modalities falls within boundaries of multimodal language; a recent research trend in natural language processing that models natural language as it happens in face-to-face communication. Although humor detection is an established research area in NLP, in a multimodal context it has been understudied. This paper presents a diverse multimodal dataset, called UR-FUNNY, to open the door to understanding multimodal language used in expressing humor. The dataset and accompanying studies, present a framework in multimodal humor detection for the natural language processing community. UR-FUNNY is publicly available for research."
}
@inproceedings{castro-etal-2019-towards,
    title = "Towards Multimodal Sarcasm Detection (An {\_}{O}bviously{\_} Perfect Paper)",
    author = "Castro, Santiago  and
      Hazarika, Devamanyu  and
      P{\'e}rez-Rosas, Ver{\'o}nica  and
      Zimmermann, Roger  and
      Mihalcea, Rada  and
      Poria, Soujanya",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1455/",
    doi = "10.18653/v1/P19-1455",
    pages = "4619--4629",
    abstract = "Sarcasm is often expressed through several verbal and non-verbal cues, e.g., a change of tone, overemphasis in a word, a drawn-out syllable, or a straight looking face. Most of the recent work in sarcasm detection has been carried out on textual data. In this paper, we argue that incorporating multimodal cues can improve the automatic classification of sarcasm. As a first step towards enabling the development of multimodal approaches for sarcasm detection, we propose a new sarcasm dataset, Multimodal Sarcasm Detection Dataset (MUStARD), compiled from popular TV shows. MUStARD consists of audiovisual utterances annotated with sarcasm labels. Each utterance is accompanied by its context of historical utterances in the dialogue, which provides additional information on the scenario where the utterance occurs. Our initial results show that the use of multimodal information can reduce the relative error rate of sarcasm detection by up to 12.9{\%} in F-score when compared to the use of individual modalities. The full dataset is publicly available for use at \url{https://github.com/soujanyaporia/MUStARD}."
}
@article{wu2024speaker,
  title={Speaker effects in spoken language comprehension},
  author={Wu, Hanlin and Cai, Zhenguang G},
  journal={arXiv preprint arXiv:2412.07238},
  year={2024}
}
@article{jensen2016affect,
  title={Affect and affordances--The role of action and emotion in social interaction},
  author={Jensen, Thomas Wiben and Pedersen, Sarah Bro},
  journal={Cognitive Semiotics},
  volume={9},
  number={1},
  pages={79--103},
  year={2016},
  publisher={De Gruyter}
}
@misc{ardila2020commonvoicemassivelymultilingualspeech,
      title={Common Voice: A Massively-Multilingual Speech Corpus}, 
      author={Rosana Ardila and Megan Branson and Kelly Davis and Michael Henretty and Michael Kohler and Josh Meyer and Reuben Morais and Lindsay Saunders and Francis M. Tyers and Gregor Weber},
      year={2020},
      eprint={1912.06670},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1912.06670}, 
}
@article{pan2002maximum,
  title={Maximum likelihood estimation},
  author={Pan, Jian-Xin and Fang, Kai-Tai and Pan, Jian-Xin and Fang, Kai-Tai},
  journal={Growth curve models and statistical diagnostics},
  pages={77--158},
  year={2002},
  publisher={Springer}
}
@article{bradley1952rank,
  title={Rank analysis of incomplete block designs: I. The method of paired comparisons},
  author={Bradley, Ralph Allan and Terry, Milton E},
  journal={Biometrika},
  volume={39},
  number={3/4},
  pages={324--345},
  year={1952},
  publisher={JSTOR}
}
@misc{tamkin2024clioprivacypreservinginsightsrealworld,
      title={Clio: Privacy-Preserving Insights into Real-World AI Use}, 
      author={Alex Tamkin and Miles McCain and Kunal Handa and Esin Durmus and Liane Lovitt and Ankur Rathi and Saffron Huang and Alfred Mountfield and Jerry Hong and Stuart Ritchie and Michael Stern and Brian Clarke and Landon Goldberg and Theodore R. Sumers and Jared Mueller and William McEachen and Wes Mitchell and Shan Carter and Jack Clark and Jared Kaplan and Deep Ganguli},
      year={2024},
      eprint={2412.13678},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2412.13678}, 
}
@misc{wang2020covost2massivelymultilingual,
      title={CoVoST 2 and Massively Multilingual Speech-to-Text Translation}, 
      author={Changhan Wang and Anne Wu and Juan Pino},
      year={2020},
      eprint={2007.10310},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2007.10310}, 
}

@misc{veliche2024measuringfairnessspeechrecognition,
      title={Towards measuring fairness in speech recognition: Fair-Speech dataset}, 
      author={Irina-Elena Veliche and Zhuangqun Huang and Vineeth Ayyat Kochaniyan and Fuchun Peng and Ozlem Kalinli and Michael L. Seltzer},
      year={2024},
      eprint={2408.12734},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2408.12734}, 
}
@inproceedings{li2024pedants,
  title={Pedants: Cheap but effective and interpretable answer equivalence},
  author={Li, Zongxia and Mondal, Ishani and Nghiem, Huy and Liang, Yijun and Boyd-Graber, Jordan},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024},
  pages={9373--9398},
  year={2024}
}

@inproceedings{zargham2022want,
  title={“I Want It That Way”: Exploring Users’ Customization and Personalization Preferences for Home Assistants},
  author={Zargham, Nima and Alexandrovsky, Dmitry and Erich, Jan and Wenig, Nina and Malaka, Rainer},
  booktitle={CHI conference on human factors in computing systems extended abstracts},
  pages={1--8},
  year={2022}
}

@article{garza2021artificial,
  title={Artificial Intelligence (AI) Assistant Helpfulness},
  author={Garza, Katelyn and Henley, Katrina and Long, Cameron},
  year={2021}
}
@article{llama3modelcard,

title={Llama 3 Model Card},

author={AI@Meta},

year={2024},

url = {https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md}

}
@misc{radford2022whisper,
  doi = {10.48550/ARXIV.2212.04356},
  url = {https://arxiv.org/abs/2212.04356},
  author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  title = {Robust Speech Recognition via Large-Scale Weak Supervision},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@article{james2017prosody,
  title={Prosody and paralanguage in speech and the social media: The vocal and graphic realisation of affective meaning},
  author={James, Allan},
  journal={Linguistica},
  volume={57},
  number={1},
  pages={137--149},
  year={2017}
}
@article{ao2024sd,
  title={SD-Eval: A Benchmark Dataset for Spoken Dialogue Understanding Beyond Words},
  author={Ao, Junyi and Wang, Yuancheng and Tian, Xiaohai and Chen, Dekun and Zhang, Jun and Lu, Lu and Wang, Yuxuan and Li, Haizhou and Wu, Zhizheng},
  journal={arXiv preprint arXiv:2406.13340},
  year={2024}
}
@article{team2024gemini,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={Team, Gemini and Georgiev, Petko and Lei, Ving Ian and Burnell, Ryan and Bai, Libin and Gulati, Anmol and Tanzer, Garrett and Vincent, Damien and Pan, Zhufeng and Wang, Shibo and others},
  journal={arXiv preprint arXiv:2403.05530},
  year={2024}
}
@article{tang2023salmonn,
  title={Salmonn: Towards generic hearing abilities for large language models},
  author={Tang, Changli and Yu, Wenyi and Sun, Guangzhi and Chen, Xianzhao and Tan, Tian and Li, Wei and Lu, Lu and Ma, Zejun and Zhang, Chao},
  journal={arXiv preprint arXiv:2310.13289},
  year={2023}
}
@article{akinnaso1985similarities,
  title={On the similarities between spoken and written language},
  author={Akinnaso, F Niyi},
  journal={Language and speech},
  volume={28},
  number={4},
  pages={323--359},
  year={1985},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{hurst2024gpt,
  title={Gpt-4o system card},
  author={Hurst, Aaron and Lerer, Adam and Goucher, Adam P and Perelman, Adam and Ramesh, Aditya and Clark, Aidan and Ostrow, AJ and Welihinda, Akila and Hayes, Alan and Radford, Alec and others},
  journal={arXiv preprint arXiv:2410.21276},
  year={2024}
}

@inproceedings{ying2019overview,
  title={An overview of overfitting and its solutions},
  author={Ying, Xue},
  booktitle={Journal of physics: Conference series},
  volume={1168},
  pages={022022},
  year={2019},
  organization={IOP Publishing}
}

@inproceedings{pujari2024statistical,
  title={Statistical Detection of Data Drift in Real-time Social Network Conversations},
  author={Pujari, Chetana and Sumith, N and Pooja, S and Chandrakala, CB and Prabhu, Vibha},
  booktitle={2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT)},
  pages={1--4},
  year={2024},
  organization={IEEE}
}

@inproceedings{radford2023robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International conference on machine learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}

@article{schneider2019wav2vec,
  title={wav2vec: Unsupervised pre-training for speech recognition},
  author={Schneider, Steffen and Baevski, Alexei and Collobert, Ronan and Auli, Michael},
  journal={arXiv preprint arXiv:1904.05862},
  year={2019}
}
@article{pipatanakul2023typhoon,
  title={Typhoon: Thai large language models},
  author={Pipatanakul, Kunat and Jirabovonvisut, Phatrasek and Manakul, Potsawee and Sripaisarnmongkol, Sittipong and Patomwong, Ruangsak and Chokchainant, Pathomporn and Tharnpipitchai, Kasima},
  journal={arXiv preprint arXiv:2312.13951},
  year={2023}
}
@inproceedings{greenberg1996understanding,
  title={Understanding speech understanding: Towards a unified theory of speech perception},
  author={Greenberg, Steven},
  booktitle={Proceedings of the ESCA Tutorial and Advanced Research Workshop on the Auditory Basis of Speech Perception},
  pages={1--8},
  year={1996},
  organization={Keele, England}
}
@inproceedings{lancucki2021fastpitch,
  title={Fastpitch: Parallel text-to-speech with pitch prediction},
  author={{\L}a{\'n}cucki, Adrian},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6588--6592},
  year={2021},
  organization={IEEE}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{zhang2023speechgpt,
  title={Speechgpt: Empowering large language models with intrinsic cross-modal conversational abilities},
  author={Zhang, Dong and Li, Shimin and Zhang, Xin and Zhan, Jun and Wang, Pengyu and Zhou, Yaqian and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2305.11000},
  year={2023}
}

@article{kong2020hifi,
  title={Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis},
  author={Kong, Jungil and Kim, Jaehyeon and Bae, Jaekyoung},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={17022--17033},
  year={2020}
}

@article{gong2023listen,
  title={Listen, think, and understand},
  author={Gong, Yuan and Luo, Hongyin and Liu, Alexander H and Karlinsky, Leonid and Glass, James},
  journal={arXiv preprint arXiv:2305.10790},
  year={2023}
}

@article{chu2023qwen,
  title={Qwen-audio: Advancing universal audio understanding via unified large-scale audio-language models},
  author={Chu, Yunfei and Xu, Jin and Zhou, Xiaohuan and Yang, Qian and Zhang, Shiliang and Yan, Zhijie and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2311.07919},
  year={2023}
}

@article{chu2024qwen2,
  title={Qwen2-audio technical report},
  author={Chu, Yunfei and Xu, Jin and Yang, Qian and Wei, Haojie and Wei, Xipin and Guo, Zhifang and Leng, Yichong and Lv, Yuanjun and He, Jinzheng and Lin, Junyang and others},
  journal={arXiv preprint arXiv:2407.10759},
  year={2024}
}

@article{borsos2023audiolm,
  title={Audiolm: a language modeling approach to audio generation},
  author={Borsos, Zal{\'a}n and Marinier, Rapha{\"e}l and Vincent, Damien and Kharitonov, Eugene and Pietquin, Olivier and Sharifi, Matt and Roblek, Dominik and Teboul, Olivier and Grangier, David and Tagliasacchi, Marco and others},
  journal={IEEE/ACM transactions on audio, speech, and language processing},
  volume={31},
  pages={2523--2533},
  year={2023},
  publisher={IEEE}
}

@article{liu2023audioldm,
  title={Audioldm: Text-to-audio generation with latent diffusion models},
  author={Liu, Haohe and Chen, Zehua and Yuan, Yi and Mei, Xinhao and Liu, Xubo and Mandic, Danilo and Wang, Wenwu and Plumbley, Mark D},
  journal={arXiv preprint arXiv:2301.12503},
  year={2023}
}

@article{held2024distilling,
  title={Distilling an end-to-end voice assistant without instruction training data},
  author={Held, William and Li, Ella and Ryan, Michael and Shi, Weiyan and Zhang, Yanzhe and Yang, Diyi},
  journal={arXiv preprint arXiv:2410.02678},
  year={2024}
}

@inproceedings{panayotov2015librispeech,
  title={Librispeech: an asr corpus based on public domain audio books},
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5206--5210},
  year={2015},
  organization={IEEE}
}

@article{ardila2019common,
  title={Common voice: A massively-multilingual speech corpus},
  author={Ardila, Rosana and Branson, Megan and Davis, Kelly and Henretty, Michael and Kohler, Michael and Meyer, Josh and Morais, Reuben and Saunders, Lindsay and Tyers, Francis M and Weber, Gregor},
  journal={arXiv preprint arXiv:1912.06670},
  year={2019}
}

@misc{bastianelli2020slurpspokenlanguageunderstanding,
      title={SLURP: A Spoken Language Understanding Resource Package}, 
      author={Emanuele Bastianelli and Andrea Vanzo and Pawel Swietojanski and Verena Rieser},
      year={2020},
      eprint={2011.13205},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2011.13205}, 
}

@article{wang2020covost,
  title={Covost: A diverse multilingual speech-to-text translation corpus},
  author={Wang, Changhan and Pino, Juan and Wu, Anne and Gu, Jiatao},
  journal={arXiv preprint arXiv:2002.01320},
  year={2020}
}

@inproceedings{wang2021covost,
  title={CoVoST 2 and Massively Multilingual Speech Translation.},
  author={Wang, Changhan and Wu, Anne and Gu, Jiatao and Pino, Juan},
  booktitle={Interspeech},
  pages={2247--2251},
  year={2021}
}

@article{jia2022cvss,
  title={CVSS corpus and massively multilingual speech-to-speech translation},
  author={Jia, Ye and Ramanovich, Michelle Tadmor and Wang, Quan and Zen, Heiga},
  journal={arXiv preprint arXiv:2201.03713},
  year={2022}
}

@article{poria2018meld,
  title={Meld: A multimodal multi-party dataset for emotion recognition in conversations},
  author={Poria, Soujanya and Hazarika, Devamanyu and Majumder, Navonil and Naik, Gautam and Cambria, Erik and Mihalcea, Rada},
  journal={arXiv preprint arXiv:1810.02508},
  year={2018}
}

@article{busso2008iemocap,
  title={IEMOCAP: Interactive emotional dyadic motion capture database},
  author={Busso, Carlos and Bulut, Murtaza and Lee, Chi-Chun and Kazemzadeh, Abe and Mower, Emily and Kim, Samuel and Chang, Jeannette N and Lee, Sungbok and Narayanan, Shrikanth S},
  journal={Language resources and evaluation},
  volume={42},
  pages={335--359},
  year={2008},
  publisher={Springer}
}

@article{faisal2021sd,
  title={SD-QA: Spoken dialectal question answering for the real world},
  author={Faisal, Fahim and Keshava, Sharlina and Anastasopoulos, Antonios and others},
  journal={arXiv preprint arXiv:2109.12072},
  year={2021}
}

@misc{siq2,
  author = {Alex Wilf and Leena Mathur and Sheryl Mathew and Claire Ko and Youssouf Kebe and Paul Pu Liang and Louis-Philippe Morency},
  title = {Social-IQ 2.0 Challenge: Benchmarking Multimodal Social Understanding},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/abwilf/Social-IQ-2.0-Challenge}},
}

@article{wu2023heysquad,
  title={HeySQuAD: A Spoken Question Answering Dataset},
  author={Wu, Yijing and Rallabandi, SaiKrishna and Srinivasamurthy, Ravisutha and Dakle, Parag Pravin and Gon, Alolika and Raghavan, Preethi},
  journal={arXiv preprint arXiv:2304.13689},
  year={2023}
}

@inproceedings{drossos2020clotho,
  title={Clotho: An audio captioning dataset},
  author={Drossos, Konstantinos and Lipping, Samuel and Virtanen, Tuomas},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={736--740},
  year={2020},
  organization={IEEE}
}

@inproceedings{kim2019audiocaps,
  title={Audiocaps: Generating captions for audios in the wild},
  author={Kim, Chris Dongjoo and Kim, Byeongchang and Lee, Hyunmin and Kim, Gunhee},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={119--132},
  year={2019}
}

@inproceedings{li2022learning,
  title={Learning to answer questions in dynamic audio-visual scenarios},
  author={Li, Guangyao and Wei, Yake and Tian, Yapeng and Xu, Chenliang and Wen, Ji-Rong and Hu, Di},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19108--19118},
  year={2022}
}

@article{agostinelli2023musiclm,
  title={Musiclm: Generating music from text},
  author={Agostinelli, Andrea and Denk, Timo I and Borsos, Zal{\'a}n and Engel, Jesse and Verzetti, Mauro and Caillon, Antoine and Huang, Qingqing and Jansen, Aren and Roberts, Adam and Tagliasacchi, Marco and others},
  journal={arXiv preprint arXiv:2301.11325},
  year={2023}
}

@article{yang2024air,
  title={AIR-Bench: Benchmarking Large Audio-Language Models via Generative Comprehension},
  author={Yang, Qian and Xu, Jin and Liu, Wenrui and Chu, Yunfei and Jiang, Ziyue and Zhou, Xiaohuan and Leng, Yichong and Lv, Yuanjun and Zhao, Zhou and Zhou, Chang and others},
  journal={arXiv preprint arXiv:2402.07729},
  year={2024}
}

@article{wang2024audiobench,
  title={Audiobench: A universal benchmark for audio large language models},
  author={Wang, Bin and Zou, Xunlong and Lin, Geyu and Sun, Shuo and Liu, Zhuohan and Zhang, Wenyu and Liu, Zhengyuan and Aw, AiTi and Chen, Nancy F},
  journal={arXiv preprint arXiv:2406.16020},
  year={2024}
}

@article{chen2024voicebench,
  title={Voicebench: Benchmarking llm-based voice assistants},
  author={Chen, Yiming and Yue, Xianghu and Zhang, Chen and Gao, Xiaoxue and Tan, Robby T and Li, Haizhou},
  journal={arXiv preprint arXiv:2410.17196},
  year={2024}
}

@article{oren2023proving,
  title={Proving test set contamination in black box language models},
  author={Oren, Yonatan and Meister, Nicole and Chatterji, Niladri and Ladhak, Faisal and Hashimoto, Tatsunori B},
  journal={arXiv preprint arXiv:2310.17623},
  year={2023}
}

@article{lin2024wildbench,
  title={WILDBENCH: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild},
  author={Lin, Bill Yuchen and Deng, Yuntian and Chandu, Khyathi and Brahman, Faeze and Ravichander, Abhilasha and Pyatkin, Valentina and Dziri, Nouha and Bras, Ronan Le and Choi, Yejin},
  journal={arXiv preprint arXiv:2406.04770},
  year={2024}
}

@article{mallick2022matchmaker,
  title={Matchmaker: Data drift mitigation in machine learning for large-scale systems},
  author={Mallick, Ankur and Hsieh, Kevin and Arzani, Behnaz and Joshi, Gauri},
  journal={Proceedings of Machine Learning and Systems},
  volume={4},
  pages={77--94},
  year={2022}
}

@article{Clark_2019,
   title={The State of Speech in HCI: Trends, Themes and Challenges},
   volume={31},
   ISSN={1873-7951},
   url={http://dx.doi.org/10.1093/iwc/iwz016},
   DOI={10.1093/iwc/iwz016},
   number={4},
   journal={Interacting with Computers},
   publisher={Oxford University Press (OUP)},
   author={Clark, Leigh and Doyle, Philip and Garaialde, Diego and Gilmartin, Emer and Schlögl, Stephan and Edlund, Jens and Aylett, Matthew and Cabral, João and Munteanu, Cosmin and Edwards, Justin and R Cowan, Benjamin},
   year={2019},
   month=jun, pages={349–371} }


@misc{boubdir2023elouncoveredrobustnessbest,
      title={Elo Uncovered: Robustness and Best Practices in Language Model Evaluation}, 
      author={Meriem Boubdir and Edward Kim and Beyza Ermis and Sara Hooker and Marzieh Fadaee},
      year={2023},
      eprint={2311.17295},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.17295}, 
}

@misc{bai2022traininghelpfulharmlessassistant,
      title={Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback}, 
      author={Yuntao Bai and Andy Jones and Kamal Ndousse and Amanda Askell and Anna Chen and Nova DasSarma and Dawn Drain and Stanislav Fort and Deep Ganguli and Tom Henighan and Nicholas Joseph and Saurav Kadavath and Jackson Kernion and Tom Conerly and Sheer El-Showk and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Tristan Hume and Scott Johnston and Shauna Kravec and Liane Lovitt and Neel Nanda and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Ben Mann and Jared Kaplan},
      year={2022},
      eprint={2204.05862},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2204.05862}, 
}

@misc{hendrycks2021measuringmassivemultitasklanguage,
      title={Measuring Massive Multitask Language Understanding}, 
      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
      year={2021},
      eprint={2009.03300},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2009.03300}, 
}

@misc{zheng2023judgingllmasajudgemtbenchchatbot,
      title={Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena}, 
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric P. Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
      year={2023},
      eprint={2306.05685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.05685}, 
}

@misc{dubois2024alpacafarmsimulationframeworkmethods,
      title={AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback}, 
      author={Yann Dubois and Xuechen Li and Rohan Taori and Tianyi Zhang and Ishaan Gulrajani and Jimmy Ba and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto},
      year={2024},
      eprint={2305.14387},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.14387}, 
}

@misc{dubois2024lengthcontrolledalpacaevalsimpleway,
      title={Length-Controlled AlpacaEval: A Simple Way to Debias Automatic Evaluators}, 
      author={Yann Dubois and Balázs Galambosi and Percy Liang and Tatsunori B. Hashimoto},
      year={2024},
      eprint={2404.04475},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2404.04475}, 
}

@article{kiela2021dynabench,
  title={Dynabench: Rethinking benchmarking in NLP},
  author={Kiela, Douwe and Bartolo, Max and Nie, Yixin and Kaushik, Divyansh and Geiger, Atticus and Wu, Zhengxuan and Vidgen, Bertie and Prasad, Grusha and Singh, Amanpreet and Ringshia, Pratik and others},
  journal={arXiv preprint arXiv:2104.14337},
  year={2021}
}

@article{wasserman2009high,
  title={High dimensional variable selection},
  author={Wasserman, Larry and Roeder, Kathryn},
  journal={Annals of statistics},
  volume={37},
  number={5A},
  pages={2178},
  year={2009},
  publisher={NIH Public Access}
}


@article{ruan2024observational,
  title={Observational Scaling Laws and the Predictability of Language Model Performance},
  author={Ruan, Yangjun and Maddison, Chris J and Hashimoto, Tatsunori},
  journal={arXiv preprint arXiv:2405.10938},
  year={2024}
}

@misc{zheng2023lmsyschat1m,
      title={LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset}, 
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Tianle Li and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zhuohan Li and Zi Lin and Eric. P Xing and Joseph E. Gonzalez and Ion Stoica and Hao Zhang},
      year={2023},
      eprint={2309.11998},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{abid2019gradio,
  title={Gradio: Hassle-free sharing and testing of [ML] models in the wild},
  author={Abid, Abubakar and Abdalla, Ali and Abid, Ali and Khan, Dawood and Alfozan, Abdulrahman and Zou, James},
  journal={arXiv preprint arXiv:1906.02569},
  year={2019}
}

@article{eyal2021data,
  title={Data quality of platforms and panels for online behavioral research},
  author={Eyal, Peer and David, Rothschild and Andrew, Gordon and Zak, Evernden and Ekaterina, Damer},
  journal={Behavior Research Methods},
  pages={1--20},
  year={2021},
  publisher={Springer}
}

@article{douglas2023data,
  title={Data quality in online human-subjects research: Comparisons between MTurk, Prolific, CloudResearch, Qualtrics, and SONA},
  author={Douglas, Benjamin D and Ewell, Patrick J and Brauer, Markus},
  journal={Plos one},
  volume={18},
  number={3},
  pages={e0279720},
  year={2023},
  publisher={Public Library of Science San Francisco, CA USA}
}

@article{chiang2024chatbot,
  title={Chatbot arena: An open platform for evaluating llms by human preference},
  author={Chiang, Wei-Lin and Zheng, Lianmin and Sheng, Ying and Angelopoulos, Anastasios Nikolas and Li, Tianle and Li, Dacheng and Zhang, Hao and Zhu, Banghua and Jordan, Michael and Gonzalez, Joseph E and others},
  journal={arXiv preprint arXiv:2403.04132},
  year={2024}
}

@article{lu2024wildvision,
  title={WildVision: Evaluating Vision-Language Models in the Wild with Human Preferences},
  author={Lu, Yujie and Jiang, Dongfu and Chen, Wenhu and Wang, William Yang and Choi, Yejin and Lin, Bill Yuchen},
  journal={arXiv preprint arXiv:2406.11069},
  year={2024}
}

@article{bogomolov2024long,
  title={Long Code Arena: a Set of Benchmarks for Long-Context Code Models},
  author={Bogomolov, Egor and Eliseeva, Aleksandra and Galimzyanov, Timur and Glukhov, Evgeniy and Shapkin, Anton and Tigina, Maria and Golubev, Yaroslav and Kovrigin, Alexander and van Deursen, Arie and Izadi, Maliheh and others},
  journal={arXiv preprint arXiv:2406.11612},
  year={2024}
}
fagin2003comparing
@misc{girdhar2023imagebindembeddingspacebind,
      title={ImageBind: One Embedding Space To Bind Them All}, 
      author={Rohit Girdhar and Alaaeldin El-Nouby and Zhuang Liu and Mannat Singh and Kalyan Vasudev Alwala and Armand Joulin and Ishan Misra},
      year={2023},
      eprint={2305.05665},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2305.05665}, 
}
@article{zhou2023webarena,
  title={Webarena: A realistic web environment for building autonomous agents},
  author={Zhou, Shuyan and Xu, Frank F and Zhu, Hao and Zhou, Xuhui and Lo, Robert and Sridhar, Abishek and Cheng, Xianyi and Ou, Tianyue and Bisk, Yonatan and Fried, Daniel and others},
  journal={arXiv preprint arXiv:2307.13854},
  year={2023}
}

@article{magar2022data,
  title={Data contamination: From memorization to exploitation},
  author={Magar, Inbal and Schwartz, Roy},
  journal={arXiv preprint arXiv:2203.08242},
  year={2022}
}



@article{touvron2023llama,
  title={LLaMA: open and efficient foundation language models. arXiv},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM transactions on audio, speech, and language processing},
  volume={29},
  pages={3451--3460},
  year={2021},
  publisher={IEEE}
}

@article{latif2023sparks,
  title={Sparks of large audio models: A survey and outlook},
  author={Latif, Siddique and Shoukat, Moazzam and Shamshad, Fahad and Usama, Muhammad and Ren, Yi and Cuay{\'a}huitl, Heriberto and Wang, Wenwu and Zhang, Xulong and Togneri, Roberto and Cambria, Erik and others},
  journal={arXiv preprint arXiv:2308.12792},
  year={2023}
}

@article{graves2012long,
  title={Long short-term memory},
  author={Graves, Alex and Graves, Alex},
  journal={Supervised sequence labelling with recurrent neural networks},
  pages={37--45},
  year={2012},
  publisher={Springer}
}

@article{sutskever2014sequence,
  title={Sequence to Sequence Learning with Neural Networks},
  author={Sutskever, I},
  journal={arXiv preprint arXiv:1409.3215},
  year={2014}
}

@article{abdel2014convolutional,
  title={Convolutional neural networks for speech recognition},
  author={Abdel-Hamid, Ossama and Mohamed, Abdel-rahman and Jiang, Hui and Deng, Li and Penn, Gerald and Yu, Dong},
  journal={IEEE/ACM Transactions on audio, speech, and language processing},
  volume={22},
  number={10},
  pages={1533--1545},
  year={2014},
  publisher={IEEE}
}


@inproceedings{satyanarayana2018study,
  title={A study of artificial social intelligence in conversational agents},
  author={Satyanarayana, Vibha and Shankar, Shruthi and Sruthi, V and Das, Bhaskarjyoti},
  booktitle={2018 3rd International Conference on Inventive Computation Technologies (ICICT)},
  pages={545--550},
  year={2018},
  organization={IEEE}
}

@article{perez2023data,
  title={Data Drift Analysis In NLP Models},
  author={P{\'e}rez Longa, Iv{\'a}n},
  year={2023}
}

@article{kumar2024opportunities,
  title={Opportunities and Challenges in Data-Centric AI},
  author={Kumar, Sushant and Datta, Sumit and Singh, Vishakha and Singh, Sanjay Kumar and Sharma, Ritesh},
  journal={IEEE Access},
  year={2024},
  publisher={IEEE}
}

@article{lee2022evaluating,
  title={Evaluating human-language model interaction},
  author={Lee, Mina and Srivastava, Megha and Hardy, Amelia and Thickstun, John and Durmus, Esin and Paranjape, Ashwin and Gerard-Ursin, Ines and Li, Xiang Lisa and Ladhak, Faisal and Rong, Frieda and others},
  journal={arXiv preprint arXiv:2212.09746},
  year={2022}
}

@article{cho2024boteval,
  title={BotEval: Facilitating Interactive Human Evaluation},
  author={Cho, Hyundong and Gowda, Thamme and Huang, Yuyang and Lu, Zixun and Tong, Tianli and May, Jonathan},
  journal={arXiv preprint arXiv:2407.17770},
  year={2024}
}

@article{cho2023can,
  title={Can language model moderators improve the health of online discourse?},
  author={Cho, Hyundong and Liu, Shuai and Shi, Taiwei and Jain, Darpan and Rizk, Basem and Huang, Yuyang and Lu, Zixun and Wen, Nuan and Gratch, Jonathan and Ferrara, Emilio and others},
  journal={arXiv preprint arXiv:2311.10781},
  year={2023}
}


@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@inproceedings{bastianelli-etal-2020-slurp,
    title = "{SLURP}: A Spoken Language Understanding Resource Package",
    author = "Bastianelli, Emanuele  and
      Vanzo, Andrea  and
      Swietojanski, Pawel  and
      Rieser, Verena",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.588",
    doi = "10.18653/v1/2020.emnlp-main.588",
    pages = "7252--7262",
    abstract = "Spoken Language Understanding infers semantic meaning directly from audio data, and thus promises to reduce error propagation and misunderstandings in end-user applications. However, publicly available SLU resources are limited. In this paper, we release SLURP, a new SLU package containing the following: (1) A new challenging dataset in English spanning 18 domains, which is substantially bigger and linguistically more diverse than existing datasets; (2) Competitive baselines based on state-of-the-art NLU and ASR systems; (3) A new transparent metric for entity labelling which enables a detailed error analysis for identifying potential areas of improvement. SLURP is available at \url{https://github.com/pswietojanski/slurp}.",
}

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}
