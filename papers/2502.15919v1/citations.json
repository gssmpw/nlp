[
  {
    "index": 0,
    "papers": [
      {
        "key": "schneider2019wav2vec",
        "author": "Schneider, Steffen and Baevski, Alexei and Collobert, Ronan and Auli, Michael",
        "title": "wav2vec: Unsupervised pre-training for speech recognition"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "hsu2021hubert",
        "author": "Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman",
        "title": "Hubert: Self-supervised speech representation learning by masked prediction of hidden units"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "radford2022whisper",
        "author": "Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya",
        "title": "Robust Speech Recognition via Large-Scale Weak Supervision"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "owsm",
        "author": "Peng, Yifan and Tian, Jinchuan and Yan, Brian and Berrebbi, Dan and Chang, Xuankai and Li, Xinjian and Shi, Jiatong and Arora, Siddhant and Chen, William and Sharma, Roshan and others",
        "title": "Reproducing whisper-style training using an open-source toolkit and publicly available data"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "latif2023sparks",
        "author": "Latif, Siddique and Shoukat, Moazzam and Shamshad, Fahad and Usama, Muhammad and Ren, Yi and Cuay{\\'a}huitl, Heriberto and Wang, Wenwu and Zhang, Xulong and Togneri, Roberto and Cambria, Erik and others",
        "title": "Sparks of large audio models: A survey and outlook"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "zhang2023speechgpt",
        "author": "Zhang, Dong and Li, Shimin and Zhang, Xin and Zhan, Jun and Wang, Pengyu and Zhou, Yaqian and Qiu, Xipeng",
        "title": "Speechgpt: Empowering large language models with intrinsic cross-modal conversational abilities"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "hsu2021hubert",
        "author": "Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman",
        "title": "Hubert: Self-supervised speech representation learning by masked prediction of hidden units"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "touvron2023llama",
        "author": "Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\\'e}e and Rozi{\\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others",
        "title": "LLaMA: open and efficient foundation language models. arXiv"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "kong2020hifi",
        "author": "Kong, Jungil and Kim, Jaehyeon and Bae, Jaekyoung",
        "title": "Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "gong2023listen",
        "author": "Gong, Yuan and Luo, Hongyin and Liu, Alexander H and Karlinsky, Leonid and Glass, James",
        "title": "Listen, think, and understand"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "chu2023qwen",
        "author": "Chu, Yunfei and Xu, Jin and Zhou, Xiaohuan and Yang, Qian and Zhang, Shiliang and Yan, Zhijie and Zhou, Chang and Zhou, Jingren",
        "title": "Qwen-audio: Advancing universal audio understanding via unified large-scale audio-language models"
      },
      {
        "key": "chu2024qwen2",
        "author": "Chu, Yunfei and Xu, Jin and Yang, Qian and Wei, Haojie and Wei, Xipin and Guo, Zhifang and Leng, Yichong and Lv, Yuanjun and He, Jinzheng and Lin, Junyang and others",
        "title": "Qwen2-audio technical report"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "borsos2023audiolm",
        "author": "Borsos, Zal{\\'a}n and Marinier, Rapha{\\\"e}l and Vincent, Damien and Kharitonov, Eugene and Pietquin, Olivier and Sharifi, Matt and Roblek, Dominik and Teboul, Olivier and Grangier, David and Tagliasacchi, Marco and others",
        "title": "Audiolm: a language modeling approach to audio generation"
      },
      {
        "key": "liu2023audioldm",
        "author": "Liu, Haohe and Chen, Zehua and Yuan, Yi and Mei, Xinhao and Liu, Xubo and Mandic, Danilo and Wang, Wenwu and Plumbley, Mark D",
        "title": "Audioldm: Text-to-audio generation with latent diffusion models"
      },
      {
        "key": "held2024distilling",
        "author": "Held, William and Li, Ella and Ryan, Michael and Shi, Weiyan and Zhang, Yanzhe and Yang, Diyi",
        "title": "Distilling an end-to-end voice assistant without instruction training data"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "panayotov2015librispeech",
        "author": "Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev",
        "title": "Librispeech: an asr corpus based on public domain audio books"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "ardila2019common",
        "author": "Ardila, Rosana and Branson, Megan and Davis, Kelly and Henretty, Michael and Kohler, Michael and Meyer, Josh and Morais, Reuben and Saunders, Lindsay and Tyers, Francis M and Weber, Gregor",
        "title": "Common voice: A massively-multilingual speech corpus"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "wang2020covost",
        "author": "Wang, Changhan and Pino, Juan and Wu, Anne and Gu, Jiatao",
        "title": "Covost: A diverse multilingual speech-to-text translation corpus"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "wang2021covost",
        "author": "Wang, Changhan and Wu, Anne and Gu, Jiatao and Pino, Juan",
        "title": "CoVoST 2 and Massively Multilingual Speech Translation."
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "jia2022cvss",
        "author": "Jia, Ye and Ramanovich, Michelle Tadmor and Wang, Quan and Zen, Heiga",
        "title": "CVSS corpus and massively multilingual speech-to-speech translation"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "poria2018meld",
        "author": "Poria, Soujanya and Hazarika, Devamanyu and Majumder, Navonil and Naik, Gautam and Cambria, Erik and Mihalcea, Rada",
        "title": "Meld: A multimodal multi-party dataset for emotion recognition in conversations"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "busso2008iemocap",
        "author": "Busso, Carlos and Bulut, Murtaza and Lee, Chi-Chun and Kazemzadeh, Abe and Mower, Emily and Kim, Samuel and Chang, Jeannette N and Lee, Sungbok and Narayanan, Shrikanth S",
        "title": "IEMOCAP: Interactive emotional dyadic motion capture database"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "faisal2021sd",
        "author": "Faisal, Fahim and Keshava, Sharlina and Anastasopoulos, Antonios and others",
        "title": "SD-QA: Spoken dialectal question answering for the real world"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "siq2",
        "author": "Alex Wilf and Leena Mathur and Sheryl Mathew and Claire Ko and Youssouf Kebe and Paul Pu Liang and Louis-Philippe Morency",
        "title": "Social-IQ 2.0 Challenge: Benchmarking Multimodal Social Understanding"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "wu2023heysquad",
        "author": "Wu, Yijing and Rallabandi, SaiKrishna and Srinivasamurthy, Ravisutha and Dakle, Parag Pravin and Gon, Alolika and Raghavan, Preethi",
        "title": "HeySQuAD: A Spoken Question Answering Dataset"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "wang2024audiobench",
        "author": "Wang, Bin and Zou, Xunlong and Lin, Geyu and Sun, Shuo and Liu, Zhuohan and Zhang, Wenyu and Liu, Zhengyuan and Aw, AiTi and Chen, Nancy F",
        "title": "Audiobench: A universal benchmark for audio large language models"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "yang2024air",
        "author": "Yang, Qian and Xu, Jin and Liu, Wenrui and Chu, Yunfei and Jiang, Ziyue and Zhou, Xiaohuan and Leng, Yichong and Lv, Yuanjun and Zhao, Zhou and Zhou, Chang and others",
        "title": "AIR-Bench: Benchmarking Large Audio-Language Models via Generative Comprehension"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "wang2024audiobench",
        "author": "Wang, Bin and Zou, Xunlong and Lin, Geyu and Sun, Shuo and Liu, Zhuohan and Zhang, Wenyu and Liu, Zhengyuan and Aw, AiTi and Chen, Nancy F",
        "title": "Audiobench: A universal benchmark for audio large language models"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "chen2024voicebench",
        "author": "Chen, Yiming and Yue, Xianghu and Zhang, Chen and Gao, Xiaoxue and Tan, Robby T and Li, Haizhou",
        "title": "Voicebench: Benchmarking llm-based voice assistants"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "ying2019overview",
        "author": "Ying, Xue",
        "title": "An overview of overfitting and its solutions"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "magar2022data",
        "author": "Magar, Inbal and Schwartz, Roy",
        "title": "Data contamination: From memorization to exploitation"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "lin2024wildbench",
        "author": "Lin, Bill Yuchen and Deng, Yuntian and Chandu, Khyathi and Brahman, Faeze and Ravichander, Abhilasha and Pyatkin, Valentina and Dziri, Nouha and Bras, Ronan Le and Choi, Yejin",
        "title": "WILDBENCH: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "oren2023proving",
        "author": "Oren, Yonatan and Meister, Nicole and Chatterji, Niladri and Ladhak, Faisal and Hashimoto, Tatsunori B",
        "title": "Proving test set contamination in black box language models"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "mallick2022matchmaker",
        "author": "Mallick, Ankur and Hsieh, Kevin and Arzani, Behnaz and Joshi, Gauri",
        "title": "Matchmaker: Data drift mitigation in machine learning for large-scale systems"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "kiela2021dynabench",
        "author": "Kiela, Douwe and Bartolo, Max and Nie, Yixin and Kaushik, Divyansh and Geiger, Atticus and Wu, Zhengxuan and Vidgen, Bertie and Prasad, Grusha and Singh, Amanpreet and Ringshia, Pratik and others",
        "title": "Dynabench: Rethinking benchmarking in NLP"
      }
    ]
  },
  {
    "index": 32,
    "papers": [
      {
        "key": "chiang2024chatbot",
        "author": "Chiang, Wei-Lin and Zheng, Lianmin and Sheng, Ying and Angelopoulos, Anastasios Nikolas and Li, Tianle and Li, Dacheng and Zhang, Hao and Zhu, Banghua and Jordan, Michael and Gonzalez, Joseph E and others",
        "title": "Chatbot arena: An open platform for evaluating llms by human preference"
      }
    ]
  },
  {
    "index": 33,
    "papers": [
      {
        "key": "lu2024wildvision",
        "author": "Lu, Yujie and Jiang, Dongfu and Chen, Wenhu and Wang, William Yang and Choi, Yejin and Lin, Bill Yuchen",
        "title": "WildVision: Evaluating Vision-Language Models in the Wild with Human Preferences"
      }
    ]
  },
  {
    "index": 34,
    "papers": [
      {
        "key": "bogomolov2024long",
        "author": "Bogomolov, Egor and Eliseeva, Aleksandra and Galimzyanov, Timur and Glukhov, Evgeniy and Shapkin, Anton and Tigina, Maria and Golubev, Yaroslav and Kovrigin, Alexander and van Deursen, Arie and Izadi, Maliheh and others",
        "title": "Long Code Arena: a Set of Benchmarks for Long-Context Code Models"
      }
    ]
  },
  {
    "index": 35,
    "papers": [
      {
        "key": "zhou2023webarena",
        "author": "Zhou, Shuyan and Xu, Frank F and Zhu, Hao and Zhou, Xuhui and Lo, Robert and Sridhar, Abishek and Cheng, Xianyi and Ou, Tianyue and Bisk, Yonatan and Fried, Daniel and others",
        "title": "Webarena: A realistic web environment for building autonomous agents"
      }
    ]
  }
]