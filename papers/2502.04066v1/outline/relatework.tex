\section{Related Work}
\label{relatework}

\subsection{Pre-training data and LLM capabilities}
The distribution characteristics of pre-training data play a crucial role in shaping the knowledge retention capacity of LLMs. Numerous studies highlight the significance of repetition frequency in this process. For instance, \citet{DBLP:conf/iclr/CarliniIJLTZ23} identified a logarithmic relationship between repetition frequency and memory effects, while \citet{DBLP:journals/jmlr/ChowdheryNDBMRBCSGSSTMRBTSPRDHPBAI23} demonstrated that sequences repeated over 500 times are completed by models with an accuracy exceeding 40\%. Similarly, \citet{DBLP:conf/acl/JuCY0DZL24} investigated the influence of data frequency on multi-hop reasoning, uncovering the presence of ``factual shortcuts''. \citet{DBLP:journals/corr/abs-2404-05405} proposed that exposing knowledge 1000 times can achieve a storage capacity of two bits per parameter in LLMs. Additionally, \citet{DBLP:conf/emnlp/RazeghiL0022} and \citet{DBLP:journals/corr/abs-2311-00871} demonstrated that lower-order co-occurrences in pre-training data enhance numerical reasoning, while \citet{DBLP:journals/corr/abs-2309-13638} associated the prevalence of tasks in pre-training data with better performance on tasks like ROT13.

Although existing research has primarily focused on the impact of occurrence frequency in pre-training data on the memory and reasoning capabilities of LLMs, occurrence-based approaches often lack precision. Moreover, studies aimed at predicting model performance on specific tasks by analyzing pre-training data remain relatively scarce.


\subsection{Evaluating LLMs using knowledge triples}
Knowledge triples (subject, relation, object) play a pivotal role in assessing the storage and retrieval capabilities of LLMs. LLMs derive their knowledge from patterns in their pre-training data. Memory, as defined by~\cite{DBLP:journals/corr/abs-2403-00510}, refers to a model’s ability to encode and retrieve knowledge by adjusting its weights, with its capacity closely tied to model size. \citet{DBLP:conf/emnlp/PetroniRRLBWM19} employed the LAMA method to evaluate the latent knowledge of models like BERT, demonstrating the value of knowledge triples in large-scale reasoning. However, \citet{DBLP:journals/corr/abs-2402-14273} pointed out the limitations of such knowledge triples in reverse reasoning.

Moreover, modular and interconnected memory structures have been described as encoding knowledge in circuits, facilitating tasks such as language processing and reasoning \cite{DBLP:conf/emnlp/WangYXQD00GJX0C24}. \citet{DBLP:conf/acl/JuCY0DZL24} observed that parameter-embedded triples influence reasoning consistency, while \citet{DBLP:conf/icml/Allen-ZhuL24} emphasized the importance of diverse pre-training data and knowledge augmentation for more effective triple extraction. They further highlighted that LLMs flexibly extract and apply knowledge, requiring both knowledge augmentation during training and the use of chains of thought in advanced reasoning tasks to address the complexities of knowledge storage and application.

Overall, knowledge triples are extensively used to evaluate LLMs’ knowledge retention and are a highly effective tool for assessing their broader capabilities.
