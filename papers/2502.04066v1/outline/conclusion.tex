\section{Conclusion}
\label{conclusion}
In this paper, we explore predicting capabilities of base LLMs using only information available prior to pre-training, with a focus on CBQA tasks to address three challenges.

First, most open-source base models do not disclose their complete pre-training data, and the costs of pre-training are prohibitively high. To address this, we allocate substantial resources to pre-training three base models of varying sizes (i.e., 1.6B, 7B, and 13B), ensuring full access to their pre-training data for comprehensive analysis and evaluation.

Second, existing methods for evaluating whether a model has retained specific knowledge often lack fine-grained granularity, making it challenging to accurately assess knowledge retention. To address this, we use knowledge triples to retrieve the pre-training data, and implement a multi-template approach to conduct fine-grained analyses of the CBQA tasks, offering more precise assessments of whether the model has retained specific knowledge.

Third, predicting a model’s retention of task-specific knowledge using only information available prior to training is challenging, as it involves modeling both the characteristics of the data and the model’s memory capacity. To address this challenge, we introduce the SMI metric, which effectively predicts knowledge retention by taking into account the specificity of the knowledge, its occurrence frequency, and the model’s inherent memory capacity.

Our experiments, including validation on TinyLlama 1.1B, reveal a strong linear correlation ($\text{R}^2 > 0.84$) between the SMI metric and ACC on CBQA tasks across models of varying sizes. Based on these findings, we offer practical recommendations for optimizing pre-training strategies, such as refining knowledge distribution in the pre-training data and balancing the relationship between data and model size. To facilitate further research, we are releasing the weights and most of the pre-training data for the 1.6B model. This work provides valuable insights and actionable solutions for advancing predictive techniques in pre-training LLMs.
