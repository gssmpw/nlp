\section{Conclusion}
We propose GE metric, which can effectively identifies the most informative samples without requiring a golden answer. Selecting samples with low GE scores enhances the efficiency and outcomes of prompt engineering and fine-tuning processes for LLMs. Extensive experiments demonstrate the effectiveness of our method, and we finally provides a fresh perspective on the data quality of LLM-agent fine-tuning.

% \section*{Limitations}
%尽管updated guideline大幅提升了api-LLM的性能，但the open-sourced LLM 由于它较弱的指令跟随能力  不能很好的遵从updated guideline。Therefore, this paper propose fine-tuning open-sourced LLMs to mitigate this issue.