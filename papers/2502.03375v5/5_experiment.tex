
\section{Experiments}
In this section, we design experiments to investigate the following fundamental research questions:
\begin{itemize}
    \item [\bf RQ1.] In a real-world dataset, is it a common case that a user likes a set of attributes and a specific configuration but dislikes the visualization resulting from the combination?
    \item [\bf RQ2.] Does the proposed bandit algorithm outperform the state-of-the-art offline method as well as other interactive methods that we adapted to our problem setting?
    \item [\bf RQ3.] Do the hierarchical structure and multi-armed bandit bias improve the performance?
\end{itemize}

\subsection{Experimental Setup} 

In this section, we discuss our experimental setup. 
First, we introduce the baseline algorithms, and then metrics used for evaluation.
\subsubsection{Baselines}
We compare our algorithm with two baseline algorithms that do not properly model the interrelation between the configuration and attributes in a visualization:
\begin{enumerate}
    \item \textbf{LinUCB} ~\cite{chu2011contextual}:  A non-combinatorial contextual bandit algorithm. This comparison demonstrates the Hier-SUCB ability to explore in a combinatorial setting. 
    \item \textbf{C2UCB} ~\cite{qin_contextual_2014}: A combinatorial contextual bandit algorithm. This comparison demonstrates the Hier-SUCB ability of more personalized and faster cold-start recommendation in PVisRec problem. 
    \item \textbf{Neuro-PVR} ~\cite{qian_personalized_2021}: A offline method trained for personalized visualization recommendation with neuro network. This comparison demonstrates the benefits of Hier-SUCB to provide personalized visualization recommendations with minimal samples.
\end{enumerate}

\subsubsection{Metric}
We follow C2UCB ~\cite{qin_contextual_2014} in the definition of cumulative regret and average reward. 
We get average reward of one round by computing the cumulative sum of the mean of the user feedback in each round. Similarly, cumulative regret is computed from the cumulative sum of the mean regret in each round. 
When comparing to the offline method Neuro-PVR ~\cite{qian_personalized_2021}, we compare the HR@K over iterations. 
Recall that HR@K (hit rate at $k$) is the fraction of the top $k$ recommended visualizations that are in the set of visualizations that are actually relevant to the user. 
We compare our method with the offline method Neuro-PVR ~\cite{qian_personalized_2021} as well as with other bandit algorithms.
For comparison, we use HR@1 as the bandit algorithms mentioned are designed for recommending one visualization.
Furthermore, HR@1 is naturally the most important, since it indicates how likely the approaches are to recommend the desired visualization to the user directly.

\subsection{Real-world Dataset}

\subsubsection{Dataset Description}
For our experiments, we used the Plot.ly dataset curated by Qian et al~\cite{qian_personalized_2021}. There are improved dataset Plotly.plus ~\cite{podo2022plotly} which provides better notation of user preference on visualizations, but for fair comparison with Neuro-PVR in ~\cite{qian_personalized_2021}, we keep the same dataset with Qian. The dataset contains information collected from the Plot.ly community, including the number of users, attributes, datasets, visualizations, and visualization configurations extracted from all the user-generated visualizations. The full corpus Plot.ly-full consists of 17469 users with 94419 datasets uploaded by these users. The corpus has a subset of 1000 datasets randomly, notated as Plot.ly-1k. We also take the attribute embedding generated by Qian from Plot.ly, representing the statistical features of attributes ~\cite{qian_personalized_2021}. The embedding provided includes 10-dimensional vector, 30-dimensional vector and a 1004-dimensional vector. 
From the HR@k and NDCG@k metrics, we conclude that 10-dimensional vectors achieve the best performance and use them as the attribute embedding in our experiments.
% perform our method on the 10-dim embedding of vectors. 
% Observe the performance of HR@k and NDCG@k from PVisRec we conclude that 10-dim have the best performance, so we perform our method on the 10-dim embedding of vectors. 

\subsubsection{Preprocess}
Given the Plot.ly data, we further explore other features of the dataset. We derive a histogram as shown in Fig. ~\ref{fig:preprocess}, which describes the distribution of the amount of attributes in different user datasets. We observe a significant long-tail effect that most dataset has less than 100 attributes. Following the preprocess in ~\cite{qian_personalized_2021}, we filter out any dataset with more than 100 attributes. We list all the configurations in the dataset, which has a small armpool.


% \begin{figure}[!ht]
%     \centering
%     \includegraphics[width=0.6\linewidth]{image/hist.pdf}
%     % \hfill
%     \vfill
%     \begin{tabular}{|c|c|c|c|c|} 
%     \hline
%     \multicolumn{5}{|c|}{All Possible Configurations}      \\ 
%     \hline
%     surface & scatter   & scattergl & box     & bar        \\ 
%     \hline
%     mesh3d  & scatter3d & contour   & heatmap & histogram  \\
%     \hline
%     \end{tabular}
%     \captionlistentry[figure]{Distribution of the number of attributes in different user datasets}
%     \captionlistentry[table]{All possible configurations the processed dataset}
%     \vspace{-1em}
%     \captionsetup{labelformat=andtable}
%     \caption{Figure 3 shows the distribution of the number of attributes in different user datasets. Table 1 shows all possible configurations of the processed dataset. The item pool of configuration is relatively small}
%     \vspace{-2em}
%     \label{fig:preprocess}
% \end{figure}
% \begin{figure}[!ht]
%     \centering
%     \begin{minipage}[t]{0.58\linewidth}
%         \centering
%         \includegraphics[width=\linewidth]{image/hist.pdf}
%     \end{minipage}%
%     \hfill
%     \begin{minipage}[t]{0.4\linewidth}
%         \centering
%         \begin{tabular}{|c|c|} 
%         \hline
%         \multicolumn{2}{|c|}{All Possible Configurations}      \\ 
%         \hline
%         surface & scatter   \\ \hline scattergl & box     \\\hline bar        &
        
%         mesh3d  \\\hline scatter3d & contour   \\\hline heatmap & histogram  \\
%         \hline
%         \end{tabular}
% \end{minipage}
%     \captionlistentry[figure]{Distribution of the number of attributes in different user datasets}
%     \captionlistentry[table]{All possible configurations the processed dataset}
%     \captionsetup{labelformat=andtable}
%     \caption{Figure 3 shows the distribution of the number of attributes in different user datasets. Table 1 shows all possible configurations of the processed dataset. The item pool of configuration is relatively small}
%     \label{fig:preprocess}
%     \vspace{-1em} % Adjust vertical spacing if needed
% \end{figure}
\begin{figure}[!ht]
    \centering
    \begin{minipage}[t]{0.5\linewidth}
        \vspace{0pt} % Anchor for top alignment
        \centering
        \includegraphics[width=\linewidth]{image/hist.pdf}
    \end{minipage}%
    \hfill
    \begin{minipage}[t]{0.5\linewidth}
        \vspace{0pt} % Anchor for top alignment
        \centering
        \begin{tabular}{|c|c|} 
        \hline
        \multicolumn{2}{|c|}{All Possible Configurations} \\ 
        \hline
        surface & scatter    \\ 
        \hline 
        scattergl & box      \\ 
        \hline 
        bar & mesh3d         \\ 
        \hline 
        scatter3d & contour  \\ 
        \hline 
        heatmap & histogram  \\
        \hline
        \end{tabular}
    \end{minipage}
    \captionlistentry[figure]{Distribution of the number of attributes in different user datasets}
    \captionlistentry[table]{All possible configurations the processed dataset}
    \captionsetup{labelformat=andtable}
    \vspace{-1em}
    \caption{Figure 3 shows the distribution of the number of attributes in different user datasets. Table 1 shows all possible configurations of the processed dataset. The item pool of configuration is relatively small}
    \Description{On the left there is a figure showing the distribution of the number of attributes in different user datasets. On the right there is a table showing all possible configurations of the processed dataset. It has 10 items in total, which means the item pool of configuration is relatively small}
    \label{fig:preprocess}
    \vspace{-2em} % Adjust vertical spacing if needed
\end{figure}
\subsubsection{Simulator}
To evaluate the performance of our bandit algorithm, we need a simulator that resembles a real user and can react to the multiple-round recommendation from our agent. 
Similar to ~\cite{peng2019practical,zhang2020adaptive}, we build a simulator that gives Bernoulli feedback based on the setting of personalized visualization recommendation described previously. 
The user will provide three kinds of feedback: the feedback on attributes evaluating user preference for attribute pairs, 
the feedback on configurations evaluating user preference for the configurations, and the feedback on the entire visualization. 
The agent receives different rewards separately to update the bandits of attributes and the configuration independently. 
We also add a noise term to the Bernoulli reward provided by the simulator, which gives users a 5\% chance of providing the opposite response.
\subsubsection{User study of simulator}
To validate the performance of simulator in the real life, we conducted a user study based on the visualization generated by algorithms. We first recorded the visualization generated by Hier-SUCB and C2UCB given the feedback of the simulator. Then we recruited 51 participants (university students aged from 18 to 26, 47 of them reported experience of creating visualizations) and recorded their preference on 10 samples randomly selected from those visualizations. As shown in Fig. ~\ref{fig:ustudy_pie} (a), we compared the percentage of user preference in round 20 and 50 of the visualization generated in simulated experiments. From human evaluation, we observed an increase in the percentage that like either of the visualization, which implies the simulator can help bandit algorithms learn user preferences in the real-world setting.
\begin{figure}[b]
    \centering
    \includegraphics[width=\linewidth]{new_plot/area_mosaic.pdf}
    \caption{(a) Our user study shows that from round 20 to 50, the percentage of users that like either visualization increases, indicating the simulator can help bandit algorithms learn user preference.
    (b) In the visualization dataset Plot.ly, even if a user prefers a set of attributes and visual configurations, they may not prefer their combination.}
    \Description{The left figure shows the results of user study. From round 20 to 50, the percentage of users that like either visualization increases, indicating the simulator can help bandit algorithms learn user preference. The right figure shows the user preference of configuration and attributes in the Plot.ly dataset. It shows that even if a user prefers a set of attributes and visual configurations, they may not prefer their combination.}
    \label{fig:ustudy_pie}
\end{figure}




\subsection{Results}

We implement some experiments on the real-world dataset and simulator introduced above. In the following sections, we will introduce how we implement the experiment and how the experiment result gives answers to the research question.

\subsubsection{A Study of Visualizations in the Dataset}
To address RQ1, we perform analysis on the Plot.ly-full dataset to observe whether it is a common case that user likes attributes and configuration but dislikes their visualization. For each user in the dataset, we find all the preferred attributes and configurations. Then we examine the ratio of their combinations in all possible combinations of attributes and configurations. As shown in Fig. ~\ref{fig:ustudy_pie} (b), the combination of preferred attributes and configurations only makes up for 4.1\% of all combinations. 
We further examine the ratio of the preferred visualization in these combinations, and find only 22\% of the combinations are liked by the users as visualizations. This observation indicates that when the agent learns from this dataset, it is highly likely that the configuration and attribute pair liked by the user will not build up a preferred visualization. 


\subsubsection{Performance in Synthetic and Real-world Dataset}
In this section, we compare the performance of bandit algorithms and offline method called Neuro-PVR~\cite{qian_personalized_2021} to show the advantage of online methods. To answer RQ2, we compare the hit rate of bandit algorithms and the offline method in the synthetic and real-world dataset (Plot.ly-1k and Plot.ly-full). We start with building a synthetic setting to simulate the setting of personalized visualization recommendation. As shown in Fig.~\ref{fig:synthetic}, the precision of Hier-SUCB and C2UCB are higher than others. Our method outperforms LinUCB and C2UCB with higher averaged reward. The experiment runs 200 rounds over 100 iterations.
\begin{figure}
	\centering
	\begin{subfigure}{0.48\columnwidth}
		\centering
		\includegraphics[width=\textwidth]{FinePlot/sreward.pdf}
		\caption{Averaged reward}
		\label{fig:sreward}
	\end{subfigure}
	\begin{subfigure}{0.48\columnwidth}
    	\centering
    	\includegraphics[width=\textwidth]{FinePlot/sregret.pdf}
    	\caption{Cumulative Regret}
    	\label{fig:sregret}
	\end{subfigure}
 \vspace{-1em}
	\caption{Comparison of the hit rate using C2UCB, LinUCB, Hier-SUCB in the synthetic data over 100 iterations. Hier-SUCB outperforms other algorithms in 200 rounds.} 
    \Description{Figures showing the hit rate using C2UCB, LinUCB, Hier-SUCB in the synthetic data over 100 iterations. Hier-SUCB outperforms other algorithms in 200 rounds.}
	\label{fig:synthetic}
    \vspace{-1em}
\end{figure}

We move forward to the real-world dataset Plot.ly. It runs 100 rounds for Plot.ly-1k and costs 0.01 second per round with Intel 13700K, and runs 200 rounds for Plot.ly-full. 
As shown in Fig.~\ref{fig:RealWorld}, in both datasets, C2UCB, Hier-SUCB converges and outperforms LinUCB. Also in the few shot setting, Hier-SUCB are higher than other two algorithms. In Plot.ly-1k, the hit rate of Hier-SUCB exceeds Neuro-PVR in 80 rounds, while in Plot.ly-full it exceeds Neuro-PVR in 160 rounds. The experiments validate that Hier-SUCB outperforms other bandit algorithms and the offline method.
\begin{figure}
	\centering
	\begin{subfigure}{0.48\columnwidth}
		\centering
		\includegraphics[width=\textwidth]{FinePlot/reward1.pdf}
		\caption{Plot.ly-1k}
		\label{fig:reward1}
	\end{subfigure}
	\begin{subfigure}{0.48\columnwidth}
    	\centering
    	\includegraphics[width=\textwidth]{FinePlot/reward2.pdf}
    	\caption{Plot.ly-full}
    	\label{fig:reward2}
	\end{subfigure}
 \vspace{-1em}
	\caption{Comparison of the averaged reward (HR@1) using C2UCB, LinUCB, Hier-SUCB and Neuro-PVR (offline method). Hier-SUCB outperforms other bandit algorithms and exceeds the HR@1 of Neuro-PVR in round 80 and 160.}
        \Description{A figure showing the averaged reward (HR@1) using C2UCB, LinUCB, Hier-SUCB and Neuro-PVR (offline method). Hier-SUCB outperforms other bandit algorithms and exceeds the HR@1 of Neuro-PVR in round 80 and 160.}
	\label{fig:RealWorld}
 \vspace{-1em}
\end{figure}

We also conduct a case study of Hier-SUCB. As shown in Fig.~\ref{fig:caseStudy}, we compare visualization recommended by C2UCB and Hier-SUCB in round 1,10,20 and 50. All the visualizations are from the same subset of Plot.ly but evaluated by different users. It shows that the visualization recommended by Hier-SUCB are more likely to be preferred by users, indicating it is more personalized than C2UCB.

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{image/CaseStudy.pdf}
    \vspace{-1em}
    \caption{A case study of the visualizations recommended by Hier-SUCB and C2UCB in round 1,10,20 and 50. The visualizations boxed by red rectangles are labeled as preferred.}
    \Description{A figure showing 5 cases of the visualizations recommended by Hier-SUCB and C2UCB in round 1,10,20 and 50. More visualizations recommended by Hier-SUCB are labeled as preferred compared to C2UCB.}
    \label{fig:caseStudy}
    \vspace{-2em}
\end{figure}

\subsubsection{A Study of Hier-SUCB Variants}
In this section, we do experiments to answer how the hierarchical structure and the bias term in bandit design help the learning process (RQ3). We first compare LinUCB with Hier-SUCB in Fig. ~\ref{fig:RealWorld}. In our experiment setting, LinUCB uses the combination of attributes and configuration as an arm. We observe LinUCB has slower convergence, lower averaged reward and higher cumulative regret over 200 rounds compared to Hier-SUCB. The observation validates our assumption in RQ3 that hierarchical structure helps the agent to learn faster.

To further confirm that the hierarchical structure contributes to the rapid convergence, we compare the average reward and cumulative regret of the original Hier-SUCB, a variation of Hier-SUCB without the hierarchical structure, and another variation that lacks the bias term in Plot.ly-full. In the variation without hierarchical structure, the agent no longer decides the configuration before deciding the visualization, so the visualizations are chosen from $O(nm^2)$ action space. In the variation without bias terms, the feedback provided by user is no longer used to update the bias term. In the experiments shown in Fig.~\ref{fig:var-regret}, we notice that the Hier-SUCB outperforms its variations with no configuration splitting in cumulative regret over 200 iterations. It is worth noting that Hier-SUCB without the bias term encounters hindrances around rounds 70 and 170. As a combinatorial contextual bandit, it is reasonable that Hier-SUCB without bias term is disturbed in the learning process by a biased estimated reward.

\begin{figure}
	\centering
	\begin{subfigure}{0.48\columnwidth}
		\centering
		\includegraphics[width=\textwidth]{FinePlot/vreward.pdf}
		\caption{Averaged Reward}
		\label{fig:var-reward}
	\end{subfigure}
	\begin{subfigure}{0.48\columnwidth}
    	\centering
    	\includegraphics[width=\textwidth]{FinePlot/vregret.pdf}
    	\caption{Cumulative Regret}
    	\label{fig:var-regret}
	\end{subfigure}
 \vspace{-1em}
	\caption{Comparison of the average reward and cumulative regret of Hier-SUCB and its variants Hier-SUCB without bias terms and Hier-SUCB without hierarchical structure. The performance drops when either component is missing.} 
        \Description{A figure showing the average reward and cumulative regret of Hier-SUCB and its variants Hier-SUCB without bias terms and Hier-SUCB without hierarchical structure. The performance drops when either component is missing.}
	\label{fig:varient}
 \vspace{-1em}
\end{figure}

% In this section, we do experiments in Plot.ly and its subset to show how the mapping from configuration to clustering helps the learning process. We compare the reward and regret curves of LinUCB, C2UCB and Hier-SUCB. In the experiments shown in Fig. ~\ref{fig:varient}, we notice that the Hier-SUCB outperforms its variation with no hierarchical structure and its variation with no bias term over 80 iterations in Plot.ly-1k. The experiments comparing Hier-SUCB with other bandit algorithms and offline method Neuro-PVR demonstrates the effectiveness of Hier-SUCB in PVisRec setting. The experiment comparing Hier-SUCB with its variants validates that hierarchical structure improves the exploration of visualization, and the bias term makes up for the gap between the real reward and estimated reward in combinatorial contextual bandits.

In this section, we conduct experiments using Plot.ly and its subset to demonstrate how the configuration-to-clustering mapping aids the learning process. We compare the reward and regret curves of LinUCB, C2UCB, and Hier-SUCB, and Neuro-PVR. We find Hier-SUCB outperforms other bandit algorithms and the offline method in the PVisRec setting. Also, as shown in Fig. ~\ref{fig:varient}, Hier-SUCB outperforms its variants over 80 iterations in Plot.ly-1k. The results confirm that the hierarchical structure enhances visualization exploration, while the bias term reduces the gap between real and estimated rewards in combinatorial contextual bandits.