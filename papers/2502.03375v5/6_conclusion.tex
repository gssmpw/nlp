
\section{Conclusion}
For a more personalized and sample-efficient recommendation of visualization, we formulate a novel combinatorial contextual semi-bandit with hierarchical structure and learnable bias term. 
To narrow the gap between the real reward and the estimated reward, we further model a learnable bias term which measures the relation between configuration and attributes. To apply the combinatorial semi-bandit to the PVisRec setting, we propose a hierarchical bandit structure that receives flexible feedback from users and provides reasonable feedback to the bias term. Combining the learnable bias term and hierarchical bandit structure, we proposed a new approach called Hier-SUCB. We perform a regret analysis on the approach and derive an improved overall regret bound of $O(\sqrt{Tln^3(m^2T ln(T))})$. Through a synthetic experiment and simulated experiments validated by human evaluation, we observe that Hier-SUCB exceeds offline methods in HR@1 in 80 rounds and outperforms traditional bandits with higher rewards and lower cumulative regrets. We also compare Hier-SUCB with its variants in a simulated experiment to demonstrate the effectiveness of the learnable bias term and hierarchical bandit structure.