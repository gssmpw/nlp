Implicit Neural Representations (INRs) employ neural networks to represent continuous functions by mapping coordinates to the corresponding values of the target function, with applications e.g., inverse graphics. 
%
However, INRs face a challenge known as spectral bias when dealing with scenes containing varying frequencies.
%
To overcome spectral bias, the most common approach is the Fourier features-based methods such as positional encoding.
%
However, Fourier features-based methods will introduce noise to output, which degrades their performances when applied to downstream tasks.
%
In response, this paper initially hypothesizes that combining multi-layer perceptrons (MLPs) with Fourier feature embeddings mutually enhances their strengths, yet simultaneously introduces limitations inherent in Fourier feature embeddings.
%
By presenting a simple theorem, we validate our hypothesis, which serves as a foundation for the design of our solution.
%
Leveraging these insights, we propose the use of multi-layer perceptrons (MLPs) without additive terms (referred to as bias-free MLPs) as adaptive linear filters. These bias-free MLPs locally suppress unnecessary frequencies while enriching embedding frequencies, which theoretically reduces the lower bound of the MLPs.
%
Additionally, we propose a line-search-based algorithm to adjust the filter's learning rate dynamically, achieving a balance between the adaptive linear filter module and the INRs which further promote the performance.
%
Extensive experiments demonstrate that our proposed method consistently improves the performance of INRs on typical tasks, including image regression, 3D shape regression, and inverse graphics. The full code will be publicly available.