
\begin{table}
	\centering
	\footnotesize
	\setlength{\tabcolsep}{6pt}
	\begin{tabular}{clccl} 
	\toprule[1.1pt]
	ID & Name & Year & Cash & Occupation \\
	\midrule
	1 & Amy & 1 & 100,000 & AI Researcher \\
	2 & Bruce & 2 & 100,000 & Lawyer \\
	3 & Charles & 1 & 100,000 & Doctor \\
	4 & David & 3 & 100,000 & Engineer \\
	5 & Ella & 2 & 100,000 & Teacher \\
	6 & Frank & 5 & 100,000 & Entrepreneur \\
	7 & Grace & 4 & 100,000 & Accountant \\
	8 & Hank & 2 & 100,000 & Architect \\
	9 & Ivy & 3 & 100,000 & Marketing Manager \\
	$\dots$ & $\dots$ & $\dots$ & $\dots$ & $\dots$\\
	\bottomrule[1.1pt]
	\end{tabular}
	\caption{\textbf{Agent Details.} ``Year'' is the investment duration, and ``Cash'' is the initial capital.} 
	\label{table_person}
	\vspace{-3pt}
\end{table}

\begin{table}
	\centering 
	\footnotesize
	\setlength{\tabcolsep}{5pt}
	\begin{tabular}{ccccc} 
	\toprule[1.1pt] 
	ID & Name & DPS & Historical Close Prices & Quantity \\ 
	\midrule
	1 & A & 22 & 454.17, $\dots$, 445.60 & 1,200 \\
	2 & B & 23 & 354.17, $\dots$, 465.80 & 1,000 \\
	3 & C & 25 & 500.47, $\dots$, 440.60 & 1,600 \\
	$\dots$ & $\dots$ & $\dots$ & $\dots$ & $\dots$\\
	\bottomrule[1.1pt]
	\end{tabular}
	\caption{\textbf{Stock Details.} ``DPS'' is the Dividend Per Share, and ``Quantity'' is the initial share count.} 
	\label{stock}
	\vspace{-3pt}
\end{table}

\section{Experimental Results}

\subsection{Experimental Setup}

\paragraph{Datasets.}

To evaluate the ability of LLMs to analyze and process data, we developed the \textit{Agent Trading Arena}, a controlled environment that isolates external factors. The system's workflow is illustrated in \autoref{fig:AgentArena}. Within this environment, agents discuss stock market trends, analyze stock data, and engage in trading activities. Each agent can execute multiple trades per day and reflect on all trades at the end of each trading session.The \textit{Agent Trading Arena} allows for adjustable numbers of agents and stocks; in our experiment, we deployed at least nine agents and three stocks. All agents were provided with the same initial capital to ensure identical starting conditions. Detailed information about each agent is presented in \autoref{table_person}, and stock-specific data is available in \autoref{stock}. To further validate our findings, we selected a subset of \textsc{NASDAQ Stock} dataset for portfolio investment. For more details, refer to \autoref{appendix_NASDAQ}.

\vspace{-3pt}

\paragraph{Evaluation Metrics.}

Each agent was assigned varying capital based on their roles, and performance was evaluated using the following metrics:

1) \textbf{Total Return (TR):} Measures the overall performance of the strategy, calculated as:
$\mathrm{TR} = {(C_1 - C_0)}/{C_0}$,
where $C_0$ is the initial asset value and $C_1$ is the final asset value.
	
2) \textbf{Win Rate (WR):} Represents the proportion of winning trades, calculated as:
$\mathrm{WR} = {N_w}/{N_t}$, 
where $N_w$ is the number of winning trades and $N_t$ is the total number of trades.
	
3) \textbf{Sharpe Ratio (SR):} Evaluates investment returns relative to risk, calculated as:
$\mathrm{SR} = {(R_p - R_f)}/{\sigma_p}$,
where $R_p$ is the mean daily return, $\sigma_p$ is the standard deviation of daily returns, and $R_f$ is the risk-free return, set to 0 as defined in SocioDojo~\citep{cheng2024sociodojo}.

4) \textbf{Mean Daily Return (Mean):} Indicates the average return per day during the trading period.

5) \textbf{Standard Deviation of Daily Returns (Std):} Reflects the volatility of daily returns, indicating the risk associated with the strategy.

\subsection{Comparative Experiments}

We conducted experiments to assess the real-time data analysis and reasoning capabilities of LLM-based agents, focusing on how textual and visual representations influence decision-making. First, we explored the impact of textual and visual representations in dynamic environments. Next, we incorporated the reflection module to enhance agents' reasoning and data interpretation, examining how reflective reasoning influences decision-making. Finally, we validated the model's effectiveness through stock investment simulations on \textsc{NASDAQ Stock} dataset, assessing agents' adaptability and decision-making in real-world scenarios.


\begin{table*}
	\centering
	\footnotesize
	\setlength{\tabcolsep}{8pt}
	\begin{tabular}{clccrccrr}
	\toprule[1.1pt]
	& LLMs & Textual & Visual & \multicolumn{1}{c}{TR $\uparrow$} & Mean $\uparrow$ & Std $\downarrow$ & \multicolumn{1}{c}{WR $\uparrow$} & \multicolumn{1}{c}{SR $\uparrow$} \\
	\midrule
	\multirow{9}[4]{*}{\rotatebox{90}{\textit{w/o} Reflection}} 
	& {LLaMa-3~\citep{LLaMa3}} & \CIRCLE & \Circle & 4.0934 & 0.6857 & 2.2700 & 62.5001 & 0.1963 \\
	& {DeepSeek~\citep{DeepSeek3v}} & \CIRCLE & \Circle & 27.3078 & 2.2478 & 2.7553 & 92.2078 & 1.5303 \\
	& {Qwen-2.5~\citep{qwen2.5}} & \CIRCLE & \Circle & 30.3740 & 2.6795 & 1.4588 & 93.7500 & 1.7025 \\
	\cmidrule(l){2-9}
	& \multirow{3}{*}{Gemini-1.5~\citep{Gemini1.5}} & \CIRCLE & \Circle & 14.3193 & 1.2210 & 2.7776 & 83.8384 & 1.7293 \\
	& & \Circle & \CIRCLE & 19.0389 & 1.6038 & 1.1654 & 90.9091 & 1.3761 \\
	& & \CIRCLE & \CIRCLE & 23.9649 & 1.9809 & 1.3342 & \textbf{100.0000} & 1.4847 \\
	\cmidrule(l){3-9}
	& \multirow{3}{*}{GPT-4o~\citep{GPT4o}} & \CIRCLE & \Circle & 13.0369 & 1.1386 & 1.9285 & 54.5455 & 0.5904 \\
	& & \Circle & \CIRCLE & 17.0661 & 1.4539 & 1.5040 & 72.7272 & 0.9668 \\
	& & \CIRCLE & \CIRCLE & 26.1806 & 2.1574 & 2.0578 & 90.9091 & 1.0484 \\
	\midrule
	\multirow{9}[4]{*}{\rotatebox{90}{\textit{w/} Reflection}} 
	& {LLaMa-3~\citep{LLaMa3}} & \CIRCLE & \Circle & 10.2458 & 1.6669 & 2.4034 & 66.6667 & 0.6936 \\
	& {DeepSeek~\citep{DeepSeek3v}} & \CIRCLE & \Circle & 30.6238 & 2.4696 & 1.5121 & \textbf{100.0000} & 1.6332 \\
	& {Qwen-2.5~\citep{qwen2.5}} & \CIRCLE & \Circle & 38.9113 & \underline{3.3244} & 1.0726 & \textbf{100.0000} & 3.0994 \\
	\cmidrule(l){2-9}
	& \multirow{3}{*}{Gemini-1.5~\citep{Gemini1.5}} & \CIRCLE & \Circle & 29.4511 & 2.5185 & 3.0116 & 93.5064 & 2.2100 \\
	& & \Circle & \CIRCLE & 37.0054 & 2.9111 & 1.2349 & \textbf{100.0000} & 2.3574 \\
	& & \CIRCLE & \CIRCLE & \underline{41.3264} & 3.1946 & \textbf{0.1588} & \textbf{100.0000} & \textbf{20.1128} \\
	\cmidrule(l){3-9}
	& \multirow{3}{*}{GPT-4o~\citep{GPT4o}} & \CIRCLE & \Circle & 33.6508 & 2.6713 & 2.1711 & 98.7013 & 2.1417 \\
	& & \Circle & \CIRCLE & 35.7622 & 2.8206 & 0.6782 & \textbf{100.0000} & 4.1590 \\
	& & \CIRCLE & \CIRCLE & \textbf{47.6851} & \textbf{3.6095} & \underline{0.5327} & \textbf{100.0000} & \underline{6.7765} \\
	\bottomrule[1.1pt]
	\end{tabular}
	\caption{\textbf{Performance Comparison Using Textual and Visual Data \textit{w/o} and \textit{w/} Reflection.} Evaluation of agent portfolios show that visual approaches outperformed textual ones, with the best results achieved by combining both. LLMs demonstrated a significant advantage in TR and SR, with visual inputs yielding greater improvements than textual inputs. The best and second-best results are highlighted in bold and underlined.}
	\label{LLMS_9agent_reflect}
    \vspace{-3pt}
\end{table*}




\vspace{-3pt}

\paragraph{Trials with Textual or Visual Input.}

To enhance LLMs' understanding of complex data in the \textit{Agent Trading Arena}, we transitioned from textual numerical inputs to visualized formats, including scatter plots, line charts, and bar charts. Three types of visualizations were used: daily K-line charts, transaction histories, and quantities traded by each agent. The experimental setup for the visualization group is shown in \autoref{textual_visualized} and detailed in \autoref{appendix_D}. In the Arena, LLMs without image input capabilities received only text input and did not perform reflection. For image-enabled LLMs, the first agent received only visual input, the second received both textual and visual input, and the others received only textual input. None of the agents had reflection capabilities. For details on the selected LLMs, please refer to \autoref{appendix_F}.

We conducted experiments across different LLMs and the results for Gemini-1.5~\citep{Gemini1.5} and GPT-4o~\citep{GPT4o} in \autoref{LLMS_9agent_reflect} show that agents with visual numerical input outperformed those with textual input alone. Agents receiving both textual and visual input achieved the best performance. This combination enables agents to focus on local details while also understanding overall trends, leading to optimal performance. This suggests that LLMs exhibit better reasoning skills with visual geometric data rather than textual numerical data, highlighting a clear distinction in their strengths in geometry and algebra.

\begin{table}
	\centering
	\footnotesize
	\setlength{\tabcolsep}{9pt}
	\begin{tabular}{lrc}
	\toprule[1.1pt]
	Strategy & \multicolumn{1}{c}{TR $\uparrow$} & SR $\uparrow$ \\
	\midrule
	MACD~\citep{macd} & 7.18 & 0.173 \\
	StockFormer~\citep{stockformer} & 9.05 & 0.073 \\
	TimesNet~\citep{timesnet} & 11.74 & 0.203 \\
	%StockMixer~\citep{stockmixer} & 16.77 & 0.333 \\
	\midrule
	GPT-4o + Textual & 8.69 & 0.167 \\
	GPT-4o + Visual & 9.91 & 0.195 \\
	% GPT-4o + Textual + Visual & 9.02 & 0.201 \\
	GPT-4o + Textual + Visual (Ours) & \textbf{12.23} & \textbf{0.291} \\
	% Textual + Visualized Input + Reflection & \\
	\bottomrule[1.1pt]
	\end{tabular}
	\caption{\textbf{Reproduced Backtesting Performance on \textsc{NASDAQ Stock} Dataset.} The agent with textual and visual input outperformed the NASDAQ-100 by \textbf{53.97\%} in SR during the same period.}
	\label{real_data}
	\vspace{-3pt}
\end{table}

\begin{table}
	\centering
	\footnotesize
	\setlength{\tabcolsep}{10pt}
	\begin{tabular}{lccll}
	\toprule[1.1pt]
	LLMs & T & V & \multicolumn{1}{c}{TR $\uparrow$} & \multicolumn{1}{c}{SR $\uparrow$} \\
	\midrule
	LLaMa-3 & \CIRCLE & \Circle & 100.00 & 100.00 \\
	DeepSeek & \CIRCLE & \Circle & \textbf{+ 35.03} & \textbf{+ 45.63} \\
	\midrule
	\multirow{2}{*}{Gemini-1.5} & \CIRCLE & \Circle & + 10.99 & + 14.93 \\
	& \Circle & \CIRCLE & + 11.49 & + 29.47 \\
	\cmidrule(l){2-5}
	\multirow{2}{*}{GPT-4o} & \CIRCLE & \Circle & + 10.39 & + 28.29	\\
	& \Circle & \CIRCLE & \underline{+ 17.18} & + \underline{40.77} \\
	\bottomrule[1.1pt]
	\end{tabular}
	\caption{\textbf{Performance Comparison in Trading Decisions \textit{w/o} Reflection, Competing Pairwise with LLaMa-3.} DeepSeek may possess unique strengths or optimizations that allow it to better adapt to the task's complexities when competing with other models.}
	\label{ablation_experiment_text_vision}
	\vspace{-3pt}
\end{table}

\begin{table*}
	\centering
	\footnotesize
	\setlength{\tabcolsep}{12pt}
	\begin{tabular}{llllll}
	\toprule[1.1pt]
	LLMs & \multicolumn{1}{c}{TR $\uparrow$} & \multicolumn{1}{c}{Mean $\uparrow$} & \multicolumn{1}{c}{Std $\downarrow$} & \multicolumn{1}{c}{WR $\uparrow$} & \multicolumn{1}{c}{SR $\uparrow$} \\
	\midrule
	LLaMa-3~\citep{LLaMa3} & 100.0000 & 100.0000 & 100.0000 & 100.0000 & 100.0000 \\
%	GPT-3.5~\citep{GPT3.5} & + 6.0067 & + 5.1603 & + 5.3833 & + 23.9437 & + 2.8530 \\
	Gemini-1.5~\citep{Gemini1.5} & + 3.8631 & + 5.9249 & + 12.0426 & - 4.0010 & + 2.2920 \\
 	DeepSeek~\citep{DeepSeek3v} & + 3.1317 & + 3.1309 & \underline{+ 1.7169} & + 9.8039 & + 1.7945 \\
	Qwen-2.5~\citep{qwen2.5} & \underline{+ 7.4578} & \underline{+ 7.3907} & \textbf{- 2.4801} & \textbf{+ 50.0000} & \underline{+ 8.0524} \\
	GPT-4o~\citep{GPT4o} & \textbf{+ 17.7636} & \textbf{+ 16.9041} & + 2.4136 & \underline{+ 37.9310} & \textbf{+ 14.2775} \\
	\bottomrule[1.1pt]
	\end{tabular}
	\caption{\textbf{Performance Comparison in Trading Decisions \textit{w/} Reflection, Competing Pairwise with LLaMa-3 Using Textual Data.} The results show that in competition with reflection using textual numerical data, GPT-4o and Qwen-2.5 outperformed other models.}
	\label{ablation_experiment_LLMs}
	\vspace{-3pt}
\end{table*}

\vspace{-3pt}

\paragraph{Trials with Reflection and Textual or Visual Input.}

Building upon the previous experiments, we incorporated the reflection module to investigate its impact on the experimental outcomes. By introducing this module, we aimed to determine whether reflective processing could improve strategies and adaptability in complex financial scenarios.

Our experiments with diverse LLMs demonstrate that reflective agents consistently outperformed non-reflective agents in stock trading. As shown in \autoref{LLMS_9agent_reflect}, text-only LLMs with reflection modules achieved enhanced returns, with GPT-4o~\citep{GPT4o} reaching 33.65\% total return using textual input alone, which increased to \textbf{47.70\%} with visual data. Combining both input types resulted in a \textbf{41.74\%} higher return compared to using textual input alone. Compared to agents without the reflection module, including the reflection module significantly enhanced each agent's stock investment performance. LLMs with the reflection module showed the greatest improvement in agents with visual inputs, compared to those with textual inputs, in both the Total Return and Sharpe Ratio. This indicates that incorporating reflection further widens the gap between LLMs' geometric reasoning with visual data and algebraic reasoning with textual numerical data, highlighting their strengths in both areas. 



\vspace{-3pt}

\paragraph{Simulation with \textsc{NASDAQ Stock} dataset.}

To further validate our findings, we conducted a two-month investment simulation on \textsc{NASDAQ Stock} dataset, starting with an initial capital of 100,000 units for portfolio investment. \textsc{NASDAQ Stock} dataset from Yahoo Finance spans July 3, 2023, to October 29, 2024, excluding weekends and holidays. Detailed information about the models used is provided in \autoref{appendix_NASDAQ}.

The results in \autoref{real_data} show that, despite StockFormer~\citep{stockformer} and TimesNet~\citep{timesnet}
% , and StockMixer~\citep{stockmixer} 
benefiting from longer training periods and larger datasets, they underperformed compared to our model. Notably, our model achieved superior results without additional training, relying solely on historical stock data for decision-making. The Sharpe ratios for Apple, NASDAQ-100, and S\&P 500 during the same period were 0.097, 0.189, and 0.205, respectively. The agent with textual and visual input outperformed the NASDAQ-100 and S\&P 500 in Sharpe Ratio by \textbf{53.97\%} and \textbf{41.95\%}, respectively. Moreover, only visual input outperformed textual input, further highlighting LLMs' stronger geometric reasoning abilities.

\subsection{Ablation Experiments}


\paragraph{Impact of Modality on LLM Competitiveness.} 

We employed a relative evaluation method for this experiment. The first and second agents used various LLMs in textual and visual settings, respectively, while the remaining agents were based on LLaMa-3~\citep{LLaMa3} as the baseline. This setup aimed to explore the impact of different agents and modalities on LLM performance. The results are shown in \autoref{ablation_experiment_text_vision}. The findings indicate that DeepSeek~\citep{DeepSeek3v} exhibited stronger competitive performance across different LLM environments, suggesting unique strengths or optimizations that enable it to adapt more effectively to the task's complexities.

\vspace{-3pt}

\paragraph{Competition Among Different LLMs with Reflection.} 


To investigate the role of reflection in competition dynamics using textual numerical data between LLMs, we conducted an ablation study in the \textit{Agent Trading Arena}. Using a relative evaluation approach, the first agent employed various LLMs, while eight LLaMa-3-based agents served as the baseline for a fair comparison. This setup effectively isolated the influence of each LLM on performance. As shown in \autoref{ablation_experiment_LLMs}, in competition with reflection, GPT-4o~\citep{GPT4o} and Qwen-2.5~\citep{qwen2.5} outperformed other models, consistent with the findings in \autoref{LLMS_9agent_reflect}.

