
\begin{figure*}
	\centering
	\includegraphics[width = \linewidth]{figure/AgentArena.pdf}
	\caption{\textbf{Stock Trading Workflow in \textit{Agent Trading Arena}.} 
	\textbf{Top:} Workflow of a trading day, including preparation, trading, and post-trading reflection. Agents discuss insights in the chat pool, analyze market trends, execute trades, and refine strategies based on performance.  
	\textbf{Bottom:} Example of agents' interactions in the chat pool and dynamic strategy updates.}
	\label{fig:AgentArena}
	\vspace{-3pt}
\end{figure*}

\section{Proposed Method}

% 核心部分visual representation，

To mitigate the influence of human prior knowledge and memory, we designed a closed-loop economic system~\citep{guo2024economics} called the \textit{Agent Trading Arena}, a zero-sum game simulating complex, quantitative real-world scenarios. The simulation workflow is illustrated in \autoref{fig:AgentArena} and further detailed in \autoref{appendix_arena}. In the \textit{Agent Trading Arena}, agents can invest in assets, earn dividends from holding assets, and pay daily expenses using virtual currency. The agent with the highest total return wins the game.

\subsection{Agent Trading Arena}

\paragraph{Structure of Agent Trading Arena.} 

To eliminate external knowledge biases, asset prices are determined by a bid-ask system, reflecting the prices at which buyers and sellers are willing to transact. The system evolves solely based on agents' actions and interactions, without external influences. This design ensures that the outcomes of agents' actions are not immediately apparent but unfold gradually, influenced by other agents' decisions.

To encourage active participation, a dividend mechanism is introduced. There are two primary sources of income in this system: capital gains from asset price differentials and dividends from holding assets. Dividends for each asset are distributed according to a predefined ratio, serving as an implicit anchor for asset prices. Agents holding more low-cost assets receive higher dividends. To prevent passive asset holding until the end of the game, agents must pay a daily capital cost proportional to their total wealth. These expenses are offset by asset dividends, and only agents with sufficient low-cost assets can cover costs. Under the pressure of significant daily expenses, agents must act swiftly and strategically, triggering frequent trades and price fluctuations to stimulate market activity. This dynamic mechanism ensures fairness in the zero-sum game while preventing agents from relying on fixed strategies to find optimal solutions.

\vspace{-3pt}

\paragraph{Agents Learn and Compete in Arena.}

The zero-sum game structure is crucial to eliminating the possibility of a universally optimal strategy. In fixed scenarios with a static optimal solution, agents could rely on predefined rules or memory-based approaches, bypassing adaptive decision-making. The zero-sum game ensures that there is no universally correct solution, with outcomes evolving dynamically based on agent interactions and competition. This design forces agents to continually adapt, learn from feedback, and develop context-dependent strategies, promoting deeper environmental exploration and preventing reliance on static or memory-driven solutions.

In the \textit{Agent Trading Arena}, agents are unaware of implicit rules, except for the objective to maximize their virtual wealth throughout the simulation. To win this zero-sum game, agents must effectively learn from experience, decipher hidden game rules, and develop strategies to counter competitors. This requires the ability to comprehend numerical feedback, formulate enduring strategies, and make informed decisions. Unlike other mathematical reasoning problems, the results of their actions unfold gradually and dynamically. Moreover, agents are easily misled by erroneous information from competitors, hindering their ability to discern strategic cues from competitors' textual data. Importantly, agents remain unaware of these implicit rules, so applying real-world knowledge does not benefit their performance. Therefore, agents must rely on experiential learning to decipher the hidden game rules and ultimately achieve victory.

\subsection{Types of Numerical Data Input}

\paragraph{Limitations of Textual Numerical Data.}

In the \textit{Agent Trading Arena}, the generated stock data is stored in numerical format. When used directly as input to an LLM, the models often struggle to interpret numerical data accurately or make sound decisions. To mitigate this, we convert the data into textual formats~\citep{numerical_text, long_text}, enhancing semantic features and clarifying output requirements to improve the models' understanding. During interactions, the LLMs process stock prices, trading volumes, and market indices presented as textual numerical data.

\begin{figure*}
	\centering
	\includegraphics[width = \linewidth]{figure/v_t.pdf}
	\caption{\textbf{Textual and Visual Representations of Corresponding Inputs and Outputs.} The left images display the agent’s Buy and Sell trading records, daily trade prices, and K-line charts for three stocks. The output from visual inputs (bottom right) captures overall stock trends and long-term behavior, while the output from textual inputs (top right) focuses on specific current prices.}
	\label{textual_visualized}
	\vspace{-3pt}
\end{figure*}

However, this textual approach reveals significant limitations. While the data is presented clearly, LLMs tend to focus excessively on specific values rather than identifying long-term trends or global patterns. They also struggle with understanding correlative relations and percentage changes, limiting their ability to assess differences and identify connections between data points. When analyzing time-series data with complex patterns, LLMs often fixate on individual data points, overlooking overarching relations. This issue is evident in the analysis output in the top-right corner of \autoref{textual_visualized}, where LLMs' focus on individual values impedes their ability to generalize, reducing their capacity to extract meaningful global insights.

Additionally, LLMs often overemphasize recent data while undervaluing historical information, even when prompted to consider its importance. This prevents them from effectively integrating past data and recognizing long-term patterns, complicating their understanding of numerical relations and trends. These challenges highlight the need for improved mechanisms to process numerical relations, identify global trends, and derive deeper insights from textual numerical data.

\vspace{-3pt}

\paragraph{Potential of Visual Numerical Data.}

Since textual numerical data often leads LLMs to focus on local details while neglecting broader relations, we investigated whether visual representations, such as scatter plots, line charts, and bar charts, could help LLMs better understand overall trends, similar to human reasoning. Thus, we transition from textual numerical data inputs to visualized formats ~\citep{storyllava}. As demonstrated in the bottom-right corner of \autoref{textual_visualized}, visual representations enable LLMs to more effectively grasp global trends, patterns, and relations that are often difficult to discern from textual numerical data alone.

These findings highlight the advantages of structured, visual numerical data, indicating that this format allows LLMs to more intuitively and comprehensively understand complex data, better capturing overall fluctuations, whereas text tends to focus on local details. By combining visualization and textual representations, LLMs not only overcome the challenges of relations in time-series data but also demonstrate better performance in identifying long-term trends and global patterns, while still attending to local details.

\subsection{Reflection Module}

We propose a strategy distillation method, illustrated in \autoref{fig:reflection}, that delivers real-time feedback to LLMs by analyzing both descriptive textual and visual numerical data. This enables the generation of new strategies and optimization of action plans. The approach allows agents to evaluate their results, refine strategies, and adapt continuously based on feedback. The process begins with assessing the day’s trajectory memory and associated strategies using an evaluation function. The strategic generation process leverages contrastive analysis of peak and nadir performers from the evaluation phase, creating bidirectional learning signals that inform subsequent iterations. This iterative cycle ensures continuous strategy evolution, fostering sustained improvement in decision-making.

\begin{figure}[t]
	\centering
	\includegraphics[width = \linewidth]{figure/reflection.pdf}
	\caption{\textbf{Design of the Reflection Module.} The process evaluates daily trajectory memory and strategies (top right), then generates new strategies (center) based on evaluation, environmental feedback (bottom right), and feedback from the 5 top- and bottom-performing strategies. Stock visualization (bottom left) enhances reflection, driving continuous improvement.}
	%The process evaluates daily trajectory memory and strategies, generating new strategies based on positive and negative feedback from the top- and bottom-performing strategies. Stock visualizations (bottom left) further enhance the reflection process, reinforcing continuous strategy refinement.}
	\label{fig:reflection}
	\vspace{-3pt}
\end{figure}

% We propose a strategy distillation method, illustrated in \autoref{fig:reflection}, that provides real-time feedback to LLMs by analyzing both descriptive textual and visualized numerical data. This enables the generation of new strategies and the optimization of action plans. The approach allows agents to assess their results, refine strategies, and continuously adapt based on feedback. The process begins by evaluating the day's trajectory memory and associated strategies using an evaluation function. From this assessment, new strategies are generated by selecting the top-performing and lowest-performing strategies, offering both positive and negative feedback. This iterative cycle ensures continuous strategy evolution, driving sustained improvement in decision-making.

The reflection module plays a crucial role in refining strategies by offering real-time feedback. It analyzes both descriptive textual and visual numerical data to generate new strategies and optimize action plans. Within the \textit{Agent Trading Arena}, the reflection module is triggered regularly to consolidate daily trading records and evaluate the effectiveness of strategies, refining both successful and unsuccessful experiences to guide future decisions. Ineffective strategies are stored in a strategy library for future reference, allowing agents to review and learn from past experiences. Further details can be found in \autoref{appendix_arena}.
