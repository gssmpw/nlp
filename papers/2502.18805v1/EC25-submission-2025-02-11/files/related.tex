
% \subsection{Related Work}
\section{Related Work: Extended Discussion}\label{apx:related}

\iffalse
\subsection{Impossibility Results}
There is a large number of impossibility results regarding truthfulness alongside other desirable properties. \eden{todo }

\textbf{voting:}
With three or more candidates, the Gibbard--Satterthwaite Theorem~\cite{gibbard1973manipulation,satterthwaite1975strategy} implies that the only \eden{efficient?} truthful rules are dictatorships. 
\fi

% \textbf{Indivisible Goods Allocations:}

% \textbf{Cake Cutting:}

% \textbf{Stable Matchings:} Roth 1982 - no mechanism is both stable and truthful for all participants.

% \textbf{Auctions:} Myerson-Satterthwaite 1983 - no mechanism can be truthful, individually rational, budget-balanced, and efficient \eden{to verify}

\subsection{Truthfulness Relaxations}

The large number of impossibility results have lead to extensive research into relaxations of truthfulness. 
A relaxed truthfulness notion usually focuses on a certain subset of all possible manipulations, which are considered more ``likely''. It requires that none of the manipulations from this subset is profitable. Different relaxations consider different subsets of ``likely'' manipulations.


% We compare some of these approaches to RAT.



% ==================================================
\paragraph{RAT}
Closest to our work is the recent paper by \cite{BU2023Rat}, which introduces the definition on which this paper is build upon - \emph{risk-avoiding truthfulness (RAT)}. 
The definition assumes that agents avoid risk - they will manipulate only when it is sometimes beneficial but never harmful. 
We first note that their original term for this concept is risk-\emph{averse} truthfulness. However, since the definition assumes that agents completely avoid any element of risk, we adopt this new name, aiming to more accurately reflect this assumption.

We extend their work in two key directions.
First, we generalize the definition from cake-cutting to any social choice problem. 
Second, we move beyond a binary classification of whether a mechanism is RAT, to a quantitative measure of its robustness to manipulation by such agents. Our new definition provides deeper insight of the mechanism' robustness.
%
In \Cref{sec:cake-cutting}, we also analyze the mechanisms proposed in their paper alongside additional mechanisms for cake-cutting.

Their paper (in Section~5) provides an extensive comparison between RAT of related relaxation of truthfulness. For completeness, we include some of these comparisons here as well.


% ==================================================
\paragraph{Maximin Strategy-Proofness}
Another related relaxation of truthfulness, introduced by \citet{brams2006better}, assumes the opposite extreme to the standard definition regarding the agents' willingness to manipulate. In the standard definition, an agent is assumed to manipulate if for \emph{some} combination of the other agents' reports, it is beneficial. In contrast, this relaxation assumes that an agent will manipulate only if the manipulation is \emph{always} beneficial — i.e., for \emph{any} combination of the other agents' reports. 

This definition is not only weaker than the standard one but also weaker than RAT, as it assumes that agents manipulate in only a subset of the cases where RAT predicts manipulation. 
We believe that, in this sense, RAT provides a more realistic and balanced assumption.
However, we note that a similar approach can be applied to this definition as well — the degree to which a mechanism is robust to always-profitable manipulations (rather than to safe manipulations).
\erel{Say that RAT-degree would probably be higher, as the manipulation is stronger.}


% ==================================================
\paragraph{NOM} 
\citet{troyan2020obvious} introduce the notion of \emph{not-obvious manipulability (NOM)}, which focuses on \emph{obvious manipulation} — informally, a manipulation that benefits the agent either in the worst case or in the best case. It presumes that agents are boundedly rational, and only consider extreme situations --- best or worst cases. A mechanism is NOM if there are no obvious manipulations. % was also considered by \cite{ortega2022obvious}

This notion is a relaxation of truthfulness since the existence of an obvious manipulation imposes a stronger requirement than merely having a profitable one.
\iffalse
Specifically, suppose there exists a manipulation whose best-case utility (i.e., under the most favorable profile of the other agents) is strictly higher than the best-case utility of truthful reporting. Then, in the profile that maximizes the manipulator’s utility when manipulating, the utility from truthful reporting is at most the best-case truthful utility. Since this value is strictly lower than the utility obtained by manipulating in that same profile, it follows that the agent strictly prefers to manipulate. Thus, if a mechanism is not NOM, it necessarily admits some profitable manipulation, implying that it is not truthful.
\fi
\erel{Can we apply our approach to NOM? }

However, an obvious manipulation is not necessarily a \emph{safe} manipulation, nor is a safe manipulation necessarily an obvious one (see Appendix D in \cite{BU2023Rat} for more details). Therefore, NOM and RAT are independent notions.





% \paragraph{Ex-post incentive compatibility} \eden{to find ref} requires truth-telling
% to be optimal ex-post, that is even if the agent learns the true type and actions of all other agents.


% ==================================================
\paragraph{Regret-Free Truth-telling (RFTT)} \citet{regret2018Fernandez} proposes another relaxation of truthfulness, called \emph{regret-free truth-telling}. This concept also considers the agent’s knowledge about other agents but does so in a different way.
Specifically, a mechanism satisfies RFTT if no agent ever regrets telling the truth after observing the outcome -- meaning that she could not have safely manipulated given that only the reports that are consistent with the observed outcome are possible.
Note that the agent does not observe the actual reports of others but only the final outcome (the agents are assumed to know how the mechanism works).


% ============== NOT TRUE
% This definition is weaker than both standard truthfulness and RAT, as it only prevents a certain type of safe manipulations.
% \Cref{sec:deferred-acceptance} demonstrates that RAT is a strictly stronger notion by proving that the well-known deferred acceptance mechanism for stable matching~\cite{gale1962college}, which is known to satisfy RFTT~\cite{regret2018Fernandez}, is not RAT.
% \eden{I would be happy that someone will verify me: This definition is weaker than RAT. right?}


An ex-post-profitable manipulation is always profitable, but the opposite is not true, as it is possible that the profiles in which a manipulation could be profitable are not consistent with the outcome. This means that RFTT does not imply RAT.
%
A safe manipulation is always ex-post-safe, but the opposite is not true, as it is possible that the manipulation is harmful for some profiles that are inconsistent with the outcome. This means that RAT does not imply RFTT.

\erel{Maybe say that we can quantify this by allowing the agent to play many times with different reports.}


\paragraph{Different Types of Risk}
\citet{slinko2008nondictatorial,slinko2014ever} and \citet{hazon2010complexity} study ``safe manipulations'' in voting. Their concept of safety is similar to ours, but allows a simultaneous manipulation by a coalition of voters. They focus on a different type of risk for the manipulators: the risk that too many or too few of them will perform the exact safe manipulation.

\subsection{Alternative Measurements}
% There are other ways to measure the required amount of information.. \eden{todo }
Various measures can be used to quantify the manipulability of a mechanism. Below, we compare some existing approaches with our RAT-degree measure.

% ==================================================
\paragraph{Computational Complexity}
Even when an agent knows the reports of all other agents, it might be hard to compute a profitable manipulation. 
Mechanisms can be ranked according to the run-time complexity of this computation: mechanisms in which a profitable manipulation can be computed in polynomial time are arguably more manipulable than mechanisms in which this problem is NP-hard. 
%\eden{TODO:}
This approach was pioneered by \citet{bartholdi1989computational,bartholdi1991single} for voting, and applied in other social choice settings. See \citet{faliszewski2010ai,veselova2016computational} for surveys.

Nowadays, with the advent of efficient SAT and CSP solvers, NP-hardness does not seem a very good defense against manipulation. Moreover, some empirical studies show that voting rules that are hard to manipulate in theory, may be easy to manipulate in practice  \citep{walsh2011hard}.
We claim that the main difficulty in manipulation is not the computational hardness, but rather the informational hardness --- learning the other agents' preferences. 


\paragraph{Queries and Bits}
Instead of counting the number of agents, we could count the number of \emph{bits} that an agent needs to know in order to have a safe manipulation
(this is similar in spirit to the concepts of communication complexity - e.g., \cite{nisan2002communication, grigorieva2006communication, Communication2019Branzei,Babichenko2019communication} and compilation complexity - e.g., \citep{chevaleyre2009compiling,xia2010compilation,karia2021compilation}).
But this definition may be incomparable between different domains, as the bit length of the input is different.
We could also measure the number of basic queries, rather than the number of agents. But then we have to define what ``basic query'' means, which may require a different definition for each setting. The number of agents is an objective measure that is relevant for all settings.

\iffalse
\paragraph{Compilation Complexity}
The compilation complexity of a mechanism refers to the number of bits required to represent the preferences of a subset of agents in a compressed way, such that the outcome can still be computed correctly for any possible preferences of the remaining agents.
The \emph{compilation complexity} of a voting rule is the amount of bits required to represent the preferences of a subset of the voters in a compressed way, such  that the outcome can be computed correctly, for any preferences of the other voters
\citep{chevaleyre2009compiling,xia2010compilation,karia2021compilation}.%
\footnote{
See Wikipedia page ``Compilation complexity''.
}
We could measure the manipulability of a mechanism by asking how many bits an agent needs in order to have a safe manipulation. But this question has a trivial answer: $1$ bit is sufficient --- a yes/no answer to the question ``is this manipulation profitable?''. 


We measure the manipulability using the number of queried agents rather than compiled queries.
\fi




% ==================================================
\paragraph{Probability of Having Profitable Manipulation.} 
Truthfulness requires that not even a \emph{single} preference-profile allows a profitable manipulation.
Mechanisms can be ranked according to the probability that such a profile exists -- e.g., \citep{barrot2017manipulation,lackner2018approval,lackner2023free}.
The probability of truthful mechanism is zero, and the lower the probability is, the more resistant the mechanism is to profitable manipulations.
% Under this approach, a mechanism is considered more robust if the probability is low. The probability of a truthful mechanism is zero and the lower the probability is, the more resistant the mechanism is to profitable manipulations.

A disadvantage of this approach is that it requires knowledge of the distribution over preference profiles; our RAT-degree does not require it.


\erel{If we do have such information, we can combine it with our approach ...}


\iffalse
% ==================================================
\paragraph{Bayesian Incentive Compatibility}

\fi



% ==================================================
\paragraph{Incentive Ratio} Another common measure is the \emph{incentive ratio} of a mechanism \citet{chen2011profitable}, which describes the extent to which an agent can increase her utility by manipulating. For each agent, it considers the maximum ratio between the utility obtained by manipulating and the utility received by being truthful, given the same profile of the others. The incentive ratio is then defined as the maximum of these values across all agents.

This measure is widely used - e.g., \cite{chen2022incentive,li2024bounding,cheng2022tight,cheng2019improved}.
However, it is meaningful only when utility values have a clear numerical interpretation, such as in monetary settings.
In contrast, our RAT-degree measure applies to any social choice setting, regardless of how utilities are represented.

% ==================================================
\paragraph{Degree of Manipulability}
\citet{aleskerov1999degree} define four different indices of "manipulability" of ranked voting rules, based on the fraction of profiles in which a profitable manipulation exists; the fraction of manipulations that are profitable; and the average and maximum gain per manipulation.
As the indices are very hard to compute, they estimate them on 26 voting rules using computer experiments. These indices are useful under an assumption that all profiles are equally probable (``impartial culture''), or assuming a certain mapping between ranks of candidates and their values for the agent.

\citet{andersson2014budget,andersson2014least} measure the degree of manipulability by counting the number of agents who have a profitable manipulation. They define a rule as \emph{minimally manipulable} with respect to a set of acceptable mechanisms if for each preference profile, the number of agents with a profitable manipulation is minimal across all acceptable mechanisms.

\eden{TODO: add a comparison to RAT-degree}
\erel{This can also be combined with our approach.}

% ==================================================

\iffalse
% EREL: This is more related to the other notion of "observed-outcomes truthfulness".
\paragraph{Other Related Notions}
\citet{tamuz2018non} study cake-cutting among two agents. 
They assume that different cutters play cut-and-choose repeatedly with the same chooser, and may observe the previous choices of the chooser. They develop protocols that are \emph{non-exploitable} in the sense that observing previous choices does not help the cutter make a cut that will give him more than $1/2$ of the total cake value.

\citet{cresto2022fair} study regret in fair cake-cutting among two agents, where the regret comes from a change in preferences: after one player sees the choice of the other player, his preferences may change. They suggest a variant of cut and choose that avoids this kind of regret. 

\citet{manurangsi2023differentially} study differential privacy in the context of fair division. Can it help to reduce manipulability?
\fi

