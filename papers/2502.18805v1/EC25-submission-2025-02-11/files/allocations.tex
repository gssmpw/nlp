
% \newpage
\section{Indivisible Goods Allocations}\label{sec:indivisible-good-aloc}
In this section, we consider several mechanisms to allocate $m$ indivisible goods $G = \{g_1, \ldots, g_m\}$ among the $n$ agents.
% The happiness of agent~$a_i$ from receiving good~$g_{\ell}$ is denoted by $v_{i,\ell} \geq 0$.
Here, the true preferences $T_i$ are given by $m$ real values: $v_{i,\ell}  \geq 0$ for any $g_{\ell} \in G$, representing the happiness of agent $a_i$ from receiving the good $g_{\ell}$. 
The reported preferences $P_i$ are real values $r_{i,\ell} \geq 0 $.
We assume the agents have \emph{additive} valuations over the goods.
% \biaoshuai{I added the next two sentences.}
Given a bundle $S\subseteq G$, let $v_i(S)=\sum_{g_\ell\in S}v_{i,\ell}$ be agent $a_i$'s utility upon receiving the bundle $S$.
% An \emph{allocation} is a partition $(A_1,\ldots,A_n)$ of $G$, where $A_i$ is the bundle received by agent $a_i$.
%
A mechanism in this context gets $n$ (potentially untruthful) reports from all the agents and determines the \emph{allocation} -- a partition $(A_1,\ldots,A_n)$ of $G$, where $A_i$ is the bundle received by agent $a_i$.

% The key difference from auctions discussed in the previous section is that allocations do not involve money. As a result, we cannot rely on monetary incentives to encourage truthful reporting, as we did before. This section explores alternative ways to achieve this behavior.


\paragraph{Results.} We start by considering a simple mechanism, the utilitarian goods allocation -- which assigns each good to the agent who reports the highest value for it.
We prove that this mechanism is safely manipulable (RAT-degree = $0$). 
We then show that the RAT-degree can be increased to $1$ by requiring normalization --- the values reported by each agent are scaled such that the set of all items has the same value for all agents.
The RAT-degree of the famous round-robin mechanism is also at most $1$.
In contrast, we design a new mechanism that satisfies the common fairness notion called EF1 (envy-freeness up to one good), that attains a RAT-degree of $n-1$.



% ===========================================
\subsection{Utilitarian Goods Allocation}\label{sec:utilitarian-alloc}
The \emph{utilitarian} rule aims to maximize the sum of agents' utilities. 
When agents have additive utilities, this goal can be achieved by assigning each good to an agent who reports the highest value for it.
This section analyzes this mechanism.

For simplicity, we assume that agentsâ€™ reports are bounded from above by some maximum possible value $r_{max} >0$.
Also, we assume that in cases where multiple agents report the same highest value for some good, the mechanism employs some tie-breaking rule to allocate the good to one of them.
However, the tie-breaking rule must operate independently for each good, meaning that the allocation for one good cannot depend on the tie-breaking outcomes of other goods.
% This ensures that the mechanism treats each good separately when resolving ties, without considering correlations or dependencies across items.


We further assume that there is at least one agent who has a value different than $0$ and $r_{max}$ for at least one of the goods.
Otherwise, for each good, all agents' (true) values are $0$ or $r_{max}$; and in this case the mechanism is trivially truthful.
% We neglect the two extreme cases where for each good either (1) all agents' (true) values are $0$, or (2) all the agents' values are $r_{max}$; as for these cases the mechanism is trivially truthful.


\begin{theoremrep}
\label{prop:auction-knownagents}
The Utilitarian allocation rule is safely manipulable (RAT-degree = 0).
\end{theoremrep}

\begin{proofsketch}
    Manipulating by reporting the highest possible value, $r_{max}$, for all goods is both profitable and safe. It is profitable because if the maximum report among the other agents for a given good lies between the manipulator's true value and their alternative bid, $r_{max}$, the manipulator's utility strictly increases. It is safe because, in all other cases, the utility remains at least as high.
\end{proofsketch}
\erel{
In the cake-cutting section, this idea is explained much more succinctly; see 
\Cref{obs:utilitarian-cake-cutting}. Maybe we can do the same here?
Then we also do not need the $r_{\max}$.
}

\begin{proof}
    To prove the mechanism is safely manipulable, we need to show one agent that has an alternative report, such that the agent always \emph{weakly} prefers the outcome that results from reporting the alternative report over reporting her true valuations, and \emph{strictly} prefers it in at least one scenario.
    
     Let $a_1 \in N$ be an agent who has a value different than $0$ and $r_{max}$ for at least one of the goods. Let $g_1$ be such good -- that is, $0 < v_{1,1} < r_{max}$.
     We prove that reporting the highest possible value, $r_{max}$, for all goods is a safe manipulation.
     Notice that this report is indeed a manipulation as it is different than the true report in at least one place.
    
    We need to show that for any combination of reports of the other agents, this report does not harm agent~$a_i$, and that there exists a combination where it strictly increases her utility. 

    Noting that since the utilities are additive and tie-breaking is performed separately for each good, we can analyze each good independently. 
    The following proves that for all goods, agent $a_1$ always weakly prefers to report truthfully. Case 4 (marked by *) proves that for the good $g_1$, there exists a combination of reports of the others, for which agent~$a_1$ strictly prefers the outcome from report truthfully.
    Which proves that it is indeed a safe manipulation. 

    
    Let $g_{\ell} \in G$ be a good. 
    We consider the following cases according to the value of agent $a_1$ for the good $g_{\ell}$, $v_{1, \ell}$; and the maximum report among the other agents for this good:
    % , denoted by $r_{-i, \ell}^{max}$: 
    \begin{itemize}
        \item $v_{1,\ell} = r_{max}$: In this case, both the truthful and the untruthful reports are the same.

        \item $v_{1,\ell} =0$: Agent~$a_1$ does not care about this good, so regardless of the reports which determines whether or not agent~$a_1$ wins the good, her utility from it is $0$.

        Thus, in this case, agent $a_1$ is indifferent between telling the truth and manipulating.
        
    
        \item $0 < v_{1,\ell} < r_{max}$ and the maximum report of the others is strictly smaller than $v_{1,\ell}$: Agent~$a_1$ wins the good in both cases -- when she reports her true value or bids $r_{max}$.
        
        Thus, in this case, agent $a_1$ is indifferent between telling the truth and manipulating.

        
        \item (*) $0 < v_{1,\ell} < r_{max}$ and the maximum report of the others is greater than $v_{i,j}$ and smaller than $r_{max}$: when agent~$a_1$ reports her true value for the good $g_{\ell}$, then she does not win it. However, by bidding $r_{max}$, she does. 

        Thus, in this case, agent~$a_1$ strictly increases her utility by lying (as her value for this good is positive).

        

        \item $0 < v_{1,\ell} < r_{max}$ and the maximum report of the others equals $r_{max}$: 
        when agent $a_1$ reports her true value for the good, she does not win it. 
        However, by bidding $r_{max}$, she gets a chance to win the good. 
        Even for risk-averse agent, a chance of winning is better than no chance.

        Thus, in this case, agent~$a_1$ strictly increases her (expected) utility by lying.
    \end{itemize}
\end{proof}

% This mechanism has a zero-information safe manipulation: reporting  the highest possible value for each item increases the agent's chances to get the item, and has no risk.


\subsection{Normalized Utilitarian Goods Allocation}\label{sec:normalized-utilitarian-alloc}

In the \emph{normalized} utilitarian allocation rule, the agents' reports are first normalized such that each agent's values sum to a given constant $V >0$.
Then, each good is given to the agent with the highest \emph{normalized} value.
% As before, if several agents report the same highest normalized value for a particular good, the good will be assigned to one of them according to some tie-breaking rule that operates independently for each good (see \Cref{sec:utilitarian-alloc} for more details).
%
% Notice that when there is only one good, the mechanism allows only one strategy; thus, in particular, there are no manipulations.
% \eden{ The case where there are exactly two goods is special and analyzed separately at the end of the section OR  in the appendix)}.
We focus on the case of at least three goods.

\begin{theorem}
\label{thm:normalized-utilitarian-goods}
For $m \geq 3$ goods,  the RAT-degree of the Normalized Utilitarian allocation rule is $1$.
\end{theorem}

We prove \Cref{thm:normalized-utilitarian-goods} using several lemmas that analyze different cases. 

The first two lemmas prove that the rule is not 
safely-manipulable, so its RAT-degree is at least $1$.
\Cref{claim:normalized-agent-who-likes-single-good} addresses agents who value only one good \er{positively}, while \Cref{claim:normalized-agent-who-likes-at-least-two} covers agents who value at least two goods \er{positively}.



\begin{lemmarep}
\label{claim:normalized-agent-who-likes-single-good}
An agent who values only one good positively cannot safely manipulate the Normalized Utilitarian allocation rule.
\end{lemmarep}

\begin{proofsketch}
Due to the normalization requirement, 
any manipulation by such an agent involves reporting a lower value for the only good she values positively, while reporting a higher values for some goods she values at 0. This reduces her chances of winning her desired good and raises her chances of winning goods she values at zero, ultimately decreasing her utility. Thus, the manipulation is \er{neither profitable nor} safe.
\end{proofsketch}

\begin{proof}
    % We prove that telling the truth is a strictly dominate strategy for such agents.
    %
    Let $a_1$ be an agent who values only one good and let $g_1$ be the only good she likes. That is, her true valuation is $v_{1,1} = V$ and $v_{1,\ell} = 0$ for any $\ell \neq 1$ (any good $g_{\ell}$ different than $g_1$).
    
    To prove that agent $a_1$ does \emph{not} have a safe manipulation, we need to show that for any report for her either (1) for any reports of the other agents, agent $a_1$ weakly prefers the outcome from telling the truth; or (2) there exists a reports of the other agents, for which agent $a_1$ strictly prefers the outcome from telling the truth.

    
    Let $(r_{1,1}, \ldots, r_{1,m})$ be an alternative report for the $m$ goods. We assume that the values are already normalized.
    We shall now prove that the second condition holds (lying may harm the agent). 
    
    First, as the alternative report is different, we can conclude that $r_{1,1} < V$.
    We denote the difference by $\epsilon = V - r_{1,j}$.
    Next, consider the following reports of the other agents (all agents except $a_1$): $V - \frac{1}{2}\epsilon$ for item $g_1$ and $\frac{1}{2}\epsilon$ for some other good. 
    
    When agent $a_1$ reports her true value she wins her desired good $g_1$, which gives her utility $V >0$. 
    However, when she lies, she loses good $g_1$ and her utility decreases to $0$ (winning goods different than $g_1$ does not increases her utility).
    
    That is, lying may harm the agent. 
\end{proof}

% If each agent values only one good, this implies that the mechanism is not safely manipulable.
% Next, we assume that there is at least one agent who values at least two of the goods, and prove that such agent cannot safely manipulate the mechanism as well. 

\begin{lemmarep}
\label{claim:normalized-agent-who-likes-at-least-two}
An agent who values positively at least two goods cannot safely manipulate the Normalized Utilitarian allocation rule.
\end{lemmarep}

% \newcommand{\increasedInd}{\ell^{\uparrow}}
% \newcommand{\decreasedInd}{\ell^{\downarrow}}
% EREL: suggestion for a different notation (my eyes could not notice the difference between u$\uparrow$ and $\downarrow$..)
\newcommand{\increasedInd}{\mathrm{inc}}
\newcommand{\decreasedInd}{\mathrm{dec}}

\begin{proofsketch}
    Since values are normalized, any manipulation by such an agent must involve increasing the reported value of at least one good $g_{\increasedInd}$ while decreasing the value of at least one other good $g_{\decreasedInd}$. We show that such a manipulation is not safe, by considering the case where all other agents report as follows: they assign a value of $0$ to $g_{\increasedInd}$, a value between the manipulator's true and reported value for $g_{\decreasedInd}$, and a value slightly higher than the manipulatorâ€™s report for all other goods (it is possible to construct such reports that are non-negative and normalized). 
    
    With these reports, the manipulation causes the manipulator to lose the good $g_{\decreasedInd}$ which has a positive value for her, whereas   
    she wins the good $g_{\increasedInd}$ with or without the manipulation, and does not win any other good. Hence, the manipulation strictly decreases her total value.
\end{proofsketch}


\begin{proof}
    Let $a_1$ be an agent who values at least two good, $\valT{1}{1}, \ldots, \valT{1}{m}$ her true values for the $m$ goods, and $\repT{1}{1}, \ldots, \repT{1}{m}$ a manipulation for $a_1$.
    We need to show that the manipulation is either not \emph{safe} -- there exists a combination of the other agents' reports for which agent $a_1$ strictly prefers the outcome from telling the truth; or not \emph{profitable} -- for any combination of reports of the other agents, agent $a_1$ weakly prefers the outcome from telling the truth. 
    We will show that the manipulation is not safe by providing an explicit combination of other agents' reports.

    First, notice that since the the true values and untruthful report of agent $a_1$ are different and they sum to the same constant $V$, there must be a good $g_{\increasedInd}$ whose value was increased (i.e., $ \valT{1}{\increasedInd} < \repT{1}{\increasedInd}$), and a good $g_{\decreasedInd}$ whose value was decreased (i.e., $ \valT{1}{\decreasedInd} > \repT{1}{\decreasedInd}$).
    
    Next, let $\epsilon := \min \left\{\frac{1}{m-1}\repT{1}{\increasedInd},~ \frac{1}{2}(\valT{1}{\decreasedInd} - \repT{1}{\decreasedInd})\right\}$, notice that $\epsilon > 0$.
    Also, let $c := \repT{1}{\increasedInd} - \epsilon$, notice that $c > 0$ as well \er{(here we use the condition $m\geq 3$).}

    We consider the combination of reports in which all agents except $a_1$ report the following values, denoted by $r(1), \ldots, r(m)$:
    \begin{itemize}
        \item For good $g_{\increasedInd}$ they report $r(\increasedInd) := 0$.

        \item For good $g_{\decreasedInd}$ they report 
%        $\repT{1}{\decreasedInd} + \epsilon$:
        % (a value higher by $\epsilon$ than the report of agent $a_1$).
        $r(\decreasedInd) := \repT{1}{\decreasedInd} + \epsilon$.

        \item For the rest of the goods, $g_\ell \in G \setminus \{g_{\increasedInd}, g_{\decreasedInd}\}$, they report 
%        $ \repT{1}{\ell} + \frac{1}{m-2} c$:
         % (a value higher by $\frac{1}{m-2} c$ than the report of agent $a_1$)
%        $\forall g_\ell \in G \setminus \{g_{\increasedInd}, g_{\decreasedInd}\}\colon \quad 
        $r(\ell) := \repT{1}{\ell} + \frac{1}{m-2} c$.
        
    \end{itemize}

We prove that the above values constitute a legal report --- they are  non-negative and normalized to $V$.

First, we show that the sum of values in this report is $V$:
    \begin{align*}
        \sum_{\ell =1}^m r(\ell) &= r(\increasedInd) + r(\decreasedInd) +\sum_{g_{\ell} \in G \setminus \{g_{\increasedInd}, g_{\decreasedInd}\}} r(\ell) 
        \\
        & = 0 + (\repT{1}{\decreasedInd} + \epsilon) + \sum_{g_{\ell} \in G \setminus \{g_{\increasedInd}, g_{\decreasedInd}\}} \left(\repT{1}{\ell} + \frac{1}{m-2} c\right) 
        \\
        & = (\repT{1}{\decreasedInd} + \epsilon) + \sum_{g_{\ell} \in G \setminus \{g_{\increasedInd}, g_{\decreasedInd}\}} \repT{1}{\ell} + (m-2)\frac{1}{m-2} c
        \\
        & = (\repT{1}{\decreasedInd} + \epsilon) + \sum_{g_{\ell} \in G \setminus \{g_{\increasedInd}, g_{\decreasedInd}\}} \repT{1}{\ell} + (\repT{1}{\increasedInd} - \epsilon) = \sum_{\ell =1}^m \repT{1}{\ell} = V.
    \end{align*}
    
Second, we show that all the values are non-negative:
    \begin{itemize}
        \item Good $g_{\increasedInd}$: it is clear as $r(\increasedInd) =0$.

        \item Good $g_{\decreasedInd}$: since  $r(\decreasedInd)$ is strictly higher than the (non-negative) report of agent $a_1$ by $\epsilon >0 $, it is clearly non-negative.

        \item Rest of the goods, $g_{\ell} \in G \setminus \{g_{\increasedInd}, g_{\decreasedInd}\}$: 
        since $\epsilon = \min \{\frac{1}{m-1}\repT{1}{\increasedInd}, ~\frac{1}{2}(\valT{1}{\decreasedInd} - \repT{1}{\decreasedInd})\}$, it is clear that $\epsilon \leq \frac{1}{m-1}\repT{1}{\increasedInd}$. As $m \geq 3$ and $\repT{1}{\increasedInd} >0$, we get that $c = \repT{1}{\increasedInd} - \epsilon = \frac{m-2}{m-1} \repT{1}{\increasedInd}$ is higher than $0$.
        As $r(\ell)$ is strictly higher than the (non-negative) report of agent $a_1$ by $c >0 $, it is clearly non-negative.
    \end{itemize}


Now, we prove that, given these reports for the $n-1$ unknown agents, agent $a_1$ strictly prefers the outcome from reporting truthfully to the outcome from manipulating.

    We look at the two possible outcomes for each good -- the one from telling and truth and the other from lying, and show that the outcome of telling the truth is always either the same or better, and that for at least one of the goods that agent $a_1$ wants (specifically, $g_\decreasedInd$) it is strictly better.

    % \eden{maybe: we show that the bundle agent $a_1$ gets when she is truthful is a subset (contained in the ?) of the the bundle she gets when she lies}
    \begin{itemize}
        \item For good $g_\increasedInd$ we consider two cases.
        \begin{enumerate}
            \item If $\valT{1}{\increasedInd} = 0$: when agent $a_1$ is truthful we have a tie for this good as $r(\increasedInd) = 0$.
            When agent $a_1$ manipulates, she wins the good (as $\repT{1}{\increasedInd} > \valT{1}{\increasedInd} = 0 = r(\increasedInd)$).
            However, as $\valT{1}{\increasedInd} = 0$, in both cases, her utility from this good is $0$.

            \item If $\valT{1}{\increasedInd} > 0$:
            Whether agent $a_1$ says is truthful or not, she wins the good as $\repT{1}{\increasedInd} > \valT{1}{\increasedInd} > 0 =r(\increasedInd)$.
            Thus, for this good, the agent receives the same utility (of $\valT{1}{\increasedInd}$) when telling the truth or lying.

        \end{enumerate}
        
        
        \item For good $g_\decreasedInd$: when agent $a_1$ is truthful, she wins the good since $r(\decreasedInd) < \valT{1}{\decreasedInd}$:
        \begin{align*}
            r(\decreasedInd) &= \repT{1}{\decreasedInd} + \epsilon \\
            &= \repT{1}{\decreasedInd} + \min \{\frac{1}{m-1}\repT{1}{\increasedInd},~ \frac{1}{2}(\valT{1}{\decreasedInd} - \repT{1}{\decreasedInd})\}\\
            &\leq \repT{1}{\decreasedInd} +  \frac{1}{2}(\valT{1}{\decreasedInd} - \repT{1}{\decreasedInd}) \\
            &= \frac{1}{2}(\valT{1}{\decreasedInd} + \repT{1}{\decreasedInd})< \frac{1}{2}(\valT{1}{\decreasedInd} + \valT{1}{\decreasedInd}) = \valT{1} {\decreasedInd} && \text{(as $\repT{1}{\decreasedInd} < \valT{1}{\decreasedInd}$)}
        \end{align*}
        But when agent $a_1$ manipulates, she loses the good since $r(\decreasedInd) > \repT{1}{\decreasedInd}$ (as $r(\decreasedInd) = \repT{1}{\decreasedInd} + \epsilon$ and $\epsilon > 0$).
        
        As the real value of agent $a_1$ for this good is positive, the agent strictly prefers telling the truth for this good.
%        (telling the truth is strictly better)

        \item Rest of the goods, $g_{\ell} \in G \setminus \{g_{\increasedInd}, g_{\decreasedInd}\}$:
        When agent $a_1$ is truthful, all the outcomes are possible -- the agent either wins or loses or that there is a tie.    
        
        However, as for this set of goods the reports of the other agents are $r(\ell) = \repT{1}{q}+\frac{1}{n-2}c > \repT{1}{\ell}$, when agent $a_1$ manipulates, she always loses the good.
        Thus, her utility from lying is either the same or smaller (since losing the good is the worst outcome).

%        (telling the truth is weakly better)
    \end{itemize}

    Thus, the manipulation may harm the agent.
\end{proof}

% \fi


\iffalse

% ===============================================
% \begin{claim}\label{normalized-more-than-2-agents-at least-2-goods}
%     When there are more than two agents and at least two goods, the normalized utilitarian goods allocation is \emph{not} safely-manipulable.
% \end{claim}
\begin{claim}\label{normalized-more-than-2-agents-at least-2-goods}
   For $n \geq 3$, the normalized utilitarian goods allocation is \emph{not} safely-manipulable.
\end{claim}

\begin{proof}
    Let $a_1$ be an agent who values at least two of the
    goods, and let $\valT{1}{1}, \ldots, \valT{1}{m}$ be her values for the $m$ goods. Assume that the values are normalized.
    
     We need to show that for any alternative preference for agent $a_1$ either (1) for any reports of the other agents, the outcome from telling the truth is always weakly preferred; or (2) there exists a reports of the other agents, for which the outcome from telling the truth is strictly preferred.

     Let $\repT{1}{1}, \ldots, \repT{1}{m}$ be alternative reports for the $m$ goods, also normalized.

     First, notice that since the the true values and untruthful reports for agent $a_1$ are different and they sum to the same constant $V$, there must be a good $\increasedInd$ whose value was increased (i.e., $ \valT{1}{\increasedInd} < \repT{1}{\increasedInd}$), and a good $\decreasedInd$ whose value was decreased (i.e., $ \valT{1}{\decreasedInd} > \repT{1}{\decreasedInd}$).


    % \eden{this proof requires $3$ agents. need to think what happens for 2 agents}
     We shall now prove that the second condition holds (lying may harm the agent). 
     Consider the case where all the other agents (all except $a_1$) report one of the following sets of values: 
     \begin{enumerate}
         \item For good $\decreasedInd$: $\valT{1}{\decreasedInd} - \frac{1}{2}\epsilon$, where  $\epsilon := \frac{1}{2}(\valT{1}{\decreasedInd} - \repT{1}{\decreasedInd})$. Notice that $\epsilon > 0$ as $ \valT{1}{\decreasedInd} > \repT{1}{\decreasedInd}$.

         For good $\increasedInd$: $\left(V - (\valT{1}{\decreasedInd} - \frac{1}{2}\epsilon)\right)$.

         Rest of the goods, $q \in Q \setminus \{\increasedInd, \decreasedInd\}$: $0$.

         \item For good $\increasedInd$: $V$.

         Rest of the goods, $q \in Q \setminus \{\increasedInd\}$: $0$.
     \end{enumerate}
     We consider only the profiles in which at least one agent reports the first set and at least one agent reports the second set.

     It is easy to see that both profiles are legal reports (all values are between $0$ and $V$ and they sum to $V$).

    Claim: agent $a_1$ strictly prefers the outcome from telling the truth.

    We look at the two outcomes per good and show that for each good, the outcome of telling the truth is either the same or better, and that for one of the goods that agent $a_1$ wants ($\decreasedInd$) it is strictly better.


    \begin{itemize}
        \item Good $\increasedInd$: when agent $a_1$ is truthful, she does not win the good --- since she values at least two goods, $\valT{1}{\increasedInd} < V$, which means that one of the agents who report $V$ wins it.
        
        However, when she lies, there are two possible cases.
        \begin{enumerate}
            \item If $\repT{1}{\increasedInd} < V$:
            as before, when agent $a_1$ manipulates, she does not win the good.
            
            (the same)
            
            \item If $\repT{1}{\increasedInd} = V$: when agent $a_1$ manipulates, we have tie for this good. 

            \begin{enumerate}
                \item If $\valT{1}{\increasedInd} = 0$, regardless of whether she receives the good or not, her utility from this good is $0$.
                
                (the same). 

                \item If $\valT{1}{\increasedInd} > 0$:
                when agent $a_1$ is truthful or lies, she wins the good (as $\repT{1}{\increasedInd} > \valT{1}{\increasedInd} > 0 =\repT{2}{\increasedInd}$.
                Thus, for this good, the agent receives the same utility (of $\valT{1}{\increasedInd}$) when telling the truth or lying (the same).
            \end{enumerate}
        \end{enumerate}
        
        
        \item Good $\decreasedInd$: when agent $a_1$ is truthful, she wins the good since $\repT{2}{\decreasedInd} < \valT{1}{\decreasedInd}$:
        \begin{align*}
            \repT{2}{\decreasedInd} &= \repT{1}{\decreasedInd} + \epsilon \\
            &= \repT{1}{\decreasedInd} + \min \{\frac{1}{n-1}\repT{1}{\increasedInd},~ \frac{1}{2}(\valT{1}{\decreasedInd} - \repT{1}{\decreasedInd})\}\\
            &\leq \repT{1}{\decreasedInd} +  \frac{1}{2}(\valT{1}{\decreasedInd} - \repT{1}{\decreasedInd}) \\
            &= \frac{1}{2}(\valT{1}{\decreasedInd} + \repT{1}{\decreasedInd})< \frac{1}{2}(\valT{1}{\decreasedInd} + \valT{1}{\decreasedInd}) = \valT{1} {\decreasedInd} && \text{(as $\repT{1}{\decreasedInd} < \valT{1}{\decreasedInd}$)}
        \end{align*}
        However, when agent $a_1$ manipulates, she loses the good since $\repT{2}{\decreasedInd} > \repT{1}{\decreasedInd}$ (as $\repT{2}{\decreasedInd} = \repT{1}{\decreasedInd} + \epsilon$ and $\epsilon > 0$).
        
        As the real value of agent $a_1$ for this good is positive, the agent strictly prefers telling the truth for this good.

        \item Rest of the goods, $q \in Q \setminus \{\increasedInd, \decreasedInd\}$: 
        When agent $a_1$ is truthful, all the outcomes are possible -- the agent either wins or loses or that there is a tie-breaking.    
        
        However, as for these goods $\repT{2}{q} = \repT{1}{q}+\frac{1}{n-2}c > \repT{1}{q}$, when agent $a_1$ manipulates, she always loses the good.
        Thus, her utility from lying is either the same or smaller (since losing the good is the worst outcome).
    \end{itemize}

    Thus, lying may harm the agent.
\end{proof}




\begin{claim}
    The RAT-degree of the normalized utilitarian goods allocation is $1$.
\end{claim}

\begin{proof}
    To prove that the RAT-degree is $1$, we need to show that the mechanism is:
    (a) \emph{not} safely-manipulable.
    (b) $1$-known-agents safely-manipulable.\\

    (a)
\end{proof}

\fi

The last lemma shows that the RAT-degree is at most $1$, thus completing the proof of the theorem.
\begin{lemmarep}\label{normalized-1-known}
    With $m \geq 3$ goods, Normalized Utilitarian is $1$-known-agent safely-manipulable.
\end{lemmarep}

\begin{proofsketch}
Consider a scenario where there is a known agent who reports $0$ for some good $g$ that the manipulator wants and slightly more than the manipulatorâ€™s true values for all other goods. In this case, by telling the truth, the manipulator has no chance to win any good except $g$. Therefore, reporting a 
value of $V$ for $g$ and a value of $0$ for all other goods is a safe manipulation.

The same manipulation is also profitable, since it is possible that the reports of all $n-2$ unknown agents for $g$ are between the manipulatorâ€™s true value and $V$. In such a case, the manipulation causes the manipulator to win $g$, which strictly increases her utility.
\end{proofsketch}


\begin{proof}
    Let $a_1$ be an agent and let $\valT{1}{1}, \ldots, \valT{1}{m}$ be her values for the $m$ goods.
    We need to show (1) an alternative report for agent~$a_1$, (2) another agent~$a_2$, and (3) a report agent ~$a_2$; such that 
    for any combination of reports of the remaining $n-2$ (unknown) agents, agent $a_1$ weakly prefers the outcome from lying, and that there exists a combination for which agent $a_1$ strictly prefers the outcome from lying.

    Let $g_{\ell^+}$ be a good that agent $a_1$ values (i.e., $\valT{1}{\ell^+} >0$).
    
    Let $a_2$ be an agent different than $a_1$.
    We consider the following report for agent~$a_2$: first, $\repT{2}{\ell^+} :=0$, and $\repT{2}{\ell} := \repT{1}{\ell} + \epsilon$ for any good $g_{\ell}$ different than $g_{\ell^+}$, where $\epsilon := \frac{1}{m-1} \valT{1}{\ell^+} $.
    Notice that $\epsilon >0$.

    We shall now prove that reporting $V$ for the good $g_{\ell^+}$ (and $0$ for the rest of the goods) is a safe manipulation for $a_1$ given that $a_2$ reports the described above.

    When agent~$a_1$ reports her true values, then she does not win the goods different than $g_{\ell^+}$ -- this is true regardless of the reports of the remaining $n-2$ agents, as agent~$a_2$ reports a higher value $\repT{1}{\ell} < \repT{1}{\ell} + \epsilon = \repT{2}{\ell}$.
    For the good $g_{\ell^+}$,  we only know that $\repT{2}{\ell^+} = 0 > \valT{1}{\ell^+} > \repT{1}{\ell^+} = V$, meaning that it depends on the reports of the $(n-2)$ remaining agents. 
    We consider the following cases, according to the maximum report for $g_{\ell^+}$ among the remaining agents:
    \begin{itemize}
        \item If the maximum is smaller than $\valT{1}{\ell^+}$: agent $a_1$ wins the good $\valT{1}{\ell^+}$ in both cases (when telling the truth or lies). 

        (the same)

        \item If the maximum is greater than $\valT{1}{\ell^+}$ but smaller than $\repT{1}{\ell^+} = V$: when agent $a_1$ tells the truth, she does not win the good. 
        However, when she lies, she does.
        
        (lying is strictly better). 

        \item If the maximum equals $\repT{1}{\ell^+} = V$: when agent $a_1$ tells the truth, she does not win the good. 
        However, when she lies, we have tie for this good.
        Although agent $a_1$ is risk-averse, having a chance to win the good is strictly better than no chance at all.
        
        (lying is strictly better). 
    \end{itemize}
    
    
\end{proof}


% ========================================
\subsection{Round-Robin Goods Allocation}
In round-robin goods allocation, the agents are arranged according to some predetermined order $\pi$. 
There are $m$ rounds, corresponding to the number of goods. 
In each round, the agent whose turn it is (based on $\pi$) takes their most preferred good from the set of goods that remain unallocated at that point.
% \biaoshuai{I added the next sentence.}
When there are multiple goods that are equally most preferred, the agent takes the good with the smallest index.
Note that normalization is not important for Round-Robin.

If there are at most $n$ goods, then the rule is clearly truthful.
Thus, we assume that there are $m\geq n+1$ goods.
% \biaoshuai{The following part is new.}
Even the slight increment to $m=n+1$ makes a significant difference:

\begin{lemma}\label{claim:RR-RAT1-tie}
    With $m\geq n+1$ goods, round-robin  is $1$-known-agent safely-manipulable.
\end{lemma}

\begin{proof}
    Let $\pi$ be the order according to agents' indices: $a_1,a_2,\ldots,a_n$.
    Let agent $a_1$'s valuation be such that $v_{1,1}=v_{1,2}=1$ and $v_{1,3}=\cdots = v_{1,m}=0$.
    Suppose agent $a_1$ knows that agent $a_2$ will report the valuation with $v_{2,1}=0$, $v_{2,2}=1$, and $v_{2,3}=\cdots=v_{2,m}=0.5$.
    We show that agent $a_1$ has a safe and profitable manipulation by reporting $v_{1,1}'=0.5$, $v_{1,2}'=1$, and $v_{1,3}'=\cdots=v_{1,m}'=0$.

    Firstly, we note that agent $a_1$'s utility is always $1$ when reporting her valuation truthfully, regardless of the valuations of agents $a_3,\ldots,a_n$.
    This is because agent $a_1$ will receive item $g_1$ (by the item-index tie-breaking rule) and agent $a_2$ will receive item $g_2$ in the first two rounds.
    The allocation of the remaining items does not affect agent $a_1$'s utility.

    Secondly, after misreporting, agent $a_1$ will receive item $g_2$ in the first round, which already secures agent $a_1$ a utility of at least $1$. Therefore, agent $a_1$'s manipulation is safe.

    Lastly, if the remaining $n-2$ agents report the same valuations as agent $a_2$ does, it is easy to verify that agent $a_1$ will receive item $g_1$ in the $(n+1)$-th round.
    In this case, agent $a_1$'s utility is $2$.
    Thus, the manipulation is profitable.
\end{proof}

We show a partial converse.
\begin{lemmarep}
    With $m=n+1$ goods, round-robin is not safely-manipulable.
\end{lemmarep}

\begin{proof}
    Clearly, the only agent that could have a  profitable manipulation is $a_1$. 
    
    Order the goods by descending order of $a_1$'s values, and subject to that, by ascending index. W.l.o.g., assume  that $v_{1,1} \geq v_{1,2} \geq \cdots \geq v_{1,m}$.
    If all valuations are equal ($v_{1,1}=v_{1,m}$), then $a_1$ always gets the same total value (two goods), so no manipulation is profitable. Therefore we assume that $v_{1,1}>v_{1,m}$.
    
    If $a_1$ is truthful, he gets $g_1$ first, and then the last good remaining after all other agents picked a good.
    If, after the manipulation, $g_1$ still has the highest value, then $a_1$ still gets $g_1$ first, and has exactly the same bundle, so the manipulation is not profitable. 
    
    Hence, we assume that $a_1$ manipulates such that some other good, say $g_t\neq g_1$, becomes the most valuable good: $v'_{1,t}\geq v'_{1,j}$ for all goods $g_j$, and $v'_{1,t} > v'_{1,1}$. We prove that the manipulation is not safe.

    Suppose the $n-1$ unknown agents all assign the lowest value to $g_t$, and the next-lowest value to $v_m$.
    If $a_1$ is truthful, he gets $g_1$ and then $g_t$, so his value is $v_{1,1}+v_{1,t}$.
    But if $a_1$ manipulates, he gets $g_t$ and then $g_m$, so his value is $v_{1,m}+v_{1,t}$, which is strictly lower.
\end{proof}

Hence, 
    The RAT-degree of round-robin is $1$ when $m=n+1$ and at most $1$ when $m\geq n+1$.

\iffalse
We show that even the slight increase to $m=n+1$ makes a significant difference: in this case, the degree drops to at most $n-2$ -- meaning that there exists an agent who can safely manipulate the outcome, even in the presence of an unknown agent.

\eden{I think the degree depends on the agent's preferences -- on how many of its most preferred goods she is willing to risk in order to get her "best-in-the-middle" - something like that.. }

% For agent $a_i$, we denote its $q$-th most-preferred good by $g^i_{[q]}$. We assume that there exists an agents, $a_1$, for whom there exists a bundle of goods that is strictly preferred over the following bundle:
% \begin{align*}
%     \{g^1_{[1]}, g^1_{[n+1]}, \ldots, g^1_{[\lfloor \frac{m}{n} \rfloor n+1]}\}
% \end{align*}
%  and completely different (no intersection between thw two sets)
    
%     Formally, let $q^1_{best} := \argmax_{q\in [m]} \valT{1}{q}$ and $q^1_{worst} := \argmin_{q\in [m]} \valT{1}{q}$. Then, there exists $q^1_{mid1} \neq q^1_{mid2} \in ([m] \setminus \{q^1_{best}, q^1_{worst}\})$ such that:
%     \begin{align*}
%         \valT{1}{q^1_{best}} + \valT{1}{q^1_{worst}} < \valT{1}{q^1_{mid1}} + \valT{1}{q^1_{mid2}}
%     \end{align*}


% and prove that the RAT-degree is \eden{???}.

% \begin{claim}
%     When there are more goods than agents, $m\geq n+1$; the RAT-degree of the round-robin goods allocation is at most $(n-2)$.

%     $n - \lceil \frac{m}{n} \rceil$
% \end{claim}

\fi

The proof of \Cref{claim:RR-RAT1-tie} uses weak preferences (preferences with ties). In particular, if $a_1$'s valuations for the top two goods are different, then picking $g_2$ first is risky.
% , as it might result in losing $g_1$.
With strict preferences, we could only prove a much weaker upper bound of $n-2$. This raises the following question.
\begin{open}
    What is the RAT-degree of round-robin when agents  report strict preferences?
\end{open}


\iffalse
\begin{claim}
    For $m = n+1$, the RAT-degree of the round-robin goods allocation is at most $(n-2)$.
\end{claim}

\begin{proof}
    To prove that the RAT-degree is at most $(n-2)$, we need to show that the mechanism is $(n-2)$-known-agents manipulable.
    To do so, we need to show that there exists an agent~$a_1$, and a set of $n-2$ known-agents such that agent~$a_1$ can safely manipulate. 

    Let $a_1$ be the agent who choose first. Notice that $a_1$ is the only agent who gets $2$ goods in this case. 
    Consider the case where her true valuations are $m$ for her most-preferred until $1$ for her leased-preferred. 
    Assume, without loss of generality, that her most-preferred is $g_m$ and her least-preferred is $g_1$.

    
    
    \eden{maybe this should be explained before}
    We assume that there exists an agents, $a_1$, for whom there are two goods that are neither her favorite nor her least-preferred, such that she prefers the bundle of these two goods over the bundle of her favorite and least-preferred goods.
    Formally, let $q^1_{best} := \argmax_{q\in [m]} \valT{1}{q}$ and $q^1_{worst} := \argmin_{q\in [m]} \valT{1}{q}$. Then, there exists $q^1_{mid1} \neq q^1_{mid2} \in ([m] \setminus \{q^1_{best}, q^1_{worst}\})$ such that:
    \begin{align*}
        \valT{1}{q^1_{best}} + \valT{1}{q^1_{worst}} < \valT{1}{q^1_{mid1}} + \valT{1}{q^1_{mid2}}
    \end{align*}
    Notice that this assumption holds in many cases -- for example, with 
    % $4$ agents and 
    $5$ goods, where the agent who picks first values the goods by $1, \ldots, 5$. Then, the bundle consisting of her favorite and least-preferred goods is worth $5+1 =6$, while the bundle of her second- and third-best goods is worth $4+3=7$ (assuming additive utilities).



    
    
    
    % , for additive ranking utilities (i.e., the utility of the $q$-th most-preferred good is $m-q+1$ and the utility from a bundles is the sum) for $n \geq 5$ -- as the utility from the bundle of the first-and-fifth most-preferred goods is $(2m-4)$ while the utility from the bundle of the second-and-third most-preferred goods is $(2m-3)$

    

    Let $a_1$ be an agent who choose first, and assume her true valuations are $\valT{1}{1} > \valT{1}{2} > \ldots > \valT{1}{m}$.
    We need to show a strategy profile for the other agents, for which agent~$a_1$ can safely manipulate. 

    Consider the case where the values of all other agents are: $\valT{1}{1} > \valT{1}{m} > \valT{1}{m-1} > \ldots > \valT{1}{2}$.

    Telling the truth for agent~$a_1$ means that she takes her favorite good~$g_1$ in the first round. In this case, she ends the second round with the goods $g_1$ and $g_2$ as all other agents prefer all the remaining other goods over $g_2$.

    Lying for agent~$a_1$ means to take some good different than $g_1$ -- specifically, one that she likes less. We prove that taking the good~$g_2$ first is a safe manipulation for agent $a_1$.
    
    When agent~$a_1$ takes the goods $g_2$ in the first round, she ends the second round with the goods $g_2$ and $g_3$ as the other agents prefer all the remaining other goods over $g_3$. 

    As agent~$a_1$ strictly prefers the good~$g_1$ over $g_3$, her utility from telling the truth is strictly higher. 
    
\end{proof}


\eden{todo}

\eden{need to explain why it is sufficient to consider the first as the potential manipulator and the last as the "bad" agent}
\begin{proof}
    To prove that the RAT-degree is $(n-1)$, we need to show that the mechanism is: (a) not $(n-2)$-known-agents manipulable; and 
    (b) $(n-1)$-known-agents manipulable.

    (a) Let $a_i$ be an agent. Assume without loss of generality that her true valuations are $\valT{i}{1} > \valT{i}{2} > \ldots > \valT{i}{m}$.
    Telling the truth in this case, means to choose the most preferred good that was not already taken be the other agents in each round.

    We consider another agent~$a_j \neq a_i$ with the same valuations, i.e., $\valT{j}{1} > \valT{j}{2} > \ldots > \valT{j}{m}$.
    We shall now prove that, regardless of the valuations of the remaining $n-2$ agents, agent $a_i$ loses when she lies.  

    % Let $\pi(i)$ be agent~$a_i$'s location in the order, l
    Let $G_b$ be the set of goods that were already taken before agent~$a_i$'s first turn
    
    
    
    
    
    
    good $g_1$ in the first round. 
    There are only $n$ possible manipulations -- namely, taking one of the goods $g_2,\ldots,g_n$ first.

     We shall now see that for any strategy profile of $(n-2)$-known-agents $a_2,\ldots, a_{n-1}$, there exists a strategy for the remaining agent, $a_n$, for which lying harm agent~$a_1$.

     Let $Q^T$ be the set of goods that the $(n-2)$-known-agents would have take if agent~$a_1$ tells the truth. Denote agent~$a_1$'s favorite good among the remaining goods -- from $G \setminus (\{q_1\} \cup Q)$ -- by $g^T$.

     Let $Q^L$ be the set of goods that the $(n-2)$-known-agents would have take for some lie of agent~$a_1$. Denote agent~$a_1$'s favorite good among the remaining goods -- from $G \setminus (\{q_1\} \cup Q)$ -- by $g^T$.

    Let $q_1 \neq g_1$ be the good that agent~$a_1$ took, and let $Q$ be the set of goods that the $(n-2)$-known-agents took.
    Denote agent~$a_1$'s favorite good among the remaining goods (from $G \setminus (\{q_1\} \cup Q)$ by $\ell^+$; and her leased-preferred among this set by $q^-$.
    Notice that $\ell^+ \neq q^-$.

    Consider the case where agent~$a_n$'s favorite good is $g_1$ and his second-best, $q^-$.

    When agent~$a_1$ tells the truth, she wins $g_1$ and $\ell^+$, since agent~$a_n$ will choose $q^-$ in this scenario. 
    However, when she lies, she wins $q_1$ and $\ell^+$, since agent~$a_n$ will choose $g_1$ in this scenario. 
 
    

    (b) Let $a_1$ be an agent who choose first, and assume her true valuations are $\valT{1}{1} > \valT{1}{2} > \ldots > \valT{1}{m}$.
    We need to show a strategy profile for the other agents, for which agent~$a_1$ can safely manipulate. 

    Consider the case where the values of all other agents are: $\valT{1}{1} > \valT{1}{m} > \valT{1}{m-1} > \ldots > \valT{1}{2}$.

    Telling the truth for agent~$a_1$ means that she takes her favorite good~$g_1$ in the first round. In this case, she ends the second round with the goods $g_1$ and $g_2$ as all other agents prefer all the remaining other goods over $g_2$.

    Lying for agent~$a_1$ means to take some good different than $g_1$ -- specifically, one that she likes less. We prove that taking the good~$g_2$ first is a safe manipulation for agent $a_1$.
    
    When agent~$a_1$ takes the goods $g_2$ in the first round, she ends the second round with the goods $g_2$ and $g_3$ as the other agents prefer all the remaining other goods over $g_3$. 

    As agent~$a_1$ strictly prefers the good~$g_1$ over $g_3$, her utility from telling the truth is strictly higher. 
    

    
    \end{proof}

% \paragraph{Intuition}
% Suppose there are $m\geq n+1$ goods, agent~$a_1$ plays first, and her true valuations are:
% \begin{align*}
%     v_{1,q} = 
%     \begin{cases}
%     2^{-q}  & q\in \{1,\ldots,n+1\}
%     \\
%     0 & q \in \{n+2,\ldots,m\}
%     \end{cases}
% \end{align*}
% It is possible that after agent $a_1$ truthfully picks good $g_1$ at the first step, her second good will be $n+1$.
% There are $n-1$ potential manipulations, namely taking good $2,\ldots,n$ first.
% However, a manipulation is profitable only if agent $a_1$ also gets the good $g_1$.

\begin{proposition}
With $n+1$ items,
Round-Robin item allocation is 

(a) not $(n-2)$-known-agents manipulable;

(b) $(n-1)$-known-agents manipulable.
\end{proposition}
\begin{proof}
(a) Suppose $i$ knows the preferences of only $n-2$ agents.
If one of them prefers item $1$\eden{ need to define it more accurately}, then $i$ has no profitable manipulation.
If none of them prefers item $1$, then $i$ may have a profitable manipulation, but this depends on the preference of the remaining (unknown) agent. Therefore, there is no safe manipulation.

(b) Knowing the preferences of all $n-1$ agents of course allows $i$ to manipulate optimally.
\end{proof}

(a) Let $a_1$ be an agent with the following true valuations:
    \begin{align*}
        v_{1,q} = 
        \begin{cases}
        2^{-q}  & q\in \{1,\ldots,n+1\}
        \\
        0 & q \in \{n+2,\ldots,m\}
        \end{cases}
    \end{align*}
    That is, she cares only about the goods $g_1,\ldots, g_{n+1}$ and $\valT{1}{1} > \valT{1}{2} > \ldots > \valT{1}{(n+1)}$.

    Telling the truth in this case, means to choose good $g_1$ first. 
    There are only $n$ possible manipulations -- namely, taking one of the goods $g_2,\ldots,g_n$ first.

\fi



   
\subsection{An EF1 Mechanism with RAT-degree $n-1$}
\label{sect:indivisible-EF1-n-1}
% \biaoshuai{new}

In this section, we focus on mechanisms that always output fair allocations (with respect to the reported valuation profile).
We consider the widely used fairness criterion \emph{envy-freeness up to one item} (EF1), which intuitively means that no agent envies another agent if one item is (hypothetically) removed from that agent's bundle.

\begin{definition}
Given a valuation profile $(v_1,\ldots,v_n)$, an allocation $(A_1,\ldots,A_n)$ is \emph{envy-free up to one item} (EF1) if for every pair of $i,j\in [n]$ there exists a good $g$ such that
$v_i(A_i)\geq v_i(A_j\setminus\{g\})$.
\end{definition}
% In words, an allocation is EF1 if any agent $a_i$ does not envy any agent $a_j$ if one good is  removed from agent $a_j$'s bundle.

It is well-known and easy to see that the round-robin mechanism always outputs an EF1 allocation.
% for any pair of $i,j\in[n]$, if agent $a_i$ comes before agent $a_j$ under $\pi$, then agent $a_i$ does not envy agent $a_j$ as agent $a_i$ weakly prefers the good she receives than the good received by agent $a_j$ in every $n$-rounds iteration; if agent $a_i$ comes after agent $a_j$, then agent $a_i$ does not envy agent $a_j$ after removing the first good received by $a_j$, as agent $a_i$ weakly prefers the good she receives in every $n$-rounds iteration than the good received by agent $a_j$ in the next $n$-rounds iteration.
However, as we have seen in the previous section, the round-robin mechanism has a very low RAT-degree.
In this section, we propose a new EF1 mechanism that has RAT-degree $n-1$.

\subsubsection{Description of Mechanism}
\label{sect:EF1Mechanism_description}
The mechanism has two components: an agent selection rule $\Gamma$ and an allocation rule $\Psi$.
The agent selection rule $\Gamma$ takes the valuation profile $(v_1,\ldots,v_n)$ as an input and outputs the indices $i^+,i^-$ of two agents, where agent $a_{i^+}$ is called \emph{the mechanism-favored agent} and agent $a_{i^-}$ is called \emph{the mechanism-unfavored agent} (the reason of both names will be clear soon).
The allocation rule $\Psi$ takes the valuation profile $(v_1,\ldots,v_n)$ and the indices of the two agents $i^+,i^-$ output by $\Gamma$ as inputs and then outputs an EF1 allocation $(A_1,\ldots,A_n)$.
We will complete the description of our mechanism by defining $\Gamma$ and $\Psi$.

% \erel{Is it possible to simplify the description by letting $\Gamma$ return a permutaiton of the agents (as in the cake-cutting section), and running round-robin according to that permutation?}
% \biaoshuai{I have thought about this, and I don't think this is true. The same counterexample in the RR RAT degree 1 proof applies here. In that example, no matter the orders, agent 1's manipulation is always safe.}

We first define $\Psi$.
Given the input valuation profile $(v_1,\ldots,v_n)$, let $\efallocations_{i^-}$ be the set of all EF1 allocations $(A_1,\ldots,A_n)$ in which agent $a_{i^-}$ is not envied by anyone else, i.e., for any agent $a_i$, we have $v_i(A_i)\geq v_i(A_{i^-})$.
Notice that $\efallocations_{i^-}$ is nonempty: 
the allocation output by the round-robin mechanism with $i^-$ being the last agent under $\pi$ satisfies both (1) and (2) above.

The rule $\Psi$ then outputs an allocation $(A_1,\ldots,A_n)$ in $\efallocations_{i^-}$ that maximizes $v_{i^+}(A_{i^+})$.
When there are multiple maximizers, the rule breaks the tie in an arbitrary consistent way.
This finishes the description of $\Psi$.

To describe $\Gamma$, we first state a key property called \emph{volatility} that we want from $\Gamma$, and then show that a volatile rule can be constructed.
Informally, volatility says the following.
If an arbitrary agent $a_i$ changes the reported valuation profile from $v_i$ to $v_i'$, we can construct a valuation profile $v_j$ for another agent $a_j$ such that $v_j$ has a positive value on only one pre-specified good and the two agents output by $\Gamma$ switch from some pre-specified $i^+,i^-$ to some pre-specified $i^{+'},i^{-'}$.

\begin{definition}
A selection rule $\Gamma$ is called \emph{volatile}
if 
for any six indices of agents $i,j,i^+,i^-,i^{+'},i^{-'}$ with $i\neq j$, $i^+\neq i^-$, and $i^{+'}\neq i^{-'}$, any good $g_{\ell^\ast}\in G$, any set of $n-2$ valuation profiles $\{v_k\}_{k\notin \{i,j\}}$, and any two reported valuation profiles $v_i,v_i'$ of agent $a_i$ with $v_i\neq v_i'$ (i.e., $v_{i,\ell}\neq v_{i,\ell}'$ for at least one good $g_{\ell}$), there exists a valuation function $v_j$ of agent $a_j$ such that
\begin{itemize}
    \item $v_{j,\ell^\ast}>0$, and $v_{j,\ell}=0$ for any $\ell\neq\ell^\ast$, and
    \item $\Gamma$ outputs $i^+$ and $i^-$ for the valuation profile $\{v_k\}_{k\notin\{i,j\}}\cup\{v_i\}\cup\{v_j\}$, and $\Gamma$ outputs $i^{+'}$ and $i^{-'}$ for the valuation profile $\{v_k\}_{k\notin\{i,j\}}\cup\{v_i'\}\cup\{v_j\}$.
\end{itemize}
\end{definition}
In other words, a manipulation of agent $i$ from $v_i$ to $v_i'$ can affect the output of $\Gamma$ in any possible way (from any pair $i^+,i^-$ to any other pair $i^{+'},i^{-'}$), depending on the report of agent $j$.

We will use an arbitrary volatile rule $\Gamma$ for our mechanism.
We conclude the description of $\Gamma$ by proving (in the appendix) that such a rule exists.

% \biaoshuai{Probably put the proof of the following proposition in the appendix?}
\begin{propositionrep}
    There exists a volatile agent selection rule $\Gamma$.
\end{propositionrep}
\begin{proof}
    The rule $\Gamma$ does the following.
    It first finds the maximum value among all agents and all goods: $\displaystyle v^\ast := \max_{i\in[n],\ell\in[m]}v_{i,\ell}$.
    It then views the value $v^\ast$ as a binary string that encodes the following information:
    \begin{itemize}
        \item the index $i$ of an agent $a_i$;
        \item a non-negative integer $t$,
        \item two non-negative integers $a,b$, between $0$ and ${n \choose 2}$.
        % \item four non-negative integers $a^+,b^+,a^-,b^-$.
    \end{itemize}
    We append $0$'s as most significant bits to $v^\ast$ if the length of the binary string is not long enough to support the format of the encoding.
   If the encoding of $v^\ast$ is longer than the length enough for encoding the above-mentioned information, we take only the least significant bits in the amount required for the encoding.


   
    The mechanism-favored agent $a_{i^+}$ and the mechanism-unfavored agent $a_{i^-}$ are then decided in the following way.
    Let $s\in\{0,1\}$ be the bit at the $t$-th position of the binary encoding of the value $v_i(g_\ell)$.

    Let $p := (a\cdot s + b) \bmod {n \choose 2}$.
    Each value of $p$ corresponds to a pair of different agents $(i^+, i^-)$.
    
    % Let $i^+ := (a^+\cdot s+b^+ \bmod n) + 1$. 
    % if $a^+\cdot s+b^+\in[n]$, and let $i^+=1$ otherwise.
    % Let $i^- := (a^-\cdot s+b^- \bmod n) + 1$.
    % If $i^+=i^-$, we make them different by setting $i^+:=1, i^-:=n$.
    % if $a^-\cdot s+b^-\in [n]$, and let $i^-=n$ otherwise.
    % \erel{Can we take $i^+ = (a^+\cdot s + b^+) \bmod n$?}

    To see that $\Gamma$ is volatile, suppose $v_i$ and $v_i'$ are different in the $t$-th bits of their binary encoding.
    We construct a value $v^*$ that encodes the integers
    $i,t,a,b$ where
    \begin{enumerate}
        \item the $t$-th bit of $v_{i}$ is $s$ and the $t$-th bit of $v_{i}'$ is $s'$ for $s\neq s'$;
        \item The pair $(i^+,i^-)$ corresponds to the integer $(a\cdot s + b) \bmod {n \choose 2}$.
        \item The pair $(i^{+'},i^{-'})$ corresponds to the integer $(a\cdot s' + b) \bmod {n \choose 2}$.
        % $i^+=a^+\cdot s+b^+$ and $i^{+'}=a^{+}\cdot s'+b^{+}$;
        % \item $i^-=a^-\cdot s+b^-$ and $i^{-'}=a^{-}\cdot s'+b^{-}$.
    \end{enumerate}
    (1) can always be achieved by some encoding rule.
    To see (2) and (3) can always be achieved, assume $s=1$ and $s'=0$ without loss of generality.
We can then take $b := $ the integer corresponding to the pair $(i^{+'},i^{-'})$, and $a := - b + $ the integer corresponding to the pair $(i^{+},i^{-})$, modulo ${n\choose 2}$.
    
    % We can then set $b^+=i^{+'}$ and $a^+=i^+-b^+$.
    % We can then set $b^+=i^{+'}$ and $a^+=i^+-b^+$.
    % Similar construction can show that (3) is always achievable.
    
    We then construct a valuation $v_j$ such that $v_{j,\ell^\ast}$ is the largest and is equal to $v^*$.
    In case $v^*$ is not large enough, we increase it as needed by adding nmost significant digits.
\end{proof}

\subsubsection{Proving RAT-degree of $n-1$}
Before we proceed to the proof, we first define some additional notions.
We say that $(A_1,\ldots,A_n)$ is a \emph{partial allocation} if $A_i\cap A_j=\emptyset$ for any pair of $i,j\in[n]$ and $\bigcup_{i=1}^nA_i\subseteq G$.
The definition of EF1 can be straightforwardly extended to partial allocations.
Given a possibly partial allocation $(A_1,\ldots,A_n)$, we say that agent $a_i$ \emph{strongly envies} agent $a_j$ if $v_i(A_i)<v_i(A_j\setminus\{g\})$ for any $g\in A_j$, i.e., the EF1 criterion from $a_i$ to $a_j$ fails.
Given $t \in[n]$, we say that a (possibly partial) allocation $(A_1,\ldots,A_n)$ is \emph{EF1 except for $t$} if for any pair $i,j\in[n]$ with $i\neq t$ we have $v_i(A_i)\geq v_i(A_j\setminus \{g\})$ for some $g\in G$.
In words, the allocation is EF1 except that agent $a_t$ is allowed to strongly-envy others.

We first prove some lemmas which will be used later.
\begin{lemma}\label{prop:partialtocomplete}
    Fix a valuation profile. Let $(A_1,\ldots,A_n)$ be a partial EF1 allocation. There exists a complete EF1 allocation $(A_1^+,\ldots,A_n^+)$ such that $v_i(A_i^+)\geq v_i(A_i)$ for each $i\in [n]$.
\end{lemma}
\begin{proof}
    Construct the envy-graph for the partial allocation $(A_1,\ldots,A_n)$ and then perform the \emph{envy-graph procedure} proposed by~\citet{lipton2004approximately} to obtain a complete allocation $(A_1^+,\ldots,A_n^+)$.
    The monotonic property of the procedure directly implies this proposition.
\end{proof}

\begin{lemmarep}\label{prop:maximuminexception}
    Fix a valuation profile and an arbitrary agent $a_{t}$. Let $\efallocations$ be the set of all complete EF1 allocations. Let ${\efallocations}^{-t}$ be the set of all possibly partial allocations that are EF1 except for possibly $a_t$. The allocation in $\efallocations$ that maximizes agent $a_t$'s utility is also the one in ${\efallocations}^{-t}$ that maximizes $a_t$'s utility.
\end{lemmarep}
In other words, if $a_t$ gets the maximum possible value subject to EF1, he cannot get a higher value by agreeing to give up the EF1 guarantee for himself.
This claim is trivially true for share-based fairness notions such as proportionality, but quite challenging to prove for EF1; see appendix.

% \biaoshuai{I think this proof should go to the appendix.}
\begin{proof}
    Assume $t=1$ without loss of generality.
    The allocation space $\efallocations$ is clearly a subset of ${\efallocations}^{-1}$.
    Assume for the sake of contradiction that, for all possibly partial allocations in ${\efallocations}^{-1}$, agent $a_1$ strongly envies someone else.
    Let $(A_1,\ldots,A_n)$ be  an allocation that minimizes $|\bigcup_{i=1}^nA_i|$ (minimizes the total number of goods allocated) among all allocations in ${\efallocations}^{-1}$.

    For each $i\neq 1$, agent $a_i$ will strongly envy some other agent if an arbitrary good is removed from $A_i$, for otherwise, the minimality is violated.
    We say that an agent $a_i$ \emph{champions} agent $a_j$ if the following holds.
    \begin{itemize}
        \item $a_i$ strongly envies $a_j$ for $i=1$;
        \item for $i\neq 1$, let agent $a_i$ removes the most valuable good from each $A_k$ (for $k\neq i$) and let $A_k^-$ be the resultant bundle; then the championed agent, agent $a_j$, is defined by the index $k$ with the maximum $v_i(A_k^-)$.
    \end{itemize}
    We then construct a \emph{champion graph} which is a directed graph with $n$ vertices where the vertices represent the $n$ agents and an edge from $a_i$ to $a_j$ represents that agent $a_i$ champions agent $a_j$.
    By our definition, each vertex in the graph has at least one outgoing edge, so the graph must contain a directed cycle $C$.

    Consider a new allocation $(A_1',\ldots,A_n')$ defined as follows. For every edge $(a_i,a_j)$ in $C$, let agent $a_i$ remove the most valuable good from $A_{j}$ and then take the bundle.
    We will show that $v_1(A_1')\geq v_1(A_1)$ and $(A_1',\ldots,A_n')\in {\efallocations}^{-1}$, which will contradict the minimality of $(A_1,\ldots,A_n)$.

    It is easy to see $v_1(A_1')\geq v_1(A_1)$. If agent $a_1$ is not in the cycle $C$, then her utility is unchanged. Otherwise, she receives a bundle that she previously strongly envies, and one good is then removed from the bundle. The property of strong envy guarantees that $v_1(A_1')>v_1(A_1)$.

    To show that $(A_1',\ldots,A_n')\in {\efallocations}^{-1}$, first consider any agent $a_i$ with $i\neq 1$ that is not in $C$.
    Agent $a_i$'s bundle is unchanged, and she will not strongly envy anyone else as before (as only item-removals happen during the update).
    
    Next consider any agent $a_i$ with $i\neq 1$ that is in $C$.
    Let $a_j$ be the agent such that $(a_i,a_j)$ is an edge in $C$.
    Let $A_j^-$ be the bundle with the most valuable good (according to $v_i$) removed from $A_j$.
    By our definition, agent $a_i$ receives $A_j^-$ in the new allocation.
    We will prove that agent $a_i$, by receiving $A_j^-$, does not strongly-envy any of the original bundles $A_k$, for any $k\in [n]$.
    
    Our definition of championship ensures that this is true for any $k\neq i$, as the new bundle of $a_i$ is at least as valuable for $a_i$ than every other bundle with an item removed.
    
    It remains to show that this holds for $k=i$.
    As we have argued at the beginning, in the original allocation $(A_1,\ldots,A_n)$, removing any item from $A_i$ would make agent $a_i$ strongly envy some other agent.
    By our definition of championship, when one good $g'$ is removed from $A_i$, agent $a_i$ strongly envies $a_j$, which implies $a_i$ thinks $A_j^-$ is more valuable than $A_i\setminus\{g'\}$.
    Therefore, in the new allocation, by receiving $A_j^-$, agent $a_i$ does not strongly envy $A_i$.
    
    We have proved that agent $a_i$, by receiving the bundle $A_j^-$, does not strongly envy any of the $n$ original bundles $A_1,\ldots,A_n$.
    Since the new allocation only involves item removals, agent $a_i$ does not strongly envy anyone else in the new allocation.
    
    Hence, the new allocation is in $\efallocations_{1^-}$, which contradicts the minimality of $(A_1,\ldots,A_n)$.
\end{proof}

\begin{theoremrep}\label{thm:gamma-psi-indivisible}
    The $\Gamma$-$\Psi$ mechanism in Sect.~\ref{sect:EF1Mechanism_description} has a RAT-degree of $n-1$.
\end{theoremrep}
\begin{proofsketch}
    For every profitable manipulation by $a_i$, and for every unknown agent $a_j$, the volatility of $\Gamma$ implies that, for some possible valuation $v_j$, 
    a truthful report by $a_i$ leads to $a_i$ being the favored agent and $a_j$ being the unfavored agent, whereas the manipulation leads to 
    $a_i$ being the unfavored agent and $a_j$ being the favored agent. We use this fact, combined with \Cref{prop:partialtocomplete} and \Cref{prop:maximuminexception}, to prove that the manipulation may be harmful for $a_i$.
\end{proofsketch}
\begin{proof}
Let $i,j$ be two arbitrary agents.
Fix $n-2$ arbitrary valuations $\{v_k\}_{k\notin\{i,j\}}$ for the remaining $n-2$ agents.
Consider two arbitrary valuations for agent $a_i$, $v_i$ and $v_i'$, with $v_i\neq v_i'$, where $v_i$ is $a_i$'s true valuation.
We will show that switching from $v_i$ to $v_i'$ is not a safe manipulation.

Let $\ell^\ast$ be some good that $a_i$ values positively, that is, $v_{i,\ell^\ast}>0$.
By the volatility of $\Gamma$, we can construct the valuation of agent $a_j$ such that 
\begin{itemize}
    \item $v_{j,\ell^\ast}>0$, and $v_{j,\ell}=0$ for any $\ell\neq\ell^\ast$;
    \item if agent $a_i$ truthfully reports $v_i$, then agent $a_i$ is mechanism-favored and agent $a_j$ is mechanism-unfavored; if agent $a_i$ reports $v_i'$ instead, then agent $a_j$ is mechanism-favored and agent $a_i$ is mechanism-unfavored.
\end{itemize}

Let $(A_1,\ldots,A_n)$ be the allocation output by $\Psi$ when agent $a_i$ reports $v_i$ truthfully, and $(A_1',\ldots,A_n')$ be the allocation output by $\Psi$ when agent $a_i$ reports $v_i'$.
Our objective is to show that $v_i(A_i)>v_i(A_i')$.

Let us consider $(A_1',\ldots,A_n')$ first.
We know that $g_{\ell^\ast}\in A_j'$.
To see this, notice that $A_j'$ maximizes agent $a_j$'s utility as long as $g_{\ell^\ast}\in A_j'$.
In addition, there exists a valid allocation $(A_1',\ldots,A_n')$ output by $\Psi$ with $g_{\ell^\ast}\in A_j'$: consider the round-robin mechanism with agent $a_j$ be the first and agent $a_i$ be the last under the order $\pi$.

Consider a new allocation $(A_1'',\ldots,A_n'')$ in which $g_{l^*}$ is moved from $a_j$ to $a_i$, that is,
\begin{itemize}
\item $A_i''=A_i'\cup\{g_{\ell^\ast}\}$,
\item $A_j''=A_j'\setminus\{g_{\ell^\ast}\}$,
\item $A_k''=A_k'$ for $k\notin\{i,j\}$.
\end{itemize}
Notice that $(A_1'',\ldots,A_n'')$ is EF1 except for $i$: 
\begin{itemize}
    \item agent $a_j$ will not envy any agent $a_k$ with $k\neq i$ (as each bundle $A_k''$ has a zero value for $j$), and agent $a_j$ will not envy agent $a_i$ upon removing the item $g_{\ell^\ast}$ from $A_i''$;
    \item no other agent $k$ strongly envies agent $i$: given that no one envies agent $i$ in $(A_1',\ldots,A_n')$ (as agent $i$ is mechanism-unfavored), no one strongly envies agent $i$ in $(A_1'',\ldots,A_n'')$;
    \item no agent strongly envies agent $a_j$, as $A_j''\subsetneq A_j'$;
    \item any two agents in $N\setminus\{a_i,a_j\}$ do not strongly envy each other, as their allocations are not changed.
\end{itemize}

Now, consider $(A_1,\ldots,A_n)$, which is the allocation that favors agent $a_i$ when agent $a_i$ truthfully reports $v_i$.
We can assume $A_j=\emptyset$ without loss of generality.
If not, we can reallocate goods in $A_j$ to the remaining $n-1$ agents while keeping the EF1 property among the remaining $n-1$ agents (\Cref{prop:partialtocomplete}).
Agent $a_j$ will not strongly envy anyone, as removing the good $g_{\ell^\ast}$ kills the envy.
Thus, the resultant allocation is still EF1 and no one envies the empty bundle $A_j$.
In addition, by \Cref{prop:partialtocomplete}, the utility of each agent $a_k$ with $k\neq j$ does not decrease after the reallocation of $A_j$.

Let ${\yefallocations}$ be the set of all EF1 allocations of the item-set $G$ to the agent-set $N\setminus\{a_j\}$.
Let ${\yefallocations}^{-i}$ be the set of all possibly partial allocations of the item-set $G$ to the agent-set $N\setminus\{a_j\}$ that are EF1 except for agent $i$.
The above argument shows that $(A_1,\ldots,A_{j-1},A_{j+1},\ldots,A_n)$ is an allocation in ${\yefallocations}$ that maximizes agent $a_i$'s utility.
We have also proved that $(A_1'',\ldots,A_{j-1}'',A_{j+1}'',\ldots,A_n'')\in {\yefallocations}^{-i}$.
By \Cref{prop:maximuminexception}, we have $v_i(A_i)\geq v_i(A_i'')$.
In addition, we have $A_i''=A_i'\cup\{g_{\ell^\ast}\}$, $g_{\ell^\ast}\notin A_i'$, and $v_{i,\ell^\ast}>0$ (by our assumption), which imply $v_i(A_i'')>v_i(A_i')$.
Therefore, $v_i(A_i)>v_i(A_i')$.
\end{proof}
