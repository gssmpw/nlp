\section{Discussion and Future Work}\label{sec:discussion}

Our main goal in this paper is to encourage a more quantitative approach to truthfulness that can be applied to various problems. When truthfulness is incompatible with other desirable properties, we aim to find mechanisms that are ``as hard to manipulate as possible'', where hardness is measured by the amount of knowledge required for a safe manipulation. We have considered several alternatives towards the same goal.

\paragraph{Using Randomization} If we used randomness, we could eliminate all safe manipulations. Consider for example the following voting rule:
\begin{itemize}
\item With some small probability $p>0$, run random dictatorship, that is, choose a random voter and elect his top candidate;
\item Otherwise, run plurality voting (or any other voting rule with desirable properties).
\end{itemize}
Due to the small probability of being a dictator, each voter might lose from manipulation, so no manipulation is safe. 
This rule is not entirely far-fetched: governments do sometimes use randomization to encourage truth-telling in tax reports (see e.g. \cite{haan2012sound}). However, randomization is very unlikely to be acceptable in high-stakes voting scenarios.


\paragraph{Beyond Worst-Case} We defined the RAT-degree as a ``worst case'' concept: to prove an upper bound, we find a single example of a safe manipulation. This is similar to the situation with the classic truthfulness notion, where to prove non-truthfulness, it is sufficient to find a single example of a manipulation.
To go beyond the worst case, one could follow relaxations of truthfulness, such as truthful-in-expectation \cite{lavi2011truthful} or strategyproofness-in-the-large \citep{azevedo2019strategy}, and define similarly ``RAT-degree in expectation'' or ``RAT-degree in the large''. 

\paragraph{Alternative Information Measurements}
Another avenue for future work is to study other ways to quantify truthfulness. For example, instead of counting the number of known \emph{agents}, one could count the number of \emph{bits} that an agent should know about other agents' preferences in order to have a safe manipulation. The disadvantage of this approach is that different domains have different input formats, and therefore it would be hard to compare numbers of bits in different domains (see \Cref{apx:related} for more details).


\paragraph{Changing Quantifiers}
One could argue for a stronger definition requiring that a safe manipulation exists for every possible set of $k$ known-agents, rather than for some set, or similarly for every possible preference profile for the known agents rather than just in some profile.
However, we believe such definitions would be less informative, as in many cases, a manipulation that is possible for some set of $k$ known-agents, is not possible for \emph{any} such set. For example, in the first-price auction with discount (see \Cref{sec:first-price-w-discount}), the RAT-degree is $1$ under our definition. But if we required the the knowledge on any agent’s bid would allow manipulation rather than just one, the degree would automatically jump to $n-1$, making the measure far less meaningful.

\paragraph{Combining the "known agents" concept with other notions} 
We believe that the ``known agents'' approach can be used to quantify the degree to which a mechanism is robust to other types of manipulations (besides safe manipulations),
such as ``always-profitable'' manipulations or ``obvious'' manipulation.
Accordingly, one can define the ``max-min-strategyproofness degree'' or the ``NOM degree'' (see \Cref{apx:related}).


% other truthfulness relaxations as well. For example one can 
% define the "NOM degree" - the smallest number of known agents required to allow an obvious manipulation.

% not-obvious manipulability — the degree to which a mechanism is robust to always-profitable manipulations (rather than to safe manipulations).



\eden{need to add explanation of choosing the "for all" and "exists" where we put them. * more informative. to illustrate with the example of first-price auction with a positive discount}

\eden{future: coming up with a relaxation of truthfulness fo risk-\emph{avoiding} agents that would manipulate even if it is a bit risky but very beneficial... not sure who to write it. }

\eden{future: instead of determine the degree by the number of agents that are completely known, consider other measurements - such as, the number of questions the agents should ask...? I think the idea is already written as the number of bits}

\eden{should say something about symmetric mechanism}
