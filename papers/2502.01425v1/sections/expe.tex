% !TeX root = ../all.tex
\begin{figure*}[!ht]
	\centering
	\subfigure[Number of samples before stopping in a random BAI instance, logarithmic scale]{\includegraphics[width=0.3\textwidth]{plot_samp.png}\label{fig:exp}
	}\hspace{1em}
	\subfigure[Number of rounds before stopping in a random BAI instance]{\includegraphics[width=0.3\textwidth]{plot_round.png}
		\label{fig:expr}} \hspace{1em}
	\subfigure[Number of samples before stopping in the min. threshold setting, hard instance]{\includegraphics[width=0.3\textwidth]{TaSbad.png}
		
		\label{fig:exptas}}\label{fig:experiments}\caption{Experimental results, $\delta=0.05$, $N=1000$ runs}\end{figure*}
	
\subsection{Experiments on the BAI setting}


	
	
	

Our algorithm PET is near-optimal in round and sample complexities for many pure exploration problems, and has theoretical guarantees for any pure exploration problem. To ascertain its practical performances, we compare it to baselines and state of the art algorithms for best arm identification and thresholding bandits.	

Each experiment is repeated over 1000 runs. All reward distributions are Gaussian with variance 1 and we use the confidence level $\delta = 0.05$, which is chosen for its relevance to statistical practice. We compare
\begin{itemize}[noitemsep]
	\item Round Robin (or uniform sampling), where the stopping rule is checked only at timesteps $(900\times2^r)_{r \ge 1}$;
	\item Track-and-Stop (TaS) \citep{garivierOptimalBestArm2016}, where the empirical value of $w$ is updated only at timesteps $(900\times 2^r)_r$, and the stopping rule is only checked at those times;
	\item Our algorithm PET, with $T_0 = 1$;
	\item Opt-BBAI \citep{jinOptimalBatchedBest2023} with $\alpha = 1.05$ and the quantities described in their Theorem 4.2.
\end{itemize}
The initial batch sizes for TaS and Round Robin were chosen to approximate the initial batch size of our algorithm, to not disadvantage them in terms of round complexity. We modified TaS in order to turn it into a batch algorithm. Note that there is no formal guarantee for the batch or sample complexity of that modification of TaS, but we use it as a sensible baseline. 

For the BAI experiment, we run each algorithm on $10$-arm instances where the best arm has mean $1$, and each other arm $i$ has mean uniformly sampled between $0.6$ and $0.9$.
See Figure~\ref{fig:exp} for the box plots of the sample complexities. The mean is indicated by a black cross.
While both our algorithm and Opt-BBAI use similarly few batches, PET outperforms Opt-BBAI for the sample complexity.
That algorithm is asymptotically optimal as $\delta\rightarrow 0$ but it uses batches that seem to be too large for moderate values of $\delta$ like the $0.05$ we use.

While the batch modification of TaS might seem to be a good alternative for the BAI experiment, there are instances of the thresholding setting where it performs sub-optimally.
That effect that was first observed in \citep{degenneNonAsymptoticPureExploration2019} for the fully online TaS and reflects that, contrary to our results, the sample complexity guarantees of TaS are only asymptotic. 
We run the algorithms on a thresholding bandit with threshold 0.6 and two arms with means 0.5 and 0.6 and observe that batched TaS has high average sample complexity (see Figure~\ref{fig:exptas}; the mean is the black cross), while PET does not.



