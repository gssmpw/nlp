\section{Related Work}
Creative writing **Klein, "The Oxford Handbook of Computational Creativity"** is on the rise; however, some studies suggest that content generated by human users tends to be more creative _____. This study shows that ChatGPT's ideas are more purchased from Wharton MBA students. There is an ongoing debate about whether LLMs can enhance creativity. To explore this, **Lake, "Building Blocks: Revision and Learning in a Conceptual Space"** demonstrates that when participants were tasked with generating creative ideas for everyday purposes, their creativity improved. However, **Hofstadter, "Fluid Concepts and Creative Analogies Computer Science"** finds that AI-generated narratives often lack imagination and typically include plot twists in a more casual manner. Additionally, **Elman, "An Introduction to Neural Network Architectures"** invited expert writers to evaluate stories generated by LLMs versus those created by professional writers using a standard creativity test. Their findings suggest that LLM-generated stories are less creative compared to those written by professionals.
Empirical studies have underscored this issue. For example, **Sohn, "A Structured Story Generation Model from Free-Text Input"** conducted qualitative analyses involving human judgment and found that after generating 500 samples, 50\% were non-repetitive ideas. However, in the following 1,500 generations, only an additional 50\% of non-repetitive ideas were produced. Alarmingly, in the final 2,000 rounds, just 12.5\% of the generated ideas were non-repetitive. This suggests that while an individual LLM output may appear novel, when generating multiple outputs, the LLM tends to become repetitive, lacking the diversity necessary to effectively enhance collective creativity.
This decline underscores the resource inefficiency and diminishing returns in prolonged LLM-generated content. \\
**Raji, "Stop AI-drunk science"** suggests that novelty in LLM outputs can be detected by ensuring "the text must not have been copied from the training data." However, a more recent study by **Wallace, "The End of History for Content as We Know It"** argues that this definition is superficial. In their experiment on story continuation, they demonstrate that while GPT-4ogenerated samples may meet this standard, the generated continuations are still quite conventional and lack diversity.
**Lowe, "An Analysis of Evaluating Creative Systems Using Human Judgment"** analyze different existing scores that can help measure diversity in LLM outputs, but these metrics all focus on surface-level features such as n-gram overlaps. **Li, "Can Machines be Creative? A Study on AI-generated Content"** indicate that "identifying novel text is not straightforward because the text many have less lexical overlap yet convey the same information." and to the best of our knowledge there is no study to evaluate the diversity, novelty, and correctness of the generated outputs at the same time.