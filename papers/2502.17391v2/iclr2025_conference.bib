
%sym:optimization
@article{neyshabur2015path,
  title={Path-sgd: Path-normalized optimization in deep neural networks},
  author={Neyshabur, Behnam and Salakhutdinov, Russ R and Srebro, Nati},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

%sym:interpretability
@article{godfrey2022symmetries,
  title={On the symmetries of deep learning models and their internal representations},
  author={Godfrey, Charles and Brown, Davis and Emerson, Tegan and Kvinge, Henry},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={11893--11905},
  year={2022}
}

%sym:bayesian
@article{kurle2022detrimental,
  title={On the detrimental effect of invariances in the likelihood for variational inference},
  author={Kurle, Richard and Herbrich, Ralf and Januschowski, Tim and Wang, Yuyang Bernie and Gasthaus, Jan},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={4531--4542},
  year={2022}
}

%relu
@inproceedings{nair2010rectified,
  title={Rectified linear units improve restricted boltzmann machines},
  author={Nair, Vinod and Hinton, Geoffrey E},
  booktitle={Proceedings of the 27th international conference on machine learning (ICML-10)},
  pages={807--814},
  year={2010}
}

%main
@article{lim2024empirical,
  title={The empirical impact of neural parameter symmetries, or lack thereof},
  author={Lim, Derek and Putterman, Theo Moe and Walters, Robin and Maron, Haggai and Jegelka, Stefanie},
  journal={arXiv preprint arXiv:2405.20231},
  year={2024}
}

%deep ensembles
@article{lakshminarayanan2017simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

%moe deep learning overview.
@article{fedus2022review,
  title={A review of sparse expert models in deep learning},
  author={Fedus, William and Dean, Jeff and Zoph, Barret},
  journal={arXiv preprint arXiv:2209.01667},
  year={2022}
}

%moe old overview
@article{yuksel2012twenty,
  title={Twenty years of mixture of experts},
  author={Yuksel, Seniha Esen and Wilson, Joseph N and Gader, Paul D},
  journal={IEEE transactions on neural networks and learning systems},
  volume={23},
  number={8},
  pages={1177--1193},
  year={2012},
  publisher={IEEE}
}


%MoE NLP
@inproceedings{du2022glam,
  title={Glam: Efficient scaling of language models with mixture-of-experts},
  author={Du, Nan and Huang, Yanping and Dai, Andrew M and Tong, Simon and Lepikhin, Dmitry and Xu, Yuanzhong and Krikun, Maxim and Zhou, Yanqi and Yu, Adams Wei and Firat, Orhan and others},
  booktitle={International Conference on Machine Learning},
  pages={5547--5569},
  year={2022},
  organization={PMLR}
}

%MoE CV
@article{puigcerver2023sparse,
  title={From sparse to soft mixtures of experts},
  author={Puigcerver, Joan and Riquelme, Carlos and Mustafa, Basil and Houlsby, Neil},
  journal={arXiv preprint arXiv:2308.00951},
  year={2023}
}
%% MoE CV
@article{riquelme2021scaling,
  title={Scaling vision with sparse mixture of experts},
  author={Riquelme, Carlos and Puigcerver, Joan and Mustafa, Basil and Neumann, Maxim and Jenatton, Rodolphe and Susano Pinto, Andr{\'e} and Keysers, Daniel and Houlsby, Neil},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={8583--8595},
  year={2021}
}

%MoE Tabular
@article{chernov2025moe,
  title={MoE vs. MLP on Tabular Data},
  author={Chernov, Andrei},
  journal={arXiv preprint arXiv:2502.03608},
  year={2025}
}

@article{hendrycks2016gaussian,
  title={Gaussian error linear units (gelus)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}


%dataset: california
@article{pace1997sparse,
  title={Sparse spatial autoregressions},
  author={Pace, R Kelley and Barry, Ronald},
  journal={Statistics \& Probability Letters},
  volume={33},
  number={3},
  pages={291--297},
  year={1997},
  publisher={Elsevier}
}

%dataset: mnist
@article{deng2012mnist,
  title={The mnist database of handwritten digit images for machine learning research [best of the web]},
  author={Deng, Li},
  journal={IEEE signal processing magazine},
  volume={29},
  number={6},
  pages={141--142},
  year={2012},
  publisher={IEEE}
}

%dataset: adult
@inproceedings{kohavi1996scaling,
  title={Scaling up the accuracy of naive-bayes classifiers: A decision-tree hybrid.},
  author={Kohavi, Ron and others},
  booktitle={Kdd},
  volume={96},
  pages={202--207},
  year={1996}
}

%relu symmetries
@inproceedings{wiese2023towards,
  title={Towards efficient MCMC sampling in Bayesian neural networks by exploiting symmetry},
  author={Wiese, Jonas Gregor and Wimmer, Lisa and Papamarkou, Theodore and Bischl, Bernd and G{\"u}nnemann, Stephan and R{\"u}gamer, David},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={459--474},
  year={2023},
  organization={Springer}
}

%permutation symmetreis
@inproceedings{pourzanjani2017improving,
  title={Improving the identifiability of neural networks for Bayesian inference},
  author={Pourzanjani, Arya A and Jiang, Richard M and Petzold, Linda R},
  booktitle={NIPS workshop on bayesian deep learning},
  volume={4},
  pages={31},
  year={2017}
}

%permutation symmetreis
@inproceedings{pittorino2022deep,
  title={Deep networks on toroids: removing symmetries reveals the structure of flat regions in the landscape geometry},
  author={Pittorino, Fabrizio and Ferraro, Antonio and Perugini, Gabriele and Feinauer, Christoph and Baldassi, Carlo and Zecchina, Riccardo},
  booktitle={International Conference on Machine Learning},
  pages={17759--17781},
  year={2022},
  organization={PMLR}
}
%scaling symmetries
@article{badrinarayanan2015understanding,
  title={Understanding symmetries in deep networks},
  author={Badrinarayanan, Vijay and Mishra, Bamdev and Cipolla, Roberto},
  journal={arXiv preprint arXiv:1511.01029},
  year={2015}
}