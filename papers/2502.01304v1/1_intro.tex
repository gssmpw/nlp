\section{INTRODUCTION} \label{Sec:Intro}
Forestry machines are equipped with redundant hydraulic manipulators which are used for manipulation tasks such as grasping and arranging heavy wood logs. 
Although automation has become prevalent across different industries, forestry machines rely primarily on manual operation. 
Operating these machines requires highly skilled operators trained for many hours. 
This is because these machines comprise un-actuated joints and hydraulic actuators with
%typical machines constitute hydraulic actuators and unactuated joints which pose 
several constraints, e.g., joint limits, actuator limits, and total pump flow limits. 
Currently, the world is facing a shortage of highly skilled machine operators due to the aging population in Europe and the USA, the high workload, and the extensive training costs. 
%truck drivers, and large-scale machine manipulators due to the age of the workforce, high-intensity workload, and high cost of training. 
As a result, there is an urgent need to develop concepts for the autonomous or semi-autonomous operation of such machines, see %autonomous or semi-autonomous large machines, see, e.g., 
\cite{ortiz2014increasing}, \cite{kalmari2017coordinated}. 

In recent years, different simulation environments and benchmarking frameworks have been developed in robotics research, e.g.,  \cite{ibarz2021train,sunderhauf2018limits,nguyen2024language,kumar2024robohive,mittal2023orbit,vuong2023grasp}, driven by the emergence of data-driven approaches like machine learning and deep reinforcement learning that heavily rely on training data. This makes the use of simulated environments for training-specific practical tasks popular because given the slow operating speeds of robots and safety considerations, acquiring a large amount of real-world robotic data is a big challenge. However, building a realistic simulator requires the capability to represent physics, dynamics, and sensors within the simulation environment. Despite the inherent challenges, the integration of machine learning, particularly reinforcement learning (RL), with robotics has enabled significant progress in intelligent systems, especially in robotic manipulation~\cite{wang2023dexterous,zhou2023hacman,vuong2024language,vu2025online}. While most RL-based approaches focus on training specific skills for conventional manipulation tasks with popular collaborative robots \cite{mu2021maniskill}, large-scale manipulators, such as those used in forestry, have only recently started to gain attention \cite{andersson2021reinforcement,ayoub2023grasp}. In this work, we prioritize two core objectives: \textit{i)} building a robust, open-source simulation environment tailored for forestry crane operations and \textit{ii)} benchmarking reinforcement learning algorithms on a challenging wood-log grasping task. Our framework not only allows for the realistic simulation of large-scale manipulator tasks but also provides a platform to evaluate and improve RL performance in heavy-duty environments.


\begin{figure*}
\centering
\label{fig:rotbot1}
\scalebox{0.98}{
\def\svgwidth{2\columnwidth}
\input{figures/mujoco-crane.pdf_tex}
}
\vspace{2ex}
\caption{(a) Snapshot of the simulated environment. While the logs' length is fixed to $l=\SI{2.75}{\meter}$, their diameters are varied in the range $d=[0.3,\:0.8]$ \SI{}{\meter}, (b) Real crane setup in outdoor environment.}
\label{fig: example mujoco}
\vspace{-0.2ex}
\end{figure*}

We consider a popular scenario in the wood-log grasping task: The forestry crane is randomly placed near a wood log location. Our goal is to estimate the wood log's six degrees of freedom (DoF) pose, including its location in the 3D Cartesian space and its orientation, and then develop an RL-based controller to grasp the wood log at its center and lift it. 
An example of the simulation environment is illustrated in Figure~\ref{fig: example mujoco}. 
%The question, ``Can we train an RL agent to learn how to robustly grasp a log that can be located anywhere in the workspace and have different sizes?'', will be answered in this paper. 
To facilitate the training, we create a closely matching simulated model and environment based on our real forestry crane setup. The system dynamics and kinematics are verified through a calibration process, which helps to reduce the sim-to-real gap in future applications. 
%Although assuming the known pose of the log is a strong assumption, 
In the real setup shown in Figure~\ref{fig: example mujoco} (b), the position of the selected tree log is localized using a precise sensor fusion vision system, such as lidar and stereo cameras. Then, the proposed RL method is used to grasp the log. In this way, thanks to its modularity, we can ensure the safety and flexibility of the proposed framework, which are very important in a large-scale environment. 


The contributions of our work are as follows:
\begin{itemize}
    \item We present a simulation environment of the large-scale forestry crane that is built from the CAD model of a real forestry crane. 
    %Additionally, we provide a detailed training environment consisting of an analysis of the observation space and reward functions for training an RL-based velocity controller. 
    \item We propose a new RL algorithm, modified Proximal Policy Optimization (mPPO) by replacing the Gaussian distribution with a restricted distribution and adding a heuristic factor to the trained network proves efficient for the heavy wood-log grasping task. 
\end{itemize}


%\textbf{Should rewrite this paragraph, stress more direct on our contribution: 1. build simulator. 2. benchmark RL} 
%\textbf{\textit{Despite these challenges, the integration of machine learning, particularly reinforcement learning (RL), and robotics has made advancements in intelligent systems, notably in the domain of robotic manipulation \cite{wang2023dexterous,zhou2023hacman}. Most existing RL-based manipulation approaches have been focused on learning specific skills to perform conventional manipulation tasks with popular collaborative robots \cite{mu2021maniskill}. On the other hand, RL-based large manipulators have received attention in recent years \cite{andersson2021reinforcement,ayoub2023grasp} but not to the same extent as other types of robots. In this work, we implement an open-source simulation environment and deploy an RL algorithm to train a wood-log grasping task with a forestry crane. }}




%\textbf{Challenges for robot?} \textbf{Missing in SOTA now in the field?}
%\textcolor{orange}{TODO: SOTA?}
%, exposing operators to mentally and physically demanding tasks with potential long-term health implications [4]. 
%Semi-automation efforts have demonstrated success in increasing productivity and reducing operator workload [6], [20], yet the potential of RL frameworks for end-to-end learning in simulated environments presents a novel approach, eliminating the need for analytic low-level controllers.

%Forestry cranes are used to load wood logs from a pile or the forest floor onto the bed of a truck. 
%The loading cycle consists of moving the grapple over one or several wood logs, grasping them, moving the crane back to the truck bed, and placing the logs there. 




% \subsection{Contribution}
% The contributions of our work are as follows:
% \begin{itemize}
%     \item We present a simulation environment of the large-scale forestry crane in the open-source software Mujoco \cite{todorov2012mujoco} that is built from the CAD model of a real forestry crane. 
%     Additionally, we provide a detailed training environment consisting of an analysis of the observation space and reward functions for training an RL-based velocity controller. 
%     \item Benchmarking results for training the simulated environment with different RL approaches, including our proposed modified Proximal Policy Optimization (mPPO), are presented. In the proposed mPPO, replacing the Gaussian distribution with a restricted distribution and adding a heuristic factor to the trained network proves efficient for the considered task. 
% \end{itemize}



%This research represents an exploration of emerging areas, as RL control for forestry crane manipulators has so far not been investigated in the field of machine learning or robotics research. 
%Our study is a preliminary attempt to evaluate the feasibility of using RL approaches to learn effective speed control strategies for grasping logs of different sizes, specifically using an underpowered forestry crane manipulator with 10 degrees of freedom (DoF). 
%The ultimate goal is to lay the groundwork for comprehensive automation of forest crane operations, thereby achieving a potential breakthrough in an industry facing profound change.

%\lipsum[1]
%\lipsum[1]
% \subsection{Paper structure}
% %The remainder of the paper is as follows. In the next section, a brief introduction to kinematics and the simulator is presented. 
% The following section presents a brief introduction to the kinematics and the simulator. 
% Section \ref{sec: method} deals with the problem's modeling, the grasping task's learning environment, and the modified PPO algorithm. 
% %, the modeling of the problem, the learning environment for the grasping task, and the modified PPO algorithm are presented in detail. 
% Simulation results and an analysis are summarized in Section \ref{Sec:exp}. Finally, Section \ref{Sec:con} concludes this work and gives directions for future research.  
% %\lipsum[1]

