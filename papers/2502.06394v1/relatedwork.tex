\section{Background and Related Work}
\subsection{Text Style Transfer}

Text Style Transfer (TST), the task of rewriting the text in a target style while preserving its semantic content and fluency, has garnered significant attention in the natural language processing community due to its potential applications in text generation~\cite{DBLP:conf/aaai/FuTPZY18}. TST encompasses various subtasks, including formality style transfer~\cite{DBLP:conf/coling/WangWMLC20, DBLP:conf/acl/LaiTN20}, sentiment style transfer~\cite{DBLP:conf/emnlp/YuZLC21}, authorship style transfer~\cite{DBLP:journals/corr/abs-2406-15586, DBLP:journals/corr/abs-2403-08043}, and detoxification~\cite{DBLP:conf/emnlp/DaleVDLKSP21,DBLP:conf/coling/AtwellHA22, DBLP:journals/corr/abs-2206-02252, DBLP:conf/emnlp/MoskovskiyPP24}. 

With the advent of Large Language Models (LLMs), in-context learning methods have increasingly been utilized for TST and detoxification tasks. \citet{DBLP:conf/emnlp/SuzgunMJ22} proposed a novel approach to TST by prompting LLMs and then reranking the generated texts based on three TST metrics: text similarity, target style strength, and fluency. Similarly, \citet{DBLP:conf/acl/ReifIYCCW22} demonstrated the effectiveness of prompting GPT-3, a state-of-the-art LLM at the time, to rewrite texts in a desired style.

\subsection{Text Detoxification}

Text Detoxification, a subtask of Text Style Transfer (TST), involves transforming an input text $x_i$, identified as toxic through toxicity estimation models, into a text $y_i$ that is non-toxic in style while maintaining semantic similarity and fluency. In this context, toxicity refers to language that is harmful, offensive, or inappropriate.

% Due to the lack of parallel training data, early research focused on unsupervised detoxification methods~\cite{DBLP:conf/acl/SantosMP18, DBLP:conf/emnlp/DaleVDLKSP21, DBLP:conf/acl/HallinanL0S23, DBLP:conf/emnlp/PourFBVPS23}. For instance,~\citet{DBLP:conf/acl/SantosMP18} proposed a cycle consistency loss for translating toxic texts into a non-toxic style in an unsupervised manner. More recently, the introduction of parallel detoxification corpora, such as ParaDetox~\cite{DBLP:conf/acl/LogachevaDUMDKS22} and APPDIA~\cite{DBLP:conf/coling/AtwellHA22}, has enabled the training of sequence-to-sequence models~\cite{DBLP:conf/acl/LogachevaDUMDKS22, DBLP:conf/emnlp/PourFBVPS23} that outperform most unsupervised approaches in terms of rewritten toxicity, fluency, and semantic similarity. Finally, \citet{DBLP:conf/emnlp/MoskovskiyPP24} used activation patched LLMs to generate synthetic parallel detoxification data for English based on ParaDetox and showed that training on this data yields better detoxification models.

Due to the lack of parallel training data, early research focused on unsupervised detoxification methods~\cite{DBLP:conf/acl/SantosMP18, DBLP:conf/emnlp/DaleVDLKSP21, DBLP:conf/acl/HallinanL0S23, DBLP:conf/emnlp/PourFBVPS23}. For instance,\cite{DBLP:conf/acl/LogachevaDUMDKS22} and APPDIA~\cite{DBLP:conf/coling/AtwellHA22}, has enabled the training of sequence-to-sequence models~\cite{DBLP:conf/acl/LogachevaDUMDKS22, DBLP:conf/emnlp/PourFBVPS23} that outperform most unsupervised approaches in terms of rewritten toxicity, fluency, and semantic similarity. In parallel, \citet{DBLP:conf/emnlp/MoskovskiyPP24} explored the use of activation patching in LLMs to generate synthetic parallel detoxification data for English. Their results demonstrated that training detoxification models on this data yields performance comparable to models trained on manually annotated datasets in automatic evaluations, while achieving superior quality in human assessments.

\subsection{Multilingual Text Style Transfer}

The scarcity of high-quality parallel multilingual detoxification data remains a major challenge in the field. Recently, new non-English parallel datasets have been introduced for various TST tasks, including a Bangla language parallel sentiment style transfer dataset~\cite{mukherjee-etal-2023-low} and the extension of the GYAFC dataset to Portuguese, French, and Italian, resulting in XFORMAL~\cite{DBLP:conf/naacl/BriakouLZT21}. Following the crowdsourcing pipeline introduced by~\cite{DBLP:conf/acl/LogachevaDUMDKS22}, a parallel text detoxification dataset for Russian was collected~\cite{DBLP:journals/corr/abs-2206-02252}. Later, using the similar data annotation pipeline,~\citet{DBLP:conf/clef/DementievaMBAR024} collected 1000 sentence pairs across nine languages, resulting in the MultiParaDetox dataset for a corresponding shared task on multilingual text detoxification. Furthermore, in a more recent work~\citet{DBLP:conf/coling/DementievaBRAR025}, provide an in-depth analysis of toxicity characteristics across languages, exploring descriptive linguistic features that influence detoxification quality.

Nevertheless, the size of MultiParaDetox is far from satisfactory with 1000 sentence pairs per language, only 400 of which are publicly available. The remaining 600 pairs comprised the test set for the multilingual text detoxification shared task~\cite{DBLP:conf/clef/DementievaMBAR024}. Such relatively small dataset may be insufficient for training big multilingual language models for multilingual text detoxification.

To bridge this gap, we present \dataset~- a synthetic parallel detoxification corpus for four European languages, namely, German, Spanish, French, and Russian, with 4000 samples for each language. The dataset creationg pipeline presented in our work can easily be transferred to other languages as well, drastically reducing the cost of annotation for parallel detoxification datasets.