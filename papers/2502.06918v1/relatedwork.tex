\section{Related works}
\label{s:rw}
\paragraph{Conformance checking for anomaly detection in BPM.}
Anomaly detection in BPM has been effectively addressed using \textit{conformance checking} techniques~\cite{Dunzer2019}. These methods excel at detecting deviations from constraints explicitly defined by business process models, such as ensuring that certain activities are performed in parallel, or that prescribed preconditions are followed in a sequence preceding an executed task. For example, in a model where activities $A$ and $B$ must run concurrently, conformance checking can easily flag an sequence of events as non-compliant if $A$ and $B$ are not executed, but will not identify any anomaly based on the order of $A$ and $B$, which may follow any ordering. However, these techniques are inherently tied to the control-flow rules derived from the process model, making it difficult to incorporate insights from other event log dimensions, such as resource allocation, event's attributes or performance indicators. This limitation makes their applicability more challenging when dealing with anomalies that span multiple dimensions or features, often requiring domain-specific solutions~\cite{Carmona2022}.

\paragraph{Machine learning for multidimensional anomaly detection.}
Machine learning techniques have also been applied to anomaly detection in BPM, offering greater flexibility in capturing multidimensional aspects of event logs~\cite{Barbon2020}. For example, by analysing attributes such as resource workloads, task durations and case metadata, machine learning models can identify complex patterns of variation, such as cases where certain resources consistently take longer for certain tasks, which could indicate inefficiencies or skill mismatches~\cite{Pasquadibisceglie2021}. However, these techniques struggle with preserving the order of events and enforcing model-specific constraints, such as parallel activities or strict sequences. For example, recognising that $A$ must always occur before $B$ becomes less direct for a machine learning model, as these relationships can be encoded using specific methods for transforming the original data. As a result, while machine learning is powerful for multidimensional anomaly detection, it may not be able to enforce strict adherence to process structure, which is critical in many BPM applications~\cite{Peeperkorn2023}.

\paragraph{Object centric anomaly detection.}
One of the proposed approaches to business process anomaly detection is via graph neural networks on object-centric event logs~\cite{b2}. Unlike traditional process mining methods that rely on ``flattened'' event logs tied to a single case identifier, this approach exploits object-centric process mining where events can be associated with multiple cases. In~\cite{b2}  a graph convolutional autoencoder (GCNAE) architecture that reconstructs object-centric event logs as attributed graphs is exploited. Anomaly detection is performed by computing anomaly scores based on the reconstruction errors of these graphs, allowing the identification of anomalies at both activity and attribute levels.
%
Despite its innovations, the approach has notable limitations. A significant drawback is its poor performance in detecting anomalies related to the temporal sequence of events. Temporal order anomalies are critical in detecting anomalies in business processes, as many anomalies involve incorrect ordering of activities. Reliance on GNNs, which primarily aggregate local neighbourhood information, can obscure subtle temporal shifts, undermining the model's ability to effectively detect such patterns.
%
While the object-centric approach improves accuracy, it also introduces significant complexity \cite{object_centric_anomaly_detection_challenge}. Transforming object-centric process instances into graphs can be computationally expensive, especially for large datasets, potentially limiting scalability and efficiency in real-world applications with large event logs.
%
In addition, the model lacks a clear interpretability mechanism to explain the root causes of detected anomalies. This reduces its practical utility, as organisations often require actionable insights to effectively address and resolve problems in their processes.



\paragraph{Fuzzy based anomaly detection.}
In \cite{b3} a method for detecting anomalies in large event logs generated by Enterprise Resource Planning (ERP) systems is presented. The approach integrates three core techniques: process mining, fuzzy multi-attribute decision making, and fuzzy association rule learning.
%
Process mining is used to check the conformance of event logs to standard operating procedures and to identify deviations that may indicate anomalies.
Fuzzy multi-attribute decisioning assigns anomaly rates to these deviations based on expert judgement, enabling a nuanced assessment of their significance.
Fuzzy association rule learning generates rules to detect fraudulent behaviour by analysing anomalies at different confidence levels.
%
While this system provides a structured methodology, it has several limitations. One critical challenge is its heavy reliance on expert judgement to determine anomaly weights and rates. This reliance creates a bottleneck for real-world implementation, requiring ongoing expert input to configure and fine-tune fuzzy parameters and thresholds. The difficulty of optimising these thresholds across different business environments can lead to an overabundance of false positives or undetected anomalies, undermining the reliability of the system.

\paragraph{LLM based anomaly detection.}
One of the LLM-based anomaly detection approaches has been introduced by Wei Guan in~\cite{b5}. In this paper, the author presents a method that detects semantic anomalies in business processes. This approach leverages LLMs, specifically \textit{Llama 2}, fine-tuned using generated logs across various domains. 
%
Although this method improves semantic anomaly detection, it inherits a limitation common to other semantic-based approaches, namely the disruption of long-distance dependencies between events. Traces are split into event pairs, which can miss critical relationships throughout the process.
%
In addition, this approach depends heavily on simulated anomalies from the generated dataset. This might limit its effectiveness when applied to entirely novel datasets with unanticipated types of anomalies. The reliance on synthetic data could also result in gaps when addressing real-world, complex processes.

\paragraph{The proposed appraoch.}
In contrast to the approaches discussed, our study introduces a \textbf{GPT-4o}-based tool that leverages natural language processing to capture multidimensional aspects, minimize preprocessing efforts, reduce reliance on domain experts, and mitigate the complexity of traditional methods, making it an appealing solution for modern, dynamic BPM environments.