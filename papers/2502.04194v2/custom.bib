% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {$L_1$}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
  url={https://dl.acm.org/doi/abs/10.1145/1273496.1273501}
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK},
    url={https://www.cambridge.org/core/books/algorithms-on-strings-trees-and-sequences/F0B095049C7E6EF5356F0A26686C20D3}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005},
	url={https://www.jmlr.org/papers/volume6/ando05a/ando05a.pdf}
}

@article{ct1965,
  title={An algorithm for the machine calculation of complex {F}ourier series},
  author={Cooley, James W. and Tukey, John W.},
  journal={Mathematics of Computation},
  volume={19},
  number={90},
  pages={297--301},
  year={1965},
  url={https://www.ams.org/journals/mcom/1965-19-090/S0025-5718-1965-0178586-1/S0025-5718-1965-0178586-1.pdf}
}


@inproceedings{chen2023codet,
  author       = {Bei Chen and
                  Fengji Zhang and
                  Anh Nguyen and
                  Daoguang Zan and
                  Zeqi Lin and
                  Jian{-}Guang Lou and
                  Weizhu Chen},
  title        = {CodeT: Code Generation with Generated Tests},
  booktitle    = {The Eleventh International Conference on Learning Representations,
                  {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  publisher    = {OpenReview.net},
  year         = {2023},
  url          = {https://openreview.net/pdf?id=ktrw68Cmu9c},
  timestamp    = {Fri, 30 Jun 2023 14:55:53 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/ChenZNZLLC23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{rozière2024codellama,
      title={Code Llama: Open Foundation Models for Code}, 
      author={Baptiste Rozière and Jonas Gehring and Fabian Gloeckle and Sten Sootla and Itai Gat and Xiaoqing Ellen Tan and Yossi Adi and Jingyu Liu and Romain Sauvestre and Tal Remez and Jérémy Rapin and Artyom Kozhevnikov and Ivan Evtimov and Joanna Bitton and Manish Bhatt and Cristian Canton Ferrer and Aaron Grattafiori and Wenhan Xiong and Alexandre Défossez and Jade Copet and Faisal Azhar and Hugo Touvron and Louis Martin and Nicolas Usunier and Thomas Scialom and Gabriel Synnaeve},
      year={2024},
      eprint={2308.12950},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{rafailov2023dpo,
      title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model}, 
      author={Rafael Rafailov and Archit Sharma and Eric Mitchell and Stefano Ermon and Christopher D. Manning and Chelsea Finn},
      year={2023},
      eprint={2305.18290},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{ethayarajh2024kto,
      title={KTO: Model Alignment as Prospect Theoretic Optimization}, 
      author={Kawin Ethayarajh and Winnie Xu and Niklas Muennighoff and Dan Jurafsky and Douwe Kiela},
      year={2024},
      eprint={2402.01306},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@article{chen2024grath,
  author       = {Weixin Chen and
                  Dawn Song and
                  Bo Li},
  title        = {{GRATH:} Gradual Self-Truthifying for Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2401.12292},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2401.12292},
  doi          = {10.48550/ARXIV.2401.12292},
  eprinttype    = {arXiv},
  eprint       = {2401.12292},
  timestamp    = {Mon, 08 Apr 2024 10:26:21 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2401-12292.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@misc{mitra2024orcamath,
      title={Orca-Math: Unlocking the potential of SLMs in Grade School Math}, 
      author={Arindam Mitra and Hamed Khanpour and Corby Rosset and Ahmed Awadallah},
      year={2024},
      eprint={2402.14830},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}



@misc{yuan2024eurus,
      title={Advancing LLM Reasoning Generalists with Preference Trees}, 
      author={Lifan Yuan and Ganqu Cui and Hanbin Wang and Ning Ding and Xingyao Wang and Jia Deng and Boji Shan and Huimin Chen and Ruobing Xie and Yankai Lin and Zhenghao Liu and Bowen Zhou and Hao Peng and Zhiyuan Liu and Maosong Sun},
      year={2024},
      eprint={2404.02078},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}


@article{alphacode,
   title={Competition-level code generation with AlphaCode},
   volume={378},
   ISSN={1095-9203},
   url={http://dx.doi.org/10.1126/science.abq1158},
   DOI={10.1126/science.abq1158},
   number={6624},
   journal={Science},
   publisher={American Association for the Advancement of Science (AAAS)},
   author={Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, Rémi and Eccles, Tom and Keeling, James and Gimeno, Felix and Dal Lago, Agustin and Hubert, Thomas and Choy, Peter and de Masson d’Autume, Cyprien and Babuschkin, Igor and Chen, Xinyun and Huang, Po-Sen and Welbl, Johannes and Gowal, Sven and Cherepanov, Alexey and Molloy, James and Mankowitz, Daniel J. and Sutherland Robson, Esme and Kohli, Pushmeet and de Freitas, Nando and Kavukcuoglu, Koray and Vinyals, Oriol},
   year={2022},
   month=dec, pages={1092–1097} }

@misc{tufano2021unittest,
      title={Unit Test Case Generation with Transformers and Focal Context}, 
      author={Michele Tufano and Dawn Drain and Alexey Svyatkovskiy and Shao Kun Deng and Neel Sundaresan},
      year={2021},
      eprint={2009.05617},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@inproceedings{randoop,
  title={Feedback-directed random test generation},
  author={Pacheco, Carlos and Lahiri, Shuvendu K and Ernst, Michael D and Ball, Thomas},
  booktitle={29th International Conference on Software Engineering (ICSE'07)},
  pages={75--84},
  year={2007},
  organization={IEEE}
}
@inproceedings{evosuite,
  title={{EvoSuite}: automatic test suite generation for object-oriented software},
  author={Fraser, Gordon and Arcuri, Andrea},
  booktitle={Proceedings of the 19th ACM SIGSOFT symposium and the 13th European conference on Foundations of software engineering},
  pages={416--419},
  year={2011}
}
@inproceedings{mosa,
  title={Reformulating branch coverage as a many-objective optimization problem},
  author={Panichella, Annibale and Kifetew, Fitsum Meshesha and Tonella, Paolo},
  booktitle={2015 IEEE 8th international conference on software testing, verification and validation (ICST)},
  pages={1--10},
  year={2015},
  organization={IEEE}
}

@article{fakhoury2024interactivetest,
  title={LLM-based Test-driven Interactive Code Generation: User Study and Empirical Evaluation},
  author={Fakhoury, Sarah and Naik, Aaditya and Sakkas, Georgios and Chakraborty, Saikat and Lahiri, Shuvendu K},
  journal={arXiv preprint arXiv:2404.10100},
  year={2024}
}
@misc{endres2024specification,
      title={Can Large Language Models Transform Natural Language Intent into Formal Method Postconditions?}, 
      author={Madeline Endres and Sarah Fakhoury and Saikat Chakraborty and Shuvendu K. Lahiri},
      year={2024},
      eprint={2310.01831},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@article{
li2023starcoder,
title={StarCoder: may the source be with you!},
author={Raymond Li and Loubna Ben allal and Yangtian Zi and Niklas Muennighoff and Denis Kocetkov and Chenghao Mou and Marc Marone and Christopher Akiki and Jia LI and Jenny Chim and Qian Liu and Evgenii Zheltonozhskii and Terry Yue Zhuo and Thomas Wang and Olivier Dehaene and Joel Lamy-Poirier and Joao Monteiro and Nicolas Gontier and Ming-Ho Yee and Logesh Kumar Umapathi and Jian Zhu and Ben Lipkin and Muhtasham Oblokulov and Zhiruo Wang and Rudra Murthy and Jason T Stillerman and Siva Sankalp Patel and Dmitry Abulkhanov and Marco Zocca and Manan Dey and Zhihan Zhang and Urvashi Bhattacharyya and Wenhao Yu and Sasha Luccioni and Paulo Villegas and Fedor Zhdanov and Tony Lee and Nadav Timor and Jennifer Ding and Claire S Schlesinger and Hailey Schoelkopf and Jan Ebert and Tri Dao and Mayank Mishra and Alex Gu and Carolyn Jane Anderson and Brendan Dolan-Gavitt and Danish Contractor and Siva Reddy and Daniel Fried and Dzmitry Bahdanau and Yacine Jernite and Carlos Mu{\~n}oz Ferrandis and Sean Hughes and Thomas Wolf and Arjun Guha and Leandro Von Werra and Harm de Vries},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2023},
url={https://openreview.net/forum?id=KoFOg41haE},
note={Reproducibility Certification}
}

@misc{lozhkov2024starcoder2,
      title={StarCoder 2 and The Stack v2: The Next Generation}, 
      author={Anton Lozhkov and Raymond Li and Loubna Ben Allal and Federico Cassano and Joel Lamy-Poirier and Nouamane Tazi and Ao Tang and Dmytro Pykhtar and Jiawei Liu and Yuxiang Wei and Tianyang Liu and Max Tian and Denis Kocetkov and Arthur Zucker and Younes Belkada and Zijian Wang and Qian Liu and Dmitry Abulkhanov and Indraneil Paul and Zhuang Li and Wen-Ding Li and Megan Risdal and Jia Li and Jian Zhu and Terry Yue Zhuo and Evgenii Zheltonozhskii and Nii Osae Osae Dade and Wenhao Yu and Lucas Krauß and Naman Jain and Yixuan Su and Xuanli He and Manan Dey and Edoardo Abati and Yekun Chai and Niklas Muennighoff and Xiangru Tang and Muhtasham Oblokulov and Christopher Akiki and Marc Marone and Chenghao Mou and Mayank Mishra and Alex Gu and Binyuan Hui and Tri Dao and Armel Zebaze and Olivier Dehaene and Nicolas Patry and Canwen Xu and Julian McAuley and Han Hu and Torsten Scholak and Sebastien Paquet and Jennifer Robinson and Carolyn Jane Anderson and Nicolas Chapados and Mostofa Patwary and Nima Tajbakhsh and Yacine Jernite and Carlos Muñoz Ferrandis and Lingming Zhang and Sean Hughes and Thomas Wolf and Arjun Guha and Leandro von Werra and Harm de Vries},
      year={2024},
      eprint={2402.19173},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@misc{guo2024deepseekcoder,
      title={DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence}, 
      author={Daya Guo and Qihao Zhu and Dejian Yang and Zhenda Xie and Kai Dong and Wentao Zhang and Guanting Chen and Xiao Bi and Y. Wu and Y. K. Li and Fuli Luo and Yingfei Xiong and Wenfeng Liang},
      year={2024},
      eprint={2401.14196},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@misc{bai2023qwen,
      title={Qwen Technical Report}, 
      author={Jinze Bai and Shuai Bai and Yunfei Chu and Zeyu Cui and Kai Dang and Xiaodong Deng and Yang Fan and Wenbin Ge and Yu Han and Fei Huang and Binyuan Hui and Luo Ji and Mei Li and Junyang Lin and Runji Lin and Dayiheng Liu and Gao Liu and Chengqiang Lu and Keming Lu and Jianxin Ma and Rui Men and Xingzhang Ren and Xuancheng Ren and Chuanqi Tan and Sinan Tan and Jianhong Tu and Peng Wang and Shijie Wang and Wei Wang and Shengguang Wu and Benfeng Xu and Jin Xu and An Yang and Hao Yang and Jian Yang and Shusheng Yang and Yang Yao and Bowen Yu and Hongyi Yuan and Zheng Yuan and Jianwei Zhang and Xingxuan Zhang and Yichang Zhang and Zhenru Zhang and Chang Zhou and Jingren Zhou and Xiaohuan Zhou and Tianhang Zhu},
      year={2023},
      eprint={2309.16609},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{rozière2024code,
      title={Code Llama: Open Foundation Models for Code}, 
      author={Baptiste Rozière and Jonas Gehring and Fabian Gloeckle and Sten Sootla and Itai Gat and Xiaoqing Ellen Tan and Yossi Adi and Jingyu Liu and Romain Sauvestre and Tal Remez and Jérémy Rapin and Artyom Kozhevnikov and Ivan Evtimov and Joanna Bitton and Manish Bhatt and Cristian Canton Ferrer and Aaron Grattafiori and Wenhan Xiong and Alexandre Défossez and Jade Copet and Faisal Azhar and Hugo Touvron and Louis Martin and Nicolas Usunier and Thomas Scialom and Gabriel Synnaeve},
      year={2024},
      eprint={2308.12950},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{luo2023wizardcoder,
      title={WizardCoder: Empowering Code Large Language Models with Evol-Instruct}, 
      author={Ziyang Luo and Can Xu and Pu Zhao and Qingfeng Sun and Xiubo Geng and Wenxiang Hu and Chongyang Tao and Jing Ma and Qingwei Lin and Daxin Jiang},
      year={2023},
      eprint={2306.08568},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{wei2023magicoder,
      title={Magicoder: Source Code Is All You Need}, 
      author={Yuxiang Wei and Zhe Wang and Jiawei Liu and Yifeng Ding and Lingming Zhang},
      year={2023},
      eprint={2312.02120},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{zheng2024opencodeinterpreter,
      title={OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement}, 
      author={Tianyu Zheng and Ge Zhang and Tianhao Shen and Xueling Liu and Bill Yuchen Lin and Jie Fu and Wenhu Chen and Xiang Yue},
      year={2024},
      eprint={2402.14658},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}


@misc{wang2024leti,
      title={LeTI: Learning to Generate from Textual Interactions}, 
      author={Xingyao Wang and Hao Peng and Reyhaneh Jabbarvand and Heng Ji},
      year={2024},
      eprint={2305.10314},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{jain2024livecodebench,
      title={LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code}, 
      author={Naman Jain and King Han and Alex Gu and Wen-Ding Li and Fanjia Yan and Tianjun Zhang and Sida Wang and Armando Solar-Lezama and Koushik Sen and Ion Stoica},
      year={2024},
      eprint={2403.07974},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}


@misc{chen2021humaneval,
      title={Evaluating Large Language Models Trained on Code}, 
      author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
      year={2021},
      eprint={2107.03374},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{austin2021mbpp,
      title={Program Synthesis with Large Language Models}, 
      author={Jacob Austin and Augustus Odena and Maxwell Nye and Maarten Bosma and Henryk Michalewski and David Dohan and Ellen Jiang and Carrie Cai and Michael Terry and Quoc Le and Charles Sutton},
      year={2021},
      eprint={2108.07732},
      archivePrefix={arXiv},
      primaryClass={cs.PL}
}

@misc{liu2023evalplus,
      title={Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation}, 
      author={Jiawei Liu and Chunqiu Steven Xia and Yuyao Wang and Lingming Zhang},
      year={2023},
      eprint={2305.01210},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}



@misc{openai2024gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{aici2024microsoft,
  author = {Moskal, Michal and Musuvathi, Madan and {K\i c\i man}, Emre},
  title = {{AI Controller Interface}},
  year = {2024},
  publisher = {{GitHub}},
  journal = {{GitHub} repository},
  howpublished = {\url{https://github.com/microsoft/aici/}}
}


@misc{ugare2024syncode,
      title={SynCode: LLM Generation with Grammar Augmentation}, 
      author={Shubham Ugare and Tarun Suresh and Hangoo Kang and Sasa Misailovic and Gagandeep Singh},
      year={2024},
      eprint={2403.01632},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{wei2023repilot,
author = {Wei, Yuxiang and Xia, Chunqiu Steven and Zhang, Lingming},
title = {Copiloting the Copilots: Fusing Large Language Models with Completion Engines for Automated Program Repair},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616271},
doi = {10.1145/3611643.3616271},
abstract = {During Automated Program Repair (APR), it can be challenging to synthesize correct patches for real-world systems in general-purpose programming languages. Recent Large Language Models (LLMs) have been shown to be helpful “copilots” in assisting developers with various coding tasks, and have also been directly applied for patch synthesis. However, most LLMs treat programs as sequences of tokens, meaning that they are ignorant of the underlying semantics constraints of the target programming language. This results in plenty of statically invalid generated patches, impeding the practicality of the technique. Therefore, we propose Repilot, a framework to further copilot the AI “copilots” (i.e., LLMs) by synthesizing more valid patches during the repair process. Our key insight is that many LLMs produce outputs autoregressively (i.e., token by token), resembling human writing programs, which can be significantly boosted and guided through a Completion Engine. Repilot synergistically synthesizes a candidate patch through the interaction between an LLM and a Completion Engine, which 1) prunes away infeasible tokens suggested by the LLM and 2) proactively completes the token based on the suggestions provided by the Completion Engine. Our evaluation on a subset of the widely-used Defects4j 1.2 and 2.0 datasets shows that Repilot fixes 66 and 50 bugs, respectively, surpassing the best-performing baseline by 14 and 16 bugs fixed. More importantly, Repilot is capable of producing more valid and correct patches than the base LLM when given the same generation budget.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {172–184},
numpages = {13},
keywords = {Program Repair, Large Language Model, Completion Engine},
location = {, San Francisco, CA, USA, },
series = {ESEC/FSE 2023}
}


@misc{codealpaca,
  author = {Sahil Chaudhary},
  title = {Code Alpaca: An Instruction-following LLaMA model for code generation},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/sahil280114/codealpaca}},
}
@misc{gu2024cruxeval,
      title={CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution}, 
      author={Alex Gu and Baptiste Rozière and Hugh Leather and Armando Solar-Lezama and Gabriel Synnaeve and Sida I. Wang},
      year={2024},
      eprint={2401.03065},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@misc{liu2024codemind,
      title={CodeMind: A Framework to Challenge Large Language Models for Code Reasoning}, 
      author={Changshu Liu and Shizhuo Dylan Zhang and Ali Reza Ibrahimzada and Reyhaneh Jabbarvand},
      year={2024},
      eprint={2402.09664},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@misc{azar2023ipo,
      title={A General Theoretical Paradigm to Understand Learning from Human Preferences}, 
      author={Mohammad Gheshlaghi Azar and Mark Rowland and Bilal Piot and Daniel Guo and Daniele Calandriello and Michal Valko and Rémi Munos},
      year={2023},
      eprint={2310.12036},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@inproceedings{kulal2019spoc,
  title={SPoC: Search-based pseudocode to code},
  author={Kulal, Aditya and Sawant, Mayur Naik and Kumar, Aditya and Natarajan, Nitin and Paliwal, Aniruddha and Das, Dipanjan and Ravi, Satish},
  booktitle={Advances in Neural Information Processing Systems},
  pages={19927--19937},
  year={2019}
}

@misc{wang2024mathshepherd,
      title={Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations}, 
      author={Peiyi Wang and Lei Li and Zhihong Shao and R. X. Xu and Damai Dai and Yifei Li and Deli Chen and Y. Wu and Zhifang Sui},
      year={2024},
      eprint={2312.08935},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{Cleston_ShareGPT_2023,
  author = {Cleston, Dome},
  title = {ShareGPT},
  year = {2023},
  howpublished = {\url{https://github.com/domeccleston/sharegpt}},
}

@misc{bai2022hhrlhf,
      title={Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback}, 
      author={Yuntao Bai and Andy Jones and Kamal Ndousse and Amanda Askell and Anna Chen and Nova DasSarma and Dawn Drain and Stanislav Fort and Deep Ganguli and Tom Henighan and Nicholas Joseph and Saurav Kadavath and Jackson Kernion and Tom Conerly and Sheer El-Showk and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Tristan Hume and Scott Johnston and Shauna Kravec and Liane Lovitt and Neel Nanda and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Ben Mann and Jared Kaplan},
      year={2022},
      eprint={2204.05862},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{zhang2023r,
  title={R-tuning: Teaching large language models to refuse unknown questions},
  author={Zhang, Hanning and Diao, Shizhe and Lin, Yong and Fung, Yi R and Lian, Qing and Wang, Xingyao and Chen, Yangyi and Ji, Heng and Zhang, Tong},
  journal={arXiv preprint arXiv:2311.09677},
  year={2023}
}

@article{zhou2024lima,
  title={Lima: Less is more for alignment},
  author={Zhou, Chunting and Liu, Pengfei and Xu, Puxin and Iyer, Srinivasan and Sun, Jiao and Mao, Yuning and Ma, Xuezhe and Efrat, Avia and Yu, Ping and Yu, Lili and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{perelman2014test-driven-programming,
author = {Perelman, Daniel and Gulwani, Sumit and Grossman, Dan and Provost, Peter},
title = {Test-Driven Synthesis},
booktitle = {PLDI '14, June 09-11, 2014, Edinburgh, United Kingdom},
year = {2014},
month = {June},
url = {https://www.microsoft.com/en-us/research/publication/test-driven-synthesis/},
edition = {PLDI ’14, June 09–11, 2014, Edinburgh, United Kingdom},
}

@inproceedings{Gulwani2016ProgrammingBE,
  title={Programming by Examples - and its applications in Data Wrangling},
  author={Sumit Gulwani},
  booktitle={Dependable Software Systems Engineering},
  year={2016},
  url={https://api.semanticscholar.org/CorpusID:7866845}
}


@inproceedings{sumith2019spoc,
 author = {Kulal, Sumith and Pasupat, Panupong and Chandra, Kartik and Lee, Mina and Padon, Oded and Aiken, Alex and Liang, Percy S},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {SPoC: Search-based Pseudocode to Code},
 url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/7298332f04ac004a0ca44cc69ecf6f6b-Paper.pdf},
 volume = {32},
 year = {2019}
}

@misc{zhang2023algo,
      title={ALGO: Synthesizing Algorithmic Programs with LLM-Generated Oracle Verifiers}, 
      author={Kexun Zhang and Danqing Wang and Jingtao Xia and William Yang Wang and Lei Li},
      year={2023},
      eprint={2305.14591},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{zelikman2023parsel,
      title={Parsel: Algorithmic Reasoning with Language Models by Composing Decompositions}, 
      author={Eric Zelikman and Qian Huang and Gabriel Poesia and Noah D. Goodman and Nick Haber},
      year={2023},
      eprint={2212.10561},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{ball2023efficientonlinereinforcementlearning,
      title={Efficient Online Reinforcement Learning with Offline Data}, 
      author={Philip J. Ball and Laura Smith and Ilya Kostrikov and Sergey Levine},
      year={2023},
      eprint={2302.02948},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2302.02948}, 
}

@misc{shinn2023reflexion,
      title={Reflexion: Language Agents with Verbal Reinforcement Learning}, 
      author={Noah Shinn and Federico Cassano and Edward Berman and Ashwin Gopinath and Karthik Narasimhan and Shunyu Yao},
      year={2023},
      eprint={2303.11366},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2303.11366}, 
}
@misc{deepseekv2,
      title={DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence}, 
      author={DeepSeek-AI and Qihao Zhu and Daya Guo and Zhihong Shao and Dejian Yang and Peiyi Wang and Runxin Xu and Y. Wu and Yukun Li and Huazuo Gao and Shirong Ma and Wangding Zeng and Xiao Bi and Zihui Gu and Hanwei Xu and Damai Dai and Kai Dong and Liyue Zhang and Yishi Piao and Zhibin Gou and Zhenda Xie and Zhewen Hao and Bingxuan Wang and Junxiao Song and Deli Chen and Xin Xie and Kang Guan and Yuxiang You and Aixin Liu and Qiushi Du and Wenjun Gao and Xuan Lu and Qinyu Chen and Yaohui Wang and Chengqi Deng and Jiashi Li and Chenggang Zhao and Chong Ruan and Fuli Luo and Wenfeng Liang},
      year={2024},
      eprint={2406.11931},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2406.11931}, 
}

@inproceedings{le2022coderl,
 author = {Le, Hung and Wang, Yue and Gotmare, Akhilesh Deepak and Savarese, Silvio and Hoi, Steven Chu Hong},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {21314--21328},
 publisher = {Curran Associates, Inc.},
 title = {CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/8636419dea1aa9fbd25fc4248e702da4-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}
@article{
shojaee2023ppocoder,
title={Execution-based Code Generation using Deep Reinforcement Learning},
author={Parshin Shojaee and Aneesh Jain and Sindhu Tipirneni and Chandan K. Reddy},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2023},
url={https://openreview.net/forum?id=0XBuaxqEcG},
note={}
}


@article{
liu2023rltf,
title={{RLTF}: Reinforcement Learning from Unit Test Feedback},
author={Jiate Liu and Yiqin Zhu and Kaiwen Xiao and QIANG FU and Xiao Han and Yang Wei and Deheng Ye},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2023},
url={https://openreview.net/forum?id=hjYmsV6nXZ},
note={}
}
@inproceedings{
haluptzok2023languageteachthemselved,
title={Language Models Can Teach Themselves to Program Better},
author={Patrick Haluptzok and Matthew Bowers and Adam Tauman Kalai},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=SaRj2ka1XZ3}
}

@article{zhang2024selfexploring,
  title={Self-Exploring Language Models: Active Preference Elicitation for Online Alignment},
  author={Zhang, Shenao and Yu, Donghan and Sharma, Hiteshi and Yang, Ziyi and Wang, Shuohang and Hassan, Hany and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2405.19332},
  year={2024}
}

@misc{ding2024sail,
      title={SAIL: Self-Improving Efficient Online Alignment of Large Language Models}, 
      author={Mucong Ding and Souradip Chakraborty and Vibhu Agrawal and Zora Che and Alec Koppel and Mengdi Wang and Amrit Bedi and Furong Huang},
      year={2024},
      eprint={2406.15567},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.15567}, 
}
@article{tajwar2024shoulduse,
  title={Preference fine-tuning of llms should leverage suboptimal, on-policy data},
  author={Tajwar, Fahim and Singh, Anikait and Sharma, Archit and Rafailov, Rafael and Schneider, Jeff and Xie, Tengyang and Ermon, Stefano and Finn, Chelsea and Kumar, Aviral},
  journal={arXiv preprint arXiv:2404.14367},
  year={2024}
}
@misc{guo2024onlineaifeedback,
      title={Direct Language Model Alignment from Online AI Feedback}, 
      author={Shangmin Guo and Biao Zhang and Tianlin Liu and Tianqi Liu and Misha Khalman and Felipe Llinares and Alexandre Rame and Thomas Mesnard and Yao Zhao and Bilal Piot and Johan Ferret and Mathieu Blondel},
      year={2024},
      eprint={2402.04792},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2402.04792}, 
}

@misc{liu2024statisticalrejectionsamplingimproves,
      title={Statistical Rejection Sampling Improves Preference Optimization}, 
      author={Tianqi Liu and Yao Zhao and Rishabh Joshi and Misha Khalman and Mohammad Saleh and Peter J. Liu and Jialu Liu},
      year={2024},
      eprint={2309.06657},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.06657}, 
}

@article{dong2023raft,
  title={Raft: Reward ranked finetuning for generative foundation model alignment},
  author={Dong, Hanze and Xiong, Wei and Goyal, Deepanshu and Zhang, Yihan and Chow, Winnie and Pan, Rui and Diao, Shizhe and Zhang, Jipeng and Shum, Kashun and Zhang, Tong},
  journal={arXiv preprint arXiv:2304.06767},
  year={2023}
}
@misc{mistralai_codestral_2024,
  author = {MistralAI},
  title = {Codestral-22B-v0.1},
  year = {2024},
  url = {https://huggingface.co/mistralai/Codestral-22B-v0.1},
  note = {Accessed: 2024-09-28}
}
@inproceedings{
xiong2024iterative,
title={Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for {RLHF} under {KL}-constraint},
author={Wei Xiong and Hanze Dong and Chenlu Ye and Ziqi Wang and Han Zhong and Heng Ji and Nan Jiang and Tong Zhang},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=c1AKcA6ry1}
}

@misc{dong2024rlhfworkflowrewardmodeling,
      title={RLHF Workflow: From Reward Modeling to Online RLHF}, 
      author={Hanze Dong and Wei Xiong and Bo Pang and Haoxiang Wang and Han Zhao and Yingbo Zhou and Nan Jiang and Doyen Sahoo and Caiming Xiong and Tong Zhang},
      year={2024},
      eprint={2405.07863},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.07863}, 
}
@misc{tang2024understandingperformancegaponline,
      title={Understanding the performance gap between online and offline alignment algorithms}, 
      author={Yunhao Tang and Daniel Zhaohan Guo and Zeyu Zheng and Daniele Calandriello and Yuan Cao and Eugene Tarassov and Rémi Munos and Bernardo Ávila Pires and Michal Valko and Yong Cheng and Will Dabney},
      year={2024},
      eprint={2405.08448},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.08448}, 
}
@misc{yang2024preferencepairscreatedequal,
      title={Not All Preference Pairs Are Created Equal: A Recipe for Annotation-Efficient Iterative Preference Learning}, 
      author={Sen Yang and Leyang Cui and Deng Cai and Xinting Huang and Shuming Shi and Wai Lam},
      year={2024},
      eprint={2406.17312},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.17312}, 
}
@article{xu2024bpo,
  title={BPO: Supercharging Online Preference Learning by Adhering to the Proximity of Behavior LLM},
  author={Xu, Wenda and Li, Jiachen and Wang, William Yang and Li, Lei},
  journal={arXiv preprint arXiv:2406.12168},
  year={2024}
}

@article{wu2024selfplay,
  title={Self-play preference optimization for language model alignment},
  author={Wu, Yue and Sun, Zhiqing and Yuan, Huizhuo and Ji, Kaixuan and Yang, Yiming and Gu, Quanquan},
  journal={arXiv preprint arXiv:2405.00675},
  year={2024}
}
@misc{pang2024iterativereasoningpreferenceoptimization,
      title={Iterative Reasoning Preference Optimization}, 
      author={Richard Yuanzhe Pang and Weizhe Yuan and Kyunghyun Cho and He He and Sainbayar Sukhbaatar and Jason Weston},
      year={2024},
      eprint={2404.19733},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.19733}, 
}
@misc{chen2024unlockcorrelationsupervisedfinetuning,
      title={Unlock the Correlation between Supervised Fine-Tuning and Reinforcement Learning in Training Code Large Language Models}, 
      author={Jie Chen and Xintian Han and Yu Ma and Xun Zhou and Liang Xiang},
      year={2024},
      eprint={2406.10305},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2406.10305}, 
}
@misc{jain2023coarsetuningmodelscodereinforcement,
      title={Coarse-Tuning Models of Code with Reinforcement Learning Feedback}, 
      author={Abhinav Jain and Chima Adiole and Swarat Chaudhuri and Thomas Reps and Chris Jermaine},
      year={2023},
      eprint={2305.18341},
      archivePrefix={arXiv},
      primaryClass={cs.PL},
      url={https://arxiv.org/abs/2305.18341}, 
}

@misc{dubey2024llama3herdmodels,
      title={The Llama 3 Herd of Models}, 
      author={Abhimanyu Dubey and Abhinav Jauhri and Abhinav Pandey and Abhishek Kadian and Ahmad Al-Dahle and Aiesha Letman and Akhil Mathur and Alan Schelten and Amy Yang and Angela Fan and Anirudh Goyal and Anthony Hartshorn and Aobo Yang and Archi Mitra and Archie Sravankumar and Artem Korenev and Arthur Hinsvark and Arun Rao and Aston Zhang and Aurelien Rodriguez and Austen Gregerson and Ava Spataru and Baptiste Roziere and Bethany Biron and Binh Tang and Bobbie Chern and Charlotte Caucheteux and Chaya Nayak and Chloe Bi and Chris Marra and Chris McConnell and Christian Keller and Christophe Touret and Chunyang Wu and Corinne Wong and Cristian Canton Ferrer and Cyrus Nikolaidis and Damien Allonsius and Daniel Song and Danielle Pintz and Danny Livshits and David Esiobu and Dhruv Choudhary and Dhruv Mahajan and Diego Garcia-Olano and Diego Perino and Dieuwke Hupkes and Egor Lakomkin and Ehab AlBadawy and Elina Lobanova and Emily Dinan and Eric Michael Smith and Filip Radenovic and Frank Zhang and Gabriel Synnaeve and Gabrielle Lee and Georgia Lewis Anderson and Graeme Nail and Gregoire Mialon and Guan Pang and Guillem Cucurell and Hailey Nguyen and Hannah Korevaar and Hu Xu and Hugo Touvron and Iliyan Zarov and Imanol Arrieta Ibarra and Isabel Kloumann and Ishan Misra and Ivan Evtimov and Jade Copet and Jaewon Lee and Jan Geffert and Jana Vranes and Jason Park and Jay Mahadeokar and Jeet Shah and Jelmer van der Linde and Jennifer Billock and Jenny Hong and Jenya Lee and Jeremy Fu and Jianfeng Chi and Jianyu Huang and Jiawen Liu and Jie Wang and Jiecao Yu and Joanna Bitton and Joe Spisak and Jongsoo Park and Joseph Rocca and Joshua Johnstun and Joshua Saxe and Junteng Jia and Kalyan Vasuden Alwala and Kartikeya Upasani and Kate Plawiak and Ke Li and Kenneth Heafield and Kevin Stone and Khalid El-Arini and Krithika Iyer and Kshitiz Malik and Kuenley Chiu and Kunal Bhalla and Lauren Rantala-Yeary and Laurens van der Maaten and Lawrence Chen and Liang Tan and Liz Jenkins and Louis Martin and Lovish Madaan and Lubo Malo and Lukas Blecher and Lukas Landzaat and Luke de Oliveira and Madeline Muzzi and Mahesh Pasupuleti and Mannat Singh and Manohar Paluri and Marcin Kardas and Mathew Oldham and Mathieu Rita and Maya Pavlova and Melanie Kambadur and Mike Lewis and Min Si and Mitesh Kumar Singh and Mona Hassan and Naman Goyal and Narjes Torabi and Nikolay Bashlykov and Nikolay Bogoychev and Niladri Chatterji and Olivier Duchenne and Onur Çelebi and Patrick Alrassy and Pengchuan Zhang and Pengwei Li and Petar Vasic and Peter Weng and Prajjwal Bhargava and Pratik Dubal and Praveen Krishnan and Punit Singh Koura and Puxin Xu and Qing He and Qingxiao Dong and Ragavan Srinivasan and Raj Ganapathy and Ramon Calderer and Ricardo Silveira Cabral and Robert Stojnic and Roberta Raileanu and Rohit Girdhar and Rohit Patel and Romain Sauvestre and Ronnie Polidoro and Roshan Sumbaly and Ross Taylor and Ruan Silva and Rui Hou and Rui Wang and Saghar Hosseini and Sahana Chennabasappa and Sanjay Singh and Sean Bell and Seohyun Sonia Kim and Sergey Edunov and Shaoliang Nie and Sharan Narang and Sharath Raparthy and Sheng Shen and Shengye Wan and Shruti Bhosale and Shun Zhang and Simon Vandenhende and Soumya Batra and Spencer Whitman and Sten Sootla and Stephane Collot and Suchin Gururangan and Sydney Borodinsky and Tamar Herman and Tara Fowler and Tarek Sheasha and Thomas Georgiou and Thomas Scialom and Tobias Speckbacher and Todor Mihaylov and Tong Xiao and Ujjwal Karn and Vedanuj Goswami and Vibhor Gupta and Vignesh Ramanathan and Viktor Kerkez and Vincent Gonguet and Virginie Do and Vish Vogeti and Vladan Petrovic and Weiwei Chu and Wenhan Xiong and Wenyin Fu and Whitney Meers and Xavier Martinet and Xiaodong Wang and Xiaoqing Ellen Tan and Xinfeng Xie and Xuchao Jia and Xuewei Wang and Yaelle Goldschlag and Yashesh Gaur and Yasmine Babaei and Yi Wen and Yiwen Song and Yuchen Zhang and Yue Li and Yuning Mao and Zacharie Delpierre Coudert and Zheng Yan and Zhengxing Chen and Zoe Papakipos and Aaditya Singh and Aaron Grattafiori and Abha Jain and Adam Kelsey and Adam Shajnfeld and Adithya Gangidi and Adolfo Victoria and Ahuva Goldstand and Ajay Menon and Ajay Sharma and Alex Boesenberg and Alex Vaughan and Alexei Baevski and Allie Feinstein and Amanda Kallet and Amit Sangani and Anam Yunus and Andrei Lupu and Andres Alvarado and Andrew Caples and Andrew Gu and Andrew Ho and Andrew Poulton and Andrew Ryan and Ankit Ramchandani and Annie Franco and Aparajita Saraf and Arkabandhu Chowdhury and Ashley Gabriel and Ashwin Bharambe and Assaf Eisenman and Azadeh Yazdan and Beau James and Ben Maurer and Benjamin Leonhardi and Bernie Huang and Beth Loyd and Beto De Paola and Bhargavi Paranjape and Bing Liu and Bo Wu and Boyu Ni and Braden Hancock and Bram Wasti and Brandon Spence and Brani Stojkovic and Brian Gamido and Britt Montalvo and Carl Parker and Carly Burton and Catalina Mejia and Changhan Wang and Changkyu Kim and Chao Zhou and Chester Hu and Ching-Hsiang Chu and Chris Cai and Chris Tindal and Christoph Feichtenhofer and Damon Civin and Dana Beaty and Daniel Kreymer and Daniel Li and Danny Wyatt and David Adkins and David Xu and Davide Testuggine and Delia David and Devi Parikh and Diana Liskovich and Didem Foss and Dingkang Wang and Duc Le and Dustin Holland and Edward Dowling and Eissa Jamil and Elaine Montgomery and Eleonora Presani and Emily Hahn and Emily Wood and Erik Brinkman and Esteban Arcaute and Evan Dunbar and Evan Smothers and Fei Sun and Felix Kreuk and Feng Tian and Firat Ozgenel and Francesco Caggioni and Francisco Guzmán and Frank Kanayet and Frank Seide and Gabriela Medina Florez and Gabriella Schwarz and Gada Badeer and Georgia Swee and Gil Halpern and Govind Thattai and Grant Herman and Grigory Sizov and Guangyi and Zhang and Guna Lakshminarayanan and Hamid Shojanazeri and Han Zou and Hannah Wang and Hanwen Zha and Haroun Habeeb and Harrison Rudolph and Helen Suk and Henry Aspegren and Hunter Goldman and Ibrahim Damlaj and Igor Molybog and Igor Tufanov and Irina-Elena Veliche and Itai Gat and Jake Weissman and James Geboski and James Kohli and Japhet Asher and Jean-Baptiste Gaya and Jeff Marcus and Jeff Tang and Jennifer Chan and Jenny Zhen and Jeremy Reizenstein and Jeremy Teboul and Jessica Zhong and Jian Jin and Jingyi Yang and Joe Cummings and Jon Carvill and Jon Shepard and Jonathan McPhie and Jonathan Torres and Josh Ginsburg and Junjie Wang and Kai Wu and Kam Hou U and Karan Saxena and Karthik Prasad and Kartikay Khandelwal and Katayoun Zand and Kathy Matosich and Kaushik Veeraraghavan and Kelly Michelena and Keqian Li and Kun Huang and Kunal Chawla and Kushal Lakhotia and Kyle Huang and Lailin Chen and Lakshya Garg and Lavender A and Leandro Silva and Lee Bell and Lei Zhang and Liangpeng Guo and Licheng Yu and Liron Moshkovich and Luca Wehrstedt and Madian Khabsa and Manav Avalani and Manish Bhatt and Maria Tsimpoukelli and Martynas Mankus and Matan Hasson and Matthew Lennie and Matthias Reso and Maxim Groshev and Maxim Naumov and Maya Lathi and Meghan Keneally and Michael L. Seltzer and Michal Valko and Michelle Restrepo and Mihir Patel and Mik Vyatskov and Mikayel Samvelyan and Mike Clark and Mike Macey and Mike Wang and Miquel Jubert Hermoso and Mo Metanat and Mohammad Rastegari and Munish Bansal and Nandhini Santhanam and Natascha Parks and Natasha White and Navyata Bawa and Nayan Singhal and Nick Egebo and Nicolas Usunier and Nikolay Pavlovich Laptev and Ning Dong and Ning Zhang and Norman Cheng and Oleg Chernoguz and Olivia Hart and Omkar Salpekar and Ozlem Kalinli and Parkin Kent and Parth Parekh and Paul Saab and Pavan Balaji and Pedro Rittner and Philip Bontrager and Pierre Roux and Piotr Dollar and Polina Zvyagina and Prashant Ratanchandani and Pritish Yuvraj and Qian Liang and Rachad Alao and Rachel Rodriguez and Rafi Ayub and Raghotham Murthy and Raghu Nayani and Rahul Mitra and Raymond Li and Rebekkah Hogan and Robin Battey and Rocky Wang and Rohan Maheswari and Russ Howes and Ruty Rinott and Sai Jayesh Bondu and Samyak Datta and Sara Chugh and Sara Hunt and Sargun Dhillon and Sasha Sidorov and Satadru Pan and Saurabh Verma and Seiji Yamamoto and Sharadh Ramaswamy and Shaun Lindsay and Shaun Lindsay and Sheng Feng and Shenghao Lin and Shengxin Cindy Zha and Shiva Shankar and Shuqiang Zhang and Shuqiang Zhang and Sinong Wang and Sneha Agarwal and Soji Sajuyigbe and Soumith Chintala and Stephanie Max and Stephen Chen and Steve Kehoe and Steve Satterfield and Sudarshan Govindaprasad and Sumit Gupta and Sungmin Cho and Sunny Virk and Suraj Subramanian and Sy Choudhury and Sydney Goldman and Tal Remez and Tamar Glaser and Tamara Best and Thilo Kohler and Thomas Robinson and Tianhe Li and Tianjun Zhang and Tim Matthews and Timothy Chou and Tzook Shaked and Varun Vontimitta and Victoria Ajayi and Victoria Montanez and Vijai Mohan and Vinay Satish Kumar and Vishal Mangla and Vítor Albiero and Vlad Ionescu and Vlad Poenaru and Vlad Tiberiu Mihailescu and Vladimir Ivanov and Wei Li and Wenchen Wang and Wenwen Jiang and Wes Bouaziz and Will Constable and Xiaocheng Tang and Xiaofang Wang and Xiaojian Wu and Xiaolan Wang and Xide Xia and Xilun Wu and Xinbo Gao and Yanjun Chen and Ye Hu and Ye Jia and Ye Qi and Yenda Li and Yilin Zhang and Ying Zhang and Yossi Adi and Youngjin Nam and Yu and Wang and Yuchen Hao and Yundi Qian and Yuzi He and Zach Rait and Zachary DeVito and Zef Rosnbrick and Zhaoduo Wen and Zhenyu Yang and Zhiwei Zhao},
      year={2024},
      eprint={2407.21783},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.21783}, 
}

@article{fisch2024robust,
  title={Robust preference optimization through reward model distillation},
  author={Fisch, Adam and Eisenstein, Jacob and Zayats, Vicky and Agarwal, Alekh and Beirami, Ahmad and Nagpal, Chirag and Shaw, Pete and Berant, Jonathan},
  journal={arXiv preprint arXiv:2405.19316},
  year={2024}
}
@misc{liu2024provablymitigatingoveroptimizationrlhf,
      title={Provably Mitigating Overoptimization in RLHF: Your SFT Loss is Implicitly an Adversarial Regularizer}, 
      author={Zhihan Liu and Miao Lu and Shenao Zhang and Boyi Liu and Hongyi Guo and Yingxiang Yang and Jose Blanchet and Zhaoran Wang},
      year={2024},
      eprint={2405.16436},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.16436}, 
}
@misc{xiong2024buildingmathagentsmultiturn,
      title={Building Math Agents with Multi-Turn Iterative Preference Learning}, 
      author={Wei Xiong and Chengshuai Shi and Jiaming Shen and Aviv Rosenberg and Zhen Qin and Daniele Calandriello and Misha Khalman and Rishabh Joshi and Bilal Piot and Mohammad Saleh and Chi Jin and Tong Zhang and Tianqi Liu},
      year={2024},
      eprint={2409.02392},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2409.02392}, 
}

@misc{gee2024codeoptimiseselfgeneratedpreferencedata,
      title={Code-Optimise: Self-Generated Preference Data for Correctness and Efficiency}, 
      author={Leonidas Gee and Milan Gritta and Gerasimos Lampouras and Ignacio Iacobacci},
      year={2024},
      eprint={2406.12502},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.12502}, 
}
@misc{hui2024qwen25,
      title={Qwen2.5-Coder Technical Report}, 
      author={Binyuan Hui and Jian Yang and Zeyu Cui and Jiaxi Yang and Dayiheng Liu and Lei Zhang and Tianyu Liu and Jiajun Zhang and Bowen Yu and Keming Lu and Kai Dang and Yang Fan and Yichang Zhang and An Yang and Rui Men and Fei Huang and Bo Zheng and Yibo Miao and Shanghaoran Quan and Yunlong Feng and Xingzhang Ren and Xuancheng Ren and Jingren Zhou and Junyang Lin},
      year={2024},
      eprint={2409.12186},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.12186}, 
}


@misc{yang2024qwen2technicalreport,
      title={Qwen2 Technical Report}, 
      author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jianxin Yang and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Xuejing Liu and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhifang Guo and Zhihao Fan},
      year={2024},
      eprint={2407.10671},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.10671}, 
}

@misc{dai2024rlprm,
      title={Process Supervision-Guided Policy Optimization for Code Generation}, 
      author={Ning Dai and Zheng Wu and Renjie Zheng and Ziyun Wei and Wenlei Shi and Xing Jin and Guanlin Liu and Chen Dun and Liang Huang and Lin Yan},
      year={2024},
      eprint={2410.17621},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2410.17621}, 
}

@misc{zhang2024instructiontuninglargelanguage,
      title={Instruction Tuning for Large Language Models: A Survey}, 
      author={Shengyu Zhang and Linfeng Dong and Xiaoya Li and Sen Zhang and Xiaofei Sun and Shuhe Wang and Jiwei Li and Runyi Hu and Tianwei Zhang and Fei Wu and Guoyin Wang},
      year={2024},
      eprint={2308.10792},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.10792}, 
}

@misc{liu2024letslearnstepstep,
      title={Let's Learn Step by Step: Enhancing In-Context Learning Ability with Curriculum Learning}, 
      author={Yinpeng Liu and Jiawei Liu and Xiang Shi and Qikai Cheng and Yong Huang and Wei Lu},
      year={2024},
      eprint={2402.10738},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.10738}, 
}


%%%%%%%% 
@article{greenwade93,
    author  = "George D. Greenwade",
    title   = "The {C}omprehensive {T}ex {A}rchive {N}etwork ({CTAN})",
    year    = "1993",
    journal = "TUGBoat",
    volume  = "14",
    number  = "3",
    pages   = "342--351"
}

@inproceedings{gillmanself,
  title={Self-Correcting Self-Consuming Loops for Generative Model Training},
  author={Gillman, Nate and Freeman, Michael and Aggarwal, Daksh and Chia-Hong, HSU and Luo, Calvin and Tian, Yonglong and Sun, Chen},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@article{ulmer2024bootstrapping,
  title={Bootstrapping llm-based task-oriented dialogue agents via self-talk},
  author={Ulmer, Dennis and Mansimov, Elman and Lin, Kaixiang and Sun, Justin and Gao, Xibin and Zhang, Yi},
  journal={arXiv preprint arXiv:2401.05033},
  year={2024}
}


@article{Berend2012OnTC,
  title={On the Convergence of the Empirical Distribution},
  author={Daniel Berend and Aryeh Kontorovich},
  journal={ArXiv Preprint},
  year={2012},
}


@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B. and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{henighan2021scaling,
  title={Scaling laws for autoregressive generative modeling},
  author={Henighan, Tom and Kaplan, Jared and Katz, Mor and Chen, Mark and Hesse, Christopher and Jackson, Jacob and Jun, Heewoo and Brown, Tom B. and Dhariwal, Prafulla and Gray, Scott and others},
  journal={arXiv preprint arXiv:2103.05847},
  year={2021}
}

@article{hestness2017deep,
      title={Deep Learning Scaling is Predictable, Empirically}, 
      author={Joel Hestness and Sharan Narang and Newsha Ardalani and Gregory Diamos and Heewoo Jun and Hassan Kianinejad and Md. Mostofa Ali Patwary and Yang Yang and Yanqi Zhou},
      year={2017},
      journal={arXiv preprint ar{X}iv:1712.00409},
}

@inproceedings{gordon-etal-2021-data,
    title = "Data and Parameter Scaling Laws for Neural Machine Translation",
    author = "Gordon, Mitchell A  and
      Duh, Kevin  and
      Kaplan, Jared",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2021.emnlp-main.478",
    pages = "5915--5922",
}

@article{
wei2022emergent,
title={Emergent Abilities of Large Language Models},
author={Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2022},
note={Survey Certification}
}

@article{arora2023theory,
      title={A Theory for Emergence of Complex Skills in Language Models}, 
      author={Sanjeev Arora and Anirudh Goyal},
      year={2023},
      journal={arXiv preprint ar{X}iv:2307.15936},
}

@misc{hoffmann2022trainingChinchilla,
      title={Training Compute-Optimal Large Language Models}, 
      author={Jordan Hoffmann and Sebastian Borgeaud and Arthur Mensch and Elena Buchatskaya and Trevor Cai and Eliza Rutherford and Diego de Las Casas and Lisa Anne Hendricks and Johannes Welbl and Aidan Clark and Tom Hennigan and Eric Noland and Katie Millican and George van den Driessche and Bogdan Damoc and Aurelia Guy and Simon Osindero and Karen Simonyan and Erich Elsen and Jack W. Rae and Oriol Vinyals and Laurent Sifre},
      year={2022},
      journal={arXiv preprint ar{X}iv:2203.15556},
}

@article{hernandez2021scaling,
      title={Scaling Laws for Transfer}, 
      author={Danny Hernandez and Jared Kaplan and Tom Henighan and Sam McCandlish},
      year={2021},
      journal={arXiv preprint ar{X}iv:2102.01293},
}


@inproceedings{
rosenfeld2020a,
title={A Constructive Prediction of the Generalization Error Across Scales},
author={Jonathan S. Rosenfeld and Amir Rosenfeld and Yonatan Belinkov and Nir Shavit},
booktitle={International Conference on Learning Representations},
year={2020},
}

@article{shumailov2023curse,
  title={The Curse of Recursion: Training on Generated Data Makes Models Forget},
  author={Shumailov, Ilia and Shumaylov, Zakhar and Zhao, Yiren and Gal, Yarin and Papernot, Nicolas and Anderson, Ross},
  journal={arXiv preprint arxiv:2305.17493},
  year={2023}
}

@article{alemohammad2023selfconsuming,
      title={Self-Consuming Generative Models Go MAD}, 
      author={Sina Alemohammad and Josue Casco-Rodriguez and Lorenzo Luzi and Ahmed Imtiaz Humayun and Hossein Babaei and Daniel LeJeune and Ali Siahkoohi and Richard G. Baraniuk},
      year={2023},
      journal={arXiv preprint arxiv:2307.01850},
}

@inproceedings{
michaud2023the,
title={The Quantization Model of Neural Scaling},
author={Eric J Michaud and Ziming Liu and Uzay Girit and Max Tegmark},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
}

@article{bertrand2023stability,
      title={On the Stability of Iterative Retraining of Generative Models on their own Data}, 
      author={Quentin Bertrand and Avishek Joey Bose and Alexandre Duplessis and Marco Jiralerspong and Gauthier Gidel},
      year={2023},
      journal={arXiv preprint arxiv:2310.00429},
}

@article{martínez2023combining,
      title={Combining Generative Artificial Intelligence (AI) and the Internet: Heading towards Evolution or Degradation?}, 
      author={Gonzalo Martínez and Lauren Watson and Pedro Reviriego and José Alberto Hernández and Marc Juarez and Rik Sarkar},
      year={2023},
      journal={arXiv preprint arxiv: 2303.01255},
}

@article{martínez2023understanding,
      title={Towards Understanding the Interplay of Generative Artificial Intelligence and the Internet}, 
      author={Gonzalo Martínez and Lauren Watson and Pedro Reviriego and José Alberto Hernández and Marc Juarez and Rik Sarkar},
      year={2023},
      journal={arXiv preprint arxiv: 2306.06130},
}

@article{
azizi2023synthetic,
title={Synthetic Data from Diffusion Models Improves ImageNet Classification},
author={Shekoofeh Azizi and Simon Kornblith and Chitwan Saharia and Mohammad Norouzi and David J. Fleet},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2023},
note={}
}

@article{Cui_2022,
year = {2022},
month = {nov},
publisher = {IOP Publishing and SISSA},
volume = {2022},
number = {11},
pages = {114004},
author = {Hugo Cui and Bruno Loureiro and Florent Krzakala and Lenka Zdeborová},
title = {Generalization error rates in kernel regression: the crossover from the noiseless to noisy regime},
journal = {Journal of Statistical Mechanics: Theory and Experiment},
}

@inproceedings{bartlett2020neurips,
 author = {Mobahi, Hossein and Farajtabar, Mehrdad and Bartlett, Peter},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {3351--3361},
 publisher = {Curran Associates, Inc.},
 title = {Self-Distillation Amplifies Regularization in {H}ilbert Space},
 volume = {33},
 year = {2020}
}

@article{Caponnetto2007OptimalRF,
  title={Optimal Rates for the Regularized Least-Squares Algorithm},
  author={Andrea Caponnetto and Ernesto de Vito},
  journal={Foundations of Computational Mathematics},
  year={2007},
  volume={7},
  pages={331-368},
}

@inproceedings{
xu2023baize,
title={Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data},
author={Canwen Xu and Daya Guo and Nan Duan and Julian McAuley},
booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
year={2023},
}

@misc{dai2023auggpt,
      title={AugGPT: Leveraging ChatGPT for Text Data Augmentation}, 
      author={Haixing Dai and Zhengliang Liu and Wenxiong Liao and Xiaoke Huang and Yihan Cao and Zihao Wu and Lin Zhao and Shaochen Xu and Wei Liu and Ninghao Liu and Sheng Li and Dajiang Zhu and Hongmin Cai and Lichao Sun and Quanzheng Li and Dinggang Shen and Tianming Liu and Xiang Li},
      year={2023},
      eprint={2302.13007},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{shipard2023diversity,
      title={Diversity is Definitely Needed: Improving Model-Agnostic Zero-shot Classification via Stable Diffusion}, 
      author={Jordan Shipard and Arnold Wiliem and Kien Nguyen Thanh and Wei Xiang and Clinton Fookes},
      year={2023},
      eprint={2302.03298},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{
bansal2023leaving,
title={Leaving Reality to Imagination: Robust Classification via Generated Datasets},
author={Hritik Bansal and Aditya Grover},
booktitle={ICLR 2023 Workshop on Trustworthy and Reliable Large-Scale Machine Learning Models },
year={2023},
}

@INPROCEEDINGS{10208358,
  author={Lin, Shaobo and Wang, Kun and Zeng, Xingyu and Zhao, Rui},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={Explore the Power of Synthetic Data on Few-shot Object Detection}, 
  year={2023},
  volume={},
  number={},
  pages={638-647},
  doi={10.1109/CVPRW59228.2023.00071}}


@article{
burg2023image,
title={Image retrieval outperforms diffusion models on data augmentation},
author={Max F Burg and Florian Wenzel and Dominik Zietlow and Max Horn and Osama Makansi and Francesco Locatello and Chris Russell},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2023},
note={}
}

@InProceedings{Hataya_2023_ICCV,
    author    = {Hataya, Ryuichiro and Bao, Han and Arai, Hiromi},
    title     = {Will Large-scale Generative Models Corrupt Future Datasets?},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2023},
    pages     = {20555-20565}
}

@misc{bohacek2023nepotistically,
      title={Nepotistically Trained Generative-AI Models Collapse}, 
      author={Matyas Bohacek and Hany Farid},
      year={2023},
      eprint={2311.12202},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{briesch2023large,
      title={Large Language Models Suffer From Their Own Output: An Analysis of the Self-Consuming Training Loop}, 
      author={Martin Briesch and Dominik Sobania and Franz Rothlauf},
      year={2023},
      eprint={2311.16822},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{guo2023curious,
      title={The Curious Decline of Linguistic Diversity: Training Language Models on Synthetic Text}, 
      author={Yanzhu Guo and Guokan Shang and Michalis Vazirgiannis and Chloé Clavel},
      year={2023},
      eprint={2311.09807},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{cabannes2023scaling,
      title={Scaling Laws for Associative Memories}, 
      author={Vivien Cabannes and Elvis Dohmatob and Alberto Bietti},
      year={2023},
      eprint={2310.02984},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{maloney2022solvable,
      title={A Solvable Model of Neural Scaling Laws}, 
      author={Alexander Maloney and Daniel A. Roberts and James Sully},
      year={2022},
      eprint={2210.16859},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{debowski2023simplistic,
      title={A Simplistic Model of Neural Scaling Laws: Multiperiodic {S}anta {F}e Processes}, 
      author={Debowski, {L}ukasz},
      year={2023},
      eprint={2302.09049},
      archivePrefix={arXiv},
      primaryClass={cs.IT}
}

@misc{huang2022large,
      title={Large Language Models Can Self-Improve}, 
      author={Jiaxin Huang and Shixiang Shane Gu and Le Hou and Yuexin Wu and Xuezhi Wang and Hongkun Yu and Jiawei Han},
      year={2022},
      eprint={2210.11610},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{wang-etal-2023-self-instruct,
    title = "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
    author = "Wang, Yizhong  and
      Kordi, Yeganeh  and
      Mishra, Swaroop  and
      Liu, Alisa  and
      Smith, Noah A.  and
      Khashabi, Daniel  and
      Hajishirzi, Hannaneh",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2023.acl-long.754",
    pages = "13484--13508",
}

@article{
mckenzie2023inverse,
title={Inverse Scaling: When Bigger Isn't Better},
author={Ian R. McKenzie and Alexander Lyzhov and Michael Martin Pieler and Alicia Parrish and Aaron Mueller and Ameya Prabhu and Euan McLean and Xudong Shen and Joe Cavanagh and Andrew George Gritsevskiy and Derik Kauffman and Aaron T. Kirtland and Zhengping Zhou and Yuhui Zhang and Sicong Huang and Daniel Wurgaft and Max Weiss and Alexis Ross and Gabriel Recchia and Alisa Liu and Jiacheng Liu and Tom Tseng and Tomasz Korbak and Najoung Kim and Samuel R. Bowman and Ethan Perez},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2023},
}

@inproceedings{
chen2023skillit,
title={Skill-it! A data-driven skills framework for understanding and training language models},
author={Mayee F Chen and Nicholas Roberts and Kush Bhatia and Jue WANG and Ce Zhang and Frederic Sala and Christopher Re},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
}

@inproceedings{
cui2021generalization,
title={Generalization Error Rates in Kernel Regression: The Crossover from the Noiseless to Noisy Regime},
author={Hugo Cui and Bruno Loureiro and Florent Krzakala and Lenka Zdeborova},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
}

@article{Cui_2023,
   title={Error scaling laws for kernel classification under source and capacity conditions},
   volume={4},
   ISSN={2632-2153},
   DOI={10.1088/2632-2153/acf041},
   number={3},
   journal={Machine Learning: Science and Technology},
   publisher={IOP Publishing},
   author={Cui, Hugo and Loureiro, Bruno and Krzakala, Florent and Zdeborová, Lenka},
   year={2023},
   month=aug, pages={035033} }

@article{hutter2021learning,
  title={Learning curve theory},
  author={Hutter, Marcus},
  journal={arXiv preprint arXiv:2102.04074},
  year={2021}
}

@misc{aghajanyan2023scaling,
      title={Scaling Laws for Generative Mixed-Modal Language Models}, 
      author={Armen Aghajanyan and Lili Yu and Alexis Conneau and Wei-Ning Hsu and Karen Hambardzumyan and Susan Zhang and Stephen Roller and Naman Goyal and Omer Levy and Luke Zettlemoyer},
      year={2023},
      eprint={2301.03728},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{SchmidtHieber2017scaling,
author = {Schmidt-Hieber, Johannes},
year = {2017},
month = {08},
pages = {},
title = {Nonparametric regression using deep neural networks with ReLU activation function},
volume = {48},
journal = {Annals of Statistics},
doi = {10.1214/19-AOS1875}
}

@inproceedings{
suzuki2018adaptivity,
title={Adaptivity of deep Re{LU} network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality},
author={Taiji Suzuki},
booktitle={International Conference on Learning Representations},
year={2019},
}

@inproceedings{
nitanda2021optimal,
title={Optimal Rates for Averaged Stochastic Gradient Descent under Neural Tangent Kernel Regime},
author={Atsushi Nitanda and Taiji Suzuki},
booktitle={International Conference on Learning Representations},
year={2021},
}

@article{Spigler_2020,
   title={Asymptotic learning curves of kernel methods: empirical data versus teacher–student paradigm},
   volume={2020},
   ISSN={1742-5468},
   DOI={10.1088/1742-5468/abc61d},
   number={12},
   journal={Journal of Statistical Mechanics: Theory and Experiment},
   publisher={IOP Publishing},
   author={Spigler, Stefano and Geiger, Mario and Wyart, Matthieu},
   year={2020},
   month=dec, pages={124001} 
}

@inproceedings{BordelonCP20spectrum,
  author       = {Blake Bordelon and
                  Abdulkadir Canatar and
                  Cengiz Pehlevan},
  title        = {Spectrum Dependent Learning Curves in Kernel Regression and Wide Neural
                  Networks},
  booktitle    = {Proceedings of the 37th International Conference on Machine Learning,
                  {ICML} 2020, 13-18 July 2020, Virtual Event},
  series       = {Proceedings of Machine Learning Research},
  volume       = {119},
  pages        = {1024--1034},
  publisher    = {{PMLR}},
  year         = {2020},
}


@InProceedings{pmlr-v89-ali19earlystop,
  title = 	 {A Continuous-Time View of Early Stopping for Least Squares Regression},
  author =       {Ali, Alnur and Kolter, J. Zico and Tibshirani, Ryan J.},
  booktitle = 	 {Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics},
  pages = 	 {1370--1378},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Sugiyama, Masashi},
  volume = 	 {89},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {16--18 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v89/ali19a/ali19a.pdf},
}



@inproceedings{
charton2023transformers,
title={Learning the greatest common divisor: explaining transformer predictions},
author={Fran{\c{c}}ois Charton},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=cmcD05NPKa}
}


@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}


@inproceedings{NEURIPS2020_1457c0d6,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 volume = {33},
 year = {2020}
}

@inproceedings{burnsweak,
  title={Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision},
  author={Burns, Collin and Izmailov, Pavel and Kirchner, Jan Hendrik and Baker, Bowen and Gao, Leo and Aschenbrenner, Leopold and Chen, Yining and Ecoffet, Adrien and Joglekar, Manas and Leike, Jan and others},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@article{zhang2024regurgitative,
  title={Regurgitative Training: The Value of Real Data in Training Large Language Models},
  author={Zhang, Jinghui and Qiao, Dandan and Yang, Mochen and Wei, Qiang},
  journal={arXiv preprint arXiv:2407.12835},
  year={2024}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}


@InProceedings{pmlr-v139-ramesh21a,
  title = 	 {Zero-Shot Text-to-Image Generation},
  author =       {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {8821--8831},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
}

@InProceedings{Rombach_2022_CVPR,
    author    = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj\"orn},
    title     = {High-Resolution Image Synthesis With Latent Diffusion Models},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {10684-10695}
}

@misc{midjourney2023,
  author = {Midjourney},
  title = {Midjourney AI},
  year = {2023},
  url = {https://www.midjourney.com/},
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{kingmaauto,
  title={Auto-encoding variational Bayes},
  author={Kingma, Diederik P and Welling, Max},
  booktitle={International Conference on Learning Representations},
    year={2014},
}


@article{zipf1935psycho,
  title={The psycho-biology of language: an introduction to dynamic philology.},
  author={Zipf, GK},
  year={1935},
  publisher={Houghton Mifflin}
}

@article{papyan2020prevalence,
  title={Prevalence of neural collapse during the terminal phase of deep learning training},
  author={Papyan, Vardan and Han, XY and Donoho, David L},
  journal={Proceedings of the National Academy of Sciences},
  volume={117},
  number={40},
  pages={24652--24663},
  year={2020},
  publisher={National Acad Sciences}
}

@article{Strubell2019EnergyAP,
  title={Energy and Policy Considerations for Deep Learning in NLP},
  author={Emma Strubell and Ananya Ganesh and Andrew McCallum},
  journal={ArXiv},
  year={2019},
  volume={abs/1906.02243},
  url={https://api.semanticscholar.org/CorpusID:174802812}
}

@article{nadarajah2016,
     author = {Saralees Nadarajah and Tibor K. Pog\'any},
     title = {On the distribution of the product of correlated normal random variables},
     journal = {Comptes Rendus. Math\'ematique},
     publisher = {Elsevier},
     year = {2016},
}

@article{dohmatob2024tale_arXiv,
  title={A Tale of Tails: Model Collapse as a Change of Scaling Laws},
  author={Dohmatob, Elvis and Feng, Yunzhen and Yang, Pu and Charton, Francois and Kempe, Julia},
  journal={arXiv preprint arXiv:2402.07043},
  year={2024}
}

@inproceedings{
dohmatob2024tale,
title={A Tale of Tails: Model Collapse as a Change of Scaling Laws},
author={Elvis Dohmatob and Yunzhen Feng and Pu Yang and Fran{\c{c}}ois Charton and Julia Kempe},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=KVvku47shW}
}

@article{dohmatob2024model,
  title={Model Collapse Demystified: The Case of Regression},
  author={Dohmatob, Elvis and Feng, Yunzhen and Kempe, Julia},
  journal={arXiv preprint arXiv:2402.07712},
  year={2024}
}

@inproceedings{kirillov2023segment,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4015--4026},
  year={2023}
}

@inproceedings{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}

@inproceedings{wei2020theoretical,
  title={Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data},
  author={Wei, Colin and Shen, Kendrick and Chen, Yining and Ma, Tengyu},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{gulcehre2023reinforced,
  title={Reinforced self-training (rest) for language modeling},
  author={Gulcehre, Caglar and Paine, Tom Le and Srinivasan, Srivatsan and Konyushkova, Ksenia and Weerts, Lotte and Sharma, Abhishek and Siddhant, Aditya and Ahern, Alex and Wang, Miaosen and Gu, Chenjie and others},
  journal={arXiv preprint arXiv:2308.08998},
  year={2023}
}


@article{setlur2024rl,
  title={RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold},
  author={Setlur, Amrith and Garg, Saurabh and Geng, Xinyang and Garg, Naman and Smith, Virginia and Kumar, Aviral},
  journal={arXiv preprint arXiv:2406.14532},
  year={2024}
}

@article{sorscher2022beyond,
  title={Beyond neural scaling laws: beating power law scaling via data pruning},
  author={Sorscher, Ben and Geirhos, Robert and Shekhar, Shashank and Ganguli, Surya and Morcos, Ari},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={19523--19536},
  year={2022}
}

@article{power2022grokking,
  title={Grokking: Generalization beyond overfitting on small algorithmic datasets},
  author={Power, Alethea and Burda, Yuri and Edwards, Harri and Babuschkin, Igor and Misra, Vedant},
  journal={arXiv preprint arXiv:2201.02177},
  year={2022}
}

@article{garg2022can,
  title={What can transformers learn in-context? a case study of simple function classes},
  author={Garg, Shivam and Tsipras, Dimitris and Liang, Percy S and Valiant, Gregory},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={30583--30598},
  year={2022}
}

@book{BenDavidUnderstanding,
  author = {Shalev-Shwartz, Shai and Ben-David, Shai},
  publisher = {Cambridge University Press},
  title = {Understanding Machine Learning - From Theory to Algorithms.},
  year = 2014
}

@article{ayed2023data,
  title={Data pruning and neural scaling laws: fundamental limitations of score-based algorithms},
  author={Ayed, Fadhel and Hayou, Soufiane},
  journal={Transactions on Machine Learning Research},
  year={2023}
}

@inproceedings{hasan-etal-2021-xl,
    title = "{XL}-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages",
    author = "Hasan, Tahmid  and
      Bhattacharjee, Abhik  and
      Islam, Md. Saiful  and
      Mubasshir, Kazi  and
      Li, Yuan-Fang  and
      Kang, Yong-Bin  and
      Rahman, M. Sohel  and
      Shahriyar, Rifat",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.413",
    pages = "4693--4703",
}

@inproceedings{wang2023enable,
  title={Enable Lanuguage Models to Implicitly Learn Self-Improvement From Data},
  author={Wang, Ziqi and Hou, Le and Lu, Tianjian and Wu, Yuexin and Li, Yunxuan and Yu, Hongkun and Ji, Heng},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@misc{biroli2024dynamical,
      title={Dynamical Regimes of Diffusion Models}, 
      author={Giulio Biroli and Tony Bonnaire and Valentin de Bortoli and Marc Mézard},
      year={2024},
      eprint={2402.18491},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{
cui2024analysis,
title={Analysis of Learning a Flow-based Generative Model from Limited Sample Complexity},
author={Hugo Cui and Eric Vanden-Eijnden and Florent Krzakala and Lenka Zdeborova},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=ndCJeysCPe}
}

@inproceedings{
cui2023highdimensional,
title={High-dimensional Asymptotics of Denoising Autoencoders},
author={Hugo Cui and Lenka Zdeborova},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=wbbTqsiKzl}
}

@article{le2022coderl,
  title={Coderl: Mastering code generation through pretrained models and deep reinforcement learning},
  author={Le, Hung and Wang, Yue and Gotmare, Akhilesh Deepak and Savarese, Silvio and Hoi, Steven Chu Hong},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21314--21328},
  year={2022}
}

@inproceedings{haluptzok2022language,
  title={Language Models Can Teach Themselves to Program Better},
  author={Haluptzok, Patrick and Bowers, Matthew and Kalai, Adam Tauman},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@inproceedings{das2023understanding,
  title={Understanding self-distillation in the presence of label noise},
  author={Das, Rudrajit and Sanghavi, Sujay},
  booktitle={International Conference on Machine Learning},
  pages={7102--7140},
  year={2023},
  organization={PMLR}
}


@article{
charton2022linear,
title={Linear algebra with transformers},
author={Fran\c{c}ois Charton},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2022},
url={https://openreview.net/forum?id=Hp4g7FAXXG},
}

@inproceedings{transformer17,
  title = {Attention is all you need},
  author = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6000--6010},
  year = {2017}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@misc{Sora,
title = {Video generation models as world simulators},
author = {OpenAI},
howpublished = {\url{https://openai.com/index/video-generation-models-as-world-simulators/}},
year = {2024}
}

@misc{OpenSora,
title = {Video generation models as world simulators},
author = {OpenAI},
howpublished = {\url{https://openai.com/index/video-generation-models-as-world-simulators/}},
year = {2024}
}

@misc{daily_generate,
title = {openai now generates about 100 billion words per day. all people on earth generate about 100 trillion words per day.},
author = {Sam Altman},
howpublished = {\url{https://x.com/sama/status/1756089361609981993?lang=en}},
year = {2024}
}

@inproceedings{NIPS2017_3f5ee243,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 volume = {30},
 year = {2017}
}


@misc{llama3,
  title = {Introducing Meta Llama 3: The most capable openly available LLM to date},
  author= {Meta},
  howpublished = {\url{https://ai.meta.com/blog/meta-llama-3/}},
  year={2024}
}


@inproceedings{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}



@article{zheng2024opencodeinterpreter,
  title={OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement},
  author={Zheng, Tianyu and Zhang, Ge and Shen, Tianhao and Liu, Xueling and Lin, Bill Yuchen and Fu, Jie and Chen, Wenhu and Yue, Xiang},
  journal={arXiv preprint arXiv:2402.14658},
  year={2024}
}

@inproceedings{
um2024dont,
title={Don't Play Favorites: Minority Guidance for Diffusion Models},
author={Soobin Um and Suhyeon Lee and Jong Chul Ye},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=3NmO9lY4Jn}
}
@inproceedings{
he2023is,
title={{IS} {SYNTHETIC} {DATA} {FROM} {GENERATIVE} {MODELS} {READY} {FOR} {IMAGE} {RECOGNITION}?},
author={Ruifei He and Shuyang Sun and Xin Yu and Chuhui Xue and Wenqing Zhang and Philip Torr and Song Bai and XIAOJUAN QI},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=nUmCcZ5RKF}
}

@article{dunlap2024diversify,
  title={Diversify your vision datasets with automatic diffusion-based augmentation},
  author={Dunlap, Lisa and Umino, Alyssa and Zhang, Han and Yang, Jiezhi and Gonzalez, Joseph E and Darrell, Trevor},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@inproceedings{wang2023self,
  title={Self-Instruct: Aligning Language Models with Self-Generated Instructions},
  author={Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A and Khashabi, Daniel and Hajishirzi, Hannaneh},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={13484--13508},
  year={2023}
}

@article{eldan2023tinystories,
  title={Tinystories: How small can language models be and still speak coherent english?},
  author={Eldan, Ronen and Li, Yuanzhi},
  journal={arXiv preprint arXiv:2305.07759},
  year={2023}
}

@article{gunasekar2023textbooks,
  title={Textbooks are all you need},
  author={Gunasekar, Suriya and Zhang, Yi and Aneja, Jyoti and Mendes, Caio C{\'e}sar Teodoro and Del Giorno, Allie and Gopi, Sivakanth and Javaheripi, Mojan and Kauffmann, Piero and de Rosa, Gustavo and Saarikivi, Olli and others},
  journal={arXiv preprint arXiv:2306.11644},
  year={2023}
}

@article{yuan2024self,
  title={Self-rewarding language models},
  author={Yuan, Weizhe and Pang, Richard Yuanzhe and Cho, Kyunghyun and Sukhbaatar, Sainbayar and Xu, Jing and Weston, Jason},
  journal={arXiv preprint arXiv:2401.10020},
  year={2024}
}

@inproceedings{padmakumar2024writing,
        author={Vishakh Padmakumar and He He},
        title={Does Writing with Language Models Reduce Content Diversity?},
        booktitle={International Conference on Learning Representations (ICLR)},
        year={2024}
}

@article{seddik2024bad,
  title={How Bad is Training on Synthetic Data? A Statistical Analysis of Language Model Collapse},
  author={Seddik, Mohamed El Amine and Chen, Suei-Wen and Hayou, Soufiane and Youssef, Pierre and Debbah, Merouane},
  journal={arXiv preprint arXiv:2404.05090},
  year={2024}
}

@article{albalak2024survey,
  title={A Survey on Data Selection for Language Models},
  author={Albalak, Alon and Elazar, Yanai and Xie, Sang Michael and Longpre, Shayne and Lambert, Nathan and Wang, Xinyi and Muennighoff, Niklas and Hou, Bairu and Pan, Liangming and Jeong, Haewon and others},
  journal={arXiv preprint arXiv:2402.16827},
  year={2024}
}

@inproceedings{
kolossov2024towards,
title={Towards a statistical theory of data selection under weak supervision},
author={Germain Kolossov and Andrea Montanari and Pulkit Tandon},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=HhfcNgQn6p}
}

@article{liu2024best,
  title={Best Practices and Lessons Learned on Synthetic Data for Language Models},
  author={Liu, Ruibo and Wei, Jerry and Liu, Fangyu and Si, Chenglei and Zhang, Yanzhe and Rao, Jinmeng and Zheng, Steven and Peng, Daiyi and Yang, Diyi and Zhou, Denny and others},
  journal={arXiv preprint arXiv:2404.07503},
  year={2024}
}

@article{trinh2024solving,
  title={Solving olympiad geometry without human demonstrations},
  author={Trinh, Trieu H and Wu, Yuhuai and Le, Quoc V and He, He and Luong, Thang},
  journal={Nature},
  volume={625},
  number={7995},
  pages={476--482},
  year={2024},
  publisher={Nature Publishing Group}
}

@article{kakade2008complexity,
  title={On the complexity of linear prediction: Risk bounds, margin bounds, and regularization},
  author={Kakade, Sham M and Sridharan, Karthik and Tewari, Ambuj},
  journal={Advances in neural information processing systems},
  volume={21},
  year={2008}
}

@inproceedings{
zhang2024when,
title={When Scaling Meets {LLM} Finetuning: The Effect of Data, Model and Finetuning Method},
author={Biao Zhang and Zhongtao Liu and Colin Cherry and Orhan Firat},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=5HCnKDeTws}
}

@article{lee2023rlaif,
  title={Rlaif: Scaling reinforcement learning from human feedback with ai feedback},
  author={Lee, Harrison and Phatale, Samrat and Mansoor, Hassan and Lu, Kellie and Mesnard, Thomas and Bishop, Colton and Carbune, Victor and Rastogi, Abhinav},
  journal={arXiv preprint arXiv:2309.00267},
  year={2023}
}

@article{bai2022constitutional,
  title={Constitutional ai: Harmlessness from ai feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{hemmat2023feedback,
  title={Feedback-guided Data Synthesis for Imbalanced Classification},
  author={Hemmat, Reyhane Askari and Pezeshki, Mohammad and Bordes, Florian and Drozdzal, Michal and Romero-Soriano, Adriana},
  journal={arXiv preprint arXiv:2310.00158},
  year={2023}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@inproceedings{furlanello2018born,
  title={Born again neural networks},
  author={Furlanello, Tommaso and Lipton, Zachary and Tschannen, Michael and Itti, Laurent and Anandkumar, Anima},
  booktitle={International conference on machine learning},
  pages={1607--1616},
  year={2018},
  organization={PMLR}
}

@article{mobahi2020self,
  title={Self-distillation amplifies regularization in hilbert space},
  author={Mobahi, Hossein and Farajtabar, Mehrdad and Bartlett, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3351--3361},
  year={2020}
}

@article{dong2019distillation,
  title={Distillation $\sim$ Early Stopping? Harvesting Dark Knowledge Utilizing Anisotropic Information Retrieval For Overparameterized Neural Network},
  author={Dong, Bin and Hou, Jikai and Lu, Yiping and Zhang, Zhihua},
  journal={arXiv preprint arXiv:1910.01255},
  year={2019}
}

@inproceedings{olausson2023self,
  title={Is Self-Repair a Silver Bullet for Code Generation?},
  author={Olausson, Theo X and Inala, Jeevana Priya and Wang, Chenglong and Gao, Jianfeng and Solar-Lezama, Armando},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@inproceedings{allen2022towards,
  title={Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@article{peng2023instruction,
  title={Instruction tuning with gpt-4},
  author={Peng, Baolin and Li, Chunyuan and He, Pengcheng and Galley, Michel and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2304.03277},
  year={2023}
}

@inproceedings{
yang2024rlcd,
title={{RLCD}: Reinforcement Learning from Contrastive Distillation for {LM} Alignment},
author={Kevin Yang and Dan Klein and Asli Celikyilmaz and Nanyun Peng and Yuandong Tian},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=v3XXtxWKi6}
}

@inproceedings{lebrun2021evaluating,
  title={Evaluating Distributional Distortion in Neural Language Modeling},
  author={LeBrun, Benjamin and Sordoni, Alessandro and O'Donnell, Timothy J},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@InProceedings{mcAllester2003,
author="McAllester, David",
title="Simplified PAC-Bayesian Margin Bounds",
booktitle="Learning Theory and Kernel Machines",
year="2003",
publisher="Springer Berlin Heidelberg",
}

@article{Shumailov2024Nature,
    author = {Shumailov, Ilia and Shumaylov, Zakhar and Zhao, Yiren and Gal, Yarin and Papernot, Nicolas and Anderson, Ross},
    title = {AI models collapse when trained on recursively generated data},
    journal = {Nature},
    year = 2024,
    page = {755–759},
    volume = 631,
}

@misc{alemohammad2024selfimprovingdiffusionmodelssynthetic,
      title={Self-Improving Diffusion Models with Synthetic Data}, 
      author={Sina Alemohammad and Ahmed Imtiaz Humayun and Shruti Agarwal and John Collomosse and Richard Baraniuk},
      year={2024},
      eprint={2408.16333},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2408.16333}, 
}
%%%%%%



@misc{kim2024evaluatinglanguagemodelssynthetic,
      title={Evaluating Language Models as Synthetic Data Generators}, 
      author={Seungone Kim and Juyoung Suk and Xiang Yue and Vijay Viswanathan and Seongyun Lee and Yizhong Wang and Kiril Gashteovski and Carolin Lawrence and Sean Welleck and Graham Neubig},
      year={2024},
      eprint={2412.03679},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.03679}, 
}

@misc{chan2024balancingcosteffectivenesssynthetic,
      title={Balancing Cost and Effectiveness of Synthetic Data Generation Strategies for LLMs}, 
      author={Yung-Chieh Chan and George Pu and Apaar Shanker and Parth Suresh and Penn Jenks and John Heyer and Sam Denton},
      year={2024},
      eprint={2409.19759},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.19759}, 
}

@article{chen2024automatedcuration,
  title={Automated data curation for robust language model fine-tuning},
  author={Chen, Jiuhai and Mueller, Jonas},
  journal={arXiv preprint arXiv:2403.12776},
  year={2024}
}

@misc{setlur2024rlincorrectsyntheticdata,
      title={RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold}, 
      author={Amrith Setlur and Saurabh Garg and Xinyang Geng and Naman Garg and Virginia Smith and Aviral Kumar},
      year={2024},
      eprint={2406.14532},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.14532}, 
}


%%%%%%%%%%%%%%%% Personalization

@article{du2023mods,
  title={Mods: Model-oriented data selection for instruction tuning},
  author={Du, Qianlong and Zong, Chengqing and Zhang, Jiajun},
  journal={arXiv preprint arXiv:2311.15653},
  year={2023}
}



@inproceedings{
alemohammad2024selfconsuming,
title={Self-Consuming Generative Models Go {MAD}},
author={Sina Alemohammad and Josue Casco-Rodriguez and Lorenzo Luzi and Ahmed Imtiaz Humayun and Hossein Babaei and Daniel LeJeune and Ali Siahkoohi and Richard Baraniuk},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=ShjMHfmPs0}
}

@inproceedings{
gerstgrasser2024iscollapseinevitable,
title={Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data},
author={Matthias Gerstgrasser and Rylan Schaeffer and Apratim Dey and Rafael Rafailov and Tomasz Korbak and Henry Sleight and Rajashree Agrawal and John Hughes and Dhruv Bhandarkar Pai and Andrey Gromov and Dan Roberts and Diyi Yang and David L. Donoho and Sanmi Koyejo},
booktitle={First Conference on Language Modeling},
year={2024},
url={https://openreview.net/forum?id=5B2K4LRgmz}
}

@misc{dohmatob2024strongmodelcollapse,
      title={Strong Model Collapse}, 
      author={Elvis Dohmatob and Yunzhen Feng and Arjun Subramonian and Julia Kempe},
      year={2024},
      eprint={2410.04840},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.04840}, 
}

@inproceedings{li2024quantitytoqulality,
    title = "From Quantity to Quality: Boosting {LLM} Performance with Self-Guided Data Selection for Instruction Tuning",
    author = "Li, Ming  and
      Zhang, Yong  and
      Li, Zhitao  and
      Chen, Jiuhai  and
      Chen, Lichang  and
      Cheng, Ning  and
      Wang, Jianzong  and
      Zhou, Tianyi  and
      Xiao, Jing",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-long.421",
    doi = "10.18653/v1/2024.naacl-long.421",
    pages = "7602--7635",
}



% Curriculum learning
@misc{zhao2024preliminarystudyintrinsicrelationship,
      title={A Preliminary Study of the Intrinsic Relationship between Complexity and Alignment}, 
      author={Yingxiu Zhao and Bowen Yu and Binyuan Hui and Haiyang Yu and Fei Huang and Yongbin Li and Nevin L. Zhang},
      year={2024},
      eprint={2308.05696},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.05696}, 
}
@misc{lee2024instructiontuninghumancurriculum,
      title={Instruction Tuning with Human Curriculum}, 
      author={Bruce W. Lee and Hyunsoo Cho and Kang Min Yoo},
      year={2024},
      eprint={2310.09518},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.09518}, 
}

@inproceedings{huang2024easytohard,
    title = "{IT}2{ACL} Learning Easy-to-Hard Instructions via 2-Phase Automated Curriculum Learning for Large Language Models",
    author = "Huang, Yufei  and
      Xiong, Deyi",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.822",
    pages = "9405--9421",
}
@misc{feng2023citinglargelanguagemodels,
      title={CITING: Large Language Models Create Curriculum for Instruction Tuning}, 
      author={Tao Feng and Zifeng Wang and Jimeng Sun},
      year={2023},
      eprint={2310.02527},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.02527}, 
}
@inproceedings{
yu2024metamath,
title={MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models},
author={Longhui Yu and Weisen Jiang and Han Shi and Jincheng YU and Zhengying Liu and Yu Zhang and James Kwok and Zhenguo Li and Adrian Weller and Weiyang Liu},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=N8N0hgNDRt}
}

@inproceedings{li2024mugglemath,
    title = "{M}uggle{M}ath: Assessing the Impact of Query and Response Augmentation on Math Reasoning",
    author = "Li, Chengpeng  and
      Yuan, Zheng  and
      Yuan, Hongyi  and
      Dong, Guanting  and
      Lu, Keming  and
      Wu, Jiancan  and
      Tan, Chuanqi  and
      Wang, Xiang  and
      Zhou, Chang",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.551",
    doi = "10.18653/v1/2024.acl-long.551",
    pages = "10230--10258",
}

@misc{hendrycks2021measuringmathematicalproblemsolving,
      title={Measuring Mathematical Problem Solving With the MATH Dataset}, 
      author={Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt},
      year={2021},
      eprint={2103.03874},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2103.03874}, 
}
@misc{grattafiori2024llama3herdmodels,
      title={The Llama 3 Herd of Models}, 
      author={Aaron Grattafiori and Abhimanyu Dubey and Abhinav Jauhri and Abhinav Pandey and Abhishek Kadian and Ahmad Al-Dahle and Aiesha Letman and Akhil Mathur and Alan Schelten and Alex Vaughan and Amy Yang and Angela Fan and Anirudh Goyal and Anthony Hartshorn and Aobo Yang and Archi Mitra and Archie Sravankumar and Artem Korenev and Arthur Hinsvark and Arun Rao and Aston Zhang and Aurelien Rodriguez and Austen Gregerson and Ava Spataru and Baptiste Roziere and Bethany Biron and Binh Tang and Bobbie Chern and Charlotte Caucheteux and Chaya Nayak and Chloe Bi and Chris Marra and Chris McConnell and Christian Keller and Christophe Touret and Chunyang Wu and Corinne Wong and Cristian Canton Ferrer and Cyrus Nikolaidis and Damien Allonsius and Daniel Song and Danielle Pintz and Danny Livshits and Danny Wyatt and David Esiobu and Dhruv Choudhary and Dhruv Mahajan and Diego Garcia-Olano and Diego Perino and Dieuwke Hupkes and Egor Lakomkin and Ehab AlBadawy and Elina Lobanova and Emily Dinan and Eric Michael Smith and Filip Radenovic and Francisco Guzmán and Frank Zhang and Gabriel Synnaeve and Gabrielle Lee and Georgia Lewis Anderson and Govind Thattai and Graeme Nail and Gregoire Mialon and Guan Pang and Guillem Cucurell and Hailey Nguyen and Hannah Korevaar and Hu Xu and Hugo Touvron and Iliyan Zarov and Imanol Arrieta Ibarra and Isabel Kloumann and Ishan Misra and Ivan Evtimov and Jack Zhang and Jade Copet and Jaewon Lee and Jan Geffert and Jana Vranes and Jason Park and Jay Mahadeokar and Jeet Shah and Jelmer van der Linde and Jennifer Billock and Jenny Hong and Jenya Lee and Jeremy Fu and Jianfeng Chi and Jianyu Huang and Jiawen Liu and Jie Wang and Jiecao Yu and Joanna Bitton and Joe Spisak and Jongsoo Park and Joseph Rocca and Joshua Johnstun and Joshua Saxe and Junteng Jia and Kalyan Vasuden Alwala and Karthik Prasad and Kartikeya Upasani and Kate Plawiak and Ke Li and Kenneth Heafield and Kevin Stone and Khalid El-Arini and Krithika Iyer and Kshitiz Malik and Kuenley Chiu and Kunal Bhalla and Kushal Lakhotia and Lauren Rantala-Yeary and Laurens van der Maaten and Lawrence Chen and Liang Tan and Liz Jenkins and Louis Martin and Lovish Madaan and Lubo Malo and Lukas Blecher and Lukas Landzaat and Luke de Oliveira and Madeline Muzzi and Mahesh Pasupuleti and Mannat Singh and Manohar Paluri and Marcin Kardas and Maria Tsimpoukelli and Mathew Oldham and Mathieu Rita and Maya Pavlova and Melanie Kambadur and Mike Lewis and Min Si and Mitesh Kumar Singh and Mona Hassan and Naman Goyal and Narjes Torabi and Nikolay Bashlykov and Nikolay Bogoychev and Niladri Chatterji and Ning Zhang and Olivier Duchenne and Onur Çelebi and Patrick Alrassy and Pengchuan Zhang and Pengwei Li and Petar Vasic and Peter Weng and Prajjwal Bhargava and Pratik Dubal and Praveen Krishnan and Punit Singh Koura and Puxin Xu and Qing He and Qingxiao Dong and Ragavan Srinivasan and Raj Ganapathy and Ramon Calderer and Ricardo Silveira Cabral and Robert Stojnic and Roberta Raileanu and Rohan Maheswari and Rohit Girdhar and Rohit Patel and Romain Sauvestre and Ronnie Polidoro and Roshan Sumbaly and Ross Taylor and Ruan Silva and Rui Hou and Rui Wang and Saghar Hosseini and Sahana Chennabasappa and Sanjay Singh and Sean Bell and Seohyun Sonia Kim and Sergey Edunov and Shaoliang Nie and Sharan Narang and Sharath Raparthy and Sheng Shen and Shengye Wan and Shruti Bhosale and Shun Zhang and Simon Vandenhende and Soumya Batra and Spencer Whitman and Sten Sootla and Stephane Collot and Suchin Gururangan and Sydney Borodinsky and Tamar Herman and Tara Fowler and Tarek Sheasha and Thomas Georgiou and Thomas Scialom and Tobias Speckbacher and Todor Mihaylov and Tong Xiao and Ujjwal Karn and Vedanuj Goswami and Vibhor Gupta and Vignesh Ramanathan and Viktor Kerkez and Vincent Gonguet and Virginie Do and Vish Vogeti and Vítor Albiero and Vladan Petrovic and Weiwei Chu and Wenhan Xiong and Wenyin Fu and Whitney Meers and Xavier Martinet and Xiaodong Wang and Xiaofang Wang and Xiaoqing Ellen Tan and Xide Xia and Xinfeng Xie and Xuchao Jia and Xuewei Wang and Yaelle Goldschlag and Yashesh Gaur and Yasmine Babaei and Yi Wen and Yiwen Song and Yuchen Zhang and Yue Li and Yuning Mao and Zacharie Delpierre Coudert and Zheng Yan and Zhengxing Chen and Zoe Papakipos and Aaditya Singh and Aayushi Srivastava and Abha Jain and Adam Kelsey and Adam Shajnfeld and Adithya Gangidi and Adolfo Victoria and Ahuva Goldstand and Ajay Menon and Ajay Sharma and Alex Boesenberg and Alexei Baevski and Allie Feinstein and Amanda Kallet and Amit Sangani and Amos Teo and Anam Yunus and Andrei Lupu and Andres Alvarado and Andrew Caples and Andrew Gu and Andrew Ho and Andrew Poulton and Andrew Ryan and Ankit Ramchandani and Annie Dong and Annie Franco and Anuj Goyal and Aparajita Saraf and Arkabandhu Chowdhury and Ashley Gabriel and Ashwin Bharambe and Assaf Eisenman and Azadeh Yazdan and Beau James and Ben Maurer and Benjamin Leonhardi and Bernie Huang and Beth Loyd and Beto De Paola and Bhargavi Paranjape and Bing Liu and Bo Wu and Boyu Ni and Braden Hancock and Bram Wasti and Brandon Spence and Brani Stojkovic and Brian Gamido and Britt Montalvo and Carl Parker and Carly Burton and Catalina Mejia and Ce Liu and Changhan Wang and Changkyu Kim and Chao Zhou and Chester Hu and Ching-Hsiang Chu and Chris Cai and Chris Tindal and Christoph Feichtenhofer and Cynthia Gao and Damon Civin and Dana Beaty and Daniel Kreymer and Daniel Li and David Adkins and David Xu and Davide Testuggine and Delia David and Devi Parikh and Diana Liskovich and Didem Foss and Dingkang Wang and Duc Le and Dustin Holland and Edward Dowling and Eissa Jamil and Elaine Montgomery and Eleonora Presani and Emily Hahn and Emily Wood and Eric-Tuan Le and Erik Brinkman and Esteban Arcaute and Evan Dunbar and Evan Smothers and Fei Sun and Felix Kreuk and Feng Tian and Filippos Kokkinos and Firat Ozgenel and Francesco Caggioni and Frank Kanayet and Frank Seide and Gabriela Medina Florez and Gabriella Schwarz and Gada Badeer and Georgia Swee and Gil Halpern and Grant Herman and Grigory Sizov and Guangyi and Zhang and Guna Lakshminarayanan and Hakan Inan and Hamid Shojanazeri and Han Zou and Hannah Wang and Hanwen Zha and Haroun Habeeb and Harrison Rudolph and Helen Suk and Henry Aspegren and Hunter Goldman and Hongyuan Zhan and Ibrahim Damlaj and Igor Molybog and Igor Tufanov and Ilias Leontiadis and Irina-Elena Veliche and Itai Gat and Jake Weissman and James Geboski and James Kohli and Janice Lam and Japhet Asher and Jean-Baptiste Gaya and Jeff Marcus and Jeff Tang and Jennifer Chan and Jenny Zhen and Jeremy Reizenstein and Jeremy Teboul and Jessica Zhong and Jian Jin and Jingyi Yang and Joe Cummings and Jon Carvill and Jon Shepard and Jonathan McPhie and Jonathan Torres and Josh Ginsburg and Junjie Wang and Kai Wu and Kam Hou U and Karan Saxena and Kartikay Khandelwal and Katayoun Zand and Kathy Matosich and Kaushik Veeraraghavan and Kelly Michelena and Keqian Li and Kiran Jagadeesh and Kun Huang and Kunal Chawla and Kyle Huang and Lailin Chen and Lakshya Garg and Lavender A and Leandro Silva and Lee Bell and Lei Zhang and Liangpeng Guo and Licheng Yu and Liron Moshkovich and Luca Wehrstedt and Madian Khabsa and Manav Avalani and Manish Bhatt and Martynas Mankus and Matan Hasson and Matthew Lennie and Matthias Reso and Maxim Groshev and Maxim Naumov and Maya Lathi and Meghan Keneally and Miao Liu and Michael L. Seltzer and Michal Valko and Michelle Restrepo and Mihir Patel and Mik Vyatskov and Mikayel Samvelyan and Mike Clark and Mike Macey and Mike Wang and Miquel Jubert Hermoso and Mo Metanat and Mohammad Rastegari and Munish Bansal and Nandhini Santhanam and Natascha Parks and Natasha White and Navyata Bawa and Nayan Singhal and Nick Egebo and Nicolas Usunier and Nikhil Mehta and Nikolay Pavlovich Laptev and Ning Dong and Norman Cheng and Oleg Chernoguz and Olivia Hart and Omkar Salpekar and Ozlem Kalinli and Parkin Kent and Parth Parekh and Paul Saab and Pavan Balaji and Pedro Rittner and Philip Bontrager and Pierre Roux and Piotr Dollar and Polina Zvyagina and Prashant Ratanchandani and Pritish Yuvraj and Qian Liang and Rachad Alao and Rachel Rodriguez and Rafi Ayub and Raghotham Murthy and Raghu Nayani and Rahul Mitra and Rangaprabhu Parthasarathy and Raymond Li and Rebekkah Hogan and Robin Battey and Rocky Wang and Russ Howes and Ruty Rinott and Sachin Mehta and Sachin Siby and Sai Jayesh Bondu and Samyak Datta and Sara Chugh and Sara Hunt and Sargun Dhillon and Sasha Sidorov and Satadru Pan and Saurabh Mahajan and Saurabh Verma and Seiji Yamamoto and Sharadh Ramaswamy and Shaun Lindsay and Shaun Lindsay and Sheng Feng and Shenghao Lin and Shengxin Cindy Zha and Shishir Patil and Shiva Shankar and Shuqiang Zhang and Shuqiang Zhang and Sinong Wang and Sneha Agarwal and Soji Sajuyigbe and Soumith Chintala and Stephanie Max and Stephen Chen and Steve Kehoe and Steve Satterfield and Sudarshan Govindaprasad and Sumit Gupta and Summer Deng and Sungmin Cho and Sunny Virk and Suraj Subramanian and Sy Choudhury and Sydney Goldman and Tal Remez and Tamar Glaser and Tamara Best and Thilo Koehler and Thomas Robinson and Tianhe Li and Tianjun Zhang and Tim Matthews and Timothy Chou and Tzook Shaked and Varun Vontimitta and Victoria Ajayi and Victoria Montanez and Vijai Mohan and Vinay Satish Kumar and Vishal Mangla and Vlad Ionescu and Vlad Poenaru and Vlad Tiberiu Mihailescu and Vladimir Ivanov and Wei Li and Wenchen Wang and Wenwen Jiang and Wes Bouaziz and Will Constable and Xiaocheng Tang and Xiaojian Wu and Xiaolan Wang and Xilun Wu and Xinbo Gao and Yaniv Kleinman and Yanjun Chen and Ye Hu and Ye Jia and Ye Qi and Yenda Li and Yilin Zhang and Ying Zhang and Yossi Adi and Youngjin Nam and Yu and Wang and Yu Zhao and Yuchen Hao and Yundi Qian and Yunlu Li and Yuzi He and Zach Rait and Zachary DeVito and Zef Rosnbrick and Zhaoduo Wen and Zhenyu Yang and Zhiwei Zhao and Zhiyu Ma},
      year={2024},
      eprint={2407.21783},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.21783}, 
}

@misc{jiang2023mistral7b,
      title={Mistral 7B}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2023},
      eprint={2310.06825},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.06825}, 
}

@misc{jiang2024mixtralexperts,
      title={Mixtral of Experts}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Antoine Roux and Arthur Mensch and Blanche Savary and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Emma Bou Hanna and Florian Bressand and Gianna Lengyel and Guillaume Bour and Guillaume Lample and Lélio Renard Lavaud and Lucile Saulnier and Marie-Anne Lachaux and Pierre Stock and Sandeep Subramanian and Sophia Yang and Szymon Antoniak and Teven Le Scao and Théophile Gervet and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2024},
      eprint={2401.04088},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2401.04088}, 
}
@misc{mistralai2024mistralsmallinstruct,
  author       = {MistralAI},
  title        = {Mistral-Small-Instruct-2409},
  year         = {2024},
  publisher    = {Hugging Face},
  howpublished = {\url{https://huggingface.co/mistralai/Mistral-Small-Instruct-2409}},
  note         = {Accessed: 2024-12-13}
}
@misc{mistralai2024codestral22b,
  author       = {MistralAI},
  title        = {Codestral-22B-v0.1},
  year         = {2024},
  publisher    = {Hugging Face},
  howpublished = {\url{https://huggingface.co/mistralai/Codestral-22B-v0.1}},
  note         = {Accessed: 2024-12-13}
}


@inproceedings{
wei2022chainofthought,
title={Chain of Thought Prompting Elicits Reasoning in Large Language Models},
author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and brian ichter and Fei Xia and Ed H. Chi and Quoc V Le and Denny Zhou},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=_VjQlMeSB_J}
}

@misc{luo2024improvemathematicalreasoninglanguage,
      title={Improve Mathematical Reasoning in Language Models by Automated Process Supervision}, 
      author={Liangchen Luo and Yinxiao Liu and Rosanne Liu and Samrat Phatale and Meiqi Guo and Harsh Lara and Yunxuan Li and Lei Shu and Yun Zhu and Lei Meng and Jiao Sun and Abhinav Rastogi},
      year={2024},
      eprint={2406.06592},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.06592}, 
}


@inproceedings{li2023making,
    title = "Making Language Models Better Reasoners with Step-Aware Verifier",
    author = "Li, Yifei  and
      Lin, Zeqi  and
      Zhang, Shizhuo  and
      Fu, Qiang  and
      Chen, Bei  and
      Lou, Jian-Guang  and
      Chen, Weizhu",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.291",
    doi = "10.18653/v1/2023.acl-long.291",
    pages = "5315--5333",
}
@misc{lightman2023letsverifystepstep,
      title={Let's Verify Step by Step}, 
      author={Hunter Lightman and Vineet Kosaraju and Yura Burda and Harri Edwards and Bowen Baker and Teddy Lee and Jan Leike and John Schulman and Ilya Sutskever and Karl Cobbe},
      year={2023},
      eprint={2305.20050},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.20050}, 
}
@article{jensen1906,
  author = {Jensen, Johan Ludwig William Valdemar},
  title = {Sur les fonctions convexes et les inégalités entre les valeurs moyennes},
  journal = {Acta Mathematica},
  volume = {30},
  pages = {175--193},
  year = {1906},
  doi = {10.1007/BF02418571}
}


@misc{slimorca,
  title = {SlimOrca: An Open Dataset of GPT-4 Augmented FLAN Reasoning Traces, with Verification},
  author = {Wing Lian and Guan Wang and Bleys Goodson and Eugene Pentland and Austin Cook and Chanvichet Vong and "Teknium"},
  year = {2023},
  publisher = {HuggingFace},
  url = {https://https://huggingface.co/Open-Orca/SlimOrca}
}

@misc{chen2024optuneefficientonlinepreference,
      title={OPTune: Efficient Online Preference Tuning}, 
      author={Lichang Chen and Jiuhai Chen and Chenxi Liu and John Kirchenbauer and Davit Soselia and Chen Zhu and Tom Goldstein and Tianyi Zhou and Heng Huang},
      year={2024},
      eprint={2406.07657},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.07657}, 
}
@misc{agarwal2024onpolicydistillationlanguagemodels,
      title={On-Policy Distillation of Language Models: Learning from Self-Generated Mistakes}, 
      author={Rishabh Agarwal and Nino Vieillard and Yongchao Zhou and Piotr Stanczyk and Sabela Ramos and Matthieu Geist and Olivier Bachem},
      year={2024},
      eprint={2306.13649},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2306.13649}, 
}


@misc{
lee2024rlaif,
title={{RLAIF}: Scaling Reinforcement Learning from Human Feedback with {AI} Feedback},
author={Harrison Lee and Samrat Phatale and Hassan Mansoor and Kellie Ren Lu and Thomas Mesnard and Johan Ferret and Colton Bishop and Ethan Hall and Victor Carbune and Abhinav Rastogi},
year={2024},
url={https://openreview.net/forum?id=AAxIs3D2ZZ}
}

@inproceedings{xu2024dposuperiorppollm,
  author={Shusheng Xu and Wei Fu and Jiaxuan Gao and Wenjie Ye and Weilin Liu and Zhiyu Mei and Guangju Wang and Chao Yu and Yi Wu},
  title={Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study},
  year={2024},
  cdate={1704067200000},
  url={https://openreview.net/forum?id=6XH8R7YrSk},
  booktitle={ICML},
}
@misc{zhang2024selfexploringlanguagemodelsactive,
      title={Self-Exploring Language Models: Active Preference Elicitation for Online Alignment}, 
      author={Shenao Zhang and Donghan Yu and Hiteshi Sharma and Han Zhong and Zhihan Liu and Ziyi Yang and Shuohang Wang and Hany Hassan and Zhaoran Wang},
      year={2024},
      eprint={2405.19332},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.19332}, 
}

@misc{miao2024aligningcodellmsdirectpreference,
      title={Aligning CodeLLMs with Direct Preference Optimization}, 
      author={Yibo Miao and Bofei Gao and Shanghaoran Quan and Junyang Lin and Daoguang Zan and Jiaheng Liu and Jian Yang and Tianyu Liu and Zhijie Deng},
      year={2024},
      eprint={2410.18585},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2410.18585}, 
}

@misc{zhang2024textbfplumimprovingcodelms,
      title={$\textbf{PLUM}$: Improving Code LMs with Execution-Guided On-Policy Preference Learning Driven By Synthetic Test Cases}, 
      author={Dylan Zhang and Shizhe Diao and Xueyan Zou and Hao Peng},
      year={2024},
      eprint={2406.06887},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.06887}, 
}

@misc{xu2023rethinkinginstructionqualitylift,
      title={Rethinking the Instruction Quality: LIFT is What You Need}, 
      author={Yang Xu and Yongqiang Yao and Yufan Huang and Mengnan Qi and Maoquan Wang and Bin Gu and Neel Sundaresan},
      year={2023},
      eprint={2312.11508},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.11508}, 
}

@inproceedings{xia2024less,
   title={{LESS}: Selecting Influential Data for Targeted Instruction Tuning},
   author={Xia, Mengzhou and Malladi, Sadhika and Gururangan, Suchin and Arora, Sanjeev and Chen, Danqi},
   booktitle={International Conference on Machine Learning (ICML)},
   year={2024}}


@inproceedings{
xu2024wizardlm,
title={Wizard{LM}: Empowering Large Pre-Trained Language Models to Follow Complex Instructions},
author={Can Xu and Qingfeng Sun and Kai Zheng and Xiubo Geng and Pu Zhao and Jiazhan Feng and Chongyang Tao and Qingwei Lin and Daxin Jiang},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=CfXh93NDgH}
}

@article{zeng2024automatic,
  title={Automatic Instruction Evolving for Large Language Models},
  author={Zeng, Weihao and Xu, Can and Zhao, Yingxiu and Lou, Jian-Guang and Chen, Weizhu},
  journal={arXiv preprint arXiv:2406.00770},
  year={2024}
}

@article{chen2023alpagasus,
  title={Alpagasus: Training a better alpaca with fewer data},
  author={Chen, Lichang and Li, Shiyang and Yan, Jun and Wang, Hai and Gunaratna, Kalpa and Yadav, Vikas and Tang, Zheng and Srinivasan, Vijay and Zhou, Tianyi and Huang, Heng and others},
  journal={arXiv preprint arXiv:2307.08701},
  year={2023}
}

@article{parkar2024selectllm,
  title={SelectLLM: Can LLMs Select Important Instructions to Annotate?},
  author={Parkar, Ritik Sachin and Kim, Jaehyung and Park, Jong Inn and Kang, Dongyeop},
  journal={arXiv preprint arXiv:2401.16553},
  year={2024}
}

@misc{li2024scar,
      title={SCAR: Efficient Instruction-Tuning for Large Language Models via Style Consistency-Aware Response Ranking}, 
      author={Zhuang Li and Yuncheng Hua and Thuy-Trang Vu and Haolan Zhan and Lizhen Qu and Gholamreza Haffari},
      year={2024},
      eprint={2406.10882},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.10882}, 
}

@misc{gulcehre2023rest,
      title={Reinforced Self-Training (ReST) for Language Modeling}, 
      author={Caglar Gulcehre and Tom Le Paine and Srivatsan Srinivasan and Ksenia Konyushkova and Lotte Weerts and Abhishek Sharma and Aditya Siddhant and Alex Ahern and Miaosen Wang and Chenjie Gu and Wolfgang Macherey and Arnaud Doucet and Orhan Firat and Nando de Freitas},
      year={2023},
      eprint={2308.08998},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.08998}, 
}
@article{kang2024getmoreforless,
  title={Get more for less: Principled Data Selection for Warming Up Fine-Tuning in LLMs},
  author={Kang, Feiyang and Just, Hoang Anh and Sun, Yifan and Jahagirdar, Himanshu and Zhang, Yuanzhi and Du, Rongxing and Sahu, Anit Kumar and Jia, Ruoxi},
  journal={arXiv preprint arXiv:2405.02774},
  year={2024}
}
@article{mekala2024smaller,
  title={Smaller language models are capable of selecting instruction-tuning training data for larger language models},
  author={Mekala, Dheeraj and Nguyen, Alex and Shang, Jingbo},
  journal={arXiv preprint arXiv:2402.10430},
  year={2024}
}

@article{yang2024smalltolarge,
  title={SmallToLarge (S2L): Scalable Data Selection for Fine-tuning Large Language Models by Summarizing Training Trajectories of Small Models},
  author={Yang, Yu and Mishra, Siddhartha and Chiang, Jeffrey N and Mirzasoleiman, Baharan},
  journal={arXiv preprint arXiv:2403.07384},
  year={2024}
}

@article{das2023deft,
  title={DEFT: Data Efficient Fine-Tuning for Large Language Models via Unsupervised Core-Set Selection},
  author={Das, Devleena and Khetan, Vivek},
  journal={arXiv preprint arXiv:2310.16776},
  year={2023}
}

@inproceedings{li2024selective,
    title = "Selective Reflection-Tuning: Student-Selected Data Recycling for {LLM} Instruction-Tuning",
    author = "Li, Ming  and
      Chen, Lichang  and
      Chen, Jiuhai  and
      He, Shwai  and
      Gu, Jiuxiang  and
      Zhou, Tianyi",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.958",
    doi = "10.18653/v1/2024.findings-acl.958",
    pages = "16189--16211"
}
@misc{du2023modsmodelorienteddataselection,
      title={MoDS: Model-oriented Data Selection for Instruction Tuning}, 
      author={Qianlong Du and Chengqing Zong and Jiajun Zhang},
      year={2023},
      eprint={2311.15653},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.15653}, 
}

@misc{OpenHermes,
  title = {OpenHermes 2.5: An Open Dataset of Synthetic Data for Generalist LLM Assistants},
  author = {Teknium},
  year = {2023},
  publisher = {HuggingFace},
  url = {https://huggingface.co/datasets/teknium/OpenHermes-2.5}
}

@misc{li2024gsmplus,
      title={GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers}, 
      author={Qintong Li and Leyang Cui and Xueliang Zhao and Lingpeng Kong and Wei Bi},
      year={2024},
      eprint={2402.19255},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.19255}, 
}

@misc{chen2023theoremqatheoremdrivenquestionanswering,
      title={TheoremQA: A Theorem-driven Question Answering dataset}, 
      author={Wenhu Chen and Ming Yin and Max Ku and Pan Lu and Yixin Wan and Xueguang Ma and Jianyu Xu and Xinyi Wang and Tony Xia},
      year={2023},
      eprint={2305.12524},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.12524}, 
}
@misc{cobbe2021trainingverifierssolvemath,
      title={Training Verifiers to Solve Math Word Problems}, 
      author={Karl Cobbe and Vineet Kosaraju and Mohammad Bavarian and Mark Chen and Heewoo Jun and Lukasz Kaiser and Matthias Plappert and Jerry Tworek and Jacob Hilton and Reiichiro Nakano and Christopher Hesse and John Schulman},
      year={2021},
      eprint={2110.14168},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2110.14168}, 
}

@misc{lambert2024tulu3,
      title={Tulu 3: Pushing Frontiers in Open Language Model Post-Training}, 
      author={Nathan Lambert and Jacob Morrison and Valentina Pyatkin and Shengyi Huang and Hamish Ivison and Faeze Brahman and Lester James V. Miranda and Alisa Liu and Nouha Dziri and Shane Lyu and Yuling Gu and Saumya Malik and Victoria Graf and Jena D. Hwang and Jiangjiang Yang and Ronan Le Bras and Oyvind Tafjord and Chris Wilhelm and Luca Soldaini and Noah A. Smith and Yizhong Wang and Pradeep Dasigi and Hannaneh Hajishirzi},
      year={2024},
      eprint={2411.15124},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.15124}, 
}
@misc{olmo2025,
      title={2 OLMo 2 Furious}, 
      author={Team OLMo and Pete Walsh and Luca Soldaini and Dirk Groeneveld and Kyle Lo and Shane Arora and Akshita Bhagia and Yuling Gu and Shengyi Huang and Matt Jordan and Nathan Lambert and Dustin Schwenk and Oyvind Tafjord and Taira Anderson and David Atkinson and Faeze Brahman and Christopher Clark and Pradeep Dasigi and Nouha Dziri and Michal Guerquin and Hamish Ivison and Pang Wei Koh and Jiacheng Liu and Saumya Malik and William Merrill and Lester James V. Miranda and Jacob Morrison and Tyler Murray and Crystal Nam and Valentina Pyatkin and Aman Rangapur and Michael Schmitz and Sam Skjonsberg and David Wadden and Christopher Wilhelm and Michael Wilson and Luke Zettlemoyer and Ali Farhadi and Noah A. Smith and Hannaneh Hajishirzi},
      year={2025},
      eprint={2501.00656},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.00656}, 
}

@misc{open_hermes_preferences,
  author = {Shengyi Costa Huang and Agustín Piqueres and Kashif Rasul and Philipp Schmid and Daniel Vila and Lewis Tunstall},
  title = {Open Hermes Preferences},
  year = {2024},
  publisher = {Argilla & Hugging Face},
  journal = {Hugging Face repository},
  howpublished = {\url{https://huggingface.co/datasets/argilla/OpenHermesPreferences}}
}

@misc{huggingface2024openhermes,
  author       = {HuggingFace-H4},
  title        = {OpenHermes-2.5-preferences-v0-deduped},
  year         = {2024},
  publisher    = {Hugging Face Datasets},
  url          = {https://huggingface.co/datasets/HuggingFaceH4/OpenHermes-2.5-preferences-v0-deduped}
}

@misc{xu2024strongermodelsstrongerteachers,
      title={Stronger Models are NOT Stronger Teachers for Instruction Tuning}, 
      author={Zhangchen Xu and Fengqing Jiang and Luyao Niu and Bill Yuchen Lin and Radha Poovendran},
      year={2024},
      eprint={2411.07133},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2411.07133}, 
}


@article{sun2024principle,
  title={Principle-driven self-alignment of language models from scratch with minimal human supervision},
  author={Sun, Zhiqing and Shen, Yikang and Zhou, Qinhong and Zhang, Hongxin and Chen, Zhenfang and Cox, David and Yang, Yiming and Gan, Chuang},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}



@article{chen2024genqa,
  title={GenQA: Generating Millions of Instructions from a Handful of Prompts},
  author={Chen, Jiuhai and Qadri, Rifaa and Wen, Yuxin and Jain, Neel and Kirchenbauer, John and Zhou, Tianyi and Goldstein, Tom},
  journal={arXiv preprint arXiv:2406.10323},
  year={2024}
}

@article{xu2024magpie,
  title={Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing},
  author={Xu, Zhangchen and Jiang, Fengqing and Niu, Luyao and Deng, Yuntian and Poovendran, Radha and Choi, Yejin and Lin, Bill Yuchen},
  journal={arXiv preprint arXiv:2406.08464},
  year={2024}
}



% On-policy vs off-policy RL
@inproceedings{
zhuang2023bpo,
title={Behavior Proximal Policy Optimization },
author={Zifeng Zhuang and Kun LEI and Jinxin Liu and Donglin Wang and Yilang Guo},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=3c13LptpIph}
}

@article{agarwal2021theory,
  title={On the theory of policy gradient methods: Optimality, approximation, and distribution shift},
  author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={98},
  pages={1--76},
  year={2021}
}

@misc{jiang2016doublyrobustoffpolicyvalue,
      title={Doubly Robust Off-policy Value Evaluation for Reinforcement Learning}, 
      author={Nan Jiang and Lihong Li},
      year={2016},
      eprint={1511.03722},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1511.03722}, 
}
@misc{shi2023offlinereinforcementlearningonpolicy,
      title={Offline Reinforcement Learning with On-Policy Q-Function Regularization}, 
      author={Laixi Shi and Robert Dadashi and Yuejie Chi and Pablo Samuel Castro and Matthieu Geist},
      year={2023},
      eprint={2307.13824},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2307.13824}, 
}
@inproceedings{fujimoto2018offpolicy,
  title={Off-Policy Deep Reinforcement Learning without Exploration},
  author={Scott Fujimoto and David Meger and Doina Precup},
  booktitle={International Conference on Machine Learning},
  year={2018},
  url={https://api.semanticscholar.org/CorpusID:54457299}
}

@inproceedings{kumar2019offpolicy,
 author = {Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
 url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/c2073ffa77b5357a498057413bb09d3a-Paper.pdf},
 volume = {32},
 year = {2019}
}

@misc{peng2019offpolicy,
      title={Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning}, 
      author={Xue Bin Peng and Aviral Kumar and Grace Zhang and Sergey Levine},
      year={2019},
      eprint={1910.00177},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1910.00177}, 
}
@misc{wang2021criticregularizedregression,
      title={Critic Regularized Regression}, 
      author={Ziyu Wang and Alexander Novikov and Konrad Zolna and Jost Tobias Springenberg and Scott Reed and Bobak Shahriari and Noah Siegel and Josh Merel and Caglar Gulcehre and Nicolas Heess and Nando de Freitas},
      year={2021},
      eprint={2006.15134},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2006.15134}, 
}
% preference learning
@misc{zhou2024wpoenhancingrlhfweighted,
      title={WPO: Enhancing RLHF with Weighted Preference Optimization}, 
      author={Wenxuan Zhou and Ravi Agrawal and Shujian Zhang and Sathish Reddy Indurthi and Sanqiang Zhao and Kaiqiang Song and Silei Xu and Chenguang Zhu},
      year={2024},
      eprint={2406.11827},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.11827}, 
}


@inproceedings{tang2010importancesampling,
author = {Tang, Jie and Abbeel, Pieter},
year = {2010},
month = {01},
pages = {1000-1008},
title = {On a Connection between Importance Sampling and the Likelihood Ratio Policy Gradient.}
}

@misc{gu2017qpropsampleefficientpolicygradient,
      title={Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic}, 
      author={Shixiang Gu and Timothy Lillicrap and Zoubin Ghahramani and Richard E. Turner and Sergey Levine},
      year={2017},
      eprint={1611.02247},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1611.02247}, 
}

@misc{gu2017interpolatedpolicygradientmerging,
      title={Interpolated Policy Gradient: Merging On-Policy and Off-Policy Gradient Estimation for Deep Reinforcement Learning}, 
      author={Shixiang Gu and Timothy Lillicrap and Zoubin Ghahramani and Richard E. Turner and Bernhard Schölkopf and Sergey Levine},
      year={2017},
      eprint={1706.00387},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1706.00387}, 
}
@misc{azar2023generaltheoreticalparadigmunderstand,
      title={A General Theoretical Paradigm to Understand Learning from Human Preferences}, 
      author={Mohammad Gheshlaghi Azar and Mark Rowland and Bilal Piot and Daniel Guo and Daniele Calandriello and Michal Valko and Rémi Munos},
      year={2023},
      eprint={2310.12036},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2310.12036}, 
}

@inproceedings{xu2024dposuperiorppo,
  author={Shusheng Xu and Wei Fu and Jiaxuan Gao and Wenjie Ye and Weilin Liu and Zhiyu Mei and Guangju Wang and Chao Yu and Yi Wu},
  title={Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study},
  year={2024},
  cdate={1704067200000},
  url={https://openreview.net/forum?id=6XH8R7YrSk},
  booktitle={ICML},
  crossref={conf/icml/2024}
}

@article{tang2024understandingperformancegap,
  title={Understanding the performance gap between online and offline alignment algorithms},
  author={Tang, Yunhao and Guo, Daniel Zhaohan and Zheng, Zeyu and Calandriello, Daniele and Cao, Yuan and Tarassov, Eugene and Munos, R{\'e}mi and Pires, Bernardo {\'A}vila and Valko, Michal and Cheng, Yong and others},
  journal={arXiv preprint arXiv:2405.08448},
  year={2024}
}

% sft
@book{information_geometry_applications,
  title     = {Information Geometry and Its Applications},
  author    = {Shun-ichi Amari},
  year      = {2016},
  publisher = {Springer},
  address   = {Tokyo, Japan},
  edition   = {1st},
  series    = {Applied Mathematical Sciences},
  volume    = {194},
  isbn      = {978-4-431-55977-3},
  doi       = {10.1007/978-4-431-55978-0},
  url       = {https://doi.org/10.1007/978-4-431-55978-0}
}

@book{cover_thomas_information_theory,
  title     = {Elements of Information Theory},
  author    = {Thomas M. Cover and Joy A. Thomas},
  year      = {2006},
  edition   = {2nd},
  publisher = {Wiley-Interscience},
  address   = {Hoboken, NJ, USA},
  isbn      = {978-0-471-24195-9},
  url       = {https://onlinelibrary.wiley.com/doi/book/10.1002/047174882X}
}

@misc{feldman2021doeslearningrequirememorization,
      title={Does Learning Require Memorization? A Short Tale about a Long Tail}, 
      author={Vitaly Feldman},
      year={2021},
      eprint={1906.05271},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1906.05271}, 
}
@misc{aghajanyan2020betterfinetuningreducingrepresentational,
      title={Better Fine-Tuning by Reducing Representational Collapse}, 
      author={Armen Aghajanyan and Akshat Shrivastava and Anchit Gupta and Naman Goyal and Luke Zettlemoyer and Sonal Gupta},
      year={2020},
      eprint={2008.03156},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2008.03156}, 
}

@misc{yang2024selfdistillationbridgesdistributiongap,
      title={Self-Distillation Bridges Distribution Gap in Language Model Fine-Tuning}, 
      author={Zhaorui Yang and Tianyu Pang and Haozhe Feng and Han Wang and Wei Chen and Minfeng Zhu and Qian Liu},
      year={2024},
      eprint={2402.13669},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.13669}, 
}

@misc{kumar2022finetuningdistortpretrainedfeatures,
      title={Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution}, 
      author={Ananya Kumar and Aditi Raghunathan and Robbie Jones and Tengyu Ma and Percy Liang},
      year={2022},
      eprint={2202.10054},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2202.10054}, 
}


@misc{cohenwang2024askdistributionshiftpretraining,
      title={Ask Your Distribution Shift if Pre-Training is Right for You}, 
      author={Benjamin Cohen-Wang and Joshua Vendrow and Aleksander Madry},
      year={2024},
      eprint={2403.00194},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2403.00194}, 
}

@inproceedings{
he2023preservingpretrained,
title={Preserving Pre-trained Features Helps Calibrate Fine-tuned Language Models},
author={Guande He and Jianfei Chen and Jun Zhu},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=NI7StoWHJPT}
}
@misc{zheng2023preservingcommonsenseknowledgepretrained,
      title={Preserving Commonsense Knowledge from Pre-trained Language Models via Causal Inference}, 
      author={Junhao Zheng and Qianli Ma and Shengjie Qiu and Yue Wu and Peitian Ma and Junlong Liu and Huawen Feng and Xichen Shang and Haibin Chen},
      year={2023},
      eprint={2306.10790},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.10790}, 
}
@misc{mukhoti2024finetuningcripplefoundationmodel,
      title={Fine-tuning can cripple your foundation model; preserving features may be the solution}, 
      author={Jishnu Mukhoti and Yarin Gal and Philip H. S. Torr and Puneet K. Dokania},
      year={2024},
      eprint={2308.13320},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2308.13320}, 
}
@article{ding2023peft,
  title={Parameter-efficient fine-tuning of large-scale pre-trained language models},
  author={Ding, Ning and Qin, Yujia and Yang, Guang and Wei, Fuchao and Yang, Zonghan and Su, Yusheng and Hu, Shengding and Chen, Yulin and Chan, Chi-Min and Chen, Weize and others},
  journal={Nature Machine Intelligence},
  volume={5},
  number={3},
  pages={220--235},
  year={2023},
  publisher={Nature Publishing Group UK London}
}
% ----

@misc{longpre2023flan,
      title={The Flan Collection: Designing Data and Methods for Effective Instruction Tuning}, 
      author={Shayne Longpre and Le Hou and Tu Vu and Albert Webson and Hyung Won Chung and Yi Tay and Denny Zhou and Quoc V. Le and Barret Zoph and Jason Wei and Adam Roberts},
      year={2023},
      eprint={2301.13688},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2301.13688}, 
}

@misc{vicuna2023,
  title = {Vicuna LLM: An open-source chatbot developed by fine-tuning the LLaMA model on user-shared conversations, achieving performance comparable to other advanced chatbots},
  author = {Vicuna Development Team},
  year = {2023},
  howpublished = {\url{https://lmsys.org/blog/2023-03-30-vicuna/}},
  note = {Accessed: 2025-01-27}
}
@misc{OpenOrca,
  title = {OpenOrca: An Open Dataset of GPT Augmented FLAN Reasoning Traces},
  author = {Wing Lian and Bleys Goodson and Eugene Pentland and Austin Cook and Chanvichet Vong and "Teknium"},
  year = {2023},
  publisher = {HuggingFace},
  journal = {HuggingFace repository},
  howpublished = {\url{https://https://huggingface.co/Open-Orca/OpenOrca}},
}

@misc{ankner2024perplexed,
      title={Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models}, 
      author={Zachary Ankner and Cody Blakeney and Kartik Sreenivasan and Max Marion and Matthew L. Leavitt and Mansheej Paul},
      year={2024},
      eprint={2405.20541},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.20541}, 
}

@misc{antonello2022selectinginformativecontextsimproves,
      title={Selecting Informative Contexts Improves Language Model Finetuning}, 
      author={Richard Antonello and Nicole Beckage and Javier Turek and Alexander Huth},
      year={2022},
      eprint={2005.00175},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2005.00175}, 
}

@misc{yin2024computeconstraineddataselection,
      title={Compute-Constrained Data Selection}, 
      author={Junjie Oscar Yin and Alexander M. Rush},
      year={2024},
      eprint={2410.16208},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.16208}, 
}

@misc{lalor2020dynamicdataselectioncurriculum,
      title={Dynamic Data Selection for Curriculum Learning via Ability Estimation}, 
      author={John P. Lalor and Hong Yu},
      year={2020},
      eprint={2011.00080},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2011.00080}, 
}




% method



@misc{Dolly,
  title = {Databricks Dolly-15k},
  author = {Databricks},
  year = {2023},
  publisher = {HuggingFace},
  url = {https://huggingface.co/datasets/databricks/databricks-dolly-15k}
}

@inproceedings{openassist,
 author = {K\"{o}pf, Andreas and Kilcher, Yannic and von R\"{u}tte, Dimitri and Anagnostidis, Sotiris and Tam, Zhi Rui and Stevens, Keith and Barhoum, Abdullah and Nguyen, Duc and Stanley, Oliver and Nagyfi, Rich\'{a}rd and ES, Shahul and Suri, Sameer and Glushkov, David and Dantuluri, Arnav and Maguire, Andrew and Schuhmann, Christoph and Nguyen, Huu and Mattick, Alexander},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {47669--47681},
 publisher = {Curran Associates, Inc.},
 title = {OpenAssistant Conversations - Democratizing Large Language Model Alignment},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/949f0f8f32267d297c2d4e3ee10a2e7e-Paper-Datasets_and_Benchmarks.pdf},
 volume = {36},
 year = {2023}
}

@inproceedings{
zhao2024wildchat,
title={WildChat: 1M Chat{GPT} Interaction Logs in the Wild},
author={Wenting Zhao and Xiang Ren and Jack Hessel and Claire Cardie and Yejin Choi and Yuntian Deng},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=Bl8u7ZRlbM}
}


@inproceedings{
zheng2024lmsyschatm,
title={{LMSYS}-Chat-1M: A Large-Scale Real-World {LLM} Conversation Dataset},
author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Tianle Li and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zhuohan Li and Zi Lin and Eric Xing and Joseph E. Gonzalez and Ion Stoica and Hao Zhang},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=BOfDKxfwt0}
}

@inproceedings{
zheng2024judging,
title={Judging {LLM}-as-a-Judge with {MT}-Bench and Chatbot Arena},
author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2023},
url={https://openreview.net/forum?id=uccHPGDlao}
}
@misc{yue2023mammoth,
      title={MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning}, 
      author={Xiang Yue and Xingwei Qu and Ge Zhang and Yao Fu and Wenhao Huang and Huan Sun and Yu Su and Wenhu Chen},
      year={2023},
      eprint={2309.05653},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.05653}, 
}
@misc{cui2024ultrafeedback,
      title={UltraFeedback: Boosting Language Models with Scaled AI Feedback}, 
      author={Ganqu Cui and Lifan Yuan and Ning Ding and Guanming Yao and Bingxiang He and Wei Zhu and Yuan Ni and Guotong Xie and Ruobing Xie and Yankai Lin and Zhiyuan Liu and Maosong Sun},
      year={2024},
      eprint={2310.01377},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.01377}, 
}


% motivation
@misc{herel2024collapseselftrainedlanguagemodels,
      title={Collapse of Self-trained Language Models}, 
      author={David Herel and Tomas Mikolov},
      year={2024},
      eprint={2404.02305},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.02305}, 
}

@misc{mobahi2020selfdistillationamplifiesregularizationhilbert,
      title={Self-Distillation Amplifies Regularization in Hilbert Space}, 
      author={Hossein Mobahi and Mehrdad Farajtabar and Peter L. Bartlett},
      year={2020},
      eprint={2002.05715},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2002.05715}, 
}
@misc{allenzhu2023understandingensembleknowledgedistillation,
      title={Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning}, 
      author={Zeyuan Allen-Zhu and Yuanzhi Li},
      year={2023},
      eprint={2012.09816},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2012.09816}, 
}

@misc{zhou2023lima,
      title={LIMA: Less Is More for Alignment}, 
      author={Chunting Zhou and Pengfei Liu and Puxin Xu and Srini Iyer and Jiao Sun and Yuning Mao and Xuezhe Ma and Avia Efrat and Ping Yu and Lili Yu and Susan Zhang and Gargi Ghosh and Mike Lewis and Luke Zettlemoyer and Omer Levy},
      year={2023},
      eprint={2305.11206},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.11206}, 
}
@misc{yang2024s2l,
      title={SmallToLarge (S2L): Scalable Data Selection for Fine-tuning Large Language Models by Summarizing Training Trajectories of Small Models}, 
      author={Yu Yang and Siddhartha Mishra and Jeffrey N Chiang and Baharan Mirzasoleiman},
      year={2024},
      eprint={2403.07384},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.07384}, 
}

@misc{liu2024deita,
      title={What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning}, 
      author={Wei Liu and Weihao Zeng and Keqing He and Yong Jiang and Junxian He},
      year={2024},
      eprint={2312.15685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.15685}, 
}


@misc{wu2024curriculumlearningqualitydrivendata,
      title={Curriculum Learning with Quality-Driven Data Selection}, 
      author={Biao Wu and Fang Meng and Ling Chen},
      year={2024},
      eprint={2407.00102},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2407.00102}, 
}
@misc{li2024superfilteringweaktostrongdatafiltering,
      title={Superfiltering: Weak-to-Strong Data Filtering for Fast Instruction-Tuning}, 
      author={Ming Li and Yong Zhang and Shwai He and Zhitao Li and Hongyu Zhao and Jianzong Wang and Ning Cheng and Tianyi Zhou},
      year={2024},
      eprint={2402.00530},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.00530}, 
}


% system
@misc{zhong2024distservedisaggregatingprefilldecoding,
      title={DistServe: Disaggregating Prefill and Decoding for Goodput-optimized Large Language Model Serving}, 
      author={Yinmin Zhong and Shengyu Liu and Junda Chen and Jianbo Hu and Yibo Zhu and Xuanzhe Liu and Xin Jin and Hao Zhang},
      year={2024},
      eprint={2401.09670},
      archivePrefix={arXiv},
      primaryClass={cs.DC},
      url={https://arxiv.org/abs/2401.09670}, 
}
@article{zhou2024survey,
  title={A survey on efficient inference for large language models},
  author={Zhou, Zixuan and Ning, Xuefei and Hong, Ke and Fu, Tianyu and Xu, Jiaming and Li, Shiyao and Lou, Yuming and Wang, Luning and Yuan, Zhihang and Li, Xiuhong and others},
  journal={arXiv preprint arXiv:2404.14294},
  year={2024}
}
@misc{hendrycks2021mmlu,
      title={Measuring Massive Multitask Language Understanding}, 
      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
      year={2021},
      eprint={2009.03300},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2009.03300}, 
}
@misc{suzgun2022bbh,
      title={Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them}, 
      author={Mirac Suzgun and Nathan Scales and Nathanael Schärli and Sebastian Gehrmann and Yi Tay and Hyung Won Chung and Aakanksha Chowdhery and Quoc V. Le and Ed H. Chi and Denny Zhou and Jason Wei},
      year={2022},
      eprint={2210.09261},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2210.09261}, 
}

@misc{dubois2024alpacaevalv2,
      title={Length-Controlled AlpacaEval: A Simple Way to Debias Automatic Evaluators}, 
      author={Yann Dubois and Balázs Galambosi and Percy Liang and Tatsunori B. Hashimoto},
      year={2024},
      eprint={2404.04475},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2404.04475}, 
}

@misc{zhao2021datasetcondensationgradientmatching,
      title={Dataset Condensation with Gradient Matching}, 
      author={Bo Zhao and Konda Reddy Mopuri and Hakan Bilen},
      year={2021},
      eprint={2006.05929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2006.05929}, 
}
@misc{zhang2024tagcostaskagnosticgradientclustered,
      title={TAGCOS: Task-agnostic Gradient Clustered Coreset Selection for Instruction Tuning Data}, 
      author={Jipeng Zhang and Yaxuan Qin and Renjie Pi and Weizhong Zhang and Rui Pan and Tong Zhang},
      year={2024},
      eprint={2407.15235},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.15235}, 
}

@misc{pan2024scalebioscalablebileveloptimization,
      title={ScaleBiO: Scalable Bilevel Optimization for LLM Data Reweighting}, 
      author={Rui Pan and Jipeng Zhang and Xingyuan Pan and Renjie Pi and Xiaoyu Wang and Tong Zhang},
      year={2024},
      eprint={2406.19976},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.19976}, 
}

@misc{TAGOS,
      title={TAGCOS: Task-agnostic Gradient Clustered Coreset Selection for Instruction Tuning Data}, 
      author={Jipeng Zhang and Yaxuan Qin and Renjie Pi and Weizhong Zhang and Rui Pan and Tong Zhang},
      year={2024},
      eprint={2407.15235},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.15235}, 
}

@misc{GraNd,
      title={Deep Learning on a Data Diet: Finding Important Examples Early in Training}, 
      author={Mansheej Paul and Surya Ganguli and Gintare Karolina Dziugaite},
      year={2023},
      eprint={2107.07075},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2107.07075}, 
}

@misc{RDS1,
      title={Learning To Retrieve Prompts for In-Context Learning}, 
      author={Ohad Rubin and Jonathan Herzig and Jonathan Berant},
      year={2022},
      eprint={2112.08633},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2112.08633}, 
}
@misc{RDS2,
      title={Evaluation of Similarity-based Explanations}, 
      author={Kazuaki Hanawa and Sho Yokoi and Satoshi Hara and Kentaro Inui},
      year={2021},
      eprint={2006.04528},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2006.04528}, 
}
@misc{Coreset,
      title={Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data Assessment and Selection for Instruction Tuning of Language Models}, 
      author={Yulei Qin and Yuncheng Yang and Pengcheng Guo and Gang Li and Hang Shao and Yuchen Shi and Zihan Xu and Yun Gu and Ke Li and Xing Sun},
      year={2024},
      eprint={2408.02085},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.02085}, 
}
@misc{FacilityLocations,
      title={An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models}, 
      author={Gantavya Bhatt and Yifang Chen and Arnav M. Das and Jifan Zhang and Sang T. Truong and Stephen Mussmann and Yinglun Zhu and Jeffrey Bilmes and Simon S. Du and Kevin Jamieson and Jordan T. Ash and Robert D. Nowak},
      year={2024},
      eprint={2401.06692},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.06692}, 
}
@misc{Uncertainty1,
      title={When Less is More: Investigating Data Pruning for Pretraining LLMs at Scale}, 
      author={Max Marion and Ahmet Üstün and Luiza Pozzobon and Alex Wang and Marzieh Fadaee and Sara Hooker},
      year={2023},
      eprint={2309.04564},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.04564}, 
}
@misc{Uncertainty2,
      title={An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models}, 
      author={Gantavya Bhatt and Yifang Chen and Arnav M. Das and Jifan Zhang and Sang T. Truong and Stephen Mussmann and Yinglun Zhu and Jeffrey Bilmes and Simon S. Du and Kevin Jamieson and Jordan T. Ash and Robert D. Nowak},
      year={2024},
      eprint={2401.06692},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.06692}, 
}
@misc{PPL1,
      title={When Less is More: Investigating Data Pruning for Pretraining LLMs at Scale}, 
      author={Max Marion and Ahmet Üstün and Luiza Pozzobon and Alex Wang and Marzieh Fadaee and Sara Hooker},
      year={2023},
      eprint={2309.04564},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.04564}, 
}
@misc{Learnability1,
      title={Prioritized Training on Points that are Learnable, Worth Learning, and Not Yet Learnt}, 
      author={Sören Mindermann and Jan Brauner and Muhammed Razzak and Mrinank Sharma and Andreas Kirsch and Winnie Xu and Benedikt Höltgen and Aidan N. Gomez and Adrien Morisot and Sebastian Farquhar and Yarin Gal},
      year={2022},
      eprint={2206.07137},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2206.07137}, 
}
@misc{
Learnability2,
title={Gauging Learnability in Supervised Fine-tuning Data},
author={Haotian Zhou and Tingkai Liu and Qianli Ma and Jianbo Yuan and Pengfei Liu and Yang You and Hongxia Yang},
year={2024},
url={https://openreview.net/forum?id=KpC3dPumJj}
}
@misc{Learnability3,
      title={DavIR: Data Selection via Implicit Reward for Large Language Models}, 
      author={Haotian Zhou and Tingkai Liu and Qianli Ma and Yufeng Zhang and Jianbo Yuan and Pengfei Liu and Yang You and Hongxia Yang},
      year={2024},
      eprint={2310.13008},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.13008}, 
}
@misc{S2LRef,
      title={Training Trajectories of Language Models Across Scales}, 
      author={Mengzhou Xia and Mikel Artetxe and Chunting Zhou and Xi Victoria Lin and Ramakanth Pasunuru and Danqi Chen and Luke Zettlemoyer and Ves Stoyanov},
      year={2023},
      eprint={2212.09803},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2212.09803}, 
}