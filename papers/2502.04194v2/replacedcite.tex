\section{Related Works}
\paragraph{Data Engineering For Instruction Tuning}

Data is central to the success of effective instruction tuning, ____, featuring both automated data synthesis____ and selection____. Some selection approaches focus on high-quality data by leveraging LLMs____ or employing principled metrics____, while others, such as ____, aim to identify diversity-optimized subsets for greater efficiency.

Another emerging trend is the customization of training data based on the characteristics of the base models. For instance, ____ leverage the base model itself to select a subset of instructions, while ____ introduce a teacher model to guide the selection process. However, these approaches primarily focus on identifying a re-weighted subset of questions for training. In contrast, \name has a different focus, where it aims to find a set of responses from the solution space that not only provide good coverage of the golden distribution but also align closely with the base model's policy.

\paragraph{On-Policy Methods For Language Model Alignment}

Recent advances in RLHF____, RLAIF____ and preference learning____ research have identified the benefits of on-policy data for model alignment____. However, these works primarily emphasize the preference-tuning stage, where models are refined to generate samples from an already reasonable policy. In contrast, less attention is given to the supervised fine-tuning phase, which starts with base models that are not yet well-prepared to generate high-quality answers that align sufficiently with the desired policy for optimization.


% \subsection{Data Personalization for Language Models}
% Data personalization, mostly for the purpose of curriculum learning, has gained popularity.