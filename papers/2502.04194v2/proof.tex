\section{Appendix: Detailed Math Proofs}

\subsection{Preliminaries}

We consider discrete distributions over a finite set of responses $\mathcal{R}$. 
For distributions $p$ and $q$ on $\mathcal{R}$, recall the Kullback-Leibler (KL) divergence:
\[
D_{\mathrm{KL}}(p \,\|\, q) 
\;=\; 
\sum_{r \in \mathcal{R}} p(r)\,\log\!\Bigl(\tfrac{p(r)}{q(r)}\Bigr).
\]
KL divergence is always non-negative and $D_{\mathrm{KL}}(p\|q) = 0$ iff $p = q$ (almost everywhere).

\subsection{Theorem~1: Policy-Guided Selection Minimizes KL}

\begin{theorem}
\label{thm:kl-min-selection}
Let $\tilde{\mathcal{R}}_i$ be a candidate pool of valid responses. Suppose we want to select a subset of size $K$ and assign a probability distribution $\tilde{\pi}$ on that subset. Our objective is to \emph{minimize} $D_{\mathrm{KL}}(\tilde{\pi} \,\|\, \pi_{\theta_0})$. 

Then the solution is:
\begin{itemize}
    \item Choose the top-$K$ responses $\mathcal{R}_i^{\theta_0}$ under $\pi_{\theta_0}$ (i.e.\ those $r$ for which $\pi_{\theta_0}(r)$ is largest).
    \item Set $\tilde{\pi}(r) \propto \pi_{\theta_0}(r)$ for $r \in \mathcal{R}_i^{\theta_0}$.
\end{itemize}

For any other distribution $\tilde{\pi}_{\mathrm{rand}}$ supported on some subset of size $K$, 
\[
D_{\mathrm{KL}}\bigl(\hat{\pi}_{\theta_0}\,\big\|\,\pi_{\theta_0}\bigr) 
\;\le\; 
D_{\mathrm{KL}}\bigl(\tilde{\pi}_{\mathrm{rand}}\,\big\|\,\pi_{\theta_0}\bigr).
\]
\end{theorem}

\begin{proof}
\textbf{Step 1: Fix a $K$-element support and solve for $\tilde{\pi}$.}\\
Fix any subset $S \subseteq \tilde{\mathcal{R}}_i$ of size $K$. Among distributions $\tilde{\pi}$ with $\mathrm{Supp}(\tilde{\pi}) = S$, we want to solve:
\[
\min_{\tilde{\pi}:\,\mathrm{Supp}(\tilde{\pi})=S} \; 
D_{\mathrm{KL}}\bigl(\tilde{\pi}\,\|\,\pi_{\theta_0}\bigr).
\]
Expand the KL:
\[
D_{\mathrm{KL}}(\tilde{\pi}\,\|\,\pi_{\theta_0}) 
= \sum_{r \in S} \tilde{\pi}(r)\,\log\!\Bigl(\tfrac{\tilde{\pi}(r)}{\pi_{\theta_0}(r)}\Bigr).
\]
Use Lagrange multipliers or note that for fixed support $S$, this KL is minimized by setting 
\[
\tilde{\pi}(r) \;=\; \frac{\pi_{\theta_0}(r)}{\sum_{r'\in S}\pi_{\theta_0}(r')}, 
\quad r \in S.
\]
Thus the minimizer is precisely the renormalized distribution of $\pi_{\theta_0}$ on $S$.

\noindent
\textbf{Step 2: Find the best $K$-element subset.}\\
Now we want to choose $S$ of size $K$ to minimize $D_{\mathrm{KL}}(\tilde{\pi}\,\|\,\pi_{\theta_0})$. 
Given Step~1, the minimal KL with support $S$ is
\[
\sum_{r \in S} \frac{\pi_{\theta_0}(r)}{\sum_{r'\in S}\pi_{\theta_0}(r')} 
   \,\log\!\Bigl(\tfrac{\pi_{\theta_0}(r)/Z_S}{\pi_{\theta_0}(r)}\Bigr),
\]
where $Z_S = \sum_{r'\in S} \pi_{\theta_0}(r')$.  Simplify the logarithm:
\[
\log\!\Bigl(\tfrac{\pi_{\theta_0}(r)/Z_S}{\pi_{\theta_0}(r)}\Bigr) 
= \log\!\Bigl(\tfrac{1}{Z_S}\Bigr) 
= -\log(Z_S).
\]
So
\[
D_{\mathrm{KL}}(\tilde{\pi}\,\|\,\pi_{\theta_0}) 
= \sum_{r \in S} \frac{\pi_{\theta_0}(r)}{Z_S}\,\bigl(-\log Z_S \bigr) 
= -\log Z_S \;\sum_{r \in S} \frac{\pi_{\theta_0}(r)}{Z_S}.
\]
But $\sum_{r \in S} \frac{\pi_{\theta_0}(r)}{Z_S} = 1$. Hence
\[
D_{\mathrm{KL}}(\tilde{\pi}\,\|\,\pi_{\theta_0}) = -\log Z_S.
\]
Because $\pi_{\theta_0}(r)\ge 0$, we have $Z_S = \sum_{r\in S} \pi_{\theta_0}(r)$. Minimizing $-\log Z_S$ is equivalent to \emph{maximizing} $Z_S$ over all $K$-element subsets $S \subseteq \tilde{\mathcal{R}}_i$. This maximum is achieved by picking the $K$ elements with the largest values of $\pi_{\theta_0}(r)$, i.e.\ the top-$K$ responses. 

Thus the distribution $\hat{\pi}_{\theta_0}$ that re-normalizes $\pi_{\theta_0}$ onto its top-$K$ support uniquely minimizes the KL.

\noindent
\textbf{Step 3: Compare to any random subset.}\\
A random subset $\mathcal{R}_i^{(\mathrm{rand})}$ supported on $K$ elements that are not necessarily the top-$K$ by $\pi_{\theta_0}$ results in $Z_S$ that is strictly smaller (unless it accidentally picks exactly those top-$K$). Thus $-\log Z_S$ is strictly larger, giving a strictly larger KL. This proves the theorem.
\end{proof}


\subsection{Theorem~2: Closer to the Golden Distribution}

\begin{theorem}
\label{thm:closer-golden}
Let $\hat{\pi}_{\theta_0}$ be the distribution over $\tilde{\mathcal{R}}_i$ formed by selecting top-$K$ valid responses and renormalizing $\pi_{\theta_0}$. Suppose $\tilde{\mathcal{R}}_i$ is drawn from a mixture $\pi_{\mathcal{C}}^{(\cup)}$ that is itself closer to $\pi^*$ than $\pi_{\theta_0}$. Then:
\[
D_{\mathrm{KL}}\Bigl(\hat{\pi}_{\theta_0}\,\Big\|\,\pi^*\Bigr) 
\;<\; 
D_{\mathrm{KL}}\Bigl(\pi_{\theta_0}\,\Big\|\,\pi^*\Bigr).
\]
\end{theorem}

\begin{proof}
\textbf{Step 1: Restricting support to valid responses.}\\
Since $\tilde{\mathcal{R}}_i$ is sampled from policies $\{\pi_{\mathcal{C}}^{(m)}\}$ that presumably place high probability on valid or near-correct solutions (closer to $\pi^*$), the set $\tilde{\mathcal{R}}_i$ excludes many low-quality responses that $\pi_{\theta_0}$ might have supported originally.

\noindent
\textbf{Step 2: Construct $\hat{\pi}_{\theta_0}$.}\\
Within $\tilde{\mathcal{R}}_i$, we keep the top-$K$ responses under $\pi_{\theta_0}$. By removing responses outside $\tilde{\mathcal{R}}_i$ (many of which might be misaligned or invalid), $\hat{\pi}_{\theta_0}$ effectively ``truncates'' the mass of $\pi_{\theta_0}$ to presumably better responses in $\tilde{\mathcal{R}}_i$.

\noindent
\textbf{Step 3: KL comparison.}\\
Write the KL divergences:
\[
D_{\mathrm{KL}}\bigl(\hat{\pi}_{\theta_0}\,\|\,\pi^*\bigr) 
= \sum_{r \in \mathcal{R}_i^{\theta_0}} \hat{\pi}_{\theta_0}(r)\,\log\!\Bigl(\tfrac{\hat{\pi}_{\theta_0}(r)}{\pi^*(r)}\Bigr).
\]
Meanwhile,
\[
D_{\mathrm{KL}}\bigl(\pi_{\theta_0}\,\|\,\pi^*\bigr) 
= \sum_{r \in \mathcal{R}} \pi_{\theta_0}(r)\,\log\!\Bigl(\tfrac{\pi_{\theta_0}(r)}{\pi^*(r)}\Bigr).
\]
Because $\hat{\pi}_{\theta_0}$ zeroes out probability on responses not in $\mathcal{R}_i^{\theta_0}$ and reweights on valid or good responses, it systematically removes the contributions to KL from any bad out-of-support $r$ that $\pi^*$ also places near-zero mass on. 
Hence $D_{\mathrm{KL}}(\hat{\pi}_{\theta_0}\,\|\,\pi^*)$ is \emph{strictly less} than $D_{\mathrm{KL}}(\pi_{\theta_0}\,\|\,\pi^*)$ (unless $\pi_{\theta_0}$ was already perfectly aligned). 
\end{proof}
