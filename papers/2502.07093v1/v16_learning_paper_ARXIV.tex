\documentclass[12pt]{article}
\usepackage{amsmath, amssymb}
%\usepackage{ntheorem}
\usepackage{enumitem}
\usepackage{authblk}
\usepackage{lineno}
\usepackage[toc,page]{appendix}
\usepackage{amsthm}
\usepackage{float}
%\usepackage{hyperref}
\usepackage{changepage}
\usepackage{aliascnt}
\usepackage{theoremref,amsthm}
\usepackage{morefloats}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{listings}
%\usepackage{biblatex}
\usepackage{xcolor}
\usepackage{float}
\usepackage{verbatim}
\usepackage{geometry}
\usepackage{centernot}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
%\usepackage{hyperref}
\usepackage{setspace}
\usepackage{thmtools}
\usepackage{xcolor}
\usepackage[bottom]{footmisc}
\usepackage{euscript}
%\documentclass{minimal}
\usepackage{mathtools}
\usepackage{enumitem}
\usepackage [autostyle, english = american]{csquotes}
\MakeOuterQuote{"}
\newcommand{\subscript}[2]{$#1 #2$}
%\DeclarePairedDelimiter\ceil{\left\lceil}{\right\rceil}
%\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\DeclareMathAlphabet{\itbf}{OML}{cmm}{b}{it}
%\newcommand{\subscript}[2]{$#1 _ #2$}
\providecommand{\keywords}[1]{\textbf{Keywords:} #1}

\newcommand{\bea}{\begin{eqnarray*}}
\newcommand{\eea}{\end{eqnarray*}}
\newcommand{\bean}{\begin{eqnarray}}
\newcommand{\eean}{\end{eqnarray}}
\newcommand{\p}{\partial}
\newcommand{\f}{\frac}
\newcommand{\s}{\sqrt}
\newcommand{\ds}{\displaystyle}
\newcommand{\no}{\nonumber}
\newcommand\ov{\overline}
\newcommand{\ri}{\rightarrow}
\newcommand{\sm}{\setminus}
\newcommand{\aaa}{\mbox{$[$}}
\newcommand{\bbb}{\mbox{$]$}}


\newtheorem{lem}{Lemma}[section]
\newtheorem{prop}{Proposition}[section]
\newtheorem{cor}{Corollary}[section]
\newtheorem{thm}{Theorem}[section]
\newtheorem{rem}{Remark}[section]


\pagenumbering{arabic}
\geometry{margin=1 in}
\setlength{\parindent}{0cm}
%\geometry{bmargin=0.5 in}
%\bibliography{LaTeX_Tutorial}
%Commands
\newcommand{\eps}{\varepsilon}
\newcommand{\doubleR}{\mathbb{R}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\doubleQ}{\mathbb{Q}}
\newcommand{\doubleZ}{\mathbb{Z}}
\newcommand{\doubleN}{\mathbb{N}}
\renewcommand{\a}[1]{\left\vert #1 \right\vert}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
%\newcommand{\p}[1]{\left( #1 \right)}
\renewcommand{\r}[1]{\frac{1}{#1}}
\renewcommand\qedsymbol{$\blacksquare$}
\renewcommand{\ov}[1]{\overline{#1}}
\newcommand{\pfrac}[2]{\frac{\partial #1}{\partial #2}}
\renewcommand{\ss}{\doubleR^{3-}\sm\ov{\Gamma}}
\newcommand{\supp}{\text{supp}}

\newcommand{\bc}{{\itbf c}}
\newcommand{\bm}{{\itbf m}}
\newcommand{\bp}{{\itbf p}}
\newcommand{\bt}{{\itbf t}}
\newcommand{\bq}{{\itbf q}}
\newcommand{\br}{{\itbf r}}
\newcommand{\bs}{{\itbf s}}
\newcommand{\bz}{{\itbf z}}
\newcommand{\bx}{{\itbf x}}
\newcommand{\bv}{{\itbf v}}
\newcommand{\bg}{{\itbf g}}
\newcommand{\bh}{{\itbf h}}
\newcommand{\bev}{{\itbf e}}
\newcommand{\bw}{{\itbf w}}
\newcommand{\bu}{{\itbf u}}
\newcommand{\bn}{{\itbf n}}
\newcommand{\by}{{\itbf y}}

 \author{Mahadevan Ganesh
\thanks{Department of Applied Mathematics and Statistics,
    Colorado School of Mines, Golden, CO, %80401 %mganesh@mines.edu
   USA},
	 Stuart C. Hawkins % stuart.hawkins@mq.edu.au
	% The first two authors gratefully acknowledge the support of the Australian Research Council (ARC) Discovery Project Grant (DP220102243)Â 
	% SCH and MG gratefully acknowledge the support of
%the Australian Research Council (ARC) Discovery Project Grant (DP220102243).
%MG was supported by the Simons Foundation through Grant No. 5188
% D. V. is supported by the Simons Foundation through Grant MPS-TSM-00007534
	\thanks{Department of Mathematical and Physical Sciences,
    Macquarie University, Sydney, NSW 2109, % 18 Wally's Walk, Ground Floor
%Macquarie University NSW 2109
    Australia}, 
Darko  Volkov 
\thanks{Department of Mathematical Sciences,
Worcester Polytechnic Institute, Worcester, MA 01609. Corresponding author email: darko@wpi.edu. 
} }
%\and 
%}  }
	%	\author{Darko Volkov}
%\author{Yulong Jiang}
%\affil{Department of Mathematical Sciences,
%Worcester Polytechnic Institute, Worcester, MA 01609}


\begin{document}
%\linenumbers
%\begin{center}
  %  \large{\textbf{Stability properties of a crack inverse problem in half space}}\\
	%	\normalsize
		%\end{center}	
		%\title{Neural network approximation for a class of operators and application to inverse scattering}
		\title{Neural network-motivated regularity analysis of  
		  inverse problems and application to inverse scattering}
			%\title{Analysis of neural network approximations for a class of unbounded region models with applications to inverse scattering}
		%\title{Neural network approximations for a class of unbounded region models: Formulation, analysis, and applications to inverse scattering}
		\maketitle
    %\textbf{NEED TITLE}\\
    %NEED SUBTITLE\\
   
		
\begin{abstract}
We derive Lipschitz regularity estimates 
for an approximate inverse of a general 
compact  operator that depends non-linearly on a vector parameter.
The regularity estimates are motivated by the desire to develop
neural networks (NN) that compute that approximate inverse
and the convergence of the NNs follows from the Lipschitz regularity
estimates.
Such compact operators arise in inverse wave scattering applications
with unbounded domains,
and we illustrate our theory by showing that the particular assumptions of our
regularity analysis hold for the problem of identifying cracks from far-field
data.
Numerical results using a NN for parameter recovery demonstrate the
accuracy, efficiency and robustness of our approach.
\end{abstract}

\textbf{MSC 2020 Mathematics Subject Classification:} 
% 35R30: Inverse problems (undetermined coefficients, etc.) for PDE
% 45-xx: Integral equations45Q05: Inverse problems
35R30,  35J67, 45Q05, 47N40, 68T07.\\
% 35J67: Boundary values of solutions to elliptic equations
% 	35J67  	Boundary values of solutions to elliptic equations and elliptic systems
%45Q05  	Inverse problems for integral equations
% 47-xx: Operator theory
% 47A52: Ill-posed problems, regularization
% 47N20: Applications to differential and integral equations
% 47N40: Applications in numerical analysis
% 35B60: Continuation and prolongation of solutions [See also 58A15, 58A17, 58Hxx]
% 68T07  	Artificial neural networks and deep learning
\keywords{Nonlinear inverse problems, Regularity estimates, Inverse scattering, Neural networks}

\section*{Acknowledgement}
SCH and MG gratefully acknowledge the support of
the Australian Research Council (ARC) Discovery Project Grant (DP220102243).
MG is supported by the Simons Foundation through Grant No. 5188.
 DV is supported by the Simons Foundation through Grant MPS-TSM-00007534.

\section{Introduction}
This article focuses on proving regularity estimates 
for the inverse of a general 
compact  operator depending non-linearly on a vector  parameter.
These regularity estimates hold on   subspaces 
in the span of a finite number of singular vectors
if two conditions \ref{U1}-\ref{U2}, stated in section \ref{prelim},  are verified.
We give generic examples to  illustrate the two conditions \ref{U1}-\ref{U2}
in section \ref{Generic examples}.
Condition \ref{U1} is just an injectivity condition while,
as discussed in  section \ref{comments1},  condition \ref{U2}
 relates to the inverse function theorem.
After that, we provide a formal proof of the regularity results.
The proof relies on functional analysis techniques such as compactness,
weak and strong convergence, and  local continuity of 
parameter  dependent
spectral projectors 
for compact symmetric operators.
These spectral projectors are known to  be not necessarily globally continuous 
with regard to that parameter  \cite{kato2013perturbation}: this is arguably the main
challenge in our proof.
Our main regularity result is stated in 
Theorem \ref{main theorem}.
Although we proved a result similar to Theorem \ref{main theorem}
  in an earlier study \cite{volkov2024stability},
there are  substantial differences between these two  results.
 % and Theorem \ref{main theorem}.
The study \cite{volkov2024stability} pertained specifically to integral  operators.
The results covered here are more general.
Moreover,  the lower bound provided here 
in  Theorem \ref{main theorem} is sharper, depending both on the nonlinear parameter
and on linear terms. 
Finally, the proof technique adopted here is quite different. 
A first result is shown in the finite dimensional case in  section \ref{finite dim sec}.
It is then involved in tackling the infinite dimensional case by use
of  maps between singular spaces  and a fixed finite dimensional space.
These maps are proved to be locally $C^1$ in the nonlinear parameter thanks to  
conditions \ref{U1}-\ref{U2}.

In section \ref{Dirichlet screen}, we apply our theory
to an example in inverse scattering. In this example, the forward  model is  governed by
the Helmholtz equation in an unbounded region.
The inverse scattering problem consists of 
identifying a crack in the propagation medium, which is done by first training a neural
network.
This example is very specific, however, we strongly believe that 
the method introduced here could work just as well
in other  propagating wave cases as long as  some integral formulation is possible
such as in \cite{colton1998inverse, DoGa:2022, DoGaSa:2020, nedelec2001acoustic, stephan1984augmented}.

Section \ref{num section} of this paper
covers  computational aspects  involved  in  the   
specific application to inverse scattering that we consider.  
These computations rely on a solid mathematical background. Indeed, first,  the general requirements from section \ref{Lipschitz regularity results sec}
guaranteeing regularity
 are proved to hold for the inverse problem at hand
in section \ref{Dirichlet screen}.
Second, the gap between regularity for this continuously defined inverse problem
and regularity for its discrete analog was  bridged in \cite[Theorem 4.2]{volkov2024stability}.
And third, 
precise convergence results were proved for approximations
of regular functions by neural networks 
\cite{shen2021neural, yarotsky2017error, de2021approximation}.
In particular, \cite[Corollary 5.4]{de2021approximation}
gives an explicit bound on the number of nodes of a deep neural network
with $n$ nodes approximating a Lipschitz continuous function 
on $[0,1]^d$.  The number of nodes does not grow faster than
$O(n^d)$ for an approximation in $L^\infty$ norm bounded
above by $O(n^{-1})$.\\
%it was recently proved that given an accuracy requirement, there is an upper
%bound on the number of nodes for an optimal deep neural network 
%to approximate a regular function
% see \cite{shen2021neural, yarotsky2017error}
%and in particular \cite[Corollary 5.4]{de2021approximation}.\\
% theorem 5.1 De Ryck et al. 2021
The simulations presented in  section \ref{num section} comprise three stages. 
First, data for training the NN is built up and stored. 
 Second, the NN is trained on that data.
Third, the accuracy and the computational speed of the NN is tested
on entirely new data.
 This new data is randomly selected from four kinds:
\begin{enumerate}
\item {\bf Plane wave excitation with unknown incident direction}: The crack is excited by an incoming plane wave. 
\item {\bf Internal source excitation with unknown source  location}: The crack is excited by a point-source located between the crack and the scattered wave measurement points.
\item {\bf External source excitation with unknown incident direction}: The crack is excited by a point-source located outside a circle containing the scattered wave measurement points.
\item {\bf Arbitrarily constructed forcing term}: The forcing term is an artificial function defined on the crack.
\end{enumerate}
The fourth case is particularly relevant for modeling the destabilization of cracks in materials under mechanical strain. 
%Thanks to the Lipschitz regularity
%proved in section 	\ref{Lipschitz regularity results sec}, 
Our results demonstrate that the NN can accurately compute
the nonlinear parameter describing the geometry of the crack
{\em { regardless of the forcing term or specific excitation method (plane wave, internal/external source, or artificial forcing function)}}, as predicted by the theory.
Additionally, the NN achieves remarkable computational efficiency, being orders of magnitude faster than traditional minimization methods for solving nonlinear inverse problems. It also exhibits robustness to noise perturbations, ensuring stability under realistic conditions. Since the 
  focus of this work is  the regularity analysis of a large class of inverse problems, the numerical  example presented here features a small number of parameters. In a future study, we shall consider
more complex geometries and accordingly, 
 larger numbers of parameters.
  

\vspace{0.1in}
\section{Preliminaries}\label{prelim}
Our theoretical framework in Section~\ref{finite dim sec} to establish Lipschitz regularity under a general theoretical framework
is based on the following  nomenclature. 
\subsection{Abstract framework and assumptions}\label{abs:framework}
Let 
\begin{itemize}
\item $K$  denote the field $\RR$ or $\CC$;
\item $E$ and $F$ be two Hilbert spaces over $K$;
\item $A_m$ be a compact linear operator from $E$ to $F$ depending on a vector parameter $m$;
\item the vector parameter $m$ be in a compact set ${\cal B}$ of $\RR^p$; and 
\item the function
	$m \mapsto A_m$ be of class $C^1$ in ${\cal B}'$, an open  neighborhood of ${\cal B}$.
\end{itemize}

For establishing the Lipschitz regularity of  the  inverse map $A_m u \mapsto (m,u)$, for all $m \in {\cal B}$ and $u \in E$, 
we need the following two  injectivity assumptions: 
\begin{enumerate}[label=(\subscript{U}{{\arabic*}})]
\item \label{U1} For any $m,m'$ in ${\cal B}$, 
for any $u, v$ in $E$, if $u\neq 0$ and $A_m  u = A_{m'}v$
then $m=m'$ and $u=v$.
%\label{Hcont}\
\item \label{U2} %\label{Hcont}
For $q $ in $\RR^p$ with $|q|=1$, denote $\p_q A_m$ the derivative of $A_m$
in $m$ in the direction of $q$. 
The linear operator $T: E \times E \ri F$, $T(u,v) = \p_q A_m u + A_m v$
is injective.
\end{enumerate}
Clearly, \ref{U1} is a necessary and sufficient condition for the inverse map $A_m u \mapsto (m,u)$
to be defined on the set $\{ A_m u: m \in {\cal B}, u\neq 0 \in E\}$.
We will explain further how condition \ref{U2} relates to the inverse function theorem.
If $E$ is infinite-dimensional, then the inverse  map $A_m u \mapsto (m,u)$ is unbounded.
Accordingly, we  will only consider in that case the  map $A_m u \mapsto (m,u)$ on subsets
of $\{ A_m u: m \in {\cal B}, u\neq 0 \in E\}$. These subsets will be defined using
$m$ dependent singular subspaces of $A_m$. These spaces can be computed in practical applications, as demonstrated further.
 

\subsection{Generic examples}\label{Generic examples}
% In practice, 
%for NN approximations to recover the parameter $m \in {\cal B}$, computations need to be carried out in 
%parameter-dependent finite dimensional  subspaces  of E, say $E_{m,N}$ of dimension $N$. In Section~\ref{finite dim sec},
%we will introduce such precise finite dimensional subspaces of $E$ based on singular values of the operator $A_m$. Hence, for 
%the infinite dimensional case we establish the Lipschitz regularity of the inverse map with respect to these concrete parameter dependent
%finite dimensional subspaces of $E$. 
Before proceeding with  
 statements of regularity results and their proof, we  
provide generic examples
illustrating how  assumptions
\ref{U1}-\ref{U2} can hold in practice.
Later, in section~\ref{inv_crack_example},  we will verify assumptions 
\ref{U1}-\ref{U2}
for a class of
wave propagation models. %$A_m$ will then be defined on an infinite dimensional space.


\vspace{0.1in}
{\bf Generic Example-1 (Finite Dimensional spaces $E$ and $F$)}:

Choose ${\cal B} = [1,2]^2$, $E=\RR^n$ with its natural basis
	$e_1, ..., e_n$,
	$F=\RR^{3n}$ with its natural basis
	$f_1, ..., f_{3n}$.
	For $m=(m_1, m_2)$ in ${\cal B} $ for our first generic example, 
	define $A_m$ by setting for $j=1, ..., n$,
	$$A_m e_j = m_1 f_j + m_2 f_{j+n} + m_2^2 f_{j + 2n}.$$
	
\vspace{0.05in}	
	To verify \ref{U1} for this example, let $u, v  \in E$ with $u=\sum_{j=1}^n u_j e_j $, $v=\sum_{j=1}^n v_j e_j $ 
	such that $u \neq 0$. 
	Let $m, m' \in {\cal B}$. Assume that $A_m u = A_{m'}v$.
	Then for some $k $ in $\{ 1, ..., n\}$, $u_k \neq 0$
	and
	$m_1 u_k = m_1' v_k$, $m_2 u_k = m_2' v_k$, 
	and $m_2^2u_k = m_2'^2 v_k$.
	This implies that $m_2= m_2'$, so $u_k=v_k$ and $m_1=m_1'$.
	$u=v$ easily follows from there.\\
	
\vspace{0.01in}	
Next to verify the assumption (U2),	we let $q=(\cos \alpha, \sin \alpha)$
	and assume that for $u=\sum_{j=1}^n u_j e_j $, $v=\sum_{j=1}^n v_j e_j $ 
	 in $E$ and some $m$ in ${\cal B}$,
	$\p_q A_m u + A_m v=0$. 
	Then for $j=1, ..., n$,
	\bea
	(\cos \alpha) u_j + m_1 v_j = 0, \\
	(\sin \alpha) u_j + m_2 v_j =0, \\
	2 m_2 (\sin \alpha) u_j + m_2^2 v_j =0.
	\eea
	If $\sin \alpha =  0$, then the first  two equations imply $u_j = v_j =0$.
	If $\sin \alpha \neq 0$, then the last two equations imply $u_j = v_j =0$.
	In all cases, we found that $\p_q A_m + A_m$ is injective on
	$E \times E$.
	
\vspace{0.1in}
{\bf Generic Example-2 (Infinite Dimensional spaces $E$ and $F$)}:

For this example, again we choose the parameter set to ${\cal B} = [1,2]^2$.
Let $E$ an infinite dimensional Hilbert space and $\{ e_n: n \geq 1 \}$ a  Hilbert basis of $E$.
Let $F$ be another  infinite dimensional Hilbert space and $\{ f_n: n \geq 1 \}$ a  Hilbert basis of $F$.
	For $m=(m_1, m_2)$ in ${\cal B} $ we 
	define $A_m$ by setting for $n \geq 1$
	$$A_m e_n = \f{m_1}{n} f_{3 n }+ \f{m_2}{n} f_{3n+1} +
	\f{m_2^2}{n} f_{ 3n+2}.$$
	Note that this definition ensures that $A_m $ is compact. Similar to  calculations in the previous Example-1,
	it can be shown that the assumptions \ref{U1}-\ref{U2} also hold for this example.
	 

\subsection{Comments on the conditions \ref{U1}--\ref{U2}
}\label{comments1}
Note that \ref{U1} implies in particular that $A_m$ is injective for all
$m$ in ${\cal B}$, while \ref{U2} implies in particular that $\p_q A_m$ is injective for all
$q $ in $\RR^p$, $q=1$, and $m$ in ${\cal B}$.\\
Condition \ref{U2} can be related to the inverse function theorem.
Indeed, consider the function
\bean \label{calAdef}
{\cal A}: {\cal B}' \times E \ri F\\
(m,u) \mapsto A_m u. 
\eean
It is of class $C^1$ according to the assumptions in Proposition 
 \ref{stable finite dim}. 
If $(m_0, u_0) $ is an interior point of ${\cal B} \times E $,
if the Jacobian $J$ of ${\cal A}$ at $(m_0, u_0) $  is injective
on $\RR^p \times E$
then ${\cal A}$ has a $C^1$ inverse in a neighborhood of $(m_0, u_0) $.

For simplicity, let us assume in this paragraph that $K = \RR$.
Let $e_1, ..., e_p$ be the natural basis of $\RR^p$ and 
$f_1, ... , f_s$ be a basis of $E$. 
$J$ is injective if and only if for all non-zero vectors
$(a_1, ..., a_p, b_1, ... , b_s)$ in $\RR^{p+s}$,
\bean
(a_1 \p_{e_1} A_{m_0}+ ... + a_p \p_{e_p} A_{m_0}) u_0 +
A_{m_0 }(b_1f_1 + ... + b_s f_s) 
\neq 0. \label{Jac inj}
\eean
If \ref{U2} holds and $u_0 \neq 0$, it is clear that \eqref{Jac inj} holds.
%Conversely, assume that $u_0 \neq 0$ 
%and that for all non-zero vectors
%$(a_1, ..., a_p, b_1, ... , b_s)$ in $\RR^{p+s}$
%\eqref{Jac inj} holds.
%Arguing by contradiction, 
Now assume  \ref{U2}  does not hold.
Then there is  $q $ in $\RR^p$ with $|q|=1$, $q=(q_1, ..., q_p)$,
$m_0$ in ${\cal B}$
and $(u_0,v_0) \neq (0,0)$ in $E \times E$ such that 
$\p_q A_m u + A_m v = 0$. 
Accordingly 
\bean
(q_1 \p_{e_1} A_{m_0}+ ... + q_p \p_{e_p} A_{m_0}) u_0 +
A_{m_0 }v_0
= 0. \label{eq 0}
\eean
If $u_0 = 0$, then $v_0 \neq 0$: this shows that condition \ref{U1} does not hold.
 If $u_0 \neq  0$, this shows  that \eqref{Jac inj} does not hold.\\

%In a first case assume that $m \neq m'$.
%\subsubsection{Comments on the conditions 
%from the more general case}







	\section{Lipschitz regularity results for the inverse of $A_m$}
		\label{Lipschitz regularity results sec}

	
	We first prove the regularity result with  finite-dimensional space setting, and subsequently 
	prove the regularity of  the inverse of $A_m$ defined on an infinite dimensional Hilbert space $E$. 
		
	\subsection{regularity proof for the finite-dimensional case}\label{finite dim sec}
	\begin{prop} \label{stable finite dim}
	Consider the framework and assumptions in  section~\ref{abs:framework}.
	In addition assume $E$ is finite-dimensional. Then there is a positive constant $C$ such that 
for all $m,m'$ in ${\cal B}$ and $u,v $
in $E$,
\bean \label{stability E finite dim}
\| A_m u - A_{m'} v  \| \geq 
C(|m-m'| \| v\| + \| u -v\|).
\eean
	\end{prop}
	
	
		\vskip 10 pt
\textbf{Proof}:
We  note that since $E$ is finite-dimensional,
${\cal B}$ is compact and $A_m $ and $\p_q A_m$ 
are continuous in $m$, according
to \ref{U2}, there is a constant $\alpha>0$ such that
\bean \label{below}
\| \p_q A_m u + A_m v \| 
\geq \alpha (\| u \| + \| v\|),
\eean
for all $m$ in $B$, all $q$ in $\RR^p$ with $|q|=1$, and all $u,v$ in $E$.\\
Arguing by contradiction assume that there
are two sequences 
$m_n, m_n'$ in ${\cal B}$ and two sequences
$u_n, v_n$ in $E$ such that
\bean \label{to contrad}
\| A_{m_n} u_n - A_{m_n'} v_n  \| \leq 
\f{1}{n}
(|m_n-m_n'| \| v_n\| + \| u_n  - v_n\| ) ,
\eean
while $|m_n-m_n'| \|  v_n\| + \|  u_n  - v_n\|
\neq 0$. 
By compactness we can assume that $m_n$ converges to some $m$ in ${\cal B}$ and
$m_n'$ converges to some $m'$ in ${\cal B}$. \\
If we assume that $ \| v_n\| =0$, we  contradict
\eqref{below}. \\
If we assume that $ \|  u_n  -  v_n\| =0$,
then 
\bea
\| (A_{m_n} - A_{m_n'} )  u_n 
   \| \leq 
\f{1}{n}
|m_n-m_n'| \|  u_n\|  .
\eea
After extracting a subsequence we may assume that $\f{ u_n }{ \|  u_n\|}$
converges to $\phi \neq 0$ in $E$.
If $m \neq m'$, we obtain at the limit $(A_{m} - A_{m'}) \phi=0$, contradicting
\ref{U1}. If $m =  m'$, then after extracting a subsequence
we may assume that $\f{m_n-m_n'}{|m_n-m_n'|}$ converges to some 
$q$ in $\RR^p$. At the limit we obtain $\p_q A_m \phi=0$ contradicting
\eqref{below}.\\

If we assume that $|m_n-m_n'| =0$ then 
$\| A_m(u_n - v_n) \| \leq \f{1}{n} \| u_n - v_n \|$
 again contradicting  \eqref{below}.\\

Altogether, after possibly extracting a subsequence we can assume that 
$ \|  v_n\| \neq 0$, $ \|  u_n  - v_n\| \neq 0$,
and $|m_n-m_n'| \neq 0$. We set 
\bea
\omega_n = \f{|m_n-m_n'|\|  v_n\|  }{|m_n-m_n'|\|  v_n\|
+  \| u_n  - v_n\|},
\eea
and by \eqref{to contrad}
we find as $n \to \infty$ that 
\bean \label{to cont 2}
\omega_n \f{A_{m_n} -  A_{m_n'}}{|m_n-m_n'| } 
\f{ v_n }{\|  v_n\|} + (1 -\omega_n)
A_{m_n} 
 \f{u_n  - v_n}{\|  u_n  -   v_n\|}
%+ \omega_n A_{m_n} \f{P_{m_n}  - P_{m_n'}}{ |m_n-m_n'|}
%\f{ P_{m_n'} v_n }{\| P_{m_n'} v_n\|}
  \to 0.
\eean
After extracting subsequences, we may assume that $\omega_n$
converges to some $\omega$ in $[0,1]$ and
$\f{  v_n }{\|  v_n\|} $ converges
 to some $\phi$ in $E$ and 
$
 \f{ u_n  - v_n}{\| u_n  -   v_n\|}$
converges 
to some $\psi$ in $E$ with $\| \phi \| = \| \psi \| =1$.
Two cases arise. In the first case $m \neq m'$.
 In that case we find at the limit
\bean \label{lim 1 }
\omega \f{A_{m} -  A_{m'}}{|m-m'| } 
\phi + (1 -\omega)
A_{m} 
\psi
  =0.
\eean
This contradicts \ref{U1} since $m\neq m'$ and $\| \phi \| = \| \psi \| =1$.
In the second case $m=m'$. After extracting a subsequence
we may assume that $\f{m_n - m_n'}{ |m_n-m_n'|}$ converges to some
$q$ in $\RR^p$ and we write
\bea
\f{A_{m_n} -  A_{m_n'}}{|m_n-m_n'| }  =
\int_0^1 \nabla_m A_{m_n' + t (m_n - m_n')} \f{m_n - m_n'}{ |m_n-m_n'|} dt.
\eea
Since $A_m$ is $C^1$ in $m$, as $n \to \infty$ we find from 
\eqref{to cont 2}
\bea
\omega \p_q A_m
\phi+ (1 -\omega)
A_{m} 
 \psi
%+ \omega_n A_{m_n} \f{P_{m_n}  - P_{m_n'}}{ |m_n-m_n'|}
%\f{ P_{m_n'} v_n }{\| P_{m_n'} v_n\|}
  = 0.
\eea
As $\| \phi \| = \| \psi \| =1$, this contradicts \ref{U2}. $\square$

\begin{rem}
Since  $m$ and $ m'$ as well as $u$ and $v$ can be switched in regularity estimate
\eqref{stability E finite dim}, we can equivalently write that for some constant $C$,
\bea
\| A_m u - A_{m'} v  \| \geq 
C(|m-m'| (\| u \| + \| v\|) + \| u -v\|),
\eea
for all $m,m'$ in $B$ and $u,v $
in $E$.
\end{rem}

\begin{rem}
We show that conditions \ref{U1}, \ref{U2} are necessary for 
Lipschitz regularity of the inverse operator estimate 
\eqref{stability E finite dim} to hold. 
Condition \ref{U1}   clearly follows from  \eqref{stability E finite dim}.
	To show \ref{U2} from   \eqref{stability E finite dim}, 
	fix $m$ and $u$
	set $m'=m-\f{q}{n}$ and $u-v = \f{w}{n}$. Let $n \ri \infty$ to obtain
\bea
\|\p_q A_m u + A_m w \| \geq C (\| u\| + \| w\|),
\eea
showing \ref{U2}.
$\square$.
%In a first case assume that $m \neq m'$.
%\subsubsection{Comments on the conditions 
%from the more general case}
\end{rem}

\subsection{The infinite-dimensional case: Projections on finite-dimensional singular spaces}\label{infinite dim sec}
	%Yosida ... possible ...\\
	We again consider the abstract framework and assumptions in section~\ref{abs:framework},
	with $E$ may be infinite-dimensional. We  introduce parameter dependent orthogonal projections 
	and first prove the regularity estimates on the range of the projections.
	
	\vspace{0.05in}
	For  $m$ in ${\cal B}$ let 
	\bea
	 \lambda_1^2(m) > ... > \lambda_N^2 (m)>  ...
	\eea
	be the distinct ordered eigenvalues of $A_m^*A_m$. 
	Fix $m_1$ in ${\cal B}$ and let $P_{m_1} $ be the orthogonal projection on the sum of the eigenspaces
	of $A_{m_1}^*A_{m_1}$ corresponding to the eigenvalues 
	$\lambda_1^2(m_1), ... ,\lambda_N^2(m_1)$.
	Let ${\cal C}_1$ be the  circle in the complex plane centered at the origin with radius
 $\max_{m \in {\cal B}} \| A_{m}^* A_{m}\|+1$, and ${\cal C}_2$ be the  circle  centered at the origin with radius
 $\ds \f{\lambda_N^2(m_1)+\lambda_{N+1}^2(m_1)}{2}$.
 
 \vspace{0.05in}
For $m$ near $m_1$ define  \cite{kato2013perturbation},
\bean \label{int for proj}
P_{m,1} = \f{1}{2\mathrm{i} \pi} \int_{{\cal C}_1} (zI -  A_{m}^* A_{m} )^{-1} \, dz -
 \f{1}{2\mathrm{i}\pi} \int_{{\cal C}_2} (zI -  A_{m}^* A_{m} )^{-1}  \, dz . 
\eean
Note that for $m$ near $m_1$,  $P_{m,1}$ is also an 
orthogonal projection 
on the sum of the eigenspaces
	of $A_{m}^*A_{m}$ corresponding to the eigenvalues 
	greater than $\ds \f{\lambda_N^2(m_1)+\lambda_{N+1}^2(m_1)}{2}$.
%can be written as the combination of contour integrals
	Formula  \eqref{int for proj} can be used to prove that
	$m \mapsto P_{m,1}$ is a  $C^1$ function in a  
	connected neighborhood $V_{m_1}$ of $m_1$. 
	Necessarily, $s_1=\dim R(P_{m,1})$ is constant in $V_{m_1}$ by 
	continuity of the trace.
	
	\vspace{0.05in}
	Next we show that after possibly shrinking $V_{m_1}$ 
	there is a linear bijection $\varphi_{m,1}: K^{s_1} \ri R(P_{m,1})$
	such that $m \mapsto \varphi_{m,1}$ is a $C^1$ function  in $V_{m_1}$.
	Indeed, let $v_{1,1}, ..., v_{1,s_1}$ be an orthonormal basis of $R(P_{m_1})$.
	The matrix $<P_{m_1,1} v_{1,i}, P_{m_1,1} v_{1,j}>_{1 \leq i,j \leq s_1}$ is the identity matrix since
	$P_{m_1,1} v_{1,i}=v_{1,i}$. By continuity,  
	$<P_{m,1} v_{1,i}, P_{m,1} v_{1,j}>_{1 \leq i,j \leq s_1}$
	is invertible for $m$ near $m_1$, proving that 
	$P_{m,1}v_{1,1}, ..., P_{m,1}v_{1,s_1}$
	is a basis of $ R(P_{m,1})$ since its dimension is also $s_1$.
	Next, we cover ${\cal B}$ by finitely many neighborhoods $V_{m_i}, i \in I$. 
	We may assume that $V_{m_i}, i \in I$, are closed balls with radius $\epsilon >0$,
	while $P_{m,i}v_{i,1}, ..., P_{m,i}v_{i,s_i}$
	is a basis of $ R(P_{m,i})$, if $m$ is in $W_{m_i } = \{ m:|m - m_i|\leq 2 \epsilon
	\} $. 
	Finally,  an explicit formula for $\varphi_{m,i}$ with $m$ in $W_{m_i}$
	can be given.
	%Let $v_{1,i}, ..., v_{s,i}$ be an orthonormal basis of $R(P_{m_i})$.
	For $|m-m_i|\leq 2 \epsilon$, we set
	\bea
	\varphi_{m,i}: K^{s_i}  \ri R(P_{m,i}), \\
	(a_1, ..., a_{s_i}) \mapsto   a_1 P_{m,i} v_{1,i}+  ... + a_{s_i}  P_{m,i}  v_{s_i,i}.
	\eea
	%Denote 
	%\bea
%	E_0 = \mbox{Span } \{ u: u \in R(P_{m'}), m' \in V_{m_i}, i \in I \}.
	%\eea
	

\begin{lem}\label{with phi der}
Consider the framework and assumptions in section~\ref{abs:framework}.
For $i$ in $I$, $m$ in $V_{m_i}$, and $q $ in $\RR^p$ with $|q|=1$,
the linear function 
%$(u,v) \ri \p_q(A_m P_m ) u + A_m v$
$(u,v) \mapsto \p_q(A_m \varphi_{m,i} ) u + \varphi_{m,i} v$
is injective on  $K^{s_i} \times K^{s_i}$.%$R(P_m) \times E$.
%$R(P_m) \times R(P_m)$.
\end{lem}
\textbf{Proof}:
%Fix $u$ in $E $. As $(I - P_m) P_m u =0$, we find that
%$$
%-\p_q P_m P_m u + (I- P_m) \p_q P_m u =0,
%$$
%thus for $v$ in $E$, $ <\p_q P_m P_m u , P_m v> =0$.
%It follows that for all $(u,v)$ in $R(P_m) \times R(P_m)$,
%$ <\p_q P_m  u , v> =0$.\\
Assume that $\p_q(A_m \varphi_{m,i} ) u + A_m \varphi_{m,i}  v =0$, for some 
$(u,v)$ in $K^{s_i} \times K^{s_i}$. % $R(P_m) \times E$.
Then
\bea
(\p_q A_m) \varphi_{m,i} u + A_m (\p_q \varphi_{m,i} u + \varphi_{m,i} v )  =0,
\eea
and using (U2), $\varphi_{m,i} u = 0$ and $\p_q \varphi_{m,i}  u + \varphi_{m,i} v   =0$.
As $\varphi_{m,i}$ is a bijection, this implies that $u=v=0$. 
%As $ u = P_m u$, it follows that 
 %$u=v=0$.
$\square$

\begin{prop}\label{proj case}
Assume that the projectors $P_{m_i}$,  with $i \in I$,  are defined as specified above 
in conjunction with the  framework and assumptions in section~\ref{abs:framework}. 
Then there is a positive constant $C$ such that 
for all $m,m'$ in ${\cal B}$,
% and $u,v $
%in $E$,
\bean \label{stability proj case}
\| A_m u - A_{m'}  v  \| \geq 
C(|m-m'| \| v\| + \| u -v\|),
\eean
for all $u$ and  $v$ linear combinations of eigenvectors of $A_m^*A_m$ and
$A_{m'}^*A_{m'}$  
where $m \in V_{m_i}$, $m' \in V_{m_j}$, $u \in R(P_{m,i})$,
$v \in R(P_{m,j})$.
\end{prop}
\textbf{Proof}:
Fix $i$ in $I$.
	By Proposition \ref{stable finite dim} and Lemma \ref{with phi der},
	using the bijections $\varphi_{m,i}$,
	there is a positive constant $C_i$ such that 
	for all $m, m'$ in $W_{m_i}$, $\tilde{u}, \tilde{v}$ in $K^{s_i}$,
	\bea%n \label{stability in Vmi}
\| A_m \varphi_{m,i} \tilde{u}- A_{m'} \varphi_{m',i} \tilde{v}  \| \geq 
C_i(|m-m'| \|\tilde{v}\| + \|  \tilde{u} - \tilde{v}\|).
\eea
Using that $\varphi_{m,i} $ is a linear  bijection from $K^{s_i}$
to $R(P_{m_i})$ such that its norm and the the norm of its inverse 
are bounded for $m$ in $W_{m_i}$, re-adjusting $C_i$ we may write
	\bean%n \label{stability in Vmi}
\| A_m P_{m,i} u- A_{m'} P_{m',i} v  \| \geq 
C_i(|m-m'| \|P_{m',i} v \| + \|  P_{m,i} u - P_{m',i} v \|),
\label{Wmi}
\eean
for all $m, m'$ in $V_{m_i}$, $u, v$ in $E$. 
%n
%where $C_i>0$ is a constant, $i$ is in $I$, $m, m'$ in 
%$V_{m_i}$, $u,v$ in $E$. 
It follows that
\bea%n \label{stability in Vmi}
\| A_m P_{m,i} u- A_{m'} P_{m',i} v  \| \geq 
C (|m-m'| \|P_{m',i} v \| + \| P_{m,i} u - P_{m',i} v\|),
\eea
for all $u,v$ in $E$, $i$ in $I$, and $m, m'$ in ${\cal B}$ such that $ |m - m_i| < \epsilon$,
$ |m' - m_i| < \epsilon$, with $C=\min_{i \in I }C_i$.
Next assume, that $m,m'$ are such that $|m-m'|< \epsilon$, $m \in V_{m_i}$,
$m' \in V_{m_j}$, and $i \neq j$.
Then %one of the two spaces 
$R(P_{m,i}) \subset R(P_{m,j})$
or $R(P_{m,j}) \subset R(P_{m,i})$. Assume
that $R(P_{m,i}) \subset R(P_{m,j})$.
Then by \eqref{Wmi},  as $m$ and $m'$ are in $W_{m_j}$,
\bea%n \label{stability in Vmi}
\| A_m P_{m,j} u- A_{m'} P_{m',j} v  \| \geq 
C(|m-m'| \|P_{m',j} v \| + \|  P_{m,j} u - P_{m',j} v \|).
\eea
But as $R(P_{m,i}) \subset R(P_{m,j})$, $P_{m,j} P_{m,i} = P_{m,i}$
thus we find that
\bea%n \label{stability in Vmi}
\| A_m P_{m,i} u- A_{m'} P_{m',j} v  \| \geq 
C(|m-m'| \|P_{m',j} v \| + \|  P_{m,i} u - P_{m',j} v \|).
\eea
The case $R(P_{m,j}) \subset R(P_{m,i})$ is handled similarly.\\
There now remains  to show that 
\bean
\inf
\f{\| A_m  P_{m,i}  u - A_{m'} P_{m',j}v \|}{|m-m'| \| P_{m',j}v\| + 
\|  P_{m,i} u -P_{m',v}v\|} >0, \label{big inf}
\eean
where the inf is taken over the set $i,j \in I$, $m \in V_i, m' \in V_j$,
such that $|m - m'|\geq \epsilon$ and $u, v$ in $E$ such that the denominator
$|m-m'| \| P_{m',j}v\| + 
\|  P_{m,i} u -P_{m',v}v\|$ is positive.
If $P_{m',j} v=0$ it suffices to show that 
\bean \label{suffices}
\inf_{  i \in I, u \in V_{m_i}, \|  P_{m,i} u\|>0}
\f{\| A_m  P_{m ,i} u\|}{ \|  P_{m,i} u \|} >0.
\eean
%This is clear due to our definition of $V_{m_i}$ and given that $I$ is finite.\\
By \eqref{int for proj}, $P_m$ is the orthogonal projection on the sum of eigenspaces
corresponding to the  eigenvalues of 
$A_m^*A_m$
greater than $\f{\lambda_N^2(m_i)+\lambda_{N+1}^2(m_i)}{2}$
so the inf in \eqref{suffices} is greater than \\
$\min_{i \in I} \left[\f{\lambda_N^2(m_i)+\lambda_{N+1}^2(m_i)}{2}\right]^{\f12}$.\\
%As $ \P_m$ is a projector, 
%\bea
%\f{P_m  u\|}{ \|  P_m u \|} = \P_m \f{P_m  u\|}{ \|  P_m u \|}.
%\eea
%Since each operator $P_m$ is compact and $m \ri P_m$ is continuous in the closed ball
%$V_{m_i}$ of $\RR^p$
%this is clear due to ... lemma required ...
Now, let $d$ be greater than the diameter of ${\cal B}$. As
 $|m-m'| \|P_{m',j} v\| + \| P_{m,i} u -P_{m',j}v\| \leq (d+1)\| P_{m',j}v\| 
 + \| P_{m,i}  u \| $, it suffices to show that
 \bea
\inf
\f{\| A_m P_{m,i} u - A_{m'}P_{m',j} v \|}{(d+1) \| P_{m',j}v\| + \|P_{m,i} u \|} > 0,
\eea 
where the inf is taken over the same set as in the inf in \eqref{big inf}.
Arguing by contradiction, assume that there are two sequences 
$i_n, j_n$ in $I$, 
$m_n, m_n'$ in $B$ with $m_n \in V_{i_n}, m_n' \in V_{j_n}$ such that $|m_n - m_n'|\geq \epsilon$, and two sequences
$u_n, v_n$ in $E$  such that 
$\|P_{m_n', j_n} v_n\|>0$ and
\bea
\lim_{n \ri \infty}
\f{\| A_{m_n} P_{m_n, i_n} u_n - A_{m_n'} P_{m_n', j_n} v_n \|}{(d+1)
 \| P_{m_n', j_n}v_n\| 
+ \| P_{m_n, i_n}u_n \|} = 0.
\eea 
Set $\omega_n = \f{ \| P_{m_n, i_n}u_n\| }{(d+1) 
\| P_{m_n', j_n} v_n\| + \|P_{m_n, i_n} u_n\|}$.
We have
\bea
\lim_{n \ri \infty} \omega_n  A_{m_n}  \f{ P_{m_n, i_n} u_n}{\| P_{m_n, i_n} u_n \|}
- (1- \omega_n) (d+1)^{-1}A_{m_n', j_n}\f{  P_{m_n', j_n}v_n}{\| P_{m_n', j_n}v_n \|}  =0.
\eea
By compactness after extracting subsequences
we can assume that  
$i_n \ri i, j_n \ri j$ in $I$, 
$\omega_n $ converges to $\omega$ in $[0,1]$,
$m_n$ converges to $m$ in $V_i$, and $m_n'$ converges to $m'$ in $V_j$. 
Necessarily  $|m - m'| \geq \epsilon$. Note that  
$\f{ P_{m_n, i } u_n}{\| P_{m_n ,i } u_n \|} =P_{m_n, i } \f{ P_{m_n, i} u_n}{\| P_{m_n, i} u_n \|}$.
%Note that $m$ is in  $V_{m_i}$, for some $i$ in $I$.
Since each operator $P_{m,i}$ is compact and $m \mapsto P_{m,i}$ is continuous in the closed ball
$V_{m_i}$ of $\RR^p$, after extracting a subsequence,
this converges strongly to some $\phi$ in $R(P_{m,i})$ with $\|\phi\|=1$. 
Similarly,  $\f{  P_{m_n'}v_n}{\| P_{m_n'}v_n \|} $ converges strongly to some
$\psi$ in $R(P_{m',j})$ with $\|\psi\|=1$.
At the limit we find
\bea
\omega  A_{m}  \phi
- (1- \omega) (d+1)^{-1}A_{m'} \psi  =0,
\eea
contradicting the assumption (P1) if $0<\omega<1$. 
If $\omega=0$ or $\omega =1$, this contradicts the assumption (U2).   
$\square$\\

In practice, we would like to state a regularity result  based on the first singular vectors of
$A_m$. We now define  more precisely what is meant by  first singular vectors.
Fix a positive integer $N$. For $m$ in ${\cal B}$, define a subspace $E_{m,N}$
of $E$, with $\dim E_{m,N} =N $,  such that 
\bea
 E_{m,N} 
\subset \mbox{Ker } (A_m^* A_m - \lambda_1^2(m) I ) ,\\
\mbox{or for some integer $r$, } \\
\sum_{j=1}^{r-1} \mbox{Ker } (A_m^* A_m - \lambda_j^2(m) I ) 
\subset E_{m,N} 
\subset 
\sum_{j=1}^{r} \mbox{Ker } (A_m^* A_m - \lambda_j^2(m) I ) .
\eea 


\begin{thm} \label{main theorem}
Consider the framework and assumption in Subection~\ref{abs:framework}. Fix a positive integer $N$. 
Then there is a positive constant $C$ such that for all
$m, m'$ in ${\cal B}$ and all $u \in E_{m,N}$ and $v \in E_{m',N} $,
\bean \label{stability EmN}
\| A_m u - A_{m'}  v  \| \geq 
C(|m-m'| \| v\| + \| u -v\|).
\eean
\end{thm}
\textbf{Proof}:
Constructing $V_{m_i}, i \in I$ as in the proof of 
Proposition \ref{proj case}, $s_i $, which denoted the dimension of 
$R(P_{m,i})$ satisfies $s_i \geq N$. It follows that 
$E_{m,N} \subset R(P_{m,i}) $, for all $i \in I$ and $m$ in $V_{m_i}$.
Since the sets $V_{m_i}$ cover ${\cal B}$, the result is proved. 
$\square$\\

\vspace{0.05in}
\textbf{Remark}: Although the finite-dimensional case was covered by
Proposition \ref{stable finite dim}, the statement from Theorem \ref{main theorem}
may  be more useful in practice. Indeed, if $E$ is finite-dimensional, given that our conditions \ref{U1}-\ref{U2}  imply that $A_m^* A_m$ is injective, it is also bijective. However, the norm of $(A_m^* A_m)^{-1}$ may be very large making this 
operator impractical to use on $E$. Using  the spaces $E_{m,N}$ amounts
to reducing  $A_m^* A_m$ to a subspace where this operator is well-conditioned. 
In the application showed in this paper, we actually obtain satisfactory results with $N=5$.

\subsection{Application to neural network approximations}
Suppose that the conditions for Proposition \ref{stable finite dim}
to hold are met. 
Then ${\cal A}$ defined by \eqref{calAdef} 
has an inverse on ${\cal A} ({\cal B} \times  E_c)$
 which is  Lipschitz continuous 
  where,
\bea
E_c =\{ u \in E:  \| u \|  \geq c \},
\eea
and $c$ is a positive constant.\\
%Another important implication of     Theorem \ref{main disc theorem}
%is that the function $\psi$
Thus it can be 
approximated by an NN.
Since ${\cal A}^{-1}$ is Lipschitz regular, the growth of the depth of this NN and of the number nodes  can be estimated given  accuracy requirements.
There are by now many papers in the NN literature
that provide upper bounds for the size of neural networks approximating
 Lipschitz functions. For example, we  refer to  
 \cite{yarotsky2017error, shen2021neural} for estimates valid if
the ReLU  function is used for activation and 
\cite{de2021approximation} if the hyperbolic tangent function ($\tanh$)  is used instead.      \\
Now suppose that the conditions for 
Theorem \ref{main theorem} to hold are met.
Consider ${\cal A}: {\cal B} \times E_{m,N,1} \ri F$ where
\bea
 E_{m,N,1} =\{ u \in E_{m,N}, \|A_m u \|  = 1\}.
\eea
The condition $\|A_m u \|  = 1$ guarantees 
that $u$ is bounded away from zero, uniformly in $m$
according to the proof of Proposition \ref{proj case}.
This condition is convenient to impose in practice in an inverse 
problem by normalizing the measurement  $\|A_m u \|  $.
%(\ref{cal A cont}, \ref{cal E 2stars}).
Here too, ${\cal A}$ defined by \eqref{calAdef}  
has a inverse on ${\cal A} (  E_{m, N,1})$
 which is  Lipschitz continuous.
%The difference here is that $E_0$ may be infinite dimensional.
%However, we can locally define a bijection $\beta_m$ between $E_m$ and $\RR^s$.
%Indeed, if we fix $m_0$ in $B$ and let $v_1, ..., v_s$ be an orthonormal basis
%of $R(P_{m_0})$ the matrix $(<v_i,v_j>)_{1 \leq i, \leq s}$ is the identity.
%Note that $<v_i,v_j>=<P_{m_0} v_i, v_j>$, thus by continuity
%the matrix  $(<P_m v_i,v_j>)_{1 \leq i, \leq s}$ is invertible for $m$
 %in a neighborhood of $m_0$. It follows that 
%$P_m v_1, ..., P_m v_s$ is a basis of $R(P_{m})$ since 
%by continuity $\dim R(P_{m}) = \dim R(P_{m_0})$ if $m$ and $m_0$ are in the same
%connected component of $B$. 
Consequently, in this case too, we can approximate 
${\cal A}^{-1}$ by a neural network with a control 
on the upper bounds for the size.\\
% of neural networks approximating
% Lipschitz functions.


%Theorem \ref{v0 disc theorem} 
%suggests what may happen if $v_0$ is not in $E_m$.
%Conceivably, if $\ca_{m_0} v_0$ can be approximated by some 
%$\ca_{m_0} u$ with $u$ in $E_m$, the neural network approximating $\psi$
%should still be able to produce an output reasonably close to 
%$m_0$
  %from the input $(\ca_{m_0} v_0 (P_{j}))_{1\leq j \leq M} \in \RR^{M}$,
	%and formula \eqref{main est disc} establishes the regular behavior of such an output.
	% instead, see pdf relating M1 to M@
	%In practice, 
	%if we assume again that 
%	$\|v_0 \| \leq A_2$ and$   \sum_{j=1}^{M_{k}} C'(j,k) | 
%\ca_{m_0}v_0 (P_{j,k})|^2 \geq A_1^2 $
%then the residual 
%$\ca_{m_0} (I - \cp_{m_0}) v_0$ is small, so the approximation of
%$v_0$ by $\cp_{m_0} v_0$ in $E_{m_0}$ must be good. 
%\newpage


%\section{Application to the inverse crack scattering problem for pressure waves}\label{direct and inverse crack problems}

\section{Discussion and  application to an inverse scattering problem}\label{Dirichlet screen}
Wave phenomena are ubiquitous.   Waves carry information about
the  environment in which they propagate. This information can be analyzed 
with
forward and inverse modeling. Forward modeling predicts wave behavior, while inverse modeling identifies underlying parameters of interest describing
the environment. Recently, NNs
 leveraging machine learning (ML) techniques
have played a pivotal role in improving physics-constrained parameter identification.
Ideally, one would want to prove and test the accuracy and robustness of such NNs.
Understandably, they depend on the regularity (in this paper, Lipschitz regularity) of the underlying
 inverse function. \\
The application to  inverse scattering covered in this section 
 is defined on an unbounded domain.
This requires the wave function to satisfy 
a radiation condition (RC)  at infinity.
The RC is crucial for modeling  wave propagation in unbounded domains.
Measurable quantities of interest (QOIs), such as scattered fields and far fields, 
constitute data for the inverse scattering problem.
Without an RC, bounded domain  PDEs and  associated inverse problems have
lately been  investigated using NN-based solutions.
Many references can be found in the survey article \cite{pinn_survey_2022}. 
Simply put,
the availability of automatic differentiation in open-source NN-optimized frameworks like PyTorch and TensorFlow has facilitated these recent studies.
These frameworks
  symbolically incorporate  the underlying 
 PDE in  NN loss functions by sampling  the PDE in the bounded domain.   The  survey article~\cite{pinn_survey_2022}  highlights the widespread adoption of Physics-Informed Neural Networks (PINNs) for such  forward and inverse bounded domain PDEs. Notably, the survey emphasizes (see the last line of its abstract) that fundamental theoretical challenges remain unresolved for PINN-based approaches to both forward and inverse problems, even within the context of bounded-domain PDEs. \\
Computational methods that preserve
 the RC without truncating the unbounded region of the PDE often rely on boundary integral
 representations \cite{colton1998inverse,nedelec2001acoustic}. 
In this approach, 
 an equivalent boundary integral equation (BIE) is formed \cite{colton1998inverse}.
Integral formulations present the advantage of seamlessly incorporating the RC
\cite{colton1998inverse,nedelec2001acoustic}.
 These BIEs were mainly developed for wave propagation problems with a constant refractive index~\cite{colton1998inverse}.   However, by employing domain decompositions   as in \cite{DoGa:2022, DoGaSa:2020},
heterogeneous media can be handled by astute combinations of finite element methods
and BIEs.\\
It is important to point out that
 NN based solutions to inverse scattering problems differ drastically  from non-ML approaches.
For instance, we refer to~\cite{colton1998inverse} 
 for the classical deterministic Tikhonov regularization approach to inverse scattering problem. This approach requires multiple solves
 of the forward model to set up the Fr\'echet derivative for Newton iterations. In contrast,  stochastic approximations for
 constructing posterior distribution of the vector parameter $m$ can be performed using a Bayesian framework. This framework is robust 
 but also necessitates solving
 forward models multiple times to establish the likelihood function:
see 
\cite{dielectric2} 
 which introduces an  online/offline Bayesian method for inverting  electromagnetic parameters from noisy far-field  data
 %Maxwell PDE 
and 
\cite{dielectric2, volkov2019stochastic, volkov2020stochastic, volkov2022parallel} 
about the half-space elasticity case.
Note that for  fast forward model evaluations within a Bayesian framework, an NN surrogate for 
 an exterior Helmholtz model was developed in~\cite{surr_bayes_2022}. \\

We now examine a specific   forward model governed by the Helmholtz equation in unbounded regions 
of $\mathbb{R}^{d}$, where $d=2,3$. We establish the well-posedness of these models. 
Next, we focus on the two-dimensional case and describe the parameter $m$
 used  to represent crack 
geometries.
  We prove that this parameterized model satisfies the two conditions \ref{U1}-\ref{U2}, 
ensuring Lipschitz regularity of the inverse function $A_m u \mapsto m$. 


\subsection{Helmholtz forward models in unbounded regions}
Let $\Gamma$ be a Lipschitz  open curve/surface in $\RR^{d}$,  Let
	$D$ be a  domain in $\RR^{d}$ with boundary $\p D$ is such that
	  $\Gamma \subset \p D$.
	The trace
	theorem (which is also valid in Lispchitz domains~\cite{ding1996proof}),
	allows us to define an inner and outer trace in $H^{\f12}(\p D)$ 
	of functions defined in $\RR^{d} \setminus \p D$ with local $H^1$ regularity.
%Let $\tilde{H}^{\f12} (\Gamma)$ be the space of functions
	%in $H^{\f12}(\p D)$ supported in $\ov{\Gamma}$.
	Let $k$ be in $L^\infty(\doubleR^{d})$  such that
\begin{enumerate}[label=(\subscript{H}{{\arabic*}})]
\item $k$ is real-valued;
\item there is a positive constant $k_{min}$ such that $k \geq k_{min}$
almost everywhere in $\doubleR^{d}$;
\item there exists positive constants  $R_0, k_0$ such that if $|x|\geq R_0$, and $x \in 
\doubleR^{d}\sm \ov{\Gamma}$,
$k(x) = k_0$.
\end{enumerate}

	
	
	
	
	
We impose on $\Gamma$ a Dirichlet condition.
Physically, this data could be  derived from 
an incoming incident wave while the problem is solved for a scattered wave. For that kind of problem, $\Gamma$ is often called a 
screen. One can find excellent references in the literature for the case where 
$k^2$ is constant in space~\cite{ hsiao1991dirichlet, stephan1985augmented, wendland1990hypersingular}. In particular, these references
include an analysis of singularities of the solution at the tip of the crack and the 
analysis of numerical methods for solving these problems using integral equations
on $\Gamma$. 
%With $d, k, \Gamma, n, {\cal V}, D$ as in section  \ref{direct and inverse crack problems},

\vspace{0.05in}
In this work, we consider the Dirichlet  crack forward scattering problem  to be the unbounded-region  boundary value problem (BVP) with Sommerfeld RC:
Find $u \in {\cal V}$  such that 
	\bean
        (\Delta + k^2 )u&=&0\text{ in }\doubleR^{d}\sm \ov{\Gamma},  \label{D1}     \\
        %\p_{x_3} u=0\text{ on  the surface } x_3=0,  \label{BVP2}     \\
    % \aaa \frac{\p u}{\p n} \right] = 0 \mbox{ across }\Gamma,   \label{BVP3}\\
      u 
			&=&g \mbox{ on }\Gamma,  \label{D2}\\
 \f{\p u}{\p r} - i k_0 u &=& O\left(|x|^{-(d+1)/2}\right), \quad \text{as} \quad r \ri \infty
    % u \in {\cal V} 
     \label{D3},
		%(\bx)=O ({\frac{1}{| \bx|}}) \text{ uniformly as } |\bx|\to \infty,     \label{Decay1}
\eean
where $g$ is the restriction to $\Gamma$ of a function in 
$H^{\f12} (\p D)$,
and ${\cal V}$ is a function space on which the BVP with the RC in \eqref{D3} is well posed and that 
the solution $u$ depends continuously on $g$.
Following \cite[Section 2.6]{nedelec2001acoustic} 
we define ${\cal V}$ defined, first for $d=2$, as 
\bea
%\mbox{if } d=3, \, {\cal V} = \{ v \in H^1_{loc}(\RR^{3}\setminus \ov{\Gamma}): \f{v}{\sqrt{1+|x|^{2}}}, 
%\f{\nabla v}{\sqrt{1+|x|^{2}}}, \f{\p v}{\p r} - i k_0 v \in L^2(\RR^{3}\setminus \ov{\Gamma})
%\}, \\
%\mbox{if }  d=2, \\
{\cal V} = \left\{ v \in H^1_{loc}(\RR^{3}\setminus \ov{\Gamma}): \f{v}{\sqrt{1+|x|}
\ln(2+|x|)}, 
\f{\nabla v}{\sqrt{1+|x|} \ln(2+|x|)}, \f{\p v}{\p r} - i k_0 v \in L^2(\RR^{2}\setminus \ov{\Gamma})
\right\}, \\
\eea
and then for $d=3$ as 
\bea
{\cal V} = \left\{ v \in H^1_{loc}(\RR^{3}\setminus \ov{\Gamma}): \f{v}{\sqrt{1+|x|^{2}}}, 
\f{\nabla v}{\sqrt{1+|x|^{2}}}, \f{\p v}{\p r} - i k_0 v \in L^2(\RR^{3}\setminus \ov{\Gamma}) \right\}.
\eea
In applications, $g$ is commonly set equal to minus the value of an incoming
incident field and  $u$ represents the scattered field for a problem while
the total field is zero on $\Gamma$.  

\begin{prop} \label{direct  dir prob}
The BVP (\ref{D1}-\ref{D3}) is uniquely solvable.
% for all wavenumbers
%$k>0$. 
The solution 
$u$ in ${\cal V}$  depends continuously on the forcing term
$g$ in $H^{\f12} (\Gamma)$.
\end{prop}
\textbf{Proof:}
We first show uniqueness. Assume that $g=0$.
Let $S_R$ be the sphere centered at the origin with radius $R$. 
Applying Green's theorem
we find that $\mbox{Im} \int_{S_R} u \f{\p \ov{u}}{\p r} = 0$. 
Next, since $u \in {\cal V}$, 
there is a sequence $R_n \ri \infty$ such that,
\bea
\lim_{n \ri \infty}\int_{S_{R_n}} \left|\f{\p u}{\p r} - i k_0 u\right|^2 = 0,
\eea 
so altogether we have that,
\bea
\lim_{n \ri \infty}\int_{S_{R_n}} \left|\f{\p u}{\p r}\right|^2 + | u|^2 = 0.
\eea 
Due to Rellich's lemma for far field patterns, it follows that $u (x) =0$, if $|x| >R_0$. 
Since the only regularity assumption on  $k$ is that it is in $L^\infty$ 
there is no elementary argument for showing that $u(x)$ is zero if $|x| \leq R_0$.
However, we can use results from the unique continuation literature,
in particular, the corollary of  Theorem 1 in \cite{barcelo1988weighted} 
to claim that $u$ is zero throughout $\RR^d\setminus \ov{\Gamma}$.\\
Next, we show existence. 
%We can extend $g$ to a function 
%$\psi$
%in $H^1(\RR^d)$
%supported strictly inside $B_{R'}$ defined  in the proof of \ref{direct  prob}.
%We can use a continuous extension operator, so that $\psi$ depends continuously 
%on $g$.
Fix $R' >R_0$. Let $B_{R'}$ the open ball centered at the origin of $\RR^d$
with radius $R'$.
We can extend $g$ to a function 
$\psi$
in $H^1(\RR^d)$
supported strictly inside $B_{R'}$. 
Using a continuous extension operator,  $\psi$ depends continuously 
on $g$.
We now seek to solve an equivalent problem for $\tilde{u} =u - \psi$.
Define the closed subspace %${\cal V}_0$ in ${\cal V}$
%and 
$H^1_{\Gamma, 0}(B_{R'}) $ of $H^1(B_{R'}) $,
%\bea
%{\cal V}_0 = \{ v \in {\cal V}: v=0 \mbox{ on } \Gamma \},
%\eea
\bea
H^1_{\Gamma, 0}(B_{R'}) = \{ w \in H^1(B_{R'}): v=0 \mbox{ on } \Gamma \}.
\eea
Note that this definition requires the trace of $v$ on $\Gamma$ to be zero
on each side.
%With ${\mathrm B}$ as in \eqref{B def} 
 Define the bilinear functional,
\bean \label{B def}
{\mathrm b}(v,w) = \int_{B_{R'}} \nabla v \cdot \nabla w -  k^2  v w  - \int_{S_{R'}} T_{R', k_0} v w,
\eean
for $ v, w \in H^1(B_{R'}) $ and where $T_{R',k_0}$ is the Dirichlet to Neumann map for radiating solutions to the Helmholtz equation in the exterior of $B_{R'}$
with wavenumber $k_0$. $T_{R',k_0}$ is known to be a  continuous
mapping from $H^{\f12 } (S_{R'})$ to $H^{-\f12 } (S_{R'})$, 
while $-T_{R',0}$ is strictly coercive, and $T_{R',k_0} - T_{R',0}$ is compact
from $H^{\f12 } (S_{R'})$ to $H^{-\f12 } (S_{R'})$, see 
\cite[Section 5.2]{colton1998inverse} or \cite[Section 2.6.5] {nedelec2001acoustic}. 
According to the uniqueness property covered above, we have that if
$v \in H^1(B_{R'})$ and
${\mathrm B}(v,w) =0 $ for all $w \in H^1(B_{R'})$, then $v=0$. \\ 
Now, consider the variational problem:
\bean \label{var pb dir}
\mbox{find } \tilde{u} \in H^1_{\Gamma, 0}(B_{R'}) \mbox{ such that } \forall w \in 
H^1_{\Gamma, 0}(B_{R'}), \no \\
{\mathrm b}(\tilde{u},w) = -{\mathrm b}(\psi,w).
\eean
This problem has at most 
one solution since ${\mathrm b}$ is non-degenerate. 
%
Existence follows by arguing that this problem is in the form strictly coercive plus compact,
which is the case thanks to the properties of the operator $T_{R',k_0}$ recalled above.
%a solution $\tilde{u}$ to this problem exists and depends continuously on 
%$g$.  
Finally, $u = \tilde{u} + \psi$ 
can be extended to $\RR^d \setminus \ov{\Gamma}$
as a function satisfying 
  (\ref{D1}-\ref{D3}).
%, is in 
%${\cal V}$, $u =  \psi$ on $\Gamma$ since 
%$\tilde{u} =  0$ on $\Gamma$.
$\square$ 
%integral operator representation and integral equation - tip singularity
% for a C^1,1 or piecewise C^1,1 \Gamma in the sense of MAzy a 

\vspace{0.1in}
If $k^2$ is constant in 
$\RR^d$
the solution $u$ to the BVP (\ref{D1}-\ref{D3}) can be written in integral
form. 
\bean \label{Dir int}
u(x) = \int_\Gamma \Phi(x,y) \left[ \f{\p u}{\p n} (y)\right] d \sigma(y),
\eean
with $\Phi $ the free space Green function for the Helmholtz equation
%\bean \label{Phi def}
%\Phi(x,y) = \f{i}{4} {\cal H}^1_0(k|x-y|),
%\eean
and  $\left[ \f{\p u}{\p n} \right] $,
the jump of $\f{\p u}{\p n} \ $ across $\Gamma$,
 is in $H^{-\f12}(\Gamma)$,
see \cite{stephan1984augmented}. 
%We can assume that $\aaa \f{\p u}{\p n} \right] $ has full support in
%$\Gamma$, otherwise $\Gamma$ can be shrunk. 
Referring to the BVP (\ref{D1}-\ref{D3}), suppose that
$\left[ \f{\p u}{\p n} \right] $ is zero on $\Gamma \cap B$, where $B$ 
is an open ball with center on $\Gamma$. Then $u$ is locally $H^1$
in $B$ and  satisfies $ (\Delta + k^2 )u=0$ in $B$. Then $B$ can be
taken out from $\Gamma$ without changing the solution $u$. 
We thus make the following minimal assumption on $\Gamma$: \\
\begin{enumerate}[label=(\subscript{J}{{\arabic*}})]
\item \label{J1}
$\ds \left[ \f{\p u}{\p n} \right] $ has full support in $\Gamma$,
\begin{center}
or equivalently,
\end{center}
  \item \label{J2} 
for any open ball $B$ centered on $\Gamma$, $u$ cannot be extended to 
	a function satisfying  $ (\Delta + k^2 )u=0$ in $B$.
	\end{enumerate}

\begin{thm}
\label{InverseProblemResultDir}
For $i=1,2$,
    let $\Gamma_i$   be a Lipschitz open surface, let 
 $u^i$ be the unique solution to the BVP  (\ref{D1}-\ref{D3}) with $\Gamma_i$ in place of $\Gamma$ and the Dirichlet condition $g^i$ in  $H^{1/2}(\Gamma_i)$ in place of $g$.  
%	Assume that for $i=1,2$,  
	%$g^i$ has full support in  $\ov{\Gamma_i}$. %, that is, 
	%$\mbox{supp } g_i = \ov{\Gamma_i}$.
	Let $R$ be greater or equal than $R_0$. 
	Let $S_R$ be a sphere. 
	Assume that  $\RR^{d} \setminus \ov{\Gamma_1 \cup \Gamma_2}$ is
	connected and that $g^i$ has full support in  $\ov{\Gamma_i}$, $i=1,2$. 
	If $u^1=u^2$ on $S_R$, then 
	$\ov{\Gamma_1}=\ov{\Gamma_2}$ and $g^1=g^2$ almost everywhere.	
\end{thm}
\textbf{Proof}: 
%A proof can be provided by a  slight modification
%of the proof of Theorem. Instead of considering jumps of $u^i$
 %across $\Gamma_i$ we just need two consider two-sided traces of $u^i$
 %across $\Gamma_i$. 
Set 
$U=\RR^{d} \setminus \ov{\Gamma_1 \cup \Gamma_2}$, $u= u^1 - u^2$ in $U$.  We can then argue as in the proof of Proposition 
\ref{direct  dir prob}
that $u$ is zero in $U$.
Next,  we argue by contradiction: suppose that there is an $x$ in $\Gamma_1$ such that 
$x \notin \ov{\Gamma_2}$. Then there is an open ball $B(x,r)$ centered at $x$
with radius $r>0$ such that $B(x,r) \cap \ov{\Gamma_2} = \emptyset$.
Now $\left[ \f{\p u}{\p n} \right]=0$ on $B(x,r) \cap \ov{\Gamma_1} $,
and as $(\Delta +k ^2)u^2 = 0$ in $B(x,r)$,
$\left[ \f{\p u^2}{\p n} \right]=0$ on $B(x,r) \cap \ov{\Gamma_1} $.
It follows that $\left[ \f{\p u^1}{\p n} \right]=0$ on $B(x,r) \cap \ov{\Gamma_1} $,
contradicting \ref{J1}. We conclude that 
$\Gamma_1 \subset \ov{\Gamma_2}$. Reversing the roles of $\Gamma_1$ and 
$\Gamma_2$ we then find that $\ov{\Gamma_1} =\ov{\Gamma_2}$. Using one more time
that $u$ is zero in $U$,
since $u=0$ on each side of  $\Gamma_1= \Gamma_2$, it follows that
$g_1- g_2 =0$ almost everywhere in $\Gamma_1$.
 $\square$

%\ref{InverseProblemResult}
\subsection{Crack inverse problem: 
verifying conditions \ref{U1}-\ref{U2}}\label{inv_crack_example}
%\subsection{The case of Dirichlet conditions on linear cracks in homogeneous space}
%\label{Phi def
We start from the solution $u$ to the BVP  (\ref{D1}-\ref{D3})  written in integral
form \eqref{Dir int} for the case $d=2$  with a concrete parametric description of a linear crack $\Gamma$.
For this case, the kernel in~\eqref{Dir int} is given by 
\bean \label{Phi def}
\Phi(x,y) = \f{i}{4} {\cal H}^1_0(k|x-y|).
\eean

The line supporting the linear crack $\Gamma$ can be parametrized
by choosing a unit vector direction $\tau$ and an offset scalar
parameter $a$ such that this line goes through the point
$a n \in \RR^2$, with  $n$ an outward unit vector normal  to $\Gamma$ at the point. 
 The solution $u$ to problem (\ref{D1}-\ref{D3}) can then be written in integral
form as
\bean
u(x) = \int_{-M}^{M} \Phi(x,y(t)) \left[ \f{\p u}{\p n} \right] (y(t)) dt, \label{bounded dir}\\
y(t) =\tau t +a n, \label{bounded2 dir}\\
\tau = (\cos \theta, \sin \theta), \quad
n=(- \sin \theta , \cos \theta),\label{bounded3 dir}
\eean 
where  $M$ is  such that the support of $\left[ \f{\p u}{\p n} \right] (y)$ is in 
$[-M, M]$ with $y=\tau t +a n$.


Accordingly, with vector parameter $m = (\theta,a)$, we define a concrete application based form of the parameterized
forward model operator $A_m$ discussed in the first three section of this article, using the framework in section~\ref{abs:framework} with 
$K =\CC$, $E= H^{-\f12 } ((-M,M))$,~$F= L^2(S_R)$, and 
\bean
{\cal B}= \{ (\theta, a ): \theta \in [-\pi/2,  \pi/2),
 -a_{\mbox{max}} \leq a \leq a_{\mbox{max}} \} \subset \RR^2, \label{Mrange}
\eean
where
\begin{enumerate}[label=(\subscript{B}{{\arabic*}})]
\item \label{B1} the constants
$R, M, a_{\mbox{max}}
$ are such that the distance from 
the line segment $t \tau  + a n $, $-M \leq t \leq M$,
to the circle $S_R$ is bounded by a positive constant.
\end{enumerate}
The interval $[-\pi/2, \pi/2)$ is compact for the circular metric
\bea
\delta (\theta, \theta') = \sqrt{(\cos 2\theta - \cos2  \theta')^2+
 (\sin2 \theta - \sin 2\theta')^2}.
\eea
In~\eqref{Mrange},  $\theta $ is restricted to $[-\pi/2, \pi/2)$ because 
the associated parametrized compact operator $A_m$, defined below,
is invariant as $(\theta, a ,t )$ is changed  to $(\theta + \pi, -a ,-t )$.
In particular, we are interested in the inversion of the operator 
$A_m: H^{-\f12 } ((-M,M)) \ri L^2(S_R)$, induced by the solution in~\eqref{bounded dir}:
\bean
%A_m: H^{-\f12 } ((-M,M)) \ri L^2(S_R),\label{Bmhere}\\
A_m \psi= u|_{S_R}, 
\mbox{ where } u(x) = \int_{-M}^{M} \Phi(x,y(t)) \psi(t) dt.\label{Bmhere2} 
\eean
It is clear due to formulation \eqref{bounded dir}
that $A_m$ is $C^1$ in $m=(\theta,a)$.

Thus if we prove that conditions \ref{U1}-\ref{U2} are satisfied by the concrete operator~\eqref{Bmhere2},
we can claim the Lipschitz regularity of the inverse of the operator. The rest of this section is on proving
these two assumptions to facilitate solving the inverse parameter model for the crack using NN approximations 
in the next section. 

First we prove the injective of the operator in $A_m$ in ~\eqref{Bmhere2}.
\begin{lem}{{\bf [Condition \ref{U1} holds]}}
 For all $\psi, \phi$ in $ H^{-\f12 }((-M,M))$, for all $m, m'$ in ${\cal B}$,
if $\psi \neq 0$,
$
A_m \psi = A_{m'} \phi$  implies $m=m'$ and
$\psi =  \phi$.
\end{lem}
\textbf{Proof:}
We set $u^1(x)=\int_{-M}^{M} \Phi(x,y) \psi (t) dt$,
$u^2(x)=\int_{-M}^{M} \Phi(x,y) \phi (t) dt$, with $y$ 
as in \eqref{bounded2 dir}.
Then by Theorem \ref{InverseProblemResultDir}, 
$m=m'$ and $u^1=u^2$ outside the line defined by \eqref{bounded2 dir}.
It follows that the jump of the normal derivative of $u^1$ across that line 
equals the jump of the normal derivative of $u^1$ so $\psi=\phi$.
$\square$\\

 As previously, $\p_{q} A_m$ denotes a partial derivative of $A_m$
with respect to the parameter $m$ in the direction of $q$.
\begin{prop} \label{Bm injective}
$\p_{q} A_m $ is injective on $H^{-\f12 }((-M,M))$ , for all $q $ in $\RR^2$ with $|q|=1$, and $m$ in $\cal B$, defined \eqref{Mrange}. 
\end{prop}
\textbf{Proof:}
Assume that $\p_{q} A_m \psi=0 $ for some 
$\psi$ in $H^{-\f12 }((-M,M))$, and $q=(q_1,q_2), |q|=1$.
Since $m=(\theta, a)$,  using~\eqref{bounded2 dir},  $\f{\p y}{\p \theta} = n t -a \tau$, 
 and $\f{\p y}{\p a} = n $.  According to the chain rule, 
for all $x$ in $S_R$, 
\bea
\p_{q} A_m \psi 
&=& q_1 \f{\p}{\p \theta  } A_m \psi + 
q_2 \f{\p}{\p a  } A_m \psi  \\
 &=&   q_1 \int_{-M}^{M}  \nabla_y \Phi(x,y) 
\cdot (nt - a \tau)  \psi(t)  dt
+ q_2 \int_{-M}^{M}  \nabla_y \Phi(x,y) 
\cdot n \psi(t)  dt  .
\eea
Define  $w(x)$   by the formula in the previous line  
 for all
$x$ in $\RR^2 \setminus \ov{\Gamma}$.
By construction, $w(x)=0$
for all $x$ on $S_R$, and $(\Delta + k^2)w=0$
in $\RR^2 \setminus \ov{\Gamma}$.
Since 
$\f{w}{\sqrt{1+r^2}\ln (2 + r)}, 
\f{\nabla w}{\sqrt{1+r^2} \ln (2 + r)},
 \f{\p w}{\p r} - i k w\in L^2(\RR^{2}\setminus \ov{\Gamma})$,
 it follows that $w$ is zero 
in $\RR^2 \setminus \ov{\Gamma}$.
The jump of $w$  across $\Gamma$ can be determined according to the rules
shown in \cite[Lemma 1]{volkov2021stability} or
\cite[Appendix C]{volkov2021stability}. According to these jump formulas 
we find that 
$(q_1 t  + q_2)\psi(t)  =0 $
inside the support of $\psi $.  
%for all $\varphi$ in $C^\infty_c(\RR)$,
%\bea
%< (q_1 t  + q_2) \left[ \f{\p u}{\p n} \right], \varphi > =0.
%\eea
%We infer  that 
%$(q_1 t  + q_2) \left[ \f{\p u}{\p n} \right]$=0.
As $|q|=1$, it follows that $g =0$.
%By \eqref{int dir}, $g$ is zero: contradiction.
 $\square$

\begin{prop} \label{BU2 cond}
{{\bf [Condition \ref{U2} holds]}} Let $\psi, \phi$ be in $H^{-\f12}((-M,M))$, and $q \in \RR^2$ be a unit vector. 
If 
$\p_{q} A_m \psi =A_m \phi $ then $\psi=\phi=0$.
\end{prop}
\textbf{Proof:}
Assume that $\p_{q} A_m \psi - A_m \phi=0 $ for some 
$\psi, \phi $ in $H^{-\f12 }((-M,M))$, and $q=(q_1,q_2)$,  $|q|=1$.
According to the chain rule, 
for all $x$ in $S_R$, 
\bea
&&\p_{q} A_m \psi -A_m \phi \\
&=& q_1 \f{\p}{\p \theta  } A_m \psi + 
q_2 \f{\p}{\p a  } A_m \psi -A_m \phi \\
 &=&   q_1 \int_{-M}^{M}  \nabla_y \Phi(x,y) 
\cdot (nt - a \tau)  \psi(t)  dt
+ q_2 \int_{-M}^{M}  \nabla_y \Phi(x,y) 
\cdot n \psi(t)  dt  
-  \int_{-M}^{M} \Phi(x,y) 
\phi(t)  dt .
\eea
Define  $w(x)$   by the formula in the previous line  
 for all
$x$ in $\RR^2 \setminus \ov{\Gamma}$.
Just as in the proof of Proposition  \ref{Bm injective}
we can argue that $w$ is zero 
in $\RR^2 \setminus \ov{\Gamma}$.
Now, the term $ \int_{-M}^{M} \Phi(x,y) 
\phi(t)  dt $ is known to be continuous  across $\Gamma$. 
Thus, just as in the proof of Proposition \ref{Bm injective} 
we find that 
$(q_1 t  + q_2)\psi(t)  =0 $
inside the support of $\psi $, so $\psi=0$.
At this stage, we just need to notice that since $\psi=0$, the jump 
of the normal derivative  of $w$ across $\Gamma$ is $\phi$, so $\phi=0$.
$\square$
\\\\
In summary,  we have shown that in the case of
a two-dimensional homogeneous scattering medium with 
 a  linear crack and Dirichlet conditions on that crack, all requirements for applying 
Proposition  \ref{proj case} are satisfied with
$E=H^{-\f12}((-M,M))$, $F=L^2(S_R)$,  %${\cal B}  = {\cal M}$,
and $A_m$ defined by \eqref{Bmhere2} if the crack is strictly included
in the ball with radius $R$ as expressed by condition \ref{B1}. 

\vspace{0.1in}
Next, as we  seek to apply Theorem \ref{main theorem},
the finite number $N$ 
of distinct singular values to be used to construct the projectors $P_m$ can be arbitrary,
but as $N$ grows large the constant $C $ in 
 \eqref{stability EmN} tends to zero. 
In fact, $C=O(\tau^{-N})$ for some $\tau$ in $(0,1)$. 
This is due to the fact that $\Phi(x,y)$ is analytic in $y$ if
$y$ is in some open neighborhood of all possible line
segments   $t \tau  + a n $ such that condition \ref{B1} holds.
 The exponential 
decay   $C=O(\tau^{-N})$ was proved in
 \cite{birman1977estimates, volkov2024optimal}.
%This can be seen by setting $v=0$
%in \eqref{stability EmN} and recalling that $B_m$ is compact.
%In fact it is known that $C = O(\tau^N)$ for some $\tau$ in $(0,1)$:
%this is due to the fact that $\Phi(x,y)$ is analytic in $y$ if $|y| \leq M$
%and $|x|=R$, \cite{volkov2024optimal, birman1977estimates}.




\section{Numerical simulations}\label{num section}
%codes are on my desktop
% C:\COMPUTATIONS\simulations\new parametrization
% code for producing data fro learning:
% produce_singular_fun_data.m
%it was run on math2022.wpi.edu
%3 data files were produced , each about 1.2 GB
%big_batch_minus_over_svd
%big_batch_plus_over_svd
%big_batch_svd
%they correspond to theta in (-\pi/2,0), (0,pi/2), (-pi/2, pi/2 )
%respectively
% in each case, learning done
% with  learn_partialSVD.m

% 3 trained nets
%name='theta_only_ltwothirdspenaltySVD';
 %load(name,"trainedNet")
%net_theta=trainedNet;
%load('theta_minus_a_only_ltwothirdspenaltySVD',"trainedNet")
%net_minus=trainedNet;
%load('theta_plus_a_only_ltwothirdspenaltySVD',"trainedNet")
%net_plus=trainedNet;
% testing and plotting:
% plane_wave_or_source.m
In this section, we conduct simulations in relation to the    inverse problem 
studied in
 section~\ref{inv_crack_example}.
The goal is to recover the  parameter $m$ in ${\cal B}$ 
from the data $A_m \psi$ defined in \eqref{Bmhere2} using an NN.
The simulations comprise three stages. 
First, data for training the NN is built up and stored. 
 Second, the NN is trained on that data.
Third, the accuracy and the computational speed of the NN is tested
on entirely new data produced by incoming waves, point sources, or
arbitrary forcing terms altogether.


\subsection{Specific values of parameters and bounds}
For the  the range in the parameter set  ${\cal B}$  defined in,  \eqref{Mrange}  we fix 
$a_{\mbox{max}} =1$. In our simulations, the constant wavenumber
$k$ is 1.5 and $R$, the radius of $S_R$,  is 4.
Next we set bounds for the support of $\psi$
for condition \ref{B1} to hold. Recalling the $y$ dependency on
$t$ \eqref{bounded2 dir},  we require   the support of $\psi$
with regard to $t$ in 
\eqref{Bmhere2} to be such that $t$ is in the interval with center
$o$ in [-1,1] and length $l$ in $[1, 3]$.  With these numbers the distance 
from the support of $\psi$ to $S_R$ is bounded below by $\sim 1.3$. 
%We next show numerical evidence that the inverse function $A_m \psi \ri m$
%can be approximated by a neural network as ascertained by Theorem 
%\ref{main theorem}.
%\\

\subsection{Discrete approximation of $A_m $ and learning data setup} 
Recall that 
$
A_m \psi =  \int_{-M}^{M} \Phi(x,y) \psi (t) dt$
where $x$ is in $S_R$ and $t$ is such that $y$ is in the support of 
$\psi$. As $x$ remains bounded from $y$, $\Phi(x,y)$ is smooth.
We  then approximate the smooth function 
 $A_m \psi $ on $S_R$, 
by the vector in $\CC^{N_S}$ $A_m \psi (x_i)$,  with $x_i = \left(R \cos (j \f{2 \pi }{N_S}), 
R\sin (i \f{2 \pi }{N_S})\right)$, $i=1, ..., N_S $.
 There are   the scattered field   observation points. In our numerical solutions, we used the value $N_S =40$.

\vspace{0.05in}
The integral $ \int_{-M}^{M} \Phi(x,y) \psi (t) dt$
equals $ \int_{M_1}^{M_2} \Phi(x,y) \psi (t) dt$
where $M_1 = o - l/2$, $M_2 = o + l/2$ given the support of $\psi$.
We then set $t=\f{M_2-M_1}{2} s +\f{M_2+M_1}{ 2}$, $ -1 \leq s \leq 1$ to 
obtain the integral $ \int_{-1}^{1} \Phi(x,y) \psi (t) \f{M_2-M_1}{2} ds$.
The well-known singularity of $\psi$ at each endpoint 
of its  support~\cite{stephan1984augmented}
allows us to write
$\psi (t) = \tilde{\psi}(s)/\sqrt{1 -s^2}$,
where $\tilde{\psi}$ is smooth.
This motivates the change of variables $s= \sin v$. 
The integral is then approximated 
 by a finite sum
using $N_\Gamma= 10 $ quadrature points for $v$ forming
a uniform grid of $[- \pi/2, \pi/2]$.
%These values followed the distribution $t=\sin v_j $, 
%$j=1, ..., N_\Gamma$, where the $v_j$ values are evenly spaced in $[-\pi/2,\pi/2]$.
%This distribution, with the trapezoidal quadrature rule for the finite sum,  improves numerical accuracy. 
We denote the associated values for $y$, $y(v_j)$,  
$v_j = -\f{\pi}{2} + (j-1)\f{\pi}{N_\Gamma -1}$
$j=1, ..., N_\Gamma$. 
Note that $y(v_j)$ depends on $o, l$, and $m$.
\vspace{0.05in}
Altogether, $A_m$ is approximated  by a $ N_S \times  N_\Gamma$
complex matrix 
$A_{m,app}$ with entries
\bea
\tau_j \Phi (x_i, y(v_j)) ) \f{M_2-M_1}{2} \f{\pi}{N_\Gamma -1} , \, 
i=1, ..., N_S, \,  j=1, ..., N_\Gamma.
\eea
Here the weights 
$\tau_1=\tau_{N_\Gamma}=\f12$ and $\tau_j=1, \mbox{ for } 1 < j < N_\Gamma$,
come from the trapezoidal rule, and
%Note that the length element on $\Gamma$ is a constant, as well as the stepsize between
%quadrature points: by linearity they can be ignored since we are only interested
%in computing singular vectors of $A_{m,app}$ .
the constant term $\f{M_2-M_1}{2} \f{\pi}{N_\Gamma -1}$
has been omitted since we are only interested in computing singular vectors.
The bridge between application of Theorem~\ref{main theorem}
to $A_{m,app}$ instead of $A_m$ is
covered in \cite[Theorem 4.2]{volkov2024stability}, which
asserts that estimate \eqref{stability EmN}
applies to $A_{m,app}$  as well with $C/2$ in place of $C$, 
as long as the dimension $N_S$ is sufficiently large enough.
In fact, this theorem implies that any numerical method based on convergent quadratures
could be used for approximating  $A_{m,app}$ from $A_m$.

\vspace{0.05in}
The steps to produce learning data are then:
\begin{enumerate}
\item A random geometry is picked for $\Gamma$. This is done 
by picking random values for $a, \theta$ using uniform probability distributions
within their range.
\item A random support is chosen for $\psi$. This is done 
by picking random values for $o, l$ using uniform probability distributions
within their range.
\item For these choices, the matrix $A_{m,app}$ is set up as described above
using~\eqref{Phi def}, the  fundamental solution of the Helmholtz equation.
\item The first $N=5 $ singular values of $A_{m,app}$ are computed
together with corresponding singular vectors $v_1, ... , v_5$.
in $\CC^{N_S}$.
\item A random vector $r_1, ..., r_5$ is picked in the ball of $\CC^5$ 
centered at the origin and with radius 1.
\item Let $w= r_1 v_1 + ... + r_5 v_5$.
The input for learning is  the normalized vector
$w / \| w \|$ 
 and the target is
$(a,\theta)$.
\end{enumerate}
The set of learning data in our NN simulations comprised $10^6$ input-target pairs.

\subsection{Neural network training step}
% matlab, Adam, parallel processors, 12 hours
% three networks to combat periodicity
We trained a neural network ${\cal N}$ on this data set.
${\cal N}$ was composed of 
an entry layer with  width 80, three hidden layers with width 80,
 and one exit layer with  width 2. 
The activation function connecting these layers was chosen to be
the hyperbolic tangent function.
This architecture, albeit heavy, proved to be adequate for the size 
of our problem:  the inputs are in $\RR^{80}$, the targets in $\RR^2$.
The inputs actually depend on $w $ in $ \CC^5\sim \RR^{10}$,
$(a, \theta)$ in $\RR^2$, and $(o, l)$ in $\RR^2$.

%We used a two-step training scheme; in the first step
%we  used an $L^2$ regularized penalty function, 
%which was improved  
%by applying an $L^{\f23}$ regularized penalty function in the second step.
The training was performed using the ADAM algorithm 
\cite{kingma2014adam}.
We found that this stochastic minimization algorithm
is particularly efficient given 
the size of our problem: 
this algorithm made it possible to 
compute gradients of the penalty function 
on randomized mini-batches.  

Recall that the equation (\ref{Bmhere2})
is invariant as $(\theta, a ,t )$ is changed 
to $(\theta + \pi, -a ,-t )$.
To ensure uniqueness,
 $\theta $
was restricted to $[-\pi/2, \pi/2)$ in~(\ref{Mrange}).  However, numerically, there is little difference
between the data for $\theta= -\pi/2, a, \psi(t)$ and
$\theta= \pi/2 - \epsilon, -a, \psi(-t)$ if $\epsilon >0 $ is small. 
In practice,
we circumvented this difficulty, 
by computing three neural networks: 
${\cal N}_1$ for which $-\pi/2 \leq \theta < \pi/2$,
${\cal N}_2$ for which $-\pi/2 \leq \theta <0$, 
and ${\cal N}_3$ for which $0 \leq \theta < \pi/2$.
${\cal N}_1$  only learns $\theta$. If $\theta $ is determined to be negative
by applying ${\cal N}_1$, then ${\cal N}_2$ is used, otherwise 
${\cal N}_3$ is used.
This quasi-periodicity issue could instead be resolved
by altering the penalty function, at the cost of 
slowing down the learning process.



\subsection{Testing the learned neural network}
We considered four cases:
\begin{enumerate}[label=\subscript{Case \, }{{\arabic*}}]
\item The Dirichlet data $g$ in  \eqref{D2} is the incoming plane 
wave $e^{ i k x \cdot \eta}$, where $\eta$ is a unit vector in $\RR^2$.
\item The Dirichlet data $g$ in  \eqref{D2} is source point wave
$\f{i}{4} {\cal H}^1_0(k|x-s|)$ where $s$ in $\RR^2$ is such that 
$3 \leq |s| \leq 3.5 $. Accordingly the source is between the screen
and $S_R$.
\item The Dirichlet data $g$ in  \eqref{D2} is source point wave
$\f{i}{4} {\cal H}^1_0(k|x-s|)$ where $s$ in $\RR^2$ is such that 
$5 \leq |s| \leq 7 $. Accordingly the source is outside $S_R$.
\item  This last case does not use Dirichlet problem  (\ref{D1}-\ref{D3}).
Instead, the data $A_m \psi = u|_{S_R} $  is directly formed from 
a given forcing term.
\end{enumerate}


%Given $g$ in $H^{\f12} (\Gamma)$, we  find \\
%\bf{independently of the case number}
Two examples 
of configurations for the fault $\Gamma$ relative to the 
circle $S_R$ are plotted in Figure \ref{fields}. 
The left plot corresponds to case 1. % with $\eta = (1, 0)$. 
This is not a plot of the scattered field $u$ solution to 
(\ref{D1}-\ref{D3}). Instead, we plotted the real part of the total field
$u + e^{ i k x \cdot \eta}$ which is more easily physically interpreted.
The right plot corresponds to case 3. The scale is different for visualization purposes as
the total field quickly decays from the source in case 3.


\begin{figure}[H]
    \centering
      \includegraphics[scale=.5]{plane_wave_sketch.pdf}
      \includegraphics[scale=.5]{source_wave_sketch.pdf}			
			       \caption{Examples 
of configurations for the fault $\Gamma$ relative to the 
circle $S_R$ in Figure \ref{fields}. The real part of the total field is sketched.
In each case, the crack $\Gamma$ is the black line segment.
The circle $S_R$ is the dotted circle. 
The left plot corresponds to case 1  with incidence angle $\eta = (1, 0)$. 
The right plot corresponds to case 3 with source $s=(6,0)$. The scale is different in order 
to facilitate visualization  as
the total field quickly decays from the source. }
    \label{fields}
\end{figure}


In Figure \ref{error_plots} we plot absolute errors for computing 
$\sin \theta$ and
$a$ using networks ${\cal N}_1,  {\cal N}_2, {\cal N}_3$.
The errors are shown for 1000 randomly generated examples.
In each example, a random geometry is picked for $\Gamma$
%. This is done 
by sampling random values for $a, \theta$ 
%using uniform probability distributions 
and a random support is chosen for $\psi$
by sampling random values for $o, \ell$
(with uniform distributions for $a, \theta, o, \ell$ 
within their range).
We then  randomly switch to case 1, 2, 3, or 4
 (with probability 0.25 for each case). 
In case 1, the incidence angle for $\eta$ is randomly chosen 
(with a uniform distribution in $[0, 2 \pi]$).
In case 2 or 3, the source is randomly chosen, with uniform distribution 
within its range.
In case 4, we pick $\psi(t) = y_1(t) -  \mathrm{i} \cos y_2(t)$ where
again $y$ depends on $t$ through equation \eqref{bounded2 dir}.
%vec=x_segment(1,:)-1i*cos(x_segment(2,:));
% run time?
We then apply the neural networks ${\cal N}_1$, then ${\cal N}_2$ 
or ${\cal N}_3$ 
to 
these 1000 cases.
Collective run time for these 1000 cases is  
0.06 seconds. 
Absolute errors for $\sin \theta$ and $a$ are shown
in Figure \ref{error_plots} in blue. The average error for these 1000 
cases is  about  0.02 for $\sin \theta$ and 0.03 for $a$. 

\subsection{Numerical stability to noise}
To simulate the effect of noise, a random perturbation was added
to the data for these 1000 trials. 
%noi=rand(size(g));
%noi=noi-.5;
%amp=norm(g,'inf');
%noi=noi*amp*.4;
%g2=g+noi;
For each trial and each coordinate
of the data vector in $\RR^{2 N_S}$,
we drew a random number in $[-0.2, 0.2]$
which we then multiplied by 
the overall sup norm of the data and used the result 
as additive noise.
We show in Figure \ref{data_example}
an example of data 
 $A_m \psi(R \cos (j \f{2 \pi }{N_S}), 
R\sin (j \f{2 \pi }{N_S}))$, $j=1, ..., N_S $,
for a particular trial.  We plotted the real part 
and the imaginary part of the noise-free data. Noisy data 
is superimposed. 
In Figure \ref{error_plots}, in red, 
we show absolute errors on $\sin \theta$ and $a$ 
evaluated applying ${\cal N}_1,  {\cal N}_2, {\cal N}_3$ to the noisy data. 
 The average error for these 1000 
trials is  about  0.08 for $\sin \theta$ and 0.09 for $a$. 




\begin{figure}[H]
    \centering
      \includegraphics[scale=.5]{sin_theta_error.pdf}
      \includegraphics[scale=.5]{a_error.pdf}			
			       \caption{Sorted absolute value errors 
						in evaluating $\sin \theta$ (left) and $a$ (right)
						for 1000 random trials of $\theta, a$
						support of the forcing term $g$
						and random choice of case 1, 2, 3, or 4.
						The horizontal solid lines indicate average error for the 1000 trials.
Blue: noise-free data. Red: noisy data. }
    \label{error_plots}
\end{figure}

\begin{figure}[H]
    \centering
      \includegraphics[scale=.7]{data_example.pdf}
			       \caption{Example of data in $\CC^{N_S}$.
						Real and imaginary parts of $A_m \psi$ 
						at $(R \cos (j \f{2 \pi }{N_S}), 
R\sin (j \f{2 \pi }{N_S}))$, $j=1, ..., N_S $ are plotted
with $j \f{2 \pi }{N_S}$ on the horizontal axis. 
The smooth curves correspond to noise-free data. 
The jagged curves correspond to noisy data.
}
    \label{data_example}
\end{figure}

%\bibliography{ref}{}
%\bibliographystyle{apalike}

\bibliographystyle{abbrv}
\begin{thebibliography}{10}

\bibitem{barcelo1988weighted}
B.~Barcelo, C.~E. Kenig, A.~Ruiz, and C.~Sogge.
\newblock Weighted {S}obolev inequalities and unique continuation for the
  laplacian plus lower order terms.
\newblock {\em Illinois Journal of Mathematics}, 32(2):230--245, 1988.

\bibitem{birman1977estimates}
M.~S. Birman and M.~Z. Solomyak.
\newblock Estimates of singular numbers of integral operators.
\newblock {\em Russian Mathematical Surveys}, 32(1):15, 1977.

\bibitem{colton1998inverse}
D.~L. Colton, R.~Kress, and R.~Kress.
\newblock {\em Inverse acoustic and electromagnetic scattering theory},
  volume~93.
\newblock Springer, 2013.

\bibitem{pinn_survey_2022}
S.~Cuomo, V.~D. Cola, F.~Giampaolo, G.~Rozza, M.~Raissi, and F.~Piccialli.
\newblock Scientific machine learning through physicsâinformed neural
  networks: {W}here we are and whatâs next.
\newblock {\em J. Scientific Computing}, 92:88 (62 pages), 2022.

\bibitem{de2021approximation}
T.~De~Ryck, S.~Lanthaler, and S.~Mishra.
\newblock On the approximation of functions by tanh neural networks.
\newblock {\em Neural Networks}, 143:732--750, 2021.

\bibitem{ding1996proof}
Z.~Ding.
\newblock A proof of the trace theorem of {S}obolev spaces on {L}ipschitz
  domains.
\newblock {\em Proceedings of the American Mathematical Society},
  124(2):591--600, 1996.

\bibitem{DoGa:2022}
V.~Dom{\'i}nguez and M.~Ganesh.
\newblock Analysis and application of an overlapped {FEM}-{BEM} for wave
  propagation in unbounded and heterogeneous media.
\newblock {\em Appl. Numer. Math.}, 171:76--105, 2022.

\bibitem{DoGaSa:2020}
V.~Dom{\'i}nguez, M.~Ganesh, and F.~J. Sayas.
\newblock An overlapping decomposition framework for wave propagation in
  heterogeneous and unbounded media: formulation, analysis, algorithm, and
  simulation.
\newblock {\em J. Comput. Phys.}, 403:109052, 20, 2020.

\bibitem{surr_bayes_2022}
M.~Ganesh, S.~C. Hawkins, N.~Kordzakhia, and S.~Unicomb.
\newblock An efficient {B}ayesian neural network surrogate algorithm for shape
  detection.
\newblock {\em ANZIAM J.}, 62:C112--C127, 2022.

\bibitem{dielectric2}
M.~Ganesh, S.~C. Hawkins, and D.~Volkov.
\newblock An efficient algorithm for a class of stochastic forward and inverse
  {Maxwell} models in {$\mathbb{R}^3$}.
\newblock {\em J. Comput. Phys.}, 398:10881, 2019.

\bibitem{hsiao1991dirichlet}
G.~C. Hsiao, E.~P. Stephan, and W.~L. Wendland.
\newblock On the {D}irichlet problem in elasticity for a domain exterior to an
  arc.
\newblock {\em Journal of computational and applied mathematics}, 34(1):1--19,
  1991.

\bibitem{kato2013perturbation}
T.~Kato.
\newblock {\em Perturbation theory for linear operators}, volume 132.
\newblock Springer Science \& Business Media, 2013.

\bibitem{kingma2014adam}
D.~P. Kingma.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{nedelec2001acoustic}
J.-C. N{\'e}d{\'e}lec.
\newblock {\em Acoustic and electromagnetic equations: integral representations
  for harmonic problems}, volume 144.
\newblock Springer, 2001.

\bibitem{shen2021neural}
Z.~Shen, H.~Yang, and S.~Zhang.
\newblock Neural network approximation: Three hidden layers are enough.
\newblock {\em Neural Networks}, 141:160--173, 2021.

\bibitem{stephan1985augmented}
E.~Stephan and W.~L. Wendland.
\newblock An augmented {G}alerkin procedure for the boundary integral method
  applied to mixed boundary value problems.
\newblock {\em Applied Numerical Mathematics}, 1(2):121--143, 1985.

\bibitem{stephan1984augmented}
E.~P. Stephan and W.~L. Wendland.
\newblock An augmented galerkin procedure for the boundary integral method
  applied to two-dimensional screen and crack problems.
\newblock {\em Applicable Analysis}, 18(3):183--219, 1984.

\bibitem{volkov2022parallel}
D.~Volkov.
\newblock A parallel sampling algorithm for some nonlinear inverse problems.
\newblock {\em IMA Journal of Applied Mathematics}, 87(2):187--206, 2022.

\bibitem{volkov2020stochastic}
D.~Volkov.
\newblock A stochastic algorithm for fault inverse problems in elastic half
  space with proof of convergence.
\newblock {\em Journal of Computational Mathematics}, 40(6):957--978, 2022.

\bibitem{volkov2024optimal}
D.~Volkov.
\newblock Optimal decay rates in {S}obolev norms for singular values of
  integral operators.
\newblock {\em Journal of Mathematical Analysis and Applications},
  537(2):128403, 2024.

\bibitem{volkov2024stability}
D.~Volkov.
\newblock Stability properties for a class of inverse problems.
\newblock {\em Journal of Inverse and Ill-posed Problems}, 32(3):333--350,
  2024.

\bibitem{volkov2021stability}
D.~Volkov and Y.~Jiang.
\newblock Stability properties of a crack inverse problem in half space.
\newblock {\em Mathematical methods in the applied sciences},
  44(14):11498--11513, 2021.

\bibitem{volkov2019stochastic}
D.~Volkov and J.~C. Sandiumenge.
\newblock A stochastic approach to reconstruction of faults in elastic half
  space.
\newblock {\em Inverse Problems \& Imaging}, 13(3):479--511, 2019.

\bibitem{wendland1990hypersingular}
W.~Wendland and E.~Stephan.
\newblock A hypersingular boundary integral method for two-dimensional screen
  and crack problems.
\newblock {\em Archive for Rational Mechanics and Analysis}, 112:363--390,
  1990.

\bibitem{yarotsky2017error}
D.~Yarotsky.
\newblock Error bounds for approximations with deep {ReLU} networks.
\newblock {\em Neural Networks}, 94:103--114, 2017.

\end{thebibliography}

\end{document}
