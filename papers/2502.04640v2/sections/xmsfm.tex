%!TEX root = ../main.tex
\input{sections/fig-pipeline.tex}

\vspace{-3mm}
\section{Structure from Motion with XM}
\label{sec:xm-sfm}

In this section, we present our SfM pipeline with \nameshort as the optimization engine, illsutrated in Fig.~\ref{fig:pipeline}. 


{\bf View graph}.
To construct view graph for an image set, we first run \colmap's \textit{feature extractor} and \textit{exhaustive matcher} to extract 2D correspondences. The {feature extractor} employs SIFT \cite{lowe1999sift} for feature detection and description, while the {exhaustive matcher} matches every image pairs. After matching, we apply \glomap's \textit{track establishment} to produce a four-column file where the first two columns represent feature point coordinates, the third indicates the image index, and the fourth corresponds to the 3D landmark indices. For now, we use the original implementation from \colmap and \glomap. However, we remark that it is possible to speedup the processes further using C++ and GPU implementation. We leave that as a future step.

% In the final release, this process will be re-implemented in our custom C++ code to enhance integration and performance.


{\bf Depth estimation}.
We use the depth estimation model \textsc{Unidepth}~\cite{piccinelli2024unidepth} to calculate the metric depth of a given image, and lift the view graph from 2D to 3D. If given the confidence map, we also use it to update the weight of different observations. We also tried other depth prediction models and compare their performance in \prettyref{app:depthcomparison}.

{\bf Filter from two-view estimation}.
Using 2D observations, we estimate the relative pose between two images. Based on this pose, we filter out 3D landmarks with large Euclidean distance errors. Specifically, landmarks with distance errors exceeding three times the median are removed.

{\bf \nameshort solver}.
We then use the lifted 3D measurements and the view-graph to form a $Q$ matrix as shown in \prettyref{eq:problem_scale_rotation_only}. We solve the \sdp~problem in \prettyref{eq:problem-sdp} using our \nameshort solver. If needed, we also delete the 10\% measurements with largest residuals and re-run the \nameshort solver. This corresponds to a greedy heuristic for outlier removal~\cite{antonante2021outlier} and we call it \xmdouble (runing twice).

{\bf \ceres refinement}.
Usually the depth predictions are quite noisy, leading to inaccurate estimations of \nameshort. We therefore also feed the estimated poses and landmarks to \ceres as a warmstart to solve the original bundle adjustment problem~\eqref{eq:ba-colmap}. As we will show, the solution of \nameshort always provide a strong warmstart for \ceres to quickly optimize~\eqref{eq:ba-colmap}.

