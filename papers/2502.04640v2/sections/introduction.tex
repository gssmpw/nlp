%!TEX root = ../main.tex

\section{Introduction}
\label{sec:introduction}

At the heart of modern structure from motion (SfM) and simultaneous localization and mapping (SLAM) sits \emph{bundle adjustment} (BA), the procedure of reconstructing camera poses and 3D landmarks from 2D image keypoints.

\textbf{Classical BA formulation}. Consider a so-called \emph{view graph} illustrated in Fig.~\ref{fig:3d-view-graph} with two types of nodes: 3D points $p_k \in \Real{3}, k=1,\dots,M$ and camera poses $(R_i, t_i) \in \SEthree,i=1,\dots,N$. The set of edges $\calE$ contains visibility information. An edge $(i,k) \in \calE$ indicates the $k$-th 3D point is visible to the $i$-th camera, and a 2D keypoint measurement $u_{ik} \in \Real{2}$ has been obtained regarding the projection of the point onto the camera frame.\footnote{
    We consider BA with calibrated cameras, i.e., $u_{ik}$ has been normalized by camera intrinsics.
} 
The bundle adjustment problem consists of estimating points and poses (i.e., $p_k$'s and $(R_i, t_i)$'s on the nodes) using the 2D keypoint measurements (i.e., $u_{ik}$'s on the edges). This is often formulated as an optimization problem:
\bea\label{eq:ba-colmap}
\min_{\substack{p_k \in \Real{3}, k=1,\dots,M \\ (R_i, t_i) \in \SEthree, i=1,\dots,N } } \sum_{(i,k)\in \calE} \left\| u_{ik} - \pi(R_i p_k + t_i) \right\|^2,
\eea
where $R_i p_k + t_i$ transforms the point $p_k$ to the $i$-th camera frame, $\pi(v):= [v_1 ; v_2]/v_3$ divides the first two coordinates by the depth and projects the 3D point to 2D, and the sum of squared errors evaluates how well the reprojected 2D points agree with the measurements $u_{ik}$ for all $(i,k) \in \calE$. Problem~\eqref{eq:ba-colmap} assumes the availability of a view graph, which is often obtained through feature detection and matching in SfM and SLAM pipelines (to be detailed in \S\ref{sec:xm-sfm}). An important observation is that problem~\eqref{eq:ba-colmap} can only be solved \emph{up to scale}. This is because $\pi(R_i p_k + t_i) \equiv \pi(R_i (\alpha p_k) + (\alpha t_i))$ for any scalar $\alpha > 0$, i.e., scaling the points and translations by a factor of $\alpha$ does not change the objective value of problem~\eqref{eq:ba-colmap}. 

\textbf{Optimization challenges}. Problem~\eqref{eq:ba-colmap} is intuitive to formulate but extremely difficult to optimize. The difficulty comes from two challenges. First, problem~\eqref{eq:ba-colmap} is highly nonconvex. The nonconvexity comes from both the nonconvex feasible set $\SEthree$ and the nonconvex objective function due to the 2D reprojection function $\pi(\cdot)$. Second, problem~\eqref{eq:ba-colmap} can have an extremely large scale. Both the number of camera poses $N$ and the number of points $M$ can range from hundreds to tens of thousands (\cf examples in Fig.~\ref{fig:demos}). Due to these challenges, BA solvers such as \ceres~\cite{agarwal2012ceres} and \gtsam~\cite{dellaert2022gtsam} require good initializations and can easily get stuck in poor local minima (\cf \S\ref{sec:exp-bal}). To address this, the popular SfM pipeline \colmap~\cite{schoenberger2016sfm} employs an \emph{incremental} strategy which starts by reconstructing only two views (i.e.,~\eqref{eq:ba-colmap} with $N=2$) and then sequentially registers additional camera images and associated 3D structure. Incremental SfM ensures stable initialization but makes the pipeline slow and hard to scale to large datasets (\cf \S\ref{sec:exp} where \colmap requires several hours runtime). The recent \emph{global} SfM pipeline \glomap~\cite{pan2025global} replaces the incremental process with rotation averaging and global positioning, but such initialization can be time-consuming (see \S\ref{sec:exp}).

Therefore, the motivating question of this paper is:

\emph{Can we design an algorithm that solves the global bundle adjustment problem~\eqref{eq:ba-colmap} without initialization and at scale?}


\input{sections/fig-view_graph.tex}

\textbf{BA with learned depth}. We start by designing an approximate formulation to problem~\eqref{eq:ba-colmap} that is simpler to optimize. The key insight is to lift the 2D keypoints $u_{ik}$ to approximate (and noisy) 3D keypoints leveraging large-scale pretrained monocular depth prediction models, such as~\cite{piccinelli2024unidepth,yang2024depth,bochkovskii2024depth}. Formally, let $d_{ik} > 0$ be the predicted depth of the 2D keypoint $u_{ik}$, we generate a 3D keypoint measurement
\bea\label{eq:3D-lifting}
\tilde{u}_{ik} = d_{ik} \begin{bmatrix}
    u_{ik} \\ 1 
\end{bmatrix}, \quad \forall (i,k) \in \calE.
\eea
However, it is well known that when using pretrained depth prediction models, for each image, there is a global scaling and offset to the predicted depth, i.e.,~the true depth for keypoint $u_{ik}$ should be ``$s_i d_{ik} + o_i$'' for some unknown scaling $s_i$ and offset $o_i$~\cite{ding2025fixing}. We ignore the offset $o_i$ but estimate the per-frame scaling $s_i$,\footnote{{The rationale for this is twofold. First, we use the model's metric depth prediction which should match the true depth when the model is perfectly trained. Second, estimating the scale leaves room to use optimization to fix imperfect predictions due to, e.g., out of distribution images.}} leading to the following \emph{scaled bundle adjustment} (SBA) formulation
\bea\label{eq:sba}
\min_{\substack{p_k \in \Real{3}, k=1,\dots,M \\ s_i > 0, i=1,\dots,N
\\ (R_i, t_i) \in \SEthree, i=1,\dots,N } } \sum_{(i,k)\in \calE} \left\| R_i (s_i \tilde{u}_{ik}) + t_i - p_k \right\|^2,
\eea
where $s_i$ scales the predicted 3D keypoint $\tilde{u}_{ik}$ in~\eqref{eq:3D-lifting}, $(R_i, t_i)$ transforms the scaled 3D keypoint to the global frame,\footnote{Although we used the same notation $(R_i,t_i)$ in both problems~\eqref{eq:ba-colmap} and~\eqref{eq:sba}, the two transformations are inverse to each other. $(R_i,t_i)$ in~\eqref{eq:ba-colmap} transforms landmarks from global frame to camera frame, while $(R_i,t_i)$ in~\eqref{eq:sba} transforms landmarks from camera frame to global frame.} and the sum of squared errors in the objective computes 3D distances to the landmarks $p_k$ without the reprojection $\pi(\cdot)$. 

\begin{remark}[Connection to Other Perception Problems]
    It is worth noting that (i) without the per-frame scaling, problem~\eqref{eq:sba} recovers the multiple point cloud registration problem~\cite{chaudhury2015global,iglesias2020global}; (ii) when $N=2$ (two frames), problem~\eqref{eq:sba} reduces to (scaled) point cloud registration~\cite{horn1987closed,yang2020teaser}.
\end{remark}
 

Through depth prediction, we removed the reprojection function $\pi(\cdot)$ from~\eqref{eq:ba-colmap} and resolved one challenge. However, nonconvexity and large scale remain in problem~\eqref{eq:sba}.

\textbf{Contributions}. First, we show the nonconvexity of problem~\eqref{eq:sba} is ``benign''. Our strategy is to first rewrite~\eqref{eq:sba} as a quadratically constrained quadratic program (QCQP), and then design a convex semidefinite program (SDP) relaxation, in the same spirit of a growing family of SDP-enabled certifiable algorithms~\cite{yang2022certifiably,rosen2019se,yu2024sim,kang2024fast,barfoot2023certifiably}. We show the SDP relaxation is empirically \emph{tight}, i.e.,~globally optimal solutions of the nonconvex~\eqref{eq:sba} can be computed from the convex SDP relaxation with optimality certificates. Second, we show the convex SDP relaxations can be solved at \emph{extreme scale and speed}---faster and more scalable than even the best local solvers such as \ceres. The enabling technique is to exploit the low-rankness of (tight) SDP optimal solutions via Burer-Monteiro (BM) factorization~\cite{burer2003nonlinear} and solve the resulting Riemannian optimization using a trust-region algorithm~\cite{boumal2023introduction}. \emph{For the first time, we implemented the trust-region Riemannian optimizer directly in C++/CUDA} and show the GPU implementation is up to $100$ times faster than the state-of-the-art \manopt package~\cite{boumal2014manopt} and can solve extreme-scale problems beyond the reach of \manopt (e.g., $N>10,000$ camera frames, see Fig.~\ref{fig:demos}). We name our GPU solver \nameshort (conveX bundle adjustMent). Third, we build a full SfM pipeline with \nameshort as the optimization engine and various techniques from prior work, such as feature matching from \colmap, view graph creation from \glomap, \ceres refinement (i.e., use the solutions of \nameshort to warmstart \ceres for solving~\eqref{eq:ba-colmap}), and outlier-robust estimation schemes~\cite{antonante2021outlier}. We test \xmsfm across six popular datasets and demonstrate that \xmsfm dominates or compares favorably with existing SfM pipelines in terms of reconstruction quality while being faster, more scalable, and initialization-free, all thanks to convex optimization. 

In summary, our contributions are:
\begin{itemize}
    \item designing an empirically tight convex SDP relaxation for the scaled bundle adjustment problem~\eqref{eq:sba};
    \item solving the convex SDP at extreme scales using BM factorization paired with a trust-region Riemannian optimizer directly implemented in C++/CUDA, \ie~\nameshort;
    \item creating a full SfM pipeline called \xmsfm that ``builds Rome with convex optimization''.
\end{itemize}


\textbf{Paper organization}. We derive the QCQP formulation for~\eqref{eq:sba} and design the SDP relaxation in \S\ref{sec:method}. We present BM factorization and the CUDA-based trust-region Riemannian optimizer in \S\ref{sec:implementation}. We describe the \xmsfm pipeline in \S\ref{sec:xm-sfm} and present experimental results in \S\ref{sec:exp}. We conclude in \S\ref{sec:conclusion}.