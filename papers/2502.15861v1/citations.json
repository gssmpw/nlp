[
  {
    "index": 0,
    "papers": [
      {
        "key": "shen2024towards",
        "author": "Shen, Hua and Knearem, Tiffany and Ghosh, Reshmi and Alkiek, Kenan and Krishna, Kundan and Liu, Yachuan and Ma, Ziqiao and Petridis, Savvas and Peng, Yi-Hao and Qiwei, Li and others",
        "title": "Towards Bidirectional Human-AI Alignment: A Systematic Review for Clarifications, Framework, and Future Directions"
      },
      {
        "key": "ji2023ai",
        "author": "Ji, Jiaming and Qiu, Tianyi and Chen, Boyuan and Zhang, Borong and Lou, Hantao and Wang, Kaile and Duan, Yawen and He, Zhonghao and Zhou, Jiayi and Zhang, Zhaowei and others",
        "title": "AI Alignment: A Comprehensive Survey"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "jobin2019global",
        "author": "Jobin, Anna and Ienca, Marcello and Vayena, Effy",
        "title": "The Global Landscape of AI Ethics Guidelines"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "li2023privacy",
        "author": "Li, Haoran and Chen, Yulin and Luo, Jinglong and Kang, Yan and Zhang, Xiaojin and Hu, Qi and Chan, Chunkit and Song, Yangqiu",
        "title": "Privacy in Large Language Models: Attacks, Defenses and Future Directions"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "abid2021persistent",
        "author": "Abid, Abubakar and Farooqi, Maheen and Zou, James",
        "title": "Persistent Anti-Muslim Bias in Large Language Models"
      },
      {
        "key": "hu2024",
        "author": "Hu, Tiancheng and Kyrychenko, Yara and Rathje, Steve and Collier, Nigel and van der Linden, Sander and Roozenbeek, Jon",
        "title": "Generative Language Models Exhibit Social Identity Biases"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "ganguli2022red",
        "author": "Ganguli, Deep and Lovitt, Liane and Kernion, Jackson and Askell, Amanda and Bai, Yuntao and Kadavath, Saurav and Mann, Ben and Perez, Ethan and Schiefer, Nicholas and Ndousse, Kamal and others",
        "title": "Red Teaming Language Models To Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned"
      },
      {
        "key": "deshpande2023toxicity",
        "author": "Deshpande, Ameet and Murahari, Vishvak and Rajpurohit, Tanmay and Kalyan, Ashwin and Narasimhan, Karthik",
        "title": "Toxicity in ChatGPT: Analyzing Persona-Assigned Language Models"
      },
      {
        "key": "shevlane2023model",
        "author": "Shevlane, Toby and Farquhar, Sebastian and Garfinkel, Ben and Phuong, Mary and Whittlestone, Jess and Leung, Jade and Kokotajlo, Daniel and Marchal, Nahema and Anderljung, Markus and Kolt, Noam and others",
        "title": "Model Evaluation for Extreme Risks"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "gabriel2020artificial",
        "author": "Gabriel, Iason",
        "title": "Artificial Intelligence, Values, and Alignment"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "schwartz1992universals",
        "author": "Schwartz, Shalom H",
        "title": "Universals in the Content and Structure of Values: Theoretical Advances and Empirical Tests in 20 Countries"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "kirk2024benefits",
        "author": "Kirk, Hannah Rose and Vidgen, Bertie and R{\\\"o}ttger, Paul and Hale, Scott A.",
        "title": "The Benefits, Risks and Bounds of Personalizing the Alignment of Large Language Models to Individuals"
      },
      {
        "key": "conitzer2024social",
        "author": "Conitzer, Vincent and Freedman, Rachel and Heitzig, Jobst and Holliday, Wesley H and Jacobs, Bob M and Lambert, Nathan and Moss{\\'e}, Milan and Pacuit, Eric and Russell, Stuart and Schoelkopf, Hailey and others",
        "title": "Social Choice Should Guide AI Alignment in Dealing with Diverse Human Feedback"
      },
      {
        "key": "sorensen2024roadmap",
        "author": "Sorensen, Taylor and Moore, Jared and Fisher, Jillian and Gordon, Mitchell and Mireshghallah, Niloofar and Rytting, Christopher Michael and Ye, Andre and Jiang, Liwei and Lu, Ximing and Dziri, Nouha and others",
        "title": "A Roadmap to Pluralistic Alignment"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "santurkar2023whose",
        "author": "Santurkar, Shibani and Durmus, Esin and Ladhak, Faisal and Lee, Cinoo and Liang, Percy and Hashimoto, Tatsunori",
        "title": "Whose Opinions Do Language Models Reflect?"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "durmus2023towards",
        "author": "Durmus, Esin and Nguyen, Karina and Liao, Thomas I and Schiefer, Nicholas and Askell, Amanda and Bakhtin, Anton and Chen, Carol and Hatfield-Dodds, Zac and Hernandez, Danny and Joseph, Nicholas and others",
        "title": "Towards Measuring the Representation of Subjective Global Opinions in Language Models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "conitzer2024social",
        "author": "Conitzer, Vincent and Freedman, Rachel and Heitzig, Jobst and Holliday, Wesley H and Jacobs, Bob M and Lambert, Nathan and Moss{\\'e}, Milan and Pacuit, Eric and Russell, Stuart and Schoelkopf, Hailey and others",
        "title": "Social Choice Should Guide AI Alignment in Dealing with Diverse Human Feedback"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "ouyang2022training",
        "author": "Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others",
        "title": "Training Language Models To Follow Instructions With Human Feedback"
      },
      {
        "key": "bai2022training",
        "author": "Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others",
        "title": "Training a Helpful and Harmless Assistant With Reinforcement Learning From Human Feedback"
      },
      {
        "key": "casper2023open",
        "author": "Casper, Stephen and Davies, Xander and Shi, Claudia and Gilbert, Thomas Krendl and Scheurer, J{\\'e}r{\\'e}my and Rando, Javier and Freedman, Rachel and Korbak, Tomasz and Lindner, David and Freire, Pedro and others",
        "title": "Open Problems and Fundamental Limitations of Reinforcement Learning From Human Feedback"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "ouyang2022training",
        "author": "Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others",
        "title": "Training Language Models To Follow Instructions With Human Feedback"
      },
      {
        "key": "rafailov2024direct",
        "author": "Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D. and Ermon, Stefano and Finn, Chelsea",
        "title": "Direct Preference Optimization: Your Language Model Is Secretly a Reward Model"
      },
      {
        "key": "hong-etal-2024-orpo",
        "author": "Hong, Jiwoo  and Lee, Noah  and Thorne, James",
        "title": "{ORPO}: Monolithic Preference Optimization without Reference Model"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "bowman2022measuring",
        "author": "Bowman, Samuel R. and Hyun, Jeeyoon and Perez, Ethan and Chen, Edwin and Pettit, Craig and Heiner, Scott and Luko{\\v{s}}i{\\=u}t{\\.e}, Kamil{\\.e} and Askell, Amanda and Jones, Andy and Chen, Anna and others",
        "title": "Measuring Progress on Scalable Oversight for Large Language Models"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "ganguli2023capacity",
        "author": "Ganguli, Deep and Askell, Amanda and Schiefer, Nicholas and Liao, Thomas I and Luko{\\v{s}}i{\\=u}t{\\.e}, Kamil{\\.e} and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and Olsson, Catherine and Hernandez, Danny and others",
        "title": "The Capacity for Moral Self-Correction in Large Language Models"
      },
      {
        "key": "sun2023salmon",
        "author": "Sun, Zhiqing and Shen, Yikang and Zhang, Hongxin and Zhou, Qinhong and Chen, Zhenfang and Cox, David and Yang, Yiming and Gan, Chuang",
        "title": "Salmon: Self-Alignment With Principle-Following Reward Models"
      },
      {
        "key": "chen2024iteralign",
        "author": "Chen, Xiusi and Wen, Hongzhi and Nag, Sreyashi and Luo, Chen and Yin, Qingyu and Li, Ruirui and Li, Zheng and Wang, Wei",
        "title": "ITERALIGN: Iterative Constitutional Alignment of Large Language Models"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "bai2022constitutional",
        "author": "Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others",
        "title": "Constitutional AI: Harmlessness From AI Feedback"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "kundu2023specific",
        "author": "Kundu, Sandipan and Bai, Yuntao and Kadavath, Saurav and Askell, Amanda and Callahan, Andrew and Chen, Anna and Goldie, Anna and Balwit, Avital and Mirhoseini, Azalia and McLean, Brayden and others",
        "title": "Specific Versus General Principles for Constitutional AI"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "petridis2024constitutionmaker",
        "author": "Petridis, Savvas and Wedin, Benjamin D. and Wexler, James and Pushkarna, Mahima and Donsbach, Aaron and Goyal, Nitesh and Cai, Carrie J. and Terry, Michael",
        "title": "ConstitutionMaker: Interactively Critiquing Large Language Models by Converting Feedback into Principles"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "findeis2024inverse",
        "author": "Findeis, Arduin and Kaufmann, Timo and H{\\\"u}llermeier, Eyke and Albanie, Samuel and Mullins, Robert",
        "title": "Inverse Constitutional AI: Compressing Preferences into Principles"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "abiri2024public",
        "author": "Abiri, Gilad",
        "title": "Public Constitutional AI"
      },
      {
        "key": "huang2024collective",
        "author": "Huang, Saffron and Siddarth, Divya and Lovitt, Liane and Liao, Thomas I and Durmus, Esin and Tamkin, Alex and Ganguli, Deep",
        "title": "Collective Constitutional AI: Aligning a Language Model with Public Input"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "huang2024collective",
        "author": "Huang, Saffron and Siddarth, Divya and Lovitt, Liane and Liao, Thomas I and Durmus, Esin and Tamkin, Alex and Ganguli, Deep",
        "title": "Collective Constitutional AI: Aligning a Language Model with Public Input"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "bowman2021will",
        "author": "Bowman, Samuel R. and Dahl, George E.",
        "title": "What Will It Take To Fix Benchmarking in Natural Language Understanding?"
      },
      {
        "key": "ganguli2023challenges",
        "author": "Deep Ganguli and Nicholas Schiefer and Marina Favaro and Jack Clark",
        "title": "Challenges in Evaluating {AI} Systems"
      },
      {
        "key": "blodgett2021stereotyping",
        "author": "Blodgett, Su Lin and Lopez, Gilsinia and Olteanu, Alexandra and Sim, Robert and Wallach, Hanna",
        "title": "Stereotyping Norwegian Salmon: An Inventory of Pitfalls in Fairness Benchmark Datasets"
      },
      {
        "key": "anwar2024foundational",
        "author": "Anwar, Usman and Saparov, Abulhair and Rando, Javier and Paleka, Daniel and Turpin, Miles and Hase, Peter and Lubana, Ekdeep Singh and Jenner, Erik and Casper, Stephen and Sourbut, Oliver and others",
        "title": "Foundational Challenges in Assuring Alignment and Safety of Large Language Models"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "wang2018glue",
        "author": "Alex Wang and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman",
        "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"
      },
      {
        "key": "wang2019superglue",
        "author": "Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel",
        "title": "Superglue: A Stickier Benchmark for General-Purpose Language Understanding Systems"
      },
      {
        "key": "hendrycks2020measuring",
        "author": "Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob",
        "title": "Measuring Massive Multitask Language Understanding"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "deng2023investigating",
        "author": "Deng, Chunyuan and Zhao, Yilun and Tang, Xiangru and Gerstein, Mark and Cohan, Arman",
        "title": "Investigating Data Contamination in Modern Benchmarks for Large Language Models"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "blodgett2020language",
        "author": "Blodgett, Su Lin and Barocas, Solon and Daum{\\'e} III, Hal and Wallach, Hanna",
        "title": "Language (Technology) Is Power: A Critical Survey Of ``Bias'' in NLP"
      },
      {
        "key": "parrish2021bbq",
        "author": "Parrish, Alicia and Chen, Angelica and Nangia, Nikita and Padmakumar, Vishakh and Phang, Jason and Thompson, Jana and Htut, Phu Mon and Bowman, Samuel R",
        "title": "BBQ: A Hand-Built Bias Benchmark for Question Answering"
      },
      {
        "key": "ganguli2023challenges",
        "author": "Deep Ganguli and Nicholas Schiefer and Marina Favaro and Jack Clark",
        "title": "Challenges in Evaluating {AI} Systems"
      },
      {
        "key": "santurkar2023whose",
        "author": "Santurkar, Shibani and Durmus, Esin and Ladhak, Faisal and Lee, Cinoo and Liang, Percy and Hashimoto, Tatsunori",
        "title": "Whose Opinions Do Language Models Reflect?"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "kundu2023specific",
        "author": "Kundu, Sandipan and Bai, Yuntao and Kadavath, Saurav and Askell, Amanda and Callahan, Andrew and Chen, Anna and Goldie, Anna and Balwit, Avital and Mirhoseini, Azalia and McLean, Brayden and others",
        "title": "Specific Versus General Principles for Constitutional AI"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "zhou2023instruction",
        "author": "Zhou, Jeffrey and Lu, Tianjian and Mishra, Swaroop and Brahma, Siddhartha and Basu, Sujoy and Luan, Yi and Zhou, Denny and Hou, Le",
        "title": "Instruction-Following Evaluation for Large Language Models"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "perez2023discovering",
        "author": "Perez, Ethan  and Ringer, Sam  and Lukosiute, Kamile  and Nguyen, Karina  and Chen, Edwin  and Heiner, Scott  and others",
        "title": "Discovering Language Model Behaviors with Model-Written Evaluations"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "wang2023chatgpt",
        "author": "Wang, Jiaan  and Liang, Yunlong  and Meng, Fandong  and Sun, Zengkui  and Shi, Haoxiang  and Li, Zhixu  and Xu, Jinan  and Qu, Jianfeng  and Zhou, Jie",
        "title": "Is {C}hat{GPT} a Good {NLG} Evaluator? A Preliminary Study"
      },
      {
        "key": "wang2023largelm",
        "author": "Peiyi Wang and Lei Li and Liang Chen and Dawei Zhu and Binghuai Lin and Yunbo Cao and Qi Liu and Tianyu Liu and Zhifang Sui",
        "title": "Large Language Models Are Not Fair Evaluators"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "ouyang2022training",
        "author": "Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others",
        "title": "Training Language Models To Follow Instructions With Human Feedback"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "qin2023large",
        "author": "Qin, Zhen and Jagerman, Rolf and Hui, Kai and Zhuang, Honglei and Wu, Junru and Yan, Le and Shen, Jiaming and Liu, Tianqi and Liu, Jialu and Metzler, Donald and others",
        "title": "Large Language Models Are Effective Text Rankers With Pairwise Ranking Prompting"
      },
      {
        "key": "liu2024aligning",
        "author": "Liu, Yinhong and Zhou, Han and Guo, Zhijiang and Shareghi, Ehsan and Vulic, Ivan and Korhonen, Anna and Collier, Nigel",
        "title": "Aligning with Human Judgement: The Role of Pairwise Preference in Large Language Model Evaluators"
      },
      {
        "key": "zhou2024fairer",
        "author": "Zhou, Han and Wan, Xingchen and Liu, Yinhong and Collier, Nigel and Vuli\u0107, Ivan and Korhonen, Anna",
        "title": "Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "wang2023largelm",
        "author": "Peiyi Wang and Lei Li and Liang Chen and Dawei Zhu and Binghuai Lin and Yunbo Cao and Qi Liu and Tianyu Liu and Zhifang Sui",
        "title": "Large Language Models Are Not Fair Evaluators"
      }
    ]
  },
  {
    "index": 32,
    "papers": [
      {
        "key": "sorensen2024roadmap",
        "author": "Sorensen, Taylor and Moore, Jared and Fisher, Jillian and Gordon, Mitchell and Mireshghallah, Niloofar and Rytting, Christopher Michael and Ye, Andre and Jiang, Liwei and Lu, Ximing and Dziri, Nouha and others",
        "title": "A Roadmap to Pluralistic Alignment"
      }
    ]
  },
  {
    "index": 33,
    "papers": [
      {
        "key": "devellis2006classical",
        "author": "DeVellis, Robert F",
        "title": "Classical test theory"
      }
    ]
  },
  {
    "index": 34,
    "papers": [
      {
        "key": "fabrigar2012exploratory",
        "author": "Fabrigar, Leandre R. and Wegener, Duane T.",
        "title": "Exploratory Factor Analysis"
      }
    ]
  },
  {
    "index": 35,
    "papers": [
      {
        "key": "embretson2013item",
        "author": "Embretson, Susan E. and Reise, Steven P.",
        "title": "Item Response Theory"
      }
    ]
  },
  {
    "index": 36,
    "papers": [
      {
        "key": "ega1",
        "author": "Golino, Hudson F. and Epskamp, Sacha",
        "title": "Exploratory Graph Analysis: A New Approach for Estimating the Number of Dimensions in Psychological Research"
      }
    ]
  },
  {
    "index": 37,
    "papers": [
      {
        "key": "ega2",
        "author": "Golino, Hudson and Shi, Dingjing and Christensen, Alexander P. and Garrido, Luis Eduardo and Nieto, Maria Dolores and Sadana, Ritu and Thiyagarajan, Jotheeswaran Amuthavalli and Martinez-Molina, Agustin",
        "title": "Investigating the Performance of Exploratory Graph Analysis and Traditional Techniques To Identify the Number of Latent Factors: A Simulation and Tutorial."
      },
      {
        "key": "golino2022exploratory",
        "author": "Golino, Hudson and Christensen, Alexander P. and Garrido, Luis Eduardo",
        "title": "Exploratory Graph Analysis in Context"
      }
    ]
  },
  {
    "index": 38,
    "papers": [
      {
        "key": "uva",
        "author": "Alexander P., Christensen, and Luis Eduardo, Garrido, and Hudson, Golino",
        "title": "Unique Variable Analysis: A Network Psychometrics Method to Detect Local Dependence"
      }
    ]
  },
  {
    "index": 39,
    "papers": [
      {
        "key": "bai2022constitutional",
        "author": "Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others",
        "title": "Constitutional AI: Harmlessness From AI Feedback"
      },
      {
        "key": "petridis2024constitutionmaker",
        "author": "Petridis, Savvas and Wedin, Benjamin D. and Wexler, James and Pushkarna, Mahima and Donsbach, Aaron and Goyal, Nitesh and Cai, Carrie J. and Terry, Michael",
        "title": "ConstitutionMaker: Interactively Critiquing Large Language Models by Converting Feedback into Principles"
      },
      {
        "key": "findeis2024inverse",
        "author": "Findeis, Arduin and Kaufmann, Timo and H{\\\"u}llermeier, Eyke and Albanie, Samuel and Mullins, Robert",
        "title": "Inverse Constitutional AI: Compressing Preferences into Principles"
      }
    ]
  }
]