\section{Experiments}
\label{sec:experiments}
\subsection{Training Details}
\label{sec:details}

\input{tables/table_nerf}

\begin{figure}[b]
    \centering
    % \vspace{-2ex}
    \includegraphics[width=\linewidth]{figs/figure_normal_3.png}
    \caption{Visualized normal results on Shiny Blender dataset~\cite{verbin2022ref}. It illustrates the superior normal estimation achieved by our method. 
    }
    \label{fig:fig_shinyblender_normal}
          
\end{figure}


\input{tables/table_glossy}

We observe that while jointly estimating all parameters, the inherent ambiguities introduced by specular lights and environment reflection complicate the differentiation between textures and lighting, leading to low-quality geometry reconstruction. Thus, we introduce phased training strategy to help decoupling the geometry and material properties. 

The training procedure is divided into three stages. In the first stage, training is guided solely by photometric losses and alpha constraints, following the approach used in 2D-GS~\cite{Huang2DGS2024}. In the second stage, normal regularization is introduced to enhance the reconstruction of robust surface geometry. In the third stage, geometry properties are fixed while optimizing only the color parameters. For specular rendering, we sample $N_s=64$ incident rays per Gaussian point. Training is conducted over 7000 iterations in the first stage, 18000 iterations in the second stage, and 15000 iterations in the final stage, totaling 40000 iterations, consistent with \cite{gao2023relightable}. All experiments are conducted on a single NVIDIA GeForce RTX 4090 GPU. 



\begin{figure*}[t]
    \centering
    \vspace{-3ex}
    \includegraphics[width=\linewidth]{figs/figure_nerf_01.png}
    \caption{The qualitative comparisons on NeRF Synthetic Dataset~\cite{mildenhall2020nerf}. Our method renders the glossy surfaces with high fidelity and reconstructs accurate shadowing. Some areas are zoomed in for better visualization.
    }
    \label{fig:nerf_synthetic}
      \vspace{-3ex}
\end{figure*}

\subsection{Baselines and Metrics}
We compare our method with recent GS-based inverse rendering techniques: GaussianShader~\cite{jiang2024gaussianshader}, GS-IR~\cite{liang2024gs}, and Relightable 3DGS~\cite{gao2023relightable} that demonstrate effciency advantage over NeRF-based methods, as well as with baseline methods including 2D-GS~\cite{Huang2DGS2024} and the top-performing Scaffold-GS~\cite{lu2024scaffold} that utilizes neural-based enhancements. Quantitative metrics used include peak signal-to-noise ratio (PSNR), structural similarity index measure (SSIM), and learned perceptual image patch similarity (LPIPS). 


\subsection{Comparisons}
To thoroughly demonstrate the effectiveness of GlossGau, we evaluate it on several datasets: the widely-used novel view synthesis (NVS) dataset, NeRF Synthetic~\cite{mildenhall2020nerf} and reflective object datasets: Glossy Synthetic~\cite{liu2023nero} and Shiny Blender~\cite{verbin2022ref} dataset. 

\noindent{\bf NeRF Synthetic dataset.}
We first evaluate the novel view synthesis (NVS) on the NeRF synthetic dataset~\cite{mildenhall2020nerf}. The results are presented in Table \ref{tab:tab_nerfsynthetic}, and visual comparisons are shown in Figure \ref{fig:nerf_synthetic}. The corresponding predicted normals is shown in Figure \ref{fig:nerf_normal}. Our approach achieves quantitatively and perceptually comparable results with both point-based~\cite{Huang2DGS2024,lu2024scaffold} and inverse-rendering methods~\cite{jiang2024gaussianshader,gao2023relightable}. GlossGau successfully reconstructs the semi-transparent drumhead and glossy components as well as the shadowing casting of the cushion. Furthermore, GlossGau accurately disentangle the geometry and surface texture in normal estimation stage, contributing to the quality of final rendering. 


\noindent{\bf Glossy Synthetic dataset \cite{liu2023nero}.}
Quantitative results are reported in Table \ref{tab:tab_glossy}. Our method excels across metrics and is comparable to GaussianShader~\cite{jiang2024gaussianshader}. As illustrated in Figure \ref{fig:glossy},  our method generates visually appealing rendering with less noisy surfaces and more realistic shadowing. While effectively capturing shiny regions, our approach maintains clean reconstruction in non-specular areas, yielding more photorealistic rendering results.


\begin{figure}
    \centering
    {\includegraphics[width=\linewidth]{figs/figure_nerf_02.png}}
    \caption{Visualized normals on NeRF Synthetic Dataset~\cite{mildenhall2020nerf}.
    }
    \label{fig:nerf_normal}
    % \vspace{-3ex}
\end{figure}


\noindent{\bf Shiny Blender dataset.~\cite{verbin2022ref}}
Visual comparisons on the Shiny Blender dataset are presented in Figure \ref{fig:refnerf}. Our method demonstrates superior reconstruction of glossy surfaces and accurate reflection characteristics compared to other approaches. These results validate the precision of our joint geometry and material parameter estimation. The complete results are included in the supplementary. 


\begin{figure*}[t]
    \centering
    \vspace{-3ex}
    \scalebox{0.9}{\includegraphics[width=\linewidth]{figs/figure_glossy.png}}
    \vspace{-1ex}
    \caption{The qualitative comparisons on Glossy Synthetic Dataset~\cite{liu2023nero}. Our method accurately characterizes surface roughness and generates realistic and smooth reflection effects compared with prior GS-based inverse rendering methods.
    }
    \label{fig:glossy}
      
\end{figure*}

\begin{figure*}[t]
\vspace{-1ex}
    \centering
    \scalebox{0.9}{\includegraphics[width=\linewidth]{figs/figure_helmet5.png}}
    \caption{Visualized comparisons on Shiny Blender Dataset~\cite{verbin2022ref}.
    }
    \label{fig:refnerf}
    \vspace{-2ex}
\end{figure*}

\input{tables/table_speed}

Additionally, we report the average training time, rendering FPS, and resultant Gaussan's size in Table~\ref{tab:tab_speed}. The reported results are averaged among objects in NeRF synthetic datasets~\cite{mildenhall2020nerf}. On the same hardware, our method only takes about 0.34 hour for training and the resulting pointcloud occupies significantly less storage compared with \cite{gao2023relightable}. Given competitive or even superior reconstruction fidelity, GlossGau exhibits notable computational advantages. 


\subsection{Ablation Study}
\label{sec:exp_ablation}
\input{tables/table_ablation}

We conduct ablation studies of our model on NeRF Synthetic Dataset. The numerical comparisons are provided in Table \ref{tab:tab_ablation}. We assess the effectiveness of anisotropic spherical Gaussian warping by comparing it against the standard isotropic spherical Gaussian BRDF formulation from~\cite{wang2009all}. Additionally, we ablate the normal regularization, relying solely on photometric loss for optimization. We also validate the necessity of our phased training protocol by comparing against simultaneous optimization of all Gaussian parameters. Detailed comparisons are provided in the supplementary material. 