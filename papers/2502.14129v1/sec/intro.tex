\section{Introduction}
\label{sec:intro}

Photorealisric reconstruction from images captured from multiple viewpoints is a critical yet challenging task in computer graphics and computer vision. In recent years, the field of 3D computer vision has witnessed remarkable advancements in the 3D reconstruction and visualization of 3D scenes. Innovations such as Neural Radiance Fields (NeRF)~\cite{mildenhall2020nerf} have achieved substantial breakthroughs in generating novel views of 3D objects and scenes, presenting the potential for high-quality and photo-realistic renderings. More recently, 3D Gaussian Splatting~\cite{kerbl20233d} combines 3D Gaussian representation and tile-based splatting techniques to achieve high-quality 3D scene modeling and real-time rendering. Despite its exceptional performance, 3D-GS struggles to model glossy surfaces within scenes. 3D Gaussian Splatting~\cite{kerbl20233d} utilizes low-order spherical harmonics (SH) instead of explicitly model appearance properties, so that fails to capture significant view-dependent changes, particularly specular highlights. Recent studies~\cite{liang2024gs,gao2023relightable,jiang2024gaussianshader} try to build inverse rendering pipelines based on 3D-GS. However, these methods mostly sacrifices training and rendering efficiency, thereby undermining the benefits of Gaussian Splatting techniques. 




In this paper, we introduce GlossGau, an efficient inverse rendering framework that reconstructs scenes with glossy surfaces while preserving computational performance of 3D-GS. Our approach jointly optimizes illumination, material properties, geometry, and surface normals from multi-view images with known camera poses. To maintain computational efficiency, we formulate specular BRDF terms using anisotropic spherical Gaussian. For normal estimation and geometry consistency, we utilize the surfel-based Gaussian Splatting, which collapses volumetric representations into thin surfaces, to rigorously define the geometry of Gaussians. The resulting Gaussians reconstruct glossy surfaces at fast training and rendering speed and supports post-manipulations such as material editing and relighting. In summary, our key contributions are:
\begin{enumerate}
    \item Our method explicitly approximates the rendering equation and analytically represents the specular BRDF using Anisotropic Spherical Gaussian, yielding photorealistic reconstruction particularly for glossy surfaces compared to standard 3D-GS, without compromising the optimization efficiency. 
    \item Leveraging surfel-based Gaussian Splatting and regularization, our approach achieves enhanced precision in surface normal estimation, reducing the material-geometry ambiguities and resulting in better inverse rendering. 
    \item Extensive experimental evaluation across diverse datasets validates GlossGau's high rendering fidelity for both general and highly-glossy surfaces. Maintaining comparable visual quality, our approach achieves up to 66\% reduction in optimization time and supports real-time rendering performance compared to existing GS-based inverse rendering methods.
\end{enumerate}



