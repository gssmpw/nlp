\section{Existing Approaches: \\ Challenges and Opportunities}
\label{sec:background}
In this section, we review the challenges and opportunities with existing approaches to dexterous manipulation that motivate our work. 
\subsection{Human Teleoperation for Imitation Learning}
\textbf{Challenge:}
Dexterous manipulation via teleoperation is challenging for humans due to the following reasons:
\paragraph{Partial Observability} During in-hand manipulation, the object motion is determined by the contact dynamics between hand and object~\cite{trinkle1990planning, okamura2000overview,ji2001planning}. Successful manipulation requires perceiving and understanding contact information, such as normal force and friction, to generate appropriate torques. However, human operators face challenges in observing this information due to occlusion and limited tactile feedback. Additionally, existing discrete haptic feedback~(e.g. binary vibration) alone is often inadequate for conveying complex touch interactions and contact geometries.

\begin{figure*}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{src/figure/rss_training_data.pdf}
    \caption{\textbf{Dataset:} The Anygrasp-to-Anygrasp dataset generation pipeline is designed for the generative pretraining of \mname. For a wide variety of objects, we extensively search for potential grasp configurations, using these as both the initial and goal states for RL policies. To ensure our diffusion model can manage diverse scenarios, we incorporate varied wrist poses, movements, and domain randomization during RL training and data collection.}
    \label{fig:dataset}
\end{figure*}
\paragraph{Embodiment Gap} Although human and robot hands may appear similar at first glance, they differ significantly in their kinematic structures and geometries. For example, human fingers have a smooth and compliant surfaces, while the robot fingers often have rough edges. These differences result in discrepancies in contact dynamics, making it challenging to directly transfer our understanding of human finger motions for object manipulation to robotic counterparts. In our early experiments, we find the object motion very sensitive to the change of fingertip shape.

\paragraph{Motion Complexity} Dexterous in-hand manipulation involves highly complex motion. The process requires precise control of a high degree-of-freedom dynamical system. Any suboptimal teleoperation motion at any DOF can lead to failures such as breaking grasping contacts.

\paragraph{Inaccuracy of Actions~(Force)} Existing robot hand teleoperation systems are based on hand retargeting with position control, which lacks an intuitive force control interface to users. As a result, users can only influence force through position-control errors, making teleoperation particularly challenging in force-sensitive scenarios. Moreover, the presence of noise in real world robot system further complicates control.

\textbf{Opportunity: High-level (Semantical) Motion Control} While humans may find it challenging to provide fine-grained, low-level actions directly, human teleoperation or even video demonstrations can still offer valuable coarse motion-level guidance for a variety of complex real-world tasks. Humans possess intuitive knowledge, such as where a robot hand should make contact and what constitutes a good grasp. Thus, human data can be leveraged to create a high-level semantic action plan. In locomotion research, recent studies have proposed using teleoperation commands as high-level motion prompts~\cite{cheng2024expressive}. However, extending this approach to finegrained dexterous manipulation remains an open question.

\subsection{Sim-to-real Reinforcement Learning}
\textbf{Challenge:} Developing a generalized sim-to-real policy for dexterous manipulation involves two main challenges:
\paragraph{Sim-to-Real Gap} It is difficult to reproduce real-world sensor observation~(mainly for vision input) and physics in simulation. This gap can make sim-to-real transfer highly challenging for complex tasks. In particular, transferring a vision-based control policy from simulation to real world for dexterous hands is a huge challenge and requires costly visual domain randomization~\cite{tobin2017domain}. For instance, Dextreme~\cite{handa2023dextreme} leveraged extensive visual domain randomization with 5M rendered images to train a single object rotation policy.

\paragraph{Reward Specification} A more important issue, beyond the sim-to-real gap, is the notorious challenge of designing reward functions for long-horizon, contact-rich problems. Existing methods often involve highly engineered rewards or overly complicated learning strategies~\cite{chen2023sequential}, which are task-specific and limit scalability.

\textbf{Opportunity: Low-level (Physical) Action Control} Although sim-to-real RL can be difficult, especially for those complex long-horizon or vision-based tasks, some recent works have shown that sim-to-real RL is sufficient to build diverse transferable manipulation primitives based on proprioception and touch~\cite{yin2023rotating}. Therefore, one opportunity for sim-to-real RL is to create rich low-level action primitives that can be combined with the high-level action plan discussed above. In this paper, we achieve this through generative pretraining.
