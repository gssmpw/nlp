\begin{figure*}
    \centering
    \includegraphics[width=1.0\linewidth]{src/figure/rss_idea_new.pdf}
    \caption{Overview of proposed framework. \textbf{Left (Training):} We collect a large multi-task dexterous in-hand manipulation dataset in simulation to pretrain a generative model that can generate diverse actions conditioned on the current state. The pretrained generative model can produce useful actions including rotation, translation, and more intricated behaviors.  \textbf{Right (Inference):} During inference, we can project dangerous motion produced by teleoperation or policy back to a high-likelihood action with guided sampling. This makes \mname{} capable of assisting a coarse high-level policy to perform complex object manipulations.}
    \label{fig:enter-label}
\end{figure*}


\section{Introduction}
Dexterous robotic hands are increasingly capturing attention due to their potential across various fields, including manufacturing, household tasks, and healthcare~\cite{okamura2000overview}. These robotic systems can replicate the fine motor skills of the human hand, enabling complex object manipulation~\cite{shaw2023leap, andrychowicz2020learning}. Their ability to perform tasks requiring human-like dexterity makes them valuable in areas where traditional automation falls short. However, effectively teaching dexterous in-hand manipulation skills to robotic hands remains a key challenge in robotics.

Recent data-driven approaches to teach robots dexterous manipulation skills can be boardly categorized into two categories: human teleoperation (for imitation learning)~\cite{hussein2017imitation, handa2020dexpilot,sivakumar2022robotic,qin2023anyteleop,ding2024bunny,lin2024learning,cheng2024open,wang2024dexcap,shaw2024bimanual} and sim-to-real Reinforcement Learning~(RL)~\cite{andrychowicz2020learning,handa2023dextreme,qi2023hand,yin2023rotating,khandate2023sampling,huang2023dynamic,chen2023sequential,kannan2023deft,agarwal2023dexterous,lum2024dextrah,yang2024anyrotate,wang2024lessons,lin2024twisting,sievers2022learning}. Despite their success, these methods face several limitations in practical applications. For human teleoperation, a major bottleneck is the collection of high-quality demonstrations~\cite{levine2020offline, yin2024offline}. In contact-rich dexterous manipulation, it is challenging for humans to perform safe and stable object manipulation actions, often resulting in objects falling from the hand. This makes teleoperation impractical for dexterous manipulation tasks. For sim-to-real RL, challenges arise from the significant domain gap between simulation and the real world, as well as the need for highly task-specific reward specifications when training an RL agent for complex tasks. We will discuss these challenges in more detail in Section~\ref{sec:background}.

While each approach has its own set of challenges, combining their strengths offers a promising strategy to address the complexities of dexterous manipulation. Specifically, recent sim-to-real RL works~\cite{qi2023hand,yin2023rotating} have shown that it is possible to train simple dexterous in-hand object manipulation primitives (e.g. rotation) that can be transferred to a robot in the real world. This suggests that RL can be leveraged to generate a large-scale dataset of dexterous manipulation primitives, including in-hand object rotation, translation, and grasp transitions. Meanwhile, humans excel at composing these skills through teleoperation to address more challenging tasks. For example, Yin et al. have shown that they can perform in-hand reorientation by calling several rotation primitives sequentially~\cite{yin2023rotating}. However, the external inputs in these studies are limited to a few discretized commands, lacking control over low-level interactions, such as finger movements and object contact. This limitation makes it difficult to prompt existing models to generate more detailed, finger-level interaction behaviors, such as using a syringe or screwdriver. 

Motivated by these observations, in this paper, we propose a novel training framework called \mnamefull{}~(\mname{}) to address the challenges of teaching dexterous in-hand manipulation skills. Our main idea is to use a broad, multitask simulation dataset generated via RL to pretrain a generative behavior model~(\mname) that can translate a coarse motion command to safe robot actions which can maximally preserve the motion while guaranteeing safety. In real-world applications, an external policy, such as human teleoperation or an imitation policy, can be used to prompt \mname{} to execute meaningful manipulation skills. Our approach effectively decouples high-level semantic motion generation from fine-grained low-level control, serving as a foundational low-level dexterity controller.

We validate our \mname{} framework through both simulated and real-world experiments. In simulation, we demonstrate that \mname{} significantly enhances the robustness and performance of a highly perturbed noisy policy, extending its stable operation duration by 10-100 times and enabling success even when input commands are predominantly noise. In real-world scenarios, we employ human teleoperation as a proxy for high-level motion commands and test the framework on various challenging dexterous manipulation tasks involving complex hand-object interactions across a diverse set of objects. Notably, it successfully synthesizes trajectories to solve challenging tasks, such as reorienting and using syringes and screwdrivers, with human guidance, for the first time.


