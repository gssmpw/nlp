
\begin{table}
    \centering
    \normalsize
    \renewcommand\arraystretch{1.0}

    \caption{The breakdown success analysis of syringe and screwdriver teleoperation. These long-horizon tasks require several stages of manipulation and remain challenging.}
    \begin{tabular*}{\linewidth}{l@{\extracolsep{\fill}}|cccc}
        \toprule
       \multirow{2}{*}{\textbf{Screwdriver}\quad} & \textbf{Reorient}  &  \textbf{Regrasp} &\textbf{Align}   & \textbf{Use}\\
        \cmidrule{2-5}
       & 16/20  & 11/20 & 5/20 & 3/20\\
       \midrule
      \multirow{2}{*}{\textbf{Syringe}\quad} & \textbf{Reorient}  &  \textbf{Regrasp} &  & \textbf{Use}\\
        \cmidrule{2-5}
       & 15/20  & 9/20 &   & 4/20\\
        \bottomrule
    \end{tabular*}

    \label{tab:longhorizon}
\end{table}
\section{Related Works}

\paragraph{Foundation Models and Pretraining for Robotics}
In recent years, the success of large foundation models in natural language processing and computer vision~\cite{achiam2023gpt,kirillov2023segment,touvron2023llama} has attracted much attention in building foundation models for robotics~\cite{brohan2022rt,brohan2023rt,du2024learning,radosavovic2023robot,team2024octo,o2023open, zhao2024aloha, kim2024openvla, khazatsky2024droid}. Existing works typically focus on building a large end-to-end control model by pretraining them on large real world datasets. Our framework also leverages large-scale pretraining, but it differentiates from these works in various aspects. First, we consider pretraining a controller on pure simulation datasets rather than real world datasets which require extensive human efforts in data collection with teleoperation. Second, we study dexterous manipulation with a high DOF robotic hand and demonstrate the advantage of generative pretraining in this challenging scenario for the first time, while existing works typically consider parallel jaw gripper problems. Third, we build a low-level foundation controller that can be prompted with continuous fine-grained guidance to provide useful actions, which can be potentially integrated with high-level planning policies in the future. Most existing robotic foundation models are conditioned on discrete language prompts or task embeddings. In summary, our pretraining framework for building a foundational low-level controller presents a new perspective in the foundation model literature.


\paragraph{Shared Autonomy} Our system is also related to shared autonomy research~\cite{aarno2005adaptive, kim2006continuous,carlson2008human, schroer2015autonomous,schwarting2017parallel}, which focuses on leveraging external action guidance to produce effective actions. Some works focus on how to train RL agents with external actions~(e.g. from teleoperation)~\cite{reddy2018shared,du2020ave,reddy2022first}. In their setup, the external inputs are usually treated as part of observation fed to the RL policy. Compared to this line of work, our method does not involve human actions in the training phase. Another line of work assumes the existence of a few task-specific intentions and goals and reduces the shared autonomy problem to the goal or intent inference~\cite{aarno2005adaptive,javdani2015shared}. A limitation of this line of work in dexterous manipulation is that they do not allow fine-grained finger control since they only provide a few options for high-dimensional action space. Our method samples fine-grained low-level behavior according to user commands in high-dimensional action space and does not suffer from this problem.  The most relevant works are ~\cite{broad2019highly, yoneda2023noise}, which also use some sampled distribution to correct user behavior. We use a different correction procedure and investigate a more general and challenging dexterous manipulation setup. 