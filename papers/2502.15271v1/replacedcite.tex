\section{Related Work}
\label{sec:rw}

In this section, we first briefly introduce existing OIQA databases. Then, we describe state-of-the-art OIQA models and IQC models.


\subsection{Subjective OIQA Databases}
\label{subsec:database}

The construction of IQA databases needs much more effort than establishing benchmarks for other computer vision tasks, \eg, object detection, semantic segmentation, and \emph{etc}, since IQA is a relatively uncertain problem and subjective quality assessment requires more labor to get stable ratings____. Generally, IQA databases act as the platform for investigating the influence of various factors on QoE of users and comparing different IQA models. Compared with the 2D-IQA databases, the weaknesses of existing OIQA databases include at least a limited number of image samples and simplistic content. The CVIQ database____ is composed of 528 images with compression distortion, which are generated from 16 reference images, while the images in the OIQA database____ are distorted by four types of synthesized distortions. Similarly, the LIVE VR IQA database____ includes 450 distorted images generated from 15 reference images, where the images are distorted by six types of synthesized distortions; the MVAQD database____ consists of 15 source images and 300 distorted images with five types of synthesized distortions; the NBU-HOID database____ investigates the influence of compression and tone mapping on the quality of high dynamic range omnidirectional images; the NBU-SOID database____ focuses on quality assessment of stereoscopic omnidirectional images, each of which is composed of a left omnidirectional image and a right omnidirectional image; the IQA-ODI database____ explores the impairments of JPEG compression and map projection on omnidirectional images. 

To sum up, all the databases mentioned above are dedicated to the issue of homogeneous degradation, \ie, every region suffers from the same type of distortion with the same level regardless of its position. These databases undeniably promote the development of OIQA, however, they ignore the heterogeneous degradation problem, which is also very important in real applications____. Fang~\et____ introduced the concept of heterogeneous distortion and built an OIQA database named JUFE (which is extended on the small database____), where they discussed the relationship between viewing condition and viewing behavior. Nevertheless, the few number of omnidirectional images in the JUFE database makes it difficult to satisfy the data-hungry demand of deep learning models. Thus, to further facilitate the development of OIQA, we propose a new large-scale database named OIQ-10K, which consists of 10,000 omnidirectional images. Besides, to approximate real applications, the proposed OIQ-10K database contains not only homogeneous distortion, but also heterogeneous distortion. The comparison of the proposed OIQ-10K database and the existing databases is listed in Table~\ref{tab:databases_summary}.


\subsection{Objective OIQA Models}
\label{subsec:oiqa_method}

A straightforward method to estimate the quality of omnidirectional images is to apply or slightly modify 2D-IQA models according to the sphere characteristic of images, such as PSNR-based models ____ and SSIM-based models ____. This type of model is far from being consistent with human ratings due to their limited quality-aware representation ability and the overlook of human behaviors____. Recently, many deep-learning-based methods have been proposed and shown promising performance. Some of them accept the omnidirectional image in the format of equirectangular projection (ERP) or cubemap projection (CMP) ____ directly. Considering the limited field of view, several researchers introduced the concept of viewport to design OIQA models. Sun~\et____ extracted six viewports from each omnidirectional image to cover the full visual content and enlarge the training samples by repeating this process with varying starting angles. Xu~\et____ and Fu~\et____ adopted the graph neural network to aggregate viewport quality. Other than using a viewport sequence to represent an omnidirectional image, some studies have also considered users' viewing behavior. Yang~\et____ proposed a trajectory-guided OIQA model, which is jointly optimized by OIQA and head trajectory prediction. Wu~\et____ designed a recursive probability sampling scheme to simulate users' browsing process and generate multiple pseudo viewport sequences from a given starting point.

Overall, these OIQA models achieve great results in capturing the quality of homogeneously distorted omnidirectional images; however, they overlook the exploration of heterogeneously distorted omnidirectional images that exist in the real world. In addition, a single quality representation, \emph{i.e.}, relying on a value to characterize image quality, could limit its ability in practical application.
\subsection{IQC Models}
\label{subsec:iqc_method}

Image captioning, which bridges computer vision and natural language processing using artificial intelligence techniques, aims to automatically generate a description about the \textit{content} and \textit{semantic} of an image____, \eg, \textit{a person is sitting on a chair next to a very small house}, rather than a global-wise single category or a pixel-wise semantic classification map____. Likewise, the objective of IQC is to describe the \textit{visual quality} using one sentence, \eg, \textit{local details are observably distorted, regional contours are slightly distorted, and global concepts are basically undistorted}____, which has richer information about visual quality than a single quantitative value. Following this idea, Yang~\et____ presented an initial study on IQC by considering it as a needs-oriented task and designed an attentive and recurrent semantic attractor network to address this problem. Latter, Yang~\et____~extended their previous work____ in a bi-directional manner. Note that IQC in both of these two works is formulated as a multiclass classification problem, and the quality description is generated by a feat of the pre-defined textual template. Similarly, Zhang~\et____ proposed to use the pre-defined textual template to construct the vision-language correspondence and optimize the joint probability over multiple tasks. Except for using hand-crafted templates to promote the learning of quality-aware visual features, some researchers have also attempted to use the \textit{users' comments} to assist in model training____. 



\begin{figure}[t]
\centering
\subfigure[CVIQD]{
\includegraphics[width=0.29\linewidth]{figs/data_analysis/SI_CI/fix_axis_cviq_si_cf_ref.jpg}
}
\subfigure[OIQA]{
\includegraphics[width=0.29\linewidth]{figs/data_analysis/SI_CI/fix_axis_oiqa_si_cf_ref.jpg}
}
\subfigure[LIVE 3D VR IQA]{
\includegraphics[width=0.29\linewidth]{figs/data_analysis/SI_CI/fix_axis_live3dvr_si_cf_ref.jpg}
}
\subfigure[MVAQD]{
\includegraphics[width=0.29\linewidth]{figs/data_analysis/SI_CI/fix_axis_mvaqd_si_cf_ref.jpg}
}
\subfigure[NBU-SOID]{
\includegraphics[width=0.29\linewidth]{figs/data_analysis/SI_CI/fix_axis_nbu-soid_si_cf_ref.jpg}
}
\subfigure[IQA-ODI]{
\includegraphics[width=0.29\linewidth]{figs/data_analysis/SI_CI/fix_axis_iqa-odi_si_cf_ref.jpg}
}
\subfigure[JUFE]{
\includegraphics[width=0.29\linewidth]{figs/data_analysis/SI_CI/fix_axis_jufe_si_cf_ref.jpg}
}
\subfigure[OIQ-10K]{
\includegraphics[width=0.29\linewidth]{figs/data_analysis/SI_CI/fix_axis_oiq-10k_si_cf_ref.jpg}
}
\caption{The scatter plots of Spatial Information (SI) and Colorfulness (CF) of existing OIQA databases and the proposed OIQ-10K database.}
\label{fig:si_cf}
\end{figure}

%------------------------------------------------------------------------