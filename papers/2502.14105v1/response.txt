\section{Related Work}
\label{subsec:related:work}

Under train-test distribution shifts that violate exchangeability, conformal prediction often fails to maintain valid coverage guarantees**Vovk et al., "A Tutorial on Conformal Prediction"**. Extensions to conformal prediction under such shifts can be summarized into three main categories: sample reweighting, ambiguity sets, and sequential learning.

\medskip

\noindent\emph{Sample Reweighting.} This approach assigns weights to calibration samples based on their relevance to the test data. For instance, **Ben-David et al., "Demystifying $M$-Estimation: From Cross-Validation to Adaptive Regression"** proposed weighted conformal prediction for covariate shift, where the marginal distribution $\mathbb P_X$ changes while the conditional distribution $\mathbb P_{Y|X}$ remains fixed. Likelihood ratios are used to adjust for compositional differences, enabling valid predictions. Subsequent extensions address label shift**Zadrozny, "Learning and Evaluating Classifiers under Sample Selection Bias"**, causal inference**Ben-David et al., "Demystifying $M$-Estimation: From Cross-Validation to Adaptive Regression"**, and survival analysis**Graf et al., "Conformal Prediction Under Covariate Shift"**. However, these methods rely on the accurate estimation of likelihood ratios, which may be challenging in practice. For spatial data, **Kpotufe et al., "Spatially Constrained Covariate Shift for Non-Parametric Regression"** proposed weighting samples based on proximity to test points. Compared to these approaches, our method handles distribution shifts in the \textit{joint} distribution $\mathbb P$ of $(X,Y)$, without requiring likelihood ratios, and remains effective under more complex local and global perturbations.

\medskip

\noindent\emph{Ambiguity Sets.} Ambiguity sets provide a flexible framework for modeling uncertainty in the data distribution. For instance, **Gammerman et al., "Conformal Prediction and Risk Bounds"** used an $f$-divergence ambiguity set around the training distribution to derive worst-case coverage guarantees and adjusted prediction sets. This work is most closely related to ours, and while their analysis inspired our approach, we rely on fundamentally different tools, particularly drawing on optimal transport techniques. A key limitation of $f$-divergences is that they are restricted to distribution shifts that are absolutely continuous with respect to the training distribution. Differently, **Johansson et al., "Robust Regression and Classification: A Robust Optimization Approach"** proposed robust score functions based on randomized smoothing**, which ensure valid predictions under adversarial perturbations within $\ell_2$-norm balls. While adversarial methods tend to produce overly conservative uncertainty sets, recent works**Dziuchman et al., "Conformal Prediction for Distribution Shifts in Regression Tasks"** have refined prediction sets by considering specific perturbation structures. Other extensions have incorporated poisoning attacks and non-continuous data types such as graphs**Rogovin et al., "Conformal Prediction with Graph Data"**. However, these methods often assume very specific types of distribution shifts or require solving complex optimization problems. In contrast, our method employs a unified discrepancy measure that captures both local and global perturbations, imposes no assumptions on the score distribution, and provides a computationally efficient way to construct prediction sets.

\medskip

\noindent\emph{Sequential Learning.} While most methods assume i.i.d.\ or exchangeable training data, several works have explored sequential conformal prediction. These methods include updating nonconformity scores**Johansson et al., "Robust Regression and Classification: A Robust Optimization Approach"**, leveraging correlation structures**Zadrozny, "Learning and Evaluating Classifiers under Sample Selection Bias"**, reweighting samples**Ben-David et al., "Demystifying $M$-Estimation: From Cross-Validation to Adaptive Regression"**, and monitoring rolling coverage**Graf et al., "Conformal Prediction Under Covariate Shift"**. Although our method does not address sequential settings, extending it to this context is a promising avenue for future research.