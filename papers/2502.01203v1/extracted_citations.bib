@article{chegini2024salsa,
  title={SALSA: Soup-based Alignment Learning for Stronger Adaptation in RLHF},
  author={Chegini, Atoosa and Kazemi, Hamid and Mirzadeh, Iman and Yin, Dong and Horton, Maxwell and Nabi, Moin and Farajtabar, Mehrdad and Alizadeh, Keivan},
  journal={arXiv preprint arXiv:2411.01798},
  year={2024}
}

@article{cohen2017data,
  title={Data-driven nonlinear expectations for statistical uncertainty in decisions},
  author={Cohen, Samuel N},
  journal={Electronic Journal of Statistics},
  volume={11},
  pages={1858--1889},
  year={2017}
}

@article{le2024multi,
  title={Multi-Reference Preference Optimization for Large Language Models},
  author={Le, Hung and Tran, Quan and Nguyen, Dung and Do, Kien and Mittal, Saloni and Ogueji, Kelechi and Venkatesh, Svetha},
  journal={arXiv preprint arXiv:2405.16388},
  year={2024}
}

@inproceedings{song2024importance,
  title={The importance of online data: Understanding preference fine-tuning via coverage},
  author={Song, Yuda and Swamy, Gokul and Singh, Aarti and Bagnell, Drew and Sun, Wen},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}

@article{sun2024inverse,
  title={Inverse-RLignment: Inverse Reinforcement Learning from Demonstrations for LLM Alignment},
  author={Sun, Hao and van der Schaar, Mihaela},
  journal={arXiv preprint arXiv:2405.15624},
  year={2024}
}

@inproceedings{wangbeyond,
  title={Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints},
  author={Wang, Chaoqi and Jiang, Yibo and Yang, Chenghao and Liu, Han and Chen, Yuxin},
  booktitle={The Twelfth International Conference on Learning Representations},
  year = {2024}  
}

@inproceedings{wortsman2022model,
  title={Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Gadre, Samir Ya and Roelofs, Rebecca and Gontijo-Lopes, Raphael and Morcos, Ari S and Namkoong, Hongseok and Farhadi, Ali and Carmon, Yair and Kornblith, Simon and others},
  booktitle={International conference on machine learning},
  pages={23965--23998},
  year={2022},
  organization={PMLR}
}

@inproceedings{xiong2024iterative,
  title={Iterative preference learning from human feedback: Bridging theory and practice for rlhf under kl-constraint},
  author={Xiong, Wei and Dong, Hanze and Ye, Chenlu and Wang, Ziqi and Zhong, Han and Ji, Heng and Jiang, Nan and Zhang, Tong},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@article{ye2024theoretical,
  title={A theoretical analysis of nash learning from human feedback under general kl-regularized preference},
  author={Ye, Chenlu and Xiong, Wei and Zhang, Yuheng and Jiang, Nan and Zhang, Tong},
  journal={arXiv preprint arXiv:2402.07314},
  year={2024}
}

@article{zhan2023provable,
  title={Provable offline preference-based reinforcement learning},
  author={Zhan, Wenhao and Uehara, Masatoshi and Kallus, Nathan and Lee, Jason D and Sun, Wen},
  journal={arXiv preprint arXiv:2305.14816},
  year={2023}
}

@article{zhao2024sharp,
  title={Sharp Analysis for KL-Regularized Contextual Bandits and RLHF},
  author={Zhao, Heyang and Ye, Chenlu and Gu, Quanquan and Zhang, Tong},
  journal={arXiv preprint arXiv:2411.04625},
  year={2024}
}

