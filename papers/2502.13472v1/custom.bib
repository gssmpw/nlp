% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").


@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@inproceedings{cieri2004fisher,
  title={The Fisher corpus: A resource for the next generations of speech-to-text.},
  author={Cieri, Christopher and Miller, David and Walker, Kevin},
  booktitle={LREC},
  volume={4},
  pages={69--71},
  year={2004}
}
@article{skantze2021turn,
  title={Turn-taking in conversational systems and human-robot interaction: a review},
  author={Skantze, Gabriel},
  journal={Computer Speech \& Language},
  volume={67},
  pages={101178},
  year={2021},
  publisher={Elsevier}
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{fu2024vita,
  title={Vita: Towards open-source interactive omni multimodal llm},
  author={Fu, Chaoyou and Lin, Haojia and Long, Zuwei and Shen, Yunhang and Zhao, Meng and Zhang, Yifan and Dong, Shaoqi and Wang, Xiong and Yin, Di and Ma, Long and others},
  journal={arXiv preprint arXiv:2408.05211},
  year={2024}
}

@article{shinn2008object,
  title={Object-based auditory and visual attention},
  author={Shinn-Cunningham, Barbara G},
  journal={Trends in cognitive sciences},
  volume={12},
  number={5},
  pages={182--186},
  year={2008},
  publisher={Elsevier}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

@misc{wang2024freezeomnismartlowlatency,
      title={Freeze-Omni: A Smart and Low Latency Speech-to-speech Dialogue Model with Frozen LLM}, 
      author={Xiong Wang and Yangze Li and Chaoyou Fu and Yunhang Shen and Lei Xie and Ke Li and Xing Sun and Long Ma},
      year={2024},
      eprint={2411.00774},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2411.00774}, 
}

@misc{lakhotia2021generativespokenlanguagemodeling,
      title={Generative Spoken Language Modeling from Raw Audio}, 
      author={Kushal Lakhotia and Evgeny Kharitonov and Wei-Ning Hsu and Yossi Adi and Adam Polyak and Benjamin Bolte and Tu-Anh Nguyen and Jade Copet and Alexei Baevski and Adelrahman Mohamed and Emmanuel Dupoux},
      year={2021},
      eprint={2102.01192},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2102.01192}, 
}

@misc{borsos2023audiolmlanguagemodelingapproach,
      title={AudioLM: a Language Modeling Approach to Audio Generation}, 
      author={Zalán Borsos and Raphaël Marinier and Damien Vincent and Eugene Kharitonov and Olivier Pietquin and Matt Sharifi and Dominik Roblek and Olivier Teboul and David Grangier and Marco Tagliasacchi and Neil Zeghidour},
      year={2023},
      eprint={2209.03143},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2209.03143}, 
}

@misc{openai2024gpt4ocard,
      title={GPT-4o System Card}, 
      author={Aaron Hurst and Adam Lere and Adam P Goucher and Adam Perelman and Aditya Ramesh and Aidan Clark and AJ Ostrow and Akila Welihinda and Alan Hayes and Alec Radford and et al.},
      year={2024},
      eprint={2410.21276},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.21276}, 
}

@misc{défossez2024moshispeechtextfoundationmodel,
      title={Moshi: a speech-text foundation model for real-time dialogue}, 
      author={Alexandre Défossez and Laurent Mazaré and Manu Orsini and Amélie Royer and Patrick Pérez and Hervé Jégou and Edouard Grave and Neil Zeghidour},
      year={2024},
      eprint={2410.00037},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2410.00037}, 
}

@inproceedings{Lin_2022, series={KDD ’22},
   title={Duplex Conversation: Towards Human-like Interaction in Spoken Dialogue Systems},
   url={http://dx.doi.org/10.1145/3534678.3539209},
   DOI={10.1145/3534678.3539209},
   booktitle={Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
   publisher={ACM},
   author={Lin, Ting-En and Wu, Yuchuan and Huang, Fei and Si, Luo and Sun, Jian and Li, Yongbin},
   year={2022},
   month=aug, pages={3299–3308},
   collection={KDD ’22} }

@misc{wang2024fullduplexspeechdialoguescheme,
      title={A Full-duplex Speech Dialogue Scheme Based On Large Language Models}, 
      author={Peng Wang and Songshuo Lu and Yaohua Tang and Sijie Yan and Wei Xia and Yuanjun Xiong},
      year={2024},
      eprint={2405.19487},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.19487}, 
}

@misc{chen2025minmomultimodallargelanguage,
      title={MinMo: A Multimodal Large Language Model for Seamless Voice Interaction}, 
      author={Qian Chen and Yafeng Chen and Yanni Chen and Mengzhe Chen and Yingda Chen and Chong Deng and Zhihao Du and et al.},
      year={2025},
      eprint={2501.06282},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.06282}, 
}

@misc{ma2024languagemodellistenspeaking,
      title={Language Model Can Listen While Speaking}, 
      author={Ziyang Ma and Yakun Song and Chenpeng Du and Jian Cong and Zhuo Chen and Yuping Wang and Yuxuan Wang and Xie Chen},
      year={2024},
      eprint={2408.02622},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.02622}, 
}

@misc{veluri2024turnbasedinterfacessynchronousllms,
      title={Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents}, 
      author={Bandhav Veluri and Benjamin N Peloquin and Bokai Yu and Hongyu Gong and Shyamnath Gollakota},
      year={2024},
      eprint={2409.15594},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.15594}, 
}

@misc{zhang2025omniflattenendtoendgptmodel,
      title={OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation}, 
      author={Qinglin Zhang and Luyao Cheng and Chong Deng and Qian Chen and Wen Wang and Siqi Zheng and Jiaqing Liu and Hai Yu and Chaohong Tan and Zhihao Du and Shiliang Zhang},
      year={2025},
      eprint={2410.17799},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.17799}, 
}

@misc{mai2025realtimetextlessdialoguegeneration,
      title={Real-Time Textless Dialogue Generation}, 
      author={Long Mai and Julie Carson-Berndsen},
      year={2025},
      eprint={2501.04877},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.04877}, 
}

@misc{ma2024embarrassinglysimpleapproachllm,
      title={An Embarrassingly Simple Approach for LLM with Strong ASR Capacity}, 
      author={Ziyang Ma and Guanrou Yang and Yifan Yang and Zhifu Gao and Jiaming Wang and Zhihao Du and Fan Yu and Qian Chen and Siqi Zheng and Shiliang Zhang and Xie Chen},
      year={2024},
      eprint={2402.08846},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.08846}, 
}

@misc{bai2024seedasrunderstandingdiversespeech,
      title={Seed-ASR: Understanding Diverse Speech and Contexts with LLM-based Speech Recognition}, 
      author={Ye Bai and Jingping Chen and Jitong Chen and Wei Chen and Zhuo Chen and Chuang Ding and Linhao Dong and Qianqian Dong and Yujiao Du and Kepan Gao and Lu Gao and Yi Guo and Minglun Han and Ting Han and Wenchao Hu and Xinying Hu and Yuxiang Hu and Deyu Hua and Lu Huang and Mingkun Huang and Youjia Huang and Jishuo Jin and Fanliu Kong and Zongwei Lan and Tianyu Li and Xiaoyang Li and Zeyang Li and Zehua Lin and Rui Liu and Shouda Liu and Lu Lu and Yizhou Lu and Jingting Ma and Shengtao Ma and Yulin Pei and Chen Shen and Tian Tan and Xiaogang Tian and Ming Tu and Bo Wang and Hao Wang and Yuping Wang and Yuxuan Wang and Hanzhang Xia and Rui Xia and Shuangyi Xie and Hongmin Xu and Meng Yang and Bihong Zhang and Jun Zhang and Wanyi Zhang and Yang Zhang and Yawei Zhang and Yijie Zheng and Ming Zou},
      year={2024},
      eprint={2407.04675},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2407.04675}, 
}

@misc{lian2024affectgptdatasetframeworkexplainable,
      title={AffectGPT: Dataset and Framework for Explainable Multimodal Emotion Recognition}, 
      author={Zheng Lian and Haiyang Sun and Licai Sun and Jiangyan Yi and Bin Liu and Jianhua Tao},
      year={2024},
      eprint={2407.07653},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2407.07653}, 
}

@misc{lin2024advancinglargelanguagemodels,
      title={Advancing Large Language Models to Capture Varied Speaking Styles and Respond Properly in Spoken Conversations}, 
      author={Guan-Ting Lin and Cheng-Han Chiang and Hung-yi Lee},
      year={2024},
      eprint={2402.12786},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.12786}, 
}

@misc{hao2023boostinglargelanguagemodel,
      title={Boosting Large Language Model for Speech Synthesis: An Empirical Study}, 
      author={Hongkun Hao and Long Zhou and Shujie Liu and Jinyu Li and Shujie Hu and Rui Wang and Furu Wei},
      year={2023},
      eprint={2401.00246},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.00246}, 
}

@misc{neekhara2024improvingrobustnessllmbasedspeech,
      title={Improving Robustness of LLM-based Speech Synthesis by Learning Monotonic Alignment}, 
      author={Paarth Neekhara and Shehzeen Hussain and Subhankar Ghosh and Jason Li and Rafael Valle and Rohan Badlani and Boris Ginsburg},
      year={2024},
      eprint={2406.17957},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2406.17957}, 
}

@misc{anastassiou2024seedttsfamilyhighqualityversatile,
      title={Seed-TTS: A Family of High-Quality Versatile Speech Generation Models}, 
      author={Philip Anastassiou and Jiawei Chen and et al.},
      year={2024},
      eprint={2406.02430},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2406.02430}, 
}

@misc{zhang2023speechgptempoweringlargelanguage,
      title={SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities}, 
      author={Dong Zhang and Shimin Li and Xin Zhang and Jun Zhan and Pengyu Wang and Yaqian Zhou and Xipeng Qiu},
      year={2023},
      eprint={2305.11000},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.11000}, 
}

@misc{du2024lauragptlistenattendunderstand,
      title={LauraGPT: Listen, Attend, Understand, and Regenerate Audio with GPT}, 
      author={Zhihao Du and Jiaming Wang and Qian Chen and Yunfei Chu and Zhifu Gao and Zerui Li and Kai Hu and Xiaohuan Zhou and Jin Xu and Ziyang Ma and Wen Wang and Siqi Zheng and Chang Zhou and Zhijie Yan and Shiliang Zhang},
      year={2024},
      eprint={2310.04673},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2310.04673}, 
}

@misc{fu2024vitaopensourceinteractiveomni,
      title={VITA: Towards Open-Source Interactive Omni Multimodal LLM}, 
      author={Chaoyou Fu and Haojia Lin and Zuwei Long and Yunhang Shen and Meng Zhao and Yifan Zhang and Shaoqi Dong and Xiong Wang and Di Yin and Long Ma and Xiawu Zheng and Ran He and Rongrong Ji and Yunsheng Wu and Caifeng Shan and Xing Sun},
      year={2024},
      eprint={2408.05211},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.05211}, 
}

@misc{ji2024wavchatsurveyspokendialogue,
      title={WavChat: A Survey of Spoken Dialogue Models}, 
      author={Shengpeng Ji and Yifu Chen and Minghui Fang and Jialong Zuo and Jingyu Lu and Hanting Wang and Ziyue Jiang and Long Zhou and Shujie Liu and Xize Cheng and Xiaoda Yang and Zehan Wang and Qian Yang and Jian Li and Yidi Jiang and Jingzhen He and Yunfei Chu and Jin Xu and Zhou Zhao},
      year={2024},
      eprint={2411.13577},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2411.13577}, 
}

@misc{zeng2024glm4voiceintelligenthumanlikeendtoend,
      title={GLM-4-Voice: Towards Intelligent and Human-Like End-to-End Spoken Chatbot}, 
      author={Aohan Zeng and Zhengxiao Du and Mingdao Liu and Kedong Wang and Shengmin Jiang and Lei Zhao and Yuxiao Dong and Jie Tang},
      year={2024},
      eprint={2412.02612},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.02612}, 
}

@misc{yao2024minicpmvgpt4vlevelmllm,
      title={MiniCPM-V: A GPT-4V Level MLLM on Your Phone}, 
      author={Yuan Yao and Tianyu Yu and Ao Zhang and Chongyi Wang and Junbo Cui and Hongji Zhu and Tianchi Cai and Haoyu Li and Weilin Zhao and Zhihui He and Qianyu Chen and Huarong Zhou and Zhensheng Zou and Haoye Zhang and Shengding Hu and Zhi Zheng and Jie Zhou and Jie Cai and Xu Han and Guoyang Zeng and Dahai Li and Zhiyuan Liu and Maosong Sun},
      year={2024},
      eprint={2408.01800},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.01800}, 
}

@inproceedings{ten2004turn,
  title={Turn-taking in social talk dialogues: temporal, formal and functional aspects},
  author={Ten Bosch, Louis and Oostdijk, Nelleke and De Ruiter, Jan Peter},
  booktitle={9th International Conference Speech and Computer (SPECOM'2004)},
  pages={454--461},
  year={2004}
}


@article{ekstedt2020turngpt,
  title={Turngpt: a transformer-based language model for predicting turn-taking in spoken dialog},
  author={Ekstedt, Erik and Skantze, Gabriel},
  journal={arXiv preprint arXiv:2010.10874},
  year={2020}
}

@article{yang2024qwen2,
  title={Qwen2. 5 technical report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024}
}

@article{chu2024qwen2,
  title={Qwen2-audio technical report},
  author={Chu, Yunfei and Xu, Jin and Yang, Qian and Wei, Haojie and Wei, Xipin and Guo, Zhifang and Leng, Yichong and Lv, Yuanjun and He, Jinzheng and Lin, Junyang and others},
  journal={arXiv preprint arXiv:2407.10759},
  year={2024}
}

@misc{openai2024o1mini,
  author = {{OpenAI}},
  title  = {OpenAI O1 Mini: Advancing Cost-Efficient Reasoning},
  year   = {2024},
  url    = {https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/},
}

@article{borsos2023audiolm,
  title={Audiolm: a language modeling approach to audio generation},
  author={Borsos, Zal{\'a}n and Marinier, Rapha{\"e}l and Vincent, Damien and Kharitonov, Eugene and Pietquin, Olivier and Sharifi, Matt and Roblek, Dominik and Teboul, Olivier and Grangier, David and Tagliasacchi, Marco and others},
  journal={IEEE/ACM transactions on audio, speech, and language processing},
  volume={31},
  pages={2523--2533},
  year={2023},
  publisher={IEEE}
}

@misc{silero2021vad,
  author = {{Silero Team}},
  title  = {Silero VAD: pre-trained enterprise-grade Voice Activity Detector (VAD), Number Detector and Language Classifier},
  year   = {2021},
  url    = {https://github.com/snakers4/silero-vad}
}

@article{das2024speechverse,
  title={Speechverse: A large-scale generalizable audio language model},
  author={Das, Nilaksh and Dingliwal, Saket and Ronanki, Srikanth and Paturi, Rohit and Huang, Zhaocheng and Mathur, Prashant and Yuan, Jie and Bekal, Dhanush and Niu, Xing and Jayanthi, Sai Muralidhar and others},
  journal={arXiv preprint arXiv:2405.08295},
  year={2024}
}


@article{xie2024mini,
  title={Mini-omni2: Towards open-source gpt-4o with vision, speech and duplex capabilities},
  author={Xie, Zhifei and Wu, Changqiao},
  journal={arXiv preprint arXiv:2410.11190},
  year={2024}
}

@inproceedings{huang2024audiogpt,
  title={Audiogpt: Understanding and generating speech, music, sound, and talking head},
  author={Huang, Rongjie and Li, Mingze and Yang, Dongchao and Shi, Jiatong and Chang, Xuankai and Ye, Zhenhui and Wu, Yuning and Hong, Zhiqing and Huang, Jiawei and Liu, Jinglin and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  pages={23802--23804},
  year={2024}
}

@article{zhang2024speechgpt,
  title={SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation},
  author={Zhang, Dong and Zhang, Xin and Zhan, Jun and Li, Shimin and Zhou, Yaqian and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2401.13527},
  year={2024}
}

@article{fang2024llama,
  title={Llama-omni: Seamless speech interaction with large language models},
  author={Fang, Qingkai and Guo, Shoutao and Zhou, Yan and Ma, Zhengrui and Zhang, Shaolei and Feng, Yang},
  journal={arXiv preprint arXiv:2409.06666},
  year={2024}
}

@article{ramirez2004efficient,
  title={Efficient voice activity detection algorithms using long-term speech information},
  author={Ram{\i}rez, Javier and Segura, Jos{\'e} C and Ben{\i}tez, Carmen and De La Torre, Angel and Rubio, Antonio},
  journal={Speech communication},
  volume={42},
  number={3-4},
  pages={271--287},
  year={2004},
  publisher={Elsevier}
}

@article{mihalache2022using,
  title={Using voice activity detection and deep neural networks with hybrid speech feature extraction for deceptive speech detection},
  author={Mihalache, Serban and Burileanu, Dragos},
  journal={Sensors},
  volume={22},
  number={3},
  pages={1228},
  year={2022},
  publisher={MDPI}
}

@article{deng2013statistical,
  title={Statistical voice activity detection based on sparse representation over learned dictionary},
  author={Deng, Shi-Wen and Han, Ji-Qing},
  journal={Digital Signal Processing},
  volume={23},
  number={4},
  pages={1228--1232},
  year={2013},
  publisher={Elsevier}
}

@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}
