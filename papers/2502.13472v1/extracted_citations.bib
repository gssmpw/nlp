@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}

@misc{du2024lauragptlistenattendunderstand,
      title={LauraGPT: Listen, Attend, Understand, and Regenerate Audio with GPT}, 
      author={Zhihao Du and Jiaming Wang and Qian Chen and Yunfei Chu and Zhifu Gao and Zerui Li and Kai Hu and Xiaohuan Zhou and Jin Xu and Ziyang Ma and Wen Wang and Siqi Zheng and Chang Zhou and Zhijie Yan and Shiliang Zhang},
      year={2024},
      eprint={2310.04673},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2310.04673}, 
}

@misc{défossez2024moshispeechtextfoundationmodel,
      title={Moshi: a speech-text foundation model for real-time dialogue}, 
      author={Alexandre Défossez and Laurent Mazaré and Manu Orsini and Amélie Royer and Patrick Pérez and Hervé Jégou and Edouard Grave and Neil Zeghidour},
      year={2024},
      eprint={2410.00037},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2410.00037}, 
}

@article{ekstedt2020turngpt,
  title={Turngpt: a transformer-based language model for predicting turn-taking in spoken dialog},
  author={Ekstedt, Erik and Skantze, Gabriel},
  journal={arXiv preprint arXiv:2010.10874},
  year={2020}
}

@misc{fu2024vitaopensourceinteractiveomni,
      title={VITA: Towards Open-Source Interactive Omni Multimodal LLM}, 
      author={Chaoyou Fu and Haojia Lin and Zuwei Long and Yunhang Shen and Meng Zhao and Yifan Zhang and Shaoqi Dong and Xiong Wang and Di Yin and Long Ma and Xiawu Zheng and Ran He and Rongrong Ji and Yunsheng Wu and Caifeng Shan and Xing Sun},
      year={2024},
      eprint={2408.05211},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.05211}, 
}

@misc{ma2024languagemodellistenspeaking,
      title={Language Model Can Listen While Speaking}, 
      author={Ziyang Ma and Yakun Song and Chenpeng Du and Jian Cong and Zhuo Chen and Yuping Wang and Yuxuan Wang and Xie Chen},
      year={2024},
      eprint={2408.02622},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.02622}, 
}

@misc{wang2024freezeomnismartlowlatency,
      title={Freeze-Omni: A Smart and Low Latency Speech-to-speech Dialogue Model with Frozen LLM}, 
      author={Xiong Wang and Yangze Li and Chaoyou Fu and Yunhang Shen and Lei Xie and Ke Li and Xing Sun and Long Ma},
      year={2024},
      eprint={2411.00774},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2411.00774}, 
}

@misc{wang2024fullduplexspeechdialoguescheme,
      title={A Full-duplex Speech Dialogue Scheme Based On Large Language Models}, 
      author={Peng Wang and Songshuo Lu and Yaohua Tang and Sijie Yan and Wei Xia and Yuanjun Xiong},
      year={2024},
      eprint={2405.19487},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.19487}, 
}

@misc{zhang2023speechgptempoweringlargelanguage,
      title={SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities}, 
      author={Dong Zhang and Shimin Li and Xin Zhang and Jun Zhan and Pengyu Wang and Yaqian Zhou and Xipeng Qiu},
      year={2023},
      eprint={2305.11000},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.11000}, 
}

