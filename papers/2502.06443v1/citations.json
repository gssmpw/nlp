[
  {
    "index": 0,
    "papers": [
      {
        "key": "ba2022high",
        "author": "Ba, Jimmy and Erdogdu, Murat A and Suzuki, Taiji and Wang, Zhichao and Wu, Denny and Yang, Greg",
        "title": "High-dimensional asymptotics of feature learning: How one gradient step improves the representation"
      },
      {
        "key": "damian2022neural",
        "author": "Damian, Alexandru and Lee, Jason and Soltanolkotabi, Mahdi",
        "title": "Neural networks can learn representations with gradient descent"
      },
      {
        "key": "dandi2023two",
        "author": "Dandi, Yatin and Krzakala, Florent and Loureiro, Bruno and Pesce, Luca and Stephan, Ludovic",
        "title": "How two-layer neural networks learn, one (giant) step at a time"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "arous2021online",
        "author": "Ben Arous, Gerard and Gheissari, Reza and Jagannath, Aukosh",
        "title": "Online stochastic gradient descent on non-convex losses from high-dimensional inference"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "damian2024smoothing",
        "author": "Damian, Alex and Nichani, Eshaan and Ge, Rong and Lee, Jason D",
        "title": "Smoothing the landscape boosts the signal for {SGD}: Optimal sample complexity for learning single index models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "bietti2022learning",
        "author": "Bietti, Alberto and Bruna, Joan and Sanford, Clayton and Song, Min Jae",
        "title": "Learning single-index models with shallow neural networks"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "berthier2024learning",
        "author": "Berthier, Rapha{\\\"e}l and Montanari, Andrea and Zhou, Kangjie",
        "title": "Learning time-scales in two-layers neural networks"
      },
      {
        "key": "ben2022high",
        "author": "Ben Arous, Gerard and Gheissari, Reza and Jagannath, Aukosh",
        "title": "High-dimensional limit theorems for {SGD}: Effective dynamics and critical scaling"
      },
      {
        "key": "chen2023learning",
        "author": "Chen, Sitan and Dou, Zehao and Goel, Surbhi and Klivans, Adam and Meka, Raghu",
        "title": "Learning narrow one-hidden-layer {ReLU} networks"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "damian2024computational",
        "author": "Damian, Alex and Pillaud-Vivien, Loucas and Lee, Jason and Bruna, Joan",
        "title": "Computational-Statistical Gaps in {G}aussian Single-Index Models"
      },
      {
        "key": "dandi2024benefits",
        "author": "Dandi, Yatin and Troiani, Emanuele and Arnaboldi, Luca and Pesce, Luca and Zdeborov{\\'a}, Lenka and Krzakala, Florent",
        "title": "The benefits of reusing batches for gradient descent in two-layer networks: Breaking the curse of information and leap exponents"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "troiani2024fundamental",
        "author": "Troiani, Emanuele and Dandi, Yatin and Defilippis, Leonardo and Zdeborov{\\'a}, Lenka and Loureiro, Bruno and Krzakala, Florent",
        "title": "Fundamental limits of weak learnability in high-dimensional multi-index models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "arnaboldi2024repetita",
        "author": "Arnaboldi, Luca and Dandi, Yatin and Krzakala, Florent and Pesce, Luca and Stephan, Ludovic",
        "title": "Repetita iuvant: Data repetition allows {SGD} to learn high-dimensional multi-index functions"
      },
      {
        "key": "lee2024neural",
        "author": "Lee, Jason D and Oko, Kazusato and Suzuki, Taiji and Wu, Denny",
        "title": "Neural network learns low-dimensional polynomials with {SGD} near the information-theoretic limit"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "bietti2023learning",
        "author": "Bietti, Alberto and Bruna, Joan and Pillaud-Vivien, Loucas",
        "title": "On learning {G}aussian multi-index models with gradient flow"
      },
      {
        "key": "abbe2023sgd",
        "author": "Abbe, Emmanuel and Adsera, Enric Boix and Misiakiewicz, Theodor",
        "title": "{SGD} learning on neural networks: leap complexity and saddle-to-saddle dynamics"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "damian2024computational",
        "author": "Damian, Alex and Pillaud-Vivien, Loucas and Lee, Jason and Bruna, Joan",
        "title": "Computational-Statistical Gaps in {G}aussian Single-Index Models"
      },
      {
        "key": "dandi2024benefits",
        "author": "Dandi, Yatin and Troiani, Emanuele and Arnaboldi, Luca and Pesce, Luca and Zdeborov{\\'a}, Lenka and Krzakala, Florent",
        "title": "The benefits of reusing batches for gradient descent in two-layer networks: Breaking the curse of information and leap exponents"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "arnaboldi2024repetita",
        "author": "Arnaboldi, Luca and Dandi, Yatin and Krzakala, Florent and Pesce, Luca and Stephan, Ludovic",
        "title": "Repetita iuvant: Data repetition allows {SGD} to learn high-dimensional multi-index functions"
      },
      {
        "key": "lee2024neural",
        "author": "Lee, Jason D and Oko, Kazusato and Suzuki, Taiji and Wu, Denny",
        "title": "Neural network learns low-dimensional polynomials with {SGD} near the information-theoretic limit"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "troiani2024fundamental",
        "author": "Troiani, Emanuele and Dandi, Yatin and Defilippis, Leonardo and Zdeborov{\\'a}, Lenka and Loureiro, Bruno and Krzakala, Florent",
        "title": "Fundamental limits of weak learnability in high-dimensional multi-index models"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "yehudai2020learning",
        "author": "Yehudai, Gilad and Shamir, Ohad",
        "title": "Learning a single neuron with gradient methods"
      },
      {
        "key": "goel2020superpolynomial",
        "author": "Goel, Surbhi and Gollakota, Aravind and Jin, Zhihan and Karmalkar, Sushrut and Klivans, Adam",
        "title": "Superpolynomial lower bounds for learning one-layer neural networks using gradient descent"
      },
      {
        "key": "shamir2018distribution",
        "author": "Shamir, Ohad",
        "title": "Distribution-specific hardness of learning neural networks"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "frei2020agnostic",
        "author": "Frei, Spencer and Cao, Yuan and Gu, Quanquan",
        "title": "Agnostic learning of a single neuron with gradient descent"
      },
      {
        "key": "wu2022learning",
        "author": "Wu, Lei",
        "title": "Learning a single neuron for non-monotonic activation functions"
      },
      {
        "key": "song2021cryptographic",
        "author": "Song, Min Jae and Zadik, Ilias and Bruna, Joan",
        "title": "On the cryptographic hardness of learning single periodic neurons"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "ba2024learning",
        "author": "Ba, Jimmy and Erdogdu, Murat A and Suzuki, Taiji and Wang, Zhichao and Wu, Denny",
        "title": "Learning in the presence of low-dimensional structure: a spiked random matrix perspective"
      },
      {
        "key": "mousavi2023gradient",
        "author": "Mousavi-Hosseini, Alireza and Wu, Denny and Suzuki, Taiji and Erdogdu, Murat A",
        "title": "Gradient-based feature learning under structured data"
      },
      {
        "key": "nitanda2024improved",
        "author": "Nitanda, Atsushi and Oko, Kazusato and Suzuki, Taiji and Wu, Denny",
        "title": "Improved statistical and computational complexity of the mean-field {L}angevin dynamics under structured data"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "mousavi2023gradient",
        "author": "Mousavi-Hosseini, Alireza and Wu, Denny and Suzuki, Taiji and Erdogdu, Murat A",
        "title": "Gradient-based feature learning under structured data"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "zweig2024single",
        "author": "Zweig, Aaron and Pillaud-Vivien, Loucas and Bruna, Joan",
        "title": "On Single-Index Models beyond {G}aussian Data"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "zweig2024single",
        "author": "Zweig, Aaron and Pillaud-Vivien, Loucas and Bruna, Joan",
        "title": "On Single-Index Models beyond {G}aussian Data"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "soltanolkotabi2017learning",
        "author": "Soltanolkotabi, Mahdi",
        "title": "Learning relus via gradient descent"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "song2021cryptographic",
        "author": "Song, Min Jae and Zadik, Ilias and Bruna, Joan",
        "title": "On the cryptographic hardness of learning single periodic neurons"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "abbe2022merged",
        "author": "Abbe, Emmanuel and Boix-Adsera, Enric and Misiakiewicz, Theodor",
        "title": "The merged-staircase property: a necessary and nearly sufficient condition for sgd learning of sparse functions on two-layer neural networks"
      },
      {
        "key": "abbe2023sgd",
        "author": "Abbe, Emmanuel and Adsera, Enric Boix and Misiakiewicz, Theodor",
        "title": "{SGD} learning on neural networks: leap complexity and saddle-to-saddle dynamics"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "joshi2024complexity",
        "author": "Joshi, Nirmit and Misiakiewicz, Theodor and Srebro, Nathan",
        "title": "On the complexity of learning sparse functions with statistical and gradient queries"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "malach2021quantifying",
        "author": "Malach, Eran and Kamath, Pritish and Abbe, Emmanuel and Srebro, Nathan",
        "title": "Quantifying the benefit of using differentiable learning over tangent kernels"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "AS20",
        "author": "Abbe, Emmanuel and Sandon, Colin",
        "title": "On the universality of deep learning"
      },
      {
        "key": "shalev2014understanding",
        "author": "Shalev-Shwartz, Shai and Ben-David, Shai",
        "title": "Understanding machine learning: From theory to algorithms"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "cornacchia2023mathematical",
        "author": "Cornacchia, Elisabetta and Mossel, Elchanan",
        "title": "A mathematical model for curriculum learning for parities"
      },
      {
        "key": "abbe2023provable",
        "author": "Abbe, Emmanuel and Cornacchia, Elisabetta and Lotfi, Aryo",
        "title": "Provable advantage of curriculum learning on parity targets with mixed inputs"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "valiant2012finding",
        "author": "Valiant, Gregory",
        "title": "Finding correlations in subquadratic time, with applications to learning parities and juntas"
      },
      {
        "key": "mossel2004learning",
        "author": "Mossel, Elchanan and O'Donnell, Ryan and Servedio, Rocco A",
        "title": "Learning functions of k relevant variables"
      }
    ]
  }
]