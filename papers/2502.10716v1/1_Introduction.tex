\section{Introduction}\label{sec:main_intro}

Domain generalization (DG) aims to train a machine learning model on multiple data distributions so that it can generalize to unseen data distributions. Although challenging, DG is crucial for practical scenarios where there is a need to quickly deploy a prediction model on a new target domain without access to target data. Various approaches have been proposed to address the DG problem, which can be broadly categorized into $4$ families: representation alignment, invariant prediction, augmentation and  ensemble learning. 

\textit{Representation alignment} which is established based on domain adaptation \citep{ben2010theory, ben2001support, phung2021learning, zhou2020deep, johansson2019support}, mainly discuss the differences between source and target domains and focuses on learning domain-invariant representations by reducing the divergence between latent marginal distributions \citep{long2017conditional, ganin2016domain, nguyen2021domain, shen2018wasserstein, xie2017controllable, ilse2020diva} or class-conditional distributions \citep{gong2016domain, li2018deep, tachet2020domain}. 
%Limite: requre target domains

%li2018domain

\textit{Invariant prediction} approaches, grounded in causality theory, ensure stable performance regardless of the domain by learning a consistently optimal classifier \citep{arjovsky2020irm, ahuja2020empirical, krueger2021out, li2022invariant,mitrovic2020representation, zhang2023causal}. %However, these approaches  typically require sufficient number of diverse training domains.


% \citep{arjovsky2020irm, ahuja2020empirical, krueger2021out, rosenfeld2020risks, li2022invariant,mitrovic2020representation, zhang2023causal}

\textit{Data augmentation} applies predefined or learnable transformations on the original samples or their features to create augmented data, thereby enhancing the model's generalization capabilities \citep{mitrovic2020representation, wang2022out, zhou2020deep, zhou2021domain, zhang2017mixup, wang2020heterogeneous, zhao2020maximum, yao2022improving, carluccidomain, yao2022pcl}.  With sufficient and diverse causal-preserving transformations, the model's generalization can be effectively guaranteed \citep{wang2020heterogeneous}.
%xu2021fourier,shankar2018generalizing
% Need to explain the relationship between ensemble and first three methods

Recently, \textit{Ensemble Learning}, which explicitly involves training multiple instances of the same architecture with different initializations or splits of the training data then combining their predictions \citep{zhou2021domain, ding2017deep, zhou2021domain, wang2020dofe, mancini2018best, cha2021swad, arpit2022ensemble}. Alternatively, implicit ensemble methods that approximate ensembling by averaging model weights (WA) from training trajectories (e.g., checkpoints at different time steps) have been shown to significantly enhance robustness under domain shifts \citep{izmailov2018averaging, cha2021swad, rame2022diverse, wortsman2022robust}.
Despite their strong performance in DG, most theoretical analyses of ensemble learning remain concentrated on the perspective of flatness of the loss landscape, or uncertainty-aware frameworks, leaving the connection between ensemble and DG largely underexplored.

Although the conventional DG algorithms (\textit{representation alignment, invariant prediction, data augmentation}) are developed with strong theoretical foundations, these methods have not consistently outperformed Empirical Risk Minimization (ERM) on fair model selection criteria \citep{gulrajani2020search, idrissi2022simple, ye2022ood, chen2022does}. In contrast, \textit{Ensemble}-based approaches (e.g., SWAD \citep{cha2021swad})  demonstrate a substantial performance improvement over the ERM  and other conventional DG algorithms by a large margin. We argue that this phenomenon arises because the theoretical frameworks behind conventional DG algorithms typically establish generalization under conditions where target domains are either known or sufficiently diverse, or when a large number of training domains are available. As a result, the extent to which domain generalization can be achieved in practical scenarios, characterized by a limited and finite number of domains, remains elusive unexplored. 
\begin{table*}[t]
\caption{Summary of Conditions for Generalization}
\begin{centering}
\resizebox{\linewidth}{!}{ %
\begin{tabular}{llll}
\toprule
\textbf{Condition} & \textbf{Type}  & \textbf{Target DG approach}\\
\midrule
Label-identifiability (\ref{as:label_idf}) &Assumption \\
\midrule
Causal support (\ref{as:sufficient_causal_support}) &  Assumption  \\
\midrule
Optimal hypothesis for training domains (\ref{def:joint_optimal})& Necessary  & \\
\midrule
Optimal hypothesis for training domains $+$ Invariant representation function (\ref{thm:sufficient_conditions}.1) &  Sufficient & Representation alignment \\
\midrule
Optimal hypothesis for training domains $+$ Sufficient and diverse domains (\ref{thm:sufficient_conditions}.2) & Sufficient & Invariant prediction \\
\midrule
Optimal hypothesis for training domains $+$ Invariance-preserving transformations (\ref{thm:sufficient_conditions}.3) & Sufficient & Data augmentation \\
\midrule
\textbf{Invariance-preserving representation function} (\ref{def:sufficient}) & \textbf{Necessary} & Ensembles \\
\bottomrule
\end{tabular}}
\par\end{centering}
\label{tab:conditions}
\end{table*}
Our work aims to fill in this gap with a comprehensive study of DG in scenarios with limited training domains through the lens of necessary and sufficient conditions for achieving generalization. The contributions of this paper are summarized as follows:

\textbf{1. DG through the lens of Necessity and Sufficiency.} We systematically establish a set of necessary and sufficient conditions for generalization, highlighting that existing DG methods act as regularization mechanisms that predominantly focus on satisfying sufficient conditions while often neglecting necessary ones (see Section \ref{sec:main_conds}.1). However, sufficient conditions are non-verifiable with limited training domains. In such cases, we argue that regularization targeting sufficient conditions aims to maximize the likelihood of generalization, while regularization targeting necessary conditions ensures its existence (see Section \ref{sec:main_conds}.2). %This insight explains why current DG algorithms fail and provides a foundation for designing effective algorithms, as summarized in the following contributions.


% \textbf{3. DG through the lens of Necessity and Sufficiency.} We then shed light on how the DG dynamics is greatly reshaped in limited domain settings. When the sufficient conditions cannot be guaranteed, the necessary conditions in fact hold greater practical value in determining how to maximize the likelihood of achieving generalization (See Section \ref{sec:efficacy_DG}). This licenses a new view to understanding why DG algorithms fail to outperform the fundamental approach of empirical risk minimization (ERM) on standard benchmarks  (See Section \ref{sec:discussion_DG}). 
% \color{black}

\textbf{2. Why do conventional DG algorithms fail?} In Section~\ref{sec:discussion_DG}, we explain why conventional DG algorithms fail to consistently outperform the ERM baseline by demonstrating that, while they promote sufficient conditions, they may inadvertently violate necessary conditions.
We also establish a connection between the necessary conditions and the recent \textit{ensemble} strategy, demonstrating that \textit{ensemble} methods indeed encourage models to satisfy these conditions.

% We explain why \textit{sufficient representation function} (\ref{def:sufficient}) condition has often been overlooked in prior research i.e.,  when a sufficient condition (\ref{thm:invariant_correlation} or \ref{thm:convergence} in Table~\ref{tab:conditions}) is met, it automatically results in the fulfillment of both necessary conditions (\ref{def:joint_optimal} and \ref{def:sufficient} in Table~\ref{tab:conditions}. Then, we establish a connection between this condition and the recent \textit{ensemble} strategy, demonstrating that \textit{ensemble} methods indeed encourage models to satisfy this condition.
  
\textbf{3. Preserving Necessity in Representation Alignment.} Finally, we empirically validate our theories by introducing a practical method that encourages the \textit{sufficient condition} \underline{without violating} the \textit{necessary conditions} through a novel subspace representation alignment strategy. Our approach achieves superior performance across all experimental settings (see Section~\ref{sec:main_proposed_method}).

%\cite{kaur2022modeling} highlights the limitations of algorithms reliant on a singular, fixed independence constraint, noting their potential failure across various data shifts. They suggest a causally adaptive constraint approach, which dynamically identifies and applies appropriate independence constraints for regularization. 

 % Specifically, we provide insights into how ensemble methods can help address the sufficient representation constraint, while propose a {novel strategy to tackle the trade-offs of representation alignment.}