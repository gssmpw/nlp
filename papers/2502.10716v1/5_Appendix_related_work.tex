% \section{Additional Discussion with Related Works} \label{apd:relation_to_IDG}

% \paragraph{Optimal Representation \citep{ruan2021optimal}} 

% While at first glance, \citep{ruan2021optimal} and our work share the same goal of identifying the necessary and sufficient conditions for generalization, the two studies fundamentally differ in the following aspects:  

% \citet{ruan2021optimal} aim to identify the set of conditions that are both necessary and sufficient, which provide theoretical guarantee essentially by assuming some knowledge of target domains. Without accessing target information, generalization is provably impossible. Meanwhile, we focus on analyzing generalizability from limited domains without assuming any additional information from the target.    

% More concretely, \citet{ruan2021optimal} propose the \textit{idealized} domain generalization hypothesis (IDG), which is the expected worst-case target risk over source risk minimizers: 

% $$
%     R_{IDG}=\mathbb{E}_{{e_i,e_j}\sim \mathcal{P}}\left [ \sup_{f\in\mathcal{F}_{\mathbb{P}^{e_i}}}\mathcal{L}(f,\mathbb{P}^{e_i}) \right ]
% $$

% $R_{IDG}$ is an expectation over all possible pairs of domains $(e_i, e_j)\sim \mathcal{P}$ where $\mathcal{P}$ is the distribution over domain space $\mathcal{E}$. During training, they sample any two domains from the domain distribution, assigning one as the source and the other as the target, to determine the worst-case target risk. 

% The representation $Z = g(X)$ deemed optimal for IDG must satisfy two conditions (by Theorem 1 therein):

% \begin{itemize}
% \item Sufficient representation: the representation needs to be task-discriminative, allowing a predictor to minimize risk across all domains. In the presence of all domains, this condition can be simply satisfied by learning a hypothesis optimal for all training domains. 

% \item The representationâ€™s marginal support must be consistent across all pairs of source and target domains. This condition generally coincides with our assumption of causal support, which is a common assumption across DG literature. 
% \end{itemize}


% It is clear from the formulation $R_{IDG}$ that \textit{all} possible domains should be known to achieve generalization. \citet{ruan2021optimal} also point out the challenge in generalization without data from the target domain and recommends incorporating data augmentation from pre-trained models such as CLIP. To our best knowledge, using augmentation in DG is not new. Various studies have shown that access to all label-preserving augmentations (which is generally unfeasible) would reveal true causal factors \citep{mitrovic2020representation,gao2023out}. 
% To satisfy this condition, \citet{ruan2021optimal} assume augmentation is Bayes-preserving augmentation (Assumption 10 therein).
