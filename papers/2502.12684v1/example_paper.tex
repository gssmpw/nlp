%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
 \usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\usepackage{color, colortbl}
\definecolor{LightGrey}{gray}{0.9}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Federated Variational Inference for Bayesian Mixture Models
}

\begin{document}

\twocolumn[
\icmltitle{Federated Variational Inference for Bayesian Mixture Models
}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Jackie Rao}{cam}
\icmlauthor{Francesca L. Crowe}{comp}
\icmlauthor{Tom Marshall}{comp}
\icmlauthor{Sylvia Richardson}{cam}
\icmlauthor{Paul D. W. Kirk}{cam}
%\icmlauthor{Firstname6 Lastname6}{sch,yyy,comp}
%\icmlauthor{Firstname7 Lastname7}{comp}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{cam}{MRC Biostatistics Unit, University of Cambridge, Cambridge, United Kingdom}
\icmlaffiliation{comp}{Institute of Applied Health Research, University of Birmingham, Birmingham, United Kingdom}

\icmlcorrespondingauthor{Jackie Rao}{jackie.rao@mrc-bsu.cam.ac.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
    We present a federated learning approach for Bayesian model-based clustering of large-scale binary and categorical datasets. We introduce a principled `divide and conquerâ€™ inference procedure using variational inference with local merge and delete moves within batches of the data in parallel, followed by `global' merge moves across batches to find global clustering structures. We show that these merge moves require only summaries of the data in each batch, enabling federated learning across local nodes without requiring the full dataset to be shared.  Empirical results on simulated and benchmark datasets demonstrate that our method performs well in comparison to existing clustering algorithms. We validate the practical utility of the method by applying it to large scale electronic health record (EHR) data. 
\end{abstract}

\section{Introduction}

Federated learning (FL) refers to the setting in which a network of clients collaboratively train a model, while ensuring that the training data are kept local \citep{Kairouz2021}.  FL was introduced as a way to enable learning when datasets are large and/or privacy sensitive \citep{McMahan2017}.  There have been numerous developments in supervised FL, but methods for unsupervised FL remain limited \citep{Tian2024}.  While a number of federated clustering algorithms have been proposed \citep[e.g. federated $k$-means:][]{Kumar2020,Liu2020,Garst2025}, and Bayesian FL (BFL) is an active area of research \citep[see][for a survey]{IJCAI2023}, we are not aware of previous studies into FL for Bayesian model-based clustering, which we consider here.  

%Cluster analysis, the task of identifying groups of similar observations in data, is a widely used unsupervised learning technique. 
Mixture models provide a probabilistic approach for clustering by assuming data are generated from a mixture of underlying probability distributions. Bayesian mixture models enable the uncertainty in cluster allocations and, potentially, the number of clusters to be modelled. %to mixture modelling allow for prior knowledge to be incorporated and account for uncertainty in parameter estimates as the data increases in complexity. 
These include Bayesian finite mixture models \citep[e.g.][]{Diebolt1994,Richardson1997,Rousseau2011}, as well as Bayesian nonparametric methods, such as Dirichlet process (DP) mixture models \citep{Ferguson1973, Escobar1995}. %, which extend finite mixture models by allowing the number of clusters to grow with the data, although come with increased computational burden.  
Markov Chain Monte Carlo (MCMC), particularly Gibbs sampling \citep{Neal2000}, is often used to draw samples from the intractable posterior \citep[e.g.][]{Robert2004, Walker2007}. Despite efforts to improve scalability, MCMC algorithms are often too computationally intensive for even moderately large datasets, and/or may experience mixing issues, preventing the sampler from reaching convergence \citep{Celeux2000}. 

To address the growth of `massive' datasets, a range of methods have been proposed to scale MCMC algorithms to large sample sizes \citep[e.g][]{Huang2005}. These include distributed computing approaches in which the computational and memory requirements of an algorithm are split, with the algorithm running in parallel on multiple nodes \citep{Zhu2017}. An important example of this for Bayesian inference is {\em consensus Monte Carlo}, where a Monte Carlo algorithm is run on partitions of the data and samples are then aggregated across partitions to enable `global' inferences to be drawn \citep{Scott2016}. Various methods have been proposed to aggregate the subset posteriors. Informally, the challenge for clustering models is how to match clusters/cluster labels across data partitions. The SNOB \citep{Zuanetti2018} and SIGN \citep{Ni2019} algorithms have been proposed to address this. 

\enlargethispage{\baselineskip}

Distributed variational inference (VI) algorithms have also been proposed to obtain an approximation of the posterior distribution, including variational consensus Monte Carlo (VCMC) \citep{NIPS2015_e94550c9}. As noted in \citet{NIPS2015_e94550c9}, models with unidentifiable latent variables, such as component allocation labels in mixture models, present additional complexity for such approaches, and the authors suggested a heuristic approach using the Hungarian algorithm \citep{Kuhn1955} to align cluster centres across data partitions. Our proposed method instead utilises the variational objective function to allow us to combine results from data partitions in a statistically principled manner.

 While VI methods tend to have better run-time performance than MCMC algorithms \citep[e.g.][]{Blei2017}, %Methods employing mean-field variational Bayes are theoretically backed by well-established statistical principles whilst also being tractable and enable us to make approximate posterior predictions and quantify uncertainty.
they can also be sensitive to initialisation due to local optima in the objective function. To address these issues when fitting mixture models, `merge' and `delete' moves may be incorporated into the variational algorithm to dynamically combine or remove unnecessary clusters. Such moves, in addition to `split' moves to create new clusters, have been seen to improve inference in expectation-maximisation (EM) algorithms \citep{ueda_smem_2000} and MCMC samplers \citep{jain_split-merge_2004, Dahl2021} for mixture models, and have also been employed less commonly in VI algorithms for DP mixtures, including Gaussian DP mixture models \citep{pmlr-v38-hughes15, NIPS2013_8c19f571}, and the hierarchical DP \citep{hughes_memoized_2013}.  %Split moves are not included in our proposed model, but we show that merge and delete moves allow for improvements in model accuracy and efficiency.


Here we propose a distributed algorithm that performs inference for Bayesian mixture models using VI with local merge
and delete moves within batches of the data across a network of nodes in parallel, followed by `global' merge moves to aggregate clusters across batches. We show that these `global' moves require only summaries of the data from each node, enabling federated learning of the model without requiring the full dataset to be shared. We anticipate that the approach may be useful for the analysis of privacy sensitive datasets, and provide an example application clustering individual-level electronic health records (EHRs).

%Here we propose a divide-and-conquer VI approach that uses merge moves to aggregate clusters across data partitions. 
%. These are multi-step methods which split data into shards and compute `local' clusters within each shard, before combining these local clusters into `global' clusters in later steps. However, both of these methods utilise MCMC methods for clustering; we instead use VI within shards, and exploit the variational framework to combine local clusters.

%With real-world datasets, there often exists noisy or irrelevant variables obscuring important structures within the data - especially as the number of these, $P$, increases. This motivates the use of feature selection to simultaneously `remove' irrelevant variables during cluster analysis \citep{Fop2018}. Identifying relevant variables in the dataset can be informative towards researchers; for example, pinpointing key genes driving disease subtypes can aid the development of targeted therapies \citep{Saeys2007}. We show in the Supplement that our model can be extended to tackle variable selection. 

%The majority of research on scalable clustering methods in the literature is centred around applications to continuous data, but we focus on applying our approach to clustering binary and categorical data in this paper, which is often more difficult to tackle due to the lack of ordinal structure. 

We focus on applications to categorical, particularly binary (2-category) datasets, but note that our approach can be straightforwardly adapted to mixtures of Gaussians and other members of the exponential family. In Section 2, we provide an overview of variational Bayesian mixture models, and in Section 3 we briefly introduce merge/delete moves. Section 4 describes how we can employ these moves to enable scaling to large datasets and federated learning. Sections 5 and 6 present results from both simulated and real-world data, including a British EHR dataset, and we discuss the results and take a brief look at future directions for the model in Section 7. We consider in the Appendix how our model can be extended to tackle variable selection.

%such as methods which perform dimensionality reduction to pre-process the data prior to clustering, or methods which perform incremental clustering, such as SUGS \citep{Wang2011}. Stochastic Variational Inference (SVI) \citep{JMLR:v14:hoffman13a}, streaming methods \citep{NIPS2013_51ef186e} and versions of these \citep{hughes_memoized_2013} are, by design, scalable versions of VI but often suffer from poor local optima and requires tuning of learning rates. 

\section{Model Overview}

\subsection{Bayesian Finite Mixture Models} \label{bayesianmixmodels}

Let ${X} = \{{x}_1, ..., {x}_N\}$ denote the observed data, where ${x}_n$ is one observation of $P$ categorical variables. We model the generating distribution as a finite mixture of $K$ components. Each observation is generated by one component. The general equation for a $K$ component finite mixture model is:
\begin{equation}
p(X|\boldsymbol{\pi}, \boldsymbol{\phi})= \sum_{k=1}^K \pi_k f(X | \phi_k),\label{mixture}
\end{equation}
where component densities $f(X | \phi_k)$ are usually from the same parametric family but with different parameters associated with each component. In the limit as $K$ goes to infinity, this is equivalent to the Dirichlet process (DP) mixture model \citep{Maceachern1994, Escobar1995}. Our model can be seen as a finite truncation of the DP mixture model to allow for simpler inference, setting $K$ to be larger than the number of clusters we expect. Each component is modelled as a categorical distribution across $P$ covariates with parameters $\phi_{kj} = [\phi_{kj1}, ..., \phi_{kjL_j}]$, where $\phi_{kjl}$ represents the probability that variable $j$ takes value $l$ in component $k$. $L_j$ is the number of categories for variable $j$. The mixture weight for the $k$-th component is denoted by $\pi_k$, satisfying $\sum_{k=1}^K \pi_k = 1$ and $\pi_k \geq 0$. 

We introduce latent variables $z_n$ associated with each $x_n$, such that each $z_n$ is a one-hot-encoded binary vector with $z_{nk} = 1$ if and only if $x_n$ is in the $k$-th cluster. We then rewrite Equation \eqref{mixture} as:
\begin{equation}
p(X|Z, \boldsymbol{\pi}, \boldsymbol{\phi}) = \prod_{n=1}^N\prod_{k=1}^K f({x}_n | \phi_{k})^{z_{nk}}.
\end{equation}

To complete the model specification for the Bayesian model, we place priors on the parameters:
\begin{align}
    \boldsymbol{\pi} = (\pi_1, ..., \pi_K) &\sim \mbox{Dirichlet}(\alpha_0), \label{piprior} \\
    \phi_{kj} = (\phi_{kj1}, ..., \phi_{kjL_j}) &\sim \mbox{Dirichlet}(\epsilon_{j}), \label{phiprior} %\\
    %\gamma_j | \delta_j &\sim \mbox{Bernoulli}(\delta_j) \\
    %\delta_j &\sim \mbox{Beta}(a), \label{hyperprior}
\end{align}
where all Dirichlet priors are symmetric. It has been shown theoretically that if $K$ exceeds the true number of clusters, then, under certain assumptions, setting $\alpha_0 < 1$ in Equation \eqref{piprior} allows the posterior to asymptotically converge to the correct number of clusters as the number of observations goes to infinity \citep{Rousseau2011, vanHavre2015, MalsinerWalli2014}. Further details of hyperparameter settings are provided in the Appendix. The model can be extended to simultaneously tackle variable selection, as in \cite{Law2004} and \cite{Tadesse2005}, which is explored in the Appendix.

\subsection{Mean-Field Variational Inference (VI)}

We employ a variational inference (VI) approach to seek an approximate distribution $q$ to the posterior. We optimise the Evidence Lower Bound (ELBO) given below, $\mathcal{L}(q)$, with respect to $q(\theta)$, where $\theta$ is a collection of all parameters in the model. 
\begin{equation}
    \mathcal{L}(q) = \int q(\theta) \ln \left(\frac{p(X, \theta)}{q(\theta)} \right)d\theta
\end{equation}

This is equivalent to minimising the Kullback-Leibler (KL) divergence between $q(\theta)$ and the true posterior, $p(\theta | X)$. We constrain $q$ to be a mean-field approximation which can be fully factorised as: $q(\theta) = q_Z(Z)q_\pi(\pi)q_\Phi(\Phi)$. We use a standard variational EM algorithm to optimise $\mathcal{L}(q)$ \citep[see, for example,][]{Bishop2006}, as described below.

\paragraph{`E' Step}

%In the variational `E' (expectation) step, the latent variables $Z$ are updated using the current variational distributions of all other parameters ($q^\ast(\pi)$, $q^\ast(\phi)$ and $q^\ast(\gamma)$, $q^\ast(\delta)$ in the variable selection case). 
We update the latent variables $Z$ with the current variational distributions of all other parameters.
\begin{equation}
q^\ast(Z) = \prod_{n=1}^N\prod_{k=1}^K r_{nk}^{z_{nk}}, \qquad r_{nk} = \frac{\rho_{nk}}{\sum_{j = 1}^K \rho_{nj}} \label{respexplanation}
\end{equation}
\begin{equation}
    \ln \rho_{nk} = \mathbb{E}_{ \pi}[\ln {\pi}_k] + \sum_{i=1}^P \mathbb{E}_{\Phi}[\ln \phi_{kix_{ni}}] \label{rhodef}
\end{equation}

$r_{nk}$ is the responsibility of the $k$-th component for the $n$-th observation, and $\mathbb{E} [z_{nk}] = r_{nk}$. %Data point $n$ is allocated to cluster $k^\ast$ where $k^\ast = \argmax_{k} r_{nk}$. 

\paragraph{`M' Step}

Given updated responsibilities $r_{nk}$ in the `E' step, we then update cluster-specific parameters:
\begin{align}
    q^\ast(\pi) &= \mbox{Dirichlet}(\alpha^\ast_1, ..., \alpha^\ast_K) \label{pidef1} \\
    q^\ast(\phi) &= \prod_{k=1}^{K} \prod_{j=1}^{P} \mbox{Dirichlet}(\epsilon^\ast_{kj1}, ..., \epsilon^\ast_{kjL_j})
\end{align} 
where for $k = 1, ..., K, j = 1, ..., P, l = 1, ..., L_j$:
\begin{align}
    \alpha^\ast_k &= \alpha_0 + \sum_{n=1}^N r_{nk} \label{alphadef} \\
    \epsilon^\ast_{kjl} &= \epsilon_{jl} + \sum_{n=1}^N \mathbb{I}(x_{nj} = l)r_{nk} \label{epsdef}
\end{align}

Expectations throughout are taken with respect to variational distributions. Between each `E' and `M' step, we calculate the value of the ELBO and use this to monitor convergence. All values are initialised using k-modes \citep{Chaturvedi2001}, a method analogous to k-means for categorical data.

\section{Variational Merge/Delete Moves}

As in eg. \citep{pmlr-v38-hughes15}, we introduce merge and delete moves which can be integrated into the VI algorithm. Merge moves refer to moves that combine observations from two clusters into one unified cluster; delete moves refer to moves to delete unnecessary extra clusters in the model. Both moves enable redundant clusters to be efficiently removed to help the model to escape local optima, and are designed in a principled manner to align with the ELBO variational objective function. 

When moves are proposed, parameters in the VI framework are updated through initially updating responsibilities, $r_{nk}$, which are directly associated with the cluster assignment of observations, and then following through with classical variational EM steps. Moves are only accepted if they improve or maintain the ELBO, otherwise the original configuration is maintained, ensuring that the method remains consistent with the underlying VI framework. 

Variational implementations of these moves in Dirichlet process mixture models, in addition to split moves, have been shown to outperform standard variational Bayes and related algorithms \citep{pmlr-v38-hughes15, Yang2019}. However, little work has been published regarding variational categorical mixture models. In particular, split moves are not relevant in the overfitted finite mixture model setting. We provide clear, practical strategies for the implementation of these moves in the categorical setting in Appendix \ref{sec:mergedeleteappend}. 

In particular, we consider how candidate clusters for merge and delete moves can be chosen to enhance efficiency in categorical mixture models. Comparing ELBOs between all possible merge/delete proposals would result in an unnecessarily high computational cost. We demonstrate through simulations in Appendix \ref{sec:corrdivrand} that using fast-to-calculate heuristics such as correlation between cluster parameters (when proposing to merge) allows for enhanced efficiency and a higher percentage of accepted merge moves compared to randomly selecting candidate clusters. This aspect has rarely been explored in prior research. 


\subsection{Computational Considerations} \label{compcons}

We name the variational algorithm including merge/delete moves `MerDel' and introduce a parameter, `laps', representing how many variational EM cycles we go through before performing a merge and a delete move. 

Both merge and delete moves include some variational E and M steps to reassign observations to new clusters as described in Appendix \ref{sec:mergedeleteappend}. These merge/delete moves are therefore relatively costly if the move is ultimately rejected, as opposed to doing purely variational steps which are guaranteed to improve the ELBO. As the model approaches convergence, more variational moves are needed to fine-tune cluster assignments while merge/delete proposals are rejected and increase overall computation. There is subsequently a trade-off between proposing more merge/delete moves to allow for bigger, more effective moves earlier on in MerDel versus reducing the amount of `wasted' moves as the model approaches convergence, which we examine further in simulations. One method to mitigate this in future could be to dynamically change the `laps' parameter as merges/deletes are more frequently rejected.

\subsection{Parallelising MerDel} \label{paralellisedmerdel}

VI requires fewer sweeps over the dataset to perform inference compared to MCMC samplers, and is feasible for datasets with thousands of observations. This allows variational mixture models to be more computationally efficient and converge quickly, especially with the addition of merge/delete moves allowing models to avoid getting stuck in local optima. Despite these improvements, VI still reaches computational bottlenecks when $N$ is particularly large; we see in simulations later that MerDel is infeasible as we reach datasets with $N$ of order $10^5$. Repeatedly updating $N \times K$ responsibilities every E step, and subsequently summing these over $N$ to update cluster-specific parameters every M step is computationally costly once $N$ is large, even if there are 100s of iterations compared to the 1000s seen in MCMC.

All individual components of the original algorithm can be parallelised using standard methods. For example, in the E step, calculation of responsibilities $r_{nk}$ can be parallelised over $n$. %the responsibilities $r_{nk}$ can be updated in batches across multiple cores, as these values are conditionally independent over observations $n$.
Summations in the M step can also be parallelised. We provide an implementation of such a parallelised VI as part of this manuscript. 

However, the overall algorithm is not embarrassingly parallel; for example, $r_{nk}$ values for all $N$ observations are required to update cluster-specific parameters for a given cluster $k$. Prior literature has consistently highlighted the limited gains achieved by such partial parallelisation for iterative methods such as VI. This is due to the significant computational overhead incurred when feeding intermediate results to and from one `master' core - a globally shared computation unit - at regular, frequent intervals \citep{Nallapati2007, neiswanger2015embarrassinglyparallelvariationalinference}. \citeauthor{Nallapati2007} in particular saw that when parallelising variational E and M steps in Latent Dirichlet Allocation, the gain in efficiency was not significant due to the read-conflict between various threads, and also raised concerns about memory constraints as the whole dataset was stored in memory (\citeyear{Nallapati2007}).


\enlargethispage{\baselineskip}

\section{Federated Variational Inference}

%VI offers a computationally efficient approach for mixture model clustering, making it feasible for datasets with thousands of observations. However, VI still involves repeatedly updating $N \times K$ variables $r_{nk}$ and using these in subsequent calculations. This is computationally infeasible for `massive' values of $N$. 

In this section, we propose a scalable clustering algorithm for large categorical datasets, FedMerDel (Federated MerDel), which  addresses the challenge of large $N$ and enables federated learning across multiple nodes. %Our method introduces a novel framework for parallelisation in variational mixture models, designed to go beyond step-level improvements, and can be viewed as a federated learning approach where only summaries of batches of data are required to be shared between nodes.

In FedMerDel, we use a `divide and conquer' inference procedure. We assume our dataset has been split into $B$ `batches' - these batches will already be pre-determined if subsets of the data are held by separate parties, or may be artificially created by random partitioning of the data. The first `local' step of the algorithm involves carrying out clustering via MerDel in each data batch separately. The size and number of these batches should be chosen so inference is computationally feasible; pre-existing subsets of the data can be divided further if necessary. Each batch is processed in parallel, and the clusters produced are referred to as `local clusters'. 

The second `global' step then combines the local clustering structures. Local clusters are frozen, and we merge similar local clusters into `global' clusters. This is conceptually similar to approaches used in SNOB \citep{Zuanetti2018} and SIGN \citep{Ni2019}, but both use MCMC methods which are computationally costly; local clustering in SNOB takes over 4 hours for a batch of size $N=1000$ in the authors' simulations. We utilise a version of the variational merge move seen in MerDel to implement a `global merge'. By freezing local clusters in the global merge, the proposed clustering structure and `global ELBO' across all observations can be efficiently calculated by utilising stored parameter values. The variational framework allows us to accept or reject global merges in a principled manner. Importantly, the full dataset is not required in the global merge.

In contrast to the approach considered in Section \ref{paralellisedmerdel}, instead of optimising individual components of the existing classical variational algorithm, our approach is designed to present a scalable clustering model which avoids these bottlenecks entirely by adopting a distributed computing approach in which each data batch is analysed independently and in parallel before `global merge' steps are used to obtain a (global) mixture model for the full dataset. This federated learning approach eliminates the need for frequent communication and synchronization during the main variational updates, while data remains decentralised.

\subsection{Estimating Global Clusters}

Assume our data has been split into $B$ batches and MerDel has been run on each batch, with $K_b$ local clusters in Batch $b$. Let $K = \sum_{b=1}^B K_b$ be the total number of local clusters. We assume we are in the setting with no variable selection. In the global step, we first `combine' all our existing variational parameters from each batch. For $q(\pi)$, we concatenate all our $K_b$-length $\alpha$ vectors to one $K$-length $\alpha$ vector. Each $q(\phi_{kj})$ is already independent for each local cluster $k$ (and each covariate $j$). We create a new matrix of responsibilities $r_{nk}$ as an $N \times K$ block diagonal matrix, consisting of blocks of $N_b \times K_b$ responsibility matrices from each batch. $\sum_{k=1}^K r_{nk} = 1$ still holds for all $n$.

Let clusters $k_1$ and $k_2$ be considered for a merge. As in the local merge, we reassign responsibilities to cluster $k_1$ via $r^{new}_{nk_1} = r_{nk_1} + r_{nk_2}$ for all $n = 1, ..., N$. This can be viewed as summing columns $k_1$ and $k_2$ in our responsibility matrix. We then use the definitions of $\alpha^\ast$, $\epsilon^\ast$ (Equations \eqref{alphadef}, \eqref{epsdef}) as follows to update cluster-specific parameters:
\begin{align}
    \alpha^{new}_{k_1} &= \alpha_0 + \sum_{n=1}^N ( r_{nk_1} + r_{nk_2} ) \\
    &= \alpha^\ast_{k_1} + \alpha^\ast_{k_2} - \alpha_0 \\
    \epsilon^{new}_{k_1jl} &= \epsilon_{jl} + \sum_{n=1}^N \mathbb{I}(x_{nj} = l) (r_{nk_1} + r_{nk_2}) \\
    &= \epsilon^\ast_{k_1jl} + \epsilon^\ast_{k_2jl} - \epsilon_{j}
\end{align}

This avoids calculating sums over $N$. To complete the merge, we remove all parameters associated with cluster $k_2$ - $\alpha^\ast_{k_2}$, $\epsilon^\ast_{k_2j}$ and $r_{nk_2}$ for all $n = 1, ..., N$, $j = 1, ..., P$. Unlike the variational merge moves, we do not perform an extra variational E/M step to allow observations to move in and out of the new cluster. This would require a whole-dataset update of responsibilities $r_{nk}$. The efficiency of the global merge hinges on the fact that local clusters are frozen. We propose global merge candidates in two ways; a greedy search and a random search.

\paragraph{Greedy Search}

We prevent merges between two clusters from the same batch with a greedy search, on the hypothesis that such merges would already have taken place at the local stage. This can be carried out in a sequential manner by examining the correlation/divergences between Cluster 1 of Batch 1 and all clusters in Batch 2. Once Cluster~1 has merged with any cluster in Batch~2, we move to Batch 3 and consider merging with the clusters in this batch. We repeat for all batches, before moving to Cluster 2 of Batch 1 and so on until we have gone through all clusters in Batch 1. We then repeat the process with Batches 2, 3, ..., B, looking only at Batches $b + 1, ..., B$ for Batch $b$.

\paragraph{Random Search}

Similarly to local merge moves, we calculate correlations/divergences between all $K$ clusters, and pick the merge candidate pair randomly between the 3 pairs with the highest correlation (provided correlation $>$ 0.05) or lowest divergence. There is no restriction on proposing merges between two clusters of the same batch. This stops after a fixed number of global merge moves (e.g. 10) have been rejected consecutively. 

\subsection{Efficient Global ELBO Calculation} \label{sec:efficientELBO}

The ELBO variational objective function allows us to accept or reject the global merge under a rigorous probabilistic framework. For the global merge to be accepted, the ELBO must be higher in the new, merged model. As we now consider the full dataset, many terms in the overall ELBO function involve all observations and clusters. `Freezing' local clusters allows us to efficiently calculate the majority of the ELBO terms while enabling the model to handle large-scale data. Two sums involving N in the full ELBO function can be written as a sum over smaller $K$, $P$, $L_j$ of sufficient statistics which can in turn be calculated as a linear function of previously calculated $\alpha^\ast$ and $\epsilon^\ast$: $T_k = \sum_{n=1}^N r_{nk} = \alpha^\ast_k - \alpha_0$ and $S_{kjl} = \sum_{n=1}^N r_{nk} \mathbb{I}(x_{nj} = l) = \epsilon^\ast_{kjl} - \epsilon_{jl}$. This vastly reduces the number of operations required.

The final term involving $N$ is an assignment entropy term, $\sum_{n=1}^N \sum_{k=1}^K r_{nk} \ln r_{nk}$, which is not linear in any previously calculated parameters. This is additive over $N$ and $K$, so we can calculate this value separately for each batch (in parallel if required) before adding all results together. However, in our greedy search where we never combine two clusters from the same batch, $r_{nk_1}$ and/or $r_{nk_2}$ will \textit{always} be zero for any merge, for all $n = 1, ..., N$. Observation $n$ is only explained by clusters originating from certain batches of data and a merge is only proposed from a new batch where $n$ is not explained by any clusters associated with that batch. This allows greedy search to be faster, although merges could potentially be missed.

Full details of the global ELBO calculation can be found in Appendix \ref{sec:globalelbo}, where all terms in the ELBO can be written without $X$. Crucially, the global merge move allows us to seek a clustering structure for the full dataset without any scan over the full data matrix $X$, which is essential for federated learning. Data from separate entities remains decentralised, where only statistics from each batch are required to be shared, allowing for increased data security and privacy. We also note that parallelisation in local batches, as in Section \ref{paralellisedmerdel}, could still be applied to FedMerDel for additional gains, given sufficient computational resources. 

\subsection{Implementation}

The model builds upon an existing R package, VICatMix \citep{VICatMix}, which applies VI for binary and categorical Bayesian finite mixture models (with no merge/delete moves). Rcpp and RcppArmadillo are used to accelerate computation with C++. MerDel runs on a single-core processor, where, for example, inference for a mixture model fitted to a binary dataset of size $N=2000$, $P=100$ generally converges in less than a minute.

FedMerDel allows MerDel to be run independently on a different core per batch of data; a subsequent global merge takes only a few seconds at most in all simulations. Reported `wall-clock times' take this parallelisation into account where clearly stated. Simulations were all run on a university multi-core HPC cluster.

\section{Examples} 

\subsection{Simulation Study}

In this section, all simulated data is binary, with the data generating mechanism detailed in the Appendix. Additional simulation studies comparing merge criteria, looking at scenarios with simulated categorical data with 3+ categories, and looking at variable selection can also be found in the Appendix. 

\paragraph{Frequency of Merge/Delete Moves}

In Section \ref{compcons}, we described the trade-off between more or fewer merge/delete moves in MerDel. We ran simulation studies comparing different values of the parameter `laps' representing the frequency of merge/delete moves in a run of MerDel, with laps $\in \{1, 2, 5, 10\}$. We also compared to a model with just merge/delete moves after performing one `E' and `M' step after initialisation (`laps = 0'), and the variational model with no merge/delete moves (`laps = 10000'). We used correlation for merge criteria.

We compared computational efficiency by measuring the wall-clock time taken for convergence. We additionally compared the number of non-empty clusters found, and the Adjusted Rand Index (ARI) with the simulated `true' labels. Details of the simulated datasets are in Appendix \ref{setup:freqmerdel}.

\paragraph{Global Merge Simulations}

We evaluated the clustering performance when splitting data into batches and performing a global merge as detailed in Section 4, and compared this with the performances of MerDel applied to the full dataset, and parallelised MerDel as described in Section \ref{paralellisedmerdel}. We looked at binary data with sizes varying between $N =$ between 10,000 to 1,000,000 with $P$ = 100 covariates, and additional simulations varying $P$ and looking at categorical data in the Appendix. Full details are in Appendix \ref{setup:globalmerge}.

\paragraph{Number of Batches} 
With datasets of size $N=100,000$ and $N=200,000$, we compared the clustering performance when considering different numbers of batches. Further details are in Appendix \ref{setup:noofshards}.

\subsection{MNIST}

We applied our model to the MNIST collection of $N=60000$ images of handwritten digits 0-9 \citep{MNIST}. As in \citet{JMLR:v17:11-392}, we downsampled each image to $16\times16$ pixels using bilinear interpolation via TensorFlow, and represented this as a 256-dimensional binary vector. Furthermore, to reduce computation on irrelevant pixels (e.g. those in corners of the image) we removed all pixels with fewer than 100 non-zero values across the whole dataset, leaving 176 covariates . We split this into 6 batches of $N=10000$ and set $K=20$ as the maximum clusters in each batch. True labels for the MNIST digits were not used at any point in the unsupervised clustering.

\subsection{Electronic Health Record (EHR) data}
We analysed an anonymised EHR dataset derived from The Health Improvement Network (THIN) database that comprised records from 289,821 individuals in the United Kingdom over the age of 80. For 94 long-term health conditions, we recorded which conditions were present in each individual to create a $289,821 \times 93$ binary matrix whose $(i,j)$-entry indicates whether individual $i$ has condition $j$ (encoded as a 1) or not (encoded as 0). Further details on data preprocessing are provided in Appendix \ref{EHRappendix}. The aim of the analysis is to identify clusters of individuals with common patterns of co-occurring conditions (multimorbidity).    

\section{Results}

\subsection{Simulation Study}

\subsubsection{Frequency of Merge/Delete} 

More detailed results for simulations, including an assessment of the quality of variable selection with noisy data, can also be found in Appendix \ref{suppfreqresults}. The main conclusions of the simulation study are as follows:

\textbf{Incorporating merge/delete enables faster convergence in terms of wall-clock time: } Generally, MerDel models are faster to converge. Figure \ref{Sim1linegraphs} in Appendix \ref{suppfreqresults} shows that early accepted merge/delete moves allow for substantial early increases in the ELBO. However, as described in Section \ref{compcons}, there is a trade-off that must be made - models with laps = 1, for example, get close to convergence very fast but then take more time to fully converge. The inclusion of frequent merge/delete moves at the start of the algorithm can also lead to the algorithm jumping to a worse local optimum, reflected in slightly lower ARIs in some cases.
   
    \textbf{Better ARIs are achieved with merge/delete: } Figure \ref{merdelARIplot} and Appendix \ref{suppfreqresults} show that (especially in Simulations 1.1, 1.2 and 1.3) using laps = \{2, 5, 10\} generally allows for models with higher ARIs than the variational model with no merge/delete moves. %Merge/delete moves can avoid poorer local optima. 


    
\begin{figure}[ht]
\centerline{\includegraphics[width=\linewidth]{figures/merdelsimARIplots.png}}
\caption{Scatter plot comparing ARIs achieved by each model across all datasets and initialisations in Simulations 1.1, 1.2 and 1.3 (labelled 1, 2, 3 respectively). Each point represents one ARI from one MerDel run.}\label{merdelARIplot}
\end{figure}

    
    \textbf{Merge/delete more accurately estimates the number of clusters: } The model with no merge/delete moves tends to vastly overestimate the number of true clusters in the data due to the existence of small unnecessary clusters. MerDel mitigates this, with Figure \ref{merdelsimclustplots} in Appendix \ref{suppfreqresults} showing that the model often is able to find the exact true number. Some sporadic small clusters remain when implementing merge/delete moves every 10 laps in Simulation 1.3, indicating we could need more frequent moves as $N$ increases.
    
    \textbf{Variational moves are still necessary: } The algorithm with purely merge/delete moves performs less well; any result of this algorithm is extremely dependent on initialisation. Observations can never move between two clusters. 

\subsubsection{Global Merge Simulations} 
Results for selected simulations with $N$ ranging from 50,000 to 500,000 can be seen in Table \ref{globalmergeresults}, with further results in Appendix \ref{globalmergeappendix}. In our simulations, we compare to the ``gold standard" setting in which the full dataset may be analysed without batching using MerDel with or without parallelisation (denoted by `par' and `full' in our results tables). We see from Table \ref{globalmergeresults} that FedMerDel gave extremely good clustering results with median ARIs only marginally lower than those for `full' and `par'. 

The time taken was substantially faster for both parallelised MerDel and FedMerDel as expected via distributed computing, where MerDel on the full dataset became infeasible as our data sizes became larger due to the computational requirements of manipulating large matrices. However, as hypothesised in Section \ref{paralellisedmerdel}, we saw that FedMerDel was faster than paralellised MerDel, and became substantially more so as $N$ increased (Figure \ref{Nlines}). Global merge times ranged from a mean of 0.29s(greedy)/0.39s(random) for $N=20,000$ to a mean of 14.8s(greedy)/18.2s(random) for $N=500,000$, showing that the time taken for the global merge was not computationally prohibitive. 

Different batches of data for a dataset provided extremely consistent results, eg. the standard deviation of ARIs across 10 different shuffles of data in an $N = 50,000$ simulation ranged from 0.0003 to 0.005 for the 20 simulated datasets. Notably, even if a cluster resides in only one batch of data, there is no requirement in our algorithm for this cluster to merge with clusters from other batches (if it does not improve the ELBO), allowing our algorithm to hold sound for data which is not identically distributed across partitions.

\begin{figure}[h!]
\subfloat[]{%
  \includegraphics[width=0.49\linewidth]{figures/globalmergeN5lines.png}%
}
\subfloat[]{%
  \includegraphics[width=0.49\linewidth]{figures/globalmergeN10lines.png}%
} %Use patchwork?
\caption{Plot comparing the mean time taken by MerDel with and without parallelisation (`par' and `full'), and FedMerDel as we vary $N$ with 5 or 10 batches/cores in `Global Merge Simulations', with an approximate 95\% confidence interval (mean $\pm$ 1.96 $\times \frac{s.d}{\sqrt{n}}$). Results for FedMerDel are with the random search.} \label{Nlines}
\end{figure}

\begin{table*}[h]
\caption{`Global Merge Simulations' results. We report the median and lower/upper quantiles across all 10 `shuffles'/initialisations and all 10 synthetic datasets. FedMerDel results use random search; greedy search results are found in the Appendix, but differed little.}
\label{globalmergeresults}
%\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lccccr}
\toprule
N & Model & Batches/Cores & ARI & Clusters & Time (s) \\
\midrule
50000 & full & 5 & 0.947 [0.941, 0.954] & 12 [12, 12] & 467 [414, 554]\\ 
 & par & 5 & 0.948 [0.942, 0.954] & 12 [12, 12] & 176 [163, 196] \\
 %& FedMerDel & 5 & 0.945 [0.939, 0.949] & 13 [13, 14] & 114 [106, 123]\\
 & FedMerDel & 5 & 0.945 [0.939, 0.948] & 12 [12, 12] & 114 [106, 123]\\
\midrule
100000 & full & 5 & 0.955 [0.944, 0.961] & 12 [12, 12] & 956 [861, 1116]\\
 & par & 5 & 0.954 [0.944, 0.961] & 12 [12, 12] & 338 [310, 380] \\
 %& FedMerDel & 5 & 0.954 [0.943, 0.960] & 13 [12, 13] & 260 [231, 287]\\
 & FedMerDel & 5 & 0.954 [0.943, 0.960] & 12 [12, 12] & 260 [232, 287]\\
\midrule
200000 & par & 10 & 0.952 [0.947, 0.958] & 12 [12, 12] & 482 [446, 536]\\
 %& FedMerDel & 10 & 0.951 [0.946, 0.957] & 13 [13, 14] & 269 [242, 303]\\
& FedMerDel & 10 & 0.951 [0.946, 0.957] & 12.5 [12, 13] & 270 [243, 305]\\
\midrule
%MORE SIMULATIONS STILL RUNNING FOR THIS ONE
500000 & par & 10 & 0.950 [0.943, 0.951] & 12 [12, 12] & 1121 [1056, 1303]\\
 %& FedMerDel & 10 & 0.949 [0.942, 0.951] & 13 [13, 14] & 685 [642, 793]\\
& FedMerDel & 10 & 0.949 [0.942, 0.951] & 12.5 [12, 13] & 688 [646, 797]\\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
%\vskip -0.1in
\end{table*}

\subsubsection{Number of Batches} We saw that as we increased the number of batches used, although there was no statistically significant difference at the 5\% level in the accuracy of the clustering as measured by ARI, we did see more clusters (Appendix \ref{result:numberofbatches}). Nevertheless, ARI values were all above 0.93 with a mean of 0.957 across all simulations.

\subsection{MNIST}

We ran FedMerDel on 5 different `shuffles' of the data into batches with $K=20$ maximum clusters in each batch, and our resulting models after a global merge consisted of 27-33 clusters. It is unreasonable to expect to find 10 clusters exactly due to the variation of handwritten digits within numbers. The increased number of clusters was not an artefact of the global merging; a run of MerDel on the MNIST test set of $N=10,000$ digits with 35 maximum clusters found between 33-35 clusters where most merges/deletes were rejected. Other unsupervised clustering models in the literature on MNIST datasets also found a high number of clusters \citep{hughes_memoized_2013, Ni2020}. 

Figure \ref{mnistheatmap} depicts the distribution of true number labels within each cluster, and demonstrates subclustering within digits in the `best' model out of our 5 clustering structures. This is chosen as the model with the highest ELBO, an approach used in other variational models \citep{Ueda2002, hughes_memoized_2013}. We expected imperfect performance due to the reduction of the image to a 1D vector; every pixel is treated as independent of one another, and we lose all information from the 2D images pertaining to correlation between nearby pixels. We found that, for example, 4, 7, 9 were often seen together in clusters; these numbers have quite similar shapes and have a variety of shapes (Figure \ref{479}). On the other hand, FedMerDel performed particularly well in distinguishing 0, 1, 2 and 6 from other digits; 95.95\% of 1's and 92.46\% of 6's were classified into clusters predominantly made up of that digit. Further classification rates can be found in Appendix \ref{sec:classrates}, as well as a comparison to other scalable clustering methods. 


\begin{figure}[ht!]
\centerline{\includegraphics[scale=0.21]{figures/mnist_paper_digits.png}}
\caption{Three examples of digits assigned to Clusters 5 and 14 depicting 6's and 0's respectively, and two generated digits from the variational distribution of each cluster.}\label{digitsgen}
\end{figure}


Furthermore, we can use the posterior distribution of our model to probabilistically produce new digits from each cluster, showing the generative potential in variational Bayes. An example of generated 0's and 6's is seen in Figure \ref{digitsgen}, and further examples can be seen in Appendix \ref{sec:gendigits}.

\subsection{Electronic Health Record (EHR) data}
We divided the data into 14 batches of size 20,000 and 1 batch of size 9,821, and ran FedMerDel with $K = 20$ maximum clusters within each batch.  After global merging, we obtained 8 clusters, which are summarised in Figure \ref{THINsummary}. Each cluster can be characterised by particular conditions.  From top to bottom in Figure \ref{THINsummary}, we have clusters of individuals with: (i) cancer; (ii) Atrial fibrilation (AF) \& arrhythmia; (iii) peripheral vascular disease \& aortic aneurism; (iv) stroke; (v) AF \& arrhythmia and stroke; (vi) blindness; (vii) dementia; and (viii) ``generally multimorbid" individuals. 

\begin{figure}[ht]
\centerline{\includegraphics[width=\linewidth]{figures/labels2Summary.pdf}}
\caption{Results of EHR clustering. Columns are health conditions, and rows correspond to clusters. The shading indicates the proportion of individuals in each cluster that had each health condition, while row labels indicate the number of individuals in each cluster. To improve visualisation, only the most prevalent health conditions are shown (see Appendix \ref{EHRappendix} for further details and coding of health conditions).}\label{THINsummary}
\end{figure}


\section{Conclusion}


%In this paper, we introduced MerDel, a variational mixture model algorithm for clustering incorporating merge/delete moves, which allows us to avoid poor local optima common in VI and achieve better accuracy and faster convergence of the algorithm. We also introduced FedMerDel, a scalable version of MerDel using true distributed computing which exploits the variational framework to perform `global' merging. This model showed good performance on both simulated and real-world data, with only slight reductions in performance compared to analysing the full dataset on one machine, and is particularly useful when federated learning is required.

In this manuscript, we introduced FedMerDel, a Bayesian mixture modelling algorithm using variational inference and `global' merge moves to enable federated learning without sharing the full dataset across nodes. This model showed good performance on both simulated and real-world data, with only slight reductions in performance compared to analysing the full dataset on one machine (when this is possible), and is particularly useful when federated learning is required.

The distribution of data into separate batches for initial inference before extending the merge move to a â€˜global mergeâ€™, directly addressed both the challenge of scaling model-based clustering, and the challenge associated with clustering data which is decentralised and held in separate locations. This is important in scenarios where data privacy is a concern, such as with patient health records. We demonstrated that our method was effective in investigating multimorbidity in one anonymised EHR dataset. We showed that FedMerDel improved time efficiency compared to stepwise parallelisation of the usual variational EM algorithm, especially as dataset sizes increased. We further showed that variational distributions can be used to generate observations from a certain cluster. 

There is clearly scope for improvement in some aspects of the model. For example, to scale up to even larger datasets, we could add extra steps in the global merge as in the SIGN model \citep{Ni2019}, where local clusters are combined over multiple steps over multiple computing cores. %Additionally, Stochastic Variational Inference (SVI) \citep{JMLR:v14:hoffman13a} and other variations of this could be implemented within each data batch to further improve scalability. %Moreover, although we found that clustering results from FedMerDel were reasonably robust over different initialisations and running settings, we note that model averaging as in [redacted] could further mitigate differences in clustering structure resulting from different data splits and/or different frequencies of merge/delete moves. %produced when data is split into batches. %We could also use summarisation to ensemble over different models with different frequencies of merge/delete moves to capture a range of initialisations.

While we presented our approach in the context of modelling large categorical datasets, we note that it can be straightforwardly adapted to mixtures of Gaussians and other members of the exponential family. The use of sufficient statistics to allow for efficient ELBO calculation in global merges could potentially extend to any exponential family distribution; \cite{hughes_memoized_2013} provides some further details. %We are also keen to extend the model to non-conjugate Bayesian distributions and models with mixed data types. 

%Make it clear that there is scope for theoretical investigation ?? but that is NOT this paper

%%%

%\section{Electronic Submission}
%\label{submission}

%Submission to ICML 2025 will be entirely electronic, via a web site
%(not email). Information about the submission process and \LaTeX\ templates
%are available on the conference web site at:
%\begin{center}
%\textbf{\texttt{http://icml.cc/}}
%\end{center}

%The guidelines below will be enforced for initial submissions and
%camera-ready copies. Here is a brief summary:
%\begin{itemize}
%\item Submissions must be in PDF\@. 
%\item If your paper has appendices, submit the appendix together with the main body and the references \textbf{as a single file}. Reviewers will not look for appendices as a separate PDF file. So if you submit such an extra file, reviewers will very likely miss it.
%\item Page limit: The main body of the paper has to be fitted to 8 pages, excluding references and appendices; the space for the latter two is not limited in pages, but the total file size may not exceed 10MB. For the final version of the paper, authors can add one extra page to the main body.
%\item \textbf{Do not include author information or acknowledgements} in your
%    initial submission.
%\item Your paper should be in \textbf{10 point Times font}.
%\item Make sure your PDF file only uses Type-1 fonts.
%\item Place figure captions \emph{under} the figure (and omit titles from inside
%    the graphic file itself). Place table captions \emph{over} the table.
%\item References must include page numbers whenever possible and be as complete
%    as possible. Place multiple citations in chronological order.
%\item Do not alter the style template; in particular, do not compress the paper
%    format by reducing the vertical spaces.
%\item Keep your abstract brief and self-contained, one paragraph and roughly
%    4--6 sentences. Gross violations will require correction at the
%    camera-ready phase. The title should have content words capitalized.
%\end{itemize}

%\subsection{Author Information for Submission}

%\subsubsection{Self-Citations}

%If you are citing published papers for which you are an author, refer
%to yourself in the third person. In particular, do not use phrases
%that reveal your identity (e.g., ``in previous work \cite{langley00}, we
%have shown \ldots'').

%Do not anonymize citations in the reference section. The only exception are manuscripts that are
%not yet published (e.g., under submission). If you choose to refer to
%such unpublished manuscripts \cite{anonymous}, anonymized copies have
%to be submitted
%as Supplementary Material via OpenReview\@. However, keep in mind that an ICML
%paper should be self contained and should contain sufficient detail
%for the reviewers to evaluate the work. In particular, reviewers are
%not required to look at the Supplementary Material when writing their
%review (they are not required to look at more than the first $8$ pages of the submitted document).


% Acknowledgements should only appear in the accepted version.
%\section*{Acknowledgements}

%\textbf{Do not} include acknowledgements in the initial version of
%the paper submitted for blind review.

%If a paper is accepted, the final camera-ready version can (and
%usually should) include acknowledgements.  Such acknowledgements
%should be placed at the end of the section, in an unnumbered section
%that does not count towards the paper page limit. Typically, this will 
%include thanks to reviewers who gave useful comments, to colleagues 
%who contributed to the ideas, and to funding agencies and corporate 
%sponsors that provided financial support.

\section*{Impact Statement}

%Authors are \textbf{required} to include a statement of the potential 
%broader impact of their work, including its ethical aspects and future 
%societal consequences. This statement should be in an unnumbered 
%section at the end of the paper (co-located with Acknowledgements -- 
%the two may appear in either order, but both must be before References), 
%and does not count toward the paper page limit. In many cases, where 
%the ethical impacts and expected societal implications are those that 
%are well established when advancing the field of Machine Learning, 
%substantial discussion is not required, and a simple statement such 
%as the following will suffice:

This paper presents work whose goal is to advance the field of 
Machine Learning. There are many potential societal consequences 
of our work, none which we feel must be specifically highlighted here.

%The above statement can be used verbatim in such cases, but we 
%encourage authors to think about whether there is content which does 
%warrant further discussion, as this statement will be apparent if the 
%paper is later flagged for ethics review.


% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite

\bibliography{mergedelete}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\setcounter{figure}{0} 
\renewcommand\thefigure{S\arabic{figure}}    

\onecolumn
\section*{Appendix}

%\enlargethispage{2\baselineskip}

\section{Variable Selection}

As explored in \citet{Law2004} and \citet{Tadesse2005}, we can introduce binary feature selection indicators $\gamma_j$ - feature saliencies - where $\gamma_j = 1$ if and only if the $j$-th covariate is relevant to the clustering structure, and irrelevant variables have their feature saliencies reduced to zero. The probability density for a data point $x_n$ in cluster $k$ is given by:
\begin{align}
f({\bf x}_n|\Phi_k) &= \prod_{j = 1}^P f_j(x_{nj} | \Phi_{kj})^{\gamma_j} f_j(x_{nj} | \Phi_{0j})^{1 - \gamma_j}
\end{align}

$\Phi_{0j} = [\phi_{0j1}, ..., \phi_{0jL_j}]$ are parameter estimates obtained for covariate $j$ under the assumption that there exists no clustering structure in the $j$-th covariate. These are precomputed using maximum likelihood estimates as seen in \citet{Savage2013}. The priors associated with $\gamma_j$ for $j=1, ..., P$ are as follows:

\begin{equation}
\gamma_j | \delta_j \sim \mbox{Bernoulli}(\delta_j)
\end{equation}
\begin{equation}
    \delta_j \sim \mbox{Beta}(a, a)
\end{equation}

\section{Hyperparameters}

We detail here further parameter settings for the priors detailed in Section \ref{bayesianmixmodels} of the main paper. 
\begin{itemize}\vspace{-0.2cm}
    \item $\boldsymbol{\phi}$: $\epsilon_{jl} = 1/L_j$ for each $j = 1, ..., P, l = 1, ..., L_j$. There is no prior favouring for a variable to take a certain value in any of the clusters. 
    \item $\boldsymbol{\gamma}, \boldsymbol{\delta}$: We set the hyperparameter for $\delta$ to be $a=2$ in all simulations, as in \citet{VICatMix}. The use of a hyperprior for $\gamma$ allows the prior probability of the inclusion of each covariate to be a target for inference. In the variational algorithm, intially we include all variables by setting $c_j = \mathbb{E}_\gamma(\gamma_j) = 1$ for all $j = 1, ..., P$. Variables are found to be irrelevant as the algorithm runs.
\end{itemize}

\section{Mean-Field Variational Inference (VI)}

To improve the readability and continuity of the supplementary material, some content from the main manuscript is repeated in this section. The true Bayesian posterior distribution is intractable as it is computationally intractable to evaluate the marginal likelihood $p(X)$. We employ a variational inference (VI) approach to seek an approximate distribution $q$ which is as close as possible to the true posterior. We do this by optimising the Evidence Lower Bound (ELBO) given below, $\mathcal{L}(q)$, with respect to $q(\theta)$, where $\theta$ is a collection of all parameters in the model. 

\begin{equation}
    \mathcal{L}(q) = \int q(\theta) \ln \left(\frac{p(X, \theta)}{q(\theta)} \right)d\theta
\end{equation}

This is equivalent to minimising the Kullback-Leibler (KL) divergence between $q(\theta)$ and the true posterior, $p(\theta | X)$. We constrain $q$ to be a mean-field approximation which can be fully factorised as (in the variable selection setting): $q(\theta) = q_Z(Z)q_\pi(\pi)q_\Phi(\Phi)q_\gamma(\gamma)q_\delta(\delta)$. The mean-field approximation is simple enough for tractable approximation of the ELBO, and is sufficiently flexible to provide good approximations.

In mean-field VI, the optimal solution $q_j^\ast(\theta_j)$ for each component of $\theta$, $\theta_j$, satisfies \citep{Bishop2006}: 
\begin{align}
q_j^\ast(\theta_j) &= \frac{\exp\left( \mathbb{E}_{i\ne j}[\ln p(X, \theta)]\right)}{\int \exp\left( \mathbb{E}_{i\ne j}[\ln p(X, \theta)]\right)d\theta_j} \label{key}
%\ln q_j^\ast(\theta_j) &= \mathbb{E}_{i\ne j}[\ln p(X, \theta)] + k,\label{key}
\end{align}
%where $k$ is an arbitrary constant ensuring that the density integrates to 1. 

We adopt an iterative procedure to optimise $\mathcal{L}(q)$ by cycling between optimising $q(\theta)$ with respect to each parameter in turn. This numerical procedure is analogous to an Expectation-Minimisation (EM) algorithm, and the variational Bayes algorithm can be reduced to the EM algorithm by setting the variational densities to point estimates \citep{Neal1998, NIPS2000_77369e37}. As the ELBO is convex with respect to each factor $q_j^\ast(\theta_j)$, convergence of the algorithm is guaranteed \citep{Boyd_Vandenberghe_2004}. The ELBO is calculated after every EM step, and we can use sufficient statistics (similar to those detailed in Section \ref{sec:efficientELBO}) to reduce computation in sums over $N$ in the ELBO. This improves the efficiency of the overall algorithm. It is important to note that the frequency of ELBO calculations is a factor contributing to the overall run-time of any variational algorithm.

\paragraph{`E' Step}

In the variational `E' (expectation) step, the latent variables $Z$ are updated using the current variational distributions of all other parameters ($q^\ast(\pi)$, $q^\ast(\phi)$ and $q^\ast(\gamma)$, $q^\ast(\delta)$ in the variable selection case). Using Equation \ref{key}, in the model without variable selection, we have:
\begin{equation}
q^\ast(Z) = \prod_{n=1}^N\prod_{k=1}^K r_{nk}^{z_{nk}}, \qquad r_{nk} = \frac{\rho_{nk}}{\sum_{j = 1}^K \rho_{nj}}
\end{equation}
\begin{equation}
    \ln \rho_{nk} = \mathbb{E}_{ \pi}[\ln {\pi}_k] + \sum_{i=1}^P \mathbb{E}_{\Phi}[\ln \phi_{kix_{ni}}] 
\end{equation}

$r_{nk}$ is the responsibility of the $k$-th component for the $n$-th observation, and $\mathbb{E} [z_{nk}] = r_{nk}$. Data point $n$ is allocated to cluster $k^\ast$ where $k^\ast = \argmax_{k} r_{nk}$. 

\paragraph{`M' Step}

Given updated responsibilities $r_{nk}$ in the `E' step, the variational `M' (maximisation) step updates cluster-specific parameters (and variable selection parameters) in the model.
\begin{align}
    q^\ast(\pi) &= \mbox{Dirichlet}(\alpha^\ast_1, ..., \alpha^\ast_K)  \\
    q^\ast(\phi) &= \prod_{k=1}^{K} \prod_{j=1}^{P} \mbox{Dirichlet}(\epsilon^\ast_{kj1}, ..., \epsilon^\ast_{kjL_j})
\end{align} 
where for $k = 1, ..., K, j = 1, ..., P, l = 1, ..., L_j$:
\begin{align}
    \alpha^\ast_k &= \alpha_0 + \sum_{n=1}^N r_{nk}  \\
    \epsilon^\ast_{kjl} &= \epsilon_{j} + \sum_{n=1}^N \mathbb{I}(x_{nj} = l)r_{nk}
\end{align}

Expectations throughout are taken with respect to variational distributions. Between each `E' and `M' step, we calculate the value of the ELBO and use this to monitor convergence. All values are initialised using k-modes \citep{Chaturvedi2001}, a method analogous to k-means for categorical data.

\section{Variational Updates with Variable Selection} \label{variableselectionupdates}

\paragraph{`E' Step}
This follows a similar form to the model with no variable selection, where $Z$ takes a multinomial distribution.
\begin{equation}
q^\ast(Z) = \prod_{n=1}^N\prod_{k=1}^K r_{nk}^{z_{nk}}, \qquad r_{nk} = \frac{\rho_{nk}}{\sum_{j = 1}^K \rho_{nj}} \label{respexplanation2}
\end{equation}
\begin{align}
    \ln \rho_{nk} &= \mathbb{E}_{ \pi}[\ln {\pi}_k] + \sum_{j=1}^P c_j \mathbb{E}_{\Phi}[\ln \phi_{kjx_{nj}}] + (1 - c_j)(\ln \phi_{0jx_{nj}}) \label{rhodef2}
\end{align}
$c_j = \mathbb{E}_\gamma(\gamma_j)$, where the expectation is taken over the variational distribution for $\gamma$.

\paragraph{`M' Step}

Similarly to the model with no variable selection, the updates for the cluster-specific parameters are given by:
\begin{align}
    q^\ast(\pi) &= \mbox{Dirichlet}(\alpha^\ast_1, ..., \alpha^\ast_K) \\
    q^\ast(\phi) &= \prod_{k=1}^{K} \prod_{j=1}^{P} \mbox{Dirichlet}(\epsilon^\ast_{kj1}, ..., \epsilon^\ast_{kjL_j})
\end{align} 
where for $k = 1, ..., K, j = 1, ..., P, l = 1, ..., L_j$:
\begin{align}
    \alpha^\ast_k &= \alpha_k + \sum_{n=1}^N r_{nk} , \qquad \epsilon^\ast_{kjl} = \epsilon_{j} + \sum_{n=1}^N \mathbb{I}(x_{nj} = l)r_{nk}c_j
\end{align}

The updates for $\gamma$ and $\delta$ are given as:
\begin{equation}
    q^\ast(\gamma_j) = \mbox{Bernoulli}(c_j), \qquad c_j = \frac{\eta_{1j}}{\eta_{1j} + \eta_{2j}} = \mathbb{E}_\gamma(\gamma_j)
\end{equation}
\begin{align}
    \ln \eta_{1i} &= \sum_{n=1}^N \sum_{k=1}^K (r_{nk} \mathbb{E}_\Phi[\ln \phi_{kjx_{nj}}]) + \mathbb{E}_\delta [\ln \delta_j] \\
    \ln \eta_{2i} &= \sum_{n=1}^N \sum_{k=1}^K (r_{nk} \ln \phi_{0jx_{nj}}) + \mathbb{E}_\delta [\ln (1 - \delta_j)]
\end{align}
\begin{align}
    q^\ast(\delta_j) = \mbox{Beta}(c_j + a, 1 - c_j + a)
\end{align}

All expectations throughout are taken over the variational distributions for each parameter. The general algorithm involves cycling between performing the `E' step to evaluate the values of $r_{nk}$ with the current parameter values, and then the `M' step to re-optimise all cluster-specific parameters and variable selection parameters. 

\section{Merge and Delete Moves: Further Detail} \label{sec:mergedeleteappend}

\subsection{Merge Moves} 
Merge moves refer to moves that combine observations from two clusters into one unified cluster. Suppose clusters $k_1$ and $k_2$ are considered for a merge. We propose a move to reassign all observations from clusters $k_1$ and $k_2$ into a single new cluster, $k^\ast$. The responsibilities for this new cluster are given by $r_{nk^\ast} = r_{nk_1} + r_{nk_2}$. All other responsibilities for other clusters remain the same. 

We then perform a `dummy' variational M step, updating the $\pi, \phi$ parameters. We run an extra E and an extra M step to allow observations to move in or out of the new cluster. We then calculate the ELBO and compare this to the ELBO before the merge move; we accept this move if the ELBO has improved, otherwise we return to the model prior to the merge. If accepted, we reassign cluster $k^\ast$ to the $k_1$ position and delete cluster $k_2$ from the model. 

\subsubsection{Selecting Candidate Clusters to Merge} \label{howtomerge}

We could choose a pair of clusters for a merge at random, but a merge is more likely to be accepted if the two clusters are `similar'. Making informed decisions on which pair of clusters to propose for a merge can improve efficiency by reducing the number of rejected merge moves. Two methods of assessing similarity between clusters using correlation and divergences between variational distributions are detailed below. Other ways include comparing marginal likelihoods or posterior probabilities of candidate models as in \citet{pmlr-v38-hughes15} and \citet{ueda_smem_2000}. 

Due to the stochastic nature of the selection from the `candidate clusters', similar results between different merge candidates are to be expected and the choice of measure is insignificant. Results from a simulation study comparing selection criteria for clusters to be merged are seen in Appendix \ref{sec:corrdivrand}. Correlation and divergence-based methods performed similarly, but did provide a reduction in overall computation time and an improvement in rates of accepted merges compared to random selection. 

\paragraph{Correlation}

We can use an assessment of correlation between the variational parameters associated with each cluster. For example, in \citet{hughes_memoized_2013}, two topics in the hierarchical Dirichlet process are proposed for a merge if the correlation between statistics representing usage of the topic across documents is above 0.05. 

We can construct a correlation score by looking at the correlation between the parameter values $\epsilon^\ast$ in the distributions $q(\phi_{kj})$. In the binary case, each $\epsilon^\ast_{kj}$ is given by a two dimensional vector, and without loss of generality, for each k, we can take the first value of each of these vectors for $j = 1, ..., P$, concatenate these into one $j$ length vector, $\epsilon^{corr}_{k}$ and then compare the correlation of these concatenated vectors across clusters. The $\epsilon^{corr}_k$ values represent the (expected) frequency of 0's in each cluster across all variables in a binary dataset of 0's and 1's. 

We select randomly between the 3 cluster pairs with the highest correlation, provided $\mbox{Corr} (\epsilon^{corr}_{k_1}, \epsilon^{corr}_{k_2})$ is above 0.05. With the categorical case with $L$ categories per variable, we could consider finding the correlation scores for $L-1$ concatenated vectors across all variables for $L-1$ of the categories (avoiding overparameterisation) and taking the mean correlation score for comparison. However, this is complicated when variables have different numbers of categories, and this method is less straightforward to extend to other probability distributions.

\paragraph{Divergence-based Measures}

We also look at using measures of distance between probability distributions to quantify similarity between clusters. For a pair of clusters $k_1$ and $k_2$, we look at the divergence between $q(\phi_{k_1j})$ and $q(\phi_{k_2j})$ and sum over all variables $j$ for a pair of clusters $k_1$ and $k_2$. We then choose randomly between the 3 cluster pairs with the lowest divergences, for example.

Different divergences could be considered; in this paper we considered both the Kullback-Leibler (KL) divergence and the Bhattacharyya distance. We emphasise that we are not seeking an exact, precise characterisation of the `distance' but are only making approximate comparisons between candidate cluster pairs.

\subsection{Delete Moves}

Delete moves refer to moves to delete unnecessary extra clusters in the model. Redundant small clusters often remain at local optima in variational algorithms for mixture models. These clusters are usually inconsistent across different initialisations, suggesting that moves to remove them and reassign observations to other clusters could improve performance. %delete this?

Let cluster $k$ be a candidate cluster for deletion. For the set of observations in cluster $k$, ie. $S_k := \{n = 1 \ldots N: z_{nk} = 1\}$, we create a new data-frame $X_{-k}$ with the rows from observations in $S_k$ removed, and the column for cluster $k$ removed. We first perform the variational E step after removing all variational parameters relevant to cluster $k$ in the model. This recalculates all responsibilities for the remaining observations. We then perform the variational M step, which updates the $\pi, \phi$ (and $\gamma, \delta$ if variable selection is used) parameters.

We then return to the original dataframe $X$ and then run an E step using $X$ with the current model parameters, which reassigns all observations in $X$ to new clusters. After performing another M step, we then calculate the value of the ELBO function. We accept the delete move if the new ELBO is higher.

Note that in both the merge and delete moves described above, there is an extremely small approximation involved in setting $r_{nk} = 0$ exactly for responsibilities associated with clusters `removed' in merge/delete moves. We go into further detail in Appendix \ref{sec:priors}, showing that this approximation simply replaces numbers extremely close to 0 (numbers smaller than $10^{-80}$) during the algorithm and has virtually no effect on the clustering structure. 

\subsubsection{Selecting Candidate Clusters to Delete}

Smaller clusters are likely to be better candidates for deletion as it is likely these observations have been `left out'. Extremely small clusters are also less informative in practical applications and may be less reproducible in other similar independent datasets. In this paper, we propose a cluster chosen randomly between all clusters which are smaller than 5\% of the dataset; if there are none, we choose randomly between the three smallest clusters. As in Appendix \ref{howtomerge}, the stochasticity of this process means that other methods should not give significantly different results.

\clearpage

\section{Global ELBO Calculation - Further Details} \label{sec:globalelbo}

For the model with no variable selection, the ELBO for the full dataset is given by:
\begin{align*}
    \mathcal{L}(q) &= \mathbb{E}_{Z, \pi, \Phi}[\ln p(X, Z, \pi, \Phi)] - \mathbb{E}_{Z, \pi, \Phi}[\ln q(Z, \pi, \Phi)] \\ 
    &= \mathbb{E}_{Z, \Phi}[\ln p(X | Z, \Phi)] + \mathbb{E}_{Z, \pi}[\ln p(Z|\pi)] + \mathbb{E}_{\pi}[\ln p(\pi)] + \mathbb{E}_{\Phi}[\ln p(\Phi)] \numberthis \\
    & \qquad - \mathbb{E}_{Z}[\ln q(Z)] - \mathbb{E}_{\pi}[\ln q(\pi)] - \mathbb{E}_{\Phi}[\ln q(\Phi)] \label{ELBObreakdown}
\end{align*}
where all expectations are taken with respect to the variational distributions for $Z, \pi, \Phi$. From standard properties of the Dirichlet distribution, we initially calculate:
\begin{align}
    \mathbb{E}_{ \pi}[\ln {\pi}_k] &= \psi(\alpha^\ast_k) - \psi(\sum_{k = 1}^K \alpha^\ast_k) \\
    \mathbb{E}_{\Phi}[\ln \phi_{kjl}] &= \psi(\epsilon^\ast_{kjl}) - \psi(\sum_{l = 1}^{L_j} \epsilon^\ast_{kjl})
\end{align}
where $\psi(x)$ refers to the digamma function.

As written in the main text of the paper, we also use the current $\alpha^\ast$ and $\epsilon^\ast$ values to calculate the values of sufficient statistics:
\begin{align}
T_k &= \sum_{n=1}^N r_{nk} = \alpha^\ast_k - \alpha_0 \\
S_{kjl} &= \sum_{n=1}^N r_{nk} \mathbb{I}(x_{nj} = l) = \epsilon^\ast_{kjl} - \epsilon_{jl}
\end{align}

Each term in Equation \eqref{ELBObreakdown} is as follows:
\begin{align}
    \mathbb{E}_{Z, \Phi}[\ln p(X | Z, \Phi)] &= \mathbb{E}_{Z, \Phi}[\sum_{n=1}^N \sum_{k=1}^K {z_{nk}} (\sum_{j=1}^P \ln \phi_{kjx_{nj}})] \\
    &= \sum_{n=1}^N \sum_{k=1}^K r_{nk} (\sum_{j=1}^P \mathbb{E}_{\Phi}[\ln \phi_{kjx_{nj}}]) \\
    &= \sum_{n=1}^N \sum_{k=1}^K \sum_{j=1}^P \sum_{l = 1}^{L_j} r_{nk} \mathbb{I}(x_{nj} = l) \mathbb{E}_{\Phi}[\ln \phi_{kjl}] \\
    &= \sum_{k=1}^K \sum_{j=1}^P \sum_{l = 1}^{L_j} S_{kjl} \mathbb{E}_{\Phi}[\ln \phi_{kjl}] \\
    \mathbb{E}_{Z, \pi}[\ln p(Z|\pi)] &= \mathbb{E}_{Z, \pi} [\sum_{n=1}^N \sum_{k=1}^K {z_{nk}} \ln \pi_k] \\
    &= \sum_{n=1}^N \sum_{k=1}^K r_{nk} \mathbb{E}_{\pi} [\ln \pi_k] \\
    &= \sum_{k=1}^K T_k \mathbb{E}_{\pi} [\ln \pi_k]
\end{align}


\begin{align}
    \mathbb{E}_{\pi}[\ln p(\pi)] &= -\ln B(\alpha) + \sum_{k=1}^K (\alpha_k - 1) \mathbb{E}_{\pi}[\ln \pi_k] \label{ELBOppi} \\
    \mathbb{E}_{\Phi}[\ln p(\Phi)] &= \sum_{k=1}^K \sum_{j=1}^P (- \ln B(\epsilon_{kj}) + \sum_{l=1}^{L_j} (\epsilon_{kjl} - 1) \mathbb{E}_{\Phi}[\ln \phi_{kjl}]) \label{ELBOpphi} \\
    \mathbb{E}_{Z}[\ln q(Z)] &= \sum_{n=1}^N\sum_{k=1}^K r_{nk} \ln r_{nk} \qquad \mbox{(assignment entropy)} \label{ELBOqz} \\
    \mathbb{E}_{\pi}[\ln q(\pi)] &= -\ln B(\alpha^\ast) + \sum_{k=1}^K (\alpha^\ast_k - 1) \mathbb{E}_{\pi}[\ln \pi_k]  \\
    \mathbb{E}_{\Phi}[\ln q(\Phi)] &= \sum_{k=1}^K \sum_{j=1}^P (- \ln B(\epsilon^\ast_{kj}) + \sum_{l=1}^{L_j} (\epsilon^\ast_{kjl} - 1) \mathbb{E}_{\Phi}[\ln \phi_{kjl}]) \label{ELBOqphi}
\end{align}

Apart from the assignment entropy term in Equation \eqref{ELBOqz}, as we have calculated $T_k$ and $S_{kjl}$ via simple linear operations on our model parameters, there are no sums over $N$ and all terms are mainly sums over much smaller $K$, $P$, $L_j$. Furthermore, there are terms in $B(\alpha)$, $B(\alpha^\ast)$, $B(\epsilon_{kj})$, $B(\epsilon^\ast_{kj})$ which cancel out - see Appendix \ref{sec:priors} for more details. Importantly, $X$ appears nowhere in the calculations; our global merge move allows us to seek a global clustering structure without any full scan over the $N \times P$ matrix $X$. 

For the assignment entropy term $\sum_{n=1}^N \sum_{k=1}^K r_{nk} \ln r_{nk}$, as detailed in the main paper, we can either calculate this value in parallel across different batches of observations across different cores, or in the case of the greedy search, this value remains constant as the merge moves only allow merges between clusters from different batches. 

\section{Global Merge - Variable Selection} \label{description:varsel}

When finding a global clustering structure in the model with variable selection, our focus is on updating cluster allocation via merging local clusters, so we use the same global ELBO function as in the model without variable selection and only update $Z, \pi, \phi$. The nature of $\phi$ updates in the model with variable selection means that the $\epsilon^\ast$ parameters are equal to the prior parameters for the given covariate if a covariate is irrelevant in the model, so variable selection is still involved with the usual global merge move. Implementing this amounts to a small approximation in the true ELBO for the true Bayesian model.

We consider a variable to be `selected' based on the percentage of times a variable was selected across the batches. In later simulations, we consider a variable selected if it was selected in either all batches, or all but one batch. This borrows ideas of `thresholds' for variable selection across multiple VI runs which is seen in \citet{VICatMix}.

\section{Approximations and Priors in MerDel} \label{sec:priors}

In Appendix \ref{sec:mergedeleteappend}, we detailed that in the process of performing our merge/delete moves, we `remove' the clusters by removing all parameters and responsibilities associated with this cluster in the model code. This could raise concerns pertaining to transdimensional inference, as on the surface, we are deleting a dimension of our model and the variational posterior now has a different dimension. 

However, we still implicitly account for the removed clusters in subsequent calculations. We call these removed clusters `zombie clusters'; despite not technically remaining in the model in the code, they are never truly removed but instead ruled only by priors. This is because the cluster-specific parameters $\alpha, \epsilon$ are determined by the prior only (as there is no data assigned to the cluster to update the cluster-specific parameters - see Section \ref{sec:M}). We can take these `zombie clusters' into account in subsequent iterations of the algorithm and accurately calculate eg. ELBO values at each variational EM step by tracking the number of `zombie clusters' we have. 

There is an approximation made where we set responsibilities associated with `zombie clusters' to 0 (by removing the responsibilities associated with the cluster). These responsibilities are not usually exactly 0. However, we describe below how the responsibilities removed are infinitesimally small for the empty cluster $k$ for all $n$ and no observations are assigned to the cluster. 

\subsection{Emptying a Cluster + M Update} \label{sec:M}

In both the merge and delete settings, when a cluster $k^\ast$ is removed, this is equivalent to assigning $r_{nk^\ast} = 0$ for all observations $n$, as $r_{nk^\ast}$ only appears in future calculations within sums. Therefore, we can think of our $N \times K_{\mbox{init}}$ responsibility matrix as now having values of 0 in column $k^\ast$. After that, in both moves, we then perform a variational M step, where cluster-specific parameters $\alpha^\ast, \epsilon^\ast$ are updated:
\begin{equation}
    \alpha^\ast_k = \alpha_0 + \sum_{n=1}^N r_{nk} , \qquad \epsilon^\ast_{kjl} = \epsilon_{jl} + \sum_{n=1}^N \mathbb{I}(x_{nj} = l)r_{nk}  \label{alphaandeps}
\end{equation}

As we have that $r_{nk} = 0$ for all $n = 1, ..., N$ for a removed cluster $k$, $\alpha^\ast_k = \alpha_0$ and $\epsilon^\ast_{kjl} = \epsilon_{jl}$. These variational posteriors for cluster $k$ are solely ruled by the priors for $\pi$ and $\Phi$.

\subsection{The Approximation: E Update} \label{sec:Eupdate}

In MerDel, we then perform a variational E update with the full dataset (and another variational M update) to allow observations to move between clusters after the cluster-specific parameter updates. Recall that responsibilities $r_{nk}$ are defined by:
\begin{equation}
r_{nk} = \frac{\rho_{nk}}{\sum_{j = 1}^K \rho_{nj}}, \qquad \ln \rho_{nk} = \mathbb{E}_{ \pi}[\ln {\pi}_k] + \sum_{j=1}^P \mathbb{E}_{\Phi}[\ln \phi_{kjx_{nj}}] \label{eqn:respandrho}
\end{equation}

The expectations in $\ln \rho_{nk}$ are given by:
\begin{align}
    \mathbb{E}_{ \pi}[\ln {\pi}_k] &= \psi(\alpha^*_k) - \psi(\sum_{k = 1}^K \alpha^*_k) \label{eqn:Epi} \\
    \mathbb{E}_{\Phi}[\ln \phi_{kjx_{nj}}] &= \psi(\epsilon^*_{kjx_{nj}}) - \psi(\sum_{l = 1}^{L_j} \epsilon^*_{kjl}) \label{eqn:Ephi}
\end{align}

For $x > 0$, the digamma function $\psi(x)$ increases approximately in an exponential fashion. 

For every cluster with observations assigned to it, we generally see that the observations are assigned to it with responsibilities close to 1. Looking at Equation \eqref{alphaandeps}, we see that $\alpha^\ast_k$ is often a high value approximately on the scale of the number of observations assigned to the cluster - sometimes in the thousands for our dataset sizes - and the value of $\alpha_0$, which is chosen to be smaller than 1, has a very small impact. $\alpha^\ast_k$ must be larger for any cluster with observations compared to any `zombie cluster'  as $\alpha^\ast_k$ is a sum of non-negative responsibilities added to $\alpha_0$. $\epsilon^\ast$ values are similar. Therefore, from Equations \eqref{eqn:Epi} and \eqref{eqn:Ephi}, $\ln \rho_{nk}$ is much smaller for `zombie clusters'. $\rho_{nk}$ is exponentially small in comparison to other cluster, and we find that after the normalising these values, $r_{nk}$ values are \textit{extremely} close to 0.

It is also almost impossible that these $r_{nk}$ values will ever become larger as we continue through the EM steps; $\alpha^\ast$ and $\epsilon^\ast$ still remain extremely small for removed clusters (virtually equal to the values of the prior) in comparison to clusters with observations, and $r_{nk}$ values still remain virtually 0, and the cycle continues. Our approximation is equivalent to setting these $r_{nk}$ values to 0 permanently by removing these columns, allowing for computational efficiency and lower memory usage. We also do not perform inference for any further cluster-specific parameters associated with cluster $k$ (by removing these values too) as they are always the same as their prior values if we set $r_{nk} = 0$. This saves wasted computation on these values. This approximation has virtually no effect on our model; we run two small simulations comparing the effects of implementing this approximation, and saw that true $r_{nk}$ values were often on the scale of $10^{-70}$ to $10^{-100}$ on typical MerDel example datasets (see Section \ref{sec:simrnk}).

We then go through and perform another M step as in the previous section, before evaluating the ELBO as detailed in the next section. Going forward with the algorithm after an accepted MerDel proposal, the variational E and M steps and ELBO calculations continue as in this appendix, where $r_{nk}$ values are set to be exactly 0 forever, and we remove all values associated with removed clusters.

This is in line with what we see in the overfitted variational model without merge/delete; when clusters are `emptied', they are usually never filled again with observations. When there are no observations assigned to a cluster, $\alpha^\ast$ and $\epsilon^\ast$ values are given by their prior values, and we see that $\ln \rho_{nk}$ is again much smaller for a cluster with no observations assigned to it compared to clusters with observations, and $r_{nk}$ is close to 0. Under the overfitted model, it is virtually impossible that these clusters are ever filled again, and $r_{nk}$ values will remain extremely close to 0 as illustrated above.

\subsubsection{Simulation in more detail} \label{sec:simrnk}

We set up 10 simulated datasets, and compared two versions of MerDel. We performed 5 runs of the `fast' version of MerDel (removing columns associated with zombie clusters) and 5 runs of the `slow' version of MerDel (not removing columns associated with zombie clusters) on each simulated dataset. We used the same initialisations for the `fast' and `slow' versions (by setting the same random number seed). For our first simulation, each dataset had $N=2000$, $P=100$, 10 true clusters and was initialised with 15 maximum clusters, laps = 5 and $\alpha_0 = 0.01$. For the second simulation, each dataset had $N=10000$, $P=100$, 10 true clusters and was initialised with 15 maximum clusters, laps = 1 and $\alpha_0 = 0.01$.

We measured the RMSE between the final $r_{nk}$ matrices (inserting 0's for `missing' columns in the `fast' MerDel version) and ARI between the final cluster labels. In both simulations, all ARIs between corresponding `fast' and `slow' clustering structures were 1 (perfect similarity). In the first simulation, the RMSE between $r_{nk}$ matrices ranged between $7.15 \times 10^{-84}$ and $4.32 \times 10^{-80}$ (with a mean of $6.63 \times 10^{-81}$); in the second simulation, the RMSE ranged between $2.85 \times 10^{-83}$ and $2.20 \times 10^{-80}$ (with a mean of $2.78 \times 10^{-81}$). When only considering $r_{nk}$ values for non-empty clusters, the RMSE was 0. The time taken for the `slow' runs was indeed slower; for example, in the second simulation, the `fast' runs took a mean time of 88.2 seconds to converge, while the `slow' runs took a mean time of 124.2 seconds. Removing `zombie' clusters saves computational time and memory usage associated with these parameters, and still gives exactly the same results.

Similar calculations show that setting $r_{nk} = 0$ for removed clusters in MerDel with variable selection results in a similarly infinitesimally small approximation.

\subsection{ELBO calculation} \label{sec:ELBOzombie}

We now look at each individual term in the ELBO. We set $r_{nk} = 0$ for all $n$ in removed clusters $k$ and we show that are able to accurately calculate the ELBO after completely removing all values associated with cluster $k$ from the model under this approximation.

\subsubsection{Terms ruled by $r_{nk}$}

\begin{align}
    \mathbb{E}_{Z, \Phi}[\ln p(X | Z, \Phi)] &= \sum_{n=1}^N \sum_{k=1}^K r_{nk} (\sum_{i=1}^D \mathbb{E}_{\Phi}[\ln \phi_{kix_{ni}}]) \label{ELBOpxzphi} \\
    \mathbb{E}_{Z, \pi}[\ln p(Z|\pi)] &= \sum_{n=1}^N \sum_{k=1}^K r_{nk} \mathbb{E}_{\pi} [\ln \pi_k] \label{ELBOpzpi} \\
    \mathbb{E}_{Z}[\ln q(Z)] &= \sum_{n=1}^N\sum_{k=1}^K r_{nk} \ln r_{nk} \label{ELBOqz2}
\end{align}

In all terms \eqref{ELBOpxzphi}, \eqref{ELBOpzpi}, \eqref{ELBOqz2} all terms in the sums are multiplied by $r_{nk}$; so all terms are equal to 0 for a removed cluster $k$. Removing terms associated with $k$ has no effect.

\subsubsection{Terms ruled by $\Phi$} \label{sec:phirule}

\begin{align}
    \mathbb{E}_{\Phi}[\ln p(\Phi)] &= \sum_{k=1}^K \sum_{i=1}^D (- \ln B(\epsilon_{ki}) + \sum_{l=1}^{L_i} (\epsilon_{kil} - 1) \mathbb{E}_{\Phi}[\ln \phi_{kil}])  \\
    &= \sum_{k=1}^K \sum_{i=1}^D \mathbb{E}_{\Phi}[\ln p(\Phi_{kj})] \\
    \mathbb{E}_{\Phi}[\ln q(\Phi)] &= \sum_{k=1}^K \sum_{i=1}^D (- \ln B(\epsilon^*_{ki}) + \sum_{l=1}^{L_i} (\epsilon^*_{kil} - 1) \mathbb{E}_{\Phi}[\ln \phi_{kil}])  \\
    &= \sum_{k=1}^K \sum_{i=1}^D \mathbb{E}_{\Phi}[\ln q(\Phi_{kj})] 
\end{align}

For the terms associated with $\Phi$, each cluster $k$ is treated independently of one another. Each $p(\Phi_{kj})$ prior and $q(\Phi_{kj})$ variational posterior is a Dirichlet distribution of dimension $L_j$. We can therefore look at each $(k, j)$ pair separately. For a removed cluster $k$, the $\epsilon^\ast_{kj}$ values associated with that cluster are equal to the prior $\epsilon_j$ values (Section \ref{sec:M}). Therefore we have, for a removed cluster $k$, $\mathbb{E}_{\Phi}[\ln p(\Phi_{kj})] - \mathbb{E}_{\Phi}[\ln q(\Phi_{kj})] = 0$, as $\epsilon^\ast_{kjl} = \epsilon_j$ for all $k=1, ..., K, j = 1, ..., P, l = 1, ..., L_j$. Ignoring cluster $k$ in both the prior and variational posterior for $\Phi$ therefore has no effect on the value of the ELBO.

\subsubsection{Terms ruled by $\pi$} \label{sec:pirule}

\begin{align}
    \mathbb{E}_{\pi}[\ln p(\pi)] &= -\ln B(\alpha) + \sum_{k=1}^K (\alpha_k - 1) \mathbb{E}_{\pi}[\ln \pi_k]\\
    \mathbb{E}_{\pi}[\ln q(\pi)] &= -\ln B(\alpha^\ast) + \sum_{k=1}^K (\alpha^\ast_k - 1) \mathbb{E}_{\pi}[\ln \pi_k] \label{ELBOqpi}
\end{align}

As in the previous section with $\Phi$, for an cluster $k$, we have that $\alpha^\ast_k = \alpha_k = \alpha_0$. Therefore, we have that the terms within the sums $\sum_{k=1}^K (\alpha_k - 1) \mathbb{E}_{\pi}[\ln \pi_k]$ and $\sum_{k=1}^K (\alpha^\ast_k - 1) \mathbb{E}_{\pi}[\ln \pi_k]$ associated with a removed cluster cancel each other out. This part of $\mathbb{E}_{\pi}[\ln p(\pi)]$ and $\mathbb{E}_{\pi}[\ln q(\pi)]$ can be considered safely dealt with.

However, $\pi$ is a $K$-length vector modelled as a $K$-length Dirichlet distribution - both under the prior and in the variational posterior. When calculating $\ln B(\alpha)$, $\ln B(\alpha^\ast)$ and $\mathbb{E}_{\pi}[\ln \pi_k]$, we must take `zombie clusters' into account.

\begin{align}
    - \ln B(\alpha) = \sum_{k=1}^K \ln \Gamma (\alpha_k) - \ln \Gamma (\sum_{k=1}^K (\alpha_k)) \\
    \ln B(\alpha^\ast) = - \sum_{k=1}^K \ln \Gamma (\alpha^\ast_k) + \ln \Gamma (\sum_{k=1}^K (\alpha^\ast_k))
\end{align}

We have that $\ln \Gamma (\alpha_k)$ and $\ln \Gamma (\alpha^\ast_k)$ inside the sums cancel each other out for a removed cluster $k$, as $\alpha_k = \alpha^\ast_k$. Therefore we need to take into account some $\alpha, \alpha\ast$ terms in $\ln \Gamma(\sum \alpha_k))$, $\ln \Gamma(\sum \alpha^\ast_k))$  which do not cancel out with each other. This is easily done by simply adding $\alpha_0 \times K_{\mbox{rem}}$ into both sums over the $\alpha$, $\alpha^\ast$ vectors, where $\alpha_0$ is the parameter in the symmetric Dirichlet prior used for $\pi$, and $K_{\mbox{rem}}$ is the number of clusters removed via merge/delete moves. This can be tracked trivially. A similar process must be used in calculating $\mathbb{E}_{\pi}[\ln \pi_k]$.


\subsection{Approximations and Priors in FedMerDel}

There is no approximation when considering a `global merge' in FedMerDel, as we never perform any variational E or M steps after performing merges. Our responsibilities $r_{nk}$ remain exactly 0 for `zombie clusters': given that we take the zombie clusters into account when calculating the `global ELBO' as above, we are okay to `remove' empty clusters from the model parameters. 

Note that as we enter the global setting, we define a new Dirichlet prior for $\pi$ over our full dataset with the total number of local clusters initialised: $B \times K_b$, if $K_b$ is the initialised number of clusters in Batch $b$. This is justified as each cluster has a prior where:
\begin{equation}
    p(\pi) \propto \prod_{k=1}^K {\pi_k}^{\alpha_0 - 1}
\end{equation} 
with K representing the number of maximum clusters desired in the model. Therefore, when we enter the global setting with $B$ batches, the maximum clusters in the model should be $B \times K_b$, the maximum total clusters when we consider all batches. A fractional prior for each batch would not be appropriate; this would be imposing a prior saying that there is a maximum number of $K_b$ clusters across the full dataset, despite the fact we actually search for this number of clusters in each partition. We do not want to constrain the model to force all clusters to merge across batches; especially in the federated learning setting, there may be clusters appearing in certain batches of data but not other batches. This is consistent with similar literature; the same Dirichlet priors for mixing probabilities are used in `local clusters' and `global clusters' in \citep{Zuanetti2018}, a similar MCMC model to FedMerDel.

%Include that theoretical work on this is left for the future

\section{Simulation Set-Up - Additional Information}

\subsection{Data Generating Mechanism}
We simulated synthetic binary data with $N$ observations and $P$ covariates by sampling the probability $p$ of a `1' in each cluster for each variable via a $\mbox{Beta} (1, 5)$ distribution, encouraging sparse probabilities. For noisy variables, the probability of a `1' was also generated by a $\mbox{Beta} (1,5)$ distribution but this probability was the same for every observation regardless of cluster membership. When simulating categorical data with $L$ categories, we instead used a $\mbox{Dirichlet} (1, ..., L)$ distribution.

\subsection{Hyperparameter Choice}
In all simulations (real-world and simulated data), we set $\alpha_0 = 0.01$, $\epsilon_j = 1/L_j$ and $a = 2$ (as in \citet{VICatMix}) in the priors in Section 2 of the main paper. We did not tune these in this manuscript as all examples are purely illustrative. All algorithms were run with a maximum of 1000 iterations (an iteration being one variational EM step) - although this limit was not reached for any simulation. 

Convergence tolerance was set between 0.000005 and 0.00000005 in all simulations. When comparing wall-clock time for convergence, all simulations in a given study had the exact same convergence tolerance. 

In all simulations involving FedMerDel, we used the parameters `laps = 5' for MerDel runs, except when explicitly specified. 

\subsection{Frequency of Merge/Delete Moves} \label{setup:freqmerdel}

Details of the scenarios for this simulation study are given in Table \ref{simFedMerDeltable} Simulations 1.1, 1.2, 1.3 were run without variable selection; Simulations 1.4, 1.5 were run with variable selection. $K_{\mbox{init}}$ refers to the initialised value of $K$ in the model. In each scenario, we generated 20 independent datasets and compared 10 different initialisations for each dataset. 

\begin{table*}[h!]
\caption{Table giving parameters for data generation for the first simulation study, `Frequency of Merge/Delete Moves'.}
\label{simFedMerDeltable}
%\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lcccccr}
\toprule
ID & Relevant & $N$ & $P$ & $K_{init}$ & $K_{true}$ & $N$ per \\
 & Variables &  &  &  &  & Cluster \\
\midrule
    1.1 &  100 & 1000 & 60 & 20 & 5 & 100-300\\
    1.2 &  100 & 2000 & 100 & 20 & 8 & 50-800 \\
    1.3 &  100 & 4000 & 100 & 25 & 10 & 200-800 \\
    1.4 &  75 & 1000 & 100 & 20 & 10 & 50-200 \\
    1.5 & 60 & 1500 & 100 & 20 & 10 & 50-200 \\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
%\vskip -0.1in
\end{table*}

\subsection{Global Merge Simulations} \label{setup:globalmerge}
We aimed to evaluate the clustering performance of FedMerDel when splitting a simulated dataset into equally sized batches, and compared this to a paralellised version of MerDel (on the full dataset) as well as the usual MerDel algorithm on the full dataset (usual variational EM with merge and delete moves). We set `laps = 5', $P=100$ covariates, 12 true clusters and 20 initialised clusters in all cases. Correlation was used for all merge criteria. These parameters were all kept the same to enable comparison of run-times between different values of $N$. Details of the values of $N$ tested and number of batches/cores used are given in Table \ref{globalmergesetuptable}. 

The full, unparallelised algorithm was only used for the first 4 simulations listed, as it became computationally infeasible for larger values of $N$ with our hardware.

\begin{table*}[h!]
\caption{Table giving parameters for data generation for the second simulation study, `Global Merge Simulations', where other parameters are set as in Section \ref{setup:globalmerge}.}
\label{globalmergesetuptable}
%\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lr}
\toprule
N & Batches/Cores\\
\midrule
20000 & 5\\
50000 & 5\\
50000 & 10 \\
100000 & 5\\
100000 & 10 \\
200000 & 5\\
200000 & 10 \\
500000 & 10 \\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
%\vskip -0.1in
\end{table*}

\paragraph{$\mathbf{K}$=6 simulations} We looked at some simulations with a lower number of `true clusters' (6). All datasets had $P = 100$ covariates, and we split these into 20 batches or parallelised over 20 cores. We initialised with 10 clusters in all MerDel cases. We compare FedMerDel to parallelised MerDel. We looked at $N = 100,000$ and $N = 500,000$.

\paragraph{Varying $\mathbf{P}$}
We additionally compared the ARI, number of clusters and the time taken for clustering models using parallelised MerDel and FedMerDel when we varied $P$. In this simulation, we simulated 5 synthetic datasets and ran MerDel and FedMerDel with 5 `shuffles'/initialisations each time. Datasets were all of size $N = 100,000$ with 10 equally sized clusters, and we initialised with 20 clusters in all cases. We split into 5 equally sized batches for FedMerDel, and parallelised over 5 cores for parallelised MerDel. Results can be found in Appendix \ref{varyingPresults}.

\paragraph{Global Merge with Variable Selection}

For this simulation with variable selection (on binary data), we employed the `greedy search' for the global merge, and used correlation to assess similarity between clusters. The two scenarios had simulated data split into 5 equally sized batches with $N =$ 20,000, 50,000, with $K = $ 15 and 10 equally sized true clusters respectively. We set $P = 100$ covariates in both cases, where 80\% were relevant to the clustering structure in the first simulation and 75\% were relevant in the second simulation. We generated 5 simulated datasets and had 5 different `shuffles' of the data, as well as running MerDel on the full data 5 times (unparallelised and parallelised), as with other `global merge' simulations in this manuscript. 

As well as looking at ARI, number of resulting clusters and wall-clock time as with other simulations, we looked at the number of selected variables. As described in Section \ref{description:varsel}, for FedMerDel, we consider a variable selected if it was selected in either all batches, or all but one batch (where a variable is selected if $c_j > 0.5$, the expectation of the variable selection latent variable (Appendix \ref{variableselectionupdates})).

\subsection{Number of Batches} \label{setup:noofshards}

With datasets of size $N=100,000$ and $N=200,000$, we compared the clustering performance when considering $B=2, 4, 10$ and $B=4, 8, 20$ batches respectively. Batches were sized equally. We simulated 20 different synthetic datasets with $P=100$ for each scenario and took 5 different `shuffles' of the data for every global merge model. Models had 10 unevenly sized `true' clusters (cluster sizes ranging from 5\% to 20\% of the dataset) and were initialised with 20 clusters.

\clearpage

\section{Additional Simulation Results}

\subsection{Frequency of Merge/Delete Moves} \label{suppfreqresults}

Tables comparing wall-clock time, final log-ELBO and ARI of the resulting clustering structures in Simulations 1.1, 1.2 and 1.3 are shown below (Tables \ref{tablesim1}, \ref{tablesim2}, \ref{tablesim3}).

\begin{table*}[htb!]
\caption{Table comparing the mean wall-clock time, mean final log-ELBO, mean ARI and mean number of clusters of the final labelling structure across all runs in Simulation 1.1 with  confidence intervals for time and ARI (+- 1.96 x standard deviation).}
\label{tablesim1}
%\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lccccr}
\toprule
Laps & Time (s) & log-ELBO & ARI & Clusters \\
\midrule
0 & \textbf{3.46 [3.43, 3.49]} & -25357 & 0.856 [0.852, 0.860] & 5.01\\
1 & 6.35 [6.16, 6.55] & \textbf{-25354} & \textbf{0.858 [0.854, 0.862]} & 5.00 \\
2 & 5.88 [5.75, 6.01] & \textbf{-25354} & \textbf{0.858 [0.854, 0.862]} & 5.00\\
5 & 6.75 [6.65, 6.85] & \textbf{-25354} & \textbf{0.858 [0.854, 0.862]} & 5.00\\
10 & 8.68 [8.57, 8.80] & \textbf{-25354} & \textbf{0.858 [0.854, 0.862]} & 5.00 \\
10000 & 14.0 [13.2, 14.7] & -25617 & 0.823 [0.818, 0.828] & 15.3\\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
%\vskip -0.1in
\end{table*}

\begin{table*}[htb!]
\caption{Table comparing the mean wall-clock time, mean final log-ELBO, mean ARI and mean number of clusters of the final labelling structure across all runs in Simulation 1.2 with  confidence intervals for time and ARI (+- 1.96 x standard deviation).}
\label{tablesim2}
%\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lccccr}
\toprule
Laps & Time (s) & log-ELBO & ARI & Clusters \\
\midrule
0 & \textbf{10.9 [10.8, 11.0]} & -81256 & 0.959 [0.957, 0.961] & 7.65\\
1 & 29.1 [26.4, 31.8] & -81245 & 0.962 [0.960, 0.963] & 7.63\\
2 & 23.4 [21.7, 25.1] & -81238 & 0.962 [0.961, 0.963] & 7.70\\
5 & 25.4 [24.1, 26.7] & \textbf{-81236} & \textbf{0.963 [0.962, 0.964]} & 7.84\\
10 & 31.0 [30.0, 32.0] & -81260 & 0.962 [0.961, 0.963] & 8.54\\
10000 & 47.5 [45.0, 50.0] & -81721 & 0.940 [0.938, 0.942] & 18.0\\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
%\vskip -0.1in
\end{table*}

\begin{table*}[htb!]
\caption{Table comparing the mean wall-clock time, mean final log-ELBO, mean ARI and mean number of clusters of the final labelling structure across all runs in Simulation 1.3 with  confidence intervals for time and ARI (+- 1.96 x standard deviation).}
\label{tablesim3}
%\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lccccr}
\toprule
Laps & Time (s) & log-ELBO & ARI & Clusters \\
\midrule
0 & \textbf{29.1 [28.8, 29.4]} & -164099 & 0.953 [0.952, 0.955] & 10.0\\
1 & 57.1 [54.8, 59.5] & \textbf{-164090} & \textbf{0.954 [0.953, 0.955]} & 10.0\\
2 & 52.1 [50.7, 53.5] & -164095 & 0.954 [0.952, 0.955] & 10.0\\
5 & 61.8 [60.5, 63.1] & -164100 & 0.954 [0.952, 0.955] & 10.2\\
10 & 76.5 [74.7, 78.3] & -164173 & 0.953 [0.951, 0.954] & 12.0\\
10000 & 122 [112, 113] & -164675 & 0.943 [0.941, 0.944] & 22.7\\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
%\vskip -0.1in
\end{table*}


\begin{figure*}[!ht]
    \centering
    \subfloat[Simulation 1.2]{\includegraphics[scale=0.25]{figures/sim2timeline.png}}

    
    \subfloat[Simulation 1.3]{\includegraphics[scale=0.25]{figures/sim3timeline.png}}
    \caption{Graphs showing the ELBO vs wall-clock time for the algorithm for two simulated datasets across all 20 initialisations for each of the different "laps" in Simulations 1.2 and 1.3. The mean end time across all initialisations is shown as well as an approximate 95 confidence interval.}
    \label{Sim1linegraphs}
\end{figure*}

We can clearly see from Figure \ref{Sim1linegraphs} that a) the original variational model clearly takes far longer than models with merge/delete b) there are steep improvements in ELBO near the start with more frequent merge/delete moves. However, for example, `laps = 1' is near convergence very early on in both plots, but the algorithm takes longer to actually converge and stop. 

Another observation we made, especially with Simulation 1.1, is that the variations of MerDel (laps between 1 to 10) frequently identified exactly the same model as one another and achieved higher ARIs than the variational models with no merge/delete moves. This could be indicative that the merge/delete moves are allowing the model to escape local optima and could be reaching a global optimum.


\begin{figure}[ht]
\centerline{\includegraphics[scale=0.7]{figures/merdelsimclustplots.png}}
\caption{Plot comparing final number of clusters in clustering models in simulations 1.1-1.3.} \label{merdelsimclustplots}
\end{figure}


\newpage
\subsubsection{Variable Selection}

Tables comparing wall-clock time, final log-ELBO, ARI and number of clusters of the resulting clustering structures in Simulations 1.4 and 1.5 are shown below (Tables \ref{tablesim4}, \ref{tablesim5}). We still see a speed up in terms of wall-clock time in these simulations, but see that there is more inconsistency with solutions with noisier data, especially as we increase the number of merge/delete moves, and the mean ARI for merge/delete models is generally lower when we incorporate more merge/delete moves. The number of clusters at convergence is also lower than the number we expect. We see from Figure \ref{merdelvsARIplot} that it seems to be that merge/delete moves lead to less consistent results in the variable selection setting, but most of the best-performing models in terms of ARI are from MerDel models. As noted later (Section \ref{sec:catfreq}), fewer clusters and lower ARIs in MerDel models could be an indication that some `true' clusters could have been merged in the MerDel structures, if the `true' clusters share similar characteristics.

However, the mean ELBO achieved by the resulting clustering models at convergence is still higher for all merge/delete models compared to the model with no merge/delete moves. This suggests that more care needs to be taken with the frequency of merge/delete moves used when including variable selection - it is likely that our merge/delete models are sometimes, for example, jumping too quickly to a model which has marked more variables as irrelevant and has fewer clusters, but does have a higher ELBO. MerDel models are still able to achieve some improved results, but these are more inconsistent. 

\begin{figure}[ht]
\centerline{\includegraphics[scale=0.75]{figures/merdelsimARIvsplots.png}}
\caption{Scatter plot comparing ARIs achieved by each model across all datasets and initialisations in Simulations 1.4 and 1.5.}\label{merdelvsARIplot}
\end{figure}

\begin{table*}[htb!]
\caption{Table comparing the mean wall-clock time, mean final log-ELBO, mean ARI and mean number of clusters of the final labelling structure across all runs in Simulation 1.4 with  confidence intervals for time and ARI (+- 1.96 x standard deviation).}
\label{tablesim4}
%\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lccccr}
\toprule
Laps & Time (s) & log-ELBO & ARI & Clusters \\
\midrule
0 & \textbf{16.9 [16.6, 17.2]} & -41913 & 0.692 [0.674, 0.710] & 7.53\\
1 & 91.7 [84.0, 99.3] & -41848 & 0.731 [0.714, 0.747] & 7.86\\
2 & 75.6 [69.8, 81.4] & -41838 & 0.753 [0.739, 0.767] & 8.10\\
5 & 74.4 [70.0, 78.7] & \textbf{-41823} & 0.773 [0.759, 0.787] & 8.48\\
10 & 92.7 [88.4, 96.9] & -41831 & \textbf{0.792 [0.780, 0.804]} & 9.16\\
10000 & 128 [118, 138] & -42372 & 0.782 [0.774, 0.791] & 19.3\\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
%\vskip -0.1in
\end{table*}

\begin{table*}[htb!]
\caption{Table comparing the mean wall-clock time, mean final log-ELBO, mean ARI and mean number of clusters of the final labelling structure across all runs in Simulation 1.5 with  confidence intervals for time and ARI (+- 1.96 x standard deviation).}
\label{tablesim5}
%\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lccccr}
\toprule
Laps & Time (s) & log-ELBO & ARI & Clusters \\
\midrule
0 & \textbf{24.0 [23.7, 24.4]} & -61781 & 0.561 [0.540, 0.581] & 6.60 \\
1 & 137 [125, 149] & -61664 & 0.625 [0.605, 0.645] & 7.29 \\
2 & 110 [101, 118] & -61640 & 0.651 [0.631, 0.670] & 7.67 \\
5 & 112 [107, 118] & -61622 & 0.679 [0.661, 0.696] & 8.12 \\
10 & 149 [143, 156] & \textbf{-61612} & 0.710 [0.695, 0.725] & 8.90 \\
10000 & 213 [199, 227] & -62204 & \textbf{0.730 [0.721, 0.739]} & 19.3 \\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
%\vskip -0.1in
\end{table*}

We additionally used $F_1$ scores to compare the quality of variable selection. Having merge/delete moves tends to improve the quality of the variable selection as quantified by $F_1$ scores compared to the model with no merge/delete moves. This is illustrated in Table \ref{selectionsim1vs} with results from Simulation 1.4 shown. The gains are made especially in terms of identifying irrelevant, noisy variables, and laps 2 and 5 get the top $F_1$ scores of 0.977, indicating extremely good feature selection performance. Overall, although there is some desire for improvement in accuracy for the clustering structure when implementing variable selection, we see that merge and delete moves make improvements in identifying relevant clustering variables.

\begin{table*}[ht]
\caption{Table comparing the mean $F_1$ scores, and number of relevant and irrelevant variables successfully found across all simulated datasets and all initialisations in Simulation 1.4 and Simulation 1.5.}
\label{selectionsim1vs}
%\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lccc|ccr}
\toprule
 & \multicolumn{3}{c }{Simulation 1.4} & \multicolumn{3}{|c}{Simulation 1.5} \\
Laps & Rel & Irrel & $F_1$ Score & Rel & Irrel & $F_1$ Score \\
\midrule
0 & 73.4 & 21.7 & 0.968 & 58.8 & 34.6 & 0.947\\
1 & 73.5 & \textbf{22.7} & 0.975 & 58.7 & \textbf{36.0} & 0.957\\
2 & 73.9 & \textbf{22.7} & \textbf{0.977} & 59.2 & 35.8 & \textbf{0.959}\\
5 & 74.0 & 22.4 & \textbf{0.977} & \textbf{59.3} & 35.5 & 0.958\\
10 & 74.0 & 22.2 & 0.975 & \textbf{59.3} & 34.9 & 0.954\\
10000 & \textbf{74.1} & 15.5 & 0.935 & \textbf{59.3} & 23.1 & 0.872\\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
%\vskip -0.1in
\end{table*}

\clearpage

\subsection{Global Merge Simulations - Additional Results} \label{globalmergeappendix}

\begin{table*}[h!]
\caption{`Global Merge Simulations' results. We report the median and lower/upper quantiles across all 10 `shuffles'/initialisations and all 10 synthetic datasets. FedMerDel/G is the greedy search, FedMerDel/R is the random search for FedMerDel. Note separate independent datasets were generated for $N$ equal but different numbers of batches/cores, accounting for slight differences in ARI.}
\label{globalmergeresultsfull}
%\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lccccr}
\toprule
N & Model & Batches/Cores & ARI & Clusters & Time (s) \\
\midrule
20000 & full & 5 & 0.943 [0.933, 0.950] & 12 [11.8, 12] & 106 [92.8, 130]\\ 
 & par & 5 & 0.943 [0.930, 0.950] & 12 [11, 12] & 37.0 [33.4, 40.6] \\
 & FedMerDel/G& 5 & 0.920 [0.912, 0.933] & 12 [12, 12] & 33.1 [28.9, 37.2]\\
 & FedMerDel/R & 5 & 0.920 [0.912, 0.932] & 12 [12, 12] & 33.2 [29.1, 37.4]\\
\midrule
50000 & full & 5 & 0.947 [0.941, 0.954] & 12 [12, 12] & 467 [414, 554]\\ 
 & par & 5 & 0.948 [0.942, 0.954] & 12 [12, 12] & 176 [163, 196] \\
 & FedMerDel/G& 5 & 0.945 [0.939, 0.949] & 13 [13, 14] & 114 [106, 123]\\
 & FedMerDel/R & 5 & 0.945 [0.939, 0.948] & 12 [12, 12] & 114 [106, 123]\\
\midrule
50000 & full & 10 & 0.957 [0.955, 0.958] & 12 [12, 12] & 465 [432, 512]\\ 
 & par & 10 & 0.956 [0.955, 0.958] & 12 [12, 12] & 126 [121, 142] \\
 & FedMerDel/G& 10 & 0.951 [0.946, 0.954] & 13 [13, 14] & 70.6 [66.2, 75.8]\\
 & FedMerDel/R & 10 & 0.951 [0.946, 0.954] & 12 [12, 13] & 71.3 [66.8, 76.6]\\
\midrule
100000 & full & 5 & 0.955 [0.944, 0.961] & 12 [12, 12] & 956 [861, 1116]\\
 & par & 5 & 0.954 [0.944, 0.961] & 12 [12, 12] & 338 [310, 380] \\
 & FedMerDel/G& 5 & 0.954 [0.943, 0.960] & 13 [12, 13] & 260 [231, 287]\\
 & FedMerDel/R & 5 & 0.954 [0.943, 0.960] & 12 [12, 12] & 260 [232, 287]\\
\midrule
100000 & par & 10 & 0.949 [0.941, 0.959] & 12 [12, 12] & 249 [231, 284] \\
 & FedMerDel/G& 10 & 0.948 [0.938, 0.952] & 13 [13, 14] & 131 [123, 143]\\
 & FedMerDel/R & 10 & 0.948 [0.938, 0.952] & 12 [12, 13] & 132 [124, 144]\\
\midrule
200000 & par & 10 & 0.952 [0.947, 0.958] & 12 [12, 12] & 482 [446, 536]\\
 & FedMerDel/G& 10 & 0.951 [0.946, 0.957] & 13 [13, 14] & 269 [242, 303]\\
& FedMerDel/R & 10 & 0.951 [0.946, 0.957] & 12.5 [12, 13] & 270 [243, 305]\\
\midrule
500000 & par & 10 & 0.950 [0.943, 0.951] & 12 [12, 12] & 1121 [1056, 1303]\\
 & FedMerDel/G& 10 & 0.949 [0.942, 0.951] & 13 [13, 14] & 685 [642, 793]\\
& FedMerDel/R & 10 & 0.949 [0.942, 0.951] & 12.5 [12, 13] & 688 [646, 797]\\
\midrule
1000000 & par & 20 & 0.948 [0.943, 0.953] & 12 [12, 12] & 2119 [2031, 2204]\\
 & FedMerDel/G& 20 & 0.948 [0.943, 0.953] & 13.5 [13, 14] & 899 [825, 984]\\
& FedMerDel/R & 20 & 0.948 [0.943, 0.953] & 14 [13, 14] & 912 [840, 1007]\\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
%\vskip -0.1in
\end{table*}


\subsubsection{K=6 simulations}

Similar results were seen as with the simulation scenarios with $K=12$, where the gains in time efficiency from using FedMerDel instead of parallelised MerDel increased as $N$ increased.

\begin{table*}[h!]
\caption{Results from `Global Merge Simulations' with $K=6$ clusters, where all datasets have $P = 100$ covariates, and are split into 20 batches or parallelised over 20 cores. We initialised with 10 clusters in all MerDel cases. We compare FedMerDel to parallelised MerDel. We report the median and lower/upper quantiles across 5 `shuffles'/initialisations for 5 synthetic datasets. Results are for the random search; greedy searches differed insignificantly.}
\label{globalmergeresultsK6}
%\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lccccr}
\toprule
N & Model & ARI & Clusters & Time (s) \\
\midrule
100000 & par & 0.974 [0.967, 0.978] & 6 [6, 6] & 111 [103, 121]\\
 & FedMerDel & 0.965 [0.972, 0.977] & 6 [6, 6] & 70.5 [66.2, 77.6] \\
\midrule
500000 & par & 0.970 [0.969, 0.975] & 6 [6, 6] & 645 [619, 734]\\
 & FedMerDel & 0.970 [0.969, 0.975] & 6 [6, 6] & 455 [404, 516] \\
%\midrule
%1,000,000 & par & 0.972 [0.972, 0.973] & 10 [10, 10] & 316 [292, 345]\\
% & FedMerDel & 0.972 [0.971, 0.972] & 10 [10, 10] & 208 [203, 229]\\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
%\vskip -0.1in
\end{table*}

\subsubsection{Varying P} \label{varyingPresults}

We saw a similar pattern to $N$ where as $P$ increases, the gains made from FedMerDel are increased compared to parallelised MerDel.

\begin{table*}[h!]
\caption{`Global Merge Simulations' results, where all datasets are of size $N = 100,000$ (split into 5 batches/parallelised over 5 cores) and have 10 equally sized clusters, but $P$ (number of covariates) is varied. We compare FedMerDel to parallelised MerDel. We report the median and lower/upper quantiles across 5 `shuffles'/initialisations for 5 synthetic datasets. Results are for the random search; greedy searches differed insignificantly.}
\label{globalmergeresultsP}
%\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lccccr}
\toprule
P & Model & ARI & Clusters & Time (s) \\
\midrule
60 & par & 0.782 [0.753, 0.796] & 10 [10, 10] & 206 [194, 231]\\
 & FedMerDel & 0.780 [0.751, 0.794] & 10 [10, 10] & 153 [130, 169] \\
\midrule
80 & par & 0.874 [0.872, 0.880] & 10 [10, 10] & 285 [256, 333]\\
 & FedMerDel & 0.872 [0.870, 0.879] & 10 [10, 10] & 190 [182, 231] \\
\midrule
120 & par & 0.972 [0.972, 0.973] & 10 [10, 10] & 316 [292, 345]\\
 & FedMerDel & 0.972 [0.971, 0.972] & 10 [10, 10] & 208 [203, 229]\\
\midrule
200 & par & 0.999 [0.999, 0.999] & 10 [10, 10] & 465 [453, 469]\\
 & FedMerDel & 0.999 [0.999, 0.999] & 10 [10, 10] & 295 [291, 302]\\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
%\vskip -0.1in
\end{table*}

\begin{figure}[ht]
\centerline{\includegraphics[scale=0.55]{figures/globalmergePlines.png}}
\caption{Plot comparing the mean time taken by parallelised MerDel (`par') and FedMerDel (`shard') as we vary $P$, with a 95\% confidence interval (mean $\pm$ 1.96 $\times \frac{s.d}{\sqrt{n}}$). Results for FedMerDel are with the greedy search, although there is no visible difference for the random search.}
\end{figure}

\subsubsection{Global Merge with Variable Selection}

Results showed similar performance in terms of ARI between FedMerDel and MerDel on the full dataset (Table \ref{globalmergeresultsvs}). In these scenarios (with relatively low $N$) FedMerDel did not outperform parallelised MerDel in terms of wall-clock time, but notably was almost always able to correctly identify relevant and irrelevant variables, outperforming both other methods, which usually wrongly identified some irrelevant variables as relevant. Global merge times were less than one second in all cases.

\begin{table*}[h!]
\caption{`Global Merge with Variable Selection' simulation results. We report the median and lower/upper quantiles across all 5 `shuffles'/initialisations and all 5 synthetic datasets. Global merge uses the `greedy search'. `Rel' and `Irrel' refer to the number of correctly identified relevant and irrelevant covariates respectively.} 
\label{globalmergeresultsvs}
%\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lcccccr}
\toprule
$N$ & Model & ARI & Clusters & Time (s) & Rel & Irrel \\
\midrule
20000 & full & 0.865 [0.862, 0.868] & 15 [15, 15] & 782 [687, 835] & 80 [80, 80] & 18 [17, 18] \\
 & par & 0.865 [0.862, 0.868] & 15 [15, 15] & 207 [187, 228]  & 80 [80, 80] & 17 [16, 17] \\
 & FedMerDel & 0.850 [0.844, 0.857] & 15 [15, 15] & 223 [212, 242]  & 80 [80, 80] & 20 [20, 20] \\
\midrule
50000 & full & 0.885 [0.876, 0.885] & 10 [10, 10] & 1607 [1493, 1767] & 75 [75, 75] & 23 [22, 24] \\
 & par & 0.885 [0.876, 0.886] & 10 [10, 10] & 462 [440, 527]  & 75 [75, 75] & 23 [22, 24] \\
 & FedMerDel & 0.881 [0.873, 0.883] & 10 [10, 10] & 630 [563, 672]  & 75 [75, 75] & 25 [25, 25] \\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
%\vskip -0.1in
\end{table*}

\subsection{Number of Batches} \label{result:numberofbatches}

Detailed results from this simulation study can be found in Table \ref{numberofshards} and Figure \ref{noofshardsboxplot}. A Kruskal-Wallis test testing for any significant difference between the ARI for different numbers of batches for $N=100,000$ gives a p-value of 0.125. For $N=200,000$, the p-value is 0.0938. One way to potentially improve inference for the number of clusters for higher values of $K_{\mbox{init}}$ would be to look at higher frequencies of merge/delete moves within each MerDel run.

\begin{table*}[htp]
\caption{`Number of Batches' simulation results. We report the median and lower/upper quantiles across all 5 `shuffles' for each of the 20 synthetic datasets. Results use the random search for the global merge; there were only marginal differences for the greedy search.}
\label{numberofshards}
%\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lccr}
\toprule
$N$ & Batches & ARI & Clusters \\
\midrule
100000 & 2 & 0.956 [0.950, 0.960] & 10 [10, 10] \\
100000 & 4 & 0.955 [0.951, 0.960] & 10 [10, 10]\\
100000 & 10 & 0.955 [0.951, 0.959] & 10 [10, 11] \\
\midrule
200000 & 4 & 0.954 [0.946, 0.959] & 10 [10, 10] \\
200000 & 8 & 0.954 [0.946, 0.959] & 10 [10, 10] \\
200000 & 20 & 0.953 [0.944, 0.958] & 10 [10, 11] \\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
%\vskip -0.1in
\end{table*}

\begin{figure}[htp]
\centering 

\subfloat[]{%
  \includegraphics[width=0.32\textwidth]{figures/number_shards_B.png}%
}
\subfloat[]{%
  \includegraphics[width=0.32\textwidth]{figures/number_shards_C.png}%
}
\caption{Boxplot showing the distribution of ARI scores across different numbers of batches in the `Number of Batches' simulation.} \label{noofshardsboxplot}
\end{figure}

\clearpage

\subsection{Comparing Merge Criteria} \label{sec:corrdivrand}

In this simulation, we compared methods of selecting candidate clusters for merging as described in Section \ref{howtomerge}. We compared a correlation measure (`corr') and two divergence-based measures (Kullback-Leibler divergence, `KL', and the Bhattacharyya distance, `bha') to completely random selection of candidate clusters (`rand').

We ran two simulation studies: one with $N=2000$, $K_{\mbox{true}}=10$, $K_{\mbox{init}}=20$ and $P=50$ (A in Figure \ref{cdrplots}), and one with $N=2000$, $K_{\mbox{true}}=20$, $K_{\mbox{init}}=40$ and $P=100$ (B in Figure \ref{cdrplots}). In both cases, we simulated 30 independently generated binary datasets. For each dataset and each model, we ran the model 10 times with a different initialisation each time (giving 40 initialisations per dataset, and 10 per model). For each initialisation, we tested laps = \{1, 5\}. 

Figure \ref{cdrplots} illustrates that generally, there was not a significant difference between the choice of methods to select candidate clusters for merging in terms of time and accuracy, although as expected, random choice did tend to take slightly longer - especially for laps = 5 and in the dataset with more clusters. In plot B in Figure \ref{cdrplots}(b), the median of the ARIs achieved by `rand' is slightly lower than other methods with both laps = 1 and 5. We saw that the proportion of accepted merges was significantly lower than all other methods with random choice in most cases, and that `corr' saw slightly lower merge rates than divergence-based measures. However, the computational complexity of calculating divergences is higher, leading to similar total times for the overall algorithm in Figure \ref{cdrplots}(a).

\begin{figure}[htp]
\centering 

\subfloat[Comparing log(total time (s))]{%
  \includegraphics[clip,width=0.75\columnwidth]{figures/cdr_time.pdf}%
}

\subfloat[Comparing ARI]{%
  \includegraphics[clip,width=0.75\columnwidth]{figures/cdr_ARI.pdf}%
}

\subfloat[Comparing `merge rate', defined as proportions of merges accepted.]{%
  \includegraphics[clip,width=0.75\columnwidth]{figures/cdr_mergerate.pdf}%
}

\caption{Boxplots comparing the distributions of ARI scores, (the logarithm of) total wall-clock time until convergence, and `merge rates'. All initialisations for each model, simulated dataset and `laps' value are included, where the boxplots illustrate the median, quantiles and range across all clustering solutions.} \label{cdrplots}
\end{figure}

\clearpage


\subsection{Categorical Data Simulations}

\subsubsection{Frequency of Merge/Delete Moves} \label{sec:catfreq}

Details of the scenarios for this simulation study with categorical data (analogous to Section \ref{setup:freqmerdel}) are given in a table below. Both simulations were run without variable selection. $K_{init}$ refers to the initialised value of $K$ in the model. In both scenarios, we generated 20 independent datasets and compared 10 different initialisations for each dataset. 

\begin{table*}[hb!]
\caption{Table giving parameters for data generation for the frequency of merge/delete moves with categorical data.}
\label{simFedMerDeltablecat}
%\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lcccccr}
\toprule
ID & $N$ & $P$ & $K_{init}$ & $K_{true}$ & $N$ per & Categories\\
  &  &  &  &  & Cluster & \\
\midrule
    cat.1  & 2000 & 100 & 20 & 8 & 50-800 & 4\\
    cat.2  & 4000 & 100 & 25 & 10 & 200-800 & 3\\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
%\vskip -0.1in
\end{table*}

Tables comparing wall-clock time, final log-ELBO and ARI of the resulting clustering structures in Simulations cat.1, and cat.2 are shown below (Tables \ref{catsim1}, \ref{catsim2}).

It is notable that the model with no merge/delete moves (laps = 10000) performed significantly worse in terms of ARI in these simulations, especially when we increased the number of categories in each covariate (ie. in Simulation cat.1 with 4 categories). We also saw in both simulations that the fully variational model never ended with fewer clusters than the initialisation, which could suggest that the lower ARI could be associated with observations remaining in smaller clusters which are subsets of the original clusters. ARI scores only take into account pairwise clustering similarity; one cluster being split into multiple subclusters in another clustering result will result in the two clustering structures sharing a relatively low ARI, due to observations being in different clusters, even though it is a subcluster of the original cluster.

A brief inspection of the resulting clustering structures in Simulation cat.1 (for example) provided further evidence to this effect, where many of the 20 clusters contained more than just a few `left-out' observations. In Simulation cat.1, the very uneven true cluster sizes could have also contributed to this effect. This further supports the usefulness of merge/delete moves in MerDel when applied to categorical data; these moves clearly help to mitigate poor optima and find a number of clusters closer to the truth.

Figure \ref{catlinegraphs} illustrates the change in ELBO versus time for one simulated dataset for both categorical simulations. It is clear in these graphs that MerDel is able to converge at a `better' local optima of the optimisation surface (ie. one with a higher ELBO) compared to the usual variational algorithm.

\begin{figure}[h!]
\centerline{\includegraphics[scale=0.7]{figures/merdelARIplots_cat.png}}
\caption{Scatter plot comparing ARIs achieved by each model across all datasets and initialisations in Simulations cat.1 and cat.2 (labelled 1, 2 respectively). Each point represents one ARI from one MerDel run.}
\end{figure}

\begin{figure}[hb!]
\centerline{\includegraphics[scale=0.7]{figures/merdelclusterplots_cat.png}}
\caption{Plot comparing final number of clusters in clustering models in simulations cat.1 and cat.2.}
\end{figure}

\begin{table*}[hb!]
\caption{Table comparing the mean wall-clock time, mean final log-ELBO, mean ARI and mean number of clusters of the final labelling structure across all runs in Simulation cat.1 with  confidence intervals for time and ARI (+- 1.96 x standard deviation).}
\label{catsim1}
%\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lccccr}
\toprule
Laps & Time (s) & log-ELBO & ARI & Clusters \\
\midrule
0 & \textbf{14.4 [14.2, 14.5]} & -238524 & 0.961 [0.951, 0.971] & 7.72\\
1 & 27.6 [25.6, 29.5] & -238378 & 0.994 [0.993, 0.995] & 7.48 \\
2 & 24.5 [23.1, 25.8] & -238356 & \textbf{0.995 [0.994, 0.996]} & 7.56 \\
5 & 29.2 [28.5, 29.8] & \textbf{-238352} & \textbf{0.995 [0.994, 0.996]} & 7.71\\
10 & 38.7 [37.8, 39.5] & -238513 & 0.986 [0.984, 0.988] & 8.37\\
10000 & 79.2 [74.6, 83.8] & -241501 & 0.831 [0.827, 0.835] & 20\\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
%\vskip -0.1in
\end{table*}

\begin{table*}[htb!]
\caption{Table comparing the mean wall-clock time, mean final log-ELBO, mean ARI and mean number of clusters of the final labelling structure across all runs in Simulation cat.2 with  confidence intervals for time and ARI (+- 1.96 x standard deviation).}
\label{catsim2}
%\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lccccr}
\toprule
Laps & Time (s) & log-ELBO & ARI & Clusters \\
\midrule
0 & \textbf{34.8 [34.1, 35.4]} & -360586 & 0.991 [0.988, 0.995] & 10.1\\
1 & 47.0 [46.0, 48.1] & \textbf{-360544} & \textbf{0.999 [0.999, 1.00]} & 10.0\\
2 & 49.8 [48.8, 50.7] & \textbf{-360544} & \textbf{0.999 [0.999, 1.00]} & 10.0\\
5 & 66.1 [65.1, 67.0] & -360568 & 0.998 [0.998, 0.999] & 10.2\\
10 & 91.1 [89.5, 92.8] & -360795 & 0.991 [0.990, 0.992] & 12.1\\
10000 & 172 [162, 181] & -312628 & 0.939 [0.937, 0.941] & 25\\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
%\vskip -0.1in
\end{table*}



\begin{figure*}[ht]
    \centering
    \subfloat[Simulation cat.1]{\includegraphics[scale=0.22]{figures/merdeltimeline_cat.png}}

    
    \subfloat[Simulation cat.2]{\includegraphics[scale=0.22]{figures/merdeltimeline_cat2.png}}
    \caption{Graphs showing the ELBO vs wall-clock time for the algorithm for two simulated datasets across all 20 initialisations for each of the different "laps" in Simulations cat.1 and cat.2. The mean end time across all initialisations is shown as well as an approximate 95 confidence interval.}
    \label{catlinegraphs}
\end{figure*}

\subsubsection{Global Merge Simulations}

For this simulation with categorical data, we employed the `random search' for the global merge and used the KL divergence to assess similarities between clusters in both the local merge move and the global merge (recall in the binary simulation, we used correlation). The three scenarios had simulated data with $N =$ 20,000, 50,000, 100,000, with $K = $ 20, 10 and 12 true clusters split into 4, 5 and 5 equally sized batches respectively. We set $P = 100$ covariates and 3 categories in each covariate in all cases. We generated 5 simulated datasets and had 10 different `shuffles' of the data in each scenario, as well as running MerDel and parallelised MerDel on the full data 10 times, as with the binary simulations. 

Results showed extremely good performance with almost perfect clustering structures whether or not we employed a global merge or not in all cases. There was a clear speed up for the global merge model and for parallelised MerDel, and as we saw with binary data, as the data size increased, we saw increased gains from using FedMerDel as opposed to parallelising MerDel stepwise. Note the higher merge times and total times with $N=20,000$ were likely a result of the increased number of true clusters and initialised clusters in each MerDel run (30). In the later two simulations, we initialised with 20 clusters.

\begin{table*}[htb!]
\caption{`Global Merge Simulations' with categorical data results. We report the median and lower/upper quantiles across all 10 `shuffles'/initialisations and all 5 synthetic datasets.}
\label{globalmergeresultscat}
%\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lccccc}
\toprule
$N$ & Model & ARI & Clusters & Time (s) & Global Merge Time (s)\\
\midrule
20000 & full & 0.999 [0.999, 0.999] & 20 [20, 20] & 387 [373, 418] & \\
& par & 0.999 [0.999, 0.999] & 20 [20, 21] & 146 [128, 157] & \\
 & FedMerDel & 0.998 [0.99, 0.998] & 20 [20, 20] & 124 [118, 131] & \hfil3.91 [3.82, 4.14]\\
\midrule
50000 & full & 0.999 [0.999, 1.00] & 10 [10, 10] & 374 [373, 375]\\
 & par & 0.999 [0.999, 1.00] & 10 [10, 10] & 127 [125, 128] & \\
 & FedMerDel & 0.999 [0.999, 1.00] & 10 [10, 10] & 83.5 [80.7, 84.1] &\hfil 1.29 [1.28, 1.34]\\
 \midrule
100000 & full & 1.00 [0.999, 1.00] & 12 [12, 12] & 946 [857, 1050]\\
 & par & 1.00 [0.999, 1.00] & 12 [12, 12] & 293 [276, 339] & \\
 & FedMerDel & 0.999 [0.990, 1.00] & 12 [12, 13] & 243 [219, 280] &\hfil 2.57 [2.49, 2.64]\\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
%\vskip -0.1in
\end{table*}


\clearpage

\section{MNIST - Additional Results}

\subsection{Supplementary Figures}

\begin{figure}[htp]
\centering 

\subfloat[Original]{%
  \includegraphics[clip,width=0.75\columnwidth]{figures/og_mnist_test.png}%
}

\subfloat[Dimension-reduced]{%
  \includegraphics[clip,width=0.75\columnwidth]{figures/dimred_mnist_test.png}%
}

\subfloat[Binarised]{%
  \includegraphics[clip,width=0.75\columnwidth]{figures/bin_mnist_test.png}%
}

\caption{Example of the first 10 MNIST test-set digits visualised in their original image format (28x28), the same digits with the dimensionality reduction applied (16x16), and the same dimension reduced digits converted to a binary format.}

\end{figure}

\begin{figure}[htp]
\centering 

\subfloat[4]{%
  \includegraphics[clip,width=0.75\columnwidth]{figures/mnist_4_images.png}%
}

\subfloat[7]{%
  \includegraphics[clip,width=0.75\columnwidth]{figures/mnist_7_images.png}%
}

\subfloat[9]{%
  \includegraphics[clip,width=0.75\columnwidth]{figures/mnist_9_images.png}%
}

\caption{10 randomly selected digits of 4, 7 and 9 from the MNIST dataset, showing similarities in their shapes.} \label{479}

\end{figure}

\begin{figure}[ht]
\centerline{\includegraphics[scale=0.36]{figures/mnist_percent.png}}
\caption{A heatmap showing the correspondence between clusters and true numbers in the clustering model with the best ELBO for the MNIST data. A darker cell colour in entry (i, j) indicates a higher percentage of samples from number i are in the given cluster j. The exact number corresponds to the percentage of cluster j made up of the given number.} \label{mnistheatmap}
\end{figure}

\begin{figure}[htp]
\centering 

\subfloat[Sorted by true digits]{%
  \includegraphics[clip,width=0.9\columnwidth]{figures/mnist_og.png}%
}

\subfloat[Sorted by cluster]{%
  \includegraphics[clip,width=0.9\columnwidth]{figures/mnist_sorted.png}%
}

\caption{Heatmaps showing the first 2000 digits in our pre-processed MNIST dataset, first sorted by true digit and then sorted by cluster for the clustering model with the best ELBO. Differences between and within digits can be seen.}

\end{figure}

\begin{figure}[htp]
\centering 

\subfloat[Columns in default order]{%
  \includegraphics[clip,width=0.9\columnwidth]{figures/mnist_0and1.png}%
}

\subfloat[Columns shuffled]{%
  \includegraphics[clip,width=0.9\columnwidth]{figures/mnist_0and1shuffle.png}%
}

\caption{Heatmaps showing only 0's and 1's in the first 10000 digits in our pre-processed MNIST dataset, sorted by cluster within both digits. Shuffling the columns allows the differences between separate clusters to be clearer.}

\end{figure}

\clearpage

\subsection{Supplementary Results - Classification Rates} \label{sec:classrates}

In Table \ref{mnist_class}, the models included are:
\begin{itemize}
    \item \textbf{FedMerDel\_rand:} Our novel federated learning model, FedMerDel, analysed in the main paper. This included 6 equally sized batches of data with 20 maximum clusters in each batch. A random search was used for the global merge. All models took between 77-126 mins. 
    \item \textbf{FedMerDel\_greedy:} FedMerDel, but with a greedy search used for the global merge. The same batches were used as with FedMerDel\_random above. All models took between 77-127 minutes.
    \item \textbf{FedMerDel\_30r}: FedMerDel with 6 equally sized batches of data, but now with 30 maximum clusters in each batch. These models had slightly better classification rates, but came at a high cost of computational time with 60 extra clusters being processed, and reduced scope for interpretation of clusters. Resulting models had between 52-70 clusters. More clusters than 30 per batch could be used if an even finer and robust clustering structure is desired, but this was not the aim of our analysis, where we focused on finding a broad clustering structure with a large dataset to validate the scalability of our method. This model used a random search.
    \item \textbf{FedMerDel\_30g}: Same model and batches as above, but with a greedy search. These models had between 52-61 clusters. 
    \item \textbf{kmeans\_xx\_yy}: In this model, in order to implement scalable clustering methods for continuous data to compare to, we projected the data to a lower dimension with Multiple Correspondence Analysis (MCA), a counterpart to principal component analysis for categorical data. We then implement the k-means algorithm on this lower-dimesional data. xx represents the number of MCA dimensions kept in the model, which is 5 (explaining 20\% of variance), 10 (explaining 30\% of variance) or 17 (explaining 40\% of variance). yy represents the number for $k$, the number of clusters, where we test 20 and 35. In all cases, we use 20 maximum iterations for k-means, and 20 different initialisations, and use the clustering with the best total within-cluster sum of squares. We saw that this method is quick (taking no longer than a minute) and generally performs well especially as we increase the number of dimensions and clusters, although does not separate numbers such as 2, 3 and 6 as well as our models.
    \item \textbf{EM\_yy}: We applied an EM algorithm for frequentist model estimation to fit a finite mixture model to the MNIST binary data via the R package \textit{flexmix} \citep{Leisch2004} and used the BIC (Bayesian Information Criterion) for model selection across a given number of initialisations. yy represents the number of clusters in the finite mixture model, and we test 20 (10.2 mins) and 35 (55.4 mins). We use 10 different initialisations, and the model returned is the maximum likelihood solution. 
    \item \textbf{MCA\_EM\_yy}: We also applied an EM algorithm to fit a Gaussian mixture model to MCA-transformed MNIST data. For this, we used the R package \textit{mclust} which also uses the BIC to select the optimal model between 14 models with different shapes, volumes, and orientations of covariances. yy represents the number of clusters in the finite mixture model, and we test 20 (4.45 mins) and 35 (9.77 mins). 
\end{itemize}
Generally, FedMerDel performed similarly well to comparitor methods, where 0's, 1's, 2's and 6's saw higher classification rates with methods such as EM. 

\begin{table}[ht]
\caption{Table comparing classification rates (\%) for each digit across different clustering models. The model analysed further in the paper and supplement was the 4th FedMerDel\_rand run as the model with the highest ELBO of all the FedMerDel\_rand and FedMerDel\_greedy runs. Classification rate is defined as the percentage of digits classified into a cluster primarily consisting of that digit.} \label{mnist_class}
\begin{center}
\begin{tabular}{llllllllllll}
\textbf{MODEL} & \textbf{RUN} & \textbf{0} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8} & \textbf{9} \\
\hline \\
FedMerDel\_rand & 1 & 83.4 & 95.5 & 83.7 & 75.5 & 49.6 & 37.8 & 90.4 & 62.2 & 65.6 & \textbf{55.3} \\
FedMerDel\_rand & 2 & 84.1 & 94.8 & \textbf{86.3} & 65.2 & 54.8 & 38.6 & 90.1 & 56.0 & 67.3 & 47.8 \\
FedMerDel\_rand & 3 & \textbf{86.4} & 95.4 & 85.8 & 73.9 & 47.6 & 34.6 & \textbf{92.7} & 63.0 & 64.4 & 49.4 \\
FedMerDel\_rand & 4 & 81.4 & \textbf{96.0} & 83.8 & 71.7 & 51.7 & \textbf{47.2} & 92.5 & 67.7 & \textbf{70.2} & 44.8\\
FedMerDel\_rand & 5 & 82.7 & 94.6 & 83.4 & \textbf{83.4} & \textbf{57.7} & 34.5 & 92.0 & \textbf{74.5} & 52.4 & 34.7 \\
\hline
FedMerDel\_greedy & 1 & 83.4 & 95.5 & 83.7 & 75.5 & 53.7 & 37.8 & 90.4 & 62.2 & 65.6 & \textbf{51.4} \\
FedMerDel\_greedy & 2 & 84.1 & 94.8 & \textbf{86.3} & 70.2 & 54.8 & 33.6 & 90.1 & 56.0 & 64.5 & 47.8 \\
FedMerDel\_greedy & 3 & \textbf{86.4} & 95.4 & 85.8 & 73.9 & 47.6 & 34.6 & \textbf{92.7} & 63.0 & 64.4 & 49.4 \\
FedMerDel\_greedy & 4 & 81.4 & \textbf{96.0} & 83.8 & 71.7 & 51.7 & \textbf{47.2} & 92.5 & 67.7 & \textbf{70.2} & 44.8 \\
FedMerDel\_greedy & 5 & 82.7 & 94.6 & 83.4 & \textbf{83.4} & \textbf{57.7} & 34.5 & 92.0 & \textbf{74.5} & 52.4 & 34.6 \\
\hline
FedMerDel\_30r & 1 & \textbf{91.8} & 94.5 & 85.7 & 80.5 & 54.5 & 51.7 & \textbf{94.3} & 71.0 & 68.8 & 50.3 \\
FedMerDel\_30r & 2 & 88.6 & 95.3 & \textbf{85.8} & 76.3 & 56.3 & 46.2 & 93.2 & 70.1 & \textbf{69.0} & \textbf{59.7} \\
FedMerDel\_30r & 3 & 91.3 & \textbf{95.4} & 85.2 & \textbf{83.0} & \textbf{59.8} & \textbf{53.8} & 93.1 & \textbf{78.5} & 65.2 & 34.5 \\
\hline
FedMerDel\_30g & 1 & \textbf{91.8} & 94.5 & 85.7 & 80.5 & 54.5 & 51.7 & \textbf{94.3} & 69.0 & 68.8 & 52.9 \\
FedMerDel\_30g & 2 & 88.6 & 95.3 & \textbf{85.8} & 74.9 & 56.3 & 44.8 & 93.2 & 70.1 & \textbf{71.6} & \textbf{59.7} \\
FedMerDel\_30g & 3 & 91.3 & \textbf{95.4} & 85.2 & \textbf{84.2} & \textbf{62.4} & \textbf{53.8} & 93.1 & \textbf{76.9} & 60.7 & 34.5 \\
\hline 
k-means\_5\_20 & & 65.2 & 92.0 & 50.2 & 41.9 & 43.1 & 40.6 & \textbf{86.9} & 63.9 & 27.5 & 33.6 \\
k-means\_5\_35 & & 86.9 & 78.6 & 58.9 & 74.0 & 31.6 & 14.9 & 80.3 & 72.8 & 24.8 & \textbf{56.5} \\
k-means\_10\_20 & & 81.4 & 97.8 & 65.9 & 74.6 & 54.3 & 31.1 & 83.2 & 70.8 & 40.2 & 39.9 \\
k-means\_10\_35 & & 86.5 & 95.8 & \textbf{73.5} & 72.9 & \textbf{77.6} & \textbf{43.4} & 86.7 & \textbf{81.2} & 49.5 & 27.7 \\
k-means\_17\_20 & & 83.1 & \textbf{98.6} & 63.7 & 60.9 & 51.9 & 33.4 & 85.0 & 79.7 & 46.3 & 32.6 \\
k-means\_17\_35 & & \textbf{91.5} & 97.8 & 68.3 & \textbf{77.9} & 62.1 & 23.5 & 83.6 & 75.7 & \textbf{57.0} & 50.0 \\
\hline
EM\_20 & & 82.1 & 95.6 & 83.7 & 84.9 & \textbf{62.2} & 29.7 & 91.8 & 72.4 & 57.4 & 38.0 \\
EM\_35 & & \textbf{87.6} & \textbf{96.1} & \textbf{90.2} & \textbf{85.8} & 51.8 & \textbf{51.9} & \textbf{94.8} & \textbf{81.8} & \textbf{72.3} & \textbf{62.6} \\
\hline
MCA\_EM\_20 & & 74.9 & 87.5 & \textbf{71.5} & 46.2 & 53.7 & \textbf{53.6} & 87.0 & 41.2 & 0.00 & \textbf{55.4} \\
MCA\_EM\_35 & & \textbf{81.7} & \textbf{89.8} & 49.7 & \textbf{73.1} & \textbf{58.9} & 41.2 & \textbf{89.1} & \textbf{62.7} & \textbf{19.3} & 39.0 \\
\end{tabular}
\end{center}
\end{table}

\clearpage

\subsection{Generated Digits} \label{sec:gendigits}

\begin{figure}[htp!]
\centerline{\includegraphics[scale=0.7]{figures/gendigits.png}}
\caption{3 randomly selected observations and 2 generated digits (from the variational distribution) from each cluster in the clustering model with the best ELBO for the MNIST data.}
\end{figure}

\clearpage

\section{EHR Data - Additional Information} \label{EHRappendix}
EHR data were obtained from The Health Improvement Network database. The start date for our study was 01 January 2010 and end date was 01 January 2017. The dataset comprised primary care health data for 289,821 individuals over 80 years old who had at least two of the long term health conditions considered in our analysis.  The full list of health conditions, and their coding, is provided in Table~\ref{LTCs}. 64.8\% of individuals contributing to the analysis dataset were female, 35.2\% were male.  

\subsection{Greedy Search Global Merge}
In Figure 3 of the main manuscript, we illustrated the global clusters identified using the ``random search" approach to perform the global merge. In Figure \ref{MMsummary1} below, we provide the corresponding results obtained using the ``greedy search" approach.


\begin{figure}[ht]
\centerline{\includegraphics[scale=0.6]{figures/summary1annotated.pdf}}
\caption{Results of global EHR clustering using the greedy search approach to perform the global merge. Columns are health conditions, and rows correspond to clusters. Row labels (shown on the right) indicate the number of individuals in each cluster. Summary names for each of the clusters are provided on the left of the plot. To improve visualisation, only the most prevalent health conditions are shown. }\label{MMsummary1}
\end{figure}


\begin{table}[!ht]
\caption{Table providing the full list of health conditions, and their coding used in the analysis and figures.} \label{LTCs}
    \centering
    \begin{tabular}{|p{2.8cm}|p{4.8cm}|p{2.8cm}|p{4.8cm}|}
    \hline
    \rowcolor{LightGrey}
        Coding  & Condition & Coding  & Condition \\ \hline
        cancerall & Any cancer diagnosis & endometriosis & Endometriosis \\ \hline
        ca\_lung & Lung cancer & pcos & Polycystic ovary syndrome \\ \hline
        ca\_breast & Breast cancer & pernicious\_anaemia & Pernicious anaemia \\ \hline
        ca\_bowel & Bowel cancer & vte & Venous thromboembolism  \\ \hline
        ca\_prostate & Prostate cancer & pulmonary\_embolism & Pulmonary embolism \\ \hline
        lymphoma & Lymphoma & coagulopathy & Coagulopathy \\ \hline
        leukaemia & Leukaemia & depression & Depression \\ \hline
        ca\_skin & Skin cancer & anxiety & Anxiety \\ \hline
        melanoma & Melanoma & smi & Serious mental illness \\ \hline
        ca\_metastatic & Metastatic cancer & substance\_misuse & Substance misuse \\ \hline
        arrhythmia & Arrhythmia & alcohol\_problem & Alcohol problem \\ \hline
        af & Atrial fibrillation & adhd & Attention deficit hyperactivity disorder \\ \hline
        hypertension & Hypertension & eating\_disorder & Eating disorder \\ \hline
        hf & Hear failure & learning\_disability & Learning disability \\ \hline
        ihd & Ischemic heart disease & alzheimers & Alzheimer's disases \\ \hline
        valve\_disease & Heart valve disease & vascular\_dementia & Vascular dementia \\ \hline
        cardiomyopathy & Cardiomyopathy  & dementia & Dementia \\ \hline
        con\_heart\_disease & Congenital heart disease & parkinsons & Pakinson's disease \\ \hline
        pvd & Peripheral vascular disease & migraine & Migraine \\ \hline
        aortic\_aneurysm & Aortic aneurysm & ms & Multiple sclerosis \\ \hline
        tia & Transient ischaemic attack   & epilepsy & Epilepsy \\ \hline
        isch\_stroke & Ischaemic stroke & hemiplegia & Hemiplegia \\ \hline
        haem\_stroke & Haemorrhagic stroke & cfs & Chronic fatigue syndrome \\ \hline
        nos\_stroke & Stroke (not otherwise specified) & fibromyalgia & Fibromyalgia \\ \hline
        tia\_stroke & TIA stroke & oa & Osteoarthritis \\ \hline
        eczema & Eczema & osteoporosis & Osteoporosis \\ \hline
        psoriasis & Psoriasis & polymyalgia & Polymyalgia \\ \hline
        vitiligo & Vitiligo & ra & Rheumatoid arthritis \\ \hline
        alopecia & Alopecia & sjogren & SjÃ¶gren's syndrome  \\ \hline
        rhin\_conjunc & Rhinoconjunctivitis & sle & Systemic lupus erythematosus  \\ \hline
        sinusitis & Sinusitis & systematic\_sclerosis & Systematic sclerosis \\ \hline
        deaf & Deafness & psoriatic\_arthritis & Psoriatic arthritis \\ \hline
        blind & Blindness & ank\_spond & Ankylosing spondylitis \\ \hline
        cataract & Cataract & gout & Gout \\ \hline
        glaucoma & Glaucoma & ckd & Chronic kidney disease \\ \hline
        amd & Age-related macular degeneration & copd & Chronic obstructive pulmonary disease  \\ \hline
        retinopathy & Retinopathy & asthma & Asthma \\ \hline
        uveitis & Uveitis & osa & Obstructive sleep apnea \\ \hline
        scleritis & Scleritis & bronchiectasis & Bronchiectasis \\ \hline
        peptic\_ulcer & Peptic ulcer & pulmonary\_fibrosis & Pulmonary fibrosis \\ \hline
        ibd & Inflammatory bowel disease & hyperthyroidism & Hyperthyroidism \\ \hline
        ibs & Irritable bowel syndrme & hypothyroid & Hypothyroidism \\ \hline
        liver\_disease & Liver disease  & t1dm & Type 1 diabetes mellitus \\ \hline
        nash\_nafl & Nonalcoholic steatohepatitis/ Nonalcoholic fatty liver  & t2dm & Type 2 diabetes mellitus \\ \hline
        diverticuli & Diverticulitis & hiv & Human immunodeficiency virus \\ \hline
        coeliac & Coeliac disease & bph & Benign prostatic hyperplasia \\ \hline
        pancreatitis & Pancreatitis & erectile\_dysfunction & Erectile dysfunction \\ \hline
    \end{tabular}
\end{table}

\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
