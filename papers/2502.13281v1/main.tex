%%
%% This is file `sample-sigconf-authordraft.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,authordraft')
%% 

%% When submitting camera ready or to TAPS, please change the command
\documentclass[sigconf]{acmart}
%\documentclass[manuscript,nonacm]{acmart}
\settopmatter{printacmref=false} % Remove ACM reference block and page numbers
\renewcommand\footnotetextcopyrightpermission[1]{} % Remove the copyright footnote
\pagestyle{plain} % Use a plain page style (no header/footer)
%\documentclass[sigconf]{revtex4}
%% for your publication.
%%


%\documentclass[manuscript,review,anonymous]{acmart}
%%\PassOptionsToPackage{dvipsnames}{xcolor}
%%\usepackage[dvipsnames]{xcolor} % Load xcolor with dvipsnames option

% Define missing colors
\definecolor{Black}{rgb}{0,0,0}
\definecolor{Thistle}{rgb}{0.847, 0.749, 0.847}

\usepackage{booktabs}
\usepackage{pgfplots}
\pgfplotsset{compat=1.17}  % Ensure compatibility
\usetikzlibrary{calc}
% Remove duplicate package loads
\usepackage{tabularx}  % For automatic column width adjustment
\usepackage{pgfplotstable}
\usepackage{graphicx}
\pgfplotsset{compat=1.17}
\usepackage{tikz}
\usepackage{caption}
\usepackage{array}
\usepackage{makecell}
\usepackage{xcolor}
\usepackage{soul}
\usepackage{enumitem}
\usepackage{adjustbox}
\captionsetup[table]{position=bottom} 
%% \BibTeX command to typeset BibTeX logo in the docs


\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Beyond Training: Social Dynamics of AI Adoption in Industry}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Riya Sahni}
\email{riya.sahni@cs.columbia.edu}
%\orcid{0000-0002-4975-2938}
\affiliation{%
  \institution{Columbia University}
  \city{New York City}
  \state{New York}
  \country{U.S.A}
}

\author{Lydia B. Chilton}
\email{chilton@cs.columbia.edu}
\affiliation{%
  \institution{Columbia University}
  \city{New York City}
  \state{New York}
  \country{U.S.A}
}

\ccsdesc[500]{Human-centered computing~Empirical studies in HCI}


\keywords{AI productivity tools; social learning; discoverability; human cognition; technology adoption}



%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
While organizations continue to invest in AI tools like M365 Copilot, little is known about how individual employees engage with these technologies once deployed. This study examines M365 Copilot adoption behaviors among a group of 10 experienced users across many industries. Findings reveal a strong preference for informal learning methods over structured training. Even though 9 out of 10 participants acknowledged that formal training for Copilot tools would be useful, 7 out of 10 stated that they ignored the Copilot onboarding videos provided to them, citing reasons such as time constraints, preference for self-guided learning, or reliance on external resources like ChatGPT. No participants used formal training as their primary learning method. Instead, experiential learning (trial and error, 8 participants) and social learning (peer discussions, 6 participants) emerged as dominant learning strategies. We discuss opportunities for promoting social learning of AI tools in the workplace.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%

%% \received{20 February 2007}
%% \received[revised]{}
%% \received[accepted]{}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle
\fancyhead{}
\section{Introduction}

\textit{“In the future, your work is going to be defined not by the tasks you perform, but by the creativity you unleash”}, said Satya Nadella, painting a vision that encapsulates Microsoft’s revolutionary approach with Microsoft 365 (M365) Copilot. Today, as AI continues to reshape the modern workplace, millions of paid users rely on M365 Copilot, positioning it as a pivotal tool in the AI race. 

Prior research has extensively documented the role of organizational readiness and environmental pressures on AI integration in professional settings \cite{Aboelmaged2014, Alsheibani2020}. However, research on the primary contributing factors of successful AI adoption at the individual level remains scarce \cite{Neumann}. Given AI’s  rapid integration into workplace environments and its evolving role in augmenting human decision-making, the lived experiences of employees as active participants in shaping AI use remain less understood. This study provides new insights into how social and experiential learning shape grassroots-level adoption of AI productivity tools, like M365 Copilot, in public U.S. organizations. 

Our central research questions are:
\begin{itemize}
    \item \textbf{What did participants use M365 Copilot for, and what are their general sentiments?}
    \item \textbf{What are the primary learning behaviors and patterns observable among these users?}
\end{itemize}

Biases in AI adoption emerge, as employees selectively trust AI recommendations based on perceived reliability and social influence \cite{AlonBarkat2022, Antons2015}. The strategic implementation of AI in organizations further depends on adaptive learning and knowledge diffusion rather than top-down training programs \cite{Ansoff2019}.

Our study, based on in-depth interviews with 10 seasoned professionals across diverse industries, reveals three key findings:
\begin{itemize}
    \item \textbf{A Distinct Preference for Non-Traditional Learning:} Despite recognizing the value of formal training, participants overwhelmingly favor self-directed, experiential, and social learning methods.
    \item \textbf{Discoverability as a Reactive Process:} Users primarily discover Copilot’s capabilities through ad hoc, informal channels—such as observing colleagues in action and spontaneous online searches—rather than through structured training.
    \item \textbf{Efficiency-Confidence Gap:} Although most participants report high perceived efficiency gains from using Copilot, a significant gap exists in their confidence in mastering its advanced features.
\end{itemize}

These findings align with broader trends in AI adoption, where employees engage in an iterative learning process, continuously refining their understanding through workplace interactions and social cues \cite{Venkatesh2003, Alsheibani2020}. On one hand, Copilot liberates users from routine busywork, allowing them to focus on more creative and strategic tasks; on the other, the constant evolution of its features and the reactive nature of learning in the workplace contribute to a pervasive uncertainty about fully harnessing its capabilities. As AI continues to permeate modern organizations, understanding how individuals learn, adapt, and shape these tools will be crucial for maximizing their potential impact.

\section{Related Work}
\subsection{Informal Learning and Social Learning}
Informal learning is learning that happens naturally, outside of formal training, and is spontaneous, unstructured, and often self-directed \cite{marsick1990informal, Eraut2004}. It can consist of solitary learning experiences such as trial and error and social learning experiences like peer influence. Social learning specifically refers to learning that occurs through the interaction, observation, and imitation of others \cite{Bandura1977}. Social learning, especially through peer-to-peer exchanges, discussions with colleagues, and shared problem solving have been observed as integral parts of informal learning in professional contexts \cite{Livingstone2001, Eraut2004}.

Additional studies further emphasize the social nature of workplace learning. For example, Lave and Wenger describe learning as something that happens within communities of practice, while Boud, Keogh, and Walker point out that much professional development occurs through everyday interactions and reflective practice \cite{Lave_Wenger_1991, boud1985reflection}. More recently, Billett has shown that workplace participatory practices play a key role in ongoing professional growth \cite{Billett2001}. Together, these studies suggest that informal learning at work is not just about individual effort, but also relies heavily on social interaction and collaboration. Building upon these insights, our study examines the roles of social and experiential learning—the two key components of informal learning—in the adoption of AI tools in industry. 


% ReelFramer, 2024; Schreiber \& Siege, 2022). Tao Long et al. (2024) further emphasize that AI users refine their interactions over time through hands-on experimentation, gradually adjusting prompts and workflows to better fit their needs.

% While this decentralized learning process is common, it raises concerns about whether informal learning fosters deep AI proficiency or reinforces surface-level use. Employees might plateau at a given skill level, remain unaware of advanced features, or mistakenly believe they have mastered an AI tool (Ackerman et al., 2020). Prior studies lack empirical evidence on whether users fully explore AI capabilities or if their learning stops at basic interactions (Kang et al., 2021).

% Our study examines these gaps by analyzing how industry professionals engage with M365 Copilot. We assess whether informal learning leads to true mastery or functional engagement, providing insights into improving AI education in the workplace.

\subsection{AI Adoption At Work}
Recent studies demonstrate that generative AI can substantially enhance workplace productivity. Recent research reveals that tools like ChatGPT help professionals complete tasks faster and with improved quality \cite{brynjolfsson2024generativeaiwork}. In one experiment, 453 college-educated professionals using ChatGPT produced higher-quality work, and Dell et al. found that consultants with access to ChatGPT generated more innovative ideas \cite{dell2023navigating}. Similar benefits are observed in technical domains, where studies by Cui and Peng report a 26\% increase in weekly coding tasks \cite{cui2024effects, peng2023impact}. In another creative context, studies demonstrate how a human-AI co-creative system can help journalists translate print articles into engaging, narrative-driven video reels, highlighting AI’s potential to support content retargeting through multiple narrative framings \cite{wang2024reelframer, schmid2021narrative,opal,kantosalo2016modes}.

At the same time, several studies highlight important limitations of AI support. Research on creativity support tools and investigations into tasks requiring core human skills indicate that while AI can assist with specific tasks, AI does not fully replicate human judgment or creativity \cite{tao2023ai, long2024novelty}. Additional research further cautions that for complex tasks, reliance on AI may lead to incorrect recommendations and documents challenges users face when integrating AI outputs into their work processes \cite{dell2023navigating, kim2024unlocking}. Moreover, Randazzo suggests that AI tends to impact specific work processes rather than transforming entire industries \cite{randazzo2024cyborgs}.

While a number of studies have examined AI adoption at the organizational level—such as Neumann, Guirguis, and Steiner’s comparative case study of Swiss public organizations that explored structural approaches to managing AI innovation—there remains a notable gap in understanding AI adoption from the individual perspective \cite{Neumann}. Recent calls in the literature urge research that considers AI adoption from the viewpoint of individual citizens and workers \cite{pencheva,Wirtz03102021}. In response, our research focuses on how employees in the United States adopt AI tools like M365 Copilot in their daily work by examining informal and social learning behaviors, like trial and error, peer discussions, and self-directed exploration. This approach bridges the gap between top–down organizational strategies and grassroots-level experiences, providing a more complete understanding of AI adoption and offering practical guidance for designing user-centered training and support systems.

% Discoverability is a major challenge in AI adoption (Durilong et al., 2021). Many users find AI features by accident or through peer recommendations, rather than intentional exploration (Training Industry, 2024; Liao et al., 2022). This contrasts with traditional software adoption, where users engage with structured documentation or guided onboarding.

% If employees rely only on features they initially discover, they may never reach full proficiency or uncover advanced functionalities (Wang \& Johnson, 2023). Studies show that AI tools often support more sophisticated interactions than what most users engage with (ReelFramer, 2024), but there is little research on whether users actively seek out new capabilities or assume they already know everything the tool can do. Tao Long et al. (2024) suggest that users may fine-tune AI interactions over time, but this does not necessarily translate to comprehensive mastery of AI tools.

% Unlike prior research that primarily relies on large-scale surveys, our study provides qualitative insights from in-depth interviews with 10 industry professionals, offering a bottom-up, grassroots perspective of AI adoption in industry. By capturing real-world adoption behaviors, we examine how users discover and integrate new features into their workflows. We identify key barriers to discoverability, including lack of awareness, reliance on peer learning, and usability friction, shedding light on why certain features remain underutilized despite their potential benefits (Chen \& Horvitz, 2023). This focused approach complements broader survey-based studies by offering a deeper understanding of user experiences in real work environments.

\subsection{Microsoft 365 Copilot Tools}
M365 Copilot is a large language model (LLM)-backed, chat-based AI productivity tool integrated with widely used applications such as Microsoft Word, PowerPoint, Power BI, and Teams. As one of the leading AI productivity tools in the industry, M365 Copilot has millions of paid users and is endorsed by numerous global enterprises for its significant contributions to efficiency, productivity, and cost savings \cite{forrester-m365-copilot, althoff2025value}. Its widespread adoption provides a unique opportunity to observe trends in AI tool adoption across a heterogeneous workforce. Consequently, M365 Copilot serves as an ideal proxy for understanding the broader learning and adoption behaviors associated with AI productivity tools across industries. For this reason, our study examines how individuals across various industries adopt M365 Copilot to reveal overall insights of grassroots-level workplace AI adoption.


\section{Methodology}
\subsection{Study Procedure}
\subsubsection{Research Design and Approach}
Between September and December 2024, we interviewed 10 industry workers in a cross-sectional, qualitative study. The purpose was to explore their experiences with learning and using M365 Copilot tools at work. The semi-structured format allowed the interviewer to flexibly adjust the conversation—skipping, reordering, or deepening questions—so as to elicit richer insights from each participant. The interview guideline, provided in Appendix A, focused on the following three primary themes:

\begin{itemize} \item \textbf{Usage and Experience:} Participants’ daily interactions with M365 Copilot tools, including their learning strategies, feature discoverability, and both positive and negative experiences. \item \textbf{Perceptions:} Participants’ perceptions of M365 Copilot, its potential capabilities, and the extent to which these capabilities are realized in practice. \item \textbf{Learning Preferences:} Preferred learning styles and methods employed by participants to acquire knowledge about new Copilot features and functionalities. \end{itemize}

Each interview lasted between 30 and 45 minutes and was conducted in English via Google Meet. All sessions were recorded and transcribed verbatim. 

% Participants were not compensated monetarily for their time. The study received exemption status from the institutional review board, ensuring adherence to ethical research guidelines.

\subsubsection{Sampling Strategy}
Participants were recruited through professional networks. We then employed a combination of purposeful and snowball sampling methods to capture a diverse range of perspectives and behaviors. Purposeful sampling ensured that participants were seasoned working professionals and active M365 Copilot users, providing a solid foundation of relevant experiences. Snowball sampling further enriched the sample by incorporating voices from a variety of industries and organizational roles. Given the diversity of job functions and organizational structures, this approach allowed us to capture a wide array of M365 Copilot use cases and learning experiences. For example, the adoption and training approaches of an executive manager supported by personal administrators may differ significantly from those of a senior manager working without administrative assistance. This sampling strategy, therefore, facilitated an examination of how M365 Copilot adoption behaviors and experiences may align or vary across different job functions, even within the same industry.
\subsubsection{Participant Criteria and Selection}
Participants were required to be active M365 Copilot users, engaging with the tool at least a few times per week for a minimum of two months. This criterion was established to ensure that the initial novelty effect had subsided and that participants’ usage behaviors reflected established habits rather than temporary excitement. Individuals who exclusively used other Copilot tools—such as GitHub Copilot or Power BI Copilot—were excluded from the study. Focusing on M365 Copilot users was a deliberate choice, as this subscription group represents the largest population among the Copilot tools and, consequently, offers a particularly rich dataset for understanding adoption and learning behaviors.


\begin{table*}[t]
    \centering
    \caption{Participant Demographics (\textit{P prefix in ID denotes "participant"})}
    \label{tab:resized}
    \small % Reduce font size
    \renewcommand{\arraystretch}{1.1}  % Adjust row height
    \setlength{\tabcolsep}{6pt}       % Reduce horizontal cell padding
    \resizebox{\textwidth}{!}{ % Ensure the table fits within text width
    \begin{tabular}{l l l c c l} % Adjust column alignment as needed
        \toprule
        ID  & Industry                & Role                         & Experience (years) & Copilot Experience & Frequency of Usage \\
        \midrule
        P1  & Media \& Entertainment  & Senior Program Manager      & 27  & 3 months  & Daily \\
        P2  & Energy \& Chemicals     & Digital AI Lead             & 12.5  & 3 months  & Daily \\
        P3  & Energy \& Chemicals     & IT Digital Strategy Leader  & 27  & 1 year    & Daily \\
        P4  & Energy \& Chemicals     & Well Engineer               & 20  & 8 months  & Daily \\
        P5  & Transportation          & Senior Manager Analytics    & 20  & 3.5 months & Weekly \\
        P6  & Consulting              & Owner                       & 22  & 4 months  & Daily \\
        P7  & Energy \& Chemicals     & Program Manager             & 18  & 2 years   & Daily \\
        P8  & Energy \& Chemicals     & Program Manager             & 38  & 1 year    & Daily \\
        P9  & Consulting              & Senior Manager              & 12  & 1.5 years & Weekly \\
        P10 & Energy \& Chemicals     & Country Head                & 26  & 2 years   & Monthly \\
        \bottomrule
        \vspace{1mm}
    \end{tabular}
    }
\end{table*}

\subsubsection{Participant Demographics}
Participants were sampled from a variety of industries, including Energy and Chemicals, Media and Entertainment, Transportation, and Consulting. The participants represent a broad spectrum of roles, from highly technical users to executive management, and exhibit varying levels of prior exposure to AI tools. Table 1 details key demographic and usage characteristics, including each participant’s industry, role or job title, years of industry experience, duration of M365 Copilot usage, and the frequency of its use.



The sample comprises 4 women and 6 men. All participants reported using Teams Copilot at work, while 3 also utilized Bing Copilot, 6 employed Copilot for Outlook, 2 used Copilot for Word, and one participant also engaged with Power BI Copilot. Beyond these specifics, additional details regarding exposure to complementary AI tools reveal that, with the exception of two participants (P2 and P3) who have received formal training and possess extensive AI/ML experience through academic or previous professional roles, the remaining 8 participants primarily encountered AI through platforms such as Copilot, Claude, and ChatGPT. Notably, P6 leads a technical writing consulting firm that leverages various AI tools—including Quillbot and Bark—beyond the Microsoft Copilot Suite. Furthermore, P5 mentioned that she and some of her peers use Amazon Q in conjunction with Copilot at work.

\subsection{Qualitative Coding \& Analysis}
The transcriptions were manually cleaned and reviewed to eliminate transcription errors and filler words while still preserving the participants’ sentiments. Given that our objective was to examine how participant responses align with established learning frameworks rather than to uncover entirely new ones, we adopted a primarily deductive approach for the qualitative analysis \cite{brennen2021qualitative}. 

Table 2 represents a codebook that was developed based on predetermined learning framework categories, including:
\begin{itemize}
    \item \textbf{Positive social learning:} instances where participants described collaborative learning experiences, knowledge sharing, and engaging in AI-related discussions with colleagues. 
    \item \textbf{Negative social learning:} Instances characterized by resistance to knowledge sharing, limited access to peer discussions, or the dissemination of inaccurate information among colleagues.
    \item  \textbf{Experiential learning:} Self-directed, hands-on experimentation with M365 Copilot to acquire new skills and insights.
    \item \textbf{Traditional learning:} Engagement with formal company-provided training resources such as internal documentation or onboarding videos.
\end{itemize}

Using the codebook as a guide, we systematically reviewed each transcription, sorting relevant participant quotes into the corresponding learning themes. To ensure coding accuracy and consistency, each transcript was reviewed twice. During this iterative review, ambiguous responses were either bolstered with additional context or flagged for further discussion. If sufficient context could not be found to confidently assign a quote to a specific category, that quote was excluded from the final analysis.

To enhance the credibility of our coding process, we maintained a detailed audit trail of coding decisions and conducted regular reflective sessions to address potential researcher bias. This systematic and reflective approach ensured that our analysis remained firmly grounded in the data and accurately reflected participants’ experiences with M365 Copilot within the context of established learning frameworks.

\begin{table*}[t]
    \centering
    \caption{Qualitative Analysis Codebook with Example Quotes}
    \label{tab:qualitative_codebook}
    \renewcommand{\arraystretch}{1.5}  % Adjust row height
    \setlength{\tabcolsep}{6pt}       % Adjust column spacing
    \setlist[itemize]{left=0pt}       % Remove indent for bullet points
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{%
        >{\raggedright\arraybackslash}p{3cm}  % Code Name
        >{\raggedright\arraybackslash}p{4cm}    % Definition
        >{\raggedright\arraybackslash}p{4.5cm}  % Inclusion Criteria
        >{\raggedright\arraybackslash}p{3.5cm}  % Example Quotes
    }
        \toprule
        \textbf{Code Name} & \textbf{Definition} & \textbf{Inclusion Criteria} & \textbf{Example Quotes} \\
        \midrule
        
        Positive Social Learning & 
        Instances where participants reported gaining valuable knowledge about M365 Copilot tool(s) by observing, mimicking, or speaking with colleagues. &
        \begin{minipage}[t]{\linewidth}
        \begin{itemize}[noitemsep, topsep=0pt]
            \item Mentions learning about M365 Copilot through colleagues
            \item Expresses appreciation for shared workplace knowledge about M365 Copilot
        \end{itemize}
        \end{minipage} & 
        “One guy accidentally typed his Copilot prompt in the chat, and I saw it. I pinged him: ‘Did that give you what you wanted?’ He said yes and showed me, and I’m like, ‘Son of a gun—alright…’”- P8 \\ 
        
        \midrule
        
        Negative Social Learning & 
        Instances where participants found social learning ineffective. &
        \begin{minipage}[t]{\linewidth}
        \begin{itemize}[noitemsep, topsep=0pt]
            \item Complaints about limited knowledge-sharing resources
            \item Resistance to knowledge sharing
            \item Colleagues providing inaccurate info
        \end{itemize}
        \end{minipage} & 
        “Copilot says ‘you have one of 30 responses.’ I knew that meant conversation length, but some people thought they only got 10 total tries—so they barely used it, afraid of running out.” - P2 \\ 
        
        \midrule
        
        Experiential Learning & 
        When participants participated in self-led or hands-on experimentation to learn about M365 Copilot. &
        \begin{minipage}[t]{\linewidth}
        \begin{itemize}[noitemsep, topsep=0pt]
            \item Self-learning through trial \& error
            \item Testing features without formal guidance
        \end{itemize}
        \end{minipage} & 
        "I’ve kind of changed my thought patterns to say, I wonder can Copilot do that instead of going and trying to figure it out on my own. And so I figure out a way to ask Copilot and see if Copilot can do it." - P4 \\ 
        
        \midrule
        
        Traditional Learning & 
        When participants use formal training resources like internal documentation or onboarding videos. &
        \begin{minipage}[t]{\linewidth}
        \begin{itemize}[noitemsep, topsep=0pt]
            \item Watching company-published trainings/tutorials
            \item Reading official documentation
        \end{itemize}
        \end{minipage} & 
        “There was another team with Enterprise AI who trained some of us as early adopters to use [Copilot] with Teams and they had a slack channel…”- P5 \\ 
        
        \bottomrule
    \end{tabular}%
    }
\end{table*}

\section{Findings}



\subsection{General Use Cases, Sentiments, and Usability Barriers in M365 Copilot Adoption}
\begin{figure*}[t] % Allows LaTeX to handle placement
\centering
\includegraphics[width=0.9\linewidth]{figures/figure1.pdf}
\caption{Distribution of positive and negative sentiments in Copilot use cases}
\label{fig:sentiment_chart}
\end{figure*}
After interviewing participants, we identified eight primary use cases for M365 Copilot and categorized each mention as positive or negative sentiment based on whether participants found Copilot helpful or frustrating. Figure 1 provides a breakdown of these mentions, illustrating both the most praised and most criticized functionalities.

\subsubsection{What Participants Enjoyed About M365 Copilot}
Among all 64 positive mentions, Figure 1 illustrates the most positively received functionalities were writing assistance (100\% positive sentiment, 14 mentions), notetaking \& summarization (70.5\% positive, 31 positive out of 44 mentions), and information retrieval/explanations (56.3\% positive, 9 out of 16 mentions). Other features, such as email/task prioritization (75.0\% positive, 3 out of 4 mentions), meeting transcript verification (33.3\% positive, 2 out of 6 mentions), scheduling/task generation (40.0\% positive, 2 out of 5 mentions), multimodal capabilities (66.7\% positive, 2 out of 3 mentions), and presentation assistance (16.7\% positive, 1 out of 6 mentions), were noted but with lower positivity rates.

Writing assistance was the highest-rated use case, with zero negative mentions and 100\% positive sentiment. Participants frequently used Copilot to refine emails and reports, adjust tone, and ensure professionalism. P3 noted,
\begin{quote}
    ``I sometimes have the tendency to write more than I need to, and when I learned that it can do an effective summary for a wider audience, I basically started writing emails without paying a lot of attention to what I'm writing and then just dumping it into Copilot.''
\end{quote}

Similarly, P4 emphasized the ease of adjusting tones, stating, \begin{quote}
    ``Now we can adjust the tones quite a bit just by selecting if it is a casual tone or more professional tone or if it needs to be concise.''
\end{quote}

Notetaking and summarization was the most frequently mentioned positive use case, with 31 positive mentions (70.5\% of all mentions in this category). Participants valued how it allowed them to stay engaged in meetings without taking notes manually. P5 recounted, \begin{quote}
    ``I would say, the most memorable experience would be using Copilot to recap a meeting that I joined in 50 minutes late on a one-hour meeting.''
\end{quote} P8 highlighted Copilot’s ability to track key discussions, saying,
\begin{quote}
    ``I think if anything, the positive outcome has been that I'm able to track the volume of information in the meetings better because I can ask Copilot to go tell me what was said in this meeting…''
\end{quote}


Information retrieval/explanations accounted for 9 positive mentions (56.3\%), making it another widely used and appreciated feature. Participants cited its usefulness in surfacing relevant documents and definitions in real time. P8 described how it streamlined document searches:
\begin{quote}
    ``I just started using it as a search feature and not just like searching the web, but searching SharePoint and searching [files]. I know I heard somebody say something in a meeting about some architecture. And so, I just put it in into Copilot and it goes out and it says, ‘Yeah, this was in this PowerPoint from this meeting on this date.'''
\end{quote}
P2 similarly noted, \begin{quote}
    ``As of right now, when I need to find information from internal [company] documents, I will use Copilot on a daily basis.''
\end{quote}

Overall, participants appreciated how M365 Copilot streamlined straightforward tasks like email writing and meeting summarization. These findings suggest that Copilot effectively meets both general and context-specific needs for routine tasks.

\subsubsection{Issues That Participants Faced With M365 Copilot} While many participants found Copilot useful, Figure 1 also highlights 33 total negative mentions, indicating key areas of dissatisfaction. The use cases with the highest proportion of negative sentiment were presentation assistance (66.7\% negative, 4 out of 6 mentions) and meeting transcript verification (66.7\% negative, 4 out of 6 mentions). Notetaking and summarization (29.5\% negative, 13 out of 44 mentions) and information retrieval/explanations (43.8\% negative, 7 out of 16 mentions) had the highest absolute number of negative mentions, indicating that while these were the most used features, they were also among the most polarizing.

Presentation assistance and meeting transcript verification, each receiving 4 negative mentions (66.7\%), were particularly criticized for inaccuracy. P7 expressed disappointment in Copilot’s PowerPoint assistance, stating,
\begin{quote}
    ``The PowerPoint outputs felt like a generic Google answer, not something tailored to our work.''
\end{quote}
Similarly, P10 mentioned issues with meeting transcript summarization, noting,
"The Copilot transcript summary didn't quite capture the essence of what people were saying."

Notetaking and summarization had the highest absolute number of negative mentions (13 negative mentions, 29.5\% of all mentions in this category). Several participants reported concerns about inaccurate or incomplete meeting summaries. P1 recalled,
\begin{quote}
    ``There was one meeting. And I'm glad I looked at the notes relatively early because there was a whole section of a discussion that was really important. And it wasn’t included in the Copilot notes at all.''
\end{quote}

P5 stated that her team stopped using Copilot for technical discussions, saying,
\begin{quote}
    ``We have stopped using [Teams Copilot] to capture anything for code reviews, or anything at all for technical now based on that one experience because we don’t want to get it wrong.''
\end{quote}


Information retrieval/explanations, with 7 negative mentions (43.8\%), was another polarizing feature, with users reporting irrelevant search results and difficulty retrieving past decisions. P2 recounted,
\begin{quote}
    ``I asked Copilot to retrieve past meeting decisions, but it said it had no recollection. I manually found the transcript with the needed information.''
\end{quote}

Other use cases had lower but still notable levels of negative sentiment: scheduling/task generation (60.0\% negative, 3 out of 5 mentions), email/task prioritization (25.0\% negative, 1 out of 4 mentions), and multimodal capabilities (33.3\% negative, 1 out of 3 mentions). P6 reported difficulties with automation workflows, saying,
"I had a workflow set up to automate table sharing, but it kept glitching."
P5 noted an issue with Copilot’s data processing, stating,
"If the table name was called A\_B, it incorrectly merged it into ABCD."

Overall, participants' primary issues with M365 Copilot centered on inaccuracies and inconsistencies in its more advanced features, such as presentation assistance and meeting transcript verification. These challenges suggest that while Copilot excels at streamlining routine tasks, its performance on complex or technical functions remains unreliable, possibly dissuading users from leveraging these use cases.




%%%%%%%%%%IGNORED%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%IGNORED%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%IGNORED%%%%%%%%%%%%%%%%%%%%%%%%%
% \iffalse
% \subsubsection*{A Generally Positive Outlook For Simple Use Cases.} Participants found Copilot valuable, but its perceived usefulness was concentrated in a small number of functions. Specficially, Notetaking and Summarization had by far the most number of positive sentiments (31), accounting for 44\% of all positive responses in the dataset. The Writing assistance capability had 14 positive mentions and zero negative responses, making it one of the most well-received use cases. Most frustrations were directed at advanced or interactive use cases, not Copilot as a whole.



% \subsubsection*{Struggles with Advanced Use Cases and Drop-Off Rates.}
% The limited adoption of more advanced Copilot use cases like task generation, building workflows, searching/retrieving information from internal sources, or leveraging its multimodal capabilites reflects a fundamental issue: participants struggled to use Copilot beyond its most obvious functions. Many viewed it as a passive assistant rather than an active productivity tool, failing to integrate it into higher-order workplace task. Figure 1 supports this by illustrating how out of 97 total references to various use cases, roughly only 36\% of these instances referred to the more advanced use cases (refer to Table 3). And out of these references to advanced use cases, only about 50\% of them were positive sentiments.

% When paticipants attempted to use Copilot for more advanced tasks, like generating presentations, structuring action items, or retrieving specific past communications, they frequently encountered usability barriers. P8 attempted to generate PowerPoint slides but ultimately blamed himself for its failure:
% \begin{quote}
%     ``I keep running into a roadblock, and I haven’t spent time figuring out what the problem is. The problem is me, I’m sure… but it failed me once, so I didn’t go back to it.''
% \end{quote}

% This self-blame phenomenon was common, with participants often assuming that they were using Copilot incorrectly rather than recognizing its inherent limitations. Copilot’s lack of transparency about its capabilities left users guessing, reinforcing a cycle of trial and error that led many to abandon certain use cases out of frustration. After his failed attempt to use Copilot to generate a PowerPoint deck from meeting notes, P8 recounted:
% \begin{quote}
%     ``I was basically saying [to Copilot] to make a slide presentation using the notes from this meeting and so it wouldn’t do it and it may not be in the capabilities… and as a result, it’s kind of like getting bitten. I never tried to do it again because I couldn’t do it. [Maybe] it can do it now or maybe I could get smarter and know how to do it, but it failed me once and so I didn’t go back to it.”
% ''
% \end{quote}

% Yet, an equally important possibility emerged: Do users struggle to adopt Copilot’s advanced features due to usability barriers, or because those features offer no meaningful benefit to them in the first place? While some participants (like P2 and P7) expressed frustration when Copilot failed to execute complex requests, others like P8 and P9 simply never revisited those features, suggesting that Copilot’s more advanced capabilities may be fundamentally mismatched with users’ actual needs and workflows.

% This was particularly evident in P5’s experience with Power BI Copilot, where usability challenges led to a complete disengagement from the tool. Rather than restructuring the data to accommodate Copilot’s requirements, her team switched to Amazon Q, which provided a more seamless user experience:

% \begin{quote} ``I don't want to add an engineer in the middle just to structure the data for Copilot. There are many models today in AWS that can extend to other platforms and do a similar job.'' \end{quote}

% Even if Copilot's usability improved, some of its more advanced features might still struggle to gain traction if users never recieve a compelling reason to use them. This combination of unclear Copilot capabilities, a reliance on trial and error, and the notion that it wouldn't provide benefit anyways, reinforces a usage pattern where participants gravitate toward only what they find the most intuitive, immediately useful functions like notetaking and summarization, which we observe in Figure 1. This means that while usability improvements might help reduce frustrations with Copilot, it might not be enough to drive deeper exploration and adoption of advanced features unless Copilot more explicitly aligns with users' workflows and expectations.



% \subsubsection*{Common Use Cases}

% The most cited use case for M365 Copilot was notetaking and summarization, particularly in Teams meetings. Many participants valued Copilot for its ability to capture meeting minutes, extract action items, and provide summaries. As P3 highlighted, ``The most memorable experience [I had] would be using Copilot to recap a meeting that I joined 50 minutes late on a one-hour meeting.'' Similarly, P9 emphasized the efficiency gained from using meeting transcriptions: ``Since Copilot came in, I’m a lot more interested in participating in the conversation rather than taking down notes.''

% Writing and communication were also widely referenced use cases. Copilot was often used to draft emails, refine writing for different audiences, and adjust tone. As P3 noted, \begin{quote}
%     “If I’m going to send something to a wider audience, let’s say 20+ people, I always have Copilot look through if there is a more concise way to write it.”
% \end{quote}
% Similarly, P7 described how Copilot assists with delicate communication:
% \begin{quote}
    
% \end{quote}

% - there's a couple mentions of this idea that sometimes participants blame themselves if Copilot cannot do something that they're asking because they assume that they're probably just not prompting correctly or that maybe the feature doesn't exist. this is a negative side effect of trial \& error/ experiential learning...

% - 
% In general, participants expressed a strong appreciation for M365 Copilot, particularly for how it enhances meetings and streamlines communication tasks. One of the key benefits participants highlighted was Copilot's ability to free users from routine tasks, enabling them to focus more on meaningful engagement during discussions. As P3 described,  
% \begin{quote}
%     ``Since Copilot came in, I'm a lot more interested in participating in the conversation in the meeting rather than taking down notes.''
% \end{quote}  
% This suggests that Copilot shifts the focus from passive documentation to active participation, allowing users to contribute more thoughtfully and dynamically. Others echoed this sentiment, recognizing Copilot’s value in capturing critical information that might otherwise be lost. For instance, P8 remarked,  
% \begin{quote}
%     ``... whenever you sit in a meeting you probably [are] only capturing mentally about 30\% of what's going on. But with Copilot I can capture the whole thing.''
% \end{quote}  
% By offloading the responsibility of notetaking, Copilot enables users to engage in discussions in real time without the anxiety of missing important details. P1 further emphasized the convenience of automated note-sharing, stating,  
% \begin{quote}
%     ``I use it to help me capture minutes and action items when I'm running a meeting doing the presentation. I love that. I don't also have to take contemporaneous notes right now.''
% \end{quote}  

% However, while many participants found Teams Copilot’s notetaking capabilities beneficial, others encountered limitations, particularly when dealing with technical discussions. P5 shared a notable instance where Copilot failed to capture essential details during a critical code review. Fortunately, another attendee had taken handwritten notes, preventing key information from being lost. This experience led P5 and their team to stop relying on Copilot for technical meetings:  
% \begin{quote}
%     ``We have stopped using [Teams Copilot] to capture anything for code reviews, or anything at all for technical now based on that one experience because we don’t want to get it wrong.''
% \end{quote}  
% This highlights an important nuance—while Copilot is effective in general meeting contexts, its reliability in capturing nuanced technical discussions remains a concern for some users. The tendency to fully trust AI-generated summaries may be misplaced in high-stakes or detail-heavy conversations, prompting users to revert to traditional notetaking methods as a safeguard.

% These mixed experiences suggest that while Copilot significantly enhances meeting engagement by reducing the burden of manual documentation, its effectiveness depends on the nature of the discussion. Users appreciate its ability to streamline notetaking but remain cautious about over-relying on it in contexts where precision and completeness are critical.

% Beyond facilitating meetings, participants also expressed a strong appreciation for Copilot's ability to refine workplace communication. P7 described Copilot's utility in crafting difficult feedback:
% \begin{quote}
%     ``Sometimes you need to give what I would consider negative feedback... I can actually go to Copilot and say I think you suck in all these 12 different domains... and then I could tell Copilot to construct this into feedback for a direct report and then it can write something that's positive.''
% \end{quote} Users liked Copilot's ability to transform blunt or potentially negative messages into constructive and professional feedback, since it helped users maintain positive workplace relationships while still conveying essential critiques.
% Additionally, P4 highlighted how Copilot's ability to adjust tone and style streamlines written communication, explaining:
% \begin{quote}
%     ``Now we can adjust the tones quite a bit just by selecting it as a casual tone or more professional tone or it needs to be concise. You can select those options and I think the new interface definitely helps with the process quite a bit.''
% \end{quote}

% These insights suggest that users appreciate M365 Copilot for its role in enhancing communication and ensuring that people can more actively participate in and engage with discussions in meetings. 

% \fi
%%%%%%%%%%IGNORED%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%IGNORED%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%IGNORED%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{High Perceived Efficiency using M365 Copilot at Work but Low Confidence in its Mastery}

\begin{figure*}[ht]
\centering
\includegraphics[width=0.8\linewidth]{figures/figure2.pdf}
\caption{Scatter plot of Efficiency versus Confidence ratings for each participant. Points are labeled with the participant ID. Points above the reference line (where Confidence exceeds Efficiency) are colored red, indicating lower confidence relative to efficiency.}
\label{fig:scatter}
\end{figure*}

The data reveal a discrepancy between how much participants perceive M365 Copilot to benefit their efficiency at work and their confidence in fully utilizing its capabilities. 7 out of 10 participants rated Copilot’s impact on their efficiency as 6 or above on a 10-point scale, indicating a strong perceived benefit. In contrast, only 20\% reported high confidence (a rating of 7 or above) in their ability to leverage all of Copilot’s features. This gap is illustrated by the scatter plot in Figure 2, where many points lie significantly below the $y=x$ dashed line—demonstrating that while users feel the tool boosts their efficiency, they remain uncertain about fully mastering it.

For example, P6 rated efficiency at 9 but expressed a confidence level of only 1, while P8 gave an efficiency rating of 9 and a confidence rating of 3. These cases underscore a recurring sentiment among many participants: despite acknowledging the practical benefits of M365 Copilot, there is a pervasive uncertainty about unlocking its full potential. Some participants, like P5, employed a variety of learning approaches—including formal workshops, reading documentation, and engaging in peer collaboration—to familiarize themselves with Teams Copilot. Yet even she admitted, “I don’t know what the new features are, but I think confidently, we have tried at least what was made aware to us.”

Conversely, P8, who rated his efficiency highly but his confidence very low, remarked, “Using it in Teams just makes me, I don’t want to say smarter, but it makes me more engaged and helps me understand more about what’s going on.” However, after attending one of Satya Nadella's keynotes, he noted: “There is so much more that can be done that I don’t even understand yet.” Further emphasizing the challenge, P7 commented, \begin{quote}
    “Even the name changing of the software and the lineage of the applications is really difficult for people who aren’t deeply engaged. It almost becomes an obsession to stay connected with what’s happening.”

\end{quote}
Collectively, these insights suggest that while M365 Copilot is widely regarded as a powerful tool for enhancing work efficiency, its constantly evolving features and frequent updates present significant barriers to mastery. 


\subsection{Why Users Avoid Training and Feel They Underutilize M365 Copilot}

 Many users expressed that they sensed they were not making full use of its capabilities. However, this sentiment was often also paired with a sense of lack of motivation to formally explore additional features. Many users acknowledged that M365 Copilot had more to offer but were unsure whether they truly needed to expand their knowledge. As P9 put it, \begin{quote}
    ``If I need to do something and I can't find an answer, I try to look up videos and do it. But if I don’t need anything, I don’t know what else it can do. You don’t know what you don’t know.''
\end{quote} 
Some participants recognized their own reluctance to explore Copilot further but cited time constraints and competing priorities as the primary reason for avoiding formal training. P1 admitted, ``There was some [formal training] made available. I haven't used them.''. P6 echoed his sentiment, saying ``I haven't really had the time to go through it personally, but I'm hoping during Christmas holidays I might be able to play around more with it.'' 

Another factor contributing to the underutilization was a rigid mental model of AI that framed Copilot as maladaptive tool. P7 framed this concept well, explaining, \begin{quote}
    "if you're not going in the direction that feels like it's going to be successful,... you abandon that use case and you move on... you just say `I'm not going to waste any more time with this... I'd rather do it manually'.''
\end{quote} Participants noted that it was easy to get frustrated with Copilot quickly, with a couple of participants explicitly defining this as a 15-minute period of patience. Some users even mentioned abandoning features after one unsuccessful attempt instead of iterating or seeking guidance.


Based on these observations, it seems that underutilization is not necessarily due to a lack of Copilot’s capabilities, but rather a combination of competing priorities, limited patience for experimentation, and a lack of perceived urgency to learn more. In many cases, users had access to training but did not prioritize it, reinforcing the idea that merely offering training may not be enough.


\subsection{Social and Experiential Learning in AI Adoption}
\subsubsection{Participants Ignored Formal Trainings.}

\begin{figure}[ht]
    \centering
    \includegraphics[width=1.05\linewidth]{figures/figure3.pdf}
    \caption{Bar chart displaying the percentage of participants citing time constraints (50\%), self-guided learning (60\%), or reliance on external resources (30\%) as reasons for ignoring onboarding videos.}
    \label{fig:barchart}
\end{figure}


Although 9 out of 10 participants acknowledged that formal training for Copilot tools could be beneficial, 7 explicitly reported ignoring official onboarding videos. Figure 3 shows that 6 participants mentioned ignoring formal training (e.g., watching videos and reading documentation) simply because they preferred self-guided, hands-on learning instead (e.g., trial and error, ad hoc exploration, and social learning). Time constraints were another key factor, with 5 participants citing lack of time as a reason for avoiding training. P10 stated, “There were onboarding classes and even some PowerPoint presentations on how Copilot can be used, but I simply did not have the time to review any of it.” 

Self-guided learning in the form of social learning also played a significant role in participants ignoring formal training.
 P4 mentioned teaching peers informally, saying, \begin{quote}
         ``... and before lunch was even over, I sent the job description out, and they’re like, ‘How did you do that?’ I said ‘it’s Copilot.’...and then I showed them. They’re like ‘wow’...''. 
 \end{quote}

Similarly, P5 found Slack discussions with other teams valuable: \begin{quote}
    ``“I realized we could share screenshots back and forth and say, 'that’s how you do that', that's 'how you do a ticket integration...' we learned from each other by sharing our screen during some of the office hours...” - P5''
\end{quote}
However, sometimes this self-guided learning was also motivated because of time constraints. P8 recounts: \begin{quote}
``I didn’t spend a whole lot of time [trying to get Copilot to generate a PowerPoint presentation]... it was probably 15 minutes or so. It wasn’t enough time to go and do [an internal] search to see if there was [formal training] out there to tell me how to do it.'' 
\end{quote}

Essentially, participants often intentionally bypassed formal training for Copilot because of time constraints and a strong preference for self-guided learning, which was also sometimes motivated by time constraints.


\subsubsection{Discoverability and AI Adoption}


\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.5\linewidth]{figures/figure4.pdf}
    \caption{Stacked bar chart representing the distribution of participants by primary learning source: Social/Peer Learning (6), Self-Exploration (3), and Minimal/Indirect Exposure (1). Each bar segment is labeled with the number of participants.}
    \label{fig:stackedLearningSources}
\end{figure*}


\iffalse In contrast to the explicit learning preferences identified in Section 4.1, results reveals that The process of discovering M365 Copilot's capabilities is largely reactive and not driven by formal training among this group of participants. Instead, the majority of participants learned about Copilot functionalities incidentally, through everyday interactions and unstructured exploration. By counting the number of instances that a participant mentioned they engaged in a certain type of learning method during our qualitative coding of participant responses - and also ensuring this count aligned with any absolute statements they might have made about learning preference during the interview - we found that\fi 


 Figure 4 illustrates the distribution of participants' primary learning methods: 60\% relied on social/peer learning and 30\% identified trial-based learning as their main approach. No participants preferred formal training, and one participant (P10) had minimal engagement (so minimal learning time) with the tool, since they delegated most Copilot tasks to two executive assistants.

Social learning played a significant role in Copilot adoption. P8 described learning a useful prompt by observing a colleague’s mistake in a Teams chat:

\begin{quote}
    ``One of the guys that was in the meeting thought he was trying to use Copilot but instead he wrote out his prompt in the chat and I saw it and I’m like okay, and then he realized what he’d done and then he moved it over and. So I pinged him on the side, and I’m like, `Did that thing [the prompt] did it give you what you wanted?' and he’s like, `Yeah,' and he showed me some things and them I’m like, `Son of a gun, all right…'''
\end{quote}

Similarly, P1 became interested in Copilot after seeing colleagues using it: ``I had peers, co-workers who were part of the pilot program. They would be on conference calls, running Copilot, and I was like, ‘I want that.’'' P5 highlighted  how peer-driven experimentation encouraged feature adoption:

\begin{quote}
    ``Our internal group learned from each other... It was peer pressure. Others were testing [Teams Copilot], so we were too. We were challenged to try new features every day. When we were on our own, like with Power BI Copilot, we weren’t as motivated.''
\end{quote}

Without a peer network, P5 noted that learning Power BI Copilot felt isolating, underscoring the role of social learning in fostering engagement with AI tools.
\iffalse \subsubsection{Social Learning can also be a Source of Misinformation.}
P2 described hearing conflicting accounts about Copilot’s ability to retrieve older files: \begin{quote}
        ``I heard rumors about there was a certain time limit that you could go back X number of weeks. But I've also seen I've been able to retrieve documents that were more than three weeks old. So it's not clear to users what the requirements are.''.
\end{quote}

 This misinformation created uncertainty about Copilot's actual capabilities, reinforcing a lack of in the tool. Instead of experimenting to clarify its functionality or seeking official documentation, P2's experience highlights a common behavioral pattern observed in prior social learning studies \hl{(3,4 in gdoc)}: users over rely on peer accounts, which might contain inaccuracies about Copilot. 

Misunderstandings like this could shape incorrect perceptions of Copilot’s capabilities, leading some users to assume limitations that do not exist. \fi 

\section{Discussion}

\subsection{Preference towards Social Learning over Formal Training for M365 Copilot}

Our study shows that professionals prefer social learning over formal training when adopting M365 Copilot. Informal learning theories and social learning theory explain that employees learn by trial and error, peer exchanges, and collaborative problem solving rather than through structured modules \cite{marsick1990informal, Eraut2004, Bandura1977}. Prior studies also show that everyday interactions and reflective practices are central to workplace learning. These findings confirm that work learning relies on social interaction, not just indivduals \cite{Livingstone2001, Lave_Wenger_1991, boud1985reflection, Billett2001}.

In AI adoption, the preference for social learning has important implications. Formal training may not fully address the challenges of rapidly evolving tools like M365 Copilot. Our findings suggest that users learn more effectively through direct interaction and observation. This grassroots approach helps bridge the gap between initial exposure and full mastery, which is an issue that formal training alone may not solve.

These results offer practical steps for organizations. Companies might create communities of practice or discussion forums where employees share tips and solve problems together. Informal workshops, peer-led sessions, or mentorship programs can also encourage workers to learn about M365 Copilot capabilities and use cases collaboratively.

\subsection{Perceived Underuse of M365 Copilots for More Complex Tasks}
Many participants expressed low confidence in their proficiency with M365 Copilot despite acknowledging its high benefits, and many believed they were severely underutilizing its capabilities. This gap between immediate perceived benefits and deep mastery has groundings in technology complexity theory. The Technology Acceptance Model \cite{Davis1989} states perceived ease of use is a key factor in technology adoption—if a tool is seen as too complex, users are less likely to adopt it fully. Similarly, the Unified Theory of Acceptance and Use of Technology \cite{venkatesh2008technology} identifies "effort expectancy" as a critical determinant, where higher perceived complexity reduces the likelihood that users will invest the effort required to master the technology. Our findings, where users benefit from Copilot yet struggle to achieve deep mastery, align with these models by illustrating that the inherent complexity of the tool can hinder full utilization, despite its clear benefits.

Looking forward, these findings have important implications for the future of AI adoption at work. To bridge the gap between high perceived benefits and low mastery, AI tools like M365 Copilot need to be more transparent about their capabilities. Enhancements such as guided walkthroughs, real-time feedback, and contextual prompts can help users discover and utilize underused features.

In addition, our interviews revealed that some users are more inclined to experiment and "tinker" with Copilot than others. This aligns with Moore’s (1991) Crossing the Chasm, which argues that a small group of early adopters play a critical role in learning and championing new technologies \cite{Moore1991}. Organizations could identify these early adopters—our internal tinkerers—and empower them as champions or mentors. Their success stories and practical tips can then help encourage and guide their peers in mastering the tool.

\section{Future Work}
This section outlines research directions to improve AI tool adoption. We propose studies on interventions to boost user confidence, reasons users forgo training, and gaps between perceived and actual Copilot usage.

\subsection{Potential Design Interventions to Improve AI Confidence}
Many users lacked confidence in using M365 Copilot, not due to missing features but unclear expectations, misinformation, and lack of feedback. This uncertainty may lead to disengagement.

Future research could test design interventions, such as:
\begin{itemize}
    \item \textbf{Real-time feedback and validation}
    \item \textbf{Gamification and confidence metrics}: integrating some sort of self-assessment features that allow users to track their progress in mastering the system without having to engage in formal training. Maybe a confidence dashboard or achievement-based learning approach might encourage users to engage more deeply with Copilot.
\end{itemize}

By designing and testing these interventions, future work could help determine which UI/UX strategies build user confidence to improve AI adoption.

\subsection{Comparing Self-Reported Underutilization with Objective Usage Data}
Users often felt they underutilized Copilot, though actual usage may differ. Some may use it effectively without realizing, while others overestimate engagement. Understanding this gap can inform training strategies.

Future research should quantify and compare self-reported vs. actual usage through:
\begin{itemize}
    \item \textbf{Usage data analytics}: detailed personal tracking key metrics including frequency of Copilot interactions, diversity of features used, and session duration to determine a score that demonstrates how effectively users actually engage with the tool
    \item \textbf{Task-based evaluations}: designing controlled experiments where users are given specific tasks to complete using Copilot. By measuring their efficiency, confidence levels, and actual usage behaviors, researchers can identify gaps between perception and actual proficiency.
    \item \textbf{Longitudinal tracking}: studying how users' confidence and usage patterns evolve over time, particularly after targeted training interventions or UX updates.
\end{itemize}


\section{Limitations}

\subsection{Industry Representation and Generalizability}
Our sample included participants from a range of industries, including Media and Entertainment, Energy and Chemicals, Transportation, and Consulting. These industries were selected due to their varying levels of AI adoption and integration, allowing us to explore how different workplace enviornments influence Copilot usage and adoption. While this diversity strengthens our findings, it also presents a limitation in terms of generalizability. Some industries, particularly those with strict compliance regulations or less exposure to AI-driven tools, may exhibit different adoption behaviors that were not captured in this study. Future research should explore Copilot adoption across a broader range of industries, partiularly in sectors where AI implementation is more regulated.

\subsection{Sampling Methodology and Bias}
This study employed a combination of purposeful sampling and snowball sampling, which allowed us to gather insights from professionals actively using Copilot. However, these methods may introduce bias by overrepresenting users who are already engaged with AI tools and underrepresenting those who may have disengaged early. Additionally, with a sample size of only 10 participants, individual perspectives may not fully reflect broader organizational or industry-wide trends. To mitigate these concerns, we included participants from diverse backgrounds and roles, but future studies should incorporate larger-scale sureys or longitudinal studies to validate and expand upon these findings.

\section{Conclusion}

Our work identifies three key factors shaping Copilot adoption: a strong preference for experiential and social learning, the role of informal discovery in learning new features, and a persistent gap between perceived efficiency gains and confidence in mastery. These insights imply that organizations should look beyond traditional training methods. Embedding real-time feedback, contextual tips, or interactive modules directly within the tool may help bridge the gap between immediate productivity and long-term proficiency.


% \section{Appendices}

% If your work needs an appendix, add it before the
% ``\verb|\end{document}|'' command at the conclusion of your source
% document.

% Start the appendix with the ``\verb|appendix|'' command:
% \begin{verbatim}
%   \appendix
% \end{verbatim}
% and note that in the appendix, sections are lettered, not
% numbered. This document has two appendices, demonstrating the section
% and subsection identification method.

% \section{Multi-language papers}

% Papers may be written in languages other than English or include
% titles, subtitles, keywords and abstracts in different languages (as a
% rule, a paper in a language other than English should include an
% English title and an English abstract).  Use \verb|language=...| for
% every language used in the paper.  The last language indicated is the
% main language of the paper.  For example, a French paper with
% additional titles and abstracts in English and German may start with
% the following command
% \begin{verbatim}
% \documentclass[sigconf, language=english, language=german,
%                language=french]{acmart}
% \end{verbatim}

% The title, subtitle, keywords and abstract will be typeset in the main
% language of the paper.  The commands \verb|\translatedXXX|, \verb|XXX|
% begin title, subtitle and keywords, can be used to set these elements
% in the other languages.  The environment \verb|translatedabstract| is
% used to set the translation of the abstract.  These commands and
% environment have a mandatory first argument: the language of the
% second argument.  See \verb|sample-sigconf-i13n.tex| file for examples
% of their usage.

% \section{SIGCHI Extended Abstracts}

% The ``\verb|sigchi-a|'' template style (available only in \LaTeX\ and
% not in Word) produces a landscape-orientation formatted article, with
% a wide left margin. Three environments are available for use with the
% ``\verb|sigchi-a|'' template style, and produce formatted output in
% the margin:
% \begin{description}
% \item[\texttt{sidebar}:]  Place formatted text in the margin.
% \item[\texttt{marginfigure}:] Place a figure in the margin.
% \item[\texttt{margintable}:] Place a table in the margin.
% \end{description}

%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
% \begin{acks}
% To Robert, for the bagels and explaining CMYK and color spaces.
% \end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}


%%
%% If your work has an appendix, this is the place to put it.
\appendix
\section{Methods}
\subsection{Interview Guidelines}

\subsection*{Phase 1: Learnability \& Onboarding}
\begin{enumerate}
    \item Did you have specific onboarding or training to learn how to use Copilot?
    \item Through which mediums have you mostly learned how to use Copilot? (e.g., trainings in your workplace, workshops, online videos, social media, your own explorations, trial and error, etc.)
    \begin{enumerate}[label*=\arabic*.]
        \item Was it through any of these mediums?
    \end{enumerate}
    \item Have you had experience using other AI tools either at work or outside of your workplace (e.g., Chat-GPT, Gemini, Claude, etc.)?
    \begin{enumerate}[label*=\arabic*.]
        \item If yes, how long have you been using these tools? What have you used them for?
        \item How have your experiences with these other AI tools helped you understand how Copilot works (e.g., what it does, how it works, its limitations)?
    \end{enumerate}
    \item On a scale of 1 to 10, with 1 being not at all and 10 being completely, how confident do you feel that you truly maximize the capabilities and features offered by Copilot when you work?
    \item Do you and your colleagues at work ever share new information about how to use Copilot (e.g., best practices, new features, discovered limitations)?
    \item What has motivated you to incorporate Copilot into your work practice? (e.g., genuine curiosity, leadership expectations, efficiency improvements)
\end{enumerate}

\subsection*{Phase 2: Last Memorable Bad Time Using Copilot}
\begin{enumerate}
    \item Can you recall a time when you were excited to use Copilot at work to help you accomplish something, but it fell short of your expectations?
    \item In general, what would you say are the biggest limitations of Copilot that you have personally experienced so far?
\end{enumerate}

\subsection*{Phase 3: Last Memorable Good Time Using Copilot}
\begin{enumerate}
    \item Can you recall a time when you were excited to use Copilot at work and it met or exceeded your expectations?
    \item In general, what would you say are the greatest strengths of Copilot that you have personally experienced so far?
\end{enumerate}

\subsection*{Phase 4: General Use of Copilot}
\begin{enumerate}
    \item What are your most common use-cases for Copilot at work?
    \item On a scale of 1 to 10 (1 = not at all, 10 = extremely well), how well does Copilot help you accomplish your tasks on average?
    \item On a scale of 1 to 10 (1 = worse off, 5 = neutral, 10 = extremely beneficial), how has Copilot affected your efficiency at work?
\end{enumerate}
% \section{Research Methods}

% \subsection{Part One}

% Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi
% malesuada, quam in pulvinar varius, metus nunc fermentum urna, id
% sollicitudin purus odio sit amet enim. Aliquam ullamcorper eu ipsum
% vel mollis. Curabitur quis dictum nisl. Phasellus vel semper risus, et
% lacinia dolor. Integer ultricies commodo sem nec semper.

% \subsection{Part Two}

% Etiam commodo feugiat nisl pulvinar pellentesque. Etiam auctor sodales
% ligula, non varius nibh pulvinar semper. Suspendisse nec lectus non
% ipsum convallis congue hendrerit vitae sapien. Donec at laoreet
% eros. Vivamus non purus placerat, scelerisque diam eu, cursus
% ante. Etiam aliquam tortor auctor efficitur mattis.

% \section{Online Resources}

% Nam id fermentum dui. Suspendisse sagittis tortor a nulla mollis, in
% pulvinar ex pretium. Sed interdum orci quis metus euismod, et sagittis
% enim maximus. Vestibulum gravida massa ut felis suscipit
% congue. Quisque mattis elit a risus ultrices commodo venenatis eget
% dui. Etiam sagittis eleifend elementum.

% Nam interdum magna at lectus dignissim, ac dignissim lorem
% rhoncus. Maecenas eu arcu ac neque placerat aliquam. Nunc pulvinar
% massa et mattis lacinia.

\end{document}
\endinput
%%
%% End of file `sample-sigconf-authordraft.tex'.
