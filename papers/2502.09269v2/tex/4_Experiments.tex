\section{Experiments}
\subsection{Setting}
\subsubsection{Datasets}
The first dataset we used is ACDC (Automatic Cardiac Diagnosis Challenge) dataset \cite{bernard2018deep}, initiated by the MICCAI challenge in 2017, which includes 150 patient cases. The second is M\&Ms (The Multi-Centre, Multi-Vendor, and Multi-Disease Cardiac Segmentation) Challenge \cite{campello2021multi}, organized at the MICCAI 2020 STACOM Workshop, consisting of 375 participants from six hospitals. Expert clinicians manually annotated both datasets' LV, RV, and MYO at the ED and ES phases. The trainset and testset have been pre-split by the committee.

\subsubsection{Pre-processing and Hyperparameters}
To process the raw datasets into a suitable format for training, we applied the following steps:
\begin{enumerate}
    \item \textbf{Size correction}. For each patient's slices, we resized the images to \(224 \times 224\) pixels in height and width using zooming.
    \item \textbf{Data augmentation}. We applied spatial augmentation, including rotation and flipping, to generate additional training samples.
    \item \textbf{Normalization}. We kept the category labels unchanged. For each pixel in the original 3D frame, we normalized its grayscale value to the \([0, 1]\).
\end{enumerate}

We chose UNet and DeepLabV3+ (denoted as D3P) without pretraining as our base classifiers to conduct comparison and ablation experiments on an NVIDIA RTX A5000 with 24~GB of GPU memory. Both have a maximum of 256 channels in the bottleneck. The batch size was set to 8, and the number of epochs to 500. All classifiers shared a single optimizer \textit{RMSprop} with a learning rate of $1 \times 10^{-4}$, a weight decay of $1 \times 10^{-7}$, and a momentum of $0.9$. We made our source code publicly available\footnote{\url{https://github.com/LEw1sin/Uncertainty-Ensemble}}.

\subsubsection{Metrics}
To evaluate the quality of segmentation, we employed three metrics:

\begin{enumerate}
    \item Dice Similarity Coefficient (DSC):
        \begin{equation}
            DSC(\hat{y}_{j},y_{j})=\frac{2 \vert \hat{y}_{j} \cap y_{j} \vert}{\vert \hat{y}_{j} \vert + \vert y_{j} \vert},
        \label{eq:DSC}
        \end{equation}
        where \(\hat{y}_{j}\) and \(y_{j}\) are the predicted probabilities and ground truth 0-1 mask for each class \(j\). It measures the degree of overlapping for class $j$.
    \item End coefficient (EC):
        \begin{equation}
            EC(\hat{y}_{end}, y_{end})=\frac{1}{K}\sum_{k=1}^{K} {\scalebox{1.0}{$\mathbb{I}$}(DSC_{Avg}(\hat{y}_{end}, y_{end}) > 0.8)}
        \label{eq:EC}
        \end{equation}
        where \(\hat{y}_{end}\) is the segmented mask of the first and last two slices of a 3D frame, and \(y_{end}\) is the ground truth. $\mathbb{I}$ is the indicator function, which takes the value $1$ if the Average DSC on end slices $DSC_{Avg}(\hat{y}_{end}, y_{end})$ is larger than the threshold $0.8$, and $0$ otherwise. $K$ is the total number of 3D frames.
    \item Hausdorff distance (HD):
    \begin{equation}
        HD(\hat{y}_{j},y_{j})=max\{ \sup_{p \in \hat{y}_{j}} d(p,y_{j}), \sup_{g \in y_{j}} d(g,\hat{y}_{j})\},
    \label{eq:HD}
    \end{equation}
    which measures the maximum discrepancy between the volumes. We use this metric in Ablation Studies for a more detailed comparison.
\end{enumerate}

\subsection{Results}
\label{sec: exp results}

\subsubsection{Comparison on ACDC and M\&Ms}

We conducted comparisons and benchmarks with cutting-edge models on ACDC and M\&Ms datasets, with results presented in Tab.~\ref{tab:comparison_acdc} and Tab.~\ref{tab:comparison_mm} (n/a indicates the model is unavailable). In Tab.~\ref{tab:comparison_acdc}, No. 1-2 are 3D-based, while No. 3-7 are attention-based. In Tab.~\ref{tab:comparison_mm}, except attention-based No. 2, the rest are fine-tuned variants of UNet. The results demonstrate that our framework achieves near SOTA performance on both ACDC and M\&Ms in terms of average DSC for RV, MYO, and LV. Moreover, it outperforms existing works on EC, making it more suitable for clinical segmentation of patient-specific samples (e.g., an EC of 81\% means the model has 81\% confidence in segmenting end slices).

\begin{table}[htb!]
\caption{Comparison Study on DSC, and EC Performance on ACDC ($\uparrow$)}
\centering
\begin{tabular}{ccccccc}
\toprule
No. & Architectures & Average & RV & MYO  & LV & EC\\ 
\midrule
1 & 2D\&3D UNets \cite{isensee2018automatic} &91.92 &90.78 &90.46 &94.54 & n/a \\
2 & 2D-3D FCNN \cite{patravali20182d} &88.33 &87.00 &85.50 &92.50 & n/a \\
3 & TransUNet \cite{chen2021transunet}   & 89.71   & 88.96  & 84.53    & 95.73  &52.83 \\
4 & SwinUNet \cite{cao2022swin}      & 90.00  & 88.55 & 85.62  & 95.83  &48.75  \\
5 & SAUNet \cite{sun2020saunet}       & 91.30   & 91.40  & 88.70   & 93.80  & 46.98 \\ 
6 & Parallel MERIT \cite{rahman2024multi}   & 92.32   &  90.87  & 90.00   & \textbf{96.08}  &  51.32\\ 
7 & FCT  \cite{tragakis2023fully}  & \textbf{93.02}   & \textbf{92.64}  & \textbf{90.51}  & 95.90  & 48.41\\
\midrule
\textbf{8} & \textbf{2UNet (Uncertainty, Ours)} &92.29  &92.11  &89.04  &95.73  &\textbf{81.00} \\
\textbf{9} & \textbf{3UNet (Uncertainty, Ours)} &92.16  &91.90  &88.99  &95.58  &69.00 \\
\bottomrule
\label{tab:comparison_acdc}
\end{tabular}
\end{table}

\begin{table}[htb!]
\caption{Comparison Study on DSC, and EC Performance on M\&Ms ($\uparrow$)}
\centering
\begin{tabular}{ccccccc}
\toprule
No. & Architectures & Average & RV & MYO & LV & EC \\ 
\midrule
1 & UNet \cite{saber2021multi}    
& 85.70 & 84.55 & 82.55 & 90.00 & 74.51\\ 
2 & Attention UNet+CycleGAN \cite{kong2021generalizable} 
& 86.57 & 86.00 & 83.30 & 90.40 & n/a \\
3 & UNet+DA+DUNN \cite{corral20212}    
& 86.62 & 86.30 & 83.35 & 90.20 & 76.14\\ 
4 & UNet (ResNet-34) \cite{parreno2021deidentifying}  
& 87.00 & 85.75 & 84.10 & 91.15 & 76.75 \\ 
5 & nnUNet \cite{full2021studying}     
& \textbf{88.35} & \textbf{88.50} & \textbf{85.30} & 91.25 & 79.48\\ 

\midrule
6 & \textbf{2UNet (Uncertainty, Ours)}  
&87.61 & 87.70 & 83.16 & 91.97 &84.93 \\ 
7 & \textbf{3UNet (Uncertainty, Ours)}  
&88.13 & 88.36 & 83.78 & \textbf{92.25} &\textbf{88.13} \\ 
\bottomrule
\label{tab:comparison_mm}
\end{tabular}
\end{table}


\subsubsection{Ablation on ACDC}
\label{sec: ablation on ACDC}

First, we evaluated Streaming with \textit{Fixed} to identify the optimal weights as a baseline for ablation studies. Visual results are in Fig.~\ref{fig:convex comb comprison viz}. The homogeneous combination 2UNet with weights (0.5, 0.5) achieves better overall performance, with an average DSC of 91.25. For the heterogeneous combination 1UNet + 1D3P, the highest DSC 90.90 is achieved with weights (0.7, 0.3).

Then, we compared \textit{Stacking}, \textit{Bagging}, \textit{Augmenting} the optimal Streaming with \textit{Fixed} (\textit{Stacking}, \textit{Bagging}, \textit{Augmenting} also taking Weighted Average as the pooling function, the same weights as \textit{Fixed} for fairness) with our Streaming with Uncertainty, with results in Tab.~\ref{tab:ablation}. The observations are as follows:


\begin{figure}
    \centering
    \includegraphics[width=0.75\linewidth]{fig/c.pdf}
    \caption{a) shows results from 1UNet + 1D3P, with the x-axis varying UNet's weight. b) shows results from 2UNet, with the x-axis varying UNet 1's weight.}
    \label{fig:convex comb comprison viz}
\end{figure}

\begin{table}[htb!]
\caption{Ablation Study on DSC, HD, and EC Performance on ACDC}
\centering
\setlength{\tabcolsep}{3pt} % 调整列间距
\resizebox{1.0\textwidth}{!}{ % 调整表格大小
\begin{tabular}{ccccccccccc}
\toprule
\multirow{2}{*}{Architectures}  & \multicolumn{2}{c}{Average} & \multicolumn{2}{c}{RV} & \multicolumn{2}{c}{MYO} & \multicolumn{2}{c}{LV} & \multirow{2}{*}{EC} \\ 
 & DSC & HD & DSC & HD & DSC & HD & DSC & HD \\ 
\midrule
UNet    
&91.27  &22.19  &90.62  &37.29  &87.93  &18.76  &95.28  &10.51  &53.00 \\ 
D3P   
&89.45  &27.53  &89.41  &37.91  &85.23  &27.22  &93.71  &17.45  &35.00 \\ 
1UNet + 1D3P (\textit{Fixed})
&90.90  &14.00  &90.63  &17.09  &87.47  &15.67  &94.60  &9.22  &70.00 \\ 
1UNet + 1D3P (\textit{Stacking})
&91.38  &20.11  &90.75  &33.81  &88.07  &17.74  &95.32 &8.77  &54.00 \\ 
1UNet + 1D3P (Uncertainty)
&90.89  &13.27  &90.41  &20.16  &87.63  &11.34  &94.62  &8.30  &38.00 \\ 
2UNet (\textit{Fixed})
&91.25  &13.32  &91.06  &18.20  &87.59  &11.67  &95.10  &10.09  &71.00 \\ 
2UNet (\textit{Bagging})
&91.71 &14.59  &90.95  &\textbf{12.08}  &88.66 &17.59 &95.53 &14.10 &73.00 \\ 
2UNet (\textit{Augmenting})
&69.90  &27.09  &59.36  &33.23  &69.60  &29.27  &80.76 &18.76  &22.00 \\ 
% 2D3P & & & & & & & & & \\
\textbf{2UNet (Uncertainty, Ours)}
&\textbf{92.29}  &10.33  &\textbf{92.11}  &13.66  &\textbf{89.04}  &10.28  &\textbf{95.73}  &7.06  &\textbf{81.00} \\ 
\textbf{3UNet (Uncertainty, Ours)}
&92.16  &\textbf{10.10}  &91.90  &16.78  &88.99  &\textbf{8.05}  &95.58  &\textbf{5.46}  &69.00 \\ 
4UNet (Uncertainty)
&91.98  &12.54  &91.80  &15.98  &88.71  &11.29  &95.44  &10.36  &68.00 \\ 
\bottomrule
\label{tab:ablation}
\end{tabular}
}
\end{table}

\begin{figure}
    \centering
    \includegraphics[width=0.7\linewidth]{fig/param.pdf}
    \caption{Test FLOPs and parameters on a 3D frame, marker size shows parameter count.}
    \label{fig:param}
\end{figure}


\begin{itemize}
    \item \textbf{obs 1)} Homogeneous ensembles weighted by Streaming with Uncertainty, together with \textit{Bagging} and \textit{Stacking} are superadditive. 2UNet with Uncertainty is the most stable on DSC and EC, while 3UNet with Uncertainty is the most stable on HD.

    \item \textbf{obs 2)} Our Streaming with Uncertainty outperforms traditional ensemble methods on overall performance. However, increasing the number of classifiers does not consistently improve segmentation performance, and two homogeneous classifiers achieve the best results.
\end{itemize}

\subsubsection{Computational Efficiency} Ensemble learning often faces complexity issues. Compared to baselines on ACDC, ours achieves near-SOTA Average DSC with low parameters and FLOPs, thanks to zero attention, as shown in Fig. \ref{fig:param}.

\begin{figure}
    \centering
    \includegraphics[width=0.7\linewidth]{fig/cmr_viz.pdf}
    \caption{UNet Trio is 3UNet (Uncertainty), and UNet \textit{i} is one of its components. Solo means working individually. $-1$ and $-2$ are the last two slices, $0$ and $1$ the first two.}
    \label{fig:cmr viz}
\end{figure}

We visualized a challenging sample from the ACDC testset in Fig.~\ref{fig:cmr viz}, the ES frame of patient114 from the hypertrophic cardiomyopathy (HCM) group. The blue box highlights the best-performing model, while the green box shows challenges in other baselines. The last two rows of the first column show \(\boldsymbol{\sigma}_{i}\) and \(\bar{\boldsymbol{\omega}}_{i}\). Uncertainty is mainly concentrated at ventricular and chamber boundaries.

