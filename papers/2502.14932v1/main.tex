% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{acl}

% Standard package includes

\usepackage{times}
\usepackage{latexsym}
\usepackage{booktabs}
% \usepackage{arydshln}
\usepackage{colortbl,array,xcolor}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{xspace}
\usepackage{amsfonts}
\usepackage{tcolorbox}
% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets
\usepackage{tikz}
\usepackage{amsmath}
\usetikzlibrary{tikzmark}
\makeatletter
\newcommand*\myfontsize{%
  \@setfontsize\myfontsize{6.7}{8}%
}

% \usepackage[dvipsnames]{xcolor}
\definecolor{c1}{HTML}{688990}
\definecolor{myred}{HTML}{C3375A}
\definecolor{mypurple}{HTML}{CD82F2}
\definecolor{mypink}{HTML}{EC9FA8}
\newcommand{\mytextbox}[2]{\tikzmarknode[draw=#1,thick,inner sep=2pt]{test}{\myfontsize #2}}

\newcommand{\mygreen}[1]{\textcolor{green}{#1}}
\definecolor{cadmiumgreen}{rgb}{0.0, 0.42, 0.24}
\newcommand{\mydarkgreen}[1]{\textcolor{cadmiumgreen}{#1}}
% \definecolor{myred}{rgb}{0.7, 0.3, 0.0}
\definecolor{myblue}{rgb}{0.2, 0.3, 0.6}
\newcommand{\rret}{\textcolor{myred}{\small{\texttt{[Relation Retrieval]}}}}
\newcommand{\ret}{\mytextbox{c1}{\textbf{\textcolor{c1}{\textit{Retrieval Token}}}}}
\newcommand{\eret}{\textcolor{myred}{\small{\texttt{[Entity Retrieval]}}}}
\newcommand{\crt}{\mytextbox{myblue}{\textbf{\textcolor{myblue}{Critique}}}}
\newcommand{\mgen}{$\mathcal{M}$\xspace}
\newcommand{\mcrt}{$\mathcal{C}$\xspace}
\newcommand{\mret}{$\mathcal{R}$\xspace}

\newcommand{\model}{\textsc{ArG}\xspace}

\newcommand{\ie}{\emph{i.e.,}\xspace}
\newcommand{\eg}{\emph{e.g.,}\xspace}
\newcommand{\wo}{\emph{w/o.}\xspace}
\newcommand{\crel}{
    \mytextbox{myblue}{
        \textbf{\textcolor{myblue}{\textit{Relevance Token}}}
    }
}
\newcommand{\cre}{
    \mytextbox{mypink}{
        \textbf{\textcolor{mypink}{\textit{Rationality Token}}}
    }
}

\newcommand{\cuse}{
    \mytextbox{mypurple}{
        \textbf{\textcolor{mypurple}{\textit{Utility Token}}}
    }
}
\newcommand{\paratitle}[1]{\noindent\textbf{#1}}
% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}
\usepackage{utfsym}
% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}
% \usepackage{algorithm}
% \usepackage[ruled]{algorithm2e}
\usepackage[ruled,vlined]{algorithm2e}
\newcommand\mycommfont[1]{\footnotesize\ttfamily\textcolor{blue}{#1}}
\SetCommentSty{mycommfont}


\usepackage{listings}
\lstset{
basicstyle=\ttfamily\linespread{1.15}\small,
commentstyle=\color{red}
columns=flexible,
breakindent=0pt,
breaklines=true,
keywordstyle=\bfseries\color{myred}, % 设置关键字为粗体，颜色为 NavyBlue
morekeywords={},
moredelim=[is][\color{mypurple}\textbf]{^}{^},
moredelim=[is][\color{mypink}\textbf]{=}{=},
moredelim=[is][\color{myblue}\textbf]{+}{+},
moredelim=[is][\color{gray}]{\{}{\}},
moredelim=[is][\color{myred}\textbf]{@}{@},
moredelim=[is][\textbf]{/*}{*/},
}

% \usepackage{algpseudocode}
% \usepackage[noend]{algpseudocode}
% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}
\usepackage{tcolorbox}
%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}

\newtheorem{example}{Example}
% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Learning to Retrieve and Reason on Knowledge Graph through Active Self-Reflection}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{Han Zhang$^{12}$ , Langshi Zhou$^{2}$, Hanfang Yang$^{12}$\thanks{Corresponding author.} \\
$^{1}$Center for Applied Statistics, Renmin University of China \\
$^{2}$School of Statistics, Renmin University of China \\
\texttt{\{hanzhang0816,zhoulangshi,hyang\}@ruc.edu.cn}
}

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
\begin{abstract}
% Extensive research has investigated the integration of large language models (LLMs) with knowledge graphs to enhance the reasoning process. However, there remains a significant gap in understanding how models perform reasoning grounded in structured graph data. Most existing approaches rely on LLMs or external retrievers to make binary decisions regarding the utilization of knowledge, often without deeper introspection. Furthermore, across the entire reasoning path, effective feedback mechanisms for reflection and correction are notably absent.
% 大量研究已经探索了如何结合大模型与知识图谱增强推理过程，然而，要理解模型基于结构化的图谱进行推理的过程仍然缺乏研究，大多数方法直接依赖LLMs或者检索器进行简单的二元判断是否使用，这过于莽断。同时，在整个推理路径上仍然缺乏有效的反馈机制进行反思矫正。本文提出了一个主动自反思的图谱推理框架，首次以端到端训练的方式，实现了基于结构化图谱内容的推理。在框架中，模型能够利用special token，主动决定是否需要进行知识的检索，并基于检索到的知识进行反思批判，迭代的在图谱上进行推理。模型产生的推理路径具有良好的可理解性，能帮助我们更好的探索模型对于结构化知识的理解。最终模型在图谱推理baseline上取得良好的结果。然而，理解模型如何利用知识进行推理的过程还未被有效探索
Extensive research has investigated the integration of large language models (LLMs) with knowledge graphs to enhance the reasoning process. However, understanding how models perform reasoning utilizing structured graph knowledge remains underexplored. Most existing approaches rely on LLMs or retrievers to make binary judgments regarding the utilization of knowledge, which is too coarse. Meanwhile, there is still a lack of feedback mechanisms for reflection and correction throughout the entire reasoning path. This paper proposes an \underline{A}ctive self-\underline{R}eflection framework for knowledge \underline{G}raph reasoning (\model), introducing for the first time an end-to-end training approach to achieve iterative reasoning grounded on structured graphs. Within the framework, the model leverages special tokens to \textit{actively} determine whether knowledge retrieval is necessary, performs \textit{reflective} critique based on the retrieved knowledge, and iteratively reasons over the knowledge graph. The reasoning paths generated by the model exhibit high interpretability, enabling deeper exploration of the model's understanding of structured knowledge. Ultimately, the proposed model achieves outstanding results compared to existing baselines in knowledge graph reasoning tasks.
% and demonstrates transferability across multiple graphs.
\end{abstract}

\section{Introduction}
% intuition 部分： 当前，知识图谱被广泛用于增强LLMs的推理能力，作为结构化推理路径和事实信息的补充。

% 本工作提出了Self-Graph方法通过利用self-reflection token来提升大语言模型在结构化图数据上的推理能力。借助于在训练集中图谱的推理路径作为弱监督，我们端到端的训练了一个语言模型，来实现在图谱上的自动化推理。
% Knowledge graphs(KGs),作为一种提供结构化的，清晰的，可编辑的知识表示，扮演了一种非常有前景的外部知识结构。
% Knowledge graphs (KGs), offering structured, explicit, and interconnected knowledge representation, serve as a highly promising external knowledge source to augment Large language models (LLMs). 然而，如何高效的理解并利用结构化的图谱信息，进行下游如knowledge graph question answering(KGQA)任务，仍然是个富有挑战的问题。从前主流的方法主要分为Information Retrieval (IR)-based方法和Semantic Parsing (SP)-based 方法。具体地， IR-based方法主要从KGs中检索与查询相关的实体，关系，三元组，用于增强推理。 SP-based方法生成结构化logical form并与KGs交互。最近，一些LLM-based方法利用LLMs的思考能力，不依赖于训练，通过按步迭代推理同样得到答案Recently, some LLM-based approaches have leveraged the reasoning capabilities of large language models (LLMs) to obtain answers through step-by-step iterative reasoning, without relying on training. for downstream tasks such as Knowledge Graph Question Answering (KGQA) 
Knowledge graph (KG), offering structured, explicit, and interconnected knowledge representation, serves as a highly promising external knowledge source to augment large language models (LLMs). However, efficiently understanding structured graphs remains a significant challenge. Mainstream approaches can typically be categorized into two main types: Information Retrieval (IR)-based methods and Semantic Parsing (SP)-based methods. Specifically, IR-based methods enhance the generation process by retrieving related entities, relations, triplets or relation paths~\cite{luo2023reasoning} from KGs. SP-based methods generate structured logical forms (\eg S-expression~\cite{GrailQA}, SPARQL~\cite{SPARQL}) and directly interact with KGs to obtain precise answers. Recently, LLM-based approaches have leveraged the reasoning capabilities of LLMs to derive answers in a step-wise and training-free manner~\cite{jiang-etal-2023-structgpt,gu-etal-2023-dont,sun2023think}.
% 基于代码的方法过于黑箱，对于推理的逻辑缺乏可视化；完全基于Prompt的图推理方法，涉及到在推理过程中多次的对于大语言模型的调用，且需要严谨的逻辑设计,token消耗。且大语言模型内部的推理逻辑和真实的推理路径往往存在差异，仅仅从相关性或者依赖LLM问答并不足够。例如，在（Knowledge Graph-Enhanced Large Language Models via Path Selection）文章中，某些相关性不那么高的entity或许也会给回答问题提供借鉴信息。
%现有的方法仍然面临显著的限制，SP-based方法的好坏依赖于模型的代码的生成能力，这样的方法缺乏对于结构化图谱理解的过程信息。该任务和图谱任务本身并不完全重合匹配需要构造大量的逻辑语义正确的代码标签，对于推理的逻辑缺乏可视化，整个流程过于黑箱。而IR-based方法大多采用retrieval and generate的框架，在retrieval的阶段，由于自然语言不同于结构化图谱知识，许多方法表现出低检索效率，在generate的阶段，基于Prompt方法如ToG.每一轮推理都需要多次迭代调用大模型Approaches like \citet{sun2023think, jiang-etal-2023-structgpt} 仅仅依赖大模型决定是否外部知识（如三元组）是否采用。 一个\model执行了更细粒度，更精确的评估的示意图
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{latex/pics/comparison_2.pdf}
    \caption{An example of \model performs a more fine-grained assessment and actively retrieves knowledge (relations) compared to LLM pruning and direct retrieval.}
    \label{fig:compare}
    % \vspace{-0.3cm}
\end{figure}


The existing methods still face notable limitations. \textbf{SP-based methods} are robust but require the annotation of high-quality, and often expensive, logical forms as supervision~\cite{zhang-etal-2022-subgraph}. Furthermore, these methods struggle to capture the procedural information underlying the comprehension of structured knowledge graphs, rendering the workflow overly "black-box".
% Besides, these methods also lack interpretability for the whole reasoning process, making the workflow overly "black-box."
\textbf{IR-based methods} typically adopt a \emph{retrieve and generate} framework. However, due to the disparity between natural language and structured graph knowledge, traditional approaches exhibit low retrieval efficiency~\cite{BM25,Contriever,SimCSE}. \textbf{LLM-enhanced methods} are more computationally efficient but demand meticulous prompt design. Approaches like \citet{sun2023think, jiang-etal-2023-structgpt} are inflexible by relying solely on LLMs to decide whether to adopt a certain instance of knowledge (\eg triplets in KG).
% 结合大语言模型，基于上述两类方法都进行了许多改进。特别地，一些方法通过step-wise的操作，在图谱上进行推理，
% During the generation phase, prompt-based methods such as ToG face additional challenges. Specifically, prompt-based approaches to graph reasoning often require multiple invocations of large language models (LLMs) throughout the reasoning process, which demands meticulous logical design and results in significant token consumption.

% 除去这些，我们提出一些实际的但仍未被解决的问题，第一，缺乏具体的相关性分数评估。大多数方法通常直接从图谱中进行检索或简单依赖大模型进行剪枝，无法回答检索到的知识与查询的相关和有效程度。第二，低检索效率。实际图谱中事实与自然语言查询并不同，粗粒度的检索往往提取低效且会忽略indirect知识。第三，缺乏合理性反思。在step-by-step推理的过程当中，及时从错误的推理路径中终止是必要的。当前的中间推理逻辑是否连贯，最终得到的答案是否可靠。这些信息都有助于我们更进一步理解模型在结构化图谱数据的推理过程。Beyond these limitations, we propose several practical yet unresolved challenges. First, there is a lack of precise relevance score evaluation. Most existing methods either directly retrieve from the knowledge graph or rely on large language models for coarse pruning, failing to assess the relevance and utility of the retrieved knowledge with respect to the query. Second, retrieval efficiency remains low. In real-world knowledge graphs, the facts often differ significantly from natural language queries, and coarse-grained retrieval tends to extract information inefficiently while neglecting indirect knowledge. Third, there is an absence of reflective reasoning. In the step-by-step reasoning process, it is crucial to exit erroneous reasoning paths in a timely manner. Evaluating whether the intermediate reasoning logic is coherent and whether the final answer is reliable is essential. Such insights can further enhance our understanding of how models perform reasoning over structured graph data.图谱例如Freebase中的关系表示不同于自然语言，同时存在大量字符相似的candidate。常规的检索效率低且会忽视结构化图谱中的隐含知识。综合所有现有的方法，我们提出3个实际但未被解决的问题

In consideration of all existing methodologies, we raise three practical yet remain underexplored issues: (\romannumeral1) \textbf{Lack of specific relevance score assessment.} Most methods either directly retrieve or rely on LLMs for binary pruning, failing to assess to what extent the retrieved knowledge contributes to the query, as illustrated in Figure~\ref{fig:compare}. (\romannumeral2) \textbf{Low retrieval efficiency.} The representation of relations in KGs, such as Freebase~\cite{Freebase}, differs from natural language questions. At the same time, numerous candidates with high lexical similarity exist. Conventional retrieval methods exhibit low efficiency and often overlook implicit relationships within the structured graph~\cite{liu-etal-2024-knowledge-graph}. (\romannumeral3) \textbf{Lack of rational self-reflection.} During iterative reasoning, it is crucial to terminate exploration of unreasonable paths in a timely manner. Evaluating the coherence of intermediate reasoning steps and the reliability of the final answer is essential for improving the model’s step-by-step reasoning over structured graphs.

% Relevance of Retrieved Entities and Relations: How relevant are the retrieved entities and relations to the given query? This remains an open question, as retrieval often suffers from mismatches between natural language and structured knowledge.
% Reliability and Reasonableness of the Answer: Is the answer obtained through the current reasoning path both reliable and logically sound? Current frameworks often lack robust mechanisms to verify the validity of reasoning paths and their intermediate steps.
% Lack of Visualization in the Reasoning Process: The entire reasoning workflow lacks clear and effective visualization, making it hard to interpret and understand the step-by-step reasoning process.
% Methods based on code are often criticized for their opacity, as they function as a "black box" and lack visual interpretability for reasoning processes. On the other hand, prompt-based approaches to graph reasoning typically involve multiple invocations of large language models (LLMs) during the reasoning process, necessitating meticulous logical design and resulting in significant token consumption. Moreover, the internal reasoning logic of LLMs frequently diverges from actual reasoning paths, rendering reliance solely on correlation or LLM-based question-answering insufficient. For example, as discussed in the paper "Knowledge Graph-Enhanced Large Language Models via Path Selection", certain entities with lower correlation may still provide valuable insights for answering questions.
Inspired by the rapid advancements in LLM for text embedding~\cite{wang-etal-2024-improving-text} and Retrieval-Augmented Generation (RAG)~\cite{asai2023selfrag, zhang-etal-2024-onegen}, this study introduces the \model framework, which integrates specialized \emph{self-reflection tokens} to enhance reasoning capabilities when interacting with structured graph data. By utilizing reasoning paths within the graph as weak supervision signals, the model is trained end-to-end to enable on-demand retrieval and reflective reasoning over knowledge graphs. At each step of the iterative reasoning process, the model determines whether retrieval is necessary. If so, it evaluates the relevance of the retrieved knowledge to the query (e.g., relations and entities) and assigns a rationality score based on the current reasoning path. Otherwise, it derives the final answer, accompanied by an evaluation of the answer's utility.
 The reasoning process of \model unfolds as a reasoning tree. Specifically, the candidates generated at each step form the nodes of the tree, enabling parallel expansion of downstream paths. Ultimately, the final score for each leaf node is computed based on backtracking the scores along its path.

In summary, our primary contributions include: (\romannumeral1) We propose an end-to-end training framework that enables the model to perform iterative reasoning over structured graph while actively deciding whether to retrieve knowledge. (\romannumeral2) We innovatively introduce special tokens in graph reasoning tasks, equipping the model with the capability to evaluate and self-reflect on its reasoning process. (\romannumeral3) We introduce a hypo-generator during the inference process to enhance retrieval efficiency.
% 总之，我们的主要贡献包括：
% 1.我们提出了一个端到端的训练框架，使得模型能够在结构化图谱中进行迭代推理，根据需要决定是否检索并最终终止检索输出答案。2.我们在图谱任务中创新的使用special tokens，使得模型具备了评估和反思的能力3.我们在推理过程中提出了hypo-generator，用于辅助增强检索效率。
% Self-Graph introduces a tree-based parsing framework to further enhance interpretability. Specifically, the reasoning process is visualized as a tree structure, and the final answer is derived through score computations along the leaf paths.


% 在每一步推理迭代的过程中，模型都会评估检索到的关系和实体，并基于当前的推理路径给出合理性分数，判断是否进行下一步迭代，最终得出答案。

% /model的整个推理过程张成了一种推理树，具体来说，每一跳得到的candidate都构成树中的结点，基于这些结点可以并行的拓展下游路径，最终基于叶子节点，我们回溯计算整条路径的分数，得出最终答案。

% Self-Graph取得了baselins数据集上的优秀结果。
% 我们可以用户端方便的控制图探索的深度和宽度
% 多个relationship融合

% 通过reasonable，判断整个分析是否合理


\section{Related Work}
\paratitle{Knowledge Graph Question Answering.}
% 传统的方法通过通过嵌入空间表示实体和关系，设计特殊的模型架构如Key Value Memory Networks，seq2seq models如LSTM-based,T5-based在大语言模型之后，基于LLM强大推理能力，涌现出不同的能够基于LLM进行知识图谱问答的方法。一些致力于通过大模型时代的方法增强对于图谱结构的理解，例如\citet{ji-etal-2024-retrieval}利用COT\cite{wei2022chain}通过中间推理步骤增强图谱知识推理能力。TOG\cite{sun2023think} leverages LLM as an agent participating in KG reasoning. StructGPT,Interactive-KBQA通过将与图谱交互的函数作为交互界面，实现迭代的基于图谱的对话.\citet{jiang2024kg}则把LLM视为Agent智能体，通过Agent与环境交互达到图谱理解的目的。
% Following the advent of LLMs, diverse methods have emerged for knowledge graph question answering, leveraging the powerful reasoning capabilities of LLMs.一些基于prompt的方法例如\citet{kb-binder}通过few-shot样例，使得模型生成正确的s-expression并执行，Graph-CoT~\cite{jin-etal-2024-graph}通过COT来鼓励模型在图谱上进行多次思考推理，ToG\cite{sun2023think} explore related entities and relations on KGs iteratively based on LLMs reasoning. Other methods, such as \citet{jiang-etal-2023-structgpt}and \citet{xiong-etal-2024-interactive}, enable iterative KG-based operation by integrating pre-defined functions as interaction interface. Similarly, \citet{jiang2024kg} treat LLMs as intelligent agents, 通过KG reasoning program构造instruction data to fine-tune the base LLM.
Traditional methods represent entities and relations within an embedding space, leveraging specifically designed model architectures such as Key-Value Memory Networks\cite{miller-etal-2016-key,das-etal-2017-question}, as well as seq2seq frameworks like LSTM-based~\cite{sun-etal-2018-open} and T5-based~\cite{shu-etal-2022-tiara} networks. Recently, leveraging the powerful reasoning capabilities of LLMs, diverse methods have emerged for knowledge graph question answering. Prompt-based approaches, such as KB-BINDER~\cite{kb-binder}, uses few-shot examples to guide the model in generating credible logical forms. Graph-CoT \cite{jin-etal-2024-graph} incorporates Chain-of-Thought (CoT) reasoning to encourage multi-step reasoning over KGs. ToG \cite{sun2023think} iteratively explores related entities and relations on KGs based on LLM-driven reasoning.

Other methods, such as \citet{jiang-etal-2023-structgpt} and \citet{xiong-etal-2024-interactive}, enable iterative KG-based operations by integrating pre-defined functions as an interaction interface. Similarly, \citet{jiang2024kg} treat LLMs as intelligent agents, generating instruction data through KG reasoning programs for fine-tuning the base LLM. In contrast to these prompt-based approaches, we employ an end-to-end training framework, wherein distinct instruction tasks are explicitly defined during the data collection phase while simultaneously enabling procedural reasoning during the inference stage. 
%不同于这些prompt-based methods,我们设计了一套end-to-end训练框架，在训练阶段通过分别定义instructio任务，使得在推理阶段模型实现自动的流程推理。 and perform reasoning based on the retrieved knowledge
% In the era of large language models (LLMs), many methods have been developed that leverage prompts to harness the powerful reasoning capabilities of LLMs for knowledge graph (KG) applications. 

% Some approaches aim to enhance the understanding of graph structures by leveraging LLM-era methodologies. For instance, \citet{ji-etal-2024-retrieval} utilize Chain-of-Thought (CoT) reasoning \cite{wei2022chain} to improve KG reasoning by incorporating intermediate reasoning steps. TOG \cite{sun2023think} leverages LLMs as agents actively participating in KG reasoning.

% Other methods, such as StructGPT and Interactive-KBQA, enable iterative KG-based dialogue by integrating graph-interacting functions as part of the interaction interface. Similarly, \citet{jiang2024kg} treat LLMs as intelligent agents, where the agent interacts with its environment to achieve an understanding of the KG.
\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{latex/pics/P4.pdf}
    \caption{The overall framework of \model. Given an input query, the trained generator model \mgen iteratively performs knowledge retrieval over the structual graph based on the retrieval token. Subsequently, the retrieved knowledge undergoes processes of critique and reflection, where implausible information is filtered. The iterative procedure culminates in the generation of an answer. \model exhibits strong interpretability when applied to structured graph. As demonstrated in the example, the step-by-step reasoning path is organized in the lower half.}
    \label{fig:Self-graph}
    % \vspace{-0.3cm}
\end{figure*}
\paratitle{RAG with Knowledge Graph.} Retrieval-Augmented Generation combines retrieved external knowledge with LLMs for improved task performance, incorporating domain-specific information to ensure factuality and credibility~\cite{guu2020retrieval}.
% \citet{jiang-etal-2023-active}uses a prediction of the upcoming sentence to adaptively retrieve passages. Self-RAG~\cite{asai2023selfrag}通过reflection tokens学习按要求检索。在知识图谱领域，检索主要聚焦在图数据库而不是文本库中，这需要额外考虑文本间的相互关系和图中的结构化信息。GNN-RAG结合GNN和RAG检索reasoning paths，TIARA~\cite{shu-etal-2022-tiara},Chatkbqa~\cite{luo-etal-2024-chatkbqa}在图谱中通过检索实体和关系，生成更可靠的logical forms. \citet{ji-etal-2024-retrieval} enhances the retrieval capabilities of KGs via CoT reasoning.
FLARE~\cite{jiang-etal-2023-active} predicts upcoming sentences to adaptively retrieve relevant passages. Self-RAG~\cite{asai2023selfrag} learns to retrival on-demand guided by reflection tokens. OneGen further unifies retrieval and generation in one model. In the context of knowledge graphs, retrieval focuses primarily on graph databases rather than text corpora, necessitating additional consideration of relationships between texts and the structural information inside. GNN-RAG~\cite{mavromatis2024gnn} integrate Graph Neural Networks (GNNs) with RAG to retrieve reasoning paths. TIARA~\cite{shu-etal-2022-tiara} and ChatKBQA~\cite{luo-etal-2024-chatkbqa} enhance the generation of reliable logical forms by retrieving entities and relations from knowledge graphs. HyKGE~\cite{jiang2024hykge} leverages LLMs to explore feasible directions within medical knowledge graphs. Furthermore, \citet{ji-etal-2024-retrieval} advances the retrieval capabilities via CoT reasoning.
% 不管是哪类方法，基于图谱的精准检索能力都是进行问答所必须的。有许多相关的工作旨在优化基于图谱的检索能力。

% 我们对此进行了复杂度分析
% 假设
% \begin{algorithm}
% \caption{\model Workflow}\label{alg:self_reward inference}
% \begin{algorithmic}[1]
% \State {\bf Input:} input $x$ and preceding generation $y_{<t}$
% \State{\bf Output:} next output segment $y_t$
% \State \mgen predicts \ret~given $(x,y_{<t})$
% \If{\ret~== \textcolor{myred}{\texttt{[Relation Retrieval]}}}
%     \State $\hat{y_t}$ = $\mathcal{M}(x, y_{<t})$
%     \Comment{\textcolor{blue}{Hypo-Generator}}
%     \State Retrieve relevant graph relationship $\mathbf{R}$ using \mret given $(x,y_{t-1}, \hat{y_t})$ 
%     \State \mgen predicts \crel for each $r \in \mathbf{R}$ 
%     % \State \mgen predicts \crel given $x, d$ and $y_{t}$ given $x,d, y_{<t}$ for each $r \in \mathbf{R}$ \Comment{\textcolor{blue}{Generate}}
%     % \State Rank $y_t$ based on \crel, \cgr, \cuse 
% \EndIf
% \If{\ret~== \textcolor{myred}{\texttt{[Entity Retrieval]}}}
%     \State Retrieve entities $\mathbf{E}$ based on the relevant relationship $r' \in \mathbf{R}$
%     \State \mgen predicts \crel for each $e \in \mathbf{E}$ and \cre given $\{x, y_{<t}\}$
% \EndIf
% \If{\ret~== \textcolor{myred}{\texttt{[No Retrieval]}}}
%  \State \mgen predicts \cre given $x, d$ and $y_{t}$ given $x,d, y_{<t}$ for each $e \in \mathbf{E}$ 
%  \State \mgen predicts [Utility]
%  \EndIf

% % \Else
% %     \State $\mathcal{M}_{gen}$ predicts $y_t$ given $x$ \Comment{\textcolor{blue}{Generate} }

% \end{algorithmic}\label{algo:inference}
% \end{algorithm}

% \section{Preamble}
% \paragraph{Details of Graph Critic Model data collections.} 
% The shortest paths that connect the questions and answers are extracted as supervised label from graph. This can ensure that our reasoning path does not deviate too far from the target entity.
% % 这可以保证我们的推理路径不偏离目标实体太远
% We use the instruction and demonstration pairs to prompt GPT-4, listed 
% Following an official recommendation, we separate instructions and outputs with ``\#\#''. 
% We use the temperature 1 and set the maximum output token counts to be 200. 
% We discard instances where GPT-4 does not follow the designated output formats or output sequences that do not match our expected category names. 

\section{Preliminary}
In this section, we introduce the fundamental concepts of the knowledge graph question answering (KGQA) task and the definition of reasoning paths.
% : $\mathcal{G} = \{(s, r, o)|s\in \mathcal{E}, r\in \mathcal{R}, o \in \mathcal{E}\cup \mathcal{L}\}$, 

\textbf{KGQA.} The task of KGQA requires predicting the correct answers based on reasoning over both free-form text $q$ and an inherently structured graph $\mathcal{G}$. The KG here consists of a set of triplets $(s, r, o)$ defined in the RDF format where $s$ is an entity, $r$ is the corresponding relation, and $o$ can be either an entity or a literal value. Each entity $e$ is uniquely identified by a MID and some have a friendly name, \eg $e$.id = \textit{"m.03\_r3"} with its friendly name \textit{"Jamaica"}. Relations in the Freebase KG are defined hierarchically, \eg $r$ = \textit{"location.country.languages\_spoken"}. We assume that the topic entities $\{e_q\}$ and the candidate answers $\{a\}$ are linked to the entities or values in $\mathcal{G}$.

% , where the answers are entities inside the graph, \ie $\{a\} \in \mathcal{G}$
\textbf{Reasoning Path.} We define a valid reasoning path $w$ of depth $D$ is a sequence of connected triplets connecting the topic entity $e_q$ and the answer $a$, which can be also refereed to as a $D$ hop path:
% \begin{equation}
% \begin{aligned}
% w = \left\{ (e_s^d, r^d, e_o^d) \middle| e_o^i = e_s^{i+1},\\ \forall i \in \{1, \ldots, D-1\}\right\}_{d=1}^D
% \end{aligned}
% \end{equation}
% \begin{equation}
% \begin{aligned}
% w &= \Big\{ (e_s^d, r^d, e_o^d) | e_s^0=e_q, e_o^D = a, \\
% e_o^i &= e_s^{i+1}, \forall i \in \{1, \ldots, D-1\} \Big \}_{d=1}^D.
% \end{aligned}
% \end{equation}
% \begin{equation}
% \small
%     \mathcal{W} = \{w(e_q, a)= (e_q, r_1,e_1,\cdots,r_D, a)|e_q\in \mathcal{T}_q, a\in \mathcal{A}_q\}.
% \end{equation}
\begin{equation}
        w_{1:D}= (e_q, r_1,e_1,\cdots,r_D, a).
\end{equation}
Based on the iterative reasoning process, the objective of the KGQA task can be formulated as the optimization of the following function:
\begin{equation}
P_{\theta}(a|q, \mathcal{G}) = \mathbb{E}_{w_{1:D} \sim Q(w)}\prod_{i=1}^{D} P_{\theta}(w_i|w_{<i}, q, \mathcal{G}),
\end{equation}
where $Q(w)$ denotes the posterior distribution of the faithful reasoning path grounded in the KG.
% \begin{example}
% $w_z=\text{Jamaica}\xrightarrow{\texttt{location.country.languages\_spoken}}\text{Canada}$
% 'Jamaica', 'location.country.languages_spoken', 'Jamaican English'
% \end{example}
\section{Methodology}
\begin{table}[t!]
\centering
\footnotesize
\begin{tabular}{p{1cm}p{2cm}p{3.5cm}}\toprule
Token Type & Category & Definitions \\ \midrule
\textit{Retrieval}    & \{relation, entity, no\} & trigger retrieval \\
\textit{Relevance}  &\{relevant, partially, unrelevant\}  &   assess relevance with $q$ \\
\textit{Rationality}  &\{reasonable, partially, unreasonable\}  & evaluate logical coherence   \\
\textit{Utility} &\{5, 4, 3, 2, 1\}  & $a$ is a useful response to $q$.   \\
\bottomrule
\end{tabular}
    \caption{Four types of reflection tokens used in \model. Each type uses several tokens to represent its output values. Details can be found in Appendix~\ref{sec:appendix}}
   \label{tab:token} 
\end{table}
% \model 探索了通过special token实现在图谱数据上自动化推理的可能性。我们通过插入四类特殊字符拓展原来的词典。在\model 中，我们以端到端训练的方式使语言模型基于每一轮检索到的实体或关系决定是否进行下一轮检索，同时，模型评估检索到的知识，并对于当前选择的路径进行反思，最终对于问题给出可靠的回答。这些评分对于我们理解模型如何在图谱上推理有巨大帮助。相反的，其余的基于大模型的方式往往直接生成表达式或者答案，缺乏对于推理路径的反思。整个框架对于模型如何理解结构化数据提供insight，同时框架与图谱推理紧密结合起来
% We introduce \underline{A}ctive Self-\underline{R}eflection \underline{G}raph Reasoning (\model), shown in Figure~\ref{fig:Self-graph}. \model explores the potential of understandable reasoning over knowledge graph through the utilization of special tokens. 训练好的LM能够决定是否需要进行知识的检索以回答查询，同时在图谱推理的过程中不断输出相关性评估和合理性反思，直到输出回答。这些token在推理时以自回归的形式生成，而不需要单独生成。
% We propose \underline{A}ctive Self-\underline{R}eflection \underline{G}raph Reasoning (\model), as illustrated in Figure~\ref{fig:Self-graph}. \model investigates the potential for interpretable reasoning over knowledge graphs through the 插入四类 of special self-reflection tokens，其流程如算法1. The trained language model actively decide whether knowledge retrieval is necessary to answer the query while continuously producing relevance assessments and rationality reflections throughout the reasoning process over the graph, iterating until the final answer 和utility分数 is generated. These tokens are trained to generate in  an autoregressive manner during inference. 在检索过程中，训练的模型被要求进一步输出可能的关系，作为检索器输入的补充。  
We propose \underline{A}ctive Self-\underline{R}eflection \underline{G}raph Reasoning (\model), as illustrated in Figure~\ref{fig:Self-graph}. \model facilitates interpretable reasoning over knowledge graphs through the integration of four types of \emph{self-reflection}  tokens (see Table~\ref{tab:token}). The primary workflow during inference is detailed in Algorithm~\ref{alg:workflow}. The trained language model actively decides whether knowledge retrieval is necessary to answer the query, while continuously generating relevance assessments and rationality reflections throughout the graph reasoning process. The iterative process continues until the final answer and its associated utility score are produced. To further optimize retrieval efficiency during the retrieval stage, the trained model is additionally tasked with generating potential relation candidates to serve as supplementary inputs for the retriever. Ultimately, the final answer is derived from the reasoning tree constructed during the exploration process.
% These tokens are trained to be generated autoregressively during inference. 
% he original vocabulary is expanded by inserting four types of special tokens. Within \model, the model determine whether to proceed with subsequent iteration of retrieval based on the retrieved entities or relations, .
% Simultaneously, the model evaluates the retrieved knowledge each hop and critiques on the currently selected reasoning path, ultimately providing a reliable response to the query. The whole workflow provides significant insights into how the model comprehends the structural data while seamlessly integrating with graph-based reasoning.
% In contrast, other approaches employing LLM often directly generate expressions or answers without incorporating reflective mechanisms for reasoning pathways.

\begin{algorithm}
\small
\caption{\model Workflow}
\label{alg:workflow}
\SetKwRepeat{Do}{do}{while}
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}
 {\bfseries Require: }{Generator model \mgen, Retriever \mret, KG $\mathcal{G}$}\\
 {\bfseries Input: }{Topic entity $e_q$ and input query $q$}\\
 {\bfseries Output: }{predicted prediction tree $T$.}\\
 {\bfseries Initialization: } $T = [w_0], d=1, w_0=(e_q,)$ \\
\While {$d$ $\leq$ $D_{max}$} {
\mgen predicts \ret~given $(q,w_{<d})$\;
\uIf{\ret~==\textcolor{myred}{\small{\texttt{[Relation Retrieval]}}}}{
$\widehat{r_d}$ = $\mathcal{M}(q, w_{<d})$ \tcp*{\textcolor{blue}{Hypo-Generator}}
Retrieve relevant relationship $\mathbf{R}$ using \mret given $(q,e_{d-1}, \widehat{r_d})$ \;
    % \Comment{\textcolor{blue}{Retrieve}}
\ForEach{$r_d \in \mathbf{R}$ }{\mgen predicts \crel \;
 \uIf{\crel $\mathrel{\mathtt{!=}}$ \textcolor{myred}{\small{\texttt{[Unrelevant]}}}}{Add $r_d$ to $w_d$\;} }}
    % \State \mgen predicts \crel given $x, d$ and $y_{t}$ given $x,d, y_{<t}$ for each $r \in \mathbf{R}$ \Comment{\textcolor{blue}{Generate}}
    % \State Rank $y_t$ based on \crel, \cgr, \cuse 

\uElseIf{\ret~== \textcolor{myred}{\small{\texttt{[Entity Retrieval]}}}}{
Retrieve tail entities $\mathbf{E}$ using $r_d$\;
    % \Comment{\textcolor{blue}{Retrieve}}
\mgen predicts \cre\;
\ForEach{$e \in \mathbf{E}$}{\mgen predicts \crel\;
 \uIf{\crel $\mathrel{\mathtt{!=}}$ \textcolor{myred}{\small{\texttt{[Unrelevant]}}}}{Add $e_d$ to $w_d$\;} }

 }
\uElseIf{\ret~== \textcolor{myred}{\small{\texttt{[No Retrieval]}}}}{
\mgen predicts \cuse given $q, w_{<d}$\;
} 
Rank $w_d$ based on reflection score and append $w_d$ to $T$\;
}
\end{algorithm}
% 为了模仿在图结构中从起始节点到终止节点的推理流程，我们基于推理路径，构建高效的数据集。Reasoning paths~\cite{wang2021relational} can capture rich semantic information between entities. 一条推理路径能够被视为基于图谱上的一次有逻辑的游走。
% However, it is often challenging to directly obtain the labeled inferential path from the knowledge graph. Instead, we can typically leverage 图搜索算法 to identify the shortest paths that connect the topic entity and the label answer. Although these paths may not always represent the optimal reasoning path, they are grounded in the knowledge graph and provide insights toward the answer. 因此，我们在每一条推理路径，补充丰富数据，最终构成了我们的训练数据集。
\subsection{\model Training}
\label{sec:train}
To emulate the inferential process within a graph structure, we construct the training dataset based on the reasoning paths. Reasoning paths~\cite{wang2021relational, luo2023reasoning} are capable of capturing rich semantic information between entities. Each reasoning path can be regarded as a logically coherent walk over the knowledge graph.

Directly obtaining labeled inferential paths $\mathcal{W}^*$ from the knowledge graph often proves to be challenging. Instead, we can typically leverage graph search algorithms to identify the shortest paths connecting the topic entity and the target candidates. While these paths may not always correspond to the optimal reasoning paths, they are grounded in the knowledge graph and offer valuable insights toward deriving the answer, as shown in the following Example.

% 我们在这一节介绍Self-Graph，主要包括。
% 推理路径能够捕捉实体间丰富的语义信息，但是想要直接从图谱中获得标签的推理路径非常困难。但是，我们往往可以通过最短路径查找，寻找到连接两个实体的推理路径。这些路径尽管并不是最优路径，但是至少能够被图谱所确认落实，不会偏离太远。
% Example: 
% 给定问题"which countries border the us"，标签的推理路径是：
\textbf{Example.} Given the question \emph{"Which countries border the US"}, one of the labeled reasoning paths is: $w$ = \emph{US}$\xrightarrow{\texttt{adjoin}}$\emph{Canada}. At the same time, another valid reasoning path exists: $w^{\prime}$ = \emph{US} $\xrightarrow{\texttt{contains}}$\emph{Columbia River}$\xrightarrow{\texttt{flow\_through}}$\emph{Canada}.

Although the latter path $w^{\prime}$ does not directly provide the adjacency information between the two countries, it uses the fact that the \emph{Columbia River} flows through \emph{Canada} and arrives at the correct entity. Consequently, we leverage the reasoning paths grounded within the graph and design curated self-reflection tasks to insert reflection tokens, ultimately training the generator model.
% 因此，我们通过图谱中可获取的推理路径，通过设计curated的反思任务插入reflection token，最终训练得到生成模型。
 
% \begin{example}
% \label{example}
% Given the question "Which countries border the US", the labeled reasoning path is: $w$ = US$\xrightarrow{\texttt{adjoin}}$Canada. At the same time, we have another valid reasoning path: $w^{\prime}$ = US $\xrightarrow{\texttt{contains}}$Columbia River$\xrightarrow{flow\_through}$Canada

% Although the latter path $w^{\prime}$ does not directly provide the adjacency information between the two countries, it uses the fact that the Columbia River flows through Canada and arrives at the correct entity.
% % This reasoning path also ultimately leads to the correct answer, Canada, based on the inferred relationships.
% \end{example}


% \noindent {\bf Training overview.} 
% % \textcolor{red}{Collecting fine-grained reflection tokens in scale is expensive~\cite{wu2023fine}. }
% By using the valid path that links question entities and answers as weak supervision, we are able to collect reasoning paths grounded on the graph.

% \model enables any arbitrary language model (LM) to generate text augmented with reflection tokens by integrating these tokens as part of the next-token prediction process within an expanded model vocabulary (i.e., the original vocabulary supplemented with reflection tokens). Specifically, we train the generator model, \mgen, on a curated corpus that incorporates grounding reasoning paths and reflection tokens generated by large language models (LLMs), which are simultaneously grounded in knowledge graphs (KGs).

% The final generator model (\mgen) is trained using the conventional language modeling objective while actively leveraging information from the training process during the inference stage.
% \model enables an arbitrary LM to generate text with reflection tokens by unifying them as next token predictions from the expanded model vocabulary (i.e., the original vocabulary plus reflection tokens). Specifically, we train the generator model \mgen on a curated corpus with grouding reasoning paths and reflection tokens predicted by LLMs and at the same time grouded by the KGs.

% we train the final generator model (\mgen) using the conventional LM objective 并且同时在推理阶段actively利用训练过程中的信息。

\paragraph{Weakly Supervised Data Collecter.} 
% 给定输入输出对，我们首先通过有效的推理路径增强原来的数据。对于每条推理路径，我们对于其中的关系和实体补充候选集。对于有效推理路径上的每一个关系，我们利用Retriever检索K个语义相似的图谱关系；而对于推理路径中的每一个实体，我们会检索当前跳中相同关系对应的其他尾结点作为候选结点。为了模仿\model的推理过程，我们进一步进行反思过程的增强。在有效路径中间的每一跳，我们会加入\rret和\eret token。对于中间的备选关系和实体，我们会利用LLMs评估其对于回答query的贡献并输出相关性分数，对于每一个step，我们会评估其推理的合理性，最终我们会输出得到该回答的有效性。
%对上面得到的推理路径补充反思过程我们在附录中总结了收集训练数据的过程。
% we could find valid reasoning paths following~\cite{luo2023reasoning}.  
We summarize the process of data collection in Algorithm~\ref{algo:data_gen}. We first extract the shortest paths connecting the questions and answers as supervisory reasoning paths, following RoG~\cite{luo2023reasoning}. For each reasoning path, we augment it with candidate sets for both the relations and entities involved, which will be utilized for downstream relevance assessment. The retriever $\mathcal{R}$ is employed to retrieve $K$ semantically relevant relations as candidate relations $\mathbf{C_r}$. Similarly, all tail nodes corresponding to the same relation at the current hop are retrieved as candidate entities $\mathbf{C_e}$.

For special token incorporation, we modularize each task with different instruction prompts and leverage critic model $\mathcal{C}$ like GPT models\footnote{\url{https://platform.openai.com/docs/models}} for assessment, facilitating the efficient insertion of reflection tokens. We prompt the critic model with type-specific instructions, wherein relevant knowledge from the reasoning path is extracted and provided as input. Through few-shot demonstrations, the model produces the corresponding evaluation and reflection. For each reasoning path, we divide it into segments based on the number of hops. At each hop, we assess the relevance of both candidate entities and relations, while simultaneously evaluating the logical coherence of the current path. Retrieval tokens are inserted accordingly until the answer entity is reached. The utility of the final answer is evaluated at last. Ultimately, each reasoning path is assembled sequentially with self-reflection tokens. Notably, when the model predicts the reasoning as \textit{[Unreasonable]}, the retrieval process is immediately terminated, and the answer is added directly. This ensures that the training data avoids propagation through unreasonable paths. Moreover, the model can learn to provide responses based on its own knowledge when encountering unreasonable paths. We provide an example data from the training data in Figure~\ref{app:train_data}. More details are provided in the Appendix~\ref{app:prompt}. 
%app:train_data最终每一条推理路径会按照顺序组装，特别地，当模型合理性预测为[Unreasonable]时，我们会直接终止检索，输出答案。这样可以让训练数据从不合理的路径中停止。 详细的prompt和样本例子见附录。我们最终基于WebQSP和CWQ的训练集构造了29117条训练数据。
% 对于special tokens，我们通过预先模块化每个任务，通过LLM进行评估，使得插入relfection token更方便高效。对于上述的每条路径，我们按照hop分割成为segmentes。对于其中每一跳，我们对于实体和关系判断relevance。并对于当前路径的逻辑合理性进行评估，插入检索token。直到到达答案实体，我们综合评估得到的答案的utility分数。
% For reflection process, at each intermediate hop within the reasoning path, we insert retrieval tokens. For the intermediate candidate relations and entities, we leverage LLMs to evaluate their contributions to answering the query and output relevance scores. For each reasoning step, we assess the logical soundness of the reasoning process. Ultimately, we evaluate the validity of the reasoning path to produce the final answer.
\paragraph{Generator Learning.}
% \model 旨在极大化基于一个知识图谱G，相关的问题q,与检索到的candidates中自回归生成推理路径和相应反思token的概率，学习的目标可以表示为以下公式：    
We train the generator model \mgen by training on the curated reasoning paths augmented with self-reflection tokens from $\mathcal{D}_{gen}$. We approximate the expectation with $K$ sampled valid paths $\mathcal{W}_k^* \subseteq  \mathcal{W}^*$, using the standard next token objective:
% \begin{equation}\label{eq:gen_training}\footnote{The constants are ignored in the formula.}
% \begin{aligned}
%     \max_{\theta}&\mathbb{E}_{(w,q,r) \sim \mathcal{D}_{gen}} \log P_{\theta} (w, r| q, \mathcal{G}) \\
%     &= \log P_{\theta}(r | w, q)P_{\theta}(w|q, \mathcal{G}) \\ 
%     &\approx \sum_{w\in\mathcal{W}_K^*}\sum_{i=1}^D\log P_{\theta}(r_i|w_i)\log P_{\theta}(w_i|w_{<i}, q,,\mathcal{G} )
%     \end{aligned}
%     \end{equation}
\begin{equation}\label{eq:gen_training}
\begin{aligned}
\hspace{-2mm}
   &\mathcal{L} = \max_{\theta}\mathbb{E}_{(w,q, r)} \log \left( P_{\theta}\left( r | w, q\right)P_{\theta}\left(w|q, \mathcal{G}\right)\right) \\ 
 &\propto \sum_{w\in\mathcal{W}_k^*}\sum_{i=1}^D\log \left( P_{\theta}\left( r_i|w_{\leq i}\right) P_{\theta}\left(w_i|w_{<i},q,\mathcal{G} \right) \right),
    \end{aligned}
    \end{equation}
% \mgen同时学习预测下一跳推理和reflection tokens.在训练期间，我们对于检索到的知识同时计算损失。这样模型同时可以学习查询和相关知识的隐层映射关系，用于推理时辅助检索器检索。我们将所有的reflection tokens拓展到原来的词典中 (w,q,r)服从D的经验分布
where $(w,q, r)$ is sampled from the distribution of $\mathcal{D}_{gen}$. The generator model \mgen learns to predict the next-hop path accompanied by the corresponding reflection tokens. During training, the loss is computed jointly for the retrieved knowledge (surrounded by \texttt{<paragraph>} and \texttt{</paragraph>} in Figure~\ref{app:train_data}), enabling the model to concurrently learn the implicit mapping between queries and structural knowledge. The original vocabulary $\mathcal{V}$ is expanded with all reflection tokens.
\subsection{\model Inference}
% 关系路径能够捕获查询与结果之间的推理逻辑关系，我们利用关系路径作为推理的弱监督，我们可以确保生成的推理内容被KG所保证。在训练数据的构造阶段，我们将
% 我们设计了一套基于树结构的推理步骤和分数计算机制用于筛选答案并通过hypothesis增强的方法，提升推理过程中的检索精度。
%细颗粒度的反思tokens能够给予推理路径一个量化的评估。在推理过程中，我们采用了树结构的推理框架，并基于generation probability对每个节点生成了分数评估，帮助我们有效的剪枝冗余节点。
Fine-grained reflection tokens provide a quantitative evaluation of the reasoning path. During the inference process, we employ a tree-based reasoning framework and assign a score derived from generation probability to each node. The scoring mechanism enables the effective pruning of redundant nodes. Additionally, by incorporating a hypothesis-enhancement method, we improve retrieval accuracy by actively generating candidates one future step forward during the relation retrieval process.
\paragraph{Hypo-Generator.}
\label{sec:hypo}
% 直接基于语义相似度进行检索，往往由于查询和知识之间的gap导致检索的精度不高。在图谱中，关系的表示方式亦不同于自然语言，特别是在自动构建的知识图谱中噪声问题更为严重 ~\cite{codeKG}在图谱中，关系的层次也并不符合自然语言的表达。在模型训练的过程中，不同于self-rag，我们的模型学习到了图谱中可能的关系表示形式。因此，我们基于微调后的模型，在每次检索的时候预先预测可能要检索的关系，将其作为查询检索相关的关系，作为补充。Direct retrieval based on semantic similarity often suffers from low precision due to the inherent gap between the query and the knowledge representation. In knowledge graphs, the representation of relations differs significantly from natural language, and this issue is exacerbated by noise, particularly in automatically constructed knowledge graphs. jiang2024hykge
% \model在训练过程中从推理路径的candidates中学习到关系与查询的隐式关联。在推理的关系检索过程，我们首先让训练的模型多预测一步，得到可能的备选关系，并将预测中的有效信息作为检索器的输入。生成式模型的输出与图谱中的关系表示是一致的，这弥补了查询表示与结构化知识的差异。learns potential representations of relations within the knowledge graph during the training process. Therefore, leveraging the fine-tuned model, we preemptively predict the relations likely to be retrieved in each step and use these predictions as queries to retrieve relevant relations, serving as supplementary information.   During the training phase, \model learns the implicit associations between relations and queries from the candidates within the reasoning paths. In the relation retrieval process during inference, the trained model is prompted to predict an additional step to generate potential candidate relations, with the informative components of these predictions serving as input to the retriever. The output of the generative model is aligned with the representation of relations in the knowledge graph, effectively bridging the gap between query representations and structured knowledge.
Direct retrieval based solely on coarse-grained retrievers or LLMs often suffers from low precision due to the inherent gap between the query and the underlying knowledge~\cite{query-rewrite, zhang2024alter}. Moreover, the representation of relations (hierarchical in Freebase) in graphs does not always align with natural language. The issue is even more severe in automatically-constructed knowledge graphs~\cite{codeKG,li-etal-2022-c3kg}. During the training phase, \model learns the implicit associations between queries and structural knowledge by actively predicting retrieved relations from the graph. In the relation retrieval process during inference, the trained model predicts one more step for hypothetical relations. The predictions are transformed as additional input to the retriever. The output from the hypo-generator is aligned with the representation of relations in the graph, effectively bridging the gap between query representations and structured knowledge.
\paragraph{Tree-based inference.}
% 在每一次检索的过程中，生成模型会并行处理多条不同的推理路径并产生不同的选择。然而，在multi-step reasoning中，过多的候选集会引入误差和不确定性。beam search被证明能够 guide and calibrate the reasoning process of LLMs，减少uncertainty。更进一步，我们基于推理树，对于每一条有效路径评估其分数
% 最近，
% Recent advancements in tree-based inference approaches have demonstrated their efficacy in guiding and calibrating the reasoning process of LLMs~\cite{yao2024tree, feng2023alphazero,wu2024comparative},  thereby reducing uncertainty. 每一步并行的候选集最终构成针对问题的一棵.在本实验中，我们结合hard和soft constraint，基于推理树得到最终的结果。具体来说，对于产生的undesirable token，例如[UnRelevant]，我们不会继续生成下游路径。对于树的叶子节点，我们最终计算其得分。不同于reinforcement learning techiniques,需要训练一个奖励模型，我们tailors the generator model自动生成评估。
During each retrieval step, the generator model is capable of processing multiple candidates (both relations and entities) in parallel, leading to the generation of diverse downstream reasoning paths. The parallel candidate sets collectively form a reasoning tree for the given query. Tree-based reasoning methods~\cite{yao2024tree, feng2023alphazero,wu2024comparative} have recently been widely adopted to enhance the reasoning process. Unlike other approaches that train a separate reward model, our model leverages the evaluation of special tokens as a process reward model, enabling effective assessment of tree nodes within the graph. During inference time, we integrate both hard and soft constraints and adopt a hop-level beam search strategy, retaining the top-$B$ candidates with the highest relevance and logical coherence scores. Specifically, for any candidate with undesirable tokens generated (\eg \textit{Unrelevant}), we simply prune it. Otherwise, we proceed to explore based on the current candidate and compute scores derived from the generation probability of special tokens. For the leaf nodes of the tree, we traverse back through the entire tree to aggregate final scores. The detailed score mechanism can be found in Appendix~\ref{app:score}.

%基于树的推理方法最近被常用于增强推理过程。不同于其他方法单独训练reward model，我们的模型利用special token的评估作为process reward model，能够对于图谱中的树结点进行有效评估。wu2024comparative However, in multi-step reasoning, an excessively large candidate set may result in increased computational overhead and amplified uncertainty. To address this, we  Additionally, each valid reasoning path is assessed through a scoring mechanism that evaluates the generation probability of special tokens derived from the hierarchical structure of the reasoning tree. The specific scoring computation is detailed in the Appendix.
% Therefore, we propose
% anticipating the future by generating a temporary
% next sentence, using it as a query to retrieve relevant documents, and then regenerating the next
% sentence conditioning on the retrieved documents
%  an active retrieval
\section{Experiments}
% \subsection{Experiemental Setup}
\subsection{Datasets and Evaluation Metrics.} We evaluate our proposed method and compare it with other methods on two widely-used KGQA benchmark datasets: WebQSP~\citep{STAGG} and CWQ~\citep{CWQ}. Specifically, WebQSP contains 4,737 natural language questions with SPARQL queries, with 3,098 in the training set and 1,639 in the testing set. CWQ contains 34,689 natural language questions with SPARQL queries, with 27,639 in the training set  3,519 in the validation set and 3,531 in the testing set. Both datasets are based on Freebase~\citep{Freebase} KB. More details of datasets are in Appendix~\ref{app:datasets}.
\subsection{Baselines.} We compare \model with 13 baseline methods grouped into 3 categories: 1) Semantic Parsing(SP)-based methods, 2) Information Retrieval(IR)-based methods, and 3) LLM-based methods. More details of baselines are in Appendix~\ref{app:baseline}.

\subsection{Experimental Settings.}
% 我们使用了4 NVIDIA A100 GPUs with 40GB memory to train the model. 所有的模型训练了3个epoch，batch size为16，最大学习率为1e-5.我们使用Deepspeed staeg3来进行多GPU分布式训练。我们使用了LLamaFactory for efficient training. ~\cite{zheng-etal-2024-llamafactory}
\paragraph{Training details.}
In total, we collect 29,117 training samples based on the training splits of WebQSP and CWQ. For the modular evaluation task of different self-reflection tokens, we employ GPT-4-mini considering computational costs and efficiency. During the training process, we use 4 NVIDIA A100 GPUs with 40GB memory to train the generator model. All models are trained for 3 epochs, with a batch size of 16 and a maximum learning rate of 1e-5. We use Deepspeed stage 3~\cite{rajbhandari2020zero} for multi-GPU distributed training. For the efficient training framework, we utilize LlamaFactory~\cite{zheng-etal-2024-llamafactory}. We employ LLama3-8b~\cite{dubey2024llama} as our base LLM backbone. 
\paragraph{Inference settings.}
For each hop-level segment, we employ a beam width of 3 by default. For the WebQSP dataset, the default search depth is set to 2, while for CWQ, the default search depth is 4. During the inference process, we utilize VLLM to accelerate reasoning. For the default retriever $\mathcal{R}$, we adopt bge-large-en-v1.5~\cite{bge_embedding}. During the construction of training data and the retrieval process, the default number of retrieved items is set to $K=5$.

\begin{table}[]
\caption{\small{Results of different methods on WebQSP and CWQ. (We use \underline{underline} to denote the second-best performance, \textbf{bold} to denote the best performance. $B$ stands for beam-width and \textit{Exhuasted} means exhausted search.)}}
\resizebox{1\linewidth}{!}{
\renewcommand{\arraystretch}{1.1}
\setlength{\tabcolsep}{3pt}
\begin{tabular}{@{}lcc@{}}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{Model}} & \multicolumn{2}{c}{Hit@1 (\%)} \\ \cmidrule(l){2-3} 
\multicolumn{1}{c}{} & \textbf{\textsc{WebQSP}} & \textbf{\textsc{CWQ   }} \\ \midrule
\rowcolor[rgb]{0.9,0.9,0.9}
\multicolumn{3}{c}{\textit{$\clubsuit$ SP-based methods}} \\ \midrule
DECAF~\cite{DECAF} & 82.1 & 70.4  \\
% RNG-KBQA~\cite{RnG-KBQA} & 1 & 2  \\
TIARA~\cite{shu-etal-2022-tiara} &  75.2 &  -  \\
ArcaneQA~\cite{gu-su-2022-arcaneqa} & 75.6&  -\\
ChatKBQA~\cite{luo-etal-2024-chatkbqa} &86.4 & \textbf{86.0}\\
% KB-BINDER~\cite{kb-binder} &  &   \midrule
\rowcolor[rgb]{0.9,0.9,0.9}
\multicolumn{3}{c}{\textit{$\heartsuit$ IR-based methods}} \\ \midrule
GrafNet~\cite{sun-etal-2018-open} & 66.4 &   36.8\\
PullNet~\cite{sun2019pullnet} &  68.1&   45.9\\
Subgraph Retrieval~\cite{zhang-etal-2022-subgraph} & 69.5 &  50.2 \\ 
UniKGQA~\cite{UniKGQA} & 77.2& 51.2\\
\midrule
\rowcolor[rgb]{0.9,0.9,0.9}
\multicolumn{3}{c}{\textit{$\spadesuit$ LLM-based methods}} \\ \midrule
 StructGPT~\cite{jiang-etal-2023-structgpt} &  72.6 &   -\\
 KG-Agent~\cite{jiang2024kg} & 83.3 & 72.2\\
 RoG~\cite{luo2023reasoning} & 85.7 &  62.6\\
ToG w/ChatGPT~\cite{sun2023think} &  76.2&  57.1\\
ToG w/GPT-4~\cite{sun2023think} &  82.6&  67.6\\
\model ($B=1$)&  84.0 &   61.7 \\ 
\model ($B=3$)& \underline{90.2} &   72.4 \\ 
\model (\textit{Exhausted}) & \textbf{93.5} & \underline{79.8} \\
\bottomrule
\end{tabular}
}
\label{tab: main}
\end{table}

\subsection{Main Results}
% 我们在表1中分别展示了\model在最终聚合根节点个数为1,3,al与baselinesl在WebQSP和CWQ数据集上相比较的结果。从表中可以看出，我们的方法在两个数据集上取得了显著的结果。其中\model 3超过了在WebQSP数据集上超过了所有的比较的方法，在CWQ数据集上仍然超过所有IR-based和LLM-based的方法。特别是在LLM-based方法中，与ToG同样基于图谱迭代推理的方法 w/GPT-4相比超过分别超过了$7.6\%$和$4.8\%$。注意到随着聚合节点的个数增加，我们的模型分数同时上升，这说明\model张成的推理树能够探索到足够丰富的图谱知识，并识别相应的正确回答。我们在表1中展示了\model采用了beam-width为1，3和进行exhausted search时与baselines在WebQSP和CWQ数据集上相比较的结果。
We present in Table~\ref{tab: main} the comparative results of \model employing beam-width of $1$ and $3$, as well as exhaustive search, with the baselines on the WebQSP and CWQ datasets. From the table, it is evident that our method achieves significant improvements on both datasets. Notably, \model achieves state-of-the-art results on WebQSP. On CWQ, the model's performance surpasses all IR-based and LLM-based models. Specifically, when compared to ToG, the latest graph-based iterative reasoning approach leveraging GPT-4, \model ($B=3$) achieves improvements of $7.6\%$ and $4.8\%$, respectively. As the beam width increases, the performance of our model also improves. The outstanding performance of \model underscores its capability to effectively explore knowledge within the graph and accurately identify plausible answers.

% with 3 aggregated root nodes surpasses all comparative methods on the WebQSP dataset and consistently outperforms all IR-based and LLM-based methods on the CWQ dataset. Specifically, when compared to ToG, a graph-based iterative reasoning approach leveraging GPT-4, \model achieves improvements of $7.6\%$ and $4.8\%$, respectively. It is worth noting that as the beam width increases, the performance of our model also improves, indicating that the reasoning tree constructed by \model effectively explores rich knowledge from the graph and accurately identifies the correct answers.

\subsection{Ablation Study}
We carry out an ablation study to assess the impact of various components and hyperparameters on the performance of \model, as well as to explore the contribution of each type of self-reflection token.

\begin{figure}[htbp]
    \centering\includegraphics[width=\linewidth]{latex/pics/depth_width_combined.pdf}
    \caption{Ablation results of different reasoning depth and search depth on the WebQSP and CWQ.}
    \label{fig:abl-1}
\end{figure}
\paratitle{Analysis of Search Depth \& Width.}
% 为了探究检索时检索的深度和beam width的关系对于\model的影响，我们在CWQ数据集上改变了推理时搜索的宽度和深度进行了实验如图，。CWQ数据集中包含更复杂，更深度的推理问题。从图中可以得知，在推理时增加检索的宽度和深度可以极大的提升检索的命中率，这说明了\model 能够捕捉到更深更广的有效信息并利用。但同时，更广的推理，特别是更宽的检索宽度，可能会引入部分的噪声，带来不确定性，这从图中F1值的变化可以得到，因此在实验中我们需要根据需求选择检索参数。 The CWQ dataset comprises more complex and deeper reasoning questions.
To investigate the impact of reasoning depth and beam width on the performance of \model, we conduct ablation experiments on the CWQ and WebQSP datasets. We vary the depth from $1$ to $4$ and the beam-width from $1$ to $5$. Additionally, we adopt an exhaustive search during the retrieval process, retaining all valid nodes for expansion (excluding undesirable tokens). The results are presented in Figure~\ref{fig:abl-1}. From the results, it can be observed that increasing the width and depth during reasoning significantly enhances the performance, demonstrating that \model is capable of capturing deeper and broader effective information by improving the exploration range. For the WebQSP dataset, the decline in performance improvement when the hops exceed $2$ is attributed to the dataset's focus on questions primarily within 2 hops. Meanwhile, broader reasoning, particularly with a wider retrieval width, may introduce noise, leading to increased uncertainty, as reflected in the changes in F1 scores. Therefore, selecting appropriate parameters is indeed necessary in practice.


% it is necessary trade-off between exploration and exploitation in practice. 
\paratitle{Analysis of Self-Reflection Tokens.}
% 我们进一步探究self-reflection tokens对于\model起到的作用。具体来说，在推理过程中，我们分别在计算中分别去除了四类分数包括Relevance,Reasoness,Utility以及Sequence score的贡献，并分别在WebQSP上重新进行了实验。实验结果如图1
% 组合去除了推理树分数计算中Relevance,Reasoness,Utility以及Sequence score并探究其对结果的影响。从结果中，我们可以发现，单独去掉Relevance或者Reasoness的分数，模型性能会轻微下降，但失去Relevance和Reasoness的分数，模型的表现都会有较大程度的下降，这说明在推理过程中,Relevance和合理性的判断对于模型正确推理十分重要，这两者相互补充，综合运用这两者综合推理能够在图谱推理任务中取得较大提升。
We further investigate the role of self-reflection tokens in \model by conducting an ablation study on the WebQSP dataset. Specifically, during the reasoning process, we selectively removed the contributions of four types of scores, including \textit{Relevance}, \textit{Rationality}, \textit{Utility}, and \textit{Sequence}. The experimental results are illustrated in Figure~\ref{abl:special}. From the experimental results, we observe that removing either the \textit{Relevance} or \textit{Rationality} score individually leads to a slight decline in model performance. However, when both \textit{Relevance} and \textit{Rationality} scores are omitted, the model's performance deteriorates significantly. This demonstrates the importance of both \textit{Relevance} and \textit{Rationality} and the complementary relationship of the two aspects. The most significant performance decline occurs when only the utility token is utilized. In this scenario, the model solely evaluates the quality of generations, which compromises the factuality of the reasoning process. With all scores integrated together, \model achieves optimal performance.
\begin{table}[]
\caption{Ablation results for investigating the impact of special tokens, the check mark indicates the retention of the contribution of that particular token type to the final score.}
\resizebox{1\linewidth}{!}{
\renewcommand{\arraystretch}{1}
\setlength{\tabcolsep}{3pt}

\begin{tabular}{@{}cccc|c@{}}
\toprule
Relevance & Rationality & Utility & Sequence & \textbf{\textsc{WebQSP}} \\ \midrule
\usym{1F5F8} & \usym{1F5F8} & \usym{1F5F8}& \usym{1F5F8} &  83.9\\
\textbf{} &\usym{1F5F8} & \usym{1F5F8} &\usym{1F5F8} & 82.4 \scriptsize{\textcolor{cadmiumgreen}{(-1.5)}}\\ 
\usym{1F5F8} & \textbf{} & \usym{1F5F8} & \usym{1F5F8} & 83.6\scriptsize{\textcolor{cadmiumgreen}{(-0.3)}} \\
\textbf{} & \textbf{} & \usym{1F5F8} & \usym{1F5F8} & 80.9\scriptsize{\textcolor{cadmiumgreen}{(-3.0)}} \\
\textbf{} & \textbf{} & \usym{1F5F8} & \textbf{} & 78.9\scriptsize{\textcolor{cadmiumgreen}{(-5.0)}} \\
\textbf{} & \textbf{} & \textbf{} & \usym{1F5F8} & 79.7\scriptsize{\textcolor{cadmiumgreen}{(-4.2)}} \\
\bottomrule
\end{tabular}
}
\label{abl:special}
\end{table}

\begin{table}[]
\small
\vskip -0.05in
\caption{Ablation results of different retrieval settings, where \wo
hypo-generator represents using the query directly as the retrieval input.}
\centering
\resizebox{0.9\linewidth}{!}{
\renewcommand{\arraystretch}{1}
\setlength{\tabcolsep}{3pt}
\begin{tabular}{@{}lcc@{}}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{Methods}} & \multicolumn{2}{c}{Hit@1} \\ \cmidrule(l){2-3} 
 & \textbf{\textsc{WebQSP}} & \textbf{\textsc{CWQ}} \\ \midrule
Ours ($K=5$) & 90.2 & 72.4 \\ \midrule
\wo hyper generator &  85.1 &  69.3\\
\wo naive retriever & 87.2 & 70.3 \\
\model ($K=3$) &  89.5 &  71.1\\ \bottomrule
\end{tabular}
}
\label{abl:hypo}
\vskip -0.1in
\end{table}
\paratitle{Analysis of Hypo-Generator.}
% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% \begin{figure}[htbp]
%     \centering\includegraphics[width=\linewidth]{latex/pics/recall.pdf}
%     \caption{Ablation results of different reasoning depth and search depth on the WebQSP and CWQ.}
%     \label{fig:abl-1}
% \end{figure}
% 我们在检索的过程中，利用Hypo-Generator对于原来朴素的检索器进行补充。我们进一步验证了Hypo-Generator的有效性。
% 我们对hypo-generator模块对\model的检索效率的影响进行了探究。实验结果如图。我们对比了单独直接基于query检索和单独基于hypo-generator增强的结果。从结果中可以发现，两者的表现都有所下降。但是注意到，采用$K=3$的\model性能会显著优于单独使用两种方法。这表明了hypo-generator能够很好的结合到\model的框架中，并辅助增强检索过程的效果。
We conducted an investigation into the impact of the hypo-generator module on the retrieval efficiency of \model. The experimental results are presented in the Table~\ref{abl:hypo}. We compared the performance of direct retrieval based solely on the query and retrieval enhanced exclusively by the hypo-generator. From the results, it can be observed that both approaches exhibit some performance degradation. However, it is noteworthy that \model with $K=3$ significantly outperforms the individual use of either method. This indicates that the hypo-generator is effectively integrated into the \model framework and serves to enhance the retrieval process.
\subsection{Transferring to Other KGs}
% 为了进一步验证我们的方法在其他KGs的迁移性，我们在基于Wiki-Movies KGs图谱上，其关系的表示形式不同于Freebase数据库，进行了额外的实验。我们采用MetaQA-3hop数据集。我们从训练数据集中抽样1000条样本按照同样的数据构造方式构造训练集，并利用两种训练策略微调\model.1）重头训练。从LLama3-8b中直接训练。 2)从从Freebase训练后的\model迁移并继续微调。最终的结果如表1，从结果可以看出，我们的模型能够适应迁移到不同的KGs，并且从Freebase迁移之后的模型具有更好的表现。这说明了通过学习图谱间的结构信息，模型能够快速迁移到其他新的图谱中
To further validate the transferability of our approach to other KGs, we conduct additional experiments on the Wiki-Movies KG, whose relational representations differ from those of Freebase. We use the MetaQA-3hop~\cite{zhang2018variational} dataset for the construction of training data and evaluation purposes. From the training split, we sample 1,000 examples and construct the training set following the same data construction methodology in Section~\ref{sec:train}. Subsequently, we fine-tune \model using two distinct training strategies, as utilized by RoG~\cite{luo2023reasoning}: 1) training from scratch, where the model is trained directly from the base LLM; and 2) transfer from Freebase, where the model pre-trained on Freebase is further fine-tuned on the new dataset. We select several representative works that demonstrate transferability across multiple knowledge graphs for comparison. The comparative results are presented in Table~\ref{exp:transfer}. From the results, it can be observed that our model demonstrates adaptability to different KGs. Moreover, the model fine-tuned from Freebase exhibits superior performance, demonstrating that by learning structural knowledge representation internally, the model can rapidly transfer to other new graphs.
\subsection{Case Study}
\begin{table}[]
\caption{Results of transferability of \model on MetaQA-3hop dataset based on Wiki-Movies KG. }
\resizebox{1\linewidth}{!}{
\renewcommand\arraystretch{0.9}
\setlength\tabcolsep{4pt}
\centering
\begin{tabular}{@{}lc@{}}
\toprule
\multicolumn{1}{c}{\multirow{2}{*}{Methods}} & \multicolumn{1}{c}{Hit@1 (\%)} \\ \cmidrule(l){2-2} 
\multicolumn{1}{c}{} & \multicolumn{1}{c}{\textbf{\textsc{MetaQA-3hop}}} \\ \midrule
StructGPT~\cite{jiang-etal-2023-structgpt} &  80.2\\
Retrieval \& Reasoning~\cite{ji-etal-2024-retrieval} & 76 \\
RoG (train from scratch)~\cite{luo2023reasoning} &  84.81\\
RoG (transfer from Freebase)~\cite{luo2023reasoning} &  88.98\\
\midrule
Ours (train from scratch)& 87.7 \\ 
Ours (transfer from Freebase)& \textbf{89.4}   \\ \bottomrule
\end{tabular}
}
\vskip -0.1in
\label{exp:transfer}
\end{table}
% 我们进行了详细的case study，对比同样迭代推理的ToG方法说明了我们方法的优点。具体的例子展示在Appendix中，case1查询了Niall Ferguson’s wife.ToG has 3-hop-deep reasoning paths,在depth-1检索到了大量relationships和entities。并在后续持续基于错误的实体进行检索，带来额外的开销。但是\model retrieved the correct answer “Ayaan Hirsi Ali” after 2 steps of inference,The reasoning process starting from “Marriage” is judged as [Unreasonable] in just one step and immediately stops.这说明了\model能够在inference过程中及时终止不合理的检索，减少开销。We also conduct case studies comparing ToG method with our ARG method. In Case 1 we select, the query is “Who is Niall Ferguson’s wife?”. Starting from “Niall Ferguson”, ToG has 3-hop-deep reasoning paths, with a large number of relationships and entities retrieved. ToG finds the correct answer “Ayaan Hirsi Ali” at Depth-2, but the reasoning process continues to retrieve other unrelated entities. In addition, there are meaningless loop structures in the inference paths, with some inference chains returning to “Niall Ferguson”, but ToG can not terminate those chains. However, ARG takes “Niall Ferguson” and “Marriage” as top entities and starts inference from these two entities separately. Starting from “Niall Ferguson”, ARG retrieved the correct answer “Ayaan Hirsi Ali” after 2 steps of inference, and the corresponding Reason Token is [Fully Reasonable]. The reasoning process starting from “Marriage” is judged as [Unreasonable] in just one step and immediately stops. It can be seen that a unique advantage of ARG is that it can terminate the inference process immediately when it is unreasonable, reducing the waste of time.
We conduct a detailed case study to compare our method with the ToG approach, which also performs iterative reasoning, thereby highlighting the advantages of our proposed framework. Specific paths are provided in Table~\ref{case:1}-\ref{case:3}.
In Table~\ref{case:1} the user queries the wife of "Niall Ferguson". ToG employs a 3-hop-deep reasoning path, retrieving a large number of relationships and entities at depth-1. It subsequently continues reasoning based on erroneous entities, resulting in additional computational overhead. In contrast, \model successfully retrieved the correct answer, "Ayaan Hirsi Ali," after just 2 inference steps. The reasoning process starting from "Marriage" was identified as \textit{Unreasonable} within a single step and was promptly terminated. This demonstrates that \model is capable of halting unreasonable retrieval processes during inference, thereby reducing unnecessary overhead.
% In table~\ref{case:2}, the user queries about the type of art "Marc Chagall" do. ToG未能检索到正确的关系，最终生成了一个vague的结果"Painting"。但是\model捕捉到了图谱中不明显的关系，通过hypo-generator通过正确的关系检索到了合理的答案。In Case 2, the query is "What type of art does Marc Chagall do?". TOG retrieves multiple unrelated relations, ultimately resulting in a vague answer "Painting". ARG accurately retrieves the most relevant relation "visual\_art.art\_period\_movement.associated\_artists" and finds five completely correct answers from this relation, such as "Expressionism" and "Modern art". This is mainly because ARG uses hypo-generator for retrieval. If LLM is directly used for retrieval, the retrieval results are often unsatisfactory because of the differences between graph structure knowledge and natural language text. However, the hypo-generator can understand the implicit association between queries and relation candidates, thereby retrieving the most accurate relation. This indicates that ARG has advantages in the ability to retrieve correct relations.

In Table~\ref{case:2}, the user queries about the type of art "Marc Chagall" do. ToG fails to retrieve the correct relationship, ultimately producing a vague response, "Painting." In contrast, \model identifies subtle relationships within the knowledge graph and, utilizing the hypothesis generator, retrieves the proper answers through the correct relational pathway. This demonstrates the effectiveness of the hypo-generator in enhancing retrieval process.

In Table~\ref{case:3}, the user queries "where do Florida Panthers play?". ToG provides "Sunrise", which is the incorrect answer. Notably, ToG does retrieve the correct answer, "Miami Arena," at depth-2; however, it fails to identify the entity and doesn't output the correct result. In contrast, \model finds two correct answers "Miami Arena" and "BB\&T Center" through a concise reasoning path. This indicates that \model also has advantages in the ability to retrieve and identify correct entities.
% In Case 3, the query is "Where do Florida Panthers play?". The answer "Sunrise" provided by TOG is incorrect, and it is worth noting that TOG does retrieve "Miami Arena" at Depth-2, but does not recognize it as the correct answer. In contrast, ARG finds two correct answers "Miami Arena" and "BB\&T Center" through a concise reasoning path. 

\section{Conclusion}
% 本工作提出了\model，一个新的在结构化图谱数据上通过retrieve on demand和self-reflection进行可信推理的框架。通过使用reasoning paths作为弱监督训练数据，我们训练模型学习迭代的检索，反思，生成。更进一步，我们通过Hypo-Generator大幅增强了检索的召回率，捕捉了图谱中的隐藏信息。生成的reasoning paths具有良好的可解释性和可视化程度。我们相信我们的方法能够对于探究模型如何理解结构化信息有启发。
This work introduces \model, a novel framework designed for reliable reasoning over structured graph data through on-demand retrieval and self-reflection mechanisms. By leveraging reasoning paths as weakly supervised training data, the model is trained to perform iterative retrieval, reflection, and generation. Furthermore, the retrieval performance is significantly enhanced through the hypo-generator, enabling the capture of latent information within the graph. The generated reasoning paths exhibit high interpretability. We posit that our approach offers valuable insights into how models comprehend structured information, contributing to the broader exploration of interpretable reasoning in machine learning.
\section{Limitations}
% \model实现了端到端的在结构化图谱中迭代进行反思推理，在推理过程中，通过推理树得到最终的答案。最近基于树的推理方法在复杂推理中被经常使用，常规的树检索方法往往会带来不确定性，这会反映在结果的精度不够高。未来，可以结合最新的树推理方法，例如RLHF中用到的方法，进一步提高树结构的推理精度。
\model achieves iterative reflective reasoning over structured graphs in an end-to-end manner, where the final answer is derived through a reasoning tree during the inference process. Recently, tree-based reasoning methods are frequently employed in complex reasoning tasks; however, conventional tree-based approaches often introduce uncertainty, which is reflected in suboptimal precision. In the future, integrating advanced tree reasoning techniques, such as those utilized in Reinforcement Learning from Human Feedback (RLHF) and deep reasoning models~\cite{feng2023alphazero, xie2023self,guan2025rstar}, could further enhance the precision of tree-structured reasoning. We will leave these explorations for future work.
% \model 首次探索
% 在附录中，针对我们Introduction部分提到的几个现实问题，我们进行了相应的case analysis，我们对比了\model与ToG在基线数据集中的种种表现。

\bibliography{main.bbl}

\appendix
\clearpage

\input{latex/appendix/appendix}
\end{document}
